1|39|Public
5000|$|In Denmark, Gerald Broflovski {{escapes from}} the control room {{with the help of}} both the troll team and the betrayed Troll Trace workers. He is guided across the {{facility}} to overload Troll Trace's operations, attracting the attention of Troll Trace CEO Lennart Bedrager. Bedrager confronts Gerald on a bridge leading to the final <b>overload</b> <b>switch,</b> resulting in a debate over the nature of trolling that Gerald [...] "wins" [...] by kicking Bedrager in the crotch and throwing him over a railing to his death. At the SpaceX facility, Cartman evacuates Elon Musk and the workers with a fake bomb threat from NASA before distracting Heidi long enough for Butters and an allied SpaceX employee to rig the Internet to the Mars power source.|$|E
25|$|Part of the {{previous}} permissive dialing plan included a mass calling prefix for radio station contests, introduced in the 1960s because some contests put unacceptable loads on the Bay Area's telephone switches. Until the 1980s, radio station call-in contests throughout the Bay Area used 575-numbers. Electromechanical switching equipment of the day had been engineered to accommodate large call volumes to 575-numbers. Large numbers of calls would otherwise have <b>overloaded</b> <b>switching</b> equipment causing slow dial tone and blocked long distance circuits.|$|R
50|$|For {{the next}} five minutes, Tappahannock, the key target of the Japanese dive bombers, fought for her life. The first Japanese dive bomber came in from off the port quarter — as the ship was {{swinging}} to starboard to evade the attack — and dropped her bomb abaft the bridge. The oiler shuddered as the explosion sent up a geyser of water higher than the mainmast. Three cane fenders and a Franklin lifebuoy were carried away topside while a fountain of water showered the bridge. Below, thermo <b>overload</b> <b>switches</b> went dead in the machinery spaces, and the oiler began to lose way.|$|R
40|$|We {{provide an}} {{analytical}} {{proof that the}} departure rate of a CBR flow at an overloaded link with FIFO buffers {{is proportional to the}} flow’s share of the total offered load at the link. This property of FIFO scheduling was recently validated in [1] in a series of traffic measurement experiments. An extension of the analysis to a multi-node scenario shows that the output rate of a flow in a network with many <b>overloaded</b> FIFO <b>switches</b> approaches the pessimistic values given by blind multiplexing...|$|R
40|$|Adding {{capacitors}} to {{an electric}} power system provides well known benefits, including power factor correction, voltage support and increase of active power transfer capacity. However, the capacitor banks modify the harmonic voltages and currents in the network and give rise to current and voltage transients, stressing switching devices and sensitive loads. The {{first part of the}} paper describes measurements and studies performed before the installation of 2 x 50 MVAr capacitor banks in a 500 - 132 kV substation, in the Argentinian Transmission System. By measurements of harmonics content in voltage and current, the IITREE performed some studies to quantify the harmonic voltage in the 132 kV busbar and the harmonic voltages and currents in the capacitors to prevent excessive <b>overload.</b> <b>Switching</b> Transients were also studied. The studies carried out with the Electromagnetic Transients Program (EMTP) are presented. The second part of the paper deals with measurements performed after the installation of the 2 x 50 MVAr capacitor banks. These measurements were carried out to verify the harmonic levels in the busbar and in the capacitor bank, and to obtain the current and voltage switching transients. The results of measurements are compared to the ones obtained by studies and simulations...|$|R
40|$|Previous {{papers have}} {{described}} and evaluated theperformance of the Early Packet Discard techniquefor maintaining packet integrity during <b>overload</b> inATM <b>switches.</b> In this paper a packet discard scheme is proposedwith the goal to provide both good performance interms of throughput and fairness {{in terms of}} band-width exploitation of the output link among all vir-tual circuits. In the scenarios here considered, theproposed discard scheme is shown to provide verygood results and to represent therefore a remarkableimprovement of the classical Early Packet Discard. Numerical results are reported and discussed forcomparing these two discarding schemes under dif-ferent operating conditions...|$|R
25|$|The diesel {{alternator}} {{sets for}} the carriages provided 3-phase 415-volt alternating current power. Only 1 phase {{was required for}} operation, so the other two phases were available for backup or for load-sharing across other carriages - useful because the ACN and BN cars required 28kW to operate and the BRN, with its additional functions, 40kW. To accommodate the extra load, the ACN and BN were upgraded midway through construction to a 35kVA supply, and the programming reworked so that the BRN would not power adjacent cars. If all alternators were off, then the cars {{was able to take}} power from an external 240vAC power supply. Around the same time as these modifications were made, the alternator set supports were modified to reduce vibration, and the radiator fan motors' thermal <b>overload</b> <b>switches</b> were moved to reduce unnecessary tripping. At the end of the modifications, the system was organised so that in event of a power failure, the batteries mounted under the carriages would automatically reroute all power to the lights at the ends of the train to protect from oncoming traffic. Those lights could function for over ten hours, at the expense of air-conditioning and other functions. The first six cars had plastic fuel pipes near the alternator units, but that was changed from car 7 onwards.|$|R
40|$|A many-to-one {{communication}} pattern is present both in Data Acquisition (DAQ) and datacenter networks. The problem arising from {{this pattern is}} widely known in the literature as incast and can be observed as TCP throughput collapse. It {{is a result of}} <b>overloading</b> the <b>switch</b> buffers, when a specific node in a network requests data from multiple sources. This paper provides two contributions. First, we confirm that there are strong analogies between the TCP behavior in DAQ and datacenter networks. Second, we evaluate different proposals from datacenter for application in DAQ to improve performance and reduce buffer requirements...|$|R
5000|$|Spencer joined Harvard in February 1997 as a {{consultant}} for federal policy issues. The following year, she was appointed associate vice president for higher education policy reporting to the President, and quickly rose through the ranks to become the Vice President for Institutional Policy. Spencer was widely known for “her collaborative approach, effectiveness in getting things done and passionate commitment to access and affordability.” In January 2003, Spencer's profile, along with other Harvard faculty was filtered into then-student Mark Zuckerberg's newly created [...] "Facemash", the site was shut down by Harvard's administration because it <b>overloaded</b> network <b>switches</b> and limited internet access.|$|R
40|$|Cluster-based and iSCSI-based storage systems rely on {{standard}} TCP/IP-over-Ethernet for client access to data. Unfortunately, when data is striped over multiple networked storage nodes, a client can experience a TCP throughput collapse {{that results in}} much lower read bandwidth than should be provided by the available network links. Conceptually, this problem arises because the client simultaneously reads fragments of a data block from multiple sources that together send enough data to <b>overload</b> the <b>switch</b> buffers on the client’s link. This paper analyzes this Incast problem, explores its sensitivity to various system parameters, and examines the effectiveness of alternative TCP- and Ethernet-level strategies in mitigating the TCP throughput collapse. ...|$|R
5000|$|In the {{construction}} of many small switches, the spring that stores the mechanical energy necessary for the snap action of the switch mechanism is made of a beryllium copper alloy that is hardened to form a spring {{as part of the}} fabrication of the contact. The same part often also forms the body of the contact itself, and is thus the current path. Abusing the switch mechanism to hold the contacts in a transition state, or severely <b>overloading</b> the <b>switch,</b> will heat and thus anneal the spring, reducing or eliminating the [...] "snap action" [...] of the switch, leading to slower transitions, more energy dissipated in the switch, and progressive failure.|$|R
40|$|Abstract—In recent years, several {{high-throughput}} low-delay scheduling algorithms {{have been}} designed for input-queued (IQ) switches, assuming admissible traffic. In this paper, we focus on queueing systems that violate admissibility criteria. We show that in a single-server system with multiple queues, the Longest Queue First (LQF) policy disallows a fair allocation of service rates 1. We also describe the duality shared by LQF’s rate allocation and a fair rate allocation. In general, we demonstrate that the rate allocation performed by the Maximum Weight Matching (MWM) scheduling algorithm in <b>overloaded</b> IQ <b>switches</b> is unfair. We attribute this {{to the lack of}} coordination between admission control and scheduling, and propose fair scheduling algorithms that minimize delay for non-overloaded queues...|$|R
25|$|At 2011-10-10 10:00 UTC {{there was}} an outage in Europe, the Middle East and Africa, {{affecting}} millions of BlackBerry users. There was another outage the following day. By October 12, 2011, the Blackberry Internet Service went down in North America. Research In Motion attributed data <b>overload</b> due to <b>switch</b> failures in their two data centres in Waterloo in Canada and Slough in England {{as the cause of}} the service disruptions.|$|R
40|$|Parallel {{operation}} of power lines with different voltages has high non-uniformity and causes problems in electric-power transmission and distribution. As {{a result the}} electric networks have additional losses of electricity and <b>overload</b> of <b>switching</b> devices and power lines with lower voltage. The task of optimization of electrical power system regimes by using linear regulators, namely cross transformers, is studied in the article. It has been found out the optimal placement location of cross transformer and its optimal transverse component of transformation ratios that help to power flow rescheduling and decrease additional losses of electricity. These results help to decrease the additional losses of electricity. It {{has been shown that}} application of cross transformer can decrease the quantity of switching of on-load tap-changing transformer and save resources. ???????????? ?????? ????? ?????????????? (???) ??????? ?????????? ??-?? ??????? ??????? ?????????????? ???????? ????????? ??? ??????????????? ? ????????????? ??????????????. ?????????? ????? ???????? ?????????????? ?????? ??????????????, ? ????? ?????????? ?????????????? ????????? ? ??? ??????? ??????????. ? ?????? ??????????? ?????? ??????????? ??????? ??? ? ?????????????? ???????? ???????????, ? ?????? ?????-??????????????? (??). ???????????? ???????????? ?????????? ?????????? ???????????? ????? ????????? ?? ? ??? ??????????? ?????????? ???????????? ???????????? ?????????????, ??? ???? ??????????? ????????? ?????????????? ?????? ??????????????. ? ????????????? ????????, ??? ????????????? ?? ????? ????????? ?????????? ???????????? ??? ???????????????, ??? ????????? ?? ?????? ??????...|$|R
40|$|Abstract—Nowadays, {{the network}} and {{communication}} technology are developing rapidly, while the network Quality of Service (QoS) are often not satisfied, because of the overburdened network and the <b>overloaded</b> routers and <b>switches.</b> Therefore, regular measurement and evaluation to the relative parameters and indexes are absolutely necessary. In this paper, the functional module of network measurement system and the commonly used network measurement instruments are introduced; active measurement, passive measurement {{and the application of}} these two measurements are presented; {{the advantages and disadvantages of}} these measurements are analyzed...|$|R
40|$|Abstract — Delegating the {{coordination}} role to proxy agents {{can improve the}} overall outcome of the task {{at the expense of}} cognitive <b>overload</b> due to <b>switching</b> subtasks. Stability and commitment are characteristics of human teamwork but must not prevent the detection of better opportunities. In addition, coordination proxy agents must be trained from examples as a single agent but must interact with multiple agents. We apply machine learning techniques to the task of learning team preferences from mixed-initiative interactions and compare the outcome results of different simulated user patterns. This paper introduces a novel approach for the adjustable autonomy of coordination actions...|$|R
40|$|The {{invention}} {{relates to}} a device for the limiting of the making current in a load circuit, having {{at least one}} limiting resistor switched in series with the load current and a briding component connected to a controller to bridge the limiting resistor. In order to limit the current reliably when the load is switched on, a control and measuring instrument (99) is provided to monitor the operating state of the limiting NTC thermistor (4) which is connected in a control circuit with a bridging component (5) and an interlock component (3) connected in series with the load. If a predefinable resistance for the NTC thermistor (4) is undershot, load power-up is blocked. The starting current can thus not exceed a predefined limit value even if the load is switched on repeatedly after {{a short period of}} time or in sequence. Moreover, the limiting NTC thermistor (4) is protected from <b>overload</b> by <b>switching</b> on and off too often. The device can be implemented without the use of electronic switching elements and is therefore particularly suited for safety-related applications (Fig. 1...|$|R
40|$|Distributed {{data center}} hosts telco virtual network functions, mixing workloads that require data {{transport}} through transport protocols with either low end-to-end latency or large bandwidth for high throughput, e. g., from tough requirements in 5 G use cases. A trend {{is the use}} relatively inexpensive, off-the-shelf switches in data center networks, where the dominated transport traffic is TCP traffic. Today’s TCP protocol {{will not be able}} to meet such requirements. The transport protocol evolution is driven by transport performance (latency and throughput) and robust enhancements in data centers, which include new transport protocols and protocol extensions such as DCTCP, MPTCP and QUIC protocols and lead to intensive standardization works and contributions to 3 GPP and IETF. By implementing ECN based congestion control instead of the packet-loss based TCP AIMD congestion control algorithm, DCTCP not only solves the latency issue in TCP congestion control caused by the switch buffer bloating but also achieves an improved performance on the packet loss and throughput. The DCTCP can also co-exist with normal TCP by applying a modern coupled queue management algorithm in the switches of DC networks, which fulfills IETF L 4 S architecture. MPTCP is an extension to TCP, which can be implemented in DC’s Fat tree architecture to improve transport throughput and shorten the latency by mitigating the bandwidth issue caused by TCP connection collision within the data center. The QUIC is a reliable and multiplexed transport protocol over UDP transport, which includes many of the latest transport improvements and innovation, which can be used to improve the transport performance on streaming media delivery. The Clos topology is a commonly used network topology in a distributed data center. In the Clos architecture, an over-provisioned fabric cannot handle full wire-speed traffic, thus there is a need to have a mechanism to handle overload situations, e. g., by scaling out the fabric. However, this will introduce more end-to-end latency in those cases the switch buffer is bloated, and will cause transport flow congestion. In this survey paper, DCTCP, MPTCP and QUIC are discussed as solutions for transport performance enhancement for 5 G mobile networks to avoid the transport flow congestion caused by the switch buffer bloating from <b>overloaded</b> <b>switch</b> queue in data centers.   Working paper, December 2017 High Quality Networked Services in a Mobile World (HITS...|$|R
40|$|Remote power {{controllers}} (RPCs) {{are solid}} state devices that combine in one unit {{the capability to}} perform all the needed functions of load <b>switching,</b> <b>overload</b> protection, and a direct indication of whether the load is on or off. They provide total system protection of equipment and wires. RPCs {{are designed to be}} located near the load and communicate control and status information remotely via low level signals of a few milliwatts. The design and operation of the RPC are considered, taking into account the operation of an RPC, the RPC power switch and drive circuits, control and trip circuits, fail-safe devices, and RPC overcurrent protection. Attention is given to the RPC development status, RPC applications, and RPC perspectives...|$|R
40|$|Cluster-based and iSCSI-based storage systems rely on {{standard}} TCP/IP-over-Ethernet for client access to data. Unfortunately, when data is striped over multiple networked storage nodes, a client can experience a TCP throughput collapse {{that results in}} much lower read bandwidth than should be provided by the available network links. Conceptually, this problem arises because the client simultaneously reads fragments of a data block from multiple sources that together send enough data to <b>overload</b> the <b>switch</b> buffers on the client’s link. This paper analyzes this Incast problem, explores its sensitivity to various system parameters, and examines the effectiveness of alternative TCP- and Ethernet-level strategies in mitigating the TCP throughput collapse. Acknowledgements: We {{would like to thank}} Jeff Butler, Abbie Matthews, and Brian Mueller at Panasas Inc. for allowing us and helping us to conduct experiments on their systems. We thank the members and companies of the PDL Consortium (including APC, Cisco, EMC, Google, Hewlett-Packard, Hitachi, IBM, Intel, LSI, Network Appliance, Oracle, Seagate, and Symantec) for their interest, insights, feedback, and support. Finally, we’d like to thank Michael Stroucken for his help managing the PDL cluster, and Michael Abd-el-Malek for feedback on our work. Thi...|$|R
40|$|Software-defined {{networking}} (SDN) is {{a promising}} network paradigm for future Internet. The centralized controller and simplified switches replace the traditional complex forwarding devices, and make network management convenient. However, the switches in SDN currently have limited ternary {{content addressable memory}} (TCAM) to store specific routing rules from the controller. This bottleneck provokes cyber attacks to <b>overload</b> the <b>switches.</b> Despite existing some countermeasures for such attacks, they are proposed based on simplified attack patterns. In this paper, we review the table-overflow attack using a sophisticated attack pattern. In the attack pattern, attack flows are targeted at their middle hops instead of endpoints. We first define potential targets in the network topology, and then we propose three specific traffic features and a monitoring mechanism to detect and locate the attackers. Further, we propose a mitigation mechanism to limit the attack rate using the token bucket model. With the control of token add rate and bucket capacity, it avoids the table overflow on the victim switch. Extensive simulations in different types of topologies and experiments in our testbed are provided to show the performance of our proposal...|$|R
40|$|Previous {{papers have}} {{described}} and evaluated {{the performance of}} packet discard techniques for maintaining packet integrity during <b>overload</b> in ATM <b>switches</b> but without taking into account different classes of service. In this paper a packet discard scheme is proposed with the goal to provide incoming flows of cells with output link bandwidth depending on the class of service they belong to. Also good performance in terms of throughput and fairness in bandwidth sharing among equal priority flows are considered as the requirements to meet. In the scenarios here considered, the proposed discard scheme is shown to provide very good results and to represent a possible solution {{for dealing with the}} most demanding data flows during congestion intervals. Numerical results are reported and discussed for different operating conditions and traffic patterns...|$|R
30|$|Whether or not {{associated}} to {{a decrease in}} oxygen supply, the RV of PAH patients shows several changes in metabolism culminating in an increased glucose uptake. While the normal heart predominantly uses fatty acids as energy source, the <b>overloaded</b> heart <b>switches</b> to glucose to preserve adenosine triphosphate (ATP) supply [37]. In addition, metabolic remodeling in the pressure overloaded RV results in a greater reliance on anaerobic energy generation {{in the form of}} glycolysis [38], similarly as for the lungs. These metabolic changes resemble the changes found in lung vascular cells and have been confirmed by PET scanning in PAH patients, showing decreased fatty acid uptake (using 11 C-palmitate as surrogate) [39] and increased 18 F-FDG uptake in the RV. Decreases in pulmonary vascular resistance with vasodilator treatment have been shown to correlate with decreases in 18 F-FDG uptake [40]. RV 18 F-FDG uptake is numerically associated with a worse clinical profile and survival [15, 41 – 44], but in most studies, correlations between 18 F-FDG uptake and hemodynamic parameters were moderate at best. There was also a considerable discrepancy between the different studies. Recent preclinical evidence suggest that the metabolic shift towards glycolysis is not sustained during the progression of RV failure [45], which would question the use of 18 F-FDG uptake as a reliable biomarker in PAH.|$|R
40|$|ABSTRACT 1 Embedded {{real-time}} {{applications that}} {{interact with the}} out-side environment may be subjected to temporal uncertainty due to the potential asynchronous characteristics of events. If event handling, which is usually associated with inter-rupts, is not carefully controlled, overload scenarios can cause application tasks to miss deadlines, with severe con-sequences. In this paper we {{address the problem of}} control-ling event handling timeliness, by enhancing the real-time multitasking kernel RTEMS with components to character-ize event rate, decide if there is an <b>overload</b> situation, and <b>switch</b> between an interrupt mode and a polling mode event handling. This is done with minimal impact on the existing application, by replacing the interrupt handler by another one that implements those control mechanisms before call-ing the original application interrupt service routine. A case study using the keyboard as the input device is presented, and implementation issues are discussed...|$|R
40|$|In a {{previous}} paper, {{one of the}} authors, gave a worst-case analysis for the Early Packet Discard technique for maintaining packet integrity during <b>overload</b> in ATM <b>switches.</b> This analysis showed that to ensure 100 % goodput during overload under worst-case conditions, requires a buffer with enough storage for one maximum length packet from every active virtual circuit. This paper refines that analysis, using assumptions that are closer to what {{we expect to see}} in practice. Our principal result is that 100 % goodput can be achieved with substantially smaller buffers, although the required buffer space can be significant when the link speed is substantially higher than the rate of the individual virtual circuits. These results are validated by comparison with simulation. We also give a simple analysis to determine the amount of buffering needed to bound the probability of buffer overflow and underflow...|$|R
40|$|Abstract—We {{describe}} {{the design of}} an agile data center with integrated server and storage virtualization technologies. Such data centers form a key building block for new cloud computing architectures. We also show how to leverage this integrated agility for non-disruptive load balancing in data centers across multiple resource layers- servers, switches, and storage. We propose a novel load balancing algorithm called VectorDot for handling the hierarchical and multi-dimensional resource constraints in such systems. The algorithm, inspired by the successful Toyoda method for multi-dimensional knapsacks, {{is the first of}} its kind. We evaluate our system on a range of synthetic and real data center testbeds comprising of VMware ESX servers, IBM SAN Volume Controller, Cisco and Brocade switches. Experiments under varied conditions demonstrate the end-to-end validity of our system and the ability of VectorDot to efficiently remove <b>overloads</b> on server, <b>switch</b> and storage nodes. I...|$|R
40|$|In a {{previous}} paper [3], {{one of the}} authors, gave a worst-case analysis for the Early Packet Discard (EPD) technique for maintaining packet integrity during <b>overload</b> in ATM <b>switches.</b> This analysis showed that to ensure 100 % goodput during overload under worst-case conditions, requires a buffer with enough storage for one maximum length packet from every active virtual circuit. This paper refines that analysis, using assumptions that are closer to what {{we expect to see}} in practice and examines how EPD performs when the buffer is not large enough to achieve 100 % goodput. We show that 100 % goodput can be achieved with substantially smaller buffers than predicted by the worst-case analysis, although the required buffer space can be significant when the link speed is substantially higher than the rate of the individual virtual circuits. We also show that high goodputs can be achieved with more modest buffer sizes, but that EPD exhibits anomalies with respect to buffer capacity, i [...] ...|$|R
40|$|A nearly {{constant}} {{switching frequency}} current hysteresis controller for a 2 -level inverter fed induction motor drive is proposed in this paper: The salient {{features of this}} controller are fast dynamics for the current, inherent protection against <b>overloads</b> and less <b>switching</b> frequency variation. The large variation of switching frequency as in the conventional hysteresis controller is avoided by defining a current-error boundary which is obtained from the current-error trajectory of the standard space vector PWM. The current-error boundary is computed at every sampling interval based on the induction machine parameters and from the estimated fundamental stator voltage. The stator currents are always monitored and when the current-error exceeds the boundary, voltage space vector is switched to reduce the current-error. The proposed boundary computation algorithm is applicable in linear and over-modulation region and it is simple to implement in any standard digital signal processor: Detailed experimental verification is done using a 7. 5 kW induction motor {{and the results are}} given to show the performance of the drive at various operating conditions and validate the proposed advantages...|$|R
40|$|In a {{previous}} paper, {{one of the}} authors gave a worstcase analysis for the early packet discard (EPD) technique formaintaining packet integrity during <b>overload</b> in ATM <b>switches.</b> This analysis showed that to ensure 100 % goodput during overloadunder worst case conditions requires a buffer with enoughstorage for one maximum length packet from every active virtualcircuit. This paper refines that analysis, using assumptions thatare closer to what we expect to see in practice, and examineshow EPD performs when the buffer is not large enough to achieve 100 % goodput. We show that 100 % goodput can be achieved withsubstantially smaller buffers than predicted by the worst caseanalysis, although the required buffer space can be significantwhen the link speed is substantially higher than the rate ofthe individual virtual circuits. We also show that high goodputscan be achieved with more modest buffer sizes, but that EPDexhibits anomalies with respect to buffer capacity, in that thereare situations in which increasing the amount of buffering cancause the goodput to decrease. These results are validated bycomparison with simulation...|$|R
40|$|To {{insure the}} {{reliability}} of a 20 kHz, AC power system on spacecraft, {{it is essential to}} analyze its behavior under many adverse operating conditions. Some of these conditions include <b>overloads,</b> short circuits, <b>switching</b> surges, and harmonic distortions. Harmonic distortions can cause malfunctions in equipment that the power system is supplying, and during extreme distortions such as voltage resonance, it can cause equipment and insulation failures due to the extreme peak voltages. HARMFLO, a power flow computer program, which was capable of analyzing harmonic conditions on three phase, balanced, 60 Hz, AC power systems, was modified to analyze single phase, 20 kHz, AC power systems. Since almost all of the equipment used on spacecraft power systems is electrically different from equipment used on terrestrial power systems, it was also necessary to develop mathematical models for the equipment to be used on the spacecraft. The results are that (1) the harmonic power now has a model of a single phase, voltage controlled, full wave rectifier; and (2) HARMFLO was ported to the SUN workstation platform...|$|R
5000|$|The 2009 {{breakdown}} {{was caused}} by what Tim Bousquet of The Coast called [...] "a perfect storm" [...] of technical errors. A Nova Scotia Power electrical outage spurred a technician to activate two backup generators to maintain operation of the plant. But the electrical load was unevenly distributed between the two generators and one became overloaded and failed. A floodgate, designed to close in emergencies to isolate the plant's [...] "wet well" [...] from the deep pipe feeding sewage to the plant, was powered by the <b>overloaded</b> generator. A <b>switch</b> designed to allow the second generator to power the floodgate happened to fail. Owing to the failed generator, {{only one of the}} four sewage pumps could convey sewage out of the wet well, and the volume of sewage began to rise, shorting out the electrical junction boxes placed above the pumps. With the floodgate jammed partially open and all four pumps inoperable, the 85-foot-deep wet well filled with sewage. The electrical control room above the wet well then also filled with sewage, destroying all the equipment there.|$|R
40|$|Abstract—Cluster-based storage systems {{increasingly}} use commodity communication technologies, such as Fibre Channel over Ethernet (FCoE), for accessing {{stored data}} over the network. Data is striped over multiple storage nodes, and storage traffic often shares the network with non-storage traffic. In such conditions, storage clients can experience severely degraded performance, such as TCP throughput collapse and network congestion due to competing network traffic. Furthermore, consolidation of multiple virtual machines (VMs) onto fewer physical nodes can worsen {{the performance of}} network storage systems. The root cause of this performance problem is that network traffic from multiple sources can cause transient <b>overloads</b> in the <b>switch</b> buffers. In this paper, we {{make the case that}} virtualization opens up a new set of opportunities to alleviate and solve such performance problems experienced by network storage in particular, and data center Ethernet in general. We present an architecture, called XCo, for explicit coordination of network traffic among VMs in a data center Ethernet that is inexpensive, fully transparent, currently feasible, and complementary to any switch-level hardware support. We present experimental evidence via proofof-concept implementation and evaluation to support this claim and describe the challenges and opportunities in a complete solution. I...|$|R
40|$|Abstract — Wireless {{networks}} are currently experiencing more overload situations than their wireline counterparts because of explosive mobile traffic growth, unpredictable traffic behavior, service differentiated traffic shedding, etc. Even though extensive research work on network overload control {{in general is}} going on, the economic aspect of the overload problem has received very little attention. Managing the incoming traffic {{in a way that}} generates the maximum possible revenue under overload warrants special attention. In this paper, we study a realistic wireless <b>switch</b> <b>overload</b> model where message exchange and message discarding at multiple nodes are considered. We propose a distributed overload control framework considering different service types to obtain the optimal revenue while maintaining the switch’s capability to handle call attempts during overload situation. This is achieved by exchanging overload information among the nodes that can have a global view of the switch-wide overload situation and its impact on revenue, and hence can adjust their own traffic shedding to improve the revenue generation. Next, we extend the proposed framework to incorporate different call priorities and discuss the conditions for reaching the optimal revenue that ensures preferential treatment to the high priority service types. Index Terms — Distributed control framework, nonlinear optimization, revenue maximization, Priority Services...|$|R
40|$|The calcium-activated {{phosphatase}} calcineurin {{is regulated}} by a binding cofactor known as modulatory calcineurin-interacting protein (MCIP) in yeast up through mammals. The physiologic function of MCIP remains {{an area of}} ongoing investigation, because {{both positive and negative}} calcineurin regulatory effects have been reported. Here we disrupted the mcip 1 and mcip 2 genes in the mouse and provide multiple lines of evidence that endogenous MCIP functions as a calcineurin facilitator in vivo. Mouse embryonic fibroblasts deficient in both mcip 1 / 2 showed impaired activation of nuclear factor of activated T cells (NFAT), suggesting that MCIP is required for efficient calcineurin–NFAT coupling. Mice deficient in mcip 1 / 2 showed a dramatic impairment in cardiac hypertrophy induced by pressure overload, neuroendocrine stimulation, or exercise, similar to mice lacking calcineurin Aβ. Moreover, simultaneous deletion of calcineurin Aβ in the mcip 1 / 2 -null background did not rescue impaired hypertrophic growth after pressure <b>overload.</b> Slow/oxidative fiber-type <b>switching</b> in skeletal muscle after exercise stimulation was also impaired in mcip 1 / 2 mice, similar to calcineurin Aβ-null mice. Moreover, CD 4 + T cells from mcip 1 / 2 -null mice showed enhanced apoptosis that was further increased by loss of calcineurin Aβ. Finally, mcip 1 / 2 -null mice displayed a neurologic phenotype that was similar to calcineurin Aβ-null mice, such as increased locomotor activity and impaired working memory. Thus, a loss-of-function analysis suggests that MCIPs serve either a permissive or facilitative function for calcineurin–NFAT signaling in vivo...|$|R
40|$|The bursty many-to-one {{communication}} pattern, {{typical for}} data acquisition systems, is particularly demanding for commodity TCP/IP and Ethernet technologies. The problem arising from {{this pattern is}} widely known in the literature as incast and can be observed as TCP throughput collapse. It {{is a result of}} <b>overloading</b> the <b>switch</b> buffers, when a specific node in a network requests data from multiple sources. This will become even more demanding for future upgrades of the experiments at the Large Hadron Collider at CERN. It is questionable whether commodity TCP/IP and Ethernet technologies in their current form will be still able to effectively adapt to bursty traffic without losing packets due to the scarcity of buffers in the networking hardware. This thesis provides an analysis of TCP/IP performance in data acquisition networks and presents a novel approach to incast congestion in these networks based on software-based packet forwarding. Our first contribution lies in confirming the strong analogies between the TCP behaviour in data acquisition and datacenter networks. We also provide experimental evaluation of different proposals from the datacenter environment for application in data acquisition to improve performance and reduce buffer requirements. The second contribution lies in the design and experimental evaluation of a data acquisition network that is based on software switches. Performance has traditionally been the challenge of this approach, but this situation changes with modern server platforms. High performance load balancers, proxies, virtual switches and other network functions can be now implemented in software and not limited to specialised commercial hardware, thus reducing cost and increasing the flexibility. We first design and optimise a software-based switch with a dedicated, throughput-oriented buffering mechanism for data acquisition. Our experimental results indicate that it performs significantly better than some typical Ethernet switches under heavy congestion. The optimised software switch with large packet buffer reaches maximum bandwidth and completely avoids throughput degradation typical for hardware switches that suffer from high packet drop counts. Furthermore, we evaluate the scalability of the system when building a larger topology of interconnected software switches. We highlight aspects such as management, costs, port density, load balancing, and failover. In this context, we discuss the usability of software-defined networking technologies, Open vSwitch Database and OpenFlow, to centrally manage and optimise a data acquisition network. We have built an IP-only parallel leaf-spine network consisting of eight software switches running on separate physical servers as a demonstrator...|$|R
40|$|Beta-thalassemia is a genetic, {{red blood}} cell {{disorder}} affecting the beta-globin chain of the adult hemoglobin gene. This results in excess accumulation of unpaired alpha-chain gene products leading to reduced {{red blood cell}} life span {{and the development of}} severe anemia. Current treatment of this disease involves regular blood transfusion and adjunct chelation therapy to lower blood transfusion–induced iron <b>overload.</b> Fetal hemoglobin <b>switching</b> agents have been proposed to treat genetic blood disorders, such as sickle cell anemia and beta-thalassemia, in an effort to compensate for the dysfunctional form of the beta-globin chain in adult hemoglobin. The rationale behind this approach is to pair the excess normal alpha-globin chain with the alternative fetal gamma-chain to promote red blood cell survival and ameliorate the anemia. Reprogramming of differentiation in intact, mature, adult white blood cells in response to inclusion of monoclonal antibody CR 3 / 43 has been described. This form of retrograde development has been termed “retrodifferentiation”, with the ability to re-express a variety of stem cell markers in a heterogeneous population of white blood cells. This form of reprogramming, or reontogeny, to a more pluripotent stem cell state ought to recapitulate early hematopoiesis and facilitate expression of a fetal and/or adult program of hemoglobin synthesis or regeneration on infusion and subsequent redifferentiation. Herein, the outcome of infusion of autologous retrodifferentiated stem cells (RSC) into 21 patients with beta-thalassemia is described. Over 6 months, Infusion of 3 -h autologous RSC subjected to hematopoietic-conducive conditions into patients with beta-thalassemia reduced mean blood transfusion requirement, increased mean fetal hemoglobin synthesis, and significantly lowered mean serum ferritin. This was always accompanied by an increase in mean corpuscular volume (MCV), mean corpuscular hemoglobin (MCH), and mean corpuscular hemoglobin concentration (MCHC) in such patients. No adverse side effects in response to the infusion of autologous RSC were noted. This novel clinical procedure may profoundly modify the devastating course of many genetic disorders in an autologous setting, thus paving the way to harnessing pluripotency from differentiated cells to regenerate transiently an otherwise genetically degenerate tissue such as thalassemic blood...|$|R
