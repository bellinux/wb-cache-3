157|960|Public
25|$|As the {{adjacent}} bins leave no gaps, the rectangles of a histogram {{touch each other}} {{to indicate that the}} <b>original</b> <b>variable</b> is continuous.|$|E
500|$|The general {{solution}} is [...] But [...] from the symmetry condition at the centre. Writing back in <b>original</b> <b>variable,</b> the equation reads, ...|$|E
2500|$|Johnson [...] {{considered}} {{the distribution of}} the logit - transformed variable ln(X/1−X), including its moment generating function and approximations for large values of the shape parameters. [...] This transformation extends the finite support [...] based on the <b>original</b> <b>variable</b> X to infinite support in both directions of the real line (−∞, +∞).|$|E
30|$|The {{goal of the}} PCA is {{to reduce}} a number of {{variables}} to {{a smaller number of}} new uncorrelated variables (principal components). The technique of the <b>original</b> <b>variables</b> grouping uses as decisive factor the correlation observed between them. More specifically, the emerging new variables are linear combinations of the <b>original</b> <b>variables,</b> so as to be uncorrelated {{to each other and to}} contain the largest possible part of the variance of <b>original</b> <b>variables.</b>|$|R
30|$|Mori et al. [54] {{have stated}} that “principal {{component}} analysis (PCA) is a commonly used descriptive multivariate method for handling quantitative data and can be extended to deal with mixed measurement level data.” Thus, PCA has been widely applied in various fields. As described by [55], PCA generates a set of variables depending on the variance-covariance structure of the <b>original</b> <b>variables.</b> These new variables are linear combinations of the <b>original</b> <b>variables</b> and are fewer in number than the <b>original</b> <b>variables.</b>|$|R
5000|$|In matrix form, the {{empirical}} covariance matrix for the <b>original</b> <b>variables</b> {{can be written}} ...|$|R
2500|$|The {{transformation}} of a linear program {{to one in}} standard form may be accomplished as follows. First, for each variable with a lower bound other than 0, a new variable is introduced representing {{the difference between the}} variable and bound. The <b>original</b> <b>variable</b> can then be eliminated by substitution. For example, given the constraint ...|$|E
2500|$|... where κ is the kurtosis, var (...) is the {{variance}} and E (...) is the expectation operator. The kurtosis {{can now be}} seen to be a measure of the dispersion of Z2 around its expectation. Alternatively it can {{be seen to be}} a measure of the dispersion of Z around +1 and−1. κ attains its minimal value in a symmetric two-point distribution. In terms of the <b>original</b> <b>variable</b> X, the kurtosis {{is a measure of the}} dispersion of X around the two values μ±σ.|$|E
5000|$|Example: or: These {{examples}} {{modify the}} value of the <b>original</b> <b>variable</b> [...]|$|E
3000|$|... (3) inverse {{transformation}} and derivation {{of the exact}} representation of the solution in the <b>original</b> <b>variables.</b>|$|R
30|$|Principal {{component}} analysis describes the correlation or variance–covariance structure between {{the set of}} variables through a few uncorrelated latent or new variables, {{each of which is}} a linear combination of the <b>original</b> <b>variables</b> which can maximize the variance accounted. Most often these new variables reveals a new interpretation that is not visible in <b>original</b> <b>variables</b> [13]. The newly created variables are called principal components.|$|R
5000|$|Return to the <b>original</b> <b>variables</b> with [...] in {{the first}} term of [...] Combine [...] to obtain: ...|$|R
5000|$|C++: C++11 {{closures}} {{can capture}} non-local variables by reference (without extending their lifetime), by copy construction or by move construction (the variable lives {{as long as}} the closure does). The former potentially avoids an expensive copy and allows to modify the <b>original</b> <b>variable</b> but is unsafe in case the closure is returned (see dangling references). The second is safe if the closure is returned but requires a copy and cannot be used to modify the <b>original</b> <b>variable</b> (which might not exist any more at the time the closure is called). The latter is safe if the closure is returned and does not require a copy but cannot be used to modify the <b>original</b> <b>variable</b> either.|$|E
5000|$|The {{solutions}} {{in terms of}} the <b>original</b> <b>variable</b> are obtained by substituting x3 back in for u: ...|$|E
5000|$|... each <b>original</b> <b>variable</b> in a node is in {{the scope}} {{of at least one}} {{constraint}} associated with the node; ...|$|E
5000|$|Similarly for {{the domain}} {{because it is}} delimited by the <b>original</b> <b>variables</b> that were {{transformed}} before ( [...] and [...] in example).|$|R
50|$|The {{density of}} the sum of two {{independent}} real-valued random variables equals the convolution of the density functions of the <b>original</b> <b>variables.</b>|$|R
5000|$|To {{select a}} subset of {{variables}} from a larger set, based on which <b>original</b> <b>variables</b> have the highest correlations with some other factors.|$|R
50|$|So if a {{variable}} of a supposedly primitive type, e.g. an integer is passed to a function, altering that variable inside the function will {{not alter the}} <b>original</b> <b>variable,</b> as a new int Object is created when inside the function. If {{a variable}} of another (not primitive) datatype, e.g. XML is passed to a function, altering that variable inside the function will alter the <b>original</b> <b>variable</b> as well, as no new XML Object is created.|$|E
5000|$|The general {{solution}} is [...] But [...] from the symmetry condition at the centre. Writing back in <b>original</b> <b>variable,</b> the equation reads, ...|$|E
50|$|As the {{adjacent}} bins leave no gaps, the rectangles of a histogram {{touch each other}} {{to indicate that the}} <b>original</b> <b>variable</b> is continuous.|$|E
50|$|In {{the dual}} problem, all {{constraints}} are binary. They all enforce two values, which are tuples, {{to agree on}} one or more <b>original</b> <b>variables.</b>|$|R
50|$|If {{it has a}} {{distribution}} from the same family of distributions as the <b>original</b> <b>variables,</b> that family of distributions {{is said to be}} closed under convolution.|$|R
40|$|This paper shows {{a method}} {{to reduce the number}} of input {{variables}} to represent incompletely specified index genera-tion functions. A compound variable is generated by EX-ORing the <b>original</b> input <b>variables.</b> By using both origi-nal and compound variables, incompletely specified index generation functions can be represented by fewer variables. As a means to select variables, a heuristic method using information gains is presented. We compare representing random functions using 1. only <b>original</b> <b>variables,</b> and 2. both <b>original</b> and compound <b>variables.</b> Experimental re-sults show that the use of compound variables effectively reduces the number of input variables. ...|$|R
5000|$|As {{suggested}} by Drakunov, a sliding mode observer {{can also be}} designed for a class of non-linear systems. Such an observer can be written in terms of <b>original</b> <b>variable</b> estimate [...] and has the form ...|$|E
5000|$|A further {{condition}} {{that is necessary}} to ensure equivalence is that the binary constraints are sufficient to enforce all [...] "copies" [...] of each <b>original</b> <b>variable</b> to assume the same value. Since the same <b>original</b> <b>variable</b> can be associated to several of the new variables, the values of these new variable must all agree on the value of the old variable. The binary constraints are used to enforce equality of the old variables shared between the two new variables. Two copies of a new variable are forced equal if there exists a path of binary constraints between their new variables and all new variables in this path contain the old variable.|$|E
50|$|Construction of pruned SSA form uses live {{variable}} {{information in}} the Φ function insertion phase to decide whether a given Φ function is needed. If the <b>original</b> <b>variable</b> name isn't live at the Φ function insertion point, the Φ function isn't inserted.|$|E
3000|$|... 5 We {{tested for}} {{statistical}} significance {{of differences between}} country groups by running a regression with the full sample where all variables were segregated by country group (interactions of <b>original</b> <b>variables</b> and dummies representing two country groups).|$|R
25|$|The variances and {{covariance}} of the logarithmically transformed variables X and (1−X) are different, in general, {{because the}} logarithmic transformation destroys the mirror-symmetry of the <b>original</b> <b>variables</b> X and (1−X), as the logarithm approaches negative infinity for the variable approaching zero.|$|R
50|$|Contrast {{with the}} central limit theorem, which states that the average of {{independent}} identically distributed random variables with finite mean and variance is asymptotically normal. Cramér's theorem shows that a finite average is not normal, unless the <b>original</b> <b>variables</b> were normal.|$|R
5000|$|Johnson [...] {{considered}} {{the distribution of}} the logit - transformed variable ln(X/1−X), including its moment generating function and approximations for large values of the shape parameters. This transformation extends the finite support 1 based on the <b>original</b> <b>variable</b> X to infinite support in both directions of the real line (−∞, +∞).|$|E
5000|$|... #Caption: Plot of logit(X) = ln(X/(1−X)) (vertical axis) vs. X in {{the domain}} of 0 to 1 (horizontal axis). Logit {{transform}}ations are interesting, as they usually transform various shapes (including J-shapes) into (usually skewed) bell-shaped densities over the logit variable, and they may remove the end singularities over the <b>original</b> <b>variable</b> ...|$|E
5000|$|The {{transformation}} of a linear program {{to one in}} standard form may be accomplished as follows. First, for each variable with a lower bound other than 0, a new variable is introduced representing {{the difference between the}} variable and bound. The <b>original</b> <b>variable</b> can then be eliminated by substitution. For example, given the constraint ...|$|E
50|$|The variances and {{covariance}} of the logarithmically transformed variables X and (1−X) are different, in general, {{because the}} logarithmic transformation destroys the mirror-symmetry of the <b>original</b> <b>variables</b> X and (1−X), as the logarithm approaches negative infinity for the variable approaching zero.|$|R
50|$|With w(1) found, {{the first}} {{component}} of a data vector x(i) can then be given as a score t1(i) = x(i) ⋅ w(1) in the transformed co-ordinates, or as the corresponding vector in the <b>original</b> <b>variables,</b> {x(i) ⋅ w(1)} w(1).|$|R
30|$|To {{evaluate}} the ash composition and its leaching behavior, multivariate statistical methods, including cluster analysis (CA) and {{principal component analysis}} (PCA), were used. CA classifies the chemical element species into groups (clusters) based on similarities in solubility to each type of leaching tests. PCA is designed to transform the <b>original</b> <b>variables</b> into new, uncorrelated variables (axes) known as principal components (PCs), which are linear combinations of <b>original</b> <b>variables.</b> By plotting samples in PC ordination diagrams using PC scores, sample relations and grouping would be visualized and provide information on the key variables explaining the differences among groups. Both {{statistical analyses were performed}} using PC-ORD ver. 5.30 (MiM software, Oregon, USA), which is used in community ecology.|$|R
