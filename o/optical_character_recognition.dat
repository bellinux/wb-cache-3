1956|2628|Public
5|$|The {{new field}} was unified and {{inspired}} {{by the appearance of}} Parallel Distributed Processing in 1986—a two volume collection of papers edited by Rumelhart and psychologist James McClelland. Neural networks would become commercially successful in the 1990s, when they began to be used as the engines driving programs like <b>optical</b> <b>character</b> <b>recognition</b> and speech recognition.|$|E
5|$|Initially {{looking for}} ways to further improve its {{electronic}} forms software, in November 1991 Delrina had attempted to buy two associated firms that produced <b>Optical</b> <b>Character</b> <b>Recognition</b> (OCR) software, with the intention of incorporating OCR functionality into its forms products. The acquisition deal fell through, though by Fall 1992 Delrina had made a deal with Caere Corporation to include its AnyFax OCR software within its products. This functionality was incorporated into WinFax PRO 3.0 in late 1992, and subsequently in FormFlow Despite the agreement with Caere, the subsequent version of WinFax used Xerox's TextBridge OCR engine instead.|$|E
25|$|Graphotactical {{rules are}} useful in error {{detection}} by <b>optical</b> <b>character</b> <b>recognition</b> systems.|$|E
40|$|<b>Optical</b> <b>Characters</b> <b>Recognition</b> (OCR) {{is one of}} {{the active}} {{subjects}} of research {{since the early days of}} computer science. Even if Arabic characters are used by more than a half a billion people; Arabic <b>characters</b> <b>recognition</b> has not received enough interests by the researchers. Little research progress has been achieved comparing to what has been done with Latin and Chinese. The cursive nature of the Arabic characters makes it more difficult to achieve a high accuracy in <b>character</b> <b>recognition</b> since even printed Arabic characters are in cursive form. This paper presents the main challenges (difficulties) researchers are facing and up to dated solutions (the commo...|$|R
40|$|International audienceSkew angle {{detection}} {{is one of}} {{the most}} important component of <b>Optical</b> <b>Characters</b> <b>Recognition</b> (OCR) systems and documents analysis. Taking documents by the blind and visually impaired people with a mobile phone always have a degree of inclination. In this paper, a novel and an efficient method based on extraction of Harris corner features points and Hough transform is presented to estimate skew angle of printed documents. A comparative study using the ICDAR 2015 database with the wellknown methods in literature, shown the effectiveness and the performance of the proposed algorith...|$|R
40|$|<b>Optical</b> <b>Characters</b> <b>Recognition</b> (OCR) {{has been}} an active subject of {{research}} {{since the early days}} of computers. Despite the age of the subject, it remains one of the most challenging and exciting areas of research in computer science. In recent years it has grown into a mature discipline, producing a huge body of work. Arabic <b>character</b> <b>recognition</b> has been one of the last major languages to receive attention. This is due, in part, to the cursive nature of the task since even printed Arabic characters are in cursive form. This paper describes the performance of combining Hough transform and Hidden Markov Models in a multifont Arabic OCR system. Experimental tests have been carried out on a set of 85. 000 samples of characters corresponding to 5 different fonts from the most commonly used in Arabic writing. Some promising experimental results are reported. </p...|$|R
25|$|<b>Optical</b> <b>character</b> <b>recognition</b> (OCR)identifying {{characters}} in images of printed or handwritten text, usually {{with a view}} to encoding the text in a format more amenable to editing or indexing (e.g. ASCII).|$|E
25|$|<b>Optical</b> <b>character</b> <b>recognition</b> is {{performed}} on images (e.g., brochures, photos, prints, scans, screen clips) {{so that any}} text that appears in them is searchable. Handwritten text on a tablet PC is also searchable.|$|E
25|$|Bulk {{business}} mail, using Mailmark® technology, attracts reduced {{prices of}} up to 32%, if the sender prints an RM4SCC barcode, or prints the address in a specified position on the envelope using a font readable by <b>optical</b> <b>character</b> <b>recognition</b> (OCR) equipment.|$|E
40|$|Various shaped-based image invariants {{are popular}} {{algorithms}} used in <b>optical</b> <b>character</b> <b>recognitions</b> (OCR), 3 D object recognitions, and pattern recognitions. The shape-based image invariants {{can be divided}} into two different categories: boundary based image invariants such as Fourier descriptors and chain code; region-based image invariants including various moment-based invariants such as Hu's seven moment invariants and Zernike moments. This thesis introduced and evaluated different shape-based image invariants from the perspective of their invariance property to image transformations including scaling, translation, rotation and different image spatial resolutions. The influence caused by salt and pepper noises of different intensities is also analyzed. The image reconstruction ability of Zernike moments is implemented and discussed as well. An OCR engine is implemented with MATLAB scripts to perform the image feature extraction and image recognition. The OCR engine is also used in the overall performance evaluation of Fourier descriptors and Hu's seven moment invariants...|$|R
50|$|Cognitive Technologies {{was founded}} in 1993 by Olga Uskova.The first {{employees}} previously worked in the team that developed the first world computer chess champion “Kaissa”. The first programs developed by Cognitive Technologies were <b>optical</b> image and <b>character</b> <b>recognition</b> software - Tiger and CuneiForm.The company signed OEM-agreements with leading global IT companies for supplying OCR software, including HP, Canon, Epson, Samsung, Oracle, Corel, Olivetti, OKI and many others.|$|R
40|$|Abstract — This paper {{describes}} an <b>Optical</b> Braille <b>character</b> <b>recognition</b> system for machine punched text documents of Kannada Braille, a south Indian language. The proposed OBR system for recognition, can handle all the basic and the combinational characters formed out of consonants and vowels of Kannada. The system first extracts images of kannada Braille script. This {{is followed by}} line, word and character segmentation. A Combination character in Kannada Braille is represented using two segmented character boxes. The system designed analyzes the present character box and also the immediate next character box and then character is recognized. The recognized Braille character is converted into normal Kannada character and stored as a document...|$|R
25|$|The {{magazine}} has an online archive with the unformatted text for every article published. The articles are indexed and were converted from scanned images using <b>optical</b> <b>character</b> <b>recognition</b> technology. There are still minor {{errors in the}} text that are remnants of the conversion into digital format.|$|E
25|$|Phishers {{have even}} started using images instead of text {{to make it}} harder for {{anti-phishing}} filters to detect text commonly used in phishing emails. However, this has led to the evolution of more sophisticated anti-phishing filters that are able to recover hidden text in images. These filters use OCR (<b>optical</b> <b>character</b> <b>recognition)</b> to optically scan the image and filter it.|$|E
25|$|The main Google Drive {{mobile app}} {{supported}} editing of documents and spreadsheets until April 2014, when the capability {{was moved to}} separate, standalone apps for Google Docs, Sheets, and Slides. The Google Drive app on Android allows users to take {{a photo of a}} document, sign, or other text and use <b>optical</b> <b>character</b> <b>recognition</b> to convert to text that can be edited. In October 2014, the Android app was updated with a Material Design user interface, improved search, the ability to add a custom message while sharing a file, and a new PDF viewer.|$|E
40|$|Building on {{previous}} work in Chinese <b>character</b> <b>recognition,</b> we describe an advanced system of classification using probabilistic neural networks. Training of the classifier {{starts with the}} use of distortion modeled characters from four fonts. Statistical measures are taken on a set of features computed from the distorted character. Based on these measures, the space of feature vectors is transformed to the optimal discriminant space for a nearest neighbor classifier. In the discriminant space, a probabilistic neural network classifier is trained. For classification, we present some modifications to the standard approach implied by the probabilistic neural network structure which yield significant speed improvements. We then compare this approach to using discriminant analysis and Geva and Sitte's Decision Surface Mapping classifiers. All methods are tested using 39, 644 characters in three different fonts. 1 Introduction 1. 1 Factors in <b>Optical</b> Chinese <b>Character</b> <b>Recognition</b> <b>Optical</b> c [...] ...|$|R
40|$|Abstract — Processing {{of natural}} {{language}} is branch of linguistics, artificial intelligence & computer science and {{its purpose is}} to have interaction among natural language of human beings and computers. We can say it is related to field of computer–human interaction. There are different challenges in this field like understanding of natural language i. e. allowing machines to have understanding from natural language of human beings. Mostly available tasks of natural language processing are: analysis of discourse, morphological separation, machine translation, generation and understanding of natural language, recognition of named entities, part of speech tagging, <b>recognition</b> of <b>optical</b> <b>characters,</b> <b>recognition</b> of speech and analysis of sentiments etc. Current research in NLP is showing more interest on learning algorithms which are either unsupervised or semi-supervised in nature. These techniques of learning can perform this task of learning from data which is not annotated manually with required answers or by applying mixture of non-annotated & annotated data. Normally, this job is very hard as compared to learning which is supervised & usually shows little correct results for particular amount of data as input. But there is large quantity of data is available which is non annotated in nature i. e. whole contents available on world wide web and it normally produces less accurate results. This paper discusses about a survey of different techniques of natural language processing. Keywords- NLP; natural language processing; natural language understanding; mining of text I...|$|R
40|$|In <b>optical</b> printed Chinese <b>character</b> <b>recognition</b> (OPCCR), many {{classifiers}} {{have been}} proposed for the recognition. Among the classifiers, support vector machine (SVM) {{might be the best}} classifier. However, SVM is a classifier for two classes. When it is used for multi-classes in OPCCR, its computation is time-consuming. Thus, we propose a neighbor classes based SVM (NC-SVM) to reduce the computation consumption of SVM. Experiments of NC-SVM classification for OPCCR have been done. The results of the experiments have shown that the NC-SVM we proposed can effectively reduce the computation time in OPCCR...|$|R
25|$|Google Keep has {{received}} mixed reviews. A review just after launch in 2013 praised its speed, {{the quality of}} voice notes, synchronization, and the widget that could {{be placed on the}} Android home screen. Reviews in 2016 have criticized the lack of formatting options, inability to undo changes, and an interface that only offers two view modes where neither was liked for their handling of long notes. However, Keep received praise for features including universal device access, native integration with other Google services, and the option to turn photos into text through <b>optical</b> <b>character</b> <b>recognition.</b>|$|E
25|$|<b>Optical</b> <b>character</b> <b>recognition</b> (OCR) is {{preferable}} to rekeying for converting existing text that is already written down but not in machine-readable format (for example, a Linotype-composed book from the 1940s). In other words, to convert the text from an image to editable text (that is, a string of character codes), a person could re-type it, or a computer could look at the image and deduce what each character is. OCR technology has already reached an impressive state (for example, Google Book Search) and promises more for the future.|$|E
25|$|Google Keep is a note-taking service {{developed}} by Google. Launched on March 20, 2013, Google Keep {{is available on}} the web, and has mobile apps for the Android and iOS mobile operating systems. Keep offers a variety of tools for taking notes, including text, lists, images, and audio. Users can set reminders, which are integrated with Google Now. Text from images can be extracted using <b>optical</b> <b>character</b> <b>recognition,</b> and voice recordings can be transcribed. The interface allows for a single-column view or a multi-column view. Notes can be color-coded, and labels can be applied for organization. Later updates have added functionality to pin notes, and to collaborate on notes with other Keep users in real-time.|$|E
40|$|<b>Optical</b> Sinhala <b>Character</b> <b>recognition</b> is {{a fairly}} {{researched}} area in the local natural language initiative. Although {{a fair amount of}} research and development has been undertaken in this field, a comprehensive product is yet to be developed. However, a Sinhala OCR has a formidable academic and commercial value. The value of such a tool is evident in the e-gonvemance intiative as well, where vast numbers of Sinhala documents, forms etc will have to be digitised. OCRs have been developed in English and many other languages, and some of these basic methodologies can be extended for a Sinhala OCR as well. A forerunning concept on OCR is the use of weighted Artificial Neural Networks. However, this method is requires heavy processing power. This abstract proposes a fresh idea to reduce processing power, using image processing and comupter vision techniques...|$|R
40|$|A proven {{strength}} of neural-network methods is their application to <b>character</b> <b>recognition</b> and document analysis. In this paper we describe a neural-net <b>Optical</b> <b>Character</b> Recognizer (OCR), neural-net preprocessing, and neuralnet hardware accelerators that together comprise a high-performance <b>character</b> <b>recognition</b> system. We also describe applications in networkbased fax and bit-mapped text processing...|$|R
40|$|This report {{relates to}} the {{development}} of automated analysis systems for the classification and declassification of documents. This report reflects the intended deliverables on the project {{at the end of the}} second year carryover project period. Products include: (1) an interactive support system to combine and coordinate classification and representation technologies, (2) a test suite for <b>optical</b> <b>character</b> and document <b>recognition,</b> (3) a classification/declassification system using logical analysis. Experimental results for the classification/declassification system are included in the report. Except for the TIPSTER component, which has been concluded, the other three components are proceeding with significant developments. It is proposed that the balance funds for the TIPSTER component be used to conclude the Knowledge Representation research...|$|R
25|$|Monospaced typefaces {{function}} {{better for}} some purposes because their glyphs {{line up in}} neat, regular columns. No glyph is given any more weight than another. Most manually operated typewriters use monospaced fonts. So do text-only computer displays and third- and fourth-generation game console graphics processors, which treat the screen as a uniform grid of character cells. Most computer programs which have a text-based interface (terminal emulators, for example) use only monospaced fonts (or add additional spacing to proportional fonts to fit them in monospaced cells) in their configuration. Monospaced fonts are commonly used by computer programmers for displaying and editing source code so that certain characters (for example parentheses used to group arithmetic expressions) are easy to see. Monospaced fonts may also {{make it easier to}} perform <b>optical</b> <b>character</b> <b>recognition.</b>|$|E
500|$|Since {{the advent}} of online editions of journals, abstracts are loaded into the ADS on or before the {{publication}} date of articles, with the full journal text available to subscribers. [...] Older articles have been scanned, and an abstract is created using <b>optical</b> <b>character</b> <b>recognition</b> software. [...] Scanned articles from before about 1995 are usually available free, by agreement with the journal publishers.|$|E
500|$|The second Group Decision Support System (GDDS2) expert mission (a {{wing of the}} World Bank) {{meeting on}} census {{enumeration}} took place during 23 – 27 February 2009, and it published a report with recommendations for the census enumeration. The report suggested using satellite imagery software, having frequent meetings with census steering committees, utilizing time-tested Optical Mark Reading (OMR) process for transferring data from census forms to computer-readable files or newer methods like <b>Optical</b> <b>Character</b> <b>Recognition</b> (OCR), assuring the quality of printing of the census questionnaires, taking Post-enumeration Survey (PES) on time, providing staff training for more in-depth census analysis, changing the population growth rate reporting structure, including measures from the 2007 Demographic and Health Survey (DHS), publishing the census in a medium conducive for general audience, obtaining technical assistance for post-census population projections at the national, provincial and district level, re-projecting [...] HIV prevalence, mortality, and AIDS orphanhood, and establishing a long-term Memorandum of understanding with a technical assistance organization like the US Census Bureau.|$|E
40|$|This paper {{presents}} {{a novel approach}} to executing handwritten code, the solution coined Iris. My research falls {{within the field of}} mobile app development, handwriting <b>recognition,</b> <b>optical</b> and intelligent <b>character</b> <b>recognition</b> (OCR & ICR), machine learning, as well as various Computer Science-related fields such as domain specific languages, or DSLs. The solution outlined in this paper details a system where one can author code using only a writing utensil (such as a pen), scratch paper (such as a napkin), and a smart phone. Iris leverages the power of the cloud to process an image of handwritten code and return the result to the user. Ultimately, my results show that Iris was able to accurately execute handwritten scripts with various levels of observed accuracy. Future work includes adding more layers of machine learning as well as further pre-processing images prior to OCR...|$|R
40|$|This paper {{presents}} a novel {{artificial neural network}} architecture with on-chip learning capability. The issue of straightforward design-flow integration of an autonomous unit is addressed with a mixed analog-digital approach, by implementing a charge-based artificial neural network which interacts with digital control and processing units. We demonstrate the circuit architecture and designflow approach for {{the case of a}} Hamming network performing pixel-pattern recognition. Keywords [...] - Charge-based ANN, mixed-mode ANN hardware architecture, ANN integration design-flow. I. Introduction T HE ABILITY of artificial neural networks (ANN) to acquire knowledge of their surrounding environment and adapt to it, as well as their use of a high degree of computing parallelism makes them very efficient in many application fields including process and quality control, consumer products, <b>optical</b> <b>character</b> and speech <b>recognition,</b> and complex forecasting tasks among many others [1]. Silicon implemen [...] ...|$|R
40|$|Unique {{identifiers}} (UID) {{are seen}} as an effective key to match identical publications across databases or identify duplicates in a database. The objective {{of the present study}} is to investigate how well UIDs work as match keys in the integration between Pure and SciVal, based on a case with publications from the health sciences. We evaluate the matching process based on information about coverage, precision, and characteristics of publications matched versus not matched with UIDs as the match keys. We analyze this information to detect errors, if any, in the matching process. As an example we also briefly discuss how publication sets formed by using UIDs as the match keys may affect the bibliometric indicators number of publications, number of citations, and the average number of citations per publication.   The objective is addressed in a literature review and a case study. The literature review shows that only a few studies evaluate how well UIDs work as a match key. From the literature we identify four error types: Duplicate digital object identifiers (DOI), incorrect DOIs in reference lists and databases, DOIs not registered by the database where a bibliometric analysis is performed, and erroneous <b>optical</b> or special <b>character</b> <b>recognition.</b> The case study explores the use of UIDs in the integration between the databases Pure and SciVal. Specifically journal publications in English are matched between the two databases. We find all error types except erroneous <b>optical</b> or special <b>character</b> <b>recognition</b> in our publication sets. In particular the duplicate DOIs constitute a problem for the calculation of bibliometric indicators as both keeping the duplicates to improve the reliability of citation counts and deleting them to improve the reliability of publication counts will distort the calculation of average number of citations per publication. The use of UIDs as a match key in citation linking is implemented in many settings, and the availability of UIDs may become critical for the inclusion of a publication or a database in a bibliometric analysis...|$|R
2500|$|SubRip – <b>optical</b> <b>character</b> <b>recognition</b> of {{subtitles}} {{superimposed on}} video (or in DVDs) ...|$|E
2500|$|... {{assess the}} {{probability}} of a given word sequence appearing in text of a language of interest in pattern recognition systems, speech recognition, OCR (<b>optical</b> <b>character</b> <b>recognition),</b> Intelligent Character Recognition (ICR), machine translation and similar applications ...|$|E
2500|$|Detection {{algorithms}} of {{all kinds}} often create false positives. <b>Optical</b> <b>character</b> <b>recognition</b> (OCR) software may detect an [...] "a" [...] where there are only some dots {{that appear to be}} an [...] "a" [...] to the algorithm being used.|$|E
5000|$|Editions 15 to 18 (the Cambridge English Pronouncing Dictionary): In 1988 {{the rights}} to the EPD were {{acquired}} by Cambridge University Press, and Peter Roach became principal editor for the 15th Edition. It was decided to add American pronunciations throughout, and James Hartman was appointed the American editor. The publishers moved to computer-based production, using <b>optical</b> scanning and <b>character</b> <b>recognition</b> of the preceding edition to compile a digital database ready for editing. The revision began in 1992, initially with Karen Stromberg as editorial assistant and subsequently with Jane Setter. More than 18,000 words were added and the new (15th) edition was published in 1997. The 16th Edition was published in 2003, the 17th in 2006 and the 18th (current) edition in 2011. For the 17th and 18th editions, Jane Setter was one of the editors. For the 18th, John Esling replaced James Hartman as American Editor.|$|R
40|$|Approximate string {{matching}} {{is an important}} paradigm in domains ranging from speech recognition to information retrieval and molecular biology. In this paper, we introduce a new formalism for a class of applications that takes two strings as input, each specified {{in terms of a}} particular domain, and performs a comparison motivated by constraints derived from a third, possibly different domain. This issue arises, for example, when searching multimedia databases built using imperfect recognition technologies (e. g., speech, <b>optical</b> <b>character,</b> and handwriting <b>recognition).</b> We present a polynomial time algorithm for solving the problem, and describe several variations that can also be solved efficiently. 1. Introduction Approximate {{string matching}} is a widely-studied paradigm with important applications in domains ranging from speech recognition to information retrieval and molecular biology [10, 3, 2, 12, 17, 4]. A key principle in this field is the concept of string edit distance, a mea [...] ...|$|R
40|$|ABSTRACT: In this paper, {{we propose}} the <b>character</b> <b>recognition</b> method using <b>optical</b> <b>character</b> reader {{technology}} for the smart phone application. The camera within Android smart phone captures the document and then the OCR is applied according to language database. As some language {{is added to the}} database, the character of the various languages can be easily recognized. From simulation results, we can see the results of tests in English...|$|R
