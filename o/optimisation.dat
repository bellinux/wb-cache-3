10000|1205|Public
5|$|Data error <b>optimisation</b> – Candidate paths varied {{speed and}} heading at each {{handshake}} to minimise the error between the calculated BFO of that path versus the actual BFO recorded from Flight 370. These paths were not {{constrained by the}} behaviour of the aircraft's autopilot.|$|E
5|$|The Airbus A330-800neo {{will retain}} the {{fuselage}} {{length of the}} A330-200, with cabin <b>optimisation</b> allowing up to six additional seats. It will feature new Rolls-Royce Trent 7000 engines with a 10:1 bypass delivering , improved aerodynamics including A350-style winglets increasing the span by 3.7m to 64m, and is scheduled to enter service in early 2018. It should cover 7500nm (13,900km) with 257 passengers (406 max).|$|E
5|$|The Airbus Airbus A330-900neo {{will keep}} the A330-300 {{fuselage}} with 10 more seats thanks to cabin <b>optimisation.</b> With the same engine and wing improvements, it should burn 14% less fuel per seat than the A330-300 on a 4,000 nmi flight {{and is expected to}} enter service at the end of 2017. It should travel 6550nm (12,130km) with 287 passengers (440 max).|$|E
40|$|In {{this note}} {{we present a}} set of <b>optimisations</b> for an {{intermediate}} lan-guage of a Standard ML compiler. Most of the <b>optimisations</b> presented are off-the-shelf <b>optimisations,</b> including dead code elimination, constant folding, recursive function specialization, in-lining and value propagation. All <b>optimisations</b> are presented in a typed setting. ...|$|R
5000|$|In April 2012 NetSurf 2.9 was released. The most {{significant}} changes were new multi-tasking behaviour, optimised URL handling, fetcher <b>optimisations,</b> cache <b>optimisations,</b> and faster CSS selection.|$|R
40|$|In {{this paper}} we {{summarise}} four recent <b>optimisations</b> to the FFS implementation in FreeBSD: soft updates, dirpref, vmiodir and dirhash. We then give a detailed exposition of dirhash's implementation. Finally we study these <b>optimisations</b> under {{a variety of}} benchmarks and look at their interactions. Under micro-benchmarks, combinations of these <b>optimisations</b> can offer improvements of over two orders of magnitude. Even real-world workloads see improvements by a factor of 2 [...] 10...|$|R
5|$|In {{computer}} science, {{simulations of}} evolution using evolutionary algorithms and artificial life {{started in the}} 1960s and were extended with simulation of artificial selection. Artificial evolution became a widely recognised <b>optimisation</b> method {{as a result of}} the work of Ingo Rechenberg in the 1960s. He used evolution strategies to solve complex engineering problems. Genetic algorithms in particular became popular through the writing of John Henry Holland. Practical applications also include automatic evolution of computer programmes. Evolutionary algorithms are now used to solve multi-dimensional problems more efficiently than software produced by human designers and also to optimise the design of systems.|$|E
25|$|Simplex {{algorithm}} – {{a method}} for solving <b>optimisation</b> problems with inequalities.|$|E
25|$|Maximum cut (<b>optimisation</b> version) is {{the problem}} ND14 in Appendix B (page 399).|$|E
40|$|Abstract—Synchronous Data flow (SDF) graphs have {{a simple}} and elegant {{semantics}} (essentially linear algebra) which makes SDF graphs eminently suitable {{as a vehicle for}} studying scheduling <b>optimisations.</b> We extend related work on using SPIN to experiment with scheduling <b>optimisations</b> aimed at minimising buffer requirements. We show that for a benchmark of commonly used case studies the performance of our SPIN based scheduler is comparable to that of state of the art research tools. The key to success is using the semantics of SDF to prove when using (even unsound and/or incomplete) <b>optimisations</b> are justified. The main benefit of our approach lies in gaining deep insight in the <b>optimisations</b> at relatively low cost. I...|$|R
40|$|In {{order to}} improve {{precision}} and efficiency sharing analysis should track both freeness and linearity. The abstract unification algorithms for these combined domains are suboptimal, hence there is scope for improving precision. This paper proposes three <b>optimisations</b> for tracing sharing in combination with freeness and linearity. A novel connection between equations and sharing abstractions is used to establish correctness of these <b>optimisations</b> even {{in the presence of}} rational trees. A method for pruning intermediate sharing abstractions to improve efficiency is also proposed. The <b>optimisations</b> are lightweight and therefore some, if not all, of these <b>optimisations</b> will be of interest to the implementor. Comment: To appear in Theiry and Practice of Logic Programmin...|$|R
40|$|Synchronous {{data flow}} (SDF) graphs {{have a simple}} and elegant {{semantics}} (essentially linear algebra) which makes SDF graphs eminently suitable {{as a vehicle for}} studying scheduling <b>optimisations.</b> We extend related work on using SPIN to experiment with scheduling <b>optimisations</b> aimed at minimising buffer requirements. We show that for a benchmark of commonly used case studies the performance of our SPIN based scheduler is comparable to that of state of the art research tools. The key to success is using the semantics of SDF to prove when using (even unsound and/or incomplete) <b>optimisations</b> are justified. The main benefit of our approach lies in gaining deep insight in the <b>optimisations</b> at relatively low cost...|$|R
25|$|The NK {{model has}} found use in many fields, {{including}} {{in the study of}} spin glasses, epistasis and pleiotropy in evolutionary biology, and combinatorial <b>optimisation.</b>|$|E
25|$|One of {{the reasons}} why the model has {{attracted}} wide attention in <b>optimisation</b> {{is that it is a}} particularly simple instance of a so-called NP-complete problem.|$|E
25|$|The main {{contributions}} of the model were firstly the initial question Ramsey posed on how much savings should be and secondly the method of analysis, the intertemporal maximisation (<b>optimisation)</b> of collective or individual utility by applying techniques of dynamic <b>optimisation.</b> Tjalling C. Koopmans and David Cass modified the Ramsey model incorporating the dynamic features of population growth at a steady rate and of Harrod-neutral technical progress again at a steady rate, giving birth to a model named the Ramsey–Cass–Koopmans model where the objective now is to maximise household's utility function.|$|E
40|$|Rights to {{individual}} papers {{remain with the}} author or the author's employer. Permission is granted for noncommercial reproduction of the work for educational or research purposes. This copyright notice must {{be included in the}} reproduced paper. USENIX acknowledges all trademarks herein. Recent Filesystem <b>Optimisations</b> in FreeBSD In this paper we summarise four recent <b>optimisations</b> to the FFS implementation in FreeBSD: soft updates, dirpref, vmiodir and dirhash. We then give a detailed exposition of dirhash’s implementation. Finally we study these <b>optimisations</b> under a variety of benchmarks and look at their interactions. Under micro-benchmarks, combinations of these <b>optimisations</b> can offer improvements of over two orders of magnitude. Even real-world workloads see improvements by a factor of 2 – 10. ...|$|R
30|$|Conclusions Over {{one hundred}} common {{prescribing}} errors and <b>optimisations</b> had modal clinical impact grades recorded for potential application in clinical practice and research. The inter-professional variability {{highlights the importance}} of multidisciplinary perspectives in assessment of medication errors and <b>optimisations</b> in clinical practice and research.|$|R
50|$|However, {{compiler}} <b>optimisations</b> {{cannot be}} done after exercising this relaxation alone. Compiler <b>optimisations</b> require the full flexibility of reordering any two {{operations in the}} PO, so the ability to reorder a write {{with respect to a}} read is not sufficiently helpful in this case.|$|R
25|$|In mathematics, {{computer}} science and operations research, mathematical optimization or mathematical programming, alternatively spelled <b>optimisation,</b> is {{the selection of}} a best element (with regard to some criterion) from some set of available alternatives.|$|E
25|$|The number 300 {{of generations}} is a {{conservative}} estimate for a slowly evolving species not at {{the brink of extinction}} by Haldane's calculation. For a difference of at least 1,000 genes, 300,000 generations might be needed – maybe more, if some gene runs through more than one <b>optimisation.</b>|$|E
25|$|The journal Reliable Computing (originally Interval Computations) {{has been}} {{published}} since the 1990s, dedicated to the reliability of computer-aided computations. As lead editor, R. Baker Kearfott, {{in addition to his}} work on global <b>optimisation,</b> has contributed significantly to the unification of notation and terminology used in interval arithmetic (Web: Kearfott).|$|E
40|$|Abstract. We {{consider}} simple compiler <b>optimisations</b> {{for removing}} redundant memory fences in programs running {{on top of}} the x 86 -TSO relaxed memory model. While the <b>optimisations</b> are performed using standard thread-local control flow analyses, their correctness is subtle and relies on a non-standard global simulation argument. The implementation and the proof of correctness are programmed in Coq as part of CompCertTSO, a fully-fledged certified compiler from a concurrent extension of a C-like language to x 86 assembler. In this article, we describe the soundness proof of the <b>optimisations</b> and evaluate their effectiveness. ...|$|R
40|$|Abstract. With this {{contribution}} we {{push the}} boundary of some known <b>optimisations</b> such as caching to the very expressive Description Logic SROIQ. The developed method {{is based on a}} sophisticated dependency management and a precise unsatisfiability caching technique, which further enables better informed tableau backtracking and more efficient pruning. Additionally, we optimise the handling of cardinality restrictions, by introducing a strategy called pool-based merging. We empirically evaluate the proposed <b>optimisations</b> within the novel reasoning system Konclude and show that the proposed <b>optimisations</b> indeed result in significant performance improvements. ...|$|R
40|$|Ordering <b>optimisations</b> are <b>optimisations</b> {{that can}} be applied to a con-current logic program when the atoms of a clause are known to be ordered. In this paper {{ordering}} <b>optimisations</b> are reviewed, reformulated and refined. The paper explains how ordering <b>optimisations</b> can be realised in terms of abstract interpretation and shows that by, building on schedule analysis, simple, efficient and accurate forms of abstract interpretation can achieved. The paper outlines how to: identify instances of unification which can be simplified or removed; distinguish repeated synchronisation instructions; in-dicate which redundant checks can be removed when producers are ordered before consumers in the same thread; identify which variables can be accessed without dereferencing; indicate where variable initialisation and unification can be simplified; and show which variables can be allocated to an environ-ment. Some safety checks can also be removed by using mode information. ...|$|R
25|$|On 1 April 2010, this Desktop Manager was updated to version 1.5.15695.18135. The update claimed, amongst other things, <b>optimisation</b> of CPU usage in full screen: 20% to 40% improvement; {{videos that}} start to {{download}} in the UK {{should be able}} to complete downloading abroad; and update to use Adobe Integrated Runtime AIR 1.5.3 which has improved reliability, compatibility and security.|$|E
25|$|One of {{the main}} {{difficulties}} with IHC staining is overcoming specific or non-specific background. <b>Optimisation</b> of fixation methods and times, pre-treatment with blocking agents, incubating antibodies with high salt, and optimising post-antibody wash buffers and wash times are all important for obtaining high quality immunostaining. In addition, the presence {{of positive and negative}} controls for staining are essential for determining specificity.|$|E
25|$|Both the A330-800neo and A330-900neo {{will retain}} the {{fuselage}} lengths of the A330-200 and A330-300, respectively. Cabin <b>optimisation</b> allows 10 additional {{seats on the}} A330-900neo (310 passengers) and six additional seats for the A330-800neo (252 travelers) with 18-inch-wide economy seats. The -800 should cover a 7500nm (13,900km) with 257 passengers (406 max) while the -900 should travel 6550nm (12,130km) with 287 passengers (440 max).|$|E
40|$|This paper {{describes}} user-level <b>optimisations</b> for virtual {{shared memory}} (VSM) systems and demonstrates performance improvements for three scientific kernel codes written in Fortran-S and {{running on a}} 30 node prototype distributed memory architecture. These <b>optimisations</b> {{can be applied to}} all consistency models and directory schemes, whether in hardware or software, which employ an invalidation based protocol. The semantics of these <b>optimisations</b> are carefully stated. Currently these <b>optimisations</b> are performed by the programmer, but there is much scope for automating this process within a compiler. 1 Introduction Virtual shared memory (VSM) systems provide the illusion of a shared address space on distributed memory architectures. A shared memory programming model is attractive because it is simple to program, thus speeding the implementation and porting of parallel programs, and enabling the parallelisation of complex adaptive programs which may be difficult to implement in message [...] ...|$|R
40|$|A {{substantial}} amount of work {{has been devoted to}} the proof of correctness of various program analyses but much less {{attention has been paid to}} the correctness of compiler <b>optimisations</b> based on these analyses. In this paper we tackle the problem in the context of strictness analysis for lazy functional languages. We show that compiler <b>optimisations</b> based on strictness analysis can be expressed formally in the functional framework using continuations. This formal presentation has two benefits: it allows us to give a rigorous correctness proof of the optimised compiler; and it exposes the various <b>optimisations</b> made possible by a strictness analysis...|$|R
40|$|Current {{proposals}} for concurrent shared-memory languages, including C++ and C, provide sequential consistency only for programs without data races (the DRF guarantee). While {{the implications of}} such a contract for hardware <b>optimisations</b> are relatively well-understood, the correctness of compiler <b>optimisations</b> under the DRF guarantee is less clear, and experience with Java shows that this area is error-prone. In this paper we give a rigorous study of <b>optimisations</b> that involve both reordering and elimination of memory reads and writes, covering many practically important <b>optimisations.</b> We first define powerful classes of transformations semantically, in a languageindependent trace semantics. We prove that any composition of these transformations is sound {{with respect to the}} DRF guarantee, and moreover that they provide basic security guarantees (no thinair reads) even for programs with data races. To give a concrete example, we apply our semantic results to a simple imperative language and prove that several syntactic transformations are safe for that language. We also discuss some surprising limitations of the DRF guarantee...|$|R
25|$|Auditing {{of results}} helps to compare {{formulae}} and <b>optimisation</b> strategies amongst each other. Due to considerable {{confusion in the}} past, a clear set of guidelines now exists to report IOL power related data. There are six key measures {{that are to be}} reported. In recognition of the fact that comparison of ideal IOL powers is likely to be error-prone, all comparisons are done for actual or predicted refractive errors.|$|E
25|$|Gelenbe {{has contributed}} {{pioneering}} research concerning {{the performance of}} multiprogramming computer systems, virtual memory management, data base reliability <b>optimisation,</b> distributed systems and network protocols. He formed, led, and trained the team that designed the commercial QNAP Computer and Network Performance Modeling Tool. He introduced the Flexsim Object Oriented approach for the simulation in manufacturing systems. He carried {{out some of the}} first work on adaptive control of computer systems, and published seminal papers on the performance <b>optimisation</b> of computer network protocols and on the use of diffusion approximations for network performance. He developed new product form queueing networks with negative customers and triggers known as G-networks. He also introduced a new spiked stochastic neural network model known as the random neural network, developed its mathematical solution and learning algorithms, and applied it to both engineering and biological problems. His inventions include the design of the first random access fibre-optics local area network, a patented admission control technique for ATM networks, a neural network based anomaly detector for brain magnetic resonance scans, and the cognitive packet network routing protocol to offer quality of service to users.|$|E
25|$|Pharmacists are {{healthcare}} professionals with specialised {{education and training}} who perform various roles to ensure optimal health outcomes for their patients through the quality use of medicines. Pharmacists may also be small-business proprietors, owning the pharmacy in which they practice. Since pharmacists know about the mode of action of a particular drug, and its metabolism and physiological effects on the human body in great detail, they {{play an important role}} in <b>optimisation</b> of a drug treatment for an individual.|$|E
40|$|The Password Based Key Derivation Function v 2 (PBKDF 2) is an {{important}} cryptographic primitive that has practical relevance to many widely deployed security systems. We investigate accelerated attacks on PBKDF 2 with commodity GPUs, reporting the fastest attack on the primitive to date, outperforming the previous stateof-the-art oclHashcat. We apply our attack to Microsoft. NET framework, showing that a consumer-grade GPU can break an ASP. NET password in less than 3 hours, and we discuss the application of our attack to WiFi Protected Access (WPA 2). We consider both algorithmic <b>optimisations</b> of crypto primitives and OpenCL kernel code <b>optimisations</b> and empirically evaluate the contribution of individual <b>optimisations</b> on the overall acceleration. In contrast to the common view that GPU acceleration is primarily driven by massively parallel hardware architectures, we demonstrate that a proportionally larger contribution to acceleration is made through effective algorithmic <b>optimisations.</b> Our work also contributes to understanding {{what is going on}} inside the black box of oclHashcat...|$|R
3000|$|... within professions (intra-rater)) {{of common}} {{prescribing}} errors and <b>optimisations</b> in critical care patients; and [...]...|$|R
40|$|Social norms enable {{coordination}} in multiagent {{systems by}} constraining agent behaviour {{in order to}} achieve a social objective. Automating the design of social norms {{has been shown to be}} NP-complete, requiring a complete state enumeration. A planning-based solution has been proposed previously to improve performance. This approach leads to verbose, problem-specific norms due to the propositional representation of the domain. We present a first-order extension of this work that benefits from state and operator abstractions to synthesise more expressive, generally applicable norms. We propose <b>optimisations</b> that can be used to reduce the search performed during synthesis, and formally prove the correctness of these <b>optimisations.</b> Finally, we empirically illustrate the benefits of these <b>optimisations</b> in an example domain...|$|R
