11|65|Public
40|$|In {{this paper}} we analyse the {{robustness}} of the Hobson-Rogers model {{with respect to}} the <b>offset</b> <b>function,</b> which depends on the whole past of the risky asset and is thus not fully observable. We prove that, if the <b>offset</b> <b>function</b> is the realisation of a stationary process, then the error in pricing a derivative asset decreases exponentially {{with respect to the}} observation window. We present sufficient conditions on the volatility in order to characterise the invariant density and three examples...|$|E
40|$|A sigmoid {{function}} has been utilized for the input/output {{functions of the}} back-propagation type neural networks. It, however, has a local minimum problem; if {{the output of the}} {{sigmoid function}} becomes 0 or 1, no further learning occurs even if there are errors between teaching inputs and outputs of the output unit. The offset method of applying some offset values to the intermediate layer cells is thought to be effective in solving the local minimum problem. In this paper, we propose two formulations of offset function; the linearly decremental <b>offset</b> <b>function</b> that decrements offset values as iteration of the learning process increases, and the logarithmic error <b>offset</b> <b>function</b> that various offset values according as logarithm of output errors. The performance of these methods are evaluated by recognition test of handwriting...|$|E
30|$|Following {{previous}} work [15, 16], we trained offset models using Gaussian Process (GP) regression [22]. A GP {{is determined by}} its mean and covariance functions. We choose a zero mean function — that is, we predict no offset {{in the absence of}} training data. As more calibration data is used, an <b>offset</b> <b>function</b> is learned.|$|E
40|$|The present {{paper is}} a short {{explanation}} related to what happen in ultrasonic calibration process. The material velocity and zero <b>offset</b> <b>functions</b> are related with the two known distance peaks classical requirement for setup. The autocalibration function is also explored and explained. The aim is to help beginners to understand the foundations of ultrasonic setup. 1...|$|R
40|$|We {{present a}} {{flexible}} Machine Learning approach for learn- ing user-specific touch input models to increase touch ac- curacy on mobile devices. The model {{is based on}} flexible, non-parametric Gaussian Process regression and is learned using recorded touch inputs. We demonstrate that signifi- cant touch accuracy improvements can be obtained when ei- ther raw sensor data is used as an input or when the device’s reported touch location is used as an input, with the latter marginally outperforming the former. We show that learned <b>offset</b> <b>functions</b> are highly nonlinear and user-specific and that user-specific models outperform models trained on data pooled from several users. Crucially, significant performance improvements can be obtained with a small (≈ 200) num- ber of training examples, easily obtained for a particular user through a calibration game or from keyboard entry data...|$|R
25|$|Machine formats {{generally}} contain primarily stitch data (<b>offsets)</b> {{and machine}} <b>functions</b> (trims, jumps, etc.) {{and are thus}} not easily scaled or edited without extensive manual work.|$|R
40|$|While an interhemispheric offset in {{atmospheric}} radiocarbon levels from AD 1950 – 950 is {{now well}} established, its existence {{earlier in the}} Holocene is less clear, with some studies reporting globally uniform 14 C levels while others finding Southern Hemisphere samples older by a few decades. In this paper, we present a method for wiggle-matching Southern Hemisphere data sets against Northern Hemisphere curves, using the Bayesian calibration program OxCal 4. 1 with the Reservoir <b>Offset</b> <b>function</b> accommodating a potential interhemispheric offset. The accuracy and robustness {{of this approach is}} confirmed by wiggle-matching known-calendar age sequences of the Southern Hemisphere calibration curve SHCal 04 against the Northern Hemisphere curve IntCal 04. We also show that 5 of 9 Holocene Southern Hemisphere data sets are capable of yielding reliable offset information. Those data sets that are accurate and precise show that interhemispheric offset levels in the Early Holocene are similar to modern levels, confirming SHCal 04 as the curve of choice for calibrating Southern Hemisphere samples...|$|E
40|$|In {{this paper}} we present an {{effective}} method for modeling realistic curly hairstyles, {{taking into account}} both artificial hairstyling processes and natural curliness. The result is a detailed geometric model of hairs that can be rendered and animated via existing methods. Our technique exploits the analogy between hairs and a vector field; interactively and efficiently models global and local hair flows by superimposing procedurally defined vector field primitives that have local influence. Usually {{only a very small}} number of vector field primitives are needed to model a complicated hairstyle. An initial model of hair strands is extracted from the superimposed vector fields by tracing their field lines. Random natural or artificial curliness can be added to the initial model through a parametric hair <b>offset</b> <b>function</b> with a randomized distribution of parameters over the scalp. Techniques for shearing and clustering are also designed to improve the overall appearance of the hair model. Our technique has been successfully applied to generate a variety of realistic hairstyles with different curliness and length distributions...|$|E
40|$|As a part {{of ongoing}} {{research}} projects at University West {{in the area of}} robot welding applications, a study was looked-for in the field of feedback control of robot systems with external sensors. A literature survey was performed in this field. A virtual instrument was developed in a PC using the LabView software from National Instruments. The instrument receives a signal from a force sensor, converts the input data and sends out the computed signal on a configured serial port. This information is then received by the robot system to be used to control the robot trajectory. The system was tested and it showed that external closed loop control of robot movement was possible to do. Problems with high delay time in the ABB IRB 2400 robot system limits the bandwidth or the speed of the closed loop system. This delay time is caused by the intrinsic <b>offset</b> <b>function</b> that is needed to change robot path during motion. This function requires a great computational cost. The conclusion is that ABB IRB 2400 robots, with the S 4 controller, are limited for applications with low bandwidth because of their motion computation program structure. It does not allow for external feedback applications that require higher robot movement speeds...|$|E
50|$|The {{functional}} {{principles of}} the two encoders are similar: a multichannel magneto-resistive sensor scans a target wheel with 256 teeth, generating sine and cosine signals. Arctangent interpolation is used to generate rectangular pulses from the sine/cosine signal periods. The precision encoder also possesses amplitude and <b>offset</b> correction <b>functions.</b> This {{makes it possible to}} further improve the signal quality, which greatly improves traction regulation.|$|R
30|$|To {{simulate}} fling-step-like motions {{in these}} seismograms, {{we used a}} simple sine ramp function (one sine pulse in acceleration) and determined three appropriate parameters: the starting time, rise time, and final <b>offset.</b> The final <b>functions</b> are shown by black broken lines in Fig.  10.|$|R
40|$|Summary- We {{will present}} coding {{techniques}} for transmission and storage channels with unknown gain and/or offset. It {{will be shown}} that a codebook of length-n q-ary codewords, S, where all codewords in S have equal balance and energy show an intrinsic resistance against unknown gain and/or <b>offset.</b> Generating <b>functions</b> for evaluating the size of S will be presented. We will present an approximate expression for the code redundancy for asymptotically large values of n. Key words: Constant composition code, permutation code, flash memory, optical recording I...|$|R
40|$|In this paper, we {{consider}} a generalisation of the Hobson–Rogers model proposed by Foschi and Pascucci (Decis Econ Finance 31 (1) : 1 – 20, 2008) for financial markets where {{the evolution of}} the prices of the assets depends not only on the current value but also on past values. Using differentiability of stochastic processes with respect to the initial condition, we analyse the robustness of such a model with respect to the so-called <b>offset</b> <b>function,</b> which generally depends on the entire past of the risky asset and is thus not fully observable. In doing this, we extend previous results of Blaka Hallulli and Vargiolu (2007) to contingent claims, which are globally Lipschitz with respect to the price of the underlying asset, and we improve the dependence of the necessary observation window on the maturity of the contingent claim, which now becomes of linear type, while in Blaka Hallulli and Vargiolu (2007), it was quadratic. Finally, in this framework, we give a characterisation of the stationarity assumption used in Blaka Hallulli and Vargiolu (2007), and prove that this model is stationary if and only if it is reduced to the original Hobson-Rogers model. We conclude by calibrating the model to the prices of two indexes using two different volatility shapes...|$|E
40|$|AbstractSimulated star maps {{serve as}} {{convenient}} inputs {{for the test}} of a star sensor, whose standardability mostly depends on the centroid precision of the simulated star image, so {{it is necessary to}} accomplish systematic error compensation for the simple Gaussian PSF (or SPSF, in which PSF denotes point spread function). Firstly, the error mechanism of the SPSF is described, the reason of centroid deviations of the simulated star images based on SPSF lies in the unreasonable sampling positions (the centers of the covered pixels) of the Gaussian probability density function. Then in reference to the IPSF simulated star image spots regarded as ideal ones, and by means of normalization and numerical fitting, the pixel center <b>offset</b> <b>function</b> expressions are got, so the systematic centroid error compensation can be executed simply by substituting the pixel central position with the offset position in the SPSF. Finally, the centroid precision tests are conducted for the three big error cases of Gaussian radius σ= 0. 5, 0. 6, 0. 671 pixel, and the centroid accuracy with the compensated SPSF (when σ= 0. 5) is improved to 2. 83 times that of the primitive SPSF, reaching a 0. 008 pixel error, an equivalent level of the IPSF. Besides its simplicity, the compensated SPSF further increases both the shape similarity and the centroid precision of simulated star images, which helps to improve the image quality and the standardability of the outputs of an electronic star map simulator (ESS) ...|$|E
40|$|The {{images in}} a short wave channel 15 (4. 45 µm) of GOES 15 Sounder show {{considerable}} striping effects. The study by ITT Exelis group showed that these striping effects can be characterized by the detector to detector (D 2 D) and scan to scan (S 2 S) stripings. The D 2 D striping {{is caused by the}} overall sinusoidal oscillation behavior across east-west scan direction for each detector with the fixed wavelength of 350 pixels. The phases of the sinusoidal oscillation for detector 1 and 3 is opposite to that for detector 2 and 4 so that the striping effects reaches to the maximum when the oscillation magnitude for 1 and 3 (1 + 3) or 2 and 4 (2 + 4) are at maximum. The D 2 D is location dependent as well as time dependent with a diurnal behavior. The S 2 S striping is overall the difference of same detector between East to West and West to East scans. This striping feature is not location dependent in an image, however, it is time dependent with the diurnal behavior. A real time de-striping algorithm implemented in GOES ground systems is presented in this study. The algorithm corrects both D 2 D and S 2 S stripings on a scan by scan basis to minimize the impact on the latency requirements of the GOES Sounder data processing in the ground system. The de-striping is done sequentially with D 2 D striping being corrected first. The algorithm retrieves the sinusoidal oscillation function from an <b>offset</b> <b>function</b> between detectors 1 + 3 and 2 + 4 through the Fast Fourier transformation (FFT), as the <b>offset</b> <b>function</b> is dominated by the D 2 D striping function. The D 2 D striping is corrected for a detector in the scan by subtracting the value of the oscillation function at the corresponding position. The S 2 S striping characteristics is obtained from the difference between the mean values of a detector at a given scan direction and the whole image. For the real time de-striping operation, the S 2 S striping for an image is corrected by an average of S 2 S striping terms from the images {{at the same time in}} previous two days. Before the correction is made, the data are collected for the current scan that will be used to evaluate the S 2 S striping characteristics, which is calculated at the end of each frame to replace the old value in the data buffer which will be used for the image at the next day at the same time. The results show that the algorithm has been very effective to provide systematic corrections to both D 2 D and S 2 S stripings. Independent evaluation of the test data shows that the S 2 S and D 2 D striping noises meet the specification after the application of correction algorithm. It is also very efficient so that it has no significant impact on the latency of the Sounder data processing in GOES ground system...|$|E
50|$|Supported common {{mathematical}} functions (unary, binary {{and variable}} number of arguments), including: trigonometric functions, inverse trigonometric functions, logarithm functions, exponential function, hyperbolic functions, Inverse hyperbolic functions, Bell numbers, Lucas numbers, Stirling numbers, prime-counting function, exponential integral function, logarithmic integral <b>function,</b> <b>offset</b> logarithmic integral , binomial coefficient and others.|$|R
40|$|Magneto-absorption {{experiments}} {{on a range}} on In 1 -xGaxAsyP 1 -y/InGaAsP multi-quantum well (MQW) structures, including both tensile and compressive strained wells, are presented. Estimates for the band offsets are made in a lattice matched and a strain-balanced structure, and a model to predict the band <b>offsets</b> as a <b>function</b> of strain in InGaAsP heterostructures is described...|$|R
40|$|We {{demonstrate}} a measurement of lithographic overlay using light scattering ellipsometry. In {{the limit of}} small amplitude surface topography, the polarization of light scattered by the two interfaces of a dielectric film can be decomposed into the roughness of each interface and the complex degree of phase correlation. For two identical but <b>offset</b> roughness <b>functions,</b> the degree of phase correlation will show oscillations, whose frequency in the spatial frequency domain will be given by the overlay distance ∆x. The method is tested using a shallow pseudorandom binary 1 -D grating, photolithographically produced on a silicon wafer and again on a spin-on glass layer deposited onto the wafer...|$|R
40|$|Taupo volcano {{in central}} North Island, New Zealand, {{is the most}} {{frequently}} active and productive rhyolite volcano on Earth. Its latest explosive activity about 1800 years ago generated the spectacular Taupo eruption, the most violent eruption known {{in the world in}} the last 5000 years. We present here a new accurate and precise eruption date of AD 232 ± 5 (1718 ± 5 cal. BP) for the Taupo event. This date was derived by wiggle-matching 25 high-precision ¹⁴C dates from decadal samples of Phyllocladus trichomanoides from the Pureora buried forest near Lake Taupo against the high-precision, first-millennium AD subfossil Agathis australis (kauri) calibration data set constructed by the Waikato Radiocarbon Laboratory. It shows that postulated dates for the eruption estimated previously from Greenland ice-core records (AD 181 ± 2) and putative historical records of unusual atmospheric phenomena in ancient Rome and China (c. AD 186) are both untenable. However, although their conclusion of a zero north–south ¹⁴C offset is erroneous, and their data exhibit a laboratory bias of about 38 years (too young), Sparks et al. (Sparks RJ, Melhuish WH, McKee JWA, Ogden J, Palmer JG and Molloy BPJ (1995) ¹⁴C calibration in the Southern Hemisphere and the date of the last Taupo eruption: Evidence from tree-ring sequences. Radiocarbon 37 : 155 – 163) correctly utilized the Northern Hemisphere calibration curve of Stuiver and Becker (Stuiver M and Becker B (1993) High-precision decadal calibration of the radiocarbon timescale, AD 1950 – 6000 BC. Radiocarbon 35 : 35 – 65) to obtain an accurate wiggle-match date for the eruption identical to ours but less precise (AD 232 ± 15). Our results demonstrate that high-agreement levels, indicated by either agreement indices or χ² data, obtained from a ¹⁴C wiggle-match do not necessarily mean that age models are accurate. We also show that laboratory bias, if suspected, can be mitigated by applying the reservoir <b>offset</b> <b>function</b> with an appropriate error value (e. g. 0 ± 40 years). Ages for eruptives such as Taupo tephra that are based upon individual ¹⁴C dates should be considered as approximate only, and confined ideally to short-lived material (e. g. seeds, leaves, small branches or the outer rings of larger trees) ...|$|E
40|$|Map-making {{presents}} a significant computational {{challenge to the}} next generation of kilopixel CMB polarisation experiments. Years worth of time ordered data (TOD) from thousands of detectors will need to be compressed into maps of the T, Q and U Stokes parameters. Fundamental to the science goal of these experiments, the observation of B-modes, is the ability to control noise and systematics. In this paper, we consider an alternative to the maximum-likelihood method, called destriping, where the noise is modelled as a set of discrete <b>offset</b> <b>functions</b> and then subtracted from the time-stream. We compare our destriping code (Descart: the DEStriping CARTographer) to a full maximum-likelihood map-maker, applying them to 200 Monte-Carlo simulations of time-ordered data from a ground based, partial-sky polarisation modulation experiment. In these simulations, the noise is dominated by either detector or atmospheric 1 /f noise. Using prior information of the power spectrum of this noise, we produce destriped maps of T, Q and U which are negligibly different from optimal. The method does not filter the signal or bias the E or B-mode power spectra. Depending on the length of the destriping baseline, the method delivers between 5 and 22 times improvement in computation time over the maximum-likelihood algorithm. We find that, for the specific case of single detector maps, it is essential to destripe the atmospheric 1 /f in order to detect B-modes, even though the Q and U signals are modulated by a half-wave plate spinning at 5 -Hz. Comment: 18 pages, 17 figures, MNRAS accepted v 2 : content added (inc: table 2), typos correcte...|$|R
2500|$|In a {{handwritten}} note on a reprint of his 1838 paper [...] "Sur l'usage des séries infinies dans la théorie des nombres", which he mailed to Carl Friedrich Gauss, Peter Gustav Lejeune Dirichlet conjectured (under {{a slightly different}} form appealing to a series rather than an integral) that an even better approximation to [...] is given by the <b>offset</b> logarithmic integral <b>function</b> , defined by ...|$|R
40|$|Summary. This paper {{examines}} {{the effects on}} cylindrical slant stacks of spatially-truncating a wide-aperture seismic section. We demonstrate that a step discontinuity in offset coverage, usually caused by only having available a limited range of data, {{is responsible for the}} linear artifacts frequently seen in slant stacks. These we show t o have slopes corresponding t o the offsets of the discontinuities in the x [...] t domain. We also show that the artifacts can be attenuated by applying an appropriate <b>offset</b> taper <b>function</b> to the section before slant stacking. This procedure is illustrated on some wide-aperture seismic data shot in the Gulf o f Mexico. Key words: edge, cylindrical, slant stack...|$|R
40|$|Abstract. We {{present a}} {{pulmonary}} vessel segmentation algorithm, which is fast, fully automatic and robust. It uses a coarse segmentation of the airway tree and a {{left and right}} lung labeled volume to restrict a vessel enhancement filter, based on an <b>offset</b> medialness <b>function,</b> to the lungs. We show the application of our algorithm on contrast-enhanced CT images, where we derive a clinical parameter to detect pulmonary hypertension (PH) in patients. Results on a dataset of 24 patients show that quantitative indices derived from the segmentation are applicable to distinguish patients with and without PH. Further work-in-progress re-sults are shown on the VESSEL 12 challenge dataset 1, which is composed of non-contrast-enhanced scans, where we range in the midfield of partic-ipating contestants. ...|$|R
40|$|There {{does not}} usually exist a closed general NURBs {{representation}} of the offset curve (or surface) to a NURBs curve (surface). In a related paper [7] a method was developed to determine a sequence of approximations to the offset curve (surface) of a given curve (surface) with the properties that the global error of each approximation from the true offset can be bounded and the sequence converges to the true offset. In this paper we {{take the next step}} and develop a method using the analysis of the <b>offset</b> error <b>function</b> that perturbs the curve or surface control points of a specified NURBs approximation to an offset of a NURBs curve (surface) so a better approximation to the offset results. ...|$|R
40|$|The {{authors have}} {{performed}} density-functional-theory calculations on seven (001) Si 6 Ge 6 superlattices grown on substrates with lattice constants ranging from 5. 36 to 5. 66 AA. They find that, {{with the exception}} of the L-derived conduction band states the energies of principal levels vary linearly with the substrate lattice constant. The valence band <b>offset</b> as a <b>function</b> of substrate lattice constant exhibits a discontinuity at the silicon and the germanium lattice constants...|$|R
5000|$|Embroidery {{machines}} {{generally have}} one or more machine formats specific to their brand. However, some formats such as Tajima's [...]dst, Melco's [...]exp/.cnd and Barudan's [...]fdr have become so prevalent that they have effectively become industry standards and are often supported by machines built by rival companies. Machine formats generally contain primarily stitch data (<b>offsets)</b> and machine <b>functions</b> (trims, jumps, etc.) and are thus not easily scaled or edited without extensive manual work.|$|R
40|$|We {{present a}} {{pulmonary}} vessel segmentation algorithm, which is fast, fully automatic and robust. It uses a coarse segmentation of the airway tree and a {{left and right}} lung labeled volume to restrict a vessel enhancement filter, based on an <b>offset</b> medialness <b>function,</b> to the lungs. We show the application of our algorithm on contrast-enhanced CT images, where we derive a clinical parameter to detect pulmonary hypertension (PH) in patients. Results on a dataset of 24 patients show that quantitative indices derived from the segmentation are applicable to distinguish patients with and without PH. Further work-in-progress results are shown on the VESSEL 12 challenge dataset, which is composed of non-contrast-enhanced scans, where we range in the midfield of participating contestants. Comment: Part of the OAGM/AAPR 2013 proceedings (1304. 1876...|$|R
40|$|An {{attitude}} control system was designed permitting large angle acquisition and alignment of the principle axis of a spinning payload to within 1 degree of the earth's magnetic field. Signals from magnetometer and gyro sensors are fed to the control algorithm to generate commands for the jet thrusters. The algorithm contains a cross axis magnetometer signal to prevent a large angle magnetometer signal to prevent a large angle equilibrium solution. The acquisition will occur within 50 seconds from initial precession and nutation angles of 30 degrees. An electronic spin filter passes signals at spin and nutation frequencies and rejects bias signals due to sensor misalignment and principle axis <b>offset.</b> Describing <b>function</b> analysis and total analog simulation techniques were used. The flight ACS hardware was interfaced with the analog computer simulation for design and verification. The controller has flown on four successful missions...|$|R
40|$|In {{their recent}} paper, Drs. Ghosh and Kumar {{considered}} the rele-vant problem of convergence {{of the power}} series expansions of trav-eltime and <b>offset</b> as <b>functions</b> of horizontal slowness, claiming that these are nowhere analytical functions. Based on this claim, they conclude that the commonly used series expansion of traveltime and traveltime squared as a <b>function</b> of <b>offset</b> is also nowhere analytic, namely that the radius of convergence is zero. This contradicts previ-ous results of Goldin 1986 and Tygel 1994, who have shown that these power series have some minimum, model-dependent, non-empty convergence regions. In what follows, we shall briefly state the problem and show that the arguments and the claim made by Drs. Ghosh and Kumar are wrong. The traveltime and offset for a multiply reflected, transmitted, and possibly converted wave are given by Slotnick 1959, Tp = ra...|$|R
40|$|International Telemetering Conference Proceedings / October 21, 2002 / Town & Country Hotel and Conference Center, San Diego, CaliforniaSimplification of {{the analog}} {{front end of}} a signal {{conditioning}} circuit {{can be accomplished by}} over-quantizing the input signal and using DSP for gain and offset. In this case, a much higher precision A/D converter is used than required by the desired output accuracy. The excess bits are then used to allow the DSP math to give an effective gain to the signal. By a similar <b>function,</b> <b>offset</b> of over 100...|$|R
40|$|In {{the process}} of form control using bonnet {{polishing}} an influence function is of vital importance for establishing material removal rates. However, the effects of polishing cloth, workpiece hardness and polishing parameters (such as precess angle, head speed, tool pressure and tool <b>offset)</b> on influence <b>function</b> when polishing CoCr alloys are not yet established and these factors affect the deterministic polishing process. In order to obtain a controlled polishing process, this study has further investigated the effects of polishing parameters on the influence function, including geometric size and volumetric material removal rates (MRRs) ...|$|R
40|$|We {{demonstrate}} that quasi {{direct band gap}} Si 1 –xGex/Si superlattices {{can be obtained by}} suitable choices of layer thicknesses. We calculate strain dependent conduction-band <b>offsets</b> as <b>functions</b> of the substrate alloy concentration, and of the epilayer alloy concentration. Optical matrix elements are computed for Si 0. 5 Ge 0. 5 /Si superlattices grown on Si 0. 75 Ge 0. 25 buffer layers with superlattice layer thicknesses of 4 to 24 monolayers. We find that optical absorption and emission strengths can vary by three to four orders of magnitude for layer thickness variations as small as 1 – 2 monolayers, suggesting that layer thicknesses must be controlled to within one monolayer to obtain enhanced optical properties. Typical optical matrix elements calculated for these Si 1 –xGex/Si superlattices are three to four orders of magnitude larger than for bulk Si or Ge, but, are still three orders of magnitude smaller than for direct band gap materials such as GaAs...|$|R
40|$|A novel {{approach}} to fault diagnosis {{for a class}} of nonlinear uncertain systems with triangular form is proposed in this paper. It {{is based on the}} extended state observer (ESO) of the active disturbance rejection controller and linearization of dynamic compensation. Firstly, an ESO is designed to jointly estimate the states and the combination of uncertainty, faults, and nonlinear function of nonlinear uncertain systems. It can derive the estimation of nonlinear function via the state estimations and system model. Then, linearization of dynamic compensation is employed to linearize the system by <b>offsetting</b> nonlinear <b>function</b> mandatorily using its estimation. An observer-based residual generator is designed {{on the basis of the}} prior linearized model for fault diagnosis. Moreover, threshold treatment technique is adopted to improve the robustness of fault diagnosis. This method is utilizable and simple in construction and parameter tuning. And also we show the construction of ESO and give the corresponding convergence proof succinctly. Finally, a numerical example is presented to illustrate the validity of the proposed fault diagnosis scheme...|$|R
40|$|An {{extensive}} {{statistical analysis}} has been undertaken {{to determine if}} a correlation exists between changes in an NR atomic hydrogen maser's frequency offset and changes in environmental conditions. Correlation analyses have been performed comparing barometric pressure, humidity, and temperature with maser frequency <b>offset</b> as a <b>function</b> of time for periods ranging from 5. 5 to 17 days. Semipartial correlation coefficients as large as - 0. 9 have been found between barometric pressure and maser frequency offset. Correlation between maser frequency offset and humidity was small compared to barometric pressure and unpredictable. Analysis of temperature data indicates that in the most current design, temperature does not significantly affect maser frequency offset...|$|R
40|$|International audienceThis paper {{deals with}} the on-line {{estimation}} of a dynamical carrier phase and a frequency offset in a digital receiver. We consider a Brownian phase evolution with a linear drift in a Data Aided scenario. The proposed study is relative {{to the use of}} an oversampled signal model after matched filtering, leading to a coloured reception noise and a non-stationary power signal. We derive a closed-form expression of the Hybrid Cramer-Rao Bound (HCRB) for this estimation problem. We use a Binary <b>Offset</b> Carrier (BOC) <b>function</b> as shaping pulse. Our numerical results show the potential gain of using the oversampled signal for estimating the dynamical phase and frequency offset, obtaining better performances than using a classical synchronizer...|$|R
50|$|Alternatively, {{autophagy}} {{has also}} been shown to play a huge role in tumor cell survival. In cancerous cells, autophagy is used as {{a way to deal with}} stress on the cell. Once these autophagy related genes were inhibited, cell death was potentiated. The increase in metabolic energy is <b>offset</b> by autophagy <b>functions.</b> These metabolic stresses include hypoxia, nutrient deprivation, and an increase in proliferation. These stresses activate autophagy in order to recycle ATP and maintain survival of the cancerous cells. Autophagy has been shown to enable continued growth of tumor cells by maintaining cellular energy production. By inhibiting autophagy genes in these tumors cells, regression of the tumor and extended survival of the organs affected by the tumors were found. Furthermore, inhibition of autophagy {{has also been}} shown to enhance the effectiveness of anticancer therapies.|$|R
