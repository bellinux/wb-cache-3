33|1|Public
25|$|A {{report by}} B. Sreejan, senior {{reporter}} with the Thiruvananthapuram bureau of The New Indian Express (12 April 2007), {{stated that the}} original chemical examination report of the vaginal swab and vaginal smear of Abhaya {{has been found to}} have been tampered with. The manuscript of the workbook report from the Chemical Examination Laboratory shows <b>over-writing</b> in four places. Using a whitener and a different ink, the word ‘‘not’’ has been added to the word ‘‘detected,’. The lab explained that it was quite normal to make corrections in the manuscript. Even Varghese P Thomas, the first investigating officer, said the post mortem and lab reports had ruled out rape, leaving no scope for suspicions on the veracity of the report.|$|E
500|$|Regarding season three, Bill Carter of The New York Times called Grey's Anatomy [...] "television's hottest show", adding: [...] " [...] is {{expected}} to challenge Grey's Anatomy for prime-time pre-eminence." [...] Contrasting with Carter's view, Monfette of IGN said that it speedily found itself [...] "mired in the annoying and absurd", adding: [...] "This third season may very well represent a case of <b>over-writing</b> a concept that has, perhaps tragically, run bone-dry on narrative fuel." [...] At the conclusion of season three, Entertainment Weekly Gregory Kirschling said [...] "the show lacked a defining happy, warm-gooseflesh moment", adding that the season [...] "didn't leave you dying for the [...] season premiere". Speaking of the fourth season, Laura Burrows of IGN said the series became [...] "a little more than mediocre, but less than fantastic", adding: [...] "This season proved that even strong chemistry and good acting cannot save a show that suffers from the inevitable recycled plot." ...|$|E
500|$|The season {{received}} mixed {{to negative}} reviews, after two seasons {{that resulted in}} heavy critical acclaim. Following a positive outlook on the second season, Christopher Monfette of IGN Entertainment expressed disappointment during the third one, mainly due to the declining quality and lack of realism of the storylines. He noted {{a growing number of}} similarities between the season's arcs and the ones that are developed in soap operas, by stating that [...] "the line which separates primetime television from soap opera is oftentimes razor thin" [...] and admitting that, despite his considering the series [...] "the best drama", he freely admits that it requires some inherent suspension of disbelief, after it [...] "found itself mired in the annoying and absurd". Whereas Monfette acknowledged that the fans would consider the problem to have been a simple case of lazy writing, he noted that <b>over-writing</b> played a main role in the series becoming unexpectedly unrealistic. He also noted the senseless intrigues in the Derek/Meredith relationship, by stating that the season would not have achieved high ratings if a functional relationship had been introduced: [...] "The season generally opts to stall out for its vast majority, providing Meredith with some bizarrely under-developed sub-plot about depression and giving Derek a season's worth of reconsidering to do".|$|E
40|$|The paper delineates {{successive}} reinscriptions by Europeans {{that followed}} the original inscribing by Aborigines and Islanders of islands lying near the tropical Queensland coast. It traces recurrent themes in the literature that records these succesive <b>over-writings,</b> including Jean Devanny's unpublished travelogue, The Island and Kay Donovan's novel, Bush Oranges (Magnetic Island); E. J. Banfield's The Confessions of a Beachcomber and Dorothy Cottrell's The Singing Gold (Dunk Island); Rosaleen Love's Reefscape (Nymph Island); Thea Astley's The Genteel Poverty Bus Company (Whitsunday Islands); and tales of shipwreck and island adventure like Ion Idriess's Madman's Island, which usually present the islands as dystopias. Finally, the paper surveys novels {{that focus on the}} islands' ethnic mixtures,such as Terri Janke's Butterfly Song (Thursday Island), and Astley's The Multiple Effects of Rainshadow (Palm Island) ...|$|R
2500|$|Six of Bishop's {{first eight}} novels are set on other worlds (the {{other two are}} {{the part of his}} UrNu {{sequence}} of stories.) Critic and author John Clute writes that [...] "…his early stories and novels display considerable intellectual complexity, and do not shirk the downbeat implications of their anthropological treatment of aliens and alienating milieux…" [...] In his major essay on these early novels, author Ian Watson writes [...] "Michael Bishop is both an exoticist and a moralist. [...] He is sometimes guilty, in the first respect, of a certain <b>over-writing</b> – underlying exotic venue by exotic diction – though the two become more organically integrated as his work progresses; and in the second respect of what one might call an over-scrupulousness on the part of his characters and his perceived attitude to them… These, however, are merely the consequence of aspiration and conscience; and as more of Bishop's work has appeared – and his reputation has grown – he has shown…a more coherent melding of exotic vision, ethics and style." ...|$|E
2500|$|The novel's {{narrative}} structure was {{singled out by}} reviewers with similarly divided verdicts. For Manning, the novel's opening, [...] "an excellent device ...to allow the book to start dramatically", and subsequent moments of pace and tension, are ruined by chronic <b>over-writing.</b> Nye felt {{the use of the}} two falls of Hephaestus as a framing device [...] "makes sense of what comes in-between", but for Nye [...] "it is a savage sort of sense, depending to a large extent on melodrama". History Today claimed the choice to retell the myths as a continuous narrative resulted in [...] "a brilliant poetic fantasy"; Hughes said of the novel's series of stories, [...] "heir zest sweeps you along. It is a real feat, to make everything sound so first hand." [...] Contemporary Review observed a [...] "slight decline in narrative cohesiveness" [...] {{in the second half of}} the book, after the [...] "fine ... reworking of the earlier myths" [...] but felt it [...] "detracts little from the effectiveness of dramatic and narrative motifs ... which help tie together the disparate myths so well." [...] The Spectator claimed [...] "the narrative is handled with dramatic, and comic, awareness of the epic voyage into our creative origins." ...|$|E
5000|$|The {{output of}} cat may be {{redirected}} to a file(or <b>over-writing</b> existing file): cat options file_names > newfile.txt ...|$|E
5000|$|Store {{the last}} 48 hours of safety-critical train data. This {{is to prevent}} <b>over-writing</b> of the crash data if the loco {{is used for the}} {{subsequent}} [...] "clean-up" [...] of the crash scene.|$|E
50|$|Writing data to a tape, erasing, or {{formatting}} a tape {{is often}} a significantly time-consuming process and can take several hours on large tapes. With many data tape technologies {{it is not necessary}} to format the tape before <b>over-writing</b> new data to the tape. This is due to the inherently destructive nature of overwriting data on sequential media.|$|E
5000|$|Rex {{belongs to}} the small but {{significant}} group of writers who have articulated {{the experiences of the}} Eurasians. I think, some <b>over-writing</b> notwithstanding, Rex's contribution is admirable. At its best, Rex's writing is passionate, humane and highly focused. Though he generally kept a low profile, his literary works will stand the test of time, combining a sharp sense of observed commentary with historical detail.|$|E
5000|$|With the {{development}} of affordable EEPROM and flash memory, it became practical to attach the controller permanently to the board and to download program code from a host computer through a serial connection. This was termed [...] "in-circuit programming". Erasure of old programs {{was carried out by}} either <b>over-writing</b> them with a new download, or bulk erasing them electrically (for EEPROM). The latter method was slower, but could be carried out in-situ.|$|E
50|$|A {{report by}} B. Sreejan, senior {{reporter}} with the Thiruvananthapuram bureau of The New Indian Express (12 April 2007), {{stated that the}} original chemical examination report of the vaginal swab and vaginal smear of Abhaya {{has been found to}} have been tampered with. The manuscript of the workbook report from the Chemical Examination Laboratory shows <b>over-writing</b> in four places. Using a whitener and a different ink, the word ‘‘not’’ has been added to the word ‘‘detected,’. The lab explained that it was quite normal to make corrections in the manuscript. Even Varghese P Thomas, the first investigating officer, said the post mortem and lab reports had ruled out rape, leaving no scope for suspicions on the veracity of the report.|$|E
5000|$|All {{the writers}} have obvious {{weaknesses}} with their writing. Grace's children {{have long since}} grown up and her ideas would be confusing to the age this kind of story is aimed at. Jess never manages to start writing, whilst Vivi is clearly <b>over-writing,</b> and her description of the detective's smitten sidekick is obviously modelled on her and her search for the right man. Brevis's long list of successfully performed musicals {{can be attributed to}} the fact that he was a teacher at a school, and now that he is retired he is stuck. And Clem gets angry that no-one can follow his incomprehensible plot, and his persistent mispronunciation of words (such as [...] "invulshable" [...] instead of [...] "invincible") drives Brevis up the wall.|$|E
5000|$|In 1950 Croft {{joined the}} {{teaching}} staff of Alleyn's boys' school in Dulwich, south London, {{and it was}} while here that he wrote his novel, which, according to the Oxford Dictionary of National Biography became [...] "a minor cause célèbre among liberal educationists" [...] and [...] "after skirmishes with the British Board of Film Censors, was filmed in 1961 with Max Bygraves as the sexually ambivalent schoolteacher." [...] Reviewing the book for The Daily Telegraph, John Betjeman wrote glowingly about it, saying: [...] "I have seldom been more alarmed and affected by a new novel than I have by 'Spare the Rod'. This is the first novel which shows a sense of narration and form, and with an absence of <b>over-writing</b> altogether admirable." ...|$|E
5000|$|Regarding season three, Bill Carter of The New York Times called Grey's Anatomy [...] "television's hottest show", adding: [...] "show is {{expected}} to challenge Grey's Anatomy for prime-time pre-eminence." [...] Contrasting with Carter's view, Monfette of IGN said that it speedily found itself [...] "mired in the annoying and absurd", adding: [...] "This third season may very well represent a case of <b>over-writing</b> a concept that has, perhaps tragically, run bone-dry on narrative fuel." [...] At the conclusion of season three, Entertainment Weekly Gregory Kirschling said [...] "the show lacked a defining happy, warm-gooseflesh moment", adding that the season [...] "didn't leave you dying for the next season premiere". Speaking of the fourth season, Laura Burrows of IGN said the series became [...] "a little more than mediocre, but less than fantastic", adding: [...] "This season proved that even strong chemistry and good acting cannot save a show that suffers from the inevitable recycled plot." ...|$|E
5000|$|Six of Bishop's {{first eight}} novels are set on other worlds (the {{other two are}} {{the part of his}} UrNu {{sequence}} of stories.) Critic and author John Clute writes that [...] "…his early stories and novels display considerable intellectual complexity, and do not shirk the downbeat implications of their anthropological treatment of aliens and alienating milieux…" [...] In his major essay on these early novels, author Ian Watson writes [...] "Michael Bishop is both an exoticist and a moralist. He is sometimes guilty, in the first respect, of a certain <b>over-writing</b> - underlying exotic venue by exotic diction - though the two become more organically integrated as his work progresses; and in the second respect of what one might call an over-scrupulousness on the part of his characters and his perceived attitude to them… These, however, are merely the consequence of aspiration and conscience; and as more of Bishop's work has appeared - and his reputation has grown - he has shown…a more coherent melding of exotic vision, ethics and style." ...|$|E
5000|$|When a {{soft-sectored disk}} is {{low-level}} [...] "formatted", each track is written {{with a number}} of bytes calculated to fit within 360 degrees at the highest expected motor speed; identification data showing where each sector should start is written at this time. The system of punched holes used by hard-sectored disks is not needed; a single hole is retained to indicate the start of the track (-inch disks use an alignment pin rather than a hole). If the motor is spinning any slower than the highest acceptable speed, which is usually the case, the data will fit in fewer than 360 degrees, resulting in a gap {{at the end of the}} track. Additionally, if a sector were to be rewritten on a drive running faster than the drive was running when the track was formatted, the new data would be larger (occupy more degrees of rotation) than the original sector. Therefore, during formatting a gap must be left between sectors to allow a rewritten sector to be larger without <b>over-writing</b> the following sector.|$|E
5000|$|The season {{received}} mixed {{to negative}} reviews, after two seasons {{that resulted in}} heavy critical acclaim. Following a positive outlook on the second season, Christopher Monfette of IGN Entertainment expressed disappointment during the third one, mainly due to the declining quality and lack of realism of the storylines. He noted {{a growing number of}} similarities between the season's arcs and the ones that are developed in soap operas, by stating that [...] "the line which separates primetime television from soap opera is oftentimes razor thin" [...] and admitting that, despite his considering the series [...] "the best drama", he freely admits that it requires some inherent suspension of disbelief, after it [...] "found itself mired in the annoying and absurd". Whereas Monfette acknowledged that the fans would consider the problem to have been a simple case of lazy writing, he noted that <b>over-writing</b> played a main role in the series becoming unexpectedly unrealistic. He also noted the senseless intrigues in the Derek/Meredith relationship, by stating that the season would not have achieved high ratings if a functional relationship had been introduced: [...] "The season generally opts to stall out for its vast majority, providing Meredith with some bizarrely under-developed sub-plot about depression and giving Derek a season's worth of reconsidering to do".|$|E
5000|$|The novel's {{narrative}} structure was {{singled out by}} reviewers with similarly divided verdicts. For Manning, the novel's opening, [...] "an excellent device ...to allow the book to start dramatically", and subsequent moments of pace and tension, are ruined by chronic <b>over-writing.</b> Nye felt {{the use of the}} two falls of Hephaestus as a framing device [...] "makes sense of what comes in-between", but for Nye [...] "it is a savage sort of sense, depending to a large extent on melodrama". History Today claimed the choice to retell the myths as a continuous narrative resulted in [...] "a brilliant poetic fantasy"; Hughes said of the novel's series of stories, [...] "their zest sweeps you along. It is a real feat, to make everything sound so first hand." [...] Contemporary Review observed a [...] "slight decline in narrative cohesiveness" [...] {{in the second half of}} the book, after the [...] "fine ... reworking of the earlier myths" [...] but felt it [...] "detracts little from the effectiveness of dramatic and narrative motifs ... which help tie together the disparate myths so well." [...] The Spectator claimed [...] "the narrative is handled with dramatic, and comic, awareness of the epic voyage into our creative origins." ...|$|E
40|$|Computer program {{presents}} {{new model}} solving temperature-distribution problem for laser rods of finite length and calculates both radial and axial components of temperature distributions in these rods. Contains several self-checking schemes to prevent <b>over-writing</b> of memory blocks {{and to provide}} simple tracing of information in case of trouble. Written in Microsoft FORTRAN 77...|$|E
30|$|DEFTL (Jia et al. 2017) {{incorporated}} PDE into FTL. DEFTL {{also has}} two modes, a public and a hidden mode. The deniability of DEFTL {{is achieved by}} using the data (and their behavior) in the public mode to deny the data (and their behavior) in the hidden mode. Most importantly, to prevent the data written in the public mode from <b>over-writing</b> the data written in the hidden mode, DEFTL carefully modifies the block allocation and garbage collection strategies in the FTL such that the two modes can be “stealthily” isolated without being known by the adversary. Specifically, the public volume will allocate flash blocks {{from the head of}} the block pool and the hidden volume will allocate flash blocks from the tail of the pool. In addition, garbage collection in the two modes will be modified as: In the public mode, garbage collection will be performed actively to fill the head of the pool; in the hidden mode, garbage collection will be performed actively to fill the tail of the pool. This can avoid that the public mode has used all the blocks in the head and starts to use the blocks in the tail, <b>over-writing</b> the hidden sensitive data. DEFTL also provides a few attacks on the existing PDE systems for mobile devices.|$|E
30|$|The first type of PDE {{technique}} is steganography (Anderson et al. 1998). The basic idea of steganography is to hide sensitive data within regular file data. For example, the sensitive {{data can be}} computed by performing an XOR operation over a few cover files (Anderson et al. 1998). A main concern of the steganography {{technique is}} to avoid <b>over-writing</b> the hidden sensitive data, since they are actually part of the regular data. This can be mitigated by creating and storing (secretly) multiple copies of the sensitive data, which in return will lead to inefficient use of disk space.|$|E
30|$|To protect {{confidentiality}} {{of the data}} deleted from a computing device, the deleted data should be made completely unrecoverable. Conventionally, this is ensured by carefully <b>over-writing</b> the storage medium storing the data using garbage information (Joukov and Zadok 2005; Wei et al. 2011; Garfinkel and Shelat 2003; Sun et al. 2008; Gutmann 1996) or deploying encryption using ephemeral keys (Perlman 2005 a, b, Geambasu et al. 2009, Tang et al. 2012, Reardon et al. 2012, Zarras et al. 2016). This unfortunately was shown to be insufficient, since past existence of the deleted data will create impacts on both the data organization (Bajaj and Sion 2013 b) and the other data which have not been deleted (Bajaj and Sion 2013 a). Those impacts can then be utilized by the adversary as an oracle to derive sensitive information about the deleted data. In the worst case, the adversary is able to completely recover the data being deleted (Chen et al. 2016). Therefore, recent secure deletion approaches focus on eliminating those impacts (Bajaj and Sion 2013 a, b, Chen and Sion 2015; Chen and Sion 2016; Jia et al. 2016).|$|E
40|$|We {{address the}} problem of secure data {{deletion}} on log-structured file systems. We focus on the YAFFS file sys-tem, widely used on Android smartphones. We show that these systems provide no temporal guarantees on data dele-tion and that deleted data still persists for nearly 44 hours with average phone use and indefinitely if the phone is not used after the deletion. Furthermore, we show that file <b>over-writing</b> and encryption, methods commonly used for secure deletion on block-structured file systems, do not ensure data deletion in log-structured file systems. We propose three mechanisms for secure deletion on log-structured file systems. Purging is a user-level mechanism that guarantees secure deletion at the cost of negligible de-vice wear. Ballooning is a user-level mechanism that runs continuously and gives probabilistic improvements to se-cure deletion. Zero overwriting is a kernel-level mecha-nism that guarantees immediate secure deletion without de-vice wear. We implement these mechanisms on Nexus One smartphones and show that they succeed in secure deletion and neither prohibitively reduce the longevity of the flash memory nor noticeably reduce the device’s battery lifetime. These techniques provide mobile phone users more confi-dence that data they delete from their phones are indeed deleted. 1...|$|E
40|$|Many {{microbes}} {{can acquire}} genetic material from their environment and incorporate {{it into their}} genome, {{a process known as}} lateral genetic transfer (LGT). Computational approaches have been developed to detect genomic regions of lateral origin, but typically lack sensitivity, ability to distinguish donor from recipient, and scalability to very large datasets. To address these issues we have introduced an alignment-free method based on ideas from document analysis, term frequency-inverse document frequency (TF-IDF). Here we examine the performance of TF-IDF on three empirical datasets: 27 genomes of Escherichia coli and Shigella, 110 genomes of enteric bacteria, and 143 genomes across 12 bacterial and three archaeal phyla. We investigate the effect of k-mer size, gap size and delineation of groups on the inference of genomic regions of lateral origin, finding an interplay among these parameters and sequence divergence. Because TF-IDF identifies donor groups and delineates regions of lateral origin within recipient genomes, aggregating these regions by gene enables us to explore, for the first time, the mosaic nature of lateral genes including the multiplicity of biological sources, ancestry of transfer and <b>over-writing</b> by subsequent transfers. We carry out Gene Ontology enrichment tests to investigate which biological processes are potentially affected by LGT...|$|E
40|$|Syntax of MinML ` x : (x) ` n : int ` e 1 : int ` e 2 : int ` e 1 e 2 : int ` true : bool ` false : bool ` e 1 : int ` e 2 : int ` e 1 =e 2 : bool ` e : bool ` e 1 : ` e 2 : ` if e then e 1 else e 2 :; f : 1 ! 2; x: 1 ` e : 2 ` fun f(x: 1) : 2 is e : 1 ! 2 ` e 1 : 2 ! ` e 2 : 2 ` e 1 (e 2) : Figure 2 : Type System of MinML <b>over-writing</b> a program's memory {{without regard}} to its purpose or validity; violating the {{assumptions}} of a procedure by calling it with too few arguments or arguments of the wrong type. A type system is typically defined by an inductive definition of a typing judgement of the form ` e :. Here e is an expression, is its type, and assigns types to the global variables that may occur within e. The typing judgement is defined {{to be the least}} three-place relation closed under a given collection of typing rules that determine whether or not an expression is well-typed. The abstract syntax of an illustrative fragment of the ML [...] ...|$|E
40|$|Syntax of MinML ` x : (x) ` n : int ` e 1 : int ` e 2 : int ` e 1 e 2 : int ` true : bool ` false : bool ` e 1 : int ` e 2 : int ` e 1 =e 2 : bool ` e : bool ` e 1 : ` e 2 : ` if e then e 1 else e 2 :; f : 1 ! 2; x: 1 ` e : 2 ` fun f(x: 1) : 2 is e : 1 ! 2 ` e 1 : 2 ! ` e 2 : 2 ` e 1 (e 2) : Figure 2 : Type System of MinML {{restrictions}} on the formation of programs {{to ensure that a}} large class of errors, those that arise from misinterpretation of values, cannot occur. Examples of such errors are: treating an integer as a pointer to a data structure or a region of executable code; <b>over-writing</b> a program's memory without regard to its purpose or validity; violating the assumptions of a procedure by calling it with too few arguments or arguments of the wrong type. A type system is typically defined by an inductive definition of a typing judgement of the form ` e :. Here e is an expression, is its type, and assigns types to the global variables [...] ...|$|E
40|$|On 29 January 1998, {{the then}} British Prime Minister, Tony Blair, made a {{statement}} to the House of Commons recommending that an inquiry be established to investigate the events of Bloody Sunday, in order to: ‘close this painful chapter once and for all. ’ What Blair did not made entirely clear, however, was what exactly the legal process of the Inquiry would succeed in closing. This article argues that the Saville Inquiry was imagined to be the <b>over-writing</b> of an earlier narrative, in which justice would be established palimpsestically through a re-presentation of past events and a correction of earlier representations. I examine this palimpsestic drive through an analysis of Bloody Sunday: Scenes from the Saville Inquiry, at the Tricycle Theatre in London in 2005. This production was a compressed and heavily edited verbatim account of the Inquiry. The article argues that the production was underscored by anxiety about the law's theatrical ability to produce representations and narratives. Despite this disavowal of the theatrical qualities of the law, I suggest that the citational qualities of the tribunal became visible in this performance, revealing the inability of the law to make final statements, and making visible the law's reliance on rhetoric and spectacle and its need for surrogates and proxies to do its work. I conclude by arguing that representations of Bloody Sunday rely on forms of surrogation and proxy performance that gesture to the ongoing multiplicity of representations that surround this event...|$|E
40|$|The {{categories}} of reader and writer {{have often been}} conceived as binary opposites representing the poles of passivity and production. The idea of this dichotomy between reading and writing has dissolved as {{the recognition of the}} indeterminacy of the text is mirrored by postmodern conceptions of the contingent nature of subjectivity. However, the novel form as we know it emerged during the post-enlightenment age when the subject was conceived as singular and original and the individual life as narrative. The issue of who gets to speak and how that speech is received continues to be a major thematic concern in the novel to the present time. This exegesis examines the locus of narrative authority as played out between representations of the author and reader, and reading and writing, in Foe and The French Lieutenant’s Woman. The same two novels also show how ‘writing starts with reading’ as Cixous says. Reading and writing share an impetus to override the existing text to rewrite what has been unsaid. These two novels explicitly address a shared reading history, through the recuperation and <b>over-writing</b> of canonical texts and their authors, and therefore illuminate the spectre of the actual author and the actual reader haunting the margins of the text. The creative component of the thesis, the manuscript ‘Tex Surfacing’, is a complementary exploration of the notions of narrative truth, narrative authority and the relationship between reading, writing and subjectivity. The characters of ‘Tex Surfacing’ play out the argumentative positions of author versus reader, and reading versus writing in order to establish who gets to tell the story and what, indeed, the story is...|$|E
40|$|A {{moving image}} work based on {{research}} with neurologists and audiologists, collectors and archivists. The film gives voice {{to the idea that}} every surface, in particular parts of our anatomy, is potentially inscribed with an unheard sound or echoes of voices from the past. The soundtrack’s musical composition is interlaced with a voice-over which draws on Rainer Maria Rilke’s text 'Primal Sound', where he reflects on the possibility of playing the coronal suture of a skull with a phonograph needle. The film uses microscopic photography, scanning electron microscopy, and sounds of otoacoustic emissions to uncover haunting aural bonescapes. The voiceovers too are recorded using old sound technology as a filter - writing and <b>over-writing</b> of wax cylinder to create unexpected scratches, glitches, loops and echoes. Exhibitions: shown as multi-channel sound/film installation AV festival (Newcastle 2010); solo exhibition at Wellcome Collection (London 2010 - 11); solo exhibition as part of the International Rotterdam Film Festival (Rotterdam 2013); solo exhibition at John Hansard Gallery (Southampton, Dec 2015 -Jan 2016); group exhibition ‘Samsung Art+ Prize’ BFI Southbank (London 2012); group exhibition ‘Transcendence’, Gertrude Contemporary, (Melbourne 2014); group exhibition ‘The Sight of Sound’, Deutsche Bank VIP Lounge, Frieze Art Fair, (NY 2012). Screenings: mini-retrospective at the Lincoln Centre, as part of the New York Film Festival (NY 2013); Jarman Award Tour screenings (2012, venues included Whitechapel Gallery, London; FACT, Liverpool; CCA, Glasgow; The Northern Charter in partnership with CIRCA projects; Nottingham Contemporary, Nottingham; Watershed, Bristol; Duke of York Cinema, Brighton); Mini-retrospective at Tate Britain (London 2014); Mini-retrospective screening, DIM Cinema, The Cinematheque (Vancouver 2015); Mini-retrospective at Whitechapel Gallery (London 2016); screening at Fridman Gallery (NY, 2016). Publications: ‘Sound Seam’ booklet with contributions by Steven Connor and Tom McCarthy (2010) ...|$|E
40|$|This {{contribution}} {{illustrates the}} results of a research project focused on the creation of an atlas of the ???architectural project for existing buildings???. This inventory aims to present itself as a rational and critical analytical instrument, allowing an overall vision of the various, current philosophical-practical approaches, adopted throughout different geographical areas and concerning projects of rehabilitation and adaptive reuse of historic buildings, through an extensive mapping of case studies, selected from over two hundred projects realised over the last 15 years. This atlas is not, however, merely an instrument of knowledge, but, above all, an opportunity to rethinking of the idea of intervention on the existing building, emphasizing the need to combine the readability and comprehensibility of the building in its historical evidence to the reality and the redefinition of its functional characteristics, with the purpose of an renewed use, with particular attention to his issues of habitable space. For this reason, the Atlas offers a critical reading of the innovative projects that reveal the presence of arrays of recurrent conceptual attitudes identified as "design actions". These actions put highlights in convergent and founding mode, as well as complementary attitudes, sometimes even antithetical, present in the process of the social, cultural and economic buildings revitalizing. These actions are: - ???approach???, an act that implies an awareness of the relation between the original body of the building and its new complementary and/or defining elements; - ???addition??? that reveals a reciprocal need for physical contact that, albeit abolishing the principle of independence, preserves the explicit reading of the added elements, describing the building as a whole generated by the co-presence of original and new portions; - ???insertion??? that is the one most intrinsically connected to internal design, because everything is realised inside the volume of the pre-existing architecture, according to the principle of inclusion. - ???superimposition??? that represents the most intense moment of comparison between the characteristics of the pre-existing building and its reconfiguration through a design voluntarily oriented towards an act of <b>over-writing...</b>|$|E
40|$|Exhibition: Fade: Site {{responsive}} Installation - {{including the}} venues light, and architectural dynamics in {{the configuration of}} the drawings. Performance-these works perform their own demise throughout the duration of the show. I am proposing to exhibit a suite drawings from my current research. How can visual perception and understandings of time be manifest in contemporary art? Velocity and traceable detection of alterations in visual phenomena are investigated through evanescent drawings and their digital translations. Perceptual transience - perception of a transaction, perception as transaction. Perception at the point of contact. How does anything become visible or invisible as an image? What are we seeing? What do we think we are seeing? Do we only see what we think we see? The work I am proposing for time. transcendence. performance is a suite of evanescent drawings, made from gathered light in my studio and including the gathering light from the time. transcendence. performance exhibition. A range of antique black and white photographic paper, with their different colours and rates of change, will directly respond to the light in the exhibition venue. To see these images is to be implicated in their disappearance. The change is simple to see in comparison to an earlier version, however, without this relative comparison, the perception of this visual shift in time is very difficult to detect. Can the movement of these changing drawings actually be perceived in time? You can't just look at Benson's evanescent drawings, you have to watch them, like you would a movie, like you would the sky on a day (or night) when time and light are so immense and immersive and intense that the need to hold onto anything just vaporises. Cassandra Barnett (ATMOS Catalogue) The instability of these image invites a viewer to come into the now, a now, and to perceive the ever present phenomenological shift and change that we are knowingly or unknowingly involved in. It is this same light that enables the viewer to see these drawings, that alters and changes these works, a subtle <b>over-writing,</b> leading to the eventual disappearance of any previously visible image or mark. The same light that allows us to see this work is irreversibly altering it. The drawings that are being proposed for time. transcendence. performance will subsume the very light from the symposium, adding the specific light from the duration of the exhibition in October into the list of materials in the work. These works are in a living present, unfixed and still gathering light, and therefore slowly, quietly expiring before our very eyes. Thus in a sense, to see it, we must miss it. If sensitive to such things we may find ourselves moved, for the work is subtly lifelike “ moving, changing, dying, eluding our grasp. Whatever we see is instantly gone forever, we have no time to get acquainted with the work in its current form, our thought can't keep up with what we are seeing. One way or another, Benson's work has the capacity to throw us out of time, to throw us out of step with ourselves. Cassandra Barnet...|$|E
40|$|The Earth’s {{atmosphere}} {{consists of}} both gaseous and condensed-phase components, the condensed-phase material is called particulate matter (PM). The effects of atmospheric PM include adverse health impacts, {{as well as}} climate forcing. Both qualitative and quantitative knowledge about PM is necessary to assess these effects, and to devise best mitigation strategies. Understanding the distribution of atmospheric particulate matter is complex because {{much of it is}} of secondary origin rather than from primary emissions. Furthermore, there are multiple anthropogenic and natural sources of the contributing precursors, and all these processes are influenced by atmospheric conditions and transport. In this work, one of the major constituents of atmospheric PM - carbonaceous aerosol - is studied. A regional application of the EMEP MSC-W atmospheric chemical transport model - EMEP 4 UK - was used to model air pollution over the British Isles with a horizontal resolution of 5 km x 5 km. One-way nesting was used from the European computational domain of 50 km x 50 km to the finer spatial grid of EMEP 4 UK. Several model experiments were devised in order to investigate the well-known deficiency that models currently underestimate organic aerosol (OA) concentrations compared with observations. The model experiments were evaluated with comprehensive year-long novel measurements from the Clear Air for London (ClearfLo) campaign in 2012. Several sources of organic aerosol that are either missing, greatly underestimated, or may be spatially misplaced in official emissions inventories were re-evaluated. Firstly, missing diesel-related intermediate volatility organic compound (IVOC) emissions from diesel vehicles derived directly from field measurements at the urban background site during the 2012 ClearfLo campaign were added into the model. According to the model simulations, these diesel-IVOCs can explain on average ~ 30 % of the annual secondary organic aerosol (SOA) in and around London. Furthermore, the 90 - th percentile of modelled daily SOA concentrations for the whole year was 3. 8 μgm- 3, constituting a notable addition to total particulate matter. More measurements of these precursors (currently not included in official emissions inventories) is recommended. Secondly, spatially and temporally resolved emissions of cooking OA (COA; emissions from meat charbroiling, or frying and deep-frying) were developed. These emissions are currently neglected in European emissions inventories, yet measurements point to significant COA contribution to ambient PM concentrations (up to 2. 0 μgm- 3 on annual average for central London). The final COA emission source strength derived here (320 mg person- 1 day- 1) was spatially distributed to workday population density (as opposed to residential population density). The impact of COA on surface concentrations is spatially very limited, however, as the modelled concentrations dropped markedly outside of urban areas. For example, annual average modelled concentration for the Harwell location was just 0. 1 μgm- 3. Thirdly, redistributing 50 % of non-industrial wood and coal burning emissions to residential population density (thus <b>over-writing,</b> in part, the assumption made by the national emissions inventory that only smokeless fuels are burned in smoke control areas) increased the modelled solid fuel OA (SFOA) concentration at the London North Kensington site to 0. 8 μgm- 3, from the Base run value (using the emissions’ spatial distribution and total as officially reported) of just 0. 3 μgm- 3. For comparison, the measured annual mean concentration of SFOA at this site was 1. 0 μgm- 3. Based on the model evaluation presented, redistribution of SFOA emissions into smoke control areas is justified, but further refinement of the amount, as well as the temporal emission profile of this component is necessary. The total effect of the three refinements undertaken in this work increased the model estimate of the annual mean OA concentration at the London North Kensington site from 1. 8 μgm- 3 to 3. 8 μgm- 3, which is much closer to the observed value of 4. 2 μgm- 3. Thus, this work has provided relevant insight into the nature and magnitude of missing, under-represented, and spatially inappropriately-distributed emissions of primary OA and OA precursors. Although the study area was focused on pollutant concentrations over the British Isles, all of the components examined here are of great relevance to the air quality in other countries as well — in Europe and globally. Therefore, the inclusion of these improvements into other air quality models and official emissions’ inventories is advised...|$|E

