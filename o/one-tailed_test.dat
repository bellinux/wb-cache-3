75|93|Public
25|$|This {{probability}} is the p-value, considering only extreme {{results that}} favor heads. This {{is called a}} <b>one-tailed</b> <b>test.</b> However, the deviation can be in either direction, favoring either heads or tails. The two-tailed p-value, which considers deviations favoring either heads or tails, may instead be calculated. As the binomial distribution is symmetrical for a fair coin, the two-sided p-value is simply twice the above calculated single-sided p-value: the two-sided p-value is 0.115.|$|E
25|$|A simple {{generalization}} of the example considers {{a mixed bag}} of beans and a handful that contain either very few or very many white beans. The generalization considers both extremes. It requires more calculations and more comparisons {{to arrive at a}} formal answer, but the core philosophy is unchanged; If the composition of the handful is greatly {{different from that of the}} bag, then the sample probably originated from another bag. The original example is termed a one-sided or a <b>one-tailed</b> <b>test</b> while the generalization is termed a two-sided or two-tailed test.|$|E
25|$|Thus {{computing}} a p-value {{requires a}} null hypothesis, a test statistic (together with deciding whether the researcher is performing a <b>one-tailed</b> <b>test</b> or a two-tailed test), and data. Even though computing the test statistic on given data may be easy, computing the sampling distribution under the null hypothesis, and then computing its {{cumulative distribution function}} (CDF) is often a difficult problem. Today, this computation is done using statistical software, often via numeric methods (rather than exact formulae), {{but in the early}} and mid 20th century, this was instead done via tables of values, and one interpolated or extrapolated p-values from these discrete values. Rather than using a table of p-values, Fisher instead inverted the CDF, publishing a list of values of the test statistic for given fixed p-values; this corresponds to computing the quantile function (inverse CDF).|$|E
50|$|Pure {{arguments}} {{over the use}} of <b>one-tailed</b> <b>tests</b> are complicated by the variety of tests. Some tests (for instance the χ2 goodness of fit <b>test)</b> are inherently <b>one-tailed.</b> Some probability distributions are asymmetric. The traditional tests of 3 or more groups are two-tailed.|$|R
30|$|We {{assessed}} {{the significance of}} each trait metric using a plot-wide Wilcoxon signed rank test with a null hypothesis that {{the average of the}} observed values of each trait metric was equal to the average of the null expectation (following Cornwell and Ackerly 2009; Kraft and Ackerly 2010). In all analyses, we used <b>one-tailed</b> <b>tests</b> based on a priori predictions of habitat filtering and niche differentiation.|$|R
5000|$|A <b>one-tailed</b> paired-difference <b>test</b> {{showed that}} the {{increase}} in salary was statistically significant at the 95% level ...|$|R
2500|$|In {{statistical}} significance testing, a <b>one-tailed</b> <b>test</b> and a two-tailed test are {{alternative ways of}} computing the {{statistical significance}} of a parameter inferred from a data set, {{in terms of a}} test statistic. A two-tailed test is appropriate if the estimated value may be more than or less than the reference value, for example, whether a test taker may score above or below the historical average.|$|E
2500|$|Suppose a {{researcher}} flips a coin {{five times in}} a row and assumes a null hypothesis that the coin is fair. The test statistic of [...] "total number of heads" [...] can be one-tailed or two-tailed: a <b>one-tailed</b> <b>test</b> corresponds to seeing if the coin is biased towards heads, but a two-tailed test corresponds to seeing if the coin is biased either way. The researcher flips the coin five times and observes heads each time (HHHHH), yielding a test statistic of 5. In a <b>one-tailed</b> <b>test,</b> this is the upper extreme of all possible outcomes, and yields a p-value of (1/2)5 = 1/32 ≈ 0.03. If the researcher assumed a significance level of 0.05, this result would be deemed significant and the hypothesis that the coin is fair would be rejected. In a two-tailed test, a test statistic of zero heads (TTTTT) is just as extreme and thus the data of HHHHH would yield a p-value of 2×(1/2)5 = 1/16 ≈ 0.06, which is not significant at the 0.05 level.|$|E
2500|$|For example, if {{flipping}} a coin, testing {{whether it}} is biased towards heads is a <b>one-tailed</b> <b>test,</b> and getting data of [...] "all heads" [...] {{would be seen as}} highly significant, while getting data of [...] "all tails" [...] would be not significant at all (p=1). By contrast, testing {{whether it is}} biased in either direction is a two-tailed test, and either [...] "all heads" [...] or [...] "all tails" [...] would both be seen as highly significant data. In medical testing, while one is generally interested in whether a treatment results in outcomes that are better than chance, thus suggesting a one-tailed test; a worse outcome is also interesting for the scientific field, therefore one should use a two-tailed test that corresponds instead to testing whether the treatment results in outcomes that are different from chance, either better or worse. In the archetypal lady tasting tea experiment, Fisher tested whether the lady in question was better than chance at distinguishing two types of tea preparation, not whether her ability was different from chance, and thus he used a <b>one-tailed</b> <b>test.</b>|$|E
25|$|<b>One-tailed</b> <b>tests</b> {{are used}} for {{asymmetric}} distributions that have a single tail, such as the chi-squared distribution, which are common in measuring goodness-of-fit, or for {{one side of a}} distribution that has two tails, such as the normal distribution, which is common in estimating location; this corresponds to specifying a direction. Two-tailed tests are only applicable when there are two tails, such as in the normal distribution, and correspond to considering either direction significant.|$|R
40|$|The {{ability to}} conduct {{hypothesis}} tests {{is among the}} most important statistical skills that our students can learn. Unfortunately, {{it is also one of}} the most difficult skills for them to learn. In our survey of 44 introductory business and economics statistics textbooks, we find that textbook authors differ over the better way to explain <b>one-tailed</b> hypothesis <b>tests.</b> Approximately half of these books use the simple null hypothesis approach, while the remaining textbooks use the composite null hypothesis approach. In this article, we show that the majority of textbooks that use the composite null hypothesis approach contain methodological shortcomings that potentially, at least, make it more difficult for students to learn how to use hypothesis tests for business decisions. Keywords: <b>One-tailed</b> hypothesis <b>tests.</b> JEL codes: A 22 and C 12. XX 0 H 0 : X 9 X 0 H a : XX 0 1 A CRITIQUE OF <b>ONE-TAILED</b> HYPOTHESIS <b>TEST</b> PROCEDURES IN BUSINESS AND ECONOMICS STAT [...] ...|$|R
5000|$|Advice {{concerning}} {{the use of}} one-tailed hypotheses has been inconsistent and accepted practice varies among fields. [...] The greatest objection to one-tailed hypotheses is their potential subjectivity. A non-significant result can sometimes be converted to a significant result {{by the use of}} a one-tailed hypothesis (as the fair coin test, at the whim of the analyst). The flip side of the argument: One-sided tests are less likely to ignore a real effect. <b>One-tailed</b> <b>tests</b> can suppress the publication of data that differs in sign from predictions. Objectivity was a goal of the developers of statistical tests.|$|R
2500|$|A <b>one-tailed</b> <b>test</b> is {{appropriate}} if the estimated value may {{depart from the}} reference value in only one direction, for example, whether a machine produces more than one-percent defective products. [...] Alternative names are one-sided and two-sided tests; the terminology [...] "tail" [...] is used because the extreme portions of distributions, where observations lead to rejection of the null hypothesis, are small and often [...] "tail off" [...] toward zero as in the normal distribution or [...] "bell curve", pictured on the right.|$|E
2500|$|In coin flipping, {{the null}} {{hypothesis}} is a sequence of Bernoulli trials with probability 0.5, yielding a random variable X which is 1 for heads and 0 for tails, and a common test statistic is the sample mean (of the number of heads) [...] If testing for whether the coin is biased towards heads, a <b>one-tailed</b> <b>test</b> would be used – only large numbers of heads would be significant. In that case a data set of five heads (HHHHH), with sample mean of 1, has a [...] chance of occurring, (5 consecutive flips with 2 outcomes - ((1/2)^5 =1/32), and thus would have [...] and would be significant (rejecting {{the null hypothesis}}) if using 0.05 as the cutoff. However, if testing for whether the coin is biased towards heads or tails, a two-tailed test would be used, and a data set of five heads (sample mean 1) is as extreme as a data set of five tails (sample mean 0), so the p-value would be [...] and {{this would not be}} significant (not rejecting the null hypothesis) if using 0.05 as the cutoff.|$|E
2500|$|In the {{approach}} of Ronald Fisher, the null hypothesis H0 will be rejected when the p-value of the test statistic is sufficiently extreme (vis-a-vis the test statistic's sampling distribution) and thus judged unlikely {{to be the result}} of chance. In a <b>one-tailed</b> <b>test,</b> [...] "extreme" [...] is decided beforehand as either meaning [...] "sufficiently small" [...] or meaning [...] "sufficiently large" [...] – values in the other direction are considered not significant. In a two-tailed test, [...] "extreme" [...] means [...] "either sufficiently small or sufficiently large", and values in either direction are considered significant. For a given test statistic there is a single two-tailed test, and two one-tailed tests, one each for either direction. Given data of a given significance level in a two-tailed test for a test statistic, in the corresponding one-tailed tests for the same test statistic it will be considered either twice as significant (half the p-value), if the data is in the direction specified by the test, or not significant at all (p-value above 0.05), if the data is in the direction opposite that specified by the test.|$|E
3000|$|Test 2 {{requires}} {{the conduct of}} two <b>one-tailed</b> z <b>tests.</b> In order for a researcher {{to conclude that the}} two populations are equivalent, (1) both z tests must be statistically significant, and (2) the two z [...]...|$|R
30|$|Chronological ages {{were not}} {{statistically}} different across groups. Group differences in the teachers’ ratings for both academic and behavioral performance across groups, were noted. The academic performance {{of students in the}} At-risk Group was significantly lower than that of the Typical Group (U[*]=[*] 297, p[*]=[*] 0.03; the p-value showed the results of <b>one-tailed</b> <b>tests).</b> With regard to behavioral problems, the Typical Group score significantly lower than the At-risk group (U[*]=[*] 118, p[*]=[*] 0.04), while the score of the At-risk Group was also significantly lower than the Diagnostic Group (U[*]=[*] 32.5, p[*]=[*] 0.05). Results suggest that children who have been diagnosed or are at risk of cognitive disorders exhibit more problematic behavior in the classroom than children with no cognitive delay.|$|R
40|$|AbstractThis paper {{demonstrates}} {{that there is}} currently a widespread misuse of two-tailed testing for directional research hypotheses tests. One probable reason for this overuse of two-tailed testing is the seemingly valid beliefs that two-tailed testing is more conservative and safer than <b>one-tailed</b> <b>testing.</b> However, the authors examine the legitimacy of this notion and find it to be flawed. A second and more fundamental cause of the current problem is the pervasive oversight in making {{a clear distinction between}} the research hypothesis and the statistical hypothesis. Based upon the explicated, sound relationship between the research and statistical hypotheses, the authors propose a new scheme of hypothesis classification to facilitate and clarify the proper use of statistical hypothesis testing in empirical research...|$|R
50|$|The {{use of a}} <b>one-tailed</b> <b>test</b> is {{dependent}} on whether the research question or alternative hypothesis specifies a direction such as whether a group of objects is heavier or the performance of students on an assessment is better. A two-tailed test may still be used {{but it will be}} less powerful than a <b>one-tailed</b> <b>test</b> because the rejection region for a <b>one-tailed</b> <b>test</b> is concentrated {{on one end of the}} null distribution and is twice the size (5% vs. 2.5%) of each rejection region for a two-tailed test. As a result, the null hypothesis can be rejected with a less extreme result if a <b>one-tailed</b> <b>test</b> was used. The <b>one-tailed</b> <b>test</b> is only more powerful than a two-tailed test if the specified direction of the alternative hypothesis is correct. If it is wrong, however, then the <b>one-tailed</b> <b>test</b> has no power.|$|E
5000|$|... binom.test(51,235,(1/6),alternative="greater") (<b>one-tailed</b> <b>test)</b> ...|$|E
5000|$|... binom.test(51,235,(1/6),alternative="less") (<b>one-tailed</b> <b>test)</b> ...|$|E
30|$|To {{assess the}} {{relationship}} between cytokine levels and cognitive impairment during chemotherapy, serum levels of sTNFRII, IL- 6, VEGF, IL- 10, BDNF and MCP- 1 were measured. Significance was assessed using a <b>one-tailed</b> Mann–Whitney <b>test</b> using GraphPad Prism version 5 (GraphPad Software, La Jolla California USA).|$|R
30|$|Scores on the NEO-FFI, PVQ, SHS, and PIL were {{calculated}} {{according to the}} instructions in their manuals or the methods employed in previous studies. Independent t tests were conducted to compare the scientist and non-scientist groups, and to compare the scientist group against the normative data. For the measures of interest described in the “Background” section, <b>one-tailed</b> <b>tests</b> were conducted. For measures for which no a priori predictions were made, two-tailed tests were conducted with Bonferroni corrections applied (the alpha level was divided by four for the NEO-FFI and by nine for the PVQ). To explore the relationships between scores, Pearson’s product–moment correlations {{were calculated}} for the scores, which were consistently associated with the scientist group in the above analyses. The results of all tests were considered statistically significant at a value of p <  0.05.|$|R
30|$|Statistically {{significant}} differences between samples were analyzed with an unpaired, <b>one-tailed</b> Student’s t <b>test.</b> The data are shown as the mean ± standard deviation (SD).|$|R
5000|$|... scipy.stats.binom_test(51, 235, 1.0/6, alternative='greater') (<b>one-tailed</b> <b>test)</b> ...|$|E
5000|$|... #Caption: A <b>one-tailed</b> <b>test,</b> {{showing the}} p-value as {{the size of}} one tail.|$|E
50|$|In this case, the {{probability}} of getting 51 or more 6s on a fair die is 0.027. If {{we were looking for}} significance at the 5% level, this result indicates that the die is loaded to give many 6s (<b>one-tailed</b> <b>test).</b>|$|E
30|$|As a {{total of}} 17 {{correlations}} were calculated, the alpha-level for statistical significance was Bonferroni-adjusted and set to α = . 003. As evidence points to stable neurocognitive deficits in bipolar patients, we hypothesized that eBPs would perform worse than HCs on our measures of neurocognition. <b>One-tailed</b> t <b>tests</b> were performed to test these hypotheses.|$|R
30|$|Comparisons of {{two groups}} {{involved}} two-tailed unpaired Student’s t-test, log-rank {{test was used}} for Kaplan-Meier survival analysis, Pearson’s product-moment correlation test was used for gene correlation analysis, and <b>one-tailed</b> Mann-Whitney <b>test</b> was used for wound healing test. The level of significance was set at *P < 0.05, **P < 0.01, ***P < 0.001.|$|R
40|$|The {{choice of}} a one- rather than a tiυo-tailed {{hypothesis}} testing strategy can influence research outcomes, but information about the type of test conducted is rarely reported in articles appearing in educational and psychological journals. Because unambiguous standards for using one- and two-tailed tests do not exist, complete reporting of hypothesis testing procedures is essential. In addition, educational researchers need to reevaluate the decision-oriented, 2 ̆ 2 critical experiment 2 ̆ 2 model of science that underlies the use of onetailed tests. It is the adherence to the arbitrary. 05 level of significance as a benchmark for publication decisions, rather than logical or methodological considerations, that largely accounts for the popularity of <b>one-tailed</b> <b>tests.</b> Effect size estimates, accompanied by confidence intervals or exact hυo-tailed probabilities, are generally more compatible with the growing meta-analytic view of social science as an incremental, cumulative, and shared enterprise...|$|R
5000|$|In MATLAB, use myBinomTest, {{which is}} {{available}} via Mathworks' community File Exchange website. myBinomTest will directly calculate the p-value for the observations given the hypothesized probability of a success. pout=myBinomTest(51, 235, 1/6) (generally two-tailed, but can optionally perform a <b>one-tailed</b> <b>test).</b>|$|E
5000|$|Fisher's {{original}} (Lady tasting tea) {{example was}} a <b>one-tailed</b> <b>test.</b> The null hypothesis was asymmetric. The odds of guessing all cups correctly {{was the same}} as guessing all cups incorrectly, but Fisher noted that only guessing correctly was compatible with the Lady's claim. (See the quotations below about his reasoning.) ...|$|E
5000|$|In {{statistical}} significance testing, a <b>one-tailed</b> <b>test</b> and a two-tailed test are {{alternative ways of}} computing the {{statistical significance}} of a parameter inferred from a data set, {{in terms of a}} test statistic. A two-tailed test is appropriate if the estimated value may be more than or less than the reference value, for example, whether a test taker may score above or below the historical average. A <b>one-tailed</b> <b>test</b> is appropriate if the estimated value may depart from the reference value in only one direction, for example, whether a machine produces more than one-percent defective products. Alternative names are one-sided and two-sided tests; the terminology [...] "tail" [...] is used because the extreme portions of distributions, where observations lead to rejection of the null hypothesis, are small and often [...] "tail off" [...] toward zero as in the normal distribution or [...] "bell curve", pictured on the right.|$|E
40|$|Independent {{measures}} of age of acquisition (AoA), name agreement, and rated object familiarity {{were obtained from}} groups of British subjects for all items in the Snodgrass and Vanderwart (1980) picture set with single names. Word frequency measures, both written and spoken, {{were taken from the}} Celex database (Centre for Lexical Information, 1993). The line drawings were presented to a separate group of participants in an object naming task, and vocal naming latencies were recorded. A subset of 195 items was selected for analysis after excluding items with, for example, low name agreement. The major determinants of picture naming speed were the frequency of the name, the interaction between AoA and frequency, and name agreement. (The main effect of the AoA of the name and the effect of the rated image agreement of the picture were also significant on <b>one-tailed</b> <b>tests.)</b> Spoken name frequency affects object naming times mainly for items with later-acquired names...|$|R
30|$|The {{mortality}} {{data for}} screening and dose-mortality response tests {{were subjected to}} analysis of variance (ANOVA) and subsequently to Dunnett’s <b>one-tailed</b> t <b>test</b> to compare test isolates against the controls with respect to mortality and mycoses. To determine the difference among isolates, the data were subjected to ANOVA and subsequently to LSD multiple comparison test. All analyses were performed by using SPSS 20.0 statistical software.|$|R
40|$|Radiofrequency {{catheter}} ablation (RFA) {{has become}} a mainstay for treatment of cardiac arrhythmias. Skin burns {{at the site of}} an indifferent electrode patch have been a rare, serious, and likely an underreported complication of RFA. The {{purpose of this study was}} to determine the incidence of skin burns in cardiac RFA procedures performed at one institution. Also, we wanted to determine the factors predicting skin burns after cardiac RFA procedures at the indifferent electrode skin pad site. Methods. A retrospective case control study was performed to compare the characteristics in patients who developed skin burns in a 2 -year period. Results. Incidence of significant skin burns after RFA was 0. 28 % (6 / 2167). Four of the six patients were female and all were Caucasians. Four controls for every case were age and sex matched. Burn patients had significantly higher BMI, procedure time, and postprocedure pain, relative to control subjects (p < 0. 05, <b>one-tailed</b> <b>testing).</b> No one in either group had evidence of dispersive pad malattachment. Conclusions. Our results indicate that burn patients had higher BMI and longer procedure times compared to control subjects. These findings warrant further larger studies on this topic...|$|R
