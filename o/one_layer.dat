2562|3866|Public
5|$|Generally sharks {{have only}} <b>one</b> <b>layer</b> of tesserae, but {{the jaws of}} large specimens, such as the bull shark, tiger shark, and the great white shark, have two to three layers or more, {{depending}} on body size. The jaws of a large great white shark may have up to five layers. In the rostrum (snout), the cartilage can be spongy and flexible to absorb the power of impacts.|$|E
5|$|Squab pie is a mutton {{pie with}} a shortcrust pastry lid. It {{should be made}} with at least <b>one</b> <b>layer</b> of onions, {{followed}} by alternating layers of sliced apples and mutton chops. The mixture should be covered with water, though less than in some pies, covered with pastry and baked {{in the oven for}} about two hours.|$|E
5|$|The {{shedding}} {{of scales}} is called ecdysis, or, in normal usage moulting or sloughing. In {{the case of}} snakes, the complete outer layer of skin is shed in <b>one</b> <b>layer.</b> Snake scales are not discrete but extensions of the epidermis hence they are not shed separately, but are ejected as a complete contiguous outer layer of skin during each moult, akin to a sock being turned inside out.|$|E
40|$|Light device {{comprising}} a substrate, {{at least}} <b>one</b> photo-organic <b>layer,</b> {{at least two}} electrode layers electrically separated by said at least <b>one</b> photo-organic <b>layer,</b> and at least <b>one</b> encapsulation <b>layer,</b> {{wherein said at least}} <b>one</b> photo-organic <b>layer</b> is positioned between said substrate and said at least <b>one</b> encapsulating <b>layer,</b> and wherein multiple openings are provided that extend through the light device to allow fluids and or heat to pass through, said openings being spaced apart from said at least <b>one</b> photo-organic <b>layer...</b>|$|R
5000|$|It {{consists}} of <b>one</b> input <b>layer,</b> <b>one</b> hidden <b>layer</b> and <b>one</b> output <b>layer.</b> The number of neurons in the output layer {{depends on the}} number of hidden units K. Each hidden neuron has N binary input neurons: The weights between input and hidden neurons are also binary: ...|$|R
30|$|A two-layer MLP network (including <b>one</b> input <b>layer,</b> <b>one</b> hidden <b>layer</b> and <b>one</b> output <b>layer)</b> {{with the}} optimum number of hidden neurons {{is capable of}} {{modeling}} the complex nonlinear functions (Haykin 1999). Therefore, two-layer MLP networks are proposed for estimating some of the well-testing model parameters in this research.|$|R
5|$|An air-cuticle {{multilayer}} in {{the scales}} creates optical interference. Each scale contains cuticle layers with randomly located blocks of cuticle that {{hold them in}} place and maintain an air gap between them. The layers and air gaps are narrower than the wavelength of visible light. The structure varies from <b>one</b> <b>layer</b> at the proximal end of each scale, to about six layers at the distal end. This multilayer structure strongly reflects certain wavelengths of light, which {{are determined by the}} thicknesses of the layers and the angle at which the light hits the scale.|$|E
5|$|The {{sandwich}} {{has a high}} {{sodium and}} fat content, and has been specifically targeted by UK caf√© chains {{in an effort to}} reduce salt and fat. Due to this, low-fat mayonnaise is a common substitute along with low salt bread and less fatty bacon. In 2009, seven large cafe chains in the UK made a commitment to reducing salt and fat through similar substitutions. A more visible solution is to use turkey bacon in lieu of normal bacon. One of the variations on the BLT is the club sandwich, a two-layered sandwich in which <b>one</b> <b>layer</b> is a BLT. The other layer can be almost any sort of sliced meat, normally chicken or turkey.|$|E
5|$|Early writers {{combined}} ctenophores with cnidarians into {{a single}} phylum called Coelenterata on account of morphological similarities between the two groups. Like cnidarians, the bodies of ctenophores consist of a mass of jelly, with <b>one</b> <b>layer</b> of cells {{on the outside and}} another lining the internal cavity. In ctenophores, however, these layers are two cells deep, while those in cnidarians are only a single cell deep. Ctenophores also resemble cnidarians in relying on water flow through the body cavity for both digestion and respiration, as well as in having a decentralized nerve net rather than a brain. However, genomic studies have suggested that the neurons of Ctenophora, which differ in many ways from other animal neurons, evolved independently from those of the other animals, and increasing awareness {{of the differences between the}} groups has persuaded more recent authors to classify the two as separate phyla. The position of the ctenophores in the evolutionary family tree of animals has long been debated, and the majority view at present, based on molecular phylogenetics, is that cnidarians and bilaterians are more closely related to each other than either is to ctenophores.|$|E
5000|$|Tempur Seni (rangkai berlapis or {{the art of}} silat arts {{network with}} more than <b>one</b> <b>layers)</b> ...|$|R
30|$|It {{is based}} on {{gradient}} descent method. It calculates gradient of error function with respect to all weights in the neural networks {{which is used to}} update the weights in an attempt to minimize the error function. The following algorithm is used for a three-layer network (<b>one</b> input <b>layer,</b> <b>one</b> hidden <b>layer,</b> and <b>one</b> output <b>layer).</b> Number of neurons in the hidden layer is 50.|$|R
5000|$|Changed for Good: A Feminist History of the Broadway Musical explains: [...] "Sheila, Bebe, and Maggie {{sing the}} same wistful melody; then their harmonies grow and build, <b>one</b> <b>layering</b> on the other".|$|R
5|$|The {{chiral nematic}} phase {{exhibits}} chirality (handedness). This phase {{is often called}} the cholesteric phase because it was first observed for cholesterol derivatives. Only chiral molecules (i.e., those that have no internal planes of symmetry) can give rise to such a phase. This phase exhibits a twisting of the molecules perpendicular to the director, with the molecular axis parallel to the director. The finite twist angle between adjacent molecules is due to their asymmetric packing, which results in longer-range chiral order. In the smectic C* phase (an asterisk denotes a chiral phase), the molecules have positional ordering in a layered structure (as in the other smectic phases), with the molecules tilted by a finite angle {{with respect to the}} layer normal. The chirality induces a finite azimuthal twist from <b>one</b> <b>layer</b> to the next, producing a spiral twisting of the molecular axis along the layer normal.|$|E
5|$|The patagium is {{the wing}} membrane. The patagium is {{stretched}} between {{the arm and}} hand bones, down the lateral {{side of the body}} and down to the hind limbs. This skin membrane consists of connective tissue, elastic fibers, nerves, muscles, and blood vessels. The muscles keep the membrane taut during flight. The skin on the body of the bat, which has <b>one</b> <b>layer</b> of epidermis and dermis, as well as the presence of hair follicles, sweat glands and a fatty subcutaneous layer, {{is very different from the}} skin of the wing membrane. The patagium is an extremely thin double layer of epidermis; these layers are separated by a connective tissue center, rich with collagen and elastic fibers. The membrane has no hair follicles or sweat glands, except between the fingers. Unlike birds whose stiff wings deliver bending and torsional stress to the shoulders, bats have a flexible wing membrane which can only resist tension. To achieve flight, a bat exerts force inwards at the points where the membrane meets the skeleton, so that an opposing force balances it on the wing edges perpendicular to the wing surface. However, this adaptation does not permit bats to reduce their wingspan as birds do, which means they cannot travel over long distances like birds can.|$|E
25|$|Most {{beginner}} solution methods involve {{solving the}} cube <b>one</b> <b>layer</b> at a time, using algorithms that preserve what {{has already been}} solved. The easiest layer by layer methods require only 3-8 algorithms.|$|E
30|$|A SAE [35] {{consists}} of multiple auto-encoders {{in which the}} code of each auto-encoder is the input of the successive auto-encoder. A SAE contains <b>one</b> input <b>layer</b> at the bottom, more than <b>one</b> hidden <b>layer</b> in the middle, and <b>one</b> output <b>layer</b> at the top. We can get a representation or feature of the input data from every layer; the higher the layer is, the more abstract the feature is.|$|R
30|$|The {{architecture}} of the BP strength prediction model was designed using Cybenko theorem (Cybenko 1989). Using the network design procedure reported by Mwasiagi et al. (2012), the final BP network had 14 inputs, <b>one</b> input <b>layer,</b> <b>one</b> hidden <b>layer</b> and <b>one</b> output (yarn strength). The ELM and DE-ELM were designed according to the reports of Huang et al. (2006 a) and Zhu et al. (2005) respectively.|$|R
40|$|Method for {{producing}} a crosslinkable elastomeric composition comprising: (a) {{at least one}} first elastomeric polymer; (b) at least <b>one</b> <b>layered</b> material having an individual layer thickness of from 0. 01 nm to 30 nm, preferably of from 0. 05 nm to 15 nm; (c) at least one vulcanizing agent; said method comprising the following steps: (i) feeding said at least <b>one</b> <b>layered</b> material (b) {{and at least one}} second elastomeric polymer (d), into at least one extruder comprising a housing, at least one screw rotatably mounted in said housing including at least one feed opening and a discharge opening, said at least <b>one</b> <b>layered</b> material being fed into said at least one extruder in an amount higher than or equal to 70 phr, preferably higher than or equal to 100 phr, more preferably of from 150 phr to 400 phr, still more preferably of from 200 phr to 300 phr; (ii) mixing and softening said mixture so as to obtain a masterbatch; (iii) discharging the obtained masterbatch through a discharge opening; (iv) mixing the obtained masterbatch with said at least one first elastomeric polymer (a) and said at least one vulcanizing agent (c), to obtain the crosslinkable elastomeric composition, said mixing being carried out in a batchwise manner...|$|R
25|$|Easy {{access to}} fresh water {{also would have}} been mandatory, which is another reason why {{settlements}} were in bottom lands near water. A number of wells from the times have been discovered, with a log-cabin type lining constructed <b>one</b> <b>layer</b> at a time as the previous layers sank into the well.|$|E
25|$|Snails need hiding places, {{especially}} during the warm daytime. Plastic soil drainage pipes from the local garden center can be split in two lengthwise, and stacked <b>one</b> <b>layer</b> one way and the next layer at a right angle, providing shelter and also increasing by 50% the number of snails that can live in the pen.|$|E
25|$|The {{shedding}} {{of scales}} is called ecdysis (or in normal usage, molting or sloughing). In {{the case of}} snakes, the complete outer layer of skin is shed in <b>one</b> <b>layer.</b> Snake scales are not discrete, but extensions of the epidermis‚Äîhence they are not shed separately but as a complete outer layer during each molt, akin to a sock being turned inside out.|$|E
40|$|AbstractR 3 B is a {{fixed target}} {{experiment}} which will study reactions with relativistic radioactive beams at FAIR. Its Si-tracker will surround the target volume {{and it will}} detect light charged-particles like protons. The detector technology in use consists of double-sided silicon strip sensors wire bonded to the custom made R 3 B-ASIC. The tracker allows for a maximum of two outer <b>layers</b> and <b>one</b> inner <b>layer.</b> This paper reports on the production of detectors necessary to build the minimum tracking configuration: <b>one</b> inner <b>layer</b> and <b>one</b> outer <b>layer...</b>|$|R
50|$|Two {{different}} Layer Jump {{methods are}} defined: Manual Layer Jump and Regular Layer Jump. The first require {{the software to}} specify to the hardware each jump point from layer zero to <b>layer</b> <b>one</b> (the jump from <b>layer</b> <b>one</b> to <b>layer</b> zero occurring always at the symmetric jump point). The latter requires the software to specify to the hardware only once the jumping interval size.|$|R
50|$|Layers: The HuC6270A VDC {{was capable}} of {{displaying}} <b>one</b> background <b>layer.</b>|$|R
25|$|Igor Aizenberg {{and colleagues}} {{introduced}} it to Artificial Neural Networks in 2000. The first functional Deep Learning networks were published by Alexey Grigorevich Ivakhnenko and V. G. Lapa in 1965. These networks are trained <b>one</b> <b>layer</b> at a time. Ivakhnenko's 1971 paper describes {{the learning of}} a deep feedforward multilayer perceptron with eight layers, already much deeper than many later networks. In 2006, a publication by Geoffrey Hinton and Ruslan Salakhutdinov introduced another way of pre-training many-layered feedforward neural networks (FNNs) <b>one</b> <b>layer</b> at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then using supervised backpropagation for fine-tuning. Similar to shallow artificial neural networks, deep neural networks can model complex non-linear relationships. Over the last few years, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.|$|E
25|$|The crystal has layered structure. Figure 15 shows {{a network}} of boron icosahedra that spreads {{parallel}} to the (001) plane, connecting with four neighbors through B1‚ÄìB1 bonds. The C3 and Si3 site atoms strengthen the network by bridging the boron icosahedra. Contrary to other boron-rich icosahedral compounds, the boron icosahedra from different layers are not directly bonded. The icosahedra within <b>one</b> <b>layer</b> are linked through Si8 ethane-like clusters with (B12)3‚â°Si-C‚â°(B12)3 bonds, as shown in figures 16a and b.|$|E
25|$|The {{network of}} {{electrodes}} connects to display circuitry, which turns the electronic ink 'on' and 'off' at specific pixels by applying a voltage to specific electrode pairs. A negative charge {{to the surface}} electrode repels the particles {{to the bottom of}} local capsules, forcing the black dye to the surface and turning the pixel black. Reversing the voltage has the opposite effect. It forces the particles to the surface, turning the pixel white. A more recent implementation of this concept requires only <b>one</b> <b>layer</b> of electrodes beneath the microcapsules.|$|E
5000|$|A unimorph or monomorph is a {{cantilever}} {{that consists}} of <b>one</b> active <b>layer</b> and <b>one</b> inactive <b>layer.</b> [...] In the case where active layer is piezoelectric, deformation in that layer may be induced by the application of an electric field. This deformation induces a bending displacement in the cantilever. The inactive layer may be fabricated from a non-piezoelectric material.|$|R
30|$|Artificial {{neural network}} {{is a massive}} {{parallel}} information processing system composed {{of a number of}} simple processing elements known as neurons or nodes (Haykin 1998). MLP is the most popularly used feed-forward hierarchical ANN which is used to map any random input with the corresponding output. Therefore, MLP has been used for a variety of studies for modeling and prediction on water research (Mondal et al. 2012; Al-Abadi 2014). MLP is comprised of different <b>layers</b> of neurons: <b>one</b> input <b>layer,</b> <b>one</b> or more hidden <b>layers,</b> and <b>one</b> output <b>layer</b> (Fig. 3).|$|R
50|$|Each of his {{paintings}} is composed of up to <b>one</b> hundred <b>layers</b> of paint.|$|R
25|$|All stupas {{contain a}} {{treasury}} filled with various objects. Small clay votive offerings called tsatsas in Tibetan fill {{most of the}} treasury. Creation of various types of tsatsas is a ceremony itself. Mantras written on paper are rolled into thin rolls and put into small clay stupas. <b>One</b> <b>layer</b> of tsatsas {{is placed in the}} treasury, and the empty space between them is filled with dry sand. On the thus created new surface, another layer of tsatsas is made, and so on until the entire space of the treasury is full.|$|E
25|$|Layered graph drawing methods (often called Sugiyama-style drawing) {{are best}} suited for {{directed}} acyclic graphs or graphs that are nearly acyclic, such as the graphs of dependencies between modules or functions in a software system. In these methods, the nodes of the graph are arranged into horizontal layers using methods such as the Coffman‚ÄìGraham algorithm, {{in such a way}} that most edges go downwards from <b>one</b> <b>layer</b> to the next; after this step, the nodes within each layer are arranged in order to minimize crossings.|$|E
25|$|Electrons {{are excited}} from their current molecular/atomic orbital. Once excited an {{electron}} can either dissipate the energy as heat {{and return to}} its orbital or travel through the cell until it reaches an electrode. Current flows through the material to cancel the potential and this electricity is captured. The chemical bonds of the material are vital for this process to work, and usually silicon is used in two layers, <b>one</b> <b>layer</b> being doped with boron, the other phosphorus. These layers have different chemical electric charges and subsequently both drive and direct the current of electrons.|$|E
40|$|Edge {{detection}} is {{the most}} fundamental {{but at the same}} time most important task in image processing and analysis. In the paper a hybrid approach combining Neural Network and Fuzzy logic based edge detection algorithm is proposed to detect edges in grayscale images. To improve the generalization ability, the neural network is trained on fuzzy inputs rather than crisp inputs. The network consists of three <b>layers,</b> <b>one</b> input <b>layer,</b> <b>one</b> hidden <b>layer</b> and <b>one</b> output <b>layer.</b> Fuzzy membership functions are used to convert neurons of input and hidden layer into fuzzy neurons. So the output of first and second layer is the membership value of the corresponding input in the fuzzy set. The proposed technique provides advantage of both neural networks and fuzzy logic and gives satisfactory results for both noisy and noise free images. The method is compared with Roberts, Prewitt, Sobel and Laplacian of Gaussian and other neural network and fuzzy logic based methods and the experimental results reveal that proposed method gives better edge map considering the problem of false edge detection...|$|R
50|$|FlipBook is {{available}} in four versions: Lite, Studio, Pro and Pro HD. The Lite edition supports one foreground and <b>one</b> background <b>layer,</b> <b>one</b> soundtrack, and up to three hundred frames per shot. The other editions support more layers, more frames, multiple soundtracks and higher output resolutions.|$|R
50|$|Simpler animals, such as sea sponges, have <b>one</b> germ <b>layer</b> {{and lack}} true tissue organization.|$|R
