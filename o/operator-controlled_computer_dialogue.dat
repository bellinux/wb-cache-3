0|82|Public
5000|$|ISO/TC 159/SC 4, Ergonomics {{of human}} system Interaction - Software {{ergonomics}} and human - <b>computer</b> <b>dialogues</b> ...|$|R
5000|$|Brockhoff, Klaus. [...] "The {{performance}} of forecasting groups in <b>computer</b> <b>dialogue</b> and face-to-face discussion." [...] The Delphi method: Techniques and applications (1975): 291-321.|$|R
40|$|In this paper, {{we examine}} {{mechanisms}} for automatic dialogue initiative setting. We show how to incorporate initiative changing in a task-oriented human [...] <b>computer</b> <b>dialogue</b> system, {{and we evaluate}} the effects of initiative both analytically and via <b>computer</b> [...] <b>computer</b> <b>dialogue</b> simulation. 1 Motivation: Initiative in Task-Oriented Dialogues Efficient human [...] <b>computer</b> <b>dialogue</b> requires immediate utterance-by-utterance accommodation {{to the needs of}} the interaction. The participants must continuously focus all concerns on the goals of the task and avoid extraneous paths. This means that the dialogue initiative should always pass immediately to the participant who is best able to handle the current task. An agent is said to have dialogue initiative over a mutual goal when that agent controls how that goal will be solved by the collaborators. In the implemented voice dialogue system "The Circuit Fix-it Shop" (Smith et al., 199...|$|R
40|$|In this paper, {{we examine}} three inter-related efficiency-improving {{dialogue}} behaviors: automatic dialogue initiative setting, negotiation for conflict resolution and summaries for plan recognition assistance. We show how to incorporate these behaviors in a task-oriented human [...] <b>computer</b> <b>dialogue</b> system, {{and we evaluate}} these mechanisms both analytically and via <b>computer</b> [...] <b>computer</b> <b>dialogue</b> simulation. Subjects: Dialogue, mixed-initiative, negotiation, summaries. 1. MOTIVATION: INITIATIVE IN TASK-ORIENTED DIALOGUES Efficient human [...] <b>computer</b> <b>dialogue</b> requires immediate utterance-by-utterance accommodation {{to the needs of}} the interaction. The participants must continuously focus all concerns on the goals of the task and avoid extraneous paths. This means that the dialogue initiative should always pass immediately to the participant who is best able to handle the current task. In the event of a conflict over which agent should handle the current task, the participants must efficiently ne [...] ...|$|R
50|$|Grosz {{specializes in}} natural {{language}} processing and multi-agent systems. She developed {{some of the earliest}} <b>computer</b> <b>dialogue</b> systems and established the research field of computational modeling of discourse.|$|R
5000|$|... system family 8864 (1975): It is a bank {{terminal}} {{and was used}} at the trade as a multi <b>computer.</b> <b>Dialogue,</b> Data gathering and control was possible. Storage were disks.|$|R
40|$|An {{experimental}} {{version of}} computer-aided {{methods of teaching}} mathematical analysis has been elaborated in the Research Centre of Applied Mathematics of the Selçuk University. The main part of this version is a textbook "Analysis"[1]. It {{is supported by the}} <b>computer</b> <b>dialogue</b> program Graphics Constructor [4] and its extended version Graphics Constructor 2. 0...|$|R
40|$|Argumentation is an {{emerging}} {{topic in the}} field of human <b>computer</b> <b>dialogue.</b> In this paper we describe a novel approach to dialogue management that has been developed to achieve persuasion using a textual argumentation dialogue system. The paper introduces a layered management architecture that mixes task-oriented dialogue techniques with chatbot techniques to achieve better persuasiveness in the dialogue. ...|$|R
40|$|We present work {{intended}} to improve speech recognition performance for <b>computer</b> <b>dialogue</b> by {{taking into account}} the way that dialogue context and intonational tune interact to limit the possibilities for what an utterance might be. We report here on the extra constraint achieved in a bigram language model, expressed in terms of entropy, by using separate submodels for different sorts of dialogue acts, and trying to predict which submodel to apply by analysis of the intonation of the sentence being recognised. 1. INTRODUCTION The ultimate goal of the work described here is to improve speech recognition performance for <b>computer</b> <b>dialogue</b> by {{taking into account the}} way that dialogue context and intonational tune interact to limit the possibilities for what an utterance might be. For example, suppose that you ask a yes/no question, and receive a short reply uttered fairly low in the speaker's pitch range and without much movement in pitch. The chances are that the reply amounts to either [...] ...|$|R
50|$|During the {{production}} of Stanley Kubrick's 1968 film 2001: A Space Odyssey, Davenport read the lines of HAL 9000 off-camera during the <b>computer's</b> <b>dialogues</b> with actors Keir Dullea and Gary Lockwood. Canadian actor Douglas Rain was ultimately chosen {{for the role of}} HAL's voice. Davenport took the leading role in the off-beat Phase IV (1974), which failed to find an audience. In 1979 he portrayed King George III in Prince Regent.|$|R
40|$|While {{researchers}} have many intuitions about the di#erences between humancomputer and human-human interactions, {{most of these}} have not previously been subject to empirical scrutiny. This work presents some initial experiments in this direction, with the ultimate goal being to use what we learn to improve <b>computer</b> <b>dialogue</b> systems. Working with data from the air travel domain, we {{identified a number of}} striking differences between the human-human and human-computer interactions...|$|R
50|$|The first <b>computer</b> <b>dialogue</b> {{system was}} {{featured}} in ELIZA, a primitive natural language processing computer program written by Joseph Weizenbaum between 1964 and 1966. The program emulated interaction between the user and an artificial therapist. With the advent of video games, interactive entertainment have attempted to incorporate meaningful interactions with virtual characters. Branching dialogues have since become a common feature in visual novels, dating sims, adventure games, and role-playing video games.|$|R
40|$|The {{computer-aided}} {{methods of}} mathematical education include three main parts: computers, textbooks and software. An experimental {{version of this}} approach was elaborated in the Research Centre of Applied Mathematics of the Selcuk University. This version includes four textbooks: Analysis [2], Linear Algebra [6], Linear Difference Equations and Stability Theory [1], and Matrix Computations with Guaranteed Accuracy in Stability Theory [12]. The version {{is supported by the}} <b>computer</b> <b>dialogue</b> system Matrix-vector calculator (MVC) [20], [21]...|$|R
40|$|We presentwork {{intended}} to improve speech recognition performance for <b>computer</b> <b>dialogue</b> by {{taking into account}} the way that dialogue context and intonational tune interact to limit the possibilities for what an utterance might be. We report here on the extra constraintachieved in a bigram language model, expressed in terms of entropy,by using separate submodels for di#erent sorts of dialogue acts, and trying to predict which submodel to apply by analysis of the intonation of the sentence being recognised...|$|R
40|$|In {{a series}} of {{screening}} interviews for psy-chological distress, conducted separately by a human interviewer and by an ani-mated virtual character controlled by a hu-man, participants talked substantially less and produced twice as many filled pauses when talking to the virtual character. This contrasts with earlier findings, where peo-ple were less disfluent when talking to a <b>computer</b> <b>dialogue</b> system. The re-sults suggest that the characteristics of computer-directed speech {{vary depending on the}} type of dialogue system used. ...|$|R
40|$|This paper {{examines}} feedback {{strategies in}} a Swedish corpus of multimodal human [...] computer interaction. The {{aim of the}} study is to investigate how users provide positive and negative feedback to a dialogue system and to discuss the function of these utterances in the dialogues. User feedback in the AdApt corpus was labeled and analyzed, and its distribution in the dialogues is discussed. The question of whether it is possible to utilize user feedback in future systems is considered. More specifically, we discuss how error handling in human [...] <b>computer</b> <b>dialogue</b> might be improved through greater knowledge of user feedback strategies. In the present corpus, almost all subjects used positive or negative feedback at least once during their interaction with the system. Our results indicate that some types of feedback more often occur in certain positions in the dialogue. Another observation is that there appear to be great individual variations in feedback strategies, so that certain subjects give feedback at almost every turn while others rarely or never respond to a spoken dialogue system in this manner. Finally, we discuss how feedback could be used to prevent problems in human [...] <b>computer</b> <b>dialogue...</b>|$|R
40|$|In this paper, {{we compare}} the {{distribution}} of disfluencies in two human [...] <b>computer</b> <b>dialogue</b> corpora. One corpus consists of unimodal travel booking dialogues, which were recorded over the telephone. In this unimodal system, all components except the speech recognition were authentic. The other corpus was collected using a semi-simulated multi-modal dialogue system with an animated talking agent and a clickable map. The aim {{of this paper is}} to analyze and discuss the effects of modality, task and interface design on the distribution and frequency of disfluencies in these two corpora...|$|R
40|$|This paper reports {{research}} {{concerning a}} suitable dialogue model for human-computer debate on a controversial issue such as capital punishment. We consider {{the adoption of}} Moore‘s [1993] utilization of Mackenzie‘s [1979] game DC, and in particular means of building conversational agents as the test-bed to facilitate evaluate of {{certain aspects of the}} proposed model. This study reveals several weaknesses of DC in preventing fallacious and common errors. It is anticipated that this work will contribute toward the development of human <b>computer</b> <b>dialogue,</b> and help to illuminate research issues in the field of dialectics itself. ...|$|R
40|$|This paper reports {{research}} {{concerning a}} suitable dialogue model for human-computer debate. In particular, {{we consider the}} adoption of Moore’s (1993) utilization of Mackenzie’s (1979) game DC, means of using computational agents as the test-bed to facilitate evaluation of the proposed model and means of using the evaluation results as motivation to further develop a dialogue model, which can prevent fallacious argument and common errors. It is anticipated that this work will contribute toward the development of human <b>computer</b> <b>dialogue,</b> and help to illuminate research issues {{in the field of}} dialectics itself...|$|R
40|$|Abstract. While human tutors {{typically}} {{interact with}} students using spoken <b>dialogue,</b> most <b>computer</b> <b>dialogue</b> tutors are text-based. We have conducted two experiments comparing typed and spoken tutoring dialogues, {{one in a}} human-human scenario, and another in a human-computer scenario. In both experiments, we compared spoken versus typed tutoring for learning gains and time on task, and also measured the correlations of learning gains with dialogue features. Our main results are that changing the modality from text to speech caused changes in the learning gains, time and superficial dialogue characteristics of human tutoring, but for computer tutoring it made less difference...|$|R
40|$|The ITSPOKE project {{developed}} an Intelligent Tutoring SPOKen dialogue system. Responsibilities involve enhancing ITSPOKE {{to detect and}} respond to student emotional/metacognitive states, and have included: 1) developing an annotation scheme for student emotional states in human and <b>computer</b> <b>dialogues,</b> 2) automating the extraction of acoustic, prosodic, lexical, syntactic, semantic, and discourse/dialogue features from the dialogues, 3) applying machine learning techniques to these features for the automatic recognition of the annotated emotional states, 4) analyzing human tutors’ responses to the student emotional states, 5) developing and implementing adaptive tutoring strategies for ITSPOKE to respond to student emotional states, 6) statistical analyses to investigate the effectiveness of human and computer adaptive tutoring strategies...|$|R
40|$|While human tutors {{typically}} {{interact with}} students using spoken <b>dialogue,</b> most <b>computer</b> <b>dialogue</b> tutors are text-based. We have conducted two experiments comparing typed and spoken tutoring dialogues, {{one in a}} human-human scenario, and another in a human-computer scenario. In both experiments, we compared spoken versus typed tutoring for learning gains and time on task, and also measured the correlations of learning gains with dialogue features. Our main results are that changing the modality from text to speech caused changes in the learning gains, time and superficial dialogue characteristics of human tutoring, but for computer tutoring it made less difference. © 2006 - IOS Press and t he authors...|$|R
40|$|This thesis {{addresses}} {{the question of}} how speakers adapttheir language when they interact with a spoken dialoguesystem. In human 9 ̆ 6 human dialogue, people continuously adaptto their conversational partners at different levels. Wheninteracting with computers, speakers also to some extent adapttheir language to meet (what they believe to be) theconstraints of the dialogue system. Furthermore, if a problemoccurs in the human 9 ̆ 6 <b>computer</b> <b>dialogue,</b> patterns oflinguistic adaptation are often accentuated. In this thesis, we used an empirical approach in which aseries of corpora of human 9 ̆ 6 computer interaction werecollected and analyzed. The systems used for data collectionincluded both fully functional stand-alone systems in publicsettings, and simulated systems in controlled laboratoryenvironments. All of the systems featured animated talkingagents, and encouraged users to interact using unrestrictedspontaneous language. Linguistic adaptation in the corpora wasexamined at the phonetic, prosodic, lexical, syntactic andpragmatic levels. Knowledge about users 9 ̆ 2 linguistic adaptations can beuseful in the development of spoken dialogue systems. If we areable to adequately describe their patterns of occurrence (atthe different linguistic levels at which they occur), we willbe able to build more precise user models, thus improvingsystem performance. Our knowledge of linguistic adaptations canbe useful in at least two ways: first, it has been shown thatlinguistic adaptations can be used to identify (andsubsequently repair) errors in human 9 ̆ 6 <b>computer</b> <b>dialogue.</b> Second, we can try to subtly influence users to behave in acertain way, for instance by implicitly encouraging a speakingstyle that improves speech recognition performance. NR 2014080...|$|R
40|$|Modern window-based user {{interfaces}} are actually {{a special kind}} of reactive system, and Petri nets may be fruitfully used to design such user - <b>computer</b> <b>dialogues.</b> This paper describes a software engineering tool aimed at supporting the use of high-level Petri nets for the specification, design and implementation of {{user interfaces}} in an event-driven interface system. We assess the rationale for the use of Petri nets in such a perspective. We then detail the object-oriented software architecture of the environment, and present an original algorithm for interpreting high-level Petri nets in an event-driven environment. Key-words : User Interface, Design, Computer tools for nets, High-level Petri nets. Contents 1. Introduction __________________________________________________________ 1 2. Event-driven programming ______________________________________________ 2 3. Architecture of interactive systems ________________________________________ 5 4. Designing event-driven interfaces wit [...] ...|$|R
40|$|We have {{conducted}} a pilot-study of one particular aspect of computer system design, namely how the speech acts {{in a human}} [...] <b>computer</b> <b>dialogue</b> system influence the disfluency production of the user. We have analysed two travel-booking corpora with the aim {{to find out how}} many disfluencies the various speech acts in the dialogues of the corpora produce. We found that the speech acts do influence the disfluency rates, and that this trend was especially discernible when addressing the `openness' of the speech acts. Our findings indicate that one way of reducing disfluencies in spoken human [...] computer systems would be {{to reduce the number of}} speech acts which present difficulty in processing for the user, and we propose that this be done in the design of the dialogue manager of the system...|$|R
40|$|In this paper, {{we propose}} a {{functional}} approach {{to overcome the}} lack of expressiveness of predicative approaches for extensional reference resolution. This later approach indeed forces designers of dialogue systems to use specific heuristics when solving some reference cases, which they can’t integrate in a unified representation framework. As we focus on extensional reference resolution in a generic framework for human <b>computer</b> <b>dialogue</b> system, we point {{the fact that the}} process of resolving referential expressions needs to take context into account even for expressions involving intrinsic characteristics of elements. Thus we propose a representation model for the semantics of intrinsic referential extractors. This model is built on three functions, the first one serves to calculate the similarity ratio between two elements, the two others serve to partition a reference domain which is previously sorted by the first functio...|$|R
40|$|We {{compare the}} {{relative}} utility of different automatically computable linguistic feature sets for modeling student learning in <b>computer</b> <b>dialogue</b> tutoring. We use the PARADISE framework (multiple linear regression) {{to build a}} learning model from each of 6 linguistic feature sets: 1) surface features, 2) semantic features, 3) pragmatic features, 4) discourse structure features, 5) local dialogue context features, and 6) all feature sets combined. We hypothesize that although more sophisticated linguistic features are harder to obtain, they will yield stronger learning models. We train and test our models on 3 different train/test dataset pairs derived from our 3 spoken dialogue tutoring system corpora. Our results show that more sophisticated linguistic features usually perform better than either a baseline model containing only pretest score or a model containing only surface features, and that semantic features generalize better than other linguistic feature sets...|$|R
40|$|We use X 2 to {{investigate}} the context dependency of student affect in our <b>computer</b> tutoring <b>dialogues,</b> targeting uncertainty in student answers in 3 automatically monitorable contexts. Our results show significant dependencies between uncertain answers and specific contexts. Identification and analysis of these dependencies is our first step in developing an adaptive version of our dialogue system...|$|R
40|$|As {{speech and}} natural {{language}} processing technology advance, it now reaches a stage where the dialogue control or initiative can be studied to realise usable and friendly human computer interface programs such as <b>computer</b> <b>dialogue</b> systems. One of the major problems concerning dialogue initiative is who should take the dialogue initiative when. This thesis tackles this dialogue initiative problem using the following approaches: ffl Human dialogue data is examined for their local dialogue structures; ffl A dialogue manager is proposed and implemented, which handles variations of human dialogue data concerning the dialogue initiative, and experimental results are obtained by having the implemented dialogue managers working with a parser and a generator exchange natural language messages with each other; and ffl A mathematical model is constructed and used to analyse who should take the dialogue initiative when. The first study shows that human dialogue data varies concerning the numb [...] ...|$|R
40|$|An {{analysis}} of task oriented dialogue {{has been developed}} around goal-directed exchanges labelled conversational games. Games account for that aspect of discourse coherence that is manifested in initiation [...] response [...] feedback patterns, and they do so by relating the form of dialogue to underlying non-linguistic goals. The system applies to real, spontaneous dialogue and may prove useful {{in the design of}} <b>computer</b> <b>dialogue</b> systems. A study was conducted to determine agreement among analysts, upon coding two sets of dialogues. One expert and three novice analysts agreed on an average of 78 % of the moves assigned. When certain consistent differences are taken into account, however, the accuracy increases to 88 %. 1 Introduction We have developed a system of discourse analysis which structures conversations on two functional levels. The level of conversational games is associated with mutually understood conversational goals such as obtaining information or getting one's conversational partn [...] ...|$|R
40|$|In {{this age}} of {{information}} technology, information access in a convenient manner has gained importance. Since speech is a primary mode of communication among human beings, it is natural for people to expect {{to be able to}} carry out spoken <b>dialogue</b> with <b>computer.</b> Speech recognition system permits ordinary people to speak to the computer to retrieve information. It is desirable to have a human <b>computer</b> <b>dialogue</b> in local language. Hindi being the most widely spoken Language in India is the natural primary human language candidate for human machine interaction. There are five pairs of vowels in Hindi languages; one member is longer than the other one. This paper describes an overview of speech recognition system that includes how speech is produced and the properties and characteristics of Hindi Phoneme. Comment: Pages: 05 Figures : 04 Tables : 03 Proceedings of the International Conference ICCSCT 2010, Tirunelveli, Indi...|$|R
40|$|In {{this paper}} {{we argue that}} {{analysis}} of <b>computer</b> [...] <b>computer</b> <b>dialogues</b> is beneficial {{in the development and}} testing of computational models of human [...] computer collaboration. By outlining the stages {{in the development of a}} human [...] computer task-oriented system, we show the role that computer simulations can play in this process. Simulations allow a measure of verification that the underlying model does indeed model the intended behavior. Further, through computer [...] computer simulation, thousands of dialogues can be gathered making statistical analysis of the computational model feasible. Research Methodology Our goal is to produce voice interactive human [...] computer collaborative systems. Creating such a complex system is not done in one step. We follow a development methodology illustrated in Figure 1. There are six stages of development: creation of an underlying model (which is based upon previous research and observations), analytical evaluation of the model, computational implementati [...] ...|$|R
40|$|In this paper, we {{will focus}} on the human <b>computer</b> <b>dialogue</b> style named direct {{manipulation}} and its “point and click” method. Pointing and clicking objects in GUI is usually accomplished by numerous peripheral devices, e. g. light pens, joystick, touch screens and – most commonly, computer mice (Greenstein & Arnaut, 1988). This study will examine the Direct Manipulation Task Efficiency Factors In Web Browser Interface Design’s effect between Internet Explorer and Mozilla Firefox) on their operation efficiency. Experiment Testing is used as a mehod, More than 32 undergraduate students in accounting will take part as a target population in this study. A special software was used to carry out the experiments. Three independent variables are used: Panel orientation (in the graphical interface: horizontal and vertical), Panel location (Left and right), and Icon graphic. Thus, the dependent variables measurement are: the acquaition time and the number errors made. Data will analised by a descriptive statistics and an analysis vatiance (ANOVA). The SPSS version 12 will used to execution...|$|R
40|$|To {{understand}} the language we use, we sometimes must turn language on itself, {{and we do}} this through {{an understanding of the}} use-mention distinction. In particular, we are able to recognize mentioned language: that is, tokens (e. g., words, phrases, sentences, letters, symbols, sounds) produced to draw attention to linguistic properties that they possess. Evidence suggests that humans frequently employ the use-mention distinction, and we would be severely handicapped without it; mentioned language frequently occurs for the introduction of new words, attribution of statements, explanation of meaning, and assignment of names. Moreover, just as we benefit from mutual recognition of the use-mention distinction, the potential exists for us to benefit from language technologies that recognize it as well. With {{a better understanding of the}} use-mention distinction, applications can be built to extract valuable information from mentioned language, leading to better language learning materials, precise dictionary building tools, and highly adaptive <b>computer</b> <b>dialogue</b> systems. This dissertation presents the first computational study of how the use...|$|R
40|$|We {{present an}} {{annotation}} scheme for student emotions in tutoring dialogues. Analyses of our scheme {{with respect to}} interannotator agreement and predictive accuracy indicate that our scheme is reliable in our domain, and that our emotion labels can be predicted {{with a high degree}} of accuracy. We discuss issues concerning the implementation of emotion prediction and adaptation in the <b>computer</b> tutoring <b>dialogue</b> system we are developing. ...|$|R
40|$|Dealing with DEAL: A {{dialogue}} {{system for}} conversation training We present DEAL, a spoken dialogue system for conversation training under development at KTH. DEAL {{is a game}} with a spoken language interface designed for second language learners. The system is intended as a multidisciplinary research platform where challenges and potential benefits of combining elements from <b>computer</b> games, <b>dialogue</b> systems and language learning can be explored. ...|$|R
