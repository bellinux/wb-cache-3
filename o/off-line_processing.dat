185|108|Public
50|$|The raw {{spectral}} {{data can be}} processed on-line to obtain real-time outputs and the final data products can be displayed on a graphics terminal or outputted to a hardcopy plotter. Otherwise, <b>off-line</b> <b>processing</b> {{at a later date}} can be accomplished.|$|E
50|$|The {{final output}} of a {{navigation}} receiver is usually its position, speed or other related physical quantities. However, {{the calculation of}} these quantities {{are based on a}} series of measurements from one or more satellite constellations. Although receivers calculate positions in real time, in many cases it is interesting to store intermediate measures for later use. RINEX is the standard format that allows the management and disposal of the measures generated by a receiver, as well as their <b>off-line</b> <b>processing</b> by a multitude of applications, whatever the manufacturer of both the receiver and the computer application.|$|E
40|$|Holographic {{data are}} {{acquired}} during hydrodynamic experiments at the Pegasus Pulsed Power Facility at the Los Alamos National Laboratory. These experiments produce a fine spray of fast-moving particles. Snapshots of the spray are captured using in-line Fraunhofer holographic techniques. Roughly one cubic centimeter is {{recorded by the}} hologram. Minimum detectable particle size in the data extends down to 2 microns. In a holography reconstruction system, a laser illuminates the hologram as it rests in a three axis actuator, recreating the snapshot of the experiment. A computer guides the actuators through an orderly sequence programmed by the user. At selected intervals, slices of this volume are captured and digitized with a CCD camera. Intermittent on-line processing of the image data and computer control of the camera functions optimizes statistics of the acquired image data for <b>off-line</b> <b>processing.</b> Tens of thousands of individual data frames (30 to 40 gigabytes of data) are required to recreate a digital representation of the snapshot. Throughput of the reduction system is 550 megabytes per hour (MB/hr). Objects and associated features from the data are subsequently extracted during <b>off-line</b> <b>processing.</b> Discrimination and correlation tests reject noise, eliminate multiple particles, and build an error model to estimate performance. Objects surviving these tests are classified as particles. The particle distributions are derived from the data base formed by these particles, their locations and features. Throughput of the <b>off-line</b> <b>processing</b> exceeds 500 MB/hr. This paper describes the reduction system, outlines the <b>off-line</b> <b>processing</b> procedure, summarizes the discrimination and correlation tests, and reports numerical results for a sample data set...|$|E
40|$|Recommendations {{based on}} <b>off-line</b> data <b>processing</b> has {{attracted}} increasing attention from both research communities and IT industries. The recommendation techniques {{could be used}} to explore huge volumes of data, identify the items that users probably like, and translate the research results into real-world applications, etc. This paper surveys the recent progress in the research of recommendations based on <b>off-line</b> data <b>processing,</b> with emphasis on new techniques (such as context-based recommendation, temporal recommendation), and new features (such as serendipitous recommendation). Finally, we outline some existing challenges for future research. <br /...|$|R
40|$|Subject of investigation: <b>off-line</b> data <b>processing</b> of {{electronic}} experiments in high-energy physics {{and design of}} a computer complex. Purpose of the work: modelling of the <b>off-line</b> data <b>processing</b> of experiments in the high-energy physics and of the optimum selection of computer facilities in a multilevel scheme of decision taking. The model is developed {{with the use of}} algorithmic and non-algorithmic knowledge. The interaction of the submodels is organized {{on the basis of a}} unique representation of the object model with the use of a relational data base control system facilities in a multi-level scheme of decision taking. Integrated decision taking support expert system "COMEX" is created. It was used for modelling the <b>off-line</b> data <b>processing</b> and for the selection of versions of computer complexes for a number {{of electronic}} experiments in the high-energy physics. The program system "COMEX" was put into practice in the United Institute of Nuclear Investigations and in the Executive Secretariate on Nuclear Problems in CubaAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|Recent a {{globalisation}} {{of technology}} and economics world causes that possibility for Internet applications are moved from <b>off-line</b> data <b>processing</b> to on-line data streaming. Internet is often becoming a part of real production processes that thanks to Internet can grow into more efficient and better distributed. A typical example of an implementation o...|$|R
40|$|All authors contributed equally. Abstract — In {{this paper}} {{we present a}} {{framework}} for realtime processing of multimodal data, {{which can be used}} for on- and <b>off-line</b> <b>processing</b> of perceived data in interactions. We propose the use of a framework based on the Real-time Database (RTDB). This framework allows easy integration of input and output modules and thereby concentrating on the core functionality of the module. Furthermore the asynchronous data from different sources is synchronized and can be recorded for <b>off-line</b> <b>processing.</b> This recorded data can be used to train recognition modules, which can then be used again on-line. Experiments and first results with off-line human-human and on-line human-robots are reported. I...|$|E
40|$|The Astrometric Data-Reduction Software (ADRS) {{processes}} fringe, delay, environmental, and {{calibration data}} for PRIMA narrow-angle astrometry. It is automated software {{designed to provide}} fully-calibrated differential delays and separation angles. The ADRS is divided into on-line and <b>off-line</b> <b>processing.</b> The former deals with calibration and data compression, while the latter applies corrections and calculates science quantities. PRIMA is the first VLTI instrument that may require removal of long-term environmental trends. The trend identification and fitting routines {{are not part of}} the distributed on-line and <b>off-line</b> <b>processing</b> software. Instead, files containing fit parameters will be updated regularly. Coding is presently underway. The PRIMA error budget summarizes the principal sources of error in PRIMA astrometric observation...|$|E
40|$|Report {{presents}} {{the test results}} of the linearity measurement of the Luminosity Photon Calorimeter readout electronics. Nonlinearity of the preamplifiers, amplifiers, 140 meters long analog signal transmission, integrators and FADC have been measured and analyzed. This allows making data correction and results in increased luminosity measurement precision for <b>off-line</b> <b>processing...</b>|$|E
40|$|During {{the beam}} {{test of a}} tracker {{prototype}} for the Compact Muon Solenoid detector proposed for the LHC, the time response of the Microstrip Gas Chambers was studied using different gases and chamber gaps. The subsequent efficiency to identify the bunch crossing at LHC is discussed for several algorithms used in the <b>off-line</b> signal <b>processing</b> of the data...|$|R
40|$|A {{combination}} of {{software and hardware}} for a time-sharing computer is described which allows the user to obtain an on-line data display {{in the control room}} of a large research facility. Display and hard copy of alphanumeric data as well as graphical data can be obtained as desired by the user. In addition, a number of utility programs provide for on-line graphic editing, program control, data manipulation, and <b>off-line</b> microfilm <b>processing...</b>|$|R
40|$|During {{sequence}} learning, individuals show motor-skill {{acquisition and}} an ability to verbally describe items within the sequence. We disrupted this latter, declarative component by having participants learn a word list immediately after sequence learning. This induced off-line skill improvements. We conclude that <b>off-line</b> memory <b>processing</b> relies not only on the engagement of neuroplastic mechanisms but also on the disengagement of an interaction between declarative and procedural memory systems...|$|R
40|$|Learning new {{facts and}} skills in {{succession}} {{can be frustrating}} because no sooner has new knowledge been acquired than its retention is being jeopardized by learning another set of skills or facts. Interference between memories has recently provided important {{new insights into the}} neural and psychological systems responsible for memory processing. For example, interference not only occurs between the same types of memories, but can also occur between different types of memories, which has important implications for our understanding of memory organization. Converging evidence has begun to reveal that the brain produces interference independently from other aspects of memory processing, which suggests that interference may have an important but previously overlooked function. A memory's initial susceptibility to interference and subsequent resistance to interference after its acquisition has revealed that memories continue to be processed ‘off-line’ during consolidation. Recent work has demonstrated that <b>off-line</b> <b>processing</b> is not limited to just the stabilization of a memory, which was once the defining characteristic of consolidation; instead, <b>off-line</b> <b>processing</b> can have a rich diversity of effects, from enhancing performance to making hidden rules explicit. <b>Off-line</b> <b>processing</b> also occurs after memory retrieval when memories are destabilized and then subsequently restabalized during reconsolidation. Studies are beginning to reveal the function of reconsolidation, its mechanistic relationship to consolidation and its potential as a therapeutic target for the modification of memories...|$|E
40|$|We {{present a}} {{bottom-up}} {{approach to the}} problem of fixing psychological requirements to concept possession. It is argued that four constraints are required: abstraction, directedness, multimodality and <b>off-line</b> <b>processing.</b> Taken together, these psychological requirements yield a view of concepts similar (on certain aspects) to “dual ” philosophical pictures: both inferential role and referential mechanisms are necessary to characterize conceptual competence...|$|E
40|$|This report {{describes}} the system {{developed by the}} University of Edinburgh and the University of Sydney for the TREC- 2005 question answering evaluation exercise. The backbone of our question-answering platform is QED, a linguistically-principled QA system. We experimented with external sources of knowledge, such as Google and Wikipedia, to enhance the performance of QED, especially for reranking and <b>off-line</b> <b>processing</b> of the corpus...|$|E
40|$|This paper {{describes}} a design methodology to implement on FPGAs piecewise-affine (PWA) functions based on representation methods from the lattice theory. An <b>off-line</b> automatic <b>processing</b> {{starts at the}} algorithmic formulation of the problem, obtains the parameters required by a parameterized digital architecture, and ends with the bitstream to program an FPGA. The methodology has been proven to implement PWA functions on Xilinx FPGAs. The results are compared with other approaches for FPGA implementations of PWA function...|$|R
40|$|Farms Batch System (FBS) was {{developed}} as a batch process management system for off-line Run II data processing at Fermilab. FBS will manage PC farms composed of up to 250 nodes and scalable to 1000 nodes with disk capacity of up to several TB. FBS allows users to start arrays of parallel processes on multiple computers. It uses a simplified resource counting method load balancing. FBS has been successfully used {{for more than a}} year at Fermilab by fixed target experiments and will be used for collider experiment <b>off-line</b> data <b>processing.</b> Fermi Inter-Process Communication toolkit (FIPC) was designed as a supplement product for FBS that helps establish synchronization and communication between processes running in a distributed batch environment. However, FIPC is an independent package, and can be used with other batch systems, as well as in a non-batch environment. FIPC provides users with a variety of global distributed objects such as semaphores, queues and string variables. Other types of objects can be easily added to FIPC. FIPC has been running on several PC farms at Fermilab for half a year and is going to be used by CDF for <b>off-line</b> data <b>processing...</b>|$|R
40|$|Metadata {{merged with}} {{duplicate}} record (	[URL] on 20. 12. 2016 by CS (TIS). This is a digitised {{version of a}} thesis that was deposited in the University Library. If you are the author please contact PEARL Admin (pearladmin@plymouth. ac. uk) to discuss options. Micro-affordance effects have been reported for several different components of the reachto- grasp action during on-line visual processing (Tucker and Ellis, 1998; Ellis and Tucker, 2000; and Tucker and Ellis, 2001). One property of these effects {{is that they have}} been shown to terminate once an object is removed from view (Tucker and Ellis, 2001). This thesis describes eight experiments that examine the presence of micro-affordance effects during <b>off-line</b> visual <b>processing.</b> All eight experiments employ a stimulus-response compatibility paradigm. Three different experimental designs were employed to examine the presence of micro-affordance effects arising from the relationship between: (a) the power and precision component of the reach-to-grasp action and the compatibility of an object for grasping with either a power or precision grasp, and (b) the orientation of an object for grasping and hand of response. The results of the experimentss uggestt hat: (a) the representationsu tilised during <b>off-line</b> visual <b>processing</b> can potentiate actions arising from the two components of the reach-tograsp action investigated;(b) the representationsu tilised during <b>off-line</b> visual <b>processing</b> can also inhibit micro-affordance effects; (c) main effects of object orientation (faster response times to either left or right-oriented objects) in those experiments examining the relationship between the orientation of an object for grasping and hand of response can be used to support a theory for the existenceo f prototype object representationsh, eld in long term memory, for the process of object recognition, and (d) due to differences in the object properties thought to give rise to micro-affordance effects, and the existence of different off-line visual processes,d ifferent experimentald esignsa re required to elicit microaffordance effects arising from the two types of micro-affordance effects investigated in this thesis. Economic and Social Research Counci...|$|R
40|$|International audienceWe {{introduce}} OM-Faust, an OpenMusic library including {{objects and}} functions to write, compile and control Faust programs. Faust is a domain-specific {{functional programming language}} designed for DSP. The integration of Faust in OpenMusic enables composers to program and compile their own audio effects and synthesizers, controllable both in real-time or deferred time contexts. This implementation suggests a more general discussion regarding the relationship between real-time and <b>off-line</b> <b>processing</b> in computer-aided composition...|$|E
40|$|The paper {{proposes a}} novel method using a neuro-fuzzy based model for {{identification}} of `off-standard' configurations of large electric distribution network components. The method provides an automatic procedure for <b>off-line</b> <b>processing</b> of historical loading {{data that are}} made available by an existing monitoring and control system of the grid. The method {{is based on a}} version of Simpson's Min-Max paradigm, optimized with respect to clustering performance measured by a suitable compactness-separability index...|$|E
40|$|Figure 1 : Multi-character {{animations}} are synthesized from single-person Motion Capture data. The individual {{interactions between}} nearby characters are precomputed into interaction patches by expanding game trees during the <b>off-line</b> <b>processing</b> stage. Our system automatically concatenates the patches and generates a complex multi-character animation, such as (a) one person fighting with many enemies, (b) {{a group of}} characters falling down onto each other like dominos, (c) an American football player holding a ball and escaping from tackling defenders, and (d) {{a group of people}} passing luggage from one to another. We propose a data-driven approach to automatically generate a scene where tens to hundreds of characters densely interact with each other. During <b>off-line</b> <b>processing,</b> the close interactions be-tween characters are precomputed by expanding a game tree, and these are stored as data structures called interaction patches. Then, during run-time, the system spatio-temporally concatenates the in-teraction patches to create scenes where a large number of charac-ters closely interact with one another. Using our method, it is possi-ble to automatically or interactively produce animations of crowds interacting with each other in a stylized way. The method can be used for a variety of applications including TV programs, adver-tisements and movies...|$|E
40|$|Sea gravity {{measurements}} {{on board the}} icebreaker SHIRASE were continuously conducted during the 27 th Japanese Antarctic Research Expedition. The NIPR-ORI sea gravity meter which was improved to get the on-line navigation data was employed in this cruise. Using those navigation data, we could successfully obtain free-air and Bouguer anomalies on board. Although we have confirmed the advantages of on-line data processing, we cannot avoid the <b>off-line</b> data <b>processing</b> after the cruise to correct the uncertain positioning of navigation system and to calibrate the gravity sensor. The main parts of the <b>off-line</b> data <b>processing</b> were as follows : (1) Determine the scale constants and drift rate of the gravity sensor. (2) Redetermine the measuring positions using updated satellite positions. (3) Recalculate the values of Eotvos, free-air and Bouguer corrections. By these processings, we have obtained gravity anomalies within an accuracy of a few mgals in most cases throughout the cruise. One of the interesting features of gravity anomalies was obtained on the Gunnerus ridge located off the Riiser-Larsen peninsula. The complete gravity data across the ridge has been obtained in this cruise for the first time. Therefore, we intend to study the detail structure of this area from the geophysical points of view...|$|R
50|$|The VisLab Intercontinental Autonomous Challenge is {{considered}} a unique milestone in vehicular robotics, just like the DARPA Grand Challenge in 2005 and the DARPA Urban Challenge in 2007. The vehicles collected about 50 terabytes of data {{to be used in}} the future for further <b>processing</b> <b>off-line.</b>|$|R
40|$|In {{this paper}} we report our efforts in data {{collection}} and performance evaluation in support of spoken dialogue system development. We describe two understanding metrics called query density and concept efficiency which can be interpreted on a perutterance basis, but which are measured {{over the course of}} a dialogue. We also describe the evaluation infrastructure we have developed to support <b>off-line</b> data <b>processing</b> using our GALAXY client-server architecture [8]. We show how we have used these metrics and mechanisms as part of the development of a spoken dialogue system for air-travel information...|$|R
40|$|Abstract. We have {{developed}} NetPay, a micro-payment protocol characterized by <b>off-line</b> <b>processing,</b> customer anonymity and relatively high performance and security using one-way hashing functions for encryption. In our NetPay prototypes {{we have identified}} three kinds of electronic wallets to store e-coins – a server-side wallet, client-side wallet application, and cookie-based wallet cache. We describe the motivation for NetPay and describe the three kinds of ewallets and their design. We report on prototype implementations of these wallets and end-user perceptions of their use. ...|$|E
40|$|Micro-payment {{systems have}} become popular {{in recent times}} as the desire to support low-value, {{high-volume}} transactions of text, music, clip-art, video and other media has increased. We describe NetPay, a micro-payment system characterized by de-centralized, <b>off-line</b> <b>processing,</b> customer anonymity and relatively high performance and security using one-way hashing functions for encryption. We describe the motivation for NetPay and its basic protocol, describe a software architecture and two NetPay prototypes we have developed, and report the results of several evaluations of these prototypes...|$|E
40|$|We propose an {{architecture}} for allowing mobile hosts {{to connect to}} a corporate IT system via a limited access network. The connection is made through a Mobile Host Support System that makes the mobile host appear to the central system as just another fixed client. The MHSS not only helps mitigate "mobility" problems such as disconnections, limited bandwidths and security, but also assists the mobile user byallowing <b>off-line</b> <b>processing.</b> This architecture is an intermediate step toward building mobile support directly into corporate computing systems. ...|$|E
40|$|In {{this paper}} {{we will give}} a short {{overview}} of the ideas underpinning the demonstrator developed within the EU-funded project Twenty-One; this system provides for the disclosure of information in a heterogeneous document environment that includes documents of different types and languages. As part of the <b>off-line</b> document <b>processing</b> that has been integrated in the system noun phrases are extracted to build a phrase-based index. They are {{the starting point for}} the generation of both a fuzzy phrase index and a translation step that is needed for the realisation of cross-language retrieval functionality...|$|R
40|$|A {{symmetric}} positron annihilation lifetime (PAL) spectrometer using a charge-to-digital converters was designed. It {{is based}} on a coincidence circuit for the trigger and recording of the timing and the charge of the pulses of two scintillation detectors. The <b>off-line</b> data <b>processing</b> allows a detailed study of the spectrometer performance in function of the width of the digital charge discriminator windows for acceptance of the pulses as starts and stops. Some technical problems when working with BaF_ 2 scintillators were solved. The parasitic effect of the pileup and backscattered γ-rays on the PAL spectrum is discussed...|$|R
30|$|The {{off-line}} analysis {{consists of}} a wide range of activities ranging from noise weather correlation to signal source location reconstruction. Direction reconstruction is one of the <b>off-line</b> signal <b>processing</b> algorithms. It is used for source location reconstruction. To simplify reconstruction the detector was designed with clusters of hydrophones. A cluster of small size, in this case six hydrophones in a volume of about one cubic meter, greatly reduces the time window necessary to be analyzed and simplifies signal selection at high background rates. Following two methods currently employed for direction reconstruction will be discussed, beamforming and the difference method.|$|R
40|$|Forming and {{detection}} algorithms {{for digital}} watermarks {{are designed for}} automatic identification of VHF radiotelephone transmissions in the maritime and aeronautical mobile services. An audible insensitivity and interference resistance of embedded digital data are provided by means of OFDM technology jointly with normalized distortions distribution and data packet detection by the hash-function. Experiments were carried out {{on the base of}} ship’s radio station RT- 2048 Sailor and USB ADC-DAC module of type Е 14 - 140 M L-CARD in the <b>off-line</b> <b>processing</b> regime in Matlab mediu...|$|E
40|$|The Short-Wavelength Spectrometer (SWS) {{is one of}} {{the four}} {{instruments}} on-board ESA's Infrared Space Observatory (ISO), launched on November 17, 1995. The spectrometer covers the wavelength range of 2. 38 to 4. 2 mu m with a spectral resolution ranging from 1000 to 2000. By inserting Fabry-Perot filters the resolution can be enhanced by a factor 20 for the wavelength range from 11. 4 to 44. 5 mu m. An overview is given of the instrument, its in-orbit calibration, performance, observing modes and <b>off-line</b> <b>processing</b> software...|$|E
40|$|The Cluster Tracker, {{introduced}} in previous work, {{is used to}} detect, track, split, merge and remove clusters of pixels {{significantly different from the}} corresponding pixels in a reference image. Clusters with common motion are grouped together into super-clusters during <b>off-line</b> <b>processing,</b> and {{the number of people in}} each super-cluster is determined by the sizes of the super-clusters and their pattern of merging and splitting. Finally, this information is used to obtain a statistical summary of the behaviour of people in the field of view...|$|E
40|$|A stable {{reference}} {{light source}} {{based on an}} LED (Light Emission Diode) is presented for stabilizing the conversion gain of the opto-electronic system of a gamma- and fast-neutron radiographic and tomographic imaging device. A constant fraction of the LED light is transported to the image plane of the camera and provides a stable reference exposure. This is used to normalize the images during <b>off-line</b> image <b>processing.</b> We have investigated parameters influencing the stability of LEDs and developed procedures and criteria to prepare and select LEDs suitable for delivering stable light outputs for several 100 h of operation...|$|R
40|$|A 36 GHz {{computer}} controlled airborne Surface Contour Radar (SCR) is described, which {{was developed by}} the Naval Research Laboratory and NASA. The system uses pulse-compression techniques and dual frequency carriers spaced far enough apart to be decorrelated on the sea surface. The continuous wave transmitter is biphase modulated, the return signal is autocorrelated, and the code length and clock rate are variable, providing selectable range resolutions of 0. 15, 0. 30, 0. 61 and 1. 52 m. The SCR generates a false-color coded elevation map of the sea surface below the aircraft in real time, and can routinely produce ocean directional wave spectra with <b>off-line</b> data <b>processing...</b>|$|R
40|$|An <b>off-line</b> post-mission <b>processing</b> {{facility}} is being established by NASA Ames Research Center to analyze differential GPS flight tests. The {{current and future}} differential systems are described, comprising an airborne segment in an SH- 3 helicopter, a GPS ground reference station, and a tracking system. The post-mission processing system provides for extensive measurement analysis and differential computation. Both differential range residual corrections and navigation corrections are possible. Some preliminary flight tests were conducted in a landing approach scenario and statically. Initial findings indicate the possible need for filter matching between airborne and ground systems (if used in a navigation correction technique), the advisability of correction smoothing before airborne incorporation, and the insensitivity of accuracy to either of the differential techniques or to update rates...|$|R
