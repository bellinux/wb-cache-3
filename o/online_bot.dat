4|15|Public
40|$|To help activists call new {{volunteers to}} action, we present Botivist: a {{platform}} that uses Twitter bots to find potential volunteers and request contributions. By leveraging differ-ent Twitter accounts, Botivist employs different strategies to encourage participation. We explore how {{people respond to}} bots calling them to action using a test case about corrup-tion in Latin America. Our {{results show that the}} majority of volunteers (> 80 %) who responded to Botivist’s calls to ac-tion contributed relevant proposals to address the assigned so-cial problem. Different strategies produced differences in the quantity and relevance of contributions. Some strategies that work well offline and face-to-face appeared to hinder peo-ple’s participation when used by an <b>online</b> <b>bot.</b> We analyze user behavior in response to being approached by bots with an activist purpose. We also provide strong evidence for the value of this type of civic media, and derive design implica-tions...|$|E
40|$|Recent {{research}} has shown a substantial active presence of bots in online social networks (OSNs). In this paper we utilise our past work on studying bots (Stweeler) to comparatively analyse the usage and impact of bots and humans on Twitter, {{one of the largest}} OSNs in the world. We collect a large-scale Twitter dataset and define various metrics based on tweet metadata. We divide and filter the dataset in four popularity groups in terms of number of followers. Using a human annotation task we assign 'bot' and 'human' ground-truth labels to the dataset, and compare the annotations against an <b>online</b> <b>bot</b> detection tool for evaluation. We then ask a series of questions to discern important behavioural bot and human characteristics using metrics within and among four popularity groups. From the comparative analysis we draw important differences as well as surprising similarities between the two entities, thus paving the way for reliable classification of automated political infiltration, advertisement campaigns, and general bot detection. Comment: This is a technical report of 18 pages including reference...|$|E
40|$|Botnet {{is one of}} {{the most}} {{dangerous}} threats ininternet. Botnet [10] consists of a network ofcompromised computers connected to the networkthat is controlled by a remote attacker (Botmaster). Botnets perform various attacks such as DDoSattacks, Click Fraud attacks, and are also involvedin distribution of spam emails, key loggers etc. Existing techniques for the detection of bot includesdeployment of Honey pots, Usage of signatures fordetection of various attacks, Monitoring Networktraffic for anomaly detection. Disadvantage inHoney pot detection is to captures and tracks theactivity only attacker directly interact with it. InSignature based detection only known attacks canbe detected and further, it needs regular update ofrules. A network-based detection monitors thenetwork traffic which involves deep packetinspection requires high computing performance. To overcome the disadvantages of the existingsolutions, A new Symptoms Based Detection andRemoval of Bot Processes algorithm is proposed. The proposed algorithm provides a host basedsolution, which enables <b>online</b> <b>bot</b> processdetection and its removal. The Detection process isbased on the detection of illegitimate process whichuses TCP connections. This involves observing theDigital signature of the process, installedPrograms path and also the registry entriesassociated with the process. The proposed solutionwhen tested on a bot infected machine, was foundto detected as well as remove the malicious Botprocesses...|$|E
50|$|In WIRED it {{was noted}} that {{nation-state}} rules such as compulsory registration and threats of punishment are not adequate measures to combat the problem of <b>online</b> <b>bots.</b>|$|R
50|$|The Washington Post {{cited the}} {{conspiracy}} theories {{as an example}} of the power of fake news to spread virally online. The paper used the example as a case study of the persistence of fake news, and found that television news media can be a soft target for such false stories. The Washington Post further found that the proliferation of fake news via Facebook had decreased, but remained powerful on Twitter due to spread via <b>online</b> <b>bots.</b> They found that the conspiracy theories with the largest potential to spread on the Internet were those that held attraction for both the alt-right movements and the political left wing. The Washington Post concluded that even if a particular false story had been sufficiently debunked, such fact-checking was unable to stop the spread of the falsehoods online.|$|R
40|$|Online Social Networks (OSNs) play an {{important}} role for internet users to carry out their daily activities like content sharing, news reading, posting messages, product reviews and discussing events etc. At the same time, various kinds of spammers are also equally attracted towards these OSNs. These cyber criminals including sexual predators, online fraudsters, advertising campaigners, catfishes, and social bots etc. exploit the network of trust by various means especially by creating fake profiles to spread their content and carry out scams. All these malicious identities are very harmful for both the users as well as the service providers. From the OSN service provider point of view, fake profiles affect the overall reputation of the network in addition to the loss of bandwidth. To spot out these malicious users, huge manpower effort and more sophisticated automated methods are needed. In this paper, various types of OSN threat generators like compromised profiles, cloned profiles and <b>online</b> <b>bots</b> (spam bots, social bots, like bots and influential bots) have been classified. An attempt is made to present several categories of features that have been used to train classifiers in order to identify a fake profile. Different data crawling approaches along with some existing data sources for fake profile detection have been identified. A refresher on existing cyber laws to curb social media based cyber crimes with their limitations is also presented. Comment: 31 pages, 8 figure...|$|R
40|$|In recent years, Botnets {{have been}} adopted as a popular method used to carry and spread many {{malicious}} codes on the Internet. These codes {{pave the way to}} conducting many fraudulent activities, including spam mail, distributed denial of service attacks (DDoS) and click fraud. While many Botnets are set up using a centralized communication architecture such as Internet Relay Chat (IRC) and Hypertext Transfer Protocol (HTTP), peer-to-peer (P 2 P) Botnets can adopt a decentralized architecture using an overlay network for exchanging command and control (C&C) messages, which is a more resilient and robust communication channel infrastructure. Without a centralized point for C&C servers, P 2 P Botnets are more flexible to defeat countermeasures and detection procedures than traditional centralized Botnets. Several Botnet detection techniques have been proposed, but Botnet detection is still a very challenging task for the Internet security community because Botnets execute attacks stealthily in the dramatically growing volumes of network traffic. However, current Botnet detection schemes face significant problem of efficiency and adaptability. The present study combined a traffic reduction approach with reinforcement learning (RL) method in order to create an <b>online</b> <b>Bot</b> detection system. The proposed framework adopts the idea of RL to improve the system dynamically over time. In addition, the traffic reduction method is used to set up a lightweight and fast online detection method. Moreover, a host feature based on traffic at the connection-level was designed, which can identify Bot host behaviour. Therefore, the proposed technique can potentially be applied to any encrypted network traffic since it depends only on the information obtained from packets header. Therefore, it does not require Deep Packet Inspection (DPI) and cannot be confused with payload encryption techniques. The network traffic reduction technique reduces packets input to the detection system, but the proposed solution achieves good a detection rate of 98. 3...|$|E
40|$|Bias is {{a common}} problem in today's media, {{appearing}} frequently in text and in visual imagery. Users on social media websites such as Twitter need better methods for identifying bias. Additionally, activists [...] those who are motivated to effect change related to some topic, need better methods to identify and counteract bias that is contrary to their mission. With both of these use cases in mind, {{in this paper we}} propose a novel tool called UnbiasedCrowd that supports identification of, and action on bias in visual news media. In particular, it addresses the following key challenges (1) identification of bias; (2) aggregation and presentation of evidence to users; (3) enabling activists to inform the public of bias and take action by engaging people in conversation with bots. We describe a preliminary study on the Twitter platform that explores the impressions that activists had of our tool, and how people reacted and engaged with <b>online</b> <b>bots</b> that exposed visual bias. We conclude by discussing design and implication of our findings for creating future systems to identify and counteract the effects of news bias. Comment: 6 pages, 6 figures, (Accepted) CHI 17 Extended Abstracts, May 06 - 11, 2017, Denver, CO, US...|$|R
40|$|First Person Shooter (FPS) is {{a popular}} genre in online gaming, {{unfortunately}} not everyone plays the game fairly, and this hinders {{the growth of the}} industry. The aiming robot (aimbot) is a common cheating mechanism employed in this genre, it differs from many other common <b>online</b> <b>bots</b> in that there is a human operating alongside the bot, and thus the in-game data exhibit both human and bot-like behaviour. The aimbot users can aim much better than the average player. However, there are also a large number of highly skilled players who can aim much better than the average player, some of these players have in the past been banned from servers due to false accusations from their peers. Therefore, {{it would be interesting to}} find out if and where the honest player's and the bot user's behaviour differ. In this paper we investigate the difference between the aiming abilities of aimbot users and honest human players. We introduce two novel features and have conducted an experiment using a modified open source FPS game. Our data shows that there is significant difference between behaviours of honest players and aimbot users. We propose a voting scheme to improve aimbot detection in FPS based on distribution matching, and have achieved approximately 93 % in both True positive and True negative rates with one of our features. © 2012 IEEE...|$|R
5000|$|In October 2014 to January 2015, the art {{collective}} !Mediengruppe Bitnik explored darknet {{culture in}} an exhibition in Switzerland entitled The Darknet: From Memes to Onionland, displaying the purchases of the Random Darknet Shopper, an automated <b>online</b> shopping <b>bot</b> which spent $100 in Bitcoins per week on Agora. The aim was to examine philosophical questions surrounding the darknet, such as the legal culpability {{of a piece of}} software or robot. The exhibition of the robot's purchases, a landscape of traded goods that included a bag of ten 120mg Ecstasy pills [...] "with no bullshit inside" [...] (containing 90mg of MDMA), was staged next-door to a police station near Zürich.|$|R
40|$|Virtual Reality Exposure Therapy (VRET) {{has been}} put forward as a {{treatment}} for patient suffering from anxiety disorder such as social phobia. Current VRET systems however provide limited speech interaction possibilities between the patient and virtual characters and therefore does not seems to offer patients an exposure to the full richness of an actual human-human dialogue. One way to support a free speech dialogue between a patient and a virtual character is to develop interactive pre-scripted dialogue scripts, where specific patient answers can trigger pre-recorded avatar responses thereby creating extensive dialogue trees. This paper discusses this approach and a dialogue editor to write these dialogue scripts. <b>Online</b> chat <b>bots</b> are proposed as a technique to evaluate and to improve an interactive dialogue script. Results of a pilot study with 4 non-phobic individuals are promising and suggest that these scripted interactive dialogues can be used to simulate a human-human dialogue...|$|R
50|$|Ultimate Knight Windom XP (Ultimate Knight ウィンダムXP Knight UindamuXP) or UKWXP, is a Japanese Indie game {{originally}} developed by Y. Kamada for the PC as {{a sequel to}} his previous work, the Bootfighter Windom XP SP-2. It features an assortment of 3D mechas which the player can control and use to fight battles, either <b>online</b> or versus <b>bot</b> opponents. The game is inspired by Japanese Mecha based on anime and video games with game-play resembling mech versus games on older consoles but with enhanced options such as the 60 FPS screen refresh rate, including online game-play capabilities.|$|R
40|$|The Random Darknet Shopper is an {{automated}} <b>online</b> shopping <b>bot</b> which we provide {{with a budget}} of $ 100 in Bitcoins per week. Once a week the bot goes shopping in the deep web where it randomly chooses and purchases one item and has it mailed directly to the exhibition space. Once the items arrive they are unpacked and displayed, each new object adding to a landscape of traded goods from the Darknet. The Random Darknet Shopper is a live Mail Art piece, {{an exploration of the}} deep web via the goods traded there. It directly connects the Darknet with the gallery. By randomizing its consumerism, the bot is guaranteed a wide selection of goods from the thousands listed on deepweb markets. In its first run from October 2014 - January 2015, Random Darknet Shopper bought 12 items from the deepweb market Agora, which were displayed at Kunst Halle St. Gallen in the exhibition «The Darknet - From Memes to Onionland. An Exploration». Since Agora discontinued its services in September, Random Darknet Shopper will now order items from Alpha Bay, currently the largest deepweb market place...|$|R
40|$|It is {{uncertain}} how many discreet users occupy the social media community. Fake tweets, sock puppets, force‐multipliers and botnets have become embedded within {{the fabric of}} new media in sufficient numbers that social media support by means of quantity {{is no longer a}} reliable metric for determining authority and influence within openly expressed issues and causes. Election campaigns, and their associated political agendas, can now be influenced by non‐specific virtual presences that cajole and redirect opinions without declaring identity or allegiance. In the lead up to the 2013 Australian Federal Election, the open source Twitter activity for the two major party leaders was examined in order to establish patterns of information diffusion. The results showed fake <b>online</b> personas, fake <b>bots</b> deploying automated Twitter dissemination, and deceptive Twitter strategies. New media tolerates slacktivism, where Twitter users mistake auto‐narrative for genuine political sentiment. This study demonstrates the need to increase legitimacy and validity in micro‐blogging forms of new media...|$|R
500|$|Although Halos overall {{reception}} {{was largely}} positive, the game received criticism for its level design. GameSpy commented, [...] "you'll trudge through countless hallways and control rooms that all look exactly the same, fighting identical-looking groups of enemies {{over and over}} and over...it is simply frustrating to see a game with such groundbreaking sequences too often degenerate [...] this kind of mindless, repetitive action." [...] Similarly, an article on Game Studies.org remarked, [...] "In {{the latter part of the}} game, the scenarios rely on repetition and quantity rather than innovativeness and quality." [...] Eurogamer concluded, [...] "Halo is very much a game of two halves. The first half is fast, exciting, beautifully designed and constantly full of surprises. The second half is festooned with gobsmacking plot twists and great cinematics but let down by repetitive paint by numbers level design." [...] Halo was released prior to the launch of Xbox Live, and the lack of both <b>online</b> multiplayer and <b>bots</b> to simulate human players was criticised by GameSpy; in 2003 GameSpy included Halo in a list of [...] "Top 25 Most Overrated Games of All Time." ...|$|R
40|$|In recent years, {{there has}} been a huge {{increase}} in the number of <b>bots</b> <b>online,</b> varying from Web crawlers for search engines, to chatbots for online customer service, spambots on social media, and content-editing <b>bots</b> in <b>online</b> collaboration communities. The online world has turned into an ecosystem of bots. However, our knowledge of how these automated agents are interacting with each other is rather poor. Bots are predictable automatons that do not have the capacity for emotions, meaning-making, creativity, and sociality and it is hence natural to expect interactions between bots to be relatively predictable and uneventful. In this article, we analyze the interactions between bots that edit articles on Wikipedia. We track the extent to which bots undid each other’s edits over the period 2001 – 2010, model how pairs of bots interact over time, and identify different types of interaction trajectories. We find that, although Wikipedia bots are intended to support the encyclopedia, they often undo each other’s edits and these sterile “fights” may sometimes continue for years. Unlike humans on Wikipedia, bots’ interactions tend to occur over longer periods of time and to be more reciprocated. Yet, just like humans, bots in different cultural environments may behave differently. Our research suggests that even relatively “dumb” bots may give rise to complex interactions, and this carries important implications for Artificial Intelligence research. Understanding what affects bot-bot interactions is crucial for managing social media well, providing adequate cyber-security, and designing well functioning autonomous vehicles...|$|R
5000|$|There are two ground vehicles, a jeep and a tank, and {{an armored}} {{personnel}} carrier is added by the Operation: Broken Mirror expansion. There are two air vehicles, the Warhawk and Nemesis (which are only cosmetically different), {{both of which}} can use nine weapons, {{an example is the}} AS-3 Tow Missile system. That weapon is the only weapon in the game where the player guides the weapon, the players screen is devoted to guiding the missile and leaving the player open to getting hit. But the upside is that it does massive damage and is the largest explosion in the game. The Omega Dawn expansion adds a dropship, and the Fallen Star expansion adds a jetpack. There are three turrets available to the player (anti-air missile turret, anti-air flak turret, and the [...]50 caliber anti-infantry machine gun). The game uses the PlayStation 3 Sixaxis and DualShock 3 controllers. The game can be set to make use of these controllers' motion sensing function to allow the players to control aircraft and ground vehicles by tilting the controller in different directions rather than the more conventional methods of using the D-pad or analog sticks. However, a traditional control scheme is the default option. Warhawk offers online and offline multiplayer play. Offline allows for 1-4 players splitscreen (without <b>bots).</b> <b>Online</b> features up to 32-player battles, with the ability to have up to 4 players use one PlayStation 3 in split screen mode (on non-ranked servers that permit it). Players 2-4 can enter or exit the game while a match is in progress.|$|R
30|$|Several {{studies for}} {{detecting}} game bots {{have been proposed}} in academia and industry. These studies can be classified into three categories: client-side, network-side, and server-side. Most game companies have adopted client-side detection methods that analyze game bot signatures as the primary measure against game bots. Client-side detection methods use the bot program’s name, process information, and memory status. This method is similar to antivirus programs that detect computer viruses (Mohaisen and Alrawi 2014). Client-side detection methods can be readily detoured by game bot developers, in addition to degrading the computer’s performance. For this reason, many countermeasures {{that are based on}} this approach, such as commercial anti-bot programs, are not currently preferred. Network-side detection methods, such as network traffic monitoring or network protocol change analysis, can cause network overload and lag in game play, a significant annoyance in the online gaming experience. To overcome these limitations of the client-side and network-side detection methods, many online game service providers employ server-side detection methods. Server-side detection methods are based on data mining techniques that analyze log data from game servers. Most game servers generate event logs whenever users perform actions such as hunting, harvesting, and chatting. Hence, these in-game logs facilitate data analysis as a possible method for detecting game <b>bots.</b> <b>Online</b> game companies analyze user behaviors or packets at the server-side, and then online game service providers can selectively block those game bot users that they want to ban without deploying additional programs on the client-side. For that, most online game service providers prefer server-side detection methods. In addition, some online game companies introduced big data analysis system approaches that make use of data-driven profiling and detection (Lee et al. 2016). Such approaches can analyze over 600 TB of logs generated by game servers and do not cause any side-effects, such as performance degradation or conflict with other programs.|$|R

