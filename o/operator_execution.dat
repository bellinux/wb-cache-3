10|70|Public
40|$|Abstract—In our {{previous}} work we proposed some {{extensions of the}} Levenberg-Marquardt algorithm; the Bacterial Memetic Algorithm and the Bacterial Memetic Algorithm with Modified <b>Operator</b> <b>Execution</b> Order for fuzzy rule base extraction from inputoutput data. Furthermore, we have investigated fuzzy flip-flop based feedforward neural networks. In this paper we introduce the adaptation of the Bacterial Memetic Algorithm with Modified <b>Operator</b> <b>Execution</b> Order for training feedforward and fuzzy flipflop based neural networks. We found that training these types of neural networks with the adaptation of the method we had used to train fuzzy rule bases had advantages over the conventional earlier methods...|$|E
40|$|Accurate {{prediction}} of <b>operator</b> <b>execution</b> {{time is a}} prerequisite for database query optimization. Although extensively studied for conventional disk-based DBMSs, cost modeling in main-memory DBMSs is still an open issue. Recent database research has demonstrated that memory access is more and more becoming a significant [...] if not the major [...] cost component of database operations. If used properly, fast but small cache memories [...] usually organized in cascading hierarchy between CPU and main memory [...] can help to reduce memory access costs. However, they make the cost estimation problem more complex...|$|E
40|$|Query {{parallelism}} improves serial query execution {{performance by}} orders of magnitude. Getting optimal performance from an already parallelized query plan is however difficult {{due to its}} dependency on run time factors such as correct operator scheduling, memory pressure, disk io performance, and operating system noise. Identifying the exact problems in a parallel query execution is difficult due to inter-dependence of these factors. In this paper we present Tomograph, a tool to visualize the parallel query execution performance bottlenecks. Tomograph provides a time ordered view of <b>operator</b> <b>execution</b> aligned with cpu, memory, and disk IO usage, in an operator at a time execution model. We discuss the usage of Tomograph to identify parallelism issues such as low multi-core utilization, erroneous operator scheduling, incorrect data partitioning, and blocking operators. We share our experiences, insights gained and discuss possible solutions to the identified problems...|$|E
5000|$|Skill-Based Errors: Errors which {{occur in}} the <b>operator’s</b> <b>execution</b> of a routine, highly practiced task {{relating}} to procedure, training or proficiency and result in an unsafe a situation (e.g., fail to prioritize attention, checklist error, negative habit).|$|R
5000|$|Multiple {{implementations}} of {{finite element}} <b>operators</b> for efficient <b>execution</b> {{on a wide}} range of CPU architectures; ...|$|R
30|$|In {{this section}} we start by {{analyzing}} overall structure of original algorithm. Then {{we continue with}} the parallelization of Euclidean distance, thinning and thickening algorithm. We conclude by a performance analysis of the entire smoothing topological <b>operator.</b> Obtained <b>execution</b> time, efficiency, speedup and cache misses will be introduced and discussed.|$|R
40|$|A {{shared-nothing}} {{architecture is}} state-of-the-art for deploying a distributed analytical in-memory database management system: it preserves the in-memory performance advantage by processing data locally on each node but {{is difficult to}} scale out. Modern switched fabric communication links such as InfiniBand narrow the performance gap between local and remote DRAM data access to a single order of magnitude. Based on these premises, we introduce a distributed in-memory database architecture that separates the query execution engine and data access: this enables a) the usage of a large-scale DRAM-based storage system such as Stanford’s RAM-Cloud and b) the push-down of bandwidth-intensive database operators into the storage system. We address the resulting challenges such as finding the optimal <b>operator</b> <b>execution</b> strategy and partitioning scheme. We demonstrate that such an architecture delivers both: the elasticity of a shared-storage approach and the performance characteristics of operating on local DRAM...|$|E
40|$|Aggregate Continuous Queries (ACQs) {{are both}} {{a very popular}} class of Continuous Queries (CQs) and also have a {{potentially}} high execution cost. As such, optimizing the processing of ACQs is imperative for Data Stream Management Systems (DSMSs) to reach their full potential in supporting (critical) monitoring applications. For multiple ACQs that vary in window specifications and pre-aggregation filters, existing multiple ACQs optimization schemes assume a processing model where each ACQ is computed as a final-aggregation of a sub-aggregation. In this paper, we propose a novel processing model for ACQs, called Tri Ops, {{with the goal of}} minimizing the repetition of <b>operator</b> <b>execution</b> at the sub-aggregation level. We also propose Tri Weave, a Tri Ops-aware multi-query optimizer. We analytically and experimentally demonstrate the performance gains of our proposed schemes which shows their superiority over alternative schemes. Finally, we generalize Tri Weave to incorporate the classical subsumption-based multi-query optimization techniques...|$|E
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThe Computer Aided Prototyping System (CAPS) and the Prototype System Description Language (PSDL) represent a pioneering {{effort in the}} field of software development. The implementation of CAPS will enable software engineers to automatically validate design specifications and functional requirements early in the design of a software system through the development and execution of a prototype of the system under construction. Execution of the prototype is controlled by an Execution Support System (ESS) within the framework of CAPS. One of the critical elements of the ESS is the Static Scheduler which extracts critical timing constraints and precedence information about operators from the PSDL source that describes the prototype. The Static Scheduler then uses this information to determine whether a feasible schedule can be built, and if it can, constructs the schedule for <b>operator</b> <b>execution</b> within the prototype. [URL] Commander, United States Nav...|$|E
40|$|International audienceHarmony search (HS), as an {{emerging}} metaheuristic technique mimicking the improvisation behavior of musicians, has demonstrated strong efficacy in solving various numerical and real-world optimization problems. This work presents a harmony search with differential mutation based pitch adjustment (HSDM) algorithm, which improves the original pitch adjustment operator of HS using the self-referential differential mutation scheme that features differential evolution - another celebrated metaheuristic algorithm. In HSDM, the differential mutation based pitch adjustment can dynamically adapt {{the properties of}} the landscapes being explored at different searching stages. Meanwhile, the pitch adjustment <b>operator's</b> <b>execution</b> probability is allowed to vary randomly between 0 and 1, which can maintain both wild and fine exploitation throughout the searching course. HSDM has been evaluated and compared to the original HS and two recent HS variants using 16 numerical test problems of various searching landscape complexities at 10 and 30 dimensions. HSDM almost always demonstrates superiority on all test problems...|$|R
40|$|Complex complex dynamic {{systems are}} usually {{controlled}} by operators who acquired their skill {{through years of}} experience. Typically, such a control skill is sub-cognitive and hard to reconstruct through introspection. The operators cannot completely describe their skill, but can demonstrate it. Therefore an attractive approach to the reconstruction of human control skill involves machine learning from <b>operator's</b> <b>execution</b> traces. The goal is to induce {{a model of the}} operator's skill, a control strategy that helps to understand the skill and can be used to control the system. Behavioural cloning is an approach to such skill reconstruction, In the most common approach to behavioural cloning a strategy is induced as a direct mapping from system's states to actions {{in the form of a}} decision or regression tree. This thesis develops new ideas to tackle problems that were generally observed with the mentioned approach to human skill reconstruction. One idea is to decompose the learning proble [...] ...|$|R
5000|$|The {{graphical}} interface modules (topology manager, designer, security manager, <b>operator)</b> and the <b>execution</b> agents (agent). These {{are entirely}} built with Java components that give {{access to the}} repository in client/server mode.|$|R
40|$|Recently, {{real-time}} planning {{has been}} actively studied for solving problems in uncertain and dy-namic environments. RTA * is a real-time search algorithm {{that can provide}} a computational ba-sis for real-time planning. However, RTA * is not always efficient since obtaining effective heuristic functions is difficult when the problem becomes complicated. In {{order to keep the}} problem sim-ple enough for efficient search, we propose an algorithm called RTSS, which incorporates the STRIPS subgoaling function into RTA*. This algorithm interleaves subgoaling and real-time search processes by evaluating the goal complex-ity and the ease of <b>operator</b> <b>execution.</b> An anal-ysis using a simple model shows that the search cost can be significantly reduced by switching be-tween subgoaling and real-time search. Further-more, experiments on a robot task planning prob-lem show that RTSS can attain the goal without performing many superfluous actions, while other algorithms often tend to perform a blind search that hils to attain the goal...|$|E
40|$|Abstract — Wireless sensor {{networks}} is {{an emerging}} technology that can significantly {{improve the quality}} of spatio-temporal data monitoring because of their untethered operation and potential for large scale deployment. In this paper, we define a communication architecture that supports distributed query processing to evaluate spatio-temporal queries within the network. We represent these queries by query trees and distribute query operators to appropriate sensor nodes. As <b>operator</b> <b>execution</b> demands high computation capability, we propose use of a heterogenous sensor network where query operators are assigned to sparsely deployed resource-rich nodes within a dense network of low power sensor nodes. We design an adaptive, decentralized, low communication overhead algorithm to determine an operator placement on the resource-rich nodes in the network to minimize cost of transmitting data along a routing tree constructed to continuously retrieve data at the sink, from a set of spatially distributed geographical regions. To the best of our knowledge, this is the first attempt to build an energy aware routing infrastructure to enable in-network processing of spatio-temporal queries. I...|$|E
40|$|In {{this thesis}} we present the {{holistic}} query evaluation model. We propose a novel query engine design that exploits {{the characteristics of}} modern processors when queries execute inside main memory. The holistic model (a) is based on template-based code generation for each executed query, (b) uses multithreading to adapt to multicore processor architectures and (c) addresses the optimization problem of scheduling multiple threads for intra-query parallelism. Main-memory query execution is a usual operation in modern database servers equipped with tens or hundreds of gigabytes of RAM. In such an execution environment, the query engine needs {{to adapt to the}} CPU characteristics to boost performance. For this purpose, holistic query evaluation applies customized code generation to database query evaluation. The idea is to use a collection of highly efficient code templates and dynamically instantiate them to create query- and hardware-specific source code. The source code is compiled and dynamically linked to the database server for processing. Code generation diminishes the bloat of higher-level programming abstractions necessary for implementing generic, interpreted, SQL query engines. At the same time, the generated code is customized for the hardware it will run on. The holistic model supports the most frequently used query processing algorithms, namely sorting, partitioning, join evaluation, and aggregation, thus allowing the efficient evaluation of complex DSS or OLAP queries. Modern CPUs follow multicore designs with multiple threads running in parallel. The dataflow of query engine algorithms needs to be adapted to exploit such designs. We identify memory accesses and thread synchronization as the main bottlenecks in a multicore execution environment. We extend the holistic query evaluation model and propose techniques to mitigate the impact of these bottlenecks on multithreaded query evaluation. We analytically model the expected performance and scalability of the proposed algorithms according to the hardware specifications. The analytical performance expressions can be used by the optimizer to statically estimate the speedup of multithreaded query execution. Finally, we examine the problem of thread scheduling in the context of multithreaded query evaluation on multicore CPUs. The search space for possible <b>operator</b> <b>execution</b> schedules scales fast, thus forbidding the use of exhaustive techniques. We model intra-query parallelism on multicore systems and present scheduling heuristics that result in different degrees of schedule quality and optimization cost. We identify cases where each of our proposed algorithms, or combinations of them, are expected to generate schedules of high quality at an acceptable running cost. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
2500|$|In 2002, the duo {{began working}} on , a satire of big-budget action films and their {{associated}} clichés and stereotypes, with particular humorous emphasis on the global implications {{of the politics of}} the United States. Starring puppets, Team America was produced using a crew of about 200 people, which sometimes required four people at a time to manipulate a marionette. Although the filmmakers hired three dozen highly skilled marionette <b>operators,</b> <b>execution</b> of some very simple acts by the marionettes proved to be very difficult, with a simple shot such as a character drinking taking a half-day to complete successfully. The deadline for the film's completion took a toll on both filmmakers, as did various difficulties in working with puppets, with Stone, who described the film as [...] "the worst time of [...] life", resorting to coffee to work 20-hour days and sleeping pills to go to bed. The film was barely completed in time for its October release date, but reviews were positive and the film made a modest sum at the box office.|$|R
50|$|NGOMSL is a {{structured}} natural language notation for representing GOMS models and a procedure for constructing them. This program form provides predictions of <b>operator</b> sequences, <b>execution</b> {{time and time}} to learn methods.An analyst constructs an NGOMSL model by performing a top-down, breadth-first expansion of the user's top-level goals into methods, until the methods contain only primitiveoperators, typically keystroke-level operators. This model explicitly represents the goal structure just like the CMN-GOMS and can so represent high-level goals. Shown below is a simple example.|$|R
40|$|Recently, mobile {{security}} has garnered considerable interest {{in both the}} research community and industry due to the popularity of smartphones. The current smartphone platforms are open systems that allow application development, also for malicious parties. To protect the mobile device, its user, and other mobile ecosystem stakeholders such as network <b>operators,</b> application <b>execution</b> is controlled by a platform security architecture. This book explores how such mobile platform security architectures work. We present a generic model for mobile platform security architectures: the model illustra...|$|R
40|$|Abstract — This paper {{introduces}} a view on planning {{that is based}} on interpreting objects not by their identity but by their functionality. Ecological psychologist J. J. Gibson’s concept of affordances provides the underlying theory for developing a system that does not distinguish between objects of functional equivalence. It will be argued that the plans resulting from this approach are both less complex and still more flexible and robust in their application while proposing solutions to symbol grounding of objects in the environment and planning <b>operators</b> in <b>execution</b> behaviors. The system will be presented by example...|$|R
40|$|This paper {{proposes a}} control scheme {{applied to the}} delayed {{bilateral}} teleoperation of wheeled robots with force feedback, considering {{the performance of the}} <b>operator’s</b> command <b>execution.</b> In addition, the stability of the system is analyzed taking into account the dynamic model of the master as well as the remote mobile robot under asymmetric and time-varying delays of the communication channel. Besides, the performance of the teleoperation system, where a human operator drives a 3 D simulator of a wheeled dynamic robot, is evaluated. In addition, we present an experiment where a robot Pioneer is teleoperated, based on the system architecture proposed...|$|R
40|$|International audienceBig Data {{analytics}} {{has recently}} gained increasing popularity {{as a tool}} to process large amounts of data on-demand. Spark and Flink are two Apache-hosted data analytics frameworks that facilitate the development of multi-step data pipelines using directly acyclic graph patterns. Making the most out of these frameworks is challenging because efficient executions strongly rely on complex parameter configurations and on an in-depth understanding of the underlying architectural choices. Although extensive research has been devoted to improving and evaluating the performance of such analytics frameworks, most of them benchmark the platforms against Hadoop, as a baseline, a rather unfair comparison considering the fundamentally different design principles. This paper aims to bring some justice in this respect, by directly evaluating the performance of Spark and Flink. Our goal is to identify and explain the impact of the different architectural choices and the parameter configurations on the perceived end-to-end performance. To this end, we develop a methodology for correlating the parameter settings and the <b>operators</b> <b>execution</b> plan with the resource usage. We use this methodology to dissect the performance of Spark and Flink with several representative batch and iterative workloads on up to 100 nodes. Our key finding is that there none of the two framework outperforms the other for all data types, sizes and job patterns. This paper performs a fine characterization of the cases when each framework is superior, and we highlight how this performance correlates to operators, to resource usage and to the specifics of the internal framework design...|$|R
40|$|Abstract — Due to its {{considerable}} ease of use, relational keyword search (R-KWS) {{has become}} increasingly popular. Its simplicity, however, comes {{at the cost of}} intensive query processing. Specifically, R-KWS explores a vast search space, comprised of all possible combinations of keyword occurrences in any attribute of every table. Existing systems follow two general methodologies for query processing: (i) graph based, which traverses a materialized data graph, and (ii) operator based, which executes relational operator trees on an underlying DBMS. In both cases, computations are largely wasted on graph traversals or <b>operator</b> tree <b>executions</b> that fail to return results. Motivated by this observation, we introduce a comprehensive framework for reachability indexing that eliminates such fruitless operations. We describe a range of indexes that capture various types of join reachability. Extensive experiments demonstrate that the proposed techniques significantly improve performance, often by several orders of magnitude...|$|R
40|$|In essence, the {{underlying}} ultimate purpose of classical deliberative planning systems is to model some world task and generate plans that {{can then be}} executed. Execution systems rely {{on the assumption that}} there is a built-in library of a variety of plans and primitive actions for performing tasks. Although hard and time consuming, such libraries of execution plans and actions are usually handcoded. Faced with two different systems, a planner and an executor, we analyze in this work the representational map between planning actions and partially-ordered plans and the execution knowledge. We developed algorithms to automatically translate classical planning <b>operators</b> to <b>execution</b> primitive actions, and partially-ordered plans into executable tasks with partially ordered subtasks. We implemented our work using the prodigy planner and the rap execution system. We provide illustrative examples of how partially-ordered plans produced by prodigy are translated to Reactive Action Packages s [...] ...|$|R
40|$|The Dslash {{operator}} {{is used in}} Lattice Quantum Chromodymamics (LQCD) {{applications to}} implement a Wilson-Dirac sparse matrix-vector product. Typically the Dslash operation has been implemented as a parallel program. Today’s Graphics Processing Units (GPU) are designed to do highly parallel numerical calculations for 3 D graphics rendering. This design works well with scientific applications such as LQCD’s implementation of the Dslash operator. The Scientific Computing group at the Thomas Jefferson National Accelerator Facility (Jefferson Lab) has implemented the Dslash <b>operator</b> for <b>execution</b> on GPUs using NVIDIA’s Compute Unified Device Architecture (CUDA). CUDA applications, however, will only run on NVIDIA hardware. OpenCL (Open Computing Language) is a new open standard for developing parallel programs across CPUs, GPUs and other processors. This paper describes {{the implementation of the}} Dslash operator using OpenCL (Open Computing Language), its performance on NVIDIA GPUs compared with CUDA, and its performance on other hardware platforms...|$|R
40|$|International Telemetering Conference Proceedings / November 19 - 21, 1979 / Town and Country Hotel, San Diego, CaliforniaThe Command and Data Handling System {{which is}} part of the NASA Multi-mission Modular Spacecraft (MMS) {{represents}} a versatile time division multiple access approach to processing spacecraft commands and retrieving data on real-time, delayed or preprogrammed basis. This paper traces the command signals from <b>operator</b> keyboard to <b>execution</b> within the spacecraft and telemetry/data signals from on-board spacecraft measurement to display on the operator's CRT page. Key technical features throughout this end-to-end signal processing loop are described and discussed...|$|R
40|$|Due to the expensiveness of {{compiling}} and executing a {{large number}} of mutants, it is usually necessary to select a subset of mutants to substitute the whole set of generated mutants in mutation testing and analysis. Most existing research on mutant selection focused on operator-based mutant selection, i. e., determining a set of sufficient mutation operators and selecting mutants generated with only this set of mutation operators. Recently, researchers began to leverage statistical analysis to determine sufficient mutation <b>operators</b> using <b>execution</b> information of mutants. However, whether mutants selected with these sophisticated techniques are superior to randomly selected mutants remains an open question. In this paper, we empirically investigate this open question by comparing three representative operator-based mutant-selection techniques with two random techniques. Our empirical results show that operator-based mutant selection is not superior to random mutant selection. These results also indicate that random mutant selection can be a better choice and mutant selection on the basis of individual mutants is worthy of further investigation...|$|R
40|$|The query {{processing}} {{in large}} scale distributed mediations systems raises new problems and presents real challenges: efficiency of access, communication, confidentiality of access, availability of data, memory allocation. In this paper, we propose an execution model based on mobile agents for the distributed dynamic query optimization. In this model, each relational <b>operator</b> of an <b>execution</b> plan is executed by a mobile agent. Also, we embed into agent a migration policy allowing agent {{to choose an}} execution site among execution sites of the considered system. The performance evaluation shows that the proposed model improves the response time whatever the variation of estimations errors...|$|R
40|$|The {{development}} {{and objectives of}} the NASA automation and robotics technology program are reviewed. The objectives of the program are to utilize AI and robotics to increase the probability of mission success; decrease the cost of ground control; and increase the capability and flexibility of space operations. There {{is a need for}} real-time computational capability; an effective man-machine interface; and techniques to validate automated systems. Current programs in the areas of sensing and perception, task planning and reasoning, control <b>execution,</b> <b>operator</b> interface, and system architecture and integration are described. Programs aimed at demonstrating the capabilities of telerobotics and system autonomy are discussed...|$|R
40|$|Abstract|In {{this paper}} two methods are {{presented}} {{so that it}} is possible to process the feedback of the errors produced by a teleoperated robot, using a voice interface with natural language processing capabilities. The solutions proposed in this paper had its initial motivations on the following ques-tions: (1) To ¯nd a method to process the feedback pro-duced by the user during the execution of a teleoperated command, expressed using a voice interface, and (2) how can the system use the information provided by the feed-back process so that the robot behaves in the way desired by the <b>operator</b> in successive <b>executions</b> of the task...|$|R
40|$|International audienceReplicating data {{fragments}} in Linked Data improves {{data availability}} and performances of federated query engines. Existing replication aware federated query engines mainly focus on source selection and query decomposition {{in order to}} prune redundant sources and reduce intermediate results thanks to data locality. In this paper, we extend replication-aware federated query engines with a replication-aware parallel join operator: PeNeLoop. PeNeLoop exploits redundant sources to parallelize the join <b>operator</b> and reduce <b>execution</b> time. We implemented PeNeLoop in the federated query engine FedX with the replicated-aware source selection Fedra and we empirically evaluated the performance of FedX+Fedra+PeNeLoop. Experimental results suggest that FedX+Fedra+PeNeLoop outperforms FedX+Fedra in terms of execution time while preserving answer completeness...|$|R
40|$|This paper {{addresses}} {{the problem of}} ensuring that agents' plans are epistemically feasible in multiagent systems specifications. We propose some solutions within the CASL formalism. We define a subjective execution construct Subj that causes the plan to be executed {{in terms of the}} agent's knowledge state rather than in therms of the world state. The definition assumes that the agent does not do planning or lookahead and chooses arbitrarily among the actions allowed by the plan. We also define another deliberative <b>execution</b> <b>operator</b> Delib for smarter agents that do planning. We show how these notions can be used to express whether a plan is epistemically feasible for an agent in several types of situations. ...|$|R
40|$|Pervasive {{computing}} applications monitor physical-world {{phenomena and}} integrate data acquisition, communication and actions across small, heterogeneous devices (e. g., smart sensors, network cameras and handheld devices). To ease {{the development of}} these applications, we propose to perform their tasks by executing action-embedded queries, which are continuous queries with operations towards devices. We extend SQL to allow applications to specify actions and action-embedded queries. We treat actions as first-class citizens (<b>operators)</b> in query <b>execution</b> plans, and investigate adaptive, costbased optimization techniques for a single query as well as for multiple queries. We evaluate our prototype query processor, Aorta, using a pervasive lab monitoring application. The initial experimental results show that Aorta ensures correct application semantics, improves query response time and balances device workload. 1...|$|R
40|$|Abstract—We {{describe}} a novel application of using data mining and statistical learning methods to automatically monitor and detect abnormal execution traces from console logs {{in an online}} setting. Different from existing solutions, we use a two stage detection system. The first stage uses frequent pattern mining and distribution estimation techniques to capture the dominant patterns (both frequent sequences and time duration). The second stage use principal component analysis based anomaly detection method to identify actual problems. Using real system data from a 203 -node Hadoop cluster, we show {{that we can not}} only achieve highly accurate and fast problem detection, but also help <b>operators</b> better understand <b>execution</b> patterns in their system. I. MOTIVATION AND OVERVIEW Internet services today often run in data centers consistin...|$|R
40|$|Abstract: This paper {{focuses on}} the study and the {{experimentation}} of a glove interface for robotics and virtual reality applications. The system can acquire the phalanxes position and force of an <b>operator</b> during the <b>execution</b> of a grasp. We show {{how it is possible}} to use and integrate this data in order to permit the user to interact with a synthetic world. In particular the system we designed can reproduce tactile and force sensation. Electrodes and actuators are activated according to the information coming from the real world (position and force of the user’s finger) and from a physical model that represents the virtual object. We also report some psychophysical experiments we conducted on five subjects, in this case only the electro-tactile stimulator was used in order to generate a touch sensation. ...|$|R
40|$|Traditional {{database}} systems execute queries {{using one}} query multiple operators approach. Such systems do not cash {{on the common}} data or computation {{which could be used}} by multiple queries. Thus leading to poor performance. To overcome these deficiencies, Staged-DB approach has been proposed, where the philosophy is one operator multiple queries. A Staged-DB system splits a traditional DBMS into a num-ber of stages and handles a stage independently. In this project we evaluate the performance of a Staged-DB system under different scheduling policies. Our study is limited to scheduling various components that constitute the execu-tion stage of a Staged-DB. We evaluate different schedul-ing policies that fix the order in which various <b>operators</b> in the <b>execution</b> stage should be executed. We demonstrate the performance of the policies in terms of response time, throughput, and memory consumption...|$|R
40|$|These {{proceedings}} {{report the}} results of a workshop on space telerobotics, which was held at the Jet Propulsion Laboratory, January 20 - 22, 1987. Sponsored by the NASA Office of Aeronautics and Space Technology (OAST), the Workshop reflected NASA's interest in developing new telerobotics technology for automating the space systems planned for the 1990 s and beyond. The workshop provided a window into NASA telerobotics research, allowing leading researchers in telerobotics to exchange ideas on manipulation, control, system architectures, artificial intelligence, and machine sensing. One of the objectives was to identify important unsolved problems of current interest. The workshop consisted of surveys, tutorials, and contributed papers of both theoretical and practical interest. Several sessions were held on the themes of sensing and perception, control <b>execution,</b> <b>operator</b> interface, planning and reasoning, and system architecture...|$|R
