221|1171|Public
2500|$|The image {{distance}} [...] {{is related to}} an <b>object</b> <b>distance</b> [...] by the thin lens equation ...|$|E
2500|$|Using a {{positive}} lens of focal length f, a virtual image results when , the lens thus being used {{a magnifying glass}} (rather than if [...] as for a camera). Using a negative lens (...) with a real object (...) can only produce a virtual image (...) , {{according to the above}} formula. It is also possible for the <b>object</b> <b>distance</b> S1 to be negative, in which case the lens sees a so-called virtual object. This happens when the lens is inserted into a converging beam (being focused by a previous lens) before the location of its real image. In that case even a negative lens can project a real image, as is done by a Barlow lens.|$|E
2500|$|The {{distance}} {{scales on}} most medium- and small-format lenses indicate {{distance from the}} camera's image plane. Most DOF formulas, including those in this article, use the <b>object</b> <b>distance</b> [...] from the lens's front nodal plane, which often {{is not easy to}} locate. Moreover, for many zoom lenses and internal-focusing non-zoom lenses, the location of the front nodal plane, as well as focal length, changes with subject distance. When the subject distance is large in comparison with the lens focal length, the exact location of the front nodal plane is not critical; the distance is essentially the same whether measured {{from the front of the}} lens, the image plane, or the actual nodal plane. The same is not true for close-up photography; at unity magnification, a slight error in the location of the front nodal plane can result in a DOF error greater than the errors from any approximations in the DOF equations.|$|E
5000|$|... yu and yv are of {{opposite}} sense, so the magnification is negative, indicating {{an inverted}} image. From similar triangles in Figure 6, the magnification also relates {{the image and}} <b>object</b> <b>distances,</b> so that ...|$|R
50|$|Increasing the <b>object's</b> <b>distance</b> {{from the}} {{audience}} makes an object appear smaller, its apparent size decreases as distance {{from the audience}} increases. This phenomenon {{is that of the}} manipulation of angular and apparent size.|$|R
40|$|This paper {{presents}} a dual-mode spectral imaging system, which allows switching between pure lateral imaging and the spectrally resolved recording of spatial information. The optical system {{was equipped with}} tunable functionalities {{in order to achieve}} high flexibility, cover a wide range of <b>object</b> <b>distances,</b> and address extended field angles. A fluidic membrane lens was used for the variable focus, and the recording of the laterally extended scene was made possible by successively adjusting the different tilting angles to the different object positions. The capability and performance of the spectral imaging system were assessed using various test scenes, with different aimed field positions and changing <b>object</b> <b>distances...</b>|$|R
5000|$|The image {{distance}} [...] {{is related to}} an <b>object</b> <b>distance</b> [...] by the thin lens equation ...|$|E
5000|$|By tracing these rays, the {{relationship}} between the <b>object</b> <b>distance</b> s and the image distance s′ can be shown to be ...|$|E
5000|$|The {{relationship}} between the <b>object</b> <b>distance</b> u, the image distance v, and the lens focal length f is given by the thin-lens equation ...|$|E
50|$|The {{amplitude}} of accommodation is the maximum potential increase in optical power that an eye can achieve in adjusting its focus. It {{refers to a}} certain range of <b>object</b> <b>distances</b> for which the retinal image is as sharply focussed as possible.|$|R
50|$|Connectivity based {{clustering}} is a {{whole family}} of methods that differ by the way distances are computed. Apart from the usual choice of distance functions, the user also needs {{to decide on the}} linkage criterion (since a cluster consists of multiple objects, there are multiple candidates to compute the distance to) to use. Popular choices are known as single-linkage clustering (the minimum of <b>object</b> <b>distances),</b> complete linkage clustering (the maximum of <b>object</b> <b>distances)</b> or UPGMA ("Unweighted Pair Group Method with Arithmetic Mean", also known as average linkage clustering). Furthermore, hierarchical clustering can be agglomerative (starting with single elements and aggregating them into clusters) or divisive (starting with the complete data set and dividing it into partitions).|$|R
40|$|In this paper, we {{demonstrate}} light field triangulation {{to determine}} depth distances and baselines in a plenoptic camera. Advances in micro lenses and image sensors have enabled plenoptic cameras {{to capture a}} scene from different viewpoints with sufficient spatial resolution. While <b>object</b> <b>distances</b> can be inferred from disparities in a stereo viewpoint pair using triangulation, this concept remains ambiguous when applied {{in the case of}} plenoptic cameras. We present a geometrical light field model allowing the triangulation to be applied to a plenoptic camera in order to predict <b>object</b> <b>distances</b> or specify baselines as desired. It is shown that distance estimates from our novel method match those of real objects placed in front of the camera. Additional benchmark tests with an optical design software further validate the model’s accuracy with deviations of less than ± 0. 33...|$|R
5000|$|The Gaussian mirror equation, {{also known}} as the mirror and lens equation, relates the <b>object</b> <b>{{distance}}</b> [...] and image distance [...] to the focal length : ...|$|E
50|$|The sensors emit {{acoustic}} pulses, with {{a control}} unit measuring the return interval of each reflected signal and calculating object distances. The system in turns warns the driver with acoustic tones, the frequency indicating <b>object</b> <b>distance,</b> with faster tones indicating closer proximity and a continuous tone indicating a minimal pre-defined distance. Systems may also include visual aids, such as LED or LCD readouts to indicate <b>object</b> <b>distance.</b> A vehicle may include a vehicle pictogram on the car's infotainment screen, with {{a representation of the}} nearby objects as coloured blocks.|$|E
50|$|By optical convention, both {{object and}} image {{distances}} are positive for real images, {{so that in}} Figure 6, the <b>object</b> <b>distance</b> u increases {{to the left of}} the lens plane LP; the vertical axis uses the normal Cartesian convention, with values above the optical axis positive and those below the optical axis negative.|$|E
5000|$|GRB 101225A, {{also known}} as the [...] "Christmas burst", was a cosmic {{explosion}} first detected by NASA's Swift observatory on Christmas Day 2010. The gamma-ray emission lasted at least 28 minutes, which is unusually long. Follow-up observations of the burst's afterglow by the Hubble Space Telescope and ground-based observatories were unable to determine the <b>object's</b> <b>distance</b> using spectroscopic methods.|$|R
40|$|In photogrammetric applications, good camera {{parameters}} {{are needed for}} mapping purpose such as an Unmanned Aerial Vehicle (UAV) that encompassed with non-metric camera devices. Simple camera calibration was being a common application in many laboratory works {{in order to get}} the camera parameter’s value. In aerial mapping, interior camera parameters’ value from close-range camera calibration is used to correct the image error. However, the causes and effects of the calibration steps used to get accurate mapping need to be analyze. Therefore, this research aims to contribute an analysis of camera parameters from portable calibration frame of 1. 5 × 1 meter dimension size. <b>Object</b> <b>distances</b> of two, three, four, five, and six meters are the research focus. Results are analyzed to find out the changes in image and camera parameters’ value. Hence, camera calibration parameter’s of a camera is consider different depend on type of calibration parameters and <b>object</b> <b>distances.</b> ...|$|R
40|$|This {{interactive}} animation is {{very similar}} to the one with the convex lens you have used before. Here, too, you can click on the object and drag it to different positions, so you can observe what happens to the image. But now, you are able to move the object not only up to the focal point, but even closer to the lens. Look what happens when the object passes the focal point! Suddenly, the real image is gone, and a virtual, enlarged image appears instead as soon as the object gets closer to the lens than the focal point. Again, since this is a virtual image, it is shown striped. Play with this animation until you feel you understand what happens. Make sure you are able to answer the questions: For what <b>object</b> <b>distances</b> does a convex lens produce a real image? For what <b>object</b> <b>distances</b> a virtual image?CCRAA (College Cost Reduction and Accessibility Act) GrantTQE (Teacher Quality Enhancement) Gran...|$|R
5000|$|For concave mirrors, {{whether the}} image is virtual or real depends on how large the <b>object</b> <b>distance</b> is {{compared}} to the focal length. If the [...] term {{is larger than the}} [...] term, [...] is positive and {{the image is}} real. Otherwise, the term is negative and the image is virtual. Again, this validates the behavior described above.|$|E
50|$|Focus is the {{tendency}} for light rays to reach the same place on the image sensor or film, independent of where they pass through the lens. For clear pictures, the focus is adjusted for distance, because at a different <b>object</b> <b>distance</b> the rays reach {{different parts of the}} lens with different angles. In modern photography, focusing is often accomplished automatically.|$|E
50|$|The {{depth of}} field is {{basically}} infinite, {{but this does not}} mean that no optical blurring occurs. The infinite {{depth of field}} means that image blur depends not on <b>object</b> <b>distance,</b> but on other factors, such as the distance from the aperture to the film plane, the aperture size, the wavelength(s) of the light source, and motion of the subject or canvas.|$|E
2500|$|... where [...] for {{lateral motion}} is {{generally}} [...] 0.0087 rad/s with probable dependence on {{deviation from the}} fovia and movement orientation, velocity {{is in terms of}} the distance units, and zero distance is straight ahead. Far <b>object</b> <b>distances,</b> close set-backs, and low velocities generally lower the salience of lateral motion. Detection with close or null set-back can be accomplished through the pure scale changes of looming motion.|$|R
5000|$|Strictly speaking, {{macrophotography}} is technical photography {{with actual}} image size ranging from near life-size (1:1 image-to-object ratio) to about ten or twenty times life-size (10 or 20:1 ratio, at which photomicrography begins). [...] "Macro" [...] lenses were originally regular formula lenses optimized for close <b>object</b> <b>distances,</b> {{mounted on a}} long extension tube or bellows accessory to provide the necessary close focusing, but preventing focusing on distant objects.|$|R
5000|$|... where [...] for {{lateral motion}} is {{generally}} &ge; 0.0087 rad/s with probable dependence on {{deviation from the}} fovia and movement orientation, velocity {{is in terms of}} the distance units, and zero distance is straight ahead. Far <b>object</b> <b>distances,</b> close set-backs, and low velocities generally lower the salience of lateral motion. Detection with close or null set-back can be accomplished through the pure scale changes of looming motion.|$|R
5000|$|For simple designs one can {{sometimes}} calculate parameters that minimize spherical aberration. For example, in a design {{consisting of a}} single lens with spherical surfaces and a given <b>object</b> <b>distance</b> o, image distance i, and refractive index n, one can minimize spherical aberration by adjusting the radii of curvature [...] and [...] of {{the front and back}} surfaces of the lens such that ...|$|E
50|$|Overhead {{projectors}} normally {{include a}} manual focusing mechanism which raises and lowers {{the position of}} the focusing lens (including the folding mirror) in order to adjust the <b>object</b> <b>distance</b> (optical distance between the slide and the lens) to focus at the chosen image distance (distance to the projection screen) given the fixed focal length of the focusing lens. This permits a range of projection distances.|$|E
50|$|The {{output of}} this device is a boxcar output where the photodiodes are {{sequentially}} lit diode-by-diode as the <b>object</b> <b>distance</b> changes {{in relation to}} the sensor, until either no diodes are lit or all diodes are lit. The residual product charge dynamic value in each light diode cell {{is a function of the}} bias current, the dark current and the incident ionizing radiation (in this case, the returning laser light).|$|E
2500|$|... {{velocity}} is the derivative (with {{respect to}} time) of an <b>object's</b> displacement (<b>distance</b> {{from the original}} position) ...|$|R
5000|$|The blur circle, of {{diameter}} C, in the focused <b>object</b> {{plane at}} <b>distance</b> S1, is an unfocused virtual {{image of the}} <b>object</b> at <b>distance</b> S2 {{as shown in the}} diagram. It depends only on these distances and the aperture diameter A, via similar triangles, independent of the lens focal length: ...|$|R
5000|$|... where f is {{the lens}} focal length, v′ and u′ are {{the image and}} <b>object</b> <b>distances</b> {{parallel}} {{to the line of}} sight, uh is the hyperfocal distance, and J is the distance {{from the center of the}} lens to the PoF rotation axis. By solving the image-side equation for tan ψ for v′ and substituting for v′ and uh in the equation above,the values may be given equivalently by ...|$|R
50|$|The main {{benefit of}} using optical power rather than focal length {{is that the}} lensmaker's {{equation}} has the <b>object</b> <b>distance,</b> image distance, and focal length all as reciprocals. A further benefit is that when relatively thin lenses are placed close together their powers approximately add. Thus, a thin 2-dioptre lens placed close to a thin 0.5-dioptre lens yields almost the same focal length as a 2.5-dioptre lens would have.|$|E
50|$|Consider {{a general}} imaging system with <b>object</b> <b>{{distance}}</b> z0, focal {{length of the}} thin lens f and an imaging distance z1. The effect of the propagation in freespace acts as nearly a chirp convolution, that is, the formula of diffraction. Besides, {{the effect of the}} propagation in thin lens acts as a chirp multiplication. The parameters are all simplified as paraxial approximations while meeting the freespace propagation. It does not consider aperture size.|$|E
50|$|The {{technique}} {{takes advantage}} of the visual cues humans use to perceive depth such as angular size, aerial perspective, shading, and relative size. In film, photography and art, perceived <b>object</b> <b>distance</b> is manipulated by altering fundamental monocular cues used to discern the depth of an object in the scene such as aerial perspective, blurring, relative size and lighting. Using these monocular cues in concert with angular size, the eyes can perceive the distance of an object. Artists are able to freely move the visual plane of objects by obscuring these cues to their advantage.|$|E
500|$|Follow-up {{observations}} were then {{carried out to}} make a preliminary determination of Eris's orbit, which allowed the <b>object's</b> <b>distance</b> to be estimated. The team had planned to delay announcing their discoveries of the bright objects Eris and [...] until further observations and calculations were complete, but announced them both on July 29 when the discovery of another large TNO they had been tracking, , was controversially announced on July 27 by a different team in Spain.|$|R
40|$|A {{telescope}} {{was designed and}} fabricated which constitutes the primary piece of instrumentation in an experiment to obtain an improved measurement of the gravitational deflection of light. A Mark 2 solar oblateness detector was also designed and built. A preliminary study {{was made of the}} problems associated with the parallax measurement of spectroscopic binaries, and it indicates that for these <b>objects</b> <b>distances</b> up to 10 to the 5 th power pc night be measured...|$|R
40|$|Reliable object {{detection}} and segmentation {{is crucial for}} active safety driver assistance applications. In urban areas where the object density is high, a segmentation based on a spatial criterion often fails due to small <b>object</b> <b>distances.</b> Therefore, optical flow estimates are combined with distance measurements of a Laserscanner in order to separate objects with different motions even if their distance is vanishing. Results are presented on real measurements taken in potentially harmful traffic scenarios...|$|R
