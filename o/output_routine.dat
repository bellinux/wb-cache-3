10|64|Public
40|$|A pretty printer is {{presented}} {{which makes it}} easy for a user to control the format of the output produced. The printer {{can be used as a}} general mechanism for printing data structures as well as programs. It is divided into two parts: a set of formatting functions, and an <b>output</b> <b>routine.</b> Each formatting function creates a sequence of directions which specify how an object is to be formatted if it can fit on one line and how it is to be formatted if it must be broken up across mtdtiple lines. Based on the line length available, the <b>output</b> <b>routine</b> decides what structures have to be broken up across multiple lines and produces the actual output following the directions created by the formatting functions. The directions passed from the formatting functions to the <b>output</b> <b>routine</b> form a well defined interface: a language for specif) 'ing formatting options...|$|E
40|$|Note: {{before using}} this routine, please read the Users ’ Note for your {{implementation}} {{to check the}} interpretation of bold italicised terms and other implementation-dependent details. 1 Purpose D 02 NXF is an optional <b>output</b> <b>routine</b> which you may call, on exit from an integrator in sub-chapter D 02 M/N, if sparse matrix linear algebra has been selected...|$|E
40|$|A Lisp pretty printer is {{presented}} {{which makes it}} easy for a user to control the format of the output produced. The printer {{can be used as a}} general mechanism for printing data structures as well as programs. It is divided into two parts: a set of formatting functions and an <b>output</b> <b>routine.</b> The user specifies how a particular type of object should be formatted by creating a formatting function for the type. When passed an object of that type, the formatting function creates a sequence of directions which specify how the object should be printed if it can fit on one line and how it should be printed if it must be broken up across multiple lines. A simple template language makes it easy to specify these directions. Based on the line length available, the <b>output</b> <b>routine</b> decides what structures have to be broken up across multiple lines and produces the actual output following the directions created by the formatting functions. The paper concludes with a discussion of how the pretty printing method presented could be applied to languages other than Lisp...|$|E
40|$|The A. A. E. C. 360 CRAM program, {{written in}} FORTRAN IV and ASSEMBLER, is {{designed}} to run under the 360 operating system on a 256 K model 50. The program can readily be changed {{to take advantage of}} additional storage that may be available on other 360 configurations. The code includes standard <b>output</b> <b>routines</b> as well as providing the user with the facility of including his own FORTRAN coded <b>output</b> <b>routines.</b> The code package includes sets of test problems for both one and two dimensional geometries...|$|R
40|$|The {{second test}} case (longitudinal vortex above, but not merging with, a {{turbulent}} boundary layer) was investigated with flow visualization studies, and photographs selected. The results of quantitative data acquisition for the non-merging test case are presented. Other {{work in progress}} includes further flow visualization of the delta-wing wake. Considerable effort is being devoted {{to the development of}} graphical <b>output</b> <b>routines...</b>|$|R
50|$|The basic VELA {{carries a}} single 4KB EPROM (ISL1 or ISL1*) which {{contains}} the basic input and <b>output</b> <b>routines</b> that handle the keyboard input and 8-digit LED display output together with seventeen user selectable programs {{which range from}} a 4-channel digital volt meter to a random event monitor {{which could be used}} with a Geiger Counter Probe to measure and log radiation levels from a source material.|$|R
40|$|International audienceThis paper {{presents}} {{the use of}} trace-based performance visualization of a large scale atmospheric model, the Ocean-Land-Atmosphere Model (OLAM). The trace was obtained with the libRastro library, and the visualization was done with Paje. The use of visualization aimed to analyze OLAM's performance and to identify its bottlenecks. Especially, {{we are interested in}} the model's I/O operations, since it was proved to be the main issue for the model's performance. We show that most of the time spent in the <b>output</b> <b>routine</b> is spent in the close operation. With this information, we delayed this operation until the next output phase, obtaining improved I/O performance...|$|E
40|$|During {{the last}} two years, the LATEX 3 project team has been making and {{releasing}} some packages belonging to what they call LATEX 2 ε∗, which {{is a sort of}} intermediate step before LATEX 3. Unlike the previously released l 3 suite of packages [2], which deals mainly with very basic programming structures such as lists and stacks, the LATEX 2 ε ∗ suite of packages are more about producing better results in more concrete areas of LATEX. Examples include the xor package, which is a new and much more versatile <b>output</b> <b>routine,</b> and the xparse package, using which one can easily define commands with complicated mixtures of mandatory, optional, and *-type arguments. The elegant interfaces and functionality of these packages promise well for the future...|$|E
40|$|Output {{routines}} involving illustrations (“floating bodies ” in the LATEX lingo) are {{the most}} complex part of TEX. For most algorithms used in TEX, LATEX and ConTEXt the basic concept is a flow of text, oc-casionally interrupted by illustrations which can be placed anywhere close to the point they are men-tioned. The story is told mainly by the text, and illustrations have a secondary role. Here we discuss the different case of an illus-trated book, where the main story is told by the illus-trations and their interaction. The simplest examples of such books are art albums. Another (surprising) example is the FAO Statistical Yearbook, where {{the story is told}} primarily by maps, charts and tables, while the text has a secondary role. We describe a concept of a relatively simple <b>output</b> <b>routine</b> for such books and its implementation in LATEX. ...|$|E
40|$|In {{this paper}} we {{describe}} the ideas behind the Grammar Workbench (GWB). The GWB {{is one of a}} series of tools for the development of AGFLs (affix grammars over a finite lattice) for natural language. Its functions comprise a specialised editor, computation of properties, and special <b>output</b> <b>routines</b> to provide an overview of a grammar. This paper discusses AGFLs, the AGFL project, the functions of the GWB, and some aspects of incremental computation as applied in the GWB...|$|R
40|$|The Symmetrical List Processor SLIP; {{developed}} by Professor Joseph Weizenbaum of MIT, was implemented with considerable modifications and additions on the University of Cape Town computer. A package to perform automated analytical differentiation (DERIV) was developed using SLIP. Basic simplification techniques {{as well as}} convenient input and <b>output</b> <b>routines</b> were included. The package was tested extensively and a rough comparison drawn with the abilities of various computer languages and programs which include the same facility as TIERIV...|$|R
40|$|We {{describe}} an inertial gesture recognition framework composed of three parts. The {{first is a}} compact, wireless six-axis inertial measurement unit to fully capture three-dimensional motion. The second, a gesture recognition algorithm, analyzes the data and categorizes it on an axis-by-axis basis as simple motions (straight line, twist, etc.) with magnitude and duration. The third allows an application designer to combine recognized gestures both concurrently and consecutively to create specific composite gestures can then be set to trigger <b>output</b> <b>routines...</b>|$|R
40|$|The first Infrared Atmospheric Sounding Interferometer (IASI) was {{launched}} in October 2006 on the European Organization for the Exploitation of Meteorological Satellites' (EUMETSAT) Meteorological Operation (MetOp) -A satellite. The instrument and its successors will continue to operate until 2020 on the current MetOp platform and two follow-on satellites. The stability of the instrument is monitored routinely by the CNES Technical Expertise Center, using onboard measurements, and by EUMETSAT, where stable, clear fields of view are compared with simulated radiances from numerical weather prediction model <b>output.</b> <b>Routine</b> monitoring of IASI data and calibration and validation activities by CNES and EUMETSAT ensure full characterization of the instrument and verify that the performance meets the requirements. In-depth evaluation is routinely performed by comparing IASI with other instruments, such as AVHRR and the High Resolution Infrared Radiation Sounder (HIRS) on the MetOp platform. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|E
40|$|Multilevel {{parallel}} {{versions of}} CFL 3 D {{have been created}} and their performance has been evaluated for a complete aircraft problem on NAS platforms. CFL 3 D is a three-dimensional multi-block Navier-Stokes flow solver for structured grids and the official version of the code employs MPI to execute calculations in parallel over the discrete geometrical regions. A second version of the code employing the MLP library was created to compare its performance {{to that of the}} MPI library. The major modification to CFL 3 D, involving the aggressive exploitation of parallelism in the main computational loop, was added to both versions of the code using the OpenMP library. Elimination of the <b>output</b> <b>routine</b> and reassembly of the output after execution increased the effectiveness of all code improvements. On the SGI 3000 architecture, the overall improvements have produced a speedup of 8. 5 in the most timeconsuming iterations and implementation on the SGI Altix has further increased this speedup by a factor of 5. 5. The MLP library demonstrates a performance somewhat superior to the MPI library because of its superior load balancing capabilities. 1...|$|E
40|$|Another {{question}} {{dealt with}} a need for multiple marks. Consider, for example, a glossary in which entries are numbered. It might be useful to place guide words in the heading on each page and "guide numbers " in the footing. w s mark feature was specifically designed to save such labels, but only one mark can be specified at a time. W e {{it is clear that}} the mark construct can be used for either guide words or guide numbers it is not obvious how to use it for both. Don suggested using W 8 2 ' s construct. For example, the macro that starts a new entry might expand to include an instruction such as (Dachshund 20) if "dachshund " is the twentieth word entered. The <b>output</b> <b>routine</b> could use the construct case ter O to find the guide word in effect at the top of the page and l to find the guide number. TUGBOAT MACRO INDEX The following list catalogues macros that have appeared in TUGboat. Entries are listed by volume, number, and page as well as author's name. Items that could not be categorized by an obvious head-word have been listed under "rniscellaneous ". Many items refer to parts of large macro packages; users of other packages may find them valuable models for macros of their own. Readers ' comments on the format as well as the contents of this index are welcome. ACM style [...] ...|$|E
50|$|Transactional NTFS (abbreviated TxF) {{brings the}} concept of atomic {{transactions}} to the NTFS file system, allowing Windows application developers to write file <b>output</b> <b>routines</b> that are guaranteed to either completely succeed or completely fail. Transactional NTFS allows for files and directories to be created, renamed, and deleted atomically. Using a transaction ensures correctness of operation; {{in a series of}} file operations (done as a transaction), the operation will be committed if all the operations succeed. In case of any failure, the entire operation will roll back and fail.|$|R
40|$|We {{present an}} {{application}} that automatically writes the Helas (HELicity Ampli-tude Subroutines) library {{corresponding to the}} Feynman rules of any in quantum field theory Lagrangian. The code is written in Python and takes the Universal FeynRules Output (Ufo) as an input. From this input it produces the complete set of routines, wave-functions and amplitudes, that are needed for the computa-tion of Feynman diagrams at leading {{as well as at}} higher orders. The represen-tation is language independent and currently it can <b>output</b> <b>routines</b> in Fortran, C++, and Python. A few sample applications implemented in the MadGraph 5 framework are presented...|$|R
5000|$|Non-graphical <b>output</b> {{for many}} <b>routines</b> in either dBase DBF or Ascii text format.|$|R
40|$|Abstract. This paper {{explains}} {{the design of}} the second release of the Zen toolkit [5 – 7]. It presents a notion of reactive engine which simulates finite-state machines represented as shared aums [8]. We show that it yields a modular interpreter for finite state machines described as local transducers. For instance, in the manner of Berry and Sethi, we define a compiler of regular expressions into a scheduler for the reactive engine, chaining through aums labeled with phases — associated with the letters of the regular expression. This gives a modular composition scheme for general finite-state machines. Many variations of this basic idea may be put to use according to circonstances. The simplest one is when aums are reduced to dictionaries, i. e. to (minimalized) acyclic deterministic automata recognizing finite languages. Then one may proceed to adding supplementary structure to the aum algebra, namely non-determinism, loops, and transduction. Such additional choice points require fitting some additional control to the reactive engine. Further parameters are required for some functionalities. For instance, the local word access stack is handy as an argument to the <b>output</b> <b>routine</b> in the case of transducers. Internal virtual addresses demand the full local state access stack for their interpretation. A characteristic example is provided, it gives a complete analyser for compound substantives. It is an abstraction from a modular version of the Sanskrit segmenter presented in [9]. This improved segmenter uses a regular relation condition relating the phases of morphology generation, and enforcing the correct geometry of morphemes. Thus we obtain compound nouns from iic*. (noun+iic. ifc), where iic and ifc are the respectively prefix and suffix substantival forms for compound formation. 1 Regular morphology Dedicated to Joseph Goguen for his 65 th birthday We first consider the simplest framework for finite automata, where the state transition graph is a dictionary structure (lexical tree or trie). Such structures represent acyclic deterministic finite-state automata, with maximal sharing of initial paths. Every state is accessible from the initial state, and we may also assume that every state is on an accepting path. When we minimize the tree as a dag, we obtain the corresponding minimal deterministic automaton. Suc...|$|E
40|$|Abstract. We {{describe}} an inertial gesture recognition framework composed of three parts. The {{first is a}} compact, wireless six-axis inertial measurement unit to fully capture three-dimensional motion. The second, a gesture recognition algorithm, analyzes the data and categorizes it on an axis-by-axis basis as simple motions (straight line, twist, etc.) with magnitude and duration. The third allows an application designer to combine recognized gestures both concurrently and consecutively to create specific composite gestures can then be set to trigger <b>output</b> <b>routines.</b> This framework was created to enable application designers to use inertial sensors {{with a minimum of}} knowledge and effort. Sample implementations and future directions are discussed. ...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedA digital computer program which will provide accurate and stable solutions of linear and nonlinear ordinary differential equation is described, as are subprograms which simulate {{many of the}} nonlinearities occurring in feedback control systems. The program employs fourth order Runge-Kutta numerical integration with automatic error checking and interval modification. Specialized coding sheets assist {{in the preparation of}} input data, and built-in print and graph <b>output</b> <b>routines</b> provide a permanent record of input equations, parameter values and output data for each solution. The program is flexible, yet it can be used by a person with only a rudimentary knowledge of FORTRAN programming. [URL] United States Nav...|$|R
40|$|This report {{describes}} a database routine called DB 90 which {{is intended for}} use with scientific and engineering computer programs. The software is written in the Fortran 90 / 95 programming language standard with file input and <b>output</b> <b>routines</b> written in the C programming language. These routines should be completely portable to any computing platform and operating system that has Fortran 90 / 95 and C compilers. DB 90 allows a program to supply relation names and up to 5 integer key values to uniquely identify each record of each relation. This permits the user to select records or retrieve data in any desired order...|$|R
40|$|We {{describe}} an inertial gesture recognition framework composed of three parts. The {{first is a}} compact, six-axis inertial measurement unit to fully capture three-dimensional motion. The second, a gesture recognition algorithm, analyzes the data and categorizes it on an axis-by-axis basis as simple motions (straight line, twist, etc.) with magnitude and duration. The third allows an application designer to combine recognized gestures both concurrently and consecutively to create specific composite gestures which are tied to <b>output</b> <b>routines.</b> This framework was implemented on a Palm III to demonstrate its lightweight nature and to evoke devices which possess both a sense of their own motion {{and the ability to}} respond to it...|$|R
5000|$|Create the {{following}} subroutine {{in the file}} FILE1: ?Section HELLO_BERNARD <b>ROUTINE</b> <b>OUTPUT</b> Hello BERNARD ...|$|R
40|$|Abstract. The <b>Output</b> <b>Routines</b> series {{started in}} 1990 with three articles. The first is an introduction; the second {{discusses}} communications techniques; {{the third is}} on insertions. The current article {{is the result of}} research efforts for the last three years. It discusses advanced techniques for communicating with the OTR from horizontal mode, making it possible to solve problems that require a detailed knowledge of the contents of the lines of text on the page. Logically, this article should be the third in the series, so new readers are advised to read the first two parts, then this part, and finally the part on insertions. Also, part I 1 should now be called "Verti-cal Techniques", instead of "Examples and Tech-niques"...|$|R
50|$|The {{language}} incorporated {{ideas from}} PL/I, ALGOL and XPL, {{and had an}} integrated macro processor. Unlike other contemporary languages such as Pascal, C or BASIC, PL/M had no standard input or <b>output</b> <b>routines.</b> It included features targeted at the low-level hardware specific to the target microprocessors, and as such, it could support direct access to any location in memory, I/O ports and the processor interrupt flags in a very efficient manner. PL/M was the first higher level programming language for microprocessor-based computers and was the original implementation language for the CP/M operating system. Many Intel and Zilog Z80 based embedded systems were programmed in PL/M during the 1970s and 1980s. For instance, the firmware of the Service Processor component of CISC AS/400 was written in PL/M.|$|R
5000|$|An {{alternate}} {{strategy is}} to create a file named FILE1 and add the following two lines: ?TACL <b>ROUTINE</b> <b>OUTPUT</b> Hello BERNARD ...|$|R
40|$|The {{new release}} is a {{basically}} unchanged {{version of the}} original. I upgraded the macros so that they work with LATEX 2 ε and used some of the additional flexibility introduced therein. For example, the command is now automatically called at, thus allowing the user to adjust the in the preamble. It is not surprisingly that I was forced to change some of the macros because they dig deep into LATEX’s <b>output</b> <b>routines.</b> Fortunately this is something normally not necessary when upgrading other LATEX 2. 09 styles to LATEX 2 ε packages. I also upgraded the documentation {{to conform to the}} LATEX 2 ε terminology, e. g., this is a package since document classes will not know about it. However it is very likely that i have missed some necessary corrections. ...|$|R
40|$|The CMC fluid {{mechanics}} program system {{was developed to}} transmit the theoretical evolution of finite element numerical solution methodology, applied to nonlinear field problems into a versatile computer code for comprehensive flow field analysis. A detailed view of the code {{from the standpoint of}} a computer programmer's use is presented. A system macroflow chart and detailed flow charts of several routines necessary to interact with a theoretican/user to modify the operation of this program are presented. All subroutines and details of usage, primarily for input and <b>output</b> <b>routines</b> are described. Integer and real scalars and a cross reference list denoting subroutine usage for these scalars are outlined. Entry points in dynamic storage vector IZ; the lengths of each vector accompanying the scalar definitions are described. A listing of the routines peculiar to the standard test case and a listing of the input deck and printout for this case are included...|$|R
40|$|A digital {{computer}} software system with generalized capability {{to solve the}} radiation related aspects of thermal analysis problems is presented. When {{used in conjunction with}} a generalized thermal analysis program such as the systems improved numerical differencing analyzer program, any thermal problem that can be expressed in terms of a lumped parameter R-C thermal network can be solved. The function of TRASYS is twofold. It provides: (a) Internode radiation interchange data; and (b) Incident and absorbed heat rate data from environmental radiant heat sources. Data of both types is provided in a format directly usable by the thermal analyzer programs. The system allows the user to write his own executive or driver program which organizes and directs the program library routines toward solution of each specific problem in the most expeditious manner. The user also may write his own <b>output</b> <b>routines,</b> thus the system data output can directly interface with any thermal analyzer using the R-C network concept...|$|R
40|$|Numerical {{solutions}} for the flowfield about several cavity configurations have been computed using the Reynolds averaged Navier-Stokes equations. Comparisons between numerical and experimental results are made in two dimensions for free shear layers and a rectangular cavity, and in three dimensions for the transonic aero-window problem of the Stratospheric Observatory for Infrared Astronomy (SOFIA). Results show that dominant acoustic frequencies and magnitudes of the self excited resonant cavity flows compare well with the experiment. In addition, solution sensitivity to artificial dissipation and grid resolution levels are determined. Optical path distortion due to the flow field is modelled geometrically and is found to match the experiment. The fluid field was computed using a diagonalized scheme within an overset mesh framework. An existing code, OVERFLOW, was utilized with the additions of characteristic boundary condition and <b>output</b> <b>routines</b> required for reduction of the unsteady data. The newly developed code is directly applicable to a generalized three dimensional structured grid zone. Details are provided in a paper included in Appendix A...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimited. The Joint Army/Navy Rotorcraft Analysis and Design (JANRAD) computer program {{was developed to}} aid in the analysis of helicopter rotor performance, stability and control, and rotor dynamics. JANRAD is an interactive, user friendly program, capable of accurately and quickly solving helicopter design problems at the preliminary design level. The program was written as a collection of MATLAB script and function files (M-files) using the 386 -MATLAB version 3. 5 programming language. The M-file janrad. in invokes the user interface routines and calls various analysis modules (M-files) which contain the appropriate analysis and <b>output</b> <b>routines.</b> Each of these modules use a common routine, trim. m, which employs blade element theory and a harmonic balance method for rotor trim. The program is limited to conditions of steady flight with no winds and is accurate at a hover and for forward airspeeds {{greater than or equal to}} 50 knots. Major, United States Arm...|$|R
40|$|This report forms part of {{deliverable}} B 7 of the COPAC/Clumps Continuing Technical Cooperation project (CC-interop). Deliverable B 7 {{consists of}} automated routines {{to allow the}} collection-level description (CLD) database of the Scottish Collections Network (SCONE) to be output in various formats. The formats of interest are those that other UK users of collection descriptions, including the JISC Information Environment, can harvest and use. There is no single stable format for collection-level descriptions agreed or in use in the United Kingdom, so routines {{for a number of}} outputs have been developed: • Text • HTML table • MARC 21 display format • RSLP schema in RDF • IESR collection schema in XML • Dublin Core Collection Description schema in RDF This report also covers the HTML output used to display CLDs in the SCONE services. During development of the <b>output</b> <b>routines,</b> a number of ambiguities and anomalies in external schema, and in the SCONE database structure, were noted, and recommendations made for resolving them...|$|R
40|$|We {{describe}} four improvements we {{have implemented}} in {{a version of}} the genetic linkage analysis programs in the LINKAGE package: subdivision of recombination classes, better handling of loops, better coordination between the optimization and <b>output</b> <b>routines,</b> and a checkpointing facility. The unifying theme for all the improvements is to store a small amount of data to avoid expensive recomputation of known results. The subdivision of recombination classes improves on a method of Lathrop and Lalouel [Amer. J. Hum. Genetics 42 (1988), pp. 498 [...] 505]. The new method of handling loops extends a proposal of Lange and Elston [Hum. Hered. 25 (1975), pp. 95 [...] 105] for loopless pedigrees with multiple nuclear families at the earliest generation. From a practical point of view, the most important improvement may be the checkpointing facility which allows the user to carry out linkage computations that are much longer than the mean-time-to-failure of the underlying computer...|$|R
40|$|The Thermal Radiation Analysis System, TRASYS, is {{a digital}} {{computer}} software system with generalized capability {{to solve the}} radiation-related aspects of thermal analysis problems. When {{used in conjunction with}} a generalized thermal analyzer program any thermal problem that can be expressed in terms of a lumped parameter R-C thermal network can be solved. The function of TRASYS is twofold. It provides: (1) internode radiation interchange data; and (2) incident and absorbed heat rate data from environmental radiant heat sources. Data of both types is provided in a format directly usable by the thermal analyzer programs. One of the primary features of TRASYS is that it allows the user to write his own executive or driver program which organizes and directs the program library routines toward solution of each specific problem in the most expeditious manner. The user also may write his own <b>output</b> <b>routines,</b> thus the system data output can directly interface with any thermal analyzer using the R-C network concept...|$|R
40|$|Transient Analysis of Linear Circuits Using Constraint Logic Programming By Archana Shankar, David R. Gilbert, Michael B. Jampel This report {{describes}} {{the design of}} a transient analysis program for linear circuits and its implementation in a Constraint Logic Programming language. CLP(R) was chosen to be the implementation language as it is designed to be efficient in handling real numbers. We have defined a circuit definition language(CDL) to input the circuit topology to the program. The transient analysis program parses the CDL into a network graph, analyses the semantic correctness of the network graph and then performs the actual transient analysis of a given circuit. There is also a library to implement the abstract data type of matrices, plus input routines to read the CDL file, and <b>output</b> <b>routines</b> to display the results to the user. The test results show that the program is at least 97 % accurate when run at two decimal places. We have compared the performance of our program with [...] ...|$|R
