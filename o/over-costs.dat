4|14|Public
50|$|The aim of lean {{thinking}} {{is to create}} a lean enterprise, one that sustains growth by aligning customer satisfaction with employee satisfaction, and that offers innovative products or services profitably while minimizing unnecessary <b>over-costs</b> to customers, suppliers and the environment. The basic insight of lean {{thinking is}} that if you train every person to identify wasted time and effort in their own job and to better work together to improve processes by eliminating such waste, the resulting enterprise will deliver more value at less expense while developing every employee’s confidence, competence and ability to work with others.|$|E
40|$|AbstractIn this paper, {{we propose}} an {{innovative}} and simple graphical framework for project control and monitoring, {{to integrate the}} dimensions of project cost and schedule with risk management, therefore extending the Earned Value methodology (EVM). EVM allows Project managers {{to know whether the}} project has overruns (<b>over-costs</b> and/or delays), but project managers do not know when deviations from planned values are so important that corrective actions should be taken or, in case of good performance, sources of improvement can be detected. From the concept of project planned variability, we build a graphical methodology to know when a project remains “out of control” or “within expected variability” during the project lifecycle. To this aim, we define and represent new control indexes and new cumulative buffers. Five areas in the chart represent five different possible project states. To implement this framework, project managers only need the data provided by EVM traditional analysis and Monte-Carlo simulation. We also explore the sensitivity of the methodology to control variables...|$|E
40|$|The project {{management}} of complex instruments for ground-based large telescopes {{is a challenge}} itself. A good management is a clue for project success in terms of performance, schedule and budget. Being on time has become a strict requirement for two reasons: to assure the arrival at the telescope due to the pressure on demanding new instrumentation for this first world-class telescopes and to not fall in <b>over-costs.</b> The budget and cash-flow {{is not always the}} expected one and has to be properly handled from different administrative departments at the funding centers worldwide distributed. The complexity of the organizations, the technological and scientific return to the Consortium partners and the participation in the project of all kind of professional centers working in astronomical instrumentation: universities, research centers, small and large private companies, workshops and providers, etc. make the {{project management}} strategy, and the tools and procedures tuned to the project needs, crucial for success. MEGARA (Multi-Espectrografo en GTC de Alta Resolucion para Astronomia) is a facility instrument of the 10. 4 m GTC (La Palma, Spain) working at optical wavelengths that provides both Integral-Field Unit (IFU) and Multi-Object Spectrograph (MOS) capabilities at resolutions in the range R= 6, 000 - 20, 000. The project is an initiative led by Universidad Complutense de Madrid (Spain) in collaboration with INAOE (Mexico), IAA-CSIC (Spain) and Universidad Politecnica de Madrid (Spain). MEGARA is being developed under contract with GRANTECAN...|$|E
40|$|We {{propose to}} {{organize}} at SAC 2006 a track {{that focuses on}} today and tomorrow methods and software to go far-ther than the precision currently available on our computers. How to manage {{the need for more}} accurate results without suffering from an impractical <b>over-cost?</b> This track aims to gather applied computer scientists, com-puter engineers and application developers together with re-searchers on numerical software quality to exhibit the cur-rent state of the art on the need and the solutions to reach both accuracy, reliability and performance in software...|$|R
30|$|The aim of {{this paper}} is to offer an {{estimate}} of the “extra” costs of severe disability for households in 31 European countries (the 28 member states of the current European Union and Iceland, Norway and Switzerland), where the term “extra” refers to the <b>over-cost</b> faced by households with members with disabilities to reach a given level of well-being compared to similar households with non-disabled members. As far as we know, this is the first attempt to offer such an estimation using homogeneous data and the same methodology for a wide set of European countries. On top, we try to outline several plausible explanations for the differences in estimated costs across countries.|$|R
40|$|International audienceThis paper {{presents}} two sufficient {{conditions to}} ensure a faithful evaluation of polynomial in IEEE- 754 floating point arithmetic. Faithfulness means that the computed value {{is one of the}} two floating point neighbours of the exact result; it can be satisfied using a more accurate algorithm than the classic Horner scheme. One condition here provided is an apriori bound of the polynomial condition number derived from the error analysis of the compensated Horner algorithm. The second condition is both dynamic and validated to check at the running time the faithfulness of a given evaluation. Numerical experiments illustrate the behavior of these two conditions and that associated running time <b>over-cost</b> is really interesting...|$|R
40|$|The growing need of {{responsiveness}} {{for manufacturing}} companies facing the market volatility raises a strong demand for flexibility in their organization. This flexibility {{can be used}} to enhance the robustness of a baseline schedule for a given programme of activities. Since the company personnel are increasingly seen as the core of the organizational structures, they provide the decision-makers with a source of renewable and viable flexibility. First, this work was implemented to model the problem of multi-period workforce allocation on industrial activities with two degrees of flexibility: the annualizing of the working time, which offers opportunities of changing the schedules, individually as well as collectively. The second degree of flexibility is the versatility of operators, which induces a dynamic view of their skills and the need to predict changes in individual performances as a result of successive assignments. The dynamic nature of workforce’s experience was modelled in function of learning-by-doing and of oblivion phenomenon during the work interruption periods. We firmly set ourselves in a context where the expected durations of activities are no longer deterministic, but result from the number and levels of experience of the workers assigned to perform them. After that, the research was oriented to answer the question “What kind of problem is raises the project we are facing to schedule?”: therefore the different dimensions of the project are inventoried and analysed to be measured. For each of these dimensions, the related sensitive assessment methods have been proposed. Relying on the produced correlated measures, the research proposes to aggregate them through a factor analysis in order to produce the main principal components of an instance. Consequently, the complexity or the easiness of solving or realising a given scheduling problem can be evaluated. In that view, we developed a platform software to solve the problem and construct the project baseline schedule with the associated resources allocation. This platform relies on a genetic algorithm. The model has been validated, moreover, its parameters has been tuned to give the best performance, relying on an experimental design procedure. The robustness of its performance was also investigated, by a comprehensive solving of four hundred instances of projects, ranked according to the number of their tasks. Due to the dynamic aspect of the workforce’s experience, this research work investigates a set of different parameters affecting the development of their versatility. The results recommend that the firms seeking for flexibility should accept an amount of extra cost to develop the operators’ multi functionality. In order to control these <b>over-costs,</b> the number of operators who attend a skill development program should be optimised, as well as the similarity of the new developed skills relative to the principal ones, or the number of the additional skills an operator may be trained to, or finally the way the operators’ working hours should be distributed along the period of skill acquisition: this is the field of investigations of the present work which will, in the end, open the door for considering human factors and workforce’s flexibility in generating a work baseline program...|$|E
6000|$|Your angel {{sure our}} Morley's mind inspired, [...] To find the remedy your ill required; [...] As once the Macedon, by Jove's decree, [...] Was taught to dream an herb for Ptolemy: [...] Or Heaven, which had such <b>over-cost</b> bestow'd, [...] As scarce it {{could afford to}} flesh and blood, [...] So liked the frame, he would not work anew, [...] To save the charges of another you. [...] Or by his middle science did he steer, [...] And saw some great {{contingent}} good appear, [...] 140 [...] Well worth a miracle to keep you here: [...] And for that end preserved the precious mould, [...] Which all the future Ormonds was to hold; [...] And meditated in his better mind [...] An heir from you, which may redeem the failing kind.|$|R
40|$|The {{compensated}} Horner algorithm {{improves the}} accuracy of polynomial evaluation in IEEE- 754 floating point arithmetic: the computed result is as accurate {{as if it was}} computed with the classic Horner algorithm in twice the working precision. Since the condition number still governs {{the accuracy of}} this computation, it may return an arbitrary number of inexact digits. We address here how to compute a faithfully rounded result, {{that is one of the}} two floating point neighbors of the exact evaluation. We propose an a priori sufficient condition on the condition number to ensure that the compensated evaluation is faithfully rounded. We also propose a validated and dynamic method to test at the running time if the compensated result is actually faithfully rounded. Numerical experiments illustrate the behavior of these two conditions and that the associated running time <b>over-cost</b> is really interesting...|$|R
40|$|Abstract – Robotic {{researches}} {{can contribute}} to the restoration of some functions lost by handicapped people. The <b>over-cost</b> generated by the additive potentialities must be affordable and related to the value of the usual product. In most cases, autonomous functions are direct transpositions of solutions applied in industrial robotics. If we consider that in addition with cost, security is a supplementary constraint of rehabilitation robotics, an important research effort is needed to propose technological components. The aim {{of this paper is to}} introduce a functionality within the context of the following plan: “technical achievement and psychological analysis of a master/slave robot assistance for the invalid person ” (HTSC: Human/Technology Complex System). This application allows a severely handicapped person to handle at the same time a movable platform and a Manus ® arm. In this paper, we will present an “automatic tracking ” functionality we developed in order to keep the Manus ® arm automatically close to the patient by using two omnidirectional vision sensors...|$|R
40|$|Colloque avec actes sans comité de lecture. The ccNUMA {{architecture}} of the SGI Origin 2000 {{has been shown to}} perform and scale {{for a wide range of}} scientific and engineering applications. This paper focuses on a well known computer graphics hierarchical algorithm - wavelet radiosity - whose parallelization is made challenging by its irregular, dynamic and unpredictable characteristics. Our previous experimentations, based on a naive parallelization, showed that the Origin 2000 hierarchical memory structure was well suited to handle the natural data locality exhibited by this hierarchical algorithm. However, our crude load balancing strategy was clearly insufficient to benefit from the whole Origin 2000 power. We present here a fine load balancing analysis and then propose several enhancements, namely "lazy copy" and "lure", that greatly reduce locks and synchronization barriers idle time. The new parallel algorithm is experimented on a 64 processors Origin 2000. Even if in theory, a communication <b>over-cost</b> has been introduced, we show that data locality is still preserved. The final performance evaluation shows a quasi optimal behavior, at least until the 32 -processor scale. Hereafter, a problematic trouble spot has to be identified to explain the performance degradation observed at the 64 -processor scale...|$|R
40|$|The ccNUMA {{architecture}} of the SGI Origin 2000 {{has been shown to}} perform and scale {{for a wide range of}} scientific and engineering applications. This paper focuses on a well known computer graphics hierarchical algorithm- wavelet radiosity- whose parallelization is made challenging by its irregular, dynamic and unpredictable characteristics. Our previous experimentations, based on a naive parallelization, showed that the Origin 2000 hierarchical memory structure was well suited to handle the natural data locality exhibited by this hierarchical algorithm. However, our crude load balancing strategy was clearly insufficient to benefit from the whole Origin 2000 power. We present here a fine load balancing analysis and then propose several enhancements, namely ”lazy copy ” and ”lure”, that greatly reduce locks and synchronization barriers idle time. The new parallel algorithm is experimented on a 64 processors Origin 2000. Even if in theory, a communication <b>over-cost</b> has been introduced, we show that data locality is still preserved. The final performance evaluation shows a quasi optimal behavior, at least until the ¢¤ £-processor scale. Hereafter, a problematic trouble spot has to be identified to explain the performance degradation observed at the ¥§ ¦-processor scale. ...|$|R
40|$|This study {{examined}} the causes, effects and solutions to the delayed of completion of building projects in Nigeria. Many projects are either abandoned or neglected in Nigeria due to many reasons {{and its effects on}} developmental projects. Delay of building construction projects posed challenges to the building professionals, clients, consultants and the contractors. Information was collated through personal contact, administration of questionnaire and review of existing literature and journals which formed the data base. Data collected were analyzed using percentages. The findings reveal that the causes of delay of building construction projects in Nigeria are lack of funds (8. 8 %), lack of materials, incomplete drawings and poor communication ranked second (8. 4 %) while lack of tools and equipment, absenteeism of workers on site, incompetent workers and government policy were ranked third (8 %). These were followed by poor site condition, labour, political instability, weather condition and safety on site. The effects of delay of building construction projects in Nigeria are caused due to loss of wealth ranked first (13. 20 %), waste of time ranked second (12. 80 %) and negotiations ranked third (12. 00 %). Followed by disputes between parties, abandonments of building projects, lawsuits to claim damages, litigations to claim rights, <b>over-cost</b> of the contract sum, overtime of workers and inadequate capacity. The main causes, effects and solution to the delay in view of building professionals in the building industry are described...|$|R
40|$|In {{most of the}} countries, energy {{efficiency}} has been delegated to the dynamics of real estate markets, after regulating a minimum legal (although not optimal) efficiency level. So, {{it is expected that}} high efficient housing stock receives a market premium that, at least, equals the <b>over-cost</b> invested in improved thermal insulation and more efficient appliances. Theoretically, under such a mechanism developers are fostered to promote sustainable housing schemes. Nonetheless, the question of whether residential users do pay more for more sustainable housing remains to be explored in emergent markets where green labelling is still not legally implemented. This paper explores the impact of energetic efficiency of housing on demand’s willingness to pay in Santiago de Chile. In doing so a contingent valuation approach is used in order to extract the structure of preferences for different levels of energetic efficiency for the residential market of houses. Results reveal that a significant proportion of respondents are willing to pay (WTP) a quantity that surpasses the cost of green investment. The results of a regression model aimed to explain the factors that lay behind WTP suggest that it is positively influenced by: income level (indirectly measured by the price range of the requested house), educational level and demographics, being households with small children who pay the most. These results have important implications on the design of public policies aimed to improve the energetic efficiency of new housing developments...|$|R
40|$|The {{quantity}} surveyors, in {{the present}} day construction industry, analyze cost components of a construction project in a scientific way and applies {{the results of the}} analysis to a variety of financial and economic problems confronting the developer and the designer. However, competence, in any sphere of work, can be a difficult concept to pin down, especially, when it relates to professional occupations where such roles are complex and involved diverse professionals in the built environment sector. This paper aims to investigate the competencies of quantity surveyors in the discharge of its professional duties by evaluating the effects of professional competency on quantity surveying practices in Nigeria. The study population comprised professional quantity surveyors who are in the private construction/consulting firms in Lagos State, Nigeria. Data were obtained to investigate the professional views on the quantity surveying profession, the roles of quantity surveyors in the construction industry and the need for professionalism and competencies in the surveying industry. Questionnaires were administered to randomly select 200 practicing quantity surveyors in Lagos state. Findings revealed that the major role of quantity surveyors in the construction industry is the preparation of the bill of quantity as it ranked 1 st with RII value of 1. 00; it was also discovered that quantity surveyors were in agreement with client service delivery as the first ethical standard that construction professionals should consider when performing their professional obligations in order to avoid project failure and <b>over-cost.</b> It is therefore recommended that the professional bodies and the academia should organize proper and adequate service trainings, workshops and seminars which will enhance the possibility of acquiring more skills and experience so as to improve competence in the discharge of quantity surveyors professional duties...|$|R
40|$|In {{the context}} of the CMS (Content Management System) on of the most used {{solutions}} is Drupal, a CMS which its best parts are its modularity, the big number of modules for it and the huge community mantaining Drupal and its modules. One of its modules is TMGMT (Translation Management Tool), it help in the task of translating content in Drupal, as by default in Drupal you can just translate a text manually, writing for each contant a translation. TMGMT extend its capabilities letting us use other translators. Currently with TMGMT, if a content item changes in one field, it needs to be resubmitted as a whole to the translator. Without a translation memory, a translator is asked to perform the same translations again and again. If the user uses a non free translator this will mean that each time he will have to pay for it, leading to a <b>over-cost</b> to maintain a multilingual site. In MD Systems, Miro Dietiker wanted to solve that problem, but non of their clients wanted to pay for the development of this module, so they asked for funds to Acquia, this was meant to improve TMGMT Local module, to convert it to a CAT (Computer-Assisted Translation) tool, but to reach that goal, one of the steps was to add this translation memory to TMGMT. But Acquia refused to give funds to MD Systems to improve TMGMT claiming that TMGMT was good enough in features, and right now they have other priorities. But in MD Systems they still want to improve TMGMT. And I as part of the team in MD Systems and as I was working a lot in the port of TMGMT to Drupal 8, I wanted to see those goals reached, so I proposed to Miro Dietiker to build TMGMT Memory as my bachelor thesis, he liked the idea and agreed to give me support, so I dropped my initial thesis and started with it also with the support of my supervisor Marta Oliva...|$|R

