7|256|Public
40|$|A {{first attempt}} to extract {{association}} rules from a database frequently yields {{a significant number of}} rules, which may be rather difficult for the user to browse in searching interesting information. However, powerful languages allow the user to specify complex mining queries {{to reduce the amount of}} extracted information. Hence, a suitable rule set may be obtained by means of a progressive refinement of the initial query. To assist the user in the refinement process, we identify several types of containment relationships between mining queries that may lead the process. Since the repeated extraction of a large rule set is computationally expensive, we propose an algorithm to perform an incremental recomputation of the <b>output</b> <b>rule</b> set. This algorithm is based on the detection of containment relationships between mining querie...|$|E
40|$|Director Musices is {{a program}} that {{transforms}} notated scores into musical performances. It implements the performance rules emerging from research projects at the Roy al Institute of Technology (KTH). Rules in the program model performance aspects such as phrasing, articulation, and intonation, and they operate on performance v ariables such as tone, inter-onset duration, amplitude, and pitch. By manipulating rule parameters, the user {{can act as a}} metaperformer controlling different features of the performance, leav ing the technical execution to the computer. Different interpretations of the same piece can easily be obtained. Features of Director M usices include M IDI file input and <b>output,</b> <b>rule</b> palettes, graphical display of all performance v ariables (along w ith music notation), and user-defined performance rules. The program is implemented in Common Lisp and is av ailable free as a stand- alone application both for M acintosh and Window s platforms. Further information, including music examples, publications, and the softw are itself, is located online a...|$|E
40|$|We {{distinguish}} {{a population}} learning Genetic Algorithm (or pure GA), and an individual learning Genetic Algorithm (a GA {{combined with a}} Classifier System). We show that for a certain class of problems these two types lead to widely differing performances. 1 AN EXAMPLE Consider a Cournot market with 40 firms producing the same commodity. The only decision variable for firm i is the quantity qi to be produced. Given the total production, the market price P is determined through the confrontation of market demand and supply. The inverse demand function is P(Q) = a+bQc, where Q=Σqi. Making the appropriate assumptions on the parameters a, b, and c ensures {{that this is a}} downward-sloping curve. We assume that the production costs are such that there are negative fixed costs, whereas the marginal costs are 0. Details of the economic model can be found in Vriend [1999]. Assume that each firm needs to learn which output levels are good. There are two ways to implement a GA. First, as a model of population learning (or pure GA). Each firm in the population is characterized by an <b>output</b> <b>rule,</b> a binary string of fixed length, specifying the firm’s production level. Each trading day, a firm produces a quantity as determined by its <b>output</b> <b>rule,</b> the market price is determined, and the firms ’ profits are computed. After every 100 trading days, the population of output rules is modified by applying some genetic operators (details of the GA can be found in Vriend [1999]). The more successful rules have been, {{the more likely they are}} to be selected for this process of imitation and re-combination. The second way to implement a GA is as a model of individual learning (a Classifier System with on top of it a GA). Each firm has a set of rules in mind, but each period only one of these rules is used to determine its output level actually supplied to the market. Attached to each rule is a measure of its success when it was activated. On top of this Classifier System, the GA is used every 100 periods to modify the set of rules a firm has in mind exactly as above. Figure 1 presents the time series of the output levels for 25 runs. ...|$|E
5000|$|These {{rules are}} typical for control {{applications}} {{in that the}} antecedents consist of the logical combination of the error and error-delta signals, while the consequent is a control command <b>output.</b> The <b>rule</b> <b>outputs</b> can be defuzzified using a discrete centroid computation: ...|$|R
5000|$|... rule 1: IF e = ZE AND delta = ZE THEN <b>output</b> = ZE <b>rule</b> 2: IF e = ZE AND delta = SP THEN <b>output</b> = SN <b>rule</b> 3: IF e = SN AND delta = SN THEN <b>output</b> = LP <b>rule</b> 4: IF e = LP OR delta = LP THEN output = LN ...|$|R
40|$|The {{purpose of}} the rules that compose by the state organ is {{to solve the problem}} and create {{definite}} situation trough the creator idea. Base on the reason, the background (situation and condition) of law making process will be influence the substance of the <b>output</b> (<b>rules).</b> This idea can be proof by description most of the rules form the beginning of the Indonesian independence till the reformation...|$|R
40|$|A {{conceptual}} model is discussed {{which allows the}} hierarchic definition of high-level input driven objects, called input-output tools, from any set of basic input primitives. An input-output tool {{is defined as a}} named object. Its most important elements are the input rule, <b>output</b> <b>rule,</b> internal tool definitions, and a tool body consisting of executable statements. The input rule contains an expression with tool designators as operands and with operators allowing for sequencing, selection, interleaving, and repetition. Input rules are similar in appearance to production rules in grammars. The input expression specifies one or more input sequences, or input patterns, in terms of tool designators. An input parser tries, at run-time, to match (physical) input tokens against active input sequences. If a match between an input token and a tool designator is found, the corresponding tool body is executed, and the output is generated according to specifications in the tool body. The control structures in the input expression allow a variety of input patterns from any number of sources. Tool definitions may occur in-line or be stored in a library. All tools are ultimately encompassed in one tool representing the program...|$|E
40|$|In recent years, support vector {{machines}} (SVMs) {{have shown}} good {{performance in a}} number of application areas, including text classification. However, the success of SVMs comes at a cost – an inability to explain the process by which a learning result was reached and why a decision is being made. Rule-extraction from SVMs is important for the acceptance of this machine learning technology, especially for applications such as medical diagnosis. It is crucial for the users to understand how the system makes a decision. In this paper, a novel approach for rule-extraction from support vector machines is presented. This approach handles rule-extraction as a learning task, which proceeds in two steps. The first is to use the labeled patterns from a data set to train an SVM. The second step is to use the generated model to predict the label (class) for an extended data set or different, unlabeled data set. The resulting patterns are then used to train a decision tree learning system and to extract the corresponding rule sets. The <b>output</b> <b>rule</b> sets are verified against available knowledge for the domain problem (e. g. a medical expert), and other classification techniques, to assure correctness and validity of rules. Key Words: SVM – Learning-based Rule Extraction algorithms – Medical diagnosis 1...|$|E
40|$|There is an {{increasing}} interest in application of Evolutionary Algo-rithms to induce classification rules. This hybrid approach can aid in areas that classical methods to rule induction have not been completely suc-cessful. One example is the induction of classification rules in imbalanced domains. Imbalanced data occur when some classes heavily outnumbers other classes. Frequently, classical Machine Learning classifiers {{are not able to}} learn in the presence of imbalanced data sets, outputting classifiers that always predict the most numerous classes. In this work we propose a novel hybrid approach to deal with this problem. We create several balanced data sets with all minority class cases and a random sample of majority class cases. These balanced data sets are given to classical Machine Learning systems that <b>output</b> <b>rule</b> sets. The rule sets are combined in a pool of rules and an evolutionary algorithm is used to build a classifier from this pool of rules. This hybrid approach has some advantages over under-sampling since it reduces the amount of discarded information, and some advantages over over-sampling since it avoids overfitting. This approach was experi-mentally analyzed and our experiments show the proposed approach can improve classification measured as the area under the ROC curve...|$|E
40|$|The aim of {{this work}} is to study the {{implementation}} feasibility of a VLS (Virtual Lambda Sensor) by a TSK (Takagi, Sugeno, Kang) singleton FIS (Fuzzy Inference System). Such a sensor {{could be used in}} a model based EMS (Engine Management System) for trade gasoline engines. FIS design target is to obtain a system with a fixed data representation (i. e. 10 bit) and a limited number of inputs, <b>outputs,</b> <b>rules</b> and membership. 1...|$|R
40|$|Submitted {{on behalf}} of EDAA ([URL] audienceThe aim of this work is to study the {{implementation}} feasibility of a VLS (Virtual Lambda Sensor) by a TSK (Takagi, Sugeno, Kang) singleton FIS (Fuzzy Inference System). Such a sensor {{could be used in}} a model based EMS (Engine Management System) for trade gasoline engines. FIS design target is to obtain a system with a fixed data representation (i. e. 10 bit) and a limited number of inputs, <b>outputs,</b> <b>rules</b> and membership...|$|R
2500|$|The <b>rule</b> <b>outputs</b> can be {{defuzzified}} using {{a discrete}} centroid computation: ...|$|R
40|$|In this paper, {{we study}} {{the issue of}} {{estimating}} a structured signal x_ 0 ∈R^n from non-linear and noisy Gaussian observations. Supposing that x_ 0 is contained in a certain convex subset K ⊂R^n, we prove that accurate recovery is already feasible {{if the number of}} observations exceeds the effective dimension of K, which is a common measure for the complexity of signal classes. It will turn out that the possibly unknown non-linearity of our model affects the error rate only by a multiplicative constant. This achievement is based on recent works by Plan and Vershynin, who have suggested to treat the non-linearity rather as noise which perturbs a linear measurement process. Using the concept of restricted strong convexity, we show that their results for the generalized Lasso can be extended to a fairly large class of convex loss functions. Moreover, we shall allow for the presence of adversarial noise so that even deterministic model inaccuracies can be coped with. These generalizations particularly give further evidence of why many standard estimators perform surprisingly well in practice, although they do not rely on any knowledge of the underlying <b>output</b> <b>rule.</b> To this end, our results provide a unified and general framework for signal reconstruction in high dimensions, covering various challenges from the fields of compressed sensing, signal processing, and statistical learning...|$|E
40|$|Many {{computational}} intelligence techniques for anomaly based network intrusion detection {{can be found}} in literature. Translating a newly discovered intrusion recognition criteria into a distributable rule can be a human intensive effort. This paper explores a multi-modal genetic algorithm solution for autonomous rule creation. This algorithm focuses on the process of creating rules once an intrusion has been identified, rather than the evolution of rules to provide a solution for intrusion detection. The algorithm was demonstrated on anomalous ICMP network packets (input) and Snort <b>rules</b> (<b>output</b> of the algorithm). <b>Output</b> <b>rules</b> were sorted according to a fitness value and any duplicates were removed. The experimental results on ten test cases demonstrated a 100 percent rule alert rate. Out of 33, 804 test packets 3 produced false positives. Each test case produced a minimum of three rule variations that could be used as candidates for a production system...|$|R
5000|$|Direct Systems (Dictionary Based Machine Translation) map {{input to}} <b>output</b> with basic <b>rules.</b>|$|R
40|$|The {{focus of}} the {{analysis}} is the tool for designing a definition, expressing {{the nature of a}} concept and the opportunity to apply this tool in economic research. The selected approach is a conceptual analysis of the relation "concept (necessity and sufficiency) – the definition as a cognitive explication – the contents of the definition (mainly of an economic object) -characteristics and varieties (fundamental and contextual, stipulating, etc) of the economic definition". The applicability of the fundamental theory was proven to define a concept of an object and some general deficits of this process are identified in the economic studies. The <b>output</b> <b>rules</b> are summarized for elaborating such an economic information. ...|$|R
40|$|This paper {{presents}} an integrative approach for design-for-recycling of products. A system approach is suggested integrating the products recycling feautres, the recycling {{process and the}} product logistic support during the products life cycle. Design-for-recycling {{is defined as a}} design for ease of product and maximum <b>output.</b> <b>Rules</b> dedicated for design-for-recycling are given particularly to the disassembly process of a product during the recycling stage. The design approach is demonstrated by investigating a washing machine as a representative of a "white" household machines family. The recyclability of the machine is evaluated, where different design-forrecycling rules are applied in order to improve the machine recycling characteristics...|$|R
50|$|Developers should design {{programs}} so {{that they}} do not print unnecessary <b>output.</b> This <b>rule</b> aims to allow other programs and developers to pick out the information they need from a program's output without having to parse verbosity.|$|R
40|$|In recent papers it {{is shown}} {{that in the}} {{presence}} of price stickiness, investment and capital accumulation activity, active monetary policy (MP) rules can lead to indeterminacy under various assumptions about the structure of the model. We analyze the conditions for real indeterminacy to occur in the model with capital accumulation. The key assumption is that we add response to output to the monetary policy rule. In our paper we show that adding Current or Expected <b>Output</b> to MP <b>rule</b> substantially changes the conditions for real indeterminacy to occur. In contrast to some existing research we show that under current-looking with respect to <b>output</b> MP <b>rules</b> indeterminacy is almost impossible; under forward-looking with respect to <b>output</b> MP <b>rules</b> indeterminacy is almost impossible under active MP rules and very likely to occur under passive MP rules. We also show that stability conditions are almost not sensitive to changes in capital share in output and aggregate markup. We provide the nominal determinacy analysis and show that active and forward-looking MP rules with respect to output give...|$|R
40|$|This {{conceptual}} paper {{examines the}} democratic legitimacy of multi-stakeholder initiatives, global regulatory mechanisms involving corporations {{and civil society}} to solve public problems. It identifies three driving factors of input legitimacy (rule credibility) and three driving factors of <b>output</b> legitimacy (<b>rule</b> effectiveness) and examines their interplay...|$|R
50|$|User-defined <b>rules,</b> <b>output</b> specs, and layout specs can be {{used for}} {{intelligent}} templates and enable resource sharing (for example, server-based style sheet definitions).|$|R
30|$|However, {{involving}} {{developing world}} collaborators in {{the drafting of}} a data sharing agreement will be meaningless if {{they are unable to}} access or interpret data. For example, while consortium or data sharing agreements typically specify database access rules (all consortium partners usually have access to a common consortium database) and research <b>output</b> <b>rules</b> (authorship sequence in consortium publications is usually determined by the respective contributions of consortium partners), partners from developing countries often lack the resources to access the pooled data, or the experience and confidence to equally contribute to research output based thereon. This places the better-resourced and experienced collaborators from affluent countries at a distinct advantage in regard to exploiting the common database and authoring publications based thereon. As such, developing world partners are sometimes absent from consortium research outputs or relegated to junior co-authorship status in such works.|$|R
40|$|Abstract Regarding {{association}} rules, transcriptomic data {{represent a}} difficult mining context. First, {{the data are}} high-dimensional which asks for an algorithm scalable {{in the number of}} variables. Second, expression values are typically quantitative variables. This variable type further increases computational demands and may result in the output with a prohibitive number of redundant rules. Third, the data are often noisy which may also cause a large number of rules of little significance. In this paper we tackle the above-mentioned bottlenecks with an alternative approach to the quantitative association rule mining. The approach is based on simple arithmetic operations with variables and it <b>outputs</b> <b>rules</b> that do not syntactically differentiate from classical association rules. We also demonstrate the way in which apriori genomic knowledge can be used to prune the search space and reduce the amount of derived rules...|$|R
40|$|Abstract. Association {{rules have}} {{exhibited}} an excellent {{ability to identify}} interesting association relationships among a set of binary variables describing huge amount of transactions. Although the rules can be relatively easily generalized to other variable types, the generalization {{can result in a}} computationally expensive algorithm generating a prohibitive number of redundant rules of little significance. This danger especially applies to quantitative and ordinal variables. This paper presents and verifies an alternative approach to the quantitative and ordinal association rule mining. In this approach, quantitative or ordinal variables are not immediately transformed into a set of binary variables. Instead, it applies simple arithmetic operations in order to construct the cedents and searches for areas of increased association which are finally decomposed into conjunctions of literals. This scenario <b>outputs</b> <b>rules</b> that do not syntactically differentiate from classical association rules...|$|R
50|$|Developers should {{design for}} {{visibility}} and discoverability by {{writing in a}} way that their thought process can lucidly be seen by future developers working on the project and using input and output formats that make it easy to identify valid input and correct <b>output.</b> This <b>rule</b> aims to reduce debugging time and extend the lifespan of programs.|$|R
40|$|In a globalizing world, {{governments are}} not always able or willing to {{regulate}} the social and environmental externalities of global business activities. Multi-stakeholder initiatives (MSI), defined as global institutions involving mainly corporations and civil society organizations, are one type of regulatory mechanism that tries to fill this gap by issuing soft law regulation. This conceptual paper examines the conditions of a legitimate transfer of regulatory power from traditional democratic nation-state processes to private regulatory schemes, such as MSIs. Democratic legitimacy is typically concerned with input legitimacy (rule credibility, or {{the extent to which}} the regulations are perceived as justified) and <b>output</b> legitimacy (<b>rule</b> effectiveness, or {{the extent to which the}} rules effectively solve the issues). In this study, we identify MSI input legitimacy criteria (inclusion, procedural fairness, consensual orientation, and transparency) and those of MSI <b>output</b> legitimacy (<b>rule</b> coverage, efficacy, and enforcement), and discuss their implications for MSI democratic legitimacy...|$|R
50|$|Rules {{post-processed}} by statistics: Translations {{are performed}} using a rules based engine. Statistics are then {{used in an}} attempt to adjust/correct the <b>output</b> from the <b>rules</b> engine.|$|R
40|$|Abstract: In the {{approximate}} fuzzy reasoning the covering over of fuzzy rule base input and rule premise of a rule determines {{the importance of}} that fuzzy rule and the <b>rule</b> <b>output</b> as well. An axiom system has been created, describing {{the relationship between the}} fuzzy rule base system, rule input and <b>rule</b> <b>output.</b> By using distance-based operators a novel reasoning method appears by the compositional rule of inference, which is based on similarity measures of fuzzy sets, and it will be shown that this new system satisfies the mentioned axiom system. ...|$|R
30|$|Most of the {{existing}} extraction methods adopt an extraction mode of learning rules first and then extracting, a popular branch is to use supervised or semi-supervised methods to learn the extraction rules based on web page structures, such as DOM (Document Object Model) tree [1, 2] or XPath [3], and then to use the <b>output</b> <b>rules</b> to find the extracted objectives. However, the myriad web page templates adopted by different web sites, especially rich formats contributed by flexible and creative users, may cause the learned extraction rules failed. The adaptability {{is necessary for the}} contemporary extraction methods except for extraction precision. Both the diversity and the variability of web page structures brought by presentation requirements make a bigger extraction challenge. Compared with extraction mode of rule learning first, the new extraction mode should make an instant extraction decision automatically on the characteristics of the current web pages to address the above challenges.|$|R
40|$|Various ways of {{estimating}} probabilities, mainly {{within the}} Bayesian framework, are discussed. Their relevance and application to machine learning is given, and their relative performance empirically evaluated. A method of accounting for noisy data is given and also applied. The reliability of estimates {{is measured by}} a significance measure, which is also empirically tested. We briefly discuss the use of likelihood ratio as a significance measure. 1 Introduction The importance of conditional probability estimation in machine learning has been rightly stressed in, for example, [4]. Learning algorithms generally <b>output</b> <b>rules</b> of the form C / A. An obvious measure {{of the quality of}} such a rule is simply P (CjA) = p, the probability that a randomly chosen example, given that it is covered by the rule, is correctly classified by the rule. 1 We will sometimes informally refer to p as the probability of the rule C / A. The exact value of p will generally be unknown [...] -but it can be estima [...] ...|$|R
5000|$|While {{the bulk}} of {{personal}} walkie-talkie traffic is in the 27 MHz and 400-500 MHz area of the UHF spectrum, there are some units that use the [...] "Part 15" [...] 49 MHz band (shared with cordless phones, baby monitors, and similar devices) {{as well as the}} [...] "Part 15" [...] 900 MHz band; in the US at least, units in these bands do not require licenses as long as they adhere to FCC Part 15 power <b>output</b> <b>rules.</b> A company called TriSquare is, as of July 2007, marketing a series of walkie-talkies in the United States based on frequency-hopping spread spectrum technology operating in this frequency range under the name eXRS (eXtreme Radio Service—despite the name, a proprietary design, not an official allocation of the US FCC). The spread-spectrum scheme used in eXRS radios allows up to 10 billion virtual [...] "channels" [...] and ensures private communications between two or more units.|$|R
40|$|In this paper, {{we present}} a swarm {{intelligence}} based technique for mining rules over a medical database. Rules are a suitable method for representing real world medical knowledge because of their simplicity, uniformity, transparency, and ease of inference. Swarm Intelligence (SI) {{has been applied to}} the rule mining process as its dynamic nature provides flexibility and robustness to process of rule mining. Traditional methods of rule mining generate a large number of rules with too many terms, making the system unusable over medical data. In this paper, the attempt is to use SI as a novel method for discovering interesting rules in the medical domain. The performance of three different swarm based techniques has been compared by observing the <b>output</b> <b>rules</b> of rule sets used to classify data. Section 1 introduces the concept of swarm intelligence and rule mining and how these can be combined. Issues that arise in mining medical data are also briefly listed. Section 2 describes conventional rule mining techniques and states the motivation behind using swarm intelligence for rule mining and classification. Section 3 describes the various SI based algorithms that have been implemented in our study. Section 4 describes the details of the experiment. Section 5 presents the results of the practical experiment followed by conclusions and future scope in section 6...|$|R
40|$|Fuzzy {{inference}} process {{usually involves}} the use of fuzzy rule base consisting in several fuzzy <b>rules.</b> Overall <b>output</b> can be obtained by aggregation of <b>outputs</b> of all <b>rules.</b> To obtain an <b>output</b> of individual <b>rule</b> the relevancy of this rule is calculated. Then the individual output is obtained from the relevancy and the consequent of the rule. Such process can be realised using an operator that is called the relevancy transformation operator. It must fulfil some requirements, which are tightly connected with an aggregation step. The properties of such operators are studied. Keywords: Implication, Conjunction, Relevancy transformation operator...|$|R
50|$|Since {{the fuzzy}} system output is a {{consensus}} {{of all of the}} inputs and all of the rules, fuzzy logic systems can be well behaved when input values are not available or are not trustworthy. Weightings can be optionally added to each rule in the rulebase and weightings can be used to regulate {{the degree to which a}} <b>rule</b> affects the <b>output</b> values. These <b>rule</b> weightings can be based upon the priority, reliability or consistency of each rule. These rule weightings may be static or can be changed dynamically, even based upon the <b>output</b> from other <b>rules.</b>|$|R
40|$|We review fuzzy-control {{principles}} and show a simulation program permitting convenien t generation of membership functions and simple output interpolation. Interactive simulation {{is more than}} ordinarily important for economical fuzzy-controller design, which must {{reduce the number of}} membership classes and input/ <b>output</b> <b>rules</b> as much as possible. We use a personal computer and interactive editing to compare linear and fuzzy servo controllers. With 50 per cent class-membership overlap ("pseudo dither"), our fuzzy logic produces linear interpolation, and thus completely unimpaired servo performance even if we use only 2 fuzzy sets ("positive " and negative") each for error and output rate. A Servomechanism Given a servomechnism with input u = u(t), output x, output rate xD, and error e = x- u, a conventional linear controller produces a motor voltage k and r are controller gain and damping parameters. The resulting motor torque, say torque = maxtrq * sat(g 2 * Q/maxtrq (2) is saturation-limited at-maxtrq and maxtrq; G 2 is another servo-gain parameter. Assuming unit inertia for convenience, the servo equations of motion (state equations) are R is a motor damping coefficient...|$|R
30|$|Inference system: In this step, the fuzzified inputs {{are taken}} {{and applied to}} the antecedents of the fuzzy rules. It is then applied to the {{consequent}} membership function. Finally, the <b>outputs</b> of all <b>rules</b> are merged.|$|R
