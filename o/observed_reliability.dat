37|157|Public
3000|$|... {{because the}} <b>observed</b> <b>reliability</b> of {{neighbor}} j typically {{varies with the}} share of messages it receives from i. As j receives a larger share, a greater portion of their destinations are farther from j, making those messages harder for j to deliver. Thus, ∂R [...]...|$|E
30|$|We next {{considered}} {{a more sophisticated}} message-dropping attack in which the attackers vary their behavior over time {{in an effort to}} avoid detection. Malicious peers coordinate these behavior changes to keep each malicious peer's <b>observed</b> <b>reliability</b> relatively high while keeping overall network connectivity low. In our simulation, attackers chose their reliabilities from a normal distribution of mean 0.3 and variance 0.12. A coordinated, distributed, denial-of-service attack of this kind can be quite effective against defense mechanisms that rely on average reliability as the sole indicator of maliciousness. Our protocol's inclusion of risk as a secondary indicator was therefore important for resisting this attack.|$|E
40|$|Thesis {{deals with}} the finding {{reliable}} measurement {{of the quality of}} milk by automatic milking system. The <b>observed</b> <b>reliability</b> of the system to measure the quality of milk is a significant parameter for herd management and also an effective tool for farmers. Thanks notice on udder health in the program T 4 C farmer is able to detect a number of health problems or deficiencies in the herd before they break out in full force. This gives the farmer more options to treat dairy cows, such as inflammation, at the very beginning and as such can successfully use homeopathic treatment...|$|E
40|$|Current genomic {{prediction}} equations, when {{carried out}} in multiple populations with admixed structures ignore structure and assume these populations are uniform. The <b>observed</b> <b>reliabilities</b> of direct genomic breeding values (DGV) for unproven bulls in these populations {{so far have been}} low. The current study evaluated reliabilities of DGV in selection candidates using multi-trait random regression model which account for interactions between marker effects and breed of origin in the admixed Nordic Red dairy cattle. Our breed-specific model used breed proportions (BP) as random predictors and deregressed proofs of estimated breeding values (DRP) as response variables weighted by approximated reliability of DRP. Reliabilities were explored as squared correlation between DRP and DGV, weighted by the mean reliability of DRP. Estimated reliabilities were low for milk (0. 32) and protein (0. 32) and slightly higher (0. 42) for fat. <b>Observed</b> <b>reliabilities</b> were similar to those estimated assuming homogenous structure. The Nordic Red cattle is admixed but closely related, thus, the model under investigation may have been unable to differentiate additive genetic effects by breed of origin with a medium dense marker dat...|$|R
5000|$|After <b>observing</b> <b>reliability</b> {{of winter}} truck traffic over Maine State Route 16, the Lawrence Plywood Company petitioned the {{railroad}} to resume service from their Carrabasset mill to Farmington. Operations resumed on 17 April 1933, with sale of unused equipment as scrap to meet operating costs. Dismantling {{of the former}} P&R began {{during the summer of}} 1934, but service to Phillips was required to reach the railroad machine shops; so the receivers petitioned for abandonment when rail removal reached Phillips in April 1935. [...] A scrap metal firm purchased the railroad at auction in May and service ended on 2 July 1935. Remaining rails were lifted for scrap metal in 1936.|$|R
40|$|Abstract- In {{order to}} assess {{sufficiency}} of Latvian power system, research simulation model has been created. It embraces Latvian, Estonian and Lithuanian systems and parts of Russian and Belorussian power systems. The software LDM-AD has been applied for analysis performance on reliability of transmission network substations and switchgear units, as well as technical and economic analysis of several dynamic development process options <b>observing</b> <b>reliability</b> economic indicators. The researches performed on planning methodology development indicated that system sufficiency estimation for 5 and 10 horizon is not capable to ensure sustainable development strategy. In order to ensure long-term development, entirely different planning methodology and other tools for analysis are required. The planning process shall be sustainable taking into consideration rather long prospective period from 30 to 50 years...|$|R
40|$|We {{present an}} {{architecture}} for autonomous creatures that allows {{learning to be}} combined with action selection, based on ideas from ethology. We show how temporal-difference learning may be used {{within the context of}} an ethologically inspired animat architecture to build and modify portions of the behavior network, and to set fundamental parameters including the strength associated with individual Releasing Mechanisms, the time course associated with appetitive behaviors, and the learning rates to be used based on the <b>observed</b> <b>reliability</b> of specific contingencies. The learning algorithm has been implemented as part of the Hamsterdam toolkit for building autonomous animated creatures. When implemented in Silas, a virtual dog, the algorithm enables Silas to be trained using classical and instrumental conditioning. ...|$|E
40|$|A more {{reliable}} automatic picking technique {{has been developed}} and tested during onsite analyses of microseismicity in practical Hot Dry Rock developments. The technique imitates human procedures {{by a combination of}} various signal processing techniques. A trial using laboratory data and past field waveforms from the Soultz HDR project in 2000 indicated good reliability as the source locations were very similar to those based on manual picking. By using the technique, about 12, 000 events were successfully located during onsite analysis both at Soultz and Australia in 2003. The <b>observed</b> <b>reliability</b> of the source locations suggests that in the future this technique may be used for more precise onsite analysis as more complex techniques can be applied using the automatic picking of the P- and S-wave arrivals...|$|E
40|$|Reliability {{generalization}} (RG) is {{a meta-analysis}} that combines and synthesizes reliability coefficients from different studies {{to ascertain the}} average <b>observed</b> <b>reliability</b> across studies. An RG study was conducted on previously reported data from 16 samples of the Overexcitability Questionnaire–Two (OEQII) with a combined N of 5, 275. Cronbach’s alpha {{was found to be}} consistently higher on all OEQII subscales when scale variance was high and the sample consisted of adults. Sample size, gender composition of the sample, number of items from the subscale used, and location of sample (United States or a different county) had varying effects on observed alpha levels for each subscale. Suggestions are proposed for substantive research using the OEQII and for future psychometric research on the instrument...|$|E
40|$|BACKGROUND: Performance {{reporting}} is increasingly focused on physician practice sites and individual physicians. OBJECTIVE: To assess {{the reliability of}} performance measurement for practice sites and individual physicians. RESEARCH DESIGN: We used data collected across multiple payers {{as part of a}} statewide measurement collaborative to evaluate the <b>observed</b> measure <b>reliability</b> and sample size requirements to achieve acceptable reliability of 4 Health Care Effectiveness Data and Information Set measures of preventive care and 10 Health Care Effectiveness Data and Information Set measures of chronic care across 334 practice sites. We conducted a parallel set of physician-level analyses using data across 118 primary physicians practicing within a large multispecialty group. MEASURES: <b>Observed</b> <b>reliabilities</b> and estimated sample size requirements to achieve reliability >/= 0. 70. RESULTS: At the practice site level, sample sizes required to achieve a reliability of 0. 70 were less than 200 patients per site for all 4 measures of preventive care, all 4 process measures of diabetes care, and 2 outcomes measures of diabetes care. Larger samples were required to achieve reliability for cholesterol screening in the presence of cardiovascular disease (n = 249) and use of appropriate asthma medications (n = 351). At the physician level, less than 200 patients were required for all 4 measures of preventive care, but for many chronic care measures the samples of patients available per physician were not sufficient to achieve a reliability of 0. 70. CONCLUSION: In a multipayer collaborative, sample sizes were adequate to reliably assess clinical process and outcome measures at the practice site level. For individual physicians, sample sizes proved adequate to reliably measure preventive care, but may not be feasible for chronic care assessment...|$|R
40|$|Annotators of {{multimodal}} corpora rely on {{a combination}} of audio and video features to assign labels to the events <b>observed.</b> The <b>reliability</b> of annotations may be influenced by the presences or absence of certain key features. For practical applications it can be useful to know what circumstances determined fluctuations in the interannotator agreement. In this paper we consider the case of annotations of addressing on the AMI corpus. 1...|$|R
40|$|A 1. 5 V, 10 -bit, 14. 3 MS/s {{pipeline}} {{analog-to-digital converter}} was implemented in a 0. 6 #mCMOS technology. Emphasiswas placed on <b>observing</b> device <b>reliability</b> constraints at low voltage. MOS switches were implemented without low-threshold devices {{by using a}} bootstrapping technique that does not subject the devices to large terminal voltages. The converter achieved a peak SNDR of 58. 5 dB, maximum DNL of 0. 51 LSB, maximum INL of 0. 66 LSB and a power consumption of 36 mW...|$|R
40|$|We tackle two {{problems}} {{of interest to}} the software assurance community. Firstly, existing models of software development (such as the waterfall and spiral models) are oriented towards one-off software development projects, while the growth of mass market computing has led to a world in which most software consists of packages which follow an evolutionary development model. This leads us to ask whether anything interesting and useful may be said about evolutionary development. We answer in the affirmative. Secondly, existing reliability growth models emphasise the Poisson distribution of individual software bugs, while the empirically <b>observed</b> <b>reliability</b> growth for large systems is asymptotically slower than this. We provide a rigorous explanation of this phenomenon. Our reliability growth model is inspired by statistical thermodynamics, but also applies to biological evolution. It is in close agreement with experimental measurements of the fitness of an evolving species a [...] ...|$|E
40|$|Using {{detailed}} data of approximately 125, 000 solar photovoltaic systems installed in California between 2007 and 2014 I {{argue that the}} adoption of solar panels from Chinese manufacturers and the in- troduction of a leasing model for solar systems are closely intertwined. First, cheaper Chinese panels allowed a leasing model to be profitable for contractors. But an asymmetric information problem exists {{in the market for}} solar panels. Solar panels are long-lived productive as- sets, where quality is important but costly for individual consumers to verify. Consumers can instead be expected to rely on brands and <b>observed</b> <b>reliability.</b> This led to a barrier to entry for cheaper pan- els from new, primarily Chinese manufacturers. The adoption of a leasing model by several large local installers solved the asymmetric information problem and led to the adoption of Chinese panels and in turn lower overall system prices...|$|E
40|$|Previous HCI-studies have {{compared}} usability evaluation methods quantitatively without supplementing these data with detailed qualitative data about how analysts actually learn and use methods. In contrast, we present two diary-based case studies that describe {{the processes of}} two novice analysts who learned about and applied the Cognitive Walkthrough (CW; Lewis, et al., 1990) to the specification of a multimedia authoring system. Results show that the two analysts easily learned to use CW but also that they found the technique tedious to use. Moreover, CW was neither reliable when comparing the two analysts ’ processes and outcomes to each other, nor accurate when comparing the analysts ’ problem predictions to results from usability tests applied to a running system. We examine these data in detail, searching for possible causes of the <b>observed</b> <b>reliability</b> and accuracy. Based on these analyses, we suggest three changes to CW method to improve its accuracy and two changes to improve its reliability. Further, we recommend developin...|$|E
40|$|A light curve {{data file}} is presented. Each {{citation}} includes the year, all authors, journal or book name, volume, and {{first and last}} page numbers. The asteroid list is ordered by asteroid number, followed by asteroid name, the period in hours, amplitude of variation or range of amplitude <b>observed,</b> and a <b>reliability</b> code...|$|R
40|$|Optical and {{magneto-optical}} {{properties of}} amorphous Gd 22 Fe 78 (GdFe) thin films prepared by direct current (DC) sputtering on thermally oxidized substrates {{were characterized by}} the combination of spectroscopic ellipsometry and magneto-optical spectroscopy in the photon energy range from 1. 5 to 5. 5 eV. Thin SiNx and Ru coatings were used to prevent the GdFe surface oxidation and contamination. Using advanced theoretical models spectral dependence of the complete permittivity tensor and spectral dependence of the absorption coefficient were deduced from experimental data. No {{significant changes in the}} optical properties upon different coatings were <b>observed,</b> indicating <b>reliability</b> of used analysis...|$|R
40|$|In this study, {{the fatigue}} {{performance}} of solder joints in four point bending test was evaluated by a novel finite-element modeling method. A simplified modeling technique was implemented {{in order to}} focus on the behavior of the critical solder joint. The fatigue life was estimated by taking into account the creep behavior of solder joints. Morrow's fatigue model was utilized to determine the fatigue life. The results were compared with the ongoing test results. Some additional studies were performed in order to <b>observe</b> the <b>reliability</b> of the modeling method and the effect test parameters. status: publishe...|$|R
40|$|Metal-insulator-metal {{capacitor}} (MIMC) {{reliability and}} electrical properties {{are defined by}} the TDDB lifetime. breakdown voltage and leakage current. In this article, the correlation is determined between these electrical properties and the {{physical and chemical properties}} of the SiN dielectric layer. It is demonstrated how a SiN dielectrics with a high refractive index have high Si content and show an increased initial leakage Current. However, contradictory to the high leakage current, these dielectrics also show high lifetimes. It is shown that SiN dielectrics with a high Si content contain high numbers of charge trapping centers. Over time, a high concentration of trapped charges is build up to such an extend that the local electric field over the dielectric is significantly decreased. This results in the <b>observed</b> <b>reliability</b> improvement of the dielectric. The final intrinsic quality and reliability of MIMC capacitors can therefore be determined by Measurable physical properties of the MIMC dielectric {{at the time of the}} deposition of this layer. (C) 2008 Elsevier Ltd. All rights reserved...|$|E
40|$|Data {{transport}} is a core {{function for}} Wireless Sensor Networks (WSNs) with different applications having varied requirements on {{the reliability and}} timeliness of data delivery. While node redundancy, inherent in WSNs, increases the fault tolerance, no guarantees on reliability levels can be assured. Furthermore, the frequent failures within WSNs impact the <b>observed</b> <b>reliability</b> over time {{and make it more}} challenging to achieve the desired reliability. Unfortunately, a framework for modeling reliability of data transport protocols in WSNs is currently missing. The existence of such a framework would simplify evaluation, comparison and also adaptation of these protocols. We formulate the problem of data transport in a WSN as a set of operations carried out on raw data. The operations aim at filtering the raw data to streamline its reliable transport towards the sink. Based on this formulation we systematically define a reliability framework. This paper argues for the usefulness of the reliability framework by classifying existing transport protocols and comparing their reliability. 1...|$|E
40|$|Abstract — Traditional {{approaches}} to programming robots are generally inaccessible to non-robotics-experts. A promising {{exception is the}} Learning from Demonstration paradigm. Here a policy mapping world observations to action selection is learned, by generalizing from task demonstrations by a teacher. Most Learning from Demonstration work to date considers data from a single teacher. In this paper, we consider the incorporation of demonstrations from multiple teachers. In particular, we contribute an algorithm that handles multiple data sources, and additionally reasons about reliability differences between them. For example, multiple teachers could be inequally proficient at performing the demonstrated task. We introduce Demonstration Weight Learning (DWL) as a Learning from Demonstration algorithm that explicitly represents multiple data sources and learns to select between them, based on their <b>observed</b> <b>reliability</b> and according to an adaptive expert learning inspired approach. We present a first implementation of DWL within a simulated robot domain. Data sources are shown to differ in reliability, and weighting is found impact task execution success. Furthermore, DWL is shown to produce appropriate data source weights that improve policy performance. I...|$|E
40|$|Thermally tunable SiN {{waveguide}} microring resonators {{in connection}} with neural network readout algorithms appear promising for use as integrated optical wavelength meters. So far, we have <b>observed</b> long-term <b>reliability</b> and a temperature immunity of the readout across several degrees of ambient temperature change [1]. However, further exploration is required for {{a better understanding of}} such immunity, and the free spectral range should be increased. With the goal to interpret future experimental data across a larger temperature range and a wider free spectral range we have modelled the influence of thermal offset heating and the transmission properties of coupled microring resonators...|$|R
3000|$|Van Dyne et al. (2012) Expanded Cultural Intelligence Scale (E-CQS) was adopted. The E-CQS is an {{expanded}} {{version of the}} Cultural Intelligence Scale (CQS) (Ang et al., 2007). The instrument comprises of 37 items measured on a 7 -point Likert scale (ranging from 1 [*]=[*]strongly disagree to 7 [*]=[*]strongly agree). The scale focuses on eleven (11) sub-dimensions and four (4) dimensions of cultural intelligence; cognitive, meta-cognitive, motivation and behavioral. In the present study, we only measured the behavioral dimension (9 items) and <b>observed</b> high <b>reliability,</b> α of [...]. 94. A sample item is “I change how I make requests of others depending on their cultural background”.|$|R
40|$|Background: A {{prototype}} {{risk assessment}} suite (FACE-CARAS) {{was developed for}} use within CAMHS and evaluated for acceptability and reliability. Method: Clinicians underwent brief training {{in the system and}} invited 69 young people to an assessment using the FACE-CARAS. A second rater produced a separate set of blind ratings for most patients. Clinicians also provided qualitative feedback. Results: The component schedules of the FACE-CARAS could be reliably rated with ‘near perfect’ to ‘moderate’ agreement <b>observed.</b> Internal <b>reliability</b> consistency values, as indexed by Cronbach's alpha, were moderate to high in all cases. Conclusions: The assessment schedules that make up the FACE-CARAS can be reliably rated by clinicians with minimal training...|$|R
40|$|Abstract: 2 ̆ 2 Previous HCI-studies have {{compared}} usability evaluation methods quantitatively without supplementing these data with detailed qualitative data about how analysts actually learn and use methods. In contrast, we present two diary-based case studies that describe {{the processes of}} two novice analysts who learned about and applied the Cognitive Walkthrough (CW; Lewis, et al., 1990) to the specification of a multimedia authoring system. Results show that the two analysts easily learned to use CW but also that they found the technique tedious to use. Moreover, CW was neither reliable when comparing the two analysts 2 ̆ 7 processes and outcomes to each other, nor accurate when comparing the analysts 2 ̆ 7 problem predictions to results from usability tests applied to a running system. We examine these data in detail, searching for possible causes of the <b>observed</b> <b>reliability</b> and accuracy. Based on these analyses, we suggest three changes to CW method to improve its accuracy and two changes to improve its reliability. Further, we recommend developing a tool to reduce the tedium and integrate our suggested improvements to CW. 2 ̆...|$|E
40|$|Traditional {{approaches}} to programming robots are generally inaccessible to non-robotics-experts. A promising {{exception is the}} learning from demonstration paradigm. Here a policy mapping world observations to action selection is learned, by generalizing from task demonstrations by a teacher. Most learning from demonstration work to date considers data from a single teacher. In this paper, we consider the incorporation of demonstrations from multiple teachers. In particular, we contribute an algorithm that handles multiple data sources, and additionally reasons about reliability differences between them. For example, multiple teachers could be inequally proficient at performing the demonstrated task. We introduce Demonstration Weight Learning (DWL) as a learning from demonstration algorithm that explicitly represents multiple data sources and learns to select between them, based on their <b>observed</b> <b>reliability</b> and according to an adaptive expert learning inspired approach. We present a first implementation of DWL within a simulated robot domain. Data sources are shown to differ in reliability, and weighting is found impact task execution success. Furthermore, DWL is shown to produce appropriate data source weights that improve policy performance...|$|E
40|$|A {{method was}} {{presented}} to evaluate the reliability of axially loaded pile groups designed using the traditional concept of group efficiency {{along the lines of}} load and resistance factor design. Group effects and system effects were identified as the major causes that led to a significantly greater <b>observed</b> <b>reliability</b> of pile foundations than calculated reliability of single piles. Statistical analyses were conducted to evaluate these effects based on observed pile performance. A database of pile group load tests was collected and interpreted for this purpose. Subsequently, the reliability of pile groups associated with the allowable stress design practice was calculated using the suggested method. The calculated probability of failure of pile groups was found to be one to four orders of magnitude smaller than that of single piles, depending on the significance of group effects and system effects, Finally, values of the target reliability index P, for single piles required to achieve a specified target reliability of pile group foundations were calculated for several design methods. Due to group effects and system effects, the values of Ps should be different for single piles, a pile group, and a pile system of several groups...|$|E
30|$|From Fig.  2, we <b>observe</b> {{that the}} <b>reliability</b> {{function}} {{obtained by the}} EM algorithm method is {{much closer to the}} Kaplan–Meier estimate than that of the reliability function estimated by the WPP plot method. The plots of cdfs shown in Fig.  3 conclude the same. These indicate that the method of estimation with the EM algorithm procedure is better than the WPP plot procedure.|$|R
40|$|Are choice-based {{measures}} reliable? Are measures {{obtained from}} the online administration of choice tasks comparable to measures obtained from paper-and-pencil administration? Does the complexity of a choice task affect reliability and comparability? We answered these questions in a test-retest study. University student participants made choices for 24 pairs of jobs in test and retest phases. Students in the low task complexity condition choose between pairs of jobs described by six attributes; students in the high task complexity condition choose between pairs of jobs described by ten attributes. To assess reliability or comparability, we used the number of choices in agreement between test and retest. We <b>observed</b> high <b>reliability</b> and comparability across methods of administration and levels of task complexity...|$|R
40|$|Abstract "Creation, validation, and {{reliability}} of a shooting simulator instrument for reaction time evaluation. " The {{aim of this study}} was to develop, validate, and verify the reliability of a shooting simulator instrument for reaction time evaluation. 90 Santa Maria Air Base military personnel participated on the study. Software was developed for use with an electronic gun where participants performed two shooting task tests: simple reaction time and choice reaction time. The results of concurrent validity were satisfactory, no significant differences were found between the two instruments and good agreement was <b>observed.</b> The <b>reliability</b> results were significant in both tests. The instrument can be used for research purposes, or for the purposes of military training as a simple, low-cost tool involving speed, accuracy, and decision-making shooting tasks...|$|R
40|$|Trenchless {{technologies}} are methods {{used for the}} construction and rehabilitation of underground utility pipes. These methods are growing increasingly popular due to their versatility and their potential to lower project costs. The use of trenchless technologies in Iowa and their effects on surrounding soil and nearby structures has not been adequately documented, however. Surveys and interviews of professionals working in trenchless related industries in Iowa were carried out {{and the results are}} analyzed and compared to survey results from the United States as a whole. The surveys focused on method familiarity, pavement distress <b>observed,</b> <b>reliability</b> of trenchless methods, and future improvements. Results indicate that the frequency of pavement distress or other trenchless related problems is an ongoing problem in the industry. Inadequate soils information and QC/QA are partially to blame. Field work involving the observation of trenchless construction projects was undertaken with the purpose of documenting current practices and applications of trenchless technology in the United States and Iowa. Field testing was performed in which push-in pressure cells were used to measure the soil stresses induced by trenchless construction methods. A program of laboratory soil testing was run in conjunction with the field testing...|$|E
40|$|Abstract Background More {{than half}} of the {{patients}} harbouring the m. 3243 A[*]>[*]G mutation were found to have trouble maintaining balance when walking in a recent study by our group. Others demonstrated that these patients had an abnormal gait pattern, as quantified by gait analysis. Gait analysis is an emerging method to quantify subtle changes in walking pattern, also during therapeutic interventions. Therefore, we aimed to test the reliability and reproducibility of gait analysis and select the most suitable protocol for this group of patients using a GAITRite electronic walkway. Four different protocols were tested: normal walking, dual task, post exercise and after a ten minutes of rest. Results In total 36 patients with the m. 3243 A[*]>[*]G mutation and 50 healthy controls were enrolled in this study. Overall high intra class correlation coefficients were found in all experimental conditions for both patients and healthy controls indicating good reproducibility. Marked differences in gait between patients and controls were observed and were in line with the only available exploratory study performed. There was a good correlation between both the overall NMDAS score, NMDAS subscale scores, both markers for disease severity, and specific gait parameters. Conclusions The <b>observed</b> <b>reliability</b> of the test makes GAITRite a suitable instrument for intervention studies in patients with mitochondrial disease...|$|E
40|$|Objective: To {{introduce}} and verify an algorithm {{designed to}} administer adaptive speech-in- noise testing to a specified reliability at selectable {{points on the}} psychometric function. Design: Speech-in-noise performances were measured using BKB sentences presented in diffuse babble-noise, using morphemic scoring. Target of the algorithm was a test-retest standard deviation of 1. 13 dB within the presentation of 32 sentences. Normal-hearing participants completed repeated measures using manual administration targeting 50 % correct, and the automated procedure targeting 25 %, 50 %, and 75 % correct. Aided hearing-impaired participants completed testing with the automated procedure targeting 25 %, 50 %, and 75 % correct, repeating measurements at the 50 % point three times. Study sample: Twelve normal-hearing and 63 hearing-impaired people who had English as first language. Results: Relative to the manual procedure, the algorithm produced the same speech reception threshold in noise (p = 0. 96) and lower test-retest reliability on normal-hearing listeners. Both groups obtained significantly different results at the three target points (p < 0. 04) with <b>observed</b> <b>reliability</b> close to expected. Target accuracy was not reached within 32 sentences for 18 % of measurements on hearing-impaired participants. Conclusions: The reliability of the algorithm was verified. A second test is recommended if the target variability is not reached during the first measurement. 6 page(s...|$|E
3000|$|We further {{sought to}} improve {{reliability}} {{by taking the}} 78 trials from the second version that produced the highest correlation between item responses and subjects’ total scores (i.e., the most informative trials), while attempting to maximize the range of difficulty in test items, to create the final VCRT. For this final VCRT, we also ordered trials from easiest to most difficult based on the item accuracies produced in the second VCRT version. The final VCRT version has 80 trials total (including two catch trials), and takes approximately 20 min to complete. This final version had average accuracy of 53.00 % (SD[*]=[*] 10.13 %) and we <b>observed</b> acceptable <b>reliability</b> in our sample (α[*]=[*]. 799). This final version is available online at [URL] the data are available at [URL] [...]...|$|R
30|$|To {{evaluate}} the effectiveness and reliability of paternity assignment, we firstly matched the maternity assigned according to the screened ten microsatellite loci with recorded maternity and found that all the offspring was assigned correctly to the <b>observed</b> mother. The <b>reliability</b> of the assignment was estimated by the LOD ranged from 2.38 to 5.01 (mean ± SE, 3.56 ± 0.32), while there were two mismatched loci, D 6 S 311 (between ZY and HL) and D 16 S 403 (between LM and HT).|$|R
40|$|This article {{investigates the}} maximum time of {{simulation}} {{in which the}} phenomenon of the intermittence can be observed with numerical confidence in discrete maps. Interval analysis and the lower error limit were used. As a result, it was <b>observed</b> that the <b>reliability</b> of the intermittency is dependent on the initial condition. Four numerical examples show the efficiency of the proposal. Comment: DINCON 2017 - Conferencia Brasileira de Dinamica, Controle e Aplicacoes - Sao Jose do Rio Preto - Brazil. 7 pages. In Portugues...|$|R
