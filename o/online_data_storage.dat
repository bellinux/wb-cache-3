24|10000|Public
25|$|Medical {{records have}} {{traditionally}} been compiled and maintained by health care providers, but advances in <b>online</b> <b>data</b> <b>storage</b> {{have led to the}} development of personal health records (PHR) that are maintained by patients themselves, often on third-party websites. This concept is supported by US national health administration entities and by AHIMA, the American Health Information Management Association.|$|E
5000|$|CT Logistics {{processes}} Sarbanes-Oxley-compliant freight {{payments in}} all modes for carriers and clients of all industries. The company utilizes 7 to 10 years of <b>online</b> <b>data</b> <b>storage.</b> CT Logistics consults on {{all aspects of}} supply chains.|$|E
50|$|Medical {{records have}} {{traditionally}} been compiled and maintained by health care providers, but advances in <b>online</b> <b>data</b> <b>storage</b> {{have led to the}} development of personal health records (PHR) that are maintained by patients themselves, often on third-party websites. This concept is supported by US national health administration entities and by AHIMA, the American Health Information Management Association.|$|E
5000|$|... i-drive was an <b>online</b> {{computer}} <b>data</b> <b>storage</b> {{service that}} operated from 1998-2002.|$|R
50|$|Steek is {{a private}} {{technology}} company based in France which provides integrated <b>online</b> multimedia <b>data</b> <b>storage,</b> file sharing, and automated backup services to telecom operators, ISPs, and portals. Its services include online file hosting and file sharing.|$|R
50|$|Diino is a {{cloud storage}} provider, {{offering}} <b>online</b> backup <b>data</b> <b>storage</b> and file sharing. The company, Diino Systems AB, was founded 2004 {{and is based}} Stockholm, Sweden, with sales offices in Atlanta, London and Mexico City. Its owners include Swisscom.|$|R
50|$|CTSI-Global {{has been}} {{accredited}} with the Better Business Bureau since 1981. J. Kenneth Hazen acquired {{the company in}} 1982. Since that time, CTSI-Global has developed from a manual freight bill audit and payment operation into a global supply chain technology and services company. CTSI-Global processes Sarbanes-Oxley-compliant payments for carriers and clients from many industries. The company offers <b>online</b> <b>data</b> <b>storage.</b>|$|E
50|$|Services {{offered by}} iTools {{included}} the first availability of @mac.com email addresses, which {{could only be}} accessed through an email client (e.g. the Mail app); iCards, a free greeting card service; iReview, a collection of reviews of popular web sites; HomePage, a free web page publishing service; {{the first version of}} iDisk, an <b>online</b> <b>data</b> <b>storage</b> system; and KidSafe, a directory of family-friendly web sites.|$|E
50|$|The MySpace.com domain was {{originally}} owned by YourZ.com, Inc., intended until 2002 {{for use as}} an <b>online</b> <b>data</b> <b>storage</b> and sharing site. By 2004, it was transitioned from a file storage service to a social networking site. A friend, who also worked in the data storage business, reminded Chris DeWolfe that he had earlier bought the domain MySpace.com. DeWolfe suggested they charge a fee for the basic Myspace service. Brad Greenspan nixed the idea, believing that keeping Myspace free was necessary {{to make it a}} successful community.|$|E
40|$|This thesis {{deals with}} the {{utilization}} of cloud computing {{in the field of}} <b>online</b> <b>data</b> <b>storages</b> for storing and backing up of user data. After defining the target group and its requirements for the service, ten most suitable options from the total set of cloud storages were selected. Selected storages were subsequently tested and analyzed in order {{to be used in the}} next stage of thesis. Materials for multicriterial analysis of options were created on the basis of set criteria and their given or measured values. The most appropriate options were calculated by application of the aforementioned mathematical method. These options were then evaluated and described from the viewpoint of commissioning...|$|R
5000|$|The TeraGrid {{integrated}} high-performance computers, data {{resources and}} tools, and experimental facilities. Resources included {{more than a}} petaflop of computing capability and more than 30 petabytes of <b>online</b> and archival <b>data</b> <b>storage,</b> with rapid access and retrieval over high-performance computer network connections. Researchers could also access more than 100 discipline-specific databases.|$|R
50|$|In 1995, Audit Master was {{replaced}} by Dakota Auditor, a compliance software solution that integrates translated Federal Regulatory content. In 1999 Dakota Tracer, a corrective action tracking and analysis tool, is released to compliment Auditor. In 2002, Dakota anticipates the value of <b>online</b> <b>data</b> access and <b>storage</b> for their multi-location customers and makes their products available online as Software as a Service (SaaS).|$|R
40|$|Current Internet trends {{have caused}} us to outgrow {{existing}} <b>online</b> <b>data</b> <b>storage</b> paradigms. This paper presents an extended model for distributed <b>online</b> <b>data</b> <b>storage.</b> The model addresses issues of data duplication, data freshness and data ownership, while facilitating two modes of data access - direct and indirect. Direct data access is implemented using advanced handoff techniques while indirect access is implemented using robust server-to-server protocols that enforce strict policies on data management. Results are presented that compare this solution to existing technologies and an example migration path is described for existing Web 2. 0 applications wishing to adopt this new paradigm...|$|E
40|$|Abstract—Current Internet trends {{have caused}} us to outgrow {{existing}} <b>online</b> <b>data</b> <b>storage</b> paradigms. This paper presents an extended model for distributed <b>online</b> <b>data</b> <b>storage.</b> The model addresses issues of data duplication, data freshness and data ownership, while facilitating two modes of data access- direct and indirect. Direct data access is implemented using advanced handoff techniques while indirect access is implemented using robust server-to-server protocols that enforce strict policies on data management. Results are presented that compare this solution to existing technologies and an example migration path is described for existing Web 2. 0 applications wishing to adopt this new paradigm. Keywords-distributed, storage, personal data, data ownership I...|$|E
40|$|Abstract — Cloud {{computing}} {{is the use}} {{of computing}} resources (hardware and software) that are delivered as a service over a network (typically the Internet). The name comes from the use of a cloud-shaped symbol as an abstraction for the complex infrastructure it contains in system diagrams. Cloud computing entrusts remote services with a user's data, software and computation. Online storage is a great way for both businesses and consumers to back up crucial data and store it online as it offers both safe access while traveling along with allowing access by remote clients or employees. The fact that online storage of data is NOT on site means that a person’s or company’s data is protected from the usual kinds of corruption that can impact on in-house stored data such as equipment failure, robbery or accidental damage. While traditional storage devices such as hard drives, USB flash drives and DVD's still have their place in the IT market, <b>online</b> <b>data</b> <b>storage</b> is fast becoming {{one of the most popular}} methods. To clarify in simple terms, <b>online</b> <b>data</b> <b>storage</b> is where computer data is stored on the Web, allowing remote access from anywhere globally. The data that can be stored ranges from all information on a computer hard drive, email accounts, image storage and text files which is then accessible on demand through web server. I...|$|E
50|$|In May 2007, TeraGrid {{integrated}} resources {{included more}} than 250 teraflops of computing capability {{and more than}} 30 petabytes (quadrillions of bytes) of <b>online</b> and archival <b>data</b> <b>storage</b> with rapid access and retrieval over high-performance networks. Researchers could access more than 100 discipline-specific databases. In late 2009, The TeraGrid resources had grown to 2 petaflops of computing capability and more than 60 petabytes storage. In mid 2009, NSF extended the operation of TeraGrid to 2011.|$|R
40|$|The {{primary focus}} of the NEBULA Future Internet Architecture is to provide {{resilient}} net-working for the emerging cloud computing model. One of the attractions of cloud comput-ing is its support for <b>online</b> services and <b>data</b> <b>storage</b> by thin clients such as mobile de-vices. This paper describes two components of NEBULA’s edge network technology, Serval and CRYSTAL. Serval provides a new layer 3. 5 service abstraction that naturally supports mobility, multi-homing, and multi-path transport, while CRYSTAL is a new virtualization scheme for software radios {{that makes it easier}} to expose greater network diversity at the network edge. I...|$|R
40|$|The Level- 1 Trigger plays a {{major role}} in the CMS {{experiment}} allowing to reduce the raw event rate at the Large Hadron Collider. Its decision is based on information from the electromagnetic and hadronic calorimeters as well as the muon detectors. The electronics of the electromagnetic calorimeter generate and deliver basic quantities called "Trigger Primitives" which correspond to local energy deposits created by electromagnetic showers. In order to ensure the correct generation of the trigger primitives by the electronics, a special software (emulator) has been implemented. It is able to reproduce the ECAL trigger functionalities at the bit level using the same inputs and identical output format. It is configured in exactly the same way as the hardware. The configuration of the electromagnetic hardware trigger requires 5 million parameters stored into an <b>Online</b> Master <b>Data</b> <b>Storage</b> database (OMDS). This poster will present the procedure used to transfer the parameters from the OMDS to the Offline database which is used to perform the validation tests with the Level- 1 Trigger emulator...|$|R
40|$|The {{exponential}} data {{growth with}} diversified access patterns demands data storage {{to have different}} performance, cost and protection levels. ITStorage, an Internet Tape Storage system, is designed and prototyped to provide a cheap, “infinite ” <b>online</b> <b>data</b> <b>storage</b> for data backups from personal users and small businesses, whose data are not as well protected as enterprise data. With Extended High Performance Tape File System (EHPTFS) as the technology core, data interleaving and tape switches are transparent to user applications while tape metadata and media information are consolidated in a commodity relational database. The performance evaluations show that ITStorage provides good online write performance throug...|$|E
40|$|Symada Technologies is a Vancouver based {{start-up}} company offering <b>online</b> <b>data</b> <b>storage</b> and backup services. The company {{is interested in}} growing its existing customer base through development of additional online services. This paper analyses several growth options for Symada’s existing services platform. The analysis consists of market research for two main options; Web Hosting and Online Business Services. In addition, an internal analysis of Symada is presented to identify any important characteristics or core capabilities {{of the company that}} might influence which option would be the best for the company to grow. By combining the market analysis with the internal analysis, the paper is able to give some clear growth strategy recommendations to Symada. The recommendations aim to increase Symada’s customer base (and revenue), {{while at the same time}} staying within the financial constraints of the company...|$|E
40|$|ABSTRACTThe {{system of}} data storage is a service of cloud computing, that modifying {{the way that}} end users and {{companies}} use information technology. Although this phenomenon gets attention of professionals and the academic community, there are still few studies on the theme. This study aims to identify the factors influencing the adoption of <b>online</b> <b>data</b> <b>storage</b> systems based in the Diffusion of Innovations (DOI) Theory. Users of a social network compose the sample of the research. Data collection was made through an online survey. They were validated 189 answers. The technique used for data analysis was confirmatory factor analysis and structural equation modeling, using the method of partial least squares PLS-PM. The results showed that factors such as Compatibility, Ease of Use, Relative Advantage and Visibility determine the adoption of storage systems in the cloud. From these results, the companies that provide these services can create strategies for wider dissemination and commercialization of this innovation. The study is also advancing in theoretical adoption of cloud computing...|$|E
40|$|In the {{globalization}} era, rapid data communication and sufficient information {{is important to}} make the right decision at the right time. At present, various organizations/ industries in Bangladesh are using paper based methods, which are time consuming. Recently, few organizations have installed computerized systems instead of traditional systems. The use of internet-based technologies to communicate information {{is one of the best}} approaches to support the informational needs of various departments of an organization. In this research work a case study was performed on a specific Garments Industry. The existing information model of that factory is studied and then a conceptual information model named Factory Information System (FIS) was suggested. Then software was developed for a smooth flow of information. The developed software is composed by two sections that are design database and functions of programs or user interfaces design. The software is built using PHP with My-SQL database. Information sharing, <b>Online</b> <b>data</b> flow and <b>storage,</b> <b>Online</b> <b>data</b> retrieval. ...|$|R
500|$|Later on, critics {{felt that}} the Xbox One's {{functionality}} had matured over the year following its launch; Jeff Bakalar of CNET, assigning it a score of 8/10, acknowledged improvements to Xbox One's software since its original release, but that its user interface was still unintuitive in comparison to Xbox 360 and PlayStation 4, explaining that [...] "navigating the interface seems {{to be much more}} problematic than it rightfully should be, and there's simply not enough transparency in the logic within it. There are oddities peppered throughout, which is the root for countless headaches and frustrations." [...] Xbox One's in-game performance was mixed, with some titles showing slower performance over PS4, but some multi-platform games performing better on Xbox One than PS4. CNET praised the wider lineup of multimedia services and apps on Xbox One over PS4, not requiring Xbox Live Gold for <b>online</b> save <b>data</b> <b>storage,</b> support for high-speed USB 3.0 as secondary storage, and having a [...] "slightly better" [...] lineup of upcoming exclusives, concluding that [...] "While the PS4 had a clear advantage at launch, that edge is slowly evaporating as Microsoft has worked feverishly to undo most of the Xbox One's original missteps." ...|$|R
40|$|Abstract — Cloud {{computing}} technology {{providing services}} {{rather than a}} product that permits users to use applications without installation of applications and access their files, application on any personal computer, laptop, tab and mobile devices within the internet or intranet connection. Whereby the software, shared resources and information are provided as a utility network. The Cloud may share data in flexible manner across multiple users. Cloud computing are an internet based sharing service. It has some benefits as avoidance of capital expenditure on personal maintenance, Hardware, software and relief of <b>online</b> burden <b>data</b> <b>storage</b> in a network. Many users can continuously access service from the remote locations. Cloud arises some issues in data security, privacy, integrity, dynamic updates. On the user side every time {{it is not possible}} to check their data consistency of stored <b>data</b> on cloud <b>storage.</b> The cloud server stores large amount of data which does not offer guarantees on data integrity and consistency. This problem is solved by a public auditing method, which ensure the integrity and to reduce online burden on cloud <b>data</b> <b>storage.</b> So that user can resort to Third-Party Auditor (TPA) to audit the data by using the ring signatures for data security. The preserving identity privacy of the signer on each block from the TPA means, the group is pre-defined before sharing data is created in the cloud. The membership of each user in the group is not changed during the data sharing stage. The original user is responsible for who is able to share his data before outsourcing data to the cloud. The TPA audits the integrity of shared data across dynamic groups of users in the cloud...|$|R
40|$|The {{emergence}} of cloud datacenters enhances {{the capability of}} <b>online</b> <b>data</b> <b>storage.</b> Since massive data is stored in datacenters, {{it is necessary to}} effectively locate and access interest data in such a distributed system. However, traditional search techniques only allow users to search images over exact-match keywords through a centralized index. These techniques cannot satisfy the requirements of content based image retrieval (CBIR). In this paper, we propose a scalable image retrieval framework which can efficiently support content similarity search and semantic search in the distributed environment. Its key idea is to integrate image feature vectors into distributed hash tables (DHTs) by exploiting the property of locality sensitive hashing (LSH). Thus, images with similar content are most likely gathered into the same node without the knowledge of any global information. For searching semantically close images, the relevance feedback is adopted in our system to overcome the gap between low-level features and high-level features. We show that our approach yields high recall rate with good load balance and only requires a few number of hops...|$|E
40|$|Cloud {{storage is}} an <b>online</b> <b>data</b> <b>storage</b> {{and it is}} located as centrally. Cloud data ownerprovidethe {{facility}} for users to online store their data and access from any location. Though it has reliable for the user to achieve a secure and dependent cloud storage service. Ina key aggregate crypto-systemkey is generated fordifferent attributes of data in different cipher text classes and its associated keys. It derived aggregate key {{on the basis of}} attribute and identitywhich, depending on the different classes according to cloud data owner. By using this technique aunique cryptographic key achieves. It is optimallysecure for cloud data and privacy preserving key generating process. The cloud data ownerdecidesthe access levelof the data, such as public, private and hierarchyaccess level in order toenhance the data access capability in a data sharing cloud mechanism. Blowfish is thebest data security algorithm. It is higher security and faster execution as compared toother cryptographic algorithms. The blowfish algorithmis a secure for storing data in the cloud. It is an effective derivation of secret key generation and key management...|$|E
40|$|Recently, digital {{forensic}} examiners {{have seen}} a remarkable increase in requests to examine data from cellular phones. The examination of cellular phones and the extraction of data from the same present challenges for forensic examiners: The numbers of phones examined over time {{using a variety of}} tools and techniques may make it difficult for an examiner to recall the examination of a particular cell phone. There is an immense variety of cellular phones on the market, encompassing a array of proprietary operating systems and embedded file systems, applications, services, and peripherals. Cellular phones are designed to communicate with the phone network and other networks via Bluetooth, infrared and wireless (WiFi) networking. To best preserve the data on the phone it is necessary to isolate the phone from surrounding networks, which may not always be possible. Cellular phones employ many internal, removable and <b>online</b> <b>data</b> <b>storage</b> capabilities. In most cases, it is necessary to apply more than one tool in order to extract and document the desired data from the cellular phone and its storage media. In certain cases, the tools used t...|$|E
40|$|Abstract:- This paper {{focus on}} {{analysing}} and explaining structure of <b>data</b> pooling, <b>online</b> <b>data</b> pooling and partition Storage model, enterprise Cloud Storage System structure proposes {{the design for}} <b>data</b> control and <b>Storage</b> in Cloud. Storage Management Control is an effective method that will reduce the working time to large-scale in <b>data</b> <b>Storage</b> management. Combining both Storage devices and control management software will provide system data sharing and system high applicable. By using Cloud Storage Management control mechanism, most of those business enterprises could be benefited. Keywords:- <b>Data</b> pooling, <b>Storage</b> Management, partition I...|$|R
40|$|In the era {{of cloud}} computing, with {{services}} such as video streaming, social networking, and online storage and file sharing, the demand for <b>online</b> <b>data</b> processing and <b>storage</b> capacity is growing rapidly. These services are hosted in huge data centers that need not only fast servers but also fast communication between servers. Because copper cables have high attenuation at high frequencies, the most promising solution is to use fiber optical links (called optical interconnects) to connect {{different parts of the}} data center. Today, gallium arsenide-based vertical-cavity surface-emitting lasers (VCSELs) emitting at 850 nm are the standard light source in transmitters used in commercially available optical interconnects, operating at up to 14 Gbit/s with a link length of up to 300 m. These lasers have the advantages of low power consumption, fast direct modulation at low currents, and low-cost manufacturing. To keep up with the demand of increasing optical interconnect capacity, the Photonics Laboratory at Chalmers university of Technology is conducting research into improving the speed, reach and capacity of VCSELs for optical interconnects...|$|R
40|$|The Acoustic Oceanographic Buoy (AOB) {{is a light}} {{acoustic}} {{receiving device}} that incorporates acoustic and non-acoustic signals received in various channels along a vertical line array that provide oceanographic and environment measurements {{all of which are}} uniquely GPS time referenced. The physical characteristics of the AOB, in terms of size, weight and autonomy, will tend to those of a standard sonobuoy with, however, the capabilities: of local <b>data</b> <b>storage,</b> dedicated signal-processing, GPS self localizing, real-time monitoring and <b>online</b> <b>data</b> transmission. FC...|$|R
40|$|Cloud {{computing}} {{is gaining}} more popularity {{because of its}} guaranteed services like <b>online</b> <b>data</b> <b>storage</b> and backup solutions, Web-based e-mail services, virtualized infrastructure etc. User is allowed to access the data stored in a cloud anytime, anywhere using internet connected device with low cost. To provide security to outsourced data in cloud storage against various corruptions, adding fault tolerance to cloud storage together with data integrity checking and failure reparation becomes critical. Existing methods for remote regenerating-coded data checking only provide private auditing, which requires data owners to always stay online and do auditing, as well as repairing, which is sometimes difficult and impractical. Here proposes a public auditing scheme for the regenerating-code-based cloud storage in which data is splitted and encrypted before outsourcing. To solve the regeneration problem of corrupted files {{in the absence of}} data owners, a proxy is introduced, which have the right to regenerate the files. This scheme can release data owners completely from online burden. The cloud server is used only to save the encrypted blocks of data. In addition, the encode coefficients are randomized with a random function to preserve data privacy...|$|E
40|$|International Telemetering Conference Proceedings / October 28 - 31, 1996 / Town and Country Hotel and Convention Center, San Diego, CaliforniaThe {{next-generation}} commercial imaging satellites {{will generate}} data at several {{times the rate}} of current systems. To be commercially successful, these systems must have earth stations as sophisticated as the satellites themselves. Space Imaging has worked with E-Systems to exploit technologies developed over four generations of image processing, analysis and application systems to create a modular, standards-based, earth station for commercial use. A Space Imaging Operations Center can be configured {{in a variety of ways}} to provide complete, end-to-end, capabilities, from task generation to receipt of downlink, image processing, and product generation. While it is intended primarily for use with imagery from Space Imaging and other commercial satellites, an Operations Center can also accept, process and manage data from land-based, airborne or seaborne collectors. A sophisticated data management product, Mission Server™, handles and routes all data from signal receipt through final product generation. A unique family of data processing applications permit simultaneous manipulation and analysis of integrated map, image, graphic and text data. <b>Online</b> <b>data</b> <b>storage</b> and archiving are provided by the EMASS® family of products. An Operations Center of any size can accept, process and manage data streams of several hundred megabits per second in real time...|$|E
40|$|In today’s world data {{analytics}} is gaining popularity due to user’s motivation towards <b>online</b> <b>data</b> <b>storage.</b> This storage is not organized because of content types and data handling schemes complexity. User aims to retrieve data in lesser time with logical outcomes as desired {{can be achieved}} by applying data mining. Clustering in data mining is one of the known categorization approach used for formation of groups of similar elements having certain properties in common with other elements. This formation sometime creates noisy result in terms of formatted clusters. It depends on various factors such as distance measures, proximity values, objective functions, categorical or numerical attribute types etc. Over the last few years various schemes are suggested by different authors for improving the performance of tradition clustering algorithms. Among them, one is ensemble based clustering. Ensemble uses the mechanism for criteria selection from newly formed clusters with a defined portioning and joining methods to generate a single result instead of multiple solutions. The generation results are affected by various environmental parameters such as number of cluster, partitioning types, proximity values, objective function etc. This paper propose a novel SMCA based ensemble clustering algorithm for improvements over the existing issues defined in the paper. At the primary level of work and analytical evaluations, it shows the promising results in near future...|$|E
50|$|Funded by the National Science Foundation (NSF), the Extreme Science and Engineering Discovery Environment (XSEDE) is {{a virtual}} system that {{scientists}} can use to interactively share computing resources, data, and expertise. XSEDE {{is the most powerful}} and robust collection of integrated advanced digital resources and services in the world. TACC {{is one of the leading}} partners in the XSEDE project, whose resources include more than one petaflop of computing capability and more than 30 petabytes of <b>online</b> and archival <b>data</b> <b>storage.</b> As part of the project, TACC provides access to Ranger, Lonestar, Longhorn, Spur, and Ranch through XSEDE quarterly allocations. TACC staff members support XSEDE researchers nationwide, and perform research and development to make XSEDE more effective and impactful.The XSEDE partnership also includes: University of Illinois at Urbana-Champaign, Carnegie Mellon University/University of Pittsburgh, University of Texas at Austin, University of Tennessee Knoxville, University of Virginia, Shodor Education Foundation, Southeastern Universities Research Association, University of Chicago, University of California San Diego, Indiana University, Jülich Supercomputing Centre, Purdue University, Cornell University, Ohio State University, University of California Berkeley, Rice University, and the National Center for Atmospheric Research. It is led by the University of Illinois's National Center for Supercomputing Applications.|$|R
30|$|<b>Data</b> <b>storage</b> and {{processing}} needs of modern Internet {{services such as}} social networks, <b>online</b> shopping, <b>data</b> analytics and visualization have necessitated new kind of storage systems, called NoSQL (Not Only SQL) databases. Such databases use new techniques that support parallel processing and replication of data across multiple nodes {{in order to ensure}} improved performance and availability of data [1].|$|R
50|$|Holographic <b>data</b> <b>storage</b> is a {{potential}} technology {{in the area of}} high-capacity <b>data</b> <b>storage</b> currently dominated by magnetic <b>data</b> <b>storage</b> and conventional optical <b>data</b> <b>storage.</b> Magnetic and optical <b>data</b> <b>storage</b> devices rely on individual bits being stored as distinct magnetic or optical changes {{on the surface of the}} recording medium. Holographic <b>data</b> <b>storage</b> records information throughout the volume of the medium and is capable of recording multiple images in the same area utilizing light at different angles.|$|R
