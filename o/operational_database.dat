88|164|Public
50|$|Gartner {{positioned}} EnterpriseDB in the Leaders Quadrant in its Magic Quadrant for <b>Operational</b> <b>Database</b> Management Systems in October 2014 {{and again}} in September 2015. EnterpriseDB was recognized in the Challengers Quadrant in the Magic Quadrant for <b>Operational</b> <b>Database</b> Management Systems in October 2016.|$|E
50|$|Operational {{databases}} {{are used}} to store, manage and track real-time business information. For example, a company might have an <b>operational</b> <b>database</b> used to track warehouse/stock quantities. As customers order products from an online web store, an <b>operational</b> <b>database</b> {{can be used to}} keep track of how many items have been sold and when the company will need to reorder stock. An <b>operational</b> <b>database</b> stores information about the activities of an organization, for example customer relationship management transactions or financial operations, in a computer database.|$|E
5000|$|October, 2015: Gartner {{positions}} Redis Labs as a Leader in its 2015 <b>Operational</b> <b>Database</b> Management Systems (ODBMS) Magic Quadrant ...|$|E
40|$|Data {{warehouses}} store {{organizational data}} extracted from many <b>operational</b> <b>databases.</b> They are mainly used for decision support and OLAP applications. As a result, queries to a data warehouse have unique idiosyncrasies {{that have to}} be separately addressed. Data warehouse queries usually are much less frequent than OLTP queries and touch upon much more data than a typical OLTP query. In addition, different paradigms of querying are often necessary to provide efficient support for the analyst who uses the data warehouse. This paper addresses issues related to query processing in data warehouses and contrasts different approaches. 1 Introduction to Data Warehouses Database systems are widely employed by organizations that record daily operations. Such <b>databases</b> are called <b>operational</b> <b>databases.</b> <b>Operational</b> <b>databases</b> are managed using Online Transaction Processing Systems (OLTP), which optimize database operations for speed and efficiency of search and update. However, in addition [...] ...|$|R
5000|$|In {{regards to}} source systems listed above, Rainer states, [...] "A common {{source for the}} data in data {{warehouses}} is the company's <b>operational</b> <b>databases,</b> which can be relational databases".|$|R
50|$|Data {{warehouses}} are {{optimized for}} analytic access patterns. Analytic access patterns generally involve selecting specific fields and rarely if ever 'select *' as {{is more common}} in <b>operational</b> <b>databases.</b> Because of these differences in access patterns, <b>operational</b> <b>databases</b> (loosely, OLTP) benefit from the use of a row-oriented DBMS whereas analytics databases (loosely, OLAP) benefit from the use of a column-oriented DBMS. Unlike operational systems which maintain a snapshot of the business, data warehouses generally maintain an infinite history which is implemented through ETL processes that periodically migrate data from the operational systems over to the data warehouse.|$|R
50|$|Gartner Research {{positions}} Microsoft as {{the leader}} in the Magic Quadrant <b>Operational</b> <b>Database</b> Management Systems in 2016 and explicitly calls out the unique capabilities of DocumentDB in their writeup.|$|E
50|$|SAP Business Suite 4 SAP HANA (or SAP S/4HANA) is a {{business}} suite that is built on SAP's proprietary <b>Operational</b> <b>Database</b> System and in-memory computing platform called SAP HANA.|$|E
50|$|According to Forrester Research, MarkLogic {{is among}} the NoSQL {{databases}} vendors with the strongest offerings {{in the market and}} regularly appears in Gartner Leaders Quadrant in the Magic Quadrant for <b>Operational</b> <b>Database</b> Management Systems.|$|E
50|$|HTAP {{solves the}} issue of {{analytic}} latency in several ways, including {{eliminating the need for}} multiple copies of the same data and the requirement for data to be offloaded from <b>operational</b> <b>databases</b> to data warehouses.|$|R
30|$|Maintain <b>operational</b> <b>databases,</b> {{cloud storage}} and data marts for the storage and {{maintenance}} of the potential availability of sensor data, and aggregates the results of monitoring, the synthesis variants of administrative decisions on the protection of objects, subjects and processes.|$|R
50|$|Sometimes {{operational}} {{systems are}} referred to as <b>operational</b> <b>databases,</b> transaction processing systems, or online transaction processing systems (OLTP). However, the use of the last two terms as synonyms may be confusing, because operational systems can be batch processing systems as well.|$|R
50|$|Schema {{evolution}} is handled via a normal update of the application's class models and then applying those {{changes to the}} <b>operational</b> <b>database.</b> Those schema changes {{can be applied to}} an existing database either via a utility or API. The result is a versioning of the database schema.|$|E
50|$|Recognizing {{the growing}} role of {{operational}} databases in the IT {{industry that is}} fast moving from legacy databases to real-time operational databases capable to handle distributed web and mobile demand and to address Big data challenges, in October 2013 Gartner started to publish the Magic Quadrant for <b>Operational</b> <b>Database</b> Management Systems.|$|E
50|$|<b>Operational</b> <b>database</b> {{management}} systems (also {{referred to as}} OLTP On Line Transaction Processing databases), are used to manage dynamic data in real-time. These types of databases allow you {{to do more than}} simply view archived data. Operational databases allow you to modify that data (add, change or delete data), doing it in real-time.|$|E
40|$|Abstract: On-line {{analytical}} processing (OLAP) systems {{deal with}} analytical tasks in businesses. As these tasks do {{not depend on}} the latest updates by transactions, it is assumed that the data used in OLAP systems are kept in a data warehouse, which separates the input coming from <b>operational</b> <b>databases</b> from the output going to di-alogue interfaces for OLAP. In this article we present a 3 -tier architecture for data warehouses and OLAP systems capturing the fundamental requirement of separating input from <b>operational</b> <b>databases</b> from output to OLAP systems. On this basis we start developing refinement rules to enable step-wise refinement for such systems, which includes pragmatic guidelines for the application of such rules. ...|$|R
50|$|The term {{can also}} refer to legitimate, managed replicas of <b>operational</b> <b>databases</b> that are {{isolated}} from the user base of the main system. These sub-systems {{can be used to}} track illegitimate changes to the primary data-store by 'back doors' exploited by expert but un-authorized users.|$|R
50|$|Experience {{management}} platforms compare multiple {{layers of}} data and statistics to enable organizations to identify any experience gaps. They connect <b>operational</b> <b>databases</b> with human feedback, analyzing respondents' emotions, beliefs, and sentiments for a holistic view of the experiences they provide. Their methods include artificial intelligence, predictive analytics, and statistical models.|$|R
50|$|InterSystems Caché is a {{commercial}} <b>operational</b> <b>database</b> management system from InterSystems, {{used to develop}} software applications for healthcare management, banking and financial services, government, and other sectors. Customer software can use the database with object and SQL code. Caché also allows developers to directly manipulate its underlying data structures: hierarchical arrays known as M technology.|$|E
50|$|In data warehousing, {{the term}} is even more specific: the <b>operational</b> <b>database</b> is the one which is {{accessed}} by an operational system (for example a customer-facing website or the application used by the customer service department) to carry out regular operations of an organization. Operational databases usually use an online transaction processing database which is optimized for faster transaction processing (create, read, update and delete operations).|$|E
50|$|Clusterpoint {{database}} delivers real-time {{business information}} management in electronic XML or JSON document format. It {{can be used}} as a high-performance <b>operational</b> <b>database</b> for web and mobile database services requiring scalability, fast speed and strong security. Software enables to safely handle financial, billing, security, medical, travel, information services, e-commerce, government and municipal open data and other data stored in electronic document data format that uses industry standard XML and JSON markup.|$|E
40|$|A data {{warehouse}} facilitates {{the integration of}} disparate <b>operational</b> <b>databases</b> in an enterprise into a single store. The warehouse then provides knowledge workers with easy access to historical, summarized {{and other forms of}} aggregated data. A major flaw in present warehouse architectures is the de-coupling of the warehouse database from its underlying <b>operational</b> <b>databases.</b> This creates two problems: the difficulty in updating the warehouse and the inability to provide users with a drill-down feature from warehouse to current data. We propose an architecture that is based on a federated database system extended to incorporate a materialized warehouse. A federated database provides the basic mechanism to tightly couple heterogeneous databases, which in this case are the <b>operational</b> and warehouse <b>databases.</b> The warehouse database is a special component in the federation, made up of historical data, external data and materialized views of the operational data. This approach enables users to access historical and current data when required, and provides a method of maintaining the warehouse as an integrated view of the underlying operational data sources...|$|R
40|$|Data {{warehouses}} {{have become}} an instant phenomenon in many large organizations that deal with a massive amount of information. Drawing on the experiences from the systems development field, we surmise that an effective CASE tool will enhance the success of warehouse implementations. Thus, we present a CASE tool designed to generate the SQL queries necessary to build a warehouse from a set of <b>operational</b> relational <b>databases.</b> The warehouse designer simply specifies a list of attribute names that {{will appear in the}} warehouse, conditions if any are desired, and a description of the <b>operational</b> <b>databases.</b> The tool returns the queries needed to populate the warehouse table. 1...|$|R
40|$|Customer {{retention}} is a {{key problem}} in the insurance industry. As new customers are generally not profitable {{for the first few}} years, minimizing defection is critical. The objective {{of this study is to}} mine the company's <b>operational</b> <b>databases</b> to predict the insured households that will most likely defect within the next 12 months. The <b>operational</b> <b>databases</b> available for mining consisted of all active policies as of January 1994 and new policies written thereafter in a particular business region. Building the analysis dataset presented several challenges. Policy level data had to be aggregated into household level information and matched with demographics from other databases. Customers who moved to a different address had to be tracked. We constructed snapshot files of active customers for each of the years 1994 - 1998. Each snapshot file contained information on about 600, 000 households and was used to build models using logistic regression (mainly) and decision trees. Eac [...] ...|$|R
50|$|In 2013, Gartner listed NuoDB as a niche {{player in}} its Magic Quadrant for <b>Operational</b> <b>Database</b> Management Systems. Boston Business Journal and Mass High Tech named NuoDB {{as one of}} their 2014 Innovation All Stars. In February 2014, NuoDB {{announced}} an extension to its Series B funding round led by Dassault Systèmes. The round added $14.2 million to the company's funding. Morgenthaler Ventures, Hummer Winblad Venture Partners and Longworth Venture Partners participated in the round.|$|E
5000|$|Since {{the early}} 90's, the <b>operational</b> <b>database</b> {{software}} {{market has been}} largely taken over by SQL engines. Today, the operational DBMS market (formerly OLTP) is evolving dramatically, with new, innovative entrants and incumbents supporting the growing use of unstructured data and NoSQL DBMS engines, as well as XML databases and NewSQL databases. Operational databases are increasingly supporting distributed database [...] architecture that provides high availability and fault tolerance through replication and scale out ability.|$|E
50|$|In 2015, Gartner again listed NuoDB, {{this time}} as a Visionary in its Magic Quadrant for <b>Operational</b> <b>Database</b> Management Systems. Morris, the company's {{founding}} CEO, became executive chairman in July 2015. Bob Walmsley, previously {{executive vice president of}} sales and services, was promoted to CEO. NuoDB raised a $17 million financing round in 2016 from existing investors including Dassault Systèmes, Hummer Winblad Venture Partners, Longworth Venture Partners and Morgenthaler Ventures. At that time, the company had raised a total of $59.7 million in funding.|$|E
40|$|Germany, {{operates}} different state-of-the-art observing {{sites in}} Chile. To manage observatory operations and observation transfer, ESO developed an end-to-end Data Flow System, from Phase I proposal preparation {{to the final}} archiving of quality-controlled science, calibration and engineering data. All information pertinent to the data flow is stored in the central databases at ESO headquarters and replicated {{to and from the}} observatory database servers. In the ESO's data flow model one can distinguish two groups of databases; the front-end databases, which are replicated from the ESO headquarters to the observing sites, and the back-end databases, where replication is directed from the observations to the headquarters. A part of the front-end database contains the Observation Blocks (OBs), which are sequences of operations necessary to perform an observation, such as instrument setting, target, filter and/or grism ID, exposure time, etc. Observatory operations rely on fast access to the OB database and quick recovery strategies in case of a database outage. After several years of operations, those databases have grown considerably. There was a necessity in reviewing the database architecture to find a solution that support scalability of the <b>operational</b> <b>databases.</b> We present the newly developed concept of distributing the OBs between two <b>databases,</b> containing <b>operational</b> and historical information. We present the architectural design in which OBs in <b>operational</b> <b>databases</b> will be archived periodically at ESO headquarters. This will remedy the scalability problems and keep the size of the <b>operational</b> <b>databases</b> small. The historical databases will only exist in the headquarters, for archiving purposes...|$|R
40|$|Queries on <b>operational</b> <b>databases</b> can {{be viewed}} as a form of {{business}} rules on data warehouse schema design. We propose to use such queries to automatically generate measures, dimensions and dimension hierarchies and their representation in a star schema. The schema produced with our approach has good properties such as non-redundant dimensional attributes and orthogonality among dimensions and can answer many more queries than just those it was generated from...|$|R
50|$|In 2006, Logi Analytics {{discontinued}} the LGX branding {{and introduced}} the Logi product line, consisting of applications for ad hoc, managed and OLAP reporting, an embedded database {{to be used}} between <b>operational</b> <b>databases</b> and reporting servers, and a connector pack for integration of commonly used Web-based sources into the Logi reporting environment. They also started to expand internationally, partnering firstly with Nano Blue in AsiaPac, then Intenda in EMEA.|$|R
50|$|One of {{the most}} {{compelling}} reasons for vendors/ISVs to utilize multitenancy is for the inherent data aggregation benefits. Instead of collecting data from multiple data sources, with potentially different database schemas, all data for all customers is stored in a single database schema. Thus, running queries across customers, mining data, and looking for trends is much simpler. This reason is probably overhyped {{as one of the}} core multitenancy requirements is the need to prevent Service Provider access to customer (tenant) information. Further, it is common to separate the <b>operational</b> <b>database</b> from the mining database (usually because of different workload characteristics), thus weakening the argument even more.|$|E
50|$|Operational {{databases}} allow {{a business}} to enter, gather, and retrieve {{large quantities of}} specific information, such as company legal data, financial data, call data records, personal employee information, sales data, customer data, data on assets and many other information. An important feature of storing information in an <b>operational</b> <b>database</b> {{is the ability to}} share information across the company and over the Internet. Operational databases can be used to manage mission-critical business data, to monitor activities, to audit suspicious transactions, or to review the history of dealings with a particular customer. They can also be part of the actual process of making and fulfilling a purchase, for example in e-commerce.|$|E
50|$|Software Independent Archiving of Relational Databases (SIARD) was {{developed}} by the Swiss Federal Archives, designed for archiving relational databases in a vendor-neutral form. A SIARD archive is a ZIP-based package of files based on XML and SQL:1999. A SIARD file incorporates not only the database content, but also machine-processable structural metadata that records the structure of database tables and their relationships. The ZIP file contains an XML file describing the database structure (metadata.xml) as well as a collection of XML files, one per table, capturing the table content. The SIARD archive may also contain text files and binary files representing database large objects (BLOBs and CLOBs). SIARD permits direct access to individual tables by exploring with ZIP tools. A SIARD archive is not an <b>operational</b> <b>database</b> but supports re-integration of the archived database into another relational database management system (RDBMS) that supports SQL:1999. In addition, SIARD supports the addition of descriptive and contextual metadata that is not recorded in the database itself and the embedding of documentation files in the archive.|$|E
5000|$|<b>Operational</b> <b>databases</b> store {{detailed}} {{data about the}} operations of an organization. They typically process relatively high volumes of updates using transactions. Examples include customer databases that record contact, credit, and demographic information about a business' customers, personnel databases that hold information such as salary, benefits, skills data about employees, enterprise resource planning systems that record details about product components, parts inventory, and financial databases that {{keep track of the}} organization's money, accounting and financial dealings.|$|R
50|$|The BBA {{managed the}} Global <b>Operational</b> Loss <b>Database</b> (GOLD) for its members. GOLD is an {{important}} tool for managing operational risk.|$|R
40|$|Abstract: Applications {{based on}} Data Warehouses {{especially}} decision support {{systems such as}} Executive Information Systems (EIS) are rapidly becoming a key to gain competitive advantage for businesses. Data Warehouse allows businesses to get data from <b>operational</b> <b>databases</b> and turn that data into useful information on which users can carry out their analysis. In this paper we will discuss the importance of meta modeling for EIS and Data Warehouses as analytical base in EIS for decision support. 1...|$|R
