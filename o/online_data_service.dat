5|10000|Public
40|$|The {open_quotes}Barn Book{close_quotes} {{has been}} a {{standard}} reference for neutron cross section data from the first edition published in 1955 as BNL- 325 through the last edition published by Academic Press in 1988. With the development of electronic networks over the past decade, most users of nuclear data now have {{direct access to the}} most current data through the National Nuclear Data Center (NNDC) <b>Online</b> <b>Data</b> <b>Service</b> and similar services provided by other members of the Nuclear Data Centers Network or through the WorldWideWeb pages maintained by the members of this Network. A planned upgrade in the NNDC <b>Online</b> <b>Data</b> <b>Service</b> allows the user to plot the data in {open_quotes}Barn Book{close_quotes} format...|$|E
40|$|The National Nuclear Data Center (NNDC) <b>Online</b> <b>Data</b> <b>Service,</b> {{available}} since 1986, {{is continually}} being upgraded and expanded. Most files {{are now available}} for access through the World Wide Web. Bibliographic, experimental, and evaluated data files are available containing information no neutron, charged-particle, and photon-induced nuclear reaction data, as well as nuclear decay and nuclear structure information. An effort is being made through the world-wide Nuclear Reaction Data Centers collaboration to make the charged-particle reaction data libraries as complete as possible. The data may be downloaded or viewed both as plots or as tabulated data. A variety of output formats are available for most files...|$|E
40|$|The National Nuclear Data Center (NNDC) {{is funded}} by the US Department of Energy to provide {{services}} {{in the field of}} low and medium energy nuclear physics to users in the US and Canada. The National Nuclear Data Center (NNDC) <b>Online</b> <b>Data</b> <b>Service,</b> available since 1986, is continually being upgraded and expanded. Most files are now available for access through the WorldWideWeb. Bibliographic, experimental, and evaluated data files are available containing information on neutron, charged-particle, and photon-induced nuclear reaction data, as well as nuclear decay and nuclear structure information. The information available to the users of NNDC services is the product of the combined efforts of the NNDC and cooperating data centers and other interested groups, both in the US and worldwide...|$|E
5000|$|DataNetwork Solutions Company Limited (DNS) - Provide <b>Online</b> <b>Data</b> Communication <b>service</b> via {{telephone}} lines {{under the name}} [...] "Datanet"in the provincial area.|$|R
5000|$|Advanced Datanetwork Communications Company Limited (ADC) - Provide <b>Online</b> <b>Data</b> Communication <b>service</b> via {{telephone}} lines {{under the name}} [...] "Datanet", licensed by TOT ...|$|R
5000|$|Rose was {{involved}} in the early development of the Silicon Alley technology community in New York, including working with pre-Internet era <b>online</b> <b>data</b> <b>services</b> and founding Ex Machina, a computer software company; The Computer Classroom, an early personal computer training company; and AirMedia, an early wireless Internet information network. In an interview in 2010, Rose stated: [...] "When AirMedia went down it was the single biggest disappointment of my life at that point. I cried myself to sleep." ...|$|R
40|$|The whole sky {{differential}} star counts (DSC) with 1 degree resolution are {{retrieved from}} 2 MASS <b>online</b> <b>data</b> <b>service.</b> Galaxy with double exponential thin and thick disks {{and a single}} power law luminosity function (LF) is used to interpret the 2 MASS data. The slope of the DSC appears roughly isotropic over the whole sky, the average value is ~ 0. 32, which corresponds to a power law index ~ 1. 8 of the LF. We find that the scale-length and scale-height the thin disk are ~ 3. 0 kpc and ~ 245 pc, {{and those of the}} thick disk are ~ 3. 0 kpc and ~ 780 pc. The ratio of the thick disk to the thin disk is ~ 7 %. The location of Sun above the disk is ~ 15 pc. A comparison of the data and model and their discrepancy are also provided...|$|E
40|$|Historically, {{libraries}} {{have been}} responsible for storing, preserving, cataloguing and making available to the public large collections of information resources. In order to classify and organize these collections, the library community has developed several standards for the production, storage and communication of data describing different aspects of library knowledge assets. However, as we will argue in this thesis, most of the current practices and standards available are limited in their ability to integrate library data within the largest information network ever created: the World Wide Web (WWW). This thesis aims at providing theoretical foundations and technical solutions to tackle some of the challenges in bridging the gap between these two areas: library science and technologies, and the Web of Data. The investigation of these aspects has been tackled with a combination of theoretical, technological and empirical approaches. Moreover, the research presented in this thesis has been largely applied and deployed to sustain a large <b>online</b> <b>data</b> <b>service</b> of the National Library of Spain: datos. bne. es. Specifically, this thesis proposes and evaluates several constructs, languages, models and methods with the objective of transforming and publishing library catalogue data using semantic technologies and ontologies. In this thesis, we introduce marimba-framework, an ontologybased library data framework, that encompasses these constructs, languages, models and methods. The specific contributions of this work include: • marimba-datamodel, a nested relational model to represent library data sources, which can be operated using a recursive relational algebra. • A query language, marimba-sql, which can be used to query and operate with library data in the marimba-datamodel. • The syntax and operational semantics of a mapping language, marimbarml, for mapping and transforming library data sources into RDF. • Methodological guidelines for library ontology development and mapping library data sources into RDF, as well as the design, implementation and publication of a large library ontology, the BNE ontology. • A method for extracting latent topics from ontologies and understanding thematical relationships between ontologies, as well as several topicbased ontology similarity measures. • An in-depth study of the impact of semantic technologies in online library applications with regards to efficiency, usability and user satisfaction measures by comparing two large-scale library systems...|$|E
5000|$|... i-drive was an <b>online</b> {{computer}} <b>data</b> storage <b>service</b> that operated from 1998-2002.|$|R
40|$|Last week, India’s Telecom Regulatory Authority (TRAI) issued {{regulations}} that prohibit service providers from charging discriminatory tariffs for <b>online</b> <b>data</b> <b>services.</b> While the regulations have been {{hailed as a}} victory for net neutrality, some have also argued that TRAI’s steps signify a lamentable loss for those not connected to the Internet. LSE alumna Anri van der Spuy provides {{a brief overview of}} some of the arguments involved and assesses how it might impact other developing countries in their attempts to improve (meaningful) Internet access...|$|R
50|$|Futuremark's {{applications}} are distributed via the Internet {{as well as}} offline media; {{in addition to the}} above benchmarks, the company also provides services such as IHV/ISV customised benchmarks, 3D demos as well as <b>online</b> and <b>data</b> <b>services.</b>|$|R
50|$|Subsequent {{instruments}} include {{early childhood}} screening instruments, and other inventories for individuals from birth through secondary levels of education. Recent {{revisions of the}} screens and inventories have included standardized, normed assessments, and <b>online</b> <b>data</b> management <b>services</b> from publisher, Curriculum Associates, Inc.|$|R
40|$|Data. gov. au {{provides}} {{an easy way}} to find, access and reuse public datasets from Government. The main purpose of the site is to encourage public access to and reuse of government data by providing it in useful formats under open licences. It was created following the Government’s Declaration of Open Government and response to the Government 2. 0 Taskforce Report (see Related Content below). The site provides both downloadable datasets and links to <b>online</b> <b>data</b> <b>services</b> provided by other government sources. Improving {{the quantity and quality of}} the site’s data will be an ongoing process.  ...|$|R
5000|$|ADVFN (...) is a {{financial}} market website. It provides <b>online</b> <b>data</b> and <b>services</b> to private investors such as stock quotes, charts, news, FOREX, Futures & Options and stock screeners. The site currently covers {{in excess of}} 70 stock exchanges from across the globe. It {{is known for its}} active bulletin boards (internet forums).|$|R
40|$|The Nuclear Data Centers Network is a world-wide {{cooperation}} of nuclear data centers {{under the auspices}} of the International Atomic Energy Agency. The Network organizes the task of collecting, compiling, standardizing, storing, assessing, and distributing the nuclear data on an international scale. Information available at the Centers includes bibliographic, experimental, and evaluated databases for nuclear reaction data and for nuclear structure and radioactive decay data. The objective of the Network is to provide the information to users in a convenient, readily-available form. To this end, <b>online</b> <b>data</b> <b>services</b> have been established at three of the centers: the National Nuclear Data Center (NNDC), the Nuclear Data Section of the International Atomic Energy Agency (NDS), and the OECD Nuclear Energy Agency Data Bank (NEADB). Some information is also available at the NNDC and NEADB World Wide Web sites...|$|R
50|$|Digimap is a {{web mapping}} and <b>online</b> <b>data</b> {{delivery}} <b>service</b> {{developed by the}} EDINA national data centre for UK academia. It offers a range of on-line mapping and data download facilities which provide maps and spatial data from Ordnance Survey, British Geological Survey, Landmark Information Group and SeaZone Ltd. (marine mapping data and charts from the UK Hydrographic Office). The service is funded by the Jisc (Joint Information Systems Committee).|$|R
50|$|Iridium {{satellites}} are now {{an essential}} component of communications with remote science camps, especially the Amundsen-Scott South Pole Station. In December 2006, an array of twelve Iridium modems was put <b>online,</b> providing continuous <b>data</b> <b>services</b> to the station for the first time. Total bandwidth is 28.8 kbit/s.|$|R
40|$|Abstract—Data {{privacy is}} a major concern when users query public <b>online</b> <b>data</b> <b>services.</b> The privacy of {{millions}} of people has been jeopardized in numerous user data leakage incidents in many popular online applications. To address the critical problem of personal data leakage through queries, we enable private querying on public <b>data</b> <b>services</b> so that the contents of user queries and any user data are hidden and therefore not revealed to the online service provider. We propose two protocols for processing private database queries, namely BHE and HHE. BHE provides complete query privacy by using Paillier’s homomorphic encryption along with the bucketization of public data. In contrast to traditional Private Information Retrieval (PIR) proposals, BHE only incurs one round of client server interaction for processing one query. Built upon BHE, HHE is a hybrid protocol that applies BHE computation and communication on a subset of the data buckets, such that this subset covers the actual requested data but also mimics frequent query patterns of common users, thus achieving practical query performance while providing proper privacy protection. Because of the use of frequent query patterns and data specific privacy protection, HHE is not vulnerable to traditional attacks on k-Anonymity that explore data similarity and skewness. Moreover, HHE consistently protects user query privacy for a sequence of queries in a query session. I...|$|R
40|$|The immense {{potential}} for new science findings {{as a result}} of inter-instrument data analysis has {{led to the development of}} a new data portal at GSFC: the A-train Data Depot. The power and utility of this new service to the general public is amplified immensely when the archived data are used in conjunction with <b>online</b> <b>data</b> analysis <b>services</b> like Giovanni. This presentation details some of the challenges of data usage from multiple distinct missions and how the tool sets we have developed can help to overcome these challenges, considerably cut down on analysis overhead and promote science exploration in an otherwise very challenging arena...|$|R
40|$|This paper {{describes}} <b>online</b> <b>data</b> mining <b>services</b> for dynamic spatial databases {{connected to}} environmental monitoring networks. These services can use Artificial Neural Networks as data mining techniques to find temporal relations in monitored parameters. The {{execution of the}} data mining algorithms is performed at the server side and a distributed processing scheme is used to overcome problems of scalability. To support the discovery of temporal relations, two other families of online services are made available: vectorial and raster visualization services and a sonification service. The use of this system {{is illustrated by the}} DM Plus client application and the SNIRH Data Mining Web site. The sonification service is described and illustrated in the part II paper...|$|R
40|$|This paper {{introduces}} <b>online</b> <b>data</b> mining <b>services</b> for dynamic spatial databases {{associated with}} environmental monitoring networks. In particular, it describes an application that uses these services with sonification for air quality location based information {{services to the}} general public. The <b>data</b> mining <b>services</b> use Artificial Neural Networks, to find temporal relations in the monitored parameters. The execution of the algorithms performed at the server side and a distributed processing scheme is used to overcome problems of scalability. In addition, two other families of web services are made available to support the discovery of temporal relations: vectorial and raster map? services and a sonification service. The map services were implemented in DM Plus, a client application presented in part I. The sonification service is described in this paper and illustrated through an application study that implements an air quality index with sonification for mobile phones...|$|R
40|$|The authors present DigiSafe-a {{secure and}} {{reliable}} system for public or corporation users to store and retrieve valuable digital data over untrusted networks. It is the electronic analogy {{to the physical}} safe boxes provided by a bank whereby customers keep their valuable belongings. DigiSafe follows a typical client/server model where <b>online</b> digital <b>data</b> depository <b>services</b> are provided by a service provider: the system is secure, highly reliable, easy to use, and accessible from anywhere...|$|R
40|$|There is {{worldwide}} {{interest in}} the potential of open science to increase the quality, impact, and benefits of science and research. More recently, attention {{has been focused on}} aspects such as transparency, quality, and provenance, particularly in regard to data. For industry, citizens, and other researchers to participate in the open science agenda, further work needs to be undertaken to establish trust in research environments. Based on a critical review of the literature, this paper examines the issue of trust in an open science environment, using virtual laboratories as the focus for discussion. A trust framework, which has been developed from an end-user perspective, is proposed as a model for addressing relevant issues within <b>online</b> research <b>data</b> <b>services</b> and tools. Information Services, Information ServicesFull Tex...|$|R
50|$|TamoGraph is {{used for}} {{measuring}} and visualizing such WLAN characteristics as signal strength, signal-to-noise ratio, signal-to-interference ratio, TCP and UDP throughput rates, etc. Visualizations are overlaid on floor plans or, in case of outdoor surveys, on site maps that can be imported {{from one of the}} <b>online</b> map <b>services.</b> <b>Data</b> is collected by a portable computer using a compatible Wi-Fi adapter.|$|R
50|$|Chittock {{sold the}} company in July 1996 to a {{management}} team comprising David Fisher, Allan Hardy, Ben Keen and Mark Smith. At that time the company had one full-time employee. Since then Screen Digest has expanded its consultancy and report publishing activities, as well as developing a set of continuously updated <b>online</b> information and <b>data</b> <b>services</b> on Advertising, Broadband Media, Cinema, Games, Mobile Media, Television, Television technology and Video. Screen Digest now counts over 50 full-time employees, with bases in New York and California in the US and Melbourne, Australia, as well as London.|$|R
40|$|Research Data Management (RDM) is {{a process}} that is {{designed}} to deliver high quality datasets, which comply with scholarly, legal and ethical requirements. There are two outputs of the RDM process: 1. Long term preservation of datasets through archiving 2. Sharing and reuse of datasets for further research and other purposes in society at large. This proposal outlines the creation of a coherent Research Data Management organization at Lund University that utilizes existing resources both within and outside the university and establishes new organizational units and information systems, specific to this new task. We propose the establishment of a new unit for Research Data Management and Coordination at the University Library whose responsibility would be to coordinate the network of existing agents who support research activities such as faculty libraries and ethical, legal, archival and data management experts. We further propose {{the creation of a new}} information system, the Lund University Dataset Directory, which will facilitate management of datasets and information retrieval throughout the data lifecycle. We expect that research datasets could be deposited for sharing at national or disciplinary repositories and eventually archived when a solution is in place at the University Archive. Advanced RDM - like semantic web technologies - will require <b>online</b> <b>data</b> <b>services</b> not currently provided by national agents. We therefor propose a Data Laboratory within the RDM network at Lund University. Finally, it's important to recognize that Research Data Management is a new way of organizing information with its own set of tasks for the library organization. Our efforts in RDM will require us to invest significant effort in learning new systems, ways of working and collaboration...|$|R
40|$|This thesis {{describes}} scenarios {{in which}} a mobile user needs various services, such as Internet telephony, secure printing and <b>online</b> <b>data</b> <b>services</b> {{in a number of}} places. From these scenarios we summarize the requirements for quality of service control, service discovery, user authentication and authorization, service access control, and user privacy. In order to implement a prototype to support service discovery, we studied different technologies including Bluetooth, Jini, and Web Services. SDPtool from BlueZ was chosen to limit the search range within the user's local area while using minimal power consumption. Also included in the implementation, the Session Initiation Protocol is used to initiate the session and exchange messages while Java Media Framework is used to capture and deliver multimedia data. In the process of adapting Dupre's authentication protocol for user authentication, we found that it is possible for a third party to intercept the messages exchanged between a user and a Foreign Agent, which may lead to denial of service attack and weakens the strength of the user's password. The protocol is then improved by introducing additional message segments and altering the way to verify the server's response. The thesis also deals with trust relationships, which are needed as a basis for communication between the two parties. Shi's probability distribution model is introduced to integrate recommendations from different domains so that a service provider could make better decisions whether a given user should be assigned certain access rights. In the other hand, a user also depends on a trust relationship to make sure that his or her sensitive data will be handled properly. Finally, based on all of the above, a trust-based access control framework for mobile users and services is proposed and choices of implementation are briefly discussed...|$|R
40|$|The PCNuDat {{program for}} IBM-PC compatibles {{is similar to}} the NuDat program {{available}} through the NNDC <b>Online</b> Nuclear <b>Data</b> <b>Service.</b> They provide a user with access to nuclear data in a convenient and menu driven system. This data is useful in both basic and applied research. The nuclear base used by NuDat is extracted from several data bases maintained at the National Nuclear Data Center (NNDC). The program is an extended DOS program which uses 32 bit addressing. It can run in a DOS window on all the current Windows operating systems. The program and its data base are currently available on both a CD-ROM or electronically over the Internet. Electronic access can be made through the NNDC`s Web home page. The files may also be FTP`d from the public area under the [pc{_}prog] directory on bnlnd 2. dne. bnl. gov. The CD-ROM version also contains the Nuclear Science References (NSR) data base and its retrieval program, Papyrus NSR...|$|R
40|$|With the Heterogeneous Missions Accessibility (HMA) initiative, the OGC {{standard}} “Web Coverage Service (WCS) Earth Observation Application Profile” {{has been}} developed to harmonize online access to very large primary Earth Observation data holdings. Although its use in web mapping servers has proven valuable capabilities, this standard is not yet widely adopted. Its acceptance for data download by end users is hampered {{by the lack of}} interpretation guidelines and its complexity requiring considerable server and client implementation efforts. In this context, the project “Evolution of EO <b>Online</b> <b>Data</b> Access Services” funded by the European Space Agency (ESA) and presented in this paper analyses relevant scenarios and technologies for data publication and access, identifies potential for improvements of standards and their implementations, prototypes and evaluates selected improvements and proposes standard extensions for future releases. We hope hereby to considerably improve the acceptance of <b>online</b> EO <b>data</b> access <b>services</b> and standards and to promote their evolution and diffusion...|$|R
5000|$|Museum {{informatics}} is {{an emerging}} field of academic {{study focused on}} the intersection between information technologies, museums and their staff members, and <b>online</b> museum <b>data</b> and <b>services.</b> The more general cultural informatics deals with, for example, information design and interaction, digital curation, cultural heritage description and access, social media, {{and the application of}} digital tools. Museums have embraced the application of museum informatics which has been supported by US federal grants and in particular by the Institute of Museum and Library Services (IMLS). The older term [...] "museum studies" [...] refers more to traditional curatorial perspectives rather than relating to the use of information science and information technology.|$|R
40|$|We {{report on}} the {{completion}} of a global control network of Enceladus containing Cassi-ni Imaging Science Subsystem (ISS) images, and asso-ciated photogrammetric and cartographic accomplish-ments. This effort was in support of a new global geo-logic map of Enceladus [1]. The resulting products include a preliminary global monochrome basemap and improved camera pointing for individual images. The basemap and ancillary data will be available through USGS Astrogeology <b>Online</b> Planetary <b>Data</b> and <b>Services</b> (PDS Annex/MAP 2) [2 - 4]. The updated pointing is recorded in the Navigation and Ancillary Information Facility (NAIF) /SPICE ck kernel format [5] and released to the community via the Integrated Software for Imagers and Spectrometers (ISIS 3) [6] public release in February 2016...|$|R
40|$|This {{presentation}} {{provides an}} overview of remote sensing and model data at GES (Goddard Earth Sciences) DISC (<b>Data</b> and Information <b>Services</b> Center); Overview of <b>data</b> <b>services</b> at GES DISC (Registration with NASA data system; Searching and downloading data); Giovanni (Geospatial Interactive Online VisualizationANd aNalysis Infrastructure) : <b>online</b> <b>data</b> exploration tool; and NASA Earth Data and Information System...|$|R
40|$|More {{and more}} users store data in “clouds ” that are {{accessed}} remotely over the Internet. We survey wellknown cryptographic tools for providing integrity and consistency for data stored in clouds and discuss recent research in cryptography and distributed computing addressing these problems. Storing data in clouds Many providers now offer {{a wide variety}} of flexible <b>online</b> <b>data</b> storage <b>services,</b> ranging from passive ones, such as online archiving, to active ones, such as collaboration and social networking. They have become known as computing and storage “clouds. ” Such clouds allow users to abandon local storage and use online alternatives, such as Amazon S 3, Nirvanix CloudNAS, or Microsoft SkyDrive. Some cloud providers utilize the fact that online storage can be accessed from any location connected to the Internet, and offer additional functionality; for example, Apple MobileMe allows users to synchronize common applications that run on multiples devices. Clouds also offer computation resources, such as Amazon EC 2, which can significantly reduce the cost of maintaining such resources locally. Finally, online collaboration tools, such as Google Apps or versioning repositories for source code, make it easy to collaborate with colleagues across organizations and countries, as practiced by the authors of this paper. What can go wrong? Although the advantages of using clouds are unarguable, there are many risks involved with releasing control over your data. One concern that many users are aware of is loss of privacy. Nevertheless, the popularity of social networks and <b>online</b> <b>data</b> sharing repositories suggests that many users are willing to forfeit privacy...|$|R
40|$|Toxic {{agent and}} {{radiation}} control is 1 of the 15 health priority areas addressed through the Public Health Service's Objectives for the Nation. Several gains in {{moving toward the}} 1990 goals for toxic agent and radiation control have been recorded. Research and technical assistance, combined with legislation {{to reduce the amount}} of lead in gasoline, have contributed to a decrease in the mean blood lead level of the general population. New testing procedures have been developed to evaluate both reproductive and developmental toxicities of chemicals. Educational implementation of pelvimetry referral criteria in a multiyear study involving approximately 200 U. S. hospitals has resulted in a 50 percent reduction in the number of pelvimetries performed. Health-related responses have been given to environmental problems such as exposures to polychlorinated biphenyls (PCBs) in Massachusetts and Florida and exposures to dioxin in Missouri and New Jersey. Chemical records for some 1, 000 compounds likely to occur in chemical dumps or in bulk transit are being either created or updated to enhance <b>online</b> <b>data</b> retrieval <b>services.</b> For the foreseeable future, however, improvement of knowledge of the potential health risk posed by toxic chemicals and radiation must remain one of the most important priorities. To control toxic agents, development of surveillance systems and data bases are equally important...|$|R
40|$|Children’s online privacy has {{garnered}} {{much attention}} in media, legislation, and industry. Adults {{are concerned that}} children may not adequately protect themselves online. How-ever, relatively little discussion {{has focused on the}} privacy breaches that may occur to children at the hands of others, namely, their parents and relatives. When adults post infor-mation online, they may reveal personal information about their children to other people, <b>online</b> <b>services,</b> <b>data</b> brokers, or surveillant authorities. This information can be gathered in an automated fashion and then linked with other online and offline sources, creating detailed profiles which can be continually enhanced throughout the children’s lives. In this paper, we conduct a study to see how widespread these behaviors are among adults on Facebook and Insta...|$|R
40|$|This paper {{describes}} a general {{model of information}} retrieval systems and processes and its implementation as a workbench for information retrieval experimentation in Common Lisp. A brief overview discusses the motivation for and goals of such a workbench. A general model of retrieval systems is presented which identifies two functional components, partitioners and transformers and a single aggregate data type, collections, and how they interact. The workbench and its implementation are discussed in general terms, including the core classes and methods and {{a small group of}} applications which have been developed for it. Finally, there is a brief discussion of the usefulness of Common Lisp as the implementation language for the workbench and its conceptual a#nity for information retrieval system modeling. 1 Introduction The world is filled with information retrieval systems: <b>online</b> catalogs and <b>data</b> <b>services,</b> indexing services, help desks, phone books, information filters, back [...] ...|$|R
