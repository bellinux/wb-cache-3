0|6277|Public
50|$|With {{more than}} 12,000 customers, ReadSoft {{claims to be}} the market leader of the Document Process Automation segment - a term first coined by ReadSoft itself to cover the {{technology}} that automates the processing of business documents. It involves data capture and extraction (<b>optical</b> <b>character</b> <b>recognition)</b> from <b>paper</b> and electronic documents, integration with company's existing ERP system and routing to company agents for approvals and problem resolution via workflow.|$|R
40|$|Handwritten Hindi text {{recognition}} is emerging {{areas of research}} in the field of <b>optical</b> <b>character</b> <b>recognition.</b> In this <b>paper,</b> a segmentation based approach is used to recognize the text. The offline handwritten text is segmented into lines, lines into words and words into <b>character</b> for <b>recognition.</b> Shape features are extracted from the characters and fed into SVM classifier for recognition. The results obtained with the proposed feature set using SVM classifier is very challenging...|$|R
40|$|Machine {{vision has}} become an {{integral}} part of today's electronic industry. Digital images capturing low contrast and low illumination conditions often cause serious problems in <b>optical</b> <b>character</b> <b>recognition</b> systems. This <b>paper</b> uses poorly digitized images of integrated circuits and documents to demonstrate the effectiveness of using the Generalized Fuzzy Operator with Histogram Equalization and Partially Overlapped Sub-Block Histogram Equalization in reducing background noise and increasing the readability of text by contrast enhancement. © 2004 Elsevier B. V. All rights reserved. link_to_subscribed_fulltex...|$|R
40|$|Despite the {{explosion}} of text on the Internet, hard copy documents that have been scanned as images still {{play a significant role}} for some tasks. The best method to perform ranked retrieval on a large corpus of document images, however, remains an open research question. The most common approach has been to perform text retrieval using terms generated by <b>optical</b> <b>character</b> <b>recognition.</b> This <b>paper,</b> by contrast, examines whether a scalable segmentation-free image retrieval algorithm, which matches sub-images containing text or graphical objects, can provide additional benefit in satisfying a user’s information needs on a large, real world dataset. Results on 7 million scanned pages from the CDIP v 1. 0 test collection show that content based image retrieval finds a substantial number of documents that text retrieval misses, and that when used as a basis for relevance feedback can yield improvements in retrieval effectiveness...|$|R
40|$|Converting {{handwritten}} documents {{into its}} machine written counterpart automatically requires several processes including removing background noise and ruled lines, then <b>Optical</b> <b>Character</b> <b>Recognition.</b> In this <b>paper,</b> {{we present a}} fast detection and removal algorithms for ruled lines in colored scanned handwritten documents. The ruled lines detection is based on Hough transform of the centralized 1 / 9 th image rectangle. Once the ruled lines are detected, the removal process or text isolation has been developed based on the hue histogram segmentation in full-color image documents. The early results show a very promising effectiveness and reliability of the proposed method...|$|R
40|$|Part-of-speech (POS) tagging is the {{foundation}} of natural language processing (NLP) systems, and thus has been an active area of research for many years. However, one question remains unanswered: How will a POS tagger behave when the input text is not error-free? This issue can be of great importance when the text comes from imperfect sources like <b>Optical</b> <b>Character</b> <b>Recognition</b> (OCR). This <b>paper</b> analyzes the performance of both individual POS taggers and combination systems on imperfect text. Experimental results show that a POS tagger's accuracy will decrease linearly with the character error rate and the slope indicates a tagger's sensitivity to input text errors...|$|R
40|$|Only a few works {{has been}} done for printed devanagari text {{in the area of}} <b>optical</b> <b>character</b> <b>recognition.</b> In this <b>paper</b> there is {{describing}} about a simple and fast algorithm for detection of italic and bold character in Devanagari script, without <b>recognition</b> of actual <b>character.</b> Here present an automatic information which tells us about the font type phase in the way of weight and slope. The process of identification and classification of italic and bold character can be used for making an accuracy of the text recognition system in the OCR. This simple and fast algorithm gives high accuracy and very easy to implement...|$|R
40|$|Abstract—This paper proposes the use {{of content}} base image {{retrieval}} (CBIR) techniques for indexing and retrieval of handwritten documents in Thai language. Issues associated with Thai handwritten documents are the lack of spacing between words, multi-level alphabets and different writing styles. This causes low recognition rate based on automated techniques such as <b>Optical</b> <b>Character</b> <b>Recognition</b> (OCR). This <b>paper</b> also examined off-line signature recognition techniques in order to adapt to Thai handwriting system for matching data. The objective of the proposal {{is to develop a}} semi-automated method to index and retrieve Thai handwritten documents based on sampled keywords by combining CBIR and signature recognition techniques. Keywords-Thai handwritten document; CBIR; sample...|$|R
40|$|This paper proposes the use {{of content}} base image {{retrieval}} (CBIR) techniques for indexing and retrieval of handwritten documents in Thai language. Issues associated with Thai handwritten documents are the lack of spacing between words, multi-level alphabets and different writing styles. This causes low recognition rate based on automated techniques such as <b>Optical</b> <b>Character</b> <b>Recognition</b> (OCR). This <b>paper</b> also examined off-line signature recognition techniques in order to adapt to Thai handwriting system for matching data. The objective of the proposal {{is to develop a}} semiautomated method to index and retrieve Thai handwritten documents based on sampled keywords by combining CBIR and signature recognition techniques...|$|R
40|$|Abstract: Recognition of text {{document}} {{images is}} the inclination of any <b>optical</b> <b>character</b> <b>recognition</b> systems. This <b>paper</b> aims at extending the functionality of <b>optical</b> <b>character</b> <b>recognition</b> system to recognize {{more than one}} language. At present <b>optical</b> <b>character</b> <b>recognition</b> technologies are able to recognize and translate only one language, however multi-lingual recognition capabilities for OCR are accomplished through incorporation of script recognizer. This paper eliminates the need of identifying the script type and achieves the automatic recognition of two different scripts with single <b>optical</b> <b>character</b> <b>recognition</b> system, which we are representing as bilingual OCR. Bilingual OCR recognizes the text document images composed of both English and Kannada scripts. The construction of bilingual OCR for English and Kannada is achieved by employing efficient constructs like multiple projection profiles, connected component analysis and principal component analysis. The devised system is proved to be effective and reliable by claiming around 95 %- 100 % accuracy...|$|R
40|$|<b>Character</b> <b>recognition</b> for {{handwritten}} isolated text is an attention-grabbing area of <b>optical</b> <b>character</b> <b>recognition</b> (OCR). This <b>paper</b> puts forward {{technique for}} recognition of offline isolated characters on English and numeric, which uses 40 point metric method for feature extraction, which a zone based method that segregates the image into 40 zones, extracting features from each zone and then structuring an image. Neuro-Fuzzy and Weighted KMA classifiers are compared for recognising the characters. The test results show, {{that the proposed}} techniques show relatively high accuracy for the handwritten recognition. Also time elapsed for training is calculated and contrasted for both the classifiers. This system will be suitable for converting handwritten documents into structural text forms and recognizing handwritten names...|$|R
40|$|Smart Phones have Internet access anywhere. The {{automatic}} text localization {{and recognition}} of text within a natural image is very useful for many problems. Once identified, the text {{can be used for}} many purposes. User can get current information about the product, place or boards. More exciting applications can be developed over the text extraction method with a high performance while also being computationally inexpensive. There are various methods proposed for Text Localization, text area segmentation, sign <b>recognition</b> and translation, <b>Optical</b> <b>Character</b> <b>Recognition.</b> In this <b>paper</b> we have described these methods. We have also compared all methods on the basis of performance and accuracy. Finally we concluded some good methods for Smartphone OCR application...|$|R
40|$|The National Library of Medicine (NLM) is {{developing}} an automated system to produce bibliographic records for its MEDLINE ® database. This system, named Medical Article Record System (MARS), employs document image analysis and understanding techniques and <b>optical</b> <b>character</b> <b>recognition</b> (OCR). This <b>paper</b> describes a key module in MARS called the Automated Labeling (AL) module, which labels all zones of interest (title, author, affiliation, and abstract) automatically. The AL algorithm {{is based on}} 120 rules that are derived from an analysis of journal page layouts and features extracted from OCR output. Experiments carried out on more than 11, 000 articles in over 1, 000 biomedical journals show the accuracy of this rule-based algorithm to exceed 96 %...|$|R
40|$|With the {{dramatic}} increase in multimedia data, escalating trend of internet, and amplifying use of image/video capturing devices; content based indexing and text extraction is gaining more and more importance in research community. In the last decade, many techniques for text extraction are reported in the literature. Methodologies of text extraction from images/videos is generally comprises of text detection and localization, text tracking, text segmentation and <b>optical</b> <b>character</b> <b>recognition</b> (OCR). This <b>paper</b> intends to highlight the contributions and limitations of text detection, localization and tracking phases. The problem is exigent due to variations in the font styles, size and color, text orientations, animations and backgrounds. The paper can serve as the beacon-house for the novice researchers of the text extraction community...|$|R
40|$|Abstract—With the {{dramatic}} increase in multimedia data, escalating trend of internet, and amplifying use of image/video capturing devices; content based indexing and text extraction is gaining more and more importance in research community. In the last decade, many techniques for text extraction are reported in the literature. Methodologies of text extraction from images/videos is generally comprises of text detection and localization, text tracking, text segmentation and <b>optical</b> <b>character</b> <b>recognition</b> (OCR). This <b>paper</b> intends to highlight the contributions and limitations of text detection, localization and tracking phases. The problem is exigent due to variations in the font styles, size and color, text orientations, animations and backgrounds. The paper can serve as the beacon-house for the novice researchers of the text extraction community. Index Terms—Text extraction, Document analysis...|$|R
40|$|The {{segmentation}} {{accuracy of}} Roman cursive characters, especially touched characters, {{is essential for}} the high performance of <b>Optical</b> <b>Character</b> <b>Recognition</b> Systems. This <b>paper</b> presents a new approach for non-linear segmentation of multiple touched Roman cursive characters based on genetic algorithm. Initially, a possible segmentation zone is detected and then best segmentation path is evolved by genetic algorithm. The initial population is composed of each point column in possible segmentation zone. The individual coding, fitness function, crossover operator and mutation operator are also defined for this task. Experimental results on a test set extracted on the IAM benchmark database exhibit high segmentation accuracy up to 89. 76 %. Proposed approach can handle some complex types of touched cursive characters without special heuristic rules and recognition. 1...|$|R
40|$|Handwritten <b>character</b> <b>recognition</b> has {{received}} extensive attention in academic and production fields. The recognition {{system can be}} either on-line or off-line. Off-line handwriting recognition is the subfield of <b>Optical</b> <b>Character</b> <b>Recognition.</b> In this <b>paper,</b> We introduce the fundamental principles of Chinese handwritten numerals, including digital image preprocessing, segmentation, features extraction and pattern recognition. The numerals are recognized by SVM classifiers, and their results are combined to form final results. A Novel approach is proposed for recognizing Handwritten Chinese numerals using direction feature extraction approach combined with Gabor and SVM It has been proved that {{the performance of the}} system is satisfactory, when both gabor and SVM are used rather than SVM alone. Experimental result shows that our proposed approach are efficient and effective with a recognition rate and accuracy of 95. 44...|$|R
40|$|International audienceUnderstanding text {{captured}} in real-world scenes is a challenging {{problem in the}} field of visual pattern recognition and continues to generate a significant interest in the OCR (<b>Optical</b> <b>Character</b> <b>Recognition)</b> community. This <b>paper</b> proposes a novel method to recognize scene texts avoiding the conventional character segmentation step. The idea is to scan the text image with multi-scale windows and apply a robust recognition model, relying on a neural classification approach, to every window in order to recognize valid characters and identify non valid ones. Recognition results are represented as a graph model {{in order to determine the}} best sequence of characters. Some linguistic knowledge is also incorporated to remove errors due to recognition confusions. The designed method is evaluated on the ICDAR 2003 database of scene text images and outperforms state-of-the-art approaches...|$|R
40|$|Optical music {{recognition}} (OMR) {{is one of}} {{the most}} promising tools for generating large-scale, distributable libraries of musical data. Much OMR work has focussed on instrumental music, avoiding a special challenge vocal music poses for OMR: lyric recognition. Lyrics complicate the page layout, making it more difficult to identify the regions of the page that carry musical notation. Furthermore, users expect a complete OMR process for vocal music to include recognition of the lyrics, reunification of syllables when they have been separated, and alignment of these lyrics with the recognised music. Unusual layouts and inconsistent practises for syllabification, however, make lyric recognition more challenging than traditional <b>optical</b> <b>character</b> <b>recognition</b> (OCR). This <b>paper</b> surveys historical approaches to lyric recognition, outlines open challenges, and presents a new approach to extracting text lines in medieval manuscripts, one of the frontiers of OMR research today. 1...|$|R
40|$|Editor’s Preface to this Online Edition This {{report by}} Cox and Foster {{is one of}} the most {{extensive}} and well-thought out reviews of the balance between the costs and benefits of occupational regulation that I have uncovered. It is also widely referenced by other reviews. † To continue to make the report widely available as a reference, I have created this unofficial (i. e. not published by the FTC) online edition of the report. I recreated this edition, by scanning and <b>optical</b> <b>character</b> <b>recognition,</b> from a <b>paper</b> copy of the FTC published report obtained in 2002. In this process, I have attempted to be true to the content, the overall layout and the original page breaks. Internal or external references to particular pages and paragraphs within the report remain valid. I have used margin and font-size settings that closely match the original line content, although there are slight variations from the original. I have deviated from the report’s original format in replacing the original typewriter-style serif font with the Trebuchet MS sans-serif font; a font designed to be highly readable via computer monitor. I have also added...|$|R
40|$|<b>Optical</b> <b>character</b> <b>recognition</b> (OCR) is an {{efficient}} way of converting scanned image into machine code which can further edit. There are {{variety of methods}} have been implemented {{in the field of}} <b>character</b> <b>recognition.</b> This <b>paper</b> proposes <b>Optical</b> <b>character</b> <b>recognition</b> by using Template Matching. The templates formed, having variety of fonts and size. In this proposed system, Image pre-processing, Feature extraction and classification algorithms have been implemented so as to build an excellent <b>character</b> <b>recognition</b> technique for different scripts. Result of this approach is also discussed in this paper. This system is implemented in Matlab...|$|R
50|$|<b>Optical</b> <b>character</b> <b>recognition.</b>|$|R
50|$|The {{application}} was originally named GOCR {{which stands for}} GNU <b>Optical</b> <b>Character</b> <b>Recognition.</b> When {{it came time to}} register the project on SourceForge the name GOCR was already taken so the project was registered as JOCR (Jörg's <b>Optical</b> <b>Character</b> <b>Recognition).</b>|$|R
40|$|There {{is a clear}} {{need for}} <b>optical</b> <b>character</b> <b>recognition</b> {{in order to provide}} a fast and {{accurate}} method to search both existing images as well as large archives of existing paper documents. However, existing <b>optical</b> <b>character</b> <b>recognition</b> programs suffer from a flawed tradeoff between speed and accuracy, making it less attractive for large quantities of documents. This paper analyzes five different algorithms which operate completely independently of <b>optical</b> <b>character</b> <b>recognition</b> programs, but which have the combined effect of decreasing computational complexity and increasing overall accuracy. Finally, the paper proposes implementing each of these algorithms on the GPU, as well as <b>optical</b> <b>character</b> <b>recognition</b> programs themselves, in order to deliver another massive speed increase...|$|R
5000|$|First Bilingual Gurmukhi/Roman <b>Optical</b> <b>Character</b> <b>Recognition</b> System ...|$|R
5000|$|... #Article: Comparison of <b>optical</b> <b>character</b> <b>recognition</b> {{software}} ...|$|R
40|$|<b>Optical</b> <b>Character</b> <b>Recognition</b> (OCR) document. WARNING! Spelling errors might subsist. In {{order to}} {{access to the}} {{original}} document in image form, click on "Original " button on 1 st page. ECO/CONF. / 29 <b>Optical</b> <b>Character</b> <b>Recognition</b> (OCR) document. WARNING! Spelling errors might subsist. In order to acces...|$|R
5000|$|<b>Optical</b> <b>Character</b> <b>Recognition</b> (OCR) {{support for}} {{image-based}} files ...|$|R
5000|$|This {{comparison}} of <b>optical</b> <b>character</b> <b>recognition</b> software includes: ...|$|R
5000|$|VisionGauge OnLine <b>Optical</b> <b>Character</b> <b>Recognition</b> and Verification Systems ...|$|R
5000|$|E-aksharayan - <b>Optical</b> <b>character</b> <b>recognition</b> {{engine for}} Indian {{languages}} ...|$|R
5000|$|Pattern {{recognition}} - {{in particular}} for <b>optical</b> <b>character</b> <b>recognition</b> ...|$|R
5000|$|... indexed (based on slide content, using <b>Optical</b> <b>Character</b> <b>Recognition),</b> ...|$|R
5000|$|... <b>optical</b> <b>character</b> <b>recognition,</b> such as {{automatic}} {{license plate}} detection.|$|R
5000|$|OsCar, an <b>optical</b> <b>character</b> <b>recognition</b> speech output reading machine ...|$|R
5000|$|<b>Optical</b> <b>character</b> <b>recognition</b> for ISO 1073-1:1976 {{and similar}} special characters.|$|R
