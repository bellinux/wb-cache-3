308|254|Public
5|$|The <b>operator</b> <b>interface</b> {{provides}} a means for an operator to start and stop the motor and adjust the operating speed. Additional operator control functions might include reversing, and switching between manual speed adjustment and automatic control from an external process control signal. The <b>operator</b> <b>interface</b> often includes an alphanumeric display and/or indication lights and meters {{to provide information about}} the operation of the drive. An <b>operator</b> <b>interface</b> keypad and display unit is often provided {{on the front of the}} VFD controller as shown in the photograph above. The keypad display can often be cable-connected and mounted a short distance from the VFD controller. Most are also provided with input and output (I/O) terminals for connecting push buttons, switches, and other <b>operator</b> <b>interface</b> devices or control signals. A serial communications port is also often available to allow the VFD to be configured, adjusted, monitored, and controlled using a computer.|$|E
25|$|The {{control system}} for this class is {{provided}} by General Dynamics Advanced Information Systems through an open architecture computing infrastructure (OPEN CI), while Lockheed provides their own control system for their variant of the LCS. OPEN CI includes the information technology (IT) infrastructure for the combat and seaframe control systems. This IT infrastructure also includes the primary <b>operator</b> <b>interface</b> for the control and monitoring of mission module operations.|$|E
2500|$|... b1257+12 (1998) - a {{software}} for sound deconstruction and composition. The intricate <b>operator</b> <b>interface</b> allows for radical manipulation of soundloops in realtime, offering {{a large amount}} of control parameters which, every now and then, take a life of their own. The name of the software refers to a rapidly rotating neutron star.|$|E
40|$|Dante II, an eight-legged {{walking robot}} {{developed}} by the Dante project, explored the active volcanic crater of Mount Spurr in July 1994. In this paper, we describe the <b>operator</b> <b>interfaces</b> and the network-based participation methods used during the Dante II mission. Both virtual environment and multi-modal <b>operator</b> <b>interfaces</b> provided mission support for supervised control of Dante II. Network-based participation methods including message communications, satellite transmission, and a World-WideWeb server enabled remote science and public interaction. We believe that these human-machine interfaces represent a significant advance in robotic technologies for exploration...|$|R
50|$|Aeronautics' ground ISR (GISR) {{solution}} incorporates advanced {{electro optical}} sensors, flexible and robust elevation systems and intuitive <b>operator</b> <b>interfaces.</b> Aeronautics GISR {{was delivered to}} several leading international military and HLS customers.|$|R
50|$|Besides {{improvements}} to power processes, the A1B reactor has other noticeable advantages. Compared to the Nimitz-class carriers' A4W, the A1B is smaller and weighs less. <b>Operator</b> <b>interfaces</b> {{are expected to}} be improved as well.|$|R
50|$|These are {{supported}} by a knowledge database, and a communication system that interconnects the functional processes and the knowledge database. Each functional element in the node may have an <b>operator</b> <b>interface.</b> The connections to the <b>Operator</b> <b>Interface</b> enable a human operator to input commands, to override or modify system behavior, to perform various types of teleoperation, to switch control modes (e.g., automatic, teleoperation, single step, pause), and to observe the values of state variables, images, maps, and entity attributes. The <b>Operator</b> <b>Interface</b> {{can also be used}} for programming, debugging, and maintenance.|$|E
5000|$|... 1985 First <b>operator</b> <b>interface</b> for the {{integration}} of production systems.|$|E
50|$|The <b>operator</b> <b>interface</b> {{provides}} a means for an operator to start and stop the motor and adjust the operating speed. Additional operator control functions might include reversing, and switching between manual speed adjustment and automatic control from an external process control signal. The <b>operator</b> <b>interface</b> often includes an alphanumeric display and/or indication lights and meters {{to provide information about}} the operation of the drive. An <b>operator</b> <b>interface</b> keypad and display unit is often provided {{on the front of the}} VFD controller as shown in the photograph above. The keypad display can often be cable-connected and mounted a short distance from the VFD controller. Most are also provided with input and output (I/O) terminals for connecting push buttons, switches, and other <b>operator</b> <b>interface</b> devices or control signals. A serial communications port is also often available to allow the VFD to be configured, adjusted, monitored, and controlled using a computer.|$|E
5000|$|Simplified Installation/Integration: These {{products}} do {{not require}} external or support electronics, thus simplifying installation and reducing weight and space requirements. Wescam has also implemented common <b>operator</b> <b>interfaces</b> and Line Replaceable Units (LRUs) to maintain interchangeability between turret models and platforms within a fleet.|$|R
50|$|Web guiding systems work at high speed, {{constantly}} {{making small}} adjustments {{to maintain the}} position of the material. The latest systems use digital technology and touch screen <b>operator</b> <b>interfaces</b> so simplify set up. Web guiding systems are used on slitting machines, slitter rewinders, printing presses, coating and laminating machines.|$|R
40|$|Abstract. The Autonomy and Robotics Area (ARA) at NASA Ames Research Center has {{investigated}} {{the use of}} various types of Virtual Reality-based <b>operator</b> <b>interfaces</b> to remotely control complex robotic mechanisms. In this paper, we describe the major accomplishments and technology applications of the ARA in this area, and highlight the advantages and issues related to this technology...|$|R
50|$|Simpler, {{effective}} OS software {{has improved}} the <b>operator</b> <b>interface</b> {{and speed of}} execution, while reducing OS failures.|$|E
50|$|There is a {{difference}} between a user interface and an <b>operator</b> <b>interface</b> or a human-machine interface (HMI).|$|E
50|$|Many patent {{applications}} are pending for new mobile phone apps. Most {{of these are}} in the technological fields of business methods, database management, data transfer, and <b>operator</b> <b>interface.</b>|$|E
40|$|The {{operation}} of remote science exploration vehicles benefits greatly from {{the application of}} advanced telepresence and virtual reality <b>operator</b> <b>interfaces.</b> Telepresence, or the projection of the human sensory apparatus into a remote location, can provide scientists with a much greater intuitive understanding of {{the environment in which}} they are working than simple camera-display systems. Likewise virtual reality, or the use of highly interactive three-dimensional computer graphics, can both enhance an operator’s situational awareness of an environment and also compensate (to some degree) for low bandwidth and/or long time delays in the communications channel between the operator and the vehicle. These advanced <b>operator</b> <b>interfaces</b> are important for terrestrial science and exploration applications, and are critical for missions involving the exploration of other planetary surfaces, such as on Mars. The undersea environment provides an excellent terrestrial analog to science exploration and operations on another planetary surface...|$|R
40|$|This paper {{develops}} {{the concept of}} mediators: virtual interfaces with haptic feedback for teleoperation. Our approach is to replace physical <b>operator</b> <b>interfaces</b> by fully parameterizable adaptive virtual interfaces. Mediators open new possibilities for multimodal feedback for control interfaces. We apply mediators {{in the context of}} teleoperation of robots. The implemented prototype shows the feasibility of using virtual haptic interfaces to drive robots remotely. 1...|$|R
50|$|Autopatches are {{telephone}} hybrids used by amateur radio <b>operators</b> to <b>interface</b> their {{radio equipment}} with telephone lines.|$|R
5000|$|Telemedicine {{allows a}} remote {{retrieval}} of three-dimensional CT scans, images rotation and zooming {{in real time}} through an <b>operator</b> <b>interface</b> to hospital server and medical equips in speakerphone.|$|E
5000|$|The user {{interface}} of a mechanical system, a vehicle or an industrial installation is {{sometimes referred to}} as the human-machine interface (HMI). HMI is a modification of the original term MMI (man-machine interface). In practice, the abbreviation MMI is still frequently used although some may claim that MMI stands for something different now. Another abbreviation is HCI, but is more commonly used for human-computer interaction. Other terms used are <b>operator</b> <b>interface</b> console (OIC) and <b>operator</b> <b>interface</b> terminal (OIT). However it is abbreviated, the terms refer to the 'layer' that separates a human that is operating a machine from the machine itself. Without a clean and usable interface, humans {{would not be able to}} interact with information systems.|$|E
50|$|Hazards in {{the field}} include water and corrosives, sand and wind, extreme temperatures, high shock and vibration, power interruptions, {{susceptibility}} to EMI/RFI radiation, etc. Also, <b>operator</b> <b>interface</b> was complex, and most operating systems were not fast in operation, or easy to learn and use in pressure situations.|$|E
40|$|A {{cost-effective}} PC-based {{motion control}} system {{was developed and}} evaluated for use on a laser welding system. The motion system is capable of X-Y simultaneous contouring and provides a rotary axis of motion also. The system motion paths can be specified in either Relative or Absolute motion. The PC controls all of the laser power supply and shutter I/O operations. All of the motion programming and <b>operator</b> <b>interfacing</b> is via the Windows {reg_sign} 95 operating system...|$|R
50|$|Patriot's crew {{stations}} {{are referred to}} as Manstation 1 and 3 (MS1 and MS3). These are the stations where Patriot <b>operators</b> <b>interface</b> with the system. The manstations consist of a monochrome (green and black) screen surrounded by various Switch Indicators. Each manstation also has a traditional QWERTY keyboard and isometric stick, a tiny joystick that functions much like a PC mouse. It is through these switch indicators and the Patriot user interface software that the system is operated.|$|R
40|$|Experience {{in recent}} {{conflicts}} indicates {{the employment of}} Unmanned Vehicle Systems (UVS) {{will continue to grow}} in coming years. New UVS capabilities involve greater complexity of payloads and interactions within unmanned vehicle (UV) subsystems, among UVS and between UVS and other systems, including Command and Control (C 2) systems. This introduces additional requirements for UV operators. In some situations UV operators easily can be faced with cognitive information overload, while increasing UVS complexity and future concepts of employment such as single-operator multiple-UV operation require increased operator attention. In order to attain the required level of operator efficiency, it is necessary to introduce higher levels of autonomy within the UVS subsystems in conjunction with the use of intelligent <b>operator</b> <b>interfaces.</b> This will allow for greater flexibility and effectiveness in supporting future mission requirements wherein UVS <b>operator</b> <b>interfaces</b> are able to reduce the work load, and allow operators to function at higher levels of abstraction. In this context, this study justifies the employment of intelligent systems to attain higher levels of autonomy for a specific family of UVS, which are the Unmanned Aerial Systems (UAS). The proposed approach i...|$|R
50|$|Operator {{commands}} {{are mostly}} two letters (as with Unix), {{and some are}} just one letter. This means that the <b>operator</b> <b>interface</b> must be learned, {{but it is very}} efficient for experienced operators who run a large mainframe system from day to day. Commands are case insensitive.|$|E
5000|$|A human-machine {{interface}} (HMI) is typically local to one machine or piece of equipment, {{and is the}} interface method between the human and the equipment/machine. An <b>operator</b> <b>interface</b> is the interface method by which multiple equipment that are linked by a host control system is accessed or controlled.|$|E
5000|$|The {{equipment}} control task did not properly synchronize with the <b>operator</b> <b>interface</b> task, so that race conditions occurred if the operator changed the setup too quickly. This was missed during testing, since {{it took some}} practice before operators were able to work quickly enough to trigger this failure mode.|$|E
40|$|MD This paper {{describes}} {{an effort to}} identify common metrics for task-oriented human-robot interaction (HRI). We begin by discussing {{the need for a}} toolkit of HRI metrics. We then describe the framework of our work and identify important biasing factors that must be taken into consideration. Finally, we present suggested common metrics for standardization and a case study. Preparation of a larger, more detailed toolkit is in progress. Categories and Subject Descriptors I. 2. 9 [Artificial Intelligence]: Robotics – <b>operator</b> <b>interfaces...</b>|$|R
5000|$|From 1997 to 2013, Dr. Endsley {{served as}} President and CEO of SA Technologies in Marietta, Georgia, a {{cognitive}} engineering {{firm specializing in}} the development of <b>operator</b> <b>interfaces</b> for advanced systems, including the next generation of systems for aviation, air traffic control, medical, power, oil & gas, and military operations. Prior to forming SA Technologies she was a Visiting Associate Professor at MIT in the Department of Aeronautics and Astronautics and Associate Professor of Industrial Engineering at Texas Tech University.|$|R
40|$|This paper {{presents}} a control system for mobile robots. The controller {{was developed to}} satisfy {{the needs of a}} wide range of <b>operator</b> <b>interfaces</b> and teleoperation in unknown, unstructured environments. In particular, the controller supports varying degrees of cooperation between the operator and robot, from direct to supervisory control. The controller has a modular architecture and includes interprocess communications, localization, map building, safeguarding, sensor management, and speech synthesis. In this paper, we describe the design of the controller and discuss its use in several applications. ...|$|R
5000|$|... #Caption: a print {{simulator}} {{integrated into}} a real press control console, the different screens show (from left to right)1. the pressroom (access to the machine and environment)2. the printed copy : high contrast, small display3. the printed copy: lower contract, large display4. a real <b>operator</b> <b>interface</b> to a process control system ...|$|E
50|$|Within Infrared Thermography in {{the early}} 1980s Thermoteknix {{developed}} electronic hardware and software. In 2002 they launched a portable infrared camera - the world’s first infrared camera with simultaneous video display, voice recording, Wi-Fi and Touch-screen <b>Operator</b> <b>interface</b> for Predictive Maintenance. These models are used for Fever Screening at airports, Science and Real-time R&D.|$|E
50|$|Research is {{currently}} being carried out {{with the aim of}} endowing RAPOSA with a higher degree of autonomy, meaning that certain operations requiring manual operation can be done autonomously by the robot. These include: autonomous stair climbing, autonomous docking, and preventive stop after hole detection. Moreover, human-robot interaction issues are also being tackled by improving the <b>operator</b> <b>interface,</b> namely exploring augmented reality techniques.|$|E
40|$|The {{mission of}} a {{tracking}} station within the NASA/Jet Propulsion Deep Space Network {{is characterized by}} a wide diversity of spacecraft types, communications ranges, and data accuracy requirements. In the present paper, the system architecture, communications techniques, and <b>operators</b> <b>interfaces</b> for a utility controller are described. The control equipment as designed and installed is meant to be a tool to study applications of automated control in the dynamic environment of a tracking station. It allows continuous experimenting with new technology without disruption of the tracking activities...|$|R
50|$|Supervisory {{control and}} data {{acquisition}} (SCADA) is a control system architecture that uses computers, networked data communications and {{graphical user interfaces}} for high-level process supervisory management, but uses other peripheral devices such as programmable logic controllers and discrete PID controllers to interface to the process plant or machinery. The <b>operator</b> <b>interfaces</b> which enable monitoring and the issuing of process commands, such as controller set point changes, are handled through the SCADA supervisory computer system. However, the real-time control logic or controller calculations are performed by networked modules which connect to the field sensors and actuators.|$|R
40|$|Abstract—Present {{generation}} AUVs act as mobile sensor platforms, allowing post mission debriefs {{which require}} {{little more than}} an adequate expression of the collected data, and only basic requirements for mission planning. As the need and capability advances, autonomy will increase in turn, leading to more complex missions, which must be supported by more capable <b>operator</b> <b>interfaces,</b> both for post mission debrief and pre-mission verification, lest a deficit of trust form between the vehicles and their operators. We present Glaykos, a system designed to automatically create audio visual debriefs for missions carried out with both real and simulated vehicles, allowing it to act as a tool for both pre-mission verification and post mission debrief. A series of data transforms are applied to the domain information and mission logs from an AUV mission, resulting in the creation of an audio visual debrief whose structure is informed by principles of human computer interaction and narrative. The approach is tested for effectiveness and results of this are presented, showing that it better able to keep users informed when compared two other debriefing strategies, one of which mimics {{the current state of the}} art. Conclusions are drawn regarding the system’s monologue based approach acting as a first step towards more complex and capable multimodal, dialogue based <b>operator</b> <b>interfaces</b> for autonomous systems. I...|$|R
