24|312|Public
5|$|Reflector sights work {{by using}} a lens or an image-forming curved mirror with a {{luminous}} or reflective <b>overlay</b> <b>image</b> or reticle at its focus, creating an optical collimator that produces a virtual image of that reticle. The image is reflected off some form of angled beam splitter or the partially silvered collimating curved mirror itself so that the observer (looking through the beam splitter or mirror) will see the image at {{the focus of the}} collimating optics superimposed in the sight's field of view in focus at ranges up to infinity. Since the optical collimator produces a reticle image made up of collimated light, light that is nearly parallel, the light making up that image is theoretically perfectly parallel with the axis of the device or gun barrel it is aligned with, i.e. with no parallax at infinity. The collimated reticle image can also be seen at any eye position in the cylindrical volume of collimated light created by the sight behind the optical window. But this also means, for targets closer than infinity, sighting towards the edge of the optical window can make the reticle move in relation to the target since the observer is sighting down a parallel light bundle at the edge. Eye movement perpendicular to the device's optical axis will make the reticle image move in exact relationship to eye position in the cylindrical column of light created by the collimating optics.|$|E
5000|$|... #Caption: Mouse kidney: (a) MALDI spectra {{from the}} tissue. (b) H&E stained tissue. N-glycans at m/z = 1996.7 (c) {{is located in}} the cortex and medulla while m/z = 2158.7 (d) is in the cortex, (e) An <b>overlay</b> <b>image</b> of these two masses, (f) {{untreated}} control tissue.|$|E
50|$|The revised cover art by Rudy Nappi shows Nancy {{in a pink}} {{suit with}} the letter {{in her hand and}} an <b>overlay</b> <b>image</b> of the letter on a blue background. An uncredited {{illustrator}} provided a frontispiece and five plain paper internal drawings featuring rare glimpses of the interior of the Drew home. The 1968 artwork remains unchanged in current imprints.|$|E
40|$|Abstract—Fluoroscopic <b>overlay</b> <b>images</b> {{rendered}} from pre-operative volumetric {{data can}} provide additional anatomical details to guide physicians during catheter ablation procedures {{for treatment of}} atrial fibrillation (AFib). As these <b>overlay</b> <b>images</b> are often compromised by cardiac and respiratory motion, motion compensation methods are {{needed to keep the}} <b>overlay</b> <b>images</b> in sync with the fluoroscopic images. So far, these approaches have either required simultaneous biplane imaging for 3 -D motion compensation, or in case of monoplane X-ray imaging, provided only a limited 2 -D functionality. To overcome the downsides of the previously suggested methods, we propose an approach that facilitates a full 3 -D motion compensation even if only monoplane X-ray images are available. To this end, we use a training phase that employs a biplane sequence to establish a patient specific motion model. Afterwards, a constraine...|$|R
40|$|Abstract. Atrial {{fibrillation}} is {{the most}} common heart arrhythmia and a leading cause of stroke. The treatment option of choice is radio-frequency catheter ablation, which is performed in elec-trophysiology labs using C-Arm X-ray systems for navigation and guidance. The goal is to electrically isolate the pulmonary vein-left atrial junction thereby rendering myocardial fibers responsible for induction and maintenance of AF inactive. The use of <b>overlay</b> <b>images</b> for fluo-roscopic guidance may improve the quality of the ablation procedure, and can reduce procedure time. <b>Overlay</b> <b>images,</b> acquired using CT, MRI, or C-arm CT, can add soft-tissue information, otherwise not visible under X-ray. MRI can be used to image a wide variety of anatomical details without ionizing radiation. In this paper, we present a method to register a 3 -D MRI volume to 2 -D biplane X-ray images using the coronary sinus. Current approaches require reg-istration of the <b>overlay</b> <b>images</b> to the fluoroscopic images to be performed after the trans-septal puncture, when contast agent can be administered. We present a new approach for registration to align <b>overlay</b> <b>images</b> before the trans-septal puncture. To this end, we manually extract the coronary sinus from pre-operative MRI and register it to a multi-electorde catheter placed in the coronary sinus...|$|R
5000|$|The {{campaign}} features semi-transparent numbers <b>overlaying</b> <b>images</b> of today’s business environment, and the tagline, We {{see more}} than numbers, emphasizes the credibility and vision that CGAs bring to organizations and clientele.” ...|$|R
50|$|In 2010 Virtual Play Games {{published}} Intellivision Lives! for the Nintendo DS handheld system, {{also developed}} by Realtime Associates. It features wireless, multiplayer support using a single game card. The Nintendo DSs touch screen emulates the Intellivisions 12-button keypad including an <b>overlay</b> <b>image</b> for each game. The Nintendo DS lacks a 16 direction pad {{used by some}} Intellivision games. This limitation was overcome, in Vectron for example, by mapping directional inputs to the touchpad. Only 10,000 copies of the Nintendo DS edition were ever printed.|$|E
50|$|Modern {{frame grabber}} devices often perform {{functions}} beyond capturing a single video input. For example, some devices can capture audio {{in addition to}} video, and some provide multiple video inputs that are captured concurrently. Other operations may be performed as well, such as deinterlacing, text or graphics <b>overlay,</b> <b>image</b> transformations (e.g., resizing, rotation, mirroring), and real time compression using algorithms such as MPEG2 and JPEG. Also, technological demands in fields such as radar acquisition, manufacturing and remote guidance {{have led to the}} development of frame grabbers that can capture images at high frame rates and resolutions.|$|E
50|$|The 7D Mark II has 65 {{autofocus}} points, {{a similar}} system {{as on the}} Canon EOS 1D X. However, certain lenses do not support all 65 AF points. The AF system uses a translucent LCD display in the viewfinder to <b>overlay</b> <b>image</b> data with the viewfinder image. The EOS 7D Mark II camera features {{the next generation of}} Canon’s exclusive Dual Pixel CMOS AF (DAF) technology, originally introduced with the Canon EOS 70D camera. Dual Pixel CMOS AF employs proprietary Canon sensor technology in which effective pixels are able to perform both imaging and phase-detection focus measurement simultaneously to achieve dramatically improved AF performance in both video and Live View still imaging modes.|$|E
50|$|Virtual disk {{images can}} be stored in a special format (qcow or qcow2) that only take up disk space that the guest OS {{actually}} uses. This way, an emulated 120 GB disk may occupy only a few hundred megabytes on the host. The QCOW2 format also allows the creation of <b>overlay</b> <b>images</b> that record the difference from another (unmodified) base image file. This provides the possibility for reverting the emulated disk's contents to an earlier state. For example, a base image could hold a fresh install of an operating system that is known to work, and the <b>overlay</b> <b>images</b> are used. Should the guest system become unusable (through virus attack, accidental system destruction, etc), the user can delete the overlay and reconstruct an earlier emulated disk-image version.|$|R
5000|$|KML {{files are}} very often {{distributed}} in KMZ files, which are zipped KML files with a [...]kmz extension. These must be legacy (ZIP 2.0) compression compatible (i.e. stored or deflate method), otherwise the [...]kmz file might not uncompress in all geobrowsers. The {{contents of a}} KMZ file are a single root KML document (notionally [...] "doc.kml") and optionally any <b>overlays,</b> <b>images,</b> icons, and COLLADA 3D models referenced in the KML including network-linked KML files. The root KML document by convention is a file named [...] "doc.kml" [...] at the root directory level, which is the file loaded upon opening. By convention the root KML document is at root level and referenced files are in subdirectories (e.g. <b>images</b> for <b>overlay</b> <b>images).</b>|$|R
40|$|Abstract—This work {{discusses}} various {{techniques used}} in visualizing sets of coregistered images for planetary lander or rover mission operations. Imagery from all available instrumentation {{on board a}} planetary rover or lander is useful in science analysis of a remote landing site. We use a visualization technique called data fusion to expedite analyzing data from an instrument suite. Data fusion uses coregistration information to <b>overlay</b> <b>images</b> from different instruments together. These <b>overlay</b> <b>images</b> are then presented to the scientist in both 2 D and 3 D visualization tools. Next, we introduce a technique for panorama visualization {{that is based on}} a spherical warp operation. This warping technique is optimized for computational efficiency in order that it is able to run dynamically and to support a 2 D or 3 D visualization tool. We then present some results of the implementation of thes...|$|R
50|$|Reflector sights work {{by using}} a lens or an image-forming curved mirror with a {{luminous}} or reflective <b>overlay</b> <b>image</b> or reticle at its focus, creating an optical collimator that produces a virtual image of that reticle. The image is reflected off some form of angled beam splitter or the partially silvered collimating curved mirror itself so that the observer (looking through the beam splitter or mirror) will see the image at {{the focus of the}} collimating optics superimposed in the sight's field of view in focus at ranges up to infinity. Since the optical collimator produces a reticle image made up of collimated light, light that is nearly parallel, the light making up that image is theoretically perfectly parallel with the axis of the device or gun barrel it is aligned with, i.e. with no parallax at infinity. The collimated reticle image can also be seen at any eye position in the cylindrical volume of collimated light created by the sight behind the optical window. But this also means, for targets closer than infinity, sighting towards the edge of the optical window can make the reticle move in relation to the target since the observer is sighting down a parallel light bundle at the edge. Eye movement perpendicular to the device's optical axis will make the reticle image move in exact relationship to eye position in the cylindrical column of light created by the collimating optics.|$|E
30|$|An <b>overlay</b> <b>image</b> was {{extracted}} by clipping the scaled down {{wide-angle camera}} image.|$|E
30|$|The {{overlay region}} {{determined}} in process 2 {{in the background}} image {{was replaced by the}} <b>overlay</b> <b>image</b> extracted in process 4.|$|E
40|$|Abstract. Fluoroscopic <b>overlay</b> <b>images</b> {{rendered}} from pre-operative vol-umetric {{data can}} provide additional guidance for physicians during catheter ablation procedures {{for treatment of}} atrial fibrillation (AFib). As these <b>overlay</b> <b>images</b> are compromised by cardiac and respiratory motion, mo-tion compensation methods have been proposed. The approaches so far either require simultaneous biplane imaging for 3 -D motion compensa-tion or, in case of mono-plane X-ray imaging, provide only a limited 2 -D functionality. To overcome the downsides of the previously suggested methods, we propose a new approach that facilitates full 3 -D motion compensation even if only mono-plane X-ray views are available. To this end, we use constrained model-based 2 -D/ 3 -D registration to track a circumferential mapping catheter which is commonly used during AFib catheter ablation procedures. Our approach yields an average 2 -D track-ing error of 0. 6 mm and an average 3 -D tracking error of 2. 1 mm. ...|$|R
5000|$|Study and {{prediction}} of facial growth by <b>overlaying</b> older <b>images</b> to compare growth.|$|R
40|$|This work {{discusses}} various {{techniques used}} in visualizing sets of coregistered images for planetary lander or rover mission operations. Imagery from all available instrumentation {{on board a}} planetary rover or lander is useful in science analysis of a remote landing site. We use a visualization technique called data fusion to expedite analyzing data from an instrument suite. Data fusion uses coregistration information to <b>overlay</b> <b>images</b> from different instruments together. These <b>overlay</b> <b>images</b> are then presented to the scientist in both 2 D and 3 D visualization tools. Next, we introduce a technique for panorama visualization {{that is based on}} a spherical warp operation. This warping technique is optimized for computational efficiency in order to run dynamically and to support a 2 D or 3 D visualization tool. We then present some results of the implementation of these techniques for the 2003 MER Science Activity Planner software, using image data from the 2002 FIDO-MER field test. We conclude with a discussion of future directions for these visualization techniques. TABLE OF CONTENTS...|$|R
40|$|Video mixing circuit places {{transparent}} <b>overlay</b> <b>image</b> on all or {{portion of}} normal image on television screen. Overlay computer-generated graphics, text, or another image. Background video brightness signal fed into one input terminal of circuit, while overlay brightness signal fed into other input terminal. Amplitude of background brightness signal modulated by overlay brightness signal, resulting in video image in which background image appears as though viewed through overlay. Multiplying video mixer, combined with additional circuitry, places transparent or opaque overlay images on normal (background) video images...|$|E
3000|$|... + at {{a current}} 5  nA; raster size of 300  μm[*]×[*] 300  μm; pulse width of 1.8  ns (bunched for {{spectrum}} mode) or 13.0  ns (not bunched for image mode); mass range, m/z of 0 – 1850; spot size of 1.0  μm in image mode; temperature of − 120 to − 130 [*]°C; a low-energy pulsed electron gun (30.0  eV) {{was used for}} surface charge compensation. Subsequently, the same region was examined using cryo-scanning electron microscopy (cryo-SEM). The conditions employed for the observation were as follows: acceleration voltage of 1.5  kV; temperature of − 120 [*]°C; working distance of 10  mm. The <b>overlay</b> <b>image</b> of the selected cryo-TOF-SIMS ion on cryo-SEM image was obtained using Photoshop CS 5 Extended (Adobe Systems Incorporated).|$|E
40|$|To {{identify}} in tissue sections {{the relative}} positions of antigen distributions {{close to the}} resolving power of the microscope, we have developed the fluorescence overlay antigen mapping (FOAM) procedure. As this technique makes high demands on the geometric fidelity of the <b>overlay</b> <b>image,</b> {{it is essential to}} recognize geometric errors resulting from optical imperfections. This applies in particular to the image shift difference (ISD) that may routinely occur during fluorescence overlay. We describe here procedures for assessment and mechanical correction of the ISD in tissue sections. Furthermore, we describe an alignment verification test to assess the accuracy of the ISD correction procedure, using collagen Type VII as the geometric verification marker. These procedures should enable reliable evaluation of relative antigen distributions in tissue sections using photomicrographic multicolor fluorescence overlay. Further details of the FOAM technique, such as color fidelity and its utility for diagnostic and research purposes, will be published separately. ...|$|E
40|$|Atrial {{fibrillation}} (Afib) is {{the most}} common heart arrhythmia and a leading cause of stroke. The treatment option is radio-frequency catheter ablation (RFCA). RFCA is performed in electrophysiology (EP) labs using C-Arm X-ray systems for navigation and guidance. The goal is to electrically isolate the pulmonary vein-left atrial junction thereby rendering myocardial fibers responsible for induction and maintenance of AF inactive [1]. The use of <b>overlay</b> <b>images</b> for fluoroscopic guidance may improve the quality of the ablation, and it can reduce procedure time [2, 3]. <b>Overlay</b> <b>images,</b> acquired using CT, MRI, or C-arm CT, can add soft-tissue information otherwise not visible under X-ray. MRI can be used to image a wide variety of anatomical details without ionizing radiation. In this paper, we show how to register 3 -D MRI volumes to 2 -D X-ray images based on the coronary sinus. Materials and Methods The MR images were obtained on a Siemens Avanto MR system (Siemens, Erlangen, Germany). For intra-procedural imaging, a biplane C-Arm system (AXIOM Artis dBC, Siemens, Forchheim, Germany) was used. Such a system consists of two C-Arms that allow simultaneous fluoroscopic imaging under different viewing directions. In our case, the syste...|$|R
5000|$|... #Caption: BisQue user {{interface}} showing {{results of a}} cell nuclei detection module run (red dots are graphical objects indicating nuclei <b>overlaying</b> the <b>image).</b>|$|R
40|$|Abstract. Radio-frequency {{catheter}} ablation (RFCA) {{has become}} an accepted treatment option for atrial fibrillation (Afib). RFCA of Afib involves isolation of the pulmonary veins under X-ray guidance. For easier navigation, two-dimensional X-ray imaging may take advantage of <b>overlay</b> <b>images</b> derived from static pre-operative 3 -D data set to add anatomical details which, otherwise, would not be visible under X-ray. Unfortunately, respiratory and cardiac motion may impair the utility of static <b>overlay</b> <b>images</b> for catheter navigation. We developed a system for image-based 2 -D motion estimation and compensation {{as a solution to}} this problem. It is based on 2 -D catheter tracking facilitated by modelbased registration of an ellipse-shaped model to fluorosocpic images. A mono-plane or a bi-plane X-ray C-arm system can be used. In the first step of the method, a 2 -D model of the catheter device is computed. Respiratory and cardiac motion at the site of ablation is then estimated by tracking the catheter device in fluoroscopic images. The cost function of the registration step is based on the average distance of the model to the segmented circumferential mapping catheter using a distance map. In our experiments, the circumferential catheter was successfully tracked in 688 fluoroscopic images with an average 2 -D tracking error of 0. 59 mm ± 0. 25 mm. Our presented method achieves a tracking rate of 10 frames-per-second. ...|$|R
40|$|Remote sensing {{technology}} {{can be used to}} better understand the earth’s characteristics. SeaWiFS (sea-viewing wide field-of-view sensor) is one of remote sensors used to observe global ocean phenomena. Previous studies showed that the distribution of chlorophyll-a in the ocean indicates the presence of fish. However, only a few studies tried to directly relate the chlorophyll-a distribution obtained through interpretation of satellite imagery to in-situ data of fish distribution. This paper investigates the relation between chlorophyll-a distribution and fish-capturing points in Aceh Province sea waters using <b>overlay</b> <b>image</b> analysis. The results are then used to identify the potential fishing ground in Aceh. The profile of chlorophyll-a concentration is derived from SeaWIFS satellite imagery. Fish-capturing points data is obtained from the fisherman communities of Banda Aceh, starting from June to November 2008. The results showed that the chlorophyll-a profile derived from satellite imagery has a positive relationship to fish-capturing point data. The most potential fish-capturing zone in Aceh sea waters is identified at 5 - 8 º north latitude (N) and 96 - 99 º east longitude (E) ...|$|E
40|$|Color {{blending}} is {{a popular}} display method for functional and anatomic image fusion. The underlay image is typically displayed in grayscale, and the <b>overlay</b> <b>image</b> is displayed in pseudo colors. This pixel-level fusion provides too much information for reviewers to analyze quickly and effectively and clutters the display. To improve the fusion image reviewing speed and reduce the information clutter, a pixel-feature hybrid fusion method is proposed and tested for PET/CT images. Segments of the colormap are selectively masked {{to have a few}} discrete colors, and pixels displayed in the masked colors are made transparent. The colormap thus creates a false contouring effect on overlay images and allows the underlay to show through to give contours an anatomic context. The PET standardized uptake value (SUV) is used to control where colormap segments are masked. Examples show that SUV features can be extracted and blended with CT image instantaneously for viewing and diagnosis, and the non-feature part of the PET image is transparent. The proposed pixel-feature hybrid fusion highlights PET SUV features on CT images and reduces display clutters. It is easy to implement and can be used as complementarily to existing pixel-level fusion methods...|$|E
40|$|ObjectiveTo {{evaluate}} the automated 2 D- 3 D image overlay system (“ 3 D Roadmap”) for use during endovascular aneurysm repair (EVAR) in the hybrid operating theater. MethodsDatasets of preoperative CT images were modified to subtract dense bone marrow {{to improve the}} visualization of vasculature on the overlaid image, and allow for accurate navigation of the endovascular devices. The 3 D-CT <b>overlay</b> <b>image</b> was registered on the 2 D fluoroscopy image to mark the iliac crest and lumbar vertebrae on both images as landmarks. ResultsArteriography was performed only twice to confirm the precision {{of the position of}} renal artery and the final evaluation. Twenty patients underwent EVAR with Medtronic Endurant, Gore Excluder, or COOK Zenith using “ 3 D Roadmap”. The origin of the renal artery and iliac bifurcation were registered with complete accuracy in 10 patients (50 %). The lower renal artery deviated toward the cranial side less than 3  mm in six patients. In all cases, EVAR was successful, and completed with the volume of contrast material limited to 43. 8  ±  3. 1  mL. Conclusion“ 3 D Roadmap” was confirmed to be valuable for visualization of vessel origin in a fused image and for reduction of contrast material during EVAR...|$|E
40|$|Abstract. Atrial {{fibrillation}} (AFib) {{has been}} identified as a major cause of stroke. Radiofrequency catheter ablation has become an increasingly important treatment option, especially when drug therapy fails. Navigation under X-ray can be enhanced by using augmented fluoroscopy. It renders <b>overlay</b> <b>images</b> from pre-operative 3 -D data sets which are then fused with X-ray images to provide more details about the underlying soft-tissue anatomy. Unfortunately, these fluoroscopic <b>overlay</b> <b>images</b> are compromised by respiratory and cardiac motion. Various methods to deal with motion have been proposed. To meet clinical demands, they have to be fast. Methods providing a processing frame rate of 3 frames-per-second (fps) are considered suitable for interventional electrophysiology catheter procedures if an acquisition frame rate of 2 fps is used. Unfortunately, when working at a processing rate of 3 fps, the delay until the actual motion compensated image can be displayed is about 300 ms. By using a novel approach involving a 3 -D catheter model, catheter segmentation and a distance transform, we can speed up motion compensation to 20 fps which results in a display delay of only 50 ms on a standard workstation for medical applications. Our method uses a constrained 2 -D/ 3 -D registration to perform catheter tracking, and it obtained a 2 -D tracking error of 0. 61 mm...|$|R
40|$|Abstract. Atrial {{fibrillation}} is {{the most}} common sustained arrhythmia. One important treatment option is radio-frequency catheter ablation (RFCA) of the pulmonary veins attached to the left atrium. RFCA is usually performed under fluoroscopic (X-ray) <b>image</b> guidance. <b>Overlay</b> <b>images</b> computed from pre-operative 3 -D volumetric data can be used to add anatomical detail otherwise not visible under X-ray. Unfortunately, current fluoro <b>overlay</b> <b>images</b> are static, i. e., they do not move synchronously with respiratory and cardiac motion. A filter-based catheter tracking approach using simultaneous biplane fluoroscopy was previously presented. It requires localization of a circumferential tracking catheter, though. Unfortunately, the initially proposed method may fail to accommodate catheters of different size. It may also detect wrong structures in the presence of high background clutter. We developed a new learning-based approach to overcome both problems. First, a 3 -D model of the catheter is reconstructed. A cascade of boosted classifiers is then used to segment the circumferential mapping catheter. Finally, the 3 -D motion at the site of ablation is estimated by tracking the reconstructed model in 3 -D from biplane fluoroscopy. We compared our method to the previous approach using 13 clinical data sets and found that the 2 -D tracking error improved from 1. 0 mm to 0. 8 mm. The 3 -D tracking error was reduced from 0. 8 mm to 0. 7 mm. ...|$|R
5000|$|... #Caption: Mosaic of Justinian, {{probably}} an <b>overlay</b> of an <b>image</b> of Theoderic.|$|R
40|$|Mekong River {{runs from}} Hengduan Mountains in central-west China to Vietnam {{covering}} 805, 604 sq km of land by its basin. The Lower Mekong Basin (LMB), the region mapped in this study, covers nearly 3 / 4 {{of the entire}} basin. About 90 % {{of the population and}} agricultural activities of the Mekong River basin is located in this fertile LMB which faces disastrous floods almost annually. Mapping LMB at moderate resolution gives number of advantages for studies of flood mitigation and land utilization. However, compiling a cloud free mosaic and collecting ground truth data for training samples and map validation make map production process a challenging task. This study utilized MODIS 250 m image data of the region obtained in 2005 February. Dry weather in Jan-Apr makes the sky relatively free of clouds and 2005 February also had fewer disturbances coming from smoke of biomass burning. The methodology of the study substantially relied on high resolution images in Google Earth for collection of training sample for supervised classification and accuracy assessment. Arc GIS generated KMZ file of unclassified and classified maps used to <b>overlay</b> <b>image</b> and map on Google Earth for identifying training site and field information extraction for accuracy assessment. Also ground information collected by a different research projects in 2008 were combined with information gathers from Google Earth images. The classified map showed 29. 2 % of the LMB under forest, 36. 5 % under Scrubland, when combine...|$|E
40|$|The {{specific}} {{patterns of}} land use change that {{can be observed in}} many economically developed countries have fundamental implications on landscape structure and geomorphological processes. Areas characterized by widespread erosion such as badlands are often sensitive to anthropic modifications and of large interest in the analysis of the topographic determinants {{of land use}} change. This work aims to analyse the land use and landscape structure changes occurred in a Mediterranean landscape by analysing historical maps and infer the underlying processes that contribute to the pattern of change. First we carried out a comparative examination of three historical image datasets (1820, 1954, 2005) through <b>overlay</b> <b>image</b> processing and cross-classification analysis. Then we analysed the relationships between the detected land-use transformations and topographic parameters. Finally we determined the landscape structure change patterns through the use of GIS-based landscape metrics. The results showed how the study areas have experienced significant land use changes, mainly due to the abandonment of traditional rural systems. We found semi-natural areas distribution to be closely connected with terrain-shaping processes. The processes that underlie the multi-temporal landscape structure change have produced an overall increase of the landscape complexity. The work {{is one of the first}} attempts to use historical cartographic data to quantitatively assess changes in land use and landscape structure in the Mediterranean area. The proposed integrated methodology can support decision-making in landscape planning and may represent a useful tool to define effective strategies for biodiversity conservation...|$|E
40|$|Abstract Background Combining {{characteristic}} morphological {{and functional}} information in one image increases pathophysiologic understanding {{as well as}} diagnostic accuracy in most clinical settings. En-face optical coherence tomography (OCT) provides a high resolution, transversal OCT image of the macular area combined with a confocal image of the same area (OCT C-scans). Creating an <b>overlay</b> <b>image</b> of a conventional angiographic image onto an OCT image, using the confocal part to facilitate transformation, combines structural and functional information of the retinal area of interest. This paper describes the construction of such overlay images and their aid in improving the interpretation of OCT C-scans. Methods In various patients, e n-face OCT C-scans (made with a prototype OCT-Ophthalmoscope (OTI, Canada) in use at the Department of Ophthalmology (Academic Medical Centre, Amsterdam, The Netherlands)) and conventional fluorescein angiography (FA) were performed. ImagePro, with a custom made plug-in, was used to make an overlay-image. The confocal part of the OCT C-scan was used to spatially transform the FA image onto the OCT C-scan, using the vascular arcades as a reference. To facilitate visualization the transformed angiographic image and the OCT C-scan were combined in an RGB image. Results The confocal part of the OCT C-scan could easily be fused with angiographic images. Overlay showed a direct correspondence between retinal thickening and FA leakage in Birdshot retinochoroiditis, localized the subretinal neovascular membrane and correlated anatomic and vascular leakage features in myopia, and showed the extent of retinal and pigment epithelial detachment in retinal angiomatous proliferation as FA leakage was subject to blocked fluorescence. The overlay mode provided additional insight not readily available in either mode alone. Conclusion Combining conventional angiographic images and en-face OCT C-scans assists {{in the interpretation of}} both imaging modalities. By combining the physiopathological information in the angiograms with the structural information in the OCT scan, zones of leakage can be correlated to structural changes in the retina or pigment epithelium. This strategy could be used in the evaluation and monitoring of patients with complex central macular pathology. </p...|$|E
5000|$|Image Derivations: derived {{images are}} {{generated}} during run-time based on descriptions such as rotation, grid and <b>overlay.</b> These <b>images</b> depend on other images {{stored in the}} HEIF file. The storage overhead of derived images is small.|$|R
40|$|Image {{registration}} {{is an important}} step in all image analysis and it performs the operation of <b>overlaying</b> <b>images</b> of the alike picture taken at various times, from various viewpoints, and/or by various sensors. The wavelet domain provides invariant that are centrally symmetric to blur. Blur invariants are constructed from different wavelet function. Template image is chosen in the degraded images using similarity the template image is matched with the original image. Using Daubuchies wavelet functions the images are accurately registered, even in the severely degraded images compared to the spatial domain blur invariants which may result in misfocus registration of an image. Key word...|$|R
40|$|The {{invention}} {{relates to}} a system (10) for displaying at least one virtual object comprising a secondary screen (20) for displaying the virtual object, a primary screen (30), an optical means for <b>overlaying</b> <b>images</b> displayed on the secondary screen (20) with images displayed on the primary screen (30), and a pointing surface combined with the primary screen (30) for detecting the contact {{of one or more}} physical pointing elements. A device (90) for manipulating at least one virtual object comprises calculation means for generating images of the virtual object displayed on the system (10) from information output from the system (10) in accordance with the actions of the operator (100) ...|$|R
