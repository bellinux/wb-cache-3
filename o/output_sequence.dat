407|688|Public
25|$|The {{output stream}} is reversible; an LFSR with {{mirrored}} taps will cycle through the <b>output</b> <b>sequence</b> in reverse order.|$|E
25|$|Sequencers', or generators, are a {{subclass}} of the acceptor and transducer {{types that}} have a single-letter input alphabet. They produce only one sequence which {{can be seen as}} an <b>output</b> <b>sequence</b> of acceptor or tranducer outputs.|$|E
25|$|A Macro is a rule {{of pattern}} that {{specifies}} how a certain input sequence (often a sequence of characters) should be mapped to an <b>output</b> <b>sequence</b> according to defined process. Frequently used or repetitive sequences of keystrokes and mouse movements can be automated.|$|E
40|$|A {{new class}} of linear {{sequence}} generators based on cellular automata is here introduced in order to model several nonlinear keystream generators with practical applications in symmetric cryptography. The <b>output</b> <b>sequences</b> are written as solutions of linear difference equations, and three basic properties (period, linear complexity and number of different <b>output</b> <b>sequences)</b> are analyzed...|$|R
30|$|The function, {{input and}} <b>output</b> <b>sequences,</b> and {{internal}} {{operations of the}} system are discussed as follows.|$|R
40|$|Feedback shift registers(FSRs) are a {{fundamental}} component in electronics and secure communication. An FSR $f$ {{is said to}} be reducible if all the <b>output</b> <b>sequences</b> of another FSR $g$ can also be generated by $f$ and the FSR $g$ has less memory than $f$. An FSR {{is said to be}} decomposable if it has the same set of <b>output</b> <b>sequences</b> as a cascade connection of two FSRs. It is proved that deciding whether FSRs are irreducible/indecomposable is NP-hard. Comment: 23 pages, 10 figure...|$|R
25|$|In {{the field}} of {{pseudorandom}} number generation, a candidate generator of undetermined quality whose <b>output</b> <b>sequence</b> lies too far outside the typical set by some statistical criteria is rejected as insufficiently random. Thus, although the typical set is loosely defined, practical notions arise concerning sufficient typicality.|$|E
500|$|Cascades of strand {{displacement}} reactions can be {{used for}} either computational or structural purposes. [...] An individual strand displacement reaction involves revealing a new sequence in response to the presence of some initiator strand. [...] Many such reactions can be linked into a cascade where the newly revealed <b>output</b> <b>sequence</b> of one reaction can initiate another strand displacement reaction elsewhere. [...] This in turn allows for the construction of chemical reaction networks with many components, exhibiting complex computational and information processing abilities. [...] These cascades are made energetically favorable through the formation of new base pairs, and the entropy gain from disassembly reactions. Strand displacement cascades allow isothermal operation of the assembly or computational process, in contrast to traditional nucleic acid assembly's requirement for a thermal annealing step, where the temperature is raised and then slowly lowered to ensure proper formation of the desired structure. They can also support catalytic function of the initiator species, where less than one equivalent of the initiator can cause the reaction to go to completion.|$|E
2500|$|When either {{sequence}} {{contains a}} string of zeros, of length L, L+1 of the circular convolution outputs are equivalent to values of [...] Methods have also been developed to use this property {{as part of an}} efficient process that constructs [...] with an [...] or [...] sequence potentially much longer than the practical transform size (N). [...] Two such methods are called overlap-save and overlap-add. [...] The efficiency results from the fact that a direct evaluation of either summation (above) requires [...] operations for an <b>output</b> <b>sequence</b> of length N. An indirect method, using transforms, {{can take advantage of the}} [...] efficiency of the fast Fourier transform (FFT) to achieve much better performance. [...] Furthermore, convolutions can be used to efficiently compute DFTs via Rader's FFT algorithm and Bluestein's FFT algorithm.|$|E
3000|$|In a usual way, the {{behavior}} relation is extended to input <b>sequences</b> I* and <b>output</b> <b>sequences</b> O*. Given states s, s′ ∈ S, an input sequence α[*]=[*]i [...]...|$|R
5000|$|Distinguishable {{states are}} {{states in a}} state machine that {{have at least one}} input <b>sequence</b> causing {{different}} <b>output</b> <b>sequences</b> - no matter which state is the initial state.|$|R
40|$|The output distribution, when rate {{is above}} capacity, is investigated. It is shown {{that there is}} an {{asymptotic}} equipartition property (AEP) of the typical <b>output</b> <b>sequences,</b> independently of the specific codebook used, as long as the codebook is typical according to the standard random codebook generation. This equipartition of the typical <b>output</b> <b>sequences</b> is caused by the mixup of input sequences when there are too many of them, namely, when the rate is above capacity. This discovery sheds some light on the optimal design of the compress-and-forward relay schemes. I...|$|R
50|$|Add v {{to the end}} of the <b>output</b> <b>sequence.</b>|$|E
50|$|Initialize the <b>output</b> <b>sequence</b> of {{vertices}} to be empty.|$|E
5000|$|For some of {{the above}} problems, {{it may also be}} {{interesting}} to ask about statistical significance. What is the probability that a sequence drawn from some null distribution will have an HMM probability (in the case of the forward algorithm) or a maximum state sequence probability (in the case of the Viterbi algorithm) at least as large as that of a particular <b>output</b> <b>sequence?</b> [...] When an HMM is used to evaluate the relevance of a hypothesis for a particular <b>output</b> <b>sequence,</b> the statistical significance indicates the false positive rate associated with failing to reject the hypothesis for the <b>output</b> <b>sequence.</b>|$|E
3000|$|... [...]. The set out(s, α) {{denotes the}} set of all <b>output</b> <b>sequences</b> ({{response}}s) that the FSM S can produce at state s {{in response to a}} defined input sequence α, i.e. out [...]...|$|R
40|$|Feedback Shift Register (FSR) {{sequences}} {{have been}} successfully implemented in many communication systems for their randomness properties and ease of implementation. These include ranging and navigation systems, spread spectrum communication systems, CDMA mobile communication systems, and crypto systems such as streamciphers. This article gives {{a brief overview of}} FSR sequences, both linear and non-linear. Two conditions on the connection logic of FSRs for better <b>output</b> <b>sequences</b> are described, which are the branchless condition and the balanced logic condition. We use mostly the state transition diagram of an FSR to describe the property of its <b>output</b> <b>sequences.</b> For linear FSR sequences, we describe the relation between the connection polynomials and the structure of the cycle decomposition in the state diagram, and hence the periodicity of the <b>output</b> <b>sequences.</b> Various randomness properties of the maximal length linear FSR sequences, known as m-sequences, are described: balance, run-distribution, span, ideal autocorrelation, constant-on-the-coset, and cycle-and-add properties. Two properties, the ideal autocorrelation function and the smallest linear complexity, of m-sequences are described in detail. Finally, a complete analysis of 4 -stage FSRs is provided...|$|R
3000|$|Remark 4.3 The {{subsequent}} equations {{describe the}} identification process when the identified process is linear in the parameters {{as well as}} the estimation parallel process. Thus, the measured output and estimated <b>output</b> <b>sequences,</b> respectively, [...]...|$|R
5000|$|... and the <b>output</b> <b>sequence</b> of xs, (the {{rightmost}} register), has period 4: ...|$|E
5000|$|For {{the special}} {{case of the}} Kronecker delta function, [...] the <b>output</b> <b>sequence</b> is the impulse response: ...|$|E
5000|$|The {{output stream}} is reversible; an LFSR with {{mirrored}} taps will cycle through the <b>output</b> <b>sequence</b> in reverse order.|$|E
40|$|Dimirovski, Georgi M. (Dogus Author) This paper {{introduces}} {{an extended}} {{environment for the}} unscented Kalman filtering that considers also the presence of additive noise on input observations in order {{to solve the problem}} of optimal estimation of noise-corrupted input and <b>output</b> <b>sequences.</b> This environment includes as sub-cases both errors-in-variables filtering and unscented Kalman filtering. The unscented Kalman filtering to the presence of additive noise on input observations is considered, and is used {{to solve the problem of}} optimal estimation of noise-corrupted input and <b>output</b> <b>sequences.</b> A Monte Carlo simulation shows that the performance of the unscented Kalman filtering technique leads to the expected minimal variance estimates...|$|R
40|$|Necessary and {{sufficient}} conditions for strict stationarity and invertibility are found for one-parameter bilinear models. These conditions involve {{the expectations of}} the logarithms of the absolute values of the input and <b>output</b> <b>sequences.</b> Time series invertibility strict stationarity ergodic bilinear model...|$|R
40|$|In {{this paper}} {{we show that}} the <b>output</b> <b>sequences</b> of the {{generalized}} self-shrinking generator are particular solutions of a binary homogeneous linear difference equation. In fact, all these sequences are just linear combinations of primary sequences weighted by binary coefficients. We show {{that in addition to}} the <b>output</b> <b>sequences</b> of the generalized selfshrinking generator, the complete class of solutions of the corresponding binary homogeneous linear difference equation also includes other balanced sequences that are very suitable for cryptographic applications, as they have the same period and even greater linear complexity than the generalized self-shrinking sequences. Cryptographic parameters of all the above mentioned sequences can be analyzed in terms of linear equation solutions...|$|R
5000|$|The {{first stage}} calculates an {{intermediate}} sequence, :The second stage applies the following filter to , producing <b>output</b> <b>sequence</b> : ...|$|E
5000|$|FCSRs are {{analyzed}} using number theory. Associated with the FCSR {{is a connection}} integer [...] Associated with the <b>output</b> <b>sequence</b> is the N-adic number [...] The fundamental theorem of FCSRs says {{that there is an}} integer [...] so that , a rational number. The <b>output</b> <b>sequence</b> is strictly periodic if and only if [...] is between [...] and [...] It is possible to express u as a simple quadratic polynomial involving the initial state and the qi.|$|E
50|$|Applying a Ghost Leg {{a finite}} number of times to an input {{sequence}} eventually generates an <b>output</b> <b>sequence</b> identical to the original input sequence.|$|E
50|$|Yongge Wang {{has shown}} that the law of the {{iterated}} logarithm holds for polynomial time pseudorandom sequences also. Furthermore, the Java based software testing tool statistical testing techniques for pseudorandom generation is available for testing whether a randomness generator <b>outputs</b> <b>sequences</b> that satisfy the LIL.|$|R
40|$|This {{application}} note describes the difference equations for discrete-time, time-invariant linear systems {{and how to}} use LabVIEW block diagrams to implement these equations. This {{application note}} also discusses the Z transform, signal flow graphs, discrete input and <b>output</b> <b>sequences,</b> and an example that models a simple...|$|R
30|$|Generally, {{attacker}} {{may make}} a slight change in the plaintext. In order to test the influence of changing a single bit in the original data, the correlation coefficients between the corresponding <b>output</b> <b>sequences</b> were calculated for {{the changes in the}} input sequence. As expected, the correlation coefficients were very small.|$|R
5000|$|There {{is also an}} {{exponential}} {{representation of}} FCSRs: if [...] is the inverse of , and the <b>output</b> <b>sequence</b> is strictly periodic, then , where [...] is an integer. It follows that the period is at most the order of N in the multiplicative group of units modulo q. This is maximized when q is prime and N is a primitive element modulo q. In this case, the period is [...] In this case the <b>output</b> <b>sequence</b> is called an l-sequence (for [...] "long sequence").|$|E
5000|$|For {{a causal}} discrete-time FIR filter of order N, each {{value of the}} <b>output</b> <b>sequence</b> is a {{weighted}} sum {{of the most recent}} input values: ...|$|E
50|$|The real {{part of the}} <b>output</b> <b>sequence</b> is the {{original}} input sequence, so that the complex output is an analytic representation of un. When the input is a segment of a pure cosine, the resulting convolution for two different values of N is depicted in Figure 4 (red and blue plots). Edge effects prevent the result from being a pure sine function (green plot). Since hNn is not an FIR sequence, the theoretical extent of the effects is the entire <b>output</b> <b>sequence.</b> But the differences from a sine function diminish with distance from the edges. Parameter N is the <b>output</b> <b>sequence</b> length. If it exceeds {{the length of the}} input sequence, the input is modified by appending zero-valued elements. In most cases, that reduces the magnitude of the differences. But their duration is dominated by the inherent rise and fall times of the hn impulse response.|$|E
40|$|We {{consider}} {{the problem of}} learning nondeterministic finite state machines (NFSMs) from systems where their internal structures are implicit and nondeterministic. Recently, an algorithm for inferring observable NFSMs (ONFSMs), which are the potentially learnable subclass of NFSMs, has been proposed based on {{the hypothesis that the}} complete testing assumption is satisfied. According to this assumption, with an input sequence (query), the complete set of all possible <b>output</b> <b>sequences</b> is given by the so-called Teacher, so the number of times for asking the same query is not taken into account in the algorithm. In this paper, we propose LNM*, a refined ONFSM learning algorithm that considers the amount for repeating the same query as one parameter. Unlike the previous work, our approach does not require all possible <b>output</b> <b>sequences</b> in one answer. Instead, it tries to observe the possible <b>output</b> <b>sequences</b> by asking the same query many times to the Teacher. We have proved that LNM* can infer the corresponding ONFSMs of the unknown systems when the number of tries for the same query is adequate to guarantee the complete testing assumption. Moreover, the proof shows that our algorithm will eventually terminate no matter whether the assumption is fulfilled or not. We also present the theoretical time complexity analysis of LNM*. In addition, experimental results demonstrate the practical efficiency of our approach...|$|R
5000|$|<b>Output</b> the <b>sequence</b> (Qn+1(x),..., Qkn(x)) of (k-1)n GF(q) {{keystream}} values ...|$|R
40|$|Abstract — In this paper, {{a mapping}} between initial {{states of the}} Fibonacci and the Galois {{configurations}} of NLFSRs is established. We show how to choose initial states for two configurations so that the resulting <b>output</b> <b>sequences</b> are equivalent. Index Terms — Fibonacci NLFSR, Galois NLFSR, initial state, pseudo-random sequence, stream cipher...|$|R
