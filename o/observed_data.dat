10000|10000|Public
5|$|Economists {{incorporated}} the theoretical {{work from the}} synthesis into large-scale macroeconometric models that combined individual equations for factors such as consumption, investment, and money demand with empirically <b>observed</b> <b>data.</b> This line of research reached its height with the MIT-Penn-Social Science Research Council (MPS) model developed by Modigliani and his collaborators. MPS combined IS/LM with {{other aspects of the}} synthesis including the neoclassical growth model and the Phillips curve relation between inflation and output. Both large-scale models and the Phillips curve became targets for critics of the synthesis.|$|E
5|$|The DCIEM 1983 {{decompression}} {{model is}} a decompression calculation model rather than a physiological model. Modifications {{were made to the}} model to get it to fit <b>observed</b> <b>data,</b> as the original model had several observed shortcomings, while retaining the basic model structure so that it could be applied to existing hardware with minimal modifications.|$|E
5|$|The concept {{underlying}} {{the method is}} based on the probability integral transform, in that a set of independent random samples derived from any random variable should on average be uniformly distributed with respect to the cumulative distribution function of the random variable. The MPS method chooses the parameter values that make the <b>observed</b> <b>data</b> as uniform as possible, according to a specific quantitative measure of uniformity.|$|E
30|$|Provenance {{confidentiality}} {{requires that}} from <b>observing</b> <b>data</b> packets and their associated provenance, it is computationally infeasible for attackers to gain information about nodes and their topology in the provenance.|$|R
50|$|The ESIP Federation’s partner {{organizations}} {{include all}} NOAA, NASA and USGS Earth <b>observing</b> <b>data</b> centers, government research laboratories, research universities, modelers, education resource providers, technology developers, nonprofits and commercial enterprises.|$|R
40|$|In {{the ocean}} {{dynamical}} environment real-time observing system of Taiwan Strait and adjacent maritime region, multiple <b>observing</b> <b>data</b> such as remote sensing data, structured data {{and so on}} are produced by the observing net from airspace, ocean surface, underwater space and ocean bottom. The data sharing and web service is a key part to influence the application efficiency of the whole system. According to {{the characteristics of the}} oceanic dynamical environment of Taiwan Strait, the construction scheme of the observing net is introduced in this paper firstly. Then the architecture of the <b>observing</b> <b>data</b> sharing and web service system is introduced, which includes four parts, i. e. the <b>observing</b> <b>data</b> acquiring module, the data integration module, the data processing and information production development module, the data sharing and web service module. Next, the user classification system and service content classification are introduced. The users are divided into five classes and the service content is divided into 4 layers. At last, the technology realization strategy and application in shipwreck salvation decision-making support system is introduced...|$|R
5|$|Models are {{initialized}} {{using this}} <b>observed</b> <b>data.</b> The irregularly spaced observations are processed by data assimilation and objective analysis methods, which perform quality control and obtain values at locations usable by the model's mathematical algorithms (usually an evenly spaced grid). The data are then {{used in the}} model {{as the starting point}} for a forecast. Commonly, the set of equations used to predict the known as the physics and dynamics of the atmosphere are called primitive equations. These equations are initialized from the analysis data and rates of change are determined. The rates of change predict the state of the atmosphere a short time into the future. The equations are then applied to this new atmospheric state to find new rates of change, and these new rates of change predict the atmosphere at a yet further time into the future. This time stepping procedure is continually repeated until the solution reaches the desired forecast time. The length of the time step is related to the distance between the points on the computational grid.|$|E
25|$|Epicurus {{emphasised}} {{the senses}} in his epistemology, and his Principle of Multiple Explanations ("if several theories {{are consistent with}} the <b>observed</b> <b>data,</b> retain them all") is an early contribution to the philosophy of science.|$|E
25|$|A {{more fully}} Bayesian {{approach}} to parameters {{is to treat}} parameters as additional unobserved variables and to compute a full posterior distribution over all nodes conditional upon <b>observed</b> <b>data,</b> then to integrate out the parameters. This approach can be expensive and lead to large dimension models, so in practice classical parameter-setting approaches are more common.|$|E
40|$|Respiratory {{diseases}} such as asthma can be triggered by environmental conditions that can be monitored using Earth <b>observing</b> <b>data</b> and environmental forecast models. Frequent dust storms in the southwestern United States, the annual cycle of juniper pollen events in the spring, and increased aerosol and ozone concentrations in summer, are health concerns shared by the community at large. Being able to forecast the occurrence of these events would help the health care community prepare for increased visits to emergency rooms, as well as allow public health officials to issue alerts to affected persons. This information also is important to epidemiologists for analyzing long-term trends and impacts of these events on {{the health and well-being}} of the community. Earth <b>observing</b> <b>data</b> collected by remote sensing platforms are important for improving the performance of models that can forecast these events, and in turn, improve products and information for decision-making by public health authorities. This presentation will discuss the benefits of using remote sensing data for forecasting environmental events that can adversely affect individuals with respiratory ailments. The presentations will include a brief discussion on relevant Earth <b>observing</b> <b>data,</b> the forecast models used, and societal benefits of the resulting products and information. Several NASA-funded projects will be highlighted as example...|$|R
30|$|Check if the <b>observed</b> stress <b>data</b> {{satisfy the}} elastic invariants.|$|R
50|$|The Israel Space Agency - Middle East Interactive Data Archive (ISA-MEIDA) is an Israeli node for NASA's EOSDIS (Earth <b>Observing</b> System <b>Data</b> and Information System). The Node was {{established}} in October 1996 {{as a part of}} the cooperation agreement between the director of NASA and the director of ISA. It is the only team in the country which focuses on collecting and preserving environmental information in Israel. The ISA-MEIDA {{was established}} in order to create and maintain an Earth <b>observing</b> <b>data</b> center available through the Internet to the research community and to the general public free of charge.|$|R
25|$|To perform {{stress testing}} and {{scenario}} analysis, the <b>observed</b> <b>data</b> {{needs to be}} altered, e.g. some payments delayed or removed. To analyze the levels of liquidity, initial liquidity levels are varied. System comparisons (benchmarking) or evaluations of new netting algorithms or rules are performed by running simulations with a fixed set of data and varying only the system setups.|$|E
25|$|This {{contrasts}} with the Bayesian approach, which requires that the hypothesis be assigned a prior probability, which is revised {{in the light of}} the <b>observed</b> <b>data</b> to obtain the final probability of the hypothesis. Within the Bayesian framework there is no risk of error since hypotheses are not accepted or rejected; instead they are assigned probabilities.|$|E
25|$|This {{study is}} now disputed {{on the basis}} of simple coding errors and biased sampling. This study also {{supports}} a continuing increase in both theoretical and observed upper human lifespan, based on <b>observed</b> <b>data</b> from 200 national populations. However, a theoretical study also suggested that the maximum human life expectancy at birth is limited by the human life characteristic value δ, which is around 104 years.|$|E
40|$|Abstract: Global {{change has}} been a focus issue all over the world. How to use {{technology}} methods to get and <b>observe</b> real time <b>data</b> of different level of the earth {{is the basis of}} the global change research. In this paper, we put forward to construct a satellite-airborne-ground (SAG) observation experiment platform which integrated satellite data, airborne data and ground or ocean <b>observing</b> <b>data</b> together. The SAG has been used in Tibet Plateau and Bohai sea experiments area to get the sensitive factors for global change...|$|R
5000|$|... Software {{to fit a}} Lotka {{power law}} {{distribution}} to <b>observed</b> frequency <b>data.</b>|$|R
5000|$|... 2003 Evaluation {{of surface}} winds and waves from {{voluntary}} <b>observing</b> ship <b>data.</b>|$|R
25|$|If {{the goal}} is prediction, or forecasting, or error reduction, linear {{regression}} {{can be used to}} fit a predictive model to an <b>observed</b> <b>data</b> set of y and X values. After developing such a model, if an additional value of X is then given without its accompanying value of y, the fitted model {{can be used to make}} a prediction of the value of y.|$|E
25|$|Oscillations in {{the light}} {{intensity}} and in the oxygen and nitrogen emission at a frequency of 100 hertz, possibly caused by the electromagnetic field of the 50Hz high-voltage power transmission line in the vicinity, were observed. From the spectrum, {{the temperature of the}} ball lightning was assessed as being lower than the temperature of the parent lightning (<). The <b>observed</b> <b>data</b> are consistent with vaporization of soil as well as with ball lightning's sensitivity to electric fields.|$|E
25|$|In the United States, an {{integrated}} approach to real-time hydrologic computer modelling utilizes <b>observed</b> <b>data</b> from the U.S. Geological Survey (USGS), various cooperative observing networks, various automated weather sensors, the NOAA National Operational Hydrologic Remote Sensing Center (NOHRSC), various hydroelectric companies, etc. combined with quantitative precipitation forecasts (QPF) of expected rainfall and/or snow melt to generate daily or as-needed hydrologic forecasts. The NWS also cooperates with Environment Canada on hydrologic forecasts that affect both the USA and Canada, {{like in the}} area of the Saint Lawrence Seaway.|$|E
40|$|Bayes {{rule for}} models A prior {{distribution}} over model space p(m) (or ‘hypothesis space’) can be updated to a posterior distribution after <b>observing</b> <b>data</b> y. This is implemented using Bayes rule p(m|y) = p(y |m) p(m) p(y) where p(y |m) {{is referred to}} as the evidence for model m and the denominator is given by p(y) = m...|$|R
40|$|For {{family therapy}} {{students}} and practitioners, this book offers stories, exercises, self-assessments, and evaluative techniques. Designed for family therapists, this book offers stories, exercises, self-assessments and evaluative techniques to improve observational skills, enhance clinical work and encourage meaningful research. The authors discuss {{their views on}} hearing stories, <b>observing</b> <b>data</b> and analyzing speech, creating an engaging and learning experience. [URL]...|$|R
5000|$|Also {{define a}} loss {{function}} , which specifies the loss we would incur by taking action [...] when the true {{state of nature}} is [...] Usually we will take this action after <b>observing</b> <b>data</b> , so that the loss will be [...] (It is possible though unconventional to recast the following definitions {{in terms of a}} utility function, which is the negative of the loss.) ...|$|R
25|$|As an {{alternative}} to probabilistic methods, heuristic methods exist for performing variant calling on NGS data. Instead of modelling {{the distribution of the}} <b>observed</b> <b>data</b> and using Bayesian statistics to calculate genotype probabilities, variant calls are made based on a variety of heuristic factors, such as minimum allele counts, read quality cut-offs, bounds on read depth, etc. Although they have been relatively unpopular in practice in comparison to probabilistic methods, in practice due to their use of bounds and cut-offs they can be robust to outlying data that violate the assumptions of probabilistic models.|$|E
25|$|Often these {{conditional}} distributions include parameters {{which are}} unknown {{and must be}} estimated from data, sometimes using the maximum likelihood approach. Direct maximization of the likelihood (or of the posterior probability) is often complex when there are unobserved variables. A classical approach to this problem is the expectation-maximization algorithm which alternates computing expected values of the unobserved variables conditional on <b>observed</b> <b>data,</b> with maximizing the complete likelihood (or posterior) assuming that previously computed expected values are correct. Under mild regularity conditions this process converges on maximum likelihood (or maximum posterior) values for parameters.|$|E
25|$|Another {{class of}} methods assesses whether the {{inference}} {{was successful in}} light of the given <b>observed</b> <b>data,</b> for example, by comparing the posterior predictive distribution of summary statistics to the summary statistics observed. Beyond that, cross-validation techniques and predictive checks represent promising future strategies to evaluate the stability and out-of-sample predictive validity of ABC inferences. This is particularly important when modeling large data sets, because then the posterior support of a particular model can appear overwhelmingly conclusive, even if all proposed models in fact are poor representations of the stochastic system underlying the observation data. Out-of-sample predictive checks can reveal potential systematic biases within a model and provide clues on to how to improve its structure or parametrization.|$|E
5000|$|Furthermore, the {{adjusted}} variance of the variable [...] after <b>observing</b> the <b>data</b> [...] {{is given by}} ...|$|R
50|$|A puzzle in {{economics}} {{is a situation}} where the implication of theory is inconsistent with <b>observed</b> economic <b>data.</b>|$|R
5000|$|Earth <b>Observing</b> System <b>Data</b> and Information System (EOSDIS) - {{provides}} end-to-end capabilities {{for managing}} NASA’s Earth science data ...|$|R
25|$|In modern terms, {{the problem}} is an inverse problem, an attempt to deduce the {{parameters}} of a mathematical model from <b>observed</b> <b>data.</b> Though {{the problem is}} a simple one for modern mathematics after the advent of electronic computers, at the time it involved much laborious hand calculation. Adams began by assuming a nominal position for the hypothesised body, using the empirical Bode's law. He then calculated the path of Uranus using the assumed position of the perturbing body and calculated the difference between his calculated path and the observations, in modern terms the residuals. He then adjusted the characteristics of the perturbing body in a way suggested by the residuals and repeated the process, a process similar to regression analysis.|$|E
25|$|A {{number of}} {{heuristic}} {{approaches to the}} quality control of ABC have been proposed, such as the quantification of the fraction of parameter variance explained by the summary statistics. A common class of methods aims at assessing {{whether or not the}} inference yields valid results, regardless of the actually <b>observed</b> <b>data.</b> For instance, given a set of parameter values, which are typically drawn from the prior or the posterior distributions for a model, one can generate a large number of artificial datasets. In this way, the quality and robustness of ABC inference can be assessed in a controlled setting, by gauging how well the chosen ABC inference method recovers the true parameter values, and also models if multiple structurally different models are considered simultaneously.|$|E
25|$|During the 1950s, {{the site}} housed a {{research}} group that used radar to scan approaching thunder storms {{as far away}} as western New York State, as part of an inquiry into the causes of lightning. Findings by this group were instrumental {{in the development of the}} US weather radar program. The installation consisted of a steel tower supporting a second-hand military radar set, several Quonset huts and box trailers, surrounded by a chain-link fence. Group members were on call to monitor the radar whenever severe storms could be <b>observed.</b> <b>Data</b> were also collected from a network of amateur co-operative observers who corresponded by mail. This era coincided with the end of the long career of the famous Director of the Observatory, Dr. Charles Brooks, said to be one of the few who accurately forecast the path of the destructive Hurricane of September, 1938.|$|E
30|$|To <b>observe</b> <b>data</b> {{discrepancies}} {{resulted from}} coal mining activities, the time-lapse data acquisition requires data acquired in different time periods must have repeatability and the non-repetitive part should be variations resulted from mining, therefore, acquisition environment, acquisition equipment and parameters must be ensured to be repetitive when acquisition is being carried out. Based on this condition, {{the reliability of}} acquired data is guaranteed through choosing appropriate acquisition parameters and survey geometry.|$|R
30|$|The EB method can {{be applied}} at the site-level if the {{available}} <b>observed</b> accident <b>data</b> can be precisely located.|$|R
3000|$|... adaptively {{so as to}} maximally whiten the <b>observed</b> {{interference}} <b>data</b> {{is provided}} in [9]. Recently, new approaches for selecting [...]...|$|R
