9765|1117|Public
25|$|Examples of {{applications}} include blob detection, corner detection, ridge detection, and <b>object</b> <b>recognition</b> via the scale-invariant feature transform.|$|E
25|$|In 1992, max-pooling was {{introduced}} to help with least shift invariance and tolerance to deformation to aid in 3D <b>object</b> <b>recognition.</b>|$|E
25|$|Microsoft notes {{four main}} {{components}} being {{important in the}} PixelSense interface: direct interaction, multi-touch contact, a multi-user experience, and <b>object</b> <b>recognition.</b>|$|E
40|$|This paper {{describes}} a new human-computer interaction, which through {{a simple and}} low-cost hardware (webcam), captures images and performs the color <b>objects</b> <b>recognition</b> or hand recognition from informations of color and shapes, making possible the control of applications in the operational system graphical user interface...|$|R
40|$|In {{this work}} we {{consider}} development of IR-based communication and perception mechanisms for real microrobotic systems. It is demonstrated that a specific combination of {{hardware and software}} elements provides capabilities for navigation, <b>objects</b> <b>recognition,</b> directional and unidirec-tional communication. We discuss open issues and their resolution based on the experiments in the swarm of microrobots ”Jasmine”. ...|$|R
30|$|This {{issue of}} the EURASIP Journal on Advances in Signal Processing {{constitutes}} the special issue related with Image Processing and Analysis applied to biomechanical systems, including data compression, data fusion, image segmentation, image registration, <b>objects</b> <b>recognition,</b> <b>objects</b> modeling, tracking and motion analysis, shape reconstruction, 3 D vision, and virtual reality. One important feature to retainment of this special issue is the interdisciplinary of works resulting from the collaboration between mechanical engineers, electrical engineers, biomedical engineers, medical doctors, computational engineers, biologists, physicians, mathematicians, among others.|$|R
25|$|Sub-domains of {{computer}} vision include scene reconstruction, event detection, video tracking, <b>object</b> <b>recognition,</b> 3D pose estimation, learning, indexing, motion estimation, and image restoration.|$|E
25|$|<b>Object</b> <b>recognition</b> (also called object classification)one {{or several}} pre-specified or learned objects or object classes can be recognized, usually {{together}} with their 2D positions in the image or 3D poses in the scene. Blippar, Google Goggles and LikeThat provide stand-alone programs that illustrate this functionality.|$|E
25|$|Machine {{perception}} {{is the ability}} to use input from sensors (such as cameras, microphones, tactile sensors, sonar and others) to deduce aspects of the world. Computer vision {{is the ability to}} analyze visual input. A few selected subproblems are speech recognition, facial recognition and <b>object</b> <b>recognition.</b>|$|E
40|$|The Augmented Virtual Studio (AVS) project aims at {{acquiring}} {{the tools of}} video analysis and visualization needed to achieve advanced interfaces or interaction with virtual avatars and virtual worlds. Those techniques consist in data visualization, object segmentation, tracking and identification of blobs but also sketch recognition and more generally faces and <b>objects</b> <b>recognition.</b> All these tools were used to build three practical applications...|$|R
5000|$|Best Paper: <b>Object</b> Class <b>Recognition</b> by Unsupervised Scale-Invariant Learning, Rob Fergus, Pietro Perona, and Andrew Zisserman ...|$|R
40|$|International audience—The Hough {{transform}} is {{a robust}} algorithm used in shapes and <b>objects</b> <b>recognition</b> and it proves {{a high quality}} of results. This algorithm is also known for its use of large computing power. This paper presents a dedicated accumulator cache to optimize Hough space access. We explored the design space by evaluating the locality of accesses and found up to a speedup of 30 with a 2 -line cache...|$|R
25|$|HSL, HSV, HSI, {{or related}} models {{are often used}} in {{computer}} vision and image analysis for feature detection or image segmentation. The applications of such tools include object detection, for instance in robot vision; <b>object</b> <b>recognition,</b> for instance of faces, text, or license plates; content-based image retrieval; and analysis of medical images.|$|E
25|$|Application areas include system {{identification}} and control (vehicle control, trajectory prediction, process control, natural resources management), quantum chemistry, game-playing {{and decision making}} (backgammon, chess, poker), pattern recognition (radar systems, face identification, signal classification, <b>object</b> <b>recognition</b> and more), sequence recognition (gesture, speech, handwritten text recognition), medical diagnosis, finance (e.g. automated trading systems), data mining, visualization, machine translation, social network filtering and e-mail spam filtering.|$|E
25|$|In humans, areas {{specialized}} {{for visual}} <b>object</b> <b>recognition</b> in the ventral stream {{have a more}} inferior location in the temporal cortex, whereas areas specialized for the visual-spatial location of objects in the dorsal stream have a more superior location in the parietal cortex. However, these two streams hypothesis, although useful, are a simplification of the visual system because the two streams maintain intercommunication along their entire rostral course.|$|E
40|$|Method of <b>objects</b> <b>recognition</b> on dynamic {{background}} is researched in given work. Stochastic, linear and nonlinear prediction models {{are used for}} modelling of dynamic background as a signal that is changed in time and space. The best quality of object definition is received with help of simplified nonlinear model as a sum of linear and quadratic signal components. Influences of model order, supporting area size and threshold value on the signal object selection are researched...|$|R
40|$|Many robot {{perception}} {{systems are}} built to only consider intrinsic object features to recognise {{the class of}} an object. By integrating both top-down spatial relational reasoning and bottom-up <b>object</b> class <b>recognition</b> the overall performance of a perception system can be improved. In this paper we present a unified framework that combines a 3 D <b>object</b> class <b>recognition</b> system with learned, spatial models of object relations. In robot experiments we show that our combined approach improves the classification results on real world office desks compared to pure bottom-up perception. Hence, by using spatial knowledge during <b>object</b> class <b>recognition</b> perception becomes more efficient and robust and robots can understand scenes more effectively. QC 20141205 StrandsEuropean Union Seventh Framework Programme (FP 7 / 2007 - 2013) under grant agreement No 60062...|$|R
40|$|Behavior-based {{navigation}} {{of autonomous}} vehicles requires {{the recognition of}} the navigable areas and the potential obstacles. In this paper we describe a model-based <b>objects</b> <b>recognition</b> system which is part of an image interpretation system intended t o assist the nav-igation of autonomous vehicles navigation that operate in industrial environments. The recognition system integrates color, shape and texture information together with the location of the vanishing point. The recognition process starts from some prior scene knowledge, that is, a generic model of the expected scene and the potencial <b>objects.</b> The <b>recognition</b> system constitutes an approach where dif-ferent low-level vision techniques extract a multitude of image descriptors which are then analyzed using a rule-based reasoning system t o interpret the image content. This system has been implemented using a rule-based cooperative Expert System. ...|$|R
25|$|M-theory {{is based}} on a {{quantitative}} theory of the ventral stream of visual cortex. Understanding how visual cortex works in <b>object</b> <b>recognition</b> is still a challenging task for neuroscience. Humans and primates are able to memorize and recognize objects after seeing just couple of examples unlike any state-of-the art machine vision systems that usually require a lot of data in order to recognize objects. Prior to the use of visual neuroscience in computer vision has been limited to early vision for deriving stereo algorithms (e.g.,) and to justify the use of DoG (derivative-of-Gaussian) filters and more recently of Gabor filters. No real attention has been given to biologically plausible features of higher complexity. While mainstream computer vision has always been inspired and challenged by human vision, it seems to have never advanced past the very first stages of processing in the simple cells in V1 and V2. Although some of the systems inspired - to various degrees - by neuroscience, have been tested on at least some natural images, neurobiological models of <b>object</b> <b>recognition</b> in cortex have not yet been extended to deal with real-world image databases.|$|E
25|$|The ventral stream pathway {{is mainly}} {{involved}} in <b>object</b> <b>recognition,</b> {{and is known}} colloquially as the 'what' pathway. It has connections to the medial temporal lobe (which {{is involved in the}} storage of long-term memories), the limbic system (which regulates emotions), and the dorsal stream pathway (which is involved in the visual-spatial locations and motions of objects). Therefore, the ventral stream pathway not only deals with the recognition of objects in the external world, but also the emotional judgement and analysis of these objects.|$|E
25|$|They {{argue that}} the {{advantages}} of using hard AI problems {{as a means for}} security are twofold. Either the problem goes unsolved and there remains a reliable method for distinguishing humans from computers, or the problem is solved and a difficult AI problem is resolved along with it. In the case of image and text based CAPTCHAs, if an AI were capable of accurately completing the task without exploiting flaws in a particular CAPTCHA design, then it would have solved the problem of developing an AI that is capable of complex <b>object</b> <b>recognition</b> in scenes.|$|E
40|$|New {{approaches}} of object representation reliable for partially occluded <b>objects</b> <b>recognition</b> are introduced in this article. Objects {{are represented by}} their boundaries, which are deformed by the occlusion. The boundary representation was made by approximation with circle arcs. The representation {{was designed to be}} local and robust to occlusion. The curve approximation with circle arcs is equivalent to the curvature representation with respect to noise. The algorithm is simple and easy to implement. Experimental results are presented...|$|R
40|$|El presente trabajo se centra en {{resolver}} el problema relacionado con el reconocimiento de objetos en un entorno de cocina, describiendo cada objeto a partir de su color y volumetría. The {{problem of}} natural <b>objects</b> <b>recognition</b> with different {{shapes and colors}} is still an open one, objects can appear in different viewpoints, lighting, rotated, cluttered, occluded, [...] . making their recognition a difficult task. This work {{is part of an}} ongoing project to automate a robotic kitche...|$|R
40|$|Vision-based {{independent}} motion detection {{systems have}} attracted {{a lot of}} attention lately. Such sort of system could be used in on-board automotive assistance system to help driver prevent possible collisions with other independently moving objects (IMOs). In this paper we present a biologically inspired model of IMOs detection system. The proposed model, according to a widely accepted in neuroscience hypothesis, consists of two information-processing streams: "what" (crucial for <b>objects</b> <b>recognition)</b> and "where" (responsible for independent motion discrimination). status: publishe...|$|R
25|$|Two other {{well-known}} {{projects of}} the artist were developed {{in cooperation with the}} agency Jung von Matt/Next for tagged in motion and nextwall. For the project nextwall DAIM and other graffiti artists created a mural. Later interactive elements such as QR Codes and <b>object</b> <b>recognition</b> were inserted that allowed to transfer information to mobile devices. Tagged in motion meanwhile was an experiment to connect augmented reality and graffiti. With 3D- glasses it was possible for Mirko Reisser to spray his works into space and watch them three dimensionally. The video on YouTube achieved over 500.000 clicks within the first few days.|$|E
25|$|Direct {{interaction}} {{refers to}} the user's ability to simply {{reach out and touch}} the interface of an application in order to interact with it, without the need for a mouse or keyboard. Multi-touch contact {{refers to the}} ability to have multiple contact points with an interface, unlike with a mouse, where there is only one cursor. Multi-user experience is a benefit of multi-touch: several people can orient themselves on different sides of the surface to interact with an application simultaneously. <b>Object</b> <b>recognition</b> refers to the device's ability to recognize the presence and orientation of tagged objects placed on top of it.|$|E
25|$|Brain {{damage is}} {{another factor that}} {{has been found to}} have an effect on visual memory. Memory {{impairment}} affects both novel and familiar experiences. Poor memory after damage to the brain is usually considered to result from information being lost or rendered inaccessible. With such impairment it is assumed that it must be due to the incorrect interpretation of previously encountered information as being novel. In experiments testing rats’ <b>object</b> <b>recognition</b> memory it was found that memory impairment can be the opposite, that there was a tendency to treat novel experiences as familiar. A possible solution for this impairment could be the use of a visual-restriction procedure that reduces interference.|$|E
5000|$|Combining Generative Models and Fisher Kernels for <b>Object</b> Class <b>Recognition.</b> Holub, AD. Welling, M. Perona, P. International Conference on Computer Vision (ICCV), 2005 ...|$|R
40|$|One {{important}} source of information in scene understanding is given by actions performed either by human actors or robots. In this paper an approach to recognition and low-level interpretation of actions is presented. Since actions are characterized by specific motion patterns of moving <b>objects,</b> <b>recognition</b> is done by detecting such motion patterns as specific constellations of interactions between moving objects. First of all, motion detection and tracking algorithms are applied to extract correspondences between moving objects in consecutive images of a sequence...|$|R
40|$|Stanton, Mark E. Fetal Alcohol Spectrum Disorders (FASDs) are {{conditions}} with {{cognitive and behavioral}} impairments stemming from exposure to alcohol during pregnancy. Exposure during the brain growth spurt has detrimental effects on cognition including spatial memory (Dokovna, Jablonski, & Stanton, 2013; Jablonski & Stanton, 2014; Goodlett & Johnson, 1997; Goodlett & Pearson, 1995; Murawski & Stanton, 2010, 2011). A rat model of FASDs with third trimester-equivalent binge-like alcohol exposure was tested on an incidental spatial learning task, <b>object</b> location <b>recognition.</b> Limited exposure from postnatal (PD) 7 - 9 resulted in no impairment in the <b>object</b> location <b>recognition</b> task (Experiment 1). A wider exposure window (PD 4 - 9) resulted in deficits in <b>object</b> location <b>recognition</b> after both a short and long delay (Experiment 2). Different ethanol exposure windows may target different brain areas and/or processes underlying spatial incidental learning tasks. University of Delaware, Department of PsychologyM. S...|$|R
25|$|Through {{environmental}} enrichment, {{researchers were}} able to enhance and partially repair memory deficits in mice between ages of 2 to 7 months with characteristics of Alzheimer's disease. Mice in enriched environments performed significantly better on <b>object</b> <b>recognition</b> tests and the Morris Water Maze than they had {{when they were in}} standard environments. It was thus concluded that environmental enrichment enhances visual and learning memory for those with Alzheimer's. Furthermore, it has been found that mouse models of Alzheimer's disease that were exposed to enriched environment before amyloid onset (at 3 months of age) and then returned to their home cage for over 7 months, showed preserved spatial memory and reduced amyloid deposition at 13 months old, when they are supposed to show dramatic memory deficits and amyloid plaque load. These findings reveal the preventive, and long-lasting effects of early life stimulating experience on Alzheimer-like pathology in mice and likely reflect the capacity of enriched environment to efficiently stimulate the cognitive reserve.|$|E
500|$|Pinker's {{research}} on visual cognition, begun {{in collaboration with}} his thesis adviser, Stephen Kosslyn, showed that mental images represent scenes and objects as they appear from a specific vantage point (rather than capturing their intrinsic three-dimensional structure), and thus correspond to the neuroscientist David Marr's theory of a [...] "two-and-a-half-dimensional sketch." [...] He also showed that this level of representation is used in visual attention, and in <b>object</b> <b>recognition</b> (at least for asymmetrical shapes), contrary to Marr's theory that recognition uses viewpoint-independent representations.|$|E
2500|$|Cognitive {{psychology}} often conceptualizes {{this deficit}} as an impairment in the <b>object</b> <b>recognition</b> process. [...] Currently visual agnosias are commonly {{explained in terms}} of cognitive models of <b>object</b> <b>recognition</b> or identification. [...] The cognitive system for visual object identification is a hierarchal process, broken up into multiple steps of processing.|$|E
40|$|Abstract—The {{developed}} {{system was}} designed in three layers named respectively: vision, strategy and control. On this paper we {{will focus on}} vision and control layers because these have more technical features to explore. The main characteristics of the vision layer are the <b>objects</b> <b>recognition</b> based on color {{and the use of}} camshift algorithm to track objects. On the other hand, the characteristics of the control layer are the use of a ZigBee protocol-based communication device to send commands to the robots and the use of a non-linear controller to move them...|$|R
40|$|In {{this work}} we {{consider}} development of IR-based communication and perception mechanisms for real microrobotic systems. It is demonstrated that a specific combination of {{hardware and software}} elements provides capabilities for navigation, <b>objects</b> <b>recognition,</b> directional and unidirectional communication. We discuss open issues and their resolution based on the experiments in the swarm of microrobots "Jasmine". Comment: IROS 2005, WS on Task-oriented Mobile Actuator and Sensor Networks, Edmonton, Canada. Extended version appeared on the 7 th Workshop on Collective & Swarm Robotics, 18 November, University of Stuttgart, Germany, 201...|$|R
40|$|This paper {{presents}} an automatic approach for camera/image based detection, recognition and tracking of flying objects (planes, missiles, etc.). The method detects appearing objects, and recognizes re-appearing targets. It uses a feature-based statistical modeling approach (e. g. HMM) for motion-based recognition, and an image feature (e. g. shape) based indexed database of pre-trained object classes, suitable for recognition on known and alerting on unknown objects. The method {{can be used}} for detection of flying <b>objects,</b> <b>recognition</b> of the same object category through multiple views/cameras and signal on unusual motions and shape appearances...|$|R
