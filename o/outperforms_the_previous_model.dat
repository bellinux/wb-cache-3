3|10000|Public
40|$|We {{propose a}} novel model to {{simulate}} user knowledge consis- tency in tutoring dialogs, where no clear user goal can be de- fined. We also propose a new evaluation measure of knowledge consistency based on learning curves. We compare our new simulation model to real users {{as well as}} to a previously used simulation model. We show that the new model performs simi- larly to the real students and to the previous model when evalu- ated on high-level dialog features. The new model <b>outperforms</b> <b>the</b> <b>previous</b> <b>model</b> when measured on knowledge consistency. Index Terms: spoken dialog, user simulation, evaluation mea- sures, knowledge consistenc...|$|E
40|$|Title {{generation}} {{is a complex}} task involving both natural language understanding and natural language synthesis. In this paper, we propose a new probabilistic model for title generation. Different from the previous statistical models for title generation, which treat title generation as a generation process that converts the `document representation' of information directly into a `title representation' of the same information, this model introduces a hidden state called `information source' and divides title generation into two steps, namely the step of distilling the `information source' from the observation of a document and the step of generating a title from the estimated `information source'. In our experiment, the new probabilistic model <b>outperforms</b> <b>the</b> <b>previous</b> <b>model</b> for title generation {{in terms of both}} automatic evaluations and human judgments...|$|E
40|$|Lane-changing {{behavior}} is significantly affected by presence of exclusive lanes like high occupancy vehicle (HOV) lanes, value priced lanes, heavy vehicle lanes etc. The state-of-the-art driving behavior models {{often fail to}} capture the special types of lane-changes that occur in presence of exclusive lanes. This paper extends our previous research on developing a generalized lane-changing model and enhances it by introducing an exclusive lane-specific component in the model. The target lane-changing model is first estimated with disaggregate data collected from Interstate- 395, Virginia {{that does not have}} any exclusive lanes. The model is then augmented using aggregate data collected from Interstate- 80, California that has an HOV lane. The model is validated and compared with the existing lane-changing model within the microscopic traffic simulator MITSIMLab. Statistical comparisons of measures of performance indicate that the new model <b>outperforms</b> <b>the</b> <b>previous</b> <b>model.</b> The improvements in the modeling capability are further strengthened by independent validation within three commercial microscopic simulators VISSIM, AIMSUN and PARAMICS...|$|E
3000|$|... ▪ Overall, <b>the</b> {{proposed}} MN-HMC <b>outperforms</b> <b>the</b> <b>previous</b> <b>models.</b> In fact, <b>the</b> proposed model utilizes {{more than}} one observed signal while it {{takes into account the}} nonstationary aspect of the hidden process. It benefits on one hand, from the advantages of the contextual information through the use of Markov theory and, on the other hand, from the benefits of the theory of evidence that permits to consider uncertainty in hidden classes priors and data fusion in the same time.|$|R
40|$|Abstract — Hybrid back {{propagation}} based genetic algorithm {{approach is a}} popular way to train neural networks for weather prediction. The major drawback of this method is that weather parameters were assumed to be independent {{of each other and}} their temporal relation with one another was not considered. So in the present research a modified time series based weather prediction model is proposed to eliminate the problems incurred in hybrid BP/GA technique. The results are very encouraging; the proposed temporal weather prediction <b>model</b> <b>outperforms</b> <b>the</b> <b>previous</b> <b>models</b> while performing for dynamic and chaotic weather conditions...|$|R
40|$|In this paper, {{we propose}} {{a model to}} {{integrate}} term dependencies. Different from previous studies, each pair of terms is assigned a different weight of dependency according to their utility to IR. The experiments show that our <b>model</b> can significantly <b>outperform</b> <b>the</b> <b>previous</b> dependency <b>models</b> using fixed weights...|$|R
40|$|Prediction of wave {{overtopping}} {{is a key}} task in {{the design}} and safety assessment of coastal structures. In this study, M 5 䠭odel tree as a new soft computing approach was used to develop a model for prediction of wave overtopping rate at rubble mound breakwaters. The main advantages of model trees are that they are easier to deploy and more importantly they produce understandable formulas. The selected data from the CLASH database were used for training of the model and the conventional governing parameters were used as the input parameters. The obtained results were also compared with those of <b>previous</b> <b>models.</b> <b>The</b> accuracy of the model was evaluated by statistical measures, and it was shown that the developed model is more accurate than <b>previous</b> <b>models.</b> Furthermore, <b>the</b> model was validated with the prototype overtopping measurements in three sites. Results indicated that <b>the</b> developed <b>model</b> <b>outperforms</b> <b>the</b> <b>previous</b> <b>models</b> in predicting <b>the</b> full scale overtopping rates as well. Full Tex...|$|R
40|$|In this paper, {{we use the}} {{fundamental}} idea of the incremental model (IM) and develop the design framework. The design method of IM is composed of two steps. In the first step, we perform a linear regression (LR) as the global model. In the second step, the errors obtained by the global model are predicted by fuzzy if-then rules generated through a local linguistic model. Although the effectiveness of IM has been demonstrated in various prediction examples, we propose an improved incremental model (IIM) to deal with complex nonlinear characteristics. For this purpose, we employ adaptive neuro-fuzzy networks (ANFN) or {{radial basis function networks}} (RBFN) to create local granular networks in the design of IIM. Furthermore, we use quadratic regression (QR) as a global model, because linear relationship of LR may not hold in many settings. Numerical studies concern four datasets (automobile data, energy efficiency data, Boston housing data and computer hardware data). The experimental results demonstrate that IIM <b>outperformed</b> <b>the</b> <b>previous</b> <b>models...</b>|$|R
40|$|Automatic teller machine (ATM) {{is one of}} {{the most}} popular banking {{facilities}} to do daily financial transactions. People use ATM services to pay bills, transfer funds and withdraw cash. Accurate ATM forecasting for the future {{is one of the}} most important attributes to forecast because business sector, daily needs of people are highly largely dependent on this. In recent years, Neural Networks have become increasingly popular in finance for tasks such as pattern recognition, classification and time series forecasting. Every financial institution (large or small) faces the same daily challenge. While it would be devastating to run out of cash, it is important to keep cash at the right levels to meet customer demand. In such case, it becomes very necessary to have a forecasting system in order to get a clear picture of demand well in advance. In this research article an integrated BP/GA technique is proposed for accurate ATM forecasting. The results are very encouraging. The comparison of proposed technique with <b>the</b> <b>previous</b> one clarifies that <b>the</b> proposed <b>model</b> <b>outperforms</b> <b>the</b> <b>previous</b> <b>models...</b>|$|R
40|$|Markov {{transition}} {{models are}} becoming a popular tool for exploring the dynamics of systems that can take on {{a finite number of}} states. However, their application in political science has thus far been mostly limited to the two-state case. This paper explains the techniques necessary to estimate and interpret higher-dimension Markov models. We then apply them to the study of democratic transitions, where we find that a three-state model including an intermediary “partial democracy ” category <b>outperforms</b> <b>the</b> <b>previous</b> two-state <b>model</b> of Przeworski, et. al. (2000). ...|$|R
40|$|Free-running and nudged {{versions}} of a Met Office chemistry–climate model are evaluated and used to investigate the impact of dynamics versus transport and chemistry within the model on the simulated evolution of stratospheric ozone. Metrics of the dynamical processes relevant for simulating stratospheric ozone are calculated, and the free-running model is found to <b>outperform</b> <b>the</b> <b>previous</b> <b>model</b> version in 10 of the 14  metrics. In particular, large biases in stratospheric transport and tropical tropopause temperature, which existed in <b>the</b> <b>previous</b> <b>model</b> version, are substantially reduced, making the current model more suitable for the simulation of stratospheric ozone. The spatial structure of the ozone hole, the area of polar stratospheric clouds, and the increased ozone concentrations in the Northern Hemisphere winter stratosphere following sudden stratospheric warmings, were all found {{to be sensitive to}} the accuracy of the dynamics and were better simulated in the nudged model than in the free-running model. Whilst nudging can, in general, provide a useful tool for removing the influence of dynamical biases from the evolution of chemical fields, this study shows that issues can remain in the climatology of nudged models. Significant biases in stratospheric vertical velocities, age of air, water vapour, and total column ozone still exist in the Met Office nudged model. Further, these can lead to biases in the downward flux of ozone into the troposphere...|$|R
40|$|This report {{proposes a}} new {{stochastic}} model of visual attention {{to predict the}} likelihood of where humans typically focus on a video scene. The proposed model is composed of a dynamic Bayesian network that simulates and combines a person’s visual saliency response and eye movement patterns to estimate the most probable regions of attention. Dynamic Markov random field (MRF) models are newly introduced to include spatiotemporal relationships of visual saliency responses. Experimental results have revealed that <b>the</b> propose <b>model</b> <b>outperforms</b> <b>the</b> <b>previous</b> deterministic <b>model</b> and <b>the</b> stochastic model without dynamic MRF in predicting human visual attention. ...|$|R
40|$|Abstract — Network {{security}} {{is an important}} task of network management. One threat to network {{security is}} malware (malicious software) propagation. One type of malware is called topological scanning that spreads based on topology information. The focus of this work is on modeling the spread of topological malwares, which is important for understanding their potential damages, and for developing countermeasures to protect the network infrastructure. Our model is motivated by probabilistic graphs, which have been widely investigated in machine the propagation of malwares that employ different scanning methods. We then use a spatial-temporal random process to describe the statistical dependence of malware propagation in arbitrary topologies. As the spatial dependence is particularly difficult to characterize, the problem becomes how to use simple (i. e., biased) models to approximate the spatially dependent process. In particular, we propose the independent model and the Markov model as simple approximations. We conduct both theoretical analysis and extensive simulations on large networks using both real measurements and synthesized topologies to test {{the performance of the}} proposed models. Our results show that the independent model can capture temporal dependence and detailed topology information, and thus <b>outperforms</b> <b>the</b> <b>previous</b> <b>models,</b> whereas <b>the</b> Markov model incorporates a certain spatial dependence and thus achieves a greater accuracy in characterizing both transient and equilibrium behaviors of malware propagation...|$|R
40|$|Abstract—Network {{security}} {{is an important}} task of network management. One threat to network {{security is}} malware (malicious software) propagation. One type of malware is called topological scanning that spreads based on topology information. The focus of this work is on modeling the spread of topological malwares, which is important for understanding their potential damages, and for developing countermeasures to protect the network infrastructure. Our model is motivated by probabilistic graphs, which have been widely investigated in machine learning. We first use a graphical representation to abstract the propagation of malwares that employ different scanning methods. We then use a spatial-temporal random process to describe the statistical dependence of malware propagation in arbitrary topologies. As the spatial dependence is particularly difficult to characterize, the problem becomes how to use simple (i. e., biased) models to approximate the spatially dependent process. In particular, we propose the independent model and the Markov model as simple approximations. We conduct both theoretical analysis and extensive simulations on large networks using both real measurements and synthesized topologies to test {{the performance of the}} proposed models. Our results show that the independent model can capture temporal dependence and detailed topology information and, thus, <b>outperforms</b> <b>the</b> <b>previous</b> <b>models,</b> whereas <b>the</b> Markov model incorporates a certain spatial dependence and, thus, achieves a greater accuracy in characterizing both transient and equilibrium behaviors of malware propagation. Index Terms—graphical models, malware, modeling, security, stochastic processes...|$|R
40|$|Traditional {{convolutional}} {{neural networks}} (CNN) are stationary and feedforward. They neither change their parameters during evaluation nor use feedback from higher to lower layers. Real brains, however, do. So does our Deep Attention Selective Network (dasNet) architecture. DasNet’s feedback structure can dy-namically alter its convolutional filter sensitivities during classification. It har-nesses {{the power of}} sequential processing to improve classification performance, by allowing the network to iteratively focus its internal attention on some of its convolutional filters. Feedback is trained through direct policy search in a huge million-dimensional parameter space, through scalable natural evolution strate-gies (SNES). On the CIFAR- 10 and CIFAR- 100 datasets, dasNet <b>outperforms</b> <b>the</b> <b>previous</b> state-of-the-art <b>model</b> on unaugmented datasets. ...|$|R
40|$|The {{need for}} a high {{fidelity}} model for design, analysis and implementation of an unmanned helicopter system (UHS) in various emerging civil applications cannot be underestimated. However, going by a first principle approach based on physical laws governing {{the dynamics of the}} system, this task is noted to be highly challenging due to the complex nonlinear characteristics of the helicopter system. On the other hand, the problem of determining network architecture for optimal/sub-optimal performances {{has been one of the}} major challenges in the use of the nonparametric approach based on Nonlinear AutoRegressive with eXogenous inputs Network (NARX-network). The performance of the NARX network in terms of complexity and accuracy is largely dependent on the network architecture. The current approach in the literature has been largely based on trial and error, while most of the reported optimization approaches have limited the domain of the problem to a single objective problem. This study proposes a hybrid of conventional back propagation training algorithm for the NARX network and multiobjective differential evolution (MODE) algorithm for identification of a nonlinear model of an unmanned small scale helicopter from experimental flight data. The proposed hybrid algorithm was able to produce models with Pareto-optimal compromise between the design objectives. The performance of the proposed optimized model is benchmarked with one of the previously reported architectures for a similar system. <b>The</b> optimized <b>model</b> <b>outperformed</b> <b>the</b> <b>previous</b> <b>model</b> architecture with up to 55 % performance improvement. Apart from the effectiveness of the optimized model, the proposed design algorithm is expected to facilitate timely development of the nonparametric model of the helicopter system...|$|R
40|$|We {{show that}} the task of {{question}} answering (QA) can significantly benefit from the transfer learning of models trained on a different large, fine-grained QA dataset. We achieve {{the state of the}} art in two well-studied QA datasets, WikiQA and SemEval- 2016 (Task 3 A), through a basic transfer learning technique from SQuAD. For WikiQA, our <b>model</b> <b>outperforms</b> <b>the</b> <b>previous</b> best <b>model</b> by more than 8 %. We demonstrate that finer supervision provides better guidance for learning lexical and syntactic information than coarser supervision, through quantitative results and visual analysis. We also show that a similar transfer learning procedure achieves {{the state of the art}} on an entailment task. Comment: Published as a conference paper at ACL 2017 (short paper...|$|R
40|$|The of {{behavioral}} patterns in online social media are often reflecting the happenings in our society. These patterns, {{which can be}} considered as opinions, are often correlated with public opinion polling. However, many correlation analyses done previously were for subsequent discoveries {{and not being able to}} handle short interval polling opinions. For opinions obtained from tracking polling with short opinion collection interval, like rolling polling, it cannot perform well in tracing the latest trends. This paper describes an extended correlation model for such kind of polling in examining the correlation between opinion in online social media and the public opinion from tracking poll. It has been tested with a recent rolling polling and it <b>outperformed</b> <b>the</b> <b>previous</b> correlation <b>models.</b> Department of ComputingRefereed conference pape...|$|R
40|$|This paper {{presents}} a novel {{neural machine translation}} model which jointly learns translation and source-side latent graph representations of sentences. Unlike existing pipelined approaches using syntactic parsers, our end-to-end model learns a latent graph parser {{as part of the}} encoder of an attention-based neural machine translation model, and thus the parser is optimized according to the translation objective. In experiments, we first show that our model compares favorably with state-of-the-art sequential and pipelined syntax-based NMT models. We also show that the performance of our model can be further improved by pre-training it {{with a small amount of}} treebank annotations. Our final ensemble <b>model</b> significantly <b>outperforms</b> <b>the</b> <b>previous</b> best <b>models</b> on <b>the</b> standard English-to-Japanese translation dataset. Comment: Accepted as a full paper at the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP 2017...|$|R
40|$|Although {{transfer}} {{learning has}} been shown to be successful for tasks like object and speech recognition, its applicability to question answering (QA) has yet to be well-studied. In this paper, we conduct extensive experiments to investigate the transferability of knowledge learned from a source QA dataset to a target dataset using two QA models. The performance of both models on a TOEFL listening comprehension test (Tseng et al., 2016) and MCTest (Richardson et al., 2013) is significantly improved via a simple transfer learning technique from MovieQA (Tapaswi et al., 2016). In particular, one of the models achieves the state-of-the-art on all target datasets; for the TOEFL listening comprehension test, it <b>outperforms</b> <b>the</b> <b>previous</b> best <b>model</b> by 7 %. Finally, we show that transfer learning is helpful even in unsupervised scenarios when correct answers for target QA dataset examples are not available...|$|R
40|$|Currently most of {{state-of-the-art}} meth-ods for Chinese word segmentation {{are based}} on supervised learning, whose fea-tures aremostly extracted from a local con-text. Thesemethods cannot utilize the long distance information which is also crucial for word segmentation. In this paper, we propose a novel neural network model for Chinese word segmentation, which adopts the long short-term memory (LSTM) neu-ral network to keep <b>the</b> <b>previous</b> impor-tant information inmemory cell and avoids the limit of window size of local context. Experiments on PKU, MSRA and CTB 6 benchmark datasets show that our <b>model</b> <b>outperforms</b> <b>the</b> <b>previous</b> neural network <b>models</b> and state-of-the-art methods. ...|$|R
40|$|We {{develop a}} fully discriminative {{learning}} approach for supervised Latent Dirich-let Allocation (LDA) model using Back Propagation (i. e., BP-sLDA), which max-imizes the posterior probability of the prediction variable given the input doc-ument. Different from traditional variational learning or Gibbs sampling ap-proaches, the proposed learning method applies (i) the mirror descent algorithm for maximum a posterior inference and (ii) back propagation over a deep architec-ture together with stochastic gradient/mirror descent for model parameter estima-tion, leading to scalable and end-to-end discriminative {{learning of the}} model. As a byproduct, we also apply this technique {{to develop a new}} learning method for the traditional unsupervised LDA model (i. e., BP-LDA). Experimental results on three real-world regression and classification tasks show that the proposed meth-ods significantly <b>outperform</b> <b>the</b> <b>previous</b> supervised topic <b>models,</b> neural net-works, and is on par with deep neural networks. ...|$|R
40|$|The {{detection}} of prosodic characteristics {{is an important}} aspect of both speech synthesis and speech recognition. Correct placement of pitch accents aids in more natural sounding speech, while automatic {{detection of}} accents can contribute to better wordlevel recognition and better textual understanding. In this paper we investigate probabilistic, contextual, and phonological factors that influence pitch accent placement in natural, conversational speech in a sequence labeling setting. We introduce Conditional Random Fields (CRFs) to pitch accent prediction task in order to incorporate these factors efficiently in a sequence model. We demonstrate the usefulness and the incremental effect of these factors in a sequence model by performing experiments on hand labeled data from the Switchboard Corpus. Our <b>model</b> <b>outperforms</b> <b>the</b> baseline and <b>previous</b> <b>models</b> of pitch accent prediction on the Switchboard Corpus. ...|$|R
40|$|The spatial {{autoregression}} (SAR) {{model is}} a knowledge discovery technique used for mining massive geo-spatial data in many application domains. Estimation of {{the parameters of the}} exact SAR model using Maximum Likelihood (ML) theory is computationally very expensive because of the need to compute the logarithm of the determinant (log-det) of a large matrix in the loglikelihood function. In this paper, we developed a faster, scalable and NOvel pRediction and estimation TecHnique for the exact SpaTial Auto Regression model solution (NORTHSTAR). In this heuristic, the SAR model parameters are first estimated using a computationally more efficient sum-of-squared errors (SSE) term of the log-likelihood function. Next, starting from an initial estimate very close to the optimal estimate, the computationally more expensive log-det term is embedded into the estimation process to save log-det computations. Experimental results show that <b>the</b> NORTHSTAR algorithm <b>outperformed</b> <b>the</b> <b>previous</b> exact SAR <b>model</b> solutions. ...|$|R
40|$|Abstract—The model {{checking}} of higher-order recursion schemes (HORS), aka. higher-order model checking, is {{the problem}} of checking whether the tree generated by a given HORS satisfies a given property. It has recently been studied actively and applied to automated verification of higher-order programs. Kobayashi and Igarashi studied an extension of higher-order model checking called µHORS model checking, where HORS has been extended with recursive types, so that a wider range of programs, including object-oriented programs and multi-threaded programs, can be precisely modeled and verified. Although the µHORS model checking is undecidable in general, they developed a sound but incomplete procedure for µHORS model checking. Unfortunately, however, their procedure was not scalable enough. Inspired by recent progress of (ordinary) HORS model checking, we propose a new procedure for µHORS model checking, based on automata-based abstraction refinement. We have implemented the new procedure and confirmed that it often <b>outperforms</b> <b>the</b> <b>previous</b> procedure. Keywords-higher-order <b>model</b> checking; tree automata; ab-straction refinement I...|$|R
40|$|We {{consider}} classification {{problems in}} which the label space has structure. A common example is hierarchical label spaces, corresponding to the case where one label subsumes another (e. g., animal subsumes dog). But labels can also be mutually exclusive (e. g., dog vs cat) or unrelated (e. g., furry, carnivore). To jointly model hierarchy and exclusion relations, {{the notion of a}} HEX (hierarchy and exclusion) graph was introduced in [7]. This combined a conditional random field (CRF) with a deep neural network (DNN), resulting in state of the art results when applied to visual object classification problems where the training labels were drawn from different levels of the ImageNet hierarchy (e. g., an image might be labeled with the basic level category "dog", rather than the more specific label "husky"). In this paper, we extend the HEX model to allow for soft or probabilistic relations between labels, which is useful when there is uncertainty about the relationship between two labels (e. g., an antelope is "sort of" furry, but not to the same degree as a grizzly bear). We call our new model pHEX, for probabilistic HEX. We show that the pHEX graph can be converted to an Ising model, which allows us to use existing off-the-shelf inference methods (in contrast to the HEX method, which needed specialized inference algorithms). Experimental results show significant improvements in a number of large-scale visual object classification tasks, <b>outperforming</b> <b>the</b> <b>previous</b> HEX <b>model.</b> Comment: International Conference on Computer Vision (2015...|$|R
40|$|While most {{approaches}} to automatically recognizing entailment relations have used classifiers employing hand engineered features derived from complex {{natural language processing}} pipelines, in practice their performance has been only slightly better than bag-of-word pair classifiers using only lexical similarity. The only attempt so far to build an end-to-end differentiable neural network for entailment failed to outperform such a simple similarity classifier. In this paper, we propose a neural model that reads two sentences to determine entailment using long short-term memory units. We extend this model with a word-by-word neural attention mechanism that encourages reasoning over entailments of pairs of words and phrases. Furthermore, we present a qualitative analysis of attention weights produced by this model, demonstrating such reasoning capabilities. On a large entailment dataset this <b>model</b> <b>outperforms</b> <b>the</b> <b>previous</b> best neural <b>model</b> and a classifier with engineered features by a substantial margin. It is the first generic end-to-end differentiable system that achieves state-of-the-art accuracy on a textual entailment dataset. Comment: ICLR 2016 camera-ready, 9 pages, 10 figures (incl. subfigures...|$|R
40|$|Several {{research}} fields have to {{deal with}} very large classification problems, e. g. handwritten character recognition and speech recognition. Many works have proposed methods to address problems with large number of samples, but few works have been done concerning problems with large numbers of classes. CombNET-II {{was one of the first}} methods proposed for such a kind of task. It consists of a sequential clustering VQ based gating network (stem network) and several Multilayer Perceptron (MLP) based expert classifiers (branch networks). With the objectives of increasing the classification accuracy and providing a more flexible model, this paper proposes a new model based on the CombNET-II structure, the CombNET-III. The new model, intended for, but not limited to, problems with large number of classes, replaces the branch networks MLP with multiclass Support Vector Machines (SVM). It also introduces a new probabilistic framework that outputs posterior class probabilities, enabling the model to be applied in different scenarios (e. g. together with Hidden Markov Models). These changes permit the use of a larger number of smaller clusters, which reduce the complexity of the final classifiers. Moreover, the use of binary SVM with probabilistic outputs and a probabilistic decoding scheme permit the use of a pairwise output encoding on the branch networks, which reduces the computational complexity of the training stage. The experimental results show that <b>the</b> proposed <b>model</b> <b>outperforms</b> both <b>the</b> <b>previous</b> <b>model</b> CombNET-II and a single multiclass SVM, while presenting considerably smaller complexity than the latter. It is also confirmed that CombNET-III classification accuracy scales better with the increasing number of clusters, in comparison with CombNET-II...|$|R
40|$|SUMMARY Several {{research}} fields have to {{deal with}} very large classification problems, e. g. handwritten character recognition and speech recognition. Many works have proposed methods to address problems with large number of samples, but few works have been done concerning problems with large numbers of classes. CombNET-II {{was one of the first}} methods proposed for such a kind of task. It consists of a sequential clustering VQ based gating network (stem network) and several Multilayer Perceptron (MLP) based expert classifiers (branch networks). With the objectives of increasing the classification accuracy and providing a more flexible model, this paper proposes a new model based on the CombNET-II structure, the CombNET-III. The new model, intended for, but not limited to, problems with large number of classes, replaces the branch networks MLP with multiclass Support Vector Machines (SVM). It also introduces a new probabilistic framework that outputs posterior class probabilities, enabling the model to be applied in different scenarios (e. g. together with Hidden Markov Models). These changes permit the use of a larger number of smaller clusters, which reduce the complexity of the final classifiers. Moreover, the use of binary SVM with probabilistic outputs and a probabilistic decoding scheme permit the use of a pairwise output encoding on the branch networks, which reduces the computational complexity of the training stage. The experimental results show that <b>the</b> proposed <b>model</b> <b>outperforms</b> both <b>the</b> <b>previous</b> <b>model</b> CombNET-II and a single multiclass SVM, while presenting considerably smaller complexity than the latter. It is also confirmed that CombNET-III classification accuracy scales better with the increasing number of clusters, in comparison with CombNET-II. key words: large scale classification problems, support vector machines, probabilistic framework, divide-and-conquer 1...|$|R
40|$|In a {{realistic}} distributed storage environment, storage nodes are usually placed in racks, a metallic support {{designed to accommodate}} electronic equipment. It is known that the communication (bandwidth) cost between nodes which {{are in the same}} rack is much lower than between nodes which are in different racks. In this paper, a new model, where the storage nodes are placed in two racks, is proposed and analyzed. Moreover, the two-rack model is generalized to any number of racks. In this model, the storage nodes have different repair costs depending on the rack where they are placed. A threshold function, which minimizes the amount of stored data per node and the bandwidth needed to regenerate a failed node, is shown. This threshold function generalizes the ones given for <b>previous</b> distributed storage <b>models.</b> <b>The</b> tradeoff curve obtained from this threshold function is compared with the ones obtained from <b>the</b> <b>previous</b> <b>models,</b> and it is shown that this new <b>model</b> <b>outperforms</b> <b>the</b> <b>previous</b> ones in terms of repair cost. Comment: Submitted to IEEE Transactions on Information Theory. arXiv admin note: text overlap with arXiv: 1301. 154...|$|R
50|$|The Nexus 7 screen {{now has a}} 1920×1200 pixel {{resolution}} (960dp × 600dp). <b>The</b> <b>previous</b> <b>model</b> had {{a resolution}} of 1280×800. Additionally, the panel's contrast ratio and color gamut are reportedly superior to <b>the</b> <b>previous</b> <b>model.</b>|$|R
50|$|The pilot {{episode of}} In Plain Sight {{attracted}} 5.25 million viewers, making it USA Network's highest-rated series premiere since Psych in 2006. It also <b>outperformed</b> <b>the</b> <b>previous</b> summer's debut of Burn Notice by 32% {{and the network}} premiere of Law & Order: Criminal Intent by 40%.|$|R
500|$|In its {{original}} American broadcast on April 21, 2010, [...] "201" [...] was watched by 3.5 million viewers, according to Nielsen Media Research, {{making it the}} most watched cable television show of <b>the</b> night. It <b>outperformed</b> <b>the</b> <b>previous</b> week's episode, [...] "200", which was seen by 3.33 million viewers.|$|R
40|$|This thesis made {{outstanding}} contribution in automating {{the discovery of}} linear causal models. It introduced a highly efficient discovery algorithm, which implements new encoding, ensemble and accelerating strategies. Theoretic research and experimental work showed that this new discovery algorithm <b>outperforms</b> <b>the</b> <b>previous</b> system in both accuracy and efficiency...|$|R
5000|$|In its {{original}} American broadcast on April 21, 2010, [...] "201" [...] was watched by 3.5 million viewers, according to Nielsen Media Research, {{making it the}} most watched cable television show of <b>the</b> night. It <b>outperformed</b> <b>the</b> <b>previous</b> week's episode, [...] "200", which was seen by 3.33 million viewers.|$|R
40|$|This paper {{proposes a}} novel {{composite}} kernel for relation extraction. The composite kernel {{consists of two}} individual kernels: an entity kernel that allows for entity-related features and a convolution parse tree kernel that models syntactic information of relation examples. The motivation of our method is to fully utilize the nice properties of kernel methods to explore and combine diverse features for relation extraction. Our study illustrates that the composite kernel can capture both flat and structured features effectively, and can also easily scale to include more features. Evaluation on the ACE corpus shows that our method <b>outperforms</b> <b>the</b> <b>previous</b> best-reported method. It also shows that due to the effective exploration of the syntactic features the sole parse tree kernel significantly <b>outperforms</b> <b>the</b> <b>previous</b> two dependency kernels by 16 in F-measure on the ACE 2003 corpus. ...|$|R
