0|10000|Public
30|$|SFL, in general, and {{systemic}} typology, in particular, have developed in interaction with many {{different approaches to}} language study. We limit <b>our</b> <b>discussion</b> <b>here</b> to connections <b>with</b> a few other functional approaches that interact with and/or influence typology research in systemic linguistics.|$|R
30|$|Other {{types of}} time {{consistency}} for stochastic processes {{may be defined}} in analogy to what is done in Section “Other types of time consistency” for the case of random variables. For brevity, we limit <b>our</b> <b>discussion</b> <b>here</b> to the update rules derived from dynamic LM-measures.|$|R
50|$|Given a ring R, the {{polynomial}} ring Rx is {{the set of}} all polynomials in x {{that have}} coefficients chosen from R. In the special case that R is also a field, then the polynomial ring Rx is a principal ideal domain and, more importantly to <b>our</b> <b>discussion</b> <b>here,</b> a Euclidean domain.|$|R
30|$|In {{the years}} since Laney’s paper was published, {{numerous}} people have proposed additions to this list and many refer to four or five V’s, adding in Value or Veracity [7]. However, we are skeptical that these additions add to an overall understanding of big data, so we focus <b>our</b> <b>discussion</b> <b>here</b> to the original three.|$|R
30|$|Robust {{representations}} {{have been}} studied for general dynamic LM-measures, not only for dynamic monetary utility measures. However, {{in this paper we}} only use robust representations for dynamic monetary utility measures for random variables, and that is why <b>our</b> <b>discussion</b> <b>here</b> is limited to this case. Consequently, we take X=L^p for a fixed p∈ 0, 1,∞.|$|R
6000|$|... "Your father's note {{suggests}} to me," [...] replied Nugent, [...] "that he {{is a little}} hurt at the short notice I gave him of <b>our</b> <b>discussion</b> <b>here.</b> I thought--if you and Madame Pratolungo went on first--that you might make our peace with the rector, and assure him that we meant no disrespect, before Oscar and I appeared. Don't you think yourself you {{would make it easier}} for us, if you did that?" ...|$|R
40|$|Three-dimensional {{integration}} is an emerging fabrication technology that vertically stacks multiple integrated chips. The benefits include {{an increase in}} device density; much greater flexibility in routing signals, power, and clock; the ability to integrate disparate technologies; {{and the potential for}} new 3 D circuit and microarchitecture organizations. This article provides a technical introduction to the technology and its impact on processor design. Although <b>our</b> <b>discussions</b> <b>here</b> primarily focus on highperformance processor design, most of the observations and conclusions apply to other microprocessor market segments...|$|R
40|$|This book {{describes}} and {{illustrates the}} application of several asymptotic methods that have proved useful in the authors' research in electromagnetics and antennas. We first define asymptotic approximations and expansions and explain these concepts in detail. We then develop certain prerequisites from complex analysis such as power series, multivalued functions (including the concepts of branch points and branch cuts), and the all-important gamma function. Of particular importance {{is the idea of}} analytic continuation (of functions of a single complex variable); <b>our</b> <b>discussions</b> <b>here</b> include so...|$|R
40|$|We {{describe}} updated {{calculations of}} Q Q̅ production in pp and π^- p interactions. We compare these results to {{total cross section}} data and discuss how the baseline cross sections extrapolate to heavy ion collider energies. We touch upon the differences between leading and next-to-leading order heavy quark production. Finally, we discuss the implications of our calculations for quarkonium production. <b>Our</b> <b>discussion</b> <b>here</b> focuses on bottom quarks. Comment: 10 pages, uses special included style file, 4 eps figures, for proceedings of the Budapest' 02 Workshop on Quark and Hadron Dynamic...|$|R
40|$|This paper {{describes}} a proposed high resolution soft X-ray and Extreme Ultraviolet (EUV) spectroscopy mission {{to carry out}} a survey of Stellar and Galactic Environments (SAGE). The payload is based on novel diffraction grating technology which has already been proven in a sub-orbital space mission and which is ready to fly on a satellite platform with minimal development. Much of the technical detail of the instrumentation has been reported elsewhere and we concentrate <b>our</b> <b>discussion</b> <b>here</b> on the scientific goals of a SAGE base-line mission, demonstrating the scientific importance of high resolution spectroscopy in the Extreme Ultraviolet for the study of stars and the local interstellar medium...|$|R
30|$|Typically, F 0 {{along with}} its delta and delta-delta {{derivatives}} form three streamsa of a context-dependent[34, 35]multi-space probability distribution (MSD)[36]left-to-right without skip transitions HSMM[58, 37] (which for obvious reasons, we shorten to simply ‘HMM’ in this paper). This model structure generates acoustic trajectories of a unit (e.g., phoneme) by emitting observations from hidden states. The output distribution {{of the state is}} a context-dependent multi-space Gaussian distribution [36], and these are clustered into groups of related contexts using a decision tree {{in order to reduce the}} number of free parameters and allow the modeling of unseen contexts. For notational simplicity, we limit <b>our</b> <b>discussion</b> <b>here</b> to an HMM with just one stream. Generalizing this to the multi-stream case is straightforward.|$|R
30|$|We {{have been}} {{conducting}} research on different pastoral systems in the Chad Basin for the last 20 years (Moritz 2008; Moritz et al. 2013 a; Moritz et al. 2010; Scholte et al. 2006), and <b>our</b> <b>discussion</b> <b>here</b> draws from <b>our</b> involvement in pastoral development in the far north region in different capacities. Two of the authors worked for the Waza Logone Project in the 1990 s (PS, SK), two others are currently members of Centre d'Appui à la Recherche et au Pastoralisme (CARPA) (SK, AM), one studied the process of delimiting the transhumance corridor as an intern at CARPA (BLC), and two others have studied different pastoral systems in the Far North Province, including pastoral development (MM, AD).|$|R
30|$|It {{should be}} noted, however, that <b>our</b> <b>discussion</b> <b>here</b> applies to {{recurrent}} excitation and inhibition. Tuned excitation and inhibition, when {{measured in terms}} of the total excitatory and inhibitory conductances in intracellular recordings, are the total excitatory and inhibitory input that a neuron observes. It is therefore possible that the tuning of the feedforward input is dominant in the tuning. Likewise, feedforward inhibition, mediated by disynaptic inhibition, can have the same tuning as the feedforward excitatory input, as the former is mediating it. The mechanisms discussed here, however, apply to recurrent excitation and inhibition, since they are a consequence of the dynamics of a network of synaptically connected neurons and, in particular, recruitment of feedback inhibition within the network.|$|R
40|$|We derive some asymptotics {{for a new}} {{approach}} to curve estimation proposed by Mr'{a}zek et al. cite{MWB 06 } which combines localization and regularization. This methodology has been considered as the basis of a unified framework covering various different smoothing methods in the analogous two-dimensional problem of image denoising. As a first step for understanding this approach theoretically, we restrict <b>our</b> <b>discussion</b> <b>here</b> to the least-squares distance where we have explicit formulas for the function estimates and where we can derive a rather complete asymptotic theory from known results for the Priestley-Chao curve estimate. In this paper, we consider only the case where the bias dominates the mean-square error. Other situations are dealt with in subsequent papers...|$|R
40|$|Abstract. In this paper, we {{consider}} the effect of dispersal on the permanence of single and interacting populations modelled by systems of integro differential equations. Different from former studies, <b>our</b> <b>discussion</b> <b>here</b> includes the important situation when species live in a weak patchy environment; i. e., species in some isolated patches will become extinct without the contribution from other patches. For the single population model considered in this paper, we show that the same species can persist for some dispersal rates and the species will vanish in some isolated patches. Based on the results for a single population model, we derive sufficient conditions for the permanence of two interacting competitive and predator-prey dispersing systems. 1...|$|R
30|$|Findings on {{the impact}} of PPPs on {{education}} quality indicates that the implementation of PPPs in Tanzania higher education has {{had an impact on the}} quality of education provided by the private sub sector. Scholars agree at some point that the quality dimension of education is better seen when the education system is viewed as a complex manufacturing industry with inputs, process and outputs (Scheerens 2011). Based on this conception of education, input and the quality of the process are what determine the quality of outputs or graduates. As we could not get data about the output indicator of quality because of our research design, <b>our</b> <b>discussion</b> <b>here</b> focuses on inputs (number and qualifications of academic staff) and partly on the process indicator (teaching and learning).|$|R
30|$|In this section, we {{investigate}} the convergence {{properties of the}} SO-DCTS algorithm in undirected networks when there is both deterministic and random (Gaussian) delay between network nodes during local time information exchange. In [19], we motivate why the Gaussian assumption is appropriate to model the undeterministic timing differences between nodes exchanging either MAC layer or physical layer timing information. We do not reiterate those arguments here but rather present convergence results for the SO-DCTS algorithm when such timing differences exist. We have separately examined {{the performance of the}} SO-DCTS algorithm considering alternate delay distributions, for example, exponential delay distribution [20]. Results show similar performance bounds as those presented in this paper for the Gaussian assumption. For this reason, we constrain <b>our</b> <b>discussion</b> <b>here</b> to the more common Gaussian delay model.|$|R
30|$|In {{existing}} research, {{there is}} also attention given {{to the use of}} film and video documentaries as sources of data (e.g. Chattoo & Das, 2014; Warmington, van Gorp & Grosvenor, 2011), however, <b>our</b> <b>discussion</b> <b>here</b> focuses on using media to capture information and communicate resulting narratives for research purposes. In our work, we promote a perspective on emergent storytelling that develops from data collection and analysis, allowing the research to drive the narrative, and situating it in the context from where data was collected. We rely on theories and practices of research and storytelling that leverage the affordances of participant observation and interview for the construction of narratives (Bailey & Tilley, 2002; de Carteret, 2008; de Jager, Fogarty & Tewson, 2017; Gallagher, 2011; Hancox, 2017; LeBaron, Jarzabkowski, Pratt & Fetzer, 2017; Lewis, 2011; Meadows, 2003).|$|R
40|$|We report {{surprising}} surface-induced torsional {{alignment of}} polydimethylsiloxane (PDMS) chains {{in contact with}} the muscovite (001) mica surface with and without confinement. The alignment was measured by polarized confocal Raman spectroscopy over diffraction-limit circular spots with ∼ 0. 3 μm diameter. <b>Our</b> <b>discussion</b> <b>here</b> focuses on the intense symmetric methyl-group vibration centered at 2907 cm- 1, whose Raman scattering intensity is found to depend on whether incident light is polarized in the x or y direction of the surface, the x direction being parallel to one of the mica optical axes. Furthermore, the Raman peak broadens significantly relative to that of bulk PDMS while remaining Lorentzian in shape, implying slower but homogeneous vibrational dephasing. However, the preferred orientation differs, apparently stochastically, from spot to spot on the surface. Possible origins of this heterogeneous surface-induced structure are discussed. close 6...|$|R
40|$|On the Mars Exploration Rovers, Mossbauer {{spectroscopy}} {{has recently}} been called upon {{to assist in the}} task of mineral identification, a job for which it is rarely used in terrestrial studies. For example, Mossbauer data were used to support the presence of olivine in Martian soil at Gusev and jarosite in the outcrop at Meridiani. The strength (and uniqueness) of these interpretations lies in the assumption that peak positions can be determined with high degrees of both accuracy and precision. We summarize here what we believe to be the major sources of error associated with peak positions in remotely-acquired spectra, and speculate on their magnitudes. <b>Our</b> <b>discussion</b> <b>here</b> is largely qualitative because necessary background information on MER calibration sources, geometries, etc., have not yet been released to the PDS; we anticipate that a more quantitative discussion can be presented by March 2005...|$|R
40|$|Iatrogenic factors {{refer to}} anyinadequate medical {{treatment}} or diagnostic proceduresconducted inadvertently by practitioners who precipitate adverse injuries or symptoms. The unavoidable {{consequences of these}} factors should be corrected promptly, as they may result in erroneous treatment or new injury either on the tooth or the periodontium or both. Periodontal disease has a multifactorial etiology, which results from the interaction of local and systemic factors, intrinsically or extrinsically. Therefore, in most cases of periodontal disease, aninterdisciplinary approach is needed, such as restorative treatment of interproximal cavities that may induced food impacted. In contrary, a periodontal therapy could also act as an iatrogenic factor {{in the case of}} dentinal hypersensitivity or gingival recessionthat frequently creates an adverse effect in esthetic. <b>Our</b> <b>discussion</b> <b>here</b> is presented so that dentists could treat carefully and give {{a lot of attention to}} potential danger of other consequences of iatrogenic factors...|$|R
30|$|The {{reason why}} the offset between the {{position}} of the bead in the two channels does not fall below the expected sum of the FRE and the particles’ localization precision for all of the points is quite complex to address. We will focus <b>our</b> <b>discussion</b> <b>here</b> {{to the fact that the}} relative drift in between the imaging channels may play a role by increasing the residual offset. Additional file 1 : Figure S 3 displays the x-y drift of a fiducial marker in an actual dual color measurement: the fiducial drift follows a slightly different path when measured in each channel, and the relative drift, that should be constant, fluctuates approximately 10 nm (as shown in lower inset in Additional file 1 : Figure S 3). It was demonstrated that this relative drift can corrected using an active stabilization of the imaging path, but only in a proof-of-principle single molecule experiment (Pertsinidis et al. 2010).|$|R
40|$|Despite the {{diversity}} of microbes associated with decayed hearts of living trees (71, 89), the degradation of the cell wall components is still ascribable to Hymenomycetes. <b>Our</b> <b>discussion</b> <b>here</b> is limited to them, although we by no means want to discount their probable interactions with other microbes that might play key roles in the decay process (89). Of the several thousand wood decaying fungi, only a small number-a few hundred-can cause decay {{in the hearts of}} living trees (95). The term heartrot is used to include the overall process that culminates in degradation of the wood in the hearts of living trees; decay per se may be only a part of the total process. The interior, primarily nonliving portion of a tree is referred to here as the heart. The term heartwood has been avoided. A great deal is known about the mechanisms by which fungi degrade the principal components of wood. Recent advances have been stimulated primarily by a desire to exploit cellulases an...|$|R
40|$|Error {{measures}} {{can be used}} to numerically assess the differences between two images. Much work has been done on binary error measures, but little on objective metrics for grey-scale images. In <b>our</b> <b>discussion</b> <b>here</b> we introduce a new grey-scale measure, Δ g, aiming to improve upon the most common grey-scale error measure, the root-mean-square error. Our new measure is an extension of the authors' recently developed binary error measure, Δ b, not only in structure, but also having both a theoretical and intuitive basis. We consider the similarities between Δ b and Δ g when tested in practice on binary images, and present results comparing Δ g to the root-mean-squared error and the Sobolev norm for various binary and grey-scale images. There are no previous examples where the last of these measures, the Sobolev norm, has been implemented for this purpose. 1 Introduction There are three main methods for comparing images: human perception, which is a subjective me [...] ...|$|R
40|$|We extend Madland's {{parameterization}} of {{the energy}} release in fission to obtain the dependence of the fission Q value for major and minor actinides on the incident neutron energies in the range 0 {le} E{sub n} {le} 20 MeV. Our parameterization {{is based on the}} actinide evaluations recommended for the ENDF/B-VII. 1 release. This paper describes the calculation of energydependent fission Q values based on the calculation of the prompt energy release in fission by Madland. This calculation was adopted for use in the LLNL ENDL database and then generalized to obtain the prompt fission energy release for all actinides. Here the calculation is further generalized to the total energy release in fission. There are several stages in a fission event, depending on the time scale. Neutrons and gammas may be emitted {{at any time during the}} fission event. While <b>our</b> <b>discussion</b> <b>here</b> is focussed on compound nucleus creation by an incident neutron, similar parameterizations could be obtained for incident gammas or spontaneous fission...|$|R
40|$|As per <b>our</b> <b>discussion</b> {{yesterday}} <b>here</b> is {{the results}} of the review by the technical staff at the Center for Nuclear Waste Regulatory Analyses (CNWRA). They were asked only to comment on issues within the U. S. Nuclear Regulatory Commission's regulatory framework. They commented on your issues 3 - 5 and 7 in the comments you provided to the Department of Energy. I would be happy to send you copies of any the NRC references cited in the CNWRA's response...|$|R
40|$|A {{boundary}} element method (BEM) {{combined with}} a linear slip boundary condition is proposed to calculate SH wave scattering from fractures. The linear slip boundary condition was proposed by Schoenberg (1980) to model elastic wave propagation through an imperfectly bonded interface, where the traction cross the interface is continuous and displacement is discontinuous. Here, we demonstrate how to simulate SH wave scattering from fractures by applying the BEM and this linear slip boundary. Comparisons between results obtained using our model with those obtained using a computationally expensive finite difference method (FDM) (Coates and Schoenberg, 1995; Kruger et al., 2005) are performed to show the validity and accuracy of our approach. An example of SH wave scattering from three curved, crossing fractures is also given. Although <b>our</b> <b>discussion</b> <b>here</b> {{is focused on the}} linear slip boundary condition, our approach can easily be adopted to various slip boundary conditions that specify the displacement discontinuity and traction relations depending on different physical models of fractures. Eni-MIT Energy Initiative Founding Member Progra...|$|R
40|$|In {{addressing}} {{issues related}} to problems of democratisation in Africa, this paper attempts to relate the issue {{to the need for}} citizenship education and the role that can play in social development. Citizenship should be central to the formation of viable civil societies that claim a tangible stake in national public spaces in post-Cold War Africa. These and related topics are discussed relative to new possibilities that could lead to the full realisation of the concept as well as the practice of enfranchised citizenship and inclusive social development in aspiring democracies in the Sub Saharan African context. The complexity of the development ‘problematique’ that Sub-Saharan Africa is facing is unique in that it is multi-dimensional, but above all else, politically located. It is, therefore, central to <b>our</b> <b>discussions</b> <b>here</b> that to correct the continent’s current schemes of underdevelopment, pragmatic schemes of governance must be achieved. To do that, we are suggesting, new possibilities of citizenship education should be formulated for the general African scene in general, and for democratising but still both institutionally and economically weakened Zambia...|$|R
40|$|Many {{commentators}} have pointed towards {{a downturn in}} the enrolment of students on economics degrees. Part of the explanation for this phenomenon is probably because business studies degrees meet students 2 ̆ 7 requirements for practical understanding more closely. We suggest here {{that one of the}} problems with economics is that introductory principles courses adopt a 2 ̆ 7 theory-first 2 ̆ 7 pedagogy. This means that students are asked to abandon any pre-formed notions/understanding about the nature of competition and accept the equilibrium model of perfect competition as the foundation of their future understanding. The downside of this approach is that: 2 ̆ 7 The everyday appearance of social life provides little in the way of verification for the student of basic economic ideas. The result is an analytical confusion that captivates the student more or less forever 2 ̆ 7 Bernstein (2004 : 33). By grounding introductory economics on the foundation stone of theories of entrepreneurship this problem is circumvented. <b>Our</b> <b>discussion</b> <b>here</b> suggests how entrepreneurship could be introduced to students and how it can lead to a deeper understanding of the true nature of the competitive process. The approach we advocate is pluralist...|$|R
40|$|Even {{though the}} trend {{components}} of economic time series {{were among the}} first to be distinguished, even today the trend remains relatively little understood. As Phillips (2005) notes, no one understands trends, but everyone sees them in the data. Economists and econometricians can give plenty of examples of trends, such as straight lines, exponentials or polynomials in time, and also forms of random walks, but these are merely examples. Individuals or groups do have their own personal definitions, but these diverse approaches illustrate the lack of a generally accepted definition of a trend. They also suggest a richness of alternatives to consider, both individually and jointly. Here, we make a variety of observations about trends, and based on these, we offer working definitions of various kinds of trends. We emphasize that these are working definitions, as our purpose here is to invite discussion, not to settle matters once and for all. Our hope is that <b>our</b> <b>discussion</b> <b>here</b> may facilitate development of increasingly better methods for prediction, estimation and hypothesis testing for non-stationary time-series data, and ultimately may enable decision makers to make more informed decisions. ...|$|R
40|$|We {{discuss the}} {{complete}} set of current algebra sum rules for the Regge residues and asymptotic constant S-limits of the structure functions of inelastic (anti) neutrino nucleon scattering. (Submitted to Phys. Rev.) *Work supported by the U. S. Atomic Energy Commission. subject of sum rules for the structure functions of forward current-hadron I s tattering. (Hereafter, we shall refer to Refs. 1 and 2 as A and B, respectively.) The principal concern of the present discussion will be the {{complete set of}} current algebra constraints on the Regge and asymptotic fixed hadronic mass 3 residues of the structure functions of inelastic (anti) neutrino nucleon scattering. For the sake of completeness and continuity, we shall begin by briefly reviewing the connection of the <b>discussion</b> <b>here</b> <b>with</b> that of A and B...|$|R
40|$|This {{reflective}} paper {{began with}} a discussion of the online program design and delivery experiences of three senior faculty members at the University of Calgary (Canada) and Deakin University (Australia), which was recorded at Deakin University. After drawing on this recording in their research and practice, one faculty member from each institution decided to review and expanded upon their intervening experiences in terms of issues of quality program design, delivery, and support issues when teaching, and learning in different cultural contexts. The authors discovered that these issues are as important today as they were when they met to record the interview, and have concluded their <b>discussion</b> <b>here</b> <b>with</b> thoughts about the teaching, student, and administrative supports that institutions engaged in online program delivery cross-culturally must address in order to successfully deliver quality online programs worldwide. <br /...|$|R
40|$|We {{present a}} model of gamma-ray {{emission}} from core-collapse supernovae originating from the explosions of massive young stars. The fast forward shock of the supernova remnant (SNR) can accelerate particles by diffusive shock acceleration (DSA) in a cavern blown by a strong, pre-supernova stellar wind. As a fundamental part of nonlinear DSA, some fraction of the accelerated particles escape the shock and interact with a surrounding massive dense shell producing hard photon emission. To calculate this emission, we have developed a new Monte Carlo technique for propagating the cosmic rays (CRs) produced by the forward shock of the SNR, into the dense, external material. This technique is incorporated in a hydrodynamic model of an evolving SNR which includes the nonlinear feedback of CRs on the SNR evolution, the production of escaping CRs along with those that remain trapped within the remnant, and the broad-band emission of radiation from trapped and escaping CRs. While our combined CR-hydro-escape model is quite general and applies to both core collapse and thermonuclear supernovae, the parameters we choose for <b>our</b> <b>discussion</b> <b>here</b> are more typical of SNRs from very massive stars whose emission spectra differ somewhat from those produced by lower mass progenitors directly interacting with a molecular cloud. Comment: Accepted in Ap...|$|R
40|$|Excerpt] In {{order to}} {{evaluate}} what the 2 ̆ 2 optimal 2 ̆ 2 level of UI benefits is, one must therefore first estimate {{the magnitude of}} the relationships between UI benefits levels and unemployed workers 2 ̆ 7 durations of unemployment and post-unemployment wages. There have been several previous studies of the impact of UI benefits on duration of spells of unemployment, however none have been completely satisfactory methodologically. To our knowledge, there have been no previous studies of the system 2 ̆ 7 s impact on subsequent wage rates. We attempt to fill these gaps, utilizing data from the National Longitudinal Survey (NLS) to estimate both relationships. The plan of our paper is as follows. First, we sketch the implications of theories of job search for our estimating equations. Next, we briefly discuss the NLS data. The following four sections summarize the empirical results we have obtained for four cohorts of data: older males, ages 45 - 59; women, ages 30 - 44; and younger males and females, ages 14 - 24. Finally, we consider the implications of our results for public policy. Due to space limitations <b>our</b> <b>discussion</b> <b>here</b> is necessarily brief and details of our research are found elsewhere...|$|R
40|$|This is the publisher’s final pdf. The {{published}} {{article is}} copyrighted by Walter de Gruyter GmbH {{and can be}} found at: [URL] many disease settings, it is likely that only a subset of the disease population will exhibit certain genetic or phenotypic differences from the healthy population. Therefore, when seeking to identify genes or other explanatory factors that might be related to the disease state, we might expect a mixture distribution of the variable of interest in the disease group. A number of methods have been proposed for performing tests to identify situations for which only a subgroup of samples or patients exhibit differential expression levels. <b>Our</b> <b>discussion</b> <b>here</b> focuses on how inattention to standard statistical theory can lead to approaches that exhibit some serious drawbacks. We present and discuss several approaches motivated by theoretical derivations and compare to an ad hoc approach based upon identification of outliers. We find that the outlier-sum statistic proposed by Tibshirani and Hastie offers little benefit over a t-test even in the most idealized scenarios and suffers from a number of limitations including difficulty of calibration, lack of robustness to underlying distributions, high false positive rates owing to its asymmetric treatment of groups, and poor power or discriminatory ability under many alternatives...|$|R
40|$|The factor Xa {{inhibitor}} apixaban {{is one of}} {{the novel}} anticoagulants to emerge as alternatives to long-standing standards of care that include low-molecular-weight heparin and warfarin. The development of apixaban reflects a strategy to optimize the clinical pharmacology profile, dosing posology, trial designs, and statistical analyses across multiple indications, and to seek alignment with global health authorities. The primary objective of dose selection was to maintain balance between efficacy and bleeding risk. Twice-daily dosing of apixaban, rather than once daily, was chosen to lower peak concentrations and reduce fluctuations between peak and trough levels. <b>Our</b> <b>discussion</b> <b>here</b> focuses on the use of apixaban for stroke prevention in nonvalvular atrial fibrillation (NVAF). Supporting this indication, a pair of registrational trials was conducted that enrolled the full spectrum of patients who, by guidelines, were eligible for anticoagulation. In the AVERROES study of patients who were unsuitable for warfarin therapy, apixaban was superior to aspirin in reducing the risk of stroke or systemic embolism (SSE), without a significant increase inmajor bleeding (MB). In theARISTOTLE (Apixaban forReduction InSTroke andOtherThromboemboLic Events inAtrial Fibrillation) study, apixabanwas superior towarfarin on the rates of SSE,MB, and all-causemortality. Overall, these studies have demonstrated a substantially favorable benefit–risk profile for apixaban over warfari...|$|R
