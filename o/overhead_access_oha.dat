0|205|Public
5000|$|One of {{the only}} known lower bounds on the <b>access</b> <b>overhead</b> of ORAMs is due to Goldreich et al. They show a [...] lower bound for ORAM <b>access</b> <b>overhead,</b> where [...] is the data size. There is also a {{conditional}} lower bound on the <b>access</b> <b>overhead</b> of ORAMs due to Boyle et al. that relates this quantity {{with that of the}} size of sorting networks.|$|R
40|$|Protocols {{like the}} Direct Access File System (DAFS) {{leverage}} user-level memory-mapped communication to enable low <b>overhead</b> <b>access</b> to network-attached storage for applications. DAFS offers {{significant improvement in}} application performance using features like direct data transfer and RDMA. Our goal is to build high performance network file servers using DAFS. The benefits of the DAFS protocol can be extended to cluster-based servers, using low overhead user-level communication within the cluster...|$|R
5000|$|Another {{important}} {{attribute of}} an ORAM construction {{is whether the}} <b>access</b> <b>overhead</b> is amortized or worst-case. Several of the earlier ORAM constructions have good amortized <b>access</b> <b>overhead</b> guarantees, but have [...] worst-case <b>access</b> <b>overheads.</b> Some of the ORAM constructions with polylogarithmic worst-case computational overheads are [...] The constructions of were for the random oracle model, where the client assumes access to an oracle that behaves like a random function and returns consistent answers for repeated queries. They also noted that this oracle could {{be replaced by a}} pseudorandom function whose seed is a secret key stored by the client, if one assumes the existence of one-way functions. The papers were aimed at removing this assumption completely. The authors of also achieve an <b>access</b> <b>overhead</b> of , which is just a log-factor away from the best known ORAM <b>access</b> <b>overhead.</b>|$|R
40|$|We {{study the}} {{trade-off}} between storage redundancy and <b>access</b> <b>overhead</b> for range queries, using {{the framework of}} [6]. We show that the Fibonacci workload of size n, which is the regular 2 -dimensional grid rotated by the golden ratio, does not admit an indexing scheme with <b>access</b> <b>overhead</b> less than the block size B (the worst possible <b>access</b> <b>overhead),</b> even for storage redundancy as high as c log n, for some constant c. We also show that this bound is tight (up to a constant factor) by providing an indexing scheme with storage redundancy Θ(log n) and constant <b>access</b> <b>overhead,</b> for any 2 -dimensional workload. We extend the lower bound to random point sets and show that if the maximum storage redundancy is less than cloglog n, the <b>access</b> <b>overhead</b> is B. Finally, we explore the relation between indexability and fractal (Hausdorff) dimension of point sets. 1 Introduction In this paper we continue the work of [6] towards a theory of indexability [...] -that is, towards a better understandin [...] ...|$|R
40|$|Abstract We {{investigate}} the tradeoff between storage redundancy and <b>access</b> <b>overhead</b> for indexing random d-dimensional point sets. We show that with high probability a range-query workload of n random points has polylogarithmic trade-off; more precisely, {{there is a}} constant cB;d such that every indexing scheme with storage redundancy cB;d logd Γ 1 n has the worst possible <b>access</b> <b>overhead</b> (equal to the block size B). We also show that this result is almost tight and that the trade-off even exhibits a threshold behavior: on a random set of points, expected storage redundancy O(logd Γ 1 n) achieves <b>access</b> <b>overhead</b> 2 d Γ 1...|$|R
40|$|Abstract. Longevity of {{distributed}} computing middleware standards, such as CORBA, {{depend on their}} ability to support a range of applications by providing low <b>overhead</b> <b>access</b> in a uniform manner to a large variety of platforms and network capabilities. OMG’s recent adaptation of Stream Control Transmission Protocol (SCTP) mapping is another instance of this trend. Applications can obtain all the benefits of this emerging protocol via a standard compliant, distributed object model. This paper reports on integration of SCTP with Adaptive Communications Framework (ACE) [2] and The Ace ORB (TAO). [3] By exploiting network path multiplexing capability of SCTP we demonstrate that CORBA applications can bound the maximum latencies they suffer under stressful network failures to under 50 msec. ...|$|R
40|$|For H. 264 /AVC decoder system, {{the motion}} {{compensation}} bandwidth comes from two parts, the reference data loading bandwidth and the equivalent bandwidth from DRAM <b>access</b> <b>overhead</b> latency. In this paper, a bandwidth-efficient cachebased MC architecture is proposed. It exploits both intra-MB and inter-MB data reuse and reduce up to 46 % MC bandwidth compared to conventional scheme. To reduce the equivalent bandwidth from DRAM <b>access</b> <b>overhead</b> latency, the DRAMfriendly data mapping and access control scheme are proposed. They can reduce averagely 89. 8 % of equivalent DRAM <b>access</b> <b>overhead</b> bandwidth. The average MC burst length {{can be improved}} to 9. 59 words/burst. The total bandwidth reduction can be up to 32 ~ 71 % compared to previous works...|$|R
40|$|NUMA (Non-Uniform Memory Access) {{multicore}} computers {{become popular}} in scientific and industrial fields {{due to its}} scalable memory performance. However, large-scale intensive data computing on NUMA architecture are facing up to the challenges in data locality problems called NUMA effects that are caused by the <b>overhead</b> <b>accesses</b> of cross-node data. Our task parallel model bases on the strategy of dynamic data placement improving system performance by reducing the frequently data access to remote memory and also by keeping load balance between each NUMA domain. The task parallel models involved OpenMP, numactl and libnuma. The evaluation demonstrates that the benchmarks using our task parallel models on a 32 -core NUMA computer with various workloads achieve system performance improvement by 50 % at least...|$|R
50|$|George G. Sharp, Inc. is a {{prominent}} naval architecture firm in New York City, founded in 1920. George G. Sharp {{was responsible for}} Savannahs design in all respects apart from the nuclear reactor, designed by Babcock & Wilcox. Savannah was the sixth large ship to have fin stabilizers, intended to enhance {{the safety of the}} reactor and to improve passenger comfort. Since the reactor occupied the center of the ship, and because the reactor required clear <b>overhead</b> <b>access</b> for a crane during refueling, the superstructure was set far back on the hull. The raked, teardrop-shaped structure was specifically designed by George G. Sharp's ship design consultant Jack Heaney and Associates of Wilton, Connecticut, for a futuristic appearance, decorated with stylized atom graphics on either side. Heaney was responsible for the interiors, which featured sleek modern styling appropriate to the atomic age.|$|R
40|$|Lars Arge Vasilis Samoladas y Jeffrey Scott Vitter z Abstract In {{this paper}} we settle several longstanding open {{problems}} in theory of indexability and external orthogonal range searching. In {{the first part}} of the paper, we apply the theory of indexability to the problem of two-dimensional range searching. We show that the special case of 3 -sided querying can be solved with constant redundancy and <b>access</b> <b>overhead.</b> From this, we derive indexing schemes for general 4 -sided range queries that exhibit an optimal tradeoff between redundancy and <b>access</b> <b>overhead...</b>|$|R
40|$|Abstract—This paper {{discusses}} energy-performance trade-off of networks-on-chip {{with real}} parallel applications. First, we propose an accurate energy-performance analytical model that conduct {{and analyze the}} impacts of both frequency-independent and frequency-dependent power. Second, we put together the communication <b>overhead,</b> memory <b>access</b> <b>overhead,</b> frequency scaling, and core count scaling to quantify the performance and energy consumed by NoCs. Third, we propose a new energy-performance optimization method, by choosing a pair of frequency and core count to get optimal energy or performance. Finally, we implement eight PARSEC parallel applications to evaluate our model and the optimization method. The experiment result confirms that our model predicts NoCs energy and performance well, and selects correct frequency level and core count for most parallel applications. Keywords—Energy; Performance; NoC I...|$|R
40|$|We {{investigate}} the tradeoff between storage redundancy and <b>access</b> <b>overhead</b> for indexing random d-dimensional point sets. We show that with high probability a range-query workload of n random points has polylogarithmic tradeoff; more precisely, {{there is a}} constant cB;d such that every indexing scheme with storage redundancy cB;d log dΓ 1 n has the worst possible <b>access</b> <b>overhead</b> (equal to the block size B). We also show that this result is almost tight and that the trade-off even exhibits a threshold behavior: on a random set of points, expected storage redundancy O(log dΓ 1 n) achieves <b>access</b> <b>overhead</b> 2 d Γ 1. 1 Introduction Indexing schemes introduced in [3] attempt to capture the intrinsic difficulty of storing large database workloads for efficient retrieval of requested data from secondary memory. Informally, an indexing scheme is a way to organize the data into a collection of disk blocks that facilitates efficient retrieval of data. In an ideal indexing scheme, w [...] ...|$|R
5000|$|Overhead: {{the use of}} locks adds <b>overhead</b> {{for each}} <b>access</b> to a resource, even when the chances for {{collision}} are very rare. (However, any chance for such collisions is a race condition.) ...|$|R
40|$|Several {{indexing}} {{techniques for}} data broadcast {{on the air}} have been proposed for power conservation on mobile computers {{in the past few}} years. Indexing techniques for broadcast channels can save battery power (estimated by tune-in time) while incurring only limited <b>overhead</b> on <b>access</b> time. In this paper, we compare indexing techniques based on the index tree and the signature methods and find that both methods prevail under different circumstances...|$|R
40|$|DAFS) {{leverage}} user-level memory-mapped {{communication to}} enable low <b>overhead</b> <b>access</b> to network-attached storage for applications. DAFS offers {{significant improvement in}} application performance using features like direct data transfer and RDMA. Our goal is to build high performance network file servers using DAFS. The benefits of the DAFS protocol can be extended to cluster-based servers, using low overhead user-level communication within the cluster. In this paper, we present Federated DAFS, a scalable and efficient cluster-based direct access file server. Federated DAFS combines an efficient user-space DAFS implementation with a low overhead clustering layer to present a scalable clustering solution for DAFS servers. Federated DAFS uses a portable mechanism for distribution and handling of client requests across the servers in the cluster. Federated DAFS also minimizes the intra-cluster communication by caching data blocks and by matching the file placement on the servers with the distribution of requests from the clients. Our results show that reasonable speedups(2. 6 on four nodes and 4. 5 on eight nodes) can be achieved using Federated DAFS on server clusters of up to eight nodes. I...|$|R
50|$|The station's main {{buildings}} {{were of a}} steel framed construction. The boiler house was clad using cellactite sheet cladding, and was of a semi-outdoor construction due to the speed of construction required. The turbine hall was a brick building with prefabricated stone used on window and door surrounds. The building's roof was made from asbestos cement. The floors in the station were made of quarry tile and terrazzo. The station's coal bunkers were steel plate and girder constructions. The entire building measured 350 ft long by 232 ft wide, containing approximately 3,800 tonnes of steel. The station also had two 300 ft tall chimneys. They were made from brick and had internal diameters of 16 ft. They were supported upon 61 ft tall concrete plinths. The administration and amenity block was built next to the station, and connected to the turbine hall by an <b>overhead</b> <b>access</b> bridge. The block contained the station's control room, along with laboratories, administration offices, a canteen, lockers and showers. It was heated by excess steam bled from the turbines.|$|R
5000|$|The Kerry Road igloos were shared {{initially}} by ANA and QANTAS, in {{the repair}} {{and maintenance of}} military aircraft for the Department of Aircraft Production. One of the middle two igloo hangars was reportedly used to remove planes' engines which were then sent to nearby Salisbury for testing. The larger igloo hangars (nos. 2 and 5) had walkways near the ridge which enabled <b>overhead</b> <b>access</b> of the planes. When U.S. forces reached the Philippines, their activities at the Kerry Road igloos ceased. From February 1945 the middle two igloo hangars were given over to the U.K.'s Royal Naval Air Service. Their transportable Aircraft Maintenance Yard No. 1, referred to as TAMY 1, assembled, repaired and flight tested aircraft for the Fleet Carrier force sent to the Pacific after Victory in Europe. Accounts of large scale dumping at sea {{of much of the}} [...] "Lease-Lend" [...] equipment from the decks of carriers, fifty miles plus off the east coast of Australia, were reported. The RAF and the Netherlands East Indies Air Force were also stationed at Archerfield from mid-1945.|$|R
5000|$|If {{the input}} program [...] uses [...] registers, the output program [...] will need [...] registers, where [...] is a {{parameter}} of the construction. [...] uses [...] memory and its (worst-case) <b>access</b> <b>overhead</b> is [...]|$|R
50|$|In 2004, Summer Hill was {{provided}} with lift facilities which are accessed from the subway. Initial plans {{called for a}} new <b>overhead</b> footbridge to <b>access</b> the station however this was opposed by locals on both aesthetic and access grounds, and the plans were subsequently altered to the current arrangement.|$|R
40|$|Abstract. The ROMIO {{implementation}} of the MPI-IO standard provides a portable infrastructure for use on top of any number of different underlying storage targets. These targets vary widely in their capabilities, {{and in some cases}} additional effort is needed within ROMIO to support all MPI-IO semantics. The MPI- 2 standard defines a class of file access routines that use a shared file pointer. These routines require communication internal to the MPI-IO implementation in order to allow processes to atomically update this shared value. We discuss a technique that leverages MPI- 2 one-sided operations and can be used to implement this concept without requiring any features from the underlying file system. We then demonstrate through a simulation that our algorithm adds reasonable <b>overhead</b> for independent <b>accesses</b> and very small <b>overhead</b> for collective <b>accesses.</b> ...|$|R
50|$|The {{station on}} a four-track section {{has a single}} island {{platform}} between center two tracks. It serves trains 12 cars long. An <b>overhead</b> bridge provides <b>access</b> to the platform, as well as unrestricted passage {{from one side of}} the station to the other. Facilities include elevators, escalators, and multipurpose toilets.|$|R
30|$|As {{shown in}} (8), {{in order to}} enhance the {{performance}} P, the variables T_shuffle, T_sync, T_extra and λ _ 1 should be reduced, while ϱ and v should be increased. In the DAE architecture, APs and EPs can work in parallel. To reduce the memory <b>access</b> <b>overhead,</b> APs accomplish most missions of memory access, and the normal memory access unit is responsible for the remaining missions of memory access. Most GEMM tasks are computations, and extra overhead makes little difference to the overall runtime. ϱ is influenced by the computation to memory <b>access</b> <b>overhead</b> ratio, and it is mainly determined by the features of the algorithm and hardware. Variables ϱ and T_extra will not be discussed in this paper. In the following subsections, the optimizations of v, T_shuffle, λ _ 1, and T_sync are mainly discussed.|$|R
5000|$|Iowa 23 {{began in}} {{downtown}} Ottumwa underneath a bridge on which US 63 passed <b>overhead.</b> Direct <b>access</b> to US 63 {{was provided by}} a ramp which connected to Kitterman Avenue. The first three quarter-miles&#32;(1.2 km) of the highway was on a one-way couplet; northbound Iowa 23 followed 2nd Street West, while southbound was on Main Street West. The two directions converged at an intersection with McPherson Street, which is located next to a level crossing of the Dakota, Minnesota and Eastern Railroad. [...] As Iowa 23 left Ottumwa, it traveled northwest on a two-lane highway with narrow shoulders.|$|R
3000|$|The work {{presented}} in [15] used a proxy AQM between the access point for WLAN and the wired network. The proxy reduces the <b>overhead</b> of the <b>access</b> point by implementing AQM functionality at the gateway. In this work the authors extend the RED/ARED scheme to a proxy mode by calculating the average queue length and updated values of [...]...|$|R
40|$|The {{goal of the}} FoxNet {{project is}} to explore the {{advantages}} (and drawbacks) of implementing networking software using an extended version of the SML language. In this report, we document {{the performance of the}} FoxNet. Using the performance results as a guide, we compare small function <b>overhead</b> and memory <b>access</b> performance of the extended SML to the dominate systems programming language C...|$|R
40|$|Abstract—The {{solid-state}} disk (SSD) {{is becoming}} increasingly popular, especially among users whose workloads exhibit substantial random access patterns. As SSD competes with the hard disk, whose per-GB cost keeps dramatically falling, the SSD must retain its performance advantages even with lowcost configurations, such as those with a small built-in DRAM cache for mapping table and using MLC NAND. To this end, {{we need to make}} the limited cache space efficiently used to support fast logical-to-physical address translation in the flash translation layer (FTL) with minimal access of flash memory and minimal merge operations. Existing schemes usually require a large number of <b>overhead</b> <b>accesses,</b> either for accessing uncached entries of the mapping table or for the merge operation, and achieve suboptimal performance when the cache space is limited. In this paper we take into account spatial locality exhibited in the workloads to obtain a highly efficient FTL even with a relatively small cache, named as S-FTL. Specifically, we identify three access patterns related to spatial locality, including sequential writes, clustered access, and sparse writes. Accordingly we propose designs to take advantage of these patterns to reduce mapping table size, increase hit ratio for in-cache address translation, and minimize expensive writes to flash memory. We have conducted extensive trace-driven simulations to evaluate S-FTL and compared it with other state-of-the-art FTL schemes. Our experiments show that S-FTL can reduce accesses to the flash for address translation by up to 70 % and reduce response time of SSD by up to 25 %, compared with the stateof-the-art FTL strategies such as FAST and DFTL. I...|$|R
40|$|As {{an energy}} carrier, {{electricity}} has no rival {{with regard to}} its environmental cleanliness, flexibility in interfacing with multiple production sources and end uses, and efficiency of delivery. In fact, the electric power grid was named ?the greatest engineering achievement of the 20 th century? by the National Academy of Engineering. This grid, a technological marvel ingeniously knitted together from local networks growing out from cities and rural centers, {{may be the biggest}} and most complex artificial system ever built. However, the growing demand for electricity will soon challenge the grid beyond its capability, compromising its reliability through voltage fluctuations that crash digital electronics, brownouts that disable industrial processes and harm electrical equipment, and power failures like the North American blackout in 2003 and subsequent blackouts in London, Scandinavia, and Italy in the same year. The North American blackout affected 50 million people and caused approximately $ 6 billion in economic damage over the four days of its duration. Superconductivity offers powerful new opportunities for restoring the reliability of the power grid and increasing its capacity and efficiency. Superconductors are capable of carrying current without loss, making the parts of the grid they replace dramatically more efficient. Superconducting wires carry up to five times the current carried by copper wires that have the same cross section, thereby providing ample capacity for future expansion while requiring no {{increase in the number of}} <b>overhead</b> <b>access</b> lines or underground conduits. Their use is especially attractive in urban areas, where replacing copper with superconductors in power-saturated underground conduits avoids expensive new underground construction. Superconducting transformers cut the volume, weight, and losses of conventional transformers by a factor of two and do not require the contaminating and flammable transformer oils that violate urban safety codes. Unlike traditional grid technology, superconducting fault current limiters are smart. They increase their resistance abruptly in response to overcurrents from faults in the system, thus limiting the overcurrents and protecting the grid from damage. They react fast in both triggering and automatically resetting after the overload is cleared, providing a new, self-healing feature that enhances grid reliability. Superconducting reactive power regulators further enhance reliability by instantaneously adjusting reactive power for maximum efficiency and stability in a compact and economic package that is easily sited in urban grids. Not only do superconducting motors and generators cut losses, weight, and volume by a factor of two, but they are also much more tolerant of voltage sag, frequency instabilities, and reactive power fluctuations than their conventional counterparts. The challenge facing the electricity grid to provide abundant, reliable power will soon grow to crisis proportions. Continuing urbanization remains the dominant historic demographic trend in the United States and in the world. By 2030, nearly 90 % of the U. S. population will reside in cities and suburbs, where increasingly strict permitting requirements preclude bringing in additional <b>overhead</b> <b>access</b> lines, underground cables are saturated, and growth in power demand is highest. The power grid has never faced a challenge so great or so critical to our future productivity, economic growth, and quality of life. Incremental advances in existing grid technology are not capable of solving the urban power bottleneck. Revolutionary new solutions are needed ? the kind that come only from superconductivity...|$|R
30|$|In Algorithm 1, most <b>overheads</b> {{of memory}} <b>access</b> are {{concealed}} by the computing time. However, {{the time of}} loading matrix B to the locked L 3 cache cannot be concealed. The overhead of loading matrix B will influence overall performance. To solve this problem, an optimized algorithm is proposed, in which the time of preloading the matrix B can be concealed, as shown in Algorithm 2.|$|R
50|$|Depending {{upon its}} {{underlying}} computer architecture, {{the performance of}} a computer may be hindered by unaligned access to memory. For example, a 16-bit computer with a 16-bit memory data bus, such as Intel 8086, generally has less <b>overhead</b> if the <b>access</b> is aligned to an even address. In that case fetching one 16-bit value requires a single memory read operation, a single transfer over a data bus.|$|R
40|$|Abstract. This poster {{proposes a}} file system as an {{abstraction}} layer for a uniform way of accessing any system resource on wireless sensor nodes. Even functions and libraries {{can be represented}} and accessed in this uniform way allowing developers a novel way to design and implement applications. A lightweight implementation on our Particle Computer platform is described and performance measurements prove small <b>overhead</b> for resource <b>access.</b> 1...|$|R
40|$|Accessing the {{relevant}} data in Big Data scenarios is increasingly difficult both for end-user and IT-experts, {{due to the}} volume, variety, and velocity dimensions of Big Data. This brings a hight cost <b>overhead</b> in data <b>access</b> for large enterprises. For instance, in {{the oil and gas}} industry, IT-experts spend 30 – 70 % of their time gathering and assessing the quality of data [1]. The Optique projec...|$|R
40|$|In {{this paper}} we propose a {{mechanism}} to develop a lightweight encryption technique. We encrypt hierarchical single key-lock access control mechanism key by encoding key (key number). Key number is derived using Chinese reminder theorem and tribes of Gaussian or rational Farey fractions are used to encode the key number. The advantages of the proposed mechanism are i) no decoding <b>overhead</b> as <b>access</b> rights are derived without decoding the encoded the key number, ii) no need to derive the key number for already existing files. Hence this method secures access control system by encoding the key number and acts as a thin layer of security; however the performance of retrieval system remains unchanged...|$|R
40|$|Active Messages (AM) is a {{lightweight}} messaging protocol used to optimize network communications {{with an emphasis}} on reducing latency by removing software overheads associated with buffering and providing applications with direct user-level access to the network hardware [1]. AM provides low-level asymmetric network messaging primitives which have come into popular use as a low-level substrate in the implementations of higher-level parallel languages and systems, for example MPI, Split-C, Titanium, and others [10], [15], [16]. Most implementations of AM are highly hardware-specific, and in particular they usually require the support of high-performance, non-commodity "smart" network interfaces such as Myrinet [12]. This unfortunately presents a problem when trying to run AM-based software on systems that have commodity network interface hardware, or network interfaces for which no AM implementation is readily available. This first part of this project attempts to bridge that gap by providing an AM- 2 implementation that runs on UDP, a standard component of the TCP/IP protocol suite that is ubiquitous across platforms and operating systems [13]. We don't expect to achieve latency performance competitive with a native implementation of AM optimized for special purpose hardware, instead we seek to provide a compatibility layer that will allow AM-based systems to quickly get up and running on virtually any platform. The motivation for choosing UDP over other protocols (such as TCP) is that it typically provides the lowest <b>overhead</b> <b>access</b> to the network with little or no internal buffering, and the connectionless model is best suited for scaling up the number of distributed processors. Because UDP occasionally drops packets, we add a thin reliability layer that provides the [...] ...|$|R
40|$|Multi-dimensional storage {{virtualization}} (MDSV) allows multiple virtual disks, {{each with}} a distinct combination of capacity, latency and bandwidth requirements, to be multiplexed on a physical disk storage system with performance isolation. This paper presents novel design and implementation techniques that solve the availability guarantee and fairness assurance problems in multi-dimensional storage virtualization. First, we show that a measurementbased admission control algorithm can reduce the effective resource requirement of a virtual disk with availability guarantee by accurately estimating its resource needs without prior knowledge of its input workload characteristics. Moreover, to accurately factor disk <b>access</b> <b>overhead</b> into real-time disk request scheduling algorithm, we propose a virtual disk switching overhead extraction and distribution algorithm that can derive the intrinsic disk <b>access</b> <b>overhead</b> associated with each virtual disk so as to achieve perfect performance isolation. Finally, we develop an adaptive server time leap-forward algorithm to effectively address the short-term unfairness problem of virtual clock-based disk scheduler, the only known proportional-share scheduler {{that is based on}} wall-clock time and thus enables disk utilization efficiency optimization while delivering disk QoS guarantees. ...|$|R
40|$|Most {{existing}} {{studies on}} association rules discovery focused on finding the association rules between all items {{in a large}} database that satisfy user-specified minimum confidence and support. In practice, users are often interested in finding association rules involving only some specified items. Meanwhile, based on the search results in former queries, users tend to change the minimal confidence and support requirements to obtain suitable number of rules. Under these constraints, the existing mining algorithms can not perform efficiently due to high and repeated disk <b>access</b> <b>overhead.</b> In this research, we present a novel mining algorithm that can efficiently discover the association rules between the user-specified items or categories via feature extraction approach. At most one scan of the database is needed for each query; hence, the disk <b>access</b> <b>overhead</b> can be reduced substantially and the query be responded quickly. 1 1. Introductions Data mining {{is the process of}} extracting previously unknown and useful information from a large database. It has been extensively applied {{to a wide variety of}} applications like sale...|$|R
40|$|It is {{frequently}} needed to compile stack-machine codes into register-machine codes. One important optimization in such compilers is reducing the stack <b>access</b> <b>overhead.</b> But an effective mapping of stack values into registers is not straightforward. In this article, {{we present a}} formal yet effective technique of inferring {{the two types of}} each stack value. We infer the type of a stack value when it is pushed (push-type) and the type when it is used (pop-type). These two type information is safely estimated across the basic blocks by a global data-flow analysis. Using this type information, we can safely use as many typed registers as possible in storing stack values. We implemented our analysis for a real compiler and its experiments show that the speed-up is 5 % to 24 %. 1 Problem and Our Approach It {{is frequently}} needed to compile stack-machine codes into register-machine codes [ATCL+ 98, Ert 96, TvSKS 83]. Stack-machine codes are used widely as intermediate languages, while most computers are register machines. One important optimization in such compilers is reducing the stack <b>access</b> <b>overhead.</b> Stack...|$|R
