9|53|Public
50|$|Contributing to the <b>overall</b> <b>assurance</b> of {{the meeting}} {{according}} to the local people a high school {{was established in the}} year of 1939 beside Dhakuria Marker. In the same year the school was well recognized by the University of Calcutta.|$|E
30|$|The Morse {{potential}} {{allows the}} network to release high-cost links {{that have an}} effect on the <b>overall</b> <b>assurance</b> of end-to-end connectivity.|$|E
30|$|In our simulations, backbone-to-backbone links, of {{critical}} importance in the network architecture, are modeled using the convex model with exponential constraint, while the backbone-to-terminal links are modeled using the Morse potential. We measured {{the average number of}} SD connections maintained and showed a significant improvement when using the hybrid energy model. The use of the Morse potential at the backbone-to-terminal links allows the network to release high-cost links that {{have an effect on the}} <b>overall</b> <b>assurance</b> of end-to-end connectivity. Results suggest a more significant improvement the more restrictive the physical constraints, such as the maximum transmission power and the mobility of terminal nodes.|$|E
40|$|This study {{investigates the}} effects of two {{technical}} enablers: Automatic Dependent Surveillance - Broadcast (ADS-B) and digital datalink communication, of the Federal Aviation Administration s Next Generation Air Transportation System (NextGen) under two separation assurance (SA) system architectures: ground-based SA and airborne SA, on <b>overall</b> separation <b>assurance</b> performance. Datalink performance such as successful reception probability in both surveillance and communication messages, and surveillance accuracy are examined in various operational conditions. Required SA performance is evaluated {{as a function of}} subsystem performance, using availability, continuity, and integrity metrics to establish <b>overall</b> required separation <b>assurance</b> performance, under normal and off-nominal conditions...|$|R
40|$|Radiocarbon {{laboratories}} undertake rigorous programmes {{of internal}} quality control (QC) and <b>overall</b> quality <b>assurance</b> (QA). In a laboratory "inter-comparison" 1 {{samples of the}} same age are dated at different laboratories using a range of techniques and the results are then compared. The authors summarise the results of the fourth of these scientific audits...|$|R
50|$|Global Information Grid Command Control, or GIG/C2 - The Global Information Grid Command Control, or GIG/C2, are two {{combined}} {{sectors that}} support <b>overall</b> asset <b>assurance</b> for CIP. The GIG is the globally interconnected set of personnel, information, and communication capabilities {{necessary to achieve}} information superiority. C2 includes assets, facilities, networks, and systems that support mission accomplishment. The Defense Information Systems Agency, or DISA, is the lead component responsible for Global Information Grid Command Control.|$|R
40|$|In {{this paper}} we develop an evidential network model for “WebTrust Assurance,” a service {{recently}} {{proposed by the}} American Institute of Certified Public Accountants and the Canadian Institute of Chartered Accountants. Our model augments the AICPA/CICA approach and presents five categories of assertions related to providing WebTrust Assurance. We then derive goals, sub-goals and evidence {{that are related to}} the <b>overall</b> <b>assurance</b> to be provided. The aggregation of evidence and the resolution of uncertainties in the model follow the approach of Dempster-Shafer theory of belief functions. Next we consider the assurance planning problem and develop a decision theoretic model for this problem...|$|E
40|$|In {{order to}} provide {{certified}} security services we must provide indicators that can measure the level of assurance that a complex business process can offer. Unfortunately the formulation of security indicators is not amenable to efficient algorithms able to evaluate the level of assurance of complex process from its components. In this paper we show an algorithm based on FD-Graphs (a variant of directed hypergraphs) {{that can be used}} to compute in polynomial time (i) the <b>overall</b> <b>assurance</b> indicator of a complex business process from its components for arbitrary monotone composition functions, (ii) the subpart of the business process that is responsible for such assurance indicator (i. e. the best security alternative) ...|$|E
40|$|Assurance {{has been}} {{identified}} as a key service quality dimension but has not attracted theoretical and empirical attention on a distinct basis. The present pilot study adopts both qualitative and quantitative methods to look at how distinct customer groups (internal and external) perceive assurance in particular when they evaluate service quality. Evidence comes from 83 individuals of the medical staff and 79 patients at an outpatient unit. The novelty of the present study lies in the combination of means-end analysis with a probabilistic model to ground the conceptually appealing composite structure of assurance on a more concrete attribute foundation. Findings suggest that while the groups under investigation realize different benefits in achieving assurance, they share a common guide when prioritizing service-related attributes, namely the professional capacity of personnel. <b>Overall,</b> <b>assurance</b> proves itself to be critical, at least for the healthcare sector...|$|E
40|$|Genetic {{testing has}} moved rapidly from {{research}} to clinical {{use and the}} issues of quality have not always received sufficient attention. In response to these needs to improve the <b>overall</b> quality <b>assurance</b> system for genetic testing and services {{there have been several}} international initiatives that are reviewed here. The main activities at European level towards improving the quality assurance of genetic testing are described. JRC. J. 5 -Agriculture and Life Sciences in the Econom...|$|R
40|$|This paper explores {{generating}} and conveying {{confidence in}} enterprise security. An enterprise assurance framework provides a structure enterprise assurance evidence that strengthens and clarifies the <b>overall</b> enterprise <b>assurance</b> argument. The structure and components of these arguments are defined and then applied to an enterprise. Finally, standards {{of evidence and}} evidence trade-offs are mentioned. This paper is largely based on a recent NIST internal report called "A Framework for Reasoning about Assurance. "...|$|R
2500|$|Global Information Grid Command Control, or GIG/C2 - The Global Information Grid Command Control, or GIG/C2, are two {{combined}} {{sectors that}} support <b>overall</b> asset <b>assurance</b> for CIP. [...] The GIG is the globally interconnected set of personnel, information, and communication capabilities {{necessary to achieve}} information superiority. C2 includes assets, facilities, networks, and systems that support mission accomplishment. [...] The Defense Information Systems Agency, or DISA, is the lead component responsible for Global Information Grid Command Control.|$|R
40|$|Deforestation and {{degradation}} {{are tied to}} a complex array of socioeconomic and political factors. Many assume that {{among the most important}} of these are the particular bundles of rights regulating who can benefit from land (tenure form) and the <b>overall</b> <b>assurance</b> that those rights will be upheld (tenure security). This paper reviews literature that connects forest outcomes and land tenure to better understand broad interactions between tenure form, security and forest change. Papers from economic theory suggest tenure is embedded in a broader socioeconomic context, with the potential for either a positive or negative conservation impact on forested land. Empirically, we find 36 publications that link land cover change to tenure conditions while also controlling for other plausibly confounding variables. Publications often investigate more than one site and more than one form of tenure, so from these we derive 118 cases linking forest change with a specific tenure form in a particular location. From these cases, we find evidence that protected areas are associated with positive forest outcomes and that land tenure security is associated with less deforestation, regardless of the form of tenure. We conclude with a call for more robust identification of this relationship in future research, as well as set of recommendations for policymakers, particularly as forest carbon incentive programs such as REDD integrate further into national policies...|$|E
40|$|There {{has been}} a {{significant}} amount of work devoted to the static verification of security protocol designs Virtually all of these results, when applied to an actual implementation of a security protocol, rely on certain implicit assumptions on the implementation (for example, that the cryptographic checks that according to the design have to be performed by the protocol participants are carried out correctly) So far {{there seems to be no}} approach that would enforce these implicit assumptions for a given implementation of a security protocol (in particular regarding legacy implementations which have not been developed with formal verification in mind) In this paper, we use a code assurance technique called "runtime verification" to solve this open problem Runtime verification determines whether or not the behaviour observed during the execution of a system matches a given formal specification of a "reference behaviour". By applying runtime verification to an implementation of any of the participants of a security protocol, we can make sure during the execution of that implementation that the implicit assumptions that had to be made to ensure the security of the overall protocol will be fulfilled The <b>overall</b> <b>assurance</b> process then proceeds in two steps First, a design model of the security protocol in UML is verified against security properties such as secrecy of data Second, the implicit assumptions on the protocol participants are derived from the design model, formalised in linear-time temporal logic, and the validity of these formulae at runtime is monitored using runtime verification The aim is to increase one's confidence that statically verified properties are satisfied not only by a model of the system, but also by the actual running system Itself We demonstrate the approach at the hand of the open source implementation Jessie of the de-facto Internet security protocol standard SSL We also briefly explain how to transfer the results to the SSL-implementation within the Java Secure Sockets Extension (JSSE) recently made open source by Sun Microsystems...|$|E
40|$|This {{dissertation}} {{examines the}} association between corporate social responsibility (CSR) assurance and firm value. This study contributes {{to the understanding of}} the economic benefits inherent in CSR assurance by investigating the incremental value added to firms by assurance. This study also explores CSR assurance quality in both Australia and New Zealand, two countries that are rarely examined. The research adopts a signalling theory view of CSR assurance, where assurance acts as a signal of disclosure quality. The quality of assurance statements has been examined using a content analysis approach. Content analysis generates quality scores that enable quantitative analysis of the effects of CSR assurance quality on firm value. The results show that CSR assurance is value-relevant, but assurance quality is not. Results remained true even after controlling for CSR performance, country and industry effects. The current study also finds that CSR assurance quality is lower when produced by an accountant, and that better governance mechanisms increase assurance statement quality. In addition to the CSR assurance quality score, scholars associate several other attributes with assurance quality. These attributes include the level of assurance and the type of assurance provider. The level of assurance and the type of assurance provider constitute signals about CSR assurance quality. These attributes are also examined to determine their effect on firm value. The results do not show any significant effect of CSR assurance quality on firm value, either from the <b>overall</b> <b>assurance</b> quality score or from the attributes of quality. This research has implications for companies, standard setters and assurance providers. Companies may benefit from adopting CSR assurance. Since the quality of assurance does not communicate any effective signal, it may be important for companies, standard setters and assurance providers to collaborate to improve assurance standards to achieve higher quality, in order to minimise the possibility of falsified signalling through substandard reporting and poor assurance quality. There are many opportunities for future research on the economic benefits of CSR assurance. Future research should look into conducting a longitudinal study on CSR assurance quality. Future research should also examine the effect of assurance and its quality on firm value at different points of time and with various types of CSR disclosure...|$|E
40|$|Seeking and {{achieving}} formal Certification and Accreditation of systems {{designed for use}} within the Department of Defense is a statutory requirement and {{a necessary part of}} a system's <b>overall</b> Information <b>Assurance</b> program. A singular focus on this "process " objective, however, too often overshadows critical Information Assurance engineering activities necessary during system design. This problem is particularly acute in tactical system developments. This guide attempts to chart a course for the tactical system develope [...] . Copyright SANS Institut...|$|R
40|$|Between 1994 and 2009, the Dr Gustavo Aldereguía University Hospital of Cienfuegos, Cuba {{implemented}} {{a series of}} interventions that reduced acute myocardial infarction case fatality rate from 47 % to 15 %. These interventions {{were part of an}} institutional plan for myocardial infarction included in the hospital's <b>overall</b> quality <b>assurance</b> strategy. Outcomes resulted primarily from organizational changes (from upgrading of the hospital emergency department and provincial emergency system to creation of a comprehensive coronary care unit and a chest pain center); optimizing use of effective drugs (streptokinase, aspirin, ACE inhibitors and beta blockers); adherence to clinical practice guidelines; and continual and participatory evaluation and adjustment...|$|R
40|$|This Quality Assurance Project Plan (QAPP) {{provides}} the <b>overall</b> quality <b>assurance</b> (QA) program requirements and general quality practices {{to be applied}} to the U. S. Department of Energy (DOE), National Nuclear Security Administration Nevada Site Office (NNSA/NSO) Underground Test Area (UGTA) Sub-Project (hereafter the Sub-Project) activities. The requirements in this QAPP are consistent with DOE Order 414. 1 C, Quality Assurance (DOE, 2005); U. S. Environmental Protection Agency (EPA) Guidance for Quality Assurance Project Plans for Modeling (EPA, 2002); and EPA Guidance on the Development, Evaluation, and Application of Environmental Models (EPA, 2009). The QAPP Revision 0 supersedes DOE [...] 341, Underground Test Area Quality Assurance Project Plan, Nevada Test Site, Nevada, Revision 4...|$|R
5|$|Shortly after Wang Zhizhi {{refused to}} return to China {{to play for the}} {{national}} team and was subsequently banned from playing for China, the CBA stipulated that Yao would have {{to return to}} play for the national team. They also said they would not let him go to the United States unless the Houston Rockets would take him first <b>overall.</b> After <b>assurances</b> from Team Yao that the Rockets would draft Yao with their number one pick, the CBA gave permission {{on the morning of the}} draft for Yao to play in the U.S. When the Rockets selected Yao with the first pick of the draft, he became the first international player ever to be selected first overall without having previously played U.S. college basketball.|$|R
40|$|The use {{of health}} based {{information}} in mission planning offers {{the opportunity to}} significantly enhance <b>overall</b> mission <b>assurance.</b> Developing mission concepts, even at a simple level, requires coordination of multiple assets and determination of common interfaces suitable for heterogeneous fleets. For systems that are subject to real failures, simulation offers the challenges of developing realistic scenarios and realistic health emulation. An alternative explored here {{is the use of}} indoor, rapid prototyping labs for exploring larger scale, heterogeneous mission concepts. Of particular interest are persistent missions were faults are a key driver in the aggregate mission performance. Results of flight tests with several different sample missions will be presented. These missions range from non-cooperative to cooperative and include a range of tasks. I...|$|R
50|$|Shortly after Wang Zhizhi {{refused to}} return to China {{to play for the}} {{national}} team and was subsequently banned from playing for China, the CBA stipulated that Yao would have {{to return to}} play for the national team. They also said they would not let him go to the United States unless the Houston Rockets would take him first <b>overall.</b> After <b>assurances</b> from Team Yao that the Rockets would draft Yao with their number one pick, the CBA gave permission {{on the morning of the}} draft for Yao to play in the U.S. When the Rockets selected Yao with the first pick of the draft, he became the first international player ever to be selected first overall without having previously played U.S. college basketball.|$|R
40|$|EPA {{does not}} {{consider}} this internal planning document an official Agency dissemination of information under the Agency's Information Quality Guidelines, {{because it is not}} being used to formulate or support a regulation or guidance; or to represent a final Agency decision or position. This planning document describes the <b>overall</b> quality <b>assurance</b> approach that will be used during the research study. Mention of trade names or commercial products in this planning document does not constitute endorsement or recommendation for use. The EPA Quality System and the HF Research Study EPA requires that all data collected for the characterization of environmental processes and conditions are of the appropriate type and quality for their intended use. This is accomplished through an Agency-wide quality system for environmental data. Components of the EPA quality system can be found a...|$|R
40|$|The continuous-energy {{neutron data}} library ENDF 60, {{for use with}} the Monte Carlo N-Particle {{radiation}} transport code MCNP 4 A, was released {{in the fall of}} 1994. It is comprised of 124 nuclide data files based on the ENDF/B-Vi evaluations through Release 2. Forty-eight percent of these materials are new or modified evaluations, while the balance are translations from ENDF/B-V. The new evaluations include most of the important materials for criticality safety calculations, and include significant enhancements such as more isotopic evaluations, better resonance-range representations, and the new correlated energy-angle distributions for emitted particles. As part of the <b>overall</b> quality <b>assurance</b> testing of the ENDF 60 library, calculations for well known benchmark assemblies were performed. The results of these calculations help the user to know how the combination of ENDF 60 and MCNP 4 A will perform for real problems...|$|R
30|$|The {{research}} has assessed the <b>overall</b> software quality <b>assurance</b> practices of practitioners in a developing country. The research which was {{spurred by the}} need to reduce the level of importation of software into Nigeria and increase the level of patronage of indigenous software organizations has unveiled some potential reasons for {{the current state of the}} industry. Recommendations have been made to tackle the current menace and improve quality software practices which if adhered to would lead to the production of quality software packages that would be patronized and stand the test of time.|$|R
40|$|Although {{effective}} management of frontline employees has been commonly considered {{a key element}} in quality management in both practice and academia, the predominant focus has been on work force training, development, empowerment, involvement, and incentive systems, without utilizing the benefit of understanding the frontline worker’s personality and perception of the work environment. This paper utilized the 16 Personality Inventory (16 PF) and Work Environment Scale (WES) to explore the relationship of frontline employee’s personality and perception of the work environment to their quality assurance performance ratings in a mediumsized manufacturing company in America. By using 16 PF and WES Real Form, Vigilance (factor L) and Work Pressure were discovered to be positively correlated with the frontline workers’ <b>overall</b> quality <b>assurance</b> performance ratings. Caution of generalization of the research result was raised in Discussion section. Recommendations for future research were presented. Yichun CaoCrowder, CindyCarroll GrahamKathy Ginter,Master’s Degree of Human Resource DevelopmentHuman Resource Development and Performance TechnologiesCunningham Memorial Library, Terre Haute, Indiana State UniversityGS 201009 MastersTitle from document title page. Document formatted into pages: contains 101 p. : ill. Includes bibliography, abstract and appendix...|$|R
40|$|The first {{international}} round-robin exercise for {{the measurement of}} the long-lived radionuclide 10 Be has been conducted. Ten participating accelerator mass spectrometry (AMS) facilities have each measured three samples at the 10 − 12 to 10 − 1410 Be/ 9 Be level. All results have been made traceable to the NIST SRM 4325 standard to avoid additional discrepancies that arise when different facilities use different calibration materials. Hence, the data concentrates on pure measurement distinctions. Multivariate statistical investigations have been performed to reveal a bias between facilities, i. e. two distinguished groups could be identified. Maximum discrepancies between two single facilities {{are in the range}} of 6 - 31 % depending on the absolute 10 Be/ 9 Be value. These findings should be considered when comparing 10 Be data produced at one AMS facility with that produced at another facility, which is e. g. often the case for in situ 10 Be dating studies. Round-robin exercises are a very helpful tool as part of an <b>overall</b> quality <b>assurance</b> scheme to improve the accuracy, and not only the precision, of AMS data...|$|R
40|$|The ICT is {{the need}} of the hour for quality {{assurance}} in Higher Education as it fastens the process of assessment and audit with greater transparency. It is a model {{that can be used}} in assessing the quality of education in Colleges of the University. The procedure of this study uses the techniques of research and development with the following steps: (i) development of ICT model (ii) analysis of the model impact on the performance of the affiliated colleges. The <b>overall</b> quality <b>assurance</b> framework followed by National Assessment and Accreditation Council (NAAC) incorporates elements of all the three basic approaches to quality assurance – accreditation, assessment and academic audit. NAAC accredits institutions and certifies for the educational quality of the institution. It also goes beyond the certification and provides an assessment that classifies an institution on a nine-point scale indicating where the institution stands in the quality continuum. This paper focus on the first two criterions identified by NAAC to serve as the basis for its assessment procedure: Curricular Aspects Criterion, Teaching Learning and Evaluatio...|$|R
40|$|Many {{molecular}} {{diagnostic laboratories}} have evolved from research laboratories, initially performing low numbers of homebrew assays, but many laboratories now perform more kit-based assays, with ever increasing test volumes. One such assay is assessment of {{bone marrow transplantation}} engraftment. Allogeneic bone marrow transplantation is performed primarily {{in the treatment of}} hematological malignancies. Monitoring of engraftment was traditionally evaluated using minisatellites (variable number tandem repeats) and Southern blotting, but most laboratories now use Food and Drug Administration-cleared microsatellite (short tandem repeats) kits to assess the extent of engraftment. With the increase in equipment reliability, the use of kit-based assays, and the desire to provide the highest quality clinical data, we began applying traditional clinical pathology quality control tools to the molecular diagnostics laboratory. In this study, we demonstrate this approach using a microsatellite-based bone marrow engraftment assay. We analyzed control samples (pure and mixed) for two different microsatellites to establish quality control parameters and constructed Levey-Jennings charts to monitor both the precision and accuracy of this assay. By incorporating these tools into an <b>overall</b> quality <b>assurance</b> program, a laboratory can identify systematic errors and perform corrective actions before actual assay failure, thereby improving the quality of patient care...|$|R
40|$|Abstract—In this work, {{we propose}} {{to apply the}} {{conjugate}} gradient algorithm to the sparse systems; we encounter these in the system admittance matrices, and we will search for a numerical solution to this system using the locally optimal steepest descent method. The system admittance matrices for an IEEE 30 -bus or 57 -bus system(s) are too large to be handled by direct methods like the Cholesky decomposition method. Hence, we will {{make use of the}} flexible preconditioned conjugate-gradient method, which makes use of sophisticated preconditioners, leading to variable preconditioning that change between successive iterations. The Polak–Ribière formula, a highly efficient preconditioner, is applied to the system, to yield drastic improvements in convergence. Our experimental results include a comparison of the Krylov subspace method with traditional methods, assuming the IEEE five-busbar, seven-line reference system as the common basis for all load-flow analysis. The system base quantities are VAbase = 100 MVA and Vbase = 132 kV. The results show an <b>overall</b> better <b>assurance</b> of convergence for all general systems, a lesser dependence on starting voltage profiles assumption and a robustness and efficiency of computation for well-conditioned systems. Keywords- Krylov subspace methods, conjugate gradient algorithm, preconditioners, Polak–Ribière formula, assured convergence. I...|$|R
40|$|Abstract—Vulnerability {{analysis}} is one among the important components of <b>overall</b> software <b>assurance</b> practice. Buffer over-flow (BoF) {{is one example}} of the such vulnerabilities and it is still the root cause of many effective attacks. A general practice to find BoF is to look for the presence of certain functions that manipulate string buffers, like the strcpy family. In these functions, data is moved from one buffer to another, within a loop, without considering destination buffer size. We argue that similar behaviour may also be present in many other functions that are coded separately, and therefore are equally vulnerable. In the present work, we investigate the detection of such functions by finding loops that exhibit similar behaviour. We call such loops Buffer Overflow Inducing Loops (BOIL). We implemented a lightweight static analysis to detect BOILs, and evaluated it on real-world x 86 binary executables. The results obtained show that this (simple but yet efficient) vulnerability pattern happens to be very effective in practice to retrieve real vulnerabilities, providing a drastic reduction of the part of the code to be analysed. Index Terms—Buffer overflow, security vulnerability, depen-dency chain, loop detection, static analysis, binary code. I...|$|R
40|$|Evaluation is {{a central}} element in the <b>overall</b> quality <b>assurance</b> of {{teaching}} and learning in higher education. For a Study Board or study unit is it important to have designed assessments procedures directed towards management, teaching and learning. Among theorists many epistemological and ideological positions exists on the nature of evaluation, on how to conduct one as well as on how to present and on how to use the generated results [1]. The School of Basic Studies at Aalborg University, Denmark, operates an internal quality assurance system which combines summative and formative assessment methods at different levels. Internal evaluation is according to Love [2] characterized by the use of internal staff or contractors closely bound to the organization to conduct evaluation activities. Programs and problems of direct relevance to the management of the organisations is the usual focus. Remedying problems, not only diagnosing them and developing recommendations, are a purpose. The faster problems can be remedied the better, for the benefits of the organisation, the clients (the students and professors) and the stakeholders, internal (study boards of later semesters) and external (industry). The article describes the setup of the internal evaluation system in detail...|$|R
40|$|Taiwan {{has shifted}} from {{harvesting}} whales and dolphins to protecting all cetacean species since 1990. Whales and dolphins have become major tourist attractions. With an eye on foreseeable future growth and increasing concerns about environmental impact, service delivery, and educational efficacy, the government seeks to achieve the <b>overall</b> quality <b>assurance</b> of whale/dolphin watching tourism by introducing an ecolabelling program. The {{aim of this study}} is to examine this program by analyzing its impact on tour operators and visitors. A survey method was used to assess the impact. The results showed that the program is having a positive impact on operators by seeking environmental sustainability and has brought about educational benefits for visitors, including: site-based knowledge, awareness of marine conservation and reinforcing intentions to perform environmentally responsible behaviors. However, money cost is a major factor discouraging tour operator's participation, even though ecolabels help to construct an image of responsibility. With potential educational benefits for visitors in mind, the study highlights the need for increasing public awareness of the program, expanding marketing of ecolabelled products, and providing economic incentives for tour operators to engage in ecolabelling. Whale/dolphin watching tourism Ecolabelling Environmental responsibility Taiwan...|$|R
40|$|Patients usually undergo {{repeated}} X-ray examinations {{after their}} initial X-ray radiographs are rejected due to poor image quality. This subjects the patients to an excess radiation exposure and extra cost and necessitates {{the need to}} investigate the causes of reject. The use of reject analysis {{as part of the}} <b>overall</b> quality <b>assurance</b> programs in clinical radiography and radiology services is vital in the evaluation of image quality of a well-established practice. It is shown that, in spite of good quality control maintained by the Radiology Department of a Teaching hospital in Ghana, reject analysis performed on a number of radiographic films developed indicated 14. 1 % reject rate against 85. 9 % accepted films. The highest reject rate was 57. 1  ±  0. 7 % which occurs in cervical spine and the lowest was 7. 7  ±  0. 5 % for lumbar spine. The major factors contributing to film rejection were found to be over exposure and patient positioning in cervical spine examinations. The most frequent examination was chest X-ray which accounts for about 42. 2 % of the total examinations. The results show low reject rates by considering the factors for radiographic rejection analysis in relation to both equipment functionality and film development in the facility...|$|R
40|$|Background: Quality {{assurance}} is a prevention-oriented {{system that}} can be used to improve the quality of care, increase productivity and monitor the performance management in clinical laboratories. ISO 9001 : 2000 requirements are a collection of management and technical systems designed to implement quality assurance and monitor performance management in organizations. Methods: A checklist was prepared to monitor the preanalytical, analytical and postanalytical stages of laboratory performance management in 16 areas and all laboratory activities in 14 of the clinical laboratories of the Tehran University of Medical Sciences (TUMS) hospitals. Collected data were stored and statistically analyzed using SPSS software. Results: The best performance, in which 77. 73 % of quality assurance indicators were observed, was found in Sina Hospital. However, only 57. 56 % of these indicators were fulfilled at Farabi Hospital, with the lowest-level performance among the clinical laboratories of TUMS hospitals. The highest level of compliance with quality assurance indicators was in the hematology departments and for facility demands in management areas. <b>Overall,</b> quality <b>assurance</b> indicators were appropriately followed in only 7 % of the clinical laboratories. Conclusion: The average quality assurance observation rate in the clinical laboratories studied was 67. 22 %, which is insufficient and must be remedied with stricter enforcement of the ISO 9001 : 2000 regulations...|$|R
40|$|AbstractPatients usually undergo {{repeated}} X-ray examinations {{after their}} initial X-ray radiographs are rejected due to poor image quality. This subjects the patients to an excess radiation exposure and extra cost and necessitates {{the need to}} investigate the causes of reject. The use of reject analysis {{as part of the}} <b>overall</b> quality <b>assurance</b> programs in clinical radiography and radiology services is vital in the evaluation of image quality of a well-established practice. It is shown that, in spite of good quality control maintained by the Radiology Department of a Teaching hospital in Ghana, reject analysis performed on a number of radiographic films developed indicated 14. 1 % reject rate against 85. 9 % accepted films. The highest reject rate was 57. 1  ±  0. 7 % which occurs in cervical spine and the lowest was 7. 7  ±  0. 5 % for lumbar spine. The major factors contributing to film rejection were found to be over exposure and patient positioning in cervical spine examinations. The most frequent examination was chest X-ray which accounts for about 42. 2 % of the total examinations. The results show low reject rates by considering the factors for radiographic rejection analysis in relation to both equipment functionality and film development in the facility...|$|R
40|$|In {{compliance}} with the Federal Facilities Compliance Agreement, Los Alamos National Laboratory (LANL) is striving to ship its low-level mixed waste (LLMW) off-site for treatment and disposal. In order to ship LLMW off site to a commercial facility, LANL must request exemption from the DOE Order 5820. 2 A requirement that LLMW be shipped only to Department of Energy facilities. Because the process of obtaining the required information and approvals for a mixed waste shipment campaign can be very expensive, time consuming, and frustrating, a well-planned program is necessary {{to ensure that the}} elements for the exemption request package are completed successfully the first time. LANL has developed such a program, which is cost- effective, quality-driven, and compliance-based. This program encompasses selecting a qualified analytical laboratory, developing a quality project-specific sampling plan, properly sampling liquid and solid wastes, validating analytical data, documenting the waste characterization and decision processes, and maintaining quality records. The products of the program are containers of waste that meet the off-site facility`s waste acceptance criteria, a quality exemption request package, documentation supporting waste characterization, and <b>overall</b> quality <b>assurance</b> for the process. The primary goal of the program is to provide an avenue for documenting decisions, procedures, and data pertinent to characterizing waste and preparing it for off-site treatment or disposal...|$|R
