10000|10000|Public
25|$|The BHHH {{algorithm}} is a non-linear <b>optimization</b> <b>algorithm</b> that is popular for Maximum Likelihood estimations.|$|E
25|$|The runner-root {{algorithm}} (RRA) is a meta-heuristic <b>optimization</b> <b>algorithm</b> {{for solving}} unimodal and multimodal problems {{inspired by the}} runners and roots of plants in nature.|$|E
25|$|In {{computer}} science and operations research, the ant colony <b>optimization</b> <b>algorithm</b> (ACO) is a probabilistic technique for solving computational problems {{which can be}} reduced to finding good paths through graphs.|$|E
40|$|Abstract. To obtain peak {{performance}} from <b>optimization</b> <b>algorithms,</b> it {{is required to}} set appropriately their parameters. Frequently, algorithm parameters can take values from the set of real numbers, or from a large integer set. To tune this kind of parameters, {{it is interesting to}} apply state-of-the-art continuous <b>optimization</b> <b>algorithms</b> instead of using a tedious, and error-prone, hands-on approach. In this paper, we study the performance of several continuous <b>optimization</b> <b>algorithms</b> for the algorithm parameter tuning task. As case studies, we use a number of <b>optimization</b> <b>algorithms</b> from the swarm intelligence literature. ...|$|R
40|$|We present constraint-based <b>optimization</b> <b>algorithms</b> and a constraintbased {{approximation}} algorithm for the job-shop scheduling problem. An empirical {{performance analysis}} shows {{that both the}} <b>optimization</b> <b>algorithms</b> and the approximation algorithm perform well. Especially the approximation algorithm is among the best algorithms known to date. We, furthermore, show that we can improve {{the performance of the}} <b>optimization</b> <b>algorithms</b> by combining them with the approximation algorithm...|$|R
30|$|Artificial {{intelligence}} <b>optimization</b> <b>algorithms</b> {{are often}} adopted for microgrids. Common <b>optimization</b> <b>algorithms</b> include clonal selection [22], {{particle swarm optimization}} [23], differential evolution (DE) [24], [25] and fuzzy advanced quantum evolution [26]. Since the EMS model of microgrids is complicated, <b>optimization</b> <b>algorithms</b> {{are likely to be}} trapped into local convergence during the process of iterations. Consequently, to arrive at the best solution, it is necessary to make improvements to these basic <b>optimization</b> <b>algorithms</b> according to specific knowledge. Furthermore, if more than one objective exists at the same time, then multi-objective processing of the coordination and trade-off between objectives is another important issue to research.|$|R
25|$|A common {{criticism}} of neural networks, particularly in robotics, {{is that they}} require too much training for real-world operation. Potential solutions include randomly shuffling training examples, by using a numerical <b>optimization</b> <b>algorithm</b> that does not take too large steps when changing the network connections following an example and by grouping examples in so-called mini-batches.|$|E
25|$|This <b>optimization</b> <b>algorithm</b> {{may be used}} to {{characterize}} matroids: if a family F of sets, closed under taking subsets, has the property that, no matter how the sets are weighted, the greedy algorithm finds a maximum-weight set in the family, then F must be the family of independent sets of a matroid.|$|E
25|$|Generally {{heuristic}} algorithm {{relies on}} the iterative strategy, scilicet based on a comparison method, optimizing the results of multiple sequence alignment by the iterative process. Davie M proposed using particle swarm <b>optimization</b> <b>algorithm</b> to solve the multiple sequence alignment problem; Ikeda T proposed a heuristic algorithm {{which is based on}} A* search algorithm; Bimey E first proposed using hidden Markov model to solve the multiple sequence alignment problem; and many other biologists use genetic algorithm to solve it. All these algorithms generally are robust and insensitive to the number of sequences, but they also have shortcoming, for example, the result got from particle swarm <b>optimization</b> <b>algorithm</b> is unstable and its merits depend on the selection of random numbers, the runtime of A * search algorithm is too long and the genetic algorithm is easy to fall into local excellent.|$|E
40|$|Abstract: Optimization {{has been}} an active area of {{research}} for several decades. As many real-world optimization problems become increasingly complex, better <b>optimization</b> <b>algorithms</b> are always needed. Recently, metaheuristic global <b>optimization</b> <b>algorithms</b> have become a popular choice for solving complex and intricate problems, which are otherwise difficult to solve by traditional methods. In the present study, an attempt is made to review {{the most popular and}} well known metaheuristic global <b>optimization</b> <b>algorithms</b> introduced during the past decades. Key words: Global <b>optimization,</b> metaheuristic <b>algorithm,</b> swarm intelligenc...|$|R
3000|$|Design other exact or {{heuristic}} <b>optimization</b> <b>algorithms</b> {{to identify}} critical nodes. Since the three performance metrics are nontrivial but nonhereditary properties in most cases, there might exist exact <b>optimization</b> <b>algorithms</b> {{that belong to}} class P; and [...]...|$|R
40|$|Optimization {{has been}} an active area of {{research}} for several decades. As many real-world optimization problems become increasingly complex, better <b>optimization</b> <b>algorithms</b> are always needed. Recently, metaheuristic global <b>optimization</b> <b>algorithms</b> have become a popular choice for solving complex and intricate problems, which are otherwise difficult to solve by traditional methods. In the present study, an attempt is made to review {{the most popular and}} well known metaheuristic global <b>optimization</b> <b>algorithms</b> introduced during the past decades...|$|R
2500|$|Intelligent {{water drops}} (IWD), a swarm-based <b>optimization</b> <b>algorithm</b> based on natural water drops flowing in rivers ...|$|E
2500|$|Given {{the above}} pre-requisites, a local <b>optimization</b> <b>algorithm</b> can then move [...] "uphill" [...] along the {{eigenvector}} {{with the most}} negative eigenvalue and [...] "downhill" [...] along all other degrees of freedom, using something similar to a quasi-Newton method.|$|E
2500|$|Another common {{method is}} Platt's {{sequential}} minimal optimization (SMO) algorithm, which breaks the problem down into 2-dimensional sub-problems that are solved analytically, {{eliminating the need}} for a numerical <b>optimization</b> <b>algorithm</b> and matrix storage. This algorithm is conceptually simple, easy to ...|$|E
40|$|Hybrid <b>optimization</b> <b>algorithms</b> {{consist of}} a number of proven {{constituent}} <b>optimization</b> <b>algorithms</b> and a control algorithm that performs automatic switching among the constituent algorithms at each stage during the optimization when the rate of convergence becomes unsatisfactory, the process tends towards a local minimum, or some other undesirable aspect of the iterative process appears. Thus, hybrid <b>optimization</b> <b>algorithms</b> that utilize a number of gradient based and non-gradient based constituent optimizers are more robust and converge better than individual constituent <b>optimization</b> <b>algorithms.</b> The logic of designing the automatic switching algorithms in hybrid optimizers is surveyed in this paper focusing on the research performed by the authors in the area of hybrid single-objective optimization initiated in 1997...|$|R
30|$|For {{efficient}} non-uniform deblurring, it {{is crucial}} to design forward blur models and efficient <b>optimization</b> <b>algorithms.</b> In this section, we briefly review the original projective motion path blur (PMPB) model and its simplified 3 D approximation, and the <b>optimization</b> <b>algorithms</b> in MAP-based deblurring.|$|R
40|$|Abstract. Global <b>optimization</b> <b>algorithms</b> {{have strong}} {{adaptability}} {{become a major}} research direction. Three global <b>optimization</b> <b>algorithms</b> which are Multi-Island Genetic Algorithm (MIGA), Adaptive simulated annealing (ASA) and Evolutionary Algorithms (EVOL) are adopted as the optimization policy. Tested with Zakharov function and Rastrigin function to analyze {{the performance of the}} global <b>optimization</b> <b>algorithms.</b> According to the results, it can be concluded that one should choose corresponding optimization methods for optimal calculation with specific issues, so that it can obtain the best optimal solution...|$|R
2500|$|... where [...] is the {{identity}} matrix and [...] is {{a unit vector}} representing the reaction path tangent at [...] By projecting out components of the energy gradient [...] or the optimization step that are parallel to the reaction path, an <b>optimization</b> <b>algorithm</b> significantly reduces the tendency {{of each of the}} beads to be optimized directly to a minimum.|$|E
2500|$|An <b>optimization</b> <b>algorithm</b> can {{use some}} or all of , [...] and [...] to try to {{minimize}} the forces and this could in theory be any method such as gradient descent, conjugate gradient or Newton's method, but in practice, algorithms which use knowledge of the PES curvature, that is the Hessian matrix, are found to be superior. For most systems of practical interest, however, it may be prohibitively expensive to compute the second derivative matrix, and it is estimated from successive values of the gradient, as is typical in a Quasi-Newton optimization.|$|E
2500|$|An ant is {{a simple}} {{computational}} agent in the ant colony <b>optimization</b> <b>algorithm.</b> It iteratively constructs a solution for the problem at hand. The intermediate solutions {{are referred to as}} solution states. At each iteration of the algorithm, each ant moves from a state [...] to state , corresponding to a more complete intermediate solution. Thus, each ant [...] computes a set [...] of feasible expansions to its current state in each iteration, and moves to one of these in probability. For ant , the probability [...] of moving from state [...] to state [...] depends on the combination of two values, viz., the attractiveness [...] of the move, as computed by some heuristic indicating the a priori desirability of that move and the trail level [...] of the move, indicating how proficient {{it has been in the}} past to make that particular move.|$|E
25|$|Chronology of ant colony <b>optimization</b> <b>algorithms.</b>|$|R
5000|$|... optimize: <b>optimization</b> <b>algorithms</b> {{including}} {{linear programming}} ...|$|R
5000|$|... #Subtitle level 3: <b>Optimization</b> <b>algorithms</b> without {{guarantees}} ...|$|R
50|$|LINCOA (LINearly Constrained <b>Optimization</b> <b>Algorithm)</b> is a {{numerical}} <b>optimization</b> <b>algorithm</b> by Michael J. D. Powell. It {{is also the}} name of Powell's Fortran 77 implementation of the algorithm.|$|E
50|$|The {{bacterial}} colony <b>optimization</b> <b>algorithm</b> is an <b>optimization</b> <b>algorithm</b> {{which is}} based on a lifecycle model that simulates some typical behaviors of E. coli bacteria during their whole lifecycle, including chemotaxis, communication, elimination, reproduction, and migration.|$|E
5000|$|... #Subtitle level 3: Quantum {{approximate}} <b>optimization</b> <b>algorithm</b> (QAOA) ...|$|E
30|$|In Section 3, we {{presented}} CP for three-way tensors. Various <b>optimization</b> <b>algorithms</b> exist to compute CP decomposition without constraint, as ALS or descent algorithms [7, 8, 19]. We subsequently present <b>optimization</b> <b>algorithms</b> {{to compute the}} CP decomposition (10), under the constraints of unit norm columns of loading matrices.|$|R
40|$|This {{bachelor}} thesis {{focuses on}} video stabilization using CRS (Controlled Random Search) and GA (Genetic <b>Algorithm)</b> <b>optimization</b> <b>algorithms.</b> It describes registration process, geometrical transformations, interpolation methods, similarity criteria and <b>optimization</b> <b>algorithms.</b> It also briefly describes {{structure of the}} program created in MATLAB. Finally it contains results of achieved stabilization...|$|R
40|$|Comparing, or benchmarking, of <b>optimization</b> <b>algorithms</b> is a {{complicated}} task that involves many subtle considerations to yield a fair and unbiased evaluation. In this paper, we systematically review the benchmarking process of <b>optimization</b> <b>algorithms,</b> and discuss the challenges of fair comparison. We provide suggestions for {{each step of the}} comparison process and highlight the pitfalls to avoid when evaluating the performance of <b>optimization</b> <b>algorithms.</b> We also discuss various methods of reporting the benchmarking results. Finally, some suggestions for future research are presented to improve the current benchmarking process. Comment: Optim Eng (2017...|$|R
50|$|His {{interests}} include <b>optimization,</b> <b>algorithm</b> {{design and}} analysis, game theory, and machine learning.|$|E
5000|$|The {{fundamental}} particle swarm <b>optimization</b> <b>algorithm</b> used in training phase generally as follows: ...|$|E
5000|$|The BHHH {{algorithm}} is a non-linear <b>optimization</b> <b>algorithm</b> that is popular for Maximum Likelihood estimations.|$|E
40|$|To obtain peak {{performance}} from <b>optimization</b> <b>algorithms,</b> it {{is required to}} set appropriately their parameters. Frequently, algorithm parameters can take values from the set of real numbers, or from a large integer set. To tune this kind of parameters, {{it is interesting to}} apply state-of-the-art continuous <b>optimization</b> <b>algorithms</b> instead of using a tedious, and error-prone, hands-on approach. In this paper, we study the performance of several continuous <b>optimization</b> <b>algorithms</b> for the algorithm parameter tuning task. As case studies, we use a number of <b>optimization</b> <b>algorithms</b> from the swarm intelligence literature. © 2010 Springer-Verlag Berlin Heidelberg. M. Dorigo, M. Birattari, G. A. Di Caro, R. Doursat, A. P. Engelbrecht, D. Floreano, L. M. Gambardella, R. Groß, E. Sahin, H. Sayama, and T. Stützle (Eds.) Swarm Intelligence, 7 th International Conference, ANTS 2010 SCOPUS: cp. kinfo:eu-repo/semantics/publishe...|$|R
5000|$|The {{following}} design <b>optimization</b> <b>algorithms</b> {{are available}} in HEEDS: ...|$|R
40|$|summarize the {{literature}} related to benchmarking <b>optimization</b> <b>algorithms</b> {{with a focus}} on benchmarking {{in the face of the}} 'no free lunch' theorem and useful statistical tools for interpreting results. This context for this review is biologically inspired <b>optimization</b> <b>algorithms</b> applied to continuous function optimization although the principles extend beyond these|$|R
