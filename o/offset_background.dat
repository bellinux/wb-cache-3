0|33|Public
40|$|We {{measured}} human psychophysical detection thresholds for test pulses {{which are}} superimposed on spatially homogeneous backgrounds that have abrupt onsets and offsets of high-contrast 25 Hz flicker. After {{the onset of}} the background flicker, test thresholds reach their steady-state levels within 20 - 60 ms. After the <b>offset</b> of the <b>background</b> flicker, test thresholds remain elevated above their steady-state level for much longer durations. Adaptation after onsets and <b>offsets</b> of <b>background</b> flicker is modeled with a divisive gain control that is activated by temporal contrast. We show that a feedback structure for the gain control can explain the asymmetric dynamics observed after onsets and <b>offsets</b> of the <b>background</b> contrast. Finally, we measure detection thresholds for tests presented on steadily flickering backgrounds {{as a function of the}} contrast of the background flicker. We show that the divisive feedback model for contrast gain control can describe these results as well. ...|$|R
40|$|Abstract Background Phase-contrast {{velocity}} images often {{contain a}} <b>background</b> or baseline <b>offset</b> error, which adds an unknown offset to the measured velocities. For accurate flow measurements, this offset must be shown negligible or corrected. Some correction techniques depend on replicating the clinical flow acquisition using a uniform stationary phantom, {{in order to}} measure the baseline offset at the region of interest and subtract it from the clinical study. Such techniques assume that the <b>background</b> <b>offset</b> is stable over the time of a patient scan, or even longer if the phantom scans are acquired later, or derived from pre-stored background correction images. There is no published evidence regarding temporal stability of the <b>background</b> <b>offset.</b> Methods This study assessed the temporal stability of the <b>background</b> <b>offset</b> on 3 different manufacturers’ scanners over 8 weeks, using a retrospectively-gated phase-contrast cine acquisition with fixed parameters and at a fixed location, repeated 5 times in rapid succession each week. A significant offset was defined as 0. 6 cm/s within 50 mm of isocenter, based upon an accuracy of 10 % in a typical cardiac shunt measurement. Results Over the 5 repeated cine acquisitions, temporal drift in the baseline offset was insignificant on two machines (0. 3 cm/s, 0. 2 cm/s), and marginally insignificant on the third machine (0. 5 cm/s) due to an apparent heating effect. Over a longer timescale of 8 weeks, insignificant drift (0. 4 cm/s) occurred on one, with larger drifts (0. 9 cm/s, 0. 6 cm/s) on the other machines. Conclusions During a typical patient study, background drift was insignificant. Extended high gradient power scanning with work requires care to avoid drift on some machines. Over the longer term of 8 weeks, significant drift is likely, preventing accurate correction by delayed phantom corrections or derivation from pre-stored <b>background</b> <b>offset</b> data. </p...|$|R
40|$|An 8 -channel 6 -bit 16 -GS/s time-interleaved ADC was {{fabricated}} using a 65 nm CMOS technology. Each A/D {{channel is}} a flash ADC using latch-type comparator with <b>background</b> <b>offset</b> calibration. Timing skews among the channels are also continuously calibrated in the background. The chip achieves 42. 3 dB SFDR and 30. 8 dB SNDR at 16 GS/s sampling rate...|$|R
40|$|International audienceThis paper {{presents}} <b>background</b> <b>offset</b> {{and gain}} calibration for time-interleaved analog-to-digital converter (TIADC). The calibration technique depends on detecting the offset and the amplitude of a calibration signal. The detection {{is based on}} a simple algorithm performed in the digital part. A digital sinusoidal wave is needed to implement the calibration technique. The calibration technique behaviors are theoretically analysed and verified by simulations. A 12 -bit, 4 -channel, 800 MS/s TIADC is used as an example...|$|R
40|$|We have {{developed}} magnetically modulated optical nanoprobes (MagMOONs) to magnetically modulate the signal from fluorescent probes and thus separate it from autofluorescence, electronic <b>offsets,</b> and other <b>background</b> signals. These micro- and nanosized particles emit fluorescence signals, indicating chemical concentrations, and blink {{in response to}} rotating magnetic fields. Demodulating the signal dramatically enhances the probe’s signal to background ratio. The probes and methods promise to improve immunoassays, intracellular chemical sensing, and fundamental biochemical research. © 2003 American Institute of Physics...|$|R
50|$|In 1987, it {{introduced}} a new livery of two tone grey similar to those adopted by the Trainload Freight and Railfreight General sub-sectors, with a logo consisting of two red diamonds on a yellow <b>background</b> <b>offset</b> {{on top of a}} red square. In 1992 in anticipation of the opening of the Channel Tunnel, the livery was revised to the 'European' version with a dark grey upper bodyside, a light grey lower bodyside, a blue coloured roof and 'Railfreight Distribution' lettering on the bodyside.|$|R
40|$|This report {{contains}} {{the most extensive}} set of tables currently available of Lanchester-Clifford-Schlafli (LCS) functions. These functions {{may be used to}} analyze Lanchester-type combat between two homogeneous forces modelled by power attrition-rate coefficients with no <b>offset.</b> Theoretical <b>background</b> for the LCS functions is given, as well as a narrative description of the physical circumstances under which the associated Lanchester-type combat model may be expected to be applicable. Numerical examples are given to illustrate the use of the LCS functions for analyzing aimed-fire combat modelled by the power attrition-rate coefficients with no offset. Our results and these tabulations allow one to study this particular variable-coefficient combat model almost as easily and thoroughly as Lanchester's classic constant-coefficient model. (Author) supported by the U. S. Army Research Office, Durham, North Carolina with R&D project No. IL 161102 BH 57 - 05 Math[URL] under MIPR No. ARO 22 - 77 and partially by the Office of Naval Researc...|$|R
40|$|A serendipitous {{observation}} led to {{this study}} of V 1 activity rebounds, which occur well after stimulus offset, {{and their relationship to}} visual aftereffects. We found that when a stimulus bar and background were simultaneously turned off, there was strong delayed rebounding activity (distinct from any off response). The neural rebound started 350 – 500 ms after stimulus offset, and its magnitude and duration were correlated with the prior visual response of the cell. In human psychophysical experiments, we found a delayed aftereffect that may be a perceptual correlate of the activity rebound. Both the rebound activity and the perceptual aftereffect disappeared if the stimulus bar and background were not extinguished together. The magnitude of the rebound varied with the spatial scale of the background even though background size had little effect on the visual response. It thus appeared that rebound magnitude was determined by a relatively large integration area. The aftereffect was not seen when the bar and <b>background</b> <b>offsets</b> were presented to different eyes, suggesting an early neural (monocular) basis for the aftereffect. Overall, we find a strong correlation between rebound activity and the perceived aftereffect. In addition to providing a possible explanation and neural correlate of a visual aftereffect, rebounding activity may provide new insight into the dynamics of early visual processing. Keywords: aftereffect, afterimage, off response, temporal context, <b>background</b> <b>offset,</b> visual perception, V 1, macaque monke...|$|R
40|$|Abstract — A {{power-efficient}} and speed-enhancing {{technique for}} time-interleaved (TI) SAR ADCs that is assisted by a low-resolution flash ADC is presented. The 3 b MSBs achieved from a flash ADC at every clock save two decision cycles from every SAR ADC channel, {{resulting in a}} reduced number of time interleaving channels with a total 27 % energy saving compared with the energy consumption of a conventional TI SAR ADC. A prototype 6 b 2 GS/s ADC in a 45 nm CMOS consumes 14. 4 mW under a 1. 2 V supply and achieves 5. 2 ENOBNyq with a <b>background</b> <b>offset</b> calibration. I...|$|R
40|$|We study modulation-free {{methods for}} {{producing}} sub-Doppler, dispersive line shapes for laser stabilization near the potassium D 2 transitions at 767 nm. Polarization spectroscopy is performed and a comparison is {{made between the}} use of a mirror or beam splitter for aligning the counter-propagating pump and probe beams. Conventional magnetically-induced dichroism is found to suffer from a small dispersion and large <b>background</b> <b>offset.</b> We therefore introduce a modified scheme, using two spatially separated pump-probe beam pairs. Finally we compare our results to methods using phase modulation and heterodyne detection. Comment: 11 pages, 8 figures; published versio...|$|R
40|$|Recovery from {{contrast}} adaptation was {{studied in}} psychophysical experiments. We measured detection thresholds for atest pulse presented on aphotopic background as afunction {{of the time}} after the offset of a high-contrastflickerofthebackground. Thedecreaseofthresholdswithtimeiswelldescribedbyapower-law function. Thresholds for tests presented at 640 ms after the <b>offset</b> of the <b>background</b> contrast are still significantly elevated above the threshold measured when the observers have completely adapted to asteady background. Wecomparethepsychophysicaldatawithcontrastestimatesofideal-observermodels. Amatch betweentheresultsforhumanandidealobserverscanbeobtainedwhentheidealobserverislimitedbynoise. For aquantitative match, {{we assume that the}} ideal observer performs aBayesian calculation on its noiseperturbed input, sampled every 10 – 20 ms. For the Bayesian calculation we assume aprior probability distributionfunctionfortheinputcontrastthathasalowercutoffatthestandarddeviationofthenoise...|$|R
25|$|The carving is so {{deep that}} the forms are almost {{completely}} <b>offset</b> from the <b>background</b> resulting in three, or even four, layers of various figures and forms. What is more, overlapping figures fill the image space entirely, allowing no room to depict a background. Thus, the sense of space has been eliminated, giving rise to chaos {{and a sense of}} weary, open-ended victory. The effect of movement in the scene is evident and, unlike many battle sarcophagi which have more tranquil scenes on the side panels, the battle events continue {{all the way around the}} sarcophagus. The perspective constructed is also notable, although certainly not linear.|$|R
40|$|Full list {{of author}} {{information}} {{is available at the}} end of the articleBackground Phase-contrast velocity mapping is applied to blood flow [1] and myocardial velocity mapping [2] in cardiovascular magnetic resonance (CMR). Velocity images are formed by subtracting the phase images of two acquisitions with differing velocity sensitivity. As is well known, other phase differences between the two images cause stationary tissue to display an apparent non-zero velocity, known as the <b>background</b> <b>offset</b> or baseline error. This may vary gra-dually with position over the velocity image and underlies stationary and moving tissues. Maxwell (or concomitant) gradient effects are one cause which can be corrected ana-lytically [3]. Eddy currents are another cause, and these are corrected to a large extent by actively-shielded gra-dient coils and pre-emphasis [4, 5] although this is compli...|$|R
40|$|For {{meteorological}} radar observations, it is {{very important}} to know the size and the characteristics of precipitation particles. In this paper, we report a method to measure snow particle size using snow particle video images. An image of snow particles, which was recorded by a specially designed portable video camera set on the ground, was digitized by a popular-priced personal computer. To reduce <b>background</b> <b>offset,</b> we used subtraction processing between images at different recording times. Using projection data on this image, the position of each snow particle was detected. Finally, we measure the three kinds of snow particle "radius". We applied this method to two sets of VCR tapes that had been recorded at Syowa Station, Antarctica, on April 5 - 6 and on October 1, 1988,and obtained relative distributions...|$|R
40|$|Abstract — In {{this paper}} {{we present a}} 10 -bit, two-bit per cycles successive-approximation A/D {{converter}} (ADC). The cir-cuit, operated at 60 MHz clock frequency, achieves a sampling frequency of 10 MHz, requiring only 6 clock cycles to accomplish a conversion. The ADC exploits three comparators to resolve two bits during each conversion cycle. To avoid the severe performance degradation due to offset mismatches among the comparators, we developed a novel <b>background</b> <b>offset</b> calibration technique. During the input signal sampling phase, when the comparators would otherwise be idle, we reconfigure the circuit to implement three one-bit per cycle, 8 -bit successive-approximation ADCs, which within 8 conversion cycles measure the offset of each comparator. The effect of the comparator offset is then canceled in the digital domain. Simulation results confirm {{the effectiveness of the}} proposed solution, allowing to achieve 10 bits of resolution...|$|R
40|$|An {{instrument}} and method for measuring chemical properties, the instrument having electrodes suitable for immersion in a chemical solution. A voltage source and a current-sensing circuit {{are connected to}} the electrodes to measure the current produced in the solution in response to a voltage applied to the electrodes to determine a value of the chemical in the solution. The {{instrument and}} method further include <b>background</b> compensation for <b>offsetting</b> the value of the analyte by an amount which is reflective of the background value of the solution. The background value is stored in an internal memory of the instrument so that when new experimental measurements are taken, the measurements are immediately <b>offset</b> by the <b>background</b> portion of the new experimental measurements. This allows operation of the instrument at high gain levels, resulting in a broad dynamic range and greater useful precision in the output signal. Georgia Tech Research Corporatio...|$|R
40|$|Recovery from {{contrast}} adaptation was {{studied in}} psychophysical experiments. We measured detection thresholds {{for a test}} pulse presented on a photopic background {{as a function of}} the time after the offset of a high-contrast flicker of the background. The decrease of thresholds with time is well described by a power-law function. Thresholds for tests presented at 640 ms after the <b>offset</b> of the <b>background</b> contrast are still significantly elevated above the threshold measured when the observers have completely adapted to a steady background. We compare the psychophysical data with contrast estimates of ideal-observer models. A match between the results for human and ideal observers can be obtained when the ideal observer is limited by noise. For a quantitative match, we assume that the ideal observer performs a Bayesian calculation on its noise-perturbed input, sampled every 10 – 20 ms. For the Bayesian calculation we assume a prior probability distribution function for the input contrast that has a lower cutoff at the standard deviation of the noise. ...|$|R
5000|$|A fourth theme {{identified}} by experts is Wegner’s engagement with architecture. For example, in his photography series “Buildings Made of Sky,” Wegner reverses urban streetscapes to reveal how skyscrapers shape the open-air spaces between one another into skyscraper-like forms of their own. Chasin described a 2004 piece from the series in these terms: “A magical reversal thereby takes place: the physical buildings read visually as a darkened <b>background</b> <b>offset</b> by architectural contours from startling blue-hued visions of skyscrapers carved from atmosphere. Sky becomes building; building, sky—or to invoke K. Michael Hays {{in a different}} context, ‘not architecture but evidence that it exists.’” Wegner has also often pushed the construction of his works in an architectural direction, presenting paintings {{in the form of}} leaning columns, complex lattices, and multi-layered scrims. Huldisch noted that “his stacks, grids, and lattice structures reveal both an interest in the forms of Minimalism and a rejection of the stringent doctrine that predicated them.” ...|$|R
40|$|We {{present an}} {{atmospheric}} inverse modeling framework to constrain terrestrial biosphere CO₂ exchange processes at subregional scales. The model is operated {{at very high}} spatial and temporal resolution, using the state of Oregon in the northwestern United States as the model domain. The modeling framework includes mesoscale atmospheric simulations coupled to Lagrangian transport, a biosphere flux model that considers, e. g., the effects of drought stress and disturbance on photosynthesis and respiration CO₂ fluxes, and a Bayesian optimization approach. This study focuses {{on the impact of}} uncertainties in advected background mixing ratios and fossil fuel emissions on simulated flux fields, both taken from external data sets. We found the simulations to be highly sensitive to systematic changes in advected background CO₂, while shifts in fossil fuel emissions played a minor role. Correcting for <b>offsets</b> in the <b>background</b> mixing ratios shifted annual CO₂ budgets by about 47 % and improved the correspondence with the output produced by bottom-up modeling frameworks. Inversion results were robust against shifts in fossil fuel emissions, which is likely a consequence of relatively low emission rates in Oregon...|$|R
40|$|The Transient Gamma Ray Spectrometer (TGRS) {{on board}} the WIND {{spacecraft}} {{has spent most of}} the interval 1995 - 1997 in a high-altitude orbit where gamma-ray backgrounds are low. Its high-resolution Ge spectrometer is thus able to detect weak lines which are slightly <b>offset</b> from stronger <b>background</b> features. One such line is predicted from nucleosynthesis in classical novae, where beta-decays on a time-scale of a few hours in an expanding envelope produce positrons that annihilate to generate a line which is blueshifted by a few keV away from the background annihilation line at 511 keV. The broad TGRS field of view contained five known Galactic novae during 1995 January - 1997 June, and we have searched the spectra taken around the times of these events for the blueshifted nova annihilation line. Although no definite detections were made, the method is shown to be sensitive enough to detect novae occurring on ONeMg-rich white dwarfs out to about 2. 5 kpc. Comment: 27 pp. + 10 figs., or offprint mailed by request to harris@tgrs 2. gsfc. nasa. go...|$|R
40|$|Summary: For {{material}} to be offset printed, the masters {{need to be}} prepared as colour separations, one for each coloured ink. Production of the masters is a time consuming task, often performed by hand. A method is proposed to enable separations to be automatically prepared if the source material is available as a colour PostScript file. The method uses any black-and-white PostScript printer, and two header files, the first defining procedures to be used in preparing the separation, and the second selecting the colour of the separation desired. The method works with any colour Level 1 PostScript documents. <b>Background</b> <b>Offset</b> printing in colour is most frequently achieved by separately printing the chosen inks onto the final piece of paper. Separate plates are made up for each of the colours, and they must be carefully aligned or registered to reproduce the desired combination of colours. If you have an original illustration or manuscript in colour, the printer must manually separate the colours into the separate plates for reproduction. This is a slow and expensive process. Printers prefer to be given the originals already separated into the component colours. If you are producing the material on a computer for later reproduction by offset printing...|$|R
40|$|A {{high-speed}} photo-polarimeter, “OPTIMA ” {{short for}} Optical Pulsar Tim-ing Analyzer, {{has been designed}} and developed in the group for gamma-ray astronomy of the Max-Planck-Institut für extraterrestrische Physik. This sen-sitive, portable detector is used to observe optical emissions of sources that radiate mainly at X- and gamma-ray energies, like pulsars and other highly variable compact sources. The single photon counting instrument is based on fiber fed avalanche photodiodes (APDs), a GPS timing receiver, a CCD camera for target acquisition and a stand-alone data acquisition and control system. Several configurations are available: for photometry a hexagonal bun-dle with seven channels and one fiber <b>offset</b> for sky <b>background</b> monitoring; for polarimetry a rotating polarization filter {{in front of the}} photometer or a newly developed 4 -channel double Wollaston system; and for coarse spectroscopy a 4 -colour prism spectrograph. 2 General Layout The concept of aperture timing photometry is very familiar to astronomers working in high-energy X- and gamma-ray astronomy. Single photon events are located on a sky map and their arrival times are registered. The desired target photons are then selected for analysis depending on their angular dis-tance from the target source. In the optical band we can operate in the same way if a suitable fast 2 dimensional detector with single photon sensitivity is 2 G. Kanbach et al...|$|R
40|$|Metal-Oxide-Semiconductor Field-Effect Transistor (MOSFET) and Single-Electron Transistor (SET) hybrid architectures, which {{combine the}} merits of both MOSFET and SET, promise to be a {{practical}} implementation for nanometer-scale circuit design. In this thesis, we design arithmetic circuits, including adders and multipliers, using SET/MOS hybrid architectures {{with the goal of}} reducing circuit area and power dissipation and improving circuit reliability. Thanks to the Coulomb blockade oscillation characteristic of SET, the design of SET/MOS hybrid adders becomes very simple, and requires only a few transistors by using the proposed schemes of multiple-valued logic (MVL), phase modulation, and frequency modulation. The phase and frequency modulation schemes are also utilized for the design of multipliers. Two types of SET/MOS hybrid multipliers are presented in this thesis. One is the binary tree multiplier which adopts conventional tree structures with multi-input counters (or compressors) implemented with the phase modulation scheme. Compared to conventional CMOS tree multipliers, the area and power dissipation of the proposed multiplier are reduced by half. The other is the frequency modulated multiplier following a novel design methodology where the information is processed in the frequency domain. In this context, we explore the implicit frequency properties of SET, including both frequency gain and frequency mixing. The major merits of this type of multiplier include: a) simplicity of circuit structure, and b) high immunity against background charges within SET islands. Background charges are mainly induced by defects or impurities located within the oxide barriers, and cannot be entirely removed by today 2 ̆ 7 s technology. Since these random charges deteriorate the circuit reliability, we investigate different circuit solutions, such as feedback structure and frequency modulation, in order to counteract this problem. The feedback represents an error detection and correction mechanism which <b>offsets</b> the <b>background</b> charge effect by applying an appropriate voltage through an additional gate of SET. The frequency modulation, on the other hand, exploits the fact that background charges only shift the phase of Coulomb blockade oscillation without changing its amplitude and periodicity. Therefore, SET/MOS hybrid adders and multipliers using the frequency modulation scheme exhibit the high immunity against these undesired charges...|$|R
40|$|The {{dynamics}} of phase separated micellar solutions of randomly sulphonated polystyrene ionomers in toluene were examined with neutron spin echo spectroscopy (NSE). The correlation functions demonstrated single exponential decays with a constant <b>background</b> <b>offset.</b> The relaxation rate (Gamma) of the ionomer micelles at small length scales in the q range 0. 075 - 0. 16 angstrom(- 1) was diffusive (Gamma similar to q(2)) as expected for the collective breathing mode of a cross-linked gel. At intermediate length scales in the q-range 0. 025 - 0. 075 the relaxation rates were non-diffusive (Gamma similar to q(0. 36),q(0. 72)), which {{is attributed to}} the hopping {{dynamics of}} the individual stickers inside the ionomer micelles (T-stick similar to 10 ns). At large length scales the scattering due to the phase separated inhomogeneities of the micellar network did not relax on the time scales of the measurements (< 20 ns), giving rise to a constant background on the correlation functions. This slow relaxation process {{may be due to}} the hopping dynamics of whole micelles previously observed in rheology experiments (T (micelle) similar to 0. 05 s). The NSE results are in agreement with a model developed in previous small-angle neutron scattering and rheology experiments for concentrated solution of ionomeric micelles. The NSE results for the associating ionomers are markedly different from the Zimm dynamics (Gamma similar to q(3)) previously observed for semi-dilute and cross-linked polystyrene polymers in a good solvent. The ionomeric cross-links thus have a large impact on the polymer chain dynamics at the nanosecond time scale. (c) 2007 Elsevier Ltd. All rights reserved...|$|R
40|$|A {{radiation}} {{model is}} constructed that includes radiative interactions with atmospheric gases, {{as well as}} parameterized treatments of scattering and absorption/emission by cloud droplets and haze particles. A unified treatment of solar and terrestrial radiation is obtained by using identical cloud and haze parameterization procedure for the shortwave and longwave region. The influence of the relative humidity of the haze particles is also considered. Snow conditions of the arctic region are simulated in terms of snow grain sizes and soot contamination in the surface layers. Data from the Arctic Stratus Cloud Experiment collected in 1980 are used for model comparisons and sensitivity studies under cloudy and hazy sky conditions. During the arctic summer, stratus clouds are a persistent feature and decrease the downward flux at the surface by about 130 - 200 W me 2. Arctic haze in the summertime is important if it is above the cloud layer or in air with low relative humidity, and it decreases the downward flux at the surface by about lo- 12 W me 2. By comparison the greenhouse effect of doubling the carbon dioxide amount increases the downward flux at the surface by about 4 - 7 W me 2 and can be <b>offset</b> by the <b>background</b> haze or {{by an increase in}} cloudiness of about 4 %. Assuming steady microstructures of stratus clouds, we find that in late June a clear sky condition results in more available downward flux for snow melt (yielding a melting rate of 9. 3 cm day-‘) than does a cloudy sky condition (6 cm day-‘). This is because the increase of infrared radiation diffused back to the surface by the cloud can not compensate for the reduction of solar radiation. When the snow starts to melt, the decreasing snow albedo further accelerates the melting process. 1...|$|R
40|$|International audienceThe Optimal Estimation Method (OEM) is {{an inverse}} method {{that allows the}} {{retrieval}} of parameters based on measurements and a forward model of the measurement. A complete uncertainty budget on a profile to profile basis, plus the vertical resolution of the measurements {{as a function of}} height can be found by this method. We use OEM {{for the first time to}} retrieval ozone profiles from a DIAL ozone lidar. The retrievals will be used on measurements from the CANDAC Stratospheric Ozone Differential Absorption Lidar located in Eureka, Canada. We will show results for simulated measurements using one Rayleigh channel. The synthetic pro?les are similar to 3 hours of the real measurements. The ozone is retrieved at 900 m vertical resolution from 7 km to 55 km altitude. The averaging kernel shows essentially no contribution from the a priori below 40 km; above this altitude the response of the averaging kernel drops to 0. 8 around 45 km; above which height the retrieval becomes less sensitive to the measurements. The percentage error between the true and retrieved profiles varies between 0. 5 % to 2 % in the region where the retrieval is valid and is less than the statistical uncertainties. In this pilot study background counts are also retrieved. A constant background was used to make synthetic measurements, however, due to the Signal Induced Noise (SIN), the background counts are not constant. We will include the effect of SIN <b>offset</b> on the <b>background</b> counts in the near future. The retrieval is currently being extended to use both of the lidar data channels. Using the two channels, we are planning to retrieve the ozone density profile, the aerosol extinction coefficient, deadtime of the detectors, and the lidar constants. We will then validate the method using measurements of ozone from other instruments, as well as against the traditional DIAL ozone analysis...|$|R
40|$|In {{this study}} an {{amorphous}} silicon electronic portal imaging device (a-Si EPID) converted to direct detection configuration was investigated as a transit dosimeter for intensity modulated radiation therapy (IMRT). After calibration to dose and correction for a <b>background</b> <b>offset</b> signal, the EPID-measured absolute IMRT transit doses for 29 fields {{were compared to}} a MatriXX two-dimensional array of ionization chambers (as reference) using Gamma evaluation (3 %, 3 mm). The MatriXX was first evaluated as reference for transit dosimetry. The accuracy of EPID measurements was also investigated by comparison of point dose measurements by an ionization chamber on the central axis with slab and anthropomorphic phantoms {{in a range of}} simple to complex fields. The uncertainty in ionization chamber measurements in IMRT fields was also investigated by its displacement from the central axis and comparison with the central axis measurements. Comparison of the absolute doses measured by the EPID and MatriXX with slab phantoms in IMRT fields showed that on average 96. 4 % and 97. 5 % of points had a Gamma index < 1 in head and neck and prostate fields, respectively. For absolute dose comparisons with anthropomorphic phantoms, the values changed to an average of 93. 6 %, 93. 7 % and 94. 4 % of points with Gamma index < 1 in head and neck, brain and prostate fields, respectively. Point doses measured by the EPID and ionization chamber were within 3 % difference for all conditions. The deviations introduced in the response of the ionization chamber in IMRT fields were < 1 %. The direct EPID performance for transit dosimetry showed that {{it has the potential to}} perform accurate, efficient and comprehensive in vivo dosimetry for IMRT...|$|R
40|$|It is very {{important}} for meteorological radar observations to know the precipitation particle size distribution functions. In this paper, we report a very simple method to evaluate snow particle size distribution functions using snow particle VTR images, and show our results at Syowa Station, Antarctica. Snow particles on the ground were recorded by a VTR camera set, and the VTR image was digitized and stored on frame memories using a video digitizer board in a personal computer. To avoid the overlap of snow particles and to reduce <b>background</b> <b>offset</b> noise on images, we used subtraction processing between images at different recording times. Next, we obtained projections of this subtracted image in the x and y directions, and determined the position of each particle using back projection processing. Since radar echo from snow is usually analyzed on the assumption that snow particles are spherical, we measured the maximum radius (γ_max) and equivalent radius (γ_area) from the identified individual snow particle images. The former is defined as the maximum diameter through the center of gravity on the particle image, the latter is calculated from its area. In this study, we used two sets of VTR tapes which were recorded at Syowa Station on April 5 and October 1, 1988. Using a personal computer, we have counted more than 2500 particles. The obtained distributions, N (γ_max) and N (γ_area), are approximated as straight lines on semi-logarithmic graph paper, N (γ) ∿(10) ^. In April, radii of snow particles, which may be graupels, were mainly distributed between 0. 2 and 0. 6 mm, and the exponents (B) of γ_max and γ_area were 42 and 50,respectively. Otherwise, in October, most particles were distributed from 0. 1 to 0. 5 mm, and the exponents of γ_max and γ_area were 62 and 33. We believe that our method is a practical approach for obtaining snow particle size distribution functions...|$|R
40|$|In Hubble Space Telescope (HST) Cycle 17, we imaged the {{well-known}} globular star cluster 47 Tucanae for 121 orbits using the Wide Field Channel of the Advanced Camera for Surveys (ACS) {{and both the}} UV/visible (UVIS) and IR channels of the newly installed Wide Field Camera 3 (WFC 3) instrument (GO- 11677, PI: H. Richer). This unique data set was obtained to address many scientific questions that demand a very deep, panchromatic, and panoramic view of the cluster's stellar populations. In total, the program obtained over 0. 75 Ms of imaging exposure time with the three HST cameras, over a time span of 9 months in 2010. The primary ACS field was imaged in the two broadband filters F 606 W and F 814 W, at 13 orientations, for all 121 orbits. The parallel WFC 3 imaging provides a panchromatic (0. 4 - 1. 7 3 ̆bcm) and contiguous imaging swath over a 2500 azimuthal range at impact radii of 6. 5 - 17. 9 pc in 47 Tuc. This imaging totals over 60 arcmin 2 in area and utilizes the F 390 W and F 606 W broadband filters on WFC 3 /UVIS and the F 110 W and F 160 W broadband filters on WFC 3 /IR. In this paper, we describe the observational design of the new survey {{and one of the}} methods used to analyze all of the imaging data. This analysis combines over 700 full-frame images taken with the three HST cameras into a handful of ultra-deep, well-sampled combined images in each of the six filters. We discuss in detail the methods used to calculate accurate transformations that provide optimal alignment of the input images, the methods used to perform sky <b>background</b> <b>offsets</b> in the input stack and the flagging of deviant pixels, and the balance reached between the input-pixel drop size onto an output supersampled pixel grid. Careful photometric, morphological, and astrometric measurements are performed on the stacks using iterative PSF-fitting techniques, and reveal unprecedented color-magnitude diagrams of the cluster extending to > 30 th magnitude in the optical, 29 th magnitude in the UV, and 27 th magnitude in the IR. The data set provides a characterization of the complete stellar populations of 47 Tuc, extending from the faintest hydrogen-burning dwarfs through the main-sequence and giant branches down to very cool white dwarf remnants in the cluster. The imaging also provides the deepest probe of the stellar populations of the background Small Magellanic Cloud galaxy, resolving low-mass main-sequence dwarfs with M 2 ̆ 272 0. 2 M 2 ̆ 299. Peer reviewed: YesNRC publication: Ye...|$|R
40|$|The rapid {{progress}} of scaling {{and integration of}} modern complimentary metal oxide semiconductor (CMOS) technology motivates the replacement of traditional analog signal processing by digital alternatives. Thus, analog-to-digital converters (ADCs), as the interfaces between the analog world and the digital one, are driven to enhance their performance in terms of speed, resolution and power efficiency. However, {{in the presence of}} imperfections of device mismatch, thermal noise and reduced voltage headroom, efficient ADC design demands new strategies for design, calibration and optimization. Among various ADC architectures, successive-approximation-register (SAR) ADCs have received renewed interest from the design community due to their low hardware complexity and scaling-friendly property. However, the conventional SAR architecture has many limitations for high-speed, high-resolution applications. Many modified SAR architectures and hybrid SAR architectures have been reported to break the inherent constraints in the conventional SAR architecture. Loop-unrolled (LU) SAR ADCs have been recognized as a promising architecture for high-speed applications. However, mismatched comparator offsets introduce input-level dependent errors to the conversion result, which deteriorates the linearity and limits the resolution and the resolution of most reported SAR ADCs of this kind are limited to 6 bits. Also, for high-resolution SAR ADCs, the comparator noise specification is very stringent, which imposes a limitation on ADC speed and power-efficiency. Lastly, capacitor mismatch is an important limiting factor for SAR ADC linearity, and generally requires dedicated calibration to achieve efficient designs in terms of power and area. In this work, we investigate the impacts of offset mismatch, comparator noise and capacitor mismatch on high-speed SAR ADCs. An analytical model is proposed to estimate the resolution and predict the yield of LU-SAR ADCs with presence of comparator <b>offset</b> mismatch. A <b>background</b> calibration technique is proposed for resolving the comparator mismatch issue. A 150 -MS/s 8 -bit LU-SAR ADC is fabricated in a 130 -nm CMOS technology to validate the concept. The measured result shows that the calibration improves the SNDR from 33. 7 -dB to 42. 9 -dB. The ADC consumes 640 μW from a 1. 2 V supply with a Figure-of-Merit (FoM) of 37. 5 -fJ/conv-step. Moreover, the bit-wise impact of comparator noise is studied for LU-SAR ADCs. Lastly, an extended statistical element selection (SES) calibration technique is proposed to calibrate the capacitor mismatch in SAR ADCs. Based on these techniques, a high-resolution, asynchronous SAR architecture employing multiple comparators with different speed and noise specifications to optimize speed and power efficiency. A 12 -bit prototype ADC is fabricated in a 1 P 9 M 65 nm CMOS technology, and fits into an active area of 500 μm × 200 μm. At 125 MS/s, the ADC achieves a signal-to-noise-and-distortion ratio (SNDR) of 64. 4 dB and a spurious-free-dynamic-range (SFDR) of 75. 1 dB at the Nyquist input frequency while consuming 1. 7 mW from a 1. 2 V supply. The resultant figure-of-merit (FoM) is 10. 3 fJ/conv-step...|$|R
40|$|The NTNU Test Satellite (NUTS) {{is planned}} to have a payload for {{observation}} of atmospheric gravity waves. The gravity waves will be observed {{by means of an}} infrared camera imaging the perturbations in the OH airglow layer. So far, no suitable camera has been found that complies with the restrictions that follows when building a small satellite. Uncooled InGaAs has however been concluded to be the most suitable detector type in terms of wavelength response and weight. InGaAs sensors are known to have a high dark current when not cooled, and processing must therefore be applied to remove the <b>background</b> <b>offset</b> and noise. The combination of the high speed of the satellite and the long exposure time that is required for the camera will create motion blur. Simulations with synthetic test images in MATLAB showed that the integration time should at least be kept under 1 second in order not to destroy the wave patterns. Longer integration times may however be required {{in order to get a}} sufficient SNR. Two signal processing solutions to this problem was investigated: motion blur removal by deconvolution and image averaging with motion compensation. The former strategy is to apply a long exposure time to get a strong signal, and then remove the blur with deconvolution techniques using knowledge of the blur filter. Simulations applying the Lucy-Richardson (LR) algorithm showed that it was not able to remove strong blur, and was very sensitive to errors in the blur filter and noise in the image. The other approach is to obtain a sequence of images with short exposure time in order to avoid motion blur, and provide the necessary SNR by shifting the images according to the known motion and combine them into one image. This concept is simpler and more reliable than the deconvolution approach, and simulations showed that it is less sensitive to errors in the speed estimate than the deconvolution algorithm. It was concluded that this is the most suitable approach for the NUTS application, and it should be implemented on-board the satellite in order to provide a good SNR for the compression to function optimally. The downlink datarate of NUTS is of only 9600 bit/s, and it has been estimated that 2. 45 Mb of payload data can be downloaded on average per day. This corresponds to less than 5 uncompressed images of 256 &# 215; 256 pixels with 8 bit per pixel. A sequence of overlapping combined images should be obtained to provide a scan of a desired area, and it was suggested that it should be encoded as video to enable efficient compression and transmission of as many images as possible to the ground station. A three-dimensional DPCM algorithm combined with a deadzone quantizer and stack-run coding was implemented in MATLAB. Simulations demonstrated that this simple compression scheme can provide a bit rate of less than 1 bit/px for a sequence of ravity wave images. One of the quantizers that was tried gave 0. 83 bits per pixel with reasonable quality. If this number can be achieved in practice, the image transfer ate would be increased to 45 images per day, which is a significant improvement. </p...|$|R

