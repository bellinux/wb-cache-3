0|1085|Public
40|$|The {{advent of}} {{multi-core}} processors has {{renewed interest in}} the idea of incorporating transactions into the programming model used to write multi-threaded programs. However, using lock based multi-threaded programming is hard to get right and easy to deadlock. Transactional Memory (TM) simplifies multi-threaded programming, by replacing use of locks with transactions. But, there are many problems that TM system development is facing today. Firstly, there are limited TM workloads, since TM systems existing today are in a preliminary stage. Secondly, TM systems cannot handle system calls inside transactions as of today. In this project, we look at TM related issues on two important server workloads- AOLserver and BIND. Our focus is primarily on network send() /recv() calls and their variants. We propose using a cross-layer mechanism which leverages both kernel and user level support to provide an easy and minimum performance <b>overhead</b> solution to <b>handle</b> <b>network</b> calls. From our current results we see upto 3 X overhead when send() /recv() are used for sending/receiving large packets (e. g. 1400 bytes). But, we believe that can be brought down to a negligible level using simple optimizations. Finally, we also handle conditional sychronization in transactions which can potentially lead to a deadlock. We use a simple busy-wait approach explored later in the paper. 1...|$|R
5000|$|... Metrorail {{was testing}} new <b>overhead</b> <b>handles</b> of {{different}} styles on 1122, 1123, 1126, 1127, {{as well as}} some 3000-series cars to gauge public opinion.|$|R
50|$|As of August 2008, Metrorail {{is testing}} new <b>overhead</b> <b>handles</b> of {{different}} styles on 3034, 3035, 3094, 3095 {{as well as}} some 1000-series cars to gauge public opinion.|$|R
5000|$|... <b>overhead</b> of <b>handling</b> dummy Method {{overriding}} {{for every}} method we use ...|$|R
5000|$|Reduce {{additional}} operational <b>overhead</b> for <b>handling</b> {{system issues}} due to performance problems ...|$|R
40|$|The {{intent of}} the {{workshop}} is to review {{the application of the}} ASME Nuclear Crane Standards ASME NOG- 1 and ASME NUM- 1 - 2000. The ASME Nuclear Crane standards provide a basis for purchasing <b>overhead</b> <b>handling</b> equipment with enhanced safety features, based upon accepted engineering principles, and including performance and environmental parameters specific to nuclear facilities...|$|R
50|$|There {{are several}} {{advantages}} to the drum seine over the power block. The net can be hauled very quickly - {{at more than}} twice the speed of using a power block, the net does not require <b>overhead</b> <b>handling,</b> and the process is therefore safer. The most important advantage is that the drum system can be operated with fewer deckhands.|$|R
5000|$|During World War II, {{the company}} reached record {{production}} levels, fueled by {{demand for the}} company's <b>overhead</b> <b>handling</b> equipment, including the improved Louden [...] "Super Track" [...] monorail systems. Military applications of Louden Monorail included its application for material handling devices used {{in the manufacture of}} the first atomic bomb at Oak Ridge, Tennessee, and for material handling in a B-29 bomber plant in Marietta, Georgia.|$|R
5000|$|In 1956, {{the company}} was {{purchased}} by Mechanical Handling Systems, Inc., of Detroit, Michigan. William's grandson, William L. Fry, served as the firm's president general manager from 1956 to 1963. In 1965, Louden's line of farm equipment was discontinued. Louden's <b>overhead</b> <b>handling</b> equipment continued to operate and became the Crane & Monorail Systems Division of American Chain and Cable Company (ACCO). [...] Acco-Louden continues to manufacture overhead monorail conveying equipment.|$|R
5000|$|Defines Management Information Base (MIBs) {{that are}} {{specific}} {{for the power}} industry, to <b>handle</b> <b>network</b> and system management through SNMP based methods.|$|R
50|$|GridFTP {{provides}} a fault tolerant implementation of FTP, to <b>handle</b> <b>network</b> unavailability and server problems. Transfers {{can also be}} automatically restarted if a problem occurs.|$|R
50|$|Similarly, {{the network}} {{infrastructure}} (switches, routers,…) uses buffers at each node to avoid packet loss. These buffers must be sized appropriately to <b>handle</b> <b>network</b> congestion.|$|R
50|$|In March 2014, RPM {{partnered with}} Envision Networks® of Cleveland, Ohio. Envision <b>handles</b> <b>network</b> ad {{sales for the}} show's {{terrestrial}} affiliate stations in the United States and Canada.|$|R
5000|$|A {{screw press}} {{is a type}} of machine press in which the ram is driven up and down by a screw. The screw shaft can be driven by a handle or a wheel. It works by using a coarse screw to convert the {{rotation}} of the handle or drive-wheel into a small downward movement of greater force. The <b>overhead</b> <b>handle</b> usually incorporates balls as flyweights. The weights helps to maintain the momentum and thrust of the tool {{to make it easier to}} operate.|$|R
5000|$|The {{house is}} within walking {{distance}} of the Louden Machinery Company, as it was the custom at the time for factory owners to be close to their properties. He was the third president of the company in Fairfield from 1940 to 1951, when he was killed in an auto accident[...] [...] During that period the company produced <b>overhead</b> <b>handling</b> equipment for American industries during World War II. The house was listed on the National Register of Historic Places in 2003.|$|R
5000|$|Dynamic Clustering- Locking was {{replaced}} with non-locking atomic operations, cleared contention bottlenecks, improved the async/epoll performance, and reduced thread <b>overhead</b> to <b>handle</b> 100,000 requests per second.|$|R
30|$|Klein et al. [91] {{considers}} QoS-aware service composition by <b>handling</b> <b>network</b> latencies. The authors {{present a}} network model that allows estimating latencies between locations and propose a genetic algorithm to achieve network-aware and QoS-aware service provisioning.|$|R
50|$|EFnet's channel {{operators}} are generally free {{to run their}} channels however they see fit without the intervention of IRCops. IRCops are primarily there to <b>handle</b> <b>network</b> and server related issues, and rarely get involved with channel-level issues.|$|R
30|$|<b>Handling</b> mixed-wet <b>networks</b> {{and extreme}} {{wettability}} changes.|$|R
30|$|HCR {{combines}} {{proactive and}} reactive methods to <b>handle</b> <b>network</b> connectivity restoration from a single-node failure in WSANs. The {{selection of a}} backup node is proactive, while the restoration is reactive. This scheme shortens the restoration process and reduces the overhead including distance cost and message cost. Next, the performance of HCR is analyzed.|$|R
40|$|Abstract—Construction of whole-genome {{networks}} from large-scale {{gene expression}} data {{is an important}} problem in systems biology. While several techniques have been developed, most cannot <b>handle</b> <b>network</b> reconstruction at the whole-genome scale, and the few that can, require large clusters. In this paper, we present a solution on the Intel R © Xeon Ph...|$|R
40|$|The {{growth of}} {{multimedia}} group applications coupled with advancement in high-speed networking are driving {{the need for}} efficient multicast communication protocols over the Internet. Many multimedia applications require Quality of Service (QoS) assurance with minimal service disruption. During the life-cycle of a multicast session, three important events can occur - group dynamics, traffic dynamics, and network dynamics - and these events need to be efficiently managed or handled by the multicasting protocol. Managing group dynamics is concerned with maintaining a good quality (cost) multicast tree taking into account dynamic join/leave of members; managing trac dynamics is concerned with flow, congestion, and error control; and <b>handling</b> <b>network</b> dynamics is concerned with providing reliable communication taking into account link/node failures. Although significant {{research has been done}} on the first two issues, the issue of <b>handling</b> <b>network</b> dynamics in multicasting is less understood and needs significant research attention. In thi...|$|R
50|$|These {{problems}} make it {{very difficult}} to <b>handle</b> trust <b>networks</b> in subjective logic.|$|R
40|$|Four {{computer}} {{methods of}} determining frequency response characteristics (magnitude, phase, and delay) of arbitrary linear time-invariant networks are described and compared {{with respect to}} computation time, accuracy, and suitability for component deviation studies. The programs, which are written in Fortran IV, are capable of <b>handling</b> <b>networks</b> containing a maximum of 40 nodes, 200 passive two-terminal branches, and 50 dependent source elements. [ [...] . ...|$|R
40|$|Summary: An {{essential}} element when analysing the structure, function, and dynamics of biological networks is {{the identification of}} communities of related nodes. An algorithm proposed recently enhances this process by clustering the links between nodes, rather than the nodes themselves, thereby allowing each node to belong to multiple overlapping or nested communities. The R package ‘linkcomm’ implements this algorithm and extends it in several aspects: (i) the clustering algorithm <b>handles</b> <b>networks</b> that are weighted, directed, or both weighted and directed; (ii) several visualization methods are implemented that facilitate {{the representation of the}} link communities and their relationships; (iii) a suite of functions are included for the downstream analysis of the link communities including novel community-based measures of node centrality; (iv) the main algorithm is written in C++ and designed to <b>handle</b> <b>networks</b> of any size; and (v) several clustering methods are available for networks that can be handled in memory, and the number of communities can be adjusted by the user...|$|R
5000|$|The {{international}} SCCP gateway {{belonging to}} each country knows which SCCP gateways <b>handle</b> each <b>network</b> ...|$|R
5000|$|... {{registration}} and <b>handling</b> of <b>network</b> security incidents for Poland and the “.pl” domain name space; ...|$|R
25|$|WinInet.dll is the {{protocol}} handler for HTTP, HTTPS and FTP. It <b>handles</b> all <b>network</b> communication over these protocols.|$|R
5000|$|Creation of a Traffic Management Microkernel (TMM) to {{directly}} {{talk to the}} networking hardware and <b>handle</b> all <b>network</b> activities.|$|R
5000|$|All 24 trams were {{refurbished}} between 2008 and 2009, {{which involved}} a deep clean, installation of new seats {{and a new}} lime green, blue and white external livery. The fleet is also progressively being fitted with new front LED lights. 2534 {{was the first to}} receive them following a collision with a Warburtons Lorry. Since then, cars 2531-2536, 2536-2544, 2546 and 2548-2553 have been fitted with the new front lights. 2553 was involved in a serious road traffic accident and was taken out of service for a number of months. It has recently returned to service after being repaired at the Therapia Lane depot, and during the repair a [...] "refresh" [...] was also carried out. The [...] "refresh" [...] involved a deep clean of all floorings, as well as a full interior repaint and repaint of all handrails and <b>overhead</b> <b>handles.</b>|$|R
40|$|Abstract: We {{analyze the}} {{scenario}} where {{a pair of}} network devices each periodically relies on the other to <b>handle</b> <b>network</b> traffic. Without immediate reward, the forwarding device incurs an opportunity cost in handling the other’s request. We find, however, situations where rational decision makers prefer bandwidth exchange to isolated operation. We base our analysis on a take-or-leave-it protocol inspired by the Rubinstein bargaining model, and extend it to evaluate repeated interaction between pairs of devices. ...|$|R
5000|$|Element {{management}} : <b>Handles</b> individual <b>network</b> elements including alarm management, {{handling of}} information, backup, logging, {{and maintenance of}} hardware and software.|$|R
5000|$|Detection and <b>handling</b> of <b>network</b> interruptions, {{possibly}} with {{an automatic}} attempt to reconnect to the device server to resume application data flow.|$|R
40|$|A {{possible}} {{model for}} future network management is proposed. This {{is based on}} a community of bacterial strains, each organism <b>handling</b> <b>network</b> requests {{in the same way as}} bacteria metabolise energy sources. This model makes use of the unique methods that bacteria use to transfer and share genetic material, to create a more robust solution to the service provision problems associated with future data networks. A community of autonomous, bacteria-like nodes appears to provide some degree of self-stabilising behaviour...|$|R
40|$|For {{software}} executing several threads in parallel, {{testing is}} unreliable, as it cannot cover all thread schedules. Model checking, however, can cover all possible thread interleavings. Software model checkers can directly verify an implementation, but typically cannot <b>handle</b> <b>network</b> input/output operations, which most programs require. This shortcoming {{can be addressed}} by a special model checker designed for multiple processes, or by different kinds of extensions and preprocessors for existing model checkers. This paper surveys currently existing approaches and tools...|$|R
40|$|SpaceWire is {{a widely}} used {{on-board}} data-handling network technology for spacecraft. This project aimed to investigate {{the way in which}} SpaceWire is being used in on-board data <b>handling</b> <b>networks</b> on scientific spacecraft. A real-time SpaceWire network simulation was made, modeled on the data <b>handling</b> <b>networks</b> of the future ESA missions BepiColombo MPO and Solar Orbiter. The CCSDS space packet protocol and the ECSS Packet Utilization Standard (PUS) were employed for the structuring of packets in the simulation. The SpaceWire EGSE device from STAR-Dundee Ltd. was used to perform simulations of scientific instruments using SpaceWire. Multiple scripts for the EGSE device were created to simulate the packet generation behavior of the different configuration of the instruments. Software for control and monitoring of multiple EGSE was implemented. A prototype for a generic PUS network node software was also developed. Additionally packet libraries for CCSDS and PUS were developed. A demonstration network was built using SpaceWire testing equipment, encompassingall of the developed tools. Finally the EGSE was evaluated in conjunction with the simulation, including the device’s support for generating CCSDS and PUS packets. Several improvements and additional features for the EGSE device and scripting language were suggested. Validerat; 20141204 (global_studentproject_submitter...|$|R
