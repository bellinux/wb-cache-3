0|18|Public
5000|$|Write permissions for the webserver {{user account}} in the PmWiki tree (required for <b>off-line</b> <b>editing</b> only) ...|$|R
50|$|CMX {{would later}} develop more {{advanced}} {{systems such as}} the 340 in 1976, and the CMX Edge, {{which could be used}} for both on and <b>off-line</b> <b>editing.</b>|$|R
50|$|The Spectra Ace was {{introduced}} to the market in 1986, and won the company an Emmy Award. The proprietary system for <b>off-line</b> <b>editing</b> incorporates an edit controller, a video switcher, single and dual-headed laser disc players, video monitors, videotape recorders, terminal equipment and associated software. It operated Laser Edit, Inc. as a marketing arm. Laser Edit became a post production house over time.|$|R
5000|$|Engineering Emmy Citation: David Bargan for the '409' and 'TRACE' Computer Programs {{used for}} <b>Off-line</b> Videotape <b>Editing</b> ...|$|R
5000|$|Instead {{of working}} with the actors on set, Coppola {{directed}} while viewing video monitors in the [...] "Silverfish" [...] (nickname) Airstream trailer, outfitted with then state-of-the-art video editing equipment. [...] Video feeds from the five stages at the Hollywood General Studios were fed into the trailer, which also included an <b>off-line</b> <b>editing</b> system, switcher, disk-based still store, and Ultimatte keyers. The setup allowed live and/or taped scenes to be composited with both full size and miniature sets.|$|R
50|$|Non-linear editing with {{computers}} {{as it is}} known today was first introduced by Editing Machines Corp. in 1989 with the EMC2 editor, a PC-based non-linear <b>off-line</b> <b>editing</b> system that utilized magneto-optical disks for storage and playback of video, using half-screen-resolution video at 15 frames per second. A couple of weeks later that same year, Avid introduced the Avid/1, the first in the line of their Media Composer systems. It was based on the Apple Macintosh computer platform (Macintosh II systems were used) with special hardware and software developed and installed by Avid. The Avid/1 was not the first system to introduce modern concepts in non-linear editing such as timeline editing and clip bins—both of those were pioneered in Lucasfilm's EditDroid in the early 1980s.|$|R
50|$|Headquartered in Sunnyvale, California, {{the company}} pioneered in {{integrating}} computers with videotape editing, starting in 1971 with the CMX 600, the first {{non-linear video editing}} system. The 600 was designed primarily for <b>off-line</b> <b>editing,</b> by creating both a rough cut edit of a video program, along with an edit decision list, or EDL. It stored its video & audio content on disk pack drives supplied by Memorex for instant random access of the video content. The 600 was paired with the CMX-200, which took the edit decision list created by the 600, and automatically controlled several VTRs to auto-assemble the final program. The 600 was controlled using a Digital PDP-11 minicomputer, and the 200 used a Teletype Model 33 terminal to input EDLs from the 600.|$|R
40|$|National audienceWiki {{systems have}} evolved in two {{different}} ways : semantic wikis and peer to peer wikis. Semantic wikis integrate the semantic web technologies {{in order to improve}} their structure, the search and the navigation between pages. Peer-to-peer wikis offer a support for massive collaboration, <b>off-line</b> <b>editing</b> mode and an ad-hoc collaboration. The main challenge in designing a peer-to-peer semantic wiki combining both approaches is the merge of wiki pages embedding semantic annotations. Merging algorithms used in peer-to-peer wiki systems have been designed for linear text. They do not handle semantic data. In this paper, we present SWooki the first peer-to-peer semantic wiki. SWooki combines the advantages of both semantic wikis and peer-to-peer wikis. We detail SWooki approach and its merging algorithm, we insist on its characteristics and its functionalities. We conclude by presenting its architecture and its implementation...|$|R
40|$|Current video {{compression}} formats optimize for either compression or editing. For example, motion-JPEG (MJPEG) provides excellent random access and moderate overall compression, while MPEG optimizes for compression {{at the expense}} of random access. Converting from one format to another, a process called transcoding, is often desirable over the life of a video segment. This paper shows how to transcode MPEG- 1 video to motion-JPEG without fully decompressing the MPEG- 1 source. The described technique for compressed domain transcoding differs from previous work because it uses a new approximation approach that is optimized for software implementations. This new approach is 1. 5 to 3 times faster than spatial domain transcoders and offers an additional degree of freedom: higher transcoding speeds can be obtained at the price of lower picture quality. This speed/quality trade-off is useful in many real-time applications such as <b>off-line</b> <b>editing</b> and video gateways. 1...|$|R
50|$|The {{first version}} of n-Track was {{released}} sometime between 1995 and 1996. It was originally a simple dialog box with 4 volume sliders {{for each of the}} 4 supported tracks.At the time when version 1.0 was released multitrack recording was still largely done on tape decks or professional digital workstations. Major music software of the time (such as Cubase or Cakewalk) still didn't have audio capabilities and were mostly MIDI only, while audio editors (e.g. Cool Edit and Sound Forge) were mainly concerned with <b>off-line</b> <b>editing</b> for sound design or broadcasting.Although since the mid 90s many other PC multitrack recording programs have emerged n-Track is still quite popular, as it provides a cutting-edge DAW feature set for less than US $100.In June 2010 n-Track Software released the {{first version of}} n-Track for OS X.In 2011 n-Track Software released n-Track Studio for iOS.In October 2013 n-Track Software released n-Track Studio for Android.|$|R
5000|$|It {{recorded}} and played back black-and-white [...] "skip-field" [...] video in analog on specially modified disk pack drives (supplied by Memorex, {{and which were}} commonly used to store data digitally on mainframe computers of the time) that were the size of washing machines. The audio was recorded digitally using PCM, and was recorded by being inserted in the [...] "back porch" [...] of the horizontal blanking interval pulses of the video. This audio was somewhat poor, due to {{a large amount of}} jitter occurring from the signal being played back from the disk packs. The video was also of less than stellar quality, due to it being recorded in skip-field mode (which was done to extend recording time on the disk packs). But all of this did not matter, since the 600's main purpose was solely for <b>off-line</b> <b>editing,</b> in order to create an Edit Decision List (EDL) for later on-line editing.|$|R
50|$|Joseph Antony Flaherty, Jr. was the Senior Vice President for Technology at CBS. He is the {{inventor}} and co-inventor of many television technologies including the miniature color camera, and <b>off-line</b> videotape <b>editing,</b> and co-inventor to Raymond D. Schneider of Electronic news-gathering. Flaherty was Chairman of the Planning Subcommittee of the U.S. Federal Communications Commission's (FCC) Advisory Committee on Advanced Television Service that developed the ATSC HDTV standard.|$|R
40|$|Colloque avec actes et comité de lecture. The {{paper will}} focus on the {{conceptual}} and technical design of a terminological forum developed {{in the context of the}} European MLIS­DHYDRO project. The aim of this project is to provide an integrated environment giving on-line access to a multilingual terminological database. This database corresponds to the computerisation of the existing Hydrographic Dictionary (HD) which has so far been published in three languages (English, French and Spanish) and is under development for a few additional languages, in particular German and Japanese. The set of functionalities considered for this forum are the following: - on-line and/or <b>off-line</b> <b>editing</b> of the different multilingual records in each language by a certified user; - coordination of the editorial work through a discussion forum; - central validation of a given entry by a co-ordinating supervisor; - on-line access to a larger public through standard web browsers. This is achieved thanks to a Java applet allowing the Internet users to build complex queries on the HD database; - publication of several by-products such as bilingual terminological lists, multicolumn polysemic dictionaries, in various paper and electronic formats (rtf, word, html [...] .); Such a complex project could only be tackled by relying upon some kind of standard representation of the terminological data which would permit us to define a central core representation independently of any specific target format (like html for instance). Furthermore, we aim at identifying a set of generic modules which makes the system architecture flexible enough to be applied in the framework of other terminological projects. These two goals led us first to experiment on the applicability of the MARTIF proposal as defined within TC 37 of ISO and second to implement a software platform fully based on the use of XML as the central exchange data format between modules. The paper will first provide arguments supporting our choices. It will also report the strategy used to convert the three monolingual polysemic dictionaries into a unique multilingual terminological database...|$|R
40|$|As {{performance}} {{gains in}} {{automatic speech recognition}} systems plateau, improvements to existing applications of speech recognition technology seem more likely to come from better user interface design than from further progress in core recognition components. Among all applications of speech recognition, the usability of systems for transcription of spontaneous speech is particularly sensitive to high word error rates. This paper presents a series of approaches to improving the usability of such applications. We propose new mechanisms for error correction, use of contextual information, and use of 3 D visualisation techniques to improve user interaction with a recogniser and maximise the impact of user feedback. These proposals are illustrated through several prototypes which target tasks such as: <b>off-line</b> transcript <b>editing,</b> dynamic transcript editing, and real-time visualisation of recognition paths. An evaluation of our dynamic transcript editing system demonstrates the gains {{that can be made}} by adding the corrected words to the recogniser's dictionary and then propagating the user's corrections...|$|R
5000|$|Joseph A. Flaherty, Jr. {{is the son}} of a {{television}} engineer. [...] He earned a degree in physics from Rockhurst College. From 1953 to 1955 Flaherty served at the United States Army Signal Corps Photographic Center. As Technical Director and Design Engineer of the U.S. Army's first television station, Flaherty designed the studio wherein training films were made through kinescope. Flaherty's career at CBS began in 1957 when he joined as a Design Engineer. Flaherty moved up in the ranks due to his innovations, and in 1977 he became Vice President for Technology. At CBS, he played an integral {{role in the development of}} such technologies as Electronic news-gathering, the miniature color camera, one inch videotape, <b>off-line</b> videotape <b>editing,</b> and high definition television. High definition television was one of Flaherty's chief areas of interest He presented many papers on the subject. Flaherty served as Chairman of the Planning Subcommittee of the FCC's Advisory Committee on Advanced Television Service that developed the ATSC HDTV standard.|$|R
40|$|This program {{looks at}} the {{creative}} skills needed by a video editor, and also considers some of the practical aspects of postproduction, using both linear videotape and nonlinear digital techniques. A range of examples illustrate the concepts [...] jumps in time and space, cutting interview material, crossing the line of action, jump cuts, controlling pace, association of ideas, and splitting audio and video edits. Sound techniques are illustrated for sound effects, dialogue, and music. More technical issues such as time-code, approaches to <b>off-line</b> and on-line <b>editing,</b> digital video effects, and digital nonlinear editing are also discussed. (32 minutes, color...|$|R
5000|$|The {{teleprinter}} circuit {{was often}} {{linked to a}} 5-bit paper tape punch (or [...] "reperforator") and reader, allowing messages received to be resent on another circuit. Complex military and commercial communications networks were built using this technology. Message centers had rows of teleprinters and large racks for paper tapes awaiting transmission. Skilled operators could read the priority code from the hole pattern and might even feed a [...] "FLASH PRIORITY" [...] tape into a reader {{while it was still}} coming out of the punch. Routine traffic often had to wait hours for relay. Many teleprinters had built-in paper tape readers and punches, allowing messages to be saved in machine-readable form and <b>edited</b> <b>off-line.</b>|$|R
40|$|A {{multiple}} reference {{peak identification}} method using a Lotus 1 - 2 - 3 ® spreadsheet program is developed for <b>off-line</b> identification and <b>editing</b> of chromatographic peaks on a PC-XT/AT compatible computer. There is no apparent {{limit to the}} total number of reference peaks. Any peak, regardless of size, {{can be used as a}} reference peak as long as it is well-resolved and present in both the sample and reference chromatograms. The identification is made by matching normalized retention indices of peaks in the sample chromatogram with those of known components in a calibration chromatogram. The accuracy of peak assignment is typically better than 95 %. The identification and editing of a chromatogram from a capillary gas chromatograph containing 200 peaks takes about 15 min. The software program is almost completely menu driven...|$|R

