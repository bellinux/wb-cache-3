476|2115|Public
5000|$|Contour tracking: {{detection}} of <b>object</b> <b>boundary</b> (e.g. active contours or Condensation algorithm). Contour tracking methods iteratively evolve an initial contour initialized {{from the previous}} frame to its new position in the current frame. This approach to contour tracking directly evolves the contour by minimizing the contour energy using gradient descent.|$|E
3000|$|... where d(s o) is the Euclidean {{distance}} between a snaxel s and a <b>object</b> <b>boundary</b> point o. So, the control point is {{chosen as the}} point on the <b>object</b> <b>boundary</b> which has the Hausdorff distance value.|$|E
30|$|Color {{contrast}} {{across the}} <b>object</b> <b>boundary</b> [26]. This measure {{was shown in}} [26] {{to be an effective}} objective measure of segmentation quality. The object contour is traced, and all along the <b>object</b> <b>boundary</b> pairs of blocks are chosen, with each pair consisting of one block inside and one block outside the object. The mean color value for each block is calculated, and the absolute difference between each pair of blocks is taken. The color contrast is the average of all these absolute differences along the <b>object</b> <b>boundary.</b>|$|E
30|$|All {{morphological}} processing {{techniques are}} composed of two base morphology operations - dilation and erosion. In binary image morphology, dilation increases forefront <b>object</b> <b>boundaries,</b> while erosion increases background <b>object</b> <b>boundaries.</b> Dilation and erosion functions are dual operators, where dilating background objects {{is the same as}} eroding foreground objects.|$|R
40|$|An energy model-based {{approach}} for estimating <b>object</b> <b>boundaries</b> is presented. We study a particular energy, which minimizer can be determined. The method estimates the {{unknown number of}} objects and draws <b>object</b> <b>boundaries</b> by selecting the "best" level lines computed from level sets of the original image. Unlike previous standard methods, the proposed method does not require iteration for minimizing the energy. In addition, our segmentation algorithm combines anisotropic diffusion-based regularization with level line selection to extract smooth <b>object</b> <b>boundaries.</b> Experimental results on 2 D biomedical and meteorological images are reported...|$|R
5000|$|... : {{ensemble}} {{maximum of}} [...] for [...] <b>objects</b> (<b>boundaries,</b> i.e. tuner positions).|$|R
40|$|Intuitively, the {{appearance}} of true object boundaries varies from image to image. Hence the usual monolithic approach of training a single boundary predictor and applying it to all images regardless of their content {{is bound to be}} suboptimal. In this paper we therefore propose situational <b>object</b> <b>boundary</b> detection: We first define a variety of situations and train a specialized <b>object</b> <b>boundary</b> detector for each of them using [Dollar and Zitnick 2013]. Then given a test image, we classify it into these situations using its context, which we model by global image appearance. We apply the corresponding situational <b>object</b> <b>boundary</b> detectors, and fuse them based on the classification probabilities. In experiments on ImageNet, Microsoft COCO, and Pascal VOC 2012 segmentation we show that our situational <b>object</b> <b>boundary</b> detection gives significant improvements over a monolithic approach. Additionally, our method substantially outperforms [Hariharan et al. 2011] on semantic contour detection on their SBD dataset...|$|E
40|$|Abstract. The aim of {{this paper}} is to give some {{researches}} and instructions of relations between the special shapes of an <b>object</b> <b>boundary</b> and their 8 -adjacency chain code strings, characteristics of these chain code strings, internal relations among these chain code strings. These characteristics can be used to identify the region of an <b>object</b> <b>boundary,</b> when necessary, to generate this regional boundary. But this is irrelevant to various operations on image. This function of a chain code string is similar to the roles of genes in biology, is called pan-genes. An <b>object</b> <b>boundary</b> on binary image is considered by many tiny line segments connected with each other. The research on characteristics of chain code strings of line segments is an important segment of recognition and generation of an <b>object</b> <b>boundary.</b> This paper gives characteristics of chain code strings of pan-genes corresponding line segments, relations among these chain code strings, chain code string organization forms of chain code string units of line segments (these units are abbreviated with UL), the effective ways and methods on recognition and generation of line segments. Thus, this paper studies the chain code features of corners and circles. This paper gives a variety forms and features of ULs, shows the effects and methods on recognition and generation of an <b>object</b> <b>boundary,</b> gets basic properties of chain code strings about corners and circles...|$|E
30|$|Local force F {{changes with}} the {{variation}} of mean value u and v based on Eq. (7). From Eq. (9), {{it can be found}} that F makes the curvature flow converge to the minimization. The curve will stop moving when the curvature flow approximates to 0 after several times of iterations and only the <b>object</b> <b>boundary</b> satisfies the condition. That means the curve can converge to the <b>object</b> <b>boundary</b> when the local energies do not change any more after iterations.|$|E
40|$|Concavities in the <b>boundary</b> of an <b>object</b> pose a {{challenge}} to active contour (snake) methods. In this paper, we present a snake-based scheme for efficiently detecting contours of <b>objects</b> with <b>boundary</b> concavities. The proposed method is composed of two steps. First, the <b>object's</b> <b>boundary</b> is detected using the proposed snake model. Second, snake points are optimized by inserting new points and deleting unnecessary points to better describe the <b>object's</b> <b>boundary.</b> The proposed algorithm can successfully extract <b>objects</b> with <b>boundary</b> concavities, and is insensitive {{to the number of}} initial snake points. Experimental results have shown that our algorithm produces more accurate segmentation results than the conventional algorithm. 1...|$|R
40|$|Traditionally, vision {{systems have}} largely relied upon the <b>object</b> <b>boundaries</b> {{extracted}} from images to accomplish recognition. Most contour detection algorithms, however, {{suffer from the}} fact that the extracted <b>object</b> <b>boundaries</b> are usually broken and incomplete due to poor imaging conditions and/or occlusions. In this paper, we describe an algorithm to perform curvilinear grouping of image edge elements for detecting <b>object</b> <b>boundaries.</b> The method works by generating hypotheses and selecting the best one. A neighborhood definition based on Delaunay graph is used to keep the number of hypotheses generated small. An energy minimizing curve is fit to the generated hypotheses to evaluate the grouping and locate discontinuities...|$|R
40|$|Engineering-based edge {{detection}} techniques generally use local intensity information to identify whether a pixel location {{is part of}} a boundary. Boundaries are presumed present where sharp transitions in the observed intensities occur. Unfortunately, these approaches are sensitive to error and hidden partial boundaries, which hinders the determination of closed <b>object</b> <b>boundaries.</b> In this research, a method to obtain statistically optimal closed <b>object</b> <b>boundaries</b> is presented...|$|R
30|$|Motion {{contrast}} {{across the}} <b>object</b> <b>boundary</b> [26]. This is calculated {{in a similar}} manner to the color contrast, except that motion vectors are used instead of color values.|$|E
40|$|Precision {{of depth}} has a {{significant}} impact on quality of virtual view synthesis in 3 DTV system. Artifacts exist in stereo correspondence. <b>Object</b> <b>boundary</b> artifact {{is one of the most}} difficult problems. The <b>object</b> <b>boundary</b> pixels receive colors from both foreground and background thus leads to wrong mapping. The occlusion fill-up process causes <b>object</b> <b>boundary</b> expansion which makes boundary pixels unreliable. We propose a boundary matting technique based on natural image matting algorithms to calculate the alpha value of the boundary pixels. Depth values which are suggested by alpha values can be recalculated. The limitation of matting algorithms is that they define only boundaries between two layers and cannot solve the multiple-layer definition problem. Our contribution is the localized methods of boundary matting which can solve the multiple layer boundaries in complex depth map. Our goal is superior view synthesis from stereo, thus the quality of virtual views are valued in experiments. The result shows that our technique reduces the boundary artifacts effectively...|$|E
40|$|Semantic {{segmentation}} {{is critical}} to image content understanding and object localization. Recent development in fully-convolutional neural network (FCN) has enabled accurate pixel-level labeling. One issue in previous works is that the FCN based method does not exploit the <b>object</b> <b>boundary</b> information to delineate segmentation details since the <b>object</b> <b>boundary</b> label is ignored in the network training. To tackle this problem, we introduce a double branch fully convolutional neural network, which separates the learning of the desirable semantic class labeling with mask-level object proposals guided by relabeled boundaries. This network, called <b>object</b> <b>boundary</b> guided FCN (OBG-FCN), is able to integrate the distinct properties of object shape and class features elegantly in a fully convolutional way with a designed masking architecture. We conduct experiments on the PASCAL VOC segmentation benchmark, and show that the end-to-end trainable OBG-FCN system offers great improvement in optimizing the target semantic segmentation quality. Comment: The results in {{the first version of}} this paper are mistaken due to overlapping validation data and incorrect benchmark method...|$|E
40|$|Detecting <b>object</b> <b>boundaries</b> in the {{presence}} of cast shadows is a difficult task for machine vision systems. A new edge detector is presented which responds to shadow penumbras and abrupt object edges with distinguishable signals. The detector requires the use of spatially extended light sources and sufficient video resolution to resolve the shadow penumbras of interest. Detection of high frequency noise is suppressed without requiring image-dependent adjustment of signal thresholds. The ability of the edge operator to distinguish shadow penumbras from abrupt <b>object</b> <b>boundaries</b> while suppressing responses to high frequency noise and texture is illustrated with idealized shadow and object edge intensity profiles. Selective detection of <b>object</b> <b>boundaries</b> in a video scene with a cast shadow has also been demonstrated with this operator...|$|R
30|$|Segmentation-quality-driven object enhancement: {{we take a}} set of {{segmentation}} measures while tracking {{objects to}} improve the accuracy of <b>object</b> <b>boundaries.</b>|$|R
40|$|A {{new method}} for {{representing}} and tracking of <b>object</b> <b>boundaries</b> is presented, {{which allows for}} the integration of uncertain a priori knowledge into an active contour model. The new fuzzy snake allows for an intuitive specification of the properties of an <b>object's</b> <b>boundary.</b> This is obtained by setting up a linguistic rule base, which describes each of the fuzzy snake's segments. Furthermore the approximate length of each contour segment may be specified to improve the segmentation process and to reduce the computational complexity...|$|R
40|$|In {{this paper}} we propose to extend the well known graph cut {{segmentation}} framework by learning superpixel relations {{and use them to}} weight superpixel-to-superpixel edges in a superpixel graph. Adjacent superpixel-pairs are analyzed to build an <b>object</b> <b>boundary</b> model, able to discriminate between superpixel-pairs belonging to the same object or placed on the edge between the foreground object and the background. Several superpixel-pair features are investigated and exploited to build a non-linear SVM to learn <b>object</b> <b>boundary</b> appearance. The adoption of this modified graph cut enhances the performance of a previously proposed segmentation method on two publicly available datasets, reaching state-of-the-art results...|$|E
40|$|A new {{hierarchical}} model for solid object representation is described. This model, called a Hierarchical Face Adjacency Hypergraph (HFAH), {{is based on}} a relational description of the <b>object</b> <b>boundary,</b> called a Face Adjacency Hypergraph (FAH), which considers faces as the primary topological entities defining the <b>object</b> <b>boundary.</b> The HFAH consists of a hierarchy of FAHs describing the decomposition of the boundary of an object into form features. In this paper the HFAH is described together with its internal encoding structure. Two basic transformations, called refinement and abstraction, are defined on the {{hierarchical model}}, these allow effective and efficient modifications of the hierarchical boundary mode...|$|E
40|$|Learning <b>object</b> <b>boundary</b> {{detection}} from motion data A significant {{barrier to}} applying {{the techniques of}} machine learning to the domain of <b>object</b> <b>boundary</b> detection {{is the need to}} obtain a large database of correctly labeled examples. Inspired by developmental psychology, this paper proposes that boundary detection can be learned from the output of a motion tracking algorithm that separates moving objects from their static surroundings. Motion segmentation solves the database problem by providing cheap, unlimited, labeled training data. A probabilistic model of the textural and shape properties of object boundaries can be trained from this data and then used to efficiently detect boundaries in novel images via loopy belief propagation. I...|$|E
5000|$|... #Caption: [...] (a) A simple 3d object. (b) Its medial axis transform. The colors {{represent}} {{the distance from}} the medial axis to the <b>object's</b> <b>boundary.</b>|$|R
40|$|Click on the DOI link {{to access}} the article (may not be free). Competing {{theories}} of partially occluded object perception (amodal completion) emphasize either relatively local contour relationships or global factors such as symmetry. These disparate theories may reflect 2 separate processes: a low-level contour interpolation process and a higher-order global recognition process. The 2 could be distinguished experimentally if only the former produces precise representations of occluded <b>object</b> <b>boundaries.</b> Using a dot localization paradigm, we measured the precision and accuracy of perceived <b>object</b> <b>boundaries</b> for participants instructed to complete occluded objects with divergent local and global interpretations. On each trial, a small red dot was flashed {{on top of an}} occluder. Participants reported whether the dot fell inside or outside the occluded <b>object's</b> <b>boundaries.</b> Interleaved, 2 -up, 1 -down staircases estimated points on the psychometric function where the probability was. 707 that the dot would be seen as either outside or inside the occluded <b>object's</b> <b>boundaries.</b> The results reveal that local contour interpolation produces precise and accurate representations of occluded contours, and consistency across observers, but completion according to global symmetry does not. These results support a distinction between local, automatic contour interpolation processes and global processes based on recognition from partial information...|$|R
40|$|The goal of nonrigid image {{registration}} {{is to find}} a suitable transformation such that the transformed moving image becomes similar to the reference image. The {{image registration}} problem can also be treated as an optimization problem, which tries to minimize an objective energy function that measures the differences between two involved images. In this paper, we consider image matching as the process of aligning <b>object</b> <b>boundaries</b> in two different images. The registration energy function can be defined based on the total energy associated with the <b>object</b> <b>boundaries.</b> The optimal transformation is obtained by finding the equilibrium state when the total energy is minimized, which indicates the <b>object</b> <b>boundaries</b> find their correspondences and stop deforming. We make an analogy between the above processes with the dislocation system in physics. The <b>object</b> <b>boundaries</b> are viewed as dislocations (line defects) in crystal. Then the well-developed dislocation energy is used to derive the energy assigned to <b>object</b> <b>boundaries</b> in images. The newly derived registration energy function takes the global gradient information of the entire image into consideration, and produces an orientation-dependent and long-range interaction between two images to drive the registration process. This property of interaction endows the new registration framework with both fast convergence rate and high registration accuracy. Moreover, the new energy function can be adapted to realize symmetric diffeomorphic transformation so as to ensure one-to-one matching between subjects. In this paper, the superiority of the new method is theoretically proven, experimentally tested and compared with the state-of-the-art SyN method. Experimental results with 3 -D magnetic resonance brain images demonstrate that the proposed method outperforms the compared methods in terms of both registration accuracy and computation time...|$|R
3000|$|... ext(ϕ) is the {{external}} energy on the processed images, which is defined {{such that it}} achieves a minimum when the zero level set of LSF ϕ is evolved to an <b>object</b> <b>boundary</b> (refer to detail in formation of [8]). R [...]...|$|E
40|$|Abstract—This paper {{proposes a}} method to segment object from the web images using logo detection. The method {{consists}} of three steps. In the first step, the logos are located from the original im-ages by SIFT matching. Based on the logo location and the ob-ject shape model, the second step extracts the <b>object</b> <b>boundary</b> from the image. In the third step, we use the <b>object</b> <b>boundary</b> to model the object appearance, which is then used in the MRF based segmentation method to finally achieve the object segmentation. The key of our method is the <b>object</b> <b>boundary</b> extraction, {{which is achieved by}} searching a variation of the shape model that best fits the local edge of the image. Affine transform is used to consider the variations among the objects. Meanwhile, the Nelder-Mead sim-plex method with a simple initial rough search is used to run the boundary search. To verify the proposed method, we collect a Lo-goSeg dataset from the web such as Flickr and Google. TheMOMI dataset is also used for the verification. The experimental results demonstrate that the proposed logo detection based segmentation method can improve the performance of the object segmentation. Index Terms—Specific object segmentation, logo detection. I...|$|E
30|$|As Figure 6 A shows, the moment-based active contour cannot {{detect the}} <b>object</b> <b>boundary</b> correctly. On the other hand, {{regarding}} to the moment-based active contour proposed method could detect and track object boundaries in all frames with high accuracy (Figure 6 B).|$|E
40|$|Object {{oriented}} {{representation of}} image sequences requires accurate motion segmentation and depth ordering techniques. Unfortunately, {{the lack of}} precise motion estimates at the <b>object</b> <b>boundaries</b> makes these two tasks' very difficult. In this' paper we present a detailed analysis' of the behaviour of dense motion estimation techniques at <b>object</b> <b>boundaries</b> which reveals' the systematic nature of the motion estimation error: {{the motion of the}} occluding surface is' observed in a small neighbourhood on the occluded side. We then show how the joint use of still image segmentation and robust regression can eliminate this' error. Furthermore we present a novel technique which uses the position of the error as a depth cue. The validity of this' technique, which requires only sub-pixel motion and which is capable of distinguishing between different types of intensity discontinuities, such as <b>object</b> <b>boundaries,</b> surface marks' and illumination discontinuities, is then demonstrated on several synthetic and real image sequences...|$|R
40|$|Previous {{papers from}} this reseach group have {{suggested}} that we group <b>object</b> <b>boundaries</b> not by tracking around the boundary but by pairing boundary points across the object. Such pairings {{can be used to}} compute the medial axis as described by Blum. In this paper, the results of a fuzzy (non-binary) operator sensitive to <b>object</b> <b>boundaries</b> are combined to create a response function of three variables: two spatial and one of scale. The value of this response function at any spatial position and scale is the likelihood of that spatial position being on the medial axis where the scale corresponds to the width of the object at that spatial position. These boundary-sensitive operators are applied at every spatial position and at a number of scales, and the results of these operators are combined using a technique similar to the Hough transform to produce the desired response function. Introduction Pizer and colleagues {{have suggested that}} we observe <b>object</b> <b>boundaries</b> by pairing corresponding [...] ...|$|R
40|$|We {{describe}} {{how to teach}} deformable models (snakes) to find <b>object</b> <b>boundaries</b> based on user-specified criteria, and we present a method for evaluating which criteria work best. These methods prove indispensable in abdominal CT images. Further work is needed in heart ultrasound images. The methods apply in any domain with consistent image conditions characterizing <b>object</b> <b>boundaries,</b> for which automated identification is nontrivial, perhaps due to interfering detail. A traditional strongest-edge-seeking snake fails to find an <b>object's</b> <b>boundary</b> when the strongest nearby image edges are not the ones sought. But we show how to instead learn, from training data, the relation between a shape and any image feature, as the probability distribution (PDF) of a function of image and shape. An important but neglected task {{has always been to}} select image qualities to guide a model. Because success depends on the relation of objective function (PDF) output to shape correctness, it is evaluate [...] ...|$|R
40|$|Two major {{challenges}} faced in active contours are poor cap-ture range and high sensitivity towards noise. Recently, {{the concept of}} tensor vector convolution (TVF) was introduced and shown to be promising in handling these challenges. However, {{in the presence of}} high noise levels, TVF may have difficulty in converging to the desired <b>object</b> <b>boundary,</b> par-ticularly if the distance is great between the initial contour and the <b>object</b> <b>boundary.</b> To tackle this challenge, the concept of a multi-scale tensor vector field (MTVF) active contour is introduced to further reduce noise sensitivity. Comparing the performance of MTVF with multi-scale gradient vector field and multi-scale vector field convolution demonstrates that MTVF is more resilient to high noise levels as well as significantly reducing computation time...|$|E
3000|$|... [...]) is {{selected}} {{by considering the}} point which contributes more to the distance between snake contour and <b>object</b> <b>boundary</b> [22]. We use the Hausdorff distance to find such a point. Assuming two sets of points S and O, the Hausdorff distance is then defined as [...]...|$|E
3000|$|The BS is a 1 -D {{representation}} of an <b>object</b> <b>boundary.</b> One {{of the most}} simple ways to generate the BS of a region is to plot {{the distance from the}} center of gravity of the region to the boundary {{as a function of the}} angle, [...]...|$|E
30|$|The {{consistent}} {{values of}} orientation generally represent the saliency intensive moving objects. A set of inconsistent orientation values, {{on the other}} hand, may refer to <b>object</b> <b>boundaries</b> or random motions.|$|R
40|$|Abstract — The goal of nonrigid image {{registration}} {{is to find}} a suitable transformation such that the transformed moving image becomes similar to the reference image. The {{image registration}} problem can also be treated as an optimization problem, which tries to minimize an objective energy function that measures the differences between two involved images. In this paper, we consider image matching as the process of aligning <b>object</b> <b>boundaries</b> in two different images. The registration energy function can be defined based on the total energy associated with the <b>object</b> <b>boundaries.</b> The optimal transformation is obtained by finding the equilibrium state when the total energy is minimized, which indicates the <b>object</b> <b>boundaries</b> find their correspondences and stop deforming. We make an analogy between the above processes with the dislocation system in physics. The <b>object</b> <b>boundaries</b> are viewed as dislocations (line defects) in crystal. Then the well-developed dislocation energy is used to derive the energy assigned to <b>object</b> <b>boundaries</b> in images. The newly derived registration energy function takes the global gradient information of the entire image into consideration, and produces an orientation-dependent and long-range interaction between two images to drive the registration process. This property of interaction endows the new registration framework with both fast convergence rate and high registration accuracy. Moreover, the new energy function can be adapted to realize symmetric diffeomorphic transformation so as to ensure one-to-one matching between subjects. In this paper, the superiority of the new method is theoretically proven, experimentally tested and compared with the state-of-the-art SyN method. Experimental results with 3 -D magnetic resonance brain images demonstrate that the proposed method outperforms the compared methods in terms of both registration accuracy and computation time. Index Terms — Convergence, dislocation, nonrigid registration. I...|$|R
40|$|In this work, {{we present}} a new method for {{recognizing}} planar objects by matching multiple concavities of <b>object</b> <b>boundaries</b> in a projective invariant manner. <b>Object</b> <b>boundaries</b> are first decomposed into several concavities using bitangents and obtained concavities are then sorted. Corresponding concavities are aligned by using the projective matrix computed from their bitangent and tangent points. Best concavities are selected based on the Hausdorff distance between aligned concavities. This subset of concavities is then used to align original and transformed objects. Closeness of two aligned objects is checked by the same distance metric. Proposed method is verified by several experiments...|$|R
