28|226|Public
2500|$|The 2005 New York City transit {{strike was}} a strike in New York City {{called by the}} Transport Workers Union Local 100 (TWU). [...] Negotiations for a new {{contract}} with the Metropolitan Transportation Authority (MTA) broke down over retirement, pension, and wage increases. The strike began at 3:00 a.m. EST on December 20, 2005. Most New York City Transit Authority and MTA Bus Company personnel observed the strike, effectively halting all service on the subway and buses, except for routes operated from the Spring Creek Depot, where workers represented by ATU Local 1181/1061 had a contract in force after striking against the predecessor <b>operator,</b> <b>Command</b> Bus Company, the previous year. Millions of commuters were affected. The strike officially ended at 2:35 p.m. EST on December 22, 2005. Service was restored overnight, with all transportation systems fully operational by the morning commute of the 23rd.|$|E
5000|$|Exploits are {{executed}} from new/unknown <b>operator</b> <b>command</b> servers; ...|$|E
5000|$|Malware {{calls out}} to or connects to known <b>operator</b> <b>command</b> servers; ...|$|E
50|$|<b>Operator</b> <b>commands</b> are {{available}} to change both the backlog and execution priorities of runs. As all <b>operator</b> <b>commands</b> {{are available}} by API to suitably privileged users, this can be automated or controlled by a remote administrator.|$|R
25|$|Operator-assist modes {{have the}} <b>operator</b> <b>commanding</b> medium-to-high-level tasks, with the robot {{automatically}} {{figuring out how}} to achieve them.|$|R
40|$|A new teletobotic control concept which couples human {{supervisory}} commands {{with computer}} reasoning is presented. The control system is responsive and accomplishes an <b>operator's</b> <b>commands</b> while providing obstacle avoidance and stable controlled {{interactions with the}} environment {{in the presence of}} communication time delays. This provides a system which not only assists the operator in accomplishing tasks but modifies inappropriate <b>operator</b> <b>commands</b> which can result in safety hazards and/or equipment damage...|$|R
50|$|WFL {{also has}} an {{instruction}} block command {{which is used to}} give operators instructions needed to run the current job. These instructions are displayed using the 'IB' <b>operator</b> <b>command.</b>|$|E
50|$|The z/OS {{operating}} system allows started tasks {{to be modified}} by an <b>operator</b> <b>command.</b> That allows {{the behavior of the}} started task to be dynamically altered. The degree of modification permitted {{is a function of the}} started task program and the limits of the environment.|$|E
50|$|Another {{security}} mechanism is that code files {{can only be}} created by trusted compilers. Malicious programmers cannot create a program {{and call it a}} compiler - a program could only be converted to be a compiler by an operator with sufficient privileges with the 'mc' make compiler <b>operator</b> <b>command.</b>|$|E
50|$|The RJE console {{operator}} could enter a restricted set of HASP Console <b>Operator</b> <b>Commands.</b> These HASP commands were the precursor of JES2's Job Entry Control Language(JES2 JECL).|$|R
30|$|In the {{teaching}} phase, a human <b>operator</b> <b>commands</b> a robot with {{an input device}} such as a teach pendant and a data glove to perform a manipulation task. Here we call it demonstration.|$|R
5000|$|There is {{some part}} of the {{physical}} world whose behavior is to be controlled in accordance with commands issued by an operator. The problem is to build a machine that will accept the <b>operator's</b> <b>commands</b> and impose the control accordingly.|$|R
50|$|High Exec {{priority}} {{is used by}} the <b>operator</b> <b>command</b> handler and some other functions that may have to run even when a real time program has control. They are expected to use only very short amounts of time. If they need more time, they should queue the work to be processed by a Low Exec activity.|$|E
50|$|The 2005 New York City transit {{strike was}} a strike in New York City {{called by the}} Transport Workers Union Local 100 (TWU). Negotiations for a new {{contract}} with the Metropolitan Transportation Authority (MTA) broke down over retirement, pension, and wage increases. The strike began at 3:00 a.m. EST on December 20, 2005. Most New York City Transit Authority and MTA Bus Company personnel observed the strike, effectively halting all service on the subway and buses, except for routes operated from the Spring Creek Depot, where workers represented by ATU Local 1181/1061 had a contract in force after striking against the predecessor <b>operator,</b> <b>Command</b> Bus Company, the previous year. Millions of commuters were affected. The strike officially ended at 2:35 p.m. EST on December 22, 2005. Service was restored overnight, with all transportation systems fully operational by the morning commute of the 23rd.|$|E
5000|$|The Avco AN/FPS-26 Radar was an Air Defense Command {{height finder radar}} {{developed}} in the Frequency Diversity Program with a tunable 3-cavity power klystron for electronic counter-countermeasures (e.g. to counter jamming). Accepted by the Rome Air Development Center on 20 January 1960 for use at SAGE radar stations, the AN/FPS-26 processed height-finder requests (e.g., from Air Defense Direction Centers) by positioning to the azimuth of a target aircraft using a high-pressure hydraulic drive, then [...] "nodding" [...] in either a default automatic mode or by <b>operator</b> <b>command.</b> The inflatable radome required a minimum pressure to prevent contact with the antenna which would result in damage to both (technicians accessed the antenna deck via an air lock.) To maintain high dielectric strength, the waveguide was pressurized with sulfur hexafluoride (SF6), which technicians were warned would produce deadly fluorine if the waveguide arcing occurred.|$|E
50|$|<b>Operator</b> <b>commands</b> {{are mostly}} two letters (as with Unix), {{and some are}} just one letter. This means that the {{operator}} interface must be learned, {{but it is very}} efficient for experienced operators who run a large mainframe system from day to day. Commands are case insensitive.|$|R
50|$|Large {{systems have}} {{dedicated}} operations terminals called ODTs (Operator Display Terminals), usually {{kept in a}} secure environment. For small systems, machines can be controlled from any terminal (provided the terminal and user have sufficient privileges) using the MARC program (Menu Assisted Resource Control). <b>Operator</b> <b>commands</b> {{can also be used}} by users familiar with them.|$|R
5000|$|... ? - <b>Operator</b> input <b>command,</b> {{used when}} user's input is required. Usually used with →(variable) ...|$|R
50|$|The main {{achievement}} {{of that time}} was the installation in 1956 of the four 45-meters metal towers with 320 spotlights with a total brightness of lightning of 500 lux. From that time on the football games in Kiev were possible to conduct in evening. Also in 1956 a more contemporary scoreboard was installed. It had a clock {{in the middle and}} was equipped with electric lamps that displayed the result of match by <b>operator</b> <b>command.</b> In October 1962 the stadium changed its name to the Central Stadium. It was at that time that the old scoreboard was replaced with a new electronic one which was bought in Hungary. On April 10, 1963 at the game Dynamo Kyiv - Spartak Moscow the spectators could for the first time see the scoreboard display the result of the match with specifying minutes when the goals were scored and the names of their authors.|$|E
40|$|This paper {{develops}} a receding horizon control based methodology as an operator support tool for large mining excavators. The system alters the <b>operator</b> <b>command</b> when necessary to avoid collisions, e. g. with trucks being loaded. We describe {{key aspects of}} the problem that must be mapped to the receding horizon framework to implement the technology. Specifically, a level-of-detail based approach is presented to map the object avoidance conditions into constraints on the state in a space conducive to control. The approach accounts for the non-predictive nature of the <b>operator</b> <b>command.</b> The efficacy of the resulting methodology is demonstrated in simulation...|$|E
40|$|NMSU’s College of Engineering {{launched}} a nanosatellite {{to collect data}} for its scientific experiments. The goals of this launch were as follows: • Science: Measuring the earth and space UV intensity every 10 seconds for at least 45 minutes at night • Engineering: Demonstrating {{the capabilities of the}} hard-ware and software components needed for orbital missions • Outreach: Providing public view of operations via the amateur radio APRS network • Bonus Features: Taking pictures upon <b>operator</b> <b>command</b> and operate payload remotely over the Internet Photo taken by NMSU’s nanosatellite Please submit your research-related news online a...|$|E
5000|$|... an operator’s {{teleprinter}} device (with a slow {{paper tape}} punch built-in) permitting programs to display {{information to the}} operator, and the operator to use the keyboard to punch up short program or data items on paper-tape. This teleprinter {{could not be used}} to input data directly to the computer, all <b>operator</b> <b>commands</b> had to be input through the operator’s console.|$|R
40|$|Kinematic {{equations}} allow arm to pass smoothly through singular region. Report discusses mathematical singularities in equations of robotarm control. <b>Operator</b> <b>commands</b> {{robot arm}} {{to move in}} direction relative to its own axis system by specifying velocity in that direction. Velocity command then resolved into individual-joint rotational velocities in robot arm to effect motion. However, usual resolved-rate equations become singular when robot arm is straightened...|$|R
50|$|Due to the {{historical}} character of the surroundings, the project underwent revisions relating to the alignment of the metro line. The discovery of a Byzantine-era vault on the Unkapanı bank during excavation works for pier foundations forced a redesign of the project. The design of the swing bridge <b>operator's</b> <b>command</b> building had to be revised when {{the wall of a}} Byzantine-era basilica and a graveyard on the same bank came to light.|$|R
40|$|Discusses three {{trends in}} the {{application}} of computer control to accelerators. These are the trends towards multi-computer control systems, the use of computer driven operator interaction devices, and the use of interpretive highlevel language software. The computer control system for the new CERN 400 GeV synchrotron carries these trends to their extremes. It consists of 24 essentially similar computers linked together using serial data links and a message transfer computer. The software is based on an interpreter for a high level interactive language NODAL. This is used as an <b>operator</b> <b>command</b> language and as a high level application programming language. (2 refs) ...|$|E
40|$|Presented at the 52 nd National Conference on Fluid Power, Las Vegas, NV, USA, March 23 - 25, 2011. Researchers at the Georgia Institute of Technology have {{demonstrated}} that the completion time of common excavation tasks is decreased when an operator and an electronic agent share control of the actuator velocity commands. In this Blended Shared Control architecture, the intended operator task is estimated with a recursive algorithm; the task is optimized in real time; and a command perturbation is computed which results in a lower task completion time when summed with the <b>operator</b> <b>command.</b> Experimental results compare Blended Shared Control to conventional manual control and manual control supplemented with haptic feedback. Trials indicate that Blended Shared Control decreases task completion time by up to 15 percent...|$|E
40|$|Computer systems which {{interact}} with human users to collect, update or provide information are growing more complex. Additionally, users are demanding more thorough testing of all computer systems. Because {{of the complexity}} and thoroughness required, automation of interactive systems testing is desirable, especially for functional testing. Many currently available testing tools, like program proving, are impractical for testing large systems. The solution presented here {{is the development of}} an automated test system which simulates human users. This system incorporates a high-level programming language, ATLIS. ATLIS programs are compiled and interpretively executed. Programs are selected for execution by <b>operator</b> <b>command,</b> and failures are reported to the operator's console. An audit trail of all activity is provided. This solution provides improved efficiency and effectiveness over conventional testing methods...|$|E
40|$|Concerns a hexapod {{walking robot}} {{designed}} for use in living and working spaces where {{it is necessary to}} ascend and descend structures such as stairs. It is designed to carry loads while always maintaining horizontal balance. It has eight CPUs for controlling the movement of twenty driving motors and for detecting attitude and its environment. It can move around autonomously as well as according to the <b>operator's</b> <b>commands.</b> The robot's configuration, structure and mechanism, and intelligence, are discussed</p...|$|R
40|$|ABSTRACT: The paper {{considers}} the case, where a service robot and human operator {{work together in}} the same working area. A novel control interface improves the communication and interaction between robot and <b>operator.</b> <b>Commands</b> and supervision are made by speech and gestures – the most natural communication for humans. Innovative yo-yo handcontroller provides unique control possibilities for all kind of teleoperation from robot driving to manipulator control. Interaction with enviroment is improved with virtual reality models and novel pointing technology...|$|R
5000|$|Additional {{commands}}: New commands can be {{such things}} as shorthand commands to issue commands to Services, to network <b>operator</b> only <b>commands</b> to manipulate a user's hostmask.|$|R
40|$|A new {{intelligent}} fusion {{scheme for}} human <b>operator</b> <b>command</b> and autonomous planner/controller in telerobotic {{system has been}} developed based on the event-based planning and control theory. It provides a unified model to integrate a human operator control command with action planning and control of autonomous operation. As a result, the telerobotic system can perform tasks which cannot be done by either human operator or autonomous planner/controller alone. This scheme lays down a foundation for planning and control of a general robotic system involving human operators, and provides a natural and efficient way to fuse the human intelligence with the machine intelligence. The scheme is implemented and tested on a PUMA 560 robotic system. The experimental results of obstacle avoidance, and hybrid force/position control with a commanded force are presented. Link_to_subscribed_fulltex...|$|E
40|$|This {{paper will}} discuss {{proposed}} Flight Operations methodologies and technologies for the Earth Observing System (EOS) Operations Center (EOC), to reduce {{risks associated with}} the operation of complex multi-instrument spacecraft in a multi-spacecraft environment. The EOC goals are to obtain 100 percent science data capture and maintain 100 percent spacecraft health, for each EOS spacecraft. Operations risks to the spacecraft and data loss due to <b>operator</b> <b>command</b> error, mission degradation due to mis-identification of an anomalous trend in component performance or mis-management of resources, and total mission loss due to improper subsystem configuration or mis-identification of an anomalous condition. This paper discusses automation of routine Flight Operations Team (FOT) responsibilities, Expert systems for real-time non-nominal condition decision support, and Telemetry analysis systems for in-depth playback data analysis and trending...|$|E
40|$|The CMM is a {{computer}} controlled robot for dimensional inspection, involving complex mathematical calculations and fast data transmissions both ways: computer (operator) – controller – actuators and reverse, probe – controller – computer. The delay between the <b>operator</b> <b>command</b> and the actual movement of the machine is significant, and other applications running on the computer increase this amount of time. Shortening the signal path by including the controllers in a software application will improve the transmission time and other features will be available. The portability of the programs developed in such application will be enhanced, the readings will be more accurate and finally {{a new type of}} hybrid CMM could be developed. Our purpose is to trace the major lines of this project and develop an application to control the movement and to acquire data from a positioning system with steppers...|$|E
30|$|The {{method is}} {{composed}} of two parts: teaching phase and playback phase. In the teaching phase, a human <b>operator</b> <b>commands</b> a robot to achieve a manipulation task. All {{the movements of the}} robot are recorded. All the images of the teaching scenes are also recorded by a camera. Then, a mapping from the recorded images to the movements is obtained as an artificial neural network. In the playback phase, the motion of the robot is determined by the output of the neural network calculated from scene images.|$|R
40|$|This paper {{introduces}} {{a framework for}} the remote execution of whole body motions for humanoid robots. Humanoid robots are biped machines which usually possess multi degrees of freedom (DOF). The complexity of their structure and the difficulty in maintaining postural stability make the whole body operation of humanoid robots fundamentally different from traditional fixed-base manipulators or stable-base mobile manipulators. Getting hints from human conscious and subconscious motion generations, we propose a method of generating whole body motions which integrates <b>operator’s</b> <b>command</b> input and the robot’s autonomous functions. Instead of giving commands to all joints all the time, the operator selects only the necessary points of the humanoid robot’s body for manipulation. This paper first explains {{the concept of the}} system and the framework for integrating <b>operator’s</b> <b>command</b> and autonomous functions in whole body motion generation. Using the framework, we constructed autonomous functions for maintaining stability constraint while satisfying the desired trajectory of operation points and a workspace extension autonomy which changes utilization of body parts. Finally the paper reports on the implementation of the proposed method to teleoperate a 30 DOF humanoid robot HRP- 2 using only two 3 DOF joysticks. Experiments teleoperating HRP- 2 confirmed the effectiveness of the proposed method...|$|R
30|$|The main {{contributions}} {{of this paper}} are the proposal for {{a modified version of}} model-based teleoperation using mixed force and motion commands and the parallel-robot-based HILS of the massive payload manipulation. The proposed method deals with force scaling. In force scaling, mitigation of excessive force at the remote site will be the key issue, because the <b>operator’s</b> <b>commands</b> are scaled-up at the remote site, and there is a serious communication delay. The mitigation of generated force at the remote site using the proposed method was verified by performing HIL simulations.|$|R
