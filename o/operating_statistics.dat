18|49|Public
5000|$|As {{a surgeon}} shares with Dr. Pablo Acosta Ortiz glory {{of being one}} of the founders of modern surgery in Venezuela. The {{hospital}} Vargas was the scene par excellence of surgical performance, supported by the head teacher of the Clinical Surgery chair. In his extensive <b>operating</b> <b>statistics,</b> several surgical procedures stand out as being performed for the first time in the country. Razetti also introduced a multitude of techniques and the use of surgical instruments. Among his surgical literature stands his book, Lessons and clinic notes, and his work about appendicitis, typhus intestinal perforations, eclampsia and the Cesarean operation. In 1911, he was the founder of the first private clinic established in Caracas for the caring for the sick and performing high surgery. Her brother, Ricardo Razetti was the design engineer and builder of the clinic, which is known to this day as [...] "Policlina Luis Razetti".|$|E
50|$|The Exit or Terminal Multiple Approach {{assumes a}} {{business}} {{will be sold}} {{at the end of}} the projection period. Valuation analytics are determined for various <b>operating</b> <b>statistics</b> using comparable acquisitions. A frequently used terminal multiple is Enterprise Value/EBITDA or EV/EBITDA. The analysis of comparable acquisitions will indicate an appropriate range of multiples to use. The multiple is then applied to the projected EBITDA in Year N, which is the final year in the projection period. This provides a future value at the end of Year N. The terminal value is then discounted using a factor equal to the number of years in the projection period. If N is the 5th and final year in this period, then the Terminal Value is divided by (1+k)5. The Present Value of the Terminal Value is then added to the PV of the free cash flows in the projection period to arrive at an implied Enterprise Value. Note that if publicly traded comparable company multiples must be used, the resulting implied enterprise value will not reflect a control premium. Depending on the purposes of the valuation, this may not provide an appropriate reference range.|$|E
50|$|The Perpetuity Growth Model {{has several}} {{inherent}} characteristics {{that make it}} intellectually challenging. Because both the discount rate and growth rate are assumptions, inaccuracies in one or both inputs can provide an improper value. The {{difference between the two}} values in the denominator determines the terminal value, and even with appropriate values for both, the denominator may result in a multiplying effect that does not estimate an accurate terminal value. Also, the perpetuity growth rate assumes that free cash flow will continue to grow at a constant rate into perpetuity. Consider that a perpetuity growth rate exceeding the annualized growth of the S&P 500 and/or the U.S. GDP implies that the company's cash flow will outpace and eventually absorb these rather large values. Perhaps the greatest disadvantage to the Perpetuity Growth Model is that it lacks the market-driven analytics employed in the Exit Multiple Approach. Such analytics result in a terminal value based on <b>operating</b> <b>statistics</b> present in a proven market for similar transactions. This provides a certain level of confidence that the valuation accurately depicts how the market would value the company in reality.|$|E
50|$|Good Morning America {{featured}} a D.C. school where Playworks <b>operates,</b> citing <b>statistics</b> that 15 minutes of recess leads to better performance in class. Two-thirds of principals reported better listening and increased focus after recess.|$|R
5000|$|... (short {{hand for}} Nigels Monitor) is a {{computer}} performance system monitor tool for the AIX and Linux operating systems developed by IBM employee Nigel Griffiths. The tool displays onscreen or saves to a data file the <b>operating</b> system <b>statistics</b> to aid the understanding of computer resource use, tuning options and bottlenecks.|$|R
30|$|The size {{of final}} {{population}}/archive must be smaller the given maximum population size, otherwise, a compulsory truncation will be <b>operated</b> in final <b>statistics</b> for fair comparisons.|$|R
40|$|In January, 1946, I read a paper {{before this}} Society, on the {{financial}} and <b>operating</b> <b>statistics</b> of the G. S. Rys. Co. and G. N. R. Co., 1938 - 44, which was preceded in May, 1938, by a similar survey of the G. S. Rys. Co. 1925 - 37, and also {{an analysis of the}} legislation affecting the Company during that period. The object of the present paper is to outline the chief provisions of the Irish Transport Acts, 1944 and 1950, and, in addition, a consideration of the financial and <b>operating</b> <b>statistics</b> of C. I. E. and of the G. N. R. Co. from 1945 to 1951...|$|E
40|$|Summary of {{financial}} and <b>operating</b> <b>statistics</b> of the 30 largest transit {{properties in the}} United States. Mode of access: Internet. Issued by: U. S. Dept. of Transportation, Federal Transit Administration, Continued by an online electronic publication called: National transit database. Transit profiles. Thirty largest agencies for [...] ...|$|E
40|$|Arailable {{information}} on gust structure, airplane reactions, and pertinent <b>operating</b> <b>statistics</b> has been examined. This report aitempts to coordinate this injormdon uith {{reference to the}} prediction ofgwt loads on airplanes. The material coceredrepresents researchup to October 1947. 1 NTRODUCTION The fact that alI airplanes fly in rough air at some time poses {{a number of problems}} reIative to safe fl&jht. One of the most important of these. problems is that of designing the airpkme structure to withstand the loads imposed b-y gusts. The three principal phases of the gust-Ioad problem are: (1) the determimt ion of the gust structure (that is, the size, shape, intensity, and frequency of occurrence), (2) the reaction of any airpIane to gusts of known structure, and (3) the determination of the <b>operating</b> <b>statistics...</b>|$|E
40|$|Includes bibliographical {{references}} (pages 53 - 56) The {{development and}} implementation of a materiel management and statistics system in the operating rooms of a University teaching hospital is described. A perpetual inventory system is described that is maintained by the operating room materiel management staff. An <b>operating</b> room <b>statistics</b> system is documented. that provides various statistical reports for management. Economic order quantity is evaluated as to the savings that can achieved...|$|R
40|$|In this paper, {{we address}} the problem of {{identifying}} and localizing multiple instances of highly deformable objects in real-time video data. We present an approach which uses PCA-SIFT (Scale Invariant Feature Transform) in combination with a clustered voting scheme to achieve detection and localization of multiple objects while providing robustness against rapid shape deformation, partial occlusion, and perspective changes. We test our approach in two highly deformable robot domains and evaluate its performance using ROC (Receiver <b>Operating</b> Characteristic) <b>statistics...</b>|$|R
50|$|The Agora World Wide Web email browser {{was based}} on the Line Mode Browser. The Line Mode Browser was very popular in the {{beginning}} of the web, since it was the only web browser available for all <b>operating</b> systems. <b>Statistics</b> from January 1994 show that Mosaic had quickly changed the web browser landscape and only 2% of all World Wide Web users browsed by Line Mode Browser. The new niche of text-only web browser was filled by Lynx, which made the Line Mode Browser largely irrelevant as a browser. One reason was that Lynx is much more flexible than the Line Mode Browser. It then became a test application for the libwww.|$|R
40|$|In May, 1938, I read a paper {{before this}} Society on the {{published}} accounts and <b>operating</b> <b>statistics</b> of the G. S. Rlys. Co. from its formation in 1925 to 1937. The present paper is much wider in scope : {{it is an}} attempt to make a somewhat similar survey of the G. S. Rlys. Co. and G. N. R. Co. for 1938 - 44...|$|E
40|$|Statement of Responsibility) Interstate Commerce Commission, Bureau of Statistics. (Dates or Sequential Designation) Feb. 1925 -(Numbering Peculiarities) Compares the <b>operating</b> <b>statistics</b> of {{the current}} month and year {{with that of the}} {{preceding}} year. "Compiled from [...] . reports of freight service statistics (form OS-A) representing [...] . railways and from [...] . reports of passenger service statistics (form OS-B) representing [...] . railways (switching and terminal companies not included) " (varies slightly). Title from caption. (Citation/Reference) Picklist IC 1 ste 2...|$|E
40|$|Description based on: 12 {{months ended}} Dec. 31, 1971; title from cover. Mode of access: Internet. Formed by the merger of: Operating {{revenues}} and operating expenses of class I railroads in the United States; Selected income and balance sheet items; <b>Operating</b> <b>statistics</b> of class I line-haul railroads in the United States, selected items; Train and yard service of class I railroads in the United States; Revenue traffic statistics of class I line-haul railroads in the United States; and Motive power and car equipment of class I railroads in the United States...|$|E
40|$|Background and Purpose —The stroke subtype, Oxfordshire Community Stroke Project classification, age, and prestroke {{modified}} Rankin (SOAR) {{score is}} a prognostic scale proposed for early mortality prediction after acute stroke. We aimed {{to evaluate whether}} including a measure of initial stroke severity (National Institutes of Health Stroke Scale and modified-SOAR [mSOAR] scores) would improve the prognostic accuracy. Methods —Using Anglia Stroke and Heart Clinical Network data, 2008 to 2011, we assessed the performance of SOAR and mSOAR against in-hospital mortality using area under the receiver <b>operating</b> curve <b>statistics.</b> We externally validated the prognostic utility of SOAR and mSOAR using an independent cohort data set from Glasgow. We described calibration using Hosmer–Lemeshow goodness-of-fit test. Results —A total of 1002 patients {{were included in the}} derivation cohort, and 105 (10. 5...|$|R
40|$|The Norwegian {{emission}} inventory {{is a joint}} undertaking between the Climate and Pollution Agency 1 and Statistics Norway. Statistics Norway {{is responsible for the}} collection and development of activity data, and emission figures are derived from models <b>operated</b> by <b>Statistics</b> Norway. The Climate and Pollution Agency is responsible for the emission factors, for providing data from specific industries and sources and for considering the quality, and assuring necessary updating, of emission models like, e. g., the road traffic model and calculation of methane emissions from landfills. Emission data are used for a range of national applications and for international reporting. The Climate and Pollution Agency is responsible for the Norwegian reporting to United Nations Framework Convention on Climate Change (UNFCCC) and to United Nations Economic Commission Europe (UN-ECE) ...|$|R
40|$|A symmetry-adapted {{algorithm}} producing uniformly {{at random}} {{the set of}} symmetry independent configurations (SICs) in disordered crystalline systems or solid solutions is presented here. Starting from Pólya's formula, {{the role of the}} conjugacy classes of the symmetry group in uniform random sampling is shown. SICs can be obtained for all the possible compositions or for a chosen one, and symmetry constraints can be applied. The approach yields the multiplicity of the SICs and allows us to <b>operate</b> configurational <b>statistics</b> in the reduced space of the SICs. The present low-memory demanding implementation is briefly sketched. The probability of finding a given SIC or a subset of SICs is discussed {{as a function of the}} number of draws and their precise estimate is given. The method is illustrated by application to a binary series of carbonates and to the binary spinel solid solution Mg(Al,Fe) 2 O 4...|$|R
40|$|The {{objective}} {{of this paper is}} to report some of the recent results obtained at SLAC in conjunction with the operation of the two-mile accelerator and to describe various key improvement programs which are now under-way or projected in the near future. 1. SLAC <b>Operating</b> <b>Statistics</b> The SLAC accelerator has been engaged in a pro-gram of particle physics research since the last quarter of calendar year 1966. Since then, the number of oper-ating shifts per week devoted to particle physics has steadily increased while the shifts used for machine physics have decreased. This trend is illustrated in Fig. 1. Because of budgetary limitations, the total num-ber of scheduled shifts has declined in the two most re-cent quarters shown but is expected to increase some...|$|E
40|$|In this {{contribution}} {{we present}} results of using possibly inaccurate knowledge of model derivatives {{as part of}} the training data for a multilayer perceptron network (MLP). Even simple constraints offer significant improvements and the resulting models give better prediction performance than traditional data driven MLP models. 1 Introduction An increasingly important application of neural networks is in modeling nonlinear plants for simulation and control purposes. Often the training must be done with measurements from normal operating situations. Then, depending on the <b>operating</b> <b>statistics</b> during the data collection, many important features of the process behavior may be lacking from the data. An important type of knowledge from any process to be controlled is the effect of control variables to the output variables. Typically the process experts can tell the direction and coarse magnitude of the change in product variables as function of the control variables, even though they could [...] ...|$|E
40|$|Hotel {{operators}} and observers often employ industry-wide averages as key points of comparison and analysis for room rates, occupancy, and revenues. The use of simple averages, however, {{can be misleading}} if one {{does not take into}} account the possibility that a mean will be pulled in one direction or another by extreme values. This analysis of three industry averages shows that those averages are, indeed, subject to distortion, or skew. The analysis, which examines figures for virtually all brand-name hotels in the United States, determined that the means for average daily rate (ADR) and revenue per available room (RevPAR) are skewed in a positive direction by hotels with extremely high rates. On the other hand, occupancy is skewed in a negative direction by a group of hotels with inordinately low occupancy levels. A more complete picture of the industry’s ADR, RevPAR, and occupancy is gained by examining two other measures: the median, which is a measure of the data’s middle value, and the mode, which states the most common data point. By comparing the mean with the median and the mode, one can determine the extent to which the mean overstates the industry’s ADR and RevPAR and understates the typical occupancy. Specifically, 61 percent of U. S. hotels recorded a RevPAR below the overall mean and 63 percent saw an ADR below the mean, but only 48 percent reported occupancy below the mean. Many of the extreme values are found in the top- 25 markets, which have hotels with inordinately high ADRs. Analysis of those markets shows that, once again, the overall statistics are distorted by a relatively small set of hotels with exceptional ADRs and occupancies. However, each of the top markets shows a distinctive rate and occupancy pattern. The pattern of skewed <b>operating</b> <b>statistics</b> carries over into individual lodging segments. The greatest distortions arise in the luxury and upscale segments, while economy and budget hotels record more consistent (normally distributed) statistics. Finally, the analysis shows that although the events of September 11, 2001, created much turmoil for the industry, the hotel business had already cooled substantially from its record pace of a year earlier. In conclusion, managers must be careful in applying overall industry statistics to their own situation and should take into account the factors that distort <b>operating</b> <b>statistics...</b>|$|E
40|$|International audienceBased on atomic scale {{simulation}} techniques, {{we study}} the dislocation pinning mechanism in a dilute Ni(Al) model solid solution. For a solute concentration between 1 and 10 at. %, {{we found that}} the pinning of the dislocation on obstacles made of Al pairs is an interaction that <b>operates</b> significantly. The <b>statistics</b> of the dislocation motion is then modified accordingly {{to the nature of the}} obstacles and follows a modified Mott-Nabarro statistics. Finally, a method to address thermal activation is proposed and exemplified on a periodic row of solute...|$|R
40|$|The Statistical Training Institute (STI) <b>operates</b> {{under the}} <b>Statistics</b> Korea(KOSTAT) {{and is the}} only {{national}} agency which offers statistical education. Mission of the STI is to nurture statistical experts and raise understanding of statistics. Sometimes, Ubiquitous learning (u-learning) is equivalent to some form of simple mobile learning that learning environments can be accessed in various contexts and situations. But, u-learning environment may detect more context data than e-learning. U-Learning Materials is defined as learning materials that may be transferred to mobile devices via cable or wirelessly and b...|$|R
30|$|We {{applied a}} machine {{learning}} (ML) algorithm, logistic LASSO, to hip and knee registry {{data from a}} high-volume facility to predict 2 -year MCICs in SF- 36 physical (PCSs) and mental component scores (MCSs). We derived models that incrementally incorporated information available: (1) before the decision to have surgery, (2) before surgery, (3) before discharge, and (4) after discharge. We evaluated performance with area under the receiver <b>operating</b> characteristic (AUROC) <b>statistics</b> using a hold-out sample of registry patients not used in model creation. We further tested whether these models could predict 6 -month MCICs in PROMIS- 10 PCSs and MCSs in a validation sample from our EMR.|$|R
40|$|After the Civil War, American railroads {{struggled}} with profitability problems because they lacked {{an understanding of}} the nature of short-range profits as they related to long-term investments, especially an investment that had to be upgraded and expanded almost continually. In the early 1870 s, Albert Fink, superintendent of the Louisville and Nashville Railroad, experimented with a cost-analysis system. In general the purpose of the system devised by Fink was to measure the profitability and efficiency of the railroad';s operations in terms of then-revolutionary concepts of fixed and variable costs and costs allocated to multiple accounting periods. Fink's <b>operating</b> <b>statistics,</b> such as revenue and expenses per ton-mile and passenger-mile, became standards in the industry and earned Fink the designation of 'Father of Railroad Economics'. Fink used his cost management techniques to argue against the regulation of the entire rail industry by impending legislation that would create the Interstate Commerce Commission which would subsequently embrace his costing methodology. His statistical analysis also helped to create the basic managerial concept of 'control through statistics', wherein business decisions are made based on sound information. Accounting History Albert Fink Us Railroads,...|$|E
40|$|The Advanced Light Source (ALS) {{has been}} {{operational}} for users since October 1993 when white {{light from a}} bend magnet was delivered to the Center for X-Ray Optic`s (CXRO) x-ray microprobe end-station. Since then, the ALS has installed and commissioned three undulators and their beamlines (including monochrornators and post-monochromator focusing optics), and eight bend magnet beamlines, including one dedicated to machine diagnostics. Apart from one serious outage, when scheduled beam was not available to users for 17 days, the ALS has enjoyed remarkable <b>operating</b> <b>statistics,</b> with typically 95 % of scheduled beam-time delivered to the users. Beam quality has also been very good. With a vertical emittance measured at 0. 06 nm-rad, the electron beam is kept stable to about one-tenth of it`s transverse dimensions, {{in the face of}} changing error fields in the insertion devices (as their main fields are varied), temperature variations and floor vibration. The longitudinal motion of the beam, which leads to an increase in the electron beam energy spread, and thence, to a degradation of the undulator spectra, has recently been brought under control by the addition of an innovative feedback system. This paper focuses on those aspects of electron beam stability that we find most affect the ALS users: beam size and position, and energy spread...|$|E
40|$|We {{study the}} {{earnings}} of executives of for-hire trucking companies from 1977 to 1986. Following deregulation of the U. S. trucking industry in 1979 - 1980, the real earnings of trucking firm executives (corporate officers) fell {{for a year or}} two, but then stabilized and, in the mid- 1980 s, recovered. Profit rates also fell immediately after deregulation, and then leveled off. The earnings of employee drivers, on the other hand, went into steady decline from 1979 to past the end of the period studied here. To analyze these trends we use a version of the Motor Carrier Financial and <b>Operating</b> <b>Statistics,</b> collected by the Interstate Commerce Commission on all medium-sized and large trucking firms for the years 1977 - 1986. Our version is unique in breaking out annual employee earnings by employee category for this time period. We document the change in the relative earnings of drivers and executives within the same trucking firms over time. We test the predictions of principal-agent theory and the political constraint model concerning the effect of deregulation on the level and performance sensitivity of executive pay, and find evidence favoring political constraint over principal-agent. We also explore the effects of union presence and union busting on the pay of executives, and find that officers in unionized firms get paid more on average, but that officers' pay increases when a unionized firm goes non-union. ...|$|E
40|$|Road {{pavements}} worldwide {{are constantly}} under pressure of ever-increasing demands from economic and other market forces. Because of these forces, road infrastructure needs constant protection {{and it is}} therefore necessary to understand the ever-changing <b>operating</b> conditions. <b>Statistics</b> on inter-regional traffic in southern Africa indicate that there is severe overloading of heavy vehicles- up {{to as much as}} 70 per cent overloading. The aim {{of this paper is to}} highlight the approach and application of the Stress-In-Motion (SIM) technology to assist in an improved definition of the actual tyre/pavement interaction of modern heavy vehicles and their loads on the current road infrastructure. Experience indicates that it is difficult to measure these tyre/pavement interaction forces from real trucks and that the measuring equipment is expensive and difficult to maintain. However, efforts have been made in South Africa to gain an improved quantification of the shape and magnitude of the three-dimensional tyre/pavement forces measured from real trucks. In the paper some SIM data sets collected on two National Highways in South Africa are also briefly discussed. Lastly, this paper provides an initial discussion on potential truck tyre parameters envisaged for Performance Based Standards (PBS) on flexible pavements...|$|R
40|$|Abstract—Previous {{distributed}} {{anomaly detection}} efforts have <b>operated</b> on summary <b>statistics</b> gathered from each node. This {{has the advantage}} that the audit trail is limited in size since event sets can be succinctly represented. While this minimizes the bandwidth consumed and helps scale the detection to {{a large number of}} nodes, it limits the infrastructure’s ability to identify the source of anomalies. We describe three optimizations that together allow fine-grained tracking of the sources of anomalous activity in a Grid, thereby facilitating precise responses. We demonstrate the scheme’s scalability in terms of storage and network bandwidth overhead with an implementation on nodes running BOINC. The results generalize to other types of Grids as well. Keywords-anomalies, correlation, filtration, lineage, monitoring, provenance, temporal, vaccinatio...|$|R
40|$|In this paper, we {{describe}} how {{we used a}} standard database management system (System 2000) and a computer utility to build a sophisticated medical records system {{in support of a}} national multi-clinic clinical trial. Privacy, protocol adherence, quality control and other key elements of an ethical clinical trial were satisfied {{at a fraction of the}} development cost for the more traditional approach of building a customized system. We feel that old lessons learned in other areas regarding the balance of manual to automated systems and the use of standard software are applicable to medical information systems. Neither a medical setting nor a clinical experiment changes the basic issues of good systems design. <b>Operating</b> and efficiency <b>statistics</b> gathered during two years of system production operation are presented...|$|R
40|$|The period 1 April 1993 [...] 31 March 1994 {{has seen}} a number of {{significant}} developments of the research program as will be noted by the large increase in individual projects reviewed in this annual report. Among the highlights of the K 500 experimental program in Sections 1, 2, and 4 are the investigations of excitation energy deposition and of fission dynamics employing both GDR and particle emission probes, measurements of isospin equilibration, studies of (d, {sup 2 }He) reactions with the proton spectrometer and of the {beta} decay of {sup 57 }Cu with MARS, and the precise studies of ionic charge state distributions using x-ray measurements. Progress in theoretical studies of the nuclear spectral function and the decay of many body systems, on the properties of mesons in hot hadronic matter and on the determination of astrophysical S-factors from experimental studies of very peripheral reactions are presented in Section 3. The status of the LAMPF based MEGA experiment and of the CERN based NA 66 experiment, both of which involve institute scientists, is also briefly presented in this report. The shift to a seven day a week operation coupled with installation of cryopanels and more careful temperature control of the cooling water system have resulted in significant improvements in the operational efficiency and beam capabilities. <b>Operating</b> <b>statistics</b> are presented in Section 5...|$|E
40|$|Background: The activPAL {{has been}} {{identified}} as an accurate and reliable measure of sedentary behaviour. However, only limited information is available on the accuracy of the activPAL activity count function as a measure of physical activity, while no unit calibration of the activPAL has been completed to date. This study aimed to investigate the criterion validity of the activPAL, examine the concurrent validity of the activPAL, and perform and validate a value calibration of the activPAL in an adolescent female population. The performance of the activPAL in estimating posture was also compared with sedentary thresholds used with the ActiGraph accelerometer. Methodologies: Thirty adolescent females (15 developmental; 15 cross-validation) aged 15 – 18 years performed 5 activities while wearing the activPAL, ActiGraph GT 3 X, and the Cosmed K 4 B 2. A random coefficient statistics model examined the relationship between metabolic equivalent (MET) values and activPAL counts. Receiver operating characteristic analysis was used to determine activity thresholds and for cross-validation. The random coefficient statistics model showed a concordance correlation coefficient of 0. 93 (standard error of the estimate = 1. 13). An optimal moderate threshold of 2997 was determined using mixed regression, while an optimal vigorous threshold of 8229 was determined using receiver <b>operating</b> <b>statistics.</b> The activPAL count function demonstrated very high concurrent validity (r = 0. 96, p, 0. 01) with the ActiGraph count function. Levels of agreement for sitting, standing, and stepping between direct observation and th...|$|E
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references. The intercity bus industry in the United States enjoyed its peak profitability and ridership during World War II. Since that time, the private automobile and air service have taken many of the bus industry's revenues and passengers away. The passage of the Bus Regulatory Reform Act of 1982 was an effort to decrease operating costs and increase ridership by allowing bus companies to discontinue unprofitable routes, have freedom over the setting of fares, and enter into new, competitive markets. While the actual effects the Bus Regulatory Reform Act has had on the bus industry nationwide have been studied, there has been no analysis of the changes in the intercity bus industry of Texas specifically. The objective of this research was to study the effects the Bus Regulatory Reform Act of 1982 has had on the Texas intercity bus industry. Data were collected on the number of places served by the intercity bus in Texas in the last twenty-three years, to see how the number of locations has changed. Financial <b>operating</b> <b>statistics</b> for bus companies serving Texas were compiled for several years {{both before and after the}} passage of the Act, to determine how regulatory reform has affected the financial status of bus operators. Surveys of both Texas households and Texas bus riders were distributed and compared against the results of similar surveys performed before the Act to determine the differences in attitudes of both the public and bus passengers toward intercity bus service. The results are consistent with the hypothesis that the Bus Regulatory Reform Act has had an impact on the intercity bus industry in Texas. First, the number of places served by the intercity bus has dropped dramatically, at a rate much greater than the rate at which places were losing service before the Act. Second, the operating ratios (ratio of operating expenses to operating revenues multiplied by 100) of bus companies serving Texas are significantly higher in years following regulatory reform, indicating that the companies have become less profitable. Finally, attitudes of the Texas public and Texas bus riders have become more negative toward intercity bus service. Further research recommended in this area includes an investigation of the effects that Greyhound Lines, Inc. 's recently announced changes (including the introduction of a computerized reservations system and the creation of a "frequent riders" program) have had on Greyhound's profitability and ridership. Because Greyhound is the nation's largest, and only national bus carrier, the results of its restructuring will likely be a harbinger of the fate of the industry as a whole...|$|E
40|$|Frontotemporal lobar {{degeneration}} (FTLD) often overlaps clinically with corticobasal syndrome (CBS) {{and progressive}} supranuclear palsy (PSP), {{both of which}} have prominent eye movement abnormalities. To investigate the ability of oculomotor performance to differentiate between FTLD, Alzheimer's disease, CBS and PSP, saccades and smooth pursuit were measured in three FTLD subtypes, including 24 individuals with frontotemporal dementia (FTD), 19 with semantic dementia (SD) and six with progressive non-fluent aphasia (PA), as compared to 28 individuals with Alzheimer's disease, 15 with CBS, 10 with PSP and 27 control subjects. Different combinations of oculomotor abnormalities were identified in all clinical syndromes except for SD, which had oculomotor performance that was indistinguishable from age-matched controls. Only PSP patients displayed abnormalities in saccade velocity, whereas abnormalities in saccade gain were observed in PSP > CBS > Alzheimer's disease subjects. All patient groups except those with SD were impaired on the anti-saccade task, however only the FTLD subjects and not Alzheimer's disease, CBS or PSP groups, were able to spontaneously self-correct anti-saccade errors as well as controls. Receiver <b>operating</b> characteristic <b>statistics</b> demonstrated that oculomotor findings were superior to neuropsychological tests in differentiating PSP from other disorders, and comparable to neuropsychological tests in differentiating the other patient groups. These data suggest that oculomotor assessment may aid in the diagnosis of FTLD and related disorders...|$|R
40|$|Country {{with good}} {{education}} condition {{can be seen}} through its citizen scientific literacy. This research aims to improving the students’ scientific literacy ability by using discovery learning model at 7 th grade students of State Junior High School 3 Ngronggot, Nganjuk-Indonesia. The instrument in this Kemmis and Taggart Model of Classroom Action Research was an essay test composed based on indicators developed by Gormaly. The results of the research showed that there were improvements on the students’ scientific literacy ability from cycle I to cycle II on six of seven indicators. Those improvements are as follows: Indentifying scientific opinion increased from 0 % into 64. 52 %, reviewing literature effectively increased from 0 % into 29. 03 %, understanding research design and the way how its effect to the finding/discussion increased from 14. 29 % into 19. 35 %, making graphic from the data correctly increased from 0 % to 58. 07 %, solving problems using quantitative skill including <b>operating</b> basic <b>statistics</b> increased from 7. 14 % to 58. 07 %. However, in making inference, prediction and drawing conclusion based on quantitative data, the improvement was only on the students’ answer that got 1 score, it increased from 7. 14 % to 77. 42 %. In addition, for the indicator of understanding and interpreting basic statistic, it decreased from 21. 43 % to 12. 90 %...|$|R
40|$|Introduction Simulation is a {{numerical}} technique for conducting experiments on a computer. Computer simulation {{is used in}} engineering and the sciences to rerun physical experiments with selected changes in parameters or <b>operating</b> conditions. In <b>statistics</b> simulation experiments are most often used to study properties of statistical methods. Many real statistical processes can be simulated on a computer {{with the aid of}} random numbers. Monte Carlo simulations in statistics are computer experiments involving random sampling from probablility distributions to study properties of statistical methods. Here, we will focus on simulations using Monte Carlo methods. Simulation is an invaluable and versatile tool in those problems where analytic techniques are inadequate. For example, in regression with correlated normally distributed errors, the properties of the generalized least squares estimator are easy to derive when the covariance matrix Var(y) is known, but what hap...|$|R
