46|112|Public
5000|$|In statistics, Cochran's C test, {{named after}} William G. Cochran, is a one-sided upper limit {{variance}} <b>outlier</b> <b>test.</b> The C test {{is used to}} decide if a single estimate of a variance (or a standard deviation) is significantly larger than a group of variances (or standard deviations) with which the single estimate {{is supposed to be}} comparable. The C test is discussed in many text books [...] and has been recommended by IUPAC [...] and ISO. [...] Cochran's C test {{should not be confused with}} Cochran's Q test, which applies to the analysis of two-way randomized block designs.|$|E
50|$|The C test {{assumes a}} {{balanced}} design, i.e. the considered full data set should consist of individual data series that all have equal size. The C test further assumes that each individual data series is normally distributed. Although primarily an <b>outlier</b> <b>test,</b> the C test {{is also in}} use as a simple alternative for regular homoscedasticity tests such as Bartlett's test, Levene's test and the Brown-Forsythe test to check a statistical data set for homogeneity of variances. An even simpler way to check homoscedasticity is provided by Hartley's Fmax test, but Hartley's Fmax test has the disadvantage that it only accounts for the minimum and the maximum of the variance range, while the C test accounts for all variances within the range.|$|E
5000|$|In statistics, in the {{analysis}} of two-way randomized block designs where the response variable can take only two possible outcomes (coded as 0 and 1), Cochran's Q test is a non-parametric statistical test to verify whether k treatments have identical effects. It is named after William Gemmell Cochran. Cochran's Q test {{should not be confused with}} Cochran's C test, which is a variance <b>outlier</b> <b>test.</b> Put in simple technical terms, Cochran's Q test requires that there only be a binary response (e.g. success/failure or 1/0) and that there be more than 2 groups of the same size. The test assesses whether the proportion of successes is the same between groups. Often it is used to assess if different observers of the same phenomenon have consistent results (interobserver variability).|$|E
40|$|Motivation: As {{the use of}} microarrays {{in human}} studies {{continues}} to increase, stringent quality assurance is necessary to ensure accurate experimental interpretation. We present a formal approach for microarray quality assessment {{that is based on}} dimension reduction of established measures of signal and noise components of expression followed by parametric multivariate <b>outlier</b> <b>testing...</b>|$|R
50|$|This is the two-sided {{version of}} the test. The Grubbs test can also {{be defined as a}} one-sided test. To test whether the minimum value is an <b>outlier,</b> the <b>test</b> {{statistic}} iswith Ymin denoting the minimum value. To test whether the maximum value is an <b>outlier,</b> the <b>test</b> statistic iswith Ymax denoting the maximum value.|$|R
40|$|Inter-laboratory {{studies are}} {{performed}} with different aims and consequently require different evaluation methods and statistical treatment. The review considers method-performance studies (collaborative trials), laboratory-performance studies (proficiency tests), collaborative bias evaluation, inter-laboratory evaluation of to-be standard methods {{as well as}} certification studies for reference materials. Besides the classical evaluation methods using <b>outlier</b> <b>tests,</b> robust statistics and graphical methods are taken into account...|$|R
5000|$|Based on {{measurements}} of [...] and , {{a set of}} values [...] and [...] is acquired for [...] Three successive values of [...] are examined for consistency within 2 μV before the data are accepted. This eliminates data that may be corrupted by the transient that occurs {{when there is a}} spontaneous transition between quantum voltage steps. Since [...] and [...] change by equal amounts during a step transition, [...] remains constant thus making the data collection process relatively immune to step transitions. Data are collected efficiently even for a Josephson array chip that may be making as many as five transitions per minute. The scatter in the data that results from noise in the unknown and in the null meter can generally be modeled by a Gaussian process with one standard deviation on the order of 20 to 100 nV. There are, however, occasional noise spikes that do not fit this process and generate glitches in the [...] data that may lie 1 μV to 10 μV away from the well behaved data. An <b>outlier</b> <b>test</b> is used to detect and eliminate such data.|$|E
40|$|With more {{satellite}} systems becoming available {{there is currently}} a need for Receiver Autonomous Integrity Monitoring (RAIM) to exclude multiple outliers. While the single <b>outlier</b> <b>test</b> can be applied iteratively, {{in the field of}} statistics robust methods are preferred when multiple outliers exist. This study compares the <b>outlier</b> <b>test</b> and numerous robust methods with simulated GPS measurements to identify which methods have the greatest ability to correctly exclude outliers. It was found that no method could correctly exclude outliers 100 % of the time. However, for a single outlier the <b>outlier</b> <b>test</b> achieved the highest rates of correct exclusion followed by the MM-estimator, L 1 -norm. As the number of outliers increased MM-estimators and the L 1 -norm obtain the highest rates of normal exclusion, which were up to ten percent higher than the <b>outlier</b> <b>test...</b>|$|E
40|$|Abstract:- A {{study is}} carried out to {{investigate}} the sampling properties of the <b>outlier</b> <b>test</b> statistics of a procedure developed for detecting level change in BL(1, 1, 1, 1) processes. It is done {{with respect to the}} sample size, the type of outlier {{and the size of the}} coefficients of the BL(1, 1, 1, 1) process. The results show that, in general, the outlier detection procedure is capable of detecting level change, although the performance is affected if ω is large. Key-Words:- Level change, bilinear process, <b>outlier</b> <b>test</b> statistics, outlier detection procedure, sampling properties. ...|$|E
40|$|Economics Research PaperThis paper {{analyses}} additive outlier and innovational <b>outlier</b> <b>tests</b> for seasonal unit roots when seasonal mean shifts occur {{under the}} null hypothesis. When {{the magnitude of}} the breaks is large, simulation evidence reveals that, for three of the four testing procedures considered, the endogenously determined break point can be incorrectly estimated, resulting in spurious rejections of the null. A simple modification to one of the testing approaches is proposed which achieves a substantial improvement in test size...|$|R
40|$|The {{methods of}} very robust {{regression}} resist up to 50 % of outliers. The algorithms for very robust regression rely on selecting numerous subsamples of the data. New algorithms for LMS and LTS estimators that have increased computational efficiency due to improved combinatorial sampling are proposed. These and other publicly available algorithms are compared for outlier detection. Timings and estimator quality are also considered. An algorithm using the forward search (FS) {{has the best}} properties for both size {{and power of the}} <b>outlier</b> <b>tests...</b>|$|R
40|$|In {{breeding}} industries, {{a challenging}} problem {{is how to}} keep genetic diversity over generations. To investigate genetic variation and identify breeding signatures in mass selected lines of Pacific oyster (Crassostrea gigas), three sixth-generation selected lines and four wild populations were assessed using 103 single nucleotide polymorphism (SNP) markers. The genetic diversity data indicated that the selected lines exhibited {{a significant reduction in}} the observed heterozygosity and observed number of alleles per locus compared with the wild populations (P≤ 0. 05), indicating the selected lines tended to lose genetic diversity contrasted with the wild populations. The unweighted pair-group method with arithmetic mean (UPGMA) analysis showed that the wild populations and selected lines were not separated into two groups. Using four <b>outlier</b> <b>tests,</b> a total of 17 loci were found under selection at two levels. The global outlier detection suggested that 4 common outlier loci were subject to selection using both the hierarchical island model and Bayesian likelihood approaches. At regional level, 3 SNPs were detected as outlier using at least two <b>outlier</b> <b>tests</b> and one <b>outlier</b> SNP (CgSNP 309) was overlapped in the two wild-selected population comparisons. The candidate outlier SNPs provide valuable resources for future association studies in C. gigas...|$|R
40|$|To {{enable the}} use of {{multiple}} satellite navigation systems in aviation, Receiver Autonomous Integrity Monitoring will be required to detect the presence of multiple satellite failures. The current methods of providing Fault Detection in the chi-square test and the <b>outlier</b> <b>test</b> provide adequate integrity for a single biased measurement. However, it is shown, with an example, that the current methods do not provide sufficient integrity against multiple faults. Consequently, a new chi-square test method for two biases is derived. In addition, the multiple <b>outlier</b> <b>test</b> method for two biases is presented with the associated Protection Levels. It is then shown that the new methods appear to provide adequate integrity against two biases...|$|E
40|$|Abstract: Critical {{values for}} the {{significance}} levels α= 0. 0100, 0. 0500, and 0. 1000 and sample sizes from n = 3 to n = 30 for Dixon’s <b>outlier</b> <b>test</b> have been calculated using Monte Carlo simulation. For the one-sided and two-sided case critical values are determined, which are accurate to within ± 0. 00001 to ± 0. 00007...|$|E
40|$|With the {{increasing}} automation of measurement, adjustment, outlier detection and the consequential {{use of the}} results for real-time applications, reliable methods to detect and mitigate an outlier are required. However, it is frequently advised that the <b>outlier</b> <b>test</b> {{should not be used}} as a means to automatically reject an outlier. One of the reasons for this is that the outlier detection test at times can identify a wrong measurement. To address this issue, this paper proposes a new outlier separability test to confirm that the identified outlier, by the <b>outlier</b> <b>test,</b> can be confidently rejected as the outlier. In addition, the Minimally Separable Bias and the separability multiplying factor are also obtained for the proposed outlier separability test. With the initial comparisons between the proposed method with the reapplication of the global model test method and multiple hypothesis method, the advantages of the new outlier separability test are demonstrated...|$|E
40|$|Understanding the {{selective}} forces promoting adaptive population divergence {{is a central}} issue in evolutionary biology. The role of environmental salinity in driving adaptation and evolution in aquatic organisms is still poorly understood. We investigated the relative impacts of habitat type (cf. saltwater vs. freshwater) and geographic area in shaping adaptive population divergence, as well as genes responsible for adaptation to different salinities in nine-spined sticklebacks (Pungitius pungitius). To this end, we employed a hitchhiking mapping approach with 111 microsatellite loci and one insertion/deletion locus including 63 loci situated within or close to genes with important physiological functions such as osmoregulation, growth, and thermal response. Using three pairs of marine and freshwater populations from different geographic areas, we identified several loci showing consistent evidence of being under directional selection in different <b>outlier</b> <b>tests.</b> Analyses of molecular variance at the loci under selection indicated that geographic area rather than habitat type has been acting as a central force in shaping adaptive population divergence. Nevertheless, both <b>outlier</b> <b>tests</b> and a spatial analysis method indicated that two loci (growth hormone receptor 2 and DEAD box polypeptide 56) are involved in adaptation to different habitats, implying that environmental salinity has been affecting them as a selective force. These loci are promising candidates for further investigations focusing on the molecular mechanisms of adaptation to marine and freshwater environments...|$|R
40|$|This {{thesis is}} mainly focused on {{developing}} a contaminated land risk assessment model in GIS. For this purpose Contaminated Land Exposure Assessment (CLEA) and Human Exposure Assessment - Soil, (HERA-Soil) are selected. CLEA {{is a popular}} model in construction and remediation industry in the UK is selected. This model is published by the Environment Agency in England and Wales and estimates the generic assessment criteria (GAC) for soil which provides a threshold to assess brownfield sites. CLEA, includes four land use scenario, Residential with Garden, without Garden, Allotment and Commercial, and estimates the exposure through ten exposure pathway for the critical receptor of each scenario. HERA-Soil is a developed version of CLEA that includes the same land uses, exposure pathways; however HERA-Soil applies the Alternative Integration Procedure (AlP) to estimate the GAC, which reduces the simulation time. CLEA and HEAR-Soil models are currently available via Excel spread sheets and are lacking visual representation of the results on a map and GIS functionalities. Another shortcoming of these models {{is the lack of}} statistical tests for soil samples of a site. This is important since, in site investigation, the GAC is compared with the soil sample of the site to decide whether the site is contaminated or not. A detailed study of CLEA, HERA-Soil and related statistical issues is undertaken in this study and two plug-ins are created. Plug-in, is a set of software components which adds specific abilities to a larger application. The first plug-in which is HERA-Soil-GIS, which implements HERA-Soil in an open source GIS application, Quantum GIS, thus makes this model available in a GIS environment and empowers it with GIS tools. The second plug-in is Soil-Statistics-Gl S, consists of a variety of statistical <b>outlier</b> <b>tests</b> on the maximum value in a sample and includes six various <b>outlier</b> <b>tests.</b> These tests are consistent with the size of the sample and the level of significance that is required. These two plug-ins complement each other and lead to a detailed comprehensive contaminated land risk assessment. To validate the HERA-Soil-GIS, results of this plug-in are compared with those from CLEA and HERA-Soil, for 54 compounds and almost resemble each other. In order to demonstrate how HERA-Soil and CLEA benefit from GIS a case study is undertaken. Google map and Satellite map can be easily loaded for any location on the globe. This case study involves using HERA-Soil and GIS tools such as voronoi polygon and other GIS features. The site can be divided into blocks (zones) that clarify how the concentration for each contaminant varies across the site. For the purpose of testing the Soil-Statistics-GIS and describing its abilities three samples of varying size and distribution are used and all the tests used in this plug-in are applied. The importance of statistical <b>outlier</b> <b>tests</b> in decision making is discussed by making a decision in one case with and without identifying potential outliers using these tests. To validate this plug-in, all the tests are applied twice, by running Soil-Statistics-GIS and applying the tests on soil samples in Excel and comparing the outcome. Contributions made by this research is connecting HERA-Soil, a developed version of CLEA, to GIS and making it available in a GIS environment, also creating statistical <b>outlier</b> <b>tests</b> available in the same GIS environment for this model. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|It {{is known}} that the {{reliability}} of a geodetic network depends on magnitude of minimum undetectable error {{and its effect on}} the unknown parameters. Thus detection and remove of all outliers from geodetic observations improves the reliability of that geodetic network. Since base of statistical procedure for detection of outliers is statistical tests on the least square residuals and generally there are correlations between least square residuals so sensitivity of this procedure is limited. This paper presents fuzzy-statistical procedure for determination of outliers set using fuzzy techniques. This procedure is tested on two simulated geodetic networks and the results have been compared with the results of the conventional <b>outlier</b> <b>testing</b> (COT) method...|$|R
30|$|Currently, the {{software}} starts the analysis with version 4 NGS card files, {{meaning that the}} group delay ambiguities have already been resolved and the ionospheric corrections have been calculated. We are presently developing a module for doing also these parts, which {{would allow us to}} start from the version 1 NGS/vgosDB files. Outliers are detected after running VIE_LSM/VIE_KALMAN by applying an <b>outlier</b> <b>test</b> (here, a simple 5 - σ <b>outlier</b> <b>test</b> was used) or by manual inspection and are then removed in a second run already when reading in the data in VIE_INIT. Clock breaks currently need to be manually detected by investigating the post-fit residuals. The clock breaks are then removed in a first, simple solution where in principle only clock parameters are estimated. For VIE_LSM, this first solution is an LSM solution, while for VIE_KALMAN, it is possible to choose between a Kalman filter and an LSM solution. In this work, we applied the LSM option in VIE_KALMAN, however tests show that this has only a minor impact on the results. We consistently applied the outliers and the clock breaks detected in the GFZ contribution to ITRF 2014 (Heinkelmann et al. 2014) (a solution calculated with VIE_LSM) in both the LSM and Kalman filter solutions.|$|E
40|$|Abstract. The {{effects of}} the model and weight {{function}} on outlier detection are evaluated by the simulated optical and radar observations. The iterative reweighted M-estimation based on different iterative reweighted functions {{is used for the}} outlier detection test. Three typical models of the optical and radar tracking data are compared for their effect on the <b>outlier</b> <b>test.</b> The simulated results show that different weight functions have small difference on the outlier detection efficiency and a good modeling selection for the same dataset is an key factor for a best outlier detection procedure...|$|E
40|$|BACKGROUND AND OBJECTIVES: European {{legislation}} requires {{manufacturers of}} plasma products to report epidemiological data on human immunodeficiency virus, hepatitis B virus and hepatitis C virus in donor populations. The incidence rates of such infections {{are directly related}} to the risk of infection transmission. We propose two statistical tests to evaluate these incidence rates. MATERIALS AND METHODS: Infection data of the four Dutch blood collection centres from 2003 through 2006 were analysed. For transversal comparison of centres and detection of increased incidence rates, a new statistical test was developed (<b>outlier</b> <b>test).</b> For longitudinal detection of trends in incidence rates, a generic test for trend is proposed. The power and risk of non-detection are evaluated for both tests. RESULTS: Application of the <b>outlier</b> <b>test</b> did not reveal any significantly increased incidence rates among centres in The Netherlands. The test for trend showed no significant increase in incidence rates in individual centres, but on national level a statistically significant increase in hepatitis C virus incidence was observed (P-value of 0. 01). CONCLUSION: The proposed tests allow signalling of outlier centres and trends in incidence rates both at individual centre and at national levels. Graphical support and the use of as much relevant historical data as possible is recommended. The statistical tests described are generic and can be applied by any blood establishment and plasma fractionation institut...|$|E
40|$|AbstractAn <b>outlier</b> {{detection}} <b>test</b> {{related to}} a robustified score test is proposed and compared with the sign test and other test based on functions of estimated residuals. Examples of an autoregressive process and a regression model with autoregressive errors are presented to illustrate the techniques...|$|R
40|$|Heterogeneity in {{lifetime}} {{data may}} be modelled by multiplying an individual's hazard by an unobserved frailty. We {{test for the}} presence of frailty of this kind in univariate and bivariate data with Weibull distributed lifetimes, using statistics based on the ordered Cox-Snell residuals from the null model of no frailty. The form of the statistics is suggested by <b>outlier</b> <b>testing</b> in the gamma distribution. We find through simulation that the sum of the k largest or k smallest order statistics, for suitably chosen k, provides a powerful test when the frailty distribution is assumed to be gamma or positive stable, respectively. We provide recommended values of k for sample sizes up to 100 and simple formulae for estimated critical values for tests at the 5 % level...|$|R
40|$|In this paper, we {{consider}} subset deletion diagnostics for fixed effects (coefficient functions), random effects and one variance component in varying coefficient mixed models (VCMMs). Some simple updated formulas are obtained, {{and based on}} which, Cook's distance, joint influence and conditional influence are also investigated. Besides, since mean shift outlier models (MSOMs) are also efficient to detect outliers, we establish an equivalence between deletion models and MSOMs, which is not only suitable for fixed effects but also for random effects, and test statistics for outliers are then constructed. As a byproduct, we obtain the nonparametric "deleteÂ =Â replace" identity. Our influence diagnostics methods are illustrated through a simulated example and a real data set. Conditional influence Cook's distance "Delete=Replace" identity Influence diagnostics Joint influence <b>Outlier</b> <b>tests...</b>|$|R
40|$|In {{this paper}} we study the {{performance}} of basketball players paying special attention to stability and regularity with the focus on points scored. To this end we model regularity using the median absolute deviation for variables explaining its variation and we employed the Cochran variance <b>outlier</b> <b>test</b> to identify the players with largest variance in his performance. Also we analyze the ordinal patterns of player’s performance considering short term evaluations (3 games per week). Our research provides an advancement on a simple but important question in basketball metrics: how to measure regularity in points scored and which factors may influence it...|$|E
40|$|The climate {{variability}} of the North Atlantic:European sector {{is characterized by}} large-scale circulation patterns {{measured in terms of}} a time series of two binary variables: the occurrence of a Grosswetter state and of a cluster set of meridional sea level pressure (SLP) gradients (characterizing the westerlies). An <b>outlier</b> <b>test</b> of the decadal behaviour of the residence time of these states identifies the decade 1981 – 1990 to be the first outlier. The climatological embedding and a possible stochastic:dynamical interpretation are presented. Copyright © 2000 Royal Meteorological Society. KEY WORDS: North Atlantic:Europe; time series; cluster analysis; Markov process; residence time; Grosswetter state; sea level pressure; air temperature 1...|$|E
40|$|Participation in {{proficiency}} testing (PT) {{is an important}} task {{to meet the requirements}} of ISO/IEC 17025 in the area of quality assurance of laboratory results. A PT program in the field of chemical analysis of iron ore was organized by CSIR-National Metallurgical Laboratory, Jamshedpur (nodal laboratory) and CSIR-National Physical Laboratory, New Delhi (PT Coordinator) during November 2011 -January 2012. Twenty-two (22) laboratories in India participated in the PT program. The results of participating laboratories were first analyzed to identify the distribution patterns and the presence of outliers. Several parametric and robust statistical methods were used to identify the outliers. Correct outlier rejection is of utmost importance because the choice of the <b>outlier</b> <b>test</b> method influence the consensus value and standard deviation which in turn determine the Z-score of a laboratory result in a PT program. In the present study, five parametric outlier tests were compared: Dixon's Q test, Grubbs single test, double test, t test, and Z-scores. In addition three robust tests as alternative to parametric tests were chosen: box plot, Huber test and MAD-based test. It was observed that multiple <b>outlier</b> <b>test</b> methods should be used to identify the outliers in a PT program especially when the number of participating laboratories is less. They complement each other and helps give diverse information and better overview of the data set. Among the 22 participating laboratories, Z-scores of 4 laboratories for analysis of total iron fall outside the acceptable limit of +/- 2. Similarly, for analysis of alumina and silica, five laboratories had unacceptable Z-scores...|$|E
40|$|Multivariate outlier {{detection}} requires computation of robust {{distances to}} be compared with appropriate cut-off points. In this {{paper we propose a}} new calibration method for obtaining reliable cut-off points of distances derived from the MCD estimator of scatter. These cut-off points are based on a more accurate estimate of the extreme tail of the distribution of robust distances. We show that our procedure gives reliable tests of outlyingness in almost all situations of practical interest, provided that the sample size is not much smaller than 50. Therefore, it is a considerable improvement over all the available MCD procedures, which are unable to provide good control over the size of multiple <b>outlier</b> <b>tests</b> for the data structures considered in this paper...|$|R
50|$|In {{the years}} 1971-1974, 1976, 1978 and 1983, he {{returned}} to the National Geodetic Survey in Maryland to perform various research projects. In 1972 he was invited to teach at the Technical University Vienna (Austria) after the death of Karl Ledersteger, but he declined. From 1977-1982 {{he was a member of}} the Satellite Geodesy Commission of DGK and the Netherlands. From 1978-2000 he had full Professorship (Universitäts-Professor) at the University of Bonn and was Director of the Geodetic Institute. His work included research in statistics, deformation measurements, variance-covariance estimations in geodesy and immobiles, optimization of geodetic networks and datum transformations of geodetic systems, and satellite altimetry. He also conducted <b>outlier</b> <b>tests</b> and reliability measures and the evaluation of satellite altimeter data to determine the geoides of oceans.|$|R
40|$|An <b>outlier</b> {{detection}} <b>test</b> {{related to}} a robustified score test is proposed and compared with the sign test and other test based on functions of estimated residuals. Examples of an autoregressive process and a regression model with autoregressive errors are presented to illustrate the techniques. Outlier detection Estimating function...|$|R
40|$|Abstract—In this paper, a non-interactive {{zero-knowledge}} proof {{scheme is}} proposed for secure identification in wireless networks, and {{it uses a}} timed oblivious transfer technique to enable a single verifier to identify multiple provers. The verifier and the prover {{do not need to}} be synchronized in this scheme. This scheme also enjoys the distance-bounding property which makes the proposed scheme invulnerable to the relay attack. We propose to use the order statistic for the detection of relay attackers. We show that it is optimal in terms of minimum variance. Finally, we shed some light on implementation issues of our proposed scheme. Index Terms—Distance-bounding, non-interactive zeroknowledge proof, discrete logarithm problem, elliptic curve cryptography, timed oblivious transfer, statistical <b>outlier</b> <b>test.</b> I...|$|E
40|$|Sets of {{relatively}} short time series arise in many situations. One aspect of their analysis may be the detection of outlying series. We examine the performance of standard normal outlier tests applied to the means, or to simple functions of the means, of AR(1) series, not necessarily of equal lengths. Although unequal lengths of series implies that the means have unequal variances, that are only known approximately, it is shown that nominal significance levels hold good under most circumstances. Thus a standard <b>outlier</b> <b>test</b> can usefully be applied, avoiding the complication of estimating the time series' parameters. The test's power is affected by unequal lengths, being higher when the slippage occurs {{in one of the}} longer series...|$|E
40|$|Abstract—Reliability and {{integrity}} {{have become increasingly}} important in ubiquitous positioning systems, and particularly in critical applications. To implement reliability {{and integrity}} measures, Fault Detection and Exclusion (FDE) methods should be used. However, the current FDE methods in the Chi-square test and the <b>outlier</b> <b>test</b> are suboptimal in terms of continuity and availability. This {{is due to the}} assumption that the bias always corresponds with the measurement that has the largest Protection Level (PL), and in the setting of the continuity probability to a predefined value rather than being maximised. The FDE methods assume that the bias always corresponds with the measurement that has the largest PL. However, {{this is not the case}} since a bias can occur in any one of the measurements. Consequently, a method of averaging the Missed Detection probabilities calculated at the Alert Limit (AL) across all measurements was proposed in the literature. However, simulations demonstrated that only minor improvements in the availability have been achieved. The FDE methods in the Chi-square test and the <b>outlier</b> <b>test</b> are also dependent on the user specifying the instantaneous continuity probability that is required to be met. It is then, once the continuity probability has been specified, that the methods determine if there is sufficient integrity, via the monitoring of the maximum PL in relation to the AL. However, in general, ubiquitous positioning systems do not have a minimum continuity probability that is required to be met; but simply desire the continuity probability to be maximised. This paper develops an optimised FDE strategy for one or more biases, which assumes that the bias can exist in any one of the measurements and allows varying satellite failure rates. In addition, the method also aims to provide a position that has sufficient integrity continuously, via maximising the instantaneous continuity probability...|$|E
40|$|Identifying local {{adaptation}} {{is crucial}} in conservation biology to define ecotypes and establish management guidelines. Local adaptation is often inferred from the detection of loci showing a high differentiation between populations, the so-called FST outliers. Methods of detection of loci under selection are reputed to be robust in most spatial population models. However, using simulations we showed that FST <b>outlier</b> <b>tests</b> provided {{a high rate of}} false-positives (up to 60 %) in fractal environments such as river networks. Surprisingly, the number of sampled demes was correlated with parameters of population genetic structure, such as the variance of FSTs, and hence strongly influenced the rate of outliers. This unappreciated property of river networks therefore needs to be accounted for in genetic studies on adaptation and conservation of river organisms...|$|R
40|$|A {{study of}} {{the various types of}} {{statistical}} methods used for interlaboratory studies is presented. Where possible reference is made to current standards and guidelines in this area. From the discussions of these standards and practical experiences it became apparent that there is no ideal statistical method for interlaboratory studies in general. Choices have to be made always and should be guided by the objective of the study. Apart from this main objective, the extraction and presentation of data obtained from the results, to support the participants in assessing and improving their activities is always important. Hence, references to alternative calculation and presentation methods are included. Many aspects, particularly the evaluation of the results of interlaboratory studies, have been discussed against this background. The use of <b>outlier</b> <b>tests</b> versus robust statistics and the presentation of results received particular attention...|$|R
40|$|This paper {{presents}} a new algorithm {{for the independent}} components analysis (ICA) problem based on an efficient entropy estimator. Like many previous methods, this algorithm directly minimizes the measure of departure from independence according to the estimated Kullback-Leibler divergence between the joint distribution and {{the product of the}} marginal distributions. We pair this approach with efficient entropy estimators from the statistics literature. In particular, the entropy estimator we use is consistent and exhibits rapid convergence. The algorithm based on this estimator is simple, computationally efficient, intuitively appealing, and outperforms other well known algorithms. In addition, the estimator's relative insensitivity to outliers translates into superior performance by our ICA algorithm on <b>outlier</b> <b>tests.</b> We present favorable comparisons to the Kernel ICA, FAST-ICA, JADE, and extended Infomax algorithms in extensive simulations. We also provide public domain source code for our algorithms...|$|R
