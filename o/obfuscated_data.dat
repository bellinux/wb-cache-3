12|44|Public
5000|$|Automatic Decoding: <b>Obfuscated</b> <b>data,</b> whether ROT13 {{encrypted}} and/or simply {{stored in}} binary form (e.g. UserAssist keys), is automatically decoded ...|$|E
40|$|Data {{obfuscation}} techniques transforms {{data into}} other {{data that are}} harder to understand. These techniques are receiving an increasing amount of attention, largely due to their applications in different areas. We illustrate an approach for obfuscating data that guarantees protection of data while allowing the execution of both equality and range queries on the <b>obfuscated</b> <b>data...</b>|$|E
40|$|International audienceWith the {{widespread}} adoption of smartphones, we have observed an increasing popularity of Location-Based Services (LBSs) {{in the past}} decade. To improve user experience, LBSs often provide personalized recommendations to users by mining their activity (i. e., check-in) data from location-based social networks. However, releasing user check-in data makes users vulnerable to inference attacks, as private data (e. g., gender) can often be inferred from the users'check-in data. In this paper, we propose PrivCheck, a customizable and continuous privacy-preserving check-in data publishing framework providing users with continuous privacy protection against inference attacks. The key idea of PrivCheck is to obfuscate user check-in data such that the privacy leakage of user-specified private data is minimized under a given data distortion budget, which ensures {{the utility of the}} <b>obfuscated</b> <b>data</b> to empower personalized LBSs. Since users often give LBS providers access to both their historical check-in data and future check-in streams, we develop two data obfuscation methods for historical and online check-in publishing, respectively. An empirical evaluation on two real-world datasets shows that our framework can efficiently provide effective and continuous protection of user-specified private data, while still preserving the utility of the <b>obfuscated</b> <b>data</b> for personalized LBS...|$|E
50|$|The Freenet {{file sharing}} network is another {{application}} of the idea. It <b>obfuscates</b> <b>data</b> sources and flows {{in order to protect}} operators and users of the network by preventing them (and, by extension, observers such as censors) from knowing where data comes from and where it is stored.|$|R
50|$|Graphs are {{designed}} to allow easier interpretation of statistical data. However, graphs with excessive complexity can <b>obfuscate</b> the <b>data</b> and make interpretation difficult.|$|R
50|$|Cross-platform, {{free and}} open source, it sends {{requests}} through a cascade and mixes the data streams of multiple users {{in order to further}} <b>obfuscate</b> the <b>data</b> to outsiders.|$|R
40|$|Data mining {{deals with}} {{automatic}} extraction of previously unknown patterns from {{large amounts of}} data. Organizations {{all over the world}} handle large amounts of data and are dependent on mining gigantic data sets for expansion of their enterprises. These data sets typically contain sensitive individual information, which consequently get exposed to the other parties. Though we cannot deny the benefits of knowledge discovery that comes through data mining, we should also ensure that data privacy is maintained in the event of data mining. Privacy preserving data mining is a specialized activity in which the data privacy is ensured during data mining. Data privacy {{is as important as the}} extracted knowledge and efforts that guarantee data privacy during data mining are encouraged. In this paper we propose a strategy that protects the data privacy during decision tree analysis of data mining process. We propose to add specific noise to the numeric attributes after exploring the decision tree of the original data. The <b>obfuscated</b> <b>data</b> then is presented to the second party for decision tree analysis. The decision tree obtained on the original data and the <b>obfuscated</b> <b>data</b> are similar but by using our method the data proper is not revealed to the second party during the mining process and hence the privacy will be preserved...|$|E
40|$|A key task {{in digital}} {{forensic}} analysis is {{the location of}} relevant information within the computer system. Identification of the relevancy of data is often dependent upon {{the identification of the}} type of data being examined. Typical file type identification is based upon file extension or magic keys. These typical techniques fail in many typical forensic analysis scenarios such as needing to deal with embedded data, such as with Microsoft Word files, or file fragments. The SÁDI (Statistical Analysis Data Identification) technique applies statistical analysis of the byte values of the data {{in such a way that}} the accuracy of the technique does not rely on the potentially misleading metadata information but rather the values of the data itself. The development of SÁDI provides the capability to identify what digitally stored data actually represents and will also allow for the selective extraction of portions of the data for additional investigation; i. e., in the case of embedded data. Thus, our research provides a more effective type identification technique that does not fail on file fragments, embedded data types, or with <b>obfuscated</b> <b>data...</b>|$|E
40|$|Privacy is a {{pinnacle}} {{concern of}} the cloud database model known as “Database as a service (DaaS) ”. DaaS is highly appreciated in business community because it saves hardware cost, cost of the technical people required to manage the database and it also saves the license cost of the database. Moreover, it offers reliable services and people can access their data 24 x 7 from anywhere provided the internet connection is available. Despite of all these advantages enterprises are reluctant to adopt DaaS, because of two types of threats {{that are associated with}} it. Firstly, it can be attacked by the hacker and secondly the privacy of data can be compromised by the administrators, managing the cloud database environment. In this paper we have focused on the second issue and proposed a model to protect privacy of data stored in cloud databases. As per proposed model we encrypt and obfuscate data on client side before sending to the cloud database. In addition we offer mechanism to query over encrypted and <b>obfuscated</b> <b>data</b> on server side. Once the required data is filtered on server side, it is transferred on client side where the de-obfuscation and decryption is performed. Experiment results are also highlighted showing the enhancement in performance due to obfuscation factor...|$|E
40|$|This paper {{proposes a}} {{scalable}} solution for obstructing and detecting malicious activity {{as well as}} erroneous events during mission mode operation of untrusted memories. The approach <b>obfuscates</b> <b>data</b> written into a memory and remaps the location of memory contents in a manner difficult for an attacker to predict, {{making it harder for}} a Hardware Trojan to be deterministically triggered or controlled by malicious agents. Simultaneously, the approach aids in the detection of soft errors. To our knowledge, this approach is among the first to reconcile SRAM security with SRAM soft error reliability. Simulation data gathered from a production-worthy silicon development environment confirms the viability of our method...|$|R
30|$|Private Information Retrieval (PIR) [37, 38] {{approaches}} <b>obfuscate</b> <b>data</b> access {{patterns and}} can be considered secure against Q&BKD-attackers. Unlike ORAM, PIR can only be applied for data retrieval, not for writing data, which is a common requirement in DaaS scenarios. In contrast to ORAM, PIR approaches can obfuscate query access patterns in a single round of communication. Computational PIR approaches [39 - 42] achieve this {{at the expense of}} increased computational cost for the SPs, while information-theoretical PIR approaches [37, 43, 44] obfuscate access patterns based on non-colluding SPs. To evaluate queries (e.g., range selections) based on probabilistic ciphertexts, PIR approaches can be combined with methods such as encrypted B+ trees. This implies a logarithmic number of communication rounds, which would cancel out the benefits of PIR over ORAM in this regard.|$|R
40|$|With {{the rise}} of big data handling, new {{solutions}} are required to drive cryptographic algorithms for maintaining data security. Here, we exploit the nonvolatile, nonlinear resistance change in BiFeO 3 memristors [Shuai et al., J. Appl. Phys. 109, 124117 (2011) ] by applying a voltage for the generation of second and higher harmonics and develop a new memristor-based encoding system from it to encrypt and <b>obfuscate</b> <b>data.</b> It is found that a BiFeO 3 memristor in high and low resistance state {{can be used to}} generate two clearly distinguishable sets of second and higher harmonics as recently predicted theoretically [Cohen et al., Appl. Phys. Lett. 100, 133109 (2012) ]. The computed autocorrelation of encrypted data using higher harmonics generated by a BiFeO 3 memristor shows that the encoded data distribute randomly...|$|R
40|$|Collaborative {{filtering}} (CF) {{systems are}} being {{widely used in}} E-commerce applications to provide recommendations to users regarding products that might {{be of interest to}} them. The prediction accuracy of these systems is dependent on the size and accuracy of the data provided by users. However, the lack of sufficient guidelines governing the use and distribution of user data raises concerns over individual privacy. Users often provide the minimal information that is required for accessing these E-commerce services. In this paper, we propose a framework for obfuscating sensitive information {{in such a way that}} it protects individual privacy and also preserves the information content required for collaborative filtering. An experimental evaluation of the performance of different CF systems on the <b>obfuscated</b> <b>data</b> proves that the proposed technique for privacy preservation does not impact the accuracy of the predictions. The proposed framework also makes it possible for multiple E-commerce sites to share data in a privacy preserving manner. Problems such as the cold-start scenario faced by new E-commerce vendors, and biased results due to insufficient users, are resolved by using a shared CF server. We describe a centralized CF server model in which a centralized CF server makes recommendations by consolidating the information received from multiple sources. 1...|$|E
40|$|Part 2 : Forensic TechniquesInternational audienceThe only digital {{forensic}} tools {{known to}} provide an automated approach for evaluating XOR <b>obfuscated</b> <b>data</b> are DCCI_Carver and DC 3 _Carver, two general-purpose carving tools developed by the Defense Cyber Crime Center (DC 3). In {{order to determine the}} use of XOR as an obfuscation technique and the need to adapt additional tools, we analyzed 2, 411 drive images from devices acquired from countries around the world. Using {{a modified version of the}} open source tool bulk_extractor, evidence of XOR obfuscation was found on 698 drive images, with a maximum of 21, 031 XOR-obfuscated features on a single drive. XOR usage in the corpus was observed in files with timestamps between the years 1995 and 2009, with the majority of the usage found in unallocated space. XOR obfuscation was used in the corpus to circumvent malware detection and reverse engineering, to hide information that was apparently being exfiltrated, and by malware detection tools for their quarantine directories and to distribute malware signatures. The results indicate that XOR obfuscation is important to consider when performing malware investigations. However, since the corpus does not contain data sets that are known to have been used by malicious entities, it is difficult to draw conclusions regarding the importance of extracting and examining XOR obfuscated files in criminal, counterintelligence and counterterrorism cases without further research...|$|E
40|$|The {{integration}} of information dispersed among multiple repositories {{is a crucial}} step for accurate data analysis in various domains. In support of this goal, {{it is critical to}} devise procedures for identifying similar records across distinct data sources. At the same time, to adhere to privacy regulations and policies, such procedures should protect the confidentiality of the individuals to whom the information corresponds. Various private record linkage (PRL) protocols have been proposed to achieve this goal, involving secure multi-party computation (SMC) and similarity preserving data transformation techniques. SMC methods provide secure and accurate solutions to the PRL problem, but are prohibitively expensive in practice, mainly due to excessive computational requirements. Data transformation techniques offer more practical solutions, but incur the cost of information leakage and false matches. In this paper, we introduce a novel model for practical PRL, which 1) affords controlled and limited information leakage, 2) avoids false matches resulting from data transformation. Initially, we partition the data sources into blocks to eliminate comparisons for records that are unlikely to match. Then, to identify matches, we apply an efficient SMC technique between the candidate record pairs. To enable efficiency and privacy, our model leaks a controlled amount of <b>obfuscated</b> <b>data</b> prior to the secure computations. Applied obfuscation relies on differential privacy which provides strong privacy guarantees against adversaries with arbitrary background knowledge. In addition, we illustrate the practical nature of our approach through an empirical analysis with data derived from public voter records...|$|E
40|$|To ensure {{platform}} independence, mobile {{programs are}} distributed in forms that are isomorphic {{to the original}} source code. Such codes are easy to decompile, and hence they {{increase the risk of}} malicious reverse engineering attacks. Code obfuscation is one of several techniques which has been proposed to alleviate this situation. An obfuscator is a tool which – through the application of code transformations – converts a program into an equivalent one that is more difficult to reverse engineer. In a previous paper [5] we have described the design of a control flow obfuscator for Java. In this paper we extend the design with transformations that <b>obfuscate</b> <b>data</b> structures and abstractions. In particular, we show how to obfuscate classes, arrays, procedural abstractions and built-in data types like strings, integers, and booleans. ...|$|R
30|$|Many {{researchers}} similarly {{assume that}} cloud service providers cannot be trusted {{and that all}} data must be encrypted before it is submitted to the cloud, see for example [6]. Mowbray and Pearson [7] recognize the problem of privacy protection when submitting sensitive information to (untrusted) clouds. Their solution uses a client based privacy manager which <b>obfuscates</b> sensitive <b>data</b> before submitting it to the cloud.|$|R
50|$|In {{order to}} provide better {{security}} when transferring data over a network, Windows Vista provides enhancements to the cryptographic algorithms used to <b>obfuscate</b> <b>data.</b> Support for 256-bit, 384-bit and 512-bit Elliptic curve Diffie-Hellman (ECDH) algorithms, {{as well as for}} 128-bit, 192-bit and 256-bit Advanced Encryption Standard (AES) is included in the network stack itself. Direct support for SSL connections in new Winsock API allows socket applications to directly control security of their traffic over a network (such as providing security policy and requirements for traffic, querying security settings) rather than having to add extra code to support a secure connection. Computers running Windows Vista can be a part of logically isolated networks within an Active Directory domain. Only the computers which are in the same logical network partition will be able to access the resources in the domain. Even though other systems may be physically on the same network, unless they are in the same logical partition, they won't be able to access partitioned resources. A system may be part of multiple network partitions.|$|R
40|$|One of the {{concerns}} users have to confronted when using IPTV system is the information overload {{that makes it difficult}} for them to find a suitable content according to their personal preferences. Recommendation service is one of the most widely adopted technologies for alleviating this problem, these services intend to provide people with referrals of items they will appreciate based on their preferences. IPTV users must ensure their sensitive preferences collected by any recommendation service are properly secured. In this work, we introduce a framework for private recommender service based on Enhanced Middleware for Collaborative Privacy (EMCP). EMCP executes a two-stage concealment process that gives the user a complete control on the privacy level of his/her profile. We utilize trust mechanism to augment the accuracy and privacy of the recommendations. Trust heuristic spot users who are trustworthy with respect to the user requesting the recommendation. Later, the neighborhood formation is calculated using proximity metrics based on these trustworthy users. Finally, Users submit their profiles in an obfuscated form without revealing any information about their data, and the computation of recommendations proceeds over the <b>obfuscated</b> <b>data</b> using secure multiparty computation protocol. We expand the obfuscation scope from single obfuscation level for all users to arbitrary obfuscation levels based on trustworthy between users. In other words, we correlate the obfuscation level with different trust levels, so the more trusted a target user is the less obfuscation copy of profile he can access. We also provide an IPTV network scenario and experimentation results. Our results and analysis show that our two-stage concealment process not only protects the privacy of users but also can maintain the recommendations accuracy. Comment: 10 pages, 7 figures, Journal Pape...|$|E
40|$|With the {{increasing}} popularity of cloud computing, clients are storing their data in cloud servers and are using “software as a service” for computing services. However, clients’ data may be sensitive, critical, and private, and processing such data with cloud servers {{may result in}} losing data privacy or compromising data confidentiality. Some cloud servers may be dishonest, while malicious entities may compromise others. In order to protect data privacy and confidentiality, clients {{need to be able}} to hide their actual data values and send the obfuscated values to cloud servers. This thesis deals with the outsourcing of computing to cloud servers, in which clients’ images can be computed and stored. This thesis proposes a technique that obfuscates images before sending them to servers, so these servers can perform computations on images without knowing the actual images. The proposed technique is expected to ensure data privacy and confidentiality. Servers will not be able to identify an individual whose images are stored and manipulated by the server. In addition, our approach employs an obfuscating technique to maintain the confidentiality of images, allowing cloud servers to compute <b>obfuscated</b> <b>data</b> accurately without knowing the actual data value, thus supporting privacy and confidentiality. The proposed approach is based on the Rabin block cipher technique, which has some weaknesses, however. The main drawback is its decryption technique, which results in four values, and only one of these values represents the actual value of plain data. Another issue is that the blocking technique requires a private key for each block that requires a high-computing effort; requiring one private key for each block of data demands that a great number of keys be stored by the client. As a result, it decreases the robustness of the Rabin block cipher. This thesis proposes additional techniques to overcome some of the weaknesses of the Rabin block cipher by introducing some new features, such as tokenization, a digit counter, and a set of blocks. The new technique increases the privacy of data and decreases the computational complexity by requiring fewer private keys. The new features have been implemented in image processing in order to demonstrate their applicability. However, in order to apply our approach to images, we must first apply some preprocessing techniques on images to make them applicable to being obfuscated by our proposed obfuscating system...|$|E
40|$|Multi-core {{technology}} is bringing parallel processing capabilities from servers to laptops and even handheld devices. At the same time, platform support for system virtualization {{is making it}} easier to consolidate server and client resources, when and as needed by applications. This consolidation is achieved by dynamically mapping the virtual machines on which applications run to underlying physical machines and their processing cores. Low cost processor and I/O virtualization methods efficiently scaled to different numbers of processing cores and I/O devices are key enablers of such consolidation. This dissertation develops and evaluates new methods for scaling virtualization functionality to multi-core and future many-core systems. Specifically, it re-architects virtualization functionality to improve scalability and better exploit multi-core system resources. Results from this work include a self-virtualized I/O abstraction, which virtualizes I/O so as to flexibly use different platforms' processing and I/O resources. Flexibility affords improved performance and resource usage and most importantly, better scalability than that offered by current I/O virtualization solutions. Further, by describing system virtualization as a service provided to virtual machines and the underlying computing platform, this service can be enhanced to provide new and innovative functionality. For example, a virtual device may provide <b>obfuscated</b> <b>data</b> to guest operating systems to maintain data privacy; it could mask differences in device APIs or properties to deal with heterogeneous underlying resources; or it could control access to data based on the ``trust' properties of the guest VM. This thesis demonstrates that extended virtualization services are superior to existing operating system or user-level implementations of such functionality, for multiple reasons. First, this solution technique makes more efficient use of key performance-limiting resource in multi-core systems, which are memory and I/O bandwidth. Second, this solution technique better exploits the parallelism inherent in multi-core architectures and exhibits good scalability properties, in part because at the hypervisor level, there is greater control in precisely which and how resources are used to realize extended virtualization services. Improved control over resource usage makes it possible to provide value-added functionalities for both guest VMs and the platform. Specific instances of virtualization services described in this thesis are the network virtualization service that exploits heterogeneous processing cores, a storage virtualization service that provides location transparent access to block devices by extending the functionality provided by network virtualization service, a multimedia virtualization service that allows efficient media device sharing based on semantic information, and an object-based storage service with enhanced access control. Ph. D. Committee Chair: Schwan, Karsten; Committee Member: Ahamad, Mustaq; Committee Member: Fujimoto, Richard; Committee Member: Gavrilovska, Ada; Committee Member: Owen, Henry; Committee Member: Xenidis, Jim...|$|E
5000|$|When {{asked about}} whether the system encrypts or <b>obfuscates</b> the <b>data</b> it processes, Janus Kristensen stated in an August 2010 AssemblyTV interview: [...] "No. The whole system is based on open ideas. When you send files to people, they can look into the files and see what's inside. Actually that's part of what's cool about a project like this. It's {{community}} based and not closed down or DRM protected in any way.".|$|R
3000|$|Since {{time is the}} {{limiting}} factor here, {{we focus on the}} when and not the where. Poker can detect a cache attack while it is under progress, but not the exact cache region (and thereby the shared library) being targeted. We follow a similar principle here as well: generate enough random noise to <b>obfuscate</b> the <b>data</b> while it is being gathered. (Always show a poker face to the attacker when you suspect him to be peeking.) [...]...|$|R
50|$|If the {{detector}} {{lies in a}} region of high beam activity, it is hit continuously by neutrons and background noise at overwhelmingly high rates. This <b>obfuscates</b> collected <b>data,</b> since there is extreme overlap in measurement, and separate events are not easily distinguished from each other. Thus, {{part of the challenge}} lies in keeping detection rates as low as possible and in designing a detector that can keep up with the high rates to yield coherent data.|$|R
5000|$|In {{order to}} provide better {{security}} when transferring data over a network, Windows Vista provides enhancements to the cryptographic algorithms used to <b>obfuscate</b> <b>data.</b> Support for 256-bit and 384-bit Elliptic curve Diffie-Hellman (DH) algorithms, {{as well as for}} 128-bit, 192-bit and 256-bit Advanced Encryption Standard (AES) is included in the network stack itself and in the Kerberos protocol and GSS messages. Direct support for SSL and TLS connections in new Winsock API allows socket applications to directly control security of their traffic over a network (such as providing security policy and requirements for traffic, querying security settings) rather than having to add extra code to support a secure connection. Computers running Windows Vista can be a part of logically isolated networks within an Active Directory domain. Only the computers which are in the same logical network partition will be able to access the resources in the domain. Even though other systems may be physically on the same network, unless they are in the same logical partition, they won't be able to access partitioned resources. A system may be part of multiple network partitions. The Schannel SSP includes new cipher suites that support Elliptic curve cryptography, so ECC cipher suites can be negotiated as part of the standard TLS handshake. The Schannel interface is pluggable so advanced combinations of cipher suites can substitute a higher level of functionality.|$|R
40|$|In {{this work}} we {{evaluate}} {{the performance of}} generic local structures as template points for secure fingerprint matching. We present a generic template structure called an n-gon that derived from a set of n neighboring minutiae points. We secure templates consisting of sets of n-gons using the fuzzy vault construct to <b>obfuscate</b> the <b>data.</b> We report the matching performance of our system {{in terms of the}} ZeroFAR and the HTER for comparison with other systems. We also briefly describe a keyed version of our system for comparison with secure systems that utilize a secret user key. 1...|$|R
40|$|Traditional assertions express {{correctness}} {{properties that}} must hold on every program execution. However, many applications have prob-abilistic outcomes and consequently their correctness properties are also probabilistic (e. g., they identify faces in images, consume sensor data, or run on unreliable hardware). Traditional assertions do not capture these correctness properties. This paper proposes that programmers express probabilistic correctness properties with probabilistic assertions and describes a new probabilistic evalu-ation approach to efficiently verify these assertions. Probabilistic assertions are Boolean expressions that express {{the probability that}} a property will be true in a given execution rather than asserting that the property must always be true. Given either specific inputs or distributions on the input space, probabilistic evaluation verifies probabilistic assertions by first performing distribution extraction to represent the program as a Bayesian network. Probabilistic evalua-tion then uses statistical properties to simplify this representation to efficiently compute assertion probabilities directly or with sam-pling. Our approach is a mix of both static and dynamic analysis: distribution extraction statically builds and optimizes the Bayesian network representation and sampling dynamically interprets this rep-resentation. We implement our approach in a tool called MAYHAP for C and C++ programs. We evaluate expressiveness, correctness, and performance of MAYHAP on programs that use sensors, per-form approximate computation, and <b>obfuscate</b> <b>data</b> for privacy. Our case studies demonstrate that probabilistic assertions describe useful correctness properties and that MAYHAP efficiently verifies them. Categories and Subject Descriptors G. 3 [Probability and Statis...|$|R
40|$|We {{study the}} {{competing}} goals of utility and privacy as they arise when a user shares personal sensor data with apps on a smartphone. On the one hand, {{there can be}} value to the user for sharing data {{in the form of}} various personalized services and recommendations; on the other hand, there is the risk of revealing behaviors to the app producers that the user would like to keep private. The current approaches to privacy, usually defined in multi-user settings, rely on anonymization to prevent such sensitive behaviors from being traced back to the user—a strategy which does not apply if user identity is already known, as is the case here. Instead of protecting identity, we focus on the more general problem of choosing what data to share, {{in such a way that}} certain kinds of inferences—i. e., those indicating the user’s sensitive behavior—cannot be drawn. The use of inference functions allows us to establish a terminology to unify prior notions of privacy as special cases of this more general problem. We identify several information disclosure regimes, each corresponding to a specific privacyutility tradeoff, as well as privacy mechanisms designed to realize these tradeoff points. Finally, we propose ipShield as a privacy-aware framework which uses current user context together with a model of user behavior to quantify an adversary’s knowledge regarding a sensitive inference, and <b>obfuscate</b> <b>data</b> accordingly before sharing. We conclude by describing initial work towards realizing this framework...|$|R
40|$|Abstract—The {{technique}} of k-anonymization {{has been proposed}} to <b>obfuscate</b> private <b>data</b> through associating it with at least k identities. This paper investigates the basic tabular structures that underline the notion of k-anonymization using cell suppression. These structures are studied under idealized conditions to identify the essential features of the k-anonymization notion. We optimize data kanonymization through requiring a minimum number of anonymized values that are balanced over all columns and rows. We study {{the relationship between the}} sizes of the anonymized tables, the value k, and the number of attributes. This study has a theoretical value through contributing to develop a mathematical foundation of the kanonymization concept. Its practical significance is still to be investigated...|$|R
50|$|The Pelophylax frogs {{belong to}} a group of {{moderately}} advanced Raninae - possibly a clade - that also includes such genera as Babina, Glandirana, Hylarana, Pulchrana, Sanguirana, Sylvirana, as well as Hydrophylax which like Pelophylax is suspected of being not monophyletic. These genera were formerly also included in Rana by most authors, and several of them have only been established in the 1990s. And as regards the possible paraphyly of Pelophylax, it seems that some species assigned there are very close to Hylarana, and thus it might simply be a matter of moving them to that genus. But hybridogenic speciation is running rampant in the Old World green frogs, and this <b>obfuscates</b> the <b>data</b> gained from DNA sequence analyses.|$|R
40|$|Mal-ware such as {{viruses and}} worms are {{increasingly}} proliferating through out all networks. Existing schemes that {{address these issues}} either assume that the mal-ware is available in its plain-text format which can be detected directly with its signature or that its exploit-code execution is directly recognizable. Hence much of the development in this area has been focussed on generating more efficient signatures or in coming up with improved anomaly-based detection and pattern matching rules. However with 2 ̆ 2 secure data 2 ̆ 2 being the watch-word and several efficient encryption schemes being developed to <b>obfuscate</b> <b>data</b> and protect its privacy, encrypted mal-ware {{is very much a}} clear and present threat. While securing resources from encrypted threats is the need of the hour, equally critical is the privacy of content that needs to be protected. In this paper we discuss encrypted mal-ware detection and propose an efficient IP-packet level scheme for encrypted mal-ware detection that does not compromise the privacy of the data {{but at the same time}} helps detect the presence of hidden mal-ware in it. We also propose a new grammar for a generalized representation of all kinds of malicious-signatures. This signature grammar is inclusive of even polymorphic and metamorphic signatures which do not have a straight-forward one-to-one mapping between the signature string and worm-recognition. In a typical system model consisting of several co-operating hosts which are un-intentional senders of mal-ware traffic, where a centralized network monitor functions as the mal-ware detection entity, we show that for a very small memory and processing overhead and almost negligible time-requirements, we achieve a very high detection rate for even the most advanced multi-keyword polymorphic signatures...|$|R
40|$|Differential power {{analysis}} (DPA) side channel attacks {{have been shown}} to have great effectiveness in breaking ciphers (such as the Advanced Encryption Standard or AES) that were previously though to be unbreakable. There are currently many methods published that prevent differential {{power analysis}} on AES. The method proposed for this project is based on the increased usage of multiprocessors and multicore processors. By using multiple copies of the same AES cipher, a randomly chosen cipher is used to encrypt each plaintext. The other ciphers are then used to <b>obfuscate</b> the <b>data</b> made available to the attacker for DPA in the hope of making DPA impossible or require a statistically large amount of data that it is practically impossible to run successfully...|$|R
40|$|We imaged-highly {{attenuating}} test {{objects in}} three dimensions with 9 -MV (at LLNL) and 15 -MV (at Hill Air Force Base) x-ray spectra. While we used the same detector and motion control, there were differences {{that we could not}} control in the two radiography bays and in the sources. The results show better spatial resolution for the 9 -MV spectrum and better contrast for the 15 -MV spectrum. The 15 -MV data contains a noise pattern that <b>obfuscates</b> the <b>data.</b> It is our judgment that if sufficient attention were given to design of the bay, beam dump, collimation, filtration and linac spot size; a 15 -MV imaging system using a flat panel could be developed with spatial resolution of 5 lp/mm and contrastive performance better than we have demonstrated using a 9 -MV spectrum...|$|R
40|$|The {{aims of the}} {{assignment}} are to: –  Build a personal data capture system- or a system for obfuscating personal data, and capture and analyse a small dataset. –  Reflect on learning content, and identify points of connection between the case studies. –  Reflect on learning process, and identify points for improvement in personal performance. –  Identify additional skills to be developed, at both domain level and professional level. CDI 1 Assignment	   3 !  Your task: –  Using the skills developed in maker days and workshops over the semester, specify and implement your own simple physical OR VIRTUAL system that captures or <b>obfuscates</b> personal <b>data.</b> –  Analyse the resulting data set. –  Identify and summarise strong and weak points in group collaborative activities, and changes from Assignment 1 to Assignment 2. –  Identify skills needs for further developing the proposed system, and for participating more effectively in groups...|$|R
40|$|Enforcing {{security}} in location based services is very crucial {{in the current}} mobile world. Past literature has examined both location and identity obfuscation techniques in order to optimally tradeoff security/privacy with utility − this primarily addresses the ‘how to enforce location security problem’; however, it {{does not address the}} ‘where to enforce location security problem’. This paper examines the ‘where’ problem and in particular, examines tradeoffs between enforcing location security at a device vs. enforcing location security at an edge location server. This paper also sketches an implementation of location security solutions at both the device and the edge location server and presents detailed experiments using real mobility and user profile data sets collected from various data sources (taxicabs, Smartphones). Our results show that while device-based solutions do not require trust in the edge location server, they either suffer from high false positive rate (about 25 % probability of not meeting the desired security requirement) or low utility (about 600 meters higher error in <b>obfuscated</b> location <b>data)</b> ...|$|R
40|$|Data {{collected}} nowadays by social-networking applications create fascinating {{opportunities for}} building novel services, {{as well as}} expanding our understanding about social struc-tures and their dynamics. Unfortunately, publishing social-network graphs is considered an ill-advised practice due to privacy concerns. To alleviate this problem, several anony-mization methods have been proposed, aiming at {{reducing the risk of}} a privacy breach on the published data, while still allowing to analyze them and draw relevant conclusions. In this paper we introduce a new anonymization approach that is based on injecting uncertainty in social graphs and publishing the resulting uncertain graphs. While existing ap-proaches <b>obfuscate</b> graph <b>data</b> by adding or removing edges entirely, we propose using a finer-grained perturbation that adds or removes edges partially: this way we can achieve the same desired level of obfuscation with smaller changes in the data, thus maintaining higher utility. Our experiments on real-world networks confirm that at the same level of iden-tity obfuscation our method provides higher usefulness than existing randomized methods that publish standard graphs. 1...|$|R
