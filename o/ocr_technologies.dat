9|125|Public
30|$|Some works [17, 37] {{are related}} to ours as they propose a {{retrieval}} system that receives multimodal queries comprising images and optional text (input by users) and returns images similar to input queries. Yeh et al. [39] utilize images captured by users’ mobile devices to suggest location-oriented information to them. Our work is different because we neither use the image as a direct query nor search images as results. We leverage <b>OCR</b> <b>technologies</b> to recognize text from the image and automatically compose text queries to retrieve documents in text.|$|E
40|$|This article {{discusses}} {{two major}} initiatives tasked with developing tools to im- prove {{optical character recognition}} (OCR) or the mechanical keying of texts that are digitally available only as page images. The two initiatives are the IMProving ACcess to Text Project in Europe and the Early Modern OCR Project in the USA. Because of dealing with a multilayered problem like <b>OCR</b> <b>technologies</b> and having to collaborate with radically interdisciplinary and international team members, the two projects developed techniques that we call Agile Project Management, outlined in this essay with rationales for their use...|$|E
40|$|Abstract — Our {{research}} goals are to extend offline <b>OCR</b> <b>technologies</b> to embedded platforms. It implies two strong constraints. First, pictures {{will be taken}} without control on camera settings and a priori on text (font or size) and background. The second issue is to link several techniques together with an optimal compromise between computational constraints and recognition efficiency. Preliminary experiments led us to consider two operating modes {{in order to improve}} global results. The first situation is pictures of natural scenes while the other one is pictures of documents. Our algorithm aims at handling numerous situations despite hardware constraints, typical of mobile environment. The paper will present the overall description of the system and its future improvements...|$|E
50|$|The {{development}} of the image translation service springs from the advances in <b>OCR</b> <b>technology</b> (miniaturization and reduction of memory resources consumed) enabling text scanning on mobile telephones.|$|R
50|$|The 1940 volumes {{have been}} scanned with <b>OCR</b> <b>technology,</b> {{resulting}} in searchable PDFs, and put online. The 1940 biography is {{unrelated to the}} current work of the same name.|$|R
50|$|A Multiline Optical Character Reader, or MLOCR, {{is a type}} of mail {{sorting machine}} that uses Optical Character Recognition (<b>OCR)</b> <b>technology</b> to {{determine}} how to route mail through the postal system.|$|R
40|$|Different {{character}} recognition problems {{have their own}} specific characteristics. The state-of-art <b>OCR</b> <b>technologies</b> take different recognition approaches, which are most effective, to recognize different types of characters. How to identify character type automatically, then use specific recognition engines, has not brought enough attention among researchers. Most of the limited researches {{are based on the}} whole document image, a block of text or a text line. This paper addresses the problem of character type identification independent of its content, including handwritten/printed Chinese character identification, and printed Chinese/English character identification, based on only one character. Exploiting some effective features, such as run-lengths histogram features and stroke density histogram features, we have got very promising result. The identification correct rate is higher than 98 % in our experiments...|$|E
40|$|Compared to typical scanners, {{handheld}} cameras offer convenient, flexible, portable, and non-contact image capture, {{which enables}} many new applications and breathes {{new life into}} existing ones. However, camera-captured documents may suffer from distortions caused by non-planar document shape and perspective projection, which lead to failure of current <b>OCR</b> <b>technologies.</b> We present a geometric rectification framework for restoring the frontal-flat view of a document from a single camera-captured image. Our approach estimates 3 D document shape from texture flow information obtained directly from the image without requiring additional 3 D/metric data or prior camera calibration. Our framework provides a unified solution for both planar and curved documents and can be applied in many, especially mobile, camera-based document analysis applications. Experiments show that our method produces results that are significantly more OCR compatible than the original images. Index Terms Camera-based OCR, image rectification, shape estimation, texture flow analysis...|$|E
40|$|Abstract — with {{advances}} of segmentation and Optical Character Recognition (<b>OCR)</b> <b>technologies,</b> the capability gap {{between humans and}} bots in recognizing distorted and connected characters becomes increasingly smaller. This trend would likely render text CAPTCHAs APIs eventually ineffective. The basic challenge in designing these obfuscations is to make them easy enough that users are not dissuaded from attempting a solution, yet still too difficult to solve using available computer vision algorithms. Main Focus of this work {{is to find out}} the Probabilities of finding out the real text behind a given CAPTCHA API. To find such a probability we have to first, Implementation a CAPTCHA Generation Algorithm in a programming language using some open CAPTCHA generation algorithm, such as Tesseract. Then apply Image Heuristics of CAPTCHA which include Image alignment, Noise Reduction filters etc. The CAPTCHA’s Heuristics alongside Filtering information will be provided to an OCR Library, such as GOCR to find out The CAPTCHA’s Text in the Main Decryption algorithm. Finally, Probability of successful CAPTCHA can be studied for each input CAPTCHA and Total system probability is calculated. some techniques we have discussed in this thesis provide more than 70 % success rate, and as the faulty CAPTCHA requests are re-evaluated by the server and absence limiting count means that CAPTCHA decryption will be successful in consecutive attacks...|$|E
40|$|We {{present a}} {{methodology}} that takes as input scanned documents of typed or hand-written text, and produces transcriptions {{of the text}} as output. Instead of using <b>OCR</b> <b>technology,</b> the methodology is game-based and produces such transcriptions as a by-product. The approach is intended particularly for languages for which language technology and resources are scarce and reliable <b>OCR</b> <b>technology</b> may not exist. It {{can be used in}} place of OCR for transcribing individual documents, or to create corpora of paired images and transcriptions required to train OCR tools. We present Minefield, a prototype implementation of the approach which is currently collecting Arabic transcriptions. 1...|$|R
40|$|This {{presentation}} was {{given at the}} FLVC regional conference at Broward College on May 7, 2015 and introduced scanning, processing, record creation, dissemination, and preservation in FIU Libraries 2 ̆ 7 Digital Collections Center. The main focus was on processing, specifically employing <b>OCR</b> <b>technology</b> with difficult sources...|$|R
30|$|Different {{from the}} <b>OCR</b> <b>technology,</b> our {{approach}} can recognize Chinese characters accurately and quickly from any angle. It {{does not matter}} whether the character is printed on cluttered background, or marred by drawings around it. Unlike OCR, our approach only requires one image sample of the character to train the recognition engine.|$|R
40|$|The ability {{area between}} people and bots in {{acknowledging}} connected and distorted figures becomes progressively smaller with advances of segmentation and Optical Character Recognition (<b>OCR)</b> <b>technologies.</b> This trend would likely make text CAPTCHAs APIs eventually ineffective. The procedure this is certainly fundamental creating these obfuscations is to cause them to become quick sufficient that users aren't dissuaded from attempting an answer, but nonetheless also hard to solve making use of provided computer system system vision formulas. Principal Focus for this jobs are to find the possibilities away from learning the written text that is real a given CAPTCHA API. This is actually open generation, such as for example Tesseract to find such a probability we have to first, Implementation a CAPTCHA Generation Algorithm in a programming language utilizing some CAPTCHA. Then apply Image Heuristics of CAPTCHA Image that is including alignment Noise Reduction filters etc. The CAPTCHA’s Heuristics alongside Filtering information will be wanted to an OCR Library, such as GOCR {{to search for the}} CAPTCHA’s Text out in the Decryption that is main algorithm. Eventually, chance for effective CAPTCHA are analyzed for every comments CAPTCHA and system this is really total is determined. Some practices we now have discussed in this thesis provide more than 70 % rate of success, so when the faulty CAPTCHA demands are re-evaluated by the lack and number count this is really limiting that CAPTCHA decryption will probably be efficient in successive assaults...|$|E
40|$|Texts are an {{important}} representation of language. Due to the volume of texts generated and the historical value of some documents, {{it is imperative to}} use computers to read generated texts, and make them editable and searchable. This task, however, is not trivial. Recreating human perception capabilities in artificial systems like documents {{is one of the major}} goals of pattern recognition research. After decades of research and improvements in computing capabilities, humans 2 ̆ 7 ability to read typed or handwritten text is hardly matched by machine intelligence. Although, classical applications of Optical Character Recognition (OCR) like reading machine-printed addresses in a mail sorting machine is considered solved, more complex scripts or handwritten texts push the limits of the existing technology. Moreover, many of the existing OCR systems are language dependent. Therefore, improvements in <b>OCR</b> <b>technologies</b> have been uneven across different languages. Especially, for Persian, there has been limited research. Despite the need to process many Persian historical documents or use of OCR in variety of applications, few Persian OCR systems work with good recognition rate. Consequently, the task of automatically reading Persian typed documents with close-to-human performance is still an open problem and the main focus of this dissertation. In this dissertation, after a literature survey of the existing technology, we propose new techniques in the two important preprocessing steps in any OCR system: Skew detection and Page segmentation. Then, rather than the usual practice of character segmentation, we propose segmentation of Persian documents into sub-words. The choice of sub-word segmentation is to avoid the challenges of segmenting highly cursive Persian texts to isolated characters. For feature extraction, we will propose a hybrid scheme between three commonly used methods and finally use a nonparametric classification method. A large number of papers and patents advertise recognition rates near 100...|$|E
40|$|The {{advances}} in Optical Character Recognition (<b>OCR)</b> <b>technology</b> {{over the past}} decade have enabled the development of many automatic document-processing systems capable of 99 % correct recognition on printed text. However, similar {{advances in}} Cursive Script Recognition (CSR) technology have not been forthcoming due, principally, to the vast variability of human handwriting. This paper investigates a method by which the more reliable <b>OCR</b> <b>technology</b> can be used to improve the CSR performance in a form processing application. A novel method is proposed to link handwriting data to contextual cue words that have been automatically obtained from an OCR process. This information is then used to select appropriate 'focused' lexicons to achieve better CSR results. The method was tested on 30 forms that were filled by 10 different writers. The experimental results together with a comparison to the base line recognition performance are presente...|$|R
50|$|Document ConversionConvert a {{document}} from its native format into a format suitable for display on a mobile device. Documents, including images or text, are processed {{in a way}} so that the content of said document is viewable on a mobile device. Some systems have employed <b>OCR</b> <b>technology,</b> while others may provide full-fidelity document viewing.|$|R
5000|$|... device camera) of some {{printed text}} (a road sign, a {{restaurant}} menu, {{a page of}} a book etc.), have the application {{send it to the}} translation server which will apply Optical Character Recognition (<b>OCR)</b> <b>technology,</b> extract the text, return it to the user for editing (if necessary) and then translate it into the chosen language.|$|R
50|$|Founded in the 1960s by 4 Connecticut {{men with}} {{financial}} backing from The Travelers Companies {{with the goal}} of developing the brand-new and barely functioning <b>OCR</b> <b>technology,</b> Scan-Optics was part of the technology groups enabling the transition from paper to digital - capturing the required data and delivering the information in the expected format making information accessible upon framework.|$|R
40|$|Research into user {{interface}} design has predominantly {{concentrated on the}} presentation of visual information. The integration of PDAs with cell phone- and GPS technologies offers new and exciting opportunities to explore how multi-sensory, multimodal, multimedia interfaces should be designed to suit a variety of human situations. Two projects from our universal, inclusive design program are presented that both involve vision. One uses cell phone cameras and Optical Character Reading (<b>OCR)</b> <b>technology</b> to «read» signs to visually impaired people. The user simply points the camera at a street sign, a shop sign, or a product sign in a supermarket, and takes a snapshot, which the <b>OCR</b> <b>technology</b> then translates into speech, which {{is sent to the}} user via the cell phone. In the second project we are investigating how to «read» graphical information using either speech or printed text or both. Preliminary experimental results from both projects will be presented...|$|R
500|$|In 2009, CSX {{began the}} {{construction}} of a $175 million intermodal facility in North Baltimore, employing <b>OCR</b> <b>technology</b> from the Saudi Arabia-based Gulf Stevedoring Contracting Company. As part of their [...] "National Gateway" [...] project, it is a rival to Norfolk Southern's [...] "Heartland Corridor" [...] project. Norfolk Southern operates a large intermodal facility in Columbus as part of their [...] "Heartland Corridor," [...] which the company recently constructed.|$|R
50|$|ABBYY Business Card Reader is {{a mobile}} {{software}} application that imports contact information from business cards directly to mobile address books using a smartphone's camera and text recognition technology. First released in 2009, the application {{is now available}} for Symbian, Apple iPhone in January 2010, and Android. It uses ABBYY's optical character recognition (<b>OCR)</b> <b>technology</b> for mobile devices, which {{was introduced to the}} market with ABBYY Mobile OCR Engine.|$|R
5000|$|In 2009, CSX {{began the}} {{construction}} of a $175 million intermodal facility in North Baltimore, employing <b>OCR</b> <b>technology</b> from the Saudi Arabia-based Gulf Stevedoring Contracting Company. As part of their [...] "National Gateway" [...] project, it is a rival to Norfolk Southern's [...] "Heartland Corridor" [...] project. Norfolk Southern operates a large intermodal facility in Columbus as part of their [...] "Heartland Corridor," [...] which the company recently constructed.|$|R
40|$|This thesis {{report is}} {{submitted}} in partial {{fulfillment of the}} requirements for the degree of Bachelor of Science in Computer Science and Engineering, 2005. Cataloged from PDF version of thesis report. Includes bibliographical references (page 102). At {{the beginning of the}} 21 st century, the field of global public health is changing rapidly, not only in its basic methods, but also in technological aspects. The first and foremost concerns of BRAC health program is to provide health service to mass populations. To cope up with changing world’s need BRAC Health department should accept the fruit of technology. As a result we have proposed three solutions to automate the entire health peocess namely- (I) using hand scanner, mobile phone and <b>OCR</b> <b>technology,</b> (II) using Epi Info software package tools for data analysis, (III) web-based database system. This report focuses on automation using hand scanner, mobile phone and <b>OCR</b> <b>technology.</b> It offers real time data usability and scope for analysis. Thus provides rapid and accurate decision making opportunity. Hasnain FerozeSoriful Alam SumonB. Computer Science and Engineerin...|$|R
30|$|Different from Optical Character Recognition (<b>OCR)</b> <b>technology,</b> {{which is}} {{sensitive}} to {{the orientation of the}} character image and its background, our approach can recognize the character accurately from any angle. It does not matter whether the character is printed in uncommon fonts, on cluttered background or marred by drawings around it. The character recognition is reliable and fast without requiring the user to capture the image from the character at its upright position.|$|R
40|$|Optical Character Recognition is a {{technique}} by which you can automatically recognize the characters with an optical mechanism. <b>OCR</b> <b>technology</b> allows you the recognition of printed or handwritten text documents. Main aim {{of this research is}} to prepare a recognition system which can be used for the recognition of offline handwritten Hindi characters. For this proposed system Support Vector Machine is used as classifier and Diagonal feature extraction approach is used to extract features...|$|R
50|$|Image {{translation}} {{is a term}} related to machine translation services for mobile devices (mobile translation). Image translation refers to an additional service provided by mobile translation applications where the user can take a photo of some printed text (menu list, road sign, document etc.), apply optical character recognition (<b>OCR)</b> <b>technology</b> to it to extract any text contained in the image, and then have this text translated into a language of their choice.|$|R
50|$|Under the old system, New Zealand Post did {{not require}} {{individual}} items of mail to include the postcode in the address, as optical character recognition (OCR) enabled automated sorting machines to scan entire addresses, rather than just post codes, {{as was the case}} with older machines. <b>OCR</b> <b>technology</b> was introduced in 1992, when the first of seven OCR machines were installed in Auckland, Wellington and Christchurch Mail Centres, most mail was sorted manually.|$|R
5000|$|In recent years, {{the major}} <b>OCR</b> <b>technology</b> {{providers}} began to tweak OCR systems to better deal with {{specific types of}} input. Beyond an application-specific lexicon, better performance can be had by taking into account business rules, standard expression, or rich information contained in color images. This strategy is called [...] "Application-Oriented OCR" [...] or [...] "Customised OCR", and {{has been applied to}} OCR of license plates, invoices, screenshots, ID cards, driver licenses, and automobile manufacturing.|$|R
40|$|Reading {{challenges}} {{can affect}} {{people who are}} blind or have low vision, those with learning disabilities or low literacy skills, as well as those who have difficulty holding books or documents. These individuals may benefit from the use of various reading technologies and strategies. One solution is to use a reading system that uses optical character recognition (<b>OCR)</b> <b>technology</b> to make an electronic copy of a document and then use text-to-speech technology to read the information to the user...|$|R
40|$|Abstract. This paper {{presents}} a scheme based upon XML based labeling for managing a large multilingual OCR project. Managing a large multi-lingual OCR project involving multiple research groups, developing script specific and script independent technologies in a collaborative fashion is a challenging problem. In this paper, we present {{some of the}} software and data management strategies designed for the project aimed at developing OCR for 11 scripts of Indian origin for which mature <b>OCR</b> <b>technology</b> was not available. ...|$|R
50|$|The ZIP Code {{is often}} {{translated}} into an Intelligent Mail barcode that is {{printed on the}} mailpiece {{to make it easier}} for automated machines to sort. The barcode can be printed by the sender (some word-processing programs such as WordPerfect and Microsoft Word include the feature), or the post office will put one on when it processes the piece. In general, the post office uses <b>OCR</b> <b>technology,</b> though in some cases a human may have to read the address.|$|R
30|$|Given a screenshot, {{we first}} apply Optical Character Recognition (<b>OCR)</b> <b>technology</b> [21] to {{identify}} text from the screenshot. A recognition result returned by our OCR engine {{consists of the}} detected language {{and a list of}} lines and their bounding boxes; a line contains a list of words and their bounding boxes; a word also has its bounding box and recognition confidence ∈ [0, 1]. Note that our approach is also applicable to other OCR engines if their recognition results contain information about lines.|$|R
40|$|Owing to a boom of {{information}} technologies {{optical character recognition}} has recently become a popular and affordable technology, enabling an effective way of sharing a large amount {{of information}} stored in paper documents. This work deals with systems for document conversion of analog data into electronic and editable form. It outlines the main methodology of <b>OCR</b> <b>technology,</b> evaluates a performance of OCR applications and analyses the contribution of imaging technologies through the benchmark tests on the set of paper documents...|$|R
50|$|The {{results of}} the {{physical}} transactions by the dealer, such as {{the outcome of the}} roulette wheel spin or the dealing of cards, are translated into data that can be utilized by the software by means of optical character recognition (<b>OCR)</b> <b>technology.</b> This enables the player to interact with the game {{in much the same way}} as they would with a virtual casino game, except for the fact that the results are determined by real-life actions rather than automated processes.|$|R
40|$|Abstract — Optical Character Recognition is a {{technique}} by which you can automatically recognize the characters with an optical mechanism. <b>OCR</b> <b>technology</b> allows you the recognition of printed or handwritten text documents. Main aim {{of this research is}} to prepare a recognition system which can be used for the recognition of offline handwritten Hindi characters. For this proposed system Support Vector Machine is used as classifier and Diagonal feature extraction approach is used to extract features. Keywords- Handwritten Character Recognition, OCR, Feature Extraction, SVM. I...|$|R
50|$|Forum spambots {{surf the}} web looking for guestbooks, wikis, blogs, forums {{and any other}} web forms to submit spam links to. These spambots often use <b>OCR</b> <b>technology</b> to bypass CAPTCHAs present. Some spam {{messages}} are targeted towards readers and can involve techniques of target marketing or even phishing. These automated schemes can {{make it more difficult}} for users to tell real posts from the bot generated ones. Some spam messages also simply contain tags and hyperlinks intended to boost search engine ranking rather than target human readers.|$|R
