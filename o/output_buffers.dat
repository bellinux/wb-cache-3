146|422|Public
50|$|Data {{read from}} the cells {{does not need to}} be fed into the <b>output</b> <b>buffers</b> or the data bus to send to the CPU.|$|E
50|$|Applications join {{specific}} {{groups as}} individual members. On joining a group a member can send or receive messages. Individual messages {{are assigned to}} specific transport classes, based on the message's size. Each transport class owns input and <b>output</b> <b>buffers.</b> Routing decisions are made at the transport class level.|$|E
50|$|The {{input buffer}} is a queue where events are stored (from keyboard, mouse etc.). The output buffer is a {{rectangular}} grid where characters are stored, {{together with their}} attributes. A console window may have several <b>output</b> <b>buffers,</b> only {{one of which is}} active (i.e. displayed) for a given moment.|$|E
5000|$|Read {{the first}} 10 MB (= 100MB / (9 chunks + 1)) of each sorted chunk into input buffers in main memory and {{allocate}} the remaining 10 MB for an <b>output</b> <b>buffer.</b> (In practice, it might provide better performance {{to make the}} <b>output</b> <b>buffer</b> larger and the input buffers slightly smaller.) ...|$|R
40|$|A class-B <b>output</b> <b>buffer</b> with {{threshold}} voltage (VTH) {{compensation for the}} data driver circuit fabricated on liquid crystal display (LCD) panel in low temperature polysilicon (LTPS) technology is proposed. This <b>output</b> <b>buffer</b> can be operated at 50 -kHz operation frequency with a 2 -to- 8 V output swing for extended graphic array (XGA) application. By employing the design technique of {{threshold voltage}} compensation, the offset voltage (VOS) of the class-B <b>output</b> <b>buffer</b> under 2 -to- 8 V input signal can be controlled within ± 100 mV for a high resolution and quality applications in LCD panel. 1...|$|R
40|$|A {{method used}} preferably with LZSS-based {{compression}} methods for compressing {{a stream of}} digital data. The method uses a run-length encoding scheme especially suited for data strings of identical data bytes having large run-lengths, such as data representing scanned images. The method reads an input data stream to determine {{the length of the}} data strings. Longer data strings are then encoded {{in one of two ways}} depending on the length of the string. For data strings having run-lengths less than 18 bytes, a cleared offset and the actual run-length are written to an <b>output</b> <b>buffer</b> and then a run byte is written to the <b>output</b> <b>buffer.</b> For data strings of 18 bytes or longer, a set offset and an encoded run-length are written to the <b>output</b> <b>buffer</b> and then a run byte is written to the <b>output</b> <b>buffer.</b> The encoded run-length is written in two parts obtained by dividing the run length by a factor of 255. The first of two parts of the encoded run-length is the quotient; the second part is the remainder. Data bytes that are not part of data strings of sufficient length are written directly to the <b>output</b> <b>buffer...</b>|$|R
50|$|Alternately, Paula may {{signal the}} CPU to load a new sample {{into any of}} the four audio <b>output</b> <b>buffers</b> by {{generating}} an interrupt when a new sample is needed. This allows for output rates that exceed 57 kHz per channel and increases the number of possible voices (simultaneous sounds) through software mixing.|$|E
50|$|A {{deadlock}} (shown in fig 1) is {{a situation}} in which no further transportation of packets can take place due to the saturation of network resources like buffers or links. The main reason for a deadlock is the cyclic acquisition of channels in the network. For example, consider there are four channels in a network. Four packets have filled up the input buffers of these four channels and needs to be forwarded to the next channel. Now assume that the <b>output</b> <b>buffers</b> of all these channels are also filled with packets that need to be transmitted to the next channel. If these four channels form a cycle, it is impossible to transmit packets any further because the <b>output</b> <b>buffers</b> and input buffers of all channels are already full. This is known as cyclic acquisition of channels and this results in a deadlock.|$|E
50|$|One way of {{reducing}} the emissions of an MC System is to extend {{the rise and fall}} time (Slew Rate Control). Some controllers like the Motorola HCS08 offer the feature of software controlled slew rate <b>output</b> <b>buffers</b> enabling the user to extend the rise time from 3 ns to 30 ns for each pin separately.|$|E
5000|$|To {{hold the}} current <b>output</b> <b>buffer</b> page {{for each of}} the [...] {{partitions}} ...|$|R
40|$|This paper {{documents}} the TRT detector readout scheme. A description is provided {{of the data}} buffers used in the TRT readout chain: the single TRT channel output data format, the DTMROC <b>output</b> data <b>buffer</b> format, the TRT-ROD input FIFO data format, the TRT-ROD <b>output</b> <b>buffer</b> format, and the ROB <b>output</b> <b>buffer</b> data format. Also documented are the current designs for the TRT-ROD zero suppression and data compression schemes. A proposal is presented for ordering the data generated by individual TRT channels suitably for Level- 2 triggering, Level- 3 triggering and offline data processing...|$|R
5000|$|The write {{function}} sends {{a string}} literal {{to the standard}} <b>output</b> <b>buffer,</b> which in most cases is a command line interface.|$|R
50|$|The LM13700 is an {{integrated}} circuit {{consisting of two}} current controlled operational transconductance amplifiers (OTA), each having differential inputs and a push-pull output. The LM13700 is like a standard op-amp: each has a pair of differential inputs and a single output, but an OTA is voltage in and current out rather than voltage in and voltage out; and OTAs are programmable via the IABC pin. Linearizing diodes at the input reduce distortion and allow increased input levels. The darlington <b>output</b> <b>buffers</b> provided are specifically designed to complement the wide dynamic range of the OTA. This chip is very useful in audio electronics especially in analog synthesizer circuits like voltage controlled oscillators, voltage controlled filters, and voltage controlled amplifiers. The darlington <b>output</b> <b>buffers</b> on the LM13700 {{are different from those}} on the LM13600 in that their bias currents (and hence their output DC levels) are independent of IABC pin. This usually results in performance superior to that of the LM13600 in audio applications.|$|E
50|$|Because {{partition}} 0 {{is never}} written to or read from disk, the hybrid hash join typically performs fewer I/O operations than the grace hash join. Note that this algorithm is memory-sensitive, {{because there are}} two competing demands for memory (the hash table for partition 0, and the <b>output</b> <b>buffers</b> for the remaining partitions). Choosing too large a hash table might cause the algorithm to recurse {{because one of the}} non-zero partitions is too large to fit into memory.|$|E
50|$|Buffers {{are used}} {{throughout}} the theory of constraints. They often result {{as part of the}} exploit and subordinate steps of the five focusing steps. Buffers are placed before the governing constraint, thus ensuring that the constraint is never starved. Buffers are also placed behind the constraint to prevent downstream failure from blocking the constraint's <b>output.</b> <b>Buffers</b> used in this way protect the constraint from variations {{in the rest of the}} system and should allow for normal variation of processing time and the occasional upset (Murphy) before and behind the constraint.|$|E
40|$|Abstract—With a 3. 3 -V interface, such as PCI-X application, {{high-voltage}} overstress on {{the gate}} oxide is a serious reliability problem in designing I/O circuits by using only 1 / 2. 5 -V low-voltage devices in a 0. 13 - m CMOS process. Thus, a new <b>output</b> <b>buffer</b> re-alized with low-voltage (1 - and 2. 5 -V) devices to drive high-voltage signals for 3. 3 -V applications is proposed in this paper. The proposed <b>output</b> <b>buffer</b> has been fabricated in a 0. 13 - m 1 / 2. 5 -V 1 P 8 M CMOS process with Cu interconnects. The experimental results have confirmed that the proposed <b>output</b> <b>buffer</b> can be successfully operated at 133 MHz without suffering high-voltage gate-oxide overstress in the 3. 3 -V interface. In addition, a new level converter that is realized with only 1 - and 2. 5 -V devices that can convert 0 / 1 -V voltage swing to 1 / 3. 3 -V voltage swing is also presented in this paper. The experimental results have also confirmed that the proposed level converter can be operated correctly. Index Terms—Gate-oxide reliability, level converter, mixed-voltage I/O, <b>output</b> <b>buffer.</b> I...|$|R
5000|$|Or most {{commonly}} when the <b>output</b> <b>buffer</b> is full - congestion (for example the combined rate of multiple inputs exceeds the output rate) ...|$|R
40|$|In {{this paper}} several methods to use eDRAM (embedded DRAM, on-chip DRAM) in packet {{switches}} are analyzed. A practical method using eDRAM as an output queue is proposed {{especially in a}} shared bus packet switch. In the newly proposed <b>output</b> <b>buffer</b> architecture, hierarchical <b>output</b> <b>buffer</b> (HOB), SRAM plays a role of the small FIFO buffer between a high-speed shared bus and a large eDRAM <b>output</b> <b>buffer.</b> The high density of eDRAM can provide larger capacity than static memories, which results in lower packet loss probability. This paper shows the performance analysis on the proposed HOB switch of 8 ports with the port speed of 10 Gbps for 10 Gigabit Ethernet or OC- 192 c standards. We determine two optimal configurations of hierarchical <b>output</b> <b>buffer</b> by simulation. One is focused on area reduction issue {{and the other on}} reduction of cell loss probability. First one achieve the cell loss probability of 10 - 6 and second one does that of 10 - 8 at 90 % offered load under real trace traffic of IP packets. About 2 times area reduction is obtained by using hierarchical and hybrid <b>output</b> <b>buffer</b> rather than SRAM buffer. A prototype chip has been designed and implemented by using 0. 16 um DRAM-based SoC technology. During the chip implementation, Both-Side I/O scheme is proposed to double the I/O data bits of eDRAM. The die area is 4 mm x 9 mm including input generation block. This chip has taped out in May 2002, and is under fabrication up to now...|$|R
5000|$|The two {{programs}} performing the commands may {{run in parallel}} with the only storage space being working buffers (Linux allows up to 64K for each buffer) plus whatever work space each command's processing requires. For example, a [...] "sort" [...] command is unable to produce any output until all input records have been read, as the very last record received just {{might turn out to}} be first in sorted order. Dr. Alexia Massalin's experimental operating system, Synthesis, would adjust the priority of each task as they ran according to the fullness of their input and <b>output</b> <b>buffers.</b>|$|E
50|$|Newer CMOS <b>output</b> <b>buffers</b> using lightly doped {{silicide}} drains {{are more}} ESD sensitive; the N-channel driver usually suffers {{damage in the}} oxide layer or n+/p well junction. This is caused by current crowding during the snapback of the parasitic NPN transistor. In P/NMOS totem-pole structures, the NMOS transistor is almost always the one damaged. The structure of the junction influences its ESD sensitivity; corners and defects can lead to current crowding, reducing the damage threshold. Forward-biased junctions are less sensitive than reverse-biased ones because the Joule heat of forward-biased junctions is dissipated through a thicker layer of the material, {{as compared to the}} narrow depletion region in reverse-biased junction.|$|E
50|$|In a {{real-time}} {{digital signal}} processing (DSP) process, the analyzed (input) and generated (output) samples can be processed (or generated) continuously {{in the time it}} takes to input and output the same set of samples independent of the processing delay. It means that the processing delay must be bounded even if the processing continues for an unlimited time. That means that the mean processing time per sample, including overhead, is no greater than the sampling period, which is the reciprocal of the sampling rate. This is the criterion whether the samples are grouped together in large segments and processed as blocks or are processed individually and whether there are long, short, or non-existent input and <b>output</b> <b>buffers.</b>|$|E
40|$|Abstract. We {{consider}} split-merge {{systems with}} heterogeneous subtask service times and limited <b>output</b> <b>buffer</b> {{space in which}} to hold completed but as yet unmerged subtasks. An important practical problem in such systems is to limit utilisation of the <b>output</b> <b>buffer.</b> This {{can be achieved by}} judiciously delaying the processing of subtasks in order to cluster subtask completion times. In this paper we present a methodology to find those deterministic subtask processing delays which minimise any given percentile of the difference in times of appearance of the first and the last subtasks in the <b>output</b> <b>buffer.</b> Technically this is achieved in three main steps: firstly, we define an expression for the distribution of the range of samples drawn from n independent heterogeneous service time distributions. This is a generalisation of the well-known order statistic result for the distribution of the range of n samples taken from the same distribution. Secondly, we extend our model to incorporate deterministic delays applied to the processing of subtasks. Finally, we present an optimisation scheme to find that vector of delays which minimises a given percentile of the range of arrival times of subtasks in the <b>output</b> <b>buffer.</b> A case study illustrates the applicability of our proposed approach. ...|$|R
40|$|To {{support the}} Internet's {{explosive}} growth and expansion into a true integrated services network, {{there is a}} need for cost-effective switching technologies that can simultaneously provide high capacity switching and advanced QoS. Unfortunately, these two goals are largely believed to be contradictory in nature. To support QoS, sophisticated packet scheduling algorithms, such as Fair Queueing, are needed to manage queueing points. However, the bulk of current research in packet scheduling algorithms assumes an <b>output</b> <b>buffered</b> switch architecture, whereas most high performance switches (both commercial and research) are input <b>buffered.</b> While <b>output</b> <b>buffered</b> systems may have the desired quality of service, they lack the necessary scalability. Input buffered systems, while scalable, lack the necessary quality of service features. In this paper, we propose the construction of switching systems that are both input and <b>output</b> <b>buffered,</b> with the scalability of input buffered switches and the r [...] ...|$|R
5000|$|Xlib {{does not}} send {{requests}} to the server immediately, but stores {{them in a}} queue, called the output buffer; the requests in the <b>output</b> <b>buffer</b> are actually sent when: ...|$|R
50|$|Under X, how {{video is}} finally drawn {{depends largely on}} the X window manager in use. With {{properly}} installed drivers, and GPU hardware such as supported Intel, ATI, and nVidia chip sets, some window managers, called compositing window managers, allow windows to be separately processed and then rendered (or composited). This involves all windows being rendered to separate <b>output</b> <b>buffers</b> in memory first, and later combined to form a complete graphical interface. While in (video) memory, individual windows can be transformed separately, and accelerated video may be added at this stage using a texture filter, before the window is composited and drawn. XVideo {{can also be used}} to accelerate video playback during the drawing of windows using an OpenGL Framebuffer Object or pbuffer.|$|E
5000|$|This is the {{reversible}} block-sort {{that is at}} {{the core}} of bzip2. The block is entirely self-contained, with input and <b>output</b> <b>buffers</b> remaining the same size—in bzip2, the operating limit for this stage is 900 kB. For the block-sort, a (notional) matrix is created in which row [...] contains the whole of the buffer, rotated to start from the [...] symbol. Following rotation, the rows of the matrix are sorted into alphabetic (numerical) order. A 24-bit pointer is stored marking the starting position for when the block is untransformed. In practice, it is not necessary to construct the full matrix; rather, the sort is performed using pointers for each position in the buffer. The output buffer is the last column of the matrix; this contains the whole buffer, but reordered so that it is likely to contain large runs of identical symbols.|$|E
50|$|A burst or {{clump of}} packets can {{arrive at a}} higher rate than {{determined}} by the emission interval T. This may be the line rate of the physical layer connection when the packets in the burst will arrive back-to-back. However, as in ATM, the tolerance may be applied to a lower rate, in that case the Sustainable Cell Rate (SCR), and the burst of packets (cells) can arrive {{at a higher rate}}, but less than the line rate of the physical layer, in that case the Peak Cell Rate (PCR). The MBS may then be the number of cells needed to transport a higher layer packet (see segmentation and reassembly), where the packets are transmitted with a maximum bandwidth determined by the SCR and cells within the packets are transmitted at the PCR; thus allowing the last cell of the packet, and the packet itself, to arrive significantly earlier than it would if the cells were sent at the SCR: transmission duration = (MBS-1)/PCR rather than (MBS-1)/SCR. This bursting at the PCR puts a significantly higher load on shared resources, e.g. switch <b>output</b> <b>buffers,</b> than does transmission at the SCR, and is thus more likely to result in buffer overflows and network congestion. However, it puts a lesser load on these resources than would transmitting at the SCR with a limit value, τSCR, that allows MBS cells to be transmitted and arrive back-to-back at the line rate.|$|E
40|$|The {{performance}} of Multistage Interconnection Networks (MIN's) constructed from <b>output</b> <b>buffered</b> switching elements (SE) {{is higher than}} those having input buffered SEs. Many of the existing analytical models for <b>output</b> <b>buffered</b> MIN's assume uniform traffic and infinite <b>buffers</b> at each <b>output</b> port of an SE. The models are not realistic because, in practice buffers are finite and the traffic may not be uniform. Moreover, because of simplifying assumptions, the models do not produce accurate results. For the purpose of network design and proper buffer dimensioning, {{it is important to}} develop an accurate analytical model under realistic traffic patterns and finite buffered SEs. The objective {{of this paper is to}} develop an accurate model for MINs using finite <b>output</b> <b>buffered</b> SEs and operating in the presence of nonuniform traffic patterns. It is shown that the proposed analytical model is much more accurate than existing models. 1 A part of this paper has been presented at the First IEEE In [...] ...|$|R
50|$|For a K-funnel {{occupies}} θ(K2) storage, and {{at least}} K2 storage. If the input lists have K3 elements total, then a K-funnel fills the <b>output</b> <b>buffer</b> in O(K3/B(logM/B K3/B)+K) memory transfers.|$|R
40|$|Problem statement: Optical Packet Switching (OPS) and {{transmission}} networks based on Wavelength Division Multiplexing (WDM) have been increasingly {{deployed in the}} Internet infrastructure {{over the last decade}} {{in order to meet the}} huge increasing demand for bandwidth. Several different technologies have been developed for optical packet switching such as space switches, broadcast-and-select, input <b>buffered</b> switches and <b>output</b> <b>buffered</b> switches. These architectures vary based on several parameters such as the way of optical buffering, the placement of optical buffers, the way of solving the external blocking inherited from switching technologies in general and the components used to implement WDM. Approach: This study surveys most of the exiting optical packet switching architectures. A simulation-based comparison of input <b>buffered</b> and <b>output</b> <b>buffered</b> architectures were presented. Results: The performance analysis of the selected two architectures derived using simulation program and compared at different scenarios. We found that the <b>output</b> <b>buffered</b> architectures give better performance than input buffered architectures. Conclusion: The simulation results shows that the-broadcast-and-select architecture is attractive in terms that it has lees number of components compared to other switches. </P...|$|R
5000|$|The {{traffic shaping}} {{mechanism}} used by stream sources is also employed by AVB bridges. AVB frames are forwarded with precedence over Best Effort traffic (i.e., reserved AVB stream traffic traversing an AVB bridge has forwarding precedence over non-reserved traffic) {{and will be}} subjected to traffic shaping rules (they may need to wait for sufficient credits).Just like for stream sources, the traffic shaping rules for bridges require that frames be distributed very evenly in time, but only on an aggregate class basis rather than on a per-stream basis. This means that all the AVB traffic being transmitted out of a particular port is distributed evenly in time measured using the QoS parameters of that class; this {{is the sum of}} the bandwidths of all the reservations for a particular AVB class for the particular port, made by the admission control process described below. This is to achieve the effect of smoothing out the delivery times (preventing bunching of frames [...] ) while a stream propagates through a network. The limited bunching provides the very useful benefit of placing a relatively small upper limit {{on the size of the}} AVB <b>output</b> <b>buffers</b> needed at all egress ports on a bridge, independent of the number of hops in the path. This bounded buffer size is a key attribute that enables bounded delay and eliminates network congestion for admitted AV streams in AVB networks even when non-admitted traffic does experience congestion.|$|E
40|$|In this article, {{the design}} of {{quadrature}} voltage controlled oscillator (Q-VCO), which covers the Bluetooh requirements is described. A methodology which makes easy {{the design of}} oscillators with negative resistance is shown. Standard 0. 35 um CMOS process was used. The circuit is fully monolithic, and this decreases its price. The oscillator has <b>output</b> <b>buffers,</b> which ensure the necessary power of the output signal. The supply voltage is 1, 5 volts and {{is limited by the}} used technology and the parameters necessary for the normal work of the os-cillator. The overall power consumption of the oscillator and the <b>output</b> <b>buffers</b> is 107 mW, and the phase noise is- 108 dBc/Hz, at 600 kHz from the carrier...|$|E
30|$|Research on vector access {{performance}} for multibank memories {{has a long}} history. In [16] a memory system was proposed with input and <b>output</b> <b>buffers</b> for all memory banks including a stalling mechanism and a bank assignment function based on a cyclic permutation.|$|E
40|$|Abstract:-A novel {{high and}} low speed <b>output</b> <b>buffer</b> circuit is {{proposed}} for Universal Serial Bus (USB) interface applications. Operation principles of this novel buffer are developed based on slew rate control and delayed turn-on technique. The mechanism for slew rate control is process variation self compensating. So, both precise rise and fall times of the output signal have been obtained for low speed operation. Moreover, the pull-up and pull-down output drivers are divided into several sub-drivers in parallel with the delayed turn-on characteristics. Therefore, the change of rate of di/dt decreases. And the simultaneous switching noise, based on simulations, are reduced from maximum overshoot 3. 47 V to 3. 36 V and maximum undershoot from- 0. 427 V to- 0. 068 V, respectively. This proposed <b>output</b> <b>buffer</b> design is low cost due to its easy realization in a digital CMOS process. The disclosed <b>output</b> <b>buffer</b> has been integrated in a complete USB transceiver circuit. Based on measured silicon data, satisfactory functions of the whole USB application IC have been obtained...|$|R
40|$|Abstract: Problem statement: Optical Packet Switching (OPS) and {{transmission}} networks based on Wavelength Division Multiplexing (WDM) have been increasingly {{deployed in the}} Internet infrastructure {{over the last decade}} {{in order to meet the}} huge increasing demand for bandwidth. Several different technologies have been developed for optical packet switching such as space switches, broadcast-and-select, input <b>buffered</b> switches and <b>output</b> <b>buffered</b> switches. These architectures vary based on several parameters such as the way of optical buffering, the placement of optical buffers, the way of solving the external blocking inherited from switching technologies in general and the components used to implement WDM. Approach: This study surveys most of the exiting optical packet switching architectures. A simulation-based comparison of input <b>buffered</b> and <b>output</b> <b>buffered</b> architectures were presented. Results: The performance analysis of the selected two architectures derived using simulation program and compared at different scenarios. We found that the <b>output</b> <b>buffered</b> architectures give better performance than input buffered architectures. Conclusion: The simulation results shows that the-broadcast-and-select architecture is attractive in terms that it has lees number of components compared to other switches...|$|R
5000|$|Perform a 9-way merge {{and store}} the {{result in the}} <b>output</b> <b>buffer.</b> Whenever the <b>output</b> <b>buffer</b> fills, write it to the final sorted file and empty it. Whenever any of the 9 input buffers empties, fill it with the next 10 MB of its {{associated}} 100 MB sorted chunk until no more data from the chunk is available. This is the key step that makes external merge sort work externally -- because the merge algorithm only makes one pass sequentially through each of the chunks, each chunk {{does not have to}} be loaded completely; rather, sequential parts of the chunk can be loaded as needed.|$|R
