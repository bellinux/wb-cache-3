3|10000|Public
40|$|A {{method of}} {{measuring}} the average sun {{time with a}} cylindrical sundial is presented in this article. The innovation represents {{the use of a}} gnomon–memory system, which has a numerical register consisting of information about the time addition necessary for the average sun time to be determined. This information {{can be found on the}} register using a moving, opaque, <b>output</b> <b>point</b> (<b>a</b> top of a pointer) and its shadow. This new idea is in a process in realization in Belogradchik...|$|E
40|$|Recent work of G. Beylkin {{helped set}} the stage for very general seismic inversions. We have {{combined}} these broad concepts for inversion with classical high-frequency asymptotics and perturbation methods to bring them closer to practically implementable algo-rithms. Applications include inversion schemes for both stacked and unstacked seismic data. Basic assumptions are that the data have relative true amplitude, and that a reasonably accurate background velocity c(x, 4 ’. z) is available. The perturbation from this background is then sought. Since high-frequency ap-proximations are used throughout, the resulting algo-rithms essentially locate discontinuities in velocity. An expression for a full 3 -D velocity inversion can be derived for a general data surface. In this degree of generality the formula does not represent a compu-tationally feasible algorithm, primarily because a key Jacobian determinant is not expressed in practical terms. In several important cases, however, this short-coming can be overcome and expressions can be ob-tained that lead to feasible computing schemes. Zero-offsets, common-sources, and common-receivers are ex-amples of such cases. Implementation of the final algorithms involves, first, processing the data by applying the FFT, making an amplitude adjustment and filtering, and applying an in-verse FFT. Then, for each <b>output</b> <b>point,</b> <b>a</b> summation is performed over that portion of the processed data influ-encing the output point. This last summation involves an amplitude and traveltime along connecting rays. The resulting algorithms are computationally competitive with analogous migration schemes...|$|E
40|$|This article {{presents}} the purchase {{management information system}}, finance management information system and security information system, their interdependence and tight correlation. Furthermore, we state {{the goals of the}} purchase management information system that must be achieved in any organisation, as the purchase (sub) process is carried out in every organisation. P-K matrix gives a detailed presentation of a public organisation, and data classes and sub-processes within the observed organisation. Other companies involved in similar activities can perform their processes in accordance with the presented business technology matrix. The business technology matrix was used for designing a data flow process diagram comprising data flow, warehouses, processes and the external entity which can also be used in such companies. The article also deals with the duration of the sub-processes. The duration of sub-processes must be reduced as much as possible in order to achieve the planned result at the process <b>output</b> <b>point.</b> <b>A</b> hypothesis was set in the article, for the period from the beginning of 2009 until the end of 2010. We observed whether the total cost-effectives coefficient in the company would fall under the threshold value of 1. The article has proven that, based on the sample (profit-and-loss account), {{there is no reason to}} discard the H 0 hypothesis, as the company's total cost-effectiveness coefficient did not fall below the permitted value of 1 for two years. The third section of the {{article presents}} the possible threat to organisations' information systems, and describes methods of protecting electronic information in processes, and recovering electronic databases in finance management information systems...|$|E
30|$|Each of {{the grid}} nodes {{represents}} {{a case of the}} decision table and each <b>output</b> <b>point</b> represents <b>a</b> FS of the control variable Δu.|$|R
5000|$|In mathematics, the {{elasticity}} or <b>point</b> {{elasticity of}} <b>a</b> positive differentiable function f {{of a positive}} variable (positive input, positive <b>output)</b> at <b>point</b> <b>a</b> is defined as ...|$|R
5000|$|Transresistance (for {{transfer}} resistance), also infrequently {{referred to}} as mutual resistance, is the dual of transconductance. It refers to the ratio between a change of the voltage at two <b>output</b> <b>points</b> and <b>a</b> related change of current through two input points, and is notated as rm: ...|$|R
3000|$|... dimensions. Terminating {{in a local}} minimum is not desirable; so if this {{is deemed}} a possibility, one should test for it (the test is {{analogous}} to the one in (3)) and restart the GAST algorithm from <b>a</b> new starting <b>point</b> as necessary. The algorithm also terminates if the distance between the input and <b>output</b> <b>points</b> of <b>a</b> line search is less than [...]...|$|R
5000|$|Van Herp painted mainly genre {{scenes and}} {{religious}} compositions. It {{is not possible}} to discern a development in his style since he only dated a few of his pictures. His style is characterised by its somewhat mannered way of drawing and the expressiveness of the figures. [...] His large <b>output</b> <b>point</b> to <b>a</b> large workshop with an almost industrial operation.|$|R
30|$|The {{results also}} showed that the output power curve of solar cell has obvious {{nonlinear}} characteristics, and each curve has only one maximum <b>output</b> power <b>point</b> and <b>an</b> optimum load resistance value.|$|R
50|$|OPTICS hence <b>outputs</b> the <b>points</b> in <b>a</b> {{particular}} ordering, annotated {{with their}} smallest reachability distance (in the original algorithm, the core distance is also exported, {{but this is}} not required for further processing).|$|R
50|$|Point clouds may {{be created}} by 3D scanners. These devices measure {{a large number of}} <b>points</b> on <b>an</b> object's surface, and often <b>output</b> <b>a</b> <b>point</b> cloud as <b>a</b> data file. The point cloud {{represents}} the set of points that the device has measured.|$|R
30|$|Once all {{the points}} {{coordinates}} (grid nodes and <b>output</b> <b>points)</b> are computed, we can {{proceed to the}} assignment by determining the minimal distance among all the distances separating each node of the grid from all the <b>output</b> <b>points</b> situated on the straight line. Then, we assign to each node of the grid the closest <b>output</b> <b>point.</b> Consequently, the decision table case corresponding to this node will contain the FS representing the selected <b>output</b> <b>point.</b> Nevertheless, <b>an</b> assignment conflict could arise {{in the case of}} equality between two minimal distances separating a node and two <b>output</b> <b>points.</b> We have proposed to select the <b>output</b> <b>point</b> which has the lower FS index if it is a case of the upper part with respect to the table diagonal or the <b>output</b> <b>point</b> which has the greater FS index if the case belongs to the lower part [37]. It should be noted that no more than two <b>output</b> <b>points</b> can be at the same distance from a given node of the grid since all the <b>output</b> <b>points</b> are on the same straight line.|$|R
40|$|The {{thesis is}} {{dedicated}} to select diagnostic methods for the insulation system of the electrical engines made by vacuum pressure impregnation method. The attention is concentrated on a test during the production and on diagnostics of the impregnated compounds. The main <b>output</b> <b>point</b> is <b>an</b> original algorithm continual checking impregnation compounds during their whole life and a research of close correlation between viscosity and admittance of the impregnating compounds. Summary in EnglishAvailable from STL, Prague, CZ / NTK - National Technical LibrarySIGLECZCzech Republi...|$|R
40|$|AbstractCodes for the {{solution}} of the initial value problem for a system of ordinary differential equations which are based on extrapolation of the explicit midpoint rule are adversely affected by “frequent” <b>output</b> at specified <b>points.</b> <b>A</b> good algorithm for the selection of order reduces the sensitivity to output significantly. A complementary algorithm is developed here which comes into play when variation of the order is no longer helpful. When it is applicable, the number of specific <b>output</b> <b>points</b> does not matter...|$|R
40|$|In {{the first}} quarter of 2006, the Austrian economy grew by 0. 6 percent in volume from the {{previous}} period. While private household demand began to stabilise, exports and industrial activity gathered considerable momentum. Manufacturers' assessment of order books climbed to a record high in May, according to evidence from the WIFO business survey for that month. Sales increases in wholesaling and the expansion of manufacturing <b>output</b> <b>point</b> to <b>an</b> upturn in investment. Employment and vacancies also posted gains, thanks to the economy's good performance. ...|$|R
50|$|Correction is not {{possible}} if the inverse does not exist—for instance if the transfer function has flat spots (the inverse would map multiple input <b>points</b> to <b>a</b> single <b>output</b> <b>point).</b> This produces <b>an</b> uncorrectable loss of information. Such a situation can occur when an amplifier is overdriven—causing clipping or slew rate distortion when, for a moment, the amplifier characteristics alone and not the input signal determine the output.|$|R
30|$|In this section, {{we present}} the {{algorithm}} of ESPRIT with subarray beamforming. The approach {{is similar to}} that in[4]; however, instead of using one output beam from each subarray, multiple <b>output</b> beams <b>pointing</b> to <b>a</b> group of closelyspaced angles are combined for ESPRIT processing.|$|R
40|$|A {{fast and}} {{accurate}} {{process for the}} evaluation of the radiation pattern of reflector antennas is presented in this paper. It is developed in the high-frequency framework of the Physical Optics approximation for the surface electric current induced on the reflector by the field radiated from the feed. Two steps form the method. The former consists in subdividing the reflector into a proper number of sub-domains and then, for each of them, calculating the field at the <b>output</b> <b>points</b> via <b>an</b> optimal interpolation algorithm which uses a nonredundant number of samples. In the latter, the results obtained at the first step for each <b>output</b> <b>point</b> are aggregated for determining the radiation pattern of the considered reflector antenna. Numerical simulations assess the efficiency of the proposed approach...|$|R
3000|$|... [...]) fix {{the grid}} nodes X-axis {{coordinates}} (resp. Y-axis coordinates) in the interval [− 1, + 1] (universe of discourse (UD)) {{with a simple}} computing formula given in the next paragraph. Each abscissa (resp. ordinate) represents a fuzzy set (FS) of the variable e (resp. Δe). The number of the grid constitutive nodes is then equal to the product result between the two FLC input FSs numbers. Once, the nodes are fixed, we introduce the <b>output</b> <b>points</b> on <b>a</b> straight line corresponding to the FLC output variable Δu. Now, the <b>points</b> (<b>output</b> ones) represent the FSs and not their coordinates. The number of points {{is equal to the}} output variable FSs number.|$|R
40|$|Quantizers {{are widely}} used in various digital systems. A {{quantizer}} is a many-to-one mapping from a possibly infinite set to a finite (generally small) set. A new quantizer, the set quantizer (SQ), is introduced in this dissertation. The SQ was motivated by set expansion of output levels and by the utilization of residual redundancy in the source process. The SQ uses a collection, or set (hence the name), of <b>output</b> <b>points,</b> instead of one <b>output</b> <b>point</b> as in the scalar quantizer, in a quantization region. The SQ maps the input sample to the available <b>output</b> <b>point</b> closest to it while keeping the quantizer output rate {{the same as the}} normal scalar quantizer. The selection of the <b>output</b> <b>point</b> in <b>a</b> given set {{is the key to the}} success of the SQ. Two schemes are proposed for this purpose: the first borrows ideas from the hidden Markov model and the second is based on a random coding approach. The SQ is tested on memoryless sources, Markov sources and image data. For bit rate greater than two, it is found that the SQ performs better for memoryless sources than all the quantizers found in the literature. ...|$|R
40|$|Contents: (1) a {{theoretical}} basis for local power calculation; (2) source radiation {{in the presence}} of a half-plane; (3) radiation from a line source near an edge at which a Kutta condition holds; (4) radiation by <b>a</b> <b>point</b> source above <b>a</b> plane independence boundary; and (5) power <b>output</b> of <b>a</b> <b>point</b> source in <b>a</b> uniform flow...|$|R
40|$|The {{present study}} proposes a robot arm that can support precise {{positioning}} in operation by a human. The robot arm has passive and actuated joints. The passive joint is not mechanically constrained and can move passively with {{the motion of}} the <b>output</b> <b>point</b> of the robot arm. Therefore, a human can move the <b>output</b> <b>point</b> of the robot arm by his will. When a human tries to move the <b>output</b> <b>point</b> along <b>an</b> object path, the displacement of the passive joint is determined passively. Then, if the actuated joint is controlled so that the <b>output</b> <b>point</b> may be on the object path, the human can achieve precise positioning. Namely, using the proposed robot arm, the human can adjust the velocity, acceleration, applied force and so on by his will, while the position is preciously compensated by the actuated joint. This paper describes a mechanical form of such robot arm for drawing of planar figures and shows that the robot arm has specific singularity condition. In order to avoid the singularity condition, the proposed robot arm interchanges the actuated joint and the passive one situationally. The study fabricated the two degrees of freedom robot arm for positioning assistance and described its control method. Furthermore, its availability is confirmed by drawing some figures...|$|R
40|$|Low-dissipation {{model and}} the endoreversible model of heat engines {{are two of the}} most {{commonly}} studied models of machines in finite-time thermodynamics. In this paper, we compare the performance characteristics of these two models under optimal power <b>output.</b> We <b>point</b> out <b>a</b> basic equivalence between them, in the linear response regime. Comment: 4 pages, revtex, No figures; Revised version accepted for Phys. Rev. ...|$|R
5000|$|... {{such that}} {{it is clear that}} the {{optimizing}} algorithm adjusts [...] Depending on the problem and number of dimensions, there may be more such parameters. The <b>output</b> of <b>a</b> <b>point</b> set registration algorithm is therefore the transformation parameter [...] of model [...] so that [...] is optimally aligned to [...]|$|R
40|$|In {{these first}} two categories, the gamut mapping is a pointwise {{operation}} from <b>an</b> input <b>point</b> to <b>an</b> <b>output</b> <b>point</b> in <b>an</b> appropriate (usually perceptual) 3 D color space. One {{of the fundamental}} attributes of pointwise operations {{is that they do}} not take spatial neighborhood effects into account. In certain situations, these neighborhood effects can be of high importance. For example, consider an im-age composed on the computer display (CRT), with black text against a blue background. The text is easily distin-guished against the background. However, when both are mapped to a printer’s gamut with an algorithm that maps out-of-gamut colors to the nearest surface color, the CRT blue maps to a much darker blue in the printer’s gamut. On the other hand, the CRT black maps to a lighter printer black. This is illustrated in Fig. 1, where the dotted an...|$|R
2500|$|... {{which are}} the {{distances}} from the fulcrum to the input <b>point</b> <b>A</b> and to the <b>output</b> <b>point</b> B, respectively.|$|R
40|$|Abstract: The current {{research}} {{in the design of}} high speed VLSI architectures for real-time digital signal processing (DSP) algorithms has been directed by the advances in the VLSI technology, which have provided the designers with significant impetus for porting algorithm into architecture. Many of the algorithms used in DSP and matrix arithmetic require elementary functions such as trigonometric, inverse trigonometric, logarithm, exponential, multiplication, and division functions and one such algorithm is CORDIC. Often trigonometric functions are used in embedded applications. Examples of this include motion control, filtering and waveform synthesis. For waveforms with few <b>output</b> <b>points</b> per cycle (for example one <b>output</b> <b>point</b> per degree) <b>a</b> lookup table will often suffice, and indeed this method is optimal in that it offers a reasonable compromise between speed and the need to use the microcontroller’s memory efficiently. The CORDIC computing technique—a highly efficient method to compute elementary functions sine and cosine values of the given angle using CORDIC algorithm...|$|R
40|$|The Shuttle is {{the first}} launch system {{deployed}} by NASA with full redundancy in the on-board computer systems. Fault-tolerance, i. e., restoring to a backup with less capabilities, was the method selected for Apollo. The Gemini capsule {{was the first to}} carry a computer, which also served as backup for Titan launch vehicle guidance. Failure of the Gemini computer resulted in manual control of the spacecraft. The Apollo system served vehicle flight control and navigation functions. The redundant computer on Skylab provided attitude control only in support of solar telescope pointing. The STS digital, fly-by-wire avionics system requires 100 percent reliability. The Orbiter carries five general purpose computers, four being fully-redundant and the fifth being soley an ascent-descent tool. The computers are synchronized at input and <b>output</b> <b>points</b> at <b>a</b> rate of about six times a second. The system is projected to cause a loss of an Orbiter only four times in a billion flights...|$|R
40|$|In this paper, we {{introduce}} {{some new}} classes of generalized F-contractions and we establish certain fixed point results for such mappings {{in the setting}} of b-metric-like spaces. Some examples will illustrate the results and the corresponding computer simulations are suggestive from the <b>output</b> <b>point</b> of view. <b>A</b> second purpose of the paper is to apply the abstract results {{in the study of the}} existence of a solution for an integral equation problem and for a boundary value problem related to a real life mathematical model, namely, the problem of conversion of solar energy to electrical energy. Our study is concluded with an open problem, related to an integrodifferential equation arising in the study of electrical and electronics circuit analysis...|$|R
40|$|A {{modified}} derivative superposition (DS) method using cascaded stages transistor is described. It {{uses the}} third order intermodulation (IMD 3) current {{generated from the}} preceding stage to cancel those at {{the output of the}} following stage. This analysis demonstrates that an IMD 3 minimum occurs near the <b>output</b> power compression <b>point.</b> <b>A</b> balanced X-band linear power amplifier (PA) monolithic microwave integrated circuit (MMIC) using this concept is presented. The results of measurement showed a carrier-to-IMD 3 ratio (C/I 3) improvement more than 30 dB compared with the conventional cascaded stages configuration...|$|R
50|$|Let the {{coordinate}} vector of {{the point}} P that defines the fulcrum be rP, and introduce the lengths which are the distances from the fulcrum to the input <b>point</b> <b>A</b> and to the <b>output</b> <b>point</b> B, respectively.|$|R
40|$|Abstract — The current {{research}} {{in the design of}} high speed VLSI architectures for real-time digital signal processing (DSP) algorithms has been directed by the advances in the VLSI technology, which have provided the designers with significant impetus for porting algorithm into architecture. Many of the algorithms used in DSP and matrix arithmetic require elementary functions such as trigonometric, inverse trigonometric, logarithm, exponential, multiplication, and division functions and one such algorithm is CORDIC. Often trigonometric functions are used in embedded applications. Examples of this include motion control, filtering and waveform synthesis. For waveforms with few <b>output</b> <b>points</b> per cycle (for example one <b>output</b> <b>point</b> per degree) <b>a</b> lookup table will often suffice, and indeed this method is optimal in that it offers a reasonable compromise between speed and the need to use the microcontroller’s memory efficiently. The CORDIC computing technique—a highly efficient method to compute elementary functions and this paper presents how to calculate sine and cosine values of the given angle using CORDIC algorithm. Summary of CORDIC synthesis results based on Xilinx FPGAs is given. The system simulation was carried out using ModelSim and Xilinx ISE Design Suite 9. 2 i. The system can be implemented usin...|$|R
40|$|Standard {{macroeconomic}} {{models of}} price stickiness assume that each firm leaves its price unchanged for {{a fixed amount}} of time. The authors present an alternative model in which the pricing decision depends {{on the state of}} the economy. They find a method of aggregating individual price changes that allows a simple characterization of macroeconomic variables. The model produces a positive money-output correlation and an empirical Phillips curve. In addition, the impact of monetary shocks depends crucially on the current level of <b>output,</b> which <b>points</b> to <b>a</b> natural connection between state-dependent microeconomics and state-dependent macroeconomics. Copyright 1991, the President and Fellows of Harvard College and the Massachusetts Institute of Technology. ...|$|R
50|$|It {{would be}} much more {{desirable}} to have an amplifier that would give Class A performance up to the transition level, with Class B after that, rather than AB. This would abolish the AB gain changes that cause extra distortion. This is the basic Class XD principle, and it’s a very simple one, develop a topology that displaces the crossover point to one side of zero crossing - it can be either positive or negative. This is achieved by the injection of an extra current, into the <b>output</b> <b>point</b> of <b>a</b> conventional Class B amplifier. The added ‘displacement’ current does not directly alter the voltage at the output - the output stage inherently has low output impedance, and this is further lowered by the use of global negative feedback. What it does do is alter the pattern of current flowing in the output devices. The displacement current can be sunk to V- from the output, or sourced from V+, so the crossover region is either displaced downward or is pulled upwards. This is arbitrary as the direction of displacement makes no difference, either could be used.|$|R
40|$|This thesis {{proposes a}} {{solution}} to the problem of resilient state estimation and sensor fusion in an autonomous micro air vehicle. The setup comprises of redundant sensors that measure the same physical signal. An adversary may spoof a subset of these sensors and send falsified readings to the controller, potentially compromising performance and safety of the system. This work integrates Brooks-Iyengar Sensor fusion algorithm with a generic state estimator as a method to thwart sensor attacks. The algorithm <b>outputs</b> <b>a</b> <b>point</b> estimate and <b>a</b> fusion interval based on an assumed set of faulty sensors. Finally, the thesis illustrates the usefulness of the resilient state estimator with a case study on a MAV flight dataset...|$|R
40|$|The current {{research}} {{in the design of}} high speed VLSI architectures for real-time digital signal processing (DSP) algorithms has been directed by the advances in the VLSI technology, which have provided the designers with significant impetus for porting algorithm into architecture. Many of the algorithms used in DSP and matrix arithmetic require elementary functions such as trigonometric, inverse trigonometric, logarithm, exponential, multiplication, and division functions and one such algorithm is CORDIC. Often trigonometric functions are used in embedded applications. Examples of this include motion control, filtering and waveform synthesis. For waveforms with few <b>output</b> <b>points</b> per cycle (for example one <b>output</b> <b>point</b> per degree) <b>a</b> lookup table will often suffice, and indeed this method is optimal in that it offers a reasonable compromise between speed and the need to use the microcontroller’s memory efficiently. The CORDIC computing technique—a highly efficient method to compute elementary functions and this paper presents how to calculate sine and cosine values of the given angle using CORDIC algorithm. Summary of CORDIC synthesis results based on Xilinx FPGAs is given. The system simulation was carried out using ModelSim and Xilinx ISE Design Suite 9. 2 i. The system can be implemented using Spartan 3 XC 3 S 50 with Xilinx ISE 9. 2 i and VHDL...|$|R
