0|259|Public
40|$|To {{the best}} of our knowledge, one or more authors of this paper were federal {{employees}} when contributing to this work. This is the publisher’s final pdf. The published article is copyrighted by the author(s) and published by Copernicus Publications on behalf of the European Geosciences Union. The published article can be found at: [URL] apply GENMOM, a coupled atmosphere–ocean climate model, to simulate eight equilibrium time slices at 3000 -year intervals for the past 21, 000 years forced by changes in Earth–Sun geometry, atmospheric greenhouse gases (GHGs), continental ice sheets, and sea level. Simulated global cooling during the Last Glacial Maximum (LGM) is 3. 8 °C and the rate of post-glacial warming is in overall agreement with recently published temperature reconstructions. The greatest rate of warming occurs between 15 and 12 ka (2. 4 °C over land, 0. 7 °C over oceans, and 1. 4 °C globally) in response to changes in radiative forcing from the diminished extent of the Northern Hemisphere (NH) ice sheets and increases in GHGs and NH summer insolation. The modeled LGM and 6 ka temperature and precipitation climatologies are generally consistent with proxy reconstructions, the PMIP 2 and PMIP 3 simulations, and other paleoclimate data–model analyses. The model does not capture the mid-Holocene “thermal maximum” and gradual cooling <b>to</b> <b>preindustrial</b> (PI) global <b>temperature</b> found in the data. Simulated monsoonal precipitation in North Africa peaks between 12 and 9 ka at values 50...|$|R
40|$|Make Poverty History have {{released}} a report outlining why we should keep climate change below 2 degrees (compared with <b>preindustrial</b> <b>temperatures),</b> what Australia 2 ̆ 7 s target should be, what our responsibilities as a wealthy developed country are in providing funding for adaptation and technology transfer to developing countries, and what assistance we should provide to 2 ̆ 7 Climate Change Refugees 2 ̆ 7...|$|R
5000|$|According to Early Anthropocene Hypothesis {{the early}} farming practises started {{to raise the}} {{atmospheric}} CO2-levels <b>to</b> <b>preindustrial</b> levels ...|$|R
40|$|Numerous {{independent}} analyses {{indicate that}} we must limit climate change to less than 2 ºC above <b>preindustrial</b> <b>temperatures</b> <b>to</b> avoid dangerous impacts to nature, humans, and the global economy. Average global warming of 2 °C will result in dangerous and irreversible effects, which rapidly worsen above 2 °C warming. This paper seeks to identify the massive difference between the impacts that will happen at 2 and 3 °C...|$|R
40|$|We must reiterate, however, {{that this}} explana-tion, which {{attempts}} to {{shed some light}} on the phenomenon of inverse grading observed in thick subaqueously emplaced cobble or boulder beds such as at Wheeler Gorge, is simplistic <b>ompared</b> <b>to</b> the enormously complex mechanisms involved in the rapid transportat ion of great masses of clastic debris for long distances...|$|R
40|$|We apply GENMOM, a coupled atmosphere–ocean climate model, to {{simulate}} eight equilibrium time slices at 3000 -year intervals {{for the past}} 21 000 years forced by changes in Earth–Sun geometry, atmospheric greenhouse gases (GHGs), continental ice sheets, and sea level. Simulated global cooling during the Last Glacial Maximum (LGM) is 3. 8 °C {{and the rate of}} post-glacial warming is in overall agreement with recently published temperature reconstructions. The greatest rate of warming occurs between 15 and 12 ka (2. 4 °C over land, 0. 7 °C over oceans, and 1. 4 °C globally) in response to changes in radiative forcing from the diminished extent of the Northern Hemisphere (NH) ice sheets and increases in GHGs and NH summer insolation. The modeled LGM and 6 ka temperature and precipitation climatologies are generally consistent with proxy reconstructions, the PMIP 2 and PMIP 3 simulations, and other paleoclimate data–model analyses. The model does not capture the mid-Holocene "thermal maximum" and gradual cooling <b>to</b> <b>preindustrial</b> (PI) global <b>temperature</b> found in the data. Simulated monsoonal precipitation in North Africa peaks between 12 and 9 ka at values ~ 50 % greater than those of the PI, and Indian monsoonal precipitation peaks at 12 and 9 ka at values ~ 45 % greater than the PI. GENMOM captures the reconstructed LGM extent of NH and Southern Hemisphere (SH) sea ice. The simulated present-day Antarctica Circumpolar Current (ACC) is ~ 48 % weaker than the observed (62 versus 119 Sv). The simulated present-day Atlantic Meridional Overturning Circulation (AMOC) of 19. 3 ± 1. 4 Sv on the Bermuda Rise (33 ° N) is comparable with observed value of 18. 7 ± 4. 8 Sv. AMOC at 33 ° N is reduced by ~ 15 % during the LGM, and the largest post-glacial increase (~ 11 %) occurs during the 15 ka time slice...|$|R
40|$|Political leaders {{around the}} world have pledged to limit global warming at most to 2 °C above <b>preindustrial</b> <b>temperatures.</b> This will require a {{fundamental}} restructuring of energy production, and the management of other human and natural systems that influence the concentration of CO 2 and other greenhouse gasses (GHGs) in the atmosphere. Scientists can assist this process by providing new knowledge and by supporting the implementation of actions. However, the involvement of experts is required in the long term, which is difficult to sustain in current research institutions. The research environment needs to be revised to ensure that the drivers of carbon research are aligned with the interests of society...|$|R
40|$|A phenomenological {{thermodynamic}} model is adopted {{to estimate the}} relative contribution of the solar-induced versus anthropogenic-added climate forcing during the industrial era. We compare different <b>preindustrial</b> <b>temperature</b> and solar data reconstruction scenarios since 1610. We argue that a realistic climate scenario is the one described by a large preindustrial secular variability (as the one shown by the paleoclimate temperature reconstruction by Moberg et al. (2005)) with the total solar irradiance experiencing low secular variability (as the one shown by Wang et al. (2005)). Under this scenario the Sun might have contributed up to approximately 50 % (or more if ACRIM total solar irradiance satellite composite (Willson and Mordvinov, 2003) is implemented) of the observed global warming since 1900...|$|R
40|$|One of {{the main}} {{challenges}} of voltage source converter based HVDC systems is DC faults. In this paper, two different modified half-bridge modular multilevel converter topologies are proposed. The proposed converters offer a fault tolerant against the most severe pole-to-pole DC faults. The converter comprises three switches or two switches and 4 diodes in each cell, which can result in less cost and losses <b>ompared</b> <b>to</b> the full-bridge modular multilevel converter. Converter structure and controls are presented including the converter modulation and capacitors balancing. MATLAB/SIMULINK simulations are carried out to verify converter operation in normal and faulty conditions...|$|R
40|$|Introduction] With {{the goal}} of {{limiting}} the rise in global temperature to two degrees relative <b>to</b> <b>preindustrial</b> levels, the global community agreed to try to halve GHG emissions (vis- 0 -vis the level in 1990) by 2050. In order to achieve this ambitious target, developed countries ought to contribute profoundly to the reduction of GHG emissions by 80...|$|R
40|$|AIM AND SCOPE Clarify the {{variations}} in carbon prices found in mitigation scenarios that limit global mean surface temperature increase to below 2 °C relative <b>to</b> <b>preindustrial</b> levels. CONTEXT Integrated assessment models 1 (IAM) are dominant tools {{for the development of}} long-term emissions scenarios in line with climate objectives. There is a large variety of IAMs and, together with variations in socioeconomic and technological assumptions, this variety results in important differences in model behavior. For the achievement of low emissions scenarios, models typically assume or produce an implicit shadow price for carbon or represent policy instruments, including carbon pricing. This briefing aims at exploring and understanding the variation in these carbon price estimates for stringent climate change mitigation scenarios. The focus of this exercise will be on scenarios that limit global mean temperature surface increase (henceforth, warming) to below 2 °C relative <b>to</b> <b>preindustrial</b> levels with a greater than 66...|$|R
5000|$|This is {{the target}} {{advocated}} (as an upper bound) in the Stern Review. As approximately a doubling of CO2 levels relative <b>to</b> <b>preindustrial</b> times, it implies a temperature increase of about three degrees, according to conventional estimates of climate sensitivity. Pacala and Socolow list 15 [...] "wedges", any 7 of which in combination should suffice to keep CO2 levels below 550 ppm.|$|R
40|$|Global-scale solar {{geoengineering}} is {{the deliberate}} {{modification of the}} climate system to offset some amount of anthropogenic climate change by {{reducing the amount of}} incident solar radiation at the surface. These changes to the planetary energy budget result in differential regional climate effects. For the first time, we quantitatively evaluate the potential for regional disparities in a multi-model context using results from a model experiment that offsets the forcing from a quadrupling of CO 2 via reduction in solar irradiance. We evaluate temperature and precipitation changes in 22 geographic regions spanning most of Earthʼs continental area. Moderate amounts of solar reduction (up to 85 % of the amount that returns global mean <b>temperatures</b> <b>to</b> <b>preindustrial</b> levels) result in regional temperature values that are closer <b>to</b> <b>preindustrial</b> levels than an un-geoengineered, high CO_ 2 world for all regions and all models. However, in all but one model, {{there is at least one}} region for which no amount of solar reduction can restore precipitation toward its preindustrial value. For most metrics considering simultaneous changes in both variables, temperature and precipitation values in all regions are closer <b>to</b> the <b>preindustrial</b> climate for a moderate amount of solar reduction than for no solar reduction...|$|R
50|$|In a far future, {{people are}} {{distributed}} over numerous planets, {{many of which}} have lost contact with Earth's civilisation. On a far ring planet, known as World Called Maanerek by its inhabitants, only a weak memory of Earth has survived, and technology has declined <b>to</b> <b>preindustrial.</b> Maanerek is coveted by a highly developed civilization because it is situated at a location of strategical value.|$|R
5000|$|... "Radiative forcing is {{a measure}} of the {{influence}} a factor has in altering the balance of incoming and outgoing energy in the Earth-atmosphere system and is an index of the importance of the factor as a potential climate change mechanism. In this report radiative forcing values are for changes relative <b>to</b> <b>preindustrial</b> conditions defined at 1750 and are expressed in Watts per square meter (W/m2)." ...|$|R
40|$|Comparative {{studies were}} made on growth and {{development}} of panicles, flowering behaviour and maturing of grains of CSH-I, 22 E and their parcnts. from its transformation from vegetative meristem to floral meristem in three seasons. Kharif, Rabi and Late Rabi. The sequence of some recognizable growth stages during GS 2 GS 3 have bcen noted parents although in some characters it has shown some expression of good growth but in most characters 22 E has shown higher degree of hete osisc <b>ompared</b> <b>to</b> its parents. The growth curves of CSH-I and 22 E have shown that 22 E was fast growing in major characters but panicle length in CSH-I in major stages was {{higher than that of}} 22 E [...] ...|$|R
5000|$|However {{unbearable}} tensions existed {{just below}} the surface, and in 1902 unknown parties decapitated the ruling house by detonating a nuclear device in London. The resulting succession wars included nuclear and biological weapons, wiped out much of humanity and reduced most of the survivors <b>to</b> <b>preindustrial</b> barbarism. But Terraustralis (Homeline Australia) escaped much of the destruction, and the techno-military cabal known as [...] "The Centrum" [...] that took control there ultimately extended its authority across the globe.|$|R
40|$|We {{report on}} the {{elliptic}} and triangular flow measurements {{for a number of}} hadrons including charged pions, and (anti-) protons, as well as those with strangeness content: kaons, ϕ-meson, K^ 0 _s, Λ/Λ̅, Ξ, and Ω. The results reported cover mid [...] rapidity, |η|< 0. 8, and a wide, 0. 2 < p_ T < 16 GeV/c, transverse momentum range for Pb-Pb collisions at √(s_ NN) = 2. 76 TeV recorded by ALICE at the LHC. The mass splitting and the scaling properties of the elliptic flow with the number of constituent quarks and the particle transverse mass are studied as a function of collision centrality. The results are <b>ompared</b> <b>to</b> RHIC measurements and to hydrodynamic model predictions. Comment: 4 pages, 6 figures, Qaurk Matter 2012 cnference proceedings to be pubblished in Nuclear Physics...|$|R
40|$|Quantitative steganalyzers are {{important}} in forensi steganalysis as they an estimate the payload, or, more pre isely, the number of embedding hanges in the stego image. This paper proposes a general method for onstru ting quantitative steganalyzers from features used in blind dete tors. The method is based on support ve tor regression, whi h is used to learn the mapping between a feature ve tor extra ted from the image and the relative embedding hange rate. The performan e is evaluated by onstru ting quantitative steganalyzers for eight steganographi methods for JPEG les, using a 275 -dimensional feature set. Error distributions of within- and between-image errors are empiri ally estimated for Jsteg and nsF 5. For Jsteg, the a ura y is <b>ompared</b> <b>to</b> state-of-the-art quantitative steganalyzers. 1...|$|R
40|$|A maximum global-mean warming of 2 ˚C above <b>preindustrial</b> <b>temperatures</b> {{has been}} adopted by the United Nations Framework Convention on Climate Change to “prevent {{dangerous}} anthropogenic interference with the climate system”. Attempts to find agreements on emissions reductions have proved highly intractable because industrialized countries are {{responsible for most of}} the historical emissions, while developing countries will produce most of the future emissions. Here we present a Fair Plan for reducing global greenhouse-gas emissions. Under the Plan, all countries begin mitiga-tion in 2015 and reduce greenhouse-gas emissions to zero in 2065. Developing countries are required to follow a miti-gation trajectory that is less aggressive {{in the early years of}} the Plan than the mitigation trajectory for developed coun-tries. The trajectories are chosen such that the cumulative emissions of the Kyoto Protocol’s Annex B (developed) and non-Annex B (developing) countries are equal. Under this Fair Plan the global-mean warming above preindustrial tem-peratures is held below 2 ˚C...|$|R
50|$|Our {{results at}} least imply that strong cooling in the North Atlantic from AMOC {{shutdown}} does create higher wind speed. The increment in seasonal {{mean wind speed}} of the northeasterlies relative <b>to</b> <b>preindustrial</b> conditions is as much as 10-20 %. Such a percentage increase of wind speed in a storm translates into an increase of storm power dissipation by a factor ∼1.4-2, because wind power dissipation {{is proportional to the}} cube of wind speed. However, our simulated changes refer to seasonal mean winds averaged over large grid-boxes, not individual storms.|$|R
40|$|The {{observed}} {{increase in}} the concentration of greenhouse gases (GHGs) since the preindustrial era has most likely committed the world to a warming of 2. 4 °C (1. 4 °C to 4. 3 °C) above the <b>preindustrial</b> surface <b>temperatures.</b> The committed warming is inferred from the most recent Intergovernmental Panel on Climate Change (IPCC) estimates of the greenhouse forcing and climate sensitivity. The estimated warming of 2. 4 °C is the equilibrium warming above <b>preindustrial</b> <b>temperatures</b> that the world will observe even if GHG concentrations are held fixed at their 2005 concentration levels but without any other anthropogenic forcing such as the cooling effect of aerosols. The range of 1. 4 °C to 4. 3 °C in the committed warming overlaps and surpasses the currently perceived threshold range of 1 °C to 3 °C for dangerous anthropogenic interference {{with many of the}} climate-tipping elements such as the summer arctic sea ice, Himalayan–Tibetan glaciers, and the Greenland Ice Sheet. IPCC models suggest that ≈ 25 % (0. 6 °C) of the committed warming has been realized as of now. About 90 % or more {{of the rest of the}} committed warming of 1. 6 °C will unfold during the 21 st century, determined by the rate of the unmasking of the aerosol cooling effect by air pollution abatement laws and by the rate of release of the GHGs-forcing stored in the oceans. The accompanying sea-level rise can continue for more than several centuries. Lastly, even the most aggressive CO 2 mitigation steps as envisioned now can only limit further additions to the committed warming, but not reduce the already committed GHGs warming of 2. 4 °C...|$|R
40|$|Solar {{geoengineering}} {{has been}} proposed as a backup plan to offset some aspects of anthropogenic climate change if timely CO 2 emission reductions fail to materialize. Modeling {{studies have shown that}} there are trade-offs between changes in temperature and hydrological cycle in response to solar geoengineering. Here we investigate the possibility of stabilizing both global mean temperature and precipitation simultaneously by combining two geoengineering approaches: stratospheric sulfate aerosol increase (SAI) that deflects sunlight to space and cirrus cloud thinning (CCT) that enables more longwave radiation to escape to space. Using the slab ocean configuration of National Center for Atmospheric Research Community Earth System Model, we simulate SAI by uniformly adding sulfate aerosol in the upper stratosphere and CCT by uniformly increasing cirrus cloud ice particle falling speed. Under an idealized warming scenario of abrupt quadrupling of atmospheric CO 2, we show that by combining appropriate amounts of SAI and CCT geoengineering, global mean (or land mean) temperature and precipitation can be restored simultaneously <b>to</b> <b>preindustrial</b> levels. However, compared to SAI, cocktail geoengineering by mixing SAI and CCT does not markedly improve the overall similarity between geoengineered climate and preindustrial climate on regional scales. Some optimal spatially nonuniform mixture of SAI with CCT might have the potential to better mitigate climate change at both the global and regional scales. Plain Language Summary Increases in atmospheric carbon dioxide cause increase in both global temperatures and precipitation. Solar geoengineering {{has been proposed}} as a means to counteract this climate change by deliberately deflecting more sunlight from the Earth's climate system. Numerous climate modeling studies have shown that proposed solar geoengineering schemes, such as injection of sulfate aerosols into the stratosphere, can cool climate, but the amount of precipitation change per degree of temperature change is greater than that for CO 2, meaning that such proposals cannot simultaneously globally restore both average temperatures and average precipitation. It has also been suggested that the Earth could be cooled by thinning cirrus clouds, but the amount of precipitation change per degree of temperature change for this method is less than that for CO 2. Our climate modeling study shows, for the first time, that a cocktail of these two approaches would decrease precipitation and temperature in the same ratios as they are increased by CO 2, which would allow simultaneous recovery of <b>preindustrial</b> <b>temperature</b> and precipitation in a high CO 2 world at global scale. We show that although the average temperatures and precipitation can be recovered at global scale, substantial differences between the geoengineered and natural climates persist at regional scale...|$|R
40|$|This {{paper is}} {{motivated}} by the analysis of gene expression sets, especially by finding differentially expressed gene sets between two phenotypes. Gene _ 2 expression levels are highly correlated and, very likely, have approximately normal distribution. Therefore, {{it seems reasonable to}} use two-sample Hotelling's test for such data. We discover some unexpected properties of the test making it different from the majority of tests previously used for such data. It appears that the Hotelling's test does not always reach maximal power when all marginal distributions are differentially expressed. For highly correlated data its maximal power is attained when about a half of marginal distributions are essentially different. For the case when the correlation coefficient is greater than 0. 5 this test is more powerful if only one marginal distribution is shifted, <b>omparing</b> <b>to</b> the case when all marginal distributions are equally shifted. Moreover, when the correlation coefficient increases the power of Hotelling's test increases as well. Comment: 8 pages, 3 figures, 1 tabl...|$|R
40|$|The {{withdrawal}} {{of water for}} irr igation in the dryer regions of Mexico already accounts for some 91 % of potential availability. Further expansion of irr igated acreage, therefore, must rely more on increased water use efficiency rather than increased supply from engineering works. A prime instrument to bring about such an improvement could be an appropriate water pricing structure. The first three sections of the paper present he conceptual issues involved, {{as well as the}} empirical findings which show that i r r iga-tion farmers pay, on average, less than 10 % of actual water costs. Water use efficiencies are shown to be less than 50 % but are mark-edly higher in irr igation distr icts with volumetric <b>ompared</b> <b>to</b> those with fixed water charges. The fourth section develops ome representative pricing structures that are designed to account for both efficiency and income distributional goals, while the last one addresses ome of the likely implementation problems. I...|$|R
40|$|The {{performance}} of user cooperation that results when users forward packets {{for each other}} in a multiaccess network is <b>ompared</b> <b>to</b> that of dedicated-relay cooperation which results from using a dedicated wireless relay when the users do not cooperate. Using the total transmit and processing power consumed at all nodes as a cost metric, the outage probabilities achieved by dynamic decode-and-forward (DDF) and amplify-and-forward (AF) are compared for the two networks. A geometry-inclusive high signal-to-noise ratio (SNR) outage analysis in conjunction with area-averaged numerical simulations shows that in a K-user time-duplexed multiaccess network, user and dedicated-relay cooperation achieve a maximum diversity per user of K and 2, respectively, under both DDF and AF. However, when accounting for energy costs of processing and communication, dedicated-relay cooperation can be more energy efficient than user cooperation, i. e., dedicated-relay cooperation achieves coding (SNR) gains, particularly in the low SNR regime, that override the diversity advantage of user cooperation...|$|R
40|$|This paper {{summarizes}} {{the results of}} an intercomparison project with Earth System Models of Intermediate Complexity (EMICs) undertaken in support of the Intergovernmental Panel on Climate Change (IPCC) Fifth Assessment Report (AR 5). The focus is on long-term climate projections designed to 1) quantify the climate change commitment of different radiative forcing trajectories and 2) explore the extent to which climate change is reversible on human time scales. All commitment simulations follow the four representative concentration pathways (RCPs) and their extensions to year 2300. Most EMICs simulate substantial surface air temperature and thermosteric sea level rise commitment following stabilization of the atmospheric composition at year- 2300 levels. The meridional overturning circulation (MOC) is weakened temporarily and recovers to near-preindustrial values in most models for RCPs 2. 6 - 6. 0. The MOC weakening is more persistent for RCP 8. 5. Elimination of anthropogenic CO 2 emissions after 2300 results in slowly decreasing atmospheric CO 2 concentrations. At year 3000 atmospheric CO 2 is still at more than half its year- 2300 level in all EMICs for RCPs 4. 5 - 8. 5. Surface air temperature remains constant or decreases slightly and thermosteric sea level rise continues for centuries after elimination of CO 2 emissions in all EMICs. Restoration of atmospheric CO 2 from RCP <b>to</b> <b>preindustrial</b> levels over 100 - 1000 years requires large artificial removal of CO 2 from the atmosphere and does not result in the simultaneous return <b>to</b> <b>preindustrial</b> climate conditions, as surface air temperature and sea level response exhibit a substantial time lag relative to atmospheric CO 2...|$|R
40|$|The Last Interglacial (LIG, ∼ 129 - 116 {{thousand}} years ago, ka) represents an excellent case study {{to investigate the}} response of sensitive components of the Earth System and mechanisms of high-lati tude amplification to a climate warmer than present-day. The Paleoclimate Model Intercomparison Project (Phase 4, hereafter referred as PMIP 4) and the Coupled Model Intercomparison Project (Phase 6, hereafter referred as CMIP 6) are coordinating the design of (1) a LIG Tier 1 equilibrium simulation to simulate the climate response at 127 ka, a time interval associated with a strong orbital forcing and greenhouse gas concentrations close <b>to</b> <b>preindustrial</b> levels and (2) associated Tier 2 sensitivity experiments to examine {{the role of the}} ocean, vegetation and dust feedbacks in modulating the response to this orbital forcing. Evaluating the capability of the CMIP 6 /PMIP 4 models to reproduce the 127 ka polar and sub-polar climate will require appropriate data-based benchmarks which are currently missing. Based on a recent data synthesis that offers the first spatio-temporal representation of high-latitude (i. e. poleward of 40 °N and 40 °S) surface temperature evolution during the LIG, we produce a new 126 – 128 ka time slab, hereafter named 127 ka time slice. This 127 ka time slice represents surface <b>temperature</b> anomalies relative <b>to</b> <b>preindustrial</b> and is associated with quantitative estimates of the uncertainties related to relative dating and surface temperature reconstruction methods. It illustrates warmer-than-preindustrial conditions in the high-latitude regions of both hemispheres. In particular, summer sea surface temperatures (SST) in the North Atlantic region were on average 1. 1 °C (with a standard error of the mean of 0. 7 °C) warmer relative <b>to</b> <b>preindustrial</b> and 1. 8 °C (with a standard error of the mean of 0. 8 °C) in the Southern Ocean. In Antarctica, average 127 ka annual surface air temperature was 2. 2 °C (with a standard error of the mean of 1. 4 °C) warmer compared <b>to</b> <b>preindustrial.</b> We provide a critical evaluation of the latest LIG surface climate compilations that are available for evaluating LIG climate model experiments. We discuss in particular our new 127 ka time-slice in the context of existing LIG surface temperature time-slices. We also compare the 127 ka time slice with the ones published for the 125 and 130 ka time intervals and we discuss the potential and limits of a data-based time slice at 127 ka {{in the context of the}} upcoming coordinated modeling exercise. Finally we provide guidance on the use of the available LIG climate compilations for future model-data comparison exercises in the framework of the upcoming CMIP 6 /PMIP 4 127 ka experiments. We do not recommend the use of LIG peak warmth-centered syntheses. Instead we promote the use of the most recent syntheses that are based on coherent chronologies between paleoclimatic records and provide spatio-temporal reconstruction of the LIG climate. In particular, we recommend using our new 127 ka data-based time slice in model-data comparison studies with a focus on the high-latitude climate. E. C. is funded by the European Union's Seventh Framework Programme for research and innovation under the Marie Skłodowska-Curie grant agreement no 600207. B. L. O-B is supported by the U. S. National Science Foundation (NSF) sponsorship of NCAR. R. F. acknowledges the funding of the NSF Arctic System Science. E. W. W. is supported by the Royal Society. This is LSCE contribution no 6117...|$|R
40|$|A {{model of}} global warming with {{endogenous}} substitution of energy resources and multiple energy demands is developed. It suggests that, if historical rates of cost reduction {{in the production of}} solar energy are maintained, most of the world's coal will never be used. The world will move from oil and natural gas use to solar energy. Temperatures will rise by only about 1. 5 - 2. 0 degrees centigrade {{by the middle of the}} twenty-first century and then decline <b>to</b> <b>preindustrial</b> levels. These results are significantly lower than those predicted by the Intergovernmental Panel on Climate Change and suggest that the case for global warming may be seriously overstated. Copyright 1997 by the University of Chicago. ...|$|R
40|$|Anthropogenic {{emissions}} {{of greenhouse gases}} could lead to undesirable effects on oceans in coming centuries. Drawing on recommendations published by the German Advisory Council on Global Change, levels of unacceptable global marine change (so-called guardrails) are defined in terms of global mean temperature, sea level rise, and ocean acidification. A global-mean climate model [the Aggregated Carbon Cycle, Atmospheric Chemistry and Climate Model (ACC 2) ] is coupled with an economic module [taken from the Dynamic Integrated Climate-Economy Model (DICE) ] to conduct a cost-effectiveness analysis to derive CO 2 emission pathways that both minimize abatement costs and are compatible with these guardrails. Additionally, the. tolerable windows approach. is used to calculate a range of CO 2 emissions paths that obey the guardrails as well as a restriction on mitigation rate. Prospects of meeting the global mean temperature change guardrail (2 and 0. 2 degrees C per decade relative <b>to</b> <b>preindustrial)</b> depend strongly on assumed values for climate sensitivity: at climate sensitivities > 3 degrees C the guardrail cannot be attained under any CO 2 emissions reduction strategy without mitigation of non-CO 2 greenhouse gases. The ocean acidification guardrail (0. 2 unit pH decline relative <b>to</b> <b>preindustrial)</b> is less restrictive than the absolute temperature guardrail at climate sensitivities > 2. 5 degrees C but becomes more constraining at lower climate sensitivities. The sea level rise and rate of rise guardrails (1 m and 5 cm per decade) are substantially less stringent for ice sheet sensitivities derived in the Intergovernmental Panel on Climate Change (IPCC) Fourth Assessment Report, but they may already be committed to violation if ice sheet sensitivities consistent with semiempirical sea level rise projections are assumed...|$|R
40|$|Uncertainty in aerosol forcing {{of climate}} since the preindustrial era hampers efforts to {{quantify}} the sensitivity of global temperature to radiative perturbations caused by human activity. Because forcings are referenced <b>to</b> <b>preindustrial</b> conditions, {{a large part of}} the uncertainty will be reduced only by accurately defining pristine aerosol conditions before air pollution. We show that pristine conditions should still be observable on a few days per month in many regions of the Earth. However, pristine cloudy regions, which are of most importance for forcing uncertainty, occur almost entirely in the Southern Hemisphere. Reduction in uncertainty of predominantly Northern Hemisphere forcing may therefore have to rely on measurements from a different hemisphere, which will limit the extent to which uncertainties can be reduced...|$|R
40|$|We have {{analysed}} time-slice simulations from 17 global models, {{participating in}} the Atmospheric Chemistry and Climate Model Intercomparison Project (ACCMIP), to explore changes in present-day (2000) hydroxyl radical (OH) concentration and methane (CH 4) lifetime relative <b>to</b> <b>preindustrial</b> times (1850) and to 1980. A comparison of modeled and observation-derived methane and methyl chloroform lifetimes suggests that the present-day global multi-model mean OH concentration is overestimated by 5 to 10 % but is {{within the range of}} uncertainties. The models consistently simulate higher OH concentrations in the Northern Hemisphere (NH) compared with the Southern Hemisphere (SH) for the present-day (2000; inter-hemispheric ratios of 1. 13 to 1. 42), in contrast to observation-based approaches which generally indicate higher OH in the SH although uncertainties are large...|$|R
50|$|The Ned Ludd cycle {{begins with}} a song about the {{enclosure}} movement in Early Modern England, effectively a pastoral ode <b>to</b> <b>preindustrial</b> England, and then moves on {{to the plight of}} the workers who have been displaced by industrialization. The third song is an appeal to the mythical Ned Ludd to destroy the machines and lead the workers in a rebellion. The fourth and fifth songs deal with the Peterloo Massacre of 1819, in which the British cavalry charged into a peaceful crowd of protesters supporting a repeal of the Corn Laws. Neither the Enclosure Movement nor the Corn Laws were directly related to the Luddite Movement, but in the cycle these serve to explore the wider problems of common workers.|$|R
40|$|Aspirin is a non-steroidal {{anti-inflammatory}} drug {{with potential}} as antiplatelet for stroke prophylaxis. Several approaches of aspirin formulations in various dosage forms have been performed. Formulations of aspirin in conventional tablet dosage form often cause gastric irritation. Aspirin is rapidly absorbed in the upper gastrointestinal tract, especially the first small intestine. Therefore f ormulation of floating drug delivery system are designed to improve the bioavailability of aspirin. The floating system will retain the tablet in stomach, allowing sufficient absorption time for aspirin in stomach and upper intestine. Aim {{of this study was}} to determine relative bioavailability of aspirin floating tablets c <b>ompared</b> <b>to</b> the aspirin enteric coated t ablet s in rabbits with crossover design method. Serial blood samples were collected from rabbit ear marginal vein over a 10 -h period. Drug s concentration in plasma (aspirin and salisylic acid) w ere determined by HPLC with benzoic acid as internal standard. The results showed that the floating aspirin tablet has better bioavailability with shorter t max and more uniform of aspirin levels compared to enteric coated tablets, though the parameters AUC and Cp max both of those products were not significant (p> 0. 05). </p...|$|R
40|$|In general, the {{commuting}} literature associates {{the use of}} {{a private}} automobile, working in a low-wage job, or being a working mother with a shorter commute time. Th ere is growing eviden ce, however, that this genera l pattern does not hold for m inority women. This paper reports findings from a study that focuses on the journey to work of black women. The study is based on Public Use M icrodata Sa mples (PU MS) for m etropolitan D etroit. The analysis controls for automobile use, occupation, income, parental status, and workplace location. First, the findings show that over the years, as more black women have more acc ess to automobiles, there is reduced racial disparity in the duration of the journey to work. The study then examined (a) opposite direction commu ters and (b) res idents of D etroit central city. C <b>ompared</b> <b>to</b> black reverse commuters, the long commutes of suburban white women with central city work locations are less constrained. Multiple analysis of variance revealed that traveling to suburban destinations in the Detroit metropolitan area imposed more commuting time constraints on black service workers than on white counterparts...|$|R
40|$|This {{thesis is}} about the re onstru tion of the depth in a s ene from 2 D images. A amera is moved around an obje t, reating a sequen e of 2 D images. Features are tra ked through the images, where the {{movement}} is used for 3 D re onstru tion. Position, rotation and translation of the amera is known. Using feature dete tion, no laser or stru tured light has to be used. Three methods of feature dete tion are proposed and ompared, where one is hosen and used. These are orner dete tion, edge dete tion and opti al ow. Tests are arried out, where edge dete tion is hosen to be the method used. An edge tra king algorithm is implemented. This tra king algorithm tra ks edges through numerous images, whi h is essential for a good 3 D re onstru tion. A 3 D re onstru tion algorithm is implemented. This algorithm uses {{the movement of the}} edges <b>ompared</b> <b>to</b> the movement of the amera to estimate the 3 D position of the edges. This implementation is tested extensively. The limitations of the system is found and solution to those proposed...|$|R
