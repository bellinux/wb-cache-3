9|5911|Public
2500|$|An ESB {{mediation}} flow {{is one of}} the [...] component {{types in}} a Service Component Architecture (SCA). Like any SCA component, the program accesses a mediation flow through exports that it provides, and the mediation flow forwards messages to <b>other</b> <b>external</b> <b>services</b> via imports. Special kinds of imports and exports for JMS, called JMS bindings, enable developers to specify the binding configuration and write data handling code. The mediation flow consists of a series of mediation primitives that manipulate messages as they flow through the bus.|$|E
5000|$|All {{colleges have}} an {{appointed}} designated safeguarding lead who {{responsible for providing}} support to staff members who carry out safeguarding duties and who liaises closely with <b>other</b> <b>external</b> <b>services</b> ...|$|E
50|$|An ESB {{mediation}} flow {{is one of}} {{the component}} types in a Service Component Architecture (SCA). Like any SCA component, the program accesses a mediation flow through exports that it provides, and the mediation flow forwards messages to <b>other</b> <b>external</b> <b>services</b> via imports. Special kinds of imports and exports for JMS, called JMS bindings, enable developers to specify the binding configuration and write data handling code. The mediation flow consists of a series of mediation primitives that manipulate messages as they flow through the bus.|$|E
50|$|Field Service Organization (also {{known as}} FSO) is a {{subsidiary}} part of Ericsson. This service {{was launched in}} mid-2008 to simplify all processes more cost efficiently for Ericsson than any <b>other</b> <b>external</b> <b>service</b> provider available for services provided.|$|R
30|$|When {{it comes}} to the last point {{regarding}} extendibility, and thanks to its modular structures, SimStadt can be also extended with further modules and more complex workflows corresponding to new urban energy analyses, provided that the required data are available either in the input 3 D city model or can be retrieved and integrated from <b>other</b> <b>external</b> web <b>services.</b>|$|R
5000|$|When code under {{development}} {{relies on a}} database, a web <b>service,</b> or any <b>other</b> <b>external</b> process or <b>service,</b> enforcing a unit-testable separation is also an opportunity and a driving force to design more modular, more testable and more reusable code. Two steps are necessary: ...|$|R
40|$|The key {{goal of the}} NIR-VANA {{project is}} to develop an ICT-based layer that will {{facilitate}} {{the work of the}} innovation agents and will also promote a change of mentality of the SMEs. Some services will be provided online using a new Networking and Innovation Room (NIR) where the innovation agents and the SMEs interact to facilitate partnerships. These services will allow direct and ongoing support provided by the innovation agents to the SMEs, links to <b>other</b> <b>external</b> <b>services</b> (orchestration logic), increased efficiency for the management and monitoring of the collaboration, and services aimed at encouraging SME’s involvement. One key aspect of these services is, that they provide a process for building new partnerships and collaborating. This process should greatly benefit SMEs as well as innovation advisors and agencies. This Project has received funding from the European Union’s Horizon 2020 research and innovation program under the grant agreement 68178...|$|E
40|$|Since 2005 {{companies}} with equity instruments traded on regulated {{markets in the}} European Economic Area have prepared their financial reports in accordance with accounting standards issued by the IASB. A survey conducted in 2007 indicated {{that most of the}} EU companies that changed from local to IFRS rules incurred additional costs in connection with the transition. Also, companies expected additional future costs from using IFRS. Although the main part of these stemmed from the companies’ internal work on IFRS statements, additional costs for external auditing and <b>other</b> <b>external</b> <b>services</b> were identified as substantial but independent of company size. We analyze whether the application of IFRS standards has increased Danish companies’ cost of auditing. Our study is based on a sample of financial reports from large Danish companies from 2002 to 2008. Controlling for a number of general audit fee driving aspects, we find that overall, audit fees have not increased significantly for companies using IFRS rules. However, when combining IFRS with company size and complexity, we find that large and complex companies using IFRS pay a heavy audit fee premium compared to small and less complex companies that also use IFRS. Our results for nonaudit fees are less conclusive. Audit fees; non audit fees; IFRS; transition of accounting regime; empirical study...|$|E
40|$|Abstract. This {{demonstration}} {{describes the}} results of {{the first year of the}} Eu-DML project, an initiative building a new multilingual service for searching and browsing the content of existing European portals of mathematical content. We demonstrate the first versions and proofs of concept of the EuDML portal, its contents ’ aggregator, and a toolset for added value. AboutEuDML. — EuDML, theEuropean DigitalMathematicsLibrary(www. eudml. eu), is a project that will build a new multilingual service for searching and browsing the con-tent of existing European mathematical portals [5, 1]. It will be based on a rich metadata repository, aggregating metadata and full text of heterogeneous and multilingual collec-tions of digitised and born digital content (articles, books, theses, etc.). The service will merge and augment the information about each document from each collection, and also will match documents and references across the entire combined library. Entities such as authors, bibliographic references and mathematical concepts will be singled out and linked to matching items in the collections; similar mechanisms will be provided as public web-services so that end-users or <b>other</b> <b>external</b> <b>services</b> will be able to discover and link to EuDML items. This way, EuDML will be a new major international player in the emerging landscape of scientific information discovery services, enabled for reuse in new added value chains. EuDML is partially funded by the Competitiveness and In...|$|E
50|$|The Men’s Health Foundation {{will create}} and promote service {{delivery}} models that facilitate and expand linkage to care, social service and <b>other</b> internal or <b>external</b> <b>service</b> providers to increase retention in care, improve medical outcomesand provide comprehensive support services for men, especially young GBTQ men of color, regardless of HIV status.|$|R
50|$|The first medical {{facility}} in Sipitang is a dispensary, {{established in the}} 1970s. This site was originally a rest house during the British colonial days. It provided limited medical <b>services,</b> among <b>others</b> are <b>external</b> patient <b>service,</b> maternal and infant care clinic, and tuberculosis and malaria control centre.|$|R
40|$|Abstract. Service-oriented {{computing}} (SOC) paradigm {{promotes the}} idea of assembling application components into a network of loosely coupled services. Web services are the most promising SOC-based technology. A BPEL process definition represents a composite service that encapsulates some complex business logic including the invocation to <b>other</b> (<b>external)</b> web <b>services.</b> The complexity of a BPEL process together with the invocation of <b>external</b> <b>services</b> subject to network and computer failures requires countermeasures to tolerate this kind of failures. In this paper we present an overview of FT-BPEL, a fault-tolerant implementation of BPEL that copes both with failures of the machine running the BPEL process and network failures in a transparent way, that is, after a failure the system is able to resume the BPEL process consistently. ...|$|R
40|$|This study set out {{to examine}} the {{decision-making}} process in care proceedings brought before the Children’s Court involving allegations of domestic violence as a child maltreatment concern in accordance with NSW Children and Young Persons (Care and Protection) Act, 1998. The growth in understanding of domestic violence as a specific category of child maltreatment has seen increased attention and involvement of an array of professionals in the child protection field including statutory caseworkers, solicitors, and <b>other</b> <b>external</b> <b>services</b> working with children and families. Court decisions encompass risk assessment and immediate and long term safety planning. They also involve professionals navigating both shared and individual language {{in the process of}} assessment. What constitutes the specific risk of domestic violence, and decision-making in cases involving domestic violence is often contested in care and protection matters. This study utilised qualitative methodology, specifically applying a case study approach involving both a prospective and retrospective review of cases. The retrospective review followed a series of cases from the commencement of the court case, to the finalisation of orders. A parallel retrospective review of archive cases and court files from Community Services was undertaken. Central to this study was examination of the role of professional stakeholders, their assessments and contribution to court decision-making. The findings in this study highlight that much professional decision-making occurs prior to proceedings. The decisions made in all reviewed matters were found {{to be the result of}} the coalescence of professional knowledge, interpretation and interagency collaboration. Professionals developed discourses of risk, compliance, insight and safety in their assessments. Such assessments formed a narrative of domestic violence characterized by an emphasis on summarising patterns within key incidents, evaluating the parent’s ongoing relationship dynamics and parenting capacity. Significantly, in this narrative, an inability to separate from a violent partner was indicative of a lack of maternal protectiveness. Additionally, childrens’ age and gender influenced the assessment of the impact of violence on individual children. These interpretations informed the court’s evaluation of evidence of domestic violence and its impact on children as well as the proposed interventions and care plans necessary to ensure children’s safet...|$|E
40|$|AbstractThe {{dissemination}} of online information services into higher education {{has led to}} constant changes in students’ learning behaviour. Nowadays they use services like Google and Wikipedia most often not only during free time but also for studying. At the same time, traditional information media such as the textbook or the printed hand-out from the teacher still form basic pillars in their learning environment. To measure the whole variety of media, that are used for learning, an international long term Media Survey in Higher Education (“MESHED”) {{was set up by}} the authors. It aims to get detailed knowledge about how students use media for study from an international and a long term perspective. This knowledge shall be used to develop recommendations for university media strategy, make prognoses for future media trends in higher education and to figure out influences of external dimensions on the media usage. Beginning with a first survey carried out at Karlsruhe Institute of Technology, Germany in 2009, currently (October 2013) a total of 30 surveys in ten countries were, or currently are carried out. The survey uses a fully standardized questionnaire that measures the acceptance of 48 media services, such as Google search, library catalogues, printed books, e-books, printed journals, e-journals, e-learning-services, virtual class, Wikipedia, open educational resources, bibliographic software and more. It also measures adjacent areas, such as the learning behaviour, study success, media usage during free time, usage of IT hardware, education biography and sociodemographic factors. This paper focusses on the results of a survey that was conducted at the University of Barcelona (UB) between March and June 2012. There, about 1, 000 samples were collected. The data showed an intense use of a broad variety of media among UB students. Though, not all media services were accepted equally: while especially some university external services, such as Google web search or Wikipedia were used by almost every student, other media, e. g. virtual learning services were used on a very low level. An exploration of hidden structures of media usage behaviour, using factor and cluster analysis revealed that especially text and text related media (books, eBooks, library catalogues) seem to {{have a positive effect on}} the learning success. A comparison of the Barcelona sample with the data of other countries showed some communalities, e. g. a high usage of Google and <b>other</b> <b>external</b> <b>services.</b> But there were also hints to cultural differences, such as an explicit maverick or non-social learning behaviour of Spanish students. This general tendency also appears in the media sector where they tend to use information media and, compared to students from other countries, use less social media. An additional survey in Canada/Ontario has been conducted in January-February 2013, and at the moment the third survey at the KIT is running. Especially some of the results from Canada show specific aspects, that might be interesting to be compared to the Spanish and German findings...|$|E
5000|$|Business (or enterprise) mashups define {{applications}} that combine their own resources, application and data, with <b>other</b> <b>external</b> Web <b>services.</b> They focus data {{into a single}} presentation and allow for collaborative action among businesses and developers. This works well for an agile development project, which requires collaboration between the developers and customer (or customer proxy, typically a product manager) for defining and implementing the business requirements. Enterprise mashups are secure, visually rich Web {{applications that}} expose actionable information from diverse internal and external information sources.|$|R
40|$|This is a {{presentation}} for Computer Applications and Quantitative Methods in Archaeology 2016 (Oslo, Norway). It discusses {{the implementation of}} Linked Open Data methodologies to integrate {{various aspects of the}} American Numismatic Society's holdings [...] coins, hoard and typology databases, digital archives, archival authorities, and digital library materials [...] to create a seamless portal for numismatic research. Through Nomisma. org and <b>other</b> <b>external</b> LOD <b>services,</b> these materials may be made available to the broader cultural heritage linked data cloud [...] in Pelagios, Social Networks and Archival Context, etc...|$|R
40|$|This paper {{describes}} the vehicle positioning system MAP (Map-Aided Positioning) developed by NIRA Dynamics AB. MAP uses sensor fusion to combine relative position {{information from the}} wheel speed sensors with digital map information, and is capable of computing an accurate estimate of a vehicle’s absolute position without support from GPS or <b>other</b> <b>external</b> positioning <b>service.</b> MAP can also be combined with GPS, in which case a very robust and accurate positioning system is obtained. MAP is available as a software module suitable for integration in a PDA or similar hardware platform. 1...|$|R
40|$|DIGMAP is {{a digital}} library {{specialized}} in searching and browsing services for old maps and related resources. The service reuses metadata from national libraries and other relevant third party metadata sources, providing added value services by aggregating {{all the data}} in comprehensive collections, browsing indexes and search functions. The services are based {{in a set of}} specialized tools, compris-ing namely a catalogue, an image’s feature indexer, a metadata repository, a geographic gazetteer and a geo-parser. The extraction of relevant visual features from images of digitized maps is another focus of the project. The architecture and the technology give it also the ability to easily interoperate with <b>other</b> complementary <b>external</b> <b>services...</b>|$|R
5000|$|Cougaar agent {{architecture}} {{is an open}} source, which includes infrastructure and core services. Agents are autonomous software entities that communicate with <b>other</b> agents or <b>external</b> <b>services</b> for a specific domain functionality. Computing agents {{are based on a}} programming methodology that facilitates direct decomposition of complex tasks.The agents manage application behavior and environment handles systemic adaptation. The agents and the environment can develop, test and configure independently, but run together.Cougaar agent abstraction includes several integrated advanced services, such as: ...|$|R
40|$|This paper {{describes}} {{the development of}} computational support tools for practically successful engineering techniques. The paper reviews the requirements for manual Quality Function Deployment techniques, presents them, and discusses their limitations. It argues that computational support tools can alleviate most of these limitations and that a graph-based information representation for such techniques is an excellent choice for supporting both QFD techniques and their integration with <b>other</b> <b>external</b> CAD-related computational <b>services.</b> The paper presents an architecture for a computational QFD (CQFD) tool based on the graph-based modeling environment n-dim. It shows how this architecture supports most of the requirements for QFD techniques, {{in addition to providing}} many additional functionalities, and briefly illustrates how the CQFD tool will be used. Keywords Quality Function Deployment, TQM, design practice, 7 management tools, graph representation, n-dim, collaborative design, d [...] ...|$|R
40|$|Network anonymization {{solutions}} {{were mostly}} designed with a single-user usage model in mind. Indeed, {{the usage of}} such solutions in collaboration scenarios, as {{this is the case}} for social networking, could lead to network as well as application level linkability (i. e. re-identification of the endusers in these networks). Furthermore, the usage of network anonymization is not applicable in some business settings. In this paper, we present a continuation of previous work that solved network anonymity for collaborative scenarios by avoiding potential linkability. By considering end-users' and business' needs, we present a multilaterally secure solution for providing communication anonymity in social networking. The proposed solution leverages both; network anonymity solutions as well as anonymous credential systems to fulfill intended social interaction goals within the EU FP 7 di. me project, offering nodes in a decentralized network and connecting with distinct identities to <b>other</b> users or <b>external</b> <b>services...</b>|$|R
40|$|Software-Defined Networking (SDN) {{has evolved}} {{as a new}} {{networking}} paradigm to solve many of current obstacles and limitations in communication networks. The SDN technology {{is going to be}} implemented in multi-tenant environments like data centers where several customers, which are called “tenants”, share network resources. In fact, the integration of SDN allows tenants in a shared network to have higher levels of control over available resources. While this approach has several advantages, the isolation between the tenants of a shared network becomes a vital factor which has not been discussed clearly so far. This thesis discusses multi-tenancy and explains current isolation approaches in a multi-tenant SDN. For increasing isolation between tenants, this thesis proposes a scalable solution that provides traffic isolation, address space isolation, control isolation and performance isolation. In the new system architecture, tenants are not limited to their own networks and they are able to make interaction with each <b>other</b> and <b>external</b> resources. Indeed, while tenants are isolated from each other, they are allowed to access special services offered by <b>other</b> tenants or <b>external</b> <b>services</b> outside of a shared network. The evaluation of the prototype proves that the new architecture provides a high level of isolation in a multi-tenant SDN and it is scalable enough to be implemented in large networks with millions of tenants...|$|R
40|$|An {{accurate}} {{simulation of}} the trigger response {{is necessary for}} high quality data analyses. This poses a challenge. For event generation and simulated data reconstruction the latest software is {{used to be in}} best agreement with the reconstructed data. Contrary the trigger response simulation needs to be in agreement with when the data was taken. The approach we follow is to use trigger software and conditions data that matches the simulated data-taking period potentially dating many years back. Having a strategy for running old software in a modern environment thus becomes essential when data simulated for past years start to present a sizable fraction of the total. examined the requirements and possibilities for such a simulation scheme within and beyond the existing ATLAS software framework and successfully implemented a proof-of-concept simulation chain. One of greatest challenges has been that of bridging old and new file formats, as most of the file formats and data representations used by ATLAS are changing with time. Over the time periods envisaged data format incompatibilities are likely to emerge in databases and <b>other</b> <b>external</b> storage <b>services</b> as well. Software availability is an issue. The support for the underlying operating system might stop. In this talk we will present the encountered problems and developed solutions, and will discuss proposals for future development. These ideas will have reach beyond the retrospective trigger simulation scheme at ATLAS as they are applicable in other areas of data preservation...|$|R
40|$|A new Scheme for ATLAS Trigger Simulation using Legacy Code {{accurate}} {{simulation of}} the trigger response {{is necessary for}} high quality data analyses. This poses a challenge. For event generation and simulated data reconstruction the latest software is {{used to be in}} best agreement with the reconstructed data. Contrary the trigger response simulation needs to be in agreement with when the data was taken. The approach we follow is to use trigger software and conditions data that matches the simulated data-taking period potentially dating many years back. Having a strategy for running old software in a modern environment thus becomes essential when data simulated for past years start to present a sizable fraction of the total. examined the requirements and possibilities for such a simulation scheme within and beyond the existing ATLAS software framework and successfully implemented a proof-of-concept simulation chain. One of the greatest challenges has been that of bridging old and new file formats, as most of the file formats and data representations used by ATLAS are changing with time. Over the time periods envisaged data format incompatibilities are likely to emerge in databases and <b>other</b> <b>external</b> storage <b>services</b> as well. Software availability is an issue. The support for the underlying operating system might stop. In this talk we will present the encountered problems and developed solutions, and will discuss proposals for future development. These ideas will have reach beyond the retrospective trigger simulation scheme at ATLAS as they are applicable in other areas of data preservation...|$|R
50|$|Generally Circuit Breaker {{can be used}} {{to check}} the {{availability}} of an <b>external</b> <b>service.</b> An <b>external</b> <b>service</b> can be a database server or a web service used by the application.|$|R
40|$|Physics {{analyses}} at the LHC which {{search for}} rare physics processes or measure Standard Model parameters with high precision require accurate simulations of the detector response and the event selection processes. The accurate simulation of the trigger response {{is crucial for}} determination of overall selection efficiencies and signal sensitivities. For the generation and the reconstruction of simulated event data, generally the most recent software releases are used to ensure the best agreement between simulated data and real data. For the simulation of the trigger selection process, however, the same software release with which real data were taken should be ideally used. This requires potentially running with software dating many years back, the so-called legacy software. Therefore having a strategy for running legacy software in a modern environment becomes essential when data simulated for past years start to present a sizeable fraction of the total. The requirements and possibilities for such a simulation scheme within the ATLAS software framework were examined and a proof-of-concept simulation chain has been successfully implemented. One {{of the greatest challenges}} was the choice of a data format which promises long term compatibility with old and new software releases. Over the time periods envisaged, data format incompatibilities are also likely to emerge in databases and <b>other</b> <b>external</b> support <b>services.</b> Software availability may become an issue, when e. g. the support for the underlying operating system might stop. The encountered problems and developed solutions will be presented, and proposals for future development will be discussed. Some ideas reach beyond the retrospective trigger simulation scheme in ATLAS as they also touch more generally aspects of data preservation...|$|R
5000|$|RTBF International <b>external</b> <b>service</b> of Belgian francophone radio ...|$|R
5000|$|Outsourcing {{relationship}} management linking to <b>external</b> <b>service</b> providers ...|$|R
40|$|Background: The Investment Framework {{for a more}} {{effective}} HIV response has become integral to discussions {{on how best to}} respond to the HIV epidemic. The Framework calls for greater synergy and attention to factors that serve as ‘critical enablers’ and optimise HIV programmes. In this paper we argue for recognition of informal and indigenous community groups as ‘critical enablers’ of the HIV response. Methods: This qualitative study was conducted in Matobo district of the Matabeleland South province in Zimbabwe. It draws on 19 individual in-depth interviews and 9 focus group discussions conducted by local researchers in September and October 2011. Data was thematically analysed. Results: Four core themes highlight the possibilities and limitations of community groups in the HIV response: (i) Membership of indigenous community groups and group-based dialogue were found to encourage group members to engage with HIV prevention, mitigation and care efforts; (ii) local networks and partnerships between groups and NGOs were said {{to play an important role}} in accessing much needed resources to aid indigenous coping with AIDS; (iii) community strengths and resources were recognised and drawn upon in the community group response; (iv) frequent droughts, poverty and stigma served as obstacles to an effective HIV response. Conclusions: In this context, social groups, although to varying degrees and in direct or indirect ways, play a key role in the HIV response. This suggest that community groups and networks can indeed act as ‘critical enablers’ to the HIV response, and that efforts need to be made to facilitate the contributions of already existing indigenous responses. Local community groups are developing local and collective solutions to structural problems, often independently of external NGO or health service efforts, and begging for synergy and collaboration between local community groups and networks, the health <b>services</b> and <b>other</b> <b>external</b> HIV <b>service</b> delivery sectors. </p...|$|R
5000|$|Fulfillment of <b>external</b> <b>service</b> {{agreements}} (Service Level Agreement, SLA) ...|$|R
5000|$|Swissinfo.ch: handles <b>external</b> <b>services</b> and the {{web portal}} swissinfo.ch ...|$|R
5000|$|... 3 are {{international}} news and current affairs <b>services</b> (<b>external</b> <b>services)</b> ...|$|R
40|$|In {{addition}} {{to the rise of}} digital games in all their forms, users often engages in existing services or even develops new <b>external</b> <b>services.</b> These <b>external</b> <b>services</b> often comes in forms of forums, mobile applications developed with a certain function in focus and applications dedicated to provide users with certain information. These <b>external</b> <b>services</b> provides the user with a different medium then the game itself, and they therefore work as a complement to the game. This study examines if the use of <b>external</b> <b>services</b> for games is related to lack of information/functions in the game. The study focuses on the case of the recent mobile game Pokémon GO and the external environment surrounding the game. As an example the study focused on the game Pokémon GO and did a case study about this game to try the thesis. ...|$|R
40|$|Abstract. Service {{oriented}} computing and {{web service}} technology provide {{the means to}} structure an organisation’s internal IT resources into a highly integrated network of services. In e-business and business process integration the internal services are interconnected with <b>other,</b> <b>external</b> organisations’ resources to form virtual organisations. This move from using <b>services</b> internally to <b>external</b> use puts new non-functional requirements on the service implementation. Without any supporting technologies, meeting these new requirements can result in re-writing or changing {{a large part of}} the service implementation. In this paper we argue that aspect oriented programming is an important technique that can be used to facilitate the implementation of the new requirements that arises when moving from internal to <b>external</b> <b>services.</b> The suggested solution is illustrated by an example where quality of service metrics is implemented by using aspect oriented programming...|$|R
40|$|Competitive markets force {{companies}} to form virtual enterprises by outsourcing activities to <b>external</b> <b>service</b> providers. The workflow concept {{has been very}} successful in streamlining business processes by automating the coordination of activities, but {{has so far been}} limited to the use within single organizations. To address the problems of cross-organizational workflows we use a service-oriented workflow model. Within this approach, we present a technique how to derive a model of the <b>external</b> <b>services,</b> based on continuous-time Markov chains, by analyzing their externally observable behavior. This allows to assess the quality of <b>external</b> <b>services,</b> without compromising the autonomy of the service providers...|$|R
5000|$|Kwiecinski Wins International Rostrum of Composers,Polish Radio <b>External</b> <b>Service,</b> Polskie Radio ...|$|R
