14|12|Public
5000|$|... where [...] is {{the maximum}} length of any sample [...] An <b>Occam</b> <b>algorithm</b> is called {{efficient}} if it runs in time polynomial in , , and [...] We say a concept class [...] is Occam learnable {{with respect to}} a hypothesis class [...] if there exists an efficient <b>Occam</b> <b>algorithm</b> for [...] using [...]|$|E
50|$|While {{the above}} theorems show that Occam {{learning}} {{is sufficient for}} PAC learning, it doesn't say anything about necessity. Board and Pitt show that, {{for a wide variety}} of concept classes, Occam learning is in fact necessary for PAC learning. They proved that for any concept class that is polynomially closed under exception lists, PAC learnability implies the existence of an <b>Occam</b> <b>algorithm</b> for that concept class. Concept classes that are polynomially closed under exception lists include Boolean formulas, circuits, deterministic finite automata, decision-lists, decision-trees, and other geometrically-defined concept classes.|$|E
40|$|AbstractThe distribution-independent {{model of}} concept {{learning}} from examples (“PAC-learning”) due to Valiant (1984) is investigated. It {{has been shown that}} the existence of an <b>Occam</b> <b>algorithm</b> for a class of concepts is a sufficient condition for the PAC-learnability of that class (Blumer 1987, 1989). (An <b>Occam</b> <b>algorithm</b> is a randomized polynomial-time algorithm that, when given as input a sample of strings of some unknown concept to be learned, outputs a small description of a concept that is consistent with the sample.) In this paper it is shown for many natural concept classes that the PAC-learnability of the class implies the existence of an <b>Occam</b> <b>algorithm</b> for the class. More generally, the property of closure under exception lists is defined, and it is shown that for any concept class with this property, PAC-learnability of the class is equivalent to the existence of an <b>Occam</b> <b>algorithm</b> for the class. An interpretation of these results is that for many classes, PAC-learnability is equivalent to data compression...|$|E
50|$|<b>Occam</b> <b>algorithms</b> {{have also}} been shown to be {{successful}} for PAC learning in the presence of errors, probabilistic concepts, function learning and Markovian non-independent examples.|$|R
40|$|Several {{versions}} of the magnetotelluric inversion for layered anisotropic conductors are presented. Basics of the direct problem solution and evaluation of the parametric sensitivities for anisotropic layered models are sum-marized. Standard linearized <b>Occam</b> <b>algorithms</b> are tested with various regularization strategies, both quadratic and non-smooth, and numerical performance of the inverse procedures is discussed. An example of a global prob-abilistic inference by the Markov chain Monte Carlo approach is presented, aiming at appraising the equivalencies and ambiguities characteristic for the inversion in anisotropic structures. ...|$|R
40|$|Abstract. We formalize a {{model for}} {{supervised}} learning of action strategies in dynamic stochastic domains and show that PAC-learning results on <b>Occam</b> <b>algorithms</b> hold in this model as well. We then identify a class of rule-based action strategies for which polynomial time learning is possible. The representation of strategies is a generalization of decision lists; strategies include rules with existentially quantified conditions, simple recursive predicates, and small internal state, but are syntactically restricted. We also study the learnability of hierarchically composed strategies where a subroutine already acquired {{can be used as}} a basic action in a higher level strategy. We prove some positive results in this setting, but also show that in some cases the hierarchical learning problem is computationally hard...|$|R
3000|$|... 1 D <b>Occam</b> <b>algorithm</b> is {{a typical}} 1 D {{inversion}} method, in which classical layered model is obtained. For better visualization, such layered models are usually presented after being interpolated in cross-sectional manner. <b>Occam</b> <b>algorithm</b> gives smooth models with sharp boundaries between geoelectrical layers and leads to a simple model containing the essential properties of all possible models fitting the field data (Constable et al. 1987). A large number of geoelectrical models could match the observed data, {{some of which may}} be highly complex. Resistivities of layers vary between field and calculated curves.|$|E
30|$|Data {{interpretation}} {{was based}} on 1 D inversion <b>Occam</b> <b>algorithm</b> using WinGLink software. The results of inversion algorithm by Occam have been interpolated and are shown as resistivity section. Distribution of resistivity is presented for two types of models: shallow up to 1000  m b.s.l. and deep up to 10  km b.s.l.|$|E
40|$|We {{introduce}} {{the notion of}} "partial Occam algorithm". A partial <b>Occam</b> <b>algorithm</b> produces a succinct hypothesis that is partially consistent with given examples, where the proportion of consistent examples {{is a bit more}} than half. By using this new notion, we propose one approach for obtaining a PAC learning algorithm. First, as shown in this paper, a partial <b>Occam</b> <b>algorithm</b> is equivalent to a weak PAC learning algorithm. Then by using boosting techniques of Schapire or Freund, we can obtain an ordinary PAC learning algorithm from this weak PAC learning algorithm. We demonstrate some examples that some improvement is possible by this approach. First we obtain a new (non-proper) PAC learning algorithm for k-DNF, which has similar sample complexity as Littlestone's Winnow, but produces hypothesis of size polynomial in d and log k for a k-DNF target with n variables and d terms (Cf. The hypothesis size of Winnow is O(n k)). Next we show that 1 decision lists of length d with n variable [...] ...|$|E
40|$|Abstract. In {{order to}} improve the {{efficiency}} of magnetotelluric <b>Occam</b> inversion <b>algorithm</b> (MT <b>Occam),</b> a parallel <b>algorithm</b> is implemented on a hybrid MPI/OpenMP parallel programming model to increase its convergence speed and to decrease the operation time. MT Occam is partitioned to map the task on the parallel model. The parallel algorithm implements the coarse-grained parallelism between computation nodes and fine-grained parallelism between cores within each node. By analyzing the data dependency, the computing tasks are accurately partitioned so as to reduce transmission time. The experimental results show that {{with the increase of}} model scale, higher speedup can be obtained. The high efficiency of the parallel partitioning strategy of the model can improve the scalability of the parallel algorithm...|$|R
40|$|We formalize a {{model for}} {{supervised}} learning of action strategies in dynamic stochastic domains and show that PAC-learning results on <b>Occam</b> <b>algorithms</b> hold in this model as well. We then identify a class of rule based action strategies for which polynomial time learning is possible. The representation of strategies is generalization of decision lists; strategies include rules with existentially quantified conditions, simple recursive predicates, and small internal state, but are syntactically restricted. We also study the learnability of hierarchically composed strategies where a subroutine already acquired {{can be used as}} a basic action in a higher level strategy. We prove some positive results in this setting, but also show that in some cases the hierarchical learning problem is computationally hard. 1 Introduction We formalize {{a model for}} supervised learning of action strategies in dynamic stochastic domains, and study the learnability of strategies represented by rule based systems [...] ...|$|R
40|$|Abstract Given a {{disjunctive}} {{normal form}} (DNF) expression ϕ and a set A of vectors satisfying the expression, called the set of exceptions, {{we would like to}} update ϕ to get a new DNF which is false on A, and otherwise is equivalent to ϕ. Is there an algorithm with running time polynomial in the number of variables, the size of the original formula and the number of exceptions, which produces an updated formula of size bounded by a certain type of function of the same parameters? The problem is related to <b>Occam</b> <b>algorithms</b> in computational learning theory. We give an efficient updating algorithm, which shows that the previously known best upper bound for the size of the updated expression is not optimal in order of magnitude. We then present a lower bound for the size of the updated formula in terms of the parameters, which is the first known lower bound for this problem. We also consider the special case (studied previously in the complexity theory of {{disjunctive normal form}}s) where the initial formula is identically true, and give efficient updating algorithms, providing new upper bounds for the size of the updated expression. 1...|$|R
40|$|We {{consider}} {{the problem of}} learning {{in the presence of}} irrelevant attributes in Valiant's PAC model [V 84]. In the PAC model, the goal of the learner is to produce an approximately correct hypothesis from random sample data. If the number of relevant attributes in the target function is small, it may be desirable to produce a hypothesis that also depends on {{only a small number of}} variables. Haussler [H 88] previously considered the problem of learning monomials of a small number of variables. He showed that the greedy set cover approximation algorithm can be used as a polynomial-time <b>Occam</b> <b>algorithm</b> for learning monomials on r of n variables. It outputs a monomial on r(ln q + 1) variables, where q is the number of negative examples in the sample. We extend this result by showing that there is a polynomial-time <b>Occam</b> <b>algorithm</b> for learning k-term DNF formulas depending on r of n variables that outputs a DNF formula depending on O(r k log k q) variables, where q is the number of negati [...] ...|$|E
40|$|Geomagnetically Induced Currents (GIC) which flow in {{technological}} {{systems such}} as power transmission grids, are {{a consequence of the}} geoelectric field induced at the surface of the Earth during geomagnetic storms. We use an electrical model of the power network, measured GIC data and geomagnetic data from Eskdalemuir observatory to estimate the MT parameters apparent resistivity and phase. The long period MT responses are generally smooth and stable over a period range which extends from about 200 - 40, 000 s. We invert the apparent resistivity and phase for a smooth 1 D resistivity model using an <b>Occam</b> <b>algorithm...</b>|$|E
40|$|Occam's Razor states that, {{all other}} things being equal, the simpler of two {{possible}} hypotheses is to be preferred. A quantified version of Occam's Razor has been proven for the PAC model of learning, giving sample-complexity bounds for learning using what Blumer et al. call an <b>Occam</b> <b>algorithm</b> [1]. We prove an analog of this result for Haussler's more general learning model, which encompasses learning in stochastic situations, learning real-valued functions, etc. 1. Introduction Work in machine learning often makes use of the Occam's Razor principle: given two explanations of the data, {{all other things}} being equal, the simpler of the two is preferable. Occam's Razor can be applied once we have {{a measure of the}} complexity of a hypothesis. Such a measure is obtained by choosing some means of representing hypotheses, and defining the complexity of a hypothesis in terms of the size of its smallest representation. Blumer et al. [1] have formalized this intuition for a restricted model of [...] ...|$|E
40|$|In this paper, {{we study}} the {{possibility}} of Occam’s razors for a widely studied class of Boolean Formulae: Disjunctive Normal Forms (DNF). An Occam’s razor is an algorithm which compresses the knowledge of observations (examples) in small formulae. We prove that approximating the minimally consistent DNF formula, and a generalization of graph colorability, is very hard. Our proof technique is such that the stronger the complexity hypothesis used, the larger the inapproximability ratio obtained. Our ratio is {{among the first to}} integrate the three parameters of Occam’s razors: the number of examples, the number of description attributes {{and the size of the}} target formula labelling the examples. Theoretically speaking, our result rules out the existence of efficient deterministic <b>Occam’s</b> razor <b>algorithms</b> for DNF. Practically speaking, it puts a large worst-case lower bound on the formulae’s sizes found by learning systems proceeding by rule searching...|$|R
40|$|In this paper, {{we study}} the {{existence}} of Occam's razors for a widely studied class of Boolean Formulae : Disjunctive Normal Forms (DNF). An Occam's razor is an algorithm which compresses the knowledge of observations (examples) in small formulae. We prove that approximating the minimally consistent DNF formula, and a generalization of graph colorability, is very hard. Other results on approximating Boolean formulae (and classical graph coloring) are negligible compared to ours. Our proof technique is such that the stronger the complexity hypothesis used, the larger the inapproximability ratio obtained. Our ratio is {{among the first to}} integrate the three parameters of Occam's razors : the number of examples, the number of description attributes {{and the size of the}} target formula labelling the examples. Theoretically speaking, our result rules out {{the existence of}} efficient deterministic <b>Occam's</b> razor <b>algorithms</b> for DNF. Practically speaking, it puts a large lower bound on the formulae's [...] ...|$|R
40|$|Production {{of methane}} from thick, {{extensive}} coal {{beds in the}} Powder River Basin of Wyoming has created water management issues. Since development began in 1997, more than 650 billion liters of water have been produced from approximately 22, 000 wells. Infiltration impoundments are used widely to dispose of by-product water from coal bed natural gas (CBNG) production, but their hydrogeologic effects are poorly understood. Helicopter electromagnetic surveys (HEM) were completed in July 2003 and July 2004 to characterize the hydrogeology of an alluvial aquifer along the Powder River. The aquifer is receiving CBNG produced water discharge from infiltration impoundments. HEM data were subjected to <b>Occam's</b> inversion <b>algorithms</b> to determine the aquifer bulk conductivity, which was then correlated towater salinity using site-specific sampling results. The HEM data provided high-resolution images of salinity levels in the aquifer, a result not attainable using traditional sampling methods. Interpretation of these images reveals clearly the produced water influence on aquifer water quality. Potential shortfalls to this method occur {{where there is no}} significant contrast in aquifer salinity and infiltrating produced water salinity and where there might be significant changes in aquifer lithology. Despite these limitations, airborne geophysical methods can provide a broadscale (watershed-scale) tool to evaluate CBNG water disposal, especially in areas where field-based investigations are logistically prohibitive. This research has implications for design and location strategies of future CBNG water surface disposal facilities within the Powder River Basin. © 2008 2008 Society of ExplorationGeophysicists. All rights reserved...|$|R
40|$|Introduction. In [4] an <b>Occam</b> <b>algorithm</b> ([1]) was {{introduced}} for PAC learning {{certain kind of}} decision lists from classified examples. Such decision lists, or hierarchical rules as we call them, are of the form shown in Fig. 1. The {{purpose of the present}} paper is to discuss the practical implementation of the algorithm, to present a linguistic application (hyphenation of Finnish), and compare the learning result with an earlier experiment in which Angluin's k-reversible automata were used. if x 2 C 1 or x 2 C 2 or : : : or x 2 Cn then oe 1 else if x 2 Cn+ 1 or x 2 Cn+ 2 or : : : or x 2 Cn+m then oe 2 : : : else if x 2 Cn+m+:::+ 1 or x 2 Cn+m+:::+ 2 or : : : or x 2 Cp then oe k else !default? oe k+ 1 Fig. 1. Hierarchical rule of depth k. The rule in Fig. 1 has k levels. Each level contains an if-statement that tests whether or not the instance x to be classified belongs to the union of some basic concepts C i and if so, then gives a classification oe j 2 f+; for x. There are k s...|$|E
40|$|AbstractWe {{study the}} {{predictability}} of geometric concepts, in particular those defined by boolean combinations of simple geometric objects. First, we give a negative results, {{showing that the}} problem of predicting the class of convex polytopes encoded by listing their vertices is prediction complete for P. Thus, an efficient solution to this prediction problem implies the existence of efficient solutions to all prediction problems whose associated evaluation problems are in P. Assuming the existence of a one-way function that is hard on iterates, there are such prediction problems which do not admit efficient solutions. Thus we show under minimal cryptographic assumptions that the class of convex polytopes encoded by listing their vertices is not predictable. As a side effect, we show that determining membership in the convex hull of a given set of points is complete for P with respect to log space reductions. Next, we establish the predictability of the class consisting of unions of a fixed number of flats by reducing its prediction problem to that of the class of flats, which has previously been shown to be predictable. Finally, we give an <b>Occam</b> <b>algorithm</b> for predicting fixed finite unions of boxes. Both constructive results for flats and boxes hold if the dimension is variable...|$|E
40|$|International audienceTwenty-six {{lava flows}} {{spanning}} the last million years were sampled in La Guadeloupe, French West Indies. Because {{of the lack}} of continuous volcano-stratigraphic sections in La Guadeloupe, dating is necessary in order to describe the temporal evolution of the geomagnetic field in this time interval. New K/Ar ages ranging from 50 ka to I Ma have been obtained on andesires using the Cassignol-Gillot technique at the Universitd Paris Sud-Institut de Physique du Globe de Paris Orsay laboratory. Additional flows (with K/At ages obtained using the same dating technique) were also sampled for paleomagnetic investigations. More than 200 samples were analyzed using both alternating field AF and thermal stepwise demagnetization techniques. Duplicate samplings of two flows at three different sites demonstrate that within-How dispersion is negligible for the andesitic lava flows sampled in this study. Direct comparison with an earlier paleomagnetic study performed on the island indicates that, for the three investigated flows, modern demagnetization techniques yield much better defined paleomagnetic directions. The Matuyama-Brunhes transition was recorded in a three-flow section and is dated at 781 + 18 ka, in good agreement with other recent radiometric age determinations. The mean paleomagnetic pole calculated from the 23 normal polarity flows is indistinguishable t¾om geographic north, which implies that no significant persistent axial quadrupole term can be identified at this site for the last million years. This result contradicts earlier results and has important implications for models of the time-averaged field (TAF). An <b>Occam</b> <b>algorithm</b> was used to construct a TAF model from the global volcanic database from the last 5 Ma. Substitution of the mean direction calculated from the earlier study for the Lesser Antilles by our new mean value reduces the quadrupole term by more than 30 •. This effect, which was produced by changing data from a single site, demonstrates that older paleomagnetic sites may need to be reinvestigated. Furthermore, it also highlights the limitations of TAF models that can be inferred from paleomagnetic databases in their present state...|$|E
40|$|This thesis {{discusses}} {{techniques for}} the design and implementation of parallel numerical algorithms for distributed memory MIMD architectures. The algorithms are targeted at machines based on the INMOS transputer family of microprocessors which include the T 4, T 8 and T 9000 processors. We investigate how features of {{each member of the}} transputer family affect the design of numerical algorithms. Run-time cost models are developed to give predictions of the total execution time of algorithms. These cost models allow us to study the run-time characteristics of algorithms and the impact of the computer architecture on <b>algorithm</b> run-time. <b>occam</b> implementations of <b>algorithms</b> are developed and their performance is compared with the predictions given by the cost models to see how much credence can be given to the models. The algorithms are designed for both efficiency and portability between a wide range of distributed memory MIMD architectures. The cost models can help to estimate the performance of an algorithm on a different distributed memory architecture and on future generations of machines...|$|R
40|$|An index e in a {{numbering}} of partial-recursive functions {{is called}} minimal if every lesser index computes a different function from e. Since the 1960 ’s {{it has been}} known that, in any reasonable program-ming language, no effective procedure determines {{whether or not a}} given index is minimal. We investigate whether the task of determin-ing minimal indices can be solved in an approximate sense. Our first question, regarding the set of minimal indices, is whether there ex-ists an algorithm which can correctly label 1 out of k indices as either minimal or non-minimal. Our second question, regarding the function which computes minimal indices, is whether one can compute a short list of candidate indices which includes a minimal index for a given program. We give some negative results and leave the possibility of positive results as open questions. 1 <b>Occam’s</b> razor for <b>algorithms</b> In any reasonable programming system, one can code a computable function many different ways. The shortest such code has practical value, theoretical significance, and philosophical allure. Despite their implicit appeal to sim-plicity, shortest codes remain elusive. Indeed no algorithm can enumerate more than finitely many shortest codes [Blu 67, Sch 98], and, as a particular ∗Research supported by the Centre for Quantum Technologies, Institute for Mathemati...|$|R
40|$|This report {{describes}} geoelectric modelling {{using data}} obtained from a reconnaissance MagnetoTe 1 luric (MT) survey carried out {{as part of the}} Southern Upland mapping programme. The 8 site survey, along a l 4 km NW-SE proﬁle, was centred on the Ae forest area to the east of Thornhill and to the SW of Moffatt. The measurements were undertaken across one of the fault-bounded tract sequences of greywackes in the Central Belt. The purpose of the limited survey was to investigate the possibility of ‘locally’ detecting concealed tectonostratigraphic structure by virtue of its (possible) resistivity expression. The MT method attempts to provide a resistivity cross-section, often through the whole crust. The sensors currently available restrict information to depths greater than several hundred metres. The present survey was carried out using a new 7 -channel ﬁeld instrument developed in-house by the BGS. The present report provides information on the modelling of the survey data and presents both one-dimensional (1 -D) vertical proﬁles and a ﬁnal 2 -D whole crustal geoelectric section. l-D inversion of data from two sites within the Palaeozoic Lochmaben basin provide estimates of basin depth comparable with estimates obtained from gravity modelling. 2 -D inversion of the proﬁle data is undertaken using a new <b>algorithm</b> (<b>OCCAM</b> 2 D) to provide a resistivity cross-section through the whole crust. Resistivities greater than 1000 ohm. m, tentatively associated with Silurian greywackes, extend to a depth of about 12 km. A relatively conducting (resistivities < 100 ohm. m) lower crust occurs at depths greater than l 5 km in keeping with previous, low frequency MT observations across the Southern Uplands. A major set of lateral resistivity gradients are found, centred on a depth of about 2. 5 km, to the NW of the northern end of the proﬁle. Underlying this anomaly a modiﬁcation in lower crustal resistivity is apparent at depths greater than l 5 km. The resistivity cross-section suggests that a form of whole crustal modiﬁcation occurs to the NW of the survey proﬁle. The location of the main anomaly remains speculative since the reconnaissance survey was of limited length...|$|R
40|$|Two {{fundamental}} problems in information integration are data exchange and entityresolution. Data exchange {{is the task}} of translating data structured under a sourceschema into data structured under a target schema. Data exchange is captured byschema mappings that specify {{the relationship between a}} source schema and a targetschema at a high level. Entity resolution is the task of identifying and linking differentrepresentations of the same real-world object. The goal of entity resolution is to createlinks among existing data. Although schema mapping and entity resolution have beensuccessfully used in many domains, manually designing schema mappings and entityresolution algorithms is a labor-intensive and time-consuming process. In this dissertation, we develop example-driven discovery/learning methods forhigh-level declarative schema mapping specifications and high-level declarative entityresolution algorithms. This dissertation contains two parts. In Part I, we present ourwork on extending and refining two major example-driven schema-mapping discoveryframeworks, namely, the repair framework introduced by Gottlob and Senellart andthe learning framework introduced by ten Cate et al. Gottlob and Senellart introduceda framework for schema-mapping discovery from a single data example, in which thederivation of a schema mapping is cast as an optimization problem. We refine andstudy this framework in more depth. Among other results, we design a polynomial-timelog(n) -approximation algorithm for computing optimal schema mappings from a given setof data examples for a restricted class of schema mappings; moreover, we show that thisapproximation ratio cannot be improved. We implemented the aforementioned log(n) -approximation algorithm and carried out an experimental evaluation in a real-worldmapping scenario. As opposed to the repair framework, in which the schema-mappingdiscovery problem is cast as an optimization problem, the derivation of a schema mappingis cast as a computational learning problem in the learning framework. We design alearning algorithm that is an <b>Occam</b> <b>algorithm</b> leading up to a PAC learning algorithm foran important class of schema mappings. We also implemented the proposed algorithm andcarried out an experimental evaluation using mapping scenarios created by iBench, whichis a state-of-the-art benchmarking tool. In Part II, we introduce a new active learningsystem for entity resolution that learns high-quality entity resolution algorithms. Ourfocus is on learning entity resolution algorithms in big data scenarios. We implementedthe aforementioned active learning system and carried out an experimental evaluation intwo real-world big data entity resolution scenarios...|$|E
40|$|Tez (Yüksek Lisans) [...] İstanbul Teknik Üniversitesi, Fen Bilimleri Enstitüsü, 2015 Thesis (M. Sc.) [...] İstanbul Technical University, Instıtute of Science and Technology, 2015 Jeofizik yöntemlerden doğru akım elektrik özdirenç yöntemi jeolojik yapıların araştırılmasında, yanal süreksizlerin ortaya konmasında, gevşek çökel malzemenin derinliği ve kalınlığı ile sağlam temel kaya derinliğinin bulunmasında, hidrojeolojik çalışmalarda tuzlu su girişimi ve yeraltı suyu kirlilik haritalarının elde edilmesinde, doğal kaynak aramalarında, jeotermal aramalarda, cevherleşme olan bölgelerin bulunmasında tüm dünyada yaygın olarak kullanılmaktadır.   Bu çalışmada MTA tarafından Kütahya Hisarcık jeotermal alanında gerçekleştirilen 5 profil boyunca 69 adet düşey elektrik sondaj (DES) ve 4 profil boyunca 65, 48, 43 ve 50 noktada doğal potansiyel (Self-Potential SP) ölçümlerinden elde edilen veriler değerlendirilmiş ve bölgenin iki boyutlu yeraltı yapısı araştırılmıştır. Arazide yapılan DES çalışmalarında AB/ 2 değerleri 1000 m. ile 2000 m. arasında değişmektedir. Bunun yanında DES profillerine dik ve paralel şekilde 4 profilde SP ölçüleri alınmıştır. DES verileri bir boyutlu, yanal kısıtlı bir boyutlu (yaklaşık 2 B) ve iki boyutlu ters çözüm algoritmaları kullanılarak değerlendirilmiştir. 1 B ters çözümde kullanılan Occam algoritması, yer içi özdirenç yapısının sürekli ve yumuşatılmış biçimde elde edilmesine dayanmaktadır. İyileştirmede kullanılan yinelemelerde, bir önceki RMS (root mean square) hatasından daha küçük hata veren {{modeller}} içerisinde en yumuşak özdirenç değişimini gösteren model araştırılmaktadır. Yaklaşık 2 B ters çözümde, yanal kısıtlı 1 B ters çözüm algoritması kullanılmaktadır. Bu algoritma, bir doğrultu boyunca ölçülen tüm verilerin iki boyutlu düzgünleyici kısıtlamalar ile yeniden düzenlenen bir boyutlu ters çözüm ile terslenmesi prensibine dayanmaktadır. Dolayısıyla bu algoritma kullanılarak 1 B ve yaklaşık 2 B ters çözümlerin karşılaştırılması ile iki boyutlu bozucu etkilerin belirlenmesi amaçlanmıştır ve bu çözümlerden elde edilen sonuca göre 2 B ters çözüm algoritmasına verilecek başlangıç modeli belirlenmektedir. 2 B Schlumberger ters çözüm algoritması, sabit tutulan blokların her yinelemede sadece özdirenç değerlerinin değiştirilmesi yöntemiyle çalışmaktadır. Elektrik özdirenç ve doğal potansiyel yöntemleri ile hesaplanan yer altı modeli ile sıcaklık ve akış modellemeleri yapılmıştır. Bu amaçla Fluent isimli program kullanılmıştır. Bulunan sonuçlar çerçevesinde araştırma alanında jeotermal alanın varlığını işaret eden kırık yapıları ve sıcak akışkan içeren rezervuarın konumu ve derinliği net bir şekilde ortaya konulmuştur. Fossil fuels such as coal, petroleum, {{natural gas}} and nuclear power are used primarily for energy production around the world. Since the global awareness increased for the detrimental effects of burning fossil fuels, clean and renewable energy sources, ie, hydroelectric, geothermal, sunlight, wind, gain more interest. Geothermal energy which {{has proven to be}} clean, renewable and safe, is one of the promising renewable energy source. Turkey is located on the Alpine-Himalayan orogenic belt and locating in region of high tectonic activity. There are Miocene or younger grabens developed in that area {{as a result of this}} orogeny. Therefore, Turkey is a country with a significant geothermal energy potential. Electricity generation, direct use (house heating, greenhouse heating) and industrial usage are some of the various geothermal energy utilizations can be done in Turkey. Resource assesment is done many times by the General Directorate of Mineral Research and Exploration (MTA) and today it is discovered more than 1000 hot and mineral water springs which their temperature is up to 100 - 140 oC and geothermal fields with a temperature range of 40 - 232 oC. 95 percent of the discovered 186 geothermal field is low-medium enthalpy source. Although Turkey is the 7 th richest country in the word in terms of geothermal potential, most of the development has been achieved at direct-use applications. Exploration of geothermal fields are in great importance since it is a cleaner energy source. For this purpose, direct current geophysical method is a well suited tool for geothermal exploration and for all that, geological structures, lateral discontinuities, sediment thickness and depth, bedrock depth, hydrogeologic studies, groundwater exploration and groundwater contamination and natural resources. In this study, it is aimed to obtain two dimensional subsurface structure of Kütahya-Hisarcık geothermal field. Detailed geophysical survey which consist of 69 vertical electrical soundings (VES) with various AB/ 2 between 1000 m. and 2000 m. and SP measurements of 4 profile were carried out by MTA. Schlumberger electrode spacing is used for VES surveys and 25 m. electrode spacing is used for SP profiling. Study area is located north of Emet-Gediz graben. Measurements took place at a 69 km 2 area near Hamamköy and Sefaköy and can be located at 1 / 25000 scaled Kütahya J 22 -c 1 map. Survey area is located at 70 km. south-west of Kütahya centrum and 10 km. south of Emet. Fault directions are observed in vicinity are, NW-SE, N-S and NE-SW. While right lateral faults are NW-SE oriented, N-S and NESw oriented ones are dip-slip normal faults. Most important tectonic element is Hisarcık fault. This fault is N-S oriented and observed in Neogene Yeniköy formation. Yeniköy formation consists of sandstone, siltstone, marl and fine grained sandstone-tuff layers. Travertines are observed in a small area north of Hamamköy. Budağan limestones, Arıkaya and Sarıcasu formations underlaying the Yeniköy formation are potential geothermal reservoirs. VES data are inverted by 1 D, quasi 2 D and 2 D inversion algorithms. <b>Occam</b> <b>algorithm</b> is used for 1 D inversion which gave a smooth and continuous resistivity variations of the area. It is more satisfactory to allow the model to be as flexible as possible but suppress complexity explicitly. Therefore a rougness value is defined. Goal here is to find the smallest roughness value that agrees with the measurements.  In order to convert the VES data by quasi 2 D, laterally constrained 1 D (LCI) algorithm is used. This algorithm uses similar approach that Occam does and based on applying modified one dimensional inversion with two dimensional smoothness constraints on a vertical electrical sounding data along a line. Therefore this quasi 2 D algorithm is compared with 2 D inversion  to determine 2 D structural effects. Lastly, 2 D Schlumberger inversion algorithm is used which based on 2 D model with fixed block boundaries during inversion and only the resistivity values of each block changes through the iteration. VES data inverted along 5 profiles which are all parallel to each other are named I, J, JK, K and M in respect to north to south. There is a high-low resistivity contrast at northern profiles. The reason for this contrast is thought of Hisarcık fault at vicinity. This boundary is located near I- 18 VES station divides the area into two zones with 400 ohm-m. - 20 ohm-m. resistivity difference. East of I- 18, there is a remnant of old depression around I- 23. According to geoelectrical structure of profile I, bedrock gets deeper eastwards. Low resistivity zone is seen around 1500 m. along profile and at a depth of 750 - 800 m. Hisarcık fault is also seen at Profile J with its characteristic high resistivity contrast. Low resistivity (less than 10 Ω m.) is 1200 - 1600 m. along profile and at 400 m. depth. Horst-graben structure is clearly seen at profile J around JK- 18 – JK- 19 and JK- 23 – JK- 24. Area between these two faults are between 1300 m. and 1800 m.  along profil J and between 400 – 600 m. depth. Faults observed at other profiles also seen clearly at profile K around K- 18 – K- 19 ves stations. Graben structure seen around K- 20 - 1 – K- 21 stations and low resistivity zone is located at a depth of 400 - 675 m. Profile M is the longest profile and located at the south of other profiles. Old depression mentioned at profile I is also shown at this profile between M- 20 – M- 27 VES stations. East and west of this depression, graben structure is visible clearly. Area is characterize with Pliocene allüvial deposits and Hisarcık formation and Miocene aged Yeniköy formation at the uppermost layer. These formations are underlayed by fructured Arıkaya and Balıkbaşı limestones. It is thought that Simav metamorfics are the bottom layer at vicinity.   There are 4 SP profiles consist of 65, 48, 43 and 50 stations are named A,B,C and D. A and B profiles are parallel to each other and perpendiculat to VES profiles. C profile is between I- 19 and I- 23 VES stations. Profile D is intercepts I, J, JK and K VES profiles. Both profiles B and A are shown similar characteristics as continuous increase or decrease. This indicates that these profiles are along the geological structures and does not intercepts a fault surface. On the other hand, profile C shows negative values between I- 21 and I- 22. These results concur with the graben structure observed at VES cross sections.   In order to find the reservoir’s location and depth, fault and fracture structures derived from VES and SP data are used in ANSYS FLUENT 6. 3. 26 computational fluid dynamics software. This software operates using finite volume method for flow and temperature modelling. Temperature, porosity, permeability, viscosity, heat capacity, thermal expansion coefficient and thermal conductivity are used as model parameters for modelling. These parameters were conbined wth the subsurface geometries derived from SP and VES studies in order to build mesh geometry. Model consist of 40710 finite volume element and 41370 nodes that binds them. Fault zones are defined by permeability contrast within surrounding rocks. While surrounding rocks have a permeability of 10 - 15, fault zones are defined with 10 - 13.  Model parameters are decided after thorough literature research and concurs with recent studies. Steady state temperature calculations shows that smooth temperature curves. This is in agreement with the expected heat conduction (less Rayleigh number than Critical Rayleigh number). Furthermore, 10 - 9 m/s Darcy velocities are observed around fault zones. This is velocity values are also concur with recent studies.    Temperature of Yenice, Yoncaağaç and Sefaköy hotsprings at Emet-Hisarcık graben are measured as 37 oC, 49 oC and 51 oC. According to this information, temperatures of the hotsprings are increasing from north to south. This also in agreement with the VES cross sections that indicates deepening bedrock through eastwards. Therefore it is possible to obtain higher temperature reservoirs and further investigations are needed. Yüksek LisansM. Sc...|$|E

