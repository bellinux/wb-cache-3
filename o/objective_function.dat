10000|6788|Public
25|$|Since the {{entering}} variable will, in general, increase from 0 {{to a positive}} number, {{the value of the}} <b>objective</b> <b>function</b> will decrease if the derivative of the <b>objective</b> <b>function</b> with respect to this variable is negative. Equivalently, the value of the <b>objective</b> <b>function</b> is decreased if the pivot column is selected so that the corresponding entry in the objective row of the tableau is positive.|$|E
25|$|An optimal {{solution}} need not exist, for two reasons. First, if two constraints are inconsistent, then no feasible solution exists: For instance, the constraints x≥2 and x≤1 cannot be satisfied jointly; in this case, {{we say that}} the LP is infeasible. Second, when the polytope is unbounded {{in the direction of}} the gradient of the <b>objective</b> <b>function</b> (where the gradient of the <b>objective</b> <b>function</b> is the vector of the coefficients of the <b>objective</b> <b>function),</b> then no optimal value is attained.|$|E
25|$|It {{can also}} be shown that if an extreme point is not a maximum point of the <b>objective</b> <b>function</b> then there is an edge {{containing}} the point so that the <b>objective</b> <b>function</b> is strictly increasing on the edge {{moving away from the}} point. If the edge is finite then the edge connects to another extreme point where the <b>objective</b> <b>function</b> has a greater value, otherwise the <b>objective</b> <b>function</b> is unbounded above on the edge and the linear program has no solution. The simplex algorithm applies this insight by walking along edges of the polytope to extreme points with greater and greater objective values. This continues until the maximum value is reached or an unbounded edge is visited, concluding that the problem has no solution. The algorithm always terminates because the number of vertices in the polytope is finite; moreover since we jump between vertices always in the same direction (that of the <b>objective</b> <b>function),</b> we hope that the number of vertices visited will be small.|$|E
40|$|Minuk Yang․Kern-Joong Kim) Abstract- The optimal {{analysis}} has <b>objective</b> <b>functions,</b> equality constraint functions and inequality <b>functions.</b> <b>Objective</b> <b>functions</b> {{may be used}} with inequality function, because occasionally variables are moved to non-analytic condition with calculating <b>objective</b> <b>functions.</b> But inequality constraint functions are very complicated problem in a optimal analysis...|$|R
40|$|Calibrating {{conceptual}} hydrological {{models is}} often done via the optimization of <b>objective</b> <b>functions</b> {{serving as a}} measure of model performance. Most of the <b>objective</b> <b>functions</b> used in the hydrological literature can be classified into distance- and weak form-based <b>objective</b> <b>functions.</b> Distance- and weak form-based <b>objective</b> <b>functions</b> can be seen respectively as generalizations of the square error and balance error. An analysis of the <b>objective</b> <b>functions</b> shows that: (i) the calibration problem is transformed from an optimization problem with distance-based <b>objective</b> <b>functions</b> into a root finding problem for weak form-based functions; (ii) weak form-based <b>objective</b> <b>functions</b> are essentially less prone to local extrema than distance-based functions; (iii) consequently, they allow simple gradient-based methods to be used; (iv) parameter redundancy can be assessed very simply by superimposing the contour lines or comparing the gradients of two <b>objective</b> <b>functions</b> of similar nature in the parameter space; and (v) simple guidelines can be defined for the selection of the calibration variables in a conceptual hydrological model. The theoretical results are illustrated by two simple test cases. Weak form-based approaches offer the potential for better-posed calibration problems, {{through the use of a}} number of independent criteria that matches the dimension of the identification problem. In contrast with distance-based <b>objective</b> <b>functions,</b> they do not have the inconvenience of solution non-uniqueness. Finally, the need for models with internal variables bearing a physical meaning is acknowledged...|$|R
50|$|The 1st theorem first hypothesizes that <b>objective</b> <b>functions</b> do {{not change}} while {{optimization}} is in progress, and then hypothesizes that <b>objective</b> <b>functions</b> may change.|$|R
25|$|Linear Programming {{requires}} {{the definition of}} an <b>objective</b> <b>function.</b> The optimal solution to the LP problem {{is considered to be}} the solution which maximizes or minimizes the value of the <b>objective</b> <b>function</b> depending on the case in point. In the case of flux balance analysis, the <b>objective</b> <b>function</b> Z for the LP is often defined as biomass production. Biomass production is simulated by an equation representing a lumped reaction that converts various biomass precursors into one unit of biomass.|$|E
25|$|The {{field of}} {{optimization}} is further split in several subfields, {{depending on the}} form of the <b>objective</b> <b>function</b> and the constraint. For instance, linear programming deals with the case that both the <b>objective</b> <b>function</b> and the constraints are linear. A famous method in linear programming is the simplex method.|$|E
25|$|When {{modeling}} smaller networks the <b>objective</b> <b>function</b> can {{be changed}} accordingly. An example {{of this would be}} {{in the study of the}} carbohydrate metabolism pathways where the <b>objective</b> <b>function</b> would probably be defined as a certain proportion of ATP and NADH and thus simulate the production of high energy metabolites by this pathway.|$|E
40|$|Tbe {{applicability}} of evolution strategies (ESs), population based stochastic optimization techniques, to optimize clustering <b>objective</b> <b>functions</b> is explored. Clustering <b>objective</b> <b>functions</b> are categorized into centroid and non-centroid type of functions. Optimization of the centroid type of <b>objective</b> <b>functions</b> {{is accomplished by}} formulating them as functions of real-valued parameters using ESs. Both hard and fuzzy clustering <b>objective</b> <b>functions</b> are considered in this study. Applicability of ESs to discrete optimization problems is extended to optimize the non-centroid type of <b>objective</b> <b>functions.</b> As ESs are amenable to parallelization, a parallel model (master/slave model) is described {{in the context of}} the clustering problem. Results obtained for selected data sets substantiate the utility of ESs in clustering...|$|R
30|$|The routing {{parameter}} MAXBAS shows {{a higher}} sensitivity {{with respect to}} the <b>objective</b> <b>functions</b> based on runoff signatures and the combined <b>objective</b> <b>functions</b> than to the more statistical measures.|$|R
5000|$|The {{procedure}} for formulating different <b>objective</b> <b>functions,</b> {{in terms of}} the production model, is introduced next. In the income formation from production the following <b>objective</b> <b>functions</b> can be identified: ...|$|R
25|$|According to Schmidhuber, his <b>objective</b> <b>function</b> {{explains}} {{the activities of}} scientists, artists, and comedians.|$|E
25|$|Note {{that the}} {{equation}} defining the original <b>objective</b> <b>function</b> is retained {{in anticipation of}} Phase II.|$|E
25|$|The {{quadratic}} {{knapsack problem}} (QKP) maximizes a quadratic <b>objective</b> <b>function</b> {{subject to a}} binary and linear capacity constraint.|$|E
30|$|The genetic {{algorithm}} {{is based on}} <b>objective</b> <b>functions</b> to compare the different solution couples. We use two image quality parameters and two signal parameters to set four <b>objective</b> <b>functions</b> up.|$|R
5000|$|Wolpert and Macready give two {{principal}} NFL theorems, the first regarding <b>objective</b> <b>functions</b> {{that do not}} change while search is in progress, and the second regarding <b>objective</b> <b>functions</b> that may change.|$|R
40|$|Structured mesh quality {{optimization}} {{methods are}} extended to optimization of unstructured triangular, quadrilateral, and mixed finite element meshes. N"ew interpretations of well-known nodally-bssed <b>objective</b> <b>functions</b> are made possible using matrices and matrix norms. The matrix perspective also suggests several new <b>objective</b> <b>functions.</b> Particularly significant is {{the interpretation of}} the Oddy metric and the Smoothness <b>objective</b> <b>functions</b> in terms of the condition number of the metric tensor and Jacobian matrix, respectively. <b>Objective</b> <b>functions</b> are grouped according to dimensionality to form weighted combinations. A simple unconstrained local optimum is computed using a modiiied N-ewton iteration. The optimization approach was implemented in the CUBIT mesh generation code and tested on several problems. Results were compared against several standard element-based quaIity measures to demonstrate that good mesh quality can be achieved with nodally-based <b>objective</b> <b>functions...</b>|$|R
25|$|Minimizing (2) can be rewritten as a {{constrained}} {{optimization problem}} with a differentiable <b>objective</b> <b>function</b> in the following way.|$|E
25|$|Adaptation of the {{covariance}} matrix amounts to learning a second order {{model of the}} underlying <b>objective</b> <b>function</b> similar to the approximation of the inverse Hessian matrix in the Quasi-Newton method in classical optimization. In contrast to most classical methods, fewer assumptions {{on the nature of}} the underlying <b>objective</b> <b>function</b> are made. Only the ranking between candidate solutions is exploited for learning the sample distribution and neither derivatives nor even the function values themselves are required by the method.|$|E
25|$|Constraint {{satisfaction}} {{studies the}} {{case in which the}} <b>objective</b> <b>function</b> f is constant (this is used in artificial intelligence, particularly in automated reasoning).|$|E
40|$|Redundancy in {{constraints}} and variables are usually studied in linear, integer and non-linear programming problems. However, main emphasis {{has so far}} been given only to linear programming problems. In this paper, an algorithm that identifies redundant <b>objective</b> <b>functions</b> in multi-objective stochastic fractional programming problems is provided. A solution procedure is also illustrated. This reduces the number of <b>objective</b> <b>functions</b> in cases where redundant <b>objective</b> <b>functions</b> exist. Stochastic programming, fractional programming, multi-objective programming, redundancy...|$|R
50|$|The second {{approach}} (the constraint method), chooses {{one of the}} <b>objective</b> <b>functions</b> as {{the single}} objective, and the other <b>objective</b> <b>functions</b> are treated as constraints with a limited value. However, the optimal solution depends on the pre-defined constraint limits.|$|R
40|$|For the Minkowski Sum Selection {{problem with}} linear <b>objective</b> <b>functions,</b> we obtain the {{following}} results: (1) optimal O(n n) time algorithms for λ= 1; (2) O(n^ 2 n) time deterministic algorithms and expected O(n n) time randomized algorithms for any fixed λ> 1. For the Minkowski Sum Finding problem with linear <b>objective</b> <b>functions</b> or <b>objective</b> <b>functions</b> {{of the form}} f(x,y) =by/ax, we construct optimal O(n n) time algorithms for any fixed λ≥ 1. Comment: 23 pages, 10 figures, accepted by ISAAC 200...|$|R
25|$|For {{the topic}} of {{approximating}} a function by a sum of others using an <b>objective</b> <b>function</b> based on squared distances, see least squares (function approximation).|$|E
25|$|When the <b>objective</b> <b>function</b> is convex, then {{any local}} minimum {{will also be}} a global minimum. There exist {{efficient}} numerical techniques for minimizing convex functions, such as interior-point methods.|$|E
25|$|One of Fermat's theorems {{states that}} optima of {{unconstrained}} problems are found at stationary points, {{where the first}} derivative or the gradient of the <b>objective</b> <b>function</b> is zero (see first derivative test). More generally, they may be found at critical points, where the first derivative or gradient of the <b>objective</b> <b>function</b> is zero or is undefined, or on the boundary of the choice set. An equation (or set of equations) stating that the first derivative(s) equal(s) zero at an interior optimum is called a 'first-order condition' or a set of first-order conditions.|$|E
3000|$|By {{calculating the}} partial {{derivatives}} of the <b>objective</b> <b>functions</b> of Eqs. (4 a) and (4 b) {{with respect to}} x, we can obtain the gradients ϕ^' and approximate symmetric positive definite Hessian matrices ϕ^" [...] of the <b>objective</b> <b>functions</b> of Eqs. (4 a) and (4 b), respectively.|$|R
30|$|The {{smaller the}} value of ε is, the better the {{approximation}} is. It is good to note that a normalization of the <b>objective</b> <b>functions</b> is {{required in order to}} obtain efficient results when the scale is not the same for all the <b>objective</b> <b>functions.</b>|$|R
40|$|In this paper, {{analysis}} of variance (ANOVA) and self-organizing map (SOM) are applied to data mining for aerodynamic design space. These methods {{make it possible to}} identify the effect of each design variable on <b>objective</b> <b>functions.</b> ANOVA shows the information quantitatively while SOM shows it qualitatively. Furthermore, ANOVA can show the effect of interaction between design variables on <b>objective</b> <b>functions</b> and SOM can visualize the trade-off among <b>objective</b> <b>functions.</b> This information will be helpful for designer to determine the final design from the non-dominated solutions of multi-objective problem. These methods are applied to a fly-back booster of reusable launch vehicle design which has 4 <b>objective</b> <b>functions</b> and 71 design variables, and a transonic airfoil design performed with adaptive search region method. I...|$|R
25|$|More formally, linear {{programming}} {{is a technique}} for the optimization of a linear <b>objective</b> <b>function,</b> subject to linear equality and linear inequality constraints. Its feasible region is a convex polytope, which is a set defined as the intersection of finitely many half spaces, {{each of which is}} defined by a linear inequality. Its <b>objective</b> <b>function</b> is a real-valued affine (linear) function defined on this polyhedron. A {{linear programming}} algorithm finds a point in the polyhedron where this function has the smallest (or largest) value if such a point exists.|$|E
25|$|Thus, {{the problem}} is to {{minimize}} the <b>objective</b> <b>function</b> subject to the m constraints. It is solved {{by the use of}} Lagrange multipliers. After some algebraic manipulations, the result is obtained.|$|E
25|$|If {{estimator}} Tn {{is defined}} implicitly, for example as a value that maximizes certain <b>objective</b> <b>function</b> (see extremum estimator), then {{a more complicated}} argument involving stochastic equicontinuity has to be used.|$|E
40|$|This paper {{develops}} a fast distributed algorithm, termed DEXTRA, {{to solve the}} optimization problem when n agents reach agreement and collaboratively minimize the sum of their local <b>objective</b> <b>functions</b> over the network, where the communication between the agents is described by a directed graph. Existing algorithms solve the problem restricted to directed graphs with convergence rates of O(k/√(k)) for general convex <b>objective</b> <b>functions</b> and O(k/k) when the <b>objective</b> <b>functions</b> are strongly-convex, where k {{is the number of}} iterations. We show that, with the appropriate step-size, DEXTRA converges at a linear rate O(τ^k) for 0 <τ< 1, given that the <b>objective</b> <b>functions</b> are restricted strongly-convex. The implementation of DEXTRA requires each agent to know its local out-degree. Simulation examples further illustrate our findings...|$|R
40|$|The basic descent {{algorithms}} for minimizing nonlinear <b>objective</b> <b>functions</b> {{will generally}} find a local minimum. For problems with multimodal <b>objective</b> <b>functions,</b> {{it is desirable}} to extend the search {{in an attempt to}} find a global minimum. Several versions of a new method for doing this are presented. Computational tests are performed to compare these methods with existing methods. (Author) The basic descent algorithms for minimizing nonlinear <b>objective</b> <b>functions</b> will generally find a local minimum. For problems with multimodal <b>objective</b> <b>functions,</b> it is desirable to extend the search in an attempt to find a global minimum. Several versions of a new method for doing this are presented. Computational tests are performed to compare these methods {{with each other and with}} existing methods. [URL]...|$|R
3000|$|Multi-objective {{optimization}} (MOO) {{methods are}} utilized when {{two or more}} <b>objective</b> <b>functions</b> are necessary to be optimized simultaneously (Deb 2001). In the case of MOO methods, relative importance of <b>objective</b> <b>functions</b> is not generally known until the system's best capabilities are determined and trade-off between the <b>objective</b> <b>functions</b> is fully understood. This feature is the main advantage of MOO methods in comparison with simply weighted cost functions. The definition of an MOO problem requires substantial acquaintance with some preliminary definitions which are described as follows: [...]...|$|R
