7|14|Public
3000|$|... discretization. The use of BioPhasor as {{the mixing}} process {{provides}} a <b>one-way</b> <b>transformation</b> that precludes exact {{recovery of the}} biometric vector from compromised hashes and stolen tokens. In addition, our user-specific [...]...|$|E
40|$|In this paper, {{we propose}} a secure {{biometric}} based authentication scheme which fundamentally {{relies on the}} use of a robust hash function. The robust hash function is a <b>one-way</b> <b>transformation</b> tailored specifically for each user based on their biometrics. The function is designed as a sum of properly weighted and shifted Gaussian functions to ensure the security and privacy of biometric data. We discuss various design issues such as scalability, collision-freeness and security. We also provide test results obtained by applying the proposed scheme to ORL face database by designating the biometrics as singular values of face images...|$|E
40|$|The {{increasing}} use of biometrics {{in different}} environments presents new challenges. Most importantly, biometric data are irreplaceable. Therefore, storing biometric templates, which is unique to individual user, entails significant security risks. In this paper, we propose a geometric transformation for securing the minutiae based fingerprint templates. The proposed scheme employs a robust <b>one-way</b> <b>transformation</b> that maps geometrical configuration of the minutiae points into a fixed-length code vector. This representation enables efficient alignment and reliable matching. Experiments are conducted by applying the proposed method on a synthetically generated minutiae point sets. Preliminary {{results show that the}} proposed scheme provides a simple and effective solution to the template security problem of the minutiae based fingerprint...|$|E
40|$|Abstract. In {{this paper}} we propose a {{fundamental}} approach to perform the class of Nearest Neighbor (NN) queries, the core class of queries used in many of the location-based services, without revealing the origin of the query in order to preserve the privacy of this information. The idea behind our approach is to utilize <b>one-way</b> <b>transformations</b> to map the space of all static and dynamic objects to another space and resolve the query blindly in the transformed space. However, in order to become a viable approach, the transformation used should be able to resolve NN queries in the transformed space accurately and more importantly prevent malicious use of transformed data by untrusted entities. Traditional encryption based techniques incur expensive O(n) computation cost (where n is the total number of points in space) and possibly logarithmic communication cost for resolving a KNN query. This is because such approaches treat points as vectors in space and do not exploit their spatial properties. In contrast, we use Hilbert curves as ef cient <b>one-way</b> <b>transformations</b> and design algorithms to evaluate a KNN query in the Hilbert transformed space. Consequently, we reduce the complexity of computing a KNN query to O(K × 22 N) and transferring the results n to the client in O(K), respectively, where N, the Hilbert curve degree, is a small constant. Our results show that we very closely approximate the result set generated from performing KNN queries in the original space while enforcing our new location privacy metrics termed u-anonymity and a-anonymity, which are stronger and more generalized privacy measures than the commonly used K-anonymity and cloaked region size measures. ...|$|R
40|$|AbstractNowadays, typical {{software}} and system engineering projects in various industrial sectors (automotive, telecommunication, etc.) involve hundreds of developers using {{quite a number}} of different tools. Thus, the data of a project as a whole is distributed over these tools. Therefore, it is necessary to make the relationships of different tool data repositories visible and keep them consistent with each other. This still is a nightmare {{due to the lack of}} domain-specific adaptable tool and data integration solutions which support maintenance of traceability links, semi-automatic consistency checking as well as update propagation. Currently used solutions are usually hand-coded <b>one-way</b> <b>transformations</b> between pairs of tools. In this article we present a rule-based approach that allows for the declarative specification of data integration rules. It is based on the formalism of triple graph grammars and uses directed graphs to represent MOF-compliant (meta) models. As a result we give an answer to OMG's request for proposals for a MOF-compliant “queries, views, and transformation” (QVT) approach from the “model driven application development” (MDA) field...|$|R
40|$|AbstractComputational asymmetry, i. e., the {{discrepancy}} between the complexity of transformations and the complexity of their inverses, {{is at the core of}} <b>one-way</b> <b>transformations.</b> We introduce a computational asymmetry function that measures the amount of one-wayness of permutations. We also introduce the word-length asymmetry function for groups, which is an algebraic analogue of computational asymmetry. We relate combinational circuits to words in a Thompson monoid, over a fixed generating set, in such a way that circuit size is equal to word-length. Moreover, combinational circuits have a representation in terms of elements of a Thompson group, in such a way that circuit size is polynomially equivalent to word-length. We show that circuits built with gates that are not constrained to have fixed-length inputs and outputs, are at most quadratically more compact than circuits built from traditional gates (with fixed-length inputs and outputs). Finally, we show that the computational asymmetry function is closely related to certain distortion functions: The computational asymmetry function is polynomially equivalent to the distortion of the path length in Schreier graphs of certain Thompson groups, compared to the path length in Cayley graphs of certain Thompson monoids. We also show that the results of Razborov and others on monotone circuit complexity lead to exponential lower bounds on certain distortions...|$|R
40|$|Biometrics is {{susceptible}} to non-revocable and privacy invasion problems. Multiple Random Projections (MRP) was introduced {{as one of the}} cancellable biometrics approaches in face recognition to tackle these issues. However, this technique is applicable only to 1 D fixed length biometric feature vector but failed in varying size feature, such as speech biometrics. Besides, simple matching metric that used in MRP unable to offer a satisfactory verification performance. In this paper, we propose a variant of MRP, coined as Probabilistic Random Projections (PRP) in text-independent speaker verification. The PRP represents speech feature in 2 D matrix format and speaker modeling is implemented through Gaussian Mixture Model. The formulation is experimented under two scenarios (legitimate and stolen token) using YOHO speech database. Besides that, desired properties such as <b>one-way</b> <b>transformation</b> and diversity are also examined...|$|E
40|$|We {{introduce}} a novel method for secure computation of biometric hash on dynamic hand signatures using BioPhasor mixing and 2 N discretization. The use of BioPhasor as the mixing process provides a <b>one-way</b> <b>transformation</b> that precludes exact {{recovery of the}} biometric vector from compromised hashes and stolen tokens. In addition, our user-specific 2 (N) discretization acts both as an error correction step {{as well as a}} real-to-binary space converter. We also propose a new method of extracting compressed representation of dynamic hand signatures using discrete wavelet transform (DWT) and discrete fourier transform (DFT). Without the conventional use of dynamic time warping, the proposed method avoids storage of user's hand signature template. This is an important consideration for protecting the privacy of the biometric owner. Our results show that the proposed method could produce stable and distinguishable bit strings with equal error rates (EERs) of 0 % and 9. 4 % for random and skilled forgeries for stolen token (worst case) scenario, and 0 % for both forgeries in the genuine token (optimal) scenario...|$|E
40|$|Abstract. Password Hashing, a {{technique}} commonly implemented by a server to protect passwords of clients, by performing a <b>one-way</b> <b>transformation</b> on the password, {{turning it into}} another string called the hashed password. In this paper, we introduce a secure password hashing framework Rig {{which is based on}} secure cryptographic hash functions. It provides the flexibility to choose different functions for different phases of the construction. The design of the scheme is very simple to implement in software and is flexible as the memory parameter is independent of time parameter (no actual time and memory trade-off) and is strictly sequential (difficult to parallelize) with comparatively huge memory consumption that provides strong resistance against attackers using multiple processing units. It supports client-independent updates, i. e., the server can increase the security parameters by updating the existing password hashes without knowing the password. Rig can also support the server relief protocol where the client bears the maximum effort to compute the password hash, while there is minimal effort at the server side. We analyze Rig and show that our proposal provides an exponential time complexity against the low-memory attack...|$|E
40|$|A concept named induced {{trapdoor}} <b>one-way</b> quantum <b>transformation</b> (OWQT) {{has been}} introduced, and {{a theoretical framework}} of public-key encryption (PKE) of quantum message is presented based on it. Then several kinds of quantum public-key encryption (QPKE) protocols, such as quantum version PKE of RSA, ElGamal, Goldwasser-Micali, elliptic curve, McEliece, Niederreiter and Okamoto-Tanaka-Uchiyama, are given within this framework. Though all of these protocols are only computationally secure, the last three are probably secure in post-quantum era. Besides, theoretical frameworks for public-key authentication and signature of quantum message are also given based on the induced trapdoor OWQT. As examples, a public-key authentication protocol of quantum message based on SN-S authentication scheme and two quantum digital signature protocols based on RSA and McEliece algorithms respectively are presented. Comment: 26 pages, 1 figure...|$|R
40|$|Metamaterials {{bring new}} {{opportunities}} to radome design, including an improved transmission over {{a broader range}} of antenna scan angles, tailorable and reconfigurable frequency bands, polarization <b>transformations,</b> <b>one-way</b> transmission and switching ability. However, the smallness of the unit cell introduces additional complications in full wave numerical simulations, requiring a very fine sampling over an electrically large area of the radome. This paper describes the results of numerical simulations of electromagnetic transmission through planar meta-sheets (infinite and circularly shaped) by using a full wave simulator and a physical optics solution...|$|R
40|$|Abstract. The {{advent of}} model-driven {{software}} development has put model transformations into focus. In practice, model transformations {{are expected to}} be applicable in different stages of a development process and help to consistently propagate changes between the different involved models which we refer to as model synchronization. However, most approaches do not fully support the requirements for model synchronization today and focus only on classical <b>one-way</b> batch-oriented <b>transformations.</b> In this paper, we present our approach for an incremental model transformation which supports model synchronization. Our approach employs the visual, formal, and bidirectional transformation technique of triple graph grammars. Using this declarative specification formalism, we focus on the efficient execution of the transformation rules and present our approach to achieve an incremental model transformation for synchronization purposes. We present an evaluation of our approach and demonstrate that due to the speedup for the incremental processing in the average case even larger models can be tackled. ...|$|R
40|$|UnrestrictedAn obvious {{requirement}} for evaluating spatial queries in Location Based Services (LBS) {{is that the}} location of the query point needs to be shared with the location server responding to user queries. Spatial data such as points of interest are indexed at this potentially untrusted server (host) and queries are evaluated by navigating the underlying index structure used to partition the data. However, a user’s location is highly sensitive information that once compromised, can expose him to various threats such as stalking and inference about his health problems or political/religious affiliations. Such growing concerns about users’ location privacy in LBS is considered to be the biggest impediment to the explosive growth and popularity of location-based services. The anonymity and cloaking-based approaches proposed to address this problem cannot provide stringent privacy guarantees without incurring costly computation and communication overhead. Furthermore, they require a trusted intermediate anonymizer to protect user locations during query processing.; In this dissertation, we identify the key challenges of enabling privacy in location-based services using an untrusted server model. We propose three solutions to the location privacy problem. Our first solution employs a space transformation scheme to privately evaluate location queries in a space unknown to the untrusted server. The novel <b>one-way</b> <b>transformation</b> developed allows fast computation of location queries in the transformed space while respecting user privacy. We develop our second solution based on the theory of Private Information Retrieval to achieve yet stronger levels of privacy. This strong measure of privacy comes with more computational cost. Finally, we propose a more fundamental technique that enables oblivious traversal of tree-structured spatial indexes for query processing. With this technique, the original spatial index is replaced with an encrypted spatial index that is hosted at the server. While preserving user privacy, this technique allows a wide range of spatial queries to be efficiently evaluated over the encrypted index...|$|E
40|$|Ultra-thin metamaterials, called meta-surfaces or meta-sheets, open up new {{opportunities}} in designing microwave radomes, including an improved transmission over {{a broader range}} of antenna scan angles, tailorable and reconfigurable frequency bands, polarization <b>transformations,</b> <b>one-way</b> transmission and switching ability. The smallness of the unit cells combined with the large electrical size of microwave radomes significantly complicates full-wave numerical simulations as a very fine sampling over an electrically large area is required. Physical optics (PO) can be used to approximately describe transmission through the radome in terms of the homogenized transmission coefficient of the radome wall. This paper presents the results of numerical simulations of electromagnetic transmission through planar meta-sheets (infinite and circularly shaped) obtained by using a full-wave electromagnetic field simulator and a PO-based solution...|$|R
40|$|Abstract. Goldreich-Krawczyk (Siam J of Comp’ 96) {{showed that}} only {{languages}} in BPP have constant-round public-coin black-box zero-knowledge protocols. We extend their lower bound to “fully black-box ” privatecoin protocols based on one-way functions. More precisely, {{we show that}} only languages in BPP Sam —where Sam is a “collision-finding ” oracle in analogy with Simon (Eurocrypt’ 98) and Haitner et. al (FOCS’ 07) —can have constant-round fully black-box zero-knowledge proofs; the same holds for constant-round fully black-box zero-knowledge arguments with sublinear verifier communication complexity. We also establish nearlinear lower bounds on the round complexity of fully black-box concurrent zero-knowledge proofs (or arguments with sublinear verifier communication) for languages outside BPP Sam. The technique used to establish these results is a transformation from private-coin protocols into Sam-relativized public-coin protocols; for the case of fully black-box protocols based on <b>one-way</b> functions, this <b>transformation</b> preserves zero knowledge, round complexity and communication complexity. ...|$|R
40|$|Abstract. Outsourcing data {{to third}} party data {{providers}} {{is becoming a}} common practice for data owners to avoid the cost of managing and maintaining databases. Meanwhile, due to the popularity of locationbased-services (LBS), the need for spatial data (e. g., gazetteers, vector data) is increasing exponentially. Consequently, we are witnessing a new trend of outsourcing spatial datasets by data collectors. Two main challenges with outsourcing datasets {{is to keep the}} data private (from the data provider) and ensure the integrity of the query result (for the clients). Unfortunately, most of the techniques proposed for privacy and integrity do not extend to spatial data in a straightforward manner. Hence, recent studies proposed various techniques to support either privacy or integrity (but not both) on spatial datasets. In this paper, for the first time, we propose a technique that can ensure both privacy and integrity for outsourced spatial data. In particular, we first use a <b>one-way</b> spatial <b>transformation</b> method based on Hilbert curves, which encrypts the spatial data before outsourcing and hence ensures its privacy. Next, by probabilistically replicating a portion of the data and encrypting it with a different encryption key, we devise a technique for the client to audit the trustworthiness of the query results. We show the applicability of our approach for both k-nearest-neighbor and spatial range queries, the building blocks of any LBS application. Finally, we evaluate the validity and performance of our algorithms with real-world datasets. ...|$|R
40|$|This thesis {{studies the}} {{manipulation}} of entanglement in three-qubit quantum systems. I consider the operational setting in which the qubits are distributed to three spatially separated parties. The parties act locally on their quantum systems and share classical communication with one another, a scenario commonly called local operations and classical communication (LOCC). In the LOCC setting, {{there are two different}} classes of entanglement in multipartite systems, called the GHZ and W classes, which are inequivalent in the sense that states from one class cannot be transformed into the other without the consumption of additional entanglement. In this thesis, I first show that the LOCC conversion of certain GHZ and W-class states becomes possible by using only one additional ebit (“entangled bit”) of shared entanglement. In many cases, this can be proven as the minimal amount of needed entanglement. I then consider the problem of <b>one-way</b> communication <b>transformations</b> from general three-qubit states into two-qubit maximally entangled states, known as EPR states. An optimal protocol in terms of success probability is provided for W-class states. The success probability of this protocol coincides with the optimal success probability if two of the parties are allowed to act jointly within the same laboratory. In other words, forcing the locality constraint on all three parties does not weaken their capabilities for obtaining bipartite entanglement when starting from a W-class state. I also present that this property holds for certain types of GHZ-class states as well...|$|R
40|$|Abstract Background The linkage {{of records}} which refer to the same entity in {{separate}} data collections is a common requirement in public health and biomedical research. Traditionally, record linkage techniques have required that all the identifying data in which links are sought be revealed {{to at least one}} party, often a third party. This necessarily invades personal privacy and requires complete trust in the intentions of that party and their ability to maintain security and confidentiality. Dusserre, Quantin, Bouzelat and colleagues have demonstrated {{that it is possible to}} use secure <b>one-way</b> hash <b>transformations</b> to carry out follow-up epidemiological studies without any party having to reveal identifying information about any of the subjects – a technique which we refer to as "blindfolded record linkage". A limitation of their method is that only exact comparisons of values are possible, although phonetic encoding of names and other strings can be used to allow for some types of typographical variation and data errors. Methods A method is described which permits the calculation of a general similarity measure, the n -gram score, without having to reveal the data being compared, albeit at some cost in computation and data communication. This method can be combined with public key cryptography and automatic estimation of linkage model parameters to create an overall system for blindfolded record linkage. Results The system described offers good protection against misdeeds or security failures by any one party, but remains vulnerable to collusion between or simultaneous compromise of two or more parties involved in the linkage operation. In order to reduce the likelihood of this, the use of last-minute allocation of tasks to substitutable servers is proposed. Proof-of-concept computer programmes written in the Python programming language are provided to illustrate the similarity comparison protocol. Conclusion Although the protocols described in this paper are not unconditionally secure, they do suggest the feasibility, with the aid of modern cryptographic techniques and high speed communication networks, of a general purpose probabilistic record linkage system which permits record linkage studies to be carried out with negligible risk of invasion of personal privacy. </p...|$|R
40|$|Purpose: The {{purpose of}} this in vitro {{research}} project was to evaluate and compare the wear behavior of human tooth enamel opposing monolithic zirconia and other different ceramic restorative materials and also to observe the tetragonal to monoclinic phase transformation in zirconia-based ceramics that may occur while simulating wear occurring at room temperature in a wet environment. Materials and Methods: A total of sixty samples were prepared for this study. Fifteen discs of glazed zirconia, 15 discs of polished zirconia without glaze, 15 discs of metal ceramic, and 15 discs of lithium disilicate were fabricated. Sixty extracted premolars were collected and randomly divided into four groups of 15 each. The discs and extracted human premolars were placed onto holders on a two-body wear machine under a constant load of 5 kg to simulate the oral wear cycle. A diffractometer was used to analyze phase <b>transformation.</b> <b>One-way</b> analysis of variance and Tukey's post hoc tests was used. Results: The mean loss of height of tooth samples and its standard deviation for Group I (monolithic zirconia with glaze), Group II (mechanically polished monolithic zirconia without glaze), Group III (porcelain fused to metal), and Group IV (glazed monolithic lithium disilicate) was obtained as 0. 2716 ± 0. 1409, 0. 1240 ± 0. 0625, 0. 1567 ± 0. 0996, and 0. 2377 ± 0. 1350, respectively. The highest mean loss in height was observed in Group I and the least was observed in Group II. Conclusion: Mechanically polished zirconia showed {{the least amount of}} enamel wear followed by porcelain fused to metal and glazed monolithic lithium disilicate, whereas glazed monolithic zirconia showed the highest enamel wear...|$|R

