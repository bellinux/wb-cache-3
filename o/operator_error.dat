301|423|Public
5|$|During {{trials of}} the first submarines, the {{propulsion}} system {{was found to be}} prone to failure for a variety of reasons. Most failures were attributed to the fifteen-tank diesel fuel system: the tanks were designed to fill with salt water as they were emptied to maintain neutral buoyancy, but water would regularly enter the engines due to a combination of poor design, gravity separation of the fuel and water being insufficient, and <b>operator</b> <b>error</b> resulting from poor training. Problems were also caused by bacterial contamination of the diesel fuel, which, along with the salt water, would cause the fuel pumps to rust and other components to seize. The fuel-related issues were solved by installing coalescers, improving training and operational procedures, and adding biocides to the fuel.|$|E
25|$|Post {{operative}} {{interview by}} an anesthetist is common practice to elucidate if awareness {{occurred in the}} case. If awareness is reported a case review is immediately performed to identify machine, medication, or <b>operator</b> <b>error.</b>|$|E
25|$|On July 21, 1990, {{two cars}} {{collided}} {{at the bottom}} of the lift hill. Seventeen people went to local hospitals for treatment of minor injuries. Operators tested the ride after the accident and found nothing mechanically or physically wrong with it. <b>Operator</b> <b>error</b> was posited as a cause. It re-opened the next day.|$|E
40|$|We {{consider}} {{methods for}} analysing interactive systems for <b>operator</b> <b>errors</b> leading to hazards. We model an industrial case study using formal methods and show how a HAZOP-based {{approach can be}} used to determine hazardous <b>operator</b> <b>errors.</b> The analysis {{can be used to}} motivate and guide redesign of the system to reduce the likelihood of such errors. The technique is amenable to automation, which we demonstrate using the Possum specification animation tool...|$|R
40|$|<b>Operator</b> quantum <b>error</b> {{correction}} is {{a technique}} for robustly storing quantum information {{in the presence of}} noise. It generalizes the standard theory of quantum error correction, and provides a unified framework for topics such as quantum error correction, decoherence-free subspaces, and noiseless subsystems. This paper develops (a) easily applied algebraic and information-theoretic conditions that characterize when <b>operator</b> quantum <b>error</b> correction is feasible; (b) a representation theorem for a class of noise processes that can be corrected using <b>operator</b> quantum <b>error</b> correction; and (c) generalizations of the coherent information and quantum data processing inequality to the setting of <b>operator</b> quantum <b>error</b> correction...|$|R
5000|$|Reactor accidents, which occur due to <b>operator</b> <b>errors</b> {{and such}} like as {{unintended}} events (e.g. during maintenance or fuel loading) in locations intended to achieve or approach criticality, for example [...] nuclear reactors or experiments.|$|R
25|$|An {{unmanned}} Australian {{spy plane}} on operations over East Timor crashes {{into a house}} in the densely populated eastern suburb of Becora in Dili. Military helicopters were quickly sent to locate the wreckage, and an investigation was scheduled to begin the next day into whether the crash was due to technical failure or <b>operator</b> <b>error.</b>|$|E
25|$|Charles Perrow, in {{his book}} Normal {{accidents}} says that multiple and unexpected failures are built into complex and tightly-coupled systems, such as nuclear power plants. Such accidents often involve <b>operator</b> <b>error</b> and are unavoidable and cannot be designed around. Since {{the terrorist attacks of}} September 11, 2001, there has been heightened concern that nuclear power plants may be targeted by terrorists or criminals, and that nuclear materials may be purloined for use in nuclear or radiological weapons.|$|E
25|$|The {{incident}} devastated Audi {{sales in}} the United States, which did not rebound for 15 years. The initial incidents which prompted the report were found by the National Highway Traffic Safety Administration and Transport Canada to have been attributable to <b>operator</b> <b>error,</b> where car owners had depressed the accelerator pedal instead of the brake pedal. CBS issued a partial retraction, without acknowledging the test results of involved government agencies. Years later, Dateline NBC, a rival to 60 Minutes, {{was found guilty of}} similar tactics regarding the fuel tank integrity of General Motors pickup trucks.|$|E
5000|$|German <b>operator</b> <b>errors</b> in {{transmitting}} {{more than}} one message with the same key, producing a [...] "depth", allowed the derivation of that key. Turingery was applied to such a key stream to derive the cam settings.|$|R
40|$|The Institution of Engineering and Technology 2016. This study {{proposes a}} sampled-data design method for robust control of open {{two-level}} quantum systems with <b>operator</b> <b>errors.</b> The required control performance is characterised using {{the concept of}} a sliding mode domain related to fidelity, coherence or purity. The authors have designed a control law offline and then utilise it online for a two-level system subject to decoherence with <b>operator</b> <b>errors</b> in the system model. They analyse three cases of approximate amplitude damping decoherence, approximate phase damping decoherence and approximate depolarising decoherence. They design specific sampling periods for these cases that can guarantee the required control performance...|$|R
50|$|Functional {{safety is}} the part of the overall safety of a system or piece of {{equipment}} that depends on the system or equipment operating correctly in response to its inputs, including the safe management of likely <b>operator</b> <b>errors,</b> hardware failures and environmental changes.|$|R
25|$|During sea trials, the {{submarine}} was often forced back to port because of equipment problems, where the Navy personnel found that ASC engineers would diagnose and repair systems {{using a combination}} of supplier data and diagnostic tools not available to the sailors. Problems with the training were compounded by an attitude from ASC that problems were always the fault of the Navy operators. However, most were the result of equipment failure, and the problems caused by <b>operator</b> <b>error</b> could be attributed to poor training or a lack of training, both of which were the responsibility of ASC.|$|E
25|$|In the 1940s and 1950s, the Hellmuth Walter KG-conceived turbine used {{hydrogen}} peroxide {{for use in}} submarines while submerged; it {{was found to be}} too noisy and require too much maintenance compared to diesel-electric power systems. Some torpedoes used {{hydrogen peroxide}} as oxidizer or propellant. <b>Operator</b> <b>error</b> in the use of hydrogen-peroxide torpedoes was named as possible causes for the sinkings of HMS Sidon and the Russian submarine Kursk. SAAB Underwater Systems is manufacturing the Torpedo 2000. This torpedo, used by the Swedish Navy, is powered by a piston engine propelled by HTP as an oxidizer and kerosene as a fuel in a bipropellant system.|$|E
25|$|May 1968: Soviet {{submarine}} K-27 reactor near meltdown. 9 people died, 83 {{people were}} injured. In August 1968, the Project 667 A - Yankee class nuclear submarine K-140 {{was in the}} naval yard at Severodvinsk for repairs. On August 27, an uncontrolled increase of the reactor's power occurred following work to upgrade the vessel. One of the reactors started up automatically when the control rods were raised to a higher position. Power increased to 18 times its normal amount, while pressure and temperature levels in the reactor increased to four times the normal amount. The automatic start-up of the reactor {{was caused by the}} incorrect installation of the control rod electrical cables and by <b>operator</b> <b>error.</b> Radiation levels aboard the vessel deteriorated.|$|E
40|$|Abstract. Two {{extensions}} of classical Shepard operators to the fuzzy case are presented. We study Shepard-type interpolation/approximation operators for functions with domain and {{range in the}} fuzzy number’s space and max-product approximation <b>operators.</b> <b>Error</b> estimates are obtained {{in terms of the}} modulus of continuity. ...|$|R
500|$|The {{chain of}} events that led to the crisis at the TMI plant {{included}} several minor equipment failures that <b>operator</b> <b>errors</b> drastically compounded, resulting in a major accident. The Three Mile Island accident is largely seen as a failure of crisis management. According to one reviewer of the book: ...|$|R
40|$|In {{this paper}} we use {{modified}} Taylor expansion of order $r$ on spline functions of degrees 0 and 1 to present two Xuli-type <b>operators.</b> <b>Errors</b> {{of the new}} operators are analyzed and they are compared with Hermite interpolation operator which uses the same data. Finally the efficiency of this method is shown by presenting some illustrative examples...|$|R
25|$|Most {{multimeters}} {{include a}} fuse, or two fuses, which will sometimes prevent {{damage to the}} multimeter from a current overload on the highest current range. (For added safety, test leads with fuses built in are available.) A common error when operating a multimeter is to set the meter to measure resistance or current, and then connect it directly to a low-impedance voltage source. Unfused meters are often quickly destroyed by such errors; fused meters often survive. Fuses used in meters must carry the maximum measuring current of the instrument, but are intended to disconnect if <b>operator</b> <b>error</b> exposes the meter to a low-impedance fault. Meters with inadequate or unsafe fusing were not uncommon; this situation {{has led to the}} creation of the IEC61010 categories to rate the safety and robustness of meters.|$|E
500|$|Following the accident, the {{engineer}} and {{conductor of the}} Capitol Limited filed lawsuits against Amtrak, CSX {{and the state of}} Maryland for $103 million (1996 USD) alleging negligence, singling out the removal of the signal between Kensington and Georgetown Junction and the <b>operator</b> <b>error</b> by the MARC engineer. Both men claimed that the injuries they sustained in the crash [...] "prevent them from returning to work." [...] In 1999, responding to the crash, the Federal Railroad Administration issued comprehensive rules for passenger car design, [...] "the first ...in the 169-year history of rail passenger service." [...] The new rules required that new control cars and multiple units be built to higher crashworthiness standards.|$|E
500|$|The ship ran aground near Newport, Rhode Island in September 1896. <b>Operator</b> <b>error</b> {{combined}} with signal failure were blamed. A few officers, including future Governor of Guam Alfred Walton Hinds, were publicly reprimanded. While under repairs in New York, the yoke that secured the main injection valve in the starboard engine room broke on 9 November 1896. Water pressure unseated the valve {{and allowed the}} compartment to flood as the receiving pipe had earlier been removed for repair. Leaks in the watertight doors, voicepipes and holes in the bulkheads for electrical cables allowed the flooding to spread to the other engine and boiler rooms, the coal bunkers adjacent to them, {{as well as most}} of the magazines and shell rooms. The ship settled to the bottom, but the water was so shallow as to aid salvage efforts. By the 11th most of the water had been pumped out, but she was still drawing too much water to enter the drydock. An estimated [...] of coal would have to be removed to lighten Texas enough to enter the drydock.|$|E
50|$|Radiation therapy sources {{can cause}} beta burns during {{exposure}} of the patients. The sources can be also lost and mishandled, as in the Goiânia accident, during which several people suffered external beta burns and more serious gamma burns, and several died. Numerous accidents also occur during radiotherapy due to equipment failures, <b>operator</b> <b>errors,</b> or wrong dosage.|$|R
50|$|The {{introduction}} of the fourth rotor did not catch Bletchley Park by surprise, because captured material dated January 1941 had made reference to its development as an adaptation of the 3-rotor machine, with the fourth rotor wheel to be a reflector wheel. Indeed, because of <b>operator</b> <b>errors,</b> the wiring of the new fourth rotor had already been worked out.|$|R
40|$|<b>Operator</b> <b>errors</b> are a {{major cause}} of outage in Internet Services and {{there is a lack of}} tools to assist {{operators}} in administering these services. This is because there is no model of operator behavior. In this paper, we describe an infrastructure for collecting data on how human operators administer a three-tier Internet Service and build Operator Models based on the data collected. ...|$|R
500|$|Shortly {{after the}} incident, WMATA General Manager John Catoe {{stated that the}} cause was not known but that [...] "the system is safe." [...] The National Transportation Safety Board (NTSB) began an investigation. WMATA and NTSB {{investigators}} considered several possible causes, which might include <b>operator</b> <b>error,</b> brake failure, fault in the computerized signal and operation system, {{or a combination of}} the three. During rush hour operation, train movement is typically controlled by a centralized computer system, and a separate decentralized system can automatically apply the brakes to prevent a collision. These systems had failed at least once in the past, and the NTSB subsequently identified incompatible specifications, from the maximum deceleration capability of the trains to the deceleration rates used in the wayside system design. [...] The train has a manual emergency brake, which can be applied by the driver {{in the event of an}} imminent collision, if the driver can see and identify the hazard with sufficient time to stop. Officials indicated that the manual brake was indeed engaged. It is possible that the brake system failed to perform as designed, or that the operator applied the brake too late. The lead car of the moving train was two months overdue for scheduled brake maintenance. In a press conference the evening of June 22, Catoe stated that the last car on the stopped train was a CAF 5000-Series car (car 5066), which entered service in 2001, and that the lead car on the moving train was a Rohr Industries 1000-Series car. WMATA later confirmed that all of the cars on the moving train were 1000-Series.|$|E
2500|$|A small {{military}} test reactor exploded at the Stationary Low-Power Reactor Number One in Idaho Falls in January 1961, causing 3 fatalities. This {{was caused}} by a combination of dangerous reactor design plus either sabotage, <b>operator</b> <b>error</b> by experienced operators. [...] A further partial meltdown at the Enrico Fermi Nuclear Generating Station in Michigan in 1966.|$|E
2500|$|Normal Accidents contributed key {{concepts}} {{to a set}} of intellectual developments in the 1980s that revolutionized the conception of safety and risk. It made the case for examining technological failures as the product of highly interacting systems, and highlighted organizational and management factors as the main causes of failures. Technological disasters could no longer be ascribed to isolated equipment malfunction, <b>operator</b> <b>error</b> or acts of God.|$|E
40|$|Growing use of {{computers}} in safety-critical systems increases the need for Human Computer Interfaces (HCIs) to be both smarter | to detect human errors | and better designed | to reduce likelihood of errors. We are developing methods for determining the likelihood of <b>operator</b> <b>errors</b> which combine current theory on the psychological causes of human errors with formal methods for modelling human-computer interaction. We present the models of the HCI and operator in an air-trac control (ATC) system simulation, and discuss the role of these in the prediction of human error rates. Keywords: HCI, ATC, cognitive model, error rate. 1 Introduction A human-computer interface is safety-critical when the potential arises for injury or loss of life from defects {{in the design of}} the HCI. Safety has frequently been compromised and lives have been lost because of <b>operator</b> <b>errors</b> caused by HCI design deciencies (e. g., see [12]). Existing models of human error do not provide a precise specic [...] ...|$|R
40|$|This report {{provides}} {{a description of}} initiatives within the Federal Energy Regulatory Commission and the Departments of Energy, Homeland Security, and Defense to protect the physical electrical utility infrastructure from outages caused by a range of activities including system <b>operator</b> <b>errors,</b> weather-related damage, and terrorist attacks. While the electric utility industry has primary responsibility, federal and state government agencies also have been addressing physical security concerns...|$|R
5000|$|Three Mile Island {{accident}} near Harrisburg, Pennsylvania (United States), 28 March 1979. [...] A {{combination of}} design and <b>operator</b> <b>errors</b> caused a gradual loss of coolant, leading to a partial meltdown. An unknown amount of radioactive gases were released into the atmosphere, so injuries and illnesses that {{have been attributed to}} this accident can be deduced from epidemiological studies but can never be proven.|$|R
2500|$|On December 10, 2015, a Red Line {{train in}} revenue service {{traveled}} from Braintree to North Quincy without an operator {{in the cab}} before it was stopped by cutting power to the third rail. [...] The MBTA initially said that the train {{appeared to have been}} tampered with and the incident was not an accident, but later determined <b>operator</b> <b>error</b> to have been the cause.|$|E
2500|$|On July 26, 1994, five {{unidentified}} riders {{were injured}} when two cars collided in {{an incident that}} inspectors said was due to <b>operator</b> <b>error.</b> After the accident, the park filed suit against Louisville, Kentucky television station WHAS-TV for reporting on the accident in a misleading and malicious manner. The station had inaccurately reported that the ride malfunctioned, was dangerous, and that the park had removed a [...] "key component" [...] of the ride. The station lost the lawsuit and was ordered to pay US$3 million to the park.|$|E
2500|$|Many sound {{reinforcement}} loudspeaker systems incorporate protection circuitry, preventing {{damage from}} excessive power or <b>operator</b> <b>error.</b> [...] Positive temperature coefficient resistors, specialized current-limiting light bulbs, and circuit-breakers were used {{alone or in}} combination to reduce driver failures. [...] During the same period, the professional sound reinforcement industry made the Neutrik Speakon NL4 and NL8 connectors the standard input connectors, replacing 1/4" [...] jacks, XLR connectors, and Cannon multipin connectors which are all limited {{to a maximum of}} 15 amps of current. [...] XLR connectors are still the standard input connector on active loudspeaker cabinets.|$|E
5000|$|Typex avoided <b>operator</b> copying <b>errors,</b> as the {{enciphered}} or deciphered {{text was}} automatically printed on paper tape.|$|R
40|$|This paper {{describes}} the online analysis of simulation data {{in real time}} using the Crew Activity Tracking System (CATS). CATS compares actual operator actions to a model of nominal operator procedures to track operator activities and detect possible <b>operator</b> <b>errors.</b> A suite of system state visualization tools, together with CATS, enables researchers to detect problematic operator-automation interactions as they occur, and replay the data to investigate interesting issues in detail. 1...|$|R
50|$|Most {{fault-tolerant}} {{computer systems}} {{are designed to}} handle several possible failures, including hardware-related faults such as hard disk failures, input or output device failures, or other temporary or permanent failures; software bugs and errors; interface errors between the hardware and software, including driver failures; <b>operator</b> <b>errors,</b> such as erroneous keystrokes, bad command sequences or installing unexpected software and physical damage or other flaws introduced to the system from an outside source.|$|R
