147|371|Public
5000|$|Assume {{an input}} matrix of 3×3 pixels where the center most pixel is the pixel to be scaled, and an <b>output</b> <b>matrix</b> of 2×2 pixels (i.e., the scaled pixel) ...|$|E
50|$|Below is the {{sequential}} pseudo-code for multiplication and {{addition of}} two matrices where {{the result is}} stored in the matrix C. The pseudo-code for multiplication calculates the dot product of two matrices A, B and stores the result into the <b>output</b> <b>matrix</b> C.|$|E
50|$|The Yamaha PM1000 {{mixing console}} was a {{significant}} product in the professional audio industry because of its many advanced features and reasonable price. Introduced in 1974 it incorporated many innovative features such as a modular design using channel strips and output strips, a 4 bus design, and an <b>output</b> <b>matrix</b> mixer. Because it was manufactured by an established company it was readily accepted in many audio industries including sound reinforcement, recording, and audio for video. It also established {{a reputation for being}} rugged in the often abusive environment of touring sound reinforcement.|$|E
30|$|<b>Output</b> {{low-rank}} <b>matrix</b> X^k.|$|R
40|$|Synchronization in {{networks}} of discrete-time linear time-invariant systems is considered under relative actuation. Neither input nor <b>output</b> <b>matrices</b> {{are assumed to}} be commensurable. A distributed algorithm that ensures synchronization via dynamic relative output feedback is presented. Comment: 10 pages, 2 figure...|$|R
40|$|Abstract:- The {{paper is}} devoted to the {{description}} of new collective method for pattern recognition based on logical correction over set of methods of different nature. <b>Output</b> <b>matrices</b> of the methods are processed according to the potentiality principle which allows increasing of recognition reliability...|$|R
5000|$|A {{controllable}} {{system is}} not necessarily output controllable. For example, if matrix D = 0 and matrix C does not have full row rank, then some positions of the output are masked by the limiting structure of the <b>output</b> <b>matrix.</b> Moreover, even though the system can be moved to any state in finite time, {{there may be some}} outputs that are inaccessible by all states. A trivial numerical example uses D=0 and a C matrix with at least one row of zeros; thus, the {{system is not}} able to produce a non-zero output along that dimension.|$|E
5000|$|The {{master control}} section {{is used to}} adjust the levels of the overall output of the mixer. The master control section has {{sub-group}} faders, master faders, master auxiliary mixing bus level controls and auxiliary return level controls. In addition it may have solo monitoring controls, a stage [...] "talk-back" [...] microphone control (so the sound engineer can talk to the band, who may be some distance away at a live show or who might be separated in an isolation booth in the recording studio), muting controls and an <b>output</b> <b>matrix</b> mixer. On smaller mixers the inputs are on {{the left of the}} mixing board and the master controls are on the right. In larger mixers, the master controls are in the center with input faders and channel strips on both sides.|$|E
5000|$|There {{are many}} other {{variations}} on the Cooley-Tukey algorithm. Mixed-radix implementations handle composite sizes {{with a variety of}} (typically small) factors in addition to two, usually (but not always) employing the O(N2) algorithm for the prime base cases of the recursion it is also possible to employ an N log N algorithm for the prime base cases, such as Rader's or Bluestein's algorithm. Split radix merges radices 2 and 4, exploiting the fact that the first transform of radix 2 requires no twiddle factor, in order to achieve what was long the lowest known arithmetic operation count for power-of-two sizes, although recent variations achieve an even lower count. [...] (On present-day computers, performance is determined more by cache and CPU pipeline considerations than by strict operation counts; well-optimized FFT implementations often employ larger radices and/or hard-coded base-case transforms of significant size.) Another {{way of looking at the}} Cooley-Tukey algorithm is that it re-expresses a size N one-dimensional DFT as an N1 by N2 two-dimensional DFT (plus twiddles), where the <b>output</b> <b>matrix</b> is transposed. The net result of all of these transpositions, for a radix-2 algorithm, corresponds to a bit reversal of the input (DIF) or output (DIT) indices. If, instead of using a small radix, one employs a radix of roughly √N and explicit input/output matrix transpositions, it is called a four-step algorithm (or six-step, depending on the number of transpositions), initially proposed to improve memory locality, e.g. for cache optimization or out-of-core operation, and was later shown to be an optimal cache-oblivious algorithm.|$|E
30|$|Step three: Calculate the <b>output</b> weight <b>matrix</b> β.|$|R
40|$|ABSTRACT:- In {{this paper}} we {{describe}} and implement an algorithm for the exact {{solution of the}} Linear Ordering problem. Linear Ordering {{is the problem of}} finding a linear order of the nodes of a graph such that the sum of the weights which are consistent with this order is as large as possible. It is an NP- Hard combinatorial optimisation problem with a large number of applications, including triangulation of input- <b>output</b> <b>matrices</b> in Economics, aggregation of individual preferences and ordering of teams in sports. We implement an algorithm for the exact solution using cutting plane and branch and bound procedures. The program developed is then applied to the triangulation problem for the input- output tables. We have been able to triangulate input- <b>output</b> <b>matrices</b> of size up to 41 x 41...|$|R
40|$|The {{paper is}} devoted to the {{description}} of hybrid pattern recognition method developed by research groups from Russia, Armenia and Spain. The method is based upon logical correction over the set of conventional neural networks. <b>Output</b> <b>matrices</b> of neural networks are processed according to the potentiality principle which allows increasing of recognition reliability...|$|R
5000|$|The goal is {{to design}} a high-gain state {{observer}} that estimates the state vector [...] using only information from the measurement [...] Hence, let the vector [...] be the estimates of the [...] states. The observer takes the formwhere [...] is a nonlinear function of the error between estimated state [...] and the output , and [...] is an observer gain vector that serves a similar purpose as in the typical linear Luenberger observer. Likewise, letwhere [...] is a column vector. Additionally, let [...] be the state estimator error. That is, [...] The error dynamics are thenwhere [...] is the estimator error for the first state estimate. The nonlinear control law [...] can be designed to enforce the sliding manifoldso that estimate [...] tracks the real state [...] after some finite time (i.e., [...] ). Hence, the sliding mode control switching functionTo attain the sliding manifold, [...] and [...] must always have opposite signs (i.e., [...] for essentially all [...] ). However,where [...] is {{the collection of the}} estimator errors for all of the unmeasured states. To ensure that , letwhereThat is, positive constant [...] must be greater than a scaled version of the maximum possible estimator errors for the system (i.e., the initial errors, which are assumed to be bounded so that [...] can be picked large enough; al). If [...] is sufficiently large, it can be assumed that the system achieves [...] (i.e., [...] ). Because [...] is constant (i.e., 0) along this manifold, [...] as well. Hence, the discontinuous control [...] may be replaced with the equivalent continuous control [...] whereSoThis equivalent control [...] represents the contribution from the other [...] states to the trajectory of the output state [...] In particular, the row [...] acts like an output vector for the error subsystemSo, to ensure the estimator error [...] for the unmeasured states converges to zero, the [...] vector [...] must be chosen so that the [...] matrix [...] is Hurwitz (i.e., the real part of each of its eigenvalues must be negative). Hence, provided that it is observable, this [...] system can be stabilized {{in exactly the same way}} as a typical linear state observer when [...] is viewed as the <b>output</b> <b>matrix</b> (i.e., [...] ""). That is, the [...] equivalent control provides measurement information about the unmeasured states that can continually move their estimates asymptotically closer to them. Meanwhile, the discontinuous control [...] forces the estimate of the measured state to have zero error in finite time. Additionally, white zero-mean symmetric measurement noise (e.g., Gaussian noise) only affects the switching frequency of the control , and hence the noise will have little effect on the equivalent sliding mode control [...] Hence, the sliding mode observer has Kalman filter - like features.|$|E
30|$|Step two: Calculate {{the hidden}} layer <b>output</b> <b>matrix</b> H.|$|E
30|$|Stage 2 Calculate the <b>output</b> <b>matrix</b> of {{the hidden}} layer, H.|$|E
30|$|Considering the {{response}} {{order of the}} DSRs, the power <b>output</b> control <b>matrix</b> is deduced from the unified state model to realize the real-time power output control of the DSRs. Once the required power change of the DSRs is determined, {{the values of the}} control variables in the power <b>output</b> control <b>matrix</b> are correspondingly generated.|$|R
30|$|Therefore, {{the mode}} {{parameters}} including frequency, damping {{and the corresponding}} mode shape may be identified by estimating the state matrix of the linearized power system, and its eigen decomposition, from measured data. With the data-driven SSI technique proposed in Section  3, mode parameters are obtained by identifying the state and <b>output</b> <b>matrices</b> firstly and then performing eigen decomposition.|$|R
5000|$|... #Caption: A {{screenshot}} of Yamaha's Studio Manager software {{showing the}} M7CL's embedded 19×8 matrix mixer section. All 16 mix buses plus the main L/R/Mono buses are routed to 8 <b>matrix</b> <b>outputs.</b> The individual <b>matrix</b> level controls are shown as horizontal bars in dark orange. The 8 <b>matrix</b> <b>outputs</b> {{are controlled by}} 8 white faders at the bottom.|$|R
30|$|The <b>output</b> <b>matrix</b> of {{the deep}} {{learning}} model is the extracted iris feature.|$|E
40|$|We {{consider}} the co-design problem of sparse output feedback and row/column-sparse <b>output</b> <b>matrix.</b> A row-sparse (resp. column-sparse) <b>output</b> <b>matrix</b> implies {{a small number}} of outputs (resp. sensor measurements). We impose row/column-cardinality constraint on the <b>output</b> <b>matrix</b> and the cardinality constraint on the output feedback gain. The resulting nonconvex, nonsmooth optimal control problem is solved by using the proximal alternating linearization method (PALM). One advantage of PALM is that the proximal operators for sparsity constraints admit closed-form expressions and are easy to implement. Furthermore, the bilinear matrix function introduced by the multiplication of the feedback gain and the <b>output</b> <b>matrix</b> lends itself well to PALM. By establishing the Lipschitz conditions of the bilinear function, we show that PALM is globally convergent and the objective value is monotonically decreasing throughout the algorithm. Numerical experiments verify the convergence results and demonstrate the effectiveness of our approach on an unstable system with 60, 000 design variables...|$|E
3000|$|R, respectively, {{according}} to any continuous probability distribution, then the hidden layer <b>output</b> <b>matrix</b> [...]...|$|E
40|$|An {{approach}} for model reduction of linear conservative or weakly damped mechanical systems is proposed. It {{is based on}} the balancing of an associated gradient system. It uses the joint knowledge of the system matrix and the input and <b>output</b> <b>matrices</b> of the Hamiltonian system. The key idea is to associate with the Hamiltonian system a gradient (or reciprocal) syste...|$|R
40|$|This article {{extends the}} tensor network Kalman filter to <b>matrix</b> <b>outputs</b> with an {{application}} in recursive identification of discrete-time nonlinear multiple-input-multiple-output (MIMO) Volterra systems. This extension completely supersedes previous work, where only $l$ scalar outputs were considered. The Kalman tensor equations are modified to accommodate for <b>matrix</b> <b>outputs</b> and their implementation using tensor networks is discussed. The MIMO Volterra system identification application requires {{the conversion of}} the <b>output</b> model <b>matrix</b> with a row-wise Kronecker product structure into its corresponding tensor network, for which we propose an efficient algorithm. Numerical experiments demonstrate both the efficacy of the proposed matrix conversion algorithm and the improved convergence of the Volterra kernel estimates when using <b>matrix</b> <b>outputs...</b>|$|R
40|$|We {{present a}} new {{parallel}} algorithm for computing arbitrary functions of triangular matrices. The presented algorithm is the rst one to date requiring polylogarithmic time, and computes an arbitrary function of an n n triangular matrix in O(log 3 n) time using O(n 6) processors. The algorithm requires the eigenvalues of the input matrix be distinct, and {{makes use of}} the commutativity relationship between the input and <b>output</b> <b>matrices.</b> ...|$|R
40|$|Key word: {{terminal}} link, {{degree of}} freedom, screw theory kinematics <b>output</b> <b>matrix</b> Abstract. The terminal link of serial robot has {{six degrees of}} freedom at most. This paper presents another method based on the screw theory and kinematics <b>output</b> <b>matrix,</b> which can conveniently calculate the degree of freedom of terminal link about serial robot, and meanwhile lay good foundation for researching the parallel robot...|$|E
30|$|<b>Output</b> <b>Matrix</b> Free (200 – 300), {{connections}} through XOR matrices, {{but only}} with those STP components {{that are responsible for}} circuit response receiving.|$|E
3000|$|Select an {{infinitely}} {{differentiable function}} g([...] [...]. [...]) as the activation of each hidden layer neuron, and calculate the <b>output</b> <b>matrix</b> H (Eq.  5) of hidden layer.|$|E
30|$|B = b_ij is an <b>output</b> {{probability}} <b>matrix.</b> b_ij {{indicates a}} probability of output symbol o_j from state q_i.|$|R
40|$|In {{this paper}} we {{consider}} two different model reduction approaches for elastic multibody systems with moving loads. The first approach {{is based on}} a parametric formulation of the input and <b>output</b> <b>matrices</b> and application of parametric model reduction. In the second approach, we approximate the time-varying input matrix in a low-dimensional subspace and perform model reduction of a time-invariant system. Both approaches are compared for a thin-walled cylinder model with a rotating force...|$|R
40|$|The aim of {{this paper}} is to {{introduce}} a new generalization of the von Neumann model and to show how this model can be applied in practical economic planning. The von Neumann theory of growth is one of the best known models in mathematical economics. Since 1937, when von Neumann first published his famous article, many authors have tried to generalize his results and, therefore, have investigated in great depth the properties of the original model and those of its various generalized forms. Kemeny, Morgenstern, and Thompson (1956) changed von Neumann's original assumptions and made the model more plausible for economic applications. In 1960 Morishima introduced a nonlinear generalization of the model, in which the input and <b>output</b> <b>matrices</b> are nonlinear functions of variables. In 1974 J. Los, introducing revenue and cost matrices that are generally different from the usual input and <b>output</b> <b>matrices,</b> extended the von Neumann theory of growth to the case of asymmetric models. Morgenstern and Thompson (1976) opened the model by including foreign trade, as well as taxes and subsidies. The model presented in this paper is an open, nonlinear, and asymmetric generalization of the von Neumann model...|$|R
40|$|In this paper, {{we propose}} a new {{supervised}} learning method {{to improve the}} learning speed for feed-forward neural networks. Our method is different from traditional supervised learning methods (such as back-propagation) that find a one-to-one mapping between the given input pattern matrix and the desired output pattern matrix. Instead, it finds one of the oneto -many mappings between the input matrix and an intermediate <b>output</b> <b>matrix,</b> and transforms the intermediate <b>output</b> <b>matrix</b> to the desired <b>output</b> <b>matrix</b> in one step using linear mapping techniques. Learning is faster with our method because there exist many intermediate output matrices, and learning can stop whenever one such matrix is found. Our extensive experimental results show that our learning algorithm converges to within a reasonable range of error after a few training epochs, making it suitable for dynamic realtime applications in which the network {{may need to be}} re-trained periodically. 1. Introduction In this paper we pr [...] ...|$|E
40|$|This is {{the first}} of two papers to {{describe}} a matrix sparsification algorithm that takes a general real or complex matrix as input and produces a sparse <b>output</b> <b>matrix</b> of the same size. The non-zero entries in the output are chosen to minimize changes to the singular values and singular vectors corresponding to the near null-space of the input. The <b>output</b> <b>matrix</b> is constrained to preserve left and right null-spaces exactly. The sparsity pattern of the <b>output</b> <b>matrix</b> is automatically determined or can be given as input. If the input matrix belongs to a common matrix subspace, we prove that the computed sparse matrix belongs to the same subspace. This works without imposing explicit constraints pertaining to the subspace. This property holds for the subspaces of Hermitian, complex-symmetric, Hamiltonian, circulant, centrosymmetric, and persymmetric matrices, and for each of the skew counterparts. Applications of our method include computation of reusable sparse preconditioning matrices for reliable and efficient solution of high-order finite element systems. The second paper in this series describes our open-source implementation, and presents further technical details...|$|E
3000|$|... where C∈R^m× n is the <b>output</b> <b>matrix.</b> The {{value of}} the output vector Y(z) {{represents}} the measurement produced by the sensors that is affected by a noise V(z) that is the Z-transform of v [...]...|$|E
40|$|In this paper, {{the problem}} of finite and {{infinite}} horizon robust Kalman filtering for uncertain discrete-time systems is studied. The system under consideration is subject to time-varying norm-bounded parameter uncertaintyinboth the state and <b>output</b> <b>matrices.</b> The problem addressed is the design of linear filters having an error variance with aguaranteed upper bound for any allowed uncertainty. A novel technique is developed for robust filter design. This technique gives necessary and sufficient conditions {{to the design of}} robust filters over finite and infinite horizon...|$|R
50|$|Inserts {{might be}} found on {{monoaural}} mixer inputs, monoaural and stereo subgroups, auxiliary inputs, main <b>outputs</b> and <b>matrix</b> <b>outputs.</b> They're rarely found on stereo line level inputs. EQs are commonly inserted on monitor mixer output mixes so that the monitor engineer can use his own wedge and the PFL/Solo bus {{to hear what the}} artist's wedge sounds like without having to climb on stage to check.|$|R
40|$|Major {{issues in}} system {{identification}} are summarized and recent advances are reviewed. Modal testing and system identification used in control theory are examined, and the mathematical relationships and conversions {{of the models}} appropriate to modal testing and those appropriate to modern control design methods are discussed. The importance of obtaining input and <b>output</b> <b>matrices</b> in modal testing is emphasized, and the changes that may be needed in modal testing procedures {{to meet the needs}} of the control system designer are addressed. Directions for future research are considered...|$|R
