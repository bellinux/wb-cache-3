8|237|Public
500|$|In early 1945, XXXCorps {{took part}} in Operation Veritable, during which the German Army was finally forced back over the Rhine. The corps {{employed}} firepower on a massive scale, and [...] "every trick that had been learnt {{during the past two}} and a half years was brought into play, and several new ones added". [...] For a short period XXX Corps had nine divisions under its command. Before the operation, Horrocks accepted an offer to use Bomber Command to attack the town of Cleves, assisting the advance of the 15th (Scottish) Infantry Division. The bombers released [...] of high explosive that devastated the town. Horrocks later said that this had been [...] "the most terrible decision I had ever taken in my life" [...] and that he felt [...] "physically sick" [...] when he saw the bombers <b>overhead.</b> <b>Operation</b> Veritable was successful; by the evening of 9 February (D+1) XXXCorps had broken through the Siegfried Line and into Germany with only light casualties. Bremen was captured on 26 April, exposing the Sandbostel concentration camp, Stalag X-B. The corps had reached Cuxhaven by the time hostilities ceased.|$|E
50|$|In {{the centre}} of Brussels some tram lines were fitted with conduits, the last ones being {{converted}} to <b>overhead</b> <b>operation</b> during World War II.|$|E
50|$|The Midland {{line was}} used for an early trial of electrification, opened between 13 April and 14 September 1908 using 6600 V AC at 25 Hz. In 1953, it was {{converted}} to 50 Hz as a trial, and this experiment led to the 25 kV, 50 Hz system becoming standard for new electrification. Latterly, former LNWR Euston to Watford EMU's ran on the Morecambe and Heysham line, converted to AC <b>overhead</b> <b>operation.</b> The branch remained electrified until it closed in 1966.|$|E
30|$|The <b>overhead</b> <b>operations</b> which {{waste energy}} are {{successful}} reception of packets (overhearing nodes), reception of collided packet, transmission of collided packet and staying idle. It is {{observed that the}} energy consumed in successful transmission and reception of data by destination and relay is almost constant. Here {{it is interesting to}} see that most of the energy is consumed in listening/overhearing by other nodes. This increases with respect to the number of nodes. In addition to this the energy consumed in receiving collided packet and staying idle also increases with the increase in number of nodes.|$|R
5000|$|... #Caption: <b>Overhead</b> {{projector}} in <b>operation</b> {{during a}} classroom lesson ...|$|R
5000|$|... #Caption: <b>Overhead</b> {{projector}} in <b>operation,</b> with a transparency being flashed ...|$|R
5000|$|In early 1945, XXX Corps {{took part}} in Operation Veritable, during which the German Army was finally forced back over the Rhine. The corps {{employed}} firepower on a massive scale, and [...] "every trick that had been learnt {{during the past two}} and a half years was brought into play, and several new ones added". [...] For a short period XXX Corps had nine divisions under its command. Before the operation, Horrocks accepted an offer to use Bomber Command to attack the town of Cleves, assisting the advance of the 15th (Scottish) Infantry Division. The bombers released 1384 LT of high explosive that devastated the town. Horrocks later said that this had been [...] "the most terrible decision I had ever taken in my life" [...] and that he felt [...] "physically sick" [...] when he saw the bombers <b>overhead.</b> <b>Operation</b> Veritable was successful; by the evening of 9 February (D+1) XXX Corps had broken through the Siegfried Line and into Germany with only light casualties. Bremen was captured on 26 April, exposing the Sandbostel concentration camp, Stalag X-B. The corps had reached Cuxhaven by the time hostilities ceased.|$|E
5000|$|Washington, D.C. {{had a large}} {{network of}} conduit lines, to avoid wires. Some lines used {{overhead}} wires when they approached rural or suburban areas. The last such line ran to Cabin John, Maryland. The current collector [...] "plow" [...] was mounted underneath the car on a fitting just forward of the rear truck on PCC streetcars. It had two cables with female connectors on cables to attach to matching cables of the car's electrical system. A [...] "plowman" [...] was assigned at each changeover point from overhead trolley wire to conduit to remove the cable attachments {{to the car and}} stow the plow, which did not remain with the car and was reattached in an incoming car running on overhead wire. The lower section of the plow [...] "board" [...] was drawn by the moving car within the cavity of the conduit. Because of this usage, many of Washington's streetcars carried trolley poles, which were lowered while operating in {{the central part of the}} city; when the cars reached a point where they switched to <b>overhead</b> <b>operation,</b> they stopped over a plow pit where the conduit plows were detached and the trolley poles raised, the reverse operation taking place on inbound runs. The 'pit' here has the meaning analogous to racing circuit pits rather than a depression in the road.|$|E
30|$|Influence of sorting {{operation}}. After {{the pattern}} string of network data is {{read in the}} MWM, all the network data service client mode strings are quickly sorted. This operation is not obvious {{when the number of}} pattern strings is small, but when the number of pattern strings of network data is very large, this operation will seriously affect the initialization speed. The {{most important thing is that}} such a large <b>overhead</b> <b>operation</b> is not well used later.|$|E
50|$|GCM {{is ideal}} for {{protecting}} packetized data because it has minimum latency and minimum <b>operation</b> <b>overhead.</b>|$|R
30|$|Despite recent {{developments}} of WiMAX networks, IEEE 802.11 -based WLAN networks {{will still be}} used in local environments and continue their growth to become more ubiquitous and to challenge WiMAX networks in larger areas. The Federal Communications Commission (FCC) allocated 75 MHz spectrum to dedicated short range communications (DSRC) [37] at 5.9 GHz frequency band to vehicle-to-vehicle (V 2 V) and vehicle-to-infrastructure (V 2 I) communications in 1999. DSRC was standardized in the draft IEEE 802.11 p [38], a variant of IEEE 802.11 a standard adjusted for low <b>overhead</b> <b>operations,</b> which supports data rates up to 6 Mbps and transmission ranges up to 300 m. In vehicular settings it is mostly assumed that WLAN radios comply with DSRC 802.11 p standard.|$|R
40|$|Safety and {{congestion}} {{are two of}} {{the biggest}} problems on our roads today. Is there a way to reduce accidents, save money, save lives? Well the answer is yes & it’s called Dedicated Short Range Communication (DSRC). DSRC technology uses IEEE 802. 11 a adjusted for low <b>overhead</b> <b>operations</b> in the DSRC spectrum, standardized as IEEE 802. 11 p. We focus on this IEEE 802. 11 p MAC protocol. This paper elicits the perfor-mance of Packet Delivery Ratio, Delay, Throughput using IEEE 802. 11 p and is compared with the values obtained for IEEE 802. 11. Results after analysis evince that 802. 11 p is much more suitable than 802. 11 for vehicular communications showing better packet delivery ratio, throughput, less delay and other advantageous improvements...|$|R
40|$|Simplex {{gradients}} are {{an essential}} feature of many derivative free optimization algorithms, {{and can be}} employed, for example, {{as part of the}} process of defining a direction of search, or as part of a termination criterion. The calculation of a general simplex gradient in R^n can be computationally expensive, and often requires an <b>overhead</b> <b>operation</b> count of O(n^ 3) and in some algorithms a storage overhead of O(n^ 2). In this work we demonstrate that the linear algebra overhead and storage costs can be reduced, both to O(n), when the simplex employed is regular and appropriately aligned. We also demonstrate that a second order gradient approximation can be obtained cheaply from a combination of two, first order (appropriately aligned) regular simplex gradients. Moreover, we show that, for an arbitrarily aligned regular simplex, the gradient can be computed in only O(n^ 2) operations. Comment: 25 page...|$|E
40|$|Dynamic Spectrum Access (DSA) allows {{unlicensed}} wireless {{devices to}} opportunistically access unoccupied licensed spectrum bands. DSA yields {{efficient spectrum utilization}} which can greatly improve wireless networking performance. In this paper, we advocate application-awareness to effectively manage the side-effects of DSA that can offset its benefits by adversely impacting application QoS. Simple application hints {{are found to be}} able to serve as key inputs in evaluating current spectrum conditions relative to application needs, leading to an informed DSA mechanism that minimizes the impact of undesirable DSA side-effects. Towards this goal, we propose a wireless service architecture called Context-Aware Spectrum Agility (CASA). The key elements of CASA are: (a) semantic dependency equations that provide the relationship between application-layer QoS state and lower-layer DSA parameters, (b) CASA Algorithm that adapts DSA parameters and activities to better suit application needs, and, (c) a low overhead interface to provide application context to DSA. CASA has been explicitly designed with the goals of practical deployment, low <b>overhead</b> <b>operation,</b> and is compatible with any DSA protocol. Compared to state-of-art DSA, the deployment of CASA along with DSA protocols is shown to improve QoS metrics, such as delay and jitter, by an average of 30 an...|$|E
50|$|Inband T1s {{are also}} capable of {{carrying}} CID and ANI information if they are configured by the carrier by sending DTMF *ANI*DNIS*. However, PRIs handle this more efficiently. While an inband T1 seemingly has a slight advantage due to 24 lines being available to make calls (as opposed to a PRI that has 23), each channel in an inband T1 must perform its own setup and tear-down of each call. A PRI uses the 24th channel as a data channel to perform all the <b>overhead</b> <b>operations</b> of the other 23 channels (including CID and ANI). Although an inband T1 has 24 channels, the 23 channel PRI can set up more calls faster due to the dedicated 24th signalling channel (D Channel).|$|R
5000|$|Increases <b>overhead</b> on update <b>operations</b> as {{each site}} {{containing}} the replica {{needed to be}} updated {{in order to maintain}} consistency.|$|R
40|$|Three {{parallel}} algorithms {{were compared}} for the direct solution of tridiagonal linear systems of equations. The algorithms {{are suitable for}} computers such as ILLIAC 4 and CDC STAR. For array computers similar to ILLIAC 4, cyclic odd-even reduction has the least operation count for highly structured sets of equations, and recursive doubling has the least count for relatively unstructured sets of equations. Since the difference in operation counts for these two algorithms is not substantial, their relative running times may be more related to <b>overhead</b> <b>operations,</b> which are not measured in this paper. The third algorithm, based on Buneman's Poisson solver, has more arithmetic operations than the others, {{and appears to be}} the least favorable. For pipeline computers similar to CDC STAR, cyclic odd-even reduction appears to be the most preferable algorithm for all cases...|$|R
40|$|Abstract — A {{hybrid model}} was {{developed}} to predict the zeroquantized discrete cosine transform (ZQDCT) coefficients for intra blocks in our previous work. However, the complicated overhead computations seriously degrade its performance in complexity reduction. This paper proposes a new prediction algorithm with less <b>overhead</b> <b>operations.</b> First, each �� � pixel block at the input of transform is resized to a ����� � �block. Then, this downsized block is decomposed into a mean value and a residual pixel block. Finally, the �� � 2 -D DCT is computed from the mean value and this residual pixel block. Experimental {{results show that the}} proposed method reduces more redundant computations than the competing techniques and better real-time performance can be expected. This is particularly suitable for low-power processors with video sequences or great number of images to encode. 1...|$|R
40|$|In {{this paper}} we {{investigate}} how shared memory clusters {{can take advantage}} of replication to tolerate single system failures. We start from a shared virtual memory protocol (GeNIMA) that has been optimized for low-latency, highbandwidth system area networks. We propose a set of extensions that maintain shared data consistent in the presence of failures and support SMP nodes. Our scheme uses dynamic data replication to guarantee that no shared data is lost when a failure occurs. A failing node is removed from the system {{and the rest of the}} nodes recover dynamically and can continue with application execution. We deal both with data consistency and lock synchronization issues. Our approach leverages the low initiation <b>overhead</b> <b>operations</b> provided by modern system area networks as well as the availability of network bandwidth to guarantee data consistency in the presence of failures, and the low-latency operations for dealing with lock synchronization issues...|$|R
40|$|Abstract. Techniques for {{aggressive}} optimization and parallelization of applications {{can have the}} side-effect of introducing copy instructions, register-to-register move instructions, into the generated code. This pre-serves program correctness while avoiding the need for global search-and-update of registers. However, copy instructions only transfer data between registers while requiring the use of system resources (ALUs) and are essentially <b>overhead</b> <b>operations</b> which can potentially limit perfor-mance. Conventional copy propagation and copy removal techniques are not powerful enough to remove these copies as, during loop paralleliza-tion, the lifetimes of the values copied may span over loop boundaries. In this paper, we present a technique for copy removal that incrementally unrolls a loop body and re-allocates registers to values so that no copy operations are required. We also present a heuristic version that limits the amount of unrolling and present experimentation that demonstrates the necessity of copy removal in gaining improved code performance. ...|$|R
30|$|The first {{objective}} function consists of nine cost components. Terms (1)–(7) {{are the same}} as those formulated by Kia et al. (2013) and calculate the total cost of intra-cell and inter-cell material handling, cell reconfiguration, machine purchase, machine <b>overhead,</b> machine <b>operation,</b> and forming cells. Finally, terms (8) and (9) which are added to the previous model are for outsourcing and inventory holding costs.|$|R
40|$|Governments {{across the}} globe try to re-balance their budgets by rationalizing <b>overhead</b> <b>operations.</b> When overhead-reducing {{policies}} are adopted, {{it is important to}} understand why some central government organizations have a higher overhead than others, and why organizational models to produce overhead efficiencies are used to different extents. This study focuses on the Flemish context to analyze differences between central government organizations in the size and organization of two overhead processes: human resources management (HRM) and finance and control (FIN). Significant effects are found for autonomy, organizational size, spatial dispersion and budgetary stress, yet effects vary according to whether HRM or FIN is considered and whether the focus is on the size or the organization of HRM or FIN. Our findings have practical implications to get a process-sensitive understanding of the size and organization of overhead, and theoretical implications as they cast light on factors that shape decision-making in public organizations. status: accepte...|$|R
3000|$|... d, which {{proves the}} {{compensation}} of WF-MAC {{in terms of}} throughput and medium access delay over additional protocol <b>operation</b> <b>overhead.</b> The weighted fair channel selection policy of WF-MAC is visualized in Fig. 6 [...]...|$|R
40|$|In {{numerous}} mobile applications involving complex video, image, signal, communication {{or security}} processing, massive parallelism is {{mainly in the}} form of data-level parallelism (DLP). However, the sorts and amount of DLP parallelism in applications vary due to different computational characteristics of applications. On the contrary, most of the processors today include single-width SIMD (vector) hardware to exploit DLP. However, single-width SIMD architectures may not be optimal to serve applications with varying DLP and they may cause performance and energy inefficiency. We propose the usage of VLIW processors with multiple native vector-widths to better serve applications with changing DLP. This paper focuses on the short SIMD code generation. More specifically, we target generating 32 -bit SIMD code for the native 32 -bit wide vector units of our example processor. In this way, we improved the performance of compiler generated SIMD code by reducing the number of <b>overhead</b> <b>operations.</b> Experimental results demonstrated that our methodology implemented in the compiler reduces the number of operations of synthetic benchmarks up to 40 %...|$|R
30|$|The {{computational}} cost of {{this device}} is low, consisting of a biquad filter plus the <b>overhead</b> of five <b>operations</b> per sample (three additions and two multiplications, {{as can be seen}} in [43] and Figure 2).|$|R
30|$|Operation overhead: We {{calculate}} {{the amount of}} control bytes transmitted during the whole simulation period for successful transmission of each byte of user data in the studied channel allocation mechanisms to compare the <b>operation</b> <b>overhead.</b>|$|R
50|$|Traditional {{transactions}} {{between a}} PCIe device and a CPU can take around 20,000 operations, whereas a CAPI attached device will only use around 500, significantly reducing latency, and effectively increasing bandwidth due to decreased <b>operations</b> <b>overhead.</b>|$|R
30|$|In this section, {{we study}} the {{performances}} of the proposed PowerNap algorithm, IEEE 802.11 PSM [13] and SleepWell [12] in terms of energy consumption, network throughput, fairness, and protocol <b>operation</b> <b>overhead,</b> carried out in ns- 3 [17].|$|R
30|$|Protocol <b>operation</b> <b>overhead</b> is {{measured}} as {{the ratio of}} the average number of control packets transmitted by the APs during the simulation period and network throughput. The control packets include hello packets, free-to-transmit message, clock synchronization packets, etc.|$|R
3000|$|... c shows that, the {{protocol}} <b>operation</b> <b>overheads</b> of WF-MAC and nQ WF-MAC {{are much higher}} than those of FMAC and random WF-MAC. We can see the integrated performance improvement of WF-MAC over the other three, as shown in Fig. 6 [...]...|$|R
40|$|Abstract—The {{degree of}} DLP {{parallelism}} in applications is not fixed and varies due to different computational characteristics of applications. On the contrary, {{most of the}} processors today include single-width SIMD (vector) hardware to exploit DLP. However, single-width SIMD architectures may not be optimal to serve applications with varying DLP and they may cause performance and energy inefficiency. We propose the usage of VLIW processors with multiple native vector-widths to better serve applications with changing DLP. SHAVE {{is an example of}} such VLIW processor and provides hardware support for the native 32 -bit and 128 -bit wide vector operations. This paper researches and implements the mixed-length SIMD code gener-ation support for SHAVE processor. More specifically, we target generating 32 -bit and 128 / 64 -bit SIMD code for the native 32 -bit and 128 -bit wide vector units of SHAVE processor. In this way, we improved the performance of compiler generated SIMD code by reducing the number of <b>overhead</b> <b>operations</b> and by increasing the SIMD hardware utilization. Experimental results demonstrated that our methodology implemented in the compiler improves the performance of synthetic benchmarks up to 47 %. I...|$|R
30|$|In networks, all end nodes must send {{field data}} to the gateway. The gateway then exchanges {{management}} messages with all the end nodes. After the initialization of the network, the enhanced Dijkstra’s algorithm is adopted for first route setup with low calculation complexity and low <b>overhead.</b> The <b>operation</b> is executed by the network manager rather than allowing each node to launch its own search process. In addition, the enhanced Dijkstra’s algorithm utilized Fibonacci heap[23] to implement Dijkstra’s algorithm to increase searching efficiency.|$|R
30|$|Number of cluster heads. We {{measure the}} number of cluster heads formed during the {{clustering}} algorithm in all the studied protocols, i.e., it represents {{the number of}} clusters in the network. The less number of clusters in the network corresponds to the reduced <b>operation</b> <b>overhead.</b>|$|R
5000|$|Nehalem {{processors}} incorporate SSE 4.2 SIMD instructions, adding seven new {{instructions to}} the SSE 4.1 set in the Core 2 series. The Nehalem architecture reduces atomic operation latency by 50% {{in an attempt to}} eliminate <b>overhead</b> on atomic <b>operations</b> such as the [...] compare-and-swap instruction.|$|R
3000|$|... e, {{we compare}} the <b>operation</b> <b>overhead</b> of HT-CAM, TE-CAM, and CC-VANET for {{increasing}} number of PUs in the network. As the number of PUs increases, the more licensed channels become occupied by them. Thus, the number of scheduled OBU pairs at each scheduling cycle decreases {{and the number of}} packet retransmissions increases. As a result, the throughput decreases and the comparative amount of control bytes exchanged increases. These cause the protocol <b>operation</b> <b>overhead</b> to increase with the {{increasing number of}} PUs in all the studied protocols. However, the proposed HT-CAM performs better than TE-CAM and CC-VANET because of a higher number of scheduled OBU pairs and lower number of packet retransmissions even {{in the presence of a}} large number of PUs in the network.|$|R
40|$|Middleware {{supporting}} secure {{applications in}} a distributed environment faces several challenges. Scalable {{security in the}} context of multicasting or broadcasting is especially hard when privacy and authenticity is to be assured to highly dynamic groups where the application allows participants to join and leave at any time. Unicast security is well-known and has widely advanced into production state. But proposals for multicast security solutions that have been published so far are complex, often require trust in network components or are inefficient. In this paper, we propose a framework of new approaches for achieving scalable security in IP multicasting. Our solutions assure that that newly joining members are not able to understand past group traffic, and that leaving members may not follow future communication. For versatility, our framework supports a range of closely related schemes for key management, ranging from tightly centralized to fully distributed and even allows switching between these schemes on-the-fly with low <b>overhead.</b> <b>Operations</b> have low complexity (for joins or leaves), thus granting scalability even for very large groups. We also present a novel concurrency-enabling scheme, which was devised for fully distributed key management. In this paper we discuss the requirements for secure multicasting, present our flexible system, and evaluate its properties, based on the existing prototype implementation...|$|R
