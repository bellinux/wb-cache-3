1|20|Public
40|$|Graduation date: 2015 Access {{restricted}} to the OSU Community, at author's request, from Nov. 24, 2014 - May 24, 2015 The conflict over water resources exploitation and sharing in the Aral Sea Basin {{is one of the}} most pressing environmental issues yet to be resolved in Central Asia. The fall of the Soviet Union in 1991 and establishment of the New Independent States (NIS) within the Aral Sea Bain led to conflicting interests vested in water resources with no mediator to solve these water issues. Presently, the Amu Darya and Syr Darya upstream states of Kyrgyzstan and Tajikistan desire to employ water resources for hydropower; while downstream Kazakhstan, Turkmenistan and Uzbekistan wish to continue practicing irrigated agriculture. This scarce and <b>over-allocated</b> <b>resource,</b> facing the needs of a growing population and climate change uncertainties, should be managed collaboratively and sustainably to be able to meet and withstand the upcoming challenges. This dissertation examines water management practices in the face of government regime change both in large and small river basins within Central Asia by analyzing international water agreements, correspondence between water managers, official reports, maps, and other archival documents. The analysis shows the inter-republican dynamics in water sector starting from 1950 s up to early 2000 s. The analysis of water relations within the Syr Darya Basin shows that there are different approaches to the change in political regime in both large and small basins. The results reveal that conflict over water resources in Central Asia existed long before the fall of the Soviet Union both in the large Syr Darya Basin, as well as within its small tributaries. The Soviet planned economy, along with the basin planning framework, set competition for water between the riparian states. Analysis of the infrastructure construction negotiations in these small shared tributaries showed that the former Soviet Republics used non-cooperative negotiation strategies to outcompete their rivals. This dissertation calls for regional cooperation in water management as it is shown that hydro-political competition in the basin may lead only to short term benefits, on the long run however, it is proven lead to heavy economic, social, political, and environmental costs...|$|E
50|$|Warming {{in western}} {{mountains}} {{is projected to}} decrease snowpack, increase winter flooding, and reduce summer flows, exacerbating competition for <b>over-allocated</b> water <b>resources.</b>|$|R
40|$|Available online Governments in many LDCs skew public {{resources}} towards urban sectors, despite {{a majority of}} citizens residing in rural areas. This paper develops a novel political argument for this urbanbias phenomenon in a framework where all voters, rural and urban, have equal voice, but differ in their access to information. We argue that this difference is sufficient to give governments an incentive to inefficiently <b>over-allocate</b> <b>resources</b> towards urban areas. The bias is shown to worsen during adverse economic times, leading to increased migration. We also examine how voter informativeness affects efficiency of the electoral process in weeding out incompetent governments...|$|R
40|$|Predictability of multi-processor systems-on-chip {{communication}} is critical {{and needs to}} be addressed by providing the right mix of soft and hard real-time guarantees. To this end, state-of-the-art packet-switched networks-on-chip (NoC) provide different levels of quality-of-service (QoS) such as best effort (BE) and guaranteed throughput (GT). Unfortunately, GT resources have to be reserved for the worst-case, resulting in <b>over-allocated</b> <b>resources.</b> We introduce the SuperGT NoC, a packet-switched NoC that, besides BE and GT, supports a new SuperGT QoS. A SuperGT connection combines guaranteed and non guaranteed traffic while maintaining in-order packet delivery. Time-slots are allocated to provide guarantees and extra BE resources are claimed by injecting data during free slots. Simulation results demonstrate the advantages of SuperGT over GT. Synthesis results of the SuperGT virtual channel manager show that the SuperGT router is an inexpensive enhancement to state-of-the-art packet-switched NoCs...|$|R
40|$|The {{issue of}} <b>resource</b> <b>over-allocating</b> {{is a big}} concern for project {{engineers}} {{in the process of}} scheduling project activities. <b>Resource</b> <b>over-allocating</b> is frequently seen after initial scheduling of a project in practice and causes significant amount of efforts to modify the initial schedules. In this research, a new method is developed for modifying over-allocated schedules in a multi-mode resource constrained project scheduling problems (MRCPSPs) with positive cash flows (MRCPSP-PCF). The aim is to maximize profit of the MRCPSPs or logically minimizing costs. The proposed method {{can be used as a}} macro in Microsoft Office Project® Software to modify <b>resource</b> <b>over-allocated</b> days after scheduling a project. This research considers progress payment method and preemptive resources. The proposed approach maximizes profit by scheduling activities through the resource calendar respecting to the available level of preemptive resources and activity numbers. To examine the performance of the proposed method a number of experiments derived from the literature are solved. The results are then compared with the circumstances where resource constraints are relaxed. The outcomes show that in all studied cases, the proposed algorithm can provide modified schedules with no over-allocated days. Afterward the method is applied to modify a manufacturing project in practice. ...|$|R
30|$|As core {{computing}} resources, CPU {{and memory}} adaptation {{have been widely}} researched. Many of the proposals scale the infrastructure horizontally by adding new VMs, typically via predefined VM classes [22 – 32]. While this is simpler to apply, compared to fine grain CPU and memory configuration, it may lead to wastage by <b>over-allocating</b> <b>resources</b> to workloads as well consume more power. In [33] the authors further argued that fine grain CPU and memory configuration reduces the provisioning overhead and mitigates SLA violations. Other proposals, particularly those focusing on maximising revenue, apply fine grain management of VM resources with CPU and memory configurations modified in discrete values using the Xen [34] hypervisor API. In [35 – 37], the authors utilise Xen’s credit-based CPU scheduler to set the CPU share for workloads and in [37, 38], the authors additionally utilise Xen’s ability to define the amount of memory assigned to each VM. The life cycle management of workloads can be categorised into two overlapping phases. Admission control [62], which is the decision to accept a new workload if it contributes to the current management objectives and resource adaptation [10], which reconfigures the infrastructure after a state change. Several proposals treat admission control as distinct phase and assume availability of free resources. While this simplifies the approach, it may unnecessarily power on a new node. Alternatively admission control should {{be used as an}} opportunity to apply cloud system adaptation and redistribute existing workloads.|$|R
40|$|An {{escalating}} {{climate crisis}} is stressing the Earth's environment. One significantly affected {{area is the}} global water infrastructure that includes hydropower, flood defense, drainage, and irrigation systems. The effect of adverse climate change on freshwater systems aggravates population growth and weakens economic conditions. In the western U. S., for example, reduced water supplies plus increased demand are likely to provoke more interstate and urban-rural competition for <b>over-allocated</b> water <b>resources.</b> Seawater desalination has existed for decades as a proven technology for supplying water in coastal areas; however, desalination processes are energy intensive and this has reduced their widespread use. It is noted that California offshor...|$|R
40|$|Purpose: The issue <b>resource</b> <b>over-allocating</b> is a {{big concern}} for project {{engineers}} {{in the process of}} scheduling project activities. <b>Resource</b> <b>over-allocating</b> drawback is frequently seen after scheduling of a project in practice which causes a schedule to be useless. Modifying an over-allocated schedule is very complicated and needs a lot of efforts and time. In this paper, a new and fast tracking method is proposed to schedule large scale projects which can help project engineers to schedule the project rapidly and with more confidence. Design/methodology/approach: In this article, a forward approach for maximizing net present value (NPV) in multi-mode resource constrained project scheduling problem while assuming discounted positive cash flows (MRCPSP-DCF) is proposed. The progress payment method is used and all resources are considered as pre-emptible. The proposed approach maximizes NPV using unscheduled resources through resource calendar in forward mode. For this purpose, a Genetic Algorithm is applied to solve. Findings: The findings show that the proposed method is an effective way to maximize NPV in MRCPSP-DCF problems while activity splitting is allowed. The proposed algorithm is very fast and can schedule experimental cases with 1000 variables and 100 resources in few seconds. The results are then compared with branch and bound method and simulated annealing algorithm and it is found the proposed genetic algorithm can provide results with better quality. Then algorithm is then applied for scheduling a hospital in practice. Originality/value: The method can be used alone or as a macro in Microsoft Office Project® Software to schedule MRCPSP-DCF problems or to modify <b>resource</b> <b>over-allocated</b> activities after scheduling a project. This can help project engineers to schedule project activities rapidly with more accuracy in practice...|$|R
40|$|Purpose: The issue <b>resource</b> <b>over-allocating</b> is a {{big concern}} for project {{engineers}} {{in the process of}} scheduling project activities. <b>Resource</b> <b>over-allocating</b> drawback is frequently seen after scheduling of a project in practice which causes a schedule to be useless. Modifying an over-allocated schedule is very complicated and needs a lot of efforts and time. In this paper, a new and fast tracking method is proposed to schedule large scale projects which can help project engineers to schedule the project rapidly and with more confidence. Design/methodology/approach: In this article, a forward approach for maximizing net present value (NPV) in multi-mode resource constrained project scheduling problem while assuming discounted positive cash flows (MRCPSP-DCF) is proposed. The progress payment method is used and all resources are considered as pre-emptible. The proposed approach maximizes NPV using unscheduled resources through resource calendar in forward mode. For this purpose, a Genetic Algorithm is applied to solve. Findings: The findings show that the proposed method is an effective way to maximize NPV in MRCPSP-DCF problems while activity splitting is allowed. The proposed algorithm is very fast and can schedule experimental cases with 1000 variables and 100 resources in few seconds. The results are then compared with branch and bound method and simulated annealing algorithm and it is found the proposed genetic algorithm can provide results with better quality. Then algorithm is then applied for scheduling a hospital in practice. Originality/value: The method can be used alone or as a macro in Microsoft Office Project® Software to schedule MRCPSP-DCF problems or to modify <b>resource</b> <b>over-allocated</b> activities after scheduling a project. This can help project engineers to schedule project activities rapidly with more accuracy in practice. Peer Reviewe...|$|R
40|$|This {{research}} {{speaks to}} {{developments in the}} conscientiousness literature regarding the consequences of being overly conscientious. Specifically, {{research has found that}} excessively conscientious individuals exhibit worse task performance than individuals with moderate levels of conscientiousness. The purpose of our study is to understand why and for whom high levels of conscientiousness may be detrimental. To this end, we incorporated resource allocation and general mental ability (GMA) to answer these questions. We conducted a laboratory study in which we manipulated the optimal level of resource allocation across multiple trials of a work simulation. Participants could maximize performance by matching actual resource allocation to the optimal level of resource allocation. This design allowed us to directly observe participants’ resource allocation decisions and vary the optimal level of resource allocation from low to high. We found that individuals with high conscientiousness and low GMA deviated most from the optimal level of resource allocation. Specifically, individuals with high conscientiousness and low GMA had a tendency to <b>over-allocate</b> <b>resources.</b> Downstream, the greater the deviation from the optimal level of resource allocation the worse performance was. Although conscientiousness may be beneficial in some circumstances, more is not always better. We demonstrated that high levels of conscientiousness can be detrimental to performance. This reduction in performance occurs when individuals are willing to invest a great deal of resources (high conscientiousness) but unable to recognize the optimal level of resource allocation (low GMA). Past research has provided limited insight into why highly conscientious individuals have been found to perform worse than individuals with moderate levels of conscientiousness. Our study extends this research by using an experimental design to demonstrate that conscientiousness and GMA interact to indirectly predict performance via resource allocation...|$|R
40|$|Side and covert {{channels}} (referred to {{collectively as}} illicit channels) are an insidious affliction of high security systems {{brought about by}} the unwanted and unregulated sharing of state amongst processes. Illicit channels can be effectively broken through isolation, which limits the degree by which processes can interact. The drawback of using isolation as a general mitigation against illicit channels is that it can be very wasteful when employed naively. In particular, permanently isolating every tenant of a public cloud service to its own separate machine would completely undermine the economics of cloud computing, as it would remove the advantages of consolidation. On closer inspection, it transpires that only a subset of a tenant's activities are sufficiently security sensitive to merit strong isolation. Moreover, it is not generally necessary to maintain isolation indefinitely, nor is it given that isolation must always be procured at the machine level. This work builds on these observations by exploring a fine-grained and hierarchical model of isolation, where fractions of a machine can be isolated dynamically using migration. Using different units of isolation allows a system to isolate processes from each other with a minimum of <b>over-allocated</b> <b>resources,</b> and having a dynamic and reconfigurable model enables isolation to be procured on-demand. The model is then realised as an implemented framework that allows the fine-grained provisioning of units of computation, managing migrations at the core, virtual CPU, process group, process/container and virtual machine level. Use of this framework is demonstrated in detecting and mitigating a machine-wide covert channel, and in implementing a multi-level moving target defence. Finally, this work describes the extension of post-copy live migration mechanisms to allow temporary virtual machine migration. This adds the ability to isolate a virtual machine on a short term basis, which subsequently allows migrations to happen at a higher frequency and with fewer redundant memory transfers, and also creates the opportunity of time-sharing a particular physical machine's features amongst a set of tenants' virtual machines...|$|R
40|$|Self-confirming Dynamics 2 Studies have {{consistently}} found that social structure influences who transacts with whom, and that actors appear to benefit when exchange occurs embedded within these relations {{rather than in}} an unstructured market. This paper argues that the apparent benefits of embedded exchange can arise from an endogenous mechanism: Actors offer better terms of trade and allocate more resources to transactions embedded within existing social relations, thereby contributing to the ostensible advantages of such exchange patterns. In the motion picture industry, not only do distributors show a preference for carrying films involving key personnel with whom they had prior relations, but also they tend to favor these films when making decisions regarding their release (opening dates {{and the level of}} promotion). After controlling for the effects of these decisions, films with stronger prior relations to the distributor perform worse at the box office. The results reveal that, rather than benefiting from repeated exchange, distributors <b>over-allocate</b> scarce <b>resources</b> to these exchange partners...|$|R
40|$|Abstract. An {{escalating}} {{climate crisis}} is stressing the Earth’s environment. One significantly affected {{area is the}} global water infrastructure that includes hydropower, flood defense, drainage, and irrigation systems. The effect of adverse climate change on freshwater systems aggravates population growth and weakens economic conditions. In the western U. S., for example, reduced water supplies plus increased demand are likely to provoke more interstate and urban–rural competition for <b>over-allocated</b> water <b>resources.</b> Seawater desalination has existed for decades as a proven technology for supplying water in coastal areas; however, desalination processes are energy intensive and this has reduced their widespread use. It is noted that California offshore oil and gas platforms already use seawater desalination to produce fresh water for platform personnel and equipment. It is proposed that as California coastal oil and gas platforms {{come to the end}} of their productive lives, they be re-commissioned for use as large-scale fresh water production facilities. Solar arrays, mounted on the platforms, are able to provide some of the power needed for seawater desalination during the daytime. However, for efficient fresh water production, a facility must be operated 24 hours a day. The use of solar power transmitted from orbiting satellites (Solar Power Satellites – SPS) to substantially augment the solar array powe...|$|R
40|$|There is an {{escalating}} {{climate crisis}} that is stressing the Earth’s environment partially a re-sult {{of the increasing}} accumulation {{of carbon dioxide and}} methane greenhouse gases in the lower atmosphere. One area that is significantly affected is the water infrastructure around the planet including hydropower, flood defense, drainage, and irrigation systems. The effect of adverse climate change on freshwater systems aggravates population growth, weakening economic con-ditions, land-use changes, and urbanization. In the western U. S., for example, reduced water supplies plus increased demand are likely to provoke more interstate and urban–rural competi-tion for <b>over-allocated</b> water <b>resources.</b> Seawater desalination has existed for decades and is a proven technology for supplying water in coastal areas. Continued population growth in coastal areas makes it economically feasible to begin considering seawater desalination as a larger source for metropolitan water supplies. It is noted that offshore oil and gas platforms already use seawater desalination to produce fresh water for platform personnel and equipment. It is pro-posed that as California coastal oil and gas platforms {{come to the end of}} their productive lives, they be re-commissioned for use as large-scale fresh water production facilities. Solar arrays, mounted on the platforms, are able to provide the power needed for seawater desalination durin...|$|R
40|$|Many {{breakthroughs}} in scientific and industrial research {{are supported by}} simulations and calculations performed on high performance computing (HPC) systems. These systems typically consist of uniform, largely parallel compute resources and high bandwidth concurrent file systems interconnected by low latency synchronous networks. HPC systems are managed by batch schedulers that order the execution of application jobs to maximize utilization while steering turnaround time. In the past, demands for greater capacity were met by building more powerful systems with more compute nodes, greater transistor densities, and higher processor operating frequencies. Unfortunately, the scope for further increases in processor frequency is restricted by the limitations of semiconductor technology. Instead, parallelism within processors and in numbers of compute nodes is increasing, while the capacity of single processing units remains unchanged. In addition, HPC systems’ memory and I/O hierarchies are becoming deeper and more complex {{to keep up with}} the systems’ processing power. HPC applications are also changing: the need to analyze large data sets and simulation results is increasing the importance of data processing and data-intensive applications. Moreover, composition of applications through workflows within HPC centers is becoming increasingly important. This thesis addresses the HPC scheduling challenges created by such new systems and applications. It begins with a detailed analysis of the evolution of the workloads of three reference HPC systems at the National Energy Research Supercomputing Center (NERSC), with a focus on job heterogeneity and scheduler performance. This is followed by an analysis and improvement of a fairshare prioritization mechanism for HPC schedulers. The thesis then surveys the current state of the art and expected near-future developments in HPC hardware and applications, and identifies unaddressed scheduling challenges that they will introduce. These challenges include application diversity and issues with workflow scheduling or the scheduling of I/O resources to support applications. Next, a cloud-inspired HPC scheduling model is presented that can accommodate application diversity, takes advantage of malleable applications, and enables short wait times for applications. Finally, to support ongoing scheduling research, an open source scheduling simulation framework is proposed that allows new scheduling algorithms to be implemented and evaluated in a production scheduler using workloads modeled on those of a real system. The thesis concludes with the presentation of a workflow scheduling algorithm to minimize workflows’ turnaround time without <b>over-allocating</b> <b>resources.</b> Work also supported by the U. S. Department of Energy, Office of Science, Office of Advanced Scientific Computing Research (ASCR) and we used resources at the National Energy Research Scientific Computing Center, a DOE Office of Science User Facility, supported by the Officece of Science of the U. S. Department of Energy, both under Contract No. DE-AC 02 - 05 CH 11231. </p...|$|R
40|$|For {{the first}} time in the Northern Territory's water {{management}} history it is facing the challenge of managing an <b>over-allocated</b> groundwater <b>resource.</b> Rapid rural residential and agricultural development in the Howard River catchment of Darwin's hinterland has increased competition for groundwater from the bore-field that supplements the capital's metropolitan water supply. This has generated tensions between different water users and precipitated a water allocation plan for the Howard East aquifer. Initial context analysis indicated a widespread lack of public understanding of groundwater systems and processes, leading to misconceptions about the origin of local groundwater resources, groundwater-surface water interactions, extraction rates and impacts. In addition there is a legacy of mistrust by some peri-urban community members of government-driven planning processes to manage groundwater resources. The main objective of this study was therefore to trial two planning tools suited to this context over a 15 month period: (i) an extended stakeholder analysis and (ii) the participatory development of a 3 D visualisation model, via a process described as the participatory Groundwater Visualisation Tool (GVT). The tools assisted the water planning agency to better understand stakeholder needs and interests, contributed to popular scientific understandings of hydro-geological conditions and processes, as well as captured local knowledge and values in preparation for an open and effective planning process. No Full Tex...|$|R
40|$|Contemporary {{embedded}} systems for wireless communications support various radios. A software-defined radio (SDR) is a radio implemented as concurrent software processes that typically {{run on a}} multiprocessor system-on-chip (MPSoC). SDRs are real-time streaming applications with throughput requirements. One efficient approach for timing analysis of concurrent real-time applications is the dataflow model of computation (MoC). Nonetheless, the dataflow modeling of SDRs is challenging due to their dynamically changing data processing workload. A dataflow MoC that is not expressive enough to capture this dynamism gives pessimistic throughput results. On the other hand, if it is too expressive and detailed, {{it may not be}} analyzable at all. In this paper, we address the challenge of dataflow modeling of SDRs such that their timing behavior can be accurately analyzed to guarantee real-time requirements without unnecessarily <b>over-allocating</b> MPSoC <b>resources.</b> The basis of our modeling approach is splitting the dynamic data processing behavior of a SDR into a group of static modes of operation. Each static mode of operation is then modeled by a Synchronous Dataflow (SDF), which we refer to as scenario. This paper has two main contributions: 1) a scenario-based dataflow model of Long Term Evolution (LTE), which is the latest standard in cellular communication, and 2) investigation of existing throughput analysis techniques of SDF scenarios for our LTE model. Our results show that scenario-based worst-case throughput computation is 2 to 3. 4 times more accurate than a state-of-the-art SDF analysis technique. Our investigation also shows that existing timing analysis techniques of SDF scenarios have very low run-time that scales very well with increase in graph size. This makes SDF scenarios suitable in practice for modeling and analyzing SDRs as well as similar dynamic application...|$|R
40|$|Resource {{allocation}} is {{the process}} of assigning resources to tasks throughout the life of a project. Despite sophisticated software packages devoted to keeping track of tasks, resources and resource assignments, it is often the case that project managers find some <b>resources</b> <b>over-allocated</b> and therefore unable to complete the assigned work in the allotted amount of time. Most scheduling software has provisions for leveling resources, but the techniques for doing so simply add time to the schedule and may cause delays in tasks that are critical to the project in meeting deadlines. This paper presents a software application that ensures that resources are properly balanced {{at the beginning of the}} project and eliminates the situation in which <b>resources</b> become <b>over-allocated.</b> It can be used in a multi-project environment and reused throughout the project as tasks, resource assignments and availability, and the project scope change. The application utilizes the bounded enumeration technique to formulate an optimal schedule for which both the task sequence and resource availability are taken into account. It is run on a database server to reduce the running time and make it a viable application for practitioners. Keywords: project management; optimization; resource allocation; bounded enumeration...|$|R
40|$|Prepared for Ministry for the Environment (Report No 4375 / 1, April 2000). The {{preparation}} of this report has involved input from {{a large number of}} people. We would particularly like to acknowledge Maurice Duncan from NIWA who provided the flow statistics from the National Hydrometric Database and Murray Doak from MAF Policy, Christchurch, who co-ordinated the MAF input. We would like to thank all the regional and district council staff who have provided information, participated in interviews and reviewed the document. The majority of this report is a summary of the work by regional councils in the water allocation area. We also thank the MAF regional offices for their input into assessing the “at-farm gate value” of irrigation water. Water allocation is identified as a high priority in the Ministry for the Environment’s Draft National Agenda for Sustainable Water Management. The purpose of this project was to develop an information base concerning the status of water allocation in each region, and the systems that are being used to allocate water. The information base will contribute essential information to ongoing work in water allocation. There are two parts to the report. First, a quantitative analysis based on consent database information to assess where water is allocated from and the uses it is allocated to. Secondly, an overview of current water allocation practice within New Zealand based on interviews with regional council staff and review of documents including draft, proposed or operative regional water plans. The quantitative analysis has shown that: • 70. 5 % of all water allocated in New Zealand is allocated from surface water, 29. 5 % is allocated from groundwater. • 77 % of water allocated is for irrigation, 16 % is for community, municipal and domestic uses, and 7 % is for industrial takes. • 58 % of water allocated in New Zealand is allocated from the Canterbury region. The North Island accounts for 17 % of water allocated. • 19 % of the current weekly allocation has been allocated since 1990. The majority of water in New Zealand was therefore initially allocated under legislation predating the RMA. • There is approximately 500, 000 hectares of irrigated land in New Zealand, 350, 000 hectares of which is in Canterbury. • 41 % of the irrigated land area is irrigated from groundwater. • The area of irrigated land is increasing at around 55 % each decade. • The “at farm gate” value of irrigation water is estimated to be around $ 800 million. The figures above are all based on weekly allocations and will typically relate to the maximum volumes required during a dry summer week. Water taken for hydro-electricity generation or any other non-consumptive use has been excluded from the analysis. The figures are for allocated volumes rather than use. Because irrigation is the dominant use of water, actual use is greatest in dry summers. When measurements of actual water use have been compared to allocated amounts on a weekly basis, the total take from a water resource is seldom more than 40 % of the allocated volume. Annual use varies between 20 % and 65 % of the allocated volume depending on climatic conditions. The second part of the report summarises the management of water quantity and water allocation by region. Issues addressed are, setting minimum river flows or groundwater levels, determining limits to the total amount of water that can be allocated from a <b>resource,</b> dealing with <b>over-allocated</b> <b>resources,</b> managing abstractions during water-short periods, promoting efficient use, consent administration, and enforcement/compliance issues. The approach chosen by each council depends {{on a wide variety of}} factors including: the dynamics of a water resource and the ecosystem it supports, the associated values, the history of water allocation, the level of information available, and the political environment. While it is not appropriate, given differences in these factors, to identify a “right” way to allocate water, the report describes a range of issues, obstacles and research needs for the implementation of successful water allocation systems...|$|R
40|$|Marketing {{scholars}} and practitioners frequently infer market responses from cross-sectional or pooled cross-section by time data. Such cases occur especially when historical data are either absent {{or are not}} representative of the current market situation. We argue that inferring market responses using cross-sections of multimarket data may in some cases be misleading because these data also reflect unobserved actions by retailers. For example, because the (opportunity) costs of doing so do not outweigh the gains, retailers are predisposed against promoting small share brands. As a consequence, local prices and promotion variables depend on local market shares—the higher the local share, the higher the local observed promotion intensity. We refer to this reverse causation as an endogeneity. Ignoring it will inflate response estimates, because both the promotion effects on share {{as well as the}} reverse effects are in the same direction. In this paper, we propose a solution to this inference problem using the fact that retailers have trade territories consisting of multiple contiguous markets. This implies that the unobserved actions of retailers cause a measurable spatial dependence among the marketing variables. The intuition behind our approach is that by accounting for this spatial dependence, we account for the effects of the retailer's behavior. In this context, our study hopes to make the following contributions at the core of which lies the above intuition. First, we separate the market response effect from the reverse retailer effect by computing responses to price and promotion net of any spatial—and therefore retailer—influence. Second, underlying this approach is a new variance-decomposition model for data with a panel structure. This model allows to test for endogeneity of prices and promotion variables in the cross-sectional dimension of the data. This test aims to complement the one developed by Villas-Boas and Winer (1999), who test for endogeneity along the temporal dimension. Third, to illustrate the approach, we use Information Resources Inc. (IRI) market share data for brands in two mature and relatively undifferentiated product categories across 64 IRI markets. Whereas we only use data with very short time horizons to estimate price and promotion responses with the spatial model, we do have data over long time windows. We use the latter to validate the approach. Specifically, within-market estimates of price and promotion response are not subject to the same endogeneity because we hold the set of retailers constant. Therefore, comparing within- and across-market estimates of price and promotion responses is a natural way to validate the approach. Consistent with our argument, ignoring the reverse causation in the cross-sectional data leads to inferences of price and promotion elasticities that are farther away from zero than the elasticities obtained from within-market analysis. In contrast, cross-sectional spatial estimates and time-series estimates show convergent validity. From a practical point of view, this means it is possible to obtain reasonable within-market estimates of price and promotion elasticities from (predominantly) cross-sectional data. This may benefit marketing managers. The manager who would act on the inflated elasticities will <b>over-allocate</b> marketing <b>resources</b> to promotions because she ignores retailers' censorship of promotions on the basis of already existing high share. We explore other approaches to correct for the inference bias, and discuss further managerial issues and future research. Spatial Analysis, Promotional Price Response, Promotion Strategy, Endogeneity Biases, Variance-Decomposition...|$|R
40|$|Water {{trading is}} {{increasingly}} becoming an important farm management tool for irrigators to manage changing environmental conditions. Studies {{have found that}} water trading increases farmers’ flexibility in water use and moves water from lower value (or less efficient) uses to higher value (or more efficient) uses. Many countries that regularly suffer periods of droughts and have <b>over-allocated</b> water <b>resources</b> face a growing challenge to allocate water to competing water uses. Some of these countries have introduced water markets {{as a response to}} help enable an efficient allocation of a scarce resource. This is especially so in Australia’s Murray-Darling Basin (MDB), which has had water markets in place for decades. The southern MDB {{is one of the most}} active water trading region worldwide, and hence, provides an ideal case study for examining water trading behaviour. The MDB faced the Millennium Drought in the 2000 s which caused intensive distress for all alike: irrigators, tourists, rural communities and especially the environment. During the midst of this drought the Federal government introduced a water buyback program that purchased water entitlements from willing irrigators to return to environmental use. To date, a number of studies have investigated irrigators’ determinants to trade water. This literature has primarily focused on farmers’ socio-economic and farm specific characteristics. But there is evidence that water trading is also affected by spatial factors, especially water entitlement trading. Thus, this thesis explores the relevance of spatial influences on irrigators’ water trade decision-making. Traditional economic models of water trading behaviour are expanded with several spatially explicit variables, such as biophysical and distance factors. The influence of neighbours’ water trading decision-making (‘neighbourhood effect’) is also tested, as anecdotal evidence shows that in the past irrigators experienced considerable social pressure if they sold or were willing to sell water entitlements. Furthermore, this thesis also examines the influence of spatial factors on irrigators’ price choices for selling and buying water entitlements. The results show that a number of spatial influences significantly affect water trading behaviour, especially water entitlement selling behaviour. Irrigators located in poorer resource areas (e. g. regarding soil degradation), in more rural areas and regions that suffer a socioeconomic decline (e. g. population decline) are more likely to sell water entitlements. There is evidence of a substitution effect between surface-water and groundwater (where viable groundwater resources exist). Irrigators in more rural areas tend to sell larger volumes of water entitlements and buy larger volumes of water allocations. Furthermore, a positive neighbourhood effect is confirmed, where irrigators’ decisions to sell water entitlements was influenced by their neighbours. Over time, it became more socially acceptable to sell water entitlements. Finally, spatial influences also affect irrigators’ valuation of their water, which is reflected in their price choices for water entitlement selling. Overall, the results of this thesis support some existing policy measures and programs (e. g. salinity impact zones) and lead to several other policy implications. One such conclusion is the need to focus policy on water entitlement buybacks rather than on water irrigation infrastructure. This thesis concludes that current and future polices (e. g. related to the water buyback) could be more spatially targeted while also considering the externalities and wider irrigator behaviour in policy development. Spatially refined policies have the potential to improve the outcome of water markets (and related environmental programs) and alleviate the pressure on socio-economic and environmental systems. Thesis (Ph. D.) (Research by Publication) [...] University of Adelaide, Centre for Global Food and Resources, 2017...|$|R

