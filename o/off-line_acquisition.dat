2|11|Public
40|$|This paper {{describes}} an integrated {{approach to the}} computerization of all major disciplines of laboratory medicine and pathology. Installed in the Department of Pathology, Singapore General Hospital (SGH), the computer system discussed comprises a RISC-based Data General Aviion 6200 computer and Meditech MAGIC software. The system has been interfaced with the hospital host IBM computer and supports patient information transfer, result reporting, phlebotomy management, and compilation of laboratory and financial management reports. The main functions of the system include: on-line and <b>off-line</b> <b>acquisition</b> of patient information and test data; preparation of single/combined/cumulative reports; transmission of reports within and between laboratories; instantaneous provision of data in response to telephone enquiries; calculations of quality control/workload/productivity statistics and indices; and generation of billing lists. The computer enables reports to be provided on patient tests results in individual wards, at various specialist out-patient clinics, and in the Accident and Emergency Department of the SGH through the IBM mainframe, {{as well as to}} remote printers installed at several other major hospitals...|$|E
40|$|PURPOSE: This paper {{describes}} {{our experience}} {{in developing a}} DICOM (Digital Imaging and Communications in Medicine) server based on widely available personal computers enabling to use X-ray digital images for teaching and scientific purposes. MATERIALS AND METHODS: The system {{is based on a}} DICOM server running on a widely used personal computer. The selected DICOM images are collected directly from the radiological equipment or from a dedicated 3 D image processing workstation through a LAN connection and converted into one of the standard formats (JPEG or GIF) to allow their direct importing into multimedia presentations for teaching or scientific purposes. RESULTS: This system allows fast and easy collection of radiological images in DICOM format directly from the diagnostic equipment or from the graphical workstation. These images may be used for scientific and teaching presentations without loss of image quality and colour characteristics in 3 D images as there is no <b>off-line</b> <b>acquisition</b> process. CONCLUSIONS: The extensive possibilities of implement the system described on widely used PCs makes the system extremely versatile and facilitates the preparation of teaching material and scientific publications...|$|E
40|$|Abstract Cone Beam Computerized Tomography (CBCT) enables threedimensional imaging with {{isotropic}} resolution. X-ray scatter {{management is}} a challenging task for quantitative CBCT imaging: scattered radiation level is significantly high on cone beam systems compared to collimated fan beam systems. The {{effects of this}} scattered radiation are cupping artifacts, streaks, and quantification inaccuracies. At CEA-LETI, an original scatter management process without additional on-line acquisition has been developed, the API (Analytical transformation Plus Indexation based) method. The proposed method is composed of two steps: a scatter calibration is first performed through <b>off-line</b> <b>acquisitions</b> and is {{used to evaluate the}} level and a global shape of scattered radiation on on-line tomographic projections of the object. This global shape is adapted to the current acquisition with an analytical transformation issued from physical equations to evaluate the scattered radiation distribution on tomographic projections. This approach has been applied successfully in medical field. This paper presents in detail the API method and evaluates i...|$|R
40|$|We {{present an}} {{integrated}} environment for stereoscopic <b>acquisition,</b> <b>off-line</b> 3 D elaboration, and visual presentation of biological hand actions. The system {{is used in}} neurophysiological experiments aimed at {{the investigation of the}} parameters of the external stimuli that mirror neurons visually extract and match on their movement related activity. 23 - 2...|$|R
40|$|The {{software}} package {{described in this}} document was 13; developed for a TDC- 316 Computer based Data Acquisition System of the 1. 2 m Trisonic Wind Tunnel. This package is capable of interactive real-ti me data <b>acquisition,</b> <b>off-line</b> data reduction and digital plotting to produce the final aerodynamic coefficients in tabulated form and graphs of selected coefficients. This {{has resulted in a}} drastic improvement in the tunnel utility. 13...|$|R
40|$|The {{availability}} of robust and deep syntactic parsing {{can improve the}} performance of all modules of a Question Answering system. In this article, this is illustrated using examples from our QA system Joost, a Dutch QA system which {{has been used for}} both open and closed domain QA. The system can make use of information found in the fully parsed version of the document collections. We demonstrate that this improves the performance of various components of the system, such as answer extraction and selection, lexical <b>acquisition,</b> <b>off-line</b> relation extraction, and passage retrieval...|$|R
40|$|Several {{distributed}} Network Management (NM) architectures, {{exploiting the}} advantages of Mobile Agents (MA), have been recently proposed to answer some of the limitations intrinsic to client-server based centralised NM, such as information bottlenecks and lack of flexibility. However, when considering network performance management, they fail to address scalability problems. In this paper, we introduce two efficient, lightweight polling modes based on MAs that address these limitations. Both real-time and <b>off-line</b> NM data <b>acquisition</b> is considered. The introduced modes are shown to outperform SNMP-based polling {{both in terms of}} response time and bandwidth consumption. 1...|$|R
40|$|Abstract: In {{order to}} {{evaluate}} vague queries, each linguistic term is considered {{according to its}} fuzzy model. Usually, the linguistic terms are defined as fuzzy sets, during a classical knowledge <b>acquisition</b> <b>off-line</b> process. But {{they can also be}} automatically extracted from the actual content of the database, by an online process. In at least two situations, automatically modeling the linguistic values would be very useful: first, to simplify the knowledge engineer’s task by extracting the definitions from the database content; and second, where mandatory, to dynamically define the linguistic values in complex criteria queries evaluation. Procedures to automatically extract the fuzzy model of the linguistic values from the existing data are presented in this paper...|$|R
40|$|The {{intrinsic}} scalability {{limitations of}} traditional centralised Network Management (NM) become significantly more pronounced when transfers of bulk network monitoring data are considered. This fact has encouraged a trend towards distributed management intelligence, which promises more flexible and scalable solutions. However, distributed Mobile Agent (MA) based NM architectures {{reported in the}} literature do not adequately address scalability problems when considering data intensive NM applications. In this paper, we present three novel applications in which MAs are used to perform management data aggregation, acquire SNMP table snapshots and filter SNMP table contents subject to filtering expressions. Both real-time and <b>off-line</b> NM data <b>acquisition</b> is considered. The applications, supported by a lightweight management framework described in previous work, are shown to outperform SNMP-based polling in terms of bandwidth consumption...|$|R
40|$|Laser range {{scanners}} {{have now}} {{the ability to}} acquire millions of 3 D points of highly detailed and geometrically complex urban sites, opening new avenues of exploration in modeling urban environments. In the traditional modeling pipeline, range scans are processed <b>off-line</b> after <b>acquisition.</b> The slow sequential acquisition though is a bottleneck. The goal of our work is to alleviate this bottleneck, by exploiting the sequential nature of the data acquisition process. We have developed novel online algorithms, never before used in laser range scanning, that perform data classification on-the-fly as data is being acquired. These algorithms are extremely efficient, and can be potentially integrated with the scanner’s hardware, rendering a sensor that not only acquires but also intelligently processes and classifies the scene points. This sensor, armed with the proposed algorithms, can classify 3 D points in real-time as being in vegetation vs. non-vegetation regions, or in horizontal vs. vertical regions. The former classification is possible by the implementation of sequential algorithms through a hidden Markov model (HMM) formulation, and the latter {{through the use of}} a combination of cleverly designed sequential detection algorithms. We envision an arsenal of algorithms of this type to be developed in the future. 1...|$|R
40|$|The {{computational}} {{capability of}} mobile phones has been rapidly increasing, {{to the point}} where augmented reality has become feasible on cell phones. We present an approach to indoor localization and pose estimation in order to support augmented reality applications on a mobile phone platform. Using the embedded camera, the application localizes the device in a familiar environment and determines its orientation. Once the 6 DOF pose is determined, 3 D virtual objects from a database can be projected into the image and displayed for the mobile user. <b>Off-line</b> data <b>acquisition</b> consists of acquiring images at different locations in the environment. The online pose estimation is done by a featurebased matching between the cell phone image and an image selected from the precomputed database using the phone’s sensors (accelerometer and magnetometer). The application enables the user both to visualize virtual objects in the camera image and to localize the user in a familiar environment. We describe in detail the process of building the database and the pose estimation algorithm used on the mobile phone. We evaluate the algorithm performance as well as its accuracy in terms of reprojection distance of the 3 D virtual objects in the cell phone image. 1...|$|R
40|$|AbstractPurpose: The {{study was}} done to improve {{quantification}} of multiple arterial stenoses and to investigate a new imaging technique for lower limb arteries. Three-dimensional power Doppler angiography was used to quantify in vitro arterial stenoses. Methods: We built two types of artery phantoms containing multiple stenoses. One used stenotic porcine arteries, {{and the other was}} designed to control the proximal and distal stenoses while we assessed central stenosis of a wall-less agar lumen. Three-dimensional power Doppler angiograms of the flow lumens were generated at different flow rates under steady and pulsatile flow conditions with a PowerPC 8500 computer-based three-dimensional ultrasound imaging system. This experimental system works <b>off-line,</b> performs three-dimensional <b>acquisition,</b> reconstruction, and display of ultrasound images. Images of flow lumens were compared with the measured B-mode images or the true geometry. Results: This technique produces good three-dimensional angiographic images of the flow lumen, and multiple stenoses do not affect the diagnosis of arterial stenoses. With this technique, the average errors for estimating 80 % and 50 % area reduction stenoses were – 10 % and – 4 %, respectively. Conclusions: Three-dimensional power Doppler angiography has the potential to quantitatively grade multisegmental stenoses in lower limbs and generate a map for vasculature surgery planning. (J Vasc Surg 1998; 27 : 681 - 8. ...|$|R

