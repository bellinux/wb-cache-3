44|966|Public
5000|$|When {{dealing with}} {{continuous}} data, a typical {{assumption is that}} the continuous values associated with each class are distributed according to a Gaussian distribution. For example, suppose the training data contains a continuous attribute, [...] We first segment the data by the class, and then compute the mean and variance of [...] in each class. Let [...] be {{the mean of the}} values in [...] associated with class c, and let [...] be the variance of the values in [...] associated with class c. Suppose we have collected some <b>observation</b> <b>value</b> [...] Then, the probability distribution of [...] given a class , , can be computed by plugging [...] into the equation for a Normal distribution parameterized by [...] and [...] That is, ...|$|E
30|$|Based on the quale, the {{observer}} produces an <b>observation</b> <b>value.</b> The function qualeToMeasure introduced below establishes a mapping between a quale and an <b>observation</b> <b>value</b> (resulting from a measurement process).|$|E
40|$|Abstract. This paper uses total {{radiation}} instrument and scattered radiation instruments to test illumination irradiance {{in the center}} point of sunshine greenhouse, and compares the test data with the software model predicted data, the results show that: the radiation of fine day indoor sunshine greenhouse is generally larger than that in cloudy. The average values in fine day of outdoor <b>observation</b> <b>value,</b> outdoor simulation value, indoor <b>observation</b> <b>value,</b> indoor simulation value are 347. 6 2 /mW, 292. 3 2 /mW, 153. 8 2 /mW and 151. 7 2 /mW, while that in cloudy day are 261. 1 2 /mW, 262. 7 2 /mW, 110. 2 2 /mW and 123. 9 2 /mW. The trend of total indoor radiation simulation value {{is consistent with the}} <b>observation</b> <b>value...</b>|$|E
30|$|Step 4 (also called ‘expression’): {{convert the}} signals to <b>observation</b> <b>values.</b>|$|R
30|$|The {{compressed}} sensing theory {{tells us}} that, if a signal is sparse or compressible through an orthogonal transformation, the signal {{can be observed}} in a lower frequency, and can be represented with least numbers of <b>observation</b> <b>values.</b> Moreover, the original signal can be estimated well by these sparse <b>observation</b> <b>values</b> (Donoho 2006; Candès and Wakin 2008).|$|R
50|$|Notice that in each case, the {{parameters}} {{which must be}} fixed determine a limit {{on the size of}} <b>observation</b> <b>values.</b>|$|R
30|$|The spatial {{resolution}} and the temporal {{resolution of the}} <b>observation</b> <b>value</b> are now equated with the {{spatial resolution}} and temporal resolution of the quale respectively 1.|$|E
30|$|Proof As {{shown in}} Fig.  1, the {{sampling}} time is treal[*]=[*]tideal[*]+[*]Δt, while the <b>observation</b> <b>value</b> is val[*]=[*]valreal[*]+[*]Δ, where Δ is the error {{caused by the}} jitter Δt.|$|E
40|$|Abstract. Based on {{the choice}} {{characteristic}} of least absolute estimation,and {{the principle of}} the minimum of summation of residual absolute value,the GM(1, 1) model is proposed to distortion inspecting and forecasting. Exemples show the precision of least absolute estimation is uncertain to be higher a little than that of least squares estimation when <b>observation</b> <b>value</b> contains gross error,and the precision of least absolute estimation is lower a little than that of least squares estimation when <b>observation</b> <b>value</b> doesn’t contain gross error. So least absolute estimation isn’t beter to GM(1, 1) ...|$|E
3000|$|... {{lead to the}} KF trusting {{the initial}} state {{estimate}} too little and not adapting to the new initial <b>observations.</b> <b>Values</b> of [...]...|$|R
40|$|Abstract. The {{investigation}} {{presents a}} new approach based on SIR particle filtering state estimation and smoothed residual for GPS receiver autonomous integrity monitoring (RAIM), which adopted the difference value between the ideal <b>observation</b> <b>values</b> acquired by state estimation and the actual state <b>observation</b> <b>values,</b> and the log likelihood ratio (LLR) test based on probability density function of state-measurement was set up. Experimental results based on real GNSS data demonstrate that the algorithm can estimate the state precisely under non-Gaussian measurement noise, detect and isolate GPS satellite failures successfully and solve the performance degradation problem of RAIM algorithm based on Kalman filter. Therefore, experimental results validate the validity of SIR particle filtering state estimation and smoothed residual for RAIM...|$|R
30|$|Listing 1 {{introduces}} three relevant datatypes for the scenario: Magnitude (to {{represent the}} magnitude of a quality), Quale (entity evoked in a cognitive agent’s mind when observing a quality), and ObsValue (to represent <b>observation</b> <b>values).</b> For a detailed discussion of these notions, see [74].|$|R
30|$|In fact, the {{following}} equations hold: spatialResolution(observation) ≤ spatialResolution(quale); temporalResolution(observation) ≤ temporalResolution(quale); thematicResolution(observation) ≤ thematicResolution(quale), since {{the transformation of}} the quale into an <b>observation</b> <b>value</b> (through the expression operation mentioned in Section The receptor-centric approach) might involve another loss of spatial/temporal/thematic detail. The example introduced here assumes no loss of spatial/temporal detail during the expression operation, and equates the spatial/temporal resolution of the observation with the spatial/temporal resolution of the quale. A thorough investigation of the interplay between resolution of quale and resolution of <b>observation</b> <b>value</b> (for the spatial, temporal and thematic dimensions) is deferred to future work.|$|E
3000|$|The LAU server (signer) {{requests}} {{a private}} key from the PKG and receives the private key D_ID = sQ_ID. The LAU server performs a digital {{signature of the}} meteorological <b>observation</b> <b>value</b> by computing U, V and sends them with the <b>observation</b> <b>value</b> to the DGS. At this point, U is U = rQ_ID, V is V = ([...] r + h)D_ID, and r chooses a random number from Z_q^ * and h is denoted as h = H_ 2 ([...] M, U). The DGS (Data Gathering Server) server (verifier) performs verification by identifying the signature ([...] U, V) of the LAU server by ê([...] P,V) = ê([...] U + h,P_PKG,Q_ID).|$|E
30|$|To {{overcome}} above problems, Rosenblatt [32] and Parzen [33] make improvements on histogram estimation methods. Firstly, replace {{indicator function}} in histogram by smooth kernel function, {{and then set}} estimation interval center as sample <b>observation</b> <b>value.</b> These improvements lead to method {{commonly referred to as}} KDE.|$|E
30|$|According to F(I)[*]≈[*] 14.5123 [*]>[*]F 0.95 and (2, 30 – 3 – 2) = 3.39, and RI is larger, it {{is obvious}} that the <b>observation</b> <b>values</b> of 29 and 30 are {{abnormal}} points. This is consistent with the results obtained by Atkinson and Cheng.|$|R
40|$|Abstract. A new {{approach}} is proposed {{to detect and}} track the moving object. The affine motion model and the non-parameter distribution model are utilized to represent the object firstly. Then the motion region of the object is detected by background difference while Kalman filter estimating its affine motion in next frame. Center association and mean shift are adopted to obtain the <b>observation</b> <b>values.</b> Finally, the distance variance and scale variance between the estimated and detected regions are used to fuse the <b>observation</b> <b>values</b> to acquire the measurement value. To correct fusion errors, the observable edges are employed. Experimental {{results show that the}} new method can successfully track the object under such case as merging, splitting, scale variation and scene noise...|$|R
3000|$|... • The triplification {{engine is}} a {{software}} component responsible for consuming and “homogenising” {{the representation of}} incoming raw <b>observation</b> <b>values.</b> The use of time-stamped RDF triples, incorporating OWL-based subjects, predicates and objects, promotes human-readability {{while at the same}} time allowing us to exploit the extensive capabilities of SPARQL query languages.|$|R
30|$|In this example, {{the goal}} is to model a {{one-dimensional}} <b>observation</b> <b>value</b> using both ME-based modeling and a contextual additive structure. Due to the prime importance of mean parameters in HMM-based speech synthesis [47], we investigate the difference between mean values predicted by two systems.|$|E
40|$|Autonomous {{unmanned}} vehicles {{equipped with}} sensors are rapidly becoming the de facto means of achieving situational awareness — {{the ability to make}} sense of, and predict what is happening in an environment. Particularly in environments that are subject to continuous change, the use of such teams to maintain accurate and up-to-date situational awareness is a challenging problem. To perform well, the vehicles need to patrol their environment continuously and in a coordinated manner. To address this challenge, we develop a near-optimal multi-agent algorithm for con-tinuously patrolling such environments. We first define a general class of multi-agent information gathering problems in which vehicles are represented by information gath-ering agents — autonomous entities that direct their activity towards collecting infor-mation with the aim of providing accurate and up-to-date situational awareness. These agents move on a graph, while taking measurements with the aim of maximising the cumulative discounted <b>observation</b> <b>value</b> over time. Here, <b>observation</b> <b>value</b> is an ab-stract measure of reward, which encodes the properties of the agents ’ sensors, and th...|$|E
30|$|In this research, we {{performed}} the registration {{of a new}} meteorological observation system using the mutual authentication. We utilized the Identity Based Signature to transmit the <b>observation</b> <b>value,</b> and verify {{the integrity of the}} transmitting result. In a case where a new weather sensor is added, we differentiated the area performing the mutual authentication between the data logger and the LAU Server from the area transmitting the observed data of the LAU server to the Data Gathering Server (DGS) utilizing the Identity Based Signature.|$|E
50|$|In {{statistical}} modelling the MSE, representing {{the difference between}} the actual observations and the <b>observation</b> <b>values</b> predicted by the model, is used {{to determine the extent to}} which the model fits the data and whether the removal or some explanatory variables, simplifying the model, is possible without significantly harming the model's predictive ability.|$|R
3000|$|... with DBH the {{diameter}} of the tree and DBHq the quadratic mean diameter of all trees on the plot at the first <b>observation.</b> <b>Values</b> smaller than zero indicate that the tree is relatively small and more likely to be suppressed, while values larger than zero indicate that the tree {{is more likely to be}} dominant.|$|R
40|$|This paper {{presents}} a novel feature for {{remote sensing image}} analysis, called multi-scale relative salience (MsRS) feature. It is constructed by modeling the process of feature value changing with scales. Firstly, the multi-scale <b>observation</b> <b>values</b> at each site are obtained by convolved with recursive Gaussian filters for efficiency. Secondly, the multi-scale <b>observation</b> <b>values</b> are compared with the initial value to generate the relative salience. Lastly, the relative salience between multi-scales are embed into a single feature called the MsRS. The scale in MsRS has explicit spatial meaning which is convenient to choose appropriate scale for specified object. In the MsRS map, the inner of each object become more consistent, while the contrast between object and background is enlarged. The MsRS {{can be used as}} preprocessing step of many applications, such as segmentation. Two state-of-art segmentations (the mean shift and the statistical region merging) are taken into experiments and the results proved that it brings improvement obviously. © 2013 Elsevier GmbH. This paper {{presents a}} novel feature for remote sensing image analysis, called multi-scale relative salience (MsRS) feature. It is constructed by modeling the process of feature value changing with scales. Firstly, the multi-scale <b>observation</b> <b>values</b> at each site are obtained by convolved with recursive Gaussian filters for efficiency. Secondly, the multi-scale <b>observation</b> <b>values</b> are compared with the initial value to generate the relative salience. Lastly, the relative salience between multi-scales are embed into a single feature called the MsRS. The scale in MsRS has explicit spatial meaning which is convenient to choose appropriate scale for specified object. In the MsRS map, the inner of each object become more consistent, while the contrast between object and background is enlarged. The MsRS can be used as preprocessing step of many applications, such as segmentation. Two state-of-art segmentations (the mean shift and the statistical region merging) are taken into experiments and the results proved that it brings improvement obviously. © 2013 Elsevier GmbH...|$|R
40|$|Mathematical {{modeling}} {{for continuous}} prediction of solar energy is inevitable for energy systems. General, existing models are mostly empirical and data dependent. This article has {{to present a}} variable model for predicting global and diffuse solar radiation on the horizontal plane. The model considered in this study has applied Hidden Markov Model (HMM) with two observations. The databases were measured according CIE standard since 2004 to 2010 for model synthetics. The new data of 2011 year used for testing model. Training, take data in time sequence and clustering. After that, create transition probability in each state have two observations matrix; Sky Ratio (SR) and solar altitude angle (Î±) are <b>observation</b> <b>value</b> of the model. Predicting, values of solar radiation are considered as the hidden events by will been calculate probability of observation from P [SR â© Î±], state as highest probability was selected for predict state and convert to solar radiation quantity. Model evaluation, three statistical namely MBD, RMSD and R 2 were used for model evaluations. The results show that, this model is appropriate for predicting sky quantities. Conclusion, the variable model from the synthesis was suitable for predicting long-term data with <b>observation</b> <b>value.</b> The advantage of {{this study showed that}} we could predict sky the quantity value when we only knew the observation values...|$|E
30|$|Observation {{values from}} the weather sensors get {{transmitted}} to the LAU (Local Acquisition Unit) Server after it gets converted into a digital signal through the data logger system. At this point, the data logger system and the LAU Server perform an encrypted communication of symmetry key types using the exchanged security key through the mutual authentication, and the data logger system transmits the <b>observation</b> <b>value</b> to the LAU server every minute. If data cannot be transmitted every minute, either a fault has arisen in the data logger system or an unexpected hijacking has happened. Therefore, an inspection for physical hijacking and responsive actions to the failure need to be performed.|$|E
40|$|In this study, {{we present}} the inverse {{analysis}} for identification of hammering signal in non-destructive hammering test. As the <b>observation</b> <b>value,</b> the observed voltage from microphone is transformed to sound pressure level, {{and the performance}} function is defined by square sum of residual between the obtained and the computed sound pressure levels. Here, the problem {{is to find the}} input sound pressure level so as to minimize the performance function. The formulation for this problem is carried out by the adjoint variable method, and the numerical simulation of the sound pressure level propagation is carried out based on the wave equation and the finite element method...|$|E
40|$|A {{comprehensive}} {{evaluation is}} conducted {{of the numerous}} attempts to estimate the mass of Neptune. It is noted that the two primary methods to mass-determination, respectively based on planetary perturbations and satellite motions, yield results of virtually equal accuracy for the mass of this planet. The attempts discussed encompass Triton <b>observations,</b> the <b>values</b> of Newcomb (1874), photographic <b>observations,</b> and <b>values</b> recently obtained from planetary and spacecraft observations...|$|R
30|$|A PKG gets {{distributed}} to the LAU server after the generation of private keys with Media Access Control (MAC) information. The LAU server transmits the weather <b>observation</b> <b>values</b> to the Data Gathering Server (DGS) signing it with a private key, and the transmitted signature gets inspected in the DGS. If the transmitted signature from the LAU server coincides with it, then the value is confirmed. If not, then the value is discarded.|$|R
40|$|IR {{absorption}} intensities {{are presented}} for thin crystalline films of HCN, HC 3 N, and C 4 N 2, together with n and k complex refractive indices determined {{on the basis}} of an iterative program for the Kramers-Konig integral via a least-squares, point-by-point fitting of the experimental transmission data. It is established that the transmission spectra generated by means of these n and k values can reproduce the experimental transmission <b>observation</b> <b>values</b> to within + or - 2 percent...|$|R
40|$|Autonomous {{unmanned}} vehicles {{equipped with}} sensors are rapidly becoming the de facto means of achieving situational awareness — {{the ability to make}} sense of, and predict what is happening in an environment. Particularly in environments that are subject to continuous change, the use of such teams to maintain accurate and up-to-date situational awareness is a challenging problem. To perform well, the vehicles need to patrol their environment continuously and in a coordinated manner. To address this challenge, we develop a near-optimal multi-agent algorithm for continuously patrolling such environments. We first define a general class of multi-agent information gathering problems in which vehicles are represented by information gathering agents — autonomous entities that direct their activity towards collecting information with the aim of providing accurate and up-to-date situational awareness. These agents move on a graph, while taking measurements with the aim of maximising the cumulative discounted <b>observation</b> <b>value</b> over time. Here, <b>observation</b> <b>value</b> is an abstract measure of reward, which encodes the properties of the agents’ sensors, and the spatial and temporal properties of the measured phenomena. Concrete instantiations of this class of problems include monitoring environmental phenomena (temperature, pressure, etc.), disaster response, and patrolling environments to prevent intrusions from (non-strategic) attackers. In more detail, we derive a single-agent divide and conquer algorithm to compute a continuous patrol (an infinitely long path in the graph) that yields a near-optimal amount of <b>observation</b> <b>value.</b> This algorithm recursively decomposes the graph, until high-quality paths in the resulting components can be computed outright by a greedy algorithm. It then constructs a patrol by concatenating these paths using dynamic programming. For multiple agents, the algorithm sequentially computes patrols for each agent in a greedy fashion, in order to maximise its marginal contribution to the team. Moreover, to achieve robustness, we develop algorithms for repairing patrols when one or more agents fail or the graph changes. For both the single and the multi-agent case, we give theoretical guarantees (lower bounds on the solution quality and an upper bound on the computational complexity {{in the size of the}} graph and the number agents) on the performance of the algorithms. We benchmark the single and multi-agent algorithm against the state of the art and demonstrate that it typically performs 35 % and 33 % better in terms of average and minimum solution quality respectively...|$|E
30|$|An {{observer}} has an id and {{a number}} of receptors of a certain type. It carries a quale and an <b>observation</b> <b>value.</b> The measurement unit used below for observation values is “ppm” standing for parts per million. For simplicity, it is assumed here that all receptors (with a similar function) have the same size, and there is no malfunction during the observation process (i.e., either all the receptors detecting the stimulus are stimulated or none of them). The assumption that all receptors have the same size is in line with Quine [59] who states: “The subject’s sensory receptors are fixed in position, limited in number, and substantially alike”. A COA has one measuring probe.|$|E
30|$|Self-localization of {{the mobile}} robot was {{realized}} by utilizing the MCL method with a belief function {{based on the}} prior known positions of the emitters {{and the strength of}} the IR signal detected by the receivers. Because multiple IR LEDs share the same ID, the belief function is utilized to compute the probability of each IR LED encoded by the detected ID. The LED with the largest probability was used to calculate the <b>observation</b> <b>value</b> for updating the importance weight of each particle. The mobile robot can estimate its location without knowing its starting position and orientation. The experimental results, which were obtained in a real environment, confirmed the validity of the proposed system.|$|E
3000|$|... in (3) were set. Like before, {{the aim was}} to {{minimize}} the distances with respect to human <b>observations.</b> The <b>value</b> of r [...]...|$|R
40|$|AbstractThe {{verification}} system aims at {{monitoring the}} forecast quality over time. Verification helps improving the forecast quality by knowing {{the strengths and}} weaknesses of the existing forecasting system and by comparing the quality of different forecasting methodologies. Thus, the web-based verification system has been developed for verification of forecast results that is produced by International Center for Theoretical Physics Regional Climate Model v 4 for our country. The forecasters and analysts can analyze the data in real-time with this web-based system. In this study, model values obtained from the system provided by ULAKBIM High Performance and Grid Computing Center. Model and station values were compared with each other for verification of model results with <b>observation</b> <b>values.</b> Therefore model grid values are transferred to station by using bi-linear and nearest neighbor (k-NN) (proximal) interpolation methods. This process in meteorological literature is called grid to point technique. Verification methods for forecasts of continuous variables are used to verify forecast <b>values</b> with <b>observation</b> <b>values.</b> Some verification methods; Mean Error, Mean Absolute Error and Root Mean Square Error, are calculated for validation. Verification results are shown as table and graphics on web-based system which is developed by the power of PHP (PHP: Hypertext Preprocessor) ...|$|R
40|$|This paper {{develops}} a computational framework for optimizing {{the parameters of}} data assimilation systems {{in order to improve}} their performance. The approach formulates a continuous meta-optimization problem for parameters; the meta-optimization is constrained by the original data assimilation problem. The numerical solution process employs adjoint models and iterative solvers. The proposed framework is applied to optimize <b>observation</b> <b>values,</b> data weighting coefficients, and the location of sensors for a test problem. The ability to optimize a distributed measurement network is crucial for cutting down operating costs and detecting malfunctions...|$|R
