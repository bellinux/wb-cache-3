48|153|Public
50|$|Word play {{is quite}} common in oral {{cultures}} {{as a method of}} reinforcing meaning. Examples of text-based (<b>orthographic)</b> <b>word</b> play are found in languages with or without alphabet-based scripts; for example, see homophonic puns in Mandarin Chinese.|$|E
5000|$|Other {{languages}} may capitalize {{the initial}} {{letter of the}} <b>orthographic</b> <b>word,</b> {{even if it is}} not present in the base, as with definite nouns in Maltese that start with certain consonant clusters. For example, [...] (the United States) capitalize the epenthetic , even though the base form of the word — without the definite article — is [...]|$|E
5000|$|The (c. 40 BCE) Jijiupian 急就篇, {{which was}} {{compiled}} by Han dynasty scholar Shi You 史游 (fl. 48-33 BCE), was a Chinese primer and a prototype for Chinese dictionaries. This Chinese character abecedarium contains {{a series of}} <b>orthographic</b> <b>word</b> lists, categorized according to character radical, and briefly explained in rhymed lines. In the Qin and Han dynasties, several similar othographic primers were in circulation, such as Cangjiepian, but the Jijiupian {{is the only one}} that survived for two millennia.|$|E
2500|$|The Bengali {{script is}} a cursive script with eleven graphemes or signs {{denoting}} nine vowels and two diphthongs, and thirty-nine graphemes representing consonants and other modifiers. There are no distinct {{upper and lower}} case letter forms. The letters run {{from left to right}} and spaces are used to separate <b>orthographic</b> <b>words.</b> Bengali script has a distinctive horizontal line running along the tops of the graphemes that links them together called [...] matra.|$|R
40|$|Pronunciation {{information}} is available in large quantities on the Web, {{in the form of}} IPA and ad-hoc transcriptions. We describe techniques for extracting candidate pronunciations from Web pages and associating them with <b>orthographic</b> <b>words,</b> filtering out poorly extracted pronunciations, normalizing IPA pronunciations to better conform to a common transcription standard, and generating phonemic from ad-hoc transcriptions. We show improvements on a letter-to-phoneme task when using web-derived vs. Pronlex pronunciations. Index Terms — Speech processing. 1...|$|R
5000|$|The Bengali {{script is}} a cursive script with eleven graphemes or signs {{denoting}} nine vowels and two diphthongs, and thirty-nine graphemes representing consonants and other modifiers. There are no distinct {{upper and lower}} case letter forms. The letters run {{from left to right}} and spaces are used to separate <b>orthographic</b> <b>words.</b> Bengali script has a distinctive horizontal line running along the tops of the graphemes that links them together called [...] matra.|$|R
40|$|We {{evaluate}} several <b>orthographic</b> <b>word</b> similarity {{measures in}} the context of bitext word alignment. We investigate the relationship between the length of the words and the length of their longest common subsequence. We present an alternative to the longest common subsequence ratio (LCSR), a widely-used <b>orthographic</b> <b>word</b> similarity measure. Experiments involving identification of cognates in bitexts suggest that the alternative method outperforms LCSR. Our results also indicate that alignment links {{can be used as a}} substitute for cognates for the purpose of evaluating word similarity measures. ...|$|E
40|$|The general aim of {{this thesis}} was to examine {{variations}} in the word decoding skills of reading disabled children. These variations were related to possible cognitive, developmental, and environmental causes of reading disability. Possible implications for educational interventions were also analysed. The thesis critically examines {{the inclusion of the}} concept of intelligence in the definition of developmental dyslexia. It is suggested that variations in word decoding skills should offer a more solid basis for a study of varieties of reading disability. The empirical studies showed that a) in young children there was a shift from phonological to <b>orthographic</b> <b>word</b> decoding; b) phonological type children (weak in phonological decoding) were characterised by specific phonological deficits; c) surface type children (weak in orthographic decoding) showed more global cognitive deficits suggesting a general developmental delay; d) surface type children showed impaired visual implicit memory for words, which might be associated with limited print exposure; e) an improvement in phonological awareness only transferred to an improved text reading ability for some reading disabled children; f) children who did not benefit from a phonological intervention seemed to rely on <b>orthographic</b> <b>word</b> decoding in text reading. Thus, the thesis suggests that variations in phonological and <b>orthographic</b> <b>word</b> decoding skills offer a useful basis for the study of varieties of reading disability and that educational interventions should pay regard to what the child is already attempting to do when reading. On the day of the defence date the status of article IV was: Manuscript...|$|E
30|$|Within SFL, {{very little}} {{work has been}} done on what {{constitutes}} a word and it is often the case, as it is generally in linguistics, that the <b>orthographic</b> <b>word</b> is the default but this is problematic for a variety of reasons. The most important reason is because English orthography has not been consistent (into but out of, corkscrew but tea towel, etc.). Indeed, the very nature of what is a word cannot be taken for granted (see Wray 2014). The focus on the <b>orthographic</b> <b>word</b> is a real danger to studies of lexis and as corpus linguistics increases in popularity, it becomes even more important to challenge the assumptions surrounding the identification of lexical items. The status of the lexeme and indeed lexical representation within the theory is critically important, not just for the theory itself but for the areas it ventures into including applications and dialogue with other theories of language.|$|E
40|$|Hunmorph: {{open source}} word {{analysis}} Common tasks involving <b>orthographic</b> <b>words</b> include spellchecking, stemming, morphological analysis, and morphological synthesis. To enable significant reuse of the language-specific resources across all such tasks, we have extended the functionality {{of the open}} source spellchecker MySpell, yielding a generic word analysis library, the runtime layer of the hunmorph toolkit. We added an offline resource management component, hunlex, which complements the efficiency of our runtime layer with a high-level description language and a configurable precompiler. ...|$|R
40|$|Learning of Morphology as {{the problem}} of {{inducing}} a description (of some kind, even if only morpheme segmentation) of how <b>orthographic</b> <b>words</b> are built up given only raw text data of a language. We briefly go through the history and motivation of this problem. Next, over 200 items of work are listed with a brief characterization, {{and the most important}} ideas in the field are critically discussed. We summarize the achievements so far and give pointers for future developments. 1...|$|R
40|$|This article surveys work on Unsupervised Learning of Morphology. We define Unsupervised Learning of Morphology as {{the problem}} of {{inducing}} a description (of some kind, even if only morpheme segmentation) of how <b>orthographic</b> <b>words</b> are built up given only raw text data of a language. We briefly go through the history and motivation of this problem. Next, over 200 items of work are listed with a brief characterization, {{and the most important}} ideas in the field are critically discussed. We summarize the achievements so far and give pointers for future developments...|$|R
40|$|WOS: 000276123600003 International audienceAn Adaptive Resonance Theory (ART) {{network was}} trained to {{identify}} unique <b>orthographic</b> <b>word</b> forms. Each word input to the model was represented as an unordered set of ordered letter pairs (open bigrams) that implement a flexible prelexical orthographic code. The network learned to map this prelexical orthographic code onto unique word representations (<b>orthographic</b> <b>word</b> forms). The network was trained on a realistic corpus of reading textbooks used in French primary schools. The amount of training was strictly identical to children's exposure to reading material from grade 1 to grade 5. Network performance was examined at each grade level. Adjustment of the learning and vigilance parameters of the network allowed us to reproduce the developmental growth of word identification performance seen in children. The network exhibited a word frequency effect and {{was found to be}} sensitive to the order of presentation of word inputs, particularly with low frequency words. These words were better learned with a randomized presentation order compared with the order of presentation in the school books. These results open up interesting perspectives for the application of ART networks in the study of the dynamics of learning to read. (C) 2009 Elsevier Ltd. All rights reserved...|$|E
40|$|Most {{research}} into orthographic learning abilities {{has been conducted}} in English with typically developing children using reading-based tasks. In the present study, we examined the abilities of French-speaking children with dyslexia to create novel orthographic representations for subsequent use in spelling and to maintain them in long-term memory. Their performance was {{compared with that of}} chronological age (CA) -matched and reading age (RA) -matched control children. We used an experimental task designed to provide optimal learning conditions (i. e. 10 spelling practice trials) ensuring the short-term acquisition of the spelling of the target <b>orthographic</b> <b>word</b> forms. After a 1 -week delay, the long-term retention of the targets was assessed by a spelling post-test. Analysis of the results revealed that, in the short term, children with dyslexia learned the novel <b>orthographic</b> <b>word</b> forms well, only differing from both CA and RA controls on the initial decoding of the targets and from CA controls on the first two practice trials. In contrast, a dramatic drop was observed in their long-term retention relative to CA and RA controls. These results support the suggestion of the self-teaching hypothesis (Share, 1995) that initial errors in the decoding and spelling of unfamiliar words may hinder the establishment of fully specified novel orthographic representations. Peer reviewe...|$|E
40|$|Reading {{familiar}} words {{differs from}} reading unfamiliar non-words in two ways. First, word reading is {{faster and more}} accurate than reading of unfamiliar non-words. Second, effects of letter length are reduced for words, particularly when they are presented in the right visual field in familiar formats. Two experiments are reported in which right-handed participants read aloud non-words presented briefly in their left and right visual fields before and after training on those items. The non-words were interleaved with familiar words in the naming tests. Before training, naming was slow and error prone, with marked effects of length in both visual fields. After training, fewer errors were made, naming was faster, {{and the effect of}} length was much reduced in the right visual field compared with the left. We propose that word learning creates <b>orthographic</b> <b>word</b> forms in the mid-fusiform gyrus of the left cerebral hemisphere. Those word forms allow words to access their phonological and semantic representations on a lexical basis. But <b>orthographic</b> <b>word</b> forms also interact with more posterior letter recognition systems in the middle/inferior occipital gyri, inducing more parallel processing of right visual field words than is possible for any left visual field stimulus, or for unfamiliar non-words presented in the right visual field...|$|E
40|$|The article takes a {{step back}} and {{examines}} the notion of part of speech (POS), arguing that POS tagsets should be constructed more carefully and, in effect, should be light in at least three senses: 1) they should pay less heed to the traditionally ill-defined notion of POS, 2) they should adopt clear POS delimitation criteria based on solely formal (morphological and morphosyntactic) properties, and 3) tags should be assigned to light units, typically not longer than <b>orthographic</b> <b>words.</b> A tagset for Polish constructed on the basis of such criteria is presented...|$|R
40|$|Words are {{all around}} us {{to the point that}} their {{complexity}} is lost in familiarity. The term “word” itself can ambiguously refer to different linguistic concepts: <b>orthographic</b> <b>words,</b> phonological words, grammatical words, word-forms, lexemes, and to an extent lexical items. While it is hard to come up with exception-less criteria for wordhood, some typical properties are that words are writeable and spellable, consist of morphemes, are syntactic units, carry meaning, and interrelate with other words. Moreover, words can be classified and categorized {{in a number of different}} ways depending on how they are used, by whom, and to what extent they are established within the lexicon. English has many ways of adding new words to its repertoire through both productive and creative means. “Knowing” a word need not entail knowing every facet of its history and usage, yet there is still more to a word than simply the symbol-to-meaning relation...|$|R
40|$|In this paper, we {{analyzed}} situations where (a) one vocabular structure showed in two diﬀerent {{ways in the}} same text or (b) had erasures. These structures ﬂuctuations were extracted from texts written by children that, when the registers were done, were second graders of elementary school. Concerning the results, we veriﬁed: (1) {{that more than one}} prosodic constituent showed in the basis of ﬂuctuation of vocabulary structures; and (2) {{that at least one of}} the limits of <b>orthographic</b> <b>words</b> was maintained in ﬂuctuation structures. These results point to the recuperation done by writers with information they have access due to their insertion in (1) oral practices and (2) literacy practices. ...|$|R
40|$|We {{present a}} novel {{incremental}} learning approach for unsupervised word segmentation that combines features from probabilistic modeling and model selection. This includes super-additive penalties {{for addressing the}} cognitive burden imposed by long word formation, and new model selection criteria based on higher-order generative assumptions. Our approach is fully unsupervised; it relies on {{a small number of}} parameters that permits flexible modeling and a mechanism that automatically learns parameters from the data. Through experimentation, we show that this intricate design has led to top-tier performance in both phonemic and <b>orthographic</b> <b>word</b> segmentation. Comment: 12 pages, 2014, unpublishe...|$|E
40|$|The {{mapping of}} a raw phonetic {{transcription}} to an <b>orthographic</b> <b>word</b> sequence {{is carried out}} in three steps: First, a syllable segmentation of the transcription is bootstrapped, based on unsupervised subtractive learning. Then, the syllables are grouped to word entities guided by non-linguistic distributional properties. Finally, the phonetic word segmentations are mapped onto entries of a canonic pronunciation dictionary {{by means of a}} co-occurrence based aligner. For syllable segmentation accuracies between 89 and 96 % are obtained, and for word segmentation accuracies between 92 and 98 %. The transcription to word conversion performance amounts 77 %. ...|$|E
40|$|We {{examined}} whether {{young children}} acquire orthographic knowledge during structured adult-led storybook reading even though minimal viewing time {{is devoted to}} print. Sixty-two kindergarten children were read 12 storybook “chapters ” while their eye movements were tracked. Results indi-cated that the children quickly acquired initial mental graphemic representations of target nonwords. This learning occurred even though they focused on the target nonwords approximately one fourth of the total time while viewing the pages. Their ability to acquire the initial orthographic representations of the target nonwords and their viewing time was affected by the linguistic statistical regularities of the words. The results provide evidence of orthographic learning during structured storybook reading and {{for the use of}} implicit linguistic statistical regularities for learning new <b>orthographic</b> <b>word</b> forms {{in the early stages of}} reading development. Experts have suggested that adult-led storybook reading enhances young children’s oral language, emergent literacy, and literacy skills (e. g., Bus, van IJzendoorn, & Pellegrini, 1995; Scarborough & Dobrich, 1994). However, based on young children’s minimal viewing time devoted to the written words on a page, researchers also have suggested that storybook read-ing is not conducive to the development of knowledge for orthographic patterns and/or specific <b>orthographic</b> <b>word</b> forms (e. g., Evans, Williamson, & Pursoo, 2008; Justice, Pullen, & Pence, 2008). However, across a series of studies, Apel and colleagues have documented young chil-dren’s ability to quickly acquire initial mental graphemic representations (MGRs), that is, At the time of this study, all authors were affiliated with Florida State University...|$|E
50|$|The other {{research}} partnership was with A. Dean Forbes, who was Project Manager for Computer Speech Recognition Research at Hewlett-Packard Laboratories in Palo Alto, California. Over {{a period of}} more than thirty-five years, Andersen and Forbes have carried out {{research in the field}} of computer-assisted corpus linguistics, developing a computer database of all the clauses in the Hebrew Bible. During the initial period of research from 1971 to 1979, Andersen transcribed the entire text of the Leningrad Codex of the Hebrew Bible into machine readable form. The <b>orthographic</b> <b>words</b> were then segmented into grammatical segments. A linguistic dictionary was generated by the computer, which included grammatical information on each segment.|$|R
25|$|Bengali text {{is written}} and read horizontally, {{from left to}} right. The {{consonant}} graphemes and the full form of vowel graphemes fit into an imaginary rectangle of uniform size (uniform width and height). The size of a consonant conjunct, regardless of its complexity, is deliberately maintained {{the same as that}} of a single consonant grapheme, so that diacritic vowel forms can be attached to it without any distortion. In a typical Bengali text, <b>orthographic</b> <b>words,</b> words as they are written, can be seen as being separated from each other by an even spacing. Graphemes within a word are also evenly spaced, but that spacing is much narrower than the spacing between words.|$|R
40|$|This project {{involved}} {{the design and}} development of a relational SQL-based database to generate an intonational model for an Argentine Spanish text to speech system. The first stage in {{the population of the}} database {{involved the}} massive loading of text, divided into three co-indexed files: sentences, <b>orthographic</b> <b>words</b> and phonological syllables. A software tool, which performed phonemic transcription and syllabic segmentation of the text, was developed to allow indexation. In the beginning, a large set of sentences was loaded, then, a subset of 741 sentences was selected, according to criteria related to syllable occurrences in all positions in words with and without stress. This set contained 97 % of all Spanish syllables extracted from a widely used Spanish dictionary...|$|R
40|$|AbstractThis article {{describes}} {{a method for}} reducing the error rate of probabilistic phone-based transcriptions resulting from mismatched crowdsourcing by using language-specific constraints to post-process the phone sequence. In the scenario under consideration, there are no native-language transcriptions or pronunciation dictionary available in the test language; instead, available resources include non-native transcriptions, a rudimentary rule-based G 2 P, {{and a list of}} <b>orthographic</b> <b>word</b> forms mined from the internet. The proposed solution post-processes non-native transcriptions by converting them to test-language orthography, composing with testlanguage word forms, then converting back to a phone string. Experiments demonstrate that the phone error rate of the transcription is reduced, using this method, by 22 % on an independent evaluation-test dataset...|$|E
30|$|However, some {{concerns}} exist when using bag-of-word models. In Chinese, {{since there are}} no delimiters used in word boundaries, a long controversy over wordhood issues has been raised among linguists. While applying bag-of-word models, the existence of wordhood needs to be assumed in advance, and a word segmentation system should be involved in preprocessing steps, for languages whose <b>orthographic</b> <b>word</b> boundary is not explicitly marked. Computational works in Chinese NLP-related studies used to take the task of wordhood assessment or word segmentation as a discrete (binary) decision, instead of continuous data segmentation, and have to presume a priori agreement (in whatever sense) that guides the production of segmented data, which could be further divided into training and testing data for follow-up procedures.|$|E
40|$|The {{current study}} {{investigated}} {{the role played by}} conflict monitoring in a lexical-decision task involving competing word representations, using event-related potentials. We extended the multiple read-out model (Grainger and Jacobs, 1996), a connectionist model of word recognition, to quantify conflict by means of Hopfield Energy, which is defined as the sum of the products of all <b>orthographic</b> <b>word</b> node pair activations within the artificial mental lexicon of this model. With increasing conflict levels in nonwords, a late negativity increased in amplitude (400 - 600 ms) accompanied by activation of the anterior cingulate cortex and the medial frontal gyrus. The simulated conflict predicted the amplitudes associated with this mediofrontal conflict-monitoring network on an item level, and is consistent with the conflict-monitoring theory. Peer-reviewedPost-prin...|$|E
40|$|International audienceIn this article, I review {{knowledge}} about the cognitive abilities involved in a crucial stage of developing reading and spelling expertise: acquiring knowledge of the <b>orthographic</b> structure of <b>words.</b> Specifically, I focus on three abilities that seem fundamental for this acquisition: (a) decoding ability—because most <b>word</b> <b>orthographic</b> knowledge is acquired implicitly during reading, the ability to deduce the pronunciation of a word from its written form is essential; (b) the ability to process simultaneously all {{the letters of the}} word that is read, an ability that is also involved in implicit acquisition and supported by both theoretical and empirical data; and (c) the ability of handwriting to enhance <b>word</b> <b>orthographic</b> acquisition. I conclude with practical consequences for teaching literacy and detecting reading and spelling difficulties early...|$|R
40|$|Automatic speech {{recognition}} (ASR) relies on three resources: audio, orthographic transcrip-tions and a pronunciation dictionary. The dictionary or lexicon maps <b>orthographic</b> <b>words</b> to sequences of phones or phonemes {{that represent the}} pronunciation of the corresponding word. The quality of a {{speech recognition}} system depends heavily on the dictionary and the transcrip-tions therein. This paper presents an analysis of phonetic/phonemic features that are salient for current Danish ASR systems. This preliminary study consists {{of a series of}} experiments using an ASR system trained on the DK-PAROLE corpus. The analysis indicates that transcribing e. g. stress or vowel duration has a negative impact on performance. The best performance is obtained with coarse phonetic annotation and improves performance 1 % word error rate and 3. 8 % sentence error rate...|$|R
30|$|Previous psycholinguistic {{work has}} {{demonstrated}} that <b>orthographic</b> similarity among <b>words</b> affects reading speeds and accuracies. In {{a review of the}} literature surrounding orthographic neighborhood effects, Andrews (1997; see also Grainger 1992) concluded that <b>words</b> with more <b>orthographic</b> neighbors (i.e., <b>words</b> that are similarly spelled to the target word) were more efficiently processed (i.e., a facilitatory effect), although others have argued that orthographic neighbors play an inhibitory role in lexical access (Perea and Rosa 2000; Davis et al. 2009). This is a central research question in the field because it can lead to insights regarding the processes underlying visual word recognition. For instance, a key feature of interactive-activation models (e.g., McClelland and Rumelhart 1981; Grainger and Jacobs 1996) is that lexical access is the outcome of competitive processes among partially activated word candidates, which suggest that increased <b>orthographic</b> similarity among <b>words</b> should inhibit lexical access—a notion that is inconsistent with prior work showing a facilitatory effect of orthographic neighbors (Siakaluk et al. 2002).|$|R
40|$|DISCERN is an {{integrated}} {{natural language processing}} system built entirely from distributed neural networks. It reads short narratives about stereotypical event sequences, stores them in episodic memory, generates fully expanded paraphrases of the narratives, and answers questions about them. Processing in DISCERN is based on hierarchically-organized backpropagation modules, communicating through a central lexicon of word representations. The lexicon is a double feature map system that transforms each <b>orthographic</b> <b>word</b> symbol into its semantic representation and vice versa. The episodic memory is a hierarchy of feature maps, where memories are stored "one-shot" at different locations. Several high-level phenomena emerge automatically from the special properties of distributed neural networks in this model. DISCERN learns to infer unmentioned events and unspecified role fillers, generates expectations and defaults, and exhibits plausible lexical access errors and memory interference beh [...] ...|$|E
40|$|We report {{patterns}} of dysgraphia in participants with primary progressive aphasia {{that can be}} explained by assuming disruption of one or more cognitive processes or representations in the complex process of spelling. These patterns are compared to those described in participants with focal lesions (stroke). Using structural imaging techniques, we found that damage to the left extrasylvian regions, including the uncinate, inferior fronto-occipital fasciculus, and sagittal stratum (including geniculostriate pathway and inferior longitudinal fasciculus), as well as other deep white and grey matter structures, was significantly associated with impairments in access to <b>orthographic</b> <b>word</b> forms and semantics (with reliance on phonology-to-orthography to produce a plausible spelling in the spelling to dictation task). These results contribute not only {{to our understanding of the}} {{patterns of}} dysgraphia following acquired brain damage but also the neural substrates underlying spelling...|$|E
40|$|In {{this paper}} we explore Simple Recurrent Networks with feature-based letter and phoneme {{encoding}} to transform orthographic representations to phonological ones of Dutch words, which {{is a part of}} the bigger, text-to-speech synthesis problem. Besides addressing cognitive plausibility, this model performs better than earlier implementations with orthogonal data encoding, which allows useful implementations. We also studied the performance of the network functionally, which led to insights about its behaviour and its implicit linguistics, which in turn were used to present the data to the network during training in a way that would improve learning. 1 Introduction Converting <b>orthographic</b> <b>word</b> representations to phonological ones is interesting from both cognitive and linguistic points of view. From the former perspective, we are looking for a biologically plausible explanation of a part of our cognitive capacity to speak, in particularly the process of reading aloud. On another hand, co [...] ...|$|E
40|$|Usage-based models {{claim that}} first {{language}} learning {{is based on}} the frequency-based analysis of memorised phrases. It is not clear though, whether adult second language learning works in the same way. It has been claimed that non-native language lacks idiomatic formulas, suggesting that learners neglect phrases, focusing instead on <b>orthographic</b> <b>words.</b> While a number of studies challenge the claim that non-native language lacks formulaicity, these studies have two important shortcomings: they fail to take account of appropriate frequency information and they pool the writing of different learners in ways that may mask individual differences. Using methodologies which avoid these problems, this study found that non-native writers rely heavily on high-frequency collocations, but that they underuse less frequent, strongly associated collocations (items which are probably highly salient for native speakers). These findings are consistent with usage-based models of acquisition while accounting for the impression that non-native writing lacks idiomatic phraseology. © Walter de Gruyter...|$|R
40|$|Discussion {{around the}} {{importance}} and prevalence of multiword expressions in the lexicon and the teaching of vocabulary has existed {{for a number of}} years in applied linguistics (e. g. lrujo, 1986; Pawley and Syder, 1983; Sinclair, 1987; Wray, 2002). While there seems to be a general agreement among scholars that formulaic language should feature in language learning and, perhaps to a lesser extent, language testing, there appears to be rather less agreement when it comes to how to select and/or prioritize specific items for inclusion. One criterion for selection which has been used often for vocabulary items of single words is frequency (i. e. how relatively common a word is), data for which can be consulted using various frequency lists that have long existed and are in the public domain, such as the General Service List (West, 1953). However, to date, no list of formulaic language that could be considered comparable to the General Service List in terms of intended use and relevance to language instruction has been attempted. The work presented in the present thesis aims to address this lack. The thesis first presents the need for such a list, and then describes the methodology employed by the researcher to ultimately produce a frequency-informed and pedagogically-relevant list of multiword expressions that can be used in conjunction with existing lists single <b>orthographic</b> <b>words</b> to help inform such instruments of L 2 pedagogy as language textbooks and language tests, entitled the PHRASal Expressions List, or PHRASE List. To that end, two projects are also presented in the thesis which exemplify ways in which the list may be usefully employed. The first is a research validation exercise carried out in collaboration with the English Profile project in order to compare the phraseological component of the English Profile Wordlist to the expressions in the PHRASE List. The second project presents the development and validation of a kind of vocabulary test that samples from the PHRASE List, and which is intended to be used to supplement knowledge assessed in existing tests of single <b>orthographic</b> <b>words,</b> such as the Vocabulary Size Test (Nation & Beglar, 2007) ...|$|R
2500|$|Within a clause, rhythm {{also plays}} a role. However, {{referential}} words (lexical words and pronouns) attract stress, whereas [...] "connecting" [...] words such as prepositions tend not to: dónu al mí or dónu al mi ('give to me'), not *dónu ál mi. In Ĉu vi vídas la húndon kiu kúras preter la dómo? ('Do you see the dog that's running past the house?'), the function words do not take stress, not even two-syllable kiu ('which') or preter ('beyond'). The verb esti ('to be') behaves similarly, {{as can be seen}} by the occasional elision of the e in poetry or rapid speech: Mi ne ’stas ĉi tie! ('I'm not here!') Phonological words do not necessarily match <b>orthographic</b> <b>words.</b> Pronouns, prepositions, the article, and other monosyllabic function words are generally pronounced as a unit with the following word: mihávas ('I have'), laknábo ('the boy'), delvórto ('of the word'), ĉetáblo ('at table'). Exceptions include kaj 'and', which may be pronounced more distinctly when it has a larger scope than the following word or phrase.|$|R
