20|1120|Public
2500|$|According to Walid Khalidi, the {{objective}} of this operation, under the command of Yigal Allon, was to clear upper Galilee of its Arab population. The <b>operation</b> <b>log</b> book, 4 May 1948, states [...] "blow up the houses and burn all the bedouin tents". Typical of the attacks was that on Mughr al-Khayt whose residents fled after a night of bombardment on 2 May 1948. Also on 2 May, the Palmach 3rd Battalion, commanded by Moshe Kelman, attacked Ein al-Zeitun with a Davidka, two 3-inch mortars and eight 2-inch mortars. During the following two days Palmach sappers blew up and burned all the houses. In the aftermath of the capture of this village Battalion Commander Kelman ordered the execution of seventy prisoners.|$|E
50|$|The master {{maintains}} {{all of the}} files's metadata, including file names, directories, and {{the mapping}} of files {{to the list of}} chunks that contain each file’s data. The metadata is kept in the master server's main memory, along with the mapping of files to chunks. Updates to this data are logged to an <b>operation</b> <b>log</b> on disk. This <b>operation</b> <b>log</b> is replicated onto remote machines. When the log become too large, a checkpoint is made and the main-memory data is stored in a B-tree structure to facilitate mapping back into main memory.|$|E
5000|$|According to Walid Khalidi, the {{objective}} of this operation, under the command of Yigal Allon, was to clear upper Galilee of its Arab population. The <b>operation</b> <b>log</b> book, 4 May 1948, states [...] "blow up the houses and burn all the bedouin tents". Typical of the attacks was that on Mughr al-Khayt whose residents fled after a night of bombardment on 2 May 1948. Also on 2 May, the Palmach 3rd Battalion, commanded by Moshe Kelman, attacked Ein al-Zeitun with a Davidka, two 3-inch mortars and eight 2-inch mortars. During the following two days Palmach sappers blew up and burned all the houses. In the aftermath of the capture of this village Battalion Commander Kelman ordered the execution of seventy prisoners.|$|E
30|$|Logging Controller {{documents}} {{critical system}} and <b>operation</b> <b>logs</b> so that users can examine them as required. This enables event tracking, diagnostics and performance evaluation tasks via the platform.|$|R
50|$|In 2007 Wiley Post <b>logged</b> 74,519 flight <b>operations.</b> This figure {{accounts}} for only those <b>operations</b> <b>logged</b> by the air traffic control tower which is open daily from 7 A.M. until 10 P.M.|$|R
50|$|Whaling {{records from}} this region have {{provided}} data {{used to justify}} scientific and historic discoveries. For example, Japanese and Filipino <b>operation</b> <b>logs</b> justified {{the existence of the}} Omura's Whale (Balaenoptera omurai) in 2003.|$|R
40|$|Abstract [...] -Decision on {{reservoir}} {{water release}} is crucial during both intense and less intense rainfall seasons. Even though reservoir water release {{is guided by}} the procedures, decision usually made based on the past experiences. Past experiences are recorded either hourly, daily, or weekly in the reservoir <b>operation</b> <b>log</b> book. In a few years this log book will become knowledge-rich repository, but very difficult and time consuming to be referred. In addition, the temporal relationship between the data cannot be easily identified. In this study window sliding technique is applied to extract information from the reservoir operational database: a digital version of the reservoir <b>operation</b> <b>log</b> book. Several data sets were constructed based on different sliding window size. Artificial neural network was used as modelling tool. The findings indicate that eight days is the significant time lags between upstream rainfall and reservoir water level. The best artificial neural network model is 24 - 15 - 3...|$|E
40|$|Background: Gall stone {{disease is}} one of the {{commonly}} handled surgical pathologies by a General Surgeon. Major intra operative complications are less commonly encountered in experienced hands. The rate may increase in a teaching hospital where Residents are allowed to operate. Therefore it was with this assumption that a study was carried to assess the incidence and contributing factors for the complications in a tertiary teaching hospital. Methods: A retrospective chart and <b>operation</b> <b>log</b> book review was done in a two-yea...|$|E
30|$|MongoDB’s {{horizontal}} scalability {{is mainly}} provided {{through the use}} of automatic sharding [56]. Replication is also supported using locks and the asynchronous master-slave model, meaning that writes are only processed by the master node and reads can be made from both the master node and from one of the slave nodes. Writes are propagated to the slave nodes by reading from the master’s oplog (<b>operation</b> <b>log)</b> [56]. Database clients can choose the kind of consistency models they wish, by defining whether reads from secondary nodes are allowed and from how many nodes the confirmation must be obtained.|$|E
50|$|Forestry {{companies}} have maintained in <b>operation</b> <b>logging</b> camps {{near the mouth}} of the “Rivière aux rats” until 1984. The ferry connecting the two banks of Saint-Maurice River was in operation until 1980, after the construction of the bridge over the Saint-Maurice River.|$|R
50|$|Kernel {{extensions}} {{were added}} to Solaris to allow for bootable Veritas VxFS <b>operation.</b> <b>Logging</b> or Journaling was added to UFS in Sun's Solaris 7. Releases of Solaris 10, Solaris Express, OpenSolaris, and other open source variants of the Solaris operating system later supported bootable ZFS.|$|R
50|$|While most railroads of this variety were temporary, {{it was not}} {{uncommon}} for permanent railroads to take their place as a complement to <b>logging</b> <b>operations</b> or as an independent <b>operation</b> once <b>logging</b> ended.|$|R
40|$|This paper {{describes}} {{the evaluation process}} for public transportation plan of On-demand bus in field experiment. The field experiment for introducing On-demand bus is generally evaluated by a questionnaire survey. It cost abundantly and cannot analysis of user's activity change in time series. By using the <b>operation</b> <b>log</b> data on On-demand bus, the improvement for operation plan is suggested considering the regional condition. Through the case studies in 8 cities, the suggested process succeeded to evaluate and feedback the operation plan efficiently. 報告番号:; 学位授与年月日: 2012 - 03 - 22; 学位の種別: 修士; 学位の種類: 修士(環境学); 学位記番号: 修創域第 4417 号; 研究科・専攻: 新領域創成科学研究科環境学研究系人間環境学専...|$|E
40|$|Following is the Operations Manual for the Pennsylvania Ave Bridge over I- 235 {{located in}} Des Moines, Iowa, which was {{installed}} from July 1992 to October 1992. The project uses ELGARD™ 210 Anode Mesh and {{is divided into}} 3 zones. Periodic data collection and/or inspection of the cathodic protection system is required to insure proper operation and a long life. This Operation Manual contains a schedule, operation procedures, <b>operation</b> <b>log</b> forms, a rectifier panel drawing, and pertinent reference matenal. Operation procedures and operating records are contained {{in the body of}} the manual, while blank operation forms, as built drawings, and pertinent reference material are contained in the appendices...|$|E
40|$|Abstract. Currently, the {{embedded}} database technology {{has become a}} very active research field, and attracted more and more attention. This paper research how to improve the storage performance of {{embedded database}} indexing mechanism using read and write characteristics of NAND flash memory. Based on the reviewed and compared of existing design of NAND flash memory, this article expressed the design and implementation of dynamic index mechanism base on B + Tree. The prototype system combines the advantages of operation of the adapted read operation disk model and write adapted write <b>operation</b> <b>log</b> model, optimal matching and converting for storage model of each node in B + tree model while running which make a variety of devices have better read and write performance...|$|E
50|$|The area {{is known}} for a history of <b>logging</b> <b>operations.</b> Remnants of <b>logging</b> railroads are still present in the area. In the 1970s, there was a plan to open a park which was {{centered}} on narrow gauge live steam equipment. It was to feature restored locomotives from the <b>logging</b> <b>operation</b> here.|$|R
40|$|Abstract. Define Ψ(x, y) to be {{the number}} of {{positive}} integers n ≤ x such that n has no prime divisor larger than y. We present a simple algorithm that log log x approximates Ψ(x, y) inO(y { log y + 1 }) floating point <b>operations.</b> <b>log</b> log y This algorithm is based directly on a theorem of Hildebrand and Tenenbaum. We also present data which indicate that this algorithm is more accurate in practice than other known approximations, including the well-known approximation Ψ(x, y) ≈ xρ(log x / log y), where ρ(u) is Dickman’s function. 1...|$|R
40|$|Motivated by {{our work}} on {{object-oriented}} Content Management, this paper proposes an extensible formal framework for delta and merging strategies, each applicable {{to a specific}} type of content under specific constraints. By exploiting type-specific constraints, adequate deltas can be computed even without detailed <b>operation</b> <b>logs.</b> The framework thereby allows the use of unmodified third-party editing applications...|$|R
30|$|Checkpoint or memory {{snapshots}} [12, 13] is {{a commonly}} used program recovery strategy, but the overhead of storing states of running program is very high, {{and it is}} not suitable for embedded applications. In addition, the logs in embedded systems record the behaviors of embedded systems, and researchers use different logs to design different recovery strategies, such as partition log [14], real-time log [15], remote log [16], and <b>operation</b> <b>log</b> [17]. However, these strategies only take the requirement of real-time into consideration, and ignore other specific requirements in embedded systems, so they cannot be applied to the embedded environment efficiently. In addition, the method proposed in [13], studied the recovery strategy in main-memory, but the method is based on virtual memory snapshots. In order to improve real-time ability, Levy and Silberschatz [18] proposed an incremental recovery strategy in main-memory database.|$|E
40|$|Usability is a multi-dimensional {{characteristic}} of a computer system. This paper focuses on usability as a measurement of interaction between the user and the system. The research employs a task-oriented approach to evaluate the usability of a meta search engine. This engine encourages and accepts queries of unlimited size expressed in natural language. A variety of conventional metrics developed by academic and industrial research, including ISO standards, are applied to the information retrieval process consisting of sequential tasks. Tasks range from formulating (long) queries to interpreting and retaining search results. Results of the evaluation {{and analysis of the}} <b>operation</b> <b>log</b> indicate that obtaining advanced search engine results can be accomplished simultaneously with enhancing the usability of the interactive process. In conclusion, we discuss implications for interactive information retrieval system design and directions for future usability research. </p...|$|E
40|$|LINAC and the Rapid Cycling Synchrotron (RCS) in the J-PARC {{accelerator}} complex {{consist of}} {{a huge number of}} accelerator machine components. They produce extreme high power beam of 1 MW. To minimize radiation due to beam loss, systematic control of machine parameters of components as the single accelerator system is required. RCS is further complex system where each beam pulse of 25 Hz is injected either into the Material and Life Science Facility (MLF) or into the 50 GeV Main Ring (MR). In order to store these complex control parameters as the only data source shared by the whole control system and accelerator components, a relational database (RDB) system has been developed. The RDB system consists of three kinds of RDB; a machine database which records static machine parameters, a data acquisition database which records data taken with the data acquisition system, and an <b>operation</b> <b>log</b> database which records history of operation parameters. The machine database stores static machine information about control system of each accelerator component. One of the main goals of the database is to generate EPICS configuration files automatically. A JAVA code has been developed and tested successfully. The machine database also stores geometry information and conversion parameters between device parameters and physics parameters. The overall RDB system is designed to have close connection to the high level accelerator operation applications and online simulators. The high level application can save and restore operation parameters with the <b>operation</b> <b>log</b> database. The same set of parameters is used to generate simulation input files together with the geometry data from the machine database. The generator code in JAVA has been developed for XAL and Trace 3 D, and SAD simulation codes. The code utilizes XAL framework [5] developed in SNS. By conversion between device and machine parameters from the machine database, the high level application can directly compare operation parameters of the machines with simulations. The design and the current status of the RDB system are discussed...|$|E
50|$|DeKalb Peachtree Airport {{occupies}} a prime location inside the Perimeter, located less than fifteen minutes from Atlanta's major business centers in Buckhead and Midtown. This proximity drives the 600 <b>operations</b> <b>logged</b> daily by the airport {{which makes it}} the second busiest {{in the state of}} Georgia behind Hartsfield-Jackson Atlanta International Airport, the world's busiest, located eighteen miles (29 km) away.|$|R
50|$|Drilling, Evaluation & Fluids - This segment covers Directional Drilling,Drill Bit Systems, MWD & LWD, Wireline <b>operations,</b> Surface <b>Logging</b> Systems, and Drilling Fluids.|$|R
40|$|Abstract. Attribute-based {{access control}} (ABAC) {{provides}} {{a high level}} of flexibility that promotes security and information sharing. ABAC pol-icy mining algorithms have potential to significantly reduce the cost of migration to ABAC, by partially automating the development of an ABAC policy from information about the existing access-control policy and attribute data. This paper presents an algorithm for mining ABAC policies from <b>operation</b> <b>logs</b> and attribute data. To the best of our knowl-edge, it is the first algorithm for this problem. ...|$|R
40|$|Abstract — Usability is a multi-dimensional {{characteristic}} of a computer system. This paper focuses on usability as a measurement of interaction between the user and the system. The research employs a task-oriented approach to evaluate the usability of a meta search engine. This engine encourages and accepts queries of unlimited size expressed in natural language. A variety of conventional metrics developed by academic and industrial research, including ISO standards, are applied to the information retrieval process consisting of sequential tasks. Tasks range from formulating (long) queries to interpreting and retaining search results. Results of the evaluation {{and analysis of the}} <b>operation</b> <b>log</b> indicate that obtaining advanced search engine results can be accomplished simultaneously with enhancing the usability of the interactive process. In conclusion, we discuss implications for interactive information retrieval system design and directions for future usability research. Index Terms—usability, search engine, search tasks, query formulation, query refinement I...|$|E
40|$|Zlog system, an {{electronic}} <b>operation</b> <b>log</b> {{system based on}} Zope, has been used since January 2004 at the KEKB and PF-AR accelerator facilities at KEK. Zope * is a Web content management system, {{which is based on}} several open source software components like Python and PostgreSQL. It enabled us to develop our Zlog system in a short period, because the Zope system includes a development framework for Web Application Server. The Zlog system was introduced also to J-PARC/KEK-JAEA and RIBF/RIKEN, based on the experiences at KEKB and PF-AR. The Zlog system was proved to be quite portable even under different computer architectures. The Zlog system at KEKB accumulates about 1. 5 million event entries so far, and screenshot images taken during the operation can be stored and viewed as well with entries. In this paper, we describe the present status and component details of the Zlog system...|$|E
40|$|Human-centered {{computing}} embeds {{the human}} {{factors such as}} social and cultural awareness, human abilities, and adaptability to others' activities in the information system and methodology design. This paper proposes a human-centered multimedia E-learning system to address several classical difficulties in distance education via Internet: poor video frame quality, high requirement of network bandwidth, and inefficient interaction. We propose a novel data partition and authoring method to improve the image quality of the lecture notes, handwritings, and web pages. We use a peer-to-peer network structure to support real-time multimedia data broadcasting. The system can provide the real-time interaction between the remote students and the instructor {{just like in the}} classroom lecture. This system also records the multimedia data with an <b>operation</b> <b>log</b> file to support offline multimedia retrieval and summarization. We test our system under the practical education environment in our university for one semester. Department of ComputingRefereed conference pape...|$|E
40|$|Biological wastes in {{forestry}} {{were observed}} from {{view of their}} by-production in silvicultural and <b>logging</b> <b>operations.</b> There were identified points where biological waste was produced in this paper, waste costs ratio for silvicultural and <b>logging</b> <b>operations</b> and were made suggestions for reduction of these costs. Biological waste costs give 34. 4 % of total costs of silvicultural operations and 30 % of total costs of <b>logging</b> <b>operations.</b> Natural regeneration and minor forest produce operations are opportunities for reduction of these costs...|$|R
40|$|International audienceAttribute-based {{access control}} (ABAC) {{provides}} {{a high level}} of flexibility that promotes security and information sharing. ABAC policy mining algorithms have potential to significantly reduce the cost of migration to ABAC, by partially automating the development of an ABAC policy from information about the existing access-control policy and attribute data. This paper presents an algorithm for mining ABAC policies from <b>operation</b> <b>logs</b> and attribute data. To the best of our knowledge, it is the first algorithm for this problem...|$|R
40|$|The {{main tasks}} of the {{operators}} at KEKB accelerator are safety management, beam tuning and <b>operation</b> <b>logging.</b> In KEKB facility, the accelerator scientists are exploring and developing new beam tuning methods to realize high luminosity. To master these new methods quickly and correctly, the operators {{developed their own}} tools for day-to-day operation. As a consequence, the stable and high performance operations have realized. In this paper, we list the operator-developed tools and report the merits of developing tool by the operators. ...|$|R
40|$|The Zlog system, {{which is}} an {{electronic}} <b>operation</b> <b>log</b> system based on Zope, has been used at the KEKB and PF-AR accelerator facilities in KEK since January 2004. Zope 1 is a Web content management system based on several open source software components such as Python and PostgreSQL. By using the Zope system, {{we were able to}} develop our Zlog system in a short period because the Zope system includes a development framework for the Web application server. The Zlog system has also been in-troduced in J-PARC/KEK-JAEA and RIBF/RIKEN {{on the basis of its}} success at the KEKB and PF-AR. The Zlog system is quite portable even under different computer ar-chitectures. The Zlog system at the KEKB has accumu-lated approximately 1. 5 million event entries thus far, and screenshot images captured during the operation can be stored and viewed along with the entries. In this paper, we describe the present status and component details of the Zlog system...|$|E
40|$|It is {{well known}} that {{learning}} customers' preference and making recommendations to them from today's information-exploded environment is critical and non-trivial in an on-line system. There are two different modes of recommendation systems, namely pull-mode and push-mode. The majority of the recommendation systems are pull-mode, which recommend items to users only when and after users enter Application Market. While push-mode works more actively to enhance or re-build connection between Application Market and users. As {{one of the most successful}} phone manufactures,both the number of users and apps increase dramatically in Huawei Application Store (also named Hispace Store), which has approximately 0. 3 billion registered users and 1. 2 million apps until 2016 and whose number of users is growing with high-speed. For the needs of real scenario, we establish a Push Service Platform (shortly, PSP) to discover the target user group automatically from web-scale user <b>operation</b> <b>log</b> data with an additional small set of labelled apps (usually around 10 apps),in Hispace Store. As presented in this work,PSP includes distributed storage layer, application layer and evaluation layer. In the application layer, we design a practical graph-based algorithm (named A-PARW) for user group discovery, which is an approximate version of partially absorbing random walk. Based on I mode of A-PARW, the effectiveness of our system is significantly improved, compared to the predecessor to presented system, which uses Personalized Pagerank in its application layer...|$|E
40|$|In this master project, {{acoustic}} {{method was}} applied for estimating the gradually changed fish density during the crowding near the pump intake in salmon plant. The purpose was to detect if {{the sensitivity of the}} echo sounder is feasible for density estimation. The experiment was conducted at the Salmar Innovamar harvesting and processing plant with two 200 kHz single beam echo sounder ?Simrad EK 15. Two transducers holding by plates were used to collect the acoustic data. The distance between the plates was set as 4, 3, 2. 5 and 1. 5 m, respectively. The experiment consisted of two parts: the first one was a normal group including two tests conducted during two harvesting periods; the second one was a control test that was done after harvesting in a nearly empty cage. Raw data from the echo sounder were processed by Matlab to extract the power data without range compensation. There were some features of the acoustic results which can be explained with the harvesting <b>operation</b> <b>log.</b> However, the fish density was so great that the acoustic energy was decreased rapidly within a range of 2 m, thus it is hard to connect the distribution of power with fish density within the sample volume. Additionally, the volume of the netting was always changed manually and it was impossible to quantify the real density. </p...|$|E
50|$|Offline <b>operations</b> like checkin, <b>log,</b> merge.|$|R
50|$|<b>Logging</b> <b>operations,</b> {{focusing}} on cypress, began in 1909 after a railroad was constructed {{into the west}} edge of the swamp. Over 431 million board feet (1,000,000 m³) of timber, much of it old-growth cypress, {{had been removed from}} the Okefenokee by 1927 when <b>logging</b> <b>operations</b> ceased.|$|R
50|$|After the {{cessation}} of the train's operations {{at the start of}} 1939, 61 001 was used for heating duties at Bw Berlin-Grunewald. From December 1940 it found itself once again in Dresden-Altstadt on express train services and was given conventional train and buffer equipment in November 1942. Its <b>operations</b> <b>log</b> shows that it only made a few runs however. From 1943 to the war's end, the Reichsbahn repair shop (Reichsbahnsausbesserungswerk or RAW) at Braunschweig was responsible for the engine. Between July 1945 and March 1946 it travelled about 40,000 km hauling passenger trains.|$|R
