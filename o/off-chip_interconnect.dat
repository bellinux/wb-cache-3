19|38|Public
50|$|Scalability in {{integration}} level allows product {{companies to}} do fast cost optimization without major extra R&D effort. NoTA core is physical interconnect agnostic and hence replacing e.g. <b>off-chip</b> <b>interconnect</b> with on-chip interconnect does not destroy the device functionality. More practical example is to integrate multiple ICs {{into the same}} package (e.g. through stacking) and use package internal interconnect technologies.|$|E
40|$|Electronic {{packages}} having compliant off-chip interconnects {{and methods}} of fabricating compliant off-chip interconnects are disclosed. A representative electronic package includes a substrate and a free-standing compliant <b>off-chip</b> <b>interconnect.</b> The free-standing compliant <b>off-chip</b> <b>interconnect</b> includes a first free-standing arcuate structure that is substantially parallel to the substrate. In addition, the method of fabricating free-standing arcuate structure compliant off-chip interconnects includes: depositing an arcuate structure compliant <b>off-chip</b> <b>interconnect</b> material; and forming the free-standing arcuate structure compliant <b>off-chip</b> <b>interconnect.</b> Georgia Tech Research Corporatio...|$|E
40|$|Abstract—With {{the rapid}} {{development}} of parallel computing technologies, {{there is an}} urgent demand on increasing the data transmission bandwidth in computer systems. The traditional electrical <b>off-chip</b> <b>interconnect</b> becomes a bottleneck due to {{the limited number of}} I/O pins and the limited per-pin-bandwidth. As an alternative, optical interconnect can support tremendous data bandwidth thanks to low transmission loss and wavelength division multiplexing techniques, but suffers from severe power overhead. Recently, optical orbital angular momentum (OAM) has stimulated much interest due to the very high data carrying ability. In this work, we fully evaluate and compare these <b>off-chip</b> <b>interconnect</b> schemes, and propose the novel OAM-based high-bandwidth interconnect structure, which is the most power-efficient. Index Terms—chip-to-chip interconnect, electrical wire, micro-bump, optical, OA...|$|E
40|$|Optics brings {{opportunities}} for addressing two key problems in electronic chips and systems – interconnects and timing. Optics in principle enables dense, high-speed, long lines and solves prob-lems of signal integrity (e. g., crosstalk, reflections, and voltage isolation) [1]; {{opportunities for}} <b>off-chip</b> <b>interconnects</b> are grow-ing, and on-chip possibilities pose key questions [2]. Optical back-planes are under commercial development, and research shows promise for dense <b>off-chip</b> <b>interconnects</b> with hybridized lasers and modulators. Optics also allows radical {{concepts such as}} short pulse interconnects [3], with timing, sensitivity and latency enhancements, and wavelength division multiplexing [4], with higher line densities and ultimate compatibility with optical net-works. All of these radical concepts have now seen laboratory demonstrations [3, 4]. Short pulse optics offers many opportunities for precise timing, a...|$|R
40|$|The {{continuous}} {{trend towards}} {{higher levels of}} integration is partially driven {{by the fact that}} on-chip interconnects are faster, denser, and more reliable than <b>off-chip</b> <b>interconnects.</b> Over the past decades, this continuous integration has enabled a tremendous improvement in density and speed of electronic systems ranging from radios and televisions to comput...|$|R
40|$|Interconnect {{is one of}} {{the most}} {{important}} functions of packaging technology. It delivers power and signals into and out of electronic systems. The performance and reliability of microsystems are dependent on the interconnect quality. This paper reviews the chip-level interconnects based on carbon nanotubes (CNTs), this includes their applications for both on-chip and <b>off-chip</b> <b>interconnects.</b> Various post-growth processing of CNTs, such as doping, densification, transfer, metallization, etc., for the improvement of their performance will be reviewed...|$|R
40|$|Abstract. This paper {{introduces}} {{the concept of}} context-independent coding using frequency-based mapping schemes {{in order to reduce}} <b>off-chip</b> <b>interconnect</b> power consumption. State-of-the-art context-dependent, double-ended codes for processor-SDRAM off-chip interfaces require the transmitter and receiver (memory controller and SDRAM) to collaborate using current and previously transmitted values to encode and decode data. In contrast, the memory controller can use a context-independent code to encode data stored in SDRAM and subsequently decode that data when it is retrieved, allowing the use of commodity memories. In this paper, a single-ended, context-independent code is realized by assigning limited-weight codes using a frequency-based mapping technique. Experimental results show that such a code can reduce the power consumption of an uncoded <b>off-chip</b> <b>interconnect</b> by an average of 30 % with less than a 0. 1 % degradation in performance. ...|$|E
40|$|This paper {{introduces}} {{a class of}} single-ended coding schemes to reduce <b>off-chip</b> <b>interconnect</b> energy consumption. State-of-the-art codes for processor-memory off-chip interfaces require the transmitter and receiver (memory controller and memory) to collaborate using current and previously transmitted values to encode and decode data. Modern embedded systems, however, cannot afford to use such double-ended codes that require specialized memories {{to participate in the}} code. In contrast, a single-ended code enables the memory controller to encode data stored in memory and subsequently decode that data when it is retrieved, allowing the use of commodity memories. In this paper, single-ended codes are presented that assign limited-weight codewords using trace-based mapping techniques. Simulation results show that such codes can reduce the energy consumption of an uncoded <b>off-chip</b> <b>interconnect</b> by up to 42. 5 %. 1...|$|E
40|$|A {{system and}} method for context-independent coding using frequency-based mapping schemes, sequence-based mapping schemes, memory trace-based mapping schemes, and/or {{transition}} statistics-based mapping schemes {{in order to}} reduce <b>off-chip</b> <b>interconnect</b> power consumption. State-of-the-art context-dependent, double-ended codes for processor-SDRAM off-chip interfaces require the transmitter and receiver (memory controller and SDRAM) to collaborate using the current and previously transmitted values to encode and decode data. In contrast, the memory controller can use a context-independent code to encode data stored in SDRAM and subsequently decode that data when it is retrieved, allowing the use of commodity memories. A single-ended, context-independent code is realized by assigning limited-weight codes using a frequency-based mapping technique. Experimental results show that such a code can reduce the power consumption of an uncoded <b>off-chip</b> <b>interconnect</b> by an average of 30 % with less than a 0. 1 % degradation in performance...|$|E
40|$|It is {{projected}} by the Semiconductor Industry Association in their International Technology Roadmap for Semiconductors (ITRS) {{that by the}} year 2019, with the IC feature size shrinking to about 10 nm, <b>off-chip</b> <b>interconnects</b> in an area array format will require a pitch of 95 µm. Also, as the industry adopts porous low-K dielectric materials, it is important to ensure that the stresses induced by the <b>off-chip</b> <b>interconnects</b> and the package do not crack or delaminate the low-K material. Compliant free-standing structures used as <b>off-chip</b> <b>interconnects</b> are a potential solution. However, there are several design, fabrication, assembly and integration research challenges and gaps with the current suite of compliant interconnects. Accordingly, as part of this research a unique parallel-path approach has been developed which enhances the mechanical compliance of the compliant interconnect without compromising the electrical parasitics. It also provides for redundancy and thus results in more reliable interconnects. Also, to meet both electrical and mechanical performance needs, as part of this research a variable compliance approach has been developed so that interconnects {{near the center of the}} die have lower electrical parasitics while the interconnects near the corner of the die have higher mechanical compliance. Furthermore, this work has developed a fabrication process which will facilitate cost-effective fabrication of free-standing compliant interconnects and investigated key factors which impact assembly yield of free-standing compliant interconnects. Ultimately the proposed approaches are demonstrated by developing an innovative compliant interconnect called FlexConnects. Hence, through this research it is expected that the developed compliant interconnect would address the needs of first level interconnects over the next decade and eliminate a bottleneck that threatens to impede the exponential growth in microprocessor performance. Also, the concepts developed in this research are generic in nature and can be extended to other aspects of electronic packaging. Ph. D. Committee Chair: Dr. Suresh K. Sitaraman; Committee Member: Dr. F. Levent Degertekin; Committee Member: Dr. Ioannis Papapolymerou; Committee Member: Dr. Madhavan Swaminathan; Committee Member: Dr. Nazanin Bassiri-Ghar...|$|R
40|$|Modeling {{approaches}} are developed to optimize emerging on-chip and <b>off-chip</b> electrical <b>interconnect</b> technologies and benchmark them against conventional technologies. While transistor scaling {{results in an}} improvement in power and performance, interconnect scaling results in a degradation in performance and electromigration reliability. Although graphene potentially has superior transport properties compared to copper, it is shown that several technology improvements like smooth edges, edge doping, good contacts, and good substrates are essential for graphene to outperform copper in high performance on-chip interconnect applications. However, for low power applications, the low capacitance of graphene results in 31 % energy savings compared to copper interconnects, for a fixed performance. Further, for characterization of the circuit parameters of multi-layer graphene, multi-conductor transmission line models that account for an alignment margin and finite width of the contact are developed. Although {{it is essential to}} push for an improvement in chip performance by improving on-chip interconnects, devices, and architectures, the system level performance can get severely limited by the bandwidth of <b>off-chip</b> <b>interconnects.</b> As a result, three dimensional integration and airgap interconnects are studied as potential replacements for conventional <b>off-chip</b> <b>interconnects.</b> The key parameters that limit the performance of a 3 D IC are identified as the Through Silicon Via (TSV) capacitance, driver resistance, and on-chip wire resistance on the driver side. Further, the impact of on-chip wires on the performance of 3 D ICs is shown to be more pronounced at advanced technology nodes and when the TSV diameter is scaled down. Airgap interconnects are shown to improve aggregate bandwidth by 3 x to 5 x for backplane and Printed Circuit Board (PCB) links, and by 2 x for silicon interposer links, at comparable energy consumption. Ph. D...|$|R
40|$|This paper {{discusses}} {{the design and}} verification of the <b>off-chip</b> <b>interconnects</b> for a 10 Gigabit Ethernet to XAUI transceiver in a plastic BGA package. The design details of a high-performance, low cost, wirebond plastic BGA package suitable for 10 Gb/s operation are first discussed. The paper then presents details of the board design, especially impedance matching between the single ended connector and the coupled differential trace. Finally, comparisons between measured and simulated eye diagrams and I/O return loss are given, illustrating the feasibility of a high-performance, low-cost 10 G transceiver that exceeds both 10 Gigabit Ethernet and SONET specifications Authors Biograph...|$|R
40|$|Abstract—In this paper,we {{present a}} {{methodology}} for generating guaranteed passive time-domain models of subsystems described by tabulated frequency-domain data obtained through measurement or through physical simulation. Such descriptions {{are commonly used}} to represent on- and <b>off-chip</b> <b>interconnect</b> effects,package parasitics,and passive devices common in high-frequency integrated circuit applications. The approach,which incorporates passivity constraints via convex optimization algorithms,is guaranteed to produce a passive-system model that is optimal {{in the sense of}} having minimum error in the frequency band of interest over all models with a prescribed set of system poles. We demonstrate that this algorithm is computationally practical for generating accurate high-order models of data sets representing realistic, complicated multiinput,multioutput systems. Index Terms—Behavior modeling,convex optimization,convex programming,interconnect modeling,rational fitting,system identification. I...|$|E
40|$|Abstract—Prototyping large SoCs (Systems on Chip) using {{multiple}} FPGAs introduces {{a risk of}} errors on inter-FPGA links. This {{raises the question of}} how we can prove the correct-ness of a SoC prototyped {{using multiple}} FPGAs. We propose using high-speed serial interconnect between FPGAs, with a transparent error detection and correction protocol working on a link-by-link basis. Our inter-FPGA interconnect has an interface that resembles that of a network-on-chip, providing a consistent interface to a prototype SoC and masking the difference between on-chip and <b>off-chip</b> <b>interconnect.</b> Low-latency communication and low area usage are favoured at the expense of a little bandwidth inefficiency, a trade-off we believe is appropriate given the high bandwidth of inter-FPGA links. Keywords-SoC; prototyping; reliability; interconnect; FPGA; communication...|$|E
40|$|International audienceCarbon {{nanotubes}} (CNTs) {{present themselves}} as a viable material for on-and <b>off-chip</b> <b>interconnect</b> material due to their unique electrical, thermal and mechanical properties. The electrothermal properties of CNTs, including high Young's modulus, resiliency and low thermal expansion coefficient offer great advantage for reliable and strong interconnects, {{and even more so}} for local and global on-chip interconnects. With aggressive scaling, on-chip interconnects contribute to power consumption and heat build-up due to their increasing parasitics with scaling which detriment overall energy efficiency of circuits. CNTs present an opportunity to address these challenges and provide solutions for reliable and energy efficient signal and power/ground interconnects. In this work, we investigate the electrical and thermal properties of CNTs based on analytical models for interconnect-level simulations. We investigate the performance of horizontally aligned CNTs as global interconnects and report on their performance...|$|E
40|$|System-in-package {{technology}} is announced {{as one of}} the key technologies, which enables the continued increase in functional density and decrease in cost per function required to maintain the progress of electronics by utilizing 3 D through innovation in packaging and interconnect technology. A key bottleneck to the realization of high-performance microelectronic systems is the lack of low latency, high-bandwidth, and high density <b>off-chip</b> <b>interconnects.</b> Photonics could overcome these challenges and leverage low-latency and high bandwidth communication within next generation architectures. In this paper state-of-the-art approaches will be discussed and the requirements in 3 D integration perspective of converging platforms will be addressed...|$|R
40|$|Carbon {{nanotubes}} (CNTs) due {{to their}} unique mechanical, thermal and electrical properties are being investigated as promising candidate material for on-chip and <b>off-chip</b> <b>interconnects.</b> The attractive mechanical properties of CNTs, including high Youngs modulus, resiliency and low thermal expansion coefficient offer great advantage for reliable and strong interconnects, {{and even more so}} for on-chip and off-chip integration. High bandwidth interconnects are required for achieving denser, faster and energy-efficient circuits. Due to their unique properties, CNTs present an opportunity to address the current challenges of copper interconnects and provide solutions for reliable efficient and smart system integration. In this work, we give an overview on the current advancements on CNT interconnects and the future prospects for energy efficient integration...|$|R
40|$|International audienceCarbon {{nanotubes}} (CNTs) due {{to their}} unique electrical, thermal, and mechanical properties are being investigated as promising candidate material for on-chip and <b>off-chip</b> <b>interconnects.</b> The attractive mechanical properties of CNTs, including high Youngs modulus, resiliency, and low thermal expansion coefficient, offer great advantage for reliable and strong interconnects, {{and even more so}} for local and global on-chip interconnects. With aggressive scaling, on-chip interconnects contribute to power consumption and heat build-up {{due to their}} increasing parasitics with scaling which detriment overall energy efficiency of circuits. Due to their unique properties, CNTs present an opportunity to address these challenges and provide solutions for reliable signal and power/ground interconnects. In this chapter, we perform detailed electro-thermal analyses of horizontally aligned CNTs and report on their performance and voltage drop...|$|R
40|$|We explore data {{compression}} {{in the context}} of a chip multiprocessor as it relates to technology trends and CMP performance. We consider {{data compression}} at various levels of the memory hierarchy, looking particularly at the possibility of data-specific compression algorithms. We analyze the requirements for a compression algorithm to improve system throughput, and look at two specific compression algorithms, analyzing their potential in this domain. We explore possible architectural support for data specific compression. We show that data-specific compression is more reasonable for main memory rather than cache compression, but that compressing the <b>off-chip</b> <b>interconnect</b> may be advisable in either case for a CMP. We conclude that suitable compression algorithms are largely limited to graphics and media application data, where data compression is already commonplace, but that potential exists for more suitable compression algorithms as the need arises. ...|$|E
40|$|Abstract — Driven by {{the need}} for higher {{bandwidth}} and complexity reduction, <b>off-chip</b> <b>interconnect</b> has evolved from proprietary busses to networked architectures. A similar evolution is occurring in on-chip interconnect. This paper presents the design, implementation and evaluation of one such on-chip network, the TRIPS OCN. The OCN is a wormhole routed, 4 x 10, 2 D mesh network with four virtual channels. It provides a high bandwidth, low latency interconnect between the TRIPS processors, L 2 cache banks and I/O units. We discuss the tradeoffs made {{in the design of}} the OCN, in particular why area and complexity were traded off against latency. We then evaluate the OCN using synthetic as well as realistic loads. We found that synthetic benchmarks do not provide sufficient indication of the behavior of realistic loads on this network. Finally, we examine the effect of link bandwidth and router FIFO depth on overall performance. I...|$|E
40|$|In chip multiprocessors (CMPs), {{multiple}} cores {{compete for}} shared {{resources such as}} on-chip caches and off-chip pin bandwidth. Stride-based hardware prefetching increases demand for these resources, causing contention that can degrade performance (up to 35 % for one of our benchmarks). In this paper, we first show that cache and link (<b>off-chip</b> <b>interconnect)</b> compression can increase the effective cache capacity (thereby reducing off-chip misses) and increase the effective off-chip bandwidth (reducing contention). On an 8 -processor CMP with no prefetching, compression improves performance by up to 18 % for commercial workloads. Second, we propose a simple adaptive prefetching mechanism that uses cache compression’s extra tags to detect useless and harmful prefetches. Furthermore, in the central result of this paper, we show that compression and prefetching interact in a strong positive way, resulting in combined performance improvement of 10 - 51 % for seven of our eight workloads. ...|$|E
40|$|The {{design of}} an {{asynchronous}} communication system using partially automated techniques {{is described in}} this paper. The protocol is formally specified as a protocol state machine and verified with respect to deadlock-freedom and delay-insensitivity using Petri net based model-checking tools. A protocol controller has been synthesized by direct mapping of the Petri net model derived from the protocol specification. The logic implementation was analysed using the Cadence toolkit. While most of the controller's logic is robust to arbitrary gate delay variations, a number of speed-up strategies based on relative timing have been considered. The results of SPICE simulation show {{the advantages of the}} direct mapping method compared to logic synthesis. Overall, the design process suggested here offers a generic way to constructing asynchronous communication systems, for both on-chip and <b>off-chip</b> <b>interconnects...</b>|$|R
40|$|International audienceCarbon {{nanotubes}} (CNTs) due {{their unique}} mechanical, thermal, and electrical properties are being investigated as promising candidate material for on-chip and <b>off-chip</b> <b>interconnects.</b> The attractive mechanical properties of CNTs, including high Young’s modulus, resiliency, and {{low thermal expansion}} coefficient offer great advantage for reliable and strong interconnects, {{and even more so}} for 3 D integration. Through-Silicon-Vias (TSVs) enable 3 D integration and implementation of denser, faster, and heterogeneous circuits, which also lead to excessive power densities and elevated temperatures. Due to their unique properties, CNTs present an opportunity to address these challenges and provide solutions for reliable power delivery networks in 2 D and 3 D integration. In this chapter, we perform detailed analyses of horizontally aligned CNTs and report on their efficiency to be exploited for both 2 D and 3 D power delivery networks...|$|R
30|$|CNT bumps {{had been}} {{demonstrated}} by several groups as potential <b>off-chip</b> <b>interconnects</b> [4 – 6]. Soga et al. {{have shown the}} bumps' good mechanical flexibility and low bundle resistance of 2.3 Ω (for a 100 -μm diameter bump) [5]. Hermann et al. demonstrated a reliable electrical flip chip interconnect using CNT bumps over 2, 000 temperature cycles [4]. CNT bumps for practical applications such as high-power amplifier application had also been demonstrated [6]. In all the mentioned works, the CNT bumps were grown using the chemical vapor deposition [CVD] approach. The mechanism for vertical alignment during the CVD approach is achieved by the van der Waals forces between the walls of CNTs, resulting in tubes that are not exactly 'aligned' [7]. The poor 'alignment' forms bends, reduces the mean free path [m.f.p.], and increases the resistance of CNTs [8]. Plasma-enhanced CVD [PECVD] is able {{to resolve this issue}} by the introduction of electric field to achieve alignment as well as lower growth temperature [9].|$|R
40|$|It is {{believed}} that to continue the scaling of silicon CMOS innovative device structures and new materials have to be created {{in order to continue}} the historic progress in information processing and transmission. Recently germanium has emerged as a viable candidate to augment Si for CMOS and optoelectronic applications. In this work we will first review recent results on growth of thin and thick films of Ge on Si, technology for appropriate cleaning of Ge, surface passivation using high-κ dielectrics, and metal induced crystallization of amorphous Ge and dopant activation. Next we will review application of Ge for high performance MOSFETs. Innovative Si/Ge MOS heterostructures will be described with high on current and low off currents. Finally we will describe optical detectors and modulators for on-chip and <b>off-chip</b> <b>interconnect.</b> Successful integration of Ge on Si should allow continued scaling of silicon CMOS to below 22 nm node. ©The Electrochemical Society...|$|E
30|$|Flip chip {{technology}} {{is one of}} the <b>off-chip</b> <b>interconnect</b> methodologies used in electronic packaging. According to the International Technology Roadmap for Semiconductor, the forecasted requirement for flip chip bump pitches will be shrinking them beyond 150 μm [1]. However, traditional solder bumps had difficulties downscaling beyond the 100 -μm pitch size due to the high diffusive and softening nature of the solder [2]. Carbon nanotubes [CNTs] show excellent electrical, thermal, and mechanical properties and have been viewed as one of the emerging choices for future flip chip interconnect [3]. As compared with metal, CNTs possess a higher current carrying capacity (109 A/cm 2), and theoretical studies had also shown that CNTs have a negligible skin depth effect and are free from the high-frequency current crowding issue due to their large kinetic inductance and negligible magnetic inductance [3]. These advantages motivate the researchers to evaluate the performance of the CNT bump for interconnect usage in both direct current [DC] and high frequency applications [3, 4].|$|E
40|$|Chip multiprocessors (CMPs) combine {{multiple}} processors on {{a single}} die, typically with private level-one caches and a shared level-two cache. However, {{the increasing number of}} processors cores {{on a single}} chip increases the demand on two critical resources: the shared L 2 cache capacity and the off-chip pin band-width. Demand on these critical resources is further exacerbated by latency-hiding techniques such as hardware prefetching. In this dissertation, we explore using compression to effectively increase cache and pin bandwidth resources and ultimately CMP performance. We identify two distinct and complementary designs where compression can help improve CMP perfor-mance: Cache Compression and Link Compression. Cache compression stores compressed lines in the cache, potentially increasing the effective cache size, reducing off-chip misses and improving perfor-mance. On the downside, decompression overhead can slow down cache hit latencies, possibly degrading performance. Link (i. e., <b>off-chip</b> <b>interconnect)</b> compression compresses communication messages before sending to or receiving from off-chip system components, thereby increasing the effective off-chip pin bandwidth, reducing contention and improving performance for bandwidth-limited configurations. While compression can {{have a positive impact on}} CMP performance, practical implementations of compressio...|$|E
40|$|As Moore’s Law {{continues}} {{to fuel the}} ability to build ever increasingly complex system-on-chips (SoCs), achieving performance goals is rising as a critical challenge to completing designs. In particular, the system interconnect must efficiently service a diverse set of data flows with widely ranging quality-of-service (QoS) requirements. However, the known solutions for <b>off-chip</b> <b>interconnects</b> such as large-scale networks are not necessarily applicable to the on-chip environment. Latency and memory constraints for on-chip interconnects are quite different from largerscale interconnects. This paper introduces a novel on-chip interconnect arbitration scheme. We show how this scheme can be distributed across a chip for high-speed implementation. We compare {{the performance of the}} arbitration scheme with other known interconnect arbitration schemes. Existing schemes typically focus heavily on either low latency of service for some initiators, or alternatively on guaranteed bandwidth delivery for other initiators. Our scheme allows service latency on some initiators to be traded off smoothly against jitter bounds on other initiators, while still delivering bandwidth guarantees. This scheme is a subset of the QoS controls that are available in the SonicsMX ™ (SMX) product. ...|$|R
40|$|As Moore's Law {{continues}} {{to fuel the}} ability to build ever increasingly complex system-on-chips (SoCs), achieving performance goals is rising as a critical challenge to completing designs. In particular, the system interconnect must efficiently service a diverse set of data flows with widely ranging quality-of-service (QoS) requirements. However, the known solutions for <b>off-chip</b> <b>interconnects</b> such as large-scale networks are not necessarily applicable to the on-chip environment. Latency and memory constraints for on-chip interconnects are quite different from larger-scale interconnects. This paper introduces a novel on-chip interconnect arbitration scheme. We show how this scheme can be distributed across a chip for high-speed implementation. We compare {{the performance of the}} arbitration scheme with other known interconnect arbitration schemes. Existing schemes typically focus heavily on either low latency of service for some initiators, or alternatively on guaranteed bandwidth delivery for other initiators. Our scheme allows service latency on some initiators to be traded off smoothly against jitter bounds on other initiators, while still delivering bandwidth guarantees. This scheme is a subset of the QoS controls that are available in the SonicsMX? (SMX) product. Comment: Submitted on behalf of EDAA ([URL]...|$|R
40|$|Technological frontiers between {{semiconductor}} technology, packaging, {{and system}} design are disappearing. Scaling down geometries {{alone does not}} provide improvement of performance, less power, smaller size, and lower cost. It will require "More than Moore" through the tighter integration of system level components at the package level. System-in-Package (SiP) will deliver the efficient use of three dimensions (3 D) through innovation in packaging and interconnect technology. A key bottleneck {{to the implementation of}} high-performance microelectronic systems, including SiP, is the lack of lowlatency, high-bandwidth, and high density <b>off-chip</b> <b>interconnects.</b> Some of the challenges in achieving high-bandwidth chip-to-chip communication using electrical interconnects include the high losses in the substrate dielectric, reflections and impedance discontinuities, and susceptibility to crosstalk. Obviously, the incentive for the use of photonics to overcome the challenges and leverage low-latency and highbandwidth communication will enable the vision of optical computing within next generation architectures. Supercomputers of today offer sustained performance of more than petaflops, which can be increased by utilizing optical interconnects. Next generation computing architectures are needed with ultra low power consumption; ultra high performance with novel interconnection technologies. In this paper we will discuss a CMOS compatible underlying technology to enable next generation optical computing architectures. By introducing a new optical layer within the 3 D SiP, the development of converged microsystems, deployment for next generation optical computing architecture will be leveraged...|$|R
40|$|Paul A. Kohl, Todd Spencer and Tyler Osborn {{from the}} School of Chemical and Biomolecular Engineering {{presented}} a lecture at the Nano@Tech Meeting on September 9, 2008 at 12 noon in room 102 of the MiRC building. Runtime: 61 : 09 minutesThe "off-chip" bandwidth {{is a major}} bottleneck causing system delays and limited throughput, especially {{in areas such as}} processor-to-memory bandwidth and processor-to-network. The ITRS cites off-chip signal bandwidth exceeding 60 GHz within 10 years. Organic substrates (i. e. chip packages or interposers) with flip-chip solder connections are the core of the first and second level of interconnect. Off-chip bandwidth is limited to several GHz due to frequency dependent attenuation, signal reflections, and crosstalk within the polymer dielectric, via structures, and I/O signal path transitions within the chip substrate and mother board. In this work, we have introduced advances in <b>off-chip</b> <b>interconnect</b> using air-isolated, coaxial links on substrates and boards to demonstrate ultra high-speed chip-to-chip and chip-to-network communications. New approaches have been found to fabricating high frequency I/O, air-and isolated coaxial links on the substrate. The materials, processes and electrical characteristics will be presented...|$|E
40|$|Abstract—As {{the number}} of cores in a chip {{multiprocessor}} (CMP) increases, the need for larger on-chip caches also increases {{in order to avoid}} creating a bottleneck at the <b>off-chip</b> <b>interconnect.</b> Utilization of these CMPs include combinations of multithreading and multiprogramming, showing a range of sharing behavior, from frequent inter-thread communication to no communication. The goal of the CMP cache design is to maximize capacity for a given size while providing as low a latency as possible for the entire range of sharing behavior. In a typical CMP design, the last level cache (LLC) is shared across the cores and incurs a latency of access that is a function of distance on the chip. Sharing helps avoid the need for replicas at the LLC and allows access to the entire on-chip cache space by any core. However, the cost is the increased latency of communication based on where data is mapped on the chip. In this paper, we propose a cache coherence design we call POPS that provides localized data and metadata access for both shared data (in multithreaded workloads) and private data (predominant in multiprogrammed workloads). POPS achieves its goal by (1) decoupling data and metadata, allowing both to be delegated to local LLC slices for private data and between sharers for shared data, (2) freeing delegated data storage in the LLC for larger effective capacity, and (3) changing the delegation and/or coherence protocol action based on the observed sharing pattern. Our analysis on an execution-driven full system simulator using multithreaded and multiprogrammed workloads shows that POPS performs 42 % (28 % without microbenchmarks) better for multithreaded workloads, 16 % better for multiprogrammed workloads, and 8 % better when one single-threaded application is the only running process, compared to the base non-uniform shared L 2 protocol. POPS has the added benefits of reduced on-chip and off-chip traffic and reduced dynamic energy consumption...|$|E
40|$|As {{technology}} scales, interconnect planning {{has been}} widely {{regarded as one of}} the most critical factors in determining the system performance and total power consumption. As the result of shrinking dimension, on-chip wires are getting more resistive, and the delay is becoming larger comparing to gate delay. On the other hand, the self capacitance of wires does not scale with feature size, and as wiring density grows, the total coupling capacitance increases, which results in substantial increment of interconnect power consumption. Meanwhile, <b>off-chip</b> <b>interconnect</b> is also becoming a limiting factor for system performance since the growth of chip's I/O bandwidth has been outpaced by the growth of communication. To meet the performance challenge, the per- pin interconnect bandwidth must be further improved with given power budget. For on-chip interconnect, buffer insertion has been adopted to reduce the signal delay. However, the added buffers require extra power consumption and increase routing complexity. In this dissertation, we investigate a set of interconnect performance metrics, optimize the repeated on-chip wires under different design goals and compare the performance metrics of optimum results. The quantitative delay-energy trade-offs for different design goals are demonstrated. Even with repeaters, nominal on-chip global wires still can not keep up with the pace of gate scaling. We propose a high speed signaling scheme using transmission line properties to address the performance issue. The transmission line allows the signal to travel at the speed of light in the medium. The signal toggles as wave instead of enforced electronic charges and thus saves power. However, the inter-symbol interference (ISI) limits the communication bandwidth. We use passive compensation to alleviate the ISI and develop an optimization flow for a given technology and wire dimension. We compare the nominal repeated wires with the transmission lines under different design goals. For off-chip serial links, we propose a set of passive equalization schemes to enhance the performance with low power consumption. We apply the schemes to the CPU-memory links using IBM POWER 6 system as a test vehicle. An optimization flow is devised to optimize the parameters of the equalizers. We derive the performance improvement and power consumption of the proposed schemes. We also demonstrate the sensitivities to the variations of RLC parameters and nois...|$|E
40|$|Memory {{bandwidth}} compression {{can be an}} effective way to achieve higher system performance and energy efficiency in modern data-intensive applications by exploiting redundancy in data. Prior works studied various data compression techniques to improve both capacity (e. g., of caches and main memory) and bandwidth utilization (e. g., of the on-chip and <b>off-chip</b> <b>interconnects).</b> These works addressed two common shortcomings of compression: (i) compression/decompression overhead in terms of latency, energy, and area, and (ii) hardware complexity to support variable data size. In this paper, we make the new observation that there is another important problem related to data compression {{in the context of the}} communication energy efficiency: transferring compressed data leads to a substantial increase in the number of bit toggles (communication channel switchings from 0 to 1 or from 1 to 0). This, in turn, increases the dynamic energy consumed by on-chip and off-chip buses due to more frequent charging and discharging of the wires. Our results, for example, show that the bit toggle count increases by an average of 2. 2 with some compression algorithms across 54 mobile GPU applications. We characterize and demonstrate this new problem across a wide variety of 221 GPU applications and six different compression algorithms. To mitigate the problem, we propose two new toggle-aware compression techniques: Energy Control and Metadata Consolidation. These techniques greatly reduce the bit toggle count impact of the six data compression algorithms we examine, while keeping most of their bandwidth reduction benefits...|$|R
40|$|Abstract—With {{the shift}} to chip multiprocessors, {{managing}} shared resources has become a critical issue in realizing their full potential. Previous {{research has shown that}} thread mapping is a powerful tool for resource management. However, the difficulty of simultaneously managing multiple hardware resources and the varying nature of the workloads have impeded the efficiency of thread mapping algorithms. To overcome the difficulties of simultaneously managing multiple resources with thread mapping, the interaction between various microarchitectural resources and thread characteristics must be well understood. This paper presents an in-depth analysis of PARSEC benchmarks running under different thread mappings to investigate the interaction of various thread mappings with microarchitectural resources including, L 1 I/D-caches, I/D TLBs, L 2 caches, hardware prefetchers, <b>off-chip</b> memory <b>interconnects,</b> branch predictors, memory disambiguation units and the cores. For each resource, the analysis provides guidelines for how to improve its utilization when mapping threads with different characteristics. We also analyze how the relative importance of the resources varies depending on the workloads. Our experiments show that when only memory resources are considered, thread mapping improves an application’s performance by as much as 14 % over the default Linux scheduler. In contrast, when both memory and processor resources are considered the mapping algorithm achieves performance improvements by as much as 28 %. Additionally, we demonstrate that thread mapping should consider L 2 caches, prefetchers and <b>off-chip</b> memory <b>interconnects</b> as one resource, and we present a new metric called L 2 -misses-memory-latency-product (L 2 MP) for evaluating their aggregated performance impact. I...|$|R
40|$|In this thesis, we {{describe}} a new, practical approach to integrating hardware-based data compression within the memory hierarchy, including on-chip caches, main memory, and both on-chip and <b>off-chip</b> <b>interconnects.</b> This new approach is fast, simple, and effective in saving storage space. A key insight in our {{approach is that}} access time (including decompression latency) is critical in modern memory hierarchies. By combining inexpensive hardware support with modest OS support, our holistic approach to compression achieves substantial improvements in performance and energy efficiency across the memory hierarchy. Using this new approach, we make several major contributions in this thesis. First, we propose a new compression algorithm, Base-Delta-Immediate Compression (BDI), that achieves high compression ratio with very low compression/decompression latency. BDI exploits the existing low dynamic range of values present in many cache lines to compress them to smaller sizes using Base+Delta encoding. Second, we observe that the compressed size of a cache block can be indicative of its reuse. We use this observation {{to develop a new}} cache insertion policy for compressed caches, the Size-based Insertion Policy (SIP), which uses the size of a compressed block as one of the metrics to predict its potential future reuse. Third, we propose a new main memory compression framework, Linearly Compressed Pages (LCP), that significantly reduces the complexity and power cost of supporting main memory compression. We demonstrate that any compression algorithm can be adapted to fit the requirements of LCP, and that LCP can be efficiently integrated with the existing cache compression designs, avoiding extra compression/decompression. Comment: PhD Thesi...|$|R
