20|62|Public
50|$|Various {{language}} modules make up {{the core}} of the FREELANG dictionary. Language modules may be accessed through either the <b>on-line</b> <b>interface</b> page or off-line FREELANG dictionary program. While the <b>on-line</b> <b>interface</b> page accommodates all platforms, the off-line dictionary program to access the modules is currently available only for Microsoft Windows. The software is available in English (en), French (fr), Dutch (nl) or Spanish (es).|$|E
50|$|Francis Irving {{currently}} does programming {{work for}} mySociety, most recently WhatDoTheyKnow, {{a site that}} provides an <b>on-line</b> <b>interface</b> to the Freedom of Information Act 2000.|$|E
50|$|In the 1980s, two {{successive}} {{grants from}} the National Endowment for the Humanities (NEH) totaling more than $290,000 funded the professional recataloging of most of MHL's books. At the time, these grants were among the largest Goshen College had ever received. Work accomplished through the grant funding now allows for ready international access to information about MHL holdings through the catalog's <b>on-line</b> <b>interface.</b> In 1991, the MHL received another $57,000 NEH grant to microfilm early North American Mennonite periodicals and, in 1998, was awarded a $373,000 grant from Lilly Foundation Inc. to study Amish and Old Order groups in Indiana.|$|E
40|$|Abstract The Parkes Pulsar Data Archive {{currently}} provides {{access to}} 165, 755 data files obtained from observations carried out at the Parkes Observatory since the year 1991. Data files and access methods are compliant with the Virtual Observatory protocol. This paper provides a tutorial {{on how to make}} use of the Parkes Pulsar Data Archive and provides example queries using <b>on-line</b> <b>interfaces.</b> Key words: pulsars; astronomical databases; miscellaneous...|$|R
50|$|Gy: The <b>on-line</b> {{charging}} <b>interface</b> {{between the}} GGSN and the {{online charging system}} (OCS). Uses the diameter protocol (DCCA application).|$|R
40|$|The Parkes Pulsar Data Archive {{currently}} provides {{access to}} 165, 755 data files obtained from observations carried out at the Parkes Observatory since the year 1991. Data files and access methods are compliant with the Virtual Observatory protocol. This paper provides a tutorial {{on how to make}} use of the Parkes Pulsar Data Archive and provides example queries using <b>on-line</b> <b>interfaces.</b> Comment: Tutorial on the Parkes Pulsar Data Archive presented at the Beijing pulsar conference during 2011. To appear in "Astronomical Research and Technology...|$|R
40|$|This report {{presents}} a recent extension {{to the open}} source traffic simulation “SUMO”, which allows to generate demonstration movies by scripting the user interface from an external application. The scripting was realised by extending an available <b>on-line</b> <b>interface.</b> For obtaining a final movie, further steps are necessary, which are described. Examples for using the extension are given and discussed...|$|E
40|$|The {{results are}} {{discussed}} of the <b>on-line</b> <b>interface</b> of the Torsional Braid Analysis experiment to an Hierarchical Computer System for data acquisition, data reduction {{and control of}} experimental variables. Some experimental results are demonstrated and the data reduction procedures are outlined. Several modes of presentation of the final computer-reduced data are discussed {{in an attempt to}} elucidate possible interrelations between the thermal variation of the rigidity and loss parameters...|$|E
40|$|A single droplet {{generator}} was {{coupled with}} a rotating ball inlet matrix-assisted laser desorption/ionization (MALDI) time of flight (TOF) mass spectrometer. Single droplets with 100 picoliter volume were ejected by a piezoelectric-actuated droplet generator and deposited onto a matrix-coated rotating stainless steel ball at atmospheric pressure. The single droplet deposit was transported to the vacuum side of the instrument where ionization was accomplished using a UV pulsed laser. Using this <b>on-line</b> <b>interface,</b> {{it was possible to}} obtain protonated molecule signal from as little as 10 fmol analyte...|$|E
5000|$|Full <b>on-line</b> help, user <b>interface</b> {{translated}} into 13 languages.|$|R
50|$|Gx: The <b>on-line</b> policy <b>interface</b> {{between the}} GGSN and the {{charging}} rules function (CRF). It {{is used for}} provisioning service data flow based on charging rules. Uses the diameter protocol.|$|R
5000|$|The {{elements}} of an <b>on-line</b> handwriting recognition <b>interface</b> typically include: ...|$|R
40|$|This paper {{focuses on}} {{different}} aspects of collaborative work used to create the electronic version of a dictionary in paper format, edited and printed by the Romanian Academy during the last century. In order to ensure accuracy in {{a reasonable amount of}} time, collaborative proofreading of the scanned material, through an <b>on-line</b> <b>interface</b> has been initiated. The paper details the activities and the heuristics used to maximize accuracy, and to evaluate the work of anonymous contributors with diverse backgrounds. Observing the behaviour of the enterprise for a period of 6 months allows estimating the feasibility of the approach till the end of the project. 1...|$|E
40|$|SA HealthPlus is a {{trial of}} Coordinated Care enrolling 4000 high-use {{patients}} in South Australia in ten groups including diabetes, cardiac, aged care and lung disease. These patients each have a designated General Practitioner (GP) Care Coordinator who formulates an individualised Care Plan designed to keep them as healthy as possible. An <b>on-line</b> <b>interface</b> to SA HealthPlus has been developed for the Care Coordinators. The Care Plan On-Line (CPOL) system provides a single coherent source whereby the GP can review the available information on a HealthPlus patient {{in the context of}} devising a Care Plan of prospective services and medications. In the same application environment CPOL provides access to care guidelines tailored for SA HealthPlus. The guidelines ar...|$|E
30|$|The {{persistence}} of transhumance systems requires continued access to key pastoral resources that together allow the seasonal movement of livestock herds over long distances. In dryland West Africa, these pastoral resources {{are vulnerable to}} competing land uses - particularly agriculture. The mapping of pastoral resources is needed as a necessary but insufficient first step in local to national efforts to manage competing forms of land use in ways that do not threaten transhumance {{as a form of}} land use. In the hopes of spurring analogous efforts elsewhere, a new digital map of the transhumance system in eastern Senegal is described. Not only does it provide detailed information about key transhumance resources (water points, encampments, corridors, pastures), but allows these to be updated, queried and questioned through an <b>on-line</b> <b>interface.</b>|$|E
5000|$|<b>On-line</b> web-based GIS <b>interface</b> to WEPP {{using the}} open source MapServer GIS program ...|$|R
40|$|Brigham Young University, {{which has}} been {{developed}} to teach students modern systems concepts and to address the knowledge required to integrate and trouble-shoot automation devices. Students study topics such as mechanism kinematics, vision system algorithms, I/O control, asynchronous versus synchronous control methods, tooling and sensors, part feeding and orienting, robot calibration, and quality testing. This paper demonstrates how EAAL’s unique open architecture serves both education and research in manufacturing. Laboratory and research experiences are offered both to undergraduate and graduate students using <b>on-line</b> <b>interfaces.</b> Some of the web-based labs can be run off-site, providing a flexible learning and programming environment. Factors affecting the success of web-based labs are discussed...|$|R
40|$|The high {{sensitivity}} {{that can}} be attained using a bienzymatic system and mediated by the redox polymer [Os(bpy) 2 ClPyCH 2 NHpoly(allylamine) ] (Os-PAA), has been verified by <b>on-line</b> <b>interfacing</b> of a rotating bioreactor and continuous-flow/stopped-flow/continuous-flow processing. When the hydrogen peroxide formed by LO x layer reaches the inner layer, the electronic flow between the immobilized peroxidase and the electrode surface produces a current, proportional to lactate concentration. The determination of lactate was possible with a limit of detection of 5 nmol l − 1 in the processing {{of as many as}} 30 samples per hour. This arrangement allows working in undiluted milk samples with a good stability and reproducibility. Horseradish peroxidase [EC 1. 11. 1. 7] and Os-PAA were covalently immobilized on the glassy carbon electrode surface (upper cell body), lactate oxidase [EC 1. 1. 3. x] was immobilized on a disk {{that can be}} rotated. <br /...|$|R
40|$|As in {{many other}} areas of science, systems biology makes {{extensive}} use of statistical association and significance estimates in contingency tables, a type of categorical data analysis known in this field as enrichment (also over-representation or enhancement) analysis. In spite of efforts to create probabilistic annotations, especially in the Gene Ontology context, or to deal with uncertainty in high throughput-based datasets, current enrichment methods largely ignore this probabilistic information since they are mainly based on variants of the Fisher Exact Test. We developed an open-source R package to deal with probabilistic categorical data analysis, ProbCD, that {{does not require a}} static contingency table. The contingency table for the enrichment problem is built using the expectation of a Bernoulli Scheme stochastic process given the categorization probabilities. An <b>on-line</b> <b>interface</b> was created to allow usage by non-programmers and is available at...|$|E
40|$|Lighthouse is an <b>on-line</b> <b>interface</b> for a Web-based {{information}} retrieval system. It accepts queries from a user, collects the retrieved {{documents from the}} search engine, organizes and presents them to the user. The system integrates two known presentations of the retrieved results [...] the ranked list and clustering visualization [...] in a novel and effective way. It accepts the user's input and adjusts the document visualization accordingly. We give {{a brief overview of}} the system. H. 3. 3 Information Search and Retrieval [...] Relevance feedback. H. 3. 5 Online Information Services [...] Web-based services; H. 5. 2 User Interfaces [...] Graphical user interfaces, Screen design; 1. Introduction Locating interesting information on the World Wide Web is the main task of on-line search engines. Such an engine accepts a query from a user and responds with a list of documents or web pages that are considered to be relevant to the query. The pages are ranked by their likelihood of being relevant to the user [...] ...|$|E
40|$|Lighthouse is an <b>on-line</b> <b>interface</b> for a Web-based {{information}} retrieval system. It integrates two known presentations of the retrieved results [...] the ranked list and clustering visualization [...] {{in a novel}} and effective way. We describe a working implementation of the system. It accepts queries from a user, collects the retrieved documents from the search engine, organizes and presents them to the user. It is relatively fast and efficient. We also describe some experiments showing that Lighthouse helps the user to locate relevant information much faster than {{it could be done}} with the ranked list and can significantly improve the retrieval effectiveness of a search engine. 1 Introduction Locating interesting information on the World Wide Web is the main task of on-line search engines. Such an engine accepts a query from a user and responds with a list of documents or web pages that are considered to be relevant to the query. The pages are ranked by their likelihood of being rele [...] ...|$|E
40|$|In {{this paper}} some preliminar results {{obtained}} {{with a new}} conception, non intrusive bed load gauge for laminar sheetflows are presented. The gauge, whose hardware has been derived by a conventional scanner, identifies the crossing of sediments through a control section operating {{on the basis of}} automated visual inspection. An <b>on-line</b> operating <b>interface</b> software allows particles recognition and counting. As an example of application, the problem of the onset of sediment transport is considered...|$|R
40|$|Research {{has shown}} that when people read paper documents, they develop an {{incidental}} memory for the location of information within those documents. However, this kind of spatial memory is undermined in conventional <b>on-line</b> scrolling <b>interfaces.</b> We report on an experiment in which we show that careful design of the interface can reinstate memory for spatial location. As we will show, this has particular implications {{for the design of}} interfaces for small screen displays...|$|R
50|$|Jones was {{inspired}} by the apparent simplicity of Sierra <b>On-Line's</b> adventure game <b>interface,</b> specifically as showcased in Space Quest IV: Roger Wilco and the Time Rippers. The first version of Adventure Creator allowed users to create only low-resolution, keyboard-controlled games.|$|R
40|$|We {{propose to}} develop a high-energy heavy-ion {{experimental}} database and make it accessible to the scientific community through an <b>on-line</b> <b>interface.</b> The database will be searchable and cross-indexed with relevant publications, including published detector descriptions. It should eventually contain all published data from older heavy-ion {{programs such as the}} Bevalac, AGS, SPS and FNAL fixed-target programs, as well as published data from current programs at RHIC and new facilities at GSI (FAIR), KEK/Tsukuba and the LHC collider. This data includes all proton-proton, proton-nucleus to nucleus-nucleus collisions as well as other relevant systems and all measured observables. Such a database would have tremendous scientific payoff as it makes systematic studies easier and allows simpler benchmarking of theoretical models to a broad range of experiments. To enhance the utility of the database, we propose periodic data evaluations and topical reviews. These reviews would provide an alternative and impartial mechanism to resolve discrepancies between published data from rival experiments and between theory and experiment. Since this database will be a community resource, it requires the high-energy nuclear physics community's financial and manpower support...|$|E
40|$|We {{propose to}} develop a high-energy heavy-ion {{experimental}} database and make it accessible to the scientific community through an <b>on-line</b> <b>interface.</b> This database will be searchable and cross-indexed with relevant publications, including published detector descriptions. Since this database will be a community resource, it requires the high-energy nuclear physics community's financial and manpower support. This database should eventually contain all published data from Bevalac and AGS to RHIC to CERN-LHC energies, proton-proton to nucleus-nucleus collisions {{as well as other}} relevant systems, and all measured observables. Such a database would have tremendous scientific payoff as it makes systematic studies easier and allows simpler benchmarking of theoretical models to a broad range of old and new experiments. Furthermore, there is a growing need for compilations of high-energy nuclear data for applications including stockpile stewardship, technology development for inertial confinement fusion and target and source development for upcoming facilities such as the Next Linear Collider. To enhance the utility of this database, we propose periodically performing evaluations of the data and summarizing the results in topical reviews...|$|E
40|$|This {{work-in-progress}} paper introduces an interface for {{the interactive}} visual {{exploration of the}} context of queries using the ArticleFirst database, a product of OCLC. We describe a workflow which allows the user to browse live entities associated with 65 million articles. In the <b>on-line</b> <b>interface,</b> each query leads to a specific network representation of the most prevailing entities: topics (words), authors, journals and Dewey decimal classes linked to the set of terms in the query. This network represents {{the context of a}} query. Each of the network nodes is clickable: by clicking through, a user traverses a large space of articles along dimensions of authors, journals, Dewey classes and words simultaneously. We present different use cases of such an interface. This paper provides a link between the quest for maps of science and on-going debates in HCI about the use of interactive information visualisation to empower users in their search. Comment: CHI' 15 Extended Abstracts, April 18 - 23, 2015, Seoul, Republic of Korea. ACM 978 - 1 - 4503 - 3146 - 3 / 15 / 0...|$|E
40|$|The Planetary Data System (PDS) is {{an active}} science data archive managed by {{scientists}} for NASA's planetary science community. With {{the advent of the}} World Wide Web the majority of the archive has been placed on-line as a science digital library for access by scientists, the educational community, and the general public. The meta-data in this archive, originally collected to ensure that future scientists would be able to understand the context within which the science data was collected and archived, has enabled the development of sophisticated <b>on-line</b> <b>interfaces.</b> The success of this effort is primarily due {{to the development of a}} standards architecture based on a formal model of the planetary science domain. A peer review process for validating the meta-data and the science data has been critical in maintaining a consistent archive. In support of new digital library research initiatives, the PDS functions as a case study in the development and management of meta-data for science digital libraries. In addition the PDS looks forward to participating in digital library research areas, including interoperability and standard protocols. The Planetary Data System (PDS) [11 {{is an active}} science data archive managed by scientists fo...|$|R
40|$|For {{tertiary}} sector providers <b>on-line</b> <b>interfaces</b> provide an efficient means of curriculum delivery 1. Historically mandatory a nursing laboratory induction program had been conducted as a didactic classroom {{session at the}} commencement of semester. This was redesigned as a multimedia on-line learning module and quiz. To evaluate {{the efficacy of the}} new induction program ability to prepare students for safe laboratory practice a mixed method study was undertaken. The sample included second year Bachelor of Nursing Science students (n= 236). A data base audit of quiz results, observation and focus group interviews revealed a correlation between the quiz audit findings and observational data indicating that the electronic induction failed to adequately prepare students for the practice of hand hygiene and management of hazardous waste. The focus group analysis confirmed student difficulty related to these areas. This presentation reports {{the results of this study}} and subsequent initiatives introduced to enhance on-line learning. This includes a second phase of research evaluating the use of virtual environments employing gaming technology to enhance learning of clinical skills. This presentation will be of interest to academics and laboratory staff involved in the application of WH&S policy and within laboratory spaces and interested in teaching clinical skill...|$|R
40|$|Includes bibliographical {{references}} (p. 38 - 39). The goal of {{this thesis}} is to provide teachers with an <b>on-line,</b> web-based <b>interface</b> to create a lesson plan that reflects national and state standards and best practices. This application is a tool to create lesson plans for teachers which {{makes it easier for}} them to employ a backwards design in lesson planning and to make it fit their lesson planning within the framework of American Council on the Teaching of Foreign Languages (ACTFL) standards, and the new California World Language Content Standards for California Public Schools...|$|R
40|$|Abstract Background As in {{many other}} areas of science, systems biology makes {{extensive}} use of statistical association and significance estimates in contingency tables, a type of categorical data analysis known in this field as enrichment (also over-representation or enhancement) analysis. In spite of efforts to create probabilistic annotations, especially in the Gene Ontology context, or to deal with uncertainty in high throughput-based datasets, current enrichment methods largely ignore this probabilistic information since they are mainly based on variants of the Fisher Exact Test. Results We developed an open-source R-based software to deal with probabilistic categorical data analysis, ProbCD, that {{does not require a}} static contingency table. The contingency table for the enrichment problem is built using the expectation of a Bernoulli Scheme stochastic process given the categorization probabilities. An <b>on-line</b> <b>interface</b> was created to allow usage by non-programmers and is available at: [URL]. Conclusion We present an analysis framework and software tools {{to address the issue of}} uncertainty in categorical data analysis. In particular, concerning the enrichment analysis, ProbCD can accommodate: (i) the stochastic nature of the high-throughput experimental techniques and (ii) probabilistic gene annotation. </p...|$|E
40|$|Abstract. Automatic {{benchmarking}} {{can provide}} a reliable first insight into the accessibility status of a web site. The eGovMon project has developed a tool which can assess web sites according to a statistically sound sampling procedure. Additionally, the tool supports detailed evaluation of single web pages. This paper describes the process of data acquisition for the case of large scale accessibility benchmarking of Norwegian public web sites. An important contribution is the elaborated approach to communicate the results to the public web site owners which can help them {{to improve the quality}} of their web sites. An <b>on-line</b> <b>interface</b> enables them to perform evaluations of single web pages and receive immediate feedback. The close collaboration with the municipalities has lead to an overall higher quality both of Norwegian public web sites, the eGovMon tool and the underlying methodology. Automated evaluation alone can not capture the whole picture, and should rather be seen as a complement to manual web accessibility evaluations. The Norwegian Agency for Public Management and eGovernment (DIFI / Norge. no) carries out an annual web quality survey that includes manual assessment of web accessibility. We present a comparison between the Norge. no results and the data collected by the eGovMon tool and verify the statistical correlation. ...|$|E
40|$|A key {{research}} {{question at the}} Large Hadron Collider (LHC) is the test of models of new physics. Testing if a particular parameter set of such a model is excluded by LHC data is a challenge: It requires the time consuming generation of scattering events, the simulation of the detector response, the event reconstruction, cross section calculations and analysis code to test against several hundred signal regions defined by the ATLAS and CMS experiment. In the BSM-AI project we attack this challenge with a new approach. Machine learning tools are thought to predict within {{a fraction of a}} millisecond if a model is excluded or not directly from the model parameters. A first example is SUSY-AI, trained on the phenomenological supersymmetric standard model (pMSSM). About 300, 000 pMSSM model sets - each tested with 200 signal regions by ATLAS - have been used to train and validate SUSY-AI. The code is currently able to reproduce the ATLAS exclusion regions in 19 dimensions with an accuracy of at least 93 percent. It has been validated further within the constrained MSSM and a minimal natural supersymmetric model, again showing high accuracy. SUSY-AI and its future BSM derivatives will help {{to solve the problem of}} recasting LHC results for any model of new physics. SUSY-AI can be downloaded at [URL] An <b>on-line</b> <b>interface</b> to the program for quick testing purposes can be found at [URL]...|$|E
40|$|This paper {{describes}} {{the design of}} a new, versatile, and low-cost <b>on-line</b> LC-GC <b>interface</b> that allows the fast and reliable introduction of large sample volumes onto a capillary GC column. The sample introduction procedure consists successively of: evaporation of the entire sample (LC fraction), selective removal of the solvent and simultaneously cold-trapping of the solutes, splitless transfer of the solutes to the GC column, on-column focusing, GC separation and detection. Quantitative and qualitative aspects of various experimental parameters are evaluated and optimum conditions are reported. The applicability of the method is demonstrated on a synthetic aqueous sample of chlorinated pesticides...|$|R
40|$|Several water {{experiments}} {{have been carried}} out to investigate the physical mechanisms relevant to the rewetting phenomena either at atmospheric conditions or in a steam environment. Yet, {{there seems to be a}} scarcity of experimental data for the low pressure range from 2 to 7 bar with parameters the liquid film flowrate and the subcooling. An experimental facility to simulate two-phase low-pressure water flow phenomena has been designed, constructed and employed to investigate the rewetting process of hot surfaces in a water-steam environment at pressures in the above range, as well as at atmospheric conditions; the facility is <b>on-line</b> <b>interfaced</b> to computers which control its operation and undertake all the data acquisition tasks. Furthermore, a numerical method to experimentally evaluate the wet front position along the rod was introduced. The present paper describes the experimental work aimed at studying the wet front propagation along a stainless steel fuel rod, in a top-flooding environment in the pressure range of 1 - 7 bar, wall temperatures up to 550 degreesC and at a liquid flowrate of 10 (- 3) m(3) min(- 1) at both saturated steam conditions and in atmospheric environment with water subcooling in the range 0 - 75 K. The experimental results fitted well to an existing dimensionless rewetting correlation, together with world available vapour environment rewetting data extending its validity down to the pressure of 1 bar Furthermore, the effect of the inlet water subcooling was introduced in to this correlation...|$|R
40|$|The {{e-learning}} interface design {{should be}} a core, integrated component of the overall design of <b>on-line</b> units. The <b>interface</b> design should be determined by how people learn and the tasks they need to perform. This should be driven by a pedagogical, not technological, approach which identifies learning outcomes (Guralnick, 2008). In this regard, design layout has {{an important role in}} the look and feel of e-learnin...|$|R
