33|29|Public
25|$|The multirole Be-200 can be {{configured}} as an amphibious {{water drop}} fire-fighting aircraft, a freighter, or as a passenger aircraft—the pressurised and air conditioned cabin allowing transportation {{of up to}} 72 passengers. The Be-200 can also be equipped for special missions. When configured as an air ambulance, the aircraft can carry up to 30 stretcher patients and seven seated patients or medical crew. In the search and rescue role, the aircraft can be equipped with searchlights and sensors, an inflatable boat, thermal and <b>optical</b> <b>surveillance</b> systems, and medical equipment. The search and rescue variant can accommodate up to 45 persons. The aircraft is also capable of being configured for anti-submarine warfare duties.|$|E
5000|$|Except the {{satellite}} which failed in launching, a second <b>optical</b> <b>surveillance</b> satellite IGS 3A was launched on 11 September 2006.|$|E
50|$|Optical surveillance: <b>Optical</b> <b>surveillance,</b> {{while not}} a {{keylogger}} {{in the classical}} sense, is nonetheless an approach {{that can be used}} to capture passwords or PINs. A strategically placed camera, such as a hidden surveillance camera at an ATM, can allow a criminal to watch a PIN or password being entered.|$|E
50|$|Moron <b>Optical</b> Space <b>Surveillance</b> (MOSS), a {{transportable}} 22-inch aperture telescope {{that contributed}} to the GEODSS system was operational at Morón Air Base, Spain from 1997 to 2012.|$|R
5000|$|Ground-based Electro <b>Optical</b> Deep Space <b>Surveillance</b> System (February 1990 - 2004) ...|$|R
50|$|The {{mission of}} the 18th SPCS is to provide direct support to USCINCSPACE’s space control mission through <b>optical</b> space <b>surveillance.</b> This {{includes}} detection, tracking, identification, and special signature collection of near space and deep space objects.|$|R
50|$|The {{surveillance}} radar and fire direction radar has {{a range of}} 20 km and the TV-link works up to 15 km. The TV-guidance system uses both regular and infrared cameras. The system can follow 8 targets simultaneously, and the guidance radar can follow both hovering helicopters as well as fighters exceeding speeds over Mach 2. The Crotale can also use surveillance data from other systems, data from <b>optical</b> <b>surveillance</b> and from the general aerial picture from the national air defence communications system.|$|E
50|$|In 1982, the U.S. Army {{accepted}} an initial delivery {{of at least}} six Dragoons from the first production batch. An unknown number (sources differ) from this batch was procured by the United States Navy. The first army vehicles were used by the 9th Infantry Division High Technology Test Bed, in three forms: Personnel Carrier (3?), EW variant with AN/MSQ-103A Teampack system (2), and a video <b>optical</b> <b>surveillance</b> vehicle with a retractable long-range day/night surveillance system mounted in a modified Arrowpointe 25 mm two-man turret, and connected to an on-board data link. This version was intended to provide field commanders and rear line command staff with a highly mobile, armour-protected observation capability.|$|E
50|$|The multirole Be-200 can be {{configured}} as an amphibious {{water drop}} fire-fighting aircraft, a freighter, or as a passenger aircraft—the pressurised and air conditioned cabin allowing transportation {{of up to}} 72 passengers. The Be-200 can also be equipped for special missions. When configured as an air ambulance, the aircraft can carry up to 30 stretcher patients and seven seated patients or medical crew. In the search and rescue role, the aircraft can be equipped with searchlights and sensors, an inflatable boat, thermal and <b>optical</b> <b>surveillance</b> systems, and medical equipment. The search and rescue variant can accommodate up to 45 persons. The aircraft is also capable of being configured for anti-submarine warfare duties.|$|E
5000|$|... 1978 CDB «Sokol» {{designed}} <b>optical</b> {{device for}} <b>surveillance</b> «IRIS». It was successfully tested with MI-24K helicopter.|$|R
40|$|Gauss and Laplace {{methods for}} initial orbit {{determination}} (IOD) are classical orbit determination tools {{and have been}} used very efficiently in <b>optical</b> satellite <b>surveillance</b> system. Several studies related to these two methods have been released until now. In this study, {{we found that the}} trends of IOD accuracy for different time interval between three pairs of measurement datas show unexpected results. Therefore, we checked the possible cause of these differences. In order to check various orbit types, we used most of satellite data which is able to obtain. To check the characteristics of methodology-only, we used simulated observation data. And we used real observation data for specific satellites to check the characteristics appeared when we applyed these methods to <b>optical</b> satellite <b>surveillance</b> system. As a result, we found that trends of IOD accuracy for time interval could be different because of satellite position observed...|$|R
5000|$|Lewis C Roberts Jr, L William Bradford, Mark A Skinner, A Theo, Nils H Turner, Ben R Oppenheimer, Andrew P Digby, Marshall D Perrin. The Effects of Scintillation on Non-Redundant Aperture Masking Interferometry1. The Advanced Maui <b>Optical</b> and Space <b>Surveillance</b> Technologies Conference. 1:98. 2006 ...|$|R
50|$|In 1997, the Royal Commission {{into the}} New South Wales Police Service {{found that the}} use of {{electronic}} surveillance was the single most important factor in achieving a breakthrough in its investigations. Justice Wood concluded that the law lagged well behind technical developments and patterns of crime and recommended a systematic and comprehensive review of legislation and procedures to assist the pursuit of law enforcement. The Surveillance Devices Bill 2007 (NSW) was introduced into the New South Wales Parliament on 6 November 2007. The bill replaced the Listening Devices Act 1984 (NSW) and expanded the application of the legislation so that it also applies to data surveillance devices, <b>optical</b> <b>surveillance</b> devices and tracking devices. The aim of the bill was to implement national model legislation developed by the Joint Working Group of the Standing Committee of Attorneys-General and the Australasian Police Ministers’ Council on National Investigation Powers. The Second Reading Speech states that for serious crimes like murder, terrorism, drug manufacture and importation it is essential that law enforcement agencies have every possible tool at their disposal to make their investigations and prosecutions as successful as possible.The Act was assented to on 23 November 2007. The date of commencement was 1 August 2008.|$|E
5000|$|The Rafale's {{ground attack}} {{capability}} is heavily reliant upon sensory targeting pods, such as Thales Optronics's Reco New Generation/Areos reconnaissance pod and Damocles electro-optical/laser designation pod. Together, these systems provide targeting information, enable tactical reconnaissance missions, and are {{integrated with the}} Rafale's IMA architecture to provide analysed data feeds to friendly units and ground stations, {{as well as to}} the pilot. Damocles provides targeting information to the various armaments carried by the Rafale and is directly integrated with the Rafale's VHF/UHF secure radio to communicate target information with other aircraft. It also performs other key functions such as aerial <b>optical</b> <b>surveillance</b> and is integrated with the navigation system as a FLIR. The Damocles designation pod were described as [...] "lacking competitiveness" [...] when compared to rivals such as the Sniper and LITENING pods; so work began on an upgraded pod, designated Damocles XF, with additional sensors and added ability to transmit live video feeds. A new Thales targeting pod, the Talios, was officially unveiled at the 2014 Farnborough Air Show and is expected to be integrated on the Rafale by 2018. Thales' Areos reconnaissance pod is an all-weather, night-and-day-capable reconnaissance system employed on the Rafale, and provides a significantly improved reconnaissance capability over preceding platforms. Areos has been designed to perform reconnaissance under various mission profiles and condition, using multiple day/night sensors and its own independent communications datalinks.|$|E
40|$|The general aim of {{surveillance}} is {{to obtain a}} description of an observed scene. Conventional systems exploiting ultrasonic, infrared or microwave information do not meet all requirements of modern surveillance systems. The development of intelligent <b>optical</b> <b>surveillance</b> systems is very advantageous as they enable powerful applications which cannot be realized with other sensor systems. The present work discusses new ways which demonstrate the exceptional efficiency of <b>optical</b> <b>surveillance</b> systems...|$|E
40|$|The {{analysis}} {{and understanding of}} video sequences is currently quite an active research field. Many applications such as video <b>surveillance,</b> <b>optical</b> motion capture or those of multimedia need to first {{be able to detect}} the objects moving in a scene filmed by a static camera. This requires the basic operation that consists of separating the moving objects called "foreground"...|$|R
40|$|We {{present a}} Bayesian {{algorithm}} to combine optical imaging of unresolved objects from distinct epochs and observation platforms for orbit determination and tracking. By propagating the non-Gaussian uncertainties {{we are able}} to optimally combine imaging of arbitrary signal-to-noise ratios, allowing the integration of data from low-cost sensors. Our Bayesian approach to image characterization also allows large compression of imaging data without loss of statistical information. With a computationally efficient algorithm to combine multiple observation epochs and multiple telescopes, we show statistically optimal orbit inferences. Comment: 8 pages, 6 figures, contribution to Advanced Maui <b>Optical</b> and Space <b>Surveillance</b> Technologies Conference 201...|$|R
50|$|Airborne ground {{surveillance}} (AGS) {{refers to}} a class of military airborne radar system (Surveillance aircraft) used for detecting and tracking ground targets, such as vehicles and slow moving helicopters, as opposed to Airborne early warning and control, whose primary role is detecting and tracking aircraft in flight. Antenna beam width should be very small to enhance resolution. This antenna size limitation demands high frequency (GHz range) of operation, to be operated in this mode. AGS radar is typically a medium or low power radar. It includes both maritime and land surveillance. Today, UAVs perform this operation, which often uses <b>optical</b> aids for <b>surveillance.</b>|$|R
40|$|An {{infusion}} {{technology is}} {{presented in this paper}} that enables an almost fully automated and controllable infusion process with as little technical effort as possible. This technology is supplemented with an <b>optical</b> <b>surveillance</b> and documentation of the injection procedure in the processing tool. ...|$|E
40|$|Like {{satellites}} before them, drones {{have moved}} beyond their military uses to reshape our vertical publics, raising fears about catastrophic aerial accidents and heightening public concerns about <b>optical</b> <b>surveillance</b> and personal or commercial privacy invasion. There is an increasingly urgent debate amongst state aviation authority review committees, industry organisations, law reform bodies, privacy activists and individual enthusiasts or entrepreneurs seeking {{to adapt and}} put drone technology to use, with equal measures of enthusiasm, uncertainty and anxiety following...|$|E
40|$|A {{fuel cell}} has been {{designed}} that combines three methods of spatially resolved measurements. The experimental setup allows to perform a simultaneous evaluation of current, temperature and water distribution in a polymer electrolyte fuel cell (PEFC) under operation. The test cell has a segmented anode flow field for current distribution measurement. The back plate of the cathode flow field is made of an optical window, which is transparent for infrared (IR) {{as well as for}} visible wavelengths. This allows infrared thermography and <b>optical</b> <b>surveillance</b> of water droplets and flow field flooding...|$|E
40|$|Optical {{observation}} through sub-meter telescope {{equipped with}} CCD camera becomes alternative method for increasing orbital debris detection and surveillance. This observational mode {{is expected to}} eye medium-sized objects in higher orbits (e. g. MEO, GTO, GSO & GEO), {{beyond the reach of}} usual radar system. However, such observation of fast-moving objects demands special treatment and analysis technique. In this study, we performed photometric analysis of the satellite track images photographed using rehabilitated Schmidt Bima Sakti telescope in Bosscha Observatory. The Hough transformation was implemented to automatically detect linear streak from the images. From this analysis and comparison to USSPACECOM catalog, two satellites were identified and associated with inactive Thuraya- 3 satellite and Satcom- 3 debris which are located at geostationary orbit. Further aperture photometry analysis revealed the periodicity of tumbling Satcom- 3 debris. In the near future, it is not impossible to apply similar scheme to establish an analysis pipeline for <b>optical</b> space <b>surveillance</b> system hosted in Indonesia. Comment: 4 pages, 7 figures, presented in the International Conferences on Mathematics and Natural Sciences 201...|$|R
40|$|We have {{developed}} a maximum likelihood source detection method capable of detecting ultra-faint streaks with surface brightnesses approximately {{an order of magnitude}} fainter than the pixel level noise. Our maximum likelihood detection method is a model based approach that requires no a priori knowledge about the streak location, orientation, length, or surface brightness. This method enables discovery of typically undiscovered objects, and enables the utilization of low-cost sensors (i. e., higher-noise data). The method also easily facilitates multi-epoch co-addition. We will present the results from the application of this method to simulations, as well as real low earth orbit observations. Comment: 11 pages, 7 figures, contribution to the Advanced Maui <b>Optical</b> and Space <b>Surveillance</b> Technologies Conference 201...|$|R
40|$|A {{comprehensive}} high-fidelity simulation {{environment of}} networked <b>optical</b> space <b>surveillance</b> sensors {{has been created}} under an effort called TASMAN (Tasking Autonomous Sensors in a Multiple Application Network). One of the first studies utilizing this environment was focused on a novel resource management approach, namely covariance-based tasking. Under this scheme, the state error covariance of resident space objects (RSO), sensor characteristics, and sensor-target geometry {{were used to determine}} the effectiveness of future observations in reducing the uncertainty in orbit estimates. The different observation effectiveness metrics evaluated in this study predicted the amount of error reduction in the position, velocity, or semimajor axis estimate for the RSO. These observation effectiveness metrics were used to schedule the most effective times for the sensors to observe the RSOs in different sensor tasking scenarios. The tasking scenarios included fully distributed sensor schedulers, a fully centralized network scheduler, and a baseline case that did not use observation effectiveness in order to roughly mirror the current Space Surveillance Network tasking. The different tasking and scheduling techniques were compared by evaluating their impact on the accuracy of the orbit estimates in the RSO catalog. The observation effectiveness metrics measuring reduction in position or velocity error all substantially reduced the errors in the catalog estimates when compared to the baseline tasking scenario and would enable a more efficient use of the sensor network for catalog maintenance. 1...|$|R
40|$|In {{addition}} to the issues that have always existed, demands are being placed on space systems for increased contamination prevention/control. <b>Optical</b> <b>surveillance</b> sensors are required to detect low radiance targets. This increases the need for very low scatter surfaces in the optical system. Particulate contamination levels typically experienced in today's working environments/habits will most likely compromise these sensors. Contamination (molecular and particulate) can also affect the survivability of space sensors in both the natural and hostile space environments. The effects of di-octyl phthalate (DOP) on sensors are discussed...|$|E
40|$|Complex signal-processing {{problems}} are naturally described by compositions of program modules that process streams of data. In {{this article we}} discuss how such compositions may be analyzed and mapped onto multiprocessor computers to effectively exploit the massive parallelism of these applications. The methods are illustrated with an example of signal processing for an <b>optical</b> <b>surveillance</b> problem. Program transformation and analysis are used to construct a program description tree that represents the given computation as an acyclic interconnection of stream-processing modules. Each module may be mapped {{to a set of}} threads run on a group of processing elements of a target multiprocessor. Performance is considered for two forms of multiprocessor architecture, one based on conventional DSP technology and the other on a multithreaded-processing element design...|$|E
40|$|THE STORAGE AND TRANSMISSION OF DIGITAL IMAGES ARE REQUIRED IN MANY APPLICATIONS LIKE <b>OPTICAL</b> <b>SURVEILLANCE,</b> REMOTE SENSING OR EXPERIMENT AUTOMATION. IN SOME APPLICATIONS NO INFORMATION ON PIXEL LEVEL HAS TO BE LOST DURING COMPRESSION AND DECOMPRESSION, EVEN IF THE COMPRESSION FACTOR WILL BE LIMITED BY THIS CONDITION. ONE OF THESE COMPRESSION METHODS IS THE HUFFMAN CODE WITH THE BASIC IDEA THAT NOT ALL QUANTIZATION LEVELS IN AN IMAGE OCCUR EQUALLY OFTEN. HUFFMAN CODE IS A VARIABLE LENGTH CODE IN WHICH SHORTER CODES ARE ASSIGNED TO THE MOST FREQUENTLY OCCURRING LEVELS. THE RESULTING COMPRESSION DEPENDS ON THE TYPE OF INPUT IMAGE. DIFFERENT CORRELATION CASES (NORMAL, LINEAR AND CROSS-DIFFERENCE) HAVE BEEN INVESTIGATED. GOOD RESULTS ARE OBTAINED USING THE LINEAR DIFFERENCE VERSION OF HUFFMAN CODE. NA-NOT AVAILABL...|$|E
40|$|Autonomous video {{surveillance}} systems typically consist of several functional modules working in concert. These modules perform specialized tasks including motion detection, {{separation of the}} foreground and background, depth estimation, object tracking, feature estimation, and behavioral analysis. Computational overhead and redundancy may result from designing each module individually, as each module may incorporate different variety of techniques and algorithms. This paper presents {{the design of a}} surveillance system that uses an optical flow algorithm throughout. We consider the capabilities, solutions, and limitations of this design. Additionally, an evaluation of the performance of optical flow in specific situations, such as depth estimation, rigid and non-rigid classification, segmentation, and tracking, is provided. The main contribution of this work is a new system-level architecture based on a single key algorithm (optical flow) for the entire {{video surveillance}} system. KEY WORDS <b>Optical</b> flow, video <b>surveillance,</b> segmentation, tracking, depth estimation, feature extraction 1...|$|R
40|$|In {{order to}} {{maximize}} sensitivity, <b>optical</b> space <b>surveillance</b> sensors use detectors that have good sensitivity {{over a wide}} region of the spectrum. For example, the CCD detectors for the Lincoln Near-Earth Asteroid Research (LINEAR) Project, which are nearly identical to the detectors of the Ground-based Electro-Optical Deep Space Surveillance System, have good sensitivity over the visible spectrum from 380 nanometers to beyond 1000 nanometers. However, photometric calibration of the intensities of objects (stars, satellites, asteroids, etc.) measured by these systems must be referenced to astronomical star catalogs that were measured over much narrower portions of the available spectrum. For example, the Sloan Digital Sky Survey (SDSS) Photometric Database contains photometric measurements in five bandpasses that are each about 150 nanometers wide. This paper will present a method for converting between photometric systems with different bandpasses. The method uses the measured response functions of the detectors of interest along with {{a model of the}} spectral transmissivity of the atmosphere (Stone, 1996), and a catalog of stellar spectra (Pickles, 1998) to derive polynomial functions that allow for the conversion of brightness measurements from astronomical catalogs to the bandpass of the sensor. The method has been extensively tested using data from the Lincoln Near-Earth Asteroid Research project in comparison with catalog measurements from the USNO B 1. 0 astrometric catalog, and the SDSS Photometric Database. Through OPAL (Optical Processing Architecture at Lincoln), this technique is being applied to ground-based and space-base...|$|R
40|$|This Special Edited Volume is {{a unique}} {{approach}} towards Computational solution for the upcoming field of study called Vision Science. From a scientific firmament Optics, Ophthalmology, and Optical Science has surpassed an Odyssey of optimizing configurations of <b>Optical</b> systems, <b>Surveillance</b> Cameras and other Nano optical devices with the metaphor of Nano Science and Technology. Still these systems are falling short of its computational aspect to achieve the pinnacle of human vision system. In this edited volume much {{attention has been given}} to address the coupling issues Computational Science and Vision Studies.   It is a comprehensive collection of research works addressing various related areas of Vision Science like Visual Perception and Visual system, Cognitive Psychology, Neuroscience, Psychophysics and Ophthalmology, linguistic relativity, color vision etc. This issue carries some latest developments in the form of research articles and presentations. The volume is rich of contents with technical tools for convenient experimentation in Vision Science. There are 18 research papers having significance in an array of application areas. The volume claims to be an effective compendium of computing developments like Frequent Pattern Mining, Genetic Algorithm, Gabor Filter, Support Vector Machine, Region Based Mask Filter, 4 D stereo camera systems, Principal Component Analysis etc. The detailed analysis of the papers can immensely benefit to the researchers of this domain. It can be an Endeavour in the pursuit of adding value in the existing stock of knowledge in Vision Science...|$|R
40|$|The paper {{presents}} the results of a detailed design, evaluation and trade-off of a potential European Space Surveillance and Tracking (SST) system architecture. The results have been produced in study phase 1 of the on-going "CO-II SSA Architectural Design" project performed by the Astrium consortium as part of ESA’s Space Situational Awareness Programme and are the baseline for further detailing and consolidation in study phase 2. The sensor network is comprised of both ground- and space-based assets and aims at being fully compliant with the ESA SST System Requirements. The proposed ground sensors include a surveillance radar, an <b>optical</b> <b>surveillance</b> system and a tracking network (radar and optical). A space-based telescope system provides significant performance and robustness for the surveillance and tracking of beyond-LEO target objects...|$|E
40|$|We {{describe}} three advanced techniques {{incorporated into}} {{the design of a}} model-based image analysis system which automatically estimates the orientation vector of satellites and their sub-components. The system, implemented in Khoros, operates on images obtained from a ground-based <b>optical</b> <b>surveillance</b> system. Features of each satellite image are first extracted by partitioning the image and constructing a model representation. Second, pose estimates are obtained from model-matching across a model database. Finally, pose refinements are derived from photogrammetric or geometric information. We discuss three advanced techniques: eigen-indexing, robust affine point matching, and random edge sampling. Eigen-indexing is a novel indexing method which constrains the number of model candidates and significantly improves the overall system speed by providing an efficient way to access the model database. We include a theoretical analysis of the eigen-indexing technique. Robust affine point matc [...] ...|$|E
40|$|The {{objectives}} {{of this study}} are to analyze the satellite visibility at the randomly established ground sites, to determine the five optimal ground sites to perform the <b>optical</b> <b>surveillance</b> and tracking of domestic satellites, and to verify the acquisition of the optical observation time sufficient to maintain the precise ephemeris at optimal ground sites that have been already determined. In order to accomplish these objectives, we analyzed the visibility for sun-synchronous orbit satellites, low earth orbit satellites, middle earth orbit satellites and domestic satellites as well as the continuous visibility along with the fictitious satellite ground track, and calculate the effective visibility. For the analysis, we carried out a series of repetitive process using the satellite tool kit simulation software developed by Analytical Graphics Incorporated. The lighting states of the penumbra and direct sun were set as the key constraints of the optical observation. The minimum of the observation satellite elevation angle was set to be 20 degree, whereas the maximum of the sun elevation angle was set to be - 10 degree which is within the range of the nautical twilight. To select the candidates for the optimal optical observation, the entire globe was divided into 84 sectors in a constant interval, the visibility characteristics of the individual sectors were analyzed, and 17 ground sites were arbitrarily selected and analyzed further. Finally, five optimal ground sites (Khurel Togoot Observatory, Assy-Turgen Observatory, Tubitak National Observatory, Bisdee Tier Optical Astronomy Observatory, and South Africa Astronomical Observatory) were determined. The total observation period was decided as one year. To examine the seasonal variation, the simulation was performed for the period of three days or less with respect to spring, summer, fall and winter. In conclusion, we decided the optimal ground sites to perform the <b>optical</b> <b>surveillance</b> and tracking of domestic satellites and verified that optical observation time sufficient to maintain the precise ephemeris could be acquired at the determined observatories...|$|E
40|$|This paper {{presents}} {{methods for}} human detection for application {{in the field}} of national security in the context of state border surveillance. Except in the context of state border security, the presented methods can be applied to monitor other protected object and infrastructure such as ports and airports, power plants, water supply systems, oil pipelines, etc. Presented methods are based on use of thermal imaging systems for the human detection, recognition and identification. In addition to methods for the detection of persons, are presented and methods for face recognition and identification of the person. The use of such systems has special significance in the context of national security in the domain of timely detection of illegal crossing of state border or illegal movement near buildings, which are of special importance for national security such as traffic infrastructure facilities, power plants, military bases, especially in mountain or forests areas. In this context, thermal imaging has significant advantages over the <b>optical</b> camera <b>surveillance</b> systems because thermal imaging is robust to weather conditions and due to such an infrared thermal system can successfully applied in any weather conditions, or the periods of the day. Featured are procedures that has human detection results as well as a brief survey of specific implementation in terms of the use of infrared thermal imagers mounted on autonomous vehicles (AV) and unmanned aerial vehicles (UAV). In addition to the above in this paper are described techniques and methods of face detection and human identification based on thermal image (thermogram) ...|$|R
40|$|Abstract — Separation {{of video}} clips into {{foreground}} and background components {{is a useful}} and important technique, making recognition, classification, and scene analysis more efficient. In this paper, we propose a motion-assisted matrix restoration (MAMR) model for foreground–background separation in video clips. In the proposed MAMR model, the backgrounds across frames are modeled by a low-rank matrix, while the foreground objects are modeled by a sparse matrix. To facilitate efficient foreground–background separation, a dense motion field is estimated for each frame, and mapped into a weighting matrix which indicates the likelihood that each pixel belongs to the background. Anchor frames are selected in the dense motion estimation to overcome the difficulty of detecting slowly moving objects and camouflages. In addition, we extend our model to a robust MAMR model against noise for practical applications. Evaluations on challenging datasets demonstrate that our method outperforms many other state-of-the-art methods, and is versatile {{for a wide range}} of surveillance videos. Index Terms — Background segmentation/subtraction, matrix restoration, motion detection, <b>optical</b> flow, video <b>surveillance...</b>|$|R
40|$|Photo-thermo-refractive (PTR) {{glass is}} a new {{photosensitive}} material for phase hologram recording. This sodium-zinc-aluminum-silicate glass doped with silver, cerium and fluorine exhibits a refractive index modulation after exposure to UV radiation followed by a thermal treatment. Holographic volume gratings recorded in this glass show an absolute diffraction efficiency exceeding 97 %, a thermal stability up to 400 °C, and a high tolerance to laser radiation. These features support its application for laser beam control in <b>optical</b> communications and <b>surveillance</b> in space-born systems. A specific aspect of the space environment {{is the presence of}} ionizing radiation, which is known to influence the properties of optical materials. We studied the induced absorption in PTR glass after exposure to gamma radiation with doses exceeding 10 Mrad. The larger part of the induced absorption is found in the visible and UV spectral regions while in the infrared the absorption level remains sufficiently low to allow a long-term use of this material in space. In this paper, we discuss the structure of the induced absorption spectra in PTR glass and glass matrix which does not contain photosensitive agents...|$|R
