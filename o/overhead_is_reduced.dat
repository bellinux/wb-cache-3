129|10000|Public
25|$|Process {{creation}} <b>overhead</b> <b>is</b> <b>reduced</b> by {{significant improvements}} to DLL address-resolving schemes.|$|E
50|$|Overall system {{complexity}} and administration <b>overhead</b> <b>is</b> <b>reduced.</b>|$|E
5000|$|Process {{creation}} <b>overhead</b> <b>is</b> <b>reduced</b> by {{significant improvements}} to DLL address-resolving schemes.|$|E
40|$|The {{popularity}} of the Internet and the web is making real-time communication achieve a new significance. Time-critical applications such as Internet phone, video teleconferencing, and streaming audio /video are becoming increasingly common. Network bandwidth delivered to these applications is limited by host protocol processing overheads, especially the receive-side overhead (since it usually exceeds transmission overhead). We present an architecture for reducing receive-side overhead for processing realtime messages. In our scheme, all protocol processing is performed by the application threads themselves. Moreover, message data needs to be copied only once (without any hardware support from the network adapter or any restrictions on the network API). We implement UDP/IP to evaluate our architecture. Measurements show that non-data-touching <b>overheads</b> <b>are</b> <b>reduced</b> 13 % which benefits short messages such as live audio. Data-touching <b>overheads</b> <b>are</b> <b>reduced</b> 20 [...] 30 % which benefits long messag [...] ...|$|R
40|$|We {{describe}} how {{the problem of}} effectively servicing a number of users by a multimedia server can be represented as a periodic disk scheduling problem. We give an overview of related work and present {{a number of new}} results, based on periodically servicing users that have different consumption requirements with different periods. In addition, by scheduling sets of disk accesses as batches the worst-case switching <b>overhead</b> <b>is</b> <b>reduce...</b>|$|R
50|$|The <b>overhead</b> can <b>be</b> <b>reduced</b> {{further by}} {{doubling}} the block size to produce 128b/130b encoding, as used by PCIe 3.0, {{and a very}} similar variant is the 128b/132b encoding used by USB 3.1.|$|R
5000|$|Finer-grained {{control of}} workloads that are {{migrated}} between cores. Because the scheduler is directly migrating tasks between cores, kernel <b>overhead</b> <b>is</b> <b>reduced</b> and power savings can be correspondingly increased.|$|E
50|$|The {{purpose of}} the grid based levels is twofold - ray to wall {{collisions}} can be found more quickly since the potential hits become more predictable and memory <b>overhead</b> <b>is</b> <b>reduced.</b> However, encoding wide-open areas takes extra space.|$|E
5000|$|Shared storage {{resources}} must typically {{be accessed}} over a {{storage area network}} or on a network attached storage server, which creates some overhead in read I/O. In DRBD that <b>overhead</b> <b>is</b> <b>reduced</b> as all read operations are carried out locally.|$|E
30|$|The {{performance}} of our MAC design is checked with simulation studies {{in a typical}} six-antenna AP and clients scenario. We observe that our MAC protocol has a slightly higher signaling overhead than traditional ready to send/clear to send (RTS/CTS) due to design constraints; however, the signaling time <b>overheads</b> <b>are</b> <b>reduced</b> by 98.67 μs compared to IEEE 802.11 ac. Another interesting aspect to highlight is the constant Throughput gain of {{four to five times}} that of the traditional RTS/CTS. Our MAC protocol obtains this gain as early as 98.67 μs compared to IEEE 802.11 ac.|$|R
30|$|The {{way that}} the {{high-quality}} images are processed {{by all of the}} algorithms that are present in the proposed ISP chain means that there are no iterations in the algorithm to reduce the execution time of the real-time budget [1]. While the basic idea of the algorithm is maintained, the operations in the algorithm have been simplified for easy parallelization on the SIMD architecture; in addition, heavy memory accesses and excessive computational <b>overheads</b> <b>are</b> <b>reduced</b> by limiting the operational ranges. Each complicated special operation is replaced by a simple operation that performs a similar function and the result was verified by experiments.|$|R
40|$|A {{trace of}} a workload’s system calls can be {{obtained}} with minimal interference, {{and can be used}} to drive repeatable experiments to evaluate system configuration alternatives. Replaying system call traces alone sometimes leads to inaccurate predictions because paging, and access to memorymapped files, are not modelled. This paper extends tracing to handle such workloads. At trace capture time, the application’s page-level virtual memory access is monitored. The size of the page access trace, and capture <b>overheads,</b> <b>are</b> <b>reduced</b> by excluding recently-accessed pages. This leads to a slight loss of accuracy. Using a suite of memory-intensive applications, we evaluate the capture overhead and measure the predictive accuracy of the approach. ...|$|R
50|$|In {{the case}} of MNP the {{overhead}} of the packet system was relatively small, but even the multi-byte CRC was taking up space better used for data. Generally using a larger packet would address this, because the CRC remains the same fixed size and thus its relative <b>overhead</b> <b>is</b> <b>reduced</b> compared {{to the amount of}} data. However, when an error does occur, using larger packets also means that more data has to be re-sent. On noisy lines, this can slow overall throughput.|$|E
50|$|A route server is {{a server}} that was {{originally}} {{made with the}} intention {{to be a part}} of the National Science Foundation funded Routing Arbiter project. This routing process directs information among Border Gateway Protocol (BGP) routers. These servers are placed at Network Access Points (NAP) in which the centralized computers that organize and match routing at the NAPs. This type of server is very important because without it managing BGP sessions would be an impossible procedure. This can be seen where overhead and management difficulties of maintaining BGP sessions through which routers with single or multiple domains that are connected could cause problems (aka full mesh routing connectivity). By introducing the route server the <b>overhead</b> <b>is</b> <b>reduced</b> and at the same time alleviates some of the problem therefore making it much easier to manage. The route server simply gives the ability to look at an IP routing table of an autonomous system where the server is located.|$|E
5000|$|In contrast, most {{microkernel}} {{systems are}} based on a model of asynchronous communications, as opposed to synchronous procedure calls. The canonical microkernel system, Mach, modeled messages as I/O, which has several important side-effects. Primary among these is that the normal task schedulers under Unix-like systems will normally block a client that is waiting on an I/O request, so in this way the actions of pausing and restarting applications waiting on messages was already built into the underlying system. The downside to this approach is that the scheduler is fairly [...] "heavyweight", and calling it was a serious performance bottleneck and led to extensive development efforts to improve its performance. Under the V-System model the message passing <b>overhead</b> <b>is</b> <b>reduced</b> because the process scheduler {{does not have to be}} consulted, there is no question as to who should next be run [...] - [...] it's the server being called. The downside to the V approach is that it requires more work on the server side if the response may take some time to process.|$|E
5000|$|... ionCube {{was founded}} in 2002, and {{introduced}} tools to protect software written using the PHP programming language from being viewed, changed, and run on unlicensed computers. The encoding technology grew out of earlier work on the PHP Accelerator project, and at first launch included an online encoding service where PHP scripts can be uploaded and an encoded version downloaded in return, and a command line tool for Linux soon after. The tools use the technique of compiling to bytecode prior to encoding so that source code is eliminated, and runtime <b>overheads</b> <b>are</b> <b>reduced.</b> A PHP extension called the ionCube Loader handles the reading and execution of encoded files at run time.|$|R
30|$|Regarding the {{efficiency}} of the protocol, we have defined that the protocol must ensure the advantages of a delegation of signaling rights approach. That <b>is,</b> the signaling <b>overhead</b> should <b>be</b> <b>reduced,</b> the signaling path should be optimized and the manageability of the solution should be increased.|$|R
30|$|According to Carrano et al. [10], {{unless the}} path {{discovery}} <b>overhead</b> <b>is</b> drastically <b>reduced</b> {{by increasing the}} efficiency of flooding mechanisms, the new standard may present a suitable behavior only for small-scale scenarios. Moreover, scalability {{is one of the}} major deciding factors for any network to be accepted and industrially deployed [13].|$|R
30|$|As {{discussed}} above, in {{the proposed}} system, the communication <b>overhead</b> <b>is</b> <b>reduced</b> since CH by itself directly estimates the metrics for processing and decision-making (CH {{does not depend on}} its member for collecting the JIM), the communication <b>overhead</b> <b>is</b> <b>reduced.</b>|$|E
3000|$|..., {{coupling}} of the UL and DL beamforming halves {{the required}} DL pilot overhead. At the same time, the UL pilot <b>overhead</b> <b>is</b> <b>reduced</b> approximately by one third.|$|E
40|$|A gearbox-type {{capacitive}} DC/DC converter {{is presented}} with an enhanced switch- and capacitor-array. The switch <b>overhead</b> <b>is</b> <b>reduced</b> significantly {{with respect to}} a conventional implementation. The presented topologies exhibit a lower swing on the intermediate capacitor nodes so that power loss due to the parasitic capacitances on these nodes is reduced drastically. status: publishe...|$|E
30|$|Figure 3 (a) {{depicts the}} {{measured}} effective data rate, which increases with MSDU size {{for the same}} number of transmitters. This is because the effect of <b>overhead</b> <b>was</b> <b>reduced,</b> leading to a raise of data efficiency. We can also find that for a given MSDU size, when the number of transmitters increases, the effective data rate first increases and then decreases. This effect can be explained as follows. As the number of transmitters increases, more packets are sent in the same times, which cause the first increase of effective data rate. But too many packets will lead to packet collision and some conflicting packets are dropped. This is why the effective data rate decreases later.|$|R
40|$|We {{investigate}} distributed cooperative antenna (COOPA) {{systems with}} limited feedback. A feedback link {{is required to}} provide chan-nel state information, {{and in many cases}} {{it is based on the}} codebook which consists of maximally spaced codes. The feedback <b>overhead</b> can <b>be</b> <b>reduced</b> by organizing the codebook structure in a smart way to exploit the temporal correlation of the channel. We have proposed the combined feedback scheme in our previous work. In this paper we suggest a method which works as a useful guideline to determine the best feedback periods. We also propose a recursive codebook design which has a subspace tracking capability. The simulation results show that the tracking capability of the feedback allows the feedback <b>overhead</b> to <b>be</b> <b>reduced</b> by more than 30 % compared with the combined codebook. 1...|$|R
40|$|Dynamic binary {{translation}} (DBT) {{can provide}} security, virtualization, resource management and other desirable services to embedded systems. Although DBT has many benefits, its run-time performance <b>overhead</b> can <b>be</b> relatively high. The run-time <b>overhead</b> <b>is</b> important in embedded systems {{due to their}} slow processor clock speeds, simple microarchitectures, and small caches. This paper addresses how to implement efficient DBT for ARM-based embedded systems, taking into account instruction set and cache/TLB nuances. We develop several techniques that reduce DBT overhead for the ARM. Our techniques focus on cache and TLB behavior. We tested the techniques on an ARM-based embedded device and found that DBT <b>overhead</b> <b>was</b> <b>reduced</b> by 54 % in comparison to a general-purpose DBT configuration that is known to perform well, thus further enabling DBT {{for a wide range}} of purposes. Categories and Subject Descriptors C. 3 [Computer Systems Organization]: Special-purpose and application- based systems–Realtime and embedded systems; D. 3. 4 [Programming Languages]: Processors–Code generation, Compilers, Incremental compilers...|$|R
40|$|The {{problem of}} the {{hypersonic}} double ellipse in rarefied flow is treated by a particle method using the collision model first described by McDonald (1988). In the approach used here, the computational <b>overhead</b> <b>is</b> <b>reduced</b> by using simple cubic cells. The {{problem of the}} definition of complex geometries is addressed by developing an algorithm to define the relation of a body surface to the network of cells...|$|E
30|$|Note {{that the}} shared-antenna array massive MIMO system {{has a single}} array, so the {{transmit}} and receive CSI are the same during the coherent time. We only need to estimate the uplink channel, and thus the estimation <b>overhead</b> <b>is</b> <b>reduced</b> by half. This {{is different from the}} separate-antenna arrays system, where the CSI of the receive and transmit arrays are different, the uplink and downlink CSI have to be estimated separately.|$|E
40|$|Abstract. The {{compensation}} of scale factor imposes significant computation overhead on the CORDIC algorithm. In this paper we present two algorithms {{and the corresponding}} architectures (one for both rotation and vectoring modes and the other only for rotation mode) to perform the scaling factor compensation in parallel with the classical CORDIC iterations. With these methods, the scale factor compensation <b>overhead</b> <b>is</b> <b>reduced</b> {{to a couple of}} iterations for any word length. The architectures presented have been optimized for conventional and redundant arithmetic. 1...|$|E
3000|$|... [...]. This <b>overhead</b> can <b>be</b> further <b>reduced</b> in {{practice}} (especially for cases similar to our wideband sensing experimentation where {{the total number}} of examined frequency bins, [...]...|$|R
5000|$|DOACROSS {{parallelism}} {{suffers from}} significant space and granularity overheads {{due to the}} synchronization primitives used. Modern day compilers often overlook this method because of this major disadvantage. [...] The <b>overheads</b> may <b>be</b> <b>reduced</b> by reducing the frequency of synchronization across the loop, by applying the primitives for groups of statements at a time.|$|R
50|$|Like all the Eastern Region AC EMUs of the period, {{they were}} {{equipped}} {{to operate on}} both 25 kV AC and the reduced 6.25 kV voltage in the inner London areas where headroom for the <b>overhead</b> wires <b>was</b> <b>reduced.</b> On the LT&S the changeover point was just east of Barking station on both Upminster and Tilbury routes.|$|R
3000|$|..., {{as defined}} in (5) and (7), respectively, is carried out in a {{straightforward}} manner for any possible muting decision α̅. However, in practical conditions such as in LTE-Advanced networks, the CSI is typically available in form of achievable data rate measurement reports, i.e., CSI reports, which contain average information of multiple time/frequency/space resources for a subset of possible muting decisions α̅, {{as defined in}} (4). Thus, the processing and signaling <b>overhead</b> <b>is</b> <b>reduced,</b> {{at the expense of}} limited CSI knowledge for the CoMP CS scheme.|$|E
40|$|Abstract. This paper {{proposes a}} new, {{efficient}} {{method of building}} a scalable generic application {{which can be used}} to provide various types of information services using mobile messaging. For specific information, mobile users send an SMS (Short Message Service) to the mobile gateway in a proper format which is then forwarded to the generic application. The generic application accordingly creates an automatic query and gen-erates a prompt reply. With this new architecture, the final query generating algorithm be-comes fast, efficient and processing <b>overhead</b> <b>is</b> <b>reduced.</b> Consequently, user gets the information promptly without any long delay...|$|E
40|$|In this article, {{we present}} CodeCast, a network coding based ad hoc {{multicast}} protocol. CodeCast well-suited especially for multimedia applications with low loss, low latency constraints such as audio/video streaming. The key ingredient of CodeCast is random network coding which transparently implements both localized loss recovery and path diversity with very low overhead. Simulation {{results show that}} in a typical setting, CodeCast yields near 100 % delivery ratio as compared to 94 % delivery ratio by traditional multicast. More importantly, the <b>overhead</b> <b>is</b> <b>reduced</b> {{by as much as}} 50 %...|$|E
40|$|Mining for {{association}} rules between {{items in}} a large database of sales transactions {{has been described as}} an important database mining problem. In this paper we present an efficient algorithm for mining association rules that is fundamentally different from known algorithms. Compared to the previous algorithms, our algorithm reduces both CPU and I/O overheads. In our experimental study it was found that for large databases, the CPU <b>overhead</b> <b>was</b> <b>reduced</b> by as much as a factor of seven and I/O <b>was</b> <b>reduced</b> by almost an order of magnitude. Hence this algorithm is especially suitable for very large size databases. The algorithm is also ideally suited for parallelization. We have performed extensive experiments and compared the performance of the algorithm with one of the best existing algorithms. 1 Introduction Increasingly, business organizations are depending on sophisticated decision-making information to maintain their competitiveness in today's demanding and fast changing marketplace [...] ...|$|R
40|$|High-performance Web servers are {{essential}} to meet the growing demands of the Internet and large-scale intranets. Satisfying these demands requires {{a thorough understanding of}} key factors affecting Web server performance. This paper presents empirical analysis illustrating how dynamic and static adaptivity can enhance Web server performance. Two research contributions support this conclusion. First, the paper presents results from a comprehensive empirical study of Web servers (such as Apache, Netscape Enterprise, PHTTPD, Zeus, and JAWS) over high-speed ATM networks. This study illustrates their relative performance and precisely pinpoints the server design choices that cause performance bottlenecks. We found that once network and disk I/O <b>overheads</b> <b>are</b> <b>reduced</b> to negligible constant factors, the main determinants of Web server performance are its protocol processing path and concurrency strategy. Moreover, no single strategy performs optimally for all load conditions and traffic type [...] ...|$|R
40|$|High-performance Web servers are {{essential}} to meet the growing demands of the Internet. Satisfying these demands requires {{a thorough understanding of}} the key factors that affect Web server performance. This paper provides three contributions to the design, implementation, and evaluation of high-performance Web servers. First, we report the results of a comprehensive empirical study of popular high-performance Web servers (such as Apache, Netscape Enterprise, PHTTPD, and Zeus) over high-speed ATM networks. This study illustrates their relative performance and identifies their performance bottlenecks. To measure performance accurately, we developed a new benchmarking technique that subjects Web servers to varying connection frequencies. We found that once network and disk I/O <b>overheads</b> <b>are</b> <b>reduced</b> to negligible constant factors, the main determinant of Web server performance is the concurrency strategy employed by the server. Moreover, no single strategy performs optimally for all load c [...] ...|$|R
