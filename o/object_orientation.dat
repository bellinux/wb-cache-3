808|456|Public
25|$|Greenfoot – Greenfoot teaches <b>object</b> <b>orientation</b> with Java. Create 'actors' which live in 'worlds' {{to build}} games, simulations, and other {{graphical}} programs.|$|E
25|$|While {{extremely}} powerful, {{it makes}} the most common case of <b>object</b> <b>orientation,</b> a struct-like object with some associated code, unnecessarily difficult. In addition, because Perl can make no assumptions about the object model in use, method invocation cannot be optimized very well.|$|E
25|$|Across a {{protracted}} development {{period of several}} years, previews of Copland garnered much press which introduced the layperson Macintosh audience to basic concepts of modern operating system design such as <b>object</b> <b>orientation,</b> crash-proofing, and multitasking. The project was Apple's trigger to cofound several industry-wide standards and consortiums for next-generation operating system development, such as OpenDoc and Taligent.|$|E
40|$|When {{reaching}} for an object, {{the proximity of}} the <b>object,</b> its <b>orientation,</b> and shape should all be correctly estimated well before the hand arrives in contact with it. We were interested in the effects of the <b>object’s</b> <b>orientation</b> on manual prehension. Subjects were asked to reach for an object at one of several possible orientations. We found that the trajectory of the hand and its rotation and opening were significantly affected by the <b>object’s</b> <b>orientation</b> within {{the first half of the}} movement. We also detected a slight delay of the wrist relative to the forearm and a small bias of the orientation of the fingers’ tips toward the orientation of the table on which the object lay. Finally, the aperture of the hand was proportional to the physical size of the object, which shows that size constancy was achieved from the variation of the <b>object’s</b> <b>orientation.</b> Taken together, these results indicate that the three components of the movement – the transport, rotation, and opening of the hand – have access to a common visual representation of the <b>object’s</b> <b>orientation...</b>|$|R
50|$|Jennifer Pastor (born 1966) is an American {{sculptor}} and Professor of Visual Arts at the University of California Irvine. Pastor examines {{issues of}} space encompassing structure, body and <b>object</b> <b>orientations,</b> imaginary forms, narrative and progressions of sequence.|$|R
50|$|Symbolization {{highlights}} the processes through which events and conditions, artifacts, people, {{and other environmental}} features that take on particular meanings, becoming nearly only <b>objects</b> of <b>orientation.</b> Human behavior is partly contingent on what the <b>object</b> of <b>orientation</b> symbolizes or means.|$|R
25|$|Literature on spatial crossmodal biases {{suggests}} that visual modality often influences information from other senses. Some {{research indicates that}} vision dominates what we hear, when varying the degree of spatial congruency. This {{is known as the}} ventriloquist effect. In cases of visual and haptic integration, children younger than 8 years of age show visual dominance when required to identify <b>object</b> <b>orientation.</b> However, haptic dominance occurs when the factor to identify is object size.|$|E
25|$|Ruby {{has been}} {{described}} as a multi-paradigm programming language: it allows procedural programming (defining functions/variables outside classes makes them part of the root, 'self' Object), with <b>object</b> <b>orientation</b> (everything is an object) or functional programming (it has anonymous functions, closures, and continuations; statements all have values, and functions return the last evaluation). It has support for introspection, reflection and metaprogramming, as well as support for interpreter-based threads. Ruby features dynamic typing, and supports parametric polymorphism.|$|E
5000|$|Alexander Stepanov compares <b>object</b> <b>orientation</b> unfavourably to generic programming: ...|$|E
3000|$|The {{retained}} preprocessing {{is based}} on the use of Zernike moments. These moments are mainly considered in shape reconstruction [8] and can be easily made invariant to changes in <b>objects</b> <b>orientation.</b> They are defined as a set of orthogonal functions based on complex polynomials originally introduced in [9]. Zernike polynomials can be expressed as [...]...|$|R
40|$|Within this Master’s thesis, {{design and}} {{construction}} of a strapdown inertial navigation system based on MEMS sensors is described. The thesis includes theoretic analysis of physics behind determining the position of an object based on the object’s aceleration {{and changes in the}} <b>object’s</b> <b>orientation</b> in space. Included is also an overview of mathematical methods related to the position calculation...|$|R
40|$|Fast and {{accurate}} object pose estimation algorithms are crucial for robotic tasks. Despite intensive research, most approaches are not generally applicable on arbitrary object characteristics and dynamic environment conditions. Learning-based methods like Convolutional Neural Networks (CNNs) have proven good generalization properties given sufficient training data. However, annotating RGB images with 3 D <b>object</b> <b>orientations</b> {{is difficult and}} requires expert knowledge. In this work, a real-time approach for joint 2 D object detection and 3 D orientation estimation is proposed. First, a CNN-based object detector [45] is used to localize objects in an image plane. In the second step, an Autoencoder (AE) predicts the 3 D <b>orientation</b> of the <b>object</b> from the resulting scene crop. The main contribution is a new training method for AEs that allows learning 3 D <b>object</b> <b>orientations</b> from synthetic views of a 3 D model, dispensing {{with the need to}} annotate orientations in real sensor data. The AE is trained to revert augmentations applied to the input and thus becomes robust against irrelevant color changes, background clutter and occlusions. It learns to produce low-dimensional representations of synthetic <b>object</b> <b>orientations</b> which can be compared to the representations of real RGB test data in a k-Nearest-Neighbor (kNN) search. Experiments on the pose annotated dataset T-LESS [23] prove the performance of the approach on different sensors. Finally, the training on synthetic data is shown to be almost on par with the training on real data...|$|R
5000|$|Link base {{register}} for dynamically linked modules (<b>object</b> <b>orientation)</b> ...|$|E
5000|$|<b>Object</b> <b>orientation</b> of the MQL {{language}} family {{meets the}} contemporary programming standards.|$|E
5000|$|Modern <b>object</b> <b>orientation</b> {{techniques}} {{make use}} of interfaces, which are essentially templates made from function signatures.|$|E
40|$|Different {{laboratories}} {{have achieved}} a consensus regarding how well human observers can estimate the average orientation {{in a set of}} N objects. Such estimates are not only limited by visual noise, which perturbs the visual signal of each <b>object’s</b> <b>orientation,</b> they are also inefficient: Observers effectively use only ffiffiffiffi N p objects in their estimates (e. g., S. C. Dakin...|$|R
40|$|Includes bibliographical {{references}} (p. 233 - 265) and index. Introduction: sports day, mushroom and locomotive [...] Part one. Models [...] The {{grounds of}} cultural continuity [...] The most beautiful {{events in the}} world [...] Part two. Levers [...] <b>Object</b> <b>orientations</b> [...] Look at the mountain [...] Part three. Assemblies [...] On having a plan [...] Collaborations [...] Engineering subjectivities [...] Conclusion & epilogue. Mode of access: Internet...|$|R
40|$|The {{important}} {{problem of}} gyrocompass without drift creation is considered in this article. The designing device allows {{to define the}} accurate information about mobile and stationary <b>objects</b> <b>orientation</b> {{in the case of}} long-term (months, years) absence of the determining the cardinal direction possibility. This article focuses on the idea of gyrocompass without drift creation, which works on the principle of gravity-inertial orientation at the theoretical level...|$|R
5000|$|It has {{substantial}} computational {{and storage}} requirements which become acute when <b>object</b> <b>orientation</b> and scale {{have to be}} considered.|$|E
5000|$|... #Caption: Graph of {{the visual}} search task results showing that {{participants}} made less <b>object</b> <b>orientation</b> errors when grasping than pointing.|$|E
50|$|The {{language}} is semi-dynamic, and optionally strongly typed, with full <b>object</b> <b>orientation.</b> All {{variables in the}} language are first class objects.|$|E
5000|$|Shape {{constancy}} {{is similar}} to size constancy in that it relies largely on the perception of distance. Regardless of changes to an <b>object's</b> <b>orientation</b> (such as a door opening), {{the shape of the}} object is perceived the same. That is the actual shape of the object is sensed as changing but then perceived as the same. According to Kanwisher & associates, the localized part of the brain responsible for this is the extrastriate cortex.|$|R
40|$|If {{you wanted}} to take a good picture of an <b>object,</b> which <b>orientation</b> (i. e., viewpoint) would you choose? A typi-cal answer is the three-quarter view, the view in which an <b>object’s</b> <b>orientation</b> is oblique between front and side. Pictures of {{products}} in advertisements and catalogues also tend to favor the three-quarter view. In fact, a high subjective “goodness ” for a three-quarter view has been empirically documented; when people are asked to take the best pictures of objects, they choose the three-quarter view for most objects (Blanz, Tarr, & Bülthoff, 1999; Palmer, Rosch, & Chase, 1981; see also Verfaillie & Boutsen, 1995). These studies have also suggested that each familiar object has a privileged orientation, referred to as the canonical view, which yields substantial advantages for a variety of cognitive tasks, including object recognition...|$|R
50|$|For example, {{the size}} of an <b>object,</b> the <b>orientation</b> of the <b>object,</b> and its {{distance}} from the observer are conflated in the retinal image. For any given projection on the retina there are an infinite number of pairings of <b>object</b> size, <b>orientation</b> and distance that could have given rise to that projection on the retina. Because the image on the retina does not specify which pairing did in fact cause the image, this and other aspects of vision qualify as an inverse problem.|$|R
50|$|Fourth, COBOL and Fortran added {{features}} such as structured programming, character string operations, and <b>object</b> <b>orientation,</b> that further reduced PL/I's relative advantages.|$|E
5000|$|Greenfoot - Greenfoot teaches <b>object</b> <b>orientation</b> with Java. Create 'actors' which live in 'worlds' {{to build}} games, simulations, and other {{graphical}} programs.|$|E
50|$|Inner classes {{therefore}} {{allow for}} the <b>object</b> <b>orientation</b> of {{certain parts of the}} program that would otherwise not be encapsulated into a class.|$|E
40|$|International audienceIn {{the present}} study, we {{compared}} the effects of two processing modes on the updating of the location and orientation of a previously viewed object in space during a guided walk without vision. In Experiment 1, {{in order to measure}} the error for initial perception of <b>object's</b> <b>orientation,</b> 12 subjects rotated a miniature model until it matched the memorized orientation of its counterpart object in space. In Experiment 2, they attempted either {{to keep track of the}} object continuously (in the object-centered [OC] task) or to estimate the object's perspective only at the terminal vantage point given the trajectory they walked (in the trajectory-centered [TC] task). Subjects indicated the location of the object by facing it, and then rotated the model in order to indicate its orientation from the new vantage point. Results showed that, with respect to the TC mode, the OC mode induced a slow-down of the subjects' self-paced locomotion velocity for both linear and angular movements, and a decrease of the latencies as well as smaller absolute errors for the orientation-of-the-object response. Mean signed errors on <b>object's</b> <b>orientation</b> were equivalent for both processing modes, suggesting that the latter induced different allocations of processing resources on a common representation of space updated by "path integration. ...|$|R
5000|$|If we {{consider}} a {{plane of the}} <b>object,</b> the <b>orientation</b> of the plane can be given by its normal line. If we draw a sphere with the center on the plane, then ...|$|R
50|$|Spatial {{relationship}}: {{relationship between}} spatial <b>objects,</b> including topological, <b>orientation,</b> similarity, etc..|$|R
5000|$|The Lucee {{language}} supports multiple development paradigms, including <b>object</b> <b>orientation</b> with inheritance and interfaces, {{and functional}} constructs like higher-order functions, closures, , and [...]|$|E
50|$|The MSC 2000 version added <b>object</b> <b>orientation,</b> refined {{the use of}} {{data and}} time in diagrams, and added the concept of remote method calls.|$|E
50|$|Objects form {{a capsule}} which {{combines}} the character to the respective behavior. Objects should enable programmers to map {{a real problem}} and its proposed software solution on a one-to-one basis. Typical objects in a business environment are, for example, ‘Customer’, ‘Order’, or ‘Invoice’. From Release 3.1 onwards, the Business Object Repository (BOR) of SAP Web Application Server ABAP has contained examples of such objects. The BOR object model will be integrated into ABAP Objects in the next Release by migrating the BOR object types to the ABAP class library.A comprehensive introduction to <b>object</b> <b>orientation</b> as a whole would go far {{beyond the limits of}} this introduction to ABAP Objects. This documentation introduces a selection of terms that are used universally in <b>object</b> <b>orientation</b> and also occur in ABAP Objects. In subsequent sections, it goes on to discuss in more detail how these terms are used in ABAP Objects. The end of this section contains a list of further reading, with a selection of titles about <b>object</b> <b>orientation.</b>|$|E
5000|$|In {{the first}} phase, 24 {{attachments}} are elicited in four categories: people, events, places and <b>objects,</b> and <b>orientations</b> to body parts. In an interview, {{the history and}} meaning of each attachment is explored.|$|R
40|$|Abstract: In {{conventional}} model-based coding schemes, predefined static {{models are}} generaliy used. Thesa models cannot adapt to new situations and hence {{they have to}} be very specific and cannot be generated from a single generic model even though they are very similar. In this paper, we present a model generation technique that can gradually build a model and dynamically modify it according to new video frames scanned. The proposed technique is robust to the <b>object's</b> <b>orientation</b> in the view and can be efficiently implemented with parallel processing lechnique. As a result, the proposed technique is more attractive to the practical use of model-based coding techniques in real applications. 1...|$|R
40|$|Digital Image Processing plays a {{vital role}} in several {{applications}}. One of the applications is detection of people faces in a digital photo. Several research works have been progressing in the field of face identification and matching, facial expressions identification, smile detection, etc. Any application related to face, first step is detection of face. Thus, the face detection plays a key role. The face detection is a complicated process due to background <b>objects,</b> <b>orientation,</b> scale, lighting, geometrics, quality of image, occlusion, disguise etc. This paper discusses different research techniques published in the peer reviewed journal and proposed a technique to detect faces in a group photo...|$|R
