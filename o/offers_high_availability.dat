17|10000|Public
50|$|Windows Server 2008 <b>offers</b> <b>high</b> <b>availability</b> to {{services}} and applications through Failover Clustering. Most server features and roles {{can be kept}} running with little to no downtime.|$|E
5000|$|Leapsight Semantic Dataspace (LSD) is a {{distributed}} {{deductive database}} that <b>offers</b> <b>high</b> <b>availability,</b> fault tolerance, operational simplicity, and scalability. LSD uses Leaplog (a Datalog implementation) for querying and reasoning and was create by Leapsight.|$|E
50|$|Basho is the {{developer}} of Riak, an open source distributed database that <b>offers</b> <b>high</b> <b>availability,</b> fault tolerance, operation simplicity and scalability. Riak Enterprise is a commercial {{version of the}} database offered by Basho, the project's sponsor, with advanced multi-data center replication and enterprise support.|$|E
40|$|Abstract. We {{present a}} {{solution}} to the <b>high</b> <b>availability</b> issue that arises when digital time-stamping authority tries pro-viding robust services to its users. <b>High</b> <b>availability</b> of time-stamping services is very important because any suspension of service due to system failure or potential attacks results in serious monetary losses. In this paper, we present a new approach that deploys an RSA threshold signature scheme to <b>offer</b> <b>high</b> <b>availability</b> for multiple time-stamping servers. It allows the sharing of signing key into n servers while the robustness of the system is unaffected even if some subsets of less than t servers are corrupted and work together. Our proposed solution provides a strong prevention measure instead of recovery measure of physical operation and cryptographical attack. Thus, it enjoys a higher level of security protection than traditional <b>high</b> <b>availability</b> protocol...|$|R
30|$|To <b>offer</b> <b>high</b> <b>availability,</b> Amazon {{replicates}} data {{across multiple}} servers within its data centres. Replicas are kept weakly consistent {{and as a}} result, some perfectly legal operations could sometime fail or return inaccurate results (see[12], Data Consistency Model section). For example, the customer might receive a ObjectDoesNotExist {{as a response to}} a legal GET request or an incomplete list of objects after executing a LIST operation. Some of these problems can be corrected by re-trying the operation. From Amazon accounting model, it is not clear who bears the cost of the failed operations and their retries.|$|R
40|$|Recovery Oriented Computing (ROC) {{is a joint}} {{research}} effort between Stanford University and the University of California, Berkeley. ROC takes the perspective that hardware faults, software bugs, and operator errors are facts to be coped with, not problems to be solved. This perspective is supported both by historical evidence and by recent studies on the main sources of outages in production systems. By concentrating on reducing Mean Time to Repair (MTTR) rather than increasing Mean Time to Failure (MTTF), ROC reduces recovery time and thus <b>offers</b> <b>higher</b> <b>availability.</b> We describe the principles and philosophy behind the joint Stanford/Berkeley ROC effort and outline some of its research areas and current projects...|$|R
50|$|OpenVMS is a multi-user, {{multiprocessing}} virtual memory-based {{operating system}} (OS) {{designed for use}} in time sharing,batch processing, and transaction processing. When process priorities are suitably adjusted, it may approach real-time operating system characteristics. The system <b>offers</b> <b>high</b> <b>availability</b> through clustering {{and the ability to}} distribute the system over multiple physical machines. This allows the system to be tolerant against disasters that may disable individual data-processing facilities.|$|E
5000|$|Riak (pronounced [...] "ree-ack" [...] ) is a {{distributed}} NoSQL key-value {{data store}} that <b>offers</b> <b>high</b> <b>availability,</b> fault tolerance, operational simplicity, and scalability. In {{addition to the}} open-source version, it comes in a supported enterprise version and a cloud storage version. Riak implements the principles from Amazon's Dynamo paper with heavy influence from the CAP Theorem. Written in Erlang, Riak has fault tolerance data replication and automatic data distribution across the cluster for performance and resilience.|$|E
50|$|XAP4, XAP5 and XAP6 are all {{designed}} with a load-store RISC architecture that is complemented with multi-cycle instructions for multiplication, division, block copy/store and function entry/exit for maximum efficiency. Cambridge Consultants’ engineers recognised {{the requirement for}} these processors to run real-time operating systems capable of handling pre-emptive events and with a fast interrupt response. Consequently the processors are {{designed with}} hardware and instruction set support for protected software operating modes that partition user code from privileged operating system and interrupt handler code. The XAP processor hardware manages the mode transitions and call stack in response to events and this approach ensures a fast and deterministic interrupt response. The protected operating modes enable a {{system on a chip}} to be designed that is a secure or trustworthy system and <b>offers</b> <b>high</b> <b>availability.</b>|$|E
40|$|While sharded NoSQL stores <b>offer</b> <b>high</b> <b>availability,</b> re-configuration {{operations}} {{present a}} major pain point in de-ployments today. For instance, {{in order to}} change a con-figuration setting such as the shard (or primary) key of a database table, the prevalent solutions entail shutting down the database, exporting and re-importing the table, and restarting the database. This goes against the philos-ophy of <b>high</b> <b>availability</b> of data. Our system Morphus provides support for reconfigu-rations for NoSQL stores in an online manner, allowing read and write operations to continue concurrently with the data transfer among servers. This paper presents: i) optimal algorithms for online reconfigurations, and ii) a systems architecture for reconfiguration operations in-corporated into MongoDB. Our evaluation using realistic workloads shows that our system completes reconfigura-tion efficiently and incurs minimal overhead for reads and writes during the reconfiguration. ...|$|R
25|$|Use of Ethernet by CobraNet <b>offers</b> many <b>high</b> <b>availability</b> {{features}} such as Spanning Tree Protocol, link aggregation, and network management. For critical applications, CobraNet devices can be wired with redundant connections to the network. In this configuration, if one CobraNet device, cable, or Ethernet switch fails, the other takes over almost immediately.|$|R
40|$|The {{systems that}} {{currently}} provide Internet users with sophisticated e-business services struggle to <b>offer</b> <b>high</b> <b>availability</b> guarantees while being managed as regular systems, because management architectures {{rely on the}} manager-agent paradigm and domain-based distribution. In this paper, we argue that e-business information systems should instead be structured as self-managed systems: they need to detect problems by themselves, work out the cause of each problem, and take corrective actions independently of any external entity. They should not depend on external managers for their efficiency and robustness. To achieve this, we propose an organizational model that allows management architectures {{to take into account}} the specific requirements of self-managed systems, and investigate how to distribute event correlation in the presence of self-managed systems...|$|R
40|$|This paper {{presents}} {{a new technique}} of recovery for object-based Distributed Shared Memory (DSM) systems. The new technique, integrated with a coherence protocol for atomic consistency model, <b>offers</b> <b>high</b> <b>availability</b> of shared objects in spite of multiple node and communication failures, introducing little overhead. It ensures fast recovery in case of multiple node failures and enables a DSM system to circumvent the network partitioning, {{as far as a}} majority partition can be constituted...|$|E
40|$|Summary. In {{this paper}} {{we present a}} work in {{progress}} dedicated to the recognition and prediction of mobile user activities. In contrast with related projects that gen-erally use GPS for localization, we employ a fusion of wireless positioning methods available in current smartphones (GPS, GSM, Wi-Fi). Our positioning system <b>offers</b> <b>high</b> <b>availability</b> and accuracy without dedicated calibration. We demonstrate how such a positioning information can improve place extraction algorithms and enable the recognition of the new types of user activities both indoors and outdoors. Be-sides that, the project addresses a number of open challenges in activity and place prediction, such as detection of behaviour changes, prediction of unseen places. Key words: activity recognition, behaviour prediction, location awareness...|$|E
40|$|Virtualization {{technology}} is transforming today’s IT community, offering new possi-bilities {{to improve the}} performance and efficiency of IT infrastructure by a dynamic mapping of the PC resources, enabling to run multiple applications and operating systems on a single physical system. Virtualization also <b>offers</b> <b>high</b> <b>availability</b> and error recovery solutions by encapsulating entire systems into single files that can be replicated and restored on any desti-nation machine. This paper brings new elements related {{to the concept of}} virtualization, presenting the princi-ples, the new architectures and the advantages of the virtualization. We make also a brief comparison between the PC’s functional structure before and after the virtualization. Finally, we present licensed software to create and run multiple virtual machines on a personal com-puter. ...|$|E
40|$|Abstract: The {{primary goal}} of {{computer}} clusters is to improve computing performances {{by taking advantage of}} the parallelism they intrinsically provide. Moreover, their use of redundant hardware components enables them to <b>offer</b> <b>high</b> <b>availability</b> services. In this paper, we present an analytical model for analyzing redundancy schemes and their impact on the cluster’s overall performance. Furthermore, several cluster redundancy techniques are analyzed with an emphasis on hardware and data redundancy, from which we derive an applicable redundancy scheme design. Also, our solution provides a disaster recovery mechanism that improves the cluster’s availability. In the case of data redundancy, we present improvements to the replication and parity data replication techniques for which we investigate the availability of the cluster under several scenarios that take into account, among other things, the number of replicated nodes, the number of CPUs that hold parity data and the relation between primary and replicated data. For this purpose, we developed a simulator that analyzes the impact of a redundancy scheme on the processing rate of the cluster. We also studied the performance of two well-known schemes according to the usage rate of the CPUs. We found that two important aspects influencing the performance of a transaction-oriented cluster were the cluster’s failover and data redundancy schemes. We simulated several data redundancy schemes and found that data replication <b>offered</b> <b>higher</b> cluster <b>availability</b> than the parity model...|$|R
40|$|Causal {{consistency}} {{has emerged}} as an attractive middle-ground to architecting cloud storage systems, as it allows for <b>high</b> <b>availability</b> and low latency, while supporting stronger-than-eventual-consistency semantics. However, causally-consistent cloud storage systems have seen limited deployment in practice. A key factor is these systems employ full replication of all the data in all the data centers (DCs), incurring high cost. A simple extension of current causal systems to support partial replication by clustering DCs into rings incurs availability and latency problems. We propose Karma, the first system to enable causal consistency for partitioned data stores while achieving the cost advantages of partial replication without the availability and latency problems of the simple extension. Our evaluation with 64 servers emulating 8 geo-distributed DCs shows that Karma (i) incurs much lower cost than a fully-replicated causal store (obviously due to the lower replication factor); and (ii) <b>offers</b> <b>higher</b> <b>availability</b> and better performance than the above partial-replication extension at similar costs...|$|R
50|$|Since version 2.0, Proxmox VE <b>offers</b> a <b>high</b> <b>availability</b> {{option for}} {{clusters}} {{based on the}} Corosync communication stack. Individual virtual servers can be configured for <b>high</b> <b>availability,</b> using the Red Hat cluster suite. If a Proxmox node becomes unavailable or fails the virtual servers can be automatically moved to another node and restarted.The database- and FUSE-based Proxmox Cluster filesystem (pmxcfs) {{makes it possible to}} perform the configuration of each cluster node via the Corosync communication stack.|$|R
40|$|Software {{development}} {{is becoming a}} more and more distributed process, which urgently needs supporting tools {{in the field of}} configuration management, software process /workflow management, communication and problem tracking. In this paper we present a new distributed software configuration management framework COMAND. It <b>offers</b> <b>high</b> <b>availability</b> through replication and a mechanism to easily change and adapt the project structure to new business needs. To better understand and formally prove some properties of COMAND, we have modeled it in a formal technique based on distributed graph transformations. This formalism provides an intuitive rule-based description technique mainly for the dynamic behavior of the system on an abstract level. We use it here to model the replication subsystem. 1. Introduction Developing software is not an easily planable process. Not only that software projects are much bigger our days than they were before but stricter quality requirements make it even more [...] ...|$|E
40|$|Abstract—While sharded NoSQL stores offer high availabil-ity, {{reconfiguration}} operations {{present a}} major pain point in deployments today. For instance, {{in order to}} change a configuration setting such as the shard (or primary) key of a database table, the prevalent solutions entail shutting down the database, exporting and re-importing the table, and restarting the database. This goes against the NoSQL philosophy of high availability of data. Our system, called Morphus, provides support towards re-configurations for NoSQL stores in an online manner. Morphus allows read and write operations to continue concurrently with the data transfer among servers. Morphus works for NoSQL stores that feature master-slave replication, range partition-ing, and flexible data placement. This paper presents: i) a systems architecture for online reconfigurations, incorporated into MongoDB, and ii) optimal algorithms for online recon-figurations. Our evaluation using realistic workloads shows that Morphus completes reconfiguration efficiently, <b>offers</b> <b>high</b> <b>availability,</b> and incurs low overhead for reads and writes. Index Terms—shard key change, reconfiguration, nosql 1...|$|E
40|$|Abstract—Unprecedented {{growth of}} online social {{networks}} (OSNs) increasingly makes privacy advocates {{and government agencies}} worrisome alike. In this paper, we propose My 3, a privacy-friendly decentralized alternative for online social networking. The My 3 system exploits well-known interesting properties of the current online social networks in its novel design namely, locality of access, predictable access times, geolocalization of friends, unique access requirements of the social content, and implicit trust among friends. It allows users to exercise finer granular access control on the content, thus making My 3 extremely privacy-preserving. Moreover, we propose different replication strategies that users may independently choose for meeting their personalized performance objectives. A detailed performance study evaluates the system regarding profile availability, access delay, freshness and storage load. By using real-world data traces, we prove that My 3 <b>offers</b> <b>high</b> <b>availability</b> even with low average online time of users in the network. Keywords-privacy; trust; decentralized social networks I...|$|E
30|$|Remus is a {{production}} level solution implemented at Xen to <b>offer</b> <b>High</b> <b>Availability</b> following this strategy [22]. Authors of that solution {{point out that}} lock-step replication results in an unacceptable resource usage overhead because communication between applications must be accurately tracked and propagated to all replicas. In contrast, checkpoints between active and standby replicas occurs periodically, in intervals of milliseconds, providing better tradeoff between resource usage overhead and updates. Taking a similar approach, Chan and Chieu [23] introduce a cost effective solution which utilizes VM snapshots coupled with a smart, on-demand snapshot collection mechanism to provide an HA in the virtualization environment. The main idea behind this proposal is to extend the snapshot service (a common service offered by virtualized infrastructures) to include checkpoint data of a VM.|$|R
40|$|The {{bachelor}} {{thesis is}} focused on topic of Transatlantic Trade and Investment Partnership and it's potential impact on EU and USA economy. The agreement prepared since 2011 is to merge two of most powerful economies on present world into Transatlantic Free Trade Area and to create barrier-free trade mechanism, which is currently operational inside the United States of America and European Union. With respect to global prespective this ambitious project can bring strong economic recovery for both economics, faster mutual trade and closer political cooperation of {{western part of the}} world. For individuals the agreement may ensure an increase of job <b>offer,</b> <b>higher</b> <b>availability</b> of foreign products and also easier travelling. If this trade agreement was realized, may affect the wide trade coperation {{all over the world and}} have strong impact on global economic and politic situation...|$|R
40|$|International audienceGeo-replicated {{databases}} often <b>offer</b> <b>high</b> <b>availability</b> and {{low latency}} {{by relying on}} weak consistency models. The inability to enforce invariants across all replicas remains a key shortcoming that prevents the adoption of such databases in several applications. In this paper we show how to extend an eventually consistent cloud database for enforcing numeric invariants. Our approach builds on ideas from escrow transactions, but our novel design overcomes the limitations of previous works. First, by relying on a new replicated data type, our design has no central authority and uses pairwise asynchronous communication only. Second, by layering our design {{on top of a}} fault-tolerant database, our approach exhibits better availability during network partitions and data center faults. The evaluation of our prototype, built on top of Riak, shows much lower latency and better scalability than the traditional approach of using strong consistency to enforce numeric invariants...|$|R
40|$|The work {{presents}} a new protocol, VELOS, for tolerating partitionings in distributed systems with replicated data. Our primary goals {{were influenced by}} efficiency and availability constraints. The proposed protocol achieves optimal availability, according to a well known metric, while ensuring one copy serializability. In addition, however, VELOS is designed {{to reduce the cost}} involved in achieving high availability. We have developed mechanisms through which transactions, in the absence of failures, can access replicated data objects and observe shorter delays than related protocols, and impose smaller loads on the network and the servers. Furthermore, VELOS <b>offers</b> <b>high</b> <b>availability</b> without relying on system transactions that must execute to restore availability when failures and recoveries occur. Such system transactions typically access all (replicas of all) data objects and thus introduce significant delays to user transactions and consume large quantities of resources such as network bandwidth and CPU cycles. Thus, we offer our protocol as a proof that high availability can be achieved inexpensively...|$|E
40|$|Online Social Networks (OSNs) are {{becoming}} more and more popular in today’s Internet. Distributed Online Social Networks (DOSNs), are OSNs which do not exploit a central server for storing users’ data and enable users to have more control on their profile content, ensuring a higher level of privacy. The main challenge of DOSNs comes from guaranteeing availability of the data when the data owner is offline. In this paper we propose a new P 2 P dynamic approach to the problem of data persistence in DOSNs. By following Dunbar’s approach, our system stores the data of a user only on a restricted number of friends which have regular contacts with him/her. Users in this set are chosen by considering several criteria targeting different goals. Differently from other approaches, nodes chosen to keep data replicas are not statically defined but dynamically change according to users’ churn. Our dynamic friend selection achieves availability higher than 90 % with a maximum of 2 online profile replicas at a time for users with at least 40 friends. By using real Facebook data traces we prove that our approach <b>offers</b> <b>high</b> <b>availability</b> even when the online time of users is low...|$|E
40|$|Abstract—Video-on-demand {{service in}} {{wireless}} networks is one important step to achieving {{the goal of}} providing video services anywhere anytime. Typically, carrier mobile networks are used to deliver videos wirelessly. Since every video stream comes from the base station, regardless of what bandwidth sharing techniques are being utilized, the media stream system is still limited by the network capacity of the base station. The key to overcome the scalability issue is to exploit resources available at mobile clients in a peer-to-peer setting. We observe that {{it is common to}} have a carrier mobile network and a mobile peer-to-peer network co-exist in a wireless environment. A feature of such hybrid environment is that the former <b>offers</b> <b>high</b> <b>availability</b> assurance, while the latter presents an opportunistic use of resources available at mobile clients. Our proposed video-on-demand technique, PatchPeer, leverages this network characteristic to allow the video-on-demand system scale beyond the bandwidth capacity of the server. Mobile clients in PatchPeer are no longer passive receivers, but also active senders of video streams to other mobile clients. Our extensive performance study shows that PatchPeer can accept more clients than the current state-of-the-art technique, while maintaining the same Quality-of-Service to clients. I...|$|E
40|$|Existing SDNs {{rely on a}} {{collection}} of intricate, mutually-dependent mechanisms to implement a logically centralized control plane. These cyclical dependencies and lack of clean separation of concerns can impact the availability of SDNs, such that a handful of link failures could render entire por-tions of an SDN non-functional. This paper shows why and when this could happen, and makes the case for taking {{a fresh look at}} architecting SDNs for robustness to faults from the ground up. Our approach carefully synthesizes various key distributed systems ideas – in particular, reliable flood-ing, global snapshots, and replicated controllers. We argue informally that it can <b>offer</b> <b>high</b> <b>availability</b> {{in the face of a}} variety of network failures, but much work needs to be done to make our approach scalable and general. Thus, our pa-per represents a starting point for a broader discussion on approaches for building highly available SDNs...|$|R
40|$|Novel energy-aware cloud {{management}} methods dynamically reallocate computation across geographically distributed {{data centers}} to leverage regional electricity price and temperature differences. As a result, a managed VM may suffer occasional downtimes. Current cloud providers only <b>offer</b> <b>high</b> <b>availability</b> VMs, without enough flexibility to apply such energy-aware management. In this paper we show how to analyse past traces of dynamic cloud management actions based on electricity prices and temperatures to estimate VM availability and price values. We propose a novel SLA specification approach for offering VMs with different availability and price values guaranteed over multiple SLAs to enable flexible energy-aware cloud management. We determine the optimal {{number of such}} SLAs {{as well as their}} availability and price guaranteed values. We evaluate our approach in a user SLA selection simulation using Wikipedia and Grid' 5000 workloads. The results show higher customer conversion and 39 % average energy savings per VM. Comment: 14 pages, conferenc...|$|R
40|$|Storage area {{networks}} <b>offer</b> <b>high</b> <b>availability,</b> reliability, and scalability, and are {{a promising}} solution for large-scale storage needs of many enterprises. As with any distributed storage system, a major design challenge for SANs is to provide secure storage, which implies data integrity and data confidentiality. In this article we propose a solution that addresses these core security requirements. In particular, we focus on mechanisms that enable efficient key management for SAN entities and allow scalable data sharing. We use strong cryptographic techniques to achieve data security and integrity. Further, we delegate {{the bulk of the}} cryptographic processing to the SAN entities, thereby removing bottlenecks at disks and causing minimal inconvenience to hosts. By recognizing the peer nature of the group of SAN entities, we propose a novel security architecture for SAN that uses a secure group communication protocol to provide efficient group keying without involving any centralized servers. This fosters both scalability and fault tolerance...|$|R
40|$|Peer-to-peer (P 2 P) {{networks}} have recently grown in popularity {{for a variety}} of applications such as content distribution, streaming multimedia and voice-over IP. P 2 P networks are built around a decentralized architecture to distribute data in a manner that <b>offers</b> <b>high</b> <b>availability</b> of content, inherent fault-tolerance and efficiency. While P 2 P networks offer several important advantages over traditional client/server architectures, experience has shown that these networks are file sharing copyright protected content, which presents significant problems for network management and copyright enforcement. P 2 P networks utilize a large amount of bandwidth, complicating network management for broadband Internet service providers (ISPs), particularly during times of peak network utilization. In addition, the illegal dissemination of copyright protected media is an obvious problem for the respective copyright holders that may result in a loss of revenue. As a consequence, there is ample incentive for both broadband ISPs and copyright holders to work to stop the proliferation of file sharing within P 2 P networks. Our primary goal in this paper is to understand the current techniques for distributing and hiding copyright protected content within P 2 P networks. We focus our discussion primarily on BitTorrent, since it is currently the most popular P 2 P protocol for file sharing. We observe that a...|$|E
40|$|Abstract. Realizing highly {{available}} datacenter power {{infrastructure is}} an extremely expensive proposition with costs more than doubling as we move from three 9 ’s (Tier- 1) to six 9 ’s (Tier- 4) of availability. Existing approaches only consider the cost/availability trade-off for a restricted set of power infrastructure configurations, relying mainly on component redundancy. A number of additional knobs such as centralized vs. distributed component placement, power-feed interconnect topology and component capacity over-provisioning also exist, whose impact has only been studied in limited forms. In this paper, we provide a systematic approach to understand the cost/availability trade-off offered by these configuration parameters {{as a function of}} supported IT load. We develop detailed datacenter availability models using Continuous-time Markov Chains and Reliability Block Diagrams to quantify the relative impact of these parameters on availability. Using real-world component availability data to parametrize these models, we offer a number of interesting insights into developing cost-effective yet highly available power infrastructure. As two salient examples, we find (i) although centralized UPS placement <b>offers</b> <b>high</b> <b>availability,</b> it does so with significant cost, and (ii) distributed server-level UPS placement is much more cost-effective but does not offer meaningful availability for operating the datacenter at full load. Based on these insights, we propose a novel hybrid strategy that combines the server-level UPS placement with a rack-level UPS, achieving as good availability as existing centralized techniques, at just two-thirds of its cost. ...|$|E
40|$|Abstract—Modern {{business}} has a 24 x 7 non-stop running {{and the availability}} of the business continuity for everything, from everywhere, at all time is a growing requirement. System out-ages are more often due to software fault, than hardware fault. Software availability is one of the weakest links in system avail-ability. Several studies have reported that one of the causes of unplanned software outages is the software aging phenomenon. Server virtualization is becoming so reliable and cost effective solutions for the availability of the business continuity. In virtua-lization environments, the hypervisor or virtual machine moni-tor (VMM) itself or virtual machines (VM) can fail with software failure. Software rejuvenation is one of the promising techniques assuring <b>high</b> <b>availability</b> of server virtualized system. To pre-vent system failures caused by software aging in both VM and VMM, software rejuvenation can be applied. The work pre-sented in this paper aims to <b>offer</b> <b>high</b> <b>availability</b> against soft-ware aging of virtualized server system by providing both VM clustering software rejuvenation and VM migration based soft-ware rejuvenation analytic model using stochastic reward nets (SRN) for time based rejuvenation policy. Numerical examples are presented to illustrate the applicability of the model. The numerical derivation results are validated with the evaluation results through SHARPE tool...|$|R
40|$|Abstract—NoSQL {{systems have}} grown in {{popularity}} for storing big data because these systems <b>offer</b> <b>high</b> <b>availability,</b> i. e., operations with high throughput and low latency. However, metadata in these systems are handled today in ad-hoc ways. We present Wasef, a system that treats metadata in a NoSQL database system, as first-class citizens. Metadata may include information such as: operational history for a database table (e. g., columns), placement information for ranges of keys, and operational logs for data items (key-value pairs). Wasef allows the NoSQL system to store and query this metadata efficiently. We integrate Wasef into Apache Cassandra, {{one of the most}} popular key-value stores. We then implement three important use cases in Cassandra: dropping columns in a flexible manner, verifying data durability during migrational operations such as node decommissioning, and maintaining data provenance. Our experimental evaluation uses AWS EC 2 instances and YCSB workloads. Our results show that Wasef: i) scales well with the size of the data and the metadata; ii) minimally affects throughput and operation latencies. 1...|$|R
40|$|Consumers often {{purchase}} goods that are “hard to find ” to conspicuously display their exclusivity and social status. Firms that produce such conspicuously consumed goods such as designer apparel, fashion goods, jewelry, etc., often face challenges in making optimal pricing and production decisions. Such firms {{are confronted with}} precipitous tradeoff between high sales volume and high margins, due to the highly uncertain market demand, strategic consumer behavior, and the display of conspicuous consumption. In this paper, we propose a model that addresses pricing and production decisions for a firm, using the rational expectations framework. We show that, in equilibrium, firms may <b>offer</b> <b>high</b> <b>availability</b> of goods {{despite the presence of}} conspicuous consumption. We show that scarcity strategies are harder to adopt as demand variability increases, and we provide conditions under which scarcity strategies could be successfully adopted to improve profits. Finally, to credibly commit to scarcity strategy, we show that firms can adopt sourcing strategies, such as sourcing from an expensive production location/supplier or using expensive raw materials, that signal deeper investment in unit production costs...|$|R
40|$|Replication {{is known}} to <b>offer</b> <b>high</b> <b>availability</b> in the {{presence}} of failures. This paper considers the case of a client making invocations on a group of replicated servers. It identifies attributes that typically characterise group invocation and replica management, and the options generally available for each attribute. A combination of options on these attributes constitutes a policy. The paper proposes an implementation framework which, by its group-oriented nature, simplifies the task of supporting these policies. It then considers a client (in UCL, London) making invocations on a replica group (in Newcastle, UK) over the Internet. It evaluates the response latencies for four policies that seem appropriate for this set-up. The evaluation takes into account the timing of server crashes with respect to client invocations; both real and virtual failures are considered, the latter being not uncommon in the Internet environment. The experiments are carried out using a CORBA compliant system called NewTop. Keywords and Phrases: server crashes, group invocation, replica management, total order, policy attributes, causal precedence, latency, CORBA. 1...|$|R
