15|140|Public
50|$|Harris, J. R., Shaw, M. L., & Altom, M. J. (1985). Serial {{position}} curves for {{reaction time}} and accuracy in visual search: Tests {{of a model}} of <b>overlapping</b> <b>processing.</b> Perception & Psychophysics, 38, 178-187.|$|E
50|$|In {{both the}} {{original}} version and 1A, clocks for Program Store and Call Store were operated out of phase, so one would be delivering data while the other was still accepting an address. Instruction decoding and execution were pipelined, to allow <b>overlapping</b> <b>processing</b> of consecutive instructions in a program.|$|E
40|$|This paper {{presents}} {{an approach to}} developing a computer-aided process planning in which three important areas of production systems are integrated. The system {{takes advantage of the}} relationship among group technology, process planning and scheduling to develop a parts processing system that considers <b>overlapping</b> <b>processing</b> of parts in more than a single cell. The system uses the powerful feature of object-oriented paradigm to develop object coding of parts that focuses on the relationship between parent and children and the inheritance feature of the object-oriented paradigm...|$|E
50|$|In human memory research, {{concurrent}} overlap, or task appropriate processing, {{is a type}} of <b>processing</b> <b>overlap</b> {{between an}} activity engaged in before the prospective memory is to be remembered and a cue that directs attention towards the prospective memory. It is prospective memory specific and is distinct from sequential <b>overlap,</b> or transfer-appropriate <b>processing,</b> which occurs in both retrospective and prospective memory and is defined as the <b>overlap</b> in <b>processing</b> the to-be-remembered memory between planning (or study in retrospective memory) and test times.|$|R
50|$|The {{processor}} has a 24-bit ALU (Arithmetic Logic Unit) and <b>overlapped</b> <b>processing</b> {{of several}} instructions (a so-called pipeline) {{which are the}} two primary reasons for its speed. Unlike the older Z280 and Z380 {{it does not have}} (or need) a cache memory. Instead, it is intended to work with fast SRAM directly as main memory (as this had become much cheaper). Nor does it have the multiplexed bus of the Z280, making it as easy to work with (interface to) as the original Z80 and Z180, and equally predictable when it comes to exact execution times.|$|R
5000|$|Vision {{processing}} unit, a {{class of}} processors aimed at machine vision (including convolutional neural networks, hence <b>overlapping</b> with 'neural <b>processing</b> units') ...|$|R
40|$|We study {{multipurpose}} {{batch process}} industries with no-wait restrictions, <b>overlapping</b> <b>processing</b> steps, and parallel resources. To achieve high utilization and reliable lead times, the master planner {{needs to be}} able to accurately and quickly estimate the makespan of a job set. Because constructing a schedule is time consuming, and production plans may change frequently, estimates must be based on aggregate characteristics of the job set. To estimate the makespan of a complex set of jobs, we introduce the concept of job interaction. Using statistical analysis, we show that a limited number of characteristics of the job set and the available resources can explain most of the variability in the job interaction...|$|E
40|$|Abstract—In this paper, {{we propose}} an {{efficient}} hierarchical DNA sequence search method {{to improve the}} search speed while the accuracy is being kept constant. For a given query DNA sequence, firstly, a fast local search method using histogram features {{is used as a}} filtering mechanism before scanning the sequences in the database. An <b>overlapping</b> <b>processing</b> is newly added to improve the robustness of the algorithm. A large number of DNA sequences with low similarity will be excluded for latter searching. The Smith-Waterman algorithm is then applied to each remainder sequences. Experimental results using GenBank sequence data show the proposed method combining histogram information and Smith-Waterman algorithm is more efficient for DNA sequence search. Keywords—Fast search, DNA sequence, Histogram feature, Smith-Waterman algorithm, Local searc...|$|E
30|$|It was not clear, a priori, whether {{speaking}} {{a second language}} and musical training should be associated with similar patterns of cognitive functioning. On one hand, music and language involve <b>overlapping</b> <b>processing</b> systems and have demonstrated transfer from one domain to the other (Asaridou & McQueen, 2013; Besson et al., 2011; Moreno, 2009; Patel, 2011, 2014). On the other, they demonstrate notable differences due to the varying functional demands of each domain (Hutka et al., 2013). Our findings help address {{the debate on the}} similarity between music and language and support a distinction between music and language since we did not observe similar patterns of performance. While, music effects were demonstrated across cognitive measures of working memory, bilingual effects were not. The current study demonstrates the unique vantage point of comparing domain-general enhancement from one training form compared to another.|$|E
5000|$|George 2 {{added the}} concept of off line {{peripheral}} handling (spooling). Several different modules, running in parallel, allowed <b>overlapping</b> of input, <b>processing</b> and output operations: ...|$|R
50|$|Greater <b>overlap</b> of <b>processing</b> at {{study and}} test result in {{increased}} performance. TAP accounts for picture superiority by an interaction of encoding and retrieval. If items are encoded during a semantic task, performance should be higher for a memory test {{that relies on}} concepts related to the items for retrieval than a test that relies on perceptual features.|$|R
25|$|Pericutaneous space: The space {{just outside}} our bodies but {{which might be}} near to {{touching}} it. Visual-tactile perceptive fields <b>overlap</b> in <b>processing</b> this space. For example, an individual might see a feather as not touching their skin but still experience the sensation of being tickled when it hovers just above their hand. Other examples include the blowing of wind, gusts of air, and the passage of heat.|$|R
40|$|DNA {{sequence}} {{search is}} a very important topic in bioinformatics algorithm development. However, this task usually spends much computational time to search on large DNA sequence database. In this paper, we propose an efficient hierarchical DNA sequence search algorithm to improve the search speed while the accuracy is being kept constant. For a given query DNA sequence, firstly, a fast local search algorithm using histogram features is used as a filtering mechanism before scanning the sequences in the database. An <b>overlapping</b> <b>processing</b> is newly added to improve the robustness of the algorithm. A large number of DNA sequences with low similarity will be excluded for latter searching. The Smith-Waterman algorithm is then applied to each remainder sequences. Experimental results using GenBank sequence data show the proposed algorithm combining histogram information and Smith-Waterman algorithm is more efficient for DNA sequence search...|$|E
40|$|One of the {{weaknesses}} of most MRP systems, {{is that they do}} not allow overlapping of activities on a batch by sequential machines. However, by letting the second machine start processing a batch before the first one has finished it yet [...] a well known idea utilized by many practitioners [...] we can often achieve considerable improvement in terms of shorter lead time. This requires the use of partial transfer lots. In this paper we address the problem from a theoretical point of view. We optimize the sizes of the transfer lots for <b>overlapping</b> <b>processing</b> on two machines to as to minimize the makespan under a constraint on the number of transfers. We also discuss the issue of several consecutive jobs (batches), and how to extend the solution to several machines in such a manner that all machines process the batch continuouslyNaval Postgraduate School, Monterey, CA. [URL]...|$|E
40|$|Many {{scientific}} applications involve grids {{that lack}} a uniform underlying structure. These applications are often also dynamic in nature {{in that the}} grid structure significantly changes between successive phases of execution. In parallel computing environments, mesh adaptation of unstructured grids through selective refinement/coarsening {{has proven to be}} an effective approach. However, achieving load balance while minimizing interprocessor communication and redistribution costs is a difficult problem. Traditional dynamic load balancers are mostly inadequate because they lack a global view of system loads across processors. In this paper, we propose a novel and general-purpose load balancer that utilizes symmetric broadcast networks (SBN) as the underlying communication topology, and compare its performance with a successful global load balancing environment, called PLUM, specifically created to handle adaptive unstructured applications. Our experimental results on an IBM SP 2 demonstrate that the SBN-based load balancer achieves lower redistribution costs than that under PLUM by <b>overlapping</b> <b>processing</b> and data migration...|$|E
40|$|Abstract. In this paper, we {{show how}} to fully exploit the {{capabilities}} of high– end SGI graphics and parallel machines to perform radiosity computations on scenes made of complex shapes both quickly and accurately. <b>Overlapping</b> multi– <b>processing</b> and multi–pipeline graphics accelerations on one hand, and incorporating recent research works on wavelet radiosity on the other hand, allows radiosity to become a practical tool for interactive design. ...|$|R
5000|$|Pericutaneous space: The space {{just outside}} our bodies but {{which might be}} near to {{touching}} it. Visual-tactile perceptive fields <b>overlap</b> in <b>processing</b> this space. For example, an individual might see a feather as not touching their skin but still experience the sensation of being tickled when it hovers just above their hand. Other examples include the blowing of wind, gusts of air, and the passage of heat.|$|R
40|$|Abstract – The fully {{parallel}} LDPC decoding architecture {{can achieve}} high decoding throughput, but it suffers from large hardware complexity {{caused by a}} large {{set of processing units}} and complex interconnections. A practical solution to achieve area-efficient decoders is to use the folded architecture in which a PU is time-multiplexed for several row or column operations. In the folded architecture, the rows or columns to be processed in a PU and their processing order should be carefully determined by analyzing their dependencies among rows and columns to enable <b>overlapped</b> <b>processing</b> that leads to increased performance. Finding an optimum grouping of rows and columns for each PU, however, takes considerable amount of time, since the number of rows and columns can be several thousands. This paper proposes an efficient scheduling algorithm that can be applied to general LDPC codes, which is based on the concept of the matrix permutation. Experimental results show that the proposed scheduling achieves a reduction of 36. 7 % processing time, on the average, for various LDPC codes, leading to a higher decoding rate...|$|R
40|$|The {{possible}} {{transfer of}} musical expertise to {{the acquisition of}} syntactical structures in first and second language has emerged recently as an intriguing topic in the research of cognitive processes. However, {{it is unlikely that}} the benefits of musical training extend equally to the acquisition of all syntactical structures. As cognitive transfer presumably requires <b>overlapping</b> <b>processing</b> components and brain regions involved in these processing components, one can surmise that transfer between musical ability and syntax acquisition would be limited to structural elements that are shared between the two. We propose that musical expertise transfers only to the processing of recursive long-distance dependencies inherent in hierarchical syntactic structures. In this study, we taught fifty-six participants with widely varying degrees of musical expertise the artificial language BROCANTO, which allows the direct comparison of long-distance and local dependencies. We found that the quantity of musical training (measured in accumulated hours of practice and instruction) explained unique variance in performance in the long-distance dependency condition only. These data suggest that musical training facilitates the acquisition specifically of hierarchical syntactic structures...|$|E
40|$|The {{objective}} {{of this study was}} to discuss the main controversies for cerebral representation of faces, considering the concepts of complex neurofunctional system. Recently neuroscientists have long puzzled over whether the brain represents and processes information in a modular or distributed fashion. Some studies point to neural modules specialized in faces perception, because some cortical areas show increased blood flow when the subjects views images of faces, compared with images of objects. On the other hand, some authors believe that the representation of faces is not located specifically in a cortical area, but it is based on a distributed and overlapping pattern of neural response. Neither extreme is likely to be correct when it is considered the modular and distributed theory. It would be appropriate to point for intermediate positions. It was concluded that the representation of faces occurs through cerebral areas interconnected, with serial and parallel processing of the information. There is a distributed and <b>overlapping</b> <b>processing,</b> in which several areas contribute to face representation; however there are specialized cerebral areas that respond with larger effectiveness to images of face...|$|E
40|$|Abstract {{copyright}} {{data collection}} owner. This research investigates how differences in dyslexic and non-dyslexic readers' fluency {{are related to}} differences in how they process multiple items. When people read, they typically have to process multiple items (eg, letters within words). Research has shown that non-dyslexic readers are more fluent when reading or naming objects aloud when they are presented {{with more than one}} item (word or letter) at a time than when items are presented individually, suggesting that they process multiple consecutive items simultaneously. In contrast, dyslexic readers are less fluent when presented with more than one item. This research investigates why this might be so, focusing on three research questions: To what extent does processing for consecutive items overlap? How does such <b>overlapping</b> <b>processing</b> affect fluency? Which specific aspects of multi-item processing are impaired in dyslexia? The research involves recording dyslexic and non-dyslexic readers' eye-movements and voice responses as they name sequences of letters. They investigate whether recognition or retrieval of a letter is influenced by early processing of that letter before it is directly looked at, or by explicit processing once it is directly looked at. They also investigate whether processing is affected by cumulative early and later exposure to a letter...|$|E
40|$|In this paper, {{filter bank}} based {{multicarrier}} systems using fast convolution approach are investigated. We show that exploiting offset quadrature amplitude modulation {{enables us to}} perform FFT/IFFT based convolution without <b>overlapped</b> <b>processing</b> and the circular distortion can be discarded {{as a part of}} orthogonal interference terms. This property has two advantages. Firstly, it leads to spectral efficiency enhancement in the system by removing the prototype filter transients. Secondly, the complexity of the system is significantly reduced due to using efficient FFT algorithms for convolution. The new scheme is compared with the conventional waveforms in terms of out of band radiation, orthogonality, spectral efficiency and complexity. The performance of the receiver and the equalization methods are investigated and compared with other waveforms through simulations. Moreover, based on the time variant nature of the filter response of the proposed scheme, a pilot based channel estimation technique with controlled transmit power is developed and analysed through lower bound derivations. The proposed transceiver is shown to be a competitive solution for future wireless networks...|$|R
40|$|The {{performance}} of parallel programs is significantly {{affected by the}} organization of communications and the direct affects of hardware architecture and constraints. Use of the standard MPI libraries often fails to give the best performance. This work describes and evaluates a variety of performance enhancements that are generally applicable to any parallel programming project. Manually tuning communications and packing/unpacking data with regard to specific hardware characteristics is shown to be superior to default MPI performance within certain constraints. <b>Overlapping</b> communications with <b>processing</b> is demonstrated {{and the application of}} threading to consume idle time is described. Memory contention and its effects on <b>overlapping</b> communications and <b>processing</b> is evaluated. 1...|$|R
40|$|Abstract—Recently {{significant}} {{progress has been}} made on point-to-point underwater acoustic communications, and the interest has grown on the application of those techniques in multiuser communication settings, where the asynchronous nature of multiuser communication poses a grand challenge. This paper develops a time-asynchronous multiuser reception approach for orthogonal frequency-division multiplexing (OFDM) transmissions in underwater acoustic channels. The received data burst is segmented and apportioned to multiple processing units in an overlapped fashion, where the length of the processing unit depends on the maximum asynchronism among users on the OFDM block level. Interference cancellation is adopted to reduce the interblock interference between <b>overlapped</b> <b>processing</b> units. Within each processing unit, the residual inter-block interference from multiple users is aggregated as one external interference which can be parameterized. Multiuser channel estimation, data detection, and interference mitigation are then carried out in an iterative fashion. Simulation and emulated experimental results demonstrate the robustness of the proposed receiver with signal asynchronism among multiple users in both time-invariant and time-varying environments. It is observed that the receiver decoding performance degrades as the channel time variation and the maximum relative delay among users increase. Index Terms—Asynchronous multiuser communications, OFDM, underwater acoustic channels, overlapped truncation, interference aggregation I...|$|R
40|$|Although {{a crucial}} role of the {{fusiform}} gyrus in face processing has been demonstrated {{with a variety of}} methods, converging evidence suggests that face processing involves an interactive and <b>overlapping</b> <b>processing</b> cascade in distributed brain areas. Here we examine the spatio-temporal stages and their functional tuning to face inversion, presence and configuration of inner features, and face contour in healthy subjects during passive viewing. Anatomically-constrained magnetoencephalography (aMEG) combines high-density whole-head MEG recordings and distributed source modeling with high-resolution structural MRI. Each person's reconstructed cortical surface served to constrain noise-normalized minimum norm inverse source estimates. The earliest activity was estimated to the occipital cortex at ~ 100 ms after stimulus onset and was sensitive to an initial coarse level visual analysis. Activity in the right-lateralized ventral temporal area (inclusive of the fusiform gyrus) peaked at ~ 160 ms and was largest to inverted faces. Images containing facial features in the veridical and rearranged configuration irrespective of the facial outline elicited intermediate level activity. The M 160 stage may provide structural representations necessary for downstream distributed areas to process identity and emotional expression. However, inverted faces additionally engaged the left ventral temporal area at ~ 180 ms and were uniquely subserved by bilateral processing. This observation is consistent with the dual route model and spared processing of inverted faces in prosopagnosia. The subsequent deflection, peaking at ~ 240 ms in the anterior temporal areas bilaterally, was largest to normal, upright faces. It may reflect initial engagement of the distributed network subserving individuation and familiarity. These results support dynamic models suggesting that processing of unfamiliar faces {{in the absence of a}} cognitive task is subserved by a distributed and interactive neural circuit...|$|E
40|$|The paper {{describes}} {{the change from}} molecular genetics to postgenomic biology. It focuses on phenomena in the regulation of gene expression that provide a break with the central dogma, according to which sequence specificity for a gene product must be template derived. In its place we find what is called here ‘constitutive molecular epigenesis’. Its three classes of phenomena, which I call sequence ‘activation’, ‘selection’ and ‘creation’, are exemplified by processes such as transcriptional activation, alternative cis- and trans-splicing, and RNA editing. These phenomena support the following main theses of the paper: 1. Other molecular resources share the causal role of ‘genes’: the ‘causal specificity’ for the linear sequence of any gene product is distributed between the coding sequence, cis-acting sequences, trans-acting factors, environmental signals, and the contingent history of the cell (the cellular code) (thesis of distributed causal specificity). 2. These multiple and <b>overlapping</b> <b>processing</b> and targeting mechanisms amplify the repertoire of RNA and protein products specified through the eukaryotic genome, expanding the possibilities specified by the literal code of DNA (thesis of genetic underdeterminism). 3. These mechanisms of gene expression change the focus of postgenomic research from single molecules and their molecular, biochemical and intrinsic function to their cellular, constituent, component or contextual function due to their recruitment and organization in complex cellular networks. In other words, all agents involved in the regulation of gene expression, including DNA, must interact with other agents to achieve full specificity, which is imposed by regulated recruitment and combinatorial control (theses of regulated recruitment and of system analysis). I conclude from these three main theses that the complexity of higher organisms lies not in its number of genes but in the flexibility, versatility and reactivity of its whole genome...|$|E
40|$|Working memory (WM) {{capacity}} – {{the ability}} to store and process information in primary memory – is a core ability that is central to most human behavior. Theoretical characterizations of WM capacity aim to identify the cognitive constructs that underlie this ability and to explain the close relationship between WM and short-term memory (STM). These characterizations are heavily based on behavioral research {{within the field of}} cognitive psychology. A relatively unexplored method that may provide {{a deeper understanding of the}} cognitive constructs that underlie WM is the use of a twin design. Twin designs allow for more detailed examination of underlying processing in that common and unique variance across constructs can be further decomposed into variance that is driven by the same or distinct sets of genes or the same or distinct environmental factors. This dissertation contributes to existing theories of WM in three ways: 1) The first aim was to determine whether existing research suggests that genes more strongly influence individual differences in WM task performance than STM task performance. Results of the meta-analysis revealed a tendency for WM tasks to be more heritable than STM tasks. 2) The second aim was to determine whether WM and STM constructs are distinguishable by decomposing their relationship into candidate cognitive subprocesses - attention control (AC) and long-term memory (LTM) - and then further decomposing those findings into genetic and environmental influences. The majority of the overlapping variance between WM and STM also covaried with AC and was almost entirely genetic in nature. 3) The final aim evaluated how much of the WM-intelligence relationship can be accounted for via mediation with the candidate cognitive constructs from Aim 2 and then determines the extent to which genes versus environmental factors are contributing to that relationship. AC and LTM significantly mediated the WM-intelligence relationship and STM played a negligible role. The genetic models revealed that the majority of <b>overlapping</b> <b>processing</b> for WM and intelligence was driven by genetics, which was mainly due to overlap with AC and only minimally due to STM...|$|E
40|$|The {{effect of}} {{aircraft}} acceleration on acoustic signals is often ignored in both analytical studies and data reduction of flight test measurements. In this study, {{the influence of}} source acceleration on acoustic signals is analyzed using computer simulated signals for an accelerating point source. Both rotating and translating sources are considered. Using a known signal allows {{an assessment of the}} influence of source acceleration on the received signal. Aircraft acceleration must also be considered in the measurement and reduction of flyover noise. Tracking of the aircraft over an array of microphones enables ensemble averaging of the acoustic signal, thus increasing the confidence in the measured data. This is only valid when both the altitude and velocity remain constant. For an accelerating aircraft, each microphone is exposed to differing flight velocities, Doppler shifts, and smear angles. Thus, averaging across the array in the normal manner is constrained by aircraft acceleration and microphone spacing. In this study computer simulated spectra, containing acceleration, are averaged across a 12 microphone array mimicking a flight test with accelerated profile in which noise data was obtained. <b>Overlapped</b> <b>processing</b> is performed is performed in the flight test measurements in order to alleviate spectral smearing...|$|R
50|$|In {{the domain}} of {{prospective}} memory, task appropriate processing refers to the <b>overlap</b> between <b>processing</b> operations required to perform an ongoing task and the processing operations required to perform the prospective memory task. Task appropriate processing {{is characterized by a}} concurrent overlap that occurs within the test phase of a prospective memory test. Prospective memory tasks also provide the opportunity for sequential overlap between the learning and test phase. This can be considered as similar to transfer-appropriate processing in retrospective memory.|$|R
30|$|Although, the GPU {{version of}} the 3 D-LTW encoder has been speeded up to 3.2 times, now, the {{bottleneck}} in the global encoder is the coding stage after computing the 3 D-DWT transform, specially at low compression rates, where {{there are lots of}} significant coefficients to encode. Several strategies could be performed in order to speed up even more the proposed encoder, like overlapping both GPU computation and memory transfer times, <b>overlapping</b> CPU <b>processing</b> times with GPU processing time, or using several GPUs to compute multiple 3 D wavelet transforms from different GOPs.|$|R
40|$|This paper {{considers}} {{the removal of}} moire patterns, which may appear during film-to-video transfer using Telecine devices. A model of moire distortion is created and studied. A new suppression algorithm using spectral analysis is presented and applied for real video sequences. This non-linear filter is based on thresholding {{of the magnitude of}} the Fourier spectrum of the image. The paper also {{considers the}} use of <b>overlapped</b> block <b>processing</b> {{in order to reduce the}} e#ect of ringing artefacts that could appear due to the non-stationarity of the moire pattern...|$|R
40|$|The {{application}} of diode pumped {{solid state laser}} radiation for producing three dimensional microstructures is {{of great interest to}} materials, which are difficult to structure by conventional machining methods. For obtaining controlled processing and processing results the material removal, the available precision and roughness must be determined. Strategies that permit an efficient manufacturing of structures smaller than 100 mu m in ceramics and hard metals are developed. The influence of repetition rate, pulse energy, <b>overlap</b> and <b>processing</b> gas atmosphere on material removal, roughness, geometry and recast layer are discussed...|$|R
50|$|From this facts {{it can be}} {{reasoned}} that the ERAN relies on neural resources related to syntactic processing (Koelsch 2008). Furthermore, they give strong evidence for the thesis, {{that there is an}} <b>overlap</b> between the <b>processing</b> of musical and linguistic syntax and therefore that syntactic operations (musical as well as linguistic) are modular.|$|R
40|$|This paper {{presents}} {{the design and}} performance of remote disk drivers for clusters of Commodity-Off-The-Shelf PCs that fetch disk blocks over System Area Networks. The driver offers a flexible interface, being capable to logically act either as computer- or network-attached storage. It allows for fine-grain remote cache control through exclusive caching. An event-driven asynchronous block delivery mode of operation helps making {{the most out of}} the available parallelism by <b>overlapping</b> request <b>processing</b> with block delivery at both involved nodes and thus yielding better performance than local disks. The driver has been implemented as a Linux kernel module...|$|R
40|$|Prospective memory (ProM) is {{the ability}} to {{remember}} and carry out a planned intention in the future. ProM performance can be improved by instructing participants to prioritize the ProM task over the ongoing task. However, the improvement of ProM performance by emphasizing the relative importance typically restricted to situations in which the <b>overlap</b> between <b>processing</b> requirements of the ProM task and the ongoing task is low. Thus, additional processing resources are allocated to the ProM task and consequently, a cost emerges for the ongoing task. The aim {{of the present study was}} to further investigate this relationship. Participants were asked to respond to either semantic or perceptual ProM cues, which were embedded in a complex ongoing short term memory task. We manipulated absolute rather than relative importance by emphasizing the importance of the ProM task to half of the participants (i. e., without instructing them to prioritize it over the ongoing task). The results revealed that importance boosted ProM performance independent of the <b>processing</b> <b>overlap</b> between the ProM task and the ongoing task. Moreover, no additional cost was associated with absolute importance. These results challenge the view that importance always enhances the allocation of resources to the ProM task...|$|R
40|$|Abstract—Spatial {{processing}} of sparse, irregular floating-point computation using a single FPGA enables {{up to an}} order of magnitude speedup (mean 2. 8 × speedup) over a conventional microprocessor for the SPICE circuit simulator. We decompose SPICE into its three constituent phases: Model-Evaluation, Sparse Matrix-Solve, and Iteration Control and parallelize each phase independently. We exploit data-parallel device evaluations in the Model-Evaluation phase, sparse dataflow parallelism in the Sparse Matrix-Solve phase and compose the complete design including the Iteration Control phase in a streaming fashion. We program the parallel architecture with a high-level, domain-specific framework that identifies, exposes and exploits parallelism available in the SPICE circuit simulator. Our design is optimized with an auto-tuner that can scale the design to use larger FPGA capacities without expert intervention and can even target other parallel architectures with the assistance of automated code-generation. This FPGA architecture is able to outperform conventional processors due to a combination of factors including high utilization of statically-scheduled resources, low-overhead dataflow scheduling of fine-grained tasks, and <b>overlapped</b> <b>processing</b> of the control algorithms. We demonstrate that we can independently accelerate Model-Evaluation by a mean factor of 6. 5 ×(1. 4 – 23 ×) across a range of non-linear device models and Matrix-Solve by 2. 4 ×(0. 6 – 13 ×) across various benchmark matrices while delivering a mean combined speedup of 2. 8 ×(0. 2 – 11 ×) for the composite design when comparing a Xilinx Virtex- 6 LX 760 (40 nm) with an Intel Core i 7 965 (45 nm). With our high-level framework, we can also accelerate Single...|$|R
