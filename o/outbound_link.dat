10|65|Public
2500|$|In other words, the PageRank conferred by an <b>{{outbound}}</b> <b>link</b> {{is equal}} to the document's own PageRank score divided by the number of outbound links L( [...] ).|$|E
50|$|Most packet {{switched}} networks use store-and-forward transmission at {{the input of}} the link. A switch using store-and-forward transmission will receive (save) the entire packet to the buffer and check it for CRC errors or other problems before sending the first bit of the packet into the <b>outbound</b> <b>link.</b> Thus, store-and-forward packet switches introduce a store-and-forward delay at the input to each link along the packet's route.|$|E
5000|$|Store {{and forward}} {{networks}} predate {{the use of}} computers. Point-to-point teleprinter equipment was used to send messages which were stored at the receiving end on punched paper tape at a relay center. A human operator at the center removed the message tape from the receiving machine, read the addressing information, and then sent it toward its destination on appropriate outbound point-to-point teleprinter link. If the <b>outbound</b> <b>link</b> was in use, the operator placed the message in tape in a physical queue, usually consisting {{of a set of}} clips or hooks. A major relay center in the mid 1900s might have dozens of inbound and outbound teleprinters, scores of operators, and thousands of messages in the queues during peak periods. Operators referred to these centers as [...] "torn-tape relay centers," [...] a reference to removing the received message from the inbound teleprinter by tearing the paper tape to separate one message from the next. The U.S. military term for such a center was [...] "Non-Automated Relay Center" [...] (NARC).|$|E
50|$|<b>Outbound</b> <b>links</b> allows webmasters {{to see the}} <b>outbound</b> <b>links</b> Bing sees.|$|R
25|$|The PageRank {{transferred}} from a given page to {{the targets of}} its <b>outbound</b> <b>links</b> upon the next iteration is divided equally among all <b>outbound</b> <b>links.</b>|$|R
5000|$|... #Subtitle level 2: Inbound <b>links,</b> <b>outbound</b> <b>links,</b> {{internal}} links ...|$|R
40|$|Abstract — Time {{division}} {{multiple access}} (TDMA) based medium access control (MAC) protocols can provide QoS with guaranteed access to wireless channel. However, in multi-hop wireless networks, these protocols may introduce delay when packets are forwarded from an inbound link to an <b>outbound</b> <b>link</b> on a node. Delay occurs if the <b>outbound</b> <b>link</b> is scheduled to transmit before the inbound link. The total round trip delay can be quite large since it accumulates at every hop in the path. This paper presents a method that finds schedules with minimum round trip scheduling delay. We show that the scheduling delay {{can be interpreted as}} a cost collected over a cycle on the conflict graph. We use this observation to formulate a min-max program for the delay across a set of multiple paths. The min-max delay program is NPcomplete since the transmission order of links is a vector of binary integer variables. We design heuristics to select appropriate transmission orders. Once the transmission orders are known, a modified Bellman-Ford algorithm finds the schedules. The simulation results confirm that the proposed algorithm can find effective min-max delay schedules...|$|E
40|$|Wavelength-convertible switch {{architecture}} and routing algorithm for circuit-switched wavelength-division multiplexing optical networks is studied in this paper. Wavelength converters {{are used to}} resolve wavelength conflicts and to reuse wavelengths. These converters are not dedicated to individual channels, but are shared by the channels of a node or those of an <b>outbound</b> <b>link</b> in the share-per-node or the share-per-link wavelength-convertible switch, respectively. A routing algorithm is developed to conserve wavelength converters while maintaining performance close {{to that of a}} network with abundant converters. We find that converters can improve the network performance such as the blocking probability and fairness considerably. link_to_subscribed_fulltex...|$|E
40|$|In {{a network}} of pages (the web), {{outbound}} and inbound links are the only connecting flow making the vertexes; while the pages represent the edges as is found on directed graphs. The ranking of a page is dependent on its content {{and the number of}} inbound links which are recommendations to the page. Contrary, an <b>outbound</b> <b>link</b> demotes the page. If the Home page (target page) is "good", then there is a flow of Page Rank booster out of it. In this work, we introduced the TrustRank (TrustRank = M- 1 * X) method to become the start process of the Page Rank method (M * PageRank = (1 - d)), since the basic idea is, taking the link structure to generate a measure for the quality of a page by the selection of good (trusted) pages for a start (by hand). These pages are the sources of trust. Trust can be transferred to other page by linking to them. Trust is propagated {{in the same way as}} PageRank from thence. Ranked result from this point would be better than those not guided by the "trusted selections"...|$|E
5000|$|Inbound and <b>outbound</b> <b>links</b> {{are those}} that {{hyperlink}} two independent web pages together whereas inbound links would hyperlink domain “A” to domain “B” and <b>outbound</b> <b>links</b> would hyperlink domain “B” to domain “A.” ...|$|R
3000|$|Within the PageRank algorithm, the PageRank of a page T {{is always}} {{weighted}} {{by the number}} of <b>outbound</b> <b>links</b> C [...]...|$|R
3000|$|... is {{selected}} {{from all the}} <b>outbound</b> <b>links</b> of node i, and its corresponding flow {{is selected}} as the best candidate flow.|$|R
40|$|Time {{division}} {{multiple access}} (TDMA) based medium access control (MAC) protocols can provide QoS with guaranteed access to the wireless channel. However, in multihop wireless networks, these protocols may introduce scheduling delay if, on the same path, an <b>outbound</b> <b>link</b> on a router is scheduled to transmit before an inbound link on that router. The total scheduling delay can be quite large since it accumulates at every hop on a path. This paper presents a method that finds conflict-free TDMA schedules with minimum scheduling delay. We show that the scheduling delay {{can be interpreted as}} a cost, in terms of transmission order of the links, collected over a cycle in the conflict graph. We use this observation to formulate an optimization, which finds a transmission order with the minmax delay across a set of multiple paths. The min-max delay optimization is NP-complete since the transmission order of links is a vector of binary integer variables. We devise an algorithm that finds the transmission order with the minimum delay on overlay tree topologies and use it with a modified Bellman-Ford algorithm, to find minimum delay schedules in polynomial time. The simulation results in 802. 16 mesh networks confirm that the proposed algorithm can find effective min-max delay schedules...|$|E
40|$|Abstract—Time {{division}} {{multiple access}} (TDMA) based medium access control (MAC) protocols can provide QoS with guaranteed access to the wireless channel. However, in multi-hop wireless networks, these protocols may introduce scheduling delay if, on the same path, an <b>outbound</b> <b>link</b> on a router is scheduled to transmit before an inbound link on that router. The total scheduling delay can be quite large since it accumulates at every hop on a path. This paper presents a method that finds conflict-free TDMA schedules with minimum scheduling delay. We show that the scheduling delay {{can be interpreted as}} a cost, in terms of transmission order of the links, collected over a cycle in the conflict graph. We use this observation to formulate an optimization, which finds a transmission order with the min-max delay across a set of multiple paths. The min-max delay optimization is NP-complete since the transmission order of links is a vector of binary integer variables. We devise an algorithm that finds the transmission order with the minimum delay on overlay tree topologies and use it with a modified Bellman–Ford algorithm, to find minimum delay schedules in polynomial time. The simulation results in 802. 16 mesh networks confirm that the proposed algorithm can find effective min-max delay schedules. Index Terms—Scheduling delay, stop-and-go queueing, TDMA scheduling algorithms. I...|$|E
40|$|Tenants in datacenters desire {{performance}} {{isolation from}} each other. Such isolation {{for the network}} {{has been difficult to}} achieve without sacrificing utilization. This paper presents a set of techniques that together could achieve such isolation without requiring hardware changes in switches. The system is evaluated on a testbed of Fulcrum switches. The techniques employed are as follows. On each switch, on each <b>outbound</b> <b>link,</b> a separate DRR queue is configured for each class of service. Tenants are clustered into these classes, and the weight of each class is the sum of the weights of the tenants. These weights are assigned by an operator when a tenant is provisioned. The traffic for each tenant is labeled so that it lands in the right queue. To handle UDP, each host needs a rate throttling shim. A centralized bandwidth allocator measures the rates of flows and then decides on new rates that are enforced using token bucket rate limiters at hosts or ingress switch ports. There is a lot to absorb in this paper and the reviewers craved more details. One reviewer was concerned about how the system scales down to a small number of tenants because of a potential for bandwidth stealing, or how it scales to fast churn in tenants. Another was more concerned about the speed with which switch configurations could be updated. All the reviewers liked the paper. It is timely and the topic is important. The implementation on Fulcrum switches impressed them. A general question worth pondering is what type of isolation the datacenter operator wants to offer, and what type tenants desire, and are those two in conflict? I suspect that one wants to offer proportional sharing of bandwidth, while the other wants minimum guaranteed bandwidths. s i g c o m m Public review written b...|$|E
5000|$|Inbound and <b>outbound</b> <b>links</b> are {{essential}} to web page visibility often enhancing web page relevance, ranking, & placement. There are few instances where inbound links would be discouraged. <b>Outbound</b> <b>links</b> however should be given sparingly and should only link material to other material of same or similar relevance. Often, developers will utilize a nofollow tag used mostly to further optimize hyperlinks by “instructing” search engines not to distribute any PageRank from the hyperlink. An example of a nofollow tag might be: ...|$|R
2500|$|... where [...] are {{the pages}} under consideration, [...] is {{the set of}} pages that link to , [...] {{is the number of}} <b>outbound</b> <b>links</b> on page , and [...] is the total number of pages.|$|R
40|$|This paper {{evaluates the}} {{effectiveness}} of some “unofficial” factors in Search Engine Optimisation. A summary of official Google guidelines is given followed by a review of “unofficial” ranking factors as reported {{by a number of}} experts in the field of Search Engine Optimisation”. These opinions vary and do not always agree. Experiments on keyword density, web page titles and the use of <b>outbound</b> <b>links</b> were conducted to investigate the expert’s hypotheses by analysing Google result pages. The results demonstrate that webmasters should avoid having unnecessary <b>outbound</b> <b>links,</b> while attempting to repeat the important keywords of each page one time in their titles, to increase the pages ranking in the results page...|$|R
30|$|In general, {{the local}} and global {{performances}} are aligned. In the studied scenario, {{this does not mean}} that a link manager should set a price to become very attractive in order to a high number of vehicles try to use it, because in this case, this could create jams near the exit of its link. This would congest the link itself, because if cars are not able to exit the link, a queue is created and this would reduce traffic flow and the reward of the link, as well as decrease the global performance. Rather, the alignment of {{the local and}} global performances means that the increase of traffic flow on a link depends on the capacity of its <b>outbound</b> <b>links</b> to receive this flow. With the proposed reinforcement learning scheme, link managers could figure out which price would result in an attractiveness for drivers that generates a traffic flow that its <b>outbound</b> <b>links</b> could handle. These <b>outbound</b> <b>links,</b> on their turn, had to adjust their prices to disperse the drivers they are receiving in an efficient way. This is done without an explicit coordination mechanism.|$|R
25|$|In Bosley Medical Institute, Inc. v. Kremer, 403 F.3d 672 (9th Cir. 2005), the Ninth Circuit looked {{not just}} at {{the nature of a}} {{potentially}} infringing webpage, but also the nature of the <b>outbound</b> <b>links</b> from the page, before determining that there was not a use in commerce.|$|R
2500|$|... where [...] is {{the number}} of neighbors of node [...] (or number of <b>outbound</b> <b>links</b> in a {{directed}} graph). Compared to eigenvector centrality and Katz centrality, one major difference is the scaling factor [...] Another difference between PageRank and eigenvector centrality is that the PageRank vector is a left hand eigenvector (note the factor [...] has indices reversed).|$|R
50|$|However, {{the link}} farms became {{susceptible}} to manipulation by unscrupulous webmasters {{who joined the}} services, received inbound linkage, and then found ways to hide their <b>outbound</b> <b>links</b> or to avoid posting any links on their sites at all. Link farm managers had to implement quality controls and monitor member compliance with their rules to ensure fairness.|$|R
5000|$|PageRank {{satisfies}} the following equation where [...] {{is the number}} of neighbors of node [...] (or number of <b>outbound</b> <b>links</b> in a directed graph). Compared to eigenvector centrality and Katz centrality, one major difference is the scaling factor [...] Another difference between PageRank and eigenvector centrality is that the PageRank vector is a left hand eigenvector (note the factor [...] has indices reversed).|$|R
2500|$|... which {{discusses}} {{the use of}} a number of different importance metrics to determine how deeply, and how much of a site Google will crawl. PageRank is presented as {{one of a number of}} these importance metrics, though there are others listed such as the number of inbound and <b>outbound</b> <b>links</b> for a URL, and the distance from the root directory on a site to the URL.|$|R
25|$|When calculating PageRank, {{pages with}} no <b>outbound</b> <b>links</b> {{are assumed to}} link out to all other pages in the collection. Their PageRank scores are {{therefore}} divided evenly among all other pages. In other words, to be fair with pages that are not sinks, these random transitions are added to all nodes in the Web, with a residual probability usually set to d = 0.85, estimated from the frequency that an average surfer uses his or her browser's bookmark feature.|$|R
40|$|Table of {{contents}} includes: ILL Policies; Passport for Cataloging Extended!; New Sets Available in OCLC WorldCat Collections Sets; DDC 22 and WebDewey; New! Create ILL Requests in FirstSearch; Recommended ILL Web Browser Settings; FirstSearch Adds <b>Outbound</b> <b>Linking</b> to CISTI for Document Delivery; Wilson Select Plus Database Enhanced with Images, New Indexes; Wilson Select Database Discontinued; More Databases Available for Inbound Linking to Full Text; Additional Content in Chemical Abstracts Student Edition; 51 Journals Added to OCLC FirstSearch Electronic Collections Online...|$|R
5000|$|In {{an effort}} to capture as many MUs as possible, {{additional}} fields can be created that blanket other fields. This is called layering, and each subsequent field that is created [...] "recaptures" [...] the MUs from the previous field(s), adding to the count. Layering is most often accomplished by utilizing one or two common portals, called anchors, to host inbound and <b>outbound</b> <b>links</b> and using a unique portal(s) each time to create each additional layered field. Periodically, faction members will coordinate large-scale layered fields that span multiple countries.|$|R
40|$|AbstractSearch Engine Optimization (SEO) is a {{collection}} of techniques that allow a site to get more traffic from search engines. Page Ranking is the fundamental concept of SEO and defines as a weighted number that represent the relative importance of the page {{based on the number of}} inbound and <b>outbound</b> <b>links.</b> In this paper, I proposed a new type of web page search which is based on the competitive intelligence. It use link-based ranking evolutionary scheme to accommodate users’ preferences. I implemented the prototype system and demonstrate the feasibility of the proposed web page search scheme...|$|R
40|$|Presentation {{given on}} November 14, 2012 at the Indiana Library Federation Annual Conference in Indianapolis, Indiana. This {{presentation}} provides a general overview of Google Analytics. Major topics covered include {{setting up an}} account, installing the Google Analytics Tracking Code, and creating filters and profiles. Learn how to navigate the Google Analytics interface and interpret metrics and reports to understand website usage patterns, visitor characteristics, and sources of site traffic. More advanced features, such as tracking <b>outbound</b> <b>links,</b> document downloads (. doc,. pdf, etc.), and social engagement are also covered. Emphasis is placed on establishing goals and identifying key performance indicators (KPIs) to generate actionable insights and strategies for website improvement...|$|R
50|$|Suppose {{instead that}} page B had {{a link to}} pages C and A, page C had a link to page A, and page D had links to all three pages. Thus, upon the first iteration, page B would {{transfer}} half of its existing value, or 0.125, to page A and the other half, or 0.125, to page C. Page C would transfer all of its existing value, 0.25, to the only page it links to, A. Since D had three <b>outbound</b> <b>links,</b> it would transfer one third of its existing value, or approximately 0.083, to A. At the completion of this iteration, page A will have a PageRank of approximately 0.458.|$|R
5000|$|In September 2014, Google {{targeted}} {{private blog}} networks (PBNs) with manual action ranking penalties. [...] This served to dissuade search engine optimization and online marketers from using PBNs {{to increase their}} online rankings. The [...] "thin content" [...] warnings are closely tied to [...] Panda which focuses on thin content and on-page quality. PBNs {{have a history of}} being targeted by Google and therefore may not be the safest option. Since Google is on the search for blog networks, they are not always linked together. In fact, interlinking your blogs could help Google and a single exposed blog could reveal the whole blog network by looking at the <b>outbound</b> <b>links.</b>|$|R
25|$|Assume a small {{universe}} of four web pages: A, B, C and D. Links from a page to itself, or multiple <b>outbound</b> <b>links</b> from one single {{page to another}} single page, are ignored. PageRank is initialized to the same value for all pages. In the original form of PageRank, the sum of PageRank over all pages was {{the total number of}} pages on the web at that time, so each page in this example would have an initial value of 1. However, later versions of PageRank, and the remainder of this section, assume a probability distribution between 0 and 1. Hence the initial value for each page in this example is 0.25.|$|R
2500|$|Suppose {{instead that}} page B had {{a link to}} pages C and A, page C had a link to page A, and page D had links to all three pages. Thus, upon the first iteration, page B would {{transfer}} half of its existing value, or 0.125, to page A and the other half, or 0.125, to page C. [...] Page C would transfer all of its existing value, 0.25, to the only page it links to, A. Since D had three <b>outbound</b> <b>links,</b> it would transfer one third of its existing value, or approximately 0.083, to A. [...] At the completion of this iteration, page A will have a PageRank of approximately 0.458.|$|R
50|$|A Web crawler may use PageRank {{as one of}} {{a number}} of {{importance}} metrics it uses to determine which URL to visit during a crawl of the web. One of the early working papers that were used in the creation of Google is Efficient crawling through URL ordering,which discusses the use of a number of different importance metrics to determine how deeply, and how much of a site Google will crawl. PageRank is presented {{as one of a}} number of these importance metrics, though there are others listed such as the number of inbound and <b>outbound</b> <b>links</b> for a URL, and the distance from the root directory on a site to the URL.|$|R
50|$|Assume a small {{universe}} of four web pages: A, B, C and D. Links from a page to itself, or multiple <b>outbound</b> <b>links</b> from one single {{page to another}} single page, are ignored. PageRank is initialized to the same value for all pages. In the original form of PageRank, the sum of PageRank over all pages was {{the total number of}} pages on the web at that time, so each page in this example would have an initial value of 1. However, later versions of PageRank, and the remainder of this section, assume a probability distribution between 0 and 1. Hence the initial value for each page in this example is 0.25.|$|R
40|$|In this paper, we {{investigate}} a specific inter-domain traffic engineering problem: the outbound load balancing in a multi-homed Autonomous System (AS). We present an optimization-based approach for this problem without modifying BGP protocol in any way. In this approach, the load balancing problem is generalized as a black-box optimization problem. The Online Simulation system [1], {{specifically designed for}} this class of problems, {{can be applied to}} adaptively adjust BGP configuration to achieve load balancing. This approach is also very flexible in that other optimization objectives can be used to achieve different TE objectives easily. The simulation results show that the proposed scheme substantially improves the load balancing or packet drop probability at the <b>outbound</b> <b>links</b> of a multi-homed AS...|$|R
