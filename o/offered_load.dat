476|437|Public
5000|$|In the {{mathematical}} theory of probability, <b>offered</b> <b>load</b> {{is a concept}} in queuing theory. The <b>offered</b> <b>load</b> {{is a measure of}} traffic in the queue. The <b>offered</b> <b>load</b> is given by Little's law: the arrival rate into the queue (symbolized with λ) multiplied by the mean holding time (symbolized by τ), the average amount of time spent by items in the queue. <b>Offered</b> <b>load</b> is expressed in Erlang units or call-seconds per hour, a dimensionless measure.|$|E
50|$|The Frame Relay network uses a {{simplified}} protocol at each switching node. It achieves simplicity by omitting link-by-link flow-control. As a result, the <b>offered</b> <b>load</b> has largely determined {{the performance of}} Frame Relay networks. When <b>offered</b> <b>load</b> is high, due to the bursts in some services, temporary overload at some Frame Relay nodes causes a collapse in network throughput. Therefore, Frame Relay networks require some effective mechanisms to control the congestion.|$|E
50|$|Network {{congestion}} {{occurs when}} a link or node is carrying so much data that its quality of service deteriorates. Typical effects include queueing delay, packet loss or the blocking of new connections. A consequence of these latter two is that incremental increases in <b>offered</b> <b>load</b> lead either only to small increase in network throughput, or to an actual reduction in network throughput.|$|E
30|$|For each configuration, we {{vary the}} inter-arrival {{time of the}} flows in source node to have {{different}} <b>offered</b> <b>loads,</b> assuming a constant packet size. With high <b>offered</b> <b>loads,</b> it causes higher packet loss because of the queue full. With low <b>offered</b> <b>loads,</b> it causes {{the increase in the}} average end-to-end delay.|$|R
30|$|The {{dependency}} of Pbn and Pftn on the <b>offered</b> traffic <b>load</b> of SUs, the <b>offered</b> traffic <b>load</b> of RUs, and {{the number}} of reserved channels has been explicitly indicated in (31).|$|R
30|$|Notice that (34) {{explicitly}} {{indicates the}} dependency of Pbn and Pftn on the <b>offered</b> traffic <b>load</b> of the SUs, the <b>offered</b> traffic <b>load</b> of the RUs, {{and the number}} of reserved channels.|$|R
50|$|The erlang (symbol E) is a {{dimensionless}} unit {{that is used}} in telephony {{as a measure of}} <b>offered</b> <b>load</b> or carried load on service-providing elements such as telephone circuits or telephone switching equipment. A single cord circuit has the capacity to be used for 60 minutes in one hour. Full utilization of that capacity, 60 minutes of traffic, constitutes 1 erlang.|$|E
50|$|Network {{congestion}} in {{data networking}} and queueing theory is the reduced {{quality of service}} that occurs when a network node is carrying more data than it can handle. Typical effects include queueing delay, packet loss or the blocking of new connections. A consequence of congestion is that an incremental increase in <b>offered</b> <b>load</b> leads either only to a small increase or even a decrease in network throughput.|$|E
50|$|Massey {{has made}} many {{original}} contributions as a mathematician {{by developing a}} theory of “dynamical queueing systems”. Classical queueing models assumed that calling rates were constant so they could use the static, equilibrium analysis of time homogeneous Markov chains. However, real communication systems call for the large scale analysis of queueing models with time-varying rates. His thesis at Stanford University created a dynamic, asymptotic method for time inhomogeneous Markov chains called “uniform acceleration” {{to deal with such}} problems. Moreover, his research on queueing networks led to new methods of comparing multi-dimensional, Markov processes by viewing them as “stochastic orderings” on “partially ordered spaces”. Finally, one of his most cited papers develops an algorithm to find a dynamic, optimal server staffing schedule for telephone call centers with time varying demand, which led to a patent. Another highly cited paper creates a temporally and spatially dynamic model for the <b>offered</b> <b>load</b> traffic of wireless communication networks.|$|E
30|$|In FF-NDMA, {{the optimal}} R for maximum {{reliability}} {{is provided with}} a large R, since the system can operate {{in a wide range}} of <b>offered</b> <b>loads</b> while maintaining the capture probability at its maximal value.|$|R
40|$|The {{well known}} problem among most random access {{protocols}} in wireless networks {{is that the}} throughput drops rapidly in heavy load. To cope with this problem, one has to control to the <b>load</b> <b>offered</b> to a network. Unlike the traditional backoff policy in Ethernet where backoff occurs after collision, {{in this paper we}} propose various control schemes based on the new idea of resampling, where carrier sensing ability is used to determine whether a backoff command should be issued or not. We show from various experiments that our schemes are capable of controlling the <b>offer</b> <b>load</b> to the optimal <b>offer</b> <b>load.</b> As a result, the throughputs of these schemes are kept close to the network capacity in heavy load. Key words: wireless networks, multiple access, random access, throughput, capacity Corresponding author. E-mail:cschang@ee. nthu. edu. tw. Fax: + 886 - 35 - 715971...|$|R
5000|$|Weatherby rifle {{ammunition}} for the [...]257 Weatherby Magnum is manufactured by Norma of Sweden. Conley Precision Cartridge Company manufactures several premium lines of [...]257 Weatherby ammunition using Barnes, Nosler, Speer, Swift and Trophy Bonded bullets. Double Tap ammunition also <b>offers</b> <b>loaded</b> {{ammunition for}} sale.|$|R
50|$|Slow-start begins {{initially}} with a congestion window size (cwnd) of 1, 2 or 10. The {{value of}} the Congestion Window will be increased by one with each acknowledgement (ACK) received, effectively doubling the window size each round-trip time ("although it is not exactly exponential because the receiver may delay its ACKs, typically sending one ACK for every two segments that it receives"). The transmission rate will be increased with slow-start algorithm until either a loss is detected, or the receiver's advertised window (rwnd) is the limiting factor, or the slow start threshold (ssthresh) is reached. If a loss event occurs, TCP assumes that it is due to network congestion and takes steps to reduce the <b>offered</b> <b>load</b> on the network. These measurements depend on the used TCP congestion avoidance algorithm. Once ssthresh is reached, TCP changes from slow-start algorithm to the linear growth (congestion avoidance) algorithm. At this point, the window is increased by 1 segment for each RTT.|$|E
30|$|In the {{following}} {{we attempt to}} find the maximum carried loads of each link in various scenarios. One observation from solving the system of equations in Section 5.1 is that the carried load will be smaller than the <b>offered</b> <b>load</b> when the <b>offered</b> <b>load</b> is too large. This corresponds to the instability of 802.11 observed in previous works (e.g., [15]). Therefore, we use binary search to find the maximum carried load under stable conditions. Initially, the search range for the <b>offered</b> <b>load</b> is between 0 and 1 [*]Mbps. We choose {{the midpoint of the}} search range to be the <b>offered</b> <b>load</b> and solve the system of equations. If the resultant carried load {{is the same as the}} <b>offered</b> <b>load,</b> the <b>offered</b> <b>load</b> can be increased, and the next search range will be the upper half of the original one. Otherwise, the <b>offered</b> <b>load</b> results in instability, and the next search range will be the lower half of the original one. This procedure is repeated until the search range is sufficiently small.|$|E
40|$|This essay, {{based on}} my 2012 MSOM Fellow Lecture, {{discusses}} an idea that has been useful for developing effective methods to set staffing levels in service systems: <b>offered</b> <b>load</b> analysis. The main idea is to tackle a hard problem by first seeking an insightful simplification. For capacity planning to meet uncertain exogenous demand, <b>offered</b> <b>load</b> analysis looks {{at the amount of}} capacity that would be used if there were no constraints on its availability. This simplification is helpful because the stochastic model becomes much more tractable. <b>Offered</b> <b>load</b> analysis can be especially helpful when the demand is not only uncertain but also time varying, as in many service systems. Given the distribution of the stochastic <b>offered</b> <b>load,</b> we often can set staffing levels to stabilize performance at target levels, even in face of a strongly time-varying arrival rate, long service times, and network structure. Key words: <b>offered</b> <b>load</b> analysis; capacity planning; server staffing; time-varying arrival rates; infinite-server queue...|$|E
5000|$|The {{table below shows}} common {{performance}} parameters for several [...]357 SIG loads. Bullet weights ranging from [...] have been <b>offered.</b> <b>Loads</b> are available with energies from [...] to over , and penetration depths from 9 in to over 16.5 in are available for various applications and risk assessments.|$|R
40|$|Abstract—This report {{presents}} {{work that}} was performed to analyze the behaviour of traffic traversing Powerline adapters. Powerline adapters are networking equipment which modulate network traffic onto electrical wiring to transfer data. These adapters can provide up to 200 Mbps of bandwidth. In our tests, the adapters synchronized between 168 and 193 Mbps (at the physical layer) on average. We tested the adapters with TCP and UDP traffic to observe how they would behave when traffic is sent at varying rates. The TCP file transfer experienced a median RTT between 4 and 24 ms for offered rates from 1 to over 70 Mbps. Uni-directional UDP traffic with <b>offered</b> <b>loads</b> from 1 and 40 Mbps experienced median RTTs between 2 and 16 ms, while <b>offered</b> <b>loads</b> over 40 Mbps led to significant increase in median RTT of almost 2000 ms. I...|$|R
50|$|ICH10 also <b>offers</b> reduced <b>load</b> on CPU and {{decreased}} power consumption.|$|R
40|$|Outlier control, <b>offered</b> <b>load</b> estimation, {{multiple}} access networks. A plethora of broadband and multimedia services {{are making their}} path to our homes, schools and businesses. An emerging shared medium, {{which is expected to}} provide this path consists of a combination of optical fibers and coaxial cables. In such networks, referred to as Hybrid Fiber Coaxial (HFC) cable networks, a contention-based reservation Medium Access Control (MAC) protocol is commonly used for coordinating channel access. In contention-based MAC protocols, it is critical to adaptively allocate contention bandwidth vis-a-vis an <b>offered</b> <b>load</b> that may vary over time. In practice, the <b>offered</b> <b>load</b> is often not known a priori, but may be estimated based on a history of contention outcomes. The accuracy of <b>offered</b> <b>load</b> estimation, which is essential for a reliable contention bandwidth allocation scheme, can be adversely affected by the presence of outliers or inconsistent observations. In this paper, we show that a method for outlier control can be used to enhance the accuracy of an <b>offered</b> <b>load</b> estimator for a framed slotted ALOHA protocol. The method, which employs contention statistics from ternary feedback to selectively discard outliers when the statistics are determined to be unreliable, is applicable to <b>offered</b> <b>load</b> estimation in a DOCSISbased HFC cable network. ...|$|E
30|$|We provide {{simulation}} based {{evidence that}} BFFR outperforms CF regardless whether the STAs are fixed or mobile, at average human walking speed, under different <b>offered</b> <b>load</b> intensities. We {{also show that}} BFFR has advantages over CF, in rigid and when rigid and elastic flows exist in a network, at different <b>offered</b> <b>load</b> intensities.|$|E
40|$|In this paper, we derive {{throughput}} of {{a threshold}} based transmission policy, namely Load-regulated CSMA, {{taking into account}} the propagation delay of the medium and the <b>offered</b> <b>load</b> at different probability of the fading channel. In case of the saturated load regulated CSMA, a trivial relationship between deterministic <b>offered</b> <b>load</b> to the channel at a particular fading channel condition and the maximum possible <b>offered</b> <b>load</b> has been shown. We further extend the load regulation concept into multi-channel domain. Both single and multi-channel load regulated CSMA improves the throughput of the system compared to the existing CSMA system which does not consider channel fading to control the packet transmissions...|$|E
50|$|In {{addition}} LiSiCA PyMOL plugin also <b>offers</b> to <b>load</b> saved results.|$|R
50|$|Nomadix {{produces}} two access gateways which extend {{wired or}} wireless networks for public Internet access: the AG 2400 and the AG 5900. The AG 5900 {{is designed for}} larger venues and supports up to 8,000 devices at a time. The company also <b>offers</b> <b>Load</b> Balancing Module software, which manages network traffic across multiple connections.|$|R
5000|$|... #Caption: Tata Super Ace <b>offers</b> a <b>loading</b> deck {{length of}} 2630 mm.|$|R
30|$|Although our QoS {{provision}} mechanism {{comprises the}} decentralized feature (the EDCA-like distributed QoS channel contention) and centralized feature (the AP-side admission control), {{the degree of}} QoS-differentiation of QoS-Fi is most substantial, {{when compared with the}} other QoS-aware schemes. Moreover, the degree of QoS differentiaion can be flexibly further tuned by varying the parameter settings.By comparing the scenario of moderate <b>offered</b> <b>load</b> and the scenario of high <b>offered</b> <b>load</b> (i.e., Figure  8 a,b versus Figure  8 c,b), the degree of QoS-differentiation of QoS-Fi is larger in high <b>offered</b> <b>load</b> conditions. This is because the MAC layer queue holds the previously untransmitted (by channel contention) packets, until the new higher priority packets arrive at the queue; higher priority packets preempts the lower priority ones, depriving the lower priority packets of the opportunity to participate channel contention. This is more frequent in the high <b>offered</b> <b>load</b> scenarios, resulting in higher degree of QoS-differentiation in the QoS-Fi scheme.|$|E
40|$|In {{this paper}} we study the `service capacity' of {{peer to peer}} (P 2 P) file sharing applications. We begin by {{considering}} a transient regime which is key to capturing the ability of such systems to handle bursty traffic, e. g., flash crowds. In this context our models, based on age dependent branching processes, exhibit exponential growth in service capacity, and permit the study of sensitivity of this growth to system policies and parameters. Then we consider a model for such systems in steady state and show how the average delay seen by peers would scale in the <b>offered</b> <b>load</b> and rate at which peers exit the system. We find that the average delays scale well in the <b>offered</b> <b>load.</b> In particular the delays are upper bounded by some constant given any <b>offered</b> <b>load</b> and even decrease in the <b>offered</b> <b>load</b> if peers exit the system slowly. We validate many of our findings by analyzing traces obtained from a second generation P 2 P application called BitTorrent...|$|E
30|$|System {{performance}} measures obtained {{on the basis}} of 50 simulation runs were plotted {{as a function of the}} <b>offered</b> <b>load.</b>|$|E
50|$|Soundstages are {{equipped}} with full grids from 26 to 45 feet, are column-free, sound-insulated, and <b>offer</b> <b>loading</b> and staging areas. Built to accommodate film, high-definition television (HDTV) and digital camera productions, each stage is wired {{with a minimum of}} 4,800 amps of power and 50 to 200 tons of cooling. Stages are accessed via 13 ft to 20 ft elephant doors.|$|R
40|$|This paper {{addresses}} {{the problem of}} configuring active queue management systems (e. g. WRED and RIO) for service level specifications in Internetworks. In particular, we focus on Assured Forwarding (AF) for non-responsive flows in Differentiated Services networks. The difficulty {{is to determine the}} correct queue level thresholds that will result in correct drop rates for various AF precedence levels under any combination of <b>offered</b> <b>loads...</b>|$|R
50|$|Given Muggs’ {{deep roots}} in the rap scene, the January release of “Bass For Your Face” on dance super-label Ultra Records was both a {{surprise}} and marked change in direction. True to its name, the album does <b>offer</b> <b>loads</b> of low-end, but more than anything else, it’s an exercise in sonic exploration for Muggs. The album meshes sounds from dubstep, glitch, trap and hip-hop into a coherent, innovative whole.|$|R
40|$|The {{effects of}} {{congestion}} {{can be seen}} in Figure 11. 1. As shown in the figure, the throughput of a connection increases as the <b>offered</b> <b>load</b> increases until a point when the queues in the system start to fill up and the increase in throughput levels off. When the <b>offered</b> <b>load</b> becomes too large and the buffers are totally filled up, packets begin to get dropped by the system and throughput starts to decrease...|$|E
3000|$|... as the <b>offered</b> <b>load</b> to the WLAN. Notice {{that the}} Erlang-B formula (6) calculates the {{blocking}} probability with the traffic [...]...|$|E
40|$|Abstract — In {{this paper}} we study the ‘service {{capacity}} ’ of {{peer to peer}} (P 2 P) file sharing applications. We begin by considering a transient regime which is key to capturing the ability of such systems to handle bursty traffic, e. g., flash crowds. In this context our models, based on age dependent branching processes, exhibit exponential growth in service capacity, and permit the study of sensitivity of this growth to system policies and parameters. Then we consider a model for such systems in steady state and show how the average delay seen by peers would scale in the <b>offered</b> <b>load</b> and rate at which peers exit the system. We find that the average delays scale well in the <b>offered</b> <b>load.</b> In particular the delays are upper bounded by some constant given any <b>offered</b> <b>load</b> and even decrease in the <b>offered</b> <b>load</b> if peers exit the system slowly. We validate many of our findings by analyzing traces obtained from a second generation P 2 P application called BitTorrent. Index Terms — system design, network measurements, peer to peer applications, flash crowds, service capacity, performance evaluation, mathematical modeling I...|$|E
40|$|Abstract * ** We {{study the}} effects of RED on the {{performance}} of Web browsing with a novel aspect of our work being the use of a usercentric measure of performance — response time for HTTP request-response pairs. We empirically evaluate RED across a range of parameter settings and <b>offered</b> <b>loads.</b> Our results show that: (1) contrary to expectations, compared to a FIFO queue, RED has a minimal effect on HTTP response times for <b>offered</b> <b>loads</b> up to 90 % of link capacity, (2) response times at loads in this range are not substantially effected by RED parameters, (3) between 90 % and 100 % load, RED can be carefully tuned to yield performance somewhat superior to FIFO, however, response times are quite sensitive to the actual RED parameter values selected, and (4) in such heavily congested networks, RED parameters that provide the best link utilization produce poorer response times. We conclude that for links carrying only web traffic, RED queue management appears to provide no clear advantage over tail-drop FIFO for end-user response times. 1...|$|R
30|$|Network {{performance}} measures obtained based on 100 simulation runs were plotted {{as a function}} of the <b>offered</b> service <b>load.</b>|$|R
40|$|Multilayer MINs {{have emerged}} mainly {{due to the}} {{increased}} need for routing capacity {{in the presence of}} multicast and broadcast traffic, their performance prediction and evaluation however has not been studied sufficiently insofar. In this paper, we use simulation to evaluate the performance of multilayer MINs with switching elements of different buffer sizes and under different <b>offered</b> <b>loads.</b> The findings of this paper can be used by MIN designers to optimally configure their networks...|$|R
