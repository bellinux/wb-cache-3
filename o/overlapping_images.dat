296|728|Public
50|$|Both {{displays}} {{are presented}} {{on the same}} screen ("duplex") as <b>overlapping</b> <b>images</b> to facilitate interpretation.|$|E
5000|$|Virtual Mosaic - a {{tool for}} quickly joining more than four {{adjacent}} or <b>overlapping</b> <b>images</b> ...|$|E
50|$|These segmentations are {{important}} because the document mosaic will be created by matching the lower right corners of words in <b>overlapping</b> <b>images</b> pair. Moreover, the segmentation operation can organize the list of images {{in the context of}} a hierarchy of rows and column reliably.|$|E
40|$|Abstract Micro PIV uses volume illumination; therefore, the {{velocity}} {{measured at the}} focal plane is a weighted average of the velocities within the measurement volume. The contribution of out-of-focus particles to the PIV cor-relation can generate significant measurement errors par-ticularly in near wall regions. We present a new application of <b>image</b> <b>overlapping,</b> which is shown to be very effective in improving the accuracy of time-averaged velocity measurements by effectively reducing the measurement depth. The performance of <b>image</b> <b>overlapping</b> and corre-lation averaging were studied using synthetic and experi-mental images of micro channel flow, both with and without image pre-processing. The results show that for flows without particle clumping, <b>image</b> <b>overlapping</b> pro-vides the best measurement accuracy without any need for image pre-processing. For flows with particle clumping, <b>image</b> <b>overlapping</b> combined with band-pass filtering pro-vides the best measurement accuracy. When <b>overlapped</b> <b>images</b> are saturated with particles due to {{a large number of}} <b>image</b> pairs, <b>image</b> <b>overlapping</b> measurement still does not show any visible pixel-locking effect. <b>Image</b> <b>overlapping</b> was found to have comparable or slightly reduced pixel-locking effects compared to correlation averaging. In addition, <b>image</b> <b>overlapping</b> utilizes significantly fewer computational resources than the other techniques. Nomenclature dx, dy Horizontal and vertical displacements in pixels dzcorr Depth of correlation k Fluorescent wavelength Ukðdx; dyÞ Correlation function from an image pair Uensðdx; dyÞ Averaged correlation function Uovlðdx; dyÞ Correlation function from an <b>overlapped</b> <b>image</b> pairs NA Numerical aperture e Signal threshold where depth of correlation ends dp Particle diamete...|$|R
40|$|Algorithm of {{distortion}} parameters {{evaluation is}} proposed for computer input optical system. For <b>overlapped</b> <b>image</b> frames the maximum of correlation function is looking for, the optimal parameters for distortion compensation is fixing and using for image restoration. ???????????? ???????? ?????? ?????????? ????????? ??????? ??????????? ????? ??????????? ? ??????????. ??? ??????????????? ?????????? ??????????? ??????????? ???????? ??????? ??????????, ??????????? ????????? ??????????? ????????? ? ????????????????? ????? ???????????...|$|R
50|$|Composite: <b>overlap</b> one <b>image</b> over another.|$|R
50|$|The square-face-first orthographic {{projection}} of the tetrahedral prism into 3D space has a cubical envelope (see diagram). Each triangular prismic cell projects onto half of the cubical volume, forming two pairs of <b>overlapping</b> <b>images.</b> The tetrahedral cells project onto {{the top and bottom}} faces of the cube.|$|E
5000|$|For image stitching, we {{must first}} decide on a final {{compositing}} surface onto which to warp or projectively transform and place all of the aligned images. We also need to develop algorithms to seamlessly blend the <b>overlapping</b> <b>images,</b> even {{in the presence of}} parallax, lens distortion, scene motion, and exposure differences.|$|E
50|$|Increased {{resolution}} can {{be accomplished}} by creating a sub-pixel image. The Pixel Shift Method uses an actuator to physically move the CCD in order to take multiple <b>overlapping</b> <b>images.</b> By combining the images within the microscope, sub-pixel resolution can be generated. This method provides sub-pixel information, averaging a standard image is also a proven method to provide sub-pixel information.|$|E
40|$|Resampling is an {{important}} signature of manipulated images. In this paper, we propose two methods to detect and localize image manipulations based {{on a combination of}} resampling features and deep learning. In the first method, the Radon transform of resampling features are computed on <b>overlapping</b> <b>image</b> patches. Deep learning classifiers and a Gaussian conditional random field model are then used to create a heatmap. Tampered regions are located using a Random Walker segmentation method. In the second method, resampling features computed on <b>overlapping</b> <b>image</b> patches are passed through a Long short-term memory (LSTM) based network for classification and localization. We compare the performance of detection/localization of both these methods. Our experimental results show that both techniques are effective in detecting and localizing digital image forgeries...|$|R
40|$|This report {{presents}} {{a new approach}} for Bi-directional Reflectance Distribution Function (BRDF) calibration which incorporates the constraint of the <b>overlaps</b> between <b>images.</b> The new approach {{was applied to the}} BRDF calibration for both aerial photographs and satellite images. Experiments of fitting BRDF kernel fitting are conducted using scanned aerial photographs, Landsat TM 5 and 7 images, and the results indicate that this method is very feasible for implementation, and works well for both aerial photographs and Landsat satellite images. 1. A linear kernel fitting model taking into account the overlap area In order to fit the kernels taking into account the <b>overlaps</b> between <b>images,</b> a proposed leastsquares model is developed. Assuming there are two <b>overlapped</b> <b>images</b> (left and right), the model can be written as (other cases can be extended) : v 3 =...|$|R
40|$|This paper {{developed}} and implemented automated image mosaicking procedures to produce seamless and smooth mosaics from random sequences of digital aerial images and satellite images. The procedure employs automated algorithms for global image registration, seam line extraction, radiometric adjustment, {{and composition of}} <b>overlap</b> <b>images.</b> Results of the experimentation on mosaicking black and white orthorectified aerial images and on mosaicking multi-resolution color infrared SPOT- 2 and Landsat- 5 satellite images show that the implementation of automated conjugate point extraction and image matching algorithms automates the establishment of geometric registration among <b>overlapped</b> <b>images,</b> while the seam line selection and two-step look-up table histogram matching approaches facilitate creating globally smooth and qualitative mosaics. The system developed in this paper makes complex composition of multi-source multi-resolution multi-band images with different geometric and radiometric characteristics an easy and efficient solution for producing reliable mosaic images...|$|R
50|$|In {{addition}} to elaborate drawings and paintings cluttered with words and images, Jon also paints portraiture, landscapes, and color fields devoid of complicated, <b>overlapping</b> <b>images.</b> Jon's current studio {{is located in}} Gloucester, Massachusetts. Jon lives in Rockport, Massachusetts with his wife Kim and son Curtis, and daughters Robin and Caroline. Jon continues to show his artwork around the world.|$|E
50|$|A {{catalogue}} of 1,990 overlapping galaxies {{was published in}} 2013, which had been collected by volunteers on the Galaxy Zoo forum using SDSS images. The abstract states: 'Analysis of galaxies with <b>overlapping</b> <b>images</b> offers a direct way to probe the distribution of dust extinction {{and its effects on}} the background light.' This catalogue was also used in a study of ultraviolet attenuation laws.|$|E
5000|$|The source {{images can}} come from film-based cameras, or digital cameras. The cameras can be mounted in an airplane, or on a satellite. A key {{requirement}} of the imagery is {{that there must be}} two or more <b>overlapping</b> <b>images,</b> taken from different vantage points. This [...] "binocular" [...] characteristic is what makes it mathematically possible to extract the 3-dimensional terrain and feature data from the imagery.|$|E
40|$|Many Sensor {{applications}} such as monitoring and surveillance may require image sensor array to conduct collaborative image transmissions in Wireless Sensor Networks (WSN). The large size image transmissions cause bottlenecks in WSN due to the limited energy resources and network capacity. In this paper, we propose a collaborative transmission scheme for image sensors to utilize inter-sensor correlations to decide transmission patterns based on transmission path diversities, which achieves minimal energy consumption, balanced sensor lifetime and required image quality. This optimization scheme not only allows each image sensor to transmit optimal fractions of the <b>overlapped</b> <b>images</b> through appropriate transmission paths in energy-efficient way, but also provides unequal protection on the <b>overlap</b> <b>image</b> regions through path selections and resource allocations to achieve good transmission image quality. The simulation {{results show that the}} proposed image transmission scheme can achieve considerable gains in terms of the network lifetime extension, image distortion reduction, and energy efficiency...|$|R
30|$|Where N is {{the number}} of <b>overlapped</b> <b>images</b> with the same name point pair as image Ii; S is the area of the overlap area; n {{is the number}} of {{matching}} points for the overlapping area. The larger the T value, the larger the weight of the image Ii in the video sequence, which is taken as the reference plane.|$|R
50|$|A single palette {{entry in}} an indexed color image can be {{designated}} as a transparent color, in order to perform a simple video overlay: superimposing a given image over a background in such way that {{some part of the}} <b>overlapped</b> <b>image</b> obscures the background and the remaining not. Superimposing film/TV titles and credits is a typical application of video overlay.|$|R
50|$|Some {{anthropologists and}} art historians theorize that the {{paintings}} {{could be an}} account of past hunting success, or could represent a mystical ritual {{in order to improve}} future hunting endeavors. This latter theory is supported by the <b>overlapping</b> <b>images</b> of one group of animals in the same cave-location as another group of animals, suggesting that one area of the cave was more successful for predicting a plentiful hunting excursion.|$|E
50|$|Lens {{distortion}} varies as {{a function}} of radial distance from the iso-centre of the photograph meaning that the centre of the image is relatively distortion free, but as the angle of view increases distortion. This is a significant source of error in earlier aerial photography. Such a distortion is impossible to correct for without knowing the details of the lens used to capture the image. <b>Overlapping</b> <b>images</b> can be used to resolve errors.|$|E
50|$|Originating in the Paleolithic period, {{the rock}} art found in Khoit Tsenkher Cave {{includes}} symbols and animal forms painted {{from the walls}} up to the ceiling. Stags, buffalo, oxen, ibex, lions, Argali sheep, antelopes, camels, elephants, ostriches, and other animal pictorials are present, often forming a palimpsest of <b>overlapping</b> <b>images.</b> The paintings appear brown or red in color, and are stylistically similar to other Paleolithic rock art {{from around the world}} but are unlike any other examples in Mongolia.|$|E
50|$|At run time, to put {{the image}} on the screen over the background, the program first masks the screen pixel's bits with the image mask at the desired {{coordinates}} using the bitwise AND operation. This preserves the background pixels of the transparent areas while resets with zeros the bits of the pixels which will be obscured by the <b>overlapped</b> <b>image.</b>|$|R
30|$|Initially, {{we track}} only {{isolated}} fish, {{because in a}} cluster of overlapping fish {{it is difficult to}} estimate the number of fish. When two or more fish tracked by our method begin to overlap, we estimate their parameters by matching the <b>overlapped</b> <b>image</b> and the image drawn from their parameters by applying the NACA model using SA. The details of our tracking algorithm are as follows.|$|R
40|$|We {{propose a}} novel {{efficient}} algorithm for {{the calculation of}} sparse optical flow fields. Our algorithm uses profiles of summed pixel values of the rows and columns of <b>overlapping</b> <b>image</b> regions. It exploits the fast area summation that is provided by integral images. We describe {{the development of the}} algorithm, its application to UAV control and navigation and examine its runtime behavior and complexity...|$|R
5000|$|Born {{in what is}} now Israel, Al-Hallaj {{is known}} {{throughout}} the Arab world, where he has been described as [...] "Syria's most famous artist" [...] and an [...] "icon of contemporary Arab graphic arts." [...] Al Hallaj died in 2002 in a fire at his home while trying to save his artwork. In Self-Portrait as God, the Devil, and Man, Al-Hallaj uses rows of <b>overlapping</b> <b>images</b> and intricate etchings that took 10 years to complete to present [...] "an epic retelling of the history of Palestinians from the 11th century B.C. to the present." ...|$|E
50|$|Jones {{belonged to}} a wealthy Swansea family. He was educated at Eton and Oriel College, Oxford, and was rector of Loughor. A friend of both John Dillwyn Llewelyn and Christopher Rice Mansel Talbot, and thus moved in the same circles as Henry Fox Talbot. Jones is {{credited}} with having taken the first photograph in Wales, a daguerrotype of Margam Castle, in 1841, {{but he did not}} take up photography as a regular occupation. During the 1840s and 1850s, however, he took many photographs of the Swansea area, and travelled with his camera in France and Italy. He also developed his own technique for taking panoramic photographs by <b>overlapping</b> <b>images.</b>|$|E
50|$|The {{following}} year two pivotal events occurred in his life. He met George Davison, a fellow photographer and a philanthropist {{who was involved}} in Theosophy and Freemasonry. This started him on a path of studying mysticism, metaphysical ideals and Druidism. He met Ezra Pound, who introduced him to the short-lived Vorticism movement in Britain. Its new visual aesthetics intrigued Coburn and, provoked by his growing spiritual quest, he began to re-examine his photographic style. He responded by making a bold and distinctive portrait of Pound, showing three <b>overlapping</b> <b>images</b> of differing sizes. Within a brief period he moved from this semi-representative image to a series of abstract images that are among the first completely non-representative photographs ever made.|$|E
40|$|Artist’s Statement: Snow Dune is from {{a series}} of work that I created during 2014 - 2015. This image was {{captured}} in the dunes at Duxbury Beach after a snowstorm. I am inspired to create artwork that shows the beauty of the constantly changing beach environments. While I was creating this artwork, I <b>overlapped</b> multiple <b>images</b> using a Holga medium format camera with 120 Kodak Porta color film. When I <b>overlap</b> my <b>images,</b> this creates a depth in the image that cannot be captured in a single image. The images together create a sense of commotion, causing the viewer to take time to discover what has been created in the <b>image.</b> By <b>overlapping</b> my <b>images,</b> I change how the beach environment appears for my viewer...|$|R
30|$|Figure  18 b shows two {{elephants}} {{walking on}} a sandy trail. The elephants do not set themselves apart from the background well (especially from the trail). While the color model produces false-positive detections on the trail, {{we are able to}} reject the entire trail during the candidate validation. The two elephants can be tracked reliably through the sequence. Note that we consider both elephants as one object to detect since they cover <b>overlapping</b> <b>image</b> regions.|$|R
40|$|A new {{classification}} scheme, primarily {{aimed at}} applications in document image processing, is presented. Features are extracted from a partial image and a sub­ classifier generates scores {{based on the}} likelihood of the sub­image belonging to the candidate classes. This partial classification is carried out for several <b>overlapping</b> <b>image</b> segments and scores are combined to make the final classification. The scheme shows promising results in OCR applications where high processing speeds are achievable with minimal compromise in the recognition accuracy...|$|R
50|$|Eight Elvises is {{composed}} of eight identical, <b>overlapping</b> <b>images</b> of Elvis Presley in cowboy attire, silkscreened over a silver background. The painting was originally {{a portion of a}} 37 ft piece, containing sixteen copies of Elvis, that was showcased in a 1963 exhibition at the Ferus Gallery in Los Angeles. The exhibition, Warhol's second at the Ferus, contained several other pieces using the same image of Elvis, as well as a series of head shots of Elizabeth Taylor. The images of Elvis were taken from a publicity still from the movie Flaming Star. When the gallery was dismantled, the section with eight images of Elvis became a distinct piece, measuring 6+1/2 by 12 ft. While Warhol created 22 versions of the painting with two Elvises on it, known as Double Elvis (Ferus Type), only one piece titled Eight Elvises was created.|$|E
50|$|Dawkins {{discusses}} how {{the image}} on the retina is upside-down and in two dimensions but the <b>overlapping</b> <b>images</b> from each of the eyes are composited to form a three-dimensional model in the brain. He shows this by asking the audience to focus on him while holding their hand at eye level which causes them to see two images of their hand; one from each eye. He then describes how using his finger to wriggle his eyeball that the outside world appears to move because he is moving {{the image on}} his retina. However this does not happen when he voluntary rolls his eyes from side to side. This is due to the brain using the internal model to compensate for the relative change in position of images on the retina. Dawkins gets someone to wear a virtual reality headset and move around in a 3-D computer generated world and draws an analogy between the model of the universe developed in one’s head with the virtual reality universe developed in the computer.|$|E
50|$|The TV camera {{consisted}} of a vidicon tube, 25 millimeter and 100 millimeter focal-length lenses, a shutter, several optical filters, and iris-system mounted along an axis inclined approximately 16 degrees from the central axis of Surveyor 1. The camera was mounted under a mirror that could be moved in azimuth and elevation. This arrangement created a virtual stereo image pair so that adjacent <b>overlapping</b> <b>images</b> were stereo image pairs and {{could be viewed as}} three-dimensional images. This stereo capability permitted some photogrammetric measurements of various lunar features. The TV camera's operation was dependent on the receipt of the proper radio commands from the Earth. Frame-by-frame coverage of the lunar surface was obtained over 360 degrees in azimuth and from +40 degrees above the plane normal to the camera's axis to -65 degrees below this plane. Both 600-line and 200-line modes of operation were used. The 200-line mode transmitted over an omnidirectional antenna for the first 14 photos and scanned one frame every 61.8 seconds. The remaining transmissions were of 600-line pictures over a directional antenna, and each frame was scanned every 3.6 seconds. Each 200-line picture required 20 seconds for a complete video transmission and it used a radio bandwidth of about 1.2 kilohertz.|$|E
40|$|This paper {{presents}} {{a new model}} for image blending based on warping. The model is represented by partial differential equations (PDEs) and gives a sequence of images, which has the properties of both blending of image intensities and warping of image shapes. We modified the energy functional in [1] in order to adapt {{the idea of the}} shape warping to the image blending. The PDEs from the proposed energy functional cover not only <b>overlapped</b> <b>images</b> but also non-overlapped ones. Key words: Image blending, warping, variational approach...|$|R
40|$|Microsoft, Motorola, Siemens, Hitachi, IAPR, NICI, IUF A new {{classification}} scheme, primarily {{aimed at}} applications in document image processing, is presented. Features are extracted from a partial image and a sub­ classifier generates scores {{based on the}} likelihood of the sub­image belonging to the candidate classes. This partial classification is carried out for several <b>overlapping</b> <b>image</b> segments and scores are combined to make the final classification. The scheme shows promising results in OCR applications where high processing speeds are achievable with minimal compromise in the recognition accuracy. ...|$|R
5000|$|The optics of the {{stereoplotter}} is what {{allows the}} operator to plot the contours and features. The light source used {{to project the}} photo is what begins the process. One photo is projected using cyan/blue filter and the other photo is projected with a red filter. The operator wears a special set of glasses that have the same color filter for lenses. Seeing the left photo in blue light while the left eye has the blue filter and the right photo projected with red light and the right eye seeing through the red filter, the <b>overlapping</b> <b>image</b> becomes three-dimensional. The images will have control points that detail how the overlap of the photos should occur. The resultant <b>overlapping</b> <b>image</b> is called an anaglyph and is a three-dimensional model of the terrain. Once the two photos are projected and the desired control points aligned the operator will then start to record the desired elevations on the terrain by [...] "flying" [...] a light spot along the contours. If the light spot appears to hover above the terrain or appears to dive into the terrain, the operator knows that he has moved it {{too far away from}} a slope or too far toward a slope, respectively.|$|R
