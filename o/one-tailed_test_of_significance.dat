1|10000|Public
40|$|A {{study was}} {{conducted}} to examine one aspect of construct validity for the Kaufman Assessment Battery for Children (K-ABC). Forty-eight Sioux children at five age levels (8 to 12. 5) were used in this study. Relying on theories of child development, most tests of mental abilities have been constructed so that raw scores will increase with age. Pearson r correlation coefficients between age and raw scores were calculated across five age levels for this sample of Sioux children. The Simultaneous-, Sequential-, and Achievement-scale raw scores significantly correlate with age at the. 05 level for a <b>one-tailed</b> <b>test</b> <b>of</b> <b>significance.</b> Number Recall and Word Order did not significantly correlate with age. Z-score comparisons between the standardization sample (n = 900) and the Sioux sample were calculated. Statistically significant Z-score discrepancies were obtained on a two-tailed test of significance (. 05) for the total Simultaneous scale, for Spatial Memory, and for Hand Movements. Gender {{differences were found between the}} Sioux males and standardization males. This study also examined the possible effects of school attendance and gender on three K-ABC global scales. An ANOVA (method of unweighted means) test of statistical significance was computed to determine main and interaction effects on the Simultaneous, Sequential, and Achievement scales. There was no significant main effect between the two classification variables and the three global scale scores. Results did indicate Sioux males tended to obtain lower Sequential scores in the low attendance condition and low attending females obtained lower scores on the Simultaneous scale...|$|E
40|$|The {{study was}} {{designed}} to gather data on both a control and an experimental group of student teachers throughout the duration of the professional semester (January - May, 1970) which could serve as a basis for a decision relevant to future structural changes in the professional semester for secondary student teachers at Butler University. The {{study was designed}} to test the following hypotheses stated in null form:Hypothesis I: There will be no significant difference between experimental and control groups in measures of emotional stability when the individuals in each group assume the duties of a full-time student teacher during the practicum part of the professional semester. Hypothesis II; There will be no significant difference between experimental and control groups in measures of actual social stability when the individuals in each group begin the duties of a full-time student teacher during the practicum part of the professional semester. Hypothesis III: There will be {{no significant difference between the}} individuals in the experimental and the control groups in the measure of professional satisfaction which will be derived from the student teaching experience. Hypothesis IV: There will be no significant difference between the experimental and the control group in the measure of confidence possessed at the beginning of the full-time student teaching experience. Hypothesis V: There will be no significant difference between the experimental and the control groups in the measure of student teachercooperating teacher satisfaction with the organizational structure of each professional semester. Included in the existing professional semester were four days of pre student teaching observation in the students' assigned schools. The professional semester for the experimental group included twelve days of pre student teaching visitation and participation in the students' assigned schools. The Edwards Personal Preference Schedule was utilized in a pre test-post test situation for both groups during the first half of the semester to assess the variables, emotional stability and social stability. The Minnesota Teacher Attitude Inventory, was administered to the groups just before and immediately after the student teaching experience to obtain an expression by the student teachers for the variable, the level of professional satisfaction which was derived from the practicum. A two-tailed <b>test</b> <b>of</b> <b>significance</b> was used for the difference in group mean scores at the. 05 and. 01 levels. A cooperating Teacher Opinionnaire and a Student Teacher Opinionnaire were administered at the beginning of the full-time student teaching experience to secure an assessment relative to the variables, amount of confidence possessed by each student teacher and the amount of satisfaction expressed with the structure of each secondary professional semester. The Likert Method of scoring responses was used in conjunction with a <b>one-tailed</b> t <b>test</b> <b>of</b> <b>significance</b> at the. 05 and. 01 levels to determine if any significant difference between the mean scores for each group had resulted. All five null hypotheses were accepted. No significant relationship existed between an increase in the number of school days spent in pre student teaching observation/participation during the professional semester, and the (1) stability of emotional self-concepts of student teachers, (2) social self-concepts of student teachers, (3) level of professional satisfaction of the student teachers, (4) confidence of the student teachers to begin teaching, and (5) satisfaction of the student teachers and cooperating teachers with the organizational structure of each professional semester at Butler University as measured by the instruments utilized. Data relative to the following variables: (1) knowledge of students by the student teachers, (2) substantial professional involvement of the student teachers, and (3) continuity of school and college experiences, as provided by the Student Teacher Opinionnaire suggest that the experimental design of the professional semester did make a significant difference in the responses of the participants. In spite of the acceptance of the null hypotheses of the study, subjective evidence indicated that the experimental professional semester better met the needs of teacher education at Butler University than did the existing professional semester. More detailed guidelines concerning pre student teaching visitation objectives should be created for student teachers and cooperating teachers. Pre professional semester meetings should occur between the cooperating teachers and the designated college supervisor. Continued effort should be made to relate the general methods classwork to actual problems encountered in teaching. Thesis (D. Ed. ...|$|R
40|$|The {{primary purpose}} of the present study was toinvestigate the {{appropriateness}} <b>of</b> several <b>tests</b> <b>of</b> <b>significance</b> for use with interrupted time series data. The second purpose was todetermine what effect the violation of the assumption of uncorrelated error would have on the three <b>tests</b> <b>of</b> <b>significance.</b> The three <b>tests</b> were the Mood test, Walker-Lev Test 3, and Double Extrapolation Technique. The procedure was basically that of generating a large number of time series having specified characteristics and performing the <b>tests</b> <b>of</b> <b>significance</b> on each generated time series. The results of the study indicated that the three <b>tests</b> <b>of</b> <b>significance</b> are appropriate for use on data of interrupted time series form. Tables and figures illustrate the text. (Author/DB) U. S. DEPARTMENT OF HEALTH...|$|R
2500|$|Fisher's {{method for}} {{combining}} independent <b>tests</b> <b>of</b> <b>significance</b> ...|$|R
5000|$|<b>Tests</b> <b>of</b> <b>Significance</b> <b>of</b> Means, Difference of Means, and Regression Coefficients ...|$|R
5000|$|... #Subtitle level 3: False {{positive}} {{rates in}} single <b>tests</b> <b>of</b> <b>significance</b> ...|$|R
5000|$|... 1942 A <b>test</b> <b>of</b> <b>significance</b> for {{multiple}} observations, Current Science, 11, 271-274 ...|$|R
5000|$|... (1950) <b>Tests</b> <b>of</b> <b>significance</b> in factor analysis. British Journal of Psychology, 3, 77-85.|$|R
5000|$|... (1950) <b>Tests</b> <b>of</b> <b>significance</b> in multivariate analysis. British Journal of Mathematical and Statistical Psychology.|$|R
3000|$|... 2 (Chi square) <b>test</b> <b>of</b> <b>significance</b> and H <b>test)</b> because <b>of</b> quantity, the patterns, however, are similar.|$|R
3000|$|And then a <b>test</b> <b>of</b> <b>significance</b> <b>of</b> {{the linear}} {{regression}} was performed. When the level <b>of</b> <b>significance</b> was α =  0.05, the F [...]...|$|R
5000|$|... (1939) A note on <b>tests</b> <b>of</b> <b>significance</b> in multivariate analysis, in Proceedings of the Cambridge Philosophical Society ...|$|R
5000|$|Biostatistics: {{measures}} of location and dispersion, sampling, probability, statistical distribution, <b>tests</b> <b>of</b> <b>significance,</b> correlation and regression, analysis of variance.|$|R
50|$|J. O. Irwin (1935) <b>Tests</b> <b>of</b> <b>Significance</b> for Differences between Percentages Based on Small Numbers, Metron, Vol. 12, pp. 83-94.|$|R
30|$|Detecting and {{correcting}} for {{the presence}} of serial correlations in time series regression models are standard econometric procedures. They are necessary to avoid understating standard errors and unduly inflate <b>tests</b> <b>of</b> <b>significance</b> <b>of</b> parameters and avoid specification errors too.|$|R
5000|$|... "The {{statement}} {{being tested}} in a <b>test</b> <b>of</b> statistical <b>significance</b> is called the null hypothesis. The <b>test</b> <b>of</b> <b>significance</b> is designed to assess {{the strength of the}} evidence against the null hypothesis. Usually, the null hypothesis is a statement of 'no effect' or 'no difference'." [...] It is often symbolized as H0.|$|R
30|$|All <b>tests</b> <b>of</b> <b>{{significance}}</b> {{were at the}} 5 % significance level. Analyses {{were conducted}} using SPSS V. 20.0 (SPSS Inc., Chicago, IL, USA).|$|R
5000|$|Festinger, L. (1943b). An exact <b>test</b> <b>of</b> <b>significance</b> for means <b>of</b> samples {{drawn from}} populations with an {{exponential}} frequency distribution. Psychometrika, 8, 153-160.|$|R
40|$|The <b>test</b> <b>of</b> <b>significance</b> {{does not}} provide the {{information}} concerning psychological phenomena characteristically attributed to it; {{and a great deal}} of mischief has been associated with its use. The basic logic associated with the <b>test</b> <b>of</b> <b>significance</b> is reviewed. The null hypothesis is characteristically false under any circumstances. Publication practices foster the reporting of small effects in populations. Psychologists have "adjusted " by misinterpretation, taking the p value as a "measure, " assuming that the <b>test</b> <b>of</b> <b>significance</b> provides automaticity <b>of</b> inference, and confusing the aggregate with the general. The difficulties are illuminated by bringing to bear the contributions from the decision-theory school on the Fisher approach. The Bayesian approach is suggested. That which we might identify as the "crisis of psychology " is closely related to what Hogben (1958) has called the "crisis in statistical theory. " The vast majority of investigation...|$|R
40|$|The <b>tests</b> <b>of</b> <b>significance</b> for koppa {{presented}} by Kruskal (1958) for one sample and by Warner and Gray (1973) for two samples are reviewed. The two sample test is extended to include multiple com-parisons for both a priori and a posteriori analysis problems. A {{significant difference between}} two or more koppa values, within different categories of a third variable, demonstrates an interaction effect. Empirical examples are included. IN a recent paper (Warner and Gray, 1973) <b>tests</b> <b>of</b> <b>significance</b> were developed for the difference between two koppas, a measure of associ-ation introduced by Kruskal (1958). In his original paper Kruskal presented <b>tests</b> <b>of</b> <b>significance</b> for a single koppa value, but did not present a test for the difference between two (or more) values of koppa. The present paper will review the development of koppa as a mea-sure of association and following this the significance tests developed by Warner and Gray will be presented. The major contribution of the present paper is {{the extension of the}} two sample tests to include both a priori and a posteriori <b>tests</b> <b>of</b> <b>significance</b> and hence multiple (more than two-sample) comparisons. 1 Kruskal traces the origin of Koppa to Fechner; hence it may be misleading to call this measure "Kruskal’s Koppa, " although this name is becoming standard in usage...|$|R
3000|$|In {{order to}} get an idea whether the {{specific}} forest-, crop-, and grassland top soil samples derive from identical or diverse populations a <b>test</b> <b>of</b> <b>significance</b> χ [...]...|$|R
40|$|The use of {{directional}} and nondirectional {{hypothesis testing}} was examined from {{the perspectives of}} textbooks, journal articles, and members of editorial boards. Three widely used statistical texts were reviewed in terms of how directional and nondirectional <b>tests</b> <b>of</b> <b>significance</b> were presented. Texts reviewed were written by: (1) D. E. Hinkle, W. Wiersma, and S. G. Jurs (1994); (2) G. V. Glass and K. D. Hopkins (1996); and (3) R. C. Sprinthall (1990). All three focused on nondirectional <b>tests</b> <b>of</b> <b>significance.</b> While all three texts introduced one-tail (directional) <b>tests</b> <b>of</b> significant, two downplayed its significance. Research methods text...|$|R
40|$|This {{thesis is}} focused on Bayesian {{analysis}} and its use in probability and statistics. It also marginally discusses random processes, furtherly describes ARMA model and defines the issue of estimation of the parameters of Bayesian approach. Acquired knowledge and derived characteristics subsequently applies in <b>testing</b> <b>of</b> <b>significance</b> <b>of</b> parameters. Thus it undoubtably affects the area <b>of</b> hypothesis <b>testing</b> and serves mainly {{as a tool to}} determine the ARMA model more accurately. This work should be regulary applied when detecting the necessity <b>of</b> <b>testing</b> <b>of</b> statistical <b>significance</b> <b>of</b> parameters of ARMA model...|$|R
40|$|Traditional {{methods for}} {{analyzing}} portfolio returns often rely on multifactor risk assessment, and <b>tests</b> <b>of</b> <b>significance</b> are typically based on variants of the t-test. � This approach has serious limitations when analyzing the returns from dynamically traded portfolios that include derivative positions, because standard <b>tests</b> <b>of</b> <b>significance</b> can be 'gamed' using options trading strategies. � To {{deal with this}} problem we propose a test that assumes nothing about the structure of returns except that they form a martingale difference. � Although the test is conservative and corrects for unrealized tail risk, the loss in power is small at high levels <b>of</b> <b>significance.</b> Excess returns, Martingale maximal inequality, Hypothesis test...|$|R
3000|$|... tot for {{treatment}} HDC was − 0.61, for all logs of the study. A two-tailed Student’s t <b>test</b> <b>of</b> <b>significance</b> showed that this correlation was {{significant at the}} 0.05 significance level.|$|R
3000|$|... {{are based}} on the delta method and {{calculated}} using the non-linear combination program “nlcom.” Additionally, both male and female estimates are combined using “suest,” and direct <b>tests</b> <b>of</b> <b>significance</b> are performed. 4 [...]...|$|R
5000|$|.....the null {{hypothesis}} must be exact, that is free from vagueness and ambiguity, because it must supply {{the basis of}} the 'problem of distribution,' <b>of</b> which the <b>test</b> <b>of</b> <b>significance</b> is the solution." ...|$|R
40|$|This is {{the first}} part of a two-part paper. Part 1 {{describes}} the basis for decision making in research. The basic statistical procedures that provide the foundations for more advanced statistical techniques, the rationale underlying hypothesis <b>testing,</b> the nature <b>of</b> probability and its relevance to the normal curve, and the meaning <b>of</b> <b>tests</b> <b>of</b> <b>significance</b> and level <b>of</b> <b>significance</b> are discussed. These concepts provide the foundation for an understanding of the interpretation of decision rules and <b>tests</b> <b>of</b> <b>significance,</b> topics that will be discussed in Part II of the paper, to be published in a subsequent issue of this journal. All concepts and procedures are discussed in terms of their clinical relevance to the practising physical therapist...|$|R
5000|$|... "The {{notion that}} {{different}} <b>tests</b> <b>of</b> <b>significance</b> are appropriate to <b>test</b> different features <b>of</b> the same null hypothesis presents no difficulty to workers engaged in practical experimentation, {{but has been}} the occasion of much theoretical discussion among statisticians." ...|$|R
30|$|Data were {{analyzed}} using Statistical Program for Social Science (SPSS) version 20.0. (SPSS, Chicago, IL) Quantitative data were expressed as mean[*]±[*]standard deviation (SD). Qualitative data were expressed as frequency and percentage. The following tests were done: independent sample t <b>test</b> <b>of</b> <b>significance</b> was used when comparing between two means, chi-square (×[*] 2) <b>test</b> <b>of</b> <b>significance</b> {{was used to compare}} proportions between two qualitative parameters, and binary logistic regression was used to predict the outcome of categorical variable based on one or more predictor variables. In all tests, P value <[*] 0.05 was considered significant, P value <[*] 0.001 was considered highly significant, and P value >[*] 0.05 was considered insignificant.|$|R
40|$|Many {{studies are}} {{performed}} on units that cannot be replicated; however, {{there is often}} an abundance of subsampling. By placing a reasonable upper bound on the intraclass correlation coefficient (ICC), {{it is possible to}} carry out classical <b>tests</b> <b>of</b> <b>significance</b> that have conservative levels <b>of</b> <b>significance...</b>|$|R
30|$|Hypothesis <b>tests,</b> the <b>tests</b> <b>of</b> <b>significance</b> for {{analysing}} {{experimental data}} are categorised as (1) parametric tests, e.g. Chi-square test, t test, z test and F test (2) non-parametric tests, the distribution-free <b>tests</b> <b>of</b> hypotheses, independent of assumptions {{based on the}} characteristics of the original population.|$|R
40|$|Quantitative {{methods in}} {{psychology}} for producing, analyzing, and interpreting data. Sampling, basic research designs, describing distributions, correlation, regression, applications of normal probability curve, confidence intervals, and <b>tests</b> <b>of</b> <b>significance.</b> Analysis {{and interpretation of}} data using statistical, spreadsheet, and word processing software...|$|R
30|$|It is {{acknowledged}} {{that differences in}} the reporting systems {{of the two countries}} could be responsible for some of the obtained findings. Furthermore, no statistical <b>tests</b> <b>of</b> <b>significance</b> were performed. Consequently, only substantial differences and clear similarities with sufficient frequencies are discussed.|$|R
50|$|Probability and {{statistics}} {{was focused on}} probability distributions and <b>tests</b> <b>of</b> <b>significance.</b> Probability was formal, well defined, but limited in scope. In particular its application was limited to situations that could be defined as an experiment or trial, with a well defined population.|$|R
5000|$|In statistics, the Conover squared ranks test [...] is a {{non-parametric}} {{version of}} the parametric Levene's <b>test</b> for equality <b>of</b> variance. The only test {{that appears to be}} a non-parametric one is the Conover squared ranks <b>test.</b> Other <b>tests</b> <b>of</b> <b>significance</b> <b>of</b> difference of data dispersion are parametric (i.e., are difference <b>of</b> variance <b>tests)</b> whereas Conover's test is non-parametric. The squared ranks test is arguably a <b>test</b> <b>of</b> <b>significance</b> <b>of</b> difference of data dispersion not variance per se. This becomes important, for example, when the Levene's test fails to satisfy the rather generous conditions for normality associated with that test and is a default alternative under those conditions for certain statistical software programs like the VarianceEquivalenceTest routine in Mathematica. The parametric tests include the Bartlett, Brown-Forsythe, and Fisher Ratio tests.|$|R
