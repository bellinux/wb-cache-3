375|212|Public
25|$|Lake {{freeze-up}} {{depends on}} the heat storage in the lake and therefore on its depth, the rate and temperature of any inflow, and water-air energy fluxes. Information on lake depth is often unavailable, although some indication of the depth of shallow lakes in the Arctic {{can be obtained from}} airborne radar imagery during late winter (Sellman et al. 1975) and spaceborne <b>optical</b> <b>imagery</b> during summer (Duguay and Lafleur 1997). The timing of breakup is modified by snow depth on the ice as well as by ice thickness and freshwater inflow.|$|E
2500|$|An {{example of}} [...] "scientific reason lit up by mysticism in the Church of England" [...] {{is seen in}} the work of Sir Thomas Browne, a Norwich {{physician}} and scientist whose thought often meanders into mystical realms, as in his self-portrait, Religio Medici, and in the [...] "mystical mathematics" [...] of The Garden of Cyrus, whose full running title reads, Or, The Quincuncial Lozenge, or Network Plantations of the ancients, Naturally, Artificially, Mystically considered. Browne's highly original and dense symbolism frequently involves scientific, medical, or <b>optical</b> <b>imagery</b> to illustrate a religious or spiritual truth, often to striking effect, notably in Religio Medici, but also in his posthumous advisory Christian Morals.|$|E
50|$|<b>Optical</b> <b>imagery</b> is {{captured}} with high-speed digital cameras.|$|E
30|$|A {{mosaic of}} SPOT <b>optical</b> {{satellite}} <b>imagery</b> {{for the years}} 2011 and 2012.|$|R
5000|$|An {{accurate}} {{diagnosis of}} retinitis pigmentosa {{relies on the}} documentation of the progressive loss photoreceptor cell function, confirmed {{by a combination of}} visual field and visual acuity tests, fundus and <b>optical</b> coherence <b>imagery,</b> and electroretinography (ERG), ...|$|R
40|$|This paper {{reports the}} result of the study in the AOE- 869 test site by {{exploring}} ASAR/APP dual polarization (VV, VH) image. The result is very promising, as it could differentiate clearly two land cover types: forest timber plantation and oil palm plantation. Although they play an important role for the monitoring of deforestation, these land covers were difficult to be differentiated in high resolution <b>optical</b> <b>imageries</b> (Landsat, SPOT,ASTER),. This ability is also required to monitor leakage in the project area for CDM A/R purpose of the Kyoto Protocol. ESA policy for the provision of free PolSAR PRO analysis software has given a concrete multiplier effect for the future potential market of polarimetric SAR data, especially in th...|$|R
50|$|Using {{evidence}} from earthquakes, remote sensing, geodesy and geomorphology {{he is able}} to observe, quantitatively, the geometry and rates of deformation processes while they are active. In addition to seismology, his current research uses space-based remote sensing (including radar interferometry, GPS measurements and <b>optical</b> <b>imagery)</b> combined with observations of the landscape in the field, to study the evolution and deformation of the continents on all scales, from the movement of individual faults in earthquakes to the evolution of mountain belts.|$|E
50|$|Lake {{freeze-up}} {{depends on}} the heat storage in the lake and therefore on its depth, the rate and temperature of any inflow, and water-air energy fluxes. Information on lake depth is often unavailable, although some indication of the depth of shallow lakes in the Arctic {{can be obtained from}} airborne radar imagery during late winter (Sellman et al. 1975) and spaceborne <b>optical</b> <b>imagery</b> during summer (Duguay and Lafleur 1997). The timing of breakup is modified by snow depth on the ice as well as by ice thickness and freshwater inflow.|$|E
50|$|THEOS was {{designed}} to be a small sized satellite with a mass of 750 kg (include equipment and fuel). It has a hexagonal shape with a height of 2.4 meters and a width of 2 meters (when the solar panel folds). It was launched into low earth orbit in 2008 to an altitude of 822 km and with an inclination of 98 degrees. It is equipped with <b>optical</b> <b>imagery</b> which can observe in the visible band to near infrared. Its mission duration is expected to be at least 5 years.|$|E
40|$|Digital {{elevation}} models (DEMs) can be generate by interferometric SAR (InSAR) and radargrammetry techniques {{from different}} acquisition of Synthetic Aperture Radar (SAR) images. Radar imaging systems record both the phase and intensity information of the backscattered signals from ground. InSAR utilizes the phase information {{of the images}} to extract useful geodetic information, such as the height of terrain, ground deformation and movement. However, InSAR technique is constrained by the temporal and spatial baselines between the images used, {{as well as the}} various atmospheric conditions at the time of acquisitions. In comparison, radargrammetry technique uses the intensity (power) information in a stereo-pair of radar images. It is similar to stereo-grammetry or photogrammetry which is a classic method for relief reconstruction using airborne/spaceborne <b>optical</b> <b>imageries.</b> In this paper, the radargrammetric DEM quality improvement method using SAR image processing is presented by ENVISAT/ASAR imageries...|$|R
5000|$|Just as color {{photography}} evolved {{with the}} addition of filters and film layers, color printing is made possible by repeating the halftone process for each subtractive color—most commonly using what is called the [...] "CMYK color model". The semi-opaque property of ink allows halftone dots of different colors to create another <b>optical</b> effect—full-color <b>imagery.</b>|$|R
50|$|This was {{especially}} important because Malaysia is usually {{covered by the}} equatorial cloud bands. Normal sun-synchronous optical satellites, which may re-visit an area only once every 7 days, will almost {{never be able to}} see the ground during their pass. As a result, much <b>optical</b> satellite <b>imagery</b> of Malaysia have more than 50% cloud cover within the image's footprint.|$|R
5000|$|An {{example of}} [...] "scientific reason lit up by mysticism in the Church of England" [...] {{is seen in}} the work of Sir Thomas Browne, a Norwich {{physician}} and scientist whose thought often meanders into mystical realms, as in his self-portrait, Religio Medici, and in the [...] "mystical mathematics" [...] of The Garden of Cyrus, whose full running title reads, Or, The Quincuncial Lozenge, or Network Plantations of the ancients, Naturally, Artificially, Mystically considered. Browne's highly original and dense symbolism frequently involves scientific, medical, or <b>optical</b> <b>imagery</b> to illustrate a religious or spiritual truth, often to striking effect, notably in Religio Medici, but also in his posthumous advisory Christian Morals.|$|E
50|$|The visual {{information}} relayed to V1 is not coded {{in terms of}} spatial (or <b>optical)</b> <b>imagery</b> but rather are better described as edge detection. As an example, for an image comprising half side black and half side white, the dividing line {{between black and white}} has strongest local contrast (that is, edge detection) and is encoded, while few neurons code the brightness information (black or white per se). As information is further relayed to subsequent visual areas, it is coded as increasingly non-local frequency/phase signals. Note that, at these early stages of cortical visual processing, spatial location of {{visual information}} is well preserved amid the local contrast encoding (edge detection).|$|E
40|$|Airborne LiDAR {{data and}} <b>optical</b> <b>imagery</b> are two {{datasets}} used for 3 D building reconstruction. In this paper, the complementarities {{of these two}} datasets are utilized to perform a primitive-based 3 D building reconstruction. The proposed method comprises following steps: (1) recognize primitives from LiDAR point cloud and roughly measure primitives ’ parameters as initial values, and (2) select primitives ’ features on the imagery, and (3) optimize primitives ’ parameters by the constraints of LiDAR point cloud and imagery, and (4) represent 3 D building model by these optimized primitives. Compared with other modelbased or CSG-based methods, the proposed method is simpler. It only uses the most straightforward features, i. e. planes of LiDAR point cloud and points of <b>optical</b> <b>imagery.</b> The experimental result shows this primitive-based method can accurately reconstruct 3 D building model. And it can tightly integrate LiDAR point cloud and <b>optical</b> <b>imagery,</b> that is to say, all primitives ’ parameters are optimized with all constraints in one step. 1...|$|E
40|$|To {{meet the}} {{requirement}} of high accuracy and high speed processing for wide swath high resolution <b>optical</b> satellite <b>imagery</b> under emergency situation in both ground processing system and on-board processing system. This paper proposed a ROI-orientated sensor correction algorithm based on virtual steady reimaging model for wide swath high resolution <b>optical</b> satellite <b>imagery.</b> Firstly, the imaging time and spatial window of the ROI is determined by a dynamic search method. Then, the dynamic ROI sensor correction model based on virtual steady reimaging model is constructed. Finally, the corrected image corresponding to the ROI is generated based on the coordinates mapping relationship which is established by the dynamic sensor correction model for corrected image and rigours imaging model for original image. Two experimental {{results show that the}} image registration between panchromatic and multispectral images can be well achieved and the image distortion caused by satellite jitter can be also corrected efficiently...|$|R
40|$|Shepherd, J. D., Dymond, J. R., Gillingham, S., Bunting, P. (2014). Accurate {{registration}} of <b>optical</b> satellite <b>imagery</b> with elevation models for topographic correction. Remote Sensing Letters, 5 (7), 637 - 641 It {{is necessary to}} remove the effects of topography from <b>optical</b> satellite <b>imagery</b> if automated techniques are {{to be used to}} infer surface properties. This is especially the case in mountainous terrain where variable slope normals cause variation in both illumination and reflectance of light. Digital elevation models (DEMs) are required to model slope normals and make topographic corrections. However, it is difficult to achieve accurate registration between ortho-rectified satellite images and DEMs. We show how this mis-registration, which can be spatially variable, may be accounted for {{with the use of a}} local correlation filter. The filter determines the offset between a DEM shade map and ortho-rectified satellite image for every pixel. Association of satellite image pixels with the 'correct' slope normal in topographic correction removes the majority of ghosting and high-frequency artefacts. authorsversionPeer reviewe...|$|R
40|$|On-orbit {{geometric}} calibration is a {{key technology}} to guarantee the geometric quality of high-resolution <b>optical</b> satellite <b>imagery.</b> In this paper, we present an approach for the on-orbit geometric calibration of high-resolution <b>optical</b> satellite <b>imagery,</b> focusing on two core problems: constructing an on-orbit geometric calibration model and proposing a robust calculation method. First, a rigorous geometric imaging model is constructed based on {{the analysis of the}} major error sources. Second, we construct an on-orbit geometric calibration model through performing reasonable optimizing and parameter selection of the rigorous geometric imaging model. On this basis, the calibration parameters are partially calculated with a stepwise iterative method by dividing them into two groups: external and internal calibration parameters. Furthermore, to verify the effectiveness of the proposed calibration model and methodology, on-orbit geometric calibration experiments for ZY 1 - 02 C panchromatic camera and ZY- 3 three-line array camera are conducted using the reference data of the Songshan calibration test site located in the Henan Province, China. The experimental results demonstrate a certain deviation of the on-orbit calibration result from the initial design values of the calibration parameters. Therefore, on-orbit geometric calibration is necessary for <b>optical</b> satellite <b>imagery.</b> On the other hand, by choosing multiple images, which cover different areas and are acquired at different points in time to verify their geometric accuracy before and after calibration, we find that after on-orbit geometric calibration, the geometric accuracy of these images without ground control points is significantly improved. Additionally, due to the effective elimination of the internal distortion of the camera, greater geometric accuracy was achieved with less ground control points than before calibration...|$|R
40|$|Developing {{accurate}} but inexpensive {{methods for}} estimating above-ground carbon biomass {{is an important}} technical challenge that must be overcome before a carbon offset market can be successfully implemented in the United States. Previous {{studies have shown that}} LiDAR (light detection and ranging) is well-suited for modeling above-ground biomass in mature forests; however, there has been little previous research on the ability of LiDAR to model above-ground biomass in areas with young, aggrading vegetation. This study compared the abilities of discrete-return LiDAR and high resolution <b>optical</b> <b>imagery</b> to model above-ground carbon biomass at a young restored forested wetland site in eastern North Carolina. We found that the <b>optical</b> <b>imagery</b> model explained more of the observed variation in carbon biomass than the LiDAR model (adj-R(2) values of 0. 34 and 0. 18 respectively; root mean squared errors of 0. 14 Mg C/ha and 0. 17 Mg C/ha respectively). <b>Optical</b> <b>imagery</b> was also better able to predict high and low biomass extremes than the LiDAR model. Combining both the optical and LiDAR improved upon the optical model but only marginally (adj-R(2) of 0. 37). These results suggest that the ability of discrete-return LiDAR to model above-ground biomass may be rather limited in areas with young, small trees and that high spatial resolution <b>optical</b> <b>imagery</b> may be the better tool in such areas...|$|E
40|$|Airborne LiDAR {{data and}} <b>optical</b> <b>imagery</b> are two {{datasets}} used for 3 D building reconstruction. By {{study of the}} complementarities of these two datasets, we proposed a primitive-based 3 D building reconstruction method, which can use LiDAR data and <b>optical</b> <b>imagery</b> at the same time. The proposed method comprises following steps: (1) recognize primitives from LiDAR point cloud and roughly measure primitives’ parameters as initial values, and (2) select primitives' features on the imagery, and (3) optimize primitives' parameters by the constraints of LiDAR point cloud and imagery, and (4) represent 3 D building model by these optimized primitives. Compared with other model-based or CSG-based methods, the proposed method has some advantages. It is simpler, because it only uses the most straightforward features, i. e. planes of LiDAR point cloud and points of <b>optical</b> <b>imagery.</b> And it can tightly integrate LiDAR point cloud and <b>optical</b> <b>imagery,</b> that is to say, all primitives' parameters are optimized with all constraints in one step. Recently, an ISPRS Test Project on Urban Classification and 3 D Building Reconstruction was launched, two datasets both with airborne LiDAR data and images are provided. The proposed method was applied to Area 3 of Dataset 1 Vaihingen, {{in which there are}} some buildings with plane roofs or gable roofs. The organizer of this test project evaluated the submitted reconstructed 3 D model using reference data. The result shows the feasibility of the proposed 3 D building reconstruction method...|$|E
40|$|This paper {{argues that}} Kepler {{considered}} {{his work in}} optics as part of natural philosophy and that, consequently, he aimed at change within natural philosophy. Back-to-back with John Schuster's claim that Descartes' optics {{should be considered as}} a natural philosophical appropriation of innovative results in the tradition of practical and mixed mathematics the central claim of my paper is that Kepler's theory of <b>optical</b> <b>imagery,</b> developed in his Paralipomena ad Vitellionem (1604), {{was the result of a}} move similar to Descartes' by Kepler. My argument consists of three parts. First, Kepler borrowed a geometrical model and experiment of <b>optical</b> <b>imagery</b> from the m,lange of mixed and practical mathematics provided in the works of the sixteenth-century mathematicians Ettore Ausonio and Giovanni Battista Della Porta. Second, Kepler criticized the Aristotelian theory of light and he developed his own alternative metaphysics. Third, Kepler used his natural philosophical assumptions about the nature of light to re-interpret the model of image formation taken from Della Porta's work. Taken together, I portray Kepler's theory of <b>optical</b> <b>imagery</b> as a natural philosophical appropriation of an innovative model of image formation developed in a sixteenth-century practical and mixed mathematical tradition which was not interested in questioning philosophical assumptions on the nature of light...|$|E
40|$|The {{proposed}} framework ranks {{data reliability}} internally, thereby avoiding the requirements to quantify absolute error {{and results in}} a high resolution, seamless product. Nested within this approach is an effective spatially explicit technique for improving the accuracy of bathymetry estimates derived empirically from <b>optical</b> satellite <b>imagery</b> through modelling the spatial structure of residuals. The approach was applied to data collected on and around Lizard Island in northern Australia. Collectively, the framework holds promise for filling the white ribbon zone in coastal areas characterised by similar data availability scenarios. The seamless DEM is referenced to the horizontal coordinate system MGA Zone 55 - GDA 1994, mean sea level (MSL) vertical datum and has a spatial resolution of 20 m.  A range of datasets are integrated: Field-collected GPS elevation points, terrestrial and bathymetric LiDAR, single and multibeam bathymetry, nautical chart depths and empirically derived bathymetry estimations from <b>optical</b> remote sensing <b>imagery...</b>|$|R
40|$|Airborne {{topographic}} {{data collection}} requires removal of errors that arise due to surface features that obstruct the ground from the sensor. Typically, {{this has been}} based on manual correction and/or automated filtering. To some degree, the latter has provided a method for identifying and removing unwanted surface obstructions in large topographic data-sets. However, the algorithms used are unintelligent in that they cannot reliably differentiate between the various types of obstructions and the ground. If coincident <b>optical</b> support <b>imagery</b> is available, the use of intelligent correction routines becomes possible. This paper describes an automated approach for removing obstruction errors using <b>optical</b> support <b>imagery</b> and simple image processing routines. Orthorectification and classification of support imagery enable obstruction errors to be identified in the digital surface model (DSM) and corrected intelligently to produce a digital terrain model (DTM). The results show that support imagery can be used with basic image processing routines to remove obstructions intelligently and automatically from large topographic data-sets. Since the approach can differentiate between types of obstructions, the removal of each type of error can be customised, making this a very flexible approach to topographic data correction...|$|R
40|$|Abstract—A {{procedure}} for automatic {{recognition of the}} state of built-up structures after a conflict, using 1 -meter-resolution <b>optical</b> satellite <b>imagery,</b> is presented. The procedure is based on a priori fuzzy rules formalized using two basic information derived from satellite data: structural information extracted by calculation of the derivative of the morphological profile using the panchromatic data, and presence of vegetation extracted from multi-spectral data. The procedure is validated using a perpixel and per-region image understanding approach. JRC. G. 2 -Support to external securit...|$|R
30|$|With {{appropriate}} {{imagery and}} reliable 3 D topographic data (e.g. Digital Terrain Model (DTM)), geological mechanisms {{responsible for the}} topographic formation in planet surface can be analyzed and interpreted accurately. Therefore, together with the on-site active measurement, <b>optical</b> <b>imagery</b> taken by remote sensing instruments is applied broadly for exploring terrain surfaces of planets.|$|E
40|$|Timely and {{accurate}} measuremen ts of forest parameters {{are critical for}} ecosystem studies, sustainable forest resources management, monitoring and planning. This paper presents a processing chain for individual tree segmentation over large areas with airborne LiDAR 3 D point cloud and very high resolution (VHR) <b>optical</b> <b>imagery.</b> The proposed processing chain consists of fo rest stand level delineation with <b>optical</b> <b>imagery,</b> individual tree segmentation with Canopy Height Model (CHM) derived from LiDAR point cloud, rough characterization of trees at forest stand level, and point clustering of individual tree with an Adaptive Mean Shift 3 D (AMS 3 D) algorithm. The processing chain is developed with the expectation of supporting operational forest inventory at individual tree level. Experiment is conducted using LiDAR data acquired in Ventoux region, France. Results suggest that the proposed processing chain can be successfully adopted for individual tree characterization over large areas with different forest stands...|$|E
40|$|The Rangeview {{software}} system presented here addresses two significant {{issues in the}} development and deployment of an AutomaticTarget Recognizer: visualization of progress of the recognizer in finding a target, and verification by an operator of the correctness of the match. The system combines range imagery from a LADAR device with <b>optical</b> <b>imagery</b> from a color CCD camera and/or FLIR sensor to display a three-dimensional representation of the scene and the target model. Range imagery creates a partial three-dimensional representation of the scene. <b>Optical</b> <b>imagery</b> is mapped onto this partial three-dimensional representation. Output from the ATR is registered in three dimensions with the scene. Recognized targets are displayed in correct spatial relation to the scene, and the registered scene and target may be visually inspected from any viewpoint. 1 Introduction Model-Based Object Recognition techniques use sensor data to find the three-dimensional position in a scene of an object whic [...] ...|$|E
40|$|This study {{concerned}} with fusion of {{synthetic aperture radar}} and <b>optical</b> satellite <b>imagery.</b> Due to {{the difference in the}} underlying sensor technology, data from synthetic aperture radar (SAR) and optical sensors refer to different properties of the observed scene and it is believed that when they are fused together, they complement each other to improve the performance of a particular application. In this paper, two category of features are generate and six classifier fusion operators implemented and evaluated. Implementation results show significant improvement in the classification accuracy...|$|R
40|$|Geometric distortions and {{intensity}} differences always exist in multi-source <b>optical</b> satellite <b>imagery,</b> seriously reducing {{the similarity between}} images, {{making it difficult to}} obtain adequate, accurate, stable, and well-distributed matches for image registration. With the goal of solving these problems, an effective image matching method is presented in this study for multi-source <b>optical</b> satellite <b>imagery.</b> The proposed method includes three steps: feature extraction, initial matching, and matching propagation. Firstly, a uniform robust scale invariant feature transform (UR-SIFT) detector was used to extract adequate and well-distributed feature points. Secondly, initial matching was conducted based on the Euclidean distance to obtain a few correct matches and the initial projective transformation between the image pair. Finally, two matching strategies were used to propagate matches and produce more reliable matching results. By using the geometric relationship between the image pair, geometric correspondence matching found more matches than the initial UR-SIFT feature points. Further probability relaxation matching propagated some new matches around the initial UR-SIFT feature points. Comprehensive experiments on Chinese ZY 3 and GaoFen (GF) satellite images revealed that the proposed algorithm performs well {{in terms of the number}} of correct matches, correct matching rate, spatial distribution, and matching accuracy, compared to the standard UR-SIFT and triangulation-based propagation method...|$|R
40|$|In {{this paper}} we {{introduce}} a concept for {{monitoring and surveillance}} based on SAR imagery. A workflow for detection and characterization of changes is presented and discussed. SAR imagery is quite efficient for detection of changes, but less adequate for characterization of the changes. For this purpose context information can be used or detailed geographical information, derived from <b>optical</b> satellite <b>imagery.</b> We discuss two case studies on basis of the workflow, one with present-day satellite SAR data and one with high-resolution air borne SAR data resembling data from future high-resolution radar satellites...|$|R
40|$|Recognizing 3 D modeled objects through {{alignment}} of object and sensor features requires {{a means of}} predicting matchable features. This paper presents a system which performs online feature prediction for CAD modeled objects and tightly couples prediction with matching. For the ATR domain, detailed CAD models of objects are available in this application, as is both range and <b>optical</b> <b>imagery.</b> Matching begins with an initial hypothesis which is refined through an iterative generate-and-test procedure. Matching interleaves feature prediction and adjustment of model-to-sensor geometry until a locally optimal match is obtained. In addition, sensor-to-sensor geometry is also adjusted, allowing the algorithm to correct minor mis-registrations between range and <b>optical</b> <b>imagery.</b> While the resulting match is locally optimal {{in terms of the}} complete space of possible matches, it globally preserves the 3 D constraints implied by sensor and object geometry. Results on real data are presented which de [...] ...|$|E
40|$|Scene {{radiation}} and atmospheric effects, mathematical pattern recognition and image analysis, information evaluation and utilization, and electromagnetic measurements and signal handling are considered. Research issues in sensors and signals, including radar (SAR) reflectometry, SAR processing speed, registration, including overlay of SAR and <b>optical</b> <b>imagery,</b> entire system radiance calibration, {{and lack of}} requirements for both sensors and systems, etc. were discussed...|$|E
40|$|A new {{stereoscopic}} {{road network}} extraction framework {{based on the}} decision-level fusion of optical and Synthetic Aperture Radar (SAR) imagery is proposed in this paper. Three steps are included in this framework: 1) road segment extraction and structure optimization through SAR imagery, 2) road segment extraction and stereoscopic information collection through <b>optical</b> <b>imagery,</b> and 3) fusion of the SAR result with the optical image and the stereoscopic information. In this study, our new road network grouping algorithm called road network grouping based on the multi-scale geometric analysis of detector Response is used, with the improved footprint method, and the stereoscopic inversion algorithm. The most important finding of our work lies in the fusion step, by which a stereoscopic road network can be acquired after going through the three aforementioned processes and by fusing the stereoscopic information obtained from <b>optical</b> <b>imagery</b> and road network extracted from SAR imagery. Our algorithm is tested on the real TerraSAR-X and QuickBird data. Peer ReviewedPostprint (published version...|$|E
40|$|The paper {{discusses}} {{some examples}} of image processing applied to improve <b>optical</b> satellite <b>imagery</b> of small craters (Kamil, Veevers, Haviland). The examples show that image processing can be quite useful for further in-situ researches, because the resultant imagery helps {{to have a better}} picture of the crater shape and of the distribution of debris about it. The paper is also disclosing an interesting underwater structure, with shape and size of a small crater, located on the coast-line of Sudan. Comment: Key-words: Image processing, Satellite maps, Craters, Underwater crater...|$|R
50|$|Details of USA-245's mission are {{classified}} by the US military, however numerous independent analysts identified it as a KH-11 before launch, and amateur satellite watchers have since observed {{it in the}} orbit used by such satellites. KH-11 satellites are used to provide high-resolution <b>optical</b> and infrared <b>imagery</b> for US intelligence agencies.|$|R
40|$|The actual high {{resolution}} optical and Synthetic Aperture Radar (SAR) satellite sensors offer interesting potentialities for Digital Surface Models (DSMs) generation. Both <b>optical</b> and SAR <b>imagery</b> and characterized by proper deformations and noise {{due to the}} different acquisition geometries and processes, which have to be duly taken into account during the DSM generation procedure in order to fully exploit the aforementioned potentialities. The aim of this work is to evaluate the performances of {{high resolution}} <b>optical</b> and SAR <b>imagery</b> for DSMs generation over the same testfield area where a dense network of GCPs and LiDAR DSM are available as ground truth data. The image processing and DSMs generation are carried out with the packages SISAR (Software Immagini Satellitari ad Alta Risoluzione) and SAT-PP (SATellite image Precision Processing) while an additional comparison is performed using PCI Geomatica 2012...|$|R
