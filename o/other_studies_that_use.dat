24|10000|Public
50|$|The {{department}} sometimes releases its own studies, {{and comments}} on <b>other</b> <b>studies</b> <b>that</b> <b>use</b> its data. For example, the department collects data on fatal work injuries in New Jersey. According to the department, around 1,500 New Jersey resident died in 2014 from kidney disease, making kidney disease the ninth {{leading cause of}} death for state residents. The department keeps a Zika Pregnancy Registry to watch for Zika, and out of 59 pregnant women on the registry, 23 babies tested positive by April 2017.|$|E
30|$|Cite {{this paper}} when {{reporting}} analytical results or <b>other</b> <b>studies</b> <b>that</b> <b>use</b> {{the table at}} a conference or in an article.|$|E
40|$|Abstract. Finance journal {{quality is}} a {{critical}} issue for faculty annual elevations, for the tenure and promotion process, and for the administration of faculty workload plans. Unlike <b>other</b> <b>studies</b> <b>that</b> <b>use</b> objective measures (such as citation frequencies) to rate journals, this study focuses on the opinions of chairpersons about the relative quality of 55 finance, insurance, and real estate journals. A sample of 218 finance department chair-persons at AACSB accredited business schools were surveyed, and 125 responses were received (57. 34 % response rate). Besides overall aggregate scores, responses are segregated and tested for differences across several dimensions. The results offer interesting and current insight on general perceptions of journal quality. Key words: journal, quality, rating, survey, evaluation The rating of finance journals {{is a critical}} issue for faculty annual elevations, for the tenure and promotion process, and for the administratin of faculty workload plans. However, much of the recent literature on this topic seems to focus on issues other than academics’ collective perception and opinion of relative journal quality. The goal {{of this study is}} to determine how one element of the “market ” views journals by surveying finance depart-ment chairpersons of business schools that are accredited by the American Assembly of Collegiate Schools of Business (AACSB). Unlike <b>other</b> <b>studies</b> <b>that</b> <b>use</b> objective mea...|$|E
30|$|To our knowledge, {{there is}} very limited {{published}} data as regards {{to the use of}} Ultracision for laparoscopic lymphadenectomies [23, 24]. Our data supports the evidence from other researchers and compares favourably with the results of <b>other</b> <b>studies</b> <b>that</b> <b>used</b> electrosurgery for this procedure.|$|R
40|$|Includes bibliographical {{references}} (pages 44 - 46) This study {{attempted to}} validate results of <b>other</b> <b>studies</b> <b>that</b> <b>used</b> regular exercise {{as a means}} of reducing disruptive behaviors in a Special Education classroom. Eight SED students participated in a daily running program over a three month period. The results of this study proved to be disappointing; however, the negative effects of the actual running program were insignificant for most of the subjects. Further research is encouraged by this investigator...|$|R
40|$|There {{is a body}} of {{scientific}} literature describing cognitive deficit in schizophrenia {{and the possibility of}} its remediation. However, in the Czech Republic, there have been so far just few <b>studies</b> <b>that</b> examined the topic. The objective of this work was to explore the feasibility of non-pharmacological intervention in the form of computer-assisted cognitive remediation of Czech schizophrenia patients with diagnosed cognitive deficit. Our results confirmed the positive short-term effect of targeted remediation of selective domains of cognitive deficit in patients with schizophrenia. Our findings suggested that 5 working memory function is the domain most sensitive to the structured intervention. These results are consistent not only with findings from <b>other</b> published <b>studies</b> <b>that</b> <b>used</b> similar computer method for remediation, but also with <b>other</b> <b>studies</b> <b>that</b> <b>used</b> different approaches. In addition, working memory function improved in the generalized form (visual intervention improved auditive function). Key words: Schizophrenia, cognition, deficit, remediation, compute...|$|R
30|$|Before we move on, we {{highlight}} two {{advantages of}} using this dataset, compared to surveys which collect data at lower (i.e. yearly or longer) frequencies. First, the high frequency {{at which the}} SSS is collected enables us to precisely time and separately estimate the announcement and disbursement effects of the SSS. Capturing the announcement effect allows us to avoid under-estimating the SSS’s effects (Blundell et al. 2011). Second, the SLP also allows us to directly test {{the validity of the}} DiD identifying assumption of parallel trends, which <b>other</b> <b>studies</b> <b>that</b> <b>use</b> data from surveys with only two or three time points cannot do.|$|E
40|$|The Gini {{index is}} the most common method for {{estimating}} the level of income inequality in countries. In this paper we suggest a simple modification that takes into account the moderating effect of in-kind government benefits. Unlike <b>other</b> <b>studies</b> <b>that</b> <b>use</b> micro level data that is rarely available for many countries or over a period of time, the proposed modified Gini index could be calculated using just the regularly available data for each country. Such data includes the original Gini coefficient, government consumption expenditures, GDP and total tax revenue as a percentage of GDP. This modified version of the Gini index allows us to calculate the level of inequality more precisely, and make better comparisons between countries and over time...|$|E
40|$|This paper {{examines}} {{total factor}} productivity (TFP) growth of the Malaysian manufacturing sector from 1983 to 2005. Unlike previous studies that use one source of data. this research use two sources of data-Malaysian Input-Output tables and Malaysian industrial manufacturing Survey. The motivation for this study brought about due {{to the need to}} present a different method for estimating TFP growth by analysing TFP using the input-output methodology. The results from this study are compared with the results from <b>other</b> <b>studies</b> <b>that</b> <b>use</b> a different method to estimate TFP growth and the findings indicate that the TFP growth is relatively low. In addition, the major source of change in TFP of the manufacturing sector is contributed by intermediate inputs, while the contribution of labour and capital is substantially low...|$|E
5000|$|One of the {{problems}} is that the results of brain-imaging studies of self-knowledge vary depending on the behavioral tasks chosen. Some studies use positron emission tomography (PET) to do self-attribution of personality traits, while others use functional magnetic resonance imaging (fMRI). <b>Other</b> <b>studies</b> prefer to do tasks involving self-recognition (recognizing a photograph or yourself and <b>others).</b> <b>Studies</b> <b>that</b> <b>use</b> self-attribution <b>studies,</b> “find neural activation of the medial prefrontal cortex (MPFC) as evidence for the self”, while studies consisting of self-recognition tasks find, “correlated activation of the right prefrontal lobe and regions of the medial and left hemisphere as evidence self-awareness and self-knowledge." ...|$|R
30|$|Our {{results are}} {{compatible}} with <b>other</b> <b>studies</b> <b>that</b> <b>used</b> different methodologies. The thresholds for W/L vary significantly between intensivists in both adult and pediatric studies where hypothetical patient scenarios are presented [8, 9]. Medical residents perceive a difference in thresholds among their attending physicians in making W/L decisions [10]. Hospital characteristics {{are associated with the}} use of DNR orders, even after accounting for differences in patient characteristics; indeed, a tenfold difference in standardized rates of DNR across counties in California may reflect different institutional cultures [13]. In Europe, the frequency of DNR and W/L decisions varies markedly between and within countries [14, 15].|$|R
40|$|Abstract: This is {{a crucial}} {{transition}} time for human genetics in general, and for HIV host genetics in particular. After years of equivocal results from candidate gene analyses, several genome-wide association studies have been published that looked at plasma viral load or disease progression. Results from <b>other</b> <b>studies</b> <b>that</b> <b>used</b> various large-scale approaches (siRNA screens, transcriptome or proteome analysis, comparative genomics) have also shed new light on retroviral pathogenesis. However, most of the inter-individual variability in response to HIV- 1 infection remains to be explained: genome resequencing and systems biology approaches are now required to progress toward {{a better understanding of}} the complex interactions between HIV- 1 and its human host...|$|R
40|$|Abstract. Ground {{reaction}} forces generated during normal walking {{have recently been}} used to identify and/or classify individuals based upon {{the pattern of the}} forces observed over time. One feature that can be extracted from vertical ground {{reaction forces}} is body mass. This single feature has identifying power comparable to <b>other</b> <b>studies</b> <b>that</b> <b>use</b> multiple and more complex features. This study contributes to understanding the role of body mass in identification by (1) quantifying the accuracy and precision with which body mass can be obtained using vertical ground reaction forces, (2) quantifying the distribution of body mass across a population larger than has previously been studied in relation to gait analysis, and (3) quantifying the expected identification capabilities of systems using body mass as a weak biometric. Our results show that body mass can be measured in {{a fraction of a second}} with less than a 1 kilogram standard deviation of error...|$|E
40|$|Protection of the {{sensitive}} data {{is an important}} issue because of the fast development of applications that need exchange of the secret information over the Internet. Secret sharing is an idea proposed by Shamir and Blakley separately with different implementations in 1979. Lin and Tsai proposed a method that uses Steganography to create meaningful shares by using Shamir's secret sharing scheme in 2004. In recent years, researchers work to remove some of the weaknesses of this method. However, all of these methods need cover images four times bigger than the secret image. This arises two problems: increased storage and bandwidth need for shares. We used cover images with {{the same size as the}} secret image by using both Blakley's secret sharing approach and Steganography. Therefore, we achieved reduced storage and transmission bandwidth for shares. Besides, the proposed method creates meaningful shares by using Steganography instead of noise-like shares, different from <b>other</b> <b>studies</b> <b>that</b> <b>use</b> Blakley's approach...|$|E
40|$|I {{would like}} to thank my advisor Dr. Erkut Ozbay as well as Dr. John Straub, Dr. Andrew Sweeting, and Jongho Park for all of their help with my research. I {{would also like to thank}} “Game Show Network ” for {{providing}} the transcripts to all of the episodes of Catch 21 and to Scott Sternberg Productions for their insight into the casting and filming of the game show. 2 I describe whether high stakes risky decisions in the game show Catch 21 are more consistent with expected utility theory or prospect theory. The show permits for an analysis of two distinct decisions: the card placement decision and the stop/continue decision. I find evidence of reference dependence in both the card placement decision and the stop/continue decision. These findings suggest that the decisions on Catch 21 may be better explained by prospect theory than expected utility theory, which is consistent with the conclusions of <b>other</b> <b>studies</b> <b>that</b> <b>use</b> game show data...|$|E
40|$|This article {{describes}} how the four key concepts of the Bioecological Theory of Human Development (process, person, context and time) {{are present in the}} Ecological Engagement methodology. The goal is to provide some lines of action that may guide research teams to use this proposal in their projects. A brief comparison is performed between the Ecological Engagement and other methodologies, which value the concept of investigation and have distinct theoretical references. Moreover, <b>other</b> <b>studies</b> <b>that</b> <b>used</b> the Ecological Engagement are presented and discussed in order to establish some common points and to define aspects that may be considered as fundamental characteristics of this methodological proposal...|$|R
40|$|This is {{a crucial}} {{transition}} time for human genetics in general, and for HIV host genetics in particular. After years of equivocal results from candidate gene analyses, several genome-wide association studies have been published that looked at plasma viral load or disease progression. Results from <b>other</b> <b>studies</b> <b>that</b> <b>used</b> various large-scale approaches (siRNA screens, transcriptome or proteome analysis, comparative genomics) have also shed new light on retroviral pathogenesis. However, most of the inter-individual variability in response to HIV- 1 infection remains to be explained: genome resequencing and systems biology approaches are now required to progress toward {{a better understanding of}} the complex interactions between HIV- 1 and its human host...|$|R
30|$|The results {{generally}} {{indicate that}} the RHA at a low specific surface was reactive in concrete and 15  % of OPC could {{be replaced by the}} RHA without strength loss at a w/b ratio of 0.50. The optimum replacement level recorded in this <b>study</b> agrees with <b>other</b> <b>studies</b> <b>that</b> <b>used</b> RHA at a higher specific surface. The results also suggest that at the cement content used for this study, there is an optimum w/b ratio that would give maximum reactivity of the RHA in concrete that result in optimum replacement level. The compressive strength gains that were recorded for this <b>study</b> suggests <b>that</b> the reactivity that resulted in compressive strength increases were mainly due to the amorphous silica content of the RHA since the specific surface was low.|$|R
40|$|An {{analysis}} is given {{of the effect}} of market makers on liquidity using a transaction-level database. For this purpose, the focus is on a financial market where a change in regulations created explicitly the category of market maker in 1997 and that date is used to construct a pseudo-experiment. In contrast with <b>other</b> <b>studies</b> <b>that</b> <b>use</b> ultrahigh frequency data, the days to be analysed are selected using a statistical procedure to match observations before and after the change in regulation. The propensity score is used to perform the matching. After choosing the days, an estimate of an ordered probit model is made to explain the intraday behaviour of price changes. The coefficient estimates from the ordered probit model are used to calculate a measure of liquidity based on the steepness of the response function of price changes to volume. The results show that liquidity, measured in this way, has not been affected by the introduction of the market makers. market makers, change in regulations, ordered probit model, liquidity,...|$|E
40|$|In an {{increasingly}} knowledge based world, people {{are confronted with}} an explosion of information from the environment which must be viewed in restricted attention spans. Hence {{there is a need}} to investigate how best to model our Visual Attention (VA) with a view to allocate our attention efficiently. We use the color-word Stroop task combined with electroencephalogram (EEG) to model VA: subjects undertake the Stroop task and their EEG is recorded. This is in contrast to <b>other</b> <b>studies</b> <b>that</b> <b>use</b> techniques such as Event Related Potentials (ERP), Contextual Modeling Frameworks, eye movements and facial recognition. The paper presents a simple and useful model to recognize VA dynamically. We use the linear EEG features of different cortical fields as the main inference factors, and take the response time (RT) of the Stroop task as a metric to quantify subject performance. First, we obtain the most relevant EEG feature vectors from the recording, using a correlation analysis. Second, we use experimental data for training the VA model, using a regression method. Last, we then apply further experimental data to test the proposed model. The results from the tests conducted demonstrate that our model maps visual attention very closely. © 2013 IEEE...|$|E
40|$|Bacillary {{dysentery}} is {{an infectious}} disease caused by Shigella dysenteriae, {{which has a}} seasonal distribution. External environmental factors, including climate, {{play a significant role}} in its transmission. This paper identifies climate-related risk factors and their role in bacillary dysentery transmission. Harbin, in northeast China, with a temperate climate, and Quzhou, in southern China, with a subtropical climate, are chosen as the study locations. The least absolute shrinkage and selectionator operator is applied to select relevant climate factors involved in the transmission of bacillary dysentery. Based on the selected relevant climate factors and incidence rates, an AutoRegressive Integrated Moving Average (ARIMA) model is established successfully as a time series prediction model. The numerical results demonstrate that the mean water vapour pressure over the previous month results in a high relative risk for bacillary dysentery transmission in both cities, and the ARIMA model can successfully perform such a prediction. These results provide better explanations for the relationship between climate factors and bacillary dysentery transmission than those put forth in <b>other</b> <b>studies</b> <b>that</b> <b>use</b> only correlation coefficients or fitting models. The findings in this paper demonstrate that the mean water vapour pressure over the previous month is an important predictor for the transmission of bacillary dysentery...|$|E
40|$|This study {{compared}} 4, 594 {{student responses}} {{from three different}} sur,-eys of incoming students at the University of South Florida (USF) with data from Florida's State University System (SUS) admissions files to determine what proportion of error occurs in the survey responses. Specifically, the study investigated the amount of measurement error in student responses to questions about application and admission activities to universities {{other than the one}} at which they were enrolling. A literature review is included that examines the problem of measurement error in <b>other</b> <b>studies</b> <b>that</b> <b>used</b> survey or self-report measures. The <b>study</b> found <b>that</b> considerable measurement error can exist in self-report measures even when a subject is reporting simple factual information; in this case the level of unbiased error was about 4 percent, and biased error was about 20 percent. The amount of error was directly proportional t...|$|R
3000|$|Source process {{analysis}} by Grandin et al. (2015) is most similar {{in terms of}} datasets. The difference between their and our resulting slip distribution is that over 4  m slip area expanded to about 50  km east of Kathmandu is only seen in Grandin et al. (2015). This slip {{can be observed in}} <b>other</b> <b>studies</b> <b>that</b> <b>used</b> InSAR data (Feng et al. 2015; Galetzka et al. 2015; Hayes et al. 2015; Kobayashi et al. 2015; Lindsey et al. 2015; Wang and Fialko 2015); however, Avouac et al. (2015) also used InSAR data, and their resulting slip distribution does not show the slip in question. This is probably because one of the two InSAR images used by Avouac et al. (2015) does not cover the eastern region of Kathmandu. As mentioned previously, the M 6.1 and M [...]...|$|R
40|$|This study investigates how the {{implementation}} of Enterprise Risk Management program affects the performance of firms using an Enterprise Risk Management model for the banking sector and an integrated model for measuring Enterprise Risk Management index {{used in the study}} by Mukhtar and Soliman (2016). Ten listed commercial banks were selected with the Enterprise Risk Management index as the main independent variable, with Return on Average Equity (ROAE), Share Price Return (SPR) and Firm Value (FV) used as three separate dependent variables. The study provides strong evidence of a positive relationship between Enterprise Risk Management implementation and performance in the Nigerian banking sector. The findings and conclusions of this study are consistent with those of <b>other</b> <b>studies</b> <b>that</b> <b>used</b> data from different industries, providing a basis from which to generalize the findings from this study to firms in other industries...|$|R
40|$|The SHE assay (pH 6. 7) {{is being}} {{considered}} as a ? 3 Rs? alternative in animal laboratory studies (1). We have previously developed a protocol to conduct Fourier-transform infrared spectroscopy in the Syrian hamster embryo (FTIRS-SHE) experiments, and corresponding software {{to build up a}} FTIRS-SHE database. Subsequently, we applied machine learning and statistical methods to analyse our datasets towards chemical-treatment classification, morphological transformation classification, and extraction of biomarkers (i. e. spectral wavenumbers) related to chemical treatment (2). In the present study, we set out to validate and develop further our biomarker extraction techniques. Biomarker validation is of extreme importance, for it was found that depending on different biomarker extraction methods (i. e. computational algorithms), there was marked variability in the subsequently identified discriminating biomolecular entities and this would inevitably give rise to different mechanistic interpretations. Furthermore, currently a number of techniques used for such biomarker extraction purposes employed in a variety of fields were never initially conceived with this intention. In this work, we compare different techniques used to extract biomarkers and present rationales for their possible disagreement. We recommend an analysis framework that can derive robust biomarkers for the FTIRS-SHE assay based on pattern classification. The application of our framework can be extended to <b>other</b> <b>studies</b> <b>that</b> <b>use</b> FTIR or Raman spectroscopy. This work was funded by Unilever and the SHE assays were conducted at BioReliance, USA...|$|E
40|$|We {{describe}} two retroviral vector-based recombination substrate systems {{designed to}} assay for lymphoid VDJ recombinase activity in cultured cells. Both substrates incorporate a constitutive dominant marker gene (the simian virus promoter-driven neo gene) to allow selection of cells that stably integrate the substrate. Both substrates {{also include a}} second marker gene that becomes transcriptionally active only when inverted by a site-specific recombination event between flanking immunoglobulin variable-region gene segments. The first vector, similar in structure to previous retrovirus-based recombination substrates, utilizes the bacterial guanine-xanthine phosphoribosyltransferase gene (gpt) as its activatable marker; detection of inversion (VDJ recombinase activity) involves drug selection and Southern blotting analyses. We have used this vector to make a more extensive and quantitative survey of VDJ recombinase activity in B-lineage cell lines than has previously been performed with stable substrates, and we have compared our results with those of <b>other</b> <b>studies</b> <b>that</b> <b>use</b> transient recombination substrates. In the second vector, the activatable gene is the bacterial beta-galactosidase gene (lacZ). Detection for inversional activation of this gene is achieved by a fluorogenic assay, termed FACS-Gal, that detects beta-galactosidase activity in viable cells. The latter assay has the unique advantage of rapidly detecting cells that undergo recombination and also allows viable sorting of cells {{on the basis of}} the presence or absence of VDJ recombinase activity. We have used the lacZ vector to rapidly quantitate VDJ recombinase activity in B-lineage cell lines and compared the results with those obtained with the gpt vector. (ABSTRACT TRUNCATED AT 250 WORDS...|$|E
40|$|Title: A {{study of}} “Situational followership”. Level: Final {{assignment}} for Bachelor Degree in Business AdministrationAuthor: Lykke SilfwerbrandSupervisor: Jonas KågströmDate: 2011 – JanuaryAim: This study {{looks at the}} new concept: “situational followership”. It discusses how followership and leadership are connected and takes {{the approach of the}} follower. The study mainly looks into the following questions: · How can situational followership can be described? · What is the most important parameter for a follower? · Does the choice of leader differ according to the situation? · How is situational leadership and situational followership connected?Method: This is a qualitative study with ten respondents. The voluntary engaged respondents are representing two different organizations. In interviews follower-situations are discussed in depth and the respondents also asses their impression of each situation. The analysis of the data takes a qualitative approach to interpret the situations discussed. Result & Conclusions: The results point out that followership is to make a decision to follow a leader in a specific situation. A follower wants to feel safe and secure with the leader and with the situation. The leader must want to lead. Suggestions for future research: This study should be widened with a larger number of respondents in order to verify the result. <b>Other</b> <b>studies</b> <b>that</b> <b>use</b> the perspective of the follower rather than the leader would broaden the understanding of the leader-follower relation. Contribution of the thesis: This study has contributed to understanding how voluntary followers understands their role and their relation to the leader. Key words: Situational leadership, situational followership, Sense Of Coherence, SDT, motivation, qualitative study. ...|$|E
40|$|Insecticide {{resistance}} (IR) monitoring is {{an important}} component of vector-borne disease control. The last assessment of IR in Papua New Guinea (PNG) was conducted in 2010. Since then, vector populations have been exposed to higher levels of pyrethroids with the continued nation-wide distribution of insecticide-treated nets. Here, we provide an update on phenotypic IR in four highly malaria-endemic areas of PNG. IR against detamethrin, lambda-chyalothrin, and dichlorodiphenyltrichloroethane was assessed using World Health Organization bioassays. A total of 108 bioassays for each insecticide were conducted screening 2, 290 adult female anopheline mosquitoes. No phenotypic resistance was observed. Bioassay parameters agreed well with those observed in <b>other</b> <b>studies</b> <b>that</b> <b>used</b> the same assays and insecticides. These results indicate that the three tested insecticides are still universally effective in PNG. Continued IR monitoring (every 1 - 2 years) in PNG is recommended to detect reduced susceptibility early and adjust guidelines to prevent widespread resistance...|$|R
30|$|Recently, {{sparsity}} constraints {{have been}} introduced into geodetic inversions (e.g., Evans and Meade 2012). Sparse modeling {{is a form of}} statistical analysis for solving a problem by introducing the sparsity of the solution as a priori information. Evans and Meade (2012) applied the absolute value (L 1) regularization approach (Tibshirani 1996) to the coseismic slip and afterslip of the 2011 Tohoku-Oki earthquake for geodetic data inversion. Using onshore GNSS observational data, compact and sharply varying afterslip distributions along the coast were obtained, and the slip areas were significantly different from <b>other</b> <b>studies</b> <b>that</b> <b>used</b> a smoothness constraint (e.g., Iinuma et al. 2012; Ozawa et al. 2012; Yamagiwa et al. 2015). The maximum slip estimated using a sparsity constraint was comparable to <b>other</b> <b>studies.</b> However, we have questions regarding the application of other shapes of slip distribution, because the estimated maximum slip was 1.7 times greater than the input value in a resolution test with a ring-shaped input slip distribution (Evans and Meade 2012).|$|R
30|$|Unfortunately, {{there are}} no <b>other</b> <b>studies</b> for {{comparison}} <b>that</b> <b>used</b> nebulization of a long-acting LA during gynecological laparoscopy. Nevertheless, nebulization of a long-acting LA did decrease postoperative pain following laparoscopic cholecystectomy [22].|$|R
40|$|The {{wind power}} sector has grown rapidly {{and has become}} a {{substantial}} part of the global sustainable energy production. Performance and condition monitoring systems are gaining ground, but most faults are still detected during planned maintenance. This can lead to long time periods of underperformance, which translates to lost revenues. In this thesis, Artificial Neural Networks (ANN) are used to model the normal behaviour of a wind turbine, which could be used for real-time monitoring of operations. A number of <b>other</b> <b>studies</b> <b>that</b> <b>use</b> ANN’s to predict wind power output were found during the literature study; but this thesis presents a new direction where the standard deviation of the wind speed is used as an input to the model, as well as a multi-dimensional filtering method, meant to exclude outliers in the training set with higher accuracy than conventional filtering techniques. The study follows the method of (Schlechtingen, et al., 2013 a), who made a comparative study of different data-mining approaches, to be able to compare the model results. The proposed model shows an improvement in prediction performance of between 16 % and 22 %, depending on performance parameter. The results from the multi-dimensional filtering shows that unhealthy data situated inside what is conventionally thought of as normal operating range can be excluded with the proposed method. It is concluded that the model is well suited for performance monitoring, but its applicability to fault prediction could ultimately not be concluded {{due to a lack of}} suitable faults during the period. Finally, it is concluded that if the proposed model had been used for performance monitoring in the turbine that was the main subject in this study, earlier maintenance could have resulted in an additional electricity generation of up to 270 MWh during the three years of data used...|$|E
40|$|Lack of {{knowledge}} about the values of ice sheet model input parameters introduces substantial uncertainty into projections of Greenland Ice Sheet contributions to future sea level rise. Computer models of ice sheet behavior provide one of several means of estimating future sea level rise due to mass loss from ice sheets. Such models have many input parameters whose values are not well known. Recent studies have investigated the effects of these parameters on model output, but the range of potential future sea level increases due to model parametric uncertainty has not been characterized. Here, we demonstrate that this range is large, using a 100 -member perturbed-physics ensemble with the SICOPOLIS ice sheet model. Each model run is spun up over 125 000 yr using geological forcings and subsequently driven into the future using an asymptotically increasing air temperature anomaly curve. All modeled ice sheets lose mass after 2005 AD. Parameters controlling surface melt dominate the model response to temperature change. After culling the ensemble to include only members that give reasonable ice volumes in 2005 AD, the range of projected sea level rise values in 2100 AD is ~ 40 % or more of the median. Data on past ice sheet behavior can help reduce this uncertainty, but none of our ensemble members produces a reasonable ice volume change during the mid-Holocene, relative to the present. This problem suggests that the model's exponential relation between temperature and precipitation does not hold during the Holocene, or that the central-Greenland temperature forcing curve used to drive the model is not representative of conditions around the ice margin at this time (among other possibilities). Our simulations also lack certain observed physical processes that may tend to enhance the real ice sheet's response. Regardless, this work has implications for <b>other</b> <b>studies</b> <b>that</b> <b>use</b> ice sheet models to project or hindcast the behavior of the Greenland Ice Sheet...|$|E
40|$|Background: Polycystic ovary {{syndrome}} (PCOS) is {{a common}} complex hormonal disorder. Many PCOS symptoms may have implications on bone mineral density (BMD). One way to analyze BMD is quantitated computed tomography (QCT), which may have advantages over other BMD analysis methods. The study analyzed descriptive characteristics {{of a group of}} PCOS cases and controls; considered the determinants of BMD (as measured by QCT) from the literature in PCOS cases and controls; and adjusted for these variables via multivariate logistic regression to determine if PCOS case status is an independent predictor of lumbar BMD after controlling for these factors. Methods: The study used women from the third implementation of the University of Pittsburgh Cardiovascular Health and Risk Management study (CHARM III). Descriptive information was gathered by survey and clinical visits and blood samples were taken to measure hormones and other biological factors. Lumbar BMD was measured by QCT in a subset of women. Student's T-Test, the Mann-Whitney U-Test and X 2 tests were used to evaluate descriptive characteristics of PCOS cases and controls. BMD measures between PCOS case and controls were compared using Student's T-test. Lumbar BMD comparisons between PCOS cases and controls were also stratified by factors determined from the literature to affect BMD, including age, ethnicity, menstrual period status, BMI, and menstrual history. Correlations of BMD with hormones in cases and controls were considered. Multivariate linear regression models were used to assess the effect of PCOS case-control status on lumbar BMD after controlling for these factors associated with BMD. Results: There was no significant BMD difference between PCOS cases and controls for any univariate comparisons, nor for any multivariate adjusted compositions. Conclusion: The deleterious effects of middle age and approaching menopause and the protective effects of heavy BMI in controls may mediate some protective effects of PCOS case status on BMD in this group. Statement of Public Health Significance: The current study is one of only a few to use QCT to measure BMD in women with PCOS. Results from this study can serve as the basis of comparison for <b>other</b> <b>studies</b> <b>that</b> <b>use</b> QCT methods to assess BMD...|$|E
30|$|When non-threaded {{pins and}} wires were used, the neck {{commonly}} {{continues to grow}} {{and this would be}} a great advantage. However, stabilisation using multiple pins was not found to provide advantages over pinning using a single screw, with substantially higher AVN, CL, FAI and OA rates. Moreover, with continued growth there is a risk that the anchorage in the epiphysis will be lost and repeat fixation will be required. Further growth of the femoral neck is less likely to occur if a screw is inserted in compression mode with the head abutting the lateral femoral cortex, causing physiodesis [73]. Three studies [23, 54, 55] showed that screws with special design allowed growth to continue; however, these were small studies (37 patients) with no comparator. The literature search identified 6 <b>other</b> <b>studies</b> <b>that</b> <b>used</b> screws which allow continued growth and reported a favourable outcome on neck growth; however, these studies could not be included in our review because we were not certain about the stability of the slips.|$|R
30|$|One of {{the main}} {{advantages}} of analysing accessibility levels and its determinants using index number theory is {{that this type of}} approach allows comparability with <b>other</b> <b>studies</b> <b>that</b> may <b>use</b> the same methodology in other places and times. In addition, we improve the methodology to accurately measure the change in accessibility and provide a consistent decomposition of these changes, which allows us to draw conclusions on the precise effects of transport infrastructure and population determinants.|$|R
30|$|A {{temporal}} variation of RTM at an almost equidistant point from the 2015 Off Satsuma Peninsula earthquake and the 2016 Kumamoto mainshock {{showed a significant}} decrease prior to the occurrence of both (Fig.  2 a, see also Table A 1 in Additional file 1). A deviation from the background level started at 2014.8  years for mid-October 2014, and the strongest deviation in 2015.8  years for mid-October 2015 was about − 20. During the critical period, the R, T, and M functions attained values of about − 2.5 to − 3.0. During a recovery stage from the quiescence to the background level, the 2015 Off Satsuma Peninsula earthquake and the 2016 Kumamoto mainshock occurred. This property is similar to <b>that</b> documented by <b>other</b> <b>studies</b> <b>that</b> <b>used</b> the RTL-/RTM-algorithm (e.g., Sobolev and Tyupkin 1997, 1999; Huang and Nagao 2002; Huang 2004, 2006; Nagao et al. 2011; Sobolev 2011). Since the RTM-algorithm is statistical and nonlinear, {{we were unable to}} identify which of earthquakes contributed to the recovery stage; this topic {{is beyond the scope of}} our work in this paper.|$|R
