8|37|Public
25|$|Report {{taken from}} No. 35 Squadron <b>Operational</b> <b>log.</b>|$|E
2500|$|Most serious {{competitive}} stations log their contest contacts using contest logging software, {{although some}} {{continue to use}} paper and pencil. [...] There are many different software logging programs written specifically for radio contesting. [...] Computer logging programs can handle many additional duties besides simply recording the log data; they can keep a running score based upon the formula of the contest, track which available multipliers have been [...] "worked" [...] and which have not, and provide the operator with visual clues about how many contacts are being made on which bands. Some contest software even provide a means to control the station equipment via computer, retrieve data from the radio and send pre-recorded morse code, voice or digital messages. [...] After {{the conclusion of a}} contest, each station must submit its <b>operational</b> <b>log</b> to the contest sponsor. [...] Many sponsors accept logs by e-mail, by upload on web sites, or even by postal mail.|$|E
5000|$|<b>Operational</b> <b>Log</b> - Records events {{related to}} vessel operation, i.e. performance, cargo {{handling}} and maritime operations. The <b>Operational</b> <b>Log</b> will typically need some customisation to owner's requirement and trade.|$|E
50|$|Documentation {{include such}} as {{feasibility}} report, technical documentation, <b>operational</b> documentation, <b>log</b> book, etc.|$|R
40|$|Data occurs {{naturally}} as sequences in a {{wide variety}} of applications, such as system call logs in a computer, biological sequences, <b>operational</b> <b>logs</b> of an aircrafts’s flight, etc. In several such domains, anomaly detection is required to detect events of interests as anomalies. There has been extensive research done on anomaly detection techniques [Chandola et al. 2008; Hodge and Austin 2004; Lazarevic et al. 2003], but most of thes...|$|R
30|$|The {{targeted}} works {{presented in}} this section provide empirical support to further explore and develop novel Deep Learning algorithms and architectures for analyzing large-scale, fast moving streaming data, as is encountered in some Big Data application domains such as social media feeds, marketing and financial data feeds, web click stream data, <b>operational</b> <b>logs,</b> and metering data. For example, Amazon Kinesis is a managed service designed to handle real-time streaming of Big Data – {{though it is not}} based on the Deep Learning approach.|$|R
50|$|Report {{taken from}} No. 35 Squadron <b>Operational</b> <b>log.</b>|$|E
50|$|Its product AI WORKS {{operates}} {{by offering}} every employee a personal assistant. AI WORKS studies and analyzes {{vast amount of}} <b>operational</b> <b>log</b> data generated from daily operations and makes intelligent predictions based on {{the task at hand}} and user’s position. Currently Works Applications market share is number 1 in Japan.|$|E
5000|$|Most serious {{competitive}} stations log their contest contacts using contest logging software, {{although some}} {{continue to use}} paper and pencil. There are many different software logging programs written specifically for radio contesting. Computer logging programs can handle many additional duties besides simply recording the log data; they can keep a running score based upon the formula of the contest, track which available multipliers have been [...] "worked" [...] and which have not, and provide the operator with visual clues about how many contacts are being made on which bands. Some contest software even provide a means to control the station equipment via computer, retrieve data from the radio and send pre-recorded morse code, voice or digital messages. After {{the conclusion of a}} contest, each station must submit its <b>operational</b> <b>log</b> to the contest sponsor. Many sponsors accept logs by e-mail, by upload on web sites, or even by postal mail.|$|E
5000|$|Evolven is a {{technology}} company that provides IT Operations Analytics (ITOA) solutions for enterprise businesses. Founded in 2007, Evolven is headquartered in Jersey City, New Jersey, USA, {{with offices in}} Europe and Israel. Evolven sells enterprise software that apply the IT Operations Analytics (ITOA) approach, offering [...] "change centric, blended analytics." [...] This means that once the system has learned from examining the systems, their <b>operational</b> <b>logs</b> and the current state, it's then possible to apply machine learning/analytics to evaluate changes made to the environment.|$|R
2500|$|Radio {{contests}} are principally {{sponsored by}} amateur radio societies, radio clubs, or radio enthusiast magazines. [...] These organizations publish {{the rules for}} the event, collect the <b>operational</b> <b>logs</b> from all stations that operate in the event, cross-check the logs to generate a score for each station, and then publish the results in a magazine, in a society journal, or on a web site. [...] Because the competitions are between stations licensed in the Amateur Radio Service (with the exception of certain contests which sponsor awards for shortwave listeners), which prohibits the use of radio frequencies for pecuniary interests, there are no professional radio contests or professional contesters, and any awards granted by the contest sponsors are typically limited to paper certificates, plaques, or trophies.|$|R
40|$|Dealing {{with large}} volumes of logs is like the prover- bial needle in the haystack problem. Finding {{relevant}} events that might be associated with an incident, or real time analysis of <b>operational</b> <b>logs</b> is extremely difficult when the underlying data volume is huge and when no explicit misuse model exists. While domain-specific knowledge and human expertise {{may be useful in}} analysing log data, automated approaches for detecting anomalies and track incidents are the only viable solutions when confronted with {{large volumes of}} data. In this paper we address the issue of automated log analysis and consider more specifically the case of ISP-provided firewall logs. We leverage approaches derived from statistical process control and information theory in order to track potential incidents and detect suspicious network activity...|$|R
40|$|Abstract. With {{continuing}} {{security concerns}} for airport operations, the protec-tion of internal operational protocols {{of an international}} airport has become more critical than ever before. Therefore, the Information Security System (ISS) was developed for Incheon International Airport which can protect the critical information related to airport operations. The developed ISS includes a document access control server/client agent, a user access control service linker, and an <b>operational</b> <b>log</b> file database. The ISS was developed in consideration of information life cycle of airport workflow. As a result, it can securely protect the computer system at Incheon International Airport by (1) performing real-time encoding of the users who accessed the protected files and folders, (2) lim-iting the user’s capability to edit the protected documents, (3) tracking transmit-ted files to the outside companies, (4) blocking the user’s access to portable storage devices, and (5) inserting security water marks on the printed outputs. With {{the implementation of the}} ISS, the real-time information system audit en-vironment has been securely established at the Incheon International Airport Corporation...|$|E
40|$|This {{research}} project provides guidelines for biogas operators, planners and manufacturers with tangible suggestions for improvements in ecology and economy. In {{order to achieve}} this, 10 biogas plants in Bavaria (Germany) with an electric capacity from 30 kWel to 560 kWel are thoroughly analysed and evaluated. Within this project, first a widespread data analysis is made. The analysis contains e. g. measuring the parasitic electric energy or detecting methane leaks. Also the <b>operational</b> <b>log</b> of the biogas plants is analysed with respect to feedstock, down times, labour times and maintenance. 3 The next step of this project is {{the evaluation of the}} generated data. For this purpose, key performance indicators are used to carry out a benchmark and error analysis. Knowing the problems of biogas plants, finally leads to the development of optimization concepts. Eight approaches are generated to improve the plants` ecology and economy. The project proves that ecology and economy can very well go together. By reducing methane emissions of biogas plants more biogas can be used in the CHP-Unit. This causes a better ecologic situation by reducing greenhouse gas emissions. Moreover, less feedstock has to be put into the biogas plants while having the same output. Using less feedstock means less current costs...|$|E
50|$|Radio {{contests}} are principally {{sponsored by}} amateur radio societies, radio clubs, or radio enthusiast magazines. These organizations publish {{the rules for}} the event, collect the <b>operational</b> <b>logs</b> from all stations that operate in the event, cross-check the logs to generate a score for each station, and then publish the results in a magazine, in a society journal, or on a web site. Because the competitions are between stations licensed in the Amateur Radio Service (with the exception of certain contests which sponsor awards for shortwave listeners), which prohibits the use of radio frequencies for pecuniary interests, there are no professional radio contests or professional contesters, and any awards granted by the contest sponsors are typically limited to paper certificates, plaques, or trophies.|$|R
40|$|At HP Labs, we are {{building}} “Live Operational Intelligence (Live OI) System ” – a system that ingests streams of operational data generated by multiple sources such as sensors and <b>operational</b> <b>logs,</b> and provides the operational staff real time insights in terms of suggested actions, event correlations, predictions, root cause analysis and visualization. In a Live OI framework some models are learnt offline and then deployed online, and some models are learnt online. Live OI system also supports querying of historical data to find past occurrences of patterns and suggested actions, and a dashboard for humans to monitor and interact with the operational system. This paper describes {{the highlights of the}} Live OI system as applied to monitoring oil production operation, through the discussion of use cases. 1...|$|R
40|$|How can we {{increase}} the recourse to forest biomass usable for energy production around the Mediterranean Rim {{in a way}} that is sustainable economically, environmentally and socially? This was the many-facetted issue tackled by the eighteen partners involved in the Proforbiomed project. Superimposed on the European and global context of converting to new sources of energy and their sustainable development are more local issues: sustainable local use, pressures on the resource, the introduction of the products onto pre-existing markets [...] . In order to respond in the most exhaustive manner possible, various slutions were tested and improved: reducing production costs through improvements to existing <b>operational</b> <b>logging</b> techniques, trials of new equipment, enhanced contacts with forest landowners, stugies for new installations of heating furnaces [...] . This article presents a summary of the partners’ main activities...|$|R
40|$|Abstract: Backbone {{networks}} must {{be highly}} reliable. The offered availability can be predicted prior to operation if the stochastic behaviour of network components is known. The {{aim of this}} paper is provide information about failures and repairs processes in an <b>operational</b> network. <b>Operational</b> <b>logs</b> from UNINETT’s core network were analysed to obtain distributions of the time between failures and downtimes of routers and links. The network components were classified according to their role in the network. The measured processes were fit with well-known distributions. The inter-failure times of routers and short distance links may be characterised by a Weibull distribution, but for the long distance links the gamma distribution yielded a better characterisation. The difference is discussed based on the hazard function. The parameters of each network component are made available and provide a detailed insight that may be used for dependability predictions and research...|$|R
40|$|Abstract—NoSQL {{systems have}} grown in {{popularity}} for storing big data because these systems offer high availability, i. e., operations with high throughput and low latency. However, metadata in these systems are handled today in ad-hoc ways. We present Wasef, a system that treats metadata in a NoSQL database system, as first-class citizens. Metadata may include information such as: operational history for a database table (e. g., columns), placement information for ranges of keys, and <b>operational</b> <b>logs</b> for data items (key-value pairs). Wasef allows the NoSQL system to store and query this metadata efficiently. We integrate Wasef into Apache Cassandra, {{one of the most}} popular key-value stores. We then implement three important use cases in Cassandra: dropping columns in a flexible manner, verifying data durability during migrational operations such as node decommissioning, and maintaining data provenance. Our experimental evaluation uses AWS EC 2 instances and YCSB workloads. Our results show that Wasef: i) scales well with the size of the data and the metadata; ii) minimally affects throughput and operation latencies. 1...|$|R
40|$|This article aims to {{evaluate}} the use of techniques of decision trees, in conjunction with the management model CRISP-DM, to help in the prevention of bank fraud. This article offers a study on decision trees, an important concept in the field of artificial intelligence. The study is focused on discussing how these trees are able to assist in the decision making process of identifying frauds by the analysis of information regarding bank transactions. This information is captured with the use of techniques and the CRISP-DM management model of data mining in large <b>operational</b> databases <b>logged</b> from internet bank transactions...|$|R
40|$|The {{objective}} {{here was}} to investigate the theoretical benefit of using tree species stratum forest inventory data instead of stand-level mean data in forest-planning simulations. This comparison was based on timing differences in thinning and clear-cuttings during a 20 -year simulation period. The development of stand characteristics (age, basalarea, volume, dominant height, mean height, mean diameter) in those stands not harvested during the simulation period was also scrutinized. The calculations were performed with SIMO simulation and optimization software. In all 245 treewise measured circular plots established in 2007 {{in the vicinity of the}} Evo Forest Station, Finland, were used as study material. The results show that the use of tree species stratum data in forest-planning simulations is highly relevant from the viewpoint of both the development of stand characteristics and the timing of logging operations. The relative standard errors stemming from the level of input data varied from 2. 1 % to 20. 6 % and from 58 % to 84 % in stand characteristics and timing of logging operations, respectively. The significance of the stratumwise input data culminated in the functioning of the specieswise growth models at different stages of stand development. The results can be utilized in assessing the suitability of airborne laser scanning-based estimation methodologies in integrating detailed forest inventory with forest planning and <b>operational</b> <b>logging</b> planning. Keywords:Airborne laser scanning (ALS), forest management planning, simulation, tree species detection, tree species stratu...|$|R
40|$|Observing {{failures}} and other – desired or undesired – behavior patterns in large scale software systems of specific domains (telecommunication systems, information systems, online web applications, etc.) is difficult. Very often, {{it is only}} possible by examining the runtime behavior of these systems through <b>operational</b> <b>logs</b> or traces. However, these systems can generate data in order of gigabytes every day, which makes a challenge to process {{in the course of}} predicting upcoming critical problems or identifying relevant behavior patterns. We can say that there is a gap between the amount of information we have and the amount of information we need to make a decision. Low level data has to be processed, correlated and synthesized in order to create high level, decision helping data. The actual value of this high level data lays in its availability at the time of decision making (e. g., do we face a virus attack?). In other words high level data has to be available real-time or near real-time. The research area of event processing deals with processing such data that are viewed as events and with making alerts to the administrators (users) of the systems about relevant behavior patterns based on the rules that are determined in advance. The rules or patterns describe the typical circumstances of the events which have been experienced by the administrators. Normally, these experts improve their observation capabilities over time as they experience more and more critical events and the circumstances preceding them. However, {{there is a way to}} aid this manual process by applying the results from a related (and from many aspects, overlapping) research area, predictive analytics, and thus improving the effectiveness o...|$|R
30|$|In this study, {{we propose}} {{a system that}} {{automatically}} switches application volume ON or OFF for Android smartphones via machine learning techniques using users’ lifelogs. Furthermore, application volume can be set differently from ringtone volume on Android smartphone. There are two key reasons why we focused on application volume. First, application volume is not associated with silent mode preference, whereas ring tone volume is connected with silent mode preference. More specifically, unless application volume is set to zero, the smartphone makes noise even if the silent mode preference is set to silent, and this is uncomfortable for an inexperienced smartphone user. Second, there are users who adjust application volume {{on a regular basis}} without switching their silent mode preferences. In our experiment, five out of nine subjects adjusted application volume on a regular basis, but only one subject switched silent mode preference on a regular basis. Our nine subjects were composed of postgraduates, undergraduates and office workers. Because of the small number of subjects, we cannot be certain that most smartphone users do not switch silent mode preferences on a regular basis: however, users who do not set silent mode preferences do tend to adjust application volume on a regular basis. For this study, focusing on the volume settings of a smartphone, we propose an intelligent system that automatically sets suitable application volume by first learning a user’s ordinary volume setting patterns. Because an automatic application volume setting system prevents the smartphone from suddenly making noise, we achieve improved smartphone usability. Our proposed system runs in the background of an Android smartphone, constantly records terminal <b>operational</b> <b>logs,</b> and learns from these recorded logs. While changing foreground applications, a suitable application volume is estimated and automatically set. In general, application volume can be set to one of sixteen-gradations; however, proposed system estimates whether application volume is ON or OFF as the first step because the objective {{of this study is to}} prevent extreme negative influence for users and disturbance to their surroundings.|$|R
40|$|Abstract—Nowadays, an {{increasing}} number of systems needs to be kept running for long periods without showing failures, but several factors compromise their correct behavior during the <b>operational</b> phase. <b>Logs</b> play a key role to address dependability issues of current systems and to enable proactive actions against failures (e. g., proactive maintenance, failure prediction). Never-theless, they may lack any information in case of software faults, which escape the testing phase and are activated on the field by complex environmental conditions. In this paper, we evaluate built-in logging capabilities of a software system, namely the Apache Web Server, by means of an extensive software fault injection campaign. We experience that, in most of cases, software faults lead to failures without leaving any information in Apache logs. For this reason, we provide a few guidelines for developers that can be used during the development cycle, in order to improve the effectiveness of <b>logs</b> during the <b>operational</b> phase...|$|R
40|$|Lakvijaya {{power station}} {{is the first}} coal fired power station in Sri Lanka having an {{installed}} capacity of 300 MW. During 2012, it has supplied 18 % of the Sri Lankan energy demand. The availability factor of this power station in 2012 was 68. 8 %. This is rather high compared with the average availability factor of coal powered power stations in {{countries in the region}} falls between 65 % - 90 %. According to the contract document, the availability factor of this plant has been expected as 85 % [1]. However, there is a strong public opinion created by media that the plant is unreliable and prone to frequent failures. Therefore, any improvement in the availability of the power station will result in improving the public image as well as reducing overall costs spent on more expensive fuels. This research aims at critically analyzing the Auxiliary Systems of the power plant to identify their contribution to the reduction of plant availability and propose means of improving overall availability through increasing the reliability of auxiliary systems. Data related to outages were collected from plant <b>operational</b> <b>logs</b> and defect reportsfrom 22. 12. 2010 to 09. 06. 2012. Existing systems and layouts were studied referring to plant operation and maintenance manuals and by field observations. Analyzing thedata, it was found that failures and unsatisfactory performance in the auxiliary systems havecontributed to the low availability of the power plant by delaying re-starts after failures and reducing the plant capacity while in operation. Failures and problems in auxiliary systems such as The Sea Water Pre-Treatment System, De-salination System, De-mineralization System, Chlorination System and the Hydrogen Production and Storage System were critically analyzed during this research and improvements to the designs are proposed based on the results. The present availability factor of 21 % of the De-salination System can be improved to 91 % by carrying out the proposals made by this research. The availability factor of other systems too can be improved above 90 % using the results. Estimated total cost of the proposals is Rs. 543 Million. However, by implementing themRs. 2. 7 Billion is expected to be saved annually, by reducing the operating and maintenance costs of auxiliary systems and improving the availability of the power plant. Expected payback period is only 2 ½ months. Therefore, the proposed modifications are extremely desirable and cost effective. They will make a good financial contribution due to the expected savings while improving the reliability and the public image of the power plant...|$|R
40|$|In {{plants of}} the chemical, nuclear and {{off-shore}} industry, application specific high-alloyed steels {{are used for}} pipe fittings. Mixing of different steel grades can lead to corrosion with severe consequential damages. Growing quality requirements and environmental responsibilities demand a 100 per cent material control {{in the production of}} the pipe fittings. Therefore, LIFT, an automatic inspection machine, was developed to insure against any mix of material grades. LIFT is able to identify more than 30 different steel grades. The inspection method is based on Laser-Induced Breakdown Spectrometry (LIBS). An expert system, which can be easily trained and recalibrated, was developed for the data evaluation. The result of the material inspection is transferred to an external handling system via PLC interface. The duration of the inspection process is 2 seconds. The graphical user interface was developed with respect to the requirements of an unskilled operator. The software is based on a realtime operating system and provides a safe and reliable operation. An interface for the remote maintenance by modem enables a fast <b>operational</b> support. <b>Logged</b> data are retrieved and evaluated. This is the basis for an adaptive improvement of the configuration of LIFT with respect to changing requirements in the production line. Within {{the first six months of}} routine operation, about 50000 pipe fittings were inspected...|$|R
3000|$|The test {{application}} conducts experiments {{using the}} described setup. An experiment {{is defined by}} experiment parameters that consist of the router configuration (see Section Implementation of fault detection and isolation, Listing 1) for the CISes and CAN traffic patterns for each CTN. A CAN traffic pattern describes CAN message contents and message rates over the duration of an experiment (i.e., message rates may change during the progression of an experiment). A single execution of an experiment is called experiment run. By design, the MU controls the hardware reset of all CISes and takes care of (re)configuring them. After all components of the test framework are configured and <b>operational,</b> the MU <b>logs</b> minimum interarrival time and maximum interarrival time violations from the CISes. For the test framework, we realized the MU software to [...]...|$|R
40|$|Time {{studies of}} {{harvesting}} and skidding tree-length logs in Aleppo pine (Pinus halepensis L.) natural coastal forests of Chalkidiki area in northern Greece {{were carried out}} to formulate linear regression models and to evaluate productivity. The harvesting system consisted of a feller with chainsaw for felling, delimbing and crosscutting, and a four wheel drive farm tractor, with a 74 kW engine, equipped with a special winch attached to the tractor three point hitch for the extraction of tree length <b>logs.</b> <b>Operational</b> factors such as distance, slope, volume and the time required for harvesting and extracting tree length logs were measured and recorded. The results illustrate that the calibrated linear regression models show strong correlation between the time needed for harvesting operations and the extraction distance from the stump to the forest road...|$|R
40|$|The massive {{amount of}} alarm data {{generated}} from intrusion detection systems is cumbersome for network system administrators to analyze. Often, important details are overlooked {{and it is difficult}} to get an overall picture of what is occurring in the network by manually traversing textual alarm logs. We have designed a novel visualization to address this problem by showing alarm activity within a network. Alarm data is presented in an overview where system administrators can get a general sense of network activity and easily detect anomalies. They then have the option of zooming and drilling down for details. The information is presented with local network IP (Internet Protocol) addresses plotted over multiple yaxes to represent the location of alarms. Time on the x-axis is used to show the pattern of the alarms and variations in color encode the severity and amount of alarms. Based on our system administrator requirements study, this graphical layout addresses what system administrators need to see, is faster and easier than analyzing text logs, and uses visualization techniques to effectively scale and display the data. With this design, we have built a tool that effectively uses <b>operational</b> alarm <b>log</b> data generated on the Georgia Tech campus network. The motivation and background of our design is presented along with examples that illustrate its usefulness...|$|R
40|$|Abstract—Heavily script-based browser {{applications}} {{change the}} manner in which users interact with web browsers. Instead of downloading a succession of HTML pages, users download a single application and use that application {{for a long period of}} time. The application is not a set of HTML pages, but rather a single page that can possible modify its own presentation based on data exchanged with a server. In such an environment, it is necessary to provide some means for the client to manage its own state. We describe the initial results of our work in providing client-side state management services for these script-based applications. We focus on browser-based services that can help the user before any data is committed on the server. Our services include state checkpointing, property binding, operation <b>logging,</b> <b>operational</b> replay, ATOM/RSS data updates, and applicationcontrolled persistence...|$|R
40|$|This paper {{focuses on}} {{semantic}} issues that arise during non update querying of interoperating relational databases; the semantics are classified {{according to their}} location in a five layer information expressivity architecture. The system used {{as a case study}} is an <b>operational</b> engineering fault <b>logging</b> system which has been significantly modified to meet user requirements; however for tactical planning purposes information from the old and new systems need to be analysed together. This paper discusses the possible use of object oriented techniques and data models for the interoperation of relational database systems. 1 INTRODUCTION 1. 1 Theoretical Framework Coulomb and Orlowska [CouOrl 93] have shown that the assumption of design autonomy for database federations was flawed; it founders on semantic heterogeneity. Additional semantic information generally needs {{to be added to the}} schema to achieve interoperaton. They have identified version control as a key issue when schema definitio [...] ...|$|R
40|$|Abstract—Generally, fraud risk implies any {{intentional}} decep-tion {{made for}} financial gain. In this paper, we consider this {{risk in the}} field of services which support transactions with electronic money. Specifically, we apply a tool for predictive security analysis at runtime which observes process behavior with respect to transactions within a money transfer service and tries to match it with expected behavior given by a process model. We analyze deviations from the given behavior specification for anomalies that indicate a possible misuse of the service related to money laundering activities. We evaluate the applicability of the proposed approach and provide measurements on computational and recognition performance of the tool – Predictive Security Analyzer – produced using real <b>operational</b> and simulated <b>logs.</b> The goal of the experiments is to detect misuse patterns reflecting a given money laundering scheme in synthetic process behavior based on properties captured from real world transaction events. Keywords—money laundering; predictive security analysis; analysis of business process behavior; security modeling and simulation; security monitoring. I...|$|R
50|$|The 270th Engineering Installation Squadron was {{originally}} activated at Philadelphia International Airport, Philadelphia, Pennsylvania as the 603rd Signal Light Construction Company on April 12, 1949. Federal {{recognition of the}} unit was extended on May 17, 1949 when the unit’s manpower consisted of 2 officers and 11 Airmen. By Jan. 1, 1951, the unit reached strength of 5 officers and 86 Airmen. When the 111th Bombardment Group, the unit’s Pennsylvania Air National Guard host, was mobilized on April 10, 1951 for the Korean War, the 603rd was left as the only Air Guard unit in Philadelphia. Due to {{the large amount of}} military air traffic in the area, one officer and six Airmen were placed on permanent duty with a mission to refuel and service military aircraft; maintain <b>operational</b> service and <b>logging</b> record on a 24-hour, 7 day per week basis. The wire construction mission continued with the unit winning several awards for military professionalism.|$|R
40|$|The {{inclusion}} of interlinked {{temporal and spatial}} elements within integrated sensor data enables a tremendous degree of flexibility when analyzing multi-component datasets. The presentation illustrates how to warehouse, process, and analyze high-resolution integrated sensor datasets to support complex system analysis at the entity and system levels. The example cases presented utilizes in-vehicle sensor system data to assess vehicle performance, while integrating a map matching algorithm to link vehicle data to roads to demonstrate the enhanced analysis possible via interlinking data elements. Furthermore, {{in addition to the}} flexibility provided, the examples presented illustrate concepts of maintaining proprietary operational information (Fleet DNA) and privacy of study participants (Transportation Secure Data Center) while producing widely distributed data products. Should real-time <b>operational</b> data be <b>logged</b> at high resolution across multiple infrastructure types, map matched to their associated infrastructure, and distributed employing a similar approach; dependencies between urban environment infrastructures components could be better understood. This understanding is especially crucial for the cities of the future where transportation will rely more on grid infrastructure to support its energy demands...|$|R
40|$|We {{consider}} hierarchical systems where nodes represent entities and edges represent binary {{relationships among}} them. An {{example is a}} hierarchical composition of Web services where the nodes denote services and edges represent the parent-child relationship of a service invoking another service. A fundamental issue to address in such systems is, for two nodes X and Y in the hierarchy whether X can see Y, that is, whether X has visibility over Y. In a general setting, X seeing Y may depend on (i) X wishing to see Y, (ii) Y wishing {{to be seen by}} X, and (iii) other nodes not objecting to X seeing Y. The visibility could be with respect to certain attributes like <b>operational</b> details, execution <b>logs,</b> security related issues, etc. In this paper, we develop a generic conceptual model to express visibility. We study two complementary notions: sphere of visibility of a node X that includes all the nodes in the hierarchy that X can see; and sphere of noticeability of X that includes all the nodes that can see X. We also identify dual properties, coherence and correlation, that relate the visibility and noticeability notions, and study their variants...|$|R
40|$|As {{the trend}} of {{successful}} network attacks continue to rise, better forms of intrusion, detection and prevention are needed. This thesis addresses network traffic visualization techniques that aid administrators in recognizing attacks. A view of port statistics and Intrusion Detection System (IDS) alerts has been developed. Each help to address issues with analyzing large datasets involving networks. Due {{to the amount of}} traffic as well as the range of possible port numbers and IP addresses, scaling techniques are necessary. A port-based overview of network activity produces an improved representation for detecting and responding to malicious activity. We have found that presenting an overview using stacked histograms of aggregate port activity, combined with the ability to drill-down for finer details allows small, yet important details to be noticed and investigated without being obscured by large, usual traffic. Another problem administrators face is the cumbersome amount of alarm data generated from IDS sensors. As a result, important details are often overlooked, {{and it is difficult to}} get an overall picture of what is occurring in the network by manually traversing textual alarm logs. We have designed a novel visualization to address this problem by showing alarm activity within a network. Alarm data is presented in an overview from which system administrators can get a general sense of network activity and easily detect anomalies. They additionally have the option of then zooming and drilling down for details. Based on our system administrator requirements study, this graphical layout addresses what system administrators need to see, is faster and easier than analyzing text logs, and uses visualization techniques to effectively scale and display the data. With this design, we have built a tool that effectively uses <b>operational</b> alarm <b>log</b> data generated on the Georgia Tech campus network. For both of these systems, we describe the input data, the system design, and examples. Finally, we summarize potential future work. Ph. D. Committee Chair: Copeland, John; Committee Member: Hamblen, James; Committee Member: Ji, Chuanyi; Committee Member: Owen, Henry; Committee Member: Stasko, Joh...|$|R
