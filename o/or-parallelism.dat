120|0|Public
50|$|The {{runtime system}} {{implements}} the virtual machine, automatic memorymanagement with garbage collection of stacks and dictionary, event handling and data-driven execution.Versions of ECLiPSe implement <b>OR-parallelism.</b>|$|E
40|$|One {{important}} {{advantage of}} logic programming {{is that it}} allows the implicit exploitation of parallelism. Towards this goal, we suggest that <b>or-parallelism</b> can be efficiently exploited in tabling systems and propose two alternative approaches, <b>Or-Parallelism</b> within Tabling (OPT) and Tabling within <b>Or-Parallelism</b> (TOP). We then focus on OPT approach where environment copying is used to implement <b>or-parallelism.</b> We give the necessary data structures and data areas and describe an algorithm for the public completion operation...|$|E
40|$|One {{important}} {{advantage of}} logic programming {{is that it}} allows the implicit exploitation of parallelism. Towards this goal, we suggest that <b>or-parallelism</b> can be efficiently exploited in tabling systems and propose two alternative approaches, <b>Or-Parallelism</b> within Tabling (OPT) and Tabling within <b>Or-Parallelism</b> (TOP). We then focus on OPT approach where environment copying is used to implement <b>or-parallelism.</b> We give the necessary data structures and data areas and describe an algorithm for the public completion operation. Keywords: Parallel Logic Programming, <b>Or-parallelism,</b> Tabling. 1 Introduction Prolog is an extremely popular and powerful logic programming language. Prolog is widely used to program symbolic computing applications in areas such as Artificial Intelligence, Natural Language, Knowledge Based Systems, Machine Learning, Database Management or Expert Systems. Prolog's popularity was also sparked by the success in Prolog compilation technology which has enabled Prolog pro [...] ...|$|E
40|$|One of the {{advantages}} of logic programming is the fact that one can exploit implicit parallelism in logic programs, such as and-parallelism and <b>or-parallelism.</b> Recently, research has been concentrated on integrating the different forms of parallelism into a single combined system. In this work we concentrate on the problem of integrating <b>or-parallelism</b> and independent and-parallelism for parallel Prolog systems. We contend that previous data structures require pure recomputation and therefore do not allow for orthogonality between and-parallelism and <b>or-parallelism.</b> In contrast, we submit that a simpler solution, the sparse binding array, does guarantee this goal, and explain in detail how independent and-parallelism and <b>or-parallelism</b> can thus be efficiently combined...|$|E
40|$|Abstract. This paper {{presents}} the logic programming concept of thread-based competitive <b>or-parallelism,</b> which combines {{the original idea}} of com-petitive <b>or-parallelism</b> with committed-choice nondeterminism and spec-ulative threading. In thread-based competitive <b>or-parallelism,</b> an explicit disjunction of subgoals is interpreted {{as a set of}} concurrent alternatives, each running in its own thread. The individual subgoals usually corre-spond to predicates implementing different procedures that, depending on the problem specifics, are expected to either fail or succeed with dif-ferent performance levels. The subgoals compete for providing an answer and the first successful subgoal leads to the termination of the remain-ing ones. We discuss the implementation of thread-based competitive <b>or-parallelism</b> in the context of Logtalk, an object-oriented logic pro-gramming language, and present experimental results...|$|E
40|$|One {{important}} {{advantage of}} logic programming {{is that it}} allows the implicit exploitation of parallelism. Towards this goal, we suggest that <b>or-parallelism</b> can be efficiently exploited in tabling systems and propose two alternative approaches, <b>Or-Parallelism</b> within Tabling (OPT) and Tabling within <b>Or-Parallelism</b> (TOP). We concentrate on the fundamental concepts of an environment copying based model to implement the OPT approach and introduce the data structures and algorithms necessary to extend the YapOr Or-Parallel system, in order to obtain a parallel tabling system...|$|E
40|$|This paper {{presents}} an extended and-or tree and an extended WAM (Warren Abstract Machine) for efficiently supporting both and-parallel and or-parallel execution of logic programs on shared-memory multiprocessors. Our approach for exploiting both and- and <b>or-parallelism</b> {{is based on}} the binding-arrays method for <b>or-parallelism</b> and the RAP (Restricted And-Parallelism) method for and-parallelism, two successful methods for implementing <b>or-parallelism</b> and and-parallelism respectively. Our combined and-or model avoids redundant computations when goals exhibit both and- and <b>or-parallelism,</b> by representing the cross-product of the solutions from the and-or parallel goals rather than re-computing them. We extend the classical and-or tree with two new nodes: a `sequential' node (for RAP's sequential goals), and a `crossproduct' node (for the cross-product of solutions from and-or-parallel goals). The paper also {{presents an}} extension of the WAM, called AO-WAM, which is used to compile logic programs [...] ...|$|E
40|$|This paper {{presents}} a new multiprocessor architecture for the parallel execution of logic programs, developed {{as part of}} the Aquarius Project. This architecture is designed to support AND-parallelism, <b>OR-parallelism,</b> and intelligent backtracking. We present the most comprehensive experi-mental results available to date on combined AND-parallelism, <b>OR-parallelism,</b> and intelligent backtracking in Prolog programs. Simulation results indicate that most Prolog programs in use today cannot effectively make use of multiprocessing. 1...|$|E
40|$|Parallelism {{and logic}} {{programming}} are two fields {{that have been}} successfully combined, as is shown by recent implementations of parallel logic programming systems. There are two main sources of parallelism in logic programming, namely <b>or-parallelism</b> and and-parallelism. <b>Or-parallelism</b> is exploited when several alternative clauses to a goal are executed in parallel. And-parallelism is exploited when we execute two or more goals of the same clause simultaneously. Exploitation of full <b>or-parallelism</b> and and-parallelism {{is limited by the}} number of physical processors available in a system. And-parallelism is also limited by the interdependence among goals in a clause. In parallel logic programming systems which exploit both and-parallelism and <b>or-parallelism,</b> a problem that arises is how to distribute processors between the dynamically varying amounts of and-work and or-work that are available. Solutions have been reported for distributing only or-work, or distributing only and-work, but the issue of distributing processors between both kinds of work has not yet been addressed. In this thesis we discuss the problem of distributing and-work and or-work in the context of Andorra-I, a parallel logic programming system that exploits determinate and-parallelism and <b>or-parallelism,</b> and propose scheduling strategies that aim at effi ciently distributing processors between and-work and or-work. We study general criteria that every scheduling strategy should meet to reconfi gure processors without incurring too high overheads in the Andorra-I system. We propose two different strategies to reconfi gure processors between and-work and or-work based on these criteria. One strategy, work-guided, guides its decisions by looking at the amount of current and-work and or-work available in [...] ...|$|E
40|$|AbstractThis paper {{presents}} an extended and—or tree and an extended WAM (Warren Abstract Machine) for efficiently supporting both and-parallel and or-parallel execution of logic programs on shared-memory multiprocessors. Our approach for exploiting both and- and <b>or-parallelism</b> {{is based on}} the binding-arrays method for <b>or-parallelism</b> and the RAP (Restricted And-Parallelism) method for and-parallelism, two succesful methods for implementing <b>or-parallelism</b> and and-parallelism, respectively. Our combined and—or model avoids redundant computations when goals exhibit both and- and <b>or-parallelism,</b> by representing the cross product of the solutions from the and—or parallel goals rather than recomputing them. We extend the classical and—or tree with two new nodes: a “sequential” node (for RAPs sequencial goals), and a “cross-product” node (for the cross product of solutions from and—or parallel goals). The paper also {{presents an}} extension of the WAM, called AO—WAM, which is used to compile logic programs for and—or parallel execution based on the extended and—or tree. The AO—WAM incorporates a number of novel features: (i) inclusion of a base array with each processor's binding array for constant-time access to variables in the presence of and-parallelism, (ii) inclusion of new stack frames and instructions to express solution sharing, and (iii) novel optimizations which minimize the cost of binding-array updates in the presence of and-parallelism...|$|E
40|$|<b>Or-parallelism</b> and And-parallelism {{have often}} been {{considered}} as two distinct forms of parallelism with not much in common. The {{purpose of this paper}} is to highlight the inherently dual nature of the two forms of parallelism and the similarities that exist between them. The dualities and similarities observed are then exploited for gaining new insights into the design, implementation, and optimization of and- and or-parallel systems. The ideas developed in this paper are illustrated with the help of ACE system [...] -a parallel Prolog system incorporating both and- and <b>or-parallelism.</b> Keywords: Prolog, And-parallelism, <b>Or-parallelism,</b> Optimizations. 1 Introduction Logic Programming is a declarative programming paradigm that is becoming increasingly popular. One of the distinguishing features of logic programming languages is that they allow considerable freedom in the way programs are executed. This latitude permits one to exploit parallelism implicitly (without the need for programmer [...] ...|$|E
40|$|One of the {{advantages}} of logic programming {{is the fact that it}} offers many sources of implicit parallelism, such as and-parallelism and <b>or-parallelism.</b> A major problem that a parallel model must address consists in represent the multiple values that shared variables can be binded to when exploited in parallel. Binding Arrays and Environment Copying are two or-parallel models that efficiently solve that problem. Recently, research in combining independent and-parallelism and <b>or-parallelism</b> within the same system has led to two new binding representation approaches: the Sparse Binding Array (an evolution of binding arrays) and the Copy-On-Write binding models. In this paper, we investigate whether for <b>or-parallelism</b> the newer models are practical alternatives to copying. To address this question, we experimented with YapOr, an or-parallel copying system using the YAP Prolog engine, and we implemented the Sparse Binding Array (SBA) and the Copy-On-Write (COWL) over the original sys [...] ...|$|E
40|$|In {{this paper}} {{we present a}} novel {{execution}} model for parallel implementation of logic programs which is capable of exploiting both independent and-parallelism and <b>or-parallelism</b> in an efficient way. This model extends the stack copying approach, which has been successfully applied in the Muse system to implement <b>or-parallelism,</b> by integrating it with proven techniques used to support independent and-parallelism. We show how all solutions to non-deterministic andparallel goals are found without repetitions. This is done through recomputation as in Prolog (and in various and-parallel systems, like &-Prolog and DDAS), i. e., solutions of and-parallel goals are not shared. We propose a scheme for the efficient management of the address space {{in a way that}} is compatible with the apparently incompatible requirements of both and- and <b>or-parallelism.</b> We also show how the full Prolog language, with all its extra-logical features, can be supported in our and-or parallel system so that its sequent [...] ...|$|E
40|$|A new {{high-level}} interface to multi-threading in Prolog, {{implemented in}} hProlog, is described. Modern CPUs often contain multiple cores and through high-level multi-threading a programmer can leverage this power {{without having to}} worry about low-level details. Two common types of high-level explicit parallelism are discussed: independent and-parallelism and competitive <b>or-parallelism.</b> A new type of explicit parallelism, pipeline parallelism, is proposed. This new type can be used in certain cases where independent and-parallelism and competitive <b>or-parallelism</b> cannot be used. Comment: Online Proceedings of the 11 th International Colloquium on Implementation of Constraint LOgic Programming Systems (CICLOPS 2011), Lexington, KY, U. S. A., July 10, 201...|$|E
40|$|This paper {{concerns}} {{the exploitation of}} user transparent inherent parallelism of pure Prolog programs using program transformation. We describe a novel paradigm enumerate-and-filter for transforming generate-and-test programs for execution under the committed-choice model extended to incorporate multiple solutions based on set enumeration. The paradigm simulates <b>OR-parallelism</b> by stream AND-parallelism integrating <b>OR-parallelism,</b> AND-parallelism, and stream parallelism. Generate-and-test programs are classified into three categories:simple generate-and-test, recursively embedded generate-and-test, and deeply intertwined generate-and-test. The intermediate programs are further transformed to reduce structure copying and metacalls. Algorithms are presented and demonstrated by transforming the representative examples of different classes of generate-and-test programs to Flat Concurrent Prolog equivalents. Statistics show that the techniques are efficient...|$|E
40|$|Avery {{important}} component of a parallel system that generates irregular computational patterns is its work distribution strategy. Scheduling strategies {{for these kinds of}} systems must be smart enough in order to dynamically balance workload while not incurring a very high overhead. Logic programs running on parallel logic programming systems are examples of irregular parallel computations. The two main forms of parallelism exploited by parallel logic programming systems are: and-parallelism, that arises when several literals in the body of a clause can execute in parallel, and <b>or-parallelism,</b> that arises when several alternative clauses in the database program can be selected in parallel. In this work we show that scheduling strategies for distributing and-work and or-work in parallel logic programming systems must combine information obtained at compile-time with runtime information whenever possible, in order to obtain better performance. The information obtained at compile-time has two advantages over current implemented systems that use only runtime information: (1) the user does not need to adjust parameters in order to estimate sizes of and-work and orwork for the programs; (2) the schedulers can use more accurate estimates of sizes of and-work and or-work to make better decisions at runtime. We did our experiments with Andorra-I, a parallel logic programming system that exploits both determinate and-parallelism and <b>or-parallelism.</b> In order to obtain compile-time granularity information we used the ORCA tool. Our benchmark set ranges from programs containing and-parallelism only, <b>or-parallelism</b> only and a combination of both and-, and <b>or-parallelism.</b> Our results show that, when well designed, scheduling strategies can actually bene t from compile-time granularity information...|$|E
40|$|Logic Programming languages, such as Prolog, {{provide an}} {{excellent}} {{framework for the}} parallel execution of logic programs. In particular, the inherent non-determinism in the way logic programs are structured makes Prolog very attractive for the exploitation of implicit parallelism. One of the most noticeable sources of implicit parallelism in Prolog programs is <b>or-parallelism.</b> <b>Or-parallelism</b> arises from the simultaneous evaluation of a subgoal call against the clauses that match that call. Arguably, the most successful model for <b>or-parallelism</b> is environment copying, that has been efficiently used {{in the implementation of}} or-parallel Prolog systems both on shared memory and distributed memory architectures. Nowadays, multicores and clusters of multicores are becoming the norm and, although, many parallel Prolog systems have been developed in the past, {{to the best of our}} knowledge, none of them was specially designed to explore the combination of shared with distributed memory architectures. Motivated by our past experience, in designing and developing parallel Prolog systems based on environment copying, we propose a novel computational model to efficiently exploit implicit parallelism from large scale real-world applications specialized for the novel architectures based on clusters of multicores...|$|E
40|$|In {{parallel}} {{logic programming}} systems that exploit both and-parallelism and <b>or-parallelism,</b> a problem arises {{that is how}} to distribute processors between the dynamically varying amounts of and-work and or-work that are available. Solutions have been reported for distributing only or-work, or distributing only and-work, but the issue of distributing processors between both kinds of work {{has not yet been}} addressed. In this work we discuss the problem of distributing and-work and or-work in the context of Andorra-I, a parallel logic programming system that exploits determinate andparallelism and <b>or-parallelism.</b> We describe dynamic scheduling strategies that aim at efficiently distributing processors between and-work and or-work, and compare their performance with the performance produced by a static scheduling strategy, {{for a wide range of}} benchmarks...|$|E
40|$|This paper {{studies the}} {{performance}} of Andorra-I, a parallel logic programming system that exploits and-parallelism and <b>or-parallelism</b> with a novel strategy to distribute and-work and orwork among processors. The strategy, work-guided guides its decisions {{by looking at the}} amount of current and-work and or-work available in an application during execution. The scheduler decision strategy moves workers from one parallel task to another according to the tasks sizes. Results show that the work-guided strategy works quite well and produces better results than the ones produced with a version of Andorra-I that does not allow dynamic migration of workers during execution. We believe that this strategy can be applied to other parallel logic programming systems that aim to exploit both and- and <b>or-parallelism</b> in a single framework...|$|E
40|$|We {{study the}} problem of {{exploiting}} <b>or-parallelism</b> from logic programming systems on distributed machines. We propose stack-splitting, a modification of the well-known stack-copying technique for environment representation, {{that can be used}} for exploiting <b>or-parallelism</b> efficiently from logic programming systems on distributed-memory machines. Stack-splitting coupled with scheduling on bottom-most choice-point leads to: (i) reduced communication during distributed execution; and, (ii) distribution of larger grain-sized work to processors. The modified technique can also be implemented on shared memory machines and performs better than standard stack-copying implementations such as Muse. We also show how stack-splitting can be adapted for realizing distributed memory implementations of and-parallelism. 1 Introduction An important property of logic programming (LP) languages is that they are single assignment languages. Unlike conventional programming languages they disallow destruct [...] ...|$|E
40|$|The {{past years}} have seen {{widening}} efforts at increasing Prolog's declarativeness and expressiveness. Tabling {{has proved to be}} a viable technique to efficiently overcome SLD's susceptibility to infinite loops and redundant subcomputations. Our research demonstrates that implicit <b>or-parallelism</b> is a natural fit for logic programs with tabling. To substantiate this belief, we have designed and implemented an or-parallel tabling engine [...] OPTYap [...] and we used a shared-memory parallel machine to evaluate its performance. To the best of our knowledge, OPTYap is the first implementation of a parallel tabling engine for logic programming systems. OPTYap builds on Yap's efficient sequential Prolog engine. Its execution model is based on the SLG-WAM for tabling, and on the environment copying for <b>or-parallelism.</b> Preliminary results indicate that the mechanisms proposed to parallelize search in the context of SLD resolution can indeed be effectively and naturally generalized to parallelize tabled computations, and that the resulting systems can achieve good performance on shared-memory parallel machines. More importantly, it emphasizes our belief that through applying <b>or-parallelism</b> and tabling to logic programs the range of applications for Logic Programming can be increased. Comment: 45 pages, 12 figures, to appear in the journal of Theory and Practice of Logic Programming (TPLP...|$|E
40|$|Abstract or-work. This {{is a new}} {{and hard}} problem to be solved In {{parallel}} logic programming systems that exploit both and-parallelism and <b>or-parallelism,</b> a problem arises that is how to distribute processors between the dynamically varying amounts of and-work and or-work that are available. Solutions have been reported for dis-tributing only or-work, or distributing only and-work, but the issue of distributing processors between both kinds of work {{has not yet been}} addressed. In this work we discuss the problem of distributing and-work and or-work in the context of Andorra-I, a parallel logic programming system that exploits determinate and-parallelism and <b>or-parallelism.</b> We describe dynamic scheduling strategies that aim at efficiently distributing processors between and-work and or-work, and compare their performance with the performance produced by a static scheduling strategy, {{for a wide range of}} bench-marks...|$|E
40|$|We {{show that}} to exploit both Independent And- and <b>Or-parallelism</b> from Prolog {{programs}} independent goals should be recomputed (vs their solutions reused). We present an abstract model, called the Composition-Tree, for representing and-or parallelism in Prolog Programs. The Composition-tree closely mirrors sequential Prolog execution (by recomputing independent goal rather than re-using them). We also present {{an extension of}} the Binding Array scheme for And-Or parallel execution of full Prolog based on the Composition-tree. A complete abstract machine for and-or parallel Prolog is presented along with scheduling and memory management issues. We demonstrate why our system is better than the earlier proposals for exploiting and-or parallelism. Keywords: <b>Or-parallelism,</b> Independent And-parallelism, Binding Arrays, RAP-WAM, Paging. 1. Introduction One of the main features of logic programming languages is that they allow implicit parallel execution of programs. There are three main forms of [...] ...|$|E
40|$|Logic {{programs}} provide {{many opportunities}} for parallel execution. Among different forms of parallelism found in logic programs, AND-parallelism and <b>OR-parallelism</b> have shown {{to be most effective}} in speeding up the execution of logic programs. Research in the exploitation of AND-parallelism, <b>OR-parallelism</b> alone and combined AND/OR-parallelism has led to the proposals and implementations of various execution models and working systems. This paper offers a review of major activities in exploiting AND-parallelism and combined AND/ORparallelism. Keywords: Logic programming, Prolog, AND-parallelism, Combined AND/OR-parallelism 1. INTRODUCTION There has been a flurry of research activities in parallel processing of logic programs in the last decade due to the growing demand for fast reasoning capabilities on the current parallel computers. Among different forms of parallelism inherent in logic programs, AND-parallelism and ORparallelism have shown to be most effective in speeding up the [...] ...|$|E
40|$|One of the {{advantages}} of logic programming {{is the fact that it}} offers many sources of implicit parallelism, such as and-parallelism and <b>or-parallelism.</b> Arguably, or-parallel systems, such as Aurora and Muse, have been the most successful parallel logic programming systems so far. Or-parallel systems rely on techniques such as Environment Copying to address the problem that branches being explored in parallel may need to assign different bindings for the same shared variable. Recent research has led to two new binding representation approaches that also support independent and-parallelism: the Sparse Binding Array and the Copy-On-Write binding models. In this paper, we investigate whether these newer models are practical alternatives to copying for <b>or-parallelism.</b> We based our work on YapOr, an or-parallel copying system using the YAP Prolog engine, so that the three alternative systems share schedulers and the underlying engine...|$|E
40|$|Andorra-I is an {{experimental}} parallel Prolog system which transparently exploits both dependent and-parallelism and <b>or-parallelism.</b> One {{of the main}} components of Andorra-I is its preprocessor. In order to obtain efficient execution of programs in Andorra-I, the preprocessor includes a compiler for Andorra-I. The compiler includes a determinacy analyser and a clause compiler, and generates code for a specialised abstract machine. In this paper we discuss the main issues in the Andorra-I compiler, presenting its abstract instruction set and describing the algorithms used in its implementation. 1 Introduction Andorra-I [13, 21] is a parallel logic programming system based on the Basic Andorra Model. It supports both dependent and-parallelism, by running determinate goals in parallel, and <b>or-parallelism,</b> by trying alternatives from nondeterminate goals in parallel. Experience in using Andorra-I has led to the following main conclusions: ffl Andorra-I performs well and exploits parallelis [...] ...|$|E
40|$|This paper {{describes}} ways {{of improving}} the performance of combined and-or parallel implementations. The model for and-or parallel execution of logic programs that we consider integrates the class of methods for exploiting <b>or-parallelism</b> which perform variable access and task-creation operations in constant-time (such as Binding Arrays method and Versions Vectors method) and the RAP method for independent and-parallelism. The major run-time overhead in such and-or parallel models {{can be traced back}} to the overhead incurred for <b>or-parallelism</b> during processor task switching. We present a number of techniques for reducing this overhead, by exploiting andparallelism and the semantics of Conditional Graph Expressions (CGEs). Essentially, we reduce the overhead by reducing the number of conditionally bound variables whose bindings need to be installed during task-switching. These techniques can be easily incorporated in a compiler, and can lead to substantial savings in execution time. Keyw [...] ...|$|E
40|$|Most {{models that}} have been proposed, or implemented, so far for {{exploiting}} both <b>or-parallelism</b> and independent and-parallelism have only considered pure logic programs (pure Prolog). We present an abstract model, called the Composition-Tree, for representing and-or parallelism in full Prolog. The Composition-Tree recomputes independent goals to ensure that Prolog semantics is preserved. We combine the idea of Composition-Tree with ideas developed earlier, to develop an abstract execution model that supports full Prolog semantics {{while at the same}} time avoiding redundant inferences when computing solutions to (purely) independent and-parallel goals. This is accomplished by sharing solutions of independent goals when they are pure (i. e. have no side-effects or cuts in them). The Binding Array scheme is extended for and-or parallel execution based on this abstract execution model. This extension enables the Binding Array scheme to support <b>or-parallelism</b> in the presence of independent and-p [...] ...|$|E
40|$|Parallel Prolog systems consist, {{at least}} conceptually, of two {{components:}} an engine and a scheduler. This paper addresses {{the problem of}} defining a clean interface between these components. Such an interface has been designed for Aurora, a prototype or-parallel implementation of the full Prolog language for shared memory multiprocessors. The practical purpose of the interface is to enable different engine and scheduler implementations to be used interchangeably. The development of the interface has, however, contributed in great extent to the clarification of issues in exploiting <b>or-parallelism</b> in Prolog. We believe that these issues are relevant to a wider circle {{of research in the}} area of or-parallel implementations of logic programming. We believe that the concept of an engine-scheduler interface is applicable to a wider range of parallel Prolog implementations. Indeed, the present interface has been used in the Andorra-I system, which supports both and- and <b>or-parallelism.</b> Keywor [...] ...|$|E
40|$|Chronolog is an {{extension}} of logic programming based on temporal logic. The paper presents a framework which can be used to exploit multiple levels of parallelism found in Chronolog programs, context parallelism, AND- and <b>OR-parallelism.</b> Based on an analysis of these modes of parallelism in Chronolog programs, a parallel execution mechanism of the language is discussed and a formal execution model is given. The inherent context-parallelism in Chronolog programs occurs when more than one childcomputation are active at a time, and it is exploited through dynamic tagging approach typically used in dataflow computers. At the level of clause arguments, we introduce an intermediate virtual machine (CVM), which is granulated to exploit the argument parallelism through temporal unification. We also give the details of the CVM instruction set. The model is process-based and supports AND-, <b>OR-parallelism</b> in the highly distributed dataflow environment. 1 Introduction Temporal logic has been wide [...] ...|$|E
40|$|This paper {{presents}} the Fire model, an implementation scheme of the "or-under-and, no reusage" execution scheme for and/or parallelism in Prolog. Unlike previous schemes, the Fire model {{does not contain}} any private storage for the alternative bindings. Instead, the bindings are stored in data-structures associated with the search-space, and is accessible by all. The advantage is that task-switching and scheduling, {{one of the major}} area of complexities with previous schemes, becomes simple and constant time. Another property of the Fire model is that when either and- or <b>or-parallelism</b> alone is exploited, there are little extra overheads when compared to schemes which exploits only one of these forms of parallelism. 1 Introduction There {{has been a lot of}} interest in the implicit parallel execution of Logic Programming languages, especially of Prolog, and many schemes which exploit various forms of and- and <b>or-parallelism</b> have been proposed and implemented. Although many of the early pro [...] ...|$|E
40|$|Abstract. Tabling is an {{implementation}} {{technique that}} improves the declarativeness and expressiveness of Prolog by reusing solutions to goals. Quite a few interesting applications of tabling {{have been developed}} {{in the last few}} years, and several are by nature non-deterministic. This {{raises the question of whether}} parallel search techniques can be used to improve the performance of tabled applications. In this work we demonstrate that the mechanisms proposed to parallelize search in the context of SLD resolution naturally generalize to parallel tabled computations, and that resulting systems can achieve good per-formance on multi-processors. To do so, we present the OPTYap par-allel engine. In our system individual SLG engines communicate data through stack copying. Completion is detected through a novel parallel completion algorithm that builds upon the data structures proposed for <b>or-parallelism.</b> Scheduling is simplified by building on previous research on <b>or-parallelism.</b> We show initial performance results for our implemen-tation. Our best result is for an actual application, model checking, where we obtain linear speedups...|$|E
40|$|In {{this paper}} we {{describe}} the architecture and implementation {{of a system that}} aims at extending in a consistent way a functional logic programming language with solving techniques of various constraint solving systems. The system is called CFLP (Constrained Functional Logic Programming language), and consists of a lazy functional logic interpreter extended in two directions: the possibility to specify constraints, and the possibility to specify AND- and <b>OR-parallelism.</b> For solving the constraints, a distributed constraint solving system was implemented...|$|E
40|$|The paper {{presents}} a data-driven execution model, CHEM, for a temporal logic programming language, Chronolog. An intermediate virtual machine is proposed, which is granulated at clause argument level to exploit argument parallelism through unification. Context-parallelism, inherent in temporal logic programs, is exploited through dynamic tagging approach typically used in dataflow computers. The model is process-based and supports AND-, <b>OR-parallelism</b> {{in the highly}} distributed dataflow environment. Implementation techniques used to support these forms of parallelism are described...|$|E
40|$|Abstract. This paper {{describes}} {{the development of}} the PALS system, an implementation of Prolog that efficiently exploits <b>or-parallelism</b> on share-nothing platforms. PALS makes use of a novel technique, called incremental stack-splitting. The technique builds on the stack-splitting approach, which in turn is an evolution of the stack-copying method used in a variety of parallel logic systems. This is the first distributed implementation based on the stack-splitting method ever realized. Experimental results obtained on a Beowulf system are presented and analyzed. ...|$|E
40|$|Three general {{techniques}} are discussed for the source-to-source translation of sequential logic programs to AND-parallel logic programs. Producer-consumer information {{is used to}} translate deterministic programs with a single solution, utilizing stream-parallelism. Operationally nondeterministic programs with a single solution are translated by simulated <b>OR-parallelism.</b> Enumeration is used for generate-and-test programs. Enumeration needs a programming idiom for AND-parallel programs, called enumerate-and-filter. The enumerate-and-filter paradigm utilizes AND-parallelism along with stream-parallelism and pipelining. The {{techniques are}} illustrated with examples of Prolog programs translated to Flat Concurrent Prolog...|$|E
