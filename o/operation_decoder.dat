0|32|Public
5000|$|A {{differential}} encoder {{provides the}} [...] <b>operation,</b> a differential <b>decoder</b> - the [...] operation.|$|R
40|$|Abstract: The all-optical {{read only}} memory (ROM) having 2 -bit address has been {{successfully}} demonstrated with a numerical assessment employing an all-optical 2 -to- 4 line decoder based on cross gain modulation (XGM) in semiconductor optical amplifiers (SOA). Experimental demonstration also {{has been carried out}} for the <b>operation</b> of <b>decoder.</b> We have shown that four characters can be stored at each address as an American standard code for information interchange (ASCII). 1...|$|R
40|$|A set of {{software}} programs which simulates a (255, 223) Reed-Solomon encoder/decoder pair is described. The transform decoder algorithm uses a modified Euclid algorithm, and closely follows the pipeline architecture {{proposed for the}} hardware decoder. Uncorrectable error patterns are detected by a simple test, and the inverse transform is computed by a finite field FFT. Numerical examples of the <b>decoder</b> <b>operation</b> are given for some test codewords, with and without errors. The use of the software package is briefly described...|$|R
5000|$|Switching slices, called SP and SI slices, {{allowing}} an encoder {{to direct}} a decoder to jump into an ongoing video stream for such purposes as video streaming bit rate switching and [...] "trick mode" [...] <b>operation.</b> When a <b>decoder</b> jumps {{into the middle of}} a video stream using the SP/SI feature, it can get an exact match to the decoded pictures at that location in the video stream despite using different pictures, or no pictures at all, as references prior to the switch.|$|R
30|$|Following {{the general}} process of MPEG to {{standardize}} transmission formats and <b>decoder</b> <b>operation</b> (and hence allowing future encoder-side improvements) the SBR amendment contains an informative (as opposed to normative) encoder description. Hence this section gives a generic {{overview of the}} various elements of an encoder; the exact design of these elements is left up to the implementer. However, for detailed information on a realization of the encoder capable of high perceptual performance, the 3 GPP specification of the SBR encoder is a good source, see [13].|$|R
40|$|Abstract [...] This paper {{presents}} a turbo soft in soft out (SISO) decoder based on Max-log-map algorithm using sliding window techniques. The proposed architecture {{is based on}} branch metric normalization to improve the speed of <b>operation</b> of the <b>decoder.</b> The architecture is coded in hardware description language and the efficient code is simulated and synthesized. From the synthesis report, {{it is observed that}} the path delay is reduced to 12. 626 ns compared with the 23. 207 ns of conventional one. Index terms [...] SISO, FPGA, ML-MAP, LLR etc. I...|$|R
40|$|Includes bibliographical {{references}} (pages 43 - 44). Application-specific {{instruction set}} processors (ASIPs) are the programmable processors optimized {{for a specific}} application. This thesis demonstrates how ASIPs can provide efficient solutions in the Wireless Communications Technology. A general-purpose MIPS (microprocessor without interlocked pipeline stages) pipelined processor is first designed and verified in Verilog HDL {{as a foundation for}} this thesis. The processor is then enhanced to support hazard detection and forwarding operations. The final goal of the thesis is to demonstrate ASIPs capability in supporting applications like quadrature amplitude modulation (QAM) and multiple-input multipleoutput (MIMO). These applications were first simulated to identify ASIP optimizations. Fixed-point arithmetic with Newton-Raphson division were identified as needed in order to support these applications. The processor is enhanced to support these two <b>operations.</b> QAM <b>decoder</b> is successfully programmed on the processor and results are verified. Matrix operations for MIMO are explored and programmed as functions in the processor instruction memory. This also includes blockwise analytical matrix inversion algorithm. 2 ?? 2 MIMO MMSE receiver is mapped on this application-specific instruction set processor and results are verified for accuracy and performance...|$|R
30|$|In this section, we {{obtain an}} {{achievable}} rate region using lattice codes for the G-CICS. If {{we use the}} common encoding and decoding as it is explained in [34], then similar to random coding, we cannot achieve the capacity region within a constant gap. Thus, we require to introduce a new scheme for this channel. For presenting this scheme, we use two modulo <b>operations</b> at the <b>decoder.</b> Then using Lemma 3, we interchange modulo operations. As we will see, this scheme can achieve the capacity region at high SNRs and within 0.5 bits regardless of all channel parameters. In the following, we present our scheme in more detail.|$|R
40|$|This paper {{presents}} a low power Viterbi decoder design based on Scarce State Transition (SST). We propose an approach which seamlessly integrates the path pruning techniques with the SST decoding {{to reduce the}} average add-compare-select (ACS) computation. The scheme has very low overhead and is practical for implementation. We also propose an uneven-partitioned memory architecture for the survivor memory unit to reduce the memory access power during the trace back <b>operation.</b> The proposed <b>decoder</b> is implemented in SMIC 0. 18 mu m CMOS process. Simulation results show that significant power consumption reduction can be achieved for high throughput wireless systems such as MB-OFDM Ultra-wide-band applications...|$|R
40|$|We {{present the}} {{concepts}} of weighted language, ~ansduction and au-tomaton from algebraic automata theory as a general framework for describing and implementing decoding cascades in speech and lan-guage processing. This generality allows us to represent uniformly such information sources as pronunciation dictionaries, language models artd lattices, and to use uniform algorithms for building de-coding stages and for optimizing and combining them. In particular, a single automata join algorithm can be used either to combine in-formation sources such as a pronunciation dictionary and a context-dependency model during {{the construction of a}} decoder, or dynam-ically during the <b>operation</b> of the <b>decoder.</b> Applications to speech recognition and to Chinese text segmentation will be discussed. 1...|$|R
40|$|This paper {{presents}} a {{design of a}} device that can access a CD-ROM drive in the IDE standard. The device is implemented with Verilog HDL (Hardware Description Language) and FPGA (Field Programmable Gate Array) technology. The system consists of three components: (i) Processing Unit that controls all system <b>operations,</b> (ii) Address <b>Decoder</b> for managing the address space of data, stack and input/output ports and (iii) IDE Host Adapter for interfacing with a CD-ROM drive. The development begins with designing and coding the system in Verilog HDL. The simulation is performed to test that it can access data from the CD-ROM drive. Finally, the system is synthesized targeting a FPGA chip {{and the amount of}} resources is reported...|$|R
40|$|Thesis (Masters Diploma (Technology)) [...] Cape Technikon, Cape Town, 1989 The {{document}} initially {{describes the}} <b>operation</b> of the <b>decoder</b> {{and the production}} system. Thereafter actual engineering problems are stated and their solutions discussed. The project involves the accurate identification of problem areas on the production line and the systematic solving for each case. Subjects include static electricity pretesting and automatic insertion machine defects. Analysis of these problems provides one with a better perspective towards the production line and its inherent problems. Results and solutions are presented photographically as well as tabulated in the annexure. In some cases, such as defect classification, deductions were concluded that were very different from those initially expected...|$|R
40|$|In this work, {{we propose}} novel encoder {{algorithms}} for the state-of-the-art video coding standard H. 264, to generate decoder friendly video bitstreams. Using the proposed algorithms, {{it is possible}} to generate bitstreams requiring significantly less decoding complexity, with negligible effect on picture quality. This is achieved by using novel algorithms for mode decision and motion estimation that bias easy-to-decode motion vectors in a Rate-Distortion optimized fashion. Experimental results show that, more than 15 % decoding complexity reduction is achieved with less than a 0. 1 dB penalty on the average video quality. We believe that this approach has potential in various use cases especially in mobile multimedia systems, where the video <b>decoder</b> <b>operation</b> is often dominating the handsets power consumption. Â© 2006 IEEE...|$|R
40|$|The {{command and}} {{data-handling}} subsystem of the Atmosphere Explorer satellite provides the necessary controls for the instrumentation and telemetry, and also controls the satellite attitude and trajectory. The subsystem executes all command information within the spacecraft, either {{in real time}} (as received over the S-band command transmission link) or remote from the command site (as required by the orbit operations schedule). Power consumption in the spacecraft is optimized by suitable application and removal of power to various instruments; additional functions include control of magnetic torquers and of the orbit-adjust propulsion subsystem. Telemetry data from instruments and the spacecraft equipment are formatted into a single serial bit stream. Attention is given to command types, command formats, <b>decoder</b> <b>operation,</b> and command processing functions...|$|R
40|$|Standards-based video {{compression}} algorithms are rapidly becoming the preferred method for transmitting image sequences. Prominent {{examples include the}} MPEG and ITU family of standards. However, {{it is important to}} realize that these standards are not bit-exact, in that only the <b>operation</b> of the <b>decoder</b> is defined by the specification. Development of the rate-control mechanism and pre- and post-processing procedures is completely controlled by the system designer, and these components can introduce discernible differences between two standards compliant realizations. In this paper, we survey the fields of pre- and post-processing techniques for {{video compression}}. We then discuss our current work on compression enhancement algorithms. These algorithms are applicable to any compression standard but are discussed within the context of MPEG- 2. 1...|$|R
40|$|A new {{slope line}} code for {{information}} transmission and storage has been proposed. The line code operates {{on the principle}} of slope coding. Two alternative slopes are used to transmit or store the binary information 1 s and 0 s. The decoder extracts the binary information from the received multilevel signal using slope comparison technique with slope violation detector from the incoming symbols. The encoder and <b>decoder</b> <b>operation</b> is described. A simulation of the encoder and decoder has been carried out using MultiSIMÃÂ® software. The simulated results are in thorough agreement with the theory. The slope line code also meets the many desirable features of other line codes. This makes it attractive and suitable for data transmission and storage on different types of telecommunication networks and multimedia systems...|$|R
40|$|A novel {{slope line}} code for data {{transmission}} and storage on digital communication systems has been proposed. The new line code operates {{on the principle}} of slope coding. The slope encoder transmits alternative slopes (stair-step-like pulses) for the transmission of the 1 s and 0 s of the input binary data. The decoder detects the received signal using correlative slope technique in order to extract the transmitted binary 1 s and 0 s from the incoming symbols. The encoder and <b>decoder</b> <b>operation</b> were described. The encoder circuit is designed and simulated using MultiSim software. The results show a thorough match with the theory. The new line code has many desirable properties which makes it attractive and a suitable for data transmission and storage on different types of telecommunication networks and multimedia...|$|R
30|$|The {{signal is}} over-sampled by 625 samples {{due to the}} default clock of 50 MHz on the FPGA, which can be lowered if power {{consumption}} is a concern. A lookup table is {{used to determine the}} symbol. A counter hi_cnt[*]is started on a high signal. Whenever a falling edge is detected, a counter lo_cnt[*]is started and the hi_cnt[*]is stopped. A rising edge indicates the end of a symbol. Furthermore, the type of symbol: TRcal, RTcal, data- 0, data- 1, invalid, and delim[*]is determined from the length of the symbol, and the high count is determined through a lookup table. The low count is only needed to determine the mode of <b>operation.</b> The command <b>decoder</b> is a state machine that is sensitive to symbols from the PIE decoder and outputs commands from the reader.|$|R
40|$|Abstract- A new {{slope line}} code for {{information}} transmission and storage has been proposed. The line code operates {{on the principle}} of slope coding. Two alternative slopes are used to transmit or store the binary information is and Os. The decoder extracts the binary information from the received multilevel signal using slope comparison technique with slope violation detector from the incoming symbols. The encoder and <b>decoder</b> <b>operation</b> is described. A simulation of the encoder and decoder has been carried out using MultiSIM Â® software. The simulated results are in thorough agreement with the theory. The slope line code also meets the many desirable features of other line codes. This makes it attractive and suitable for data transmission and storage on different types of telecommunication networks and multimedia systems...|$|R
40|$|Motion-compensated {{prediction}} {{that accounts for}} loss in the channel is achieved by the source-channel prediction (SCP) method, {{which is based on}} the expected decoder reconstruction of past frames (rather than their encoder reconstruction). The decoder reconstruction is estimated by exploiting the recursive optimal per-pixel estimate (ROPE), which explicitly accounts for the quantization distortion, channel loss, error propagation, as well as the <b>decoder</b> <b>operation,</b> and achieves improved error resilience. We take this paradigm further by noting that the decoder can, in turn, be re-optimized to match the modification introduced to the encoder for SCP. Simulation results demonstrate substantial performance gains over conventional decoding. We then examine the benefits of re-optimizing the encoder for the newly matched decoder, and then re-optimizing the decoder, etc., and note that further incremental gains are minor. Hence, one complete round of SCP optimization offers significant gains, but multiple re-optimization iterations may not be cost-effective. 1...|$|R
40|$|AbstractÙÙÙ Ù Arithmetic coding {{provides}} a high compression performance {{and is a}} key element for improved coding efficiency of recent multimedia communication standards such as H. 264, and JPEG 2000. In this article, we present a new block implementation of arithmetic codes that facilitates high speed coding, by eliminating the computationally complex interval renormalization. The proposed method operates on fixed length input and is set up based on following the <b>decoder</b> <b>operations</b> (intervals) at the encoder. Subsequently, for simultaneous truncation of arithmetic coding of an input block at the encoder and decoder, a few terminating bits are transmitted. As a result, the correct final interval is instantaneously obtained at the decoder, when the input block ends. Our extensive simulation results show that the redundancy of the proposed method with respect to entropy is small, while it maintains a very low complexity. Index Terms- Arithmetic coding, variable length coding, entropy coding, data compression I...|$|R
40|$|Network coding is a {{promising}} technique for data communications in wired and wireless networks. However, it places an additional computing overhead {{on the receiving}} node {{in exchange for the}} improved bandwidth. This paper proposes an FPGA-based reconfigurable and parallelized network coding decoder for embedded systems especially for vehicular ad hoc networks. In our design, rapid decoding process can be achieved by exploiting parallelism in the coefficient vector <b>operations.</b> The proposed <b>decoder</b> is implemented by using a modern Xilinx Virtex- 5 device and its performance is evaluated considering the performance of the software decoding on various embedded processors. The performance on four different sizes of the coefficient matrix is measured and the decoding throughput of 18. 3 Mbps for the size 16 Ã 16 and 6. 5 Mbps for 128 Ã 128 has been achieved at the operating frequency of 64. 5 MHz. Compared to the recent TEGRA 250 processor, the result obtained with 128 Ã 128 coefficient matrix reaches up to 5. 06 in terms of speedup...|$|R
40|$|The {{problem of}} error control and {{concealment}} in video communication {{is becoming increasingly}} important because of the growing interest in video delivery over unreliable channels such as wireless networks and the Internet. This paper reviews the techniques {{that have been developed}} for error control and concealment in the past 10 â 15 years. These techniques are described in three categories according to the roles that the encoder and decoder play in the underlying approaches. Forward error concealment includes methods that add redundancy at the source end to enhance error resilience of the coded bit streams. Error concealment by postprocessing refers to <b>operations</b> at the <b>decoder</b> to recover the damaged areas based on characteristics of image and video signals. Last, interactive error concealment covers techniques that are dependent on a dialogue between the source and destination. Both current research activities and practice in international standards are covered. KeywordsâError concealment, error control in video transport, video communications. I...|$|R
40|$|A MATLABÂ®-based FM {{demodulator}} for the RBDS {{system was}} designed to investigate software-based FM demodulator techniques. An overview of the <b>operation</b> of FM <b>decoder</b> design is presented. The FM radio signal contains stereo/audio, as well as RBDS data. This thesis develops a FM radio receiver that extracts these message elements from the RBDS data and displays the message details in a user-friendly format. An Agilent vector signal analyzer (VSA- 89600) is used to capture radio signals from a local radio station, and to convert this received FM radio signal into a MATLABÂ®- compatible format. The signal is then recorded on the host computer and processed using signal processing algorithms. Derivations and designs are done for various blocks of the processing chain to extract the RBDS signal from the FM radio signal, to demodulate this signal and recover the RBDS message (bits), and to decode these bits into a text message that is understandable by any user. Experimental results regarding message details of the received signal show a successful match with the original message information obtained from the radio station...|$|R
40|$|AbstractâModern VLSI decoders for low-density parity-check (LDPC) codes require high {{throughput}} performance while achieving {{high energy}} efficiency on the smallest possible foot-print. In this paper, we present two optimizations to enhance the throughput and reduce the power consumption for these decoders. As a first optimization, we seek to speedup the decoding task by modifying the processing step known as syndrome check. We partition this task and perform it in on-the-fly fashion. As a second optimization, we address the topic of iteration control {{in order to save}} energy and time on unnecessary <b>decoder</b> <b>operation</b> when processing undecodable blocks. We propose an iteration control policy that is driven by the combination of two decision metrics. Furthermore, we show empirically how stopping criteria should be tuned as a function of false alarm and missed detection rates. Throughout this paper we use the codes defined in the IEEE 802. 11 n standard to show performance results of the proposed optimizations. KeywordsâLDPC codes; iterative decoding; syndrome cal-culation; throughput enhancement; stopping criteria; iteration control; low power. I...|$|R
30|$|In this paper, a novel {{parametric}} prosody coding {{approach to}} efficiently encoding prosodic-acoustic features for segment-based Mandarin speech coding is proposed. It {{differs from the}} conventional prosody coding approaches using simple scalar- or vector-quantization mainly on adopting an analysis-synthesis scheme to obtain a parametric representation of the prosodic features of the input speech for encoding by an analysis operation in the encoder, and to reconstruct the prosodic features from the decoded parameters by a synthesis <b>operation</b> in the <b>decoder.</b> A hierarchical prosodic model (HPM) proposed previously [41] is employed {{to serve as the}} prosody-generating model in the analysis-synthesis scheme. The HPM is a sophisticated speech prosody model to well describe the various relations among prosodic-acoustic features, prosodic structure, and linguistic features {{so that it can be}} used to produce a compact and accurate representation of the prosodic features of the input speech for high-performance prosody coding. Besides, the HPM also provides us a platform to easily realize some post-modifications on the decoded prosody via manipulating its parameters. An example of modifying the speaking rate of the reconstructed speech via directly replacing the HPM parameters will be demonstrated in this study.|$|R
40|$|An {{efficient}} ASIC chip of the Golay codec {{has been}} designed for channel coding. This paper describes the new architecture used in this chip and the ASIC design. Due to the new architecture which implements a permutation decoding algorithm based on a new minimum permuation set proposed by J. Wolfmann (A Permutation Decoding of the (24, 12, 8) Golay code, IEEE Trans on Inform. Theory, vol. IT- 29, no. 5, pp. 748 - 750, Sept. 1983), the codec architecture is relatively simple and a higher speed of the decoding procedure can be achieved compared with the Golay decoder of the decoding algorithms in common use, error-trapping algorithm and step-by-step method. From S-W. Wei and C-H. Wei (On High-Speed Decoding of the (23, 12, 7) Golay Code, IEEE Trans. on Inform. Theory, vol IT- 36, no. 3, pp. 692 - 695, May 1990) Kasami's error-trapping decoder requires 46 shift-operations for decoding one completely received word and the modified step-by-step decoder requires 35 shift-operations, while our decoder requires only 14 permutation operations, generalized shift <b>operations.</b> Consequently, this <b>decoder</b> can work faster than the Kasami's error-trapping decoder and the modified step-by-step decoder...|$|R
40|$|The {{microprocessor}} industry {{trend towards}} many-core architectures introduced {{the necessity of}} devising appropriately scalable applications. In video decoding, the main challenges are the optimized partitioning of <b>decoder</b> <b>operations,</b> efficient tracking of dependencies and resource allocation/synchronization for multiple threads. In this paper, we propose a decoder architecture that replaces the conventional monolithic design with a pipelined structure. Bit stream decoding and image processing are separated from each other {{by means of a}} Meta Format Stream. The Meta Format is forward-oriented and self contained and multistandard capable, so that processing of Meta Streams is independent of the originating bit stream. Our approach does not require special coding settings and is applicable to accelerated decoding of any standards-compliant bit stream. A H. 264 multiprocessing proposal is presented as a case study for the potential our our decoder architecture. The case study combines coarse grained frame-level parallel decoding of the bit stream with fine-grained macroblock level parallelism in the image processing stage. The proposed H. 264 decoder achieved speedup factors of up to 7. 6 on an 8 core machine with 2 -way SMT. We are reporting actual decoding speeds of up to 150 frames per second in 2160 p-resolution...|$|R
40|$|Most {{distributed}} {{source coding}} schemes involve {{the application of}} a channel code to the signal and transmission of the resulting syndromes. For low complexity encoding with superior compression performance, graph-based channel codes such as LDPC codes are used to generate the syndromes. The encoder performs simple XOR <b>operations,</b> while the <b>decoder</b> uses belief propagation (BP) decoding to recover the signal of interest using the syndromes and some correlated side information. We consider parallelization of BP decoding on general-purpose multi core CPUs. The motivation is to make BP decoding fast enough for realtime applications. We consider three different BP decoding algorithms: Sum-Product BP, Min-Sum BP and Algorithm E. The speedup obtained by parallelizing these algorithms is examined along with the tradeoff against decoding performance Parallelization is achieved by dividing the received syndrome vectors among different cores, and by using vector operations to simultaneously process multiple check nodes in each core. While Min-Sum BP has intermediate decoding complexity, a âvectorizedâ version of Min-Sum BP performs nearly as fast as the much simpler Algorithm E with significantly fewer decoding errors. Our experiments indicates that, for the best compromise between speed and performance, the decoder should use Min-Sum BP when the side information is of good quality and Sum-Product BP otherwise...|$|R
40|$|Abstract- Variable length coding (VLC) is very {{suitable}} for regular data and efficient to compress data without any loss. VLC uses shorter bits of codewords instead of data occurring frequently, but uses the longer bits of codewords instead of data occurring infrequently. It {{is used in}} MPEG â 1 / 2 / 4 and H. 26 X (video and image compression standards). The entropy decoder in MPEG- 4 AVC/H. 264 baseline standard adopts Content Adaptive Variable Length Decoder (CAVLD). Because of symbol-to-symbol dependency, a traditional CAVLC decoder consumes lots of clock cycles in decoding and brings down the performance. We discover the decoding of two parameters spending almost eighty percent of computing time through profiling the computation of sub-modules and analyzing the encoding rules, which are non-zero coefficient (Level) and run_before. Thus this paper proposes a fast algorithm adapted for run_before decoder and the parallel architecture for level decoder, to improve the decoding performance. According to the features of these two methods, we name these two new methods as MLD (Multiple Level Decoding) and NZS (Non-Zero Skipping for run_before decoding). By performing parallel <b>operation</b> on level <b>decoder,</b> MLD can decode two levels in one cycle at most situations, and NZS can produce several values of run_before in the same cycle. These two methods have the advantages of low complexity and regularity design. Keywords [...] CAVLC Encoder, Decoder, H. 264. I...|$|R
40|$|In {{order to}} enhance {{performance}} {{and to support}} highly integrated functions, on-chip memory area has increased every technology generation. However, increased effect of parametric variations, susceptibility to soft errors, and increased leakage current in scaled technologies pose significant challenges {{in the design of}} low-power robust on-chip memory. In addition, there are application-specific design requirements. This research addresses the aforementioned issues related to on-chip memories to achieve robustness as well as optimality in terms of design requirements. ^ Soft errors are especially important in Field Programmable Gate Arrays (FPGAs). In particular, soft errors in programming memory, leads to incorrect functionality in FPGAs. We present soft-error-tolerant FPGA operations using a new built-in 2 -dimensional Hamming product code. Next, we propose a wide-range Voltage-Frequency-Scaling (VFS) Viterbi decoder using a novel traceback memory. Considering memory access patterns specific to Viterbi traceback, along with low-voltage array design, highly energy-efficient Viterbi <b>decoder</b> <b>operation</b> with wide-range of VFS is achieved. For general purpose computing, we first focus on on-chip SRAM cache design for energy-efficient high-performance operation. We present a 1 R/ 1 W multi-port 8 T-SRAM array with column selection that enables supply-voltage-scalable set-associative caches with 1 R/ 1 W multi-port. The proposed technique addresses the limitation of a conventional 8 T SRAM in which column selection prevents multi-port operation and vice versa. Finally, we consider Spin-Transfer Torque Magnetic RAM (STT-MRAM) as an alternative to SRAMs for future processors. A detailed analysis of energy-efficiency, area, and performance in comparisons to SRAM caches is carried out. It is shown that STT-MRAM cache has significant energy and performance benefits in low level cache hierarchy. In order to address excessive write-energy requirement of STT-MRAM, we propose a new cache architecture performing partial-line-update. The proposed architecture provides significant write-energy reduction, which can potentially make STT-MRAM suitable for on-chip caches. ...|$|R
40|$|A {{prototype}} decoder for a serially concatenated pulse position modulation (SCPPM) code {{has been}} implemented in a {{field-programmable gate array}} (FPGA). At {{the time of this}} reporting, this is the first known hardware SCPPM decoder. The SCPPM coding scheme, conceived for free-space optical communications with both deep-space and terrestrial applications in mind, is an improvement of several dB over the conventional Reed-Solomon PPM scheme. The design of the FPGA SCPPM decoder is based on a turbo decoding algorithm that requires relatively low computational complexity while delivering error-rate performance within approximately 1 dB of channel capacity. The SCPPM encoder consists of an outer convolutional encoder, an interleaver, an accumulator, and an inner modulation encoder (more precisely, a mapping of bits to PPM symbols). Each code is describable by a trellis (a finite directed graph). The SCPPM decoder consists of an inner soft-in-soft-out (SISO) module, a de-interleaver, an outer SISO module, and an interleaver connected in a loop (see figure). Each SISO module applies the Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm to compute a-posteriori bit log-likelihood ratios (LLRs) from apriori LLRs by traversing the code trellis in forward and backward directions. The SISO modules iteratively refine the LLRs by passing the estimates between one another much like the working of a turbine engine. Extrinsic information (the difference between the a-posteriori and a-priori LLRs) is exchanged rather than the a-posteriori LLRs to minimize undesired feedback. All computations are performed in the logarithmic domain, wherein multiplications are translated into additions, thereby reducing complexity and sensitivity to fixed-point implementation roundoff errors. To lower the required memory for storing channel likelihood data and the amounts of data transfer between the decoder and the receiver, one can discard the majority of channel likelihoods, using only the remainder in <b>operation</b> of the <b>decoder.</b> This is accomplished in the receiver by transmitting only a subset consisting of the likelihoods that correspond to time slots containing the largest numbers of observed photons during each PPM symbol period. The assumed number of observed photons in the remaining time slots is set to the mean of a noise slot. In low background noise, the selection of a small subset in this manner results in only negligible loss. Other features of the decoder design to reduce complexity and increase speed include (1) quantization of metrics in an efficient procedure chosen to incur no more than a small performance loss and (2) the use of the max-star function that allows sum of exponentials to be computed by simple operations that involve only an addition, a subtraction, and a table lookup. Another prominent feature of the design is a provision for access to interleaver and de-interleaver memory in a single clock cycle, eliminating the multiple clock-cycle latency characteristic of prior interleaver and de-interleaver designs...|$|R

