30|192|Public
2500|$|Many {{operators}} of particular web applications (e.g. forums and webmail) allow users to utilize a limited subset of HTML markup. When accepting HTML input from users (say, <b>very</b> large), <b>output</b> <b>encoding</b> (such as &lt;b&gt;very&lt;/b&gt; large) will not suffice since the user input {{needs to be}} rendered as HTML by the browser (so it shows as [...] "very large", instead of [...] "<b>very</b> large"). Stopping an XSS attack when accepting HTML input from users is much more complex in this situation. Untrusted HTML input must be run through an HTML sanitization engine {{to ensure that it}} does not contain XSS code.|$|E
5000|$|<b>Output</b> <b>encoding</b> can done to most {{most common}} {{video and audio}} formats ...|$|E
5000|$|<b>Output</b> <b>encoding,</b> i.e. {{preventing}} HTML Injection (XSS) {{attacks against}} web site visitors ...|$|E
30|$|Queries O_Encode oracle for EncodeforAttributes and EncodeforPolicy of _PE. That is to say, {{choosing}} {{one subject}} attribute conjunction A_ 1 and one attribute conjunction in an authorization policy _ 1, <b>outputting</b> <b>encoded</b> attributes BF_ 1 ^A and encoded policy BF_ 1 ^P.|$|R
40|$|Communication systems having transmitter, {{includes}} a coder configured to receive user bits and <b>output</b> <b>encoded</b> bits at an expanded <b>output</b> <b>encoded</b> bit rate, a mapper configured to map encoded bits to symbols in a symbol constellation, a modulator configured {{to generate a}} signal for transmission via the communication channel using symbols generated by the mapper. In addition, the receiver {{includes a}} demodulator configured to demodulate the received signal via the communication channel, a demapper configured to estimate likelihoods from the demodulated signal, a decoder that is configured to estimate decoded bits from the likelihoods generated by the demapper. Furthermore, the symbol constellation is a capacity optimized geometrically spaced symbol constellation that provides a given capacity at a reduced signal-to-noise ratio compared to a signal constellation that maximizes d. sub. min...|$|R
40|$|Developmental {{temperature}} sensor consists of silicon Fabry-Perot etalon attached to end of optical fiber. Features immunity to electrical interference, small size, light weight, safety, and chemical inertness. <b>Output</b> <b>encoded</b> in ration of intensities at two different wavelengths, {{rather than in}} overall intensity, with result that temperature readings not degraded much by changes in transmittance of fiber-optic link...|$|R
5000|$|SubRip's default <b>output</b> <b>encoding</b> is {{configured}} as Windows-1252. However, output {{options are}} also given for many Windows code pages as well Unicode encodings, such as UTF-8 and UTF-16, {{with or without}} Byte Order Mark (BOM). Therefore, there's no de facto character encoding standard for [...] files, which means that any SubRip file parser must attempt to use Charset detection. Unicode Byte Order Mark (BOM) are typically used to aid detection.|$|E
5000|$|Many {{operators}} of particular web applications (e.g. forums and webmail) allow users to utilize a limited subset of HTML markup. When accepting HTML input from users (say, very large), <b>output</b> <b>encoding</b> (such as <b>very</b> large) will not suffice since the user input {{needs to be}} rendered as HTML by the browser (so it shows as [...] "very large", instead of [...] "very large"). Stopping an XSS attack when accepting HTML input from users is much more complex in this situation. Untrusted HTML input must be run through an HTML sanitization engine {{to ensure that it}} does not contain XSS code.|$|E
3000|$|..., the {{encoding}} {{process will}} resemble other traditional linear coding schemes, i.e., the <b>output</b> <b>encoding</b> sequence is x=u [...]...|$|E
50|$|Time domain {{refers to}} how {{analysis}} and quantization is performed on short, discrete samples/chunks of the audio waveform. This offers low delay {{as only a}} small number of samples are analyzed before encoding, as opposed to frequency domain encoding (like MP3) which must analyze many times more samples before it can decide how to transform and <b>output</b> <b>encoded</b> audio. This also offers higher performance on complex, random and transient impulses (such as percussive instruments, and applause), offering avoidance of artifacts like pre-echo.|$|R
40|$|Abstract — Image compression, in {{the present}} context of heavy network traffic, is going through major {{research}} and development. The lossless compression techniques, presently in practise, follow three basic paradigms – character repetition removal, frequency measurement-encoding and dictionary maintenance. In the proposed method, the character repetition removal and dictionary maintenance concepts were incorporated together. The <b>output</b> <b>encoded</b> file had yielded comparably better results than standard lossless image compression techniques. The proposed method had been tested {{on a series of}} continuous and discreet tone standard test images...|$|R
50|$|At {{the end of}} {{the dynamic}} {{programming}} optimization, the whole optimal encoding of the longest substring considered is <b>output,</b> and <b>encoding</b> continues at the first uncompressed byte not already encoded, after updating the LZMA state and least used distances.|$|R
40|$|This paper {{addresses}} the stabilization of quantized linear systems under Denial-of-Service (DoS) attacks. Using a state transformation that satisfies a certain norm condition, we first propose an <b>output</b> <b>encoding</b> method that achieves the stabilization of systems with finite-data rates only under an assumption on {{the duration of}} DoS attacks. Next we add a condition on the frequency of DoS attacks and develop an <b>output</b> <b>encoding</b> method with an arbitrary state transformation. Finally we illustrate the obtained results with numerical simulations. Comment: 8 pages, 7 figure...|$|E
40|$|We {{present a}} new <b>output</b> <b>encoding</b> problem as follows: Given a {{specification}} table, {{such as a}} truth table or a finite state machine state table, {{where some of the}} outputs are specified in terms of 1 's, 0 's and don't cares, and others are specified symbolically, and assuming that the minimum number of bits are used to encode the symbolic outputs (#log 2 n# bits for n symbolic outputs), determine a binary code for each symbol of the symbolically specified output column such that the total number of output functions to be implemented after encoding the symbolic outputs and compacting the columns is minimum. There are several applications of this <b>output</b> <b>encoding</b> problem, one of which is to reduce the area overhead while implementing scan or pseudo-random BIST in a circuit with one-hot signals. We develop an exact algorithm to solve the above problem and present experimental data to validate the claim that our encoding strategy helps to reduce the area of a synthesized circuit...|$|E
40|$|The {{design of}} {{self-checking}} circuits through <b>output</b> <b>encoding</b> finds a bottleneck in {{the realization of}} the network so that each fault produces only detectable errors. New conditions are defined for identifying the set of gates that, if faulty, cause undetectable errors, taking into account AUED codes (Berger and m-out-of-n) and the Parity code, for a reduction of the re-design of the circuit and, consequently, of costs...|$|E
5000|$|Vulnerability protections: the {{framework}} <b>encodes</b> <b>output,</b> provides CSRF protection, cross-site scripting protection, input filtering features, and prevents SQL injection.|$|R
5000|$|The model {{includes}} an oracle that executes the group operation. This oracle takes two encodings of group elements as input and <b>outputs</b> an <b>encoding</b> {{of a third}} element. If the group should allow for a pairing operation this operation would be modeled as an additional oracle.|$|R
40|$|Increasingly, {{practitioners}} apply {{neural networks}} to complex problems in {{natural language processing}} (NLP), such as syntactic parsing, that have rich output structures. Many such applications require deterministic constraints on the output values; for example, requiring that the sequential <b>outputs</b> <b>encode</b> a valid tree. While hidden units might capture such properties, the network is not always able to learn them from the training data alone, and practitioners must then resort to post-processing. In this paper, we present an inference method for neural networks that enforces deterministic constraints on outputs without performing post-processing or expensive discrete search over the feasible space. Instead, for each input, we nudge the continuous weights until the network's unconstrained inference procedure generates an output that satisfies the constraints. We find that our method reduces the number of violating outputs by up to 94 %, while improving accuracy in constituency parsing...|$|R
40|$|A {{technique}} for designing sequential circuits which are totally self-checking for single stuck at faults is presented. This technique uses m-out-of-n codes for state assignments and for <b>output</b> <b>encoding.</b> The next stage logic and the output logic are implemented such that any stuck-at-fault will either create a single bit error or unidirectional multibit error at the output. The technique {{has been applied}} to MCNC benchmark circuits and the overhead is estimated...|$|E
40|$|This paper {{presents}} our novel {{method to}} encode word confusion networks, which can represent a rich hypothesis space of {{automatic speech recognition}} systems, via recurrent neural networks. We demonstrate the utility of our approach for the task of dialog state tracking in spoken dialog systems that relies on automatic speech recognition <b>output.</b> <b>Encoding</b> confusion networks outperforms encoding the best hypothesis of the automatic speech recognition in a neural system for dialog state tracking on the well-known second Dialog State Tracking Challenge dataset. Comment: Speech-Centric Natural Language Processing Workshop @EMNLP 201...|$|E
40|$|We {{present a}} novel method for state {{minimization}} of incompletely-specified finite state machines. Where classic methods simply minimize {{the number of}} states, ours directly addresses the implementation's logic complexity, and produces an exactly optimal implementation under input encoding. The method incorporates optimal "state mapping", i. e., the process of reducing the symbolic next-state relation which results from state splitting to an optimal conforming symbolic function. Further, it offers a number of convenient sites for applying heuristics to reduce time and space complexity, and is amenable to implementation based on implicit representations. Although our method currently makes use of an input encoding model, we believe it can be extended smoothly to encompass <b>output</b> <b>encoding</b> as well...|$|E
40|$|Tree {{codes are}} known to be capable of {{performing}} arbitrarily close to the rate-distortion function for any memoryless source and single-letter fidelity criterion. Tree coding and tree search strategies are investigated for the discrete-time memoryless Gaussian source encoded for a signal-power-to-mean-squared-error ratio of about 30 dB (about 5 binary digits per source output). Also, a theoretical lower bound on average search effort is derived. Two code search strategies (the Viterbi algorithm and the stack algorithm) were simulated in assembly language on a large digital computer. After suitable modifications, both strategies yielded encoding with a signal-to-distortion ratio about 1 dB below the limit set by the rate-distortion function. Although this performance is better than that of any previously known instrumentable scheme, it unfortunately requires search computation of the order of 100, 000 machine cycles per source <b>output</b> <b>encoded...</b>|$|R
5000|$|The PMD 85-3 added colour TV <b>output.</b> Character <b>encoding</b> {{included}} all Czech and Slovak characters, and a Cyrillic version was also produced. System monitor was enlarged to 8 KiB and included routines for communication with PMD 32 floppy disk assembly, a ROM integrity test and also [...] "PMD 85 compatibility mode" [...] by relocation.|$|R
40|$|A ones adder is an {{important}} circuit block that is required in many varying applications. This work proposes a design that largely relies on passive transmission-gate multiplexers. Many variations are suggested that can inherently generate a thermometer coded <b>output</b> or one-hot <b>encoded</b> <b>output.</b> The proposed structure has area and power that increases with order n 2 for a n number of inputs. A folding technique is then suggested that reduces the area/power to order n log(n). The folded PLINCO also has a cell-based structure that aids in layout and {{makes it possible to}} be added to a digital standard cell library...|$|R
40|$|This article {{addresses}} {{the relation between}} item recognition and associative (cued) recall. Going beyond measures of performance on each task, the analysis focuses on {{the degree to which}} the contingency between successful recognition and successful recall of a studied item reflects the commonality of memory processes underlying the recognition and recall tasks. Specifically, 4 classes of distributed memory models are assessed for their ability to account for the relatively invariant correlation (. 5) between successive recognition and recall. Basic versions of each model either under- or overpredict the intertask correlation. Introducing variability in goodness-of-encoding and response criteria, as well as <b>output</b> <b>encoding,</b> enabled all 4 models to reproduce the moderate intertask correlation and the increase in correlation observed in 2 mixed-list experiments. This model-based analysis provides a general theoretical framework for interpreting contingencies between successive memory tests...|$|E
40|$|We {{propose a}} new {{approach}} to state assignment which explores area-power tradeoffs during state assignment. We show that the primary output transition density for any finite state machine depends only on the <b>output</b> <b>encoding</b> and input symbol statistics, assuming hazard-free logic implementations. We evaluate an approach to sequential circuit power estimation which takes temporal auto-correlations of state inputs into account. This is used to measure the efficacy of a new cost function for exploring area-power tradeoffs. We also show that output reencoding can considerably reduce the power consumed. Extensive results on benchmark state machines are included. I. Introduction Portable applications have made low power design an important issue. Besides, the power consumed may be the limiting factor in high performance systems, due to cooling costs and reliability concerns. The power consumed by an IC is primarily due to the clock drivers, the I/O circuitry and the internal logic. The state [...] ...|$|E
40|$|Software-engineering {{aspects of}} an {{experimental}} printed-page reader are described, {{with emphasis on}} data-structure choices. This reader performs {{a wide variety of}} tasks, including geometric layout analysis, symbol recognition, linguistic contextual analysis, and user-selectable <b>output</b> <b>encoding</b> (e. g. Unicode). We have implemented a single common data structure to support all these tasks. It embraces iconic, geometric, probabilistic, and symbolic data, and can represent the full physical document hierarchy as well as many partial stages of analysis. We illustrate the evolution of this data structure, in the course of reading a page, from purely iconic to purely symbolic form. The data structure can be snapshot in machine- and OS-independent peripheral files. Careful agreement on its semantics allows it {{to be used as a}} `blackboard' in an elegant exploitation of generic UNIX multi-processing. One partly unresolved issue is the best representation for ambiguities spanning several levels of [...] ...|$|E
50|$|The table below {{compares the}} most used forms of binary-to-text encodings. The {{efficiency}} listed is the ratio between {{number of bits}} in the input {{and the number of}} bits in the <b>encoded</b> <b>output.</b>|$|R
50|$|In coding theory, a {{systematic}} code is any error-correcting code {{in which the}} input data {{is embedded in the}} <b>encoded</b> <b>output.</b> Conversely, in a non-systematic code the output does not contain the input symbols.|$|R
40|$|Recent {{models of}} speech {{encoding}} suggest that movement plans for frequently used words are stored and {{that not all}} <b>output</b> is <b>encoded</b> by a process of segment-by segment assembly (Levelt, et al., 1999; Whiteside & Varley, 1998; Varley & Whiteside, 2001). We explore {{the implications of this}} view for the management of apraxia of speech (AOS). In a treatment study, the effectiveness of a computer-administered, word-level therapy was examined...|$|R
40|$|This paper explores {{hierarchical}} classification of web content {{by using a}} collection of probabilistic multiclassifiers implementing Error Correcting <b>Output</b> <b>Encoding</b> (ECOC) and Probabilistic Support Vector Machines. Error correcting output coding is a technique where ensembles of binary classifiers are used for the multi-way classification task. Using probabilistic support vector machines as binary classifiers, which {{are known for their}} effectiveness in text classification, we applied a probabilistic ECOC technique in categorizing real world datasets for the multi-class learning problem. In {{hierarchical classification}}, the initial classification is critical since subsequent level of multi classifiers cannot recover from an error that occurred at a higher level. We tried to approach this problem by constructing another category structure called a shortcut hierarchy, which skips the intermediate level in the category structure. By observing prediction disagreements between the direct and shortcut hierarchical classifiers, misclassifications could be detected which could aid in error recovery...|$|E
40|$|This paper {{presents}} {{techniques for}} designing arbitrary combinational circuits {{so that any}} single stuck-at fault will result in either single bit error or unidirectional multibit error at the output. If the outputs are encoded using Berger code or m-out-of-n code, then the proposed technique will enable on-line detection of faults in the circuit. An algorithm for indicating whether a certain fault at an input will create bidirectional error at the output is presented. An input encoding algorithm and an <b>output</b> <b>encoding</b> algorithm that ensure that every fault will either produce single bit error or unidirectional multibit error at the output are proposed. If there are no input fault which produces bidirectional error, no internal stuck-at fault will result in such an error irrespective {{of the way the}} circuit is implemented. Thus, only single bit or unidirectional multibit error will result {{in the presence of a}} fault in the circuit. The proposed techniques have been applied to MCNC benchmark circuits and the overhead is estimated...|$|E
40|$|Abstract Despite {{the fact}} that many {{symbolic}} and neural network (connectionist) learning algorithms address the same problem of learning from classified examples, very little is known regarding their comparative strengths and weaknesses. Experiments comparing the ID 3 symbolic learning algorithm with the perception and backpropagation neural learning algorithms have been performed using five large, real-world data sets. Overall, backpropagation performs slightly better than the other two algorithms in terms of classification accuracy on new examples, but takes much longer to train. Experimental results suggest that backpropagation can work significantly better on data sets containing numerical data. Also analyzed empirically are the effects of (1) the amount of training data, (2) imperfect training examples, and (3) the encoding of the desired outputs. Backpropagation occasionally outperforms the other two systems when given relatively small amounts of training data. It is slightly more accurate than ID 3 when examples are noisy or incompletely specified. Finally, backpropagation more effectively utilizes a &quot;distributed &quot; <b>output</b> <b>encoding...</b>|$|E
40|$|Abstract: Deoxyribonucleic Acid or DNA-based {{computing}} is {{an emerging}} field that {{bridging the gap}} between chemistry, molecular biology, computer science, and mathematics. This research area is a new paradigm whereby the computation {{can be done by}} the use of DNA molecules to encode the computational problem. During the massively parallel computation in a test tube, a series of bio-molecular reactions are employed and the <b>output</b> <b>encoded</b> also by DNA molecules can be printed and read out by electrophoretical fluorescent method. Since DNA computing is very suitable for combinatorial problems, in this paper, an idea on DNA-based computing algorithm for solving unconstraint assignment problem is proposed. The proposed approach basically consists of two phases; encoding phase and computational phase. During the encoding phase, a method to encode the computational problem is carried out by introducing four rules. On the other hand, for the computational phase, it is discovered that the complexity of the unconstraint assignment problem can be reduced to a path problem of a graph, and the possibility to solve the unconstraint assignment problem by DNA computing approach is shown in detail...|$|R
40|$|Deoxyribonucleic Acid or DNA-based {{computing}} is {{an emerging}} field that {{bridging the gap}} between chemistry,molecular biology, computer science, and mathematics. This research area is a new paradigm whereby the computation canbe done {{by the use of}} DNA molecules to encode the computational problem. During the massively parallel computation in atest tube, a series of bio-molecular reactions are employed and the <b>output</b> <b>encoded</b> also by DNA molecules can be printed andread out by electrophoretical fluorescent method. Since DNA computing is very suitable for combinatorial problems, in thispaper, an idea on DNA-based computing algorithm for solving unconstraint assignment problem is proposed. The proposedapproach basically consists of two phases; encoding phase and computational phase. During the encoding phase, a method toencode the computational problem is carried out by introducing four rules. On the other hand, for the computational phase, itis discovered that the complexity of the unconstraint assignment problem can be reduced to a path problem of a graph, and thepossibility to solve the unconstraint assignment problem by DNA computing approach is shown in detail...|$|R
5000|$|A [...] {{appears at}} the end of every packet to {{indicate}} end-of-packet to the data receiver. This packet delimiter byte does not correspond to a data byte; it is an additional byte that is appended to the <b>encoded</b> <b>output.</b>|$|R
