2229|10000|Public
5|$|Radiocarbon dating tests {{conducted}} on 1QpHab and 4QpPsa at the Arizona Accelerator Mass Spectrometry Facility gave a <b>one</b> <b>standard</b> <b>deviation</b> confidence interval of 104-43 BCE and a two sigma confidence interval of 120-5 BCE (97%); for 4QpPsa (4Q171) the <b>one</b> <b>standard</b> <b>deviation</b> confidence interval was 22-78 CE {{and the two}} sigma confidence interval was 5-111 CE. Earlier paleographic dating of 1QpHab indicated a date range of 30-1 BCE.|$|E
5|$|Radiocarbon {{dates are}} {{generally}} {{presented with a}} range of <b>one</b> <b>standard</b> <b>deviation</b> (usually represented by the Greek letter sigma as 1σ) {{on either side of the}} mean. However, a date range of 1σ represents only 68% confidence level, so the true age of the object being measured may lie outside the range of dates quoted. This was demonstrated in 1970 by an experiment run by the British Museum radiocarbon laboratory, in which weekly measurements were taken on the same sample for six months. The results varied widely (though consistently with a normal distribution of errors in the measurements), and included multiple date ranges (of 1σ confidence) that did not overlap with each other. The measurements included one with a range from about 4250 to about 4390 years ago, and another with a range from about 4520 to about 4690.|$|E
25|$|If the {{distribution}} has finite variance, then {{the distance between}} the median and the mean is bounded by <b>one</b> <b>standard</b> <b>deviation.</b>|$|E
5000|$|The Threshold GARCH (TGARCH) {{model by}} Zakoian (1994) {{is similar to}} GJR GARCH. The {{specification}} is <b>one</b> on conditional <b>standard</b> <b>deviation</b> instead of conditional variance: ...|$|R
25|$|Moderate: Two facial {{features}} ranked as severe and one feature ranked as moderate (lip or philtrum ranked at 3, or PFL between <b>one</b> and two <b>standard</b> <b>deviations</b> below average).|$|R
5000|$|The {{effect size}} {{is a measure}} {{obtained}} by dividing {{the difference between the}} means of the baseline and posttreatment scores by the SD of the baseline scores. An effect size cut off point can be used to define MCID {{in the same way as}} the <b>one</b> half <b>standard</b> <b>deviation</b> and the <b>standard</b> error of measurement.|$|R
25|$|African American, Hispanic, and Native American students, on average, {{perform an}} order of <b>one</b> <b>standard</b> <b>deviation</b> lower on the SAT than white and Asian students.|$|E
25|$|The nonparametric skew is {{one third}} of the Pearson 2 {{skewness}} coefficient and lies between 1 and +1 for any distribution. This range is implied {{by the fact that the}} mean lies within <b>one</b> <b>standard</b> <b>deviation</b> of any median.|$|E
25|$|About 68% {{of values}} {{drawn from a}} normal {{distribution}} are within <b>one</b> <b>standard</b> <b>deviation</b> σ away from the mean; about 95% of the values lie within two standard deviations; and about 99.7% are within three standard deviations. This fact {{is known as the}} 68-95-99.7 (empirical) rule, or the 3-sigma rule.|$|E
5000|$|The {{racial group}} {{differences}} across admissions tests, {{such as the}} SAT, ACT, GRE, GMAT, MCAT, LSAT, Advanced Placement Program examinations and other measures of educational achievement, have been fairly consistent. Since the 1960s, the population of students taking these assessments has become increasingly diverse. Consequently, the examination of ethnic score differences have been more rigorous. Specifically, the largest gaps exist between white and African American students. On average, they score about [...]82 to 1.18 <b>standard</b> <b>deviations</b> lower than white students in composite test scores. Following closely behind is the gap between white and Hispanic students. Asian American students performance were {{comparable to those of}} White students except Asian American students performed <b>one</b> quarter <b>standard</b> <b>deviation</b> unit lower on the SAT verbal section, and about <b>one</b> half a <b>standard</b> <b>deviation</b> unit higher in the GRE Quantitative test.|$|R
2500|$|... (equivalently, {{from the}} fact that normal {{distributions}} maximize the entropy of all such with a given variance), it readily follows that this entropic uncertainty principle is stronger than the <b>one</b> based on <b>standard</b> <b>deviations,</b> because ...|$|R
50|$|With average SAT {{scores of}} 635, 609, and 596 in the math, {{critical}} reading, and writing sections respectively, students who attend Mercer Island High School score just over <b>one</b> full <b>standard</b> <b>deviation</b> {{above the national}} average SAT score. Mercer Island also features the highest Washington Assessment of Student Learning scores statewide. Additionally, more than 90% of graduates pursue higher education, with 87% of those attending four-year institutions.|$|R
25|$|IQ {{scales are}} ordinally scaled. While <b>one</b> <b>standard</b> <b>deviation</b> is 15 points, and two SDs are 30 points, and so on, {{this does not}} imply that mental ability is linearly related to IQ, such that IQ 50 means half the {{cognitive}} ability of IQ 100. In particular, IQ points are not percentage points.|$|E
25|$|If a data {{distribution}} is approximately normal then about 68 {{percent of the}} data values are within <b>one</b> <b>standard</b> <b>deviation</b> of the mean (mathematically, μ±σ, where μ is the arithmetic mean), about 95 percent are within two standard deviations (μ±2σ), and about 99.7 percent lie within three standard deviations (μ±3σ). This {{is known as the}} 68-95-99.7 rule, or the empirical rule.|$|E
25|$|Patients with demyelinating illnesses, such as MS, {{have shown}} {{cognitive}} deficits {{even when there}} is minimal physical disability. Research suggests that similar effects are seen after ADEM, but that the deficits are less severe than those seen in MS. A study of six children with ADEM (mean age at presentation 7.7 years) were tested {{for a range of}} neurocognitive tests after an average of 3.5 years of recovery. All six children performed in the normal range on most tests, including verbal IQ and performance IQ, but performed at least <b>one</b> <b>standard</b> <b>deviation</b> below age norms in at least one cognitive domain, such as complex attention (one child), short-term memory (one child) and internalizing behaviour/affect (two children). Group means for each cognitive domain were all within <b>one</b> <b>standard</b> <b>deviation</b> of age norms, demonstrating that, as a group, they were normal. These deficits were less severe than those seen in similar aged children with a diagnosis of MS.|$|E
50|$|Error bars in {{the last}} digit or digits are shown by numbers in parentheses. Thus, 0.729724(3) signifies 0.729724 ± 0.000003, and 0.74042195(80) signifies 0.74042195 ± 0.00000080. The error bars {{variously}} represent <b>one</b> or two <b>standard</b> <b>deviations</b> in net error (including statistical and expected systematic error), or an empirical confidence interval.|$|R
30|$|Children with MMC are at {{increased}} risk of pathological fractures due to motor and sensory deficits and disuse of lower limbs compared with their able-bodied peers. It has been demonstrated that children with MMC have a bone mineral density <b>one</b> to two <b>standard</b> <b>deviations</b> below the mean of the normal population [32].|$|R
5000|$|The quantum entropic {{uncertainty}} principle is more restrictive than the Heisenberg {{uncertainty principle}}. From the inverse logarithmic Sobolev inequalities(equivalently, {{from the fact}} that normal distributions maximize the entropy of all such with a given variance), it readily follows that this entropic uncertainty principle is stronger than the <b>one</b> based on <b>standard</b> <b>deviations,</b> because ...|$|R
25|$|Here {{the program}} calculates an optimal {{alignment}} of initial regions {{as a combination}} of compatible regions with maximal score. This optimal alignment of initial regions can be rapidly calculated using a dynamic programming algorithm. The resulting score initn is used to rank the library sequences.This joining process increases sensitivity but decreases selectivity. A carefully calculated cut-off value is thus used to control where this step is implemented, a value that is approximately <b>one</b> <b>standard</b> <b>deviation</b> above the average score expected from unrelated sequences in the library. A 200-residue query sequence with kmer 2 uses a value 28.|$|E
25|$|Divergence Angle: The {{representative}} {{range of}} leeway angles for {{a category of}} leeway objects. It can be calculated by obtaining the net leeway angle over time for a specific leeway object’s drift trajectory, and then averaging again {{for a series of}} leeway drift trajectories of a number of leeway objects in a leeway category, to determine the mean leeway angle and standard deviation of the leeway angle for the category. Divergence angle is then calculated as twice the standard deviation of the leeway angle, or mean plus <b>one</b> <b>standard</b> <b>deviation</b> of the leeway angle, or mean plus two standard deviations of the leeway angle depending on the particular study.|$|E
25|$|Another study {{compared}} nineteen {{children with}} a history of ADEM, of which 10 were five years of age or younger at the time (average age 3.8 years old, tested an average of 3.9 years later) and nine were older (mean age 7.7y at time of ADEM, tested an average of 2.2 years later) to nineteen matched controls. Scores on IQ tests and educational achievement were lower for the young onset ADEM group (average IQ 90) compared to the late onset (average IQ 100) and control groups (average IQ 106), while the late onset ADEM children scored lower on verbal processing speed. Again, all groups means were within <b>one</b> <b>standard</b> <b>deviation</b> of the controls, meaning that while effects were statistically reliable, the children were as a whole, still within the normal range. There were also more behavioural problems in the early onset group, although there is some suggestion that this may be due, at least in part, to the stress of hospitalization at a young age.|$|E
5000|$|The term [...] "six sigma process" [...] {{comes from}} the notion that if <b>one</b> has six <b>standard</b> <b>deviations</b> between the process mean and the nearest {{specification}} limit, {{as shown in the}} graph, practically no items will fail to meet specifications. This is based on the calculation method employed in process capability studies.|$|R
30|$|To {{assess the}} {{accuracy}} of the results, three parameters were used. The first one, the maximal distance, is the distance between the furthest point from the point cloud and the surface. The second one, the average distance, is the mean distance between all points from the point cloud and the surface. The last <b>one</b> is the <b>standard</b> <b>deviation.</b>|$|R
5000|$|The 2-dimensional Ising model {{exists on}} a lattice, {{which is a}} {{collection}} of squares in a chessboard pattern. With the finite lattice, the edges can be connected to form a torus. In theories of this kind, one constructs an involutive transform. For instance, Lars Onsager suggested that the Star-Triangle transformation could be used for the triangular lattice. [...] Now the dual of the discrete torus is itself. Moreover, the dual of a highly disordered system (high temperature) is a well-ordered system (low temperature). This is because the Fourier transform takes a high bandwidth signal (more <b>standard</b> <b>deviation)</b> to a low <b>one</b> (less <b>standard</b> <b>deviation).</b> So <b>one</b> has essentially the same theory with an inverse temperature.|$|R
25|$|In 1963 Benoit Mandelbrot {{analyzed}} the variations of cotton prices on a time series starting in 1900. There were two important findings. First, price movements {{had very little}} to do with a normal distribution in which the bulk of the observations lies close to the mean (68% of the data are within <b>one</b> <b>standard</b> <b>deviation).</b> Instead, the data showed a great frequency of extreme variations. Second, price variations followed patterns that were indifferent to scale: the curve described by price changes for a single day was similar to a month’s curve. Surprisingly, these patterns of self-similarity were present during the entire period 1900-1960, a violent epoch that had seen a Great Depression and two world wars. Mandelbrot used his fractal theory to explain the presence of extreme events in Wall Street. In 2004 he published his book on the “misbehavior” of financial markets - The (Mis)behavior of Markets: A Fractal View of Risk, Ruin, and Reward. The basic idea that relates fractals to financial markets is that the probability of experiencing extreme fluctuations (like the ones triggered by herd behavior) is greater than what conventional wisdom wants us to believe. This of course delivers a more accurate vision of risk in the world of finance. The central objective in financial markets is to maximize income for a given level of risk. Standard models for this are based on the premise that the probability of extreme variations of asset prices is very low.|$|E
500|$|The current {{scoring method}} for all IQ tests is the [...] "deviation IQ". In this method, an IQ score of 100 {{means that the}} test-taker's {{performance}} on the test is at the median level of performance in the sample of test-takers of {{about the same age}} used to norm the test. An IQ score of 115 means performance <b>one</b> <b>standard</b> <b>deviation</b> above the median, a score of 85 performance <b>one</b> <b>standard</b> <b>deviation</b> below the median, and so on. Lewis Terman and other early developers of IQ tests noticed that most child IQ scores come out to approximately the same number by either procedure. Deviation IQs are now used for standard scoring of all IQ tests in large part because they allow a consistent definition of IQ for both children and adults. By the current [...] "deviation IQ" [...] definition of IQ test standard scores, about two-thirds of all test-takers obtain scores from 85 to 115, and about 5 percent of the population scores above 125.|$|E
500|$|For example, [...] "cal 1220–1281 AD (1σ)" [...] means a {{calibrated}} {{date for}} which the true date lies between 1220 AD and 1281 AD, with the confidence level given as 1σ, or <b>one</b> <b>standard</b> <b>deviation.</b> Calibrated dates can also be expressed as BP instead of using BC and AD. The curve used to calibrate the results should be the latest available INTCAL curve. Calibrated dates should also identify any programs, such as OxCal, used to perform the calibration. [...] In addition, an article in Radiocarbon in 2014 about radiocarbon date reporting conventions recommends that information should be provided about sample treatment, including the sample material, pretreatment methods, and quality control measurements; that the citation to the software used for calibration should specify the version number and any options or models used; and that the calibrated date should be given with the associated probabilities for each range.|$|E
40|$|Existing {{studies from}} the United States, Latin America, and Asia provide scant {{evidence}} that private schools dramatically improve academic performance relative to public schools. Using data from Kenya—a poor country with weak public institutions—we find a large effect of private schooling on test scores, equivalent to <b>one</b> full <b>standard</b> <b>deviation.</b> This finding is robust to endogenous sorting of more able pupils into private schools. The {{magnitude of the}} effect dwarfs the impact of any rigorously tested intervention to raise performance within public schools. Furthermore, nearly two-thirds of private schools operate at lower cost than the median government school. ...|$|R
30|$|When {{considering}} {{the development of}} competencies, one half of a <b>standard</b> <b>deviation</b> was considered to represent a moderate change, and <b>one</b> full <b>standard</b> <b>deviation</b> was considered to represent a substantial change. The analysis according to the longitudinal model resulted in an estimated development of 0.04 <b>standard</b> <b>deviations</b> between t 1 and t 2, which also provides confirmation of the latent correlation of r = . 89. This indicates {{that in terms of}} competencies, very little changed over time. The slight increase in the <b>standard</b> <b>deviation</b> of the second measurement also suggests that the competency level barely shifted. However, a closer examination of these developments reveals that there are two groups of comparable size, one with a substantial learning progression (14.7  %) and another with a substantial learning regression (12.2  %). The groups with moderate development are also of mutually similar size as 33.9  % of participants experienced a moderate progression and 22.6  % experienced a moderate regression after 1  year. This suggests that the development of competency occurred at similar rates in two distinct directions, which explains the observation of zero net overall growth.|$|R
40|$|Preliminary version – Do not cite or {{circulate}} without author’s permission The general-equilibrium {{effects of}} performance-related teacher pay include long-term incentive and teacher-sorting mechanisms that usually elude experimental studies but are captured in cross-country comparisons. Combining country-level performance-pay measures with rich PISA- 2003 international achievement microdata, this paper estimates student-level international education production functions. The use of teacher salary adjustments for outstanding performance is {{significantly associated with}} math, science, and reading achievement across countries. Scores in countries with performance-related pay are about <b>one</b> quarter <b>standard</b> <b>deviations</b> higher. Results avoid bias from within-country selection and are robust to continental fixed effects and to controlling for non-performance-based forms of teacher salary adjustments...|$|R
500|$|The Wechsler {{intelligence}} {{scales were}} originally developed from earlier intelligence scales by David Wechsler. The first Wechsler test published was the Wechsler–Bellevue Scale in 1939. The Wechsler IQ tests {{for children and}} for adults are {{the most frequently used}} individual IQ tests in the English-speaking world and in their translated versions are perhaps the most widely used IQ tests worldwide. The Wechsler tests have long been regarded as the [...] "gold standard" [...] in IQ testing. The Wechsler Adult Intelligence Scale—Fourth Edition (WAIS–IV) was published in 2008 by The Psychological Corporation. The Wechsler Intelligence Scale for Children—Fifth Edition (WISC–V) was published in 2014 by The Psychological Corporation, and the Wechsler Preschool and Primary Scale of Intelligence—Fourth Edition (WPPSI–IV) was published in 2012 by The Psychological Corporation. Like all current IQ tests, the Wechsler tests report a [...] "deviation IQ" [...] as the standard score for the full-scale IQ, with the norming sample median raw score defined as IQ 100 and a score <b>one</b> <b>standard</b> <b>deviation</b> higher defined as IQ 115 (and one deviation lower defined as IQ 85).|$|E
2500|$|Its density has two {{inflection}} points (where {{the second}} derivative of [...] is zero and changes sign), located <b>one</b> <b>standard</b> <b>deviation</b> {{away from the}} mean, namely at [...] and [...]|$|E
2500|$|A 2017 {{study in}} the Economic Journal found that for Britain during the period 1851–1860, [...] "a <b>one</b> <b>standard</b> <b>deviation</b> {{increase}} in coal use raised infant mortality by 6–8% and that industrial coal use explains roughly one-third of the urban mortality penalty observed during this period." ...|$|E
40|$|The {{major event}} of the 9 / 11 terror attacks {{is likely to have}} induced an {{increase}} in anti-immigrant and anti-foreigner sentiments, not only among US residents but also beyond US borders. Using longitudinal data from the German Socio-Economic Panel and exploiting exogenous variation in interview timing throughout 2001, I find that the terror attacks in the US caused an immediate shift of around 40 percent of <b>one</b> within <b>standard</b> <b>deviation</b> to more negative attitudes toward immigration and resulted in a considerable decrease in concerns over xenophobic hostility among the German population. Furthermore, in exploiting within-individual variation this quasi-experiment provides evidence on the role of education inmoderating the negative terrorism shock...|$|R
40|$|The general-equilibrium {{effects of}} performance-related teacher pay include {{long-term}} incentive and teacher-sorting mechanisms that usually elude experimental studies but are captured in cross-country comparisons. Combining country-level performance-pay measures with rich PISA- 2003 international achievement micro data, this paper estimates student-level international education production functions. The use of teacher salary adjustments for outstanding performance is {{significantly associated with}} math, science, and reading achievement across countries. Scores in countries with performance-related pay are about <b>one</b> quarter <b>standard</b> <b>deviations</b> higher. Results avoid bias from within-country selection and are robust to continental fixed effects and to controlling for non-performance-based forms of teacher salary adjustments. PISA, teacher performance pay, international, student achievement...|$|R
40|$|In {{the last}} twenty years Electrical Resistivity Tomography and time-domain Induced Polarization {{techniques}} have been widely used for geological, environmental, chemical and hydro-geological applications. As a matter of fact, the choice of electrodes (material and number) to be employed is crucial to avoid large measurement errors. The aim of this work is the quantitative assessment of errors in acquisition with respect to different electrode materials and configurations, as well as a comparison with previous results. To this end, a cylindrical column (height of 280 mm, diameter of 135 mm) is set up and all measurements are performed on a 7 electrode, 2 D horizontal cross-section. Resistance, chargeability and self-potential measurements for different electrode materials (steel, iron, aluminium, copper and carbon) are acquired over a cylindrical sample filled by water with known conductivity. A statistical analysis of the experimental data demonstrates that iron and steel provide the best performances both for resistance and for chargeability. Carbon and copper are reliable for resistive surveys, but not for capacitive <b>ones.</b> <b>Standard</b> <b>deviations</b> associated to aluminium electrodes are the highest among the five materials. Changing the number of electrodes (from 7 to 20) results in an exponential increase of resolution of the resistive and chargeable anomalies included in the samples. © 2011 - OGS...|$|R
