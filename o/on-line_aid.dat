5|30|Public
5000|$|Daniel V. Klein {{develops}} UOLT, a Unix-based On Line aid to Training. This system features {{presentation of}} on-line courses and individualized testing and grading. Later renamed and published as “UBOAT - A Unix Based <b>On-Line</b> <b>Aid</b> to Tutorials”, in the Proceedings of the European Unix User’s Group, Dublin IRELAND, September 1987.|$|E
40|$|As {{part of a}} US/UK {{cooperative}} aeronautical research pragram, a joint activity {{between the}} Dryden Flight Research Facility of the NASA Ames Research Center (Ames-Dryden) and the Royal Aerospace Establishment (RAE) on Knowledge Based Systems was established. Under the agreement, a Flight Status Monitor Knowledge base developed at Ames-Dryden was implemented using the real-time IKBS toolkit, MUSE, which {{was developed in the}} UK under RAE sponsorship. The Flight Status Monitor is designed to provide <b>on-line</b> <b>aid</b> to the flight test engineer in the interpretation of system health and status by storing expert knowledge of system behavior in an easily accessible form. The background to the cooperation is described and the details of the Flight Status Monitor, the MUSE implementation are presented...|$|E
40|$|The report {{describes}} {{how to use}} the ELLPACK system through a set of terminal command procedures, called macros, designed for easy, on-line use. The macros as described are a preliminary set; an expanded set will be prepared once some experience is gained with this preliminary set. The capabilities of the preliminary set allow users at remote sites to create an ELLPACK program for solving a PDE, run a ELLPACK program, check the program output, have results mailed, display data from the ELLPACK per-formance evaluation system,send messages (trouble reports) to network members and provide <b>on-line</b> <b>aid</b> to using the macros. Information about accessing the network and Purdue's computer system is given elsewhere. CONTENTS 1. Summary of capabilities 2. Anotated example session 3. Logging on the Purdue syste...|$|E
25|$|Bimba's {{papers are}} housed at the Immigration History Research Center, {{located at the}} University of Minnesota in Minneapolis. A {{detailed}} <b>on-line</b> finding <b>aid</b> is not yet available.|$|R
25|$|John Work's {{papers are}} housed by the Milwaukee Public Library. The {{collection}} is contained 7 manuscript boxes {{and is available}} to scholars, who should contact the library in advance {{in order to work}} the papers. There is no <b>on-line</b> finding <b>aid.</b>|$|R
25|$|Matthews' {{papers are}} housed in Durham, North Carolina at the Duke University Rare Book, Manuscript, and Special Collections Library. The papers include a massive 479 linear feet of material, {{consisting}} of 307,000 individual items. An <b>on-line</b> finding <b>aid</b> is available.|$|R
40|$|This paper {{presents}} the SYDOX/MATCOMP/Xi project, {{funded by the}} French Ministry of Industry. The goal {{of the project was}} to provide the construction professionals with an <b>on-line</b> <b>aid</b> for component specification and selection at different levels of the construction life cycle. This two years project started in 1997 and involved several partners. This paper describes the main features of the information system: databases, query and communication systems. SYDOX(SYstème de DOnnées compleXes) is aimed at defining and demonstrating a prototype to access information about MATerials and COMPonents used in construction, implemented on a WWW server. Though the objective is general, the work was focused on a restricted sub-section of the construction domain. We describe the domain and the scope of the project, the starting point and the lessons learnt from the development of the prototype. We also propose some important ideas on which this research is based...|$|E
40|$|Our {{objective}} is to develop devices, systems, and languages for fruitful interaction between scientists and computers, {{through the use of}} the computer as a powerful, <b>on-line</b> <b>aid</b> to understanding. Taking cost and computer capacity into consideration, we can provide this facility by time-sharing a slightly modified computer with a normal-sized memory. The computer is equipped with random access files and many low-cost remote consoles, each of which has low-data-rate graphical and character-producing input-output devices. The consoles can be operated simultaneously. Work in this field has been concerned with the following problems. We have tested on-line programming and computation, utilizing a system of multiple independent type-writers. An existing digital plotter has been connected to an IBM 709 computer, and we are constructing a special-purpose computer to control multiple independent plotters. A prototype of a high-resolution graphical input device for figures and symbols that are drawn by hand is being built. Design modifications for an IBM 7090 computer have been proposed and incorporated into the Computation Center machine. Scheduling systems for time-sharing and memory allocation have been simulated and found satisfactory...|$|E
50|$|John Work's {{papers are}} housed by the Milwaukee Public Library. The {{collection}} is contained 7 manuscript boxes {{and is available}} to scholars, who should contact the library in advance {{in order to work}} the papers. There is no <b>on-line</b> finding <b>aid.</b>|$|R
40|$|Medication {{errors are}} common in general {{practice}} and in hospitals. Both errors {{in the act of}} writing (prescription errors) and prescribing faults due to erroneous medical decisions can result in harm to patients. Any step in the prescribing process can generate errors. Slips, lapses, or mistakes are sources of errors, as in unintended omissions in the transcription of drugs. Faults in dose selection, omitted transcription, and poor handwriting are common. Inadequate knowledge or competence and incomplete information about clinical characteristics and previous treatment of individual patients can result in prescribing faults, including the use of potentially inappropriate medications. An unsafe working environment, complex or undefined procedures, and inadequate communication among health-care personnel, particularly between doctors and nurses, have been identified as important underlying factors that contribute to prescription errors and prescribing faults. Active interventions aimed at reducing prescription errors and prescribing faults are strongly recommended. These should be focused on the education and training of prescribers and the use of <b>on-line</b> <b>aids.</b> The complexity of the prescribing procedure should be reduced by introducing automated systems or uniform prescribing charts, in order to avoid transcription and omission errors. Feedback control systems and immediate review of prescriptions, which can be performed with the assistance of a hospital pharmacist, are also helpful. Audits should be performed periodically...|$|R
40|$|This paper {{considers}} {{the role of}} online multiple choice revision quizzes within the Virtual Learning Environment {{as a means of}} improving learning outcomes. A quiz was offered to 1 st year undergraduates. Results were analysed to consider whether student participation improved performance. The analysis reveals little or no direct association between exam performance and participation, both at the mean and throughout the performance distribution, suggesting that the benefits from participation in <b>on-line</b> revision <b>aids</b> are not large. The use of such material needs to be made available judiciously since it may encourage displacement activity and provide little material benefit to the student...|$|R
40|$|Most current-day <b>on-line</b> {{information}} finding <b>aids</b> (search engines, {{digital library}} catalogs) are geared toward the one-stop-search {{paradigm of the}} traditional Information Retrieval Model: ‘one–query, one–use’. This paradigm may suit {{a large group of}} users in their basic searching needs, but for many, ‘one size’ may not fit all. In this thesis we have attempted to formulate a model for an ‘ideal’ <b>on-line</b> finding <b>aid</b> for one such group of users, for which the ‘straightforward’ traditional IR model is not a perfect fit: historians. As frequent scholarly users of archives and libraries, they display a more organic approach to information-seeking. Their behavior resembles the ‘Berrypicking’ model as described by Bates (1989), and involves a wide range of techniques not covered by the traditional model, like serendipitous browsing, name-collecting and citation chaining. In order to come to such a model we have not only analyzed the user, but also the usage—the historians’ usage of primary resource material and bibliographic (meta) data, to be exact. For this we have examined the Evans corpus, a set of over 40, 000 printed primary source documents concerning early American history, politics and culture. Evans is a premier example of the kind of bibliographic data historians come across and use in their daily research practice. We have translated our findings regarding user and data into a new proposed model— and accompanying algorhitm—for historical interface design. This model—dubbed the ‘Semantically-enhanced Berry Basket’—combines the flexibility and usability of the Social Web (or Web 2. 0) with the power and precision of the Semantic Web. The ‘cognition-augmenting’ capabilities of Information Visualizalizations (Card et al., 1999), when combined with powerful ‘berry’-suggestion mechanisms (powered by ‘Semantic’ triples) form a promising basis for a user-/historian-centered <b>on-line</b> electronic finding <b>aid</b> for primary resource material...|$|R
40|$|Virtual {{colonoscopy}} is a non-invasive computerized {{medical examination}} method for examining {{the interior of}} the human colon, aiding the detection of polyps. In our study we have examined the most popular approaches to the problems of high-speed rendering and navigation within the colon, and devised our own algorithms. Our intent was to make them fast and reliable enough to be implementable on a consumer-end PC system, instead of state of the art high-end workstations, and to minimize off-line calculations. In this paper we present our idea of a real-time direct volume rendering based visualization technique combined with an <b>on-line</b> computer <b>aided</b> interactive navigation method for the examination of volume data constructed from CT scans. Parts of this algorithm have been implemented in our colon visualization program called ColVis...|$|R
40|$|Abstract- In this paper, an {{effective}} nonstationary boundary estimation scheme in EIT is presented {{based on the}} interacting multiple model (IMM) algorithm. The inverse problem is treated as a stochastic nonlinear state estimation problem with the time-varying boundary (state) being estimated <b>on-line</b> with the <b>aid</b> of the IMM algorithm. In {{the design of the}} IMM algorithm multiple models with different process noise covariances are incorporated to reduce the modeling uncertainty. Simulations are provided to illustrate the proposed algorithm. 1...|$|R
40|$|In {{supervisory}} control {{systems such as}} satellite ground control, {{there is a need}} for human-centered automation where the focus is to understand and enhance the human-system interaction experience in the complex task environment. Operator support in the form of off-line intelligent tutoring and <b>on-line</b> intelligent <b>aiding</b> is one approach towards this effort. The tutor/aid paradigm is proposed here as a design approach that integrates the two aspects of operator support in one system for technically oriented adults in complex domains. This paper also presents GT-VITA, a proof-of-concept graphical, interactive, intelligent tutoring system that is a first attempt to illustrate the tutoring aspect of the tutor/aid paradigm in the domain of satellite ground control. Evaluation on GT-VITA is conducted with NASA personnel with very positive results. GT-VITA is presented being fielded as it is at Goddard Space Flight Center...|$|R
40|$|The STS Meteorological Expert (STSMET) is a {{long-term}} project to acquire general Shuttle operational weather forecasting expertise specific to the launch locale, to apply it to Shuttle operational weather forecasting tasks at the Cape Canaveral Forecast Facility, and ultimately to provide an <b>on-line</b> real-time operational <b>aid</b> to the duty forecasters in performing their tasks. Particular attention {{is given to the}} development of an approach called scenario-based reasoning, with specific application to summer thunderstorms; this type of reasoning can also be applied to frontal weather phenomena, visibility including fog, and wind shear...|$|R
40|$|Much of the author’s recent {{experience}} {{is attempting to}} teach Mathematics primarily to undergraduate students following degree programmes in Electronics or Audio Technology. Increasingly, {{it is found that}} although such students may be able to perform mechanistic steps such as obtaining a simple derivative, or evaluating a straightforward definite integral, they have little idea as to what these quantities mean. Very few (if any?) would know that these results are connected to a limiting process. Unless the student’s understanding of basic calculus is strengthened, they have little chance of subsequently dealing with the solution of differential equations or the construction of Fourier series. This paper shows how imaginative deployment of computer algebra (DERIVE) can substantially assist the understanding of calculus and its applications in the aforementioned areas. In particular, the paper will demonstrate the advantages of using computer algebra as an <b>on-line</b> teaching <b>aid</b> in the classroom compared with using traditional methods of teaching topics such as solving differential equations. 1...|$|R
40|$|This {{research}} {{is concerned with}} the application 	of fuzzy theory to PTP(Point to Point) control of a 	redundant manipulator. On PTP control, an inverse 	kinematics problem which is to determine each joint 	angles when the position of an end-effector is given, 	is unsolvable because its solution is not always 	unique owing to its redundancy. In this study, the 	self-controlled manipulator for PTP control can be 	realized using the fuzzy theory. 	The basic structure and uses of the fuzzy 	controller are developed with an <b>on-line</b> computer <b>aid,</b> 	by which the manipulator can reach at any prescribed 	position. The fuzzy inference is proceeded on nine 	fuzzy rules with respect to output angles for each 	joints using "product-sum-gravity method" and 	"simplified method". Two types of output membership 	functions are proposed and the effectiveness is 	discussed through simulation studies. By experiments 	using Rhino robot, it is ascertained that the proposed 	fuzzy controller is valid to PTP control of the real 	manipulator...|$|R
40|$|Climate control {{computers}} in greenhouses control heating and ventilation, supply water, dilute and dispense nutrients and integrate models into an optimally controlled system. This paper describes how information technology, as {{in use in}} other sectors of industry, applies to greenhouse control. In other fields of industrial automation, the introduction of WINDOWS and OS 2 {{gave way to the}} use of a whole new generation of hardware and software tools: fieldbus systems, a real time <b>on-line</b> database, computer <b>aided</b> program engineering and object oriented programming. The introduction of these modern concepts in horticulture adds extra power to climate control in greenhouses...|$|R
40|$|A {{variety of}} {{approaches}} to the design and use of on-line group decision support systems have been described and tested. This paper describes an <b>on-line</b> system to <b>aid</b> groups to identify rapidly and then explore their differences of opinion in debate {{in order to reach}} decisions. The approach involves a specially designed group decision support system, called TEAMWORKER. Case-studies describing uses of the system in varied contexts are presented. The experiences of these applications are linked with existing theoretically orientated literature from a number of associated fields in order to construct a process framework as a guide to users of this type of approach. decision making/process decision support systems group decisions judgement priorities R&D...|$|R
40|$|Abstract {{copyright}} {{data collection}} owner. This project follows a two year study {{funded by the}} New Dynamics of Ageing Programme, entitled Detecting and preventing elder financial abuse: decision making by professionals in health, social care and banking The aim is to maximise {{the impact of the}} findings via the development of web-based decision making tools that key professional groups can access to enhance their ability to detect and respond to financial abuse. Using the findings of the previous research, two <b>on-line</b> decision <b>aids</b> will be developed: one for health and social care professionals and one for finance professionals. Following approval from Brunel University Research Ethics Committee, a randomised control trial will be conducted to measure the effectiveness of the decision aid design, by identifying if novices who receive the training are able to make decisions more like experienced professionals. Educational resources will be hosted on a dedicated research website. These will include podcasts of professionals giving their perspective on case examples of financial abuse and discussing the challenges of decision making in this field. In addition seminar training activities will be designed so that the findings can be used to inform small group training. These resources will be evaluated to ensure suitability for practice education...|$|R
40|$|Multi-armed bandits may {{be viewed}} as decompositionally-structured Markov {{decision}} processes (MDP's) with potentially very large state sets. A particularly elegant methodology for computing optimal policies was developed over twenty ago by Gittins [Gittins & Jones, 1974]. Gittins' approach reduces the problem of finding optimal policies for the original MDP to a sequence of low-dimensional stopping problems whose solutions determine the optimal policy through the so-called "Gittins indices. " Katehakis and Veinott [Katehakis & Veinott, 1987] have shown that the Gittins index for a task in state i may be interpreted as a particular component of the maximum-value function associated with the "restart-in-i" process, a simple MDP to which standard solution methods for computing optimal policies, such as successive approximation, apply. This paper explores the problem of learning the Gittins indices <b>on-line</b> without the <b>aid</b> of a process model; it suggests utilizing task-state-spe [...] ...|$|R
40|$|The APD {{software}} features include: On-line help, Three level architecture, (Logic environments, Setup/Application environment, Data environment), Explanation capability, and File handling. The {{kinds of}} experimentation and record keeping {{that leads to}} effective expert systems is facilitated by: (1) a library of inferencing modules (in the logic environment); (2) an explanation capability which reveals logic strategies to users; (3) automated file naming conventions; (4) an information retrieval system; and (5) <b>on-line</b> help. These <b>aid</b> with effective use of knowledge, debugging and experimentation. Since the APD software anticipates the logical rules becoming complicated, it is embedded in a production system language (CLIPS) to insure the full power of the production system paradigm of CLIPS and availability of the procedural language C. The development is discussed of the APD software and three example applications: toy, experimental, and operational prototype for submarine maintenance predictions...|$|R
40|$|New methods, procedures, {{and devices}} are {{transforming}} {{the way the}} water-supply industry will do business in the 21 st Century. Past practices point the way to improved technological and managerial efficiency in ground-water development, water-well construction, maintenance, and protection from contamination. The cost-benefit {{of the use of}} ground water and surface water requires new ways to meet demands involving conjunctive use programs. Past practices have depleted the low-cost, high-quality ground-water resources and as a result water costs will be higher in the future as high-cost, low quality surface water resources are brought <b>on-line.</b> With the <b>aid</b> of the Internet, new developments will be distributed faster than ever before. With the aid of EPA and state regulatory programs, in cooperation with local utility management, the general public will be supplied with relevant, timely information on the quality of drinking water it consumes. The general prognosis is good. The details require attention...|$|R
40|$|Air {{pollution}} {{in the form of}} sulfates and nitrates has been directly linked to problems of acid rain in eastern North America. Fossil fuel combustion is a main source of these pollutants. In an effort to find a remedy to the problem of acid rain, mathematical modeling has been employed by Ellis, et al. Specifically, a linear programming model has been formulated to find the minimum emissions reductions required to reduce acid depositions to a predetermined maximum level,given a set of functional constraints. However, application of the model has been limited because of the complexity involved in preparing it for implementation in a conventional linear programming format. The purpose of the project is the design of an interactive computer software package, in the Pascal programming language, which greatly reduces the effort involved in using the model to evaluate acid rain reduction policies. The results are displayed for maximum clarity and ease of understanding, both numerically and graphically. Extensive explanatory notes are available <b>on-line</b> to <b>aid</b> in using the program effectively. The completed software was used to extend the analyses of acid rain control policies which were previously done. From preliminary research, it appears that it will be necessary for the United States and Canadian governments to place severe requirements on emissions reductions of sulfur dioxide in the near future in order to bring acid deposition levels down to environmentally acceptable levels in sensitive areas...|$|R
40|$|Like many corporations, Chevron began {{a broad-based}} process journey in the 1980 ’s when {{several of its}} {{divisions}} launched Total Quality Management (TQM) programs. In the Nineties, process efforts continued and focused on large process management investments, made at operating company level, in ERP and Supply Chain Management implementations. With the introduction of Chevron’s Operational Excellence (OE) initiative in 2001, a process management perspective {{began to focus on}} enterprise-wide process challenges. The spread of OE gradually {{led to the development of}} a corporate-wide BPM foundation that currently embraces process governance, methodologies, and process management technologies. This paper describes a specific approach that Chevron has developed to make it possible to transition efficiently from running process improvement projects to supporting day-to-day employee performance with <b>on-line</b> job <b>aids.</b> In essence, a process is modeled, analyzed and improved. Then, using the same process model in the same software tool, the redesign team extends the process model to include step-by-step advice for employees who are expected to perform the process. In many cases, detailed business rules are added to define exactly how decisions should be made and what actions should be taken. The extended process model – now called a “Storyboard ” [1] – is made available, online, for any employee who needs to use the process, and is maintained and improved by the organization which owns the process. Analyzing Processes Chevron personnel routinely analyze processes by documenting their understanding in a graphical process flow model. Chevron’s goal is to keep the process content as simple as possible so that the same model is as easily understood by employees as it is by process analysts. Figure 1 provides a look at a process that has been modeled in Nimbus Control [2], a modeling tool that Chevron has adopted and branded as “ProChart. ” Figure 1. A high-level model of a process for managing an inciden...|$|R
40|$|Communication is defined, for {{the purpose}} of this paper, as the sharing of {{information}} between statisticians and users in a way to maximise understanding. Principally to maxi-mise use of information to fulfil the mission of national statistical offices; to minimise misuse of statistics by ensuring the contexts, caveats, and other limitation of the informa-tion is understood. To maximise communication, we will need to understand how the mind comprehends information. ABS research into cognitive psychology suggests there are three key cognitive processes involved in comprehension, namely perception, attention and learning. Whilst the cognitive psychology theory is of general applicability, a number of issues need to be borne in mind for web communication, as follows: Web surfers are users, not readers They scan and skim read the material on-line to look for the information they are after. The term „satisficing “ was coined by cognitive psychologists to describe the behaviour that they will stop looking once they come across something they think satisfy their needs (Simon, 1957). Accordingly, we must design our statistical releases to <b>aid</b> <b>on-line</b> users of the information eg concise writing, information in dot points to assist scanning...|$|R
40|$|This {{dissertation}} {{presents a}} set of design tools and approaches for synthesis of both rigid body and compliant mechanisms. The research goal is to achieve design automation for articulated mechanical systems. It is comprised of two parts. The focus of the first part is on synthesis and design of planar rigid body linkages for path generation problems. The solution approach includes an off-line linkage library and the <b>on-line</b> computer <b>aided</b> design framework. The former introduces curve characterization, type-P Fourier descriptor normalization that a digital library that characterizes the motion curves of variety of planar linkages. And the latter brings a new computer-aided linkage design and simulation system that integrates a curve matching algorithm and design optimization routines. This computer-aided design system is built to achieve design automation and interactive design. To enable the design automation framework, first a pre-built library of open and closed planar curves is generated according to commonly used planar linkages. Then the classical linkage path generation problem is translated into a database-searching problem together with a local optimization problem, which embeds a rapid search algorithm that compares the Fourier descriptors of the task path against those of the linkage samples in the library, and retrieves a design candidate from them. To enable the interactive design framework, {{a set of}} design interfaces are implemented that facilitate designers intervene and steer the design process. The second part of this dissertation focuses on type synthesis of compliant mechanisms with screw theory. Here a systematic synthesis procedure for flexure elements and general compliant mechanisms is proposed. In this approach, we first categorize a list of commonly used atomic flexure primitives, and through which, basic R-joints and P-joints that allow a single rotation or a single translation are defined. By using parallel structures of these flexure primitives, eleven designs of R-joints and eight designs of P-joints are systematically synthesized. In contract to freedom elements, we synthesize serial chains of flexure primitives and obtained six designs of P-constraints and three designs of R-constraints. These freedom and constraint elements are basic building blocks for designing more complex flexure mechanisms. To demonstrate our theory, hybrid structures with a serial and parallel combination of compliant elements are designed, and also parallel compliant mechanisms with three translational degrees of freedom are synthesized...|$|R
40|$|Bioprocesses {{often require}} {{considerable}} expertise to insure proper operation and performance. However, {{they are also}} rich in both data and factual knowledge. Supervision and control can be improved by utilizing information from all available sources. Knowledge about dynamics may be incomplete, particularly during upsets or equipment failure. Additional information derived from past data trends, expert operators and the literature can be very useful in process analysis, fault detection, process salvaging and optimization. In this work an expert system which utilizes on-line real-time data as well as archived data trends and operator expertise to analyze a process is developed. A modular format (the hierarchical modular structure) is designed to organize the large body of information [...] typical of the knowledge likely to be encountered in a bioprocess. The highly modular format allows for knowledge to be classified as general, process configuration specific or system specific. The expert system is challenged with process faults which are not easily noticed without a qualitative understanding of process dynamics. The supervisor is able to detect the unusual situations by first generating a process assessment based on a synthesis of all available on-line measurements in conjunction with known qualitative information. Once a global process picture is established, the expert system can decide upon appropriate strategies for recovery or backup control. Process analysis, recovery and optimization were experimentally demonstrated using Clostridium acetobutylicum fermentation as a sample system. Successful expert system process analysis was able to detect sensor failures and media feed flow failures. In addition, effective backup pH control and process recovery strategies were suggested and implemented in real-time by the expert system supervisor. The expert system ability to <b>aid</b> <b>on-line</b> optimization by shortening {{the time needed to}} analyze process transients may result in faster attainment of the region of optimal performance...|$|R
40|$|The {{objective}} of this thesis was to develop the basic techniques and computer programs for the interactive <b>on-line</b> computer <b>aided</b> design of linear microwave circuits. Initially all the possible types of microwave circuits were considered {{to see how they}} could be analysed in a computer program. The result of this was that {{it was found that the}} best way to analyse a microwave circuit was to consider the circuit to consist of an assembly of n-port networks, with the entire circuit consisting of a single n-port network. All the results of interest to the microwave engineer were described and the equations given for these. For the analysis of microwave circuits the chain matrix, nodal analysis and a new mixed matrix method of analysis were considered in detail and a comparison of the optimum method and computation time made. The result of this was that it was found that the chain matrix analysis was the fastest but of limited application whilst the new mixed matrix analysis was able to analyse any microwave circuit. The first computer programs developed by the author used the chain matrix analysis, the main one of these being the CHAIN 1 program. This program advanced the use of chain matrix analysis to its limit. A path topological analysis was included in the program which broke the circuit down into an assembly of cascades of 2 -port networks in the circuit. Thus it was not necessary to define the path topology precisely in the data. Later the MICRO 3 program was developed by the author to use the new mixed matrix analysis for a general assembly of n-port networks. This program was found to be far more versatile and almost any microwave circuit could be handled by the method of analysis used in this program. During the development of the programs, as each new program was developed, more facilities were included for the interactive on-line use of the programs. In the MICRO 3 program a list processing approach to the data structure in the program and a full syntactical analysis of the data was included. This made it possible to generate very complex data structures in the program thus making the program ideal for interactive on-line use on a computer. The data for this program was more like a programming language than normal data and any data error could be correct on-line during the run of the program. The program could be used on batch processing, on a remote teletype interactively or with a graphical display to display the results of an analysis in graphical form. An investigation into the equations describing microwave components and optimisation techniques was carried out. The MICRO 3 program was prepared for these facilities but there was not sufficient time to include these facilities completely...|$|R
40|$|By placing their {{descriptions}} on-line, archives {{have gained}} greater public. This new public is mainly {{consisting of the}} novice users {{not familiar with the}} archival research process. Archival research is usually conducted through the Finding Aids, which serve users as a guide to the discovery of archival holdings. However, those Finding Aids were originally used by the archivists for the records management and for interpreting users’ requests by deriving answers from provenance and context driven descriptions. In the <b>on-line</b> environment, Finding <b>Aids</b> are usually accessible through and encoded in the Encoded Archival Description (EAD) standard. The EAD was developed with the purpose of encoding and capturing many different archival descriptive practices The problem has arisen with the notion that the Finding <b>Aids</b> in the <b>on-line</b> environment have the exact same form as in traditional environment, just without the archivist as an mediating factor. This causes many problems to the general user public that is not familiar with the archival research process. This thesis tends to explore one possible approach for facilitating access on behalf of the general user public to the archival holdings in on-line environment. This approach is by transforming the data encoded in EAD standard to another, more general model. The goal model in question is the Europeana Data Model (EDM) developed for the purpose of Europeana v. 1. 0 project. The objective of this thesis is investigating weather EDM would bring the wanted changes to the accessibility of archival data. In order to achieve this, the general method for mapping EAD standard to EDM was developed. Furthermore the method developed was applied on the two fonds originating from the archive of Accademia Nazionale di Santa Cecilia, musical academy in Rome, for the purpose of validation of the developed method and analyzing the results of the mapping. The results of this study have shown that transforming archival description in EDM would bring certain improvements to the non-expert users accessing on-line. The main improvements are regarding terminology, facilitated access to the different levels of the archival description, improved search functionalities and better visibility of archival holdings...|$|R
40|$|This paper {{discusses}} {{possibilities of}} developing new tools for architectural design. It argues that architects should {{meet the challenge}} of information technology and computer-based design techniques. One such attempt has been {{the first phase of the}} development of an architectural design information system (ADIS), also an architectural design decision support system. The system should benefit from the developments of the artificial intelligence to enable the architect to have access to information required to carry out design work. In other words: the system functions as a huge on-line electronic library of architecture, containing up-to-date architectural design information, literature, documents, etc. At the same time, the system offers necessary design aids such as computer programs for design process, drawing programs, evaluation programs, cost calculation programs, etc. The system also provides data communication between the architect and members of the design coalition team. This is found to be of vital importance in the architectural design process, because it can enable the architect to fit in changes, brought about in the project by different parties. Furthermore, they will be able, to oversee promptly the consequences of changes or decisions in a comprehensive manner. The system will offer advantages over the more commonly applied microcomputer based CAAD and IGDM (integrated graphics database management) systems, or even larger systems available to an architect. Computer programs as well as hardware change rapidly and become obsolete. Therefore, unrelenting investment pressure to up-date both software and hardware exists. The financial burden of this is heavy, in particular for smaller architectural practices (for instance an architect working for himself or herself and usually with few or no permanent staff). ADIS, as an <b>on-line</b> architectural design <b>aid,</b> is constantly up-dated by its own organisation. This task will be co-ordinated by the ADIS data- base administrator (DBA). The processing possibilities of the system are faster, therefore more complex processing tasks can be handled. Complicated large graphic data files, can be easily retrieved and manipulated by ADIS, a large system. In addition, the cost of an on-line system will be much less than any other system. The system is based on one model of the architectural design process, but will eventually contain a variety of design models, as it develops. The development of the system will be an evolutionary process, making use of its users'feed-back system. ADIS is seen as a step towards full automation of architectural design practices. Apart from being an architectural design support system, ADIS will assist the architect in his/her administrative and organisational activities...|$|R

