258|498|Public
25|$|The {{components}} {{include the}} yoke, the magnetic coil, the poles, the polepiece, and the external control circuitry. The pole piece must be manufactured {{in a very}} symmetrical manner, as this provides the boundary conditions for the magnetic field that forms the lens. Imperfections {{in the manufacture of}} the pole piece can induce severe distortions in the magnetic field symmetry, which induce distortions that will ultimately limit the lenses' ability to reproduce the <b>object</b> <b>plane.</b> The exact dimensions of the gap, pole piece internal diameter and taper, as well as the overall design of the lens is often performed by finite element analysis of the magnetic field, whilst considering the thermal and electrical constraints of the design.|$|E
2500|$|The {{limit of}} {{resolution}} obtainable in a TEM may be described in several ways, and is typically {{referred to as the}} information limit of the microscope. One commonly used value is a cut-off value of the contrast transfer function, a function that is usually quoted in the frequency domain to define the reproduction of spatial frequencies of objects in the <b>object</b> <b>plane</b> by the microscope optics. A cut-off frequency, qmax, for the transfer function may be approximated with the following equation, where Cs is the spherical aberration coefficient and λ is the electron wavelength: ...|$|E
50|$|The {{locus of}} {{focus for the}} {{inclined}} <b>object</b> <b>plane</b> is a plane; intwo-dimensional representation, the y-intercept {{is the same as}} that for theline describing the <b>object</b> <b>plane,</b> so the <b>object</b> <b>plane,</b> lens plane, and imageplane have a common intersection.|$|E
5000|$|... #Subtitle level 3: Detection of 3D <b>objects</b> (<b>Planes</b> and cylinders) ...|$|R
50|$|<b>Object</b> <b>planes</b> {{perpendicular}} to the optical axis are conjugate to image planes {{perpendicular to}} the axis.|$|R
5000|$|In Technical drawing Stereotomy is {{now known}} as Descriptive geometry, and [...] "is {{concerned}} with two-dimensional representations of three dimensional <b>objects.</b> <b>Plane</b> projections and perspective drawings of solid figures are used to describe and analyze their properties for engineering and manufacturing purposes. Attention is paid to theproperties of surfaces, including normal lines and tangent planes." ...|$|R
5000|$|The point spread {{function}} may {{be independent}} of position in the <b>object</b> <b>plane,</b> in which case it is called shift invariant. In addition, {{if there is no}} distortion in the system, the image plane coordinates are linearly related to the <b>object</b> <b>plane</b> coordinates via the magnification M as: ...|$|E
5000|$|... #Caption: Diffraction geometry, showing {{aperture}} (or diffracting <b>object)</b> <b>plane</b> {{and image}} plane, with coordinate system.|$|E
5000|$|In a {{two-dimensional}} representation, an <b>object</b> <b>plane</b> inclined to the lensplane {{is a line}} described by ...|$|E
40|$|We {{present a}} model-based method for {{detailed}} automatic building reconstruction from images. The method starts with recovering a coarse building model {{consisting of the}} main <b>object</b> <b>planes.</b> This model is upgraded by detecting deviations from the planes and fitting predefined shape primitives to these deviations to refine the geometry. The proposed method is presented on real datasets. ...|$|R
40|$|In {{this paper}} we {{investigate}} performance metrics for quantitative evaluation of object-based video segmentation algorithms. The metrics address {{the case when}} ground-truth video <b>object</b> <b>planes</b> are available. The proposed metrics are used to evaluate three essentially different approaches for video segmentation, i. e., an edge-based [1], a motion clustering based [2], and a total feature vector clustering based [3] algorithm. 1...|$|R
40|$|The video coding {{standard}} MPEG- 4 is enabling content-based functionalities by {{the introduction of}} video <b>object</b> <b>planes</b> (VOP's) which represent semantically meaningful objects. In this paper, a novel fast, unsupervised semantic segmentation scheme is presented for stereoscopic sequences, which utilizes the provided depth information. Each stereo pair is first analyzed and the disparity field and occluded areas are estimated. Then...|$|R
5000|$|Perhaps a lens figure-of-merit in this [...] "point spread function" [...] {{viewpoint}} {{would be}} to ask how well a lens transforms an Airy function in the <b>object</b> <b>plane</b> into an Airy function in the image plane, {{as a function of}} radial distance from the optic axis, or {{as a function of the}} size of the <b>object</b> <b>plane</b> Airy function. This is somewhat like the point spread function, except now we're really looking at it as a kind of input-to-output plane transfer function (like MTF), and not so much in absolute terms, relative to a perfect point. Similarly, Gaussian wavelets, which would correspond to the waist of a propagating Gaussian beam, could also potentially be used in still another functional decomposition of the <b>object</b> <b>plane</b> field.|$|E
5000|$|... where M is {{the system}} magnification. The <b>object</b> <b>plane</b> {{transmittance}} above can now be re-written in a slightly modified form: ...|$|E
5000|$|At {{this point}} another {{coordinate}} transformation can be proposed (i.e., the Abbe sine condition) relating the <b>object</b> <b>plane</b> wavenumber spectrum {{to the image}} plane wavenumber spectrum as ...|$|E
40|$|Abstract. In {{this paper}} we {{describe}} the first full implementation of a content-based indexing and retrieval system for MPEG- 2 and MPEG- 4 videos. We con-sider a video {{as a collection of}} spatiotemporal segments called video objects; each video object is a sequence of video <b>object</b> <b>planes.</b> A set of representative video <b>object</b> <b>planes</b> is used to index each video object. During the database population, the operator, using a semi-automatic outlining tool we developed, manually selects video objects and insert some semantical information. Low-level visual features like color, texture, motion and geometry are automatically computed. The system has been implemented on a commercial relational DBMS and is based on the client server paradigm. The database population client is a stand-alone Windows application; the querying of the system is performed with a web-based client. To test the system we indexed a number of videos taken from Italian soccer championship games. A few examples of queries in this par-ticular domain are reported and results appear very promising. 1 Introduction and Related Wor...|$|R
40|$|Aberration {{correction}} using Reference Conjugated Hologram (RCH) {{method is}} investigated. However {{we use it}} not for a single but {{for a number of}} reconstructed <b>object</b> <b>planes</b> in Digital Holographic Microscopy (DHM). We build an off-axis DHM for testing the performance of the method. The limits of this method have been studied. We compare in-line with aberration compensated off-axis DHM. The in-line DHM compensates quite the same aberrations physically as the RCH method numerically...|$|R
50|$|Incidence {{structures}} {{are most often}} considered in the geometrical context where they are abstracted from, and hence generalize, planes (such as affine, projective, and Möbius planes), but the concept is very broad and not limited to geometric settings. Even in a geometric setting, incidence {{structures are}} not limited to just points and lines; higher-dimensional <b>objects</b> (<b>planes,</b> solids, -spaces, conics, etc.) can be used. The study of finite structures is sometimes called finite geometry.|$|R
5000|$|Now, assume for {{simplicity}} {{that the}} system has no image distortion, so that the image plane coordinates are linearly related to the <b>object</b> <b>plane</b> coordinates via the relation ...|$|E
50|$|Optical systems {{typically}} {{fall into}} one of two different categories. The first is the ordinary focused optical imaging system, wherein the input plane is called the <b>object</b> <b>plane</b> and the output plane is called the image plane. The field in the image plane is desired to be a high-quality reproduction of the field in the <b>object</b> <b>plane.</b> In this case, the impulse response of the optical system is desired to approximate a 2D delta function, at the same location (or a linearly scaled location) in the output plane corresponding to the location of the impulse in the input plane. The actual impulse response typically resembles an Airy function, whose radius is on the order of the wavelength of the light used. In this case, the impulse response is typically referred to as a point spread function, since the mathematical point of light in the <b>object</b> <b>plane</b> has been spread out into an Airy function in the image plane.|$|E
5000|$|Numerical {{calculation}} of the integral using the trapezoidal rule or Simpson's rule is not efficient and becomes numerically unstable especially for configurations with large Fresnel number. However, {{it is possible to}} solve the radial part of the integral so that only the integration over the azimuth angle remains to be done numerically. For a particular angle one must solve the line integral for the ray with origin at the intersection point of the line P0P1 with the circular <b>object</b> <b>plane.</b> The contribution for a particular ray with azimuth angle [...] and passing a transparent part of the <b>object</b> <b>plane</b> from [...] to [...] is: ...|$|E
40|$|Part 10 : Image-Video Classification and ProcessingInternational audienceRecent advancements in 3 D {{television}} {{allow for}} the capture of scene depth from multiple cameras and the interactive selection of view point and direction within a certain range, the so-called Free Viewpoint Video (FVV). State-of-the-art video codecs such as H. 264 /AVC exploit {{the large amount of}} inter-view statistical dependencies by combined temporal and inter-view prediction, i. e. prediction from temporally neighboring images as well as from images in adjacent views. This is known as Multi-view Video Coding (MVC). We propose herein an alternative object oriented video coding scheme for multi-view video with associated multiple depth data (N-video plus N-depth). A structure that we call a Multi-view Video Plane (MVP) is introduced. <b>Object</b> <b>planes</b> associated with a certain view are approximated as multilinear components of an image that are projected onto other views in a tensor-like fashion. The order of the tensor equals the number of multiple views. The coefficients of the tensor subspace projections as well as the updates of the multi-linear components (object-planes) are quantized and transmitted in the MPEG stream. Motion-compensated prediction is carried out in order to transmit the residual <b>object</b> <b>planes</b> (P-frames) using conventional MPEG algorithms...|$|R
50|$|The {{line of nodes}} is the {{intersection}} of the <b>object's</b> orbital <b>plane</b> with the plane of reference. It passes through the two nodes.|$|R
40|$|The article {{presents}} methods based on probability theory and mathematical statistics for solving {{a number of}} basic problems: formation and evaluation of the current flight safety level; forecasting the level of flight safety; ranking the <b>objects</b> (<b>planes,</b> pilots) in terms of flight safety; evaluation of the presence (or absence) of control actions arising {{in the context of}} the organization of corporate safety management system. At the same time as the main source of information are considered forward-looking events received from flight data...|$|R
5000|$|... {{where the}} various terms have been simply multiplied and divided in the {{exponent}} by M, the system magnification. Now, the equations {{may be substituted}} above for image plane coordinates in terms of <b>object</b> <b>plane</b> coordinates, to obtain, ...|$|E
5000|$|A lens is {{basically}} a low-pass plane wave filter (see Low-pass filter). Consider a [...] "small" [...] light source located on-axis in the <b>object</b> <b>plane</b> of the lens. It is assumed that the source is small enough that, by the far-field criterion, the lens is in the far field of the [...] "small" [...] source. Then, the field radiated by the small source is a spherical wave which is modulated by the FT of the source distribution, as in eqn. (2.2), Then, the lens passes - from the <b>object</b> <b>plane</b> over onto the image plane - only {{that portion of the}} radiated spherical wave which lies inside the edge angle of the lens. In this far-field case, truncation of the radiated spherical wave is equivalent to truncation of the plane wave spectrum of the small source. So, the plane wave components in this far-field spherical wave, which lie beyond the edge angle of the lens, are not captured by the lens and are not transferred over to the image plane. Note: this logic is valid only for small sources, such that the lens is in the far field region of the source, according to the 2 D2 / λ criterion mentioned previously. If an <b>object</b> <b>plane</b> transparency is imagined as a summation over small sources (as in the Whittaker-Shannon interpolation formula, Scott 1990), each of which has its spectrum truncated in this fashion, then every point of the entire <b>object</b> <b>plane</b> transparency suffers the same effects of this low pass filtering.|$|E
5000|$|... #Caption: Lens and ray diagram for {{calculating the}} circle of {{confusion}} diameter c for an out-of-focus subject at distance S2 when the camera is focused at S1. The auxiliary blur circle C in the <b>object</b> <b>plane</b> (dashed line) makes the calculation easier.|$|E
40|$|The {{analysis}} of the models describing topological changes in communication systems is carried out. As {{a result of the}} analysis it is defined, that the given models are inapplicable for the description of communication systems with dynamic network topology where as network units large mobile <b>objects</b> (<b>planes,</b> ships, trains) are used. Taking into account the features of displacement of a group of large mobile objects criteria of new topological model are developed. According to the given model the dynamic topology is represented as static in which opening and closing of network channels take place...|$|R
40|$|This paper {{presents}} an automatic approach for camera/image based detection, recognition and tracking of flying <b>objects</b> (<b>planes,</b> missiles, etc.). The method detects appearing objects, and recognizes re-appearing targets. It uses a feature-based statistical modeling approach (e. g. HMM) for motion-based recognition, and an image feature (e. g. shape) based indexed database of pre-trained object classes, suitable for recognition on known and alerting on unknown objects. The method {{can be used}} for detection of flying objects, recognition of the same object category through multiple views/cameras and signal on unusual motions and shape appearances...|$|R
500|$|... {{a foreign}} <b>object</b> {{striking}} the <b>plane</b> and penetrating the cabin ...|$|R
5000|$|Using the {{framework}} of Fourier optics, we may easily explain {{the significance of the}} Abbe sine condition. Say an object in the <b>object</b> <b>plane</b> of an optical system has a transmittance function of the form, T(xo,yo). We may express this transmittance function in terms of its Fourier transform as ...|$|E
50|$|If {{the imaging}} system {{produces}} an inverted image, we may simply regard the image plane coordinate axes as being reversed from the <b>object</b> <b>plane</b> axes. With these two assumptions, i.e., that the PSF is shift-invariant {{and that there}} is no distortion, calculating the image plane convolution integral is a straightforward process.|$|E
5000|$|The blur circle, of {{diameter}} C, in the focused <b>object</b> <b>plane</b> {{at distance}} S1, is an unfocused virtual {{image of the}} object at distance S2 {{as shown in the}} diagram. It depends only on these distances and the aperture diameter A, via similar triangles, independent of the lens focal length: ...|$|E
40|$|The {{emerging}} video {{coding standard}} MPEG- 4 enables various content-based functionalities for multimedia applications. To support such functionalities, {{as well as}} to improve coding e#ciency, MPEG- 4 relies on a decomposition of each frame of an image sequence into video <b>object</b> <b>planes</b> (VOP's). Each VOP corresponds to a single moving object in the scene. In this thesis, a new method for automatic segmentation of moving objects in image sequences is presented. We formulate the problem as graph labeling over a region adjacency graph (RAG), based on motion information. The label field is modeled as a Markov random field (MRF) ...|$|R
40|$|One of {{the actual}} 3 D {{measurement}} problems is the optical inspection of various holes. In this respect, the task of plane image formation of holes as extended 3 D objects using optical methods {{turns out to be}} of primary importance. We have developed specialized lenses that perform such transformations due to specially increased aberrations (field curvature, astigmatism) for the formation of extended <b>objects</b> <b>plane</b> images. The calculations of the lens parameters are presented. The detail analysis of the imaging properties was carried out. The presented hole inspection lens has been designed, constructed and used for inspection of the fuel assembly spacer grids...|$|R
40|$|A ray-rotation sheet {{consists}} of miniaturized optical components that function - ray optically - as a homogeneous medium that rotates the local direction of transmitted light rays around the sheet normal by an arbitrary angle [A. C. Hamilton et al., arXiv: 0809. 2646 (2008) ]. Here {{we show that}} two or more parallel ray-rotation sheets perform imaging between two planes. The image is unscaled and un-rotated. No other planes are imaged. When seen through parallel ray-rotation sheets, planes that are not imaged appear rotated, whereby the rotation angle changes with the ratio between the observer's and the <b>object</b> <b>plane's</b> distance from the sheets. Comment: 8 pages, 6 figure...|$|R
