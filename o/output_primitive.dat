2|34|Public
5000|$|Information {{should be}} exchanged, it will {{flow from the}} {{outputting}} to the inputting process. The <b>output</b> <b>primitive</b> will specify the data to be sent. In , this data is [...] Similarly, if an input expects to receive data, one or more bound variables will act as place-holders to be substituted by data, when it arrives. In , [...] plays that role. The choice {{of the kind of}} data that can be exchanged in an interaction {{is one of the key}} features that distinguishes different process calculi.|$|E
40|$|Abstract. A robust {{combiner}} is {{a construction}} that combines several implementations of a primitive based on different assumptions, and yields an implementation {{guaranteed to be}} secure if at least some assumptions (i. e. sufficiently many but not necessarily all) are valid. In this paper we generalize this concept by introducing error-tolerant combiners, which in addition to protection against insecure implementations provide tolerance to functionality failures: an error-tolerant combiner guarantees a secure and correct implementation of the <b>output</b> <b>primitive</b> even {{if some of the}} candidates are insecure or faulty. We present simple constructions of error-tolerant robust combiners for oblivious linear function evaluation. The proposed combiners are also interesting in the regular (not error-tolerant) case, as the construction is much more efficient than the combiners known for oblivious transfer. ...|$|E
40|$|HS＿GKS 3 D是在 0600 系列工作站上开发的一个GKS－ 3 D的 2 c级实现系统。本文在讨论GKS－ 3 D的功能特点及其实现系统的设计原则的基础上，对HS＿GKS 3 D主要部分的实现作了介绍，其中包括：（ 1 ）系统的整体结构；（ 2 ）图段存贮、元文件管理；（ 3 ）三维输出流水线的设计及实现，并考虑与二维流水线的兼容；（ 4 ）输出图元和控制功能的实现；（ 5 ）c级输入功能（request、sample、event）的实现。在本文的最后一章，对三维图形标准的发展趋势进行了分析和预测。A 2 c level {{implementation}} of GKS- 3 D, called HS_GKS 3 D, {{is presented in}} this thesis. The implementation details of the major parts of the system described include: (1) the overall structure of HS_GKS 3 D; (2) segment storage and metafile management; (3) the design and {{implementation of}} the GKS- 3 D output pipeline, considering the compatibility with GKS; (4) <b>output</b> <b>primitives,</b> control functions; and (5) c level input functions (request, sample, event). Finally, the trends of the 3 D graphical standards are also discussed...|$|R
40|$|International audienceThe expressiveness of {{communication}} primitives has been explored {{in a common}} framework based on the pi-calculus by considering four features: synchronism, arity, communication medium, and pattern-matching. These all assume asymmetric communication between input and <b>output</b> <b>primitives,</b> however some calculi consider more symmetric approaches to communication such as fusion calculus and Concurrent Pattern Calculus. Symmetry can be considered either as supporting exchange of information between an action and co-action, or as unification of actions. By means of possibility/impossibility of encodings, this paper shows that the exchange approach is related to, or more expressive than, many previously considered languages. Meanwhile, the unification approach is more expressive than some, but mostly unrelated to, other languages...|$|R
40|$|The {{most basic}} <b>output</b> <b>primitives</b> in every {{computer}} graphics library are “lineSegment() ” and “Polygon() ”, ortheir equivalents. These are, of course, sufficent {{in the sense}} that any curved line or surface can be arbitrarrily well approximated by straight line segments or planar polygons, but in many contexts that is not enough. Such approximations often require large amounts of data to obtain satifactory smoothness, and they are awkward to manipulate. Then too, even with the the most sophisticated continous shading models, polygonaltechniques can resultin visually ojectionable images. Mach bands may be apparent at the borders between adjacent polygons, and there is always a telltale angularity to polygonal silhouettes. Hence many modelling systems are augmented by circles, spheres, cylinders, etc. and allow such simple primitives to be combined to form quite complex objects...|$|R
40|$|In this tutorial, we program big-step and small-step total interpreters for the While {{language}} extended with {{input and}} <b>output</b> <b>primitives.</b> While {{is a simple}} imperative language consisting of skip, assign-ment, sequence, conditional and loop. We first develop trace-based interpreters for While. Traces are potentially infinite nonempty sequences of states. The interpreters assign traces to While programs: for us, traces are denotations of While programs. The trace is finite if the program is terminating and infinite if the program is non-terminating. However, we cannot decide (i. e., write a program to determine), for any given program, whether its trace is finite or infinite, which amounts to deciding the halting problem. We then extend While with interactive input/output primitives. Accordingly, we extend the interpreters by generalizing traces to resumptions. The tutorial is based on our previous work with T. Uustalu on reasoning about interactive pro-grams {{in the setting of}} constructive type theory. ...|$|R
40|$|There exist several {{approaches}} {{to extract the}} boundary of a 3 D image. Most of them represent the extracted boundary {{as a collection of}} a large number of little triangular or quadrangular faces whereas few approaches give general orthogonal faces (with any number of edges and with possible holes). One of these approaches is based on a secondary model EVM and focusses mainly on the process to obtain the orientation of the <b>output</b> <b>primitives</b> (edges and faces). Actually, this algorithm obtains, for each plane, a set of oriented edges that have to be rearranged as contours and these contours have to be classified in order to have the corresponding inclusion relationships. These last two processes are performed in a simple brute force way. In this paper, we present an improved algorithm that processes all the edges of a plane and, following a plane-sweep based method, obtains the contours and the inclusion relationships. Postprint (published version...|$|R
40|$|This paper {{suggests}} a novel model-free primitive-based hierarchical approach to trajectory tracking, which endows the feedback control systems with learning and planning capabilities. The reference inputs (r. i. s) are first optimized {{at the low}} level in a Model-Free Iterative Learning Control framework to achieve controlled output trajectory tracking, without using {{a model of the}} environment. The learning takes place in a Linear Time Invariant (LTI) setting. The learned r. i. -controlled output pairs are called primitive pairs. Each new complex trajectory to be tracked is then decomposed at the high level in terms of the learned <b>output</b> <b>primitives</b> regarded as basis functions. The optimal r. i. ensuring output tracking of the new trajectory is obtained by merging the leaned r. i. primitives using the superposition principle specific to LTI. Therefore, the optimal r. i. is computed offline and avoids learning to track new trajectories from repeated executions of the tracking task. The efficiency of this approach is illustrated on a positioning control system for an aerodynamic system...|$|R
40|$|This study {{attempts}} {{to develop an}} automatic method to identify and characterize urban areas and urban sprawl, and that have the possibility of replicating to different urbanization regions of Brazil. Urban sprawl has been characterized as dispersed form of urban growth that causes environment impacts (deforestation, river pollution); increase urban infrastructure cost; lost of agricultural lands and is highly dependent on the automobile. The objective is to achieve a methodology for the increase of precision and reduction of processing time and subjectivity. Object-based Image Analysis with Definiens software and LANDSAT images (acquired in September of 2007) referring to Piracicaba, Limeira and Rio Claro region (São Paulo state) were used. The object-based approach is a spatial analysis method based essentially on segmentation and classification <b>outputs.</b> <b>Primitive</b> objects are created on given space scale levels with different resolution, and classification rules are applied based on a fuzzy rule decision tree classifier. High-resolution images (Quick Bird images) available at Google Earth were used for accuracy assessment. Omission and commission error were calculated. The good results obtained (Global Accuracy: 0. 94 and Kappa Index: 0. 72) from automatic classification {{of the study area}} indicate that the object-based method can be suitable for semi-automatic urban mapping. Pages: 569 - 57...|$|R
40|$|Extracting the {{boundary}} of a 3 D or a 2 D image is a fundamental operation in several image processing related fields. In other fields as NC-data generation, obtaining the cutting areas of sculptured surfaces can be performed by first representing the surface using a regular grid model which is equivalent to a 2 D binary image. There exist several approaches to extract {{the boundary}} of a 3 D image. Most of them represent the extracted boundary {{as a collection of}} a large number of little triangular or quadrangular faces whereas few approaches give general orthogonal contours with the corresponding inclusion relationships. One of these approaches is based on a secondary model EVM and allows to obtain the orientation of the <b>output</b> <b>primitives</b> (edges and faces). It actually obtains, for each plane of the resulting B-Rep model, a set of oriented edges that have to be rearranged as contours and these contours have to be classified in order to have the corresponding inclusion relationships. These last two processes are performed in a simple brute force way. In this paper, we present an improved algorithm that processes all the edges of a plane and, following a plane-sweep based method, obtains the contours and the inclusion relationships. The presented algorithm can also be applied to extract {{the boundary of}} a 2 D image. Postprint (published version...|$|R
40|$|This paper {{suggests}} that input and <b>output</b> are basic <b>primitives</b> of programming and that parallel composition of communicating sequential processes {{is a fundamental}} program structuring method. When combined with a development of Dijkstra's guarded command, these concepts are surprisingly versatile. Their use is illustrated by sample solutions {{of a variety of}} familiar programming exercises...|$|R
40|$|Parallel {{visualization}} of large datasets in GeoFEM is described. Our visualization subsystem supports concurrent visualization with computation, and outputs a simplified small graphic primitive set, {{which can be}} displayed by a basic viewer on clients. This subsystem provides many kinds of parallel visualization algo-rithms for the users to visualize their data from scalar, vector to tensor. Scalar field topology analysis, flow field topology and semi-automatic parameter design are employed {{to improve the quality}} of visualization results. We also present a simplification algorithm to reduce the number of <b>output</b> graphic <b>primitives,</b> ac-counting for both shape attribute and color attribute. The experimental results show the effectiveness of our subsystem...|$|R
50|$|INT 10h, INT 10H or INT 16 is {{shorthand}} for BIOS interrupt call 10hex, the 17th interrupt vector in an x86-based computer system. The BIOS typically {{sets up a}} real mode interrupt handler at this vector that provides video services. Such services include setting the video mode, character and string <b>output,</b> and graphics <b>primitives</b> (reading and writing pixels in graphics mode).|$|R
40|$|An initial {{overview}} of parallel visualization in the GeoFEM software system is provided. Our visualization subsystem offers {{many kinds of}} parallel visualization methods for the users to visualize their huge finite element analysis datasets for scalar, vector and/or tensor fields at a reasonable cost. A polygonal simplification scheme is developed to make more efficient, the transmission and rendition of <b>output</b> graphic <b>primitives.</b> A salient feature of the subsystem lies in its capability in automatic setting of visualization parameter values based on the analysis of scalar/flow field topology and volumetric coherence, {{to improve the quality}} of visualization results with a minimized number of batch re-executions. Representative experimental results illustrate the effectiveness of our subsystem...|$|R
500|$|A {{series of}} statistical-dynamical models, which used {{regression}} equations based upon CLIPER output {{and the latest}} <b>output</b> from <b>primitive</b> equation models run at the National Meteorological Center, then National Centers for Environmental Prediction, were developed between the 1970s and 1990s and were named NHC73, NHC83, NHC90, NHC91, and NHC98. [...] Within the field of tropical cyclone track forecasting, despite the ever-improving dynamical model guidance which occurred with increased computational power, {{it was not until}} the decade of the 1980s when numerical weather prediction showed skill, and until the 1990s when it consistently outperformed statistical or simple dynamical models. [...] In 1994, a version of SHIFOR was created for the northwest Pacific Ocean for typhoon forecasting, known as the Statistical Typhoon Intensity Forecast (STIFOR), which used the 1971–1990 data for that region to develop intensity forecasts out to 72hours into the future.|$|R
40|$|The basic {{building}} blockss of all graphical <b>output</b> are <b>primitives</b> such as polyline, polymarker, text, {{cell array}} and fill area. These primitives have additional data {{associated with them}} to render visual effect on the display surface of a workstation. I have explored and analyzed these primitives and implemented them by routines written in C language for IBM and IBM Compatible Personal Computers. Some of the algoriths for these routines were integrated and implemented in the Extensible Graphics Software(EGS). EGS is a prototype graphics system developed by the faculty and students of Ball State University to study and research graphics systems. I have created a font for English alphabets and digit characters. The font and any algorithms created in this thesis would be included and implemented for further development of EGS. An effective attempt is made in this thesis to show how a graphics system could be developed with a minimal dependency on hardware of computers. Department of Computer ScienceThesis (M. S. ...|$|R
40|$|A {{simple method}} for blood spatter {{analysis}} was implemented using an image processing technique. The advantagesof the computer application were exploited which subsequently provides minimal time consumed and user friendly interface. The outputs {{from the program}} associated with the string method are used for finding {{the origin of the}} incident, i. e. wherethe blood came from. The direction and the impact angle of the bloodstain use 4 -step process analysis. The comparisonsbetween outputs from the program and the traditional method were reported. The <b>primitive</b> <b>outputs</b> from the program aremarginally acceptable with approximately 10 % error; however, with a simple tweak manually, the errors drop more than threetimes...|$|R
40|$|In his 2000 book Logical Properties Colin McGinn {{argues that}} predicates denote {{properties}} rather than sets or individuals. I support the thesis, but {{show that it}} is vulnerable to a type-incongruity objection, if properties are (modelled as) functions, unless a device for extensionalizing properties is added. Alternatively, properties may be construed as primitive intensional entities, as in George Bealer. However, I object to Bealer’s construal of predication as a primitive operation inputting two <b>primitive</b> entities and <b>outputting</b> a third <b>primitive</b> entity. Instead I recommend we follow Pavel Tichý in construing both predication and extensionalization as instances of the primitive operation of functional application. PhilosophyTechnology, Policy and Managemen...|$|R
40|$|Abstract- The {{finding of}} {{collisions}} (i. e. different inputs that {{map to the}} same <b>output)</b> in cryptographic <b>primitives</b> (hash functions or block ciphers) is an extremely difficult task. It generally requires {{hundreds or thousands of}} hours of a talented cryptanalyst. Even in this case, results are not always guaranteed. In this work, we will present a new method for easing the find of collisions, based in the use of genetic algorithms. Our method automatically seeks for correlations between the input and the output bits {{that can be used for}} producing pseudocollisions (i. e. collisions of parts of the output). These pseudocollisions are then useful for creating a full output collision. These ideas are shown to work over...|$|R
40|$|This paper proposes how {{to learn}} and {{generate}} multiple action sequences of a humanoid robot. At first, all the basic action sequences, also called primitive behaviors, are learned by a recurrent neural network with parametric bias (RNNPB) {{and the value of}} the internal nodes which are parametric bias (PB) determining the <b>output</b> with different <b>primitive</b> behaviors are obtained. The training of the RNN uses back propagation through time (BPTT) method. After that, to generate the learned behaviors, or a more complex behavior which is the combination of the primitive behaviors, a reinforcement learning algorithm: Q-learning (QL) is adopt to determine which PB value is adaptive for the generation. Finally, using a real humanoid robot, the proposed method was confirmed its effectiveness by the results of experiment...|$|R
40|$|The Direct 3 D 10 /SM 4. 0 system [Blythe 2006] is the 4 th genera-tion {{programmable}} graphics processing units (GPUs) architecture. The new pipeline introduces significant additions {{and changes}} to prior generation pipeline. We explore these new features and ex-periment to judge their performance. The main facilities introduced that we ponder upon are, Unified Architecture providing common features set for all programmable stages, Geometry Shader {{which is a}} new programmable stage capable of generating additional primi-tives, Stream <b>output</b> with which <b>primitive</b> data can be streamed to memory, Array textures and primitive level redirection to different frame buffers through layered rendering. We analyze our imple-mentations and with experimentation, we draw conclusions on their efficient usage and provide some of their limitations...|$|R
40|$|Congress on Evolutionary Computation. Honolulu, HI, 12 - 17 May 2002 The {{finding of}} {{collisions}} (i. e. different inputs that {{map to the}} same <b>output)</b> in cryptographic <b>primitives</b> (hash functions or block ciphers) is an extremely difficult task. It generally requires {{hundreds or thousands of}} hours of a talented cryptanalyst. Even in this case, results are not always guaranteed. We present a new method for easing collision finding, based on genetic algorithms. Our method automatically seeks correlations between the input and the output bits {{that can be used for}} producing pseudocollisions (i. e. collisions of parts of the output). These pseudocollisions are then useful for creating a full output collision. These ideas are shown to work over a version of the block cipher TEA reduced to one round...|$|R
40|$|In {{the paper}} we show, through a {{hypothetical}} "conversation" among two pupils and a computer, {{how it is}} possible to use the Logo language in interactive way for solving verbal poblems with the top-down method. The interaction man-machine is very simple: {{it is based on the}} <b>primitives</b> <b>OUTPUT</b> and TRACE of the Italian version of Logo Commodore and on the particular type of its messages of error. In the paper we present, in an unusual manner, a trace of the work developed with pupils aged 11 - 12, for a concrete and motivated approach to the analysis of problems and to their decomposition in to subproblems. The theme has been chosen for the importance that this method assumes both in the problem solving and in the approach to the structured programming...|$|R
40|$|The MyOcean R&D project MESCLA (MEsoSCaLe {{dynamical}} Analysis through combined model, {{satellite and}} in situ data) {{was devoted to}} the high resolution 3 -D retrieval of tracer and velocity fields in the oceans, based on the combination of in situ and satellite observations and quasi-geostrophic dynamical models. The retrieval techniques were also tested and compared with the <b>output</b> of a <b>primitive</b> equation model, with {{particular attention to the}} accuracy of the vertical velocity field as estimated through the Q vector formulation of the omega equation. The project focused on a test case, covering the region where the Gulf Stream separates from the US East Coast. This work demonstrated that innovative methods for the high resolution mapping of 3 -D mesoscale dynamics from observations can be used to build the next generations of operational observation-based products...|$|R
5000|$|Linguistic {{insecurity}} {{in relation}} to creoles {{has to do with}} the underlying assumption and classification of these languages as inferior forms of the parent languages from which they are derived. Typical of most non-official languages, creoles are regarded as mere degenerate variants and rudimentary dialects that are subsumed under the main [...] "standard" [...] languages for that particular community. With this popular view, creoles are thought to be impoverished, <b>primitive</b> <b>outputs</b> that are far from their European target languages. The negative nonlinguistic implications lead to claims of creole use as being a [...] "handicap" [...] for their speakers. This has caused speakers of these creole languages to experience insecurity and lack of confidence in the use of their form of language, which has undermined the prevalence of creoles spoken in societies.|$|R
5000|$|In this design, the {{renderer}} must {{store the}} entire frame buffer in memory since the final image cannot be <b>output</b> until all <b>primitives</b> have been processed. A common memory optimization introduces a step called bucketing {{prior to the}} dicing step. The output image is divided into a coarse grid of [...] "buckets," [...] each typically 16 by 16 pixels in size. The objects are then split roughly along the bucket boundaries and placed into buckets based on their location. Each bucket is diced and drawn individually, and {{the data from the}} previous bucket is discarded before the next bucket is processed. In this way only a frame buffer for the current bucket and the high-level descriptions of all geometric primitives must be maintained in memory. For typical scenes, this leads to a significant reduction in memory usage compared to the unmodified Reyes algorithm.|$|R
40|$|Abstract. For secure two-party and multi-party {{computation}} with abort, {{classification of}} which primitives are complete {{has been extensively}} studied in the literature. However, for fair secure computation, where (roughly speaking) either all parties learn the output or none do, the question of complete primitives has remained largely unstudied. In this work, we initiate a rigorous study of completeness for primitives that allow fair computation. We show the following results: – No “short ” primitive is complete for fairness. In surprising contrast to other notions of security for secure two-party computation, we show that for fair secure computation, no primitive of size O(log k) is complete, where k is a security parameter. This is the case even if we can enforce parallelism in calls to the primitives (i. e., the adversary does not get <b>output</b> from any <b>primitive</b> in a parallel call until it sends input to all of them). This negative result holds regardless of any computational assumptions. – A fairness hierarchy. We clarify the fairness landscape further by exhibiting {{the existence of a}} “fairness hierarchy”. We show that for every “short ” ℓ...|$|R
40|$|Biological {{movement}} control and planning {{is based upon}} motor primitives. Each motor primitive takes responsibility for controlling a small sub-block of motion, containing coherent muscle activation outputs. A central timing controller cues these subroutines of movement, creating complete movement strategies that are built up by overlaying primitives, thus creating synergies of muscle activation. This partitioning allows the movement to be defined by a sparse code representing the timing of primitive activations. We have shown {{that it is possible}} to use a factorial hidden Markov model to infer primitives in handwriting data. The variation in the handwriting data can to a large extent be explained by timing variation in the triggering of the primitives. Once an appropriate set of primitives has been inferred, the characters can be represented as a set of timings of primitive activations, along with variances, giving a very compact representation of the character. The model is naturally partitioned into a low level <b>primitive</b> <b>output</b> stage, and a top-down primitive timing stage. This partitioning gives us an insight into behaviours such as scribbling, and what is learnt in order to write a new character. ...|$|R
40|$|We address {{high-level}} {{synthesis of}} low-power {{digital signal processing}} (DSP) systems by using efficient switching activity models. We present a technology-independent hierarchical scheme {{that can be easily}} integrated into current communications/DSP CAD tools for comparing the relative power/performance of two competing DSP designs without specific knowledge of transistor-level details. The basic building blocks considered for such systems are a full adder, a half adder, and a one-bit delay. Estimates of the switching activity at the <b>output</b> of these <b>primitives</b> are used to model the activity in more complex building blocks of DSP systems. The presented hierarchical method is very fast and simple. The accuracy of estimates obtained using the proposed approach is shown to be within 4 % of the results obtained using extensive bit-level simulations. Our approach shows that the choice of multiplier/multiplicand is important when using array multipliers in a datapath. If the input signal with smaller mean square value is chosen as the multiplicand, almost 20 % savings in switching activity can be achieved. This observation is verified by an analog simulation using a 16 x 16 bit array multiplier implemented in a 0. 6 -mu process with 3. 3 V supply voltage...|$|R
40|$|A {{primitive}} based generative {{model to}} infer timing information in unpartitioned handwriting data Areas: Perception, Vision, Adaptive Systems Biological movement control and planning {{is based upon}} motor primitives. Each motor primitive takes responsibility for controlling a small sub-block of motion, containing coherent muscle activation outputs. A central timing controller cues these subroutines of movement, creating complete movement strategies that are built up by overlaying primitives, thus creating synergies of muscle activation. This partitioning allows the movement to be defined by a sparse code representing the timing of primitive activations. This paper shows {{that it is possible}} to use a factorial hidden Markov model to infer primitives in handwriting data. The variation in the handwriting data can to a large extent be explained by timing variation in the triggering of the primitives. Once an appropriate set of primitives has been inferred, the characters can be represented as a set of timings of primitive activations, along with variances, giving a very compact representation of the character. The model is naturally partitioned into a low level <b>primitive</b> <b>output</b> stage, and a top-down primitive timing stage. This partitioning gives us an insight into behaviours such as scribbling, and what is learnt in order to write a new character. ...|$|R
40|$|Ames Research Graphics System, ARCGRAPH, is a {{collection}} of libraries and utilities which assist researchers in generating, manipulating, and visualizing graphical data. In addition, ARCGRAPH defines a metafile format that contains device independent graphical data. This file format is used with various computer graphics manipulation and animation packages at Ames, including SURF (COSMIC Program ARC- 12381) and GAS (COSMIC Program ARC- 12379). In its full configuration, the ARCGRAPH system consists of a two stage pipeline which may be used to <b>output</b> graphical <b>primitives.</b> Stage one is associated with the graphical primitives (i. e. moves, draws, color, etc.) along with the creation and manipulation of the metafiles. Five distinct data filters make up stage one. They are: 1) PLO which handles all 2 D vector primitives, 2) POL which handles all 3 D polygonal primitives, 3) RAS which handles all 2 D raster primitives, 4) VEC which handles all 3 D raster primitives, and 5) PO 2 which handles all 2 D polygonal primitives. Stage two is associated with the process of displaying graphical primitives on a device. To generate the various graphical primitives, create and reprocess ARCGRAPH metafiles, and access the device drivers in the VDI (Video Device Interface) library, users link their applications to ARCGRAPH's GRAFIX library routines. Both FORTRAN and C language versions of the GRAFIX and VDI libraries exist for enhanced portability within these respective programming environments. The ARCGRAPH libraries were developed on a VAX running VMS. Minor documented modification of various routines, however, allows the system to run on the following computers: Cray X-MP running COS (no C version); Cray 2 running UNICOS; DEC VAX running BSD 4. 3 UNIX, or Ultrix; SGI IRIS Turbo running GL 2 -W 3. 5 and GL 2 -W 3. 6; Convex C 1 running UNIX; Amhdahl 5840 running UTS; Alliant FX 8 running UNIX; Sun 3 / 160 running UNIX (no native device driver); Stellar GS 1000 running Stellex (no native device driver); and an SGI IRIS 4 D running IRIX (no native device driver). Currently with version 7. 0 of ARCGRAPH, the VDI library supports the following output devices: A VT 100 terminal with a RETRO-GRAPHICS board installed, a VT 240 using the Tektronix 4010 emulation capability, an SGI IRIS turbo using the native GL 2 library, a Tektronix 4010, a Tektronix 4105, and the Tektronix 4014. ARCGRAPH version 7. 0 was developed in 1988...|$|R
40|$|Pluripotent stem cell-derived cardiomyocytes are {{currently}} being investigated for in vitro human heart models and as potential therapeutics for heart failure. In this study, we have developed a differentiation protocol that minimizes the need for specific human embryonic stem cell (hESC) line optimization. We first reduced the heterogeneity that exists within the starting population of bulk cultured hESCs by using cells adapted to singlecell passaging in a 2 -dimensional. (2 D) culture format. Compared with bulk cultures, single-cell cultures comprised larger fractions of TG 30 (hi) /OCT 4 (hi) cells, corresponding to an increased expression of pluripotency markers OCT 4 and NANOG, and reduced expression of early lineage-specific markers. A 2 D temporal differentiation protocol was then developed, aimed at reducing the inherent heterogeneity and variability of embryoid body-based protocols, with induction of primitive streak cells using bone morphogenetic protein 4 and activin A, followed by cardiogenesis via inhibition of Wnt signaling using the small molecules IWP- 4 or IWR- 1. IWP- 4 treatment resulted in {{a large percentage of}} cells expressing low amounts of cardiac myosin heavy chain and expression of early cardiac progenitor markers ISL 1 and NKX 2 - 5, thus indicating the production of large numbers of immature cardiomyocytes (similar to 65, 000 / cm(2) or similar to 1. 5 per input hESC). This protocol was shown to be effective in HES 3, H 9, and, to a lesser, extent, MEL 1 hESC lines. In addition, we observed that IWR- 1 induced predominantly atrial myosin light chain (MLC 2 a) expression, whereas IWP- 4 induced expression of both atrial (MLC 2 a) and ventricular (MLC 2 v) forms. The intrinsic flexibility and scalability of this 2 D protocol mean that the <b>output</b> population of <b>primitive</b> cardiomyocytes will be particularly accessible and useful for the investigation of molecular mechanisms driving terminal cardiomyocyte differentiation, and potentially for the future treatment of heart failure...|$|R
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references. Issued also on microfiche from Lange Micrographics. Human smooth pursuit tracking eye movements were analyzed in the frequency domain. The stimulus used was a sum of sinusoids, in lieu of white Gaussian noise. The feasibility of the nonlinear analysis by a sum of sinusoids consisting of only 6 frequencies was evaluated through computer simulation with a known nonlinear system. A new method which makes use of the linear property of the discrete Fourier transform and uses the sum of sinusoids as stimulus with which to determine interaction frequencies is presented for the estimation of different order nonlinearities and primitive frequencies of a nonlinear system. The data of smooth tracking electrooculogram (EOG) responses to the sum of sinusoids from eight subjects were applied and analyzed in the frequency domain. The average power of these linear components which dominate the responses takes 63. 66 % in the smooth pursuit tracking responses for the eight subjects. With the notion of <b>primitive</b> frequencies, the <b>outputs</b> at the <b>primitive</b> frequencies of order n (n= 4 at most) were detected. The proportions of both the magnitudes and powers of different order primitive frequencies were calculated and analyzed. It is significant that magnitude proportions for the eight subjects are very close to each other. The average magnitude proportions are 18. 75 % for order 2, 30. 68 % for order 3, and 50. 49 % for order 4; however, there are great differences among the power proportions for the eight subjects. In addition, strength indices indicate that the 2 nd order primitive frequencies have more average magnitude contribution to the nonlinearity of the human smooth pursuit system than the 3 rd and 4 th order primitive frequencies in EOG responses to the stimulus pattern 0...|$|R
40|$|The {{upgrades}} of the LHC accelerator and {{the experiments}} in 2019 / 20 and 2023 / 24 will allow to in-crease the luminosity to 2 × 1034 cm− 2 s− 1 and 5 - 7 × 1034 cm− 2 s− 1, respectively. For the HL-LHC phase, the expected {{mean number of}} interactions per bunch crossing will be 55 at 2 × 1034 cm− 2 s− 1 and ~ 140 at 5 × 1034 cm− 2 s− 1. This increase drastically impacts the ATLAS trigger and trigger rates. For the ATLAS Muon Spectrometer, a replacement of the innermost endcap stations, the so-called “Small Wheels” operating in a magnetic field, is therefore planned for 2019 / 20 {{to be able to}} maintain a low pT threshold for single muon and excellent tracking capability in the HL-LHC regime. The New Small Wheels will feature two new detector technologies: Resistive Micromegas and small strip Thin Gap Chambers comprising a system of ~ 2. 4 million readout channels. Both detector technologies will provide trigger and tracking primitives fully compliant with the post- 2024 HL-LHC operation. To al-low for some safety margin, the design studies assume a maximum instantaneous luminosity of 7 × 1034 cm− 2 s− 1, 200 pile-up events, trigger rates of 1 MHz at Level- 0 and 400 KHz at Level- 1. A radia-tion dose of ~ 1700 Gy (inner radius) is expected. The electronics design of such a system will be implemented in some 8000 on-detector boards including the design of four different custom ASICs. Among them the 64 -channel VMM, a common frontend mixed-signal ASIC for both detector tech-nologies and charge-interpolating trackers, provides amplitude and timing measurements, direct <b>output</b> of trigger <b>primitives</b> and Level- 0 trigger buffering. The candidate selection is required to be within a budget latency of 1 us, and 6 us after 2024. Moreover, the design integrates the GBTx (a radiation hard 5 Gigabit transceiver) and a Slow Control ASICs developed at CERN. The custom GBTx data flow links are aggregated onto an industry standard high speed network to which standard PCs perform data acquisition, configuration, and monitoring. The large number of readout channels, high speed output data rate, harsh radiation and magnetic environment, small available space, poor access and low power consumption all impose great challenges on the system design. The overall design and first results from integration of the electronics in a vertical slice test will be presented...|$|R

