99|1361|Public
25|$|Moritz von Rohr {{also used}} an <b>object</b> <b>field</b> method, but unlike Merklinger, {{he used the}} {{conventional}} criterion of a maximum circle of confusion diameter in the image plane, leading to unequal front and rear depths of field.|$|E
25|$|The hyperfocal {{distance}} is the nearest focus distance {{at which the}} DOF extends to infinity; focusing the camera at the {{hyperfocal distance}} results in the largest possible depth of field for a given f-number (Ray 2000, 55). Focusing beyond the hyperfocal distance does not increase the far DOF (which already extends to infinity), but it does decrease the DOF {{in front of the}} subject, decreasing the total DOF. Some photographers consider this wasting DOF; however, see <b>Object</b> <b>field</b> methods above for a rationale for doing so. Focusing on the hyperfocal distance is a special case of zone focusing in which the far limit of DOF is at infinity.|$|E
25|$|Traditional depth-of-field {{formulas}} {{and tables}} assume equal circles of confusion for {{near and far}} objects. Some authors, such as Merklinger (1992), have suggested that distant objects often need to be much sharper to be clearly recognizable, whereas closer objects, being larger on the film, {{do not need to}} be so sharp. The loss of detail in distant objects may be particularly noticeable with extreme enlargements. Achieving this additional sharpness in distant objects usually requires focusing beyond the hyperfocal distance, sometimes almost at infinity. For example, if photographing a cityscape with a traffic bollard in the foreground, this approach, termed the <b>object</b> <b>field</b> method by Merklinger, would recommend focusing very close to infinity, and stopping down to make the bollard sharp enough. With this approach, foreground objects cannot always be made perfectly sharp, but the loss of sharpness in near objects may be acceptable if recognizability of distant objects is paramount.|$|E
5000|$|Each Record <b>object</b> {{contains}} many <b>fields,</b> and a RecordSet object has a corresponding <b>Field</b> <b>object</b> also. The RecordSet <b>object's</b> <b>Field</b> <b>object</b> {{corresponds to a}} column in the database table that it references.|$|R
5000|$|C# initializes <b>object</b> <b>fields</b> in the {{following}} order when creating an object: ...|$|R
5000|$|How {{to handle}} null <b>object</b> <b>fields</b> - by default {{they are not}} present in the output ...|$|R
5000|$|... #Subtitle level 3: Determining {{a circle}} of {{confusion}} diameter from the <b>object</b> <b>field</b> ...|$|E
50|$|Moritz von Rohr {{also used}} an <b>object</b> <b>field</b> method, but unlike Merklinger, {{he used the}} {{conventional}} criterion of a maximum circle of confusion diameter in the image plane, leading to unequal front and rear depths of field.|$|E
5000|$|The join {{points in}} AspectJ include method or {{constructor}} call or execution, the initialization {{of a class}} or <b>object,</b> <b>field</b> read and write access, exception handlers, etc. They do not include loops, super calls, throws clauses, multiple statements, etc.|$|E
5000|$|Besides {{using the}} {{language}} Scheme, Java <b>object</b> <b>fields</b> and methods {{can be accessed}} using code such as: ...|$|R
50|$|In general, {{the above}} {{distinction}} between an <b>object's</b> <b>fields</b> (i.e. its data-type members) and an object's properties {{is the reason}} for the fact that fields are specified through data-type declarations, whereas properties are fundamentally specified through the definition of read and write access-semantics. This is an important distinction, and can be encapsulated by the maxim that <b>object</b> <b>fields</b> address internal structural concerns, and properties address use and access semantics concerns.|$|R
40|$|International audienceThis paper {{presents}} a static analysis technique based on effects and behavioural types for deriving synchronisation patterns of stateful active objects and verifying {{the absence of}} deadlocks in this context. This is challenging because active objects use futures to refer to results of pending asynchronous invocations and because these futures {{can be stored in}} <b>object</b> <b>fields,</b> passed as method parameters, or returned by invocations. Our effect system traces the access to <b>object</b> <b>fields,</b> thus allowing us to compute behavioural types that express synchronisation patterns in a precise way. The behavioural types are thereafter analysed by a solver that discovers potential deadlocks...|$|R
50|$|Opening {{the eyes}} returns {{one to the}} normal {{physical}} world, but still with the CEV <b>object</b> <b>field</b> overlaid onto it and present. In this state {{it is possible to}} see things that appear to be physical objects in the open-eye physical world, but that aren't really there.|$|E
50|$|The hyperfocal {{distance}} is the nearest focus distance {{at which the}} DOF extends to infinity; focusing the camera at the {{hyperfocal distance}} results in the largest possible depth of field for a given f-number (Ray 2000, 55). Focusing beyond the hyperfocal distance does not increase the far DOF (which already extends to infinity), but it does decrease the DOF {{in front of the}} subject, decreasing the total DOF. Some photographers consider this wasting DOF; however, see <b>Object</b> <b>field</b> methods above for a rationale for doing so. Focusing on the hyperfocal distance is a special case of zone focusing in which the far limit of DOF is at infinity.|$|E
50|$|The {{basic idea}} is that the {{illumination}} pattern is imaged onto a geometrically congruent cutoff pattern (essentially a multiplicity of knife edges) with focusing optics, while density gradients lying between the illumination pattern and the cutoff pattern are imaged, typically by a camera system. As in classical schlieren, the distortions produce regions of brightening or darkening corresponding to the position and direction of the distortion, because they redirect rays either away from or onto the opaque part of the cutoff pattern. While in classical schlieren, distortions over the whole beam path are visualized equally, in focusing schlieren, only distortions in the <b>object</b> <b>field</b> of the camera are clearly imaged. Distortions away from the <b>object</b> <b>field</b> become blurred, so this technique allows some degree of depth selection. It also has the advantage that a wide variety of illuminated backgrounds can be used, since collimation is not required. This allows construction of projection-based focusing schlieren systems which are much easier to build and align than classical schlieren systems. The requirement of collimated light in classical schlieren is often a substantial practical barrier for constructing large systems due to the need for the collimating optic to be {{the same size as the}} field of view. Focusing schlieren systems can use compact optics with a large background illumination pattern, which is particularly easy to produce with a projection system. For systems with large demagnification, the illumination pattern needs to be around twice the size of the field of view to allow for defocusing of the background pattern.|$|E
5000|$|... #Caption: Active electrolocation. Conductive <b>objects</b> {{concentrate}} the <b>field</b> and resistive <b>objects</b> {{spread the}} <b>field.</b>|$|R
30|$|All {{microcode}} instructions have {{a constant}} execution time of one cycle. No stalls are {{possible in the}} microcode pipeline. Loads and stores of <b>object</b> <b>fields</b> are handled explicitly. The absence of timing dependencies between bytecodes results in a simple processor model for the low-level WCET analysis.|$|R
40|$|This paper {{presents}} an analysis and transformation for individual object reclamation in Java programs. First, we propose a uniqueness inference algorithm that identifies variables and <b>object</b> <b>fields</b> that hold unique references. The algorithm performs an intraprocedural analysis of each method, and then builds and solves {{a set of}} inter-procedural uniqueness dependencies to find the global solution. Second, our system uses the uniqueness information to automatically instrument programs with explicit deallocation of individual objects. A key feature of the transformation {{is its ability to}} deallocate entire heap structures, including recursive structures, when their root objects are freed. This is achieved by generating object destructors that recursively free all of the unique <b>object</b> <b>fields.</b> Our experiments show that the analysis is effective at reclaiming a large fraction of the objects at a low analysis cost...|$|R
50|$|Traditional depth-of-field {{formulas}} {{and tables}} assume equal circles of confusion for {{near and far}} objects. Some authors, such as Merklinger (1992), have suggested that distant objects often need to be much sharper to be clearly recognizable, whereas closer objects, being larger on the film, {{do not need to}} be so sharp. The loss of detail in distant objects may be particularly noticeable with extreme enlargements. Achieving this additional sharpness in distant objects usually requires focusing beyond the hyperfocal distance, sometimes almost at infinity. For example, if photographing a cityscape with a traffic bollard in the foreground, this approach, termed the <b>object</b> <b>field</b> method by Merklinger, would recommend focusing very close to infinity, and stopping down to make the bollard sharp enough. With this approach, foreground objects cannot always be made perfectly sharp, but the loss of sharpness in near objects may be acceptable if recognizability of distant objects is paramount.|$|E
50|$|An {{effective}} {{approach for}} the compensation of losses in metamaterials, called plasmon injection scheme, has been recently proposed. The plasmon injection scheme {{has been applied}} theoretically to imperfect negative index flat lenses with reasonable material losses and {{in the presence of}} noise as well as hyperlenses. It has been shown that even imperfect negative index flat lenses assisted with plasmon injection scheme can enable subdiffraction imaging of objects which is otherwise not possible due to the losses and noise. Although plasmon injection scheme was originally conceptualized for plasmonic metamaterials, the concept is general and applicable to all types electromagnetic modes. The main idea of the scheme is the coherent superposition of the lossy modes in the metamaterial with an appropriately structured external auxiliary field. This auxiliary field accounts for the losses in the metamaterial, hence effectively reduces the losses experienced by the signal beam or <b>object</b> <b>field</b> {{in the case of a}} metamaterial lens. The plasmon injection scheme can be implemented either physically or equivalently through deconvolution post-processing method. However, the physical implementation has shown to be more effective than the deconvolution. Physical construction of convolution and selective amplification of the spatial frequencies within a narrow bandwidth are the keys to the physical implementation of the plasmon injection scheme. This loss compensation scheme is ideally suited especially for metamaterial lenses since it does not require gain medium, nonlinearity, or any interaction with phonons. Experimental demonstration of the plasmon injection scheme has not yet been shown partly because the theory is rather new.|$|E
40|$|An aberration-compensated {{image of}} an <b>object</b> <b>field</b> is created by {{generating}} a full-field complex hologram of the <b>object</b> <b>field,</b> generating a guide star complex hologram of a guide star selected from the <b>object</b> <b>field,</b> performing mathematical correlation between the guide star complex hologram and the full-field complex hologram, and generating from the correlation an aberration-compensated image of the <b>object</b> <b>field</b> from the correlation...|$|E
50|$|IBM's {{open source}} {{adaptive}} Java virtual machine, Jikes RVM, uses extended Array SSA, {{an extension of}} SSA that allows analysis of scalars, arrays, and <b>object</b> <b>fields</b> in a unified framework. Extended Array SSA analysis is only enabled at the maximum optimization level, which {{is applied to the}} most frequently executed portions of code.|$|R
40|$|In {{object-oriented}} programming, {{the overall}} reference structure {{is the combination}} of individual structures induced by the attributes of the underlying classes. This article makes {{the transition from a}} coarse-grained view to one allowing individual consideration of <b>object</b> <b>fields.</b> This is part of a series of articles. See here for links to the others...|$|R
40|$|Static {{analysis}} {{which takes}} into account the value of data stored in the heap is typically considered complex and computationally intractable in practice. Thus, most static analyzers do not keep track of <b>object</b> <b>fields</b> (or fields for short), i. e., they are field-insensitive. In this paper, we propose locality conditions for soundly converting fields into local variables. This way, field-insensitive analysis over the transformed program can infer information on the original fields. Our notion of locality is context-sensitive and can be applied both to numeric and reference fields. We propose then a polyvariant transformation which actually converts <b>object</b> <b>fields</b> meeting the locality condition into variables and which is able to generate multiple versions of code when this leads to increasing the amount of fields which satisfy the locality conditions. We have implemented our analysis within a termination analyzer for Java bytecode...|$|R
40|$|Aim Retinal {{anatomical}} {{studies have}} used the Drasdo & Fowler three-refracting surface schematic eye to convert between retinal distances and <b>object</b> <b>field</b> angles. We compared its performance at this task with those of more sophisticated four-refracting surface schematic eyes. Method Raytracing was performed for Drasdo & Fowler, Lotmar, Navarro, Liou & Brennan, Kooijman and Atchison schematic eyes, {{and some of their}} variants. Results The Drasdo & Fowler eye gives a greater rate of change of <b>object</b> <b>field</b> angle with retinal distance at the retinal centre of about 5...|$|E
40|$|Abstract—Both {{explicit}} {{analysis and}} FEM numerical simulation {{are used to}} analyze the field distribution of a line current in the so-called Maxwell’s fish eye lens [bounded with a perfectly electrical conductor (PEC) boundary]. We show that such a 2 D Maxwell’s fish eye lens cannot give perfect imaging {{due to the fact that}} high order modes of the <b>object</b> <b>field</b> can hardly reach the image point in Maxwell’s fish eye lens. If only zeroth order mode is excited, a good image of a sharp object may be achieved in some cases, however, its spot-size is larger than the spot size of the initial <b>object</b> <b>field.</b> The image resolution is determined by the field spot size of the image corresponding to the zeroth order component of the <b>object</b> <b>field.</b> Our explicit analysis consists very well with the FEM results for a fish eye lens. Time-domain simulation is also given to verify our conclusion. Multi-point images for a single object point are also demonstrated. 1...|$|E
30|$|We {{can obtain}} salient objects by {{the ratio of}} the number of pixels of the part {{touching}} the image boundary to those of the entire <b>object</b> <b>field.</b> The part with the smallest ratio is the salient object as shown in Eqs. (1)~(3).|$|E
50|$|Alternatively, one {{can return}} a {{completely}} new object from the current <b>objects</b> <b>fields,</b> which can be done first calling the constructor, and later assigning non final fields. Another alternative method is actually making the idea formal : creating a copy constructor that takes an instance. In fact {{that is what is}} recommended over clone by some people.|$|R
40|$|Digital Holography is an imaging {{modality}} {{made up of}} two parts: (i) Recording an interference pattern on a CCD, where an <b>object</b> wave <b>field</b> and a known reference wave are coincident and extracting the complex <b>object</b> wave <b>field</b> from this interference pattern and (ii) Replaying or reconstructing the hologram on a computer by simulating the propagation of the <b>object</b> wave <b>field</b> back to the object plane. Thus an image is obtained. We show how to adapt the reconstruction algorithm in {{a simple way to}} allow it to generate any output range and in any location making it far more versatile for zooming in on specific regions of our reconstructed image...|$|R
5000|$|In some multiparadigm {{languages}} {{that allow}} both object-oriented and functional styles, {{both of these}} features may be combined. For example, in OCaml <b>object</b> <b>fields</b> are immutable by default and must be explicitly marked with the [...] keyword to be mutable, while in Scala bindings are explicitly immutable, defined with [...] for [...] "value" [...] or explicitly mutable, defined with [...] for [...] "variable".|$|R
40|$|International audienceCommon-path digital in-line {{holography}} {{is considered}} as a valuable 3 D diagnostic techniques {{for a wide range}} of applications. This configuration is cost effective and relatively immune to variation in the experimental environment. Nevertheless, due to its common-path geometry, the signal to noise-ratio of the acquired hologram is weak as most of the detector (i. e. CCD/CMOS sensor) dynamics is occupied by the reference field signal, whose energy is orders of magnitude higher than the field scattered by the imaged object. As it is intrinsically impossible to modify the ratio of energy of reference to the <b>object</b> <b>field,</b> we propose a co-design approach (Optics/Data Processing) to tackle this issue. The reference to <b>object</b> <b>field</b> ratio is adjusted by adding a 4 -f device to a conventional in-line holographic setup, making it possible to reduce the weight of the reference field while keeping the <b>object</b> <b>field</b> almost constant. Theoretical analysis of the Cràmer-Rao lower bounds of the corresponding imaging model illustrate the advantages of this approach. These lower bounds can be asymptotically reached using a parametric inverse problems reconstruction. This implementation results in a 60 % gain in axial localization accuracy (for of 100 µm diameter spherical objects) compared to a classical in-line holography setup...|$|E
40|$|Both {{explicit}} {{analysis and}} FEM numerical simulation {{are used to}} analyze the field distribution of a line current in the so-called Maxwell's fish eye lens [bounded with a perfectly electrical conductor (PEC) boundary]. We show that such a 2 D Maxwell's fish eye lens cannot give perfect imaging {{due to the fact that}} high order modes of the <b>object</b> <b>field</b> can hardly reach the image point in Maxwell's fish eye lens. If only zeroth order mode is excited, a good image of a sharp object may be achieved in some cases, however, its spot-size is larger than the spot size of the initial <b>object</b> <b>field.</b> The image resolution is determined by the field spot size of the image corresponding to the zeroth order component of the <b>object</b> <b>field.</b> Our explicit analysis consists very well with the FEM results for a fish eye lens. Time-domain simulation is also given to verify our conclusion. Multi-point images for a single object point are also demonstrated. Comment: This article has been published on Progress In Electromagnetics Research(PIER) : F. Sun and S. He, "Can maxwell's fish eye lens really give perfect imaging?," Progress In Electromagnetics Research, Vol. 108, 307 - 322, 2010. Web-link: [URL] The former version of this article is 1009. 281...|$|E
40|$|Coded {{aperture}} sensors for photons or energetic neutral atoms (ENAs), which incorporate FOV limiters and subdivide the <b>object</b> <b>field</b> into {{a number}} of elements which is smaller than the number of detector pixels, are described. A least squares fit to the data is made in reconstructing the <b>object</b> <b>field.</b> To evaluate the optics and reconstruction algorithms, two 'breadboard' sensors have been constructed, one based on a film camera and the other upon a UV-light sensitive microchannel plate detector system. Results obtained thus far show that the concept is viable, and no special difficulties should be encountered in adapting the detector geometries to neutral particle imaging systems. Charged particle deflection plates could be incorporated into the region between the FOV limiter and the aperture, or installed ahead of the limiter...|$|E
40|$|A key {{component}} of automated object-oriented unit-test generation is to find method-call sequences that generate desired inputs of a method under test (MUT). Previous work cannot find desired sequences effectively due to the large search space of possible sequences. To address this issue, we present a MUT-aware sequence recommendation approach called RecGen to improve the effectiveness of random object-oriented unit-test generation. Unlike existing random testing approaches that select sequences without considering how a MUT may use inputs generated from sequences, Rec-Gen analyzes <b>object</b> <b>fields</b> accessed by a MUT and recommends a short sequence that mutates these fields. In addition, for MUTs whose test generation keeps failing, RecGen recommends a set of sequences {{to cover all the}} methods that mutate <b>object</b> <b>fields</b> accessed by the MUT. This technique further improves the chance of generating desired inputs. We have implemented RecGen and evaluated it on three libraries. Evaluation results show that RecGen improves code coverage over previous random testing tools...|$|R
40|$|Abstract. Static {{analysis}} {{which takes}} into account the value of data stored in the heap is typically considered complex and computationally intractable in practice. Thus, most static analyzers do not keep track of <b>object</b> <b>fields</b> (or fields for short), i. e., they are field-insensitive. In this paper, we propose locality conditions for soundly converting fields into local variables. This way, field-insensitive analysis over the transformed program can infer information on the original fields. Our notion of locality is context-sensitive and can be applied both to numeric and reference fields. We propose then a polyvariant transformation which actually converts <b>object</b> <b>fields</b> meeting the locality condition into variables and which is able to generate multiple versions of code when this leads to increasing the amount of fields which satisfy the locality conditions. We have implemented our analysis within a termination analyzer for Java bytecode. Interestingly, we can now prove termination of programs which use iterators without the need of a sophisticated heap analysis. ...|$|R
40|$|This {{document}} {{contains a}} test plan for testing input values to the General Mission Analysis Tool (GMAT). The plan includes four primary types of information, which rigorously define all tests {{that should be}} performed to validate that GMAT will accept allowable inputs and deny disallowed inputs. The first is {{a complete list of}} all allowed <b>object</b> <b>fields</b> in GMAT. The second type of information, is test input to be attempted for each field. The third type of information is allowable input values for all <b>objects</b> <b>fields</b> in GMAT. The final piece of information is how GMAT should respond to both valid and invalid information. It is VERY {{important to note that the}} tests below must be performed for both the Graphical User Interface and the script!! The examples are illustrated using a scripting perspective, because it is simpler to write up. However, the test must be performed for both interfaces to GMAT...|$|R
