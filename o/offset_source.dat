7|125|Public
40|$|The paper {{deals with}} a {{procedure}} for the correction of scan converter-based transient digitizers. The procedure includes two main phases: an experimental characterization for identifying the actual distortion model, and a correction for compensating errors directly on the converter output. The characterization {{is based on a}} dc generator; thus, the proposed procedure can be implemented as a self-correction technique by using the internal reference <b>offset</b> <b>source</b> of the scan digitizer. If periodically carried out, the procedure allows the influence of thermal effects on semiconductor diodes of target matrix to be significantly reduced. The procedure and the experimental results of its application to an actual digitizer have been made available to a large number of scan converter users by developing a Web site. © 1998 Elsevier Science B. V. All rights reserved...|$|E
40|$|We present Herschel {{observations}} at 70, 160, 250, 350 and 500 ??m of {{the environment}} of the radio galaxy 4 C+ 41. 17 at z = 3. 792. About 65 per cent of the extracted sources are securely identified with mid-infrared sources observed with the Spitzer Space Telescope at 3. 6, 4. 5, 5. 8, 8 and 24 ??m. We derive simple photometric redshifts, also including existing 850 and 1200 ??m data, using templates of active galactic nuclei, starburst-dominated systems and evolved stellar populations. We find that most of the Herschel sources are foreground to the radio galaxy and therefore do not belong to a structure associated with 4 C+ 41. 17. We do, however, find that the spectral energy distribution (SED) of the closest (??? 25 arcsec <b>offset)</b> <b>source</b> to the radio galaxy is fully consistent with being at the same redshift as 4 C+ 41. 17. We show that finding such a bright source that close to the radio galaxy at the same redshift is a very unlikely event, making the environment of 4 C+ 41. 17 a special case. We demonstrate that multiwavelength data, in particular on the Rayleigh???Jeans side of the SED, allow us to confirm or rule out the presence of protocluster candidates that were previously selected by single wavelength data set...|$|E
40|$|The {{definitive}} {{article is}} available at: [URL] Copyright John Wiley & Sons, Ltd. [Full text {{of this article}} is not available in the UHRA]In this paper the modelling, analysis and compensation of current conveyor tracking non-idealities in signal-processing circuits employing the second-generation current conveyor (CCII) as a transconductance amplifier are generally investigated. The voltage- and current-following inaccuracies of the CCII are represented in the forms of absolute and relative errors. Analysis shows that the effects of absolute tracking errors in a non-ideal CCII-based transconductance amplifier can be represented by an ideal CCII transconductance amplifier with an external voltage or current <b>offset</b> <b>source.</b> With this model the circuit output signal shift due to tracking errors can be easily evaluated using any excitation-response circuit analysis method. For the relative error description the effects of CCII following inaccuracies are modelled as a change in the transconductance resistance for the CCII transconductance amplifier. The affected circuit parameters are therefore readily assessed by directly replacing the nominal transconductance resistance in the ideal expressions by the varied counterpart, and the impact of relative errors can thus be precisely compensated by simply adding a proper resistance in parallel or series with the transconductance resistance. The methods developed for conventional CCIIs with unity gains are also extended to incorporate generalized CCIIs with any specified voltage and current gains...|$|E
3000|$|... where k_h_z {{refers to}} the {{vertical}} <b>offset</b> between <b>source</b> and receiver wavefields (Biondi and Shan 2002).|$|R
40|$|A signal {{conditioning}} circuit is described including operational amplifier, a variable <b>source</b> of <b>offset</b> potential, and four resistive impedance. The circuit has constant input impedance independent of gain and offset adjustments. Gain change is effected by varying {{one of the}} impedances in an amplifier feedback circuit; offset adjustment is effected through variation of the <b>offset</b> potential <b>source...</b>|$|R
5000|$|... where x = offset; v = {{velocity}} of the medium above the reflecting interface; [...] = travel time at zero <b>offset,</b> when the <b>source</b> and receiver {{are in the same}} place.|$|R
40|$|A {{velocity}} {{model is}} described in which we assume that velocity increases linearly with depth and varies elliptically with propagation direction. That is, we consider a linearly inhomogeneous elliptically anisotropic model. The variation of velocity with depth is given in terms of parameters a and b, and the elliptical anisotropy is given in terms of parameter x. An analytical traveltime expression is then derived {{to account for the}} direct traveltime between an <b>offset</b> <b>source</b> and a receiver in a well; such as in a vertical seismic profile (VSP) setting. A method of inverting traveltime observations to estimate parameters a, b and x is derived. The application of this method is exemplified using a data set from the Western Canada Basin. The parameter estimation also includes a statistical analysis. In the above case, we obtain a good agreement between the field data and the model. Furthermore, the inclusion of elliptical anisotropy is validated by showing that an isotropic model is outside of the confidence interval for x. Once a, b and x are known, a further application is considered; namely, we use the model to calculate the possible reflection points, collectively referred to as the zone of illumination, for a VSP experiment with a given source-receiver geometry. Such modelling is useful for both data analysis and survey design. Two computer codes are given using Maple®. The first code is for the estimation of the parameters and the second one is for the calculation of the zone of illumination...|$|E
40|$|We present Lick Natural Guide Star Adaptive Optics {{observations}} of the L 8 brown dwarf Gl 337 C, which is resolved {{for the first time}} into two closely separated (0 B 53 0 B 03), nearly equal magnitude components with a Ks flux ratio of 0 : 93 0 : 10. Companionship is inferred from the absence of a 3 B 6 <b>offset</b> <b>source</b> in TwoMicron All Sky Survey or photographic plate images, implying that the observed secondary component is a comoving late-type dwarf. With a projected separation of 11 AU and nearly equal magnitude components, Gl 337 CD has properties similar to those of other known companion and field substellar binaries. Its long orbital period (estimated to be 140 – 180 yr) inhibits short-term astrometric mass measurements, but the Gl 337 CD system is ideal for studying the L-T transition at a fixed age and metallicity. From a compilation of all known widely separated (k 100 AU) stellar– brown dwarf multiple systems, we find evidence that the binary fraction of brown dwarfs in these systems is notably higher than that of field brown dwarfs, 45 þ 1513 % versus 18 þ 7 4 % for analogous samples. We speculate on possible reasons for this difference, including the possibility that dynamic (ejection) interactions that may form such wide pairs preferentially retain binary secondaries because of their greater combined mass and/or ability to absorb angular momentum...|$|E
40|$|Abstract: This paper {{talks about}} a method of {{conception}} and design constraints on mm-wave reflectarrays. The developed tool allows us to plan quickly the behavior of large reflectarray (several tens of wavelength) according to parameters as illumination law or manufacturing tolerance with good agreement with measurements. An ultra-low side-lobe reflectarrays of 130 mm diameter is designed. The structure combines the advantages of a reflectarray with an <b>offset</b> <b>source</b> and those of a specific primary source, exhibiting a prolate radiation pattern, having very low side lobe levels. The maximum gain obtained at 94 GHz is 40 dBi and the side-lobe level is inferior to- 28 dB. Finally, a simultaneous multi-lobe antenna is designed at 94 GHz. The primary source is an open-ended waveguide and the phase profile is calculated by the program introduced in the first part. In this case, the four main lobes are placed in the same plane and for equal to- 30,- 10, 10, 30 °. This reflectarray {{can be used for}} actual and future generations of automotive radar. The first obtained results are encouraging and show the validity of the concept. Solution retained here is a low-cost solution. The proposed structures are developed on a single layer substrate and fabricated using standard photolithographic techniques. The aim {{of this article is to}} show that we can obtain interesting results with relatively simple and low-cost solutions, but also to show the limits of these type of solutions...|$|E
40|$|A {{conventional}} 3 rd generation Computed Tomography (CT) {{system with}} a single circular source trajectory is limited in terms of longitudinal scan coverage since extending the scan coverage beyond 40 [*]mm results in significant cone-beam artifacts. A multiaxial CT acquisition is achieved by combining multiple sequential 3 rd generation axial scans or by performing a single axial multisource CT scan with multiple longitudinally <b>offset</b> <b>sources.</b> Data from multiple axial scans or multiple sources provide complementary information. For full-scan acquisitions, we present a window-based 3 D analytic cone-beam reconstruction algorithm by tessellating data from neighboring axial datasets. We also show that multi-axial CT acquisition can extend the axial scan coverage while minimizing cone-beam artifacts. For half-scan acquisitions, one cannot take advantage of conjugate rays. We propose a cone-angle dependent weighting approach to combine multi-axial half-scan data. We compute the relative contribution from each axial dataset to each voxel based on the X-ray beam collimation, the respective cone-angles, and the spacing between the axial scans. We present numerical experiments {{to demonstrate that the}} proposed techniques successfully reduce cone-beam artifacts at very large volumetric coverage...|$|R
40|$|The analysis, design, and {{implementation}} of a two-step current-sampling switched-current (S 2 I) multiplier is presented. The S 2 I technique has been employed to compensate analog errors due to charge injection {{as well as those}} arising from the finite output impedance. A thorough circuit analysis investigating the <b>offset</b> <b>sources</b> of the S 2 I cell and of the multiplier's nonlinearities sets up the platform to effectively design the multiplier and to avoid the use of feedback, or cascode techniques, to deal with channel modulation effects. The multiplier has been implemented using a 2 -µm n-well MOSIS CMOS technology. Experimental results are in agreement with the theoretical findings. The following are brief highlights of the measurement results: (1) 0. 425 millions of multiplications per second; (2) 1. 7 % total harmonic distortion for a sinusoidal of 35 -µA (50 Hz); (3) 206 kHz of bandwidth; (4) 50 dB of SNR; and (5) 0. 3 -mW zero input power consumption for a ± 3 -V power supply. A complete set of detailed experimental results is provided in the pape...|$|R
40|$|Every mode of a {{single-mode}} or multimode helical fibre {{is always}} leaky but, for practical purposes, {{can be treated}} as being bound with an effective cut-off wavelength. The leakage loss for each mode is quantified, showing that, for fixed core <b>offset</b> and <b>source</b> wavelength, the cut-off pitch increases with increasing mode order. The value of the cut-off pitch for each mode is in agreement with experimental measurements. © 1990 Chapman and Hall Ltd...|$|R
40|$|In {{the past}} few years, there has been {{considerable}} research and interest in a topic known by various names, such as Time Reverse Acoustics (TRA), Time Reverse Mirrors (TRM), and Time Reverse Cavities (TRC), which exploits reciprocity and the time symmetric property of the wave equation. Very little of this work has been directed at the seismic exploration imaging problem. In fact, {{most of the work}} has had application in sonar, medical and non-destructive testing applications. Here we present some initial results of applying this technology to the seismic imaging of a salt dome flank. We create a set of synthetic traces representing a multi-level, walk away VSP for a model composed of a simplified Gulf of Mexico vertical velocity gradient and an embedded overhanging salt dome. To process these data, we first apply the concepts of TRA to the synthetic traces. This creates a set of stacked traces without having to perform any velocity analysis or complicated processing. Each of these stacked traces is equivalent to the output of a spatially coincident, or zero offset, down hole source and receiver pair. Thus we have the equivalent of a zero offset seismic section as if it were collected from down hole sources and receivers. After having applied the TRA concepts, we then apply conventional post stack depth migration to this zero offset section to produce the final image of the salt dome flank. Our results show a very good image of the salt. In fact, the image created is nearly identical to an image actually using data from down hole, zero <b>offset</b> <b>source</b> and receiver pairs. The simplicity of the TRA implementation provides a virtually automated method to create a stacked section {{as if it had been}} collected from the reference frame of the borehole containing the VSP survey. Massachusetts Institute of Technology. Earth Resources Laborator...|$|E
50|$|Line {{comments}} either {{start with}} a comment delimiter and continue {{until the end of}} the line, or in some cases, start at a specific column (character line <b>offset)</b> in the <b>source</b> code, and continue {{until the end of the}} line.|$|R
40|$|Background  In the UK, Early Intensive Behavioural Intervention [EIBI] {{programmes}} {{typically are}} conducted within {{the homes of}} children with autism. Despite evidence for their effectiveness in producing appreciable developmental gains in children with autism, a concern expressed about EIBI programmes is that stressful effects from {{the high levels of}} demand they place on family resources could undermine their effectiveness [The Effectiveness of Early Interventions for Children with Autistic Spectrum Disorders (ASD). A report for the DfES South East Regional Special Educational Needs Partnership. SERSEN Website, 2004]. This study investigates the positive impacts and the stressors experienced by families running EIBI programmes. Method  Sixteen parents from nine different families participated in semi-structured qualitative interviews on their experiences of running a home-based EIBI programme. Data were analysed using the Grounded Theory process. Results  Positive and negative impacts of the programmes were reported. Analysis indicated that sources of support obtained through the programmes’ benefits <b>offset</b> <b>sources</b> of stress through the programmes’ demands. Conclusions  The interaction between programme demands and benefits and the resources available to each family strongly influences the impact of running a home-based EIBI programme...|$|R
40|$|Abstract. Kaohsiung and Pintung are {{the first}} regions were set into action of total {{quantity}} control zones for air quality in Taiwan. Cap and trade programs have built for the particle matters (PM 10), sulfur oxides (SOx), nitrogen oxides (NOx) and Volatile Organic Compounds (VOCs) in 2010. The offset ratio was designed as 1. 0 or 1. 2 various on the <b>offset</b> <b>sources.</b> The fixed <b>offset</b> ratio setting is suitable for PM 10, SOx, and NOx since their characters are unitary. However, VOCs include a variety of chemicals, {{some of which may}} have short- or long-term adverse health effects. Even the same pollutant trading amount cannot guarantee the same health risk or environmental impacts. It would induced the highly uncertainty of air quality for the fixed offset ratio system. This study therefore tried to create a new methodology based on the pollutant impact strength of health and environment for determining the offset ratio of VOCs. An equation for calculating the offset ratio of VOCs was proposed and evaluated by case study. The elasticity of weighting determination was remained to the decision makers for confronting the various environmental improving targets...|$|R
40|$|Abstract A {{volcanic}} earthquake with Mw 5 : 6 occurred {{beneath the}} Bárdarbunga caldera in Iceland on 29 September 1996. This earthquake {{is one of}} a decade-long sequence ofM 5 events at Bárdarbunga with non-double-couple mechanisms in the Global Centroid Moment Tensor catalog. Fortunately, it was recorded well by the regional-scale Iceland Hotspot Project seismic experiment. We investigated the event with a complete moment tensor inversion method using regional long-period seismic waveforms and a composite structural model. The moment tensor inversion using data from stations of the Iceland Hotspot Project yields a non-double-couple solution with a 67 % vertically oriented compensated linear vector dipole component, a 32 % double-couple component, and a statistically insignificant (2 %) volumetric (isotropic) con-traction. This indicates the absence of a net volumetric component, which is puzzling {{in the case of a}} large volcanic earthquake that apparently is not explained by shear slip on a planar fault. A possible volcanic mechanism that can produce an earthquake without a volumetric component involves two <b>offset</b> <b>sources</b> with similar but opposite volume changes. We show that although such a model cannot be ruled out, the circumstances under which it could happen are rare...|$|R
40|$|Some {{argue that}} a “single tax principle,” said to {{underlie}} tax treaties, requires that cross-border income should generally be taxed once, rather than twice or not at all. Even if one accepts this principle, {{it is important to}} recognize the difference between “upside” departures, which occur when the same dollar of income is taxed more than once, and “downside” departures, which occur when it is not taxed at all. This article argues that a focus on barring upside departures from the single tax principle can be quite misguided. While over-taxing cross-border activity, relative to that occurring in one country, may be undesirable, this should not stand in the way of letting residence countries tax foreign source income at a reduced rate, in lieu of wholly <b>offsetting</b> <b>source</b> country taxes via foreign tax credits. As for barring downside departures from the single tax principle, such as by addressing stateless income, while this often is desirable from a given country’s unilateral national welfare standpoint (and is even more clearly worth pursuing multilaterally), the issues raised are more complicated than adherence to the single tax principle might appear to suggest...|$|R
5000|$|The {{register}} offset addressing mode is only {{available for the}} [...] instruction, where the Ww register {{may be used as}} a register <b>offset</b> for the <b>source,</b> destination, or both. All other instructions use this encoding for an unsigned 5-bit immediate source instead.|$|R
40|$|This paper {{shows that}} a country’s wealth drives its {{comparative}} advantage when sectors in the economy face differential access to credit. Wealthier nations exhibit a comparative advantage toward goods produced in sectors facing more severe financial imperfections, typically smaller firms. Empirically this paper documents that those sectors are also labor intensive. Consequently this theory partially <b>offsets</b> traditional <b>sources</b> of comparative advantage and offers an explanation for Trefler’s missing trade mystery and the Leontief paradox. Furthermore, the theory makes the relation between trade and income distribution endogenous. ...|$|R
40|$|This short paper, {{prepared}} for a symposium, “Reconsidering the Tax Treaty,” {{to be held at}} Brooklyn Law School on October 23, 2015, examines the “single tax principle,” arguably underlying bilateral tax treaties, in connection with evaluating the treaties’ future {{role in the development of}} international tax law and policy. It distinguishes between “upside” departures from the single tax principle, which occur when the same dollar of income is taxed more than once, and “downside” departures, which occur when it is not taxed at all. The paper argues that a focus on barring upside departures from the single tax principle can be quite misguided. While over-taxing cross-border activity, relative to that occurring in one country, may be undesirable, this should not stand in the way of letting residence countries tax foreign source income at a reduced rate, in lieu of wholly <b>offsetting</b> <b>source</b> country taxes via foreign tax credits. As for barring downside departures from the single tax principle, such as by addressing stateless income, while this often is desirable from a given country’s unilateral national welfare standpoint (and is even more clearly worth pursuing multilaterally), the issues raised are more complicated than adherence to the single tax principle might appear to suggest...|$|R
40|$|This article {{examines}} economic incentives and other mechanisms to <b>offset</b> non-point <b>source</b> pollution from agriculture. A biophysical simulator to estimate technical relationships {{is linked to}} linear programming models for representative farms in the Willamette Valley of Oregon. The models are then optimized for profit maximization under alternative non-point pollution control policies. The results indicate that site-specific resource conditions and production possibilities greatly influence policy effectiveness {{and the cost of}} achieving pollution abatement. Nevertheless, some abatement is possible on all farms for relatively little cost. Environmental Economics and Policy,...|$|R
50|$|Beyond {{increasing}} numerical aperture, {{there are}} few techniques available to improve optical sectioning in bright-field light microscopy. Most microscopes with oil immersion objectives are reaching the limits of numerical aperture possible due to refraction limits.Differential interference contrast (DIC) provides modest improvements to optical sectioning. In DIC the sample is effectively illuminated by two slightly <b>offset</b> light <b>sources</b> which then interfere to produce an image resulting from the phase differences of the two <b>sources.</b> As the <b>offset</b> in the light sources is small the only difference in phase results from the material close to the focal plane.|$|R
50|$|Any of {{the above}} gas vectors could comply with the terms of Schedule 4. In reality, the only gas {{transmission}} network in the UK connecting two or more power plants is the existing UK gas grid. Provided, therefore, that methane injected into the grid has had its anthropogenic carbon emissions <b>offset</b> at <b>source</b> {{by the use of}} either biogenic fuels, CCS or a combination of both, such methane will comply with the terms of The Energy Act, and generators burning such gas to produce low carbon electricity will be eligible for support by Contracts for Differences. DECC has confirmed that such a scheme is eligible for support by CfD.|$|R
40|$|The Goddard VLBI group {{reports the}} results of {{analyzing}} 1412 Mark II data sets acquired from fixed and mobile observing sites {{through the end of}} 1990 and available to the Crustal Dynamics Project. Three large solutions were used to obtain Earth rotation parameters, nutation <b>offsets,</b> global <b>source</b> positions, site velocities, and baseline evolution. Site positions are tabulated on a yearly basis from 1979 through 1992. Site velocities are presented in both geocentric Cartesian coordinates and topocentric coordinates. Baseline evolution is plotted for 175 baselines. Rates are computed for earth rotation and nutation parameters. Included are 104 sources, 88 fixed stations and mobile sites, and 688 baselines...|$|R
30|$|Mozafari et al. [29] {{proposed}} a framework called Heterogeneous Max-margin Classifier Adaptation (HMCA) which addresses heterogeneous and homogeneous domain adaptation problems. This method uses model-transferring for these DA tasks {{and is an}} extension from their previous work [30]. Model-transferring domain adaptation methods use a previously trained source classifier for adaptation purposes on a target domain. These methods require trained source classifiers and the target data during training thus the source training samples are not required for building the classifier in the target. This is because, in this case, the parameters from the source classifier {{are used in the}} adaptation process rather than the source samples. HMCA learns a max-margin classifier for the target domain, and adapts it according to the <b>source</b> classifier’s pre-learned <b>offset.</b> This adaption occurs through a modification in the target’s SVM objective function which minimizes the distance of the target’s <b>offset</b> from the <b>source’s</b> <b>offset.</b> To do this, the source classifier and the labeled target domain data are projected onto a one-dimensional space. This offset {{can be seen as the}} discrimination point which the classifier uses to separate and distinguish the two classes in the one-dimensional space. Thus, to utilize source knowledge and adapt the target classifier utilizing the source model, a linear SVM is found whose offset discriminates the target samples correctly in the one-dimensional space. This is done under the condition that it also must have the minimum distance to the <b>offset</b> of the <b>source</b> as to maximize the similarity between the domains.|$|R
40|$|The {{purpose of}} this {{research}} is to establish a recommended procedure for performing multichannel analysis of surface waves (MASW) on pavements as well as evaluating the ability of MASW to detect a change in shear wave velocity as damage in concrete increases. The tests for establishing a recommended procedure for performing MASW on pavements was conducted at five sites at the University of Arkansas Engineering Research Center in Fayetteville, Arkansas. The five sites consisted of three materials: asphalt, concrete, and soil (two sites were on asphalt, two were on concrete, and one was on soil). The methods evaluated at these sites include the source type, distance from the source to the first receiver in the array (i. e., <b>source</b> <b>offset),</b> the spacing between receivers in the array, and the minimum number of receivers in the array. It was determined that for the data collected on asphalt, the optimum procedure included a 230 g metal-tipped hammer, 2. 5 cm receiver spacing, a minimum of 24 receivers, and <b>source</b> <b>offsets</b> of 12. 5 cm, 25 cm, and 50 cm. For concrete, the optimum procedure included a 230 g metal-tipped hammer, 5 cm receiver spacing, a minimum of 18 receivers, and <b>source</b> <b>offsets</b> of 12. 5 cm, 25 cm, 50 cm, and 75 cm. For soil, the optimum procedure included a 230 g metal-tipped hammer, 5 cm receiver spacing, a minimum of 12 receivers, and <b>source</b> <b>offsets</b> of 12. 5 cm, 25 cm, and 50 cm. Additionally, it was determined from a limited data set of six tests, that MASW has the ability to detect a decrease in shear wave velocity as damage increases up to a strain level of at least 0. 09 %. However, MASW testing done on concrete with expansions of 0. 09 % and 0. 29 % showed only a 2 % difference in shear wave velocity between the two large strain sections. Given the data collected it cannot be determined if MASW can be used to differentiate between concrete sections with strains larger than 0. 09 % (i. e., sections with heavy damage) ...|$|R
30|$|There are two {{possible}} approaches to angle-gather construction with wavefield continuation. In the first approach, one generates gathers at each depth level converting offset-space-frequency planes into angle-space planes simultaneously with applying the imaging condition. The offset {{in this case}} refers to the local <b>offset</b> between <b>source</b> and receiver parts of the downward continued prestack data. Such a construction was suggested, for example, by Prucha et al. (1999). This approach is attractive because of its localization in depth. However, the method of Prucha et al. (1999) produces gathers in the offset ray parameter as opposed to angle. As a result, the angle-domain information becomes structure-dependent: the output depends {{not only on the}} scattering angle but also on the structural dip.|$|R
30|$|To {{study the}} {{severity}} of the above effects on the shape of the PSF, a simulation study was performed on the cone beam (50  cm) collimator. The collimator configuration was modeled in GATE [15] with one point source positioned {{at the center of the}} collimator and one at the edge of the collimator (with a spatial shift of 10  cm), both at a distance of 25  cm from the gamma camera (see Fig.  3). This is a region in which the greatest deviation between PSFs is expected, because the <b>offset</b> point <b>source</b> is detected close to the edge of the gamma camera. The differences in magnitude and shape of the retrieved PSFs were measured for comparison.|$|R
40|$|Microphone arrays {{can be used}} to {{localize}} and estimate the strengths of acoustic sources present in a region of interest. However, the array measurement of a region, or beam map, is not an accurate representation of the acoustic field in that region. The true acoustic field is convolved with the array s sampling response, or point spread function (PSF). Many techniques exist to remove the PSF's effect on the beam map via deconvolution. Currently these methods use a theoretical estimate of the array point spread function and perhaps account for installation offsets via determination of the microphone locations. This methodology fails to account for any reflections or scattering in the measurement setup and still requires both microphone magnitude and phase calibration, as well as a separate shear layer correction in an open-jet facility. The research presented seeks to investigate direct measurement of the array's PSF using a non-intrusive acoustic point source generated by a pulsed laser system. Experimental PSFs of the array are computed for different conditions to evaluate features such as shift-invariance, shear layers and model presence. Results show that experimental measurements trend with theory with regard to <b>source</b> <b>offset.</b> The <b>source</b> shows expected behavior due to shear layer refraction when observed in a flow, and application of a measured PSF to NACA 0012 aeroacoustic trailing-edge noise data shows a promising alternative to a classic shear layer correction method...|$|R
40|$|Seismic images {{obtained}} by multicomponent wave-equation migration can be decomposed into angle-gathers with a transformation that generalizes the equivalent construction for primary waves. A par-ticularly simple formulation {{is to use}} all three components of the <b>offset</b> vector separating <b>sources</b> and receivers at image points. Using full vector offsets, multicomponent angle-gathers are built using simple transformations that are implemented partially in the Fourier domain and partially in the space domain. ...|$|R
40|$|We {{propose a}} method to correct for {{spectral}} pointing-induced throughput error (SPITE) when the observer has an accurate estimate of the expected spectrum from a source. By comparing {{the shape of a}} spectrum observed to that expected, one can estimate the <b>offset</b> of a <b>source</b> and correct for the resulting SPITE. The spectral data are weighted to maximize the sensitivity of the method for determining the offset. This method will be most useful for observations of standard stars. ...|$|R
40|$|We have {{quantified}} {{the errors}} associated with VTI parameter estimation using multi-offset VSP data. Two common methods, P-wave slownesses only and slowness-polarization are investigated. Estimation errors {{are expressed in}} terms of the magnitude of the earth anisotropy, uncertainties related to first break pickings and maximum available <b>source</b> <b>offset.</b> For homogeneous overburden, P-wave slownesses technique can be used to estimate VTI parameters. We demonstrate that estimation errors of using only P-wave slownesses are significantly decreased as longer <b>source</b> <b>offsets</b> are included in the inversion algorithm. Larger offsets involve P-waves which propagate near horizontal at the receiver level and enhance the method's efficiency. An example synthetic VSP is presented next where P-wave slownesses technique successfully recovers VTI model parameters. In case of heterogeneous overburden, P-wave slowness-polarization technique seems to be a solution as {{there is no need to}} compute P-wave horizontal slownesses. However, we demonstrate that the errors of VTI parameter estimation using this technique are small only where the anisotropy is very weak (below 5 %) and they are not improved by increasing the offset. Furthermore, wave interference effect on polarizations makes the method impractical even on noise free synthetic data...|$|R
50|$|The {{approach}} can be further expanded to model the response of a 3D geological model. This is used to reduce the uncertainty in interpretation by modelling {{the response of the}} 3D model to a synthetic seismic acquisition that matches as closely as possible to that actually used in acquiring the data that has been interpreted. The synthetic seismic data is then processed using the same sequence as that used for the original data. This method can be used to model both 2D and 3D seismic data that has been acquired over the area of the geological model. During the planning of a seismic survey, 3D modelling can be used to test the effect of variation in seismic acquisition parameters, such as the shooting direction or the maximum <b>offset</b> between <b>source</b> and receiver, on the imaging of a particular geological structure.|$|R
40|$|The {{multiple}} {{images of}} lensed quasars provide {{evidence on the}} mass distribution of the lensing galaxy. The lensing invariants are constructed from {{the positions of the}} images, their parities and their fluxes. They depend only on the structure of the lensing potential. The simplest is the magnification invariant, which is the sum of the signed magnifications of the images. Higher order configuration invariants are the sums of products of the signed magnifications with positive or negative powers of the position coordinates of the images. We consider the case of the four and five image systems produced by elliptical power-law galaxies with ψ ∝ (x 2 +y 2 q − 2) β/ 2. This paper provides simple contour integrals for evaluating all their lensing invariants. For practical evaluation, this offers considerable advantages over the algebraic methods used previously. The magnification invariant is exactly B = 2 /(2 − β) for the special cases β = 0, 1 and 4 / 3; for other values of β, this remains an approximation, but an excellent one at small <b>source</b> <b>offset.</b> Similarly, the sums of the first and second powers of the image positions (or their reciprocals), when weighted with the signed magnifications, are just proportional to the same powers of the <b>source</b> <b>offset,</b> with a constant of proportionality B. To illustrate the power of the contour integral method, we calculate full expansions in the <b>source</b> <b>offset</b> for all lensing invariants in the presence of arbitrary external shear. As an example, we use the elliptical power-law galaxies to fit to the data on the four images of the Einstein Cross (G 2237 + 030). The lensing invariants play a role by reducing the dimensionality of the parameter space in which the χ 2 minimisation proceeds with consequent gains in accuracy and speed. Subject headings: gravitational lensing – galaxies: structure – quasars individual: G 2237 + 030 – 2 – 1...|$|R
40|$|Full-band Monte-Carlo {{simulations}} of short channel double-gate SOI nMOSFETs {{were used to}} assess possible enhancement of drain current in devices featuring a conduction band <b>offset</b> between the <b>source</b> and the channel as those obtained using non-conventional source/drain materials. We found that the coupling between carrier transport and device electrostatics tends to balance the enhancement of charge injection provided by the band discontinuity, so that the largest contribution to the current enhancement given by alternative S/D materials is due to the strain that they induce in the channel...|$|R
