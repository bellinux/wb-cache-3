388|59|Public
25|$|Some CPU designs {{can perform}} some {{optimizations}} at runtime. Some examples include <b>Out-of-order</b> <b>execution,</b> Speculative execution, Instruction pipelines, and Branch predictors. Compilers {{can help the}} program {{take advantage of these}} CPU features, for example through instruction scheduling.|$|E
25|$|Another {{source of}} {{improved}} performance is in microarchitecture techniques exploiting {{the growth of}} available transistor count. <b>Out-of-order</b> <b>execution</b> and on-chip caching and prefetching reduce the memory latency bottleneck {{at the expense of}} using more transistors and increasing the processor complexity. These increases are described empirically by Pollack's Rule, which states that performance increases due to microarchitecture techniques are square root of the number of transistors or the area of a processor.|$|E
25|$|Since its introduction, {{the model}} has been further {{extended}} to account for a broader set of metrics and hardware-related bottlenecks. Already available in literature there are extensions that {{take into account the}} impact of NUMA organization of memory, of <b>out-of-order</b> <b>execution,</b> of memory latencies, and to model at a finer grain the cache hierarchy in order to better understand what is actually limiting performance and drive the optimization process.|$|E
5000|$|Pipelined {{processor}} with an <b>out-of-order</b> superscalar <b>execution</b> pipeline ...|$|R
50|$|A {{re-order}} buffer (ROB) {{is used in}} a Tomasulo algorithm for <b>out-of-order</b> instruction <b>execution.</b> It allows {{instructions to}} be committed in-order.|$|R
30|$|We use the Alpha EV 6 as {{our base}} {{processor}} (Kessler 1999) with a 3  GHz clock frequency. The Alpha EV 6 is an <b>out-of-order</b> speculative <b>execution</b> core that {{is commonly used}} as a test-bench core in thermal management research.|$|R
25|$|Although {{this process}} might sound slow, {{it is very}} cache-local and highly {{parallelizable}} {{due to the lack}} of register dependencies and therefore in fact has excellent performance on modern <b>out-of-order</b> <b>execution</b> CPUs. A red-black tree for example performs much better on paper, but is highly cache-unfriendly and causes multiple pipeline and TLB stalls on modern CPUs which makes that algorithm bound by memory latency rather than CPU speed. In comparison, a bitwise trie rarely accesses memory, and when it does, it does so only to read, thus avoiding SMP cache coherency overhead. Hence, it is increasingly becoming the algorithm of choice for code that performs many rapid insertions and deletions, such as memory allocators (e.g., recent versions of the famous Doug Lea's allocator (dlmalloc) and its descendents).|$|E
25|$|The {{first few}} {{generations of the}} Alpha chips {{were some of the}} most {{innovative}} of their time. The first version, the Alpha 21064 or EV4, was the first CMOS microprocessor whose operating frequency rivalled higher-powered ECL minicomputers and mainframes. The second, 21164 or EV5, was the first microprocessor to place a large secondary cache on chip. The third, 21264 or EV6, was the first microprocessor to combine both high operating frequency and the more complicated <b>out-of-order</b> <b>execution</b> microarchitecture. The 21364 or EV7 was the first high performance processor to have an on-chip memory controller. The unproduced 21464 or EV8 would have been the first to include simultaneous multithreading, but this version was canceled after the sale of DEC to Compaq. The Tarantula research project, which most likely would have been called EV9, would have been the first Alpha processor to feature a vector unit.|$|E
500|$|Most modern {{processors}} {{also have}} multiple execution units. They usually combine this feature with pipelining {{and thus can}} issue more than one instruction per clock cycle (...) [...] These processors are known as superscalar processors. Instructions can be grouped together only {{if there is no}} data dependency between them. Scoreboarding and the Tomasulo algorithm (which is similar to scoreboarding but makes use of register renaming) are two of the most common techniques for implementing <b>out-of-order</b> <b>execution</b> and instruction-level parallelism.|$|E
5000|$|Fully <b>out-of-order</b> memory <b>execution</b> and disambiguation. The Goldmont {{microarchitecture}} can execute one {{load and}} one store per cycle (compared to one load or one store per cycle in the Silvermont microarchitecture). The memory execution pipeline {{also includes a}} second level TLB enhancement with 512 entries for 4KB pages.|$|R
40|$|Many {{large-scale}} discrete event simulation computations for modeling telecommunication networks, computer systems, transportation grids, and {{a variety}} of other applications are excessively time consuming, and are a natural candidate for parallel execution. However, discrete event simulations are challenging to parallelize because cause-and-effect relationships determine dependencies between simulation computations and are difficult or impossible to predict prior to execution. This makes synchronization a non-trivial issue. Time Warp is a well-known synchronization protocol that detects <b>out-of-order</b> <b>executions</b> of computations as they occur, and recovers using a rollback mechanism. This article discusses important issues concerning the design of a Time Warp-based parallel simulation executive for shared-memory multiprocessors. It is observed that interactions between memory management mechanisms and buffer management techniques can have a dramatic effect on the performance of message-pas [...] ...|$|R
5000|$|Generally, clock {{frequency}} is favored over increasing instructions per cycle. Complex {{features such as}} <b>out-of-order</b> instruction <b>execution</b> are deliberately not implemented, because they impact the ability to increase the clock rate, {{require a lot of}} extra die space and power, and have little impact on performance in several common application scenarios.|$|R
5000|$|Larger <b>out-of-order</b> <b>execution</b> {{window and}} buffers that enable deeper <b>out-of-order</b> <b>execution</b> across integer, FP/SIMD, and memory {{instruction}} types.|$|E
50|$|The P6 {{microarchitecture}} was {{the first}} microarchitecture by Intel to implement both <b>out-of-order</b> <b>execution</b> and register renaming. The P6 microarchitecture was used in Pentium Pro, Pentium II, Pentium III, Pentium M, Core, and Core 2 microprocessors. The Cyrix M1, released on October 2, 1995, {{was the first}} x86 processor to use register renaming and <b>out-of-order</b> <b>execution.</b> Other x86 processors (such as NexGen Nx686 and AMD K5) released in 1996 also featured register renaming and <b>out-of-order</b> <b>execution</b> of RISC μ-operations (rather than native x86 instructions).|$|E
50|$|About {{three years}} later, the IBM System/360 Model 91 (1966) {{introduced}} Tomasulo's algorithm, which made full <b>out-of-order</b> <b>execution</b> possible. In 1990, IBM introduced the first out-of-order microprocessor, the POWER1, although <b>out-of-order</b> <b>execution</b> {{was limited to}} floating-point instructions (as was also the case on the Model 91).|$|E
40|$|International audienceWe {{consider}} the verified compilation of high-level managed languages like Java or C# whose intermediate representations {{provide support for}} shared-memory synchronization and automatic memory management. Our development is framed {{in the context of}} the Total Store Order relaxed memory model. Ensuring com-plier correctness is challenging because high-level actions are translated into sequences of non-atomic ac-tions with compiler-injected snippets of racy code; the behavior of this code depends not only on the actions of other threads, but also on <b>out-of-order</b> <b>executions</b> performed by the processor. A naïve proof of correctness would require reasoning over all possible thread interleavings. In this paper we propose a refinement-based proof methodology that precisely relates concurrent code expressed at different abstraction levels, cognizant throughout of the relaxed memory semantics of the underlying processor. Our technique allows the compiler writer to reason compositionally about the atomicity of low-level concurrent code used to implement man-aged services. We illustrate our approach with examples taken from the verification of a concurrent garbage collector...|$|R
40|$|We {{propose a}} method to {{precisely}} model implementations of Instruction Set Architectures (ISA) using term rewriting systems (TRS). Our method facilitates understanding of important micro-architectural differences without delving into low-level implementation details. More importantly, the use of TRS allows us to prove rigorously the equivalence of different implementations. We first define AX, a simple RISC ISA, by specifying its operational semantics using a simple in-order execution model. We then give an AX implementation which uses register renaming and permits <b>out-of-order</b> instruction <b>execution.</b> The equivalence of the two models is proved by showing that the two TRS's can simulate each other. 1 Introduction Modern microprocessors embody increasingly complex micro-architectures to achieve high performance. Optimization techniques such as <b>out-of-order</b> and speculative <b>execution,</b> write buffers and split-phase bus transactions, can make the semantics of certain instructions difficult [...] ...|$|R
5000|$|Improved front-end, deeper <b>out-of-order</b> buffers, {{improved}} <b>execution</b> units, more execution units (third vector integer ALU(VALU)) {{for five}} ALUs in total, more load/store bandwidth, improved hyper-threading (wider retirement), speedup of AES-GCM and AES-CBC by 17% and 33% accordingly.|$|R
50|$|<b>Out-of-order</b> <b>execution</b> where {{instructions}} execute in any {{order that}} does not violate data dependencies. Note that this technique is independent of both pipelining and superscalar. Current implementations of <b>out-of-order</b> <b>execution</b> dynamically (i.e., while the program is executing and without any help from the compiler) extract ILP from ordinary programs. An alternative is to extract this parallelism at compile time and somehow convey this information to the hardware. Due {{to the complexity of}} scaling the <b>out-of-order</b> <b>execution</b> technique, the industry has re-examined instruction sets which explicitly encode multiple independent operations per instruction.|$|E
5000|$|... four-way superscalar, <b>out-of-order</b> <b>execution,</b> 64-bit MIPS {{architecture}} {{processor core}} ...|$|E
5000|$|... #Subtitle level 2: <b>Out-of-order</b> <b>execution</b> versus {{compiler}} reordering optimizations ...|$|E
50|$|By {{using the}} memory {{dependence}} predictor to keep most dependent loads and stores in order, the processor gains {{the benefits of}} aggressive <b>out-of-order</b> load/store <b>execution</b> but avoids many of the memory dependence violations that occur when loads and stores were incorrectly executed. This increases performance because it reduces the number of pipeline flushes that are required to recover from these memory dependence violations. See the memory disambiguation article {{for more information on}} memory dependencies, memory dependence violations, and recovery.|$|R
50|$|Processors {{that fully}} support <b>out-of-order</b> load/store <b>execution</b> can use an additional, related technique, called memory {{dependence}} prediction, {{to attempt to}} predict true dependences between loads and stores before their addresses are known. Using this technique, the processor can prevent loads that are predicted {{to be dependent on}} an in-flight store from executing before that store completes, avoiding a RAW dependence violation and thus avoiding the pipeline flush and the performance penalty that is incurred. See the memory dependence prediction article for more details.|$|R
5000|$|The IBM System/360 Model 91 was {{announced}} in 1964 as a competitor to the CDC 6600. [...] Functionally, the Model 91 ran like any other large-scale System/360, but the internal organization was the most advanced of the System/360 line, {{and it was the}} first IBM computer to support <b>out-of-order</b> instruction <b>execution.</b> It ran OS/360 as its operating system. It was designed to handle high-speed data processing for scientific applications. This included space exploration, theoretical astronomy, sub-atomic physics and global weather forecasting.|$|R
5000|$|... #Subtitle level 3: <b>Out-of-order</b> <b>execution</b> {{and memory}} access {{operations}} ...|$|E
5000|$|An <b>out-of-order</b> <b>execution</b> engine with a 3-wide superscalar pipeline. Specifically: ...|$|E
5000|$|<b>Out-of-order</b> <b>execution</b> and Speculative execution, up to 4 CPU cores ...|$|E
30|$|For workloads, we {{simulated}} the SPEC 2000 benchmark (13 floating {{points and}} 12 integer benchmarks) suite (Henning 2000), using Simple Scalar (Burger & Austin 1997) 3.0 e. The Simple Scalar simulates a superscalar processor with <b>out-of-order</b> issue and <b>execution.</b> For each application, we simulated 10 million instructions.|$|R
40|$|In this work, {{we present}} {{a survey of the}} {{different}} task scheduling parallel programming models in order to support <b>Out-of-Order</b> (OoO) <b>execution</b> for high performance computing in an Multiprocessor System on Chip (MPSoC) environment. Thus, we review different parallel programming approaches, as well as current heterogeneous parallel programming models. In addition, we analyze different OoO execution architectures to solve the data dependency issues. The characteristics, strengths, and weaknesses are presented in all the cases. The study shows that the availability of multi-core CPUs has given new impulse to the OoO programming approach...|$|R
50|$|The {{instruction}} window has {{a finite}} size, and new instructions {{can enter the}} window (usually called dispatch or allocate) only when other instructions leave the window (usually called retire or commit). Instructions enter and leave the instruction window in program order, and an instruction can only leave the window when it is the oldest instruction in the window {{and it has been}} completed. Hence, the instruction window {{can be seen as a}} sliding window in which the instructions can become <b>out-of-order.</b> All <b>execution</b> within the window is speculative (i.e., side-effects are not applied outside the CPU) until it is committed.|$|R
5000|$|In {{the case}} of <b>out-of-order</b> <b>execution,</b> the {{algorithm}} used can be: ...|$|E
5000|$|... use <b>out-of-order</b> <b>execution</b> to {{potentially}} prevent {{the need for}} pipeline bubbles ...|$|E
5000|$|Superscalar <b>Out-of-order</b> <b>execution</b> Power Architecture core, {{specially}} modified for the Wii platform ...|$|E
50|$|The {{company is}} not well known {{to the general public}} as none of its designs were ever {{manufactured}} in volume. The company is known within the computer architecture community as it published articles in technical journals in the early 1990s that described how an <b>out-of-order</b> with speculative <b>execution</b> CPU might be designed. This {{was one of the first}} publicly disclosed OoO designs from a non-academic source.|$|R
40|$|Most {{microprocessor}} chips today use an <b>out-of-order</b> instruction <b>execution</b> mechanism. This mechanism allows superscalar processors {{to extract}} reasonably {{high levels of}} instruction level parallelism (ILP). The most significant problem with this approach is a large instruction window and the logic to support instruction issue from it. This includes generating wake-up signals to waiting instructions and a selection mechanism for issuing them. Wide-issue width also requires a large multi-ported register file, so that each instruction can read and write its operands simultaneously. Neither structure scales well with issue width leading to poor performance relative to the gates used. Furthermore, to obtain this ILP, the execution of instructions must proceed speculatively. An alternative, which avoids this complexit...|$|R
40|$|Pipelining is an {{important}} technique in high-level synthesis, which overlaps the execution of successive loop iterations or threads to achieve high throughput for loop/function kernels. Since existing pipelining techniques typically enforce in-order thread execution, a variable-latency operation in one thread would block all subsequent threads, resulting in considerable performance degradation. In this paper, we propose a multithreaded pipelining approach that enables context switching to allow <b>out-of-order</b> thread <b>execution</b> for data-parallel kernels. To ensure that the synthesized pipeline is complex-ity effective, we further propose efficient scheduling algorithms for minimizing the hardware overhead associated with context man-agement. Experimental results show that our proposed techniques can significantly improve the effective pipeline throughput over conventional approaches while conserving hardware resources. 1...|$|R
