10|55|Public
50|$|During {{emergency}} response {{the situation and}} hazards are often inherently less predictable than for planned activities. In general, if the situation and hazards are predictable, standard operating procedures should deal with them adequately, and in some emergencies this holds true and the prepared and trained responses are adequate to manage the situation. These situations are usually those that the operator can deal with without outside assistance, or {{with the assistance of}} a backup team who are prepared and available to step in at short notice. Other emergencies occur where there is no previously planned protocol, or when an outsider group is brought in to handle the situation, and they are not specifically prepared for the scenario that exists, but must deal with it without undue delay. Examples include police, fire department, disaster response and other public service rescue teams. In these cases ongoing risk assessment by the involved personnel can advise appropriate action to reduce risk. HM Fire Services Inspectorate has defined dynamic risk assessment (DRA) as: The continuous assessment of risk in the rapidly changing circumstances of an <b>operational</b> <b>incident,</b> in order to implement the control measures necessary to ensure an acceptable level of safety.|$|E
40|$|Analysing the Australian Defence Organisation’s {{information}} disclosure {{policy with}} regard to an <b>operational</b> <b>incident</b> {{that took place in}} Afghanistan nearly two years ago, this article argues that a particularly toxic combination of deliberate opaqueness, stalled process, and capacity constraints have served to create a roadblock to defence transparency and public accountability. Introduction In a bureaucracy as large as the Australian Defence Organisation (ADO) attributing the cause of policy failure is a difficult task. I’ve previously highlighted societal and parliamentary factors that hamper transparency and the scrutiny of defence policy in Australia. This commentary will more deeply consider bureaucratic, legal, and cultural traits within the ADO that militate against the organisation’s own stated policy of a “pro-disclosure” culture, as well as Defence’s legislated requirement to be open and accountable to the Australian public. Analysing the ADO’s information disclosure policy {{with regard to}} an <b>operational</b> <b>incident</b> that took place in Afghanistan nearly two years ago, shows that a particularly toxic combination of deliberate opaqueness, stalled process, and capacity constraints have served to create a roadblock to defence transparency and public accountability. The case study examined is one in which Australian soldiers were originally accused of having committed war crimes: a grisly incident where Special Forces personnel decided to sever the hands of dead Afghans for tactical reasons. To be sure it is not an incident of which Defence is particularly proud, but as will be argued the ADO’s policy response contravenes its own stated policy, weakens the public reputation of the Australian Defence Force, does not serve the ADF members involved well, and undermines the important need within a parliamentary democracy for military forces to be both transparent and accountable. Of course, there are many pressures on the defence establishment at the moment, and providing information to the general public about a sensitive <b>operational</b> <b>incident</b> might seem an annoyance. But the true test of an organisation’s character is best measured at such pressure points. This incident suggests a serious need for renewed efforts to ensure the ADO complies with its need to be transparent...|$|E
40|$|During {{the fourth}} quarter of 1974, the Shippingport Atomic Power Station was {{shutdown}} for PWR/LWBR (Pressurized Water Reactor/Light Water Breeder Reactor) Core Conversion. On December 26 while performing a cooldown, following a heat-up test, on <b>operational</b> <b>incident</b> occurred during which the cooldown rate exceeded the 10 $sup 0 $F/hour allowable limit. A cooldown rate of 13 $sup 0 $F to 14 $sup 0 $F/ hour was experienced for a two hour period. After an evaluation of this incident, it was concluded that no deleterious effects to the primary coolant system occurred. Defueling operations continued during {{the fourth quarter}}. (auth...|$|E
5000|$|VII. Success in organising {{ambulance}} services under special difficulties, for example, managing major, serious or dangerous <b>operational</b> <b>incidents,</b> which make exceptional demands on personnel; ...|$|R
25|$|CFOs do attend some <b>operational</b> <b>incidents.</b> Hertfordshire's CFO, Roy Wilsher, took command at the Buncefield oil depot fire in 2005, forming part of {{the gold}} command team. If a CFO attends an incident, he will usually be the {{commanding}} officer of that incident.|$|R
50|$|CAOs are the {{operational}} and administrative {{heads of the}} Ambulance Service and take command of all ambulance personnel at large <b>operational</b> <b>incidents.</b> They also set policy and targets (along with a board of directors) and {{are responsible for the}} day-to-day running of the Service.|$|R
40|$|Abstract: Human error {{identification}} {{systems have}} been criticised for failing to consider the problems of <b>operational</b> <b>incident</b> investigators and system developers. Increasingly esoteric human error modelling and classification approaches have often been met with resistance from the potential user groups that could apply them with the greatest impact. In order to improve the transfer of this technology, error classification techniques must balance a range of criteria- some more practical than have previously been considered. This paper {{provides an example of}} one such technique in air traffic management (ATM) - ‘TRACEr lite ’- that has been developed with practical aims in mind, while retaining its conceptual roots...|$|E
40|$|In {{order to}} improve the {{operational}} surveillance of a VVER- 1000 unit of the Ukrainian nuclear power plant Zaporosh´ye a technical monitoring system has been specified. The system will enable the state regulatory and supervisory bodies to survey the unit operation independently of operators to assess its safety status, and to impose appropriate conditions. Due to its up-to-date configuration the system provides early indication of any <b>operational</b> <b>incident</b> and emission of radioactive materials connected. Based on the system an immediate warning in mergency situations is possible {{as well as an}} effective emergency management. For this purpose 49 different operational parameters of the unit, 18 radiological parameters of the unit and the plant site and 6 meteorological parameters are monitored. The monitoring concept and its technical realization are described...|$|E
40|$|We {{develop a}} dynamic multi-agent model of an interbank payment system where banks choose {{their level of}} {{available}} funds {{on the basis of}} private payoff maximisation. The model consists of the repetition of a simultaneous move stage game with incomplete information, incomplete monitoring, and stochastic payoffs. Adaptation takes place with bayesian updating, with banks maximizing immediate payoffs. We carry out numerical simulations to solve the model and investigate two special scenarios: an <b>operational</b> <b>incident</b> and exogenous throughput guidelines for payment submission. We find that the demand for intraday credit is an S-shaped function of the cost ratio between intraday credit costs and the costs associated with delaying payments. We also find that the demand for liquidity is increased both under operational incidents and in the presence of effective throughput guidelines...|$|E
5|$|Other <b>operational</b> <b>incidents</b> of note {{include a}} 1988 fire during a return voyage from Iceland to the United States which forced {{the ship to}} stop in Newfoundland for repairs, and a crane {{breakdown}} on 15 November 1991 during cargo operations that required repairs be made in Praia da Vitória, Azores.|$|R
40|$|Decision making at <b>operational</b> <b>incidents</b> {{involving}} the UK Fire and Rescue Service was 12 investigated using first-person video footage. This footage was independently coded and used 13 to guide recollection by participants. The resulting analysis revealed marked departures in the 14 {{decision making process}} from the normative models that have informed operational guidance...|$|R
5000|$|Unplanned <b>operational</b> {{critical}} <b>incidents,</b> such as situations involving armed offenders including sieges and hostage situations ...|$|R
40|$|The Australian rail {{industry}} is expanding exponentially {{and is therefore}} facing significant risk due {{to the introduction of}} new technologies. Bringing new systems into network control rooms for various industries has been universally problematic and has heightened concerns of negative safety impacts on operations. A review of the literature revealed that new technology adoption is now the normal process of business operations. In many cases they are adopted when existing technologies fail to adequately support changing operations. Disconnect often results from aging technologies,changed work demands, organisational and/or external pressures. Although offering improvements, new technologies bring uncertainty and may contain hidden technological flaws that can go undetected until a subsequent <b>operational</b> <b>incident</b> occurs. This review highlights the need for the rail industry to proactively safeguard against the risks of new technologies. Although diverse perspectives from various disciplines exist, these need to be brought together to enable a holistic approach to new technology analysis. Therefore, further research is required to identify the human factors issues that impact successful adoption of new technology to facilitate suitable selection, implementation and use within the rail industry...|$|E
40|$|The {{application}} of mapping and spatial analytical techniques to explore geographical patterns of crime incidence is well established. In contrast, {{the analysis of}} <b>operational</b> <b>incident</b> data routinely collected by fire brigades has received relatively less research attention, certainly in the UK academic literature. The aim {{of this paper is}} to redress this balance through the {{application of}} spatial analyt- ical techniques that permit an exploration of the spatial dynamics of fire incidents and their relation- ships with socio-economic variables. By examining patterns for different fire incident types, including household fires, vehicle fires, secondary fires and malicious false alarms in relation to 2001 Census of Population data for an area of South Wales, we demonstrate the potential of such techniques to reveal spatial patterns that may be worthy of further contextual study. Further research is needed to establish how transferable these findings are to other geographical settings and how replicable the findings are at different geographical scales. The paper concludes by drawing attention to the cur- rent gaps in knowledge in analysing trends in fire incidence and proposes an agenda to advance such research using spatial analytical techniques...|$|E
40|$|The {{objective}} {{of this paper is}} to quantify the contagion effect of an <b>operational</b> <b>incident</b> occurring at one ARTIS participant’s site on the payment activity of the other ARTIS participants. We used model simulations to focus on operational problems occurring at one of the participants, not an operational failure of the ARTIS platform itself. The scenarios are designed according to an ex-ante estimation of potential risk concentrations based on actual data for the sample period (Schmitz et al., 2006). The main conclusion from the simulations was that the contagion effect in ARTIS is low on condition that the existing business continuity arrangements prove effective. However, this is a very restrictive assumption. Without the use of business continuity arrangements or if they turn out to be not fully effective, the contagion effect on the smooth functioning of the payment system was substantial in all three scenarios. In contrast to the most common approach described in the literature, we used actual (instead of simulated) liquidity data to study the contagion effect at the individual bank level as well as at the aggregate level of unsettled payments. A non-negligible number of banks failed to settle payments in all three scenarios. The paper also provides results on two features of large-value payment systems that have hitherto gone unstudied in the literature: the stop-sending rule and debit authorization. Payment Systems, Operational Risk, Financial Stability...|$|E
50|$|It is a {{difficult}} role to perform as the firefighter regards them as management, and so has an element of distrust, and the senior management treats them with disdain as the lowest of all the ranks. Depending on the fire service qualifications that an individual crew manager/commander has obtained reflects in the disregard that many senior officers have for them, especially at <b>operational</b> <b>incidents,</b> where their knowledge, help and experience is often ignored.|$|R
50|$|The Crime Operational Support unit {{also moved}} to SOCA, and {{provides}} specialist operational skills and {{to assist in}} the resolution of exceptional crime series and <b>operational</b> critical <b>incidents.</b>|$|R
50|$|The {{mission of}} the WMD-CST is to support civil {{authorities}} {{at the direction of}} the Governor, at domestic CBRN incident sites by identifying CBRN agents/substances, assessing current and projected consequences, advising on response measures, and assisting with requests for additional support. In the National Defense Authorization Act (NDAA), Fiscal Year (FY) 2007, Congress expanded the <b>operational</b> <b>incidents</b> a WMD-CST could be used to include the intentional or unintentional release of CBRN and natural or man-made disasters in the United States that result, or could result, in the catastrophic loss of life or property.|$|R
40|$|In this paper, {{we report}} on the main {{building}} blocks of an ongoing project to develop a computational agent-based simulator for a generic real-time large-value interbank payment system with a central processor that can implement different rules for payment settlement. The main types of payment system in their polar forms are Real Time Gross Settlement (RTGS) and Deferred Net Settlement (DNS). DNS generates large quantities of settlement risk; in contrast, the elimination of settlement risk in RTGS comes with excessive demands for liquidity on banks. This could lead them to adopt various delaying tactics to minimise liquidity needs with free-riding and other ‘bad’ equilibria as potential outcomes. The introduction of hybrid systems with real-time netting is viewed as a means by which liquidity costs can be reduced while settlement risk is unchanged. Proposed reforms for settlement rules make it imperative to have a methodology to assess the efficiency of the different variants along three dimensions: the cost of liquidity to the individual banks and the system as a whole, settlement risk at both bank and system levels, and how early in the day payments are processed, since this proxies the impact of an <b>operational</b> <b>incident.</b> In this paper, we build a simulator for interbank payments capable of handling real time payment records along with autonomous bank behaviour and show that {{it can be used to}} evaluate different payment system designs against these three criteri...|$|E
5000|$|The Upholder/Victoria-class submarines, {{also known}} as the Type 2400 (due to their {{displacement}} of 2,400 tonnes), are diesel-electric fleet submarines designed in the UK in the late 1970s to supplement the Royal Navys nuclear submarine force. They were decommissioned {{with the end of the}} Cold War after a short length of service in the Royal Navy. In 1998, Canada purchased the submarines and a suite of trainers from the Royal Navy to replace the decommissioned [...] of submarines. In Canadian service they have been beset with problems and <b>operational</b> <b>incidents</b> that have limited their active service.|$|R
40|$|Banking-financial {{institutions}} are organizations {{which might be}} included in the category of complex systems. Consequently, they can be applied after adaptation and particularization, in the general description and assessment methods of the technical or organizational systems. The banking-financial system faces constrains regarding the functioning continuity. Interruptions in continuity as well as <b>operational</b> <b>incidents</b> represent risks which can lead to the interruption of financial flows generation and obviously of profit. Banking incidents include from false banknote, cloned cards, informatics attacks, false identity cards to ATM attacks. The functioning of banking institutions in an incident-free environment generates concern from both risk assessment and forecasting points of view. ...|$|R
50|$|The National Interagency Incident Management System was developed; {{along with}} its <b>operational</b> organization, the <b>Incident</b> Command System.|$|R
40|$|We lay out and {{simulate}} a multi-agent, multi-period model of an RTGS payment system. At {{the beginning of}} the day, banks choose how much costly liquidity to allocate to the settlement process. Then, they use it to execute an exogenous, random stream of payment orders. If a bank’s liquidity stock is depleted, payments are queued until new liquidity arrives from other banks, imposing costs on the delaying bank. We study the equilibrium level of liquidity posted in the system, performing some comparative statics and obtaining: i) a liquidity demand curve which links liquidity to delay costs; ii) insights on the efficiency of alternative system configurations; iii) insights on the effects of <b>operational</b> <b>incidents</b> on the amount of liquidity present in the system. † Bank of England...|$|R
40|$|The {{financial}} crisis of 2008 {{was the most}} severe crisis since the great depression: millions of jobs and billions of pounds of household income were lost, resulting in pervasive unemployment, inequality and a rise in suicide rates (Barr et al., 2012). The failure exhibited complex organisational properties, such as tight coupling (e. g. the bankruptcy of Lehman Brothers triggered the collapse of other key organisations), the prioritisation of production over safety (e. g. profit over the wellbeing of clients) and a collective inaction to heed early warning signs (e. g. surrounding credit derivative swaps). Yet, research in the financial sector has failed to capture critical information on how the behaviours and practises (e. g. systemic rate rigging) within the industry eroded risk management processes, and led to organisational failure (Power, Ashby, & Palermo, 2013; Ring, et al., 2014). This thesis draws on human factors theory and methodology that have successfully been applied in other high-risk domains (e. g. aviation) and applies them to a financial trading organisation to investigate whether human factors approaches help understand error in the financial trading domain. To achieve this, four articles and three additional chapters {{have been developed for}} this thesis. Chapter 1 (introduction) conceptualises financial trading as a high-risk organisation and considers the implications of this for the domain, and the field of human factors. Chapter 2 (Article 1, published in Journal of Risk Research) conducts a systematic literature review of 19 studies in financial trading in order to establish the relevance of non-technical skills theory to the domain. Chapter 3 reports on the development of a methodology for capturing <b>operational</b> <b>incidents</b> within a financial trading firm: the Financial Incident Analysis System (FINANS). Chapter 4 (Article 2, published in Human Factors) uses FINANS to analyse 1, 000 incidents and reveals the human factors issues that underlie <b>operational</b> <b>incidents</b> (e. g. 1...|$|R
2500|$|By the war's end, 242 F-100 Super Sabres {{had been}} lost in Vietnam, as the F-100 was {{progressively}} replaced by the F-4 Phantom II and the F-105 Thunderchief. The Hun had logged 360,283 combat sorties {{during the war and}} its wartime operations came to end on 31 July 1971. The four fighter wings with F-100s flew more combat sorties in Vietnam than over 15,000 P-51 Mustangs flew during World War II. [...] After 1965, they did not fly into North Vietnam and mainly performed close air support missions. [...] Despite the April 1965 dogfight, the air force classified the engagement as resulting in a [...] "probable" [...] kill, and no F-100 was ever officially credited with any aerial victories. [...] No F-100 in Vietnam was lost to enemy fighters, but 186 were shot down by anti-aircraft fire, seven were destroyed from Vietcong attacks on airbases, and 45 crashed in <b>operational</b> <b>incidents.</b>|$|R
40|$|International audienceScience gateways, {{such as the}} Virtual Imaging Platform (VIP), enable {{transparent}} {{access to}} distributed computing and storage resources for scientific computations. However, their large scale {{and the number of}} middleware systems involved in these gateways lead to many errors and faults. This chapter addresses the autonomic management of workflow executions on science gateways in an online and non-clairvoyant environment, where the platform workload, task costs, and resource characteristics are unknown and not stationary. The chapter describes a general self-management process based on the MAPE-K loop (Monitoring, Analysis, Planning, Execution, and Knowledge) to cope with <b>operational</b> <b>incidents</b> of workflow executions. Then, this process is applied to handle late task executions, task granularities, and unfairness among workflow executions. Experimental results show how the approach achieves a fair quality of service by using control loops that constantly perform online monitoring, analysis, and execution of a set of curative actions...|$|R
5000|$|By the war's end, 242 F-100 Super Sabres {{had been}} lost in Vietnam, as the F-100 was {{progressively}} replaced by the F-4 Phantom II and the F-105 Thunderchief. The Hun had logged 360,283 combat sorties {{during the war and}} its wartime operations came to end on 31 July 1971. The four fighter wings with F-100s flew more combat sorties in Vietnam than over 15,000 P-51 Mustangs flew during World War II. After 1965, they did not fly into North Vietnam and mainly performed close air support missions. Despite the April 1965 dogfight, the air force classified the engagement as resulting in a [...] "probable" [...] kill, and no F-100 was ever officially credited with any aerial victories. No F-100 in Vietnam was lost to enemy fighters, but 186 were shot down by anti-aircraft fire, seven were destroyed from Vietcong attacks on airbases, and 45 crashed in <b>operational</b> <b>incidents.</b>|$|R
40|$|International audienceDistributed {{computing}} infrastructures {{are commonly}} used through scientific gateways, but operating these gateways requires important human intervention to handle <b>operational</b> <b>incidents.</b> This paper presents a self-healing process that quantifies incident degrees of workflow activities from metrics measuring long-tail effect, application efficiency, data transfer issues, and site-specific problems. These metrics are simple enough to be computed online and they make little assumptions on the application or resource characteristics. From their degree, incidents are classified in levels and associated to sets of healing actions that are selected based on association rules modeling correlations between incident levels. We specifically study the long-tail effect issue, and propose a new algorithm to control task replication. The healing process is parametrized on real application traces acquired in production on the European Grid Infrastructure. Experimental results obtained in the Virtual Imaging Platform show that the proposed method speeds up execution up to a factor of 4, consumes up to 26 % less resource time than a control execution and properly detects unrecoverable errors...|$|R
40|$|A year ago, I {{told you}} that the Subprime Credit Crisis was the worst {{financial}} crisis of our lifetime. It seemed like an improbable story then, {{but we all know}} it too well today. The causes of this crisis are many. There were incremental failures and frauds at every link in the financial supply chain. All together, each weak link created a systemic collapse of credit. It is incredibly hard for any institution to measure the impact of incremental exposures on systemic risk – especially if you don't have the tools to do it! I feel very strongly that {{now is the time to}} propose bold new standards in how risk is measured, capitalized, and reported. This is why I have proposed a new XBRL Taxonomy for Risk. XBRL (Extensible Business Reporting Language) is an XML language for describing business terms, and the relationship of terms, in a report. It enables semantic clarity of terminology, and that clarity is absolutely essential for the accurate recording and reporting of credit, market, and <b>operational</b> <b>incidents,</b> loss events, and losses...|$|R
40|$|Grid {{computing}} and {{workflow management}} systems emerged as {{solutions to the}} challenges arising from the processing and storage of shear volumes of data generated by modern simulations and data acquisition devices. Workflow management systems usually document {{the process of the}} workflow execution either as structured provenance information or as log files. Provenance is recognized as an important feature in workflow management systems, however there are still few reports on its usage in practical cases. In this paper we present the provenance system implemented in our platform, and then use the information captured by this system during 8 months of platform operation to analyze the platform usage and to perform multilevel error pattern analysis. We make use of the large amount of structured data using the explanatory potential of statistical approaches to find properties of workflows, jobs and resources that are related to workflow failure. Such an analysis enables us to characterize workflow executions on the infrastructure and understand workflow failures. The approach is generic and applicable to other e-infrastructures to gain insight into <b>operational</b> <b>incidents.</b> (C) 2013 Elsevier B. V. All rights reserve...|$|R
500|$|In {{addition}} to the almost non-stop succession of challenges related to the contracts on the U.S.Iceland run, Rainbow Hope {{was involved in a}} few notable <b>operational</b> <b>incidents.</b> [...] The most notable of these involves a labor strike that prevented Rainbow Hope from discharging cargo, keeping the vessel at anchor for 22 days. [...] The ship was scheduled to depart bound for Iceland on 24 September 1984, but the U.S. Government and Rainbow were aware there was the possibility of a strike by Icelandic longshoremen scheduled to begin on 4 October. [...] Rainbow Hope arrived at Njarðvík, Iceland on 8 October, while the [...] strike was already underway. [...] Rainbow repeatedly contacted the U.S. government for instructions, but none were given. [...] The ship remained idle at anchor for 22 days unable to discharge its cargo. [...] The strike ended on 30 October, and the cargo was delivered the next day. [...] The government paid Rainbow $266,370.50 for the delivery, but Rainbow filed suit in the 3rd Circuit Court seeking remuneration for the extra 22 days of waiting. [...] The court denied the claim, and appeals lasted until 24 June 1991, when the appeals court upheld the earlier decision.|$|R
40|$|Abstract. In {{this work}} {{we focus on}} one {{particular}} area of the smart grid, namely, the challenges faced by distribution network operators in securing the balance between supply and demand in the intraday market. Typically, the intraday market {{is used as a}} mechanism for coping with various unplanned <b>operational</b> <b>incidents</b> that may arise in the grid. It is anticipated that it will gain even more significance, as a growing number of load controllable devices and small-scale, intermittent generators coming from renewables are expected to pervade the system. On one hand, this means that the task of managing the network efficiently becomes increasingly complex and stochastic due to the large number of decentralized autonomous actors embedded in the network. On the other hand, their dynamic adaptability and capability to conform to higher volatility can lead towards compelling solutions. In this position paper we propose a set of desiderata for a multi-agent design to facilitate coordinating the various actors and alleviate these drawbacks. As the network is becoming more reliant on the power generated by DERs, the role of the balancing market is expected to gain significant importance. The goal is then to maximise th...|$|R
5000|$|In {{addition}} to the almost non-stop succession of challenges related to the contracts on the U.S. - Iceland run, Rainbow Hope {{was involved in a}} few notable <b>operational</b> <b>incidents.</b> The most notable of these involves a labor strike that prevented Rainbow Hope from discharging cargo, keeping the vessel at anchor for 22 days. [...] The ship was scheduled to depart bound for Iceland on 24 September 1984, but the U.S. Government and Rainbow were aware there was the possibility of a strike by Icelandic longshoremen scheduled to begin on 4 October. [...] Rainbow Hope arrived at Njarðvík, Iceland on 8 October, while the strike was already underway. [...] Rainbow repeatedly contacted the U.S. government for instructions, but none were given. [...] The ship remained idle at anchor for 22 days unable to discharge its cargo. [...] The strike ended on 30 October, and the cargo was delivered the next day. [...] The government paid Rainbow $266,370.50 for the delivery, but Rainbow filed suit in the 3rd Circuit Court seeking remuneration for the extra 22 days of waiting. [...] The court denied the claim, and appeals lasted until 24 June 1991, when the appeals court upheld the earlier decision.|$|R
50|$|On 9 February 2012 at 8:30 p.m. Kori 1 {{was shut}} down for regular inspections. After this the reactor lost all power for 12 minutes, and the diesel {{generator}} did not start. The reactor was to be inspected and the nuclear fuel was to be exchanged. According to the South Korean nuclear regulator all facilities for the spent-fuel-pool and the cooling of the reactor were still <b>operational.</b> The <b>incident</b> was not reported to the regulator before 12 March 2012. The incident was graded at INES level 2. Subsequently five senior engineers were charged for a coverup of the serious incident.|$|R
50|$|The International Civil Aviation Organization {{established}} English as {{the international}} aviation language in 1951 to improve consistency, accuracy, and effectiveness of pilot - air traffic control communication. It requires that all pilots on international flights and air traffic controllers serving international airports and routes {{must be able to}} communicate in English effectively, as well as in their native language. The goal was to achieve standards that would eliminate communication error, language, and comprehension difficulties, all of which have been a major cause of <b>operational</b> airspace <b>incidents.</b> Miscommunication between pilots and air traffic control is a prominent factor in fatal airplane crashes, airspace incidents, runway incursion, and mid-air collisions.|$|R
40|$|Asset Management Systems (AMS) are {{dedicated}} information technology (IT) applications intended {{to support the}} management tasks of assets of electrical utilities with the overall objective of maximizing the return on investment. The assets considered here are tangible capital intensive entities such as switch gear, transformers, lines, and substations. An AMS ideally encompasses the support of management tasks during the entire lifecycle of an individual asset. It provides support for the planning phase of the asset, e. g., investment decision support for the installation, replacement or refurbishment. An AMS also provides support for management tasks during the operation phase, e. g., maintenance planning. A characteristic property of an AM application is that it typically needs data from both the utility 9 ̆ 2 s operations systems (substation automation systems, SCADA, EMS) and the back office finance and business systems. The utilities' day-to-day operations of transmission and distribution networks involve specialized control systems. Up to now they {{have little or no}} ability to share data - either among themselves or with business applications. For asset management, however, shared access to almost any utility data source is vital. A data warehouse can provide the means of making the data accessible for asset management applications and appear homogeneous despite the physically distributed and heterogeneous data sources. Numerous AM applications are considered in this paper: From asset replacement support over asset maintenance and diagnosis to contract/tender support. A use case based on the contract/tender application is presented first, to set the context for the detailed description of lifecycle costs and availability calculations, which are central to many AM applications. For a precise prediction of costs and availability, knowledge of the failure rates of the components has to be inferred from operational data. An IT concept is presented on how to collect and store the operational data in the data warehouse as objects called <b>operational</b> <b>incidents.</b> <b>Operational</b> <b>incidents</b> consist of, part serial number, date and time, the type of incident, and some additional information. The types of incidents reported and stored are: Start of operation, failure detected (which failure mode), repair finished (working time, labor and material costs, duration of repair), end of operation without failure, or still in operation without failure. The last type of incident is necessary for an unbiased statistical estimate. Next we describe how a distribution utility collects actually its data. The selected utility operates a network consisting of two 50 kV rings, with 13 kV radial networks, with a 0. 4 kV consumer voltage level. The utility collects and stores operational and disturbance data in a variety of different ways, ranging from completely manual to fully automatic. The information required to feed the AMS exists, but the IT infrastructure does not yet allow the automatic transfer into the developed data warehouse. With respect to Swiss distribution utilities this leads to the conclusions that on short term, more individual, but state-of the-art, IT applications and tools would provide advantages for the activities of the utilities' departments, {{while at the same time}} paving the way for AM systems of the future. In order to prepare for a smooth transition to the upcoming IT systems and applications we strongly recommend that utilities pay careful attention to the interoperability issues of the IT systems they are about to purchase, replace, or enhance. Keywords: Asset management 9 ̆ 6 Availability 9 ̆ 6 Lifecycle Cost 9 ̆ 6 Risk 9 ̆ 6 Data Warehouse 9 ̆ 6 Maintenance Strategy 9 ̆ 6 Tender Suppor...|$|R
