56|66|Public
5000|$|User {{information}} bits {{do not include}} the <b>overhead</b> <b>bits</b> originated by, or having their primary functional effect within, the telecommunications system.|$|E
50|$|In data {{transmission}} and telecommunication, bit stuffing (also known—uncommonly—as positive justification) is {{the insertion of}} non information bits into data. Stuffed bits {{should not be confused}} with <b>overhead</b> <b>bits.</b>|$|E
50|$|In data {{transmission}} and telecommunication, <b>overhead</b> <b>bits</b> are nondata bits necessary for transmission (usually {{as part of}} headers, checksums, and such).Such bits are not counted {{as part of the}} goodput.|$|E
30|$|Note that here, the {{simulated}} <b>bit</b> <b>overhead</b> β _CS^(A) that may include several CS measurements (cycles) is used, whereas (53) {{refers to the}} optimal <b>bit</b> <b>overhead</b> of only one CS measurement.|$|R
40|$|SUMMARY With the {{increase}} of commercial multimedia applications using digital video, the security of video data {{becomes more and more}} important. Although several techniques have been proposed in order to protect these video data, they provide limited security or introduce significant overhead. This paper proposes a video security scheme for MPEG video compression standard, which includes two methods: DCEA (DC Coefficient Encryption Algorithm) and “Event Shuffle. ” DCEA is aim to encrypt group of codewords of DC coefficients. The feature of this method is the usage of data permutation to scatter the ciphertexts of additional codes in DC codewords. These additional codes are encrypted by block cipher previously. With the combination of these algorithms, the method provides enough security for important DC component of MPEG video data. “Event Shuffle ” is aim to encrypt the AC coefficients. The prominent feature of this method is a shuffling of AC events generated after DCT transformation and quantization stages. Experimental results show that these methods introduce no <b>bit</b> <b>overhead</b> to MPEG <b>bit</b> stream while achieving low processing overhead to MPEG codec. key words: commercial multimedia applications, selective encryption, MPEG codec, MPEG bitstream, data shuffle, processing <b>overhead,</b> <b>bit</b> <b>overhead</b> 1...|$|R
40|$|The {{independent}} directed acyclic graphs (IDAGs) introduces Link-independent and Node-independent DAGs. The polynomial- time {{algorithms used}} to compute link-independent and node-independent DAGs. The algorithm provides: 1) provides multipath routing; 2) utilizes all possible edges; 3) guarantees recovery from single link failure; 4) recovery from dual link failure and 5) {{reduce the number}} of <b>overhead</b> <b>bit</b> required in the packet header. The effectiveness of the proposed IDAGs approach by comparing key performance indices to that of the independent trees and multiple pairs of independent trees techniques will shown in advanced JAVA platform...|$|R
50|$|In the E-carrier European hierarchy, each digroup {{supports}} 15 PCM channels {{or their}} equivalent in other services. The DS1 line rate (2 digroups plus <b>overhead</b> <b>bits)</b> is 2.048 Mbit/s, supporting 30 voice channels or their equivalent in other services.|$|E
5000|$|In the North American and Japanese T-carrier digital hierarchies, each digroup {{supports}} 12 PCM voice channels {{or their}} equivalent in other services. The DS1 line rate (2 digroups plus <b>overhead</b> <b>bits)</b> is 1.544 Mbit/s, supporting 24 voice channels or their equivalent in other services.|$|E
50|$|In 2003, PCI-SIG {{introduced}} PCIe 1.0a, with a per-lane {{data rate}} of 250 MB/s and a transfer rate of 2.5 gigatransfers per second (GT/s). Transfer rate {{is expressed in}} transfers per second instead of bits per second {{because the number of}} transfers includes the <b>overhead</b> <b>bits,</b> which do not provide additional throughput; PCIe 1.x uses an 8b/10b encoding scheme, resulting in a 20% (= 2/10) overhead on the raw channel bandwidth.|$|E
40|$|Abstract—This paper {{develops}} a new resilient multipath routing technique, {{referred to as}} SPT-DAG, that has the following characteristics: (1) provides multipath routing over directed acyclic graphs (DAG); (2) the shortest path tree is guaranteed {{to be part of}} the DAG; and (3) provides guaranteed recovery from single link failures. We develop a polynomial time algorithm to compute the SPT-DAG and a routing protocol to forward packets over the SPT-DAG using one <b>overhead</b> <b>bit</b> in the packet. We consider different load-balancing approaches for forwarding a packet when the packet has not encountered a failure. Through extensive flow-based simulations, we show that SPT-DAG performs significantly better than those approaches that exclusively target load balancing or resiliency. I...|$|R
3000|$|... [...]) of 80, 100, and 120 bytes, to {{minimize}} the PHY (6 bytes) and MAC (8 bytes) headers <b>overhead</b> per information <b>bit.</b>|$|R
30|$|For {{conventional}} feedback, only a quantized CSI is fed back to BS in each feedback period, so {{the feedback}} <b>overhead</b> is B <b>bits</b> in a feedback period.|$|R
5000|$|In {{computer}} networks, goodput is the application-level throughput (i.e. {{the number}} of useful information bits delivered by the network to a certain destination per unit of time). The amount of data considered excludes protocol <b>overhead</b> <b>bits</b> as well as retransmitted data packets. This {{is related to the}} amount of time from the first bit of the first packet sent (or delivered) until the last bit of the last packet is delivered.|$|E
50|$|When {{the rate}} of the {{incoming}} flow in any of the tributary lines is below this reading rate, the multiplexer cannot read any bits from the elastic memory, and so it uses a stuffing bit or justification bit (called justification opportunity) in the output aggregate signal. Its task is that of adapting the signal that enters the multiplexer to the rate at which this signal is transmitted within the output frame (its highest clock value). This type of justification is called positive justification.Justification bits, together with other <b>overhead</b> <b>bits,</b> make the output rate higher than the total of the input signals.|$|E
50|$|The Protocol {{overhead}} of a {{coding scheme}} is {{the ratio of}} the number of added coding bits to the number of raw payload bits. The overhead of 64b/66b encoding is 2 <b>overhead</b> <b>bits</b> for every 64 raw bits transmitted or 3.125%. This is considerably more efficient than the 25% overhead of the previously used 8b/10b encoding scheme which essentially charges every 8 bits of source data with a 2 bit (or 25%) tax. At the time 64b/66b was deployed, it allowed 10 Gb Ethernet to be transmitted with the same lasers used by SONET OC-192, rather than requiring 12.5 Gbit/s lasers, which were not expected to become available for several years.|$|E
40|$|This paper proposes an {{advanced}} spatially {{scalable video coding}} approach that exploits the inter layer correlation between different resolution layers by classified patch learning. The novelty of our proposed scheme is twofold. First, the correlation between low and high resolution frames is explored at patch level with regard to image features. Patches extracted from the previous coded frame are classified into structural and textural sets according to the gradient information. Then the inter layer correlation is separately studied for the two sets, resulting in two databases containing pairs of patches at different resolutions. Second, our proposed patch-based compensation manages to simultaneously exploit the spatial and temporal redundancies without <b>overhead</b> <b>bit</b> for motion. Based on the two databases, a high resolution prediction {{is derived from the}} current low resolution reconstruction at structural and textural regions, respectively. Experimental results show that our proposed approach improves the performance of H. 264 /MPEG spatially scalable coding up to 1. 9 dB and significantly enhances the subjective quality, especially at low bit rates. Index Terms — Scalable video coding, spatially scalable, inter layer correlation, classified patch learnin...|$|R
40|$|The {{combination}} of broadcast and on-demand data delivery services {{is an economic}} way to build a highly scalable wireless information system with limited bandwidth. The use of data broadcasting should be adaptive so that the system response time can always be minimised. A traditional approach requires {{the development of a}} system response time equation in order to find the optimal solution. However, obtaining such an equation is not always possible. We observe that by maintaining a certain level of on-demand request arrival rate, a close approximation to the optimal solution can be obtained. Using this approach, a real-time adaptive data delivery algorithm is developed. Our algorithm does not require the access information of the data items to be known exactly, which is needed normally for this kind of optimization problems. A simple and low <b>overhead</b> <b>bit</b> vector mechanism is able to capture the relative popularities of the data items. With this information, our algorithm can give a performance comparable to the ideal case in which the access information for each data item is known exactly...|$|R
3000|$|... is an integer; this {{assumption}} {{can be easily}} satisfied {{in a real system}} by appending virtual zero bits to the data bits in the MAC frame. As mentioned in earlier discussions, fragment error information is piggybacked on the ACK frames. We assume that the <b>overhead</b> of additional <b>bits</b> for this piggybacking is negligible. The size of the bitmap for correctly received and corrupted packets is dependent on the number of virtual fragments and stays same as long as number of virtual fragments is kept same. Therefore, even if new bits have {{to be added to the}} ACK frames, the <b>overhead</b> of these <b>bits</b> would be negligible.|$|R
50|$|The PDH {{based on}} the E0 signal rate is {{designed}} so that each higher level can multiplex a set of lower level signals. Framed E1 is designed to carry 30 or 31 E0 data channels plus 1 or 2 special channels, all other levels are designed to carry 4 signals from the level below. Because of the necessity for <b>overhead</b> <b>bits,</b> and justification bits to account for rate differences between sections of the network, each subsequent level has a capacity greater than would be expected from simply multiplying the lower level signal rate (so for example E2 is 8.448 Mbit/s and not 8.192 Mbit/s {{as one might expect}} when multiplying the E1 rate by 4).|$|E
50|$|There {{are various}} AIS formats {{based on the}} {{signaling}} level of the errored circuit. When an element of T-1 or (DS-1) circuit loses signal (LOS) or framing (OOF), the device replaces the erroneous data bits {{with a series of}} ones. This is where the term All Ones originates. At the DS3 signal level, the intermediate element receiving an errored signal replaces the errored channel data with a signal consisting of a valid DS-3 frame with the <b>overhead</b> <b>bits</b> (the M-subframe alignments bits, M-frame alignment bits, and P bits) with the payload set to a 1010... sequence, the C bits all set to zero, and the X bits set to one. This way, the integrity of the DS-3 frame is maintained even though the underlying data was compromised.|$|E
40|$|Abstract—In {{this paper}} we propose a {{hierarchical}} addressing scheme for Network-on-Chip applications. This scheme will facilitate a user to transmit a lesser number of <b>overhead</b> <b>bits</b> while transmitting a message to some other user. The number of <b>overhead</b> <b>bits</b> required will be dependent on the distance (in terms of number of routing nodes or routers) from source IP to destination IP. We also define a channel utility factor and show how the overall utilization of the channel increases with this scheme. Index Terms—Channel capacity, IP, Network-on-Chip, System-on-Chip, Table-lookup routing, virtual channels, wormhole routing...|$|E
50|$|JBIG {{is based}} on a form of {{arithmetic}} coding developed by IBM (known as the Q-coder) that also uses a relatively minor refinement developed by Mitsubishi, resulting in {{what became known as the}} QM-coder. It bases the probability estimates for each encoded bit on the values of the previous bits and the values in previous lines of the picture. JBIG also supports progressive transmission, which generally incurs a small <b>overhead</b> in <b>bit</b> rate (around 5%).|$|R
50|$|The simple {{variant of}} the {{chaffing}} and winnowing technique described above adds many <b>bits</b> of <b>overhead</b> per <b>bit</b> of original message. To make the transmission more efficient, Alice can process her message with an all-or-nothing transform and then send it out in much larger chunks. The chaff packets {{will have to be}} modified accordingly. Because the original message can be reconstructed only by knowing all of its chunks, Charles needs to send only enough chaff packets to make finding the correct combination of packets computationally infeasible.|$|R
30|$|Given {{that the}} encoder and decoder {{work on the}} same set of data to {{estimate}} the pattern direction, {{there is no need to}} transmit the five direction masks and only the directional weighting coefficients for the left view (i.e., η _h^l, η _ 45 ^l, η _v^l, η _ 135 ^l, and η _ud^l) and the right view, need to be estimated at the encoder side and transmitted to the decoder side. Obviously, the <b>overhead</b> <b>bit</b> cost of transmitting the weighting coefficients is negligible in comparison to the bit cost of texture and depth map. In the experimental results section, the term “DDFU” will be used to refer to this proposed full version scheme. In addition, DDFU can be simplified to only transmit the weighting coefficients of the first frame, which will be used for the fusion of all the remaining frames as well. This simplification is possible as the content of each frame does not change significantly, especially for the sequences with slow motion. Based on this observation, the simplified approach can further reduce the amount of transmitted side information with little quality degradation. In the experimental section, the term “DDFU (first frame η)” will be used to refer to this simplified scheme.|$|R
3000|$|... where DC is {{the duty}} cycle, Ndata the {{sampling}} data bits within one frame time, Noh the <b>overhead</b> <b>bits</b> within one frame time, Nsync the synchronization bits within one frame time, fc the communication data rate (bits per s) and fs the sampling data rate (bits per s).|$|E
30|$|The {{effect of}} reduced coding {{efficiency}} and additional <b>overhead</b> <b>bits</b> when using FMO is progressively severe at low bit rates, where header bits can occupy a significantly larger {{portion of the}} total bit budget compared to the source bits. Increasing the <b>overhead</b> <b>bits</b> reduces the number of bits allocated for source coding, resulting in reduced video quality. Thus, when using FMO as an error resilient tool for video transmission at low bit rates, careful consideration of the trade-offs is essential when error rates are high and bandwidth is limited. Our approach is to consider a new header bits model that works well when FMO is enabled to allocate the header bits more efficiently. Also, we propose enhancements to the frame layer rate control to better allocate the source bits.|$|E
40|$|Abstract. In this paper, {{we first}} {{describe}} a seamless switching scheme for scalable video bitstreams that fully {{takes advantage of}} both the high coding efficiency of non-scalable bitstreams and the flexibility of scalable bitstreams. Small bandwidth fluctuations are absorbed by the scalability of the bitstreams, while large bandwidth fluctuations are tolerated by switching between scalable bitstreams. Flexible and efficient switching techniques are investigated {{as the focus of}} this paper. A flexible method is proposed to switch from current scalable bitstream to one operated at lower rates at any frame without any <b>overhead</b> <b>bits.</b> Since additional bits are necessary in the proposed scheme when switching from a scalable bitstream operated at lower rates to one operated at higher rates, an efficient method is proposed to greatly reduce the amount of <b>overhead</b> <b>bits.</b> Experimental results show that the seamless switching scheme with the proposed switching techniques significantly outperforms both the approach with a single scalable bitstream and the approach of switching among multiple nonscalable bitstreams. ...|$|E
40|$|In a {{wireless}} communication environment, data broadcasting allows simultaneous access of data by an arbitrary {{number of clients}} while on-demand data delivery service provides instant access to data items. Therefore, complementing the use of broadcast and on-demand data delivery services can be an economic way to build a highly scalable wireless information system with limited bandwidth. The use of data broadcasting should be adaptive, such that system response time can always be minimised. A traditional approach requires {{the development of a}} system response time equation, based on which, the optimal solution can be found. However, obtaining such an equation is not always possible. We have observed that by maintaining a certain level of on-demand channel utilization, a close approximation to the optimal solution can be obtained. Using this approach, a real-time adaptive data delivery algorithm is developed. Our algorithm does not require the access information of the data items to be known exactly, which is needed normally for this kind of optimization problems. A simple and low <b>overhead</b> <b>bit</b> vector mechanism is able to capture the relative popularities of the data items. With this information, our algorithm can give a performance comparable to the ideal case in which the access information for each data item is known exactly...|$|R
40|$|In {{this paper}} {{we present a}} new method to produce low <b>overhead</b> {{redundant}} <b>bits</b> used to detect transmission errors of J 2 K streams on noisy communication channels. This method takes advantage of algorithms already existing on the JPEG 2000 standard and does not require any intrusive alterations on the coder. We will show {{that it is possible}} to improve standard JPEG 2000 error resilience in exchange for null resource footprint. Remark that this capability can be very important, for example in wireless communications that are mainly used by mobile devices with small processing capabilities...|$|R
50|$|PCIe 1.x {{is often}} quoted {{to support a}} data rate of 250 MB/s in each direction, per lane. This figure is a {{calculation}} from the physical signaling rate (2.5 gigabaud) divided by the encoding <b>overhead</b> (10 <b>bits</b> per byte.) This means a sixteen lane (×16) PCIe card would then be theoretically capable of 16×250 MB/s = 4 GB/s in each direction. While this is correct in terms of data bytes, more meaningful calculations {{are based on the}} usable data payload rate, which depends on the profile of the traffic, which {{is a function of the}} high-level (software) application and intermediate protocol levels.|$|R
40|$|In MPEG- 4 Fine Granular Scalability(FGS) video, Selective Enhancement(SE) {{function}} is adopted {{to enhance the}} subject quality of the region of interest(ROI) in truncated bit stream. But it has the problem of excessive increase in bit-rate. We present a new rectangular region-based SE(RSE) algorithm that can work almost as well as SE with negligible increase in bit-rate. It is shown by simulation that the proposed RSE can provide a good visual quality for the selected ROI with significantly reduced <b>overhead</b> <b>bits.</b> 1...|$|E
40|$|Fault {{and attack}} {{survivability}} in all-optical transport networks (AOTNs) require new approaches because of unique transmission characteristics. Specifically, fiber non-linearities and network transparency to transmitted signal types {{may make the}} network vulnerable to unorthodox at-tacks. Furthermore, unlike in electronic networks that re-generate signals at every node, attack detection and iso-lation schemes may {{not have access to}} the <b>overhead</b> <b>bits</b> used to transport supervisory information between regener-ators or switching sites to perform their functions. This pa-per presents a discussion on attack scenarios and proposes a conceptual framework for modeling faults and attacks in AOTNs. ...|$|E
40|$|Fault {{and attack}} {{survivability}} issues concerning physical fiber security in all-optical transport networks (AOTNs) require {{a new approach}} taking into consideration AOTN physical characteristics. Furthermore, unlike in electronic networks that regenerate signals at every node, attack detection and isolation schemes may {{not have access to}} the <b>overhead</b> <b>bits</b> used to transport supervisory information between regenerators or switching sites to perform their functions. This paper presents an analysis of attack and protection problems in AOTNs and proposes a conceptual framework for modeling attack problems and protection schemes for AOTNs. 1...|$|E
40|$|Abstract. This paper proposes an {{identity}} authentication mechanism at the link layer for acknowledgment frame in IEEE 802. 15. 4 network. With the proposed mechanism {{there are only}} three bits for authenti-cation, which can greatly reduce <b>overhead.</b> The encrypted <b>bit</b> stream for identity authentication will be transmitted to device by coordinator within association process. Statistical method indicates that our mecha-nism is successful in handling MAC layer attack. ...|$|R
30|$|These methods achieve {{very good}} {{performance}} compared to BSS but require a considerable <b>bit</b> <b>overhead</b> (at least 5 kbit/s per source according to [14]). The compatibility of the ISS {{with the current}} normalized formats implies to transmit this information through watermarking. Although high-capacity watermarking was recently proposed [20] for this purpose, it is dedicated to uncompressed formats (16 bits PCM) {{and would not be}} robust to bitrate compression.|$|R
40|$|Abstract For {{high speed}} fiber optical {{communications}} Low-Density Parity-Check (LDPC) codes with code overhead be-tween 5 and 15 % are of great interest. We focus on Euclidean and projective geometry LDPC codes and present a large num-ber {{of them with}} the mentioned <b>overhead.</b> Further the <b>bit</b> error rate perfomance (BER) {{of some of the}} presented codes is com-pared using an iterative soft-in soft-out sum product algorithm (SPA) decoder and a two-stage hybrid decoder...|$|R
