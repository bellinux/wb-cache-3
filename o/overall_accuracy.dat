5855|3052|Public
5|$|From March 2007 until November 2012, Folding@home took {{advantage}} of the computing power of PlayStation 3s. At the time of its inception, its main streaming Cell processor delivered a 20x speed increase over PCs for some calculations, processing power which could not be found on other systems such as the Xbox 360. The PS3's high speed and efficiency introduced other opportunities for worthwhile optimizations according to Amdahl's law, and significantly changed the tradeoff between computing efficiency and <b>overall</b> <b>accuracy,</b> allowing the use of more complex molecular models at little added computing cost. This allowed Folding@home to run biomedical calculations that would have been otherwise infeasible computationally.|$|E
25|$|The {{nasogastric}} aspirate {{can help}} determine the location of bleeding and thus direct initial diagnostic and treatment plans. Witting found that nasogastric aspirate has sensitivity 42%, specificity 91%, negative predictive value 64%, positive predictive value 92% and <b>overall</b> <b>accuracy</b> of 66% in differentiating upper GI bleeding from bleeding distal to the ligament of Treitz. Thus, in this study a positive aspirate is more helpful than a negative aspirate. In a smaller study, Cuellar found a sensitivity of 79% and specificity of 55%, somewhat opposite results from Witting.|$|E
25|$|One {{critical}} component of the securitization system in the US market is the Mortgage Electronic Registration Systems (MERS) created in the 1990s, which created a private system wherein underlying mortgages were assigned and reassigned outside of the traditional county-level recording process. The legitimacy and <b>overall</b> <b>accuracy</b> of this alternative recording system have faced serious challenges {{with the onset of}} the mortgage crisis: as the US courts flood with foreclosure cases, the inadequacies of the MERS model are being exposed, and both local and federal governments have begun to take action through suits of their own and the refusal (in some jurisdictions) of the courts to recognize the legal authority of MERS assignments. The assignment of mortgage (deed of trust) and note (obligation to pay the debt) paperwork outside of the traditional US county courts (and without recordation fee payment) is subject to legal challenge. Legal inconsistencies in MERS originally appeared trivial, but they may reflect dysfunctionality in the entire US mortgage securitization industry.|$|E
40|$|Effects of spatial, spectral, and radiometric {{resolution}} on re-mote mapping of fourth-order in-stream habitats were eval-uated by comparing hyperspectral imagery to simulated multispectral data. Spectral resolution {{was more important}} than spatial or {{radiometric resolution}} in improving classi-fication <b>accuracies,</b> although <b>overall</b> <b>accuracies</b> never ex-ceeded 62 percent. <b>Overall</b> <b>accuracies</b> were significantly greater for (1) hyperspectral data (7. 2 percent) compared to simulated multispectral imagery, (2) 1 -m pixels (4. 7 percent) compared to 2. 5 -m pixels, and (3) 11 -bit data (0. 8 percent) compared to &bit data. Higher spatial resolution also enabled removal of transitional areas between units by using interior buffers, improving accuracy by up to 15. 6 percent. We believe low <b>overall</b> <b>accuracies</b> were primarily due to the subjective and oversimplified nature of the polygon-based field maps used as ground reference data, and high-resolution imagery might provide a more detailed representation of in-stream habitats. Improved methods of collecting ground reference data, utilizing a point-based approach, should be developed for assessing the accuracy of classifications derived from fine spatial resolution (less than 5 -m) imagery...|$|R
30|$|The <b>overall</b> <b>accuracies</b> of {{classified}} outputs {{were evaluated by}} adding the number of sampled accurately classified pixels divided {{by the total number}} of sampled pixels. Furthermore, both overall kappa (accompanied by its variance) and class estimated kappa coefficients were also evaluated.|$|R
40|$|Abstract: This study explores {{a method}} to {{classify}} seven tropical rainforest tree species from full-range (400 – 2, 500 nm) hyperspectral data acquired at tissue (leaf and bark), pixel and crown scales using laboratory and airborne sensors. Metrics that respond to vegetation chemistry and structure were derived using narrowband indices, derivative- and absorption-based techniques, and spectral mixture analysis. We then used the Random Forests tree-based classifier to discriminate species with minimally-correlated, importance-ranked metrics. At all scales, best <b>overall</b> <b>accuracies</b> were achieved with metrics derived from all four techniques and that targeted chemical and structural properties across the visible to shortwave infrared spectrum (400 – 2500 nm). For tissue spectra, <b>overall</b> <b>accuracies</b> were 86. 8 % for leaves, 74. 2 % for bark, and 84. 9 % for leaves plus bark. Variation in tissue metrics was best explained by an axis of red absorption related to photosynthetic leaves and an axis distinguishing bark water and other chemical absorption features. <b>Overall</b> <b>accuracies</b> for individual tree crowns were 71. 5 % for pixel spectra, 70. 6 % crown-mean spectra, and 87. 4 % for a pixel-majority technique. At pixel and crown scales, tree structure and phenology {{at the time of}} image acquisition were important factors that determined species spectral separability...|$|R
25|$|Even {{though in}} most {{statistical}} classification methods, the neutral class is ignored {{under the assumption}} that neutral texts lie near the boundary of the binary classifier, several researchers suggest that, as in every polarity problem, three categories must be identified. Moreover, it can be proven that specific classifiers such as the Max Entropy and the SVMs can benefit from the introduction of a neutral class and improve the <b>overall</b> <b>accuracy</b> of the classification. There are in principle two ways for operating with a neutral class. Either, the algorithm proceeds by first identifying the neutral language, filtering it out and then assessing the rest in terms of positive and negative sentiments, or it builds a three-way classification in one step. This second approach often involves estimating a probability distribution over all categories (e.g. naive Bayes classifiers as implemented by the NLTK). Whether and how to use a neutral class depends {{on the nature of the}} data: if the data is clearly clustered into neutral, negative and positive language, it makes sense to filter the neutral language out and focus on the polarity between positive and negative sentiments. If, in contrast, the data are mostly neutral with small deviations towards positive and negative affect, this strategy would make it harder to clearly distinguish between the two poles.|$|E
500|$|Fitzroy {{was able}} to measure the <b>overall</b> <b>accuracy</b> of his entire journey by using his {{chronometers}} to measure the time of local noon {{when he returned to}} his home port. [...] As he sailed west, local noon occurred progressively later, until finally, when he had circumnavigated the globe, the shift in local noon time, as measured by his chronometers should be exactly twenty-four hours. [...] In fact, Fitzroy's measurements exceeded this by 33 seconds, which is equivalent to just [...] [...] This was impressive for a journey {{of tens of thousands of}} miles over five years, but nevertheless Fitzroy considered the error to be inexplicably large.|$|E
2500|$|Postwar {{analysis}} {{placed the}} <b>overall</b> <b>accuracy</b> of daylight precision attacks with the Norden {{at about the}} same level as radar bombing efforts. The 8th Air Force put 31.8% of its bombs within [...] from an average altitude of , the 15th Air Force averaged 30.78% from , and the 20th Air Force against Japan averaged 31% from [...]|$|E
30|$|Results for {{classification}} methods. The best <b>overall</b> <b>accuracies</b> {{are obtained}} by the random forest classifier for both our model (weighted accuracies ranging from 0.61 to 0.72) and the benchmark (weighted accuracies ranging from 0.50 to 0.60), suggesting that it is beneficial to account for non-linearity and interaction effects.|$|R
40|$|Classification-trees {{were used}} to model forest type groups and forest types for the conterminous United States and Alaska. The {{predictor}} data were a geospatial data set with a spatial resolution of 250 m developed by the U. S. Department of Agriculture Forest Service (USFS). The response data were plot data from the USFS Forest Inventory and Analysis program. <b>Overall</b> <b>accuracies</b> for the conterminous U. S. for the forest type group and forest type were 69 percent (Kappa � 0. 66) and 50 percent (Kappa � 0. 57), respectively. The <b>overall</b> <b>accuracies</b> for Alaska for the forest type group and forest type were 78 percent (Kappa � 0. 69) and 67 percent (Kappa � 0. 61), respectively. This is the first forest type map produced for the U. S. The forest type group map is an update of a previous forest type group map created by Zhu and Evans (1994). B. Ruefenacht and M. V. Finco are with the USDA Fores...|$|R
40|$|The Biolog Identification System (Biolog, Inc., Hayward, Calif.) was {{challenged}} at two separate laboratories with 113 coded isolates, including 33 type strains of staphylococci, 5 strains of Micrococcus spp., and 1 strain of Stomatococcus mucilaginosus. Test parameters between the sites were controlled {{as much as}} possible. Discrepancies were arbitrated by using conventional biochemicals. <b>Overall</b> <b>accuracies</b> (correct to the species level) upon initial testing were 47. 7 and 59. 3 %, respectively, at the two laboratories. After repeat testing of isolates generating "no identification" responses or errors, the <b>overall</b> <b>accuracies</b> increased to 69. 0 and 74. 3 % at the two sites, respectively, revealing {{no significant difference in}} the final results at the two laboratories (78 of 113 versus 84 of 113; P > 0. 05). Error rates were 7. 1 % at one site and 9. 7 % at the other. The Biolog is not yet accurate enough to serve as a primary method for identifying staphylococci...|$|R
2500|$|... }} “In recent years, optical atomic clocks {{have become}} {{increasingly}} competitive in performance with their microwave counterparts. The <b>overall</b> <b>accuracy</b> of single-trapped-ion-based optical standards closely approaches that of the state-of-the-art caesium fountain standards. Large ensembles of ultracold alkaline earth atoms have provided impressive clock stability for short averaging times, surpassing that of single-ion-based systems. So far, interrogation of neutral-atom-based optical standards {{has been carried out}} primarily in free space, unavoidably including atomic motional effects that typically limit the overall system accuracy. An alternative approach is to explore the ultranarrow optical transitions of atoms held in an optical lattice. The atoms are tightly localized so that Doppler and photon-recoil related effects on the transition frequency are eliminated.” ...|$|E
5000|$|... (<b>Overall</b> <b>accuracy</b> varies {{depending}} on the type of tilt sensor (or inclinometer) and technology used) ...|$|E
5000|$|... revM06-L: Local functional, 0% HF exchange. M06-L revised for {{smoother}} {{potential energy}} curves and improved <b>overall</b> <b>accuracy.</b>|$|E
30|$|Measures of {{diagnostic}} performances were calculated on a patient-based level. McNemar test (paired data) and chi 2 /Fischer’s exact test (unpaired data) were performed for comparisons of sensitivities, specificities and <b>overall</b> <b>accuracies.</b> Additional comparisons were performed with a generalised mixed effect model {{taking into account}} that each participant underwent scans with three different methods (SAS software, version 9.4, SAS institute Inc., Cary, NC, US).|$|R
5000|$|Nowcasting can {{additionally}} {{be combined}} with econometric models to improve <b>overall</b> forecast <b>accuracy,</b> as well as reduce errors.|$|R
40|$|The digital {{airborne}} sensor, CASI (Compact Airborne Spectrographic Imager) has considerable {{potential for}} mapping marine habitats. Here we present {{an account of}} one of the first coral reef applications. The CASI was flown over reefs of the Turks and Caicos Islands (British West Indies) and set to view 1  m pixels in 8 spectral bands. In addition, reef habitats were sampled in situ by visual assessment of percent cover in 1  m quadrats. Seagrass standing crop was assessed using a calibrated visual scale. Benthic habitats were classified using hierarchical cluster and similarity percentage analyses of the field survey data. Two levels of habitat discrimination were assessed: a coarse level (corals, algae, sand, seagrass) and a fine level which included nine reef habitats. <b>Overall</b> <b>accuracies</b> of CASI-derived habitat maps were 89 % and 81 % for coarse and fine levels of habitat discrimination, respectively. Accuracies were greatest once CASI data had been processed to compensate for variations in depth and edited to take account of generic patterns of reef distribution. These <b>overall</b> <b>accuracies</b> were significantly (...|$|R
50|$|The {{designer}} states an <b>overall</b> <b>accuracy</b> of 0.3 MOA {{field tested}} with bipod. Fixed {{may be more}} accurate.|$|E
50|$|The <b>overall</b> <b>accuracy</b> of GS is {{reported}} as 97% for mice, 84% for rabbits, 82% for rats and 73.3% for horses.|$|E
50|$|Four {{companies}} {{carry out}} national and sectoral opinion polls in Ireland. They use different methodologies, which {{can have a}} bearing on <b>overall</b> <b>accuracy.</b>|$|E
30|$|The {{classified}} {{images were}} compared with GPS, topographical sheets and available wetland maps of the study area, to determine how each site represented {{on the ground as}} observed during ground truthing was classified on the image. Error matrices as described by Congalton and Green (1999) were used for assessing the <b>accuracies.</b> The <b>overall</b> <b>accuracies</b> for the classifications were calculated to be 74.84 %, 81.65 % and 81.41 % respectively for 1989, 2000 and 2010 images.|$|R
30|$|Generally, {{our results}} are {{justified}} using the actual LULC maps of 1973, 1986, 2000, and 2015 with an <b>overall</b> <b>accuracies</b> of 86.5 % and a Kappa statistic of 0.803, which {{is within the}} range of accuracies reported in previous studies (Echeverria et al. 2008; Kamusoko et al. 2011). The LULC patterns and changes in the mountain grasslands of Sidama in South Ethiopia are reflective of the various prospects and restraints for the use and conservation of mountain grassland ecosystems in the region.|$|R
30|$|MRI is {{considered}} the most accurate imaging modality for preoperative assessment of endometrial carcinoma due to its excellent soft-tissue contrast resolution. <b>Overall</b> <b>accuracies</b> have been reported at 83 - 92 % [33, 34]. MRI is probably of greatest value in evaluating tumours that {{may be at risk}} of extrauterine spread, where a tumour mass is seen at ultrasound and histology is Grade 2 or 3. The MRI findings corresponding to the FIGO Stage of endometrial cancer are summarised in Table  2.|$|R
50|$|MPI {{has been}} {{demonstrated}} to have an <b>overall</b> <b>accuracy</b> of about 83% (sensitivity: 85%; specificity: 72%), and is comparable with (or better than) other non-invasive tests for ischemic heart disease.|$|E
5000|$|Accuracy. The TCP {{strives to}} produce texts {{that are as}} {{accurately}} transcribed as possible, with a specified <b>overall</b> <b>accuracy</b> rate of 99.995% or better (i.e. one error or fewer per 20,000 characters).|$|E
5000|$|The <b>overall</b> <b>accuracy</b> of CNAP devices {{has been}} {{demonstrated}} {{in comparison with the}} current gold standard invasive blood pressure (IBP) in numerous studies during the last few years. As examples, investigators came to the following conclusions: ...|$|E
40|$|During {{the process}} of unknown word {{detection}} in Chinese word segmentation, many detected word candidates are invalid. These false unknown word candidates deteriorate the <b>overall</b> segmentation <b>accuracy,</b> as it will affect the segmentation accuracy of known words. Therefore, we propose to eliminate as many invalid word candidates as possible by a pruning process. Our experiments show that by cutting down the invalid unknown word candidates, we improve the segmentation accuracy of known words and hence that of the <b>overall</b> segmentation <b>accuracy.</b> ...|$|R
40|$|Landcover test on Salt Lake {{test site}} {{illustrates}} potential issues with AWiFS/LISS-III for classification of certain land cover classes (evergreen, shrub/scrub, woody wetlands, emergent wetlands). Canopy and impervious graphs of product differences from source indicate slightly lower <b>overall</b> <b>accuracies</b> (shorter peaks, wider bases) for AWiFS/LISS-III, compared to L 5 /L 7. Inspection of individual products from canopy and impervious estimate tests revealed issues with combining AWifs quadrants, and similar but less severe effects with combining multiple dates of L 7 scan gap data...|$|R
40|$|Experiments were {{conducted}} to see {{the effects of a}} set of factors on the Resilient backpropagation (Rprop) artificial neural network classification of an Indian urban environment using IRS- 1 C satellite data. Factors investigated were sample size, number of neurons in hidden layers and number of epochs. The effect of including texture information in the form of neighbourhood information and grey level co-occurance matrix (GLCM) features in the classification process has been explored. Statistically similar <b>overall</b> classification <b>accuracy</b> is achieved for Rprop and Gaussian maximum likelihood classification (GMLC). Investigations have revealed that a large sample size gave higher test accuracy; variation in number of neurons in hidden layer did not affect the <b>overall</b> classification <b>accuracy</b> significantly; lesser number of epochs resulted in higher <b>overall</b> test <b>accuracy.</b> Incorporation of texture information by both approaches improved classification accuracy in a statistically significant manner...|$|R
50|$|The <b>overall</b> <b>accuracy</b> of the {{historic}} survey and the survey using 2011 technology produced remarkably similar results. For example, the distance between Southeast stones numbers 6 and 7 is 5,280.824 ft, almost exactly one mile (5,280 ft).|$|E
5000|$|... {{the crank}} Nicholson {{is based on}} central {{differencing}} and hence is second order accurate in time. The <b>overall</b> <b>accuracy</b> of a computation depends also on the spatial differencing practice, so the Crank-Nicolson scheme is normally {{used in conjunction with}} spatial central differencing ...|$|E
50|$|In the {{endeavor}} to standardize the parameters, the clamping {{down of the}} Almen rounds follows a strict geometry. The clamping head fixes the Almen round in correct manner, thus important for all related procedure. When working with the monitoring sensor, the specimen is preloaded to increase <b>overall</b> <b>accuracy.</b>|$|E
40|$|A cubic spline {{collocation}} procedure {{has recently}} been developed for the numerical solution of partial differential equations. In the present paper, this spline procedure is reformulated so that {{the accuracy of the}} second-derivative approximation is improved and parallels that previously obtained for lower derivative terms. The final result is a numerical procedure having <b>overall</b> third-order <b>accuracy</b> for a non-uniform mesh and <b>overall</b> fourth-order <b>accuracy</b> for a uniform mesh. Solutions using both spline procedures, as well as three-point finite difference methods, will be presented for several model problems. ...|$|R
40|$|In this study, we used {{structural}} and evolutionary based features {{to represent the}} sequences of gram-positive and gram-negative subcellular localizations. To do this, we proposed a normalization method to construct a normalize Position Specific Scoring Matrix (PSSM) using the information from original PSSM. To investigate {{the effectiveness of the}} proposed method we compute feature vectors from normalize PSSM and by applying support vector machine (SVM) and naïve Bayes classifier, respectively, we compared achieved results with the previously reported results. We also computed features from original PSSM and normalized PSSM and compared their results. The archived results show enhancement in gram-positive and gram-negative subcellular localizations. Evaluating localization for each feature, our results indicate that employing SVM and concatenating features (amino acid composition feature, Dubchak feature (physicochemical-based features), normalized PSSM based auto-covariance feature and normalized PSSM based bigram feature) have higher accuracy while employing naïve Bayes classifier with normalized PSSM based auto-covariance feature proves to have high sensitivity for both benchmarks. Our reported results in terms of <b>overall</b> locative <b>accuracy</b> is 84. 8 % and <b>overall</b> absolute <b>accuracy</b> is 85. 16 % for gram-positive dataset; and, for gram-negative dataset, <b>overall</b> locative <b>accuracy</b> is 85. 4 % and <b>overall</b> absolute <b>accuracy</b> is 86. 3 %. Full Tex...|$|R
40|$|The {{multiple}} classifier system (MCS) is {{an effective}} automatic classification method, useful in connection with remote sensing analysis techniques. Combining MSC with induced fuzzy topology enables a decomposition of image classes. This fuzzy topological MCS then provides a new and improved approach to classification. The basic classification methods discussed in this paper include maximum likelihood classification (MLC), minimum distance classification (MIND) and Mahalanobis distance classification (MAH). In this paper, {{the use of the}} fuzzy topology techniques in combination with the current classification methods is discussed. The methods included are (1) ordinary single classifier classification methods; (2) fuzzy single classifier classification methods; (3) simple average MCS; (4) fuzzy topological simple average MCS; (5) eigen-value MCS; (6) fuzzy topology and eigen-values MCS. This new experimental approach, involving such combinations for comparing the kappa values and <b>overall</b> <b>accuracies</b> is also discussed. After comparing the kappa values and <b>overall</b> <b>accuracies</b> of these classification methods, the experimental results, demonstrated that (a) methods combining with fuzzy topology concepts produced better classification accuracy than the ordinary methods; (b) the eigen-value MCS method produces better classification accuracy than the non-fuzzy method and (c) the best classifier combination was found to be MLC+MIND+MAH fuzzy eigen-value MCS. Department of Land Surveying and Geo-Informatic...|$|R
