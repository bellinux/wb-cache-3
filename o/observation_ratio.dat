4|338|Public
30|$|The <b>observation</b> <b>ratio</b> {{was found}} to have a clear {{seasonal}} variation, with a value of approximately 90 % in the winter season, becoming smaller during the summer. In addition to the seasonal fluctuations, the <b>observation</b> <b>ratio</b> during the summer season continuously decreases over time, from approximately 86 % in 2006 to approximately 84 % in 2007, suggesting a relationship between decreases in the <b>observation</b> <b>ratio</b> and annual tree growth and the corresponding increase in signal blockage. Figure 7 also clearly shows that the minimum ratio occurs during the months of July and August, which coincide with the period when the leaf area index in Korea is the highest (Kim et al., 2005). The <b>observation</b> <b>ratio</b> also shows a decreasing trend over time during the winter season when all the leaves of deciduous trees fall, with monthly averages for January of 89.2 % in 2006, 88.4 % in 2007, and 87.8 % in 2008. This continuous, gradual reduction is believed to be caused by the growing stems and branches.|$|E
30|$|We {{compare the}} methods using general matrix {{completion}} problem. In the experiments, p=m/n^ 2 denotes the <b>observation</b> <b>ratio,</b> where m {{is the number}} of observed entries. Here, p= 0.1, 0.2, 0.3, 0.5 are the different choices of the above ratio. The relative error is RES=Y_k-D _F/D_F. The values of the parameters are: τ _ 0 = 100, c_ 1 = 0.8, c_ 2 = 0.9 and ϵ= 5 e- 6.|$|E
30|$|IGS Site Guidelines {{state that}} the site {{location}} should have a clear horizon with minimal obstruction at elevations > 5 ° (Dow et al., 2005). Thus, buildings or structures near the GPS antenna that can block the signal should be avoided. Growing trees are even worse sources of error, {{not only because of}} their growth, but also due to seasonal changes of foliage. In our study, we have demonstrated the blockage of GPS signals due to foliage by analyzing seasonal changes in the ratio of complete to possible observations for permanent GPS stations. As expected, the <b>observation</b> <b>ratio</b> was higher in the winter season, when all of the leaves of deciduous trees have fallen. With the growth of trees grow above the antenna at one of the test sites, in 2007 the <b>observation</b> <b>ratio</b> of the summer season was found to drop from approximately 86 % to in 2006 to approximately 84 %. This signal blockage due to trees has the same effect as an increased elevation cutoff angle, decreasing the height estimate. The multipath error index MP 2 was computed for more than 4 years for three permanent GPS sites with different foliage conditions. Seasonal signals in MP 2 were observed at all sites, but those sites with thick foliage or higher tree density were found to have higher amplitudes and an increasing trend in annual variation. Signal attenuation due to foliage and the resulting degradation of accuracy were investigated with the coordinate uncertainties in the parameter estimation process. The 1 -σ values in the height estimates also showed annual variation; their amplitudes were higher for the sites with thick foliage.|$|E
40|$|CLEO: Science and Innovations 2016 Session - Microwave Photonics (SF 2 G) : Paper no. SF 2 G. 4 We {{demonstrate}} {{a method to}} substantially increase the <b>observation</b> duty <b>ratio</b> in temporal-magnification system without sacrificing the temporal resolution. 30 % or even 100 % <b>observation</b> duty <b>ratio</b> can be achieved on a 10 -ns or longer waveform. © 2016 OS...|$|R
40|$|Tornadoes induce very {{different}} wind forces than a straight-line (SL) wind. A suitably designed building for a SL wind may fail {{when exposed to}} a tornado-wind of the same wind speed. It is necessary to design buildings that are more resistant to tornadoes. Most {{studies have been conducted}} to investigate tornado forces on cubic, gable-roof and cylinder buildings. However, little {{attention has been paid to}} investigate tornado force on dome buildings; hence, further research is conducted in this study. The forces on a dome, cube and prisms were analyzed and compared using Computational Fluid Dynamics (CFD) for tornadic and SL winds. One typical tornado parameter was considered for comparison. The conclusions drawn from this study were illustrated in visualizations. The tornado force coefficients on the cube and prisms were larger than those on the dome by at least 90 % in the x-y directions, and 140 % in the z direction. The tornado pressure coefficients on cube and prisms were greater at least 200 %. The force coefficients on cube and prisms due to SL wind were higher than those on the dome due to tornado wind by about 100 % in the z-direction. The ratio of tangential (Vθ) to translational (Vt) velocity reported in recent studies is 10 or greater, which is larger than the field <b>observation</b> <b>ratios.</b> The influence of Vθ/Vt ratios on the tornado force coefficient for a cubic, prism and dome buildings were compared using a systematic study. The Vθ/Vt ratios were considered to be 1, 3, 6, and 8 for comparison. These ratios were very much in agreement with field <b>observation</b> <b>ratios.</b> The magnitudes of the forces were found to be larger for slower translation speed or higher Vθ/Vt ratios. For faster translation speeds or, lower Vθ/Vt ratio, the maximum force coefficients shifted to the left of the time history...|$|R
40|$|This paper studies how the HP-Filter {{should be}} adjusted, when {{changing}} {{the frequency of}} observations. The usual choices in the literature are to adjust the smoothing parameter by multiplying it with either {{the square of the}} <b>observation</b> frequency <b>ratios</b> or simply with the observation frequency. In contrast, the paper recommends to adjust the filter parameter by multiplying it with the fourth power of the <b>observation</b> frequency <b>ratios.</b> Based on this suggestion, some well-known comparisons of business cycles moments across countries and time periods are recomputed. In particular, we overturn a finding by Backus and Kehoe (1992) on the historical changes in output volatility and return instead to older conventional wisdom (Baily, 1978, Lucas, 1977) : based on the new HP-Filter adjustment rule, output volatility turns out to have decreased after the Second World War. ...|$|R
40|$|The {{methodology}} for flood detection developed at Dartmouth Flood Observatory (DFO) (Brakenridge and others, 2007) {{on a global}} scale, was implemented at the Joint Research Centre (JRC) of the European Commission on an automatic operational basis. The technique is using AMSR-E passive microwave remote sensing data of the descending orbit, H polarization, 36 GHz band to detect flood events from space around the globe with a daily temporal resolution. DFO was formerly using the daily global composite images having 3 days of lag in time whereas JRC implemented the model on the near-real time swath data available about 24 hours after acquisition. A ratioing of the water/dry signals described in the article are considered {{as a tool to}} observe surface water area changes. Thresholding the calculated <b>observation</b> <b>ratio</b> allows the detection of riverine inundation events. Validation of the model results is ongoing. Nevertheless, preliminary results show a promising correlation of the increase in river discharge on-site and changes at the observed signal of the sensor. Thus following the technique the detection of flood events in ungauged and inaccessible remote river channels is feasible from space. Software was developed at the JRC to automatically acquire and process the remotely sensed data in real time on an operational basis. After the validation and calibration of the satellite based near-real time Global Flood Detection System (GFDS) the remotely observed flood events are planned to be integrated into the Global Disaster Alert and Coordination System (www. gdacs. org/floods). GDACS is running at the JRC providing near real-time alerts about natural disasters around the world and tools to facilitate response coordination, including news and maps. JRC. G. 2 -Support to external securit...|$|E
40|$|The Magellanic Clouds {{are great}} {{laboratories}} {{to study the}} evolution of stars at two metallicities lower than solar. They provide excellent testbeds for stellar evolution theory and in particular {{for the impact of}} metallicity on stellar evolution. It is important to test stellar evolution models at metallicities lower than solar in order to use the models to predict the evolution and properties of the first stars. In these proceedings, after recalling the effects of metallicity, we present stellar evolution models including the effects of rotation at the Magellanic Clouds metallicities. We then compare the models to various <b>observations</b> (<b>ratios</b> of sub-groups of massive stars and supernovae, nitrogen surface enrichment and gamma-ray bursts) and show that the models including the effects of rotation reproduce most of the observational constraint...|$|R
40|$|Collaboration avec l'EPFLIndustrial {{application}} of micro-milling faces several scientific, technological and economic issues. To address these issues, {{we have developed}} a micro-orthogonal cutting facility in which chip thickness can be controlled to within a micron and cutting forces can be measured. This paper presents the facility and preliminary results of micro-orthogonal cutting on copper, {{in the form of}} span <b>observations,</b> cutting <b>ratio</b> measurements and estimates of shear angles and cutting forces...|$|R
40|$|Vertical fluxes of {{fatty acids}} were {{measured}} in sinking particles collected using a time-series sediment trap in Breid Bay, Antarctica during the austral summer from December 1985 to February 1986. Major components of fatty acids {{indicated that the}} sinking organic matter was mainly derived from diatoms and the contribution of zooplankton to the sinking particles was small. Temporal variation in fatty acid fluxes indicated changes in the abundance and the growth activity of diatom communities in overlying waters during the <b>observations.</b> <b>Ratios</b> of unsaturated fatty acids to saturated fatty acids in the sinking particles increased in the exponential growth phase of the overlying diatom bloom as inferred from changes in the organic carbon and Chl a content of sinking particles which reached their peak and started decreasing thereafter. Relative abundance of 20 : 5 in total fatty acids increased in the peak fluxes of the sinking particles. Our {{results suggest that the}} increase of sinking fluxes during the observations was due to the accumulation of the diatom population, of which growth was induced by some favorable environmental conditions in the surface water...|$|R
40|$|This paper studies how the Hodrick-Prescott filter {{should be}} {{adjusted}} when changing {{the frequency of}} observations. It complements the results of Baxter and King (1999) with an analytical analysis, demonstrating that the filter parameter should be adjusted by multiplying it with the fourth power of the <b>observation</b> frequency <b>ratios.</b> This yields an HP parameter value of 6. 25 for annual data given a value of 1600 for quarterly data. The relevance of the suggestion is illustrated empiricall...|$|R
3000|$|... =  1.32; {{the results}} {{obtained}} in these cases are {{not as good as}} in the homogeneous ones but still appreciable and meaningful. The method performs better using several observations collected in few monitoring points rather than one observation at different points. However, in HE 1, 300 unknowns (N) were estimated by using 20 <b>observations</b> (<b>ratio</b> equal to 0.067), while in HE 2 50 observations collected at two different points at different times (ratio equal to 0.167) have been used. The observations have been compared with the ones reproduced by the forward transport model by using the estimated release history as source term: the results show that the agreement is acceptable in both cases. Note again that the ratio of the number of observations on the unknowns (M/N) is very low (0.067) in comparison with the ratio M/N =  0.305 used by Woodbury and Ulrych (1996) in their applications to homogeneous 1 -D aquifers. The present results have demonstrated that the method is efficient with few observations too and the less performance can be ascribed to the non-uniformity of the flow field rather than to the amount of available data.|$|R
3000|$|... {{were the}} {{complete}} reverse {{of the internal}} ratios. The field ratios illustrate that for the surface magnetic <b>observations,</b> the <b>ratio</b> of the external fluctuation part caused by the magnetic ring current decreased whereas {{the ratio of the}} internal induced field increased during the storm main phase, reaching extreme values at the Dst-minimum before achieving slow recovery. For the sake of simplicity, the physical parameters of the magnetic fields and ratios referred in the SEA results all represent their SEA mean values.|$|R
40|$|Abstract—This paper studies how the Hodrick-Prescot t � lter {{should be}} {{adjusted}} when changing {{the frequency of}} observations. It complements the results of Baxter and King (1999) with an analytical analysis, demonstrating that the � lter parameter should be adjusted by multiplying it with the fourth power of the <b>observation</b> frequency <b>ratios.</b> This yields an HP parameter value of 6. 25 for annual data given a value of 1600 for quarterly data. The relevance of the suggestion is illustrated empirically...|$|R
40|$|This Paper studies how the HP-Filter {{should be}} adjusted, when {{changing}} {{the frequency of}} observations. It complements the results of Baxter and King (1999) with an analytical analysis, demonstrating that the filter parameter should be adjusted by multiplying it with the fourth power of the <b>observation</b> frequency <b>ratios.</b> This yields an HP parameter value of 6. 25 for annual data given a value of 1600 for quarterly data. The relevance of the suggestion is illustrated empirically. Business cycles; historical business cycle properties; HP-filter; temporal aggregation; trends...|$|R
40|$|Consider two-parameter {{statistical}} models for positive continuous observations. Suppose that these models are closed under change of scale and under reciprocals, properties {{that are very}} appropriate when the <b>observations</b> are <b>ratios</b> of positive magnitudes. Additionally, suppose that the maximum likelihood estimator of the population mean is the sample mean (Gauss's principle). Surprisingly, only one statistical model satisfies these three properties {{and this is a}} special case of the generalized inverse gaussian family of distributions known as Harmonic Law. Characterization of distributions Halphen distribution Harmonic distribution Gauss's principle Generalized inverse Gaussian distribution...|$|R
30|$|The {{effect of}} {{deciduous}} trees growing above antenna height on {{data collected by}} permanent Global Positioning System (GPS) stations was investigated. Signal blockage due to foliage and branches {{was found to have}} the same effect as an increased elevation cutoff angle, i.e., there was a change in the computed position. Height estimates were affected the most, showing a decrease with tree growth. Empirical Orthogonal Function (EOF) analysis on the height-time series from five test sites and two stations surrounded by trees showed a similar EOF mode of signal. Signal availability, computed as the ratio of the complete to possible set of observations, decreased with increasing tree growth and showed seasonal variation, with the <b>observation</b> <b>ratios</b> being higher during the winter months when the leaves had fallen. A similar seasonal variation was observed in multipath error and signal attenuation due to foliage. The multipath error index MP 2 was computed using the TEQC program and found to increase at a significant rate at sites with growing trees. Signal attenuation was analyzed using 1 -σ uncertainties from the estimation process of daily GPS data processing. While 1 -σ uncertainties did not show any seasonal variations at sites without trees, they were highly dependent on conditions related to the seasonal change of foliage when deciduous trees were near the antenna.|$|R
30|$|Recently, much {{study for}} {{improving}} {{the performance of the}} VADs in various high noise environments has been carried out by incorporating a statistical model and a likelihood ratio test (LRT) [6]. Those algorithms assume that the distributions of the noise and the noisy speech spectra are specified in terms of some certain parametric models such as complex Gaussian [7], complex Laplacian [8], generalized Gaussian [9], or generalized Gamma distribution [10]. Moreover, some algorithms based on LRT consider more complex statistical structure of signals, such as the multiple <b>observation</b> likelihood <b>ratio</b> test (MO-LRT) [11, 12], higher order statistics (HOS) [13, 14], and the modified maximum a posteriori (MAP) criterion [15, 16].|$|R
40|$|A Doppler imaging {{analysis}} of HD 184905 is pre-sented. Based on time series of high resolution and high signal-to-noise <b>ratio</b> <b>observations</b> we have refined vsini and v_rad {{with the help}} of synthesis modelling tools. The maps of Mg and Si abundance distributions were obtained {{with the help of}} Doppler imaging software, which was done for the first time for this particular object...|$|R
40|$|<b>Observations</b> on the <b>ratio</b> of positrons to the electron-positron sum {{made in the}} 5 to 50 GeV range by Buffington et al. (1974) {{are used}} to put an upper limit on the ratio of antiprotons to protons at various energies. The {{calculation}} of the latter ratio is based on detailed measurements of the cross section of antiproton production up to intersecting storage ring energies...|$|R
40|$|In {{the present}} {{research}} radiation sterilization dose of Bactrocera cucurbitae (Coquillett) was determined. Egg viability was reduced to 0. 93 % at a dose of 30 Gy. Cent percent sterility in {{both males and females}} was achieved at 40 Gy. Mating competitiveness and sexual or total competitiveness of males were measured quantitatively from direct <b>observations</b> and <b>ratio</b> test methods, respectively. In direct observation method the males treated up to 30 Gy were almost equally competitive as untreated males. In ratio test method the total competitiveness values (C) of treated males were estimated 0. 73 - 0. 91 at three different ratios from 1 : 1 : 1 to 3 : 1 : 1 under laboratory condition...|$|R
40|$|The {{ratio of}} positron/electron fluxes {{originated}} in nuclear spallation reactions in the Earth's magnetosphere is considered. It is supposed that positrons {{as well as}} electrons are produced in the decay of charged pions (pi± ® m ± ->e±) born in nuclear collisions of trapped relativistic inner zone protons with the residual atmosphere. These positrons and electrons are captured in the magnetosphere and create positron and electron radiation belts of nuclear origin. The positron/electron trapped magnetospheric fluxes formed with this mechanism are simulated and the resulting computed e+/e- flux ratio ~ 4 appears {{in agreement with the}} recent <b>observations.</b> This <b>ratio</b> is significantly different from the ratio ~ 1 obtained from the primary cosmic ray source through the same mechanism...|$|R
40|$|A {{method is}} {{presented}} that permits {{the determination of}} atmospheric depolarization-ratio profiles from three elastic-backscatter lidar signals with different sensitivity {{to the state of}} polarization of the backscattered light. The three-signal method is insensitive to experimental errors and does not require calibration of the measurement, which could cause large systematic uncertainties of the results, {{as is the case in}} the lidar technique conventionally used for the <b>observation</b> of depolarization <b>ratios...</b>|$|R
40|$|Probabilities {{and cross}} {{sections}} for ionization plus excitation in helium produced by fast heavy-particle impact have been evaluated. In these calculations, contributions from shake-off, time ordering, and independent interactions of the frozen-target electrons with the projectile are included. A comparison {{is made to}} recent experimental <b>observations</b> for the <b>ratio</b> of excitation-ionization to single-ionization total cross sections. A comparison is also made to calculations of excitation-ionization by fast electron impact...|$|R
40|$|We {{followed}} 9602 {{patients with}} Crohn's disease or ulcerative colitis for anal {{squamous cell carcinoma}} for up to 18 years. No significant increase was observed: two cases occurred vs 1. 3 expected during 99 229 person-years of <b>observation,</b> (standardized incidence <b>ratio</b> = 1. 6; 95 confidence interval: 0. 2 – 5. 7). Anal squamous cell carcinoma is rare even in inflammatory bowel disease. © 2000 Cancer Research Campaig...|$|R
30|$|The {{maximization}} of S/N ratio maximizes the desirable characteristic against noise factors. The desirable {{characteristic of}} this work is the minimization of wear volume loss. <b>Observation</b> of S/N <b>ratio</b> gives an optimal combination of input parameters for required output characteristic. From table expt. 12 offers an optimal combination of 15  N load and 8  % hBN for minimum wear volume loss of 0.011  mm 3 /m with corresponding maximum S/N ratio of 39.09354042  dB.|$|R
40|$|Random Forests™ is {{reported}} {{to be one of the}} most accurate classification algorithms in complex data analysis. It shows excellent performance even when most predictors are noisy and the number of variables is much larger than the number of observations. In this thesis Random Forests was applied to a large-scale lung cancer case-control study. A novel way of automatically selecting prognostic factors was proposed. Also, synthetic positive control was used to validate Random Forests method. Throughout this study we showed that Random Forests can deal with large number of weak input variables without overfitting. It can account for non-additive interactions between these input variables. Random Forests can also be used for variable selection without being adversely affected by collinearities. ^ Random Forests can deal with the large-scale data sets without rigorous data preprocessing. It has robust variable importance ranking measure. Proposed is a novel variable selection method in context of Random Forests that uses the data noise level as the cut-off value to determine the subset of the important predictors. This new approach enhanced the ability of the Random Forests algorithm to automatically identify important predictors for complex data. The cut-off value can also be adjusted based on the results of the synthetic positive control experiments. ^ When the data set had high variables to <b>observations</b> <b>ratio,</b> Random Forests complemented the established logistic regression. This study suggested that Random Forests is recommended for such high dimensionality data. One can use Random Forests to select the important variables and then use logistic regression or Random Forests itself to estimate the effect size of the predictors and to classify new observations. ^ We also found that the mean decrease of accuracy is a more reliable variable ranking measurement than mean decrease of Gini. ...|$|R
40|$|Abstract. We compare SUMER {{observations}} of six Si IV emission lines detected at the quiet Sun disk centre with recent theoretical line ratio calculations. Good agreement is found {{between theory and}} <b>observation</b> for <b>ratios</b> involving the 1394, 1403 and 818 ˚A line intensities. This agreement supports the theoretical prediction that the temperature where Si IV has its maximum ionisation fraction in ionisation equilibrium is Tmax ≃ 10 4. 8 K, as well as showing that Lyman continuum absorption does not significantly effect line intensities for transitions with wavelengths below 912 ˚A. We find that the 815, 1122 and 1128 ˚A lines are blended by approximately 30, 55 and 45 %, respectively, in the SUMER transitions. Key words: atomic data – line: identification – Sun: transition region – Sun: UV radiation 1...|$|R
40|$|The {{properties}} of the resonance X(3872) are discussed {{under the assumption that}} this resonance is dominantly a `molecular' J^PC= 1 ^++ state of neutral D and D^* mesons. It is argued that in these properties should dominate the states with the total spin of the charmed quark-antiquark pair equal to one. As a practical application of this <b>observation</b> the <b>ratio</b> of the rates of the decays X →π^ 0 χ_cJ for different J is predicted. It is also pointed out that the total rate of these decays is likely to be comparable to that of the observed transitions X →π^+ π^- Jψ and X →π^+ π^- π^ 0 Jψ. The decays of the X into light hadrons and its production in hadronic processes are also briefly discussed. Comment: 7 page...|$|R
40|$|This paper {{deals with}} {{underwater}} target classification using synthesized active sonar signals. Firstly, we synthesized ac-tive sonar returns from 3 D highlight model of underwater targets using the ray tracing algorithm. Then, we applied a multiaspect target classification {{scheme based on}} a hidden Markov model to classify them. For feature extraction from the synthesized sonar signals, a matching pursuit algorithm was used. Experimental results depending {{on the number of}} <b>observations</b> and signal-to-noise <b>ratio</b> are presented with our discussions. 1...|$|R
40|$|In view of {{the fact}} that the AMS- 02 {{instrument}} has recently been used to make preliminary <b>observations</b> of the <b>ratio</b> of the antiprotons (P) to protons (P) in the primary cosmic radiation we have returned to our idea of signatures of a local recent supernova. We find that at the present level of accuracy there is no inconsistency between our predictions for the P/P ratio to some hundreds of GeV using the preliminary observations. Comment: 7 PAGES, 3 FIGURE...|$|R
40|$|Results {{of recent}} EMC effect {{measurements}} and nuclear scaling measurements {{have both been}} attributed to local nuclear density effects and not properties of the bulk nuclear system. This lead us to the phenomenological <b>observation</b> that the <b>ratio</b> of the slopes in the 0. 3 1 nuclear scaling plateaus. Using this correlation, we developed a phenomenological relation which reproduces the general trends and features of the EMC effect for nuclei from 3 He to 56 Fe. Comment: 14 pages, 3 figures, 1 tabl...|$|R
30|$|The {{bandwidth}} {{and energy}} constraints are two critical {{issues for the}} design of WSNs. When the strict bandwidth constraint is taken into account, the decentralized estimation when the sensors only transmit one bit for each observation, that is, using binary quantization, is studied in [4 – 9]. When communication channels are noiseless, a maximum likelihood estimator (MLE) is introduced and optimal quantization is discussed in [4]. A universal and isotropic quantization rule is proposed in [6], and adaptive binary quantization methods are studied in [7, 8]. When channels are noisy, the MLE in additive white Gaussian noise (AWGN) channels is studied and several low complexity suboptimal estimators are derived in [9]. It has been found that the binary quantization is sufficient for decentralized estimation at low <b>observation</b> signal-to-noise <b>ratio</b> (SNR), but more bits are required for each observation at high observation SNR [4].|$|R
40|$|Supraglacial melt ponds {{are common}} {{features}} of ice sheets and valuable parameters {{in the mass}} budget of the cryosphere. In addition, melt ponds are a useful proxy for monitoring global climate change as they are influenced by both {{the temperature of the}} surrounding ice and the incident radiation, which itself is influenced by the atmosphere. This document will describe an investigation of supraglacial melt ponds in a small region of the southwestern coast of the Greenland Ice Sheet, which was surveyed using an unmanned aerial vehicle in July of 2008. The data gathered during this expedition will be mined for melt ponds using Iterative Self-Organizing Data Analysis Technique, Adaptive Boosting, and Maximum Likelihood methods, and this information will be used to estimate the size and volume of the melt ponds using the known attenuation properties of water and the Beer-Lambert-Bouguer Law. Comparisons of the lake location data from UAV and satellite observations indicates that the results of the Adaptive Boosting and Maximum Likelihood algorithms are accurate to within 300 meters, or approximately ten pixels in the satellite data. The results of the lake depth analysis were inconclusive due to disagreements in the outcome when the calculations were made with different observing wavelengths and {{because of a lack of}} ground truth data. The most likely error source is the presence of suspended sediment in the lake, floating ice crystals on the lake, either of which would affect the attenuation coefficient of the water, or settled sediment on the lake bottom, which would affect the lake bottom reflectivity. Finally, attempts to develop methods to detect drained supraglacial lakes led to the promising possibility that texture analysis or <b>observation</b> band <b>ratio</b> analysis could reveal drained lake locations without the advantage of change detection. However, texture analysis proved useful only in the UAV data, which has an extremely high spatial resolution, and no correlation between lake depth and <b>observation</b> band <b>ratio</b> was observed...|$|R
40|$|In this paper, {{the precise}} {{observations}} of earth tidal strains in the meridionaland the prime vertical direction are performed with newly devised extensometersof which the sensitivities are 3. 7 x 10 ~/mm and 5. 7 x l 0 ~/mm at Osakayama. According {{to the present}} <b>observation,</b> the <b>ratios</b> 01 /M 2 of the tidal component ofthe strains are 0. 48 in the meridional component and 0. 87 in the prime vertical com-ponent. And {{according to the observations}} at Osakayama, Kishu, Suhara and Matsu-shiro, the cos-terms of M 2 -tide of horizontal linear strains are positive in all theazimuths. Therefore, it is probable that the effect due to oceanic tide is far smallerthan the direct effect due to the tide generating potential at Osakayama and ratio I/his not negligible. And so a factor (h- 31), relating to horizontal areal strain and ratioh/I are calculated as follows...|$|R
40|$|We {{discuss the}} dust {{attenuation}} {{and the star}} formation rates in the nearby universe obtained from a comparison of far-infrared (IRAS) and ultraviolet (GALEX) <b>observations.</b> The <b>ratio</b> of the dust to UV flux ratio is used to derive the dust attenuation: this dust attenuation is found to increase with the luminosity of the galaxies and from z= 0 to z= 1. The slope of the UV continuum {{is found to be}} a very poor tracer of the dust attenuation in "normal" galaxies. Galaxies selected by their UV emission are found to be rather quiescent with a recent star formation rate equal to only 25 - 30 % of the past averaged one. Galaxies selected in FIR appear slightly more active in star formation. Comment: 10 pages, invited conference, The Spectral Energy Distribution of Gas Rich Galaxies: Confronting Models with Data Heidelberg, Germany October 4 - 8, 200...|$|R
