12|10000|Public
25|$|Grids are {{a form of}} {{distributed}} computing whereby a “super virtual computer” is composed of many networked loosely coupled computers acting together to perform very large tasks. This technology {{has been applied to}} computationally intensive scientific, mathematical, and academic problems through volunteer computing, and it is used in commercial enterprises for such diverse applications as drug discovery, economic forecasting, seismic analysis, and back <b>office</b> <b>data</b> <b>processing</b> in support for e-commerce and Web services.|$|E
5000|$|A Kimball tag was a {{cardboard}} tag that included {{both human and}} machine-readable data to support punched card processing. [...] A Kimball tag was an early form of stock control label that, like its later successor the barcode, supported back <b>office</b> <b>data</b> <b>processing</b> functions. They were predominantly used by the retail clothing ("fashion") industry.|$|E
5000|$|Prestel {{was created}} {{based on the}} work of Samuel Fedida at the then Post Office Research Station in Martlesham, Suffolk. In 1978, under the {{management}} of David Wood the software was developed by a team of programmers recruited from within the Post <b>Office</b> <b>Data</b> <b>Processing</b> Executive. As part of the privatisation of British Telecom, the team were moved into a [...] "Prestel Division" [...] of BT.|$|E
5000|$|Office of Satellite and Project Operations (OSPO) {{formerly}} the <b>Office</b> of Satellite <b>Data</b> <b>Processing</b> & Distribution (OSDPD) ...|$|R
50|$|By 20 September 1965 {{a central}} site was chosen at Bootle on Merseyside. The Post Office bought {{land on the}} site of sidings of the North Mersey Branch railway. It also built a large, purpose built <b>office</b> and <b>data</b> <b>processing</b> complex for the site, {{completed}} in March 1968.|$|R
40|$|Significant {{numbers of}} {{physicians}} are using <b>data</b> <b>processing</b> services {{and a large}} number of firms are offering an increasing variety of services. This paper quantifies user dissatisfaction with <b>office</b> practice <b>data</b> <b>processing</b> systems and analyzes factors affecting dissatisfaction in large group practices. Based on this analysis, a proposal is made for a more structured approach to obtaining <b>data</b> <b>processing</b> services in order to lower the risks and increase satisfaction with <b>data</b> <b>processing...</b>|$|R
50|$|Grids are {{a form of}} {{distributed}} computing whereby a “super virtual computer” is composed of many networked loosely coupled computers acting together to perform very large tasks. This technology {{has been applied to}} computationally intensive scientific, mathematical, and academic problems through volunteer computing, and it is used in commercial enterprises for such diverse applications as drug discovery, economic forecasting, seismic analysis, and back <b>office</b> <b>data</b> <b>processing</b> in support for e-commerce and Web services.|$|E
50|$|The current main {{building}} of the Russian State Social University passed through a long and interesting history. Starting from the 1920s there was a headquarters of International Academy for the Trade-Union Movement, where were built-up the members of Communist Parties from different countries, where these activities were banned. The Communist International (Comintern) settled {{in the same building}} from 1938 till 1943. During that time there were working such important players of the International Movement as Georgi Dimitrov, Dmitri Manuilsky, Moris Torez, Dolores Ibarruri, Klement Gottwald, Palmiro Togliatti, Otto Kuusinen, Walter Ulbricht, and others. From 1943, with the demands of the historical period, in the building was located the Soviet Information Bureau, sort of a fusion between the KGB, the Ministry of Foreign Affairs and the Soviet Counterintelligence. There were prepared a lot of acknowledged operations against Nazi Intelligence <b>Office,</b> <b>data</b> <b>processing</b> etc.In 1956, the {{main building}} on Wilhelm Pieck Street passed to the Higher Party School, which in 1959 was replaced by the Marx-Engels-Lenin Institute, existed there until 1991.In 2003 it became a part of Russian State Social University campus.|$|E
40|$|As {{the name}} implies work, as {{measured}} by planimetry and altimetry in Kabely situated in the cadastral area Hustopeče u Brna, it is a fucused on geodetic work. In this thesis describes the procedure works surveying planimetric and altimetry, <b>office</b> <b>data</b> <b>processing</b> and creating map in surveyed area. For measurements be were selected procedures and devices which are commonly used in surveying practice. Processing of measured data in programs Groma and Kokeš also frequently used in practice. The main output of this work is the map of measured area at a scale of 1 : 250, which should {{be used as a}} basis for the implementation of the landscaping in the area...|$|E
5000|$|Subjects include: English Language, Mathematics, Social Studies, Information Technology, Integrated Science, Caribbean History, Spanish, Religious Education, English Literature, Clothing and Textile, Home Economics Management, Food and Nutrition, Accounts, Principles of Business, <b>Office</b> Administration, Electronic <b>Data</b> <b>Processing</b> Management (EDPM), Agricultural Science, Visual Arts, and Physical Education.|$|R
50|$|On 1 January 1975, Siegen's {{population}} surpassed 100,000 {{through the}} amalgamation of Hüttental (38,867 inhabitants in 1974) and Eiserfeld (22,354 inhabitants in 1974), {{making it a}} city. With 117,224 inhabitants it also {{at the same time}} reached its all-time highest population. At the end of June 2005, according to the North Rhine-Westphalia State <b>Office</b> for <b>Data</b> <b>Processing</b> and Statistics (Landesamt für Datenverarbeitung und Statistik Nordrhein-Westfalen), 105,328 people made Siegen their main abode. Since 1975, the population has fallen by roughly 10% (12,000).|$|R
50|$|The 1980s were a {{time when}} the {{hospital}} continued to grow. A surgical wing was added in 1980, the entire inside of the hospital received a facelift in 1982 and the business <b>office</b> and <b>data</b> <b>processing</b> center was remodeled to accommodate a new in-house computer system. In 1985, a wing of the hospital was converted into an Emergency Urgent Care facility, including new state-of-the-art treatment facilities. One year later, in 1986, HMH joined Adventist Health and a memorial chapel was added.|$|R
40|$|The {{use of the}} Global Positioning System (GPS) {{for data}} capture, {{combined}} with a telemetry link, has meant that precise position information is now available {{in the field in}} real-time. Position and attribute data captured in the field is often manually transported back to the office and loaded into mapping packages, civil engineering packages, or GIS databases for further processing. By using a telemetry link to transfer data between the field and the office, improvements in security of data and efficiency can be achieved. However, data arriving in real-time poses a number of problems and requires the method in which <b>office</b> <b>data</b> <b>processing</b> is carried out to be modified. A number of approaches are discussed in this paper, including a large common database, assigning data to smaller databases as it is received from the field, a common exchange standard and agent-based software...|$|E
40|$|Over {{the last}} decade, {{fieldwork}} data collection methodology has fallen increasingly behind <b>office</b> <b>data</b> <b>processing</b> techniques. This {{has resulted in}} a gap between the form in which raw data is brought in from the field and the form in which the office systems require their input. Taking digital fieldwork techniques to the field with mobile comput-ing offers an opportunity to reduce or close the gap, eliminating to a significant extent both the problem of expensive post-processing and the need for intermediate procedures which are a known source of transcription errors. A case study is explained in this paper wherein is tested what immediate effect the introduction of mobile computing has on efficiency, quality and reliability of fieldwork results. This paper was compiled for the Münster GI-Days 2004. It describes the expected or sought advantages of digital fieldwork techniques and what was done in the case study ‘CropSpy’, but contains no technical information for implementation...|$|E
40|$|Epidemiological {{surveillance}} is {{an activity}} analysis systematically and continuously against the diseases and conditions {{that affect the}} increase and spread of diseases or health problems. The accuracy and completeness of epidemiologic surveillance report delivery {{is an important factor}} related to the accuracy of the data. The {{purpose of this study was}} to determine the process of recording data, data processing, reporting and feed back reporting of epidemiological surveillance of disease outbreaks in DKK Karanganyar potential. This research is qualitative. The study population was a village midwife, health centers Surveillance Officer, Surveillance Officer and Head of Karanganyar DKK DKK P 2 PL Karanganyar. The results showed the recording and reporting of potential disease outbreaks epidemiological surveillance carried out every day, every week and every month reported by the village midwife Surveillance Officer Health Center reported to DKK Karanganyar then subsequently reported to the Provincial Health <b>Office.</b> <b>Data</b> <b>processing</b> carried out by a surveillance officer DKK Karanganyar. Feed back reporting to follow up depending on size of the problem, widespread problem, the number of cases, and the type of case. The conclusions of this study is the implementation of epidemiological surveillance management of potential disease outbreaks in DKK Karanganyar still experiencing delays in the collection of surveillance data...|$|E
40|$|The paper briefly {{explores the}} issues of what does office {{automation}} mean. Furthermore, it discusses whether office workers are information or knowledge workers. Three stages of <b>office</b> automation - <b>data</b> <b>processing,</b> facilitate existing <b>office</b> procedures, elimination of some intermediary functions and introduction of office technology into managerial, professional and technical jobs - are identified. Finally changes to skills in office work are emphasized...|$|R
5000|$|The {{following}} overview {{shows the}} numbers of inhabitants of the city Rheda-Wiedenbrück and for 1939, 1950 and 1961 the number of inhabitants of the present-day city area. The figures up to 1970 and for 1987 are census results [...] and from 1975 based on official updates by the State <b>Office</b> for <b>Data</b> <b>Processing</b> and Statistics. The figures from 1975 to 1985 are estimated values, the figures from 1990 extrapolations {{based on the results}} of the census of 1987. The data refer to the resident population and from 1985 to the population with the main place of residence in the city.|$|R
40|$|Industrial sectors {{producing}} income-elastic {{products can}} grow rapidly but are highly vulnerable to {{fluctuations in the}} world economy. Policymakers need {{to take into account}} this trade-off between output and employment growth over the longer term and volatility in the short to medium term. We bring the principles of portfolio theory to bear on the issue. Our analysis is applied to Irish manufacturing employment where growth has been concentrated in foreign-owned sectors such as <b>Office</b> and <b>Data</b> <b>Processing</b> Equipment, Pharmaceuticals and Professional Instruments. We show that, increased volatility notwithstanding, the country 2 ̆ 019 s hightech FDI-driven strategy has brought the economy 2 ̆ 019 s industrial portfolio closer to the mean-variance efficiency frontier...|$|R
40|$|Abstract: While IT {{researchers}} have long focused on achieving strategic benefits provided by IT investments, recently some have claimed “IT doesn’t matter. ” We {{believe that most}} large organizations have both highly strategic and highly commoditized IT investments, and that differences in the strategic importance of information systems help explain where firms will adopt new technologies. We develop a framework that considers the tradeoffs between features, risk, and cost in IT adoption, and show {{how it can be}} applied to explain the adoption of open source software in large firms. We discuss a planned survey to provide empirical support linking the framework to enterprise deployment of open source software. The two decades from 1980 - 2000 marked tremendous growth in the organizational adoption of information technologies, through new users, new uses, and new technologies. Some (mainly smaller) firms adopted their first computers with the availability of desktop computing, while at larger enterprises, computing shifted from being a back <b>office</b> <b>data</b> <b>processing</b> system to {{become an integral part of}} daily operations and even used as a competitive weapon. Much of the growth came from innovations leading to new technologies such as RDBMS, 1 RISC-based computing, local area networks, and web-based intranets. However, this huge growth in technology adoption masked a contrary trend in the declining real cost of computing, by mor...|$|E
40|$|As a {{technology}} major from Jackson State University (JSU) I {{was called in}} as a summer intern at Kennedy Space Center (KSC) {{to work in the}} NASA Engineering, Control and Data Systems (NE-C) Division supporting the Spaceport Command and Control System (SCCS) at the Space Station Processing Facility (SSPF). I was given a two-part project; the first consisted of lending support relocating SCCS Computer Equipment and Project Personnel to the Launch Control Center (LCC). This task involved me using a Microsoft <b>Office</b> <b>data</b> <b>processing</b> tool to assist with the analysis and information management of logistics worth millions of dollars. With the assistance of two other interns, I was responsible for collecting data on equipment used, on a daily basis, by over 200 KSC employees. The many network servers, enterprise switches, desktop computers, and fiber optics had to be handled in an equally prompt and precise manner in order to ensure a minimal amount of equipment down time; which is critical in ensuring a properly secured networking environment. The second part of my project was to assist KSC in developing a more cost effective way of maintaining and taking full advantage of the functionality of some new kiosk units. Since KSC currently has no expert on the servicing and maintenance of the units, I, as a computer technology major, was given the opportunity to assess the hardware and software of the machines. The goal was to learn to establish a secure and remote environment for the kiosks; a goal highly valuing convenience by preserving valuable man-hours saved by not having to travel to each individual kiosk location. In addition, I was to leave a clear and precise plan for future users and administrators of the devices to follow...|$|E
40|$|Grid {{computing}} is a {{distributed system}} that breaks the workload into small self-contained units and then assigns them to geographically spread independent computers {{with the goal}} of achieving the best performance. The resource intensive scientific and engineering applications were the prime mover behind the development of grid computing systems as they require large amount of resources that cannot be met by a single computer. Grid systems are today being used for running many different types of applications including drug discovery, weather forecasting, economic forecasting, financial analysis, seismic analysis, and back <b>office</b> <b>data</b> <b>processing</b> for large scale e-commerce and web services. This report presents the work carried out for setting the Sintok-Grid, an extension of the Academic grid Malaysia to the Universiti Utara Malaysia. Setting up a grid site and connecting it to an existing one is not a straight forward task such as installing a server and connecting it to a communication link. It requires to go through several well planned steps including setting up of a right network environment with required security and access controls, the right computing architecture, communication facilities and required middle ware services. On top of carrying out these meticulously planned actions, it is necessary to decide the right Virtual Organization and be implemented. Thus comprehensive research was carried out {{in order to understand the}} requirements and technicalities of setting up of a suitable grid infrastructure. The researchers involved in this study underwent several training programmes and attended workshops conducted by leading researchers and practitioners in this field. These trainings and workshops provided them with valuable knowledge and hands-on experience in setting up a grid site bottom up. At the end of the research phase, the researchers developed a comprehensive implementation plan including environment, hardware, software and network designs. The implementation plan identified every step to be followed in detail. Once the detailed plan was ready, the Sintok-Grid was implemented and connected to the A-Grid Malaysia. During the design phase, several compromises had to be made due to financial constraints. These compromises include running two servers namely IS and SE in one server class computer and hosting the UI in a non-server class computer. But, the researchers were careful that these compromises would not affect the performance and quality of the grid implementation. Finally a comprehensive test was carried out on the operation and security of the grid system...|$|E
40|$|Extract] Computer Systems is an American {{multinational}} {{computer manufacturer}} which began its operations in California in the mid- 1960 s. Initially concentrating on mini-computers, {{the range of}} computers produced has been extended, and the corporation has moved into the related areas of <b>office</b> automation, <b>data</b> <b>processing</b> and computer-aided engineering. Computer Systems has a Far East regional office in Japan and manufacturing facilities in Singapore, Thailand, Indonesia, Hong Kong and Japan. The Singapore operation, representing a US 70 million investment, is {{one part of a}} vertically integrated multinational corporation (MNC). Competition world-wide has meant a recent "trimming" operation with a workforce cutback of about 8 per cent in the United States and the Far East, though Singapore has not been affected...|$|R
40|$|Since {{embarking on}} its {{economic}} reform and open door {{policy in the}} late 1970 s, China {{has emerged as the}} world’s new economic powerhouse. Its accession into the World Trade Organization (WTO) in 2001 further accelerated the growth. China’s vast potential market and cost competitiveness have combined to attract substantial foreign investment especially in electronics production. China’s dominance in electronics production as reflected in its export performance may jeopardize the position of ASEAN- 5 countries, which have previously been the established locations for electronics production. This paper sets {{to assess the impact of}} China’s impressive economic growth and ascendancy on its ASEAN- 5 neighbors by examining the trends in their export performances of <b>office</b> machines, <b>data</b> <b>processing</b> machines, and telecommunication equipments. The findings suggest that by 2004, China’s exports have surpassed the combined exports of ASEAN- 5 countries in all three product group...|$|R
40|$|The {{relatively}} {{high number of}} doctoral dissertations accepted every year in Spanish Universities and, with regard to scientific and cultural progress of the country, the undoubted value of any activity that may contribute towards sending out information on doctoral dissertations”, were the reasons which lead the Ministry of Education and Science to create, in 1975, a mechanised datafile of Spanish doctoral dissertations; the State Board of Universities, through the State Subcommittee of Research Promotion, {{were in charge of}} the permanent collection and transmission of data, and the General Technical <b>Office,</b> through the <b>Data</b> <b>Processing</b> Centre, was entrusted with setting up, maintaining and running the datafile...|$|R
40|$|The {{intention}} of the bachelor’s thesis is geodetic survey of former mining sites V zrcadlech and creation thematic map of area of interest at a scale of 1 : 500 and according to ČSN 01 3410 Maps of large scales. Base and thematical maps. The {{first part of the}} thesis deals with the preparation and surveying of the site. The second part deals with the <b>office</b> work, both <b>data</b> <b>processing,</b> as well as creation of the thematic maps. There was built survey net of auxiliary survey points on the site, which was determined by polygonal traverse and three-tripod equipment system using a total station. Connection of the traverse was carried out on horizontal control and points measured using GNSS. Points of detailed survey were measured from auxiliary survey points. The computational work was made in software Groma v. 7. 0 and the graphic work was made in software MicroStation PowerDraft V 8 i and Atlas DMT...|$|R
40|$|<b>Data</b> <b>Processing</b> {{discusses}} the principles, practices, and associated tools in <b>data</b> <b>processing.</b> The book {{is comprised of}} 17 chapters that are organized into three parts. The first part covers the characteristics, systems, and methods of <b>data</b> <b>processing.</b> Part 2 deals with the <b>data</b> <b>processing</b> practice; this part {{discusses the}} data input, output, and storage. The last part discusses topics related to systems and software in <b>data</b> <b>processing,</b> which include checks and controls, computer language and programs, and program elements and structures. The text will be useful to practitioners of computer-re...|$|R
40|$|This paper {{proposes a}} {{conceptual}} matrix model with algorithms for biological <b>data</b> <b>processing.</b> The required elements for constructing a matrix model are discussed. The representative matrix-based methods and algorithms which have potentials in biological <b>data</b> <b>processing</b> are presented / proposed. Some application {{cases of the}} model in biological <b>data</b> <b>processing</b> are studied, which show the applicability of this model in various kinds of biological <b>data</b> <b>processing.</b> This conceptual model established a framework within which biological <b>data</b> <b>processing</b> and mining could be conducted. The model is also heuristic to other applications. <br /...|$|R
30|$|Quality <b>data</b> <b>processing</b> defines {{configuration}} {{and processing}} parameters, which are utilized {{in the evaluation}} process of quality attributes. Examples of configuration parameters include location of binary or configuration files, and environmental execution parameters (e.g. number of CPU cores, size of memory). Processing parameters refer to input data, which should be provided to <b>data</b> <b>processing</b> executables (e.g. Spark streaming). Supported quality <b>data</b> <b>processing</b> defines processing, which can be performed with a specific <b>data</b> <b>processing</b> tool. Especially, it can be specified what kind of quality attributes for a data source can be evaluated with a specific <b>data</b> <b>processing</b> tool.|$|R
40|$|Abstract. UnifiedViews is an Extract-Transform-Load (ETL) frame-work {{that allows}} users – publishers, consumers, or analysts – to define, execute, monitor, debug, schedule, and share RDF <b>data</b> <b>processing</b> tasks. The <b>data</b> <b>processing</b> tasks may use custom plugins created by users. UnifiedViews differs from other ETL {{frameworks}} by natively supporting RDF data and ontologies. The practical demonstration of UnifiedViews {{at the conference}} will (1) clearly demonstrate how UnifiedViews helps RDF/Linked Data users with RDF <b>data</b> <b>processing</b> (2) and show the real instance of UnifiedViews with tens of <b>data</b> <b>processing</b> tasks and DPUs motivated by real <b>data</b> <b>processing</b> use cases. ...|$|R
40|$|DE 102007026480 A 1 UPAB: 20081222 NOVELTY - The method {{involves}} attaching mobile <b>data</b> <b>processing</b> {{units to}} collection containers contained with products to be commissioned. The <b>data</b> <b>processing</b> units command over micro-controllers, local memory, sensor interfaces and wireless communication devices. The mobile <b>data</b> <b>processing</b> unit is addressed on the <b>data</b> <b>processing</b> {{system in a}} commissioning controlling system to identify the current collection containers. The numbers of products, which can be inferred, are indicated. DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a device for the execution of a method for the commissioning of goods. USE - Method for the commissioning of goods. ADVANTAGE - The method involves attaching mobile <b>data</b> <b>processing</b> units to collection containers contained with products to be commissioned, where the mobile <b>data</b> <b>processing</b> unit is addressed on the <b>data</b> <b>processing</b> system in a commissioning controlling system to identify the current collection containers, and hence ensures to simplify the commissioning work by retrofitting the existing stock option and shelving systems...|$|R
5000|$|Pure {{communications}} and pure <b>data</b> <b>processing</b> {{have very different}} characteristics that led to different policy results. The markets that the technology existed on assisted the FCC make its policy decisions. [...] "The pure <b>data</b> <b>processing</b> market was viewed as an innovative, competitive market with low barriers to entry and little chance of monopolization." [...] The FCC established that no additional regulation or safeguards where required for the pure <b>data</b> <b>processing</b> market. The pure communications market {{on the other hand}} was being managed by an incumbent monopoly. The FCC had four concerns about the incumbent telephone companies which were: [...] "the sale of <b>data</b> <b>processing</b> services by carriers should not hurt the provision of common carrier services, the costs of such <b>data</b> <b>processing</b> services should not be passed on to telephone rate payers, revenues derived from common carrier services should not be used to cross subsidize <b>data</b> <b>processing</b> services, and the furnishing of such <b>data</b> <b>processing</b> services by carriers should not hurt the competitive computer market." ...|$|R
50|$|The IEA <b>Data</b> <b>Processing</b> and Research Center (DPC) is the <b>data</b> <b>processing</b> and {{research}} department of IEA, located in Hamburg, Germany.|$|R
40|$|Moore's law {{was first}} {{postulated}} in 1968, and it loosely {{says that the}} cost of making calculations on a computer falls by 50 % each year. Securities markets are, in essence, a form of <b>data</b> <b>processing.</b> Consequently, Moore’s law has driven important changes in those markets over the past forty years. Faster <b>data</b> <b>processing</b> was essential for major changes in securities trading. Increased turnover of portfolios was a result of faster <b>data</b> <b>processing.</b> Consequently, the criticism of that turnover may be misplaced. The effectiveness of regulatory changes, such as the lowering of brokerage commissions and the reduction in bid ask spreads, depended on reduced <b>data</b> <b>processing</b> costs, that is on Moore's Law. Deregulation of brokerage commissions could not have reduced rates by as much as it did if we had not had decreasing costs of <b>data</b> <b>processing.</b> The reduction in bid ask spreads which followed decimalization of securities quotes depended on improved <b>data</b> <b>processing.</b> Continued reductions in <b>data</b> <b>processing</b> costs will require a new regulatory approach. Regulators should consider the improvements in <b>data</b> <b>processing</b> and <b>data</b> transmission when they establish capital requirements and haircuts. ...|$|R
40|$|<b>Data</b> <b>processing</b> complexity, partitionability, {{locality}} and provenance play {{a crucial}} role in the effectiveness of distributed <b>data</b> <b>processing.</b> Dynamics in <b>data</b> <b>processing</b> necessitates effective modeling which allows the understanding and reasoning of the fluidity of <b>data</b> <b>processing.</b> Through virtualization, resources have become scattered, heterogeneous, and dynamic in performance and networking. In this paper, we propose a new distributed <b>data</b> <b>processing</b> model based on automata where <b>data</b> <b>processing</b> is modeled as state transformations. This approach falls within a category of declarative concurrent paradigms which are fundamentally different than imperative approaches in that communication and function order are not explicitly modeled. This allows an abstraction of concurrency and thus suited for distributed systems. Automata give us a way to formally describe <b>data</b> <b>processing</b> independent from underlying processes while also providing routing information to route data based on its current state in a P 2 P fashion around networks of distributed processing nodes. Through an implementation, named Pumpkin, of the model we capture the automata schema and routing table into a <b>data</b> <b>processing</b> protocol and show how globally distributed resources can be brought together in a collaborative way to form a <b>processing</b> plane where <b>data</b> objects are self-routable on the plane...|$|R
40|$|This paper {{reviews the}} {{historical}} development of <b>data</b> <b>processing,</b> discerning three approximate decades of distinct evolutionary cycles. Each cycle {{is seen as}} forking, two contrasting styles of <b>data</b> <b>processing</b> forming and separating during the cycle. On this basis, a classification of the major general areas of <b>data</b> <b>processing</b> is suggested. For each decade, characteristic aspects are discussed and both the lines of development are described. Finally, some observations regarding the present decade and its requirements are given, and some predictions relating to the next decade and its prerequisites are made. DESCRIPTORS: Classification of <b>data</b> <b>processing.</b> Evolution of <b>data</b> <b>processing.</b> Philosophical implications. Computing milieu. Terminology. CR CATEGORIES: 1. 2, 1. 3, 2. ...|$|R
40|$|A {{system for}} {{assessing}} vestibulo-ocular function includes a motion sensor system adapted to be coupled to a user's head; a <b>data</b> <b>processing</b> system configured {{to communicate with}} the motion sensor system to receive the head-motion signals; a visual display system configured {{to communicate with the}} <b>data</b> <b>processing</b> system to receive image signals from the <b>data</b> <b>processing</b> system; and a gain control device arranged to be operated by the user and to communicate gain adjustment signals to the <b>data</b> <b>processing</b> system...|$|R
