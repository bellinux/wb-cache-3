25|181|Public
25|$|The {{traditional}} {{method for}} producing century eggs {{is the development}} and improvement from the aforementioned <b>primitive</b> <b>process.</b> Instead of using just clay, a mixture of wood ash, calcium oxide, and salt {{is included in the}} plastering mixture, thereby increasing its pH and sodium content. The addition of calcium oxide and wood ash to the mixture lowers the risk of spoilage and also increases the speed of the aforementioned <b>primitive</b> <b>process.</b> A recipe for creating century eggs through this process starts with the infusion of three pounds of tea in boiling water. To the tea, three pounds of calcium oxide (or seven pounds when the operation is performed in winter), nine pounds of sea salt, and seven pounds of ash from burned oak is mixed into a smooth paste. While wearing gloves to prevent the chemicals from burning the skin, each egg is individually covered by hand, then rolled in a mass of rice chaff to keep the eggs from adhering to one another before they are placed in cloth-covered jars or tightly woven baskets. The mud slowly dries and hardens into a crust over several months, and then the eggs are ready for consumption.|$|E
60|$|Otter too looked {{sufficiently}} strange, robed as an Arab {{and wearing}} a turban. Being a dwarf, the difficulty was that all the dresses proved too long for him. Finally it was found necessary to cut one down by the <b>primitive</b> <b>process</b> of laying it on a block of wood and chopping through it with a sabre.|$|E
60|$|And, lastly, the sluice begat the jet, or {{hydraulicking}} proper, {{which is}} at present the highest effort of placer-mining. We thus reverse the <b>primitive</b> <b>process</b> which carried the wash-dirt to the water; we now carry the water to the wash-dirt. In California I found the miners washing down loose sandstones and hillocks of clay, passing the stuff through sluices, and making money when the gold averaged only 9d. and even 4d. to the ton. A man could work under favourable circumstances twenty to thirty tons a day. An Australian company, mentioned by Mr. R. Brough Smyth, with 200 inches of water, directed by ten hands, 'hydraulicked' in six days 224,000 cubic feet of dirt. The results greatly vary; in some places a man will remove 200 cubic yards a day, and in others only 50.|$|E
5000|$|... {{a set of}} <b>{{primitive}}</b> <b>processes,</b> {{which would}} be termed primitive functions in modern languages.|$|R
25|$|<b>Primitive</b> <b>processes</b> {{represent}} fundamental behaviors: {{examples include}} STOP (the process that communicates nothing, also called deadlock), and SKIP (which represents successful termination).|$|R
5000|$|Interaction can be (but isn't always) a {{directed}} flow of information. That is, {{input and}} output can be distinguished as dual interaction <b>primitives.</b> <b>Process</b> calculi that make such distinctions typically define an input operator (e.g. [...] ) and an output operator (e.g. [...] ), both of which name an interaction point (here [...] ) {{that is used to}} synchronise with a dual interaction primitive.|$|R
5000|$|Fire {{hardening}}, {{also known}} as [...] "fire polishing", a <b>primitive</b> <b>process</b> for hardening wood ...|$|E
50|$|The pith of the sago palm, {{although}} {{highly toxic}} to animals in its raw form, {{is an important}} human food source in Melanesia and Micronesia {{by virtue of its}} starch content and its availability. There is an easy, <b>primitive</b> <b>process</b> of starch extraction from sago pith that leaches away a sufficient amount of the toxins and thus only the starch component is consumed. The form of the starch after processing is similar to tapioca.|$|E
50|$|The {{traditional}} {{method for}} producing century eggs {{is the development}} and improvement from the aforementioned <b>primitive</b> <b>process.</b> Instead of using just clay, a mixture of wood ash, calcium oxide, and salt {{is included in the}} plastering mixture, thereby increasing its pH and sodium content. The addition of calcium oxide and wood ash to the mixture lowers the risk of spoilage and also increases the speed of the aforementioned <b>primitive</b> <b>process.</b> A recipe for creating century eggs through this process starts with the infusion of three pounds of tea in boiling water. To the tea, three pounds of calcium oxide (or seven pounds when the operation is performed in winter), nine pounds of sea salt, and seven pounds of ash from burned oak is mixed into a smooth paste. While wearing gloves to prevent the chemicals from burning the skin, each egg is individually covered by hand, then rolled in a mass of rice chaff to keep the eggs from adhering to one another before they are placed in cloth-covered jars or tightly woven baskets. The mud slowly dries and hardens into a crust over several months, and then the eggs are ready for consumption.|$|E
40|$|We study a multiclass open {{queueing}} {{network with}} a set of single-server stations that operate under a combination of FIFO (first-in-first-out) and priority service disciplines, and are subject to random breakdowns. Assuming that the <b>primitive</b> <b>processes</b> [...] in particular, external arrivals, service requirements, service capacities (up and down times) and the routing mechanism [...] follow two-moment approximations (based on functional central limit theorems), we develop a semi-martingale reflected Brownian motion (SRBM) approx- imation for the performance processes such as workload, queue lengths and sojourn times...|$|R
2500|$|CSP {{provides}} {{two classes}} of <b>primitives</b> in its <b>process</b> algebra: ...|$|R
2500|$|As {{its name}} suggests, CSP allows the {{description}} of systems in terms of component processes that operate independently, and {{interact with each other}} solely through message-passing communication. However, the [...] "Sequential" [...] part of the CSP name is now something of a misnomer, since modern CSP allows component processes to be defined both as sequential processes, and as the parallel composition of more <b>primitive</b> <b>processes.</b> The relationships between different processes, and the way each process communicates with its environment, are described using various process algebraic operators. Using this algebraic approach, quite complex process descriptions can be easily constructed from a few primitive elements.|$|R
50|$|The duo's {{name comes}} {{from the use of}} audio {{cassette}} in their early work. Their musical approach can be traced from the origins of sampling, musique concrète and Plunderphonics. Most pieces are constructed from numerous audio and video snippets taken from TV, radio, film and popular music; The Parker Tapes was constructed using the laborious, <b>primitive</b> <b>process</b> of manually splicing segments of audio together via a two-deck tape system, or ghettoblaster; later albums are constructed digitally using sound editing software.|$|E
50|$|Fish {{byproducts}} {{have been}} used historically to feed poultry, pigs, and other farmed fish. A primitive form of fishmeal is mentioned in The Travels of Marco Polo {{at the beginning of}} the 14th century: 'they accustom their cattle, cows, sheep, camels, and horses to feed upon dried fish, which being regularly served to them, they eat without any sign of dislike.' The use of herring as an industrial raw material started as early as about 800 AD in Norway; a very <b>primitive</b> <b>process</b> of pressing the oil out of herring by means of wooden boards and stones was employed.|$|E
40|$|That is {{the second}} salient feature of today's China: the {{increasing}} influence of neoliberalism in policy-making. This doctrine dictates that to catch up, China {{has to go through}} a <b>primitive</b> <b>process</b> of capital accumulation similar to the process of British industrialisation. Profits have to be made at somebody's cost. And the somebodies, in this case, are the rural poor, shedding sweat to develop modern China...|$|E
40|$|NiMo (Nets In Motion) is a Graphic-Functional-Data Flow {{language}} {{designed to}} visualize algorithms and their execution in an understandable way. Programs are process networks that evolve showing the full state at each execution step. Processes are polymorphic, higher order and have multiple outputs. The language has {{a set of}} <b>primitive</b> <b>processes</b> well suited for stream programming and supports open programs and interactive debugging. The {{new version of the}} environment NiMo Toons includes: an also graphic and incremental type inference system, multiple output processes as higher order parameters, symbolic execution, five evaluation modes that can be globally or locally set for each process and dynamically changed, and facilities to measure the used resources (parallelism level, number of steps, number of processes, etc. ...|$|R
40|$|A counter {{operating}} system creates {{a hierarchy of}} levels of abstraction, so that at a given level all details concerning lower levels can be ignored. This hierarchical structure separates functions according to their complexity, characteristic time scale, and level of abstraction. The lowest levels include the system's hardware; concepts associated explicitly with the coordination of multiple tasks appear at intermediate levels, which conduct 'primitive processes'. Software semaphore is the mechanism controlling <b>primitive</b> <b>processes</b> that must be synchronized. At higher levels lie, in rising order, the access to the secondary storage devices of a particular machine, a 'virtual memory' scheme for managing the main and secondary memories, communication between processes {{by way of a}} mechanism called a 'pipe', access to external input and output devices, and a hierarchy of directories cataloguing the hardware and software objects to which access must be controlled...|$|R
30|$|Regarding {{this last}} aspect [7, 8], we can remark that {{low-level}} vision gets useful measurements such as color, spatial frequency, binocular disparity, motion processing, etc., from several channels. Some {{of the aforementioned}} channels or space-temporal filters can be identified with receptive fields that deliver information to the retina. Others, such as binocular disparity or motion processing, are combinations of the previously mentioned ones. Mid-level vision integrates <b>primitives</b> <b>processes</b> at a previous level. Information delivered at this stage corresponds to real-world inferences such as egomotion and independent moving objects (IMOs). They are called causal actions or object candidates in connection with any multimodal characterization. Examples of these are the combination of luminance measurements to infer lightness, shape from shading, perceptual grouping, figure organization, etc. Finally, high-level vision interprets the scene through specific tasks such as relational reasoning, knowledge building, object recognition, etc.|$|R
40|$|Following {{an abrupt}} {{transition}} at birth from the sterile uterus to an environment with abundant commensal and pathogenic microbes, neonatal mammals {{are protected by}} maternal Abs at mucosal surfaces. We show in mice that different Ab isotypes work in distinct ways to protect the neonatal mucosal surface. Secretory IgA acts to limit penetration of commensal intestinal bacteria through the neonatal intestinal epithelium: an apparently <b>primitive</b> <b>process</b> that does not require diversification of the primary natural Ab repertoire. In contrast, neonatal protection against the exclusively luminal parasite Heligmosomoides polygyrus required IgG from primed females. This immune IgG could either be delivered directly in milk or retrotransported via neonatal Fc receptor from the neonatal serum into the intestinal lumen to exert its protective effect...|$|E
40|$|The {{treatment}} {{of this article}} renders closed-form density approximation feasible for univariate continuous-time models. Implementation methodology depends directly on the parametric-form of the drift and the diffusion of the <b>primitive</b> <b>process</b> and not on its transformation to a unit-variance process. Offering methodological convenience, the approximation method relies on numerically evaluating one-dimensional integrals and circumvents existing dependence on intractable multidimensional integrals. Density-based inferences can now be drawn for a broader set of models of equity volatility. Our empirical results provide insights on crucial outstanding {{issues related to the}} rank-ordering of continuous-time stochastic volatility models, the absence or presence of nonlinearities in the drift function, and the desirability of pursuing more flexible diffusion function specifications. (c) 2006 Elsevier B. V. All rights reserved...|$|E
40|$|This paper {{describes}} the initial {{results of a}} project to create a self-supervised algorithm for learning object segmentation from video data. Developmental psychology and computational experience have demonstrated that the motion segmentation of objects is a simpler, more <b>primitive</b> <b>process</b> than the detection of object boundaries by static image cues. Therefore, motion information provides a plausible supervision signal for learning the static boundary detection task and for evaluating performance on a test set. A video camera and previously developed background subtraction algorithms can automatically produce a large database of motion-segmented images for minimal cost. The purpose of this work {{is to use the}} information in such a database to learn how to detect the object boundaries in novel images using static information, such as color, texture, and shape. Singapore-MIT Alliance (SMA...|$|E
40|$|A process {{algebraic}} {{foundation is}} developed, for formal analysis of synchronous hardware designs using the commercially available hardware design language, ELLA. An underlying semantic foundation, based on input/outputtrace sets, is presented first {{through the use}} of state machines. Such a representation enables direct application of standard, fully automated, trace equivalence checking tools. However, to overcome the computational limitations imposed by such analysis methods, the input/output trace semantics is re-presented through a synchronous <b>process</b> algebra, EPA. <b>Primitive</b> <b>processes</b> in EPA denote the behaviour of primitive hardware components, such as delays or multiplexers, with composition operators corresponding to the different ways in which behaviours may be built. Of particular significance is the parallel composition operator which captures the machinery for building networks from other components/networks. Actions in EPA are structured and signify the state of input and ou [...] ...|$|R
40|$|Abstract We study a {{structural}} model {{that allows us}} to examine how credit spreads are affected by the interaction betweeen macroeconomic conditions and firm characteristics. Unlike most other structural models, our model explicitly incorpo-rates equilibrium macroeconomic dynamics and models a firm’s cash flow as <b>primitive</b> <b>processes.</b> Corporate securities are priced as contingent claims written on cash flows. Default occurs when the firm’s cash flow cannot cover the interest payments and the recovery rate is dependent on the economic condition at default. Our model produces the folloBarLinewing predictions: (i) credit spread is mostly negatively correlated with interest rate; (ii) credit spread yield curves are upward sloping for low-grade bonds; (iii) firm characteristics have significant effects on credit spreads and these effects also vary with economic conditions. These predictions are consistent with the available empirical evidence and generate implications for further empirical investigation...|$|R
40|$|We {{argue that}} while it is a {{valuable}} contribution, Carruthers' Model may be too restrictive to elaborate {{our understanding of the}} development of mindreading and metacognition, or to enrich our knowledge of individual differences and psychopathology. To illustrate, we describe pertinent examples where there may be a critical interplay between <b>primitive</b> social-cognitive <b>processes</b> and emerging self-attributions...|$|R
40|$|This memo {{describes}} the initial {{results of a}} project to create aself-supervised algorithm for learning object segmentation from videodata. Developmental psychology and computational experience havedemonstrated that the motion segmentation of objects is a simpler,more <b>primitive</b> <b>process</b> than the detection of object boundaries bystatic image cues. Therefore, motion information provides a plausiblesupervision signal for learning the static boundary detection task andfor evaluating performance on a test set. A video camera andpreviously developed background subtraction algorithms canautomatically produce a large database of motion-segmented images forminimal cost. The purpose of this work {{is to use the}} information insuch a database to learn how to detect the object boundaries in novelimages using static information, such as color, texture, and shape. This work was funded in part by the Office of Naval Research contract#N 00014 - 00 - 1 - 0298, in part by the Singapore-MIT Alliance agreement of 11 / 6 / 98, and in part by a National Science Foundation Graduate StudentFellowship...|$|E
40|$|We {{argue that}} the {{intractable}} part of the measurement problem—the ‘big ’ mea-surement problem—is a pseudo-problem that depends for its legitimacy on the ac-ceptance of two dogmas. The first dogma is John Bell’s assertion that measurement should never be introduced as a <b>primitive</b> <b>process</b> in a fundamental mechanical the-ory like classical or quantum mechanics, but should always be open to a complete analysis, in principle, of how the individual outcomes come about dynamically. The second dogma is {{the view that the}} quantum state has an ontological signif-icance analogous to the significance of the classical state as the ‘truthmaker ’ for propositions about the occurrence and non-occurrence of events, i. e., that the quan-tum state is a representation of physical reality. We show how both dogmas can be rejected in a realist information-theoretic interpretation of quantum mechan-ics {{as an alternative to the}} Everett interpretation. The Everettian, too, regards the ‘big ’ measurement problem as a pseudo-problem, because the Everettian rejects the assumption that measurements have definite outcomes, in the sense that on...|$|E
40|$|This memo {{describes}} the initial {{results of a}} project to create a self-supervised algorithm for learning object segmentation from video data. Developmental psychology and computational experience have demonstrated that the motion segmentation of objects is a simpler, more <b>primitive</b> <b>process</b> than the detection of object boundaries by static image cues. Therefore, motion information provides a plausible supervision signal for learning the static boundary detection task and for evaluating performance on a test set. A video camera and previously developed background subtraction algorithms can automatically produce a large database of motion-segmented images for minimal cost. The purpose of this work {{is to use the}} information in such a database to learn how to detect the object boundaries in novel images using static information, such as color, texture, and shape. This work was funded in part by the Office of Naval Research contract #N 00014 - 00 - 1 - 0298, in part by the Singapore-MIT Alliance agreement of 11 / 6 / 98, and in part by a National Science Foundation Graduate Student Fellowship...|$|E
50|$|John is {{surprised}} when, rather than return {{his leg and}} foot bones, the hospital gives him his entire amputated leg, including the flesh and muscle. John makes several failed attempts to skin the leg himself before deciding to mummify it. The leg ends up in a barbecue grill in John’s storage shed, undergoing a <b>primitive</b> mummification <b>process.</b>|$|R
40|$|Abstract: This paper {{presents}} {{the development of}} an advanced tool to facilitate accident data-collection and analysis processes. An integration of three technologies: hand-held computers, GPS and GIS is proposed with objectives to replace cumbersome <b>primitive</b> <b>processes,</b> to make accident data-collection and analysis more standardized, less error-prone and, therefore, more efficient. Under a proposed concept, the hand-held computers would {{play a major role in}} recording non-spatial data, while a main function of GPS is a spatial data collector. GIS would be a versatile database management tool for other tasks including data retrieval, data analysis, and information distribution. In order to demonstrate the proposed concept, the EMS data system in Khon Kaen City, Thailand, was selected as a case study. The development is potentially useful as it can offer a means to facilitate EMS data collection as well as explore the new dimension for EMS data analysis...|$|R
40|$|We study {{a general}} multiclass {{queueing}} network {{with a set}} of single-server stations that operate under a combination of FIFO (first-in-first-out) and priority service disciplines, and are subject to random breakdowns. Assuming that the <b>primitive</b> <b>processes</b> [...] in particular, external arrivals, service requirements, service capacities (up and down times) and the routing mechanism [...] follow strong approximations, we develop a semi-martingale reected Brownian motion (SRBM) approximation for performance processes such as workload, queue lengths and sojourn times. We illustrate through numerical examples in comparison against simulation that the SRBM approximation, while not always supported by a limit theorem, exhibits good accuracy in most cases, even when the systems are moderately loaded. Through analyzing special networks, we also discuss the existence of the SRBM approximation in relation to the stability and the heavy trac limits of the networks. Key words: multiclass queueing network, pr [...] ...|$|R
40|$|Summary. This paper {{describes}} ongoing {{work toward}} a principled controller synthesis methodology for large-scale, minimalist multi-robot systems. The work’s key objectives {{is to establish a}} set of programming primitives (processes) for which macroscopic behavior can be formally predicted. Such prediction is made possible by statistical physics techniques that use properties of time-invariant processes while exploiting the system’s large size. This paper’s focus is on the use of numerical and simulation methods during construction of the <b>primitive</b> <b>process</b> set. A computational method, developed by physicists, is used as a high-level simulation to characterize individual process behavior. The output, when interpreted qualitatively, guides distributed system design. In order to validate the approach, we consider a sequential inspection domain with a swarm of 400 + simulated robots. Synchronization is achieved through processes analyzed with the methods described, and predictions are compared with behavior exhibited in a traditional multi-robot simulation. The two simulation tools play different roles in characterizing collective behavior, and these differences shed new light on the multi-robot controller synthesis problem. ...|$|E
40|$|This {{meta-analysis}} {{research has}} gone through more than 200 studies from 1934 to 2016 to find the differences and similarities in cancer cells, mostly the cause. The most important difference between normal cells and cancer cells is how they respire. Normal cells use the sophisticated process of respiration to efficiently turn any kind of nutrient that is fat, carbohydrate or protein into high amounts {{of energy in the}} form of ATP. This process requires oxygen and breaks food down completely into harmless carbon dioxide and water. Cancer cells use a <b>primitive</b> <b>process</b> of fermentation to inefficiently turn either glucose from carbohydrates or the amino acid glutamine from protein into small quantities of energy in the form of ATP. This process does not require oxygen, and only partially breaks down food molecules into lactic acid and ammonia, which are toxic waste products. The most important result is that fatty acids or better told fats cannot be fermented by cells. This research mentions the role of ROS and inflammation in causing mitochondrial damage and answers the most important questions behind cancer cause and mentions some beneficial methods in preventing and treatment of cancer...|$|E
40|$|SUMMARY The {{embryonic}} {{development of}} germ cells in tetrapods is described, focusing on groups with the inductive mode of germ cell specification. In mammals PGCs are induced {{early in the}} gastrulation process, they are internalized with future extraembryonic mesoderm in the early posterior primitive streak, and specified soon thereafter. Strong evidence indicates that a similar process occurs in turtles and some other reptiles. In amniotes, the PGCs appear well before formation of the gonad in the posterior trunk, resulting in {{a period in which}} they are located outside the embryo before their migration to the gonad. In contrast, in urodeles the PGCs appear relatively late, and throughout development maintain a position close to precursors of the somatic cells of the gonad so that migration is not required. In lampreys early development of germ cells is strikingly similar to that in urodeles, suggesting this is the <b>primitive</b> <b>process.</b> As amniotes evolved large yolky eggs and better access to nutrition, development of the posterior half of the trunk became more dependent on cell proliferation; this was followed or accompanied by a shift of early germ cell development to the equivalent of the early primitive streak. A similar process may have occurred as some basal vertebrates developed large yolky eggs...|$|E
40|$|We study a {{structural}} model {{that allows us}} to examine how credit spreads are affected by the interaction betweeen macroeconomic conditions and firm characteristics. Unlike most other structural models, our model explicitly incorporates equilibrium macroeconomic dynamics and models a firm's cash flow as <b>primitive</b> <b>processes.</b> Corporate securities are priced as contingent claims written on cash flows. Default occurs when the firm's cash flow cannot cover the interest payments and the recovery rate is dependent on the economic condition at default. Our model produces the folloBarLinewing predictions: (i) credit spread is mostly negatively correlated with interest rate; (ii) credit spread yield curves are upward sloping for low-grade bonds: (iii) firm characteristics have significant effects on credit spreads and these effects also vary with economic conditions. These predictions are consistent with the available empirical evidence and generate implications for further empirical investigation. © Springer Science + Business Media, LLC 2006. link_to_subscribed_fulltex...|$|R
40|$|EASST (European Association of Software Science and Technology); University of Cyprus; ATHK/CYTA (Cyprus Telecom-munications Authority); ARTIST 2 Network of Excellence; University of Dortmund; et. al. Algebraical {{approach}} and logical approach {{are two different}} methodologies for designing concurrent systems. In this paper, we show some connections between these two approaches. On one hand, we relate a set of <b>primitives</b> of <b>process</b> algebras which exactl...|$|R
40|$|Several message [...] passing {{parallel}} programming languages have become available on various MIMD machines (e. g. Occam on the transputer and CMMD on the CM [...] 5) in recent years. Yet run [...] time characteristics of {{this class of}} languages has not been widely studied, and the programming support is much needed for more productive and efficient program development. This paper {{provides an overview of}} a modelling tool for Occam 2, implemented as two levels of meta interpreters. The general features of a message [...] passing programming paradigm is modelled through an extended Prolog with the notion of dynamically created, time [...] dependent, communication processes. The extended communication and process creation and termination mechanisms, and their interpretations are described. The second level interpreter interprets the <b>primitive</b> <b>processes</b> and constructions of the Occam 2 language. Given a performance metrics of the target machine, e. g. a network of transputers, the interpreter can predict the program s [...] ...|$|R
