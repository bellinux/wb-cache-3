29|43|Public
2500|$|The <b>privacy</b> <b>notice</b> {{must also}} {{explain to the}} {{customer}} the opportunity to 'opt out'. [...] Opting out means that the client can say [...] "no" [...] to allowing their information to be shared with nonaffiliated third parties. [...] The Fair Credit Reporting Act {{is responsible for the}} 'opt-out' opportunity, but the <b>privacy</b> <b>notice</b> must inform the customer of this right under the GLB. [...] The client cannot opt out of: ...|$|E
2500|$|The Financial Privacy Rule {{requires}} {{financial institutions}} to provide each consumer with a <b>privacy</b> <b>notice</b> {{at the time}} the consumer relationship is established and annually thereafter. [...] The <b>privacy</b> <b>notice</b> must explain the information collected about the consumer, where that information is shared, how that information is used, and how that information is protected. [...] The notice must also identify the consumer's right to opt out of the information being shared with unaffiliated parties pursuant to the provisions of the Fair Credit Reporting Act. [...] Should the privacy policy change at any point in time, the consumer must be notified again for acceptance. Each time the <b>privacy</b> <b>notice</b> is reestablished, the consumer has the right to opt out again. [...] The unaffiliated parties receiving the nonpublic information are held to the acceptance terms of the consumer under the original relationship agreement. [...] In summary, the financial privacy rule provides for a privacy policy agreement between the company and the consumer pertaining to the protection of the consumer's personal nonpublic information.|$|E
2500|$|Under the GLB, {{financial}} institutions must provide their clients a <b>privacy</b> <b>notice</b> that explains what information the company gathers about the client, where {{this information is}} shared, and how the company safeguards that information. [...] This <b>privacy</b> <b>notice</b> {{must be given to}} the client prior to entering into an agreement to do business. [...] There are exceptions to this when the client accepts a delayed receipt of the notice in order to complete a transaction on a timely basis. [...] This has been somewhat mitigated due to online acknowledgement agreements requiring the client to read or scroll through the notice and check a box to accept terms.|$|E
40|$|In {{an effort}} to address {{persistent}} consumer privacy concerns, policy makers and the data industry seem to have found common grounds in proposals that aim at making online privacy more “transparent. ” Such self-regulatory approaches rely on, among other things, providing more and better information to users of Internet services about how their data is used. However, we illustrate {{in a series of}} experiments that even simple <b>privacy</b> <b>notices</b> do not consistently impact disclosure behavior, and may in fact be used to nudge individuals to disclose variable amounts of personal information. In a first experiment, we demonstrate that the impact of <b>privacy</b> <b>notices</b> on disclosure is sensitive to relative judgments, even when the objective risks of disclosure actually stay constant. In a second experiment, we show that the impact of <b>privacy</b> <b>notices</b> on disclosure can be muted by introducing simple misdirections that do not alter the objective risk of disclosure. These findings cast doubts on the likelihood of initiatives predicated around notices and transparency to address, by themselves, online privacy concerns...|$|R
40|$|As {{smartphones}} {{become more}} ubiquitous, {{increasing amounts of}} information about smartphone users are created, collected, and shared. This information may pose privacy and security risks to the smartphone user. The risks may vary from government surveillance to theft of financial information. Previous work {{in the area of}} smartphone privacy and security has both identified specific security flaws and examined users’ expectations and behaviors. However, {{there has not been a}} broad examination of the smartphone ecosystem to determine the risks to users from smartphone data sharing and the possible mitigations. Two of the five studies in this work examine the smartphone data sharing ecosystem to identify risks and mitigations. The first study uses multi-stakeholder expert interviews to identify risks to users and the mitigations. A second study examines app developers in order to quantify the risky behaviors and identify opportunities to improve security and privacy. In the remaining three of five studies discussed in this work, we examine one specific risk mitigation that has been popular with policy-makers: <b>privacy</b> <b>notices</b> for consumers. If done well, <b>privacy</b> <b>notices</b> should inform smartphone users about the risks and allow them to make informed decisions about data collection. Unfortunately, previous research has found that existing <b>privacy</b> <b>notices</b> do not help smartphone users, as they are neither noticed nor understood. Through user studies, we evaluate options to improve notices. We identify opportunities to capture the attention of users and improve understanding by examining the timing and content of notices. Overall, this work attempts to inform public policy around smartphone privacy and security. We find novel opportunities to mitigate risks by understanding app developers’ work and behaviors. Also, recognizing the current focus on <b>privacy</b> <b>notices,</b> we attempt to frame the debate by examining how users’ attention to and comprehension of notices can be improved through content and timing...|$|R
40|$|One of {{the aims}} of the SPION project is to promote the design of privacy-friendly ‘model’ privacy {{policies}} for Online Social Networks (OSNs). Building on the legal, social and technical research performed thus far, we have distilled a number of recommendations for the development of such policies. The objective of these recommendations is to promote privacy policies which are not only complete from a legal perspective, but also designed so that users can easily ascertain the level of privacy offered by the OSN. This report starts by providing a checklist of the minimum information which providers of OSN services must provide to their users. Next, it discusses current best practices regarding the presentation of <b>privacy</b> <b>notices.</b> This discussion is then followed by a number of specific guidelines which the drafters of <b>privacy</b> <b>notices</b> should take into account when developing these notices. status: publishe...|$|R
50|$|<b>Privacy</b> <b>notice</b> is a {{text that}} will {{explain to the}} data owner how the data will be used, and is {{generated}} in print or electronic (appears as a link on a Web page). The law and its regulations mentioned in several articles that will shape this <b>privacy</b> <b>notice.</b> Additionally, on January 17, 2013 the Ministry of Economy published in the Official Journal in August Federation guidelines for generating the <b>Privacy</b> <b>Notice,</b> {{in order to minimize}} the need for them to have recourse to private companies for advice in its creation. The publication of three forms differ Privacy Notice: Integral, Simplified and Short, depending on your application.|$|E
5000|$|The <b>privacy</b> <b>notice</b> {{must also}} {{explain to the}} {{customer}} the opportunity to 'opt out'. Opting out means that the client can say [...] "no" [...] to allowing their information to be shared with affiliated parties. The Fair Credit Reporting Act {{is responsible for the}} 'opt-out' opportunity, but the <b>privacy</b> <b>notice</b> must inform the customer of this right under the GLB. The client cannot opt out of: ...|$|E
50|$|The Financial Privacy Rule {{requires}} {{financial institutions}} to provide each consumer with a <b>privacy</b> <b>notice</b> {{at the time}} the consumer relationship is established and annually thereafter. The <b>privacy</b> <b>notice</b> must explain the information collected about the consumer, where that information is shared, how that information is used, and how that information is protected. The notice must also identify the consumer's right to opt out of the information being shared with unaffiliated parties pursuant to the provisions of the Fair Credit Reporting Act. Should the privacy policy change at any point in time, the consumer must be notified again for acceptance. Each time the <b>privacy</b> <b>notice</b> is reestablished, the consumer has the right to opt out again. The unaffiliated parties receiving the nonpublic information are held to the acceptance terms of the consumer under the original relationship agreement. In summary, the financial privacy rule provides for a privacy policy agreement between the company and the consumer pertaining to the protection of the consumer's personal nonpublic information.|$|E
40|$|This article {{discusses}} {{the results of}} an updated consumer privacy survey based on the original version of the FTC survey. Its main objective was to find out what kind of personal information web sites are collecting from consumers today, and which web sites offer <b>privacy</b> <b>notices</b> regarding the handling and collection of personal information on their web site...|$|R
40|$|The Office of the Australian Information Commissioner (OAIC) {{undertook}} a privacy {{assessment of the}} Coles flybuys loyalty program (flybuys) to assess whether the program: 	managed personal information in an open and transparent way as required by Australian Privacy Principle (APP) 1 	notified individuals of the collection of personal information in accordance with its APP 5 obligations. The assessment also considered whether flybuys was adequately describing its main uses and disclosures of information, particularly in relation to any analytical or ‘big data’ activities, in its <b>privacy</b> <b>notices...</b>|$|R
40|$|Website {{and mobile}} {{application}} privacy policies are intend-ed {{to describe the}} system’s data practices. However, they are often written in non-standard formats and contain ambi-guities that {{make it difficult for}} users to read and compre-hend these documents. We propose a crowdsourcing ap-proach to extract data practices from privacy policies to provide more concise and useable <b>privacy</b> <b>notices</b> to users and support the analysis of stated data practices. To that end, we designed a hierarchical task workflow for crowdsourcing the extraction of data practices from privacy policies. We discuss our workflow design and report prelim-inary results...|$|R
50|$|Users of Loopt must {{register}} their {{mobile phone}} number, full name, and date of birth. Loopt's <b>privacy</b> <b>notice</b> states that users can control who receives geo-location information via privacy settings.|$|E
5000|$|Are {{important}} {{principles of}} consent, information and purpose, under which managers {{can only make}} the {{processing of personal data}} if owning them give their consent for the purposes outlined in the <b>privacy</b> <b>notice</b> [...]|$|E
50|$|On November 17, 2009, eight federal {{regulatory}} agencies released {{the final version}} of a model <b>privacy</b> <b>notice</b> form {{to make it easier for}} consumers to understand how financial institutions collect and share information about consumers.|$|E
40|$|Solutions {{to privacy}} {{concerns}} centered on notifying consumers about (transparency), and granting them {{control over the}} collection and use of their personal information (choice) are pervasive. Policy makers posit that these measures will aid consumers in improved privacy decision making. Conversely, scholars argue that these protections may {{have a negative impact}} on market efficiency and firm technology innovation and adoption. Chapter 2 evaluates the impact of regulation providing consumers transparency and choice on technology adoption by hospitals and finds, in contrast to prior results, evidence for a beneficial role of privacy regulation. I also find evidence that these gains may be a result of reduced barriers to adoption stemming from consumer privacy concerns. In Chapters 3 and 4 I shift my focus to evaluate the premise proposed by policy makers that increased transparency and choice will improve consumer privacy decision making. In Chapter 3, I first find that simple <b>privacy</b> <b>notices</b> communicating lower <b>privacy</b> decision making. I Chapter 3, I first find that simple <b>privacy</b> <b>notices</b> communication lower <b>privacy</b> protection can, under some conditions, result in less disclosure from participants, in-line with the policy aims for increased transparency. However, I also find that simple and common changes in those same notices, exploiting individual heuristics and biases, can result in the effect of even straightforward and accessible <b>privacy</b> <b>notices</b> being predictably manipulated (Experiment 1) or entirely thwarted (Experiment 2). Finally, in chapter 4 I find substantial malleability in individual privacy decision making in response to changes in choice framing. Specifically, the labeling of settings, the mix of setting relevance, and the presentation of choices as a choice to reject all impacted the decision frame for participants in a manner that significantly influenced participants 2 ̆ 7 choice of privacy protective settings. Taken together, these results suggest that while privacy solutions centered on transparency and choice may alleviate barriers to technology adoption stemming from consumer privacy concerns, the implicit assumption that they will reduce consumer privacy risks may be questioned. Implications for policy makers include a persistence, and perhaps increase, in consumer privacy risks despite increased transparency and control...|$|R
40|$|Accurate {{personal}} information provision {{is one of}} the most important determinants of the commercial development of the Web. However, consumers are usually reluctant to provide {{personal information}} or tend to provide false information online because of their concern about privacy violation risks. We employ a 2 × 2 × 2 experimental design to examine the effects of reputation, <b>privacy</b> <b>notices,</b> and rewards on online consumer behavior in volunteering two types of personal information on the Internet: demographic information and personally identifiable information. We discuss the theoretical and practical implications of the findings. © Springer Science + Business Media, Inc. 2006. link_to_subscribed_fulltex...|$|R
40|$|Data {{protection}} laws require organisations to be transparent {{about how}} they use personal data. This article explores the potential of machine-readable <b>privacy</b> <b>notices</b> to address this transparency challenge. We analyse a large source of open data comprised of semi-structured privacy notifications from {{hundreds of thousands of}} organisations in the UK, to investigate the reasons for data collection, the types of personal data collected and from whom, and the types of recipients who have access to the data. We analyse three specific sectors in detail; health, finance, and data brokerage. Finally, we draw recommendations for possible future applications of open data to privacy policies and transparency notices...|$|R
50|$|When the {{responsible}} party intends {{to transfer the}} data holder shall inform this fact in its <b>privacy</b> <b>notice,</b> requiring {{the consent of the}} holder, unless you apply any of the exceptions contemplated by this chapter.|$|E
50|$|Under the GLB, {{financial}} institutions must provide their clients a <b>privacy</b> <b>notice</b> that explains what information the company gathers about the client, where {{this information is}} shared, and how the company safeguards that information. This <b>privacy</b> <b>notice</b> {{must be given to}} the client prior to entering into an agreement to do business. There are exceptions to this when the client accepts a delayed receipt of the notice in order to complete a transaction on a timely basis. This has been somewhat mitigated due to online acknowledgement agreements requiring the client to read or scroll through the notice and check a box to accept terms.|$|E
50|$|The GAPP {{framework}} {{was previously}} {{known as the}} AICPA/CICA Privacy Framework, and is founded on a single privacy principle: personally identifiable information must be collected, used, retained and disclosed {{in compliance with the}} commitments in the entity's <b>privacy</b> <b>notice</b> and with criteria set out in the GAPP issued by the AICPA/CICA. This privacy objective is supported by ten main principles and over seventy objectives, with associated measurable criteria.|$|E
40|$|This article {{discusses}} telemedicine providers¿ online {{privacy and}} security disclosures. It {{presents the results}} of an exploratory study of a number of telecardiology companies¿ Web sites, providing insight in some of the current strategies towards data protection and information security in the international telemedicine market. The paper concludes that the online <b>privacy</b> <b>notices</b> in our sample are far from being standardized and complete. In view of privacy risks, as well as the transitory stage of the telemedicine sector, the underdeveloped state of online privacy notifications is disappointing ¿ and a missed chance for those who are interested in the successful future development of Internet privacy and telemedicine¿based healthcare...|$|R
40|$|The first {{principle}} of the original fair information practices – {{that there should be}} no secret systems – is fundamental to the ability of individuals to assert their interest in the privacy of their personal information. To assure openness about the existence and operation of data collection systems, collectors of personal information post <b>privacy</b> <b>notices</b> – statements that represent, among other things, the manner in which the collector acquires, uses, shares, protects and provides access to an individual’s personal information. As privacy is often defined as the ability of individuals to exercise control over the disclosure and subsequent uses of their personal information (Westin 1967), notice is fundamental to th...|$|R
5000|$|In {{the report}} the FTC {{describes}} {{the limitations of}} the existing notice and choice model, which it states, “have become increasingly apparent in recent years”. [...] The FTC states that the notice and choice-based model, “encourages companies to develop <b>privacy</b> <b>notices</b> describing their information collection and use practices to consumers, so that consumers can make informed choices”. However, “the notice-and-choice model, as implemented, has led to long, incomprehensible privacy policies that consumers typically do not read, let alone understand. Likewise, the harm-based model has been criticized for failing to recognize a wider range of privacy-related concerns, including reputational harm or the fear of being monitored”.|$|R
50|$|Echo uses {{an address}} {{set in the}} Alexa {{companion}} app when it needs a location. Amazon and third-party apps and websites use location information to provide location-based services and store this information to provide voice services, the Maps app, Find Your Device, and to monitor the performance and accuracy of location services. For example, Echo voice services use the user's location {{to respond to the}} user's requests for nearby restaurants or stores. Similarly, Echo uses the user's location to process the user's mapping-related requests and improve the Maps experience. All information collected is subject to the Amazon.com <b>Privacy</b> <b>Notice.</b>|$|E
50|$|Privacy {{concerns}} {{include the}} storing of data regarding payment information, transaction details, payment attempts {{and other information}} stored by Google indefinitely. The privacy policy for Google Wallet, called the Google Payments <b>Privacy</b> <b>Notice,</b> indicates {{that much of the}} data is stored but may not be shared outside Google except under certain circumstances. Information that may be collected upon signing up includes credit or debit card number and expiration date, address, phone number, date of birth, social security number, or taxpayer ID number. Information that may be collected about a transaction made through Google Wallet includes date, time, and amount of transaction, merchant’s location and description, a description of goods or services purchased, any photo the user associates with the transaction, the names and email addresses of sender and recipient, the type of payment method used, and a description of the reason for the transaction if included.|$|E
50|$|The Facebook {{privacy and}} {{copyright}} hoaxes are {{a collection of}} similar internet hoaxes that claim that posting a status on social networking site Facebook constitutes a <b>privacy</b> <b>notice</b> that protects your posts on the site from copyright infringement or that provides privacy protection to their profile information and other content they have posted to the site. The hoax {{takes the form of}} a Facebook status that, when posted, urges others to post the same or a similar status. The hoax first became popular in May and June 2012, but has since re-appeared multiple times, including in November 2012 and then again in 2015, first in January and later in September of that year. All of the hoaxes are based on several misunderstandings, including, with respect to the privacy version, the fact that it incorrectly assumes that Facebook becoming a public company in May 2012 affects how it treats user information, the assumption that posting certain content online can protect someone from adverse legal consequences, and the fact that the hoax ignores that if Facebook wanted to significantly change its terms of service agreement, it would have to provide notification of these changes.|$|E
40|$|A Web page {{typically}} {{contains many}} information blocks. Besides, the content blocks, it usually has such blocks as navigation panels, copyright and <b>privacy</b> <b>notices,</b> and advertisements. These blocks {{that are not}} the main content blocks of the page, we call them as noisy blocks. We show that {{the information contained in}} these noisy blocks can seriously harm Web data mining. Thus eliminating these noises is of great importance. In our work we focus on identifying and removing local noises in web pages to improve the performance of mining. A simple idea for detection and removal of noises a new DOM tree structure is proposed. The result shows the remarkable increase in F score and accuracy is obtained...|$|R
40|$|In today’s global economy, {{the flow}} of {{information}} is essential for the growth of international commerce and for the cross border access for both B 2 B and B 2 C services. The e-commerce phenomenon has elevated the privacy issue to a global platform. This paper examines the extent to which sample firms in four European countries post <b>privacy</b> <b>notices</b> on their websites. While posted privacy policy does not necessarily mean compliance with privacy protection policy, the absence of it indicates failure to comply with the most basic principle of privacy protection. We also reviewed the posted privacy policies of 425 firms and evaluated them against their corresponding country’s directives as well as fair information policies of th...|$|R
40|$|Abstract- A Web page {{typically}} {{contains many}} information blocks. Besides, the content blocks, it usually has such blocks as navigation panels, copyright and <b>privacy</b> <b>notices,</b> and advertisements. These blocks {{that are not}} the main content blocks of the page, we call them as noisy blocks. We show that {{the information contained in}} these noisy blocks can seriously harm Web data mining. Thus eliminating these noises is of great importance. In our work we focus on identifying and removing local noises in web pages to improve the performance of mining. A simple idea for detection and removal of noises a new DOM tree structure is proposed. The result shows the remarkable increase in F score and accuracy is obtained. Keywords- Noise elimination, DOM tree, Web page cleaning...|$|R
5000|$|The license has {{common terms}} against reverse {{engineering}} and copying, and it disclaims warranties and liability. Starting in 2016 the GeFORCE license says Nvidia [...] "SOFTWARE may access, collect non-personally identifiable information about, update, and configure Customer's system {{in order to}} properly optimize such system for use with the SOFTWARE." [...] The <b>privacy</b> <b>notice</b> goes on to say, [...] "We {{are not able to}} respond to [...] "Do Not Track" [...] signals set by a browser at this time. We also permit third party online advertising networks and social media companies to collect information... We may combine personal information that we collect about you with the browsing and tracking information collected by these and beacons technologies." [...] The software configures the user's system to optimize its use, and the license says, [...] "NVIDIA will have no responsibility for any damage or loss to such system (including loss of data or access) arising from or relating to (a) any changes to the configuration, application settings, environment variables, registry, drivers, BIOS, or other attributes of the system (or any part of such system) initiated through the SOFTWARE".|$|E
40|$|To be able {{to provide}} data {{collecting}} services to customers, service provides are required by law to design privacy policies and present their content to users as privacy notices that informs the user on privacy consequences and demonstrate that an explicit informed consent of the user has been collected before processing of the data. However, despite the increase in data collection by services and hence increase of privacy impact, yet privacy notices do not implement proper mechanisms that can assure that data subjects are well informed and their consent are provided with comprehension. The root of this problem is the fact that typically only theoretical description of what consent is and what it involves is offered by existing literature but no “practical” design guides are available for decision makers and practitioners on how to effectively integrate a targeted consent level in privacy notices. This thesis work addresses the need for explicit integration of consent in <b>privacy</b> <b>notice</b> designs by presenting the Extended <b>Privacy</b> <b>Notice</b> Design Space (XPNDS) construct that guides on explicitly incorporating different levels of consent in privacy notices. This thesis uses theories of eye movement in reading and technical references from computer vision for comprehension and attention determination to prove the feasibility of integrating higher level of consent in the design space that may guide to assured informed consent. The construct can be used by managers to communicate, practitioners to design, and regulators to analyze informed consent incorporation in <b>privacy</b> <b>notice</b> designs. Unlike most works available in the literature on consent which only provide theoretical opinion of what informed consent is, this work cast the conceptual consent guidelines in to a practical <b>privacy</b> <b>notice</b> design space to provide an XPNDS that guides to the practicality of achieving assured informed consent in privacy notices. It is the hope of the author that the XPNDS will be useful to both practitioners and academicians in incorporating informed consent in <b>privacy</b> <b>notice</b> designs to an assured level. Validerat; 20160622 (global_studentproject_submitter) </p...|$|E
40|$|Through a {{controlled}} online experiment with 447 Android phone users {{using their own}} devices, we investigated how em-powering users with information-disclosure control and en-hancing their ads awareness affect their installation behav-iors, information disclosure, and privacy perceptions toward different mobile apps. In the 3 (control: no, low, high) x 2 (ads awareness: absent, present) x 3 (app context: Wallpaper, BusTracker, Flashlight) fractional factorial between-subjects experiment, we designed <b>privacy</b> <b>notice</b> dialogs that simulate real Android app pre-installation privacy-setting interfaces to implement and manipulate control and ads awareness. Our findings suggest that empowering users with control over in-formation disclosure and enhancing their ads awareness be-fore installation effectively help them make better privacy de-cisions, increase their likelihood of installing an app, and im-prove {{their perceptions of the}} app. Implications for designing mobile apps ’ <b>privacy</b> <b>notice</b> dialogs and potential separate-ads-control solutions are discussed...|$|E
40|$|A typical consent dialog {{was shown}} in 2 × 2 × 3 {{experimental}} variations to 80, 000 users of an online privacy tool. We find that polite requests and button texts pointing to a voluntary decision decrease the probability of consent—in contrast to findings in social psychology. Our data suggests that subtle positive effects of polite requests indeed exist, but stronger negative effects of heuristic processing dominate the aggregated results. Participants seem to be habituated to coercive interception dialogs—presumably due to ubiquitous EULAs—and blindly accept terms the more their presentation resembles a EULA. Response latency and consultation of online help were taken as indicators to distinguish more systematic from heuristic responses. Author Keywords informed consent, <b>privacy</b> <b>notices,</b> EULA, default button, user behavior, field experiment, AN. ON/JonDonym ACM Classification Keyword...|$|R
40|$|The National Telecommunications and Information Administration (NTIA) has {{proposed}} a set of categories and definitions to create a United States national standard for short-form <b>privacy</b> <b>notices</b> on mobile devices. These notices are intended to facilitate user decision-making by categorizing both smartphone data to be shared and the entities with which that data is shared. In order to determine whether users consistently understand these proposed categories and their definitions, we conducted an online study with 791 participants. We found that participants had low agreement on how different data and entities should be categorized. We also compared our online results with those provided by four anonymous NTIA stakeholders, finding that even the stakeholders did not consistently categorize data or entities. Our work highlights areas of confusion for both survey participants and experts in the proposed scheme, and we offer suggestions for addressing these issues...|$|R
5000|$|The Health Insurance Portability and Accountability Act (HIPAA) <b>privacy</b> rules {{requires}} <b>notice</b> {{in writing}} of the privacy practices of health care services, and this requirement also applies if the health service is electronic.|$|R
