0|3300|Public
40|$|The {{association}} structure between manifest variables {{arising from}} the single-factor model is investigated using <b>partial</b> <b>correlations.</b> The additional insights to the practitioner provided by <b>partial</b> <b>correlations</b> for detecting a single-factor model are discussed. The parameter space for the <b>partial</b> <b>correlations</b> is presented, as are the patterns of signs in a matrix containing the <b>partial</b> <b>correlations</b> that are not compatible with a single-factor model. Key words: anti-image correlation matrix, elliptical tetrahedron, factor analysis, factor <b>partial</b> <b>correlation,</b> manifest <b>partial</b> <b>correlation...</b>|$|R
5000|$|To test if {{a sample}} <b>partial</b> <b>correlation</b> [...] implies a true {{population}} <b>partial</b> <b>correlation</b> of 0, Fisher's z-transform of the <b>partial</b> <b>correlation</b> can be used: ...|$|R
40|$|We {{propose a}} new <b>partial</b> <b>correlation</b> {{approach}} using Gaussian copula. Our empirical {{study found that}} the Gaussian copula <b>partial</b> <b>correlation</b> has the same value as that which is obtained by performing a Pearson's <b>partial</b> <b>correlation.</b> With the proposed method, based on canonical vine and d-vine, we captured direct interactions among eight histone genes. <b>Partial</b> <b>correlation</b> Gaussian copula Gene network...|$|R
50|$|It can be {{computationally}} {{expensive to}} solve the linear regression problems. Actually, the nth-order <b>partial</b> <b>correlation</b> (i.e., with |Z| = n) can be easily computed from three (n - 1)th-order <b>partial</b> <b>correlations.</b> The zeroth-order <b>partial</b> <b>correlation</b> ρXY·Ø is defined to be the regular correlation coefficient ρXY.|$|R
5000|$|Next {{we use the}} {{resulting}} node correlations to compute the <b>partial</b> <b>correlations.</b> The first order <b>partial</b> <b>correlation</b> coefficient is a statistical measure indicating how a third variable affects the correlation between two other variables. The <b>partial</b> <b>correlation</b> between nodes i and k {{with respect to a}} third node [...] is defined as: ...|$|R
40|$|<b>Partial</b> <b>correlations</b> are {{the natural}} {{interaction}} terms {{to be associated}} with the edges of the independence graph of a multivariate normal distribution. Two edges of the graph can thus be compared by comparing the corresponding <b>partial</b> <b>correlations.</b> The comparison of "dependent" correlations is a well known problem in statistics but, when the variables satisfy some conditional independence relations, the maximum likelihood estimates of <b>partial</b> <b>correlations</b> are different from the sample <b>partial</b> <b>correlations,</b> so that classical results no longer bold. In this paper we analyze to what extent the classical test statistics can be applied. We show that maximum likelihood estimates of <b>partial</b> <b>correlations</b> are more efficient than sample <b>partial</b> <b>correlations.</b> Furthermore we show that the conditional independence structure of the model can be used to turn the comparison of "dependent" correlations into the comparison of "independent" parameters...|$|R
40|$|Model {{selection}} for Gaussian concentration graph {{is based on}} multiple testing of pairwise conditional independence. In practical applications <b>partial</b> <b>correlation</b> tests are widely used. However {{it is not known}} whether <b>partial</b> <b>correlation</b> test is uniformly most powerful for pairwise conditional independence testing. This question is answered in the paper. Uniformly most powerful unbiased test of Neymann structure is obtained. It turns out, that this test can be reduced to usual <b>partial</b> <b>correlation</b> test. It implies that <b>partial</b> <b>correlation</b> test is uniformly most powerful unbiased one. Comment: 11 page...|$|R
40|$|An {{essential}} part of empirical economics research is {{the identification of the}} size of an empirical effect. <b>Partial</b> <b>correlations</b> offer a convenient statistically based measure of the strength of an economic relationship. A key question arises in their interpretation: When is a <b>partial</b> <b>correlation</b> large? This paper draws upon the observed distribution of 22, 000 <b>partial</b> <b>correlations</b> from a diverse group of economics fields. The median absolute <b>partial</b> <b>correlation</b> from these fields is 0. 173, which under Cohen’s (1988) conventional guidelines for zero order correlations is a small to moderate effect. The paper develops new guidelines for key qualitative categories (small, medium and large). According to the new guidelines, <b>partial</b> <b>correlations</b> that are larger than ± 0. 33 can be deemed to be large. This is considerably different to Cohen’s guideline of ± 0. 50 for zero order correlations. Researchers and meta-analysts should exercise caution when applying Cohen’s guidelines to describe the importance of <b>partial</b> <b>correlations</b> in economics. <b>partial</b> correlations; guidelines; empirical economics; meta-analysis...|$|R
40|$|Velicer (1976) {{proposed}} that, when conducting {{principal components}} analysis as a version of factor analysis, the number of components one should extract is that at which the average <b>partial</b> <b>correlation</b> of the variables, after partialling out m principal components, would be a minimum. minap calculates this minimum average <b>partial</b> <b>correlation.</b> It can take as input either a variable list or a correlation matrix. principal components, <b>partial</b> <b>correlation,</b> factor analysis...|$|R
50|$|The {{constraints}} {{on a regular}} vine {{may be associated with}} <b>partial</b> <b>correlations</b> or with conditional bivariate copula. In the former case, we speak of a <b>partial</b> <b>correlation</b> vine, and in the latter case of a vine copula.|$|R
40|$|ABSTRACT Plasma calcium {{increased}} {{during the}} two weeks prior to first egg. The increase was in the protein bound (Cajj) but not the ultrafilterable (Cay) fraction. Plasma neutral lipids (NL) and low density lipoprotein fraction (LDF, d. 6) and significant (P<. 01). The correlations tended to be greater in the stimulatory period than in the laying period. <b>Partial</b> <b>correlations</b> of the three estrogens with the other factors were calculated for the stimu-latory and laying periods. The <b>partial</b> <b>correlations</b> of E u were significant for all factors except Cap during the stimulatory period, but only with FFA, P p and Pj in the laying period. The <b>partial</b> <b>correlation</b> of Ej with LDF was significant in the stimulatory period, and for LDF, NL, and P; in the laying period. <b>Partial</b> <b>correlations</b> of Ej within the stimulatory period were not significant, but in the laying period a significant <b>partial</b> <b>correlation</b> with NL was noted...|$|R
40|$|<b>Partial</b> {{distance}} <b>correlation</b> measures {{association between}} two random vectors {{with respect to}} a third random vector, analogous to, but more general than (linear) <b>partial</b> <b>correlation.</b> Distance correlation characterizes independence of random vectors in arbitrary dimension. Motivation for the definition is discussed. We introduce a Hilbert space of U-centered distance matrices in which squared distance covariance is the inner product. Simple computation of the sample <b>partial</b> distance <b>correlation</b> and definitions of the population coefficients are presented. Power of the test for zero <b>partial</b> distance <b>correlation</b> is compared with power of the <b>partial</b> <b>correlation</b> test and the partial Mantel test. © Springer International Publishing Switzerland 2016...|$|R
40|$|Learning of {{large-scale}} networks of interactions from microarray data {{is an important}} and challenging problem in bioinformatics. A widely used approach is {{to assume that the}} available data constitute a random sample from a multivariate distribution belonging to a Gaussian graphical model. As a consequence, the prime objects of inference are full-order <b>partial</b> <b>correlations</b> which are <b>partial</b> <b>correlations</b> between two variables given the remaining ones. In the context of microarray data the number of variables exceed the sample size and this precludes the application of traditional structure learning procedures because a sampling version of full-order <b>partial</b> <b>correlations</b> does not exist. In this paper we consider limited-order <b>partial</b> <b>correlations,</b> these are <b>partial</b> <b>correlations</b> computed on marginal distributions of manageable size, and provide a set of rules that allow one to assess the usefulness of these quantities to derive the independence structure of the underlying Gaussian graphical model. Furthermore, we introduce a novel structure learning procedure based on a quantity, obtained from limited-order <b>partial</b> <b>correlations,</b> that we call the non-rejection rate. The applicability and usefulness of the procedure are demonstrated by both simulated and real data...|$|R
40|$|The {{concept of}} the inverse {{correlation}} function of a stationary process was introduced by Cleveland (Technometrics 14 (1972), 277 - 293). The inverse <b>partial</b> <b>correlation</b> function of a stationary process may intuitively {{be thought of as}} the corresponding extension of the {{concept of the}} <b>partial</b> <b>correlation</b> function. A precise mathematical definition of this function is given. Its importance in describing the structure of a moving average of finite order h is discussed. Having observed X 1, [...] .,XT, the autoregressive method of estimating the inverse correlations is employed for constructing sample estimates of the inverse <b>partial</b> <b>correlations.</b> For the hth-order moving average process, the estimates beyond h are, as T [...] > [infinity], asymptotically independent normally distributed with 0 mean and variance T- 1. Their use for estimating h and for testing hypotheses concerning h is examined. Inverse covariance function inverse <b>correlation</b> function <b>partial</b> <b>correlation</b> function inverse <b>partial</b> <b>correlation</b> function autoregressive spectral estimate moving average model...|$|R
30|$|The <b>partial</b> <b>correlation</b> {{analysis}} (PCA) {{was used}} to evaluate the relationships between the stand LAI and stand parameters. The PCA provides the correlations between two variables by controlling other variables that have important effect on the relation among these two variables. The PCA yields the <b>partial</b> <b>correlation</b> coefficients, which depict spurious and hidden correlations, including the effects of other variables. The <b>partial</b> <b>correlation</b> coefficients were obtained using PROC CORR procedures of the SAS/ETS v 9 software (SAS Institute Inc. 2012).|$|R
40|$|When {{dealing with}} {{graphical}} Gaussian models for gene regulatory networks, {{the major problem}} is to compute the matrix of <b>partial</b> <b>correlations.</b> Based on the close connection between <b>partial</b> <b>correlations</b> and least squares regression, we suggest estimation of high-dimensional gene networks in terms of partial least squares (PLS) regression and the adaptive Lasso, respectively. In a simulation study, we compare {{the performance of the}} proposed methods in terms of their ability to estimate <b>partial</b> <b>correlations</b> and to derive the underlying network structure. ...|$|R
5000|$|Correlations: Pearson {{product-moment}} correlation coefficient, Spearman's rank correlation coefficient, Kendall tau rank <b>correlation</b> coefficient, <b>Partial</b> <b>correlation,</b> Intraclass correlation ...|$|R
30|$|There {{is another}} type of linear <b>correlation,</b> namely the <b>partial</b> <b>correlation</b> that captures the direct {{influence}} between two variables, thereby eliminating the indirect influence via other variables. The <b>partial</b> <b>correlation</b> is useful for measuring the direct and indirect linkages between asset returns. Some previous research works including Kenett et al. (2010) and Kenett et al. (2015) have used the <b>partial</b> <b>correlation</b> to explore the underlying structures of stock markets. In this research, {{we focus on the}} standard correlation, since the overall interaction including indirect ones should be considered for many financial operations including portfolio optimization and risk quantification. The method proposed below, however, can be applied {{for the use of the}} <b>partial</b> <b>correlation</b> by converting the estimated standard <b>correlation</b> into the <b>partial</b> one.|$|R
40|$|In this article, {{we propose}} a {{computationally}} efficient approach—space (Sparse <b>PArtial</b> <b>Correlation</b> Estimation) —for selecting nonzero <b>partial</b> <b>correlations</b> under the high-dimension-low-sample-size setting. This method assumes the overall sparsity of the <b>partial</b> <b>correlation</b> matrix and employs sparse regression techniques for model fitting. We illustrate {{the performance of}} space by extensive simulation studies. It is shown that space performs well in both nonzero <b>partial</b> <b>correlation</b> selection and the identification of hub variables, and also outperforms two existing methods. We then apply space to a microarray breast cancer dataset and identify a set of hub genes that may provide important insights on genetic regulatory networks. Finally, we prove that, under a set of suitable assumptions, the proposed procedure is asymptotically consistent in terms of model selection and parameter estimation...|$|R
5000|$|... #Caption: The {{transition}} from normal (healthy) market behavior into abnormal seizure-like behavior {{at the end}} of 2001 (the vertical dashed line). Top is the S&P Index from March 7, 2000 until March 22, 2011. The third panel shows the stock correlations and the second panel shows the <b>partial</b> <b>correlations</b> (the correlations after subtraction of the index effect). The decrease in the <b>partial</b> <b>correlations</b> manifests the abnormal dominance of the Index. This effect is further pronounced when looking at the Index Cohesive Force - the ratio between the stock <b>correlations</b> and the <b>partial</b> <b>correlations,</b> shown at the bottom panel.|$|R
40|$|Functional {{connectivity}} {{has emerged}} as a promising approach to study the functional organisation of the brain and to define features for prediction of brain state. The most widely used method for inferring functional connectivity is Pearson-s correlation, but it cannot differentiate direct and indirect effects. This disadvantage is often avoided by computing the <b>partial</b> <b>correlation</b> between two regions controlling all other regions, but this method suffers from Berkson-s paradox. Some advanced methods, such as regularised inverse covariance, have been applied. However, these methods usually depend on some parameters. Here we propose use of minimum <b>partial</b> <b>correlation</b> as a parameter-free measure for the skeleton of functional connectivity in functional magnetic resonance imaging (fMRI). The minimum <b>partial</b> <b>correlation</b> between two regions is the minimum of absolute values of <b>partial</b> <b>correlations</b> by controlling all possible subsets of other regions. Theoretically, there is a direct effect between two regions if and only if their minimum <b>partial</b> <b>correlation</b> is non-zero under faithfulness and Gaussian assumptions. The elastic PC-algorithm is designed to efficiently approximate minimum <b>partial</b> <b>correlation</b> within a computational time budget. The simulation study shows that the proposed method outperforms o thers in most cases and its application is illustrated using a resting-state fMRI dataset from the human connectome project...|$|R
30|$|Where PRP is the {{percentage}} reduction in <b>partial</b> <b>correlation</b> {{with respect to}} the correlation coefficient, P.r is the <b>partial</b> <b>correlation</b> coefficient, and R 1 is the correlation coefficient between the predictor and predictand. Predictand variable which has high multi co-linearity with the super predictor variable is avoided.|$|R
50|$|In fact, if we {{compute the}} Pearson {{correlation}} coefficient between variables X and Y, {{the result is}} approximately 0.836, while if we compute the <b>partial</b> <b>correlation</b> between X and Y, using the formula given below, we find a <b>partial</b> <b>correlation</b> of 0.919, which is stronger than the full correlation.|$|R
40|$|<b>Correlation</b> and <b>partial</b> <b>correlation</b> {{are often}} used to provide a {{characterisation}} of the network properties of the human brain, based on functional brain imaging data. However, for <b>partial</b> <b>correlation,</b> the choice of network nodes (brain regions) and regularisation parameters is crucial and not yet well explored. Here we assess a number of approaches by calculating how each approach performs when used to discriminate different ongoing states of brain activity. We find evidence that <b>partial</b> <b>correlation</b> matrices, when estimated with appropriate regularisation, can provide a useful characterisation of brain functional connectivity. © 2013 IEEE...|$|R
40|$|Insight into brain {{development}} and organization can {{be gained by}} computing correlations between structural and functional measures in parcellated cortex. <b>Partial</b> <b>correlations</b> can often reduce ambiguity in correlation data by identifying those pairs of regions whose similarity cannot {{be explained by the}} influence of other regions with which they may both interact. Consequently a graph with edges indicating non-zero <b>partial</b> <b>correlations</b> may reveal important subnetworks obscured in the correlation data. Here we describe and investigate PC*, a graph pruning algorithm for identification of the <b>partial</b> <b>correlation</b> network in comparison to direct calculation of <b>partial</b> <b>correlations</b> from the inverse of the sample correlation matrix. We show that PC* is far more robust and illustrate its use in the study of covariation in cortical thickness in ROIs defined on a parcellated cortex...|$|R
40|$|Motivation: Gaussian {{graphical}} models (GGMs) are {{a popular}} tool for representing gene association structures. We propose using estimated <b>partial</b> <b>correlations</b> from these models to attach lengths {{to the edges}} of the GGM, where the length of an edge is inversely related to the <b>partial</b> <b>correlation</b> between the gene pair. Graphical lasso is used to fit the GGMs and obtain <b>partial</b> <b>correlations.</b> The shortest paths between pairs of genes are found. Where terminal genes have the same biological function intermediate genes on the path are classified as having the same function. We validate the method using genes of known function using the Rosetta Compendium of yeast (Saccharomyces Cerevisiae) gene expression profiles. We also compare our results with those obtained using a graph constructed using correlations. Results: Using a <b>partial</b> <b>correlation</b> graph, we are able to classify approximately twice as many genes to the same level of accuracy as when using a correlation graph. More importantly when both methods are tuned to classify a similar number of genes, the <b>partial</b> <b>correlation</b> approach can increase the accuracy of the classifications. Contact...|$|R
30|$|Relationships between banks can be {{measured}} by their <b>partial</b> <b>correlation,</b> that expresses the direct influence of a bank on another. <b>Partial</b> <b>correlations</b> can be estimated assuming that the observations follow a graphical Gaussian model, in which Σ is constrained by the conditional independence described by a graph (see e.g. [13]).|$|R
5000|$|The semipartial (or part) {{correlation}} statistic {{is similar}} to the <b>partial</b> <b>correlation</b> statistic. Both compare variations of two variables after certain factors are controlled for, but to calculate the semipartial correlation one holds the third variable constant for either X or Y but not both, whereas for the <b>partial</b> <b>correlation</b> one holds the third variable constant for both. The semipartial correlation compares the unique variation of one variable (having removed variation associated with the Z variable(s)), with the unfiltered variation of the other, while the <b>partial</b> <b>correlation</b> compares the unique variation of one variable to the unique variation of the other.|$|R
50|$|The {{distribution}} of the sample <b>partial</b> <b>correlation</b> was described by Fisher.|$|R
40|$|Currently, network-oriented {{analysis}} of fMRI data {{has become an}} important tool for understanding brain organization and brain networks. Among the range of network modeling methods, <b>partial</b> <b>correlation</b> has shown great promises in accurately detecting true brain network connections. However, the application of <b>partial</b> <b>correlation</b> in investigating brain connectivity, especially in large-scale brain networks, has been limited so far due to the technical challenges in its estimation. In this paper, we propose an efficient and reliable statistical method for estimating <b>partial</b> <b>correlation</b> in large-scale brain network modeling. Our method derives <b>partial</b> <b>correlation</b> based on the precision matrix estimated via Constrained L 1 -minimization Approach (CLIME) which is a recently developed statistical method that is more efficient and demonstrates better performance than the existing methods. To help select an appropriate tuning parameter for sparsity control in the network estimation, we propose a new Dens-based selection method that provides a more informative and flexible tool to allow the users to select the tuning parameter based on the desired sparse level. Another appealing feature of the Dens-based method {{is that it is}} much faster than the existing methods, which provides an important advantage in neuroimaging applications. Simulation studies show that the Dens-based method demonstrates comparable or better performance with expect to the existing methods in network estimation. We applied the proposed <b>partial</b> <b>correlation</b> method to investigate resting state functional connectivity using rs-fMRI data from the Philadelphia Neurodevelopmental Cohort (PNC) study. Our results show that <b>partial</b> <b>correlation</b> analysis removed considerable between-module marginal connections identified by full correlation analysis, suggesting these connections were likely caused by global effects or common connection to other nodes. Based on <b>partial</b> <b>correlation,</b> we find that the most significant direct connections are between homologous brain locations in the left and right hemisphere. When comparing <b>partial</b> <b>correlation</b> derived under different sparse tuning parameters, an important finding is that the sparse regularization has more shrinkage effects on negative functional connections than on positive connections, which supports previous findings that many of the negative brain connections were due to non-neurophysiological effects...|$|R
40|$|We {{investigate}} {{the possibility of}} exploiting <b>partial</b> <b>correlation</b> graphs for identifying interpretable latent variables underlying a multivariate time series. It is shown how the collapsibility and separation properties of <b>partial</b> <b>correlation</b> graphs {{can be used to}} understand the relation between a factor model and the structure among the observable variables. [...] Time series analysis,Dimension reduction,Factor analysis,Partial correlations...|$|R
40|$|Between-taxon {{interactions}} can {{be detected}} by calculating the sampling data of taxon sample type. In present study, Spearman rank correlation and proportion correlation are chosen as the general correlation measures, and their <b>partial</b> <b>correlations</b> are calculated and compared. The results show that for Spearman rank correlation measure, in all predicted candidate direct interactions by <b>partial</b> <b>correlation,</b> about 16. 77...|$|R
40|$|In this paper, an old {{identity}} of G. U. Yule among <b>partial</b> <b>correlation</b> coefficients {{is recognized as}} being equal to the cosine law of spherical trigonometry. Exploiting this connection enables us to derive some new (and potentially useful) relations among <b>partial</b> <b>correlation</b> coefficients. Moreover, this observation provides new (dual) non-Euclidean geometrical interpretations of the Schur and Levinson-Szegö algorithms...|$|R
40|$|In this paper, {{we propose}} a {{computationally}} efficient approach [...] space(Sparse <b>PArtial</b> <b>Correlation</b> Estimation) [...] for selecting non-zero <b>partial</b> <b>correlations</b> under the high-dimension-low-sample-size setting. This method assumes the overall sparsity of the <b>partial</b> <b>correlation</b> matrix and employs sparse regression techniques for model fitting. We illustrate {{the performance of}} space by extensive simulation studies. It is shown that space performs well in both non-zero <b>partial</b> <b>correlation</b> selection and the identification of hub variables, and also outperforms two existing methods. We then apply space to a microarray breast cancer data set and identify a set of hub genes which may provide important insights on genetic regulatory networks. Finally, we prove that, under a set of suitable assumptions, the proposed procedure is asymptotically consistent in terms of model selection and parameter estimation. Comment: A paper based on this report has been accepted for publication on Journal of the American Statistical Association([URL]...|$|R
40|$|In {{this paper}} {{we present a}} new measure to {{investigate}} the functional structure of financial markets, the Sector Dominance Ratio (SDR). We study the information embedded in raw and <b>partial</b> <b>correlations</b> using random matrix theory (RMT) and examine the evolution of economic sectoral makeup on a yearly and monthly basis for four stock markets, those of the US, UK, Germany and Japan, {{during the period from}} January 2000 to December 2010. We investigate the information contained in raw and <b>partial</b> <b>correlations</b> using the sector dominance ratio and its variation over time. The evolution of economic sectoral activities can be discerned through the largest eigenvectors of both raw <b>correlation</b> and <b>partial</b> <b>correlation</b> matrices. We find a characteristic change of the largest eigenvalue from raw and <b>partial</b> <b>correlations</b> and the SDR that coincides with sharp breaks in asset valuations. Finally, we propose the SDR as an indicator for changes in VIX indexes...|$|R
40|$|Spatial {{correlation}} between variables may exist if the observed data exhibits spatial variation {{in a manner}} that is described by Tobler's first law of geography. <b>Partial</b> <b>correlation</b> is useful when considering multivariate data as it can highlight the effects of certain control variables on the {{correlation between}} any two other variables. Techniques for estimating spatial correlation have been developed based on a geographically weighted scheme. However, a <b>partial</b> <b>correlation</b> technique for spatial data has not yet been considered. Hence, we describe a technique for obtaining geographically weighted <b>partial</b> <b>correlation</b> coefficients between three variables. This approach is then applied, as an example, to global climate data in order to explore the relationship between terrestrial vegetation (by NDVI proxy), land surface temperature, and precipitation in the year 2014. Spatial variations of those variables are observed and the geographically weighted <b>correlation</b> and <b>partial</b> <b>correlation</b> coefficients (along with associated levels of statistical significance) are compared...|$|R
