0|695|Public
2500|$|In 1917 and 1918, Pegram [...] {{served on}} a {{committee}} established by the National Research Council headed by the President of Columbia University, Nicholas Murray Butler, with Michael I. Pupin as its secretary, that created a quartz <b>piezo-electric</b> <b>sound</b> detector for locating submerged submarines. The device worked, and the Naval Experimental Station at New London, Connecticut, took over its development in September 1918. He was awarded an honorary Doctor of Science degree by Duke University in 1918.|$|R
5000|$|Arancia Scorenote (extra=Human, age 15, female, <b>Sound</b> <b>element)</b> ...|$|R
5000|$|... #Subtitle level 3: Overview of {{personal}} endings: typical <b>sound</b> <b>elements</b> ...|$|R
50|$|See {{also the}} section Overview of {{personal}} endings: typical <b>sound</b> <b>elements.</b>|$|R
40|$|When {{it comes}} to {{experiencing}} traditional sound design in movies, the audience is often presented with hidden mediation and production processes: abrupt sound changes are softened, noise and annoying reverb are avoided, unwanted <b>sound</b> <b>elements</b> are reduced and desired sounds are amplified. Sound designers make these kinds of selections to enhance the illusion of continuity {{in an attempt to}} engage the audience. In most cases this means the sound designer will compose a sound track and furthermore the audience is not aware of the sound designer’s mediation and manipulation. In sharp contrast to this, many movie trailers include <b>sound</b> <b>elements</b> in which traces of the mediation process are clearly recognised and connected to various visual elements like camera movements, cuts, dissolves and speed variations like slow motion. The following discussion revolves around movie trailers and the use of <b>sound</b> <b>elements</b> that in themselves draw attention to the process of production and mediation, also involving a discussion of how the various <b>sound</b> <b>elements</b> function...|$|R
5000|$|Fight Club (2009). Performed in {{a parking}} lot with {{lighting}} and <b>sound</b> <b>elements</b> provided by vehicles ...|$|R
5000|$|... 17.5 mm film, in this context, is for {{magnetic}} <b>sound</b> <b>elements</b> only, {{and only}} for very cost-conscious producers.|$|R
50|$|Both {{picture and}} <b>sound</b> <b>elements</b> {{for the film}} no longer exist, so the film is {{considered}} to be a lost film.|$|R
50|$|The Dance Chimes is a {{foot-operated}} chime-like {{musical instrument}} {{that consists of}} 9 bronze tiles, with mechanical <b>sound</b> <b>elements</b> under each.|$|R
5000|$|In the 1970's as {{a student}} at Otis she photographed the passage of time by photographing natural {{phenomena}} like shadows, waves and wind. At this time Grimmer started photographing blocks of ice and then freezing objects in blocks of ice [...] The <b>sound</b> <b>element</b> intrigued her and in 1980's Grimmer started adding the <b>sound</b> <b>element</b> of melting ice in her installations. [...] The first ice sculpture was shown at the Japan America Community Culture Center in downtown Los Angeles.|$|R
40|$|Some past {{studies suggest}} that when <b>sound</b> <b>elements</b> are heard as one object, the spatial cues in the {{component}} elements are integrated to determine perceived location, and that this integration is reduced when the elements are perceived in separate objects. The current study explored how object localization depends on the spatial, spectral, and temporal configurations of <b>sound</b> <b>elements</b> in an auditory scene. Localization results are interpreted in light of results {{from a series of}} previous experiments studying perceptual grouping of the same stimuli, e. g., Shinn-Cunningham et al. [Proc. Natl. Acad. Sci. U. S. A. 104, 12223 – 12227 (2007) ]. The current results suggest that the integration (pulling) of spatial information across spectrally interleaved elements is obligatory when these elements are simultaneous, even though past results show that these simultaneous <b>sound</b> <b>elements</b> are not grouped strongly into a single perceptual object. In contrast, perceptually distinct objects repel (push) each other spatially with a strength that decreases as the temporal separation between competing objects increases. These results show that the perceived location of an attended object is not easily predicted by knowledge of how <b>sound</b> <b>elements</b> contribute to the perceived spectro-temporal content of that object...|$|R
50|$|Altogether, nearly over a whole decade {{psychedelic}} <b>sounds,</b> <b>elements</b> of symphonic {{rock and}} electronic music mould Shamalls style {{of music in}} this era (1989-1999).|$|R
50|$|Francesco Filidei (born 1973 in Pisa) is an Italian organist and composer, {{student of}} Salvatore Sciarrino.He imagines music which {{has lost the}} <b>sound</b> <b>element.</b>|$|R
5000|$|Euternity October 2008: first {{electronic}} cover version. Created by Ukrainian music project, it mixes in the <b>sound</b> <b>elements</b> of electronic, pop-rock with opera vocals.|$|R
2500|$|In {{the context}} of motion {{pictures}} and television, sound effects refers to an entire hierarchy of <b>sound</b> <b>elements,</b> whose production encompasses many different disciplines, including: ...|$|R
50|$|According to Jan Hammer's manager Elliot Sears, {{the missing}} guitar lead hook {{was the result}} of the <b>sound</b> <b>elements</b> not being mixed {{together}} as Hammer intended.|$|R
5000|$|The text further {{describes}} how the sound fragments of the mantra [...] "Om Namo Narayanaya" [...] includes Brahma, Vishnu, Rudra, Ishvara, all of the universe, Purusha, Bhagavan and Param-atman (supreme self). Om is also the indestructible, unchanging reality (Brahman), states the text, which alone ought to be worshipped. The [...] "Om" [...] mantra has eight subtle <b>sound</b> <b>elements,</b> describes the Upanishad, [...] "A", [...] "U", [...] "M", bindu, nada, kala (era, present time), kalatita (beyond present era, or future), and the last subtle <b>sound</b> <b>element</b> is what is beyond kalatita.|$|R
50|$|A {{version of}} the film, with some <b>sound</b> <b>elements,</b> was made {{alongside}} the silent version. The film is credited as being the primary inspiration for Terrence Malick's Days of Heaven.|$|R
50|$|Since Kubrick's death, Vitali has overseen the {{restoration}} of both picture and <b>sound</b> <b>elements</b> for most of Kubrick's films. In 2004, Vitali was honored with the Cinema Audio Society's President's Award for this work.|$|R
5000|$|The song [...] "RAF" [...] by Brian Eno and Snatch (Judy Nylon/Patti Palladin) {{was created}} using <b>sound</b> <b>elements</b> from a Baader Meinhof ransom message {{available}} by public telephone {{at the time}} of the hijacking.|$|R
5000|$|The {{test and}} refine phase {{to where the}} {{combination}} of <b>sound</b> <b>elements</b> are optimized {{to ensure that they}} communicate essence, values, and promise of the brand. In this phase, psycho-acoustic research would be conducted, if needed.|$|R
40|$|This paper {{discusses}} {{the relationship between}} Malay and Lampung language, and attempts to answer the issue whether Lampung language is actually as old as Malay language. Malay language is considered more dominant them Lampung language, {{and the people are}} unclined to use Malay language. The result of reconstruction and comparative analyses of <b>sound</b> <b>elements</b> of lexicons indicate that Lampung language barrows and absorbs <b>sound</b> <b>elements</b> of Malay language. The status of relationship between Malay and Lampung language may be defined as languages of a family. People use Malay language to listeners outside his ethnic groups and use Lampung language on family and traditional ceremonies in the villag...|$|R
5000|$|In 1994, Sharon S., a Dutch act {{whose name}} was {{inspired}} by Robin S., used similar <b>sounded</b> <b>elements</b> of [...] "Show Me Love" [...] for their single [...] "Wonderful," [...] which was later sampled by Firebeatz in 2013.|$|R
5000|$|UK Hardcore is a {{genre of}} music which evolved from and {{incorporates}} <b>sound</b> <b>elements</b> from happy hardcore. UK Hardcore has a characteristically [...] "harder" [...] style and less break-beat {{associated with the}} happy hardcore music of the 1990s.|$|R
40|$|Our {{ability to}} {{understand}} auditory signals depends on properly separating the mixture of sound arriving from multiple sources. <b>Sound</b> <b>elements</b> tend to belong to only one object at a time, consistent with the principle of disjoint allocation, although there are instances of duplex perception or coallocation, in which two sound objects share one <b>sound</b> <b>element.</b> Here we report an effect of “nonallocation,” in which a <b>sound</b> <b>element</b> “disappears” when two ongoing objects compete for its ownership. When a target tone is presented either {{as one of a}} sequence of tones or simultaneously with a harmonic vowel complex, it is heard as part of the corresponding object. However, depending on the spatial configuration of the scene, if the target, the tones, and the vowel are all presented together, the target may not be perceived in either the tones or the vowel, even though it is not perceived as a separate entity. This finding suggests an asymmetry in the strength of the perceptual evidence required to reject vs. to include an element within the auditory foreground, a result with important implications for how we process complex auditory scenes containing ambiguous information...|$|R
40|$|Auditory system detects {{sound signals}} {{and uses the}} temporal-frequency {{information}} of the sound signals to conduct sound identification, sound localization, and sound source separation. Thanks to the past studies, {{we know that the}} hair cells at cochlea show frequency-dependent responses against input sound signals. But, little is known about how the sound information is conducted to and processed within the auditory cortex. Recently, B. A. Pearlmutter and A. M. Zador proposed an algorithm for monaural source separation under the assumption that the precise head-related transfer function (HRTF) and all the <b>sound</b> dictionary <b>elements</b> are known (ref. [1]). To apply this algorithm to the real sound signals, here I propose that non-negative matrix factorization (NMF) applied to the spectrograms of sound signals would successfully give a set of <b>sound</b> dictionary <b>elements.</b> When NMF was applied to solo-music signals with an appropriate value for the rank of factorization, it could extract instrument-specific patterns of basis spectrograms, each of which has a peak frequency for different notes. Interestingly, the sound signals converted back from the obtained basis spectrograms sounded more or less like the corresponding instrument, which suggests that the obtained basis spectrograms, or basis <b>sound</b> <b>elements,</b> would be a good candidate for the sound dictionary. When NMF was applied to sound signals played with several different instruments, the obtained basis <b>sound</b> <b>elements</b> can be categorized into each instrument-specific pattern by hand. In addition, using the categorized <b>elements,</b> <b>sound</b> signals can be reconstructed corresponding to each instrument part of the original music. The fact that source separation can be done using the basis <b>sound</b> <b>elements</b> obtained by NMF suggests that NMF would be a possible way to learn sound dictionaries from sound signals. ...|$|R
50|$|Hideaki Ishi (born July 29, 1962), {{better known}} by his stage name DJ Krush, {{is a record}} {{producer}} and DJ. He {{is known for his}} atmospheric instrumental production which incorporates <b>sound</b> <b>elements</b> from nature and extensive use of jazz and soul samples.|$|R
50|$|The {{original}} motion picture score was composed by Harry Gregson-Williams. Alan Meyerson mixed the <b>sound</b> <b>elements</b> for the chorus, while Richard Whitfield edited the film's music. The soundtrack {{for the film}} was released on March 10, 1998 by the Varèse Sarabande music label.|$|R
50|$|The {{original}} motion picture soundtrack was composed by musician John Powell. Jorge Adrados mixed the <b>sound</b> <b>elements</b> for the chorus, while Jon Olive edited the film's music. The soundtrack {{for the film}} was released on March 9, 2010, by the Varèse Sarabande music label.|$|R
50|$|After a {{long time}} rehearsing and {{practicing}} their work they moved {{to work in a}} studio. With the real scene around them their band's 'sound' really started coming through. Their vocal and instrumental style had <b>sound</b> <b>elements</b> of pop, while still maintaining a distinct rocking edge.|$|R
5000|$|UK {{hardcore}} is a {{genre of}} music which evolved from and incorporates <b>sound</b> <b>elements</b> from happy hardcore. UK hardcore has a characteristically [...] "harder" [...] style by it's [...] "thicker" [...] harsher bassline as wells as less break-beat {{associated with the}} happy hardcore music of the 1990s.|$|R
50|$|After studying, Brody {{was searching}} for ways of {{expanding}} performance and interaction with his audiences. His early works attempt to break the barriers of the traditional performance environment, and he often interacts directly with his audiences or creates multidimensional installations using <b>sound,</b> <b>elements</b> of performance art, and video.|$|R
50|$|Get Crazy is not {{currently}} in print. Embassy Home Entertainment released the film on VHS in the 1980s, but no DVD edition of Get Crazy {{has been released}} as of 2013. Director Allan Arkush has stated that a DVD release is unlikely, due to issues with the <b>sound</b> <b>elements.</b>|$|R
50|$|Seven Footprints to Satan is {{the fifth}} of seven films made by Christensen during his tenure in Hollywood, {{and is one of}} only four that survive in a {{relatively}} complete state (Eagle's Nest and Haunted House are believed to be lost; House of Horror exists only in <b>sound</b> <b>elements).</b>|$|R
50|$|Generation and {{manipulation}} of <b>sound</b> <b>elements</b> {{is widely used}} {{in a variety of}} human-computer interfaces, in computer games and video games. Almost all large productions have one or a few sound designers. Without these sound designers, the audio of the production would not be as rich and realistic to the audience.|$|R
40|$|Research {{regarding}} children 2 ̆ 7 s instrumental articulation {{development has}} provided the speech clinician with schedules of speech sound development. These developmental tables list ages when specific phonemes are mastered by normal children. Such schedules tend {{to give the impression}} that certain sounds must be developed before others can occur. Menyuk (1972) has expressed a similar point of view regarding phonemes /t/ and /k/. She has hypothesized: that phoneme /t/ must develop before phoneme /k/; and that <b>sound</b> <b>element</b> initial /t/ is mastered at an earlier age than initial /k/. The present investigation was designed to operationally test the validity of Menyuk 2 ̆ 7 s observations. The primary purpose of this study was to determine the ages at which phonemes /t/ and /k/ are mastered by normally developing children, thereby obtaining the order in which these phonemes are learned. A secondary purpose was to present an alternative to the concept of mastery of speech sounds by determining the ages at which children acquire phonemes /t/ and /k/. Four specific questions were posed by this study: Is phoneme /t/ mastered before phoneme /k/? Is <b>sound</b> <b>element</b> initial [t mastered before initial [k]? What is the order of mastery of the remaining two <b>sound</b> <b>elements</b> of each phoneme? What is the order of acquisition of the two phonemes...|$|R
