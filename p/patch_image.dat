9|2135|Public
5000|$|In Top Gun, {{starring}} Tom Cruise, {{during any}} flight scenes one can clearly see [...] "GOOSE VF-1" [...] on LTJG Nick Bradshaw's (Anthony Edwards') flight helmet, {{as well as}} when {{they are on the}} USS Enterprise in the opening scenes of the movie, where the tail flash of the VF-1 is clearly visible in some of the shots. On Maverick's flight suit, he wears a squadron patch that says [...] "VF-1" [...] on the scroll underneath, but the <b>patch</b> <b>image</b> is that of VAW-110, which at the time served as the west coast fleet replacement squadron for the E-2 Hawkeye.|$|E
40|$|The {{programs}} presented {{are intended}} to provide a way to extract a sample from a full-frame scene and summarize it in a useful way. The sample in each case was chosen to fill a 512 -by- 512 pixel (sample-by-line) image since {{this is the largest}} image that can be displayed on the Integrated Multivariant Data Analysis and Classification System. This sample size provides one megabyte of data for manipulation and storage and contains about 3 % of the full-frame data. A <b>patch</b> <b>image</b> processor computes means for 256 32 -by- 32 pixel squares which constitute the 512 -by- 512 pixel image. Thus, 256 measurements are available for 8 vegetation indexes over a 100 -mile square...|$|E
40|$|In this paper, {{we propose}} a method called Convolutional Neural Network-Markov Random Field (CNN-MRF) to {{estimate}} the crowd count in a still image. We first divide the dense crowd visible image into overlapping patches and then use a {{deep convolutional neural network}} to extract features from each <b>patch</b> <b>image,</b> followed by a fully connected neural network to regress the local patch crowd count. Since the local patches have overlapping portions, the crowd count of the adjacent patches has a high correlation. We use this correlation and the Markov random field to smooth the counting results of the local patches. Experiments show that our approach significantly outperforms the state-of-the-art methods on UCF and Shanghaitech crowd counting datasets. Comment: 6 pages, 6 figures, JACIII Vol. 21 No. ...|$|E
30|$|Aligned single JPEG {{compressed}} (ASJPEG in short): When the uncompressed <b>image</b> <b>patches</b> {{undergo a}} JPEG compression with the block structure aligned to the <b>image</b> <b>patch,</b> the output <b>image</b> <b>patches</b> are called ASJPEG patches. They are usually {{referred to as}} single JPEG <b>image</b> <b>patches</b> in the literature.|$|R
40|$|A {{method for}} {{compressing}} a digital image comprises the steps of:selecting an <b>image</b> <b>patch</b> {{of the digital}} image; assigning the selected <b>image</b> <b>patch</b> to a specific class (z); transforming the <b>image</b> <b>patch,</b> with a pre-determined class-specific transformation function; and quantizing the transformed <b>image</b> <b>patch...</b>|$|R
50|$|Advanced {{technology}} allows {{virtually any}} design to be recreated in thread on an embroidered <b>patch.</b> <b>Images</b> previously created by {{hand in a}} time-consuming process can now be quickly, digitally scanned, and computer-controlled, with multi-head sewing machines use several colors of thread simultaneously.|$|R
40|$|A kind of {{interference}} measurement system with crystal is designed, {{which is not}} influenced much by other factors such as vibration for the property of common path. For the distance measurement, the phase of fringes is calculated on the oblique incident holography to avoid effects of fringe curvature, backup and light fluctuation. But the measurement result {{is affected by the}} uniformity of the crystal, and another method of adjusting position based on normal incident holography is also discussed. B-splines function is used to calculate zero position in normal incident holography, which is fitted over the <b>patch</b> <b>image</b> around gray extreme points of the stripes obtained by gray projection. Experiment results show that combining the normal and oblique incident holography reduce the repeatability error of the system and improve the measurement precision effectively. </p...|$|E
40|$|Recent {{advances}} in image processing for atmospheric propagation {{have provided a}} foundation for tackling the similar but perhaps more complex problem of underwater imaging, which is impaired by scattering and optical turbulence. As {{a result of these}} impairments underwater imagery suffers from excessive noise, blur, and distortion. Underwater turbulence impact on light propagation becomes critical at longer distances as well as near thermocline and mixing layers. In this work, we demonstrate a method for restoration of underwater images that are severely degraded by underwater turbulence. The key element of the approach is derivation of a structure tensor oriented image quality metric, which is subsequently incorporated into a lucky <b>patch</b> <b>image</b> processing framework. The utility of the proposed image quality measure guided by local edge strength and orientation is emphasized by comparing the restoration results to an unsuccessful restoration obtained with equivalent processing utilizing a standard isotropic metric. Advantages of the proposed approach versus three other state-of-the-art image restoration techniques are demonstrated using the data obtained in the laboratory water tank and in a natural environment underwater experiment. Quantitative comparison of the restoration results is performed via structural similarity index measure and normalized mutual information metric...|$|E
40|$|When facing {{extremely}} complex infrared background, due to {{the defect}} of 11 norm based sparsity measure, the state-of-the-art infrared patch-image (IPI) model {{would be in a}} dilemma where either the dim targets are over-shrinked in the separation or the strong cloud edges remains in the target image. In order to suppress the strong edges while preserving the dim targets, a weighted infrared <b>patch</b> <b>image</b> (WIPI) model is proposed, incorporating structural prior information into the process of infrared small target and background separation. Instead of adopting a global weight, we allocate adaptive weight to each column of the target patch-image according to its patch structure. Then the proposed WIPI model is converted to a column-wise weighted robust principal component analysis (CWRPCA) problem. In addition, a target unlikelihood coefficient is designed based on the steering kernel, serving as the adaptive weight for each column. Finally, in order to solve the CWPRCA problem, a solution algorithm is developed based on Alternating Direction Method (ADM). Detailed experiment results demonstrate that the proposed method has a significant improvement over the other nine classical or state-of-the-art methods in terms of subjective visual quality, quantitative evaluation indexes and convergence rate. (C) 2016 Elsevier B. V. All rights reserved. </p...|$|E
40|$|Motivated by {{the fact}} that <b>image</b> <b>patches</b> could be {{inherently}} represented by matrices, single-image super-resolution is treated as a problem of learning regression operators in a matrix space in this paper. The regression operators that map low-resolution <b>image</b> <b>patches</b> to high-resolution <b>image</b> <b>patches</b> are generally defined by left and right multiplication operators. The pairwise operators are respectively used to extract the raw and column information of low-resolution <b>image</b> <b>patches</b> for recovering high-resolution estimations. The patch based regression algorithm possesses three favorable properties. Firstly, the proposed super-resolution algorithm is efficient during both training and testing, because <b>image</b> <b>patches</b> are treated as matrices. Secondly, the data storage requirement of the optimal pairwise operator is far less than most popular single-image super-resolution algorithms because only two small sized matrices need to be stored. Lastly, the super-resolution performance is competitive with most popular single-image super-resolution algorithms because both raw and column information of <b>image</b> <b>patches</b> is considered. Experimental results show the efficiency and effectiveness of the proposed patch-based single-image superresolution algorithm...|$|R
30|$|Shifted single JPEG {{compressed}} (SSJPEG in short): Different from SDJPEG <b>patches,</b> {{when the}} <b>image</b> <b>patches</b> before the shifted JPEG compression (with the block structure in dashed line) {{have never been}} compressed with the block structure starting from the top-left corner, the output <b>image</b> <b>patches</b> are called SSJPEG patches.|$|R
30|$|In {{order to}} achieve better results for image denoising, a shape-adaptive BM 3 D (SA-BM 3 D) [37] has been {{proposed}} by combining the advantages of both BM 3 D and SA-DCT. Specifically, SA-BM 3 D groups similar shape-adaptive neighborhoods (such as <b>image</b> <b>patches),</b> instead of shape-fixed image blocks in the BM 3 D method. In this way, the adaptation of non-local model, and also the local image characteristics, can be simultaneously used by particularly improving the spatial correlation within each <b>image</b> <b>patch.</b> As each <b>image</b> <b>patch</b> is not necessarily square, the orthogonal wavelet transform cannot be directly applied to the shape-adaptive <b>image</b> <b>patch.</b> Therefore, SA-DCT is first used on each shape-adaptive <b>image</b> <b>patch,</b> and then one-dimensional orthogonal wavelet transform is performed in the third dimension, followed by shrinking the transform coefficients with hard thresholding or Wiener filtering to finally achieve image denoising.|$|R
40|$|Remote sensing image {{clustering}} is {{a challenging}} task considering its intrinsic complexity. Recently, {{by combining the}} spectral and spatial information of the remote sensing data, the clustering performance can be dramatically enhanced, termed as Spectral-Spatial Clustering (SSC). However, {{it has always been}} difficult to determine the weight parameter for balancing the spectral term and spatial term of the clustering objective function. In this paper, spectral-spatial clustering with a local weight parameter determination method for remote sensing image was proposed, i. e., L-SSC. In L-SSC, considering the large scale of remote sensing images, the weight parameter can be determined locally in a <b>patch</b> <b>image</b> instead of the whole image. Afterwards, the local weight parameter was used in constructing the objective function of L-SSC. Thus, the remote sensing image clustering problem was transformed into an optimization problem. Finally, in order to achieve a better optimization performance, a variant of differential evolution (i. e., jDE) was used as the optimizer due to its powerful optimization capability. Experimental results on three remote sensing images, including a Wuhan TM image, a Fancun Quickbird image, and an Indian Pine AVIRIS image, demonstrated that the proposed L-SSC can acquire higher clustering accuracy in comparison to other spectral-spatial clustering methods...|$|E
40|$|AbstractSalient stimuli {{are more}} readily {{detected}} than less salient stimuli, and {{individual differences in}} such detection may be relevant to why some people fail to notice an unexpected stimulus that appears in their visual field whereas others do notice it. This failure to notice unexpected stimuli is termed ‘Inattentional Blindness’ and {{is more likely to}} occur when we are engaged in a resource-consuming task. A genetic algorithm is described in which artificial stimuli are created using a saliency model as its fitness function. These generated stimuli, which vary in their saliency level, are used in two studies that implement a pop-out visual search task to evaluate the power of the model to discriminate the performance of people who were and were not Inattentionally Blind (IB). In one study the number of orientational filters in the model was increased to check if discriminatory power and the saliency estimation for low-level images could be improved. Results show that the performance of the model does improve when additional filters are included, leading to the conclusion that low-level images may require a higher number of orientational filters for the model to better predict participants’ performance. In both studies we found that given the same target <b>patch</b> <b>image</b> (i. e. same saliency value) IB individuals take longer to identify a target compared to non-IB individuals. This suggests that IB individuals require a higher level of saliency for low-level visual features in order to identify target patches...|$|E
40|$|In {{this paper}} we analyze sampled high {{dimensional}} data with the NEB method {{from a range}} image database. Select a large random sample of log-valued, high contrast, normalized, 8 × 8 range <b>image</b> <b>patches</b> from the Brown database. We make a density estimator and we establish 1 -dimensional cell complexes from the range <b>image</b> <b>patch</b> data. We find topological properties of 8 × 8 range <b>image</b> <b>patches,</b> prove that there exist two types of subsets of 8 × 8 range <b>image</b> <b>patches</b> modelled as a circle...|$|R
40|$|Diabetic retinopathy, {{a subject}} of many studies in the medical image {{processing}} field since long time, {{is one of the}} major complications of diabetes mellitus and it cause blindness. In this study, we proposed a method that consist of keypoint detector-feature extraction-reduction process and classifier stages within the framework of hybrid approach for the detection of hard exudates. This method is divided into two parts: learning and querying. In the learning phase, initially we created visual dictionaries for the representation of pathological or non-pathological regions on retinal images. After, we completed modeling process with the training and testing processes. In the querying phase, keypoints and <b>patch</b> <b>images</b> are obtained with keypoint detector algorithm from new retinal images. Thus, knowledge is obtained by these <b>patch</b> <b>images</b> are classified in the final part of this phase. Experimental validation was performed on DIARETDB 1 public database. The obtained results are showed us that positive effects of machine learning technique suggested by us for diagnosis of exudate...|$|R
40|$|The {{effect of}} <b>image</b> <b>patch</b> size on phase {{difference}} determination by fringe pattern matching is discussed, The standard deviations {{based on the}} measurements from different sizes of <b>image</b> <b>patches</b> are derived from the statistical analysis of the fringe pattern matching process. The effect of <b>image</b> <b>patch</b> size on phase difference determination is examined by both computer simulation and experimentation. The background noise levels of interferograms are obtained by computer generated speckle noise, Gaussian noise {{and salt and pepper}} noise added to ideal fringe patterns, and the results from different sizes of <b>image</b> <b>patches</b> were acquired by fringe pattern matching in the simulation. The experimental results were also achieved from different sizes of <b>image</b> <b>patches.</b> The computer simulation and experimental results have shown that the larger <b>image</b> <b>patches</b> have a better accuracy in the presence of noise, which is in accordance with the results from theoretical analysis. (C) 1997 Society of Photo-Optical instrumentation Engineers...|$|R
40|$|<b>Image</b> <b>patches</b> are {{fundamental}} elements for object modeling and recognition. However, {{there has not}} been a panoramic study in the literature on the structures of the whole ensemble of natural <b>image</b> <b>patches.</b> In this article, we study the mathematical structures of the ensemble of natural <b>image</b> <b>patches</b> and map <b>image</b> <b>patches</b> into two types of subspaces which we call “explicit manifolds” and “implicit manifolds” respectively. On explicit manifolds, one finds those simple and regular image primitives, such as edges, bars, corners and junctions. On implicit manifolds, one finds those complex and stochastic <b>image</b> <b>patches,</b> such as textures and clutters. On these manifolds, different perceptual metrics are used. Then we show a unified framework for learning a probabilistic model on the space of patches by pursuing both types of manifolds under a common information theoretical principle. The connection between the two types of manifolds are realized through image scaling which changes the entropy of the <b>image</b> <b>patches.</b> The explicit manifolds live in low entropy regimes while the implicit manifolds live in high entropy regimes. In experiments, we cluster the natural <b>image</b> <b>patches</b> and compare the two types of manifolds with a common information theoretical criterion. We also study the transition of the manifolds over scales and show that the complexity peak in a middle entropy regime where most objects and parts reside...|$|R
40|$|Abstract. We {{propose a}} super-resolution method that {{exploits}} selfsimilarities and group structural information of <b>image</b> <b>patches</b> using only one single input frame. The super-resolution problem is posed as learning the mapping between pairs of low-resolution and high-resolution <b>image</b> <b>patches.</b> Instead {{of relying on}} an extrinsic set of training images as often required in example-based super-resolution algorithms, we employ a method that generates image pairs directly from the image pyramid of one single frame. The generated patch pairs are clustered for training a dictionary by enforcing group sparsity constraints underlying the <b>image</b> <b>patches.</b> Super-resolution <b>images</b> are then constructed using the learned dictionary. Experimental results show the proposed method is able to achieve the state-of-the-art performance. ...|$|R
40|$|Abstract — In this paper, {{we propose}} online-learned {{classifiers}} for data association in multitarget tracking. The classifiers are dynamically constructed and incrementally online learned using <b>image</b> <b>patches,</b> which are associated based on location proimity. A biological inspired architecture {{is used to}} compute the classification label of <b>image</b> <b>patch.</b> The extracted <b>image</b> <b>patches</b> are coded and learned by a 3 -layer neural network that implements in-place learning. We employ minimum-cost network flow optimization to associate tracks with the <b>image</b> <b>patches</b> based on their appearance and location proximities. The presented framework is applied to learn 11 targets encountered in a PETS 2009 data set. Cross validation {{results show that the}} overall recognition accuracy is above 93 %. The comparison with other learning algorithms is promising. The results of the implemented multitarget tracker demonstrate the effectiveness of the approach. Key Workds: Intelligent video surveillance system, object learning, and biologically inspired neural network...|$|R
40|$|Many visual tasks {{involve the}} {{matching}} of <b>image</b> <b>patches</b> derived from imaging {{a scene from}} different viewpoints. Matching two <b>image</b> <b>patches</b> can, however, be a difficult task. This is because changes in the relative orientation of a surface {{with respect to a}} camera cause deformations {{in the image of the}} surface. Thus this deformation needs to be taken into account when matching or registering two <b>image</b> <b>patches</b> of an object under changes in viewpoint. Up to first order these deformations can be described using an affine transform. ^ Here, a computational scheme to match two <b>image</b> <b>patches</b> under an affine transform is presented. The two <b>image</b> <b>patches</b> are filtered with Gaussian and derivative of Gaussian filters. The problem of matching the two <b>image</b> <b>patches</b> is then recast as one of finding amount by which these filters must be deformed so that the filtered outputs from the two images are equal. For robustness, it is necessary to use the filter outputs from many points in a small region to obtain an overconstrained system of equations. The resulting equations are linearized with respect to the affine transforms and then iteratively solved for the affine transforms. The method is local and can match <b>image</b> <b>patches</b> in situations where other algorithms fail. It is also shown that the same framework may be used to match points and lines. ...|$|R
3000|$|Now we {{have all}} the tools {{required}} for an OMP algorithm that perform the sparse coding stage in optimal SSIM sense. The modified OMP pursuit algorithm is explained in Algorithm 1. There are two main differences between the OMP algorithm [29] and the one proposed in this work. First, the stopping criterion is based on SSIM. Unlike MSE, SSIM is adaptive according to the reference image. In particular, if the distortion is consistent with the underlying reference e.g., contract enhancement, the distortion is non-structural and is much less objectional than structural distortions. Defining the stopping criterion according to SSIM essentially means that we are modifying the set of accepted points (<b>image</b> <b>patches)</b> around the noisy <b>image</b> <b>patch</b> which can be represented as the linear combination of dictionary atoms. This way, in the space of <b>image</b> <b>patches,</b> we are omitting <b>image</b> <b>patches</b> in the direction of structural distortion and including the ones which are {{in the same direction as}} the original <b>image</b> <b>patch</b> in the set of acceptable <b>image</b> <b>patches.</b> Therefore, we can expect to see more structures in the image constructed using sparsity as a prior. Second, we calculate the SSIM-optimal coefficients from the optimal coefficients in [...]...|$|R
40|$|This paper {{proposes a}} Fully Affine Invariant Feature (FAIF) {{detector}} {{which is based}} on affine Gaussian scale-space. The covariance matrix of Maximally Stable Extremal Region is interpreted as an isotropy measure of an <b>image</b> <b>patch.</b> A local anisotropic <b>image</b> <b>patch</b> can be supposed as an affine transformed isotropic <b>image</b> <b>patch.</b> Therefore, the affine deformation of a MSER can be estimated by its covariance matrix. According to affine Gaussian scale-space theory, filters must be compatible with local image structures. An anisotropic <b>image</b> <b>patch</b> should be smoothed by an elliptical Gaussian filter which is difficult to be constructed directly. In order to use circular Gaussian filters, FAIF transforms affine Gaussian scale-space into scale space by the way that rotating and compressing an anisotropic image region into an isotropic one. The fully affine invariant features are detected on isotropic <b>image</b> <b>patches</b> by Scale Invariant Feature Transform (SIFT) algorithm. Experimental results show that FAIF has much more matches than the state-of-the-art algorithms. The International Association for Pattern Recognitio...|$|R
40|$|The problem {{considered}} {{here is how}} {{to select}} the feature points (in practice small <b>image</b> <b>patches</b> are used) in an image from an image sequence, such {{that they can be}} tracked well further through the sequence. Usually, tracking is performed by some sort of local search methods searching for a similar patch in the next image from the sequence. Therefore, it would be useful if we could estimate 'the size of the convergence region' for each <b>image</b> <b>patch.</b> It is less likely to erroneously calculate the displacement for an <b>image</b> <b>patch</b> with a large convergence region than for an <b>image</b> <b>patch</b> with a small convergence region. Consequently, the size of the convergence region {{can be used as a}} proper goodness measure for a feature point. For the standard Kanade-Lucas-Tomasi (KLT) tracking method we propose a simple and fast method to approximate the convergence region for an <b>image</b> <b>patch.</b> In the experimental part we test our hypothesis on a large set of real data...|$|R
40|$|This thesis {{presents}} {{a new approach}} to single-image super-resolution (SR), based on sparse signal recovery. Research on image statistics suggests that <b>image</b> <b>patches</b> can be well represented as a sparse linear combination of elements from an appropriately chosen over-complete dictionary. Inspired by this observation, we seek a sparse representation for each patch of the low-resolution input, and then use the coefficients of this representation to generate the high-resolution output. Theoretical results from compressed sensing suggest that under mild conditions, the sparse representation can be correctly recovered from the downsampled signals. By jointly training two dictionaries for the low- and high-resolution <b>image</b> <b>patches,</b> we can enforce the similarity of sparse representations between the low- and high-resolution <b>image</b> <b>patch</b> pairs with respect to their own dictionaries. Therefore, the sparse representation of a low-resolution <b>image</b> <b>patch</b> can be applied with the dictionary of high-resolution <b>image</b> <b>patches</b> to generate a high-resolution <b>image</b> <b>patch.</b> Compared to previous approaches, which simply sample a large amount of raw <b>image</b> <b>patch</b> pairs, the learned dictionary pair is a more compact representation of the patch pairs, and, therefore, reduces the computation cost substantially. The effectiveness of such a sparsity prior is demonstrated on both general image super-resolution and the special case of face hallucination. In both cases, our algorithm can generate high-resolution images that are competitive or superior in quality to images produced by other similar SR methods, but with much faster processing speed...|$|R
3000|$|..., is {{obtained}} as follows. Since the SSJPEG patch {{has never been}} compressed with the block structure starting from the top-left corner of the <b>image</b> <b>patch,</b> the DCT coefficients of SSJPEG can be assumed distributed approximately as the original uncompressed <b>image</b> <b>patch</b> [8, 14]. Moreover, [...]...|$|R
30|$|For a {{specific}} {QF 1,QF 2 } pair, 10, 000 <b>image</b> <b>patches</b> are randomly {{extracted from the}} uncompressed image database. The ‘positive’ samples are constructed by performing shifted JPEG compression with quality factor of QF 1 and random coordinate shifts (x S, y S) (0 [*]≤[*]x S, y S[*]≤[*] 7 and (x S, y S)[*]≠[*](0, 0)) and then saving the <b>image</b> <b>patches</b> in JPEG format with QF 2. The ‘negative’ samples are constructed by directly saving the same uncompressed <b>image</b> <b>patches</b> in JPEG with QF 2.|$|R
40|$|Motion {{confidence}} measures aim {{to identify}} how well an <b>image</b> <b>patch</b> determines <b>image</b> motion. These kinds of confidence measures {{are commonly used}} to select points for optical flow estimation and feature tracking. The brute force approach of computing confidence for every <b>image</b> <b>patch</b> is inefficient, especially when the patches are large. The faster approach of computing confidence for a regular grid of patches is sub-optimal; good patches may be missed because they straddle grid boundaries. We present a new algorithm that efficiently selects globally optimal patches. Our primary innovation {{is the use of}} confidence bounds to identify image regions that should be explored by a queue-based search algorithm...|$|R
40|$|Matching of keypoints across <b>image</b> <b>patches</b> {{forms the}} basis of {{computer}} vision applications, such as object detection, recognition, and tracking in real-world images. Most of keypoint methods are mainly used to match the high-resolution images, which always utilize an image pyramid for multiscale keypoint detection. In this paper, we propose a novel keypoint method to improve the matching performance of <b>image</b> <b>patches</b> with the low-resolution and small size. The location, scale, and orientation of keypoints are directly estimated from an original <b>image</b> <b>patch</b> using a Log-Spiral sampling pattern for keypoint detection without consideration of image pyramid. A Log-Spiral sampling pattern for keypoint description and two bit-generated functions are designed for generating a binary descriptor. Extensive experiments show that the proposed method is more effective and robust than existing binary-based methods for <b>image</b> <b>patch</b> matching...|$|R
40|$|This paper {{presents}} a content-based image retrieval technique based on interest points matching and geometric hashing. We estimate points with significant luminance variations as interest points. A small region around the interest point is located as an <b>image</b> <b>patch.</b> Low-level features are extracted to describe each <b>image</b> <b>patch.</b> To provide geometric invariant image matching, we index the <b>image</b> <b>patches</b> into a 2 -D hash table by geometric hashing technique. Thus, the matching is invariant to global and local geometric transforms. In addition, since {{we use the}} <b>image</b> <b>patch</b> to capture the local information, the indexing can effectively handle partial matching. We formulate a matching criterion by weighted voting technique to incorporate the spatial interrelationship into consideration. We have performed a series of experiments to confirm the effectiveness of our method. Images are globally transformed and locally manipulated to examine the efficiency of our indexing scheme. Experimental results indicate satisfactory retrieval {{in the case of}} partial matching and geometric transformation. Keywords: Content-based image retrieval, interest points, geometric hashing, geometric invariance, <b>image</b> <b>patches,</b> partial occlusion 1...|$|R
40|$|The problem {{considered}} {{in this paper}} is how to select the feature points (in practice, small <b>image</b> <b>patches</b> are used) in an image from an image sequence, such {{that they can be}} tracked adequately further through the sequence. Usually, the tracking is performed by some sort of local search method looking for a similar patch in the next image in the sequence. Therefore, it would be useful if we could estimate ``the size of the convergence region¿¿ for each <b>image</b> <b>patch.</b> There is a smaller chance of error when calculating the displacement for an <b>image</b> <b>patch</b> with a large convergence region than for an <b>image</b> <b>patch</b> with a small convergence region. Consequently, the size of the convergence region {{can be used as a}} proper goodness measure for a feature point. For the standard Kanade-Lucas-Tomasi (KLT) tracking method, we propose a simple and fast way to approximate the convergence region for an <b>image</b> <b>patch.</b> In the experimental part, we test our hypothesis on a large set of real data...|$|R
40|$|This paper {{presents}} {{a new approach}} to single-image superresolution, based on sparse signal representation. Research on image statistics suggests that <b>image</b> <b>patches</b> can be wellrepresented as a sparse linear combination of elements from an appropriately chosen over-complete dictionary. Inspired by this observation, we seek a sparse representation for each patch of the low-resolution input, and then use the coefficients of this representation to generate the high-resolution output. Theoretical results from compressed sensing suggest that under mild conditions, the sparse representation can be correctly recovered from the downsampled signals. By jointly training two dictionaries for the low- and high-resolution <b>image</b> <b>patches,</b> we can enforce the similarity of sparse representations between the low resolution and high resolution <b>image</b> <b>patch</b> pair with respect to their own dictionaries. Therefore, the sparse representation of a low resolution <b>image</b> <b>patch</b> can be applied with the high resolution <b>image</b> <b>patch</b> dictionary to generate a high resolution <b>image</b> <b>patch.</b> The learned dictionary pair is a more compact representation of the patch pairs, compared to previous approaches, which simply sample a large amount of <b>image</b> <b>patch</b> pairs [1], reducing the computational cost substantially. The effectiveness of such a sparsity prior is demonstrated for both general image superresolution and the special case of face hallucination. In both cases, our algorithm generates high-resolution images that are competitive or even superior in quality to images produced by other similar SR methods. In addition, the local sparse modeling of our approach is naturally robust to noise, and therefore the proposed algorithm can handle super-resolution with noisy inputs in a more unified framework...|$|R
30|$|Aligned double JPEG {{compressed}} (ADJPEG in short): When the ASJPEG patches undergo another JPEG {{compression and}} the block {{structures of the}} two JPEG compressions are aligned with each other, the output <b>image</b> <b>patches</b> are called ADJPEG patches. They are usually referred to as double JPEG <b>image</b> <b>patches</b> in the literature.|$|R
40|$|International audiencePatch-level {{descriptors}} underlie {{several important}} computer vision tasks, such as stereo-matching or content-based image retrieval. We introduce a deep convolutional architecture that yields patch-level descriptors, {{as an alternative}} to the popular SIFT descriptor for image retrieval. The proposed family of descriptors, called Patch-CKN, adapt the recently introduced Convolutional Kernel Network (CKN), an unsupervised framework to learn convolutional architectures. We present a comparison framework to benchmark current deep convolutional approaches along with Patch-CKN for both <b>patch</b> and <b>image</b> retrieval, including our novel ``RomePatches'' dataset. Patch-CKN descriptors yield competitive results compared to supervised CNNs alternatives on <b>patch</b> and <b>image</b> retrieval...|$|R
40|$|Abstract. The {{increased}} use of context for high level reasoning has been popular in recent works to increase recognition accuracy. In this paper, we consider an orthogonal application of context. We explore the use of context to determine which low-level appearance cues in an image are salient or representative of an image’s contents. Existing classes of low-level saliency measures for <b>image</b> <b>patches</b> include those based on interest points, as well as supervised discriminative measures. We propose {{a new class of}} unsupervised contextual saliency measures based on co-occurrence and spatial information between <b>image</b> <b>patches.</b> For recognition, <b>image</b> <b>patches</b> are sampled using a weighted random sampling based on saliency, or using a sequential approach based on maximizing the likelihoods of the <b>image</b> <b>patches.</b> We compare the different classes of saliency measures, along with a baseline uniform measure, for the task of scene and object recognition using the bag-of-features paradigm. In our results, the contextual saliency measures achieve improved accuracies over the previous methods. Moreover, our highest accuracy is achieved using a sparse sampling of the image, unlike previous approaches who’s performance increases with the sampling density. ...|$|R
30|$|Uncompressed: These <b>patches</b> are raw <b>images</b> {{and have}} never been JPEG compressed.|$|R
