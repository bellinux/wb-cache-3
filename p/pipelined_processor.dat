140|649|Public
25|$|An {{early and}} {{important}} application of CSP was its use for specification and verification of {{elements of the}} INMOS T9000 Transputer, a complex superscalar <b>pipelined</b> <b>processor</b> designed to support large-scale multiprocessing. CSP was employed in verifying the correctness of both the processor pipeline, and the Virtual Channel Processor which managed off-chip communications for the processor.|$|E
500|$|All modern {{processors}} have multi-{{stage in}}struction pipelines. Each {{stage in the}} pipeline corresponds to a different action the processor performs on that instruction in that stage; a processor with an N-stage pipeline can have up to N different instructions {{at different stages of}} completion and thus can issue one instruction per clock cycle (...) [...] These processors are known as scalar processors. The canonical example of a <b>pipelined</b> <b>processor</b> is a RISC processor, with five stages: instruction fetch (IF), instruction decode (ID), execute (EX), memory access (MEM), and register write back (WB). The Pentium 4 processor had a 35-stage pipeline.|$|E
2500|$|WebMIPS is a {{browser-based}} MIPS simulator {{with visual}} {{representation of a}} generic, <b>pipelined</b> <b>processor.</b> [...] This simulator is quite useful for register tracking during step by step execution.|$|E
40|$|The <b>pipeline</b> <b>processor</b> is {{a common}} {{paradigm}} for very high speed computing machinery. <b>Pipeline</b> <b>processors</b> provide high speed because their separate stages can operate concurrently, much as different people on a manufacturing assembly line work concurrently on material passing down the line. Although the concurrency of <b>pipeline</b> <b>processors</b> makes their design a demanding task, they {{can be found in}} graphics processors, in signal processing devices, in integrated circuit components for doing arithmetic, and in the instruction interpretation units and arithmetic operations of general purpose computing machinery. Because I plan to describe a variety of <b>pipeline</b> <b>processors,</b> I will start by suggesting names for their various forms. <b>Pipeline</b> <b>processors,</b> or more simply jus...|$|R
40|$|This paper {{presents}} {{a method of}} test program generation for software-based self-test of <b>pipelined</b> <b>processors.</b> We propose a model of <b>pipelined</b> <b>processors</b> and testability measures for registers. We generate a test program efficiently by means of specific behaviors of <b>pipelined</b> <b>processors</b> and combinational ATPG. Experimental {{results show that the}} proposed method obtains high fault efficiency. [URL]...|$|R
50|$|A linear <b>pipeline</b> <b>processor</b> is {{a series}} of {{processing}} stages and memory access.|$|R
5000|$|<b>Pipelined</b> <b>processor</b> with 7-way superscalar {{execution}} pipeline ...|$|E
5000|$|... 8-stage <b>pipelined</b> <b>processor</b> with 2-way superscalar, in-order {{execution}} pipeline ...|$|E
5000|$|<b>Pipelined</b> <b>processor</b> with deeply out of order, {{speculative}} issue 3-way superscalar execution pipeline ...|$|E
5000|$|Molnar, C., Sproull, R., Sutherland, I. (1994), Counterflow <b>Pipeline</b> <b>Processor</b> Architecture, Sun Microsystems, Technical Report TR-94-25.|$|R
40|$|We have {{developed}} PGPG (Pipeline Generator for Programmable GRAPE), a software which generates the low-level {{design of the}} <b>pipeline</b> <b>processor</b> and communication software for FPGA-based computing engines (FBCEs). An FBCE typically consists of one or multiple FPGA (Field-Programmable Gate Array) chips and local memory. Here, the term "Field-Programmable" means that one can rewrite the logic implemented to the chip after the hardware is completed, and therefore a single FBCE {{can be used for}} calculation of various functions, for example <b>pipeline</b> <b>processors</b> for gravity, SPH interaction, or image processing. The main problem with FBCEs is that the user need to develop the detailed hardware design for the processor to be implemented to FPGA chips. In addition, she or he has to write the control logic for the processor, communication and data conversion library on the host processor, and application program which uses the developed processor. These require detailed knowledge of hardware design, a hardware description language such as VHDL, the operating system and the application, and amount of human work is huge. A relatively simple design would require 1 person-year or more. The PGPG software generates all necessary design descriptions, except for the application software itself, from a high-level design description of the <b>pipeline</b> <b>processor</b> in the PGPG language. The PGPG language is a simple language, specialized to the description of <b>pipeline</b> <b>processors.</b> Thus, the design of <b>pipeline</b> <b>processor</b> in PGPG language is much easier than the traditional design. For real applications such as the pipeline for gravitational interaction, the <b>pipeline</b> <b>processor</b> generated by PGPG achieved the performance similar to that of hand-written code. In this paper we present a detailed description of PGPG version 1. 0. Comment: 24 pages, 6 figures, accepted PASJ 2005 July 2...|$|R
50|$|It {{fails to}} project the {{concurrency}} in <b>pipeline</b> <b>processors,</b> as degree of parallelism doesn't account for concurrency handle by pipe-lined design.|$|R
5000|$|C V Ramamoorthy and Benjamin W Wah. An Optimal Algorithm for Scheduling Requests on Interleaved Memories for a <b>Pipelined</b> <b>Processor.</b> IEEE Trans. Computers (...) , 30(10):787- 800, 1981.|$|E
50|$|A <b>pipelined</b> <b>processor</b> may {{deal with}} hazards by {{stalling}} {{and creating a}} bubble in the pipeline, resulting {{in one or more}} cycles in which nothing useful happens.|$|E
50|$|WebMIPS is a {{browser-based}} MIPS simulator {{with visual}} {{representation of a}} generic, <b>pipelined</b> <b>processor.</b> This simulator is quite useful for register tracking during step by step execution.|$|E
40|$|Speculative {{execution}} of code {{is becoming a}} key technique for enhancing the performance of <b>pipeline</b> <b>processors.</b> We study schemes that predict the execution path of a program based {{on the history of}} branch executions. Building on previous work, we present a model for analyzing the effective speedup from pipelining using various schemes for speculative execution. We follow this with stochastic analyses of various speculative execution schemes. Finally, we conclude with simulations covering several of the settings we study. 1. Introduction We consider the problem of on-line instruction fetch on <b>pipeline</b> <b>processors.</b> <b>Pipelining</b> is commonly used on modern processors for speeding up the {{execution of}} programs. Typically, the execution of a single instruction in the code can be partitioned to steps, starting with instruction fetch. While traditional processors allow the execution of one instruction at a time, a <b>pipeline</b> <b>processor</b> starts the execution of an instruction as soon as the previous [...] ...|$|R
5000|$|<b>Pipelined</b> <b>processors</b> {{commonly}} use {{three techniques}} {{to work as}} expected when the programmer assumes that each instruction completes before the next one begins: ...|$|R
40|$|Abstract. We {{consider}} {{the problem of}} bounded model checking of systems expressed in a decidable fragment of first-order logic. While model checking is not guaranteed to terminate for an arbitrary system, it converges for many practical examples, including <b>pipelined</b> <b>processors.</b> We give a new formal definition of convergence that generalizes previously stated criteria. We also give a sound semi-decision procedure to check this criterion based on a translation to quantified separation logic. Preliminary results on simple <b>pipeline</b> <b>processor</b> models are presented...|$|R
5000|$|... #Caption: A {{canonical}} five-stage <b>pipelined</b> <b>processor.</b> In {{the best}} case scenario, it takes one clock cycle to complete one instruction {{and thus the}} processor can issue scalar performance (...) [...]|$|E
50|$|The machine {{specifications}} include a {{finite state machine}} that determines the processor's micro-operations. The canonical implementation of the state machine is an excellent candidate for reduction, and can also be re-implemented as a <b>pipelined</b> <b>processor.</b>|$|E
50|$|The {{instructions}} of {{the program}} may not be run in the correct order, {{as long as the}} end result is correct. It separates the fetch and decode stages from the execute stage in a <b>pipelined</b> <b>processor</b> by using a buffer.|$|E
40|$|The {{need for}} low-cost, real-time, image {{processing}} for automated inspection and other industrial applications {{has led to}} considerable effort being directed at many novel computer architectures. Two main avenues of work have become apparent: the use of powerful parallel architectures {{and the use of}} <b>pipelined</b> <b>processors.</b> The former while offering great flexibility, have, to date, been associated with high cost. The latter, being essentially simpler processors can produce considerable cost savings but have generally been inflexible and provided a limited number of functions. <b>Pipeline</b> <b>processors</b> have generally found application as pre-processors for use with parallel machines or in image enhancement for human operators where relatively simple processing is required. The paper describes the development of an adaptive <b>pipeline</b> <b>processor</b> which offers the potential cost efficiency of large scale integration together with the flexibility of an adaptive system. The processor concerned accepts d [...] ...|$|R
5000|$|A <b>pipelined</b> <b>processor's</b> need to {{organize}} all its work into modular steps may require the duplication of registers {{that increases the}} latency of some instructions.|$|R
40|$|Teaching {{methodology}} Learning {{objectives of}} the subject To provide students with the general concepts and techniques used in current high-performance general purpose microprocessors and systems. Basic contents of the course are the following: <b>Processor</b> design, <b>pipelined</b> <b>processors,</b> superscalar processors, multiprocessor and vector architectures. 1 /...|$|R
50|$|An {{early and}} {{important}} application of CSP was its use for specification and verification of {{elements of the}} INMOS T9000 Transputer, a complex superscalar <b>pipelined</b> <b>processor</b> designed to support large-scale multiprocessing. CSP was employed in verifying the correctness of both the processor pipeline, and the Virtual Channel Processor which managed off-chip communications for the processor.|$|E
5000|$|The {{technique}} of self-modifying code can be problematic on a <b>pipelined</b> <b>processor.</b> In this technique, {{one of the}} effects of a program is to modify its own upcoming instructions. If the processor has an instruction cache, the original instruction may already have been copied into a prefetch input queue and the modification will not take effect.|$|E
50|$|Instructions in a <b>pipelined</b> <b>processor</b> are {{performed}} in several stages, {{so that at}} any given time several instructions are being processed in the various stages of the pipeline, such as fetch and execute. There are many different instruction pipeline microarchitectures, and instructions may be executed out-of-order. A hazard occurs when two or more of these simultaneous (possibly out of order) instructions conflict.|$|E
40|$|Abstract: 2 ̆ 2 We {{consider}} {{the problem of}} bounded model checking of systems expressed in a decidable fragment of first-order logic. While model checking is not guaranteed to terminate for an arbitrary system, it converges for many practical examples, including <b>pipelined</b> <b>processors.</b> We give a new formal definition of convergence that generalizes previously stated criteria. We also give a sound semi-decision procedure to check this criterion based on a translation to quantified separation logic. Preliminary results on simple <b>pipeline</b> <b>processor</b> models are presented. 2 ̆...|$|R
40|$|<b>Pipeline</b> FFT <b>processors</b> {{are used}} in mobile {{communication}} systems and in particular in OFDM-based systems. This paper presents a method for power analysis and clock optimization of <b>pipeline</b> FFT <b>processors</b> for particular OFDM baseband system. This method is applied to various architectures with different radices. The analysis {{can be used in}} the design of high speed <b>pipeline</b> FFT <b>processors...</b>|$|R
5000|$|Counterflow <b>Pipeline</b> <b>Processor</b> Architecture, by Ivan E. Sutherland, Charles E. Molnar (Charles Molnar), and Robert F. Sproull (Bob Sproull), Sun Microsystems Laboratories Report Number TR-94-25, April 1994 ...|$|R
50|$|Programs {{written for}} a <b>pipelined</b> <b>processor</b> {{deliberately}} avoid branching to minimize possible loss of speed. For example, the programmer {{can handle the}} usual case with sequential execution and branch only on detecting unusual cases. Using programs such as gcov to analyze code coverage lets the programmer measure how often particular branches are actually executed and gain insight with which to optimize the code.|$|E
50|$|A multi-ported cache is a cache {{which can}} serve {{more than one}} request at a time. When {{accessing}} a traditional cache we normally use a single memory address, whereas in a multi-ported cache we may request N addresses at a time where N {{is the number of}} ports that connected through the processor and the cache. The benefit of this is that a <b>pipelined</b> <b>processor</b> may access memory from different phases in its pipeline. Another benefit is that it allows the concept of super-scalar processors through different cache levels.|$|E
5000|$|Superscalar {{processors}} {{differ from}} multi-core processors {{in that the}} several execution units are not entire processors. A single processor is composed of finer-grained execution units such as the ALU, integer multiplier, integer shifter, FPU, etc. There may be multiple versions of each execution unit to enable execution of many instructions in parallel. This differs from a multi-core processor that concurrently processes instructions from multiple threads, one thread per processing unit (called [...] "core"). It also differs from a <b>pipelined</b> <b>processor,</b> where the multiple instructions can concurrently be {{in various stages of}} execution, assembly-line fashion.|$|E
40|$|Modeling and {{simulating}} <b>pipelined</b> <b>processors</b> in procedural languages such as C/C++ requires lots of cost {{in handling}} concurrent events, which hinders fast simulation. A number of researches on simulation have devised speed-up techniques {{to reduce the}} number of events. This paper presents a new simulation approach developed to enhance the simulation of <b>pipelined</b> <b>processors.</b> The proposed approach is based on early pipeline evaluation that all the intermediate values of an instruction are computed in advance, creating a future state for the next instructions. The future state allows the next instructions to be computed without considering data dependencies between nearby instructions. We apply this concept to building a cycleaccurate simulator for a <b>pipelined</b> RISC <b>processor</b> and achieve almost the same speed as the instruction-level simulator. 1...|$|R
40|$|Abstract — In this paper, the {{effectiveness}} of the ASIP (Application Specific Instruction set Processor) design system PEAS-III is evaluated through experiments. Examples in experiments are a MIPS R 3000 compatible processor, DLX, a simple RISC controller, and PEAS-I core. While they are simple in-order <b>pipelined</b> <b>processors,</b> they have enough facilities for real embedded system design. Through experiments, easiness of design and modification for improvement and design quality in terms of performance and hardware cost are discussed. It has been confirmed that the design method used in PEAS-III is effective to design space exploration for simple <b>pipelined</b> <b>processors.</b> I...|$|R
50|$|Instruction {{scheduling}}: Instruction scheduling is {{an important}} optimization for modern <b>pipelined</b> <b>processors,</b> which avoids stalls or bubbles in the pipeline by clustering instructions with no dependencies together, while being careful to preserve the original semantics.|$|R
