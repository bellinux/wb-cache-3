365|1043|Public
5000|$|Market volatility: {{changing}} {{market conditions}} like raw material supply and sales volumes drive business <b>process</b> <b>complexity</b> ...|$|E
50|$|The {{original}} service blueprint is {{a highly}} visual, graphical map that delineates the key contact points in the service process {{and the nature of}} the contact - whether with physical evidence, personnel or procedures. It can be seen as a two dimensional map in which the horizontal axis represents time and the vertical axis represents the basic steps in the process. A line of visibility is included to separate actions visible to the customer from actions out of sight. Employee latitude, which refers to the amount of discretion given to employees to vary the service process, is shown on the map a call-out sign attached to the step. <b>Process</b> <b>complexity</b> is shown simply by the number of steps in the process.|$|E
50|$|Blueprinting is a {{technique}} designed to document the visible customer experience. In its simplest form, the service blueprint is an applied process chart which shows the service delivery process from the customer's perspective. The original service blueprint is a highly visual, graphical map that delineates the key contact points in the service process {{and the nature of}} the contact - whether with physical evidence, personnel or procedures. It can be seen as a two dimensional map in which the horizontal axis represents time and the vertical axis represents the basic steps in the process. A line of visibility is included to separate actions visible to the customer from actions out of sight. Employee latitude, which refers to the amount of discretion given to employees to vary the service process, is shown on the map a call-out sign attached to the step a shown in the figure. <b>Process</b> <b>complexity</b> is shown simply by the number of steps in the process.|$|E
40|$|High {{demand for}} first {{principle}} modeling of chemical <b>processes</b> <b>Complexity</b> of <b>processes</b> and models Structure of implemented models Goals of computer-based modeling computer-aided process engineering systematical modeling approaches reusable and transparent models Physically motivated concepts for structuring of balance based model...|$|R
40|$|This book {{offers a}} {{complete}} introduction for novices to understand key concepts of biocatalysis {{and how to}} produce in-house enzymes {{that can be used}} for low-cost biofuels production. The authors discuss the challenges involved in the commercialization of the biofuel industry, given the expense of commercial enzymes used for lignocellulose conversion. They describe the limitations in the <b>process,</b> such as <b>complexity</b> of lignocellulose structure, different microbial communities’ actions and interactions for degrading the recalcitrant structure of lignocellulosic materials, hydrolysis mechanism and potential for bio refinery. Readers will gain understanding of the key concepts of microbial catalysis of lignocellulosic biomass, <b>process</b> <b>complexities</b> and selection of microbes for catalysis or genetic engineering to improve the production of bioethanol or biofuel...|$|R
3000|$|We {{presented}} two voice-to-phoneme conversion algorithms, each {{of which}} utilizes a phonetic decoder and speaker-independent HMMs to create speaker-independent voice-tags. However, these two algorithms employ radically different approaches for sample combination. It is difficult to theoretically compare the algorithms' creation <b>process</b> <b>complexities,</b> though we have observed that the creation processes of both algorithms require similar computational resources (CPU and RAM). The voice-tag created by both algorithms {{is a set of}} phonetic strings that require very low storage, making them suitable for embedded platforms. So, for a voice-tag with [...]...|$|R
5000|$|There are {{two major}} {{disadvantages}} to the gas atomisation spray forming process. The most significant disadvantage is the relatively low process yield with typical losses of ~30%. Losses occur because of overspray (droplets missing the emerging billet), splashing of material from the billet surface, and material ‘bouncing’ off the semi-solid top surface. Many operators of the spray forming process now use a particle injector system to re-inject the overspray powder, and thus recycle material {{that would otherwise be}} lost, or sell the overspray powder as a product in its own right. The second major disadvantage is one of process control. As it is essentially a free-forming process with many interdependent variables, it has proved difficult to predict the shape, porosity or deposition rate for a given alloy. Much of the control is based on operator experience and empirical relationships. It is partly the <b>process</b> <b>complexity</b> and lack of robust process control that has prevented the widespread commercialisation of this process. Some developments using feed-back control have proved successful in improving the variations in billet diameter and improving yield in specific systems but these have yet to find widespread implementation.|$|E
5000|$|IC {{development}} {{for more than}} a quarter-century has been dominated by the MOS technology. In the 1970s and 1980s NMOS was favored owing to speed and area advantages, coupled with technology limitations and concerns related to isolation, parasitic effects and <b>process</b> <b>complexity.</b> During that era of NMOS-dominated LSI and the emergence of VLSI, the fundamental scaling laws of MOS technology were codified and broadly applied. [...] It was also during this period that TCAD reached maturity in terms of realizing robust process modeling (primarily one-dimensional) which then became an integral technology design tool, used universally across the industry. [...] At the same time device simulation, dominantly two-dimensional owing to the nature of MOS devices, became the work-horse of technologists in the design and scaling of devices. [...] The transition from NMOS to CMOS technology resulted in the necessity of tightly coupled and fully 2D simulators for process and device simulations. This third generation of TCAD tools became critical to address the full complexity of twin-well CMOS technology (see Figure 3a), including issues of design rules and parasitic effects such as latchup. [...] An abbreviated but prospective view of this period, through the mid-1980s, is given in; and {{from the point of view}} of how TCAD tools were used in the design process.|$|E
5000|$|Sputtering a stacked {{multilayer}} {{of metal}} - for example a Cu/In/Ga/Cu/In/Ga... structure - produces a smoother surface and better crystallinity in the absorber {{compared to a}} simple bilayer (Cu-Ga alloy/In) or trilayer (Cu/In/Ga) sputtering. These attributes result in higher efficiency devices, but forming the multilayer is a more complicated deposition process and did not merit the extra equipment or the added <b>process</b> <b>complexity.</b> Additionally, the reaction rates of Cu/Ga and Cu/In layers with Se are different. If the reaction temperature is not high enough, or not held long enough, CIS and CGS form as separate phases. [...] Companies currently that used similar processes include Showa Shell, Avancis (now an affiliate of Saint-Gobain Group), Miasolé, Honda Soltec, and Energy Photovoltaics (EPV). Showa Shell sputtered a Cu-Ga alloy layer and an In layer, followed by selenization in H2Se and sulfurization in H2S. The sulfurization step appears to passivate the surface in a way similar to CdS in most other cells. Thus, the buffer layer used is Cd-free, eliminating any environmental impact of Cd. Showa Shell reported a maximum module efficiency of 13.6% {{with an average of}} 11.3% for 3600 cm2 substrates. Shell Solar uses the same technique as Showa Shell to create the absorber; however, their CdS layer comes from chemical vapor deposition. Modules sold by Shell Solar claim 9.4% module efficiency. Miasole had procured venture capital funds for its process and scale up. However, little is known about their process beyond their stated efficiency of 9 to 10% for modules. EPV uses a hybrid between coevaporation and sputtering in which In and Ga are evaporated in a Se atmosphere. This is followed by Cu sputtering and selenization. Finally, In and Ga are again evaporated in the presence of Se. Based on Hall measurements, these films have a low carrier concentration and relatively high mobility. EPV films have a low defect concentration.|$|E
40|$|The paper {{presents}} {{an analysis of}} SPC (Statistical Process Control) procedures usability in foundry engineering. The authors {{pay particular attention to}} the <b>processes</b> <b>complexity</b> and necessity of correct preparation of data acquisition procedures. Integration of SPC systems with existing IT solutions in area of aiding and assistance during the manufacturing process is important. For each particular foundry, methodology of selective SPC application needs to prepare for supervision and control of stability of manufacturing conditions, regarding specificity of data in particular “branches ” of foundry production (Sands, Pouring, Metallurgy, Quality) ...|$|R
50|$|Most modern CISC {{processors}} use {{a combination}} of pipelined logic to <b>process</b> lower <b>complexity</b> opcodes which can be completed in one clock cycle, and microcode to implement ones that take multiple clock cycles to complete.|$|R
5000|$|Arturo Carsetti (2009) Embodiment <b>processes</b> and {{intentional}} <b>complexity.</b> La Nuova Critica, 53-59, 103-122.|$|R
40|$|<b>Process</b> <b>complexity</b> {{is one of}} {{the basic}} {{variants}} of Kolmogorov complexity. Unlike plain Kolmogorov complexity, <b>process</b> <b>complexity</b> provides a simple characterization of randomness for real numbers in terms of initial segment complexity. <b>Process</b> <b>complexity</b> was first developed in (Schnorr 1973). Schnorr’s definition of a process, while simple, can be difficult to work with. In many situations, a preferable definition of a process is that given by Levin in (Levin & Zvonkin 1970). In this paper we define a variant of <b>process</b> <b>complexity</b> based on Levin’s definition of a process. We call this variant strict <b>process</b> <b>complexity.</b> Strict <b>process</b> <b>complexity</b> retains the main desirable properties of <b>process</b> <b>complexity.</b> Particularly, it provides simple characterizations of Martin-Löf random real numbers, and of computable real numbers. However, we will prove that strict <b>process</b> <b>complexity</b> does not agree within an additive constant with Schnorr’s original <b>process</b> <b>complexity.</b> One of the basic properties of prefix-free complexity is that it is subadditive. Subadditive means that there is some constant d such that for all strings σ, τ the complexity of στ (σ and τ concatenated) is {{less than or equal to}} the sum of the complexities of σ and τ plus d. A fundamental question about any complexity measure is whether or not it is subadditive. In this paper we resolve this question for <b>process</b> <b>complexity</b> by proving that neither of these process complexities is subadditive. ...|$|E
40|$|Complexity in {{business}} processes can be inhibitor {{of performance and}} a motivator at the same time. Current studies on business <b>process</b> <b>complexity</b> primarily focus on the structural aspect of <b>process</b> <b>complexity.</b> However given the subjective nature of complexity, {{it is important to}} expand the notion beyond the structural dimension so as to provide a more accurate reading of <b>process</b> <b>complexity.</b> In this paper we present an integrated framework for business <b>process</b> <b>complexity</b> that spans across structural, variability, and performance aspects of business processes. We further provide respective methods for measurement of the three aspects of complexity. The applicability of the integrated framework and its constituent methods is evaluated through an example. Results of the study demonstrate that the expanded notion of complexity as proposed in the integrated framework provides a more meaningful and accurate means for business <b>process</b> <b>complexity</b> analysis...|$|E
40|$|We {{propose a}} variant of the Kolmogorov concept of {{complexity}} which yields a common theory of finite and infinite random sequences. Processes are sequential coding schemes such as prefix coding schemes. The <b>process</b> <b>complexity</b> is the minimal length of the description of a sequence in a sequential coding scheme. The <b>process</b> <b>complexity</b> does not oscillate. We establish some concepts of effective tests which are proved to be equivalent...|$|E
40|$|In {{this paper}} the <b>process</b> <b>complexities</b> and par-asitic {{substrate}} coupling effects are compared for several different high-density capacitive tactile im-agers. The dissolved-wafer p ocess using diffused bulk-silicon row lines and metal-on-glass columns {{is found to}} offer the simplest process and fastest response, requiring only five non-critical masks and producing a settling time for the column charge of about 1 #s. Using this process, a 1024 -element array with a force range of I gm and a spatial resolution of 500 #m produces a force resolution equivalent o seven bits. Scaled to a 4096 -element array, this same process hould pro-duce a force resolution of nearly six bits for th...|$|R
40|$|This work {{begins its}} {{considerations}} stressing the importance that strategic planning has assumed among scientific community and politicians as an innovative tool in urban government construction. Moreover, most frequently scientists, public administrators and politicians put together their experiences building a ‘community of practice’. Available studies have speeded up a systematic knowledge flown in manual book production, written {{not only to}} give some guide lines to build strategic plans but to reform the fragmented action logic; in this work the author makes a reconnaissance of these principal Italian manuals, trying to underline how they can reduce urban construction <b>processes</b> <b>complexity,</b> making them a technical activity and a skill...|$|R
40|$|This paper {{describes}} {{the application of}} parallel simulation techniques to represent structured functional parallelism present within the Space Shuttle Operations Flow, utilizing the Synchronous Parallel Environment for Emulation and Discrete-Event Simulation (SPEEDES), an object-oriented multicomputing architecture. SPEEDES is a unified parallel simulation environment, which allocates events over multiple processors to get simulation speed up. Its optimistic processing capability minimizes simulation lag time behind wall clock time, or multiples of real-time. SPEEDES accommodates increases in <b>processes</b> <b>complexity</b> with additional parallel computing nodes to allow sharing of processing loads. This papers focuses on {{the whole process of}} translating a model of Space Shuttle Operations Flow represente...|$|R
40|$|Business {{processes}} have {{an inherent}} complexity which if not controlled can keep on increasing with time, thus making the processes error-prone, {{difficult to understand}} and maintain. In the last few years, several researchers have proposed a number of metrics {{which can be used}} to measure and therefore control the complexity of business processes. In this study, a survey of business <b>process</b> <b>complexity</b> metrics is conducted with the goal of investigating if there are any gaps in literature. Initially, a description of the process of metrics definition and validation is presented, followed by an analysis of business <b>process</b> <b>complexity</b> metrics that have appeared in literature in the last 5 years. The reviewers checked whether the identified metrics have any tool support, whether they have been validated and whether validation results are significant or not. Findings show that few business <b>process</b> <b>complexity</b> metrics have been proposed so far and that even fewer have been validated. In order to address these issues, some future research directions are proposed...|$|E
30|$|We {{selected}} a large German OEM as focal {{company for the}} evaluation. As described before, selecting an OEM offers {{the opportunity for a}} broad evaluation of the applicability of the PMS within an environment with a high <b>process</b> <b>complexity.</b>|$|E
40|$|Abstract—In {{a highly}} {{competitive}} environment, it becomes more important to shorten the whole business process while delivering or even enhancing the business value to the customers and suppliers. Although the workflow management systems receive much attention for its capacity to practically support the business process enactment, the effective workflow modeling method remain still challenging and {{the high degree of}} <b>process</b> <b>complexity</b> makes it more difficult to gain the short lead time. This paper presents a workflow structuring method in a holistic way that can reduce the <b>process</b> <b>complexity</b> using activity-needs and formal concept analysis, which eventually enhances the key performance such as quality, delivery, and cost in business process. Keywords—Workflow management, reengineering, formal concept analysis. I...|$|E
30|$|DMSM: The DMSM {{operation}} includes {{normal and}} explore actions. In the normal action, since this {{action would be}} performed NormalTimes (appeared in Equation 30) in the overall learning <b>process,</b> the <b>complexity</b> of this action is O(NormalTimes). In the explore action, because the FP-growth and association rules mining are performed only {{in the beginning of}} this action or when the system falls into local optima. As a result, the effect caused by these two operations on the overall learning efficiency is not crucial. The complexity of these two operators can be skipped. Moreover, since the explore action would be performed (ExploreTimes-NormalTimes) times in the overall learning <b>process,</b> the <b>complexity</b> of this action is O(ExploreTimes-NormalTimes), where ExploreTimes appeared in Equation 33.|$|R
50|$|The {{rewriting}} <b>process</b> shows <b>complexities</b> {{not easily}} explained. For example, the later version has new features more appropriate for, but not included in, the original version, e.g., Jimmy's habitual carrying of a flashlight suitable for burglary and detailed knowledge of white jargoon.|$|R
50|$|The {{instrumentation}} and <b>process</b> control <b>complexity</b> {{requirements are}} relatively high. The {{advantage of this}} technique over selective methanation is the higher space velocity, which reduces the required reactors size. For the case of strong temperature rises, the feed of air can simply be broken.|$|R
40|$|Abstract—Process {{measurement}} is {{the task}} of empirically and objectively assigning numbers to the properties of business processes {{in such a way}} as to describe them. Desirable attributes to study and measure include complexity, cost, maintainability, and reliability. In our work we will focus on investigating <b>process</b> <b>complexity.</b> We define <b>process</b> <b>complexity</b> as the degree to which a business process is difficult to analyze, understand or explain. One way to analyze a process ’ complexity is to use a process control-flow complexity measure. In this paper, an attempt has been made to evaluate the control-flow complexity measure in terms of Weyuker’s properties. Weyuker’s properties must be satisfied by any complexity measure to qualify as a good and comprehensive one. Keywords—Business process measurement, workflow, complexity. ...|$|E
40|$|This study {{aimed to}} explore the {{influence}} of the therapist’s theoretical orientation on patient’s narrative production. Cathy’s therapeutic narratives with Carl Rogers, Arnold Lazarus and Everett Shostrom were analyzed in terms of three narrative dimensions: structural coherence, <b>process</b> <b>complexity</b> and content multiplicity. Results showed statistically significant differences in scores of Cathy’s total narrative production depending on the therapist she was interacting with. <b>Process</b> <b>complexity</b> was the only narrative dimension that registered statistically significant differences between the three therapists. Comparison between the three therapists showed statistically significant differences between Rogers and Shostrom but neither between Rogers and Lazarus nor between Lazarus and Shostrom. Cathy’s highest narrative production scores were obtained with Carl Rogers. Results suggest that the therapist’s theoretical orientation influences the patient’s narrative production in psychotherapy...|$|E
30|$|Clustering {{plays an}} {{important}} role in constructing practical network systems. In this paper, we propose a novel clustering algorithm with low complexity for dense small cell networks, which is a promising deployment in next-generation wireless networking. Our algorithm is a matrix-based algorithm where metrics for the clustering process are represented as a matrix on which the clustering problem is represented as the maximization of elements. The proposed algorithm simplifies the exhaustive search for all possible clustering formations to the sequential selection of small cells, which significantly reduces the clustering <b>process</b> <b>complexity.</b> We evaluate the complexity and the achievable rate with the proposed algorithm and show that our algorithm achieves almost optimal performance, i.e., almost the same performance achieved by exhaustive search, while substantially reducing the clustering <b>process</b> <b>complexity.</b>|$|E
40|$|Introduction. The process {{optimization}} method {{of the manufacturing}} of radio-electronic equipment, based on using of optimizing Pareto-planes is offered. Main part. Proposed method involves the using of optimization Pareto-planes for solving problems of optimization processes (TP) which {{can be considered as}} modification of Pareto. The method is universal, does not contain restrictions on <b>processes</b> <b>complexity</b> and allows establishing technological processes options which meet conditions of providing the set level of products deficiency at admissible expenses. Conclusions. Offered a universal method of optimization that uses the principles of Pareto optimization and is as close to the real production conditions, including taking into account the possible configurations of used technological and control equipment, requirements for quality and reliability of products in general. ???????????? ????? ??????????? ??????????????? ????????? ???????????? ???????????????? ??????????, ???????????? ?? ????????????? ??????????????? ??????-??????????. ????? ???????????, ?? ???????? ??????????? ?? ????????? ????????? ? ????????? ????????????? ???????? ??????????????? ?????????, ??????? ???????? ???????? ??????????? ????????? ?????? ??????????? ??????? ??? ?????????? ????????...|$|R
40|$|The {{features}} of the large Cluster projects’ management <b>processes,</b> <b>complexity,</b> “one-off” and “irreversibility”, make the projects’ process knowledge hard to be expressed, analyzed and obtained accurately. It is also not convenient to be accumulated and disseminated, and can’t be learned and used by managers. However, such knowledge is the crystallization of human wisdom. It has {{an important role in}} promoting efficiency of projects management and increasing accumulation of social knowledge. A better way is needed to find for its representation and utilization. From the perspective of cluster project management department, this article takes a cluster project’s construction as an example, and proposes a suitable method for the process knowledge representation in large cluster projects’ management processes, combined with the Topic Maps and MFFC-Ⅱ & MLD-Ⅱ...|$|R
40|$|Previous {{literature}} {{has been critical}} of public participation practices, finding unimpressive application of public participation principles {{and low levels of}} public satisfaction. Ecosystem-based management generally involves mixed land ownerships, which adds considerable complexity to the planning <b>process.</b> This <b>complexity</b> increases both the importance of public participation and th...|$|R
40|$|Purpose – The {{purpose of}} this paper is to test whether {{complexity}} interacts with Sales and Operations Planning (S&OP) practices by positively moderating the impact of S&OP practices on manufacturing operational performance dimensions of quality, flexibility and delivery. Design/methodology/approach – Three hypotheses are developed on the relationships between S&OP practices, task complexity and <b>process</b> <b>complexity</b> and manufacturing operational performance. Scales are validated with structural equation modelling. The hypotheses are tested through a hierarchical regression analysis using data from a sample of 725 manufacturing plants from 21 countries. Findings – S&OP practices of organizational management, technological integration, measurement systems and integration of plans impact positively on manufacturing operational dimensions of quality, delivery and flexibility. <b>Process</b> <b>complexity</b> moderates the effect of S&OP practices, amplifying its impact upon all three performance dimensions. Product complexity moderates the effect on quality, but not on delivery and flexibility. Practical implications – S&OP practices of organizational and technological coordination of manufacturing and new product design; information technology to measure information sharing and planning; dedicated information systems do impact upon manufacturing operational performance. Results are amplified by <b>process</b> <b>complexity.</b> The more complex are the manufacturing processes the larger the gains of S&OP. Originality/value – This research applies contingency theory to S&OP and empirically demonstrates its impact on manufacturing operational performance and the moderator role of complexity. info:eu-repo/semantics/publishedVersio...|$|E
40|$|Parnas {{tables are}} forms of tabular {{software}} requirement representations. Case studies on using Parnas tables in developing General Motor’s Individual Dealership Marketing Co-op web-enabled system show the {{significant reduction in}} requirement resources, testing and correction cost, and <b>process</b> <b>complexity.</b> This {{is largely due to}} the precision and simplicity of the tables. 1...|$|E
30|$|The rest of {{the paper}} is {{organized}} as follows. Section 2 describes the system model and Section 3 describes the proposed algorithm. In Section 4, we present a performance evaluation in which we evaluated the clustering <b>process</b> <b>complexity</b> and the achievable rate per small cell. Finally, Section 5 concludes the paper with a summary of key points.|$|E
40|$|The {{article of}} record as {{published}} may be located at [URL] history of developing {{and using a}} simulation model {{for the study of}} software error <b>processes,</b> <b>complexity</b> and structure is traced. Strong and weak points of simulation as they relate to model validity, accuracy and cost of implementation and use are discussed. The simulation model is compared t o a similar analytic model. The history of an experiment in software complexity and error analysis is used to show the correspondence between empirical and model results. Empirical wthods are contrasted with the use of models in terms of validity, accuracy, generality and cost. An assessment is made of the applicability of the techniques, based on these experiences. Supported {{by a grant from the}} Naval Air Development Center, Warminster, PA...|$|R
3000|$|To {{solve for}} the {{complexity}} factors, invert the matrix and solve {{the system of}} equations. As long as the equations are well conditioned, which they almost always will be because of the unique nature of refinery configurations—literally, no two refineries are alike in <b>process</b> capacities—the <b>complexity</b> factors are computed thus: [...]...|$|R
50|$|Place {{branding}} is {{a process}} made up of several sub-processes. Unlike branding simpler entities like a product, service, company, person or classical subjects of branding, place branding, and in particular nation and city branding, is a complex <b>process.</b> The <b>complexity</b> comes from the great diversity of stakeholders in the process.|$|R
