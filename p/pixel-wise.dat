1029|12|Public
25|$|Image {{processing}} and image analysis {{tend to focus}} on 2D images, how to transform one image to another, e.g., by <b>pixel-wise</b> operations such as contrast enhancement, local operations such as edge extraction or noise removal, or geometrical transformations such as rotating the image. This characterization implies that image processing/analysis neither require assumptions nor produce interpretations about the image content.|$|E
5000|$|These values can be {{represented}} <b>pixel-wise</b> {{in the form of}} images: ...|$|E
50|$|The format uses <b>pixel-wise</b> {{differential}} encoding between frames (similarly GIF) to reduced the data amount.|$|E
40|$|This paper {{presents}} an automatic liver parenchyma segmentation algorithm that can segment liver in abdominal CT images. There are three major {{steps in the}} proposed approach. Firstly, a texture analysis is applied to input abdominal CT images to extract pixel level features. In this step, wavelet coefficients are used as texture descriptors. Secondly, support vector machines (SVMs) are implemented to classify the data into <b>pixel-wised</b> liver area or non-liver area. Finally, integrated morphological operations are designed to remove noise and finally delineate the liver. Our unique contributions to liver segmentation are twofold: one {{is that it has}} been proved through experiments that wavelet features present good classification result when SVMs are used; the other is that the combination of morphological operations with the <b>pixel-wised</b> SVM classifier can delineate volumetric liver accurately. The algorithm can be used in an advanced computer-aided liver disease diagnosis and liver surgical planning system. Examples of applying the proposed algorithm on real CT data are presented with performance validation based on the comparison between the automatically segmented results and manually segmented ones...|$|R
40|$|This paper {{introduces}} {{an automatic}} liver parenchyma segmentation algorithm that can delineate liver in abdominal CT images. The proposed approach {{consists of three}} main steps. Firstly, a texture analysis is applied onto input abdominal CT images to extract pixel level features. Here, two main categories of features, namely wavelet coefficients and Haralick texture descriptors are investigated. Secondly, support vector machines (SVM) are implemented to classify the data into <b>pixel-wised</b> liver or non-liver. Finally, specially combined morphological operations are designed as a post processor to remove noise and to delineate the liver. Our unique contributions to liver segmentation are twofold: one {{is that it has}} been proved through experiments that wavelet features present better classification than Haralick texture descriptors when SVMs are used; the other is that the combination of morphological operations with a <b>pixel-wised</b> SVM classifier can delineate volumetric liver accurately. The algorithm can be used in an advanced computer-aided liver disease diagnosis and surgical planning systems. Examples of applying the algorithm on real CT data are presented with performance validation based on the automatically segmented results and that of manually segmented ones...|$|R
40|$|Valuable {{information}} can be hidden in images, however, few research discuss data mining on them. In this paper, we propose a general framework based on the decision tree for mining and processing image data. <b>Pixel-wised</b> image features were extracted and transformed into a database-like table which allows various data mining algorithms to make explorations on it. Each tuple of the transformed table has a feature descriptor formed {{by a set of}} features in conjunction with the target label of a particular pixel. With the label feature, we can adopt the decision tree induction to realize relationships be-tween attributes and the target label from image pixels, and to construct a model for <b>pixel-wised</b> image processing according to a given training image dataset. Both experi-mental and theoretical analyses were performed in this study. Their results show that the proposed model can be very efficient and effective for image processing and image min-ing. It is anticipated that by using the proposed model, various existing data mining and image processing methods could be worked on together in different ways. Our model {{can also be used to}} create new image processing methodologies, refine existing image proc-essing methods, or act as a powerful image filter...|$|R
5000|$|The congealing {{algorithm}} {{begins with}} a set of images [...] and a corresponding transform matrix , which {{at the end of the}} algorithm will represent the transformation of [...] into its latent image [...] These latent images [...] minimize the joint <b>pixel-wise</b> entropies. Thus the task of the congealing algorithm is to estimate the transformations [...]|$|E
5000|$|Image {{processing}} and image analysis {{tend to focus}} on 2D images, how to transform one image to another, e.g., by <b>pixel-wise</b> operations such as contrast enhancement, local operations such as edge extraction or noise removal, or geometrical transformations such as rotating the image. This characterization implies that image processing/analysis neither require assumptions nor produce interpretations about the image content.|$|E
50|$|QuickTime Animation uses run-length {{encoding}} and conditional replenishment for compression. When encoding, {{the input}} frame is scanned <b>pixel-wise</b> in raster-scan order and processed line-wise. Within a line, pixels are segmented into runs, {{the length of}} which is variable and signaled in the bitstream. For each run, one of three coding modes is used: same color, skip, or PCM. In same color mode, a run of pixels is represented by a single color in a run-length encoding fashion. If pixels with different colors are joined into a run (of a single color) by the encoder, the coding process is lossy, otherwise it is lossless. The lossless mode is used at the 100% quality level. In skip mode, the run of pixels is left unchanged from the previous frame (conditional replenishment). In PCM mode, the color of each pixel is written to the bitstream, without any compression.|$|E
30|$|It can be {{understood}} that through using the proposed classifier, the classification accuracies are increased significantly {{when compared to the}} <b>pixel-wised</b> classification. In the Indian Pines, the MSEPF-MMSF increases the classification accuracy compared to the SVM classifier by about 13 %. In the PaviaU data set, the OA is improved by 18 % points and the AA by 12.13 % points. It is worth noting that the SSEPF-MMSF classifier is presented with better performance than the MSEPF-MMSF classifier in the PaviaU. In the following, the reason for this result is explained. PaviaU data set contained many small areas such as shadow.|$|R
40|$|In this paper, a {{supervised}} {{video object}} segmentation algorithm {{using a small}} number of interactions is proposed. The proposed algorithm is composed of three steps: semi-automatic first frame segmentation, automatic object tracking and boundary refinement. Homogeneous region segmentation is performed before the user interaction for the first frame to minimize the amount of interaction. Then, a polygon with very few key nodes can be drawn conveniently to get the segmentation mask of the first frame. In the object region tracking, <b>pixel-wised</b> backward tracking is adopted. Finally, a method for the mask refinement is proposed by considering similar pixels of each pixel in its neighbor region. Extensive experimental results show that the proposed algorithm is effective for video object segmentation semiautomatically. 1...|$|R
40|$|Although it is a {{powerful}} feature selection algorithm, the wrapper method is rarely used for hyperspectral band selection. Its accuracy is restricted {{by the number of}} labeled training samples and collecting such label information for hyperspectral image is time consuming and expensive. Benefited from the local smoothness of hyperspectral images, a simple yet effective semisupervised wrapper method is proposed, where the edge preserved filtering is exploited to improve the <b>pixel-wised</b> classification map and this in turn can be used to assess the quality of band set. The property of the proposed method lies in using the information of abundant unlabeled samples and valued labeled samples simultaneously. The effectiveness of the proposed method is illustrated with five real hyperspectral data sets. Compared with other wrapper methods, the proposed method shows consistently better performance...|$|R
30|$|Therefore, we use {{different}} criteria for object labeling. We calculate four evaluation metrics of (1) <b>pixel-wise</b> precision rate per object averaged over all object predictions (Mi-AP), (2) <b>pixel-wise</b> recall rate per object of groundtruth (Mi-AR), (3) <b>pixel-wise</b> precision rate over all pixels (Ma-AP), and (4) <b>pixel-wise</b> recall rate over all pixels (Ma-AR).|$|E
30|$|The {{two lines}} {{at the bottom of}} each chart {{presents}} the performance of <b>pixel-wise</b> methods: anisotropic diffusion and the bilateral filter. From the charts, we can conclude that the block-wise denoising methods perform better than the <b>pixel-wise</b> methods. When using σ= 10 and σ= 20, the results are similar except with the <b>pixel-wise</b> methods. The performance of the methods will be discussed in the following two paragraphs.|$|E
30|$|A {{number of}} {{fingerprint}} segmentation methods are known from literature, {{which can be}} roughly divided into block-wise methods [3 – 12] and <b>pixel-wise</b> methods [13 – 16]. Block-wise methods first partition a fingerprint image into nonoverlapping blocks of the same size, and then classify the blocks into foreground and background based on the extracted block-wise features. <b>Pixel-wise</b> methods classify pixels through the analysis of <b>pixel-wise</b> features. The commonly used features in fingerprint segmentation include gray-level features, orientation features, frequency domain features, and so forth.|$|E
40|$|In {{the field}} of {{saliency}} detection, many graph-based algorithms heavily depend on {{the accuracy of the}} pre-processed superpixel segmentation, which leads to significant sacrifice of detail information from the input image. In this paper, we propose a novel bottom-up saliency detection approach that takes advantage of both region-based features and image details. To provide more accurate saliency estimations, we first optimize the image boundary selection by the proposed erroneous boundary removal. By taking the image details and region-based estimations into account, we then propose the regularized random walks ranking to formulate <b>pixel-wised</b> saliency maps from the superpixel-based background and foreground saliency estimations. Experiment results on two public datasets indicate the significantly improved accuracy and robustness of the proposed algorithm in comparison with 12 state-of-the-art saliency detection approaches. 1...|$|R
40|$|Deformation {{monitoring}} by multi-baseline repeat-pass {{synthetic aperture}} radar (SAR) interferometry is so far the only imaging-based method to assess millimeter-level deformation over large areas from space. Past research mostly focused on the optimal deformation parameters retrieval on a pixel-basis. Only until recently, the first demonstration of object-based urban infrastructures monitoring by fusing SAR interferometry (InSAR) and the semantic classification labels derived from optical images was presented in [1]–[3]. Given such classification label in the SAR image, we propose a general framework for object-based InSAR parameters retrieval where the estimation of the parameters is achieved in an object-level instead of pixel-wisely. Furthermore, to handle outliers in real data, a robust phase recovery step in prior to the parameters inversion is also introduced. The proposed method outperforms the current <b>pixel-wised</b> estimators, e. g. periodogram, {{by a factor of}} forty in the standard deviation of the linear deformation estimates, for scatterers with 0 dB signal-to-noise ratio. Last but not least, for practical demonstration on bridge monitoring, we presented a full workflow of long-term bridge monitoring using the proposed approach...|$|R
40|$|This paper {{presents}} an accurate non-rigid object segmentation method that fuses both statistical features and structural features. In particular, {{the approach is}} detailed and applied on liver segmentation. It consists of three main components. First, an image texture analysis is done to derive pixel level features. It efficiently fuses the statistical features with structural features to achieve better segmentation. Then, a trained classifier based on support vector machine (SVM) is applied to classify the image into liver pixels or non-liver pixels. Finally, composite morphological operations are used to remove small wrongly classified areas and delineate the liver region. The approach is unique in two aspects: it states and provides experimental data {{to demonstrate that the}} fusion of the two classes of features does improve segmentation rate, comparing to the cases where only statistical features or structural features are used; it shows that an accurate segmentation can be achieved by combing regional morphological operations with <b>pixel-wised</b> SVM classifier. The algorithm can be applied to general non-rigid object segmentation which is a crucial part of an automatic surgical training and planning system...|$|R
3000|$|Sum of <b>pixel-wise</b> {{absolute}} {{differences of}} every two consecutive images, {{divided by the}} number of summands (Equation 6) [...]...|$|E
3000|$|... are <b>pixel-wise</b> operators, the {{computational}} {{complexity of}} GAC {{is the same}} as that of the AC model, i.e., O(C [...]...|$|E
30|$|Simple <b>pixel-wise</b> {{refinement}} post-processing is additionally {{proposed to}} improve the disparity map after calculation. In general it is similar to propagation {{in the way that}} it propagates disparities through their immediate neighbours but this time it uses <b>pixel-wise</b> matching cost (AD or BT) and penalises disparity jumps thus smoothing the overall disparity image. In order to reduce the smoothing near edge features the penalty is reduced if the corresponding image intensity gradient is high.|$|E
30|$|B, j =  1, 2, …, n} at the input. At first, the hyperspectral {{image is}} {{smoothed}} by multiscale bilateral filter defined in Section  2. At this point, the controversial {{issue is the}} reference image selection, I. In order to tackle this problem, principal component analysis (PCA) is applied because the optimum portrayal of the image {{is presented in the}} mean-squared sense. Original hyperspectral image undergoes dimension reduction via PCA, and the first r principal components are chosen as the reference image for the bilateral filter. The value of r can be automatically selected by analyzing the eigenvalues of scatter matrices computed from the PCA [26]. In this step, we have Q-filtered images. A spectral-spatial classification using MMSF is done in each individual Q scale. We propose to use an SVM classifier for <b>pixel-wised</b> classification, which is strongly suitable for hyperspectral data classification [13]. In the pre-segmentation stage, we implemented watershed since it detects good boundaries and retains small differences within the objects. Typically, the watershed transformation is used for a one-band image. There are several ways for generalizing this technique to an r-band hyperspectral image [19].|$|R
40|$|Synthetic {{aperture}} radar (SAR) interferometry is {{the only}} imaging-based method for assessing long-term millimetre-level deformation of individual building over a large area from space, credited to the availability of meter-resolution spaceborne SAR data, and the development in advanced InSAR techniques, such as SAR tomography. However, the inevitable SAR side-looking imaging geometry results in undesired occlusion and layover especially in urban areas, rendering the SAR images difficult to interpret. Aiming at a semantic-level urban infrastructure monitoring, this paper proposed an algorithm to bridge the precise deformation estimates of InSAR and good visual interpretability of optical images by a strict 3 -D geometric fusion of SAR and optical images, {{which has not been}} mentioned for large urban area so far. Via the precise geometrical fusion, the semantics derived from optical image can be fused to the InSAR point clouds. The proposed approach provides the first InSAR point cloud of an entire urban area textured with optical attributes. Hence, the InSAR deformation analysis can be done systematically in a semantic level, instead of the current <b>pixel-wised</b> analysis and manual identification of the regions of interest. Examples on bridges and railway segments monitoring are demonstrated...|$|R
40|$|Deformation {{monitoring}} by multi-baseline repeat-pass {{synthetic aperture}} radar (SAR) interferometry is so far the only imaging-based method to assess millimeter-level deformation over large areas from space. Past research mostly focused on the optimal deformation parameters retrieval on a pixel-basis. Only until recently, the first demonstration of object-based urban infrastructures monitoring by fusing SAR interferometry (InSAR) and the semantic classification labels derived from optical images was presented in [1]–[3]. This paper demonstrates a general framework for object-based InSAR parameters retrieval where the estimation of the parameters is achieved in an object-level instead of pixel-wisely. Furthermore, to handle outliers in real data, a robust phase recovery step in prior to the parameters inversion is also introduced. The proposed method outperforms the current <b>pixel-wised</b> estimators, e. g. periodogram, {{by a factor of}} as much as several dozens in the accuracy of the linear deformation estimates. [1] Y. Wang and X. X. Zhu, “Fusing Meter-Resolution 4 -D InSAR Point Clouds and Optical Images for Semantic Urban Infrastructure Monitoring,” IEEE Trans. Geosci. Remote Sens., 2016. [2] Y. Wang and X. X. Zhu, “InSAR Forensics: Tracing InSAR Scatterers in High Resolution Optical Image,” presented at the Fringe 2015, 2015. [3] Y. Wang and X. X. Zhu, “Semantic Fusion of SAR Interferometry and Optical Image with Application to Urban Infrastructure Monitoring,” presented at the CMRT, France, La Grande Motte, France, 2015...|$|R
40|$|Full list {{of author}} {{information}} {{is available at the}} end of the articlesampling points along the T 2 * decay curve using a gradient-echo sequence and then fitting the points to an exponential function-. This tool allows clinicians to study and diagnose diseases that cause iron overload in tissue such as β-thalassemia and hemochromatosis [3 - 7]. values have potential to provide more spatial context than the ROI-based method in that the delineation of adjacent tissues with different T 2 * values may be less ap-parent on the raw images. Studies have shown that using <b>pixel-wise</b> T 2 * maps as opposed to the region-based approach reduces inter- and intra-observer variability [8]. However, <b>pixel-wise</b> T 2 * mapping suffers from * Correspondence: hui. xue@nih. gov 1 National Heart, Lung, and Blood Institute, National Institutes of Health,verse relaxation decay rate after electromagnetic excita-region-based mapping thereby decreasing both its accuracy and precision. In this study, the effects that noise has on the precision and accuracy of <b>pixel-wise</b> T 2 * mapping were investigated and techniques to mitigate those effects are proposed. Methods: To study precision across T 2 * mapping techniques, a pipeline to estimate the <b>pixel-wise</b> standard deviatio...|$|E
30|$|We {{combined}} the class likelihoods and scores by using <b>pixel-wise</b> SVM training and evaluated {{the performances of}} the individual methods and their combinations.|$|E
3000|$|... 2 -norm {{minimization}} approach, {{which is}} essentially taking the <b>pixel-wise</b> mean of the aligned images, is performed to produce the final HR image.|$|E
3000|$|The <b>pixel-wise</b> {{difference}} between the current image and the previous image warped provides information on {{the likelihood of the}} current object state candidate, s [...]...|$|E
40|$|Dynamic contrast-enhanced {{magnetic}} resonance imaging was performed in control patients with normal bone marrow and patients with untreated bone metastases of prostate cancer (PCa). Perfusion data were assessed using region of interest-based and <b>pixel-wise</b> current standard postprocessing techniques (signal intensity pattern, increase in signal intensity, upslope, time to peak, extended Kety model, k-means clustering). Bone marrow perfusion is significantly increased in bone metastases of PCa compared to normal bone marrow. <b>Pixel-wise</b> kinetic modeling should be recommended to assess tumoral processes affecting bone marrow microcirculation...|$|E
40|$|Objectives To {{compare the}} values of {{pulmonary}} regurgitation in patients with repaired Tetralogy of Fallot quantified from two-dimensional phase-contrast data, by using a new <b>pixel-wise</b> analysis and the standard velocity-averaging method. Design Quantitative in silico and in vivo analysis. Setting Hospital Sótero del Río. The magnetic resonance images were acquired using a Philips Achieva 1. 5 T scanner. Participants Twenty-five patients with repaired Tetralogy of Fallot who underwent cardiovascular magnetic resonance imaging requested by their referring physicians were included in this study. Main outcome measures Using a computational fluid dynamics simulation, we validated our <b>pixel-wise</b> method, quantifying the error of our method {{in comparison with the}} standard method. The patients underwent a standard two-dimensional phase-contrast magnetic resonance imaging acquisition for quantifying pulmonary artery flow. Pulmonary regurgitation fraction was estimated by using our <b>pixel-wise</b> and the standard method. The two-dimensional flow profiles were inspected looking for simultaneous antegrade and retrograde flows in the same cardiac phase. Statistical analysis was performed with t-test for related samples, Bland–Altman plots, and Pearson correlation coefficient. Results Estimation of pulmonary regurgitation fraction using the <b>pixel-wise</b> analysis revealed higher values compared with the standard method (39 [*]±[*] 16 % vs. 30 [*]±[*] 22 %, p-value < 0. 01). Eight patients (32 %) had a difference of more than 10 % between methods. Analysis of two-dimensional flow profiles in these patients revealed simultaneous antegrade and retrograde flows through the pulmonary artery during systole–early diastole. Conclusion Quantification of pulmonary regurgitation fraction in patients with repaired Tetralogy of Fallot through a <b>pixel-wise</b> analysis yields higher values of pulmonary regurgitation compared with the standard velocity-averaging method...|$|E
3000|$|... 2010). SOFI {{is based}} on a <b>pixel-wise</b> auto- or cross-cumulant analysis, which yields a {{resolution}} enhancement growing with the cumulant order in all three dimensions (Dertinger et al.|$|E
3000|$|Poisson {{noise is}} applied {{on the image}} <b>pixel-wise.</b> Each pixel has a Poisson noise drawn from a Poisson {{distribution}} with mean equal to the pixel value. 1 [...]...|$|E
40|$|Autonomously {{detecting}} novelties using background subtraction has {{quickly become}} a very important area of image analysis with many different approaches to novelty detection and the output therein. The ultimate goal of the approaches is to be robust to false detections and noise whilst using as little computational power as possible. This review focuses {{on some of the}} most prominent <b>pixel-wise</b> background subtraction techniques currently in use, and compares and contrasts their attributes and capabilities. The purpose of this review is to practically summarize the <b>pixel-wise</b> approaches and suggest a way forward from these techniques...|$|E
40|$|International audienceThe paper {{presents}} a new segmentation and classification scheme to analyze hyperspectral (HS) data. The Robust Color Morphological Gradient of the HS image is computed, and the watershed transformation {{is applied to}} the obtained gradient. After the <b>pixel-wise</b> Support Vector Machines classification, the majority voting within the watershed regions is performed. Experimental results are presented on a 103 -airborne ROSIS image, of the University of Pavia, Italy. The integration of the spatial information from the watershed segmentation into the HS image classification improves the classification accuracies, when compared to the <b>pixel-wise</b> classification...|$|E
3000|$|As {{mentioned}} in Section 3, interlaced BI-RL is useful only when <b>pixel-wise</b> computations (2) and (5), instead of FFT-based ones, {{are used for}} [...] T and [...] T^*. In simulation studies, we used a personal computer equipped with 2.0 GHz Intel Core 2 Duo CPU and 8 GB RAM. In this computing environment, one RL iteration with FFT-based computations took 5.04 s both for Gaussian and diagonal deblurrings. On the other hand, one round of interlaced BI-RL (the for-loop in steps I 3, I 4, and I 5) with <b>pixel-wise</b> computations took 4.84 s for 4 × 4 rectangularly-down-sampled blocks for Gaussian deblurring (| S_k_G| = 441) and 0.88 s for 8 diagonally-down-sampled blocks for the diagonal deblurring (| S_k_D| = 61). This result implies that interlaced BI-RL is, at least computational point of view, useful for both deblurring problems in our simulation. Considering these facts, we used <b>pixel-wise</b> computations (2) and (5) in our simulation.|$|E
3000|$|... 1 -norm {{minimization}} SR {{because the}} study of Farsiu et al. (2004) showed {{that it is more}} robust and highlights edges more clearly [2]. Thus, from a <b>pixel-wise</b> mean, L [...]...|$|E
