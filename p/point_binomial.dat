1|48|Public
40|$|Weighted Monte Carlo {{calculations}} {{requiring a}} uniform {{sampling of the}} problem-space can suffer from diminished statistical significance because many, if not most, of the randomly-chosen sampling points contribute only slightly to the desired result. Their contribution is reduced in size due the variable-size of the weighting terms. In contrast, none of the randomly-chosen points which are favored by variable size weighting terms will have their statistical significance enhanced beyond that of just one random point in the Monte Carlo sampling. A Monte Carlo analysis was used in earlier work to verify both Gauss 2 ̆ 7 Law and Newton 2 ̆ 7 s Shell Theorem. Both examples suffered from statistical difficulties since each Monte Carlo sampling point has a weight inversely proportional to {{the square of the}} distance between source and field points. The present work analyzes the diminished significance in weighted Monte Carlo for the specific example of Newton 2 ̆ 7 s Shell Theorem, describing the geometry in terms of closest approach distance of the spherical mass shell to the field <b>point.</b> <b>Binomial</b> Statistics is used to remedy this diminished statistical significance by providing a prescription for increasing the value of the Monte Carlo sample size needed to assure that the chosen precision remains invariant as the mass-shell geometry is changed...|$|E
40|$|Relative {{intra-day}} cumulative {{volume is}} intra-day cumulative volume divided by final total volume. If intra-day cumulative volume is modeled as a Cox (doubly stochastic Poisson) point process, then using initial enlargement of filtration with the filtration of the Cox process enlarged by knowledge of final volume, it is shown that relative intra-day volume conditionally has a binomial distribution {{and is a}} novel generalization of a <b>binomial</b> <b>point</b> process: the doubly stochastic <b>binomial</b> <b>point</b> process. Re-scaling the intra-day traded volume to a relative volume between 0 (no volume traded) and 1 (daily trading completed) allows empirical intra-day volume distribution information for all stocks to be used collectively to estimate and identify the random intensity component of the doubly stochastic <b>binomial</b> <b>point</b> process and closely related Cox point process. Doubly stochastic <b>binomial</b> <b>point</b> process, Relative volume, Cox process, Initial enlargement of filtration, NYSE, New York Stock Exchange, VWAP,...|$|R
30|$|The {{result for}} <b>binomial</b> <b>point</b> {{processes}} will follow from Theorem 1.6 {{and the following}} result.|$|R
30|$|Now also we give a {{function}} at a <b>point</b> p^nx by <b>binomial</b> expression and (p,q)-derivative of order k.|$|R
30|$|The {{convergence}} of {{the expectations of}} Betti numbers of Čech complexes built on <b>binomial</b> <b>point</b> processes in the thermodynamic regime is established.|$|R
40|$|Negative <b>binomial</b> <b>point</b> {{processes}} are defined for which all finite-dimensional distributions associated with disjoint bounded Borel sets are negative binomial {{in the usual}} sense. For these processes we study classical notions such as infinite divisibility, conditional distributions, Palm probabilities, convergence, etc. Negative <b>binomial</b> <b>point</b> processes appear to be of interest because they are mathematically tractable models {{which can be used}} in many situations. The general results throw some new light on some well-known special cases like the Polya process and the Yule process. ...|$|R
40|$|If {{intra-day}} {{volume is}} modelled as a Cox point process, then relative intra-day cumulative volume (intra-day cumulative volume divided by final total volume) {{is shown to}} be a novel generalization of a <b>binomial</b> <b>point</b> process; the doubly stochastic <b>binomial</b> <b>point</b> process. Re-scaling the intra-day traded volume to a relative volume between 0 (no volume traded) and 1 (daily trading completed) allows empirical intra-day volume distribution information for all stocks to be used collectively to estimate and identify the random intensity component of the <b>binomial</b> <b>point</b> process and closely related Cox point process. This is useful for Volume Weighted Average Price (VWAP) traders who require a stochastic model of relative intra-day cumulative volume to implement risk-optimal VWAP trading strategies. binomial; point process; doubly stochastic; relative volume; Cox process, random probability measure; VWAP; volume weighted average pricing; NYSE; New York Stock Exchange...|$|R
3000|$|... 2,…, be a {{sequence}} of i.i.d. (independent identically distributed) R^d-valued random variables with common probability density function f(x). Define the induced <b>binomial</b> <b>point</b> processes as X_n = {X_ 1, [...]..., X_n}. The object here is the Čech complex C (X_n, r_n) built on X_n, where the radius r [...]...|$|R
40|$|The {{likelihood}} function for the positive binomial with unknown parameters, N and p, {{is not in}} general unimodal. However, it is unimodal in a large class of cases (for example, when {{the mean of the}} observations is an integer). This paper develops sufficient conditions for unimodality and presents a counter-example to unimodality when these conditions do not hold. This example is given {{in the form of a}} set of observations for which the {{likelihood function}} has two critical points: a local maximum and a saddle <b>point.</b> Positive <b>binomial</b> unimodality maximum likelihood estimator...|$|R
40|$|We {{develop a}} new class of event {{detection}} algorithms in Wireless Sensor Networks where the sensors are randomly deployed spatially. We formulate the detection problem as a binary hypothesis testing problem and design the optimal decision rules for two scenarios, namely the Poisson <b>Point</b> Process and <b>Binomial</b> <b>Point</b> Process random deployments. To calculate the intractable marginal likelihood density, we develop three types of series expansion methods which are based on an Askey-orthogonal polynomials. In addition, we develop a novel framework to provide guidance on which series expansion is most suitable (i. e., most accurate) to use for different system parameters. Extensive Monte Carlo simulations are carried out to illustrate the benefits of this framework as well as the quality of the series expansion methods, and the impacts that different parameters have on detection performance via the Receiver Operating Curves (ROC) ...|$|R
30|$|It {{is noted}} that the method here {{can be applied to}} show the {{convergence}} of persistence diagrams of Čech complexes built on <b>binomial</b> <b>point</b> processes. The convergence of Betti numbers and persistence diagrams related to i.i.d. sampling were observed in [4] by numerical simulation. Here we give a rigorous mathematical proof of the convergences.|$|R
40|$|We give error bounds which {{demonstrate}} optimal {{rates of}} convergence in the CLT {{for the total}} covered volume {{and the number of}} isolated shapes, for germ-grain models with fixed grain radius over a <b>binomial</b> <b>point</b> process of $n$ points in a toroidal spatial region of volume $n$. The proof is based on Stein's method via size-biased couplings. Comment: Published in at [URL] the Annals of Applied Probability ([URL] by the Institute of Mathematical Statistics ([URL]...|$|R
30|$|To {{establish}} a limit theorem for Betti numbers, we exploit {{the following two}} properties. The first one is the nearly additive property of Betti numbers {{that was used in}} [9] to study Betti numbers of Čech complexes built on stationary point processes. The second one is the property that <b>binomial</b> <b>point</b> processes behave locally like a homogeneous Poisson point process. The latter property is also a key tool to establish the law of large numbers for local geometric functionals [6, 7].|$|R
40|$|Abstract—This paper {{analyzes}} the outage performance in finite wireless networks. Unlike most prior works, which either assumed a specific network shape or considered a special {{location of the}} reference receiver, we propose two general frameworks for analytically computing the outage probability at any arbitrary location of an arbitrarily-shaped finite wireless network: (i) a moment generating function-based framework {{which is based on}} the numerical inversion of the Laplace transform of a cumulative distribution and (ii) a reference link power gain-based framework which exploits the distribution of the fading power gain between the reference transmitter and receiver. The outage probability is spatially averaged over both the fading distribution and the possible locations of the interferers. The boundary effects are ac-curately accounted for using the probability distribution function of the distance of a random node from the reference receiver. For the case of the node locations modeled by a <b>Binomial</b> <b>point</b> process and Nakagami-m fading channel, we demonstrate the use of the proposed frameworks to evaluate the outage probability at any location inside either a disk or polygon region. The analysis illustrates the location dependent performance in finite wireless networks and highlights the importance of accurately modeling the boundary effects. Index Terms—Finite wireless networks, outage probability, <b>Binomial</b> <b>point</b> process, distance distributions, boundary effects...|$|R
40|$|The use of {{confidence}} intervals to estimate population parameters is briefly reviewed. Exact binomial confidence intervals {{can be calculated}} {{through the use of}} tables or statistical software packages. As an alternative, a microcomputer program to calculate sensitivity and specificity, <b>point</b> estimates and <b>binomial</b> confidence intervals for false-negative and -positive rate, positive and negative predictive power, prevalence of cases and non-cases, correct classification rate, and misclassification rate has also been developed. Characteristics of the computer program, 'AccuCon', which is available from the authors, are described. (C) 1997 Elsevier Science Ireland Ltd. status: publishe...|$|R
40|$|This {{survey of}} methods {{surrounding}} lattice <b>point</b> methods for <b>binomial</b> ideals {{begins with a}} leisurely treatment of the geometric combinatorics of binomial primary decomposition. It then proceeds to three independent applications whose motivations come from outside of commutative algebra: hypergeometric systems, combinatorial game theory, and chemical dynamics. The exposition is aimed at students and researchers in algebra; it includes many examples, open problems, and elementary introductions to the motivations and background from outside of algebra. Comment: 57 pages, 31 figures; to appear in proceedings of 2009 Abel Symposium (Voss, Norway...|$|R
3000|$|... which {{characteristically}} {{appears in}} the analysis of aggregate interference with discrete node location models (continuous models will be explained in Section 3.2). The function f(·) represents the received power from an individual interferer at location ×. Consequently, I=∑ _×∈Φf(×). Since I is a RV that is strictly positive, its LT always exists. It {{is important to note that}} the exact expressions for the LT, MGF, and CF are only available for basic PPs, encompassing PPP, <b>binomial</b> <b>point</b> process (BPP), and Poisson cluster process (PCP). For other types of PPs such as hardcore processes, only approximations are available.|$|R
40|$|We {{present a}} novel event {{detection}} algorithm in sensor networks {{for the case}} where the sensors are randomly deployed in space. In particular we consider a random sensors deployment according to a Homogeneous Finite <b>Binomial</b> <b>Point</b> Process. We first derive the optimal event detection decision rule. We then develop a novel algorithm to evaluate the intractable marginal likelihood based on the Gram-Charlier series expansion. We evaluate our algorithms through extensive Monte Carlo simulations. Simulation results present the detection and false alarm rates for different system parameters such as number of sensors deployed, deployment region size etc...|$|R
40|$|Random {{abstract}} {{simplicial complex}} representation provides a mathematical description of wireless networks and their topology. In {{order to reduce}} the energy consumption in this type of network, we intend {{to reduce the number of}} network nodes without modifying neither the connectivity nor the coverage of the network. In this paper, we present a reduction algorithm that lower the number of points of an abstract simplicial complex in an optimal order while maintaining its topology. Then, we study the complexity of such an algorithm for a network simulated by a <b>binomial</b> <b>point</b> process and represented by a Vietoris-Rips complex...|$|R
40|$|Using a {{coupling}} argument, we establish a general weak law {{of large numbers}} for functionals of <b>binomial</b> <b>point</b> processes in d-dimensional space, with a limit that depends explicitly on the (possibly non-uniform) density of the point process. The general result {{is applied to the}} minimal spanning tree, the k-nearest neighbors graph, the Voronoi graph, and the sphere of influence graph. Functionals of interest include total edge length with arbitrary weighting, number of vertices of specifed degree, and number of components. We also obtain weak laws for functionals of marked point processes, including statistics of Boolean models. ...|$|R
30|$|Samuel and Pignatiello (2001) derived {{the maximum}} {{likelihood}} estimator (MLE) of a step-change <b>point</b> for <b>binomial</b> processes. Evaluating the estimator for different shift sizes, {{they concluded that}} it provides accurate results. In {{the case of a}} step change, Perry and Pignatiello (2005) compared the MLE of the process fraction non-conforming with the built-in change-point estimators of the binomial CUSUM and EWMA control charts described by Page (1954) and Nishina (1992), respectively. They showed that the MLE provides better results than the other two estimators do. Perry et al. (2007) derived the MLE of a monotonic change point of the process fraction non-conforming and compared it with the MLE of a step-change point derived by Samuel and Pignatiello (2001). They concluded that using their proposed estimator is better when the type of change is only known to be monotonic. Zandi et al. (2011) proposed an MLE to estimate the time of a linear-trend change in the process fraction non-conforming and compared it to the MLEs derived for step and monotonic change disturbances proposed by Samuel and Pignatiello (2001) and Perry et al. (2007), respectively.|$|R
40|$|In a digraph with n vertices, a {{minuscule}} construct is a subdigraph with m<<n vertices. We study {{the number of}} copies of {{a minuscule}} constructs in k nearest neighbor (kNN) digraph of the data from a random point process in R^d. Based on the asymptotic theory for functionals of point sets under homogeneous Poisson process and <b>binomial</b> <b>point</b> process, we provide a general result for the asymptotic behavior {{of the number of}} minuscule constructs and as corollaries, we obtain asymptotic results for the number of vertices with fixed indegree, the number of shared kNN pairs and the number of reflexive kNN's in a kNN digraph. Comment: 28 pages, 7 figure...|$|R
40|$|The lilypond {{model on}} a point process in $d$-space is a growth-maximal system of {{non-overlapping}} balls centred at the points. We establish central limit theorems for the total volume {{and the number of}} components of the lilypond model on a sequence of Poisson or <b>binomial</b> <b>point</b> processes on expanding windows. For the lilypond model over a homogeneous Poisson process, we give subexponentially decaying tail bounds for the size of the cluster at the origin. Finally, we consider the enhanced Poisson lilypond model where all the balls are enlarged by a fixed amount (the enhancement parameter), and show that for $d > 1 $ the critical value of this parameter, above which the enhanced model percolates, is strictly positive...|$|R
40|$|When S=(S_t) _t> 0 is an α-stable subordinator, the {{sequence}} of ordered jumps of S, up till time 1, omitting the r largest of them, and taken as proportions of their sum ^(r) S_t, defines a 2 -parameter distribution on the infinite dimensional simplex, ∇_∞, which we call the PD_α^(r) distribution. When r= 0 it reduces to the PD_α distribution introduced by Kingman in 1975. We observe a serendipitous connection between PD_α^(r) and the negative <b>binomial</b> <b>point</b> process of Gregoire (1984), which we exploit to analyse in detail a size-biased version of PD_α^(r). As a consequence we derive a stick-breaking representation for the process and a useful form for its distribution. This program produces a large new class of distributions available {{for a variety of}} modelling purposes. Comment: 17 page...|$|R
40|$|The paper {{analyses}} the {{outage probability}} of a radio node in a finite size large-scale data aggregation network which employs slotted random medium access. In most literature, this performance metric is usually derived from a Poisson point process distribution of radio nodes in infinite space. In contrast, we analyse a network with finite area and a fixed number of interfering nodes using a <b>binomial</b> <b>point</b> process. Based on the point process, conditional outage probabilities in a log-normal fading channel in case of n interferers are derived. These interim results are used to obtain the outage {{probability of a}} desired radio node {{as a function of}} the offered network load. We present numerical outage probabilities for distinct path loss exponents, capture thresholds and varying distances between node and receiver...|$|R
40|$|We {{investigated}} temporal {{trends and}} geographical variations in lung cancer mortality in China from 2006 to 2012. Lung cancer mortality counts for people aged over 40 years were {{extracted from the}} China Mortality Surveillance System for 161 disease surveillance <b>points.</b> Negative <b>binomial</b> regression was used to investigate potential spatiotemporal variation and correlations with age, gender, urbanization, and region. Lung cancer mortality increased in China over the study period from 78. 77 to 85. 63 (1 / 100, 000), with higher mortality rates evident in men compared to women. Median rate ratios (MRRs) indicated important geographical variation in lung cancer mortality between provinces (MRR = 1. 622) and counties/districts (MRR = 1. 447). On average, lung cancer mortality increased over time and was positively associated with county-level urbanization (relative risk (RR) = 1. 15). Lung cancer mortality seemed to decrease in urban and increase in rural areas. Compared to the northwest, mortality was higher in the north (RR = 1. 98), east (RR = 1. 87), central (RR = 1. 87), and northeast (RR = 2. 44). Regional differences and county-level urbanization accounted for 49. 4 % and 8. 7 % of provincial and county variation, respectively. Reductions in lung cancer mortality in urban areas may reflect improvements in access to preventive healthcare and treatment services. Rising mortality in rural areas may reflect a clustering of risk factors associated with rapid urbanization...|$|R
40|$|Abstract — Reliable channel {{estimation}} is {{an essential}} task {{in the development of}} receivers for multiple input multiple output (MIMO) finite ad hoc networks. The major problem in the estimation of channel coefficients in a MIMO ad hoc network is the interference from the other nodes. In this paper, channel estimation is performed for a finite MIMO ad hoc network where transmitter employs antenna selection. The spatial node distribution in a finite network, containing finite number of nodes in a finite region is characterized using the <b>binomial</b> <b>point</b> process. Linear Minimum Mean Square Error (LMMSE) algorithm is developed for estimating channel coefficients using training sequences. The algorithm uses the spatial correlation of receive antennas. The MSE performance of proposed LMMSE channel estimator for MIMO ad hoc network in the interference limited environment is analysed through simulations...|$|R
40|$|Let η t be a Poisson point {{process with}} {{intensity}} measure tμ, t> 0, over a Borel space X, where μ is a fixed measure. Another point process ξ t {{on the real}} line is constructed by applying a symmetric function f to every k -tuple of distinct points of η t. It is shown that ξ t behaves after appropriate rescaling like a Poisson point process, as t→∞, under suitable conditions on η t and f. This also implies Weibull limit theorems for related extreme values. The result is then applied to investigate problems arising in stochastic geometry, including small cells in Voronoi tessellations, random simplices generated by non-stationary hyperplane processes, triangular counts with angular constraints and non-intersecting k -flats. Similar results are derived if the underlying Poisson point process {{is replaced by a}} <b>binomial</b> <b>point</b> process...|$|R
40|$|Let η_t be a Poisson point {{process with}} {{intensity}} measure tμ, t> 0, over a Borel space X, where μ is a fixed measure. Another point process ξ_t {{on the real}} line is constructed by applying a symmetric function f to every k-tuple of distinct points of η_t. It is shown that ξ_t behaves after appropriate rescaling like a Poisson point process, as t→∞, under suitable conditions on η_t and f. This also implies Weibull limit theorems for related extreme values. The result is then applied to investigate problems arising in stochastic geometry, including small cells in Voronoi tessellations, random simplices generated by non-stationary hyperplane processes, triangular counts with angular constraints and non-intersecting k-flats. Similar results are derived if the underlying Poisson point process {{is replaced by a}} <b>binomial</b> <b>point</b> process. Comment: Chapter of the forthcoming book "Stochastic analysis for Poisson point processes: Malliavin calculus, Wiener-Itō chaos expansions and stochastic geometry" edited by G. Peccati and M. Reitzne...|$|R
40|$|Cache-enabled {{device-to-device}} (D 2 D) networks turn {{memory of}} the devices at the network edge, such as smart phones and tablets, into bandwidth by enabling asynchronous content sharing directly between proximate devices. Limited storage capacity of the mobile devices necessitates the determination of optimal set of contents to be cached on each device. In order to study the problem of optimal cache placement, we model the locations of devices in a finite region (e. g., coffee shop, sports bar, library) as a uniform <b>binomial</b> <b>point</b> process (BPP). For this setup, we first develop a generic framework to analyze the coverage probability of the target receiver (target-Rx) when the requested content {{is available at the}} $k^{th}$ closest device to it. Using this coverage probability result, we evaluate optimal caching probability of the popular content to maximize the total hit probability. Our analysis concretely demonstrates that optimal caching probability strongly depends on the number of simultaneously active devices in the network...|$|R
40|$|Abstract—Most {{studies that}} {{consider}} {{the problem of}} estimating {{the location of a}} point source in wireless sensor networks assume that the source location is estimated by a set of spatially distributed sensors, whose locations are fixed. Motivated {{by the fact that the}} observation quality and performance of the localization algorithm depend on the location of the sensors, which could be randomly distributed, this paper investigates the performance of a recently proposed energy-based source-localization algorithm under the assumption that the sensors are positioned according to a uniform clustering process. Practical considerations such as the existence and size of the exclusion zones around each sensor and the source will be studied. By introducing a novel performance measure called the estimation outage, it will be shown how parameters related to the network geometry such as the distance between the source and the closest sensor to it as well as the number of sensors within a region surrounding the source affect the localization performance. Index Terms—Distributed source localization, distributed esti-mation, spatial randomness, <b>binomial</b> <b>point</b> process with repul-sion, uniform clustering process, energy detector, fusion center, wireless sensor networks. I...|$|R
40|$|Modeling the {{locations}} of nodes as a uniform <b>binomial</b> <b>point</b> process (BPP), we present a generic mathematical framework to characterize the performance of an arbitrarily-located reference receiver in a finite wireless network. Different {{from most of the}} prior works where the serving transmitter (TX) node is located at the fixed distance from the reference receiver, we consider two general TX-selection policies: i) uniform TX-selection: the serving node is chosen uniformly at random amongst transmitting nodes, and ii) k-closest TX-selection: the serving node is the k-th closest node out of transmitting nodes to the reference receiver. The key intermediate step in our analysis is the derivation of a new set of distance distributions that lead not only to the tractable analysis of coverage probability but also enable the analyses of wide range of classical and currently trending problems in wireless networks. Using this new set of distance distributions, we first investigate the diversity loss due to SIR correlation in a finite network. We then obtain the optimal number of links that can be simultaneously activated to maximize network spectral efficiency. Finally, we evaluate optimal caching probability to maximize the total hit probability in cache-enabled finite networks. Comment: A preliminary version of Section IV. C appears in the conference version available at arXiv: 1603. 0192...|$|R
40|$|Persistent homology, while ostensibly {{measuring}} {{changes in}} topology, captures multiscale geometrical information. It {{is a natural}} tool {{for the analysis of}} point patterns. In this paper we explore the statistical power of the (persistent homology) rank functions. For a point pattern X we construct a filtration of spaces by taking the union of balls of radius a centered on points in X, X_a = ∪_x∈ XB(x,a). The rank function β_k(X) :{(a,b) ∈R^ 2 : a≤ b}→R is then defined by β_k(X) (a,b) = rank (ι_*:H_k(X_a) → H_k(X_b)) where ι_* is the induced map on homology from the inclusion map on spaces. We consider the rank functions as lying in a Hilbert space and show that under reasonable conditions the rank functions from multiple simulations or experiments will lie in an affine subspace. This enables us to perform functional principal component analysis which we apply to experimental data from colloids at different effective temperatures and of sphere packings with different volume fractions. We also investigate the potential of rank functions in providing a test of complete spatial randomness of 2 D point patterns using the distances to an empirically computed mean rank function of <b>binomial</b> <b>point</b> patterns in the unit square. Comment: 25 pages, 15 figure...|$|R
40|$|In this work, we {{investigate}} the joint optimization of base station (BS) location, its density, and transmit power allocation {{to minimize the}} overall network operational cost required to meet an underlying coverage constraint at each user equipment (UE), which is randomly deployed following the <b>binomial</b> <b>point</b> process (BPP). As this joint optimization problem is nonconvex and combinatorial in nature, we propose a non-trivial solution methodology that effectively decouples it into three individual optimization problems. Firstly, by using the distance distribution of the farthest UE from the BS, we present novel insights on optimal BS location in an optimal sectoring type for a given number of BSs. After that we provide a tight approximation for the optimal transmit power allocation to each BS. Lastly, using the latter two results, the optimal number of BSs that minimize the operational cost is obtained. Also, we have investigated both circular and square field deployments. Numerical results validate the analysis and provide practical insights on optimal BS deployment. We observe that the proposed joint optimization framework, that solves the coverage probability versus operational cost tradeoff, can yield a significant reduction of about 65 % in the operational cost {{as compared to the}} benchmark fixed allocation scheme. Comment: 30 pages, 15 figures, submitted to IEEE Transactions on Green Communications and Networkin...|$|R
40|$|In {{a mobile}} ad hoc network (MANET), {{effective}} prediction of time-varying interferences can enable adaptive transmission designs and therefore improve the communication performance. This paper investigates interference prediction in MANETs with {{a finite number}} of nodes by proposing and using a general-order linear model for node mobility. The proposed mobility model can well approximate node dynamics of practical MANETs. In contrast to previous studies on interference statistics, we are able through this model to give a best estimate of the time-varying interference at any time rather than long-term average effects. Specifically, we propose a compound Gaussian point process functional as a general framework to obtain analytical results on the mean value and moment-generating function of the interference prediction. With a series form of this functional, we give the necessary and sufficient condition for when the prediction is essentially equivalent to that from a <b>Binomial</b> <b>Point</b> Process (BPP) network in the limit as time goes to infinity. These conditions permit one to rigorously determine when the commonly used BPP approximations are valid. Finally, our simulation results corroborate the effectiveness and accuracy of the analytical results on interference prediction and also show the advantages of our method in dealing with complex mobilities. Comment: 14 pages, 9 figures, accepted for publication in IEEE Transactions on Wireless Communication...|$|R
40|$|This paper {{analyzes}} the outage performance in finite wireless networks. Unlike most prior works, which either assumed a specific network shape or considered a special {{location of the}} reference receiver, we propose two general frameworks for analytically computing the outage probability at any arbitrary location of an arbitrarily-shaped finite wireless network: (i) a moment generating function-based framework {{which is based on}} the numerical inversion of the Laplace transform of a cumulative distribution and (ii) a reference link power gain-based framework which exploits the distribution of the fading power gain between the reference transmitter and receiver. The outage probability is spatially averaged over both the fading distribution and the possible locations of the interferers. The boundary effects are accurately accounted for using the probability distribution function of the distance of a random node from the reference receiver. For the case of the node locations modeled by a <b>Binomial</b> <b>point</b> process and Nakagami-$m$ fading channel, we demonstrate the use of the proposed frameworks to evaluate the outage probability at any location inside either a disk or polygon region. The analysis illustrates the location dependent performance in finite wireless networks and highlights the importance of accurately modeling the boundary effects. Comment: accepted to appear in IEEE Transactions on Communication...|$|R
