5|0|Public
40|$|Finding an {{objective}} image quality metric {{that matches the}} subjective quality {{has always been a}} challenging task. We propose a new full reference image quality metric based on features extracted from Convolutional Neural Networks (CNNs). Using a <b>pre-trained</b> <b>AlexNet</b> model, we extract feature maps of the test and reference images at multiple layers, and compare their feature similarity at each layer. Such similarity scores are then pooled across layers to obtain an overall quality value. Experimental results on four state-of-the-art databases show that our metric is either on par or outperforms 10 other state-of-the-art metrics, demonstrating that CNN features at multiple levels are superior to handcrafted features used in most image quality metrics in capturing aspects that matter for discriminative perception...|$|E
30|$|We trained a pre-trained CNN {{employing}} transfer {{learning in}} order to address the low sensitivity. Owing to optimized feature kernels that are trained using an image dataset in the order of millions, the <b>pre-trained</b> <b>AlexNet</b> enables a great improvement in performance compared to the HOG features based SVM classifier. Transfer learning makes it possible to apply a pre-trained network to a new domain such as T-cell and B-cell detection with a dataset only in the order of thousands. With AlexCAN we achieved an accuracy of 98 %, sensitivity of 97 % and specificity of 99 %. Even though recent advances in GPU architecture rendered it possible to train CNNs as large as ours, using the sliding window method and classifying all the windows in every image from an experiment is time consuming.|$|E
40|$|Glomerulus {{classification}} and detection in kidney tissue segments are key {{processes in}} nephropathology {{used for the}} correct diagnosis of the diseases. In this paper, {{we deal with the}} challenge of automating Glomerulus classification and detection from digitized kidney slide segments using a deep learning framework. The proposed method applies Convolutional Neural Networks (CNNs) between two classes: Glomerulus and Non-Glomerulus, to detect the image segments belonging to Glomerulus regions. We configure the CNN with the public <b>pre-trained</b> <b>AlexNet</b> model and adapt it to our system by learning from Glomerulus and Non-Glomerulus regions extracted from training slides. Once the model is trained, labeling is performed by applying the CNN classification to the image blocks under analysis. The results of the method indicate that this technique is suitable for correct Glomerulus detection in Whole Slide Images (WSI), showing robustness while reducing false positive and false negative detections...|$|E
40|$|Given the {{progress}} in image recognition with recent data driven paradigms, it's still expensive to manually label a large training data {{to fit a}} convolutional neural network (CNN) model. This paper proposes a hybrid supervised-unsupervised method combining a <b>pre-trained</b> <b>AlexNet</b> with Latent Dirichlet Allocation (LDA) to extract image topics from both an unlabeled life-logging dataset and the COCO dataset. We generate the bag-of-words representations of an egocentric dataset from the softmax layer of AlexNet and use LDA to visualize the subject's living genre with duplicated images. We use a subset of COCO on 4 categories as ground truth, and define consistent rate to quantitatively analyze {{the performance of the}} method, it achieves 84 % for consistent rate on average comparing to 18. 75 % from a raw CNN model. The method is capable of detecting false labels and multi-labels from COCO dataset. For scalability test, parallelization experiments are conducted with Harp-LDA on a Intel Knights Landing cluster: to extract 1, 000 topic assignments for 241, 035 COCO images, it takes 10 minutes with 60 threads. Comment: 9 pages, 9 figure...|$|E
40|$|The {{millions}} of filter weights in Convolutional Neural Networks (CNNs), {{all have a}} well-defined and analytical expression for the partial derivative to the loss function. Therefor these weights {{can be learned from}} data with a technique called gradient descent optimization. While the filter weights have a well-defined derivative, the filter size has not. There is currently no other way to optimize filter sizes, then with an exhaustive search over multiple CNNs trained with different filter sizes. In this report, we propose a new filter called Structured Receptive Field of which the filter size can be optimized during the training stage. This new filter constitutes a parameterization of a normal filter as a linear combination of all 2 D Gaussian derivatives up to a certain order. Instead of learning the weights of the resulting filter directly, we learn the weights of the linear combination and the sigma of the Gaussian derivatives that implicitly define the filter weights. The advantage of parameterizing normal filters in this way, is that gradient descent optimization of the continuous sigma parameter which has a well-defined derivative, {{can be used as a}} proxy for optimizing the discrete filter size which has no well-defined derivative. The basic idea for this parameterization comes from scale-space theory in which the scale of image features is studied by parameterizing the image features with a continuous scale parameter. Thereby explicitly decoupling the spatial structure of image feature from the scale at which it occurs in the image. Structured receptive fields have several compelling advantages: they can learn bigger filters without increasing the number of learnable parameters and without increasing the complexity of the structure of the filter. In this report, we both provide theoretical and empirical evidence that structured receptive fields can approximate any filter learned by normal CNNs. I. e. we show that structured receptive fields of order 4 can approximate the filters in all layers of a <b>pre-trained</b> <b>AlexNet.</b> Furthermore, we demonstrate empirically that structured receptive fields can indeed learn their own filter size during training, and that this extra ability over normal filters seems to give them an advantage over normal filters when used for classification tasks. I. e. by replacing normal filters in a DenseNet architecture and keeping every- thing else the same, a ~ 1 % higher test accuracy was obtained on the highly competitive CIFAR- 10 benchmark dataset. It would not be wise to draw hard conclusions from a single training run on a single dataset, but this result definitely looks promising. In future research, we hope to demonstrate that, because of their extra ability to learn their filter size, replacing normal filters with structured receptive fields will always lead to strictly better or equal performance. Research and Development trac...|$|E

