1|1048|Public
40|$|A {{technique}} for systematically generating representations of finite fields is presented. Relations {{which must be}} physically realized in order to implement a <b>parallel</b> <b>arithmetic</b> <b>unit</b> to add, multiply, and divide elements of finite fields of 2 n elements are obtained. Finally, techniques for using a maximal length linear recurring sequence to modulate a radar transmitter and the means of extracting range information from the returned sequence are derived. *Operated {{with support from the}} U. S. Army, Navy and Air Force...|$|E
40|$|A simple {{redundant}} {{binary number}} representation suitable for digital-optical computers is presented. By means of this representation {{it is possible}} to build an <b>arithmetic</b> with carry-free <b>parallel</b> algebraic sums carried out in constant time and parallel multiplication in log N time. This redundant number representation naturally fits the 2 's complement binary number system and permits the construction of inherently <b>parallel</b> <b>arithmetic</b> <b>units</b> that are used in various optical technologies. Some properties of this number representation and several examples of computation are presented...|$|R
40|$|Abstract. This paper {{addresses}} {{the problem of}} accelerating large artificial neural networks (ANN), whose topology and weights can evolve via {{the use of a}} genetic algorithm. The proposed digital hardware architecture is capable of processing any evolved network topology, whilst at the same time providing a good trade off between throughput, area and power consumption. The latter is vital for a longer battery life on mobile devices. The architecture uses multiple <b>parallel</b> <b>arithmetic</b> <b>units</b> in each processing element (PE). Memory partitioning and data caching are used to minimise the effects of PE pipeline stalling. A first order minimax polynomial approximation scheme, tuned via a genetic algorithm, is used for the activation function generator. Efficient arithmetic circuitry, which leverages modified Booth recoding, column compressors and carry save adders, is adopted throughout the design. ...|$|R
40|$|Abstract:- The paper {{describes}} {{the design of}} all optical parallel adder and all optical <b>arithmetic</b> <b>unit</b> by using {{of a set of}} optical full adders and hard-limiters. The <b>parallel</b> adder and <b>arithmetic</b> <b>unit</b> are demonstrated via simulations and experiments. The optical <b>Arithmetic</b> <b>unit</b> can be used to perform a fast central processor unit using optical hardware components...|$|R
50|$|The SAPO (short for Samočinný počítač, “automatic computer”) was {{the first}} Czechoslovak computer. It {{operated}} in the years 1957-1960 in Výzkumný ústav matematických strojů, part of the Czechoslovak Academy of Sciences. The computer {{was the first}} fault-tolerant computer - it had three <b>parallel</b> <b>arithmetic</b> logic <b>units,</b> which decided on the correct result by voting, an example of triple modular redundancy (if all three results were different, the operation was repeated).|$|R
40|$|AbstractEmbedded CPUs {{typically}} use {{much less}} power than desktop or server CPUs but provide limited or no support for floating-point arithmetic. Hybrid reconfigurable CPUs combine fixed and reconfigurable computing fabrics to balance better execution performance and power consumption. We show how a Stretch S 6 hybrid reconfigurable CPU (S 6) {{can be extended}} to natively support double precision floating-point arithmetic. For lower precision number formats, multiple <b>parallel</b> <b>arithmetic</b> <b>units</b> can be implemented. We evaluate if the superlinear performance improvement of floating-point multiplication on reconfigurable fabrics can be exploited {{in the framework of}} a hybrid reconfigurable CPU. We provide an in-depth investigation of data paths to and from the S 6 reconfigurable fabric and present peak and sustained throughput as a function of wide registers used and total operand size. We demonstrate the effect of the given interface when using a floating-point fused multiply-accumulate (FMA) SIMD unit to accelerate the LINPACK benchmark. We identify a mismatch between the size of the S 6 s reconfigurable fabric and the available interface bandwidth as the major bottleneck limiting performance which makes it a poor choice for scientific workloads relying on native support for floating-point arithmetic...|$|R
40|$|Abstract:- VHDL {{synthesis}} and FPL {{implementation of}} a RNS-enabled RISC DSP are presented in this paper. Four <b>parallel</b> modular <b>arithmetic</b> <b>units</b> optimized for multiply-and-accumulate are used in a parallel SIMD architecture. The moduli 256, 251, 241 and 239 are selected to optimize area and performance. Thus, pipelined Galois Field multipliers are used for prime moduli while conventional adders and multipliers are used for power of two modulus. A three-level pipelined control unit prefetches, decodes and executes instructions over parallel high performance modular arithmetic enhanced channels. Performance and area were analysed through synthesis and simulation over Altera FLEX 10 K FPL devices. A representative set of DSP applications shows a sustained increase in performance when compared with commercially available and commonly used VLSI DSP technology...|$|R
40|$|Elliptic curve {{cryptography}} (ECC) {{offers a}} viable alternative to Rivest-Shamir-Adleman (RSA) by delivering equivalent security with a smaller key size. This has several advantages, including smaller bandwidth demands, faster key exchange, and lower latency encryption and decryption. The fundamental operation for ECC is scalar point multiplication, wherein a point P on an elliptic curve defined over a finite field is multiplied by a scalar k. The complexity of this operation requires a hardware implementation to achieve high performance. The algorithms involved in scalar point multiplication are constantly evolving, incorporating the latest developments in number theory to improve computation time. These competing needs, high performance and flexibility, have caused previous implementations to either limit their adaptability or to incur performance losses. This thesis explores the use of a hybrid-FPGA for scalar point multiplication. A hybrid- FPGA contains a general purpose processor (GPP) in addition to reconfigurable fabric. This allows for a software/hardware co-design with low latency communication between the GPP and custom hardware. The elliptic curve operations and finite field inversion are programmed in C code. All other finite field arithmetic is implemented in the FPGA hardware, providing higher performance while retaining flexibility. The resulting implementation achieves speedups ranging from 24 times to 55 times faster than an optimized software implementation executing on a Pentium II workstation. The scalability of the design is investigated in two directions: faster finite field multiplication and increased instruction level parallelism exploitation. Increasing the number of <b>parallel</b> <b>arithmetic</b> <b>units</b> beyond two is shown to be less efficient than increasing the speed of the finite field multiplier...|$|R
40|$|This paper {{presents}} a novel (low <b>arithmetic</b> <b>unit</b> count) hardware architecture for performing lifting-based JPEG 2000 ’s 513 Discrete Wavelet Transform (DWT). The architecture {{is built around}} <b>parallel</b> Shift-Accumulator <b>Arithmetic</b> Logic <b>Units</b> (ALUs) which can encode (with implicit embedded extension[S]) up to five levels of transformation. The proposed architecture, which consists of three adders, two subtractor-adders and five shifters, has a significantly lower hardware count compared to the architectures proposed by K. Andra et. al. [5] and G I. Lian et. al. [6]. In addition, the architecture has an efficient memory organisation, which uses lesser amount of embedded memory for processing and buffering. In this paper, we present the architecture and demonstrate that it closely adheres to the JPEG 2000 ’s specification while reducing the hardware requirements and hence area and power consumption. 1...|$|R
40|$|International audiencePublic key {{cryptography}} {{is required}} in many applications such as key exchange, digital signature and some specific encryption schemes. Elliptic curve cryptography (ECC) has become the standard public-key crypto-system in many countries, where it has superseeded RSA thanks to its lower cost and much better performance. For instance, ECC uses a mere 224 -bit key to replace a 2048 -bit RSA key, for the same theoretical level of security. Recent research has pointed out hyper-elliptic curve cryptography (HECC) as a possible way to further improve public-key crypto-systems. HECC can provide the same theoretical level of security as ECC, with keys and finite eld elements that are only half the size, albeit curve operations require more computation steps. In order to provide a fair comparison of ECC and HECC, one needs to implement, optimize and analyze them within the same experimental setup. Our research group has been studying and implementing arithmetic operators, hardware accelerators and counter-measures for ECC for a long time, and has more recently taken an interest in HECC. Our goal for the near future is to evaluate the possible trade-offs between computation time, implementation costs (silicon area and energy consumption) and resilience to physical attacks (side-channel analysis in particular) for HECC. In this work, we present a customizable crypto-processor dedicated to ECC or HECC. The processor has been fully implemented and validated on FPGA. We are also developing dedicated programming tools (assembler, small compiler and a library of ECC/HECC cryptographific primitives). We present implementation results (on Xilinx Spartan 6 LX 75) and comparisons for various configurations of the crypto-processor. Using {{an exploration of the}} number of <b>parallel</b> <b>arithmetic</b> <b>units</b> and of their inner sizes/performances, we are able to propose a large number of speed-area trade-offs so as to best answer the specic constraints of each application. Our experimental results tend to conrm that HECC is more ecient than ECC for the same theoretical security level, with an approximate 40 % speed improvement for equivalent silicon areas. We plan to distribute some congurations of our (H) ECC crypto-processor and the programming tools in open source in the future...|$|R
40|$|Living creatures pose amazing {{ability to}} learn and adapt, {{therefore}} researchers are trying to apply this ability to machines. There are many mathematical models that mimic the behaviour of the central neural system, especially the brain, with neural networks being one of them. One {{of the most widely}} used neural networks is a multilayer perceptron, which gained its popularity with discovery of the back propagation learning algorithm. A high degree of parallelism is inherently present in all types of neural networks. Since computers are not inherently parallel, the question arises, whether the existing architectures are appropriate for the implementation of such structures. Therefore, in the presented work we are trying to develop a chip with a new architecture, capable of vastly exploiting a parallelism present in the multilayered perceptron. Programmable devices based on the FPGA technology enable us to quickly and efficiently develop and test new architectures. The behaviour of these devices can be specified in design-entry languages like the VHDL. In the developing cycle we have heavily relied on the Matlab simulations that enabled us to quickly solve restrictions and limitations posed by the FPGA technology. Following the successful completion of these simulations, a decision was made to create a powerful <b>arithmetic</b> logic <b>unit,</b> which is able to process a neuron in only one clock cycle. Perhaps in the future, when the density of the gates in the FPGA devices becomes higher, a number of <b>parallel</b> <b>arithmetic</b> logic <b>units</b> might be applied. The practical application in the field of character recognition confirms the suitability of the proposed architecture for the target FPGA devices. There are many possibilities for future work, especially in the area of optimization and expansion of the presented architecture. ...|$|R
40|$|In {{order to}} enjoy {{performance}} improvement effects of variable computation time <b>arithmetic</b> <b>units</b> {{in a system}} level, we propose a new synchronous control unit design methodology for dataflow graphs under allocation of a telescopic <b>arithmetic</b> <b>unit</b> {{which is one of}} well-known synchronous variable computation time <b>arithmetic</b> <b>units.</b> The proposed method generates an independent synchronous controller for each component <b>arithmetic</b> <b>unit,</b> and builds a distributed synchronous control unit through integrating derived controllers. The distributed structure of a final synchronous control unit maximizes performance improvement effect of telescopic <b>arithmetic</b> <b>units</b> through a complete preservation of original concurrency among operations...|$|R
40|$|This paper {{presents}} {{the design of}} an early condition resolution circuit. The proposed circuit works in <b>parallel</b> with the <b>arithmetic</b> <b>unit,</b> and calculates the Equal to (EQ), Greater-than (GT), Less-than (LT), Overflow (OV), Underflow (UF), and Carry-out (Cout), conditions. The proposed logic is reconfigurable, and can calculate all the conditions (mentioned above) for one 64 -bit, two 32 -bit, four 16 -bit, or eight 8 -bit signed and unsigned operands. The reconfigurability of the logic is achieved using only four control signals. Two of the control signals (Part 0, Part 1) are used to partition the logic into 64, 32, 16, or 8 bit independent condition resolvers and the Sign control signal is used to control the signed/unsigned operation. The Add-Sub control signal specifies and controls the Add/Subtract operation for the condition resolution. In order to achieve high speed with reconfigurability and minimum area, new techniques are developed for calculating the conditions before the results are available. The proposed logic is designed for VLIW or Media processors, which require {{a high degree of}} reconfigurability, and high speed operation. It can also be used in MIPS family of processors for early branch condition resolution, to avoid branch stalls. Simulations of realizations in a standard digital CMOS fabrication technology show a 30 % improvement in speed and a 25 % savings in area using the approaches presented here. 1...|$|R
2500|$|Efficient vector <b>parallel</b> <b>arithmetic</b> {{operations}} on integer, fixed-point and floating-point data ...|$|R
40|$|Abstract — Nowadays, {{variable}} delay <b>arithmetic</b> <b>units</b> {{have been used}} for implementing a datapath of a target system in pursuit of performance improvement. However, adoption of {{variable delay}} <b>arithmetic</b> <b>units</b> requires modification of a typical synchronous control unit design methodology. A telescopic <b>arithmetic</b> <b>unit</b> based methodology is one of representative methodologies to design synchronous control units for variable delay datapaths. In this paper, we propose two optimization methods for it. Proposed optimization techniques will be analyzed in order to show their performance improvement effects explicitly. I...|$|R
25|$|Construction (<b>arithmetic</b> <b>unit</b> only): transistor-diode {{logic is}} used.|$|R
50|$|The CPUs {{included}} two independent <b>arithmetic</b> <b>units</b> with different capabilities.|$|R
5000|$|<b>Arithmetic</b> <b>unit</b> {{can make}} division, multiplication, shift and {{normalize}} operations ...|$|R
5000|$|... 1982 Mike Farmwald, On the Design of High Performance Digital <b>Arithmetic</b> <b>Units</b> ...|$|R
40|$|CMOS scaling {{has been}} {{the driving force behind}} the {{revolution}} of digital signal processing (DSP) systems, but scaling is slowing down and the CMOS device is approaching its fundamental scaling limit. At the same time, DSP algorithms are continuing to evolve, so there is a growing gap between the increasing complexities of the algorithms and what is practically implementable. The gap can be bridged by exploring the synergy between algorithm and hardware design, using the so-called co-design techniques. In this thesis, algorithm and architecture co-design techniques are applied to X-ray computed tomography (CT) image reconstruction. Analysis of fixed-point quantization and CT geometry identifies an optimal word length and a mismatch between the object and projection grids. A water-filling buffer is designed to resolve the grid mismatch, and is combined with <b>parallel</b> fixed-point <b>arithmetic</b> <b>units</b> to improve the throughput. The analysis eventually leads to an out-of-order scheduling architecture that reduces the off-chip memory access by three orders of magnitude. The co-design techniques are further applied to the design of neural networks for sparse coding. Analysis of the neuron spiking dynamics leads to the optimal tuning of network size, spiking rate, and update step size to keep the spiking sparse. The resulting sparsity enables a bus-ring architecture to achieve both high throughput and scalability. A 65 nm CMOS chip implementing the architecture demonstrates feature extraction at a throughput of 1. 24 G pixel/s at 1. 0 V and 310 MHz. The error tolerance of sparse coding can be exploited to enhance the energy efficiency. As a natural next step after the sparse coding chip, a neural-inspired inference module (IM) is designed for object recognition. The object recognition chip consists of an IM based on sparse coding and an event-driven classifier. A learning co-processor is integrated on chip to enable on-chip learning. The throughput and energy efficiency are further improved using architectural techniques including sub-dividing the IM and classifier into modules and optimal pipelining. The result is a 65 nm CMOS chip that performs sparse coding at 10. 16 G pixel/s at 1. 0 V and 635 MHz. The co-design techniques can be applied to the design of other advanced DSP algorithms for emerging applications...|$|R
40|$|Processor {{architectures}} with tens {{to hundreds}} of <b>arithmetic</b> <b>units</b> are emerging to handle media processing applications. These applications, such as image coding, image synthesis, and image understanding, require arithmetic rates of up to 10 11 operations per second. As the number of <b>arithmetic</b> <b>units</b> in a processor increases to meet these demands, register storage and communication between the <b>arithmetic</b> <b>units</b> dominate the area, delay, {{and power of the}} <b>arithmetic</b> <b>units.</b> In this paper we show that partitioning the register file along three axes reduces the cost of register storage and communication without significantly impacting performance. We develop a taxonomy of register architectures by partitioning across the data-parallel, instruction-level parallel, and memory hierarchy axes, and by optimizing the hierarchical register organization to operate on streams of data. Compared to a centralized global register file, the most compact of these organizations reduces the register file ar [...] ...|$|R
5000|$|Construction (<b>Arithmetic</b> <b>unit</b> only) Type Quantity Diodes 37,543 All types Transistors 13,819 All types ...|$|R
5000|$|Multiple <b>arithmetic</b> <b>units</b> {{may require}} memory {{architectures}} to support several accesses per instruction cycle ...|$|R
5000|$|Vladislav Paunović: <b>Arithmetic</b> <b>unit</b> of the CER-12 computer, AUTOMATIKA, No 3, pp. 161-165, Zagreb 1971.|$|R
50|$|The high {{performance}} of the Model 75 was attributed to half a dozen advanced features, including <b>Parallel</b> <b>arithmetic,</b> Overlapped memory fetch and Parallel addition for address calculation.|$|R
40|$|Arithmetic {{data value}} {{speculation}} (ADVS) is {{a scheme to}} increase the throughput of a processor pipeline similar to conventional branch prediction. An approximate <b>arithmetic</b> <b>unit,</b> with an associated probability of correctness, provides an approximate result earlier than an exact unit, allowing the speculative issue of dependent operations. This paper investigates the performance gain in terms of retired instructions per clock (IPC) by employing ADVS in a RISC processor. Simulated results show the effect of probability of correctness and latency of approximate <b>arithmetic</b> <b>units</b> on IPC. In particular, minimum requirements for approximate <b>arithmetic</b> <b>units</b> are characterized, and maximum increase in IPC is shown for typical benchmark applications. Daniel R. Kelly, Braden J. Phillips and Said Al-Saraw...|$|R
5000|$|<b>Arithmetic</b> <b>Unit</b> and Storage was in {{a cabinet}} that was 10 ft high and 11 ft long.|$|R
50|$|A similar idea, {{introduced}} only a {{few years}} later, was to execute multiple instructions in <b>parallel</b> on separate <b>arithmetic</b> logic <b>units</b> (ALUs). Instead of operating on only one instruction at a time, the CPU will look for several similar instructions that do not depend on each other, and execute them in parallel. This approach is called superscalar processor design.|$|R
30|$|In particular, we {{are looking}} at <b>arithmetic</b> <b>units</b> (Steffe, 2010 a; Ulrich, 2015), which are interiorized {{counting}} acts.|$|R
40|$|Abstract: The study {{implemented}} an FPGA-based face detector using Neural Networks and a scalable Floating Point <b>arithmetic</b> <b>Unit</b> (FPU). The FPU provides {{dynamic range}} {{and reduces the}} bit of the <b>arithmetic</b> <b>unit</b> more than fixed point method does. These features led to reduction in the memory {{so that it is}} efficient for neural networks system with large size data bits. The <b>arithmetic</b> <b>unit</b> occupies 39 ~ 45 % of the total neural networks system area. Therefore bits reduction is needed not only for memory but also for a FPU and system size. Reduction from FPU 32 bits (IEEE 754 single precision) to 16 bits reduced the size of memory and <b>arithmetic</b> <b>units</b> by 50 %, having only 1. 25 % deterioration in the detection rate. In order to determine the least and acceptable bits of the FPU, we examined how representation errors affect a detection rate through the MRRE. The scalable FPU and the error analysis may be useful to determine the details, especially area and speed of FPU for the embedded neural network system...|$|R
40|$|This paper aims at Implementation of Fixed Point <b>Arithmetic</b> <b>Unit.</b> The {{real number}} is {{represented}} in Qn. m format where n {{is the number of}} bits {{to the left of the}} binary point and m is the number of bits to the right of the binary point. The Fixed Point <b>Arithmetic</b> <b>Unit</b> was designed using Verilog HDL. The Fixed Point <b>Arithmetic</b> <b>Unit</b> incorporates adder, multiplier and subtractor. We carried out the simulations in ModelSim and Cadence IUS, used Cadence RTL Compiler for synthesis and used Cadence SoC Encounter for physical design and targeted 180 nm Technology for ASIC implementation. From the synthesis result it is found that our design consumes 1. 524 mW of power and requires area 20823. 26 μm 2...|$|R
50|$|The {{instruction}} queue {{is filled}} with the instructions fetched from the memory. The address <b>arithmetic</b> <b>unit</b> serves for address calculations.|$|R
40|$|A floating-point <b>arithmetic</b> <b>unit</b> is {{described}} {{which is being}} used in the Ground Facility of Large Space Structures Control Verification (GF/LSSCV). The experiment uses two complete inertial measurement units and a set of three gimbal torquers in a closed loop to control the structural vibrations in a flexible test article (beam). A 6502 (8 -bit) microprocessor controls four AMD 9511 A floating-point <b>arithmetic</b> <b>units</b> to do all the computation in 20 milliseconds...|$|R
40|$|The initial {{control and}} {{programming}} philosophies of the RELAPSE are discussed. A block diagram showing {{the relationship of}} the <b>Arithmetic</b> <b>Units</b> (composed of Stages and Bit Processors), to the Functional Units, and other components of the RELAPSE is used to guide this discussion. The latest version of the Bit Processor design is presented. Included is a detailed discussion of the Bit Processor's new scratch pad memory component. The section also clarifies the usage of the Bit Processor's processing registers, and Input/Output functions. The final design phase of the <b>Arithmetic</b> <b>Unit</b> is underway by a study of the Proposed IEEE Floating Point Standard. The decisions on conformation to this standard will be used as inputs into the finalization of the designs of the Bit Processor, Stage, and <b>Arithmetic</b> <b>Units</b> of the RELAPSE...|$|R
5000|$|<b>Arithmetic</b> <b>unit</b> I {{had three}} 16-bit {{registers}} called A, B, and C, and a 16-bit D register which {{functioned as a}} buffer.|$|R
40|$|The {{floating}} point <b>arithmetic</b> <b>units</b> are complex in their algorithms and many scientific problems require {{floating point}} units with high accuracy. Hence for increased performance and fault tolerance operations the double precision floating point <b>arithmetic</b> <b>units</b> adder, subtractor, multiplier and divider is designed which {{is enough for}} most System on Chip (SoC) applications and it also improves the accuracy during long chain of computations. The synthesized code results are verified and the complete layout is generated using backend flow...|$|R
