11|5|Public
5|$|User {{authentication}} mode: This mode {{requires that}} the user provide some authentication to the <b>pre-boot</b> <b>environment</b> {{in the form of}} a pre-boot PIN or password.|$|E
500|$|The [...] "Transparent {{operation}} mode" [...] and [...] "User authentication mode" [...] of BitLocker use TPM {{hardware to}} detect {{if there are}} unauthorized changes to the <b>pre-boot</b> <b>environment,</b> including the BIOS and MBR. If any unauthorized changes are detected, BitLocker requests a recovery key on a USB device. This cryptographic secret is used to decrypt the Volume Master Key (VMK) and allow the bootup process to continue.|$|E
5000|$|User {{authentication}} mode: This mode {{requires that}} the user provide some authentication to the <b>pre-boot</b> <b>environment</b> {{in the form of}} a pre-boot PIN or password.|$|E
50|$|With a <b>Pre-Boot</b> Authentication <b>environment,</b> the key used {{to encrypt}} {{the data is}} not decrypted until an {{external}} key is input into the system.|$|R
50|$|HDD FDE {{is made by}} HDD vendors {{using the}} OPAL and Enterprise {{standards}} developed by the Trusted Computing Group. Key management takes place within the hard disk controller and encryption keys are 128 or 256 bit Advanced Encryption Standard (AES) keys. Authentication on power up of the drive must still take place within the CPU via either a software <b>pre-boot</b> authentication <b>environment</b> (i.e., with a software-based full disk encryption component - hybrid full disk encryption) or with a BIOS password.|$|R
50|$|Remote Installation Services (RIS) are a {{means to}} {{automatically}} install Windows 2000 Professional (and not Windows 2000 Server) to a local computer over a network from a central server. Images {{do not have to}} support specific hardware configurations and the security settings can be configured after the computer reboots as the service generates a new unique security ID (SID) for the machine. This is required so that local accounts are given the right identifier and do not clash with other Windows 2000 Professional computers on a network.RIS requires that client computers are able to boot over the network via either a network interface card that has a <b>Pre-Boot</b> Execution <b>Environment</b> (PXE) boot ROM installed or that the client computer has a network card installed that is supported by the remote boot disk generator. The remote computer must also meet the Net PC specification. The server that RIS runs on must be Windows 2000 Server and it must be able to access a network DNS Service, a DHCP service and the Active Directory services.|$|R
5000|$|... rEFInd is a boot {{menu and}} {{maintenance}} toolkit for UEFI-based machines like all new PCs and Intel Macs. It {{can be used}} to boot multiple operating systems. It also provides a way to enter and explore the EFI <b>pre-boot</b> <b>environment.</b>|$|E
50|$|By default, {{when the}} {{operating}} system is running in real mode (or in a <b>pre-boot</b> <b>environment,</b> when no operating system is started yet), this keystroke combination is intercepted by the BIOS. The BIOS reacts by performing a soft reboot (also known as a warm reboot).Examples of such operating systems include DOS, Windows 3.0 in Standard Mode as well as earlier versions of Windows.|$|E
5000|$|... rEFIt is a boot {{menu and}} {{maintenance}} toolkit for EFI-based machines like the Intel Macs. It {{can be used}} to boot multiple operating systems, including triple-boot setups with Boot Camp. It also provides a way to enter and explore the EFI <b>pre-boot</b> <b>environment.</b> The name [...] "rEFIt" [...] is likely a play on the terms [...] "refit" [...] and [...] "EFI." ...|$|E
40|$|This is {{a vendor}} {{presentation}} We see a complementary relationship between DMTF’s WBEM/CIM initiative and embedded hardware manageability standards like IPMI, ASF, PXE and SMBIOS. There {{is no guarantee}} that this presentation represents the perspectives of all DMTF members or even any vendor other than the one making this presentation. That said, we hope to provide you with valuable insight about the potential synergy between WBEM/CIM and some industry standard, hardware level, embedded manageability technologies. Copyright © 2003 Global Management ConferenceJune 16 - 19 San Jose, California WBEM/CIM is powerfully complemented by hardware-level, embedded manageability technologies. The Intelligent Platform Management Interface (IPMI v 1. 5), the DMTF's Alert Standard Format (ASF v 2. 0), the <b>Pre-Boot</b> Execution <b>Environment</b> (PXE) and the SAF-HPI are all helpful. These hardware-level management standards map nicely into recent CIM schemas. As they do, they close WBEM's pre-OS, hung-OS and missing-OS manageability coverage gaps. Getting to this level of "total manageability " requires IPMI/ASF/PXE manageability (firmware), bundled OS device drivers, corresponding (SAF-HPI) system libraries and layered CIM providers. This “stack ” of building blocks delivers the “last mile” manageability required for “lights out ” servers, headless systems, blades, grids, clusters, farms and more. Real-world success of a “total manageability ” stack is assured by the compelling economics of extensible, common-off-the-shelf building (xCOTS) blocks...|$|R
40|$|The aim of {{this project}} was {{airports}} network design and implementation {{and the introduction of}} a suitable network for most airports around the world. The following project focused on three main parts: security, quality, and safety. The project has been provided with different utilities to introduce a network with a high security level for the airport. These utilities are hardware firewalls, an IP access control list, Mac address port security, a domain server and s proxy server. All of these utilities have been configured to provide a secure environment for the entire network and to prevent hackers from entering sensitive departments like the flight management and service providers departments. Improving the performance of any network requires a high quality of techniques and services which help to improve the general task of the network. The technical services that have been placed in the airport’s network are failover firewalls utility, a <b>Pre-boot</b> Execution <b>Environment</b> (PXE) server, a Dynamic Host Configuration Protocol (DHCP) server, a Domain Name System (DNS) server and a cabling system. These tools can increase the performance of the network in general and provide a stable internet service for the Air Traffic Control System by using dual internet service providers and the failover utility. The dual internet service providers’ role was to provide the flight management department, which helps to confirm the backup operation for the Air Traffic Control Complex (BATCX) system to outside the local network. This is achieved by using Windows servers backup (iSCSI initiators and iSCSI target) servers which helps to keep the Air Traffic Control systems’ information in a safe place. Also, for passengers’ personal information safety, the web server has been placed in the local network, which provides a secure environment for any network’s element...|$|R
5000|$|The [...] "Transparent {{operation}} mode" [...] and [...] "User authentication mode" [...] of BitLocker use TPM {{hardware to}} detect {{if there are}} unauthorized changes to the <b>pre-boot</b> <b>environment,</b> including the BIOS and MBR. If any unauthorized changes are detected, BitLocker requests a recovery key on a USB device. This cryptographic secret is used to decrypt the Volume Master Key (VMK) and allow the bootup process to continue.|$|E
5000|$|Control-Alt-Delete (often {{abbreviated}} to Ctrl+Alt+Del, {{also known as}} the [...] "three-finger salute") is a computer keyboard command on IBM PC compatible computers, invoked by pressing the Delete key while holding the Control and Alt keys: [...] The function of the key combination differs depending on the context but it generally interrupts or facilitates interrupting a function. For instance, in <b>pre-boot</b> <b>environment</b> (before an operating system starts) or in DOS, Windows 3.0 and earlier versions of Windows or OS/2, the key combination reboots the computer. Starting with Windows 95, the command invokes a task manager or security related component that facilitates ending a Windows session.|$|E
40|$|UEFI (Unified Extensible Firmware Interface) is a {{specification}} detailing an interface {{that helps}} hand off {{control of the}} system for the <b>pre-boot</b> <b>environment</b> (i. e. : after the system is powered on, but before the operating system starts) to an operating system, such as Windows * or Linux*. UEFI will provide a clean interface between operating systems and platform firmware at boot time, and will support an architecture-independent mechanism for initializing add-in cards. The Unified EFI Forum manages and evolves this specification. The Unified EFI Forum has also been working on establishing a configuration infrastructure standard for UEFI-compliant platforms. The aim of this document is to define the liaison relationship between the DMTF and the Unified EF...|$|E
40|$|Generic Ericsson Processor {{boards are}} general purpose {{hardware}} platforms which provide generic processing services. They support the Unified Extensible Firmware Interface Specification. They have several network interfaces available {{and they are}} connected to Ericsson’s laboratory network. Several servers are also connected to this network. These boards require periodic firmware upgrades. They also require acquiring new firmware components and data files. Currently, an application to download or upload files from and to Ericsson’s laboratory servers when an Operating System has not already been booted does not exist. Therefore, the files have {{to be transferred to}} USB drives which are connected later to the boards in order to transfer the files. This is a time consuming operation which decreases Ericsson’s productivity. In addition, although Generic Ericsson Processor boards have an optional solid-state drive as secondary storage, Ericsson {{wants to be able to}} operate without it. This is because this secondary storage is not always available and Ericsson does not want to use it when the Generic Ericsson Processor boards are operating before an Operating System has been loaded. They prefer to use Random Access Memory storage. This project is focused on studying possible solutions for those two problems. Several file transfer protocols are analyzed. Several file system solutions mounted on Random Access Memory are also explored. A Trivial File Transfer Protocol client application and a Random Access Memory Disk driver prototype are designed, implemented and tested. They are tailored to work on a <b>pre-boot</b> <b>environment,</b> when the boards have not booted an Operating System yet, in Ericsson’s laboratory network. Finally, a secure file transfer protocols’ study is developed. This study will be used to assess Ericsson on the optimal secure file transfer protocol choice in order to implement possible secure future versions of the system...|$|E
40|$|Monday, October 8, 2007 Opening Plenary The opening speaker for {{the conference}} was very good. His speech was called “The Future is So Bright, We Have to Wear Shades. ” He talked about {{emerging}} technologies in the education industry, and different technologies {{that we should be}} watching for in the near future. He talked about the younger generation and how they see information technologies differently than most IT workers. Overall, he was a very passionate speaker and presented lots of great ideas and trends. Session 5 a – Decentralized and Centralized IT Support at Tulane University – A Case Study From a Hybrid Model This was a very good session. The whole focus of their presentation was on a project for deploying Microsoft Exchange on their campus. Their project was unique {{in the sense that they}} have two different levels of IT at their school: Decentralized IT and Centralized IT. Decentralized IT is the department that deals with the user level support. (Helpdesk, PC Support, etc.) Centralized IT is the department that deals with the global IT projects over many Decentralized units. This presentation really hit home, because I have worked in this sort of setup in my previous employment at the Federal Government. I worked in regional IT, which is the same as decentralized IT. We actually worked on an Exchange deployment collaboratively with Corporate IT as well, so many of the things they spoke about I could relate to. It was great to see the differences and similarities with their project as we had with ours. I learned some things that I could have done differently in our situation. It would have been nice to see this presentation prior to our project. Session 5 b – TAG – You’re It! Again, this was a great session. The speaker talked in detail about how in their organization, they had a bunch of computing services “Silos”, or independent units basically all doing their own thing with a lack of communication and collaboration. She was frustrated with this situation, and developed something called a TAG team. TAG stands for Technical Action Group. Basically, people from various IT units assemble once a month or more and discuss problems, solutions, projects, etc. They have the means of discussing topics that may affect other units and getting both positive and negative feedback. It sounds like their situation is much like the one we are currently experiencing in Computing Services at AU. There are many units in CS that essentially see the other units as impeding progress. I think that assembling a sort of TAG team here at AU would be mutually beneficial to all parties involved. Session 10 a – American ITIL The presentation on ITIL was a fairly high level overview of the Information Technology Infrastructure Library. ITIL is basically a set of best practices in IT service management. One of the presenters was actually the CIO at Hobart and William Smith Colleges, so he explained how the whole approach to IT has changed since he has been there. It was really nice to see a CIO doing a presentation, and he also had one of his employees with him to show the collaboration between everyone at their school. I did see some of the advantages of implementing an ITIL structure in an IT organization, but I felt that this approach is not best for all situations. The presentation also felt a little like a sales pitch, which made me a little uncomfortable. Overall, it was a generally informative presentation. Session 10 b – The Magical World of An Information Commons This session was a little strange. I didn’t really see how it fit in with the rest of the sessions. It was about how the Oberlin College renovated their library. It was an interesting space that they developed, but I didn’t really find it relevant to IT in any way. Session 11 a – Vista Preparedness at Indiana University This was a session that Travis and myself were really looking forward to. There is a need to get prepared for Vista here at Athabasca University, and we are currently in a testing phase. We thought that they would have shared a little about how they decided to go to Vista, but it was lacking in content or upgrade justification. The only problem they talked about was that some of their hardware could not run Vista, so they had to negotiate with Dell for good pricing on new computers. They did not talk about the testing process much, or why they were forced to go to Vista. They didn’t really identify any software issues, which is the main concern here at AU and it would have been nice to see how other people dealt with it. The presentation didn’t really provide us with any additional information that we didn’t know already. Session 11 b – Windows Vista: Implementation Challenges This session, as well as the previous Vista session was packed. It was interesting that there is this many people having trouble and fears with rolling out Vista to their clients. This presentation was very informative, because their situation was very similar to ours. They talked about different roadblocks that are being encountered in their testing and deployment. They also talked about their mandate to deploy full disk encryption which Vista addressed to a certain extent. I got a great deal of very relevant information from this presentation, and their paper that went with the presentation is full of detailed information that we can definitely use in the future. Tuesday, October 9, 2007 Session 18 a – Open Source – A Practical Solution This session was interesting in the fact that they implemented an open source solution for their call tracking software. Even though they were a small group of IT workers, the implementation of a call tracking system seemed like it worked perfectly for them. Even though an open source “free” solution might not work for larger IT organizations such as Athabasca University, it was interesting to see how much could be accomplished using a free program. They have many of the same features (and some nice new ones) that HEAT has with no cost. Session 18 b – Ursula or Ariel? Is Your Help Desk Application Evil or Good in the Eyes of Your Support Staff? This session had to do with transitioning to a new Call Tracking System. The call tracking system that they used was HEAT, and they were unhappy with it. This may have been because they didn’t have a nicely customized one like the one in AU, or that it didn’t fit their business process properly. One of the important things that I got out of the presentation was to document your current process thoroughly. Another was to examine your process and see if you are doing things that way because of a limitation of the old program. The new program may have a more streamlined way of doing things. I found this session particularly useful because there was a lengthy question period where many people asked about the different products they evaluated. Session 18 c – Overhaul Your Helpdesk Ticketing System This was another session about replacing a call tracking software package. This one was a little different though, because the software that they chose was completely web-based and customers could submit their own tickets and classify them accordingly. I was a little skeptical about people submitting their own tickets and classifying themselves, but from what they say it works pretty well. The one thing that I found amazing is that they have had pretty much full acceptance from the entire organization, not just the IT staff. This is because it is web-based, has an easy to use interface, and has little to no learning curve associated with it. I know that we cannot say that about our call tracking software here at AU because HEAT is a fairly cumbersome program to learn. Hopefully when the web-based HEAT product is released, we can see this sort of impact. Session 24 a – Who’s Really in Your Top 8 : Network Security in the Age of Social Networking I found this session very interesting and very informative. The session was based on social engineering, and the evolution of internet communications. They did a number of surveys to gauge the students knowledge about social engineering scams and privacy settings on popular social networking websites. I found it very interesting to see how many people actually are aware of these threats. This shows the great digital divide, and how the younger generations are raised with a sense of paranoia, even on the internet. It was actually the younger people that were more proactive about security. Overall, it was a presentation that was very informative and gives me a different outlook on personal security as a whole. Session 24 b – Virtualization’s Next Frontier: Security This presentation was about them using virtual machines as test computers. They would create a virtual machine and test its security by hammering it with different attacks, etc. We have always discussed doing testing in a virtual environment, but have never really seen it done in practice. It is nice to see that they are having good results doing it this way, and I am sure that this is the approach we will take in the future when it comes to testing. Session 25 a – Is Your Support Services Train Derailing? How One Integrated Software Package Got Us Back on Track This session dealt with a software product that they deployed called LANDesk. LANDesk is basically a complete Helpdesk/PC Support solution for internal clients. It allows inventory management, software deployment, and remote desktop capabilities. In their case, it worked quite well because they had not previously had anything in place. They were mostly impressed with the remote desktop capabilities. In our case here at AU, this would not work. Our remote desktop software is capable of going through home router firewalls, as well as our firewalls. This is a big thing for us because of our distributed workforce. It would be nice to have a fully integrated solution such as the one that they implemented, but it is not practical in our situation. Session 25 b – Desktop Imaging to Achieve Standardization and Application Delivery This was probably my favorite session out of the whole conference. They used a product called ZENworks to do their imaging. The approach to imaging was very different from most. You start with a base “package”, which would be windows xp fully patched. You then add on “application packages”. This would save many problems with setup time, as you would just choose the packages that you wish to install, and it would automate the process. There would be little setup time after the fact. I would really like to explore using this process in the future. I would need a great deal of project time to do so, but it may be worth it. Session 25 c – Image Baby, Image! Making PC Cloning More Efficient This was another session that was interesting. They had a fully automated imaging procedure using Windows PE (<b>Pre-boot</b> <b>environment).</b> They used this primarily on lab machines. They would reimage the computers periodically, and would do this remotely. It is automated, and all they have to do is check the computers after the fact to see if it was successful. I think that our procedure of putting deepfreeze on our lab computers is more efficient although, and better for our purposes. Poster Sessions There were a couple poster sessions that I found of interest. One of them was called “Implementing Preinstallation Environment Media for Use in User Support”. I found it neat that they had a fully functional bootable windows os with all the support tools that they needed. This is the same concept as Session 25 c but not network bootable. This would be easy to make network bootable, and is worth looking at in some aspects. At least for testing. Another interesting on was called “Inspiring Collaboration through the Use of Videoconferencing Technology”. It was relevant just because of what is going on here at AU. They had mostly positive things to say, but when I asked them about technical problems they gave the look of “OH YEAH!” and said that it was hard to categorize any specific problems because it was always something else. Hopefully things go more smoothly here at AU. Wednesday, October 10, 2007 Session 32 a – Encryption Technologies: Testing and Identifying Campus Needs This was a very worthwhile session where they explained different encryption technologies and techniques. They had some great data from their testing of the different products, and this is going to help us a lot as we move forward with the decision on an encryption technique for AU. Travis received their testing data after the conference, and this is going to be great reference material for us to us in the near future. They even included pricing information, which is going to give us a good idea of how much everything costs. Session 32 b – IS 3 PACE – Casting the Information Security Spell for Cultural Change It was interesting what they did in this project. It was about promoting security and being aware of threats, etc. Although it was a fun presentation to attend, it didn’t really give me any information that I did not know already. Maybe just some techniques that could be used to promote security, which isn’t the PC unit’s primary concerns. Session 32 c – Desktop Security in an Academic Environment: How to Herd Cats Successfully This was a great session where they spoke about the security advantages of having an actively managed security system. They actively manage their workstations’ antivirus, antispyware, antimalware, windows updates, and firewalls. This is an ideal system for a closed computing environment. By closed, I mean that they are all on an internal network. I wish that we could do this here at AU, and we are definitely working in this direction. I am hoping that we can get McAfee working outside of AU. Once that happens, we will have a great managed system in place. We already have Altiris working outside on the internet, so we are moving in the right direction. Overall Conference Impression Even though this was my first year ever attending this conference, I felt that it was a great learning experience. It gave me insight on what other universities are doing in their Computing Services departments. It provided me with different ways of thinking and doing things. Most importantly though, it allowed some of the members of the PC unit and helpdesk to have some time not at AU to collaborate and think of great ideas that could be implemented once we return. I really enjoyed it and I hope to attend it every year or every couple years if possible. The conference presents an opportunity for professionals involved in the support of Information Technology (IT) at institutions of higher education to network peers, learn and share ideas about supporting clients and delivering services, and discuss the future of IT support on campus. Academic & Professional Development Fund (A&PDF...|$|E

