0|14|Public
40|$|El Maestro Hugo Zemelman se nos ha adelantado en este caminar por la vida y la existencia, ha cerrado sus ojos para abrirlos permanentemente en las enseñanzas que deja en sus escritos, historias y recuerdos en cada uno de nosotros. El maestro nos dejó muchos retos en su fugaz pero {{invaluable}} contacto con nuestro equipo de trabajo en Medellín, intercambios fraternos que afortunadamente logramos tener en este andar por la vida. Enseñanzas tan profundas que requieren tiempo y sobre todo mucha sensibilidad <b>para</b> <b>procesar</b> y asimilar, enseñanzas que buscaban movilizar el sentir-pensar. Abstract: Master Hugo Zemelman {{has gone}} ahead in this walk through life and existence. He has {{closed his eyes}} in order to open them permanently in the teachings derived from his writings, stories, and memories in each of us. The master left us many challenges in his brief but invaluable contact with our team in Medellin, fraternal exchanges that fortunately we managed to have in this walk through life. So profound teachings that require time and above all great sensitivity to process and assimilate, teachings that sought to mobilize the feeling - thinking. His teachings which were so deep require time and much sensitivity in order to process and to assimilate them which aimed at mobilizing both feeling and thinking...|$|R
40|$|Geopolymerization is {{a viable}} way to process and re-use alumino-silicate {{industrial}} waste while producing highstrength, high chemical inertia materials that can effectively immobilize other industrial by-products, and even hazardous waste. In this study industrial waste from different stages of the manufacture of lightweight expanded clay aggregate was characterized for its possible transformation, via alkali activation, to geopolymers. The ultimate aim {{was to assess the}} possibility of using such geopolymers to develop thermal and acoustic insulation panels. The containment of hazardous materials is another important application for these new materials. Geopolymers were prepared for this study with different particles size distributions and activator concentrations. Their mechanical properties, composition and microstructure were characterized and a material with promising insulating properties was produced. A preliminary analysis was conducted of the salt formation observed in these geopolymers, the chief drawback to their use. La geopolimerizaci&# 243;n es una manera viable <b>para</b> <b>procesar</b> y agregar valor a los residuos industriales de alumino-silicato dando lugar a materiales con elevadas resistencias mec&# 225;nmicas, alta inercia qu&# 237;mica y que permiten encapsular otros residuos, incluso peligrosos. Los residuos industriales que proceden de diversos tipos de arcillas para la fabricaci&# 243;n de &# 225;ridos ligeros se han caracterizado para la producci&# 243;n de geopol&# 237;meros mediante el proceso de ataque alcalino. Su incorporaci&# 243;n en una matriz geopolim&# 233;rica permite la posibilidad de desarrollo de paneles de aislamiento (t&# 233;rmico y ac&# 250;stico). Adem&# 225;s, la inmovilizaci&# 243;n de materiales peligrosos es un logro adicional importante. Los geopol&# 237;meros se han producido con f&# 243;rmulas diferentes y se han caracterizado sus propiedades mec&# 225;nicas, composici&# 243;n y microestructura, para dar lugar a una composici&# 243;n interesante con propiedades aislantes. Se ha llevado a cabo adem&# 225;s un an&# 225;lisis preliminar sobre la formaci&# 243;n de sales que tiene lugar en este tipo de geopol&# 237;meros como una desventaja de los mismos...|$|R
40|$|La Bioinformática es una disciplina que nos permite tratar de almacenar y analizar la gran cantidad de información {{experimental}} que existe en la actualidad en el campo de la Biología. Con la aparición de nuevas tecnologías, los volúmenes de información cada vez son mayores y con ello aumenta la complejidad <b>para</b> <b>procesar</b> todos estos datos de los que disponemos. La necesidad de nuevos desarrollos informáticos orientados a la comprensión de datos genéticos cada vez es mayor, ya que las técnicas de análisis existentes crecen a un ritmo mucho menor que la producción de datos. Este proyecto consiste en el desarrollo de una plataforma de análisis de datos. Dicha plataforma tiene una serie de métodos y algoritmos que permiten el análisis y la visualización de los datos. Lo hemos desarrollado en Matlab porque nos permite que el tiempo de procesamiento de los datos sea menor que si se lleva a cabo con otros lenguajes. Nuestro proyecto va a permitir ampliar y mejorar un toolbox ya existente en Bioinformática, ya que aporta nuevas aplicaciones aún no existentes. [ABSTRACT] The Bio-Computer Science is {{a discipline}} that allows {{to try to}} store and to analyze the great amount us of experimental information that it exists {{at the present time}} in the field of the Biology. With the appearance of new technologies, the volumes of information every time are greater and with it it increases the complexity to process all these data which we have. The necessity of new computer science developments oriented to the understanding of genetic data every time is greater, since the techniques of existing analyses grow to a rate much smaller than the production of data. This project consists of the development of a platform of analysis of data. This platform has a series of methods and algorithms that allow to the analysis and the visualization of the data. We have developed it in Matlab because it allows us that the time of processing of the data is minor who if it is carried out with other languages. Our project is going to allow to extend and to improve toolbox already existing in Bio-Computer Science, since it contributes new existing applications not yet...|$|R
40|$|One of {{the most}} common debates {{surrounding}} the Mesolithic and early Neolithic periods in northern Spain focuses on the scarcity of lithic and osseous technologies identified in large shell midden contexts. Currently, several hypotheses have been proposed that attribute this phenomenon to differences in site spatial organization, increases in perishable material use, or changes in subsistence strategies. However, recently shell tools have been identified in the early Neolithic levels at Santimamiñe cave located in the Basque Country of northern Spain. These artifacts are the first evidence of shell tools to be identified in Northern Spain in an early Neolithic shell midden context. This paper proposes the hypothesis that shell tools were being used in subsistence activities. To test this hypothesis, the authors developed an experimental programme using different types of mollusc shells to examine evidence of functional use on wood, dry/fresh animal skin and non-woody plants. The experimental results were then used to examine the patterns of use on the seven shell tools from Santimamiñe. The results of the comparisons indicate that the seven shell tools have similar use patterns as the experimental shells. This evidence supports the proposed hypothesis that shell tools may have been used frequently in shell midden contexts during the Mesolithic and early Neolithic for the working of wood, plants or animal skin. Uno de los debates más extendidos en la historiografía sobre el Mesolítico y el Neolítico inicial en la región cantábrica es el de la escasez de tecnologías “tradicionales” en la mayor parte de los contextos existentes, especialmente en aquellos con grandes acumulaciones de conchas. Actualmente, varias de las hipótesis propuestas atribuyen este fenómeno a diferencias en la organización espacial de los asentamientos, al aumento en la utilización de materiales perecederos o a cambios en las estrategias de subsistencia. A partir del hallazgo de siete instrumentos de concha en el yacimiento de Santimamiñe (Kortezubi, Bizkaia), que a su vez constituyen la primera evidencia de su categoría en la región cantábrica, se propone como hipótesis el empleo de tecnologías de concha en algunas de las actividades productivas desarrolladas por los grupos de cazadores recolectores de los períodos indicados. Con el objetivo de confirmar/refutar los resultados obtenidos mediante el análisis funcional de estos instrumentos se ha llevado a cabo un programa experimental con diferentes especies de moluscos <b>para</b> <b>procesar</b> madera, piel fresca/seca y planta no leñosa. Los resultados del programa experimental confirman la utilización de estos instrumentos en diversas actividades productivas orientadas al procesado de algunas de estas materias...|$|R
40|$|La investigación se realiza en el Centro de Investigaciones del Níquel, con el objetivo de diseñar la Planeación Estratégica de la empresa y así mejorar su desempeño. Para alcanzar el objetivo, se utilizaron métodos teóricos de investigación científica: análisis y síntesis, hipotético-deductivo, histórico-lógico; así como algunos de los métodos empíricos de investigación: observación directa, entrevistas, tormenta de ideas, encuestas, {{consulta}} y revisión de documentos, trabajo en grupos, entre otros. <b>Para</b> <b>procesar</b> toda la información obtenida se empleó el paquete de programas de Office y otros software. Entre los principales resultados alcanzados se encuentran la definición de una nueva misión y visión del centro, involucrando a los trabajadores en el proceso de toma de decisiones; la definición de los objetivos estratégicos y las estrategias a seguir para alcanzarlos; así como la elaboración del plan de acción, cuya ejecución ha permitido desde el 2007 a la fecha actual, el incremento de las ventas en un 23 % con la realización de 60 nuevos servicios científico-tecnológicos, la disminución del consumo de energía eléctrica en 180 MW, el aumento de la productividad en más de 3000 pesos, y el logro de la ejecución de inversiones por 594 miles de pesos, que significan un mejoramiento considerable en las condiciones de trabajo del centro. AbstractThe {{investigation is}} {{carried out in the}} Nickel research Center, with the objective of designing the Strategic Projection of the company in order to improve its performance. To reach the objective, theoretical methods of scientific investigation were used, such as: the analysis-synthesis method, deductive-hypothetical, logical-historical method; {{as well as some of}} the empiric methods of investigation: direct observation, interviews, brainstorming, surveys, the consult and revision of documents, team group, among others. To process all the obtained information it was used the package of programs of Office and others software. Among the main results that were reached are the definition of a new mission and vision for the Centre, involving the workers into the process of decision making; the definition of the strategic objectives and the strategies to reach them; as well as the action plan whose execution has allowed from the 2007 to the present date the increment of the sales in 23 %, with the execution of new 60 scientific-technological services, the decrease of the electric power consumption in 180 MW, the increase of productivity in more than 3000 pesos, and the execution of investments for 594 thousands of pesos, which mean a considerable improvement under the work conditions of this centre...|$|R
40|$|La fabricación de briquetas fue una {{necesidad}} urgente de reemplazar a los combustibles tradicionales como la leña, el carbón y otros; {{de esta forma}} se evitó la tala indiscriminada de los bosques. El uso industrial de la briqueta, específicamente para la producción local de ladrillos se incluyó en la utilización de sus cenizas en el proceso de manufactura de ladrillos con el propósito de dar una disposición final de las cenizas, además de aumentar la resistencia de los ladrillos, al incorporarla a la materia prima, y de sustituir la leña como combustible, lo que contribuirá a disminuir la tala indiscriminada que se produce en los bosques de la región San Martín. Otro beneficio fue la eliminación de la contaminación causada por la quema de cáscara y sus residuos. La briquetadora que actualmente posee el proyecto procesa sólo 30 kilogramos por hora, pero se planea incrementar la capacidad <b>para</b> <b>procesar</b> más de mil kilogramos por hora. Una vez comprobada su viabilidad y el grado de aceptación entre la población, la fábrica extenderá su producción a la demanda en las ladrilleras y suscribir contratos con los molinos de arroz. The {{production of}} briquettes was an urgent necessity to replace to the traditional fuels as the firewood, the coal and other fuels this way we avoid the indiscriminate pruning of the forests. In this project, recommendations are given, experiences {{in the study of}} the prosecution of the briquette of rice shell. The use of the briquette will be possible for industrial purposes for this action were carried out experiments of use of briquette of shell of rice, specifically for the local production of bricks it will include the use of the ashy ones of briquette of shell of rice in the factory process of bricks manufacturing with the purpose of a final disposition of the ashes, besides increasing the resistance of the bricks, when incorporating it to the matter, and the substitution of the firewood as fuel, what will contribute to the indiscriminate pruning that in San Martin forest takes place. Another additional benefit will be the elimination of the contamination caused for the burns of rice shell and accumulation of the same one or its residuals. Although this innovation, largely caressed by many people, reality has been made belatedly, already this here is a promise. The factory of briquettes is still a project pilot. The briquette machine at the moment that the project owns only processes 30 kilograms per hour, but there is a plan to increase the capacity to process to more than a thousand kilograms per hour. Once proven their viability and the grade of acceptance among the population, the factory will extend its production...|$|R
40|$|La presente investigaci??n tuvo como objetivo establecer la relaci??n que existe entre el riesgo financiero de los socios de la Cooperativa de Ahorro y Cr??dito Parroquia San Lorenzo y la morosidad, Trujillo - 2017. El enunciado del problema fue ??Cu??l es la incidencia del riesgo financiero de los socios activos de la Cooperativa de Ahorro y Cr??dito Parroquia San Lorenzo de la sede {{principal}} de Trujillo en la morosidad al a??o 2017 ?; y siendo la hip??tesis: La incidencia del riesgo financiero que tienen los socios activos de la Cooperativa de Ahorro y Cr??dito Parroquia San Lorenzo de la sede principal de Trujillo en la morosidad es fuerte al a??o 2017. La poblaci??n objeto de estudio estuvo conformada por 16 753 socios activos de la sede principal de la Cooperativa San Lorenzo ubicada en Trujillo, se aplic?? el muestreo probabil??stico aleatorio simple obteniendo una {{muestra de}} 242 socios. El dise??o de investigaci??n aplicado fue explicativo correlacional. Para la recolecci??n de datos se aplic?? la encuesta, a partir de ello para la variable independiente se utiliz?? la herramienta de identificaci??n de nivel de riesgo financiero; para la variable dependiente se utiliz?? la herramienta de identificaci??n de nivel de morosidad <b>para</b> <b>procesar</b> los datos de la base de datos de la Cooperativa San Lorenzo. En conclusi??n, se determin?? que la correlaci??n existente entre las variables de riesgo financiero y morosidad es moderadamente positiva, resultados que son corroborados con la prueba estad??stica Chi Cuadrado, cuyo valor es < 0, 05 lo cual indica que existe una relaci??n directa. The present research had as objective establish {{the relationship that}} exist between the financial risk of the partners of the Cooperative of Saving and Credit Parish Saint Lorenzo and the morosity, Trujillo ??? 2017. The statement of the problem was: What is the incidence of the financial risk of the active partners of the Cooperative of Saving and Credit Parish Saint Lorenzo of the main headquarters of Trujillo in the morosity to the year 2017 ?; And the hypothesis: The financial risk of the active partners of the Cooperative of Saving and Credit Parish Saint Lorenzo of the main headquarters of Trujillo strongly affects the morosity to the year 2017. The population under study consisted of 16, 753 active partners of the main headquarters of the Cooperative Saint Lorenzo located in Trujillo, simple probabilistic random sampling was applied obtaining a sample of 242 members. The applied research design was correlational explanatory. For the data collection we applied the survey, for the variable for the independent variable we used the financial risk level identification tool; for the dependent variable, the morosity level identification tool was used to process data from the San Lorenzo Cooperative database. In conclusion, {{it was determined that}} the correlation between the variables of financial risk and morosity is moderately positive, results that are corroborated with the Chi Square test, whose value is < 0. 05 which indicates that there is a direct relationship...|$|R
40|$|SE DETERMINA LA FACTIBILIDAD TECNICA Y ECONOMICA PARA UTILIZAR EL RIO DAULE PARA LA NAVEGACION FLUVIAL. SE DESARROLLA EL ESTUDIO PRELIMINAR PARA DETERMINAR LA FACTIBILIDAD TECNICA Y ECONOMICA, PARA UTILIZAR LOS RIOS DE LA CUENCA DEL GUAYAS COMO HIDROVIAS DE COMUNICACION ENTRE LAS ZONAS DE PRODUCCION AGRICOLA Y LOS CANTONES QUE INCLUYEN FACILIDADES <b>PARA</b> ALMACENAR Y <b>PROCESAR</b> DICHOS PRODUCTOS. ESTO INCLUYE PRIMERO LA SELECCION DE LA ZONA A SERVIR, Y UNA ESTIMACION DE LA CANTIDAD DE PRODUCTOS AGRICOLAS A TRANSPORTAR. SE DISEÑA PRELIMINARMENTE LA EMBARCACION QUE SASTIFAGA LOS REQUIRIMIENTOS Y FINALMENTE ES NECESARIO DETERMINAR EL COSTO POR TRANSPORTAR LA CARGA PARA PODER COMPARARLA CON LAS ALTERNATIVAS ACTUALMENTE DISPONIBLES. FINALMENTE SE REALIZO UN ANALISIS ECONOMICO, QUE DETERMINO QUE LOS FLETES MINIMOS REQUERIDOS PARA ESTOS GRUPOS SON DE $ 0. 16 /MILLA/TM. Y $ 0. 25 /MILLA/TM PARA LOGRAR UNA TASA INTERNA DE RETORNO DEL 20 % Y CONSIDERANDO UN TIEMPO DE AMORTIZACION DE 20 AÑOS...|$|R
40|$|In {{the centers}} of teacher {{training}} emerges an influential and basic phenomenon in the quality educational praxis, constituted by {{the perceptions of the}} learning of its key actors. This affirmation promotes the study of this construct with the purpose of unveiling and updating the essential elements as distinctive for its conceptualization. This study was inserted in the naturalistic paradigm, where the method to process the information and to interpret it in its essence was the phenomenological one. The initial informants were made up of students and professors of the Cognitive Processes Development Course (DPC 0113) of the Miranda Pedagogical Institute José Manuel Siso Martínez de Venezuela in the academic periods 2015 -II - 2016 -I. Under the principles of theoretical saturation, the 12 final informants were determined. The techniques used to gather information were participant observation, supported by an observation guide and the in-depth interview, based on an interview script. The emerging findings allow us to affirm that the perception about learning in teacher training continually changes along with the cognitive, affective and ethical actions of the subjects that make it up. This phenomenon allows us to construct theoretical approaches that allow us to generate actions for quality teacher training. En los centros de formación docente emerge un fenómeno influyente y básico en la praxis educativa de calidad, constituido por las percepciones del aprendizaje de sus actores clave. Dicha afirmación impulsa el estudio de este constructo con la finalidad de develar y actualizar los elementos esenciales como distintivos para su conceptualización. Este estudio se insertó en el paradigma naturalístico, donde el método <b>para</b> <b>procesar</b> la información e interpretarla en su esencia fue el fenomenológico. Los informantes iniciales lo conformaron estudiantes y profesores del curso Desarrollo de Procesos Cognoscitivos (DPC 0113) del Instituto Pedagógico de Miranda José Manuel Siso Martínez de Venezuela en los períodos académicos 2015 -II - 2016 -I. Bajo los principios de la saturación teórica, se determinaron los 12 informantes finales. Las técnicas empleadas para recabar la información fueron la observación participante, apoyada en una guía de observación y la entrevista en profundidad, sustentada en un guion de entrevista. Los hallazgos emergentes permiten afirmar, que la percepción sobre el aprendizaje en la formación docente continuamente se transforma a la par de las acciones cognitivas, afectivas y éticas de los sujetos que la conforman. Este fenómeno permite construir aproximaciones teóricas que permiten generar acciones para una formación docente de calidad. PERCEPTIONS OF LEARNING, INFLUENCING PHENOMENON IN QUALITY TEACHING TRAININGSummaryIn {{the centers of}} teacher training emerges an influential and basic phenomenon in the quality educational praxis, constituted by the perceptions of the learning of its key actors. This affirmation promotes the study of this construct with the purpose of unveiling and updating the essential elements as distinctive for its conceptualization. This study was inserted in the naturalistic paradigm, where the method to process the information and to interpret it in its essence was the phenomenological one. The initial informants were made up of students and professors of the Cognitive Processes Development Course (DPC 0113) of the Miranda Pedagogical Institute José Manuel Siso Martínez de Venezuela in the academic periods 2015 -II - 2016 -I. Under the principles of theoretical saturation, the 12 final informants were determined. The techniques used to gather information were participant observation, supported by an observation guide and the in-depth interview, based on an interview script. The emerging findings allow us to affirm that the perception about learning in teacher training continually changes along with the cognitive, affective and ethical actions of the subjects that make it up. This phenomenon allows us to construct theoretical approaches that allow us to generate actions for quality teacher training. Keywords: Perceptions, Learning; Teacher Training; Qualit...|$|R
40|$|Durante el transcurso de esta Tesis Doctoral se ha realizado un estudio de la problemática asociada al desarrollo de sistemas de interacción hombre-máquina sensibles al contexto. Este problema se enmarca dentro de dos áreas de investigación: los sistemas interactivos y las fuentes de información contextual. Tradicionalmente la integración entre ambos campos se desarrollaba a través de soluciones verticales específicas, que abstraen a los sistemas interactivos de conocer los procedimientos de bajo nivel de acceso a la información contextual, pero limitan su interoperabilidad con otras aplicaciones y fuentes de información. Para solventar esta limitación se hace imprescindible potenciar soluciones interoperables que permitan acceder a la información del mundo real a través de procedimientos homogéneos. Esta problemática {{coincide}} perfectamente con los escenarios de Ubicua" e de las Cosas", donde se apunta a un futuro en el que los objetos que nos rodean serán capaces de obtener información del entorno y comunicarla a otros objetos y personas. Los sistemas interactivos, al ser capaces de obtener información de su entorno a través de la interacción con el usuario, pueden tomar un papel especial en este escenario tanto como consumidores como productores de información. En esta Tesis se ha abordado la integración de ambos campos teniendo en cuenta este escenario tecnológico. Para ello, en primer lugar se ha realizado un an álisis de las iniciativas más importantes para la definición y diseño de sistemas interactivos, y de las principales infraestructuras de suministro de información. Mediante este estudio se ha propuesto utilizar el lenguaje SCXML del W 3 C para el diseño de los sistemas interactivos y el procesamiento de los datos proporcionados por fuentes de contexto. Así, se ha reflejado cómo las capacidades del lenguaje SCXML para combinar información de diferentes modalidades pueden también utilizarse <b>para</b> <b>procesar</b> e integrar información contextual de diferentes fuentes heterogéneas, y por consiguiente diseñar sistemas de interacción sensibles al contexto. Del mismo modo se presenta a la iniciativa Sensor Web, y a su extensión semántica Semantic Sensor Web, como una iniciativa idónea para permitir un acceso y suministro homogéneo de la información a los sistemas interactivos sensibles al contexto. Posteriormente se han analizado los retos que plantea la integración de ambos tipos de iniciativas. Como resultado se ha conseguido establecer una serie de funcionalidades que son necesarias implementar para llevar a cabo esta integración. Utilizando tecnologías que aportan una gran flexibilidad al proceso de implementación y que se apoyan en recomendaciones y estándares actuales, se implementaron una serie de desarrollos experimentales que integraban las funcionalidades identificadas anteriormente. Finalmente, con el fin de validar nuestra propuesta, se realizaron un conjunto de experimentos sobre un entorno de experimentación que simula el escenario de la conducción. En este escenario un sistema interactivo se comunica con una extensión semántica de una plataforma basada en los estándares de la Sensor Web para poder obtener información y publicar las observaciones que el usuario realizaba al sistema. Los resultados obtenidos han demostrado la viabilidad de utilizar el lenguaje SCXML para el diseño de sistemas interactivos sensibles al contexto que requieren acceder a plataformas avanzadas de información para consumir y publicar información a la vez que interaccionan con el usuario. Del mismo modo, se ha demostrado cómo la utilización de tecnologías semánticas en los procesos de consulta y publicación de información puede facilitar la reutilización de la información publicada en infraestructuras Sensor Web por cualquier tipo de aplicación, y de este modo contribuir al futuro escenario de Internet de las Cosas. ABSTRACT In this Thesis, we {{have addressed}} the difficulties related {{to the development of}} context-aware human-machine interaction systems. This issue is part of two research fields: interactive systems and contextual information sources. Traditionally both fields have been integrated through domain-specific vertical solutions that allow interactive systems to access contextual information without having to deal with low-level procedures, but restricting their interoperability with other applications and heterogeneous data sources. Thus, it is essential to boost the research on interoperable solutions that provide access to real world information through homogeneous procedures. This issue perfectly matches with the scenarios of Computing" and of Things", which point toward a future in which many objects around us will be able to acquire meaningful information about the environment and communicate it to other objects and to people. Since interactive systems are able to get information from their environment through interaction with the user, they can {{play an important role in}} this scenario as they can both consume real-world data and produce enriched information. This Thesis deals with the integration of both fields considering this technological scenario. In order to do this, we first carried out an analysis of the most important initiatives for the definition and design of interactive systems, and the main infrastructures for providing information. Through this study the use of the W 3 C SCXML language is proposed for both the design of interactive systems and the processing of data provided by different context sources. Thus, this work has shown how the SCXML capabilities for combining information from different modalities can also be used to process and integrate contextual information from different heterogeneous sensor sources, and therefore to develope context-aware interaction systems. Similarly, we present the Sensor Web initiative, and its semantic extension Semantic Sensor Web, as an appropriate initiative to allow uniform access and delivery of information to the context-aware interactive systems. Subsequently we have analyzed the challenges of integrating both types of initiatives: SCXML and (Semantic) Sensor Web. As a result, we state a number of functionalities that are necessary to implement in order to perform this integration. By using technologies that provide exibility to the implementation process and are based on current recommendations and standards, we implemented a series of experimental developments that integrate the identified functionalities. Finally, in order to validate our approach, we conducted different experiments with a testing environment simulating a driving scenario. In this framework an interactive system can access a semantic extension of a Telco plataform, based on the standards of the Sensor Web, to acquire contextual information and publish observations that the user performed to the system. The results showed the feasibility of using the SCXML language for designing context-aware interactive systems that require access to advanced sensor platforms for consuming and publishing information while interacting with the user. In the same way, it was shown how the use of semantic technologies in the processes of querying and publication sensor data can assist in reusing and sharing the information published by any application in Sensor Web infrastructures, and thus contribute to realize the future scenario of of Things"...|$|R
40|$|In {{the late}} 90 s, Paul C. Kocher {{introduced}} {{the concept of}} differential attack focused on the power consumption of a cryptographic device. In this type of analysis the plain text sent to the device is known, and all possible hypotheses of {{a subset of the}} key, related to a specific point of the cryptographic algorithm, are tested. If the key value at that point depends only on 1 byte, it is possible to predict the input current based on a theoretical model of power consumption. Thus, using statistic procedures, it is easy to compare the consumption measured during the processing of each plain text and the intermediate values related to all the hypothesis of the key. The one with the highest level of similarity will correspond to the actual key. So far the countermeasures proposed to prevent the success of the attack can be classified into two groups: Masking and Hiding. Masking tries to decouple the processed data and the power consumption by adding a random mask which is unknown by the attacker. Therefore, it is impossible to make a hypothesis that allows the theoretical and the real power consumption of the device to be related. Although is a valid method, the key could be revealed by performing a second-order attack that analyzes several points of the current trace. Hiding aims at making constant the consumption of a device in each clock cycle and independent of the processed data. In order to achieve this objective, the data is processed in double line, {{in such a way that}} the datum and its complementary are processed together, so that the same number of transitions always occur on every clock cycle. The weakness of such a method lies on the impossibility of building identical CMOS cells, which causes a minimum difference of consumption between the two lines that can be used successfully to discover the key. This thesis proposes a countermeasure based on a differentiated protection strategy with respect to the proposals made in other specific studies. It is intended to modify the algorithm in order to force a very high correlation with a different hypothesis to the one of the true key (Faking). Thus, the actual key is hidden behind the strong correlation, which is impossible to differentiate from the rest of false assumptions and remains protected. To verify its performance a trial bank has been designed to launch consumption analysis attacks. We have implemented the algorithm AES due to its simplicity and strength. Two types of attacks have been carried out. In the first one, the analysis was performed using both the correlation and the mean difference analysis without including any countermeasure. In the second attack, the proposed countermeasure has been added and the attack was repeated to check its effectiveness. We have evaluated three different situations. First of all, the algorithm and the countermeasure are solved by software on a 32 -bit processor. Secondly, the algorithm is executed in software and the implementation of the countermeasure has been performed with a specific hardware coprocessor. Finally, a full hardware implementation including both the algorithm and the countermeasure has been chosen. All of them have been implemented on a Virtex 5 FPGA Xilinx. Several conclusions are obtained from the comparison between each of the AES implementations without countermeasures and their respective solution with the added countermeasure. The obtained results are also compared to other which use "masking" and "hiding" techniques. The results demonstrate that the proposal is valid. In all three cases, the protected system behaves like the unprotected system but returning the false key after the attacks. It should be noted that the amount of resources needed to carry out the "Faking" is less than the "Masking" or "Hiding" and the time needed to process the plain text is not particularly affected. A finales de los 90 Paul C. Kocher introdujo por primera vez el concepto de ataque diferencial sobre el consumo de corriente de un dispositivo criptográfico. En este tipo de análisis, se conoce el texto plano que se envía al dispositivo y se plantean todas las posibles hipótesis de la clave para un punto concreto del algoritmo. Si el valor en ese punto del algoritmo depende únicamente de 1 byte de la clave, es posible calcular todos los valores que se producirán. Llegado a este punto, se compara, por métodos estadísticos, el consumo medido durante el procesado de cada texto plano y los valores intermedios relacionados con todas las hipótesis de la clave. Aquella que mayor nivel de similitud tenga corresponderá con la clave real. Las contramedidas propuestas hasta la fecha, para evitar el éxito del ata-que, pueden separarse en dos grupos: enmascaramiento (Masking) y ocultación (Hiding). El enmascaramiento trata de desvincular el dato procesado del consumo eléctrico mediante la adición de una máscara aleatoria y desconocida por el atacante. En consecuencia, resulta imposible realizar una hipótesis que permita relacionar los consumos teórico y real del dispositivo. Si bien este es un método inicialmente válido, puede descubrirse la clave realizando un ataque de segundo orden que analiza varios puntos del consumo. La ocultación persigue que el consumo de un dispositivo sea el mismo en cada ciclo de reloj e independiente del dato procesado. Para ello, se procesa el dato en doble línea, por un lado el dato propiamente dicho y por el otro su complementario, de forma que siempre se produzcan la misma cantidad de transiciones en cada ciclo de reloj. La debilidad de este método radica en la práctica imposibilidad de construir celdas CMOS idénticas, esto provoca que siempre exista una diferencia de consumo entre las dos líneas y pueda usarse con éxito para descubrir la clave. En esta tesis se propone una contramedida basada en una estrategia de protección claramente diferenciada con respecto a las propuestas realizadas en la bibliografía específica. Se pretende modificar el algoritmo con el objetivo de forzar una correlación muy alta en una hipótesis diferente a la de la clave (Faking). De este modo, la clave real se oculta tras la fuerte correlación aparecida, resulta imposible diferenciarla del resto de hipótesis falsas y queda protegida. Para verificar su funcionamiento se ha montado un banco de pruebas para realizar ataques por análisis de consumo. Se ha implementado el algoritmo AES debido a su simplicidad y robustez. Se han realizado dos tipos de ataques: en el primero se han practicado análisis de correlación y diferencia de medias sin contramedida alguna; en el segundo, se ha añadido la contramedida y se han repetido los ataques para comprobar su eficacia. Se han evaluado 3 escenarios diferentes, primeramente el algoritmo y la contramedida se resuelven mediante software en un procesador de 32 bits. En segundo lugar, el algoritmo se resuelve mediante software y la implementación de la contramedida se ha realizado en un coprocesador hardware específico. Fi-nalmente, se ha elegido una implementación totalmente hardware para resolver tanto el algoritmo como la contramedida. Todos ellos se han implementado sobre una FPGA Virtex 5 de Xilinx. Las conclusiones se obtienen de la comparación entre cada una de las im-plementaciones del AES sin contramedidas y su respectiva solución con la con-tramedida añadida. También se comparan los resultados obtenidos con otros que utilizan las técnicas "Masking" y "Hiding" Los resultados demuestran que la propuesta es válida. En los tres casos, el sistema protegido se comporta igual que el sistema sin proteger, pero retornando la clave falsa ante los ataques realizados. Se ha de destacar que, la cantidad de recursos necesarios para llevar a cabo el "Faking" es menor que con el "Masking" o el "Hiding" y el tiempo necesario <b>para</b> <b>procesar</b> el texto plano no se ve particularmente afectado por su inclusión...|$|R
40|$|This PhD thesis {{comprises}} five studies {{aiming to}} investigate differences between low math- anxious (LMA) and high math-anxious (HMA) individuals in numeric processing {{by means of}} behavioral and event-related potential (ERPs) measures. The excellent temporal resolution of the ERP technique was expected to provide detailed information that would shed light about the difficulties HMA individuals face {{when they have to}} deal with numbers. The first study aimed to adapt into Spanish and validate the Shortened Mathematics Anxiety Rating Scale (sMARS; Alexander & Martray, 1989) as a starting point of this thesis, in order to make sure that the construct of math anxiety (MA) was going to be assessed with an instrument providing valid and reliable measures. The adaptation into Spanish of the sMARS scale gave sound evidence of its good psychometric properties: strong internal consistency, high 7 -week test-retest reliability and good convergent/discriminant validity. Study II aimed to investigate, with the ERP technique, the use of the plausibility strategy in math-anxious individuals by studying Faust et al. (1996) ´s finding on flawed scores for dramatically incorrect solutions (large-split) in an arithmetic verification task. We were able to replicate, for the first time, those findings, by finding a greater percentage of flawed scores for large-split solutions for the HMA group as compared to the LMA one. Moreover, ERP analysis showed that large-split solutions generated a P 600 /P 3 b component of larger amplitude and delayed latency for the HMA group as compared to the LMA one. Given the functionality of this component, this finding suggested that large-split solutions demanded more cognitive resources and required more time to be processed for the HMA group than for the LMA one. These findings were interpreted according to the Attentional Control Theory (ACT; Eysenck, Derakshan, Santos, & Calvo, 2007) : HMA individuals, being more influenced by the stimulus-driven attentional system, would have succumbed to the distractor nature of the large-split solution, devoting more time (P 600 /P 3 b latency) and cognitive resources (P 600 /P 3 b amplitude) to process this clearly wrong solution, instead of using the plausibility strategy. Study III consisted of finding the electrophysiological correlates of numeric interference in LMA and HMA individuals, by means of a numeric Stroop task. We found that HMA individuals needed more time to solve this task as compared to their LMA peers, suggesting that they were distracted by the task-irrelevant dimension of the stimuli (i. e. physical size of numbers). ERP data analysis showed that LMA and HMA individuals differed in the way they adapted to conflict: the LMA group presenting a greater N 450 component for the interference effect preceded by congruence than when preceded by incongruity while the HMA group showed the same enhancement but for the subsequent Conflict sustained potential. These results suggested that both groups showed a different implementation of attentional control, which was executed in a proactive way by LMA individuals and in a reactive way by HMA ones. A reactive recruitment of attentional control in HMA individuals would have made them more influenced by bottom-up input (i. e. stimulus-driven attentional system), making them more vulnerable to distraction. The two remaining studies of this PhD thesis aimed to explore two possible factors contributing to the development of MA. Given that errors are crucial for mathematical learning, because of its cumulative nature, one concept building on the next, Study IV aimed to assess whether LMA and HMA individuals differed in the way they processed a numeric error as compared to a non- numeric one. We found that HMA individuals showed an increased error-related negativity (ERN) when they committed an error in the numeric Stroop task, but not in the classical Stroop task. Furthermore, standardized low resolution electromagnetic tomography (sLORETA) analysis showed significant greater voxel activation at the right insula for the errors committed in the numerical task as compared to the classical one for the HMA group and not differences at all for the LMA one. Given that the right insula has been associated with the discomfort with one´s own physiological responses and given that errors are considered to generate a cascade of physiological responses, this finding suggests that HMA individuals´ may have experienced a discomfort with the physiological responses generated by a numeric error. This negative bodily reaction towards numeric errors may be at the base of the development of negative attitudes towards mathematics and of the tendency of HMA individuals to avoid math-related situations. Finally, Study V aimed to investigate, by means of an emotional Stroop task, whether MA is characterized by an attentional bias towards math-related information, given that an attentional bias towards threatening information is considered to be a contributory factor in the origin and maintenance of several types of anxiety. This study showed that HMA individuals showed a clear tendency of responding slower to math-related words as compared to neutral words. Given that this slowdown in an emotional Stroop task has traditionally been interpreted as an attentional bias towards threatening or emotional stimuli, this study demonstrates that MA is also characterized by an attentional bias, in this case, towards math-related words, which could probably be at the base of its development and maintenance. To sum up, this PhD thesis has shown that MA is characterized by a vulnerability to distraction, which was shown when a large-split solution was presented for a simple addition task (Study II) and when physical size interfered with numerical magnitude in a numeric Stroop task (Study III). Moreover, HMA individuals also showed a reactive recruitment of attentional control after conflict detection (Study III), a greater sensitivity or emotional response to numeric errors (Study IV) and a clear tendency of an attentional bias towards math-related stimuli (Study V). Esta tesis doctoral se compone de cinco estudios cuyo objetivo era investigar las diferencias en el procesamiento numérico entre individuos con alta ansiedad a las matemáticas (AAM) y aquellos con baja ansiedad a las matemáticas (BAM) a través de medidas conductuales y de potenciales evocados cerebrales (ERPs). Esperábamos que la excelente resolución temporal de esta técnica nos permitiera obtener información más específica sobre los problemas a los que se enfrentan los individuos con AAM cuando han de procesar números. El primer estudio pretendía adaptar al español y validar la escala sMARS (Alexander & Martray, 1989), como punto de partida de esta tesis, para asegurarnos de que el constructo de la ansiedad a las matemáticas (AM) fuera medido con un instrumento que nos proporcionara medidas válidas y fiables. La adaptación al español de esta escala dio evidencias de sus buenas propiedades psicométricas: alta consistencia interna, alta fiabilidad test-retest de 7 semanas, y alta validez convergente/discriminante. El Estudio II pretendía investigar, con la ayuda de los ERPs, el uso de la estrategia de plausibilidad en los individuos con AAM, estudiando el hallazgo de Faust et al. (1996) en su medida de puntuaciones anómalas (flawed scores) para las soluciones exageradamente incorrectas (large- split solutions). En primer lugar, reproducimos el patrón obtenido por dichos autores. Además, el análisis de ERPs mostró que las soluciones exageradamente incorrectas generaban un componente P 600 /P 3 b de mayor amplitud y de latencia más tardía para el grupo de AAM comparado con el de BAM. Dada la funcionalidad de este componente, estos resultados sugirieron que las soluciones exageradamente incorrectas demandaron más recursos cognitivos y requirieron más tiempo para ser procesadas en el grupo de AAM que en el de BAM. Estos resultados fueron interpretados de acuerdo a la Teoría del Control Atencional (ACT; Eysenck, Derakshan, Santos, & Calvo, 2007) : los individuos con AAM, estando más influenciados por el sistema atencional ligado a estímulos (stimulus-driven attentional system), habrían sido más vulnerables a la distracción, y habrían sucumbido a la naturaleza distractora de las soluciones exageradamente incorrectas, empleando más recursos cognitivos y más tiempo (reflejado por la amplitud y la latencia del componente P 600 /P 3 b) <b>para</b> <b>procesar</b> esta solución implausible, en lugar de utilizar la estrategia de plausibilidad. Por otro lado, el Estudio III consistió en investigar el correlato electrofisiológico de la interferencia numérica en individuos con AAM, por medio de una tarea de Stroop numérico. En este estudio encontramos que los individuos con AAM necesitaban más tiempo para resolver la tarea que los individuos con BAM, sugiriendo que éstos se distraían con la dimensión irrelevante de la tarea (esto es, el tamaño físico). El análisis de ERPs demostró que los individuos con AAM y BAM presentaban una adaptación al conflicto diferente: el grupo de BAM mostró una mayor amplitud del componente N 450 para la interferencia precedida por congruencia respecto a la precedida por incongruencia, mientras el grupo de AAM mostró dicho aumento de amplitud, pero para el componente CSP. Estos resultados sugirieron que los grupos implementaban el control atencional de un modo diferente: de una manera proactiva por el grupo de BAM y de una manera reactiva por el grupo de AAM. Un uso reactivo del control atencional en individuos con AAM los habría hecho más influenciables por el sistema atencional ligado a estímulos y, por tanto, más vulnerables a la distracción. Los dos estudios restantes de esta tesis doctoral pretendían explorar dos factores que podrían contribuir al desarrollo de la AM. Dado que los errores son cruciales para el aprendizaje de las matemáticas, el Estudio IV pretendía evaluar si los individuos con AAM y BAM diferirían en la manera en que procesan un error numérico respecto a otro no numérico. En este estudio encontramos que los individuos con AAM mostraron un componente ERN de mayor amplitud cuando cometían un error en la tarea numérica que cuando lo cometían en una tarea no numérica. Además el estudio con sLORETA mostró una mayor activación de la ínsula derecha para los errores cometidos en la tarea numérica respecto a la tarea no numérica, sólo para el grupo de AAM. Dado que la ínsula derecha se ha asociado al desagrado con las respuestas fisiológicas y dado que se considera que los errores generan una cascada de dichas respuestas, este hallazgo fue interpretado como indicador del malestar que los individuos con AAM habrían experimentado respecto a su respuesta fisiológica ante errores numéricos. Esta reacción corporal negativa hacia errores numéricos podría estar en la base del desarrollo de actitudes negativas hacia las matemáticas y de la tendencia de los individuos con AAM a evitar situaciones con contenido numérico. Finalmente, el Estudio V pretendía estudiar si la ansiedad a las matemáticas podría desarrollarse a través de los mismos mecanismos por los que se ha sugerido que se desarrollarían otros tipos de ansiedad investigando, por medio de la tarea de Stroop emocional, si la AM se caracteriza por un sesgo atencional hacia información relacionada con las matemáticas. Este estudio mostró que los individuos con AAM eran más lentos en indicar el color de la tinta de palabras relacionadas con las matemáticas comparado con palabras neutras, mientras que no hubo diferencias en este sentido para el grupo de BAM. Dado que este enlentecimiento en los tiempos de respuesta en la tarea de Stroop emocional se interpreta como un sesgo atencional hacia información emocional u amenazante, este estudio demuestra que la ansiedad a las matemáticas también se caracteriza por un sesgo atencional, que podría jugar algún papel en su desarrollo, mantenimiento o empeoramiento. Para resumir, esta tesis doctoral ha mostrado que la AM se caracteriza por una vulnerabilidad a la distracción, la cual se mostró cuando se presentó una solución exageradamente incorrecta para una tarea de sumas simples (Estudio II) y cuando el tamaño físico interfería con la magnitud numérica en una tarea de Stroop numérico (Estudio III). Además, los individuos con AAM también mostraron un uso reactivo del control atencional tras la detección del conflicto (Estudio III), mayor sensibilidad o respuesta emocional al error (Estudio IV) y un sesgo atencional hacia palabras relacionadas con las matemáticas (Estudio V) ...|$|R
40|$|La investigación consistió en la aplicación de la técnica de los Mapas Mentales con el objetivo de desarrollar las habilidades de comprensión y producción de textos en los estudiantes del cuarto grado de educación primaria, en el área de Comunicación Integral de la Institución Educativa Experimental "José Carlos Mariátegui" de ta Facultad de Educación y Humanidades -Rioja. La investigación surgió {{debido a}} que se pudo observar que en la actualidad no se utilizan modelos o técnicas sistematizados <b>para</b> leer y <b>procesar</b> la información de los textos y en vista de que los estudiantes leen como pueden: Unos identificando ideas principales de los párrafos con algún criterio técnico; otros, copiando la información literalmente o simplemente suprimiendo algunas líneas del texto. De esta manera, casi nunca emplean esquemas o representaciones gráficas para traducir el producto de la lectura y comprensión def texto; tampoco conocen cómo se elaboran los Mapas Mentales, entre otras técnicas que le ayuden en su proceso de aprendizaje. A la luz de esta realidad, y en base a los antecedentes de la investigación. se postuló que con fa técnica de los Mapas Mentales los estudiantes desarrollarían sus habilidades para la comprensión y producción de textos, lo cual se constituyó en la hipótesis de investigación. En cuanto a la parte metodológica, se trabajó con una muestra de 15 estudiantes a quienes se les administró un pretest al inicio de La investigación y un postest después de aplicar 12 sesiones de aprendizaje en base a los Mapas mentales. Respecto a los resultados, la contrastación de la hipótesis se realizó con un nivel de confianza del 95 %, mediante la prueba t de Student para la diferencia pareada de te = 46, 72 y un valor tabular de tr = 1, 761, aceptándose la hipótesis de investigación, lo cual significa que la aplicación de la técnica de los Mapas Mentales ha desarrollado significativamente !as habilidades de la comprensión y producción de textos en los alumnos del 4 ° Grado de Educación Primaria de la Institución Educativa "José Carlos Mariátegui"TesisThe {{investigation}} consisted on {{the application of the}} technique of the Mental Maps with the objective of developing the abilities of understanding and production of texts in the students of the fourth grade of primary education, in the area of Integral Communication of the Experimental Educational lnstitution José Carlos Mariátegui of the Ability of Education and Humanities - Rioja. The investigation arase because one could observe that at the present time models or techniques are not used systematized to read and to process the information of the texts and {{in view of the fact}} that the students read like they can: Sorne identifying main ideas of the paragraphs with sorne technical approach; other, copying th. e information literally or simply suppressing sorne lines of the text. This way, they hardly ever use outlines or graphic representatíons to translate the product of the reading and understanding of the text; neither they know how the Mental Maps are elaborated, among other techniques that you/they help him in their learning process. By the Hght of this reality, and based on the antecedents of the investigation, it was postulated that with the technique of the Mental Maps the students would develop their abilities for the understanding and production of texts, that which was constituted in the investigation hypothesis. As for the methodological part, one worked with a sample of 15 students to who you/they were administered a pretest to the beginning of The investigation and a postest after applying 7 leaming sessions based on the mental Maps. Regarding the results, the contrastación of the hypothesis was carried out with a leve! of trust of 95 %, by means of the test t of Student for the paired difference te = 46. 72 maijor score de tt = 1, 761, accepted the investigation hypothesis, that which means that the application of the technique of the Mental Maps has developed the abilities of the understanding and production of texts significantly in the students of the 4 ° Grade of Primary Education of the Educationallnstitution "José Carlos Maríátegui...|$|R
40|$|A {{recommender}} system is an automatic system that, given a customer model {{and a set}} of available documents, is able to select and offer those documents that are more interesting to the customer. From {{the point of view of}} security, there are two main issues that {{recommender system}}s must face: protection of the users' privacy and protection of other participants of the recommendation process. Recommenders issue personalized recommendations taking into account not only the profile of the documents, but also the private information that customers send to the recommender. Hence, the users' profiles include personal and highly sensitive information, such as their likes and dislikes. In order to have a really useful recommender system and improve its efficiency, we believe that users shouldn't be afraid of stating their preferences. The second challenge from the point of view of security involves the protection against a new kind of attack. Copyright holders have shifted their targets to attack the document providers and any other participant that aids in the process of distributing documents, even unknowingly. In addition, new legislation trends such as ACTA or the ¿Sinde-Wert law¿ in Spain show the interest of states all over the world to control and prosecute these intermediate nodes. we proposed the next contributions: 1. A social model that captures user's interests into the users' profiles, and a metric function that calculates the similarity between users, queries and documents. This model represents profiles as vectors of a social space. Document profiles are created by means of the inspection of the contents of the document. Then, user profiles are calculated as an aggregation of the profiles of the documents that the user owns. Finally, queries are a constrained view of a user profile. This way, all profiles are contained in the same social space, and the similarity metric can be used on any pair of them. 2. Two mechanisms to protect the personal information that the user profiles contain. The first mechanism takes advantage of the Johnson-Lindestrauss and Undecomposability of random matrices theorems to project profiles into social spaces of less dimensions. Even if the information about the user is reduced in the projected social space, under certain circumstances the distances between the original profiles are maintained. The second approach uses a zero-knowledge protocol to answer the question of whether or not two profiles are affine without leaking any information in case of that they are not. 3. A distributed system on a cloud that protects merchants, customers and indexers against legal attacks, by means of providing plausible deniability and oblivious routing to all the participants of the system. We use the term DocCloud to refer to this system. DocCloud organizes databases in a tree-shape structure over a cloud system and provide a Private Information Retrieval protocol to avoid that any participant or observer of the process can identify the recommender. This way, customers, intermediate nodes and even databases are not aware of the specific database that answered the query. 4. A social, P 2 P network where users link together according to their similarity, and provide recommendations to other users in their neighborhood. We defined an epidemic protocol were links are established based on the neighbors similarity, clustering and randomness. Additionally, we proposed some mechanisms such as the use SoftDHT to aid in the identification of affine users, and speed up the process of creation of clusters of similar users. 5. A document distribution system that provides the recommended documents at the end of the process. In our view of a recommender system, the recommendation is a complete process that ends when the customer receives the recommended document. We proposed SCFS, a distributed and secure filesystem where merchants, documents and users are protectedEste documento explora c omo localizar documentos interesantes para el usuario en grandes redes distribuidas mediante el uso de sistemas de recomendaci on. Se de fine un sistema de recomendaci on como un sistema autom atico que, dado un modelo de cliente y un conjunto de documentos disponibles, es capaz de seleccionar y ofrecer los documentos que son m as interesantes para el cliente. Las caracter sticas deseables de un sistema de recomendaci on son: (i) ser r apido, (ii) distribuido y (iii) seguro. Un sistema de recomendaci on r apido mejora la experiencia de compra del cliente, ya que una recomendaci on no es util si es que llega demasiado tarde. Un sistema de recomendaci on distribuido evita la creaci on de bases de datos centralizadas con informaci on sensible y mejora la disponibilidad de los documentos. Por ultimo, un sistema de recomendaci on seguro protege a todos los participantes del sistema: usuarios, proveedores de contenido, recomendadores y nodos intermedios. Desde el punto de vista de la seguridad, existen dos problemas principales a los que se deben enfrentar los sistemas de recomendaci on: (i) la protecci on de la intimidad de los usuarios y (ii) la protecci on de los dem as participantes del proceso de recomendaci on. Los recomendadores son capaces de emitir recomendaciones personalizadas teniendo en cuenta no s olo el per l de los documentos, sino tambi en a la informaci on privada que los clientes env an al recomendador. Por tanto, los per les de usuario incluyen informaci on personal y altamente sensible, como sus gustos y fobias. Con el n de desarrollar un sistema de recomendaci on util y mejorar su e cacia, creemos que los usuarios no deben tener miedo a la hora de expresar sus preferencias. Para ello, la informaci on personal que est a incluida en los per les de usuario debe ser protegida y la privacidad del usuario garantizada. El segundo desafi o desde el punto de vista de la seguridad implica un nuevo tipo de ataque. Dado que la prevenci on de la distribuci on ilegal de documentos con derechos de autor por medio de soluciones t ecnicas no ha sido efi caz, los titulares de derechos de autor cambiaron sus objetivos para atacar a los proveedores de documentos y cualquier otro participante que ayude en el proceso de distribuci on de documentos. Adem as, tratados y leyes como ACTA, la ley SOPA de EEUU o la ley "Sinde-Wert" en España ponen de manfi esto el inter es de los estados de todo el mundo <b>para</b> controlar y <b>procesar</b> a estos nodos intermedios. Los juicios recientes como MegaUpload, PirateBay o el caso contra el Sr. Pablo Soto en España muestran que estas amenazas son una realidad...|$|R

