5008|978|Public
5|$|The Apple A5 chip doubles <b>processing</b> <b>speed</b> and has {{graphics}} processing {{that is up}} to {{nine times}} faster than the previous iPad. However, benchtests and hardware assessments performed by various third party news sources and technology blogs indicate that those claims are exaggerated; the benchmark assessment conducted by Anandtech showed that the GPU of the iPad 2 is only 3 times faster than that of the original iPad. CPU benchmarks conducted on the iPad 2 by iOSnoops indicate a 66% performance increase compared to the original iPad.|$|E
5|$|By 1961, MIT had {{acquired}} the DEC PDP-1 minicomputer, {{the successor to}} the TX-0, which also used a vector display system. The system's comparatively small size and <b>processing</b> <b>speed</b> meant that, like with the TX-0, the university allowed its undergraduate students and employees to write programs for the computer which were not directly academically related whenever {{it was not in}} use. In 1961-62, Harvard and MIT employees Martin Graetz, Steve Russell, and Wayne Wiitanen created the game Spacewar! on the PDP-1, inspired by science fiction books such as the Lensman series. The game was copied to several of the early minicomputer installations in American academic institutions, making it potentially the first video game to be available outside a single research institute.|$|E
5|$|Cognitive {{disturbances}} {{can occur}} {{in the early stages}} of the disease and sometimes prior to diagnosis, and increase in prevalence with duration of the disease. The most common cognitive deficit in PD is executive dysfunction, which can include problems with planning, cognitive flexibility, abstract thinking, rule acquisition, inhibiting inappropriate actions, initiating appropriate actions, working memory, and control of attention. Other cognitive difficulties include slowed cognitive <b>processing</b> <b>speed,</b> impaired recall and impaired perception and estimation of time. Nevertheless, improvement appears when recall is aided by cues. Visuospatial difficulties are also part of the disease, seen for example when the individual is asked to perform tests of facial recognition and perception of the orientation of drawn lines. A person with PD has two to six times the risk of dementia compared to the general population.|$|E
40|$|We use {{a method}} similar to Google's PageRank {{procedure}} to rank {{banks in the}} Canadian Large Value Transfer System (LVTS). Along the way we obtain estimates of the payment <b>processing</b> <b>speeds</b> for the individual banks. These differences in <b>processing</b> <b>speeds</b> are essential for explaining why observed daily distributions of liquidity differ from the initial distributions, which {{are determined by the}} credit limits selected by banks. Payment, clearing, and settlement systems...|$|R
40|$|AbstractWe have {{developed}} various industrial transparent material scribing processes and a laser tool, picosecond MHz-range all- fiber laser X-Lase CoreScriber. The remarkably high peak power, exceptionally good beam quality, and integrability of the X-Lase CoreScriber combined with high achievable material <b>processing</b> <b>speeds</b> provide tempting solutions for high- precision glass processing. Here presented sapphire and Gorilla glass dicing processes {{are based on}} transparent material internal modification with short and intense high repetition rate ps-laser pulses. Increased <b>processing</b> <b>speeds</b> and cutting qualities in comparison to other conventional processing methods are presented...|$|R
30|$|A better {{understanding}} of the thermal behavior of polymers in this regime would be beneficial. One important industrial example is the computer-to-plate process for printing plates. In this step of the offset printing process, the computer generated information are transferred to a physical image on the printing plate by microsecond laser pulses. The functional coating for such an application mainly consists of polymers. Faster <b>processing</b> <b>speeds</b> and thus shorter illumination times are required in order to speed up the overall process in particular in newspaper printing. Related with faster <b>processing</b> <b>speeds</b> are shorter illumination and thus reaction times.|$|R
5|$|Limited {{computer}} power: There was {{not enough}} memory or <b>processing</b> <b>speed</b> to accomplish anything truly useful. For example, Ross Quillian's successful work on natural language was demonstrated with a vocabulary of only twenty words, because {{that was all that}} would fit in memory. Hans Moravec argued in 1976 that computers were still millions of times too weak to exhibit intelligence. He suggested an analogy: artificial intelligence requires computer power {{in the same way that}} aircraft require horsepower. Below a certain threshold, it's impossible, but, as power increases, eventually it could become easy. With regard to computer vision, Moravec estimated that simply matching the edge and motion detection capabilities of human retina in real time would require a general-purpose computer capable of 109 operations/second (1000 MIPS). As of 2011, practical computer vision applications require 10,000 to 1,000,000 MIPS. By comparison, the fastest supercomputer in 1976, Cray-1 (retailing at $5 million to $8 million), was only capable of around 80 to 130 MIPS, and a typical desktop computer at the time achieved less than 1 MIPS.|$|E
25|$|<b>Processing</b> <b>speed.</b> Adolescents {{think more}} quickly than children. <b>Processing</b> <b>speed</b> {{improves}} sharply between age five and middle adolescence; it then begins to level off at age 15 and {{does not appear to}} change between late adolescence and adulthood.|$|E
25|$|<b>Processing</b> <b>speed</b> (Gs) is {{the ability}} to perform {{automatic}} cognitive tasks, particularly when measured under pressure to maintain focused attention.|$|E
5000|$|The SP0 and SP0-S are {{produced}} by Aitech Defense Systems is a 3U cPCI SBC which utilizes the SOI PowerQUICC-III MPC8548E capable of <b>processing</b> <b>speeds</b> ranging from 833 MHz to 1.18 GHz. http://www.rugged.com/sp0-3u-compactpci-radiation-tolerant-powerpc%C2%AE-sbc ...|$|R
50|$|IncrediBots allows {{movement}} in a two-dimensional plane, {{in which the}} bottom of the user's screen is the gravitational 'down'. Although this lack of a third dimension can be limiting, it allows for much easier construction and faster <b>processing</b> <b>speeds.</b>|$|R
5000|$|GNP {{does not}} {{distinguish}} between qualitative improvements {{in the state of}} the technical arts (e.g., increasing computer <b>processing</b> <b>speeds),</b> and quantitative increases in goods (e.g., number of computers produced), and considers both to be forms of [...] "economic growth".|$|R
25|$|Introduced in January 2017, the G6 model adds {{an updated}} Garmin Perspective-Plus flight deck with a 10-times faster <b>processing</b> <b>speed,</b> and new LED wingtip lights.|$|E
25|$|The Garmin Perspective-Plus {{avionics}} {{flight deck}} {{was introduced in}} 2017, with a faster <b>processing</b> <b>speed,</b> animated datalink weather, payload management, visual approach capabilities, wireless database uploads and more.|$|E
25|$|Speed of {{processing}} is another theory {{that has been}} raised to explain working memory deficits. As a result of various studies he has completed examining this topic, Salthouse argues that as we age our speed {{of processing}} information decreases significantly. It is this decrease in <b>processing</b> <b>speed</b> that is then responsible for our inability to use working memory efficiently as we age. The younger persons brain is able to obtain and process information at a quicker rate which allows for subsequent integration and manipulation needed to complete the cognitive task at hand. As this processing slows, cognitive tasks that rely on quick <b>processing</b> <b>speed</b> then become more difficult.|$|E
50|$|High {{hardware}} {{costs and}} relatively slow <b>processing</b> <b>speeds</b> forced developers to use resources 'efficiently'. Data storage formats were heavily compacted, for example. A common {{example is the}} removal of the century from dates, which eventually led to the 'millennium bug'.|$|R
40|$|The {{increasing}} {{popularity of}} the Internet stimulates an explosive growth of the data transmitted on the Internet {{as well as the}} dramatic increase of the transmission speeds. As a result, the TCP/IP processing has become a bottleneck. Traditional software-based TCP/IP processing on general-purpose processors (GPPs) is no longer able to keep pace with network wire speeds. Consequently, there is an urgent need to design performance-critical TCP/IP functions as special functional units to accelerate the <b>processing</b> <b>speeds</b> and to offload the processing tasks from GPPs. Such functional units performing micro-level functions can be implemented on field-programmable gate arrays (FPGAs). FPGAs as programmable hardware devices are particularly suitable to encompass both high <b>processing</b> <b>speeds</b> and flexibility to meet the quickly changing Internet. In this thesis, an in-depth survey o...|$|R
40|$|We {{consider}} {{a cluster of}} heterogeneous servers, modeled as $M/G/ 1 $ queues with different <b>processing</b> <b>speeds.</b> The scheduling policies for these servers can be either processor-sharing or first-come first-serve. Furthermore, a dispatcher that assigns jobs to the servers takes as input only {{the size of the}} arriving job and the overall job-size distribution. This general model captures the behavior of a variety of real systems, such as web server clusters. Our goal is to identify assignment strategies that the dispatcher can perform to minimize expected completion time and waiting time. We show that there exist optimal strategies that are deterministic, fixing the server to which jobs of particular sizes are always sent. We prove that the optimal strategy for systems with identical servers assigns a non-overlapping interval range of job sizes to each server. We then prove that when server <b>processing</b> <b>speeds</b> differ, it is necessary to assign each server a distinct set of intervals of job sizes in order to minimize expected waiting or response times. We explore some of the practical challenges of identifying the optimal strategy, and also study a related problem that uses our model of how to provision server <b>processing</b> <b>speeds</b> to minimize waiting and completion time given a job size distribution and fixed aggregate processing power...|$|R
25|$|The Cattell–Horn–Carroll theory {{includes}} creativity as {{a subset}} of intelligence. Specifically, it {{is associated with the}} broad group factor of long-term storage and retrieval (Glr). Glr narrow abilities relating to creativity include: ideational fluency, associational fluency, and originality/creativity. Silvia et al. conducted a study to look at the relationship between divergent thinking and verbal fluency tests, and reported that both fluency and originality in divergent thinking were significantly affected by the broad level Glr factor. Martindale extended the CHC-theory {{in the sense that it}} was proposed that those individuals who are creative are also selective in their <b>processing</b> <b>speed</b> Martindale argues that in the creative process, larger amounts of information are processed more slowly in the early stages, and as the individual begins to understand the problem, the <b>processing</b> <b>speed</b> is increased.|$|E
25|$|A 2013 {{meta-analysis}} confirmed {{people with}} OCD to have mild but wide-ranging cognitive deficits; significantly regarding spatial memory, {{to a lesser}} extent with verbal memory, fluency, executive function and <b>processing</b> <b>speed,</b> while auditory attention was not significantly affected. People with OCD show impairment in formulating an organizational strategy for coding information, set-shifting, motor and cognitive inhibition.|$|E
25|$|There is data {{supporting}} high-performing late learners {{well beyond}} the critical period: in an experiment testing grammaticality by J. L. McDonald, 7/50 L2 English late-learner subjects had scores within range of native speakers. The results are linked to how individual differences in L2 memory capacity, decoding, or <b>processing</b> <b>speed</b> affect processing resources to automatically apply the relevant grammatical knowledge.|$|E
40|$|In {{a number}} of studies, Kail (1986. 1988 a, 1992) has shown that {{estimates}} of young children’s information <b>processing</b> <b>speeds</b> {{using a variety of}} tasks and task conditions (that invoke many different processes) are perfectly correlated with older children’s <b>processing</b> <b>speeds.</b> Kail has argued that this supports the view that changes in speeded task performance are due to a single global factor that influences all processes. In this paper, I challenge this claim by simulating the consequences of using specific developmental functions (for different processors) or estimated processing times for children of different ages. The simulations demonstrate that Kail’s correlational technique is insensitive to differences in underlying developmental functions. Further, the correlational technique is sensitive, unfortunately, to arbitrary differences in the experimental designs used to gather the data...|$|R
40|$|This thesis {{presents}} the Ultra Low Voltage Dual Rail (ULVDR) logic style, a technology aimed at achieving high <b>processing</b> <b>speeds</b> at low supply voltage. Implementations of ULVDR inverters, NAND/NOR gates, XOR gates, and adders are shown. Useful simulations, principles, and guidelines for creating ULVDR circuits are introduced. When compared to equivalent circuits implemented in Cascode Voltage Switch Logic (CVSL), the ULVDR NAND gates were 57 times faster, ULVDR XOR gates were 28 times faster, and the ULVDR full-adder was 52 times faster. Simulations were done on long chains (30 - 32 elements) using a supply voltage of 300 mV. The {{increase in speed}} can enable new types of applications, where high <b>processing</b> <b>speeds</b> are essential, or allow lower power consumption by further decreasing supply voltage or putting circuits to sleep when done processing...|$|R
40|$|Recently, {{economists have}} argued that a bank's {{importance}} within the financial system depends not only on its individual characteristics but also on its position within the banking network. A bank is deemed to be "central" if, based on our network analysis, it is predicted to hold the most liquidity. In this paper, we use a method similar to Google's PageRank procedure to rank banks in the Canadian Large Value Transfer System (LVTS). In doing so, we obtain estimates of the payment <b>processing</b> <b>speeds</b> for the individual banks. These differences in <b>processing</b> <b>speeds</b> are essential for explaining why observed daily distributions of liquidity differ from the initial distributions, which {{are determined by the}} credit limits selected by banks. Banks and banking, Central; Banks and banking; Liquidity (Economics); Electronic funds transfers...|$|R
25|$|This test is {{considered}} to measure selective attention, cognitive flexibility and <b>processing</b> <b>speed,</b> and it {{is used as a}} tool in the evaluation of executive functions. An increased interference effect is found in disorders such as brain damage, dementias and other neurodegenerative diseases, attention-deficit hyperactivity disorder, or a variety of mental disorders such as schizophrenia, addictions, and depression.|$|E
25|$|Furthermore, {{there seems}} to be a {{trade-off}} between the noise in gene expression, the speed with which genes can switch, and the metabolic cost associated their functioning. More specifically, for any given level of metabolic cost, there is an optimal trade-off between noise and <b>processing</b> <b>speed</b> and increasing the metabolic cost leads to better speed-noise trade-offs.|$|E
25|$|In {{establishing}} a causal direction to {{the link between}} IQ and work performance, longitudinal studies by Watkins and others suggest that IQ exerts a causal influence on future academic achievement, whereas academic achievement does not substantially influence future IQ scores. Treena Eileen Rohde and Lee Anne Thompson write that general cognitive ability, but not specific ability scores, predict academic achievement, with the exception that <b>processing</b> <b>speed</b> and spatial ability predict performance on the SAT math beyond the effect of general cognitive ability.|$|E
40|$|Recently, we have {{witnessed}} dramatic improvements in <b>processing</b> <b>speeds</b> and visualization displays. Yet input devices {{for the most part}} have lagged behind, presenting a bottleneck in applications that require a human operator in the processing loop. In this paper a review of vision-based hand gestures for human computer interaction is presented...|$|R
40|$|Abstract—The {{range of}} {{verification}} {{problems that can}} be solved with logic model checking tools has increased significantly {{in the last few}} decades. This increase in capability is based on algorithmic advances and new theoretical insights, but it has also benefitted from the steady increase in <b>processing</b> <b>speeds</b> and main memory sizes on standard computers. The steady increase in <b>processing</b> <b>speeds,</b> though, ended when chip-makers started redirecting their efforts to the development of multi-core systems. For the near-term future, we can anticipate the appearance of systems with large numbers of CPU cores, but without matching increases in clockspeeds. We will describe a model checking strategy that can allow us to leverage this trend, and that allows us to tackle significantly larger problem sizes than before. Index Terms—software engineering tools and techniques, logic model checking, distributed algorithms, software verification...|$|R
2500|$|Detectors {{used for}} {{wavelength}} dispersive spectrometry {{need to have}} high pulse <b>processing</b> <b>speeds</b> in order {{to cope with the}} very high photon count rates that can be obtained. In addition, they need sufficient energy resolution to allow filtering-out of background noise and spurious photons from the primary beam or from crystal fluorescence. There are four common types of detector: ...|$|R
25|$|Beside the {{above-mentioned}} views on computer vision, {{many of the}} related research topics can also be studied from a purely mathematical point of view. For example, many methods in computer vision are based on statistics, optimization or geometry. Finally, {{a significant part of}} the field is devoted to the implementation aspect of computer vision; how existing methods can be realized in various combinations of software and hardware, or how these methods can be modified in order to gain <b>processing</b> <b>speed</b> without losing too much performance.|$|E
25|$|People with {{executive}} dysfunction have {{a slower}} cognitive <b>processing</b> <b>speed</b> and thus often {{take longer to}} complete tasks than people who demonstrate typical executive function capabilities. This can be frustrating for the individual and can serve to impede academic progress. Disorders affecting children such as ADHD, along with oppositional defiant disorder, conduct disorder, high functioning autism and Tourette’s syndrome have all been suggested to involve executive functioning deficits. The main focus of current research has been on working memory, planning, set shifting, inhibition, and fluency. This research suggests that differences exist between typically functioning, matched controls and clinical groups, on measures of executive functioning.|$|E
25|$|The rate {{at which}} {{different}} qualities are detected in first impressions {{may be linked to}} what has been important to survival from an evolutionary perspective. For example, trustworthiness and attractiveness were the two traits most quickly detected and evaluated in a study of human faces. People are fairly good at assessing personality traits of others in general, but {{there appears to be a}} difference in first impression judgments between older and younger adults. Older adults judged young adult target photos as healthier, more trustworthy, and less hostile, but more aggressive, than younger adults did of the same photos. Older adults could have a lower response to negative cues due to a slower <b>processing</b> <b>speed,</b> causing them to see facial features on young adults as more positive than younger adults do.|$|E
40|$|We {{report the}} first {{realization}} of integrated, all-optical first- and higher-order photonic differentiators operating at terahertz (THz) <b>processing</b> <b>speeds.</b> This is accomplished in a Silicon-on-Insulator (SOI) CMOS-compatible platform using a simple integrated geometry based on (π-) phase-shifted Bragg gratings. Moreover, we achieve on-chip generation of sub-picosecond Hermite-Gaussian pulse waveforms, which are noteworthy for applications in next-generation optical telecommunications...|$|R
50|$|Development of MUSE—a name {{derived from}} {{microsecond}} engine—began at Manchester University in 1956. The {{aim was to}} build a computer that could operate at <b>processing</b> <b>speeds</b> approaching one microsecond per instruction, about one million instructions per second. The prefix micro- (abbreviation µ) in the SI or International System of Units denotes a factor of 10−6 (one millionth).|$|R
40|$|In modern society, time {{is arguably}} the most {{precious}} commodity and it motivates us to look for ways of doing things faster. This is particularly true in the electronics industry where increasing <b>processing</b> <b>speeds</b> has been a never-ending goal. However, the result of this high-speed quest has been an attendant increase in power which raises a new concer...|$|R
