2675|65|Public
5|$|The navy {{sees the}} battleships as <b>prohibitively</b> <b>expensive,</b> {{and is working}} to persuade Congress {{to allow it to}} remove Iowa and Wisconsin from the Naval Vessel Register by {{developing}} extended-range guided munitions and a new ship to fulfill marine corps requirements for naval surface fire support (NSFS).|$|E
5|$|Between 1918 and 1922, over 350 Percherons were {{imported}} to Britain from France and, {{combined with}} stock from the US and Canada, {{were used as}} breeding stock to establish the breed in the country. In 1918, the British Percheron Horse Society was formed. British breeders and owners continue to import Percherons from France, and also occasionally from Canada, when not <b>prohibitively</b> <b>expensive.</b>|$|E
5|$|ACC teams viewed a {{berth in}} the Humanitarian Bowl as {{undesirable}} due to its location. Aside from {{being one of the}} lower priority tie-ins, the destination is far outside the conference's geographic footprint. Travel costs from the East Coast are <b>prohibitively</b> <b>expensive</b> and historically caused low turnout among ACC fans. In addition, the game is hosted at a cold-weather venue, which is a disadvantage in comparison with ACC bowl games in places such as Florida, California, and Georgia.|$|E
50|$|In practice, AAD was {{uncommon}} and DAD {{was very}} rare, as many companies (especially the well-known classical music labels) used digital tape recorders (which was not <b>prohibitively</b> more <b>expensive</b> than analog tape recorders) during the editing or mixing stage.|$|R
50|$|Wider {{adoption}} of hydrofoils is prevented by the increased complexity of building and maintaining them. Hydrofoils are generally <b>prohibitively</b> more <b>expensive</b> than conventional watercraft. However, {{the design is}} simple enough {{that there are many}} human-powered hydrofoil designs. Amateur experimentation and development of the concept is popular.|$|R
50|$|N-body {{simulations}} {{are simple}} in principle, because they merely involve integrating the 6N ordinary differential equations defining the particle motions in Newtonian gravity. In practice, the number N of particles involved is usually very large (typical simulations include many millions, the Millennium simulation included ten billion) {{and the number}} of particle-particle interactions needing to be computed increases on the order of N2, and so direct integration of the differential equations can be <b>prohibitively</b> computationally <b>expensive.</b> Therefore, a number of refinements are commonly used.|$|R
5|$|Materials for {{building}} the Shrine were sourced from within Australia: the chosen building stone was granodiorite quarried from Tynong; the internal walls use sandstone from Redesdale; {{and the black}} marble columns used stone from Buchan. This raised some concerns when redeveloping the Shrine, as the Tynong quarry {{was no longer in}} use, and it proved to be <b>prohibitively</b> <b>expensive</b> to reopen the site. Fortunately another quarry in the area was available and was able to provide the necessary stone.|$|E
5|$|Sonic & Knuckles was {{developed}} at the Sega Technical Institute by members of Sonic Team in the United States. It and Sonic 3 were originally planned as a single game; due to time constraints and the <b>prohibitively</b> <b>expensive</b> manufacturing costs of a cartridge with more memory, Sega split the game in half, with Sonic & Knuckles as {{the second part of}} the Sonic 3 story.|$|E
5|$|Jerry Goldsmith had {{composed}} {{the music for}} The Motion Picture, but {{was not an option}} for The Wrath of Khan given the reduced budget; Meyer's composer for Time After Time, Miklós Rózsa, was likewise <b>prohibitively</b> <b>expensive.</b> Bennett and Meyer wanted the music for the film to go in a different direction, but had not decided on a composer by the time filming began. Meyer initially hoped to hire an associate named John Morgan, but Morgan lacked film experience, which would have troubled the studio.|$|E
5|$|Multiple {{sequence}} alignment also {{refers to}} the process of aligning such a sequence set. Because three or more sequences of biologically relevant length can be difficult and are almost always time-consuming to align by hand, computational algorithms are used to produce and analyze the alignments. MSAs require more sophisticated methodologies than pairwise alignment because they are more computationally complex. Most multiple sequence alignment programs use heuristic methods rather than global optimization because identifying the optimal alignment between more than a few sequences of moderate length is <b>prohibitively</b> computationally <b>expensive.</b>|$|R
40|$|With {{the advent}} of {{nanoscale}} technologies, even RTL and system designers must consider interconnect analysis to provide predictable performance, reliability and meet power budgets. However, system-wide modeling of high-speed interconnects using conventional circuit simulators such as SPICE can become <b>prohibitively</b> CPU <b>expensive.</b> We propose to formulate analytical interconnect macromodels capturing noise effects, and to integrate them into the SystemC communication abstractions. Experimental results show that HDL simulations achieve an average accuracy of 5 % from SPICE, while a few case studies illustrate {{the applicability of the}} proposed framework for fast exploration of physical channel configuration and performance estimation...|$|R
50|$|Because cloud {{computing}} is still relatively new, standards {{are still being}} developed. Many cloud platforms and services are proprietary, meaning that they are built on the specific standards, tools and protocols developed by a particular vendor for its particular cloud offering. This can make migrating off a proprietary cloud platform <b>prohibitively</b> complicated and <b>expensive.</b>|$|R
5|$|The {{transporter}} {{had originally}} been developed for the television series {{as a matter of}} convenience; it would have been <b>prohibitively</b> <b>expensive</b> to show the Enterprise land on every new planet. For the redesign Michelson felt that the transporter should look and feel more powerful. He added a sealed control room that would protect operators from the powerful forces at work. The space between the transporter platform and the operators was filled with complex machinery, and cinematographer Richard Kline added eerie lighting to the set to create atmosphere.|$|E
5|$|Sonic 3 and Sonic & Knuckles were {{originally}} planned {{as a single}} game. However, time was limited and the manufacturing costs of a 34-megabit cartridge with NVRAM would have been <b>prohibitively</b> <b>expensive.</b> Sonic Team split the game in half, giving the developers more time to finish the second part, and splitting the cost between two cartridges. The cartridge has {{a small amount of}} non-volatile RAM built into it, which allows the player to save game progress to the game cartridge. Sega planned to release a single cartridge version of both games titled Sonic the Hedgehog 3 Limited Edition, though it was eventually cancelled for unknown reasons; a prototype ROM image of this version was leaked in 2008.|$|E
5|$|Thallium {{can also}} be {{obtained}} from the smelting of lead and zinc ores. Manganese nodules found on the ocean floor contain some thallium, but the collection of these nodules has been <b>prohibitively</b> <b>expensive.</b> There is also the potential for damaging the oceanic environment. In addition, several other thallium minerals, containing 16% to 60% thallium, occur in nature as complexes of sulfides or selenides that primarily contain antimony, arsenic, copper, lead, and/or silver. These minerals are rare, and they have had no commercial importance as sources of thallium. The Allchar deposit in southern Macedonia was the only area where thallium was actively mined. This deposit still contains an estimated 500tonnes of thallium, and it is a source for several rare thallium minerals, for example lorándite.|$|E
5|$|Building a full spliced blank {{from scratch}} was an {{expensive}} and painstaking process, {{and the large}} manufacturing facilities of Brunswick turned out good quality blanks, with beautiful points, veneers and sound construction. In Balabushka's case, his entire workshop consisted of a single lathe and other woodworking equipment {{in the confines of}} his modest garage, and building his own full-splice butts would have been <b>prohibitively</b> difficult and <b>expensive</b> for him.|$|R
50|$|On February 26, 2002, Blue World {{released}} Lasso 5, {{a radical}} departure from the FileMaker-centric language to date. (There was never a Lasso 4 release; the version number skipped from 3 to 5.) Lasso 5 included, among many updates, a completely rewritten architecture (for OS X, Windows, Linux), and an embedded MySQL database. Though Lasso 5 still spoke to a FileMaker database (but not to a FileMaker Server), FileMaker as a data source remained relatively slow compared to an SQL engine, and was <b>prohibitively</b> more <b>expensive.</b> Since v2.0, Lasso was fully multithreaded, allowing many connections at once, but succumbed to FileMaker's latency or lag in certain operations, {{and there was no way}} to get around it reliably other than to make major changes to the data source.|$|R
40|$|Multi-hypothesis {{tracking}} (MHT) {{techniques can}} become <b>prohibitively</b> computationally <b>expensive</b> {{as the number}} of hypotheses increases. In order to maintain an estimate with bounded computational cost, multi-hypothesis methods often merge the estimates together. When the hypotheses are distributed according to a known probability then standard mixture reduction (SMR) methods exist for merging estimates. Also, covariance union (CU) has become a popular approach to merging hypotheses when their distribution is not known. This paper generalises CU to a new theory, which we refer to as generalised covariance union (GCU). GCU merges estimates when their distribution is not known precisely but is, instead, bounded above and below. We show that CU and the SMR approaches are limiting cases of GCU. We demonstrate the efficacy of the new approach via a Global Positioning System (GPS) tracking application with time delayed satellite signals. © 2006 IEEE...|$|R
5|$|The {{number of}} Class C retail {{licenses}} for bars, restaurants, and liquor stores {{is limited by}} population and often by municipal ordinances. Licenses are typically obtained from existing licensees who choose to sell, or when a new license is offered as a town's population grows. As a result, the price for a retail license is often <b>prohibitively</b> <b>expensive.</b> The sale of a new license is usually conducted by public auction. The intense competition can benefit a town by generating {{several hundred thousand dollars}} of revenue from the highest bidder. A 2006 license auction in Cherry Hill, New Jersey set the state record at $1.5 million.|$|E
5|$|In 1935, Wolf Klaphake and {{his wife}} Maria emigrated to Australia. The Klaphakes' {{decision}} to emigrate was probably primarily the result of Maria's encounters with Nazi authorities; their decision to settle in Australia (rather than, say, in Britain) was influenced by Wolf's desire to develop a dew condenser. As a dry continent, Australia was likely to need alternative sources of fresh water, and the Premier of South Australia, whom he had met in London, had expressed an interest. Klaphake made a specific proposal for a condenser at {{the small town of}} Cook, where there was no supply of potable water. At Cook, the railway company had previously installed a large coal-powered active condenser, but it was <b>prohibitively</b> <b>expensive</b> to run, and it was cheaper to simply transport water. However, the Australian government turned down Klaphake's proposal, and he lost interest in the project.|$|E
5|$|One of Tolkien's least-known short {{works is}} the children's storybook Mr. Bliss, {{published}} in 1982. It {{tells the story}} of Mr. Bliss and his first ride in his new motor-car. Many adventures follow: encounters with bears, angry neighbours, irate shopkeepers, and assorted collisions. The story was inspired by Tolkien's own vehicular mishaps with his first car, purchased in 1932. The bears were based on toy bears owned by Tolkien's sons. Tolkien was both author and illustrator of the book. He submitted it to his publishers as a balm to readers who were hungry for more from him after the success of The Hobbit. The lavish ink and coloured-pencil illustrations would have made production costs <b>prohibitively</b> <b>expensive.</b> Tolkien agreed to redraw the pictures in a simpler style, but then found he did not have time to do so. The book was published in 1982 as a facsimile of Tolkien's difficult-to-read illustrated manuscript, with a typeset transcription on each facing page.|$|E
40|$|Inferring model {{parameters}} from {{experimental data}} {{is a grand}} challenge in many sciences, including cosmology. This often relies critically on high fidelity numerical simulations, which are <b>prohibitively</b> computationally <b>expensive.</b> The application of deep learning techniques to generative modeling is renewing interest in using high dimensional density estimators as computationally inexpensive emulators of fully-fledged simulations. These generative models {{have the potential to}} make a dramatic shift in the field of scientific simulations, but for that shift to happen we need to study the performance of such generators in the precision regime needed for science applications. To this end, in this letter we apply Generative Adversarial Networks to the problem of generating cosmological weak lensing convergence maps. We show that our generator network produces maps that are described by, with high statistical confidence, the same summary statistics as the fully simulated maps. Comment: 8 pages, 5 figure...|$|R
40|$|The {{situation}} frequently arises where {{working with}} the likelihood function is problematic. This can happen for several reasons [...] -perhaps the likelihood is <b>prohibitively</b> computationally <b>expensive,</b> perhaps it lacks some robustness property, or perhaps {{it is simply not}} known for the model under consideration. In these cases, it is often possible to specify alternative functions of the parameters and the data that can be maximized to obtain asymptotically normal estimates. However, these scenarios present obvious problems if one is interested in applying Bayesian techniques. Here we describe open-faced sandwich adjustment, a way to incorporate a wide class of non-likelihood objective functions within Bayesian-like models to obtain asymptotically valid parameter estimates and inference via MCMC. Two simulation examples show that the method provides accurate frequentist uncertainty estimates. The open-faced sandwich adjustment is applied to a Poisson spatio-temporal model to analyze an ornithology dataset from the citizen science initiative eBird...|$|R
40|$|The {{problem of}} {{efficient}} implementation {{of an object}} tracking algorithm for the multi-static frequency-modulated continuous-wave (FM-CW) collision avoidance radar is addressed in the paper. The task of the algorithm is to construct the image of target locations from multiple peak sets that represent radial distances of the targets from the antenna system. Evaluating all possible peak combinations in every sweep would be <b>prohibitively</b> computationally <b>expensive,</b> considering the real-time requirements of the system. Instead, an incremental approach is proposed, where the combinations are evaluated only for the new peaks, while the peaks that were already associated with a target are only checked for validity [...] - this makes the operation {{an order of magnitude}} cheaper. 1. Introduction Colarado (Collision Avoidance Radar) is a multistatic frequency-modulated continuous wave (FMCW) radar system developed for use in the control system of an autonomous vehicle. The aim of the system is to find [...] ...|$|R
5|$|The {{tracks of}} this station {{continue}} {{south of the}} station, down to 25th Street, to allow trains to be stored south of the station during off-peak hours; the tail tracks are seven blocks long, enough to store two 11-car trains each, since the delivery of the R188 train cars was to add 66 more cars to the fleet of the 7 service. There are also two diamond crossovers, one north and one south of the station. The storage tracks at this location were constructed due to the Corona Yard in Queens lacking any space to hold any more trains, and expanding the yard is very difficult due to its location next to the Flushing River. A new storage yard elsewhere would be <b>prohibitively</b> <b>expensive,</b> as it would cost {{hundreds of millions of}} dollars.|$|E
5|$|Some bootlegs {{consist of}} private or {{professional}} studio recordings distributed without the artist's involvement, including demos, works-in-progress or discarded material. These {{might be made}} from private recordings {{not meant to be}} widely shared, or from master recordings stolen or copied from an artist's home, a recording studio or the offices of a record label, or they may be copied from promotional material issued to music publishers or radio stations, but not for commercial release. A theme of early rock bootlegs was to copy deleted records, such as old singles and B-sides, onto a single LP, as a cheaper alternative to obtaining all the original recordings. Strictly speaking, these were unlicensed recordings, but because the work required to clear all the copyrights and publishing of every track for an official release was considered to be <b>prohibitively</b> <b>expensive,</b> the bootlegs became popular. Some bootlegs, however, did lead to official releases. The Who's Zoo bootleg, collecting early singles of The Who, inspired the official album Odds And Sods, which beat the bootleggers by issuing unreleased material, while various compilations of mid-1960s bands inspired the Nuggets series of albums.|$|E
25|$|On 28 November 2012, {{following}} {{concerns that}} small loans, {{intended to be}} short-term, could become <b>prohibitively</b> <b>expensive,</b> the government announced it would give the Financial Conduct Authority powers to prevent indefinite rolling over of loans and effectively limit charges.|$|E
40|$|Despite {{incredible}} {{recent advances}} in machine learning, building machine learning applications remains <b>prohibitively</b> time-consuming and <b>expensive</b> {{for all but the}} best-trained, best-funded engineering organizations. This expense comes not from a need for new and improved statistical models but instead from a lack of systems and tools for supporting end-to-end machine learning application development, from data preparation and labeling to productionization and monitoring. In this document, we outline opportunities for infrastructure supporting usable, end-to-end machine learning applications {{in the context of the}} nascent DAWN (Data Analytics for What's Next) project at Stanford...|$|R
40|$|We {{describe}} an algebraic technique for performing timing analysis on a restricted class of Petri nets with interval time delays specified on the places of the net. The timing analysis we perform determines the extreme separation in time between specified occurrences of pairs of transitions for all possible timed executions of the system. We present {{the details of}} the timing analysis algorithm and demonstrate polynomial running time on a non-trivial parameterized example. Petri nets with 3000 nodes and 10 16 reachable states have been analyzed using these techniques. 1 Introduction The majority of research involving the formal analysis of temporal issues in concurrent systems has focused on powerful models of concurrency and these techniques are therefore often <b>prohibitively</b> computationally <b>expensive.</b> This paper takes the approach of using a less expressive model of a concurrent system in favor of a more efficient analysis. Our model of a concurrent system is based on safe Petri ne [...] ...|$|R
40|$|One of {{the most}} {{attractive}} recent approaches to processing well-structured large-scale convex optimization problems is based on smooth convex-concave saddle point reformulation {{of the problem of}} interest and solving the resulting problem by a fast first order saddle point method utilizing smoothness of the saddle point cost function. In this paper, we demonstrate that when the saddle point cost function is polynomial, the precise gradients of the cost function required by deterministic first order saddle point algorithms and becoming <b>prohibitively</b> computationally <b>expensive</b> in the extremely large-scale case, can be replaced with incomparably cheaper computationally unbiased random estimates of the gradients. We show that for large-scale problems with favorable geometry, this randomization accelerates, progressively as the sizes of the problem grow, the solution process. This extends significantly previous results on acceleration by randomization, which, {{to the best of our}} knowledge, dealt solely with bilinear saddle point problems. We illustrate our theoretical findings by instructive and encouraging numerical experiments...|$|R
25|$|Economic– Where pumping gas {{to shore}} can be <b>prohibitively</b> <b>expensive,</b> FLNG makes {{development}} economically viable. As a result, {{it will open}} up new business opportunities for countries to develop offshore gas fields that would otherwise remain stranded, such as those offshore East Africa.|$|E
25|$|Route {{coverage}} {{might have}} been wider still but {{the terms of the}} 1870 Act meant that the passage of new tramways had to be negotiated individually with local authorities, who would sometimes impose <b>prohibitively</b> <b>expensive</b> improvement works as a condition of approval.|$|E
25|$|Jonathan Powell, {{producer}} of Tinker, Tailor, Soldier, Spy (1979), said the BBC considered producing The Honourable Schoolboy but a production in South East Asia was considered <b>prohibitively</b> <b>expensive</b> {{and therefore the}} BBC instead adapted the third novel of the Karla Trilogy Smiley's People (1979) which was transmitted in 1982.|$|E
40|$|As {{data sets}} {{continue}} to grow in size and complexity, effective and efficient techniques are needed to target important features in the variable space. Many of the variable selection techniques that are commonly used alongside clustering algorithms are based upon determining the best variable subspace according to model fitting in a stepwise manner. These techniques are often computationally intensive and can require {{extended periods of time}} to run; in fact, some are <b>prohibitively</b> computationally <b>expensive</b> for high-dimensional data. In this paper, a novel variable selection technique is introduced for use in clustering and classification analyses that is both intuitive and computationally efficient. We focus largely on applications in mixture model-based learning, but the technique could be adapted for use with various other clustering/classification methods. Our approach is illustrated on both simulated and real data, highlighted by contrasting its performance with that of other comparable variable selection techniques on the real data sets...|$|R
40|$|Variable {{selection}} {{techniques have}} become increasingly popular amongst statisticians due to an increased number of regression and classification applications involving high-dimensional data where we expect some predictors to be unimportant. In this context, Bayesian variable selection techniques involving Markov chain Monte Carlo exploration of the posterior distribution over models can be <b>prohibitively</b> computationally <b>expensive</b> and so there has been attention paid to quasi-Bayesian approaches such as maximum a poste-riori (MAP) estimation using priors that induce sparsity in such estimates. We focus on this latter approach, expanding on the hierarchies proposed to date to provide a Bayesian interpretation and generalization of state-of-the-art penalized optimization approaches and providing simultaneously a natural way to include prior information about parameters within this framework. We give examples of how to use this hierarchy to compute MAP estimates for linear and logistic regression as well as sparse precision-matrix estimates in Gaussian graphical models. In addition, an adaptive group lasso method is derived using the frame-work. ...|$|R
40|$|The {{optimisation}} of predicted control {{policies in}} model predictive control (MPC) enables {{the use of}} information on uncertainty that, though not available at current time, will be so at a future point on the prediction horizon. Optimisation over feedback laws is however <b>prohibitively</b> computationally <b>expensive.</b> The so-called affine-in-the-disturbance strategies provide a compromise and this article considers the use of disturbance compensation in the context of stochastic MPC. Unlike the earlier approaches, compensation here is applied over the entire prediction horizon (extending to infinity) thereby leading to a significant constraint relaxation which makes more control authority available for the optimisation of performance. In addition, our compensation has a striped lower triangular dependence on the uncertainty on account of which the relevant gains can be obtained sequentially, thereby reducing computational complexity. Further reduction in computation is achieved by performing this computation offline. Simulation results show that this reduction can be gained at a negligible cost in terms of closed-loop performance. © 2013 Taylor and Francis Group, LLC...|$|R
