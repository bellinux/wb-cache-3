315|8977|Public
25|$|Discretization is {{typically}} achieved by sampling the Gaussian filter kernel at discrete points, normally at positions {{corresponding to the}} midpoints of each pixel. This reduces the computational cost but, for very small filter kernels, <b>point</b> <b>sampling</b> the Gaussian function with very few samples leads to a large error. In these cases, accuracy is maintained (at a slight computational cost) by integration of the Gaussian function over each pixel's area.|$|E
5000|$|<b>Point</b> <b>sampling,</b> bi-linear sampling, tri-linear filtering, and cubic textures ...|$|E
50|$|Nearest-neighbor {{interpolation}} (also {{known as}} proximal interpolation or, in some contexts, <b>point</b> <b>sampling)</b> {{is a simple}} method of multivariate interpolation {{in one or more}} dimensions.|$|E
40|$|The primary {{objective}} of the research reported in this thesis is to develop new techniques for dense <b>point</b> <b>sampled</b> surface models that directly work on the <b>point</b> <b>samples.</b> Rather than using a deterministic approach, our techniques use a statistical approach of associating properties with points based {{on the distribution of}} the <b>point</b> <b>samples</b> in a local neighborhood. Based on this research, our main thesis can be stated as follows: We can classify points using the statistical techniques of principal component analysis (PCA) into different categories such as flat, corner, crease and border. This classification can then be used to devise efficient techniques for processing such dense <b>point</b> <b>sampled</b> models. Specifically we have developed and tested new techniques for efficient rendering and reverse engineering the boundary representation of such dense <b>point</b> <b>sampled</b> models. Rendering efficiency is considerably improved by using stochastic sampling that is controlled using various model features and view dependent image space properties. (Abstract shortened by UMI. ...|$|R
40|$|We {{present a}} novel multi-resolution <b>point</b> <b>sample</b> {{rendering}} algorithm for keyframe animations. The algorithm accepts triangle meshes of arbitrary topology as input which are animated by specifying {{different sets of}} vertices at keyframe positions. A multi-resolution representation consisting of prefiltered <b>point</b> <b>samples</b> and triangles is built to represent the animated mesh {{at different levels of}} detail. We introduce a novel sampling and stratification algorithm to efficiently generate suitable <b>point</b> <b>sample</b> sets for moving triangle meshes. Experimental results demonstrate that the new data structure can be used to render highly complex keyframe animations like crowd scenes in real-time...|$|R
40|$|Evaluating {{water quality}} {{is a key}} tool in lake management. Typically water quality samples are {{restricted}} to {{a limited number of}} <b>point</b> <b>samples</b> collected in situ in the field, which can be time consuming and costly. Also, the few in situ <b>points</b> <b>sampled</b> fail to capture the spatial variability, e. g., for the large Lake Waikare (3, 400 ha; Figure. 1) ...|$|R
50|$|The Land Use Statistics are {{compiled}} {{by means of}} aerial <b>point</b> <b>sampling</b> of aerial photographs of the Federal Office of Topography. Some 4.1 million sample points at intervals of 100x100m are made.|$|E
50|$|Discretization is {{typically}} achieved by sampling the Gaussian filter kernel at discrete points, normally at positions {{corresponding to the}} midpoints of each pixel. This reduces the computational cost but, for very small filter kernels, <b>point</b> <b>sampling</b> the Gaussian function with very few samples leads to a large error. In these cases, accuracy is maintained (at a slight computational cost) by integration of the Gaussian function over each pixel's area.|$|E
50|$|It is {{a concept}} that comes from {{variable}} radius plots, or <b>point</b> <b>sampling.</b> It happens when a tree cannot be easily determined as in or out when using a prism or angle gauge. Borderline trees occur only when the distance from the sampling point {{to the center of the}} tree is equal to the DBH times plot radius factor (PRF). The PRF is determined based on the type of prism or angle gauge being used. Basal Area Factor (BAF) 5, 10, and 20 angle gauges result in PRFs of 3.89, 2.75, and 1.94 (feet inch−1) respectively. The metric equivalents of these PRFs are 0.467, 0.33, and 0.233 (m cm−1).|$|E
5000|$|... #Caption: The {{reconstruction}} of a density field from a discrete set of <b>points</b> <b>sampling</b> this field.|$|R
5000|$|... #Caption: <b>Point</b> <b>samples</b> {{generated}} using Poisson disc sampling, and {{graphical representation}} of the minimum inter-point distance ...|$|R
50|$|Finite {{difference}} method {{describes the}} unknowns {{of the flow}} problem by means of <b>point</b> <b>samples</b> at the node points of a grid co-ordinate lines. Taylor series expansions are used to generate finite difference approximations of derivatives in terms of <b>point</b> <b>samples</b> at each grid point and its immediate neighbours. Those derivatives appearing in the governing equations are replaced by finite differences yielding an algebraic equation.|$|R
50|$|The Relascope {{is often}} used for <b>point</b> <b>sampling.</b> This is done by using the set spacing marked in the Relascope to gauge whether a tree is {{in or out of}} the stand. When one says the tree is IN or OUT they mean does it fill the space between the lines on the scale in the Relascope if it does than this tree is IN if it doesn't than this tree is OUT (Figure 1). If the tree is IN this means that it is counted as basal area within one's plot. To figure out what this trees basal area is all one has to do is {{multiply}} the number of trees by the basal area factor which is based on the width of one's gauge.|$|E
50|$|Chasys Draw IES went {{freeware}} on 6 June 2009. With {{the coming}} of the freeware IES, two blending modes (Hue and Chroma) were added. Textures were improved to allow multiple layer-based textures. The TextArt G3 engine was enhanced with LINK metadata, and alpha shift was improved. IES 2.72 added the Luma Wand tool, fixed PNG and TIFF transparency issues, and fixed Smart-Paste transparency. IES 2.74 introduced alpha protection, and 2.75 followed with a new adjustments engine that faced out many effects implemented by the effects engine. The adjustments engine was designed to appeal to experienced image editors. IES 2.76 introduced a new transform engine and the Resizer for IES plug-in supporting multi-core and 18 scaling methods, including customizable windowed Sinc interpolation. IES 2.77 added Greyscale with Tint adjustment, separated the Lock and Click-Thru layer properties, extended the Cloning Brush with three options (this, below and composite) and also extended the Color Picker with multiple <b>point</b> <b>sampling.</b>|$|E
50|$|In {{the oldest}} and most popular {{sampling}} approach, the region to be covered is gridded and volunteers are expected to visit representative locations within each grid cell and gather data that is subsequently collated. The method of collecting data, time and season in which to obtain the sample information are pre-decided as part of a protocol. In some cases the numbers and species of birds that are found to be breeding are recorded, others may use timed <b>point</b> <b>sampling</b> or transects within the grid cells to obtain quantitative estimates of abundance. In some countries the grid cells follow the latitudes and longitudes - cell intervals of 1 degree, 30 and 15 minutes are often chosen for convenience. In higher latitudes where such an approaches leads to grid cells with large differences in area, sizes are more often fixed using grid distances of 1, 2, 5, 10 or even 50 km grid intervals. A disadvantage with grids is that boundaries rarely match those of habitats, making them unsuitable for ecological studies. Another problem is that the data collected in one project cannot be readily reused with new grid alignments that may be needed for instance when combining information with other projects. Repeat atlases made after a decade or two have helped in identifying long term range changes.|$|E
5000|$|<b>Sampling</b> (single <b>point,</b> all <b>points</b> without <b>sampling,</b> all <b>points</b> with {{interval}} <b>sampling),</b> ...|$|R
40|$|Abstract. From a {{sufficiently}} large <b>point</b> <b>sample</b> {{lying on a}} compact Riemannian submanifold of Euclidean space, one can construct a simplicial complex which is homotopy-equivalent to that manifold with high confidence. We describe a corresponding result for a Lipschitz-continuous function between two such manifolds. That is, we outline {{the construction of a}} simplicial map which recovers the induced maps on homotopy and homology groups with high confidence using only finite sampled data from the domain and range, as well as knowledge of the image of every <b>point</b> <b>sampled</b> from the domain. We provide explicit bounds {{on the size of the}} <b>point</b> <b>samples</b> required for such reconstruction in terms of intrinsic properties of the domain, the co-domain and the function. This reconstruction is robust to certain types of bounded sampling and evaluation noise. 1...|$|R
3000|$|... for all j, {{then each}} {{measurement}} vector we obtain {{will be a}} <b>point</b> <b>sampled</b> from the embedded manifold Φℳ ⊂ ℝ [...]...|$|R
50|$|Coloring Book is {{the third}} mixtape from Chicago artist Chance the Rapper. According to Jon Caramanica of the New York Times, Chance comes “as close as anyone has to eradicating the walls between the sacred and the secular.” At many points {{throughout}} the project, Chance connects with his deep-rooted sense of spirituality, at one <b>point</b> <b>sampling</b> Chris Tomlin’s vocals on “How Great is Our God” as an intro to the song “How Great.” Chance also refers to “blessings” on the track “Blessings”, saying, “When the praises go up, the blessings come down.” Chance goes onto the reprise of “Blessings” questioning his listeners by asking, “Are you ready for your miracle?” On a song unreleased on the album due to copyright issues entitled, “Grown Ass Kid,” Chance talks about his identity as a rapper in a largely secular industry, saying, “My favorite rapper a christian rapper.” His self given identity as a Christian rapper speaks to his major influences from religion, mainly stemming from his connection to Kanye West, both as believers of Christianity, and Chicago Natives. In Jon Caramanica’s same New York Times article, he speaks on the identity Chance has created for himself. “The pop song is the praise song.” Chance the Rapper has introduced his style of heavy religious themes, and turned them into songs that many have listened to and enjoyed, as it received 4 stars from Rolling Stone, a 9.1/10 on Pitchfork, and a rating of XL on XXL.|$|E
50|$|The {{framework}} {{proposed in}} this method by Soonmin Hwang et al., is split into four steps. First, {{the data from}} the camera and 3D lidar is input into to the system. Both inputs from lidar and camera are parallelly obtained and the color image from the camera is calibrated with the lidar. To improve the efficiency, horizontal 3D <b>point</b> <b>sampling</b> is applied as pre-processing. Second, the segmentation stage is where the entire 3D points are divided into several groups per the distance from the sensor and local planes from close plane to far plane are sequentially estimated. The local planes are estimated using statistical analysis. The group of points closer to the sensor are used to compute the initial plane. By using the current local plane, the next local plane is estimated by iterative update. The object proposals in the 2D image are used to separate foreground objects from background. For faster and accurate detection and tracking Binarized Normed Gradients for Objectness Estimation at 300fps is used. BING is a combination of normed gradient and its binarized version which speeds up the feature extraction and testing process, to estimate the objectness of an image window. This way the foreground and background objects are separated. To form objects after estimating the objectness of an image using BING, the 3D points are grouped or clustered. Clustering is done using DBSCAN (Density-Based Spatial Clustering of Applications with Noise) algorithm which could be robust due to its less-parametric characteristic. Using the clustered 3D points, i.e. 3D segment, more accurate region-of-interests (RoIs) are generated by projecting 3D points on the 2D image. The third step is detection, which is broadly divided into two parts. First is object detection in 2D image which is achieved using Fast R-CNN as this method doesn't need training and it also considers an image and several regions of interest. Second is object detection in 3D space which is done by using the spin image method. This method extracts local and global histograms to represent a certain object. To merge the results of 2D image and 3D space object detection, same 3D region is considered and two independent classifiers from 2D image and 3D space are applied to the considered region. Scores calibration is done to get a single confidence score from both detectors. This single score is obtained in the form of probability. The final step is tracking. This is done by associating moving objects in present and past frame. For object tracking, segment matching is adopted. Features such as mean, standard deviation, quantized color histograms, volume size and number of 3D points of a segment are computed. Euclidean distance is used to measure differences between segments. To judge the appearance and disappearance of an object, similar segments (obtained based on the Euclidean distance) from two different frames are taken and the physical distance and dissimilarity scores are calculated. If the scores go beyond a range for every segment in previous frame, the object being tracked is considered to have disappeared.|$|E
40|$|This {{article is}} written as an invited paper on natural {{resource}} accounting to the 44 th {{session of the}} International Statistical Insti-tute in Madrid in September 1983. It gives a review of methods used for estimating and evaluating natural resources, and a description of land use and environmental statistics obtained by <b>point</b> <b>sampling</b> in Norway. In addition, the paper contains detailed considerations on the statistical properties of <b>point</b> <b>sampling,</b> especially on the precision of sys-tematic <b>point</b> <b>sampling...</b>|$|E
5000|$|... #Caption: <b>Points</b> <b>sampled</b> {{from three}} von Mises-Fisher {{distributions}} on the sphere (blue: , green: , red: [...] ). The mean directions [...] are shown with arrows.|$|R
40|$|From a {{sufficiently}} large <b>point</b> <b>sample</b> {{lying on a}} compact Riemannian submanifold of Euclidean space, one can construct a simplicial complex which is homotopy-equivalent to that manifold with high confidence. We describe a corresponding result for a Lipschitz-continuous function between two such manifolds. That is, we outline {{the construction of a}} simplicial map which recovers the induced maps on homotopy and homology groups with high confidence using only finite sampled data from the domain and range, as well as knowledge of the image of every <b>point</b> <b>sampled</b> from the domain. We provide explicit bounds {{on the size of the}} <b>point</b> <b>samples</b> required for such reconstruction in terms of intrinsic properties of the domain, the co-domain and the function. This reconstruction is robust to certain types of bounded sampling and evaluation noise. Comment: 15 pages, To Appear in the Journal of Computational Dynamics (2014...|$|R
30|$|The double eye blink signals {{have five}} signals, 80 -s length per signal, 20, 480 <b>sampling</b> <b>points</b> per signal, and each signal {{containing}} eight known peak points and some additional signal patterns. The additional signal patterns are the edge transitions {{that represent the}} horizontal eye movements. The signals occasionally contain a peak of the single eye blink. The total training and testing <b>sampling</b> <b>points</b> are 51, 200 and 51, 200, respectively. From the total <b>sampling</b> <b>points,</b> 4662 <b>sampling</b> <b>point</b> locations are identified as the locations of peak candidates, 40 <b>sampling</b> <b>point</b> locations are identified as the locations of true peaks, and 4622 <b>sampling</b> <b>point</b> locations are identified as the locations of false peaks.|$|R
40|$|We {{introduce}} the Fast Marching farthest <b>point</b> <b>sampling</b> (FastFPS) approach for the progressive sampling of planar domains and curved manifolds in triangulated, point cloud or implicit form. By using Fast Marching for the incremental computation of distance maps across the sampling domain, we obtain a farthest <b>point</b> <b>sampling</b> technique superior to earlier <b>point</b> <b>sampling</b> principles in two important respects. Firstly, our method performs equally well {{in both the}} uniform and the adaptive case. Secondly, the algorithm is applicable to both images and higher dimensional surfaces in triangulated, point cloud or implicit form. This paper presents the methods underlying the algorithm and gives examples for the processing of images and triangulated surfaces...|$|E
40|$|Vertical <b>point</b> <b>sampling</b> {{has seen}} {{relatively}} little use in practical forestry, {{in part because}} existing field techniques are difficult. We show how vertical <b>point</b> <b>sampling</b> can be implemented quickly and easily using a camera. We give tables and equations for calculating the height-squared factor, which plays a role {{similar to that of}} the basal area factor in horizontal <b>point</b> <b>sampling.</b> Some suggestions for choosing a height-squared factor are discussed, along with potential applications for further exploration. We illustrate the technique using a case study in southern Maine. Direct estimates with no statistically detectable bias were obtained using height-squared factors greater than 3. The results also suggested that the technique could be used as a correlate in double sampling for variables such as cubic volume, stand density index, and biomass, and possibly board foot volume as well...|$|E
30|$|In this section, we {{introduce}} the major {{components of the}} proposed LV-ET extraction, including edge <b>point</b> <b>sampling</b> and tracking, trajectory generation, and its pruning strategy.|$|E
40|$|Abstract: This paper proposes and {{analyzes}} {{a method}} called meshless parameterization for reconstructing curves from unordered <b>point</b> <b>samples.</b> The method solves a linear {{system of equations}} based on convex combinations so as to map the <b>sampled</b> <b>points</b> into corresponding parameter values, whose natural ordering provides the ordering of the points. Using the theory of M-matrices, we derive natural conditions on the <b>point</b> <b>sample</b> which guarantee the correct ordering. A sufficient condition is that the underlying curve be tangent-continuous and free of self-intersections and that the sample is dense enough. AMS subject classification: 65 D 05, 65 D 10. Key words: parameterization, curve reconstruction, monotonicity, M-matrix, surface reconstruction, triangulation. 1...|$|R
5000|$|AMS dating of bone <b>point</b> <b>samples</b> {{from the}} Aurignacian and Gravettian layers to an age between 30,000 and 27,000 years ago {{confirmed}} consistency of subsequent cultural corrections.|$|R
50|$|This method {{needs to}} {{calculate}} the averages of absolute amplitudes from a seismic trace by using three moving time windows before and after each time <b>point</b> (<b>sample).</b>|$|R
40|$|Avian surveys using <b>point</b> <b>sampling</b> for {{abundance}} estimation {{have either}} focused on distance sampling or more commonly mark-recapture to correct for detection bias. Combining mark-recapture and distance sampling (MRDS) {{has become an}} effective tool for line transects, {{but it has been}} largely ignored in <b>point</b> <b>sampling</b> literature. We describe MRDS and show that the previously published methods for point sam-pling are special cases. Using simulated data and golden-cheeked warbler (Dendroica chrysoparia) survey data from Texas, we demonstrate large differences in abundance estimates resulting from different independence assumptions. Data and code are pro-vided in supplementary materials...|$|E
3000|$|... to {{evaluate}} its robustness; (2) the median estimation error Δ among all Nsuc successful estimations {{to evaluate}} its accuracy; (3) the median estimation time t over all Nrun runs to evaluate its efficiency. Note that the estimation time {{does not include}} pre-processing computation time (i.e., texture feature detection/matching, <b>point</b> <b>sampling,</b> etc), but it incorporates the codebook building time, which took < 1 s with the basic RANSAC and around two seconds with the probabilistic RANSAC using our parameter setting. The feature detectors listed by increasing processing time are Harris, FAST, SURF and SIFT. The <b>point</b> <b>sampling</b> approaches listed by increasing processing time are random, probabilistic and uniform samplings.|$|E
40|$|Graduation date: 1967 This {{study was}} a test of eight basal area factors and five <b>point</b> <b>sampling</b> cluster {{patterns}} in a computer oriented sampling study of coastal Alaska old-growth spruce-hemlock stands. It {{was an attempt to}} learn which basal area factor and which type of point sample cluster pattern should be used in such stands. A. test of the effect of stand density on <b>point</b> <b>sampling</b> was also made. All trees 3. 0 inches d. b. h. and larger on ten 3. 5 acre areas were measured and mapped in the field. Five of the areas had crown densities of from 40 to 69...|$|E
50|$|The {{minimum weight}} cycle {{basis of a}} nearest {{neighbor}} graph of <b>points</b> <b>sampled</b> from a three-dimensional surface {{can be used to}} obtain a reconstruction of the surface.|$|R
30|$|In each {{treatment}} plot, fuel {{loads and}} mean fire temperatures were estimated at 100 spatially referenced <b>sampling</b> <b>points.</b> <b>Sampling</b> <b>points</b> were arranged as systematic clusters. This sampling design is {{more capable of}} detecting spatial structures than regular grids (Fortin et al. 1989). The minimum distance between <b>sampling</b> <b>points</b> was 1 m. The maximum distance between <b>sampling</b> <b>points</b> varied due to plot configuration and ranged from 375 to 575 m.|$|R
40|$|We {{consider}} {{the problem of}} denoising a noisily sampled submanifold M in R d, where the submanifold M is a priori unknown and we are only given a noisy <b>point</b> <b>sample.</b> The presented denoising algorithm {{is based on a}} graph-based diffusion process of the <b>point</b> <b>sample.</b> We analyze this diffusion process using recent results about the convergence of graph Laplacians. In the experiments we show that our method is capable of dealing with non-trivial high-dimensional noise. Moreover using the denoising algorithm as pre-processing method we can improve the results of a semi-supervised learning algorithm. ...|$|R
