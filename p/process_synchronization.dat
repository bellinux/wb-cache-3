161|733|Public
5000|$|Process manager: {{offers an}} ACID-like file system {{abstraction}} that includes disk rollback and <b>process</b> <b>synchronization</b> ...|$|E
50|$|Monitors (and Concurrent Pascal) {{were soon}} used to {{structure}} <b>process</b> <b>synchronization</b> in the Solo operating system.|$|E
5000|$|When the {{producer}} is a software algorithm, the system pauses {{the producer}} {{with the same}} <b>process</b> <b>synchronization</b> techniques.|$|E
50|$|The {{semantics}} of executability {{provides the}} basic means in Promela for modeling <b>process</b> <b>synchronizations.</b>|$|R
40|$|Mechanisms of {{automatic}} control in parallel computing and synchronization is developed and investigated. Developed mechanisms improved the standard FPGA tools from the leading manufacturers of FPGA and increased efficient of the <b>processes</b> <b>synchronization</b> in multiprocessor systems-on-chip. ??????????? ? ??????????? ???????? ??????????????? ?????????? ????????????? ???????????? ? ?????????????, ??????? ????????? ????????????????? ????????? ?????????? ??????????????, ???????????? ???????? ??????????????? ????, ? ???????? ????????????? ????????????? ????????? ? ?????????????????? ????????-??-?????????...|$|R
40|$|Abstract Hive is a Java library {{implementing}} a distributed shared memory on {{a cluster of}} workstations. The memory is structured {{as a set of}} variable size areas and a user can exploit two consistency models, sequential and release consistency. Hive defines original strategies to implement the consistency models and to synchronize concurrent <b>processes.</b> <b>Synchronization</b> is implemented through tokens, i. e. privileges. Preliminary performance figures are discussed...|$|R
50|$|In {{computer}} science, synchronization {{refers to}} one of two distinct but related concepts: synchronization of processes, and synchronization of data. <b>Process</b> <b>synchronization</b> refers to the idea that multiple processes are to join up or handshake at a certain point, in order to reach an agreement or commit to a certain sequence of action. Data synchronization refers to the idea of keeping multiple copies of a dataset in coherence with one another, or to maintain data integrity. <b>Process</b> <b>synchronization</b> primitives are commonly used to implement data synchronization.|$|E
50|$|Remote {{procedure}} calls used {{in modern}} operating systems trace their roots {{back to the}} RC 4000 multiprogramming system, which used a request-response communication protocol for <b>process</b> <b>synchronization.</b>|$|E
5000|$|An event flag is a <b>process</b> <b>synchronization</b> {{primitive}} in the OpenVMS operating system. It has {{two possible}} states, set or cleared. The following basic primitive operations are provided: ...|$|E
40|$|Abstract- This paper {{introduces}} a modular modeling approach for distributed production systems, considering production and maintenance <b>processes</b> <b>synchronization.</b> Thus, production job shop, preventive and curative specialized telemaintenance actions are studied together. Stochastic synchronized Petri nets {{are used for}} modeling. This tool was adapted to the tele/maintenance distributed case and to integrate distant communications, synchronization problems and execution scheduling. Performance evaluation uses Markov Processes and Monte-Carlo simulation...|$|R
40|$|Code <b>Synchronization</b> is the <b>process</b> {{to achieve}} an {{equalized}} state among code domains. However, the equalization process is not clearly defined. An equal state can be achieved in various forms, such as destroying all irrelevant code parts, or just letting them exist without including them in the <b>synchronization</b> <b>process.</b> For this reason, a <b>synchronization</b> <b>process</b> is depended on its synchronization behavior. This behavior is {{the characteristics of the}} process. Additionally, conditions of a <b>synchronization</b> <b>process</b> {{have an impact on the}} realization of the behavior. Behavior can only be realized if the conditions of compared states, environment variables, and abilities are configured in support of the behavior. Thus, it can be said that synchronization behavior is both the analyzer and the decision maker of a <b>synchronization</b> <b>process.</b> When a <b>synchronization</b> <b>process</b> consists of a singular synchronization analysis and implementation process for two or more code bodies, then this can also be called a synchronization attempt. A synchronization attempt is analyzed under the provided synchronization behavior in limited, expected and exceptional conditions. Though thi...|$|R
40|$|A new {{proposal}} for synchronization and communication in parallel programs is presented. The proposal, called synchronization resources, combines and extends aspects of procedures, coroutines, monitors, communicating sequential processes, and distributed processes. It provides a single notation for parallel programming {{with or without}} shared variables and is suited for either shared or distributed memory architectures. The essential new concepts are operations, input statements, multiple processes and resources. The proposal is illustrated by solving a variety of parallel programming problems. Key Words and Phrases: parallel programming, <b>processes,</b> <b>synchronization,</b> <b>process</b> communication, monitors, distributed processing, programming languages, operating systems, data bases. CR Categories: 4. 20, 4. 22, 4. 32, 4. 3...|$|R
50|$|In {{computer}} programming, explicit parallelism is the representationof concurrent computations {{by means}} of primitivesin the form of special-purpose directives or function calls. Most parallel primitives are related to <b>process</b> <b>synchronization,</b> communication or task partitioning. As they seldom contribute to actually carry out the intended computation of the program, their computational cost is often consideredas parallelization overhead.|$|E
50|$|In {{concurrent}} computing, a deadlock is a {{state in}} which each member of a group is waiting for some other member to take action, such as sending a message or more commonly releasing a lock.Deadlock is a common problem in multiprocessing systems, parallel computing, and distributed systems, where software and hardware locks are used to handle shared resources and implement <b>process</b> <b>synchronization.</b>|$|E
50|$|Habermann's {{research}} included programming languages, operating systems, {{and development}} of large software systems. He {{was known for his}} work on inter-process communication, <b>process</b> <b>synchronization</b> and deadlock avoidance, and software verification, but particularly for the computer languages ALGOL 60, BLISS, Pascal, and Ada. He also contributed to new operating systems such as Edsger Dijkstra's THE multiprogramming system, the Family of Operating Systems (FAMOS) at Carnegie Mellon, Berlin's Dynamically Adaptable System (DAS), and UNIX.|$|E
40|$|Abstract. Integration of the {{cognitive}} approach to human body and the technical system as the main design theory and information technology, innovative design from the mechanical and electrical products, ways of thinking, creative problem solving strategies designed to mechanical and electrical product manufacturing <b>processes,</b> <b>synchronization</b> means of design and manufacturing innovation, through the CAD/CAPP two-way data flow, the introduction of genetically achieved CAPP/CNC's highly integrated, effectively improve the mechanical and electrical product innovation capabilities...|$|R
40|$|Task-dependent {{changes of}} nonlinear-linear {{synchronization}} features and graph theoretical {{properties of the}} delta and theta frequencies were analyzed in the present EEG study that were related to episodic memory maintenance <b>processes.</b> <b>Synchronization</b> was found to increase with respect to both the delta and theta bands within the frontal and parietal areas and also between these regions. Results of graph theoretical analysis indicated a task-related shift towards small-world network topology in the theta band. © 2012...|$|R
40|$|Keywords：workflow, graph recduction, RTWD net. Abstract. In this paper, {{we propose}} {{a set of}} {{reduction}} rules of graphical representation in a workflow process model called RTWD net. The concept of <b>synchronization</b> <b>processes</b> is introduced for reducing net structure, and an algorithm of abstracting <b>synchronization</b> <b>processes</b> is presented. We can clarify the main structure of RTWD net model through reduction rules and abstracting its <b>synchronization</b> <b>processes.</b> Finally, the feasibility of the method is illustrated by a case study...|$|R
5000|$|Remote {{procedure}} calls used {{in modern}} operating systems trace their roots {{back to the}} RC 4000 multiprogramming system, which used a request-response communication protocol for <b>process</b> <b>synchronization.</b> The idea of treating network operations as remote procedure calls goes {{back at least to}} the 1970s in early ARPANET documents. In 1978, Per Brinch Hansen proposed Distributed Processes, a language for distributed computing based on [...] "external requests" [...] consisting of procedure calls between processes.|$|E
50|$|For simple loops, {{where each}} {{iteration}} {{is independent of}} the others, loop-level parallelism can be embarrassingly parallel, as parallelizing only requires assigning a process to handle each iteration. However, many algorithms are designed to run sequentially, and fail when parallel processes race due to dependence within the code. Sequential algorithms are sometimes applicable to parallel contexts with slight modification. Usually, though, they require <b>process</b> <b>synchronization.</b> Synchronization can be either implicit, via message passing, or explicit, via synchronization primitives like semaphores.|$|E
5000|$|Often the {{contents}} of a bytestream are dynamically created, such as the data from the keyboard and other peripherals (/dev/tty), data from the pseudorandom number generator /dev/urandom, etc.In those cases, when the destination of a bytestream (the consumer) uses bytes faster than they can be generated, the system uses <b>process</b> <b>synchronization</b> to make the destination wait until the next byte is available.When bytes are generated faster than the destination can use them, there are several techniques to deal with the situation: ...|$|E
40|$|This paper {{introduces}} a new parallel programming model for situated multi-agent systems simulations and its parallel library implementation on shared memory MIMD parallel computers. The first {{goal is to}} allow users to easily implement situated multi-agent systems, following their natural paradigm: concurrent agent behavior definition and environment update programming. The second goal is to obtain e#cient parallel executions on shared memory MIMD parallel computers, without dealing with parallel programming di#culties (such as load balancing and <b>processes</b> <b>synchronization)</b> ...|$|R
40|$|Abstract—Synchronization {{between the}} slow {{oscillations}} of {{heart rate and}} blood pressure having in humans a basic frequency close to 0. 1 Hz is investigated. A method is proposed for quantitative estimation of synchronization between these oscillating processes based on calculation of relative time of phase synchronization of oscillations. It is shown that healthy subjects exhibit in average substantially longer epochs of synchronization between the slow oscillations in heart rate and blood pressure than patients after acute myocardial infarction. Keywords—Cardiovascular system, slow oscillating <b>processes,</b> <b>synchronization.</b> I...|$|R
40|$|Spinlocks {{are widely}} used in {{database}} engines for <b>processes</b> <b>synchronization.</b> KGX mutexes is new retrial spinlocks appeared in contemporary Oracle versions for submicrosecond synchronization. The mutex contention is frequently observed in highly concurrent OLTP environments. This work explores how Oracle mutexes operate, spin, and sleep. It develops predictive mathematical model and discusses parameters and statistics related to mutex performance tuning, as well as results of contention experiments. Comment: Proceedings of International Conference on Informatics MEDIAS 2012. Cyprus, Limassol, May 7 [...] 14, 2012. ISBN 978 - 5 - 88835 - 023 - 2. 12 pages, 15 figure...|$|R
5000|$|... “First, in {{conversation}} unlike writing, speakers have limited time {{for planning and}} revision. They need to overcome this limitation, {{and in doing so}} they may exploit techniques possible only {{in conversation}}al settings. Second, speech is evanescent. The listener has to attend to, hear, and try to understand an utterance at virtually the same time it is being issued. That requires a type of <b>process</b> <b>synchronization</b> not found in reading. And third, listeners in conversations aren’t mute or invisible during an utterance. Speakers may alter what they say midcourse based on what addressees say and do.” ...|$|E
50|$|In 1966, Brinch Hansen {{moved to}} Henning Isaksson’s {{hardware}} group in Regnecentralen, now {{a company with}} shareholders. Together with Peter Kraft, he defined the architecture and instruction set for Regnecentralen’s third computer, the RC 4000, using Algol 60 as a hardware definition language to produce a formal specification. Inexperienced with multiprogramming, he used a copy of Cooperating Sequential Processes Edsger Dijkstra had sent him to understand <b>process</b> <b>synchronization</b> using semaphores, and then implemented a specialized RC 4000 real-time monitor, for use in managing a fertilizer plant. Peter Kraft and a then-teenaged Charles Simonyi wrote a p-code interpreter and data logging task programs that were compiled to p-code.|$|E
50|$|If the {{resource}} cannot {{be provided by}} the operator, the operator can DS the task as a last resort. This is different from other systems, which automatically terminate a task when a resource such as a file is not available. The MCP provides this level of operator recoverability of tasks. Other systems force programmers to add code to check {{for the presence of}} files before accessing them, and thus extra code must be written in every case to provide recoverability, or <b>process</b> <b>synchronization.</b> Such code may be written in an MCP program when it is not desirable to have a task wait, but because of the operator-level recoverability, this is not forced and therefore makes programming much simpler.|$|E
40|$|Language {{acquisition}} is {{a complex}} process that requires the synergic involvement of different cognitive functions, which include extracting and storing {{the words of the}} language and their embedded rules for progressive acquisition of grammatical information. As has been shown in other fields that study learning <b>processes,</b> <b>synchronization</b> mechanisms between neuronal assemblies might have a key role during language learning. In particular, studying these dynamics may help uncover whether different oscillatory patterns sustain more item-based learning of words and rule-based learning from speech input. Therefore, we tracked the modulation of oscillatory neural activity during the initial exposure to an artificial language, which contained embedded rules. We analyzed both spectral powe...|$|R
3000|$|... {{denote the}} {{instantaneous}} coupling configuration, which {{play a key}} role in the <b>synchronization</b> <b>process.</b>|$|R
50|$|Two {{files of}} MyNotex {{can be kept}} synchronized. Thus, changes made to one file will result in changes to the other during the <b>process</b> of <b>synchronization.</b> All types of changes are tracked (new, changed and deleted subjects, notes and attachments).|$|R
50|$|The most {{immediate}} {{challenge in the}} realm of parallel processing does not lie as much in the type of hardware architecture used, but in how easy it will be to program the system in question in a real-world environment with acceptable performance. Machines like Imagine use a straightforward single-threaded model with automated dependencies, memory allocation and DMA scheduling. This in itself {{is a result of the}} research at MIT and Stanford in finding an optimal layering of tasks between programmer, tools and hardware. Programmers beat tools in mapping algorithms to parallel hardware, and tools beat programmers in figuring out smartest memory allocation schemes, etc. Of particular concern are MIMD designs such as Cell, for which the programmer needs to deal with application partitioning across multiple cores and deal with <b>process</b> <b>synchronization</b> and load balancing. Efficient multi-core programming tools are severely lacking today.|$|E
40|$|In {{computer}} programs with multiple processes (or threads), process communication is of high importance. One {{of the main}} classes of inter-process communication (IPC) mechanisms are <b>process</b> <b>synchronization</b> mechanisms, for example semaphores, conditional variables, rendezvous. <b>Process</b> <b>synchronization</b> mechanisms differ {{from each other in}} several respects: operation logic, existence of process blocking etc. Therefore, before choosing a <b>process</b> <b>synchronization</b> mechanism, in each separate case it is important to realize its properties and distinctive features. In many modern programming languages and software frameworks, there exist some built-in <b>process</b> <b>synchronization</b> mechanisms; therefore, a selected programming language or framework to some extent affects the use of synchronization mechanisms (as well as other IPC mechanisms). An analysis of classes of <b>process</b> <b>synchronization</b> mechanisms is one of the tasks of this paper. The second task is to analyze support of <b>process</b> <b>synchronization</b> mechanisms in different modern programming languages (Ada, C#, Java, C++ etc.) ...|$|E
40|$|Abstract—All {{processes}} prevent casual {{exchange of}} data. However, occasionally two processes {{might need to}} communicate with each other. One method that enables processes to communicate is called Inter <b>Process</b> <b>Synchronization</b> (IPS). In an Operating System on which several threads run concurrently, {{it is important to be}} able to synchronize the activities of various threads. Windows provides several synchronization objects that enable to synchronize a thread's actions with those of another thread. These objects include critical sections, mutexes, events, and semaphores. The different solutions for Inter <b>Process</b> <b>Synchronization</b> problem are suggested [1] where some of these solutions have their own limitations or performance related issues. The agent based approach used in this paper has suggested a new algorithm for agent IPSM which is an attempt to propose an optimal solution to the problem. IPSM stands for Inter <b>Process</b> <b>Synchronization</b> Manager which is an agent used for solving the problem of inter <b>process</b> <b>synchronization.</b> In the present paper agent based Inter <b>Process</b> <b>Synchronization</b> Manager (IPSM) is described and its performance is compared with agent based IPSM on different Windows based operating systems...|$|E
50|$|Generators can be {{electrically}} connected together through the <b>process</b> of <b>synchronization.</b> Synchronization involves matching voltage, frequency and phase before connecting the generator to the system. Failure to synchronize before connection {{could cause a}} high short circuit current or {{wear and tear on}} the generator or its switchgear. The <b>synchronization</b> <b>process</b> can be done automatically by an auto-synchronizer module, or manually by the instructed operator. The auto-synchronizer will read the voltage, frequency and phase parameters from the generator and busbar voltages, while regulating the speed through the engine governor or ECM (Engine Control Module).|$|R
40|$|Abstract — In {{this paper}} {{we present a}} new way of {{achieving}} chaos synchronization for synchronous Multi-User (MU) chaos-based DS-CDMA system. The <b>synchronization</b> <b>process</b> is realized through a binary code used as a pilot sequence. The Chebyshev chaotic map is used to generate spreading signals for data sequences. To avoid an additional noise for <b>synchronization</b> <b>process,</b> the data signal and the pilot signal are modulated in Quadrature Amplitude Modulation (QAM). Gold sequence is used as pilot signal to accomplish the synchronization. An additive white Gaussian noise channel is assumed. Performance of the system is studied and evaluated. The <b>synchronization</b> <b>process</b> is evaluated in terms of probability of detection and probability of false alarm I...|$|R
40|$|Aspect-oriented {{modeling}} and simulation is a new approach which uses the separation of concerns principle to {{enhance the quality of}} models and simulation tools. It adopts the separation of concerns (SOC) principle. Thus, crosscutting concerns such as <b>processes</b> <b>synchronization,</b> steady state detection, and graphical animation could be separated from simulation functional modules. The capture of crosscutting concerns in a modular way is carried out to cope with complexity and to achieve the required engineering quality factors such as robustness, modularity, adaptability, and reusability. This paper provides a summary of aspect-oriented paradigm with its usage in simulation by illustrating the main crosscutting concerns that may infect simulation systems. A practical example is given {{with the use of the}} Japrosim discrete event simulation library...|$|R
