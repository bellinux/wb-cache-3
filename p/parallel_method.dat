384|2641|Public
25|$|Dial-out PCR: {{a highly}} <b>parallel</b> <b>method</b> for {{retrieving}} accurate DNA molecules for gene synthesis. A complex library of DNA molecules is modified with unique flanking tags before massively parallel sequencing. Tag-directed primers then enable the retrieval of molecules with desired sequences by PCR.|$|E
25|$|Serial Attached SCSI (SAS). The SAS {{is a new}} {{generation}} serial communication protocol for devices designed to allow for much higher speed data transfers and is compatible with SATA. SAS uses a mechanically identical data and power connector to standard 3.5-inch SATA1/SATA2 HDDs, and many server-oriented SAS RAID controllers are also capable of addressing SATA HDDs. SAS uses serial communication instead of the <b>parallel</b> <b>method</b> found in traditional SCSI devices but still uses SCSI commands.|$|E
25|$|Algebraic {{notation}} (or AN) is {{a method}} for recording and describing the moves {{in a game of}} chess. It is based on a system of coordinates to uniquely identify each square on the chessboard. It is now standard among all chess organizations and most books, magazines, and newspapers. In English-speaking countries, the <b>parallel</b> <b>method</b> of descriptive notation was generally used in chess publications until about 1980. Some older players still use descriptive notation, but it is no longer recognized by FIDE.|$|E
40|$|This work proposes four <b>parallel</b> <b>methods</b> for multipattern {{matching}} {{which are}} executed on a heterogeneous cluster. These <b>parallel</b> <b>methods</b> {{are based on}} the master- worker paradigm and they implement different partitioning schemes such as static and dynamic load balancing. Furthermore, the <b>parallel</b> <b>methods</b> are analyzed experimentally using the Message Passing Interface (MPI) library on a cluster of heterogeneous workstations. Further, we propose a performance modeling of the <b>parallel</b> <b>methods</b> {{that can be used to}} predict the parallel performance on a cluster of workstations. The results by the theoretical performance models have been validated against experimental results of the four <b>parallel</b> <b>methods...</b>|$|R
5000|$|... pContainers - generic, {{distributed}} data structures with <b>parallel</b> <b>methods.</b>|$|R
40|$|A new {{parallel}} {{approach for}} solving a pentadiagonal linear system is presented. The <b>parallel</b> partition <b>method</b> for this {{system and the}} TW <b>parallel</b> partition <b>method</b> on a chain of P processors are introduced and discussed. The result of this algorithm is a reduced pentadiagonal linear system of order P Γ 2 compared with a system of order 2 P Γ 2 for the <b>parallel</b> partition <b>method.</b> More importantly the new method involves only half the number of communications startups than the <b>parallel</b> partition <b>method</b> (and other standard <b>parallel</b> <b>methods)</b> and hence {{is a far more}} efficient parallel algorithm...|$|R
5000|$|OpenMOC - An MIT {{developed}} {{open source}} <b>parallel</b> <b>method</b> of characteristics code ...|$|E
50|$|Stencil {{lithography}} is a resist-less and <b>parallel</b> <b>method</b> of fabricating {{nanometer scale}} patterns using nanometer-size apertures as shadow-masks.|$|E
5000|$|Dial-out PCR: {{a highly}} <b>parallel</b> <b>method</b> for {{retrieving}} accurate DNA molecules for gene synthesis. A complex library of DNA molecules is modified with unique flanking tags before massively parallel sequencing. Tag-directed primers then enable the retrieval of molecules with desired sequences by PCR.|$|E
5000|$|<b>Parallel</b> <b>Methods</b> on Large-Scale Structural Analysis & Physics Applications, Pergamon Press 1991.|$|R
40|$|One of the {{algorithms}} used in multi-agent systems {{is based on}} the wave propagation model. This article discusses some sequential (recursive, iterative, and based on distance) and <b>parallel</b> <b>methods</b> (frontier exchanging, domain decomposition changing, private environments, and mutex-based) to implement it. The mixing between these sequential and <b>parallel</b> <b>methods</b> is also shown, and the performance of some of them on two shared-memory parallel architectures is introduced...|$|R
5000|$|... "Investigation of the Comparative Values of Concentrated and <b>Parallel</b> <b>Methods</b> of Mortar Fire." [...] 1896. Journal of the United States Artillery ...|$|R
5000|$|Serial Attached SCSI (SAS). The SAS {{is a new}} {{generation}} serial communication protocol for devices designed to allow for much higher speed data transfers and is compatible with SATA. SAS uses a mechanically identical data and power connector to standard 3.5-inch SATA1/SATA2 HDDs, and many server-oriented SAS RAID controllers are also capable of addressing SATA HDDs. SAS uses serial communication instead of the <b>parallel</b> <b>method</b> found in traditional SCSI devices but still uses SCSI commands.|$|E
50|$|Algebraic {{notation}} (or AN) is {{a method}} for recording and describing the moves {{in a game of}} chess. It is based on a system of coordinates to uniquely identify each square on the chessboard. It is now standard among all chess organizations and most books, magazines, and newspapers. In English-speaking countries, the <b>parallel</b> <b>method</b> of descriptive notation was generally used in chess publications until about 1980. A few older players still use descriptive notation but it is no longer recognized by FIDE.|$|E
5000|$|A [...] "parallel synthesis" [...] {{method was}} {{developed}} by Mario Geysen and his colleagues for preparation of peptide arrays. They synthesized 96 peptides on plastic rods (pins) coated at their ends with the solid support. The pins were immersed into the solution of reagents placed in the wells of a microtiter plate. The method is widely applied particularly by using automatic parallel synthesizers. Although the <b>parallel</b> <b>method</b> is much slower than the real combinatorial one, its advantage {{is that it is}} exactly known which peptide or other compound forms on each pin.|$|E
30|$|The {{digital signal}} {{processing}} part (i.e., baseband processing) has two major tasks. First, the Doppler frequencies and code phases of the satellites need to be acquired. The details of the acquisition process are well explained in literature, for example, [1, 7]. There {{are a number of}} ways to implement acquisition, with <b>parallel</b> <b>methods</b> being faster than serial ones, but at the cost of consuming more resources. The <b>parallel</b> <b>methods</b> can be applied either as convolution in the time domain (matched filters) or as multiplication in the frequency domain (using FFT and IFFT).|$|R
3000|$|The {{discrete}} likelihood probability {{defines a}} relaxed {{correspondence between the}} source and target training vectors, {{as opposed to a}} one-to-one match defined in other <b>parallel</b> <b>methods,</b> for which p(x [...]...|$|R
40|$|Stochastic {{gradient}} descent~(SGD) and its variants {{have become}} more and more popular in machine learning due to their efficiency and effectiveness. To handle large-scale problems, researchers have recently proposed several <b>parallel</b> SGD <b>methods</b> for multicore systems. However, existing <b>parallel</b> SGD <b>methods</b> cannot achieve satisfactory performance in real applications. In this paper, we propose a fast asynchronous <b>parallel</b> SGD <b>method,</b> called AsySVRG, by designing an asynchronous strategy to parallelize the recently proposed SGD variant called stochastic variance reduced gradient~(SVRG). Both theoretical and empirical results show that AsySVRG can outperform existing state-of-the-art <b>parallel</b> SGD <b>methods</b> like Hogwild! in terms of convergence rate and computation cost...|$|R
5000|$|From its {{beginnings}} in Cincinnati in 1906, cooperative education {{has evolved into}} a program offered at the secondary and post-secondary levels in two predominant models [...] In one model, students alternate a semester of academic coursework with an equal amount of time working, repeating this cycle several times until graduation. The <b>parallel</b> <b>method</b> splits the day between school and work, typically structured to accommodate the student's class schedule. Thus, like school-to-work (STW), the co-op model includes school-based and work-based learning and, in the best programs, [...] "connecting activities" [...] such as seminars and teacher-coordinator work site visits. These activities help students explicitly connect work and learning.|$|E
40|$|Abstract: In {{this paper}} Present survey on Data mining, Data mining using Rough set Theory and Data Mining using <b>parallel</b> <b>method</b> for rough set Approximation with MapReduce Technique. With the {{development}} of Information technology data growing at a tremendous rate, so big data mining and knowledge discovery become a new challenge. Rough set theory has been successfully applied in data mining by using MapReduce programming technique. We use the Hadoop MapReduce System as an Implementation platform. The lower and upper approximations are two basic concept of rough set theory. A <b>parallel</b> <b>method</b> {{is used for the}} effective computation of approximation and is improving the performance of data mining. With the benefits of MapReduce it makes our approach more ideal for executing large scale data using <b>parallel</b> <b>method...</b>|$|E
30|$|This set of {{algorithms}} represents is {{the set of}} <b>parallel</b> <b>method</b> {{based on}} MapReduce to solve the least square problem.|$|E
40|$|We {{consider}} hierarchically structured {{systems of}} algebraic-differential equations. Numerical methods for their solution are described. <b>Parallel</b> <b>methods</b> are discussed. (orig.) Available from TIB Hannover: RR 5549 (71) +a / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|R
40|$|We {{present a}} <b>parallel</b> {{computational}} <b>method</b> for retrieving similar sequences from large genetic and protein databases using a dynamic programming comparison algorithm. Two previously published <b>parallel</b> <b>methods</b> for performing this task are first discussed and evaluated. The advantages {{of these two}} <b>parallel</b> <b>methods</b> are combined and incorporated into our new method to obtain better performance than either of the original two. Using the entire GenBank database (release 80. 0), we compare {{the performance of the}} three methods on an Intel iPSC/ 860 parallel computer. 1. Introduction Advances in biotechnology have resulted in the generation of a massive volume of biological data such as that found in the GenBank and SWISS-PROT databases. These databases contain a large number of genetic and protein sequences and their associated biological and bibliographical information. Retrieving homologous sequences from such databases is important to the biomedical research community. When we discover new [...] ...|$|R
30|$|In this paper, {{we carry}} out a {{comparative}} study between the <b>parallel</b> <b>methods</b> aiming to solve the least square estimation problem and our proposal. The results promote {{the use of the}} proposed method as the results confirm its efficiency and rapidity. Moreover, we presents {{a detailed description of the}} <b>parallel</b> MapReduce-based Adjoint <b>method.</b> The application of the method to predict the Alzheimer’s disease risk confirms its robustness.|$|R
40|$|Three {{parallel}} methods (OpenMP, MPI, and OpenACC) {{are evaluated}} for the computation of a two-dimensional dam-break model using the explicit finite volume method. A dam-break {{event in the}} Pangtoupao flood storage area in China is selected {{as a case study}} to demonstrate the key technologies for implementing parallel computation. The subsequent acceleration of the methods is also evaluated. The simulation results show that the OpenMP and MPI parallel methods achieve a speedup factor of 9. 8 × and 5. 1 ×, respectively, on a 32 -core computer, whereas the OpenACC <b>parallel</b> <b>method</b> achieves a speedup factor of 20. 7 × on NVIDIA Tesla K 20 c graphics card. The results show that if the memory required by the dam-break simulation does not exceed the memory capacity of a single computer, the OpenMP <b>parallel</b> <b>method</b> is a good choice. Moreover, if GPU acceleration is used, the acceleration of the OpenACC <b>parallel</b> <b>method</b> is the best. Finally, the MPI <b>parallel</b> <b>method</b> is suitable for a model that requires little data exchange and large-scale calculation. This study compares the efficiency and methodology of accelerating algorithms for a dam-break model and can also be used as a reference for selecting the best acceleration method for a similar hydrodynamic model...|$|E
40|$|In a {{companion}} paper Lopez and Trigiante [4] introduced BVM methods for solving linear ODEs. In this paper {{we describe the}} implementation of a particular method in this class on a parallel computer. The corresponding discrete problem requires the solution of an unsymmetric block tridiagonal linear system, which is solved by means of an iterative method. A brief survey of such iterative methods is given. Comparisons of the <b>parallel</b> <b>method</b> with the LSODE package are reported, both in terms of precision of the numerical solution and speed-up, showing the effectiveness of the <b>parallel</b> <b>method...</b>|$|E
40|$|Standard No. EN 15831 : 2004 {{provides}} 2 {{methods of}} calculating insulation: parallel and serial. The <b>parallel</b> <b>method</b> {{is similar to}} the global one defined in Standard No. ISO 9920 : 2007. Standards No. EN 342 : 2004, EN 14058 : 2004 and EN 13537 : 2002 refer to the methods defined in Standard No. EN ISO 15831 : 2004 for testing cold protective clothing or equipment. However, it is necessary to consider several issues, e. g., referring to measuring human subjects, when using the serial method. With one zone, there is no serial–parallel issue as the results are the same, while more zones increase the difference in insulation value between the methods. If insulation is evenly distributed, differences between the serial and <b>parallel</b> <b>method</b> are relatively small and proportional. However, with more insulation layers overlapping in heavy cold protective ensembles, the serial method produces higher insulation values than the parallel one and human studies. Therefore, the <b>parallel</b> <b>method</b> is recommended for standard testing...|$|E
40|$|S University of Manchester/UMIST Manchester Centre for Computational Mathematics Numerical Analysis Reports Reports {{available}} from: Department of Mathematics University of Manchester Manchester M 13 9 PL England And {{over the}} World-Wide Web from URLs [URL] ftp://vtx. ma. man. ac. uk/pub/narep Performance of <b>parallel</b> <b>methods</b> for {{the solution of}} linear systems In many scientific and engineering problems large linear systems of equations occur. Gaussian elimination (GE) and LU factorisation (LU) are two well known sequential methods used to solve such systems. Parallelised versions of GE and LU using BLAS have been developed and widely implemented on parallel computers. Two <b>parallel</b> <b>methods</b> for matrix elimination and matrix factorisation have been presented in [1993]. The <b>Parallel</b> Implicit Elimination <b>method</b> (PIE) is a scheme that eliminates two matrix elements simultaneously (not one element as in GE). The Quadrant Interlocking Factorisation method (QIF) dec [...] ...|$|R
30|$|The <b>parallel</b> multisplitting {{iterative}} <b>method</b> {{with the}} self-adaptive weighting matrices {{has been proposed}} for the linear system of equations (1.1) when the coefficient matrix is an H-matrix. The convergence theory is established for the <b>parallel</b> multisplitting <b>method</b> with self-adaptive weightings. The numerical {{results show that the}} new <b>parallel</b> multisplitting iterative <b>method</b> with the self-adaptive weightings is effective.|$|R
30|$|Besides, we will utilize more discriminative {{features}} to segment object instances, {{such as the}} features captured by convolutional neural networks. Our method {{can be applied to}} autonomous driving systems, robots, etc. Considering the computational complexity, we may refer to some <b>parallel</b> <b>methods</b> [34, 35].|$|R
40|$|International audienceThe {{methods of}} {{reflections}} were invented to obtain approximate solutions {{of the motion}} {{of more than one}} particle in a given environment, provided that one can represent the solution for one particle rather easily. This motivation is quite similar to the motivation of the Schwarz domain decomposition method, which was invented to prove existence and uniqueness of solutions of the Laplace equation on complicated domains, which are composed of simpler ones, for which existence and uniqueness of solutions was known. Like for Schwarz methods, there is also an alternating and a <b>parallel</b> <b>method</b> of reflections, but interestingly, the <b>parallel</b> <b>method</b> is not always convergent. We carefully trace in this paper the historical development of these methods of reflections, give several precise mathematical formulations, an equivalence result with the alternating Schwarz method for two particles, and also an analysis for a one dimensional model problem with three particles of the alternating, parallel, and a recent averaged <b>parallel</b> <b>method</b> of reflections...|$|E
40|$|The linear {{feasibility}} problem {{arises in}} several areas of applied mathematics and medical science, in several forms of image reconstruction problems. The surrogate constraint algorithm of Yang and Murty for the linear feasibility problem is implemented and analyzed. The sequential approach considers projections one at a time. In the parallel approach, several projections are made simultaneously and their convex combination is taken to be used at the next iteration. The sequential method is compared with the <b>parallel</b> <b>method</b> for varied numbers of processors. Two improvement schemes for the <b>parallel</b> <b>method</b> are proposed and tested. © Springer-Verlag Berlin Heidelberg 1996...|$|E
40|$|This paper {{considers}} the project scheduling problem with multiple constrained resources. Two classes of heuristic procedure, both {{making use of}} priority rules, are discussed: the <b>parallel</b> <b>method,</b> which generates just one schedule; and the sampling method, which generates a set of schedules using probabilistic techniques and selects the best schedule from this sample. An experimental investigation is described in which a set of projects with different characteristics is scheduled by each of these heuristics {{with a variety of}} priority rules. The effects of the heuristic method, the project characteristics and the priority rules are assessed. It is shown that the choice of priority rule is important with the <b>parallel</b> <b>method,</b> but with the sampling method, although it does affect the distribution of the sample, the choice of rule is not significant. The sampling method with sample size 100 is shown to produce samples at least 7 % better than those generated by the corresponding <b>parallel</b> <b>method,</b> with 99 % confidence. Further results are discussed and conclusions are presented. ...|$|E
40|$|In {{this paper}} we {{investigate}} some parallel variants of Broyden’s method and, {{for the basic}} variant, we present its convergence properties. The main {{result is that the}} behavior of the considered parallel Broyden’s variants is comparable with the classical <b>parallel</b> Newton <b>method,</b> and significantly better than the <b>parallel</b> Cimmino <b>method,</b> both for linear and nonlinear cases. The considered variants are also compared with two more recently proposed <b>parallel</b> Broyden’s <b>method.</b> Some numerical experiments are presented to illustrate the advantages and limits of the proposed algorithms...|$|R
50|$|Methods of Picking: {{automatic}} first-break picking {{has played}} an important role in seismic data processing, and directly influences the quality of seismic sections. Because of the increase of seismic survey size, more efficient and fast first break picking methods are needed, with <b>parallel</b> <b>methods</b> being preferred.|$|R
40|$|We present {{implementations}} of <b>parallel</b> DFA run <b>methods.</b> We {{compare the}} <b>parallel</b> <b>methods</b> with well known sequential versions {{of these methods}} and find whether and under what conditions is worthy to use the <b>parallel</b> <b>methods</b> of simulation of run of finite automata. We introduce the paralell DFA run methods for general DFA, which are universal, but due to the dependency of simulation time {{on the number of}} states |Q | of automaton being run, they are suitable only for run of automata with the smaller number of states. On the other hand, if we apply some restrictions to properties of automata being run, we can reach the linear speedup compared to the sequential simulation method. First, we show methods benefiting from k-locality that allows optimum parallel run of exact and approximate pattern matching automata. Finally, we show the results of experiments conducted on two types of parallel computers (Cluster of workstations and Symmetric shared-memory multiprocessors). ...|$|R
