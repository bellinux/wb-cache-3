45|1454|Public
50|$|The PS {{program can}} be used for studies with dichotomous, continuous, or {{survival}} response measures. The user specifies the alternative hypothesis in terms of differing response rates, means, survival times, relative risks, or odds ratios. Matched or independent study designs may be used. <b>Power,</b> <b>sample</b> size, and the detectable alternative hypothesis are interrelated. The user specifies any two of these three quantities and the program derives the third. A description of each calculation, written in English, is generated and may be copied into the user's documents. Interactive help is available. The program provides methods that are appropriate for matched and independent t-tests, survival analysis, matched and unmatched studies of dichotomous events, the Mantel-Haenszel test, and linear regression.The program can generate graphs of the relationships between <b>power,</b> <b>sample</b> size and the detectable alternative hypothesis. It can plot graphs of any two of these variables while holding the third constant. Linear or logarithmic axes may be used and multiple curves can be plotted on each graph. Graphs may be copied and pasted into other documents or programs for further editing.|$|E
40|$|Description The package {{contains}} {{functions for}} calculating power,sample size, and minimal detectable mediation effect for testing mediation effect in linear, logistic, poisson, or cox regression. The package also contains functions for calculating <b>power,</b> <b>sample</b> size, and minimal detectable slope for testing the slope {{in a simple}} linear regression (only one predictor) ...|$|E
40|$|Power {{and sample}} size {{determination}} {{has been a}} challenging issue for multiple testing procedures, especially stepwise procedures, mainly because (1) there are several power definitions, (2) power calculation usually requires multivariate integration involving order statistics, and (3) expansion of these power expressions in terms of ordinary statistics, instead of order statistics, is generally a difficult task. Traditionally power and sample size calculations rely on either simulations or some recursive algorithm; neither is straightforward and computationally economic. In this paper we develop explicit formulas for minimal power and r-power of stepwise procedures as well as complete power of single-step procedures for exchangeable and non-exchangeable bivariate and trivariate test statistics. With the explicit power expressions, {{we were able to}} directly calculate the desired power, given sample size and correlation. Numerical examples are presented to illustrate the relationship among <b>power,</b> <b>sample</b> size and correlation. <b>Power</b> <b>Sample</b> size Correlation Multiple tests Order statistics...|$|E
30|$|Where A (experiment) {{represents}} absorbance of wells with cells, CCK- 8 {{solution and}} <b>power</b> <b>samples</b> solution; A (blank) represents absorbance of wells with medium and CCK- 8 solution without cells and A (control) represents absorbance of wells with cells, CCK- 8 solution without <b>power</b> <b>samples</b> solution.|$|R
5000|$|Shy FX & T <b>Power</b> <b>sampled</b> {{the song}} on their album, Set It Off, {{on the track}} [...] "Don't Give A Damn".|$|R
40|$|Abstract—Masking is a side-channel {{countermeasure}} that randomizes side-channel leakage, such as {{the power}} dissipation of a circuit. Masking is only effective {{on the condition that}} the internal random mask remains a secret. Previous research has illustrated how a successful estimation of the mask bit in circuit-level masking leads to successful side-channel attacks. In this paper, we extend this concept to algorithmic masking, which uses multi-bit masks. Our key observation is that the power dissipation of a masked circuit and the mask value are not independent. We exploit this property by using a slice of the <b>power</b> <b>samples</b> obtained by partial selection. This slice has a statistically biased mask, even when the mask signal itself is generated with a uniform distribution. We demonstrate this attack by showing how a perfectly masked AES SBox can be broken using part of the observed <b>power</b> <b>samples,</b> while the same circuit remains secure if we use all of the observed <b>power</b> <b>samples...</b>|$|R
40|$|We {{discuss how}} {{to assess the}} {{performance}} for credit scores {{under the assumption that}} for credit data only a part of the defaults and non-defaults is observed. The paper introduces a criterion that is based on the difference of the score distributions under default and non-default. We show how to estimate bounds for this criterion, the Gini coefficient and the accuracy ratio. Keywords: credit rating, credit score, discriminatory <b>power,</b> <b>sample</b> selection, Gini coefficient, accuracy ratio JEL Classification: G 21...|$|E
40|$|The {{first part}} of this title {{contained}} all statistical tests relevant to starting clinical investigations, and included tests for continuous and binary data, <b>power,</b> <b>sample</b> size, multiple testing, variability, confounding, interaction, and reliability. The current part 2 of this title reviews methods for handling missing data, manipulated data, multiple confounders, predictions beyond observation, uncertainty of diagnostic tests, and the problems of outliers. Also robust tests, non-linear modeling, goodness of fit testing, Bhatacharya models, item response modeling, superiority testing, varia...|$|E
40|$|The non-central Chi-squared {{distribution}} {{can be used}} {{to calculate}} power for tests detecting departure from a null hypothesis. Required sample size can also be calculated because it is proportional to the non-centrality parameter for the distribution. We demonstrate how these calculations can be carried out in Stata using the example of calculating power and sample size for case-control studies of gene-gene and gene-environment interactions. Do-files are available for these calculations. Copyright 2003 by Stata Corporation. gene-environment interaction, gene-gene interaction, <b>power,</b> <b>sample</b> size, study design, non-central Chi-squared...|$|E
50|$|Several {{songs on}} the album make use of film samples. On Doppelgänger and The <b>Power</b> <b>samples</b> of Star Wars can be heard. One (which is a Metallica cover,) {{contains}} samples from Born on the Fourth of July and Disclipes of Disclipine contains samples from Omen III: The Final Conflict.|$|R
40|$|GLIMMPSE is a free, web-based {{software}} tool that calculates <b>power</b> and <b>sample</b> size {{for the general}} linear multivariate model with Gaussian errors ([URL] GLIMMPSE provides a user-friendly interface for the computation of <b>power</b> and <b>sample</b> size. We consider models with fixed predictors, and models with fixed predictors and a single Gaussian covariate. Validation experiments demonstrate that GLIMMPSE matches the accuracy of previously published results, and performs well against simulations. We provide several online tutorials based on research in head and neck cancer. The tutorials demonstrate the use of GLIMMPSE to calculate <b>power</b> and <b>sample</b> size...|$|R
50|$|In September 2009, Foxconn {{announced}} {{it is working}} on smartbook development.In November 2009, a Quanta Computer pre-production Snapdragon <b>powered</b> <b>sample</b> smartbook device that ran Android was unveiled. Companies like Acer Inc. planned to release a smartbook, but due to the popularity of tablets, MacBook Air and Ultrabooks, plans were scrapped.|$|R
30|$|Optimal working {{settings}} for steam <b>power,</b> <b>sample</b> volume and distillation time were initially investigated. The same central composite design as described previously (Lachenmeier et al. 2006) {{was used for}} this purpose. The steam power was varied at levels of 40, 45, 65, 85 and 100  %, the distillation time was varied at levels of 20, 44, 80, 116 and 140  s, and the sample pipetting volume was varied at 5, 14, 28, 41 and 50  mL. The experiment (n =  20) was conducted at both instruments using the same fruit liqueur.|$|E
40|$|We {{discovered}} a superconducting transition with the charge-density-wave {{state in a}} ternary compound Bi 2 Rh 3 Se 2. This compound crystallizes in the parkerite-type structure composed of sheets containing one-dimensional Rh-Rh chains. The electrical resistivity, magnetic susceptibility, thermoelectric <b>power,</b> <b>sample</b> length change, and x-ray diffraction measurements reveal that this compound is in the CDW state below 240 K. Furthermore, the specific heat and electrical resistivity measurements show a superconducting transition at ~ 0. 7 K. The various superconducting parameters were determined, and the GL parameter (0) shows the considerably large value of 151 indicating an extreme type-II superconductor...|$|E
30|$|The first {{experiment}} investigated steam <b>power,</b> <b>sample</b> {{volume and}} distillation time. The factors {{are given in}} coded values, which make the models directly comparable between each other and offer the opportunity to find the importance of each regression term in the model. Significant {{differences between the two}} steam distillation devices were found. The old instrument (Vapodest 30) showed a significant influence of steam power and distillation time, an additional quadratic influence of distillation time, as well as an interaction between steam power and distillation time. The new instrument (Vapodest 200) only showed a significant influence of distillation time as well as an additional quadratic influence of distillation time.|$|E
5000|$|... #Subtitle level 2: Software for <b>power</b> and <b>sample</b> size {{calculations}} ...|$|R
5000|$|GraphPad StatMate {{performs}} <b>power</b> and <b>sample</b> size calculations (Windows and Mac).|$|R
50|$|GURPS Supers is a {{supplement}} of rules for comic-book superhero characters and campaigns for GURPS. The first edition book includes new combat rules, 24 superpowers, bionic superlimbs, gadgets and equipment, and rules for creating new <b>powers,</b> <b>sample</b> heroes and villains, and a briefly described campaign world. The second edition book is revised and corrected.|$|R
30|$|Based on the {{prediction}} results of each components, we then combine these prediction values into a BPNN by taking each component sample data as an input, using the actual wind <b>power</b> <b>sample</b> value as an output {{to train the}} model, and then substituting into the predicted value of each component to ultimately obtain a final wind power prediction value. Finally, we adopt the MAE, MSE, and RMSE as the evaluation indices to compare {{the prediction}} performance of the proposed model, single prediction model (BPNN, ARMA, LS-SVM), and multi-modal prediction model based on EMD and EEMD decomposition. The {{results show that the}} proposed model outperformed the others.|$|E
40|$|There {{will be a}} {{need for}} a wide array of {{chemical}} sensors for biomedical experimentation and for the monitoring of water and air recycling processes on Space Station Freedom. The infrequent logistics flights of the Space Shuttle will necessitate onboard analysis. The advantages of biosensors and chemical sensors over conventional analysis onboard spacecraft are manifold. They require less crew time, space, and <b>power.</b> <b>Sample</b> treatment is not needed. Real time or near-real time monitoring is possible, in some cases on a continuous basis. Sensor signals in digitized form can be transmitted to the ground. Types and requirements for chemical sensors to be used in biomedical experimentation and monitoring of water recycling during long-term space missions are discussed...|$|E
40|$|We {{review the}} current {{understanding}} of the emission line regions in radio galaxies at redshifts z 1. First, we consider {{the evolution of the}} emission line gas properties from the nearby Universe out to z 1. Next, we consider the origin of the ionization and kinematical states of the gas in powerful 3 CR radio galaxies at z 1, and in particular show that these evolve very strongly through the lifetime of the radio source due to the profound e#ect of the passage of the radio source shocks through the interstellar medium of the host galaxy. We show that this dichotomy persists at lower redshifts and also in a lower radio <b>power</b> <b>sample</b> of radio galaxies at the same redshift. We discuss the implications of these results for understanding the nature of the emission line gas and the broader role of jet-cloud interactions...|$|E
40|$|The shock-implantation of gases is {{studied by}} artificially {{shocking}} whole rock and <b>power</b> <b>samples</b> of terrestrial basalt to pressures of 2 - 40 GPa. Ar, Kr, Xe, and Ne were implanted into the silicate. It is {{observed that the}} amount of implanted gas is linearly proportional to its partial pressure over a pressure range of 0. 0001 to 0. 1 atmosphere. The fractionation effect in the implanted gas and the gas diffusion properties are examined. The amounts of gas that would have been implanted with 100 percent efficiency are calculated from the measured porosities of the <b>power</b> <b>samples</b> and are compared to observed abundances. It is determined that the implantation efficiencies are approximately 0. 5 percent at 2 GPa, 7 percent at 5 GPa, and greater than 50 percent at both 20 and 35 GPa. The experimental data correlate with the shock implantation of Martian gases without mass fractionation into the shock-melted phase of meteorite EETA 79001...|$|R
5000|$|PS [...] is an {{interactive}} computer program for performing statistical <b>power</b> and <b>sample</b> size calculations.|$|R
5000|$|Numerous free and/or {{open source}} {{programs}} {{are available for}} performing <b>power</b> and <b>sample</b> size calculations. These include ...|$|R
40|$|The {{short-term}} {{electricity demand}} forecasting {{has become one}} of the major research area in power system engineering. By combining the smart metering to the short term demand forecasting techniques, new features can be added to save on demand and electricity bill. This paper illustrates the methodology used to forecast electricity demand over short period of time which can be used with smart meters. Polynomial fitting with interpolation is used to forecast the demand by taking the apparent <b>power</b> <b>sample</b> points from smart meters. The outcome of this work will be beneficial to the residential or industrial electricity consumers to control the demand side loads. It will help the industrial consumers to save on maximum demand charge with the introduction of warning message or residential consumers to reduce their electricity bill by cutting down non-essential loads in peak hours...|$|E
40|$|Null {{hypothesis}} statistical testing (NHST) {{has been}} debated extensively but always successfully defended. The technical merits of NHST are not disputed in this article. The widespread misuse of NHST {{has created a}} human factors problem that this article intends to ameliorate. This article describes an integrated, alternative inferential confidence interval approach to testing for statistical difference, equiva-lence, and indeterminacy that is algebraically equivalent to standard NHST proce-dures and therefore exacts the same evidential standard. The combined numeric and graphic tests of statistical difference, equivalence, and indeterminacy are designed to avoid common interpretive problems associated with NHST procedures. Mul-tiple comparisons, <b>power,</b> <b>sample</b> size, test reliability, effect size, and cause-effect ratio are discussed. A section on the proper interpretation of confidence intervals {{is followed by a}} decision rule summary and caveats. The long-standing controversy surrounding null hy-pothesis statistical testing (NHST) has typically been argued on its technical merits, and they are not dis...|$|E
40|$|The present review {{introduces}} {{the notion of}} statistical power and the hazard of under-powered studies. The {{problem of how to}} calculate an ideal sample size is also discussed within the context of factors that affect power, and specific methods for the calculation of sample size are presented for two common scenarios, along with extensions to the simplest case. Keywords statistical <b>power,</b> <b>sample</b> size Previous reviews in this series introduced confidence intervals and P values. Both of these have been shown to depend strongly {{on the size of the}} study sample in question, with larger samples generally resulting in narrower confidence intervals and smaller P values. The question of how large a study should ideally be is therefore an important one, but it is all too often neglected in practice. The present review provides some simple guidelines on how best to choose an appropriate sample size...|$|E
40|$|Time {{variations}} of fixed wireless channels {{result from the}} relative movements of scatterers in the propagating environment. We consider the temporal gain {{variations of}} shortrange channels due to scattering from wind-blown leaves. In particular, we present a method for estimating the Doppler spectrum from the received signal's <b>power</b> <b>samples,</b> without requiring the phase information. We then apply the method {{to the results of}} measurements we recently conducted on fixed, shortrange paths...|$|R
30|$|Discussion: This study {{stopped before}} {{recruitment}} could reached the statistically <b>powered</b> <b>sample</b> size of n= 100. Despite this, the {{significant improvement in}} the outcome measures in VAS scores, SF- 12 and EHP- 30 scores were achieved in its present form. In selected population of women presenting to the gynecological clinic with chronic pelvic pain, adhesiolysis in those who had adhesions is of benefit in terms of improvement of their quality of life.|$|R
30|$|Regarding space complexity, the {{dominant}} variables for all algorithms are VMs’ and servers’ {{information such as}} CPU and RAM. No extra information is needed for MBFD. The extra RAM for PABFD is the power utilization model of the servers which is defined by 11 <b>power</b> <b>samples</b> of servers. Thus in the worst case, PABFD need 11 ∗n extra units of memory. Likewise, the proposed algorithms need the peak power of servers to calculate the power-efficiency which takes an extra memory of n units.|$|R
40|$|Abstract: The Melt {{spinning}} {{technique of}} Nano Zinc Oxide/PP/PLA composites filaments fabricated by plasma treated Nano Zinc Oxide（NZOP ） was {{studied in the}} present investigation. The experimental {{results showed that the}} physical and mechanical properties of Nano Zinc Oxide/PP/PLA composites filaments depended on the following factors of the percentage of NZOP, the percentage of maleic anhydride (MAH), the plasma treatment parameters, helium gas flow rate, output <b>power,</b> <b>sample</b> treatment or stationary time and oxygen gas flow rate. Among them the oxygen gas flow rate had the significant influence on the filament properties of tensile modulus, the yield strength, the melting temperature and the crystallization temperature. Stepwise multiple regressions orthogonal design method of system optimization was used to determine the percent of contribution of each factor. It was found that the four indicators were different by these analyses. The experimental results indicated that the optimized conditions by stepwise multiple regressions were better than that by traditional analysis. 1...|$|E
40|$|In this paper, {{we propose}} two {{efficient}} statistical sampling techniques for estimating the total power consumption of large hierarchical circuits. We first show that, {{due to the}} characteristic of sampling efficiency in Monte Carlo simulation, granularity of samples {{is an important issue}} in achieving high overall efficiency. The proposed techniques perform sampling both temporally (across different clock cycles) and spatially (across different modules) so that smaller sample granularity can be achieved while maintaining the normality of samples. The first proposed technique, which {{is referred to as the}} module based approach, samples each module independently when forming a <b>power</b> <b>sample.</b> The second technique, which is referred to as the cluster-based approach, lumps the modules of a system into a number of clusters on which sampling is then performed. Both techniques adapt strati cation to further improve the efficiency. Experimental results show that these techniques provide a reduction of 2 - 3 x in simulation run time compared to existing Monte-Carlo simulation techniques...|$|E
40|$|This work proposes {{the use of}} {{factorial}} design for optimization of microwave-assisted digestion of lubricating oil. The accuracy of digestion procedures is affected by critical experimental parameters, such as sample amount, concentrated acid volumes, microwave radiation applied power, and digestion time. The effects of these key variables on the microwave-assisted digestion efficiency were investigated. The residual carbon content and the acidity were determined in all digestates after microwave-assisted digestion as response of the {{factorial design}}. Calcium, Cu, Mg, P, S, and Zn were determined in oil digestates obtained by using two systems: a cavity- and a focused-oven. The accuracy was checked using one standard reference material, NIST SRM 1848 - Lubricating Oil Additive Package. All determined and certified values are in agreement at a 95 % confidence level. The digestion time, microwave applied <b>power,</b> <b>sample</b> mass, and the interaction between these variables were significant according to P-values when the analysis of variance (ANOVA) was used...|$|E
40|$|This {{paper is}} the final report on DOE-OSS Task ANLE 88002 Fast Air Chamber Calorimetry. '' The task {{objective}} was to design, construct, and test an isothermal air chamber calorimeter for plutonium assay of bulk samples that would meet the following requirements for <b>sample</b> <b>power</b> measurement: average <b>sample</b> measurement time less than 20 minutes. Measurement of <b>samples</b> with <b>power</b> output up to 10 W. Precision of better than 1 % RSD for <b>sample</b> <b>power</b> greater than 1 W. Precision better than 0. 010 watt SD, for <b>sample</b> <b>power</b> less than 1 W. This report gives {{a description of the}} calorimeter hardware and software and discusses the test results. The instrument operating procedure, included as an appendix, gives examples of typical input/output and explains the menu driven software...|$|R
40|$|Imports stats, {{survival}} Description This {{package includes}} {{a set of}} functions to calculate <b>power</b> and <b>sample</b> size for testing main effect or interaction effect in the survival analysis of epidemiological studies (non-randomized studies), {{taking into account the}} correlation between the covariate of the interest and other covariates. Some calculations also take into account the competing risks and stratified analysis. This package also includes a set of functions to calculate <b>power</b> and <b>sample</b> size for testing main effect in the survival analysis of randomized clinical trials...|$|R
40|$|In {{the design}} of {{microarray}} or next-generation sequencing experiments {{it is crucial to}} choose the appropriate number of biological replicates. As often the number of differentially expressed genes and their effect sizes are small and too few replicates will lead to insufficient power to detect these. On the other hand, too many replicates unnecessary leads to high experimental costs. <b>Power</b> and <b>sample</b> size analysis can guide experimentalist in choosing the appropriate number of biological replicates. Several methods for <b>power</b> and <b>sample</b> size analysis have recently been proposed for microarray data. However, most of these are restricted to two group comparisons and require user-defined effect sizes. Here we propose a pilot-data based method for <b>power</b> and <b>sample</b> size analysis which can handle more general experimental designs and uses pilotdata to obtain estimates of the effect sizes. The method can also handle? 2 distributed test statistics which enables <b>power</b> and <b>sample</b> size calculations for a much wider class of models, including high-dimensional generalized linear models which are used, e. g., for RNA-seq data analysis. The performance of the method is evaluated using simulated and experimental data from several microarray and next-generation sequencing experiments. Furthermore, we compare our proposed method for estimation of the density of effect sizes from pilot data with a recent proposed method specific for two group comparisons. © 2013 Walter de Gruyter GmbH, Berlin/Boston...|$|R
