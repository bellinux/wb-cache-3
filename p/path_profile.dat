32|203|Public
5000|$|In telecommunication, a <b>path</b> <b>profile</b> is {{a graphic}} {{representation}} of the physical features of a propagation path in the vertical plane containing both endpoints of the path, showing {{the surface of the}} Earth and including trees, buildings, and other features that may obstruct the radio signal.|$|E
40|$|A core {{equation}} for {{estimation of}} fuel burn from <b>path</b> <b>profile</b> data was developed. This equation {{was used as}} a necessary ingredient in a dynamic program to define a fuel efficient flight path. The resultant algorithm is oriented toward use by general aviation. The pilot provides a description of the desired ground track, standard aircraft parameters, and weather at selected waypoints. The algorithm then derives the fuel efficient altitudes and velocities at the waypoints...|$|E
40|$|Recently, {{there has}} been a growing {{interest}} in exploiting profile information in adaptive systems such as just-in-time compilers, dynamic optimizers and, binary translators. In this paper, we show that sophisticated software profiling schemes that provide highly accurate information in an offline setting are ill-suited for these dynamic code generation systems. We experimentally demonstrate that hot path predictions must be made early in order to control the rising cost of missed opportunity that result from the prediction delay. We also show that existing sophisticated path profiling schemes, if used in an online setting, offer no prediction advantages over simpler schemes that exhibit much lower runtime overheads. Based on these observation we developed a new low-overhead software profiling scheme for hot path prediction. Using an abstract metric we compare our scheme to <b>path</b> <b>profile</b> based prediction and show that our scheme achieves comparable prediction quality. In our second set of experiments we include runtime overhead and evaluate the performance of our scheme in a realistic application: Dynamo, a dynamic optimization system. The results show that our prediction scheme clearly outperforms <b>path</b> <b>profile</b> based prediction and thus confirm that less profiling as exhibited in our scheme will actually lead to more effective hot path prediction. 1...|$|E
40|$|Software {{testing is}} {{extensively}} used for uncovering bugs in large, complex software. Testing relies on well designed regression test suites that anticipate all reasonable software usage scenarios. Unfortunately, testers today {{have no way}} of knowing how much of real-world software usage was untested by their regression suite. Recent advances in low-overhead <b>path</b> <b>profiling</b> provide the opportunity to rectify this deficiency and perform residual <b>path</b> <b>profiling</b> on deployed software. Residual <b>path</b> <b>profiling</b> identifies all <b>paths</b> executed by deployed software that were untested during software development. We extend prior research to perform low-overhead interprocedural <b>path</b> <b>profiling.</b> We demonstrate experimentally that low-overhead <b>path</b> <b>profiling,</b> both intraprocedural and interprocedural, provides valuable quantitative information on testing effectiveness. We also show that residual edge profiling is inadequate as a significant number of untested paths include no new untested edges...|$|R
40|$|Writing correct {{programs}} is hard. Proving {{that they are}} correct is even harder. Consequently, testing is extensively used for un-covering bugs in large, complex software. Since testing software exhaustively is infeasible, well designed regression test suites aim to anticipate all reasonable software usage scenarios and generate test cases that exercise those behaviors. Unfortunately, testers to-day {{have no way of}} knowing how much of real-world software usage was untested by their regression suite. While collecting <b>path</b> <b>profiles</b> of deployed software would provide this information, profiling over-heads preclude this. This often results in released software shipping with bugs that could have been detected with a better test suite. Recent advances in low-overhead <b>path</b> <b>profiling</b> provide the oppor-tunity to rectify this deficiency and perform residual <b>path</b> <b>profiling</b> on deployed software. Residual <b>path</b> <b>profiling</b> identifies all <b>paths</b> executed by deployed software that were untested during software development. We extend prior research to perform low-overhead in-terprocedural <b>path</b> <b>profiling.</b> We demonstrate experimentally that low-overhead <b>path</b> <b>profiling,</b> both intraprocedural and interproce-dural, provides valuable quantitative information on testing effec-tiveness. We also show that residual edge profiling is inadequate as a significant number of untested paths include no new untested edges...|$|R
40|$|The goal of {{our project}} {{is to look at}} what we will call “incremental <b>path</b> profiling”. <b>Path</b> <b>profiling</b> is an {{important}} part of compiler optimization; however, its computational overhead is quite high. Our project’s aim is to lessen the computational overhead of <b>path</b> <b>profiling</b> while still providing useful information about the hot paths of the program being compiled. We will do this by incrementally increasing the number of <b>paths</b> we <b>profile</b> by slowly adding instrumentation along high-use paths. By doing this, we hope to show that partial instrumentation of paths incurs less overhead than full <b>path</b> <b>profiling</b> while still providing enough information about which paths are hot to be useful in optimizations. 3. 2 Background <b>Path</b> <b>profiles</b> can be used by compilers for better optimization of programs. In particular, the “hot path”, the most frequently taken path through a function, can receive special treatment that results in faster execution (Ammons & Larus, 1998). While somewhat impractical for normal compilers, these optimizations are commonly performed by modern Just in Time (JIT) compilers. Unfortunately, <b>path</b> <b>profiling</b> is expensive. For example, the original “efficient ” algorithm proposed by Ball & Larus (1996) is reported by the author...|$|R
40|$|In {{the present}} work we {{considered}} three different sintered duplex stainless steels. Their fatigue crack propagation resistance was investigated {{by means of}} fatigue crack propagation tests according to ASTM E 647 standard, considering three different stress ratios (R = Kmin/Kmax). Crack surfaces were extensively analysed {{by means of a}} scanning electron microscope. Crack paths were investigated by means of a crack <b>path</b> <b>profile</b> analysis performed by means of an optical microscope. In order to analyse alfa/gamma volume fractions and micropores influence, da/dN-deltaK fatigue crack propagation results were compared with profile an fracture surface analysis...|$|E
40|$|In {{this paper}} we {{introduce}} a runtime, non-trace based algorithm {{to compute the}} critical <b>path</b> <b>profile</b> of the execution of a message passing parallel program. Our algorithm permits starting or stopping the critical path computation during program execution and reporting intermediate values. We also present an online algorithm to compute a variant of critical path, called critical path zeroing, that measures the reduction in application execution time that improving a selected procedure will have. Finally, we present a brief case study to quantify the runtime overhead of our algorithm and to show that online critical path profiling ca...|$|E
40|$|The paper {{deals with}} the Triscan concept - a dual-antenna {{microwave}} landing guidance system, using triangulation for close-in accuracy - developed to facilitate the landing of VTOL aircraft on ships in all-weather conditions. Analysis of the navigation performance of an onboard system receiving data from Triscan and data-linked information regarding {{the motion of the}} ship showed that the approach navigation performance depends on the approach <b>path</b> <b>profile</b> flown, the magnitude of the measurement bias error, and the navigation system's knowledge of the shipboard landing pad motion, which was implemented through the concept of a landing pad deviation vector...|$|E
40|$|<b>Path</b> <b>profiles</b> {{provide a}} more {{accurate}} characterization of a program&s dynamic behavior than basic block or edge profiles, but are relatively more expensive to collect. This has limited their use in practice despite demonstrations of their advantages over edge profiles {{for a wide variety}} of applications. We present a new algorithm called preferential <b>path</b> <b>profiling</b> (PPP), that reduces the overhead of <b>path</b> <b>profiling.</b> PPP leverages the observation that most consumers of <b>path</b> <b>profiles</b> are only interested in a subset of all program paths. PPP achieves low overhead by separating interesting paths from other paths and assigning a set of unique and compact numbers to these interesting paths. We draw a parallel between arithmetic coding and path numbering, and use this connection to prove an optimality result for the compactness of path numbering produced by PPP. This compact path numbering enables our PPP implementation to record path information in an array instead of a hash table. Our experimental results indicate that PPP reduces the runtime overhead of <b>profiling</b> <b>paths</b> exercised by the largest (ref) inputs of the SPEC CPU 2000 benchmarks from 50 % on average (maximum of 132...|$|R
40|$|Abstract—Call <b>path</b> <b>profiling</b> is a {{scalable}} {{measurement technique}} {{that has been}} shown to provide insight into the performance characteristics of complex modular programs. However, poor presentation of accurate and precise call <b>path</b> <b>profiles</b> obscures insight. To enable rapid analysis of an execution’s performance bottlenecks, we make the following contributions for effectively presenting call <b>path</b> <b>profiles.</b> First, we combine a relatively small set of complementary presentation techniques to form a coherent synthesis that is greater than the constituent parts. Second, we extend existing presentation techniques to rapidly focus an analyst’s attention on performance bottlenecks. In particular, we (1) show how to scalably present three complementary views of callingcontext-sensitive metrics; (2) treat a procedure’s static structure as first-class information with respect to both performance metrics and constructing views; (3) enable construction of a large variety of user-defined metrics to assess performance inefficiency; and (4) automatically expand hot paths based on arbitrary performance metrics — through calling contexts and static structure — to rapidly highlight important program contexts. Our work is implemented within HPCTOOLKIT, which collects call <b>path</b> <b>profiles</b> using low-overhead asynchronous sampling. I...|$|R
40|$|Critical <b>Path</b> <b>Profiling</b> is a {{technique}} that provides guidance to help programmers try to improve the running time of their program. However, Critical <b>Path</b> <b>Profiling</b> provides only an upper bound estimate of the improvement possible in a parallel program execution. In this paper, we present a new metric, called Slack, to complement Critical Path and provide additional information to parallel programmers about {{the potential impact of}} making improvements along the critical path. 1...|$|R
40|$|While {{classical}} {{control theory}} has been demonstrated to be highly successful in many manufacturing technology applications, there are shortcomings when applied to processes that require the intuitive skills of a human operator. Fuzzy logic technique can be a significant aid in enabling machine systems to imitate the control stategy of an operator and so achieve an efficient control function. Commencing with {{the basic principles of}} fuzzy logic theory, the paper provides a practical guide to the design techniques used to establish fuzzy controller. An example of a welding robot to achieve an irregular weld <b>path</b> <b>profile</b> is used to illustrate the procedure. PublishedN/...|$|E
40|$|For {{aggressive}} path-based optimizations to {{be profitable}} in cost-senstive environments, accurate path profiles must {{be available at}} low overheads. In this paper, we propose a low-overhead, programmable hardware path profiling scheme that can be configured to (1) detect a variety of paths including acyclic, intraprocedural paths, extended paths and sub-paths for the Whole Program Path and (2) track {{one of the many}} architectural metrics along paths. The profiler consists of a path stack that detects paths using branch information from the processor pipeline and a Hot Path Table that records the <b>path</b> <b>profile</b> during program execution. Our experiments using programs from the SPECCPU 2000 benchmark suite show that the path profiler occupying 7 KB of hardware real-estate collects accurate path profiles at negligible overheads (0. 6...|$|E
40|$|In this paper, we {{introduce}} a runtime, nontrace-based algorithm {{to compute the}} critical <b>path</b> <b>profile</b> of the execution of message passing and shared-memory parallel programs. Our algorithm permits starting or stopping the critical path computation during program execution and reporting intermediate values. We also present an online algorithm to compute a variant of critical path, called critical path zeroing, that measures the reduction in application execution time that improving a selected procedure will have. Finally, we present a brief case study to quantify the runtime overhead of our algorithm and to show that online critical path profiling {{can be used to}} find program bottlenecks. Index Terms [...] -Parallel and distributed processing, measurement, tools, program tuning, on-line evaluation. [...] ##p## [...] 1 INTRODUCTION N performance tuning parallel programs, simple sums of sequential metrics, such as CPU utilization, do not [...] ...|$|E
40|$|Since their introduction, <b>path</b> <b>profiles</b> {{have been}} used to guide the {{application}} of aggressive code optimizations and performing instruction scheduling. However, for optimization and scheduling, it is often desirable to obtain frequency counts of paths that extend across loop iterations and cross procedure boundaries. These longer paths, referred to as interesting paths in this paper, account for over 75 % of the flow in a subset of SPEC benchmarks. Although the frequency counts of interesting paths can be estimated from <b>path</b> <b>profiles,</b> the degree of imprecision of these estimates is very high. We extend Ball Larus (BL) paths to create slightly longer overlapping paths and develop an instrumentation algorithm to collect their frequencies. While these paths are slightly longer than BL paths, they enable very precise estimation of frequencies of potentially much longer interesting paths. Our experiments show that the average cost of collecting frequencies of overlapping paths is 86. 8 % which is 4. 2 times that of BL paths. However, while the average imprecision in estimated total flow of interesting paths derived from BL path frequencies ranges from- 38 % to + 138 %, the average imprecision in flow estimates derived from overlapping path frequencies ranges only from- 4 % to + 8 %. Keywords- <b>path</b> <b>profiles,</b> overlapping <b>path</b> <b>profiles,</b> profile guided optimization, and instruction scheduling. ...|$|R
50|$|He {{has written}} many papers {{and has an}} h-index of 54. One of his best known papers is his paper on {{efficient}} <b>path</b> <b>profiling.</b>|$|R
40|$|Abstract Many {{features}} of modern architectures, such as Performance Monitering Units (PMUs), can be leveraged forefficient program profiling. We present several simple heuristics to estimate <b>path</b> <b>profiles</b> from sampled partial paths {{which can be}} collected at runtime. Like recent work [13], we show {{that we can find}} 80 - 90 % of the hot paths within aprogram using these techniques. However, we also find that despite this high accuracy in identifying hot paths, using estimated paths to perform superblock formation does not necessarily yield an equivalent boost in performance. Weevaluate how estimated <b>path</b> <b>profiles</b> impact superblock formation in the CASH compiler. In addition, we compare superblocks to hyperblocks and demonstrate that predicate calculation overhead can cause maximal hyperblocks tohave inferior performance. 1 Introduction and Motivation Profiles of a program's runtime behavior, such as instruction, edge, or path counts, provide valuable information thatenables a number of optimizations, such as trace scheduling [8], superblock formation [9], code positioning [12], and improved function inlining [6]. Moreover, a number of dynamic optimization systems [3, 7] use execution profiles tocontinuously optimize programs in the face of changing or phase-oriented workloads. <b>Path</b> <b>profiles</b> are especially useful because they capture correlation among different branches in program traces. Traditionally, accurate <b>path</b> <b>profiles</b> are collected by explicitly instrumenting program code, such as in [4]. However, instrumentation usually degrades performance too much to include in production code, sometimes limiting path pro-files to unrealistic or unpredictable workloads. For example, Ball and Larus [4] noted that even efficient <b>path</b> <b>profiling</b> incurred an overhead of 31 %...|$|R
40|$|In this work, an {{accurate}} method {{to determine the}} total signal field spread at the receiver, {{under the influence of}} channel effects due to city street canyons, is proposed. Multiple rays are considered based on the <b>path</b> <b>profile</b> they have traversed to the receiver. The developed formulations to determine path loss or signal strength degradation, take into account the reflection and diffraction coefficients resulting from signal waves impinging geometrical as well as reflective surfaces within the street canyons. The results from computed formulations are compared with measured results in specific environments with similar electrical characteristics to the parameters used in the model. From these results it is possible to determine whether a cellular network within a city central business district requires either a micro-cell or Pico-cell to increase capacity and minimize signal degradation at the receiver within a given area...|$|E
40|$|A <b>path</b> <b>profile</b> {{determines how}} many times each acyclic path in a routine executes. This type of {{profiling}} subsumes the more common basic block and edge profiling, which only approximate path frequencies. Path profiles have many potential uses in program performance tuning, profile-directed compilation, and software test coverage. This paper describes a new algorithm for path profiling. This simple, fast algorithm selects and places profile instrumentation to minimize run-time overhead. Instrumented programs run with overhead comparable to the best previous profiling techniques. On the SPEC 95 benchmarks, path profiling overhead averaged 31 %, as compared to 16 % for efficient edge profiling. Path profiling also identifies longer paths than a previous technique, which predicted paths from edge profiles (average of 88, versus 34 instructions). Moreover, profiling shows that the SPEC 95 train input datasets covered most of the paths executed in the ref datasets. This research supported by: W [...] ...|$|E
40|$|We {{present a}} <b>path</b> <b>profile</b> guided partial dead code {{elimination}} algorithm that uses predication to enable sinking {{for the removal}} of deadness along frequently executed paths at the expense of adding additional instructions along infrequently executed paths. Our approach to optimization is particularly suitable for VLIW architectures since it directs the efforts of the optimizer towards aggressively enabling generation of fast schedules along frequently executed paths by reducing their critical path lengths. The paper presents a cost-benefit data flow analysis that uses path profiling information to determine the profitability of using predication enabled sinking. The cost of predication enabled sinking of a statement past a merge point is determined by identifying paths along which an additional statement is introduced. The benefit of predication enabled sinking is determined by identifying paths along which additional dead code elimination is achieved due to predication. The results [...] ...|$|E
40|$|<b>Path</b> <b>profiles</b> {{record the}} {{frequencies}} of execution paths through a program. Until now, the best global instruction schedulers have relied upon profile-gathered frequencies of conditional branch directions to select sequences of basic blocks that only approximate the frequently-executed program paths. The identified sequences are then enlarged using the profile data to improve the scope of scheduling. Finally, the enlarged regions are compacted so that they complete in {{a small number of}} cycles. <b>Path</b> <b>profiles</b> remove the need to approximate the frequently-executed paths that are so important {{to the success of the}} compaction phase. In this paper, we describe how one can modify a trace-based instruction scheduler, and in particular a superblock scheduler, to use <b>path</b> <b>profiles</b> in both the selection and enlargement phases of global scheduling. As our experimental results demonstrate, the use of more detailed profile data allows the scheduler to construct superblocks that are more likely to avo [...] ...|$|R
40|$|Call <b>path</b> <b>profiling</b> {{associates}} resource consumption {{with the}} calling {{context in which}} resources were consumed. We describe the design and implementation of a low-overhead call path profiler based on stack sampling. The profiler uses a novel sample-driven strategy for collecting frequency counts for call graph edges without instrumenting every procedure’s code to count them. The data structures and algorithms used are efficient enough to construct the complete calling context tree exposed during sampling. The profiler leverages information recorded by compilers for debugging or exception handling to record call <b>path</b> <b>profiles</b> even for highly-optimized code. We describe an implementation for the Tru 64 /Alpha platform. Experiments profiling the SPEC CPU 2000 benchmark suite demonstrate the low (2 %- 7 %) overhead of this profiler. A comparison with instrumentation-based profilers, such as gprof, showsthat for call-intensive programs, our sampling-based strategy for call <b>path</b> <b>profiling</b> has over {{an order of magnitude}} lower overhead. 1...|$|R
40|$|Most {{dynamic program}} {{analysis}} {{techniques such as}} proﬁle-driven compiler optimizations, software testing and runtime property checking infer program properties by proﬁling one or more executions of a program. Unfortunately, program proﬁling does not come for free. For example, even the most eﬃcient techniques for <b>proﬁling</b> acyclic, intra-procedural <b>paths</b> can slow down program execution {{by a factor of}} 2. In this thesis, we propose techniques that signiﬁcantly lower the overheads of <b>proﬁling</b> <b>paths,</b> enabling the use of path-based dynamic analyzes in cost-sensitive environments. Preferential <b>path</b> <b>proﬁling</b> (PPP) is a novel software-only <b>path</b> <b>proﬁling</b> scheme that eﬃciently proﬁles given subsets of paths, which we refer to as interesting paths. The algorithm is based on the observation that most consumers of <b>path</b> <b>proﬁles</b> are only interested in proﬁling a small set of paths known a priori. Our algorithm {{can be viewed as a}} generalization of the Ball-Larus <b>path</b> <b>proﬁling</b> algorithm. Whereas the Ball-Larus algorithm assigns weights to the edges of a given CFG such that the sum of the weights of the edges along each path through the CFG is unique, our algorithm assigns weights to the edges such that the sum of the weights along the edges of interesting paths is unique. Furthermore, our algorithm attempts to achieve a minimal and compact encoding of the interesting paths; such an encoding signiﬁcantly reduces the overheads of <b>path</b> <b>proﬁling</b> by eliminating expensive hash operations during proﬁling. Interestingly, we ﬁnd that both the Ball-Larus algorithm and PPP are essentially a form of arithmetic coding. We use this connection to prove that the numbering produced by PPP is optimal. We also propose a programmable, non-intrusive hardware path proﬁler (HPP). The hardware proﬁler consists of a path detector that detects paths by monitoring the stream of retiring branch instructions emanating from the processor pipeline. The path detector can be programmed to detect various types of paths and track architectural events that occur along paths. The second component of the hardware proﬁling infrastructure is a Hot Path Table (HPT), that collects accurate hot <b>path</b> <b>proﬁles.</b> Our experimental evaluation shows that PPP reduces the overheads of <b>proﬁling</b> <b>paths</b> to 15 % on average (with a maximum of 26 %). The algorithm can be easily extended to <b>proﬁle</b> inter-procedural <b>paths</b> at minimal additional overheads (average of 26 %). We modeled HPP using a cycle-accurate superscalar processor simulator and ﬁnd that HPP generates accurate <b>path</b> <b>proﬁles</b> at extremely low overheads (0. 6 % on average) with a moderate hardware budget. We also evaluated the use of PPP and HPP in a realistic proﬁling scenarios. We ﬁnd that the proﬁles generated by HPP can eﬀectively replace expensive proﬁles used in proﬁle-driven optimizations. We also ﬁnd that even well-tested programs tend to exercise a large number of untested paths in the ﬁeld, emphasizing the need for eﬃcient proﬁling schemes that can be deployed in production environments...|$|R
40|$|Many compilers use {{profiles}} of programs {{to direct the}} focus and degree of performance optimizations. Profiles are statistics from program runs, usually collected at individual points in the program text, e. g., branches, call sites, or memory accesses. But optimizations based on individual sample points in the program miss an important detail of program behavior: how pieces of the program {{relate to each other}} dynamically. A <b>path</b> <b>profile</b> collects statistics over paths (sequences of points) in the program, linking the statistics to the dynamic behavior. By instrumenting and collecting path profiles through a program, we can exploit this dynamic behavior, improving performance more than point profiling techniques have allowed. This thesis shows how to collect path profiles efficiently, then applies the path profiles to two optimizations, static correlated branch prediction and path-based superblock scheduling. These two optimizations address different performance aspects of modern machine [...] ...|$|E
40|$|While {{programs}} {{contain a}} large number of paths, a very small fraction of these paths are typically exercised during program execution. Thus, optimization algorithms should be designed to trade off the performance of less frequently executed paths in favor of more frequently executed paths. However, traditional formulations to code optimizations are incapable of performing such a trade-off. We present a <b>path</b> <b>profile</b> guided partial redundancy elimination algorithm that uses speculation to enable the removal of redundancy along more frequently executed paths at the expense of introducing additional expression evaluations along less frequently executed paths. We describe cost-benefit data flow analysis that uses path profiling information to determine the profitability of using speculation. The cost of enabling speculation of an expression at a conditional is determined by identifying paths along which an additional evaluation of the expression is introduced. The benefit of enabling specul [...] ...|$|E
40|$|Multipath fading is the {{dominant}} propagation factor for fixed terrestrial microwave line-of-sight (LOS) radio links operating at frequencies below 10 GHz. Fading due to multipath propagation attenuates received signals on line-of-sight links and thereby impair the performance of point-to-point systems. Several methods are used to reduce the effects of multipath fading without or {{with the need for}} diversity. Antenna spacing in spacing diversity {{is one of the most}} effective methods of mitigating multipath fading. This paper provides an evaluation of the concept of two antenna space-diversity configuration for fixed terrestrial microwave line-of-sight radio links. Multipath fading events due to multipath arising from ground reflection points have been analysed along the terrain <b>path</b> <b>profile.</b> A spatial diversity with two antenna configuration in different antenna heights above ground level is simulated over sample fixed terrestrial microwave line-of-sight radio links. The results have been evaluated in terms of the available signal power at the receiver. © 2015 IEEE...|$|E
30|$|Then, the {{simulation}} has been repeated by introducing a three <b>paths</b> <b>profile</b> with PDP = [0,− 3,− 6] dB. This way, the system simultaneously includes nonlinearity and multipath. The {{performance of the}} complete system is also shown in Figure 23.|$|R
40|$|For {{aggressive}} path-based program optimizations to {{be profitable}} in cost-sensitive environments, accurate <b>path</b> <b>profiles</b> must {{be available at}} low overheads. In this paper, we propose a low-overhead, non-intrusive hardware <b>path</b> <b>profiling</b> scheme that can be programmed to detect several types of paths including acyclic, intra-procedural paths, extended paths and sub-paths for the Whole Program Path. The profiler consists of a path stack, which detects paths and generates a sequence of path descriptors using branch information from the processor pipeline, and a hot path table that collects a <b>profile</b> of hot <b>paths</b> for later use by a program optimizer. With assistance from the processor’s event detection logic, our profiler can track a host of architectural metrics along paths, enabling context-sensitive performance monitoring and bottleneck analysis. We illustrate the utility of our scheme by associating paths with a power metric that estimates power consumption in the cache hierarchy caused by instructions along the path. Experiments using programs from the SPECCPU 2000 benchmark suite show that our path profiler, occupying 7 KB of hardware real-estate, collects accurate <b>path</b> <b>profiles</b> (average overlap of 88 % with a perfect profile) at negligible execution time overheads (0. 6 % on average). 1...|$|R
40|$|Many {{features}} of modern architectures, such as Performance Monitering Units (PMUs), can be leveraged for efficient program profiling. We present several simple heuristics to estimate <b>path</b> <b>profiles</b> from sampled partial paths {{which can be}} collected at runtime. Like recent work [13], we show {{that we can find}} 80 - 90 % of the hot paths within a program using these techniques. However, we also find that despite this high accuracy in identifying hot paths, using estimated paths to perform superblock formation does not necessarily yield an equivalent boost in performance. We evaluate how estimated <b>path</b> <b>profiles</b> impact superblock formation in the CASH compiler. In addition, we compare superblocks to hyperblocks and demonstrate that predicate calculation overhead can cause maximal hyperblocks to have inferior performance. ...|$|R
40|$|In this paper, {{we present}} a {{technique}} for reducing the overhead of collecting path profiles {{in the context of}} a dynamic optimizer. The key idea to our approach, called Targeted Path Profiling (TPP), is to use an edge profile to simplify the collection of a <b>path</b> <b>profile.</b> This notion of profileguided profiling is a natural fit for dynamic optimizers, which typically optimize the code in a series of stages. TPP is an extension to the Ball-Larus Efficient Path Profiling algorithm. Its increased efficiency comes from two sources: (i) reducing the number of potential paths by not enumerating paths with cold edges, allowing array accesses to be substituted for more expensive hash table lookups, and (ii) not instrumenting regions where paths can be unambiguously derived from an edge profile. Our results suggest that on average the overhead of profile collection can be reduced by half (SPEC 95) to almost two-thirds (SPEC 2000) relative to the Ball-Larus algorithm with minimal impact on the information collected. 1...|$|E
40|$|Stainless steels are {{attractive}} materials for many applications (e. g. petrochemical industry, chemical and nuclear plants, marine environment, desalination, etc.). They are sometimes characterized by considerable difficulties from the manufacturing point of view, and powder metallurgy offers an excellent alternative to produce these steels. Sintered stainless steels {{are characterized by}} the presence of micropores and by different microstructures that depend on the sintering procedures (powders, sintering temperature and duration, etc.). In the present work we consider five different sintered stainless steels, characterized by different microstructures: fully ferritic, fully austenitic, ferritic austenitic, ferritic austenitic martensitic (two different volume fractions). Their fatigue crack propagation resistance is investigated by means of fatigue crack growth tests according to ASTM E 647 standard, considering a stress ratio value (R = K-min/ K-max) equal to 0. 1. Crack propagation micromechanisms are examined through both fracture surface analyses (by means of a scanning electron microscope) and crack <b>path</b> <b>profile</b> analyses (by means of an optical microscope) ...|$|E
40|$|Abstract — In {{this paper}} we report some {{investigations}} {{on the problem}} of controlling isomerization for small poly-atomic non–rigid molecules, using the LiNC/LiCN system as an example. Two methods of control in the classical en-semble of LiNC/LiCN system are described and analyzed by performing computer simulations for the corresponding canonical ensemble. The first method is based on control-ling the total energy. The second one is based on changing the minimum energy <b>path</b> <b>profile,</b> and the potential energy surface for a certain “representative ” configurations of the molecule. The algorithm used in both cases is based on the speed–gradient principle. The control function obtained in the classical mechanical study, with the total energy con-trol algorithm, is subsequently applied to the quantum me-chanical ensemble of LiNC/LiCN molecules. The quantum mechanical calculations are carried out within a finite basis approximation, consisting of 14 energy levels and the corre-sponding eigenfunctions. A comparison between the simu-lation results for the classical and quantum models shows a reasonable similarity in the performance on the control. I...|$|E
40|$|In <b>path</b> <b>profiling,</b> {{a program}} is {{instrumented}} with code that counts {{the number of}} times particular path fragments of the program are executed. This paper extends the intraprocedural path-profiling technique of Ball and Larus to collect information about interprocedural paths (i. e., paths that may cross procedure boundaries) ...|$|R
40|$|The speed-up {{estimation}} of parallelized code {{is crucial to}} efficiently compare different parallelization techniques or task graph transformations. Unfortunately, most of the time, during the parallelization of a specification, the {{information that can be}} extracted by profiling the corresponding sequential code (e. g. the most executed paths) are not properly taken into account. In particular, correlating sequential <b>path</b> <b>profiling</b> with the corresponding parallelized code can help in the identification of code hot spots, opening new possibilities for automatic parallelization. For this reason, starting from a well-known profiling technique, the Efficient <b>Path</b> <b>Profiling,</b> we propose a methodology that estimates the speed-up of a parallelized specification, just using the corresponding hierarchical task graph representation and the information coming from the dynamic profiling of the initial sequential specification. Experimental results show that the proposed solution outperforms existing approaches...|$|R
40|$|Prior {{work has}} found call <b>path</b> <b>profiles</b> {{to be useful}} for optimizers and programmer-productivity tools. Unfortunately, {{previous}} approaches for collecting <b>path</b> <b>profiles</b> are expensive: they need to either execute additional instructions (to track calls and returns) or they need to walk the stack. The state-of-the-art techniques for call <b>path</b> <b>profiling</b> slow down the program by 7 % (for C programs) and 20 % (for Java programs). This paper describes an innovative technique that collects minimal information from the running program and later (offline) infers the full call paths from this information. The key insight behind our approach is that readily available information during program execution—the height of the call stack and {{the identity of the}} current executing function—are good indicators of calling context. We call this pair a context identifier. Because more than one call path may have the same context identifier, we show how to disambiguate context identifiers by changing the sizes of function activation records. This disambiguation has no overhead in terms of executed instructions. We evaluate our approach on the SPEC CPU 2006 C++ and C benchmarks. We show that collecting context identifiers slows down programs by 0. 17 % (geometric mean). We can map these context identifiers to the correct unique call path 80 % of the time for C++ programs and 95 % of the time for C programs...|$|R
