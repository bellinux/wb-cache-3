49|720|Public
50|$|The SSA {{includes}} quantitative FMEA, {{which is}} summarized into FMES. Normally FMES probabilities {{are used in}} quantitative FTA {{to demonstrate that the}} hazard <b>probability</b> <b>limits</b> are in fact met. Cutset analysis of the fault trees demonstrates that no single failure condition will result in a hazardous or catastrophic event. The SSA may include the results of all safety analysis and be one document or may be many documents. An FTA is only one method for performing the SSA. Other methods include dependence diagram or reliability block diagram and Markov Analysis.|$|E
50|$|The PSSA {{may contain}} {{qualitative}} FTA, {{which can be}} used to identify systems requiring redundancy so that catastrophic events do not result from a single failure (or dual failure where one is latent). A fault tree is prepared for each SFHA hazard rated hazardous or catastrophic. Fault trees may be performed for major hazards if warranted. DALs and specific safety design requirements are imposed on the subsystems. The safety design requirements are captured and traced. These may include preventive or mitigation strategies selected for particular subsystems. The PSSA and CCA generate separation requirements to identify and eliminate common mode failures. Subsystem failure rate budgets are assigned so that hazard <b>probability</b> <b>limits</b> can be met.|$|E
5000|$|Alternatively, one {{may recall}} that trembles {{are to be}} {{interpreted}} as modelling mistakes made by the players with some negligible probability when the game is played. Such a mistake would most likely consist of a player making another move than the one intended {{at some point during}} play. It would hardly consist of the player choosing another strategy than intended, i.e. a wrong plan for playing the entire game. To capture this, one may define the perturbed game by requiring that every move at every information set is taken with non-zero <b>probability.</b> <b>Limits</b> of equilibria of such perturbed games as the tremble probabilities goes to zero are called extensive-form trembling hand perfect equilibria.|$|E
3000|$|..., {{which is}} not {{taken into account in}} the outage <b>probability</b> <b>limit.</b> Therefore, we argue that the outage <b>probability</b> <b>limit</b> is in general not {{achievable}} by a JNCC, which is illustrated by means of an example.|$|R
30|$|To {{assess the}} {{performance}} of the SMARC-JNCC we need to compare it with the outage <b>probability</b> <b>limit</b> (Section “Calculation of the outage probability”). We show that the outage <b>probability</b> <b>limit</b> is not always tight and we propose a tighter lower bound, which is presented in Section “Calculation of a tighter lower bound on WER”.|$|R
3000|$|On {{the basis}} of pre-set risk <b>probability</b> <b>limiting</b> values, project {{activity}} risk is defined in the proposed three-dimensional risk analysis: [...]...|$|R
40|$|Abstract. It has {{recently}} been shown that the marginalization paradox (MP) can be resolved by interpreting improper inferences as <b>probability</b> <b>limits.</b> The key to the resolution is that <b>probability</b> <b>limits</b> need not satisfy the formal Bayes ’ law, which {{is used in the}} MP to deduce an inconsistency. In this paper, I explore the differences between <b>probability</b> <b>limits</b> and the more familiar pointwise limits, which do imply the formal Bayes ’ law, and show how these differences underlie some key differences in the interpretation of the MP...|$|E
40|$|It has {{recently}} been shown that the marginalization paradox (MP) can be resolved by interpreting improper inferences as <b>probability</b> <b>limits.</b> The key to the resolution is that <b>probability</b> <b>limits</b> need not satisfy the formal Bayes' law, which {{is used in the}} MP to deduce an inconsistency. In this paper, I explore the differences between <b>probability</b> <b>limits</b> and the more familiar pointwise limits, which do imply the formal Bayes' law, and show how these differences underlie some key differences in the interpretation of the MP. Comment: Presented at Maxent 2007, Saratoga Springs, NY, July 200...|$|E
30|$|Furthermore, we can {{use these}} <b>probability</b> <b>limits</b> to compare the {{relative}} bias in the OLS and CE estimators. The following proposition follows immediately from a comparison of equations (3) and (9).|$|E
2500|$|Convergence in {{probability}} is {{denoted by}} adding the letter p over an arrow indicating convergence, or using the “plim” <b>probability</b> <b>limit</b> operator: ...|$|R
30|$|For group {{comparisons}} and paired comparisons, paired t {{tests were}} applied with an error <b>probability</b> <b>limit</b> of 0.05. A linear {{regression analysis was}} performed as well.|$|R
3000|$|... (see Equation 6), {{which is}} not {{taken into account in}} the outage <b>probability</b> <b>limit.</b> In fact, in Proposition 1, it was proved that the maximal {{diversity}} order does not depend on R [...]...|$|R
40|$|Abstract: Many process {{characteristics}} follow exponential distribution and control charts {{based on such}} a distribution have attracted a lot of attention. Traditional control limits may be not appropriate {{because of the lack}} of symmetry. In this paper, process monitoring through a normalizing power transformation is studied. The traditional individual measurements control charts can be used based on the transformed data. The properties of this control chart are investigated. Comparison with the chart using <b>probability</b> <b>limits</b> is also carried out for the cases of known and estimated parameter. Without losing much accuracy even compared with the exact <b>probability</b> <b>limits,</b> the power transformation approach can easily be used to produce charts that can be interpreted when the normality assumption is valid...|$|E
40|$|This short note derives the <b>probability</b> <b>limits</b> {{of several}} estimators for panel AR(1) models under misspecification using {{sequential}} asymptotics. The {{results show that}} GMM estimators based on the forward orthogonal deviation transformation converge to the first-order autocorrelation coefficient, (C) 2008 Elsevier B. V. All rights reserved...|$|E
40|$|In {{this paper}} we provide a {{systematic}} {{study of the}} robustness of <b>probability</b> <b>limits</b> and central limit theory for realised multipower variation when we add finite activity and infinite activity jump processes to an underlying Brownian semimartingale. Bipower variation, Infinite activity, Multipower variation, Power variation, Quadratic variation, Semimartingales, Stochastic volatility...|$|E
30|$|T) {{only if the}} {{interference}} generated by secondary transmitter (cognitive transmitter) at primary receiver is tolerable and controlled by an acceptable level, i.e., below a threshold or an outage <b>probability</b> <b>limit</b> that guarantees certain QoS for primary user’s communication.|$|R
30|$|If Cov(u,X*)[*]=[*]Cov(u,ϵ)[*]=[*] 0 this {{simplifies}} to {{the textbook}} attenuation bias associated with classical measurement error. However, {{it is well}} known that violation of either of these conditions will alter the <b>probability</b> <b>limit</b> of the OLS estimator such that the direction of the inconsistency cannot be established a-priori.|$|R
40|$|An open {{queueing}} {{network model}} in light traffic has been developed. The <b>probability</b> <b>limit</b> theorem for the idle time process of customers in heavy traffic in open queueing networks has been presented. Finally, we present {{an application of}} the theorem - an idle time model from computer network practice...|$|R
40|$|In 1957, Parzen {{proved a}} {{central limit theorem}} for a class of scalar {{processes}} which he called multilinear processes. In the present paper only stationary bilinear processes are considered, but the theory is generalized to the multivariate case. bilinear process central limit theorem iterated <b>probability</b> <b>limits</b> linear and bilinear transformations...|$|E
40|$|This paper {{deals with}} optimum link {{capacity}} sizing in Erlang multiservice loss networks with fixed routing. The objective function is link capacity installation cost {{which is to}} be minimized subject to call blocking <b>probability</b> <b>limits.</b> We describe a new heuristic algorithm we use to find a close match solution to this optimization problem. The algorithm is based on knapsack reduced load approximation...|$|E
40|$|The {{results of}} Cox (1961, 1962) on tests of {{separate}} families of hypotheses {{are used to}} develop tests for some log linear regression models. The consequences of using one model when another is true are studied. The <b>probability</b> <b>limits</b> and asymptotic efficiencies of the estimators of the regression coefficients when using a false model {{in relation to the}} true model are investigated...|$|E
3000|$|... [...]. In {{addition}} to the measurement error in lifetime earnings, Haider and Solon (2006) and Grawe (2006) presented empirical evidence of another source of inconsistency that short-run earnings deviate from long-run earnings over the life cycle: The <b>probability</b> <b>limit</b> of the least squares estimator of the coefficient of x [...]...|$|R
40|$|In {{this paper}} we provide a {{systematic}} {{study of how}} the <b>probability</b> <b>limit</b> and central limit theorem for realised multipower variation changes when we add finite activity and infinite activity jump processes to an underlying Brownian semimartingale. Bipower variation Infinite activity Multipower variation Power variation Quadratic variation Semimartingales Stochastic volatility...|$|R
40|$|AbstractIt {{is shown}} that {{a wide range of}} <b>probabilities</b> and <b>limiting</b> <b>probabilities</b> in finite {{classical}} groups have integral coefficients when expanded as a power series in q− 1. Moreover, it is proved that the coefficients of the <b>limiting</b> <b>probabilities</b> in the general linear and unitary cases are equal modulo 2. The rate of stabilization of the finite-dimensional coefficients as the dimension increases is discussed...|$|R
40|$|Control charts for {{monitoring}} process variability, {{such as the}} R-chart and S-chart, do not have symmetric <b>probability</b> <b>limits</b> as {{the distribution of the}} sample variability is not normal. Hence, the usual zone rules can not be applied although it is still desirable {{to be able to use}} the information from more than one point in decision making. In this paper, a modified S-chart based on an optimal normalizing transformation of the sample variance is first introduced. The new chart is shown to have approximate symmetric <b>probability</b> <b>limits</b> and hence can be interpreted in the same way as that of a ¯ X chart. This modified chart is shown to be comparable with the probability S-chart and have a much better performance than the usual Shewhart S-chart for the cases of known and estimated limits. The effect of parameter estimation is investigated. The optimal normalizing transformation is a simple power transformation. The power parameter depends only on the sample size and approaches 1 / 3 as the sample size increases. Hence, the transformation S-chart can be easily implemented and integrated into any SPC system...|$|E
40|$|This study {{demonstrates}} that a location parameter of an exponential distribution significantly influences normalization of the exponential. The Kullback-Leibler information number {{is shown to}} be an appropriate index for measuring data normality using a location parameter. Control charts based on <b>probability</b> <b>limits</b> and transformation are compared for known and estimated location parameters. The probabilities of type II error (β-risks) and average run length (ARL) without a location parameter indicate an ability to detect an out-of-control signal of an individual chart using a power transformation similar to using <b>probability</b> <b>limits.</b> The β-risks and ARL of control charts with an estimated location parameter deviate significantly from their theoretical values when a small sample size of n≤ 50 is used. Therefore, without taking into account {{of the existence of}} a location parameter, the control charts result in inaccurate detection of an out-of-control signal regardless of whether a power or natural logarithmic transformation is used. The effects of a location parameter should be eliminated before transformation. Two examples are presented to illustrate these findings. location parameter, exponential distribution, power transformation, natural logarithmic transformation, Kullback-Leibler information number,...|$|E
40|$|We {{consider}} large factor models where factors’explanatory power {{does not}} strongly dominate the explanatory {{power of the}} idiosyncratic terms in …nite samples, which is the situation often observed in the empirical applications. To study the principal components (PC) estimator of such a weak factors, we introduce a Pitman-drift-like asymptotic device, which we call weak factors asymptotics. We …nd the <b>probability</b> <b>limits</b> of the PC estimator under weak factors asymptotics when the idiosyncratic terms can be both cross-sectionally and temporally correlated. We show that the <b>probability</b> <b>limits</b> may be drastically di¤erent from the true factors and factor loadings even for factors with substantial explanatory power. For a special case of no cross-sectional and temporal correlation of the idiosyncratic terms, we establish the second order weak factors asymptotics of the PC estimator. The estimator is asymptotically normal with the covariance matrix depending {{on the strength of}} the factors and on the ratio of the cross-sectional and the temporal dimensions of the data. JEL code: C 13, C 33. Key words: approximate factor models, principal components, weak factors, inconsistency, bias, asymptotic distribution, Marµcenko-Pastur law...|$|E
30|$|Many {{researchers}} have {{paid attention to}} the study of the <b>probability</b> <b>limit</b> theorem and its applications for the independent random variables, while the fact is that most of the random variables found in real practice are dependent, which just motivates the authors’ interests in how well the dependent random variables will behave in some cases.|$|R
30|$|The outage <b>probability</b> <b>limit</b> is the <b>probability</b> {{that the}} {{instantaneous}} mutual information between the {{sources and sinks}} of the network {{is less than the}} transmitted rate. The outage probability is an achievable (using a random codebook) lower bound of the average WER of coded systems in the limit of large block length [27, 33, 34].|$|R
40|$|This paper extends laws {{of large}} numbers under upper {{probability}} to sequences of stochastic processes generated by linear interpolation. This extension characterizes the relation between sequences of stochastic processes and subsets of continuous function space {{in the framework of}} upper <b>probability.</b> <b>Limit</b> results for sequences of functional random variables and some useful inequalities are also obtained as applications...|$|R
40|$|In this paper, {{forecasting}} {{models are}} constructed for the monthly inward and outward station {{movements of the}} Wisconsin Telephone Company using an iterative procedure developed by Box and Jenkins. Data covering the period January 1951 through October 1966 were used to develop the model. Forecasts with 95 -percent <b>probability</b> <b>limits</b> were calculated for three years from November 1966, and were compared with the actual observations. The properties of the models are discussed in detail. Alternative models for forecasting are also entertained and compared with those chosen. ...|$|E
40|$|The {{quality control}} {{department}} of a manufacturing facility {{is concerned with}} variability increases in the dimension of a product component, where the dimension has a standard normal distribution. This paper evaluates the viability of an S chart configuration that uses <b>probability</b> <b>limits</b> and a Western Electric-type warning rule by comparing it to a standard S chart scheme that uses only <b>probability</b> <b>limits.</b> A Markov chain analysis using the concept of first passage time is used to define a warning zone on the composite S chart scheme such that the composite S chart has the same "in-control" average run length (ARL) as the non-composite S chart scheme. The performances of the two configurations are then simulated {{in order to obtain}} the ARL profiles as the process standard deviation increases from 1. The results of the simulation corroborate the underlying theory, i. e., the ARL decreases as the process standard deviation increases. Moreover, the simulation indicates that the composite S chart scheme (using warning limits) detects process standard deviation shifts more quickly than the non-composite configuration when the size of the shift is "small. " The simulation uses the concept of common random numbers (CRN) {{in order to reduce the}} variance of the estimators for the ARL...|$|E
40|$|A {{procedure}} for combining evidence from different biological assays {{is shown to}} be equivalent both to generalized least-squares and to maximum-likelihood estimation. By appropriate nesting of hypotheses, the likelihood function {{can be used to}} test the agreement between the assays and to obtain <b>probability</b> <b>limits</b> for the combined estimate of potency. The properties of these limits are examined, with particular reference to the situation, unusual but not impossible in practice, in which the values of relative potency that they define consist of several disjoint segments instead of a single interval. The connection with general theory of estimating linear functional relations is pointed out...|$|E
40|$|This {{article focuses}} on the {{estimation}} of long-run effects on panel data. Pirotte showed that the <b>probability</b> <b>limit</b> of the between estimator of a static relation - whereas the true specification is a dynamic error components model - converges to the long-run effects. This article illustrates this theoretical result by an empirical study to labour demand. ...|$|R
40|$|In {{this paper}} we provide a {{systematic}} {{study of how}} the <b>probability</b> <b>limit</b> and central limit theorem for realised multipower variation changes when we add finite activity and infinite activity jump processes to an underlying Brownian semimartingale. © 2006 Elsevier B. V. All rights reserved. This is an Open Archive article {{that may be used}} according to the terms at [URL]...|$|R
3000|$|..., Ptr 1 is the SU {{transmit}} power limit, Ptr 2 {{is the average}} interference power limit, r is the instantaneous interference power tolerance at the PU-Rx, and pth is the PU outage <b>probability</b> <b>limit.</b> The objective function is the SU transmission rate, and the four constraints are the average {{transmit power}}, the average interference power, the PU outage probability constraints, and the positive semi-definite constraint, respectively.|$|R
