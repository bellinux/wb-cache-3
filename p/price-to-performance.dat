9|0|Public
50|$|Pritiraj Mohanty, a Boston University physicist, and Matt Crowley, former {{director}} of Boston University's technology development fund, co-founded Sand 9 in 2007. The company aimed to produce timing products with a better <b>price-to-performance</b> ratio than quartz in core markets.|$|E
50|$|In computing, a vector {{processor}} or array processor {{is a central}} processing unit (CPU) that implements an instruction set containing instructions that operate on one-dimensional arrays of data called vectors, compared to scalar processors, whose instructions operate on single data items. Vector processors can greatly improve performance on certain workloads, notably numerical simulation and similar tasks. Vector machines appeared in the early 1970s and dominated supercomputer design through the 1970s into the 1990s, notably the various Cray platforms. The rapid fall in the <b>price-to-performance</b> ratio of conventional microprocessor designs led to the vector supercomputer's demise in the later 1990s.|$|E
50|$|Currently, {{the best}} lab {{examples}} of traditional crystalline silicon solar cells have efficiencies between 20% and 25%, while lab examples of multi-junction cells have demonstrated performance over 46% under concentrated sunlight. Commercial examples of tandem cells {{are widely available}} at 30% under one-sun illumination, and improve to around 40% under concentrated sunlight. However, this efficiency is gained {{at the cost of}} increased complexity and manufacturing price. To date, their higher price and higher <b>price-to-performance</b> ratio have limited their use to special roles, notably in aerospace where their high power-to-weight ratio is desirable. In terrestrial applications, these solar cells are emerging in concentrator photovoltaics (CPV), with a growing number of installations around the world.|$|E
40|$|The present work {{illustrates}} the architecture and utilization of a simulated ATM testbed, which enables studies of ATM-based workstation networks {{to be carried}} over another network technology, like Ethernet. The current testbed models a very simple ATM network (applications lay directly over AAL), but it allows an easy addition of protocol layers in order to evaluate {{their impact on the}} performance of the whole system. In particular, we have measured the communication latency and the global performance achieved by the ATM model and have compared them with the performance of both an Ethernet-based workstation cluster and a supercomputer. 1 Introduction Up to now, high performance computing has been exploited mostly by vector and massively parallel supercomputers. As these systems have rather a low <b>price-to-performance</b> ratio, the search of alternative approaches has become a matter of interest. The most promising proposal is the use of networked workstations, since the rapid improvement [...] ...|$|E
40|$|In {{the last}} decade or so, the high {{performance}} community is observing a paradigm shift with interconnection methodology for processing elements. Combining commercial off-the-shelf components to build supercomputers has provided users with an excellent <b>price-to-performance</b> ratio. At the same time, scientific applications ranging from molecular dynamics to ocean modeling are being designed with Message Passing Interface (MPI) being the de facto programming model. The insatiable computational requirements of the scientific applications has been continuously pushing the scale of these clusters. Increasing scale of these clusters has aggravated the occurrence of hot-spots in the network and reduced the mean time between failures of difference network components. In order to provide the best performance to the scientific applications, it is imperative that the MPI libraries are capable of avoiding network hot-spots and resilience to faults in the network. At the same time, InfiniBand has emerged as a popular interconnect, providing a plethora of modern features with open standard and high performance. In this dissertation, we focus on designing a communications and network fault toleranc...|$|E
40|$|All SPARC {{trademarks}} {{are used}} under license and are trademarks or registered trademarks of SPARC International, Inc. in the United States and other countries. Products bearing SPARC trademarks {{are based upon}} an architecture developed by Sun Microsystems, Inc. OpenGL is a registered trademark of Silicon Graphics, Inc. Just the Facts November 1998 Sun OpenGL ® for Solaris TM Positioning Sun OpenGL 1. 1. 2 for Solaris Sun OpenGL ® 1. 1. 2 for Solaris TM software provides a robust implementation of the industry-standard 3 -D graphics application programming interface (API) specified by the OpenGL Architecture Review Board (ARB), for developing and deploying 3 -D applications on Sun’s UltraSPARC TM workstations. It enables mainstream, industry-leading, 3 -D graphics and visualization applications to be deployed on Sun’s Ultra TM Creator 3 D and Sun Elite 3 D graphics workstations at a compelling <b>price-to-performance</b> ratio. OpenGL is an API that provides 2 -D and 3 -D graphics functions, including modeling, transformations, color, lighting, and smooth shading, as well as advanced features such as texture mapping, NURBS, fog, alpha blending, and motion blur. OpenGL works in both immediate and non-editable display-list graphics modes. OpenGL is targeted at developers creating interactive 3 -D applications for the enterprise, the intranet, an...|$|E
40|$|A vector processor, or array processor, is {{a central}} {{processing}} unit (CPU) that implements an instruction set containing instructions that operate on one-dimensional arrays of data called vectors. This {{is in contrast to}} a scalar processor, whose instructions operate on single data items. Vector processors can greatly improve performance on certain workloads, notably numerical simulation and similar tasks. Vector machines appeared in the early 1970 s and dominated supercomputer design through the 1970 s into the 90 s, notably the various Cray platforms. The rapid rise in the <b>price-to-performance</b> ratio of conventional microprocessor designs led to the vector supercomputer's demise in the later 1990 s. Today, most commodity CPUs implement architectures that feature instructions for a form vector processing on multiple (vectorized) data sets, typically known as SIMD (Single Instruction, Multiple Data). Common examples include VIS, MMX, SSE, AltiVec and AVX. Vector processing techniques are also found in video game console hardware and graphics accelerators. In 2000, IBM, Toshiba and Sony collaborated to create the Cell processor, consisting of one scalar processor and eight vector processors, which found use in the Sony PlayStation 3 among other applications. Other CPU designs may include some multiple instructions for vector processing on multiple (vectorised) data sets, typically known as MIMD (Multiple Instruction, Multiple Data) and realized with VLIW. Such designs are usually dedicated to a particular application and not commonly marketed for general purpose computing. In the Fujitsu FR-V VLIW/vector processor both technologies are combined...|$|E
40|$|The {{robotics}} {{revolution is}} here. A world where teams of robots form a pervasive network of sensors, computers, and smart devices {{is not far}} off. By forming the “physical ” layer of this network, robots will act as sensing and actuation agents for end-users. Robots {{will be able to}} collect and relay real-time data from hard to reach places at unprecedented spatio-temporal scales. Access to such data can enable new discoveries and help solve grand challenges in areas such as agronomy, oceanography, climate science, surveillance, and emergency response. Technology today has matured to the point where robots capable of autonomous operation in the air, on the ground, and in waters are available commercially. This trend will continue as the <b>price-to-performance</b> ratio of sensing, processing, and communication continues to fall. However, for such networks to be effective, they must be able to close the loop. In other words, we must develop efficient decision-making algorithms that make full use of the technology and ultimately further our understanding about the limits of technology and autonomy. My research focuses on solving fundamental problems on deployment, coverage and path planning for robotic sensing. I develop algorithms that have rigorous theoretical performance guarantees and are extensively val-idated in the field. Most of these problems are NP-hard. However, exploiting the underlying geometric and combinatorial structure of these problems allows us to design efficient approximation algorithms. My research is motivated by applications where robots act as autonomous information gathering agents. I am equally intereste...|$|E
40|$|In 2014, BGS and the University of Lancaster won an STFC Public Engagement {{grant to}} build and deploy 10 Raspberry Pi magnetometers to {{secondary}} schools across the UK. The system uses a Raspberry Pi computer as a logging and data transfer device, connected {{to a set of}} three orthogonal miniature fluxgate magnetometers. The system has a nominal sensitivity of around 1 nanoTesla (nT), in each component direction (North, East and Down). This is around twenty times less sensitive than a current scientific-level instrument, but given its relatively low-cost, at about £ 250 per unit, this is an excellent <b>price-to-performance</b> ratio given we could not improve the sensitivity unless we spent a lot more money. The magnetic data are sampled at a 5 second cadence and sent to the AuroraWatch website at Lancaster University every 2 minutes. The data are freely available to view and download. The primary aim of the project is to encourage students from 14 - 18 years old to look at how sensors can be used to collect geophysical data and integrate it together to give a wider understanding of physical phenomena. A second aim is to provide useful data on the spatial variation of the magnetic field for analysis of geomagnetic storms, alongside data from the BGS observatory and University of Lancaster’s SAMNET variometer network. We show results from the build, testing and running of the sensors including some recent storms and we reflect on our experiences in engaging schools and the general public with information about the magnetic field. The information to build the system and logging and analysis software for the Raspberry Pi is all freely available...|$|E

