0|10000|Public
3000|$|The channel {{preprocessing}} {{is about}} the <b>precalculation</b> <b>of</b> equalization coefficient matrices from the estimated channel matrix [...]...|$|R
50|$|<b>Precalculation</b> <b>of</b> aggregates, complex {{calculations}} {{and application of}} complex business logic may {{be done in a}} staging area to support highly responsive service level agreements (SLAs) for summary reporting in target systems.|$|R
30|$|Gonzalez et al. use the {{hierarchy}} of roads for partitioning the network into areas and make <b>precalculations</b> <b>of</b> shortest path in these areas (Gonzalez et al. 2007). This approach uses {{the fact that some}} roads are more traveled than others and drivers usually use the largest roads.|$|R
40|$|A {{new method}} for {{computation}} of gas cooling for Lagrange approach is suggested. The method {{is based on}} <b>precalculation</b> <b>of</b> cooling law for known cooling function. Unlike implicit methods, this method is very efficient, it is an one-step method which is even more accurate than implicit methods of the same order. Comment: submitted to JCompPhys, 5 pages, 1 figur...|$|R
40|$|Sea wave {{behavior}} calculations {{require the}} <b>precalculation</b> <b>of</b> wave elements {{as well as}} consideration of the spectral functions of ocean wave formation. The spectrum of the random wave process is largely determined by the distribution {{of energy in the}} actual wind waves observed {{on the surface of the}} sea as expressed in statistical and spectral characteristics of the sea swell...|$|R
30|$|Bast et al. define an {{approach}} based on relevant nodes (transit nodes) for long-distance travel (Bast et al. 2007). It consists <b>of</b> making <b>precalculations</b> <b>of</b> shortest path between all pairs of transit nodes and from each potential source or destination to its access transit nodes. This approach needs an effective notion of “far away” and the optimal results are guaranteed {{depending on the}} local filter selected.|$|R
40|$|Abstract: It {{is shown}} that the 13 C-NMR {{chemical}} shifts of carbon atoms in substituted sixmembered heteroaromatic compounds correlate with the correponding "additivity parameters" for substituted benzene derivatives. Thus, for <b>precalculation</b> <b>of</b> chemical shifts in such compounds, just one set of parameters can be used. The differences between experimental chemical shifts and those calculated from correlation with the common set may provide insights into intramolecular interactions not reported in the literature...|$|R
40|$|System-level {{investigations}} {{are crucial to}} determine the per-formance of transmission strategies on network level. In this paper we derive a novel link measurement model for the eval-uation of Alamouti encoded transmissions. Our model allows for the <b>precalculation</b> <b>of</b> so-called fading parameters which are real valued scalars, thus effectively reducing the compu-tational complexity in system level simulations. Finally, we present fading simulations based on our model and discuss the basic performance characteristics of the transmission scheme. 1...|$|R
40|$|In {{this paper}} we present two novel {{visualisation}} tools: the Influence Explorer and the Prosection Matrix. These were specifically created to support engineering artifact design and similar tasks {{in which a}} set of parameter values must be chosen to lead to acceptable artifact performance. These tools combine two concepts. One is the interactive and virtually immediate responsive display of data in a manner conducive to the acquisition of insight. i%e other, involving the <b>precalculation</b> <b>of</b> samples of artifact performance, facilitates smooth exploration and optimisation leading to a design decision. The anticipated benepts of these visualisation tools are illustrated by an example taken from electronic circuit design, in which full account must be taken of the uncertainties in parameter values arising from inevitable variations in the manufacturing process. ...|$|R
30|$|The key concept {{proposed}} by us is to apply advanced, adaptive spectrum shaping algorithms originally considered {{to be used in}} non-contiguous multicarrier transmission schemes [14]. These solutions can guarantee a significant reduction of unwanted out-of-band emission even in a very narrow frequency band at a reasonable complexity. Moreover, these algorithms can be applied {{at the beginning of a}} frame, allowing for a <b>precalculation</b> <b>of</b> the required spectrum masks (filter shapes). The moments when the new spectrum masks have to be changed within the cell are indicated by solid bold vertical lines in Fig. 4.|$|R
40|$|Runge-Kutta and Adams {{methods are}} the most popular codes to solve numerically nonstiff ODEs. The Adams methods are useful {{to reduce the number of}} {{function}} calls, but they usually require more CPU time than the Runge-Kutta methods. In this work we develop a numerical study of a variable step length Adams implementation, which can only take preassigned step-size ratios. Our aim is the reduction of the CPU time of the code by means <b>of</b> the <b>precalculation</b> <b>of</b> some coefficients. We present several numerical tests that show the behaviour of the proposed implementation...|$|R
40|$|Abstract Exploring unknown models or scenes is {{a highly}} in-teractive and dynamic process. Systems for {{automatic}} presentation of models or scenes either require cinemato-graphic rules, direct human interaction, framesets or <b>precalculation</b> <b>of</b> paths to a known goal. We are looking for asystem which can deal with rapidly changing user interest in objects of a scene or model {{as well as with}} dynamic modelsand changes of the camera position introduced interactively by the user or through cuts. In this paper we describe Cubi-calPath, a new potential field-based camera control system that helps with the exploration of virtual environments. 1...|$|R
40|$|The {{parameters}} of the Freundlich-equation for the adsorption of phenol from an aqueous solution at Winkler-dust depend on the pH value. The effect is conditioned by the phenolate anion formed {{in accordance with the}} dissociation equilibrium and by its adsorbability being less compared with the undissociated phenol. The connections between the phenol load and the pH value can be described both by means of an empirical model and a mixture-adsorption model being physically and chemically founded by the IAS-theory. The developed mathematical relations permit the <b>precalculation</b> <b>of</b> the adsorption result {{in the case of a}} pH modification in phenolic effluents...|$|R
40|$|A reduced order {{numerical}} {{computational method}} based on flux tube modelling is {{proposed for the}} rapid electromagnetic analysis and design of electromechanical energy transducers using {{an example of a}} synchronous reluctance machine. The flux tube method is applied to establish flux linkage functions facilitating fast and accurate inductance estimation. The practical advantage is that the approach does not require <b>precalculation</b> <b>of</b> the air gap flux functions using computationally expensive methods such as finite elements. Initial results indicate that the method can predict, reliably and accurately, the flux distribution in the magnetic circuit, thus ultimately enabling efficient estimation of the inductance, and is suitable for rotational and translational synchronous reluctance machines...|$|R
40|$|This article {{reports on}} an error-repair {{algorithm}} for LR parsers. It locally inserts, deletes or shifts symbols at the positions where errors are detected, thus modifying the right context {{in order to}} resume parsing on a valid piece of input. This method improves on others in {{that it does not}} require the user to provide additional information about the repair process, it does not require <b>precalculation</b> <b>of</b> auxiliary tables, and it can be easily integrated into existing LR parser generators. A Yacc-based implementation is presented along with some experimental results and comparisons with other well-known methods. Comisión Interministerial de Ciencia y Tecnología TIC 2000 – 1106 –C 02 – 0...|$|R
40|$|The EPS stage, {{the second}} upper {{stage of the}} Ariane 5 {{launcher}}, was tested in the launcher test stand in Lampoldshausen, Germany {{during the second half}} <b>of</b> 1994. The <b>precalculations</b> <b>of</b> its structural dynamic behaviour revealed the possibility of the occurrence of severe so-called POGO vibrations. In order to monitor and control the occurrence of these unstable variations, a so-called "red-line" system was developed based on modal data. Structural identification tests were performed by DLR to acquire a reliable data basis for POGO risk control. The tests comprised frequency response functions and free decay measurements. This report describes the test performance, data evaluation, and test results...|$|R
40|$|In this work, {{we present}} a {{three-dimensional}} (3 D) model for the optimization of the probe placement in radio-frequency ablation (RFA). The model {{is based on a}} system of partial differential equations (PDEs) that describe the electric potential of the tissue and the steady state of the heat which is induced into the tissue. The PDE system is solved by a finite element approach and the optimization is performed by minimizing a temperature based objective functional under the constraining PDE systems. A well-known difficulty associated with RFA is the cooling influence of large blood vessels on the ablation result. A method is discussed, which efficiently estimates the cooling effect of those vessels, based on a <b>precalculation</b> <b>of</b> all patient-independent data and tabulation of the results...|$|R
40|$|Abstract—Today’s {{manufacturing}} industry is {{under pressure to}} increase the flexibility of its factory lines. One approach {{to achieve this goal}} is the shift from centralized control systems towards dis-tributed, service-oriented architectures (SOA). To fully leverage the benefit of this new paradigm, the SOA should extend down to the device level and even include resource-constrained devices, such as smart sensors and actuators. In this paper, we present our approach for a lightweight distributed service choreography without a central point of control. It is based on network-aware <b>precalculation</b> <b>of</b> a static, non-preemptive schedule for each device and is thus suitable even for constrained devices. In contrast to previous work, our focus lies on the planning components required for achieving a service choreography. Since scheduling is a central part of our architecture, and we expect it to be executed many times during the planning process, we evaluate different heuristics for this task. I...|$|R
40|$|Van Uytsel D. H., Van Compernolle D., Wambacq P., "Maximum-likelihood {{training}} of the PLCG-based language model", Proceedings Workshop on automatic speech recognition and understanding, ASRU- 2001, December 9 - 13, 2001, Madonna di Campiglio Trento, Italy. In [1] a parsing language model based on a probabilistic left-corner grammar (PLCG) was proposed and encouraging performance on a speech recognition task using the PLCG-based language model was reported. In this paper we show how the PLCG-based language model can be further optimized by iterative parameter reestimation on unannotated training data. The <b>precalculation</b> <b>of</b> forward, inner and outer probabilities of states in the PLCG network provides an elegant crosscut to the computation of transition frequency expectations, which are needed in each iteration of the proposed reestimation procedure. The training algorithm enables model training on very large corpora. In our experiments, test set perplexity is close to saturation after three iterations, 5 to 16 % lower than initially. We however observed no significant improvement of recognition accuracy after reestimation. status: publishe...|$|R
40|$|Symmetries of a Place/Transition-net can be {{exploited}} during the reachability analysis {{by considering only}} one representative marking in each orbit induced by the symmetries. In this report, three new algorithms for transforming a marking into a symmetric canonical representative marking are described. All the algorithms depend on the <b>precalculation</b> <b>of</b> a SchreierSims representation for the symmetry group of the net in question. The first algorithm uses a black box graph canonizer algorithm to produce a canonical version of the characteristic graph associated with a marking and then derives the canonical representative marking from it. The second algorithm is a backtrack search in the Schreier-Sims representation, pruning the search with the marking in question and its stabilizers found during the search. The third algorithm combines {{the first and second}} one by pruning the search in the Schreier-Sims representation with an ordered partition obtained with a standard preprocessing technique applied in graph isomorphism algorithms...|$|R
40|$|The paper {{presents}} {{a model of}} the CVD- and CVI- proceses based on the principles for the description of the gas solid reactions on the outer surface of the substrate and the inner surface of the pores. The model parameters mass transfer coefficient and rate constant of the chemical reaction at the surface were determined experimentally. The model for the inpore deposition takes into account that during the CVI- process the geometry of the pores changes and thus no steady state is reached during the process. The <b>precalculation</b> <b>of</b> the CVI- effect using the above model and experimental results are compared for demonstration of the applicability of the mathematical model. Also for porous substrates with a pore size distribution the model describes quantitatively the impregnation effect. The experimental demonstration was performed as SiC- CVI of substrates with micropores between 3 and 15 µm in diameter and as SiC- CVI of SiC- whisker sheets with a diameter distribution ranging from 0. 1 µm to 200 µm...|$|R
40|$|GF (2 m). ???????? ??????????? ??????????????? ??????? ? ???????????? ???????????? ??????????? ??????????????, ??? ???????????? ???? ???? ???. ???????? ????????? ????????????? ?????????? ????????? ??????????????, ???????? ????????. ??????????, ?? ?? ?????????? ????????? ?????????? ?????? ?? ????? ????? GF (2 m). ????????, ?? ????????????? ?????????? O(m) ?????????? ??????? ??????? ????? ?? ?????????? ??????? ????????, ??? ????????? O(m?). In article {{the method}} of {{accelerated}} calculation of square root on Galois fields GF (2 m) has been proposed. The main feature of proposed method is using results <b>of</b> <b>precalculations</b> many times, which are calculated only once. The technology <b>of</b> executing <b>of</b> <b>precalculations</b> is given in details, examples are given. It is researched how proposed technology accelerates calculation of square root on Galois fields GF (2 m). It is proved, that calculation complexity O(m) of proposed method is much smaller then complexity of known methods, which equals O(m?) ...|$|R
40|$|International audienceComponent-based systems (including {{distributed}} {{programs and}} multiagent systems) involve {{a lot of}} coordination. This coordination {{is done in the}} background, and is transparent to the operation of the system. The reason for this overhead is the interplay between concurrency and non-deterministic choice: processes alternate between progressing independently and coordinating with other processes, where coordination can involve multiple choices of the participating components. This kind of interactions appeared as early as some of the main communication-based programming languages, where overhead effort often causes a restriction on the possible coordination. With the goal of enhancing the efficiency of coordination for component-based systems, we propose here a method for coordination-based on the <b>precalculation</b> <b>of</b> the knowledge of processes and coordination agents. This knowledge can be used to lift part of the communication or synchronization that appears in the background of the execution to support the interaction. Our knowledge-based method is orthogonal to the actual algorithms or primitives that are used to guarantee the synchronization: it only removes messages conveying information that knowledge can infer...|$|R
40|$|Nearly all {{algorithms}} for {{linear model}} predictive control (MPC) either {{rely on the}} solution of convex quadratic programs (QPs) in real time, or on an explicit <b>precalculation</b> <b>of</b> this solution for all possible problem instances. In this paper, we present an online active set strategy for the fast solution of parametric QPs arising in MPC. This strategy exploits solution information of the previous QP {{under the assumption that}} the active set does not change much from one QP to the next. Furthermore, we present a modification where the CPU time is limited {{in order to make it}} suitable for strict real-time applications. Its performance is demonstrated with a challenging test example comprising 240 variables and 1191 inequalities, which depends on 57 parameters and is prohibitive for explicit MPC approaches. In this example, our strategy allows CPU times of well below 100 ms per QP and was about one order of magnitude faster than a standard active set QP solver. Copyright (c) 2007 John Wiley & Sons, Ltd. status: publishe...|$|R
40|$|Abstract. Component-based systems (including {{distributed}} {{programs and}} multiagent systems) involve {{a lot of}} coordination. This coordination {{is done in the}} background, and is transparent to the operation of the system. The reason for this overhead is the interplay between concurrency and non-deterministic choice: processes alternate between progressing independently and coordinating with other processes, where coordination can involve multiple choices of the participating components. This kind of interactions appeared as early as some of the main communication-based programming languages, where overhead effort often causes a restriction on the possible coordination. With the goal of enhancing the efficiency of coordination for component-based systems, we propose here a method for coordination-based on the <b>precalculation</b> <b>of</b> the knowledge of processes and coordination agents. This knowledge can be used to lift part of the communication or synchronization that appears in the background of the execution to support the interaction. Our knowledge-based method is orthogonal to the actual algorithms or primitives that are used to guarantee the synchronization: it only removes messages conveying information that knowledge can infer. ...|$|R
40|$|The paper {{presents}} a software tool that supports {{design for assembly}} in an early design stage. It integrates a 3 D solid modeller, an expert system shell and an object-oriented data base, thus providing parallel knowledge-based support in DFA through a CAD-system. At first, the paper describes an integrated information model {{which serves as a}} basis for the system development. It is structured into data models for product, process, assembly equipment and order, which has been described using the STEP-EXPRESS language. The data models have been implemented in the expert system object base. Assembly process knowledge is represented within the knowledge base in form of frames, constraints and IF-THEN-rules. Subsequent to the description of the system's architecture four application examples which are concerned with the assembly of mobile telephones are presented. These examples are optimizing of drilling hole coordinates for automated assembly of printed circuit board and telephone housing, optimizing the groove profile for automated pressing-in of a flexible gasket, the selection of standardized endeffectors and the <b>precalculation</b> <b>of</b> assembly costs...|$|R
40|$|The {{filament}} winding {{process has been}} well-proven {{in the production of}} highly stressed components since many years. However, so far there have been no methods of exactly predicting the process-inherent laminate thickness of a component and thus its external geometry. The objective of this documented research project is to create a numerical basis for determining laminate thickness, which takes into account the process-inherent influencing parameters. In order to develop such a numerical method, the effects of various process parameters are indicated in experiments based on theoretical considerations. The parameters core diameter, winding angle, winding pattern, filament tension, resin viscosity and number of layers are considered as being relevant. Experimental results show a good correlation with theoretically derived relationships. In summary, the investigations resulted in the identification of algorithms which permit a <b>precalculation</b> <b>of</b> the laminate thickness to be expected. This calculation is possible for simple rotationally symmetrical components without requiring further aids. (orig.) SIGLEAvailable from TIB Hannover: F 95 B 1282 / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekArbeitsgemeinschaft Industrieller Forschungsvereinigungen e. V., Koeln (Germany) DEGerman...|$|R
40|$|A novel {{strategy}} for the modeling of indoor MIMO channels based on a spatial extension of appropriate SISO channel models is presented. The approach enables a <b>precalculation</b> <b>of</b> potential MIMO spectral efficiencies within a particular environment from the SISO channel information while {{taking into account the}} correlation of the MIMO channel. The objective measure is given by the spatial probability distribution of the MIMO capacity which is to be predicted correctly. The method is exemplified by Saleh’s popular SISO indoor channel model. However, the approach is not limited to this SISO model. In order to practically verify the method, firstly, the key parameters for the SISO model are derived from measured data, before the extension to the MIMO channel model is performed. Finally, the spatial cumulative distribution function, which is predicted by the model is compared to its counterpart which was derived using a fast MIMO radio channel sounder. In the measurements a strong Line-Of-Sight (LOS) signal component was always present resulting in correlated entries within the MIMO channel matrix. For the accurate capacity modeling in such correlated channels, the characterization of the LOS signal part by a spherical wave model is a crucial prerequisite. I...|$|R
40|$|We {{describe}} an application supporting alternating interaction and animation {{for the purpose}} of exploration in a surround-screen projection-based virtual reality system. The exploration of an environment is a highly interactive and dynamic process in which the presentation of objects of interest can give the user guidance while exploring the scene. Previous systems for automatic presentation of models or scenes need either cinematographic rules, direct human interaction, framesets or precalculation (e. g. <b>precalculation</b> <b>of</b> paths to a predefined goal). We report on the development of a system that can deal with rapidly changing user interest in objects of a scene or model as well as with dynamic models and changes of the camera position introduced interactively by the user. It is implemented as a potential-field based camera data generating system. In this paper we describe the implementation of our approach in a virtual art museum on the CyberStage, our surround-screen projection-based stereoscopic display. The paradigm of guided exploration is introduced describing the freedom of the user to explore the museum autonomously. At the same time, if requested by the user, guided exploration provides just-in-time navigational support. The user controls this support by specifying the current field of interest in high-level search criteria. We also present an informal user study evaluating this approach...|$|R
40|$|Intensity Modulated Radiotherapy (IMRT) {{belongs to}} the most {{advanced}} techniques in cancer treatment. Due to {{the large number of}} degrees of freedom the inverse problem of IMRT is formulated as a scalar optimization problem. The conventional scalarization approach of the objective function represents an a priori trade-off between the planning goals and can lead to time consuming planning process. New multiobjective approaches try to overcome the difficulties by a <b>precalculation</b> <b>of</b> a set of Pareto optimal treatment plans from which the planner can subsequently choose the best suited plan. In this work we evaluate a new multiobjective treatment planning system. We investigate three different generalized equivalent uniform dose (gEUD) based modeling approaches and study the sensitivities of the corresponding model parameters. Quality measures for entire Pareto optimal databases are developed and applied to clincal cases. In retrospective planning studies we show that the new system is compatible with a clinical reference treatment planning system and that the total planning time for prostate cases can be significantly reduced. In the last part we develop a method to detect the imperative trade-offs in a plan database and apply techniques from linear as well as non-linear dimensionality reduction. They allow meaningful visualizations of high dimensional Pareto fronts and an insight into the underlying trade-offs between the planning goals...|$|R
3000|$|In this section, we {{show how}} {{assortment}} decisions {{can be incorporated}} into the CSRPBS. The resulting model is denoted as CASRPBS, whereas the additional “A” represents the assortment decision. So far, we have assumed that the assortment is determined in a previous planning step and that the retailer must assign all items of set N to the shelf, i.e., we did not allow zero facings k_i= 0. Including the assortment decision allows more flexibility for two reasons: (1) Solutions for situations with S<N, can now be generated and items delisted. (2) Even if S> N, it might be beneficial to delist specific items and use the shelf space for more beneficial items, e.g., items with a higher margin and/or space elasticity. The inclusion of assortment decisions requires an adaptation of the demand function (cf. Eq.  3) to account for additional demand arousing from out-of-assortment (OOA) situations (Smith and Agrawal 2000; Kök and Fisher 2007). OOA substitution expresses the customer’s willingness to buy an alternative item if the preferred item is not listed. By taking substitution into account, demand and the profit for an item i also depend on the availability of all other items j, j [...] i. This extension increases the combinatorial complexity of our model, since the cross-product interdependencies result in a quadratic problem and the isolated <b>precalculation</b> <b>of</b> the item-specific profits as input to the MIP (see Sect.  4) does not capture these product interlinks anymore.|$|R
40|$|International audienceCommonly, the {{confinement}} {{effects are}} studied from the grand canonical Monte Carlo (GCMC) simulations from the computation of {{the density of}} liquid in the confined phase. The GCMC-modeling and chemical potential (mu) calculations {{are based on the}} insertion/deletion of the real and ghost particle, respectively. At high density, i. e., at high pressure or low temperature, the insertions fail from the Widom insertions while the performing methods as expanded method or perturbation approach are not efficient to treat the large and complex molecules. To overcome this problem we use a simple and efficient method to compute the liquid's density in the confined medium. This method does not require the <b>precalculation</b> <b>of</b> mu and is an alternative to the GCMC simulations. From the isothermal-isosurface-isobaric statistical ensemble we consider the explicit framework/liquid external interface to model an explicit liquid's reservoir. In this procedure only the liquid molecules undergo the volume changes while the volume of the framework is kept constant. Therefore, this method is described in the Np(n) AV(f) T statistical ensemble, where N is the number of particles, p(n) is the normal pressure, V-f is the volume of framework, A is the surface of the solid/fluid interface, and T is the temperature. This approach is applied and validated from the computation of the density of the methanol and water confined in the mesoporous cylindrical silica nanopores and the MIL- 53 (Cr) metal organic framework type, respectively. (C) 2011 American Institute of Physics...|$|R
40|$|Wireless Sensor Networks (WSNs) {{have been}} a growing {{research}} domain during {{the past couple of}} years. One of the most challenging tasks of WSN research is still location estimation. As a well performing fine grained localization approach, Distributed Least Squares (DLS) was introduced, splitting the localization process in a complex global precalculation and a simple local postcalculation. Nevertheless, as size <b>of</b> <b>precalculation</b> and cost <b>of</b> computation and communication are increasing with the WSN dimensions, it was shown that this algorithm is unsuitable for large ones. This constraint has been overcome by scalable DLS (sDLS). Further, the computational costs of sDLS have been improved by using sDLSne. Unfortunately, sDLSne comes along with decreased localization accuracy and thus represents a tradeoff. The presented hybrid solution combines sDLSne with various coarse grained localization techniques to avoid this drawback. The resulting localization accuracy overcomes the efficient sDLSne approach as well as the more precise sDLS approach, while computational costs still outperforms sDLS. ...|$|R
40|$|Abstract: Wireless Sensor Networks (WSNs) {{have been}} a growing {{research}} domain during {{the past couple of}} years. One of the most challenging tasks of WSN research is still location estimation. As a well performing fine grained localization approach, Distributed Least Squares (DLS) was introduced, splitting the localization process in a complex global precalculation and a simple local postcalculation. Nevertheless, as size <b>of</b> <b>precalculation</b> and cost <b>of</b> computation and communication are increasing with the WSN dimensions, it was shown that this algorithm is unsuitable for large ones. This constraint has been overcome by scalable DLS (sDLS). Further, the computational costs of sDLS have been improved by using sDLS ne. Unfortunately, sDLS ne comes along with decreased localization accuracy and thus represents a tradeoff. The presented hybrid solution combines sDLS ne with various coarse grained localization techniques to avoid this drawback. The resulting localization accuracy overcomes the efficient sDLS ne approach as well as the more precise sDLS approach, while computational costs still outperforms sDLS. Copyright © 2011 IFSA...|$|R
40|$|A neural net {{structure}} {{has been developed}} which is capable of solving deterministic jobshop scheduling problems, part of the large class of np-complete problems. The problem was translated in an integer linear-programming format which facilitated translation in an adequate neural net structure. Use of the presented structure eliminated the need for integer adjustments. The search space was reduced by the use <b>of</b> <b>precalculation,</b> allowing the rapid calculation of feasible solutions. The neural net structure was reliable in simulated operation and its performance was superior to structures which have been presented previously...|$|R
40|$|Radiofrequency (RF) {{ablation}} is {{a widely}} used, minimally invasive technique {{for the treatment of}} liver cancer. Within this method, an RF current is used to heat the tumor tissue up to high temperatures which are lethal to the tissue. The RF current is generated by a high frequency generator and induced into the tissue via so-called needle- or umbrella probes, which contain one or more electrodes. Especially, in situations where a surgical resection is not possible due to the patient's physical condition and state of the tumors, the RF ablation technique offers a powerful but less invasive alternative. However, the success of an RF ablation, i. e. the completeness of tumor destruction with minimum amount of effected native tissue, considerably depends on the accuracy of needle insertion and control of the energy supply, {{as well as on the}} cooling effects of blood perfusion. The aim of this work is to develop a three-dimensional model for the optimization of the RF probe placement. The model is based on a numerical finite element computation of the electric potential and heat distribution inside the malignant and surrounding native tissue during an RF ablation. The optimization is performed by minimizing a temperature based objective functional under these constraining equations. Moreover, since the tissue properties of the individual patient cannot be determined exactly in advance, also a model based on stochastically distributed tissue parameters is developed, in order to investigate the sensitivity of an optimal probe placement found by the presented algorithm, with respect to changes in these quantities. A further well-known difficulty associated with RF ablation is the cooling influence of blood perfusion on the ablation result. For this reason, a method to quickly estimate the cooling effect of large blood vessels based on a <b>precalculation</b> <b>of</b> all patient-independent quantities, is introduced. Finally, a first approach towards an optimal control of the electric energy which is induced into the tissue via the RF generator, is presented and discussed. The results show that the simulation and optimization of an RF ablation is of essential importance to yield the best possible outcome and thus present a helpful tool for assisting the interventional radiologist...|$|R
