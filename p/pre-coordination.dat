30|0|Public
5000|$|A {{contention-based}} protocol (CBP) is {{a communications}} protocol for operating wireless telecommunication equipment that allows many users {{to use the}} same radio channel without <b>pre-coordination.</b> The [...] "listen before talk" [...] operating procedure in IEEE 802.11 is the most well known contention-based protocol.|$|E
5000|$|The {{final phase}} of {{indexing}} is to present the entries in a systematic order. This may involve linking entries. In a pre-coordinated index the indexer determines {{the order in which}} terms are linked in an entry by considering how a user may formulate their search. In a post-coordinated index, the entries are presented singly and the user can link the entries through searches, most commonly carried out by computer software. Post-coordination results in a loss of precision in comparison to <b>pre-coordination</b> ...|$|E
5000|$|In contrast, one-way {{computer}} communication, {{which is}} like the push-to-talk or [...] "barge in" [...] feature found on some phones and two-way radios, sends a message without waiting for a response. Sending an email {{is an example of}} one-way communication, and another example are fieldbus sensors, such as most CAN bus sensors, which periodically and autonomously send out their data, whether or not any other devices on the bus are listening for it. (Most of these systems use a [...] "listen before talk" [...] or other contention-based protocol so multiple sensors can transmit periodic updates without any <b>pre-coordination.)</b> ...|$|E
50|$|Historically subject {{headings}} {{were designed}} to describe books in library catalogs by catalogers while thesauri were used by indexers to apply index terms to documents and articles. Subject headings tend to be broader in scope describing whole books, while thesauri {{tend to be more}} specialized covering very specific disciplines. Also because of the card catalog system, subject headings tend to have terms that are in indirect order (though with the rise of automated systems this is being removed), while thesaurus terms are always in direct order. Subject headings also tend to use more <b>pre-coordination</b> of terms such that the designer of the controlled vocabulary will combine various concepts together to form one authorized subject heading. (e.g., children and terrorism) while thesauri tend to use singular direct terms. Lastly thesauri list not only equivalent terms but also narrower, broader terms and related terms among various authorized and non-authorized terms, while historically most subject headings did not.|$|E
50|$|Earlier SNOMED {{versions}} had faceted structure {{ordered by}} semantic axes, requiring that more complex situations {{required to be}} coded by a coordination of different codes. This had two major shortcomings. On the one hand, the necessity of post-coordination was perceived as a user-unfriendly obstacle, which has certainly contributed to the rather low adoption of early SNOMED versions. On the other hand, uniform coding was difficult to obtain. E.g.,Acute appendicitis could be post-coordinated in three different ways with no means to compute semantic equivalences.SNOMED RT had addressed this problem by introducing description logic formula. With the addition of CTV3 {{a large number of}} concepts were redefined using formal expressions. However, the fusion with CTV3, as a historically grown terminology with many close-to user descriptions, introduced some problems which still affect SNOMED CT. In addition to a confusing taxonomic web of many hierarchical levels with massive multiple inheritance (e.g. there are 36 taxonomic ancestors for Acute appendicitis), many ambiguous, context-dependent concepts have found their way into SNOMED CT. <b>Pre-coordination</b> was sometimes pushed to extremes, so there are, for example, 350 different concepts for burns found on the head.|$|E
40|$|Abstract: The {{introduction}} of computerized post-coordination has solved {{many of the}} problems of pre-coordinated subject access. However, the adoption of computerized post-coordination results in the loss of some <b>pre-coordination</b> benefits. Specifically, the effect of hiding terms within the context of others is lost in post-coordination which gives lead status to every document term. This results in spurious matches of terms out of context. Library patrons and Internet searchers are increasingly dissatisfied with subject access performance, in part because of unmanageably large retrieval sets. The need to enhance precision and limit the size of retrieval sets motivates this work which proposes partial coordination, an approach which incorporates the advantages of computer search with the ability of <b>pre-coordination</b> to limit spurious partial matches and thereby enhance precision...|$|E
40|$|As the {{prevalence}} of autonomous agents grows, so does the number of interactions between these agents. Therefore, it is desirable for these agents {{to be capable of}} collaborating without <b>pre-coordination.</b> While past research on ad hoc teamwork has focused mainly on relatively simple domains, the long-term vision has been to enable robots and other au-tonomous agents to exhibit the sort of flexibility and adapt-ability on complex tasks that people do. This research intro-duces a series of pick-up robot soccer experiments that were carried out in three different leagues at the international RoboCup competition in 2013. In all cases, agents from different labs were put on teams with no <b>pre-coordination.</b> This abstract summarizes the structure of these experiments and analyzes the results. The work describes a new large-scale ad hoc teamwork testbed that can serve {{as a starting point for}} future experimental ad hoc teamwork research...|$|E
40|$|<b>Pre-coordination</b> of {{index terms}} has {{fallen out of}} favor {{with the advent of}} {{automated}} information retrieval. This is unjustified, as a certain amount of <b>pre-coordination</b> greatly enhances the searcher's possibilities of fine-tuning the query to match the level of detail of the information request. We propose a system of index concepts that allows concepts to be coordinated by means of special coordinators. The query engine able to handle coordinated and uncoordinated concepts is specified by means of an elaborate functional specification. The query engine combines the facilities of pre- and post-coordination. The feasibility of the query engine is demonstrated by a prototype that can be run over WWW. 1 Introduction 1. 1 Pre- and post-coordination The advent of automated Information Retrieval (IR) systems is generally held to have implied the demise of pre-coordinated index terms. Post-coordination is the norm, said to be to the advantage of users. Briefly, the distinction between pre- a [...] ...|$|E
40|$|Ad hoc {{teamwork}} {{has recently}} been introduced as a general challenge for AI and especially multiagent systems [15]. The goal is to en-able autonomous agents to band together with previously unknown teammates towards a common goal: collaboration without <b>pre-coordination.</b> While research to this point has focused mainly on theoretical treatments and empirical studies in relatively simple domains, the long-term vision {{has always been to}} enable robots or other autonomous agents to exhibit the sort of flexibility and adaptability on complex tasks that people do, for example when they play games of “pick-up” basketball or soccer. This paper chronicles the first evaluation of autonomous robots doing just that: playing pick-up soccer. Specifically, in June 2013, the authors helped organize a “drop-in player challenge” in three different leagues at the international RoboCup competition. In all cases, the agents were put on teams with no <b>pre-coordination.</b> This paper documents the structure of the challenge, describes some of the strategies used by participants, and analyzes the results...|$|E
40|$|Abstract — As the {{prevalence}} of autonomous agents grows, so does the number of interactions between these agents. Therefore, it is desirable for these agents {{to be capable of}} banding together with previously unknown teammates towards a common goal: to collaborate without <b>pre-coordination.</b> While past research on ad hoc teamwork has focused mainly on theoretical treatments and empirical studies in relatively simple domains, the long-term vision has been to enable robots and other autonomous agents to exhibit the sort of flexibility and adaptability on complex tasks that people do, for example when they play games of “pick-up ” basketball or soccer. This paper introduces a series of pick-up robot soccer experiments that were carried out in three different leagues at the international RoboCup competition in 2013. In all cases, agents from different labs were put on teams with no <b>pre-coordination.</b> This paper introduces the structure of these experiments, describes the strategies used by UT Austin Villa in each challenge, and analyzes the results. The paper’s main contribution is the introduction of a new large-scale ad hoc teamwork testbed that can serve {{as a starting point for}} future experimental ad hoc teamwork research. I...|$|E
40|$|Before deployment, agents {{designed}} for multiagent team settings are commonly developed together or are given standardized {{communication and coordination}} protocols. However, in many cases this <b>pre-coordination</b> is not possible because the agents {{do not know what}} agents they will encounter, resulting in ad hoc team settings. In these problems, the agents must learn to adapt and cooperate with each other on the fly. We extend existing research on ad hoc teams, providing theoretical results for handling cooperative multi-armed bandit problems with infinite discounted rewards. Categories and SubjectDescriptor...|$|E
40|$|The Standard Platform League is {{a soccer}} league {{at the annual}} RoboCup world championships in which teams of five {{humanoid}} robots play against each other. In 2014, the Drop-in Player Competition {{was added to the}} league to serve as a testbed for cooperation without <b>pre-coordination.</b> Instead of homogeneous robot teams that are programmed by each team to implicitly work together, this competition features ad hoc teams, i. e. teams that consist of robots originating from different RoboCup teams and that are each running different software. In this extended abstract, we provide an overview of this competition, including its motivation and rules...|$|E
40|$|As {{autonomous}} agents proliferate in {{the real}} world, both in software and robotic settings, they will increasingly need to band together for cooperative activities with previously unfamiliar teammates. In such ad hoc team settings, team strategies cannot be developed a priori. Rather, an agent {{must be prepared to}} cooperate with many types of teammates: it must collaborate without <b>pre-coordination.</b> This article defines two aspects of collaboration in two-player teams, involving either simultaneous or sequential decision making. In both cases, the ad hoc agent is more knowledgeable of the environment, and attempts to influence the behavior of its teammate such that they will attain the optimal possible joint utility...|$|E
40|$|As {{autonomous}} agents proliferate in {{the real}} world, both in software and robotic settings, they will increasingly need to band together for cooperative activities with previously unfamiliar teammates. In such ad hoc team settings, team strategies cannot be developed a priori. Rather, an agent {{must be prepared to}} cooperate with many types of teammates: it must collaborate without <b>pre-coordination.</b> This paper challenges the AI community to develop theory and to implement prototypes of ad hoc team agents. It defines the concept of ad hoc team agents, specifies an evaluation paradigm, and provides examples of possible theoretical and empirical approaches to challenge. The goal is to encourage progress towards this ambitious, newly realistic, and increasingly important research goal. ...|$|E
40|$|Abstract. Medical {{vocabulary}} is complex, expanding, and convoluted {{not least}} {{because of the large}} numbers of compound terms. Formalized medical terminologies such as SNOMED-CT and ICD- 10 take one of two strategies when representing medical language: so-called <b>pre-coordination</b> where valid compound terms are included explicitly in the terminologies and so-called post-coordination where the terminology consists of a basis and a generative function from which the compound terms may be derived. However, these notions are not used with particular precision in the literature. In this paper, we provide a formalization of the notion of coordination, a technique for estimating the degree of coordination in a given system, and an examination, based on our technique, of the coordination level of a number of major existing terminologies...|$|E
40|$|Abstract — With the {{emergence}} of a ubiquitous web of data and services, interoperability between those services without the need for <b>pre-coordination</b> becomes of great importance. However, current web services are often engineered in the remote function call style. This imposes very specific interaction patterns on the peers involved, and creates a significant barrier to interoperability. This work introduces a different communication abstraction, the Free Speech system, which aims removing any ordering constraints on the communication that are not strictly needed for business requirements. We compare our first implementation of some services in the Free Speech system with a classic WSDL implementation of the same services. Our first experiments show that the Free Speech approach results in a much higher degree of interoperability between services with different business requirements...|$|E
40|$|Classification {{theory is}} divided into two areas: {{analysis}} of conceptual structure and file organization, and the primacy of the first is stressed, A model for conceptual structure in terms of concept coordination and polyhierarchy is sketched, Some problems of file organization, namely post-coordination vs. <b>pre-coordination</b> and synthetic vs. enumerative schemes are discussed in relation to this model. A model for a classification scheme for different kinds of file organization is then proposed. The scheme would consist of a "core classification scheme " made up of elemental concepts and an "extended classification scheme " made up of combinations of elemental concepts. While the core scheme would be universal, extended schemes would be developed as needed in a specific application. This would make for flexibility while maintaining inter-system compatibility. - 1 -...|$|E
40|$|Handover (HO) {{mechanism}} {{is one of}} the critical operations in mobile WiMAX. It takes place when a mobile -station (MS) moves from a serving base station (BS) to another BS. However, the HO latency in mobile WiMAX is still an issue that may affect continuity of real-time application sessions such as Voice over Internet Protocol (VoIP). This paper presents performance comparison of some HO mechanisms for real-time applications in mobile WiMAX, including HO, cross-layer HO, <b>pre-coordination</b> HO, passport HO mechanisms and fast intra-network and cross-layer HO (FINCH). Each one of these mechanisms reduces HO latency, especially during downlink traffic; however, they still produce insufficient HO latency during uplink traffic. Except for FINCH, they do not consider the scenario of HO between BSs that belong to different access service network-gateways (ASN-GWs) or to different connectivity service networks (CSNs); these two cases cause extra layer 3 (L 3) HO latency...|$|E
40|$|Abstract—Throughout the history, the {{military}} capabilities have been employed during not only war times but also disasters and other emergency circumstances. Post-disaster urban environment {{is one of}} these operational theaters. However, it has challenging characteristics for military operations especially when high number of troops requested by local authorities. Considering Public Safety and Security (protection of the population and critical assets) in a post-disaster environment is of top priority to set off other emergency response and recovery activities, military units should make sure that they have robust and resilient plans in terms of effective preparedness, <b>pre-coordination</b> of common supporting methodologies and timely exchange of necessary information. Developing a security plan for an urban area hinges on the identification of critical assets within the area of responsibility, and follow-up criticality and vulnerability/threat assessments. However, from tactical level security planning perspective, there is no model of an urban area critical asset prioritization methodology that employs both multiple criteria decision making approach (like fuzzy sets for multiple system states) and criteria sets that specifically address unique post-disaster urban environment characteristics...|$|E
40|$|AbstractKnowledge-Intensive Case Based Reasoning (KI-CBR) systems mainly {{depend on}} {{ontology}}. Using ontology as domain knowledge supports {{the implementation of}} semantically-intelligent case retrieval algorithms. The case-based knowledge must be encoded with the same concepts of the domain ontology. Standard medical ontologies, such as SNOMED CT (SCT), can {{play the role of}} domain ontology to enhance case representation and retrieval. This study has three stages. First, we propose an encoding methodology using SCT. Second, this methodology is used to encode the case-based knowledge. Third, all the used SCT concepts are collected in a reference set, and an OWL 2 ontology of 550 pre-coordinated concepts is proposed. A diabetes diagnosis is chosen as a case study of our proposed framework. SCT is used to provide a <b>pre-coordination</b> concept coverage of ∼ 75 % for diabetes diagnosis terms. Whereas, the uncovered concepts in SCT are proposed. The resulting OWL 2 ontology will be used as domain knowledge representation in diabetes diagnosis CBR systems. The proposed framework is tested by using 60 real cases...|$|E
40|$|The Dynamic Recursive Unified Internet Design (DRUID) is {{a future}} Internet design that unifies overlay {{networks}} with conventional layered network architectures. DRUID {{is based on}} the fundamental concept of recursion, enabling a simple and direct network architecture that unifies the data, control, management, and security aspects of the current Internet, leading to a more trustworthy network. DRUID’s architecture is based on a single recursive block that can adapt to support a variety of communication functions, including parameterized mechanisms for hard/soft state, flow and congestion control, sequence control, fragmentation and reassembly, compression, encryption, and error recovery. This recursion is guided by the structure of a graph of translation tables that help compartmentalize the scope of various functions and identifier spaces, while relating these spaces for resource discovery, resolution, and routing. The graph also organizes persistent state that coordinates behavior between individual data events (e. g., coordinating packets as a connection), among different associations (e. g., between connections), as well as helping optimize the recursive discovery process through caching, and supporting prefetching and distributed <b>pre-coordination.</b> This paper describes the DRUID architectur...|$|E
30|$|Mobile devices use a {{wireless}} channel as a transmission medium. Unlike wired networks, the time-varying condition on the wireless channel {{is the dominant}} cause of packet loss. TCP proposals mostly designed for wired networks are unable to react adequately to the packet loss due to channel noise, fading, or interference since they assume {{the only source of}} packet loss is congestion [31]. The random packet loss in the wireless channel makes it difficult for mobile nodes using one of those proposals (e.g. TCP CUBIC [32]) to estimate available channel bandwidth and achieve optimal TCP throughput. In addition, most of wireless protocols allow wireless devices to share the same channel through contention-based media access control (MAC) that includes procedures for initiating a new transmission, determining the channel state (e.g. available or unavailable), and managing retransmissions {{in the event of a}} busy channel or data loss. This has several limitations. If many nodes attempt to communicate at the same time, for example, many collisions may occur lowering the available bandwidth. Furthermore, there is no appropriate method to prioritize data traffic and prevent unfair transmissions without <b>pre-coordination.</b> Not many studies have been made on TCP performance of mobile distributed applications under these limitations.|$|E
40|$|Certifying {{electronic}} components {{is a very}} involved process. It includes <b>pre-coordination</b> with the radiation test facility for time, schedule and cost, as well as intimate work with designers to develop test procedures and hardware. It also involves work with radiation engineers to understand {{the effects of the}} radiation field on the test article/setup as well as the analysis and production of a test report. The technical content of traditional ionizing radiation testing protocol is in wide use and generally follows established standards (ref. Appendix C). This document is not intended to cover all these areas but to cover the methodology of using Variable Depth Bragg Peak (VDBP) to accomplish the goal of characterizing an electronic component. The Variable Depth Bragg Peak (VDBP) test method is primarily used for deep space applications of electronics. However, it can be used on any part for any radiation environment, especially those parts where the sensitive volume cannot be reached by the radiation beam. An example of this problem would be issues that arise in de-lidding of parts or in parts with flip-chip designs, etc. The VDBP method is ideally suited to test modern avionics designs which increasingly incorporate commercial off-the-shelf (COTS) parts and units. Johnson Space Center (JSC) developed software provides assistance to users in developing the radiation characterization data from the raw test data...|$|E
40|$|Economic ethics {{describes}} {{the interaction of}} ethics and economics in explaining human action and in giving normative advice to ethically justifiable and efficient choices of action. As ethical economy, it analyses the ethical conditions of coordination in markets and the economic conditions of ethically legitimate behaviour. Ethical economy is a theory of the ethics {{and culture of the}} economy. Formal ethics is the <b>pre-coordination</b> of the economic coordination of the price system, material value ethics is the clarification of the value categories of goods and a general theory of value and good. Economic ethics is applied to the questions of incomplete contracts, professional ethics and the marginal ethics of an industry, and conflicts of interest. Business ethics {{describes the}} role of ethics in commercial firms and not-for-profit organisations. It is an organisational ethics and an individual ethics since there is organisational and individual failure to act properly. Individual ethics can neither be substituted for institutional ethics nor institutional ethics by individual ethics. The basic principles of business ethics in business interactions are mutual value creation and serving contracts. The role of the manager is not only to be the agent of the owners or shareholders but to be the fiduciary of the whole firm and to act in the common interest of the firm. The right incentives must be set in firms since there are also perverse incentives. Triple bottom line accounting that encompass ethical and environmental performance indicators introduces richer criteria of business success. Both articles are the longer versions of articles that were prepared for the leading German encyclopaedia, Brockhaus Enzyklopädie in 30 Bänden, 21 st edition, Leipzig (F. A. Brockhaus) Fall 2006. ...|$|E
40|$|A {{computer-assisted}} {{method of}} indexing and retrieving documents {{from a personal}} collection is described. The sys-tem allows input of author, title, bibliographic details and keywords. Documents are allocated a numeric code and stored sequentially. Three types of output are provided: an alphabetic keywords list with document reference numbers (including an author index), a reference list of document titles, bibliographic details and authors, and the output from searches upon the system. Use of the system can be by manual consultation of the indexes or by computer search using the Boolean operators AND or OR. Keywords are selected by the researcher/collection owner and can be up to 36 characters in length. This allows both for unusually long keywords and for <b>pre-coordination</b> of key-words, which in turn permits {{a high degree of}} specificity in the vocabulary if this is considered desirable. A facility is also included to allow for the allocation of subject categories to the documents in the collection. The collection is stored in box files and is added to sequentially. In practice a number of new documents is allowed to build up and these are indexed at regular intervals. It is stated that the system has many advantages both for the collection owners and documentalists/information personnel. It is easy to maintain and update, material {{does not have to be}} read through before indexing, a wide range of material can be entered, the system is easy to use and finally, the system allows information personnel to serve a far wider user group by relieving them of this indexing task. Finally, some results of an analysis of thirteen collections are presented. These indicate wide variations whose probable causes are individual indexing styles and different areas of science. Relations between postings and collection size and between depth of indexing and vocabulary size are indicated...|$|E
40|$|Team {{formation}} {{is the most}} rudimentary form of interactions in distributed AI and multiagent systems as it allows coherent collections of agents {{to work together in}} a beneficial manner towards a common goal of interest. Basically, individual expertise are assembled together in an additive fashion for accomplishing tasks together. A plethora of the related studies found in the literature often make several unrealistic assumptions such as coordination amongst the agents, or agents having knowledge of the whole environment, or agents and/or tasks are of the same kind, or a static environment setting. Against this background, we argue that there are real-world characteristics that make team formation more challenging: (1) There is no or minimal <b>pre-coordination</b> since storage and retrieval is a costly affair, (2) There is diversity amongst types of agents (Apprentices, Generalists, and Specialists) and tasks (Low, Medium, and High), (3) The environment is open i. e., agents and tasks can leave and enter the environment, and (4) Agents are continuously learning and improving their capabilities. The main contribution of this research is to study in great depths the impacts of various permutations of open and diverse environments on team formation and how agents learn to form these teams. Based on the findings of these studies, we demonstrate that both diversity and openness have impacts on the team formation. Having evaluated the results of the impacts of openness and diversity on the environment we, to strengthen the robustness of the original model, we introduce an enhanced version of this model. The next contribution of this thesis is putting forth an enhanced probabilistic modelling solution. To be able to carry out new investigations and introduce the new model, we have restructured and cleaned up the simulation software used for building the original model. Having implemented the enhanced model, we then show how this new model performs better than the original model. The final contribution of this thesis was to show why the new model performed better than the original model. Advisor: Leen-Kiat So...|$|E
40|$|As {{computational}} {{devices and}} entities become further established as routine, omnipresent components of {{our everyday lives}} (e. g., wearable sensors, smart homes, cyber-physical systems, embodied agents, human-robot interactions), such systems face an increased pressure to perpetually understand the complex, noisy, uncertain world around them in real-time. This environmental knowledge enables computational systems to intelligently decide how to best behave {{in response to the}} current situation, adapt to the ever-changing conditions of the dynamic world, and accomplish system goals that ultimately aim to improve our daily experience. However, achieving and maintaining such knowledge is very complicated due to the complexities and challenging properties of real-world environments. ^ In this research, we study how to improve environment knowledge in intelligent agents and multiagent systems through reflective, deliberative information gathering. By being deliberative, an agent intentionally and selectively chooses how to gather information. By being reflective, an agent can self-evaluate its informational needs and performance in order to understand its needs and past sensing outcomes to best guide deliberative information gathering, as well as adapt and learn in an uncertain environment. Within reflective, deliberative information gathering, this dissertation addresses two key problems: (1) the Analysis Problem, whereby an agent must determine how to measure and balance sensing benefits and costs in order to reflect and improve deliberative information gathering, (2) the Information Sharing Problem, whereby multiple agents must determine how to cooperatively sense together and share information to update collective beliefs. ^ For the Analysis Problem, we propose two improvements to a popular framework for reasoning under uncertainty—partially observable Markov decision processes (POMDPs) : (1) Potential-based Reward Shaping (PBRS) providing metareasoning about information gathering within time-constrained planning, and (2) Difference-based Heuristic Selection (DHS) with Long Sequence Entropy Minimization (LSEM) for situationally-aware planning capable of balancing knowledge improvement and costs minimization. For the Information Sharing Problem, we propose two solutions for improving large team information sharing observing localized, non-stationary phenomena: (3) cooperative change detection and response and (4) forgetting-based adaptation of information sharing. We also propose: (5) a learning-based approach for ad hoc information gathering that enables agents to learn how to share information without requiring <b>pre-coordination.</b> ...|$|E
40|$|Future space {{applications}} {{are likely to}} rely heavily on Ka-band frequencies (20 - 40 GHz) for communications traffic. Many space research activities are now conducted using S-band and X-band frequencies, which are becoming congested and require a degree of <b>pre-coordination.</b> In addition to providing relief from frequency congestion, Ka-band technologies offer potential size, weight, and power savings when compared to lower frequency bands. The use of the 37. 0 - 37. 5 and 40. 0 - 40. 5 GHz bands for future planetary missions was recently approved at the 1992 World Administrative Radio Conference (WARC- 92). WARC- 92 also allocated the band 25. 25 - 27. 5 GHz to the Intersatellite Service on a primary basis to accommodate Data Relay Satellite return link requirements. Intersatellite links are defined to be between artificial satellites and thus a communication link with {{the surface of a}} planetary body, such as the moon, and a relay satellite orbiting that body are not permitted in this frequency band. This report provides information about preliminary communications system concepts for forward and return links for earth-Mars and earth-lunar links using the 37. 0 - 37. 5 (return link) and 40. 0 - 40. 5 (forward link) GHz frequency bands. In this study we concentrate primarily on a conceptual system for communications between earth and a single lunar surface terminal (LST), and between earth and a single Mars surface terminal (MST). Due to large space losses, these links have the most stringent link requirements for an overall interplanetary system. The earth ground station is assumed to be the Deep Space Network (DSN) using either 34 meter or 70 meter antennas. We also develop preliminary communications concepts for a space-to-space system operating at near 26 GHz. Space-to-space applications can encompass a variety of operating conditions, and we consider several 'typical' scenarios described in more detail later in this report. Among these scenarios are vehicle-to-vehicle communications, vehicle-to-geosyncronous satellite (GEO) communications, and GEO-to-GEO communications. Additional details about both the interplanetary and space-to-space communications systems are provided in an 'expanded' final report which has been submitted to the Tracking and Communications Division (TCD) at the NASA Johnson Space Center...|$|E
40|$|In {{this article}} a {{detailed}} description of the gallium-based nitride, oxide and Oxonitride phases, their synthesis methods and properties is provided. The stoichiometric gallium nitride (GaN) crystallizes in three known polymorphs. The stable phase at ambient conditions is the hexagonal wurtzite-type structure, where the gallium atoms are tetrahedral coordinated by their nearest neighbours. The problem in synthesizing single crystals for substrates and wafers due to decomposition of GaN below the melting point is presented as well as the approach of heteroepitaxial growth techniques for GaN thin films. Concerning gallium oxide (Ga 2 O 3) the main focus lies on the description of the numerous polymorphs. The stable monoclinic betha-Ga 2 O 3 exhibits like GaN a direct wide-band gap, which can be tuned within a large range by synthesis conditions and dopants. The other phases of Ga 2 O 3 are less investigated and often show low crystallinity. The importance of the gallium nitride and gallium oxide for a large family of electronic and optical applications leads to an increasing interest in the ternary system Ga-O-N. Thus the article mainly deals with gallium oxide nitride, characterized by direct gallium-Nitrogen and gallium-oxygen bonds. The right nomenclature following IUPAC conventions for these materials is said to be gallium oxonitrides. Beside the amorphous oxonitrides known since the 1970 s the approaches in theoretical and experimental investigations on crystalline gallium oxonitride are presented here. The defect spinel structure is according to first principal methods believed to be the lowest in energy, nevertheless still showing positive formation energy. Experimental results confirmed the formation of a defective spinel structure exhibiting vacancies on cation and anion sites. Because of the positive formation energy, high temperature high pressure synthesis techniques are necessary. One approach is the formation of the spinel phase by the reaction of GaN-Ga 2 O 3 mixtures. Here pressures and temperatures in the range of 5 GPa and 1700 °C are needed because of the low energy state of betha-Ga 2 O 3. The advantage of a single source molecular precursor approach is pointed out. The <b>pre-coordination</b> of gallium with nitrogen and oxygen leads to formation temperatures of about 1100 °C. Showing also a direct wide band gap these gallium oxonitrides are believed to have high potential for future electronic and optical applications...|$|E

