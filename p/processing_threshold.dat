18|164|Public
5000|$|Since reef {{flat and}} rocky shore {{foraging}} occurs at multiple sites at variable distances from the residential camp, the authors calculated the mean one-way travel distance <b>processing</b> <b>threshold</b> ( [...] , in meters) for each species. The CPF model accurately predictsfield processing {{for the majority}} of reef flat foraging events for bivalves. Hippopus andTridacna have small <b>processing</b> <b>threshold</b> distances ( [...] = 74.6 and 137 respectively),and no shell is returned to camp at distances beyond 150 meters. Women’s fit nears100%, but children and men made the optimal choice less frequently because they usuallyforage for shellfish opportunistically, and therefore do not always carry the appropriateprocessing technology.|$|E
5000|$|For {{gastropods}} (Lambis lambis, [...] = 278.7), {{the model}} accurately predicts processingonly 58-59% of the time. This could in part {{be due to}} a preference for cooking some species inside of their shells (i.e. the shell has some utility), or also because some prey items are prepared at “dinner-time camps” rather than the residential camp. A. violascens and N. undata are never field processed, consistent with their large <b>processing</b> <b>threshold</b> distances (2418.5 and 5355.7 respectively).|$|E
30|$|Before <b>processing</b> <b>threshold</b> segmentation, some {{pre-processing}} {{steps for}} the original image are required. First, the original image is changed into gray-scale image. Then, noise points made by stray light and camera noise in the image are removed by weighted median filtering method.|$|E
40|$|Specific {{language}} impairment is {{a developmental}} language-based learning disorder affecting {{six to eight}} percent of children entering kindergarten. The etiology of specific language impairment is currently unknown. One prevalent hypothesis asserts that difficulty in efficiently processing rapidly occurring auditory events such as rapid frequency transitions within the speech stream is underlying the language deficits of children with specific language impairment. Previous research examining temporal auditory <b>processing</b> <b>thresholds</b> in school-age children and infants has elicited {{evidence in support of}} this hypothesis. However, temporal auditory <b>processing</b> <b>thresholds</b> have yet to be investigated in toddlers and preschoolers, an important age range for language acquisition. This pilot study tested the feasibility of a new behavioral task created to measure temporal auditory <b>processing</b> <b>thresholds</b> in young children. The results of this pilot study indicate a pattern to warrant further investigation testing {{the reliability and validity of}} this task. A sensitive measure of temporal auditory <b>processing</b> <b>thresholds</b> in young children would contribute to the understanding of language acquisition and could have potential implications for the screening of specific language impairment in toddlers and preschoolers. Keywords: language, auditory perception, rapid auditory processing, specific languag...|$|R
40|$|In {{digital image}} <b>processing,</b> <b>thresholding</b> is a {{well-known}} technique for image segmentat ion. Because of its wide applicability {{to other areas of}} the digital image processing, quite a number of thresholding methods have been proposed over the years. In this paper, we present a survey of thresholding techniques and update the earlier survey work by Weszka (Comput. Visio...|$|R
40|$|Abstract—Segmentation {{is one of}} the {{essential}} tasks in image <b>processing.</b> <b>Thresholding</b> {{is one of the}} simplest techniques for performing image segmentation. Multilevel thresholding is a simple and effective technique. The primary objective of bi-level or multilevel thresholding for image segmentation is to determine a best thresholding value. To achieve multilevel thresholding various techniques has been proposed. A study of some nature inspired metaheuristic algorithms for multilevel thresholding for image segmentation is conducted. Here, we study about Particle swarm optimization (PSO) algorithm, artificial bee colony optimization (ABC), Ant colony optimization (ACO) algorithm and Cuckoo search (CS) algorithm. Keywords—Ant colony optimization, Artificial bee colon...|$|R
40|$|Mammogram {{breast cancer}} images {{have the ability}} to assist {{physicians}} in detecting disease caused by cells normal growth. Developing algorithms and software to analyze these images may also assist physicians in there daily work. This study that shows the outcome of applying image <b>processing</b> <b>threshold,</b> edge-based and watershed segmentation on mammogram breast cancer image and also presents a case study between them based on time consuming and simplicity...|$|E
40|$|Abstract. This paper compares and {{analyzes}} the common recognition method and technology of irregular graphics and image, and {{its application to}} specific graphics recognition. In this paper, the application system realizes the image histogram <b>processing,</b> <b>threshold</b> value processing and edge processing, realizes the binary image, and then compared with database information, recognizing the need of graphic information, but also the graphic information such as encryption and decryption. The system is practical, the application scope is very broad, and has good popularization value...|$|E
40|$|This article {{introduces}} a method which adopts the computer image manipulation {{to process the}} collected images of yarn black. Aiming at the hairiness and scratches existing in the yarn blackboard, we adopt the methods such as smoothness <b>processing,</b> <b>threshold</b> value division and image repairing to obtain a clear digital image without yawp points and exactly measure the yarn diameter. Comparing with the actual yarn diameter, the computed yarn diameter accords with the actual diameter, which proves that the yarn diameter measured by image processing method is accurate, exactly reflects the appearance features of the yarn such as slubs, neps and nips, and establishes {{the foundation for the}} automatic assessment of the yarn blackboard...|$|E
40|$|This study {{investigated}} temporal integration processes underlying cochlear implant (CI) users’ amplitude modulation <b>processing.</b> <b>Thresholds</b> for modulation detection (AMDTs) and modulation frequency discrimination (AMFDTs) were measured for 50 -, 100 -, and 200 -Hz modulation frequencies with stimulus durations from 50 to 400 ms in eight adult CI users. The results showed significant interactions between modulation frequency and stimulus duration for AMDTs and AMFDTs. The {{data suggest that}} temporal integration limits CI users’ sensitivity to low temporal pitch over short durations, and that temporal integration over longer durations may not enhance CI users’ sensitivity to high temporal pitch...|$|R
40|$|The main {{topic of}} this work is focused on a {{connection}} of a camera with PC and processing of the gained pictures. There are described basic concepts of image processing and coding standards of the color signal. Attention is devoted mainly to PAL system, which is used by our camera. Furthermore, there are summarized and described the basic methods for image <b>processing</b> (<b>thresholding,</b> averaging, convolution, etc.). These methods are also used {{for the detection of}} the fundamental position of the eyes. This detection is designed to be the most universal and applicable on the various images obtained...|$|R
40|$|The thesis {{consists}} of three parts. Theoretical description of digital image processing, optical character recognition and design of system for car licence plate recognition (LPR) in image or video sequence. Theoretical part describes image representation, smoothing, methods used for blob segmentation and proposed are two methods for optical character recognition (OCR). Concern of practical part is to find solution and design procedure for LPR system included OCR. The design contain image pre-processing, blob segmentation, object detection based on its properties and OCR. Proposed solution use grayscale trasformation, histogram <b>processing,</b> <b>thresholding,</b> connected component,region recognition based on its patern and properties. Implemented is also optical recognition method of licence plate where acquired values are compared with database used to manage entry of vehicles into object...|$|R
40|$|Mammography is {{a special}} case of CT scan who adopts X-ray method & uses the high {{resolution}} film {{so that it can}} detect well the tumors in the breast. Low radiation is the strength of this method. Mammography is especially used only in the breast tumor detection Mammogram breast cancer images have the ability to assist physicians in detecting disease caused by cells normal growth. Developing algorithms and software to analyse these images may also assist physicians in there daily work. This study that shows the outcome of applying image <b>processing</b> <b>threshold,</b> edge based and watershed segmentation on mammogram breast cancer image and also presents a case study between them based on time consuming and simplicity. The real-time implementation of this paper can be implemented using data acquisition hardware and software interface with th...|$|E
40|$|This paper {{examines}} {{data processing}} and probability analysis of pulsed terahertz NDE scans of corrosion defects under a Shuttle tile. Pulsed terahertz {{data collected from}} an aluminum plate with fabricated corrosion defects {{and covered with a}} Shuttle tile is presented. The corrosion defects imaged were fabricated by electrochemically etching areas of various diameter and depth in the plate. In this work, the aluminum plate echo signal is located in the terahertz time-of-flight data and a threshold is applied to produce a binary image of sample features. Feature location and area are examined and identified as corrosion through comparison with the known defect layout. The results are tabulated with hit, miss, or false call information for a probability of detection analysis that is used to identify an optimal <b>processing</b> <b>threshold...</b>|$|E
40|$|International audienceSpectrum Sensing {{is widely}} used in smart or cognitiveradio {{transmission}} system in order to allocate unusedbandwidth by a primary user to a secondary user. The allocationscheme depends on determining a threshold reflecting theexistence or not of the primary user. This manuscript deals withthis problem by proposing two major contributions: the first oneis a novel mechanism to calculate the threshold based on a knowndistribution of the correlation function between the pilot and thereceived signal. Our main finding is that the threshold couldbe, in some circumstances, independent from the SNR whichrelieves the detector from <b>processing</b> <b>threshold</b> updates in casewhen the SNR frequently varies. In the second contribution weuse the Waveform technique in order to detect the existing or notof Primary user signals while a secondary user is transmittingwithout interrupting the detection mechanism of the primaryuser. Contrary to existing methods, which require a silence periodof secondary users in order to sense {{the activity of the}} primaryuser, our approach does not need this period which enhances thetotal transmission rate. Our simulation results corroborate the two proposed approaches. Simulation results are presented and discussed...|$|E
40|$|Abstract — Polymerase chain {{reaction}} (PCR) using microma-chined structures promises improved temperature uniformity and cycling time together with decreased reagent and sample volumes. Thermal design of these structures {{will benefit from}} measurements of the temperature distribution in the reacting liquid. We report measurements of temperature uniformity and time constant in a microfabricated 18 -vessel array using encap-sulated liquid crystals suspended in the liquid. Separate sets of crystals are used to image temporal and spatial temperature variations near the <b>processing</b> <b>thresholds</b> of 55 C and 95 C with a resolution of 0. 1 C. While the thermometry technique developed here is particularly useful for characterizing microfabricated PCR systems, it can also aid with the thermal design of a broad variety of microfluidic devices. [330] Index Terms — Design, liquid crystals, microfabrication, mi-crofluidic, polymerase {{chain reaction}}, thermometry...|$|R
40|$|Dark blue {{rings and}} circles emerged when the {{non-specific}} polysaccharide stain lactophenol cotton blue {{was added to}} Gram stained slides. The dark blue staining is attributable {{to the presence of}} capsular polysaccharides and bacterial slime associated with clumps of Gram-negative bacteria.  Since all bacterial cells are glycosylated and concentrate polysaccharides from the media, the majority of cells stain light blue. The contrast between dark and light staining is sufficient to enable a digital image <b>processing</b> <b>thresholding</b> technique to be quantitative with little background noise. Prior to the addition of lactophenol cotton blue, the Gram-stained slides appeared unremarkable, lacking ubiquitous clumps or stained polysaccharides.  Adding lactophenol cotton blue to Gram stained slides is a quick and inexpensive way to screen cell cultures for bacterial slime, clumps and biofilms that are invisible using the Gram stain alone...|$|R
40|$|Image {{segmentation}} {{is one of}} {{the important}} tasks in computer vision and image <b>processing.</b> <b>Thresholding</b> isa simple but most effective technique in segmentation. It based on classify image pixels into object andbackground depended on the relation between the gray level value of the pixels and the threshold. Otsutechnique is a robust and fast thresholding techniques for most real world images with regard to uniformityand shape measures. Otsu technique splits the object from the background by increasing the separabilityfactor between the classes. Our aim form this work is (1) making a comparison among five thresholdingtechniques (Otsu technique, valley emphasis technique, neighborhood valley emphasis technique, varianceand intensity contrast technique, and variance discrepancy technique) on different applications. (2) determining the best thresholding technique that extracted the object from the background. Ourexperimental results ensure that every thresholding technique has shown a superior level of performanceon specific type of bimodal images...|$|R
40|$|A {{process for}} {{fabricating}} PMOS transistors and test devices {{has been developed}} for educational purposes {{as part of a}} microfabrication undergraduate/graduate laboratory course at the University of Louisville. This is to help students from multiple disciplines to understand and perform basic microfabrication processes. Several designs of PMOS devices were fabricated using standard processes such as oxidation, photolithography, diffusion, and sputtering. Process characterization involved testing PMOS transistors, Cross Bridge Kelvin Structures, and Van der Pauw structures. Characterization of PMOS transistors was performed using I-V curves for varying oxide thicknesses (tox) grown using dry oxidation, wet oxidation and RTP (rapid thermal <b>processing).</b> <b>Threshold</b> voltages ranged from 1 volt for the thin RTP gate oxide to over 4 volts for the thicker gate oxide. Threshold voltages (Vth) were also compared to the theoretical values. Van der Pauw structures were used to determine sheet resistance (Rs) 2 ̆ 6 Cross Bridge Kelvin structures for determining contact resistance (Rc). Effects on MOS-capacitors, due to gate oxide thickness, band bending with varying gate voltage and how these factors effect the functioning of transistors have been explained with the results of the fabricated devices...|$|E
40|$|Hydroacoustic {{monitoring}} of fish growing in sea cages needs of an accurate relationship between fish size and target strength (TS) for every species of commercial interest. We discuss {{the conditions for}} TS measurement in near range conditions in sea cages for {{the case of the}} dorsal and ventral aspects of gilthead sea bream and bluefin tuna. Gilthead sea bream dorsal and ventral TS distributions, obtained with a split beam echosounder, are unimodal and the same results are derived for single beam data analysis when specific <b>processing</b> <b>threshold</b> criteria are applied. The expected linear relationship between the average TS and the logarithm of fish length is only found for the ventral case, being more accurate the uncompensated TS single beam analysis, probably due to near range errors. Bluefin tuna dorsal measurements performed in a fattening farm from February to July did not show a significant variation of TS distributions, and we propose a synchronized system of echosounder and video recordings, in order to relate target strength and orientation and size of specific tuna in the acoustic beam. Preliminary results indicate that only ventral TS values correlate properly with tuna size...|$|E
40|$|Abstract—Edges {{characterize}} object {{boundaries in}} image {{and are therefore}} useful for segmentation, registration, feature extraction, and identification of objects in a scene. Edges detection is used to classify, interpret and analyze the digital images in a various fields of applications such as robots, the sensitive applications in military, optical character recognition, infrared gait recognition, automatic target recognition, detection of video changes, real-time video surveillance, medical images, and scientific research images. There are different methods of edges detection in digital image. Each one of these methods is suited to {{a particular type of}} images. But most of these methods have some defects in the resulting quality. Decreasing of computation time is needed in most applications related to life time, especially with large size of images, which require more time for <b>processing.</b> <b>Threshold</b> is one of the powerful methods used for edge detection of image. In this paper, We propose a new method based on different Multi-Threshold values using Shannon entropy {{to solve the problem of}} the traditional methods. It is minimize the computation time. In addition to the high quality of output of edge image. Another benefit comes from easy implementation of this method. Keywords—image processing; multi-threshold; edges detection; clustering I...|$|E
30|$|Developed over 15 years ago, the maximum-likelihood-probabilistic data {{association}} {{target tracking}} algorithm {{has been demonstrated}} {{to be effective in}} tracking very low observable (VLO) targets where target signal-to-noise ratios (SNRs) require very low detection <b>processing</b> <b>thresholds</b> to reliably give target detections. However, this algorithm has had limitations, which in many cases would preclude use in real-time tracking applications. In this paper, we describe three recent advances in the ML-PDA algorithm which make it suitable for real-time tracking. First we look at two recently reported techniques for finding the ML-PDA track estimate which improves computational efficiency by one order of magnitude. Next we review a method for validating ML-PDA track estimates based on the Neyman-Pearson lemma which gives improved reliability in track validation over previous methods. As our main contribution, we extend ML-PDA from a single-target tracker to a multitarget tracker and compare its performance to that of the probabilistic multihypothesis tracker (PMHT).|$|R
40|$|Increasing {{importance}} {{has been}} placed on particle shape implementation within discrete element modelling (DEM) in order to more accurately reflect the non-spherical behaviour of the bulk material being handled. As computational resources grow, complex particle shapes are increasingly being modelled as the associated simulation times become more realistic to provide timely solutions. The objective of this research is to assess particle shape descriptors through a digital image segmentation technique, and to further implement particle shape parameters into generation of corresponding irregular shaped DEM particles. Separated and lumped particle images were analysed and reconstructed through the development of two distinct methodologies. Subsequently, various particle shape descriptors were obtained using combinations of image segmentation algorithms, including mathematical morphology <b>processing,</b> <b>thresholding,</b> edge detection, region growing, region splitting and region merging. DEM particles were subsequently created using particle shape results obtained above. Shape parameters of DEM particles were then examined and validated against the real particle shape parameters...|$|R
40|$|Developed over 15 years ago, the Maximum Likelihood–Probabilistic Data Association target {{tracking}} algorithm {{has been demonstrated}} {{to be effective in}} tracking Very Low Observable (VLO) targets where target signal-to-noise ratios (SNR) require very low detection <b>processing</b> <b>thresholds</b> to reliably give target detections. However this algorithm has had limitations, which in many cases would preclude use in realtime tracking applications. In this paper we describe three recent advances in the ML-PDA algorithm which make it suitable for real-time tracking. First we look at two recently reported techniques for finding the ML-PDA track estimate which improves computational efficiency by one order of magnitude. Next we review a method for validating ML-PDA track estimates based on the Neyman-Pearson Lemma which gives improved reliability in track validation over previous methods. As our main contribution, we extend ML-PDA from a single-target tracker to a multi-target tracker and compare its performance to that of the Probabilistic Multi-Hypothesis Tracker (PMHT) ...|$|R
40|$|Various Edge {{detection}} algorithms {{have been}} proposed in the literature for extracting the edges from the image. But after emerging the fuzzy logic concept, a lot of Researcher of image processing has been shifted towards the fuzzy logic and its applicability {{in the field of}} image processing. This paper presents a fuzzy rule base algorithm, in MATLAB environment, which is capable of detecting edges of an input image by scanning it throughout using a 2 * 2 pixel window efficiently from the gray scale images. Fuzzy inference system designed has four inputs, which corresponds to four pixels of instantaneous scanning matrix, one output that tells whether the pixel under consideration is “low”, “medium ” or “high ” pixel. Rule base comprises of seven rules, which classify the target pixel. Also, a Graphical User Interface (GUI) in MATLAB has been designed to aid the loading of the image, and to display the resultant image at different intermediate levels of <b>processing.</b> <b>Threshold</b> level for the image can be set from the slider control of GUI. Main feature of the algorithm is that it has been designed by the smallest possible mask with less number of rules i. e. 2 * 2 with seven rules unlike 3 * 3 or bigger masks found in the literature...|$|E
40|$|This paper {{reports the}} implementation, in MATLAB environment, {{of a very}} simple but {{efficient}} fuzzy logic based algorithm to detect the edges of an input image by scanning it throughout using a 2 * 2 pixel window. Also, a Graphical User Interface (GUI) in MATLAB {{has been designed to}} aid the loading of the image, and to display the resultant image at different intermediate levels of <b>processing.</b> <b>Threshold</b> level for the image can be set from the slider control of GUI. Fuzzy inference system designed has four inputs, which corresponds to four pixels of instantaneous scanning matrix, one output that tells whether the pixel under consideration is “black”, “white ” or “edge ” pixel. Rule base comprises of sixteen rules, which classify the target pixel. Algorithm for the noise removal has been implemented at different levels of processing. The resultant image from FIS is subjected to first and second derivative to trace the edges of the image and for their further refinement. The results of the implemented algorithm has been compared with the standard edge detection algorithm such as ‘Canny’, ‘Sobel’, ‘Prewit ’ and ‘Roberts’. Main feature of the algorithm is that it has been designed by the smallest possible mask i. e. 2 * 2 unlike 3 * 3 or bigger masks found in the literature...|$|E
40|$|A novel drifter {{platform}} {{was used}} to measure the properties of aggregated particles called flocs—a key component of sediment transport in muddy environments. Also concurrently measured were turbulence, suspended sediment concentration (SSC), velocity, and salinity in both Lagrangian and Eulerian frames of reference. In Lagrangian mode the system performed well in a heavily sediment-laden river, providing measurements over a large spatial scale. The platform navigated itself through a complex geometry encompassing many bends and significant depth changes. Observed velocities relative to the drifter and salinities indicated that the drifter motion was almost Lagrangian with minimal slippage between the drifter and the water motion. The small amount of slippage that did occur was sufficient to ensure that the drifter oriented itself into the oncoming flow. High-quality in situ images of flocs were collected using a high-magnification floc camera (FlocCam). An automatic image analysis routine was developed to identify and characterize flocs within each FlocCam image, employing an artificial neural network (ANN) to ensure that only in-focus particles were included in the analyses. The results indicated that the FlocCam system had an upper working SSC limit of around 350 – 400 mg L⁻¹. The SSC estimates show that the drifters encountered considerable variability as they were advected downstream; however, concentrations predominantly remained under the image <b>processing</b> <b>threshold</b> of 350 – 400 mg L⁻¹. The system captured the evolution of floc characteristics over short spatial scales (hundreds of meters). The median floc size (d₅₀) was found to be positively correlated with SSC (r² = 0. 5). A comparison between Eulerian and Lagrangian floc histories can then be used to evaluate the role of antecedent conditions within the flocculation process...|$|E
40|$|The Large Time Frequency Analysis Toolbox (LTFAT, [URL] is free, {{open source}} Octave/Matlab toolbox {{for working with}} time-frequency {{analysis}} and synthesis. It is intended both as an educational and a computational tool. The toolbox provides {{a large number of}} linear transforms including Gabor and wavelet transforms. The wavelet module provides routines for calculating various discrete and discretized wavelet transforms, reconstructions from their coefficients and coefficient manipulation and plotting. In the fully discrete case, apart from the routines using the well-known Mallatâs iterated two-channel filterbank the module provides a framework for working with any tree-shaped filterbanks (e. g. wavelet packets) but individual nodes of the tree are not restricted to the two-channel critically subsampled case. In addition, the module includes an implementation of the SegDWT algorithm for calculating wavelet transforms block-wise, such that blocks of the input data stream are analyzed and synthesized without creating block artifacts even after any kind of a coefficient <b>processing</b> (<b>thresholding,</b> compression). In the talk, we will introduce capabilities of the toolbox and will also give an overview of the used algorithms...|$|R
30|$|On {{the basis}} of {{infrared}} image denoising method based on wavelet coefficient <b>threshold</b> <b>processing,</b> {{the advantages and disadvantages}} of soft and hard threshold functions are deeply analyzed, and an adaptive threshold function with adjustable parameters is constructed.|$|R
40|$|We {{present a}} new method for extracting objects moving {{independently}} of the background from a video sequence taken by a moving camera. We first extract and track feature points through the sequence and select the trajectories of background points by exploiting geometric constraints based on the affine camera model. Then, we generate a panoramic image of the background and compare it with the individual frames. We describe our image <b>processing</b> and <b>thresholding</b> techniques. 1...|$|R
40|$|Abstract − Models of {{simulated}} {{schools have}} been used to determine the intrinsic variability in echotraces due to beam pattern effect. This work concerns only morphometric and energetic parameters that can be extracted from echotraces. It appears that dST, the difference between school density and <b>processing</b> <b>threshold</b> is a key parameter, which directly influences the concerned detection angles. Relations, taking into account dST but also, Nbi, the relative school length image compared to the beam width, have been settled for the calculation of length and density corrections. In most cases, corrected values are obtained with errors less than respectively 5 % for length and 0. 5 dB for density (reverberation index), provided that the Nbi value is 1. 5 or more. When Nbi is less than 1, it seems impossible to bring some pertinent corrections. The school energy does not need any correction. It is recommended to use threshold values not too low, to avoid detection through the side lobes. However this setting must be determined in order to obtain dST values greater than 10 dB. Thresholds between – 60 and – 65 dB seem adequate, at least for schools volume backscattering strength (VBS, Sv) values commonly encountered in the Bay of Biscay. © 2001 Ifremer/CNRS/Inra/IRD/Cemagref/Éditions scientifiques et médicales Elsevier SAS acoustic / fish detection / fish schools Résumé − Correction de descripteurs géométriques et énergétiques extraits de bancs de poissons: approche basée sur de la simulation d’images acoustiques. Une analyse de la variabilité des descripteurs extraits des échos de bancs de poissons a été effectuée en tenant compte des différents paramètres qui conditionnent l’image acoustique obtenue grâce au sondeur vertical...|$|E
40|$|BACKGROUND: Tissue {{abnormality}} {{is usually}} {{related to a}} dissimilar part of an otherwise homogeneous image. Choosing the optimal post <b>processing</b> <b>threshold</b> value can be difficult because the image composition may {{vary depending on the}} acquisition parameters and the type of tissue. Hierarchical Clustering-based Segmentation (HCS) is an approach to Computer Aided Monitoring (CAM) that enables a user to define a region of interest and the process generates a hierarchy of segmentation results to highlight the varied dissimilarities that might be present. HCS allows the user to derive the maximum benefit from the computational capability (perception) of the machine while at the same time, enabling them to incorporate their own interpretation in the appropriate place. This achieves a complementary synthesis of both computer and human strengths [1]. Aim of the Study: HCS PROCESS AS AN AID TO DIAGNOSIS IN mpMRI OF PROSTATE To evaluate HCS process as semi-quantitative analytical tool, to complement radiologist's interpretation of mpMR images of prostate METHOD: In prostate cancer, the leaky characteristics of the tumour angiogenesis, is demonstrated in DCE-MRI by the early rapid high enhancement just after the administration of contrast medium followed immediately by a relatively rapid decline. In comparison there will be a lower and continuously increasing enhancement for normal tissues. The above characteristics can be demonstrated by the quantitative measurement of signal enhancement in DCE-MRI with time i. e. Time Intensity Curve (TIC). The characteristic shape of the TIC (Figure 2) may be used for supporting diagnosis. Within the user defined ROI, the HCS process is applied to the DCE-MRI temporal frame of a slice of interest identified by the user. For qualitative analysis, for dissimilar regions, HCS process provides following (Fig. 3 A, B) heat map, regions coloured as per their TIC types and correlation with T 2 regions. For quantitative analysis, parametric image of the time intensity curves of the contrast wash-in, wash-out process are plotted for suspicious regions confirmed by user (Fig. 3 C) ...|$|E
40|$|Dynamic Contrast Enhanced Magnetic Resonance Imaging (DCE-MRI) {{has become}} an {{important}} component in the diagnostic imaging pathway and is emerging as a useful clinical technique for evaluating the severity, location, and extent of primary and recurrent cancer. But DCE-MRI typically generates around 30 images per section and image interpretation requires substantial experience to detect and categorize lesions. Tissue abnormality is usually related to a dissimilar part of an otherwise homogeneous image. Choosing the optimal post <b>processing</b> <b>threshold</b> value can be difficult because the image composition may {{vary depending on the}} acquisition parameters and the type of tissue. Hierarchical Clustering-based Segmentation (HCS) is an approach to Computer Aided Monitoring (CAM) that enables a user to define a region of interest and the process generates a hierarchy of segmentation results to highlight the varied dissimilarities that might be present. This new HCS process based CAM system offers a versatile and flexible environment by allowing the user to derive the maximum benefit from the computational capability (perception) of the machine. At the same time, the user is able to incorporate their own interpretation in the appropriate place and thus limit the machine's interpretive function to achieve a complementary synthesis of both computer and human strengths. As a diagnostic aid for the analysis of DCE-MRI image data, the process starts with the user defining a rough region of interest (ROI) on a section/slice of choice. Within the user defined ROI, the HCS process is applied to all the DCE-MRI temporal frames of the slice. HCS process output provides heat map images based on the normalised average pixel value of the various dissimilar regions within the ROI. Time intensity curves of the contrast wash-in, wash-out process are then plotted for suspicious regions confirmed by the user. Early results suggest that the HCS process based CAM system offers increased capability to differentiate suspicious areas by combining users' expertise and computer system's processing capability. The application is useful at the point of first diagnosis because often lesions are not solitary in nature, which can result in an incomplete treatment regime and affect prognosis; and also in monitoring the effects of drugs or radiotherapy. Ongoing research applications of the HCS process based CAM system are prostate, breast, knee, brain, and liver imaging. An example of the HCS process based CAM system for prostate is outlined below. </p...|$|E
40|$|Satellite borne radar scatterometers provide {{frequent}} {{estimates of}} near surface wind vectors over the Earth’s oceans. However in the polar oceans, {{the presence of}} sea ice {{in or near the}} measurement footprint can adversely affect scatterometer measurements resulting in inaccurate wind estimates. Currently, such ice contamination is mitigated by discarding measurements within 50 km of detected sea ice. This approach is imperfect and causes loss of coverage. This thesis presents a new algorithm which detects ice-contaminated measurements based on a metric called the Ice Contribution Ratio (ICR) which measures the spatial ice contribution for each measurement. The ICR calculation is made for each measurement using a spatial ice probability map which is determined using Bayesian probability theory. Determined by simulation, the ICR <b>processing</b> <b>thresholds</b> the ICR for each measurement depending on local wind, ice backscatter, and cross-track location. ICR processing retrieves winds at a distance of 22. 5 km from the ice edge on average, while ensuring wind accuracy. Retrieved wind distributions using ICR processing more closely resembles uncontaminated wind distributions than winds retrieved using previous methods. The algorithm is applied to QuikSCAT in this thesis but could be applied to other scatterometers such as the Oceansat- 2 scatterometer...|$|R
50|$|Unimodal {{thresholding}} is an algorithm for automatic image threshold {{selection in}} image <b>processing.</b> Most <b>threshold</b> selection algorithms {{assume that the}} intensity histogram is multi-modal; typically bimodal. However, some types of images are essentially unimodal since a much larger proportion of just one class of pixels (e.g. the background) {{is present in the}} image, and dominates the histogram. In such circumstances many of the standard threshold selection algorithms will fail. However, a few algorithms have been designed to specifically cope with such images.|$|R
50|$|Circular {{thresholding}} is an algorithm for automatic image threshold {{selection in}} image <b>processing.</b> Most <b>threshold</b> selection algorithms {{assume that the}} values (e.g. intensities) lie on a linear scale. However, some quantities such as hue and orientation are a circular quantity, and therefore require circular thresholding algorithms. The example shows that the standard linear version of Otsu's Method when applied to the hue channel of an image of blood cells fails to correctly segment the large white blood cells (leukocytes). In contrast the white blood cells are correctly segmented by the circular version of Otsu's Method.|$|R
