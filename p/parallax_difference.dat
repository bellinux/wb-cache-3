2|10|Public
40|$|This paper {{describes}} {{the evolution of}} classic stereo-radargrammetric techniques to the bistatic spaceborne geometry. When a monostatic image and a bistatic one are adopted to form the stereoscopic pair, new relations are needed to define parallax {{as a function of}} the peculiar parameters of bistatic surveying geometry. Two models are analyzed to extract <b>parallax</b> <b>difference</b> from radar data: <b>parallax</b> <b>difference</b> estimation from SAR images and <b>parallax</b> <b>difference</b> calculation by exploiting slant-range equations. An error budget of elevation measurement accuracy has been performed, showing that bistatic radargrammetric techniques applied to a spaceborne scenario mission can achieve an error in height measurement adequate for several applications and lower than the one obtained by previous monostatic experiments...|$|E
40|$|We {{propose a}} method which {{constructs}} a panoramic depth image. We use a digital still {{camera and a}} panoramic lens. The lens has omnidirectional mirror that is pointed in the camera direction and the camera can shoot a horizontal panoramic image through it. We use two panoramic images to construct a panoramic depth image. Each image is photographed at different height {{and there is the}} <b>parallax</b> <b>difference</b> between these images. Our method seeks corresponding point between these images and calculates the depth value at each pixel. In addition, we had some experience to evaluate effectiveness of our method. The results shows that our method is useful for making three-dimensional contents form the real scenery...|$|E
50|$|Parallax {{scanning}} depth enhancing imaging methods rely on discrete <b>parallax</b> <b>differences</b> between depth planes in a scene. The differences {{are caused by}} a parallax scan. When properly balanced (tuned) and displayed, the discrete <b>parallax</b> <b>differences</b> are perceived by the brain as depth.|$|R
50|$|However, by 1917 refined {{measured}} <b>parallax</b> <b>differences</b> {{demonstrated that}} the separation was significantly less. The binary nature of this system was clear by 1934, and orbital elements were published.|$|R
40|$|Vision {{exploits}} {{multiple sources}} of optical information {{to specify the}} three-dimensional layout of objects and their surfaces. One of these sources is stereoscopic vision√∂the strong, immediate sense of 3 -D provided by the slight <b>parallax</b> <b>differences</b> between left-eye and right-eye views (Wheatstone 1838). The very keen sense of depth (Ogl...|$|R
5000|$|The {{perception}} of depth and 3-dimensional structure is, however, possible with information visible from one eye alone, such as differences in object size and motion <b>parallax</b> (<b>differences</b> {{in the image}} of an object over time with observer movement), though the impression of depth in these cases is often not as vivid as that obtained from binocular disparities.Therefore, the term stereopsis (or stereoscopic depth) can also refer specifically to the unique impression of depth associated with binocular vision; what is colloquially referred to as seeing [...] "in 3D".|$|R
40|$|An {{overview}} of Magellan Mission requirements, radar system characteristics, {{and methods of}} data collection {{is followed by a}} description of the image data, mosaic formats, areal coverage, resolution, and pixel DN-to-dB conversion. The availability and sources of image data are outlined. Applications of the altimeter data to estimate relief, Fresnel reflectivity, and surface slope, and the radiometer data to derive microwave emissivity are summarized and illustrated in conjunction with corresponding SAR image data. Same-side and opposite-side stereo images provide examples of <b>parallax</b> <b>differences</b> from which to measure relief with a lateral resolution many times greater than that of the altimeter. Basic radar interactions with geologic surfaces are discussed with respect to radar-imaging geometry, surface roughness, backscatter modeling, and dielectric constant. Techniques are described for interpreting the geomorphology and surface properties of surficial features, impact craters, tectonically deformed terrain, and volcanic landforms. The morphologic characteristics that distinguish impact craters from volcanic craters are defined. Criteria for discriminating extensional and compressional origins of tectonic features are discussed. Volcanic edifices, constructs, and lava channels are readily identified from their radar outlines in images. Geologic map units are identified on the basis of surface texture, image brightness, pattern, and morphology. Superposition, cross-cutting relations, and areal distribution of the units serve to elucidate the geologic history...|$|R
50|$|After Copernicus {{proposed}} his heliocentric system, {{with the}} Earth in revolution around the Sun, {{it was possible}} to build a model of the whole Solar System without scale. To ascertain the scale, it is necessary only to measure one distance within the Solar System, e.g., the mean distance from the Earth to the Sun (now called an astronomical unit, or AU). When found by triangulation, this {{is referred to as the}} solar <b>parallax,</b> the <b>difference</b> in position of the Sun as seen from the Earth's centre and a point one Earth radius away, i. e., the angle subtended at the Sun by the Earth's mean radius. Knowing the solar parallax and the mean Earth radius allows one to calculate the AU, the first, small step on the long road of establishing the size and expansion age of the visible Universe.|$|R
40|$|The visual {{function}} of lens accommodation was measured while subjects used stereoscopic vision {{with a head}} mounted display (HMD). Eyesight while viewing stereoscopic Landolt ring images displayed on HMD was also studied. Accommodation to virtual objects was seen when subjects viewed stereoscopic images of 3 D computer graphics, but not when the images were displayed without appropriate binocular parallax. This suggests that stereoscopic moving images on HMD induced visual accommodation. Accommodation should be adjusted {{to the position of}} virtual stereoscopic images induced by <b>parallax.</b> A <b>difference</b> in the distances of the focused display and stereoscopic image may cause visual load. However, an experiment showed that Landolt rings of almost the same size were distinguished regardless of virtual distance of 3 D images if the parallax was not larger than the fusional upper limit. The {{results of this study suggest}} that stereoscopic moving images on HMD induced visual accommodation by expansion and contraction of the ciliary muscle, which was synchronized with convergence. Appropriate parallax of stereoscopic vision should not reduce the visibility of stereoscopic virtual objects...|$|R
40|$|Image mosaics stitch photos into {{a single}} {{composite}} with a wide field of view. They are easy to create and can be panned by dragging the mouse, thus enabling simple and effective photorealistic visualizations. However, they are restricted to structured input where the camera motion is limited and the appearance variation across photos can be controlled. In my thesis, I extend mosaics to unstructured cases that include more general camera motion, appearance variation and Internet photo collections, enabling visualization of more complex scenes. I first develop a mosaicing technique for a general class of photo collections subsuming rotational mosaics. In contrast to prior approaches that stitch a single static mosaic, my approach dynamically composites a mosaic based on the current viewpoint as the user navigates, allowing for distortion-free mosaicing and {{a broader range of}} camera motion. Exposure <b>differences,</b> <b>parallax,</b> misalignment between photos and scene motion lead to stitching artifacts in static mosaics. My dynamic approach avoids these artifacts and enhances realism by preserving scene motion and changes in brightness...|$|R
40|$|Of all planet-finding techniques, microlensing is {{potentially}} {{the most sensitive}} to Earth-mass planets. However, microlensing lightcurves generically yield only the planet-star mass ratio: the mass itself is uncertain to a factor of a few. To determine the planet mass, one must measure both the ``microlens parallax'' and source-lens relative proper motion. Here we present a new method to measure microlens masses for terrestrial planets. We show that, with only a modest adjustment to the proposed orbit of the dedicated satellite that finds the events, and combined with observations from a ground-based observing program, the planet mass can be measured routinely. The dedicated satellite that finds the events will automatically measure the proper motion and one projection of the ``vector microlens parallax. '' If the satellite is placed in an L 2 orbit, or a highly elliptical orbit around the Earth, the Earth-satellite baseline is sufficient to measure a second projection of the vector microlens <b>parallax</b> from the <b>difference</b> in the lightcurves {{as seen from the}} Earth and the satellite as the source passes over the caustic structure induced by the planet. This completes the mass measurement. Comment: 5 pages, 1 figure. Revised version, very minor changes. Accepted to ApJL, to appear in the July 1, 2003 issue (v 591...|$|R
40|$|Thesis (Ph. D.) [...] University of Washington, 2012 Image mosaics stitch photos into {{a single}} {{composite}} with a wide field of view. They are easy to create and can be panned by dragging the mouse, thus enabling simple and effective photorealistic visualizations. However, they are restricted to structured input where the camera motion is limited and the appearance variation across photos can be controlled. In my thesis, I extend mosaics to unstructured cases that include more general camera motion, appearance variation and Internet photo collections, enabling visualization of more complex scenes. I first develop a mosaicing technique for a general class of photo collections subsuming rotational mosaics. In contrast to prior approaches that stitch a single static mosaic, my approach dynamically composites a mosaic based on the current viewpoint as the user navigates, allowing for distortion-free mosaicing and {{a broader range of}} camera motion. Exposure <b>differences,</b> <b>parallax,</b> misalignment between photos and scene motion lead to stitching artifacts in static mosaics. My dynamic approach avoids these artifacts and enhances realism by preserving scene motion and changes in brightness. In the latter part of my thesis, I focus on highly unstructured collections comprising tourist photos downloaded from the Internet that are not captured with the intention of creating a mosaic. First, I describe an algorithm to discover rotational panoramas (photos taken from nearly the same viewpoint) and orbits (photos looking at a common object), within these collections. These photo sets can then be browsed by dragging the mouse like traditional mosaics. Second, I focus on extreme variation in appearance of these photos. I prove that any photo of a scene can be represented as a linear combination of a set of basis photos. I show theoretically and empirically that under suitable assumptions, for a scene with k n distinct orientations and k œÅ different materials, k n k œÅ basis photos are sufficient to span the space of all possible photos of the scene. I then describe a method to robustly compute these basis photos from Internet photos and show novel applications like removing people and expanding the field of view of a photo...|$|R

