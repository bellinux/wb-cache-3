69|62|Public
5000|$|Data exchanges {{are carried}} out via the {{communications}} link and <b>plausibility</b> <b>checks.</b>|$|E
50|$|More than {{a decade}} later spammers started to abuse this flaw in post-1123 SMTP, today most mails are spam and most reverse paths are forged. Note that spammers {{typically}} forge working reverse paths, many MTAs reject mail if callback verification or other <b>plausibility</b> <b>checks</b> fail for the reverse path.|$|E
40|$|Software fault {{tolerance}} demands additional tasks like error detection and recovery through executable assertions, exception handling, diversity and redundancy based mechanisms. These mechanisms {{do not come}} for free, rather they introduce additional complexity to the core functionality. This paper presents light weight error detection and recovery mechanisms based on {{the rate of change}} in signal or data values. Maximum instantaneous and mean rates are used as <b>plausibility</b> <b>checks</b> to detect erroneous states and recover. These <b>plausibility</b> <b>checks</b> are exercised in a novel aspect oriented software fault tolerant design framework that reduces the additional logical complexity. A Lego �XT Robot based case study has been completed to demonstrate the effectiveness of the proposed design framework...|$|E
40|$|Latest {{technological}} developments have enabled {{the evolution of}} new vehicle systems which allow the implementation of new functions or the realisation of known functions with alternative actuation systems. The rising complexity of such systems seriously affects the safety demands on these systems. The following contribution describes a <b>plausibility</b> <b>checking</b> system and a method to define the requirements to <b>plausibility</b> <b>checking</b> systems {{in order to achieve}} required safety demands for new vehicle systems...|$|R
40|$|The {{evaluated}} {{concept of}} echocardiographic dyssynchrony investigation with 100 subjects consisting of combined TDI and TSI with their <b>plausibility</b> <b>check</b> {{has been successfully}} applied in patients with LBBB. The condition is given to test this method in a multicenter study to determine scientifically whether our approach really improves dyssynchrony diagnostics...|$|R
30|$|If {{there is}} {{disagreement}} {{or lack of}} conclusiveness, e.g., about the probability of harm occurring, a <b>plausibility</b> <b>check</b> of the available data should be performed. The plausibility should be decided {{on the basis of}} scientific criteria that are recognised by the scientific community. Theories or hypotheses must explain a specific phenomenon and be testable, fulfil coherence requirements, and satisfy the principle of organised scepticism (for instance, through peer review). To conduct this check in accordance with scientific criteria, it is necessary to have complete access to the information that has led to the formulation of the scientific theory. The data must be presented in an understandable manner and include any information that does not support the scientific theory. To ensure that the <b>plausibility</b> <b>check</b> is carried out in an unbiased manner and according to scientific criteria, the scientific institutions must be independent.|$|R
30|$|All {{data were}} {{collected}} through a web based data acquisition system previously used in other observational studies (Cutlip et al. 2007; Wöhrle et al. 2012; Zeymer et al. 2014). National principal investigators {{were responsible for the}} accuracy of their datasets and performed source data verification when the routinely performed web based <b>plausibility</b> <b>checks</b> indicated discrepancies.|$|E
40|$|This paper {{estimates}} {{annual data}} on educational attainment for 3, 076 mainland U. S. counties 1991 - 2005. Being estimated {{without resorting to}} ancillary information, this data is suited particular well for panel regression analyses. Several <b>plausibility</b> <b>checks</b> indicate that the data is fairly reliable and yields plausible parameter estimates in a panel regression...|$|E
30|$|The MYPTAS object {{describes}} a pTAS distribution with parameterization P_P(α,γ,θ)= (0.5, 1, 1.5). The PTAS function automatically performs some <b>plausibility</b> <b>checks</b> on the given parameters and translates the given parameterization (i.e. according to Palmer et al. (2008) in this case) {{to the other}} ones. In addition, distribution figures such as mean, variance, skewness and kurtosis are calculated.|$|E
40|$|This {{document}} {{describes an}} {{implementation of a}} program which does an extensive consistency and <b>plausibility</b> <b>check</b> {{on a set of}} C program files. This may lead to warnings which help the programmer to debug the program, to remove useless code and to improve his style. The program has been used to test itself and has found bugs in sources of some heavily used code...|$|R
50|$|Prior {{attempts}} at integrating static and dynamic typing {{tried to make}} the dynamic type be both {{the top and bottom of}} the subtype hierarchy. However, because subtyping is transitive, that results in every type becoming related to every other type, and so subtyping would no longer rule out any static type errors. The addition of a second phase of <b>plausibility</b> <b>checking</b> to the type system did not completely solve this problem.|$|R
2500|$|Any {{physically}} meaningful equation (and likewise any {{inequality and}} inequation) {{will have the}} same dimensions on its left and right sides, a property known as dimensional homogeneity. Checking for dimensional homogeneity is a common application of dimensional analysis, serving as a <b>plausibility</b> <b>check</b> on derived equations and computations. [...] It also serves as a guide and constraint in deriving equations that may describe a physical system {{in the absence of a}} more rigorous derivation.|$|R
40|$|An ad hoc {{network is}} a {{collection}} of mobile nodes that dynamically form a temporary network and are infrastructure less. Black hole attack is an attack in network layer which degrades the network performance by dropping packets. This paper identifies black hole attack against Optimized Link State Routing (OLSR) protocols, one of the four standard routing protocols for MANETs. We used Topology Graph Based Anomaly Detection (TOGBAD) a new centralized approach using topology graphs to identify nodes attempting to create a black hole. It is used to gain knowledge about the network topology and use this knowledge to perform <b>plausibility</b> <b>checks</b> of the routing information propagated by the nodes in the network. When a node generates fake (malicious) routing information or when <b>plausibility</b> <b>checks</b> fail, an alarm is triggered. This paper gives the corresponding simulation results in NS 2. It also demonstrates detection process when the attempt to create a black hole before the actual impact occurs...|$|E
30|$|Thin strut cobalt {{chromium}} BMS implantation in a priori pre-defined subgroups {{was investigated in}} a non-randomized, international, multi-center ‘all-comers’ observational study. Primary end-point was the 9 -month clinically driven target lesion revascularization (TLR) rate. Secondary end-points included the 9 -month major adverse cardiac event (MACE) and procedural success rates. Data collection was done using an established electronic data acquisition form with built-in <b>plausibility</b> <b>checks.</b>|$|E
40|$|Due to the {{complexity}} of studies with peripheral artery disease in the past, data clear-ing for such studies lasted intolerably long. This couldpartly be improved by increas-ing on-site monitoring frequency and duration. In order to improve data quality and reduce time for data clearing further, a computer-assistedplausibility check program was establishedprior to initiating a multicenter, multinational study concept (PART-NER concept) (I). In four completed studies (total N = 512 in 36 centers all over Europe) the num-ber of correction lists and inquiries due to open questions after completion of the recruitment period could be remarkably lowered in comparison to previous studies where no computer-assistedplausibility check was employed. The number of missing values was reduced to a minimum (100 % of the data with regard to both primary endpoints were available). The number of correction sheets that had to be filled in by the investigator was 3. 4 sheets per patient in the study with early <b>plausibility</b> <b>checks,</b> whereas the number was 5. I sheets per patient in the study where <b>plausibility</b> <b>checks</b> were started later (the average of items to be corrected was I 0 in the study with earl...|$|E
50|$|CubETH is a {{technology}} demonstration mission. The first {{goal is to}} prove that low cost receivers {{can be used for}} positioning in space. The orbit as well as the attitude of the spacecraft will be computed on-board the satellite and send to a station on earth. The post-processing of the data will allow a first <b>plausibility</b> <b>check.</b> In order to fulfil an external validation, CubETH will be equipped with satellite laser ranging reflectors for range measurements from ground stations.|$|R
5000|$|EEX {{operates}} [...] "Transparency in Energy Markets”, {{the neutral}} platform for energy market data which fulfils the statutory publication requirements and implements the market participants’ voluntary commitments. The platform {{was established by}} EEX and the four German transmission system operators and launched in October 2009. In 2011, the Austrian transmission system operator Austrian Power Grid AG joined the cooperation. EEX {{is in charge of}} the operation of the platform, which comprises <b>plausibility</b> <b>checking,</b> anonymisation, aggregation and publication of the data reported.|$|R
30|$|Another {{important}} {{issue that has}} not been addressed in this work is to obtain a confidence measure giving indication about the reliability of the inferred crowd density. It may be that due to a small percentage of users compared to the total number of attendees, the inferred crowd density may even become null. Hereby, a <b>plausibility</b> <b>check</b> e.g. by comparing the active number of users to a roughly estimated number of attendees by the security personnel could give confidence about the inferred crowd density.|$|R
30|$|LDA {{models were}} firstly applied on the Europe-wide dataset of moss {{sampling}} sites {{with information on}} land use density around the sampling sites. Model-specific error rates (%) were calculated by means of confusion matrix values (actual vs. predicted values). Charts for the linear discriminant functions were used for <b>plausibility</b> <b>checks.</b> Logistic regression models were built using the same predictors from the LDA models. Confusion matrices and error rates (%) specified for each LR model were calculated and compared with the statistical characteristics of the LDA models.|$|E
40|$|Abstract. We {{present a}} general vision-based method for reconstructing {{multiple}} unknown objects (e. g. humans) within a known environment (e. g. tables, racks, robots) which usually has occlusions. These occlusions {{have to be}} explicitly considered since parts of the unknown objects might be hidden in some or even all camera views. In order to avoid cluttered reconstructions, <b>plausibility</b> <b>checks</b> are used to eliminate reconstruction artifacts which actually do not contain any unknown object. One application is a supervision/surveillance system for safe human/robot-coexistence and – cooperation. Experiments for a voxel-based implementation are given. ...|$|E
40|$|This {{contribution}} {{emerged as}} part of the collaborative project “Data network for better European organic market information” carried out in the 7 th Framework Programme of the EU. Up to now, organic market data collection has been inconsistent throughout European countries; data from different organisations and/or countries is hard to compare, because very different sampling methods, product categories, and nomenclatures have been used. Interpretations based on incomplete and inconsistent data might lead to wrong decisions and misinvestments of companies or policy divisions. The objective of this contribution is the identification of inconsistencies in organic market data which is currently available throughout Europe. Therefore <b>plausibility</b> <b>checks</b> were applied to data collected through a standardized survey in 39 countries. The inconsistencies that could be revealed were grouped according to data type and also according to data origin. The number of inconsistencies highly depends on the availability of data, which in turn depends on the country the data stems from. These inconsistencies often occur due to heterogeneous nomenclature and varying definitions of product categories. Inconsistencies in data from two subsequent years often occur because data from different sources was used. Further steps resulting from the outcome of the data <b>plausibility</b> <b>checks</b> are the compilation of a guideline for organic market data collectors, the exchange of opinions and experiences within the organic data network, and the revision of current organic market data reports...|$|E
40|$|This paper {{introduces}} a time {{series of the}} Dutch capital stock for 1900 - 1995. The estimates were derived using the perpetual inventory method. To enhance international comparability, we followed Maddison's standardized methodology. To ensure transparency a thorough description of sources and methods is given. A <b>plausibility</b> <b>check</b> is performed by comparing our results with the stylized facts of Dutch {{economic growth in the}} twentieth century. It is concluded that the new data fit other available evidence for Dutch macroeconomic development better than previously used. ...|$|R
40|$|Visualisations can highly {{contribute}} to the importance and authority of new ideas, concepts, and knowledge claims. Among the many visualisations, few become well-known and influential in environmental governance. Whilst these have been objects of specific research, this study questions what constitutes and underpins their influence. For this, the paper codifies influential visualisations and defines criteria for studying their visual characteristics. The criteria are applied to two case studies, the “traffic light” and the “planetary-boundaries” diagrams. To increase {{the validity of the}} findings, the study also introduces two “failure cases” as <b>plausibility</b> <b>check...</b>|$|R
50|$|The European Severe Weather Database (ESWD) {{collects}} and verifies {{reports on}} dust, sand- or steam devils, tornado sightings, gustnados, large hail, heavy rain and snowfall, severe wind gusts,damaging lightning strikes and avalanches all over Europe {{and around the}} Mediterranean. The ESWD {{is the most important}} database for such events in Europe. Everybody is welcome to report extreme weather observations. Each report undergoes a quality control and each event is flagged either as received (QC0), <b>plausibility</b> <b>checked</b> (QC0+), report confirmed by other observer (QC1) or as fully verified by trusted source (QC2).|$|R
40|$|To {{accommodate}} {{the growing demand}} for complexity in the automotive industry, an approach for a cross-process information model is introduced: the infrastructure presented aims at storing and relating key development data from the various software engineering phases. The model can be harmonized with proprietary development methodologies by means of metamodeling and serves {{as the starting point}} for the traceability of requirements, global <b>plausibility</b> <b>checks,</b> and (semi-) automatic transformation of model elements. Based on the medini tool chain, the model infrastructure is open with respect to the models and tools used thanks to the consistent deployment of OMG standards and the benefit of metamodeling...|$|E
40|$|This paper {{presents}} {{an approach to}} safe navigation of autonomous mobile systems within partially known or unknown dynamic environments. In this context, faulty, maladjusted and otherwise influenced sensors must be recognized (error detection), and adequate measures for failure correction (error recovery) must be taken. As a general basis for monitoring the state of environmental sensors, a so called "error detection model" was created, which consists of sub-models for data from laser range finders and ultrasonic sensors. With {{the aid of the}} created models, different kinds of redundancy can be utilized and consistency and <b>plausibility</b> <b>checks</b> can be carried out. The error detection model serves for failure recognition based on environment modeling and on hypotheses for expected sensor readings...|$|E
40|$|This paper {{presents}} a non-cooperative model of intra-household decision-making regarding investment in migration. It is {{shown that the}} combination of liquidity constraints and imperfect commitment are a source of underinvestment in migration. More precisely, we highlight that, if remittances are unenforceable as a repayment for parent?s contribution in migration transaction costs, then both migrant and parent?s liquidity constraints, rather than households liquidity constraint as a whole, matter in determining the investment decision. Besides, the insurance motive for remittances is shown to generate divergence of interest over the characteristics of migration. This result calls for a theoretical approach that properly takes account of potential internalization problems, which the paper intends to offer. <b>Plausibility</b> <b>checks</b> of the model are provided by comparative statics whose outcomes are consistent with previous research on migration and remittances. ...|$|E
30|$|Before {{utilizing}} these data, we subjected {{them to a}} <b>plausibility</b> <b>check.</b> For example, {{the data}} processing performed {{as part of the}} ranking was checked {{on the basis of the}} raw data provided. In addition to minor corrections, in particular of the number of personnel, above all an error in the internationally visible publications was corrected. 269 international publications were erroneously assigned to LMU Munich. However, only 38 publications could actually be found in the Web of Science database for the period under consideration. We therefore only made use of these corrected data sets in our analyses.|$|R
40|$|Abstract—The {{new idea}} of this {{research}} is application of a new fault detection and isolation (FDI) technique for supervision of sensor networks in transportation system. In measurement systems, it is necessary to detect all types of faults and failures, based on predefined algorithm. Last improvements in artificial neural network studies (ANN) led to using them for some FDI purposes. In this paper, application of new probabilistic neural network features for data approximation and data classification are considered for <b>plausibility</b> <b>check</b> in temperature measurement. For this purpose, two-phase FDI mechanism was considered for residual generation and evaluation. Keywords—Fault detection and Isolation, Neural network, Temperature measurement, measurement approximation and classification. I...|$|R
40|$|This paper {{presents}} the {{hardware and software}} design of a battery monitoring circuit developed {{to be used in}} aviation applications employing lithium-ion batteries in their electrified powertrain. The considered aircraft is a manned sailplane able to take-off and climb by using its electric propulsion system supplied by NCA/Graphite lithium-ion batteries. The battery monitoring electronics was developed with the highest considerations in terms of fail-safe and fail-operational requirements. The electronic design of the battery monitoring circuit integrates the battery busbars and uses new passive balancing components with an innovative busbar cooling solution, thus increasing the reliability and the robustness of the whole battery system. The software also contributes to the high safety level by employing crosscheck and <b>plausibility</b> <b>check</b> mechanisms...|$|R
40|$|A revised {{plan for}} the 2000 Decennial Census was {{announced}} in a 24 February 1999 Bureau of the Census publication [9] and a press statement by K. Prewitt, Director of the Bureau of the Census [39]. Census 2000 will include counts and &quot; counts. The adjustments involve complicated procedures and calculations on data from a sample of blocks, extrapolated throughout the country to demographic groups called -strata. &quot; The 2000 adjustment plan is called Accuracy and Coverage Evaluation (ACE). ACE is quite similar to the 1990 adjustment plan, called the Post-Enumeration Survey (PES). The 1990 PES fails some <b>plausibility</b> <b>checks</b> [4, 12, 44] and probably would have reduced the accuracy of counts and state shares [3, 4]. ACE and PES di er in sample size, data capture, timing, record matching, poststrati cation, methods to compensate for missing data, the treatment ofmovers, an...|$|E
40|$|Abstract—We {{present a}} novel multi-view 3 D {{reconstruction}} algorithm which unifies {{the advantages of}} several recent reconstruction approaches. Based on a known environment causing occlusions and on the cameras ' pixel grid discretization, an irregular partitioning of the reconstruction space is chosen. Reconstruction artifacts are rejected by using <b>plausibility</b> <b>checks</b> based on additional information about the objects to be reconstructed. The binary occupancy decision is solely performed in reconstruction space instead of fusing back-projected silhouettes in image space. Hierarchical data structures are used to reconstruct the objects progressively focusing on boundary regions. Thus, the algorithm can be stopped at any time with a certain conservative level of detail. Most parts of the algorithm may be processed in parallel using GPU programming techniques. The main application domain is the surveillance of real environments like in human/robot coexistence and cooperation scenarios...|$|E
40|$|The {{usage of}} link quality based routing metrics {{significantly}} improves {{the quality of}} the chosen paths and by that the performance of the network. But, attackers may try to exploit link qualities for their purposes. Especially in tactical multi-hop networks, routing may fall prey to an attacker. Such routing attacks are a serious threat to communication. TOGBAD is a centralised approach, using topology graphs to detect routing attacks. In this paper, we enhance TOGBAD with the capability to detect fake link qualities. We use a Challenge/Response method to estimate the link qualities in the network. Based on this, we perform <b>plausibility</b> <b>checks</b> for the link qualities propagated by the nodes in the network. Furthermore, we study the impact of attackers propagating fake link qualities and present simulation results showing TOGBAD 2 ̆ 7 s detection rate...|$|E
40|$|This comment {{describes}} the actions {{taken on a}} report of a potential error in the units of indicative values of BCR- 723. As raw data were no longer available, we confirmed the correctness of this claim by a <b>plausibility</b> <b>check.</b> We investigated the possible {{extent of the problem}} and informed customers who bought the material. Finally, we highlight differences between the organization of production of certified reference materials in the Community Bureau of Reference (BCR) and Standards, Measurements and Testing (SMT) Programs and the current system at the European Commission’s Institute for Reference Materials and Measurements (IRMM), and that should minimize the risk of re-occurrence of such problems. JRC. DG. D. 2 -Reference material...|$|R
40|$|Today’s {{power grids}} must utilize {{more energy than}} they were {{originally}} planned for. Hence, they are slowly reaching their stability limits and that causes {{an increased risk of}} blackouts in electrical networks. To avoid such critical situations in the control room the system dynamic state must be assessed as quickly as possible and its personnel have to react to it early enough. This kind of evaluation could be done by the so-called Dynamic Security Assessment system which is able to assess the dynamic state of the electrical network online. This paper presents completely automatic methods of the dynamic security assessment system integration into a power grid, functionality testing of the Over Excitation Limiter (OXL) - which is implemented in the Automatic Voltage Regulator (AVR), and the electrical grid <b>plausibility</b> <b>check...</b>|$|R
40|$|An {{important}} goal of smart home automation {{is to improve}} the user’s comfort and security along with a reduced overall energy consumption. A core element of this strategy is an automated decentralised indoor climate control system. The subjective perception of indoor air quality and thermal comfort in rooms is influenced by a large number of different physical parameters, the most important being the mean air room temperature, the relative air humidity, the mean air velocity, and the CO 2 concentration. For a comprehensive indoor climate monitoring and control system, multi-gas sensor arrays and person detection sensors are required. In the paper, the features of a flexible KNX based distributed sensor network, including stationary multi-gas sensor modules and wearable wireless devices, is described. Important issues for smart sensor design like self-monitoring, <b>plausibility</b> <b>check</b> and model-based self-calibration abilities have been especially devoted to. An outlook for a perspective sensor miniaturization is given...|$|R
