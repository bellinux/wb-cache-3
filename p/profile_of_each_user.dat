12|10000|Public
40|$|Healthy {{mobile phone}} users aged 18 â 30 Â y. o. {{provided}} exfoliated buccal cells {{samples from the}} right and left inner cheeks. A total of 2000 cells per subject were screened for the presence of micronuclei as a sign of genotoxic damage, according to the mobile phone use <b>profile</b> <b>of</b> <b>each</b> <b>user.</b> Keywords: Electromagnetic fields, Mobile phones, Genotoxicity, Micronuclei, Exfoliated buccal cells, Feulgen stai...|$|E
40|$|The {{behavioural}} advertising represents the publicity carried out following the assessment and the observation, in time, of the Internet users’ behaviour, {{based on the}} studies made on the behavioural characterises, in order to attain a specific <b>profile</b> <b>of</b> <b>each</b> <b>user</b> and to supply him/her with certain personalised advertising materials. Due to the extension {{on a large scale}} of the on-line {{behavioural advertising}}, based on the usage of tracking cookies and other tracking dispositive, certain issues concerning referring to the protection of private life of Internet users appear. Following, we will analyse the applicability of the personal data protection principles on the data processing involved in the on-line behavioural advertising. profiling, on-line behavioural advertising, consent, right to information, personal data...|$|E
30|$|The {{proposed}} algorithm {{presumes that}} {{the information to the}} traveler is provided through mobile devices (phones or PDAs) with different memory capacities and platforms (ranging from Symbian, to iPhones and Android), thus the minimum requirements of the less expensive devices should be taken into consideration. In addition, most likely the timeframe within which the traveler requests information is quite tight (during travelling). For these reasons, only the optimal solutions must be given to the user, according to his/her preferences and not just providing him/her a list of possible routes and asking him/her to select. To solve the above problem, an algorithm has been developed in a PhD thesis [6], with the aim to prioritise the available routes according to the personal <b>profile</b> <b>of</b> <b>each</b> <b>user.</b>|$|E
3000|$|In (user-based) {{collaborative}} filtering [31], a KNN graph connects <b>each</b> <b>user</b> u to a user v if v {{is one of}} the k nearest neighbors of u in the considered application. The similarity between users is computed on the <b>profiles</b> <b>of</b> <b>each</b> <b>user,</b> for instance the lists of items that users have rated (e.g., movies in a movie recommender system), or vectors of features for images, using one of several similarity metrics developed for informational retrieval such as the cosine similarity metric [31], and the Jaccard index. A brute force KNN computation has an O(N [...]...|$|R
2500|$|Last.fm is a music website, {{founded in}} the United Kingdom in 2002. Using a music {{recommender}} system called [...] "Audioscrobbler", Last.fm builds a detailed <b>profile</b> <b>of</b> <b>each</b> <b>user's</b> musical taste by recording details of the tracks the user listens to, either from Internet radio stations, or the user's computer or many portable music devices. This information is transferred ("scrobbled") to Last.fm's database either via the music player itself (including, among others Spotify, Deezer, Tidal, and MusicBee) or via a plugin installed into the user's music player. The data is then displayed on the user's profile page and compiled to create reference pages for individual artists.|$|R
50|$|Filmow allows all users, whether {{registered}} or not, {{to access}} any title {{information from the}} website database, making it a free for research, where anyone can seek information (cast, trailers, posters, reviews...), but only those who register the site can set up a profile and enjoy all the social functions. The site creates a detailed <b>profile</b> <b>of</b> <b>each</b> <b>user's</b> movie taste, gathering and displaying movies and favorite artists and also the movies the user have seen, want to see and doesn't want see. Furthermore users can also share their opinions about the movies, series and novels through assessments on each title's own page. If a title is not found on the site, users can add their own.|$|R
40|$|Future mobile {{systems will}} be {{characterized}} by high user density and high mobility enabling users to communicate regardless of their geographical location. Large number of handovers and registrations will place great demands on radio links. One of the major issues in mobile wireless systems is location management, which is the process that allows a network to identify {{the exact location of}} a mobile terminal (MT) for call delivery. In this paper, we present a user pattern learning (UPL) strategy using genetic algorithm tuned artificial neural network (GAANN) to reduce the location update cost. the system maintains a list of places where each user is most likely to be in at each time interval. The intelligence of the location management procedure is increased by updating the <b>profile</b> <b>of</b> <b>each</b> <b>user</b> by users past calling history. Unless the MT detects that it has moved out of the registered profile, it does not perform any other location update. Paging is also done selectively as in the registered profile upon a call arrival for the MT. Experimental results shows that the profile based intelligent system using GAANN performs well than other well known strategies...|$|E
40|$|Mobile Ad-hoc Networks (MANETs) {{enable users}} in {{physical}} proximity {{to each other}} to exchange data {{without the need for}} expensive communication infrastructures. Each user represents a node in the network, and executes a neighbor discovery Typically, nodes broadcast beacon messages that are received by other participants within the sender’s communication range. Routing strategies are computed on-line based on the locations of nearby nodes, and geocasting is employed to deliver data packets to their destinations. However, mobile users may be reluctant to share their exact locations with other participants, since location can disclose private details about a person’s lifestyle, religious or political affiliations, etc. A common approach to protect location privacy is to replace exact coordinates with coarser-grained regions, based on the privacy <b>profile</b> <b>of</b> <b>each</b> <b>user.</b> In this paper, we investigate protocols that support MANET routing without disclosing exact positions of nodes. Each node defines its own privacy profile, and reports a cloaked location information to its neighbors. We adopt a novel strategy to advertise beacons, to prevent inference of node locations. We also propose packet forwarding heuristics that rely on cloaking regions, rather than point locations. Our extensive experimental evaluation shows that the proposed routing scheme achieves low delays and high packet delivery ratios, without incurring significant overhead compared to conventional MANET routing protocols...|$|E
40|$|The {{first part}} of this report {{examines}} an interference suppression technique for multicarrier (MC) CDMA systems. The proposed technique exploits carrier offsets between users, which arise because of inaccuracies of oscillators or Doppler shifts. The suppression capability comes from oversampling the received signal in the frequency domain. It is shown that the proposed technique is robust in severe near-far interference environments. In addition, the system performance can easily be found using the derived signal-to-interference ratio and the Conditional Gaussian Approximation (CGA). ^ The second part of the report examines the structure of asynchronous direct sequence (DS) CDMA systems with space-time codes. It is shown that the MMSE combining solution for joint space-time decoding and interference suppression must be done in a specific way to ensure the received signal has a pseudo-correlation matrix equal to zero. A simple technique is proposed to provide both multiple-access interference suppression and transmit diversity. ^ Finally, a new technique for interference avoidance in asynchronous DS-CDMA systems is proposed. The user capacity of such systems is shown to improve significantly if users are allowed to control their signature sequences to avoid interference from other users. The degree to which the user capacity increases {{is a function of the}} chip waveform and the delay <b>profile</b> <b>of</b> <b>each</b> <b>user.</b> The effective dimension of a chip waveform is characterized and optimal delay profile sets are determined based on properties of specific chip waveforms. ...|$|E
40|$|In this paper, {{a system}} able to {{retrieve}} contents deemed relevant for the users through a text categorization process, is presented. The system is built exploiting a generic multiagent architecture {{that supports the}} implementation of applications aimed at (i) retrieving heterogeneous data spread among different sources (e. g., generic html pages, news, blogs, forums, and databases); (ii) filtering and organizing them according to personal interests explicitly stated by each user; (iii) providing adaptation techniques to improve and refine throughout time the <b>profile</b> <b>of</b> <b>each</b> selected <b>user.</b> In particular, the implemented multiagent system creates personalized press-revies from online newspapers. Preliminary results are encouraging and highlight {{the effectiveness of the}} approach...|$|R
3000|$|... “Fog computing” [17] {{suggests}} an approach totally {{different from the}} others. The access operations <b>of</b> <b>each</b> cloud <b>user</b> are monitored, realising a sort <b>of</b> <b>profiling</b> for <b>each</b> <b>user.</b> This profiling facilitates the detection of abnormal behaviour. When unauthorized access is suspected and then verified, the method uses disinformation attacks by returning large amounts of decoy information to the malicious insiders, keeping this way {{the privacy of the}} real users’ data.|$|R
50|$|On its homepage, {{the website}} {{displays}} {{a list of}} minority languages it has cached. After selecting a language, the user is brought to a table of everyone who is tweeting in that language. Indigenous Tweets provides the <b>profile</b> picture <b>of</b> <b>each</b> Twitter <b>user</b> and statistics about <b>each</b> person's number <b>of</b> followers. In addition to providing statistics about the percentage of tweets a person writes in different languages, Indigenous Tweets has a selection of the trending topics in the various minority languages.|$|R
40|$|International audienceMental-Imagery based Brain-Computer Interfaces (MI-BCIs) {{allow their}} users to send {{commands}} {{to a computer}} using their brain-activity alone (typically measured by ElectroEncephaloGraphy-EEG), which is processed while they perform specific mental tasks. While very promising, MI-BCIs remain barely used outside laboratories {{because of the difficulty}} encountered by users to control them. Indeed, although some users obtain good control performances after training, a substantial proportion remains unable to reliably control an MI-BCI. This huge variability in user-performance led the community to look for predictors of MI-BCI control ability. However, these predictors were only explored for motor-imagery based BCIs, and mostly for a single training session per subject. In this study, 18 participants were instructed to learn to control an EEG-based MI-BCI by performing 3 MI-tasks, 2 of which were non-motor tasks, across 6 training sessions, on 6 different days. Relationships between the participants' BCI control performances and their personality, cognitive profile and neurophysiological markers were explored. While no relevant relationships with neurophysiological markers were found, strong correlations between MI-BCI performances and mental-rotation scores (reflecting spatial abilities) were revealed. Also, a predictive model of MI-BCI performance based on psychometric questionnaire scores was proposed. A leave-one-subject-out cross validation process revealed the stability and reliability of this model: it enabled to predict participants' performance with a mean error of less than 3 points. This study determined how users' profiles impact their MI-BCI control ability and thus clears the way for designing novel MI-BCI training protocols, adapted to the <b>profile</b> <b>of</b> <b>each</b> <b>user...</b>|$|E
40|$|Fair {{allocation}} {{has been}} studied intensively in both economics and computer science. This subject has aroused renewed interest {{with the advent of}} virtualization and cloud computing. Prior work has typically focused on mechanisms for fair sharing of a single resource. We consider a variant where each user is entitled to a certain fraction of the system’s resources, and has a fixed usage profile describing how much he would want from each resource. We provide a new definition for the simultaneous fair allocation of multiple continuously-divisible resources that we call bottleneck-based fairness (BBF). Roughly speaking, an allocation of resources is considered fair if every user either gets all the resources he wishes for, or else gets at least his entitlement on some bottleneck resource, and therefore cannot complain about not receiving more. We show that BBF has several desirable properties such as providing an incentive for sharing, and also promotes high overall utilization of resources; we also compare BBF carefully to another notion of fairness proposed recently, dominant resource fairness. Our main technical result is that a fair allocation can be found for every combination of user requests and entitlements. The allocation <b>profile</b> <b>of</b> <b>each</b> <b>user</b> is proportionate to the user’s profile of requests. The main problem is that the bottleneck resources are not known in advance, and indeed one can find instances that allow different solutions with different sets of bottlenecks. Therefore known techniques such as linear programming do not seem to work. Our proof uses tools from the theory of ordinary differential equations, showing the existence of a sequence of points that converge upon a solution. It is constructive and provides a practical method to compute the allocations numerically. ...|$|E
40|$|Due to the {{ever-increasing}} {{quantity of}} available information, which users have to scan {{in order to}} find relevant items, noise has become a major issue in the implementation and use of information retrieval systems. The aim {{of this study was to}} design an information retrieval system permitting the "personalization" of search, by taking into account user profile. A pre-orientation system was first developed to give access to a personalized subcorpus. To limit noise in information retrieval systems, the textual material offered to the user is reduced and contains only those sections (units) of the document that interest him and are significant to him (where textual material is used in the sense of document units to be processed by content analysis in order to build descriptions of the documents). In this way, the documents are structured on the basis of utility functions. The selected document units are part of the sub-corpus defined by the pre-orientation system. Next, the <b>profile</b> <b>of</b> <b>each</b> <b>user</b> is characterized by determining competence in a given field and at different levels. Each user is characterized by: * -stable information, related to the person rather than to a particular search. This information provides a general description of the user and his habits, * -variable information, related to a specific search. The priority here is to describe the objective of the search (search may be either exhaustive or non-exhaustive; it may concern specialized or popular publications, etc.). The function of the pre-orientation system is to associate a set of characteristics applying to document units to a given user profile. Search is then applied only to the subset of the selected document units that are relevant to the user and established following his profile. Document units are not characterized on the basis of thematic criteria related to content, but rather on the basis of criteria relating to utility. The objective was to propose a hypothesis on the different parameters determining user profile and document unit characteristics, and to test such a hypothesis using an existing information retrieval system incorporating full-text natural language processing tools...|$|E
40|$|In this paper, {{we propose}} {{database}} intrusion detection mechanism {{to enhance the}} security of DBMS. In a typical database environment, {{it is possible to}} define the <b>profile</b> <b>of</b> transactions that <b>each</b> <b>user</b> is allowed to execute. In our approach, we use the transactions profile and overall system architecture is divided into two parts, learning phase and intrusion detection phase. The learning phase generates authorized transactions profile automatically and is used at detection phase to check the behaviour of executable transactions. We also implement the detection phase with the help of Counting Bloom Filter (CBF) and comparing both the approaches...|$|R
40|$|Americans are {{accustomed}} {{to a wide range}} of data collection in their lives: census, polls, surveys, user registrations, and disclosure forms. When logging onto the Internet, users’ actions are being tracked everywhere: clicking, typing, tapping, swiping, searching, and placing orders. All of this data is stored to create data-driven <b>profiles</b> <b>of</b> <b>each</b> <b>user.</b> Social network sites, furthermore, set the voluntarily sharing of personal data as the default mode of engagement. But people’s time and energy devoted to creating this massive amount of data, on paper and online, are taken for granted. Few people would consider their time and energy spent on data production as labor. Even if some people do acknowledge their labor for data, they believe it is accessory to the activities at hand. In the face of pervasive data collection and the rising time spent on screens, why do people keep ignoring their labor for data? How has labor for data been become invisible, as something that is disregarded by many users? What does invisible labor for data imply for everyday cultural practices in the United States? Invisible Labor for Data addresses these questions. I argue that three intertwined forces contribute to framing data production as being void of labor: data production institutions throughout history, the Internet’s technological infrastructure (especially with the implementation of algorithms), and the multiplication of virtual spaces. There is a common tendency in the framework of human interactions with computers to deprive data and bodies of their materiality. My Introduction and Chapter 1 offer theoretical interventions by reinstating embodied materiality and redefining labor for data as an ongoing process. The middle Chapters present case studies explaining how labor for data is pushed to the margin of the narratives about data production. I focus on a nationwide debate in the 1960 s on whether the U. S. should build a databank, contemporary Big Data practices in the data broker and the Internet industries, and the group of people who are hired to produce data for other people’s avatars in the virtual games. I conclude with a discussion on how the new development of crowdsourcing projects may usher in the new chapter in exploiting invisible and discounted labor for data...|$|R
40|$|Injection Drug User (IDU) as abuse {{activities}} {{is one of}} causes to increase HIV/AIDS cases. To provide a holistic overview on IDU users behaviour, it needs an ethnography study. This ethnography study would focuss to potrait IDU <b>users</b> on <b>each</b> community group. One of there was transvestate group. A specifis effort was conducted to get and provide <b>profile</b> <b>of</b> <b>each</b> IDU <b>users,</b> history <b>of</b> use, their activities and their sexual activities. Because the IDU users group was exclusively closed, so data collection were more relied on key informan. If thouroughly observed on the main problem, most influencing factor drive them to drug abuse was psychologic distress associated with their characteristics. To observe the overview on IDU users activities in transvestate group, we shoud be open-hearted in seeing the problem of drug abuse, especially not only on law enforcement aspect but also on humanistic aspect. For the reasons, it {{is a need to}} minimalize psichologic distress for IDU users presence. With concern to drug abuse, especially IDU users, the government should facilitate social respectable organizations to do control activities by attendanship.   Keywor ds : ethnography, injection drug user, transvestate group</p...|$|R
40|$|Secure {{remote access}} is {{integral}} to the workflow of virtually every enterprise today. It is also an avenue ripe for network infiltration [...] -attackers who can steal network-login credentials can often readily penetrate a site's perimeter security to obtain a persistent foothold within the network. Once inside, they can often further their access by escalating privileges and moving laterally, potentially operating for months, all the while remaining undetected {{under the guise of}} a legitimate user. Such threats can prove hugely expensive and damaging to sites, fueling APT campaigns and enormous data breaches. For example, the 2013 theft from Target of 40, 000, 000 credit card numbers began with attackers compromising remote-access credentials of one of its contractors, and the 2015 breach of SSNs and biometric data of millions of government employees likewise stemmed from a stolen credential. This dissertation aims to advance the state of credential compromise detection for enterprise settings. We leverage several years worth of real-world network logs from the Lawrence Berkeley National Laboratory (LBNL) in order to develop systems for detecting: (i) stealthy, distributed brute-force attacks that compromise password-based credentials by attempting a number of guesses against the site's servers [...] -these attacks proceed in a stealthy fashion by distributing the brute-force work across an army of machines, such that each individual host only makes a few attempts, and thereby becomes hard to differentiate from failed attempts of legitimate users, and (ii) anomalous logins indicating that a user's login credentials may have been potentially compromised [...] -either through brute-forcing attacks or broadly through other vectors (phishing attacks and credential-stealing malware). For the detection of stealthy brute-force attacks, we first develop a general approach for flagging distributed malicious activity in which individual attack sources each operate in a stealthy, low-profile manner. We base our approach on observing statistically significant changes in a parameter that summarizes aggregate activity, bracketing a distributed attack in time, and then determining which sources present during that interval appear to have coordinated their activity. We then apply this approach to the problem of detecting stealthy distributed SSH brute-forcing activity, showing that we can model the process of legitimate users failing to authenticate using a beta-binomial distribution, which enables us to tune a detector that trades off an expected level of false positives versus time-to-detection. Using the detector we study the prevalence of distributed brute-forcing, finding dozens of instances in an extensive eight-year dataset collected at the Lawrence Berkeley National Lab. Many of the attacks [...] -some of which last months [...] -would be quite difficult to detect individually. While a number of the attacks reflect indiscriminant global probing, we also find attacks that targeted only the local site, as well as occasional attacks that succeeded. For the detection of anomalous logins, we first extensively characterize the volumes and diversity of login activity at LBNL's network, with the goal of engineering features that with good confidence can serve as indicators of compromise. We then develop a practical rule-based detector that leverages the global view of the network as well as historical <b>profile</b> <b>of</b> <b>each</b> <b>user</b> to flag potentially compromised credentials. On average, our detector raises 2 [...] 3 alarms per week [...] -a reasonable analyst workload for an enterprise with several thousand users. To understand these alarms, we worked with the site operators, who deemed the top ten percent of instances suspicious enough to merit an inquiry to the affected user. Our detector successfully flagged a known compromised account and discovered an instance of a (benign) shared credential in use by a remote collaborator. In summary, this dissertation develops approaches to detect both stealthy brute-force attempts and anomalous successful logins among hundreds of thousands of logins in an enterprise network's activity. Using our detectors, we show that stealthy brute-force attacks that target password-based credentials have been around for years, and that attackers do occasionally succeed in compromising the credentials. Our work makes advances in detecting such stealthy break-ins that, if remain undetected, can prove hugely expensive for sites...|$|E
40|$|Online news {{websites}} {{are becoming}} {{one of the most popular}} and influential social media platforms allowing people to easily access information about daily life topics, share their opinions on different issues, and give feedback on published content. The tremendous increase of published news requires effective recommendation techniques that help users to find interesting news articles that match with their interests. Thus, users are continuously encouraged to participate to online news websites and keep sharing their opinions, which represent a valuable source of social information. In this thesis, we have investigated how to exploit user-generated-content for personalized news recommendation purpose. The intuition behind this line of research is that the opinions provided by users, on news websites, represent a strong indicator about their profiles. By mining such content, we can extract valuable information about the domains of interests of users, their inclination towards a certain version of news articles, their political orientation, their favorite sport teams, their preferences, and many other interesting features. Furthermore, such content can also be used to enrich the content of news articles, particularly for those describing controversial news articles that can reveal various aspects that are not well described or even not found in their content. Thus, user-generated-content is the core component of our work. This thesis is divided into three main parts, as described in the bellow, which represent the different steps of developing a news recommendation system based on user-generated-content. In the first part, we have developed a fine-grained model that captures both users and article profiles. The <b>profile</b> <b>of</b> <b>each</b> <b>user</b> is extracted from all the opinions and the reactions that are provided on the news websites, while the profile of an article is extracted from its content. A profile is mainly composed of the entities, the aspects, and the sentiments expressed in the corresponding content. While the extraction of entities is a well-established problem, aspect extraction often relies on supervised techniques, which are domain dependent. For a more general solution, we have proposed an unsupervised technique for aspect extraction from opinions and articles. We have investigated two types of models in three different applications. The first model, called a sentiment-dependent profile, exploits the sentiments related to each entity and aspect to define the orientations of users towards a specific trend. For this purpose, we have built a knowledge base of trends, more specifically of political orientations, that guides the extraction of profiles in an unsupervised manner. We have assessed the accuracy of the extracted profiles on two datasets crawled from CNN and Al-Jazeera and the results show that our approach gives high quality results. The second model, called a sentiment-independent profile, focuses only on entities and aspects and is used on the purpose of news recommendation. This model was used to define both users’ interests and the content of news articles. We have test it on a large test collection based on real users’ activities in four news websites, namely The Independent 3, The Telegraph 4, CNN and Al-Jazeera. The results show that our model outperforms baseline models achieving high accuracy. In the third application, we have used a combination of the two former models for news recommendation purpose: the sentiment-independent profile model to define users’ interests is combined with the sentiment-dependent profile model to describe the content of news articles. The main goal of this application was to give a method that deal with the problem of redundancy on the list of recommended news articles. For this purpose, we have used a diversification model on news articles profiles to reduce the redundancy of the list of recommended news articles. We have tested our approach on real users’ activities on four news websites CNN, Al-Jazeera, The Telegraph, and The Independent. The results show that diversification improve the qualityof recommended news articles. In the second part, we have focused on how to enrich the article profiles with user generated-content. The idea behind is to exploit the rich structure of opinions to tailor the articles to the specific needs and interests of users. The main challenge of this task is how to select the opinions used for profile enrichment. The large number and the noisy nature of opinions calls for an effective ranking strategy. To achieve this goal, we have proposed a novel-scoring model that ranks opinions based on their relevance and prominence, where the prominence of an opinion is based on its relationships with other opinions. To find prominent opinions, we have (1) suggested a directed graph model of opinions where each link represents the sentiment an opinion expresses about another opinion (2) built a new variation of the PageRank algorithm that increases the scores of opinions along links with positive sentiments and decreases them as well as links with negative sentiments. We have tested the effectiveness of our model through extensive experiments using three datasets crawled from CNN, The Independent, and The Telegraph news websites. The experiments showed that our scoring model selects meaningful and insightful opinions. In the third part, we have focused on the development of a recommendation technique that exploits the results of the previous part and use them to enrich the content of news articles. We have tested various methods of leveraging opinions on the content of news articles. Concretely, we have worked on two main aspects. Firstly, we have only focused on sentiment-independent profiles, which consist on entities and aspects, and investigated of thoroughly the profile construction process. Secondly, we have enhanced the opinion ranking strategy described earlier by proposing an opinion diversification model based on authorities, semantic and sentiment diversification. The goal is to deal with redundant information and have a wide coverage of topic aspects. We have tested our approach by running large experiments on four datasets crawled from CNN, The Independent, The Telegraph, and Al-Jazeera. The results show that our model provide effective recommendation, particularly when enriching the content of news articles with a diversified set of opinions. Les sites de presse en ligne deviennent une des plateformes les plus populaires et les plus influentes des médias sociaux. Ils permettent aux gens d'accéder facilement aux informations sur des sujets de la vie quotidienne, de partager leurs opinions sur différentes questions, et de donner des commentaires sur le contenu publié. L'augmentation considérable des informations publiées nécessite des techniques de recommandation efficaces qui aident les utilisateurs à trouver les articles de presse qui correspondent à leurs intérêts. Ainsi, les utilisateurs sont constamment encouragés à participer à des sites de presse en ligne et à continuer à partager leurs opinions, qui représentent elles-mêmes une source précieuse d'information sociale. Dans cette thèse, nous avons étudié comment exploiter les contenus générés par les utilisateurs à des fins de recommandation personnalisée. L'intuition derrière cette ligne de recherche est que les opinions fournies par les utilisateurs, sur les sites de presse représentent un indicateur fort sur leurs profils. En exploitant ce type de contenu, nous pouvons extraire des informations précieuses sur les domaines d'intérêts des utilisateurs, leur inclination vers une certaine sorte d'articles de presse, leur orientation politique, leurs équipes sportives préférées, leurs préférences, et de nombreuses autres caractéristiques intéressantes. En outre, ce contenu peut également être utilisé pour enrichir le contenu des articles de presse eux-mêmes. En particulier, le contenu ajouté par les utilisateurs peut permettre de révéler des aspects qui ne sont pas bien décrits ou même ne se trouvent pas du tout dans l'article. Le contenu généré par l'utilisateur est le composant de base de notre travail. Cette thèse est divisée en trois parties principales qui représentent les différentes étapes du développement d'un système de recommandation d'articles de presse sur la base des contenus joutés par les utilisateurs. Dans la première partie, nous avons développé un modèle à grain fin qui capture les deux profils de l'article et de l'utilisateur. Le profil de chaque utilisateur est extrait de toutes les opinions et de toutes les réactions qui sont fournies sur les sites de presse étudiés, tandis que le profil d'un article est extrait de son contenu. Un profil est composé principalement des entités, des aspects et des sentiments exprimés dans le contenu correspondant. Bien que l'extraction d'entités est un problème bien établi, l'extraction d'aspect repose souvent sur des techniques supervisées, qui dépendent du domaine. Pour une solution plus générale, nous avons proposé une technique non-supervisée pour l'extraction des aspects, des opinions et des articles. Nous avons étudié deux types de modèles dans trois applications différentes. Le premier modèle, appelé profil dépendant du sentiment, exploite les sentiments liés à chaque entité et l'aspect de définir les orientations des utilisateurs vers une tendance spécifique. A cet effet, nous avons construit une base de connaissances des tendances, plus précisément des orientations politiques, qui guide l'extraction des profils d'une manière non supervisée. Nous avons évalué la précision des profils extraits sur deux ensembles de données glanées sur CNN et Al-Jazeera et les résultats montrent que notre approche donne des résultats de haute qualité. Le second modèle, appelé un profil indépendant du sentiment, se concentre uniquement sur les entités et les aspects et est utilisé avec un objectif de recommandation. Ce modèle a été utilisé pour définir à la fois les intérêts des utilisateurs et le contenu des articles de presse. Nous l'avons testé sur une grande collection d'articles et sur les activités réelles des utilisateurs dans quatre sites de presse, à savoir The Independent, The Telegraph, CNN et Al-Jazeera. Les résultats montrent que notre modèle surpasse les modèles existants et atteint une grande précision. Dans la troisième application, nous avons utilisé une combinaison des deux modèles précédent pour la recommandation d'articles de presse : le profil indépendant du sentiment pour définir les intérêts des utilisateurs est combiné avec le modèle de profil dépendant du sentiment pour décrire le contenu des articles de presse. L'objectif principal de cette application était de donner une méthode qui traite le problème de la redondance sur la liste des articles de presse recommandés. A cet effet, nous avons utilisé un modèle de diversification des profils des articles de presse pour réduire la redondance de la liste des articles recommandés. Nous avons testé notre approche sur les activités réelles des utilisateurs sur quatre sites de presse CNN, Al-Jazeera, The Telegraph, et The Independent. Les résultats montrent que la diversification améliore la qualité des articles de presse recommandés. Dans la deuxième partie, nous nous sommes concentrés sur la façon d'enrichir les profils d'article avec le contenu ajouté par les utilisateurs. L'idée consiste à exploiter la structure riche des opinions pour adapter la recommandation des articles aux besoins et aux intérêts de chaque utilisateur. Le principal défi de cette tâche consiste à savoir comment sélectionner les opinions utilisées pour le profil d'enrichissement. Le grand nombre et la nature bruitée des opinions demande une stratégie efficace de classement. Pour atteindre cet objectif, nous avons proposé un nouveau modèle de classement des avis en fonction de leur pertinence et de leur importance, où l'importance d'une opinion est basée sur ses relations avec d'autres opinions. Pour trouver des avis importants, nous avons (1) proposé un modèle de graphe orienté d'opinions où chaque lien représente le sentiment qu'une opinion exprime sur une autre opinion (2) construit une nouvelle variante de l'algorithme PageRank qui augmente ou diminue les scores des opinions liens selon qu'elles sont liées avec des sentiments positifs ou négatifs. Nous avons testé l'efficacité de notre modèle par le biais de vastes expériences en utilisant trois ensembles de données glanées à partir des sites de presse de CNN, The Independent, et The Telegraph. Les expériences ont montré que notre modèle de classement sélectionne des avis utiles et perspicaces. Dans la troisième partie, nous nous sommes concentrés sur le développement d'une technique de recommandation qui exploite les résultats de la seconde partie afin d'enrichir le contenu des articles de presse. Nous avons testé différentes méthodes pour tirer parti des avis sur le contenu des articles de presse. Concrètement, nous avons travaillé sur deux aspects principaux. Tout d'abord, nous avons seulement mis l'accent sur les profils indépendants du sentiment, entités et aspects seulement, et étudié le processus de construction du profil. Deuxièmement, nous avons amélioré la stratégie de classement des opinions décrite précédemment en proposant un modèle de diversification basé sur l'autorité de chaque utilisateur. Nous avons testé notre approche à grande échelle avec quatre ensembles de données glanées sur CNN, The Independent, The Telegraph et Al-Jazeera. Les résultats montrent que notre modèle fournit des recommandations précises, en particulier lorsque le contenu des articles de presse est enrichi avec un ensemble diversifié d'opinions...|$|E
30|$|A game {{is played}} by {{multiple}} users who come together {{to start a new}} game. The ID and <b>profile</b> <b>of</b> <b>each</b> <b>of</b> these <b>users</b> are sent to the TPE. During the progress of a game, changes to player information should be transactional to maintain consistency of the ongoing game. Recall that the TPE manages transactions for the system and the TPE stores schema information. Therefore, the TPE is in charge of implementing all user interactions, transactional semantics and applications schema information. The TPE interacts with the TSM to manage ordering and scheduling of user requests during a game. This will help to manage the consistency of the gaming application. Information that transcends a game (such as player profile or player ratings) is then stored back at the DMS for future games. Note that the implementation is used as a proof of concept and does not provide full implementation of a gaming application.|$|R
40|$|This {{research}} is part of the Socioeconomic Research & Monitoring Program for the Florida Keys National Marine Sanctuary (FKNMS), which was initiated in 1998. In 1995 - 96, a baseline study on the knowledge, attitudes and perceptions of proposed FKNMS management strategies and regulations of commercial fishers, dive operators and on selected environmental group members was conducted by researchers at the University of Florida and the University of Miami’s Rosenstiel School of Atmospheric and Marine Science (RSMAS). The baseline study was funded by the U. S. Man and the Biosphere Program, and components of the study were published by Florida Sea Grant and in several peer reviewed journals. The study was accepted into the Socioeconomic Research & Monitoring Program at a workshop to design the program in 1998, and workshop participants recommended that the study be replicated every ten years. The 10 -year replication was conducted in 2004 - 05 (commercial fishers) 2006 (dive operators) and 2007 (environmental group members) by the same researchers at RSMAS, while the University of Florida researchers were replaced by Thomas J. Murray & Associates, Inc., which conducted the commercial fishing panels in the FKNMS. The 10 -year replication study was funded by NOAA’s Coral Reef Conservation Program. The study not only makes 10 -year comparisons in the knowledge, attitudes and perceptions of FKNMS management strategies and regulations, but it also establishes new baselines for future monitoring efforts. Things change, and following the principles of “adaptive management”, management has responded with changes in the management plan strategies and regulations. Some of the management strategies and regulations that were being proposed {{at the time of the}} baseline 1995 - 96 study were changed before the management plan and regulations went into effect in July 1997. This was especially true for the main focus of the study which was the various types of marine zones in the draft and final zoning action plan. Some of the zones proposed were changed significantly and subsequently new zones have been created. This study includes 10 -year comparisons <b>of</b> socioeconomic/demographic <b>profiles</b> <b>of</b> <b>each</b> <b>user</b> group; sources and usefulness of information; knowledge of purposes of FKNMS zones; perceived beneficiaries of the FKNMS zones; views on FKNMS processes to develop management strategies and regulations; views on FKNMS zone outcomes; views on FKNMS performance; and general support for FKNMS. In addition to new baseline information on FKNMS zones, new baseline information was developed for spatial use, investment and costs-and-earnings for commercial fishers and dive operators, and views on resource conditions for all three user groups. Statistical tests were done to detect significant changes in both the distribution of responses to questions and changes in mean scores for items replicated over the 10 -year period. (PDF has 143 pages. ...|$|R
40|$|People {{in modern}} {{societies}} form different social networks through numerous means of communication. These communication networks reflect {{different aspects of}} human's societal structure. The billing records of calls among mobile phone users enable us to construct a directed calling network (DCN) and its Bonferroni network (SVDCN) in which the preferential communications are statistically validated. Here we perform a comparative investigation of the cliques of the original DCN and its SVDCN constructed from the calling records of more than nine million individuals in Shanghai {{over a period of}} 110 days. We find that the statistical properties of the cliques of the two calling networks are qualitatively similar and the clique members in the DCN and the SVDCN exhibit idiosyncratic behaviors quantitatively. Members in large cliques are found to be spatially close to each other. Based on the clique degree <b>profile</b> <b>of</b> <b>each</b> mobile phone <b>user,</b> the most active users in the two calling networks can be classified in to several groups. The users in different groups are found to have different calling behaviors. Our study unveils interesting communication behaviors among mobile phone users that are densely connected to each other. Comment: 18 pages, 10 figure...|$|R
40|$|International audienceInfluence on Twitter {{has drawn}} {{a lot of}} {{attention}} these past few years since this microblogging service is used to share, seek or debate about any kind of information. Several tools providing so-called influential scores have thus been proposed. However, the algorithms behind them are kept secret and {{it is not clear how}} they consider influence. Yet, many users rely on such tools to evaluate and even try to improve their influence in the Twitter network. In a recent work, it has been shown that automatic accounts can obtain high influential scores with no intuitive reason. Extending and completing this work, we show that such measures fail at distinguishing so-called social capitalists from real, truthful users. This enlights the fact that actual scores do not seem to consider the way followers and interactions are obtained on the network. To overcome this issue, we define a classifier that discriminates social capitalists from truthful users. To that aim, we crawled the Twitter network to gather examples of certified social capitalists and regular users and obtained features related to the <b>profile</b> and behavior <b>of</b> <b>each</b> <b>user.</b> We then use such a classifier to balance Klout's score to adjust influential scores. We also developed an application that allows using our classifier online. We believe our work should raise the question of the legitimacy of influence on Twitter, and lead to significant improvements in the way it is measured...|$|R
40|$|This study {{explored}} {{the patterns of}} cocaine use and the lifestyles of users in Northern Ireland {{with the aim of}} providing the Department of Health, Social Services and Public Safety (DHSSPS) and treatment service providers with a better understanding of cocaine use in Northern Ireland. This primarily qualitative study was conducted in two phases. In Phase I a ‘Community Assessment Process’ was conducted to gain an understanding of the experiences of drug treatment professionals to cocaine use in Northern Ireland. In phase II 40 in-depth interviews were conducted with cocaine users. The study identified two types of cocaine user, these are recreational or socially integrated users and those referred for drug treatment who as a group was socially marginalized users. For {{the purposes of this study}} these users will be referred to as either recreational or treatment <b>users.</b> The demographic <b>profiles</b> <b>of</b> <b>each</b> type <b>of</b> <b>user</b> differed in a number of important respects. The recreational users were typically young, educated and anchored to a largely conventional lifestyle and whose pattern of non-work activities involved partying and drug use. Treatment users, on the other hand, generally had low level educational qualifications and were typically unemployed and living on state benefits. A number of the treatment users were either living in a hostel at the time of interview or had experienced homelessness at some time in their life. None of the recreational users reported any experience of homelessness. These distinctions, as well as differences between the groups in terms of their drug use patterns, preferences and practices, strongly suggest that in unravelling the nature of cocaine use and cocaine problems there is a need to look beyond the drug itself...|$|R
30|$|The {{algorithms}} {{guarantee the}} fairness among the streams <b>of</b> <b>each</b> <b>user,</b> {{which not only}} boost the performance <b>of</b> <b>each</b> <b>user,</b> but bring much convenience to the modulation/demodulation and coding/decoding procedures.|$|R
30|$|To {{estimate}} the channel <b>of</b> <b>each</b> <b>user,</b> we adopt the least squares (LS) estimator.|$|R
3000|$|... where 0 ≤ |ρe, k| ≤ 1. Because the SNR <b>of</b> pilots <b>of</b> <b>each</b> <b>user</b> can be different, ρe, kof <b>each</b> <b>user</b> can be different.|$|R
3000|$|... {{contains}} the column scaling ambiguity Λ, it is immaterial for estimating {{the timing and}} frequency offset <b>of</b> <b>each</b> <b>user.</b> It is because the timing and frequency offset <b>of</b> <b>each</b> <b>user</b> is obtained by phase differential term. Therefore, the scaling effect on the matrix is diminished. In addition, each timing offset with frequency offset is even automatically paired without heavy computational search for the pairing.|$|R
30|$|When 50 {{users are}} divided into six classes, {{sentiment}} tendency graph <b>of</b> <b>each</b> <b>user</b> is shown in Fig.  2.|$|R
40|$|Producing {{seamless}} tiled {{images from}} multiple displays includes measuring a luminance <b>profile</b> <b>of</b> <b>each</b> <b>of</b> the displays, computing a desired luminance <b>profile</b> for <b>each</b> <b>of</b> the displays, and determining a spatial gradient <b>profile</b> <b>of</b> <b>each</b> <b>of</b> the displays {{based on the}} measured luminance profile and the computed desired luminance profile. The determined spatial gradient profile is applied to a spatial filter to be inserted into <b>each</b> <b>of</b> the displays to produce the seamless tiled display image...|$|R
3000|$|... is {{directly}} {{linked with the}} MS velocity <b>of</b> <b>each</b> <b>user</b> and <b>each</b> <b>user</b> has a different velocity as stated in Section “System model and assumptions”, the average MS velocity [...]...|$|R
3000|$|... -node {{representing}} a multicast-user node has one outgoing edge {{associated with the}} individual key <b>of</b> <b>each</b> <b>user</b> node. <b>Each</b> [...]...|$|R
30|$|In this section, {{we study}} the bit and power {{allocation}} problem {{to maximize the}} downlink EE of the CoMP-CB system, where {{the total number of}} feedback bits <b>of</b> <b>each</b> <b>user</b> is given. We consider the system providing real-time services under a block fading channel, where <b>each</b> <b>user</b> requires a constant data rate. Since the data rate requirement <b>of</b> <b>each</b> <b>user</b> may not be supported under fading channel with imperfect CDI, to guarantee the QoS, a constraint on outage probability is considered, which is assumed less than a target value.|$|R
40|$|Conference PaperWe {{present a}} maximum {{likelihood}} method for delay estimation in a CDMA wireless communication system. An antenna array is {{used at the}} receiver, which facilitates the concomitant estimation of the direction of arrival (DOA) <b>of</b> <b>each</b> <b>user.</b> In addition, the amplitude <b>of</b> <b>each</b> <b>user</b> is also estimated. A single path is considered for <b>each</b> <b>user</b> thereby resulting in uncorrelated signals at the receiver. The delay estimation reduces to the solution {{of a set of}} quadratic equations while the DOA estimation problem is equivalent to an eigenvalue problem. Noki...|$|R
3000|$|..., is {{computed}} in per-user fashion. As a result, {{the queue}} length <b>of</b> <b>each</b> <b>user</b> is always controlled towards the target queue length.|$|R
