0|10000|Public
40|$|In {{the recent}} {{development}} {{of history and}} sociology of science, <b>peer</b> <b>review</b> practice has been scrutinized. However, historians have not {{paid any attention to}} this important topic in the history of Chinese psychology. Primarily based on thirteen recently discovered letter correspondences among leading scholars such as I. Huang, Siegen K. Chou, and Wu Youxun, this paper studies the complicated stories behind I. Huang’s two publications on the size-weight illusion using a microhistory approach. I. Huang (1903 - 1944) was an important Chinese psychologist who received trainings in child psychology and Gestalt psychology from Arnold Gesell and Kurt Koffka in the USA. A few years after returning to China, Huang’s research was severely impeded by the Sino-Japanese War, poverty, and terminal cancer. Nonetheless, Huang persevered in conducting research in hopes of delivering two research reports to international colleagues. Unexpectedly, in 1941 and again in 1943, the only two state-run international outlets both invited the same reviewer, Wang Jingxi, a physiological psychologist heading the Psychology Institute of Academia Sinica, who kept criticizing Huang’s reports. Unconvinced by Wang’s criticisms, Huang wrote letters to the editors in defense of his reports as well to his old classmate and colleague, psychologist Siegen K. Chou, for support. These correspondences discussed a number of core issues in the <b>peer</b> <b>review</b> practice: <b>evaluation</b> <b>criteria,</b> the composition and qualifications of reviewer (s), dispute resolution, and institutional and social factors that shape research activities. For example, various <b>evaluation</b> <b>criteria</b> – originality, theoretical contribution, methodological rigor, sample size, experimenter effects, the suitability of the statistics used, replicability, referencing, and language style – were brought up and discussed. In Huang’s view, Wang nitpicked about language style while downplaying other more important criteria, failed to appreciate that high reliability and statistical significance can overcome the limitation of the small sample size, and did not possess appropriate expertise to evaluate his research. When Wang criticized Huang’s study as repetitive of extant literature, Huang argued, first, that successful replication is not entirely useless, and, moreover, that his research was mainly aimed at theoretical integration rather than empirical findings. Huang admitted that his reports did indeed have certain shortcomings but argued that the wartime scarcity of literature and research equipment had made these inevitable. For instance, such scarcity had led to Huang’s lack of awareness of extant literature resembling his independent theoretical innovation. In order to resolve the disagreements, Huang contended that his methodological and language choices were no different than those of authoritative psychologists. When Huang called upon Siegen K. Chou to mediate the dispute, Chou delicately voiced his support of Huang, his intimate friend and colleague, while paying due respect to Wang, the leading figure in Chinese psychology. Chou echoed Huang’s proposal of recruiting additional reviewers, and offered further suggestions to improve the <b>peer</b> <b>review</b> process. Finally, Huang refused the two state-run outlets’ sympathetic offers of acceptance of the articles along with remuneration. He instead submitted the articles to The Journal of General Psychology based in the USA. Unfortunately, Huang soon passed away in extraordinary hardship before his articles were published. It is worth noting that the published papers include editorial footnotes about their having been accepted by Arnold Gesell, who deeply respected and mourned his former student...|$|R
50|$|A key {{outcome of}} MASSIVE is to a promote a <b>peer</b> <b>review</b> <b>evaluation</b> approach, based on models widely {{tested in the}} {{university}} partners. Via <b>Peer</b> <b>Review</b> Visits, those {{in charge of the}} best support services practices will help each university to refne and improve their support services for e-learning. At this point the project becomes very similar to a benchmarking project.|$|R
5000|$|<b>Peer</b> <b>review</b> and <b>evaluation</b> {{of digital}} {{resources}} {{for the arts and}} humanities. London, 2006. (co-authored report) ...|$|R
40|$|In {{this paper}} we analyze the {{objectivity}} of the <b>peer</b> <b>review</b> process of research performance by research {{groups in the}} scientific and technological Valencian system, over the period 1998 – 2002. For that purpose, we use qualitative and quantitative indicators to assess which of them {{are the most important}} to determine a research group as excellent one, based on <b>peer</b> <b>review</b> <b>evaluation</b> methodology. The results show that excellence appears to be driven only by publications in SCI/SSCI and the number of sexenios, and suggest that the <b>peer</b> <b>review</b> process is not as objective as we expected. Peer reviewe...|$|R
5000|$|Nursing <b>peer</b> <b>review</b> {{appears to}} have gained {{momentum}} {{as a result of}} growth of hospital participation in the American Nursing Association’s Magnet Program. [...] Even so, less than 7% of U.S. hospitals have qualified. Magnet hospitals are required to have had a <b>peer</b> <b>review</b> <b>evaluation</b> process in place designed to improve practice and performance for all RNs for at least 2 years. [...] The literature on nursing <b>peer</b> <b>review</b> is more limited than that which has been developed for physician <b>peer</b> <b>review,</b> and has focused more on annual performance appraisal than on case review. [...] No aggregate studies of clinical nursing <b>peer</b> <b>review</b> practices have been published. Nevertheless, more sophisticated studies have been reported.|$|R
40|$|The paper {{extends the}} current {{literature}} on <b>peer</b> <b>review</b> journal <b>evaluations</b> {{by providing a}} number of insights based on the diversity of Production and Operations Management (POM) research. We provide <b>peer</b> <b>review</b> <b>evaluations</b> for POM research outlets, based on a sampling frame that includes {{a large number of}} POM researchers worldwide. More specifically, the paper develops and tests various hypotheses as to whether the perceived quality and relevance of a journal is affected by such factors as: (i) nature of research work (empiricists versus modelers), (ii) society membership, (iii) research productivity, (iv) geographical location, and (v) seniority. Our findings suggest that caution must be exercised when utilizing existing POM journal rankings, as some factors, particularly the difference between empiricists and modelers, may influence journal evaluation. These must be considered when addressing issues such as faculty promotions, tenure, and salary. © 2006 Elsevier B. V. All rights reserved...|$|R
50|$|Replacing <b>peer</b> <b>review</b> with post-publication <b>evaluations</b> can {{encourage}} researchers {{to think more}} about the long-term consequences of excessive or unsubstantiated claims. That system was adopted in physics and mathematics with good results.|$|R
50|$|CESD {{ranked as}} one of the top think tanks in the world by the University of Pennsylvania. According to the University of Pennsylvania rankings - a result of surveys from 1500 {{scholars}} and <b>peer</b> <b>review</b> <b>evaluation</b> - the Center for Economic and Social Development (CESD) is one of the top 25 think tanks in Central and Eastern Europe, including CIS. CESD is the only think tank from the Caucasus and Central Asia included in the top think tanks rankings.CESD is also ranked {{as one of}} the top 25 domestic economic policy thinks tanks in the world. Only CESD (ranked 19) and the Center for Economic and Social Research (CASE), (Poland, ranked 21) were included in the list from Central and Eastern Europe and CIS countries.|$|R
50|$|Students {{often provide}} {{feedback}} {{in the form}} of <b>evaluations</b> or <b>reviews</b> on success of the teamwork experienced during cooperative learning experiences. <b>Peer</b> <b>review</b> and <b>evaluations</b> may not reflect true experiences due to perceived competition among peers. Students might feel pressured into submitting inaccurate evaluations due to bullying. To eliminate such concerns, confidential evaluation processes may help to increase evaluation strength.|$|R
40|$|MERLOT (Multimedia Educational Resource for Learning and Online Teaching) is a Web-based open {{resource}} designed {{primarily for}} {{faculty and students}} in higher education that aims to alleviate the difficulties in locating relevant materials of high quality. The resources in MERLOT include learning materials and support materials {{from a wide variety}} of disciplines that can be integrated within the context of a larger course. Support resources attached to materials include sample assignments and evaluations of the learning materials, and help faculty members identify learning materials that are high quality and pedagogically appropriate for their courses. Evaluation materials include discipline panel <b>peer</b> <b>reviews</b> and individual user reviews. The resources in the MERLOT repository currently include 8, 500 free learning materials and support materials. The number of registered individual members who can add teaching-learning materials, comments, and assignments to the MERLOT collection has exceeded 13, 600. The paper presents an overview of the MERLOT and its current state. Keywords: Web-based learning, online teaching, <b>peer</b> <b>review</b> <b>evaluation...</b>|$|R
5000|$|CESD {{ranked as}} one of the top think tanks in the world by The University of Pennsylvania, United States in Global [...] "Go-To Think Tanks" [...] Report in 2010. According to the University of Pennsylvania rankings - a result of surveys from 1500 {{scholars}} and <b>peer</b> <b>review</b> <b>evaluation</b> - the Center for Economic and Social Development (CESD) is one of the top 25 think tanks in Central and Eastern Europe, including CIS. CESD is the only think tank from the Caucasus and Central Asia included in the top think tanks rankings. CESD is also ranked {{as one of}} the top 25 domestic economic policy thinks tanks in the world. Only CESD (ranked 19) and the Center for Social and Economic Research (CASE), (Poland, ranked 21) were included in the list from Central and Eastern Europe and CIS countries.|$|R
40|$|The {{appraisal}} of scientific quality {{is a particularly}} difficult problem. Editorial boards resort to secondary criteria including crude publication counts, journal prestige, the reputation of authors and institutions, and estimated importance and relevance of the research field, making <b>peer</b> <b>review</b> a controversial rather than a rigorous process. On this background different methods for evaluating research may become required, including citation rates and journal impact factors (IF), which {{are thought to be}} more quantitative and objective indicators, directly related to published science. The aim of this review is to go into the two pillars of contemporary medical publishing, that is the <b>peer</b> <b>review</b> process and the IF. Qualified experts' reviewing the publications appears to be the only way for the evaluation of medical publication quality. To improve and standardise the principles, procedures and <b>criteria</b> used in <b>peer</b> <b>review</b> <b>evaluation</b> is of great importance. Standardizing and improving training techniques for peer reviewers, would allow for the magnification of a journal's impact factor. This may be a very important reason that impact factor and <b>peer</b> <b>review</b> need to be analyzed simultaneously. Improving a journal's IF would be difficult without improving peer-review efficiency. Peer-reviewers need to understand the fundamental principles of contemporary medical publishing, that is peer-review and impact factors. The current supplement of the Hippokratia for supporting its seminar for reviewers will help to fulfil some of these scopes...|$|R
50|$|The {{process of}} <b>peer</b> <b>review</b> {{involves}} <b>evaluation</b> {{of the experiment}} by experts, who typically give their opinions anonymously. Some journals request that the experimenter provide lists of possible peer reviewers, especially if the field is highly specialized. <b>Peer</b> <b>review</b> does not certify correctness of the results, only that, {{in the opinion of}} the reviewer, the experiments themselves were sound (based on the description supplied by the experimenter). If the work passes <b>peer</b> <b>review,</b> which occasionally may require new experiments requested by the reviewers, it will be published in a peer-reviewed scientific journal. The specific journal that publishes the results indicates the perceived quality of the work.|$|R
50|$|It is {{the only}} Italian {{publishing}} company that does not require exclusive rights for its publications.Aracne publishes both paper books and eBooks, {{most of them in}} Italian, although a considerable number of works is published in English. It uses the <b>peer</b> <b>review</b> as an <b>evaluation</b> system.|$|R
40|$|Recent years saw the {{emergence}} of research information systems (RIS) in University IT portfolios. The increasing number of local RIS show {{the need for the}} institutions to provide tools for its academic and administrative staff as well as for senior management for making strategic decision or complying with reporting requirements. This seminar lecture focuses on trends and challenges in managing implementations of RIS from an institutional view: Data curation and data quality issues form the basis of the quest for a fit-for-purpose, efficient and sustainable RIS. Examples based around interconnectivity will exploit the application of data standards to increase efficiency and sustainability in research information matters. Previously used for retrospective mandatory reporting requirements (e. g. <b>peer</b> <b>review</b> <b>evaluation</b> in REF, funder post-award reports), RIS expand to more than that: Academic Profiles, network and collaboration analysis form part of latest developments to futureproof the University RIS to become a pro-active tool used by academics in their day-to-day business...|$|R
2500|$|... "Fifty {{percent of}} {{physicians}} look up {{conditions on the}} (Wikipedia) site, and some are editing articles themselves {{to improve the quality}} of available information." [...] Beck continued to detail in this article new programs of Dr. Amin Azzam at the University of San Francisco to offer medical school courses to medical students for learning to edit and improve Wikipedia articles on health-related issues, as well as internal quality control programs within Wikipedia organized by Dr. James Heilman to improve a group of 200 health-related articles of central medical importance up to Wikipedia's highest standard of articles using its Featured Article and Good Article <b>peer</b> <b>review</b> <b>evaluation</b> process. In a May 7, 2014, follow-up article in The Atlantic titled [...] "Can Wikipedia Ever Be a Definitive Medical Text?", Julie Beck quotes Wikiproject Medicine's Dr. James Heilman as stating: [...] "Just because a reference is peer-reviewed doesn't mean it's a high-quality reference." [...] Beck added that: [...] "Wikipedia has its own <b>peer</b> <b>review</b> process before articles can be classified as 'good' or 'featured.' Heilman, who has participated in that process before, says 'less than 1 percent' of Wikipedia's medical articles have passed.|$|R
40|$|Design-oriented {{learning}} requires {{tools that}} support creative processes and student-to-student and student-to-faculty interactions. While most present E-Education systems perform as the asynchronous distribution channel for teaching material, they usually offer little support for project based design processes. This research maps out the key learning events in design classes at MIT's Department of Mechanical Engineering, and proposes guidelines for building E-Education systems {{to support the}} unique characteristics of design-oriented learning. Two creative learning processes are identified and two independent, yet tightly related, software systems are implemented and evaluated. The first application, the <b>Peer</b> <b>Review</b> and Engineering Process (PREP), is a web system that helps instructors and students conduct and manage <b>peer</b> <b>review</b> <b>evaluation</b> of design concepts. The second is a real time application called InkBoard that leverages the Tablet PC and Ink medium to provide real-time collaborative sketching over TCP/IP networks. A new streaming network protocol for transferring Ink objects is proposed and implemented. A comparative study against other ink-enabled protocols is also presented. by Hai Ning. Thesis (Ph. D.) [...] Massachusetts Institute of Technology, Dept. of Civil and Environmental Engineering, 2004. Includes bibliographical references (p. 149 - 155) ...|$|R
40|$|The {{development}} of a Monte Carlo simulation of procurement activities at the NASA Ames Research Center is described. Data cover: simulation of the procurement cycle, construction of a performance evaluation model, examination of employee development, procedures and <b>review</b> of <b>evaluation</b> <b>criteria</b> for divisional and individual performance evaluation. Determination of the influences and apparent impact of contract type and structure and {{development of}} a management control system for planning and controlling manpower requirements...|$|R
40|$|Students {{can enhance}} their soft skills and {{learning}} experience {{through the use}} of group projects. However, evaluating group project performance has become very challenging. This paper presents the concept of group management in measuring individual performance in group projects in an academic setting. Individual performances in similar courses were also compared based on two consecutive semesters (Semesters 1 and 2). The respondents for this study were first year students who attended similar courses for both semesters. Performance measurement was based on <b>peer</b> <b>review</b> and lecturer <b>evaluations.</b> The <b>criteria</b> for these <b>evaluations</b> were similar for both semesters. The current study aims to determine the weaknesses and strengths of an individual in a group, and relate them with group performance based on the individual presentation marks. The study also analyzes the relationship between these two performance tools. Findings indicate that <b>peer</b> <b>review</b> and lecturer <b>evaluations</b> can be used to determine the performance of students in a group project, and that these two evaluation tools are not significantly correlated. <br /...|$|R
40|$|This report {{discusses}} {{the issues involved}} in evaluating a software bidding model. We {{found it difficult to}} assess the appropriateness of any model evaluation activities without a baseline or standard against which to assess them. This paper describes our attempt to construct such a baseline. We <b>reviewed</b> <b>evaluation</b> <b>criteria</b> used to assess cost models and an evaluation framework that was intended to assess the quality of requirements models. We developed an extended evaluation framework that will be used to evaluating our bidding model. Furthermore, we suggest the evaluation framework might be suitable for evaluating other models derived from expert opinion based influence diagrams. We use a simple process model to relate the evaluation framework to the model building process. The process model indicates the order in which different evaluation activities are performed and the role responsible for performing them. It also illustrates the difference between evaluating a generic bidding model and evaluating...|$|R
50|$|<b>Peer</b> <b>review</b> is the <b>evaluation</b> {{of work by}} one or {{more people}} of similar {{competence}} to the producers of the work (peers). It constitutes a form of self-regulation by qualified members of a profession within the relevant field. <b>Peer</b> <b>review</b> methods are employed to maintain standards of quality, improve performance, and provide credibility. In academia, scholarly <b>peer</b> <b>review</b> is often used to determine an academic paper's suitability for publication. <b>Peer</b> <b>review</b> can be categorized by the type of activity and by the field or profession in which the activity occurs, e.g., medical <b>peer</b> <b>review.</b>|$|R
50|$|A Lehman Review is an {{independent}} <b>peer</b> <b>review</b> and <b>evaluation</b> {{of the status of}} a major construction project in the United States Department of Energy's (DOE's) Office of Science. Lehman Reviews evaluate all aspects of a construction project's current status, including technical aspects, cost, schedule and management, and they are usually held twice a year. Lehman Reviews are widely known in DOE, other agencies and abroad. The reviews are named after Daniel Lehman, Director of the DOE Office of Science's Office of Project Assessment since 1991.|$|R
40|$|This paper {{describes}} the method for ex-post <b>peer</b> <b>review</b> <b>evaluation</b> per research discipline {{used at the}} Vrije Universiteit Brussel (VUB) and summarizes the outcomes obtained from it. The method produces pertinent advice and triggers responses - {{at the level of}} the individual researcher, the research team and the university's research management - for the benefit of research quality, competitivity and visibility. Imposed reflection and contacts during and after the evaluation procedure modify the individual researcher's attitude, improve the research teams' strategies and allow for the extraction of general recommendations that are used as discipline-dependent guidelines in the university's research management. The deep insights gained in the different research disciplines and the substantial data sets on their research, support the university management in its policy decisions and in building policy instruments. Moreover, the results are used as a basis for comparison with other assessments, leading to a better understanding of the possibilities and limitations of different <b>evaluation</b> processes. The <b>peer</b> <b>review</b> method can be applied systematically in a pluri-annual cycle of research discipline evaluations to build up a complete overview, or it can be activated on an ad hoc basis for a particular discipline, based on demands from research teams or on strategic or policy arguments. Comment: 21 pages, 4 figure...|$|R
5000|$|On March 5, 2014, Julie Beck {{writing for}} The Atlantic {{magazine}} {{in an article}} titled [...] "Doctors' #1 Source for Healthcare Information: Wikipedia", stated that"Fifty percent of physicians look up conditions on the (Wikipedia) site, and some are editing articles themselves {{to improve the quality}} of available information." [...] Beck continued to detail in this article new programs of Dr. Amin Azzam at the University of San Francisco to offer medical school courses to medical students for learning to edit and improve Wikipedia articles on health-related issues, as well as internal quality control programs within Wikipedia organized by Dr. James Heilman to improve a group of 200 health-related articles of central medical importance up to Wikipedia's highest standard of articles using its Featured Article and Good Article <b>peer</b> <b>review</b> <b>evaluation</b> process. In a May 7, 2014, follow-up article in The Atlantic titled [...] "Can Wikipedia Ever Be a Definitive Medical Text?", Julie Beck quotes Wikiproject Medicine's Dr. James Heilman as stating: [...] "Just because a reference is peer-reviewed doesn't mean it's a high-quality reference." [...] Beck added that: [...] "Wikipedia has its own <b>peer</b> <b>review</b> process before articles can be classified as 'good' or 'featured.' Heilman, who has participated in that process before, says 'less than 1 percent' of Wikipedia's medical articles have passed.|$|R
40|$|AbstractConstructivist {{approach}} of science education is undertaking of wide scope nowadays, mainly {{in teaching and}} learning processes. According to constructivist evaluation there are important the skills students achieved during learning process, their abilities to use in real life, what they learned and the way they refer themselves to others. New constructivist learning strategies are more and more numerous, so the evaluation has to be discriminating from the traditional one. Constructivist teachers develop alternative evaluating methods according to students’ different learning styles as to offer to everyone the opportunity to express themselves. During evaluation process students may interact one to each other, may use ICT or online environments. Auto <b>evaluation</b> and <b>peer</b> <b>review</b> <b>evaluation</b> are also encouraged as to develop communication and social skills. Assessing testes and home works in traditional way will not be a common preoccupation for today teacher, but to think out of how to implement new evaluating strategies. In this paper we present some alternatives to traditional evaluation for middle and college school students who studied advanced science concepts in constructivist classe...|$|R
50|$|Over time, the journal’s {{trends in}} {{publication}} reveal two notable characteristics Figure 3. First, the journal, although each year grew in numbers of publications and content, did not publish any issues in 2002. (Thomas Reuters 2013) This gap {{may be due}} to the changes in leadership, from Professor Hannoun to Professor Hofman, during that year. Second, the journal’s publications in 2006 more than tripled compared to all other years before and after, from around 200 to 650 published items. (Thomas Reuters 2013) This may be a result of the European Congress of Epidemiology 2006’s the Board of the European Epidemiology Federation of the International Epidemiological Federation of the International Epidemiological Association’s (IEA-EEF) Congress, an international meeting to exchange ideas at Utrecht University through keynote sessions and meetings. (Geert et al. 2006) The surge in scientists in the Netherlands encouraged numerous abstract submissions and <b>peer</b> <b>review</b> <b>evaluations</b> to publish. (Geert et al. 2006) Aside from those two anomalies, the journal has had a leveled number of publications, averaging at 200 per issue. Despite that, the number of citations has grown exponentially Figure 3.|$|R
40|$|Describes the Bachelor of Science (B. S.) in Computer Science {{assessment}} {{activities for}} the academic year 2011 - 2012. The Bachelor of Science (B. S.) in Computer Science annual assessment report to the College for the Office of Academic Assessment. The report details assessment through exams, <b>peer</b> <b>review</b> surveys,research paper <b>evaluation,</b> employer surveys, and senior exit surveys...|$|R
40|$|Three {{themes in}} {{educational}} practice and policy create {{a need for}} consideration of ethics to frame practices of teachers serving {{in the evaluation of}} colleagues. First is a reoccurring series of evaluation designs that directly involve teachers in formative and/or summative peer evaluation (e. g., NBPTS, 2002 : Peterson, 2000). The second basis is a call for increased teacher professionalism, which includes some form of <b>peer</b> <b>review</b> or <b>evaluation</b> (Cooperm 1998; Darling-Hammond, 1989). Finally, ethical codes to guide professional behavior have been established for a variety of educational applications (NEA, 1975; Sparks, 2000) ...|$|R
40|$|<b>Peer</b> <b>review</b> {{technique}} used in educational context could {{be beneficial for}} students from several points of view. Besides of developing students’ writing skills, critical thinking, practising articulation of own knowledge to the others and giving them feedback, it can encourage collaborative learning and boost the students’ interest in the course. In our web design course we successfully introduced <b>peer</b> <b>review</b> activities more than 2 years ago. In this paper we discuss the students’ acceptance of <b>peer</b> <b>review</b> applied on <b>evaluation</b> of other students’ projects...|$|R
40|$|It is {{increasingly}} accepted that {{the completion of}} undergraduate medical education {{is only the first}} step in a process of life long learning for physicians. At its simplest, life long learning involves participation in continuing medical education (CME), designed to keep physicians up-to-date on clinical developments and medical knowledge. The broader concept of continuing professional development (CPD) includes CME along with the development of personal, social and managerial skills. More demanding methods incorporate other tools such as <b>peer</b> <b>review,</b> external <b>evaluation</b> and practice inspection. The outcome of these processes may be recertification or relicensure, although this is rarely the case in Europe...|$|R
40|$|The {{increasing}} {{importance of}} Knowledge Management (KM) has prompted many researchers to examine {{facets of the}} topic. However, understanding the acquisition of KM software in organisations and particularly the factors and conditions that affect the acquisition process has been largely ignored in the literature. Here we argue that incorporating an understanding of issues relating to KM software acquisition into KM frameworks could have real business benefits such as substantial savings in terms of cost, time, and improved administrative procedures, and could lessen the risk and uncertainty associated with KM software. The paper first examines KM definitions, KM processes and frameworks. Then, it briefly <b>reviews</b> <b>evaluation</b> <b>criteria</b> for acquiring KM software. A conceptual framework is introduced to describe {{the nature of the}} KM software acquisition process. Lastly, that framework is illustrated using two case studies to highlight its usefulness. This framework can also be used as a tool to explore the appropriateness of a particular software solution to an organisation by analysing the solution against the factors and conditions depicted in the framework. Empirical examination of the factors identified in our framework could also lead {{to a better understanding of}} the critical success factors of KM initiatives...|$|R
40|$|This is {{the third}} {{professional}} <b>peer</b> <b>review</b> of the <b>evaluation</b> function at a multilateral development or humanitarian organisation. It was carried out at WFP’s request {{by a group of}} international <b>evaluation</b> experts. The <b>review</b> has assessed {{the strengths and weaknesses of}} the evaluation function at WFP along three criteria or dimensions: independence, credibility and utility. A number of measures for improvement are proposed in the report. The professional <b>peer</b> <b>reviews</b> are joint initiatives by the OECD-DAC Network on Development Evaluation and the UN Evaluation Group (UNEG) ...|$|R
40|$|<b>Peer</b> <b>review,</b> <b>evaluation,</b> and {{selection}} {{is a fundamental}} aspect of modern science. Funding bodies the world over employ experts to review and select the best proposals of those submitted for funding. The problem of peer selection, however, is much more general: a professional society may {{want to give a}} subset of its members awards based on the opinions of all members; an instructor for a MOOC or online course may want to crowdsource grading; or a marketing company may select ideas from group brainstorming sessions based on peer evaluation. We make three fundamental contributions to the study of procedures or mechanisms for peer selection, a specific type of group decision-making problem, studied in computer science, economics, and political science. First, we propose a novel mechanism that is strategyproof, i. e., agents cannot benefit by reporting insincere valuations. Second, we demonstrate the effectiveness of our mechanism by a comprehensive simulation-based comparison with a suite of mechanisms found in the literature. Finally, our mechanism employs a randomized rounding technique that is of independent interest, as it solves the apportionment problem that arises in various settings where discrete resources such as parliamentary representation slots need to be divided proportionally. Comment: 1 Figure, Source Code available at [URL]...|$|R
40|$|TITLE: <b>Peer</b> <b>Review</b> of Vocational Education and Training Schools AUTHOR: Stanislav Michek DEPARTMENT: Department of Primary Education, Charles University in Prague SUPERVISOR: prof. PhDr. Karel Rýdl, CSc. ABSTRACT: The {{subject of}} the {{research}} of the thesis {{is the issue of}} external evaluation, particularly technical and vocational schools by partners at the same level (<b>peer</b> <b>review).</b> In the theoretical part is paid attention to concepts associated with the development of the school, the <b>peer</b> <b>review</b> is set in the context of other forms of external evaluation in education in general level and then describes {{the current state of the}} external evaluation of schools in the Czech Republic. For the empirical research was designed mixed methods design. When the research was, along with other research methods effected multiple case study - fed 4 specific stories of <b>peer</b> <b>review</b> in the Czech Republic. From the findings have been identified following supportive factors peer review: attitudes toward evaluation, condition, experience with evaluation, competency of the participants, of the interaction rated the school and peers and support <b>peer</b> <b>review.</b> At the end are suggested other possible ways of research and recommendations for educational policy. KEYWORDS: <b>peer</b> <b>review,</b> external <b>evaluation,</b> mixed methodology, school, teacher...|$|R
40|$|Coaching {{supervision}} is {{a relatively}} recent development, but already competency frameworks and content and process models exist. What does not yet exist is an articulation of coach supervisors’ attitudes, and how these drive delivery and influence how relationships are managed. In this article, based on current literature and my experience as a practitioner, I propose a rudimentary framework, articulating seven principles of a coaching supervision mind-set. The discussion considers {{the validity of the}} framework and looks at some potential criticisms, before exploring how the principles might be useful for practitioners. Discussion highlights the need for further articulation, <b>peer</b> <b>review</b> and <b>evaluation.</b> The article ends with a call to action, seeking participants for an Action Research projec...|$|R
40|$|The {{inadequate}} {{documentation of}} an emergency medical service (EMS) incident has been a chronic problem affecting the Saint Paul Fire Department {{and has become a}} critically important issue with the increase in litigation involving EMS operations and the evolution of quality improvement programs. The purpose of this research project was to determine whether a <b>peer</b> <b>review</b> and <b>evaluation</b> program could be used to improve the documentation of the Saint Paul Fire Department’s EMS incident reports. The research employed evaluative and action methods to address the following questions: 1. What data elements must be present to constitute an acceptable EMS incident report? 2. Can an objective evaluation tool be developed that could quantify the elements required for an acceptable EMS incident report? 3. Could an effective EMS incident report <b>peer</b> <b>review</b> program be accepted in a large, career fire department without creating organizational conflict and without committing additional resources...|$|R
