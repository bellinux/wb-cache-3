0|22|Public
6000|$|... "It was jest like this: You see, Skip he come up an' hit Teddy in the jaw, and Teddy {{tried to}} hit back. Skip let {{out with a}} left-hander; Teddy warded it off. Then Skip jumped; down went the <b>papers.</b> <b>Skip</b> got frightened of a cop; he started to run, Teddy after him, an' Teddy was 'rested, and that's all there is 'bout it." ...|$|R
30|$|If take L= 0 in Corollaries  3.4 - 3.6, we {{get three}} more consequences. Regarding {{the volume of}} the <b>paper,</b> we <b>skip</b> the details.|$|R
25|$|Reality intervened, however. The paper's initial {{financial}} {{needs were}} met by a one-year subsidy provided by Anita McCormick Blaine, an heir to the McCormick Harvesting Machine Company fortune, which soon expired, leaving the editors {{in charge of a}} paper with a production cost of 12 cents an issue and a cover price of just 5 cents. The <b>paper</b> <b>skipped</b> issues and slashed pay of its office staff, barely surviving the financial crisis. The paper's cover price was hiked to 10 cents in an effort to balance costs and revenues.|$|R
40|$|Extraction-dependent {{methods were}} used to {{evaluate}} the antioxidant capacity up to now. The extraction conditions applied before the measurement represent a source of variations among laboratories and in some cases are not reliable. The direct procedure described in this <b>paper</b> <b>skips</b> all time-consuming solvent extraction and hydrolysis steps. A review of the solubility and localization of food antioxidant compounds was provided as base to understand the advantage of the direct procedure with respect to the extraction protocols present in the literature. The application of the procedure to some case-studies was also illustrated...|$|R
50|$|Reality intervened, however. The paper's initial {{financial}} {{needs were}} met by a one-year subsidy provided by Anita McCormick Blaine, an heir to the McCormick Harvesting Machine Company fortune, which soon expired, leaving the editors {{in charge of a}} paper with a production cost of 12 cents an issue and a cover price of just 5 cents. The <b>paper</b> <b>skipped</b> issues and slashed pay of its office staff, barely surviving the financial crisis. The paper's cover price was hiked to 10 cents in an effort to balance costs and revenues.|$|R
60|$|It was {{not long}} before he succeeded in imitating their cries, and had already sold four <b>papers</b> when <b>Skip</b> Jellison, who was {{accompanied}} by his friends Sid Barker and Teenie Massey, appeared in view.|$|R
40|$|Abstract. This work {{proposes a}} way to model the {{structure}} and behaviour of agents in terms of executable coloured Petri net protocols. Structure and behaviour are not all aspects of agent based computing: agents need a world to live in (mostly divided into platforms), they need a general structure (e. g. including a standard interface for communication) and their own special behaviour. Our approach tackles all three parts in terms of Petri nets. This <b>paper</b> <b>skips</b> the topic of agent platforms and handles the agent structure briefly to introduce a key concept of our work: the graphical modelling of the behaviour of autonomous and adaptive agents. A special kind of coloured Petri nets is being used throughout the work: reference nets. Complex agent behaviour is achieved via dynamic composition of simpler sub-protocols, a task that reference nets are especially well suited for. The inherent concurrency of Petri nets is another point that {{makes it easy to}} model agents: multiple threads of control are (nearly) automatically implied in Petri nets...|$|R
5000|$|Pen {{manufacturers}} using {{a proprietary}} cartridge (which {{in almost all}} cases are the more expensive ones like the ones mentioned above) tend to discourage the use of cheaper [...] internationally standardised short/long cartridges or adaptations thereof due to their variance in ink quality in the cartridges which may not offer as much performance, or be of lesser quality than the manufacturer of the pen; ink that has been designed specifically for the pen. In addition, cheaper ink tends to take longer to dry on <b>paper,</b> may <b>skip</b> or produce uneven colour on the page and less [...] "tolerant" [...] on lower, thinner grades of paper (e.g. 75gs/m).|$|R
40|$|This <b>paper</b> {{conveniently}} <b>skips</b> any controversy {{associated with}} the science of climate change. On the assumption that greenhouse gas emissions are causing climate change that is detrimental to humanity, the paper focuses on some economic dimensions of the issue which seem to be poorly understood by Australian media commentators, policy analysts, interest groups and the political parties. Using a neoclassical welfare economics framework the paper explores {{the costs and benefits}} of greenhouse gas abatement with reference to the findings of the Stern Report, the setting of greenhouse gas targets by Australian political parties, the danger of the government “picking winners” and the emerging carbon theory of value. The paper concludes with a brief review of the relative merits of a carbon tax and a cap and trade approach. Key Words: This <b>paper</b> conveniently <b>skips</b> any controversy {{associated with the}} science of climate change. On the assumption that greenhouse gas emissions are causing climate change that is detrimental to humanity, the paper focuses on some economic dimensions of the issue which seem to be poorly understood by Australian media commentators, policy analysts, interest groups and the political parties. Using a neoclassical welfare economics framework the paper explores {{the costs and benefits of}} greenhouse gas abatement with reference to the findings of the Stern Report, the setting of greenhouse gas targets by Australian political parties, the danger of the government “picking winners” and the emerging carbon theory of value. The paper concludes with a brief review of the relative merits of a carbon tax and a cap and trade approach. climate change, economics, targets, policy, carbon tax, cap and trade, Environmental Economics and Policy, Political Economy, Public Economics,...|$|R
6000|$|... "He's a feller what {{walked down}} from Saranac, an' got here {{yesterday}} mornin'; but jest {{as he was}} goin' to sell <b>papers</b> up jumped <b>Skip,</b> 'cause he thinks he owns the whole town, an' 'lowed he was goin' to clean Teddy right out. Now, I never did think Skip could fight any great deal, 'cause how was {{it when he was}} over to Brooklyn, an' that feller tackled him?" ...|$|R
40|$|Skip {{lists are}} a {{probabilistic}} data structure that {{seem likely to}} supplant balanced trees as the implementation method of choice for many applications. Skip list algorithms have the same asymptotic expected time bounds as balanced trees and are simpler, faster and use less space. The original <b>paper</b> on <b>skip</b> lists only presented algorithms for search, insertion and deletion. In this paper, we show that skip lists are as versatile as balanced trees. We describe and analyze algorithms to use search fingers, merge, split and concatenate skip lists, and implement linear list operations using skip lists. The skip list algorithms for these actions are faster and simpler than their balanced tree cousins. The merge algorithm for skip lists we describe has better asymptotic time complexity than any previously described merge algorithm for balanced trees. CR Categories and Subject Descriptors: E. 1 [Data Structures]: Lists; F. 1. 2 [Models of Computation]: Probabilistic computation; F. 2. 2 [Nonnumeric [...] ...|$|R
40|$|Abstract. Traditional small block Forward Error Correction (FEC) codes, {{like the}} Reed-Solomon erasure (RSE) code, {{are known to}} raise {{efficiency}} problems, in particular when they are applied to the Asynchronous Layered Coding (ALC) reliable multicast protocol. In this paper we describe {{the design of a}} simple large block Low Density Generator Matrix (LDGM) codec, a particular case of LDPC code, which is capable of operating on source blocks that are several tens of megabytes long. We also explain how the iterative decoding feature of LDGM/LDPC can be used to protect a large number of small independent objects during time-limited partially-reliable sessions. We illustrate this feature with an example derived from a video streaming scheme over ALC. We then evaluate our LDGM codec and compare its performances with a well known RSE codec. Tests focus on the global efficiency and on encoding/decoding performances. This <b>paper</b> deliberately <b>skips</b> theoretical aspects to focus on practical results. It shows that LDGM/LDPC open many opportunities in the area of bulk data multicasting...|$|R
5000|$|A three-day-symposium {{organized}} by Hans Reinhard Seeliger in the Catholic Academy in Schwerte {{was dedicated to}} the first three volumes {{in the beginning of}} October 1992. Besides Seeliger, 22 other specialists in Christian history, patrology, old history, archaeology, jurisprudence, and other fields participated. The symposium's papers were published in 1993 as an anthology. Deschner refused the invitation arguing that he already answered all basic questions sufficiently in the preface of his first volume. He decided to exemplarily confront the paper Emperor Konstantin, one of the Greats in history? in a reply which was put in front of the fifth volume. The other <b>papers</b> were <b>skipped.</b> Hermann Gieselbusch, lector with the Rowohlt publishing house, noted at the same place (preface of vol. 5), that only few symposium participants [...] "abstained at least from personal revilement", mentioning four speakers by name - Ulrich Faust, Theofried Baumeister, Erich Feldmann und Gert Haendler - and thanking them for their fairness in Deschner's name.|$|R
40|$|Abstract:This <b>paper</b> {{studies the}} <b>skip,</b> under some assumptions, {{of a process}} control operation. The case of one tool, one {{enhanced}} buffer and one metrology tool of a monotonic parameter is analyzed. The paper presents in which circumstances a release of the control can happen, due to buffer behavior's. After presenting the industrial issue, the article goes through literature review. The article follows by presenting the model and steps toward industrial development. A demonstrator is then presented applied at a case study. A test over a 300 mm wafer-fab data set shows serious improvements: around 10 % of defectivity controls {{have been allowed to}} be skipped without any loss of information...|$|R
40|$|This <b>paper</b> {{presents}} step <b>skipping</b> acceleration {{techniques for}} a class of convergence algorithms computing arithmetic functions. In particular, {{an extension of the}} fast adder carry-skip procedure is carried out for special purpose cellular array circuits implementing iterative logical functions for which some propagating information may be fruitfully computed ahead of the current step output computation. This information is thus carried to the next stage, accelerating the overall calculation. An application is given for the 2 ´s complement sign changing circuit, then for the step-skipping acceleration circuits used in the implementation of the ln(x) convergence algorithm. FPGA implementations on Xilinx Virtex IV have been achieved with comparative analysis of 32 - to 512 -bit computing algorithms. Workshop de Arquitecturas, Redes y Sistemas Operativos (WARSO...|$|R
40|$|Abstract [...] -Text mining is a {{practice}} which {{is regarded as}} the supporting pillars of Information Retreival. This paper is in simple terms dedicated to text mining and bear a prime focus on mining academic papers. An architecture is proposed by the authors is presented in the paper, which they have named HTPI. This framework is built upon Java eclipse using Apache Hadoop. The problem under consideration for the paper is the reference metamorphosis of the references mentioned in the references section of any scientific paper based upon the similarity score(between the referenced paper and the paper whose reference list is being re-ordered) retrieved. Various notions have been used in the <b>paper</b> like stemming, <b>skipping</b> and similarity calculation using Jaccard Coefficient...|$|R
40|$|A {{construction}} of the fundamental solution for Schrödinger equations By Naoto Kumano-go Abstract. In this <b>paper,</b> applying the <b>skip</b> method in Fujiwara [3] {{to the theory of}} multi-products of Fourier integral operators in Ki-tada and H. Kumano-go [6], we give a {{construction of}} the fundamental solution for the Cauchy problem of a pseudo-differential equation of Schrödinger’s type. We regard this construction as a multi-product of Fourier integral operators, and investigate the pointwise convergence of the phase function and that of the symbol. Here we use neither the solution of the Hamilton-Jacobi equation in [6] nor the action of the classical orbit in [2],[4]. Let Lh be a Schrödinger operator defined by Lh ≡ i∂t +Kh(t,X,Dx) on [0, T] with a parameter 0 < h < 1. For sufficiently small T 0 (0 < T 0 ≤ T) ...|$|R
5000|$|In 2005, during Hurricane Katrina and its aftermath, the Star (as it {{is often}} called locally) {{continued}} operation via emergency measures and <b>skipped</b> <b>paper</b> publication on just one day — Tuesday August 30 - the only date since 1959 that the Star had not published as scheduled. In the meantime, even on that Tuesday as during the preceding weekend, the Star staff was at work and, with the public power outage, used generators and laptop computers to maintain the newspaper's web site; issues for August 31 and September 1 and 2 were printed in Denham Springs. [...] During and after the storm the Star facilities in Hammond served as the temporary operations center for the Associated Press New Orleans bureau and as the temporary reporting-base for several newspapers {{from around the country}} in covering the New Orleans situation. With just one day of interrupted publication on paper, the Star published accounts of the hurricane and its aftermath, including controversies related to the Federal Emergency Management Agency (FEMA).|$|R
40|$|Abstract. A {{two year}} study of {{evaluate}} the valid service life of durable pavement markings on urban roads {{was conducted in}} Beijing as a pilot field study of Chinese national transportation product evaluation program and minimum retro-reflectivity requirements standards and road maintenance standards. 34 pavement marking lines including edge line, arrow, skip line, crossing line and stop line were installed on expressway and intersection. Marking materials included thermoplastic with glass beads, preformed thermoplastic tape with glass beads and preformed rubber based pavement tape. Service life evaluation was base on minimum value of durability and retro-reflectivity. Retro-reflectivity attenuation varies at different locations (express way, intersection), different marking functions (e. g., skip line, edge line) and different materials (thermoplastic or tape). It was found the more accumulated traffic, the more loss of retro-reflectivity. The most loss of retro-reflectivity happens at stop lines, skip line and cross line are better, arrows are less, edge line is the best. Cleanliness factor are also considered, retro-reflectivity significantly rises after cleaned. A maintenance schedule for different markings was given in this <b>paper.</b> Stop line, <b>skip</b> line and crossing line are suggested to be replaced every 12 months; arrow and edge line are suggested to be replaced every 24 months with a special concern of cleanliness at urban area...|$|R
40|$|Background: Central {{obesity is}} one of the major public health problems. Recent studies have {{indicated}} that body fat distribution would be important in general health. Materials and Methods: The present study is a review of several studies which discuss the contributing factors of abdominal obesity, particulary in Iran. This study reviews 34 cross-sectional and interventional studies, which have been comducted during 1995 - 2012 and issued in English language. PubMed search engine and the related keywords were used to search the <b>papers.</b> Results: Breakfast <b>skipping</b> and also the sleep duration as well as the quality of diet are also associated with central adiposity. Dietary diversity score among Iranians can be related to abdominal adiposity. Fastfood consumption can increase the risk of central adiposity among young Iranian population. Red meat intake and food source of trans fat can increase the risk of central adiposity. Low quality diet with low amount of nutrients can increase the risk of central adiposity. Conclusion: Some behaviours such as sleep duration and eating breakfast can be associated with central adiposity among Iranians. Diet quality and dietary diversity score is also associated with this problem among Iranians. Copyright © 2013 Zahedan University of Medical Sciences. All rights reserved...|$|R
40|$|A {{real-time}} {{system is}} one in which the temporal aspects of its behaviour are part of their specification. The problem with traditional real-time specification is no guarantees on when and how many deadlines may be missed can be given to the tasks because their specification is focused on met all the deadlines and cannot missed it, otherwise the tasks is totally failed. Thus, the weakly hard specification solve this problem with define a gradation on how the deadlines can be missed while still guaranteeing the tasks meets their deadlines. In this paper, a review has been made on the three specifications of real-time systems which is losses or missed of the deadlines can be permitted occasionally. Three criteria used in the evaluation are the process model, temporal specifications and predictability. These three criteria were chosen because the tasks in real-time systems are usually periodic in nature, have timing constraints like deadlines and the behaviour of the systems must be predictable. The three specifications we reviewed in this <b>paper</b> are the <b>skip</b> constraints known as skip factor s, (m,k) -firm deadlines and the weakly hard constraints. The objective of review is to find which specification is better in order to predict the behaviour of a task based on those three criteria. Based on our review, it is concluded that the weakly hard constraints outperforms the two conventional specifications of weakly hard real-time systems using that three criteria based on our evaluation by using a mobile robot case study due to its capability to specify in a clear of the distribution of deadlines met and missed...|$|R

