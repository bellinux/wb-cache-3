3|120|Public
40|$|Water {{resource}} managers {{planning for}} the adaptation to future events of extreme precipitation now have access to high resolution downscaled daily projections derived from statistical bias correction and constructed analogs. We also show that along the Pacific Coast the Northern Oscillation Index (NOI) is a reliable predictor of storm likelihood, and therefore a predictor of seasonal precipitation totals and likelihood of extremely intense precipitation. Such time series {{can be used to}} <b>project</b> <b>intensity</b> duration curves into the future or input into stormwater models. However, few climate projection studies have explored the impact of the type of downscaling method used on the range and uncertainty of predictions for local flood protection studies. Here we present a study of the future climate flood risk at NASA Ames Research Center, located in South Bay Area, by comparing the range of predictions in extreme precipitation events calculated from three sets of time series downscaled from CMIP 5 data: 1) the Bias Correction Constructed Analogs method dataset downscaled to a 1 / 8 degree grid (12 km); 2) the Bias Correction Spatial Disaggregation method downscaled to a 1 km grid; 3) a statistical model of extreme daily precipitation events and projected NOI from CMIP 5 models. In addition, predicted years of extreme precipitation are used to estimate the risk of overtopping of the retention pond located on the site through simulations of the EPA SWMM hydrologic model. Preliminary results indicate that the intensity of extreme precipitation events is expected to increase and flood the NASA Ames retention pond. The results from these estimations will assist flood protection managers in planning for infrastructure adaptations...|$|E
40|$|The {{existence}} {{or absence}} of motivation among project members can {{determine whether or not}} a project succeeds or fails. Establishing and maintaining motivation, however, are difficult tasks for project managers. Individuals have different triggers of motivation and it is a complex task to understand the underlying motivational drivers of every member of a project, especially because projects are characterized by constraints of time and resources. Each industry has a specific approach to creating a sense of motivation among its project members and the deciding factor seems to be the different social contexts that each industry provides. Additionally, the social context of each individual project also impacts the motivation of the specific project team members, which creates even more complex managerial requirements. This study aims at distinguishing the primary sources of motivation in projects and among project team members by comparing interview results from project team members and managers in two industries: construction and consulting. The two industries are different in most aspects, but have the important similarity of <b>project</b> <b>intensity</b> and, as a result, the similarities in the two will help in identifying general motivational triggers in projects. Motivation among the project team members and managers interviewed is surprisingly similar for the two different industries in which motivation originates from three main aspects: the role of the project leader, feedback, and the project context. The aspects of understanding individuals and their motivational triggers are vital in project teams, because they {{play an important role in}} the establishment of autonomy, which in turn lays the foundation for development of competence. Competence is a factor that can be distinguished in both industries, but stems from different sources, mastery in construction opposed to learning in consulting. The three main aspects do not affect motivation in isolation; instead, they are interrelated and an increase in one area has the potential of increasing motivation in the other two parts as well...|$|E
40|$|The idea of {{an ideological}} {{potentiality}} for architectural re cycling is obviously anything but unprecedented. All along the 20 th Century art first and then architecture became critically conscious of an attitude of re-using, re-creating, re-manipulating physical and conceptual materials that had been there forever, from the Roman stones to Diocleziano’s Palace in Split, from Duchamp’s Mona Lisa with Moustache to Andy Warhol, from the Superstudio’s proposal to build {{on top of the}} Colosseum to the more recent Palais de Tokyo. What happened in the last years is that this infinite legacy came to react with ecological and social emergencies, creating the conditions for a very interesting phase for architectural research, design, criticism, eventually pushing us to reshape our academic curriculums and programs. All this made in fact clear to all how architecture between {{the end of the second}} millennium and the start of the third has had to learn how to deal with full and void, the existing and the new, urban and anti-urban, and always with the same know-how and the same <b>project</b> <b>intensity,</b> keeping clearly in mind the fact that it is no longer possible to consider these dyads in terms of a pure dialectic opposition. More specifically, the growing mass of buildings of every type, nature and value that end their life cycle on our territories has made clear the inadequacy of the traditional cultures of restoration and reuse before the myriad houses, schools, public buildings, factories, warehouses that in most cases didn't deserve a conservative approach, and that for another thousand reasons weren't and aren't worth demolishing. Hence, what we urgently need is a recycling culture—to Re-cycle—that is as bold and unfaithful as mainstream restoration is attentive and (not always sincerely) faithful to the original, and just as fast, uncanny and indeterminate as the usual approach to "reuse" is pedantic, punctilious and Architecture is a negotiable art, which produces its language via the mediation of three different types of claims: those of a technical nature, those related to its own history and the rules inherent to the discipline, and those of society and its times. When the architect's productive, creative or political obsession decides to identify architecture entirely or prevalently with one of these three claims, it exposes it to the risk of self-referentiality, it undermines its social utility, it dangerously dries up its sources of energy. To us, Re-cycle is a perfect device to credit the relation with society an appropriate role in the design process, i. e. it is a possible and accessible solution to many of the problems of contemporary architecture, obsessed by self-referentiality and technolog...|$|E
50|$|Mellencamp's {{paintings}} from the 1990s—of {{family and friends}} and many of himself—show lone figures isolated frontally against simple, shadowy backgrounds. They stare at the viewer or off into space with eyes both tough and vulnerable, <b>projecting</b> <b>intensity</b> akin to Beckmann's self-portraits with his sad, glowering eyes.|$|R
40|$|Point {{processes}} with stochastic intensities are {{ubiquitous in}} many application areas, including finance, insurance, reliability and queuing. They can be simulated from a standard Poisson process by time-scaling with the cumulative intensity, or compensator. The paths of the compensator are often generated with a discretization method. However, discretization introduces bias into the simulation results. The {{magnitude of the}} bias is difficult to quantify. This paper develops a method for the exact simulation of point processes with stochastic intensities. The method {{is based on a}} change of the filtration that describes the information flow in the point process model. The point process is first projected onto its own filtration, and then sampled based on the <b>projected</b> <b>intensity</b> in that filtration. The <b>projected</b> <b>intensity</b> is deterministic between event times, and this facilitates exact sampling. The method is exemplified for a point process whose intensity is a function of a jump-diffusion process and the point process itself. Filtering arguments lead to the conditional distribution of the driving jump-diffusion given the point process path, and a recursiv...|$|R
25|$|Commodity Exchange Bratislava (CEB) has {{calculated}} {{carbon intensity}} for Voluntary Emissions Reduction <b>projects</b> carbon <b>intensity</b> in 2012 to be 0,343 tn/MWh.|$|R
40|$|Computational ghost imaging (CGI) enables {{an image}} to be {{recorded}} using a single-pixel detector. The image can be reconstructed from correlations between the scene {{and a series of}} known <b>projected</b> <b>intensity</b> patterns. In this work we investigate the performance of CGI using pseudo non-diffracting (ND) speckle patterns. We demonstrate an extended depth-of-field that is ∼ 2 – 3 times greater than that achievable with conventional speckle, when only computing each intensity pattern to a single depth. In addition, the average speckle grain size of ND speckle is reduced by a factor of ∼ 1. 5 relative to conventional speckle, which enhances the lateral Rayleigh-limit resolving power of our reconstructed images. However, the point-spread function (PSF) of our imaging system {{takes the form of a}} Bessel beam, which manifests itself as long-range correlations between speckle grains in the projected patterns. We discuss the trade-off between enhancement of the depth-of-field and the lateral resolution when using ND speckle, at the expense of a reduction in image contrast. Our work demonstrates that the tailoring of lateral and axial correlations in <b>projected</b> <b>intensity</b> patterns permits PSF engineering in CGI...|$|R
40|$|We {{present a}} novel {{concept of a}} {{low-energy}} e{sup +} source with <b>projected</b> <b>intensity</b> {{on the order of}} 10 {sup 10 } slow e{sup +}/s. The key components of this concept are a continuous wave e{sup -} beam, a rotating positron-production target, a synchronized raster/anti-raster, a transport channel, and extraction of e{sup +} into a field-free area through a magnetic plug for moderation in a cryogenic solid. Components were designed in the framework of GEANT 4 -based (G 4 beamline) Monte Carlo simulation and TOSCA magnetic field calculation codes. Experimental data to demonstrate the effectiveness of the magnetic plug is presented...|$|R
40|$|We {{propose a}} {{modified}} {{design of the}} phase contrast filter to optimize the synthetic reference wave (SRW) in the generalized phase contrast method. The modified filter consists of a π-phase shifting disk surrounded by an annular ring to modulate the curvature of the intensity distribution generally associated with the SRW. We identify optimal filter parameters to yield a uniform intensity distribution within the working area. Performance tests where done for both periodic and arbitrary input phase patterns using the optimal filter parameters. Assessment {{of the quality of}} the <b>projected</b> <b>intensity</b> patterns suggests a more uniform intensity distribution at the output when using the modified filter...|$|R
40|$|Scalar {{diffraction}} {{theory is}} combined with beam-propagation techniques to investigate the projection of near-field diffraction patterns to spatial locations away from the aperture for use in optically trapping cold neutral alkali-metal atoms. Calculations show that intensity distributions with localized bright and dark spots usually found within a millimeter of the diffracting aperture can be projected to a region free from optical components such as a cloud of cold atoms within a vacuum chamber. Calculations also predict that the critical properties of the optical dipole atom traps are not only maintained for the <b>projected</b> <b>intensity</b> patterns but also can be manipulated and improved by adjustment of the optical components outside the vacuum chamber...|$|R
40|$|Many {{problems}} in physics like {{reconstruction of the}} radially distributed emissivity from the line-of-sight <b>projected</b> <b>intensity,</b> the 3 -D image reconstruction from cone beam projections in computerized tomography, etc. lead naturally, {{in the case of}} radial symmetry, to the study of Abel’s type integral equation. Obtaining the physically relevant quantity from the measured one requires, therefore the inversion of the Abel’s integral equation. The aim of this letter is to present a user friendly algorithm to invert generalized Abel integral equation by using homotopy perturbation method. The stability of the algorithm is analysed. The validity and applicability of this powerful technique is illustrated through various particular cases which demonstrate its efficiency and simplicity in solving these types of integral equations...|$|R
50|$|Energy intensity: This is {{the total}} primary energy supply (TPES) per unit of GDP (Rogner et al., 2007:107). In all of the {{baseline}} scenarios Fisher et al. (2007) assessed, energy <b>intensity</b> was <b>projected</b> to improve significantly over the 21st century. The uncertainty range in <b>projected</b> energy <b>intensity</b> was large.|$|R
25|$|On {{the other}} hand, K. Ladavac et al. used a spatial light {{modulator}} to <b>project</b> an <b>intensity</b> pattern to enable the optical sorting process. K. Xiao and D. G. Grier applied holographic video microscopy to demonstrate that this technique can sort colloidal spheres with part-per-thousand resolution for size and refractive index.|$|R
40|$|We {{present a}} {{conceptual}} {{design for a}} novel continuous wave electron-linac based high-intensity high-brightness slow-positron production source with a <b>projected</b> <b>intensity</b> {{on the order of}} 10 $^{ 10 }$ e$^+$/s. Reaching this intensity in our design relies on the transport of positrons (T$_+$ below 600 keV) from the electron-positron pair production converter target to a low-radiation and low-temperature area for moderation in a high-efficiency cryogenic rare gas moderator, solid Ne. This design progressed through Monte Carlo optimizations of: electron/positron beam energies and converter target thickness, transport of the e$^+$ beam from the converter to the moderator, extraction of the e$^+$ beam from the magnetic channel, a synchronized raster system, and moderator efficiency calculations. For the extraction of e$^+$ from the magnetic channel, a magnetic field terminator plug prototype has been built and experimental results on the effectiveness of the prototype are presented. The dissipation of the heat away from the converter target and radiation protection measures are also discussed. Comment: 10 pages, 13 figure...|$|R
40|$|The {{mechanical}} properties of phospholipid membranes have been extensively studied {{over the past}} few decades [1]. Their ability to bend under very low stress is one of the main {{mechanical properties}} of such soft materials. This softness is characterized by a very small value of the bending modulus (on the order of 10 kBT). As a result, a flaccid vesicle can attain many thermally allowed shapes at constant volume, which leads the thin-walled vesicles to fluctuate (the so-called flicker phenomenon) [1]. Measurements of these stochastic fluctuations have been used to estimate the bending modulus of red blood cells and artificial vesicles [2, 3, 4]. Here, we re-examine this methodology and discuss some of its limitations; e. g., video-microscopy gives only partial information in the sense that it provides a two-dimensional view of the three-dimensionally fluctuating vesicle. In order to overcome this technical limitation, we develop two new possible methods for inferring mechanical information about membranes from the <b>projected</b> <b>intensity</b> of fluorescent quasi-spherical vesicles...|$|R
40|$|Recently, vision {{research}} has centred on the extraction {{and organization of}} geometric features, and on geometric relations. It is largely assumed that topological structure, that is linked edgel chains and junctions, cannot be extracted reliably from image intensity data. In this paper we demonstrate that this view is overly pessimistic and that visual tasks, such as perceptual grouping, {{can be carried out}} much more efficiently and reliably if well-formed topological structures are available. Towards this end, we describe an edge detection algorithm designed to recover much better scene topology than previously considered possible. In doing this we need make no sacrifice to geometric accuracy of the edge description. 1 Introduction It is generally assumed that the boundaries of objects in intensity images are such that each point on a boundary corresponds to a step discontinuity in the <b>projected</b> <b>intensity.</b> These points, or edgels, 1 are located both where the local intensity surfac [...] ...|$|R
40|$|The {{sources of}} {{magnetic}} fields in recurrent streams were examined. Most fields and plasmas at 1 AU {{were related to}} coronal holes, and the magnetic field lines were open in those holes. Some of the magnetic fields and plasmas were related to open field line regions on the sun which were not associated with known coronal holes, indicating that open field lines are more basic than coronal holes as sources of the solar wind. Magnetic field intensities in five equatorial coronal holes ranged from 2 G to 18 G. Average measured photospheric magnetic fields along the footprints of the corresponding unipolar fields on circular equatorial arcs at 2. 5 solar radii had a similar range and average, but in two cases the intensities were approximately three {{times higher than the}} <b>projected</b> <b>intensities.</b> The coronal footprints of the sector boundaries on the source surface at 2. 5 solar radii, meandered between - 45 deg and + 45 deg latitude, and their inclination ranged from near zero to near ninety degrees...|$|R
40|$|The {{invention}} {{relates to}} a device and {{a method for}} determining spatial coordinates of surfaces of macroscopic objects (1). The proposed device comprises a line projector (6), two line-scan cameras (7), and a control and evaluation unit (8), wherein the control and evaluation unit (8) is designed to perform the following steps: - controlling the line projector (6) such that the line projector projects a series of different intensity distributions (12) within a plane that remains the same for said series, - controlling the line-scan cameras (7) such {{that each of the}} line-scan cameras (7) captures a one-dimensional image for each of said intensity distributions (12), such that a series of measured values is determined for each pixel of an image line (10) of the particular line-scan camera (7), - determining pixels of the two image lines (10) of the two line-scan cameras (7) that correspond to each other by correlating the series of measured values determined by means of the two line-scan cameras (7), and - calculating spatial coordinates for a plurality of points of a line of intersection of the <b>projected</b> <b>intensity</b> distributions (12) with an object surface by triangulation...|$|R
40|$|Weighting {{artifact}} {{counts in}} archaeology has typically followed either a spatial or frequency-based approach. The following paper proposes a Bayesian inferential model using the Poisson distribution to normalize counts of artifacts as a rate, when comparing assemblages from archaeological <b>projects</b> of differing <b>intensities...</b>|$|R
40|$|Results are {{presented}} ofthe first measurements of laser-ablation impulse on structured targets ofthe modified Fabbro type in which impulse coupling coefficients Cm Up to 500 dyne-s/J {{were obtained for}} 85 -ns duration laser pulses by direct measurement with momentum pendula. Our target design generated these Cm values for single-pulse laser fluence of 1. 2 J/cm 2 d peak intensity 14 MW/cm 2, {{an order of magnitude}} below the intensity at which similar coupling has been observed before. This result is important for the ORION demonstration, since it effectively closes a factor-of- 20 deficit between presently available <b>projected</b> <b>intensity</b> at 300 km range and the intensity required for optimum coupling to standard materials. The Nd:glass laser employed in these measurements had 1. O 5 um wavelength and pulse duration from 25 to lOOns. Ambient pressure was less than 10 millitorr. Impulse coupling data on water ice, stone, carbon phenolic, PMMA and other materials were also obtained, for cross-calibration and because of interest in applications to "uncooperative" natural bodies in space. We discuss the significance ofthese results for planning a laser propulsion demonstration in space, as well as possible extensions which could yield appropriate Cm for repetitively-pulsed propulsion of objects into low Earth orbit (LEO) ...|$|R
40|$|We present {{two years}} of {{monitoring}} observations of the extremely variable quasar J 1819 + 3845. We observe large yearly changes in the timescale of the variations (from ~ 1 hour to ~ 10 hours at 5 GHz). This annual effect can only be explained if the variations are caused by a propagation effect, and thus affected by the Earth's relative speed through the <b>projected</b> <b>intensity</b> pattern. To account for this effect, the scattering plasma must have a transverse velocity {{with respect to the}} local standard of rest. The velocity calculated from these observations is in good agreement with that obtained from a two telescope delay experiment (Dennett-Thorpe & de Bruyn 2001). We also show that either the source itself is elongated, or that the scattering plasma is anisotropic, with an axial ratio of > 6 : 1. As the source is extended on scales relevant to the scattering phenomenon, it seems plausible that the anisotropy is due to the source itself, but this remains to be investigated. From the scintillation characteristics we find that the scattering material is a very strong, thin scatterer within ~ten parsecs. We determine a source size at 5 GHz of 100 to 900 microarcsecs, and associated brightness temperatures of 10 ^{ 10 } to 10 ^{ 12 }K. Comment: Accepted for publication in A&...|$|R
40|$|The {{characteristics}} of large-scale tomographic PIV in thick measurement volumes (MVs), which {{are necessary for}} measuring large-scale structures in convective air flows, are discussed. In thick MVs the number of illuminated particles outside the reconstructed volume increases under different circumstances. The complete intensity of these particles needs to be back projected in the volume during the reconstruction process. By conducting numerical simulations {{the influence of the}} back <b>projected</b> <b>intensity</b> of these particles on the measurement accuracy is investigated. Further, in order to make possible processing of large amounts of data a parallel implementation of the tomographic PIV algorithms was developed. In this course an implementation of the simultaneous multiplicative reconstruction algorithm as recently proposed by Atkinson and Soria (Exp Fluids 47 : 553 - 568, 2009) for tomographic PIV is discussed and validated for large-scale tomographic PIV. A strategy of processing these routines on high performance computer clusters is also reviewed. Large-scale tomographic Particle Image Velocimetry (tomographic PIV) using Helium filled soap bubbles as tracer particles has been applied to convective air flow in a long rectangular convection cell. The mean flow fields in forced and mixed convection of air in a convection cell for a Reynolds number of 345, 530 and 800 and for the same Re at a Rayleigh number Ra = 1. 65 * 10 ^ 8, respectively are analyzed...|$|R
40|$|Network-based {{controllers}} such as PLC’s {{and measurement}} stations {{will be used}} in the control system of the JAERI-KEK joint <b>project</b> (High <b>Intensity</b> Proton Accelerator Facility). The ability for the network hardware and software to be standardized has led to this decision. EPICS software support for those controllers has been designed with special attention paid to robustness. This software has been implemented and applied for the accelerator test stand, where the basic functionalities have been confirmed. Miscellaneous functions, such as software diagnostics, will be added at a later date. To enable more manageable controllers, network-based equipment such as oscilloscopes are also being considered. ...|$|R
40|$|There are {{currently}} plans to construct neutrino factories based on muon storage rings. Such projects {{are parts of}} large programmes for the production, cooling, acceleration and storage of muons for dedicated muon colliders, and the lower-energy neutrino factories are perceived {{as a first step}} towards the colliders at a much higher energy. We shall explore possible experiments at the <b>projected</b> high- <b>intensity</b> neutrino beams. Among these experiments the measurement of the nuclear coherent scattering cross section would be based on the use of thermal calorimetric detectors segmented so that self-vetoing would supplement the surrounding veto detectors. (4 refs) ...|$|R
40|$|The paper {{presents}} a time-domain finite-element solver developed for simulations related to solving electromagnetic compatibility issues. The software is applied as a module {{integrated into a}} computational framework developed within a FP 7 European <b>project</b> High <b>Intensity</b> Radiated Field – Synthetic Environment (HIRF SE) able to simulate a large class of problems. In the paper, the mathematical formulation is briefly presented, and special emphasis is put on the user {{point of view on}} the simulation tool-chain. The functionality is demonstrated on the computation of shielding effectiveness of two composite materials. Results are validated through experimental measurements and agreement is confirmed by automatic feature selective algorithms...|$|R
50|$|In {{scientific}} visualization, a {{local maximum}} intensity projection (LMIP) is a volume rendering method for 3D data, that is proposed as an improvement {{to the maximum}} intensity projection (MIP). Where the MIP <b>projects</b> the maximum <b>intensity</b> that falls {{in the way of}} parallel rays traced from the viewpoint, LMIP takes the first local maximum value, that is above a certain threshold.|$|R
50|$|Carbon intensity: This is the CO2 {{emissions}} {{per unit}} of TPES. Compared with other scenarios, Fisher et al. (2007) found that the carbon intensity was more constant in scenarios where no climate policy had been assumed. The uncertainty range in <b>projected</b> carbon <b>intensity</b> was large. At {{the high end of}} the range, some scenarios contained the projection that energy technologies without CO2 emissions would become competitive without climate policy. These projections were based on the assumption of increasing fossil fuel prices and rapid technological progress in carbon-free technologies. Scenarios with a low improvement in carbon intensity coincided with scenarios that had a large fossil fuel base, less resistance to coal consumption, or lower technology development rates for fossil-free technologies.|$|R
50|$|MIPS-concept {{has been}} applied in {{multiple}} research projects, especially in Germany and Finland. The most extensive projects in Finland concerned transport sector and household consumption. FIN-MIPS Transport project studied the Finnish transport system both from passenger and goods transport perspective in 2003-2005 whereas the FIN-MIPS Household <b>project</b> examined material <b>intensity</b> of housing, mobility, foodstuffs, household goods, tourism, leisure and sport activities in Finland and on sample of 27 Finnish households.|$|R
40|$|In {{the control}} system of the JAERI-KEK joint <b>project</b> (High <b>Intensity</b> Proton Accelerator Facility), it is planned to employ network-based {{controllers}} such as PLC’s and measurement stations instead of using other field control networks, since the network hardware and software can be standardized {{and they have been}} successfully utilized in other accelerator control systems in KEK. EPICS software support for those controllers was designed paying special attention to robustness and has been implemented and applied for the accelerator test stand. Basic functionalities were confirmed and miscellaneous functions such as diagnosis of the software itself would be added. Since many kinds of network-based equipment such as oscilloscopes have become available recently, they are considered to be integrated as well. They may enable more manageable controllers. ...|$|R
5000|$|In {{the field}} of biology, {{bright-field}} transmission electron microscopy (BF-TEM) and high-resolution TEM (HRTEM) are the primary imaging methods for tomography tilt series acquisition. However, there are two issues associated with BF-TEM and HRTEM. First, acquiring an interpretable 3-D tomogram requires that the <b>projected</b> image <b>intensities</b> vary monotonically with material thickness. This condition is difficult to guarantee in BF/HRTEM, where image intensities are dominated by phase-contrast {{with the potential for}} multiple contrast reversals with thickness, making it difficult to distinguish voids from high-density inclusions. Second, the contrast transfer function of BF-TEM is essentially a high-pass filter - information at low spatial frequencies is significantly suppressed - resulting in an exaggeration of sharp features. However, the technique of annular dark-field scanning transmission electron microscopy ...|$|R
50|$|The {{methodology}} is {{made available}} by UN Global Compact Cities Programme for its engagement with {{its more than}} 80 Signatory Cities. In particular, some of the 14 Innovating Cities in the programme have influenced {{the development of the}} Circles of Sustainability method through their management of major <b>projects,</b> some with <b>intensity</b> and others as a background feature. They use a cross-sectoral and holistic approach for developing a response to self-defined seemingly intractable problems.|$|R
40|$|The {{purpose of}} this work was to {{evaluate}} and compare the visibility of simulated tumors in 2 D digital mammography (DM) and breast tomosynthesis (BT) images of patients. Images of the same women were acquired on both a DM system (Mammomat Novation, Siemens) and a BT prototype system adapted from {{the same type of}} DM system. Using the geometrical properties of the two systems, simulated, ellipsoid-shaped tumors (average dimension: 8. 4 mm × 6. 6 mm × 5 mm) with irregular margins were projected and added to each DM image as well as each BT projection image prior to 3 D reconstruction. The same beam quality and approximately the same total absorbed dose were used for each breast image acquisition on both systems. Two simulated tumors were added to each of thirty patient scans, yielding sixty cases. A series of 4 -alternative forced choice (4 -AFC) human observer experiments were conducted in order to determine what <b>projected</b> signal <b>intensity</b> (contrast) of the tumors in the DM images would be needed to achieve the same detectability as in the reconstructed BT images. Nine observers participated. For the BT 4 -AFC experiment, when the signal intensity of the tumor on the central projection was 0. 010 (natural logarithmic units) the mean percent of correct responses (PC) was measured to be 81. 5 %, which converted to a detectability index value (d') of 1. 96. For the DM system, the same detectability was achieved at a signal intensity determined to be 0. 038. Equivalent levels of tumor detection in BT images were thus achieved at around four times less <b>projected</b> signal <b>intensity</b> than in DM images, indicating that the use of BT may lead to earlier detection of breast cancer...|$|R
40|$|The {{harmonization}} of profitability {{and social}} responsibility is possible under the adoption and practice conditions by the companies of some adequate business models. “Responsible profitability” must benefit as well of management tools that guide the business sequentially, based on some objective decision making criteria towards sustainable economic behaviors. The simultaneous increase of the specific economic over-value generated by social responsible investment (SRI) <b>project</b> and responsible <b>intensity</b> of economic employment reflects the company’s strong subscription to the authentic sustainable development path...|$|R
40|$|Abstract. In this paper, a novel face {{recognition}} method based on Gabor-wavelet and {{linear discriminant analysis}} (LDA) is proposed. Given training face images, discriminant vectors are computed using LDA. The function of the discriminant vectors is two-fold. First, discriminant vectors are used as a transform matrix, and LDA features are extracted by <b>projecting</b> original <b>intensity</b> images onto discriminant vectors. Second, discriminant vectors are used to select discriminant pixels, the number of which is much {{less than that of}} a whole image. Gabor features are extracted only on these discriminant pixels. Then, applying LDA on the Gabor features, one can obtain the Gabor-LDA features. Finally, a combined classifier is formed based on these two types of LDA features. Experimental results show that the proposed method performs better than traditional approaches in terms of both efficiency and accuracy [...] ...|$|R
5000|$|Despite {{the large}} {{quantities}} of oil available in non-conventional sources, Matthew Simmons argued in 2005 that limitations on production prevent them from becoming an effective substitute for conventional crude oil. Simmons stated [...] "these are high energy <b>intensity</b> <b>projects</b> that can never reach high volumes" [...] to offset significant losses from other sources. Another study claims that even under highly optimistic assumptions, [...] "Canada's oil sands will not prevent peak oil," [...] although production could reach [...] by 2030 in a [...] "crash program" [...] development effort.|$|R
40|$|Anisotropic Diffusion {{is widely}} used for noise {{reduction}} with simultaneous preservation of vascular structures in maximum <b>intensity</b> <b>projected</b> (MIP) angiograms. However, extension to minimum <b>intensity</b> <b>projected</b> (mIP) venograms in Susceptibility Weighted Imaging (SWI) poses difficulties due to spatially varying baseline. Here, we introduce {{a modified version of}} the directional anisotropic diffusion which allows us to simultaneously reduce the noise and enhance vascular structures reconstructed using both M/mIP angiograms. This method is based on spatial adaptation of the diffusion function, separately in the directions of the gradient, and along those of the minimum and maximum curvatures. The existing approach of directional anisotropic diffusion uses binary switched diffusion function to ensure diffusion along the direction of maximum curvature stopped near the vessel borders. Here, the choice of a threshold for detecting the upper limit of diffusion becomes difficult in the presence of spatially varying baseline. Also, the approach of using vesselness measure to steer the diffusion process results in structural discontinuities due to junction suppression in mIP. The merits of the proposed method include elimination of the need for an apriori choice of a threshold to detect the vessel, and problems due to junction suppression. The proposed method is also extended to multi-channel phase contrast angiogram...|$|R
