23|20|Public
5000|$|In {{the absence}} of {{standard}} methods, a range of system based around the use of web bugs have been developed. However, these are often seen as underhand or raising privacy concerns, and only work with email clients that support rendering of HTML. Many mail clients now default to not showing [...] "web content". Webmail providers can also disrupt web bugs by <b>pre-caching</b> images.|$|E
50|$|The {{practice}} of <b>pre-caching</b> supplies of food or equipment along a route, or utilizing external help at any point, also {{results in a}} less than pure, and ultimately less satisfying final outcome. This all said, again as with climbing 'morals' and 'etiquette', each individual or team will eventually find their own 'rules' {{that they will be}} happy with.Assisted manhauling is where at least some fraction of the motive power is provided by some other source: most commonly dog power, or by use of a wind assisted sail.Polar, glacier or snow covered land, is the most common terrain where manhauling takes place; although sledges or tyres are often dragged across sand or rough fields for training purposes.|$|E
30|$|Komninos, A. and M.D. Dunlop, A {{calendar}} based Internet content <b>pre-caching</b> {{agent for}} small computing devices. Personal Ubiquitous Comput., 2008. 12 (7): p. 495 – 512.|$|E
25|$|SuperFetch caches frequently-used {{applications}} and documents in memory, and {{keeps track of}} when commonly used applications are usually loaded, {{so that they can}} be <b>pre-cached</b> and it also prioritizes the programs currently used over background tasks. SuperFetch aims to negate the negative performance effect of having anti-virus or backup software run when the user is not at the computer. Superfetch is able to learn at what time of a given day an application is used and so it can be <b>pre-cached.</b>|$|R
5000|$|Offline Portal - An {{application}} {{that allows the}} user to browse content categories and preview content free of charge through <b>pre-cached</b> content that doesn’t require a WAP connection and creates a mobile environment that blurs offline and online experiences.|$|R
50|$|This is simplified, {{according}} to the IAB. Exchanges may try to unload unsold ("remnant") space at low prices through other exchanges. Some agencies maintain semi-permanent <b>pre-cached</b> bids with ad exchanges, and those may be examined before going out to additional demand side platforms for bids. The process for mobile advertising is different and may involve mobile carriers and handset software manufacturers.|$|R
40|$|We {{described}} in earlier publications {{the principles of}} a system where Internet content would be pre-cached, based on contextual information obtained from a user's electronic calendar. The model for such a system envisioned a set of cooperating agents, distributed on a user's desktop and mobile device, which {{would be responsible for}} making decisions on the context and preferences of the user, and downloading the relevant internet content through a land-based broadband connection and storing it on the mobile device. This paper presents and discusses established <b>pre-caching</b> techniques and their suitability for use on mobile information access scenarios. It proceeds in describing the implementation details of an alternative approach, a calendar-based <b>pre-caching</b> system and presents the findings of tests that were made with human subjects on such a system...|$|E
40|$|Abstract—In this paper, {{we address}} the problem of {{providing}} video-on-demand (VoD) services to numerous clients energy-efficiently. To reduce energy consumption, multiple requests for the same video are batched and served by one single multicast stream. However, this brings additional delay to most clients. Utilizing client <b>pre-caching</b> is an efficient way to eliminate the delay: while the server is batching multiple requests, the clients can play the locally cached prefix of the requested video. The multicast session containing the later part of a video can be delayed till the prefix is played out. Our evaluation demonstrates that with a carefully designed <b>pre-caching</b> scheme, even a small cache (with the size of a video) can reduce 50 % energy consumption. Moreover, we determine the optimal client cache allocation scheme to maximize the utilization of client cache and further minimize the energy consumption. I...|$|E
40|$|Motivated by {{the need}} to access {{internet}} content on mobile devices with expensive or non-existent network access, this paper discusses the possibility for contextual information extracted from electronic calendars to be used as sources for Internet content predictive retrieval (<b>pre-caching).</b> Our results show that calendar based contextual information is useful for this purpose and that calendar based information can produce web queries that are relevant to the users' task supportive information needs...|$|E
5000|$|WorldMap has {{its origins}} in AfricaMap, [...] a website begun in 2007 by art {{historian}} Suzanne Blier with Harvard University Provost funds in Innovative Computing and was developed in 2008 and 2009 by GIS scientists Ben Lewis and Wendy Guan with input from Blier and Sinologist, Peter Bol, the Director of the Center for Geographic Analysis, to make {{a broad range of}} materials on Africa available within an online mapping environment. Lewis, who built the first peer-to-peer GIS system, established with Scott Melby the Geonomy Project from which AfricaMap's innovative technical features in part were based. These include a large searchable place name gazetteer overlaid on Google Maps, using tile services to displaying the many layers simultaneously with transparency control and <b>pre-cached</b> tiles.|$|R
40|$|UrbanWeb {{is a novel}} Web-based {{context-aware}} hypermedia platform. It provides essential {{mechanisms for}} mobile social computing applications: the framework implements context as an extension to Web 2. 0 tagging and provides developers with an easy to use platform for mobile context-aware applications. Services can be statically or dynamically defined in the user’s context, data can be <b>pre-cached</b> for data intensive mobile applications, and shared state supports synchronization between running applications such as games. The paper discusses how UrbanWeb acquires cues about the user’s context from sensors in mobile phones, ranging from GPS data, to 2 D barcodes, and manual entry of context information, {{as well as how}} to utilize this context in applications. The experiences show that the UrbanWeb platform efficiently supports a rich variety of urban computing applications in different scales of user populations...|$|R
2500|$|On December 22, 2005, Valve {{released}} a 64-bit {{version of the}} Source game engine for x86-64 processor-based systems running Windows XP Professional x64 Edition, Windows Server 2003 x64, Windows Vista x64, or Windows Server 2008 x64. This update, delivered via Steam, enabled Half-Life 2 and other Source-based games to run natively on 64-bit processors, bypassing the 32-bit compatibility layer. Gabe Newell, {{one of the founders}} of Valve, stated that this is [...] "an important step in the evolution of our game content and tools", and that the game benefits greatly from the update. The response to the release varied: some users reported huge performance boosts, while technology site Techgage found several stability issues and no notable frame rate improvement. At the time of release, 64-bit users reported bizarre in-game errors including characters dropping dead, game script files not being <b>pre-cached</b> (i.e., loaded when first requested instead), map rules being bent by AI, and other glitches.|$|R
40|$|This paper {{presents}} a study into {{the effectiveness of}} our algorithm for automatic categorisation of real users' diary entries, {{as a first step}} towards personal Internet content <b>pre-caching</b> on mobile devices. The study reports an experiment comparing trial subjects allocations of 99 diary entries to those predicted by a keyword-based algorithm. While leaving considerable grounds for improvement, results are positive and show pave the way for supporting mobile services based on categorising users' diary entries...|$|E
40|$|The recent {{emergence}} of agent prototyping environments for developing Java agents (Aglets, JATlite, JACK, Agent Factory) {{and the availability}} of the J 2 ME (Java 2 Micro Edition) on light devices (PDAs and cellular phones) provides the ability for strong agenthood to be delivered in the mobile and ubiquitous sector. This is an experience paper that discusses the lessons learnt in the construction of agent-based ubiquitous sytems. Within this paper we consider four such systems namely Ad-me, WAY, Gulliver's Genie, and Easishop. They all have been developed at UCD. The common denominator for all prototypes is the use of Lightweight BDI agents and the intelligent <b>pre-caching</b> of content...|$|E
40|$|Current {{projects}} that automate {{the collection of}} provenance information use a centralized architecture for managing the resulting metadata- that is, provenance is gathered at remote hosts and submitted to a central provenance management service. In contrast, we are developing a completely decentralized system with each computer maintaining the authoritative repository of the provenance gathered on it. Our model has several advantages, such as scaling to large amounts of metadata generation, providing low-latency access to provenance metadata about local data, avoiding the need for synchronization with a central service after operating while disconnected from the network, and letting users retain control over their data provenance records. We describe the SPADE project’s support for tracking data provenance in distributed environments, including how queries can be optimized with provenance sketches, <b>pre-caching,</b> and caching...|$|E
40|$|Abstract: The Media Point concept aims to {{facilitate}} the provision of personalized services to mobile users within WLAN hotspots. In this paper we describe our prototypical implementation of a Media Point network. An insight into our performance evaluation using the prototype is given. Our work {{has shown that the}} Media Point system functionalities can already be realized and demonstrated using state-of-the-art technologies. Based on our experience the system performance strongly depends on the level of interworking between the various software modules, e. g., SIP modules, DHCP modules, WLAN device driver, etc. In particular the signalling mechanism within the network by means of SIP doesn’t cause any significant delay. Given that the dwell time of the mobile user within the hotspots is in scope of minutes or longer the overall system performance regarding session setup time of 6. 3 seconds, wherein 39. 03 Mbytes of user data should be <b>pre-cached,</b> and session resume time of 2. 8 seconds is found as acceptable. 1...|$|R
5000|$|On December 22, 2005, Valve {{released}} a 64-bit {{version of the}} Source game engine for x86-64 processor-based systems running Windows XP Professional x64 Edition, Windows Server 2003 x64, Windows Vista x64, or Windows Server 2008 x64. This update, delivered via Steam, enabled Half-Life 2 and other Source-based games to run natively on 64-bit processors, bypassing the 32-bit compatibility layer. Gabe Newell, {{one of the founders}} of Valve, stated that this is [...] "an important step in the evolution of our game content and tools," [...] and that the game benefits greatly from the update. The response to the release varied: some users reported huge performance boosts, while technology site Techgage found several stability issues and no notable frame rate improvement. At the time of release, 64-bit users reported bizarre in-game errors including characters dropping dead, game script files not being <b>pre-cached</b> (i.e., loaded when first requested instead), map rules being bent by AI, and other glitches.|$|R
40|$|Caching popular {{contents}} is {{a promising}} way to offload the mobile data traffic in wireless networks, {{but so far}} the potential advantage of caching in improving physical layer security (PLS) is rarely considered. In this paper, we contribute to the design and theoretical understanding of exploiting the caching ability of users to improve the PLS in a wireless heterogeneous network (HetNet). In such network, the base station (BS) ensures the secrecy of communication by utilizing some of the available power to transmit a <b>pre-cached</b> file, such that only the eavesdropper's channel is degraded. Accordingly, the node locations of BSs, users and eavesdroppers are first modeled as mutually independent poisson point processes (PPPs) and the corresponding file access protocol is developed. We then derive analytical expressions of two metrics, average secrecy rate and secrecy coverage probability, for the proposed system. Numerical results are provided to show the significant security advantages of the proposed network and to characterize the impact of network resource on the secrecy metrics. Comment: submitted to IEEE ICC 201...|$|R
40|$|Detecting {{the most}} {{probable}} {it next} page a user {{is bound to}} visit inside a website has important practical consequences: it allows to suggest recommendations to the visitors as to {{which may be the}} pages of interest to them in a complex website; it is of help for website designers for deciding how to organize the site contents and it is also useful for <b>pre-caching</b> voluminous objects that the user will very probably need. In sum, it helps to customize web contents. In order to achieve that goal a classification, prediction an evaluation cycle has to be performed. Among the several possible alternative technologies we discuss a real use of Bayesian Network representations. The obtained results are commented, compared to other approaches and its applicability to other domains is also discussed. Postprint (published version...|$|E
40|$|Since {{the boom}} of the smart phones, {{there is a huge}} amount of {{applications}}that deal with data located in the cloud. This fact can makethese applications unavailable when the network is inaccessible due tocoverage or congestion. A solution to these problems have been designedand developed for the Android OS in this master thesis. The approachis the application of location-based <b>pre-caching,</b> downloading the contentof an application before the user enters in the zone where the applicationmay use this content. Network coding has also been introduced in orderto reduce the amount of data sent over the wireless networks. A cachingscheme is introduced in binary network coding and applied to the problemof retransmission in wireless broadcast network. A binary network codingalgorithm is designed which could asymptotically approach the efficiency of linear network coding with a much lower decoding complexity. ...|$|E
40|$|Abstract—Web caching and pre-fetching {{are vital}} {{technologies}} that {{can increase the}} speed of Web loading processes. Since speed and memory are crucial aspects in enhancing the performance of mobile applications and websites, a better technique for Web loading process should be investigated. The weaknesses of the conventional Web caching policy include meaningless information and uncertainty of knowledge representation in Web logs data from the proxy cache to mobile-client. The organisation and learning task of the knowledge-processing for Web logs data require explicit representation to deal with uncertainties. This {{is due to the}} exponential growth of rules for finding a suitable knowledge representation from the proxy cache to the mobileclient. Consequently, Rough Set is chosen in this research to generate Web <b>pre-caching</b> decision rules to ensure the meaningless Web log data can be changed to meaningful information. Keywords-component; decision rules; rough set; web caching; web pre-fetching; web log data I...|$|E
40|$|Figure 1. Scrubbing {{behavior}} of a traditional streaming video player, the Swift interface [16], and our new Swifter interface, which shows multiple frames around the active timeline location and allows for direct selection of each frame. Online streaming video systems have become extremely popular, yet navigating to target scenes of interest can be a challenge. While recent techniques have been introduced to enable real-time seeking, they break down for large videos, where scrubbing the timeline causes video frames to skip and flash too quickly to be comprehendible. We present Swifter, a new video scrubbing technique that displays a grid of <b>pre-cached</b> thumbnails during scrubbing actions. In a series of studies, we first investigate possible design variations of the Swifter technique, {{and the impact of}} those variations on its performance. Guided by these results we compare an implementation of Swifter to the previously published Swift technique, in addition to the approaches utilized by YouTube and Netfilx. Our results show that Swifter significantly outperforms each of these techniques in a scene locating task, by a factor of up to 48 %...|$|R
40|$|The {{distributed}} NDGF Tier- 1 {{and associated}} Nordugrid clusters are well {{integrated into the}} ATLAS computing model but follow a slightly different paradigm than other ATLAS resources. The current strategy does not divide the sites as in the commonly used hierarchical model, but rather treats them as a single storage endpoint and a pool of distributed computing nodes. The next generation ARC middleware with its several new technologies provides new possibilities in development of the ATLAS computing model, such as pilot jobs with <b>pre-cached</b> input files, automatic job migration between the sites, integration of remote sites without connected storage elements, and automatic brokering for jobs with non-standard resource requirements. ARC's data transfer model provides an automatic way for the computing sites to participate in ATLAS' global task management system without requiring centralised brokering or data transfer services. The powerful API combined with Python and Java bindings can easily be used to build new services for job control and data transfer. Integration of the ARC core into the EMI middleware provides a natural way to implement the new services using the ARC component...|$|R
40|$|In this thesis, {{we present}} a new algorithm: Demand Sensitive Map Abstraction (DSMA). DSMA is {{a special kind of}} {{hierarchical}} pathfinding algorithm in which we vary the granularity of abstraction of the high-level map based on pathfinding request demand associated with various regions in the high level map and the search time of the last path request. Additionally, the low level A* search is not restricted by the boundaries of the high level sectors. By dynamically varying the abstraction we are able to maintain a balance between path quality and search time. We compare DSMA with two variations where the granularity of abstraction is constant; one of those contains maximum granularity throughout (Dense HA*) and the other contains the minimum (Sparse HA*). Our experimental results show that DSMA 2 ̆ 7 s performance is a balance between Dense HA* and Sparse HA*. Depending on the resources available DSMA can behave either as Dense HA* or as Sparse HA* or lie somewhere in between. Moreover we do not pre-cache paths at any level, which gives us the added benefit of working with a flexible abstract map without the necessity of changing the <b>pre-cached</b> paths if the low level map changes...|$|R
40|$|Cellular {{networks}} {{have become an}} essential part of our lives. With increasing demands on its available bandwidth, we are seeing failures and performance degradations for data and voice traffic on the rise. In this paper, we propose the view that fog computing, integrated in the edge components of cellular networks, can partially alleviate this situation. In our vision, some data gathering and data analytics capability will be developed {{at the edge of the}} cellular network and client devices and the network using this edge capability will coordinate to reduce failures and performance degradations. We also envisage proactive management of disruptions including prediction of impending events of interest (such as, congestion or call drop) and deployment of appropriate mitigation actions. We show that a simple streaming media <b>pre-caching</b> service built using such device-fog cooperation significantly expands the number of streaming video users that can be supported in a nominal cellular network of today...|$|E
40|$|We {{develop a}} {{spectral}} method for solving univariate singular integral equations over unions of intervals by utilizing Chebyshev and ultraspherical polynomials to reformulate the equations as almost-banded infinite-dimensional systems. This {{is accomplished by}} utilizing low rank approximations for sparse representations of the bivariate kernels. The resulting system can be solved in O(m^ 2 n) operations using an adaptive QR factorization, where m is the bandwidth and n is the optimal number of unknowns needed to resolve the true solution. The complexity is reduced to O(m n) operations by <b>pre-caching</b> the QR factorization when the same operator is used for multiple right-hand sides. Stability is proved by showing that the resulting linear operator can be diagonally preconditioned to be a compact perturbation of the identity. Applications considered include the Faraday cage, and acoustic scattering for the Helmholtz and gravity Helmholtz equations, including spectrally accurate numerical evaluation of the far- and near-field solution. The Julia software package SingularIntegralEquations. jl implements our method with a convenient, user-friendly interface...|$|E
40|$|Title: Efficient {{visibility}} calculation {{for light}} transport simulation in participating media Author: Čestmír Houška Department / Institute: Department of Software and Computer Science Educa- tion Supervisor {{of the master}} thesis: doc. Ing. Jaroslav Křivánek, Ph. D. Abstract: This thesis investigates the use of acceleration methods for the testing of visibility in light transport calculation algorithms {{with the emphasis on}} conser- vativeness and low accelerated query overhead. Several published non-directional and directional distance field methods are presented with the description of their characteristic properties. Two of these methods are then implemented and thor- oughly tested in an existing rendering framework on a path tracing volumetric integrator as well as on an own implementation of a ray marching single scattering integrator. A method that further accelerates the original distance field methods by <b>pre-caching</b> results of some of the queries is also proposed, implemented and tested. Furthermore, several possible extensions to this method are outlined. Keywords: computer graphics, rendering, participating media, visibilit...|$|E
40|$|POSTSCRIPT is a page {{description}} language {{which is used}} to transmit printing information from a host computer (i. e. Apple Macintosh) to a printer (i. e. Apple LaserWriter Plus). It has the ability to describe pages consisting of text, vector graphics, and scanned bit-map images. Printing text is the area of concentration for this thesis. Specifically several variables that affect the printing speed of a common POSTSCRIPT printer, the Apple LaserWriter Plus, are looked at when printing text in a variety of fonts, sizes, and orientations. The variables that affect printer performance include: - use of outline vs. bit-map fonts; - the outline font rasterization process; - the use of <b>pre-cached</b> bit-map fonts; - background outline font rasterization; - arbitrary scaling and rotation; - downloading host-resident fonts; - Adobe and Third Party host-resident downloadable fonts vs. printer-resident fonts; - Appletalk vs. RS- 232 communications interfaces; - use of the POSTSCRIPT show, ashow, and widthshow instructions; - targeting the POSTSCRIPT instructions at a particular engine resolution; - print engine overhead A sequence of POSTSCRIPT files were transmitted to the Apple LaserWriter Plus printer. The experiments were carefully constructed to exercize each of the variables listed above. Performance measurements were carefully recorded and analyzed. Where applicable, improvements were proposed to improve printer performance...|$|R
40|$|In this paper, {{we present}} a new {{automatic}} shader simplification method using surface signal approximation. We regard the entire multi-stage rendering as a process that generates signals on sur-face, and formulate the simplification of the fragment shader as a global simplification problem across multi-shader stages. Three new shader simplification rules are proposed to solve the problem. First, the code transformation rule transforms fragment shader code to other shader stages in order to redistribute computations on pix-els up to on geometry primitives. Second, the surface-wise approx-imation rule uses high-order polynomial basis functions to approx-imate pixel-wise computations in the fragment shader on surfaces. These approximations are <b>pre-cached</b> and simplify computations at runtime. Third, the surface subdivision rule tessellates surfaces into smaller patches. It combines with previous two rules to ap-proximate pixel-wise signals on different tessellations with differ-ent computation times and visual errors. To evaluate simplified shaders with regard to these simplification rules, we introduce a new cost model including the visual quality, the rendering time and the memory consumption. With these simplification rules and the cost model, {{we present a}}n integrated shader simplification algo-rithm {{that is capable of}} automatically generating variants of simpli-fied shaders and selecting a sequence of preferable shaders. Results show that the sequence of selected simplified shaders well balance the performance, the accuracy and the memory consumption...|$|R
40|$|As the {{capacity}} demand of mobile applications keeps increasing, the backhaul network {{is becoming a}} bottleneck to support high quality of experience (QoE) in next-generation wireless networks. Content caching at base stations (BSs) is a promising approach to alleviate the backhaul burden and reduce user-perceived latency. In this paper, we consider a wireless caching network where all the BSs are connected to a central controller via backhaul links. In such a network, users can obtain the required data from candidate BSs if the data are <b>pre-cached.</b> Otherwise, the user data need to be first retrieved from the central controller to local BSs, which introduces extra delay over the backhaul. In {{order to reduce the}} download delay, the caching placement strategy needs to be optimized. We formulate such a design problem as the minimization of the average download delay over user requests, subject to the caching capacity constraint of each BS. Different from existing works, our model takes BS cooperation in the radio access into consideration and is fully aware of the propagation delay on the backhaul links. The design problem is a mixed integer programming problem and is highly complicated, and thus we relax the problem and propose a low-complexity algorithm. Simulation results will show that the proposed algorithm can effectively determine the near-optimal caching placement and provide significant performance gains over conventional caching placement strategies. Comment: 6 pages, 3 figures, accepted to IEEE Globecom, San Diego, CA, Dec. 201...|$|R
40|$|The {{adaptive}} applications framework {{presented here}} aims at enabling hosts {{in a network}} to share objects such as applications or data. The framework consists {{of a set of}} components needed at each host in the network. They are the repository, the monitor, and the mobile agents. The repository acts as a database for storage of objects and object semantics. An adaptive application, which itself is an object, first tries to access an object from the local repository. If it is not found, the search is extended to the repositories of co-operating hosts by the use of mobile agents. An object or a proxy object is returned to the requester. The application can be executed on the local host or on the remote host depending on predefined network and host load conditions. The framework that has been prototyped will form a base for further work, which includes exploring the use of semantic modelling for <b>pre-caching</b> and intelligent download of resources. Godkänd; 2000; 20060921 (ysko...|$|E
40|$|Abstract — This paper {{studies the}} {{conditions}} under which P 2 P sharing can increase the capacity of IPTV services over FTTN networks. For a typical FTTN network, our study shows a) P 2 P sharing is not beneficial when the total traffic in a local video office is low; b) P 2 P sharing increases the load on FTTN switches and routers in local video offices; c) P 2 P sharing is the most beneficial when the network bottleneck is experienced in the southbound segment of a local video office (equivalently a northbound segment of an FTTN switch); and d) sharing among all FTTN serving communities is not needed when network congestion problems are solved by using some other technologies such as program <b>pre-caching</b> or replication. Based on the analytical results, we design and implement the MediaGrid platform for IPTV services which monitors FTTN network conditions and decides when and how to share videos among peers to maximize the service capacity. Simulations and bounds both validate the potential benefits of the MediaGrid IPTV service platform...|$|E
40|$|International audienceIn {{order to}} achieve the {{autonomy}} of mobile robots, effective localization is a necessary prerequisite. In this paper, we propose an improved Monte Carlo localization algorithm using self-adaptive samples, abbreviated as SAMCL. By employing a <b>pre-caching</b> technique to reduce the on-line computational burden, SAMCL is more efficient than regular MCL. Further, we define the concept of similar energy region (SER), which {{is a set of}} poses (grid cells) having similar energy with the robot in the robot space. By distributing global samples in SER instead of distributing randomly in the map, SAMCL obtains a better performance in localization. Position tracking, global localization and the kidnapped robot problem are the three sub-problems of the localization problem. Most localization approaches focus on solving one of these sub-problems. However, SAMCL solves all these three sub-problems together thanks to self-adaptive samples that can automatically separate themselves into a global sample set and a local sample set according to needs. The validity and the efficiency of the SAMCL algorithm are demonstrated by bothsimulations and experiments carried out with different intentions. Extensive experiment results and comparisons are also given int his paper...|$|E
40|$|In this work, we {{investigate}} the profit maximization {{problem for a}} wireless network carrier and the payment minimization for end-users. Motivated by recent findings on proactive resource allocation, {{we focus on the}} scenario whereby end-users who are equipped with device-to-device (D 2 D) communication can harness predictable demand in proactive data contents caching and the possibility of trading their proactive downloads to minimize their expected payments. The carrier, on the other hand, utilizes a dynamic pricing scheme to differentiate between off-peak and peak time prices and applies commissions on each trading process to further maximize its profit. A novel marketplace that is based on risk sharing between end-users is proposed where the tension between carrier and end-users is formulated as a Stackelberg game. The existence and uniqueness of the non-cooperative sub-game Nash equilibrium is shown. Furthermore, we explore the equilibrium points for the case when the D 2 D is available and when it is not available, and study the impact of the uncertainty of users future demands on the system's performance. In particular, we compare the new equilibrium with the baseline scenario of flat pricing. Despite end-users connectivity with each other, the uncertainty of their future demands, and the freshness of the <b>pre-cached</b> contents, we characterize a new equilibrium region which yields to a win-win situation with respect to the baseline equilibrium. We show that end-users activity patterns can be harnessed to maximize the carrier's profit while minimizing the end-users expected payments. Comment: 31 page...|$|R
40|$|We {{consider}} a wireless device-to-device (D 2 D) network where the nodes have <b>pre-cached</b> {{information from a}} library of available files. Nodes request files at random. If the requested file {{is not in the}} on-board cache, then it is downloaded from some neighboring node via direct “local ” communication, without going through the base station. An outage event occurs when a requested file is not found in the neighborhood of the requesting node, or if the network scheduling policy decides not to serve the request. Motivated by the current trend in the standardization of the D 2 D mode for LTE wireless networks, we restrict to one-hop D 2 D communication. We {{consider a}} simple “protocol model ” for the network and define the optimal throughput-outage tradeoff. We characterize such tradeoff in terms of tight scaling laws for various regimes, where both the number of nodes and the number of files in the library grow to infinity. Then, we also provide some numerical results based on a realistic scenario of user density, cache size, file library size and propagation channel models, and compare the throughput-outage performance of the D 2 D one-hop caching network with the corresponding performance of other solutions based downlink (one-hop) transmission from the base station only. Our results show that the combination of D 2 D spectrum reuse and caching at the user nodes yields very significant gains with respect to both the current cellular technology and the recently proposed “coded multicasting ” approach, inspired by index coding. Index Terms Throughput-outage tradeoff, scaling laws, caching wireless networks, device-to-device communica-tions...|$|R
40|$|We {{consider}} a wireless Device-to-Device (D 2 D) network where communication {{is restricted to}} be single-hop. Users make arbitrary requests from a finite library of files and have <b>pre-cached</b> information on their devices, subject to a per-node storage capacity constraint. A similar problem has already been considered in an ``infrastructure'' setting, where all users receive a common multicast (coded) message from a single omniscient server (e. g., a base station having all the files in the library) through a shared bottleneck link. In this work, we {{consider a}} D 2 D ``infrastructure-less'' version of the problem. We propose a caching strategy based on deterministic assignment of subpackets of the library files, and a coded delivery strategy where the users send linearly coded messages {{to each other in}} order to collectively satisfy their demands. We also consider a random caching strategy, which is more suitable to a fully decentralized implementation. Under certain conditions, both approaches can achieve the information theoretic outer bound within a constant multiplicative factor. In our previous work, we showed that a caching D 2 D wireless network with one-hop communication, random caching, and uncoded delivery, achieves the same throughput scaling law of the infrastructure-based coded multicasting scheme, in the regime of large number of users and files in the library. This shows that the spatial reuse gain of the D 2 D network is order-equivalent to the coded multicasting gain of single base station transmission. It is therefore natural to ask whether these two gains are cumulative, i. e.,if a D 2 D network with both local communication (spatial reuse) and coded multicasting can provide an improved scaling law. Somewhat counterintuitively, we show that these gains do not cumulate (in terms of throughput scaling law). Comment: 45 pages, 5 figures, Submitted to IEEE Transactions on Information Theory, This is the extended version of the conference (ITW) paper arXiv: 1304. 585...|$|R
