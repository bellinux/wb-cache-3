5|59|Public
50|$|After his {{own success}} in {{motorcycle}} trials {{in the early}} 1930s, Baughan began to make a range of trial-optimised motorcycles until 1936. Although a <b>production</b> <b>template</b> existed, each machine was a bespoke per-customer fitment. Powered again using either Blackburne or mainly JAP V-twins, {{ranging in size from}} 250 to 500 cc, each used qd real-wheel. Production {{is believed to have been}} small.|$|E
50|$|But Billboard, {{gave the}} song a very {{positive}} review, by saying that 'Surgeon' finds the young siren operating {{under the guise of}} a sexual braggart on a song that sounds like it may have been modeled after the late Aaliyah's more ambitious album tracks. Tricky Stewart creates a tense <b>production</b> <b>template</b> for the singer to explore a darker, sexier side than listeners may be used to hearing from her. Plodding synth lines, an unusual bassline and a stop-and-go rhythm add up to one of Ciara's most interesting singles to date".|$|E
40|$|Since {{the seminal}} {{contribution}} by Shewhart, the dominating approach to production is to minimize all variation {{in order to}} get the productive activities into control. Thus, the goal is to avoid all such complexity and uncertainty which could disturb this tight control. This approach is applied in lean production, which is considered to be the superior <b>production</b> <b>template</b> of today. It has to be noted that usually our concepts, for example “waste”, are based on this understanding of production. However, there are production situations with inherent complexity and unpredictability not least in project production. The primary goal of the paper is to chart and analyze the different approaches available for coping with these situations. Four different strategies are identified and discussed: reducing complexity, codifying procedures, learning to improvise and buffering. A secondary goal of the paper is to discuss whether and how the conceptual framework in production management should be further developed for taking these different approaches to project complexity into account...|$|E
50|$|Apple {{also made}} changes to ease of use. These include the {{discontinuation}} of the XSKey dongle, and a streamlined interface. Each plug-in {{used in the}} channel strip opens in a new window when double-clicked. Many of the features found in Logic 7 have been consolidated into one screen. Other additions to the new interface included consolidated arrange windows, dual channel strips, built in browsers (like that in GarageBand) and <b>production</b> <b>templates.</b>|$|R
50|$|To enable {{students}} to acquire the knowledge, skills and attitudes for <b>production</b> of <b>templates</b> and assembly of wooden furniture. Students learn about sculptured wood, veneering, marquerty and furniture composed of panels and composites. Students learn ornamental woodwork and staircases, installation of manufactured component, repair and restoration of furniture.|$|R
40|$|The {{demand for}} more {{cost-effective}} field developments {{have led to a}} substantial focus on separation equipment that reduces weight and deck space. Of particular concern are field developments with subsea <b>production</b> <b>templates</b> and multiphase transportation to existing field installations. Additionally, environmental aspects concerning the use of large amounts of chemical demulsifiers are crucial these days. This paper presents a new compact electrostatic coalescer (CEC) that has the capability to reduce both weight and size, and to eliminate the use of chemical demulsifiers in some cases. The basic principle of performance of the laboratory version of the CEC is discussed with respect to emulsion properties, flow rate, applied voltage, and residence time in the electric field. Performance is quantified using both a laser particle and droplet size analyser and a Hamamatsu image analysis system. Some results from a prototype test on live crude are also given...|$|R
40|$|An {{explanation}} for the low innovation activity in const¡uction is put forward. The central argument is that the cur¡ent theory of construction is one root cause for low innovation activity. Instead, an explicit and more powerful theory of construction is needed for further imovation, which is 'to manage new ideas into good currency'. There are three main mechanisms in the current tbeory of construction which are identified as causing this hindrance. Firstly, production theories in general, as well as construction theories specifically, have been implicit. Therefore, {{it has not been}} possible ro transfel radical managerial innovations, such as lean production, from manufacturing to construction at a theoretical level. Direct application of this <b>production</b> <b>template</b> to construction has been limited due to the different context of construcrion in comparison with manufacturing. Secondly, the current theoretical model of construction is based on the transformation model of production. It is argued that the principles of this model are counterproductive, because uncertainty and interdependence are abstracted away. This leads to fragmented and myopic mânagement and inflated variability. practical examples show that these deficiencies and related practical constraints hinder rhe implementation of top-down innovations. Thirdly, empirical research shows that âlso bottom-up innovations - systematic learning and problem solving - are being hindered by the current theory. Thus, the advancement of innovations in construction requires that a new, explicit and valid theory of construction is created, and business models and control methods are developed on the basis of that new theor...|$|E
40|$|Oil and gas {{exploration}} on the Norwegian Continental Shelf {{has been}} going on since the 1960. Many smaller oil fields have been found and at that stage they have not been developed, because alone they have not been economically recoverable with the technology of that day. The Gullfaks field started to produce in 1986 and when the subsea concept was developed, the nearby oilfield Gullfaks South was developed as a subsea solution in 1998, tied-in to the Gullfaks A platform. Low production rates and newer 4 -D seismic surveys of the Gullfaks South field showed that the recoverable oil from this field was only 8 %. This was the key driver for the new development, the GSO, Gullfaks South Oil. The GSO project shall increase the recovery rate by developing the field with 2 new subsea templates that includes four production wells and two gas injection wells. The Gullfaks Oil field is already developed with six templates including flowlines that have been producing since 1998. Some of the existing infrastructure shall be re-used due to the existing templates are at their end of production lifetime. Lack of spare J-tubes for new risers on the Gullfaks A supports the decision of re-using existing infrastructure. The <b>production</b> <b>template,</b> the O-template, shall be tied-in to existing flowlines. By re-using these flowlines the cost of the development will be reduced, but limitations will be given due to fixed diameters on the flowlines. The O-template shall have one 8 ” and one 6 ” flowline, these are within the design criteria of material stresses based on the reservoir properties and ambient environmental properties. Arrival pressures on the platform, from the template are within the limitations of the process pressure at 56 bars for the 8 ” throughout the whole production lifetime. The 6 ” shall co-produce with other wells, this is only analysed to this point where they start to co-produce. The injection template, the P-template will have an extended flowline from another injection template, this will provide necessary reservoir stimulation for the GSO. The production flowlines, the 6 ” and 8 ” are analysed for flow assurance challenges. Flow assurance is a very important design requirement for subsea flowlines. It is important to understand how and why they occur to be able to mitigate them. It is essential to keep good flow assurance for a subsea development, and necessary to understand how to both avoid them and to get out off flow assurance challenges in a safe matter. The challenges found are manageable with the chosen measures. The analyses are done with the basis in the production profile and the ambient surroundings. The 6 ” and 8 ” flowlines are not redundant, but a supplement to each other during the whole production lifetime. The 6 ” is suitable in {{the beginning and end of}} the production life, the 8 ” is the best option in the middle part of the production lifetime. The GSO development is a sensible development to increase the recovery rate at the Gullfaks South oil field...|$|E
30|$|Loss of {{position}} of the dynamically positioned rig without safe disconnection could result in critical damage to the well barrier, {{as well as to}} exposed subsea equipment. The ultimate consequence could be a blowout and/or severe damage to subsea production systems like <b>production</b> <b>templates,</b> resulting in risk to personnel, environmental damage, financial loss and harm to the reputation of the company (Paula and Fonseca 2013). Currently, all dynamically positioned rigs are equipped with an emergency disconnect button which initiates a pre-programmed sequence of functions designed to secure the well in a minimal amount of time prior to disconnecting the LMRP riser connector (Sattler and Lewis 2004). An emergency disconnect sequence (EDS) is a sequence of actions, events and interlocks that are automatically initiated once the EDS button is pressed on any BOP panel in the rig. These actions will activate the mechanism or equipment responsible for disconnecting the rig from the well (Paula and Fonseca 2013).|$|R
40|$|The top-quark mass M_top is {{measured}} using top quark-antiquark pairs produced in proton-antiproton collisions at a center-of-mass energy of 1. 96 TeV and decaying into a fully hadronic final state. The full data set collected with the CDFII detector at the Fermilab Tevatron Collider, corresponding to an integrated luminosity of 9. 3 fb- 1, is used. Events are selected that have {{six to eight}} jets, {{at least one of}} which is identified as having originated from a b quark. In addition, a multivariate algorithm, containing multiple kinematic variables as inputs, is used to discriminate signal events from background events due to QCD multijet <b>production.</b> <b>Templates</b> for the reconstructed top-quark mass are combined in a likelihood fit to measure M_top with a simultaneous calibration of the jet-energy scale. A value of M_top = 175. 07 +- 1. 19 (stat) + 1. 55 - 1. 58 (syst) GeV/c^ 2 is obtained for the top-quark mass. Comment: Minor modifications to the text based on the feedback from the journal refere...|$|R
40|$|The top-quark mass Mtop is {{measured}} using top quark-antiquark pairs produced in proton-antiproton collisions at a center-of-mass energy of 1. 96  TeV and that decay into a fully hadronic final state. The full data set collected with the CDF II detector at the Fermilab Tevatron Collider, corresponding to an integrated luminosity of 9. 3 [*][*]fb− 1, is used. Events are selected that have {{six to eight}} jets, {{at least one of}} which is identified as having originated from a b quark. In addition, a multivariate algorithm, containing multiple kinematic variables as inputs, is used to discriminate signal events from background events due to QCD multijet <b>production.</b> <b>Templates</b> for the reconstructed top-quark mass are combined in a likelihood fit to measure Mtop with a simultaneous calibration of the jet energy scale. A value of Mtop= 175. 07 ± 1. 19 (stat) [*]+ 1. 55 − 1. 58 (syst) [*][*]GeV/c 2 is obtained for the top-quark mass...|$|R
40|$|The top-quark mass M[subscript top] is {{measured}} using top quark-antiquark pairs produced in proton-antiproton collisions at a center-of-mass energy of 1. 96  TeV and that decay into a fully hadronic final state. The full data set collected with the CDF II detector at the Fermilab Tevatron Collider, corresponding to an integrated luminosity of 9. 3 [*][*]fb[superscript - 1], is used. Events are selected that have {{six to eight}} jets, {{at least one of}} which is identified as having originated from a b quark. In addition, a multivariate algorithm, containing multiple kinematic variables as inputs, is used to discriminate signal events from background events due to QCD multijet <b>production.</b> <b>Templates</b> for the reconstructed top-quark mass are combined in a likelihood fit to measure M[subscript top] with a simultaneous calibration of the jet energy scale. A value of M[subscript top] = 175. 07 ± 1. 19 (stat) [*] [+ 1. 55 over - 1. 58](syst) [*][*]GeV/c[superscript 2] is obtained for the top-quark mass. United States. Dept. of EnergyNational Science Foundation (U. S.) Alfred P. Sloan Foundatio...|$|R
40|$|Housing in the UK {{accounts}} for 30. 5 % of all energy consumed and {{is responsible for}} 25 % of all carbon emissions. The UK Government’s Code for Sustainable Homes requires all new homes to be zero carbon by 2016. The development and widespread diffusion of low and zero carbon (LZC) technologies is recognised as being a key solution for housing developers to deliver against this zero-carbon agenda. The innovation challenge to design and incorporate these technologies into housing developers’ standard design and <b>production</b> <b>templates</b> will usher in significant technical and commercial risks. In this paper we report early results from an ongoing Engineering and Physical Sciences Research Council project looking at the innovation logic and trajectory of LZC technologies in new housing. The principal theoretical lens for the research is the socio-technical network approach which considers actors’ interests and interpretative flexibilities of technologies and how they negotiate and reproduce ‘acting spaces’ to shape, in this case, the selection and adoption of LZC technologies. The initial findings are revealing the form and operation of the technology networks around new housing developments as being very complex, involving a range of actors and viewpoints that vary for each housing development...|$|R
40|$|The Code for Sustainable Homes (the Code) {{will require}} new {{homes in the}} United Kingdom to be ‘zero carbon’ from 2016. Drawing upon an {{evolutionary}} innovation perspective, this paper contributes to {{a gap in the}} literature by investigating which low and zero carbon technologies are actually being used by house builders, rather than the prevailing emphasis on the potentiality of these technologies. Using the results from a questionnaire three empirical contributions are made. First, house builders are selecting a narrow range of technologies. Second, these choices are made to minimise the disruption to their standard design and <b>production</b> <b>templates</b> (SDPTs). Finally, the coalescence around a small group of technologies is expected to intensify with solar-based technologies predicted to become more important. This paper challenges the dominant technical rationality in the literature that technical efficiency and cost benefits are the primary drivers for technology selection. These drivers play an important role but one which is mediated by the logic of maintaining the SDPTs of the house builders. This emphasises the need for construction diffusion of innovation theory to be problematized and developed within the context of business and market regimes constrained and reproduced by resilient technological trajectories...|$|R
5000|$|In the {{equation}} above, xi is {{the concentration of}} template Ii; x is the total concentration of all templates; ki is the excess <b>production</b> rate of <b>template</b> Ii, which {{is a difference between}} formation fi by self-replication of the template and its degradation di, usually by hydrolysis; ki,j is the <b>production</b> rate of <b>template</b> Ii catalysed by Ij; and &phi; is a dilution flux; which guarantees that the total concentration is constant. Production and degradation rates are expressed in numbers of molecules per time unit at unit concentration (xi = 1). Assuming that at high concentration x the term ki can be neglected, and, moreover, in the hypercycle, a template can be replicated only by itself and the previous member of the cycle, {{the equation}} can be simplified to: ...|$|R
40|$|The {{measurement}} by the ATLAS {{collaboration of}} Higgs boson properties is presented, {{in terms of}} <b>production</b> cross-sections, simplified <b>template</b> cross-sections, couplings. The measurements {{are based on the}} analysis of the H decay channels to diphoton and 4 leptons, using 36. 1 fb- 1 of 13 TeV data recorded in 2015 and 2016...|$|R
40|$|A {{number of}} {{different}} procedures {{have been developed for}} direct sequence analysis of PCR products. These methods rely on the cumbersome isolation of specific PCR products from agarose gels or the <b>production</b> of single-stranded <b>template</b> DNAs. In the approach presented here, we describe primers for the amplification of 16 -S rDNA and a simple preparation of PCR product for sequencing...|$|R
40|$|It {{is argued}} that {{construction}} innovation is significantly hindered by the prevalent theory of construction, which is implicit and deficient. There are three main mechanisms through which this hindrance is being caused. Firstly, because production theories in general, as well as construction theories specifically, have been implicit, {{it has not been}} possible to transfer such radical managerial innovation as mass production or lean production from manufacturing to construction. Direct application of these <b>production</b> <b>templates</b> in construction has been limited due to different context in construction in correspondence to manufacturing. On the other hand, without explicit theories, it has not been possible to access core ideas of concepts and methods of these templates, and to recreate them in construction environment. In consequence, theory and practice of construction has not progressed as in manufacturing. Secondly, it {{is argued that}} the underlying, even if implicit, theoretical model of construction is the transformation model of production. There are two first principles in the transformation model. First, the total transformation can be achieved only by realising all parts of it. Thus, we decompose the total transformation into parts, finally into tasks, ensure that all inputs are available and assign these tasks to operatives or workstations. Second, minimising the cost of each task, i. e. each decomposed transformation, minimises the cost of production. It is argued that these principles, in which uncertainty and time are abstracted away, are counterproductive, and lead to myopic control and inflated variability. Practical examples show that these deficiencies and related practical constraints hinder the top-down implementation of innovations. Thirdly, empirical research shows that also bottom-up innovation - systematic learning and problem solving - is hindered by this deficient theory. Thus, the advancement of construction innovation requires that a new, explicit and valid theory of construction is created, and business models and control methods based on it are develope...|$|R
40|$|Thesis (MPhil (Informations Science)) [...] University of Stellenbosch, 2009. This {{research}} utilises {{theories of}} organisational knowledge creation {{from the field}} of knowledge management to analyse {{the manner in which the}} industrialisation of the software development industry is likely to occur. The aim of the research is to prove the following hypothesis: If the software development industry moves towards industrialisation, then knowledge assets in the format of universal <b>production</b> <b>templates</b> will come into being. The research commences by providing background information on the state of practise of software engineering by giving an overview of the changes in the industry over the past four decades. The software development industry is consequently presented from the viewpoint of the proponents of a craftsmanship based approach to software development, and from the viewpoint of those proposing that industrialisation will offer a solution to the problems besetting the industry. In this discussion the terms industrialisation as well as economies of scale and scope are defined. Potential paths and drivers that will allow the industrialisation of the industry are presented – software factories as a path towards industrialisation, and cloud computing as a driver for industrialisation. In order to supply a knowledge management perspective, the theories of Ikujiro Nonaka and Max Boisot are presented. These theories assume different perspectives on the creation of organisational knowledge, but an attempt is made to reconcile the differences between the two theories. Particular attention is paid to the economic meaning and implications of knowledge, information and data as factors of production. The concept of knowledge assets are examined in detail, and placed into the context of software development. In the last chapter the research and conclusions of the previous chapters are consolidated, to prove the central hypothesis of this work...|$|R
40|$|The Sagrada Familia Church has {{appointed}} {{two groups of}} consultants to assist the translation of Gaudi's 1 : 10 scaled models of the nave into coherent information from which to build. One team has been undertaking the static analysis of the nave roof vault structure and the other {{the study of the}} complexities of Gaudi's composition in order to provide full-scale <b>production</b> <b>templates</b> and models for the walls. Both teams had begun using the same basic CAD package and both have had to move onto high-end and very expensive solid-modelling software normally used by mechanical engineers and vehicle designers. Both groups are collaborating together with different accents despite an improbable geographical separation. The original problem, one of intersecting ruled-surfaces accurately to reflect the geometries of the surviving fragments of the original models, has led to surprising possibilities which were not anticipated at the outset. Currently the potential of parametric variation and associative geometries are being investigated as a mirror for some of the intuitive design process and finite element analysis is being considered as a means of interactively analysing the structural implications for each study. The software being used also has a powerful ray-tracing module, rather than being simply a tool to produce eye-catching'realistic'renderings it has proved to be invaluable in allowing the computer user to understand the spatial complexities of the components being studied. This paper discusses the merits of an architecture so demanding (despite having been designed {{at the beginning of this}} century) that it requires the most costly equipment in today's market and it will consider the proposition that in ordinary circumstances, an architecture too complex to be described using basic CAD tools is an architecture beyond our reach. The interdisciplinary nature of the diverse and powerful modules within the software referred to will be used to contest this proposition using the presence of both teams in schools of architecture as evidence...|$|R
40|$|Introduction: The {{aim of this}} {{systematic}} review was to analyze the dental literature regarding accuracy and clinical application in computer-guided template-based implant dentistry. Materials and methods: An electronic literature search complemented by manual searching was performed to gather data on accuracy and surgical, biological and prosthetic complications in connection with computer-guided implant treatment. For the assessment of accuracy meta-regression analysis was performed. Complication rates are descriptively summarized. Results: From 3120 titles after the literature search, eight articles met the inclusion criteria regarding accuracy and 10 regarding the clinical performance. Meta-regression analysis revealed a mean deviation at the entry point of 1. 07 mm (95 % CI: 0. 76 - 1. 22 mm) and {{at the apex of}} 1. 63 mm (95 % CI: 1. 26 - 2 mm). No significant differences between the studies were found regarding method of <b>template</b> <b>production</b> or <b>template</b> support and stabilization. Early surgical complications occurred in 9. 1 %, early prosthetic complications in 18. 8 % and late prosthetic complications in 12 % of the cases. Implant survival rates of 91 - 100 % after an observation time of 12 - 60 months are reported in six clinical studies with 537 implants mainly restored immediately after flapless implantation procedures. Conclusion: Computer-guided template-based implant placement showed high implant survival rates ranging from 91 % to 100 %. However, a considerable number of technique-related perioperative complications were observed. Preclinical and clinical studies indicated a reasonable mean accuracy with relatively high maximum deviations. Future research should be directed {{to increase the number of}} clinical studies with longer observation periods and to improve the systems in terms of perioperative handling, accuracy and prosthetic complications...|$|R
40|$|Part 2 : CommunicationsInternational audienceTraditional {{sketching}} aids rely on {{the physical}} <b>production</b> of <b>templates</b> or stencils which is particularly problematic {{in the case of}} larger formats. One possible solution is 2 D virtual tracing using a virtual template to create a physical sketch. This paper evaluates a mobile phone as a 2 D virtual tracing tool by comparing three tracing methods: (i) a traditional tracing method with a printed template, (ii) a virtual tracing method Static Peephole (SP) in which the virtual template is manually adjusted to a physical contour by drag and pinch gestures, and (iii) a virtual tracing method augmented reality Magic Lens (ML) in which template is projected on the physical object such as paper hence navigation is possible through physical movement of the mobile device. The results show {{that it is possible to}} use mobile phones for virtual tracing, however, ML only achieved comparable performance to SP mode and traditional methods continued to be quicker and preferred by users...|$|R
40|$|Denna rapport beskriver utvecklingen av examensarbetet som utfördes på uppdrag av BrandEx Brandtätningar AB. Ett företag som brandskyddar byggnader, fartyg, oljeplattformar med mera. En officiell webbsida och en CD-ROM-produktion skapades åt företaget. Webbsidan konstruerades i webbredigeringsprogrammet Macromedia Dreamweaver 4 och CD-ROM-produktionen i multimedieprogrammet Macromedia Director 7. Det använda materialet innehöll bilder och PDF-filer som BrandEx hade i sitt arkiv, men mycket nytt skapades, exempelvis animeringar och egna musikstycken. Webbsidan gjordes enligt önskemål från BrandEx med en enkel ochstilren design. CD-ROM-produktionen skapades under friare förhållanden med avseende på innehåll och design. Innehållet blandades med animeringar, en videofilm, bilder, text, ljud och musik. Både webbsidan och CD-ROM-produktionen gjordes mer som produktionsmallar åt BrandEx. De skall själva kunna uppdatera dessa med ny information. BrandEx {{kommer att}} ge ut CD:n till kunder och andra intressenter som vill veta mer om företaget och om brandskydd. Den skall distribueras kostnadsfritt. Webbsidan kommer att vara den centrala informationsplatsen för BrandEx i Sverige. This report {{describes}} {{the process of}} the examination work that was made after an offer from BrandEx Brandtätningar AB. A company that fireprotects buildings, ships, oil platforms and so on. An official web site and a CD-ROM-production were created for the company. The web site was constructed in the web editing software Macromedia Dreamweaver 4 and the CD-ROM-production in the authoring tool for multimedia production Macromedia Director 7. The used material contained pictures and PDF-files from BrandEx archives, but lot of new material was created, for instance animations and own music tracks. The web site was made according to the wishes from BrandEx in a simple and pure design style. The CD-ROM-production was created under rather free conditions concerning content and design. The content was mixed with animations, a video, pictures, text, sounds and music. Both the web site and the CD-ROM-production were made more like <b>production</b> <b>templates</b> for BrandEx. They will be able to update with new information by themselves. BrandEx will issue the CD to customers and other partners that {{want to know more about}} the company and about fireprotections. It will be freely distributed. The web site will be the central place of information for BrandEx in Sweden...|$|R
40|$|Nanoscale {{structural}} cavities in ionomer membrane {{films were}} used as templates for the facile synthesis of small aluminum nanoparticles via catalytic decomposition of an alane precursor. The loading of reactive aluminum in the composite film could be varied, {{up to more than}} half of the film weight. While the embedded nanoparticles were protected by the membrane structure from any significant oxidation for the composite films to exhibit surprising stability in ambient air, they could be fully accessed in base water for the hydrogen <b>production</b> quantitatively. The <b>templated</b> synthesis may represent a new route for stable aluminum nanoparticles and related energetic nanomaterials...|$|R
5000|$|... "We've {{had some}} {{productions}} that were stressful, {{but this one}} ran very smoothly and DreamWorks is this <b>production</b> as a <b>template</b> on how they would like future productions to run. We lucked out, and there really {{was a sense of}} harmony on the animation. Even the production people. We all seemed like we were on the same page, believing in the film. That doesn’t happen very often. I tell animators, you will be working on dumpers for most of your career, {{but every once in a}} while you get a gem. Kung Fu Panda was a gem." [...] —Dan Wagner, Head of Character Animation.|$|R
40|$|Within an {{authentic}} learning framework, second year pre-service teachers {{were introduced to}} LAMS (the Learning Activity Management System) as {{part of one of}} the information and communication technology (ICT) units they are required to complete as part of their course. Using case study methodology, the students returned some interesting results: LAMS helped the students plan all aspects of their lesson and allowed them to preview their lesson from the learner’s perspective. Additionally, the software provided a visual overview of the lesson which assisted them to identify the learning styles that were addressed with the activities employed. Students also saw the benefit in the <b>production</b> of standardised <b>templates</b> of activities that could easily be modified for future re-use...|$|R
40|$|Due to {{a number}} of {{different}} production issues, the manufacture of template pipes is often delayed. These delays hold up pipe system completion on board the ships in production and can delay payments from the Ministry of Defense. In order to improve the <b>production</b> of <b>template</b> pipes, a number of changes are recommended to the pipe production processes overall. These include improvements in production planning, along with changes in procurement and scheduling methods. These changes in production methods will result in more material available when it is needed and will therefore improve the manufacture of template pipes. Additionally, they will improve the overall availability of pipes when needed as well as reducing inventory of finished pipes and decreasing the amount of rework. A number of other recommendations to improve the overall pipe manufacture process are also identified, including changes in performance measures, production planning, and other potential areas of improvement. by Shaheen J. Zojwalla. Thesis (S. M.) [...] Massachusetts Institute of Technology, Dept. of Materials Science and Engineering; and, (M. B. A.) [...] Massachusetts Institute of Technology, Sloan School of Management; in conjunction with the Leaders for Manufacturing Program at MIT, 2004. Includes bibliographical references (p. 63) ...|$|R
40|$|The micro-complement-fixation assay {{has been}} {{demonstrated}} to be a sensitive assay for flagella which occur in nanogram amounts. By use of this assay, {{it was found that}} flagellar synthesis occurs during starvation of Salmonella typhimurium for tryptophan, an amino acid not present in flagellar protein. Under these conditions net ribonucleic acid (RNA) synthesis was reduced to approximately 10 % of the control rate. Less than 1 μg of actinomycin D per ml further reduced RNA synthesis to less than 1 % of the control rate in a culture sensitized by prior treatment for 5 min at 37 C with 5 × 10 − 4 m ethylenediaminetetraacetate in 0. 33 m tris(hydroxymethyl) aminomethane-chloride (pH 8. 0). In the presence of actinomycin D, no synthesis of flagellar protein could be detected. Analysis of fractions of RNA separated by zone centrifugation indicated that actinomycin D reduces the <b>production</b> of <b>template</b> RNA as well as of ribosomal RNA. This suggests that in S. typhimurium the production of flagellar protein requires the concomitant synthesis of RNA. There is no evidence that a stable messenger RNA specific for flagellar synthesis is present...|$|R
40|$|Performance {{modeling}} {{has been}} made easier by architectures which package psychological theory for reuse at different levels. Both CPM-GOMS, which packages theory at the task level, and ACT-R, which packages theory at the lower level of rules for perceptual-motor interaction, {{have been shown to}} be useful. This paper describes ACT-Stitch, a framework for translating CPM-GOMS templates and interleaving theory into ACT-R. The research involved in producing ACT-Stitch will benefit reusable template research by showing how to implement templates and interleaving in a new architecture that processes resource information. ACT-R research will benefit from re-usable productions packaged at a higher task level and from the multi-tasking control structure used that allows ACT-R to interleave <b>productions</b> from different <b>templates.</b> The zero-parameter predictions of ACT-Stitch are empirically validated...|$|R
40|$|This paper studies an NP-hard multi-period production-distribution {{problem to}} {{minimize}} the sum of three costs: production setups, inventories and distribution. This problem is solved by a very recent form of metaheuristic called memetic algorithm with population management (MA|PM). Contrary to classical two-phase methods (production planning, then distribution planning), the algorithm simultaneously tackles production and distribution decisions. Several versions with different population management strategies are evaluated and compared with a two-phase heuristic and a Greedy Randomized Adaptive Search Procedure (GRASP), on 90 randomly generated instances with 20 periods and 50, 100 or 200 customers. The significant savings obtained compared to the two other methods confirm both the interest of integrating production and distribution decisions and of using the MA|PM <b>template.</b> <b>Production</b> Distribution Inventory routing Memetic algorithm...|$|R
40|$|We {{describe}} a high-throughput protocol for RNA {{in situ hybridization}} (ISH) to Drosophila embryos in a 96 -well format. cDNA or genomic DNA templates are amplified by PCR and then digoxigenin-labeled ribonucleotides are incorporated into antisense RNA probes by in vitro transcription. The quality of each probe is evaluated before ISH using a RNA probe quantification (dot blot) assay. RNA probes are hybridized to fixed, mixed-staged Drosophila embryos in 96 -well plates. The resulting stained embryos can be examined and photographed immediately or stored at 4 oC for later analysis. Starting with fixed, staged embryos, the protocol takes 6 d from probe <b>template</b> <b>production</b> through hybridization. Preparation of fixed embryos requires a minimum of 2 weeks to collect embryos representing all stages. The method {{has been used to}} determine the expression patterns of over 6, 000 genes throughout embryogenesis...|$|R
40|$|Advent of osseointegration has rapidly led to use {{of dental}} {{implants}} over recent years. Implant complications are often inadvertent sequelae of improper diagnosis, treatment planning, surgical method, and placement. This can be overcome by using surgical guides for implant positioning. Although conventionally made surgical guide are used, the clinical outcome is often unpredictable, {{and even if the}} implants are well placed, the location and deviation of the implants may not meet the optimal prosthodontic requirements. High accuracy in planning and execution of surgical procedures is important in securing a high success rate without causing iatrogenic damage. This can be achieved by computed tomography, 3 D implant planning software, image-guided <b>template</b> <b>production</b> techniques, and computer-aided surgery. This article evaluates about the various systems of conventionally made surgical guide using radiograph and also the newer computer generated surgical guide in detail...|$|R
40|$|The paper {{deals with}} the process of 3 D {{digitization}} as a tool for increasing production efficiency of complex shaped parts. Utilizes the concept of reverse engineering and new the model of NC program generation STEP-NC, for the of <b>templates</b> <b>production</b> for winding the stator coil of electromotors that is for electric household appliances. The manual production of prototype was substituted by manufacturing with NC machines. A 3 D scanner was used for data digitizing, CAD/CAM system Pro/Engineering was used for NC program generation, and 3 D measuring equipment was used for verification of new produced parts. The company estimated that only due to the implementation of STEP NC standard into production process it was allowed to read the 3 D geometry of the product without problems. It helps the workshop to shorten the time needed for part production by about 30 %...|$|R
40|$|Advances in gas field {{ion source}} {{technology}} {{over the last}} decade have led to renewed interest in ion beam lithography {{as an alternative to the}} widely-used electron beam lithography technique. At the forefront of this resurgence is helium ion beam lithography, in which a sub-nanometer focused beam of helium ions is used to define high-resolution (sub- 10 nm scale) patterns in resist. This chapter firstly describes the helium ion beam system, before presenting a comprehensive study on the unique properties of ion-solid interactions that potentially make helium ions more favourable than electrons in lithographic applications. Examples of helium ion beam lithography applied to various resists, both polymeric and molecular, are then discussed with a focus on sensitivity, proximity effect and minimum feature size of high-density patterns. Potential applications of helium ion beam lithography are reviewed, including rapid prototyping of nanodevices, <b>production</b> of nanoimprint <b>templates</b> and pre-screening of extreme ultraviolet resists...|$|R
40|$|Bottom-up {{approaches}} {{are widely used}} in preparation of high density nanoparticle assemblies since they can offer cost-effectivity and versatility for <b>production</b> of large-scale <b>templates.</b> Taking advantage of intense near field at plasmonic metal nanoparticles or in gaps between them resulting from localized surface plasmon resonances enables us to enhance spectroscopic signals particularly Raman and fluorescence. Several effects depend on the nanoscale distances. First, the plasmon band tuning and electric field strength directly depend on the nanoparticles gap size. Second, the spectral overlap of plasmon resonance and reporter molecule is also important. Moreover in fluorescence spectroscopy, fluorescence quenching is directly affected by metal-fluorophore distances. Therefore, overall distance control at nanoscale was considered as a main objective of this research. We used bottom-up techniques such as seed-mediated growth and layer by layer deposition. The prepared tunable and large-scale plasmonic templates gave promising results in enhanced spectroscopy...|$|R
40|$|While {{antibodies}} currently play {{a dominant}} role as affinity reagents in biological research and for diagnostics, {{a broad range}} of recombinant proteins are emerging as promising alternative affinity reagents in detection assays and quantification. DNA-mediated affinity-based assays, such as immuno-PCR and proximity ligation assays (PLA), use oligonucleotides attached to affinity reagents as reporter molecules. Conjugation of oligonucleotides to affinity reagents generally employs chemistries that target primary amines or cysteines. Because of the random nature of these processes neither the number of oligonucleotides conjugated per molecule nor their sites of attachment can be accurately controlled for affinity reagents with several available amines and cysteines. Here, we present a straightforward and convenient approach to functionalize recombinant affinity reagents for PLA by expressing the reagents as fusion partners with SNAP protein tags. This allowed us to conjugate oligonucleotides in a site-specific fashion, yielding precisely one oligonucleotide per affinity reagent. We demonstrate this method using designed ankyrin repeat proteins (DARPins) recognizing the tumor antigen HER 2 and we apply the conjugates in different assay formats. We also show that SNAP or CLIP tags, expressed as fusion partners of transfected genes, allow oligonucleotide conjugations to be performed in fixed cells, with no need for specific affinity reagents. The approach is used to demonstrate induced interactions between the fusion proteins FKBP and FRB by allowing the in situ conjugated oligonucleotides to direct the <b>production</b> of <b>templates</b> for localized rolling circle amplification reactions...|$|R
