434|999|Public
25|$|The Language Comprehension Department, {{headed by}} Anne Cutler, {{undertakes}} empirical investigation and computational modeling of {{the understanding of}} spoken language. Until 2009, the work within the department was largely divided between two research projects: decoding continuous speech and phonological learning for speech perception. From 2009 onwards, {{most of the work}} of the department goes into the project called Mechanisms and Representations in Comprehending Speech. This project focuses on core theoretical issues in speech comprehension such as on how episodic memories - such as hearing someone speak in an unfamiliar dialect - influence the speech <b>perception</b> <b>system,</b> or how is prior knowledge about one's language (phonotactic probabilities, lexical knowledge, frequent versus infrequent word combinations) used during perception.|$|E
50|$|A flicker meter is {{composed}} of several function blocks which simulate a 230 V/60 W incandescent lamp (reference lamp) and the human <b>perception</b> <b>system</b> (eye-brain model).|$|E
5000|$|Color {{constancy}} is {{a feature}} of the human color <b>perception</b> <b>system</b> which ensures that the color of an object remains similar under varying conditions and {{is the result of a}} very complicated 'calculation' by an unconsciously working mechanism within our central nervous system.|$|E
50|$|Masters {{introduced}} his 3D printing technology at CAD/CAM conferences {{in the late}} 1980s with little success. Undeterred, he founded <b>Perception</b> <b>Systems</b> to handle {{research and development of}} his technology. In 1992, <b>Perception</b> <b>Systems</b> changed its name to Ballistic Particle Manufacturing (BPM) and received funding from Palmetto Seed Capital, a state funded South Carolina venture capital group by headed by former South Carolina Governor Carroll A. Campbell, Jr..|$|R
30|$|Machine {{perception}} {{is a difficult}} problem both from a practical or implementation point of view {{as well as from}} a theoretical or algorithm point of view. Machine <b>perception</b> <b>systems</b> based on biological <b>perception</b> <b>systems</b> show great promise in many areas but they often have processing requirements and/or data flow requirements that are difficult to implement, especially in small or low-power systems. We propose a system design approach that makes it possible to implement complex functionality using cooperative analog-digital signal processing to lower-power requirements dramatically over digital-only systems, as well as provide an architecture facilitating the development of biologically motivated <b>perception</b> <b>systems.</b> We show the architecture and application development approach. We also present several reference systems for speech recognition, noise suppression, and audio classification.|$|R
40|$|As robots are {{becoming}} ubiquitous and more capable, {{the need for}} introducing solid robot software development methods is pressing to increase robots' task spectrum. This thesis is concerned with improving software engineering of robot <b>perception</b> <b>systems.</b> The presented research employs a model-based approach to provide the means to represent knowledge about robotics software. The thesis {{is divided into three}} parts, namely research on the specification, deployment and adaptation of robot <b>perception</b> <b>systems...</b>|$|R
50|$|The {{aim was to}} {{test and}} stress the current {{technology}} in a unique event: non-polluting and non-oil based autonomous vehicles in real traffic conditions on an extreme journey between two continents, the final outcome being a huge dataset with a very large variety of situations to be further used to refine the onboard <b>perception</b> <b>system.</b>|$|E
50|$|In {{robotics}} one often combines external {{sensory input}} and motor kinematics. A Sensory Motor-Map(SMM) is a map between the <b>perception</b> <b>system</b> of the robot and an action {{performed by the}} robot. The map gives the robot {{an understanding of how}} certain motor actions affect the perceived reality by relating the kinematics and dynamics used by the robot to achieve the external sensory input.|$|E
5000|$|Color {{constancy}} is {{an example}} of subjective constancy and a feature of the human color <b>perception</b> <b>system</b> which ensures that the perceived color of objects remains relatively constant under varying illumination conditions. A green apple for instance looks green to us at midday, when the main illumination is white sunlight, and also at sunset, when the main illumination is red. This helps us identify objects.|$|E
40|$|As robots are {{becoming}} ubiquitous and more capable, {{the need for}} introducing solid robot software development methods is pressing to increase robots' task spectrum. This thesis is concerned with improving software engineering of robot <b>perception</b> <b>systems.</b> The presented research employs a model-based approach to provide the means to represent knowledge about robotics software. The thesis {{is divided into three}} parts, namely research on the specification, deployment and adaptation of robot <b>perception</b> <b>systems.</b> The first part contributes the design and development of two domain-specific languages, namely RPSL and DepSL. Those languages provide suitable notations and abstractions to enable domain experts to express, compose and explore functional, architectural and deployment design decisions of robot <b>perception</b> <b>systems.</b> The resulting models are interpretable, thus they can be used not only to communicate design decisions to stakeholders, but also to verify them in an early development stage. The second part contributes means for deploying <b>perception</b> <b>systems</b> on real robot systems even in the presence of varying resource conditions. To this end, functional, architectural and deployment models are composed in a graph-structure. Such a graph enables not only humans, but also robots to derive implicitly defined information about their software both at design time and run time. The second part also contributes a reference architecture for deploying robot <b>perception</b> <b>systems.</b> The architecture provides a template solution for integrating not only the models required for deployment, but also all the other means required to carry out deployment. The third part utilizes both RPSL, DepSL and the reference architecture to specify, implement and evaluate three different robot <b>perception</b> <b>systems.</b> Those are capable to satisfy changing requirements induced, for example, by the robot's tasks or environment. This is achieved by proposing algorithms which derive adaptation actions based on models and varying requirements...|$|R
40|$|AbstractThe {{differential}} effect of stimulus inversion on face and object recognition suggests that inverted faces are processed by mechanisms for {{the perception of}} other objects rather than by face perception mechanisms. We investigated the face inversion using {{functional magnetic resonance imaging}} (fMRI). The principal effect of face inversion on was an increased response in ventral extrastriate regions that respond preferentially to another class of objects (houses). In contrast, house inversion did not produce a similar change in face-selective regions. Moreover, stimulus inversion had equivalent, minimal effects for faces in in face-selective regions and for houses in houseselective regions. The results suggest that the failure of face <b>perception</b> <b>systems</b> with inverted faces leads to the recruitment of processing resources in object <b>perception</b> <b>systems,</b> but this failure is not reflected by altered activity in face <b>perception</b> <b>systems...</b>|$|R
40|$|We present ROBOSHERLOCK, an {{open source}} {{software}} framework for implementing <b>perception</b> <b>systems</b> for robots performing human-scale everyday manipulation tasks. In ROBOSHERLOCK, perception and interpretation of realistic scenes is formulated as an unstructured information management (UIM) problem. The application of the UIM principle supports the implementation of <b>perception</b> <b>systems</b> that can answer task-relevant queries about objects in a scene, boost object recognition performance by combining the strengths of multiple perception algorithms, support knowledge-enabled reasoning about objects and enable automatic and knowledge-driven generation of processing pipelines. We demonstrate {{the potential of the}} proposed framework by three feasibility studies of systems for real-world scene perception that have been built on top of ROBOSHERLOCK...|$|R
50|$|Most placental mammals {{other than}} {{primates}} {{have only two}} types of color photoreceptor and are therefore dichromats; color perception in these creatures is presumably simpler than in our own. Meanwhile, birds and marsupials have four color photoreceptors in their eyes, and hence are tetrachromats with a more complex colour <b>perception</b> <b>system.</b> There is no currently peer reviewed scholarly work that has confirmed {{the existence of a}} functional human tetrachromat, but they are suspected to exist.|$|E
5000|$|The {{occipital}} lobe is {{the smallest}} of all four lobes in the human cerebral cortex and located in the rearmost part of the skull and considered {{to be part of}} the forebrain. [...] The occipital lobe sits directly above the cerebellum and is situated posterior to the Parieto-occipital sulcus, or parieto-occipital sulcus. This lobe is known as the centre of the visual <b>perception</b> <b>system,</b> the main function of the occipital lobe is that of vision.|$|E
5000|$|Apperceptive {{prosopagnosia}} has typically {{been used}} to describe cases of acquired prosopagnosia {{with some of the}} earliest processes in the face <b>perception</b> <b>system.</b> The brain areas thought to {{play a critical role in}} apperceptive prosopagnosia are right occipital temporal regions. [...] People with this disorder cannot make any sense of faces and are unable to make same-different judgments when they are presented with pictures of different faces. They are unable to recognize both familiar and unfamiliar faces. However, they may be able to recognize people based on non-face clues such as their clothing, hairstyle, skin color, or voice.|$|E
50|$|The {{time spent}} from 1990 to 1995 in developing, installing, and testing <b>perception</b> <b>systems</b> {{in a real}} {{automotive}} environment was of paramount importance and was a key factor for the growing of Broggi's reputation in the field.|$|R
40|$|Abstract — We present ROBOSHERLOCK, an {{open source}} {{software}} framework for implementing <b>perception</b> <b>systems</b> for robots performing human-scale everyday manipulation tasks. In ROBOSHERLOCK, perception and interpretation of realistic scenes is formulated as an unstructured information manage-ment (UIM) problem. The application of the UIM principle supports the implementation of <b>perception</b> <b>systems</b> that can answer task-relevant queries about objects in a scene, boost object recognition performance by combining the strengths of multiple perception algorithms, support knowledge-enabled reasoning about objects and enable automatic and knowledge-driven generation of processing pipelines. We demonstrate {{the potential of the}} proposed framework by three feasibility studies of systems for real-world scene perception that have been built on top of ROBOSHERLOCK. I...|$|R
50|$|In July 2015 Ambarella {{acquired}} VisLab, {{a pioneer}} in <b>perception</b> <b>systems</b> and autonomous vehicle research founded by Professor Alberto Broggi. VisLab has developed computer vision and intelligent control systems for automotive and commercial applications, including Advanced driver-assistance systems and several generations of autonomous vehicle driving systems.|$|R
50|$|The Language Comprehension Department, {{headed by}} Anne Cutler, {{undertakes}} empirical investigation and computational modeling of {{the understanding of}} spoken language. Until 2009, the work within the department was largely divided between two research projects: decoding continuous speech and phonological learning for speech perception. From 2009 onwards, {{most of the work}} of the department goes into the project called Mechanisms and Representations in Comprehending Speech. This project focuses on core theoretical issues in speech comprehension such as on how episodic memories - such as hearing someone speak in an unfamiliar dialect - influence the speech <b>perception</b> <b>system,</b> or how is prior knowledge about one's language (phonotactic probabilities, lexical knowledge, frequent versus infrequent word combinations) used during perception.|$|E
5000|$|Vicarious is {{developing}} machine learning software {{based on the}} computational principles of the human brain. Known as the Recursive Cortical Network (RCN), it is a visual <b>perception</b> <b>system</b> that interprets the contents of photographs and videos {{in a manner similar}} to humans. The system is powered by a balanced approach that takes sensory data, mathematics, and biological plausibility into consideration.On October 22, 2013, beating CAPTCHA, Vicarious announced its AI was reliably able to solve modern CAPTCHAs, with character recognition rates of 90% or better. However, Luis von Ahn, a pioneer of early CAPTCHA and founder of reCAPTCHA, expressed skepticism, stating: [...] "It's hard for me to be impressed since I see these every few months." [...] He pointed out that 50 similar claims to that of Vicarious had been made since 2003.|$|E
50|$|The {{empirical}} evidence for predictive coding is most robust for perceptual processing. As early as 1999, Rao and Ballard proposed a hierarchical visual processing {{model in which}} higher-order visual cortical area sends down predictions and the feedforward connections carry the residual errors between the predictions and the actual lower-level activities (Rao and Ballard, 1999). According to this model, each level in the hierarchical model network (except the lowest level, which represents the image) attempts to predict the responses at the next lower level via feedback connections, and the error signal is used to correct the estimate of the input signal at each level concurrently (Rao and Ballard, 1999). Emberson et al. established the top-down modulation in infants using a cross-modal audiovisual omission paradigm, determining that even infant brains have expectation about future sensory input that is carried downstream from visual cortices and are capable of expectation-based feedback (Emberson et al., 2015). Functional near-infrared spectroscopy (fNIRS) data showed that infant occipital cortex responded to unexpected visual omission (with no visual information input) but not to expected visual omission. These results establish that in a hierarchically organized <b>perception</b> <b>system,</b> higher-order neurons send down predictions to lower-order neurons, which in turn sends back up the prediction error signal.|$|E
50|$|In 2010 VisLab {{launched}} VIAC, the VisLab Intercontinental Autonomous Challenge, a 13,000 km {{test run}} for autonomous vehicles, from Italy to China. This {{was the first}} autonomous driving test on an intercontinental route; it lasted three months. All data were logged and used back in laboratory to improve the <b>perception</b> <b>systems.</b>|$|R
30|$|The second {{development}} path {{is concerned with}} perception of humans and human activities, on the one hand, and with implementing <b>perception</b> <b>systems</b> imitating human <b>perception</b> for broader application areas, on the other. Involved research fields are, among others, cognitive sciences, artificial intelligence, image processing, audio data processing, natural language processing, user interfaces, and human-machine interfaces.|$|R
40|$|AbstractTutorial <b>system</b> <b>perception,</b> {{academic}} self-efficacy, {{and creativity}} are assumed as factors influencing homeschooling students’ self-regulated learning. Do the tutorial <b>system</b> <b>perception,</b> academic self-efficacy, and creativity have effect simultaneously to homeschooling students’ self-regulated learning? The {{purpose of this}} study is to measure the direct and indirect effect in the model of tutorial <b>system</b> <b>perception,</b> academic self-efficacy, and creativity to homeschooling students’ self-regulated learning. The subjects are 205 homeschooling students in Jakarta. Tutorial <b>system</b> <b>perception</b> constructed from Eggen and Kauchack (2009) (α = 0. 885), academic self-efficacy constructed from Bandura (1997) (α = 0. 831), self-regulated learning constructed from Zimmerman (1996) (α = 0. 862), and creativity measured by Figural Test from Torrence's concept. Structural Equation Model is used to analyze the data. The empirical model has goodness of fit. The model could explain the influence of tutorial <b>system</b> <b>perception,</b> academic self-efficacy, and creativity to homeschooling students’ self-regulated learning. The other finding is only tutorial <b>system</b> <b>perception</b> and academic self-efficacy has direct effect to self-regulated learning, respectively. Tutorial system not only developing homeschooling students’ self-regulated learning but also increasing the academic self-efficacy. Tutorial <b>system</b> <b>perception,</b> academic self-efficacy, and creativity are important in shaping homeschooling students’ self-regulated learning...|$|R
5000|$|The most {{important}} {{function of the}} Occipital lobe is vision. Due to the positioning of this lobe {{at the back of}} the head it is not susceptible to much injury but any significant damage to the brain can cause a variety of damage to our visual <b>perception</b> <b>system.</b> Common problems in the occipital lobe are field defects and scotomas, movement and colour discrimination, hallucinations, illusions, inability to recognize words and inability to recognize movement. A study was done in which patients suffered from a tumour on the occipital lobe and the results shows that the most frequent consequence was contralateral damage to the visual field. When damage occurs in the occipital lobe it is most common to see the effects on the opposite side of the brain. Since the brain regions are so specialized in their functioning damages done to specific areas of the brain can cause specific type of damage. Damage to the left side of the brain can lead to language discrepancies, i.e. difficulty in properly identifying letters, numbers and words, inability to incorporate visual stimuli to comprehend multiple ways an object can be found. Right side damage causes non-verbal problems, i.e. identifying geometric shapes, perception of figures and faces. [...] In almost all regions of the brain left side damage leads to general language problems whereas right side damage leads to general perception and problem solving skills.|$|E
5000|$|This sort of {{evidence}} has been crucial in supporting the theory {{that there may be}} a specific face <b>perception</b> <b>system</b> in the brain. Most researchers agree that the facial perception process is holistic rather than featural, as it is for perception of most objects. A holistic perception of the face does not involve any explicit representation of local features (i.e., eyes, nose, mouth, etc.), but rather considers the face as a whole. Because the prototypical face has a specific spatial layout (eyes are always located above nose, and nose located above mouth), it is beneficial to use a holistic approach to recognize individual/specific faces from a group of similar layouts. This holistic processing of the face is exactly what is damaged in prosopagnosics. They are able to recognize the specific spatial layout and characteristics of facial features, but they are unable to process them as one entire face. This is counterintuitive to many people, as not everyone believes faces are [...] "special" [...] or perceived in a different way from other objects in the rest of the world. Though evidence suggests that other visual objects are processed in a holistic manner (e.g., dogs in dog experts), the size of these effects are smaller and are less consistently demonstrated than with faces. In a study conducted by Diamond and Carey, they showed this to be true by performing tests on dog-show judges. They showed pictures of dogs to the judges and to a control group and they then inverted those same pictures and showed them again. The dog-show judges had greater difficulty in recognizing the dogs once inverted compared to the control group; the inversion effect, the increased difficulty in recognizing a picture once inverted, was shown to be in effect. It was previously believed that the inversion effect was associated only with faces, but this study shows that it may apply to any category of expertise.|$|E
40|$|We {{describe}} the <b>perception</b> <b>system</b> for the Ambler, an autonomous, legged mobile robot that operates in rugged environments. The Ambler's <b>perception</b> <b>system</b> uses 3 -D laser range images to construct elevation {{maps of the}} local terrain, processing hundreds of images and thousands of elevation points during a walking experiment. This paper presents the design, implementation, and analysis of a <b>perception</b> <b>system</b> {{to meet the needs}} of long-duration walking, emphasizing issues of perforumnce, accuracy, and reliability...|$|E
40|$|Human {{activity}} is extremely complex. Current technology {{allows us to}} handcraft real-time <b>perception</b> <b>systems</b> for a specific perceptual task. However, such an approach is inadequate for building systems that accommodate the variety that is typical of human environments. In this paper we define a framework for context aware observation of human activity. A context in this framework {{is defined as a}} network of situations. A situation networ...|$|R
30|$|Hypothesis H 1 a: The user’s <b>perception</b> {{regarding}} <b>system</b> quality {{will affect}} the adoption of CRM in supply chain organizations.|$|R
25|$|Bayesian {{networks}} {{are a very}} general tool {{that can be used}} for a large number of problems: reasoning (using the Bayesian inference algorithm), learning (using the expectation-maximization algorithm), planning (using decision networks) and perception (using dynamic Bayesian networks). Probabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping <b>perception</b> <b>systems</b> to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).|$|R
40|$|Abstract: Machine {{perception}} {{plays an}} important role in any intelligent system, and in particular, guiding an autonomous mobile agent. Machine perception techniques have progressed significantly in recent years, however perception systems are still plagued by a lack of flexibility and an inadequacy in performance speed for use in real-time tasks. To overcome these problems, we have applied integrated karning lechniques to a <b>perception</b> <b>system</b> that is based on a selective sens ingpad ip. The incorporation of multiple learning algorithms at different levels in our <b>perception</b> <b>system</b> provides a great deal of flexibility and robustness when performing different perceptual tasks. Making use of a selective sensing paradigm allows the system to eliminate a large amount of non-pertinent sensory data so that processing speed is greatly increased. We are implementing such a <b>perception</b> <b>system</b> to be used on an autonomous mobile agent. In this paper, we describe our methodology and give a preliminary example of learning within our <b>perception</b> <b>system.</b> 1...|$|E
40|$|To perform {{planetary}} exploration without human supervision, {{a complete}} autonomous robot {{must be able}} to model its environment and to locate itself while exploring its surroundings. For that purpose, the authors propose a modular <b>perception</b> <b>system</b> for an autonomous explorer. The <b>perception</b> <b>system</b> maintains a consistent internal representation of the observed terrain from multiple sensor views. The representation can be accessed from other modules through queries. The <b>perception</b> <b>system</b> is intended to be used by the Ambler, a six-legged vehicle being built at CMU. A partial implementation of the system using a range scanner is presented as well as experimental results on a testbed that includes the sensor, one computer-controlled leg, and obstacles on a sandy surface...|$|E
40|$|The most {{challenging}} technical problems facing successful autonomous UGV operation in off-road environments are reliable sensing and perception. In this paper, we describe our progress {{over the last}} year toward solving these problems in Phase II of DARPA's PerceptOR program. We have developed a <b>perception</b> <b>system</b> that combines laser, camera, and proprioceptive sensing elements on both ground and air platforms to detect and avoid obstacles in natural terrain environments. The <b>perception</b> <b>system</b> has been rigorously tested in a variety of environments and has improved over time as problems have been identified and systematically solved. The paper describes the <b>perception</b> <b>system</b> and the autonomous vehicles, presents results from some experiments, and summarizes the current capabilities and limitations...|$|E
40|$|This paper {{presents}} {{an approach to}} promote the integrity of <b>perception</b> <b>systems</b> for outdoor unmanned ground vehicles (UGV) operating in challenging environmental conditions (presence of dust or smoke). The proposed technique automatically evaluates {{the consistency of the}} data provided by two sensing modalities: a 2 D laser range finder and a millimetre-wave radar, allowing for perceptual failure mitigation. Ex-perimental results, obtained with a UGV oper-ating in rural environments, and an error anal-ysis validate the approach. ...|$|R
50|$|Work {{such as the}} {{one from}} Scharnowski and Gegenfurtner {{suggests}} that both the action and <b>perception</b> <b>systems</b> are equally fooled by such illusions. Other studies, however, provide strong support for the idea that skilled actions such as grasping are not affected by pictorial illusions and suggest that the action/perception dissociation is a useful way to characterize the functional division of labor between the dorsal and ventral visual pathways in the cerebral cortex.|$|R
50|$|Humans and {{primates}} {{are unique}} as they possess trichromatic color vision, {{and are able}} to discern between violet wave (SW), green wave (MW), and yellow-green wave (LW).Mammals other than primates generally have less effective two-receptor color <b>perception</b> <b>systems,</b> allowing only dichromatic color vision; marine mammals have only a single cone type and are thus monochromats. Honey- and bumblebees have trichromatic color vision, which is insensitive to red but sensitive in ultraviolet to a color called bee purple.|$|R
