1264|201|Public
25|$|SAS System {{includes}} univariate <b>probability</b> <b>mass</b> {{function and}} distribution function.|$|E
25|$|This {{equation}} is the <b>probability</b> <b>mass</b> function (PMF) for a Poisson distribution.|$|E
25|$|The <b>probability</b> <b>mass</b> {{function}} can {{be calculated}} by various Taylor expansion methods or by numerical integration (Fog, 2008).|$|E
3000|$|... (m), {{which are}} {{interpreted}} as <b>probability</b> <b>masses.</b> The random measure {{is thus a}} weighted sum of M particles and their weights.|$|R
2500|$|In particular, if [...] is a {{discrete}} random variable assuming [...] with corresponding <b>probability</b> <b>masses</b> , then in the formula for total variance, the first term {{on the right-hand side}} becomes ...|$|R
5000|$|The above can be {{extended}} in {{a simple way to}} allow consideration of distributions which contain both discrete and continuous components. Suppose that the distribution consists of a number of discrete <b>probability</b> <b>masses</b> pk(θ) and a density f(x | θ), where the sum of all the ps added to the integral of f is always one. Assuming {{that it is possible to}} distinguish an observation corresponding to one of the discrete <b>probability</b> <b>masses</b> from one which corresponds to the density component, the likelihood function for an observation from the continuous component can be dealt with in the manner shown above. For an observation from the discrete component, the likelihood function for an observation from the discrete component is simply ...|$|R
25|$|Closed form {{expressions}} for the <b>probability</b> <b>mass</b> function exist (Lyons, 1980), {{but they}} are not very useful for practical calculations because of extreme numerical instability, except in degenerate cases.|$|E
25|$|This {{recursive}} dependency {{gives rise}} to a difference equation with a solution that is given in open form by the integral in the expression of the <b>probability</b> <b>mass</b> function in the table above.|$|E
25|$|Mode: for a {{discrete}} random variable, the value with highest probability (the location {{at which the}} <b>probability</b> <b>mass</b> function has its peak); for a continuous random variable, a location at which the probability density function has a local peak.|$|E
2500|$|To {{solve the}} {{two-stage}} stochastic problem numerically, one often needs {{to assume that}} the random vector [...] has a finite number of possible realizations, called scenarios, say , with respective <b>probability</b> <b>masses</b> [...] Then the expectation in the first-stage problem's objective function can be written as the summation: ...|$|R
5000|$|Consider [...] to be {{the sample}} and [...] {{to be the}} {{likelihood}} ratio, where [...] is the <b>probability</b> density (<b>mass)</b> function of the desired distribution and [...] is the <b>probability</b> density (<b>mass)</b> function of the biased/proposal/sample distribution. Then the problem can be characterized by choosing the sample distribution [...] that minimizes the variance of the scaled sample: ...|$|R
40|$|In this paper, {{we present}} a {{bounding}} methodology that allows to compute a tight lower bound on the cycle time of fork [...] join queueing networks with blocking and with general service time distributions. The methodology relies on two ideas. First, <b>probability</b> <b>masses</b> fitting (PMF) discretizes the service time distributions so that {{the evolution of the}} modified network can be modelled by a Markov chain. The PMF discretization is simple: the <b>probability</b> <b>masses</b> on regular intervals are computed and aggregated on a single value in the corresponding interval. Second, we take advantage of the concept of critical path, i. e. the sequence of jobs that covers a sample run. We show that the critical path can be computed with the discretized distributions and that the same sequence of jobs offers a lower bound on the original cycle time. The tightness of the bound is shown on computational experiments. Finally, we discuss the extension to split [...] and [...] merge networks and approximate estimations of the cycle time...|$|R
25|$|In the {{continuous}} univariate case above, the reference measure is the Lebesgue measure. The <b>probability</b> <b>mass</b> {{function of a}} discrete random variable is the density {{with respect to the}} counting measure over the sample space (usually the set of integers, or some subset thereof).|$|E
25|$|The mode is not {{necessarily}} unique to a given discrete distribution, since the <b>probability</b> <b>mass</b> function may take the same maximum value at several points x1, x2, etc. The most extreme case occurs in uniform distributions, where all values occur equally frequently.|$|E
25|$|To {{understand}} the above {{definition of the}} <b>probability</b> <b>mass</b> function, note that the probability for every specific sequence of knbsp&successes and rnbsp&failures is , because the outcomes of the knbsp&+nbsp&r trials are supposed to happen independently. Since the rthnbsp&failure comes last, it remains to choose the knbsp&trials with successes out of the remaining knbsp&+nbsp&rnbsp&−nbsp&1 trials. The above binomial coefficient, due to its combinatorial interpretation, gives precisely the number of all these sequences of length knbsp&+nbsp&rnbsp&−nbsp&1.|$|E
40|$|Abstract. We propose {{semantic}} distance measures {{based on}} the criterion of approximate discernibility and on evidence combination. In the presence of incomplete knowledge, the distance measures the degree of belief in the discernibility of two individuals by combining estimates of basic <b>probability</b> <b>masses</b> related {{to a set of}} discriminating features. We also suggest ways to extend this distance for comparing individuals to concepts and concepts to other concepts. ...|$|R
3000|$|... {{particles}} that are heavier will have greater tendency to dominate X̃_t compared to lighter particles. This {{leads to the}} creation of additional new particles in the region having heavier particles during the subsequent time step. This results into exploration improvements after resampling. Furthermore, the focus of exploration moves to the portions of space that possess large <b>probability</b> <b>masses.</b> Due to resampling, the particles propagated from X̃_t will possess less discriminate weights compared to the propagation using the X [...]...|$|R
50|$|The theorem is very {{important}} in extending the ideas of probability theory from <b>probability</b> <b>masses</b> and <b>probability</b> densities defined over real numbers to probability measures defined over arbitrary sets. It tells if and how it is possible to change from one probability measure to another. Specifically, the probability density function of a random variable is the Radon-Nikodym derivative of the induced measure with respect to some base measure (usually the Lebesgue measure for continuous random variables).|$|R
25|$|The {{need for}} deep {{learning}} with real-valued inputs, as in Gaussian restricted Boltzmann machines, {{led to the}} spike-and-slab RBM (ssRBM), which models continuous-valued inputs with strictly binary latent variables. Similar to basic RBMs and its variants, a spike-and-slab RBM is a bipartite graph, while like GRBMs, the visible units (input) are real-valued. The difference is in the hidden layer, where each hidden unit has a binary spike variable and a real-valued slab variable. A spike is a discrete <b>probability</b> <b>mass</b> at zero, while a slab is a density over continuous domain; their mixture forms a prior.|$|E
25|$|A random {{variable}} has a probability distribution, which specifies {{the probability that}} its value falls in any given interval. Random variables can be discrete, that is, taking any of a specified finite or countable list of values, endowed with a <b>probability</b> <b>mass</b> function characteristic of the {{random variable}}'s probability distribution; or continuous, taking any numerical value in an interval or collection of intervals, via a probability density function that is characteristic of the random variable's probability distribution; or a mixture of both types. Two random variables with the same probability distribution can still differ {{in terms of their}} associations with, or independence from, other random variables. The realizations of a random variable, that is, the results of randomly choosing values according to the variable's probability distribution function, are called random variates.|$|E
25|$|Probability {{distributions}} {{are generally}} {{divided into two}} classes. A discrete probability distribution (applicable to the scenarios where the set of possible outcomes is discrete, such as a coin toss or a roll of dice) can be encoded by a discrete list of the probabilities of the outcomes, known as a <b>probability</b> <b>mass</b> function. On the other hand, a continuous probability distribution (applicable to the scenarios where the set of possible outcomes can take on values in a continuous range (e.g. real numbers), such as the temperature on a given day) is typically described by probability density functions (with the probability of any individual outcome actually being 0). The normal distribution is a commonly encountered continuous probability distribution. More complex experiments, such as those involving stochastic processes defined in continuous time, may demand the use of more general probability measures.|$|E
5000|$|... where [...] {{denote the}} atoms (also denoted as singletons) and [...] {{the number of}} atoms [...] that appear in [...] Hence, <b>probability</b> <b>masses</b> [...] are equally {{distributed}} among the atoms of A.This strategy corresponds {{to the principle of}} insufficient reason (also denoted as principle of maximum entropy) according to which an unknown distribution most probably corresponds to a uniform distribution. In the TBM pignistic probability functions are described by functions [...] Such a function satisfies the probability axioms:with ...|$|R
40|$|International audienceIn {{this paper}} we study the flux through a finite Markov chain of a quantity, {{that we will}} call mass, which moves through {{the states of the}} chain {{according}} to the Markov transition <b>probabilities.</b> <b>Mass</b> is supplied by an external source and accumulates in the absorbing states of the chain. We believe that studying how this conserved quantity evolves through the transient (non-absorbing) states of the chain could be useful for the modelization of open systems whose dynamics has a Markov property...|$|R
5000|$|Thinking of <b>probability</b> as <b>mass</b> {{helps to}} avoid {{mistakes}} since the physical mass is conserved {{as is the}} total probability for all hypothetical outcomes x: ...|$|R
2500|$|<b>Probability</b> <b>mass,</b> <b>Probability</b> <b>mass</b> function, p.m.f., Discrete {{probability}} distribution function: [...] for discrete random variables.|$|E
2500|$|... may be {{considered}} to represent a discrete <b>probability</b> <b>mass</b> function of , with an associated <b>probability</b> <b>mass</b> function constructed from the transformed variable, ...|$|E
2500|$|The Kullback–Leibler {{divergence}} [...] is convex in {{the pair}} of <b>probability</b> <b>mass</b> functions , i.e. if [...] and [...] are two pairs of <b>probability</b> <b>mass</b> functions, then ...|$|E
40|$|Micelle gel is a radiochromic {{hydrogel}} {{with the}} potential {{to be used as a}} three dimensional (3 D) radiation dosimeter. Since an ideal dosimeter should present water equivalent properties, in this study the water equivalence of two formulations of micelle gel has been investigated by calculating electron density, effective atomic number, fractional interaction <b>probabilities,</b> <b>mass</b> attenuation coefficient. The depth doses for kilovoltage and megavoltage x-ray beams have also modelled using Monte Carlo code. Based on the results of this work, micelle gels can be considered as water equivalent dosimeters. 5 page(s...|$|R
50|$|Beliefs from {{different}} sources {{can be combined}} with various fusion operators to model specific situations of belief fusion, e.g. with Dempster's rule of combination, which combines belief constraints that are dictated by independent belief sources, {{such as in the}} case of combining hints or combining preferences. Note that the <b>probability</b> <b>masses</b> from propositions that contradict each other can be used to obtain a measure of conflict between the independent belief sources. Other situations can be modeled with different fusion operators, such as cumulative fusion of beliefs from independent sources which can be modeled with the cumulative fusion operator.|$|R
40|$|International audienceWhen {{working with}} sets of probabilities, basic {{information}} fusion operators quickly reach their limits: intersection becomes empty, while union {{results in a}} poorly informative model. An attractive means to overcome these limitations is to use maximal coherent subsets (MCS). However, identifying the maximal coherent subsets is generally NP-hard. Previous proposals advocating the use of MCS to merge probability sets have not provided efficient ways to perform this task. In this paper, we propose an efficient approach to do such a merging between imprecise <b>probability</b> <b>masses,</b> a popular model of probability sets, and test it on an ensemble classification problem...|$|R
2500|$|The {{function}} [...] mapping a {{point in}} the sample space to the [...] "probability" [...] value is called a <b>probability</b> <b>mass</b> function abbreviated as pmf. The modern definition does not try to answer how <b>probability</b> <b>mass</b> functions are obtained; instead it builds a theory that assumes their existence.|$|E
2500|$|Under this {{parametrization}} the <b>probability</b> <b>mass</b> function will be ...|$|E
2500|$|The <b>probability</b> <b>mass</b> {{function}} of the negative binomial distribution is ...|$|E
40|$|Genipin gel is a radiochromic gel {{with the}} {{potential}} {{to be used as a}} three dimensional (3 D) dosimeter. An ideal dosimeter should present radiologically water equivalent properties. In this work, we have evaluated the water equivalency of genipin gel by calculating its radiological properties, such as mass and electron density, effective atomic number, fractional interaction <b>probabilities,</b> <b>mass</b> energy absorption coefficient and mass stopping powers as well as depth doses for kilovoltage x-ray and megavoltage electron beams. Based on the results of this study, we conclude that genipin gel is a water equivalent dosimeter. 5 page(s...|$|R
3000|$|... 2. Yücel N, Lefering R, Maegele M, et al. Trauma Associated Severe Hemorrhage (TASH)-Score: <b>probability</b> of <b>mass</b> {{transfusion}} as {{surrogate for}} life threatening hemorrhage after multiple trauma. J Trauma 2006; 60 (6): 1228 – 1236.|$|R
40|$|We derive {{some simple}} {{relations}} that demonstrate how the posterior convergence rate {{is related to}} two driving factors: a "penalized divergence" of the prior, which measures {{the ability of the}} prior distribution to propose a nonnegligible set of working models to approximate the true model and a "norm complexity" of the prior, which measures the complexity of the prior support, weighted by the prior <b>probability</b> <b>masses.</b> These formulas are explicit and involve no essential assumptions and are easy to apply. We apply this approach to the case with model averaging and derive some useful oracle inequalities that can optimize the performance adaptively without knowing the true model. Comment: 8 page...|$|R
