1689|2967|Public
5|$|SAM {{has been}} used as a source of {{alignments}} for protein structure prediction to participate in the CASP structure prediction experiment and to develop a database of predicted proteins in the yeast species S. cerevisiae. HHsearch is a software package for the detection of remotely related protein sequences based on the <b>pairwise</b> <b>comparison</b> of HMMs. A server running HHsearch (HHpred) was by far the fastest of the 10 best automatic structure prediction servers in the CASP7 and CASP8 structure prediction competitions.|$|E
25|$|The {{two samples}} to be {{compared}} (<b>pairwise</b> <b>comparison)</b> are grown/acquired. In this example treated sample (case) and untreated sample (control).|$|E
2500|$|... {{then the}} {{pairwise}} majority preference {{of the group}} is that A wins over B, B wins over C, and C wins over A: these yield rock-paper-scissors preferences for any <b>pairwise</b> <b>comparison.</b> [...] In this circumstance, any aggregation rule that satisfies the very basic majoritarian requirement that a candidate who receives a majority of votes must win the election, will fail the IIA criterion, if social preference is required to be transitive (or acyclic). [...] To see this, suppose that such a rule satisfies IIA. [...] Since majority preferences are respected, the society prefers A to B (two votes for A > B and one for B > A), B to C, and C to A. [...] Thus a cycle is generated, which contradicts the assumption that social preference is transitive.|$|E
40|$|One of {{the major}} {{challenges}} for collective intelligence is inconsistency, which is unavoidable whenever subjective assessments are involved. <b>Pairwise</b> <b>comparisons</b> allow one to represent such subjective assessments and to process them by analyzing, quantifying and identifying the inconsistencies. We propose using smaller scales for <b>pairwise</b> <b>comparisons</b> and provide mathematical and practical justifications for this change. Our postulate's aim is to initiate a paradigm shift {{in the search for}} a better scale construction for <b>pairwise</b> <b>comparisons.</b> Beyond <b>pairwise</b> <b>comparisons,</b> the results presented may be relevant to other methods using subjective scales. Keywords: <b>pairwise</b> <b>comparisons,</b> collective intelligence, scale, subjective assessment, inaccuracy, inconsistency. Comment: 16 pages, 1 figure; the mathematical theory has been provided for the use of small scale (1 to 3) for <b>pairwise</b> <b>comparisons</b> (but not only...|$|R
40|$|We {{propose a}} new method for {{deriving}} rankings from fuzzy <b>pairwise</b> <b>comparisons.</b> It {{is based on}} the observation that quantification of the uncertainty of the <b>pairwise</b> <b>comparisons</b> should be used to obtain a better crisp ranking, instead of a fuzzified version of the ranking obtained from crisp <b>pairwise</b> <b>comparisons.</b> With our method, a crisp ranking is obtained by solving a linear programming problem, when the fuzzy <b>pairwise</b> <b>comparisons</b> are fuzzy triangular numbers. Our method simplifies the recent method by Mikhailov...|$|R
50|$|The example above shows Schulze STV's {{resistance}} to vote management. Since it performs Condorcet <b>pairwise</b> <b>comparisons,</b> like CPO-STV, it doesn't suffer from defects caused by sequential exclusions. In addition, {{the number of}} <b>pairwise</b> <b>comparisons</b> are greatly reduced, since Schulze STV only has to compare outcomes that differ by one candidate, unlike CPO-STV which must compare all possible <b>pairwise</b> <b>comparisons.</b>|$|R
5000|$|This matrix {{summarizes}} the corresponding <b>pairwise</b> <b>comparison</b> counts: ...|$|E
5000|$|The Kemeny-Young method {{arranges}} the <b>pairwise</b> <b>comparison</b> {{counts in}} the following tally table: ...|$|E
5000|$|<b>Pairwise</b> <b>comparison,</b> {{the process}} of {{comparing}} two entities to determine which is preferred ...|$|E
40|$|This paper {{shows how}} to manage null entries in <b>pairwise</b> <b>comparisons</b> matrices. Although {{assessments}} can be imprecise, since subjective criteria are involved, the classical <b>pairwise</b> <b>comparisons</b> theory expects {{all of them to}} be available. In practice, some experts may not be able (or available) to provide all assessments. Therefore managing null entries is a necessary extension of the <b>pairwise</b> <b>comparisons</b> method. It is shown that certain null entries can be recovered {{on the basis of the}} transitivity property which each <b>pairwise</b> <b>comparisons</b> matrix is expected to satisfy. Comment: 5 page...|$|R
5000|$|If <b>pairwise</b> <b>comparisons</b> {{are in fact}} {{transitive}} {{in respect}} to the four mentioned rules, then <b>pairwise</b> <b>comparisons</b> {{for a list of}} alternatives (A1, A2, A3, ..., An&minus;1, and An) can take the form: ...|$|R
50|$|One {{important}} {{application of}} <b>pairwise</b> <b>comparisons</b> is the widely used Analytic Hierarchy Process, a structured technique for helping people deal with complex decisions. It uses <b>pairwise</b> <b>comparisons</b> of tangible and intangible factors to construct ratio scales that {{are useful in}} making important decisions.|$|R
5000|$|The Kemeny-Young method {{arranges}} the <b>pairwise</b> <b>comparison</b> {{counts in}} the following tally table (with [...] ) : ...|$|E
5000|$|Experienced {{software}} engineers use AHP’s <b>pairwise</b> <b>comparison</b> {{to estimate}} the relative cost of implementing each candidate requirement.|$|E
5000|$|Condorcet loser criterion—If a {{candidate}} loses {{to every other}} candidate in <b>pairwise</b> <b>comparison,</b> does that candidate always lose? ...|$|E
30|$|Conducting <b>pairwise</b> <b>comparisons</b> on the clusters.|$|R
40|$|Abstract—Low-dimensional {{embedding}} {{based on}} non-metric data (e. g., non-metric multidimensional scaling) {{is a problem}} that arises in many applications, especially those involving human subjects. This paper investigates the problem of learning an embedding of n objects into d-dimensional Euclidean space that is consistent with <b>pairwise</b> <b>comparisons</b> of the type “object a is closer to object b than c. ” While there are O(n 3) such comparisons, experimental studies suggest that relatively few are necessary to uniquely determine the embedding up to the constraints imposed by all possible <b>pairwise</b> <b>comparisons</b> (i. e., the problem is typically over-constrained). This paper is concerned with quantifying the minimum number of <b>pairwise</b> <b>comparisons</b> necessary to uniquely determine an embedding up to all possible comparisons. The comparison constraints stipulate that, with respect to each object, the other objects are ranked relative to their proximity. We prove that at least Ω(dn log n) <b>pairwise</b> <b>comparisons</b> are needed to determine the embedding of all n objects. The lower bounds cannot be achieved by using randomly chosen <b>pairwise</b> <b>comparisons.</b> We propose an algorithm that exploits the low-dimensional geometry in order to accurately embed objects based on relatively small number of sequentially selected <b>pairwise</b> <b>comparisons</b> and demonstrate its performance with experiments. I...|$|R
30|$|<b>Pairwise</b> <b>comparisons</b> at time {{intervals}} for all patients.|$|R
50|$|The main {{features}} of PriEsT include: supporting <b>Pairwise</b> <b>comparison</b> method with any scale for ratio-based judgements; providing widely used measures for inconsistency in judgements; offers several non-dominated solutions {{with the help}} of Evolutionary Multi-objective optimization; implements all the widely used prioritization methods for research purpose; graphical and Equalizer views for the <b>pairwise</b> <b>comparison</b> judgements; exporting problems into an XML data file; platform-independent Java-based Tool (runs on Linux, Android and Windows).|$|E
50|$|Note that <b>pairwise</b> <b>comparison</b> of four nodes {{requires}} six separate comparisons, {{while that}} of three nodes requires only three.|$|E
5000|$|Customers {{and users}} (or {{suitable}} substitutes) apply AHP’s <b>pairwise</b> <b>comparison</b> method {{to assess the}} relative value of the candidate requirements.|$|E
5000|$|Tukey's {{procedure}} {{is only applicable}} for <b>pairwise</b> <b>comparisons.</b>|$|R
40|$|This paper {{examines}} {{the problem of}} ranking a collection of objects using <b>pairwise</b> <b>comparisons</b> (rankings of two objects). In general, the ranking of $n$ objects can be identified by standard sorting methods using $n log_ 2 n$ <b>pairwise</b> <b>comparisons.</b> We are interested in natural situations in which relationships among the objects may allow for ranking using far fewer <b>pairwise</b> <b>comparisons.</b> Specifically, {{we assume that the}} objects can be embedded into a $d$-dimensional Euclidean space and that the rankings reflect their relative distances from a common reference point in $R^d$. We show that under this assumption the number of possible rankings grows like $n^{ 2 d}$ and demonstrate an algorithm that can identify a randomly selected ranking using just slightly more than $d log n$ adaptively selected <b>pairwise</b> <b>comparisons,</b> on average. If instead the comparisons are chosen at random, then almost all <b>pairwise</b> <b>comparisons</b> must be made in order to identify any ranking. In addition, we propose a robust, error-tolerant algorithm that only requires that the <b>pairwise</b> <b>comparisons</b> are probably correct. Experimental studies with synthetic and real datasets support the conclusions of our theoretical analysis. Comment: 17 pages, an extended version of our NIPS 2011 paper. The new version revises the argument of the robust section and slightly modifies the result there to give it more impac...|$|R
50|$|By {{participating}} in the election the three voters supporting A would change A from winner to loser. Their ballots support 3 of the 6 <b>pairwise</b> <b>comparisons</b> of the ranking A > D > C >B, but four <b>pairwise</b> <b>comparisons</b> of the ranking B > A > D > C, enough to overcome the first one.|$|R
5000|$|The {{two samples}} to be {{compared}} (<b>pairwise</b> <b>comparison)</b> are grown/acquired. In this example treated sample (case) and untreated sample (control).|$|E
5000|$|Condorcet criterion—If a {{candidate}} beats every other candidate in <b>pairwise</b> <b>comparison,</b> does that candidate always win? (This implies the majority criterion, above) ...|$|E
5000|$|HHpred is {{a popular}} {{threading}} server which runs HHsearch, a widely used software for remote homology detection based on <b>pairwise</b> <b>comparison</b> of hidden Markov models.|$|E
40|$|We {{describe}} the algebraic properties of <b>pairwise</b> <b>comparisons</b> matrices with coefficients in an arbitrary group. We provide a vocabulary adapted for {{the description of}} main algebaric properties of inconsistency maps, describe an example where {{the use of a}} non abelian group is necessary, and decribe a generalization of <b>pairwise</b> <b>comparisons</b> matrices and inconsistency maps on a graph...|$|R
40|$|This study investigates a {{powerful}} model, targeted to subjective assessments, based on <b>pairwise</b> <b>comparisons.</b> It provides a proof that a distance-based inconsistency reduction transforms an inconsistent <b>pairwise</b> <b>comparisons</b> (PC) matrix into a consistent PC matrix which {{is generated by}} the geometric means of rows of a given inconsistent PC matrix. The distance-based inconsistency indicator was defined in 1993 for <b>pairwise</b> <b>comparisons.</b> Its convergence was analyzed in 1996 (regretfully, with an incomplete proof; finally completed in 2010). However, there was no clear interpretation of the convergence limit which is of considerable importance for applications and this study does so. Comment: 16 page, 1 figure. For <b>pairwise</b> <b>comparisons,</b> the normalized vector o geometric means (GM) {{is equal to the}} normalized principal eigenvector (EV) for consistent matrices. For inconsistent matrices, the limit is "make it consistent" process is GM (specifically, not EV). This contribution finally concludes the discussion "GM or EV" originated in 1980...|$|R
5000|$|At first, <b>pairwise</b> <b>comparisons</b> will be {{made between}} all the actions for each criterion: ...|$|R
5000|$|The lower-case d {{described}} above {{is the difference}} between these two numbers—the average number of polymorphisms found in <b>pairwise</b> <b>comparison</b> (2) and M. Thus [...]|$|E
50|$|Duncan's Bayesian MCP {{discusses}} {{the differences between}} ordered group means, where the statistics in question are <b>pairwise</b> <b>comparison</b> (no equivalent is defined for the property of a subset having 'significantly different' property).|$|E
5000|$|A {{variation}} on his model (see <b>Pairwise</b> <b>comparison</b> and the BTL model), {{states that the}} difference between their quality values is equal to the log of the odds that object-A will beat object-B: ...|$|E
5000|$|The {{results of}} the 10 {{possible}} <b>pairwise</b> <b>comparisons</b> between the candidates are as follows: ...|$|R
40|$|AbstractThe {{algorithm}} {{for finding}} a consistent approximation to an inconsistent <b>pairwise</b> <b>comparisons</b> matrix {{is based on}} a logarithmic transformation of a <b>pairwise</b> <b>comparisons</b> matrix into a vector space with the Euclidean metric. An orthogonal basis is introduced in the vector space formed by the images of consistent matrices. The required consistent approximation is the orthogonal projection of the transformed matrix onto this space...|$|R
40|$|International audienceWe {{describe}} a seriation algorithm for ranking {{a set of}} $n$ items given <b>pairwise</b> <b>comparisons</b> between these items. Intuitively, the algorithm assigns similar rankings to items that compare similarly with all others. It does so by constructing a similarity matrix from <b>pairwise</b> <b>comparisons,</b> using seriation methods to reorder this matrix and construct a ranking. We first show that this spectral seriation algorithm recovers the true ranking when all <b>pairwise</b> <b>comparisons</b> are observed and consistent with a total order. We then show that ranking reconstruction is still exact even when some <b>pairwise</b> <b>comparisons</b> are corrupted or missing, and that seriation based spectral ranking is more robust to noise than other scoring methods. An additional benefit of the seriation formulation {{is that it allows}} us to solve semi-supervised ranking problems. Experiments on both synthetic and real datasets demonstrate that seriation based spectral ranking achieves competitive and in some cases superior performance compared to classical ranking methods...|$|R
