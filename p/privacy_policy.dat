899|1049|Public
5|$|In March 2016, the New York Civil Liberties Union (NYCLU), the New York City {{office of}} the American Civil Liberties Union, {{wrote a letter to}} Mayor de Blasio {{outlining}} their privacy concerns. In the letter, representatives for the NYCLU wrote that CityBridge could be retaining too much information about LinkNYC users. They also stated that the <b>privacy</b> <b>policy</b> was vague and needed to be clarified. They recommended that the <b>privacy</b> <b>policy</b> be rewritten so that it expressly mentions whether the Links' environmental sensors or cameras are being used by any NYPD or city systems.|$|E
5|$|Lam Wing-kee (林榮基, age 60), {{the founder}} of Causeway Bay Books, has been missing since 24 October 2015. He habitually spent long hours at the {{bookshop}} and occasionally slept there. His wife filed a missing persons report with the police on 5 November and his family received {{a telephone call from}} him several hours later; he refused to reveal his whereabouts. When filing the police report, they were referred to the Immigration Department, who said it was against <b>privacy</b> <b>policy</b> to reveal a person's records of entry and exit of Hong Kong without the subject's permission. However, legislator James To said this was a reasonable request that was exempt from <b>privacy</b> <b>policy.</b> Police followed up on his case once, asking whether they had heard from him. His family allege that upon learning that he had contacted his family, the officer who called them informed that the case would be closed as resolved.|$|E
25|$|Some users do {{not like}} the {{overlapping}} <b>privacy</b> <b>policy,</b> wishing to keep the service of Google separate. The update to Google’s <b>privacy</b> <b>policy</b> has alarmed both public and private sectors. The European Union has asked Google to delay the onset of the new <b>privacy</b> <b>policy</b> {{in order to ensure that}} it does not violate E.U. law. This move is in accordance with objections to decreasing online privacy raised in other foreign nations where surveillance is more heavily scrutinized. Canada and Germany have both held investigations into the legality of both Facebook, against respective privacy acts, in 2010. The new <b>privacy</b> <b>policy</b> only heightens unresolved concerns regarding user privacy.|$|E
40|$|Organizational <b>privacy</b> <b>policies</b> and <b>privacy</b> {{practices}} {{reflect an}} organization’s perceived trustworthiness {{to those with}} which it conducts business. This paper proposes a framework, based upon an in-depth two-year analysis of Internet <b>privacy</b> <b>policies,</b> for examining an organization’s privacy management practices {{within the context of}} their respective <b>privacy</b> <b>policies.</b> The framework aids in evaluating privacy from various organizational perspectives: legal, technical, business rules, social norms and contractual norms. It also provides assistance when developing <b>privacy</b> <b>policies</b> for e-commerce Web sites. We discuss a case study in which the framework was employed to analyze 23 Internet health care Web site <b>privacy</b> <b>policies...</b>|$|R
5000|$|Additionally, the lab {{archives}} {{web sites}} <b>privacy</b> <b>policies</b> {{and has been}} creating a toolkit {{to aid in the}} automated analysis of both P3P policies as well as natural language <b>privacy</b> <b>policies.</b>|$|R
40|$|Nowadays {{privacy is}} a key issue and {{enterprises}} have adopted various strategies to protect customers privacy and to make public their <b>privacy</b> <b>policies.</b> This paper presents a conceptual model for the definition and enforcement of <b>privacy</b> <b>policies.</b> The model is described by means of UML and it provides a clear and simple way for representing <b>privacy</b> <b>policies.</b> Furthermore, the model supports different ways for enforcing <b>privacy</b> <b>policies</b> by defining when the controls are {{to be done and}} what actions need to be performed. Finally, the paper introduces a small example in order to better explain the proposed approach...|$|R
25|$|Google has one <b>privacy</b> <b>policy</b> {{that cover}} {{all of its}} services.|$|E
25|$|In June 2010, Apple updated {{its general}} <b>privacy</b> <b>policy</b> for the iTunes Store and iOS 4 {{supported}} devices, revealing {{that it could}} and would collect real-time location-based information on users aged 13 and over. The information had been included in various device-specific EULAs since 2008, but {{was not included in}} Apple's general <b>privacy</b> <b>policy</b> until 2010.|$|E
25|$|On September 20, 2017, Plex {{was going}} to {{implement}} a new <b>privacy</b> <b>policy</b> {{in which it was}} no longer possible for users of Plex to prevent their user data from being collected. However, in a later <b>privacy</b> <b>policy</b> update, the CEO of Plex, Keith Valory, has stated that they will generalize the playback data and offer users the ability to opt out of sending more specific playback information.|$|E
40|$|Online <b>privacy</b> <b>policies</b> are {{important}} mechanisms for informing web site users {{about the level}} of information privacy protection afforded them when visiting web sites. To date, societal mechanisms and technologies have been the focus of attempts to improve the quality and effectiveness of online <b>privacy</b> <b>policies.</b> Little attention, however, has been given to the development and use of organisational measures for this purpose. In this paper we present findings from a longitudinal, empirical study of online <b>privacy</b> <b>policies.</b> Our research found that although online <b>privacy</b> <b>policies</b> have improved in quality and effectiveness since 2000, they still fall well short of the level of privacy assurance desired by consumers. This study has identified broad areas of deficiency in existing online <b>privacy</b> <b>policies,</b> and offers a solution {{in the form of an}} holistic framework for the development, factors and content of online <b>privacy</b> <b>policies</b> for organisations. Our study adds to existing theory in this area and, more immediately, will assist businesses concerned about the effect of privacy issues on consumer web usage...|$|R
30|$|The {{possible}} solution presented here provides all these features [18]. The <b>privacy</b> <b>policies</b> are described with XACML [19], which facilitates {{the possibility of}} having different levels of granularity in the rules. As mentioned before, this information can be included (or linked to) within the image file, i.e., the APP 11 marker segment {{in case of a}} JPEG- 1 file format. In our specific implementation, based on MIPAMS [18], the <b>privacy</b> <b>policies</b> are included in the image with only a reference to an external system that will handle everything (access to the <b>privacy</b> <b>policies,</b> authorization of access to the images, protection of the image, creation of the <b>privacy</b> <b>policies,</b> etc.).|$|R
40|$|We present {{findings}} from a longitudinal, empirical study of [...] . online <b>privacy</b> <b>policies.</b> Our research found that although online <b>privacy</b> <b>policies</b> have improved in quality and effectiveness since 2000, they still fall {{well short of}} the level of privacy assurance desired by consumers. This study has identified broad areas of deficiency in existing online <b>privacy</b> <b>policies,</b> and offers a solution {{in the form of an}} holistic framework for the development, factors and content of online <b>privacy</b> <b>policies</b> for organizations. Our study adds to existing theory in this area and, more immediately, will assist businesses concerned about the effect of privacy issues on consumer web usage...|$|R
25|$|Google’s <b>privacy</b> <b>policy</b> {{explains}} {{information they}} collect {{and why they}} collect it, how they use the information, and how to access and update information. Google will collect information to better service its users such as their language, which ads they find useful or people {{that are important to}} them online. Google announces they will use this information to provide, maintain, protect Google and its users. The information Google uses will give users more relevant search results and advertisements. The new <b>privacy</b> <b>policy</b> explains that Google can use shared information on one service in other Google services from people who have a Google account and are logged in. Google will treat a user as a single user across all of their products. Google claims the new <b>privacy</b> <b>policy</b> will benefit its users by being simpler. Google will, for example, be able to correct the spelling of a user’s friend’s name in a Google search or notify a user they are late based on their calendar and current location. Even though Google is updating their <b>privacy</b> <b>policy,</b> its core privacy guidelines will not change. For example, Google does not sell personal information or share it externally.|$|E
25|$|Angela Beesley and Florence Nibart-Devouard {{were elected}} to the Board of Trustees of the Wikimedia Foundation. During this time, Angela was active in editing content and setting policy, such as <b>privacy</b> <b>policy,</b> within the Foundation.|$|E
25|$|During 2006–10, Google Streetview camera cars {{collected}} about 600 gigabytes of {{data from}} users of unencrypted public and private Wi-Fi networks in more than 30 countries. No disclosures nor <b>privacy</b> <b>policy</b> was given to those affected, nor to {{the owners of the}} Wi-Fi stations.|$|E
40|$|<b>Privacy</b> <b>policies</b> are {{a nearly}} {{ubiquitous}} feature of websites and online services, and {{the contents of}} such policies are legally binding for users. However, the obtuse language and sheer length of most <b>privacy</b> <b>policies</b> tend to discourage users from reading them. We describe a pilot experiment to use automatic text categorization to answer simple categorical questions about <b>privacy</b> <b>policies,</b> {{as a first step}} toward developing automated or semi-automated methods to retrieve salient features from these policies. Our results tentatively demonstrate the feasibility of this approach for answering selected questions about <b>privacy</b> <b>policies,</b> suggesting that further work toward user-oriented analysis of these policies could be fruitful...|$|R
40|$|A {{letter report}} {{issued by the}} General Accounting Office with an {{abstract}} that begins "Pursuant to a congressional request, GAO provided information on whether agencies were adhering to the Office of Management and Budget's (OMB) memorandum requiring federal agencies to post <b>privacy</b> <b>policies</b> on their Internet Websites, focusing on: (1) whether agencies have clearly labelled and easily accessed <b>privacy</b> <b>policies</b> posted on their principal Web sites; (2) whether agencies' <b>privacy</b> <b>policies</b> posted on their principal Web sites inform visitors about what information an agency collects, why the agency collects it, and how the agency will use the information; (3) how selected agencies have interpreted the requirement to post <b>privacy</b> <b>policies</b> at major entry points; and (4) whether selected agencies have posted <b>privacy</b> <b>policies</b> on Web pages where the agency collects substantial personal information or when applicable, notices that refer to the Privacy Act of 1974. ...|$|R
40|$|Abstract [...] Privacy has {{recently}} become a prominent {{issue in the}} context of electronic commerce Web sites. Increasingly, <b>privacy</b> <b>policies</b> posted on such Web sites are receiving considerable attention from the government and consumers. In this paper we present a taxonomy for Web site privacy requirements. We have used goal-mining, the extraction of pre-requirements goals from post-requirements text artifacts, as a technique for analyzing <b>privacy</b> <b>policies.</b> The identified goals are useful for analyzing implicit internal conflicts within <b>privacy</b> <b>policies</b> and conflicts with the corresponding web sites and their manner of operation. These goals {{can also be used to}} reconstruct the implicit requirements met by the <b>privacy</b> <b>policies.</b> We present the results of our analysis of 23 Internet <b>privacy</b> <b>policies</b> for companies in three health care industries: pharmaceutical, health insurance and online drugstores. Index Terms—Requirements engineering, privacy requirements, internet security and privacy, goal-driven requirements analysis...|$|R
25|$|During the campaign's summer 2007 {{financial}} woes, it used a list {{of donors}} as collateral {{in order to get}} approval on a bank loan. This raised {{the question of whether the}} campaign's <b>privacy</b> <b>policy</b> was violated by such a use. A McCain spokesperson said it did not, since all of the campaign's assets were pledged as collateral at the time, not just the donor list.|$|E
25|$|As part of {{the social}} {{networking}} functionality, information about what content users watch is transmitted to Boxee.tv Inc's servers. Concerns have arisen over the use of this information, as Boxee is being created by a for-profit company and possible revenue-generation models for media center applications include the sale of user activity data to advertisers and other interested parties. Boxee's <b>privacy</b> <b>policy</b> does not directly address this issue.|$|E
25|$|Privacy advocates raised {{concerns}} about this practice; concerns included that allowing email content to be read by a machine (as opposed to a person) can allow Google to keep unlimited amounts of information forever; the automated background scanning of data raises {{the risk that the}} expectation of privacy in email usage will be reduced or eroded; information collected from emails could be retained by Google for years after its current relevancy to build complete profiles on users; emails sent by users from other email providers get scanned despite never having agreed to Google's <b>privacy</b> <b>policy</b> or terms of service; Google can change its <b>privacy</b> <b>policy</b> unilaterally, and for minor changes to the policy it can do so without informing users; in court cases, governments and organizations can potentially find it easier to legally monitor email communications; at any time, Google can change its current company policies to allow combining information from emails with data gathered from use of its other services; and any internal security problem on Google's systems can potentially expose many - or all - of its users.|$|E
40|$|Online <b>privacy</b> <b>policies</b> are {{important}} mechanisms for informing web site users {{about the level}} of information privacy protection afforded when visiting web sites. To date, societal mechanisms and technologies have been the focus of attempts to improve the quality and effectiveness of online <b>privacy</b> <b>policies.</b> Little attention, however, has been given to the development and use of organisational measures for this purpose. In this paper we present findings from an empirical study of online <b>privacy</b> <b>policies,</b> resulting in a set of organisational guidelines for effective online <b>privacy</b> <b>policies,</b> which extend the research base in this area and, more immediately, will assist companies concerned about the impact of privacy concerns on consumer web usage...|$|R
40|$|This project {{describes}} the continuing {{development of a}} Privacy Label to present to consumers the ways organizations collect, use, and share personal information. Several studies have indicated the importance of privacy for consumers, yet current mechanisms to present <b>privacy</b> <b>policies</b> of websites have not been successful. This research addresses the present gap in the communication and understanding of <b>privacy</b> <b>policies,</b> by creating an information design that improves the visual presentation and comprehensibility of <b>privacy</b> <b>policies.</b> Drawing from the nutrition, warning, and energy labeling, {{as well as from}} the effort towards creating a standardized banking privacy notification, I present the process and ongoing results of the development of a usable information design for <b>privacy</b> <b>policies...</b>|$|R
40|$|Abstract. Privacy {{has become}} a {{significant}} concern in modern society as personal information about individuals is increasingly collected, used, and shared, often using digital technologies, by {{a wide range of}} organizations. To mitigate privacy concerns, organizations are required to respect privacy laws in regulated sectors (e. g., HIPAA in healthcare, GLBA in financial sector) and to adhere to self-declared <b>privacy</b> <b>policies</b> in self-regulated sectors (e. g., <b>privacy</b> <b>policies</b> of companies such as Google and Facebook in Web services). This article provides an overview of a body of work on formalizing and enforcing <b>privacy</b> <b>policies.</b> We formalize <b>privacy</b> <b>policies</b> that prescribe and proscribe flows of personal information as well as those that place restrictions on the purposes for which a governed entity may use personal information. Recognizing that traditional preventive access control and information flow control mechanisms are inadequate for enforcing such <b>privacy</b> <b>policies,</b> we develop principled accountability mechanisms that seek to encourage policy-compliant behavior by detecting policy violations, assigning blame, and punishing violators. We apply these techniques to several U. S. privacy laws and organizational <b>privacy</b> <b>policies,</b> in particular, producing the first complete logical specification and audit of all disclosure-related clauses of the HIPAA Privacy Rule. ...|$|R
25|$|Pressure on Switzerland {{has been}} applied by several states and {{international}} organizations attempting to alter the Swiss <b>privacy</b> <b>policy.</b> The European Union, whose member countries geographically surround Switzerland, has complained about member states' nationals using Swiss banks to avoid taxation in their home countries. The EU has long sought a harmonized tax regime among its member states, although many Swiss banking officials (and, according to some polls, the public) are resisting any such changes.|$|E
25|$|In June 2016, Julia Angwin of ProPublica {{wrote about}} Google's updated <b>privacy</b> <b>policy,</b> which deleted a clause that had stated Google would not combine DoubleClick web {{browsing}} cookie information with {{personally identifiable information}} from its other services. This change has allowed Google to merge users’ personally identifiable information from different Google services to create one unified ad profile for each user. After publication of the article, Google reached out to ProPublica {{to say that the}} merge would not include Gmail keywords in ad targeting.|$|E
25|$|In May 2011, Soghoian filed a {{complaint}} with the FTC, in which he claimed that online backup service Dropbox was deceiving its customers about the security of its services. Soon after Soghoian first publicly voiced his concerns, Dropbox updated its terms of service and <b>privacy</b> <b>policy</b> to make it clear that the company does not in fact encrypt user data with a key only known to the user, and that the company can disclose users' private data if forced to by law enforcement agencies.|$|E
40|$|Default <b>privacy</b> <b>policies</b> have a {{significant}} impact on the overall dynamics and success of online social networks, as users tend to keep their initial <b>privacy</b> <b>policies.</b> In this work-inprogress, we present a new method for suggesting <b>privacy</b> <b>policies</b> for new users by exploring knowledge of existing policies. The defaults generation process performs a collaborative analysis of the policies, finding personalized and representative suggestions. We show how the process can be extended to a wide range of domains, and present results based on 543 <b>privacy</b> <b>policies</b> obtained from a live location-based social network. Finally, we present a user interaction model that lets the user retain control over the default policies, allowing the user to make knowledgeable decisions regarding which default policy to take. Keywords information disclosure, <b>privacy,</b> default <b>policies,</b> online social networks, location sharing technology Copyright is held by the author/owner(s) ...|$|R
50|$|In some cases, {{private parties}} enforce {{the terms of}} <b>privacy</b> <b>policies</b> by filing class action lawsuits, which may result in {{settlements}} or judgments. However, such lawsuits are often not an option, due to arbitration clauses in the <b>privacy</b> <b>policies</b> or other terms of service agreements.|$|R
40|$|Librarians have a {{long history}} of {{protecting}} user privacy, but they have done seemingly little to understand or influence the <b>privacy</b> <b>policies</b> of library resource vendors that increasingly collect user information through Web 2. 0 -style personalization features. After citing evidence that college students value privacy, this study used content analysis to determine the degree to which the <b>privacy</b> <b>policies</b> of 27 major vendors meet standards articulated by the library profession and information technology industry. While most vendors have <b>privacy</b> <b>policies,</b> the policy provisions fall short on many library profession standards and show little support for the library Code of Ethics...|$|R
25|$|In 1998, {{the company}} faced heavy {{criticism}} because privacy groups {{alleged that the}} RealJukebox software program incorporated spyware to track unsuspecting users' listening patterns and download history. In response, RealNetworks amended its <b>privacy</b> <b>policy</b> to fully disclose its privacy practices regarding user listening patterns. Subsequently, RealNetworks submitted to independent outside audits of its privacy practices. Several lawsuits regarding the alleged privacy violations were settled out of court. This incident has in part formed her views on privacy and thus her opposition to the Bush administration's post-9/11 policies.|$|E
25|$|In 2013, {{a formal}} {{complaint}} on the shopping lens was {{filed with the}} Information Commissioner's Office (ICO), the UK data privacy office. Almost one year later the ICO ruled in favour of Canonical, considering the various improvements introduced to the feature in the meantime to render it conformable with the Data Protection Directive. According to European rules, this ruling is automatically effective in {{the entirety of the}} European Union. However, the ruling also made clear {{that at the time of}} introduction the feature was not legal, among other things, since it was missing a <b>privacy</b> <b>policy</b> statement.|$|E
25|$|In August 2009, a Rocky Mountain Bank {{employee}} {{was asked}} by a customer to forward loan reports to the customer's agent. Instead, the employee mistakenly sent the email to a different account and mistakenly included a file of sensitive loan details from 1,325 individual and business customers. He emailed the Gmail user, asking the user to contact the bank and delete the email. Because the user was unresponsive, the employee asked Google to divulge the user's identity. Pursuant to its <b>privacy</b> <b>policy,</b> Google refused, noting that the bank needed to obtain {{a court order to}} obtain the information.|$|E
40|$|Website {{and mobile}} {{application}} <b>privacy</b> <b>policies</b> are intend-ed {{to describe the}} system’s data practices. However, they are often written in non-standard formats and contain ambi-guities that {{make it difficult for}} users to read and compre-hend these documents. We propose a crowdsourcing ap-proach to extract data practices from <b>privacy</b> <b>policies</b> to provide more concise and useable privacy notices to users and support the analysis of stated data practices. To that end, we designed a hierarchical task workflow for crowdsourcing the extraction of data practices from <b>privacy</b> <b>policies.</b> We discuss our workflow design and report prelim-inary results...|$|R
40|$|Simple Privacy {{provides}} {{a system for}} Australian organisations to create <b>privacy</b> <b>policies</b> for the personal information they collect online. The <b>privacy</b> <b>policies</b> it creates are legally compliant and easy to understand. We developed this system because small Australian organisations seemed to find <b>privacy</b> <b>policies</b> too complicated to manage with the resources they have available. This paper describes the framework behind Simple Privacy and discusses the choices that we made during development. These choices balance {{the requirements of the}} privacy legislation and the needs of both organisations and customers...|$|R
50|$|Some {{websites}} also {{define their}} <b>privacy</b> <b>policies</b> using P3P or Internet Content Rating Association (ICRA), allowing browsers to automatically assess {{the level of}} privacy offered by the site, and allowing access only when the site's privacy practices {{are in line with}} the user's privacy settings. However, these technical solutions do not guarantee websites actually follows the claimed <b>privacy</b> <b>policies.</b> They also require users to have a minimum level of technical knowledge to configure their own browser privacy settings. These automated <b>privacy</b> <b>policies</b> have not been popular either with websites or their users.|$|R
