28|6|Public
40|$|The {{feasibility}} of structuring the satellite <b>photogrammetric</b> <b>triangulation</b> as an iterative Extended Kalman estimation algorithm is demonstrated. Comparative numerical {{results of the}} sequential against batch estimation algorithm are presented. Difficulty of accurately modeling of the attitude motion is overcome by utilizing the on-board angular rate measurements. Solutions of the differential equations and the evaluation of state transition matrix are carried out numerically...|$|E
40|$|A {{method for}} {{experimentally}} determining the radial {{distance of a}} probe aircraft from a trailing vortex is described. The method relies on <b>photogrammetric</b> <b>triangulation</b> of targets entrained in the vortex core. The theory and preliminary testing were described using laboratory mock-ups. Solid state video cameras were to provide data at 300 Hz rates. Practical methods for seeding the vortex are under separate investigation and are not addressed...|$|E
40|$|Laser {{scanning}} (LIDAR) is {{a recent}} technology that is receiving an increasing interest from professionals dealing with mapping applications. The interest in LIDAR is attributed to the rich geometric surface {{information provided by the}} data in the form of dense non-selective points. On the other hand, photogrammetric processing of stereo-images provides an accurate surface model represented by few points as well as a wealth of semantic information about the photographed objects. Considering the nature of photogrammetric and LIDAR data, {{it is clear that the}} two systems provide complementary information. However, the complementary information can only be fully utilized after successful alignment/absolute orientation of the photogrammetric and LIDAR models relative to a common reference frame. This paper deals with two alternative approaches for utilizing linear features derived from LIDAR data as control information for aligning the photogrammetric model relative to the LIDAR reference frame. The first approach incorporates LIDAR lines as control information directly in a <b>photogrammetric</b> <b>triangulation.</b> The second approach starts by generating a photogrammetric model through a <b>photogrammetric</b> <b>triangulation</b> using an arbitrary datum (no control information). LIDAR features are then used as control information for the absolute orientation of the photogrammetric model. A mathematical model is derived to utilize the LIDAR features for the absolute orientation of the photogrammetric model. These features can be extracted from range data using various methods. For example, planar patches can be extracted from 3 dimensional LIDAR data through segmentation techniques. Then, neighbouring planar patches can be intersected to generate linea...|$|E
50|$|Hexagon - Intergraph: Hexagon Geospatial {{provides}} <b>photogrammetric</b> {{tools for}} <b>triangulation,</b> real stereo visualization, terrain generation and editing, orthomosaic creation and 3D feature extraction.|$|R
40|$|This {{research}} {{has sought to}} demonstrate the benefits of kinematic GPS in conjunction with <b>photogrammetric</b> aerial <b>triangulation</b> for mapping purposes. The work was performed with the existing INDOT aerial camera which is quite old, and while this affected {{the accuracy of the}} results, the demonstration of capability with a likely potential for excellent results was achieved. Ground point accuracies from the strip were in the sub-meter range with only a single control point. This is contrasted with full-model control requiring 50 - 80 control points for such a strip. In order to bring accuracies down to an acceptable level, i. e. sub decimeter, {{it will be necessary to}} retrofit the INDOT camera with a better shutter event signal (or obtain a new camera). A computer program for least squares adjustment of independent models has been developed. This would permit processing of data from INDOT Wild B 8 stereoplotters. With a few implementation steps, INDOT would have an operational and production capability yielding significant productivity improvements...|$|R
40|$|Traditional field {{methods for}} {{measuring}} tree heights are often too costly and time consuming. An alternative remote sensing {{approach is to}} measure tree heights from digital stereo photographs which is more practical for forest managers and less expensive than LiDAR or synthetic aperture radar. This work proposes an estimation of stand height and forest volume(m 3 /ha) using normalized digital surface model (nDSM) from high resolution stereo photography (25 cm resolution) and forest type map. The study area was located in Mt. Maehwa model forest in Hong Chun-Gun, South Korea. The forest type map has four attributes such as major species, age class, DBH class and crown density class by stand. Overlapping aerial photos were taken in September 2013 and digital surface model (DSM) was created by <b>photogrammetric</b> methods(aerial <b>triangulation,</b> digital image matching). Then, digital terrain model (DTM) was created by filtering DSM and subtracted DTM from DSM pixel by pixel, resulting in nDSM which represents object heights (buildings, trees, etc.). Two independent variables from nDSM were used to estimate forest stand volume: crown density (...|$|R
40|$|Viking Orbiter {{images of}} Phobos and Deimos have been {{measured}} to establish global control networks for 98 surface {{features of the}} former and 53 of the latter; <b>photogrammetric</b> <b>triangulation</b> has yielded body-fixed coordinates of these control-points, as well as mean triaxial radii of 13. 3 x 11. 1 x 9. 3 km for Phobos and 7. 5 x 6. 2 x 5. 4 for Deimos. Expressions are also obtained for the inertial orientations of these bodies' spin axes and prime meridians. While these expressions should be accurate to a few tenths of a deg for the 1971 - 1980 period, their accuracy will degrade with time as the orbit accuracy degrades...|$|E
40|$|Photogrammetric {{manipulation}} of imagery has been, {{for the major}} part, a point-based operation. The utilization of points remains to be convenient since few manually digitized points can be accurately obtained to carry out various photogrammetric orientation procedures (e. g., relative and absolute orientation as well as <b>photogrammetric</b> <b>triangulation).</b> On the other hand, the constant evolution of digital photogrammetry calls {{for the use of}} other primitives since distinct points fall short when attempting to derive higher level/semantic information from the input imagery. As a result, there has been a tremendous interest by photogrammetric researchers in utilizing linear features in various photogrammetric activities. This interest is attributed {{to the fact that the}} extraction of linear features from the image space is easier to automate than distinct points. On the other hand, object space linear features can be directly derived form terrestrial Mobile Mapping Systems (MMS), GIS databases, and/or existing maps. Moreover, automatic matching of linear features, either within overlapping images or between image and object space, is easier than that of distinct points. Finally, linear features possess more semantic information than distinct points since they likely correspond to object boundaries. Such semantics can be automatically identified in the input imagery to facilitate higher-level tasks (e. g., surface reconstruction and object recognition). This paper summarizes the authors ’ prior research using linear features, which might be represented by analytical functions (e. g., straight-line segments) or irregular (free-form) shapes, in photogrammetric activities such as automatic space resection, <b>photogrammetric</b> <b>triangulation,</b> camera calibration, image matching, surface reconstruction, image registration, and absolute orientation as well as in medical applications. Current progress, future expectations, and possible research directions ar...|$|E
40|$|Maps of Venus {{based on}} Magellan data are being {{compiled}} at 1 : 50, 000, 000, 1 : 5, 000, 000 and 1 : 1, 500, 000 scales. Topographic contour lines based on radar altimetry data are overprinted {{on the image}} maps, along with feature nomenclature. Map controls are based on existing knowledge of the spacecraft orbit; <b>photogrammetric</b> <b>triangulation,</b> a traditional basis for geodetic control for bodies where framing cameras were used, is not feasible with the radar images of Venus. Preliminary synthetic aperture radar (SAR) image maps have some data gaps and cosmetic inconsistencies, which will be corrected on final compilations. Eventual revision of geodetic controls and of the adopted Venusian spin-axis location will result in geometric adjustments, particularly on large-scale maps...|$|E
40|$|Jakobshavns Isbrae (69 o 10 'N, 49 o 59 'W) drains about 6. 5 {{percent of}} the Greenland Ice Sheet and is the fastest ice stream known. The Jakobshavns Isbrae basin of about 10, 000 km 2 was mapped photogrammetrically from four sets of aerial photography, two taken in July 1985 and two in July 1986. Positions and {{elevations}} of several hundred natural features on the ice surface were determined for each epoch by <b>photogrammetric</b> block aerial <b>triangulation,</b> and surface velocity vectors were computed from the positions. The two flights in 1985 yielded the best results and provided the most common points (716) for velocity determinations and are therefore used in the modeling studies. The data at these irregularly spaced points were used to calculate ice elevations and velocity vectors at uniformly spaced gridpoints 3 km apart by interpolation. The field of surface strain rates was then calculated from this gridded data and used to compute the field of surface deviatoric stresses, using t [...] ...|$|R
40|$|Recent {{developments}} of 3 D technologies and tools have increased availability and relevance of 3 D data (from 3 D points to complete city models) in the geospatial and geo-information domains. Nevertheless, {{the potential of}} 3 D data is still underexploited and mainly confined to visualization purposes. Therefore, the major challenge today is to create automatic procedures that make best use of available technologies and data for the benefits and needs of public administrations (PA) and national mapping agencies (NMA) involved in “smart city” applications. The paper aims to demonstrate a step forward in this process by presenting {{the results of the}} SENECA project (Smart and SustaiNablE City from Above – [URL]). State-of-the-art processing solutions are investigated in order to (i) efficiently exploit the <b>photogrammetric</b> workflow (aerial <b>triangulation</b> and dense image matching), (ii) derive topologically and geometrically accurate 3 D geo-objects (i. e. building models) at various levels of detail and (iii) link geometries with non-spatial information within a 3 D geo-database management system accessible via web-based client. The developed methodology is tested on two case studies, i. e. the cities of Trento (Italy) and Graz (Austria). Both spatial (i. e. nadir and oblique imagery) and non-spatial (i. e. cadastral information and building energy consumptions) data are collected and used as input for the project workflow, starting from 3 D geometry capture and modelling in urban scenarios to geometry enrichment and management within a dedicated webGIS platform...|$|R
40|$|The {{availability}} of digital imagery {{gives rise to}} the use of linear features as an additional source of information, or as an alternative to using point features. There are many kinds of linear features. In this thesis, research is focused on straight lines and circles, since they are more frequently encountered in practice than other kinds of linear features. Different parameterization and mathematical modeling for representation of these linear features in both two and three dimensional spaces are developed. Geometric constraints among linear features are also enumerated and functionally described. These constraints provide significant information regarding the exploitation of linear features. ^ There are three main operations involved in the exploitation of linear features for applications in photogrammetry. The first is linear feature extraction or measurement. Before linear features can be extracted from an image, edge pixels designating linear features need to be detected. A concise discussion on edge detection is first presented before different linear feature extraction techniques are reviewed. Some of these techniques are then adopted for use in this research. ^ The second operation involves linear feature matching, in which the correspondence between linear features from overlapping images is established. Previous work related to linear feature matching, especially straight line matching, is reviewed. Different techniques which can be combined for straight line matching are then listed. ^ The last operation deals with <b>photogrammetric</b> image <b>triangulation</b> and object reconstruction. Mathematical equations for various two- and three-dimensional coordinate transformations and photogrammetric conditions needed for both tasks are derived. The developed equations are employed, with the technique of unified least squares adjustment, in several photogrammetric applications, especially image triangulation. An extensive number of experiments, using synthetic and real data, have been performed to test the developed mathematical models and to study the effectiveness of the exploitation of linear features in photogrammetric applications. Results from a representative set of the experiments are shown and analyzed. ^ In the last several years, there has {{been a great deal of}} effort attempted at automation of various photogrammetric applications. Many techniques have been developed to reach the ultimate goal where human activity is not required. Such techniques usually work under very restricted conditions. This research follows the philosophy where the human operator 2 ̆ 7 s role is to supervise the automated tools provided in the system. A set of automated tools developed for object reconstruction based on linear features is described and their use in a human-supervised approach on a digital photogrammetric workstation, which was used as a development platform, is described. ...|$|R
40|$|This paper proposes {{the quick}} {{use of the}} <b>photogrammetric</b> <b>triangulation</b> to survey and monitor landslides, by using non-metric images taken from ground and/or from {{helicopter}} by a CCD. Is then possible achieve with rapidity and precision a 3 D numerical model of the landslide morphology, {{as soon as it}} has happened, and monitor with data processing procedures its spatial evolution in the time, on the base of images and/or measures later acquired. The application of the non-metric triangulation (bundle adjustment) allows to dramatically reduce the control point number to acquire with topographic instrumentation, limiting or even eliminating the times/costs for measures on inaccessible points and/or in no-safety conditions. The experimentation to a case study has shown the good obtainable precision with this quick method of digital photogrammetry. Considering the very short operation time, it could also be applied for the precision survey of a landslide to plan the emergency stabilization operations...|$|E
40|$|Camera {{calibration}} {{has always}} been an essential component of photogrammetric measurement, with self-calibration nowadays being an integral and routinely applied operation within <b>photogrammetric</b> <b>triangulation,</b> especially in high-accuracy close-range measurement. With the very rapid growth in adoption of off-the-shelf digital cameras for a host of new 3 D measurement applications, however, there are many situations where the geometry of the image network will not support robust recovery of camera parameters via on-the-job calibration. For this reason, stand-alone camera calibration has again emerged as an important issue in close-range photogrammetry, and it also remains a topic of research interest in computer vision. This paper overviews the current approaches adopted for camera calibration in close-range photogrammetry and computer vision, and discusses operational aspects for self-calibration. Also, the results of camera calibrations using different algorithms are summarized. Finally, the impact of chromatic aberration on modelled radial distortion is touched upon to highlight {{the fact that there are}} still issues of research interest in the photogrammetric calibration of consumer-grade digital cameras. 1...|$|E
40|$|The multi-epoch {{deformation}} {{monitoring of}} a series of super-hot steel beams by digital close-range photogrammetry is reported. An on-line configuration of three CCD cameras was established to measure both stable reference points and targets subject to positional displacement. Measurements for each beam were conducted at 70 - 80 epochs over two hours as the steel cooled from 1100 C to near room temperature. Special targeting was required to accommodate the changing colour of the beams from white-hot to brown as they cooled and ensure target survival through a large temperature range. A computational approach was employed whereby the <b>photogrammetric</b> <b>triangulation</b> process for any given recording epoch utilised all images obtained up until that time. The paper discusses all aspects of the project in which seven beams were monitored to a dimensional tolerance of close to 1 mm (RMS 1 -sigma). Key Words: vision metrology; deformation measurement; multi-epoch data processing; automated image measurement...|$|E
40|$|Abstract—Advances {{technology}} {{in the field of}} photogrammetry replaces analog cameras with reflection on aircraft GPS/IMU system with a digital aerial camera. In this system, when determining the position of the camera with the GPS, camera rotations are also determined by the IMU systems. All around the world, digital aerial cameras have been used for the photogrammetry applications in the last ten years. In this way, in terms of the work done in photogrammetry it is possible to use time effectively, costs to be reduced to a minimum level, the opportunity to make fast and accurate. Geo-referencing techniques that are the cornerstone of the GPS / INS systems, <b>photogrammetric</b> <b>triangulation</b> of images required for balancing (interior and exterior orientation) brings flexibility to the process. Also geo-referencing process; needed in the application of photogrammetry targets to help {{to reduce the number of}} ground control points. In this study, the use of direct and indirect geo-referencing techniques on the accuracy of the points was investigated in the production of photogrammetric mapping...|$|E
40|$|Georeferencing of {{multi-line}} CCD array {{optical sensors}} {{with a general}} photogrammetric model Abstract — This paper describes a general sensor model for the georeferencing of imagery from CCD linear array sensors with along-track stereo viewing. The software combines the standard <b>photogrammetric</b> <b>triangulation</b> with a sensor external orientation modeling and self-calibration. The sensor attitude and position, which are different for each image-line, are modeled with timedependent piecewise polynomial functions while the systematic errors due to lens distortions are described by additional parameters. In case of sensors whose optical system consists of more lenses, the collinearity equations are extended in order to include additional parameters describing the relative orientations of each lens. Using Ground Control Points (GCPs) and, additionally, Tie Points (TPs), the functions parameters and the ground coordinates of the TPs are estimated in a least-squares adjustment. The described procedures have been applied to imagery from different CCD linear sensors carried on airplane and satellite. In particular, the results obtained with MOMS-P 2 imagery are presented and discussed. Pushbroom; sensor modelling; external orientation; selfcalibration; indirect georeferencing I...|$|E
40|$|Commission V, WG V/ 1 Camera {{calibration}} {{has always}} been an essential component of photogrammetric measurement, with self-calibration nowadays being an integral and routinely applied operation within <b>photogrammetric</b> <b>triangulation,</b> especially in high-accuracy close-range measurement. With the very rapid growth in adoption of off-the-shelf digital cameras for a host of new 3 D measurement applications, however, there are many situations where the geometry of the image network will not support robust recovery of camera parameters via on-the-job calibration. For this reason, stand-alone camera calibration has again emerged as an important issue in close-range photogrammetry, and it also remains a topic of research interest in computer vision. This paper overviews the current approaches adopted for camera calibration in close-range photogrammetry and computer vision, and discusses operational aspects for self-calibration. Also, the results of camera calibrations using different algorithms are summarized. Finally, the impact of chromatic aberration on modelled radial distortion is touched upon to highlight {{the fact that there are}} still issues of research interest in the photogrammetric calibration of consumer-grade digital cameras. 1...|$|E
40|$|The {{wide variety}} of uses of {{measurements}} from imagery to provide spatial information for medicine and human sciences is categorized into three distinct groups. The first category of applications involves surface shape measurement of {{any part of the}} body, whether very small or large. It is now commonly undertaken by laser scanning and structured light measurement, and finds uses in plastic surgery, reconstructive medicine, orthopaedics, prosthetics orthodontics and other dentistry, dermatology and cosmetics. The second group involves the recording of the human body in motion, which is widely used predominantly but not solely for studies of walking people. The third group represents the most novel application: the surgical use of realtime measurement to precisely position surgical instruments and prostheses in the operating theatre. The latter two fields are distinguished from the first by being well suited to conventional <b>photogrammetric</b> <b>triangulation</b> using camera imagery in conjunction with the matching of features in the images. This chapter identifies the main challenges in these three groups, specifies the technical features which characterize each, and records some of the applications for purposes involving human beings...|$|E
40|$|ABSTRACT: In this study, we {{developed}} a newly designed portable panoramic image mapping system (PPIMS). It is specially designed for some areas that a vehicle-based mapping system {{is not allowed to}} enter. PPIMS can capture eight images simultaneously with e-GPS positioning. When images are taken from multiple stations, a large amount of images are needed to handle. Finding targets among images becomes a puzzled task. To resolve this difficulty, this study proposes a new concept of photogrammetry by using panoramic images. Eight images captured by PPIMS can form a spherical panorama image (SPI). Instead of using the original images, PPIMS SPIs are used for <b>photogrammetric</b> <b>triangulation</b> and mapping. Because the collinearity condition is not rigorously kept that causes a certain amount of error in multi-station network adjustment. We also propose a method to correct the imperfect geometry of PPIMS SPI. Two experiments were done. One is on the test field at Tzu-Chiang Campus, NCKU, Taiwan, and the other is at the Eternal Golden Castle. Both of them reveal bundle adjustment of SPI is feasible, and applying corrections for PPIMS SPIs is necessary and effective for bundle adjustment...|$|E
40|$|Terrestrial {{laser scanner}} {{technology}} is, today, one {{the most widely}} investigated topics in architectural applications. While the acquisition and filtering of the recorded points are well known procedures, the registration of adjacent scans is still a not completely investigated field. The registration of two adjacent scans with a large overlap can be properly solved either by using an interactive procedure (manual selection of homologous points) or automatically by using reflecting targets. Alternatively automatic registration can be performed by means of shape-reasoning procedure (e. g. spin images). Some practical problems arise when the object to be surveyed is large {{and one or two}} scans are not sufficient to geometrically describe it,. First of all the overlap between two adjacent scans must be reduced in order to speed up the acquisition phase; in a second step an “ad hoc ” registration procedure must be conceived to avoid propagation errors. The paper shows the effect of the registration of multiple scans acquired in order to survey a large object and describes a procedure for the registration of multiple scans with minimum overlapping using the experience of <b>photogrammetric</b> <b>triangulation</b> adjustment. 1...|$|E
40|$|Semicontrolled image mosaics of Venus, {{based on}} Magellan data, are being {{compiled}} at 1 : 50, 000, 000, 1 : 10, 000, 000, 1 : 5, 000, 000, and 1 : 1, 000, 000 scales {{to support the}} Magellan Radar Investigator (RADIG) team. The mosaics are semicontrolled {{in the sense that}} data gaps were not filled and significant cosmetic inconsistencies exist. Contours are based on preliminary radar altimetry data that is subjected to revision and improvement. Final maps to support geologic mapping and other scientific investigations, to be compiled as the dataset becomes complete, will be sponsored by the Planetary Geology and Geophysics Program and/or the Venus Data Analysis Program. All maps, both semicontrolled and final, will be published as I-maps by the United States Geological Survey. All of the mapping is based on existing knowledge of the spacecraft orbit; <b>photogrammetric</b> <b>triangulation,</b> a traditional basis for geodetic control on planets where framing cameras were used, is not feasible with the radar images of Venus, although an eventual shift of coordinate system to a revised spin-axis location is anticipated. This is expected to be small enough that it will affect only large-scale maps...|$|E
40|$|In {{this work}} an {{alternative}} method, respect today’s tipical road survey, is presented. Tipically, a road survey {{is carried out}} by a team composed by three operators at least, that moves with a vehicle on which an odometer is mounted on the rear {{in order to measure}} the effective travelled road. Given this operational procedure, a road survey requires, as a rule, a lot of time, resulting therefore very laborious and expensive regarding the employement of economic and human resources. Possible solutions to these problems could be represented by integration of Computer Vision technology with modern satellite positioning system, as GPS. Also in agreement with this idea, GeoVision, a digital photogrammetric software for road survey, has been developed at the University of Padua (Italy). The system consists of a van equipped with two digital cameras, Sony XC 75 CE recording in continous way the surveyed environment and a GPS receiver that provides post-processed differential positions. From a pair of correspondent digital images, the 3 D position of a feature can be determined in a global reference system (namely WGS- 84), by integration of <b>photogrammetric</b> <b>triangulation</b> techniques and computer vision algoritms. In following sections the tools regarding digital image processing subsystem of GeoVision will be described in detail...|$|E
40|$|This paper {{describes}} a general sensor {{model for the}} georeferencing of imagery from CCD linear array sensors with along-track stereo viewing, carried on airplane or satellite. The model combines the standard <b>photogrammetric</b> <b>triangulation</b> with a sensor external orientation modeling. The sensor attitude and position, which are different for each image-line, are modeled with time-dependent piecewise polynomial functions and integrated in the collinearity equations, resulting in an indirect georeferencing model. The continuity of the functions and their first and second derivatives between adjacent segments is imposed. If GPS and INS systems are carried on board and provide the sensor external orientation of each line, the observed sensor position and attitude {{are included in the}} piecewise polynomial functions. Using Ground Control Points (GCPs) and, additionally, Tie Points (TPs), the functions parameters and the ground coordinates of the TPs are estimated in a least-squares adjustment. In case of sensors whose optical system consists of more lenses, the collinearity equations are extended in order to include additional parameters describing the relative orientations of each lens. The described procedures have been applied to imagery from two multi-lens sensors carried on airplane (TLS) and satellite (MOMS- 02). The results are presented and discussed, together with the future model extensions and applications...|$|E
40|$|The latest {{generation}} of high-resolution commercial imaging satellites, such as IKONOS and QuickBird, {{has opened a}} new era of earth observation and digital mapping. This paper presents the geometric modeling principles and photogrammetric processing methods involved in high-precision mapping using stereo IKONOS and QuickBird images. First, the imaging geometry and systematic errors in the Rational Function-based sensor model are described. Then the results of a comparison study of IKONOS and QuickBird geopositioning accuracy improvement in which different adjustment models, as well as different number and configuration of ground control points, are presented. Results indicate that a simple adjustment model (e. g., Affine or Scale & Translation) is effective for elimination of the systematic errors found in vendor-provided RFCs (Rational Function Coefficients) and for improvement of 3 D geopositioning accuracies to a 1 - 2 m level for IKONOS images and a 0. 6 - 1 m level for QuickBird images. For coastal mapping purposes, a semi-automatic 3 D shoreline extraction method is proposed. In this method, a 2 D shoreline is extracted by manual digitizing on one QuickBird image; then corresponding shoreline points on the other image of the stereo pair are automatically extracted by image matching. The 3 D shoreline is computed using <b>photogrammetric</b> <b>triangulation</b> with the improved geometric model...|$|E
40|$|ABSTRACT: This article {{describes}} the sensor modeling and the <b>photogrammetric</b> <b>triangulation</b> procedure for the TLS (Three-Line-Scanner) system. This system is a new airborne digital sensor, developed by STARLABO Corporation, Tokyo jointly with the Institute of Industrial Science, University of Tokyo. It utilizes the Three-Line-Scanner principle to capture digital image triplets in along-strip mode. The imaging system contains three times three (RGB) one-dimensional CCD arrays, with 10 200 pixels of 7 µm each, mounted {{parallel to each other}} in the focal plane. They produce seamless high-resolution images (5 - 10 cm footprint on the ground) with three viewing directions (forward, nadir and backward). In order to get precise attitude data and high quality image data from an aerial platform, a high quality stabilizer stabilizes the camera and outputs attitude data at 500 Hz. A Trimble MS 750 serves as Rover GPS and collects L 1 /L 2 kinematic data at 5 Hz and another Trimble MS 750 serves as Base GPS on the ground. The position and attitude elements measured by the on-board GPS/INS do not refer to the perspective center of the imaging camera. Additionally, there is a boresight misalignment between the axes of the INS and the camera. These translational and rotational offsets have been taken into account in our sensor model and triangulation procedures. In our experiments, the following 3 trajectory model ar...|$|E
40|$|The {{availability}} of high accuracy position and orientation information {{obtained from the}} integration of GPS and inertial systems allows the direct determination of the image orientation parameters {{without the need for}} ground control points. Although several advantages are offered by the direct sensor orientation, precaution should be taken when dealing with multi-sensor systems. In GPS/INS-assisted photogrammetric systems, besides the camera calibration, the geometric relationship between the sensors (mounting parameters) must be known as well. More specifically, the lever-arm offset between the sensors, as well as the misalignment (boresight angles) between the IMU body frame and the photogrammetric camera should be determined. The offsets are usually measured using traditional surveying techniques, while approximate values for the boresight angles are known from the mechanical alignment. Since these initial mounting parameters might be biased, they should be refined through an in-flight calibration. The objective {{of this paper is to}} investigate the aspects involved in the design and implementation of an in-flight mounting parameters calibration, as they relate to control and flight configuration requirements. The paper starts with a brief discussion of the concept and prerequisites of GPS/INS-assisted <b>photogrammetric</b> <b>triangulation</b> procedure. Then, a mathematical analysis of the GPS/INS-assisted camera point-positioning equation, leading to the determination of the flight configuration and the control requirements for mounting parameters estimation, is performed. The presented analysis is evaluated through experimental results using simulated and real datasets. 1...|$|E
40|$|A {{great deal}} of {{interest}} has arisen lately {{in the application of}} expert systems to problems in which computer solutions were previously inapplicable. The aim of this research was to explore the application of expert systems to digital photogrammetry, specifically to <b>photogrammetric</b> <b>triangulation,</b> feature extraction, and photogrammetric problem solving. In 1987, prototype expert systems were developed for doing system startup, interior orientation, and relative orientation in the mensuration stage. The system explored means of performing diagnostics during the process. ^ In the area of feature extraction, the relationship of metric uncertainty to symbolic uncertainty was the topic of research. Error propagation through the Dempster-Shafer formalism for representing evidence was performed in order to find the variance in the calculated belief values due to errors in measurements made to gather the initial evidence needed to begin labeling of observed image features with features in an object model. ^ In Photogrammetric problem solving, an expert system is under continuous development which seeks to solve photogrammetric problems using mathematical reasoning. The key to the approach used is the representation of knowledge directly in the form of equations, rather than in the form of if-then rules. Then each variable in the equations is treated as a goal to be solved. Once the solution set of equations able to solve the problem is determined, the set is submitted to the Vaxima (MACSYMA) expert system for solution. Development of a rule-based part to deal with the heuristic knowledge needed in solving the equations, such as choosing optimum equations, and selecting suitable approximations, has been described. ...|$|E
40|$|This paper {{describes}} a general model for CCD linear array sensors with along-track stereo viewing. The sensor external orientation, which is different for each image line, is modelled with time-dependent piecewise polynomial functions and integrated {{in the standard}} <b>photogrammetric</b> <b>triangulation,</b> resulting in an indirect georeferencing model. The continuity of the functions and their first and second derivatives between adjacent segments is imposed. In case of sensors carried on airplane, the sensor position and attitude observed by GPS/INS instruments {{are included in the}} piecewise polynomial functions. Using Ground Control Points (GCPs) and, additionally, Tie Points (TPs), the function parameters and the ground coordinates of the TPs are estimated in a least-squares adjustment. The model was tested on imagery acquired by TLS and MOMS- 02 sensors, which were carried on helicopter and satellite respectively, using different numbers and distributions of GCPs. The Japanese TLS (Three-Line Sensor) scans along-track in 3 directions with a one-lens optical system. The sensor external orientation for each image line was available by GPS/INS instruments, together with 46 GCPs measured in the images. An absolute accuracy of 4 - 13 cm in planimetry and 6 - 16 cm in height was achieved (ground pixel size: 10 cm). MOMS- 02 sensor was carried on the Russian MIR station. The stereopairs used for the test were acquired during the Priroda mission in 1997 and had ground resolution of 18 m. The preliminary results showed an absolute accuracy of 6. 3 - 9. 3 m in planimetry and 3. 0 - 12. 3 m in height. 1...|$|E
40|$|Mobile mapping {{has been}} the subject of {{significant}} research and development by several research teams over the past decade. A mobile mapping system consists mainly of a moving platform, navigation sensors, and mapping sensors. The mobile platform may be a land vehicle, a vessel, or an aircraft. Generally, the navigation sensors, such as GPS (Global Positioning System) receivers, vehicle wheel sensors, and INS (Inertial Navigation System), provide both the track of the vehicle and positional and orientational information of the mapping sensors. Objects to be surveyed are sensed directly by mapping sensors, for instance CCD (Charge Coupled Device) cameras, laser rangers, and radar sensors. Since the orientation parameters of the mapping sensors are estimated directly by the navigation sensors, complicated computations such as <b>photogrammetric</b> <b>triangulation</b> are greatly simplified or avoided. Spatial information of the objects is extracted directly from the georeferenced mapping sensor data by integrating navigation sensor data. Mobile mapping technology has evolved to a stage which allows mapping and GIS industries to apply it in order to obtain high flexibility in data acquisition, more information with less time and effort, and high productivity. In addition, a successful extension of this technology to helicopter- borne and airborne systems will provide a powerful tool for large scale and medium scale spatial data acquisition and database updating. This paper provides a systematic introduction to the use of mobile mapping technology for spatial data acquisition. Issues related to the basic principle, data processing, automation, achievable accuracies and a break down of errors are given. Application considerations and application examples of the technology in highway and utility mapping are described. Finally, the perspective of the mobile mapping technology is discussed...|$|E
40|$|This paper {{presents}} a low-cost 3 D surface scanner, {{composed of two}} fixed web cameras and a hand-held planar laser beam. Setup pre-calibration provides interior orientations of the cameras and their scaled relative orientation. Our calibration algorithm, based on bundle adjustment, uses image pairs of a chessboard, whose nodes are identified automatically and referred to the ground points. For scanning, synchronized image pairs are continuously recorded from each location of the static cameras as the laser source is slowly moved by hand; each pair thus records {{a profile of the}} 3 D surface intersected by the laser plane. Epipolar resampling reduces the search for point correspondences to finding the intersections of homologous epipolar lines with the recorded laser profile. After a smoothing operation, peaks are identified as the maxima of Gaussian curves fitted to the gray-value data along the epipolar lines; the final identification of peaks involves information from the neighbourhood of the initial estimation. An innovative aspect is that the <b>photogrammetric</b> <b>triangulation</b> of 3 D points gains in robustness by enforcing extra geometric constraints. Thus, all points of a profile must lie on a laser plane, whose coefficients are involved as unknowns in the 3 D reconstruction adjustment. This allows identifying blunders in peak detection; for epipolar lines with more peaks, only points which, when reconstructed, satisfy a distance threshold from the laser plane participate in the final 3 D data set. Furthermore, the object is placed in a corner (the equations of its two planes in the setup system are found automatically by prior scanning), which is intersected by the laser plane in two lines. Their points are identified and constrained to simultaneously satisfy both the corresponding plane equation and the equation of the laser plane. Usin...|$|E
40|$|The paper {{describes}} the first Malaysian Craniofacial soft tissue 3 D imaging system which was developed {{based on the}} integration of stereophotogrammetry and triangulation-based laser scanning system. The main purposes of developing the imaging system are to provide a non-contact method for craniofacial anthropometric measurement and fast and radiation free 3 D modelling of craniofacial soft tissue. The stereophotogrammetric system consists of high resolution digital cameras setup as three stereo cameras placed at the left, front and right sides of the patient. The system was also add-up with another extra two digital cameras setup in convergent mode at bottom left and bottom right of the patient. The combination of all the cameras allowed for the accuracy improvement of craniofacial anthropometry through a novel technique called “natural features technique”. In the natural features technique, the images acquired from the camera system were used to digitize the natural features on the human face. <b>Photogrammetric</b> <b>triangulation</b> method was {{used to calculate the}} 3 D coordinates of the features. The cameras was highly synchronized (0. 2 miliseconds) using a new external shutter controller. The stereophotogrammetric system was designed to be operated in battery system for mobile data capturing purposes. Apart from the camera system, the developed stereophotogrammetric system was completely designed with the object space control frame. The new patient’s chair and photogrammetric control frame has been designed and developed. The object distance is 700 mm. Special-built camera calibration device was designed and developed to calibrate each camera individually. The camera was placed at the camera platform to capture eight convergent images of the 3 D test field. The self calibration bundle adjustment process was carried out using Australis software to calculate the calibration parameters. The develope...|$|E
40|$|Registration {{activities}} combine {{data from}} different sources {{in order to}} attain higher accuracy and derive more information than available from one source. The increasing availability {{of a wide variety}} of sensors capable of capturing high quality and complementary data requires parallel efforts for developing accurate and robust registration techniques. Currently, photogrammetric and LIDAR systems are being incorporated in a wide spectrum of mapping applica¬tions such as city modeling, surface reconstruction, and object recognition. Photogrammetric processing of overlapping imagery provides accurate information regarding object space break-lines in addition to an explicit semantic description of the photographed objects. On the other hand, LIDAR systems supply dense geometric surface information in the form of non-selective points. Considering the properties of photogrammetric and LIDAR data, it is clear that the two technologies provide complementary information. However, the synergic characteristics of both systems can be fully utilized only after successful registration of the photogrammetric and LIDAR data relative to a common reference frame. The registration methodology has to deal with three issues: registration primitives, transformation function, and similarity measure. This paper presents two methodologies for utilizing straight-line features derived from both datasets as the registration primitives. The first methodology directly incorporates the LIDAR lines as control information in the <b>photogrammetric</b> <b>triangulation.</b> The second methodology starts by generating a photogrammetric model relative to an arbitrary datum. Then, LIDAR features are used as control information for the absolute orientation of the photogram¬metric model. In addition to the registration methodologies, the paper presents a comparative analysis between two approaches for extracting linear features from raw and processed/interpolated LIDAR data. Also, a comparative analysis between metric analog and amateur digital cameras within the registration process will be presented. The perform¬ance analysis is based on the quality of fit of the final alignment between the LIDAR and photogrammetric models...|$|E
40|$|The {{original}} invariance {{theory for}} frame photography used in classical photogrammetry has been recently extended by researchers in Image Understanding (IU) and Computer Vision (CV). This thesis explores {{the potential of}} image invariance as an alternative or complementary approach to photogrammetric mensuration tasks. ^ Invariance techniques, for planar objects, are linear in the unknowns. An inconsistency problem due to using different point and line sequences in forming the equations was discovered and a solution developed based on a refined least squares approach. ^ For 3 D objects, {{the use of the}} fundamental matrix in image transfer is shown to produce widely varying results. Introducing the constraint of zero determinant of the fundamental matrix stabilizes the solution. The photogrammetric equivalent technique to image transfer is developed through the introduction of the concept of Extended Relative Orientation (ERO). The trilinearity equations are developed to overcome the problems encountered when working with the fundamental matrix. A new technique is developed to recover the camera parameters from essential and fundamental matrices. The number of recoverable independent camera parameters for various cases of 2 or more cameras is derived and evaluated. ^ Point-based invariance methods for 3 D object reconstruction from two overlapping photographs are discussed and compared to the photogrammetric equivalent method which is based on the bundle adjustment technique. A multi-photo invariance technique is developed as an extension to the invariance method of F matrix factorization. Relationships between the imaging parameters and the variables involved in invariance are investigated. A new technique is proposed for invariance-supported <b>photogrammetric</b> <b>triangulation</b> where the invariance techniques are applied to provide initial approximations for the more robust photogrammetric solution. ^ Line-based invariance techniques for 3 D objects, both for image transfer and object reconstruction, are investigated. The trilinearity equations for lines are presented for image line transfer. Invariance techniques for 3 D object reconstruction are analyzed and compared to recent photogrammetric formulations. A new linear technique is then developed, based on the combined advantages of invariance and photogrammetry, which provides input to the more accurate photogrammetric model. ...|$|E

