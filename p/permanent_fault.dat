104|434|Public
2500|$|Mode $0A lists emission-related [...] "permanent" [...] {{diagnostic}} trouble codes stored. As per CARB, any diagnostic trouble {{codes that}} is commanding MIL on and stored into non-volatile memory shall be logged as a <b>permanent</b> <b>fault</b> code.|$|E
5000|$|A <b>permanent</b> <b>fault</b> is {{a massive}} loss of power {{typically}} caused by a fault on a power line. Power is automatically restored once the fault is cleared.|$|E
5000|$|Mode $0A lists emission-related [...] "permanent" [...] {{diagnostic}} trouble codes stored. As per CARB, any diagnostic trouble {{codes that}} is commanding MIL on and stored into non-volatile memory shall be logged as a <b>permanent</b> <b>fault</b> code.|$|E
30|$|Safety-critical {{real-time}} applications must function {{correctly and}} meet their timing constraints {{even in the}} presence of faults. Such <b>faults</b> can be <b>permanent</b> such as broken communication links and damaged stations, or transient such as temporary faults caused by interference. Transient faults occur temporarily in the system but occur more frequently (100 times more than <b>permanent</b> <b>faults)</b> than <b>permanent</b> <b>faults</b> [5, 6]. This paper discusses transient fault tolerance, leaving the extension to tolerate <b>permanent</b> <b>faults</b> in future work.|$|R
40|$|Time {{redundant}} {{execution of}} tasks and comparison of results {{is a well-known}} technique for detecting transient faults in computer systems. However, time redundancy is also capable of detecting <b>permanent</b> <b>faults</b> that occur during or between the executions of two task replicas, provided the faults affect {{the results of the}} two tasks in different ways. In this paper, we derive an expression for estimating the probability of detecting data errors generated by <b>permanent</b> <b>faults</b> with time redundant execution. The expression is validated experimentally by injecting <b>permanent</b> stuck-at <b>faults</b> into a multiplier unit of a microprocessor. We use the derived expression to show how tasks can be scheduled to improve the detection probability of errors generated by <b>permanent</b> <b>faults.</b> We also show that the detection capability of <b>permanent</b> <b>faults</b> is low for the Temporal Error Masking (TEM) technique (i. e. triplicated execution and voting to mask transient faults) and may not be increased by scheduling. Thus, we propose complementing TEM with special test tasks...|$|R
40|$|The {{effects of}} <b>permanent</b> <b>faults,</b> arising along working life of digital {{electronic}} systems, may impact their reliability and performance. In-field test {{may help to}} detect these faults and to prevent serious effects in safety-critical applications. Distributed electronic systems introduce further complexity in this scenario, as the low observability {{and the lack of}} maintenance make difficult the detection as well as the identification of failing elements and their repairing. Functional workloads are often used for on-line tests of distributed systems to detect <b>permanent</b> <b>faults.</b> Suitable techniques for test generation and early identification of functionally untestable <b>permanent</b> <b>faults</b> are critical issues that are faced in this wor...|$|R
5000|$|A <b>permanent</b> <b>fault</b> {{shift in}} Shigang District {{resulted}} in serious {{damage to the}} Shihgang Dam, {{as well as the}} necessity of patching affected roads and trails with inclines, in order to restore their usefulness. Two notable examples of this are the biking/hiking trail between Dongshi District and Fengyuan District, and Fengshi Road which also connects these two districts. Some locals humorously call this new inclination [...] "Singapore", in Chinese (...) [...]|$|E
5000|$|The {{control system}} for a {{recloser}} allows a selected number of attempts to restore service after adjustable time delays. For example a recloser may have 2 or 3 [...] "fast" [...] reclose operations with a few seconds delay, then a longer delay and one reclose; if the last attempt is not successful, the recloser will lock out and require human intervention to reset. If the fault is a <b>permanent</b> <b>fault</b> (downed wires, tree limbs lying on the wires, etc.) the autorecloser will exhaust its pre-programmed attempts to re-energize the line and remain tripped off until manually commanded to try again. About 80-90% of faults on overhead power lines are transient and can be cured by autoreclosing. The result is increased availability of supply.|$|E
50|$|Controversially, {{the energy}} policy {{depended}} less on {{renewable energy sources}} and dependence on imported oil increased that created a <b>permanent</b> <b>fault</b> in country's energy conservation system. By 1995, only 27 IPPs were able to generate ~6,335MW of electricity. By 1998, the ratio was stabilised by the policies enforced by Prime Minister Nawaz Sharif. In 2001, the military government led by President Pervez Musharraf and Prime Minister Shaukat Aziz, while contributing {{to the growth of}} domestic demand for electricity through large-scale provision of bank loans for the purchase of air-conditioners and home appliances (share of domestic energy consumption had jumped to 46% of the total by 2008), did not add any new capacity to the energy system. In 2012 Pakistan's first wind power installation came online at the FFCEL Wind Energy Project in Jhimpir.|$|E
30|$|Fault latency {{is defined}} as the {{interval}} between the moments of fault occurrence and error generation (Shin and Lee [1984]). This information is extremely important, since it directly affects how to handle the error caused by the fault. In terms of latency, <b>faults</b> can be <b>permanent,</b> transient or intermittent. <b>Permanent</b> <b>faults</b> are continuous and stable. In hardware, <b>permanent</b> <b>faults</b> reflect an irreversible physical change. <b>Permanent</b> <b>faults</b> are also known as “hard” faults. Transient faults result from temporary environmental conditions, and can be fixed by changing the respective conditions that cause the fault. Transient faults are also known as “soft” faults. Intermittent faults are only occasionally present due to unstable hardware or varying hardware or software states. Intermittent and transient faults are the major source of system errors. Even when {{it is not possible to}} repair the fault, the use of redundant resources allows the system to tolerate faults (Gärtner [1999]; Lee and Anderson [1990]). The manifestations of transient and intermittent faults and of incorrect hardware or software design are much more difficult to determine than <b>permanent</b> <b>faults.</b>|$|R
5000|$|<b>Permanent</b> <b>faults</b> {{affect the}} logic {{values in the}} system permanently, these faults are easier to detect using a memory tester. Examples include: ...|$|R
5000|$|<b>Permanent</b> <b>faults</b> {{lead to a}} {{continuing}} error and are typically due to some physical failure such as metal electromigration or dielectric breakdown.|$|R
5000|$|In {{the past}} several decades, the most popular fault model used in {{practice}} is the single stuck-at fault model. In this model, one of the signal lines in a circuit {{is assumed to be}} stuck at a fixed logic value, regardless of what inputs are supplied to the circuit. Hence, if a circuit has n signal lines, there are potentially 2n stuck-at faults defined on the circuit, of which some can be viewed as being equivalent to others. The stuck-at fault model is a logical fault model because no delay information is associated with the fault definition. It is also called a <b>permanent</b> <b>fault</b> model because the faulty effect is assumed to be permanent, in contrast to intermittent faults which occur (seemingly) at random and transient faults which occur sporadically, perhaps depending on operating conditions (e.g. temperature, power supply voltage) or on the data values (high or low voltage states) on surrounding signal lines. The single stuck-at fault model is structural because it is defined based on a structural gate-level circuit model.|$|E
30|$|If {{the fault}} is temporary, the fault {{terminal}} can be resumed {{to the normal}} operating condition once the fault is cleared. If it is a <b>permanent</b> <b>fault,</b> the MTDC system will be re-configured as a three-terminal HVDC system. In the following case studies, the AC fault is applied as a <b>permanent</b> <b>fault</b> at T 1.|$|E
30|$|Synchronous {{operation}} of the transfer branch in a hybrid HVDC breaker (HHB) [36] has been proposed to reduce the adverse effects on the VSC-based DC grid from a DCB reclosing operation under a <b>permanent</b> <b>fault</b> [37]. Specifically, all fully-controlled fast-power electronic switches in the transfer branch are energized {{to carry out the}} reclosing operation synchronously. Then the main branch is conducted if no fault is detected. Conversely, once a <b>permanent</b> <b>fault</b> is detected, all the fully-controlled fast-power electronic switches in the transfer branch will be immediately de-energized synchronously to interrupt the fault current. We call this the traditional sequential auto-reclosing strategy in this paper, and with its help, the fault current can be interrupted immediately if a <b>permanent</b> <b>fault</b> is detected. However, potential negative impacts such as erroneous protection, line-insulation failure, and even damage to power electronic devices will occur when the fault is temporary.|$|E
40|$|Submitted {{on behalf}} of EDAA ([URL] audienceSingle Event Upsets (SEU) as well as <b>permanent</b> <b>faults</b> can {{significantly}} affect the correct on-line operation of digital systems, such as memories and microprocessors; a memory can be made resilient to <b>permanent</b> and transient <b>faults</b> by using modular redundancy and coding. In this paper, different memory systems are compared: these systems utilize simplex and duplex arrangements {{with a combination of}} Reed Solomon coding and scrubbing. The memory systems and their operations are analyzed by novel Markov chains to characterize performance for dynamic reconfiguration as well as error detection and correction under the occurrence of <b>permanent</b> and transient <b>faults.</b> For a specific Reed Solomon code, the duplex arrangement allows to efficiently cope with the occurrence of <b>permanent</b> <b>faults,</b> while the use of scrubbing allows to cope with transient faults...|$|R
40|$|In {{this paper}} we are {{interested}} in mixed-criticality embed-ded applications implemented on distributed architectures. Depending on their time-criticality, tasks can be hard or soft real-time and regarding safety-criticality, tasks can be fault-tolerant to transient <b>faults,</b> <b>permanent</b> <b>faults,</b> or have no dependability requirements. We use Earliest Deadline First (EDF) scheduling for the hard tasks and the Constant Bandwidth Server (CBS) for the soft tasks. The CBS pa-rameters determine the quality of service (QoS) of soft tasks. Transient faults are tolerated using checkpointing with roll-back recovery. For tolerating <b>permanent</b> <b>faults</b> in proces-sors, we use task migration, i. e., restarting the safety-critical tasks on other processors. We propose a Greedy-based on-line heuristic for the migration of safety-critical tasks, in response to <b>permanent</b> <b>faults,</b> and the adjustment of CBS parameters on the target processors, such that the faults are tolerated, the deadlines for the hard real-time tasks are sat-isfied and the QoS for soft tasks is maximized. The proposed online adaptive approach has been evaluated using several synthetic benchmarks and a real-life case study. 1...|$|R
40|$|A {{reconfigurable}} Computer {{system must}} distinguish between transient <b>faults</b> and <b>permanent</b> <b>faults.</b> A transient fault usually only causes incorrect behavior temporarily, and consequently {{the operating system}} should not permanently remove the affected conq?onent via reconfiguration. Unfortunately, transient faults appear to occur mre frequently than <b>permanent</b> <b>faults.</b> The available empirical data show that transients occur about 10 times more frequently than <b>permanent</b> <b>faults.</b> (See ref. 1.) Thus, if an operating system removes too many processors affected by transient faults, then the reliability will be seriously compromised. The development of an effective transient/penuanent fault discrimination algorithm is a critical problem for fault-tolerant cosaputer system designers. The objective of this experiment is threefold: 1. To gain som fundamental information concerning error latency and the error propagation process {{in the presence of}} injected transient faults 2. To obtain the necessary data to perform a reliability analysis of the SIFT computer system (ref. 2) including the effects of <b>permanent</b> and transient <b>faults</b> 3. To determine the effectiveness of the operating system's ability to discriminate between transient and <b>permanent</b> <b>faults</b> Only a small number of injections have been performed, therefore, statistically significant conclusions cannot yet be drawn. The {{purpose of this paper is}} to present the experimental approach and data analysis techniques in detail. c W random variable representing the duration of transient faults Z' random variable representing the elapsed time from fault injection until last error appears. Y R' random variable representing the elapsed time from fault injection until the system reconfigures Z randm variable representing the elapsed time from fault injection until last error appears given that reconfiguration does not occur R x...|$|R
40|$|The Jiggling {{architecture}} extending TMR+Scrubbing {{is shown}} to mitigate FPGA transient and permanent faults using low overhead. Mission operation is never interrupted. The repair circuitry is sufficiently small that a pair could mutually repair each other. A minimal evolutionary algorithm is used during <b>permanent</b> <b>fault</b> self-repair. Reliability analysis of the studied case shows the system has a 0. 99 probability of surviving 17 times the mean time to local <b>permanent</b> <b>fault</b> arrival. Such a system would be 0. 99 probable to survive 100 years with one fault every 6 years...|$|E
40|$|Abstract — In {{this project}} a fault {{tolerant}} solution for a Network-On-Chip (NOC) is proposed. The faults included {{here are the}} transient fault and <b>permanent</b> <b>fault.</b> A fault diagnosis process is proposed to find out single error and double error per cycle. This {{is a process of}} diagnosing fault that occurs in the defined path between the network routers or nodes. Communication is possible only after the path is established between the required nodes/routers with no errors and reduced time. The aim of detecting faults is to establish a defined path as faster as possible. Single error can be corrected easily but when double error occurs one may need to take decision to establish a defined path. The double error is considered as <b>permanent</b> <b>fault.</b> The fault detection, hardware requirements and power consumptions are considered. The aim is to detect the faults (Transient fault and <b>Permanent</b> <b>fault)</b> that occur in Network On Chip with reduced power consumption when compared to the existing system...|$|E
40|$|FPGA {{fault repair}} schemes remove faulty {{elements}} from designs through reconfiguration. In designs with high FPGA utilization, {{a sufficient number}} of routable faultfree elements may not be available for <b>permanent</b> <b>fault</b> repair. We present a new <b>permanent</b> <b>fault</b> repair scheme, in which the original design is reconfigured into another fault tolerant design that has smaller area, so the damaged element can be avoided. Three new schemes that fully utilize available fault-free area and provide low impact on availability are presented. Analytical results show that our schemes improve availability compared to a module removal approach, which removes a redundant module when it becomes faulty...|$|E
40|$|Nowadays Field-Programmable Gate Arrays (FP-GAs) are {{increasingly}} used in critical applications. In these scenarios {{fault tolerance techniques}} are needed to increase system dependability and lifetime. This paper proposes a novel methodology to achieve autonomous fault tolerance in FPGA-based systems affected by <b>permanent</b> <b>faults.</b> A design flow is defined to help designers to build a system with increased lifetime and availability. The methodology exploits Dynamic Partial Reconfiguration (DPR) to relocate at run-time faulty modules implemented onto the FPGA. A partitioning method is also presented to provide a solution which maximizes the number of <b>permanent</b> <b>faults</b> the system can tolerate. Experimental results highlight the negligible performance degradation introduced by applying the proposed methodology, and the improvements with respect to state-of-the-art solution...|$|R
40|$|AbstractIn {{the complex}} {{computing}} system, processing units {{are dealing with}} devices of smaller size, which {{are sensitive to the}} transient faults. A transient fault occurs in a circuit caused by the electromagnetic noises, cosmic rays, crosstalk and power supply noise. It is very difficult to detect these faults during offline testing. Hence an area efficient fault tolerant full adder for testing and repairing of transient and <b>permanent</b> <b>faults</b> occurred in single and multi-net is proposed. Additionally, the proposed architecture can also detect and repair <b>permanent</b> <b>faults.</b> This design incurs much lower hardware overheads relative to the traditional hardware architecture. In addition to this, proposed design also provides higher error detection and correction efficiency when compared to the existing designs...|$|R
40|$|Abstract This paper {{presents}} an approach for increas-ing {{the lifetime of}} systems implemented on SRAM-based FPGAs, by introducing fault tolerance properties enabling the system to autonomously manage the occurrence of both transient and <b>permanent</b> <b>faults.</b> On {{the basis of the}} foreseen mission time and application environment, the designer is supported in the implementation of a system able to recon-figure itself, either by reloading the correct configuration in case of transient faults, or by relocating part of the func-tionality in presence of <b>permanent</b> <b>faults.</b> The result is a system implementation offering good performance and cor-rect functionality even when faults occur. The proposed approach is evaluated in a case study to highlight the overall characteristics of the final implementation...|$|R
30|$|In this accident, four {{protection}} components operated, including pilot distance, automatic re-closure, dead-zone {{protection and}} busbar differential. It was confirmed later from the disturbance recorder report and a site inspection that phase A had a <b>permanent</b> <b>fault</b> with earth.|$|E
40|$|In {{the present}} paper, {{the concept of}} a hybrid fault {{situation}} is introduced, which specifies bounded combinations of permanently faulty and intermittently faulty units in a system. The general class of hybrid fault situations includes, as special cases, the all <b>permanent</b> <b>fault</b> case and the unrestricted intermittent fault case, which have been previously considered with PMC models. An approach compatible with the diagnosis of <b>permanent</b> <b>fault</b> situations is then applied to the diagnosis of hybrid fault situation. The motivation for doing so is the common practice of testing for the presence of intermittent faults in systems by means of repeated applications of tests that are designed for the detection of permanent faults. The testing assignment of PMC models of system is characterized, and interrelationships between the number of intermittently and permanently faulty units that can be diagnosed is established...|$|E
40|$|This paper {{analyzes}} {{different types}} of symmetrical and unsymmetrical fault of grid connected wind turbine generator system (WTGS), where the six-mass drive train model is considered. The unsuccessful re-closing due to <b>permanent</b> <b>fault</b> is also considered. Moreover, the blade-shaft stresses of the six-mass drive train model of WTGS are also analysed for both successful and unsuccessful re-closing...|$|E
40|$|Causes and {{symptoms}} of logic faults in digital systems. Reliable performance of hardware has been a require-ment for digital systems since {{the construction of the}} first digital computer. Improper functioning of the logic circuits in a digital system is manifested by logic faults, which are defined for this paper as "permanent or transient deviations of logic variables from the values specified in design. " <b>Permanent</b> <b>faults</b> are caused by physical changes in the components of a logic circuit which permanently alter the logic function specified by the designer. The most common <b>permanent</b> <b>faults</b> are the determinate faults of "stuck on zero " and "stuck on one " types. Less frequent is the indeterminate or "stuck on X " fault...|$|R
40|$|In {{the complex}} {{computing}} system, processing units {{are dealing with}} devices of smaller size, which {{are sensitive to the}} transient faults. A transient fault occurs in a circuit caused by the electromagnetic noises, cosmic rays, crosstalk and power supply noise. It is very difficult to detect these faults during offline testing. Hence an area efficient fault tolerant full adder for testing and repairing of transient and <b>permanent</b> <b>faults</b> occurred in single and multi-net is proposed. Additionally, the proposed architecture can also detect and repair <b>permanent</b> <b>faults.</b> This design incurs much lower hardware overheads relative to the traditional hardware architecture. In addition to this, proposed design also provides higher error detection and correction efficiency when compared to the existing designs...|$|R
40|$|This paper {{presents}} an approach {{for increasing the}} lifetime of systems implemented on SRAM-based FPGAs, by introducing fault tolerance properties enabling the system to autonomously manage the occurrence of both transient and <b>permanent</b> <b>faults.</b> On {{the basis of the}} foreseen mission time and application environment, the designer is supported in the implementation of a system able to reconfigure itself, either by reloading the correct configuration in case of transient faults, or by relocating part of the functionality in presence of <b>permanent</b> <b>faults.</b> The result is a system implementation offering good performance and correct functionality even when faults occur. The proposed approach is evaluated in a case study to highlight the overall characteristics of the final implementation...|$|R
40|$|Abstract—Fault {{tolerance}} (FT) {{has become}} a major concern in computing systems. Instruction duplication has been proposed to verify application execution at run time. Two techniques, instruction memoization and precomputation, have been shown to improve the performance and fault coverage of duplication. This work shows that the combination of these two techniques is much more powerful than either one in isolation. In addition to performance, it improves the long-lasting transient and <b>permanent</b> <b>fault</b> coverage upon the memoization scheme. Compared to the precomputation scheme, it reduces the longlasting transient and <b>permanent</b> <b>fault</b> coverage of 10. 6 % of the instructions, but covers 2. 6 times as many instructions against shorter transient faults. On a system with 2 integer ALUs, the combined scheme reduces the performance degradation due to duplication by on average 27. 3 % and 22. 2 % compared to the precomputation and memoization-based techniques, respectively, with similar hardware requirements. I...|$|E
40|$|Abstract. It is {{well known}} that {{lightning}} strokes produce mal-operation of transmission line protection relays. Where, protection devices cannot identify correctly between lightning stroke that generates or not permanent faults. Thus, when a flash produces a <b>permanent</b> <b>fault,</b> the protection relay sends a trip order, and the Transmission Line (TL) is disconnected correctly. However, when a lightning stroke does not produce a <b>permanent</b> <b>fault,</b> the protection devices also send the trip order, and the TL is disconnected unnecessary. In this context, these phenomena can produce unnecessary electric power outages, producing damage for the society and economic. Therefore, it is necessary to correctly identify between these lightning stroke signals. Besides that, direct lightning strokes, which hit directly on TLs or transmission towers, have usually been analyzed. However, induced lightning strokes, which hit on ground, have not been considered in previous analyzed. In this paper, in order to identify these induced lightning strokes, an algorithm based on a deterministic focus is proposed...|$|E
40|$|In this paper, {{we propose}} and {{evaluate}} a fault-tolerant real-time scheduling algorithm that can tolerate one processor's <b>permanent</b> <b>fault</b> in a heterogeneous distributed system. Workload {{in this study}} consists of a stream of real-time jobs where each job contains multiple precedence-constrained tasks with individual deadlines. A Primary Backup (PB) model is employed, where each real-time task has two copies, i. e. a primary one and a backup one, that are allocated to two different processors. The backup copy executes only if the primary copy fails due {{to the failure of}} its assigned processor. The proposed scheduling algorithm also takes the reliability measure into account, in order to further enhance the reliability of the heterogeneous system. In addition, the detection time for <b>permanent</b> <b>fault</b> is incorporated into the scheduling scheme so as to make the scheduling result more realistic and accurate. Simulation results show that the proposed algorithm provides significantly improved reliability and schedulability...|$|E
40|$|Wireless Sensor Networks (WSN) {{currently}} {{represent the}} best candidate to be adopted as the communication solution for the last mile connection in process control and monitoring applications in industrial environments. Most of these applications have stringent dependability (reliability and availability) requirements, as a system failure may result in economic losses, put people in danger or lead to environmental damages. Among the different type of faults {{that can lead to}} a system failure, <b>permanent</b> <b>faults</b> on network devices have a major impact. They can hamper communications {{over long periods of time}} and consequently disturb, or even disable, control algorithms. The lack of a structured approach enabling the evaluation of <b>permanent</b> <b>faults,</b> prevents system designers to optimize decisions that minimize these occurrences. In this work we propose a methodology based on an automatic generation of a fault tree to evaluate the reliability and availability of Wireless Sensor Networks, when <b>permanent</b> <b>faults</b> occur on network devices. The proposal supports any topology, different levels of redundancy, network reconfigurations, criticality of devices and arbitrary failure conditions. The proposed methodology is particularly suitable for the design and validation of Wireless Sensor Networks when trying to optimize its reliability and availability requirements...|$|R
40|$|AbstractA {{new class}} of {{symmetric}} error correcting/unidirectional error detecting codes are developed. They provide protection against both transient and <b>permanent</b> <b>faults.</b> The codes are systematic in nature and, hence, the information bits are easy to retrieve. The encoding/decoding methods for these codes are discussed...|$|R
40|$|Intermittent scan chain hold-time {{fault is}} {{discussed}} in this paper and a method to diagnose the faulty site in a scan chain is proposed as well. Unlike the previous scan chain diagnosis methods that targeted <b>permanent</b> <b>faults</b> only, the proposed method targets both <b>permanent</b> <b>faults</b> and intermittent faults. Three ideas are presented in this paper. First an enhanced upper bound on the location of candidate faulty scan cells is obtained. Second a new method to determine a lower bound is proposed. Finally a statistical diagnosis algorithm is proposed to calculate the probabilities of the bounded set of candidate faulty scan cells. The proposed algorithm is shown to be efficient and effective for large industrial designs with multiple faulty scan chains. ...|$|R
