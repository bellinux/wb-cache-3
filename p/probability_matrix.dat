786|612|Public
25|$|A {{convenient}} {{method of}} modelling oligonucleotide genomic signatures {{is to use}} Markov chains. The transition <b>probability</b> <b>matrix</b> can be derived for endogenous vs. acquired genes, from which Bayesian posterior probabilities for particular stretches of DNA can be obtained.|$|E
25|$|A Bernoulli {{scheme is}} a special case of a Markov chain where the {{transition}} <b>probability</b> <b>matrix</b> has identical rows, {{which means that the}} next state is even independent of the current state (in addition to being independent of the past states). A Bernoulli scheme with only two possible states is known as a Bernoulli process.|$|E
25|$|Markov {{chains are}} {{employed}} in algorithmic music composition, particularly in software such as CSound, Max and SuperCollider. In a first-order chain, {{the states of the}} system become note or pitch values, and a probability vector for each note is constructed, completing a transition <b>probability</b> <b>matrix</b> (see below). An algorithm is constructed to produce output note values based on the transition matrix weightings, which could be MIDI note values, frequency (Hz), or any other desirable metric.|$|E
3000|$|... [...]. Depending on the {{selected}} SNR thresholds, the state-transition <b>probability</b> <b>matrices</b> of RS-to-train channels, denoted as [...]...|$|R
3000|$|..., t= 1,…,n are the {{transition}} <b>probability</b> <b>matrices</b> of the imbedded Markov chain defined {{on the state}} space Ω [...]...|$|R
30|$|Corresponding {{to various}} u and v except for (u,v)[*]=[*](0, 0), 63 {{transition}} <b>probability</b> <b>matrices</b> are formed for each component pair, such as {Y, U}, {Y, V}, and {U, V}. Similarly, {{in order to}} lower feature dimensions, we average the 63 matrices for the three component pairs separately. Finally, we utilize the resulting three tradition <b>probability</b> <b>matrices</b> with size (T[*]+[*] 1)[*]×[*](T[*]+[*] 1) to form a 3 [*]×[*](T[*]+[*] 1)[*]×[*](T[*]+[*] 1) dimensional feature vector viewed as inter-component features for an encrypted color JPEG image.|$|R
2500|$|While the {{mutation}} <b>probability</b> <b>matrix</b> [...] is not symmetric, {{each of the}} PAM matrices are. This somewhat surprising {{property is}} a result of the relationship that was noted for the mutation probability matrix: ...|$|E
2500|$|A Markov {{process is}} called a {{reversible}} Markov process or reversible Markov chain precisely if it satisfies the detailed balance equations. These equations require that the transition <b>probability</b> <b>matrix,</b> P, for the Markov process possess a stationary distribution (i.e. equilibrium probability distribution) π such that ...|$|E
2500|$|... where P'ij is the Markov {{transition}} probability) {{from state}} i to state j, i.e. P'ij=P(X't=j|X't−1=i), and πi and πj are the equilibrium probabilities {{of being in}} states i and j, respectively. [...] When Pr(X't−1=i)=πi for all i, this {{is equivalent to the}} joint <b>probability</b> <b>matrix,</b> Pr(X't−1=i,X't=j) being symmetric in i and j; or symmetric in t−1 andt.|$|E
40|$|AbstractThis {{investigation}} {{aimed to}} one common key {{issue of the}} two imaging types, the sampling of the template configuration. A first selector framework that employs MATLAB to perform attractive features of the small <b>probability</b> <b>matrices</b> in random sampling matrix from Gaussian random matrix was presented. Gaussian random matrix is usually used as random sampling matrix in Single Pixel Camera. The small <b>probability</b> <b>matrices</b> in random sampling matrix can obtain a recovery image of higher accuracy for singe detector imaging system and detector array imaging system...|$|R
40|$|AbstractIncrease {{of credit}} {{derivative}} transaction volumes and credit related exposures in trading books, contingent {{effect of the}} recent financial crisis along with insufficient measure of so called Value At Risk calculations raised new methodologies for credit risk models as well as input parameters such as transition <b>probability</b> <b>matrices.</b> Conditional transition <b>probability</b> <b>matrices</b> {{are one of the}} main inputs of the credit risk models and it is required to estimate for short liquidity horizons. This study presents conditional transition <b>probability</b> <b>matrices</b> for sovereigns using factor modeling approaches under various symmetric and asymmetric distribution assumptions. Asymmetric models are found to provide superior results over the symmetric models for both in sample and out of sample results. Furthermore, the proposed methodology is applicable for quarterly sovereign transitions where rating movements are not observed frequently. Finally the model incorporates the dependence of the business cycles to the estimated credit cycle indices using main macroeconomic factors...|$|R
40|$|I {{study the}} product of {{independent}} identically distributed D × D random <b>probability</b> <b>matrices.</b> Some exact asymptotic results are obtained. I find that {{both the left and}} the right products approach exponentially to a <b>probability</b> matrix(asymptotic <b>matrix)</b> in which any two rows are the same. A parameter λ is introduced for the exponential coefficient which can be used to describe the convergent rate of the products. λ depends on the distribution of individual random matrices. I find λ = 3 / 2 for D = 2 when each element of individual random <b>probability</b> <b>matrices</b> is uniformly distributed in [0, 1]. In this case, each element of the asymptotic matrix follows a parabolic distribution function. The distribution function of the asymptotic matrix elements can be numerically shown to be non-universal. Numerical tests are carried out for a set of random <b>probability</b> <b>matrices</b> with a particular distribution function. I find that λ increases monotonically from ≃ 1. 5 to ≃ 3 as D increases from 3 to 99, and the distribution of random elements in the asymptotic products can be described by a Gaussian function with its mean to be...|$|R
2500|$|One {{method of}} finding the {{stationary}} probability distribution, π, of an ergodic continuous-time Markov chain, Q, is by first finding its embedded Markov chain (EMC). [...] Strictly speaking, the EMC is a regular discrete-time Markov chain, {{sometimes referred to as}} a jump process. [...] Each element of the one-step transition <b>probability</b> <b>matrix</b> of the EMC, S, is denoted by s'ij, and represents the conditional probability of transitioning from state i into state j. [...] These conditional probabilities may be found by ...|$|E
2500|$|Evolutionary {{analyses}} of sequences are conducted {{on a wide}} variety of time scales. Thus, it is convenient to express these models in terms of the instantaneous rates of change between different states (the Q matrices below). [...] If we are given a starting (ancestral) state at one position, the model's Q matrix and a branch length expressing the expected number of changes to have occurred since the ancestor, then we can derive the probability of the descendant sequence having each of the four states. [...] The mathematical details of this transformation from rate-matrix to <b>probability</b> <b>matrix</b> are described in the mathematics of substitution models section of the substitution model page. By expressing models in terms of the instantaneous rates of change we can avoid estimating a large numbers of parameters for each branch on a phylogenetic tree (or each comparison if the analysis involves many pairwise sequence comparisons).|$|E
50|$|In exact recovery, {{the goal}} is to recover the latent {{partition}} into communities exactly. The community sizes and <b>probability</b> <b>matrix</b> may be known or unknown.|$|E
3000|$|..., {{are changed}} accordingly. Given {{the states of}} the current RS and {{potential}} next RS, the overall state transition <b>probability</b> <b>matrices</b> can be easily obtained through Kronecker tensor product, i.e., [...]...|$|R
40|$|Spatial-temporal k-anonymity {{has become}} a {{mainstream}} approach among techniques for protection of users' privacy in location-based services (LBS) applications, and {{has been applied to}} several variants such as LBS snapshot queries and continuous queries. Analyzing large-scale spatial-temporal anonymity sets may benefit several LBS applications. In this paper, we propose two location prediction methods based on transition <b>probability</b> <b>matrices</b> constructing from sequential rules for spatial-temporal k-anonymity dataset. First, we define single-step sequential rules mined from sequential spatial-temporal k-anonymity datasets generated from continuous LBS queries for multiple users. We then construct transition <b>probability</b> <b>matrices</b> from mined single-step sequential rules, and normalize the transition probabilities in the transition matrices. Next, we regard a mobility model for an LBS requester as a stationary stochastic process and compute the n-step transition <b>probability</b> <b>matrices</b> by raising the normalized transition <b>probability</b> <b>matrices</b> to the power n. Furthermore, we propose two location prediction methods: rough prediction and accurate prediction. The former achieves the probabilities of arriving at target locations along simple paths those include only current locations, target locations and transition steps. By iteratively combining the probabilities for simple paths with n steps and the probabilities for detailed paths with n- 1 steps, the latter method calculates transition probabilities for detailed paths with n steps from current locations to target locations. Finally, we conduct extensive experiments, and correctness and flexibility of our proposed algorithm have been verified...|$|R
3000|$|To {{underline}} {{the influence of}} the masonry infill walls, particular damage <b>probability</b> <b>matrices</b> have been obtained for maximum considered earthquake (MCE) and design basis earthquake (DBE). These are the two seismic hazard levels defined in IS 1893 (2016). Three fragility curves corresponding to IO, LS and CP damage states have been developed for each model in two directions, and therefore, four damage stages are considered as No damage (ND), Slight damage (SD), Moderate damage (MD) and Collapse damage (CD) stage. Table  8 presents discrete damage <b>probability</b> <b>matrices</b> results. Discrete damage probabilities can be calculated as follows: [...]...|$|R
50|$|An {{alternative}} design {{called the}} negative beta encoder (called so {{due to the}} negative eigenvalue of the transition <b>probability</b> <b>matrix)</b> has been proposed to further reduce the quantization error.|$|E
5000|$|The {{transition}} <b>probability</b> <b>matrix</b> for a M/D/1 queue with arrival rate λ {{and service}} time 1, such that λ <1 (for {{stability of the}} queue) is given by P as below: ...|$|E
5000|$|While the {{mutation}} <b>probability</b> <b>matrix</b> [...] is not symmetric, {{each of the}} PAM matrices are. This somewhat surprising {{property is}} a result of the relationship that was noted for the mutation probability matrix: ...|$|E
3000|$|... are {{considered}} being discrete and memoryless with conditional probability distribution PY Z∣X(y, z∣x). The marginal channels PY∣X and PZ∣X constitute the transition <b>probability</b> <b>matrices</b> {{of the main}} channel and the opponent channel, respectively.|$|R
40|$|We develop Bayesian {{techniques}} for modelling {{the evolution of}} entire distributions over time and apply them to the distribution of team performance in Major League baseball for the period 1901 - 2000. Such models offer insight into many key issues (e. g. competitive balance) {{in a way that}} regression-based models cannot. The models involve discretizing the distribution and then modelling the evolution of the bins over time through transition <b>probability</b> <b>matrices.</b> We allow for these matrices to vary over time and across teams. We find that, with one exception, the transition <b>probability</b> <b>matrices</b> (and, hence, competitive balance) have been remarkably constant across time and over teams. The one exception is the Yankees, who have outperformed all other teams. Copyright 2004 Royal Statistical Society. ...|$|R
40|$|Goal: To develop {{scalable}} modeling {{tools for}} monitoring complex distributed systems and predicting catastrophic performance degradations. Use Discrete Time Markov Chain (DTMC) : – Develop time-inhomogeneous model of system behavior. – Perturb DTMC transition <b>probability</b> <b>matrices</b> (TPMs) to simulate alternative system evolutions � Identify failure scenarios System to state mode...|$|R
5000|$|A {{terminating}} Markov {{chain is}} a Markov chain where all states are transient, except {{one which is}} absorbing.Reordering the states, the transition <b>probability</b> <b>matrix</b> of a terminating Markov chain with [...] transient states is ...|$|E
5000|$|For partial recovery, the {{appropriate}} scaling {{is to take}} [...] for fixed , resulting in graphs of constant average degree. In the case of two equal-sized communities, in the assortative planted partition model with <b>probability</b> <b>matrix</b> ...|$|E
50|$|A {{convenient}} {{method of}} modelling oligonucleotide genomic signatures {{is to use}} Markov chains. The transition <b>probability</b> <b>matrix</b> can be derived for endogenous vs. acquired genes, from which Bayesian posterior probabilities for particular stretches of DNA can be obtained.|$|E
3000|$|... are channel {{observation}} <b>probability</b> <b>matrices</b> for S 2 R channel, R 2 D channel, and S 2 D channel, respectively. ⊗ denotes Kronecker product {{which is}} used here to expand the transition matrices. Note that all the channel observation probability is independent. That is why we can use ⊗ to expand it.|$|R
40|$|In {{a product}} market or stock market, {{different}} products or stocks {{compete for the}} same consumers or purchasers. We propose a method to estimate the time-varying transition matrix of the product share using a multivariate time series of the product share. The method {{is based on the}} assumption that each of the observed time series of shares is a stationary distribution of the underlying Markov processes characterized by transition <b>probability</b> <b>matrices.</b> We estimate transition <b>probability</b> <b>matrices</b> for every observation under natural assumptions. We demonstrate, on a real-world dataset of the share of automobiles, that the proposed method can find intrinsic transition of shares. The resulting transition matrices reveal interesting phenomena, for example, the change in flows between TOYOTA group and GM group for the fiscal year where TOYOTA group’s sales beat GM’s sales, which is a reasonable scenario...|$|R
3000|$|... where x, y ∈ [0, T]. To {{reduce the}} feature dimensionality, we average the {{transition}} <b>probability</b> <b>matrices</b> {{generated from the}} 62 element pairs to generate a new matrix with (T[*]+[*] 1)[*]×[*](T[*]+[*] 1) elements, {{all of which are}} used as features. Thus, we have a (T[*]+[*] 1)[*]×[*](T[*]+[*] 1) dimensional feature vector for the matrix D [...]...|$|R
5000|$|If the <b>probability</b> <b>matrix</b> is a constant, in {{the sense}} that [...] for all , then the result is the Erdős-Rényi model [...] This case is degenerate—the {{partition}} into communities becomes irrelevant—but it illustrates a close relationship to the Erdős-Rényi model.|$|E
50|$|The network <b>probability</b> <b>matrix</b> {{describes}} the probability {{structure of a}} network based on the historical {{presence or absence of}} edges in a network. For example, individuals in a social network are not connected to other individuals with uniform random probability. The probability structure is much more complex. Intuitively, there are some people whom a person will communicate with or be connected more closely than others. For this reason, real-world networks tend to have clusters or cliques of nodes that are more closely related than others (Albert and Barabasi, 2002, Carley year, Newmann 2003). This can be simulated by varying the probabilities that certain nodes will communicate. The network <b>probability</b> <b>matrix</b> was originally proposed by Ian McCulloh.|$|E
5000|$|Stochastic block models {{exhibit a}} sharp {{threshold}} effect reminiscent of percolation thresholds. Suppose that we allow the size [...] of the graph to grow, keeping the community sizes in fixed proportions. If the <b>probability</b> <b>matrix</b> remains fixed, {{tasks such as}} partial and exact recovery become feasible for all non-degenerate parameter settings. However, if we scale down the <b>probability</b> <b>matrix</b> at a suitable rate as [...] increases, we observe a sharp phase transition: for certain settings of the parameters, it will become possible to achieve recovery with probability tending to 1, whereas {{on the opposite side}} of the parameter threshold, the probability of recovery tends to 0 no matter what algorithm is used.|$|E
40|$|AbstractSufficiency {{conditions}} are {{given for the}} existence of stationary Blackwell optimal policies. These conditions concern only the one step transition <b>probability</b> <b>matrices</b> and their resolvents and therefore appear to be more natural than those recently introduced by Dekker and Hordijk. We use the same operator-theoretic approach and standard results about spectral theory of bounded linear operators...|$|R
30|$|Since {{the target}} {{velocity}} {{is within the}} range of 0 - 2 ppf with a possible jitter of 0.5 ppf, the pixel can move up to 2.5 ppf in the horizontal and vertical directions; hence, a valid area from which a pixel might origin from in the previous frame is a 7 × 7 pixel area (matrix). Such a search area can be resized according to different velocity ranges and jitter values. The search area will define the <b>probability</b> <b>matrices</b> that contain the probabilities of pixels in the previous frames being the origin of the pixel in the current frame. To take into account unreasonable changes of direction, penalty matrices are introduced with the aim of building <b>probability</b> <b>matrices</b> for the different possible directions of movement. These <b>matrices</b> give high <b>probabilities</b> to pixels in the estimated direction and decreasing probabilities (punishment) as the direction varies from the estimated direction.|$|R
40|$|This paper {{studies the}} problem of {{ergodicity}} of transition <b>probability</b> <b>matrices</b> in Markovian models, such as hidden Markov models (HMMs), and how it makes very difficult the task of learning to represent long-term context for sequential data. This phenomenon hurts the forward propagation of long-term context information, as well as learning a hidden state representation to represent long-term context, which depends on propagating credit information backwards in time. Using results from Markov chain theory, we show that this problem of diffusion of context and credit is reduced when the transition probabilities approach 0 or 1, i. e., the transition <b>probability</b> <b>matrices</b> are sparse and the model essentially deterministic. The results found in this paper apply to learning approaches based on continuous optimization, such as gradient descent and the Baum-Welch algorithm. 1. Introduction Problems of learning on temporal domains can be significantly hindered {{by the presence of}} long [...] ...|$|R
