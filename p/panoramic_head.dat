9|15|Public
50|$|A {{panoramic}} tripod head is a {{piece of}} photographic equipment, mounted to a tripod, which allows photographers to shoot a sequence of images around the entrance pupil of a lens {{that can be used to}} produce a panorama. The primary function of the <b>panoramic</b> <b>head</b> is to precisely set the point of rotation about the entrance pupil for a given lens and focal length, eliminating parallax error.|$|E
50|$|In 1957, an {{entrepreneur}} requested {{a picture of}} his buildings, which stood at three of the corners of a street-crossing, and he wanted to show the group of buildings in one single photo, which would have to cover 360°. Using a Rolleiflex with a <b>panoramic</b> <b>head,</b> ten negatives were taken that, enlarged and mounted, resulted in a 360° photo. Leme then addressed the challenge of taking a 360° photo in a single negative.|$|E
5000|$|Camera cranes may be small, medium, or large, {{depending}} on the load capacity and length of the loading arm. Historically, the first camera crane provided for lifting the chamber together with the operator, and sometimes an assistant. The range of motion of the boom was restricted {{because of the high}} load capacity and the need to ensure operator safety. In recent years a camera crane boom tripod with a remote control has become popular. It carries on the boom only a movie or television camera without an operator and allows shooting from difficult positions as a small load capacity makes it possible to achieve a long reach of the crane boom and relative freedom of movement. The operator controls the camera from the ground through a motorized <b>panoramic</b> <b>head,</b> using remote control and video surveillance by watching the image on the monitor. A separate category consists of telescopic camera cranes. These devices allow setting an arbitrary trajectory of the camera, eliminating the characteristic jib crane radial displacement that comes with traditional spanning shots.|$|E
50|$|Robotic <b>panoramic</b> <b>heads</b> {{are also}} available. The robotic head {{performs}} the rotation and image capture functions automatically under computer control. Robotic heads {{can also be}} used with time-lapse photography.|$|R
5000|$|<b>Panoramic</b> <b>heads</b> {{facilitate}} {{taking a}} number of images that will be stitched {{together to make a}} single panoramic image. The most important function is to rotate the camera around the entrance pupil of the lens, frequently (but inaccurately) called the nodal point. Commercially available heads are categorized as [...] "single-row heads" [...] and [...] "multi-row heads". Single row heads rotate round a single vertical axis and typically require the lens axis to be positioned horizontally. Multi-row heads allow rotation about two axes.|$|R
50|$|Pan heads can be {{used for}} panoramas, but suffer from the {{deficiency}} that the axes of rotation normally do not go through the entrance pupil of the lens and thus can give rise to problems with parallax. A better choice for panoramas is a custom-built <b>panoramic</b> tripod <b>head.</b>|$|R
40|$|This thesis {{introduces}} the construction design of two-axis positioning device {{to be used}} as <b>panoramic</b> <b>head.</b> Theoretical part explains parts of the device and in the practical part is the device assembled. The result is a complete positioning device for digital camera Canon EOS 500 D and for similar camera...|$|E
40|$|Bachelor's thesis {{deals with}} {{stitching}} panoramic image, from its beginning given by setting properties of camera and 303 SPH Manfrotto <b>panoramic</b> <b>head,</b> to assembly of images captured in {{different kinds of}} scenery. This work describes the transformation used with stitching images, for calculating the matrix homograph from specific points of correspondence and transfer from plane to cylindrical or spherical coordinates. It also includes {{a description of the}} functions using the OpenCV library used in the assembly...|$|E
40|$|Two {{simulations}} {{were conducted}} to study the effect of dynamic perspective displays on performance measures collected during simulated flight. The first study was a pure altitude regulation task with simple first order plant dynamics. In the second simulation, pilots performed two basic rotary-wing flight tasks with dynamic perspective displays projected out-the-window (<b>panoramic</b> <b>head</b> up display) or on a panel mounted simulation of a sensor display. The data from the two studies, taken together, show that when such displays are used during flight, they will not degrade performance; and, under certain display configurations, they will minimize flight control errors...|$|E
5000|$|... #Caption: A <b>panoramic</b> tripod <b>head</b> {{keeps the}} point of view of the camera {{stationary}} by placing it in the axis of rotation. One must use the mount to adjust for the difference between the tripod mount and the focal point of the camera. This is accomplished by sliders on the mount.|$|R
50|$|At {{the upper}} portion, {{it offers a}} view of the south of the city {{including}} Várzea and its stadium, Gamboa, Ilhéu de Santa Maria and Prainha-Temerosa. It offers less <b>panoramic</b> views downhill <b>heading</b> southeast, where it offers a view of Praia Harbor and its port and a part of Achada Grande.|$|R
50|$|The team {{created an}} indoor-version of the Google Street View {{360-degree}} camera system to capture gallery images by pushing the camera 'trolley' through a museum. It also used professional <b>panoramic</b> <b>heads</b> CLAUSS RODEON VR Head HD and CLAUSS VR Head ST to take high resolution {{photos of the}} artworks within a gallery. Only this technology allowed to achieve the excellent attention to detail and this highest image resolution. Each partner museum selected one artwork to be captured at ultra-high resolution with approximately 1,000 times more detail than the average digital camera. The largest image, Alexander Andreyevich Ivanov's The Apparition of Christ to the People, is over 12 gigapixels. To further maximize image quality, the Google team coordinated with partner museums’ lighting technicians and photography teams. For example, at the Tate Britain, the Google team and Tate representatives collaborated to capture the Tate's gigapixel image No Woman No Cry in both natural light and in the dark. The Tate suggested this method, so that the Art Project could capture the painting's hidden phosphorescent image, which glows in the dark. The Google camera team had to adapt their method, and keep the camera shutter open for 8 seconds in the dark to capture a distinct enough image. Now, unlike at the Tate, Google Art Project visitors can view the painting in both light settings.|$|R
40|$|In this paper, {{we present}} a method for acquiring, {{spatially}} filtering and viewing annotated videos captured with a full field of view multi-head camera moving along a path. We describe our tailored ego-motion recovery algorithm used for calculating the trajectoiy path of the <b>panoramic</b> <b>head.</b> We then focus on sampluig the plenoptic path efficiently according to geomeeic visibility events. Appropriate samplings allow us to filter and compress the panoramic images avoiding some redundancies in the image database. We present several applications and results of plenoptic paths either obtained fmm indoor shootings or perfectly rendered by computer gmphics scripts. Keywords: Image-based modeling & rendering, Plenoptic sampling, Visibility. 1...|$|E
40|$|Abstract: The STEREOPOLIS mobile mapping system, {{developed}} in the MATIS laboratory of IGN for city modelling and multimedia applications, integrates a <b>panoramic</b> <b>head</b> composed of 10 full HD cameras very accurately synchronised. For each pose, a panoramic image is generated from the set of corresponding but poorly overlapping images. In this paper, we evaluate {{the performance of a}} three-step method {{developed in}} Craciun [1] that computes the relative pose between the different frame camera images composing the panoramic frame. A phototheodolite, i. e. a theodolite coupled with a digital camera, is used to construct a reference data set with a ground truth which is sufficiently accurate (to some extent) to evaluate by comparison the results of our pose estimation process. We present the different steps to compute, then we present the algorithm which is used as well as mathematic concept and finally results are commented the results of our pose estimation process will also be compared with an off-the-shelf high quality software using SIFT-based corresponding points and bundle adjustment, i. e. Autopano[2]. 1...|$|E
40|$|This paper {{deals with}} a fusion of range and {{panoramic}} images, where the range image is acquired by a 3 D laser scanner and the panoramic image is acquired with a digital still camera mounted on a <b>panoramic</b> <b>head</b> and tripod. The fused resulting dataset, called "textured range image", provides more reliable information about the investigated object for conservators and historians, than using both datasets separately. A simple example of fusion of a range and panoramic images, both obtained in St. Francis Xavier Church in town Opařany, is given here. Firstly, we describe the process of data acquisition, then the processing of both datasets into a proper format for following fusion {{and the process of}} fusion. The process of fusion can be divided into a two main parts: transformation and remapping. In the first, transformation, part, both images are related by matching similar features detected on both images with a proper detector, which results in transformation matrix enabling transformation of the range image onto a panoramic image. Then, the range data are remapped from the range image space into a panoramic image space and stored as an additional "range" channel. The process of image fusion is validated by comparing similar features extracted on both datasets...|$|E
40|$|We have {{analyzed}} {{the possibilities of}} a spacecraft-based meteor search in the atmosphere of planets, focusing on Earth and Mars. This work concentrates on the geometrical conditions and prospects when using the wide-angle camera SPOSH (Smart <b>Panoramic</b> Optical Sensor <b>Head)</b> in varying heights above the surface and incident angles of meteor streams...|$|R
40|$|Photographic {{observations}} {{were carried out}} from two stations in Greece monitoring the early activity of the Perseids from 22 nd to 30 th of July. Two Smart <b>Panoramic</b> Optical Sensor <b>Heads</b> (SPOSH) were deployed on Mts Mainalon and Parnon. The radiants, velocites and trajectories of meteors captured simultaneously from both stations have been determined. Here we present the results of 107 meteors, {{a subset of the}} several thousands recorded during the observations...|$|R
40|$|Background: Head neck {{cancer in}} Indonesia is quite high, which ranks fourth of all malignancies. Radiotherapy {{is still one}} of the most {{important}} treatment option for patients with head and neck cancer. In addition to tumor cells, ionizing radiation also affect healthy tissue around the target, resulting in serious side effects. Dental caries is not the main effect of radiotherapy, but evolved as a secondary condition. Dental caries in irradiated patients can be developed rapidly since 3 months after radiotherapy. To detect dental caries require radiographic evaluation with high accuracy. Panoramic radiographs have been used widely as a means of detection and screening in the case of dental pathology. Objective: Determine the incidence of dental caries through panoramic photos in patients who had completed radiotherapy neck head for at least 3 months at the Dr. Kariadi Hospital Semarang. Methods: This study was cross-sectional observational assess x <b>panoramic</b> picture <b>head</b> neck cancer patients who had completed radiotherapy. Subjects were patients who had completed radiotherapy for at least 3 months at the Dr. Kariadi Hospital Semarang (n = 20). Subjects of research done taking panoramic photos, and then the result are read by two expert radiologists in the department Dr. Kariadi Hospital Semarang. Results: The results of chi-square test showed a significant relationship between the head neck radiotherapy relation to the incidence of dental caries seen through panoramic photo (p < 0. 05). Conclusion: There were significant results that the head neck radiotherapy relation to the incidence of dental caries seen through a <b>panoramic</b> photo. Keywords: <b>head</b> neck radiotherapy, dental caries, panoramic photo...|$|R
40|$|We have {{developed}} a camera breadboard, SPOSH (Smart <b>Panoramic</b> Optical Sensor <b>Head),</b> designed for observations of transient phenomena on the night hemisphere of Earth (or other planets) from an orbiting spacecraft. The camera features a highly sensi-tive (1024 x 1024) CCD chip, a wide (> 120 °) field of view, is typically operated at a high rate (2 frames / sec), and has sophisticated built-in software for event detections and reporting. Event detection is currently optimized for the identification of atmos-pheric meteors. The instrument was successfully tested under real-sky conditions during prominent meteor showers of 2004...|$|R
40|$|We have {{developed}} the camera concept and breadboard SPOSH (Smart <b>Panoramic</b> Opti-cal Sensor <b>Head),</b> designed for observations of transient phenomena on the night hemisphere of Earth (or other planets) from an orbiting spacecraft. The camera features a highly sensitive (1024 x 1024) CCD chip, a wide (> 120 °) field of view, is typically operated at a high rate (2 frames / sec), and has sophisticated built-in software for event detections and reporting. The event detection for the breadboard is currently optimized for the identification of atmospheric meteors. The instrument was successfully tested under real-sky conditions during prominent meteor showers of 2004...|$|R
40|$|We {{will carry}} out a meteor observing {{campaign}} for the Perseids 2010 using the SPOSH (Smart <b>Panoramic</b> Optical Sensor <b>Head)</b> cameras (see. Fig. 1). The SPOSH camera has been developed at DLR and Jena Optronics under contract to ESA/ESTEC. The camera is designed to imaging faint transient noctilucent phenomena on dark planetary hemispheres and meteor observations of high radiometric and geometric quality have been demonstrated. The camera features a custom-made optical system with a field of view (FOV) of 120 ° x 120 ° (168 ° across the image diagonal) and {{is equipped with a}} highly sensitive back-illuminated 1024 x 1024 CCD chip. Two SPOSH cameras will be deployed at remote observing posts in Greece. The choice of the locations will assure a dark sky and favorable weather conditions, which prevail in southern Europe during the summer. From double-station observations (see Fig. 2), the trajectories and the orbits of the meteoroids will be calculated, and the photometric properties of the meteors will also be determined. Assuming a successful campaign, the observation results will be presented at the conference. The campaign will be organized by the DLR and the Technical University of Berlin, involving students and amateur astronomers from Greece...|$|R
40|$|We have {{developed}} a camera dedicated to imaging faint transient noctilucent phenomena, such as aurorae, electric discharges, meteors or impact flashes, on dark planetary hemispheres. The SPOSH (Smart <b>Panoramic</b> Optical Sensor <b>Head)</b> {{is equipped with a}} back-illuminated 1024 x 1024 CCD chip E 2 V 47 - 20 with up to 90 % quantum efficiency and has a custom-made optical system of high light-gathering power with a wide field of view of 120 x 120 º. Images can be obtained over extended periods at high rate to make monitoring for transient events possible. To reduce the data transmission rate, only those images (or relevant portions thereof) that contain events are returned to the user. The camera has a sophisticated processing unit prepared to interface with a spacecraft system, for image processing and event detection at rates of up to 3 images per second at full resolution. While software optimized for detection of any noctilucent phenomenon can be implemented, the software is currently optimized for the detection of meteors. Over the past years, we have routinely carried out outdoor tests with 4 camera breadboard units that demonstrate that the camera has excellent radiometric performance and geometric resolution at low light levels over its large field of view. The camera has been demonstrated to capture meteors of magnitudes as faint as + 6 m moving at angular speeds of 5 °/s. The camera opens up new science opportunities for planetary missions...|$|R
40|$|The Technical University of Berlin (TUB) and the German Aerospace Center (DLR) {{organize}} observing campaigns {{every summer}} monitoring the Perseids activity. The observations {{are carried out}} using the Smart <b>Panoramic</b> Optical Sensor <b>Head</b> (SPOSH) camera system. The SPOSH camera has been developed by DLR and Jena-Optronik GmbH under an ESA/ESTEC contract and {{it is designed to}} image faint, short-lived phenomena on dark planetary hemispheres. The camera features a highly sensitive back- illuminated 1024 x 1024 CCD chip and a high dynamic range of 14 bits. The custom-made fish-eye lens offers a 120 ◦x 120 ◦ field-of-view (168 ◦ over the diagonal). The observations will be made on the Greek Peloponnese peninsula monitoring the post-peak activity of the Perseids during a one-week period around the August New Moon (14 th to 21 st). Two SPOSH cameras will be deployed in two remote sites in high altitudes for the triangulation of meteor trajectories captured at both stations simultaneously. The observations during this time interval will give us the possibility to study the poorly-observed postmaximum branch of the Perseid stream and compare the results with datasets from previous campaigns which covered different periods of this long-lived meteor shower. The acquired data will be processed using dedicated software for meteor data reduction developed at TUB and DLR. Assuming a successful campaign, statistics, trajectories and photometric properties of the processed double-station meteors will be presented at the conference. Furthermore, a first order statistical analysis of the meteors processed during the 2011 and the new 2012 campaigns will be presented...|$|R
40|$|International audienceIn {{comparison}} with existing ground-based camera networks for meteors monitoring, a space-based optical system would escape dependency on weather and atmospheric conditions and would offer a wide spatial coverage and an unrestricted and extinction-free spectral domain. The potential rates of meteor detections by such systems are evaluated {{in this paper}} {{as a function of}} observations parameters (optical system capabilities, orbital parameters) and considering a reasonable range of meteoroids properties (e. g., mass, velocity, composition) determining their luminosity. A numerical tool called SWARMS (Simulator for Wide Area Recording of Meteors from Space) has been developed. SWARMS is also intended to be used in an operational phase to facilitate the comparison of observations with up-do-date constraints on the flux and characteristics of the interplanetary matter entering our planet׳s atmosphere. The laws governing the conversion of a fraction of the meteor kinetic energy into radiation during atmospheric entry have been revisited and evaluated based on an analysis of previously published meteor trajectories. Rates of detection were simulated for two different systems: the SPOSH (Smart <b>Panoramic</b> Optical Sensor <b>Head)</b> camera optimized for the observation of transient luminous events, and the JEM-EUSO (Japanese Experiment Module-Extreme Universe Space Observatory) experiment on the ISS (International Space Station). We conclude that up to 6 events per hour in the case of SPOSH, and up to 0. 67 events in the case of JEM-EUSO may be detected. The optimal orbit for achieving such rates of detections depends on the mass index of the meteoroid populations. The determination of this parameter appears therefore critical before an optimal orbiting system might be designed for meteors monitoring...|$|R

