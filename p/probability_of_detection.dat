2163|10000|Public
25|$|The US Coast Guard {{utilizes}} Monte Carlo methods {{within its}} computer modeling software SAROPS {{in order to}} calculate the probable locations of vessels during search and rescue operations. Each simulation can generate as many as ten thousand data points which are randomly distributed based upon provided variables. Search patterns are then generated based upon extrapolations of these data in order to optimize the probability of containment (POC) and the <b>probability</b> <b>of</b> <b>detection</b> (POD), which together will equal an overall probability of success (POS). Ultimately this serves as a practical application of probability distribution {{in order to provide}} the swiftest and most expedient method of rescue, saving both lives and resources.|$|E
25|$|After the {{implementation}} of the WSR-88D network in the U.S., the <b>probability</b> <b>of</b> <b>detection</b> of tornadoes increased substantially, the average lead time rose from four minutes to thirteen minutes, and a 2005 NOAA report estimates {{that as a result of}} improved warnings that there are 45 percent fewer fatalities and 40 percent fewer injuries annually. Dual-polarization radar, being implemented to the US NEXRAD network, may provide enhanced warning of tornadoes and severe winds and hail associated with the hook echo due to distinct precipitation drop characteristics. Polarimetric radar boosts precipitation observation and prediction, especially rainfall rates, hail detection, and distinguishing precipitation types. Proposed radar technologies, such as phased array and CASA, would further improve observations and forecasts by increasing the temporal and spatial resolution of scans in the former as well as providing low-level radar data over a wide area in the latter.|$|E
500|$|Several {{statistical}} scores can {{be based}} on the observed and forecast fields. [...] One, known as a bias, compares the size of the forecast field to the observed field, with the goal of a score of 1. [...] The threat score involves the intersection of the forecast and observed sets, with a maximum possible verification score of 1. [...] The <b>probability</b> <b>of</b> <b>detection,</b> or POD, is found by dividing the overlap between the forecast and observed fields {{by the size of the}} observed field: [...] the goal here is a score of 1. [...] The critical success index, or CSI, divides the overlap between the forecast and observed fields by the combined size of the forecast and observed fields: [...] the goal here is a score of 1. [...] The false alarm rate, or FAR, divides the area of the forecast which does not overlap the observed field by the size of the forecasted area. [...] The goal value in this measure is zero.|$|E
3000|$|... {{decide to}} {{transmit}} or not, {{based on the}} final combined sensing decision of the coalition head. Therefore, the <b>probabilities</b> <b>of</b> <b>detection</b> and false alarm of a coalition head are also the <b>probabilities</b> <b>of</b> <b>detection</b> and false alarm of each CR [...]...|$|R
3000|$|... =M= 1024. The <b>probabilities</b> <b>of</b> <b>detection</b> {{and false}} alarm {{are the results}} of 105 Monte Carlo simulations.|$|R
3000|$|Again, u≡d and u≡f {{represent}} the corresponding <b>probabilities</b> <b>of</b> <b>detection</b> or false alarm, respectively. Recall that [...]...|$|R
2500|$|<b>Probability</b> <b>of</b> <b>Detection</b> (POD): The {{likelihood}} of detecting an object or recognizing the search object. Different aircraft, environmental conditions and search object types {{can give a}} different <b>probability</b> <b>of</b> <b>detection.</b> Generally, the <b>probability</b> <b>of</b> <b>detection</b> decreases with increasing distance from the search object.|$|E
2500|$|The {{elements}} of the infrastructure themselves are also considered possible targets of terrorism. Traditionally, critical infrastructure elements have been lucrative targets for anyone wanting to attack another country. Now, because the infrastructure has become a national lifeline, terrorists can achieve high economic and political value by attacking {{elements of}} it. Disrupting or even disabling the infrastructure may reduce the ability to defend the nation, erode public confidence in critical services, and reduce economic strength. [...] Additionally, well chosen terrorist attacks can become easier and less costly than traditional warfare because of the interdependence of infrastructure elements. These infrastructure elements can become easier targets {{where there is a}} low <b>probability</b> <b>of</b> <b>detection.</b>|$|E
2500|$|The <b>probability</b> <b>of</b> <b>detection</b> is {{the square}} of the {{amplitude}} of the wave and can be calculated with classical waves (see below). The particles do not arrive at the screen in a predictable order, so knowing where all the previous particles appeared on the screen and in what order tells nothing about where a future particle will be detected. If there is a cancellation of waves at some point, {{that does not mean that}} a particle disappears; it will appear somewhere else. Ever since the origination of quantum mechanics, some theorists have searched for ways to incorporate additional determinants or [...] "hidden variables" [...] that, were they to become known, would account for the location of each individual impact with the target.|$|E
40|$|We {{consider}} a combined sleeping and censoring scheme for energy-efficient spectrum sensing in cognitive sensor networks. We analyze the <b>detection</b> performance <b>of</b> this scheme by theoretically deriving the global <b>probabilities</b> <b>of</b> <b>detection</b> and false-alarm. Our {{goal is to}} minimize the energy consumption incurred in distributed sensing, given constraints on the global <b>probabilities</b> <b>of</b> <b>detection</b> and false-alarm, by optimally designing the sleeping rate and the censoring thresholds. Using specific transceiver models for sensors based on IEEE 802. 15. 4 /ZigBee, we show the energy savings achieved under an optimum choice of the design parameters...|$|R
50|$|A testing {{reliability}} {{is a set}} <b>of</b> two <b>probabilities,</b> {{the definition}} <b>of</b> which varies by field. In medicine, the sensitivity and specificity are conventionally used. In the field <b>of</b> defect <b>detection</b> testing, the <b>probabilities</b> <b>of</b> <b>detection</b> and false call are conventionally used.|$|R
40|$|Abstract This letter {{addresses}} {{the problem of}} spectrum sensing over fading channel, in which a licensee and multiple unlicensed users coexist and operate in the licensed channel in a local area. We derive the overall average <b>probabilities</b> <b>of</b> <b>detection</b> and false alarm by jointly taking the fading {{and the location of}} SUs into account and employing the energy detection as the underlying detection scheme. Furthermore, we develop a statistical model of cumulate interference by the help of the overall average <b>probabilities</b> <b>of</b> <b>detection.</b> Based on the cumulate interference, we also obtain a closed-form expression <b>of</b> outage <b>probability</b> at the primary user's receiver according to a specific distribution of the fading. </p...|$|R
2500|$|The ROC {{curve is}} created by {{plotting}} the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. The true-positive rate {{is also known as}} sensitivity, recall or <b>probability</b> <b>of</b> <b>detection</b> in machine learning. The false-positive rate is also known as the fall-out or probability of false alarm and can be calculated as (1 − specificity). The ROC curve is thus the sensitivity as a function of fall-out. In general, if the probability distributions for both detection and false alarm are known, the ROC curve can be generated by plotting the cumulative distribution function (area under the probability distribution from [...] to the discrimination threshold) of the detection probability in the y-axis versus the cumulative distribution function of the false-alarm probability on the x-axis.|$|E
2500|$|A fourth {{hypothesis}} for an anti-predatory {{effect of}} fish schools is the [...] "encounter dilution" [...] effect. The dilution effect is an elaboration of safety in numbers, and {{interacts with the}} confusion effect. A given predator attack will eat a smaller proportion of a large shoal than a small shoal. Hamilton proposed that animals aggregate because of a [...] "selfish" [...] avoidance of a predator and was thus a form of cover-seeking. Another formulation of the theory was given by Turner and Pitcher and {{was viewed as a}} combination of detection and attack probabilities. In the detection component of the theory, it was suggested that potential prey might benefit by living together since a predator is less likely to chance upon a single group than a scattered distribution. In the attack component, it was thought that an attacking predator is less likely to eat a particular fish when a greater number of fish are present. In sum, a fish has an advantage if it is in the larger of two groups, assuming that the <b>probability</b> <b>of</b> <b>detection</b> and attack does not increase disproportionately with the size of the group.|$|E
6000|$|... "By no means," [...] replied Ratcliffe. [...] "That the {{imagination}} of this gentleman is disordered, I will not pretend to dispute; I have already told you that it has sometimes broken out into paroxysms approaching to real mental alienation. But it is of his common state of mind that I speak; it is irregular, but not deranged; the shades are as gradual as those that divide the light of noonday from midnight. The courtier who ruins his fortune for the attainment of a title which can do him no good, or power of which he can make no suitable or creditable use, the miser who hoards his useless wealth, and the prodigal who squanders it, are all marked with a certain shade of insanity. To criminals who are guilty of enormities, when the temptation, to a sober mind, bears no proportion to {{the horror of the}} act, or the <b>probability</b> <b>of</b> <b>detection</b> and punishment, the same observation applies; and every violent passion, as well as anger, may be termed a short madness." ...|$|E
30|$|Chair and Varshney {{provided}} the optimal data fusion rule in a distributed local hard decision detection system [13]. This optimal rule {{is in fact}} the sum of weighted local decisions where the weights are functions <b>of</b> <b>probabilities</b> <b>of</b> <b>detection</b> and false alarm.|$|R
3000|$|... {{is equal}} to m, if (15) is true. Two {{measures}} are of importance to characterize the quality <b>of</b> the <b>detection</b> algorithm: <b>probability</b> <b>of</b> missed <b>detection</b> Pmd and <b>probability</b> <b>of</b> false alarm Pfa. Both probabilities depend on the decision threshold ρ. The first one indicates the <b>probability</b> <b>of</b> a <b>detection</b> failure if a preamble is present but is not detected. The second one provides {{the probability that a}} preamble is detected if only noise is received.|$|R
50|$|A {{quality control}} {{procedure}} {{is considered to}} be optimum when it minimizes (or maximizes) a context specific objective function. The objective function depends on the <b>probabilities</b> <b>of</b> <b>detection</b> <b>of</b> the nonconformity of the process and of false rejection. These probabilities depend on the parameters of the quality control procedure (1) and on the probability density functions (see <b>probability</b> density function) <b>of</b> the monitored variables of the process.|$|R
5000|$|<b>Probability</b> <b>of</b> <b>Detection</b> (POD): The {{likelihood}} of detecting an object or recognizing the search object. Different aircraft, environmental conditions and search object types {{can give a}} different <b>probability</b> <b>of</b> <b>detection.</b> Generally, the <b>probability</b> <b>of</b> <b>detection</b> decreases with increasing distance from the search object.|$|E
50|$|A cascade chart is an {{alternative}} way from the traditional damage tolerance analysis (DTA) methodology for determining a reliable inspection interval. It uses the scatter from crack growth simulations, uncertainty in material properties, and <b>probability</b> <b>of</b> <b>detection</b> distribution to determine the NDI interval, given a desired cumulative <b>probability</b> <b>of</b> <b>detection</b> under a given confidence level.|$|E
5000|$|They {{are merely}} {{reacting}} to circumstances {{that increase the}} <b>probability</b> <b>of</b> <b>detection</b> or apprehension.|$|E
50|$|Grubbs' test detects one outlier at a time. This outlier is expunged {{from the}} dataset {{and the test}} is {{iterated}} until no outliers are detected. However, multiple iterations change the <b>probabilities</b> <b>of</b> <b>detection,</b> and the test {{should not be used}} for sample sizes of six or fewer since it frequently tags most of the points as outliers.|$|R
40|$|In {{this paper}} we {{introduce}} an algorithm for velocity estimation of a ground moving point target using a multi-channel along-track interferometry (MC-ATI) system. The presented results are {{relative to a}} multi frequency system, but the algorithm can be used also for a multi-baseline one. The performance {{of the system is}} evaluated by presenting also the <b>probabilities</b> <b>of</b> <b>detection...</b>|$|R
30|$|ASE systems allow massive deterrence. The device means a {{significant}} increase in the intensiveness of police surveillance and in the <b>probability</b> <b>of</b> effective <b>detection</b> <b>of</b> offenders.|$|R
50|$|The {{variable}} pi {{represents the}} <b>probability</b> <b>of</b> <b>detection</b> for each crack size, and the variable n represents {{the number of}} inspections conducted. Due to all the factors that {{play a role in}} determining the <b>probability</b> <b>of</b> <b>detection,</b> {{there will always be a}} non-zero probability that a crack will be missed, no matter what NDI method is used to inspect the structure.|$|E
50|$|The <b>probability</b> <b>of</b> <b>{{detection}}</b> {{and false}} detection rate is generally good, {{but it is}} application dependent.|$|E
50|$|The <b>probability</b> <b>of</b> <b>detection</b> {{distribution}} curve for a chosen NDI method is superimposed to the crack growth curve, and the inspection interval is systematically changed {{to compute the}} cumulative <b>probability</b> <b>of</b> <b>detection</b> for a crack growing from the minimum to the critical size. The simulation is repeated several times, and a distribution of inspection interval versus structural reliability can be formed. To refine the randomization of the values, the Latin Hypercube procedure was also introduced.|$|E
40|$|We {{substitute}} {{the fully}} absorbing obstacle in the Elitzur-Vaidman experiment by a semitransparent object {{and show that}} the <b>probabilities</b> <b>of</b> <b>detection</b> can be manipulated in dependence of the transparency of such an object. Then, we connect our results with the delayed choice experiment proposed by Wheeler. It is found that the transparency of the obstacle determines either a particle-like or a wave-like behaviour of a test photon...|$|R
3000|$|Usually, the {{performance}} of VAD algorithms is evaluated in terms of receiver operating characteristic (ROC) curves. For this, the <b>probability</b> <b>of</b> correct <b>detection</b> <b>of</b> speech P [...]...|$|R
40|$|Abstract—This paper {{presents}} a solution procedure of search parameter optimization for minimum load ensuring desired one-off and cumulative <b>probabilities</b> <b>of</b> <b>detection</b> in a multifunction phased array radar. The key {{approach is to}} convert this nonlinear optimization on four search parameters into a scalar optimization on signal-to-noise ratio by a semi-analytic process based on subproblem decomposition. The efficacy of the proposed solution approach is verified with theoretical analysis and numerical case studies...|$|R
50|$|The <b>probability</b> <b>of</b> <b>detection</b> (POD), a {{function}} of the NDI method, accessibility, and crack size, can be modeled by the equation below.|$|E
50|$|WAM {{provides}} {{performance that}} {{is comparable to}} secondary surveillance radar (SSR) in terms of accuracy, <b>probability</b> <b>of</b> <b>detection,</b> update rate and availability/ reliability. Performance varies {{as a function of}} the location of aircraft in relation to the ground sensors.WAM is adaptable to interrogation rates, output modes and output periods. Update rates and <b>probability</b> <b>of</b> <b>detection</b> can be tailored to various applications such as precision runway monitoring (PRM), terminal maneuvering area (TMA) and En-route surveillance. Interrogation rates can be reduced by passively processing replies to SSR or traffic collision avoidance system (TCAS) interrogations.|$|E
50|$|If we make {{realistic}} (wave-based) assumptions {{regarding the}} behaviour {{of light on}} encountering polarisers and photodetectors, we find {{that we are not}} compelled to accept that the <b>probability</b> <b>of</b> <b>detection</b> will reflect Malus' Law exactly.|$|E
5000|$|The Russian Nakidka {{camouflage}} kit {{was designed}} to reduce the Optical, Thermal, Infrared, and Radar signatures of a tank, so that acquisition of the tank would be difficult. According to Nii Stali, the designers of Nakidka, Nakidka would reduce the <b>probabilities</b> <b>of</b> <b>detection</b> via [...] "visual and near-IR bands by 30%, the thermal band by 2-3 fold, radar band by 6 fold, and radar-thermal band to near-background levels.|$|R
6000|$|In the meanwhile, {{the girl}} {{contrived}} {{an excuse for}} entering the room where she was quite aware Hetty and Clavering had met. She did not find her mistress, but, as it happened, noticed the writing-case, and, having a stake in affairs, opened it. Inside she found two sheets of paper, and after considering the <b>probabilities</b> <b>of</b> <b>detection</b> appropriated one <b>of</b> them on which was written, [...] "Larry dear." ...|$|R
40|$|Despite {{the concern}} that student {{plagiarism}} has become increasingly common, there is relatively little objective data on the prevalence or determinants of this illicit behavior. This study {{presents the results of}} a natural field experiment designed to address these questions. Over 1, 200 papers were collected from the students in undergraduate courses at a selective post-secondary institution. Students in half of the participating courses were randomly assigned to a requirement that they complete an anti-plagiarism tutorial before submitting their papers. We found that assignment to the treatment group substantially reduced the likelihood of plagiarism, particularly among student with lower SAT scores who had the highest rates of plagiarism. A follow-up survey of participating students suggests that the intervention reduced plagiarism by increasing student knowledge rather than by increasing the perceived <b>probabilities</b> <b>of</b> <b>detection</b> and punishment. These results are consistent with a model of student behavior in which the decision to plagiarize reflects both a poor understanding of academic integrity and the perception that the <b>probabilities</b> <b>of</b> <b>detection</b> and severe punishment are low. ...|$|R
