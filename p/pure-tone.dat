902|15|Public
5|$|The common {{starling}} is a noisy bird. Its song {{consists of}} a wide variety of both melodic and mechanical-sounding noises as part of a ritual succession of sounds. The male is the main songster and engages in bouts of song lasting for a minute or more. Each of these typically includes four varieties of song type, which follow each other in a regular order without pause. The bout starts with a series of <b>pure-tone</b> whistles and these are followed by the main part of the song, a number of variable sequences that often incorporate snatches of song mimicked from other species of bird and various naturally occurring or man-made noises. The structure and simplicity of the sound mimicked is of greater importance than the frequency with which it occurs. In some instances, a wild starling has been observed to mimic a sound it has heard only once. Each sound clip is repeated several times before the bird moves on to the next. After this variable section comes a number of types of repeated clicks followed by a final burst of high-frequency song, again formed of several types. Each bird has its own repertoire with more proficient birds having a range of up to 35 variable song types and as many as 14 types of clicks.|$|E
25|$|Tests of {{auditory}} system (hearing) function include <b>pure-tone</b> audiometry, speech audiometry, acoustic-reflex, electrocochleography (ECoG), otoacoustic emissions (OAE), {{and auditory}} brainstem response test (ABR; {{also known as}} BER, BSER, or BAER).|$|E
25|$|A {{binaural}} beat is an auditory illusion perceived {{when two}} different <b>pure-tone</b> sine waves, both with frequencies lower than 1500Hz, {{with less than}} a 40Hz difference between them, are presented to a listener dichotically (one through each ear).|$|E
40|$|This study {{investigates the}} {{relation}} between physical measurements of <b>pure-tones,</b> third-octave bands of noise and third-octave bands of speech and subjective judgments of auditory threshold, most-comfortable listening level (MCL) and uncomfortable-listening level (UCL) for three normally hearing listeners...|$|R
25|$|For example, if a 530Hz {{pure tone}} is {{presented}} to a subject's right ear, while a 520Hz pure tone {{is presented to}} the subject's left ear, the listener will perceive the auditory illusion of a third tone, {{in addition to the}} two <b>pure-tones</b> presented to each ear. The third sound is called a binaural beat, and in this example would have a perceived pitch correlating to a frequency of 10Hz, that being the difference between the 530Hz and 520Hz pure tones presented to each ear.|$|R
40|$|Abstract. The project {{aimed at}} {{developing}} a software audiometer for hearing loss screening. The proposed software is definitely {{based on the}} internal peripherals of the computer without any externals devices. It has functionality to test patient’s hearing by generating <b>pure-tones</b> and masking signal for airconducted or bone-conducted stimuli. Practical hearing losses measurements of hard and normal of hearing patients {{have been done in}} order to evaluate the performances of the proposed software. The hearing measurements have been assisted with ENTs specialized Doctors. The obtained audiograms have been compared with those of classical audiometers AC 33 and AC 50 Keywords: Audiometers, Hearing Losses. ...|$|R
50|$|Das mathematisch-reine Tonsystem mathematically <b>pure-tone</b> system, 1891.|$|E
50|$|Based on studies, it is {{believed}} that male A. musicus produced <b>pure-tone</b> (musical) songs using a resonant mechanism tuned at a frequency of 6.4 kHz.|$|E
50|$|Tests of {{auditory}} system (hearing) function include <b>pure-tone</b> audiometry, speech audiometry, acoustic-reflex, electrocochleography (ECoG), otoacoustic emissions (OAE), {{and auditory}} brainstem response test (ABR; {{also known as}} BER, BSER, or BAER).|$|E
40|$|Abstract—Early {{postnatal}} freeze-lesions to the cortical plate {{result in}} malformations resembling human microgyria. Micro-gyria in primary somatosensory cortex (S 1) of rats are asso-ciated with a reduced behavioral detection of rapid auditory transitions {{and the loss}} of large cells in the thalamic nucleus projecting to primary auditory cortex (A 1). Detection of slow transitions in sound is intact in animals with S 1 microgyria, suggesting dissociation between responding to slow versus rapid transitions and a possible dissociation between levels of auditory processing affected. We hypothesized that neu-ronal responses in primary auditory cortex (A 1) would be differentially reduced for rapid sound repetitions but not for slow sound sequences in animals with S 1 microgyria. We assessed layer IV cortical responses in primary auditory cor-tex (A 1) to single <b>pure-tones</b> and periodic noise bursts (PNB...|$|R
40|$|This {{study was}} {{designed}} to determine if there was a significant relationship among audiometric data, otoacoustic emissions, and cardiovascular fitness levels within a group of noise exposed individuals such as musicians versus a control group of non-musicians. Sixty-six volunteer participants were recruited from Miami University. Data was analyzed using Multivariate analyses to contrast and compare research variables as well as Pearson’s correlation coefficient and linear regression analyses to assess significance between and within groups. No difference in otoacoustic emissions, <b>pure-tones</b> or fitness level was found within and between the subject groups. One significant association was found within the group of musicians concerning the signal to noise ratios of the otoacoustic emissions. Significance was attributed to the absolute signal to noise ratio amplitudes between frequencies at 2000 and 4000 Hz within the musician subject grou...|$|R
40|$|The present paper {{investigates the}} {{influence}} of the bichord interval between two <b>pure-tones</b> on perceptual simultaneity. In the experiment, 30 participants (musicians and non musicians) listened to tone pairs (bichords: C-D; C-E flat; C-F sharp; C-G) with different degrees of asynchronization and indicated whether two tones had been simultaneous or successive. The method of constant stimuli was used. An ANOVA showed that bichords intervals were perceived with different degrees of simultaneity (p< 0. 0001). Tones that are less distant in frequency are not necessarily easier to perceive as simultaneous. This result suggests that judgement of simultaneity cannot be accounted for only in terms of frequency or temporal relationship between single stimuli at the physical level. The effect of a non temporal variable concerning the perceptual moment hypothesis is discussed...|$|R
50|$|Matched {{filters are}} often used in signal detection. As an example, suppose that we wish to judge the {{distance}} of an object by reflecting a signal off it. We may choose to transmit a <b>pure-tone</b> sinusoid at 1 Hz. We assume that our received signal is an attenuated and phase-shifted form of the transmitted signal with added noise.|$|E
50|$|Click stimuli have no {{frequency}} specificity, {{thus it is}} {{not possible}} to know which frequencies specifically contribute to a click threshold. tonal stimuli are required to obtain frequency-specific thresholds. An ideal tone burst has energy at a <b>pure-tone</b> frequency (e.g. 2000 Hz) regardless of the intensity. This tone burst would stimulate the corresponding area on the basilar membrane. However, if a tone burst is too short in duration, it could cause spectral splatter and lose its frequency selectivity. Tone bursts approximately 5 cycles in duration appear to be acceptable.|$|E
50|$|Hearing loss is {{classified}} as mild, moderate, severe or profound. <b>Pure-tone</b> audiometry for air conduction thresholds at 500, 1000 and 2000 Hz is traditionally used to classify the degree of hearing loss in each ear. Normal hearing thresholds {{are considered to be}} 25 dB sensitivity, though it has been proposed that this threshold is too high, and that 15 dB (about half as loud) is more typical. Mild hearing loss is thresholds of 25-45 dB; moderate hearing loss is thresholds of 45-65 dB; severe hearing loss is thresholds of 65-85 dB; and profound hearing loss thresholds are greater than 85 dB.|$|E
50|$|In general, three {{different}} types of sounds are produced by dolphins (and other toothed whales). These are click trains, which are made of numerous individual clicks, usually broadband signals that change from low value to high value quickly, burst pulses, which are individual clicks with high repetition and can be heard by humans only as a buzzing sound, and whistles, which are signals that are <b>pure-tones</b> and whose frequency varies depending on the time. Dusky dolphins produce all three sounds, but most commonly make burst pulses. Whistling is more common when dusky dolphins mingle with other dolphin species such as common dolphins. Their echolocation signals are broadband and of short duration, much like those other whistle-producing toothed whales. They tend to have bimodal frequency spectra which peak between 40 and 50 kHz at low frequency and between 80 and 110 kHz at high frequency. The species' echolocation signals are about 9-12 dB lower than for the larger white-beaked dolphin.|$|R
40|$|Mosquitoes hear {{with their}} antennae, which in most species are sexually dimorphic. Johnston, who {{discovered}} the mosquito auditory organ {{at the base of}} the antenna 150 years ago, speculated that audition was involved with mating behaviour (1). Indeed, male mosquitoes are attracted to female flight-tones (2 - 4). The male auditory organ has been proposed to act as an acoustic filter for female flight-tones, but female auditory behaviour is unknown (5). We show, for the first time, interactive auditory behaviour between males and females that leads to sexual recognition. Individual males and females both respond to <b>pure-tones</b> by altering wing-beat frequency. Behavioural auditory tuning curves, based on minimum threshold sound levels that elicit a change in wing-beat frequency to pure tones, are sharper than the mechanical tuning of the antennae, with males being more sensitive than females. We flew opposite-sex pairs of tethered Toxorhynchites brevipalpis and found that each mosquito alters its wing-beat frequency in response to the flight-tone of the other, so that within seconds their flight-tone frequencies are closely matched, if not completely synchronised. The flight-tones of same-sex pairs may converge in frequency but eventually diverge dramatically...|$|R
40|$|For {{communication}} headsets {{equipped with}} active noise reduction (ANR), {{the performance of}} the control system may influence the communication signal reaching the ear. Conversely, the communication signal may perturb the operation of the ANR system. The interaction between the communication and control signals depends primarily on the control structure, and on the bandwidths and frequency responses of the signal channels. The effects are described for two circumaural communication headsets with similar passive, and active, noise reductions, one with an analog feedback control system and the other an adaptive digital feedforward control system. Measurements were conducted in a diffuse sound field, with the headsets mounted on a head and torso simulator. The frequency response of sound reproduced by the communication channel was measured when the ANR system was not operating, and when the control system was operating, with swept <b>pure-tones,</b> and broadband noise. The speech intelligibility was estimated for environmental noise shaped to represent the spectrum of speech, the noise within a tank, or the noise within an aircraft cockpit, by the Speech Transmission Index (STI). The STI and fidelity of sound reproduced by the communication channel of the device with a feed-forward control structure tended to exceed that of the more common feedback control structure. This appeared to be a consequence of the compromised frequency response of the earphone an...|$|R
5000|$|Speech {{audiometry}} is {{a diagnostic}} hearing test designed to test word or speech recognition. It {{has become a}} fundamental tool in hearing-loss assessment. In conjunction with <b>pure-tone</b> audiometry, it can aid in determining the degree and type of hearing loss. Speech audiometry also provides information regarding discomfort or tolerance to speech stimuli and information on word recognition abilities. In addition, information gained by speech audiometry can help determine proper gain and maximum output of hearing aids and other amplifying devices for patients with significant hearing losses and help assess how well they hear in noise. Speech audiometry also facilitates audiological rehabilitation management.|$|E
50|$|Fixation of the stapes {{within the}} oval window causes a {{conductive}} hearing loss. In <b>pure-tone</b> audiometry, this manifests as air-bone gaps on the audiogram (i.e. {{a difference of}} more than 10 dB between the air-conduction and bone-conduction thresholds at a given test frequency). However, medial fixation of the ossicular chain impairs both the inertial and osseotympanic modes of bone conduction, increasing the bone-conduction thresholds between 500 Hz and 4 kHz, and reducing the size of air-bone gaps. As 2 kHz is the resonant frequency of the ossicular chain, the largest increase in bone-conduction threshold (around 15 dB) occurs at this frequency - the resultant notch is called Carhart's notch and is a useful clinical marker for medial ossicular-chain fixation.|$|E
50|$|To {{judge the}} {{distance}} of the object, we correlate the received signal with a matched filter, which, in the case of white (uncorrelated) noise, is another <b>pure-tone</b> 1-Hz sinusoid. When the output of the matched filter system exceeds a certain threshold, we conclude with high probability that the received signal has been reflected off the object. Using the speed of propagation and the time that we first observe the reflected signal, we can estimate {{the distance of}} the object. If we change the shape of the pulse in a specially-designed way, the signal-to-noise ratio and the distance resolution can be even improved after matched filtering: this is a technique known as pulse compression.|$|E
40|$|Thresholds for {{detecting}} {{a gap between}} two complex tones were determined for young listeners with normal hearing and old listeners with mild age-related hearing loss. The leading tonal marker was always a 20 -ms, 250 -Hz complex tone with energy at 250, 500, 750, and 1000 thinsp;Hz. The lagging marker, also tonal, could differ from the leading marker with respect to fundamental frequency (f 0), the presence versus absence of energy at f 0, {{and the degree to}} which it overlapped spectrally with the leading marker. All stimuli were presented with steeper (1 thinsp;ms) and less steep (4 thinsp;ms) envelope rise and fall times. F 0 differences, decreases in the degree of spectral overlap between the markers, and shallower envelope shape all contributed to increases in gap-detection thresholds. Age differences for gap detection of complex sounds were generally small and constant when gap-detection thresholds were measured on a log scale. When comparing the results for complex sounds to thresholds obtained for <b>pure-tones</b> in a previous study by Heinrich and Schneider [(2006). J. Acoust. Soc. Am. 119, 2316 ndash; 2326], thresholds increased in an orderly fashion from markers with identical (within-channel) pure tones to different (between-channel) pure tones to complex sounds. This pattern of results was true for listeners of both ages although younger listeners had smaller thresholds overall...|$|R
40|$|Introduction Enhanced {{auditory}} {{perception in}} musicians {{is likely to}} result from auditory perceptual learning during several years of training and practice. Many {{studies have focused on}} biological processing of auditory stimuli among musicians. However, {{there is a lack of}} literature on temporal resolution and active auditory discrimination skills in vocal musicians. Objective The aim of the present study is to assess temporal resolution and active auditory discrimination skill in vocal musicians. Method The study participants included 15 vocal musicians with a minimum professional experience of 5 years of music exposure, within the age range of 20 to 30 years old, as the experimental group, while 15 age-matched non-musicians served as the control group. We used duration discrimination using <b>pure-tones,</b> pulse-train duration discrimination, and gap detection threshold tasks to assess temporal processing skills in both groups. Similarly, we assessed active auditory discrimination skill in both groups using Differential Limen of Frequency (DLF). All tasks were done using MATLab software installed in a personal computer at 40 dBSL with maximum likelihood procedure. The collected data were analyzed using SPSS (version 17. 0). Result Descriptive statistics showed better threshold for vocal musicians compared with non-musicians for all tasks. Further, independent t-test showed that vocal musicians performed significantly better compared with non-musicians on duration discrimination using pure tone, pulse train duration discrimination, gap detection threshold, and differential limen of frequency. Conclusion The present study showed enhanced temporal resolution ability and better (lower) active discrimination threshold in vocal musicians in comparison to non-musicians...|$|R
40|$|Although neural {{responses}} to sound stimuli have been thoroughly investigated in various {{areas of the}} auditory cortex, the results electrophysiological recordings cannot establish a causal link between neural activation and brain function. Electrical microstimulation, which can selectively perturb neural activity in specific parts of the nervous system, is an important tool for exploring the organization and function of brain circuitry. To date, the studies describing the behavioral effects of electrical stimulation have largely been conducted in the primary auditory cortex. In this study, to investigate the potential differences in the effects of electrical stimulation on different cortical areas, we measured the behavioral performance of cats in detecting intra-cortical microstimulation (ICMS) delivered in the primary and secondary auditory fields (A 1 and A 2, respectively). After being trained to perform a Go/No-Go task cued by sounds, we found that cats could also learn to perform the task cued by ICMS; furthermore, the detection of the ICMS was similarly sensitive in A 1 and A 2. Presenting wideband noise together with ICMS substantially decreased the performance of cats in detecting ICMS in A 1 and A 2, consistent with a noise masking effect on the sensation elicited by the ICMS. In contrast, presenting ICMS with <b>pure-tones</b> in the spectral receptive field of the electrode-implanted cortical site reduced ICMS detection performance in A 1 but not A 2. Therefore, activation of A 1 and A 2 neurons may produce different qualities of sensation. Overall, our study revealed that ICMS-induced neural activity could be easily integrated into an animal’s behavioral decision process and had an implication {{for the development of}} cortical auditory prosthetics...|$|R
50|$|A {{binaural}} beat is an auditory illusion perceived {{when two}} different <b>pure-tone</b> sine waves, both with frequencies lower than 1500 Hz, {{with less than}} a 40 Hz difference between them, are presented to a listener dichotically (one through each ear).For example, if a 530 Hz pure tone is presented to a subject's right ear, while a 520 Hz pure tone is presented to the subject's left ear, the listener will perceive the auditory illusion of a third tone, in addition to the two pure-tones presented to each ear. The third sound is called a binaural beat, and in this example would have a perceived pitch correlating to a frequency of 10 Hz, that being the difference between the 530 Hz and 520 Hz pure tones presented to each ear.|$|E
50|$|The flight {{call of the}} {{chipping}} sparrow is heard year-round. Its flight call is piercing and <b>pure-tone,</b> lasting about 50 milliseconds. It starts out around 9 kHz, then falls to 7 kHz, then rises again to 9 kHz. The flight call may be transliterated as seen? Chipping sparrows migrate by night, and their flight calls are a characteristic sound {{of the night sky}} in spring and fall in the United States. In the southern Rockies and eastern Great Plains, the {{chipping sparrow}} appears to be the most common nocturnal migrant, judged by the number of flight calls detected per hour. On typical nights in August in this region, chipping sparrows may be heard at a rate of 15 flight calls per hour. On better-than-average nights, chipping sparrows occur at a rate of 60 flight calls per hour, and on exceptional nights chipping sparrows' flight calls are heard more than 200 times per hour.|$|E
5000|$|Published in 1994, {{this patient}} was {{monitored}} {{over the course}} of almost 20 years after exhibiting signs of hearing impairment as an infant. Audiologic and related test results in concurrence with MRI confirmed bilateral absence of considerable portions of her temporal lobes resulting in cortical deafness. Although physiologic measures demonstrate normal peripheral hearing sensitivity, this patient's speech has the inflection and prosodic characteristics associated with profound peripheral hearing loss, and she is unable to understand spoken communication. Behaviorally obtained <b>pure-tone</b> thresholds were variable, ranging from normal to moderate hearing loss with normal middle ear muscle reflexes and normal ABRs to high- and low-intensity stimuli. Auditory middle latency and cortical evoked potentials were grossly abnormal, consistent with the central nature of cortical deafness. Because of her inability to communicate auditorily, this patient was ultimately taught American Sign Language and educated at the Louisiana School for the Deaf. At the completion of the case study, the patient was married and expecting a child.|$|E
40|$|OBJETIVO: Comparar o desempenho entre mulheres jovens e idosas para o Random Gap Detection Test (RGDT). MÉTODOS: Foram avaliadas 72 mulheres, distribuídas em dois grupos: Grupo Controle (GC), composto por 48 jovens (idade média: 23, 8 anos) com audição periférica normal, e Grupo Experimental (GE), composto por 24 idosas (idade média 66, 8 anos) com audição periférica normal ou curva audiométrica do tipo neurossensorial de grau leve. Os indivíduos dos dois grupos foram submetidos ao RGDT para tons puros, nas frequências de 500, 1000, 2000 e 4000 Hz. RESULTADOS: Todos os indivíduos do GC identificaram intervalo até 40 ms em todas as frequências, sendo o intervalo médio de respostas entre as frequências 12, 2 ms. Com relação ao GE, observamos que 20 dos 24 indivíduos não identificaram o intervalo até 40 ms em uma ou mais freqüências. A análise dos dados mostrou diferença estatisticamente significante entre o desempenho dos dois grupos (p PURPOSE: To {{compare the}} {{performances}} of young and elderly women on the Random Gap Detection Test (RGDT). METHODS: Seventy two women were evaluated, distributed in two groups: Control Group (CG), composed by 48 young women (mean age = 23. 8 years) with normal peripheral hearing, and Experimental Group (EG), composed by 24 elderly women (mean age = 66. 8 years) with normal peripheral hearing or mild sensorineural hearing loss. Both groups were submitted to the RGDT for <b>pure-tones,</b> in the frequencies of 500, 1000, 2000 and 4000 Hz. RESULTS: All subjects from CG identified gaps up to 40 ms in all tested frequencies, with average gap of 12. 2 ms among them. In the EG, {{it was observed that}} 20 out of the 24 subjects did not identify intervals up to 40 ms in one or more frequencies. Data analysis showed statistically significant differences between {{the performances of}} the groups (p< 0001). CONCLUSIONS: Age increase was shown as an aggravating factor for performance on the RGDT. This test proved to be a valuable tool for the evaluation of aging effects on auditory temporal resolution ability...|$|R
40|$|Background: Individuals {{with autism}} {{spectrum}} disorder (ASD) show atypical brain activity, {{perhaps due to}} delayed maturation. Previous studies examining the maturation of auditory electrophysiological activity have been limited due to their use of cross-sectional designs. The present study took {{a first step in}} examining magnetoencephalography (MEG) evidence of abnormal auditory response maturation in ASD via the use of a longitudinal design. Methods: Initially recruited for a previous study, 27 children with ASD and nine typically developing (TD) children, aged 6 - to 11 -years-old, were re-recruited two to five years later. At both timepoints, MEG data were obtained while participants passively listened to sinusoidal <b>pure-tones.</b> Bilateral primary/secondary auditory cortex time domain (100  ms evoked response latency (M 100)) and spectrotemporal measures (gamma-band power and inter-trial coherence (ITC)) were examined. MEG measures were also qualitatively examined for five children who exhibited “optimal outcome”, participants who were initially on spectrum, but no longer met diagnostic criteria at follow-up. Results: M 100 latencies were delayed in ASD versus TD at the initial exam (~ 19  ms) and at follow-up (~ 18  ms). At both exams, M 100 latencies were associated with clinical ASD severity. In addition, gamma-band evoked power and ITC were reduced in ASD versus TD. M 100 latency and gamma-band maturation rates did not differ between ASD and TD. Of note, the cohort of five children that demonstrated “optimal outcome” additionally exhibited M 100 latency and gamma-band activity mean values in-between TD and ASD at both timepoints. Though justifying only qualitative interpretation, these “optimal outcome” related data are presented here to motivate future studies. Conclusions: Children with ASD showed perturbed auditory cortex neural activity, as evidenced by M 100 latency delays as well as reduced transient gamma-band activity. Despite evidence for maturation of these responses in ASD, the neural abnormalities in ASD persisted across time. Of note, data from the five children whom demonstrated “optimal outcome” qualitatively suggest that such clinical improvements may be associated with auditory brain responses intermediate between TD and ASD. These “optimal outcome” related results are not statistically significant though, likely due to the low sample size of this cohort, and to be expected {{as a result of the}} relatively low proportion of “optimal outcome” in the ASD population. Thus, further investigations with larger cohorts are needed to determine if the above auditory response phenotypes have prognostic utility, predictive of clinical outcome...|$|R
5000|$|A {{more recent}} study, {{published}} in 2013 the patient described is a 56-year-old woman {{a history of}} hypertension, hypercholesterolemia, and multiple cerebrovascular accident (CVA) who presented in March 2009 with a complaint of complete bilateral hearing loss. In March 2009, she experienced an acute right-sided insulotemporal intracerebral hemorrhage. Immediately after this event, the patient complained of hearing loss with the inability to hear all sounds except for severe bilateral tinnitus. Imaging revealed sequelae in the left cerebral cortex from her previous CVA. The new right-sided hemorrhage was centered on the posterior putamen with surrounding edema involving the posterior portion of the posterior limbs of the internal, external, and extreme capsules. Signal abnormalities extended into the right temporal lobe. The patient had no other neurologic deficits and spoke fluently, although with poor internal volume control of her voice. Otoscopic examination revealed normal-appearing external auditory canals, intact tympanic membranes bilaterally, and normal middle ear anatomy. Audiogram at that time showed bilateral profound hearing loss with no responses to <b>pure-tone</b> or speech testing.|$|E
5000|$|Evoked otoacoustic {{emissions}} are currently evoked using three different methodologies. Stimulus Frequency OAEs (SFOAEs) are measured during {{the application of}} a <b>pure-tone</b> stimulus, and are detected by the vectorial difference between the stimulus waveform and the recorded waveform (which consists of the sum of the stimulus and the OAE). Transient-evoked OAEs (TEOAEs or TrOAEs) are evoked using a click (broad frequency range) or toneburst (brief duration pure tone) stimulus. The evoked response from a click covers the frequency range up to around 4 kHz, while a toneburst will elicit a response from the region that has the same frequency as the pure tone. Distortion product OAEs (DPOAEs) are evoked using a pair of primary tones [...] and [...] with particular intensity (usually either 65 - 55 dBSPL or 65 for both) and ratio (...) [...] The evoked responses from these stimuli occur at frequencies (...) mathematically related to the primary frequencies, with the two most prominent being [...] (the [...] "cubic" [...] distortion tone, most commonly used for hearing screening) and [...] (the [...] "quadratic" [...] distortion tone, or simple difference tone).|$|E
50|$|The common {{starling}} is a noisy bird. Its song {{consists of}} a wide variety of both melodic and mechanical-sounding noises as part of a ritual succession of sounds. The male is the main songster and engages in bouts of song lasting for a minute or more. Each of these typically includes four varieties of song type, which follow each other in a regular order without pause. The bout starts with a series of <b>pure-tone</b> whistles and these are followed by the main part of the song, a number of variable sequences that often incorporate snatches of song mimicked from other species of bird and various naturally occurring or man-made noises. The structure and simplicity of the sound mimicked is of greater importance than the frequency with which it occurs. In some instances, a wild starling has been observed to mimic a sound it has heard only once. Each sound clip is repeated several times before the bird moves on to the next. After this variable section comes a number of types of repeated clicks followed by a final burst of high-frequency song, again formed of several types. Each bird has its own repertoire with more proficient birds having a range of up to 35 variable song types and as many as 14 types of clicks.|$|E
5000|$|Considerations when {{determining}} {{an effective}} school-based screening protocol {{in developing countries}} includes hearing loss criteria, screening tools, and an appropriate referral pathway. In regards to the pass/fail criteria for hearing screenings, the American Speech-Language-Hearing Association (ASHA) guidelines use a >20 dB HL cut-off intensity (Roush, 1990) {{though there is a}} growing tendency for audiologists in developed countries to use a >15 dB HL criteria. The World Health Organization (WHO) criterion for [...] "priority for hearing aids" [...] in children is an average hearing loss in the 31 to 80 dB HL range in the better ear (WHO, 2004). However, if there is a local capacity to provide appropriate hearing health care, according to McPherson and Olusanya (2008), then this does not preclude screening that also targets milder degrees of hearing loss. Research has shown that even minimal intervention such as preferential seating in the classroom may improve educational outcomes for children with slight and mild hearing loss and unilateral hearing loss (McPherson & Holborow, 1985; Olusanya et al., 2004).The three recommended tests in school-based-screenings for developing countries are otoscopy, <b>pure-tone</b> audiometry screening, and otoacoustic emissions (OAEs). Otoscopy is useful in the examination of the external ear, ear canal, and tympanic membrane. Otoscopic examination is useful in ruling out impacted cerumen. According to Rao et al. (2002), Lyn et al. (1998), and Swart et al. (1995), impacted cerumen {{is one of the most}} common ear diseases and causes of hearing loss, with prevalence rate between 7.4% and 63%. Additionally, otoscopy does not require a great deal of expertise beyond basic training and is useful to refer a child when the tympanic membrane cannot be visualized due to occlusion of the external auditory meatus by cerumen.Pure-tone audiometry screening, in which there is typically no attempt to find threshold, has been found to accurately assess hearing status in children six years and older, when trained health workers in the community of rural Bangladeshi village used a simple condition play response procedure (Berg et al., 2006 [...] ). Recommended test frequencies are 1000, 2000, and 4000 Hz, at 20 dB HL according to the ASHA (1997) guidelines for screening audiometry. However, 500 Hz has been found to identify the auditory impact of otitis media with effusion in children and should be included at 25 dB HL when permitted by ambient noise levels (WHO, 1997). [...] In regards to equipment, noise-excluding earphones are advisable in order to limit external noise factors. If possible, though costly, an effective way to reduce background noise is through the use of a mobile hearing screening facility. Examples of such a facility include the use of a 4x4 vehicles in the HARK Project of South Africa (Ogilvy & Michelson, 2003). These facilities incorporate a sound-treated environment for hearing screening. Lastly, in order to reduce operator errors, Roeser and Clark (2004) recommend a minimum training program of no less than five days while WHO recommends an initial three-week training program (WHO, 2004) for ‘primary ear health workers.’Otoacoustic emissions (OAEs) can be in both newborns and child based hearing screenings. OAEs are an objective tool that can be used to measure the integrity of the outer hair cells in the cochlear; however, test results below 2000 Hz can be adversely affected by high levels of ambient noise in the school environment (Nozza, 2001 [...] ). OAEs can be used in populations where responses to <b>pure-tone</b> audiometry are either unable to be obtained or results are unreliable. OAEs may be particularly useful in the screening of preschool age children.|$|E
50|$|Although Scharf et al.’s (1993, 1994, 1997) {{experiments}} {{failed to}} produce any clear differences in the basic psychophysical characteristics of hearing (other than the detection of unexpected sounds), many other studies using both animals and humans have implicated the OCB in listening-in-noise tasks using more complex stimuli. In constant BGN, rhesus monkeys with intact OCBs have been observed to perform better in vowel discrimination tasks than those without (Dewson, 1968). In cats, an intact OCB is associated with better vowel identification (Heinz et al., 1998), sound localisation (May et al., 2004), and intensity discrimination (May and McQuone, 1995). All of these studies were performed in constant BGN. In humans, speech-in-noise discrimination measurements have been performed on individuals who had undergone unilateral vestibular neurectomy (resulting in OCB sectioning). Giraud et al. (1997) observed a small advantage in the healthy ear over the operated ear for phoneme recognition and speech intelligibility in BGN. Scharf et al. (1988) had previously investigated the role of auditory attention during speech perception, and suggested that speech-in-noise discrimination is assisted by attentional focus on frequency regions. In 2000, Zeng et al., reported that vestibular neurectomy did not directly affect <b>pure-tone</b> thresholds or intensity discrimination, confirming earlier findings of Scharf et al. 1994; 1997. For the listening-in-noise tasks, they observed a number of discrepancies between the healthy and operated ear. Consistent with the earlier findings of May and McQuone (1995), intensity discrimination in noise was observed to be slightly worse in the ear without olivocochlear bundle (OCB) input. However, Zeng et al.’s main finding related to the “overshoot” effect, which {{was found to be}} significantly reduced (~50%) in the operated ears. This effect was first observed by Zwicker (1965), and was characterised as an increased detection threshold of a tone when it is presented {{at the onset of the}} noise compared to when it is presented in constant, steady-state noise. Zeng et al. proposed that this finding is consistent with MOCS-evoked antimasking; that is, MOCS-evoked antimasking being absent at the onset of noise however becoming active during steady-state noise. This theory was supported by the time course of MOC activation; being similar to the time course of the overshoot effect (Zwicker, 1965), as well as the overshoot effect being disrupted in subjects with sensorineural hearing loss, for whom the MOCS would be most likely ineffectual (Bacon and Takahashi, 1992).|$|E
40|$|Purpose: The vast {{majority}} of previous studies {{suggest that there is}} no relationship between the acceptable noise level (ANL) and <b>pure-tone</b> hearing thresholds reported as the average <b>pure-tone</b> hearing thresholds (<b>pure-tone</b> average). This study aims to explore (a) the relationship between hearing thresholds at individual frequencies and the ANL and (b) a measure of the slope of the audiogram and ANL. Method: Sixty-three Danish adult hearing aid users participated. Assessments were <b>pure-tone</b> audiogram and 3 different versions of the ANL test made monaurally at 2 different sessions. Results: The findings show that low-frequency hearing thresholds and the slope of the audiogram are significantly related to all versions of the ANL. Conclusion: It is possible that previous studies have failed to discover a relationship between ANL and hearing thresholds due {{to the use of the}} broad 4 -frequency <b>pure-tone</b> average. This has implications for our understanding of the ANL test...|$|E
40|$|It {{was found}} that intense pure-tones which damage hair cells in chicks, also result in damage to the tectorial {{membrane}} ((TM)). This {{study was designed to}} elucidate the effects of a second <b>pure-tone</b> insult on hair cells which survived a priming <b>pure-tone</b> exposure. Chicks were exposed to a <b>pure-tone</b> of 1. 5 kHz at 124 dB SPL. Lesion was found in both (TM) and hair cells, but the area of damage to the (TM) was much larger than that to the hair cells. Following this exposure, chicks were exposed to a second intense <b>pure-tone</b> at 2. 2 kHz 124 dB SPL. The frequency of the second exposure corresponded to a region where the (TM) did, but hair cells {{did not appear to be}} injured by the first exposure. The second exposure caused significantly less hair cell damage in chicks already exposed to the 1. 5 kHz <b>pure-tone</b> than in controls which were not primed with the first exposure. This finding suggests that the first exposure provides a degree of protection for the surviving hair cells, perhaps by uncoupling them from the (TM) ...|$|E
