2|25|Public
40|$|Balanced laminates, {{with zero}} {{in-plane}} to out-of-plane stiffness coupling are optimised over {{a range of}} tri-axial (Nx, Ny and Nxy) critical design loadings for minimum normalised elastic energy; equivalent to optimising for minimum mass {{in the absence of}} matrix failure. Laminates comprising standard angle plies (0 , ± 45  and 90 ) are designed for either a fixed design loading with a 10 % minimum ply <b>percentage</b> <b>rule</b> (current practice) or directly for an uncertain design loading. Results show that the 10 % rule performs well for the majority of design loadings. Nevertheless, for 8 % of design loads considered, significantly lower mass (> 10 %) designs are achieved with standard angle plies when designing directly for uncertain loading. Expansion of the ply envelope to include designs with continuous angles (0 ° ≤ θ ≤ 180 °) under an uncertain loading allows maximum mass savings up to 16 % over current design practice. However, when designing directly for an uncertain loading, no significant mass reductions are achieved through the use of continuous angles...|$|E
40|$|An {{approach}} is presented for the optimization of stiffened composite skins, which guarantees the continuity (blending) of plies over all individual panels. To fulfill design guidelines {{with respect to}} symmetry, balance, contiguity, disorientation and <b>percentage</b> <b>rule</b> of the layup, first a stacking sequence table is generated. Next, a novel multi-level set gradient based method is introduced for the global optimization of the location of ply drops. The method aims to turn the discrete optimization problem associated with the integer number of plies into a continuous one. It gives the optimum thickness distribution over the structure {{in relation to the}} specific table of stacking sequence. The proposed method is applied to the optimization of the layup of a composite stiffened skin of a structure resembling a wing, considering constraints on the local buckling load. During gradient based buckling optimization it is crucial to take switching of the critical buckling mode into account. An effective method is presented to achieve this and the point of implementation is discussed in detail. Optimum design of a stiffened structure resembling the upper panel of a wing torsion box subjected to different in-plane normal and shear loads is optimized subjected to no local buckling constraint...|$|E
40|$|We discuss {{methods of}} {{developing}} consensus in measuring improvement in myositis. We consider selecting candidate variables, reliability and validity, <b>percentage</b> improvement/worsening <b>rules,</b> rules based on CART and logistic regression. We discuss criteria for determining an acceptable rule that include both numerical measures and physician acceptance. ...|$|R
40|$|Abstract. The {{complexity}} of seismic response for skew bridge rises higher seismic-vulnerability relatively {{in comparison with}} right bridge. One of the parameters that directly affects the seismic response on a skew bridge is the excitation angle of the ground motion[1]. This paper investigates the effects of seismic force direction on the responses of skew bridges without considering impact effect in time history nonlinear dynamic analyses. The combination rules for orthogonal earthquake effects, such as the 100 / 30, 100 / 40 <b>percentage</b> <b>rules</b> and the SRSS method are also examined. It is concluded that the angle of excitation that produces the critical responses depends both on the ground motion and bridge characteristics, and the three combination rules are all relatively conservative, a new formula which considers the influence of skew angle and excitation angle of the ground motion is suggested...|$|R
40|$|In transformation-based parsing, {{a finite}} {{sequence}} of tree rewriting rules are checked for application to an input structure. Since in practice {{only a small}} <b>percentage</b> of <b>rules</b> are applied to any particular structure, the naive parsing algorithm is rather inefficient. We exploit this sparseness in rule applications to derive an algorithm two to three orders of magnitude faster than the standard parsing algorithm...|$|R
50|$|Most {{income tax}} systems allow a tax {{deduction}} for recovery {{of the cost of}} assets used in a business or for the production of income. Such deductions are allowed for individuals and companies. Where the assets are consumed currently, the cost may be deducted currently as an expense or treated as part of cost of goods sold. The cost of assets not currently consumed generally must be deferred and recovered over time, such as through depreciation. Some systems permit full deduction of the cost, at least in part, in the year the assets are acquired. Other systems allow depreciation expense over some life using some depreciation method or <b>percentage.</b> <b>Rules</b> vary highly by country, and may vary within a country based on type of asset or type of taxpayer. Many systems that specify depreciation lives and methods for financial reporting require the same lives and methods be used for tax purposes. Most tax systems provide different rules for real property (buildings, etc.) and personal property (equipment, etc.).|$|R
3000|$|There are 23 {{patients}} who have the properties stated in Rule 1. Prostate cancer is found in eight of these patients. Hence, the risk <b>percentage</b> for first <b>rule</b> is [...]...|$|R
3000|$|... are {{convenient}} to Rule 3, Rule  4 and Rule 8. When {{we look at}} the risk <b>percentage</b> of these <b>rules,</b> we see that Rule 8 has the highest rate. Hence the risk percentage of [...]...|$|R
40|$|Background and Aim: Proper {{designing}} {{of partial}} denture frameworks is {{the duty of}} dentists, but this task is often abdicated to technicians because of lack of time and experience. Computer assisted learning and designing can be used for both training dental students and helping dentists design proper frameworks. As the first step to prepare software for framework designing, this study evaluated the agreement on different framework designing principles, among prosthodontists of dental schools in Iran. "nMaterials and Methods: A questionnaire consisting of 121 design rules was sent to 41 prosthodontists at seven dental schools in Iran. The percentage rate of agreement on results was used for data analysis. "nResults: The <b>percentage</b> of <b>rules</b> accepted by more than 60 % of the prosthodontists was 76. 2 %. It consisted 80 % saddle rules, 76. 2 % rest rules, 78. 4 % clasp rules, 63. 6 % maxillary major connector's rules and 80. 9 % mandibular major connector <b>rules.</b> "nConclusion: The <b>percentage</b> of accepted <b>rules</b> by Iranian prosthodontists was 76. 2 %. Maxillary major connectors had the least acceptance...|$|R
50|$|Generally, {{these kind}} of {{provisions}} require to disclose data on the name and nationality of the owner's; address; shareholdings; founding capital, etc., but the exact <b>rules,</b> <b>percentages</b> and thresholds vary from country to country. Failure to provide the requested information generally leads to fines and sanctions, and invalidation of the company registration.|$|R
40|$|Technical trading {{rules have}} been used in {{financial}} markets in order to examine their ability to yield a superior return. In the early empirical literature, a body of studies showed that trading rules do not outperform a simple buy and hold strategy. However, more recent research finds evidence that supports technical trading rules. This study examines the profitability of trading rules in 14 Middle East and North African (MENA) markets. The trading rules that used are: moving average trading rules (MA), trading range breakout (TRB) trading rules, filter trading rules, channel trading rules, Bollinger band (BB) trading rules and moving average coverage divergence (MACD) trading rules. The markets used in this work include the Bahrain stock market, the Jordan stock market, the Kuwait stock market, the Lebanon stock market, the Maltese stock market, the Morocco stock market, the Oman stock market, the Qatar stock market, the Saudi Arabian stock market, the Tunisia stock market, the Turkey stock market, the United Arab Emirates stock markets, the Cyprus stock market and the Egypt stock market. Our results indicate that according to mean return criterion, the best simple moving average (SMA), exponential moving average (EMA), triangular moving average (TMA), trading range breakout (TRB), filter and moving average coverage divergence (MACD) trading rules are for Turkey market. Malta, Bahrain and Oman have the highest <b>percentage</b> of <b>rules</b> that generate positive mean return. In terms of the Sharpe ratio, the best trading rules according to TMA, SMA, filter and channel trading rules are for Turkey market. Furthermore, Turkey has the highest <b>percentage</b> of <b>rules</b> that have a positive Sharpe ratio followed by Cyprus and Egypt. Controlling for data snooping, the results show that the number of trading rules that generate positive return comparing with buy and hold strategy has been reduced but there are still a large number of profitable rules through some markets...|$|R
5|$|From the league's {{founding}} in 1920 until 1932, {{there was no}} scheduled championship game. From 1920–1923, the championship was awarded to a team {{by a vote of}} team owners at the annual owners' meeting. From 1924–1932, the team having the best winning percentage was awarded the championship. As each team played a different number of games, simply counting wins and losses would have been insufficient. Additionally, tie games were not counted in the standings in figuring winning <b>percentage</b> (under modern <b>rules,</b> ties count as ½ win and ½ loss).|$|R
30|$|In {{this step}} we analyze the soft rules and {{calculate}} the prostate cancer risk percentage. The patients set for each rule was {{obtained in the}} fourth step. We consider these sets and observe {{how many of the}} patients in the set have prostate cancer, then we rate the patients with prostate cancer to each patient in the set. Therefore we have the prostate cancer risk <b>percentage</b> for each <b>rule.</b> If a patient’s data is convenient to more than one rule and so has more than one rate, then we accept the highest one.|$|R
50|$|From the league's {{founding}} in 1920 until 1932, {{there was no}} scheduled championship game. From 1920-1923, the championship was awarded to a team {{by a vote of}} team owners at the annual owners' meeting. From 1924-1932, the team having the best winning percentage was awarded the championship. As each team played a different number of games, simply counting wins and losses would have been insufficient. Additionally, tie games were not counted in the standings in figuring winning <b>percentage</b> (under modern <b>rules,</b> ties count as ½ win and ½ loss).|$|R
40|$|In transformation-based parsing, {{a finite}} {{sequence}} of tree rewriting rules are checked for application to an input structure. Since in practice {{only a small}} <b>percentage</b> of <b>rules</b> are applied to any particular structure, the naive parsing algorithm is rather inefficient. We exploit this sparseness in rule applications to derive an algorithm two to three orders of magnitude faster than the standard parsing algorithm. 1 Introduction The idea of using transformational rules in natural language analysis dates {{back at least to}} Chomsky, who attempted to define a set of transformations that would apply to a word sequence to map it from deep structure to surface structure (see (Chomsky, 1965)). Transformations have also been used in much of generative phonology to capture contextual variants in pronunciation, starting with (Chomsky and Halle, 1968). More recently, transformations have been applied to a diverse set of problems, including part of speech tagging, pronunciation network creation, pr [...] ...|$|R
40|$|AbstractIn recent years, the {{evaluation}} of building performance in terms of environmental, social and economic aspects has become a topic of discussion in the Slovak Republic. A new Building Environmental Assessment System (BEAS) has been developed at the Institute of Environmental Engineering, Technical University of Košice. The main fields and indicators of BEAS are proposed {{on the base of}} available information analysis from particular fields and also on the base of our experimental experiences. The proposed indicators respect Slovak standards and <b>rules.</b> <b>Percentage</b> weight of fields and indicators are determined on the basic their significance, according to multi-criteria decision analysis...|$|R
40|$|A {{small-scale}} {{replication of}} Keith Krehbiel’s original test on the 99 th Congress {{is carried out}} in this paper. This replication consists of four committees in the 112 th Congress selected because of their symptomatic distributive tendency. The aim in {{this paper is to}} characterize committees as diverse in composition with heterogeneous high demanding members who possess different bits of information. Furthermore, this heterogeneity of membership is associated with a higher <b>percentage</b> of closed <b>rules</b> assigned to the committee by the House Committee on Rules. Though evidence supports Krehbiel’s assessment of committee composition, there {{does not appear to be}} a relationship between membership heterogeneity on committees and the number of closed rules it is granted...|$|R
40|$|In this paper, a novel focused time lagged {{recurrent}} {{neural network}} (FTLR NN) with gamma memory filter {{is designed to}} learn the subtle complex dynamics of a typical magnetic stirrer process. Magnetic stirrer exhibits complex nonlinear operations where reaction is exothermic. It appears to us that identification of such a highly nonlinear system is not yet reported by other researchers using neural networks. As magnetic stirrer process includes time relationship in the input-output mappings, time lagged recurrent neural network is particularly used for identification purpose. The standard back propagation algorithm with momentum term has been proposed in this model. The various parameters like number of processing elements, number of hidden layers, training and testing <b>percentage,</b> learning <b>rule</b> and transfer function in hidden and output layer are investigated {{on the basis of}} performance measures like MSE, NMSE and correlation coefficient on testing data set. Finally, effect of different norms are tested along with variation in gamma memory filter. It is shown that dynamic NN model has a remarkable system identification capability for the problem considered in this paper. Thus, FTLR NN with gamma memory filter can be used to learn underlying highly nonlinea...|$|R
40|$|The {{objective}} {{of this study was}} to develop a fuzzy model to estimate the possibility of neonatal mortality. A computing model was built, based on the fuzziness of the following variables: newborn birth weight, gestational age at delivery, Apgar score, and previous report of stillbirth. The inference used was Mamdani's method and the output was the risk of neonatal death given as a <b>percentage.</b> 24 <b>rules</b> were created according to the inputs. The validation model used a real data file with records from a Brazilian city. The receiver operating characteristic (ROC) curve was used to estimate the accuracy of the model, while average risks were compared using the Student t test. MATLAB 6. 5 software was used to build the model. The average risks were smaller in survivor newborn (p < 0. 001). The accuracy of the model was 0. 90. The higher accuracy occurred with risk below 25 %, corresponding to 0. 70 in respect to sensitivity, 0. 98 specificity, 0. 99 negative predictive value and 0. 22 positive predictive value. The model showed a good accuracy, as well as a good negative predictive value and could be used in general hospitals...|$|R
40|$|A focused time lagged {{recurrent}} {{neural network}} (FTLR NN) with gamma memory filter {{is designed to}} learn the subtle complex dynamics of a typical CSTR process. Continuous stirred tank reactor exhibits complex nonlinear operations where reaction is exothermic. It is noticed from literature review that process control of CSTR using neuro-fuzzy systems was attempted by many, but optimal neural network model for identification of CSTR process is not yet available. As CSTR process includes temporal relationship in the input-output mappings, time lagged recurrent neural network is particularly used for identification purpose. The standard back propagation algorithm with momentum term has been proposed in this model. The various parameters like number of processing elements, number of hidden layers, training and testing <b>percentage,</b> learning <b>rule</b> and transfer function in hidden and output layer are investigated {{on the basis of}} performance measures like MSE, NMSE, and correlation coefficient on testing data set. Finally effects of different norms are tested along with variation in gamma memory filter. It is demonstrated that dynamic NN model has a remarkable system identification capability for the problems considered in this paper. Thus FTLR NN with gamma memory filter can be used to learn underlying highly nonlinear dynamics of the system, which is a major contribution of this paper...|$|R
5000|$|Mr C. H. Hudson, of Derby, {{is to be}} congratulated {{on having}} {{notified}} an arrival in Rome race Tuesday last. The bird has proved itself capable of great endurances and of suffering much fatigue, and possessing wonderful staying power to make its way back from Rome to Derby. Up till Tuesday evening out of the 1200 birds sent by Belgian fanciers, 62 birds had been notified. The <b>percentage</b> as a <b>rule</b> that get back of birds sent to Rome by Belgian fanciers works out on average at 7 per cent, {{so that there are}} hopes yet {{that there will be some}} more English birds home. At any rate, the distance has been accomplished eclipsing all past long-distance records in the United Kingdom. When it was sent to Rome it was rung as NU1907DY168.|$|R
40|$|This article {{describes}} {{a study conducted}} to identify mathematical practi ces in the activities developed by masons {{in the construction of}} brick house s. This research was developed with the builders of the city of Urucará. We used a qualitative approach through non - structured interviews with open questions and direct observation to uncover the ideas and mathematical reasoning present in the process, thereby showing the various situations linked to the construction of the home, these involving a practical knowledge that can be approached by observing the problem in relation to its theorization. The math concepts perceived during the construction process are: the metric relationships of the right triangle and regular quadrilateral, the calculation and measurement of the area, volume, and capacity, and the <b>percentages</b> of the <b>rule</b> of three. This study shows {{that it is possible to}} investigate the mathematic knowledge involved in distinct practices in order to contextualize and promote significant concepts and reveal a more enriching mathematics worthy of study...|$|R
40|$|Neglected conditions, also {{referred}} as missing paths, {{are known to}} be an important class of software defects. Revealing neglected conditions around individual API calls in an application requires the knowledge of programming rules that must be obeyed while reusing those APIs. To mine those implicit programming rules and hence to detect neglected conditions, we develop a novel framework, called NEGWeb, that substantially expands mining scope to billions of lines of open source code available on the web by leveraging a code search engine. We evaluated NEGWeb to detect violations of mined rules in local code bases or open source code bases. In our evaluation, we show that NEGWeb finds three real defects in Java code reported in the literature and also finds three previously unknown defects in a large-scale open source project called Columba (91, 508 lines of Java code) that reuses 541 classes and 2225 methods. We also report a high <b>percentage</b> of real <b>rules</b> among the top 25 reported patterns mined for APIs provided by five popular open source applications...|$|R
40|$|In a {{study of}} the {{archives}} of the Chief Inspector for Healthcare in the Netherlands during the period 1992 - 2003, the number of complaints against gynaecologists submitted to disciplinary boards (n = 371) was found to be higher than during the period of 1980 - 1991 (n = 240). On the other hand, the number of complaints per gynaecologist had decreased from 6. 3 complaints per 100 gynaecologists in 1992 to 2. 6 / 100 in 2003. The number of complaints declared legitimate relative to the number of submitted complaints remained the same in both periods (55 / 240 (23 %) in 1980 - 1991 and 84 / 371 (23 %) in 1992 - 2003), although the <b>percentage</b> of complaints <b>ruled</b> as legitimate did increase {{during the course of the}} second period from 14 between 1992 - 1997 to 28 during the 1998 - 2003 period. Interesting points included the number of rulings regarding the death of an infant (40 %), the interpretation of the cardiotocography recording, the need to keep medical records up to date (in particular the informed consent) and the fact that almost 50 % of complaints ruled to be legitimate related to how the locum position was arranged, the role of the duty gynaecologist and that of the house office...|$|R
40|$|The Sixth International Society of Pediatric Oncology study (SIOP 6) {{concerned}} Wilms' tumor with favorable histology, preoperatively {{treated to}} obtain {{a high rate of}} stage I patients, and sought to reduce treatment for patients with stage I and stage II negative nodes (IIN 0) tumors and to find better therapy to prevent relapses in stage II positive nodes (IIN 1) and stage III patients. Eligible patients (N = 509) had received four weekly doses of vincristine (VCR) and two courses of dactinomycin (AMD) preoperatively and were assigned after surgery, according to stage and lymph node involvement, to three different prognostic groups, which were to be randomized. Stage I patients (n = 303) received VCR and AMD either for 17 weeks (S) or 38 weeks (L). Stage IIN 0 patients (n = 123) received either 20 Gy irradiation (R+) or no irradiation (R-) and received VCR and AMD for 38 weeks. Stage IIN 1 and III patients (n = 83) received intensified VCR and AMD (INTVCR) versus VCR, AMD, and Adriamycin (ADRIA; Doxorubicin Farmitalia Carbo Erba, Rueil, Malmaison, France; doxorubicin). Assessment criteria were 2 -year disease-free survival (DFS) and 5 -year survival (SURV) <b>percentages.</b> A stopping <b>rule</b> was added that took into account abdominal recurrences for the stage IIN 0 trial. A 52 % rate of stage I tumors was obtained, with a low rate of ruptures (7 %). The 2 -year DFS and 5 -year SURV rates according to the different therapeutic groups were stage I, 92 % versus 88 % (equivalent) and 95 % versus 92 % for S and L, respectively; stage IIN 0, 72 % versus 78 % (stage equivalent) and 88 % versus 85 % for R+ and R-, respectively; and stage IIN 1 and stage III, 49 % versus 74 % (P <. 029) and 77 % versus 80 % for INTVCR and ADRIA, respectively, which results in an 82 % DFS and 89 % SURV rate for the entire trial population. However, six abdominal metastases observed {{during the first year of}} follow-up (FU) in the R- group versus none in the R+ group resulted in discontinuation of the stage IIN 0 trial. Risk-adapted therapy to limit risk of sequelae is possible. More intensive chemotherapy is necessary to prevent abdominal recurrences in nonirradiated stage IIN 0 patients treated preoperatively. A three-drug protocol is necessary in stage IIN 1 and stage III patient...|$|R
40|$|Purpose: This study aims to {{describe}} and compare the content of instruments that assess environmental factors (EF) using the International Classification of Functioning, Disability and Health (ICF). Relevance: Assessing the impact of EF on patients' functioning {{is an important part}} of the rehabilitation process. Physiotherapists need to know which instruments assess EF, which EF these instruments assess and which methodology of assessment they use, in order to choose the appropriate instrument. The ICF provides a universal framework that can be used {{to describe}} and compare the health of patients and that serves as a reference for the documentation in physiotherapy. Therefore it can be used to characterise existing instruments. Participants: Not applicable. Methods: A systematic search of 3 databases (PubMed, CINAHL and PEDro) was conducted to identify all instruments that assess EF. Combinations of the following key words were used without language restriction: environment, factors, components, barriers to participation, facilitators to participation, International Classification of Functioning, Disability and Health, social participation. Two investigators independently screened all instruments identified, which were included if developed for adults, addressed more than one 2 nd level category of any of the 5 Chapters on EF and not specific to a health condition. Analysis: Included instruments had their content examined independently by 2 investigators that identified all meaningful concepts and linked them to the most precise ICF category according to published <b>rules.</b> <b>Percentage</b> agreement between the 2 investigators varied between 84 % and 95 %. Results: 8 instruments met the inclusion criteria containing 558 meaningful concepts linked to 2 nd or 3 rd level ICF categories from one of the 5 EF chapters (1. Products and technology, 2. Natural Environment, 3. Support and relationships, 4. Attitudes, 5. Services, systems and policies). 5 / 8 instruments cover all the 5 chapters; 1 / 8 instrument covers 4 / 5 chapters (1, 3 - 5); 1 / 8 instrument covers chapters 1 and 2 and 1 / 8 instrument covers chapter 1 only. 5 / 8 instruments had between 61 % and 100 % of their items linked to categories in Chapter 1. In contrast, the highest percentage of items from one instrument linked to categories in Chapter 2 was 11 %, Chapter 3 was 30 %, Chapter 4 was 20 % and Chapter 5 was 49 %. 3 / 8 instruments assessed whether EF were present or absent in a specific context, 3 / 8 assessed the intensity of EF' impact and 2 / 8 assessed the intensity and frequency of the EF' impact. Conclusions: Instruments assessing EF differ in their content and type of assessment and have several items linked to the same ICF category. Most instruments are designed to assess primarily products and technology (Chapter 1) and only a minority assesses the intensity and frequency of EF' impact, which is of great relevance to rehabilitation. Different instruments are needed that assess the intensity and frequency of EF' impact and that use ICF categories as the items for assessment. Implications: The results of this study can guide physiotherapists in clinical practice and research in selecting an appropriate EF instrument for a specific purpose...|$|R
40|$|Thesis (Ph. D. (Risk Management)) [...] North-West University, Potchefstroom Campus, 2007. Portfolio {{managers}} {{typically have}} two choices: let the portfolio drift with the markets or give direction to the portfolio by rebalancing {{according to a}} target allocation. Simply allowing the portfolio to drift with the markets without rebalancing is no longer appropriate. This leaves portfolio managers with the second option of giving direction to the portfolio according to a target allocation. 'This {{can be achieved by}} implementing an existing rebalancing strategy. Portfolio managers typically rely on ad hoc rebalancing strategies that are either calendar-based, such as monthly or quarterly rebalancing, or volatility-based, such as rebalancing whenever the asset ratios are more than 5 % from the target. In the volatility-based rebalancing strategies, the percentage from the target indicates when rebalancing should occur, and the <b>percentage</b> relies on <b>rule</b> of thumb or the use of historical data. The problem with using historical data is that it will not necessarily predict appropriate ranges for the future. These ranges give the indication of when rebalancing should occur. This indicates a need to develop a well-defined rebalancing strategy that assists the portfolio manager to manage a portfolio. Such a rebalancing strategy should be easy to implement. The aim of this research was to develop and implement a well-defined rebalancing strategy that is adjustable over time to assist portfolio managers to maintain their portfolios in line with the objectives and risk aversions of the trustees' of a pension fund. The study introduced the concept of a portfolio drift strategy to set the scene for the different rebalancing strategies. This was to emphasise the importance for a portfolio manager to adopt a rebalancing strategy for a pension fund. An overview is provided of the five broad rebalancing strategies followed by some advantages and disadvantages of each. Certain rebalancing strategies were used to explain the benefit of rebalancing and the cost of rebalancing. The study investigated different methodologies used to identify when the portfolio manager should rebalance and how far back the portfolio manager should rebalance. The study focused on Masters' range rebalancing strategy and this strategy was used as the benchmark strategy for the study. The study summarises the benchmark strategy that will be used to evaluate the alternative rebalancing strategies. A selective number of performance measurement tools were used to evaluate the benchmark strategy. This criterion was used to compare the alternative rebalancing strategies. The study introduced a new decision-making method that has the same return as the benchmark strategy but the risk of the portfolio is lower. The decision-making method is called the second difference method (SD-method). The SD-method builds on Masters' range rebalancing strategy by eliminating certain implicit assumptions made by Masters. The elimination of Masters' implicit assumptions led to an increase in the complexity of the SD-method of the procedure to rebalance. The complexity was eliminated using a computer program formulating the rules of the SD-method. The study developed a new method called the Cusum Test method (CT-method) with its own assumptions and risk specifications to identify when rebalancing should occur. The new method discussed in the study was less complex to implement and, in contrast to Masters' range rebalancing, the ranges were adjustable over time. The CT-method outperformed Masters' range rebalancing strategy and the SD-method on a risk-adjusted return basis. Doctora...|$|R

