5|5|Public
40|$|An {{expected}} {{utility model}} of individual choice is formulated {{which allows the}} decision maker to specify his available actions {{in the form of}} "controls" (<b>partial</b> <b>contingency</b> plans) and to simultaneously choose goals and controls in end-mean pairs. It is shown that the Savage expected utility model, the Marschak- Radner team model, the Bayesian statistical decision model, and the standard optimal control model can be viewed as special cases of this "goal-control expected utility model. ...|$|E
40|$|In [7] a "goal-control {{expected}} utility model" was formulated {{which allows}} the decision maker to specify his acts {{in the form of}} "controls" (<b>partial</b> <b>contingency</b> plans) and to simultaneously choose goals and controls in end-mean pairs. It was shown that the Savage expected utility model, the Marschak-Radner team model, the Bayesian statistical decision model, and the standard optimal control model can be viewed as special cases of this model. In this paper the goal-control expected utility representation for the goal-control model primitives is axiomatized...|$|E
40|$|A {{generalization}} {{of the standard}} n-person game is presented, with flexible information requirements suitable for players constrained by bounded rationality. Strategies (complete contingency plans) are replaced by "policies," i. e., end-mean pairs of candidate goals and "controls" (<b>partial</b> <b>contingency</b> plans). The existence of individual objective functions over the joint policy choice set is axiomatized in terms of primitive preference and probability orders. Conditions are given {{for the existence of}} pure policy Nash equilibrium points in n-person games, and pure policy Nash bargaining and equilibrium threat solutions in 2 -person policy games. Connectedness of the policy and payoff sets is not required...|$|E
40|$|Copyright ? 2012 Elsevier B. V. All rights reserved. Behaviours {{that have}} been rewarded {{intermittently}} persist for longer during periods of non-reward than behaviours {{that have been}} rewarded continuously. This classic phenomenon {{is known as the}} partial reinforcement extinction effect. For decades it has been generally understood that this phenomenon is fundamental to the persistence of gambling in the absence of winning. One obvious, yet untested hypothesis arising from this is that persistent (here, high-frequency) gamblers might be more sensitive to <b>partial</b> reinforcement <b>contingencies.</b> Therefore, our aim was to test the hypothesis that compared to low-frequency gamblers, high-frequency gamblers would show greater resistance to extinction following partial reinforcement in a computer based experiment. Participants were 19 high-frequency gamblers and 21 low-frequency gamblers, all healthy non-smokers aged between 18 and 52. Following partial or continuous reinforcement, persistence of responding in extinction was measured as the number of times a target response was made. After partial reinforcement, high-frequency gamblers made the target response a greater number of times in extinction (compared to low-frequency gamblers). Moreover, the partial reinforcement extinction effect was larger in high-frequency gamblers than in low-frequency gamblers. It {{remains to be seen whether}} increased sensitivity to partial reinforcement is a cause or effect of persistent gambling. Nevertheless, the present study represents an important first step in investigating the role of simple <b>partial</b> reinforcement <b>contingencies</b> in determining resistance to extinction in gamblers, the importance of which, whilst hitherto recognised, has never been demonstrated experimentally. Peer reviewe...|$|R
40|$|Rats {{were trained}} in a discrete-trial {{paradigm}} with no intertrial interval. The first response changed an auditory stimulus {{for the remainder of}} the trial. Shocks were delivered only at the end of the trial cycle. Avoidance contingencies were defined by the conditional probability of shock, given no response (P 0), and the conditional probability of shock given a response (P 1). The maximal avoidance contingency was P 0 = 1. 0, P 1 = 0, and noncontingent conditions were those for which P 0 =P 1. In Experiment I, after training on the maximal contingency, three groups of subjects experienced either P 0 =P 1 = 0, P 0 =P 1 = 0. 5, or P 0 =P 1 = 1. 0. Eight of 10 subjects stopped responding under the noncontingent conditions. Experiment II studied <b>partial</b> <b>contingencies</b> by varying P 0 and P 1. For one group, P 0 was reduced holding P 1 = 0. Responding decreased to zero as P 0 approached zero. A second group was studied under P 1 > 0, holding P 0 = 1. 0. For three of the six rats in this group, responding decreased to zero with increasing P 1. The other three maintained responding as P 1 was increased up to the noncontingent, P 1 =P 0 = 1. 0 value. The P 0 group was also studied with P 0 =P 1 > 0, and half of these subjects responded. The results demonstrated two modes of response to weakening or eliminating the avoidance contingency. Some subjects were sensitive to contingency only, and insensitive to changes in shock density. Approximately one half of the subjects were sensitive to both contingency and shock density. This shared control was observed only when P 1 > 0...|$|R
40|$|In this paper, {{we discuss}} {{factorization}} of a posterior distribution and present a partial imputation algorithm for a graphical model with incomplete data. We use an ordinary graph {{to represent a}} graphical model and introduce a hypergraph to represent an observed data pattern where each hyperedge {{is a set of}} variables observed for a group of individuals. First, in terms of a decomposition of such a mixed graph, we discuss factorization of a joint posterior distribution into several marginal posterior distributions so that calculation of posterior distribution can be localized. Then, for a mixed graph which cannot be decomposed without loss of information, we present a partial imputation algorithm which imputes only a part of missing data and reduces unnecessary imputation of an ordinary Gibbs sampler. Finally, we discuss the efficiency improved by a decomposition and the <b>partial</b> imputation algorithm. <b>Contingency</b> table Dirichlet distribution Graphical models Incomplete data Imputation algorithm...|$|R
40|$|The paper {{addresses}} {{two related}} issues: the optimal intergenerational sharing of laborproductivity risks, through a Pay-As-You-Go (PAYG) social security, and the mix ofPAYG and savings for retirement provision {{in a small}} open economy. It shows that <b>partial</b> <b>contingency</b> {{of the social security}} on the stochastic labor productivity is ex ante optimal,when the interest rate is above the expected growth rate of the economy and when thegovernment has a lifetime perspective of the risk exposure. The paper also provides acondition for partial displacement of savings by the PAYG, which is in line with vastempirical evidence. intergenerational risk sharing; PAYG social security; household's savings...|$|E
40|$|This paper {{addresses}} {{two related}} issues: the optimal intergenerational sharing of labor productivity risks, through a Pay-As-You-Go (PAYG) social security with contingent rates of benefits and contributions, and the optimal combination of PAYG and funded savings {{in a small}} open economy. It shows that <b>partial</b> <b>contingency</b> {{of the social security}} on the labor productivity is ex ante optimal, when the interest rate is above the expected growth rate of the economy, and when the government has a lifetime perspective of the risk exposure. In addition, the government may induce a higher saving rate, due to the expected lower PAYG return and the household's desire of smoothing consumption over time...|$|E
40|$|Avoidance {{contingencies}} {{were defined}} by the absolute probability of the conjunction of responding or not responding with shock or no shock. The “omission” probability (ρ 00) is the probability of no response and no shock. The “punishment” probability (ρ 11) is the probability of both a response and a shock. The traditional avoidance contingency never omits shock on nonresponse trials (ρ 00 = 0) and never presents shock on response trials (ρ 11 = 0). Rats were trained on a discrete-trial paradigm with no intertrial interval. The first lever response changed an auditory stimulus {{for the remainder of}} the trial. Shocks were delivered only at the end of each trial cycle. After initial training under the traditional avoidance contingency, one group of rats experienced changes in omission probability (ρ 00 > 0), holding punishment probability at zero. The second group of rats were studied under different punishment probability values (ρ 11 > 0), holding omission probability at zero. Data from subjects in the omission group looked similar, showing graded decrements in responding with increasing probability of omission. These subjects approximately “matched” their nonresponse frequencies to the programmed probability of shock omission on nonresponse trials, producing a very low and approximately constant conditional probability of shock given no response. Subjects in the punishment group showed different sensitivity to increasing absolute punishment probability. Some subjects decreased responding to low values as punishment probability increased, while others continued to respond at substantial levels even when shock was inevitable on all trials (noncontingent shock schedule). These results confirm an asymmetry between two dimensions of <b>partial</b> avoidance <b>contingencies.</b> When the consequences of not responding included occasional omission of shock, all subjects showed graded sensitivity to changes in omission frequency. When the consequences of responding included occasional shock delivery, some subjects showed graded sensitivity to punishment frequency while others showed control by overall shock frequency as well...|$|R
40|$|Since 1996, the Research and Development (R&D) {{sector in}} Malaysia has {{received}} greater policy attention than before. Despite fiscal and non-fiscal incentives provided {{to support the}} growth of this sector, the level of R&D {{measured in terms of}} R&D outputs (i. e. number of patent) is still dismal which is mirrored in the overall performance of local R&D companies. Many studies have investigated factors which influence the performance of organizations. The present study attempts {{to examine the relationship between}} human resource management (HRM) practices and organizational performance of R&D firms based on contingency theory and resource based view. The moderating role of interfirm collaboration and environment on the relationship between HRM practices and organizational performance are also studied. Organizational performance was measured in terms of profitability. The data for the study were obtained from survey responses from 64 R&D companies. Results of EFA and CFA confirmed the 4 dimensions of HRM practices: participation, reward, training and development, and teamwork practices. Regression results showed participation and reward practices have positive and significant relation with organizational performance while training and development practice has negative relation with organizational performance. There is no significant relationship between teamwork practice and organizational performance. Results also indicated that only collaboration in manufacturing significantly moderated the relationship between some of the HRM practices and organizational performance. Other types of interfirm collaborations did not show any moderating roles on the aforesaid relationships. Also, the present study found that environment was not a moderator in the relationship between HRM practices and organizational performance. Overall, the findings of the present study provide <b>partial</b> support of <b>Contingency</b> Theory and RBV. Theoretical contributions and managerial implications of the study as well as suggestions for future research were discussed...|$|R

