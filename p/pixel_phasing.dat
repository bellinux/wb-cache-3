0|87|Public
40|$|This paper {{presents}} algorithms {{developed for}} <b>pixel</b> merging <b>phase</b> of object-space parallel polygon rendering on hypercube-connected multicomputers. These algorithms reduce volume of communication in <b>pixel</b> merging <b>phase</b> by only exchanging local foremost pixels. In {{order to avoid}} message fragmentation, local foremost pixels should be stored in consecutive memory locations. An algorithm, called modified scanline z-buffer, is proposed to store local foremost pixels efficiently. This algorithm also avoids the initialization of scanline z-buffer for each scanline on the screen. Good processor utilization is achieved by subdividing the image-space among the processors in <b>pixel</b> merging <b>phase.</b> Efficient algorithms for load balancing in the <b>pixel</b> merging <b>phase</b> are also proposed and presented. Experimental results obtained on a 16 -processor Intel's iPSC/ 2 hypercube multicomputer are presented...|$|R
40|$|A diffractive optical element having equal-width {{concentric}} square rings is {{analyzed in}} this article. This constant width makes possible its realization using spatial light modulators or square <b>pixels</b> <b>phase</b> screens. It allows a simple analytical treatment, and the element is also simulated using the Rayleigh-Sommerfeld approach. An experimental verification of its performance {{has been compared}} with the simulated results...|$|R
40|$|An optical teardown, {{or reverse}} engineering, of an Amazon Kindle Paperwhite electrophoretic display was {{performed}} by Optical Coherence Tomography at 1060 nm. The display incorporates an optical diffuser, lightguide and scattering layers for white light illumination, capacitive touch sensing, and an electrophoretic display. All these layers can be imaged by OCT {{as well as the}} thin film transistor array on the back side for driving the <b>pixels.</b> <b>Phase</b> sensitive OCT is used to measure motion of the pigment particles as the display changes between black and white...|$|R
40|$|This paper {{presents}} algorithms for object-space parallel polygon rendering on hypercube-connected multicomputers. A modified scanline z-buffer {{algorithm is}} proposed for local rendering phase. The proposed algorithm avoids message fragmentation by packing local foremost pixels in consecutive memory locations efficiently, and it eliminates the initialization of scanline z-buffer for each scanline. Several algorithms, utilizing different communication strategies and topological embeddings, are proposed for global z-buffering of local foremost pixels during the <b>pixel</b> merging <b>phase.</b> The performance comparison of these pixel merging algorithms are presented based on the communication overhead incurred in each scheme. Two adaptive screen subdivision heuristics are proposed for load balancing in the <b>pixel</b> merging <b>phase.</b> These heuristics utilize the distribution of foremost pixels on the screen for the subdivision. Experimental results obtained on an Intel's iPSC/ 2 hypercube multicompu [...] ...|$|R
40|$|We {{present a}} double image {{encryption}} scheme by using random <b>pixel</b> exchanging and <b>phase</b> encoding in gyrator domains. Two original images {{are regarded as}} the amplitude and phase of a function in the encryption algorithm. The pixels of the two images are exchanged randomly by controlling of a matrix. The same random matrix {{is used in the}} process of <b>pixel</b> exchanging and <b>phase</b> encoding for saving space in the application of transmission and storage of key. Some numerical simulation results are made for demonstrating the performance and security of the double image encryption. (C) 2012 Elsevier Ltd. All rights reserved...|$|R
40|$|A phase {{imaging method}} for an optical {{wavefront}} acquires {{a plurality of}} phase images of the optical wavefront using a phase imager. Each phase image is unique and is shifted with respect to another of the phase images by a known/controlled amount that {{is less than the}} size of the <b>phase</b> imager's <b>pixels.</b> The <b>phase</b> images are then combined to generate a single high-spatial resolution phase image of the optical wavefront...|$|R
40|$|AbstractÐThis paper {{presents}} algorithms for object-space parallel polygon rendering on hypercube-connected multicomputers. A modi®ed scanline z-bu€er {{algorithm is}} proposed for local rendering phase. The proposed algorithm avoids message fragmentation by packing local foremost pixels in consecutive memory locations e ciently, and it eliminates the initialization of scanline z-bu€er for each scanline. Several algorithms, utilizing di€erent communication strategies and topological embeddings, are proposed for global z-bu€ering of local foremost pixels during the <b>pixel</b> merging <b>phase.</b> The performance comparison of these pixel merging algorithms are presented based on the communication overhead incurred in each scheme. Two adaptive screen subdivision heuristics are proposed for load balancing in the <b>pixel</b> merging <b>phase.</b> These heuristics utilize the distribution of foremost pixels on the screen for the subdivision. Experimental results obtained on an Intel's iPSC/ 2 hypercube multicomputer and a Parsytec CC system are presented. Rendering rates of 300 K± 700 K triangles per second are attained on 16 processors of Parsytec CC system in the rendering of datasets from publicly available SPD database. ...|$|R
40|$|Cataloged from PDF {{version of}} article. This paper {{presents}} algorithms for object-space parallel polygon rendering on hypercube-connected multicomputers. A modified scanline z-buffer {{algorithm is proposed}} for local rendering phase. The proposed algorithm avoids message fragmentation by packing local foremost pixels in consecutive memory locations efficiently, and it eliminates the initialization of scanline z-buffer for each scanline. Several algorithms, utilizing different communication strategies and topological embeddings, are proposed for global z-buffering of local foremost pixels during the <b>pixel</b> merging <b>phase.</b> The performance comparison of these pixel merging algorithms are presented based on the communication overhead incurred in each scheme. Two adaptive screen subdivision heuristics are proposed for load balancing in the <b>pixel</b> merging <b>phase.</b> These heuristics utilize the distribution of foremost pixels on the screen for the subdivision. Experimental results obtained on an Intel's iPSC/ 2 hypercube multicomputer and a Parsytec CC system are presented. Rendering rates of 300 K- 700 K triangles per second are attained on 16 processors of Parsytec CC system in the rendering of datasets from publicly available SPD database. (C) 1998 Elsevier Science Ltd. All rights reserved...|$|R
40|$|In {{conjunction}} with an external UV-sensitive cathode, an electron-bombarded CCD {{may be used}} as a high quantum efficiency/wide dynamic range photon-counting UV detector. Results are presented for the case of a 1024 x 1024, 18 -micron square <b>pixel</b> virtual <b>phase</b> CCD used with an electromagnetically focused f/ 2 Schmidt camera, which yields excellent simgle-photoevent discrimination and counting efficiency. Attention is given to the vacuum-chamber arrangement used to conduct system tests and the CCD electronics and data-acquisition systems employed...|$|R
50|$|A {{fundamental}} {{requirement of}} {{the removal of the}} ground signal is that the sum of phase contributions from the individual targets within the pixel remains constant between the two images and is completely removed. However, there are several factors that can cause this criterion to fail. Firstly the two images must be accurately co-registered to a sub-pixel level to ensure that the same ground targets are contributing to that pixel. There is also a geometric constraint on the maximum length of the baseline - the difference in viewing angles must not cause phase to change over the width of one pixel by more than a wavelength. The effects of topography also influence the condition, and baselines need to be shorter if terrain gradients are high. Where co-registration is poor or the maximum baseline is exceeded the <b>pixel</b> <b>phase</b> will become incoherent - the phase becomes essentially random from pixel to pixel rather than varying smoothly, and the area appears noisy. This is also true for anything else that changes the contributions to the <b>phase</b> within each <b>pixel,</b> for example changes to the ground targets in each pixel caused by vegetation growth, landslides, agriculture or snow cover.|$|R
40|$|Locating and {{steering}} entire ensembles of microscopic objects has become extremely practical {{with the emergence}} of holographic optical tweezers. Application of this technology to single molecule experiments requires great accuracy in the spatial positioning of optical traps. This paper calculates the theoretical position resolution of a single holographic beam, predicting that sub-nanometer resolution is easily achieved. Experimental corroboration of the spatial resolution’s inverse dependence on the hologram’s number of <b>pixels</b> and <b>phase</b> levels is presented. To at least a nanometer range position resolution, multiple optical tweezers created by complex superposition holograms also follow the theoretical predictions for a single beam...|$|R
40|$|This paper {{describes}} {{a method for}} converting a complex Fresnel hologram into a phase-only hologram that can be embedded with large amount of data. Briefly, each row of pixels in the hologram is scanned sequentially in a left-to-right direction. The magnitude of each visited pixel is set to a constant, and its phase is embedded with the data. Subsequently, the error is diffused to the neighborhood <b>pixels.</b> The <b>phase</b> hologram realized with such means, which {{is referred to as}} the data-embedded-error-diffusion (DEED) hologram, is capable of preserving high fidelity on the content of the hologram and the embedded data...|$|R
30|$|If a <b>pixel</b> has the <b>phase</b> {{standard}} deviation {{less than a}} certain threshold, it {{can be regarded as}} a PS. However, if adjacent pixels contain point scatterers [23], the clutter may be overestimated, which may result in the rejection of suitable PSC. In addition, a lot of computation time is needed in the implementation of this method.|$|R
30|$|The second {{process takes}} place {{to predict the}} missing pixels using the clusters, which {{performs}} a new framework for predicting the missing <b>pixels.</b> The clustering <b>phase</b> regroups automatically the pixels of an image into different homogeneous regions. These homogeneous regions usually contain similar objects or part of them. As a result, interesting performance will be achieved in the prediction step.|$|R
40|$|In this paper, we have {{presented}} a new permutation-substitution image encryption architecture using chaotic maps and Tompkins-Paige algorithm. The proposed encryption system includes two major parts, chaotic pixels permutation and chaotic pixels substitution. A logistic map {{is used to}} generate a bit sequence, {{which is used to}} generate pseudorandom numbers in Tompkins-Paige algorithm, in 2 D permutation <b>phase.</b> <b>Pixel</b> substitution <b>phase</b> includes two process, the tent pseudorandom image (TPRI) generator and modulo addition operation. All parts of the proposed chaotic encryption system are simulated. Uniformity of the histogram of the proposed encrypted image is justified using the chi-square test, which is less than 2 (255, 0. 05). The vertical, horizontal, and diagonal correlation coefficients, as well as their average and RMS values for the proposed encrypted image are calculated that is about 13 % less than previous researches. To quantify the difference between the encrypted image and the corresponding plain-image, three measures are used. These are MAE, NPCR, and UACI, which are improved in our proposed system considerably. NPCR of our proposed system is exactly the ideal value of this criterion. The key space of our proposed method is large enough to protect the system against any Brute-force and statistical attacks...|$|R
40|$|This paper {{describes}} an efficient algorithm for real-time terrain shadowing by directional light. The main concept for this algorithm is fast preprocessing stage in model space that dramatically speeds up shadow calculation for <b>pixels</b> in rasterization <b>phase.</b> Preprocessing is very fast {{and can be}} performed every frame still achieving interactive frame rates. Therefore it is suitable for dynamic height field and moving light source visualization...|$|R
40|$|Accurate {{diagnosis}} of acute appendicitis {{is a difficult}} problem in practice especially when the patient is too young or women in pregnancy. In this paper, we propose a fully automatic appendix extractor from ultrasonography by applying a series of image processing algorithms and an unsupervised neural learning algorithm, self-organizing map. From the suggestions of clinical practitioners, we define four shape patterns of appendix and self-organizing map learns those patterns in <b>pixel</b> clustering <b>phase.</b> In the experiment designed to test the performance for those four frequently found shape patterns, our method is successful in 3 types (1 failure out of 45 cases) but leaves a question for one shape pattern (80 % correct) ...|$|R
40|$|The CMS <b>pixel</b> {{detector}} <b>phase</b> 1 upgrade in 2017 {{requires an}} upgraded DAQ to accept higher data rates. A new DAQ {{system has been}} developed based {{on a combination of}} custom and standard microTCA parts. Custom mezzanines on FC 7 AMCs provide a front-end driver for readout, and front-end controller for configuration, clock and trigger. The DAQ system is undergoing a series of integration tests including readout of the pilot pixel detector already installed in CMS, checkout of the phase 1 detector during its assembly, and testing with the CMS central DAQ. This paper describes the DAQ system, integration tests and results, and an outline of the activities up to commissioning the final system at CMS in 2017...|$|R
50|$|Photonic Mixer Devices (PMD), the Swiss Ranger, and CanestaVision work by {{modulating}} {{the outgoing}} beam with an RF carrier, then measuring the phase shift of that carrier on the receiver side. This approach has a modular error challenge; ranges are mod the maximum range, {{which is the}} RF carrier wavelength. The Swiss Ranger is a compact, short-range device, with ranges of 5 or 10 meters, with 176 x 144 <b>pixels.</b> With <b>phase</b> unwrapping algorithms, the maximum uniqueness range can be increased. The PMD can provide ranges up to 60m. Illumination is pulsed LEDs, rather than a laser. CanestaVision developer Canesta was purchased by Microsoft in 2010. The Kinect2 for Xbox One was based on ToF technology from Canesta.|$|R
40|$|An {{overview}} of the ATLAS detector upgrade plans covering the main systems for phase 1 and phase 2. A slightly more {{detailed description of the}} silicon tracker upgrades, including the insertable b-layer (IBL) for phase 1, and the new <b>pixel</b> system for <b>phase</b> 2. A brief discussion of phase 2 track trigger options. As time allows, the FE-I 4 pixel readout chip and plans for a further generation...|$|R
40|$|Abstract Background Subtraction of Dynamic Contrast-Enhanced 3 D Magnetic Resonance (DCE-MR) volumes {{can result}} in images that depict and {{accurately}} characterize a variety of liver lesions. However, the diagnostic utility of subtraction images depends {{on the extent of}} co-registration between non-enhanced and enhanced volumes. Movement of liver structures during acquisition must be corrected prior to subtraction. Currently available methods are computer intensive. We report a new method for the dynamic subtraction of MR liver images that does not require excessive computer time. Methods Nineteen consecutive patients (median age 45 years; range 37 – 67) were evaluated by VIBE T 1 -weighted sequences (TR 5. 2 ms, TE 2. 6 ms, flip angle 20 °, slice thickness 1. 5 mm) acquired before and 45 s after contrast injection. Acquisition parameters were optimized for best portal system enhancement. Pre and post-contrast liver volumes were realigned using our 3 D registration method which combines: (a) rigid 3 D translation using maximization of normalized mutual information (NMI), and (b) fast 2 D non-rigid registration which employs a complex discrete wavelet transform algorithm to maximize <b>pixel</b> <b>phase</b> correlation and perform multiresolution analysis. Registration performance was assessed quantitatively by NMI. Results The new registration procedure was able to realign liver structures in all 19 patients. NMI increased by about 8 % after rigid registration (native vs. rigid registration 0. 073 ± 0. 031 vs. 0. 078 ± 0. 031, n. s., paired t -test) and by a further 23 % (0. 096 ± 0. 035 vs. 0. 078 ± 0. 031, p t -test) after non-rigid realignment. The overall average NMI increase was 31 %. Conclusion This new method for realigning dynamic contrast-enhanced 3 D MR volumes of liver leads to subtraction images that enhance diagnostic possibilities for liver lesions. </p...|$|R
40|$|Most {{optical and}} IR spectra are now {{acquired}} using detectors with finite-width pixels {{in a square}} array. This paper examines the effects of such pixellation, using computed simulations to illustrate the effects which most concern the astronomer end-user. Coarse sampling increases the random noise errors in wavelength by typically 10 - 20 % at 2 pixels/FWHM, but with wide variation depending on the functional form of the instrumental Line Spread Function (LSF) and on the <b>pixel</b> <b>phase.</b> Line widths are even more strongly affected at low sampling frequencies. However, the noise in fitted peak amplitudes is minimally affected. Pixellation has a substantial but complex effect {{on the ability to}} see a relative minimum between two closely-spaced peaks (or relative maximum between two absorption lines). The consistent scale of resolving power presented by Robertson (2013) is extended to cover pixellated spectra. The systematic bias errors in wavelength introduced by pixellation are examined. While they may be negligible for smooth well-sampled symmetric LSFs, they are very sensitive to asymmetry and high spatial frequency substructure. The Modulation Transfer Function for sampled data is shown to give a useful indication of the extent of improperly sampled signal in an LSF. The common maxim that 2 pixels/FWHM is the Nyquist limit is incorrect and most LSFs will exhibit some aliasing at this sample frequency. While 2 pixels/FWHM is often an acceptable minimum for moderate signal/noise work, it is preferable to carry out simulations for any actual or proposed LSF to find the effects of sampling frequency. Where end-users have a choice of sampling frequencies, through on-chip binning and/or spectrograph configurations, the instrument user manual should include an examination of their effects. (Abridged) Comment: 22 pages, 37 figures. Accepted for publication in PAS...|$|R
40|$|The {{need for}} DC {{balancing}} <b>phase</b> <b>pixels</b> in ferroelectric liquid-crystal-on-silicon spatial light modulators leads to control schemes that limit {{their use in}} beam steering applications where a continuous display of a routing hologram is required. By analyzing the phase redundancy in binary phase holograms, a new DC balancing algorithm has been developed that allows more general beam splitting and multiple beam steering functions. The theoretical derivation of the algorithm and experimentally measured properties of the optical beams are presented and discussed...|$|R
40|$|Phase {{images are}} derived from source images by {{applying}} a modulus operation to each <b>pixel</b> value. <b>Phase</b> unwrapping {{is the problem of}} inferring the original, unwrapped values from the wrapped values, using prior knowledge about the smoothness of the image. One approach to solving this problem is to infer the gradient vector field of the unwrapped image and then integrate the gradient field. The gradient in a particular direction at a pixel is equal to the observed pixel difference plus an unknown integer number of shifts. We introduce a technique for inferring these shifts using the low-complexity probability propagation algorithm, applied in a graphical model that prefers shifts that match the phase image and that constrains the shifts to satisfy the properties of a gradient field. We present results for a phase image from the region of the Sandia National Laboratories...|$|R
40|$|This paper {{presents}} algorithms {{developed for}} object-space parallelism for polygon rendering on hypercube-connected multicomputers. In object-space parallelism, each processor {{is given the}} responsibility to render {{a portion of the}} input polygons. Each processor shades and z-buffers the locally generated pixels. After this local rendering, the remaining pixels in each processor should be globally z-buffered. Efficient parallelization of this pixel merging operation is important. This is the only place where an overhead is incurred due to parallelization. In this paper, efficient algorithms are presented to perform local rendering and global pixel merging operations. A modified scanline based z-buffer algorithm is proposed. This algorithm reduces the number of pixels sent and received in the pixel merging operation and avoids the re-initialization of the z-buffer for each scanline. Various algorithms are proposed for <b>pixel</b> merging <b>phase.</b> These algorithms use different communication charac [...] ...|$|R
40|$|Owing to the {{platform}} instability and precision limitations of motion sensors, motion errors negatively {{affect the quality of}} synthetic aperture radar (SAR) images. The autofocus Back Projection (BP) algorithm based on the optimization of image sharpness compensates for motion errors through phase error estimation. This method can attain relatively good performance, while assuming the same phase error for all pixels, i. e., it ignores the spatial variance of motion errors. To overcome this drawback, a high-precision motion error compensation method is presented in this study. In the proposed method, the Antenna Phase Centers (APC) are estimated via optimization using the criterion of maximum image intensity. Then, the estimated APCs are applied for BP imaging. Because the APC estimation equals the range history estimation for each <b>pixel,</b> high-precision <b>phase</b> compensation for every pixel can be achieved. Point-target simulations and processing of experimental data validate the effectiveness of the proposed method...|$|R
40|$|The U. S. design {{concept for}} the Square Kilometer Array (SKA) program {{is based on}} {{utilizing}} {{a large number of}} 15 meter dish antennas. The Technology Development Project (TDP) is planning to design and build the first of these antennas to provide a demonstration of the technology and a solid base on which to estimate costs. This paper describes the performance of the selected optics design. It is a dual-shaped offset Gregorian design with a feed indexer that can accommodate corrugated horns, wide band single <b>pixel</b> feeds or <b>phased</b> array feeds...|$|R
40|$|Introduction The Dawn {{mission to}} Vesta has greatly {{improved}} {{the quality and}} resolution of data available to explore the asteroid. Prior to the Dawn mission the best data available was the one from Hubble Space Telescope [1 - 6] with a maximum resolution of 50 km per <b>pixel.</b> The survey <b>phase</b> of the mission has pushed spatial resolution up to about 100 meters per pixel by the Framing Camera (FC, [7]) on-board Dawn, and 700 meters per pixel for the VIR spectrometer, spanning the spectral range from the visible to infrared at 0 : 2...|$|R
40|$|In this paper, {{the authors}} propose a cell {{segmentation}} algorithm via spectral analysis over phase retardation features, which {{are derived from}} the optical principle of phase contrast microscopy image formation process. Images are first partitioned into phase-homogeneous atoms by clustering neighboring <b>pixels</b> with similar <b>phase</b> retardation features. Cell segmentation is then performed by clustering the atoms into several clusters using multi-class spectral analysis. Experimental results demonstrate that our method generates quality cell segmentation results and outperforms previous methods. Index Terms — phase contrast microscopy image analysis, phase retardation feature, spectral analysis, cell segmentation 1...|$|R
40|$|A {{significant}} concern {{when using}} Electronic Speckle Pattern Interferometry (ESPI) to measure surface displacements is the modest signal-to-noise ratio. The noise content causes the measured phase map {{to be very}} irregular, often leading to difficulties when phase unwrapping. Common filtering techniques tend to average the noise with adjacent pixels, thereby ameliorating the bad data by distorting the good data. This paper describes simple procedures to evaluate individual pixel quality and identify defective <b>pixels.</b> The <b>phase</b> data at these defective pixels is replaced by interpolations from the adjacent good pixels. In this way, defective pixels are “repaired ” without damaging the adjacent good pixels. The quality evaluation is done by examining the saturation, visibility and variation of each pixel. The suggested evaluation and correction procedures are demonstrated using a phase map from a hole-drilling residual stress experiment. The {{results show that the}} procedures provide an effective method for enhancing the quality of ESPI measurements...|$|R
40|$|Abstract—the {{key point}} of super {{resolution}} {{process is the}} accurate measuring of sub-pixel shift. Any tiny error in measuring such shift leads to an incorrect image focusing. In this paper, methodology of measuring sub-pixel shift using Phase correlation (PC) are evaluated using different window functions, then modified version of (PC) method using high pass filter (HPF) is introduced. Comprehensive analysis and assessment of (PC) methods shows that different natural features yield different shift measurements. It is concluded {{that there is no}} universal window function for measuring shift; it mainly depends on the features in the satellite images. Even the question of which window is optimal of particular feature is generally remains open. This paper presents the design of a method for obtaining high accuracy sub <b>pixel</b> shift <b>phase</b> correlation using (HPF). The proposed method makes the change in the different locations that lack of edges easy. Keywords-phase correlation (PC); high pass filter (HPF); window function; sub-pixel shift. I...|$|R
40|$|Liquid Crystal Spatial Light Modulators (LC SLMs) {{can be used}} as dynamic diffractive {{elements}} {{which can}} be controlled using for instance a computer. A wide range of possible applications exist, and LC SLMs have proven to be useful in for example laser beam steering. The aim {{of this study was to}} investigate if capabilities such as autofocus and Field of View tracking (FOV-tracking) found in a human eye can be transferred to a camera system based on a LC SLM. A setup was constructed using a 512 times 512 <b>pixels</b> <b>phase</b> modulating LC SLM from Boulder Nonlinear Systems (BNS) placed in the fourier plane of a 4 f-system. To go beyond what could be studied experimentally a simulation software was developed in Matlab. With this software the effect of optical phase delays, not achievable in the lab, could be studied. As expected from previous research, image quality was a large issue with the system. In FOV-steering and coherent illumination, undesired ghost images degraded the image at large steering angles (0. 5 degrees). In polychromatic illumination and FOV-steering, the images got heavily blurred. The situation was much better when the SLM was used for focusing and quite good image quality was achieved in that case, both in coherent and incoherent polychromatic illumination. The broadening of an intensity peak in polychromatic illumination was only a few pixels. This can be compared to FOV-steering where the broadening was about ten times larger. Simulations showed that the image quality would be improved if the SLM could generate larger phase delays. Autofocus and FOV-tracking were implemented successfully. The FOV-tracking system could reject disturbances below approximately 0. 4 Hz. The autofocus algorithm established focus from a largely defocused position within a few seconds. From this work, one can conclude that both autofocus and FOV-tracking can be implemented in a camera system based on a LC SLM and hence without any moving parts. FOV-tracking is difficult in polychromatic illumination while autofocus can be achieved in both coherent and incoherent polychromatic light. In future development of the system several improvements can be made concerning image quality and speed. Validerat; 20101217 (root...|$|R
40|$|Received date/Accepted date Aims. The primary {{objective}} {{of this study is}} to search for and identify wave modes within a sunspot penumbra. Methods. Infrared spectropolarimetric time series data are inverted using a model comprising two atmospheric components in each spatial <b>pixel.</b> Fourier <b>phase</b> difference analysis is performed on the line-of-sight velocities retrieved from both components to determine time delays between the velocity signals. In addition, the vertical separation between the signals in the two components is calculated from the Stokes velocity response functions. Results. The inversion yields two atmospheric components, one permeated by a nearly horizontal magnetic field, the other with a less-inclined magnetic field. Time delays between the oscillations in the two components in the frequency range 2. 5 − 4. 5 mHz are combined with speeds of atmospheric wave modes to determine wave travel distances. These are compared to expected path lengths obtained from response functions of the observed spectral lines in the different atmospheric components. Fast-mode (i. e., modified p-mode) waves exhibit the best agreement with the observations when propagating toward the sunspot at an angle∼ 50 ◦ to the vertical...|$|R
40|$|Aims: The primary {{objective}} {{of this study is}} to search for and identify wave modes within a sunspot penumbra. Methods: Infrared spectropolarimetric time series data are inverted using a model comprising two atmospheric components in each spatial <b>pixel.</b> Fourier <b>phase</b> difference analysis is performed on the line-of-sight velocities retrieved from both components to determine time delays between the velocity signals. In addition, the vertical separation between the signals in the two components is calculated from the Stokes velocity response functions. Results: The inversion yields two atmospheric components, one permeated by a nearly horizontal magnetic field, the other with a less-inclined magnetic field. Time delays between the oscillations in the two components in the frequency range 2. 5 - 4. 5 mHz are combined with speeds of atmospheric wave modes to determine wave travel distances. These are compared to expected path lengths obtained from response functions of the observed spectral lines in the different atmospheric components. Fast-mode (i. e., modified p-mode) waves exhibit the best agreement with the observations when propagating toward the sunspot at an angle ~ 50 degrees to the vertical. Comment: 8 pages, 12 figures, accepted for publication in Astronomy & Astrophysic...|$|R
40|$|A {{high-speed}} hybrid optical–digital correlator {{system was}} designed, constructed, modeled, and demonstrated experimentally. This correlator {{is capable of}} operation at approximately 3000 correlations/s. The input scene is digitized at a resolution of 512 × 512 <b>pixels</b> and the <b>phase</b> information of the two-dimensional fast Fourier transform calculated and displayed in the correlator filter plane at normal video frame rates. High-fidelity reference template images are stored in a phase-conjugating optical memory placed at the nominal input plane of the correlator and reconstructed with a high-speed acousto-optic scanner; this allows for cross correlation of the entire reference data set with the input scene within one frame period. A high-speed CCD camera is used to capture the correlation-plane image, and rapid correlation-plane processing is achieved with a parallel processing architecture...|$|R
40|$|An {{algorithm}} of phase-shifted image matching for {{the measurement}} of displacement from interferometric images is presented. The algorithm is capable of detecting the displacements between the interferograms captured by a CCD camera with subpixel accuracy. The phase curves are obtained from mean-square-difference calculations of any two fringe patterns shifted pixel by <b>pixel,</b> and the <b>phase</b> differences between the interferograms are computed by interpolation. An example of measurement of electrostatic force displacement by a fiber optic interferometer system is described. The experiment shows that the algorithm has the advantages of high measurement precision and high resistance to noise. The high resistance to noise of the algorithm makes it suitable for measurement even in harsh environmental conditions. (C) 1996 Society of Photo-Optical Instrumentation Engineers...|$|R
