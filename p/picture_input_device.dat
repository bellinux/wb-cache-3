0|4272|Public
40|$|A tablet <b>input</b> <b>device</b> (BID PAD) {{manufactured}} by Summagraphics Corp. {{is connected with}} a popular personal computer APPLE II which has high resolution graphic function. The system can <b>input</b> <b>pictures</b> from the tablet and display them on color TV screen. As software, drawing, painting, squaring, line drawing, and shaping routines are developed. The total program list is given...|$|R
40|$|This paper {{presents}} {{our approach}} {{for exploring the}} design space of <b>input</b> <b>devices</b> for three-dimensional graphics applications. We use an extended <b>input</b> <b>device</b> taxonomy as an inspiring source for generating permutations of sensors to suggest sensor configurations for new <b>input</b> <b>devices.</b> The taxonomy uses the integrated and separated degrees of freedom of an <b>input</b> <b>device</b> as a major classification criterion. We suggest and discuss <b>input</b> <b>devices</b> with six and twelve degrees of freedom, which are inspired by our taxonomy. By examining the properties of various devices and the different phases of a docking task, the idea for an <b>input</b> <b>device</b> with redundant degrees of freedom is derived. ...|$|R
5000|$|ZigBee <b>input</b> <b>device</b> - ZigBee (RF4CE) {{supports}} HID devices {{through the}} ZigBee <b>input</b> <b>device</b> profile.|$|R
40|$|Abstract: Experimental {{studies of}} spatial <b>input</b> <b>devices</b> {{have focused on}} demonstrating either the superiority of 3 D <b>input</b> <b>devices</b> over 2 D <b>input</b> <b>devices,</b> or the superiority of bimanual {{interaction}} over unimanual interaction. In this paper, we argue that hybrid interfaces that combine a 3 D <b>input</b> <b>device</b> with a 2 D <b>input</b> <b>device</b> have received little attention up to now and are potentially very useful. We demonstrate {{by means of an}} experimental evaluation that working with hybrid interfaces can indeed provide superior performance compared to strictly 3 D and 2 D interfaces...|$|R
40|$|The ToolStone is a cordless, {{multiple}} degree-of-freedom (MDOF) <b>input</b> <b>device</b> that senses {{physical manipulation}} of itself, such as rotating, flipping, or tilting. As an <b>input</b> <b>device</b> for the non-dominant hand when a bimanual interface is used, the ToolStone provides several interaction techniques including a toolpalette selector, and MDOF interactors such as zooming, 3 D rotation, and virtual camera control. In this paper, {{we discuss the}} design principles of <b>input</b> <b>devices</b> that effectively use a human's physical manipulation skills, and describe the system architecture and applications of the ToolStone <b>input</b> <b>device.</b> KEYWORDS: Interaction techniques, <b>input</b> <b>devices,</b> physical user interfaces, multiple function inputs, multiple-degreeof -freedom input, two-handed input INTRODUCTION Although the mouse is the most successful <b>input</b> <b>device</b> {{in the history of}} computer interfaces, its limits are becoming frustrating as the complexity of software increases. The mouse is a generic <b>input</b> <b>device,</b> so a [...] ...|$|R
40|$|Keyboards {{have been}} used on {{typewriters}} and as <b>input</b> <b>devices</b> to computers and many keyboards have been proposed {{in order to improve}} their performance. Some glove-based <b>input</b> <b>devices</b> to computers have been also proposed for compactness and flexibility. In this paper, an <b>input</b> <b>device</b> to computers consisting of a pair of gloves is proposed. The keys of the proposed gloves are mounted on the fingers of gloves and their chording methods resemble those of a Braille keyboard. Since the Braille representation for numbers and characters is efficient and has been well established for every language, the proposed <b>input</b> <b>device</b> may be one of good <b>input</b> <b>devices</b> to computers. Furthermore, since the Braille has been used for visually impaired people, the proposed one can be easily used as an <b>input</b> <b>device</b> to computers for them. Index Terms – keyboard, chord keyboard, chord glove, <b>input</b> <b>device,</b> Braille 1...|$|R
40|$|This' paper proposes virtual <b>input</b> <b>devices</b> {{based on}} {{collision}} detection for easy construc#on of interactive 3 D graphics applications, which use a motion capture {{system as a}} real-#me <b>input</b> <b>device.</b> Each virtual <b>input</b> <b>device</b> is' composed jm several collision sensor objects and an actuator object. These objects are software components' represented as a visible object which users can manipulate on a computer screen. Each virtual <b>input</b> <b>device</b> has a certain metaphor associated with its' role that is' determined by location and composition structure of its' components: Therefore, it is' possible to define various virtual <b>input</b> <b>devices</b> eas'ily only by combining several sensor objects and an actuator object through direct manipulations on a computer screen. This' paper presents' a realization mechanism and actual examples' of virtual <b>input</b> <b>devices...</b>|$|R
5000|$|When {{unprocessed}} data {{is sent to}} {{the computer}} with the help of <b>input</b> <b>devices,</b> the data is processed and sent to output <b>devices.</b> The <b>input</b> <b>devices</b> may be hand-operated or automated. The act of processing is mainly regulated by the CPU. Some examples of hand-operated <b>input</b> <b>devices</b> are: ...|$|R
50|$|Audio <b>input</b> <b>devices</b> {{are used}} to capture sound. In some cases, an audio output device {{can be used as}} an <b>input</b> <b>device,</b> in order to capture {{produced}} sound.Audio <b>input</b> <b>devices</b> allow a user to send audio signals to a computer for processing, recording, or carrying out commands. Devices such as microphones allow users to speak to the computer in order to record a voice message or navigate software.Aside from recording, audio <b>input</b> <b>devices</b> are also used with speech recognition software.|$|R
50|$|<b>Input</b> <b>devices</b> are {{instruments}} used {{to manipulate}} objects, and send control {{instructions to the}} computer system. They vary in terms of degrees of freedom available to them and can be classified into standard <b>input</b> <b>devices,</b> trackers, control devices, navigation equipment, and gesture interfaces. Standard <b>input</b> <b>devices</b> include keyboards, tablets and stylus, joysticks, mice, touch screens, knobs, and trackballs.|$|R
40|$|DE 19846762 A UPAB: 20000613 NOVELTY - An <b>input</b> <b>device</b> (1) {{creates an}} input signal. A display {{appliance}} has a display surface (3) fitted with an identifying mechanism for identifying an input signal. On its bottom side the <b>input</b> <b>device</b> forms an even surface (10) containing three trackballs (11) in a triangle. The <b>input</b> <b>device</b> slides {{on the display}} surface of a display appliance. USE - For multiple user applications, such as team work on factory planning projects. ADVANTAGE - The <b>input</b> <b>device</b> allows for the input {{of two or more}} signals...|$|R
50|$|Gauntlet is a {{wireless}} glove {{that can be}} used as a computer keyboard <b>input</b> <b>device.</b> The glove was invented under a project called G.A.U.N.T.L.E.T. (Generally Accessible Universal Nomadic Tactile Low-power Electronic Typist), and it is still in the beta phase. In addition to being a computer <b>input</b> <b>device,</b> Gauntlet can also be used as an <b>input</b> <b>device</b> for smartphones and other portable devices.|$|R
40|$|Concepts such as {{the logical}} device, taxonomies, and other {{descriptive}} frameworks have improved understanding of <b>input</b> <b>devices</b> but ignored or else treated informally their pragmatic qualities, which are fundamental to selection of <b>input</b> <b>devices</b> for tasks. We seek the greater leverage of a predictive theoretical framework by basing our investigation of three-dimensional vs. two-dimensional <b>input</b> <b>devices</b> on Garner’s theory of processing of perceptual structure in multidimensional space. We hy~othesize that perceptual structure ~rovides a key to understanding performance of multidimensional <b>input</b> <b>devices</b> on multidimensional tasks, Two three-dimensional tasks may seem equivalent, but if they involve different types of perceptua...|$|R
40|$|The paper {{describes}} two <b>input</b> <b>devices</b> and {{a software}} interface that allow severely impaired people to easily interact {{with a personal}} computer. The first <b>input</b> <b>device</b> does not require residual movement but makes use of skin electrical signals and applies Artificial Neural Networks to decode the mind-driven commands. The second <b>input</b> <b>device</b> is an evolution of a proximity sensor that can be activated using minimal residual movements, therefore it is suitable for {{the main part of}} motor disabilities. The software interface can be adapted to any kind of <b>input</b> <b>device</b> and makes it possible to access any standard software installed on a PC...|$|R
40|$|Persons {{suffering}} from intractable disease like ALS (Amyotrophic Lateral Sclerosis) and {{spinal cord injury}} often show deterioration in muscular function. Some of these patients are obliged to use artificial respirators and cannot have verbal communication with others. In order to support their communication, there exist various <b>input</b> <b>devices</b> like touch sensor <b>input</b> <b>devices,</b> capacitance sensor <b>input</b> <b>devices</b> and also vision <b>input</b> <b>devices.</b> In addition, computer controlled environment is helpful for such patients. By developing proper computer controlled environment which {{is controlled by the}} proper <b>input</b> <b>device,</b> even the patient with serious disability can live sound life. Due to the infrared network system, the computer controlled environment could be well organized. 9 th IEEE International Conference on Mobile Ad-Hoc and Sensor Networks, MSN 2013; Dalian; China; 11 December 2013 through 13 December 201...|$|R
50|$|An absolute-movement <b>input</b> <b>device</b> (e.g., stylus, {{finger on}} touch screen) {{provides}} a consistent mapping between {{a point in}} the input space (location/state of the <b>input</b> <b>device)</b> and {{a point in the}} output space (position of pointer on screen). A relative-movement <b>input</b> <b>device</b> (e.g., mouse, joystick) maps displacement in the input space to displacement in the output state. It therefore controls the relative position of the cursor compared to its initial position.|$|R
40|$|SummaryObjectiveTo {{study the}} effect of new {{interactive}} computer <b>input</b> <b>devices</b> on cartilage segmentation in terms of time, consistency between <b>input</b> <b>devices,</b> and precision in quantitative magnetic resonance imaging (qMRI). DesignWe compared two new <b>input</b> <b>devices,</b> an interactive digitizing tablet and an interactive touch-sensitive screen, to a traditional mouse. Medial tibial and patellar cartilage of six healthy and six osteoarthritic knees were segmented using each <b>input</b> <b>device.</b> Cartilage volume, surface area and mean thickness were assessed using a validated algorithm and used to determine consistency and precision. Segmentation time was also measured. ResultsSegmenting with an interactive touch-sensitive screen reduced segmentation time by 15 % {{when compared to the}} traditional mouse but we found no significant difference in segmentation time between the interactive digitizing tablet and the traditional mouse. We found no difference in consistency or precision of cartilage volume, mean thickness or surface area between the three <b>input</b> <b>devices</b> tested. ConclusionsWe conclude that measurements of cartilage made using articular cartilage segmentation from MR images are independent of the <b>input</b> <b>device</b> chosen for user interaction...|$|R
25|$|X is an architecture-independent {{system for}} remote {{graphical}} user interfaces and <b>input</b> <b>device</b> capabilities. Each person using a networked terminal {{has the ability to}} interact with the display with any type of user <b>input</b> <b>device.</b>|$|R
40|$|We {{present a}} new {{approach}} to the integration of <b>input</b> <b>devices</b> into virtual environment software systems. Our approach employs a so-called Mapper module as an intermediate between <b>input</b> <b>device</b> drivers and virtual environment application. Major advantages of our approach are full device-independence, including the easy integration of new <b>input</b> <b>devices</b> and emulation of missing device capabilities, interactive reconfiguration, sharing of <b>input</b> <b>devices</b> among multiple applications, automatic selection of devices and interaction appropriate for the task, and high-level support for a large variety of navigation styles in virtual environments. 1. Introduction Successful human-computer interaction requires efficient transfer of information from humans to computers. Such communication is mediated via <b>input</b> <b>devices,</b> which have become more diverse with the introduction of virtual reality systems that frequently use 6 degree of freedom (DOF) trackers and other devices that cannot really be consi [...] ...|$|R
5000|$|We {{categorize}} computer <b>devices</b> as <b>input</b> <b>devices</b> {{because we}} use these devices to send {{instructions to the}} computer, we are sending our [...] "Input" [...] to the computer, some common examples of computer <b>input</b> <b>devices</b> are: ...|$|R
40|$|ICon is {{an editor}} {{designed}} to select a set of <b>input</b> <b>devices</b> and connect them to actions into a graphical interactive application. ICon allows physically challenged users to connect alternative <b>input</b> <b>devices</b> and/or configure their interaction techniques according to their needs. It allows skilled users [...] graphic designers or musicians for example [...] to configure any ICon aware application to use their favorite <b>input</b> <b>devices</b> and interaction techniques (bimanual, voice enabled, etc.) ...|$|R
40|$|The present {{invention}} is in {{the technical}} field of computer <b>input</b> <b>devices.</b> More particularly, the present invention {{is in the}} technical field of computer keyboards. More particularly, a computer keyboard comprising capacitive multi-touch technology. Conventional computer <b>input</b> <b>devices</b> consist of a keyboard and a pointing device. These devices are often separated spatially thus decreasing the efficiency of user input due to time spent moving hands and fingers between the different <b>input</b> <b>devices...</b>|$|R
5000|$|Head-mounted {{displays}} are {{not designed}} to be workstations, and traditional <b>input</b> <b>devices</b> such as keyboards {{do not support the}} concept of smart glasses. <b>Input</b> <b>devices</b> that lend themselves to mobility and/or hands-free use are good candidates, for example: ...|$|R
40|$|Current <b>input</b> <b>device</b> {{taxonomies}} {{and other}} frameworks typically emphasize the mechanical structure of <b>input</b> <b>devices.</b> We suggest that selecting an appropriate <b>input</b> <b>device</b> for an interactive task requires looking beyond the physical structure of devices to the deeper perceptual {{structure of the}} task, the device, and the interrelationship between the perceptual structure of the task and the control properties of the device. We affirm that perception is key to understanding performance of multidimensional <b>input</b> <b>devices</b> on multidimensional tasks. We have therefore extended the theory of processing of perceptual structure to graphical interactive tasks and to the control structure of <b>input</b> <b>devices.</b> This allows us to predict task and device combinations that lead to better performance and hypothesize that performance is improved when the perceptual structure of the task matches the control structure of the device. We conducted an experiment in which subjects performed two tasks wi [...] ...|$|R
50|$|A position-control <b>input</b> <b>device</b> (e.g., mouse, {{finger on}} touch screen) {{directly}} changes the absolute or relative {{position of the}} on-screen pointer.A rate-control <b>input</b> <b>device</b> (e.g., trackpoint, joystick) changes the speed {{and direction of the}} movement of the on-screen pointer.|$|R
40|$|Little work {{exists on}} the testing and {{evaluation}} of computer-game related <b>input</b> <b>devices.</b> This paper presents five new performance metrics and utilizes two tasks from the literature to quantify differences between <b>input</b> <b>devices</b> in constrained threedimensional environments, similar to “first-person”-genre games...|$|R
5000|$|... #Caption: The {{joystick}} was {{the primary}} <b>input</b> <b>device</b> for 1980s era games. Now game programmers must account {{for a wide range}} of <b>input</b> <b>devices,</b> but the joystick today is supported in relatively few games, though still dominant for flight simulators.|$|R
40|$|This paper {{presents}} a new <b>input</b> <b>device</b> called Digital Foam designed to support natural sculpting operations {{similar to those}} used when sculpting clay. We have constructed two prototypes to test the concept of using a conductive foam <b>input</b> <b>device</b> to create 3 D geometries and perform sculpting operations. The novel contributions of this paper include the realization that conductive foam sensors are accurate enough to allow fine grained control of position sensing and can be used to build foam based <b>input</b> <b>devices.</b> We have designed a novel foam sensor array by combining both conductive and non-conductive foam to allow interference free sensor readings to be recorded. We also constructed two novel <b>input</b> <b>devices,</b> one flat <b>input</b> <b>device</b> with one hundred sensors, and a second spherical design with twenty one sensors, both allowing user interactions by touching or squeezing the foam surface. We present the design idea, foam sensor theory, two prototype designs, and the initial application ideas used to explore the possible uses of Digital Foam...|$|R
40|$|This paper {{presents}} a study which examined {{the selection of}} Web search results with a gaze-based <b>input</b> <b>device.</b> A standard list interface was compared to a grid and a tabular layout with regard to task performance and subjective ratings. Furthermore, the gazebased <b>input</b> <b>device</b> was compared to conventional mouse interaction. Test persons had to accomplish a series of search tasks by selecting search results. The study revealed that mouse users accomplished more tasks correctly than users of the gazebased <b>input</b> <b>device.</b> However, {{no differences were found}} between <b>input</b> <b>devices</b> regarding the number of search results taken into account to accomplish a task. Regarding task completion time and ease of search result selection only in the list interface gaze-based interaction was inferior to mouse interaction. Moreover, with a gaze-based <b>input</b> <b>device</b> search tasks were accomplished faster in tabular presentation than in a standard list interface, suggesting a tabular interface as best suited for gaze-based interaction...|$|R
40|$|This {{technical}} note presents a novel plastic-slider based mouse <b>input</b> <b>device</b> {{which may be}} used as a classical hand mouse (on a pad) or as a foot mouse (typically, on carpet). Our motivation is two-fold: first to understand the imagined versus feasible design space of constrained and unconstrained input technologies, and then to propose a novel sliding-based <b>input</b> <b>device</b> which we explicitly designed for standing. Unlike most mice, the slider mouse is designed to be easily used while standing rather than whilst seated, as an exertion interface which encourages hip and ankle mobility, lower body proprioception and single-leg strength & balance. We use this foot-based slider mouse as a research probe into questions of constrained-to-a-plane versus unconstrained <b>input</b> <b>devices,</b> and standing versus seated postures. Finally, we discuss results from the iterative prototyping process, and a qualitative pilot study of slider-based foot <b>input</b> <b>devices</b> and interaction techniques. ACM Classification: H 5. 2 [Information interfaces and presentation]: User Interfaces. – <b>Input</b> <b>devices</b> and strategies...|$|R
50|$|In computing, an <b>input</b> <b>device</b> is (a {{piece of}} {{computer}} hardware equipment) {{used to provide}} data and control signals to an information processing system such as a computer or information appliance. Examples of <b>input</b> <b>devices</b> include keyboards, mouse, scanners, digital cameras and joysticks.|$|R
40|$|This paper {{reports on}} an {{investigation}} into the basic properties and requirements of automatic speech recognition as an <b>input</b> <b>device</b> to a trial human computer interface. The experiments required subjects to carry out a simulated target acquisition and report filling task, with the available <b>input</b> <b>devices</b> being automatic speech recognition, trackball, function keys or a simultaneous combination of all three. Experiments were carried out under varying workload to examine the degradation of overall interface and individual <b>input</b> <b>device</b> performance under user stress...|$|R
40|$|My {{research}} interests span several overlapping areas of interactive digital media, including: Human-Computer Interaction: o Novel <b>input</b> <b>device</b> evaluation, mobile device interaction, large/tiled displays, experimental methodology Computer Games: o Game control and <b>input</b> <b>devices,</b> VR games, scale effects in game UIs, game information visualizatio...|$|R
50|$|<b>Input</b> <b>devices</b> {{allow the}} user to enter {{information}} into the system, or control its operation. Most personal computers have a mouse and keyboard, but laptop systems typically use a touchpad instead of a mouse. Other <b>input</b> <b>devices</b> include webcams, microphones, joysticks, and image scanners.|$|R
40|$|Abstract: Interacting in an {{immersive}} {{virtual environment}} {{we refer to}} the real world. The user gets to expect real world behaviour from virtual objects and functions. We explore the idea of bringing aspects of product design {{to the development of}} <b>input</b> <b>devices</b> and interaction techniques for virtual environments. We use ergonomics and product language to design the physical <b>input</b> <b>device,</b> the virtual representation and the connection between real and virtual parts. This connection, which we call amalgamation, is the most important element of the design, since it defines, if the user rather interacts with virtual objects as “virtual products ” (via an <b>input</b> <b>device),</b> or rather interacts with an <b>input</b> <b>device</b> as a “real product ” controlling virtual content. 1...|$|R
40|$|We {{describe}} {{a collection of}} tools designed {{to be used in}} a Modular Visualization Environment (MVE) that facilitate the use of a Virtual Reality (VR) <b>input</b> <b>device.</b> VR <b>input</b> <b>devices</b> provide the means to easily and intuitively specify information which is three- or six-dimensional. Many scientific visualization tasks require this type of information. Our goal is to reduce the user interface complexity by employing a six-dimensional <b>input</b> <b>device</b> to specify six-dimensional data in scientific visualization. In the following sections, we describe relevant previous work and the functions supported by tools: <b>device</b> <b>input,</b> camera positioning, object transformations and developer's tools...|$|R
