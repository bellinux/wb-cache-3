2|29|Public
40|$|The {{development}} of branding is a neglected theme in business history. This {{article examines the}} emergence {{on a large scale}} of the unique product brand name - distinct from a company name or <b>product</b> <b>descriptor</b> - in the UK in the later nineteenth century. It looks at the interaction of branding strategies and UK trade mark law, which is shown to have accorded property rights in word-based marks only gradually and shaped the {{development of}} branding in the UK. Trademark application data from the 1870 s to the 1920 s is cited to illustrate the widespread take-up of the brand name in the UK from the 1880 s, and to consider its use by different types of consumer goods firms. The article then analyses the effects of such branding into the twentieth century, including its contribution to competitive advantage, the introduction of brand architecture, and the problem of brand genericisation. It is argued that the adoption of the brand name marked a major shift in brands, from descriptions of origin to objects of artifice. branding, brand names, trade marks, brand architecture,...|$|E
40|$|The study {{investigated}} the effect of product description cues {{as a way to}} differentiate luxury products for the absolute luxury consumer and the effect of individual traits such as need for product involvement and product knowledge on consumers 2 ̆ 7 perceptions of expected price. An adult sample of 253 female US consumers were recruited for an online survey. The study results revealed that all <b>product</b> <b>descriptor</b> cues positively impacted consumers 2 ̆ 7 perceived prices of products. Clothing involvement was positively related to participants 2 ̆ 7 product knowledge which in turn positively influenced participants 2 ̆ 7 perceived change in expected price of products in response to various product descriptors or cues related to absolute luxury products. This study extends the research into the luxury market and identifies elements of the marketing mix which might be manipulated to better inform potential customers about the luxury product. The study further emphasizes that product descriptors or cues can have an impact on price judgments, especially for highly involved and knowledgeable consumers. This is especially important to academicians as well as marketers since high fashion involved consumers have often been seen as drivers, influential and legitimists of the fashion adoption process...|$|E
3000|$|... ” section. In addition, {{we check}} for matches between aspect {{expressions}} {{and the target}} product as a whole. In this case, we rely {{on the concept of}} <b>product</b> <b>descriptors,</b> also introduced in “ [...]...|$|R
40|$|Background: In theU. S., limited {{evidence}} {{exists on the}} impact of colors and brand imagery used in cigarette pack design. Purpose: This study examined the impact of pack design, <b>product</b> <b>descriptors,</b> and health warnings on risk perception and brand appeal. Methods: A cross-sectional mall-intercept study was conducted with 197 adult smokers and 20...|$|R
5000|$|If {{the company}} offers a single service or <b>product,</b> this <b>descriptor</b> would be sufficient. (ex. ZXC Services&Products 800-123-4567) ...|$|R
5000|$|In 2009, R. J. Reynolds Tobacco Company {{changed the}} flavor {{descriptors}} {{of all the}} Pall Mall brand hard packs to color designations. The descriptor change occurred because the FDA banned <b>product</b> <b>descriptors</b> such as [...] "Light," [...] "Ultra Light" [...] and [...] "Mild" [...] in 2010. Along with the change in descriptors, the rings and branding on the cigarettes have changed to match both {{the color of the}} box and the Pall Mall lettering on the filter for that particular descriptor. The soft packs are still sold with the traditional style packaging and design.|$|R
5000|$|In June 2009, the United States Senate passed anti-smoking {{legislation}} {{described by}} USA Today as “the most sweeping tobacco-control measure ever passed by Congress,” and this legislation directly impacts the marketing {{and consumption of}} light tobacco products. [...] In addition to giving the FDA regulatory power over all tobacco products, the bill severely restricts the tobacco industry’s previous marketing strategies, many of which relied on making implicit health claims about their products. [...] According to the bill, cigarette manufacturers are also forbidden from using <b>product</b> <b>descriptors</b> such as “light,” “low-tar,” and “mild.” ...|$|R
40|$|Sustainable {{development}} {{is not just}} about technological innovation, but rather about a radical shift in the way society thinks. The environmental effects of our choices and behavior must be internalized. In the context of product development, this internalization should occur in early product development under the guidance of an environmental expert. During early product design phases there may be numerous concepts with significant differences, detailed information is scarce, and decisions must be made quickly. The overhead in developing parametric life-cycle assessment (LCA) models for a diverse range of concepts, and the lack of detailed information make the integration of environmental expertise through traditional LCA models impractical. Therefore, a new approach was developed to incorporate analytically based environmental assessment in early design stages. <b>Product</b> <b>descriptors</b> are the communication interface between environmental experts and designers for this new model, called a learning surrogate LCA. <b>Product</b> <b>descriptors</b> are a set of keywords both understood by designers in relation to a preliminary product, and meaningful in an approximate environmental impact assessment of a product. This thesis develops a set of <b>product</b> concept <b>descriptors</b> for use in environmental assessment. The chosen descriptor set was measurable by designers in conceptual design, and produced reasonable results when used to predict environmental impacts using an approximate model. Tests within the DOME integrated modeling environment have shown it is possible to predict the life-cycle energy consumption of a product. There is also a basis for the method to be used in predicting solid material, greenhouse effect, ozone layer depletion, acidification, eutrophication, winter smog, and summer smog. by Julie L. Eisenhard. Thesis (S. M.) [...] Massachusetts Institute of Technology, Dept. of Mechanical Engineering, 2000. Includes bibliographical references (p. 68 - 72) ...|$|R
40|$|International audienceAlthough {{there is}} a lot of {{research}} on competitive analysis based on consumer data, little is known about how managers identify a product/brand as a competitor and on the criteria they use. Moreover, several questions can be asked as to the fact that different managers placed in similar market situations will or not define competition in the same way and on the basis of similar criteria. Our qualitative study shows that managers identify few competitors, mostly direct, and use especially <b>product</b> <b>descriptors</b> and impact descriptors rather than customer descriptors. Furthermore, managers tend to use few but very different criteria with the greatest differences observed between sales and marketing managers...|$|R
40|$|Geographical {{indications}} of origin are important tools for consumer protection and product differentiation {{in the wine}} industry. The federal Bureau ofAlcohol, Tobacco, and Firearms ("A TF") regulates their use on American wine labels. However, geographic terms also may appear on American wine labels in several other contexts, including as brand names, winery addresses, wine types, or even as grape variety names. These geo-graphic terms often conflict with a wine's geographical indication of agri-cultural origin. This Comment examines the core purposes ofATFs wine-labeling regulatory scheme and compares these purposes to the similar purposes of trademark law. Applying consumer confusion and dilution analyses of trademark law to wine label content, this Comment argues that significant inconsistencies in ATFs regulation of geographic terms un-dermine its ability to serve its core regulatory purposes. These "nonconformities " in ATF's overall zoning scheme {{for the use of}} <b>product</b> <b>descriptors</b> on wine labels have produced a great deal of industry debat...|$|R
40|$|International audienceSensory {{profiles}} are classically {{summed up}} by a Principal Component Analysis (PCA) performed on the table of means crossing <b>products</b> and <b>descriptors.</b> This paper proposes a way for evaluating the variability around the variables' representation in PCA. It is thus possible to {{have an idea of}} the uncertainty of the position of each variable. To do this, the resampling methods used take into account the special nature of sensory data...|$|R
30|$|Training a {{non-linear}} Support Vector Machine (SVM): {{the spatial}} histograms {{are used as}} image descriptors and fed to a linear SVM classifier. Linear SVMs are very fast to train, but also limited to use an inner <b>product</b> to compare <b>descriptors.</b> Much better results {{can be obtained by}} pre-transforming the data and to compute an explicit feature map that “emulates” a non-linear χ 2 -kernel as a linear one.|$|R
40|$|Chapter 1 {{examines}} {{the determinants of}} nursing home costs and cost efficiency, and investigates how various measures of nursing home care quality influence both of these. It applies a one-step stochastic frontier approach to a large panel of California nursing homes surveyed between 2009 and 2013. Quality is measured by three different ratings available on the Nursing Home Compare website: rating on quality measures, rating on the health inspection, and rating on staffing levels. Results show that the rating on quality measures, an outcome-based measure of quality, is inversely related to costs but unrelated to mean cost efficiency. In other words, a better rating on quality measures is associated with lower nursing home costs. The health inspection rating is not associated with either costs or mean cost efficiency. The rating for staffing levels, a structural measure of quality, is negatively associated with cost efficiency. These findings reveal that different measures of quality have different relationships with costs and cost efficiency. The findings suggest that better quality outcomes in nursing homes may be achievable with fewer resources and/or improved care procedures, which in turn should reduce nursing home costs. Chapter 2 investigates the relationships between three recently launched five-star quality ratings and technical efficiency of nursing homes. It employs an input-oriented two-stage data envelopment analysis {{in a sample of}} 338 nursing homes in California from 2009 through 2013. Results show that the quality measures rating and health inspection rating, used as <b>product</b> <b>descriptors,</b> do not affect mean technical efficiency of nursing homes. These ratings, however, affect efficiency of particular nursing homes and hence alter the ranking of nursing homes based on efficiency scores. The staffing rating, used as a structural quality, is negatively associated with mean technical efficiency. The different dimensions of quality have different impacts on technical efficiency and that a higher staff /resident ratio does not necessarily lead to an improved care process. It implies that a reallocation of a part of resources from nursing staffs towards monitoring care process/procedure may lead to better resource utilization and higher care quality...|$|R
5000|$|Sensory {{analysis}} A {{same set}} of products has been evaluated {{by a panel of}} experts and a panel of consumers. For its evaluation, each jury uses a list of descriptors (sour, bitter, etc.). Each judge scores each <b>descriptor</b> for each <b>product</b> on a scale of intensity ranging for example from 0 = null or very low to 10 = very strong. In the table associated with a jury, at the intersection of the row [...] and column , is the average score assigned to <b>product</b> [...] for <b>descriptor</b> [...]|$|R
40|$|Functional {{magnetic}} resonance imaging (fMRI) was used to investigate whether semantic judgments about products and persons are processed similarly. Our results suggest they are not: comparisons of neural correlates of <b>product</b> versus human <b>descriptor</b> judgments indicated greater activation in the medial prefrontal cortex regions for persons; for products, activation was greater in the left inferior prefrontal cortex, an area known {{to be involved in}} object processing. These findings serve to challenge the view that processing of products and brands is akin to that of humans and set a precedent for the use of fMRI techniques in consumer neuroscience studies. (c) 2006 by JOURNAL OF CONSUMER RESEARCH, Inc [...] ...|$|R
40|$|The {{description}} of large state spaces through stochastic structured modelingformalismslikestochasticPetrinets,stochasticautomatanetworksand performance evaluation process algebra isusually maderepresenting theinfinitesimal generator {{of the underlying}} Markov chain as a Kronecker descriptor instead of a single large sparse matrix. Themost known algorithms used to compute iterative solutions of such structured models are: the pure sparsesolutionapproach,analgorithmthatcanbeverytimeefficient,andalmost always memory prohibitive; the Shuffle algorithm which performs the <b>product</b> of a <b>descriptor</b> byaprobability vector withavery impressive memory efficiency; and a recent new option that offers a trade-off between time and memory savings, the Split algorithm. This paper presents a full comparison of these algorithms solving some examples of structured Kronecker represented modelsinordertonumericallyillustratethegainsachievedconsidering each model characteristics. ...|$|R
40|$|This thesis {{develops}} an approximate, analytically based {{environmental assessment}} method that provides fast evaluations of product concepts. Traditional life-cycle assessment (LCA) studies and their streamlined analytical versions are costly, time-consuming, and data intensive. Thus, {{they are not}} practical to apply during early concept design phases where little information is available and ideas change quickly. Alternatives currently used are mostly qualitative, ad-hoc approaches that often provide overly simplistic assessments difficult to trade-off with other design objectives. The Learning Surrogate LCA method is an alternative approach that uses simple, high-level, and accessible descriptive information about a product to provide approximate, yet useful, analytical LCA results during early concept design stages. The method relies on a general artificial neural network (ANN) trained on high-level <b>product</b> <b>descriptors</b> and environmental performance data from pre-existing detailed life-cycle assessment studies or related data. To quickly obtain an approximate environmental impact assessment for a product concept, the design team queries the trained artificial model with new set of descriptors, without requiring {{the development of a}} new model. The predicted environmental performance, along with other key performance measures, can be used in tradeoff analysis and concept selection. Foundations for the approach were established by investigating: (1) model inputs in the form of a compact, and meaningful set of product concept descriptors; (2) ability to gather data and appropriately train an ANN-based surrogate LCA model. (cont.) Proof-of-concept tests on life-cycle energy consumption showed that ANN-based surrogate models were able to: (a) match detailed LCA results within the accuracy of typical LCA studies; (b) predict relative differences of distinct product concepts; (c) correctly predict and generalize trends associated with changes for a given product concept. A product classification system based upon concept descriptors was developed to improve performance. The method was then applied to a case study with a heavy truck manufacturing company. A demonstration example was used to illustrate application scenarios for tradeoff analysis within DOME (Distributed Object-based Modeling Environment). The study suggested that high-level, customizable simulation interfaces of learning surrogate LCA models are likely to have a significant practical impact in the early decision making process. by Inês Sousa. Thesis (Ph. D. in Environmental Systems Design) [...] Massachusetts Institute of Technology, Engineering Systems Division, Technology, Management, and Policy Program, 2002. Includes bibliographical references (p. 143 - 150) ...|$|R
40|$|One task facing market {{researchers}} {{is that of}} profiling a product, {{by taking}} a predefined list of descriptors and eliciting {{the relationship between the}} <b>product</b> and each <b>descriptor</b> in turn (“applicable ” or “not applicable”; “good description ” or “bad description”). Accuracy is gained if in addition the relationships among the descriptors are known: they become a meaningful nomological net, which can be depicted as a geometrical model. In this study, a large, extensive net is constructed, using an innovative split-deck sorting procedure to collect the data. It is argued that in comparison with the conventional treatment of sorting data, the custom-designed algorithms involved in the construction of this net are less susceptible to artefacts...|$|R
40|$|The {{description}} of large state spaces through stochastic struc-tured modeling formalisms like stochastic Petri nets, stochastic au-tomata networks and performance evaluation process algebra usu-ally represent the infinitesimal generator {{of the underlying}} Markov chain as a Kronecker descriptor instead of a single large sparse ma-trix. The best known algorithms used to compute iterative solutions of such structured models are: the pure sparse solution approach, an algorithm {{that can be very}} time efficient, and almost always mem-ory prohibitive; the Shuffle algorithm which performs the <b>product</b> of a <b>descriptor</b> by a probability vector with a very impressive mem-ory efficiency; and a newer option that offers a trade-off between time and memory savings, the Split algorithm. This paper presents a comparison of these algorithms solving some examples of struc-tured Kronecker represented models in order to numerically illus-trate the gains achieved considering each model’s characteristics...|$|R
40|$|Robert Welsh are gratefully acknowledged. We wish {{to thank}} Gus Craik for {{providing}} us with a compiled list of trait adjectives. In addition, the authors acknowledge the helpful input of the editor, associate editor, reviewers, Jennifer Aaker, and Trey Hedden. 3 Functional magnetic resonance imaging (fMRI) was used to investigate whether semantic judgments about products and persons are processed similarly. Our results suggest they are not: comparisons of neural correlates of <b>product</b> versus human <b>descriptor</b> judgments indicated greater activation in the medial prefrontal cortex regions for persons; for products, activation was greater in the left inferior prefrontal cortex, an area known {{to be involved in}} object processing. These findings serve to challenge the view that processing of products and brands is akin to that of humans, and set a precedent for the use of fMRI techniques in consumer neuroscience studies. 4 Consumer researchers and marketing practitioners have long asserted that products ca...|$|R
40|$|To detect panel disagreement, {{we propose}} the {{clustering}} around latent variables for three-way data (CLV 3 W) approach which extends the clustering of variables around latent components (CLV) approach to three-way data typically {{obtained from a}} conventional sensory profiling procedure (i. e., assessors rating <b>products</b> on various <b>descriptors).</b> The CLV 3 W method groups the descriptors into Q clusters and estimates for each cluster an associated latent sensory component such that the attributes within each cluster are as much related (i. e., highest squared covariance) as possible with the latent component. Simultaneously, for each latent sensory component separately, a system of weights is estimated that yields information regarding {{the extent to which}} an assessor (dis) agrees {{with the rest of the}} panel according to the latent sensory component under study. Our new approach is illustrated with a dataset pertaining to Quantitative Descriptive Analysis applied to cider varieties. It is shown that CLV 3 W, as opposed to related approaches, is able to detect differential panel disagreement on various latent sensory components. status: publishe...|$|R
40|$|International audienceDuring {{the last}} decade, a {{significant}} {{attention has been}} paid, by the computer vision and the computer graphics communities, to three dimensional (3 D) object retrieval. Shape retrieval methods {{can be divided into}} three main steps: the shape descriptors extraction, the shape signatures and their associated similarity measures, and the machine learning relevance functions. While the first and the last points have vastly been addressed in recent years, in this paper, we focus on the second point; presenting a new 3 D object retrieval method using a new coding/pooling technique and powerful 3 D shape descriptors extracted from 2 D views. For a given 3 D shape, the approach extracts a very large and dense set of local descriptors. From these descriptors, we build a new shape signature by aggregating tensor <b>products</b> of visual <b>descriptors.</b> The similarity between 3 D models can then be efficiently computed with a simple dot product. We further improve the compactness and discrimination power of the descriptor using local Principal Component Analysis on each cluster of descriptors. Experiments on the SHREC 2012 and the McGill benchmarks show that our approach outperforms the state-of-the-art techniques, including other BoF methods, both in compactness of the representation and in the retrieval performance...|$|R
40|$|Functional {{magnetic}} resonance imaging (fMRI) was used to investigate whether semantic judgments about products and persons are processed similarly. Our results suggest they are not: comparisons of neural correlates of <b>product</b> versus human <b>descriptor</b> judgments indicated greater activation in the medial prefrontal cortex regions for persons; for products, activation was greater in the left inferior prefrontal cortex, an area known {{to be involved in}} object processing. These findings serve to challenge the view that processing of products and brands is akin to that of humans and set a precedent for the use of fMRI techniques in consumer neuroscience studies. Consumer researchers and marketing practitioners have long asserted that products can possess humanlike traits (Aaker 1997; Azoulay and Kapferer 2003; Plummer 1985). A tendency to view or describe products {{in a manner similar to}} persons may reflect a general inclination to anthropomorphize everyday objects (e. g., cars, computers). There are a number of interrelated reasons for terms descriptive of human traits to be extrapolated to products and brands. Among the most compelling of these is evolutionary: over the millennia, a richly detailed conceptual system has emerged to allow humans to relate their characters and actions to one another; identifiable branding of goods is a comparatively abrupt de...|$|R
40|$|During {{the last}} decade, a {{significant}} {{attention has been}} paid, by the computer vision and the computer graphics communities, to three dimensional (3 D) object retrieval. Shape retrieval methods {{can be divided into}} three main steps: the shape descriptors extraction, the shape signatures and their associated similarity measures, and the machine learning relevance functions. While the first and the last points have vastly been addressed in recent years, in this paper, we focus on the second point; presenting a new 3 D object retrieval method using a new coding/pooling technique and powerful 3 D shape descriptors extracted from 2 D views. For a given 3 D shape, the approach extracts a very large and dense set of local descriptors. From these descriptors, we build a new shape signature by aggregating tensor <b>products</b> of visual <b>descriptors.</b> The similarity between 3 D models can then be efficiently computed with a simple dot product. We further improve the compactness and discrimination power of the descriptor using local Principal Component Analysis on each cluster of descriptors. Experiments on the SHREC 2012 and the McGill benchmarks show that our approach outperforms the state-of-the-art techniques, including other BoF methods, both in compactness of the representation and in the retrieval performance...|$|R
40|$|It is {{important}} to trade-off environmental effects and product performance, preferably using integrated analytical models, when designing a product. One approach to collaborative modelling for this purpose is to view sub-models, including life cycle assessment models, as objects which exchange services. This communicating object architecture for integrated environmental assessment has been demonstrated successfully in prior research. However, it is often prohibitively time consuming to build detailed LCA models when designs are evolving rapidly. This paper explores the feasibility of an approach to address this issue, using surrogate LCA models based upon learning systems which extrapolate results from detailed product LCA analyses available in databases. First, a list of key <b>product</b> attributes or <b>descriptors</b> is identified based on existing LCA studies and databases. Then, a database of LCA results, mapped to these attributes, is developed. A neural network is trained using these data to generalize the relationships between product attributes and LCA indicators. The services of this surrogate LCA model are then made available to other models {{so that it can}} provide preliminary predictions of LCA indicators for a new design without requiring a new detailed LCA model. A preliminary implementation is described and tests to assess the feasibility of the approach are provided. The trained surrogate LCA model is used to predict LCA indicators of products and compared with traditional LCA results and issues requiring further research are outlined...|$|R
40|$|This thesis {{documents}} research undertaken {{into the}} design and evaluation of a computer tool (Colour Concept Generator) to produce colour schemes for <b>products</b> from verbal <b>descriptors</b> depicting a required aesthetic image or style. The system was designed to translate between descriptive words and colour combinations and aims to provide a form of ideas stimulus for a product designer at {{the initial stages of}} the design process. The computer system uses elements of artificial intelligence (AI) to `learn' colour and descriptor semiotic relations from a product designer based upon a proposed objective criteria or to reflect a designers personal style. Colour concepts for products can then be generated from descriptors based upon these semiotic relations. The philosophy of the research is based upon the idea of computing colour aesthetics at {{the front end of the}} design process and the design of an Al software mechanism to facilitate this. The problem was analysed with respect to the available literature on colour and a set of detail requirements for the system were presented. The system was then designed and code based upon the requirements and evaluated in terms of the overall philosophy, system methodology and application of computer media. The research is a contribution to the field of computer aided design regarding colour aesthetics and demonstrates the possibility of using an artificial intelligent machine to inspire and stimulate creative human thought. The Al software mechanism of the Colour Concept Generator is presented as an application of Al to aesthetic design. 1...|$|R
40|$|University of Minnesota Ph. D. dissertation. September 2008. Major: Food science. Advisor: Gary A. Reineccius. 1 {{computer}} file (PDF); viii, 100 pages. Frontenac (Vitis spp. MN 1047) is a new, cold-hardy red wine grape {{that is currently}} the most-planted grape cultivar {{in much of the}} Upper Midwest. Though typically described as having notes of cherry, black currant and spice, the volatile characteristics of Frontenac wine have not been investigated, and no structured evaluation of common sensory characteristics has been performed. To develop a standard set of aroma descriptors that characterize red Frontenac table wines, descriptive analysis was performed on six <b>products.</b> Thirteen sensory <b>descriptors</b> were developed and defined with reference standards; correlation plots indicated that attributes were discrete and not redundant. All 13 attribute descriptors were useful for describing and/or distinguishing between red Frontenac table wines. In order to determine odor active compounds, eight Frontenac table wines were evaluated using stirbar sorptive extraction (SBSE) combined with concurrent gas chromatography-olfactometry/ mass spectrometry (GCO/MS). Twenty-four volatiles perceived by panelists were identified via mass spectra comparison, and included five alcohols, fourteen esters, one lactone, two acids and two volatile phenols. Twenty-four of these were confirmed with LRI comparisons in separate GC/MS analyses using a C 6 to C 16 carbon ladder, and 23 were quantified in runs using a known concentration of internal standard. Analyses of wines produced from V. riparia clone # 89, a parent of Frontenac, identified 16 volatiles common to Frontenac wines. Tentative identification, via GC/MS, of Frontenac juice with two days of skin contact suggested that four volatiles found in the wine may originate in the fruit...|$|R
40|$|Abstract Background Explicit {{labelling}} {{of lower}} strength alcohol products could reduce alcohol consumption by attracting {{more people to}} buy and drink such products instead of higher strength ones. Alternatively, it may lead to more consumption due to a ‘self-licensing’ mechanism. Equivalent labelling of food or tobacco (for example “Low fat” or “Low tar”) could influence consumption of those products by similar mechanisms. This systematic review {{examined the effects of}} ‘Low alcohol’ and equivalent labelling of alcohol, food and tobacco products on selection, consumption, and perceptions of products among adults. Methods A systematic review was conducted based on Cochrane methods. Electronic and snowball searches identified 26 eligible studies. Evidence from 12 randomised controlled trials (all on food) was assessed for risk of bias, synthesised using random effects meta-analysis, and interpreted in conjunction with evidence from 14 non-randomised studies (one on alcohol, seven on food and six on tobacco). Outcomes assessed were: quantities of the product (i) selected or (ii) consumed (primary outcomes - behaviours), (iii) intentions to select or consume the product, (iv) beliefs associated with it consumption, (v) product appeal, and (vi) understanding of the label (secondary outcomes – cognitions). Results Evidence for impacts on the primary outcomes (i. e. amounts selected or consumed) was overall of very low quality, showing mixed effects, likely to vary by specific label <b>descriptors,</b> <b>products</b> and population characteristics. Overall very low quality evidence suggested that exposure to ‘Low alcohol’ and equivalent labelling on alcohol, food and tobacco products can shift consumer perceptions of products, with the potential to ‘self-licence’ excess consumption. Conclusions Considerable uncertainty remains about the effects of labels denoting low alcohol, and equivalent labels, on alcohol, food and tobacco selection and consumption. Independent, high-quality studies are urgently needed to inform policies on labelling regulations...|$|R
40|$|Background Explicit {{labelling}} {{of lower}} strength alcohol products could reduce alcohol consumption by attracting {{more people to}} buy and drink such products instead of higher strength ones. Alternatively, it may lead to more consumption due to a ‘self-licensing’ mechanism. Equivalent labelling of food or tobacco (for example “Low fat” or “Low tar”) could influence consumption of those products by similar mechanisms. This systematic review {{examined the effects of}} ‘Low alcohol’ and equivalent labelling of alcohol, food and tobacco products on selection, consumption, and perceptions of products among adults. Methods A systematic review was conducted based on Cochrane methods. Electronic and snowball searches identified 26 eligible studies. Evidence from 12 randomised controlled trials (all on food) was assessed for risk of bias, synthesised using random effects meta-analysis, and interpreted in conjunction with evidence from 14 non-randomised studies (one on alcohol, seven on food and six on tobacco). Outcomes assessed were: quantities of the product (i) selected or (ii) consumed (primary outcomes - behaviours), (iii) intentions to select or consume the product, (iv) beliefs associated with it consumption, (v) product appeal, and (vi) understanding of the label (secondary outcomes – cognitions). Results Evidence for impacts on the primary outcomes (i. e. amounts selected or consumed) was overall of very low quality, showing mixed effects, likely to vary by specific label <b>descriptors,</b> <b>products</b> and population characteristics. Overall very low quality evidence suggested that exposure to ‘Low alcohol’ and equivalent labelling on alcohol, food and tobacco products can shift consumer perceptions of products, with the potential to ‘self-licence’ excess consumption. Conclusions Considerable uncertainty remains about the effects of labels denoting low alcohol, and equivalent labels, on alcohol, food and tobacco selection and consumption. Independent, high-quality studies are urgently needed to inform policies on labelling regulations. This report was joint-funded by the Department of Health in England Policy Research Programme (Policy Research Unit in Behaviour and Health (PR-UN- 0409 - 10109)) and an NIHR Senior Investigator Award (NF-SI- 0513 - 10101) held by T. M. Marteau (corresponding author) ...|$|R
40|$|Background: Caffeine {{is one of}} {{the most}} widely used psychoactive {{substances}} worldwide, and can be found in a wide variety of food and beverages. It is regularly used for mental and physical stimulation; however its use has also been linked to adverse effects such as uncontrollable tremors, headaches, hospitalisation and even death. The caffeine intake of New Zealanders is unknown. There is currently no comprehensive tool available to assess caffeine intake patterns, influences, and adverse experiences in the New Zealand adult population. Aim: To develop a questionnaire that accurately evaluates caffeine intake patterns, influences on consumption, and positive and negative experiences across a range of caffeinated products in New Zealand adults aged 15 years and over. Method: The caffeine consumption habits questionnaire (CaffCo) was developed in two stages. Firstly, seven focus groups (n= 43) were conducted across a range of demographic groups to explore factors influencing the consumption of tea, coffee, chocolate, kola drinks, energy drinks, caffeinated alcoholic premixed beverage (RTDs), caffeinated sports supplements, and caffeine tablets. Focus groups were audio recorded and then transcribed. NVivo software was used for qualitative analysis of the transcripts. Sections of text were coded by inductive analysis into 4 key themes, each with their own set of theme descriptors. Findings from the thematic analysis were then used to develop a draft of the online CaffCo using Qualtrics online survey software. Online pilot testing of CaffCo was then undertaken among focus group participants, academic staff and community members (n= 227). The pilot test participants provided feedback on the comprehensibility and ease of use of the questionnaire. Results: From thematic analysis of the focus group transcripts four main themes which influenced caffeinated product intake were identified. These were social drivers, environmental opportunity, functional expectations and individual experiences. The questionnaire items were derived from associations of <b>products</b> with theme <b>descriptors.</b> ii Conclusion: The caffeine consumption habits questionnaire CaffCo was successfully developed as a result of this study. CaffCo has the potential to be used in New Zealand-wide studies of adults aged 15 years and over, or adapted for use in different population groups / countries to identify potentially harmful patterns of caffeine consumption across a range of caffeinated products. Pilot testing of CaffCo demonstrated an accurate reflection of influences of caffeinated product consumption, and identified three additional influences on consumption. Pilot testing of the resultant questionnaire enabled demonstration of content validity, construct validity and inter-rater reliability. Further testing of the CaffCo to determine test-retest reliability is warranted...|$|R
40|$|Abstract: Changes in food {{process and}} the higher demand for foods that have health benefits, besides high sensory and {{nutritional}} quality, make new-products development necessary. This study aimed to develop different formulas of glutenfree carrot cake with maize oil and traditional carrot cakes with wheat flour and maize oil or palm oil. Acceptance by consumers, their purchase intention and the nutritional facts of the formulas were also goals of this research. Firstly, a mix of gluten-free flours was suggested in order to replace wheat flour in cakes. Glutenfree cake was compared to two types of cake made with wheat flour (gluten) and with different types of fat. The gluten-free cake (BIG) produced with MIX - 1, the cake with gluten and maize oil (BGOM) and the cake with gluten and palm oil (BGOP) with 80 and 100 g were assessed for their nutritional values, preference and purchase intent. BIG MIX- 1 and BGOP 80 g had nutritional values, preference and purchase intent comparable to standard formulation. Therefore, the glutenfree-flour mix (MIX- 1) and palm oil {{can be used as}} ingredients for carrot cake, providing products with features that meet the requirements of the consumer market. Secondly, a new goal was drawn and new gluten-free formulas were developed and standardized from the first suggested gluten-free-flour mix. Acceptance rates were one more time evaluated. For this purpose and due to the large number of variables, mix of gluten-free flours and maize oil were the only two variables chosen. Thus, we left the suggestion of new experiments with palm oil. For the 12 -essays-experimental design, three gluten-free mixes with four different gluten-free flours were developed. The attributes of the cakes made with these mixes were compared with the attributes of the standard cake, with gluten. The results were analyzed by ANOVA, Tukey test (p< 0. 05) and Cluster Analysis. Three trials did not differ significantly from standard cake. The best formulas have obtained mass ratio between six and four. Overall linking of the gluten-free formulas was scored between 7. 55 and 6. 80 and the standard, gained 7. 15. Hardness, fracturability, gumminess and Adhesiveness interfered negatively in the acceptance, while Softness, resilience, cohesiveness and water activity interfered in a positive way. Thus, {{it can be said that}} it is feasible to substitute wheat flour for gluten-free flours in the production of carrot cake and keep its sensory characteristics. Once we have reached results that showed that the ratio of mass between six and four presented the best sensory and instrumental responses we decided to continue the research by standardizing the gluten-free formulations and also suggested a new mix of gluten-free flour, but at this time, without corn meal once some consumers commented that cakes with that flour tasted like cornmeal cake. In addition, we elaborated the diet version (without sucrose) of gluten-free formulas. So, the novel goal was to assess the sensory and temporal profiles and the overall acceptance rate of the new seven different formulas of carrot cakes. The formulas were then evaluated by Descriptive Quantitative Analysis (QDA) with 12 trained panelists and by Time-Intensity Analysis (TI) with 13 trained panelists. The results were analyzed by ANOVA, Tukey test (p< 0. 05) and Principal Component Analysis (PCA). In order to complement the analysis, Global Acceptance was carried out with 120 consumers and its results were analyzed by ANOVA, Tukey (p < 0. 05) and External Preference Mapping (MPREFE) which informed the descriptive attributes most preferred by the consumers in order to ensure acceptance of the <b>products.</b> Sixteen <b>descriptor</b> terms were defined during QDA study, and only sweet taste attribute underwent temporal study. It was observed that the samples that contained corn meal in its formula were more brittle, sandy, apparently drier, less elastic and less soft. In contrast, the formulas without cornmeal were more adhesive, but with better taste and flavor of carrots, while the standard sample, with gluten and sucrose, was said as being the softest, due to the presence of gluten. Cake samples showed no significant difference for the temporal profile of their sweet taste. The differences observed by the QDA trained panelists were not detected by consumers, who showed good acceptance for all samples with no difference. Furthermore, MPREFE shows that, for consumers, carrot cakes are supposed to be moist and soft, porous and smell sweet. Therefore, it was concluded that the replacement of wheat flour and sucrose in carrot cake is possible and meets consumer expectations. Finally, acceptance of appearance, aroma, flavor, texture and overall liking of the seven samples was evaluated by 120 consumers of carrot cake using the 9 cm-linear scale. Data were analyzed by ANOVA, Tukey test (p < 0. 05), internal preference mapping and dendogram. Furthermore, data of texture parameters such as hardness, adhesiveness, gumminess, chewiness, cohesiveness, fracturability and resilience, water activity and color of the samples were analyzed by Partial Least Square (PLS) in order to determine the influence of instrumental parameters on consumers' hedonic acceptance. It was observed that all the cakes were well accepted, except the SGD 1, which sweetness seemed to be questionable. As for the instrumental aspects, cohesiveness and elasticity have influenced the acceptance of products. The other parameters were not relevant to the panelists. Finally, we obtained results for purchase intention using the 5 -point-attitude scale. Panelists indicated an interest in buying the cakes, except for the SGD 1 sampl...|$|R

