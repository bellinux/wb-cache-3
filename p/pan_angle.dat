28|49|Public
50|$|A {{virtual studio}} is a {{television}} studio {{that allows the}} real-time combination of people or other real objects and computer generated environments and objects in a seamless manner. A key point of a virtual studio is that the real camera can move in 3D space, while {{the image of the}} virtual camera is being rendered in real-time from the same perspective, therefore, this virtual scene has to adapt at any time to the camera settings (zoom, <b>pan,</b> <b>angle,</b> traveling, etc.). This is what differentiates a virtual studio from the traditional technique of chromakey. It also differs from techniques used in film, in which scenes are edited later. A virtual studio does not need any post production because it is in real-time. However a 3-D graphic artist and 3D computer graphics software are needed to create the virtual background, and any graphics that appear in front.|$|E
50|$|The {{gameplay}} {{is based}} primarily on using jumps and maneuvering to traverse obstacles while simultaneously battling foes. Since the player is punished implicitly for missing jumps over bottomless pits this game can be considered within the genre of 3D platformers. The camera follows the SOPHIA's viewing angle when in the vehicle, but having dismounted, the camera must be controlled manually by the player. Targeting while running may therefore be seen by some as difficult because of the combination of having to adjust the camera <b>pan</b> <b>angle</b> manually. This difficulty can be exacerbated {{by the fact that}} when the player chooses to move laterally from the angle the character is facing, strafing is done literally by jumping. This means that once the player has committed to dodging in a certain direction, it cannot be changed. Unlike SOPHIA, the player cannot initiate a lateral dodge movement after leaving the ground. The graphics are typical of the 32-bit gaming era, and models are original and varied. The game has a load sequence between each room or when transferring Roddy back to SOPHIA when on foot. Load times can be shortened if playing on a PS2 by changing the disc speed on the PS driver from within the PlayStation BIOS. Sound effects tend to be recycled throughout the game, and each level has its own background theme music.|$|E
40|$|Although {{aircraft}} cabin design has improved over the years, passengers continue {{to complain about}} sitting discomfort whilst flying. These complaints are often centred on the cramped and restricted seating conditions. Whilst passenger comfort is important, in order for airline companies {{to attract and retain}} customers, {{it is also important to}} design for cabin space needs. Denel Aviation intends to build a South African Regional Aircraft (SARA) that will fly point-to-point, linking regional centres and intends to design aircraft seats that not only optimise passenger comfort, but which also save cabin space. The aim of this investigation was two-fold. The first aim was to determine how aircraft backrest angle affected passenger comfort, ease of seat access, perceived restriction and legroom, with different seat pan angles and seat heights. The second aim was to determine whether passenger comfort was affected with the most preferred backrest angle for each seat <b>pan</b> <b>angle</b> and seat height. Determining how seat <b>pan</b> <b>angle</b> and seat height affect the preferred angle of the backrest was considered important as Denel intend to use aircraft seats with a non-adjustable backrest angle. For this study, 80 participants were recruited from Rhodes University and the general Grahamstown population. The participants consisted of 40 males and 40 females and were not limited by race, ethnicity or culture. The participants were classified into two age groups; 18 - 30 years of age and 31 - 60 years of age. Participant stature, body mass, BMI and lower leg length was recorded to determine the effect these factors had on sitting comfort when the participants were seated in different seating conditions. From the results obtained, it was found that, by altering seat height, seat <b>pan</b> <b>angle,</b> and backrest angle, passenger comfort can be optimised. Furthermore, it was found that certain combinations of seat height, seat <b>pan</b> <b>angle</b> and backrest angle are more beneficial with regards to saving {{aircraft cabin}} space. However, this means that a compromise needs to be found for SARA as passenger comfort needs to be optimised, whilst decreasing the use of cabin space to reduce costs...|$|E
40|$|Real-time {{efficient}} {{video analytics}} (VA) for surveillance system requires 'in-camera' or 'at camera edge' decision-making. Video Analytics {{is required to}} work on good resolution footage in order to register tiny but important information that may otherwise be lost during subsequent compression process, especially in temporally exploited streams. This paper presents a novel approach to estimate 3 D location coordinates of selected control points from panning camera footage. The two frames at different <b>panning</b> <b>angles</b> {{are considered to be}} two images captured from two different coplanar viewpoints with some translational distance between their optical centers. To simulate panned images as coplanar the information required is the <b>panning</b> <b>angle.</b> With the help of the <b>panning</b> <b>angle</b> transformational matrix two image planes are calculated. The approach developed here will help extract motion descriptors, including and not limited to, motion activity and direction of motion activity. The performance of the algorithm is evaluated in the paper using several test sequences. This paper provides a comprehensive implementation issues onto TI DaVinci platform...|$|R
40|$|Listening {{tests were}} {{conducted}} to examine the influence of source spectrum and loudspeaker azimuth on the accuracy of vertical amplitude panning. Subjects judged the perceived elevation of the phantom images created using vertical loudspeaker pairs placed at 0 °and 30 ° azimuths. Six sound sources with different spectral characteristics were used: broadband, low-passed and high-passed pink noises as well as speech, bird and tank shot recordings. Results generally indicated that the localization accuracy was poor, however, lower or upper response biases observed in the results {{were found to be}} significantly dependent on the target <b>panning</b> <b>angle,</b> the stimuli and the loudspeaker azimuth angle. In particular, the low-passed noise presented from the loudspeakers at 30 ° azimuth was perceived to be significantly elevated...|$|R
40|$|Abstract — Expression {{recognition}} from non-frontal faces is a challenging research area with growing interest. In this paper, we explore discriminative learning of Gaussian Mixture Models for multi-view facial expression recognition. Adopting the BoW model from image categorization, our image descriptors are computed using Soft Vector Quantization {{based on the}} Gaussian Mixture Model. We do extensive experiments on recognizing six universal facial expressions from face images {{with a range of}} seven <b>pan</b> <b>angles</b> (− 45 ◦ ∼ + 45 ◦) and five tilt angles (− 30 ◦ ∼ + 30 ◦) generated from the BU- 3 dFE facial expression database. Our results show that our approach not only significantly improves the resulting classification rate over unsupervised training but also outperforms the published state-of-the-art results, when combined with Spatial Pyramid Matching. I...|$|R
40|$|A {{prototype}} twin-camera {{stereo vision}} system for autonomous robots {{has been developed}} at Goddard Space Flight Center. Standard charge coupled device (CCD) imagers are interfaced with commercial frame buffers and direct memory access to a computer. The overlapping portions of the images are analyzed using photogrammetric techniques to obtain information about the position and orientation of objects in the scene. The camera head consists of two 510 x 492 x 8 -bit CCD cameras mounted on individually adjustable mounts. The 16 mm efl lenses are designed for minimum geometric distortion. The cameras can be rotated in the pitch, roll, and yaw (<b>pan</b> <b>angle)</b> directions {{with respect to their}} optical axes. Calibration routines have been developed which automatically determine the lens focal lengths and <b>pan</b> <b>angle</b> between the two cameras. The calibration utilizes observations of a calibration structure with known geometry. Test results show the precision attainable is plus or minus 0. 8 mm in range at 2 m distance using a camera separation of 171 mm. To demonstrate a task needed on Space Station Freedom, a target structure with a movable I beam was built. The camera head can autonomously direct actuators to dock the I-beam to another one so that they could be bolted together...|$|E
40|$|We {{present a}} method for head pose {{estimation}} for moving targets in multi-camera environments. Our approach utilizes an ensemble of exemplar classifiers for joint head detection and pose estimation and provides finer-grained predictions than previous approaches. We incorporate dynamic cam-era selection, which allows a variable number of cameras to be selected at each time step and provides a tunable trade-off between accuracy and speed. On a benchmark dataset for multi-camera head pose estimation, our method predicts head <b>pan</b> <b>angle</b> with a mean absolute error of ∼ 8 ◦ for dif-ferent moving targets. CCS Concepts •Computing methodologies→Computer vision tasks...|$|E
40|$|When {{a camera}} {{installed}} on a vehicle is used, {{estimation of the}} camera pose including tilt, roll, and <b>pan</b> <b>angle</b> {{with respect to the}} world coordinate system is important to associate camera coordinates with world coordinates. Previous approaches using huge calibration patterns have the disadvantage that the calibration patterns are costly to make and install. And, previous approaches exploiting multiple vanishing points detected in a single image are not suitable for automotive applications as a scene where multiple vanishing points can be captured by a front camera is hard to find in our daily environment. This paper proposes a camera pose estimation method. It collects multiple images of lane markings while changing the horizontal angle with respect to the markings. One vanishing point, the cross point of the left and right lane marking, is detected in each image, and vanishing line is estimated based on the detected vanishing points. Finally, camera pose is estimated from the vanishing line. The proposed method is {{based on the fact that}} planar motion does not change the vanishing line of the plane and the normal vector of the plane can be estimated by the vanishing line. Experiments with large and small tilt and roll angle show that the proposed method outputs accurate estimation results respectively. It is verified by checking the lane markings are up right in the bird’s eye view image when the <b>pan</b> <b>angle</b> is compensated. ? ??? ?????????????????(???“GPS-DR, ?????????????? ??? 20 cm ??? ??? ?? ??? ??”, ????: 10045880) ? ??? ?? ?????...|$|E
40|$|We {{present an}} {{algorithm}} {{to solve the}} sensor planning problem for a trinocular, active vision system. This algorithm uses an iterative optimization method to first solve for the translation between the three cameras and then uses this result to solve for parameters such as <b>pan,</b> tilt <b>angles</b> of the cameras and zoom setting...|$|R
40|$|This paper {{presents}} a stereo active vision system which performs tracking tasks on smoothly moving objects in complex backgrounds. Dynamic {{control of the}} vergence angle adapts the horopter geometry {{to the target position}} and allows to pick it up easily on the basis of stereoscopic disparity features. We introduce a novel vergence control strategy based on the computation of "virtual horopters" to track a target movement generating rapid changes of disparity. The control strategy is implemented on a binocular head, whose right and left <b>pan</b> <b>angles</b> are controlled independently. Experimental results of gaze holding on a smoothly moving target translating and rotating in a complex surrounding demonstrate the efficiency of the tracking system. 1 Introduction The importance of eye movement to biological visual systems is obvious. In contrast, controlled camera movement have played a small role in computer vision research, but are becoming increasingly recognized as important capabilities in [...] ...|$|R
40|$|A {{neural network}} {{is used for}} {{three-dimensional}} (3 D) reconstruction of a point {{from a pair of}} images obtained with an active stereo system. Our active stereo system describes the position of a point with eight parameters: two <b>pan</b> <b>angles,</b> two tilt angles, and two-dimensional coordinates of the projected point in each image. Three-dimensional (3 D) reconstruction consists of learning the function which maps these eight parameters to the 3 D world coordinates (xw, yw, and zw). This paper outlines two possible networks for learning the mapping function. One contains simple Gaussian neurons in the hidden layer. The other is composed of neurons based on a model of the neurons in the parietal cortex of the human brain thought to be involved in 3 D reconstruction from visual data. The paper compares the performance of each network. We evaluate the size of training set required and the effect of the selection method used to obtain the training examples...|$|R
40|$|Abstract: When {{a camera}} {{installed}} on a vehicle is used, {{estimation of the}} camera pose including tilt, roll, and <b>pan</b> <b>angle</b> {{with respect to the}} world coordinate system is important to associate camera coordinates with world coordinates. Previous approaches using huge calibration patterns have the disadvantage that the calibration patterns are costly to make and install. And, previous approaches exploiting multiple vanishing points detected in a single image are not suitable for automotive applications as a scene where multiple vanishing points can be captured by a front camera is hard to find in our daily environment. This paper proposes a camera pose estimation method. It collects multiple images of lane markings while changing the horizontal angle with respect to the markings. One vanishing point, the cross point of the left and right lane marking, is detected in each image, and vanishing line is estimated based on the detected vanishing points. Finally, camera pose is estimated from the vanishing line. The proposed method is {{based on the fact that}} planar motion does not change the vanishing line of the plane and the normal vector of the plane can be estimated by the vanishing line. Experiments with large and small tilt and roll angle show that the proposed method outputs accurate estimation results respectively. It is verified by checking the lane markings are up right in the bird’s eye view image when the <b>pan</b> <b>angle</b> is compensated...|$|E
40|$|AbstractIn this paper, {{we present}} a novel {{algorithm}} to calibrate cameras for lane departure warning system(LDWS). The algorithm only need a set of parallel lane markings and parallel lines perpendicular to the ground plane to determine the camera parameters such as the roll angle, the tilt angle, the <b>pan</b> <b>angle</b> and the focal length. Then with the camera height, the positions of objects in world space can be easily obtained from the image. We apply the proposed method to our lane departure warning system which monitors {{the distance between the}} car and road boundaries. Experiments show that the proposed method is easy to operate, and can achieve accurate results...|$|E
40|$|In this paper, {{a remote}} O 2 ion source {{is used for}} the {{formation}} of nano-oxide layers. The oxidation efficiency was measured in CoFe-oxide films, and a decrease of the oxide layer with the <b>pan</b> <b>angle</b> and the oxidation pressure is observed. For the same oxidation pressure, the oxidation efficiency depends on the O 2 content in the Ar-O 2 plasma. These results were applied in optimizing the fabrication of Al 2 O 3 barrier for tunnel junctions. This method was also used to fabricate junctions with Fe-oxide layers inserted at the Al 2 O 3 -CoFe interface. TEM and magnetization data indicate that after anneal at 385 °C, a homogeneous ferromagnetic Fe-oxide layer (Fe 3 O 4 ?) is formed...|$|E
40|$|It {{is widely}} {{known that the}} {{vertical}} localisation of a real source relies on spectral cues. In order to examine the influence of source spectrum on the accuracy of vertical amplitude panning, the present study conducted subjective localisation tests using six sound sources with different spectral characteristics: broadband, low-passed and high-passed pink noises as well as speech, bird and tank shot recordings. Results generally indicated that the localisation accuracy of vertical amplitude panning was poor regardless of the source type. However, lower or upper response biases observed in the results {{were found to be}} significantly dependent on the target <b>panning</b> <b>angle</b> and the type of sound source. The bird and tank shot sources tended to have upper biases regardless of the target angle. The so-called ‘pitch-height’ effect was observed for low-passed and high-passed noise sources, but this was not consistent with the target angle. Overall, the results suggest that the localisation of elevated phantom source is significantly frequency-dependant...|$|R
40|$|In this paper, a novel {{algorithm}} {{for creating}} virtual indoor environments is described. First, a panoramic mosaic is generated {{from a series}} of photos taken with a camera rotates along a horizontal axis. Then, from the panoramic mosaic image, a non-fixed viewing point virtual walkthrough system can be created by defining manually the corners in the vertical panoramic mosaic. The side ratio of the virtual walkthrough system can be obtained from the <b>panning</b> <b>angle</b> subsequently. By applying the cylindrical projection technique, the texture for the sides of the virtual walkthrough environment can be projected in a more realistic way. Real images have been used to verify our proposed algorithm with satisfactory results. 1. Introduction In recent years, image-based rendering is commonly used by most computer graphic applications to construct virtual walkthrough environments. A collection of images is used to synthesize the scenes instead of building a complete 3 D model of the objects. There [...] ...|$|R
30|$|The {{experiment}} used five channels (C 1, C 2, C 3, C 4, C 5) in spherical 22.2 multichannel configuration {{as shown}} in Figure  4. Considering that PCA is the best decorrelation transform theoretically and Independent channel coding is widely used for 22.2 multichannel compression, the experiment compared the proposed 3 D-M/S method with PCA and Independent channel coding in bitrate, complexity and objective quality. Three MPEG test sequences (es 01 voice signal, sc 03 symphony music signal, si 02 castanets transient signal, mono 48 -kHz sampling) were used as the moving virtual sources following the VBAP rule, four sequences (si 03, si 01, sc 01, es 02) were used as the discrete fixed-position virtual sources. The virtual sources and respective azimuth and altitude <b>panning</b> <b>angle</b> are generated on a per-frame basis. Here, only point virtual sources were {{used to test the}} best performance of three methods, as subband signals can be regarded as point sources in subband coding when bandwidths are small enough. Signals with decorrelated elements are beyond the scope of VBAP model and will decrease the coding performance, for its difference signals retains high energy which depends on the correlation and the energy of the decorrelated elements. Uncorrelated signals with independent audio content is tested in the end.|$|R
40|$|Abstract — In {{this paper}} we {{consider}} the problem of planning optimal paths for a differential drive robot with limited sensing, that must maintain visibility of a fixed landmark as it navigates in its environment. In particular, {{we assume that the}} robot’s vision sensor has a limited field of view, and that the fixed landmark must remain within the field of view throughout the robot’s motion. We first investigate the nature of extremal paths that satisfy the field-of-view constraint. These extremal paths saturate the camera <b>pan</b> <b>angle.</b> We then show that optimal paths are composed of straight-line segments and sections of these these extremal paths. We provide the complete characterization of the shortest paths for the system by partitioning the plane into a set of disjoint regions, such that the structure of the optimal path is invariant over the individual regions. I...|$|E
40|$|Abstract. This paper {{presents}} {{a novel approach}} {{to the problem of}} determining head pose estimation and face 3 D orientation of several people in low resolution sequences from multiple calibrated cameras. Spatial redundancy is exploited and the head in the scene is approximated by an ellipsoid. Skin patches from each detected head are located in each camera view. Data fusion is performed by back-projecting skin patches from single images onto the estimated 3 D head model, thus providing a synthetic reconstruction of the head appearance. A particle filter is employed to perform the estimation of the head <b>pan</b> <b>angle</b> of the person under study. A likelihood function based on the face appearance is introduced. Experimental results proving the effectiveness of the proposed algorithm are provided for the SmartRoom scenario of the CLEAR Evaluation 2007 Head Orientation dataset. ...|$|E
40|$|Three-dimensional {{computer}} vision techniques have been actively studied {{for the purpose}} of visual traffic surveillance. To determine the 3 -D environment, camera calibration is a crucial step to resolve the relationship between the 3 -D world coordinates and their corresponding image coordinates. A novel camera calibration using the geometry properties of road lane markings is proposed. A set of equations that computes the camera parameters from the image coordinates of the road lane markings and lane width is derived. The camera parameters include <b>pan</b> <b>angle,</b> tilt angle, swing angle, focal length, and camera distance. Our results show that the proposed method outperforms the others in terms of accuracy and noise sensitivity. The proposed method accurately determines camera parameters using the appropriate camera model and it is insensitive to perturbation of noise on the calibration pattern. published_or_final_versio...|$|E
40|$|Abstract—This paper {{considers}} {{the use of}} servo-mechanisms {{as part of a}} tightly integrated homogeneous Wireless Multimedia Sensor Network (WMSN). We describe the design of our second generation WMSN node platform, which has increased image resolution, in-built audio sensors, PIR sensors, and servomechanisms. These devices have a wide disparity in their energy consumption and in the information quality they return. As a result, we propose a framework that establishes a hierarchy of devices (sensors and actuators) within the node and uses frequent sampling of cheaper devices to trigger the activation of more energy-hungry devices. Within this framework, we consider the suitability of servos for WMSNs by examining the functional characteristics and by measuring the energy consumption of 2 analog and 2 digital servos, in order to determine their impact on overall node energy cost. We also implement a simple version of our hierarchical sampling framework to evaluate the energy consumption of servos relative to other node components. The evaluation results show that: (1) the energy consumption of servos is small relative to audio/image signal processing energy cost in WMSN nodes; (2) analog servos can have higher energy consumption than digital servos due to their pulsed mechanism; and (3) for digital servos the energy cost per degree panning is lower for larger <b>panning</b> <b>angles.</b> I...|$|R
40|$|In this paper, an {{approach}} for object tracking that is inspired from human oculomotor system is proposed and verified experimentally. The developed approach {{divided into two}} phases, fast tracking or saccadic phase and smooth pursuit phase. In the first phase, the field of the view is segmented into four regions that are analogue to retinal periphery in the oculomotor system. When the object of interest is entering these regions, the developed vision system responds by changing {{the values of the}} <b>pan</b> and tilt <b>angles</b> to allow the object lies in the fovea area and then the second phase will activate. A fuzzy logic method is implemented in the saccadic phase as an intelligent decision maker to select the values of the <b>pan</b> and tilt <b>angle</b> based on suggested logical rules. In smooth pursuit phase, the object is kept in the center area of the field of the view by smooth adjusting the values of the <b>pan</b> and tilt <b>angles</b> where this stage is analogue to putting the observing object in the fovea centralis of the oculomotor system. The proposed approach was implemented by using (Camera-Pan / Tilt) configuration and showed good results to improve the vision capability of the humanoid robots...|$|R
40|$|This paper {{considers}} {{the use of}} servo-mechanisms {{as part of a}} tightly integrated homogeneous Wireless Multi- media Sensor Network (WMSN). We describe the design of our second generation WMSN node platform, which has increased image resolution, in-built audio sensors, PIR sensors, and servo- mechanisms. These devices have a wide disparity in their energy consumption and in the information quality they return. As a result, we propose a framework that establishes a hierarchy of devices (sensors and actuators) within the node and uses frequent sampling of cheaper devices to trigger the activation of more energy-hungry devices. Within this framework, we consider the suitability of servos for WMSNs by examining the functional characteristics and by measuring the energy consumption of 2 analog and 2 digital servos, in order to determine their impact on overall node energy cost. We also implement a simple version of our hierarchical sampling framework to evaluate the energy consumption of servos relative to other node components. The evaluation results show that: (1) the energy consumption of servos is small relative to audio/image signal processing energy cost in WMSN nodes; (2) digital servos do not necessarily consume as much energy as is currently believed; and (3) the energy cost per degree panning is lower for larger <b>panning</b> <b>angles...</b>|$|R
40|$|Abstract. This paper {{presents}} {{a novel approach}} {{to the problem of}} determining head pose estimation and face 3 D orientation of several people in low resolution sequences from multiple calibrated cameras. Spatial redundancy is exploited and the head in the scene is approximated by an ellipsoid. Skin patches from each detected head are located in each camera view. Data fusion is performed by back-projecting skin patches from single images onto the estimated 3 D head model, thus providing a synthetic reconstruction of the head appearance. A particle filter is employed to perform the estimation of the head <b>pan</b> <b>angle</b> of the person under study. A likelihood function based on the face appearance is introduced. Experimental results proving the effectiveness of the proposed algorithm are provided for the SmartRoom scenario of the CLEAR Evaluation 2007 Head Orientation dataset. 1 Video Head Pose Estimation This section {{presents a}} new approach to multi-camera head pose estimation from low-resolution images based on Particle Filtering (PF) [1]. A spatial and color analysis of these input images is performed and redundancy among cameras is exploited to produce a synthetic reconstruction of the head of the person. This informationis used to construct the likelihood function that will weight the particles of this PF based on visual information. The estimation of the head orientation will be computed as the expectation of the <b>pan</b> <b>angle</b> thus producing a real valued output. For a given frame in the video sequence, a set of N images are obtained from the N cameras. Each camera is modeled using a pinhole camera model based on perspective projection. Accurate calibration information is available. Bounding boxes describing the head of a person in multiple views are used to segment the interest area where the colour module will be applied. Center and size of the bounding box allow defining an ellipsoid model H = {c,R,s} where c is the center, R the rotation along each axis centered on c and s the length of each axis. Colour information is processed as described in the following subsection...|$|E
40|$|International audienceWe {{present and}} {{validate}} {{a framework for}} vi- sual navigation with obstacle avoidance. The approach was originally designed in 1, but major improvements and real outdoor experiments are added here. Visual navigation consists of following a path, represented as an ordered set of key images, that have been acquired in a preliminary teaching phase. While following such path, the robot is able to avoid new obstacles which were not present during teaching, and which are sensed by a range scanner. We guarantee that collision avoidance and navigation are achieved simultaneously by actuating th camera <b>pan</b> <b>angle,</b> {{in the presence of}} obstacles, to maintai scene visibility as the robot circumnavigates the obstacle. Th circumnavigation verse and the collision risk are estimated using a potential vector field derived from an occupancy grid. The framework can also deal with unavoidable obstacles, which make the robot decelerate and eventually stop...|$|E
40|$|In this paper, {{we propose}} and {{validate}} {{a framework for}} visual navigation with collision avoidance for a wheeled mobile robot. Visual navigation consists of following a path, represented as an ordered set of key images, which have been acquired by an on-board camera in a teaching phase. While following such path, the robot is able to avoid obstacles which were not present during teaching, and which are sensed by an on-board range scanner. Our control scheme guarantees that obstacle avoidance and navigation are achieved simultaneously. In fact, {{in the presence of}} obstacles, the camera <b>pan</b> <b>angle</b> is actuated to maintain scene visibility while the robot circumnavigates the obstacle. The risk of collision and the eventual avoiding behaviour are determined using a tentacle-based approach. The framework can also deal with unavoidable obstacles, which make the robot decelerate and eventually stop. Simulated and real experiments show tha...|$|E
40|$|Automatic facial {{expression}} recognition from non-frontal views is a challenging research topic which has recently started {{to attract the}} attention of the research community. In this paper, we propose a novel approach to tackling this problem based on the ergodic hidden Markov model (EHMM) supervector representation of facial images. First, the scale-invariant feature transform (SIFT) feature vectors are extracted from a dense grid of every facial images. Next, an EHMM is trained over all facial images in the training set and is referred to as the universal background model (UBM). The UBM is then maximum a posteriori adapted to each facial image in the training and test sets to produce the image-specific EHMMs. Based on these EHMMs, we derive a supervector representation of the facial images by means of an upper bound approximation of the Kullback-Leibler divergence rate between two EHMMs. Finally, {{facial expression}} recognition is performed in the linear discriminant subspace of the EHMM supervectors using the k-nearest-neighbor classification algorithm. Our experiments of recognizing six universal facial expressions over extensive multiview facial images with seven <b>pan</b> <b>angles</b> (− 45 o ∼ + 45 o) and five tilt angles (− 30 o ∼ + 30 o), which are synthesized from the BU- 3 DFE facial expression database, show promising results compared to the state of the arts recently reported...|$|R
40|$|Abstract. This paper {{addresses}} {{the problem of}} estimating head pose {{over a wide range}} of angles from low-resolution images. Faces are detected using chrominance-based features. Grey-level normalized face imagettes serve as input for linear auto-associative memory. One memory is computed for each pose using a Widrow-Hoff learning rule. Head pose is classified with a winner-takes-all process. We compare results from our method with abilities of human subjects to estimate head pose from the same data set. Our method achieves similar results in estimating orientation in tilt (head nodding) angle, and higher precision for estimating orientation in the <b>pan</b> (side-to-side) <b>angle.</b> 1...|$|R
3000|$|... = 2.0 ms, respectively; the {{tracking}} time τ _t included a delay time of τ _r= 0.5 ms. The desired {{trajectory of the}} <b>pan</b> and tilt <b>angles</b> of the mirror-drive 2 -DOF active vision system was generated as two 16 -bit digital sequences at 200 kHz for a duration of τ _t + τ _b [...]...|$|R
40|$|International audienceIn this paper, {{we propose}} and {{validate}} {{a framework for}} visual navigation with collision avoidance for a wheeled mobile robot. Visual navigation consists of following a path, represented as an ordered set of key images, which have been acquired by an on-board camera in a teaching phase. While following such path, the robot is able to avoid obstacles which were not present during teaching, and which are sensed by an on-board range scanner. Our control scheme guarantees that obstacle avoidance and navigation are achieved simultaneously. In fact, {{in the presence of}} obstacles, the camera <b>pan</b> <b>angle</b> is actuated to maintain scene visibility while the robot circumnavigates the obstacle. The risk of collision and the eventual avoiding behaviour are determined using a tentacle-based approach. The framework can also deal with unavoidable obstacles, which make the robot decelerate and eventually stop. Simulated and real experiments show that with our method, the vehicle can navigate along a visual path while avoiding collisions...|$|E
40|$|Abstract. Subspace {{analysis}} {{has been widely}} used for head pose estimation. However, such techniques are usually sensitive to data alignment and background noise. In this paper a two-stage approach is proposed {{to address this issue}} by combining the subspace analysis together with the topography method. The first stage is based on the subspace analysis of Gabor wavelets responses. Different subspace techniques were compared for better exploring the underlying data structure. Nearest prototype matching using Euclidean distance was used to get the pose estimate. The single pose estimated was relaxed to a subset of poses around it to incorporate certain tolerance to data alignment and background noise. In the second stage, the uncertainty is eliminated by analyzing finer geometrical structure details captured by bunch graphs. This coarse-tofine framework was evaluated with a large data set. We examined 86 poses, with the <b>pan</b> <b>angle</b> spanning from − 90 o to 90 o and the tilt angle spanning from − 60 o to 45 o. The experimental results indicate that the integrated approach has a remarkably better performance than using subspace analysis alone. ...|$|E
40|$|Abstract- This paper {{presents}} a neurologically inspired vergence control model {{that uses the}} optimization of the disparity error between interlaced cortical maps incident on the visual cortex (VC). This {{was inspired by the}} work of Hubel et al [4] where their investigations led to the discovery of the alternating organization of ocular dominance columns. While the implemented system consists of many modules including a simple component to function as the superior colliculus (SC) and modeling of attention traces from the Frontal Eye Fields (FEF) [5], this paper emphasizes the parts specific to using the log-polar maps on the visual cortex for vergence control. We explain how the log-polar image incident on the VC can be used successfully to determine the <b>pan</b> <b>angle</b> (saccade) to perform binocular vergence on points of in the scene. A discussion {{at the end of the}} paper highlights the significant differences between this system and the conventional object correspondence systems that require matching of specific object shapes. In this model, the cortically magnified VC image is used to match the entire image...|$|E
40|$|A paper {{describes}} a method devised {{to increase the}} robustness and accuracy of tracking of targets by means of three stereoscopic pairs of video cameras on a Mars-rover-type exploratory robotic vehicle. Two of the camera pairs are mounted on a mast that can be adjusted in pan and tilt; the third camera pair is mounted on the main vehicle body. Elements of the method include a mast calibration, a camera-pointing algorithm, and a purely geometric technique for handing off tracking between different camera pairs at critical distances as the rover approaches a target of interest. The mast calibration {{is an extension of}} camera calibration in which the camera images of calibration targets at known positions are collected at various <b>pan</b> and tilt <b>angles.</b> In the camerapointing algorithm, <b>pan</b> and tilt <b>angles</b> are computed by a closed-form, non-iterative solution of inverse kinematics of the mast combined with mathematical models of the cameras. The purely geometric camera-handoff technique involves the use of stereoscopic views of a target of interest in conjunction with the mast calibration...|$|R
3000|$|... = 6.5 ms; 1310 16 -bit {{data for}} each angle were updated with an 8 -ms cycle time. The home {{positions}} of the <b>pan</b> and tilt <b>angles</b> of the mirror-drive 2 -DOF active vision system were set to one end of their movable range such that θ_ 0 = 0, where their drive voltages were 0  V. Because of the narrow movable ranges of the <b>pan</b> and tilt <b>angles</b> of the 2 -DOF active vision system, 0.17 ^∘ and 0.14 ^∘, respectively, the maximum speed of objects under observation without motion blur being incurred was determined theoretically by {{the ratio of the}} movable range of the duration time of the open exposure. Considering that the variations in the view angles via the mirrors correspond to twice those of the mirror angles, the maximum angular speeds for the <b>pan</b> and tilt <b>angles</b> are 67.1 ^∘/s and 49.7 ^∘/s, respectively. When the focal length of the zoom lens and the pixel pitch of the image sensor are f [mm] and Δ x = 0.01  mm, respectively, one pixel corresponds to 57.3 tan ^- 1 (Δ x/f) ≈ 0.573 f^- 1 ^∘, assuming f ≫Δ x; 1 ^∘ corresponds to 1.75 f pixel. When f= 112.5  mm, the maximum apparent speeds in the x and y directions on the image sensor for objects under observation without motion blur being incurred are 13.0 and 9.7 pixel/ms, respectively, corresponding to the displacements of 52.2 and 38.6 pixels in the x and y directions during an exposure time of 4  ms. When f= 650  mm, the maximum apparent speeds in the x and y directions on the image sensor for objects under observation without motion blur being incurred are 76.1 and 56.4 pixel/ms, respectively, corresponding to the displacements of 304 pixels and 225 pixels in the x and y directions during an exposure time of 4  ms.|$|R
40|$|This {{dissertation}} {{presents the}} calibration-free image sensor modelling process applicable for localisation, such {{that these are}} robust to changes in environment and in sensor properties. The modelling process consists of two distinct parts, which are deterministic and stochastic techniques, and is achieved using mechanistic deconvolution, where the sensors mechanical and electrical properties are utilised. 	In the deterministic technique, the sensors effective focal length is first estimated by known lens properties, and is used to approximate the lens system by a thick lens and its properties. The aperture stop position offsetwhich {{is one of the}} thick lens propertiesthen derives a new factor, namely calibration-free distortion effects factor, to characterise distortion effects inherent in the sensor. Using this factor and the given <b>pan</b> and tilt <b>angles</b> of an arbitrary plane of view, the corrected image data is generated. The corrected data complies with the image sensor constraints modified by the <b>pan</b> and tilt <b>angles.</b> In the stochastic technique, the stochastic focal length and distortion effects factor are first approximated, using tolerances of the mechanical and electrical properties. These are then utilised to develop the observation likelihood necessary in recursive Bayesian estimation. The proposed modelling process reduces dependency on image data, and, as a result, do not require experimental setup or calibration. 	An experimental setup was constructed to conduct extensive analysis on accuracy of the proposed modelling process and its robustness to changes in sensor properties and in <b>pan</b> and tilt <b>angles</b> without recalibration. This was compared with a conventional modelling process using three sensors with different specifications and achieved similar accuracy with one-seventh the number of iterations. The developed model has also shown itself to be robust and, in comparison to the conventional modelling process, reduced the errors by a factor of five. Using area coverage method and one-step lookahead as control strategies, the stochastic sensor model was applied into a recursive Bayesian estimation application and was also compared with a conventional approach. The proposed model provided better target estimation state, and also achieved higher efficiency and reliability when compared with the conventional approach...|$|R
