71|263|Public
5|$|Transmission of many Ida images {{was delayed}} {{due to a}} <b>permanent</b> <b>failure</b> in the spacecraft's high-gain antenna. The first five images were {{received}} in September 1993. These comprised a high-resolution mosaic of the asteroid at a resolution of 31–38m/pixel. The remaining images were sent in February 1994, when the spacecraft's proximity to the Earth allowed higher speed transmissions.|$|E
6000|$|The {{number of}} actual and {{possible}} sources of profit {{and methods of}} distinction is infinite. Not all the trusts in the world combined in one trust of trusts could appreciably reduce it--could condemn to <b>permanent</b> <b>failure</b> one man with the talent {{and the will to}} succeed. They can abolish that doubtful benefactor of the [...] "small dealer," [...] who lives by charging too much, and that very thickly disguised blessing the [...] "drummer," [...] whom they have to add to the price of everything they sell; but for every opportunity they close they open a new one and leave untouched a thousand actual and a million possible ones. As to their dishonest practices, these are conspicuous and striking, because [...] "lumped," [...] but no worse than the silent, steady aggregate of cheating; by which their constituent firms and individuals, formerly consumed the consumer without his special wonder.|$|E
50|$|Nonunion is <b>permanent</b> <b>failure</b> {{of healing}} {{following}} a broken bone.|$|E
40|$|Since sensor/actuator {{networks}} {{are to be}} used in error-prone environments, it is required that media access protocols for such {{networks are}} tolerant to failures. Field studies show that the probability of transient failures to occur is much higher then the probability for <b>permanent</b> <b>failures.</b> After th...|$|R
40|$|Partial Discharges are {{symptoms}} of insulation degradation that continually promotes {{the deterioration of}} the insulation condition, eventually leading to <b>permanent</b> <b>failures.</b> The PD event itself is not dangerous but it is the state of the discharge activity that can lead to unforeseen failures. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|Abstract: The CAN {{protocol}} possesses fault confinement mechanisms {{aimed at}} differentiating between short disturbances caused by electromagnetic interferences (EMI) and <b>permanent</b> <b>failures</b> due to hardware dysfunctioning. In this study, we derive a Markovian {{analysis of these}} mechanisms and identify several problems. We then propose new mechanisms {{in order to address}} them...|$|R
50|$|Components {{that are}} {{susceptible}} to temporary malfunction or <b>permanent</b> <b>failure</b> if overheated include integrated circuits such as CPUs, chipset, graphics cards, and hard disk drives.|$|E
50|$|Major {{criticism}} of the India Mark II is that its design {{makes it difficult to}} repair at the village level and hence, without government support, NGO intervention, or community savings systems in place, the pump is more susceptible to extended periods of non-function or <b>permanent</b> <b>failure.</b>|$|E
50|$|Transmission of many Ida images {{was delayed}} {{due to a}} <b>permanent</b> <b>failure</b> in the spacecraft's high-gain antenna. The first five images were {{received}} in September 1993. These comprised a high-resolution mosaic of the asteroid at a resolution of 31-38 m/pixel. The remaining images were sent in February 1994, when the spacecraft's proximity to the Earth allowed higher speed transmissions.|$|E
40|$|In this paper, we {{investigate}} how system area networks {{can deal with}} transient and <b>permanent</b> network <b>failures.</b> We design and implement a firmware–level retransmission scheme to tolerate transient failures and an on–demand network mapping scheme to deal with <b>permanent</b> <b>failures.</b> Both schemes are transparent to applications and are conceptually simple and suitable for low–level implementations, e. g. in firmware. We then examine how the retransmission scheme affects system performance and how various protocol parameters impact system behavior. We analyze and evaluate system performance by using a real implementation on a state–of–the art cluster and both micro– benchmarks and real applications from the SPLASH- 2 suite. 1...|$|R
40|$|This paper {{discusses}} {{an approach}} that uses statistical observations about the steady-state behavior of a nite state machine (FSM) in order to detect and identify <b>permanent</b> <b>failures</b> in its state transition mechanism. The intended application domain is in testing/monitoring digital dynamic systems against <b>permanent</b> <b>failures,</b> such as manufacturing defects or stack-at faults. In order to test for the correctness of the state transition function of a given FSM, we apply inputs that are chosen according to some xed probability distribution. We show that by analyzing perturbations in the steady-state probabilities of dierent states, one can detect and identify permanent changes in the state transition function. The proposed technique only requires knowledge of the input probability distribution and the steady-state reached by the FSM, and can potentially be used in testing /monitoring of distributed systems (where the exact order of inputs, states and outputs may not be known) or in systems with observability constraints in their inputs, states and/or outputs...|$|R
40|$|International audienceA core {{abstraction}} {{for many}} distributed algorithms simulates shared memory [3]; this abstraction allows to take algorithms designed for shared memory, and port them to asynchronous message-passing systems, {{even in the}} presence of failures. There has been significant work on creating such simulations, under various types of <b>permanent</b> <b>failures,</b> as well as on exploiting this abstraction in order to derive algorithms for message-passing systems (see [2]. ...|$|R
50|$|Besides the {{intermediate}} reply for DATA, each server's reply {{can be either}} positive (2xx reply codes) or negative. Negative replies can be permanent (5xx codes) or transient (4xx codes). A reject is a <b>permanent</b> <b>failure</b> and the client should send a bounce message to the server it received it from. A drop is a positive response followed by message discard rather than delivery.|$|E
50|$|Opportunity {{was poised}} to enter Victoria Crater from its perch {{on the rim of}} Duck Bay on June 28, 2007, but due to {{extensive}} dust storms, it was delayed until the dust had cleared and power returned to safe levels. Two months later, Spirit and Opportunity resumed driving after hunkering down during raging dust storms that limited solar power to a level that nearly caused the <b>permanent</b> <b>failure</b> of both rovers.|$|E
50|$|The {{processes}} of an agent is specified {{as a set}} which define its functionality including asynchronous emission of a message, migration to other location. Consequently, locations are organized in a tree to represent {{the movement of the}} agent easier. With this representation, a benefit of this solution is the possibility to create a simple model of failure. Usually a crash of a physical site causes the <b>permanent</b> <b>failure</b> of all its locations. But with the join-calculus a problem with a location can be detected at any other running location, allowing error recovery.|$|E
50|$|In mild cases, full {{recovery}} is expected. In severe cases, <b>permanent</b> kidney <b>failure</b> or death may result.|$|R
40|$|Distributed storage systems {{often use}} data {{replication}} to mask failures and guarantee high data availability. Node failures can be transient or permanent. While the system must generate new replicas to replace replica lost to <b>permanent</b> <b>failures,</b> it can save significant replication costs by not replicating following transient faults. Given {{the unpredictability of}} network dynamics, however, distinguishing <b>permanent</b> and transient <b>failures</b> is extremely difficult. Traditional timeout approaches are difficult to tune and can introduce unnecessary replication. 1 In this paper, we propose Protector, an algorithm that addresses this problem using network-wide statistical prediction. Our algorithm drastically improves prediction accuracy by making predictions across aggregate replica groups instead of single nodes. These {{estimates of the number}} of "live replicas " can guide efficient data replication policies. We prove that given data on node down times and the probability of <b>permanent</b> <b>failures,</b> the estimate given by our algorithm is more accurate than all alternatives. We describe two ways to obtain the failure probability function driven by models or traces. We conduct extensive simulations based both on synthetic and real traces, and show that Protector closely approximates the performance of a perfect “oracle ” failure detector, while significantly outperforming timeout-based detectors using a wide range of parameters. 1...|$|R
50|$|This {{syndrome}} {{can also}} be fatal. In some cases, it {{has been known to}} cause <b>permanent</b> renal <b>failure.</b>|$|R
50|$|BitVault faults can {{be either}} {{transient}} or permanent. A transient failure will occur when a brick is experiencing temporary failure such as a software crash forcing a reboot. A <b>permanent</b> <b>failure</b> indicates errors such as hardware failure. Whenever any fault is detected, other bricks which have {{a replica of the}} affected object update the entry of the object in the index to be partial, and thus triggering further replication. All the other bricks containing replicas collaboratively send different parts of the object data, in parallel, to a new brick which will hold the replica. This parallel replication speeds up the repair of a damaged index to get it back to the complete state.|$|E
5000|$|On a {{technical}} level, some misbehaving SMTP senders may interpret the temporary rejection as a <b>permanent</b> <b>failure.</b> Old clients conforming {{only to the}} obsolete specification (RFC 821) and ignoring its recommendations may give up on delivery after the first failed attempt: RFC 821 states that clients [...] "should" [...] retry messages rather than using the word [...] "must". RFC 2119 dictates that [...] "should" [...] means recommended and to ignore at your own risk, {{and it is a}} violation of the current SMTP standard for the client to fail to retry. The current SMTP specification (RFC 5321) clearly states that [...] "the SMTP client retains responsibility for delivery of that message" [...] (section 4.2.5) and [...] "mail that cannot be transmitted immediately MUST be queued and periodically retried by the sender." [...] (section 4.5.4.1).|$|E
5000|$|Is {{the fifth}} stage reached, the {{selection}} of a new strategy (5a) has been made by the company. Especially researcher typically concentrates on this one of the reposition process. Most of them focus on the structure {{and its impact on the}} performance of the strategy that was implemented. It is even stated by the scientist, that a commercial success is again possible after a failing of the company. But different risk-averse groups, like suppliers, customers or staff may be against a change or are sceptical about the implementation of the strategy. These circumstances could result in a blockade of the realization. Also the conclusion is conceivable, that no escape strategy is found (5b), as a result that some targets can’t be achieved. In the public sector it is difficult to find a recoverable strategy, which therefore could lead to a <b>permanent</b> <b>failure.</b> The case may also be, that though a recovery plan is technically feasible, it might not be political executable.|$|E
40|$|The Simple Object-Oriented Concurrent Programming (SCOOP) model {{proposed}} by Bertrand Meyer and illustrated through the Eiffel programming {{language is a}} simple yet powerful model for concurrent programming. In this paper, we analyze {{the applicability of the}} SCOOP model to physically distributed systems manifesting transient and <b>permanent</b> <b>failures.</b> We suggest additions to the basic SCOOP model in order to cope with such failures, coining the term Distributed Reliable Object-Oriented Programming (DROOP) ...|$|R
40|$|A self-stabilizing {{protocol}} provides {{by definition}} a tolerance to transient failures. Recently, {{a new class}} of self-stabilizing protocols appears. These protocols provides also a tolerance to a given number of <b>permanent</b> <b>failures.</b> In this article, we are interested in self-stabilizing protocols that deal with Byzantines failures. We prove that, for some problems which not allow strict stabilization (see [Nesterenko,Arora, 2002]), there exist solutions that tolerates Byzantine faults if we define a new criteria of tolerance...|$|R
40|$|Fault-tolerance is an {{important}} requirement for real-time distributed system, {{which is designed to}} provide solutions in a stringent timing constraint. This paper considers fault-tolerant scheme on heterogeneous multi-component distributed system architecture using a software technique based on Distributed Recovery Block (DRB). The experiment shows that, the proposed scheme based on DRB with Random-EDF heuristic tolerates about 10 % to 20 % number of <b>permanent</b> <b>failures</b> and an arbitrary number of timing failures. 1...|$|R
30|$|The {{fault model}} {{comprises}} transient faults that {{are unable to}} cause <b>permanent</b> <b>failure</b> of a system. Transient faults can occur {{for a number of}} reasons such as sending wrong and contradictory information, or receiving altered data during transmission. Transmitted packets may also get dropped for a variety of reasons such as link failure and channel interference.|$|E
40|$|Nodes, {{among the}} {{components}} of distributed embedded systems, exhibit the greatest <b>permanent</b> <b>failure</b> rate. Thus, providing tolerance to nodes faults is mandatory whenever high-reliability is required, being node replication the most common technique for that purpose. This paper proposes a novel technique suitable for CAN-based systems that simpli-fies existing approaches {{taking advantage of a}} star topology and the FTT protocol. 1...|$|E
40|$|Blocking coordinated {{checkpointing}} is {{a well-known}} method for achieving fault tolerance in cluster computing systems. In this work, we introduce a new approach for blocking coordinated checkpointing using two-level checkpointing. The first level of checkpointing is local checkpointing, and computing nodes save the checkpoints in local disk. If a transient failure occurs in the computing node, the process can recover from local disk. Second level of checkpointing is global checkpointing and computing nodes send their checkpoints to highly reliable global stable storage. If a <b>permanent</b> <b>failure</b> occurs in the computing node, {{it can not be}} used and the process can recover from global storage in a new computing node. Local checkpoints are taken more frequently than global checkpoints. Also, in the end of each local checkpointing interval, the system determines the expected recovery time in the case of <b>permanent</b> <b>failure</b> and adaptively takes a global checkpoint, or skips. Experimental results show that average execution time of NAS-BT application is significantly reduced by using the proposed method. Maximum reduction of execution time of this application is 38 %...|$|E
50|$|The {{multicellular}} microprocessor architecture {{makes it}} easier to perform parallel execution because the need to access intermediate memory for each operation is eliminated, thus each cell can operate independently until the result is needed. The microprocessor can operate with reduced performance if {{one or more of the}} microprocessor cells become non-functioning. The dynamic reconfiguration of the microprocessor, in case of <b>permanent</b> <b>failures</b> makes it ideal for operation under harsh conditions such as in space applications.|$|R
30|$|SN {{software}} failures: SNs {{are prone}} to random <b>permanent</b> software <b>failures</b> which can render them inactive, i.e., unable to sense or communicate.|$|R
40|$|Distributed {{redundant}} disk arrays {{can be used}} in a {{distributed computing}} system or database system to provide recovery in the presence of temporary and <b>permanent</b> <b>failures</b> of single sites. In this paper, we look at the problem of partitioning the sites into redundant arrays in such way that the communication costs for maintaining the parity information are minimized. We show that the partitioning problem is NP-complete and we propose two heuristic algorithms for finding approximate solutions...|$|R
40|$|A {{major concern}} for robotic {{guidance}} systems {{is that a}} temporary or <b>permanent</b> <b>failure</b> of a given sensor within the system will erroneously trigger a potential system failure state. This paper introduces a generalised artificial neural system which is capable of addressing such problems {{by means of the}} inclusion of a weight value able to incorporate a distinct failure value. This will serve to significantly improve the performance and reliability of the guidance syste...|$|E
40|$|University-community {{partnerships}} {{are a new}} organizational {{form that}} has emerged out of the economic crises that characterized urban landscapes in the 1990 s. Based on an 18 -month, multimethod, qualitative case study of one university-community partnership, the au-thors find that when participants have contradictory interests and work within an ambiguous organizational structure, the organization will tend toward persistent failure. This effect will be particularly problematic in organizational hybrids that feature partnerships among groups from systematically unequal social positions. Thus, {{the findings suggest that}} these or-ganizational hybrids are predisposed to nonrational tendencies and <b>permanent</b> <b>failure...</b>|$|E
40|$|Abstract:- Surge arresters protect {{substation}} equipments against switching {{and atmospheric}} surges. A defective arrester may expose the power system to failures {{that can lead}} to a complete turn off of the system, or even explode damaging other equipments or hurting people [1]. An efficient predictive maintenance helps avoiding this kind of problem with arresters, indicating the necessity for their substitution when a <b>permanent</b> <b>failure</b> is detected. This work presents a series of tests done to relate thermal images and usual failures in ZnO arresters {{and the development of a}} computational algorithm based on artificial intelligence technique to analyze arresters thermal images. ...|$|E
40|$|Real-time {{distributed}} system, {{which is}} designed to provide solutions in a stringent timing constraint requires faulttolerance. This paper presents a new fault-tolerant scheme and an adaptive FT on heterogeneous multi-component distributed system architecture based on Distributed Recovery Block (DRB). The experiment shows that, the proposed scheme based on DRB with Random-EDF heuristic acting upon periodic tasks with timing and precedence constraints can tolerates about 10 % to 20 % number of <b>permanent</b> <b>failures</b> and an arbitrary number of timing failures. ...|$|R
40|$|Abstract—In {{this paper}} we propose a {{distributed}} routing algorithm for networks-on-chip (NoCs) that can dynamically detect <b>permanent</b> <b>failures</b> in NoC links and recalculate routing paths using healthy links. What sets the proposed methodology apart from the previous works is that it provides a better tradeoff point between the improvement in fault tolerance and performance penalty due to the required redundancy and extra logic. An NoC prototype is implemented and simulated in Verilog-HDL to show the correct operation of the proposed adaptive routing. I...|$|R
40|$|Extended version {{available}} as: B. Gaujal, N. Navet, "Fault Confinement mechanisms on CAN : Analysis and Improvements", IEEE Transactions on Vehicular Technology, vol 54, n° 3, pp 1103 - 1113, May 2005. International audienceThe CAN protocol possesses fault confinement mechanisms {{aimed at}} differentiating between short disturbances caused by electromagnetic interferences (EMI) and <b>permanent</b> <b>failures</b> due to hardware dysfunctioning. In this study, we derive a Markovian {{analysis of these}} mechanisms and identify several problems. We then propose new mechanisms {{in order to address}} them...|$|R
