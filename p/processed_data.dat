1771|10000|Public
25|$|Event {{filtering}} {{is required}} to reduce this data inflow to a meaningful depiction of moving goods passing a threshold. Various concepts have been designed, mainly offered as middleware performing the filtering from noisy and redundant raw data to significant <b>processed</b> <b>data.</b>|$|E
25|$|Transcriptomics studies {{generate}} {{large amounts}} of data that has potential applications far beyond the original aims of an experiment. As such, raw or <b>processed</b> <b>data</b> may be deposited in public databases to ensure their utility for the broader scientific community. For example, as of 2016, the Gene Expression Omnibus contained millions of experiments.|$|E
25|$|The {{imaging system}} calls up the {{structure}} of polygons needed for the scene to be created from the database. This is transferred to active memory and finally, to the display system (screen, TV monitors etc.) so that the scene can be viewed. During this process, the imaging system renders polygons in correct perspective ready for transmission of the <b>processed</b> <b>data</b> to the display system. Although polygons are two-dimensional, through the system computer they are placed in a visual scene in the correct three-dimensional orientation.|$|E
30|$|Manufacturing <b>process</b> <b>data</b> {{analysis}} The reviewed platforms must {{be designed}} for manufacturing and specifically for <b>process</b> <b>data</b> analysis.|$|R
40|$|Statistics Sweden has {{continuously}} {{been working}} to improve the total quality of official statistics. One of the processes in which considerable work has been invested is in editing and imputation of statistical data. Recently a project for developing, evaluating and introducing methods for preserving <b>process</b> <b>data</b> has been established. The <b>process</b> <b>data</b> will be another dimension in the already formalized and implemented metadata system. One component will be the editing <b>process</b> <b>data.</b> This paper discusses some of the aspects of collecting, saving and using editing <b>process</b> <b>data</b> and outlines some possible approaches to the solution of this task...|$|R
30|$|We {{describe}} how the pipelines are used. A pipeline used interactively to <b>process</b> <b>data</b> submitted {{by end users}} has different requirements than a pipeline used to batch <b>process</b> <b>data</b> from a sequencing machine.|$|R
25|$|The 53d WRS {{maintains}} similarly configured {{satellite communications}} ground stations within CARCAH at the NHC and its facility at Keesler to receive and process {{data from the}} aircraft. The Keesler ground station is maintained as a backup to the primary system at NHC, which has greater data streaming capability, and would be manned by CARCAH personnel {{in the event of}} a long-term satellite communications failure at NHC. During temporary outages, 53d personnel at Keesler act as operators and relay data from the aircraft by land line to the CARCAH ground station. <b>Processed</b> <b>data</b> is transmitted to the Weather Product Management and Distribution System (WPMDS) of the Air Force Weather Agency at Offutt AFB, Nebraska, which then relays it to the NWS Telecommunication Gateway at Silver Spring, Maryland, for worldwide distribution. The Keesler site has direct communications capability with WPMDS in the event of land line/internet failure between Keesler and the NHC. The system also provides backup transmission paths to WPMDS using local NHC servers and satellite connection to Keesler in the event of internet outages, except if an outage originates at Offutt.|$|E
2500|$|Documented Documents (2010–2011) is an {{overview}} of her oeuvre, a series of 120 collage works on paper from leftovers out of her archives with text comments in her handwritings. Portrait of Ernst Gombrich – Où est l'Original, d'après MB - (2011–2012) {{is a series of}} collage paintings exploring the original and its copy, based on Gombrich's Story of Art. Torn Mirages (2012–2013) are collage works on paper consisting of torn (former) drawings with text references. Inventories, Part X of the series Encyclopaedia Arcadia is finished in 2013; 40 graphic samples of lists meet [...] torn images from Gombrich's historic art overview. Data Parade (2014-2015) is a series of 24 drawings dealing with the increased use of <b>processed</b> <b>data</b> in numbers, graphics and lists determinant in articles, views and opinions in all media. PINK recreates her life and work in Bio-Graphics (2016-2017), a series of 74 drawings in graphic text on paper.|$|E
5000|$|Graphical Visualization: Raw or <b>processed</b> <b>data</b> {{collected}} in a simulation can be graphed using tools like Gnuplot, matplotlib or XGRAPH.|$|E
40|$|Abstract. The {{effective}} {{usage of}} the automatically collected software <b>process</b> <b>data</b> may be challenging. By using general purpose query languages like SQL, retrieval of software process information introduces a cost and competence barrier, which limits the adoption of Automated In-process Software Engineering Measurement and Analysis (AISEMA) systems, since it requires a considerable effort for query writing {{as well as a}} deep understanding of <b>process</b> <b>data</b> collection and representation. In this paper, we describe the implementation of a query language, SyQL, mainly but not exclusively designed for software <b>process</b> <b>data.</b> SyQL significantly reduces the competence barrier by providing a query interface aimed to software <b>process</b> <b>data...</b>|$|R
40|$|Standard multivariate {{statistical}} {{process control}} (SPC) techniques, such as Hotelling’s T 2, cannot easily handle large-scale, complex <b>process</b> <b>data</b> and often fail to detect out-of-control anomalies for such data. We develop a computationally efficient and scalable Chi-Square (χ 2) Distance Monitoring (CSDM) procedure for monitoring large-scale, complex <b>process</b> <b>data</b> to detect out-of-control anomalies, and test {{the performance of the}} CSDM procedure using various kinds of <b>process</b> <b>data</b> involving uncorrelated, correlated, auto-correlated, normally distributed, and non-normally distributed data variables. Based on advantages and disadvantages of the CSDM procedure in comparison with Hotelling’s T 2 for various kinds of <b>process</b> <b>data,</b> we design a hybrid SPC method with the CSDM procedure for monitoring large...|$|R
30|$|The Process {{method that}} <b>process</b> <b>data.</b>|$|R
50|$|Communication usually {{involves}} {{the transfer of}} information, a generic term that embraces meaning such as knowledge, <b>processed</b> <b>data,</b> skills and technology.|$|E
5000|$|... (d) The term [...] "analysed {{information}}" [...] {{means the}} information {{resulting from the}} interpretation of <b>processed</b> <b>data,</b> inputs of data and knowledge from other sources; ...|$|E
5000|$|Several {{software}} packets {{are used}} in which the acquired (and sometimes already <b>processed)</b> <b>data</b> from images or sensors is imported. The software packets include (in alphabetical order): ...|$|E
40|$|Process {{capability}} indexes {{are widely}} used in the manufacturing industries and by supplier companies in process assessments and {{in the evaluation of}} purchasing decisions. One concern about using the process capability indexes is the assumption of the mutual independence of the <b>process</b> <b>data,</b> because, in <b>process</b> industries, <b>process</b> <b>data</b> are often autocorrelated. This paper discusses the use of the process capability indexes Cp and Cpk when the <b>process</b> <b>data</b> are autocorrelated. Interval estimation procedures for Cp and Cpk are proposed and their properties are studied. ...|$|R
5000|$|Estimating <b>process</b> <b>data</b> using {{self-organizing}} {{neural networks}} ...|$|R
40|$|There is a {{continuous}} pressure on organizations {{to improve their}} work processes. In order to improve these processes, knowledge about them is necessary. To support process improvement the organization should collect <b>process</b> <b>data,</b> transform <b>process</b> <b>data</b> into knowledge and then insert this knowledge back into the organization...|$|R
50|$|Output {{from the}} batch and speed layers {{are stored in}} the serving layer, which {{responds}} to ad-hoc queries by returning precomputed views or building views from the <b>processed</b> <b>data.</b>|$|E
5000|$|... (e) The term [...] "remote sensing activities" [...] {{means the}} {{operation}} of remote sensing space systems, primary data collection and storage stations, and activities in :processing, interpreting and disseminating the <b>processed</b> <b>data.</b>|$|E
50|$|MetaboAnalyst {{generates a}} PDF report that {{includes}} a written record of each analysis step and displays results in graphical and tabular format. Users can also download <b>processed</b> <b>data</b> files and PNG image files.|$|E
30|$|It <b>processes</b> <b>data</b> in {{secure and}} {{appropriate}} ways.|$|R
40|$|This study {{discusses}} a novel method called automatic process measurement, {{which is}} based on the idea of mining <b>process</b> <b>data</b> from workflow logs. We improve the process mining technique by using Bluetooth wireless technology to do real-time acquisition of <b>process</b> <b>data.</b> The automatic measurement system is capable of collecting <b>process</b> <b>data</b> of elderly people's daily process as well as nursing personnel's behavior in the open healthcare. Similarly, retail and logistics processes can be measured with the system. The data can be used further in process analysis and modeling...|$|R
30|$|Capability to <b>process</b> <b>data</b> for the {{determination}} on relevant information.|$|R
50|$|Raw and {{calibrated}} {{data from}} performed experiments are {{provided to the}} scientists for analyses; however the raw and calibrated data formally remain property of ESA, whilst <b>processed</b> <b>data</b> become property of the scientists.|$|E
50|$|ECOsystem in {{most cases}} is highly {{effective}} at achieving results on novel or proprietary file-types, as well as pre-compressed media such as JPEG images and MPEG4 video. Ocarina successfully <b>processed</b> <b>data</b> in over 600 file formats to-date.|$|E
50|$|Use of the SO-CPR {{data for}} {{research}} purposes is encouraged. Data are made available soon after the CPR samples are <b>processed.</b> <b>Data</b> are held at the Australian Antarctic Data Centre and at the SCAR Marine Biodiversity Information Network.|$|E
5000|$|To LIMS: quality test requests, sample lots, {{statistical}} <b>process</b> <b>data</b> ...|$|R
40|$|The concept Lean Web Automation (LWA) {{describes}} {{a new approach}} for web-based operation of automation devices in distributed systems, {{which can be used}} flexible by means of compact and low-cost software without installa-tion expense on the client side. A dynamic <b>process</b> <b>data</b> transfer in the TCP/IP network is implemented by a java-based application model. This model uses a <b>process</b> <b>data</b> proxy to create at web clients an interface to <b>process</b> <b>data</b> of a remote automation device. A first practical realiza-tion of the LWA is the software toolkit Web Access Kit for OPC, which uses OPC as the interface to the process...|$|R
5000|$|The {{software}} <b>processes</b> <b>data</b> from mass spectrometers of {{the following}} companies: ...|$|R
50|$|Event {{filtering}} {{is required}} to reduce this data inflow to a meaningful depiction of moving goods passing a threshold. Various concepts have been designed, mainly offered as middleware performing the filtering from noisy and redundant raw data to significant <b>processed</b> <b>data.</b>|$|E
50|$|The {{satellite}} {{is designed}} for multi-spectral remote sensing of the Earth's surface aimed at acquiring high-quality visible images in near real-time as well as on-line data delivery via radio link and providing {{a wide range of}} consumers with value-added <b>processed</b> <b>data.</b>|$|E
5000|$|... #Caption: Figure 1: The {{principal}} {{steps of}} a workflow for compressing genomic re-sequencing data: (1) processing of the original sequencing data (e.g., reducing the original dataset to only variations relative to a specified reference sequence; (2) Encoding the <b>processed</b> <b>data</b> into binary form; and (3) decoding the data back to text form.|$|E
30|$|This survey {{identifies}} {{and addresses}} two research questions {{with the goal}} of supporting data engineers in the development of big data analysis pipelines for manufacturing <b>process</b> <b>data.</b> The first research question addresses the requirements for big data analysis pipelines for manufacturing <b>process</b> <b>data.</b> The second research question surveys the available pipelines in academic literature.|$|R
5000|$|HDD optimization. The {{system can}} <b>process</b> <b>data</b> that doesn't fit in RAM.|$|R
5000|$|ISO/TC 154, <b>Processes,</b> <b>data</b> {{elements}} and documents in commerce, industry and administration ...|$|R
