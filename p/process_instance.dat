178|1232|Public
5000|$|Instances {{of object}} class and process class: These are two {{distinct}} kinds of classes. An instance {{of a class}} is an incarnation of a particular identifiable instance of that class, an actual object of some class of objects bearing the same classification identifier. A single actual object is an object instance, while the pattern of object, which all the instances follow, is an object class. A process class is a pattern of happening, which involves object classes that {{are members of the}} preprocess and postprocess object sets. A single actual process occurrence, which follows this pattern and involves particular object instances in its preporcess and postprocess object sets, is a <b>process</b> <b>instance.</b> Hence, a <b>process</b> <b>instance</b> is a particular occurrence of a process class to which that instance belongs. Any <b>process</b> <b>instance</b> have associated with it a distinct set of preporcess and postprocess object instance sets.|$|E
50|$|Process : A {{real world}} event or {{state of affairs}} {{involving}} one or more individuals over some (possibly instantaneous) interval of time. Typically, a process involves some sort {{of change in the}} properties of {{one or more of the}} individuals within the process. Because of the ambiguity in the term “process”, sometimes referred to as <b>process</b> <b>instance.</b>|$|E
50|$|Most rules engines {{function}} as a callable library. However, it is becoming more popular for them to run as a generic process akin to the way that RDBMSs behave. Most engines treat rules as a configuration to be loaded into their <b>process</b> <b>instance,</b> although some are actually code generators for the whole rule execution instance and others allow the user to choose.|$|E
40|$|Abstract. BPM {{techniques}} {{are becoming more}} widely used, {{and there are more}} and more business <b>process</b> models and <b>instances</b> emerging. In this demonstration, we show how to manage large scale of <b>process</b> models and <b>instances</b> with <b>Process</b> Space. Creating, importing, storing, indexing and querying of models and instances will be exhibited. Since online tools for managing massive <b>process</b> <b>instances</b> are very rare, we focus on showing our useful tool of exploring <b>process</b> <b>instances.</b> ...|$|R
5000|$|API to administrate {{and monitor}} <b>processes,</b> <b>instances</b> and {{messages}} ...|$|R
5000|$|Each {{execution}} of a process definition is called a [...] "process instance". jBPM manages the <b>process</b> <b>instances.</b> Some activities are automatic like sending an e-mail or invoking a service. Some activities act as wait states, like for example human tasks or waiting for an external service to return results. jBPM will manage and persist {{the state of the}} <b>process</b> <b>instances</b> at all times.|$|R
50|$|Protected View is {{implemented}} {{as a separate}} child <b>process</b> <b>instance</b> of Excel, PowerPoint, and Word. The main process of each app is assigned the current user's access token and hosts the Office user interface elements such as the ribbon, whereas the Protected View process consists of the document viewing area, parses and renders the document content, and operates with reduced privileges; the main process serves as a mediator for requests initiated by the separate process. In Windows Vista and later versions of Windows, Mandatory Integrity Control and User Interface Privilege Isolation further restrict the separate process. Protected View is also available in Office 2010 when installed on Windows XP, {{but it is not}} as robust due to the absence of these security features.|$|E
5000|$|One view [...] {{argues that}} since a modern {{discovery}} <b>process</b> <b>instance</b> serves a similar purpose to a mathematical proof {{it should have}} similar properties, namely it allows results to be deterministically reproduced when re-executed and that intermediate results can be viewed to aid examination and comprehension. In this case, simply modelling the provenance of data is not sufficient. One has to model the provenance of the hypotheses and results generated from analyzing the data as well so as to provide evidence that support new discoveries. Scientific workflows have thus been proposed and developed to assist scientists to track the evolution of their data, intermediate results and final results {{as a means to}} document and track the evolution of discoveries within a piece of scientific research.|$|E
5000|$|As Professor of Software Engineering, Warboys {{researches}} {{the development}} of techniques which enable the dynamic evolution (the ability to change s/w whilst it is executing) of the design of very large systems. [...] He was the founder and principal of the Informatics Process Group (IPG) in the School of Computer Science. IPG was established in 1991 to advance the application of Process Modelling {{in the context of}} the organization. Between 1997 and 2002 he led the EPSRC funded Compliant Systems Architecture (CSA) projects.Within Europe he has headed the Manchester operating system team on the ESPRIT-funded EDS project, and the IPG's involvement in the ESPRIT Basic Research Activity PROMOTER on software process modelling and technology.In 2001 he led the IPG's involvement in the Framework IV Basic Research Action PIE, <b>process</b> <b>instance</b> evolution, and later the Archware project. in which he was also joint technical coordinator.|$|E
5000|$|Explorer, a web tool {{to deploy}} process definitions, start new <b>process</b> <b>instances</b> and {{carry-out}} work on workflows ...|$|R
40|$|Abstract. The earlier {{critical}} decision can be made, {{the more}} business value can be retained or even earned. The {{goal of this}} research is to reduce a decision maker’s action distance to the observation of critical events. We report {{on the development of the}} software tool preCEP that facilitates predictive event-driven process analytics (edPA). The tool enriches business activity monitoring with prediction capabilities. It is implemented by using complex event processing technology (CEP). The prediction component is trained with event log data of completed <b>process</b> <b>instances.</b> The knowledge obtained from this training, com-bined with event data of running <b>process</b> <b>instances,</b> allows for making predic-tions at intermediate execution stages on a currently running <b>process</b> <b>instance’s</b> future behavior and on process metrics. preCEP comprises a learning compo-nent, a run-time environment as well as a modeling environment, and a visuali-zation component of the predictions...|$|R
5000|$|Support an {{identification}} mechanism for <b>process</b> <b>instances</b> {{that allows the}} definition of instance identifiers at the application message level. Instance identifiers should be defined by partners and may change.|$|R
40|$|WS-BPEL is the {{standard}} to define executable business processes in a Web service world. Numerous commercial and open source BPEL engines exist {{on the market today}} that allow the execution of process models defined in BPEL. However, these execution engines only provide access to process model and <b>process</b> <b>instance</b> data in terms of proprietary APIs. In this paper we present an approach that models BPEL process models and pro-cess instances as resources and thus provides a uniform access scheme for process model and <b>process</b> <b>instance</b> data. This is crucial because access to process model and <b>process</b> <b>instance</b> data is needed in different scenar-ios that are of key relevance in enterprises today. These scenarios include compliance checking, repair of faulted business processes as well as real-time monitoring of business processes. The lack of a uniform access scheme to process model and <b>process</b> <b>instance</b> data hampers the exchangeability of BPEL engines and therefore results in a potential vendor lock-in. 1...|$|E
40|$|Abstract—The {{business}} process must reflect {{changes in the}} environment, therefore, the adaptation of the process model or the particular <b>process</b> <b>instance</b> is essential. The state compliance criterion has been introduced to check that dynamic process change is correct and {{does not lead to}} soundness problems or run-time errors. In some cases, however, the <b>process</b> <b>instance</b> must immediately be migrated to the changed model or updated itself. Hence, the strategy of coping with the non-compliant <b>process</b> <b>instance</b> must be chosen. This paper presents the process re-execution approach which effectively implements the state compliance test. The re-execution algorithm makes it possible to defer the suitable activities and use them later, thus offering a flexible solution for treating the non-compliant process instances. Moreover, a custom strategy of treating can be used based on the full context of the activity that caused the inconsistency. In many cases, the process re-execution approach enables to treat the non-compliant <b>process</b> <b>instance</b> automatically and thus the total number of instances that are successfully migrated is increased. Keywords-flexibility; process change; process evolution; state compliance; re-execution. I...|$|E
40|$|Business process {{management}} {{has grown into}} a mature discipline supported by a large number of commercial and open source products, collectively referred to as Business Process Management (BPM) systems. BPM systems store the <b>process</b> <b>instance</b> information in a physical storage known as <b>Process</b> <b>Instance</b> Repository. In an organisation several BPMS products can co-exist and work alongside each other. Each one of these BPM tools has its own definition of process instances, creating a heterogeneous environment. This reduces interoperability between business {{process management}} systems and increases the effort involved in analysing the data. In this thesis, we propose a common model for business process instances, named Business <b>Process</b> <b>Instance</b> Model (BPIM), which provides a holistic view of business process instances generated from multiple systems. BPIM consists of visual notations and their meta data schema. It captures three dimensions of process instances: process execution paths, instance data provenance and meta data. BPIM aims to provide an abstract layer between the <b>process</b> <b>instance</b> repository and BPM engines, leading to common understanding of business process instances...|$|E
40|$|Process-Aware Information Systems (PAISs) support executions of {{operational}} processes that involve people, resources, and software applications {{on the basis}} of process models. Process models describe vast, often infinite, amounts of <b>process</b> <b>instances,</b> i. e., workflows supported by the systems. With the increasing adoption of PAISs, large process model repositories emerged in companies and public organizations. These repositories constitute significant information resources. Accurate and efficient retrieval of process models and/or <b>process</b> <b>instances</b> from such repositories is interesting for multiple reasons, e. g., searching for similar models/instances, filtering, reuse, standardization, process compliance checking, verification of formal properties, etc. This paper proposes a technique for indexing process models that relies on their alternative representations, called untanglings. We show the use of untanglings for retrieval of process models based on <b>process</b> <b>instances</b> that they specify via a solution to the total executability problem. Experiments with industrial process models testify that the proposed retrieval approach is up to three orders of magnitude faster than the state of the art...|$|R
40|$|Development {{processes}} are inherently difficult to manage. Tools for managing development processes {{have to cope}} with continuous process evolution. The management system AHEAD is based on long-term experience gathered in different disciplines (software, mechanical, or chemical engineering). AHEAD provides an integrated set of tools for evolving both process definitions and their instances. Furthermore, changes at the definition level may be propagated to the instance level and vice versa (round-trip process evolution). Finally, AHEAD deals with both incomplete and incorrect process knowledge by supporting untyped <b>process</b> <b>instances</b> and allowing for deviations of <b>process</b> <b>instances</b> from their definitions, respectively...|$|R
5000|$|Support the {{implicit}} creation and termination of <b>process</b> <b>instances</b> {{as the basic}} lifecycle mechanism. Advanced lifecycle operations such as [...] "suspend" [...] and [...] "resume" [...] may be added in future releases for enhanced lifecycle management.|$|R
40|$|Nowadays {{organizations}} face fast organizational {{changes and}} employee turnover, e. g user are unavailable or they change roles {{because of a}} promotion, that might compromise the execution of a business <b>process</b> <b>instance</b> and, thus, the achievement of organizational business goals. In this paper, we investigate the problem of dynamic resiliency {{to changes in the}} assignment of users to roles. The goal of dynamic resiliency is to guarantee that when the assignment of users to roles changes during the execution of a business <b>process</b> <b>instance,</b> it is possible to find a user to perform the activities whose execution is still pending. We propose an approach to verify that the execution of a business <b>process</b> <b>instance</b> can terminate when there are changes in the in the assignment of users to roles...|$|E
40|$|Predictive {{business}} process monitoring {{is a family}} of techniques to determine how running instances of a {{business process}} are likely to unfold in the future. Techniques in this space differ according to their object of prediction. Some predict {{whether or not a}} running <b>process</b> <b>instance</b> will fulfill a compliance rule, others predict whether or not a given activity will occur, while others predict the remaining execution time. These and other predictive process monitoring problems are subsumed by the problem of predicting the remaining sequence of activities of a given <b>process</b> <b>instance.</b> In this paper, we tackle this latter problem using two alternative approaches. In the first one, we statically construct a transition system from an event log of completed process instances and annotate each transition with a probability calculated using a k-nearest neighbors classifier. At runtime, we map the (incomplete) trace of a <b>process</b> <b>instance</b> to a state in the transition system. To predict the remaining activity sequence of a <b>process</b> <b>instance,</b> we calculate a highest-probability path starting from the current state. In the second approach, we treat the problem of activity sequence prediction as a structured output prediction problem and apply recurrent neural networks. The accuracy of the two proposed approaches is evaluated on real-life and synthetic datasets and compared against an existing baseline technique...|$|E
40|$|International audience— Process mining {{has been}} {{successfully}} used in automatic knowledge discovery and in providing guidance or support. The known process mining approaches rely on processes being executed {{with the help of}} information systems thus enabling the automatic capture of process traces as event logs. However, there are many other fields such as Humanities, Social Sciences and Medicine where workers follow processes and log their execution manually in textual forms instead. The problem we tackle in this paper is mining <b>process</b> <b>instance</b> models from unstructured, text-based process traces. Using natural language processing with a focus on the verb semantics, we created a novel unsupervised technique TextProcessMiner that discovers <b>process</b> <b>instance</b> models in two steps: 1. ActivityMiner mines the process activities; 2. ActivityRelationshipMiner mines the sequence, parallelism and mutual exclusion relationships between activities. We employed technical action research through which we validated and preliminarily evaluated our proposed technique in an Archaeology case. The results are very satisfactory with 88 % correctly discovered activities in the log and a <b>process</b> <b>instance</b> model that adequately reflected the original process. Moreover, the technique we created emerged as domain independent...|$|E
30|$|Furthermore, the {{original}} execution environment exposes all the events {{to all the}} subscription scopes (<b>process</b> engine, <b>process</b> <b>instances</b> or activities) through a single event channel. This will greatly impact {{the efficiency of the}} matching functions when the system scales.|$|R
40|$|Only recently, process mining {{techniques}} {{emerged that}} can be used for Operational decision Support (OS), i. e., knowledge extracted from event logs is used to handle running <b>process</b> <b>instances</b> better. In the process mining tool ProM, a generic OS service has been developed that allows ProM to dynamically interact with an external information system, receiving streams of events and returning meaningful insights on the running <b>process</b> <b>instances.</b> In this paper, we present the implementation of a novel business constraints monitoring framework on top of the ProM OS service. We discuss the foundations of the monitoring framework considering two logic-based approaches, tailored to Linear Temporal Logic on finite traces and the Event Calculus...|$|R
40|$|In {{real-world}} {{business processes}} {{it is often}} difficult to explain why some <b>process</b> <b>instances</b> take longer than usual to complete. With process mining techniques, it is possible to do an a posteriori analysis of a large number of <b>process</b> <b>instances</b> and detect the occurrence of delays, but discovering the actual cause of such delays is a different problem. For example, it may be the case that when a certain activity is performed or a certain user (or combination of users) participates in the process, the process suffers a delay. In this work, we show that it is possible to retrieve possible causes of delay based on the information recorded in an event log. The approach consists in translating the event log into a logical representation, and then applying decision tree induction to classify <b>process</b> <b>instances</b> according to duration. Besides splitting those instances into several subsets, each path in the tree yields a rule that explains why a given subset has an average duration that is higher or lower than other subsets of instances. The approach is applied in two case studies involving real-world event logs, where it succeeds in discovering meaningful causes of delay, some of which having been pointed out by domain experts...|$|R
30|$|The key {{characteristic}} of agile business is repeatability of <b>process</b> <b>instance</b> which could provide support to changed requirements faster and with less effort. According to this paradigm, all the Device and Process services are reusable {{as a new}} service to other process in our case.|$|E
40|$|In {{order to}} create, share and improve {{knowledge}} on business processes, humans need a common, readable and preferably visual notation. So far, {{a lot of}} effort has been put into visualisation of process definitions (e. g. the recently published Business Process Modelling Notation-BPMN). In this paper we propose to put equal stress on visualisation of process execution, thus allowing process performers to understand the process history, its current state and possible future execution. We define a <b>process</b> <b>instance</b> notation as an extension of BPMN. The underlying premise for this approach is the reuse of well-defined and commonly accepted concepts from the process definition level on the <b>process</b> <b>instance</b> level. The prototype implementation is being integrated within the ICONS knowledge management platform. 1...|$|E
40|$|International Conference on Research Challenges in Information Science (13 - 15 May 2015, Athens, Greece). Process mining {{has been}} {{successfully}} used in automatic knowledge discovery and in providing guidance or support. The known process mining approaches rely on processes being executed {{with the help of}} information systems thus enabling the automatic capture of process traces as event logs. However, there are many other fields such as Humanities, Social Sciences and Medicine where workers follow processes and log their execution manually in textual forms instead. The problem we tackle in this paper is mining <b>process</b> <b>instance</b> models from unstructured, text-based process traces. Using natural language processing with a focus on the verb semantics, we created a novel unsupervised technique TextProcessMiner that discovers <b>process</b> <b>instance</b> models in two steps: 1. ActivityMiner mines the process activities; 2. ActivityRelationshipMiner mines the sequence, parallelism and mutual exclusion relationships between activities. We employed technical action research through which we validated and preliminarily evaluated our proposed technique in an Archaeology case. The results are very satisfactory with 88 % correctly discovered activities in the log and a <b>process</b> <b>instance</b> model that adequately reflected the original process. Moreover, the technique we created emerged as domain independent. Peer Reviewe...|$|E
40|$|Enabling dynamic process {{changes is}} an {{essential}} re-quirement for any adaptive process management technol-ogy. Particularly, {{it should be possible}} to migrate (long-) running <b>process</b> <b>instances</b> to a new process schema ver-sion. Further, instance migration must not violate sound-ness; i. e., structural and behavorial consistency of executed process schemas need to be preserved. State compliance has been introduced as basic correctness notion to ensure that instances, whose state has progressed too far, are pro-hibited from being migrated. However, this also excludes them from future process optimizations, which is often not tolerable in practice. This paper introduces advanced mi-gration strategies for coping with non-compliant instances in the context of process change such that they can benefit from future process type changes on the one hand, but do not run into soundness problems on the other hand. Contrary to existing approaches, the strategies proposed in this paper are based on adjustments at <b>process</b> type and <b>instance</b> level. Altogether, the suggested migration strategies complement treatment of non-compliant <b>process</b> <b>instances.</b> ...|$|R
40|$|Abstract. Security {{analysis}} {{is growing in}} complexity {{with the increase in}} functionality, connectivity, and dynamics of current electronic business processes. To tackle this complexity, the application of models in pre-operational phases is becoming standard practice. Runtime models are also increasingly applied to analyze and validate the actual security status of business <b>process</b> <b>instances.</b> In this paper we present an approach to support not only model-based evaluation of the current security status of business <b>process</b> <b>instances,</b> but also to allow for decision support by analyzing close-future process states. Our approach is based on operational formal models derived from development-time process and security models. This paper exemplifies our approach utilizing real world processes from the logistics domain and demonstrates the systematic development and application of runtime models for situational security analysis...|$|R
40|$|The {{performance}} of business processes is measured and monitored {{in terms of}} Key Performance Indicators (KPIs). If the monitoring {{results show that the}} KPI targets are violated, the underlying reasons have to be identified and the process should be adapted accordingly to address the violations. In this paper we propose an integrated monitoring, prediction and adaptation approach for preventing KPI violations of business <b>process</b> <b>instances.</b> KPIs are monitored continuously while the process is executed. Additionally, based on KPI measurements of historical <b>process</b> <b>instances</b> we use decision tree learning to construct classification models which are then used to predict the KPI value of an instance while it is still running. If a KPI violation is predicted, we identify adaptation requirements and adaptation strategies in order to prevent the violation...|$|R
30|$|Process {{deviance}} {{indicates that}} a business process shows different behavior than intended. It may occur in individual tasks, sub-processes, or the entire process (scope). Process deviance may occur in one <b>process</b> <b>instance,</b> various or all process instances (frequency). Finally, it may also occur intentionally or unintentionally (intention).|$|E
40|$|Abstract. Subject-oriented {{business}} process management (S-BPM) introduces {{a new technique}} for process modeling that {{emphasizes the importance of}} the actors in {{business process}}es (subjects) and gives a balanced consideration to subjects, their actions, and goals. Because of the formal foundation and the clear declaration of subjects, S-BPM allows the distributed modeling and execution of processes, without losing the capability to verify the compatibility of processes. Executing cooperating processes in a distributed system also poses new requirements to the communication middleware, which is responsible for routing messages from one <b>process</b> <b>instance</b> to a remote peer <b>process</b> <b>instance.</b> In this paper, we describe an engine to execute S-BPM process choreographies. It is based on subject-oriented process modeling and a publish/subscribe middleware as communication basis. Our process engine also runs on mobile devices. ...|$|E
40|$|This paper {{presents}} an algorithm for mining fuzzy temporal patterns from a given <b>process</b> <b>instance.</b> The fuzzy representation of time intervals embedded between the activities {{is used for}} this purpose. Initially, the activities are portrayed with their temporal relationships through temporal graphs and then, the defined data structures are used to retrieve the data suitable for the proposed algorithm. Similar to the familiar k-itemsets and k-dim sequences, their counterparts are introduced in this work. The proposed process-instance level data structure generates an optimum number of temporal itemsets. The proposed algorithm differs from the other existing algorithms on this topic in {{the representation of the}} mined data and patterns. An example is provided to demonstrate the algorithm. temporal data mining; fuzzy temporal patterns; weighted temporal graphs; <b>process</b> <b>instance</b> data; temporal itemsets; fuzzy representation; time intervals. ...|$|E
40|$|Security {{analysis}} {{is growing in}} complexity {{with the increase in}} functionality, connectivity, and dynamics of current electronic business processes. To tackle this complexity, the application of models in pre-operational phases is becoming standard practice. Runtime models are also increasingly applied to analyze and validate the actual security status of business <b>process</b> <b>instances.</b> In this paper we present an approach to support not only model-based evaluation of the current security status of business <b>process</b> <b>instances,</b> but also to allow for decision support by analyzing close-future process states. Our approach is based on operational formal models derived from development-time process and security models. This paper exemplifies our approach utilizing real world processes from the logistics domain and demonstrates the systematic development and application of runtime models for situational security analysis...|$|R
40|$|Abstract: During {{automated}} process execution semantic activity failures may frequently occur, e. g., when {{a vehicle}} transporting a container has a breakdown. So far {{there are no}} applicable solutions to overcome such exceptional situations. Often the only possibility is to cancel and roll back respective <b>process</b> <b>instances</b> what is not always possible and more often not desired. In this paper we contribute towards the system–assisted support of finding forward recovery solutions. Our framework {{is based on the}} facility to (automatically) perform dynamic changes of single <b>process</b> <b>instances</b> {{in order to deal with}} the exceptional situation. We identify and formalize factors which influence the kind of applicable recovery solutions. Then we show how to derive possible recovery solutions and how to evaluate their quality with respect to different constraints. All statements are illustrated by well–studied cases from different domains. ...|$|R
40|$|Processes {{modeling}} and execution (with a process engine) {{are getting more}} and more incorporated in todays business environments. This movement puts a lot of stress on classical process engines which have to coordinate many <b>process</b> <b>instances</b> simultaneously. Performance degrades quickly as the number of <b>process</b> <b>instances</b> increases, and a single point of failure is introduced by using a central process execution engine. In this paper, we address these challenges by providing a non-intrusive approach to distribute a process flow and have the flow executed by multiple, smaller process engines. We pay special attention to flexibility of the eventual distributed execution, since process change is costly in a distributed environment. We demonstrate the feasibility of our approach by providing an implementation of the transformation and execution architecture, and demonstrate the lower cost of process change that is achieved when using a flexible process runtime architecture. status: publishe...|$|R
