136|10000|Public
30|$|The {{superior}} <b>performance</b> <b>of</b> <b>SVM</b> {{relative to}} other algorithms {{has also been shown}} in the previous studies [3]. This superiority can be attributed to SVM’s better capability for analyzing the non-linear behaviors of the brain.|$|E
40|$|We {{investigate}} practical {{selection of}} meta-parameters for SVM regression (that is, ε-insensitive zone and regularization parameter C). The proposed methodology advocates analytic parameter selection {{directly from the}} training data, rather than resampling approaches commonly used in SVM applications. Good generalization performance of the proposed parameter selection is demonstrated empirically using several low-dimensional and high-dimensional regression problems. Further, we point out the importance of Vapnik’s ε-insensitive loss for regression problems with finite samples. To this end, we compare generalization <b>performance</b> <b>of</b> <b>SVM</b> regression (with optimally chosen ε) with regression using ‘least-modulus ’ loss (ε = 0). These comparisons indicate superior generalization <b>performance</b> <b>of</b> <b>SVM</b> regression, for finite sample settings...|$|E
40|$|This paper {{deals with}} the {{application}} of support vector machine (SVM) for bond rating. The three commonly used methods for solving multi-class classification problems in SVM, one-against-all, one-against-one, and directed acyclic graph SVM (DAGSVM) are used. The <b>performance</b> <b>of</b> <b>SVM</b> is compared with several benchmarks. One real U. S. bond data is collected using the Fixed Investment Securities database (FISD) and the Compustat database. The experiment shows that SVM significantly outperforms the benchmarks. Among the three SVM based methods, there is the best performance in DAGSVM. Furthermore, an analysis of features shows that the generalization <b>performance</b> <b>of</b> <b>SVM</b> can be further improved by performing feature selection...|$|E
40|$|The {{generalization}} <b>performance</b> <b>of</b> the <b>SVM</b> classifier depends {{mainly on}} the VC dimension and the dimensionality of the data. By reducing the VC dimension <b>of</b> the <b>SVM</b> classifier, its generalization performance is expected to increase. In the present paper, we argue that the VC dimension <b>of</b> <b>SVM</b> classifier can be reduced by applying bootstrapping and dimensionality reduction techniques. Experimental results showed that bootstrapping the original data and bootstrapping the projected (dimensionally reduced) data improved the <b>performance</b> <b>of</b> the <b>SVM</b> classifier...|$|R
40|$|Abstract Background The {{ability to}} {{distinguish}} between genes and proteins is essential for understanding biological text. Support Vector Machines (SVMs) have been proven to be very efficient in general data mining tasks. We explore their capability for the gene versus protein name disambiguation task. Results We incorporated into the conventional SVM a weighting scheme based on distances of context words from the word to be disambiguated. This weighting scheme increased the <b>performance</b> <b>of</b> <b>SVMs</b> by five percentage points giving performance better than 85 % {{as measured by the}} area under ROC curve and outperformed the Weighted Additive Classifier, which also incorporates the weighting, and the Naive Bayes classifier. Conclusion We show that the <b>performance</b> <b>of</b> <b>SVMs</b> can be improved by the proposed weighting scheme. Furthermore, our results suggest that in this study the increase <b>of</b> the classification <b>performance</b> due to the weighting is greater than that obtained by selecting the underlying classifier or the kernel part <b>of</b> the <b>SVM.</b> </p...|$|R
40|$|Support Vector Machines (SVMs) have {{successfully}} shown efficiencies {{in many areas}} such as text categorization. Although recommendation systems share many similarities with text categorization, the <b>performance</b> <b>of</b> <b>SVMs</b> in recommendation systems is not acceptable due to the sparsity of the user-item matrix. In this paper, we propose a heuristic method to improve the predictive accuracy <b>of</b> <b>SVMs</b> by repeatedly correcting the missing values in the user-item matrix. The performance comparison to other algorithms has been conducted. The experimental {{studies show that the}} accurate rates of our heuristic method are the highest...|$|R
40|$|A {{classification}} technique using Support Vector Machine (SVM) classifier for {{detection of}} {{rolling element bearing}} fault is presented here.   The SVM was fed from features that were extracted from of vibration signals obtained from experimental setup consisting of rotating driveline that was mounted on rolling element bearings which were run in normal and with artificially faults induced conditions. The time-domain vibration signals were divided into 40 segments and simple features such as peaks in time domain and spectrum along with statistical features such as standard deviation, skewness, kurtosis etc. were extracted. Effectiveness of SVM classifier was compared {{with the performance of}} Artificial Neural Network (ANN) classifier and {{it was found that the}} <b>performance</b> <b>of</b> <b>SVM</b> classifier is superior to that of ANN. The effect of pre-processing of the vibration signal by Discreet Wavelet Transform (DWT) prior to feature extraction is also studied and it is shown that pre-processing of vibration signal with DWT enhances the effectiveness of both ANN and SVM classifiers. It has been demonstrated from experiment results that <b>performance</b> <b>of</b> <b>SVM</b> classifier is better than ANN in detection of bearing condition and pre-processing the vibration signal with DWT improves the <b>performance</b> <b>of</b> <b>SVM</b> classifier...|$|E
40|$|AbstractSupport vector machine (SVM) {{has been}} used in many fields as a new {{learning}} method developed in recent years. When dealing with time series forecasting problem one encounters time correlation prior knowledge of time series data. If prior knowledge at hand can be incorporated into Support Vector learning machines, the generalization <b>performance</b> <b>of</b> <b>SVM</b> may be improved efficiently. In order to incorporate time correlation into SVM, this paper presents time geodesic distance for structural feature of learning data, and this presented new metric can be made use of by classification methods based on distance in training of learning machine. Comparing with the traditional SVM based on air quality database, the presented approach can greatly improve the generalization <b>performance</b> <b>of</b> <b>SVM...</b>|$|E
40|$|Abstract—Support Vector Machine (SVM) is {{a recent}} class of {{statistical}} classification and regression techniques playing an increasing role in applications to detection problems in various engineering problems, notably in statistical signal processing, pattern recognition, image analysis, and communication systems. In this paper, SVM is applied to an infrared (IR) binary communication system with different types of channel models including Ricean multipath fading and partially developed scattering channel with additive white Gaussian noise (AWGN) at the receiver. The structure and <b>performance</b> <b>of</b> <b>SVM</b> {{in terms of the}} bit error rate (BER) metric is derived and simulated for these channel stochastic models and the computational complexity of the implementation, in terms of average computational time per bit, is also presented. The <b>performance</b> <b>of</b> <b>SVM</b> is then compared to classical binary signal maximum likelihood detection using a matched filter driven by On-Off keying (OOK) modulation. We found that the <b>performance</b> <b>of</b> <b>SVM</b> is superior to that of the traditional optimal detection schemes used in statistical communication, especially for very low signal-to-noise ratio (SNR) ranges. For large SNR, the performance of the SVM {{is similar to that of}} the classical detectors. The implication of these results is that SVM can prove very beneficial to IR communication systems that notoriously suffer from low SNR at the cost of increased computational complexity...|$|E
30|$|Correlation {{coefficient}} (CC) and root-mean-square error (RMSE) {{values were}} calculated {{to investigate the}} <b>performance</b> <b>of</b> GP, <b>SVM</b> and M 5 P tree modelling approaches.|$|R
40|$|Part 7 : Optimization-SVM (OPSVM) International audienceAlthough Support Vector Machines (SVMs) are {{considered}} effective supervised learning methods, their training procedure is time-consuming and has high memory requirements. Therefore, SVMs are inappropriate for large datasets. Many Data Reduction Techniques {{have been proposed}} {{in the context of}} dealing with the drawbacks of k-Nearest Neighbor classification. This paper adopts the concept of data reduction in order to cope with the high computational cost and memory requirements in the training process <b>of</b> <b>SVMs.</b> Experimental results illustrate that Data Reduction Techniques can effectively improve the <b>performance</b> <b>of</b> <b>SVMs</b> when applied as a preprocessing step on the training data...|$|R
40|$|Although Gaussian RBF kernels {{are one of}} {{the most}} often used kernels in modern machine {{learning}} methods such as support vector machines (SVMs), little is known about the structure of their reproducing kernel Hilbert spaces (RKHSs). In this work we give two distinct explicit descriptions of the RKHSs corresponding to Gaussian RBF kernels and discuss some consequences. Furthermore, we present an orthonormal system for these spaces. Finally we discuss how our results can be used for analyzing the learning <b>performance</b> <b>of</b> <b>SVMs...</b>|$|R
40|$|In this paper, support vector {{machines}} (SVM) {{are applied}} to multi-user detector (MUD) for direct sequence (DS) -CDMA system. This work shows an analytical <b>performance</b> <b>of</b> <b>SVM</b> based multi-user detector with some of kernel functions, such as linear, sigmoid, and Gaussian. The basic idea in SVM based training is to select the proper number of support vectors by maximizing the margin between two different classes. In simulation studies, the <b>performance</b> <b>of</b> <b>SVM</b> based MUD with different kernel functions is compared {{in terms of the}} number of selected support vectors, their corresponding decision boundary, and finally the bit error rate. It was found that controlling parameter, in SVM training have an effect, in some degree, to SVM based MUD with both sigmoid and Gaussian kernel. It is shown that SVM based MUD with Gaussian kernels outperforms those with other kernels...|$|E
40|$|In this paper•, a novel {{method to}} voiced/unvoiced/silence of speech {{classification}} using Support Vector Machine (SVM) is proposed. This classifier can correctly classify speech frames into voiced frame, unvoiced frame and silence frame. The comparison of experiment result {{shows that the}} proposed method outperforms other traditional methods. The <b>performance</b> <b>of</b> <b>SVM</b> for different kernel functions in the experiment was analyzed and discussed as well. 1...|$|E
40|$|Abstract — Ensemble {{learning}} is a method for improving the performance of classification and prediction algorithms. However, its performance can be degraded due to multicollinearity problem where multiple classifiers of an ensemble are highly correlated with. This paper proposes genetic algorithm-based optimization techniques of SVM ensemble to solve multicollinearity problem. Empirical results with bankruptcy prediction on Korea firms indicate that the proposed optimization techniques can improve the <b>performance</b> <b>of</b> <b>SVM</b> ensemble...|$|E
40|$|Abstract. Learning from {{imbalanced}} datasets {{is inherently}} difficult {{due to lack}} of information about the minority class. In this paper, we study the <b>performance</b> <b>of</b> <b>SVMs,</b> which have gained great success in many real applications, in the imbalanced data context. Through empirical analysis, we show that SVMs suffer from biased decision boundaries, and that their prediction performance drops dramatically when the data is highly skewed. We propose to combine an integrated sampling technique with an ensemble <b>of</b> <b>SVMs</b> to improve the prediction performance. The integrated sampling technique combines both over-sampling and under-sampling techniques. Through empirical study, we show that our method outperforms individual SVMs as well as several other state-of-the-art classifiers. ...|$|R
40|$|Nonlinear Support Vector Machines (SVMs) are {{investigated}} for visual sex classification with low resolution "thumbnail" faces (21 by - 12 pixels) processed from 1, 755 {{images from the}} FERET face database. The <b>performance</b> <b>of</b> <b>SVMs</b> is shown to be superior to traditional pattern classifiers (Linear, Quadratic, Fisher Linear Discriminant, Nearest-Neighbor) {{as well as more}} modern techniques such as Radial Basis Function (RBF) classifiers and large ensembleRBF networks. Furthermore, the SVM performance (3. 4 % error) is currently the best result reported in the open literature...|$|R
40|$|Using {{methods of}} Statistical Physics, we {{investigate}} the generalization <b>performance</b> <b>of</b> support vector machines (SVMs), {{which have been}} recently introduced as a general alternative to neural networks. For nonlinear classification rules, the generalization error saturates on a plateau, {{when the number of}} examples is too small to properly estimate the coefficients of the nonlinear part. When trained on simple rules, we find that SVMs overfit only weakly. The <b>performance</b> <b>of</b> <b>SVMs</b> is strongly enhanced, when the distribution of the inputs has a gap in feature space. Comment: REVTeX, 4 pages, 2 figures, accepted by Phys. Rev. Lett (typos corrected...|$|R
40|$|Support Vector Machine (SVM) {{is known}} in {{classification}} and regression modeling. It has been receiving attention {{in the application of}} nonlinear functions. The aim is to motivate the use of the SVM approach to analyze the time series models. This is an effort to assess the <b>performance</b> <b>of</b> <b>SVM</b> in comparison with ARMA model. The applicability of this approach for a unit root situation is also considered. Key-Words: • Support Vector Machine; time series analysis; unit root...|$|E
40|$|Abstract—Support Vector Machine (SVM) is a {{statistical}} learning tool that was initially developed by Vapnik in 1979 and later developed {{to a more}} complex concept of structural risk minimization (SRM). SVM is playing an increasing role in applications to detection problems in various engineering problems, notably in statistical signal processing, pattern recognition, image analysis, and communication systems. In this paper, SVM is applied to signal detection in communication systems {{in the presence of}} channel noise in the form of fully developed Rayleigh multipath fading and receiver noise generalized as additive color Gaussian noise (ACGN). The structure and <b>performance</b> <b>of</b> <b>SVM</b> in terms of the bit error rate (BER) metric is derived and simulated for these advanced stochastic noise models and the computational complexity of the implementation, in terms of average computational time per bit, is also presented. The <b>performance</b> <b>of</b> <b>SVM</b> is then compared to conventional M-ary signalling optimal model-based detector driven by M-ary phase shift keying (MPSK) modulation. We show that the SVM performance is superior to that of conventional detectors which require as much as 7 bits-coding (M ≥ 128) to produce comparable results to those of SVM...|$|E
40|$|Information in {{visually}} rich formats such as PDF and HTML {{is often}} conveyed {{by a combination}} of textual and visual features. In particular, genres such as marketing flyers and info-graphics often augment textual information by its color, size, positioning, etc. As a result, tradi-tional text-based approaches to informa-tion extraction (IE) could underperform. In this study, we present a supervised ma-chine learning approach to IE from on-line commercial real estate flyers. We evaluated the <b>performance</b> <b>of</b> <b>SVM</b> clas-sifiers on the task of identifying 12 type...|$|E
40|$|This paper {{describes}} a hybrid {{model and the}} corresponding algorithm combining support vector machines (SVMs) with statistical methods to improve the <b>performance</b> <b>of</b> <b>SVMs</b> for the task of Chinese Named Entity Recognition (NER). In this algorithm, a threshold of {{the distance from the}} test sample to the hyperplane <b>of</b> <b>SVMs</b> in feature space is used to separate SVMs region and statistical method region. If the distance is greater than the given threshold, the test sample is classified using SVMs; otherwise, the statistical model is used. By integrating the advantages of two methods, the hybrid model achieves 93. 18 % F-measure for Chinese person names and 91. 49 % Fmeasure for Chinese location names. ...|$|R
30|$|In the following, {{we focus}} our {{attention}} on studying the most appropriate features to propose a robust fused descriptor representing driver head pose. Moreover, we evaluate the <b>performance</b> <b>of</b> the <b>SVM</b> classifier for estimating head poses.|$|R
3000|$|... [...]) are the radial basis {{function}} and, less frequently, the polynomial kernel. The generalization <b>performance</b> <b>of</b> a <b>SVM</b> {{depends on}} parameters regulating the trade-off between {{accuracy and complexity}} in the training process [32] and the kernel-specific parameters.|$|R
40|$|Shared {{virtual memory}} (SVM) {{is a virtual}} memory layer with a single address space {{on top of a}} {{distributed}} real memory on parallel computers. We examine the behavior and <b>performance</b> <b>of</b> <b>SVM</b> running a parallel program with loop-level parallelism on top of it. A simulator for the underlying parallel architecture can be used to examine the behavior of SVM more deeply. The influence of several parameters, such as the number of processors, page size, cold or warm start, and restricted page replication, is studied...|$|E
40|$|Abstract—Support Vector Machine (SVM) is a {{statistical}} learning tool developed {{to a more}} complex concept of structural risk minimization (SRM). In this paper, SVM is applied to signal detection in communication systems {{in the presence of}} channel noise in various environments in the form of Rayleigh fading, additive white Gaussian background noise (AWGN), and interference noise generalized as additive color Gaussian noise (ACGN). The structure and <b>performance</b> <b>of</b> <b>SVM</b> in terms of the bit error rate (BER) metric is derived and simulated for these advanced stochastic noise models and the computational complexity of the implementation, in terms of average computational time per bit, is also presented. The <b>performance</b> <b>of</b> <b>SVM</b> is then compared to conventional binary signaling optimal model-based detector driven by binary phase shift keying (BPSK) modulation. We show that the SVM performance is superior to that of conventional matched filter-, innovation filter-, and Wiener filter-driven detectors, even in the presence of random Doppler carrier deviation, especially for low SNR (signal-to-noise ratio) ranges. For large SNR, the performance of the SVM was {{similar to that of the}} classical detectors. However, the convergence between SVM and maximum likelihood detection occurred at a higher SNR as the noise environment became more hostile. Keywords—Colour noise, Doppler shift, innovation filter, least square-support vector machine, matched filter, Rayleigh fading...|$|E
40|$|Evapotranspiration is a {{major factor}} that {{controls}} hydrological process and its accurate estimation provides valuable information for water resources planning and management, particularly in extremely arid regions. The objective of this research was to evaluate the use of a support vector machine (SVM) to model daily reference evapotranspiration (ET 0) using limited climatic data. For the SVM, four combinations of maximum air temperature (T-max), minimum air temperature (T-min), wind speed (U- 2) and daily solar radiation (R-s) in the extremely arid region of Ejina basin, China, were used as inputs with T(max) and T-min as the base data set. The results of SVM models were evaluated by comparing the output with the ET 0 calculated using Penman-Monteith FAO 56 equation (PMF- 56). We found that the ET 0 estimated using SVM with limited climatic data was in good agreement with those obtained using the conventional PMF- 56 equation employing the full complement of meteorological data. In particular, three climatic parameters, T-max, T-min, and R-s were enough to predict the daily ET 0 satisfactorily. Moreover, the <b>performance</b> <b>of</b> <b>SVM</b> method was also compared with that of artificial neural network (ANN) and three empirical models including Priestley-Taylor, Hargreaves, and Ritchie. The results showed that the <b>performance</b> <b>of</b> <b>SVM</b> method was the best among these models. This offers significant potential for more accurate estimation of the ET 0 with scarce data in extreme arid regions. Evapotranspiration {{is a major}} factor that controls hydrological process and its accurate estimation provides valuable information for water resources planning and management, particularly in extremely arid regions. The objective of this research was to evaluate the use of a support vector machine (SVM) to model daily reference evapotranspiration (ET 0) using limited climatic data. For the SVM, four combinations of maximum air temperature (T-max), minimum air temperature (T-min), wind speed (U- 2) and daily solar radiation (R-s) in the extremely arid region of Ejina basin, China, were used as inputs with T(max) and T-min as the base data set. The results of SVM models were evaluated by comparing the output with the ET 0 calculated using Penman-Monteith FAO 56 equation (PMF- 56). We found that the ET 0 estimated using SVM with limited climatic data was in good agreement with those obtained using the conventional PMF- 56 equation employing the full complement of meteorological data. In particular, three climatic parameters, T-max, T-min, and R-s were enough to predict the daily ET 0 satisfactorily. Moreover, the <b>performance</b> <b>of</b> <b>SVM</b> method was also compared with that of artificial neural network (ANN) and three empirical models including Priestley-Taylor, Hargreaves, and Ritchie. The results showed that the <b>performance</b> <b>of</b> <b>SVM</b> method was the best among these models. This offers significant potential for more accurate estimation of the ET 0 with scarce data in extreme arid regions...|$|E
40|$|Abstract-Support Vector Machines (SVMs) {{are a new}} clas-sification {{technique}} {{which has}} a high generalization ability, yet a heavy computational load since margin maximization results in a quadratic programming problem. It is known that this maxi-mization task results in a pth-order programming problem if we employ the p-norm instead of the Euclidean norm, that is. When p = 1, for example, it is a linear programming problem with a much lower computational load. In this article, we theoretically show that p has very little affect on the generalization <b>performance</b> <b>of</b> <b>SVMs</b> in practice by considering its geometrical meaning. I...|$|R
40|$|Abstract. Support vector {{machines}} (SVMs) are {{a promising}} type of learning machine based on structural risk minimization and statistical learning theory, {{which can be}} divided into two categories: support vector classification (SVC) machines and support vector regression machines (SVR). The basic elements and algorithms of SVC machines are discussed. As modeling and prediction methods are introduced into the experiment of microwave calcining AUC, the better prediction accuracy and the better fitting results are compare with back propagation (BP) neural network method. This is conducted to elucidate the good generalization <b>performance</b> <b>of</b> <b>SVMs,</b> especially good for dealing with the data of some nonlinearity...|$|R
40|$|In {{the last}} decade, the {{application}} of statistical and neural network classifiers to remote-sensing images has been deeply investigated. Therefore, performances, characteristics, and {{pros and cons of}} such classifiers are quite well known, even from remote-sensing practitioners. In this paper, we present the application to remote-sensing image classification of a new pattern recognition technique recently introduced {{within the framework of the}} Statistical Learning Theory developed by V. Vapnik and his co-workers, namely, the Support Vector Machines (SVMs). In section 1, the main theoretical foundations <b>of</b> <b>SVMs</b> are presented. In section 2, experiments carried out on a data set of multisensor remote-sensing images are described, with particular emphasis on the design and training phase <b>of</b> a <b>SVM.</b> In section 3, the experimental results are reported, together with a comparison between the <b>performances</b> <b>of</b> <b>SVMs,</b> neural network, and k-NN classifiers...|$|R
40|$|Abstract. Accent {{classification}} technologies directly {{influence the}} performance of speech recognition. Currently, two models are used for accent detection namely: Hidden Markov Model (HMM) and Artificial Neural Networks (ANN). However, both models have some drawbacks of their own. In this paper, we use Support Vector Machine (SVM) to detect different speakers ’ accents. To examine the <b>performance</b> <b>of</b> <b>SVM,</b> Hidden Markov Model is used to classify the same problem set. Simulation results show that SVM can effectively classify different accents. Its performance {{is found to be}} very similar to that of HMM. ...|$|E
40|$|Recent {{researches}} {{have investigated}} the impact of feature selection methods {{on the performance of}} support vector machine (SVM) and claimed that no feature selection methods improve it in high dimension. However, they have based this argument on their experiments with simulated data. We have taken this claim as a research issue and investigated different feature selection methods on the real time micro array gene expression data. Our research outcome indicates that feature selection methods do {{have a positive impact on}} the <b>performance</b> <b>of</b> <b>SVM</b> in classifying micro array gene expression data...|$|E
40|$|An {{implementation}} for {{the classification}} of remote sensing images with support vector machines (SVM) is introduced. This tool, called imageSVM, allows a user-friendly work, especially with large, highly-resolved data sets in the ENVI/IDL environment. imageSVM uses LIBSVM for the training of the SVM in combination with a user-defined grid search. Parameter settings can be set flexibly during the entire workflow and a time-efficient processing becomes possible. First tests underline the high-accuracy of SVM classification using heterogeneous hyperspectral data and the good <b>performance</b> <b>of</b> <b>SVM</b> {{in the context of}} multi-sensoral studies...|$|E
40|$|Abstract. Recently Support Vector Machines (SVMs) {{have played}} a leading role in pattern classification. SVMs are quite {{effective}} to classify static data in numerous applications. However, the use <b>of</b> <b>SVMs</b> in dynamically data driven application systems (DDDAS) is somewhat limited. This motivates the devel-opment of incremental approaches to handle DDDAS. In an incremental learn-ing approach, it is critical to keep a certain number of support vectors (SVs) without seriously sacrificing the generalization <b>performance</b> <b>of</b> <b>SVMs.</b> In this paper a novel incremental SVM method, called an incremental revised support vector machine with filters (IRSVMF) is proposed to resolve the above limita-tions. Computational experiments with tornado data show that this approach is quite effective {{to reduce the number of}} SVs and computing time and to increase the detection rate of tornados. ...|$|R
40|$|In this paper, we {{investigate}} {{the problem of}} exploiting global information to improve the <b>performance</b> <b>of</b> <b>SVMs</b> on large scale classification problems. We first present a unified general framework for the existing min-max machine methods in terms of within-class dis-persions and between-class dispersions. By defining a new within-class dispersion measure, we then propose a novel max-margin ratio machine (MMRM) method that can be formu-lated as a linear programming problem with scalability for large data sets. Kernels can be easily incorporated into our method to address non-linear classification problems. Our empirical {{results show that the}} proposed MMRM approach achieves promising results on large data sets. 1...|$|R
40|$|In {{this paper}} we propose a real time face {{recognition}} method that combines face matching and identity verification modules in a feedback loop, exploiting the temporal efficiency of matching and the <b>performances</b> <b>of</b> <b>SVM</b> classifiers. Our approach represents an ad-hoc solution for settings characterized by variable quantity, quality and distribution of labeled data among the identities. We assess the procedure on two data sets of different complexities, showing the effectiveness of our solution. For its intrinsic peculiarities and its limited computational cost the method finds application in real time systems, and will be implemented on a wearable device for supporting visually impaired people to localize known faces...|$|R
