22|13|Public
25|$|The ancient Chinese had {{advanced}} arithmetic studies {{dating from the}} Shang Dynasty and continuing through the Tang Dynasty, from basic numbers to advanced algebra. The ancient Chinese used a positional notation {{similar to that of}} the Greeks. Since they also lacked a symbol for zero, they had one set of symbols for the unit's place, and a second set for the ten's place. For the hundred's place they then reused the symbols for the unit's place, and so on. Their symbols were based on the ancient counting rods. It is a complicated question to determine exactly when the Chinese started calculating with <b>positional</b> <b>representation,</b> but it was definitely before 400BC. The ancient Chinese were the first to meaningfully discover, understand, and apply negative numbers as explained in the Nine Chapters on the Mathematical Art (Jiuzhang Suanshu), which was written by Liu Hui.|$|E
5000|$|... #Subtitle level 3: Properties of its <b>positional</b> <b>representation</b> {{in certain}} radixes ...|$|E
50|$|In mathematics, {{trailing}} zeros are {{a sequence}} of 0 in the decimal representation (or more generally, in any <b>positional</b> <b>representation)</b> of a number, after which no other digits follow.|$|E
40|$|Matching natural {{language}} sentences is central for many {{applications such as}} information retrieval and question answering. Existing deep models rely on a single sentence representation or multiple granularity representations for matching. However, such methods cannot well capture the contextualized local information in the matching process. To tackle this problem, we present a new deep architecture to match two sentences with multiple <b>positional</b> sentence <b>representations.</b> Specifically, each <b>positional</b> sentence <b>representation</b> is a sentence representation at this position, generated by a bidirectional long short term memory (Bi-LSTM). The matching score is finally produced by aggregating interactions between these different <b>positional</b> sentence <b>representations,</b> through $k$-Max pooling and a multi-layer perceptron. Our model has several advantages: (1) By using Bi-LSTM, rich context of the whole sentence is leveraged to capture the contextualized local information in each positional sentence representation; (2) By matching with multiple <b>positional</b> sentence <b>representations,</b> it is flexible to aggregate different important contextualized local information in a sentence to support the matching; (3) Experiments on different tasks such as question answering and sentence completion demonstrate the superiority of our model. Comment: Accepted by AAAI- 201...|$|R
40|$|Henson (1996) {{provided}} {{a number of}} demonstrations of error patterns in serial recall that contradict chaining models. One such error pattern concerned when participants make intrusions from prior lists: Rather than originating from random positions in the prior list, intrusions tend to be recalled {{in the same position}} as their position in the prior list, a finding which led to the endorsement of positional models of serial recall. However, all of the demonstrations of positional intrusions occurred in designs in which relatively small sets of items were repeatedly employed as stimuli. In recent years, a number of investigations have found evidence for chaining in designs in which large sets of items are employed and items are never reused across trials (open sets). We conducted 2 experiments using open sets of items to test whether a pure chaining model is a viable model for open-set conditions. Both experiments revealed that intrusions from the immediately preceding list exhibited a strong tendency to be output in the same position as their position in the prior list, suggesting the usage of <b>positional</b> <b>representations</b> in open-set designs. A chaining model that lacks <b>positional</b> <b>representations</b> provides an inadequate account of serial recall in open-set conditions...|$|R
50|$|Digits in the <b>positional</b> <b>representations</b> of real numbers such as , e, and irrational {{roots are}} {{believed}} to appear with equal frequency (see normal number). Such numbers {{can be viewed as}} the opposite extreme of Chaitin-Kolmogorov random numbers in that they appear random but have very low information entropy. Their use is motivated by early controversy over the U.S. Government's 1975 Data Encryption Standard, which came under criticism because no explanation was supplied for the constants used in its S-box (though they were later found to have been carefully selected to protect against the then-classified technique of differential cryptanalysis). Thus a need was felt for a more transparent way to generate constants used in cryptography.|$|R
50|$|Other key {{techniques}} {{in this field}} are negative sampling and word embedding. Word embedding, such as word2vec, {{can be thought of}} as a representational layer in a deep learning architecture that transforms an atomic word into a <b>positional</b> <b>representation</b> of the word relative to other words in the dataset; the position is represented as a point in a vector space. Using word embedding as an RNN input layer allows the network to parse sentences and phrases using an effective compositional vector grammar. A compositional vector grammar {{can be thought of as}} probabilistic context free grammar (PCFG) implemented by an RNN. Recursive auto-encoders built atop word embeddings can assess sentence similarity and detect paraphrasing. Deep neural architectures have achieved state-of-the-art results in natural language processing tasks such as constituency parsing, sentiment analysis, information retrieval, spoken language understanding, machine translation, contextual entity linking, writing style recognition and others.|$|E
5000|$|Greek numerals {{were used}} by Archimedes, Diophantus and others in a {{positional}} notation not very different from ours. Because the ancient Greeks lacked a symbol for zero (until the Hellenistic period), they used three separate sets of symbols. One set for the unit's place, one for the ten's place, {{and one for the}} hundred's. Then for the thousand's place they would reuse the symbols for the unit's place, and so on. Their addition algorithm was identical to ours, and their multiplication algorithm was only very slightly different. Their long division algorithm was the same, and the square root algorithm that was once taught in school was known to Archimedes, who may have invented it. He preferred it to Hero's method of successive approximation because, once computed, a digit doesn't change, and the square roots of perfect squares, such as 7485696, terminate immediately as 2736. For numbers with a fractional part, such as 546.934, they used negative powers of 60 instead of negative powers of 10 for the fractional part 0.934. The ancient Chinese used a similar positional notation. Because they also lacked a symbol for zero, they had one set of symbols for the unit's place, and a second set for the ten's place. For the hundred's place they then reused the symbols for the unit's place, and so on. Their symbols were based on the ancient counting rods. It is a complicated question to determine exactly when the Chinese started calculating with <b>positional</b> <b>representation,</b> but it was definitely before 400 BC. The Bishop of Syria, Severus Sebokht (650 AD), [...] "Indians possess a method of calculation that no word can praise enough. Their rational system of mathematics, or of their method of calculation. I mean the system using nine symbols." ...|$|E
40|$|In {{this article}} I discuss {{a case of}} primary school teacher {{education}} concerning an important piece of mathematics knowledge, that is the <b>positional</b> <b>representation</b> of numbers. Traditionally the topic is introduced by means of different artifacts (for instance abaci; base ten blocks). But {{it is well known}} that no artifact is transparent for the mathematical meaning, unless the social practices of the mathematics classroom, started by the teacher, are effective. The aim of this article is to describe and discuss a four session (16 hours) laboratory for 30 prospective primary school teachers, where the topic of the use of artifacts for <b>positional</b> <b>representation</b> of numbers in base ten is tackled, within a suitable theoretical framework. In the article the different sessions are analysed, focusing the differences between the tasks related to different components of the knowledge needed by mathematics teachers...|$|E
50|$|Bhaskara's {{probably}} most important mathematical contribution concerns {{the representation of}} numbers in a positional system. The first <b>positional</b> <b>representations</b> were known to Indian astronomers about 500 years ago. However, the numbers were not written in figures, but in words or allegories, and were organized in verses. For instance, the number 1 was given as moon, since it exists only once; the number 2 was represented by wings, twins, or eyes, since they always occur in pairs; the number 5 was given by the (5) senses. Similar to our current decimal system, these words were aligned such that each number assigns the factor {{of the power of}} ten corresponding to its position, only in reverse order: the higher powers were right from the lower ones.|$|R
40|$|Abstract. We {{consider}} digital expansions of scalars for supersingular Koblitz curves in characteristic three. These are <b>positional</b> <b>representations</b> of integers to {{the base}} of τ, where τ is a zero of the characteristic polynomial T 2 ± 3 T + 3 of a Frobenius endomorphism. They are then applied to the improvement of scalar multiplication on the Koblitz curves. A simple connection between τ-adic expansions and balanced ternary representations is given. Windowed non-adjacent representations are considered whereby the digits are elements of minimal norm. We give an explicit description of the elements of the digit set, allowing for a very simple and efficient precomputation strategy, whereby the rotational symmetry of the digit set is also used to reduce the memory requirements. With respect to {{the current state of the}} art for computing scalar multiplications on supersingular Koblitz curves we achieve the following improvements: (i) speed-ups of up to 40 %, (ii) a reduction of memory consumption by a factor of three, (iii) our methods apply to all window sizes without requiring operation sequences for the precomputation stage to be determined offline first. Additionally, we explicitly describe the action of some endomorphisms on the Koblitz curve as a scalar multiplication by an explicitly given integer. 1...|$|R
40|$|We {{discuss the}} main {{concepts}} of circuit solutions for <b>positional</b> data <b>representation</b> and propose appropriate mathematical models. The basic features of positional information model {{formation in the}} displays with different (linear and array) types of element connection are analyzed. The mathematical models of digital circuits and their realizations for positional indication on different types of LED bar graph arrays are presented. An optimized analytical model and applicable logic structure for display with series connection of LED scale elements are proposed. The minimized circuit solutions for the reliable positional display units with different electric design of information area are offered...|$|R
40|$|It {{is proven}} that, {{contrarily}} {{to the common}} belief, the notion of zero is not necessary for having positional representations of numbers. Namely, for any positive integer k, a <b>positional</b> <b>representation</b> with the symbols for 1, 2, [...] ., k is given that retains all the essential properties of the usual <b>positional</b> <b>representation</b> of base k (over symbols for 0, 1, 2 [...] ., k- 1). Moreover, in this zero-free representation, a sequence of symbols identifies the number that corresponds to the order number that the sequence has in the ordering where shorter sequences precede the longer ones, and among sequences of the same length the usual lexicographic ordering of dictionaries is considered. The main properties of this lexicographic representation are proven and conversion algorithms between lexicographic and classical positional representations are given. Zero-free positional representations are relevantt in {{the perspective of the}} history of mathematics, as well as, in the perspective of emergent computation models, and of unconventional representations of genomes. Comment: 15 page...|$|E
40|$|The {{purpose of}} this chapter is to discuss several {{critical}} issues in early mathematics education, particularly the use of manipulatives to teach <b>positional</b> <b>representation</b> of numbers. For our prehistoric ancestors, the representation of numbers larger than the ones that {{could be counted on}} their fingers and toes represented a significant challenge. This problem was solved by a brilliant insight of using position to represent and distinguish large numbers. Some tools have been extremely useful in performing math operations on large numbers. In the history, the abacus and the pascaline played a part in implementing and improving the system of <b>positional</b> <b>representation</b> of numbers. These tools can also {{play a significant role in}} helping young children understand the role of position. This chapter discusses and provides examples of how teachers can facilitate young children acquiring strategies for using these tools to represent numbers and to make arithmetical operations. A point worth noting is that the use of these tools is not intrinsically helpful in promoting children's learning. Their effectiveness depends largely on how thoughtfully and intentionally they are used, shaping classroom practices. In other words one simply cannot give children a set of blocks or any other tool and expect that learning is produced from access to those tools. Teachers must think carefully about what it is they want children to do and how they might benefit and then structure their environment and guide children so that these outcomes are likely to be achieved...|$|E
40|$|International audienceWe propose an hybrid {{representation}} of large integers, or prime field elements, combining both positional and residue number systems (RNS). Our hybrid position-residues (HPR) number system mixes a high-radix <b>positional</b> <b>representation</b> and digits represented in RNS. RNS offers {{an important source}} of parallelism for addition, subtraction and multiplication operations. But, due to its non-positional property, it makes comparisons and modular reductions more costly than in a positional number system. HPR offers various trade-offs between internal parallelism and the efficiency of operations requiring position information. Our current application domain is asymmetric cryptography where HPR significantly reduces the cost of some modular operations compared to state-of-the-art RNS solutions. Index Terms—number representation; large integer; finite field; modular arithmetic; residue number system...|$|E
40|$|Timing {{and order}} memory 2 Three {{experiments}} are reported that {{examine the relationship}} between short-term memory for time and order information, and the more specific claim that order memory is driven by a timing signal. Participants were presented with digits spaced irregularly in time, and postcued (Experiments 1 and 2) or precued (Experiment 3) to recall the order or timing of the digits. The primary results of interest were: 1) Instructing participants to group lists had similar effects on serial and timing recall in inducing a pause in recall between suggested groups; 2) The timing of recall was predicted by the timing of the input lists in both serial recall and timing recall; and 3) When the recall task was precued, there was a tendency for temporally isolated items to be more accurately recalled than temporally crowded items. The results place constraints on models of serial recall that assume a timing signal generates <b>positional</b> <b>representations,</b> and suggest an additional role for information about individual durations in short-term memory. Timing and order memory 3 Multiple roles for time in short-term memory: Evidence from serial recall of order and timing How do we remember the temporal structure of sequences of events? This question has concerned short-term memory researchers for a number of decades, and has culminated in the formulation of a number of models specifically dedicated to explaining short-term memory for ordered sequences of information (Brown, Preece, & Hulme, 2000...|$|R
40|$|In this paper, we {{restore a}} blurred image caused by defocus of a lens using the shift-invariant Wavelet {{transform}} realized by the RI-Spline Wavelets. In a defocus blurred image, the blurring kernel becomes shiftvariant, so the <b>positional</b> frequency <b>representation</b> {{such as the}} Wavelet space is necessary for deblurring them. For restoring the defocusing blur, {{we assume that the}} blurring kernel of any position in a image can be obtained. In the experiments using synthesized images, our method using the shift-invariant Wavelet transform shows the better deblurring performance than the method using the ordinary Wavelet transform. We also show that our method can be applied to real images with the help of additional range data. ...|$|R
40|$|Abstract. For {{points in}} d real dimensions, we {{introduce}} a geometry for general digit sets. We introduce a positional number system where {{the basis for}} our representation is a fixed d by d matrix over Z. Our starting point is a given pair (A, D) with the matrix A assumed expansive, and D a chosen complete digit set, i. e., in bijective correspondence with the points in Z d /A T Z d. We give an explicit geometric representation and encoding with infinite words in letters from D. We show that the attractor X(A T, D) for an affine Iterated Function System (IFS) based on (A, D) {{is a set of}} fractions for our digital representation of points in R d. Moreover our <b>positional</b> “number <b>representation</b> ” is spelled out {{in the form of an}} explicit IFS-encoding of a compact solenoid SA associated with the pair (A, D). The intricate part (Theorem 6. 15) is played by the cycles in Z d for the initial (A, D) -IFS. Using these cycles we are able to write down formulas for the two maps which do the encoding as well as the decoding in our positional D-representation...|$|R
40|$|Abstract. Most {{digital systems}} {{operate on a}} <b>positional</b> <b>representation</b> of data, such as binary radix. An {{alternative}} is to operate on random bit streams where the signal value is encoded by the probability of obtaining a one versus a zero. This representation is much less compact than binary radix. However, complex opera-tions can be performed with very simple logic. Furthermore, since the represen-tation is uniform, with all bits weighted equally, it is highly tolerant of soft errors (i. e., bit flips). Both combinational and sequential constructs have been proposed for operating on stochastic bit streams. Prior work has shown that combinational logic can implement multiplication and scaled addition effectively; linear finite-state machines (FSMs) can implement complex functions such as exponentiation and tanh effectively. Building on these prior results, this paper presents case stud-ies of useful circuit constructs implement with the paradigm of logical computa-tion on stochastic bit streams. Specifically, it describes finite state machine im-plementations of functions such as edge detection and median filter-based noise reduction. ...|$|E
40|$|Computing {{structures}} {{based on}} Residue Number Sistems are very interesting because addition and multiplication are fast and modular and are {{well suited for}} VLSI implementation. In this paper the problem of multiplying two integers in residue representation is faced with and a new modulo m multiplier is defined. Such a multiplier can be integrated on a single chip with present VLSI technology and exhibits, for example, an expected response time of about 150 nseconds to multiply integers ranging up to 10 &# 8710; 12 using five 8 -bit moduli. It allows any choice of moduli values and has considerably low complexity figures, if compared with ROM-based structures, which are generally considered the most suited for RNS-based systems. Finally, new direct and reverse converters between binary <b>positional</b> <b>representation</b> and residue representation, exploiting the multiplier structure defined, are presented. They are the best solutions known under {{a wide range of}} hypotheses about RNS 2 ̆ 7 s...|$|E
40|$|NoUntil recently, it {{was widely}} {{believed}} that object position and object motion were represented independently in the visual cortex. However, several {{studies have shown that}} adaptation to motion produces substantial shifts in the perceived position of subsequently viewed stationary objects [[13]]. Two stages of motion adaptation have been proposed: an initial stage at the level of V 1 and a secondary stage thought to be located in V 5 /MT [[4]]. Indeed, selective adaptation can be demonstrated at each of these levels of motion analysis [[5, 6]]. What remains unknown is which of these cortical sites are involved in modulating the <b>positional</b> <b>representation</b> of subsequently viewed objects. To answer this question directly, we disrupted cortical activity by using transcranial magnetic stimulation (TMS) immediately after motion adaptation. When TMS was delivered to V 5 /MT after motion adaptation, the perceived offset of the test stimulus was greatly reduced. In marked contrast, TMS of V 1 had no effect on the changes that normally occur in perceived position after motion adaptation. This result demonstrates that the anatomical locus at which motion and positional information interact is area V 5 /MT rather than V 1 /V 2...|$|E
40|$|Computing {{structures}} {{based on}} residue number systems (RNS), which {{are useful in}} special applications as signal processing, where speed is a goal, are well suitable for VLSI implementations, because of their features of modularity and regularity. However, a bottleneck to the efficiency can be represented {{by the process of}} data converting forth and back between the usual <b>positional</b> (weighted) <b>representation</b> and the residue representation. Some authors have considered the problem of designing optimal VLSI representation converters, but unfortunately the complexity of the proposed solutions strongly depends on the characteristics of the residue system, namely the number and the size of moduli. In this work a lower bound AT&# 8710; 2 =&# 8486;(n&# 8710; 2) for the conversion from positional to residue is derived according to the VLSI complexity theory, and existent solutions for the same problem are briefly revisited in the light of such bound. Moreover, a structure is proposed, which works optimally independently of RNS parameters, according to a pipeline scheme. Such a structure can be implemented both with VLSI technology and with discrete components; the latter solution has been applied outlining a specific size design, based on the use of look-up tables...|$|R
40|$|Acquiring the {{complete}} surface geometry {{of an object}} using a range scanner invariably requires that multiple range images be taken of it from different viewpoints. An algorithm is presented which solves the "next best view" (NBV) problem: determine the next position for the range scanner given its previous scans of the object. As part of a complete surface acquisition system the scanner's next position should cause it not only to sample more of the object's surface but to resample part of the object already scanned {{to allow for the}} registration and integration of the new data with the previous scans. A novel <b>representation,</b> <b>positional</b> space, is presented which facilitates a solution to the NBV problem by representing what must be and what can be scanned in a unified data structure. The expensive operation of determining the visibility of part of the viewing volume is computed only once, not for each potential position of the scanner, thus breaking the computational burden of choosing t [...] ...|$|R
40|$|To {{acquire the}} {{complete}} surface {{description of a}} nontrivial object using range cameras several range images from different viewpoints are needed. We present a complete system to automatically acquire a surface model of an arbitrary part and outline the constraints this system places on {{a solution to the}} problem of where to position the range camera to take the next range image, i. e. the next best view (NBV) problem. We present a solution which uses no a-priori knowledge about the part and which addresses the most crucial of these constraints which is that each new range image must contain range data of part of the object's surface already scanned so that it can be registered with the previously taken range images. A novel <b>representation,</b> <b>positional</b> space, is presented which is capable of representing both those hypothetical sampling directions which could scan the unseen portions of the viewing volume and those which could rescan parts of the object. In addition, positional space makes [...] ...|$|R
40|$|The work {{finds its}} place within a project {{concerning}} the 'active' introduction of Computer Science in the didactics of Mathematics {{through the use}} of the computer as a 'machine for thinking'. In this work, from a Computer Science point of view, a naive approach to the subject of recursivity was faced with great caution, in order to avoid, where possible, the known teaching/learning difficulties associated with it. On the contrary, from a Mathematics point of view, a reflection on the <b>positional</b> <b>representation</b> of the natural numbers and on the changes in base was developed. In the experimentation the pupils, starting from the analysis of the functioning of the odometer and its simulation in Logo, have been able to consciously acquire the rules of passage from the base ten to another base and viceversa and moreover have been able to: i) gain confidence with the use of variables, with the structure of 'string type' and relative primitives; ii) read and interpret simple procedures realized by the teacher and realize simple ricursive procedures; iii) make significant activities of discovery of errors and debugging; iv) go from recursive algorithms to relative direct algorithms...|$|E
40|$|The {{main goal}} {{of this paper is}} to define a 1 - 1 {{correspondence}} between between substitution tilings constructed by inflation and the arithmetic of <b>positional</b> <b>representation</b> in the underlying real vector space. It introduces a generalization of inflationary tessellations to equivalence classes of tiles. Two tiles belong to the same class if they share a defined geometric property, such as equivalence under a group of isometries, having the same measure, or having the same `decoration'. Some properties of ordinary tessellations for which the equivalence relation is congruence with respect to the full group of isometries are already determined by the weaker relation of equivalence with respect to equal measure. In particular, the multiplier for an inflationary tiling (such as a Penrose aperiodic tiling) is an algebraic number. Equivalence of tiles under measure facilitates the investigation of properties of tilings that are independent of dimension, and provides a method for transferring tilings from one dimension to another. Three well-known aperiodic tilings illustrate aspects of the correspondence: a tiling of Ammann, a Penrose tiling, and the monotiling of Taylor and Socolar-Taylor. Comment: 42 pages, 18 figure...|$|E
40|$|Abstract—Most {{digital systems}} {{operate on a}} <b>positional</b> <b>representation</b> of data, such as binary radix. An {{alternative}} is to operate on random bit streams where the signal value is encoded by the probability of obtaining a one versus a zero. This representation is much less compact than binary radix. However, complex operations can be performed with very simple logic. Furthermore, since the representation is uniform, with all bits weighted equally, it is highly tolerant of soft errors (i. e., bit flips). Both combinational and sequential constructs have been proposed for operating on stochastic bit streams. Prior work has shown that combinational logic can implement multiplication and scaled addition effectively while linear finite-state machines (FSMs) can implement complex functions such as exponentiation and tanh effectively. Prior work on stochastic computation has largely been validated empirically. This paper provides a rigorous mathematical treatment of stochastic implementation of complex functions such as exponentiation and tanh implemented using linear finite state machines. It presents two new functions, an absolute value function and exponentiation based on an absolute value, motivated by specific applications. Experimental {{results show that the}} linear FSM-based constructs for these functions have smaller area-delay products than the corresponding deterministic constructs. They also are much more tolerant of soft errors. Index Terms—stochastic computing, finite state machine, stochastic bit streams. ...|$|E
40|$|The {{volume of}} {{information}} in natural languages in electronic format is increasing exponentially. The demographics of users of information management systems are becoming increasingly multilingual. Together these trends create a requirement for information management systems to support processing {{of information in}} multiple natural languages seamlessly. Database systems, the backbones of information management, should support this requirement effectively and efficiently. Earlier {{research in this area}} had proposed multilingual operators [7, 8] for relational database systems, and discussed their implementation using existing database features. In this paper, we specifically focus on the SemEQUAL operator [8], implementing a multilingual semantic matching predicate using WordNet [12]. We explore the implementation of SemEQUAL using OrdPath [10], a <b>positional</b> <b>representation</b> for nodes of a hierarchy that is used successfully for supporting XML documents in relational systems. We propose the use of OrdPath to represent position within the Wordnet hierarchy, leveraging its ability to compute transitive closures efficiently. We show theoretically that an implementation using OrdPath will outperform those implementations proposed previously. Our initial experimental results confirm this analysis, and show that the OrdPath implementation performs significantly better. Further, since our technique is not specifically rooted to linguistic hierarchies, the same approach may benefit other applications that utilize alternative hierarchical ontologies. ...|$|E
40|$|NoAfter an {{observer}} adapts to a moving stimulus, texture within a stationary stimulus {{is perceived to}} drift in the opposite direction¿the traditional motion aftereffect (MAE). It has recently been shown that the perceived position of objects can be markedly influenced by motion adaptation [1] and [2]. In the present study, we examine the selectivity of positional shifts resulting from motion adaptation to stimulus attributes such as velocity, relative contrast, and relative spatial frequency. In addition, we ask whether spatial position can be modified {{in the absence of}} perceived motion. Results show that when adapting and test stimuli have collinear carrier gratings, the global position of the object shows a substantial shift {{in the direction of the}} illusory motion. When the carrier gratings of the adapting and test stimuli are orthogonal (a configuration in which no MAE is experienced), a global positional shift of similar magnitude is found. The illusory positional shift was found to be immune to changes in spatial frequency and to contrast between adapting and test stimuli¿manipulations that dramatically reduce the magnitude of the traditional MAE. The lack of sensitivity for stimulus characteristics other than direction of motion suggests that a specialized population of cortical neurones, which are insensitive to changes in a number of rudimentary visual attributes [3], may modulate <b>positional</b> <b>representation</b> in lower cortical areas...|$|E
40|$|The Where’s Waldo problem {{concerns}} {{how individuals}} can rapidly learn to search a scene to detect, attend, recognize, {{and look at}} a valued target object in it. This article develops the ARTSCAN Search neural model to clarify how brain mechanisms across the What and Where cortical streams are coordinated to solve the Where's Waldo problem. The What stream learns positionally-invariant object representations, whereas the Where stream controls positionally-selective spatial and action representations. The model overcomes deficiencies of these computationally complementary properties through What and Where stream interactions. Where stream processes of spatial attention and predictive eye movement control modulate What stream processes whereby multiple view- and positionally-specific object categories are learned and associatively linked to view- and positionally-invariant object categories through bottom-up and attentive top-down interactions. Gain fields control the coordinate transformations that enable spatial attention and predictive eye movements {{to carry out this}} role. What stream cognitive-emotional learning processes enable the focusing of motivated attention upon the invariant object categories of desired objects. What stream cognitive names or motivational drives can prime a view- and positionally-invariant object category of a desired target object. A volitional signal can convert these primes into top-down activations that can, in turn, prime What stream view- and positionally-specific categories. When it also receives bottom-up activation from a target, such a positionally-specific category can cause an attentional shift in the Where stream to the <b>positional</b> <b>representation</b> of the target, and an eye movement can then be elicited to foveate it. These processes describe interactions among brain regions that include visual cortex, parietal cortex inferotemporal cortex, prefrontal cortex, amygdala, basal ganglia, and superior colliculus...|$|E
40|$|Introduction: Fitness {{and skill}} are {{considered}} {{key components of}} basketball game play and eventual team success, with tests related to key performance indicators (KPI) validated through their ability to discriminate between levels of performance. Purpose: To compare group performance on sport specific fitness tests and KPI-related skill tests in elite male youth basketball players from one high ranked and one low ranked basketball nation. Method: Thirty three male U 16 -year-old elite and/or national representative players from a high ranked basketball nation (in top five of Division A at the 2005 World Championships, n= 16) and a low ranked basketball nation (between 6 - 10 th place in Division B at the 2005 World Championships, n= 17) completed four sport specific fitness tests: 20 metre sprint (Sprint); countermovement standing vertical jump (CMJ); standing vertical jump from 90 degree squat (SVJ); Abalakov jump (AJ); and three KPIrelated skill tests: ball dribbling (BD); jump shot (JS); and free throws (FT) using protocols adapted from Balciunas et al., (2006). The best score or time from three attempts was used for group comparison using paired samples t-tests (p<. 05). Results: There were no significant group differences found between the Division A and Division B teams for height (1. 92 ±. 07 m vs 1. 86 ±. 09 m, p=. 07), weight (72. 6 ± 5. 4 kg; Div B 74. 2 ± 9. 1 kg, p=. 55), 20 m sprint time (3. 13 ±. 20 secs vs 3. 15 ±. 09 secs, p=. 66), CMJ (40. 4 ± 3. 1 cm vs 40. 5 ± 4. 8 cm, p=. 93), SVJ (38. 5 ± 3. 3 cm vs 38. 9 ± 4. 7 cm, p=. 79) and BD (7. 79 ±. 49 secs vs 7. 82 ±. 51 secs). Significant group differences between the Division A and Division B nations were apparent for BMI (19. 8 ± 1. 2 kg. m 2 vs 21. 3 ± 1. 3 kg. m 2, t= 3. 32, p<. 01, eta 2 =. 26), AJ (50. 4 ± 3. 7 cms vs 45. 1 ± 5. 0 cms, t= 3. 42, p<. 01, eta 2 =. 27), JS (12. 2 ± 2. 7 vs 8. 5 ± 3. 6, t= 3. 31, p<. 01, eta 2 =. 26) and FT (22. 8 ± 3. 4 vs 18. 8 ± 6. 6, t= 2. 25, p<. 05, eta 2 =. 14). Conclusions: As a group, and being similar in <b>positional</b> <b>representation,</b> the higher ranked nation demonstrated a lower weight to height ratio, suggesting a taller and leaner player profile, although more accurate body composition measurement is recommended in future studies. The higher-ranking nation were also found to perform better at arguably the most game specific vertical jump (the Abalakov jump) and the two most ‘score-outcome related’ skill tests. Relative body composition and these three tests may therefore be the most useful for discrimination between levels of performance in elite male youth basketball. Without suggestion of causality, specific physical training and technique/skill practice are recommended for less successful basketball teams {{in order to improve}} these seemingly performance related fitness and skill attributes...|$|E
40|$|University of Minnesota Ph. D. dissertation. June 2013. Major: Electrical Engineering. Electrical Engineering. Advisor: David J. Lilja. 1 {{computer}} file (PDF); x, 111 pages. Most digital systems {{operate on a}} <b>positional</b> <b>representation</b> of data, such as binary encoding. An alternative is to operate on random bit streams where the signal value is encoded by the probability of obtaining a one versus a zero. This representation is much less compact than the binary encoding. However, complex operations can be performed with very simple logic. Furthermore, since the representation is uniform, with all bits weighted equally, it is highly tolerant of soft errors (i. e., bit flips). Complex algorithms, such as artificial neural networks (ANN), low-density parity-check (LPDC) error-correcting coding, and kernel density estimation (KDE) -based image segmentation, can be implemented using stochastic encoding with much lower hardware cost and higher fault-tolerance. For example, the hardware area of the stochastic implementation of the KDE-based image segmentation is only 1. 2 % of the corresponding deterministic implementation, and it can tolerate more than 30 % soft errors. Compared to conventional fault-tolerant techniques, such as triple-module redundance (TMR), the stochastic implementations of the complex algorithms normally consumes equivalent or less energy and have better fault-tolerance. For example, the TMR implementation of the KDE-based implementation can only tolerate up to 10 % soft errors, but consumes the same energy as the stochastic implementation. In addition, thanks to the simple construction of the stochastic computing elements, it makes the rounting much easier, {{which is a big}} issue for very large scale integrated circuit (VLSI) deterministic implementations of these complex algorithms. Both combinational and sequential constructs have been proposed for operating on stochastic bit streams. Prior work has shown that combinational logic can implement multiplication and scaled addition effectively while finite-state machines (FSMs) can implement complex functions such as exponentiation and tanh effectively. Although the combinational logic-based stochastic computing elements had been well studied, they are inefficient for complex operations. The FSM-based stochastic computing elements are very efficient for complex operations. However, only three FSM-based stochastic computing elements were proposed by prior work, which limits the applications of stochastic computing. To implement more applications and functions stochastically, this dissertation focuses on the FSM-based stochastic computing. We first analyze the FSM-based stochastic computing elements proposed by prior work, which had largely been validated empirically. In this dissertation, we provide a rigorous mathematical treatment of the FSM-based stochastic computing elements. This gives us intuition about how to construct arbitrary functions stochastically using the FSM. Then, based on the existing stochastic computing elements, we implement five digital image processing algorithms as case studies. So far as we know, {{this is the first time}} these digital image processing algorithms are implemented stochastically. For all the five algorithms, the stochastic implementation has much less hardware cost and better fault-tolerance than the corresponding deterministic implementation. Last but not the least, we present a general method to synthesize a given target function stochastically using FSMs. We proposed three FSM topologies and discuss how to use these FSMs to synthesize the given target functions. The trade-offs among these different FSM topologies are introduced. Based on this synthesis method, more applications can be implemented stochastically to achieve lower hardware cost and better fault-tolerance...|$|E

