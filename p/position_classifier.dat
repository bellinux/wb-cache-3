5|25|Public
30|$|It is {{important}} to recognize the carrying position of an unconstrained smartphone accurately and robustly, since carrying positions may directly impact the parameter settings for step detection and step length estimation. Many previous works [24, 25] have pointed out that the acceleration patterns for different carrying positions show distinct features. The statistics of three dimensional raw measured acceleration samples are deployed as input features to develop the carrying <b>position</b> <b>classifier.</b> The developed classifiers are all designed upon relatively stable device orientations. If the device orientations are unconstrained, the raw measured acceleration samples may vary a lot with the changing orientations under the same carrying positions. As a result, these classifiers may render degraded recognition accuracy with the unconstrained uses of smartphones.|$|E
40|$|Abstract—In this paper, a novel human {{articulated}} pose {{estimation method}} based on AdaBoost algorithm is presented. The human articulated pose is estimated by locating major human joint positions. We learn the classifiers on a normalized image for classifying each pixel position into a certain category. Two {{different kinds of}} classifiers, bottom-up joint <b>position</b> <b>classifier</b> and top-down skeleton classifier, are combined to achieve final results. HOG (Histogram of Oriented Gradient) feature is used for training both classifiers. Our human pose estimation system consists of three models, human detection, view classification, and pose estimation. The implemented system can automatically estimate human pose of different views. Experiment results are reported to show our proposed method can work on relatively small-size human images without using human silhouettes as a prerequisite, which is very efficient, robust and accurate enough for potential applications in visual surveillance...|$|E
40|$|Bibliography: pages 174 - 182. This {{dissertation}} {{investigates the}} machine vision grading of flue-cured Virginia tobacco {{by means of}} digital processing of tobacco leaf images. With reference to international grading standards and to modem image processing techniques, two classifiers are designed. The colour classifier uses seven features extracted from each leaf image to grade the leaf into one of five official colour classes. It does this with an expected correct classification rate of 93. 5 %. The plant <b>position</b> <b>classifier</b> identifies the {{position on the stalk}} from which a leaf was reaped, using ten size and shape features to classify the leaf into one of six plant position categories. It has a correct classification rate of 70 %. Average colours for each colour class and archetypal shapes for each plant position category are derived from the digital leaf data. These should be of value to tobacco graders as objective representations of typical leaves within each class...|$|E
50|$|By {{completing}} the baccalaureate, he obtained a <b>position</b> as <b>classifier</b> of official {{documents in the}} National Archives and joined the Faculty of Law and Social Sciences, where {{he was president of}} the Students’ Council of this house of studies in 1903. He earned his doctorate degree in law and Social Science 22 December 1905. As he was studying, he was a professor of mathematics and story in secondary schools.|$|R
40|$|While context has {{received}} little {{attention in the}} visual object classification literature, it nevertheless plays {{a vital role in}} the ability to identify objects in a scene. This paper seeks to improve the performance of object classifiers by incorporating contextual information. Our method uses probability maps to guide classifiers to image regions likely to contain the object in question, based on the object's past positions and the positions of surrounding objects. We contrast our method with a baseline unguided classifier and show that using probability maps as a preprocessing step significantly reduces the number of <b>positions</b> a <b>classifier</b> needs to evaluate. The structures presented here can be used with any classification algorithm that evaluates windowed image regions...|$|R
40|$|An {{algorithm}} is developed for a learning, adaptive, statistical pattern classifier for remotely sensed data. The estimation procedure {{consists of two}} steps: (1) an optimal stochastic approximation of the parameters of interest, and (2) a projection of the parameters in time and space. The results reported are for Gaussian data in which the mean vector of each class may vary with time or <b>position</b> after the <b>classifier</b> is trained...|$|R
30|$|In this paper, {{we propose}} an UKF-based WiFi/PDR-integrated {{localization}} approach. For WiFi localization, we deploy a KDE-based model {{to measure the}} measurement noise covariance adaptively rather than set them empirically. For PDR, we deploy another UKF model for device attitude tracking by integrating inertial sensors with magnetometers and construct relationship between quaternion vector and user heading. As a result, an improved user heading estimation is obtained. Furthermore, the covariance of user heading estimation can also be accurately measured and used for PDR in the UKF. Besides, the proposed device carrying <b>position</b> <b>classifier</b> using orientation invariant features may achieve significant recognition accuracy improvement than those using normal features, when the device orientation is unconstrained. Experiments show that compared with the integrated localization approaches empirically setting process and measurement noise parameters based on UKF, EKF, and KF, respectively, individual approaches including WiFi localization and PDR, the proposed localization approach decreases mean localization error by 24.8 % (0.25 [*]m), 30.3 % (0.33 [*]m), 36.1 % (0.43 [*]m), 58.5 % (1.07 [*]m), and 66.4 % (1.50 [*]m), respectively.|$|E
40|$|This paper {{proposes a}} novel heading {{estimation}} approach for indoor pedestrian navigation using the built-in inertial sensors on a smartphone. Unlike previous approaches constraining the carrying {{position of a}} smartphone on the user’s body, our approach gives the user a larger freedom by implementing automatic recognition of the device carrying position and subsequent selection of an optimal strategy for heading estimation. We firstly predetermine the motion state by a decision tree using an accelerometer and a barometer. Then, to enable accurate and computational lightweight carrying position recognition, we combine a <b>position</b> <b>classifier</b> with a novel position transition detection algorithm, which may {{also be used to}} avoid the confusion between position transition and user turn during pedestrian walking. For a device placed in the trouser pockets or held in a swinging hand, the heading estimation is achieved by deploying a principal component analysis (PCA) -based approach. For a device held in the hand or against the ear during a phone call, user heading is directly estimated by adding the yaw angle of the device to the related heading offset. Experimental results show that our approach can automatically detect carrying positions with high accuracy, and outperforms previous heading estimation approaches in terms of accuracy and applicability...|$|E
40|$|We {{describe}} a component based face detection system trained only on positive examples. On the first layer, SVM classifiers detect predetermined rectangular portions of faces in gray scale images. On the second level, histogram based classifiers judge the pattern using only {{the positions of}} maximization of the first level classifiers. Novel aspects of our approach are: a) using selected parts of the positive pattern as negative training for component classifiers, b) The use of pair wise correlation between facial component <b>positions</b> to bias <b>classifier</b> outputs and achieve superior component localization...|$|R
40|$|In recent years, {{the use of}} a {{smartphone}} accelerometer {{in physical}} activity recognition has been well studied. However, the role of a gyroscope and a magnetometer is yet to be explored, both when used alone as well as in combination with an accelerometer. For this purpose, we investigate the role of these three smartphone sensors in activity recognition. We evaluate their roles on four body <b>positions</b> using seven <b>classifiers</b> while recognizing six physical activities. We show that in general an accelerometer and a gyroscope complement each other, thereby making the recognition process more reliable. Moreover, in most cases, a gyroscope does not only improve the recognition accuracy in combination with an accelerometer, but it also achieves a reasonable performance when used alone. The results for a magnetometer are not encouraging because it causes over-fitting in training classifiers due to its dependence on directions. Based on our evaluations, we show {{that it is difficult to}} make an exact general statement about which sensor performs better than the others in all situations because their recognition performance depends on the smartphone’s <b>position,</b> the selected <b>classifier,</b> and the activity being recognized. However, statements about their roles in specific situations can be made. We report our observations and results in detail in this paper, while our data-set and data-collection app is publicly available, thereby making our experiments reproducible...|$|R
40|$|Abstract—In recent years, {{the use of}} a {{smartphone}} accelerometer {{in physical}} activity recognition has been well studied. However, the role of a gyroscope and a magnetometer is yet to be explored, both when used alone as well as in combination with an accelerometer. For this purpose, we investigate the role of these three smartphone sensors in activity recognition. We evaluate their roles on four body <b>positions</b> using seven <b>classifiers</b> while recognizing six physical activities. We show that in general an accelerometer and a gyroscope complement each other, thereby making the recognition process more reliable. Moreover, in most cases, a gyroscope does not only improve the recognition accuracy in combination with an accelerometer, but it also achieves a reasonable performance when used alone. The results for a magnetometer are not encouraging because it causes over-fitting in training classifiers due to its dependence on directions. Based on our evaluations, we show {{that it is difficult to}} make an exact general statement about which sensor performs better than the others in all situations because their recognition performance depends on the smartphone’s <b>position,</b> the selected <b>classifier,</b> and the activity being recognized. However, statements about their roles in specific situations can be made. We report our observations and results in detail in this paper, while our data-set and data-collection app is publicly available, thereby making our experiments reproducible. Keywords — accelermeter; activity recognition; assisted living; gyroscope; health monitoring; magnetometer; sensor fusion; smartphone sensors; well-being applications. I...|$|R
40|$|Abstract—This paper {{presents}} a nonintrusive prototype com-puter vision system for monitoring a driver’s vigilance in real time. It {{is based on}} a hardware system for the real-time acquisi-tion of a driver’s images using an active IR illuminator and the software implementation for monitoring some visual behaviors that characterize a driver’s level of vigilance. Six parameters are calculated: Percent eye closure (PERCLOS), eye closure duration, blink frequency, nodding frequency, face position, and fixed gaze. These parameters are combined using a fuzzy classifier to infer the level of inattentiveness of the driver. The use of multiple visual parameters and the fusion of these parameters yield a more robust and accurate inattention characterization than by using a single parameter. The system has been tested with different sequences recorded in night and day driving conditions in a motorway and with different users. Some experimental results and conclusions about the performance of the system are presented. Index Terms—Driver vigilance, eyelid movement, face <b>position,</b> fuzzy <b>classifier,</b> percent eye closure (PERCLOS), visual fatigue behaviors. I...|$|R
40|$|Abstract:- This paper {{proposes a}} {{technique}} for recognizing Arabic characters. This technique involves of three parts: body classifier, complementary classifier, and aggregate classifier. The body classifier {{is designed to}} recognize {{the main body of}} the unknown character. It uses a Hopfield network to enhance the unknown character and to get rid of noise and associated complementary. Furthermore, it uses a backpropagation network to recognize {{the main body of the}} enhanced unknown character. The complementary classifier is responsible of recognizing the number of dots or zigzag that are associated with the body of character and their <b>position.</b> The aggregate <b>classifier</b> combines the results of the previous two classifiers and classifies the whole unknown character. The proposed technique has been implemented shown a reasonable recognition rate...|$|R
40|$|A neural {{classifier}} of planar trajectories is presented. There {{already exist}} a large variety of classifiers that are specialized on particular invariants {{contained in a}} trajectory classification task such as position-invariance, rotation-invariance, size-invariance, [...] .. That is, there exist classifiers specialized on recognizing trajectories e. g. independently of their <b>position.</b> The neural <b>classifier</b> {{presented in this paper}} is not restricted to certain invariants in a task: The neural network itself extracts the invariants contained in a classification task by assessing only the trajectories. The trajectories need to be given as a set of points. No additional information must be available for training, which saves the designer from determining the needed invariants by himself. Besides its applicability to real-world problems, such a more general classifier is also cognitively plausible: In assessing trajectories for classification, human beings are able to find class specific feature [...] ...|$|R
40|$|Motivation: Bacterial type III {{secreted}} (T 3 S) effectors {{are delivered}} into host cells specifically via type III secretion systems (T 3 SSs), which play {{important roles in}} the interaction between bacteria and their hosts. Previous computational methods for T 3 S protein prediction have only achieved limited accuracy, and distinct features for effective T 3 S protein prediction remain to be identified. Results: In this work, a distinctive N-terminal position-specific amino acid composition (Aac) feature was identified for T 3 S proteins. A large portion (∼ 50 %) of T 3 S proteins exhibit distinct position-specific Aac features that can tolerate <b>position</b> shift. A <b>classifier,</b> BPBAac, was developed and trained using Support Vector Machine (SVM) based on the Aac feature extracted using a Bi-profile Bayes model. We demonstrated that the BPBAac model outperformed other implementations in classification of T 3 S and non-T 3 S proteins, givin...|$|R
40|$|Test data {{prediction}} is about assigning {{the most suitable}} class for each test case during classification. In Associative Classification (AC) data mining, this step is considered crucial since the overall performance of the classifier is heavily dependent on the class assigned to each test case. This paper investigates the classification (prediction) step in AC {{in an attempt to}} come up with a novel generic prediction method that assures the best class assignment for each test case. The outcome is a new prediction method that takes into account all applicable rules ranking <b>position</b> in the <b>classifier</b> beside the class number of rules. Experimental results using different data sets from the University of California Irvine (UCI) repository and two common AC prediction methods reveal that the proposed method is more accurate for the majority of the data sets. Further, the proposed method can be plugged and used successfully by any AC algorithm...|$|R
40|$|Man {{portable}} {{air defence}} systems, MANPADS, pose a big threat to {{civilian and military}} aircraft. This thesis aims to find methods {{that could be used}} in a missile approach warning system based on infrared cameras. The two main tasks of the completed system are to classify the type of missile, and also to estimate its position and velocity from a sequence of images. The classification is based on hidden Markov models, one-class classifiers, and multi-class <b>classifiers.</b> <b>Position</b> and velocity estimation uses a model of the observed intensity as a function of real intensity, image coordinates, distance and missile orientation. The estimation is made by an extended Kalman filter. We show that fast classification of missiles based on radiometric data and a hidden Markov model is possible and works well, although more data would be needed to verify the results. Estimating the position and velocity works fairly well if the initial parameters are known.  Unfortunately, some of these parameters can not be computed using the available sensor data...|$|R
40|$|This paper {{presents}} a novel technique—Floating Centroids Method (FCM) {{designed to improve}} {{the performance of a}} conventional neural network classifier. Partition space is a space that is used to categorize data sample after sample is mapped by neural network. In the partition space, the centroid is a point, which denotes the center of a class. In a conventional neural network <b>classifier,</b> <b>position</b> of centroids and the relationship between centroids and classes are set manually. In addition, number of centroids is fixed with reference to the number of classes. The proposed approach introduces many floating centroids, which are spread throughout the partition space and obtained by using K-Means algorithm. Moreover, different classes labels are attached to these centroids automatically. A sample is predicted as a certain class if the closest centroid of its corresponding mapped point is labeled by this class. Experimental results illustrate that the proposed method has favorable performance especially with respect to the training accuracy, generalization accuracy, and average F-measures. Web of Science 31345443...|$|R
40|$|This {{paper is}} devoted to the {{analysis}} of (DP, AP, and PP) postnominal modifiers of personal pronouns, focusing especially on Romanian. Regarding the internal structure of personal pronouns, we adopt the traditional view that they actually do not have a nominal restriction; instead, they themselves are definite NPs that raise to the D-domain, thus coming to be DPs. By means of the suffixal definite article, Romanian provides a contrast between definite modifiers, which prove to be DP-internal, and non-definite modifiers, which prove to be DP-external. Non-definite modifiers are non‑problematic: they are predicates in a small clause configuration. By contrast, the definite postpronominal modifiers are analysed as occupying the specifier <b>position</b> of a <b>Classifier</b> Phrase, present in the extended projection of DPs headed by pronouns and proper names (Cornilescu 2007); the modifier “classifies” the personal pronouns with respect to the kind of the pronoun’s referent (e. g. we linguists / Rom. noi lingviştii). Corroborative data from English and other Romance languages support the proposed analysis...|$|R
40|$|In this paper, a {{probabilistic}} multi-class {{pattern recognition}} algorithm is developed for damage detection, localization, and quantification in smart mechanical structures. As these structures can face damages of different severities located at various <b>positions,</b> multi-class <b>classifiers</b> are naturally needed in that context. Furthermore, {{because of the}} lack of available data in the damaged state and of environmental effects, the experimentally obtained damage sensitive features may differ from those learned offline by the classifier. A multiclass classifier that provides probabilities associated with each damage severity and location instead of a binary decision is thus greatly desirable in that context. To tackle this issue, we propose an original support vector machine (SVM) multi-class clustering algorithm that is based on a probabilistic decision tree (PDT) and that produces a posteriori probabilities associated with damage existence, location, and severity. Furthermore, the PDT is here built by iteratively subdividing the surface of the structure and thus takes into account the actual structure geometry. The proposed algorithm is very appealing as it combines both the computational efficiency of tree architectures and the classification accuracy of SVMs. The effectiveness of this algorithm is illustrated experimentally on a composite plate instrumented with piezoelectric elements on which damages are simulated using added masses. Damage sensitive features are computed using an active approach based on the permanent emission of non-resonant Lamb waves into the structure and on the recognition of amplitude disturbed diffraction patterns. On the basis of these damage-sensitive features, the proposed multi-class probabilistic classifier generates decisions that are in excellent agreement with the actual severities and locations of the simulated damages...|$|R
30|$|After {{the first}} {{iteration}} of training the classifier, when the user requests a sample from the unlabelled pool, each sample can be <b>positioned</b> in the <b>classifier</b> view {{based on the}} current prediction of the machine, using any of the training schemes as selected by the user. The sample is positioned in the horizontally based on the appropriate class label, and vertically based on the confidence associated with that class label. The confidence of the machine prediction {{can be obtained from}} the output layer of the classifier model that essentially serves as a probability distribution across all possible classes. This is the case for both the logistic regression model, and the convolutional neural network model, and would extend to many other classifier models also. Samples are positioned with a yellow highlight applied, indicating to the user that this is a machine prediction. The user can then confirm the class decision, or refine the decision by moving the sample to a new class region. If the user confirms the decision, the sample is shown as blue, and if the user refines the decision, the sample is shown as red. This serves as a effective visual cue to the distribution of machine-labelled and human-labelled samples within each class. The highlighting of yellow samples also provides a effective means of ‘seeing’ the classifier improve over time, as machine-positioned samples gradually become positioned higher up in each class region with each iteration of training. As before, the user can also manually select samples from the sample pool and see how these are <b>positioned</b> within the <b>classifier</b> view, giving a significantly more effective analysis of the classification performance compared to the higher-level overview of the confusion matrix and test accuracy scores. The number of ‘corrected’ labels provided by the user can also be shown as a bar chart if desired. This indicates the number of cases where the machine label is incorrect and a user has therefore had to relabel (regardless of the user’s confidence). This could also be considered as ‘user effort’, which ideally we would hope to minimise using active machine learning. In our experimentation, we report on user effort for the machine-driven, user-driven, and collaborative selection strategies, in conjunction with the achieved accuracy of the classifier.|$|R
40|$|International audienceIn this paper, a {{probabilistic}} multi-class {{pattern recognition}} algorithm is developed for damage detection, localization, and quantification in smart mechanical structures. As these structures can face damages of different severities located at various <b>positions,</b> multi-class <b>classifiers</b> are naturally needed in that context. Furthermore, {{because of the}} lack of available data in the damaged state and of environmental effects, the experimentally obtained damage sensitive features may differ from those learned offline by the classifier. A multiclass classifier that provides probabilities associated with each damage severity and location instead of a binary decision is thus greatly desirable in that context. To tackle this issue, we propose an original support vector machine (SVM) multi-class clustering algorithm that is based on a probabilistic decision tree (PDT) and that produces a posteriori probabilities associated with damage existence, location, and severity. Furthermore, the PDT is here built by iteratively subdividing the surface of the structure and thus takes into account the actual structure geometry. The proposed algorithm is very appealing as it combines both the computational efficiency of tree architectures and the classification accuracy of SVMs. The effectiveness of this algorithm is illustrated experimentally on a composite plate instrumented with piezoelectric elements on which damages are simulated using added masses. Damage sensitive features are computed using an active approach based on the permanent emission of non-resonant Lamb waves into the structure and on the recognition of amplitude disturbed diffraction patterns. On the basis of these damage-sensitive features, the proposed multi-class probabilistic classifier generates decisions that are in excellent agreement with the actual severities and locations of the simulated damages...|$|R
40|$|Abstract — DNA {{sequence}} basecalling {{is commonly}} {{regarded as a}} solved problem, despite significant error rates being reflected in inaccuracies in databases and genome annotations. These errors commonly arise from an inability to sequence through peak height variations in DNA sequencing traces from the Sanger sequencing method. Recent efforts toward improving basecalling accuracy have taken the form of more sophisticated digital filters and feature detectors. We demonstrate that the variation in peak heights itself encodes novel information {{which can be used}} for basecalling. To isolate this information for a clear demonstration, we perform a peculiar blind basecalling experiment using ABI processed output. Using classifiers responding to measurements {{in the context of the}} basecalling position, we call bases without reference to the peak heights at the basecalling <b>position</b> itself. Tree <b>classifiers</b> indicate which features are pertinent, and the application of neural nets to these features results in a startlingly high initial success rate of 78 %. Our analysis indicates that we can make viable basecalls using information that has never been accessed before. I...|$|R
40|$|Abstract Background HIV- 1 targets {{human cells}} expressing both the CD 4 receptor, which binds the viral {{envelope}} glycoprotein gp 120, {{as well as}} either the CCR 5 (R 5) or CXCR 4 (X 4) co-receptors, which interact primarily with the third hypervariable loop (V 3 loop) of gp 120. Determination of HIV- 1 affinity for either the R 5 or X 4 co-receptor on host cells facilitates the inclusion of co-receptor antagonists {{as a part of}} patient treatment strategies. A dataset of 1193 distinct gp 120 V 3 loop peptide sequences (989 R 5 -utilizing, 204 X 4 -capable) is utilized to train predictive classifiers based on implementations of random forest, support vector machine, boosted decision tree, and neural network machine learning algorithms. An in silico mutagenesis procedure employing multibody statistical potentials, computational geometry, and threading of variant V 3 sequences onto an experimental structure, is used to generate a feature vector representation for each variant whose components measure environmental perturbations at corresponding structural <b>positions.</b> Results <b>Classifier</b> performance is evaluated based on stratified 10 -fold cross-validation, stratified dataset splits (2 / 3 training, 1 / 3 validation), and leave-one-out cross-validation. Best reported values of sensitivity (85 %), specificity (100 %), and precision (98 %) for predicting X 4 -capable HIV- 1 virus, overall accuracy (97 %), Matthew's correlation coefficient (89 %), balanced error rate (0. 08), and ROC area (0. 97) all reach critical thresholds, suggesting that the models outperform six other state-of-the-art methods and come closer to competing with phenotype assays. Conclusions The trained classifiers provide instantaneous and reliable predictions regarding HIV- 1 co-receptor usage, requiring only translated V 3 loop genotypes as input. Furthermore, the novelty of these computational mutagenesis based predictor attributes distinguishes the models as orthogonal and complementary to previous methods that utilize sequence, structure, and/or evolutionary information. The classifiers are available online at [URL]. </p...|$|R
40|$|This paper proposes the method, {{called the}} Filter Partitioning Machine Learning Classifier (FPMLC). It can enhance an {{accuracy}} of indoor positioning based on fingerprinting by using {{machine learning algorithms}} and prominent access points (APs). FPMLC selects limited information of groups of the signal strength and combines a clustering task and a classification task. There are three processes in FPMLC, i. e. feature selection to choose prominent APs, clustering to determine approximated positions, and classification to determine fine positions. This work demonstrates the procedure of FPMLC creation. The results of FPMLC are {{compared with those of}} a primitive method by using real measured data. FPMLC is compared with well-known machine learning classifiers, i. e. Decision Tree, Naive Bayes, and Artificial Neural Networks. The performance comparison is done in terms of accuracy and error distance between classified positions and actual positions. The appropriate number of selected prominent APs and the number of clusters, are assigned in the clustering process. The result of this study shows that FPMLC can increase performance for indoor <b>positioning</b> of all <b>classifiers.</b> In addition, FPMLC is the most optimized model while having Decision Tree as its classifier. ...|$|R
40|$|Gamma-aminobutyric acid type-A receptors (GABAARs) {{belong to}} multisubunit {{membrane}} spanning ligand-gated ion channels (LGICs) which {{act as the}} principal mediators of rapid inhibitory synaptic transmission in the human brain. Therefore, the category prediction of GABAARs just from the protein amino acid sequence would be very helpful for the recognition and research of novel receptors. Based on the proteins’ physicochemical properties, amino acids composition and <b>position,</b> a GABAAR <b>classifier</b> was first constructed using a 188 -dimensional (188 D) algorithm at 90 % cd-hit identity and compared with pseudo-amino acid composition (PseAAC) and ProtrWeb web-based algorithms for human GABAAR proteins. Then, four classifiers including gradient boosting decision tree (GBDT), random forest (RF), a library for support vector machine (libSVM), and k-nearest neighbor (k-NN) were compared on the dataset at cd-hit 40 % low identity. This work obtained the highest correctly classified rate at 96. 8 % and the highest specificity at 99. 29 %. But the values of sensitivity, accuracy, and Matthew’s correlation coefficient were a little {{lower than those of}} PseAAC and ProtrWeb; GBDT and libSVM can make a little better performance than RF and k-NN at the second dataset. In conclusion, a GABAAR classifier was successfully constructed using only the protein sequence information...|$|R
40|$|In {{this paper}} we {{describe}} an automated system for extracting people’s names from websites containing lists of people. The contents of these websites describe attributes {{common to the}} people listed. This public information has strategic value, such as demonstrating who tends to appear at similar events. Unlike traditional named entity recognition (NER) we are extracting names embedded in HTML without natural language context. We use a hidden markov model (HMM) to segment the document’s HTML source in order to extract entire names. Engineering features for this classifier led us to several general types of features useful for segmenting text in structured documents. Rosters may order first and last names in many ways. A first/last classifier determines the ordering used by each document using dictionaries to provide partial knowledge {{of the distribution of}} names across token <b>positions.</b> The first/last <b>classifier</b> uses the two dimensional coordinates of text as it would appear when rendered by a browser in order to abstract away the HTML. The HMM segmenter was able to achieve 95 % precision and 91 % recall while the first/last classifier achieved 84 % precision and 82 % recall, on average in a corpus of 37 documents containing approximately 10, 000 names...|$|R
40|$|The {{position}} of on-body motion sensors {{plays an important}} role in human activity recognition. Most often, mobile phone sensors at the trouser pocket or an equivalent position are used for this purpose. However, this position is not suitable for recognizing activities that involve hand gestures, such as smoking, eating, drinking coffee and giving a talk. To recognize such activities, wrist-worn motion sensors are used. However, these two positions are mainly used in isolation. To use richer context information, we evaluate three motion sensors (accelerometer, gyroscope and linear acceleration sensor) at both wrist and pocket <b>positions.</b> Using three <b>classifiers,</b> we show that the combination of these two positions outperforms the wrist position alone, mainly at smaller segmentation windows. Another problem is that less-repetitive activities, such as smoking, eating, giving a talk and drinking coffee, cannot be recognized easily at smaller segmentation windows unlike repetitive activities, like walking, jogging and biking. For this purpose, we evaluate the effect of seven window sizes (2 – 30 s) on thirteen activities and show how increasing window size affects these various activities in different ways. We also propose various optimizations to further improve the recognition of these activities. For reproducibility, we make our dataset publicly available...|$|R
40|$|Illumination {{variation}} {{is a big}} problem in object recogni-tion which usually requires a costly compensation prior to classification. It would be desirable to have an image to image transform which uncovers only the structure of an object for an efficient matching. In this context the contri-bution of our work is twofold. First we introduce illumina-tion invariant Local Structure Features for object detection. For an efficient computation we propose a Modified Cen-sus Transform which enhances the original work of Zabih and Woodfill [10]. We show some shortcomings and how to get over them with the modified version. Secondly we in-troduce a efficient four-stage classifier for rapid detection. Each single stage classifier is a linear classifier which con-sists of a set of feature lookup-tables. We show that the first stage which evaluates only 20 features filters out more than 99 % of all background <b>positions.</b> Thus the <b>classifier</b> struc-ture is much simpler than previous described multi-stage approaches, while having similar capabilities. The combination of illumination invariant features to-gether with a simple classifier leads to a real-time system on standard computers (60 msec, image size: 288 × 384, 2 GHz Pentium). Detection results are presented on two com-monly used databases in this field namely the MIT+CMU set of 130 images and the BioID set of 1526 images. We are achieving detection rates of more than 90 % with a very low false positive rate of 10 − 7 %. We also pro-vide a demo program that {{can be found on the}} interne...|$|R
40|$|UnrestrictedCurrent {{models of}} {{sentence}} processing make contrasting predictions regarding {{the processing of}} head-final relative clauses (RCs) in Chinese, but existing research has found mixed results. It {{is not yet clear}} (i) whether subject-extracted RCs are easier to process than object-extracted RCs; and (ii) whether classifiers in a dislocated position before the RC can facilitate processing. This dissertation investigates how extraction site, animacy configuration, and <b>classifier</b> <b>positioning</b> guide real-time parsing of Chinese RCs. Assuming a correlation between frequency of occurrence and ease of processing, I analyzed the frequency pattern of these factors in the Chinese Treebank 5. 0 corpus, then formulated and experimentally tested hypotheses to account for the patterns observed.; Chapter 1 and 2 introduce the issues and review the relevant literature. Chapter 3 presents a corpus analysis, focusing on extraction type (subject-extracted vs. object-extracted) and animacy of the head and embedded nouns. The results show that subject-extracted RCs are more frequent than object-extracted RCs and suggest three Animacy Preference Constraints (APCs) : (i) head nouns that are RC subjects tend to be animate; (ii) head nouns that are RC objects tend to be inanimate; (iii) in both cases, the animacy of the head and embedded nouns tend to contrast.; Chapter 4 presents three self-paced reading experiments to test whether the hypothesized APCs influence ease of RC parsing. The results show that animacy configurations modulate the processing load induced by Chinese RCs: subject-extracted RCs are easier to process than object-extracted RCs when the animacy configuration is inversely contrastive (i. e., RC subject = inanimate, RC object = animate).; Chapter 5 focuses on classifiers as possible cues for upcoming RCs. The corpus reveals an asymmetrical pattern of classifier distribution in subject-extracted and object-extracted RCs. I propose two processing principles related to anticipatory processing and lexical access. These principles are supported by one eye-tracking and two reading-time experiments. Results suggest that pre-RC classifiers help the human parsing system identify head-final RC structures efficiently.; I consider the findings in light of four major theoretical accounts, and suggest that the parsing of Chinese RCs best fits the probabilistic, expectation-based constraint-satisfaction model...|$|R

