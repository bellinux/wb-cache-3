34|74|Public
25|$|One of the {{earliest}} non-IBM channel systems was hosted in the CDC 6600 supercomputer in 1965. The CDC utilized 10 logically independent computers called peripheral processors, or PPs for this role. PPs were powerful, a modern version of CDC's first 'personal computer', the CDC 160A. The operating system resided and executed in the <b>primary</b> <b>processor,</b> PP0. Since then, channel controllers have been a standard part of most mainframe designs and a primary advantage mainframes have over smaller, faster, personal computers and network computing.|$|E
25|$|Video game {{manufacturers}} {{used the}} 68000 as {{the backbone of}} many arcade games and home game consoles: Atari's Food Fight, from 1982, {{was one of the}} first 68000-based arcade games. Others included Sega's System 16, Capcom's CP System and CPS-2, and SNK's Neo Geo. By the late 1980s, the 68000 was inexpensive enough to power home game consoles, such as Sega's Mega Drive (Genesis) console and also the Sega CD attachment for it (A Sega CD system has three CPUs, two of them 68000s). The 1993 multi-processor Atari Jaguar console used a 68000 as a support chip, although some developers used it as the <b>primary</b> <b>processor</b> due to familiarity. The 1994 multi-processor Sega Saturn console used the 68000 as a sound co-processor (much as the Mega Drive/Genesis uses the Z80 as a co-processor for sound and/or other purposes).|$|E
5000|$|Some {{multi-core}} chips can {{be programmed}} {{so that one}} of their processors is the <b>primary</b> <b>processor,</b> and the other processors are supporting coprocessors.|$|E
50|$|Canada has {{a supply}} {{management}} system where marketing boards govern the broiler and broiler hatching egg industries. For broilers, prices are negotiated at the provincial level. In each province, the minimum {{price per kg}} that processors will pay to producers is set periodically through negotiations between processors and the provincial marketing board. From 1992 to 2003, negotiated prices in Ontario are generally used as a benchmark when conducting price negotiations in other provinces. In Ontario, Chicken Farmers of Ontario (CFO) has price-negotiating authority. It negotiates the base price paid by <b>primary</b> <b>processors</b> for live chicken with <b>primary</b> <b>processors.</b> Since 2003, the live chicken price is determined by a “live price formula” established by the Agriculture, Food, and Rural Affairs Appeals Tribunal that includes the price of chicks, feed and producer margin.|$|R
50|$|IWTO is the {{international}} body representing {{the interests of the}} world's wool textile trade and industry. IWTO membership covers wool growers, traders, <b>primary</b> <b>processors,</b> spinners, weavers, garment makers and retailers of wool and allied fibers in its member-countries, as well as all kinds of organizations related to wool products and the wool business in general.|$|R
5000|$|... #Caption: Merit PDP-11 based <b>Primary</b> Communications <b>Processor</b> (PCP) at the University of Michigan, c. 1975 ...|$|R
50|$|The EZ80L92 is the <b>primary</b> <b>processor</b> in the ST Robotics robot controller, clocked at 50MHz. It has 128Kb of {{external}} RAM and 128Kb {{of external}} flash memory.|$|E
50|$|To {{standardize}} thermal behavior, processor {{position is}} defined, including {{primary and secondary}} processor identification. For motherboards with only one processor installed, it is recommended the <b>primary</b> <b>processor</b> socket be populated first.|$|E
50|$|The Firefly {{contained}} a <b>primary</b> <b>processor</b> board and zero, one, {{two or three}} secondary processor boards. These processor boards were 8 by 10 inches large. The <b>primary</b> <b>processor</b> board {{contained a}} microprocessor, its floating-point coprocessor and cache, and the Q-Bus control logic. The secondary processor boards each contained two microprocessors, their floating-point coprocessors and caches. The original Firefly processor boards used the MicroVAX 78032 microprocessor and MicroVAX 78132 floating-point coprocessor, but later Firefly systems used the faster CVAX 78034 microprocessors, CVAX Floating Point Chips (floating-point coprocessors). The processor boards communicated {{with each other and}} the memory via the MBus. The components used in the processor boards of the original Firefly were the same as those originally designed for the MicroVAX II system.|$|E
40|$|The declining price anomaly for {{sequential}} {{sales of}} identical commodities challenges auction theory which predicts constant prices within a day. Among other hypotheses explaining the phenomenon stands the dual value of goods including a risk premium in early transactions. We consider that asymmetric bidder groups (<b>primary</b> <b>processors,</b> fishmongers, supermarket buyers) and seasonal landings may also affect the daily price pattern. On {{the basis of}} stylized facts and several panel data models, this hypothesis is tested on a Redundant French fish market of homogenous goods (live Nephrops norvegicus) when the time effects (high and low seasons, weekday effect) affecting the demand and supply conditions are taken into consideration. All models support the evidence of a daily declining pattern, {{but not to the}} same extent for all days and seasons, and all categories of buyers. Our results also show an earlier and steeper decline on periods of lower supply (or higher demand), supporting the theoretical hypothesis of risk-averse behaviors of bidders, especially fishmongers with respect to <b>primary</b> <b>processors</b> and supermarkets...|$|R
40|$|Zooplankton are the <b>primary</b> <b>processors</b> of photosynthetically {{fixed carbon}} in the oceans, and play pivotal roles in {{transferring}} {{matter and energy}} to higher trophic levels (Ingrid et al. 1996, Turner et al. 2001). Zooplankton grazing transfers substantial amounts of organic matter from surface waters to deeper water layers. The magnitude of the downward flux of organic carbon {{is determined by the}} partitioning of carbon among various size classes of grazers. Meso- and macrozooplankton substantially contribute to th...|$|R
40|$|This paper designs {{a set of}} {{evaluation}} indexes of supply chain {{from the perspectives of}} the organization and the operation of supply chains, and constructs an effective matrix. Based on 6 <b>primary</b> <b>processors</b> and further processors, we use AHP to calculate the weight of each index and put the data of sample enterprises in effective matrix of supply chain to valuate effectiveness. We find that there are not strong partnership and perfect communication in pork supply chain, so processing enterprises should integrate with upstream farmers to set up strategic alliance and consolidate information communication...|$|R
50|$|In The Terminator: Dawn of Fate, the Resistance invades Cheyenne Mountain {{in order}} to destroy Skynet's Central Processor. Kyle Reese is {{instrumental}} in destroying the <b>primary</b> <b>processor</b> core despite heavy opposition from attacking Skynet units. Before its destruction, Skynet is able to contact an orbiting satellite and activates a fail-safe which restores Skynet at a new location (presumably the Los Angeles base).|$|E
50|$|The {{first model}} was the DN416 workstation, later {{referred}} to as the DN100 after the green screen was substituted with a black and white screen. This system used two 68000 processors and implemented virtual memory (which the 68000 wasn't theoretically capable of) by stopping one processor when there was a page fault and having the other processor handle the fault, then release the <b>primary</b> <b>processor</b> when the page fault was handled.|$|E
50|$|A {{coprocessor}} is {{a computer}} processor used to supplement {{the functions of the}} <b>primary</b> <b>processor</b> (the CPU). Operations performed by the coprocessor may be floating point arithmetic, graphics, signal processing, string processing, encryption or I/O Interfacing with peripheral devices. By offloading processor-intensive tasks from the main processor, coprocessors can accelerate system performance. Coprocessors allow a line of computers to be customized, so that customers who do not need the extra performance don't need to pay for it.|$|E
40|$|The Magellan {{synthetic}} aperture radar (SAR) produces Venus surface images from data collected by the SAR carried on board the Magellan spacecraft. The core of the <b>primary</b> Magellan SAR <b>processor</b> is the digital correlator subsystem (DCS). The pipeline DSC architecture enables the Magellan <b>primary</b> SAR <b>processor</b> (PSP) to achieve real-time data processing capability. The implementation and performance of the DSC are described. Hardware (H/W) constraints that influenced the processing algorithm design are highlighted...|$|R
50|$|Control of Galaxy IV {{was lost}} on May 19, 1998 when the satellite's <b>primary</b> control <b>{{processor}}</b> failed. The backup control processor {{had suffered a}} previously undetected anomaly, and PanAmSat {{was not able to}} regain control of the spacecraft. Galaxy IV was declared a loss on May 20, 1998. Failure of the <b>primary</b> control <b>processor</b> was attributed to tin whisker growth, a phenomenon in which tendrils grow from solder, causing an electrical short circuit. Engineers believe that a hole developed in the conformal wax coating over the solder, allowing whiskers to develop. The satellite manufacturer, Hughes, has replaced pure tin plating with nickel to alleviate the problem in newer designs, adding 45 to 90 kg per payload.|$|R
50|$|In {{spite of}} these problems, FullWrite {{developed}} a faithful following and some amount of commercial success. Douglas Adams used FullWrite as his <b>primary</b> word <b>processor</b> for some time. Douglas Hofstadter published several of his books directly from FullWrite, notably Le Ton beau de Marot.|$|R
5000|$|The 1st Aero on February 6, 1967, moved {{operations}} to the Group III Space Defense Center, the integrated missile warning/space surveillance facility (496L Spacetrack system with Philco 212 <b>primary</b> <b>processor)</b> at the Cheyenne Mountain nuclear bunker (FOC {{of the new}} bunker's command center—a portion of the Burroughs 425L Command/Control and Missile Warning System—had been on July 1, 1966.) Interim operations of the Avco 474N SLBM Detection and Warning System began in July 1970 (IOC was 5 May 1972), and in 1972 20% of the Bendix AN/FPS-85 Phased Array Radar's surveillance capability [...] "became dedicated to search for SLBMs" [...] (the FPS-85 relayed SLBM data via the 474N network for SLBM warning to [...] "SAC, the National Military Command Center, and the Alternate NMCC over BMEWS circuits").|$|E
5000|$|Much later, the {{channels}} were implemented as an on-board processor {{residing in the}} same box as the CPU, generally {{referred to as a}} [...] "channel processor", and which was usually a RISC processor, but which could be a System/390 microprocessor with special microcode as in IBM's CMOS mainframes. One of the earliest non-IBM channel systems was hosted in the CDC 6600 supercomputer in 1965. The CDC utilized 10 logically independent computers called peripheral processors, or PPs for this role. PPs were powerful, a modern version of CDC's first 'personal computer', the CDC 160A. The operating system resided and executed in the <b>primary</b> <b>processor,</b> PP0. Since then, channel controllers have been a standard part of most mainframe designs and a primary advantage mainframes have over smaller, faster, personal computers and network computing.|$|E
50|$|Video game {{manufacturers}} {{used the}} 68000 as {{the backbone of}} many arcade games and home game consoles: Atari's Food Fight, from 1982, {{was one of the}} first 68000-based arcade games. Others included Sega's System 16, Capcom's CP System and CPS-2, and SNK's Neo Geo. By the late 1980s, the 68000 was inexpensive enough to power home game consoles, such as Sega's Mega Drive (Genesis) console and also the Sega CD attachment for it (A Sega CD system has three CPUs, two of them 68000s). The 1993 multi-processor Atari Jaguar console used a 68000 as a support chip, although some developers used it as the <b>primary</b> <b>processor</b> due to familiarity. The 1994 multi-processor Sega Saturn console used the 68000 as a sound co-processor (much as the Mega Drive/Genesis uses the Z80 as a co-processor for sound and/or other purposes).|$|E
40|$|There {{has been}} {{considerable}} interest in implementing a multithreaded program execution and architecture model on a multiprocessor whose <b>primary</b> <b>processors</b> consist of today's off-the-shelf microprocessors. Unlike some custom-designed multithreaded processor architectures, which can interleave multiple threads concurrently, conventional processors can only execute one thread at a time. This presents {{a unique and}} challenging problem to the compiler: partition a program into threads so that it executes both correctly and in minimal time. We present a new heuristic algorithm based on an interesting extension of the classical list scheduling algorithm. Based on a cost model, our algorithm groups instructions into threads by considering the trade-offs among parallelism, latency tolerance, thread switching costs and sequential execution efficiency. The proposed algorithm has been implemented, and its performance measured through experiments {{on a variety of}} architecture parameters a [...] ...|$|R
50|$|To {{expand the}} network, the Merit staff {{developed}} new hardware interfaces for the Digital PDP-11 based on printed circuit technology. The new system {{became known as}} the <b>Primary</b> Communications <b>Processor</b> (PCP), with the earliest PCPs connecting a PDP-10 located at WMU and a DEC VAX running UNIX at U-M's Electrical Engineering department.|$|R
40|$|A {{computer}} framework {{feasible for}} developing parallel systems {{according to the}} Bulk Synchronous Parallel (BSP) computing model is described: Switched Interconnection of Parallel Processors (Swipp). Demanding applications {{can be described as}} directed graphs where the interdependent subtasks constitute the nodes. The tasks are predistributed by a system master, Computer Executive Engine (CEE), to a set of heterogeneous computing nodes. Each computing node has a preprogrammed secondary control processor attached for performing communication and runtime tasks, thus allowing <b>primary</b> <b>processors</b> of various kinds and programming styles. Synchronization of a bulk of subactivities is done in locksteps by the CEE. Basic features are modelled by the Ptolemy framework and prototype modules are being implemented. I. INTRODUCTION The performance of sequential single CPU processors has been steadily increasing over the last decades due to circuit technology improvements. The von Neumann model of comp [...] ...|$|R
5000|$|The R3000 {{and later}} {{microprocessors}} {{had only a}} typical amount of internal error checking, insufficient for Tandem's needs. So the Cyclone/R ran pairs of R3000 processors in lock step, running the same data thread. It used a curious variation of lock stepping. The checker processor ran 1 cycle behind the <b>primary</b> <b>processor.</b> This allowed them to share a single copy of external code and data caches without putting excessive pinout load on the sysbus and lowering the system clock rate. To successfully run microprocessors in lock step, the chips must be designed to be fully deterministic. Any hidden internal state must be cleared by the chip's reset mechanism. Otherwise, the matched chips will sometimes get out of sync for no visible reason and without any faults, long after the chips are restarted. All chip designers agree that these are good principles because it helps them test chips at manufacturing time. But all new microprocessor chips seemed to have bugs in this area, and required months of shared work between MIPS and Tandem to eliminate or work around the final subtle bugs.|$|E
40|$|Real-time {{multiprocessor}} systems frequently {{assume that}} there exists a dedicated processor for task allocation that never fails. This assumption is, however, too strong {{in the sense that}} all the physical objects are subject to failure. Moreover, once the dedicated processor fails, the whole multiprocessor system will fail. As a way to solve this problem, we propose a fault-tolerant scheduling algorithm based on moving dual-token. While the <b>primary</b> <b>processor</b> holding a primary token performs task allocation, the backup processor holding a backup token, in case that the <b>primary</b> <b>processor</b> has failed, does <b>primary</b> <b>processor</b> creation. Since no dedicated processor for task allocation exists in this scheme, failure of the whole multiprocessor system due to that of the dedicated processor can be avoided. In addition, the deadline-friendly scheduling policy used for backup task allocation, compared to heuristic scheduling, allows easier implementation and improved scheduling predictability. Simulation results show that the proposed dualtoken based algorithm yields low rejection rates over those with dedicated processor for task allocation...|$|E
40|$|While the USDA {{regulation}} {{for meat}} inspection only requires that “all meat {{offered for sale}} must originate from a federally inspected slaughter facility, ” the USDA Food Safety Inspection Service (FSIS) allows two <b>primary</b> <b>processor</b> exemptions to this rule: custom and retail. These exemptions, available in their entirety within the Code of Federal Registers a...|$|E
50|$|He was {{responsible}} for the campaign to design a drop-in replacement for the SAM Coupé <b>primary</b> control <b>processor</b> (ASIC), working with the original hardware designer, Bruce Gordon, and publicized in Your Sinclair magazine. The new ASIC would have improved the capabilities of the computer by adding better sound, graphics and hardware-assisted rendering. It would have cost £50,000 to produce.|$|R
50|$|There are 2567 {{certified}} organic businesses reported in Australia in 2014. They include 1707 <b>primary</b> producers, 719 <b>processors</b> and manufacturers, 141 wholesalers and retailers plus other operators.|$|R
40|$|Abstract—The Standby-Sparing (SS) {{technique}} has been pre-viously explored to improve energy efficiency while providing fault tolerance in dual-processor real-time systems. In this paper, by considering both transient and permanent faults, we develop energy-efficient {{fault tolerance techniques}} for real-time systems deploying an arbitrary number of identical processors. First, we study the Paired-SS technique, where processors are organized as groups of two (i. e., pairs) and SS is applied within each pair of processors directly after partitioning tasks to the pairs. Then, we propose a Generalized-SS technique that partitions processors into two groups containing <b>primary</b> and secondary <b>processors,</b> respectively. The main and backup copies of tasks are executed on the <b>primary</b> and secondary <b>processors</b> under the partitioned-EDF and partitioned-EDL scheduling policies, respectively. The objective {{is to reduce the}} overlapped executions of the main and backup copies in order to improve energy savings. Our experimental evaluations show that, for a given system with fixed number of processors, typically there exists a configuration of <b>primary</b> and secondary <b>processors</b> under the Generalized-SS technique that can lead to better energy savings when compared to the Paired-SS technique. I...|$|R
40|$|Abstract—Energymanagement andreliabilityaretwoimportantdesignobjectivesforreal-timeembeddedsystems. Recently, the standby-sparing {{scheme that}} uses a <b>primary</b> <b>{{processor}}</b> and a spare processor has been exploited to provide fault tolerance while keeping the energy consumption under control through DVSandDPMtechniques. Inthispaper,weconsiderthestandbysparingtechniqueforfixed-priorityperiodicreal-timetasks. We propose a dual-queue mechanism through which the execution of backup tasks are maximally delayed, as well as online algorithms to manage energy consumption. Our experimental {{results show that the}} proposed scheme provides energy savings overtime-redundancybasedtechniqueswhileofferingreliability improvements. I...|$|E
40|$|Currently, {{the single}} screw {{extruder}} (SSE) {{is not a}} <b>primary</b> <b>processor</b> of RPVC dry blend because they have required a complex vacuum hopper and a crammer feeder. Conical twin screw extruders (TSE), being capable of processing RPVC dry blend {{without the use of}} a crammer feeder or vacuum hopper has therefore dominated RPVC dry blend processing. A new SSE is introduced that overcomes the need for a vacuum hopper and a crammer feeder with a simple screw design. This paper presents data on an SSE showing simple processing of RPVC dry blend with a surprising increase in screw speed to 180 rpm and output at only 174 °C, vented, starved or flood fed...|$|E
40|$|The {{exploration}} of techniques to accelerate big data applicationshas been an active area of research. Although we have highly efficient computing cores and high-speed networks, the bottleneck in most big data applications {{has been the}} latency of data access. The foremost contributors to this latency are the network communication, storage systems, software stack and data transfer. Heterogeneous co-processors, FPGA accelerators, and flash based storage accelerators try to overcome this latency by offloading processing from the <b>primary</b> <b>processor,</b> but these cause additional overheads to an already costly data-center server and increase the total deployment cost. With an ever growing size of data, the need to exploit the available resources in the <b>primary</b> <b>processor</b> while achieving the best possible performance becomes increasingly necessary. A humble performance improvement of even 1 % {{goes a long way}} in a typical data center environment. Consequently, this work evaluates the effectiveness of Data Direct Input Output (DDIO) commonly known as Direct Cache Access (DCA) for I/O intensive big data workloads. We begin with a survey of various kinds and characteristics of big data workloads and then present the performance gain/loss due to DCA for I/O intensive workloads on Xeon E 5 based servers. The big data applications are considerably different from the workloads traditionally used in architectural studies hence micro-benchmarks are used to emulate workloads which could gain/lose considerable performance when using direct cache access. Also, we present the performance of I/O intensive tasks from state of the art Cloudsuite benchmark suite. We finally make a case for the dynamic use of DCA in the processor for better performance of big data applications (change the percentage of cache available for DDIO to use or the cache levels DCA can access) ...|$|E
40|$|This {{paper was}} {{presented}} at the annual meeting of the Canadian Agricultural Economics Society (Montreal, July 2003). Papers presented at CAES meetings are not subjected to the journal’s standard refereeing process. The Issue The grain handling sector in Canada and the United States is vital to agriculture and trade. In a typical year on the Canadian prairies, about 140, 000 producers deliver some 20 to 30 mmt of grain for export to primary elevators. In the United States, about 2. 1 million producers deliver about 300 mmt of grain to primary elevators. Canadian grain is moved to export position using more than 400, 000 hopper cars and marine containers, where about 1, 200 ships per year are loaded. In the United States, about 1. 08 million rail carloads of grain are originated per year, and about 23 mmt of grain are shipped on barges per year. These U. S. figures are in addition to trucks, which, more so than in Canada, are also used to deliver grain to <b>primary</b> <b>processors</b> and to terminal and export markets...|$|R
40|$|Biologically based {{systems are}} under {{evaluation}} as <b>primary</b> water <b>processors</b> for next generation {{life support systems}} due to their low power requirements and their inherent regenerative nature. This paper will summarize the results of two recent studies involving membrane aerated biological water processors and present results of a trade study comparing the two systems with regards to waste stream composition, nutrient loading and system design. Results of optimal configurations will be presented...|$|R
50|$|WriteNow {{was one of}} the two {{original}} {{word processor}} applications developed for the launch of the Apple Macintosh in 1984, and was the <b>primary</b> word <b>processor</b> for computers manufactured by NeXT. WriteNow was purchased from T/Maker by WordStar in 1993, but shortly after that, WordStar was purchased by The Learning Company, which ended sales. It remains fondly remembered to this day, for a combination of powerful features, excellent performance, and small system requirements.|$|R
