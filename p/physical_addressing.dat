27|1446|Public
25|$|CAN bus {{may also}} be used for {{communication}} beyond the standard OBD messages. <b>Physical</b> <b>addressing</b> uses particular CAN IDs for specific modules (e.g., 720h for the instrument cluster in Fords) with proprietary frame payloads.|$|E
5000|$|The {{disadvantages}} {{of having an}} IOMMU, compared to direct <b>physical</b> <b>addressing</b> of the memory, include: ...|$|E
5000|$|MIPS P5600 {{multiprocessor}} core (MIPS32 Release 5): hardware virtualization with hardware table walk, 128-bit SIMD, 40-bit eXtended <b>Physical</b> <b>Addressing</b> (XPA) ...|$|E
5000|$|... 32-bit linear {{addresses}} are virtual <b>addresses</b> {{rather than}} <b>physical</b> addresses; they are translated to <b>physical</b> <b>addresses</b> through a page table. In the 80386, 80486, {{and the original}} Pentium processors, the <b>physical</b> <b>address</b> was 32 bits; in the Pentium Pro and later processors, the <b>Physical</b> <b>Address</b> Extension allowed 36-bit <b>physical</b> <b>addresses,</b> although the linear address size was still 32 bits.|$|R
5000|$|When {{operating}} in legacy mode the AMD64 architecture supports <b>Physical</b> <b>Address</b> Extension (PAE) mode, as do most current x86 processors, but AMD64 extends PAE from 36 bits to an architectural limit of 52 bits of <b>physical</b> <b>address.</b> Any implementation therefore allows the same <b>physical</b> <b>address</b> limit as under long mode.|$|R
5000|$|... 24-bit <b>physical</b> <b>address</b> space, 16 Mbyte <b>physical</b> memory <b>address</b> space ...|$|R
50|$|The first CPUs {{implementing}} the x86-64 architecture, namely the AMD Athlon 64 / Opteron (K8) CPUs, had 48-bit virtual and 40-bit <b>physical</b> <b>addressing.</b>|$|E
5000|$|A {{microprocessor}} typically has {{a number}} of addressing lines equal to the base-two logarithm of its <b>physical</b> <b>addressing</b> space. For example, a processor with 4 GB of <b>physical</b> <b>addressing</b> space requires 32 lines, which are named A0 through A31. The lines are named after the zero-based number of the bit in the address that they are transmitting. The least significant bit is first and is therefore numbered bit 0 and signaled on line A0. A20 transmits bit 20 (the 21st bit) and becomes active once addresses reach 1 MB, or 220.|$|E
50|$|CAN bus {{may also}} be used for {{communication}} beyond the standard OBD messages. <b>Physical</b> <b>addressing</b> uses particular CAN IDs for specific modules (e.g., 720h for the instrument cluster in Fords) with proprietary frame payloads.|$|E
5000|$|... 32-bit <b>physical</b> <b>address</b> space, 4 Gbyte <b>physical</b> memory <b>address</b> space ...|$|R
5000|$|Aliasing: Multiple virtual {{addresses}} can map to {{a single}} <b>physical</b> <b>address.</b> Most processors guarantee that all updates to that single <b>physical</b> <b>address</b> will happen in program order. To deliver on that guarantee, the processor must ensure that only one copy of a <b>physical</b> <b>address</b> resides in the cache at any given time.|$|R
25|$|The Large <b>Physical</b> <b>Address</b> Extension (LPAE), {{which extends}} the <b>physical</b> <b>address</b> size from 32 bits to 40 bits, {{was added to}} the ARMv7-A {{architecture}} in 2011.|$|R
5000|$|Distribution: Lock server and 64-bit object IDs support dynamic {{addressing}} space (with each federation capable of managing up to 65,535 individual databases and 10^24 bytes (one quadrillion gigabytes, or a yottabyte) of <b>physical</b> <b>addressing</b> space).|$|E
50|$|MBus {{specified}} a 64-bit datapath, {{which used}} 36-bit <b>physical</b> <b>addressing,</b> giving an address space of 64 GB. The transfer rate is 80 MB/s sustained (320 MB/s peak) at 40 MHz, or 100 MB/s (400 MB/s peak) at 50 MHz. Bus controlling {{is done by}} an arbiter. Interrupt, reset, and timeout logic are also specified.|$|E
50|$|This {{data set}} allows for <b>physical</b> <b>addressing,</b> which {{allows it to}} be used by systems such as that Operating systems. The benefit of this is that systems such as the OS can access {{multiple}} disk spindles and view it as a single storage implementation. The limitations of this, though, is that this does not make this particularly useful to higher level abstraction levels.|$|E
5000|$|... 40-bit Large <b>Physical</b> <b>Address</b> Extensions (LPAE) {{addressing}} up to 1 TB of RAM. As per the x86 <b>Physical</b> <b>Address</b> Extension, {{virtual address}} space remains 32 bit.|$|R
5000|$|In {{protected}} mode, {{introduced in}} the 80286, a segment register no longer contains the <b>physical</b> <b>address</b> {{of the beginning of}} a segment, but contain a [...] "selector" [...] that points to a system-level structure called a segment descriptor. A segment descriptor contains the <b>physical</b> <b>address</b> of the beginning of the segment, the length of the segment, and access permissions to that segment. The offset is checked against the length of the segment, with offsets referring to locations outside the segment causing an exception. Offsets referring to locations inside the segment are combined with the <b>physical</b> <b>address</b> of the beginning of the segment to get the <b>physical</b> <b>address</b> corresponding to that offset.|$|R
50|$|An iconic {{example of}} virtual-to-physical address {{translation}} is virtual memory, where different pages of virtual address space map either to page file or to main memory <b>physical</b> <b>address</b> space. It {{is possible that}} several numerically different virtual addresses all refer to one <b>physical</b> <b>address</b> and hence to the same physical byte of RAM. It {{is also possible that}} a single virtual address maps to zero, one, or more than one <b>physical</b> <b>address.</b>|$|R
50|$|Although the D620 {{accepts a}} maximum of 4 GB of {{physical}} memory, it cannot be used fully, because of the 32-bit <b>physical</b> <b>addressing</b> limitation of the 945 Core 2 mobile chipsets Intel-945GM/PM-chipset, (not related to the BIOS {{or the use of}} a 32-bit or 64-bit OS), restricts the usable memory by the operating system to 3.5 GB, or 3.3 GB with on board video (memory is shared).|$|E
50|$|In {{a general}} purpose {{computer}} system, which requires multitasking, resource allocation and protection, the flat memory system must be augmented by some memory management scheme, which is typically implemented {{through a combination of}} dedicated hardware (inside or outside the CPU) and software built into the operating system. The flat memory model (at the <b>physical</b> <b>addressing</b> level) still provides the greatest flexibility for implementing this type of memory management.|$|E
5000|$|In {{computer}} architecture, 31-bit integers, memory addresses, {{or other}} data units {{are those that}} are 31 bits wide. In 1983, IBM introduced 31-bit addressing in the System/370-XA mainframe architecture as an upgrade to the 24-bit physical and virtual, and transitional 24-bit-virtual/26-bit <b>physical,</b> <b>addressing</b> of earlier models. This enhancement allowed address spaces to be 128 times larger, permitting programs to address memory above 16 MiB (referred to as [...] "above the line").|$|E
50|$|For {{privacy and}} other purposes, postal {{services}} {{have made it}} possible to receive mail without revealing one's <b>physical</b> <b>address</b> or even having a fixed <b>physical</b> <b>address.</b> Examples are post office boxes, service addresses and poste restante (general delivery).|$|R
50|$|MIPS32 and MIPS32r2 support 32 bits {{of virtual}} address space {{and up to}} 36 bits of <b>physical</b> <b>address</b> space. MIPS64 {{supports}} up to 64 bits of virtual address space and up to 59 bits of <b>physical</b> <b>address</b> space.|$|R
50|$|A page {{table is}} the data {{structure}} {{used by a}} virtual memory system in a computer operating system to store the mapping between virtual <b>addresses</b> and <b>physical</b> <b>addresses.</b> Virtual addresses are used by the accessing process, while <b>physical</b> <b>addresses</b> are used by the hardware, or more specifically, by the RAM subsystem.|$|R
50|$|As {{defined by}} Sitarski, a hashed array tree has a {{top-level}} directory containing {{a power of}} two number of leaf arrays. All leaf arrays are {{the same size as}} the top-level directory. This structure superficially resembles a hash table with array-based collision chains, which is the basis for the name hashed array tree. A full hashed array tree can hold m2 elements, where m is the size of the top-level directory. The use of powers of two enables faster <b>physical</b> <b>addressing</b> through bit operations instead of arithmetic operations of quotient and remainder and ensures the O(1) amortized performance of append operation in the presence of occasional global array copy while expanding.|$|E
5000|$|The {{limit of}} <b>physical</b> <b>addressing</b> {{constrains}} how much installed RAM {{is able to}} be accessed by the computer. On a ccNUMA multiprocessor system (Opteron) this includes the memory which is installed in the remote nodes, because the CPUs can directly address (and cache) all memory regardless if {{it is on the}} home node or remote. The 1 TB limit (40-bit) for physical memory for the K8 is huge by typical personal computer standards, but might have been a limitation for use in supercomputers. Consequently, the K10 (or [...] "10h") microarchitecture implements 48-bit physical addresses and so can address up to 256 TB of RAM.|$|E
5000|$|Some {{programs}} predating the 80286 {{were designed}} {{to take advantage of}} the wrap-around (modulo) memory addressing behavior, so the 80286 presented a problem for backward compatibility. Forcing the 21st address line (the actual logic signal wire coming out of the chip) to a logic low, representing a zero, results in a modulo-2^20 effect to match the earlier processors' address arithmetic, but the 80286 has no internal capability to perform this function. When IBM used the 80286 in their IBM Personal Computer AT, they solved this problem by including a software-settable gate to enable or disable (force to zero) the A20 address line, between the A20 pin on the 80286 and the system bus; this is known as Gate-A20 (the A20 gate), and it is still implemented in PC chipsets to this day. Most versions of the HIMEM.SYS extended memory driver for IBM-/MS-DOS famously displayed upon loading a message that they had installed an [...] "A20 handler", a piece of software to control Gate-A20 and coordinate it to the needs of programs. In protected mode the A20 line needs to be enabled, or else <b>physical</b> <b>addressing</b> errors will occur, likely leading to a system crash.|$|E
2500|$|MIPS32 and MIPS32r2 support 32 bits {{of virtual}} address space {{and up to}} 36 bits of <b>physical</b> <b>address</b> space. [...] MIPS64 {{supports}} up to 64 bits of virtual address space and up to 59 bits of <b>physical</b> <b>address</b> space.|$|R
50|$|The TLB is {{sometimes}} implemented as content-addressable memory (CAM). The CAM search key is the virtual address {{and the search}} result is a <b>physical</b> <b>address.</b> If the requested address {{is present in the}} TLB, the CAM search yields a match quickly and the retrieved <b>physical</b> <b>address</b> can be used to access memory. This is called a TLB hit. If the requested address is not in the TLB, it is a miss, and the translation proceeds by looking up the page table in a process called a page walk. The page walk is time consuming when compared to the processor speed, as it involves reading the contents of multiple memory locations and using them to compute the <b>physical</b> <b>address.</b> After the <b>physical</b> <b>address</b> is determined by the page walk, the virtual <b>address</b> to <b>physical</b> <b>address</b> mapping is entered into the TLB. The PowerPC 604, for example, has a two-way set-associative TLB for data loads and stores. Some processors have different instruction and data address TLBs.|$|R
5000|$|Increase from 32-bit (4 GiB) to 36-bit (64 GiB) <b>physical</b> <b>address</b> space. This change {{means that}} e500v2-based devices often use a more {{advanced}} board support package (BSP) than e500v1-based devices, as various peripheral units have moved to <b>physical</b> <b>addresses</b> higher than 4 GiB.|$|R
50|$|While tiering {{solutions}} and caching may {{look the same}} on the surface, the fundamental differences lie {{in the way the}} faster storage is utilized and the algorithms used to detect and accelerate frequently accessed data. SSD caching operates much like SRAM-DRAM caches do i.e. they make a copy of frequently accessed blocks of data, for example in 4K cache page sizes, and store the copy in the SSD and use this copy instead of the original data source on the slower backend storage. Every time a storage IO occurs, the caching software look to see if a copy of this data already exists using a variety of algorithms and service the host request from the SSD if it is found. The SSD is used in this case as a lookaside device as it {{is not part of the}} primary storage. While some good caching algorithms can demonstrate native SSD performance on reads and short bursts of writes, caching typically operates well below the maximum sustainable rate of the underlying SSD devices as overhead CPU cycles are introduced during the host IO commands that increasingly impact performance as the amount of data cached grows. Tiering on the other hand operates very differently. Using the specific case of SSDs, once data is identified as frequently used, the identified blocks of data are moved in the background to the SSD and not copied as the SSD is being utilized as a primary storage tier, not a look aside copy area. When the data is subsequently accessed, the IOs occur at or near the native performance of the SSDs as there area are few if any CPU cycles needed to do the simpler virtual to <b>physical</b> <b>addressing</b> translations.|$|E
40|$|Abstract: The present work {{is about}} an {{advanced}} architecture for generating video signals from microprocessor-based systems. This architecture is a solution for real time image processing hardware/software systems which require a significant recording time and uses a reduced area of <b>physical</b> <b>addressing</b> of microprocessor-based systems. This solution investigates both the Fast <b>Physical</b> <b>Addressing</b> and the simultaneous video memory read-write system. This latter is ensured by a split of the hardware video memory in separate capacities and by association of a selecting circuit...|$|E
40|$|This {{research}} {{describes the}} Extended <b>Physical</b> <b>Addressing</b> bus transactions between the microprocessor-based {{systems and the}} external peripherals. This addressing technique, based {{on the use of}} software/hardware systems and reduced physical addresses, enlarges the interfacing capacity of the microprocessor-based systems and improves the speed of data exchange. The input of our system hardware part will be connected to the system bus. The output, which is a new bus, will be connected to an external device. To accomplish the bus transactions, the hardware part realizes a conversion of system bus data into new bus addresses. Furthermore, the software part ensures the transfer, with distinct addresses, of the simple data and the data that is intended to be converted. The use of this system with two system addresses and N bit data bus gives a new bus with N bit data bus and 2 N <b>physical</b> <b>addressing</b> capacity...|$|E
5000|$|The stationâ€™s <b>physical</b> <b>address</b> is:Witsieshoek, Phuthaditjhaba ...|$|R
5000|$|Virtually indexed, {{physically}} tagged (VIPT) caches use {{the virtual}} address for the index and the <b>physical</b> <b>address</b> in the tag. The advantage over PIPT is lower latency, as the cache {{line can be}} looked up in parallel with the TLB translation, however the tag cannot be compared until the <b>physical</b> <b>address</b> is available. The advantage over VIVT is that since the tag has the <b>physical</b> <b>address,</b> the cache can detect homonyms. VIPT requires more tag bits, as the index bits no longer represent the same address.|$|R
5000|$|A {{legitimate}} <b>physical</b> <b>address</b> of {{the publisher}} and/or advertiser is present. PO Box addresses are acceptable {{in compliance with}} [...] and if the email is sent by a third party, the legitimate <b>physical</b> <b>address</b> of the entity, whose products or services are promoted through the email should be visible.|$|R
