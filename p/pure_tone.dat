1531|668|Public
5|$|Mole crickets {{have three}} life stages, eggs, nymphs, and adults. Most {{of their life}} in these stages is spent underground, but adults have wings and {{disperse}} in the breeding season. They vary in their diet; some species are vegetarian, mainly feeding on roots, others are omnivores, including worms and grubs in their diet, while a few are largely predatory. Male mole crickets have an exceptionally loud song; they sing from a subsurface burrow that opens out into {{the air in the}} shape of an exponential horn. The song is an almost <b>pure</b> <b>tone,</b> modulated into chirps. It is used to attract females, either for mating, or for indicating favourable habitats for them to lay their eggs.|$|E
5|$|Male mole crickets sing by stridulating, always underground. In Gryllotalpa gryllotalpa {{the song}} {{is based on an}} almost <b>pure</b> <b>tone</b> at 3.5 kiloHertz, loud enough to make the ground vibrate 20cm all round the burrow; in fact {{the song is}} unique in each species. In Gryllotalpa gryllotalpa the burrow is {{somewhat}} roughly sculpted; in Gryllotalpa vineae, the burrow is smooth and carefully shaped, with no irregularities larger than 1 millimetre. In both species the burrow {{takes the form of a}} double exponential horn with twin openings at the soil surface; at the other end there is a constriction, then a resonating bulb, and then an escape tunnel. A burrow is used for at least a week. The male positions himself head down with his head in the bulb, his tail near the fork in the tunnel.|$|E
25|$|Tests of {{auditory}} system (hearing) function include <b>pure</b> <b>tone</b> audiometry, speech audiometry, acoustic reflex, electrocochleography (ECoG), otoacoustic emissions (OAE), and {{the auditory}} brainstem response test.|$|E
5000|$|... #Subtitle level 2: Biological Explanation via Theories of Pitch of <b>Pure</b> <b>Tones</b> ...|$|R
40|$|Researchers {{from the}} University of Georgia and Berry College {{recently}} completed a project designed to evaluate the impact of <b>pure</b> <b>tones</b> (i. e., continuous sounds at one frequency) coming from moving vehicles on roadside deer behavior. The {{results of this study}} are summarized here. The researchers stated that the frequencies of the <b>pure</b> <b>tones</b> investigated i...|$|R
40|$|Doppler shift {{compensation}} behaviour in horseshoe bats, Rhinolophus rouxi, {{was used}} to test the interference of <b>pure</b> <b>tones</b> and narrow band noise with compensation performance. The distortions in Doppler shift compensation to sinusoidally frequency shifted echoes (modulation frequency: 0. 1 Hz, maximum frequency shift: 3 kHz) consisted of a reduced compensation amplitude and/or a shift of the emitted frequency to lower frequencies (Fig. 1). <b>Pure</b> <b>tones</b> at frequencies between 200 and 900 Hz above the bat's resting frequency (RF) disturbed the Doppler shift compensation, with a maximum of intererence between 400 and 550 Hz (Fig. 2). Minimum duration of <b>pure</b> <b>tones</b> for interference was 20 ms and durations above 40 ms were most effective (Fig. 3). Interfering <b>pure</b> <b>tones</b> arriving later than about 10 ms after the onset of the echolocation call showed markedly reduced interference (Fig. 4). Doppler shift compensation was affected by <b>pure</b> <b>tones</b> at the optimum interfering frequency with sound pressure levels down to – 48 dB rel the intensity level of the emitted call (Figs. 5, 6). Narrow bandwidth noise (bandwidth from ± 100 Hz to ± 800 Hz) disturbed Doppler shift compensation at carrier frequencies between – 250 Hz below and 800 Hz above RF with a maximum of interference between 250 and 500 Hz above resting frequency (Fig. 7). The duration and delay of the noise had similar influences on interference with Doppler shift compensation as did <b>pure</b> <b>tones</b> (Figs. 8, 9). Intensity dependence for noise interference was more variable than for <b>pure</b> <b>tones</b> (- 32 dB to - 45 dB rel emitted sound pressure level, Fig. 10). The temporal and spectral gating in Doppler shift compensation behaviour is discussed as an effective mechanism for clutter rejection by improving the processing of frequency and amplitude transients in the echoes of horseshoe bats. ...|$|R
25|$|For example, if a 530Hz <b>pure</b> <b>tone</b> is {{presented}} to a subject's right ear, while a 520Hz <b>pure</b> <b>tone</b> {{is presented}} to the subject's left ear, the listener will perceive the auditory illusion of a third tone, {{in addition to the}} two pure-tones presented to each ear. The third sound is called a binaural beat, and in this example would have a perceived pitch correlating to a frequency of 10Hz, that being the difference between the 530Hz and 520Hz pure tones presented to each ear.|$|E
25|$|The {{boundary}} layer on the airfoil of a glider is laminar and vortex shedding {{similar to that}} of a cylinder occurs at the trailing edge. The sound can be a nearly <b>pure</b> <b>tone.</b>|$|E
25|$|When a {{rectangular}} jet impinges on a sharp edged object {{such as a}} wedge, a feedback loop can be established resulting in a nearly <b>pure</b> <b>tone.</b> The figure on the right shows schematically the circulation of two vortices as they pass the wedge. This simple diagram {{suggests that there is}} a force applied to the wedge whose angle varies as the vortices pass.|$|E
2500|$|... the 'intermittent-beam sounder' – used in {{spectral}} analysis {{and in the}} generation of <b>pure</b> <b>tones</b> (1880); ...|$|R
50|$|The tubes used {{provide a}} <b>purer</b> <b>tone</b> than solid {{cylindrical}} chimes, {{such as those}} on a mark tree.|$|R
40|$|Interaural level {{differences}} (ILDs) are {{the dominant}} cue for localizing {{the sources of}} high frequency sounds that differ in azimuth. Neurons in the primary auditory cortex (A 1) respond differentially to ILDs of simple stimuli such as tones and noise bands, but {{the extent to which}} this applies to complex natural sounds, such as vocalizations, is not known. In sufentanil/N 2 O anaesthetized marmosets, we compared the responses of 76 A 1 neurons to three vocalizations (Ock, Tsik and Twitter) and <b>pure</b> <b>tones</b> at cells’ characteristic frequency. Each stimulus was presented with ILDs ranging from 20 dB favouring the contralateral ear to 20 dB favouring the ipsilateral ear to cover most of the frontal azimuthal space. The response to each stimulus was tested at three average binaural levels (ABLs). Most neurons were sensitive to ILDs of vocalizations and <b>pure</b> <b>tones.</b> For all stimuli, the majority of cells had monotonic ILD sensitivity functions favouring the contralateral ear, but we also observed ILD sensitivity functions that peaked near the midline and functions favouring the ipsilateral ear. Representation of ILD in A 1 was better for <b>pure</b> <b>tones</b> and the Ock vocalization in comparison to the Tsik and Twitter calls; this was reflected by higher discrimination indices and greater modulation ranges. ILD sensitivity was heavily dependent on ABL: changes in ABL by ± 20 dB SPL from the optimal level for ILD sensitivity led to significant decreases in ILD sensitivity for all stimuli, although ILD sensitivity to <b>pure</b> <b>tones</b> and Ock calls was most robust to such ABL changes. Our results demonstrate differences in ILD coding for <b>pure</b> <b>tones</b> and vocalizations, showing that ILD sensitivity in A 1 to complex sounds cannot be simply extrapolated from that to <b>pure</b> <b>tones.</b> They also show A 1 neurons do not show level-invariant representation of ILD, suggesting that such a representation of auditory space is likely to require population coding, and further processing at subsequent hierarchical stages...|$|R
25|$|Since most {{persons with}} {{tinnitus}} also have hearing loss, a <b>pure</b> <b>tone</b> hearing test {{resulting in an}} audiogram may help diagnose a cause, though some persons with tinnitus do not have hearing loss. An audiogram may also facilitate fitting of a hearing aid in those cases where hearing loss is significant. The pitch of tinnitus is often {{in the range of}} the hearing loss.|$|E
25|$|The {{disturbance}} in the jet is a symmetric vortex ring that moves at some speed {{slower than the}} mean jet speed until it encounters the hole and some fluid is forced through it, resulting in a monopole-like sound field in the half space outside. The oscillatory volumetric flow in the hole sends a wave back to the orifice to complete the feedback loop and causing a nearly <b>pure</b> <b>tone.</b>|$|E
25|$|The {{simplest}} {{gravitational waves}} are those with constant frequency. The waves given {{off by a}} spinning, non-axisymmetric neutron star would be approximately monochromatic: a <b>pure</b> <b>tone</b> in acoustics. Unlike signals from supernovae of binary black holes, these signals evolve little in amplitude or frequency over the period it would be observed by ground-based detectors. However, {{there would be some}} change in the measured signal, because of Doppler shifting caused by the motion of the Earth. Despite the signals being simple, detection is extremely computationally expensive, because of the long stretches of data that must be analysed.|$|E
40|$|SummaryWhereas {{extensive}} neuroscientific {{and behavioral}} evidence has confirmed a role of auditory-visual integration in representing space [1 – 6], {{little is known}} about the role of auditory-visual integration in object perception. Although recent neuroimaging results suggest integrated auditory-visual object representations [7 – 11], substantiating behavioral evidence has been lacking. We demonstrated auditory-visual integration in the perception of face gender by using <b>pure</b> <b>tones</b> that are processed in low-level auditory brain areas and that lack the spectral components that characterize human vocalization. When androgynous faces were presented together with <b>pure</b> <b>tones</b> in the male fundamental-speaking-frequency range, faces were more likely to be judged as male, whereas when faces were presented with <b>pure</b> <b>tones</b> in the female fundamental-speaking-frequency range, they were more likely to be judged as female. Importantly, when participants were explicitly asked to attribute gender to these <b>pure</b> <b>tones,</b> their judgments were primarily based on relative pitch and were uncorrelated with the male and female fundamental-speaking-frequency ranges. This perceptual dissociation of absolute-frequency-based crossmodal-integration effects from relative-pitch-based explicit perception of the tones provides evidence for a sensory integration of auditory and visual signals in representing human gender. This integration probably develops because of concurrent neural processing of visual and auditory features of gender...|$|R
50|$|Underwater, {{humans are}} much less able than in air to tell where a sound came from. Research showed that what ability remains is better with bang!-type noises than with <b>pure</b> <b>tones.</b>|$|R
50|$|A {{harmonic}} {{series is}} {{the sequence of}} sounds - <b>pure</b> <b>tones,</b> represented by sinusoidal waves - in which the frequencyof each sound is an integer multiple of the fundamental, the lowest frequency.|$|R
25|$|Blowing {{over the}} edge of a jug or bottle can create a nearly <b>pure</b> <b>tone</b> of low frequency. The driving force is the flow over the jug edge so one might expect an edge tone dipole sound field. In this case, The {{curvature}} and roundness of the edge makes a strong edge tone unlikely. Any periodicity at the edge is likely submerged in the Class III feedback from the jug volume. The unsteady edge flow sets up a classical Helmholtz resonator response in which the interior geometry and the jug neck determines the resultant frequency. A resonance equation is shown below.|$|E
25|$|Fetuses between 32 and 39 weeks {{gestation}} {{were presented}} a <b>pure</b> <b>tone</b> (CS), which was {{paired with a}} vibroacoustic stimulus (US). A vibroacoustic stimulus is a low bass sound frequency that is felt by the fetus as a mechanical vibration. After 10-20 pairings, approximately 50% of the fetuses showed successful conditioning, unrelated to age or sex of the fetus. It is suggested that poorly prepared experimental set up, inaccurate or inappropriate response measures and unsuitable stimuli could all contribute to failed conditioning, as opposed to lack of fetal memory. Reasons for some fetuses demonstrating conditioning, while others do not, remains undetermined.|$|E
25|$|The {{figure on}} the right shows an example. A {{boundary}} layer flow was created {{on both sides of}} a thin rigid flat plate which terminated with a square trailing edge. Note the nearly <b>pure</b> <b>tone</b> at 2000Hz with a Strouhal number of 0.21 protruding above the turbulent sound spectrum. Once again the magic number of Strouhal appears. The characteristic speed was the mean speed of the jet, U and the characteristic dimension was chosen as the trailing edge thickness t. The better characteristic dimension would have been the boundary layer thickness, but fortunately the two dimensions were almost the same. The measured sound field was clearly dipole-like (modified slightly by the plate presence).|$|E
50|$|The {{sound level}} meter is useless for {{properly}} assessing noise levels, since the commonly used A-weighting is based on equal-loudness contours for <b>pure</b> <b>tones,</b> and is not valid for the random noise.|$|R
25|$|A-weighting is {{only really}} valid for {{relatively}} quiet sounds and for <b>pure</b> <b>tones</b> {{as it is}} based on the 40-phon Fletcher–Munson curves which represented an early determination of the equal-loudness contour for human hearing.|$|R
5000|$|... 468-weighting {{is still}} {{demanded by the}} BBC and many other broadcasters, with {{increasing}} awareness of its existence {{and the fact that}} it is more valid on random noise where <b>pure</b> <b>tones</b> do not exist.|$|R
25|$|Later, {{in early}} 1980s, {{listening}} tests {{were carried out}} on synthetic speech stripped of acoustic cues to assess their significance. Time-varying formant frequencies and amplitudes derived by linear predictive coding were synthesized additively as <b>pure</b> <b>tone</b> whistles. This method is called sinewave synthesis. Also the composite sinusoidal modeling (CSM) used on a singing speech synthesis feature on Yamaha CX5M (1984), is known to use a similar approach which was independently developed during 19661979. These methods are characterized by extraction and recomposition {{of a set of}} significant spectral peaks corresponding to the several resonance modes occurred in the oral cavity and nasal cavity, in a viewpoint of acoustics. This principle was also utilized on a physical modeling synthesis method, called modal synthesis.|$|E
25|$|A {{system with}} high quality factor (Qnbsp&>nbsp&) {{is said to}} be underdamped. Underdamped systems combine {{oscillation}} at a specific frequency with a decay of the amplitude of the signal. Underdamped systems with a low quality factor (a little above Q =nbsp&) may oscillate only once or a few times before dying out. As the quality factor increases, the relative amount of damping decreases. A high-quality bell rings with a single <b>pure</b> <b>tone</b> {{for a very long time}} after being struck. A purely oscillatory system, such as a bell that rings forever, has an infinite quality factor. More generally, the output of a second-order low-pass filter with a very high quality factor responds to a step input by quickly rising above, oscillating around, and eventually converging to a steady-state value.|$|E
500|$|Like Green, {{who made}} {{particular}} mention of Beiderbecke's [...] "amount of teaching," [...] the jazz historian Ted Gioia also has emphasized Beiderbecke's lack of formal instruction, {{suggesting that it}} caused him to adopt [...] "an unusual, dry embouchure" [...] and [...] "unconventional fingerings," [...] which he retained {{for the rest of}} his life. Gioia points to [...] "a characteristic streak of obstinacy" [...] in Beiderbecke that provokes [...] "this chronic disregard of the tried-and-true." [...] He argues that this stubbornness was behind Beiderbecke's decision not to switch from cornet to trumpet when many other musicians, including Armstrong, did so. In addition, Gioia highlights Beiderbecke's precise timing, relaxed delivery, and <b>pure</b> <b>tone,</b> which contrasted with [...] "the dirty, rough-edged sound" [...] of King Oliver and his protégé Armstrong, whose playing was often more energetic and whose style held more sway early in the 1920s than Beiderbecke's. Gioia further wonders whether the many hyperbolic and quasi-poetic descriptions of Beiderbecke's style—most notably Condon's [...] "like a girl saying yes"—may indicate that Beiderbecke's sound was muddled on recordings.|$|E
25|$|Air Force blue colours are {{a variety}} of colours that are mostly various tones of the colour azure, the <b>purest</b> <b>tones</b> of which are {{identified}} as being the colour of the sky on a clear day.|$|R
50|$|His {{voice was}} not large {{but it was}} {{exceptionally}} <b>pure</b> <b>toned</b> and sweet, lacking any disruptive vibrato. He sang legato passages with impressive smoothness but he could also dispatch florid music with flair and considerable agility.|$|R
40|$|In {{the last}} few years, Functional Magnetic Resonance Imaging (fMRI) has been widely {{accepted}} as an effective tool for mapping brain activities in both the neurosensorial and the cognitive field. The present work aims to assess {{the possibility of using}} fMRI methods to perform a non-invasive evaluation of the human auditory function. To this end the cortical response to different non speech stimuli (<b>pure</b> <b>tones,</b> pulsed tones) was examined for ten subjects with no audiological impairment. Our findings point out some remarkable differences in both the spatial and the temporal features of the primary auditory cortex response to pulsed <b>tones</b> and to <b>pure</b> <b>tones...</b>|$|R
500|$|Mole crickets stridulate {{like other}} crickets by {{scraping}} the rear {{edge of the}} left forewing, which forms a plectrum, against the lower surface of the right forewing, which has a ratchet-like series of asymmetric teeth: the more acute edges face backwards, as do those of the plectrum. The plectrum can move forwards with little resistance; but moving it backwards makes it catch each tooth, setting up a vibration in both wings. The sound-producing stroke is the raising (levation) of the wings. The resulting song resembles the result of modulating a <b>pure</b> <b>tone</b> with a 66 Hertz wave to form regular chirps. In G. vineae, the wing levator muscle, which weighs 50 milligrams, can deliver 3.5 milliWatts of mechanical power; G. gryllotalpa can deliver about 1 milliWatt. G. vineae produces an exceptionally loud song from half an hour after sunset, continuing for an hour; it can be heard up to 600 metres away. At a distance of 1 metre from the burrow, the sound has a mean power over the stridulation cycle of up to 88 decibels; the loudest recorded peak power was about 92 decibels; at the mouths of the burrow, the sound reaches around 115 decibels. G. gryllotalpa can deliver a peak sound pressure of 72 decibels and a mean of about 66 decibels. [...] The throat of the horn appears to be tuned (offering low inductive reactance), making the burrow radiate sound efficiently; the efficiency increases when the burrow is wet and absorbs less sound. Mole crickets are the only insects that construct a sound-producing apparatus. Given the known sensitivity of a cricket's hearing (60 decibels), a night-flying G. vineae female {{should be able to}} detect the male's song at a range of 30 metres; this compares to about 5 metres for a typical Gryllus cricket that does not construct a burrow.|$|E
2500|$|Period length or neural-firing coincidence: {{with the}} length of {{periodic}} neural firing created by two or more waveforms, higher simple numbers creating longer periods or lesser coincidence of neural firing and thus dissonance ( [...] ; [...] ). Purely harmonic tones cause neural firing exactly with the period or some multiple of the <b>pure</b> <b>tone.</b>|$|E
2500|$|One {{characteristic}} of a whistle is that it creates a pure, or nearly <b>pure,</b> <b>tone.</b> The conversion of flow energy to sound comes from an interaction between a solid material and a fluid stream. The forces in some whistles are sufficient to set the solid material in motion. Classic examples are [...] tones that result in galloping power lines, or the Tacoma Narrows Bridge (galloping Gertie). Other examples are circular disks set into vibration.|$|E
40|$|Subjects {{were asked}} to {{count the number of}} times a 'target' sound {{occurred}} in lists of speech sounds (pa or ba) or <b>pure</b> <b>tones</b> (250 or 600 c/sec) in which one of the sounds (the 'frequent') appeared about four times as often as the target. The response to both targets and frequents were separately averaged from electrodes at vertex at symmetrical left and right parietal locations. The expected sequence of deflections, including P 3 waves with about 350 msec latency, was found in the responses to target stimuli. Very little difference was found between the right and left hemispheric responses to speech or <b>pure</b> <b>tones,</b> either frequent or target...|$|R
25|$|Around 1870 Mr. C. F. Varley, F.R.S., a {{well-known}} English electrician, patented {{a number of}} variations on the audio telegraph based on Reis' work. He never claimed or produced a device capable of transmitting speech, only <b>pure</b> <b>tones.</b>|$|R
50|$|Nummer 5 met zuivere tonen (Number 5 with <b>Pure</b> <b>Tones)</b> is {{a musical}} {{work by the}} Belgian {{composer}} Karel Goeyvaerts, realized at the WDR Studio for Electronic Music in 1953 {{and one of the}} earliest pieces of electronic music.|$|R
