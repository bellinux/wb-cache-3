3816|1738|Public
25|$|Mosegaard, K., & Tarantola, A. (2002). 16 <b>Probabilistic</b> <b>approach</b> to inverse problems. International Geophysics, 81, 237-265.|$|E
25|$|At times, a non-rigorous, <b>probabilistic</b> <b>approach</b> {{leads to}} a number of {{heuristic}} algorithms and open problems, notably Cramér's conjecture.|$|E
25|$|When {{activity}} {{recognition is}} performed indoors and in cities using the widely available Wi-Fi signals and 802.11 access points, {{there is much}} noise and uncertainty. These uncertainties are modeled using a dynamic Bayesian network model by Yin et al. A multiple goal model that can reason about user's interleaving goals is presented by Chai and Yang, where a deterministic state transition model is applied. A better model that models the concurrent and interleaving activities in a <b>probabilistic</b> <b>approach</b> is proposed by Hu and Yang. A user action discovery model is presented by Yin et al., where the Wi-Fi signals are segmented to produce possible actions.|$|E
5000|$|Existing {{uncertainty}} propagation <b>approaches</b> include <b>probabilistic</b> <b>approaches</b> and non-probabilistic approaches. There are basically five categories of <b>probabilistic</b> <b>approaches</b> for {{uncertainty propagation}}: ...|$|R
50|$|Some <b>probabilistic</b> <b>approaches</b> {{have been}} developed.|$|R
40|$|Advantages of <b>probabilistic</b> <b>approaches</b> • Understand better how {{accurate}} {{the risk is}} • Incentive to reduce uncertainty (e. g. more tests) • Avoids ‘worst case’-assumptions Disadvantages of <b>probabilistic</b> <b>approaches</b> • Difficult to quantify all sources of uncertainty • Difficult concept (e. g. to communicate) 3 BIOMATHF. Verdonck Variability and uncertaint...|$|R
25|$|The current {{process for}} {{evaluating}} the seismic hazard for a nuclear plant is set out in Règle Fondamentale de Sûreté (Fundamental Safety Rule) RFS 2001-01, published by the Institute for Radioprotection and Nuclear Safety, which uses more detailed seismotectonic zones. RFS 2001-01 replaced RFS I.2.c, published in 1981, however it has been criticised for continuing to require a deterministic assessment (rather than a <b>probabilistic</b> <b>approach)</b> that relies primarily on the strongest 'historically known' earthquake near a site. This leads {{to a number of}} problems including the short period (in geological timescales) for which there are records, the difficulty of assessing the characteristics of earthquakes that occurred prior to the use of seismometers, the difficulty of identifying the existence of all earthquakes that pre-date the historic record, and ultimately the reliance on one single earthquake scenario. Other criticisms include the use of intensity in the evaluation method, rather than spectral acceleration, which is commonly used elsewhere.|$|E
500|$|... discuss {{extended}} maximum spacing {{methods to}} the multivariate case. As {{there is no}} natural order for , they discuss two alternative approaches: a geometric approach based on Dirichlet cells and a <b>probabilistic</b> <b>approach</b> based on a “nearest neighbor ball” metric.|$|E
2500|$|The Schrödinger {{equation}} {{details the}} behavior of [...] but says nothing of its nature. [...] Schrödinger tried to interpret it as a charge density in his fourth paper, but he was unsuccessful. In 1926, {{just a few days}} after Schrödinger's fourth and final paper was published, Max Born successfully interpreted [...] as the probability amplitude, whose absolute square is equal to probability density. Schrödinger, though, always opposed a statistical or <b>probabilistic</b> <b>approach,</b> with its associated discontinuities—much like Einstein, who believed that quantum mechanics was a statistical approximation to an underlying deterministic theory—and never reconciled with the Copenhagen interpretation.|$|E
40|$|This article surveys <b>probabilistic</b> <b>approaches</b> to {{modeling}} information retrieval. The {{basic concepts}} of <b>probabilistic</b> <b>approaches</b> to information retrieval are outlined and {{the principles and}} assumptions upon which the approaches are based are presented. The various models proposed {{in the development of}} IR are described, classified, and compared using a common formalism. New approaches that constitute the basis of future research are describe...|$|R
50|$|The {{comparison}} between <b>probabilistic</b> <b>approaches</b> (not only bayesian programming) and possibility theories {{continues to be}} debated.|$|R
30|$|Alternative {{variants}} of direct methods are the collocation methods, the spectral or pseudo-spectral methods, the <b>probabilistic</b> <b>approaches,</b> etc.|$|R
2500|$|Partly {{following}} a heuristic {{method of calculation}} pioneered by Boltzmann for gas molecules, Planck considered the possible ways of distributing electromagnetic energy over the different modes of his hypothetical charged material oscillators. This acceptance of the <b>probabilistic</b> <b>approach,</b> following Boltzmann, for Planck was a radical change from his former position, which till then had deliberately opposed such thinking proposed by Boltzmann. Heuristically, Boltzmann had distributed the energy in arbitrary merely mathematical quanta [...] , which he had proceeded to make tend to zero in magnitude, because the finite magnitude [...] had served only to allow definite counting {{for the sake of}} mathematical calculation of probabilities, and had no physical significance. Referring to a new universal constant of nature, , Planck supposed that, in the several oscillators of each of the finitely many characteristic frequencies, the total energy was distributed to each in an integer multiple of a definite physical unit of energy, , not arbitrary as in Boltzmann's method, but now for Planck, in a new departure, characteristic of the respective characteristic frequency. His new universal constant of nature, , is now known as Planck's constant.|$|E
5000|$|... #Article: <b>Probabilistic</b> <b>Approach</b> for Protein NMR Assignment Validation ...|$|E
50|$|He is a {{coauthor}} of the book Logarithmic Combinatorial Structures: A <b>Probabilistic</b> <b>Approach.</b>|$|E
40|$|The paper {{provides}} {{an introduction to}} and survey of <b>probabilistic</b> <b>approaches</b> to modelling Information Retrieval. The basic concepts of <b>probabilistic</b> <b>approaches</b> to Information Retrieval are outlined, and the principles and assumptions upon which the approaches are based are presented. The various models that have been proposed {{in the development of}} IR are described, classified, and compared. The models are classified and compared using a common formalism. New approaches that constitute the basis of future research are described...|$|R
50|$|For highly {{non-linear}} functions, {{there exist}} five categories of <b>probabilistic</b> <b>approaches</b> for uncertainty propagation; see Uncertainty Quantification#Methodologies for forward uncertainty propagation for details.|$|R
40|$|We {{consider}} <b>probabilistic</b> <b>approaches</b> {{and stress}} tests as methods for regulators {{to set the}} minimum solvency margin for insurers. Each method has advantages and disadvantages. We assess {{the implications of the}} global financial crisis for each method, concentrating on life insurers. We have concerns that the probabilities used in <b>probabilistic</b> <b>approaches</b> are not robust. Regulators may find it beneficial to focus on the use of stress tests, although there are lessons to learn from the global financial crisis about the design and use of such tests. ...|$|R
5000|$|Mosegaard, K., & Tarantola, A. (2002). 16 <b>Probabilistic</b> <b>approach</b> to inverse problems. International Geophysics, 81, 237-265.|$|E
50|$|At times, a non-rigorous, <b>probabilistic</b> <b>approach</b> {{leads to}} a number of {{heuristic}} algorithms and open problems, notably Cramér's conjecture.|$|E
5000|$|The <b>probabilistic</b> <b>approach</b> (described in this article) {{assumes that}} the {{measured}} data is random with probability distribution dependent on the parameters of interest ...|$|E
40|$|International audienceParametric <b>probabilistic</b> <b>approaches</b> allow data {{uncertainties}} to be modelled, {{but have}} some difficulties to represent model uncertainties. It has been recently shown that both model and data uncertainties {{can be taken}} into account with a non-parametric approach. Moreover, it is known that with increasing complexity of a mechanical system, model uncertainties also increase. Based on these considerations, both parametric and non-parametric <b>probabilistic</b> <b>approaches</b> are used on a complex system of aerospace engineering constituted of a satellite coupled with its launcher. First, a parametric probabilistic model is constructed for analysing the sensitivity of the response due to data uncertainties. Then, the non-parametric probabilistic model is introduced with the same uncertainty level in order to study the sensitivity of the response with respect to the model and the data uncertainties. The dynamical responses obtained with these two <b>probabilistic</b> <b>approaches</b> are analysed in order to quantify the sensitivity of the structure to data uncertainties as well as model uncertainties...|$|R
40|$|For the multi-robot {{coverage}} problem deterministic deliberative {{as well as}} <b>probabilistic</b> <b>approaches</b> {{have been}} proposed. Whereas deterministic approaches usually provide provable completeness and promise good performance under perfect conditions, <b>probabilistic</b> <b>approaches</b> are more robust to sensor and actuator noise, but completion cannot be guaranteed and performance is sub-optimal {{in terms of time}} to completion. In reality, however, almost all deterministic algorithms for robot coordination can be considered probabilistic when considering the unpredictability of real world factors. This paper investigates experimentally and analytically how probabilistic and deterministic algorithms can be combined for maintaining the robustness of <b>probabilistic</b> <b>approaches,</b> and explicitly model the reliability of a robotic platform. Using realistic simulation and data from real robot experiments, we study system performance of a swarm-robotic inspection system at different levels of noise (wheel-slip). The prediction error of a purely deterministic model increases when the assumption of perfect sensors and actuators is violated, whereas a combination of probabilistic and deterministic models provides a better match with experimental data...|$|R
5000|$|Optimizing Embedded Applications Deterministic Vs. <b>probabilistic</b> <b>approaches</b> for {{complexity}} management; Randomized algorithms; Evolutionary optimization; Application porting to low precision platforms; Robustness analysis; Techniques {{for performance}} assessment at the application level.|$|R
5000|$|N Bigdely-Shamlo, T. Mullen, K. Kreutz-Delgado, S Makeig. Measure {{projection}} analysis: A <b>probabilistic</b> <b>approach</b> to EEG source comparison and multi- subject inference. doi://10.1016/j.neuroimage.2013.01.040 (2013) ...|$|E
50|$|Together {{with his}} colleagues, Wolfram Burgard {{developed}} numerous probabilistic approaches to mobile robot navigation. This includes Markov localization, a <b>probabilistic</b> <b>approach</b> to mobile localization which can robustly track {{the position of}} a mobile robot, estimate its global position when it starts without any prior knowledge about it, and can even recover from localization failures. In 1999, Frank Dellaert, Dieter Fox, Sebastian Thrun, and Wolfram Burgard developed Monte Carlo localization, a <b>probabilistic</b> <b>approach</b> to mobile robot localization that is based on particle filters.|$|E
50|$|Recursive Bayesian estimation, {{also known}} as a Bayes filter, is a general <b>probabilistic</b> <b>approach</b> for {{estimating}} an unknown probability density function recursively over time using incoming measurements and a mathematical process model.|$|E
40|$|In {{traditional}} machine learning, classification {{is typically}} {{undertaken in the}} way of discriminative learning using <b>probabilistic</b> <b>approaches,</b> i. e. learning a classifier that discriminates one class from other classes. The above learning strategy is mainly due to the assumption that different classes are mutually exclusive and each instance is clear-cut. However, the above assumption does not always hold in the context of real-life data classification, especially when the nature of a classification task is to recognize patterns of specific classes. For example, in the context of emotion detection, multiple emotions may be identified from the same person at the same time, which indicates in general that different emotions may involve specific relationships rather than mutual exclusion. In this paper, we focus on classification problems that involve pattern recognition. In particular, we position the study in the context of granular computing, and propose the use of fuzzy rule-based systems for recognition-intensive classification of real-life data instances. Furthermore, we report an experimental study conducted using 7 UCI data sets on life sciences, to compare the fuzzy approach with four popular <b>probabilistic</b> <b>approaches</b> in pattern recognition tasks. The experimental results show that the fuzzy approach can not only be used as an alternative one to the <b>probabilistic</b> <b>approaches</b> but also is capable to capture more patterns which <b>probabilistic</b> <b>approaches</b> cannot achieve...|$|R
30|$|The {{stochastic}} {{nature of}} wind power {{leads to the}} poor accuracy in short-term spot forecast. Hence <b>probabilistic</b> <b>approaches</b> providing expected wind power values along with quantitative uncertainty description may be better choices.|$|R
30|$|The use of {{fire spread}} models as a {{decision-support}} tool for fire management must quantify and integrate the uncertainty associated with input data uncertainty and thus <b>probabilistic</b> <b>approaches</b> should be favoured over deterministic ones.|$|R
5000|$|In {{case it is}} not {{possible}} to predict with certainty what will be the outcome of a particular decision, a <b>probabilistic</b> <b>approach</b> is necessary. In its most general form, it can be expressed as follows: ...|$|E
5000|$|Probabilistic Semantics [...] {{extends the}} current {{semantic}} technology {{to overcome that}} limitation. However, due to their <b>probabilistic</b> <b>approach,</b> Probabilistic Semantics are able to describe only those uncertainties that can be quantified, namely they cannot model conceptual uncertainty.|$|E
5000|$|... discuss {{extended}} maximum spacing {{methods to}} the multivariate case. As {{there is no}} natural order for , they discuss two alternative approaches: a geometric approach based on Dirichlet cells and a <b>probabilistic</b> <b>approach</b> based on a “nearest neighbor ball” metric.|$|E
40|$|Connectionist and {{dynamical}} systems approaches explain human thought, {{language and}} behavior {{in terms of}} the emergent consequences {{of a large number of}} simple noncognitive processes. We view the entities that serve as the basis for structured <b>probabilistic</b> <b>approaches</b> as abstractions that are occasionally useful but often misleading: they have no real basis in the actual processes that give rise to linguistic and cognitive abilities or to the development of these abilities. Although structured <b>probabilistic</b> <b>approaches</b> can be useful in determining what would be optimal under certain assumptions, we propose that connectionist, dynamical systems, and related approaches, which focus on explaining the mechanisms that give rise to cognition, will be essential in achieving a full understanding of cognition and development...|$|R
40|$|The {{number of}} <b>probabilistic</b> <b>approaches</b> to ``classic'' {{distributed}} systems {{problems such as}} reliable broadcast, consensus, or leader election, has further increased recently. Probabilistic algorithms, possibly starting from probabilistic system models, have been motivated by the need for practicable solutions to such problems, circumventing bottlenecks and limitations inherent to distributed computing. While many approaches {{coming out of this}} revival of <b>probabilistic</b> <b>approaches</b> are indeed pathbreaking, it is legitimate to question the usefulness of certain efforts, which claim some form of probabilistic reliability, yet fail to provide clear specifications of the proposed algorithms. In this paper, we point out the inherent difficulties related to the specification of the behavior of probabilistic algorithms through various examples...|$|R
40|$|This paper revisits the two-hop {{forwarding}} {{policy in}} delay tolerant networks (DTNs) using simple <b>probabilistic</b> <b>approaches.</b> Closed form expressions are derived {{for the main}} performance measures. We then study competitive and cooperative operation of DTNs and derive the structure of optimal and of equilibrium policies...|$|R
