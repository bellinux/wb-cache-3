17|167|Public
50|$|Predetermined {{variables}} are variables that were determined {{prior to the}} current period. In econometric models this implies that the current period error term is uncorrelated with current and lagged values of the <b>predetermined</b> <b>variable</b> but may be correlated with future values. This is a weaker restriction than strict exogeneity, which requires the variable to be uncorrelated with past, present, and future shocks.|$|E
50|$|A common {{example of}} a <b>predetermined</b> <b>variable</b> is {{consumption}} in models with credit constraints and rational expectations. Here, consumption is predetermined but not strictly exogenous. An unpredictable negative income shock will be uncorrelated with past (and potentially current) consumption, but will surely be correlated with future consumption—the individual {{will be forced to}} adjust their future consumption to accommodate their poorer state, inducing correlation. If the shock affects current consumption, predeterminedness (defined now as lags only) provides potential instruments--lagged values of the variable.|$|E
3000|$|... 8 The {{assumption}} of independence over {{time for the}} error terms is also critical in taking duration of residence as a <b>predetermined</b> <b>variable.</b>|$|E
40|$|International audienceIn this paper, I {{study the}} {{existence}} of Sunspot Equilibria in a general framework whose dynamics allow {{for the presence of}} <b>predetermined</b> <b>variables</b> in the system. The main motivation for this research {{comes from the fact that}} previous studies did not allow for such <b>predetermined</b> <b>variables</b> which, nevertheless, appear quite naturally in economic models. I show, for a non-negligible subset of dynamics with <b>predetermined</b> <b>variables</b> verifying usual assumptions, {{the existence of}} Stationary Sunspot Equilibria fluctuating between an arbitrary finite number of states arbitrarily close to a steady state...|$|R
40|$|A zero-one random {{variable}} {{is assumed to}} follow the logistic law, where the logit is a linear function {{of two or more}} <b>predetermined</b> <b>variables.</b> Three tests for the necessity of including one of the <b>predetermined</b> <b>variables</b> in the model are discussed; their powers are compared and approximations to them are derived. 1...|$|R
50|$|Similar to the {{continuity}} of observable variables, one would expect there to be continuity in <b>predetermined</b> <b>variables</b> at the treatment cut-off. Since these variables were determined before the treatment decision, treatment status should {{have no effect on}} them. Consider the earlier merit-based scholarship example. If the outcome of interest is future grades, then we would not expect the scholarship to affect earlier grades. If a discontinuity in <b>predetermined</b> <b>variables</b> is present at the treatment cut-off, then this puts the validity of the regression discontinuity design into question.|$|R
40|$|In this paper, {{we propose}} a simple {{geometrical}} method {{to study the}} occurrence of sunspot equilibria near an indeterminate steady state of a non-linear, two-dimensional economic model without any <b>predetermined</b> <b>variable.</b> We prove that, if the steady state is a saddle point of the perfect foresight dynamical system {{and the economy is}} truly nonlinear, then there exist Markovian sunspot equilibria on a compact two-dimensional setVxqvsrw htxloleulxp/ lqghwhuplqdf|/ vdggoh srlqw/ lqyduldqw vhw...|$|E
40|$|We {{consider}} a linear stochastic univariate rational expectations model, with a <b>predetermined</b> <b>variable,</b> and provide alternative representations of SSEs (stationary sunspot equilibria). For a strict {{subset of the}} parameter space there exist SSEs that are locally stable under least squares learning provided agents use a common factor representation for their estimated law of motion. These results indicate that for some parameter regions SSEs {{are more likely to}} arise under private agent learning than previously recognized...|$|E
30|$|In principle, {{the share}} of {{temporary}} work at the firm level, tw_i,t- 1, could also {{have been used in}} the interaction terms since, in line with LP s (2003) estimation approach of a_it, it is also be a <b>predetermined</b> <b>variable.</b> However, since there could be some doubts about the absence of a direct effect of tw_i,t- 1 in a given year on a firm’ s TFP in future years, we prefer to use more aggregate shares at the cell level.|$|E
40|$|A {{forecast}} {{produced by}} an econometric {{model is a}} weighted aggregate of <b>predetermined</b> <b>variables</b> in the model. In many models the number of <b>predetermined</b> <b>variables</b> used is very large, often exceeding the number of observations. A method is proposed in this paper for testing an econometric model as an aggregator of {{the information in the}}se <b>predetermined</b> <b>variables</b> relative to a specified subset of them. The test, called the "information aggregation" (IA) test, tests whether the model makes effective use of the information in the <b>predetermined</b> <b>variables</b> or whether a smaller information set carries as much information. The method {{can also be used to}} test one model against another. The method is used to test the Fair model as an information aggregator. The Fair model is also tested against two relatively non theoretical models: a VAR model and an "autoregressive components" (AC) model. The AC model, which is new in this paper, estimates an autoregressive equation for each component of real GNP, with real GNP being identically determined as the sum of the components. The results show that the AC model dominates the VAR model, although both models are dominated by the Fair model. The results also show that the Fair model seems to be a good information aggregator. ...|$|R
30|$|In the use {{of dynamic}} panel models, some {{specifications}} must be followed. Among them, the errors could not be correlated with <b>predetermined</b> <b>variables,</b> according to Arellano and Bover (1995).|$|R
40|$|The use of <b>predetermined</b> <b>variables</b> to {{represent}} public information and time-variation has produced new insights about asset pricing models but {{the literature on}} mutual fund performance has not exploited these insights. This paper advocates conditional performance evaluation in which the relevant expectations are conditioned on public information variables. The authors modify several classical performance measures to this end and find that the <b>predetermined</b> <b>variables</b> are both statistically and economically significant. Conditioning on public information controls for biases in traditional market timing models and makes the average performance of the mutual funds in the authors' sample look better. Copyright 1996 by American Finance Association. ...|$|R
40|$|A just {{identified}} two-equation {{econometric model}} is simulated using both Classical and Bayesian procedures. The {{estimates of the}} parameters for both methods were compared under {{a wide range of}} scenarios; sample size, residual variance and variance of the data on the <b>predetermined</b> <b>variable.</b> The Monte Carlo experiment was performed using E-veiws and WinBUGS computer softwares. The median, being a robust estimator of average in terms of validity, was used as the posterior estimate. As indicated in similar research in the past where the posterior mode was used as estimate, the Bayesian procedure performed better in most cases, while some scenarios showed similar behavior for the two procedures...|$|E
30|$|Complementarity and subset {{allocation}} As {{described in}} the “Data description and model selection” section, we allocate firms to the three subsets by their mean energy cost share. The energy cost share is endogenous to our modeling approach. It would be preferable to split the firm sample by applying a truly exogenous variable to prevent any endogeneity issues. As argued before, given the available data {{as well as other}} restrictions, we are not able to use a completely <b>predetermined</b> <b>variable</b> to split our sample {{and at the same time}} analyze substitution possibilities of firms with different energy intensity in their production processes. In this section, we examine the sensitivity of our results using different approaches of sample splitting.|$|E
40|$|This paper {{studies the}} {{dynamics}} {{implied by the}} Chamley (1993) model, {{a variant of the}} two-sector model with an implicit characterization of the learning function. We first show that under some ‘‘regularity’’ conditions regarding the learning function, the model has (a) one steady state, (b) no steady states or (c) two steady states (one saddle and one non-saddle). Moreover, via the Bogdanov–Takens theorem, we prove that for critical regions of the parameters space, the dynamics undergoes a particular global phenomenon, namely the homoclinic bifurcation. Because these findings imply the existence of a continuum of equilibrium trajectories, all departing from the same initial value of the <b>predetermined</b> <b>variable,</b> the model exhibits global indeterminacy...|$|E
40|$|This article {{develops}} {{a framework for}} efficient IV estimators of random effects models with information in levels which can accommodate <b>predetermined</b> <b>variables.</b> Our formulation clarifies {{the relationship between the}} existing estimators and the role of transformation in panel data models. We characterise the valid transformations for relevant models and show the optimal estimators are invariant to the transformation used to remove individual effects. We present an alternative transformation for models with predetermined instruments which preserves the orthogonality among the errors. Finally, we consider models with <b>predetermined</b> <b>variables</b> that have constant correlation with effects and illustrate their importance with simulations...|$|R
40|$|The paper {{presents}} a general solution method for rational expectations models {{that can be}} represented by systems of. deterministic first order linear differential equations with constant coefficients. It is the continuous time adaptation of the method of Blanchard and Kahn. To obtain a unique solution there must be as many linearly independent boundary conditions as there are linearly independent state variables. Three slightly different versions of a well-known small open economy macroeconomic model were used to illustrate three fairly general ways of specifying the required boundary conditions. The first represents the standard {{case in which the}} number of stable characteristic roots equals the number of <b>predetermined</b> <b>variables.</b> The second represents the case where the number of stable roots exceeds the number of <b>predetermined</b> <b>variables</b> but equals the number of <b>predetermined</b> <b>variables</b> plus the number of "backward-looking" but non-predetermined variables whose discontinuities are linear functions of the discontinuities in the forward-looking variables. The third represents the case where the number of unstable roots is less than the number of forward-looking state variables. For the last case, boundary conditions are suggested that involve linear restrictions on the values of the state variables at a future date. The method of this paper permits the numerical solution of models with large numbers of state variables. Any combination of anticipated or unanticipated, current or future and permanent or transitory shocks can be analyzed. ...|$|R
50|$|<b>Predetermined</b> <b>variables</b> {{will lead}} static fixed effects estimators, such as First Differencing or Within-Group Fixed Effects models to be inconsistent. The strict exogeneity {{assumption}} fails in dynamic models. Let eit denote the idiosyncratic {{part of the}} error terms (i.e. {{it does not include}} the fixed effect ai). Consider the following Fixed Effects model.|$|R
40|$|We {{consider}} a linear univariate rational expectations model, with a <b>predetermined</b> <b>variable,</b> and study existence {{and stability of}} solutions driven by an extraneous finite-state Markov process. We show that when the model is indeterminate there exists {{a new class of}} k-state dependent sunspot equilibria in addition to the k-state sunspot equilibria (k-SSEs) already known to exist in part of the indeterminacy region. The new type of equilibria, which we call ergodic k-SSEs, are driven by a finite-state sunspot but can have an infinite range of values even in the nonstochastic model. Stability under econometric learning is analyzed using representations that nest both types of equilibria. 2 -SSEs and ergodic 2 -SSEs are learnable for parameters in proper subsets of the regions of their existence. Our results extend to models with intrinsic random shocks...|$|E
40|$|This paper compares {{commonly}} used approaches for estimating {{the relation between}} long-horizon returns and a <b>predetermined</b> <b>variable</b> X 1, such as dividend yields. Specifically, we look at regression of (i) nonoverlapping multiperiod returns on X t (ii) overlapping multiperiod returns on X t, (iii) single-period returns on multiperiod X t, and (iv) single-period returns on X t and its implied long-horizon regression coefficient. We provide analytical formulae which quantify {{the efficiency of the}} estimators used in the various approaches. Using the formulae, as well as Monte Carlo simulations, we demonstrate that the relative efficiency of the estimators used in the various approaches differs remarkably, depending on the dynamic structure of the regressor. of special interest for financial economists, when the regressors are highly autocorrelated, we find that the regressions (ii) (iii), and (iv) provide only "marginal" efficiency gains above and beyond the nonoverlapping long-horizon regression. Copyright 1994 Blackwell Publishers. ...|$|E
40|$|Abstract. A propositional proof {{system based}} on ordered binary deci-sion {{diagrams}} (OBDDs) was introduced by Atserias et al. in [3]. Kraj́ıček proved exponential lower bounds for a strong variant of this system us-ing feasible interpolation [14], and Tveretina et al. proved exponential lower bounds for restricted versions of this system for refuting formulas derived from the Pigeonhole Principle [20]. In this paper we prove the first lower bounds for refuting randomly generated unsatisfiable formu-las in restricted versions of this OBDD-based proof system. In particular we consider two systems OBDD * and OBDD+; OBDD * is restricted by having a fixed, <b>predetermined</b> <b>variable</b> order for all OBDDs in its refu-tations, and OBDD+ is restricted by having a fixed order in which the clauses of the input formula must be processed. We show that for some constant > 0, with high probability an OBDD * refutation of an un-satisfiable random 3 -CNF formula must be of size at least 2 n, and an OBDD+ refutation of an unsatisfiable random 3 -XOR formula must be of size at least 2 n. ...|$|E
40|$|When econometric {{models are}} used as {{forecasting}} tools, forecast errors can be decomposed into several components, {{one of which is}} due to estimation errors, while another one is due to the stochastic nature of the variables to be predicted. Conditional on model's specification and on the <b>predetermined</b> <b>variables,</b> it is possible to compute a standard error of forecasts one-step-ahead. ...|$|R
40|$|We analyze semiparametric {{efficient}} {{estimation of}} non-linear simultaneous equation models {{in a time}} series context and derive a semiparametric efficiency bound for estimation of the parameters when the errors are i. i. d. from an unknown elliptically symmetric density. We derive the bound {{in the case of}} errors that are elliptically symmetric conditional on <b>predetermined</b> <b>variables.</b> Copyright Royal Economic Society 2007...|$|R
40|$|This paper {{introduces}} structural equations that do {{not satisfy}} the rank and/or order condition(s) for identification but still are identifiable. These equations are called seemingly unidentified structural equations. The key to the identifiability of these equations is that the right-hand-side endogenous variables undergo structural changes {{with respect to the}} exogenous and/or <b>predetermined</b> <b>variables.</b> To estimate the seemingly unidentified structural equations, this paper uses the classical minimum distance (MD) estimator and the principal components instrumental variables (PCIV) estimator. The PCIV estimator is different from conventional IV estimators for structural equations in that nonlinear functions of exogenous and/or <b>predetermined</b> <b>variables</b> are used as instruments. Simulation results comparing the estimator efficiency of the MD and PCIV estimators are reported in this paper. The results indicate that the MD and PCIV estimators are complementary to each other. The estimation methods proposed in this paper are applied to the Japanese export and GDP data to study the effect of export growth rate on that of GDP...|$|R
40|$|AbstractThe BLU {{properties}} of OLS estimators under known assumptions have encouraged {{the widespread use}} of OLS multivariate regression analysis in many empirical studies that are based upon a conceptual model of a single explanatory equation. However, such a model may well be an imperfect empirical approximation to the valid underlying conceptual model, that may well contain several important additional inter-relationships between the relevant variables. In this paper, we examine the conditions under which we can predict the direction of the resultant endogeneity bias that will prevail in the OLS asymptotic parameter estimates for any given endogenous or <b>predetermined</b> <b>variable,</b> {{and the extent to which}} we can rely upon simple heuristics in this process. We also identify the underlying structural parameters to which the magnitude of the endogeneity bias is sensitive. The importance of such sensitivity analysis has been underlined by an increasing awareness of the inability of standard diagnostic tests to shed light upon the extent of the endogeneity bias, rather than upon merely its existence. The paper examines the implications of the analysis for statistical inferences about the true value of the regression coefficients and the validity of associated t-statistics...|$|E
40|$|Conventional {{discussions of}} balance sheet {{management}} by nonfinancial firms take {{the set of}} positive net present value (NPV) projects as given, which in turn determines {{the size of the}} firm’s assets. The focus is on the composition of equity and debt in funding such assets. In contrast, the balance sheet management of financial intermediaries reveals that it is equity that behaves like the <b>predetermined</b> <b>variable,</b> and the asset size of the bank or financial intermediary is determined by the degree of leverage that is permitted by market conditions. The relative stickiness of equity reveals possible nonpecuniary benefits to bank owners so that they are reluctant to raise new equity, even during boom periods when raising equity is associated with less stigma and, hence, smaller discounts. We explore the empirical evidence for both market-based financial intermediaries such as the Wall Street investment banks, as well as the commercial bank subsidiaries of the large U. S. bank holding companies. We further explore the aggregate consequences of such behavior by the banking sector for the propagation of the financial cycle and securitization. Assets (Accounting); Equity; Debt; Intermediation (Finance); Investment banking; Bank holding companies...|$|E
40|$|The BLU {{properties}} of OLS estimators under known assumptions have encouraged {{the widespread use}} of OLS multivariate regression analysis in many empirical studies that are based upon a conceptual model of a single explanatory equation. However, such a model may well be an imperfect empirical approximation to the valid underlying conceptual model, that may well contain several important additional inter-relationships between the relevant variables. In this paper, we examine the conditions under which we can predict the direction of the resultant endogeneity bias that will prevail in the OLS asymptotic parameter estimates for any given endogenous or <b>predetermined</b> <b>variable,</b> {{and the extent to which}} we can rely upon simple heuristics in this process. We also identify the underlying structural parameters to which the magnitude of the endogeneity bias is sensitive. The importance of such sensitivity analysis has been underlined by an increasing awareness of the inability of standard diagnostic tests to shed light upon the extent of the endogeneity bias, rather than upon merely its existence. The paper examines the implications of the analysis for statistical inferences about the true value of the regression coefficients and the validity of associated t-statistics. 62 J 05 62 F 12 62 F 05 Multivariate analysis and parameter estimation Endogeneity bias Sensitivity analysis Simultaneity bias Simultaneous equations bias Specification error Exogeneity t-statistics Diagnostic tests...|$|E
40|$|Abstract. This paper {{considers}} {{the problem of}} identification and estimation in panel data sample selection models with a binary selection rule when the latent equations contain possible <b>predetermined</b> <b>variables,</b> lags of the dependent variables, and unobserved individual effects. The selection equation contains lags of the dependent variables from both the latent and the selection equations {{as well as other}} possible <b>predetermined</b> <b>variables</b> relative to the latent equations. We derive a set of conditional moment restrictions that are then exploited to construct a three-step GMM sieve estimator for the parameters of the main equation including a nonparametric estimator of the sample selection term. In the second-step the unknown parameters of the selection equation are consistently estimated using a transformation approach in the spirit of Berkson’s minimum chi-square sieve method and a first-step kernel estimator for the selection probability. This second-step estimator is of interest in its own right: {{it can be used to}} semiparametrically estimate a panel data binary response model with correlated random effects without making any distributional assumptions. We show that both estimators (second and third stage) are vn-consistent and asymptotically normal. ...|$|R
40|$|This {{study has}} been made to further explain the cattle cycle in the United States and in three {{selected}} regions. Structural models of the cattle cycle are specified and estimated, and hypotheses about their parameters are tested. For this study, the cattle cycle is divided into three cycles that include the inventory cycle, the price and income cycle and the slaughter and import cycle. Further analysis is then made to determine the important explanatory variables within each cycle. Several simultaneous equation models are constructed of the form: y 2 ̆ 7 (t) C + x 2 ̆ 7 (t) B + u 2 ̆ 7 (t) = o 2 ̆ 7 where y 2 ̆ 7 (t), x 2 ̆ 7 (t) and u 2 ̆ 7 (t) are the row vectors, respectively, of the jointly dependent <b>variables,</b> the <b>predetermined</b> <b>variables</b> and the unobserved disturbances in the equations and where C and B are the matrices of the coefficients of the jointly dependent variables and of the <b>predetermined</b> <b>variables,</b> respectively...|$|R
40|$|This paper generalises a {{classical}} theorem on the {{minimisation of the}} ratio of two quadratic forms so as to permit the denominator to be nonnegative definite, provides a modified formula for the minimum variance ratio estimation including the limited information maximum likelihood, and collaterally shows {{that the use of}} the principal components of some <b>predetermined</b> <b>variables</b> in the first stage of two stage least squares is afraid of leading to biased estimators. ...|$|R
30|$|Endogeneity {{comes from}} three sources: firstly, {{measurement}} error, {{that is to}} say that a correlation exists between the number of children, children’s years of schooling, and measurement error. 11 The second source is simultaneity. Our research design was structured to avoid simultaneity. It is unlikely that parents’ current life quality is the cause of their earlier decision about the number of children or children’s years of schooling. Fertility decision is a <b>predetermined</b> <b>variable,</b> and all children in this sample have completed their studies or at least are not in school. The third source is omitted variables. Variables that may result in bias are those related to the quantity of children, years of education, {{and at the same time}} with parents’ life quality. For example, it is possible that young parents may have income levels and quality of life levels that, at that time, would affect a fertility decision and their ability to invest in children’s education and thus affect their current life quality. In order to avoid omitted variable bias, we use the following method: firstly, we restrict our sample to rural areas. Children from the object families were born between 1956 and 1984, during which time rural residents were largely peasants, and differences in income were not obvious. Secondly, we try to control for the variables that would reflect the living standards of the time and affect current life quality according to existing research. Examples include years of education of the elderly, whether or not they are party members, number of siblings, and families’ geographical environment. During the time when work points 12 were decided by the number of laborers, the number of parents’ siblings reveals the living standards of the parents at that time. Thirdly, the child planning policy was not strictly implemented in the 1960 s or 1970 s, and few people in rural areas ran tests to determine the sex of the child in utero, so gender can be regarded as random. In the model, we differentiate the number of daughters from that of sons. Generally speaking, children’s highest years of schooling is unlikely to be controlled by parental choice alone; even if parents strongly hope that their children will receive higher education, in situations where education resources are limited, children’s highest years of education is largely decided by internal factors including their IQ and their work efforts, as well as external factors such as local educational resources and enrollment rates.|$|E
40|$|This paper {{develops}} algorithms that {{solve for}} optimal discretionary and optimal pre-commitment policies in rational-expectations models. The techniques developed are simpler to apply than existing methods; {{they do not}} require identifying and separating <b>predetermined</b> <b>variables</b> from jump variables, and they eliminate many of the mathematical preliminaries that are required to implement existing methods. The techniques developed are applied to examples to assess the benefits of pre-commitment over discretion. Monetary policy; Rational expectations (Economic theory) ...|$|R
40|$|In this paper, {{we propose}} a {{geometric}} method {{for the analysis}} of first-order sunspot equilibra in a class of nonlinear dynamic economic models without <b>predetermined</b> <b>variables.</b> We show that such stochastic equilibria exist around a steady state whenever it is locally indeterminate. Moreover, under some assumptions, we prove the existence of sunspot equilibria persisting on a full dimensioned support close to the steady state even when local indeterminacy is only lower dimensional, (C) 2001 Academic Press...|$|R
40|$|The distinctiof between <b>predetermined</b> and non-predetermined <b>variables</b> is {{a crucial}} one in {{rational}} expectations models. I consider and reject two definitions, one proposed by Blanchard and Kahn and one by Chow. Both definitions lead to possible misc 1 assifications. Instead I propose the following defin) tion. A variable is non-`redetermined {{if and only if}} its current value is a function of current anticipations mf future values of endogenous and/or exogenous variables. This definition focuses on the essential economic property of non-predetermined variables: unlike <b>predetermined</b> <b>variables</b> they can respond instantaneously to changes in expectations due to "news. " The new definition also fits the structure of rational expectations models solution algorithms such as the one proposed by Blanchard and Kahn. ...|$|R
40|$|Exponential {{models of}} Autoregressive Conditional Heteroscedasticity (ARCH) are of special interest, since they enable richer {{dynamics}} (e. g. contrarian or cyclical), provide greater robustness to jumps and outliers, and guarantee the positivity of volatility. The latter is not guaranteed in ordinary ARCH models, in particular when additional exogenous and/or <b>predetermined</b> <b>variables</b> ("X") {{are included in}} the volatility specification. Here, we propose estimation and inference methods for univariate and multivariate Generalised log-ARCH-X (i. e. log-GARCH-X) models when the conditional density is not known. The methods employ (V) ARMA-X representations and relies on a biasadjustment in the log-volatility intercept. The bias is induced by (V) ARMA estimators, but the remaining parameters are consistently estimated by (V) ARMA methods. We derive a simple formula for the bias-adjustment, and a closed-form expression for its asymptotic variance. Next, we show that adding exogenous or <b>predetermined</b> <b>variables</b> and/or increasing the dimension of the model does not change the structure of the problem. Accordingly, the univariate bias-adjustment result is likely to hold not only for univariate log-GARCH-X models, but also for multivariate log-GARCH-X models equation-by-equation. Extensive simulation evidence verify our results, and an empirical application show that they are particularly useful when the X-vector is high-dimensional. ...|$|R
40|$|This paper {{considers}} {{the problem of}} identi 8 ̆ 5 cation and estimation in panel-data sample-selection models with a binary selection rule when the latent equations contain possibly <b>predetermined</b> <b>variables,</b> lags of the dependent variables, and un-observed individual e¤ects. The selection equation contains lags of the dependent variables from both the latent and the selection equations {{as well as other}} possibly <b>predetermined</b> <b>variables</b> relative to the latent equations. We derive a set of condi-tional moment restrictions that are then exploited to construct a three-step sieve estimator for the parameters of the main equation including a nonparametric esti-mator of the sample-selection term. In the second step the unknown parameters of the selection equation are consistently estimated using a transformation approach in the spirit of Berksons minimum chi-square sieve method and a 8 ̆ 5 rst-step kernel estimator for the selection probability. This second-step estimator is of interest in its own right. It can be used to semiparametrically estimate a panel-data binary response model with a nonparametric individual speci 8 ̆ 5 c e¤ect without making any other distributional assumptions. We show that both estimators (second and third stage) are p n-consistent and asymptotically normal. ...|$|R
