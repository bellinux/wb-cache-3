97|3|Public
25|$|A 2D or <b>primal</b> <b>sketch</b> of the scene, {{based on}} feature {{extraction}} of fundamental {{components of the}} scene, including edges, regions, etc. Note the similarity in concept to a pencil sketch drawn quickly by an artist as an impression.|$|E
5000|$|This {{algorithm}} {{with its}} applications in computer vision {{is described in}} more detail in Lindeberg's thesis [...] as well as the monograph on scale-space theory [...] partially basedon that work. Earlier presentations of this algorithm can also be found in. More detailed treatments of applications of grey-level blob detection and the scale-space <b>primal</b> <b>sketch</b> to computer vision and medical image analysis are given in.|$|E
50|$|Lindeberg {{studied the}} problem of linking local extrema and saddle points over scales, and {{proposed}} an image representation called the scale-space <b>primal</b> <b>sketch</b> which makes explicit the relations between structures at different scales, and also makes explicit which image features are stable over large ranges of scale including locally appropriate scales for those. Bergholm proposed to detect edges at coarse scales in scale-space and then trace them back to finer scales with manual choice of both the coarse detection scale and the fine localization scale.|$|E
40|$|The proper {{combination}} of optical design with image plane processing, {{as in the}} mechanism of human vision, which allows to improve the performance of sensor array imaging systems for edge detection and location was examined. Two dimensional bandpass filtering during image formation, optimizes edge enhancement and minimizes data transmission. It permits control of the spatial imaging system response to tradeoff edge enhancement for sensitivity at low light levels. It is shown {{that most of the}} information, up to about 94 %, is contained in the signal intensity transitions from which the location of edges is determined for raw <b>primal</b> <b>sketches.</b> Shading the lens transmittance to increase depth of field and using a hexagonal instead of square sensor array lattice to decrease sensitivity to edge orientation improves edge information about 10 %...|$|R
40|$|Our aim in {{this paper}} is to tighten the link between wavelets, some {{classical}} image-processing operators, and David Marr’s theory of early vision. The cornerstone of our approach is a new complex wavelet basis that behaves like a smoothed version of the Gradient-Laplace operator. Starting from first principles, we show that a single-generator wavelet can be defined analytically and that it yields a semi-orthogonal complex basis of, irrespective of the dilation matrix used. We also provide an efficient FFT-based filterbank implementation. We then propose a slightly redundant version of the transform that is nearly translation-invariant and that is optimized for better steerability (Gaussian-like smoothing kernel). We call it the Marr-like wavelet pyramid because it essentially replicates the processing steps in Marr’s theory of early vision. We use it to derive a <b>primal</b> wavelet <b>sketch</b> which is a compact description of the image by a multiscale, subsampled edge map. Finally, we provide an efficient iterativ...|$|R
40|$|Consider an p n � p n {{processor}} mesh where, {{in addition}} to the local links, each row and column is enhanced by a COM-MON CRCW bus. Assume that each processor stores an element of a commutative semigroup, and only k�nentries (in arbitrary positions) are nonzero. We wish to compute the sum of all entries. For this problem we easily obtain a lower time bound of ��k 1 = 4 � if k � n 2 = 3. Our main result is an O�k 1 = 4 log 2 k � time algorithm. It requires a composition of several data movement and compaction techniques which seem to be of general use for solving problems with sparse inputs scattered on the mesh, as it is typical e. g. for <b>primal</b> <b>sketches</b> in digital image processing. 1 : Model, Motivation, and Problem The mesh-connected computer with row and column buses (other denotations in the literature are: mesh or processsor array with multiple broadcasting, enhanced mesh) has reached some attention as an architecture for parallel processing, especially suitable for digital geometry problems. It consists of a p n � p n grid of processors. Each processor is connected to its (at most four) neighbors by local links. Additionally, each row and column is equipped with a bus for long-distance communication. Each processor has local memory (of usually O�log n � bits) and applies in each time unit a global instruction to its own data. A processor can perform local computations and send and receive messages through the local links and buses. All processors in a row or column, respectively, can simultaneously read the message from the bus, but for technical reasons only one message per step can be broadcast by the bus. If only one processor per step is allowed to send a message, we speak of CREW buses, according to the terminology for PRAMs. Since the first treatment in [9], many complexity results have been obtained for this architecture. Usually one assumes that the input has length n and is pretiled onto the whole mesh, or it has length k � n and stands initially in k prescribed processors [2]. The mesh is often considered as a natural device for geometric problems on digital images ([9] [10] [3] and others) – every processor represents...|$|R
5000|$|Compared {{to other}} {{watershed}} methods, the flooding in this algorithm stops once the intensity level falls below the intensity {{value of the}} so-called delimiting saddle point associated with the local maximum. However, it is rather straightforward to extend this approach to other types of watershed constructions. For example, by proceeding beyond the first delimiting saddle point a [...] "grey-level blob tree" [...] can be constructed. Moreover, the grey-level blob detection method was embedded in a scale space representation and performed {{at all levels of}} scale, resulting in a representation called the scale-space <b>primal</b> <b>sketch.</b>|$|E
40|$|This paper proposes {{an image}} {{compression}} approach, {{in which we}} incorporate <b>primal</b> <b>sketch</b> based learning into the mainstream image compression framework. The key idea of our approach is to use <b>primal</b> <b>sketch</b> information to {{enhance the quality of}} distorted images. With this method, we only encode the down-sampled image and use the <b>primal</b> <b>sketch</b> based learning to recover the high frequency information which has been removed by down-sampling. Experimental results demonstrate that our scheme achieves better objective visual quality as well as subjective quality compared with JPEG 2000 at the same bit-rates. Index Terms—image compression, <b>primal</b> <b>sketch,</b> low bitrate coding 1...|$|E
40|$|We {{present a}} novel {{architecture}} for extracting <b>primal</b> <b>sketch</b> features (edges, bars, blobs and ends) in a log-polar representation. Symmetry operators and a PCA preprocessing module precede {{a set of}} neural networks that learn the feature's class and contrast. Key words: <b>primal</b> <b>sketch</b> features, log-polar images, neural networks, principal component analysis...|$|E
30|$|In {{computational}} modelling of vision, Marr {{pointed out}} the need for perceptual clustering algorithms for obtaining full <b>primal</b> <b>sketch</b> from the raw <b>primal</b> <b>sketch,</b> using criteria such as collinearity and size similarity [22]. Clustering and segmentation algorithms broadly studied by the researchers {{in the field of}} CV and our intention for explaining illusory tilt effect focus on simple modelling of retinal low-level processing. We presented our investigation on a variant of the retinal classical receptive field (CRF) model implementing processing in the retinal ganglia and then used the model to generate an edge map representation as a raw <b>primal</b> <b>sketch,</b> which clearly highlight the emergence of tilt on a few Tile Illusion patterns.|$|E
40|$|In {{this paper}} we {{introduce}} a novel {{representation of the}} significant changes in curvature along the bounding contour of planar shape. Ve call the representation the curvature primgl,sketch. We describe an implemented algorithn that computes the curvature <b>primal</b> <b>sketch</b> and illustra. te its performance {{on a set of}} tool shapes. The curvature <b>primal</b> <b>sketch</b> derites ils name from the close analogy to the <b>primal</b> <b>sketch</b> representation advocated ty Mart for descri. bi!) g significant intensity changes. We define a set of primitive parameterized curvature discontinuities, and derive expressions for their convolutions vith the first and second derivatives ot' a Gaussian. The convolved primitives, sorted according to the scale at 'which they are detected, provide us with a multi-scaled interpretation of the'contoar of a shape...|$|E
40|$|In this paper, {{we present}} a {{mathematical}} theory for Marr’s <b>primal</b> <b>sketch.</b> We first conduct a theoretical study of the descriptive Markov random field model and the generative wavelet/sparse coding model {{from the perspective of}} entropy and complexity. The competition between the two types of models defines the concept of “sketchability”, which divides image into texture and geometry. We then propose a <b>primal</b> <b>sketch</b> model that integrates the two models and, in addition, a Gestalt field model for spatial organization. We also propose a sketching pursuit process that coordinates the competition between two pursuit algorithms: the matching pursuit [8] and the filter pursuit [12], that seek to explain the image by bases and filters respectively. The model can be used to learn a dictionary of image primitives, or textons in Julesz’s language, for natural images. The <b>primal</b> <b>sketch</b> model is not only parsimonious for image representation, but produces meaningful sketches over a large number of generic images. 1...|$|E
40|$|A {{key issue}} in brain imaging {{concerns}} how {{to detect the}} functionally activated regions from PET and fMRI images. In earlier work, {{it has been shown}} that the scale-space <b>primal</b> <b>sketch</b> provides a useful tool for such analysis [1]. The method includes presmoothing with different filter widths and automatic estimation of the spatial extent of the activated regions (blobs). The purpose is to present two modifications of the scale-space <b>primal</b> <b>sketch,</b> as well as a quantitative evaluation which shows that these modifications improve the performance, measured as the separation between blob descriptors extracted from PET images and from noise images. This separation is essential for future work of associating a statistical p-value with the scale-space blob descriptors. QC 20111209 </p...|$|E
40|$|A {{dominant}} approach to brain mapping is to define functional {{regions in the}} brain by analyzing brain activation images obtained by PET or fMRI. In [1], {{it has been shown}} that the scale-space <b>primal</b> <b>sketch</b> provides a useful tool for such analysis. Some attractive properties of this method are that it only makes few assumptions about the data and the process for extracting activations is fully automatic. In the present version of the scale-space <b>primal</b> <b>sketch,</b> however, there is no method for determining p-values. The purpose here is to present a new methodology for addressing this question, by introducing a descriptor referred to as the -curve, which serves as a first step towards determining the probability of false positives, i. e. alpha. QC 20110913 </p...|$|E
40|$|Abstract. Developing a variational {{model that}} {{is capable of}} {{restoring}} both smooth (no edges) and non-smooth (with edges) images is still a valid challenge in the image processing. In this paper, we present two methods for image denoising problems based {{on the use of the}} LLT model (see [14]) and iterated total variation refinement. The idea of our methods is, first make use of the LLT model to get a smooth <b>primal</b> <b>sketch,</b> and then get some meaningful signal by iterated total variation refinement from the removed noise image. Numerical experiments show that our method is able to maintain some important information such as small details in the image, and at the same time to get a better visualization. Key words. Image denoising, staircasing effect, <b>primal</b> <b>sketch,</b> hierarchical decomposition, iter-ated regularization...|$|E
40|$|We {{present a}} novel {{approach}} 1 for extracting <b>primal</b> <b>sketch</b> features (edges, bars, blobs and ends) from a log-polar image. Symmetry operators and a PCA pre-processing module precede a set of neural networks that learn the feature’s class and contrast. Experiments show the process accurately extracts the desired feature-based image description...|$|E
40|$|When {{an image}} is viewed at varying resolutions, {{it is known}} to create {{discrete}} perceptual jumps or transitions amid the continuous intensity changes. In this paper, we study a perceptual scale-space theory which differs from the traditional image scale-space theory in two aspects. (i) In representation, the perceptual scale-space adopts a full generative model. From a Gaussian pyramid it computes a sketch pyramid where each layer is a <b>primal</b> <b>sketch</b> representation (Guo et al. in Comput. Vis. Image Underst. 106 (1) : 5 – 19, 2007) —an attribute graph whose elements are image primitives for the image structures. Each <b>primal</b> <b>sketch</b> graph generates the image in the Gaussian pyramid, and the changes between the <b>primal</b> <b>sketch</b> graphs in adjacent layers are represented {{by a set of}} basic and composite graph operators to account for the perceptual transitions. (ii) In computation, the sketch pyramid and graph operators are inferred, as hidden variables, from the images through Bayesian inference by stochastic algorithm, in contrast to the deterministic transforms or feature extraction, such as computing zerocrossings, extremal points, and inflection points in the image scale-space. Studying the perceptual transitions under the Bayesian framework makes it convenient to use the statistical modeling and learning tools for (a) modeling the Gestalt properties of the sketch graph, such as continuity and parallelism etc; (b) learning the most frequent graph operators...|$|E
40|$|Following Marr’s insight, {{we propose}} a {{generative}} image representation called <b>primal</b> <b>sketch,</b> which integrates two modeling components. The first component explains the structural {{part of an}} image, such as ob ject boundaries, by a hidden layer of image primitives. The second component models the remaining textural part without distinguishable elements by Markov random fields that interpolate the structural part of the image. We adopt an artist’s notion by calling the two components “sketchable” and “non-sketchable” parts respectively. A dictionary of image primitives are used for modeling structures in natural images, and each primitive is specified by variables for its photometric, geometric, and topological attributes. The primitives in the image representation are not independent but organized in an sketch graph. This sketch graph is modeled by a spatial Markov model that enforces Gestalt organizations. The inference of the sketch graph consists of two phases. Phase I sequentially adds the most prominent image primitives in a procedure similar to matching pursuit. Phase II edits the sketch graph {{by a number of}} graph operators to achieve good Gestalt organizations. Experiments show that the <b>primal</b> <b>sketch</b> model produces satisfactory results for a large number of generic images. The <b>primal</b> <b>sketch</b> model is not only a parsimonious image representation for lossy image coding, but also provides a meaningful mid-level generic representation for other vision tasks...|$|E
40|$|This article {{describes}} how {{a certain way}} of expressing low-level feature detectors, in terms of singularities of differential expressions defined at multiple scales in scale-space, simplifies {{the analysis of the}} effect of smoothing. It is shown how such features can be related across scales, and generally valid expressions for drift velocities are derived with examples concerning edges, junctions, Laplacean zero-crossings, and blobs. A number of invariance properties are pointed out, and a particular representation defined from such singularities, the scale-space <b>primal</b> <b>sketch,</b> is treated in more detail. Keywords: scale-space, drift velocity, feature detection, <b>primal</b> <b>sketch,</b> singularity, invariance. 1 Introduction A common way of implementing low-level feature detectors in computer vision and image processing is by applying non-linear operations to smoothed input data. Examples of this are edge detection, junction detection, and blob detection. The pre-smoothing step can be motiva [...] ...|$|E
40|$|This code is an {{implementation}} of T. Lindeberg’s scale-invariant <b>primal</b> <b>sketch</b> [5, 4] {{and is used}} for object detection in [2] and shape analysis in [3]. The code takes as input a grayscale image and convolves it with Gaussian kernels of increasing size. Using this scale-space, edge and ridge contours are found as maxima in spac...|$|E
40|$|In this paper, {{we propose}} a new {{representation}} of the cortical surface {{that may be used}} to study the cortex folding process and to recover some putative stable anatomical landmarks called sulcal roots usually burried in the depth of adult brains. This representation is a <b>primal</b> <b>sketch</b> derived from a scale space computed for the mean curvature of the cortical surface. This scale-space stems from a diffusion equation geodesic to the cortical surface. The <b>primal</b> <b>sketch</b> is made up of objects defined from mean curvature minima and saddle points. The resulting sketch aims first at highlighting significant elementary cortical folds, second at representing the fold merging process during brain growth. The relevance of the framework is illustrated by the study of central sulcus sulcal roots from antenatal to adult age. Some results are proposed for ten different brains. Some preliminary results are also provided for superior temporal sulcus...|$|E
40|$|Abstract When {{an image}} is viewed at varying resolutions, {{it is known}} to create {{discrete}} perceptual jumps or transi-tions amid the continuous intensity changes. In this pa-per, we study a perceptual scale-space theory which differs from the traditional image scale-space theory in two aspects. (i) In representation, the perceptual scale-space adopts a full generative model. From a Gaussian pyramid it computes a sketch pyramid where each layer is a <b>primal</b> <b>sketch</b> represen-tation (Guo et al. in Comput. Vis. Image Underst. 106 (1) : 5 – 19, 2007) —an attribute graph whose elements are image primitives for the image structures. Each <b>primal</b> <b>sketch</b> graph generates the image in the Gaussian pyramid, and the changes between the <b>primal</b> <b>sketch</b> graphs in adjacent layers are represented {{by a set of}} basic and composite graph oper-ators to account for the perceptual transitions. (ii) In compu-tation, the sketch pyramid and graph operators are inferred, as hidden variables, from the images through Bayesian infer-ence by stochastic algorithm, in contrast to the deterministic transforms or feature extraction, such as computing zero-crossings, extremal points, and inflection points in the image scale-space. Studying the perceptual transitions under the Bayesian framework makes it convenient to use the statisti-cal modeling and learning tools for (a) modeling the Gestalt properties of the sketch graph, such as continuity and par-allelism etc; (b) learning the most frequent graph operators, A short version was published in ICCV 05 (Wang et al. 2005) ...|$|E
40|$|A {{fundamental}} problem in brain imaging concerns how to define functional areas consisting of neurons that are activated together as populations. We propose {{that this issue}} can be ideally addressed by a computer vision tool {{referred to as the}} scale-space <b>primal</b> <b>sketch.</b> This concept has the attractive properties that it allows for automatic and simultaneous extraction of the spatial extent and the significance of regions with locally high activity. In addition, a hierarchical nested tree structure of activated regions and subregions is obtained. The subject in this article is to show how the scale-space <b>primal</b> <b>sketch</b> can be used for automatic determination of the spatial extent and the significance of rCBF changes. Experiments show the result of applying this approach to functional PET data, including a preliminary comparison with two more traditional clustering techniques. Compared to previous approaches, the method overcomes the limitations of performing the analysis at a single scale or assuming specific models of the data. QC 20111028 </p...|$|E
40|$|This paper {{presents}} a novel integrated background model for video surveillance. Our model uses a <b>primal</b> <b>sketch</b> representation for image appearance and 3 D scene geometry {{to capture the}} ground plane and major surfaces in the scene. The <b>primal</b> <b>sketch</b> model divides the background image into three types of regions — flat, sketchable and textured. The three types of regions are modeled respectively by mixture of Gaussians, image primitives and LBP histograms. We calibrate the camera and recover important planes such as ground, horizontal surfaces, walls, stairs in the 3 D scene, and use geometric information to predict the sizes and locations of foreground blobs to further reduce false alarms. Compared with the state-of-theart background modeling methods, our approach is more effective, especially for indoor scenes where shadows, highlights and reflections of moving objects and camera exposure adjusting usually cause problems. Experiment results demonstrate that our approach improves the performance of background/foreground separation at pixel level, and the integrated video surveillance system at the object and trajectory level. 1...|$|E
40|$|This paper {{presents}} a log-polar image representation composed of low-level features extracted using a connectionist approach. The low level features (edges, bars, blobs and ends) {{are based on}} Marr's <b>primal</b> <b>sketch</b> hypothesis for the human visual system [3] and are used as the entry point of an iconic vision system [1]. This unusual image representation has been created using a neural network that learns examples of the features in a window of receptive elds of the image representation. ...|$|E
40|$|This paper {{contains}} {{a survey of}} image texture analysis techniques Three broad classes of methods are discussed: pixel-based local-feature based and region-based The pixelbased models include grey level cooccurrence matrices difference histograms and energy-measures. The local feature-based models mostly rely on edges as local features and include Marrs <b>primal</b> <b>sketch</b> model and a generalization of cooccurrence matrices. Region-based models include a region-growing model and a topographic model which treats the texture image as a digital terrain model...|$|E
40|$|Abstract. Automatic 1 {{monitoring}} for {{the assessment}} of pain can sig-nificantly improve the psychological comfort of patients. Recently intro-duced databases with expert annotation opened the way for pain in-tensity estimation from facial analysis. In this contribution, pivotal face elements are identified using the Histograms of Topographical features (HoT) which are a generalization of the topographical <b>primal</b> <b>sketch.</b> In order to improve the discrimination between different pain intensity values and respectively the generalization with respect to the monitored persons, we transfer data representation from the emotion oriented Cohn-Kanade database to the UNBC McMaster Shoulder Pain database...|$|E
40|$|In this paper, {{we compare}} two {{distinct}} <b>primal</b> <b>sketch</b> feature extraction operators: {{one based on}} neural network feature learning and the other based on mathematical models of the features. We tested both kinds of operator {{with a set of}} known, but previously untrained, synthetic features and, while varying their classification thresholds, measured the operator's false acceptance and false rejection errors. Results have shown that the model-based approach is more unstable and unreliable than the learning-based approach, which presented better results with respect to the number of correctly classified features...|$|E
40|$|A {{dominant}} approach to brain mapping is to define functional {{regions in the}} brain by analyzing images of brain activation obtained from positron emission tomography (PET) and {{functional magnetic resonance imaging}} (fMRI). This paper presents an evaluation of using one such tool, called the scale-space <b>primal</b> <b>sketch,</b> for brain activation analysis. A comparison is made concerning two possible definitions of a significance measure of blob structures in scale-space, where local contrast is measured either relative to a local or global reference level. Experiments on real brain data show that (i) the global approach with absolute base level has a higher degree of correspondence to a traditional statistical method than a local approach with relative base level, and that (ii) the global approach with absolute base level gives a higher significance to small blobs that are superimposed on larger scale structures, whereas the significance of isolated blobs largely remains unaffected. Relative to previously reported works, the following two technical improvements are also presented. (i) A post-processing tool is introduced for merging blobs that are multiple responses to image structures. This simplifies automated analysis from the scale-space <b>primal</b> <b>sketch.</b> (ii) A new approach is introduced for scale-space normalization of the significance measure, by collecting reference statistics of residual noise images obtained from the general Linear model. QC 20100525 </p...|$|E
40|$|Based on {{the class}} of complex gradient-Laplace operators, we show {{the design of a}} non-separable {{two-dimensional}} wavelet basis from a single and analytically defined generator wavelet function. The wavelet decomposition is implemented by an efficient FFT-based filterbank. By allowing for slight redundancy, we obtain the Marr wavelet pyramid decomposition that features improved translation-invariance and steerability. The link with Marr’s theory of early vision is due to the replication of the essential processing steps (Gaussian smoothing, Laplacian, orientation detection). Finally, we show how to find a compact multiscale <b>primal</b> <b>sketch</b> of the image, and how to reconstruct an image from it...|$|E
40|$|Redundant sensors {{are needed}} on a mobile robot {{so that the}} {{accuracy}} with which it perceives its surroundings can be increased. Sonar and infrared sensors are used here in tandem, each compensating for deficiencies in the other. The robot combines the data from both sensors to build a representation which is more accurate than if either sensor were used alone. Another representation, the curvature <b>primal</b> <b>sketch,</b> is extracted from this perceived workspace and is used as the input to two path planning programs: one based on configuration space and one based on a generalized cone formulation of free space...|$|E
40|$|Recent psychophysical {{evidence}} suggests that the human visual system uses a <b>Primal</b> <b>Sketch</b> stage of processing that is radically different from the original proposal of Marr (1976). Spatial filters of different sizes are used by two distinct processes. One is concerned with statistical, "texture" properties of the image, the other with the spatial geometry of the image. The statistical processor appears to have immediate access to all the appropriate spatial scales in an image. The subject is able to report texture qualities no more accurately after a 1000 ms exposure than after a 10 ms exposure. The geometric processor, however, appears to scan through th...|$|E
40|$|We {{consider}} {{detection of}} local image symmetry using linear filters. We prove a simple criterion for determining if a filter {{is sensitive to}} a group of symmetries. We show that derivative-of-Gaussian (DtG) filters are excellent at detecting local image symmetry. Building on this, we propose a very simple algorithm that, based on the responses of a bank of six DtG filters, classifies each location of an image into one of seven Basic Image Features (BIFs). This effectively and efficiently realizes Marr's proposal for an image <b>primal</b> <b>sketch.</b> We summarize results on the use of BIFs for texture classification, object category detection, and pixel classification...|$|E
40|$|The {{characteristics}} and performances of a hierarchical neural architecture, inspired by models of mammalian visual cortex, are considered. The visual pathway from sensory {{space to the}} intermediate (cortical) representation is structured in three layers, with intra and inter-layer connections through feedforward and recurrent pathways. These interconnections provide a complex perceptual organization that integrates the specific functional tasks performed by each layer. This improves {{the capabilities of the}} architecture in feature extraction and segregation, further providing clues on the information content of the intermediate representation (<b>primal</b> <b>sketch).</b> Applications to preattentive vision tasks (edge and contour extractions, texture analysis and boundary completion, and defect detection) are presented with satisfactory results...|$|E
40|$|The {{inability}} of automated edge detection methods inspired from <b>primal</b> <b>sketch</b> models to accurately calculate object edges {{under the influence}} of pixel noise is an open problem. Extending the principles of image perception i. e. Weber-Fechner law, and Sheperd similarity law, we propose a new edge detection method and formulation that use perceived brightness and neighbourhood similarity calculations in the determination of robust object edges. The robustness of the detected edges is benchmark against Sobel, SIS, Kirsch, and Prewitt edge detection methods in an example face recognition problem showing statistically significant improvement in recognition accuracy and pixel noise tolerance. Comment: accepted for publication in IEEE Signal Processing Letters, 201...|$|E
40|$|A local {{change in}} {{intensity}} (edge) is a characteristic that is preserved when an image is filtered through a bandpass filter. <b>Primal</b> <b>sketch</b> representations of images, using the bandpass-filtered data, {{have become a}} common process since Marr proposed his model for early human vision. Here, researchers move beyond the <b>primal</b> <b>sketch</b> extraction to the recovery of intensity and reflectance representations using only the bandpass-filtered data. Assessing the response of an ideal step edge to the Laplacian of Gaussian (NAb/A squared G) filter, {{they found that the}} resulting filtered data preserves the original change of intensity that created the edge in addition to the edge location. Using the filtered data, they can construct the primal sketches and recover the original (relative) intensity levels between the boundaries. It was found that the result of filtering an ideal step edge with the Intensity-Dependent Spatial Summation (IDS) filter preserves the actual intensity {{on both sides of the}} edge, in addition to the edge location. The IDS filter also preserves the reflectance ratio at the edge location. Therefore, one can recover the intensity levels between the edge boundaries as well as the (relative) reflectance representation. The recovery of the reflectance representation is of special interest as it erases shadowing degradations and other dependencies on temporal illumination. This method offers a new approach to low-level vision processing as well as to high data-compression coding. High compression can be gained by transmitting only the information associated with the edge location (edge primitives) that is necessary for the recover...|$|E
