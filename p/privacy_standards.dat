94|103|Public
2500|$|The article {{noted the}} irony of Kennedy's musings about the {{difficulty}} of crafting <b>privacy</b> <b>standards</b> with technology evolving at a rapid pace when applied to a case that turned on text messages sent on [...] "two-way pager devices that were issued to employees a decade ago and that would likely be deemed antiquated by today's teenagers and young professionals", who largely tend to use cell phones for texting. [...] "Presumably, societal norms with respect to pagers are as developed as they will ever be." [...] Nor could it see work-related employer-issued pagers or other devices being used for self-expressive purposes as Kennedy suggested, since they were functionally no {{different from any other}} such item a police department might issue to officers, [...] "much like a police officer's patrol cruiser or sidearm". It did concede that the conflict between the department's written policy and Lt. Duke's verbal assurances to Quon made the issue more complex in this particular case.|$|E
5000|$|They develop {{products}} that aim to maintain strong <b>privacy</b> <b>standards</b> and practices.|$|E
5000|$|Require {{that the}} SSA's <b>privacy</b> <b>standards</b> for data sharing meet the State Privacy Standard.|$|E
25|$|In September 2015, Google {{announced}} that Google Drive for Work would be compliant {{with the new}} ISO/IEC 27018:2014 security and <b>privacy</b> <b>standard,</b> which confirmed that Google would not use data in Drive for Work accounts for advertising, enabled additional tools for handling and exporting data, more transparency about data storage, and protection from third-party data requests.|$|R
50|$|The DSF has {{provided}} monthly educational opportunities {{in a variety}} of formats to facilitate learning opportunities, whitepapers and case studies important to the industry. Some of the initial activities of the association included a member directory, online topical webinars, adoption of an industry <b>privacy</b> <b>standard,</b> and recognition of college affiliated chapters. The DSF has established Regional Networking Events, attended various industry shows, and provided industry research.|$|R
40|$|Web search logs contain {{extremely}} sensitive data, {{as evidenced by}} the recent AOL incident. However, storing and analyzing search logs can be very useful for many purposes (i. e. investigating human behavior). Thus, an important research question is how to privately sanitize search logs. Several search log anonymization techniques have been proposed with concrete privacy models. However, in all of these solutions, the output utility of the techniques is only evaluated rather than being maximized in any fashion. Indeed, for effective search log anonymization, it is desirable to derive the optimal (maximum utility) output while meeting the <b>privacy</b> <b>standard.</b> In this paper, we propose utility-maximizing sanitization based on the rigorous <b>privacy</b> <b>standard</b> of differential <b>privacy,</b> in the context of search logs. Specifically, we utilize optimization models to maximize the output utility of the sanitization for different applications, while ensuring that the production process satisfies differential privacy. An added benefit is that our novel randomization strategy ensures that the schema of the output is identical to that of the input. A comprehensive evaluation on real search logs validates the approach and demonstrates its robustness and scalability. Comment: 12 page...|$|R
5000|$|There are <b>privacy</b> <b>standards</b> put {{in place}} by the Ontario {{government}} to protect each individual who provides personal information online during the registration process.|$|E
50|$|The Naked Society is a 1964 book on privacy by Vance Packard. The book {{argues that}} changes in {{technology}} are encroaching on privacy and could create a society in the future with radically different <b>privacy</b> <b>standards.</b>|$|E
5000|$|Critics of P3P {{also argue}} that {{non-compliant}} sites are excluded. According to a study done by CyLab Privacy Interest Group at Carnegie Mellon University [...] only 15% of the top 5,000 websites incorporate P3P. Therefore, many sites that don’t include the code but do practice high <b>privacy</b> <b>standards</b> will not be accessible to users who use P3P as their only online privacy guide.|$|E
2500|$|Intelligent air conditioner, <b>privacy</b> {{glass as}} <b>standard</b> {{equipment}} ...|$|R
50|$|Lin {{has served}} as advisors to the FCC, {{pressing}} for development of app industry <b>privacy</b> policy <b>standards,</b> and strives to educate consumers on mobile security and data privacy.|$|R
5000|$|Titanium (adds Sony CD/MP3 player as <b>standard,</b> <b>privacy</b> {{glass and}} sports seats) ...|$|R
50|$|Dr. Benjamin Edelman of the Harvard Business School {{found in}} January 2006 that sites with TrustArc {{certification}} were 50% {{more likely to}} violate privacy policies than uncertified sites. Dr. Edelman has also reported that TrustArc does {{not go far enough}} to punish seal holders that break TrustArc's rules and that the organization is not quick enough in revoking the seal on companies that violate <b>privacy</b> <b>standards.</b>|$|E
50|$|In a {{consumer}} protection approach, in contrast, it is claimed that individuals {{may not have}} the time or knowledge to make informed choices, or may not have reasonable alternatives available. In support of this view, Jensen and Potts showed that most privacy policies are above the reading level of the average person. Therefore, this approach advocates greater government definition and enforcement of <b>privacy</b> <b>standards.</b>|$|E
50|$|Since its incorporation, the DSF {{has hosted}} {{a number of}} {{projects}} and initiatives with the aim to support research in, and to improve legislation, regulations, code and standards that affect the sale and use of, digital signage and other products and services within the interactive technologies industry, and the DOOH industry. It has established <b>Privacy</b> <b>Standards</b> that have since been cited in national publications and before Congress;.|$|E
5000|$|Peter Winn, {{a federal}} {{prosecutor}} in Washington and lecturer at the University of Washington School of Law, takes note in {{a history of the}} formulation of the reasonable expectation of <b>privacy</b> <b>standard</b> established in Katz that Mancusi was its first application to a later case. He finds it interesting that while Harlan first articulated it in his Katz concurrency as a two-part test with a subjective and objective component, in Mancusi he, like other judges after him, refers only to the objective aspect. [...] "Perhaps Katz, Justice Harlan felt the subjective component of the test was still needed to mirror the old trespass element that an intrusion lackpermission," [...] he speculated.|$|R
5000|$|In May 2013 Bloomberg LP {{appointed}} Palmisano as {{an independent}} advisor for the company's <b>privacy</b> and data <b>standards.</b>|$|R
40|$|N. B. This is {{the full}} {{version of the}} conference paper pub-lished as [12]. This version {{includes}} an Appendix with proofs and additional results, and corrects a few typographical er-rors discovered after publication. It also adds an improve-ment in the error bounds achieved under (, δ) -differential privacy, included as Theorem 5. Differential privacy is a robust <b>privacy</b> <b>standard</b> that has been successfully applied {{to a range of}} data analysis tasks. But despite much recent work, optimal strategies for answer-ing a collection of related queries are not known. We propose the matrix mechanism, a new algorithm for answering a workload of predicate counting queries. Given a workload, the mechanism requests answers to a different set of queries, called a query strategy, which are answere...|$|R
50|$|HIPAA (the Health Insurance Portability and Accountability Act) is a United States {{federal law}} that {{establishes}} security and <b>privacy</b> <b>standards</b> for electronic medical information exchange, including telemental health services. In order to comply with HIPAA guidelines, many providers develop their own specialized videoconferencing services, since common third-party consumer solutions do not include sufficient security and privacy safeguards. There are also {{a growing number of}} HIPAA-compliant technologies available for telepsychiatry.|$|E
50|$|One {{difficulty}} with HIPAA {{is that there}} must be a mechanism to authenticate the patient who demands access to his/her data. As a result, medical facilities have begun to ask for Social Security Numbers from patients, thus arguably decreasing privacy by simplifying the act of correlating health records with other records. The issue of consent is problematic under HIPAA, because the medical providers simply make care contingent upon agreeing to the <b>privacy</b> <b>standards</b> in practice.|$|E
5000|$|Email lists {{serve the}} same purpose in the digital world. A highly {{targeted}} list of email subscribers allows the owner to market their product and service with a fairly high probability of success. With the proliferation of spam, however, consumers are very careful about giving out their email addresses. To ease consumer concerns experienced online, businesses create [...] "Squeeze Pages" [...] that detail the businesses' <b>privacy</b> <b>standards</b> and what the subscriber will receive.|$|E
40|$|Differential {{privacy is}} a robust <b>privacy</b> <b>standard</b> {{that has been}} {{successfully}} applied {{to a range of}} data analysis tasks. Despite much recent work, optimal strategies for answering a collection of correlated queries are not known. We study the problem of devising a set of strategy queries, to be submitted and answered privately, that will support the answers to a given workload of queries. We propose a general framework in which query strategies are formed from linear combinations of counting queries, and we describe an optimal method for deriving new query answers from the answers to the strategy queries. Using this framework we characterize the error of strategies geometrically, and we propose solutions to the problem of finding optimal strategies. Comment: 22 pages, 1 figur...|$|R
5000|$|... 19 July 2011 - The Commons Culture, Media and Sport Committee begins {{follow-up}} to the 2009 inquiry into press <b>standards,</b> <b>privacy</b> and libel, including phone hacking.|$|R
30|$|Harnsamut and Natwichai (2008) {{developed}} a novel heuristic algorithm based on Classification Correction Rate (CCR) of particular database {{to secure the}} privacy and sustain the quality of data. The proposed algorithm is tested and the experimental results are validated. The heuristic algorithm {{is found to be}} highly effective and efficient. Seisungsittisunti and Natwichai 2011) highlighted the issues related to data transformation to protecting privacy for data mining technique and associative classification in an incremental-data scenario. An incremental polynomial-time algorithm is proposed to transform the data to maintain a <b>privacy</b> <b>standard</b> called k-anonymity. Quality can still be maintained even under transformation when constructing an associative classification model. Different experiments are performed to evaluate {{developed a}}lgorithm performance and compared with non-incremental algorithm. It is established to be more efficient in every problem setting. It is worth to examine the stored data in the distributed systems rather than a single repository.|$|R
5000|$|The 1978 {{report of}} the British government's Data Protection Committee {{expressed}} concern that different <b>privacy</b> <b>standards</b> in different countries {{would lead to the}} transfer of personal data to countries with weaker protections; it feared that Britain might become a [...] "data haven." [...] Also in 1978, Adrian Norman published a mock consulting study on the feasibility of setting up a company providing a wide range of data haven services, called [...] "Project Goldfish." ...|$|E
5000|$|In 2008, a Galexia Consulting study {{reported}} that TrustArc had terminated only one customer for non-compliance in the previous eleven years, despite {{a number of significant}} privacy violations which had received press coverage. [...] "The most significant criticism of trustmarks is that in practice they have proved to be virtually worthless in the face of major privacy breaches. Their <b>privacy</b> <b>standards</b> are low to begin with, but even these rules are simply not enforced against large, paying members." ...|$|E
5000|$|TrustArc's {{founding}} Executive Director, Susan Yamada, formerly {{editor of}} Upside Magazine, served until 2001. In 2000, TrustArc {{became the first}} organization to join the U.S. Department of Commerce's, and the European Union's Safe Harbor framework, and subsequently launched its EU Safe Harbor Seal Program. [...] The US-EU Safe Harbor was agreed upon by the U.S. Department of Commerce and the European Union to {{provide a framework for}} American companies to comply with European data and <b>privacy</b> <b>standards.</b>|$|E
40|$|Data sharing is {{challenging}} but important for healthcare research. Methods for privacy-preserving data dissemination {{based on the}} rigorous differential <b>privacy</b> <b>standard</b> have been developed {{but they did not}} consider the characteristics of biomedical data and make full use of the available information. This often results in too much noise in the final outputs. We hypothesized that this situation can be alleviated by leveraging a small portion of open-consented data to improve utility without sacrificing privacy. We developed a hybrid privacy-preserving differentially private support vector machine (SVM) model that uses public data and private data together. Our model leverages the RBF kernel and can handle nonlinearly separable cases. Experiments showed that this approach outperforms two baselines: (1) SVMs that only use public data, and (2) differentially private SVMs that are built from private data. Our method demonstrated very close performance metrics compared to nonprivate SVMs trained on the private data...|$|R
40|$|The Internet raises {{enhanced}} {{and unique}} concerns regarding informational health privacy and Internet pharmacy sales. As technology advances and the Internet changes {{the way people}} obtain medical services and products, protecting consumers and their informational health data in online pharmaceutical transactions is paramount. This Comment charts and compares the existing legal frameworks in the United States and Canada relative to informational health privacy. Following this discussion, each legal framework comes into sharp focus with regard to Internet pharmacy sales. Ultimately, this Comment concludes that based on the highly sensitive nature of personal medical information, a baseline <b>privacy</b> <b>standard</b> should be adopted {{at the federal level}} to provide consumers with meaningful protection and redress. To realize the benefits of online pharmaceutical transactions, there should be national standards for licensure, as well as continued tough enforcement of laws targeting rogue Web site operators, enabling this valuable medium to flourish...|$|R
50|$|Aronson {{writes on}} {{issues related to}} {{international}} communication policy, globalization and international trade and trade negotiations. His current research focuses on ways in which communication and network developments related to <b>privacy,</b> equity, <b>standard</b> setting, competition policy, and international intellectual property shape the path of globalization. His most recent writings consider the implications of new communications technologies for globalization and international communications competition.|$|R
50|$|Jurisdiction: (1) Oversight of {{laws and}} {{policies}} governing the collection, protection, use and dissemination of commercial information {{by the private sector}}, including online behavioral advertising, privacy within social networking websites and other online privacy issues; (2) Enforcement and implementation of commercial information privacy laws and policies; (3) Use of technology by the private sector to protect privacy, enhance transparency and encourage innovation; (4) <b>Privacy</b> <b>standards</b> for the collection, retention, use and dissemination of personally identifiable commercial information; and (5) Privacy implications of new or emerging technologies.|$|E
50|$|The NYCLU filed {{a lawsuit}} against the Department of Defense in 2006 (Hanson v. Rumsfeld) {{claiming}} the unconstitutionality of the JAMRS database. They succeeded in getting a settlement forcing the DOD to stop collecting Social Security Numbers, keep student information for only three years, restrict the ages of students included in the database, and maintain better <b>privacy</b> <b>standards</b> for student information. Also, the Department of the Defense clarified the procedure for opting out of the database. The Department of Defense updated those procedures in January 2011.|$|E
50|$|Grouf co-founded Firefly, an {{outgrowth}} of the RINGO project at the MIT Media Lab. Firefly invented collaborative filtering and developed the first online collaborative recommendation software, and helped to define online <b>privacy</b> <b>standards</b> as a contributor to the Platform for Privacy Preferences. He later co-founded PeoplePC, which bundled personal computers with internet service and access to other discounted products and services, and Spot Runner, an internet-based platform to produce, buy, place, and distribute targeted cable TV ads. Through Clementine Capital, he has worked with startups including Lootcrate and Pluto TV, a streaming web platform.|$|E
40|$|Abstract: In this paper, {{we present}} anapproach {{to solve the}} problem of provably secure {{execution}} of semantic web service composition plans. The integrated components of this approach include our OWL-S service matchmaker, OWLS-MX, the service composition planner, OWLS-XPlan, and the security checker module for formally verifying the compliance of the created composition plan to be executed with given data and service security policies using type-based information flow analysis. We demonstrate this approach by means of its application to ause casescenario ofhealth servicecomposition planning. 1 Introduction The composition of complex services available in the Web, and the semantic Web, at design time isawell-understood principle which is nowadays supported by, for example, service composition planners such as SHOP 2, or OWLS-XPlan. However, ensuring the secure execution of composed services still remains tobeachallenge. Related tasks range from secure communication via protection of services against misuse to the preservation ofuser data <b>privacy.</b> <b>Standard</b> approaches for secure execution ofservice...|$|R
40|$|Abstract. The privacy {{preserving}} {{data mining}} (PPDM) {{has been one}} of the most interesting, yet challenging, research issues. In the PPDM, we seek to outsource our data for data mining tasks to a third party while maintaining its privacy. In this paper, we revise one of the recent PPDM schemes (i. e., FS) which is designed for privacy preserving association rule mining (PP-ARM). Our analysis shows some limitations of the FS scheme in term of its storage requirements guaranteeing a reasonable <b>privacy</b> <b>standard</b> and the high computation as well. On the other hand, we introduce a robust definition of privacy that considers the average case privacy and motivates the study of a weakness in the structure of FS (i. e., fake transactions filtering). In order to overcome this limit, we introduce a hybrid scheme that considers both privacy and resources guidelines. Experimental results show the efficiency of our proposed scheme over the previously introduced one and opens directions for further development...|$|R
5000|$|The IGF Dynamic Coalition of Internet Rights and Principles {{introduced}} a document they had produced as a Charter of Human Rights. The Charter has twenty-one clauses based on ten broad principles that summarize {{the intent of}} the Charter: universality, accessibility, neutrality, freedom of expression, life, liberty and security, <b>privacy,</b> diversity, <b>standards</b> and regulation and governance. The Charter is a live document, still undergoing changes.|$|R
