391|1471|Public
5000|$|In {{time series}} analysis, Bartlett's method (also {{known as the}} method of {{averaged}} <b>periodograms),</b> is used for estimating power spectra. It provides a {{way to reduce the}} variance of the periodogram in exchange for a reduction of resolution, compared to standard <b>periodograms.</b> A final estimate of the spectrum at a given frequency is obtained by averaging the estimates from the <b>periodograms</b> (at the same frequency) derived from a non-overlapping portions of the original series.|$|E
5000|$|The {{method of}} {{averaged}} <b>periodograms,</b> [...] more {{commonly known as}} Welch's method, [...] divides a long xn sequence into multiple shorter, and possibly overlapping, subsequences. It computes a windowed periodogram of each one, and computes an array average, i.e. an array where each element is an average of the corresponding elements of all the <b>periodograms.</b> For stationary processes, this reduces the noise variance of each element by approximately a factor equal to the reciprocal {{of the number of}} <b>periodograms.</b>|$|E
5000|$|Average {{the result}} of the <b>periodograms</b> above for the K data segments.|$|E
40|$|Abstract — The {{sunspot number}} time series {{was used to}} examine {{different}} methods of the <b>periodogram</b> as a spectrum estimator. The <b>periodogram</b> was used as the benchmark to compare the results of the sunspot cycle period estimate to the modified <b>periodogram,</b> the Blackman-Tukey method of <b>periodogram</b> smoothing, the Welch-Bartlett method of <b>periodogram</b> averaging and the Multitaper method. The Welch-Bartlett method resulted in the closest estimate to the modern sunspot cycle period estimate of 10. 4883 years/cycle...|$|R
50|$|The {{generalized}} Lomb-Scargle <b>periodogram</b> {{has also}} {{been referred to as}} a floating mean <b>periodogram.</b>|$|R
40|$|A {{bootstrap}} {{methodology for}} the <b>periodogram</b> of a stationary process is proposed {{which is based}} on a combination of a time domain parametric and a frequency domain nonparametric bootstrap. The parametric fit is used to generate <b>periodogram</b> ordinates and imitate the essential features of the data and the weak dependence structure of the <b>periodogram</b> while a nonparametric (kernel based) correction is applied in order to catch features not represented by the parametric fit. The asymptotic theory developed shows validity of the proposed bootstrap procedure for a large class of <b>periodogram</b> statistics. For important classes of stochastie processes, validity of the new procedure is established also for <b>periodogram</b> statistics not captured by existing frequency domain bootstrap methods based on independent <b>periodogram</b> replicates...|$|R
5000|$|Least-squares {{spectral}} analysis, for computing <b>periodograms</b> in {{data that}} is not equally spaced ...|$|E
5000|$|Bartlett's {{method is}} {{the average of the}} <b>periodograms</b> taken of {{multiple}} segments of the signal to reduce variance of the spectral density estimate ...|$|E
50|$|Periodogram-based {{techniques}} introduce small biases {{that are}} unacceptable in some applications. Other techniques {{that do not}} rely on <b>periodograms</b> are presented in the spectral density estimation article.|$|E
40|$|This paper {{addresses}} {{the problem of}} detecting and estimating hidden periodicity from noisy observations when the noise distribution is asymmetric with heavy tail on one side. The ordinary <b>periodogram</b> is less effective in handling such noise. In this paper, we introduce an alternative periodogram-like function, called the quantile <b>periodogram.</b> The quantile peri-odogram is constructed from trigonometric regression where a specially designed objective function is used to substitute the squared 2 norm {{that leads to the}} ordinary <b>periodogram.</b> Simulation results are provided to demonstrate the superior performance of the quantile <b>periodogram</b> in comparison with the ordinary <b>periodogram</b> when the noise is asymmetrically distributed with a heavy tail. The asymptotic distribution of the quantile <b>periodogram</b> is derived under the white noise as-sumption. Extensions to the multivariate case and the com-plex case are also discussed. 1...|$|R
40|$|The wavelet <b>periodogram</b> is hard {{to smooth}} because of the low {{signal-to-noise}} ratio and non-stationary covariance structure. This article introduces a method for denoising a local wavelet <b>periodogram</b> by applying a Haar-Fisz transform which Gaussianises and stabilizes the variance of the <b>periodogram.</b> Consequently the transformed <b>periodogram</b> is easier to smooth. This article demonstrates {{the superiority of the}} new method over existing methods and supplies theory that proves the Gaussianising, variance stabilizing and decorrelation properties of the Haar-Fisz transform...|$|R
30|$|Since the <b>periodogram</b> is an {{unbiased}} but {{inconsistent estimator}} of the spectrum, a consistent estimator {{can be achieved}} by smoothing it (use of lag windows or averaging). One such consistent estimator is the modified (boxed) <b>periodogram.</b> Actually, Robinson (1994) proved that the averaged <b>periodogram</b> estimator was consistent under very mild conditions. It involves dividing the log of the <b>periodogram</b> into equally spaced boxes and then averaging the values inside each of the boxes leaving out very low frequencies. Further, to address the scattered nature of the <b>periodogram,</b> a robustified least squares (least-trimmed squares of regression) which minimises approximately T /  2 smallest squared residuals can be employed.|$|R
5000|$|After {{doing the}} above, the {{periodogram}} is calculated by computing the discrete Fourier transform, and then computing the squared {{magnitude of the}} result. The individual <b>periodograms</b> are then averaged, which reduces the variance of the individual power measurements. The end result is an array of power measurements vs. frequency [...] "bin".|$|E
50|$|In signal processing, a {{periodogram}} is {{an estimate}} of the spectral density of a signal. The term was coined by Arthur Schuster in 1898. Today, the periodogram is a component of more sophisticated methods (see spectral estimation). It is the most common tool for examining the amplitude vs frequency characteristics of FIR filters and window functions. FFT spectrum analyzers are also implemented as a time-sequence of <b>periodograms.</b>|$|E
50|$|During {{the war he}} also {{produced}} a series of papers extending to work of R.A. Fisher on the theory of k-statistics, and developed a number of extensions to this work through the 1950s. After the war, {{he worked on the}} theory and practice of time series analysis, and conclusively demonstrated (with the meager computing resources available at the time) that unsmoothed sample <b>periodograms</b> were unreliable estimators for the population spectrum.|$|E
40|$|Estimation of {{the memory}} {{parameter}} in time series with long range dependence is considered. A pooled log <b>periodogram</b> regression estimator is proposed that utilizes a set of mL <b>periodogram</b> ordinates with L approaching infinity rather than m ordinates used in the conventional log <b>periodogram</b> estimator. Consistency and asymptotic normality of the pooled regression estimator are established. The pooled estimator is shown to have smaller variance but larger bias than the conventional log <b>periodogram</b> estimator. Finite sample performance is assessed in simulations, and the methods are illustrated in an empirical application with inflation and stock returns. Discrete Fourier transform, log <b>periodogram</b> regression, long memory parameter, pooling frequency bands, semiparametric estimation...|$|R
5000|$|The {{spectral}} estimates can {{be obtained}} by finding the square of the magnitude of the Fourier transform also called as <b>Periodogram.</b> The spectral estimates obtained from the <b>periodogram</b> have a large variance in amplitude for consecutive <b>periodogram</b> samples or in wavenumber. This problem is resolved using techniques that constitute the classical estimation theory. They are as follows: ...|$|R
40|$|We {{show the}} {{consistency}} of the log-periodogram estimate of the long memory parameter íor long range dependent linear, non necessarily Gaussian, time series when we make a pooling oí <b>periodogram</b> ordinates. Then, we study the asymptotic behaviour oí the tapered <b>periodogram</b> of long range dependent time series íor írequencies near the origin. Finally, we obtain the asymptotic distribution of the log-periodogram estimate íor possibly non-Gaussian observations when we use the tapered <b>periodogram.</b> For that result we rely on higher order asymptotic properties of a vector of <b>periodogram</b> ordinates of the linear innovations...|$|R
5000|$|One of the periodogram's {{deficiencies}} is {{that the}} variance at a given frequency does not decrease {{as the number of}} samples used in the computation increases. It does not provide the averaging needed to analyze noiselike signals or even sinusoids at low signal-to-noise ratios. Window functions and filter impulse responses are noiseless, but many other signals require more sophisticated methods of spectral estimation. Two of the alternatives use <b>periodograms</b> as part of the process: ...|$|E
50|$|An FFT {{analyzer}} computes a time-sequence of <b>periodograms.</b> FFT {{refers to}} a particular mathematical algorithm used in the process. This is commonly {{used in conjunction with}} a receiver and analog-to-digital converter. As above, the receiver reduces the center-frequency of a portion of the input signal spectrum, but the portion is not swept. The purpose of the receiver is to reduce the sampling rate that the analyzer must contend with. With a sufficiently low sample-rate, FFT analyzers can process all the samples (100% duty-cycle), and are therefore able to avoid missing short-duration events.|$|E
5000|$|The close {{connections}} between Fourier analysis, the periodogram, and least-squares fitting of sinusoids {{have long been}} known. [...] Most developments, however, are restricted to complete data sets of equally spaced samples. In 1963, J. F. M. Barning of Mathematisch Centrum, Amsterdam, handled unequally spaced data by similar techniques, including both a periodogram analysis equivalent {{to what is now}} referred to the Lomb method, and least-squares fitting of selected frequencies of sinusoids determined from such <b>periodograms,</b> connected by a procedure that is now known as matching pursuit with post-backfitting or orthogonal matching pursuit.|$|E
40|$|It {{has been}} well known for at least twenty years that {{computing}} the maximizer of the <b>periodogram,</b> in order to estimate the unknown frequency in a noisy sinusoid, is problematic. In particular, because the <b>periodogram</b> is highly nonlinear, a grid size of order o (T- 1) is needed to find the maximizer reliably, where T is the sample size, and that Newton 2 ̆ 7 s method may fail to find the zero of the first derivative of the <b>periodogram</b> closest to the maximizer of the <b>periodogram</b> calculated, for example, using the FFT. In this paper, we show that Newton 2 ̆ 7 s method does, in fact, work if it is applied to an appropriately chosen monotonic function of the <b>periodogram...</b>|$|R
40|$|It is a {{well-known}} fact that the <b>periodogram</b> ordinates of an lid mean-zero Gaussian sequence at the Fourier frequencies constitute an lid exponential vector, hence the maximum of these <b>periodogram</b> ordinates has a limiting Gumbel distribution. We show for a non-Gaussian lid mean-zero, finite variance sequence that this statement remains valid. We also prove that the point process constructed from the <b>periodogram</b> ordinates converges to a Poisson process. This implies the joint weak convergence of the upper order statistics of the <b>periodogram</b> ordinates. These results are {{in agreement with the}} empirically observed phenomenon that various functionals of the <b>periodogram</b> ordinates of an lid finite variance sequence have very much the same asymptotic behavior as the same functionals applied to an lid exponential sample...|$|R
40|$|The {{evolutionary}} <b>periodogram</b> {{has been}} introduced to mechanical fault diagnosis and relationship between the evolutionary <b>periodogram</b> and time-frequency spectrogram has been investigated. The evolutionary <b>periodogram</b> is unveiled as an especially windowed spectrogram, and is applied to gearbox fault diagnosis. It {{has been shown that}} the window used in the evolutionary <b>periodogram</b> is not a single function but a combination of a set of functions. Two cases of gearbox diagnosis are presented as examples of application. Vibration signals and a synchronous signal are collected for the analysis. The time synchronous averaging is used to reduce background noise or random transients to enhance the periodicity of a specific gear rotation. The performance of the evolutionary <b>periodogram</b> has been compared with the spectrogram for gear diagnosis, showing that the evolutionary <b>periodogram</b> is an alternative technique in time-frequency analysis for fault detection and better resolution can be obtained as more choices are offered by the way of constructing the window...|$|R
40|$|We propose {{using the}} {{integrated}} periodogram to classify time series. The method assigns a new element {{to the group}} minimizing {{the distance from the}} integrated periodogram of the element to the group mean of integrated <b>periodograms.</b> Local computation of these <b>periodograms</b> allows the application of the approach to non- -stationary time series. Since the integrated <b>periodograms</b> are functional data, we apply depth-based techniques to make the classification robust. The method provides small error rates with both simulated and real data, and shows good computational behaviour...|$|E
30|$|The {{concept of}} {{multiple}} windows or multitapers {{was invented by}} David Thomson [8, 9], but multitapers were actually used much earlier {{in the form of}} one window shifted in time, the Welch method or Weighted Overlap Segmented Averaging (WOSA) by Welch [10]. The main idea of multitapers is to reduce the variance of the periodogram by averaging several uncorrelated <b>periodograms.</b> The time-shifted window by Welch gives uncorrelated <b>periodograms</b> as the time-shifted window overlaps different data sequences, although the same window was used. The idea by Thomson was to use the same data sequence for all <b>periodograms,</b> i.e., the whole data sequence, but to change the shape of the window for the different <b>periodograms</b> in a way that gave uncorrelated <b>periodograms</b> and thereby reduced variance. For smooth spectra, the Thomson multitaper method is used [8], but for spectra with larger dynamics and peaks, the peak matched multiple windows [11], the sinusoidal multitapers [12], and also more advanced multitaper methods, such as the adaptive Thomson method [8], {{have been shown to be}} more suitable.|$|E
40|$|This paper {{sets forth}} {{some of the}} salient results in the algebra of {{circulant}} matrices {{which can be used}} in time-series analysis. It provides easy derivations of some results that are central to the analysis of statistical <b>periodograms</b> and empirical spectral density functions. A statistical test for the stationarity or homogeneity of empirical processes is also presented. Time-series analysis, Circulant matrices, Discrete Fourier transforms, <b>Periodograms...</b>|$|E
5000|$|The {{standard}} Lomb-Scargle <b>periodogram</b> {{is valid}} for a model with zero mean. Commonly, this is approximated by subtracting {{the mean of}} the data before calculating the <b>periodogram.</b> However, this is an inaccurate assumption when {{the mean of the}} model (the fitted sinusoids) is non-zero. The generalized Lomb-Scargle <b>periodogram</b> removes this assumption, and explicitly solves for the mean. In this case, the function fitted is ...|$|R
30|$|Having {{calculated}} the <b>periodogram,</b> {{the next step}} is to identify peaks within the <b>periodogram</b> and to return a list of targets, including their ranges and relative velocities. We call this process target detection.|$|R
50|$|<b>Periodogram</b> smoothing.|$|R
40|$|The report {{discusses}} {{methods for}} evaluating stability of technological processes for production of pipes. It is {{shown that the}} statistical methods of quality assessment technology does not provide the required level of confidence to go to selective methods of control. It is proposed to use the comparison of smoothed <b>periodograms</b> for randomly selected tubes from the party. Invited to quantify the similarity of <b>periodograms,</b> {{which can be used}} as a measure of stability technology...|$|E
40|$|We {{establish}} {{asymptotic normality}} of weighted sums of <b>periodograms</b> of a stationary linear process where weights {{depend on the}} sample size. Such sums appear in numerous statistical applications and {{can be regarded as}} a discretized versions of quadratic forms involving integrals of weighted <b>periodograms.</b> Conditions for asymptotic normality of these weighted sums are simple, minimal, and resemble Lindeberg-Feller condition for weighted sums of independent and identically distributed random variables. Our results are applicable to a large class of short, long or negative memory processes. The proof is based on sharp bounds derived for Bartlett type approximation of these sums by the corresponding sums of weighted <b>periodograms</b> of independent and identically distributed random variables. Comment: Published in at [URL] the Bernoulli ([URL] by the International Statistical Institute/Bernoulli Society ([URL]...|$|E
40|$|<b>Periodograms</b> {{are used}} as a key {{significance}} assessment and visualisation tool to display the significant periodicities in unevenly sampled time series. We introduce a framework of <b>periodograms,</b> called "Agatha", to disentangle periodic signals from correlated noise and to solve the 2 -dimensional model selection problem: signal dimension and noise model dimension. These <b>periodograms</b> are calculated by applying likelihood maximization and marginalization and combined in a self-consistent way. We compare Agatha with other <b>periodograms</b> {{for the detection of}} Keplerian signals in synthetic radial velocity data produced for the Radial Velocity Challenge as well as in radial velocity datasets of several Sun-like stars. In our tests we find Agatha is able to recover signals to the adopted detection limit of the radial velocity challenge. Applied to real radial velocity, we use Agatha to confirm previous analysis of CoRoT- 7 and to find two new planet candidates with minimum masses of 15. 1 M_⊕ and 7. 08 M_⊕ orbiting HD 177565 and HD 41248, with periods of 44. 5 d and 13. 4 d, respectively. We find that Agatha outperforms other <b>periodograms</b> in terms of removing correlated noise and assessing the significances of signals with more robust metrics. Moreover, {{it can be used to}} select the optimal noise model and to test the consistency of signals in time. Agatha is intended to be flexible enough to be applied to time series analyses in other astronomical and scientific disciplines. Agatha is available at [URL] 22 pages, 16 figures, 5 tables, MNRAS in press, the app is available at [URL]...|$|E
40|$|We {{show the}} {{consistency}} of the log-periodogram regression estimate of the long memory parameter for long range dependent linear, not necessarily Gaussian, time series when we make a pooling of <b>periodogram</b> ordinates. Then, we study the asymptotic behavior of the tapered <b>periodogram</b> of long range dependent time series for frequencies near the origin, and we obtain the asymptotic distribution of the log-periodogram estimate for possibly non-Gaussian observation when the tapered <b>periodogram</b> is used. For these results we rely on higher order asymptotic properties of a vector of <b>periodogram</b> ordinates of the linear innovations. Finally, we assess the validity of the asymptotic results for finite samples via Monte Carlo simulation. Publicad...|$|R
40|$|In {{the time}} series {{literature}} one can often find {{the claim that}} the <b>periodogram</b> ordinates of an iid sequence at the Fourier frequencies behave like an iid standard exponential sequence. We review some results about functions of these <b>periodogram</b> ordinates, including the convergence of extremes, point processes, the empirical distribution function and the empirical process. We show when the analogy with an iid exponential sequence is valid and study situations when it fails. <b>Periodogram</b> ordinates of an infinite variance iid sequence are also considered. <b>Periodogram</b> Fourier frequency iid sequence Asymptotic normality Empirical process Point process Weyl's theorem Infinite variance process Stable distribution Asymptotic expansion Functional CLT...|$|R
40|$|We {{address the}} problem of {{assessing}} the statistical significance of candidate periodicities found using the so-called `multi-harmonic' <b>periodogram,</b> which is being used for detection of non-sinusoidal signals, and is based on the least-squares fitting of truncated Fourier series. The recent investigation (Baluev 2008) made for the Lomb-Scargle <b>periodogram</b> is extended to the more general multi-harmonic <b>periodogram.</b> As a result, closed and efficient analytic approximations to the false alarm probability, associated with multi-harmonic <b>periodogram</b> peaks, are obtained. The resulting analytic approximations are tested under various conditions using Monte Carlo simulations. The simulations showed a suitable precision and robustness of these approximations. Comment: 8 pages, 6 figures, 1 table. Accepted to MNRA...|$|R
