10000|4902|Public
25|$|Geodesics {{without a}} {{particular}} <b>parameterization</b> are {{described by a}} projective connection.|$|E
25|$|Under a <b>parameterization</b> of long host {{lifespan}} {{and short}} infectious period, {{they found that}} strains would form self-organized sets that would emerge and replace one another.|$|E
25|$|The {{addition}} of another parameter (a shift parameter) formally {{results in a}} shifted log-logistic distribution, but this is usually considered in a different <b>parameterization</b> so that the distribution can be bounded above or bounded below.|$|E
40|$|Abstract. We {{address the}} {{question}} of the degree of unirational <b>parameterizations</b> of degree four and degree three del Pezzo surfaces. Specifically we show that degree four del Pezzo surfaces over finite fields admit degree two <b>parameterizations</b> and minimal cubic surfaces admit <b>parameterizations</b> of degree 6. It is an open question whether or not minimal cubic surfaces over finite fields can admit degree 3 or 4 <b>parameterizations.</b> 1...|$|R
40|$|I {{describe}} <b>parameterizations</b> of realistic e^±- and γ-beam spectra at future linear e^+e^ [...] colliders. Emphasis {{is put on}} {{simplicity and}} reproducibility of the <b>parameterizations,</b> supporting reproducible physics simulations. The <b>parameterizations</b> are implemented in a library of distribution functions and event generators...|$|R
40|$|<b>Parameterizations</b> {{of double}} nucleon removal from the {{electromagnetic}} and strong interactions of cosmic rays with nuclei are presented. These <b>parameterizations</b> are {{an extension of}} previous single nucleon removal <b>parameterizations</b> and combined they represent the dominant part of the electromagnetic dissociation encountered by a cosmic ray on its traversal through matter. Such <b>parameterizations</b> should be very useful in studying cosmic-ray transport through the interstellar medium, the Earth's atmosphere, spacecraft walls, and extraterrestrial matter...|$|R
25|$|The KH-99 {{algorithm}} by Knudsen and Hein {{lays the}} basis of the Pfold approach to predicting RNA secondary structure. In this approach the <b>parameterization</b> requires evolutionary history information derived from an alignment tree in addition to probabilities of columns and mutations. The grammar probabilities are observed from a training dataset.|$|E
25|$|The <b>parameterization</b> with k and θ {{appears to}} be more common in {{econometrics}} and certain other applied fields, where for example the gamma distribution is frequently used to model waiting times. For instance, in life testing, the waiting time until death is a random variable that is frequently modeled with a gamma distribution.|$|E
25|$|The {{database}} of compounds used for <b>parameterization,</b> i.e., the resulting {{set of parameters}} and functions is called the force field, {{is crucial to the}} success of molecular mechanics calculations. A force field parameterized against a specific class of molecules, for instance proteins, would be expected to only have any relevance when describing other molecules of the same class.|$|E
40|$|International audienceThis article aims at {{reviewing}} the state-of-the-science <b>parameterizations</b> for modelling dry deposition and scavenging of atmospheric tracers, {{with a focus}} on radionuclides. These <b>parameterizations</b> are key components of the numerical models that are used for environmental forecast. We present detailed models and <b>parameterizations.</b> Both are characterized by many uncertainties...|$|R
40|$|<b>Parameterizations</b> {{of single}} nucleon {{emission}} from the electromagnetic interactions of cosmic rays with nuclei are presented. These <b>parameterizations</b> {{are based upon}} the most accurate theoretical calculations available today. When coupled with Strong interaction <b>parameterizations,</b> they should be very suitable for use in cosmic ray propagation through intersteller space, the Earth's atmosphere, lunar samples, meteorites and spacecraft walls...|$|R
30|$|Hazard <b>parameterizations</b> can fit exponential, Weibull and Gompertz distributions. Widely used log-time <b>parameterizations</b> are exponential, Weibull, log-normal, log-logistic and the {{generalized}} gamma distribution (Cleves, Gutierrez, Gould, & Marchenko 2010).|$|R
25|$|In {{terms of}} {{algebraic}} geometry, the algebraic variety of rational {{points on the}} unit circle is birational to the affine line over the rational numbers. The unit circle is thus called a rational curve, {{and it is this}} fact which enables an explicit <b>parameterization</b> of the (rational number) points on it by means of rational functions.|$|E
25|$|The {{most obvious}} {{reason is that}} the list of simple groups is quite complicated: with 26 {{sporadic}} groups there are likely to be many special cases that have to be considered in any proof. So far no one has yet found a clean uniform description of the finite simple groups similar to the <b>parameterization</b> of the compact Lie groups by Dynkin diagrams.|$|E
25|$|The TIP4P model, first {{published}} in 1983, is widely implemented in computational chemistry software packages and often used for the simulation of biomolecular systems. There have been subsequent reparameterizations of the TIP4P model for specific uses: the TIP4P-Ew model, for use with Ewald summation methods; the TIP4P/Ice, for simulation of solid water ice; and TIP4P/2005, a general <b>parameterization</b> for simulating the entire phase diagram of condensed water.|$|E
40|$|Total {{cross section}} <b>parameterizations</b> for neutral and charged pion {{production}} in nucleon-nuelcon collisions are {{compared to an}} extensive set of experimental data over the projectile momentum range from threshold to 300 GeV. Both proton-proton and proton-neutron reactions are considered. Good agreement between <b>parameterizations</b> and experiment is found, and therefore the <b>parameterizations</b> will be useful for applications, such as transport codes...|$|R
40|$|Retention and {{refreezing}} of meltwater are {{acknowledged to}} be important processes for the mass budget of polar glaciers and ice sheets. Several <b>parameterizations</b> of these processes exist for use in energy and mass balance models. Due {{to a lack of}} direct observations, validation of these <b>parameterizations</b> is difficult. In this study we compare a set of 6 refreezing <b>parameterizations</b> against output of the Regional Atmospheric Climate Model (RACMO 2), applied to the Greenland ice sheet. In RACMO 2, refreezing is explicitly calculated in a snow model that calculates vertical profiles of temperature, density and liquid water content. For consistency, the <b>parameterizations</b> are forced with output (surface temperature, precipitation and melt) of RACMO 2. For the ice sheet-integrated amount of refreezing and its inter-annual variations, all <b>parameterizations</b> give similar results, especially after some tuning. However, the spatial distributions differ significantly. Results are especially sensitive to the choice of the depth of the thermally active layer, which determines the cold content of the snow in most <b>parameterizations...</b>|$|R
40|$|Our {{approach}} involved validating <b>parameterizations</b> directly against measurements {{from field}} programs, and using this validation to tune existing <b>parameterizations</b> and {{to guide the}} development of new ones. We have used a single-column model (SCM) to make the link between observations and <b>parameterizations</b> of clouds, including explicit cloud microphysics (e. g., prognostic cloud liquid water used to determine cloud radiative properties). Surface and satellite radiation measurements were used to provide an initial evaluation of the performance of the different <b>parameterizations.</b> The results of this evaluation will then used to develop improved cloud and cloud-radiation schemes, which were tested in GCM experiments...|$|R
25|$|Solutions to this {{apparent}} contradiction may include exotic mechanisms {{that do not}} require a sustained CO2-H2O greenhouse, such as episodic heating due to volcanism or impacts. Other possibilities (other than misinterpretation of the geology and geomorphology) are defects in the physics of, or boundary conditions for, the climate models - a stronger Sun than current theory predicts, defective assumptions about trace (but powerful) greenhouse gases, or failings in the <b>parameterization</b> of CO2 clouds.|$|E
25|$|Inferences about regoliths from phase curves are {{frequently}} based on Hapke <b>parameterization.</b> However, in a blind test M. Shepard and P. Helfenstein found no {{strong evidence that}} {{a particular set of}} Hapke parameters derived from photometric data could uniquely reveal the physical state of laboratory samples. These tests included modeling the three-term Henyey-Greenstein phase functions and the coherent backscatter opposition effect. This negative finding suggests that the radiative transfer model developed by B. Hapke may be inadequate for physical modeling based on photometry.|$|E
25|$|The <b>parameterization</b> {{of these}} very {{coarse-grained}} models must be done empirically, by matching {{the behavior of the}} model to appropriate experimental data or all-atom simulations. Ideally, these parameters should account for both enthalpic and entropic contributions to free energy in an implicit way. When coarse-graining is done at higher levels, the accuracy of the dynamic description may be less reliable. But very coarse-grained models have been used successfully to examine a wide range of questions in structural biology, liquid crystal organization, and polymer glasses.|$|E
40|$|Different <b>parameterizations</b> for {{vertical}} mixing {{and the effects}} of ocean mesoscale eddies are tested in an eddy-permitting ocean model. It has a horizontal resolution averaging about 0. 78 and was used as the ocean component of the parallel climate model. The old ocean <b>parameterizations</b> used in that coupled model were replaced by the newer <b>parameterizations</b> used in the climate system model. Both ocean-alone and fully coupled integrations were run for at least 100 years. The results clearly show that the drifts in the upper-ocean temperature profile using the old <b>parameterizations</b> are substantially reduced in both sets of integrations using the newer <b>parameterizations.</b> The sea-ice distribution in the fully coupled integration using the newer ocean parameteri-zations is also improved. However, the sea-ice distribution is sensitive to both sea-ice <b>parameterizations</b> and the atmospheric forcing, in addition to being dependent on the ocean simulation. The newer ocean <b>parameterizations</b> have been shown to improve considerably the solutions in non-eddy-resolving configurations, such as in the climate system model, where the horizontal resolution of the ocean component is about 28. The work presented here is a clear demonstration that the improvements continue into the eddy-permitting regime, where the ocean component has an average horizontal resolution of less than 18. 1...|$|R
40|$|I {{describe}} <b>parameterizations</b> of realistic e^±- and γ-beam spectra at future linear e^+e^ [...] colliders. Emphasis {{is put on}} {{simplicity and}} reproducibility of the <b>parameterizations,</b> supporting reproducible physics simulations. The <b>parameterizations</b> are implemented in a library of distribution functions and event generators. Comment: 26 pages, LaTeX (using amsmath. sty), PostScript figures included, paper saving version formatted for A 4 available from ftp://crunch. ikp. physik. th-darmstadt. de/pub/preprints/IKDA- 96 - 13. ps. g...|$|R
40|$|The {{literature}} on <b>parameterizations</b> of cloud microphysical processes was reviewed {{to examine the}} theoretical bases of those <b>parameterizations</b> and to evaluate their applicability to regional models. New <b>parameterizations</b> were produced by multiple regression upon the solution fields derived from simulations of a cloud model incorporating sophisticated microphysics. The currently available rates for cloud microphysical interactions were generally derived {{under the assumption that}} the size distribution functions for various hydrometeors are given. Such <b>parameterizations</b> must therefore be applied with caution because the spectral evolution of various types of hydrometeors in reality varies significantly during the stages of cloud development. Uncertainties exist in assigning values for aerodynamic properties such as the bulk collection efficiency, and the growth processes for various types of ice crystals are not well enough known for accurate multiphase cloud-microphysics <b>parameterizations.</b> The new <b>parameterizations,</b> in general, compare favorably with those currently available and are more efficient and applicable to regional models. The largest discrepancies occur in the autoconversion rates, whereas the accretion rates agree closely when the assumed collection efficiencies in other formulas are smaller than unity...|$|R
25|$|Various sources can {{contribute}} {{to a range of}} simulation results. The range of the simulation results is defined as model uncertainty. One of the most important sources not possible to quantify is the conceptual model, which is developed and defined by the modeller. Further sources are the <b>parameterization</b> of the model regarding the hydraulic (only when simulating transport) and mineralogical properties. The parameters used for the geochemical simulations can also contribute to model uncertainty. These are the applied thermodynamic database and the parameters for the kinetic minerals dissolution. Differences in the thermodynamic data (i.e. equilibrium constants, parameters for temperature correction, activity equations and coefficients) can result in large uncertainties. Furthermore, the large spans of experimentally derived rate constants for minerals dissolution rate laws can cause large variations in simulation results. Despite this is well-known, uncertainties are not frequently considered when conducting geochemical modelling.|$|E
25|$|The four-site {{models have}} four {{interaction}} points by adding one dummy atom near of the oxygen along the bisector of the HOH {{angle of the}} three-site models (labeled M in the figure). The dummy atom only has a negative charge. This model improves the electrostatic distribution around the water molecule. The first model to use this approach was the Bernal–Fowler model published in 1933, which {{may also be the}} earliest water model. However, the BF model doesn't reproduce well the bulk properties of water, such as density and heat of vaporization, and is thus of historical interest only. This is a consequence of the <b>parameterization</b> method; newer models, developed after modern computers became available, were parameterized by running Metropolis Monte Carlo or molecular dynamics simulations and adjusting the parameters until the bulk properties are reproduced well enough.|$|E
500|$|The {{amount of}} solar {{radiation}} reaching the ground, {{as well as}} the formation of cloud droplets occur on the molecular scale, and so they must be parameterized before they can be included in the model. [...] Atmospheric drag produced by mountains must also be parameterized, as the limitations in the resolution of elevation contours produce significant underestimates of the drag. [...] This method of <b>parameterization</b> is also done for the surface flux of energy between the ocean and the atmosphere, in order to determine realistic sea surface temperatures and type of sea ice found near the ocean's surface. [...] Sun angle {{as well as the}} impact of multiple cloud layers is taken into account. [...] Soil type, vegetation type, and soil moisture all determine how much radiation goes into warming and how much moisture is drawn up into the adjacent atmosphere, and thus it is important to parameterize their contribution to these processes. [...] Within air quality models, parameterizations take into account atmospheric emissions from multiple relatively tiny sources (e.g. roads, fields, factories) within specific grid boxes.|$|E
40|$|Extracting the {{geometric}} characteristics of conic sections, {{such as their}} center, axes and foci, from their defining equations is required for various applications in computer graphics and geometric modeling. Although there exist standard techniques for computing {{the geometric}} characteristics for conics in implicit form, in shape modeling applications conic sections are often represented by rational quadratic <b>parameterizations.</b> Here we present closed formulas for computing the geometric characteristics of conics directly from their quadratic <b>parameterizations</b> without resorting to implicitization procedures. Our approach uses the invariants of rational quadratic <b>parameterizations</b> under rational linear reparameterizations. These invariants are also used to give a complete characterization of degenerate conics represented by rational quadratic <b>parameterizations.</b> link_to_subscribed_fulltex...|$|R
40|$|We {{present a}} {{combined}} analy 8 is of apparent optical properties and inherent optical {{properties of the}} California Current based on multi-instrument bio-optical measurements during the California Cooperative Oceanic Fisheries Investigation (Ca 1 COFI) cruises. Detailed radiative transfer model-ing is employed and radiance and irradiances for the model are derived and compared to measured values. Blo-optical <b>parameterizations</b> for the California Current are developed and compared to existing <b>parameterizations</b> for Case 1 waters. Discrepancies between absorption <b>parameterizations</b> are discussed...|$|R
40|$|Abstract—Some {{general issues}} in the “black-box ” {{identification}} of multivariable systems are first discussed. It is then suggested that balanced <b>parameterizations</b> {{can be used to}} give identifiable forms. A particular advantage is that balanced <b>parameterizations</b> are known for several useful classes of linear dynamic mod-els, including stable minimal models, minimum-phase models, positive-real models, and normalized coprime factor models. Before optimizing the parameters of balanced <b>parameterizations,</b> an initial model must be found. We use realization-based meth-ods and so-called “subspace ” methods for this purpose. These methods are very effective at finding accurate initial models without preliminary estimation of various structural indexes. The paper ends with two simulation examples, which compare the use of balanced <b>parameterizations</b> with more traditional ones, and three “real ” examples based on practical problems: a distillation column, an industrial dryer, and the (irrational) spectrum of sea waves. Index Terms—Balanced <b>parameterizations,</b> identifiable forms, multivariable systems, parameter estimation, system identifica-tion. I...|$|R
2500|$|The Wolfenstein <b>parameterization</b> of the CKM matrix, is an {{approximation}} {{of the standard}} <b>parameterization.</b> To order λ3, it is: ...|$|E
2500|$|Such a {{rational}} <b>parameterization</b> {{may be considered}} in the projective space by equating the first projective coordinates to the numerators of the <b>parameterization</b> and the last one to the common denominator. As the parameter is defined in a projective line, the polynomials in the parameter should be homogenized. For example, the projective <b>parameterization</b> of above ellipse is ...|$|E
2500|$|An affine {{variety is}} a {{rational}} variety {{if it is}} birationally equivalent to an affine space. This means that the variety admits a rational <b>parameterization.</b> For example, the circle of equation [...] is a rational curve, as it has the <b>parameterization</b> ...|$|E
40|$|The {{long-term}} {{goal of this}} research is to refine and extend simple (existing) model <b>parameterizations</b> for turbulent diapycnal mixing for use in large scale numerical ocean models where such processes occur at the subgrid-scale. From a scientific view point, the goal is to obtain new insights into the dynamics of stratified turbulence that will translate into simple effective <b>parameterizations</b> for use in ocean models. OBJECTIVES The primary objective of this project is {{to bridge the gap between}} <b>parameterizations</b> and models for small-scale turbulent mixing developed from fundamental direct numerical simulations (DNS) and grid turbulence experiments (Venayagamoorthy and Stretch 2006, 2010, Stretch and Venayagamoorthy 2010) to geophysical (mesoscale and larger) scale models with an emphasis on making progress towards improved turbulent <b>parameterizations</b> in the ocean. The strategy is to use model-data comparisons in conjunction with theoretical modeling efforts to investigate and improve the efficacy of existing <b>parameterizations</b> for turbulent mixing. APPROACH This research takes a twin pronged approach involving process studies to assess existing turbulen...|$|R
40|$|Our {{overall goal}} is {{identical}} {{to that of the}} Atmospheric Radiation Measurement (ARM) Program: the development of new and improved <b>parameterizations</b> of cloud-radiation effects and related processes, using ARM data at all three ARM sites, and the implementation and testing of these <b>parameterizations</b> i...|$|R
40|$|Calculated surface fluxes {{from seven}} surface layer <b>parameterizations</b> are {{verified}} against 45 months of ob-servations from Halley, Antarctica, with a temporal resolution of 1 h. The surface layer <b>parameterizations</b> {{are taken from}} widely used numerical models including the National Center for Atmospheric Research (NCAR...|$|R
