0|450|Public
5000|$|In a Markov chain, a state [...] {{is said to}} be ergodic if it is {{aperiodic}} and <b>positive</b> <b>recurrent</b> (a <b>state</b> is <b>recurrent</b> {{if there}} is a nonzero probability of exiting the state and the probability of an eventual return to it is 1; if the former condition is not true the state is [...] "absorbing"). If all states in a Markov chain are ergodic, the chain {{is said to be}} ergodic.|$|R
40|$|Finite, discrete-time Markov chain {{models of}} genetic {{algorithms}} {{have been used}} successfully {{in the past to}} understand the complex dynamics of a simple GA. Markov chains can exactly model the GA by accounting for all of the stochasticity introduced by various GA operators, such as initialization, selection, crossover, and mutation. Although such models quickly become unwieldy with increasing population size or genome length, they provide initial insights that guide our development of approximate, scalable models. In this study, we use Markov chains to analyze the stochastic effects of the "niching operator" of a niched GA. Specifically, we model the effect of fitness sharing on a singlelocus genome. Without niching, our model is an absorbing Markov chain. With niching, we are dealing with a "quasi-ergodic" Markov chain. Rather than calculating expected times to absorption, we are interested in steady-state probabilities for <b>positive</b> <b>recurrent</b> <b>states.</b> Established te [...] ...|$|R
40|$|The {{theory of}} $L^ 2 $-spectral gaps for {{reversible}} Markov chains {{has been studied}} by many authors. In this paper we consider <b>positive</b> <b>recurrent</b> general <b>state</b> space Markov chains with stationary transition probabilities. Replacing the assumption of reversibility by a less strong one, we still obtain a simple necessary and sufficient condition for the spectral gap property of the associated Markov operator in terms of isoperimetric constant. Moreover, we define a new sequence of isoperimetric constants which provides a necessary and sufficient condition {{for the existence of}} a spectral gap in a very general setting. Finally, these results are used to obtain simple sufficient conditions for the existence of a spectral gap in terms of the first and second order transition probabilities...|$|R
40|$|Abstract — This {{paper is}} a {{continuation}} of our previous work and discusses the consensus problem for a network of dynamic agents with directed information flows and random switching topologies. The switching is determined by a Markov chain, each topology corresponding to a state of the Markov chain. We show that in order to achieve consensus almost surely and from any initial state, each union of graphs from the sets of graphs corresponding to the closed <b>positive</b> <b>recurrent</b> sets of <b>states</b> of the Markov chain must have a spanning tree. The analysis relies on tools from matrix theory, Markovian jump linear systems theory and random process theory. The distinctive feature of this work is addressing the consensus problem with “Markovian switching ” topologies. I...|$|R
30|$|Let us {{notice that}} if the process X is <b>positive</b> <b>recurrent</b> (or ergodic) and the {{processes}} X and X are similar, then also the process X (with μ̃_ 0 = 0) is <b>positive</b> <b>recurrent</b> (ergodic).|$|R
30|$|By Corollary  1, if b_i< 0 {{for some}} i∈ S, then the trivial {{solution}} of subsystem (4) is SGAS. Hence Theorem  1 {{means that if}} the trivial solution of every individual subsystem of system (3) is SGAS, then, {{as the result of}} Markovian switching, the trivial solution of system (3) is still SGAS. On the other hand, if b_i> 0 for some i∈ S, then the solution of subsystem (4) is <b>positive</b> <b>recurrent</b> and has a UEAID. Thus Theorem  1 shows that if the solution of every subsystem of system (3) is <b>positive</b> <b>recurrent</b> and has a UEAID, then, as the result of Markovian switching, the solution of system (3) is still <b>positive</b> <b>recurrent</b> and has a UEAID. However, Theorem  1 indicates a much more interesting result: If the solution of some subsystems in system (3) is <b>positive</b> <b>recurrent</b> and has a UEAID while the trivial solution of some subsystems is SGAS, then, as the results of Markovian switching, the solution of system (3) may be <b>positive</b> <b>recurrent</b> and has a UEAID or tends to its trivial solution, depending on the sign of b̅=∑_i= 1 ^mπ_ib_i. If b̅> 0, then the solution of system (3) is <b>positive</b> <b>recurrent</b> and has a UEAID; if b̅< 0, then the trivial solution of system (3) is SGAS.|$|R
40|$|AbstractThis article {{attempts}} {{to lay a}} proper foundation for studying asymptotic properties of nonhomogeneous diffusions, extends earlier criteria for transience, recurrence, and positive recurrence, and provides sufficient conditions for the weak convergence of a shifted nonhomogeneous diffusion to a limiting stationary homogenous diffusion. A functional central limit theorem is proved for the class of <b>positive</b> <b>recurrent</b> homogeneous diffusions. Upper and lower functions for <b>positive</b> <b>recurrent</b> nonhomogeneous diffusions are also studied...|$|R
25|$|<b>State</b> i is <b>positive</b> <b>{{recurrent}}</b> (or non-null persistent) if Mi is finite; otherwise, state i is null recurrent (or null persistent).|$|R
40|$|This article {{attempts}} {{to lay a}} proper foundation for studying asymptotic properties of nonhomogeneous diffusions, extends earlier criteria for transience, recurrence, and positive recurrence, and provides sufficient conditions for the weak convergence of a shifted nonhomogeneous diffusion to a limiting stationary homogenous diffusion. A functional central limit theorem is proved for the class of <b>positive</b> <b>recurrent</b> homogeneous diffusions. Upper and lower functions for <b>positive</b> <b>recurrent</b> nonhomogeneous diffusions are also studied. Stopping times space-time harmonic functions invariant measures...|$|R
40|$|AbstractThe <b>recurrent</b> <b>states</b> of the Abelian sandpile model (ASM) {{are those}} states that appear {{infinitely}} often. For this reason they occupy a central position in ASM research. We present several new results for classifying <b>recurrent</b> <b>states</b> of the Abelian sandpile model on graphs {{that may be}} decomposed {{in a variety of}} ways. These results allow us to classify, for certain families of graphs, <b>recurrent</b> <b>states</b> in terms of the <b>recurrent</b> <b>states</b> of its components. We use these decompositions to give recurrence relations for the generating functions of the level statistic on the recurrent configurations. We also interpret our results with respect to the sandpile group...|$|R
50|$|Since a {{stochastic}} process {{defined by a}} Markov chain that is irreducible, aperiodicand <b>positive</b> <b>recurrent</b> has a stationary distribution, the entropy rate is independent of the initial distribution.|$|R
40|$|This {{paper is}} {{concerned}} with the class of d-dimensional diﬀusion processes known as semi-martingales reﬂecting Brownian motions (SRBMs). Such processes arise as approximations for open d-station queueing networks. The data for such a process are a drift vector θ, a non-singular d×d covariance matrix Σ, and a d×d reﬂection matrix R. A standard problem is to determine under what conditions the process is <b>positive</b> <b>recurrent.</b> Necessary and suﬃcient conditions for positive recurrence are easy to formulate for d = 2, but not for d > 2. Associated with the pair (θ,R) are ﬂuid paths, which are solutions of deterministic equations corresponding to the random equations of the SRBM. A standard result in literature states that when every ﬂuid path associated with the SRBM is attracted to the origin, the SRBM is <b>positive</b> <b>recurrent.</b> In this article the author provides a family of examples, in d = 6, for which the SRBM is <b>positive</b> <b>recurrent,</b> but possesses a divergent linear ﬂuid path. Leonardo Pasin...|$|R
40|$|The use of Gibbs {{samplers}} {{driven by}} improper posteriors {{has been a}} controversial issue in the statistics literature {{over the last few}} years. Recently, Gelfand and Sahu (1999), Liu and Wu (1999), Meng and van Dyk (1999), and van Dyk and Meng (2001) have given examples demonstrating {{that it is possible to}} make valid statistical inferences through such Gibbs samplers. Furthermore, these authors provide theoretical and empirical evidence that there are actually computational advantages to using these non-positive recurrent Markov chains rather than more standard <b>positive</b> <b>recurrent</b> chains. These results provide motivation for a general study of the behavior of the Gibbs Markov chain when it is not <b>positive</b> <b>recurrent.</b> This paper concerns stability relationships among the two-variable Gibbs sampler and its subchains. We show that these three Markov chains always share the same stability; that is, they are either all <b>positive</b> <b>recurrent,</b> all null recurrent, or all transient. In additi [...] ...|$|R
2500|$|... where [...] is the {{normalizing}} constant. Further, if the <b>positive</b> <b>recurrent</b> {{chain is}} both irreducible and aperiodic, {{it is said}} to have a limiting distribution; for any i and j, ...|$|R
5000|$|An {{irreducible}} chain has {{a stationary}} distribution if {{and only if}} all of its <b>states</b> are <b>positive</b> <b>recurrent.</b> In that case, π is unique and is related to the expected return time: ...|$|R
2500|$|An {{irreducible}} chain has {{a positive}} stationary distribution (a stationary distribution such that [...] ) {{if and only if}} all of its <b>states</b> are <b>positive</b> <b>recurrent.</b> In that case, π is unique and is related to the expected return time: ...|$|R
25|$|<b>Recurrent</b> <b>states</b> are {{guaranteed}} (with probability 1) {{to have a}} finite hitting time.|$|R
40|$|We study {{positive}} recurrence and transience of a two-station {{network in}} which {{the behavior of the}} server in each station is governed by a Markov chain with a finite number of server states; this service process can represent various service disciplines such as a non-preemptive priority service and K-limited service. Assuming that exogenous customers arrive according to independent Markovian arrival processes (MAPs), we represent the behavior of the whole network as a continuous-time Markov chain and, by the uniformization technique, obtain the corresponding discrete-time Markov chain, which is <b>positive</b> <b>recurrent</b> (transient) if and only if the original continuous-time Markov chain is <b>positive</b> <b>recurrent</b> (resp. transient). This discrete-time Markov chain is a four-dimensional skip-free Markov modulated reflecting random walk (MMRRW) and, applying several existing results of MMRRWs to the Markov chain, we obtain conditions on which the Markov chain is <b>positive</b> <b>recurrent</b> and on which it is transient. The conditions are represented in terms of the difference of the input rate and output rate of each queue in each induced Markov chain. In order to demonstrate how our results work in two-station networks, we give several examples. Comment: 35 pages, 2 figure...|$|R
40|$|For a {{strongly}} subcritical branching process (Zn) n[greater-or-equal, slanted] 0 in random environment the non-extinction probability at generation n decays {{at the same}} exponential rate as the expected generation size and given non-extinction at n the conditional distribution of Zn has a weak limit. Here we prove conditional functional limit theorems for the generation size process (Zk) 0 [less-than-or-equals, slant]k[less-than-or-equals, slant]n {{as well as for}} the random environment. We show that given the population survives up to generation n the environmental sequence still evolves in an i. i. d. fashion and that the conditioned generation size process converges in distribution to a <b>positive</b> <b>recurrent</b> Markov chain. Branching process Random environment Random walk Change of measure <b>Positive</b> <b>recurrent</b> Markov chain Functional limit theorem...|$|R
40|$|International audienceWe {{introduce}} k-step exclusion {{processes as}} generalizations {{of the simple}} exclusion process. We state their main equilibrium properties when the underlying stochastic matrix corresponds to a random walk or is <b>positive</b> <b>recurrent</b> and reversible. Finally, we prove laws of large numbers for tagged and second-class particles...|$|R
5000|$|... where Bi and Ai are k × k matrices. (Note that unmarked matrix entries {{represent}} zeroes.) Such {{a matrix}} describes the embedded Markov chain in an M/G/1 queue. If P is irreducible and <b>positive</b> <b>recurrent</b> then the stationary distribution {{is given by}} {{the solution to the}} equations ...|$|R
40|$|This paper {{studies the}} {{functional}} {{estimation of the}} drift and diffusion functions for recurrent scalar diffusion processes from equally spaced observations using the local polynomial kernel approach. Almost sure convergence and a CLT for the estimators are established as the sampling frequency and the time span go to infinity. The asymptotic distributions follow a mixture of normal laws. This theory covers both <b>positive</b> and null <b>recurrent</b> diffusions. 	 Almost sure convergence rates are sometimes path dependent but expected rates can always be characterized in terms of regularly varying functions. 	 The general theory is specialized for <b>positive</b> <b>recurrent</b> diffusion processes, and it is shown {{in this case that}} the asymptotic distributions are normal. 	 We also obtain the limit theory for kernel density estimators when the process is <b>positive</b> <b>recurrent,</b> namely, requiring only that the invariant probability measure exists. Nonetheless, it is also shown that such an estimator paradoxically vanishes almost surely when the invariant measure is fat tailed and nonintegrable, that is, in the null recurrent case. ...|$|R
40|$|AbstractAn {{averaging}} {{principle is}} proved for diffusion processes of type (Xε(t),Yε(t)) with null-recurrent fast component Xε(t). In contrast with <b>positive</b> <b>recurrent</b> setting, the slow component Yε(t) alone cannot {{be approximated by}} diffusion processes. However, one can approximate the pair (Xε(t),Yε(t)) by a Markov diffusion with coefficients averaged in some sense...|$|R
5000|$|Consider an {{irreducible}} discrete-time Markov chain on a countable {{state space}} S having a transition probability matrix P with elements pij for pairs i, j in S. Foster's theorem {{states that the}} Markov chain is <b>positive</b> <b>recurrent</b> {{if and only if}} there exists a Lyapunov function , such that [...] and ...|$|R
25|$|A state i {{is said to}} be ergodic if it is {{aperiodic}} and <b>positive</b> <b>recurrent.</b> In other words, a state i is ergodic if it is recurrent, has {{a period}} of 1, and has finite mean recurrence time. If all states in an irreducible Markov chain are ergodic, then the chain {{is said to be}} ergodic.|$|R
40|$|We {{define a}} random {{walk on the}} set of {{primitive}} points of Z^d. We prove that for walks generated by measures satisfying mild conditions these walks are recurrent in a strong sense. That is, we show that the associated Markov chains are <b>positive</b> <b>recurrent</b> and there exists a unique stationary measure for the random walk. Comment: 11 page...|$|R
40|$|In this paper, we {{establish}} a new limit theorem for partial sums of random variables. As corollaries, we generalize the extended Borel-Cantelli lemma, and obtain some strong laws of large numbers for Markov chains {{as well as a}} generalized strong ergodic theorem for irreducible and <b>positive</b> <b>recurrent</b> Markov chains. Extended Borel-Cantelli lemma Strong laws of large numbers...|$|R
40|$|We give a few {{examples}} of substitutions on infinite alphabets, and the beginning of a general theory of the associated dynamical systems. In particular, the drunken man substitution can be associated to an ergodic infinite measure preserving system, while substitutions of constant length with a <b>positive</b> <b>recurrent</b> infinite matrix correspond to ergodic finite measure preserving systems. ...|$|R
5000|$|In {{probability}} theory, Foster's theorem, {{named after}} Gordon Foster, {{is used to}} draw conclusions about the positive recurrence of Markov chains with countable state spaces. It uses the fact that <b>positive</b> <b>recurrent</b> Markov chains exhibit a notion of [...] "Lyapunov stability" [...] in terms of returning to any state while starting from it within a finite time interval.|$|R
40|$|Let (M_n,S_n) _n> 0 be a Markov {{random walk}} with <b>positive</b> <b>recurrent</b> driving chain (M_n) _n> 0 having {{countable}} state space S and stationary distribution π. It {{is shown in}} this note that, if the dual sequence (^#M_n,^#S_n) _n> 0 is positive divergent, i. e. ^#S_n→∞ a. s., then the strictly ascending ladder epochs σ_n^> of (M_n,S_n) _n> 0 are a. s. finite and the ladder chain (M_σ_n^>) _n> 0 is <b>positive</b> <b>recurrent</b> on some S^>⊂S. We also provide simple expressions for its stationary distribution π^>, {{an extension of the}} result to the case when (M_n) _n> 0 is null recurrent, and a counterexample that demonstrates that ^#S_n→∞ a. s. does not necessarily entail S_n→∞ a. s., but rather _n→∞S_n=∞ a. s. only. Our arguments are based on Palm duality theory, coupling and the Wiener-Hopf factorization for Markov random walks with discrete driving chain...|$|R
40|$|We {{introduce}} k-step exclusion {{processes as}} generalizations {{of the simple}} exclu-sion process. We state their main equilibrium properties when the underlying stochastic matrix corresponds to a random walk or is <b>positive</b> <b>recurrent</b> and reversible. Finally, we prove laws of large numbers for tagged and second-class particles. KEY WORDS: Interacting particle systems; invariant measures; tagged particle; second-class particle; exclusion process; k-step exclusion process...|$|R
40|$|International audienceLet $X$ be a one {{dimensional}} <b>positive</b> <b>recurrent</b> diffusion observed in continuous time. Without assuming strict stationarity of the process, we propose a nonparametric estimator of the drift function obtained by penalization. Our estimators {{belong to a}} finite-dimensional function space whose dimension is chosen according to the data. Our risk-bounds for the estimator are non-asymptotic and hold in a non-stationary regime...|$|R
40|$|An {{averaging}} {{principle is}} proved for diffusion processes of type (X[var epsilon](t),Y[var epsilon](t)) with null-recurrent fast component X[var epsilon](t). In contrast with <b>positive</b> <b>recurrent</b> setting, the slow component Y[var epsilon](t) alone cannot {{be approximated by}} diffusion processes. However, one can approximate the pair (X[var epsilon](t),Y[var epsilon](t)) by a Markov diffusion with coefficients averaged in some sense. Averaging principle Null-recurrent diffusion Arcsine law Homogenization...|$|R
40|$|This paper studies {{aspects of}} the Siegmund dual of the Markov {{branching}} process. The principal results are optimal convergence rates of its transition function and limit theorems in the case {{that it is not}} <b>positive</b> <b>recurrent.</b> Additional discussion is given about specifications of the Markov branching process and its dual. The dualising Markov branching processes need not be regular or even conservative...|$|R
40|$|It is {{now known}} that the usual traffic {{condition}} (the nominal load being less than one at each station) is not sufficient for stability for a multiclass open queueing network. Although {{there has been some}} progress in establishing the stability conditions for a multiclass network, there is no unified approach to this problem. In this paper, we prove that a queueing network is <b>positive</b> Harris <b>recurrent</b> if the corresponding fluid limit model eventually reaches zero and stays there regardless of the initial system configuration. As an application of the result, we prove that single class networks, multiclass feedforward networks and first-buffer-first-served preemptive resume discipline in a re-entrant line are <b>positive</b> Harris <b>recurrent</b> under the usual traffic condition. AMS 1991 subject classification: Primary 60 K 25, 90 B 22; Secondary 60 K 20, 90 B 35. Key words and phrases: multiclass queueing networks, Harris <b>positive</b> <b>recurrent,</b> stability, fluid approximation Running title: Stability of mu [...] ...|$|R
40|$|We {{consider}} a Markov chain on $R^+$ with asymptotically zero drift and finite second moments of jumps which is <b>positive</b> <b>recurrent.</b> A power-like asymptotic behaviour of the invariant tail distribution is proven; such a heavy-tailed invariant measure happens {{even if the}} jumps of the chain are bounded. Our analysis is based on test functions technique and on construction of a harmonic function. Comment: 27 page...|$|R
