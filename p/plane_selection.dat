30|41|Public
2500|$|Although 1up.com {{likewise}} {{approved of}} the game's action-oriented gameplay, the site criticized the [...] "lame 'favors for everyone' mechanic" [...] surrounding the missions, noting that the player is always forced to perform [...] "chores" [...] for other characters in the game. [...] GameSpy noted that the game had [...] "some repetitiveness." [...] IGN dis{{approved of the}} game's undescriptive <b>plane</b> <b>selection</b> screen, which does not inform the player of a plane's weapons loadout. [...] IGN also disparaged the game's upgrade system, which was described as [...] "dry and unimaginative" [...] {{in comparison to the}} plane customization feature in the Crimson Skies PC game.|$|E
40|$|Multiple {{sclerosis}} {{has been}} known to cause atrophy and deformation in the corpus callosum. In longitudinal studies, these changes have been typically quantified by using medical image analysis techniques for measuring and analyzing {{the size and shape of}} a corpus callosum cross-section embedded in a specially selected measurement plane. Our contributions are three fold: (i) We introduce and quantify the effects of the error in measurement <b>plane</b> <b>selection</b> and image interpolation on the cross-sectional area of the corpus callosum; (ii) We present a novel and clinically meaningful criterion for the measurement <b>plane</b> <b>selection</b> which addresses significant drawbacks with previous methods of <b>plane</b> <b>selection.</b> We present a nested optimization based framework for accurate identification and extraction of this plane with simultaneous segmentation of its corpus callosum cross-section; (iii) We present a medial shape representation based technique for longitudinal, regional and deformation-specific shape analysis of the corpus callosum...|$|E
3000|$|... w 7.5), the {{differences}} in the fault <b>plane</b> <b>selection</b> and in the scaling laws used result in relatively small differences in the initial tsunami height condition, indicating that the tsunami source is approximated as a point source and result in small differences in the forecasts (Figs.  9 and 10 b). For the larger M [...]...|$|E
5000|$|A 1-fusil {{is a line}} segment. A 2-fusil is a rhombus. Its <b>plane</b> cross <b>selections</b> in all {{pairs of}} axes are rhombi.|$|R
40|$|AbstractNew {{orthonormal}} {{bases of}} improved time frequency atoms are constructed. These atoms {{are similar to}} R. Baraniuk's “chirplets. ” These new bases are used to unfold frequency modulated signals in the time frequency <b>plane.</b> The <b>selection</b> of the “best basis” amounts to finding an optimal covering with Heisenberg boxes with arbitrary eccentricities and orientations. This analysis is as sharp as the one provided by the Wigner transform...|$|R
40|$|A {{modified}} version of the Block Truncation Coding (BTC), which is a non-information preserving image compression technique, is studied. The first modification is the introduction of variable block sizes to the standard BTC technique. The second modification is the adaptive omission of bit <b>planes.</b> Threshold <b>selections</b> for this modified BTC technique are analyzed {{in the context of the}} human visual system. Modified BTC techniques are compared against the standard technique from the point of view of visual image quality and compresion efficiency...|$|R
40|$|International audienceDeformable image {{registration}} {{is a fundamental}} problem in computer vision and medical image computing. In this paper we investigate the use of graphical models {{in the context of}} a particular type of {{image registration}} problem, known as slice-to-volume registration. We introduce a scal-able, modular and flexible formulation that can accommodate low-rank and high order terms, that simultaneously selects the plane and estimates the in-plane deformation through a single shot optimization approach. The proposed framework is instantiated into different variants seeking either a compromise between computational efficiency (soft <b>plane</b> <b>selection</b> constraints and approximate definition of the data similarity terms through pair-wise components) or exact definition of the data terms and the constraints on the <b>plane</b> <b>selection.</b> Simulated and real-data in the context of ultrasound and magnetic resonance registration (where both framework instantiations as well as different optimization strategies are considered) demonstrate the potentials of our method...|$|E
40|$|Cutting plane {{plays an}} {{important}} role in the theory and computation of integer programming. Nowadays, most state-of-the-art integer programming solvers tend to bias their cutting <b>plane</b> <b>selection</b> towards sparse ones, which emphasizes the significance of sparse cutting planes. In this thesis, we conduct a comprehensive study of sparse cutting planes and prove several theoretical results. We also develop a new approximation algorithm for sparse packing integer programs. Ph. D...|$|E
30|$|Tsunami {{forecast}} systems {{similar to}} the SWIFT TSUNAMI system have been also developed by PTWC and CPPT. The PTWC system has shown forecast results with successively updated CMT solutions (Wang et al. 2012). The CPPT study has shown forecast uncertainties with respect to CMTs derived from different research institutions (Jamelot and Reymond 2015). We show the forecast uncertainties due to the fault <b>plane</b> <b>selection,</b> the scaling laws used, and other possible factors, especially for greater earthquakes and tsunamis.|$|E
40|$|A {{thorough}} {{literature review}} on current research for trisomy 21 detection using ultrasound {{will be carried}} out for existing modality’s drawback investigation. Due to its critical restriction, computing on ultrasound markers in term of its recognition, segmentation and measurement are essentially required. 3 D reconstruction of nuchal translucency becomes a breakthrough to select the appropriate scanning plane of ultrasound markers. It shall resolve the problematic issue on scanning <b>plane</b> <b>selections</b> which depends on operator assumption and experience. Data sources from hospital patient scanning should obtain the approval from Medicine ethical committee. Consent and simple agreement document shall be prepared. The main ultrasound images sources will be taken from Health Center Universiti Teknologi Malaysia, Hospital Universiti Sains Malaysia, and Hospital Universiti Kebangsaan Malaysia. External collaboration parties are Hospital Sultanah Aminah and Technische Universitat Ilmenau, Germany. Other than fetal data, maternal health data will also be recorded. This data is important to obtain the knowledge of correlation between fetal and mother data. It is recommended that pregnant women should be older than 30 years old. This chapter will describe the book in terms of its background, history and the related works in greater detail. The focus will be on the Trisomy 21 background, history, existing detection techniques, and ultrasound application using 2 D and 3 D image formation on fetal abnormalities detection. Previous related research works are discussed and each of their limitation is remarked...|$|R
40|$|A three {{dimensional}} body-fitted {{coordinate system}} developed {{for use in}} the calculation of inviscid flows over ablated, asymmetric reentry vehicle nosetips is described. Because of the potential geometric asymmetries, no standard coordinate system (e. g., spherical, axisymmetric reference surface-normal) is capable of being closely aligned with the nosetip surface. To generate a 3 -D, body-fitted coordinate system an analytic mapping procedure is applied that is conformal within each meridional plane of the nosetip; these transformations are then coupled circumferentially to yield a three dimensional coordinate system. The mappings used are defined in terms of hinge points, which are points selected to approximate the body contours in each meridional <b>plane.</b> The <b>selection</b> of appropriate hinge points was automated to facilitate the use of the resulting nosetip flow field code...|$|R
40|$|Abstract—This paper {{presents}} a new diagnosis method of induction motor faults based on time–frequency classification {{of the current}} waveforms. This method {{is based on a}} representation space, a selection criterion, and a decision criterion. In order to define the representation space, an optimized time–frequency representation (TFR) is designed from the time–frequency ambiguity <b>plane.</b> The <b>selection</b> criterion is based on Fisher’s discriminant ratio, which allows one to maximize the separability between classes representing different faults. A distinct TFR is designed for each class. The following two classifiers were used for decision criteria: the Mahalanobis distance and the hidden Markov model. The flexibility of this method allows an accurate classification independent from the level of load. This method is validated on a 5. 5 -kW induction motor test bench. Index Terms—Diagnosis, hidden Markov model (HMM), induction motor, time–frequency classification. I...|$|R
40|$|Various {{techniques}} for object selection in virtual environments {{have been proposed}} over the years. Among them, the virtual pointer or ray-casting {{is one of the}} most popular method because it is easy and intuitive to use and allows the user to select objects that are far away. Variants of the virtual pointer metaphor include the Aperture [5], Flashlight [3], and Image plane method [1] as categorized as such by [10]. In a monoscopic environment, these methods are essentially 2 D interaction techniques, as the selection is made effectively on the image plane. Such a 2 D based selection (or more generally, interaction) method has an added advantage in that it can find many good uses in 3 D environments ranging from a simple 2 D oriented subtask to a situation where a whole 2 D application is embedded in the 3 D environment. In this paper, we experimentally compare the performance of four different virtual pointer implementations, namely, the direct image <b>plane</b> <b>selection,</b> head-directed pointer, hand-directed pointer and head-hand-directed pointer. The experimental results revealed that the direct image <b>plane</b> <b>selection</b> produced the best performance among the four in terms of both task completion time and the pixel-level pointing error...|$|E
40|$|This {{paper is}} an attempt to {{formulate}} an estimation method which can efficiently determine the critical plane according to the criteria under consideration. It is required to maintain greater accuracy than the incremental angle methods used conventionally in critical plane searching algorithms. The multi-criteria-based critical <b>plane</b> <b>selection</b> method is evaluated; the considered criteria include a fatigue parameter and variance of shear stress, both maximized to find the most damaging plane. The results show that the proposed model reduces the number of iterations by 90...|$|E
40|$|International audienceThe atomic and {{electronic}} {{structures of the}} (100) and (001) surfaces of the Al 5 Co 2 complex metallic alloy are studied by ab initio calculations. The relative stability of the possible surface planes built from bulk truncation is calculated {{and the influence of}} the atomic surface density, the interlayer spacing and the surface chemical composition on the <b>plane</b> <b>selection</b> is discussed. In addition, we show that the simulated images of scanning tunneling microscopy for each possible termination present a specific signature that appears to be sufficient to experimentally identify the surface plane...|$|E
40|$|Abstract. Content {{adaptive}} true motion estimator for H. 264 video coding is a fast block-based matching esti-mator with implemented multi-stage {{approach to}} estimate motion fields between two image frames. It considers {{the theory of}} 3 D scene objects projection into 2 D image <b>plane</b> for <b>selection</b> of motion vector candidates from the higher stages. The stages of the algorithm and its hierarchy are defined upon motion estimation reliability measurement (image blocks including two different directions of spatial gradient, blocks with one dominant spatial gradient and blocks including minimal spatial gradient). Parameters of the image classification into stages are set adaptively upon image structure. Due to search strategy are the estimated motion fields more corresponding to a true motion in an image sequence {{as in the case}} of conventional motion estimation algorithms that use fixed sets of motion vector candidates from tight neighborhood...|$|R
40|$|An {{algorithm}} is presented for the recognition and localization of thre-dimensional polyhedral objects {{based on an}} optical proximity sensor system capable of measuring the depth and orientation of a local area of an object surface. Emphasis {{is given to the}} determination of an optimal sensor trajectory or an optimal probing, for efficient discrimination among all the possible interpretations. The determination of an optimal sensor trajectory for the next probing consists of the selection of optimal beam orientations based on the surface normal vector distribution of the multiple interpretation image (MII) and the selection of an optimal probing plane by projecting the MII onto the projection plane perpendicular to a selected beam orientation and deriving the optimal path on the projection <b>plane.</b> The <b>selection</b> of optimal beam orientation and probing plane is based on the measure of discrimination power of a cluster of surfaces of an MII. Simulation results are shown...|$|R
40|$|During the Mars Exploration Rovers (MER) landings, the Descent Image Motion Estimation System (DIMES) {{was used}} for {{horizontal}} velocity estimation. The DIMES algorithm combines measurements from a descent camera, a radar altimeter and an inertial measurement unit. To deal with large changes in scale and orientation between descent images, the algorithm uses altitude and attitude measurements to rectify image data to level ground <b>plane.</b> Feature <b>selection</b> and tracking is employed in the rectified data to compute the horizontal motion between images. Differences of motion estimates are then compared to inertial measurements to verify correct feature tracking. DIMES combines sensor data from multiple sources in a novel way to create a low-cost, robust and computationally efficient velocity estimation solution, and DIMES is the first use of computer vision to control a spacecraft during planetary landing. In this paper, the detailed implementation of the DIMES algorithm and {{the results from the}} two landings on Mars are presented...|$|R
40|$|Abstract. We {{present a}} new {{framework}} for correcting multiperspective distortions using collineations. A collineation describes the transformation between {{the images of}} a camera due to changes in sampling and image <b>plane</b> <b>selection.</b> We show that image distortions in many previous models of cameras can be effectively reduced via proper collineations. To correct distortions in a specific multiperspective camera, we develop an interactive system that allows users to select feature rays from the camera and position them at the desirable pixels. Our system then computes the optimal collineation to match the projections of these rays with the corresponding pixels. Experiments demonstrate that our system robustly corrects complex distortions without acquiring the scene geometry, and the resulting images appear nearly undistorted. ...|$|E
40|$|International audiencePurpose: This paper {{introduces}} a novel decomposed graphical model {{to deal with}} slice-to-volume registration {{in the context of}} medical images and image guided surgeries. Methods: We present a new non-rigid slice-to-volume registration method whose main contribution is the ability to decouple the <b>plane</b> <b>selection</b> and the in-plane deformation parts of the transformation -through two distinct graphs- towards reducing the complexity of the model while being able to obtain simultaneously the solution for both of them. To this end, the <b>plane</b> <b>selection</b> process is expressed as a local graph-labeling problem endowed with planarity satisfaction constraints, which is then directly linked with the deformable part through the data registration likelihoods. The resulting model is modular with respect to the image metric, can cope with arbitrary in-plane regularization terms and inherits excellent properties in terms of computational efficiency. Results: The proof of concept for the proposed formulation is done using cardiac MR sequences of a beating heart (an artificially generated 2 D temporal sequence is extracted using real data with known ground truth) as well as multimodal brain images involving ultrasound and computed tomography images. We achieve state of the art results while decreasing the computational time when we compare with another method based on similar techniques. Conclusions: We confirm that graphical models and discrete optimization techniques are suitable to solve non-rigid slice-to-volume registration problems. Moreover, we show that decoupling the graphical model and labeling it using two lower dimensional label spaces, we can achieve state of the art results while substantially reducing the complexity of our method and moving the approach close to real clinical applications once considered in the context of modern parallel architectures...|$|E
3000|$|... w 7.5 – 8.6). The system {{considers}} forecast uncertainties due to {{the fault}} <b>plane</b> <b>selection</b> and the scaling law used and shows four possible scenarios for each tsunamigenic event. The forecast results based on the four scenarios were evaluated by the DART and tide gauge observations. We {{have shown that the}} forecasts with associated uncertainties range from half to double the total amplitude of the leading wave of the DART observations and range mostly within the same order of magnitude as the maximum heights of the tide gauge observations. It is also found that the forecast uncertainties become larger for greater earthquakes because the tsunami source is no longer approximated as a point source for greater earthquakes (e.g., M [...]...|$|E
40|$|This paper {{proposes a}} method to {{autonomously}} select stable visual landmarks from observed features by stereo vision and a given 2 D obstacle map. The robot selects as stable landmarks vertical line segments which are distinct and on a vertical plane, because {{they are expected to}} be observed reliably from various viewpoints. Due to the vision and motion error of the robot, the observed feature positions include uncertainty. This uncertainty can be reduced by matching the detected vertical plane which includes the features to a known plane in the map. The position of a selected feature is modeled by a probabilistic distribution on the known <b>plane.</b> The <b>selection</b> and modeling process is performed on-line to adapt to an actual lighting and background condition which varies depending on viewpoints. When the robot moves, it uses several, less uncertain landmarks to estimate its motion. Experimental results in real scenes show the validity of the proposed method. 1 Introdu [...] ...|$|R
40|$|Abstract — We {{discuss the}} {{criteria}} affecting {{the choice of}} optical configuration for the MMA antennas. Receiver bands will be separated in the focal <b>plane</b> so the <b>selection</b> of Cassegrain parameters {{is influenced by the}} acceptable size and separation of the feeds and the associated aberrations. The secondary mirror size is determined by blockage restrictions and by nutation requirements. Specifications for the nutation of the secondary need to be carefully considered since the dynamics and aberrations are very strongly influenced by beam-throw and nutation frequency requirements. A set of design parameters is derived which is a reasonable compromise among the various constraints. I...|$|R
40|$|We propose an {{algorithm}} for automatic photo {{selection for}} media and entertainment applications like photobook and slide-show. The technique comprises three main steps: photo quality estimation and elimination of poor-quality photos, adaptive quantization of survived photos in time-camera <b>plane,</b> and <b>selection</b> {{of the most}} appealing photos from each quantized group. For detection of low-quality photos complex classifier comprising of two AdaBoost classifiers committees is created. Photos with exposure defects, such as over- and underexposed, backlit, blurred photos as well as images affected by strong JPEG artifacts are detected confidently. For quantization of photos the method similar to median-cut color quantization is proposed. The appealing photos are selected basing on novel scheme via comparison of visual salience among several images as well as face detection. Our method of identification of the most salient photo among others is based on Itti-Koch-Niebur algorithm of saliency map building. Obtained results of selection as well as time performance issues are discussed. The majority of observers were pleased {{with the results of}} the algorithm...|$|R
40|$|International audienceIn {{this paper}} we propose a novel method based on {{discrete}} optimization of high order graphs, to perform deformable slice-to-volume registration of 2 D images and 3 D volumes. To this end, a 2 D grid superimposed to the image is considered with control points deforming in 3 D and their deformations corresponding to the label space. Geometrical consistency (unique <b>plane</b> <b>selection)</b> and deformation smoothness (in-plane deformations) as well as image similarity (visual matching) are encoded in different third order cliques. The proposed formulation is optimized through its mapping to a factor graph using conventional graph optimization methods. A dataset composed of 2 D slices and 3 D MRI volumes of the heart was used to evaluate its accuracy leading to very promising results...|$|E
40|$|Essential for {{the success}} of branch-and-cut {{algorithms}} for solving combinatorial optimization problems are the availability of reasonable tight relaxations and effective routines for solving the associated separation problems. In this paper we introduce the concept of small instance relaxations which can be particularly useful for problems with symmetric structure. Small instance relaxations base on the facets of polytopes associated with small instances of the combinatorial optimization problem to be solved and can be generated automatically by facet enumeration. For a certain class of symmetric problems, we describe a general approach to the separation problem. Algorithmic aspects of using small instance relaxations effectively (parallel separation, facet selection, cutting <b>plane</b> <b>selection)</b> are discussed in detail. Extensive computational results are presented for the linear ordering problem and a certain betweenness problem. 1 Introduction During the last years, branch-and-cut algo [...] ...|$|E
40|$|Summarization of {{the video}} content is {{necessary}} {{in order to reduce the}} large amount of data involved in video retrieval. In a frame-based digital video retrieval framework, this is achieved by representing the content of a video sequence using "key frames". Similarly, in an object-based framework, such as the one suggested by the MPEG- 4 standard, video object planes can be used for summarization of video object content. In this paper, we propose a method for key video object <b>plane</b> <b>selection</b> using the compressed domain shape information in MPEG- 4. Two popular shape distance measures, the Hamming and Hausdorff distance measures, are employed to measure the similarities between the approximated shapes {{of the video}} objects. The corresponding algorithms, with different implementation complexity and computation tradeoffs, select key video object planes that represent efficiently the salient content of the video objects...|$|E
40|$|Nos remerciements à IEEE pour l'autorisation de mise à {{disposition}} du papier complet. © IEEE Copyright Notice : Personal use of {{this material}} is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must {{be obtained from the}} IEEE. International audienceThis paper presents a new diagnosis method of induction motor faults based on time-frequency classification of the current waveforms. This method is based on a representation space, a selection criterion, and a decision criterion. In order to define the representation space, an optimized time-frequency representation (TFR) is designed from the time-frequency ambiguity <b>plane.</b> The <b>selection</b> criterion is based on Fisher's discriminant ratio, which allows one to maximize the separability between classes representing different faults. A distinct TFR is designed for each class. The following two classifiers were used for decision criteria: the Mahalanobis distance and the hidden Markov model. The flexibility of this method allows an accurate classification independent from the level of load. This method is validated on a 5. 5 -kW induction motor test bench...|$|R
40|$|Two-dimensional microshutter arrays {{are being}} {{developed}} at NASA Goddard Space Flight Center (GSFC) for the Next Generation Space Telescope (NGST) {{for use in the}} near-infrared region. Functioning as focal <b>plane</b> object <b>selection</b> devices, the microshutter arrays are 2 -D programmable masks with high efficiency and high contrast. The NGST environment requires cryogenic operation at 45 K. Arrays are close-packed silicon nitride membranes with a unit cell size of 100 x 100 micrometer. Individual shutters are patterned with a torsion flexure permitting shutters to open 90 degrees with minimized mechanical stress concentration. The mechanical shutter arrays are fabricated with MEMS technologies. The processing includes a RIE front-etch to form shutters out of the nitride membrane, an anisotropic back-etch for wafer thinning, and a deep RIE (DRIE) back-etch down to the nitride shutter membrane to form frames and to relieve the shutters from the silicon substrate. A layer of magnetic material is deposited onto each shutter. Onto the side-wall of the support structure a metal layer is deposited that acts as a vertical hold electrode. Shutters are rotated into the support structure by means of an external magnet that is swept across the shutter array for opening. Addressing is performed through a scheme using row and column address lines on each chip and external addressing electronics...|$|R
40|$|An adaptive-antenna array {{provides}} an e~ective means of suppressing interj+erence signals. However, in medium- to long-range HF communications, sky-wave propagation often produces multipath that can hamper effective interference suppression. The differential time delays and elevation separations between paths vary widely {{depending on which}} reflecting ionospheric layers are active during the transmission. In mid-range sky-wave propagation (about 1000 km) where single-hop transmissions are dominant, the time-delay differences between paths increase with the elevation-angle differences. When adaptive weights are calculated based on an embedded known reference in the waveform, {{it is possible to}} resolve the multiple paths in elevation, based on the di~erential time delays. This can be achieved by forming composite antenna-pattern nulls pointing towards unwanted-signal paths in the vertical <b>plane.</b> The <b>selection</b> of a desirable signal path is made based on its specific time delay. Nulls are also formed towards all the paths of the interference signals. When the paths are close in elevation, a three-dimensional antenna-array arrangement can be used to enhance the vertical resolution. This paper characterizes multipath propagation based on a mid-range sky- wave scenario and investigates, by computer simulation, how antenna-array configuration aflects the suppression of unwanted multipath components of the desired signal in the presence of interference...|$|R
40|$|Staphylococcus aureus is an {{aggressive}} pathogen {{and a model}} organism to study cell division in sequential orthogonal planes in spherical bacteria. However, {{the small size of}} staphylococcal cells has impaired analysis of changes in morphology during the cell cycle. Here we use super-resolution microscopy and determine that S. aureus cells are not spherical throughout the cell cycle, but elongate during specific time windows, through peptidoglycan synthesis and remodelling. Both peptidoglycan hydrolysis and turgor pressure are required during division for reshaping the flat division septum into a curved surface. In this process, the septum generates less than one hemisphere of each daughter cell, a trait we show is common to other cocci. Therefore, cell surface scars of previous divisions do not divide the cells in quadrants, generating asymmetry in the daughter cells. Our results introduce a need to reassess the models for division <b>plane</b> <b>selection</b> in cocci...|$|E
40|$|Object-based video representation, {{such as the}} one {{suggested}} by the MPEG- 4 standard, offers a framework that is better suited for object-based video indexing and retrieval. In such a framework, the concept of a "key frame" is replaced by that of a "key video object plane". In this paper, we propose a method for key video object <b>plane</b> <b>selection</b> using the shape information in the MPEG- 4 compressed domain. The shape of the video object is approximated using information on the shape coding modes in the MPEG- 4 bitstream. Two popular shape distance measures, the Hamming and Hausdorff distance measures, are modified to measure the similarities between the approximated shapes of the video objects. Although they feature different computational and implementation complexity tradeoffs, the corresponding algorithms achieve essentially the same performance levels in selecting key video object planes that represent efficiently the salient content of the video objects. Key words: Key video [...] ...|$|E
40|$|Introduction The {{diagnosis}} of ventriculomegaly depends on accurate measurements of ventricular size and volume {{both in the}} fetus {{as well as in}} the neonate. In the antenatal period the ventricular size is determined by ultrasound measuring the transverse width of the lateral ventricles at the level of the atria. Measurements of 10 mm or less are considered normal (1). Evaluation of the ventricular size is important in the detection of ventriculomegaly both in the fetus and the neonate. In the neonatal period US and other imaging modalities are used to assess ventricular size. The frontal and occipital horn ratio has been used in the evaluation of hydrocephalus (2), but errors can be induced by image <b>plane</b> <b>selection.</b> In our pilot study we used 3 D magnetic resonance imaging of fetuses in utero and neonates of different gestational age to determine absolute volumes of the ventricular system during early development. These images were post processed with advanced image analysis to...|$|E
40|$|With the {{construction}} of the neutron detection wall at the external target position on Heavy Ion Research Facility in Lanzhou-Cooling Storage Ring (HIRFL-CSR), {{it will be possible to}} detect high energy neutron. A BUU model is applied to simulate the flow in both symmetric (Ni+Ni, Pb+Pb) and asymmetric(Pb+Ni) systems. It is shown that at above several hundreds MeV/u, the flow signals are very obvious and depend clearly on the centrality of the collisions. Based on the products in the forward angle less than 20 degrees, the simulation also reveals that the determination of the reaction <b>plane</b> and the <b>selection</b> of the impact parameter, both of which are essential in the flow measurement, are well implemented. The double event and its influence on the determination of the neutron flow are also simulated...|$|R
40|$|Instrumental {{selection}} {{effects can}} act upon {{the estimates of}} the peak energy Ep, the fluence F and the peak flux P of GRBs. If this were the case, then the correlations involving the corresponding rest frame quantities (i. e. Ep, Eiso and the peak luminosity Liso) would be questioned. We estimated, {{as a function of}} Ep, the minimum peak flux necessary to trigger a GRB and the minimum fluence a burst must have to determine the value of Ep by considering different instruments (BATSE, Swift, BeppoSAX). We find that the latter dominates over the former. We then study the Ep-fluence (and flux) correlation in the observer plane. GRBs with redshift show well defined Ep-F and Ep-P correlations: in this <b>planes</b> the <b>selection</b> effects are present, but do not determine the found orrelations. This is not true for Swift GRBs with redshift, for which the spectral analysis threshold does affect their distribution in the observer planes. Extending the sample to GRBs without z, we still find a significant Ep-F correlation, although with a larger scatter than that defined by GRBs with redshift. We find that 6 % are outliers of the Amati correlation. The Ep-P correlation of GRBs with or without redshift is the same and no outlier is found among bursts without redshift. Comment: 6 pages, 3 figures. Contributed to the Proceedings of the Sixth Huntsville GRB Symposiu...|$|R
40|$|Abstract. Instrumental {{selection}} {{effects can}} act upon {{the estimates of}} the peak energy Eobs peak, the fluence F and the peak flux P of GRBs. If this were the case, then the correlations involving the corresponding rest frame quantities (i. e. Epeak, Eiso and the peak luminosity Liso) would be questioned. We estimated, {{as a function of}} Eobs peak, the minimum peak flux necessary to trigger a GRB and the minimum fluence a burst must have to determine the value of Eobs peak by considering different instruments (BATSE, Swift, BeppoSAX). We find that the latter dominates over the former. We then study the Eobs peak-fluence (and flux) correlation in the observer plane. GRBs with redshift show well defined Eobs peak-F and Eobs peak-P correlations: in this <b>planes</b> the <b>selection</b> effects are present, but do not determine the found correlations. This is not true for Swift GRBs with redshift, for which the spectral analysis threshold does affect their distribution in the observer planes. Extending the sample to GRBs without z, we still find a significant Eobs peak-F correlation, although with a larger scatter than that defined by GRBs with redshift. We find that 6 % are outliers of the Amati correlation. The Eobs peak-P correlation of GRBs with or without redshift is the same and no outlier is found among bursts without redshift...|$|R
