0|10000|Public
40|$|Linguistic {{ambiguity}} and linguistic variations {{are two major}} problems associated with modern information retrieval systems. Handling the vocabulary problem by using <b>a</b> <b>thesaurus</b> is <b>an</b> ideal solution. This paper deals with the overview of methodologies suggested for the development <b>of</b> <b>a</b> <b>thesaurus.</b> The work further describes the approaches adopted for designing and development <b>of</b> <b>a</b> <b>thesaurus</b> in Nanotechnology...|$|R
50|$|The purpose <b>of</b> <b>a</b> <b>thesaurus</b> is {{to offer}} the user <b>a</b> listing <b>of</b> similar or related words; these are often, but not always, synonyms.|$|R
40|$|Software environments {{support the}} process of {{constructing}} and maintaining application systems. This paper describes the idea <b>of</b> <b>a</b> <b>thesaurus</b> 1 as <b>a</b> viable foundation for software environments. <b>A</b> <b>thesaurus</b> contains information about the names and identifiers in all the software written in all the languages <b>of</b> <b>an</b> application. Information about extensional dat...|$|R
40|$|During the BMWI granted project “Print-IT”, {{the need}} <b>of</b> <b>a</b> <b>thesaurus</b> based uniform and {{consistent}} language for the German printing industry became evident. In this paper we introduce a semi-automatic construction approach for such <b>a</b> <b>thesaurus</b> and present <b>a</b> workflow which supports users to generate thesaurus typical information structures from relevant digitalized resources {{with the help}} of common IT-tools...|$|R
3000|$|The {{construction}} <b>of</b> <b>a</b> <b>thesaurus</b> {{is based}} on semi-manual annotations and the refinement of key words. However, since the official Sina Weibo beta in late 2009, people have relied on Twitter-like networks to publish increasingly more subjective comments from the media platform. Furthermore, the freedom and relaxation of the network are subtly influencing people’s originally strict and normative expressions. <b>A</b> wide range <b>of</b> online vocabulary and online styles arose. Hence, the previous method <b>of</b> extracting <b>a</b> <b>thesaurus</b> and the validity of this thesaurus can no longer adapt to the current gender identification research; [...]...|$|R
40|$|The paper {{addresses}} {{the problem of}} automatic enrichment <b>of</b> <b>a</b> <b>thesaurus</b> by classifying new words into its classes. The proposed classification method makes use of both the distributional data about a new word {{and the strength of}} the semantic relatedness of its target class to other likely candidate classes. ...|$|R
40|$|Our group {{participated in}} the Japanese and English Retrieval Subtasks of �TCIR- 6. Our goal was to {{evaluate}} the effectiveness <b>of</b> <b>a</b> <b>thesaurus</b> constructed from patents for invalidity search. To confirm the effectiveness of our thesaurus-based query expansion, we conducted experiments and found that our method can improve upon traditional document retrieval systems...|$|R
40|$|The paper {{examines}} different possibilities to {{take advantage}} of the taxonomic organization <b>of</b> <b>a</b> <b>thesaurus</b> to improve the accuracy of classifying new words into its classes. The results of the study demonstrate that taxonomic similarity between nearest neighbors, in addition to their distributional similarity to the new word, may be useful evidence on which classification decision can be based...|$|R
40|$|Abstract. This paper {{describes}} {{the work done}} in the TIPS project about the construction <b>of</b> <b>a</b> <b>thesaurus</b> base. This construction is a merge from <b>a</b> <b>thesaurus</b> manually built and one automatically extracted from large text corpora. Several manually built thesaurus have been semiformatted to be merged in a consistent common base. The automatic extraction is based on both syntax and statistics. We present inthispaper the way thesaurus are built and the results on Scienti c corpus {{in the context of}} the TIPS project. ...|$|R
40|$|The paper {{describes}} development <b>of</b> <b>a</b> <b>thesaurus</b> in the roofing domain. This work is part <b>of</b> <b>a</b> larger {{effort to}} investigate the potential <b>of</b> thesauri as <b>an</b> aid in product modeling. Extractor, a software module that extracts keyphrases from documents, was used for collecting candidate thesaurus terms from Internet sources. The principal advantage of the Internet as <b>a</b> source <b>of</b> candidate terms is that it reflects colloquial language: [...] the language that is actually used by building practitioners and that it covers the widest range of different `user views' on the domain. The advantage of using Extractor or similar software {{is that it allows}} processing huge text corpora available on the Internet and it eliminates irrelevant terms. The methodology used was found to be highly useful, although it was not sufficient by itself for constructing <b>a</b> construction <b>thesaurus,</b> as considerable human intervention was required. Though limited time resources did not allow full exploitation of Extractor's capabilities, some possibilities for customization of the software and for partial automation <b>of</b> <b>a</b> <b>thesaurus</b> construction process are suggested...|$|R
40|$|International audienceThis paper {{describes}} {{the work done}} in the TIPS project about the construction <b>of</b> <b>a</b> <b>thesaurus</b> base. This construction is a merge from <b>a</b> <b>thesaurus</b> manually built and one automatically extracted from large text corpora. Several manually built thesaurus have been semi-formatted to be merged in a consistent common base. The automatic extraction is based on both syntax and statistics. We present in this paper the way thesaurus are built and the results on Scientific corpus {{in the context of}} the TIPS project...|$|R
40|$|It {{is argued}} that <b>a</b> <b>thesaurus,</b> or {{semantic}} classification, may be required in the resolution of multiple meaning for machine translation and allied purposes. The problem <b>of</b> constructing <b>a</b> <b>thesaurus</b> is then considered; this involves a method for defining the meanings or uses <b>of</b> words, and <b>a</b> procedure for classifying them. It is suggested that word uses may be {{defined in terms of}} their "semantic relations " with other words, and that the classification may be based on these relations; the paper then shows how the uses of words may be defined by synonyms to give "rows" or sets of synonymous word uses, which can then be grouped by their common words, to give thesauric classes. <b>A</b> discussion <b>of</b> the role of synonymy in language is followed by <b>an</b> examination <b>of</b> the way in which multiple meaning may be resolved by the use <b>of</b> <b>a</b> <b>thesaurus</b> <b>of</b> the kind described. The work described below has arisen from the Cambridge Language Research Unit’s original ideas abou...|$|R
40|$|This paper {{seeks to}} report an {{investigation}} into the ways in which end-users perceive a thesaurus-enhanced search interface, in particular thesaurus and search interface usability. The results suggest that interface usability is <b>a</b> factor affecting <b>thesaurus</b> browsing/navigation and other information-searching behaviours. Academic staff viewed the function <b>of</b> <b>a</b> <b>thesaurus</b> as being useful for narrowing down a search and providing alternative search terms, while postgraduates stressed the role of the thesaurus for broadening searches and providing new terms...|$|R
40|$|Jean Dartnall {{describes}} an indexing project {{for a community}} organization which has a strong focus on user needs. The project included the development <b>of</b> <b>a</b> <b>thesaurus</b> and <b>of</b> broad subject browsing options. Also discussed are the differences between indexing information about organizations and indexing documents. These differences are <b>a</b> consequence <b>of</b> the facts that organizations change, people with different backgrounds use the index, and organizations may request input into indexing decisions...|$|R
40|$|This paper {{deals with}} the {{creation}} <b>of</b> <b>a</b> <b>thesaurus</b> for information retrieval using fuzzy set theory. The author names the generalization as a fuzzy association. It is shown that the fuzzy association incorporates some current methods of indexing for bibliographic databases. An algorithm to develop the fuzzy association is given. <b>A</b> method <b>of</b> information retrieval through the fuzzy association is developed and two algorithms for this are discussed...|$|R
40|$|The author proposes the {{creation}} <b>of</b> <b>a</b> <b>thesaurus</b> automation management system using a conceptual scheme. A {{study has been}} made on the theory of thesauri and the entity-relationship and relational models to develop a computer application that contemplates the aspects studied. The result is a program with a modular and open structure that includes all aspects of thesaurus construction including semantic restrictions, lexical units, navigation system, semantic relations, etc...|$|R
40|$|Faced {{with growing}} volume and {{accessibility}} of electronic textual information, information retrieval, and, in general, automatic documentation require updated terminological {{resources that are}} ever more voluminous. A current problem is the automated construction of these resources (e. g., terminologies, thesauri, glossaries, etd ~ ~) from a corpus. Various linguistic and statistical methods to handle this problem are coming to light. One problem that has been less studied is that of updating these resources, in particular, <b>of</b> classifying <b>a</b> term extracted from a corpus in a subject field, discipline or branch <b>of</b> <b>an</b> existing <b>thesaurus.</b> This {{is the first step}} in positioning a term extracted from a corpus in the structure <b>of</b> <b>a</b> <b>thesaurus</b> (generic relations, synonymy relations [...] ). This is an important problem in certain disciplines in which knowledge, and, in particular, vocabulary is not very stable over time, especially because of neologisms. This experiment compares different models for representing a term from a corpus for its automatic classification in the subject fields <b>of</b> <b>a</b> <b>thesaurus.</b> The classification method used is linear discriminatory analysis, based on a learning sample. The models evaluated here are: a term/document model where each term is a vector in document vector space, two term/term models where each term is a vector in term space, and the coordinates are either the co-occurrence, or the mutual information between terms. The most effective model is the one based on mutual information between terms, which typifies the fact that two terms often appear together in the corpus, but rarely apart...|$|R
50|$|An {{abridgment}} of the work, {{under the}} name <b>of</b> Kol Bo, <b>a</b> <b>thesaurus,</b> came into common use, replacing the original work.|$|R
30|$|Finally, {{the work}} in [22] is the closest to the present discussion, {{introducing}} a preliminary—but still purely statistical—version of our system and the training and test data sets that we have presently reused. However, the system presented in [22] was still lacking many of the current functionalities, including the rule-based methods to limit over-generation and the use <b>of</b> <b>a</b> <b>thesaurus</b> to exploit word synonymy. The current system, by contrast, outperforms its early version in [22], but it is of course more language-dependent.|$|R
40|$|This paper {{presents}} {{a method to}} resolve word sense ambiguity in a Korean-to-Japanese machine translation system using neural networks. The execution of our neural network model {{is based on the}} concept codes <b>of</b> <b>a</b> <b>thesaurus.</b> Most previous word sense disambiguation approaches based on neural networks have limitations due to their huge feature set size. By contrast, we reduce the number of features of the network to a practical size by using concept codes as features rather than the lexical words themselves...|$|R
40|$|This paper {{describes}} a graphical interface for the navigation {{and construction of}} faceted thesauri {{that is based on}} formal concept analysis. Each facet <b>of</b> <b>a</b> <b>thesaurus</b> is represented as a mathematical lattice that is further subdivided into components. Users can graphically navigate through the Java implementation of the interface by clicking on terms that connect facets and components. Since there are many applications for thesauri in the knowledge representation field, such a graphical interface has the potential of being very useful...|$|R
40|$|Abstract: <b>A</b> <b>thesaurus</b> is <b>a</b> {{controlled}} vocabulary {{arranged in}} a known order and structured so that equivalence, homographic, hierarchical, and associative relationships among terms are displayed clearly and identified by standardized relationship indicators that are employed reciprocally. The primary purposes <b>of</b> <b>a</b> <b>thesaurus</b> are (<b>a)</b> to facilitate retrieval of documents and (b) to achieve consistency in the indexing of written or otherwise recorded documents and other items, mainly for postcoordinate {{information storage and retrieval}} systems. This standard provides guidelines for constructing monolingual thesauri: formulating the descriptors, establishing relationships among terms, and effectively presenting the information in print and on a screen. It also includes thesaurus maintenance procedures and recommended features of thesaurus management systems...|$|R
40|$|Abstract. This article {{describes}} {{a system for}} ontology alignment, SAMBO, and presents its results for the benchmark and anatomy tasks in the 2007 Ontology Alignment Evaluation Initiative. For the benchmark task {{we have used a}} strategy based on string matching as well as the use <b>of</b> <b>a</b> <b>thesaurus,</b> and obtained good results in many cases. For the anatomy task we have used <b>a</b> combination <b>of</b> string matching and the use of domain knowledge. This combination performed well in former evaluations using other anatomy ontologies. ...|$|R
40|$|In example-based NLP, {{the problem}} of cmnputationM cost of example {{retrieval}} is severe, since the retrieval time increases {{in proportion to the}} number of examples in the database. This paper proposes a novel example retrieval nethod for avoiding full retrieval of examples. The proposed method has the following three features,) it generates retrieval queries from similarities, 2) ef- ficient example retrieval through the tree structure <b>of</b> <b>a</b> <b>thesaurus,</b> 3) binary search along subsumption ordering of retrieval queries. Exmnple retrieval time drastically decreases with the method...|$|R
50|$|Her Wizards of the Coast {{biography}} {{mentions that}} she is fond <b>of</b> going through <b>a</b> <b>thesaurus.</b> She enjoys Beowulf, Norse mythology, and Orlando Innamorato.|$|R
50|$|IMS VDEX {{allows the}} {{exchange}} and expression of simple machine-readable lists of human language terms, along with {{information that may}} assist a human in understanding {{the meaning of the}} various terms, i.e. <b>a</b> flat list <b>of</b> values, <b>a</b> hierarchical tree <b>of</b> values, <b>a</b> <b>thesaurus,</b> <b>a</b> taxonomy, a glossary or a dictionary.|$|R
40|$|Choose between "e-learning", "digital learning" or "virtual learning" as {{a keyword}} for a {{scientific}} article {{can be a}} dilemma for a researcher who does not know the management <b>of</b> <b>a</b> <b>thesaurus</b> which should normalize the keywords of your contribution. So far, the selection of key words with greater or lesser success is a requirement that scientific journals make their authors and they consider them a procedure more in preparation for shipment <b>of</b> <b>an</b> item. Today, {{with the ability to}} search the full-text articles, is it useful to continue considering...|$|R
40|$|Text <b>of</b> <b>a</b> speech {{given on}} 1 April 1993  during the Library Week. Difficulties faced by landcape architects, who do research work, in access to {{information}} have been expressed as lack of guidance on how and where to find information; limited open hours or not being abl? to take photocopies even if the service is open beyond office hours; lack <b>of</b> <b>a</b> <b>thesaurus</b> fo r landscape architecture to choose the right terms for an online literature search; insufficiency of the number o f periodicals available in the country’; lack of copying facilities for nonbook materials such as plans, slides, engravings, sound and video cassettes...|$|R
40|$|Automatic query {{expansion}} {{methods for}} English and other languages text retrieval {{have been studied}} for a long time. In this research we study the retrieval effectiveness, achieved when we apply a successful automatic query expansion method in Arabic text retrieval based on <b>an</b> automatic <b>thesaurus.</b> Our experiments show that the automatic query expansion method resulted in a notable improvement in Arabic text retrieval using <b>a</b> sample <b>of</b> abstracts of Arabic documents. The study showed that the use <b>of</b> <b>a</b> <b>thesaurus</b> has improved information retrieval system by 10 % - 20 %. The study also shows that the greater the number of documents in the building thesaurus, Thesaurus was more accurate...|$|R
40|$|Thesauri of {{scientific}} terminology are indispensable tools {{for purposes of}} information retrieval serviees and indexing. The extent <b>of</b> <b>a</b> <b>thesaurus</b> in <b>an</b> area <b>of</b> scientific knowledge should depend upon <b>a</b> number <b>of</b> decisions concerning the type; amount and level of information on one side, and user qualifications and financial resources available on the other. Bearing these constraints in mind thesaurus contraction {{can be achieved by}} employing spercial metbods which lead to special structures. Thesaurus preparation according to ISO Standard 2788 has been reviewed;:s an aid to probable designers of Turkish thesauri...|$|R
30|$|Pattern matching: Phrase {{that matches}} with “should”, “could”, “include”, “could have” or some with similar intent phrases are {{indicators}} of suggestions. We {{came up with}} <b>a</b> list <b>of</b> phrases, <b>a</b> <b>thesaurus</b> as shown in Table  2 through empirically observing students’ comments, similar to Brun and Hagege (2013).|$|R
40|$|Introduction Software environments {{support the}} process of {{constructing}} and maintaining application systems. This paper describes the idea <b>of</b> <b>a</b> <b>thesaurus</b> 1 as <b>a</b> viable foundation for software environments. <b>A</b> <b>thesaurus</b> contains information about the names and identifiers in all the software written in all the languages <b>of</b> <b>an</b> application. Information about extensional data in a database or persistent store is also included. The comprehensiveness of the thesaurus {{is in contrast to}} most commercially available tools which focus either on the source code only (source code analysers) or on database-specific information (data dictionaries). A few data dictionary tools also include source code information, but relationships between names and identifiers in the software written in the various languages are not recorded automatically. All the contents of the thesaurus are automatically maintained. The whole application system is anal...|$|R
40|$|Abstract. Building <b>a</b> <b>thesaurus</b> is {{very costly}} and {{time-consuming}} task. To alleviate this problem, this paper proposes a new method for extending <b>a</b> <b>thesaurus</b> by adding taxonomic information automatically extracted from an MRD. The proposed method adopts a {{machine learning algorithm}} in acquiring rules for identifying a taxonomic relationship to minimize human-intervention. The accuracy of our method in identifying hypernyms <b>of</b> <b>a</b> noun is 89. 7 %, and {{it shows that the}} proposed method can be successfully applied to the problem <b>of</b> extending <b>a</b> <b>thesaurus.</b> ...|$|R
50|$|A Study in Frustration: The Fletcher Henderson Story is a box set {{compilation}} surveying studio {{recordings of}} the Fletcher Henderson Orchestra from 1923 to 1938, released in 1961 on Columbia Records, CXK 85470. It initially appeared as a four-album set produced by Frank Driggs and assembled by John Hammond, both of whom also wrote the liner notes. The set was part <b>of</b> <b>a</b> <b>Thesaurus</b> <b>of</b> Classic Jazz series on Columbia which included King of the Delta Blues Singers also worked on by Hammond and Driggs and released in 1961, the first album reissue of songs by blues legend Robert Johnson.|$|R
40|$|The article {{presents}} a basic {{proposal for the}} automation and use of thesauri for information retrieval in distributed environments, through web services based on the Resource Description Framework (RDF) architecture. It begins by reviewing the proposals for descriptive tagging for thesauri coding that have appeared {{over the past four}} years. This is followed by <b>a</b> description <b>of</b> the basic architecture <b>of</b> <b>a</b> <b>thesaurus</b> implemented in Java. The article concludes by reviewing different communication and data exchange protocols, together with applications {{that can be used to}} implement this service. The text is accompanied by the computer application that has been developed...|$|R
40|$|This paper {{describes}} {{the work done}} in the TIPS project about the construction <b>of</b> <b>a</b> <b>thesaurus.</b> This construction is a merge from <b>a</b> compilation <b>of</b> data from several web sources. These data comes from manual work, some data are real thesaurus, other are indexing recommendations. The merge is done with automatically extracted terms from large text corpora. The automatic extraction is based on both syntax and statistics. We present in this paper the way thesaurus are built and the results on Scientific corpus {{in the context of}} the TIPS project. This short paper emphasis on some technical aspects...|$|R
