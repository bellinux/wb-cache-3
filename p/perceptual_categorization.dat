144|30|Public
25|$|Secondary {{consciousness}} {{is seen in}} animals with semantic capabilities, such as the four great apes. It is present in its richest form in the human species, which is unique in possessing complex language made up of syntax and semantics. In considering how the neural mechanisms underlying primary consciousness arose and were maintained during evolution, it is proposed that at some time around the divergence of reptiles into mammals and then into birds, the embryological development {{of large numbers of}} new reciprocal connections allowed rich re-entrant activity to take place between the more posterior brain systems carrying out <b>perceptual</b> <b>categorization</b> and the more frontally located systems responsible for value-category memory. The ability of an animal to relate a present complex scene to its own previous history of learning conferred an adaptive evolutionary advantage. At much later evolutionary epochs, further re-entrant circuits appeared that linked semantic and linguistic performance to categorical and conceptual memory systems. This development enabled the emergence of secondary consciousness.|$|E
5000|$|Sergent, J., & Lorber, E. (1983). <b>Perceptual</b> <b>categorization</b> in the {{cerebral}} hemispheres. Brain and Cognition, 2(1), 39-54. doi:10.1016/0278-2626(83)90028-3 ...|$|E
50|$|<b>Perceptual</b> <b>categorization</b> is said {{to occur}} when a person or animal {{responds}} {{in a similar way}} to a range of stimuli that share common features. For example, a squirrel climbs a tree when it sees Rex, Shep, or Trixie, which suggests that it categorizes all three as something to avoid. This sorting of instances into groups is crucial to survival. Among other things, an animal must categorize if it is to apply learning about one object (e.g. Rex bit me) to new instances of that category (dogs may bite).|$|E
40|$|Perception and {{production}} data of nonsense CVV syllable paires differing with minimal {{opposition in the}} initial sounds were analysed to examine {{whether or not the}} perception of speech sound differences precedes the articulation of them during the phonological acquisition period. The initial consonants are /s/, /z/, /∫/, /ts/, /dz/, /t∫/and /dʒ/, and compose CVV syllables with /a/ (or/w/) and /o/. Paires of dolls are given CVV names and the subjects are asked to repeat the syllables and to performe certain actions with the named doll. If he is correct on 7 out of 10 trials he is assumed to have demonstrated phonemic perception of the opposition in question. His imitated responses are recorded and transcribed to evaluate his articulatory production of the oppositions From the results of this experiment, one might hypothesize that the child could produce. members of acoustically similar speech sounds differently each other before he could perceptually distinguish them, and after establishing his <b>perceptual</b> <b>categorizations</b> he could acquire the abiity to articulate accurately each of speech sounds...|$|R
2500|$|Early work in <b>perceptual</b> and {{conceptual}} <b>categorization</b> assumed that categories had critical features and that category membership could {{be determined by}} logical rules for the combination of features. More recent theories have accepted that categories may have an ill-defined or [...] "fuzzy" [...] structure and have proposed probabilistic or global similarity models for the verification of category membership.|$|R
40|$|This paper {{presents}} {{an overview of}} work {{on the effects of}} earcons and auditory icons on picture categorization and the results of 2 new experiments. The general finding of the experiments is that earcons have an inhibitory effect on picture categorization whereas auditory icons, in general, have a facilitating effect. These findings will be discussed and related to the theoretical framework of <b>perceptual</b> versus conceptual <b>categorization.</b> 1...|$|R
5000|$|Edelman {{integrates}} the DCH hypothesis into Neural Darwinism, {{in which}} metastable interactions in the thalamocortical region cause {{a process of}} selectionism through re-entry, a host of internal feedback loops. [...] "Re-entry", as Edelman states, [...] "provides the critical {{means by which the}} activities of distributed multiple brain areas are linked, bound, and then dynamically altered in time during <b>perceptual</b> <b>categorization.</b> Both diversity and re-entry are necessary to account for the fundamental properties of conscious experience." [...] These re-entrant signals are reinforced by areas Edelman calls [...] "degenerate". Degeneracy doesn't imply deterioration, but instead redundancy as many areas in the brain handle the same or similar tasks. With this brain structure emerging in early humans, selection could favor certain brains and pass their patterns down the generations. Habits once erratic and highly individual ultimately became the social norm.|$|E
50|$|While {{animals with}} primary {{consciousness}} have long-term memory, they lack explicit narrative, and, at best, can only {{deal with the}} immediate scene in the remembered present. While they still have an advantage over animals lacking such ability, evolution has brought forth a growing complexity in consciousness, particularly in mammals. Animals with this complexity {{are said to have}} secondary consciousness.Secondary consciousness is seen in animals with semantic capabilities, such as the four great apes. It is present in its richest form in the human species, which is unique in possessing complex language made up of syntax and semantics. In considering how the neural mechanisms underlying primary consciousness arose and were maintained during evolution, it is proposed that at some time around the divergence of reptiles into mammals and then into birds, the embryological development of large numbers of new reciprocal connections allowed rich re-entrant activity to take place between the more posterior brain systems carrying out <b>perceptual</b> <b>categorization</b> and the more frontally located systems responsible for value-category memory. The ability of an animal to relate a present complex scene to its own previous history of learning conferred an adaptive evolutionary advantage. At much later evolutionary epochs, further re-entrant circuits appeared that linked semantic and linguistic performance to categorical and conceptual memory systems. This development enabled the emergence of secondary consciousness.|$|E
40|$|Two {{experiments}} investigated binary {{categorization of}} artificial, multidimensional objects that were presented for intervals between 33 and 200 ms. The experiments {{consisted of two}} stages. In the first stage, participants learned to categorize nine objects into two categories. In the second stage, the same objects were presented for categorization again, and the presentation duration of the objects was manipulated. The results show systematic effects of exposure duration on category choices. Three formal process models of <b>perceptual</b> <b>categorization</b> were applied to the choice data. The extended generalized context model, which is a dimension-sampling model of <b>perceptual</b> <b>categorization,</b> provided the best account of the data...|$|E
40|$|Presented at the 7 th International Conference on Auditory Display (ICAD), Espoo, Finland, July 29 -August 1, 2001. This paper {{presents}} {{an overview of}} work {{on the effects of}} earcons and auditory icons on picture categorization and the results of 2 new experiments. The general finding of the experiments is that earcons have an inhibitory effect on picture categorization whereas auditory icons, in general, have a facilitating effect. These findings will be discussed and related to the theoretical framework of <b>perceptual</b> versus conceptual <b>categorization...</b>|$|R
40|$|The {{question}} of how the human brain "makes sense" of the sensory input it receives has been at the heart of cognitive and neuroscience research for the last decades. One of the most fundamental <b>perceptual</b> processes is <b>categorization</b>  the ability to compartmentalize knowledge for efficient retrieval. Recent advances in computer graphics and computer vision have made it possible to both produce highly realistic stimulus material for controlled experiments in life-like environments as well as to enable highly detailed analyses of the physical properties of realworld stimuli...|$|R
40|$|Recent {{research}} {{has argued that}} categorization is strongly tied to language processing. For example, language (in the form of verbal category labels) {{has been shown to}} influence perceptual discriminations of color (Winawer et al., 2007). However, does this imply that categorical perception is essentially verbally mediated perception? The present study extends recent findings in our lab showing that categorical perception can occur {{even in the absence of}} overt labels. In particular, we evaluate the degree to which certain interference tasks (verbal and spatial) reduce the effect of learned categorical perception for complex visual stimuli (faces). Contrary to previous findings with color categories, our results show that a verbal interference task does not disrupt learned categorical perception effects for faces. Our results are interpreted in light of the ongoing debate about the role of language in categorization. In particular, we suggest that at least a sub-set of categorical perception effects may be effectively “language-free”. Keywords: <b>Perceptual</b> Learning, <b>Categorization,</b> Concept Learning, Language...|$|R
40|$|Visual object {{recognition}} and categorization are fundamental abilities required for successful negotiation {{of the visual}} world. Humans effortlessly classify and recognize objects and faces within busy scenes, thousands of times a day. Thus, understanding how <b>perceptual</b> <b>categorization</b> and learning occur and how suc...|$|E
40|$|Category rule {{learning}} was examined in two amnesic patients using the <b>perceptual</b> <b>categorization</b> task (e. g., Ashby & Gott, 1988; Filoteo & Maddox, 1999). Traditional accuracy-based analyses {{as well as}} quantitative model-based analyses were performed. Unlike accuracy-based analyses, the model-based approach allowed us to examine both categorization rule learning and variability in the trial-by-trial application of the participant's categorization rule...|$|E
40|$|From {{at least}} two months onwards, infants can form perceptual categories. During {{the first year of}} life, object {{knowledge}} develops from the ability to represent individual object features to representing correlations between attributes and to integrate information from different sources. At {{the end of the first}} year, these representations are shaped by labels, opening the way to conceptual knowledge. Here, we review the development of object knowledge and object categorization over the first year of life. We then present an artificial neural network model that models the transition from early <b>perceptual</b> <b>categorization</b> to categories mediated by labels. The model informs a current debate on the role of labels in object categorization by suggesting that although labels do not act as object features they nevertheless affect perceived similarity of perceptually distinct objects sharing the same label. The model presents the first step of an integrated account from early <b>perceptual</b> <b>categorization</b> to language-based concept learning...|$|E
40|$|Looking beyond looks: Comments on Sloutsky, Kloos, and Fisher How do we acquire {{knowledge}} about the world around us? Do the sources of information that underlie knowledge acquisition in young children {{differ from those of}} adults? These fundamental questions have permeated scientific inquiry since the time of Socrates and Aristotle. Following in this tradition, a recent paper by Sloutsky, Kloos, and Fisher (SKF) (2006) is ambitious, indeed classic. Their goal was to uncover the contributions of conceptual and perceptual information in children’s categorization and induction about natural kinds. But experimental evidence {{is only as good as}} the theory and logic upon which it rests. Unfortunately, SKF’s approach to each of the key constructs—concepts, <b>perceptual</b> information, <b>categorization,</b> induction—misses its mark. To quickly review: SKF taught children two novel categories of bug-like entities, stipulating that the categories could be distinguished by the ratio of buttons to fingers (members of one category had more buttons, members of the other had more fingers). SKF introduced novel words (“ziblet ” and “flurp”) for these categories. Childre...|$|R
40|$|Event-related {{potentials}} {{were used}} to investigate neural processes relating perceptual similarity to action control. To assess whether perceptual overlap among targets and nontargets would modulate the N 2 /P 3 complex, the present study used multiple nontarget categories varying in their targetlike characteristics. Participants made one (relatively rare) response to a low-probability stimulus (target), and they made a different (relatively common) response to all other stimuli (nontargets). The critical nontarget categories had equivalent probability (. 10) but varied in their targetlike characteristics. Supporting the N 2 component as sensitive {{to the strength of}} conflicting action imperatives, perceptual overlap among targets and nontargets elicited a prominent N 2. In contrast, amplitude of the P 3 component appeared most sensitive to the extent of cognitive processing needed for categorization. Descriptors: ERPs, Event-related potentials, P 3, N 2, Choice RT, <b>Perceptual</b> similarity, <b>Categorization,</b> Conflict monitoring Pursuing any particular course of action requires overcoming competing tendencies triggered by the many cues typically present in one’s thoughts and environment. A motorist who needs to turn left at North Nitch Street but not North Hitc...|$|R
40|$|This paper {{proposes that}} SOUND SYMBOLISM, and more {{specifically}} PHONEMIC ICONICITY, {{plays a role in}} conveying emotional weight in the context of poetry. Previous research has indicated that the ratio of plosives to nasals in poetry predicts overall perception of emotional affect, with plosives designating activity and pleasantness, and nasals designating inactivity and unpleasantness (Auracher, Albers, Zhai, Gareeva, 2 ̆ 6 Stavniychuk 2010); however, this research has ignored the influence of such potentially mitigating factors as orthography and lexical meaning. The current study involves naive English L 1 speakers listening to recordings of selected haiku from Matsuo Basho 2 ̆ 7 s Oku No Hosomichi (`Narrow Road to the Deep North 2 ̆ 7) in the original Japanese, and as such, the potential of orthography and lexical meaning to influence perception of emotion is eliminated. After listening to each haiku twice, subjects were asked to rate the appropriateness of eight emotion words that ranged from active and positive to inactive and positive, and from active and negative to inactive and negative, on a five-point Likert scale. Emotion words were chosen {{on the basis of their}} respective positions on the Circumplex Model of Affect, in which each emotion is conceptualized in terms of its location along two intersecting axes measuring valence (negative - positive) and arousal (inactive - active) (Russell 1980). The selected words occupied regularly spaced positions along this two-dimensional circular model. Results indicate that plosive to nasal ratio may indeed play a role in the perception of emotion in poetry, particularly in the case of poems with high plosive to nasal ratios, which were perceived as markedly more active and positive than other poems. Wider implications of the discernible patterns of perception of emotional affect based on plosive to nasal ratio include the possibility that phonemic iconicity plays a role in general language processing. As this research involves Japanese L 2 phonemic perception by naÃ 2 ̆ 6 hibar;ve English L 1 listeners, current L 2 phonological perceptual theory is discussed, and taken into account in the analysis of the results. Specific consideration is given to the potential of English L 1 speakers to perceive the Japanese rhotic /r/, which does not appear in English, as the plosives /t/ or /d/, and the Japanese affricate /ts/, which commonly appears syllable-initially in Japanese, but is much rarer in this position in English, as /s/ (Nozawa 2008). Future research on English L 1 speakers 2 ̆ 7 underlying <b>perceptual</b> <b>categorizations</b> of targeted sounds in Japanese is also proposed...|$|R
40|$|<b>Perceptual</b> <b>{{categorization}}</b> at {{the basic}} level is faster than categorization at more superordinate or subordinate levels (Rosch et al, 1976). For categories of perceptual expertise, this basic-level advantage is attenuated such that subordinate levels are categorized {{as fast as}} the basic level (Tanaka & Taylor, 1991). But, {{what does it mean to}} be fastest? One explanation is that levels of abstraction that are categorized faster are processed first. We tested this "fastest means first " hypothesis by contrasting the time-course of basic- and subordinate-level categorization for novice and expert categories with a signal-to-respond task. Results indicated no qualitative differences in the time courses of perceptual decisions for novice and expert categories, nor was there evidence for a basic-level stage preceding a subordinate-level stage. Simulations with an extant object categorization model investigated how seemingly qualitative differences between novice and expert categorization can be accounted for with quantitative changes to model parameters over learning. Together, the behavioral data and simulation results suggest that fastest does not necessarily mean first in <b>perceptual</b> <b>categorization...</b>|$|E
30|$|The {{remaining}} errors (3 of 50 syllables) {{resulted from}} an incorrect <b>perceptual</b> <b>categorization</b> of the phonetic feature “stressed vs. unstressed”, which {{may result from}} the fact that the settings of the pulmonary and laryngeal actions was fixed within the current version of our model. Thus, the main acoustic cue for identifying the stressed vs. unstressed condition, which is available in our model, is the length of the whole syllable and the length of single sound segments within each syllable.|$|E
40|$|Abstract Recent {{theoretical}} {{advances in}} theories of catego-rization response times {{have made it}} possible to differentiate mental architectures that specify how processes occurring over several information-processing channels are combined (e. g., in serial or in parallel). This article introduces the nu-merical computations necessary to generate predictions for a class of logical rule-based models that have recently been used to account for speeded <b>perceptual</b> <b>categorization</b> judg-ments (Fifić, M., Little, D. R. & Nosofsky, R. M [...] Psycholog...|$|E
40|$|Abstract: It is {{possible}} that in Czech a vowel is consistently longer before a tautosyllabic voiced as opposed to voiceless obstruent. The main {{purpose of this study}} was to determine if this hypothesized variation interacts with the perception of vowel quantity. Two experiments were conducted that examined the effect of a voiceless vs. devoiced coda context and of a voiceless vs. voiced coda context on <b>perceptual</b> short/long vowel <b>categorization.</b> It was found that quantitatively ambiguous vowels were more likely to be perceived as short before a voiced coda than before a voiceless coda. It is concluded that vowel duration is indeed affected by coda voicing in Czech and that listeners are sensitive to this variation because they adjust the perception of vowel quantity accordingly...|$|R
40|$|Categorization is {{essential}} for perception and provides an important foundation for higher cognitive functions. In this review, I focus on <b>perceptual</b> aspects of <b>categorization,</b> especially related to object shape. In order to visually categorize an object, the visual system has to solve two basic problems. The first one is how to recognize objects after spatial transformations like rotations and size-scalings. The second problem is how to categorize objects with different shapes {{as members of the}} same category. I review the literature related to these two problems against the background of the hierarchy of transformation groups specified in Felix Klein’s Erlanger Programm. The Erlanger Programm provides a general framework for the understanding of object shape, and may allow integrating object recognition and categorization literatures...|$|R
40|$|Infants respond {{categorical}}ly to color. However, {{the nature}} of infants' categorical responding to color is unclear. The current study investigated two issues. First, is infants' categorical responding more absolute than adults' categorical responding? That is, can infants discriminate two stimuli from the same color category? Second, is color categorization in infants truly <b>perceptual?</b> Color <b>categorization</b> was tested by recording adults' and infants' eye movements on a target detection task. In Experiment 1, adults were faster at fixating a colored target when it was presented on a colored background from a different color category (between-category) than when it was presented on a colored background from the same color category (within-category), even when within- and between-category chromatic differences were equated in CIE (Committee International d'Eclairage) color space. This category effect was found for two chromatic separation sizes. In Experiment 2, 4 -month-olds also responded categorically on the task. Infants were able to fixate the target when the background color was from the same category. However, as with adults, infants were faster at fixating the target when the target background chromatic difference was between-category than when it was within-category. This implies that infant color categorization, like adult color <b>categorization,</b> is truly <b>perceptual.</b> (c) 2005 Elsevier Inc. All rights reserved...|$|R
40|$|Abstract Response {{inhibition}} in {{stop signal}} tasks has been explained as {{the outcome of}} a race between GO and STOP processes (e. g., Logan, 1981). Response choice in two-alternative <b>perceptual</b> <b>categorization</b> tasks has been explained as {{the outcome of a}}n accumulation of evidence for the alter-native responses. To begin unifying these two powerful inves-tigation frameworks, we obtained data from humans and macaque monkeys performing a stop signal task with re-sponses guided by <b>perceptual</b> <b>categorization</b> and variable degrees of difficulty, ranging from low to high accuracy. Comparable results across species reinforced the validity of this animal model. Response times and errors increased with categorization difficulty. The probability of failing to inhibit responses on stop signal trials increased with stop signal delay, and the response times for failed stop signal trials were shorter than those for trials with no stop signal. Thus, the Logan race model could be applied to estimate the duration of the stop-ping process. We found that the duration of the STOP process did not vary across a wide range of discrimination accuracies. This is consistent with the functional, and possibly mechanis-tic, independence of choice and inhibition mechanisms...|$|E
40|$|The {{nature and}} early time {{course of the}} initial {{processing}} differences between visually matched linguistic and nonlinguistic images were studied with event-related potentials ~ERPs!. The first effect began at 90 ms when ERPs to written words diverged from other objects, including faces. By 125 ms, ERPs to words and faces were more positive than those to other objects, effects identified with the P 150. The amplitude and scalp distribution of P 150 s to words and faces were similar. The P 150 seemed to be elicited selectively by images resembling any well-learned category of visual patterns. We propose that ~a! visual <b>perceptual</b> <b>categorization</b> based on long-term experience begins by 125 ms, ~b! P 150 amplitude varies with the cumulative experience people have discriminating among instances of specific categories of visual objects ~e. g., words, faces!, and ~c! the P 150 is a scalp reflection of letterstring and face intracranial ERPs in posterior fusiform gyrus. Descriptors: Event-related potentials, Visual <b>perceptual</b> <b>categorization,</b> Word perception, Face perception, Perceptual skill learning, Posterior fusiform gyrus Performance differences between linguistic and nonlinguistic visual objects have been demonstrated in behavioral studies {{using a variety of}} tasks ~e. g., Potter & Faulconer, 1975 !; these finding...|$|E
40|$|We examine {{occurrences of}} {{categorical}} assimi-lation (neutralizations) in French, {{the perception of}} voiced and unvoiced word-final obstruents in dif-ferent phonological contexts. We first show the categorical nature of the alternation (Exp. 1), sup-ported in Exp. 2 by <b>perceptual</b> <b>categorization</b> data. In Exp. 3, the interpretation of this first percept appears to be corrected in certain contexts, induc-ing compensation. We argue that context effects are phonological in this case, rather than auditory or phonetic. We conclude that linguistic knowl-edge of alternations is necessary in compensation for categorical assimilation...|$|E
40|$|Semantic {{memory was}} {{investigated}} in a patient (MR) affected by a severe apperceptive visual agnosia, due to an ischemic cerebral lesion, bilaterally affecting the infero-mesial parts of the temporo-occipital cortices. The study was made {{by means of a}} Semantic Knowledge Questionnaire (), which takes separately into account four categories of living beings (animals, fruits, vegetables and body parts) and of artefacts (furniture, tools, vehicles and musical instruments), does not require a visual analysis and allows to distinguish errors concerning super-ordinate <b>categorization,</b> <b>perceptual</b> features and functional/encyclopedic knowledge. When the total number of errors obtained on all the categories of living and non-living beings was considered, a non-significant trend toward a higher number of errors in living stimuli was observed. This difference, however, became significant when body parts and musical instruments were excluded from the analysis. Furthermore, the number of errors obtained on the musical instruments was similar to that obtained on the living categories of animals, fruits and vegetables and significantly higher of that obtained in the other artefact categories. This difference was still significant when familiarity, frequency of use and prototypicality of each stimulus entered into a logistic regression analysis. On the other hand, a separate analysis of errors obtained on questions exploring super-ordinate <b>categorization,</b> <b>perceptual</b> features and functional/encyclopedic attributes showed that the differences between living and non-living stimuli and between musical instruments and other artefact categories were mainly due to errors obtained on questions exploring perceptual features. All these data are at variance with the ‘domains of knowledge’ hypothesis’, which assumes that the breakdown of different categories of living and non-living things respects the distinction between biological entities and artefacts and support the models assuming that ‘category-specific semantic disorders’ are the by-product of the differential weighting that visual-perceptual and functional (or action-related) attributes have in the construction of different biological and artefacts categories...|$|R
40|$|Abstract—Given {{a set of}} captioned {{images of}} {{cluttered}} scenes containing various objects in different positions and scales, we learn named contour models of object categories without relying on bounding box annotation. We extend a recent language-vision integration framework that finds spatial configurations of image features that co-occur with words in image captions. By substituting appearance features with local contour features, object categories are recognized by a contour model that grows along the object’s boundary. Experiments on ETHZ are presented to show that 1) the extended framework is better able to learn named visual categories whose withinclass variation is better captured by a shape model than an appearance model; and 2) typical object recognition methods fail when manually annotated bounding boxes are unavailable. Keywords-Language-Vision integration, Image annotation, <b>Perceptual</b> grouping, Object <b>categorization,</b> Semi-supervise...|$|R
40|$|An {{important}} question in cognitive science is how conceptual knowledge interacts with perception. For example, how does knowing that trucks have wheels and windshields impact a person's {{recognition of a}} truck? Through a series of categorization tasks, we explore two pathways by which humans can learn to identify objects. One pathway involves the acquisition of perceptual expertise through extensive taskrelevant experience, and leads to the rapid identification of individual stimuli. A second pathway involves a translation process in which percepts of objects are encoded into symbolic descriptions. The use of this pathway results in a similar ability to identify individual stimuli, but requires more time to operate due {{to the demands of}} the online translation process. These results are discussed in terms of related work in <b>categorization,</b> <b>perceptual</b> expertise, and influence of language on thought...|$|R
40|$|As {{the use of}} {{wearable}} haptic devices with vibrating alert features is commonplace, {{an understanding}} of the <b>perceptual</b> <b>categorization</b> of vibrotactile frequencies has become important. This understanding can be substantially enhanced by unveiling how neural activity represents vibrotactile frequency information. Using functional magnetic resonance imaging (fMRI), this study investigated categorical clustering patterns of the frequency-dependent neural activity evoked by vibrotactile stimuli with gradually changing frequencies from 20 to 200 Hz. First, a searchlight multi-voxel pattern analysis (MVPA) was used to find brain regions exhibiting neural activities associated with frequency information. We found that the contralateral postcentral gyrus (S 1) and the supramarginal gyrus (SMG) carried frequency-dependent information. Next, we applied multidimensional scaling (MDS) to find low-dimensional neural representations of different frequencies obtained from the multi-voxel activity patterns within these regions. The clustering analysis on the MDS results showed that neural activity patterns of 20 - 100 Hz and 120 - 200 Hz were divided into two distinct groups. Interestingly, this neural grouping conformed to the perceptual frequency categories found in the previous behavioral studies. Our findings therefore suggest that neural activity patterns in the somatosensory cortical regions may provide a neural basis for the <b>perceptual</b> <b>categorization</b> of vibrotactile frequency. clos...|$|E
40|$|According {{to various}} {{influential}} formal models of cognition, <b>perceptual</b> <b>categorization</b> and old−new recognition recruit the same memory system. By contrast, the prevailing {{view in the}} cognitive neuroscience literature is that separate neural systems mediate <b>perceptual</b> <b>categorization</b> and recognition. A direct form of evidence is that separate brain regions are activated when observers engage in categorization and recognition tasks involving {{the same types of}} stimuli. However, even if the same memory-based comparison processes underlie categorization and recognition, one would not expect to see identical patterns of brain activity across the tasks; the reason is that observers would adjust parameter settings (e. g., vary criterion settings) across the tasks to satisfy the different task goals. In this fMRI study, we conducted categorization and recognition tasks in which stimulus conditions were held constant, and in which observers were induced to vary hypothesized parameter settings across conditions. A formal exemplar model was fitted to the data to track the changes in parameters to help interpret the fMRI results. We observed systematic effects of changes in parameters on patterns of brain activity, which were interpretable in terms of differing forms of evidence accumulation that resulted from the changed parameter settings. After controlling for stimulus and parameter-related differences, we found little evidence that categorization and recognition recruit separate memory systems...|$|E
40|$|Functional Phonology, {{which makes}} a principled {{distinction}} between articulatory and perceptual representations, features, and constraints, can describe as well as explain the symmetries {{as well as the}} gaps in inventories of vowels and consonants. Symmetries are the language-specific results of general human limitations on the acquisition of <b>perceptual</b> <b>categorization</b> and motor skills. Gaps are the results of local hierarchies of articulatory effort, perceptual contrast, and perceptual confusion. There is no need to posit a dedicated inventory grammar: inventories are the automatic result of the constraints and their rankings in the production grammar...|$|E
40|$|This article {{describes}} the feature-sampling theory of recognition (FESTHER), {{a new model of}} the time course of recognition judgments based on a model of the time course of <b>perceptual</b> processing in <b>categorization</b> (K. Lamberts, 1995, 1998). FESTHER is applied to previous results and to data from 4 old-new recognition experiments. Experiments 1 and 2 provided a preliminary test of the model's ability to explain recognition judgments of simple objects under response deadlines. Experiments 3 and 4 involved a response-signal procedure to elicit recognition judgments at different time lags after presentation of a stimulus. Simple objects and words were used as stimuli in Experiments 3 and 4, respectively. The new model accounts well for the data from the 4 experiments and offers a parsimonious account of the time course of recognition judgments based on the time-dependent availability of stimulus information...|$|R
40|$|Observers can rapidly {{perform a}} variety of visual tasks such as categorizing a scene as open, as outdoor, or as a beach. Although we know that {{different}} tasks are typically associated with systematic differences in behavioral responses, to date, {{little is known about}} the underlying mechanisms. Here, we implemented a single integrated paradigm that links <b>perceptual</b> processes with <b>categorization</b> processes. Using a large image database of natural scenes, we trained machine-learning classifiers to derive quantitative measures of task-specific perceptual discriminability based on the distance between individual images and different categorization boundaries. We showed that the resulting discriminability measure accurately predicts variations in behavioral responses across categorization tasks and stimulus sets. We further used the model to design an experiment, which challenged previous interpretations of the so-called "superordinate advantage. " Overall, our study suggests that observed differences in behavioral responses across rapid categorization tasks reflect natural variations in perceptual discriminability...|$|R
40|$|Known as the cross-race effect (CRE), {{psychological}} {{research has}} consistently shown {{that people are}} extremely inept at identifying {{the face of a}} person who is from a race that is different than their own. While the CRE has most often been demonstrated in recognition memory, its effects have also been found in temporally preceding cognitive stages. The purpose of the current {{study was to examine the}} psychological underpinnings of the CRE by using a path-model analysis to estimate how temporally preceding mechanisms may mediate the cross-race effects demonstrated in recognition memory. Specifically, results estimated the mediating influences of interracial contact and social attitudes along with racial <b>categorization,</b> <b>perceptual</b> discrimination, and recollection. Temporal models assessing own-race faces and other-race faces demonstrated strong model-fit. Parameter difference estimates between the models suggests that own-race face recognition is strongly mediated by recollection, while other-race face recognition is more strongly mediated by perceptual discrimination. ...|$|R
