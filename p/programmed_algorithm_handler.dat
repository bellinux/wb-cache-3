0|7510|Public
40|$|The Dynamic <b>Programming</b> <b>algorithm</b> {{proposed}} by Rosenblatt and Kaspi (Rosenblatt, M. J., M. Kaspi. 1985. A dynamic <b>programming</b> <b>algorithm</b> for joint replenishment under general order cost functions. Management Sci. 31 (March) 369 [...] 373.) for an optimum partition problem {{is shown to}} be incorrect. An alternative Dynamic <b>Programming</b> <b>algorithm</b> is presented for this problem. ...|$|R
40|$|Rosenblatt and Kaspi (Rosenblatt, M. J., M. Kaspi. 1985. A dynamic <b>programming</b> <b>algorithm</b> {{for joint}} {{replenishment}} under general order cost functions. Management Sci. 31 (March) 369 [...] 373.) suggested a dynamic <b>programming</b> <b>algorithm</b> for partitioning {{a number of}} items ordered from a single supplier. It was assumed that items belonging to a group have a fixed common ordering cycle. Queyranne (Queyranne, M. 1987. Comment on a dynamic <b>programming</b> <b>algorithm</b> for joint replenishment under general order cost. Management Sci. 33 (1, January) 131 [...] 133.) in his comments on Rosenblatt and Kaspi described the correct dynamic <b>programming</b> <b>algorithm</b> for this optional partitioning problem. ...|$|R
40|$|In this paper, we {{demonstrate}} {{another approach}} with visualisation. The concepts of a game, {{combined with the}} use of colours (or shades of gray), is used to teach dynamic <b>programming</b> <b>algorithms.</b> We focus on sequence alignment algorithms, which are typical dynamic <b>programming</b> <b>algorithms.</b> (This <b>program</b> is written in Java and can be found at [URL] Finally, we claim that this approach is an e#ective way to teach dynamic <b>programming</b> <b>algorithms...</b>|$|R
40|$|New cache-oblivious and cache-aware {{algorithms}} {{for simple}} dynamic programming based on Valiant’s context-free language recognition algorithm are designed, implemented, analyzed, and empirically evaluated with timing studies and cache simulations. The {{studies show that}} for large inputs the cache-oblivious and cache-aware dynamic <b>programming</b> <b>algorithms</b> are significantly faster than the standard dynamic <b>programming</b> <b>algorithm.</b> Keywords: Dynamic <b>Programming,</b> Cache-Oblivious <b>Algorithms,</b> Cache-Aware Algorithms...|$|R
40|$|This {{dissertation}} {{contains a}} discussion concerning {{the validity of}} the principle of optimality and the dynamic <b>programming</b> <b>algorithm</b> in the context of discrete time and state multistage decision processes. The multistage decision model developed for the purpose of the investigation is of a general structure, especially as far as the reward function is concerned. The validity of the dynamic <b>programming</b> <b>algorithm</b> as a solution method is investigated and results are obtained for a rather wide class of decision processes. The intimate relationship between the principle and the algorithm is investigated and certain important conclusions are derived. In addition to the theoretical considerations involved in the implementation of the dynamic <b>programming</b> <b>algorithm,</b> some modeling and computational aspects are also investigated. It is demonstrated that the multistage decision model and the dynamic <b>programming</b> <b>algorithm</b> as defined in this study provide a solid framework for handling a wide class of multistage decision processes. The flexibility of the dynamic <b>programming</b> <b>algorithm</b> as a solution procedure for nonroutine reservoir control problems is demonstrated by two examples, one of which is a reliability problem. To the best of the author's knowledge, many of the theoretical derivations presented in this study, especially those concerning the relation between the principle of optimality and the dynamic <b>programming</b> <b>algorithm,</b> are novel...|$|R
30|$|The {{optimization}} <b>algorithm</b> is nonlinear <b>programming</b> <b>algorithm.</b>|$|R
2500|$|... a {{declarative}} {{programming language}} for dynamic <b>programming</b> <b>algorithms</b> ...|$|R
5000|$|<b>Programming,</b> <b>algorithms,</b> {{information}} technology, mathematics, analysis, probabilities, statistics, ...|$|R
40|$|International audienceNew cache-oblivious and cache-aware {{algorithms}} {{for simple}} dynamic programming based on Valiant's context-free language recognition algorithm are designed, implemented, analyzed, and empirically evaluated with timing studies and cache simulations. The {{studies show that}} for large inputs the cache-oblivious and cache-aware dynamic <b>programming</b> <b>algorithms</b> are significantly faster than the standard dynamic <b>programming</b> <b>algorithm...</b>|$|R
40|$|In [Zangwill, W. I. 1969. Convergence {{conditions}} for nonlinear <b>programming</b> <b>algorithms.</b> Management Sci. 16 (1, September). ] Zangwill states conditions which are necessary and sufficient for convergence of a nonlinear <b>programming</b> <b>algorithm.</b> However, the conditions offered merely comprise a restatement of Zangwill's definition of convergence, and, as such, their potential usefulness is limited. ...|$|R
40|$|This paper {{contributes}} to the rigorous understanding of genetic <b>programming</b> <b>algorithms</b> by providing runtime complexity analyses of the well-studied Max problem. Several experimental {{studies have indicated that}} it is hard to solve the Max problem with crossover-based algorithms. Our analyses show that different variants of the Max problem can provably be solved using simple mutation-based genetic <b>programming</b> <b>algorithms.</b> Our results advance the body of computational complexity analyses of genetic programming, indicate the importance of mutation in genetic programming, and reveal new insights into the behavior of mutation-based genetic <b>programming</b> <b>algorithms.</b> Timo Kötzing, Andrew M. Sutton, Frank Neumann and Una-May O'Reill...|$|R
50|$|The optimal {{encoding}} can {{be found}} using a dynamic <b>programming</b> <b>algorithm.</b>|$|R
40|$|This {{paper is}} {{a survey of}} dynamic <b>programming</b> <b>algorithms</b> for {{problems}} in computer science. For each of the problems the author derives the functional equations and provides numerous references to related results. For {{many of the problems}} a dynamic <b>programming</b> <b>algorithm</b> is explicitly given. In addition, the author presents several new problems and result...|$|R
5000|$|... "Viterbi path" [...] and [...] "Viterbi algorithm" [...] {{have become}} {{standard}} terms {{for the application}} of dynamic <b>programming</b> <b>algorithms</b> to maximization problems involving probabilities.For example, in statistical parsing a dynamic <b>programming</b> <b>algorithm</b> can be used to discover the single most likely context-free derivation (parse) of a string, which is commonly called the [...] "Viterbi parse".|$|R
40|$|To solve {{a problem}} with a dynamic <b>programming</b> <b>algorithm,</b> one must {{reformulate}} the problem such that its solution can be formed from solutions to overlapping subproblems. Because overlapping subproblems may not be apparent in the specification, it is desirable to obtain the algorithm directly from the specification. We describe a semi-automatic synthesizer of linear-time dynamic <b>programming</b> <b>algorithms.</b> The programmer supplies a declarative specification of the problem and the operators that might appear in the solution. The synthesizer obtains the algorithm by searching a space of candidate algorithms; internally, the search is implemented with constraint solving. The space of candidate algorithms is defined with a program template reusable across all lineartime dynamic <b>programming</b> <b>algorithms,</b> which we characterize as first-order recurrences. This paper focuses on how to write the template so that the constraint solving process scales to real-world linear-time dynamic <b>programming</b> <b>algorithms.</b> We show how to reduce the space with (i) symmetry reduction and (ii) domain knowledge of dynamic <b>programming</b> <b>algorithms.</b> We have synthesized algorithms for variants of maximal substring matching, an assembly-line optimization, and the extended Euclid algorithm. We have also synthesized a problem outside the class of first-order recurrences, by composing three instances of the algorithm template...|$|R
30|$|The {{model is}} solved by the {{well-known}} Integer Continuous Linear <b>Programming</b> <b>algorithm.</b>|$|R
50|$|Consists of {{projects}} that test computer <b>programs,</b> <b>algorithms,</b> computer languages, and hardware.|$|R
40|$|AbstractThe Bounded Set-up Knapsack Problem (BSKP) is a {{generalization}} of the Bounded Knapsack Problem (BKP), where each item type has a set-up weight and a set-up value that {{are included in}} the knapsack and the objective function value, respectively, if any copies of that item type are in the knapsack. This paper provides three dynamic <b>programming</b> <b>algorithms</b> that solve BSKP in pseudo-polynomial time and a fully polynomial-time approximation scheme (FPTAS). A key implication from these results is that the dynamic <b>programming</b> <b>algorithms</b> and the FPTAS can also be applied to BKP. One of the dynamic <b>programming</b> <b>algorithms</b> presented solves BKP with the same time and space bounds of the best known dynamic <b>programming</b> <b>algorithm</b> for BKP. Moreover, the FPTAS improves the worst-case time bound for obtaining approximate solutions to BKP as compared to using FPTASs designed for BKP or the 0 - 1 Knapsack Problem...|$|R
5000|$|Daniel A. Spielman and Shang-Hua Teng, for {{smoothed}} {{analysis of}} linear <b>programming</b> <b>algorithms.</b>|$|R
5000|$|... 8 <b>program</b> <b>algorithms,</b> 12 factory {{variations}} {{provide a}} selection of simulated ambient environments ...|$|R
40|$|A {{generalized}} dynamic <b>programming</b> based <b>algorithm</b> {{and a local}} search heuristic {{are used}} to solve the Two Runway Departure Scheduling Problem that arises at an airport. The objective of this work is to assign the departing aircraft {{to one of the}} runways and find a departing time for each aircraft so that the overall delay is minimized subject to the timing, safety, and the ordering constraints. A reduction in the overall delay of the departing aircraft at an airport can improve the airport surface operations and aircraft scheduling. The generalized dynamic <b>programming</b> <b>algorithm</b> is an exact algorithm, and it finds the optimal solution for the two runway scheduling problem. The performance of the generalized dynamic <b>programming</b> <b>algorithm</b> is assessed by comparing its running time with a published dynamic <b>programming</b> <b>algorithm</b> for the two runway scheduling problem. The results from the generalized dynamic <b>programming</b> <b>algorithm</b> show that this algorithm runs much faster than the dynamic <b>programming</b> <b>algorithm.</b> The local search heuristic with k ? exchange neighborhoods has a short running time in the order of seconds, and it finds an approximate solution. The performance of this heuristic is assessed based {{on the quality of the}} solution found by the heuristic and its running time. The results show that the solution found by the heuristic for a 25 aircraft problem has an average savings of approximately 15 percent in delays with respect to a first come-first served solution. Also, the solutions produced by a 3 -opt heuristic for a 25 aircraft scheduling problem has an average quality of 8 percent with respect to the optimal solution found by the generalized dynamic <b>programming</b> <b>algorithm.</b> The heuristic can be used for both real-time and fast-time simulations of airport surface operations, and it can also provide an upper limit for an exact algorithm. Aircraft arrival scheduling problems may also be addressed using the generalized dynamic <b>programming</b> <b>algorithm</b> and the local search heuristic with slight modification to the constraints...|$|R
40|$|Solving multiagent {{planning}} problems modeled as DEC-POMDPs is {{an important}} challenge. These models are often solved by using dynamic programming, but the high resource usage of current approaches results in limited scalability. To improve the efficiency of dynamic <b>programming</b> <b>algorithms,</b> we propose a new backup algorithm {{that is based on}} a reachability analysis of the state space. This method, which we call incremental policy generation, can be used to produce an optimal solution for any possible initial state or further scalability can be achieved by making use of a known start state. When incorporated into the optimal dynamic <b>programming</b> <b>algorithm,</b> our experiments show that planning horizon can be increased due to a marked reduction in resource consumption. This approach also fits nicely with approximate dynamic <b>programming</b> <b>algorithms.</b> To demonstrate this, we incorporate it into the state-of-the-art PBIP algorithm and show significant performance gains. The results suggest that the performance of other dynamic <b>programming</b> <b>algorithms</b> for DEC-POMDPs could be similarly improved by integrating the incremental policy generation approach...|$|R
40|$|We propose {{an optimal}} {{framework}} for active surface extraction from video sequences. An active surface {{is a collection}} of active contours in successive frames such that the active contours are constrained by spatial and temporal energy terms. The spatial energy terms impose constraints on the active contour in a given frame. The temporal energy terms relate the active contours in different frames to preserve desired internal and external properties of the active surface. For computational efficiency, we reduce the 3 -D active surface ((x, y, t) coordinates) optimization problem to a 2 -D model ((φ, t) coordinates) by considering only point indices along normal lines φ of each contour and define the energy terms in a causal way. We develop an n-D dynamic tree <b>programming</b> <b>algorithm</b> to find the optimum of n-D semi-causal functions. We prove that the n-D dynamic tree <b>programming</b> <b>algorithm</b> converges to the global optimum. In particular, the classical 1 -D dynamic <b>programming</b> <b>algorithm</b> is a special case of the n-D dynamic tree <b>programming</b> <b>algorithm.</b> The optimal active surface is subsequently obtained by using the 2 -D dynamic tree <b>programming</b> <b>algorithm.</b> Simulation results show the efficiency and robustness of the proposed approach in active surface extraction for video tracking and segmentation of the human head in real-world video sequences...|$|R
5000|$|BioShell is a {{threading}} algorithm using optimized profile-to-profile dynamic <b>programming</b> <b>algorithm</b> {{combined with}} predicted secondary structure.|$|R
5000|$|... (1) {{to study}} the methods for {{developing}} programs (specification methods, object-oriented design, structured <b>programming</b> <b>algorithms,</b> testing); ...|$|R
40|$|Rosenblatt and Kaspi (Rosenblatt, M. J., M. Kaspi. 1985. A dynamic <b>programming</b> <b>algorithm</b> {{for joint}} {{replenishment}} under general order cost functions. Management Sci. 31 (March) 369 - 373.) proposed a dynamic <b>programming</b> <b>algorithm</b> for determining joint ordering policies {{for a class}} of items with EOQ-like demands and holding costs and "general order cost functions. " Comments that follow by Queyranne and Quernheim and Bastian provide some counter-examples. ...|$|R
5000|$|The straightforward, {{recursive}} way {{of evaluating}} this recurrence takes exponential time. Therefore, {{it is usually}} computed using a dynamic <b>programming</b> <b>algorithm</b> that is commonly credited to Wagner and Fischer, although it {{has a history of}} multiple invention.After completion of the Wagner-Fischer algorithm, a minimal sequence of edit operations can be read off as a backtrace of the operations used during the dynamic <b>programming</b> <b>algorithm</b> starting at [...]|$|R
40|$|Title: Lot-sizing problem Author: Ondřej Kafka Department: Department of {{probability}} and mathematical statistics Supervisor: RNDr. Martin Branda, Ph. D. Abstract: In the present work, we define the basic concepts of lot-sizing. We introduce Wagner-Whitin's dynamic lot size problem and derive a dynamic <b>programming</b> <b>algorithm</b> for the solution. Next {{we look at}} the case of PCLSP (Profit maximizing capacitated lot size problem) problem with fixed prices and negligable setup costs and solve it using specialized linear <b>programming</b> <b>algorithm.</b> Everything we try to explain with concrete examples. In the end we verify the efficiency of those algorithms by numerical study on random data comparing the performance of <b>programmed</b> <b>algorithms</b> with the professional optimization solver Gurobi. Keywords: Lot-sizing, dynamic programming, linear programmin...|$|R
30|$|This {{problem can}} be solved in {{polynomial}} time by standard linear <b>programming</b> <b>algorithms</b> (Chen et al. 2001).|$|R
3000|$|The steps {{used by the}} {{stepwise}} quadratic <b>programming</b> <b>algorithm</b> {{proposed by}} Han (1977) are as follows: [...]...|$|R
30|$|In the following, {{additional}} notations {{and concepts}} are introduced {{that are needed}} to describe the dynamic <b>programming</b> <b>algorithm.</b>|$|R
50|$|There are {{algorithms}} {{that are}} more efficient than the O(n3) dynamic <b>programming</b> <b>algorithm,</b> though they are more complex.|$|R
30|$|The {{results of}} the greedy <b>algorithm,</b> dynamic <b>programming</b> <b>algorithm,</b> {{discrete}} bat algorithm {{as well as the}} optimal can be calculated for each set of data. We list the maximum request time that can be placed in an idle network sequence and list the mapping sequence based on the greedy <b>algorithm,</b> dynamic <b>programming</b> <b>algorithm,</b> discrete bat algorithm, and finally, list the ratio of maximum request time to optimal solution.|$|R
40|$|Approximate dynamic <b>programming</b> <b>algorithms,</b> such as {{approximate}} value iteration, {{have been successfully}} applied to many complex reinforcement learning tasks, and a better approximate dynamic <b>programming</b> <b>algorithm</b> is expected to further extend the applicability of reinforcement learning to various tasks. In this {{paper we propose a}} new, robust dynamic <b>programming</b> <b>algorithm</b> that unifies value iteration, advantage learning, and dynamic policy programming. We call it generalized value iteration (GVI) and its approximated version, approximate GVI (AGVI). We show AGVI's performance guarantee, which includes performance guarantees for existing algorithms, as special cases. We discuss theoretical weaknesses of existing algorithms, and explain the advantages of AGVI. Numerical experiments in a simple environment support theoretical arguments, and suggest that AGVI is a promising alternative to previous algorithms...|$|R
40|$|The {{rapid growth}} of new {{information}} services, especially like new media services, providing content distribution to clients with good quality of service(QoS) while retaining efficient is a great challenge. This paper investigates the QoS-aware replica placement problem (QRPP) for distributed caching system. We propose a dynamic <b>programming</b> <b>algorithm</b> for the problem in general graph, it first ensures the QoS requirement is satisfied of each request, then places the replica along the request forward path to minimize the total cost. The simulation results show the dynamic <b>programming</b> <b>algorithm</b> can achive a good balance between the access latency and the requested availability. When the request is more concentrated, the dynamic <b>programming</b> <b>algorithm</b> can have better performance than the MODULO and LRU both in access latency and requested availability...|$|R
50|$|In {{the second}} step, the optimal {{fractional}} solution can typically be computedin polynomial timeusing any standard linear <b>programming</b> <b>algorithm.</b>|$|R
