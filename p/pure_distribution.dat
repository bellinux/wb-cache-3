12|100|Public
50|$|British Lion Films {{is a film}} {{production}} and distribution company active under several forms since 1919. Originally known as British Lion Film Corporation Ltd, it went into receivership of 1 June 1954. From 29 January 1955 to 1976 the company was known as British Lion Films Ltd, and was a <b>pure</b> <b>distribution</b> company with a filmography of 232 films. As a production company, they are still active and have produced over 170 films.|$|E
50|$|For {{wholesalers}} too, {{real growth}} often came by increasing market share {{at the expense}} of another wholesaler, merging and acquiring other wholesalers and moving horizontally to handle other related products - air-conditioning wholesalers might expand into refrigeration and vice versa. As technology issues helped drive the merger of contractor, engineering and manufacturer associations in the 50s and 60s, <b>pure</b> <b>distribution</b> issues in the 90s helped inspire the consolidation of the two major HVACR wholesale trade groups- Northamerican Heating, Refrigeration & Airconditioning Wholesalers (NHRAW)' and Air-conditioning & Refrigeration Wholesalers International (ARWI).|$|E
50|$|After having begun as a <b>pure</b> <b>distribution</b> {{company in}} 1911, Ideal also began {{producing}} films in 1916. In 1917, the company acquired {{the first of}} the Elstree Studios in Borehamwood from the Neptune Film Company. During the silent era, the Ideal Film Company became one of the leading British production companies, benefiting from the post-First World War boom in films. However the company was badly hit by the Slump of 1924, and stopped its production, while the distribution arm continued. In 1927 the company was merged into the Gaumont British empire, where it continued to distribute under its own name until 1934.|$|E
40|$|Keywords:Fresnel diffraction; grating; {{fractional}} Talbot effect; array illumination; <b>pure</b> phase <b>distribution</b> Abstract:Our {{analysis is}} based on the <b>pure</b> phase <b>distribution</b> equations of the Fresnel diffraction of an amplitude grating. Suppose P and M are positive integers which have no common divisor and 1 /M is the opening ratio of the amplitude grating. Characteristics of the <b>pure</b> <b>distributions</b> are analysed. For instance at the fractional P/ 2 M Talbot distance and (1 -P/ 2 M) Talbot distance, the amplitudes of the Fresnel diffraction field of the grating are the same while the phases are opposite. As an example we design two Talbot illuminators which phase distributions occur respectively at the fractional P/ 2 M and (1 -P/ 2 M) Talbot distance. Both phase distribution can carry out illumination behind them. Array illumination has important application in information optics. I...|$|R
2500|$|Viewed as a <b>pure</b> {{probability}} <b>distribution,</b> the Bose–Einstein distribution {{has found}} application in other fields: ...|$|R
40|$|We present joint {{threshold}} and recoil resummed transverse momentum distributions for heavy quark hadroproduction, at next-to-leading logarithmic accuracy. We study {{the dependence of}} these distributions on the production channel, the color configurations and the differences with the <b>pure</b> threshold-resummed <b>distribution.</b> Comment: 14 pages, 7 figure...|$|R
5000|$|Thorlabs designs & {{manufactures}} {{products in}} the areas of breath analysis technology, fiber optics, lasers, optical instrumentation, optomechanics, photonics, and vibration isolation. [...] Approximately 90% of the products it sells are manufactured in-house. [...] "I see much greater value in a business that designs, manufactures and distributes, rather than a <b>pure</b> <b>distribution</b> model", Cable explained. [...] "the design process allows us to be an agile competitor, on price and also on innovating the product." [...] Roughly 30% of the products were created in response to, or inspired by, customer requests. [...] Customers include research institutions, manufacturers, and biomedical organizations. [...] Products are sold primarily through a print catalog.|$|E
40|$|Atomic force {{calculations}} {{within the}} variational and diffusion quantum Monte Carlo (VMC and DMC) methods are described. The advantages of calculating DMC {{forces with the}} "pure" rather than the "mixed" probability distribution are discussed. An accurate and practical method for calculating forces using the <b>pure</b> <b>distribution</b> is presented and tested for the SiH molecule. The statistics of force estimators are explored and violations of the Central Limit Theorem are found in some cases...|$|E
40|$|We {{face the}} problem of allocationg a fixed amount of a {{perfectly}} divisible good {{among a group of}} agents with single-peaked preferences. We survey the three different cases studied in the literature: the <b>pure</b> <b>distribution</b> case, the redistribution case, and the gerneral case. The so called general case provide with a natural framework to analyze the idea of path-independence. In this framework, we explore the existence of rules fulfilling this property. Our first result is negative: a strong version of this property cannot be fulfilled together with efficiency. Nonetheless, some restricted versions of the path-independence property are compatible with interesting properties, in particular no manipulability, and no envy. We then identify two solutions satisfying this sort of property: the equal distance rule, and a new extension of the uniform rule. Single-peaked preferences, allocation rules, path-independence, strategy-proofness, no envy...|$|E
40|$|The {{following}} problem {{arises in}} computer vision, diagnostic medical imaging and remote sensing: At each pixel in an image a vector of observations is measured. The distribution of these measurements is modeled by {{a mixture of}} certain <b>pure</b> class <b>distributions.</b> The goal is to estimate the mixing proportions of the classes by pixel in the image together with any unknown parameters in the <b>pure</b> class <b>distributions.</b> In many problems of this type {{it is appropriate to}} incorporate constraints on the mixing proportions. This paper deals with spatial smoothness constraints. An estimation methodology using penalized likelihood with multiple smoothing parameters is applied. Numerical methods for evaluating parameters in the model are developed. These methods make essential use of the Expectation Maximization formalism. A novel Monte Carlo importance sampling technique for approximating the effective degrees of freedom of the model is described. The methodology is illustrated wit...|$|R
3000|$|As {{mentioned}} in the Introduction, the tidally locked planets are identical except for their sea surface temperature <b>distributions.</b> The <b>pure</b> TLE SST <b>distribution</b> resembles the SST reported by Merlis and Schneider (2010) (Fig. 1 [...]...|$|R
50|$|R. Tomaschek Non-elastic tilt of the Earth's crust due to {{meteorological}} pressure <b>distributions,</b> <b>Pure</b> and Applied Geophysics Volume 25, Number 1, 17-25 (1953). The {{author was}} cited as {{being at the}} Anglo-Iranian Oil Co. Research Centre, Kirklington Hall, Nr. Newark Notts, Notts, UK.|$|R
40|$|This paper {{concerns}} lot-sizing in a multistage and multifacility <b>pure</b> <b>distribution</b> network. A {{facility at}} the end of the distribution network experiences a deterministic and continuous demand. Each facility has an echelon holding cost rate for each item it distributes, and a facility-dependent set up cost. In this paper an algorithm is presented of complexity 0 (rd log r) where r is the number of end facilities and d is the maximum depth of the distribution system. The algorithm exploits a lower bound obtained by decomposing the distribution network into facilities-in-series problems. Using a set up cost allocation procedure, the maximum of the continuous solution of the decomposed problem is obtained. This maximizing solution provides the lower bound which is used for solving the distribution problem. This gives a power-of-two heuristic with a worst case performance no more than 2 % above optimal. inventory, multi-stage, distribution, lower bound, heuristic...|$|E
40|$|Part 7 : Operations Planning, Scheduling and ControlInternational audienceAllocation of jobs to {{machines}} and subsequent sequencing each machine {{is known as}} job scheduling problem. Classically, both operations are done in a centralized and static/offline structure, considering some assumptions about the jobs and machining environment. Today, {{with the advent of}} Industry 4. 0, the need to incorporate real-time data in the scheduling decision process is clear and facilitated. Recently, several studies have been conducted on the collection and application of distributed data in real-time of operations, e. g., job scheduling and control. In practice, <b>pure</b> <b>distribution</b> and decentralization is not yet fully realizable because of e. g., transformation complexity and classical resistance to change. This paper studies a combination of decentralized sequencing and central optimum allocation in a lithography job-shop problem. It compares the level of applicability of two decentralized algorithms against the central scheduling. The results show better relative performance of sequencing in stochastic cases...|$|E
40|$|In {{this paper}} we discuss a {{periodic}} review control policy for general N-echelon distribution networks without batch size or capacity constraints. Only stockpoints {{at the end of the}} network are allowed to hold stock, whereas the intermediate stockpoints act as <b>pure</b> <b>distribution</b> centers that allocate incoming goods immediately to downstream stockpoints. Larger distribution networks (N = 3, 4, 5) are often encountered in practice and therefore suitable inventory management policies are needed. Instead of defining a cost structure, we apply a service level approach where the main goal is to realize predetermined target service levels in the final stockpoints. A fast and accurate approximation method is presented which enables us to compute the parameters of the control policy; i. e. the system order-up-to-level and the allocation fractions for the allocation policy at the intermediate stockpoints. Finally, some attention is given to the important phenomenon of imbalance, which is caused by highly fluctuating demand processes at the final stockpoints. This phenomenon can affect the service performance of the developed control policy significantly...|$|E
40|$|In {{this paper}} we use {{numerical}} simulations {{to calculate the}} particle yields. We demonstrate that in the model of local particle creation the deviation from the <b>pure</b> exponential <b>distribution</b> is natural even in equilibrium, and an approximate Tsallis-Pareto-like distribution function can be well fitted to the calculated yields, {{in accordance with the}} experimental observations. We present numerical simulations in classical Φ^ 4 model {{as well as in the}} SU(3) quantum Yang-Mills theory to clarify this issue. Comment: 8 pages, 12 figure...|$|R
40|$|In the PREDICT study, a {{randomised}} controlled trial comparing dexamethasone with prednisolone {{in patients}} with chronic inflammatory demyelinating polyradiculoneuropathy (CIDP), {{almost a quarter of}} patients deteriorated soon after starting treatment. The primary objective of this post-hoc analysis was to test the hypothesis that a focal demyelination pattern is associated with early deterioration after corticosteroid treatment and to explore whether various clinical characteristics are associated with deterioration after corticosteroid treatment. Clinical outcome was categorised into early deterioration and non-early deterioration. A neurophysiologist blinded for treatment outcome scored electrophysiological data into following categories: pure focal versus non-focal distribution of demyelination and no/minor versus moderate/severe sensory involvement. Additionally, we compared electrophysiological and clinical baseline parameters, with emphasis on previously reported possible associations. Early deterioration was found in 7 out of 33 patients (21 %). Ten patients had <b>pure</b> focal <b>distribution</b> of demyelination, of whom 5 had early deterioration; 23 patients had non-focal distribution, of whom 2 had early deterioration (p[*]=[*] 0. 02). Higher mean median nerve sensory nerve conduction velocity (SNCV) was found in patients with early deterioration compared to patients with non-early deterioration (52. 6 and respectively 40. 8 m/s, p[*]=[*] 0. 02). <b>Pure</b> focal <b>distribution</b> of demyelination and lesser sensory electrophysiological abnormalities may be associated with early deterioration in CIDP patients treated with corticosteroid...|$|R
40|$|We {{calibrate}} the X-ray imaging spectrometers, {{which are}} CCD cameras {{installed on the}} ASTRO-E satellite, by using dispersed continuous soft X-rays from a grating spectrometer. We obtained the signal-pulse height and energy-resolution {{as a function of}} X-ray energies continuously. However, the wings of the line spread function of the grating distorts the center of the signal-pulse height derived by a simple analysis. An estimation of this distortion is presented. We also describe two methods of extracting the <b>pure</b> signal-pulse-height <b>distribution</b> from the data using the spectrometer. A brie...|$|R
40|$|This paper {{considers}} {{the problem of}} allocating warehouse inventory to retailers where retailer orders and the replenishment of warehouse inventory occur periodically on a fixed schedule. We assume that the warehouse and the retailers have the opportunity oexchange demand information through Electronic Data Interchange (EDI). At the warehouse level, for instance, the available information on the retailer's demand may be utilized in determining the shipment quantities needed to meet the desired service level to the retailers. Unlike similar models focusing primarily on optimizing systems wide performance measures, {{in this paper we}} focus on the service level furnished to the retailers by the warehouse. To this end, three different allocation policies are considered: static, myopic, and dynamic rules characterizing the impact of available demand information on the resulting service levels. Numerical illustrations exemplify the allocation rules considered. An interesting though counter intuitive observation is that the existence of additional demand information cannot, a prior, be assumed superior. © 1997 Elsevier Science B. V. 1. Introduct ion This paper {{considers the}} problem of allocating warehouse inventory to retailers when retailer orders do not occur simultaneously, and the warehouse has the opportunity to exchange demand information through Electronic Data Interchange (EDI). We spec-ify the problem by assuming a <b>pure</b> <b>distribution</b> system in that transhipments between retailers and stock returns to the warehouse are disallowed. Fur-thermore, retailers may backorder any demand that cannot be satisfied. In this environment, we measure • Corresponding author...|$|E
40|$|This thesis {{analyses}} how the Distribution System Operator (DSO) {{enables the}} electricity market by enabling {{the implementation of}} smart grids. Two example cases of connecting small-scale production and demand response are examined. The DSO has {{a crucial role in}} making these functions possible by providing smart electricity meter that is capable of metering and delivering the values reliably on hourly bases. The material for this thesis was mainly collected from the 25 specialist interviews that were executed in Finland and in Sweden. The Nordic electricity market works relatively well and is considered to be an example for the other electricity markets around the world. Smart grids make it possible to improve the functioning even more. The main reason for the interest towards smart girds is that they are considered to be the key to achieve the European Union's environmental 20 - 20 - 20 objective. Smart grids create numerous possibilities to develop services and products around them. The roles of the market actors have to be considered carefully. Nevertheless, DSO's role will concentrate more to <b>pure</b> <b>distribution</b> of electricity and ensuring that the development is possible for the other parties. In this way DSO works as a platform and an enabler for the smart grids and this way to the whole electricity market. Developing the distribution network ready for smart grids DSOs need to be allowed to invest to the grid. /Kir 1...|$|E
50|$|A Frenkel defect, Frenkel pair, or Frenkel {{disorder}} {{is a type}} of point defect in a crystal lattice. The defect forms when an atom or smaller ion (usually cation) leaves its place in the lattice, creating a vacancy, and becomes an interstitial by lodging in a nearby location. Their prime mechanism of generation is by particle irradiation, as their equilibrium concentration according to the Boltzmann distribution is much smaller than the <b>pure</b> vacancies <b>distribution,</b> due to the large energy necessary for the creation of the associated interstitial atoms. The phenomenon is named after the Soviet physicist Yakov Frenkel, who discovered it in 1926.|$|R
40|$|Based on a Gaussian mixture {{model for}} the {{reflectivity}} sequence, we present a new technique for blind deconvolution of seismic data. The method obtains a deconvolution filter that maximizes at its output {{a measure of the}} relative entropy between the proposed Gaussian mixture and a <b>pure</b> Gaussian <b>distribution.</b> A new updating procedure for the mixture parameters is included in the algorithm: it allows us to apply the algorithm without any prior knowledge about the signal and noise. A simulation example illustrates the performance of the proposed method. Index Terms [...] -Deconvolution, estimation, iterative methods, seismology. I...|$|R
40|$|Abstract The {{effect of}} undersampling on {{estimating}} {{the size of}} extreme natural hazards from historical data is examined. Tests using synthetic catalogs indicate that the tail of an empirical size distribution sampled from a <b>pure</b> Pareto probability <b>distribution</b> can range from having one-to-several unusually large events to appearing depleted, relative to the parent distribution. Both of these effects are artifacts caused by limited catalog length. It {{is more difficult to}} diagnose the artificially depleted empirical distributions, since one expects that a <b>pure</b> Pareto <b>distribution</b> is physically limited in some way. Using maximum-like-lihood methods and the method of moments, we estimate the power-law exponent and the corner size parameter of tapered Pareto distributions for several natural hazard examples: tsunamis, floods, and earthquakes. Each of these examples has varying catalog lengths and measurement thresholds, relative to the largest event sizes. In many cases where there are only several orders of magnitude between the measurement threshold and the largest events, joint two-parameter estimation techniques are necessary to account for estimation dependence between the power-law scaling exponent and the corner size parameter. Results indicate that whereas the corner size parameter of a tapered Pareto distribution ca...|$|R
40|$|The mixed inverse Gaussian {{given by}} Whitmore (1986) {{provides}} a conve-nient way for testing {{the goodness of}} fit of a <b>pure</b> inverse Gaussian <b>distribution.</b> The test is a one-sided score test with the null hypothesis being the pure inverse Gaussian (i. e., the mixing parameter is zero) and the alternative a mixture. We devise a simple score test and study its finite sample properties. Monte Carlo results show that it compares favorably to the smooth test of Ducharme (2001). In practical applications, when the <b>pure</b> inverse Gaussian <b>distribution</b> is rejected, one is interested in making inference about the general values of the mixing parameter. However, as {{it is well known}} that the inverse Gaussian mix-ture is a defective distribution, hence the standard likelihood inference cannot be applied. We propose several alternatives and provide score tests for the mix-ing parameter. Finite sample properties of these tests are examined by Mont...|$|R
40|$|We {{calculate}} the scale dependence of nonsinglet nucleon structure functions. Due to anomalous axial symmetry breaking a large flavour asymmetry of the quark [...] antiquark sea is generated nonperturbatively. This produces a strong scale {{dependence of the}} nonsinglet structure function in an intermediate range of $Q^ 2 $. Evolving nonperturbatively a <b>pure</b> valence <b>distribution</b> from an infrared scale we can thus compute $F_ 2 ^p-F_ 2 ^n$ {{as measured by the}} NMC, and give detailed predictions for its $Q^ 2 $ dependence at fixed $x$. We also compare our results with Drell [...] Yan data. Comment: 13, harvmac 6 figures, CERN-TH. 7189 / 94 and DFTT 02 / 9...|$|R
40|$|Abstract. We {{calculate}} three jet {{cross sections}} in photoproduction using exact matrix elements for {{the direct and}} resolved contributions. Numerical distributions are presented in a generic, irreducible set of variables that allows to disentangle the dynamics of partonic QCD subprocesses {{from each other and}} from <b>pure</b> phase space <b>distributions.</b> The results are compared to preliminary data from the ZEUS collaboratio...|$|R
40|$|From the {{analysis}} of AGASA data above 4 × 10 ^ 19 eV, we show that the ultra-high energy cosmic rays flux is neither purely isotropic, nor reflects the expected anisotropy from a <b>pure</b> source <b>distribution</b> that maps large scale structure in the local universe. The arrival distribution {{seems to be the}} result of a mixture of fluxes (e. g., dark matter halo plus large scale structure) or the superposition of a direct and a diffuse radiation field components respectively. Another viable option is an arbitrary extragalactic flux reprocessed by a magnetized galactic wind model as recently proposed in the literature. Comment: Astrophysical Journal accepted (September 2000) - 16 pages - 5 figure...|$|R
40|$|We {{consider}} {{the design and}} potential benefits of peerassisted video-on-demand, in which participating peers assist the server in delivering VoD content. The assistance is done {{in such a way}} that it provides the same user quality experience as <b>pure</b> clientserver <b>distribution.</b> We focus on the single-video approach, whereby a peer only redistributes a video that it is currently watching. We first describe three natural prefetching policies for exploiting surplus peer upload capacity. We then study the performance of peer-assisted VoD using stochastic simulation and trace-driven simulation, with traces collected from the MSN Video service. The results of these simulations show that peer-assisted VoD, with the proper prefetching policy, can dramatically reduce server bandwidth costs...|$|R
40|$|We analyze {{data about}} the micro-blogging site Twitter using {{sentiment}} extraction techniques. From an information per-spective, Twitter users are involved mostly in two processes: information creation and subsequent <b>distribution</b> (tweeting), and <b>pure</b> information <b>distribution</b> (retweeting), with pro-nounced preference to the first. However a rather substantial fraction of tweets are retweeted. Here, we address {{the role of the}} sentiment expressed in tweets for their potential after-math. We find that although the overall sentiment (polarity) does not influence the probability of a tweet to be retweeted, a new measure called emotional divergence does have an im-pact. In general, tweets with high emotional diversity {{have a better chance of}} being retweeted, hence influencing the dis-tribution of information. ...|$|R
5000|$|The {{concept of}} magic numbers (in {{the field of}} chemistry) was first {{recognized}} by inspecting the intensity of mass-spectrometric signals of rare gas cluster ions. In case a gas condenses into clusters of atoms, the number of atoms in these clusters, that form most likely, varies between a few and hundreds. However, there are peaks at specific cluster sizes, deviating from a <b>pure</b> statistical <b>distribution.</b> Therefore, {{it was concluded that}} clusters of these specific numbers of rare gas atoms dominate due to their exceptional stability. The concept was also successfully applied to explain the monodispersed occurrence of [...] thiolate-protected gold clusters; here the outstanding stability of specific cluster sizes is connected with their respective electronic configuration.|$|R
40|$|Abstract. The {{bremsstrahlung}} emissivity and absorption coefficient, in the ra-diofrequencies range, {{are derived}} in {{the assumption that}} the electron population is not purely thermal, but presents a tail of high energy particles. This population is approximated by a bi-Maxwellian distribution. It is shown that, if the temper-ature ratio of the two Maxwellians is larger than 10, the absorption coefficient and the effective temperature depend only on the fraction R of particles in the highest temperature Maxwellian. The microwave radio spectrum is computed for some values of R, finding brightness temperatures lower than those computed with a <b>pure</b> thermal <b>distribution.</b> This fact could explain some inconsistencies found between radio and EUV observations. Key words. Emission and absorption coefficients, Non thermal particles 1...|$|R
40|$|Digital speckle three-shearing-aperture {{interferometry}} {{used for}} the measurement of curvature distribution fields of a deformation object is proposed for the first time. In this method, <b>pure</b> curvature <b>distribution</b> fringes without containing slope distribution fringes {{can be obtained by}} using digital speckle three-shearing-aperture interferometry. Two specklegrams, one before and the other after object deformation, are recorded by a CCD camera and stored in a computer. A 2 -D fast Fourier transform (FFT) and a 2 -D inverse FFT (IFFT) are performed on the two specklegrams. The subtraction of the transformed specklegrams will produce curvature distribution fringes, and the speckle noises in curvature distribution fringes can be removed after these fringes pass through low-pass filtering. Results from theory and experiments are in good agreement...|$|R
40|$|We {{propose a}} deep study on tissue {{modelization}} andclassification Techniques on T 1 -weighted MR images. Threeapproaches {{have been taken}} into account to perform thisvalidation study. Two of them are based on FiniteGaussian Mixture (FGM) model. The first one consists onlyin <b>pure</b> gaussian <b>distributions</b> (FGM-EM). The second oneuses a different model for partial volume (PV) (FGM-GA). The third one {{is based on a}} Hidden Markov Random Field(HMRF) model. All methods have been tested on a DigitalBrain Phantom image considered as the ground truth. Noiseand intensity non-uniformities have been added tosimulate real image conditions. Also the effect of ananisotropic filter is considered. Results demonstratethat methods relying in both intensity and spatialinformation are in general more robust to noise andinhomogeneities. However, in some cases there is nosignificant differences between all presented methods...|$|R
40|$|The {{investigation}} of the dissociation equilibrium of Nitroso-R-Salt (NRS) in aqueous micellar solution was determined spectrophotometrically at 25 °C and at the constant ionic strength I = 0. 1 M KNO 3. For this purpose, the effect of nonionic (Triton X- 100), cationic (CTAB), and anionic (SDS) surfactants on the absorption spectra of NRS at different pH values were studied. The acidity constants of all related equilibria are estimated using the whole spectral fitting of the collected data to an established factor analysis model. The computer program DATAN was used to extract the desired information from the spectral data. The outputs of the fitting processes were acidity constant, spectral profiles of <b>pure</b> forms, <b>distribution</b> diagrams and other factor analysis data. The effects of surfactant on acidity constant and pure spectrum of each component are discusse...|$|R
40|$|Properties of the nucleon twist- 3 {{distribution}} function e a (x) are reviewed. It is {{emphasized that the}} QCD equations of motion imply {{the existence of a}} δ-function at x = 0 in e a (x), which gives rise to the pion-nucleon sigma-term. According to the resulting “practical ” DIS sum rules the first and the second moment of e a (x) vanish, a situation analogue to that of the <b>pure</b> twist- 3 <b>distribution</b> function g 2 (x) ...|$|R
40|$|Using magnetomechanical damping experiments, we {{have studied}} the {{influence}} of various structural defects (dislocations, grain boundaries, interstitial carbon atoms and precipitated carbides) on the hysteretic behaviour of 90 ° magnetic domain walls (DW's) in <b>pure</b> iron. The <b>distribution</b> of internal local stresses and the shape factor of the magnetomechanical hysteresis cycle, as defined in the model of Smith and Birchak [1], have been examined. Their variations {{are linked to the}} modifications of density and arrangement of structural defects...|$|R
