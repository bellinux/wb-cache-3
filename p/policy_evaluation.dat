1831|1575|Public
5|$|In 1976 Lucas wrote a paper criticizing {{large-scale}} Keynesian models {{used for}} forecasting and <b>policy</b> <b>evaluation.</b> Lucas argued that economic models based on empirical relationships between variables are unstable as policies change: a relationship under one policy regime may be invalid after the regime changes. The Lucas's critique went further {{and argued that}} a policy's impact is determined by how the policy alters the expectations of economic agents. No model is stable unless it accounts for expectations and how expectations relate to policy. New classical economists argued that abandoning the disequilibrium models of Keynesianism and focusing on structure- and behavior-based equilibrium models would remedy these faults. Keynesian economists responded by building models with microfoundations grounded in stable theoretical relationships.|$|E
25|$|She {{has also}} been the {{recipient}} of numerous research grants for research in her areas of interest which include the role of public policies, unemployment, and immigration on labor markets and <b>policy</b> <b>evaluation</b> in developed and developing countries.|$|E
25|$|There {{has been}} some {{controversy}} over the relative strengths {{of different types of}} research. Because randomized trials provide clear, objective evidence on “what works”, policy makers often take only those studies into consideration. Some scholars have pushed for more random experiments in which teaching methods are randomly assigned to classes. In other disciplines concerned with human subjects, like biomedicine, psychology, and <b>policy</b> <b>evaluation,</b> controlled, randomized experiments remain the preferred method of evaluating treatments. Educational statisticians and some mathematics educators have been working to increase the use of randomized experiments to evaluate teaching methods. On the other hand, many scholars in educational schools have argued against increasing the number of randomized experiments, often because of philosophical objections, such as the ethical difficulty of randomly assigning students to various treatments when the effects of such treatments are not yet known to be effective, or the difficulty of assuring rigid control of the independent variable in fluid, real school settings.|$|E
40|$|Three {{issues for}} <b>evaluation</b> <b>policy</b> and {{practice}} are described: <b>evaluation</b> <b>policy</b> dimensions, <b>evaluation</b> <b>policy</b> instruments, {{and the political}} and economic environment for <b>evaluation</b> <b>policy.</b> Selected future directions are outlined, including the need to describe the <b>evaluation</b> <b>policy</b> landscape, further articulate an <b>evaluation</b> <b>policy</b> taxonomy, and develop and implement tactics for influencing <b>evaluation</b> <b>policy,</b> with particular attention to the role of professional associations...|$|R
40|$|Three {{issues for}} <b>evaluation</b> <b>policy</b> and {{practice}} are described: <b>evaluation</b> <b>policy</b> dimensions, <b>evaluation</b> <b>policy</b> instruments, {{and the political}} and economic environment for <b>evaluation</b> <b>policy.</b> Selected future directions are outlined, including the need to describe the <b>evaluation</b> <b>policy</b> landscape, further articulate an <b>evaluation</b> <b>policy</b> taxonomy, and develop and implement tactics for influencing <b>evaluation</b> <b>policy,</b> with particular attention to the role of professional associations. © Wiley Periodicals, Inc. If the context of evaluation practice is largely defined by <b>evaluation</b> <b>policies,</b> then <b>evaluation</b> <b>policy</b> gives us a way to think about systematically influencing that context. Through policy, such principles as technical quality, respect for people, and utility can be explicitly and systematically built into the evaluation expectations of an organization rather than being values we fight for, one evaluation at a time. Of course, it is never this simple (Julnes & Rog, 2007). To be a player in the world of <b>evaluation</b> <b>policy</b> making, we need to develop a language for communicating about types o...|$|R
40|$|This brief {{sets out}} {{the case for}} making public <b>policy</b> <b>evaluations</b> public. It first reviews the various {{challenges}} associated with impact evaluations, paying {{particular attention to the}} unique hurdles involved in evaluating Indigenous policy. Lessons learned from clinical trials registries in medical research are then used to argue that Australian economic and social <b>policy</b> <b>evaluations</b> could be improved by making them public...|$|R
2500|$|RCTs are {{currently}} being used {{by a number of}} international development experts to measure the impact of development interventions worldwide. [...] Development economists at research organizations including Abdul Latif Jameel Poverty Action Lab (J-PAL) and Innovations for Poverty Action have used RCTs to measure the effectiveness of poverty, health, and education programs in the developing world. While RCTs can be useful in <b>policy</b> <b>evaluation,</b> it is necessary to exercise care in interpreting the results in social science settings. For example, interventions can inadvertently induce socioeconomic and behavioral changes that can confound the relationships (Bhargava, 2008).|$|E
2500|$|Dr. Adriana Kugler is Vice-Provost for Faculty {{and a full}} {{professor}} at the McCourt School of Public Policy. [...] She was founder and co-director of the International Summer Institute on <b>Policy</b> <b>Evaluation</b> between 2010-2013. She served as chief economist of the U.S. Department of Labor in 2011 and 2012, where she worked actively on developing policies and proposals on unemployment insurance, training programs, retirement benefits, overtime pay and minimum wages, immigration, disability insurance and occupational safety regulations. Prior to coming to Georgetown, she was a full and {{associate professor at the}} economics departments at the University of Houston [...] and at Pompeu Fabra University [...] in Barcelona.|$|E
2500|$|These {{predictions}} may not {{be feasible}} {{when some of the}} variables are unobserved, as in most <b>policy</b> <b>evaluation</b> problems. The effect of the action [...] can still be predicted, however, whenever a criterion called [...] "back-door" [...] is satisfied. It states that, if a set Z of nodes can be observed that d-separates (or blocks) all back-door paths from X to Y then [...] A back-door path is one that ends with an arrow into X. Sets that satisfy the back-door criterion are called [...] "sufficient" [...] or [...] "admissible." [...] For example, the set Z=R is admissible for predicting the effect of S=T on G, because R d-separate the (only) back-door path S←R→G. However, if S is not observed, there is no other set that d-separates this path and the effect of turning the sprinkler on (S=T) on the grass (G) cannot be predicted from passive observations. We then say that P(G|do(S=T)) is not [...] "identified." [...] This reflects the fact that, lacking interventional data, we cannot determine if the observed dependence between S and G is due to a causal connection or is spurious ...|$|E
50|$|Methods - Gathering facts, analysis, and <b>policy</b> <b>evaluations</b> {{whenever}} {{possible with the}} cooperation from other institutions scholars.|$|R
5000|$|... 2011, [...] "Conventions for Measuring and Questioning Policies. The Case of 50 Years of <b>Policies</b> <b>Evaluations</b> {{through a}} Statistical Survey", Historical Social Research, 36(4).|$|R
40|$|Environmental <b>policy</b> <b>evaluations</b> are a {{relatively}} recent phenomenon in Flanders. Environmental impact reports (MER) and regulatory impact analyses (RIA) are legal obligations for projects and policy measures with a potentially important impact on the environment. To obtain meaningful results from these environmental <b>policy</b> <b>evaluations,</b> {{it is important to}} work in a systematic way. The ten steps we describe in this article offer a general framework that can be implemented for different categories of environmental problems. Every step is illustrated for the Flemish afforestation policy. ...|$|R
5000|$|... #Subtitle level 2: Intergenerational {{equity in}} <b>policy</b> <b>evaluation</b> ...|$|E
50|$|Section 11: Foreign <b>Policy</b> <b>Evaluation</b> under Senior Specialist Dr Kurzbach.|$|E
5000|$|The Center for Science and Technology <b>Policy</b> <b>Evaluation</b> and Research ...|$|E
40|$|We report three {{additional}} mediation analyses below. Similar {{to the analysis}} reported in the main text, all mediation analyses use policy type (stick vs. carrot policy) as the independent variable and <b>policy</b> <b>evaluations</b> as the dependent variable, and implement a bootstrapping procedure with 5, 000 replications. The three analyses use the following mediators: (i) negative company attitudes towards overweight participants, (ii) positive company attitudes towards healthy-weight participants, and (iii) a difference score between the two measures (reflecting the relative amount of information conveyed about overweight vs. healthy-weight employees). Before turning to the meditation analyses, we first report the basic pairwise associations between all measures and <b>policy</b> <b>evaluations.</b> As shown in the correlation matrix displayed in Table S 1, we find a reliable relationship between <b>policy</b> <b>evaluations</b> {{and all of the}} inferential items except for positive company attitudes towards the overweight. That is, participants who viewed a policy as speaking primarily to overweight participants, or who viewed the policy as communicating negative information to overweight employees, also tended to evaluate that policy negatively (all |rs | ≥. 45, ps <. 001). Inferences about positive attitudes towards healthy-weight employees, on the other hand, were not correlated with <b>policy</b> <b>evaluations</b> (r =. 09, p =. 34) ...|$|R
40|$|The author {{develops}} {{the basic idea}} of <b>evaluation</b> <b>policy,</b> describes a practical model for development and revision of <b>evaluation</b> <b>policies</b> (including a taxonomy, structure, and set of principles), and suggests critical challenges and opportunities {{for the future of}} <b>evaluation</b> <b>policy.</b> An <b>evaluation</b> <b>policy</b> is any rule or principle that a group or organization uses to guide its decisions and actions when doing evaluation. Every entity that engages in evaluation, including government agencies, private businesses, and nonprofit organizations, has <b>evaluation</b> <b>policies.</b> Sometimes they are explicit and written; more often they are implicit and ad hoc principles or norms that have simply evolved over time...|$|R
40|$|<b>Evaluation</b> <b>policy</b> is of {{considerable}} importance, especially {{in relation to}} the limited amount of attention it receives as a general topic in the mainstream <b>evaluation</b> literature. <b>Evaluation</b> <b>policies</b> matter for several reasons, among them that they can profoundly affect evaluation practice, they underlie many recent and current controversies about evaluation, and they may be a lever for change that can have far-reaching effects for practice. This chapter gives an overview of several issues regarding <b>evaluation</b> <b>policy,</b> including defining it, identifying possible facets of <b>evaluation</b> <b>policy,</b> describing how it is established, and outlining the potentially greater role for evaluators in shaping the <b>evaluation</b> <b>policies</b> that influence <b>evaluation</b> practice...|$|R
5000|$|Local {{transport}} planning <b>policy</b> <b>evaluation</b> for the Department for Transport ...|$|E
5000|$|... 2010.12 ~ 2011.12 Adviser to the Prosecutor <b>Policy</b> <b>Evaluation</b> Committee ...|$|E
5000|$|... from Investments and Loans Evaluation and Statistics Team to <b>Policy</b> <b>Evaluation</b> and Statistics Bureau ...|$|E
5000|$|This section {{adopts a}} “human {{resource}} strategy” that makes provisions for the training, recruitment, hiring priority, employment, employment support systems (including discrimination <b>policies),</b> <b>evaluation</b> {{of the human}} resource strategy by the Raglan committee, and finally the provision for alternative employment upon permanent closing of the mine. 3) Inuit Enterprises ...|$|R
40|$|Program {{evaluation}} plays {{a significant}} role in aiding our understanding of the effectiveness of interventions. Evaluations operate under the auspices of <b>evaluation</b> <b>policies,</b> which shape aspects of evaluation design including research questions, data collection and analysis procedures, and reporting of findings. Despite considerable speculation about the influence that <b>evaluation</b> <b>policy</b> has over <b>evaluation</b> practice, we do not yet have any empirical evidence to support these ideas. Through document analysis, interviews, and an instrumental multiple case study, this study examines both the explicit and implicit policies that overarch the research and evaluation work commissioned by the Robert Wood Johnson Foundation (RWJF), the nation's largest philanthropy devoted to our public health. The primary objectives of the current study were to: 1) detail and describe RWJF's <b>evaluation</b> <b>policies</b> (including their development and communication to relevant parties); and 2) describe how the implementation of those <b>evaluation</b> <b>policies</b> happens in the field. Findings suggest the existence of two main policy distinctions [...] policies that are goal statements (which describe the desired outcomes of evaluation activities) and operationalized policies (which describe the specific processes that take place during the course of evaluations). This dichotomy serves as the basis for an argument that <b>evaluation</b> <b>policies</b> function as a system, rather than existing in silos as previously described in the extant literature. Furthermore, this study sheds light on the ways <b>evaluation</b> <b>policies</b> relate to organizational and shared learning within the Foundation. Finally, it is argued that the development of specific and directed policies to promote innovation are a necessary step to take to advance <b>evaluation</b> practice. <b>Evaluation</b> <b>policy</b> {{is one of the most}} critical issues facing the field of evaluation today. This study was designed to shed light on a Foundation's <b>evaluation</b> <b>policies</b> in an effort to draw connections about how <b>evaluation</b> <b>policies</b> influence <b>evaluation</b> practice. The investigation helped further understanding of these connections, and generated some insight into the components of <b>evaluation</b> <b>policies,</b> and the role they might play in shaping the future of evaluation practice...|$|R
40|$|Agricultural {{economists have}} often {{attempted}} {{to estimate the}} parameters of behavioral equations which derive from economic theory, such as demand, supply, and investment functions These estimates {{were thought to be}} useful {{for a wide range of}} problems: analysis of proposed <b>policies,</b> <b>evaluation</b> of existing <b>policies,</b> forecasting, and improved understanding of the economy...|$|R
5000|$|Desk reviews {{involving}} legislative analysis, {{case law}} reviews, <b>policy</b> <b>evaluation,</b> gap analyses, and needs assessments; ...|$|E
5000|$|Scientometrics, {{bibliometrics}} and economics: {{science and}} <b>policy</b> <b>evaluation,</b> data mining and information extraction, knowledge discovery.|$|E
5000|$|Research Institute for <b>Policy</b> <b>Evaluation</b> and Design: Interdisciplinary {{research}} {{with a focus}} on Southeast Asia ...|$|E
40|$|Reinforcement {{learning}} {{based on}} direct search in policy space requires few {{assumptions about the}} environment. Hence it is applicable in certain situations where most traditional reinforcement learning algorithms are not, especially in partially observable, deterministic worlds. In realistic settings, however, reliable <b>policy</b> <b>evaluations</b> are complicated by numerous sources of uncertainty, such as stochasticity in policy and environment. Given a limited life-time, how much time should a direct policy searcher spend on <b>policy</b> <b>evaluations</b> to obtain reliable statistics? Our efficient approach based on the success-story algorithm (SSA) is radical {{in the sense that}} it never stops evaluating any previous policy modification except those it undoes for lack of empirical evidence that they have contributed to lifelong reward accelerations. While previous experimental research has already demonstrated SSA's applicability to large-scale partially observable environments, a study of why it performs [...] ...|$|R
40|$|The paper {{develops}} a methodology for the <b>evaluation</b> of competition <b>policy.</b> Based {{on the existing}} literature and experiences with <b>policy</b> <b>evaluations</b> {{in other areas of}} economic activity, the three-step / nine-building-blocks methodology provides guidance for evaluation projects and also assists in the identification of avenues for further academic research. [...] Competition Policy,Evaluation,Merger control,Cartel enforcement...|$|R
40|$|We {{show that}} the {{capability}} approach can greatly facilitate ex ante <b>policy</b> <b>evaluations,</b> in particular those that are geared towards multiple goals. It enables a structured discussion on policy benefits, distributional issues, freedom and ethics. We illustrate our general ideas with a real-world application: the impact assessment of an EU-proposal on organ donation. Capability approach Organ donation...|$|R
50|$|According to {{the bulk}} of {{literature}} describing IFPRI-Progresa, the project was the first large-scale social <b>policy</b> <b>evaluation</b> implemented in a ‘developing’ country context to use randomized controlled trial (RCT) research design. In the perennial debates surrounding the RCT {{as a tool of}} social <b>policy</b> <b>evaluation</b> IFPRI-Progresa provided (and continues to provide) an important proof-of-concept, an example exalted by proponents and held aloft before critics.|$|E
5000|$|Financial Systems in Developing Economies: Growth, Inequality, Poverty and <b>Policy</b> <b>Evaluation</b> in Thailand (Oxford University Press, 2008)[...]|$|E
5000|$|Lindblom, Charles E.; Braybrooke, David (1963), A {{strategy}} of decision: <b>policy</b> <b>evaluation</b> {{as a social}} process. Free Press.|$|E
40|$|Most applied welfare {{analyses}} for environmental <b>policy</b> <b>evaluations,</b> whether benefit-cost or natural resource damage assessments, rely on adaptations of existing benefit estimates {{in what is}} described as benefits transfer rather than new research. Almost 10 years ago, David Brookshire organized a set of papers in Water Resources Research {{to focus attention on}} the practice of benefi...|$|R
40|$|Science-Metrix {{specializes in}} the {{measurement}} and evaluation of science, technology and innovation. Our data collection and assessment methods include bibliometrics, scientometrics, technometrics, surveys and interviews, environmnetal scans, monitoring and intelligence gathering. We perform program and <b>policy</b> <b>evaluations,</b> benchmarking and sector analyses, market studies and strategic planning. Science-Metrix has a robust knowledge of life and environmental sciences...|$|R
40|$|How does {{regeneration}} affect {{health and}} how have successive urban <b>policy</b> <b>evaluations</b> sought to measure such impacts? This article draws on a systematic review of national-level evaluation documentation relating to government-funded, area-based regeneration initiatives in the UK since 1980. The review examined whether health impacts had been intended and, if so, {{how they had}} been measured. The process and difficulties of conducting the review raise significant questions about <b>policy</b> formulation and <b>evaluation.</b> Is evidence-based <b>policy</b> possible where <b>evaluations</b> are not stored centrally? In short, a model policy development as 'enlightened' or incremental is hard to sustain where a lack of systematic storage of data means that researchers, policy makers and practitioners may struggle to produce clear answers to important policy questions...|$|R
