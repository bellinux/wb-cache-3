0|53|Public
40|$|We {{present a}} new method and {{architecture}} to merge efficiently IEEE 754 - 2008 decimal rounding with sig-nificand BCD addition and subtraction. This {{is a key}} component to improve several decimal floating-point operations such as addition, multiplication and fused multiply-add. The decimal rounding unit {{is based on a}} direct implementation of the IEEE 754 - 2008 round-ing modes. We show that the resultant implementations for IEEE 754 - 2008 Decimal 64 (16 <b>precision</b> <b>digits)</b> and Decimal 128 (34 <b>precision</b> <b>digits)</b> formats reduce signifi-cantly the area and latency required for significand BCD addition/subtraction and decimal rounding in previous high-performance decimal floating-point adders. 1...|$|R
25|$|It {{is often}} used for {{currency}} conversions and price roundings (when the amount is first converted into the smallest significant subdivision of the currency, such as cents of a euro) as {{it is easy to}} explain by just considering the first fractional digit, independently of supplementary <b>precision</b> <b>digits</b> or sign of the amount (for strict equivalence between the paying and recipient of the amount).|$|R
50|$|For {{tables with}} greater <b>precision</b> (more <b>digits</b> per value), higher order {{interpolation}} {{may be needed}} to get full accuracy. In the era before electronic computers, interpolating table data in this manner was the only practical way to get high accuracy values of mathematical functions needed for applications such as navigation, astronomy and surveying.|$|R
2500|$|... for [...] and [...] are {{for example}} [...] [...] Where the same {{calculation}} {{is done with}} single <b>digit</b> <b>precision,</b> the result would normally be [...] But , ...|$|R
40|$|When {{grasping}} rectangular or circular {{objects with}} a <b>precision</b> grip the <b>digits</b> {{close in on}} the object in opposite directions. In doing so the digits move perpendicular to the local surface orientation as they approach {{opposite sides of the}} object. This perpendicular approach is advantageous for accurately placing the digits. Trapezoidal objects have non-parallel surfaces so that moving the digits in opposite directions would make the digits approach the contact surfaces at an angle that is not 90 °. In this study we examined whether this happens, or whether subjects tend to approach trapezoidal objects' surfaces perpendicularly. We used objects of different sizes and with different surface slants. Subjects tended to approach the object's surfaces orthogonally, suggesting that they aim for an optimal <b>precision</b> of <b>digit</b> placement rather than simply closing their hand as it reaches the object. © 2007 Springer-Verlag...|$|R
50|$|The 11 {{bit width}} of the {{exponent}} allows the representation of numbers between 10−308 and 10308, with full 15-17 decimal <b>digits</b> <b>precision.</b> By compromising precision, the subnormal representation allows even smaller values up to about 5 × 10−324.|$|R
30|$|In {{order to}} assess the {{accuracy}} of block pulse function method for solving higher-order differential equations with multi-point boundary conditions we will consider the following examples. The associated computations with the examples were performed using MAPLE  17 with 64 <b>digits</b> <b>precision</b> on a personal computer.|$|R
5000|$|... (C99) - {{minimum number}} of decimal digits such that any number of the widest {{supported}} floating-point type can be represented in decimal with a <b>precision</b> of [...] <b>digits</b> and read back in the original floating-point type without changing its value. [...] is at least 10.|$|R
5000|$|... {{showed how}} to find further {{extensions}} of this type, [...] and [...] proposed improved algorithms, and finally the most efficient algorithm was proposed by [...] Quadruple <b>precision</b> (34 decimal <b>digits)</b> coefficients for (G7, K15), (G10, K21), (G15,K31), (G20,K41) and others are computed and tabulated.|$|R
40|$|The fast Lyapunov {{indicators}} are functions defined on the tangent fiber of the phase-space of a discrete (or continuous) dynamical system {{by using a}} finite number of iterations of the dynamics. In the last decade, they have been largely used in numerical computations to localize the resonances in the phase-space and, more recently, also the stable and unstable manifolds of normally hyperbolic invariant manifolds. In this paper, we provide an analytic description of the growth of tangent vectors for orbits with initial conditions which are close to the stable-unstable manifolds of hyperbolic saddle points. The representation explains why the fast Lyapunov indicator detects the stable-unstable manifolds of all fixed points which satisfy a certain condition. If the condition is not satisfied, a suitably modified fast Lyapunov indicator can be still used to detect the stable-unstable manifolds. The new method allows for a detection of the manifolds with a number of <b>precision</b> <b>digits</b> which increases linearly with respect to the integration time. We illustrate the method on the critical problems of detection of the so-called tube manifolds of the Lyapunov orbits of L 1, L 2 in the planar circular restricted three-body problem; detection of the Lorenz manifold; detection of the stable manifold of a saddle equilibrium point for two strongly coupled pendula...|$|R
50|$|Excel {{works with}} a {{modified}} 1985 version of the IEEE 754 specification. Excel's implementation involves conversions between binary and decimal representations, leading to accuracy that is on average better than one would expect from simple fifteen <b>digit</b> <b>precision,</b> but that can be worse. See the main article for details.|$|R
5000|$|In Windows 98 and later, it uses an arbitrary-precision {{arithmetic}} library, {{replacing the}} standard IEEE floating point library. It offers bignum precision for basic operations (addition, subtraction, multiplication, division) and 32 <b>digits</b> of <b>precision</b> (128 bits internally actual <b>precision,</b> 38.5 <b>digits,</b> {{which can be}} verified by calculating a square root on the calc and a more precise product, or doing the same calculation two different ways) for advanced operations (square root, transcendental functions). The largest value that can be represented on the Windows Calculator is currently <1010,000 and the smallest is 10−9,999. (Also ! calculates factorial function not just factorial so one can get 4.7! [...] ).|$|R
2500|$|For ease of {{presentation}} and understanding, decimal radix with 7 <b>digit</b> <b>precision</b> {{will be used}} in the examples, as in the IEEE 754 decimal32 format. [...] The fundamental principles are the same in any radix or precision, except that normalization is optional (it does not affect the numerical value of the result). [...] Here, s denotes the significand and e denotes the exponent.|$|R
50|$|Presanella {{may have}} first been climbed by {{surveyors}} in 1854. Eduard Pechmann's 1865 Notizen zur Höhen- und Profilkarte has Presanella's height with two <b>digits</b> <b>precision</b> (1878.26 Viennese Klaster or 3,562.1 m), {{which in this}} list indicated that a measurement {{was taken from the}} summit during the trigonometric survey, which for Presanella was done in 1854. This possible ascent is otherwise unrecorded.|$|R
5000|$|However, the Leibniz formula {{can be used}} to {{calculate}} [...] to high <b>precision</b> (hundreds of <b>digits</b> or more) using various convergence acceleration techniques. For example, the Shanks transformation, Euler transform or Van Wijngaarden transformation, which are general methods for alternating series, can be applied effectively to the partial sums of the Leibniz series. Further, combining terms pairwise gives the non-alternating series ...|$|R
40|$|A {{principle}} constraint with {{constructing a}} Planck unit {{theory is that}} the Planck units are limited to the precision of G and so to 4 -digits which in turn limits the usefulness of Planck theories. By postulating the sqrt of Planck momentum Q as a link between mass and charge, we can formulate the above primary constants as geometrical shapes and then define them in terms of the 4 most accurate constants c (exact), permeability of vacuum µ 0 (exact), Rydberg constant (12 <b>digit</b> <b>precision)</b> and the fine structure constant alpha α (10 <b>digit</b> <b>precision)</b> giving us solutions to the Planck units whose precision is limited only by the precision of alpha. A resultant Planck unit theory emerges which suggests that particles are dimensionless formulas dictating the frequency of Planck events via a periodic (analog) electric wave-state to digital (integer) Planck-time-mass point-state oscillation. The dimensions of our universe then reduce to the 3 units (dimensions) of motion; Planck momentum, Planck time and velocity c. ...|$|R
40|$|Most {{quantitative}} mathematical problems {{cannot be}} solved exactly, {{but there are}} powerful algorithms for solving many of them numerically to a specified degree of <b>precision</b> like ten <b>digits</b> or ten thousand. In this article three difficult problems of this kind are presented, and {{the story is told}} of the SIAM 100 -Dollar, 100 -Digit Challenge. The twists and turns along the way illustrate some of the flavor of algorithmic continuous mathematics...|$|R
5000|$|The {{first product}} was a [...] "four-function" [...] {{calculator}} that could add, subtract, multiply, and divide. The display was only eight digits, but the calculations were performed with 16 <b>digits</b> <b>precision.</b> The MITS Model 816 calculator kit was {{featured on the}} November 1971 cover of Popular Electronics. The kit sold for $179 and an assembled unit was $275. Unlike the previous kits that MITS had offered, thousands of calculator orders came in each month.|$|R
40|$|We {{obtain an}} {{analytical}} expression for the Next-to-Next-to-Leading {{order of the}} Balitsky-Fadin-Kuraev-Lipatov (BFKL) Pomeron eigenvalue in planar SYM N= 4 using Quantum Spectral Curve (QSC) integrability based method. The result is verified with more than 60 <b>digits</b> <b>precision</b> using the numerical method developed by us in a previous paper. As a byproduct we developed a general analytic method of solving the QSC perturbatively. Comment: 6 pages; v 2 : typos fixed, references and supplementary Mathematica files adde...|$|R
40|$|The {{validity}} of the standard model of physics, even in extreme environments, can be tested by high precision measurements of values that are predicted by theory. For a single 28 Si 13 + ion, stored for several months in a Penning trap, the magnetic moment of the electron bound to the nucleus was measured to 11 <b>digits</b> <b>precision,</b> confirming the corresponding calculations. This constitutes to date the most stringent test of quantum electrodynamics of bound states...|$|R
50|$|This gives from 15 to 17 {{significant}} decimal <b>digits</b> <b>precision.</b> If a decimal string with at most 15 significant digits {{is converted}} to IEEE 754 double-precision representation, and then converted back to a decimal string with {{the same number of}} digits, the final result should match the original string. If an IEEE 754 double-precision number {{is converted to}} a decimal string with at least 17 significant digits, and then converted back to double-precision representation, the final result must match the original number.|$|R
40|$|It is {{well known}} that the {{computation}} of accurate trajectories of the Lorenz system is a difficult problem. Computed solutions are very sensitive to the discretization error determined by the time step size and polynomial order of the method, as well as round-off errors. In this work, we show how round-off errors limit the computability of the Lorenz system and quantify exactly the length of intervals over which solutions can be computed, expressed in terms of the floating point precision. Using adjoint-based a posteriori error analysis techniques, we estimate the stability of computations with respect to initial data, discretization, and round-off errors, respectively. The analysis is verified by computing an accurate solution on the time interval [0, 1000] using a very high order (order 200) finite element method and very high floating point <b>precision</b> 400 <b>digits).</b> Comment: Proceedings of "International conference on Adaptive Modeling and Simulation (ADMOS) 2013...|$|R
50|$|In {{order to}} achieve a {{substantial}} speed up, a shorter floating point number format has been applied, one that is close to single precision IEEE 754-1985, consisting of 1-byte exponent and 3-byte fraction (effectively 7 decimal <b>digits</b> <b>precision).</b> The original Sinclair BASIC utilizes 1-byte exponent and 4-byte fraction. All floating point arithmetic routines have been rewritten, including basic operations like addition, multiplication, division and functions like square root, logarithm, exponent. A unique algorithm has been developed for the calculation of trigonometric functions. Line drawing, circle drawing and other graphics functions have also been written.|$|R
5000|$|To work {{effectively}} in a real-life implementation, intervals must {{be compatible with}} floating point computing. The earlier operations were based on exact arithmetic, but in general fast numerical solution methods may not be available. The range of values of the function for [...] and [...] are for example [...] Where the same calculation is done with single <b>digit</b> <b>precision,</b> the result would normally be [...] But ,so this approach would contradict {{the basic principles of}} interval arithmetic, {{as a part of the}} domain of [...] would be lost.Instead, the outward rounded solution [...] is used.|$|R
50|$|Despite their {{practical}} popularity, finite difference formulas {{like the}} above {{two have been}} harshly criticized by some researchers, in particular by proponents of automatic differentiation because their simplicity must be set against {{the fact that their}} accuracy is low - in rough terms, calculations in six <b>digit</b> <b>precision</b> will produce a slope of only three-digit precision whereas evaluating a function that calculates the slope may still deliver nearly six-digit precision. For example, given f(x) = x2, calculating the slope from 2x will give near full precision, whereas the finite difference approximation will have difficulties as described below.|$|R
5|$|In {{laboratory}} conditions, {{the interactions}} of individual electrons can be observed by means of particle detectors, which allow measurement of specific properties such as energy, spin and charge. The development of the Paul trap and Penning trap allows charged particles to be contained within a small region for long durations. This enables precise measurements of the particle properties. For example, in one instance a Penning trap was used to contain a single electron {{for a period of}} 10 months. The magnetic moment of the electron was measured to a <b>precision</b> of eleven <b>digits,</b> which, in 1980, was a greater accuracy than for any other physical constant.|$|R
40|$|We {{report on}} Fourier {{spectroscopy}} experiments performed with near-surface nitrogen-vacancy centers in a diamond chip. By detecting the free precession of nuclear spins rather than applying a multipulse quantum sensing protocol, {{we are able}} to unambiguously identify the NMR species devoid of harmonics. We further show that by engineering different Hamiltonians during free precession, the hyperfine coupling parameters as well as the nuclear Larmor frequency can be selectively measured with high <b>precision</b> (here 5 <b>digits).</b> The protocols can be combined to demonstrate two-dimensional Fourier spectroscopy. The technique will be useful for mapping nuclear coordinates in molecules en route to imaging their atomic structure. Comment: 5 pages, 5 figure...|$|R
40|$|ISBN: 0818689633 International audienceThe authors {{deal with}} the {{detailed}} VLSI implementation of a fast bit-serial operator designed to perform very high <b>precision</b> (600 decimal <b>digits)</b> additions, multiplications, and divisions, {{and some of the}} applications of the circuit are discussed. Online arithmetic needs carry-free redundant number systems. Frequently, the radix chosen is different from 2, since a carry-free addition algorithm can be used in radix r not= 2. In radix 2, carry-free addition is possible, but with two inconveniences: the algorithm seems more complicated, and the delay is larger. The authors show that the first inconvenience vanishes if good binary representation of the digits in radix- 2 signed digit notation is chosen...|$|R
50|$|In {{laboratory}} conditions, {{the interactions}} of individual electrons can be observed by means of particle detectors, which allow measurement of specific properties such as energy, spin and charge. The development of the Paul trap and Penning trap allows charged particles to be contained within a small region for long durations. This enables precise measurements of the particle properties. For example, in one instance a Penning trap was used to contain a single electron {{for a period of}} 10 months. The magnetic moment of the electron was measured to a <b>precision</b> of eleven <b>digits,</b> which, in 1980, was a greater accuracy than for any other physical constant.|$|R
5000|$|The above re-expression of a size-N DFT as two size-N/2 DFTs is {{sometimes}} called the Danielson-Lanczos lemma, since the identity was noted by those two authors in 1942 (influenced by Runge's 1903 work). They applied their lemma in a [...] "backwards" [...] recursive fashion, repeatedly doubling the DFT size until the transform spectrum converged (although they apparently didn't realize the linearithmic order N asymptotic complexity they had achieved). The Danielson-Lanczos work predated widespread availability of computers and required hand calculation (possibly with mechanical aids such as adding machines); they reported a computation time of 140 minutes for a size-64 DFT operating on real inputs to 3-5 significant digits. Cooley and Tukey's 1965 paper reported a running time of 0.02 minutes for a size-2048 complex DFT on an IBM 7094 (probably in 36-bit single <b>precision,</b> ~8 <b>digits).</b> [...] Rescaling the time {{by the number of}} operations, this corresponds roughly to a speedup factor of around 800,000. (To put the time for the hand calculation in perspective, 140 minutes for size 64 corresponds to an average of at most 16 seconds per floating-point operation, around 20% of which are multiplications.) ...|$|R
40|$|In {{this paper}} {{we present a}} C# 4. 0 high {{precision}} framework for simulation of relativistic many-body systems. In order to benefit from, previously developed, chaos analysis instruments, all new modules were designed to be integrated with Chaos Many-Body Engine [1, 3]. As a direct application, we used 46 <b>digits</b> <b>precision</b> for analyzing the Butterfly Effect of the gravitational force in a specific relativistic nuclear collision toy-model. Trying to investigate the average Lyapunov Exponent dependency on the incident momentum, an interesting case of intermittency was noticed. Based on the same framework, other high-precision simulations are currently in progress (e. g. study {{on the possibility of}} considering, hard to detect, extremely low frequency photons as one of the dark matter components) ...|$|R
40|$|Numerical {{simulations}} of dynamical systems often rely inexplicitely on {{the hypothesis that}} the simulated pseudo-trajectory represents a true trajectory of the system in the sense that both the pseudo-trajectory and the true trajectory stay close to each other for arbitra-rily long time. This is guaranteed to hold for hyperbolic systems by the shadowing lemma (Anosov 1967, Bowen 1975). However, {{this is not the case}} in general. Virtually, all real systems which physicists encounter, are nonhyperbolic, and in most systems the shado-wing property does not hold. Dynamical systems with unstable dimension variability have recently gained interest as a source both of nonhyperbolicity and nonshadowability. Some recent publications[7] claim that the nonshadowability due to unstable dimension variability is particularly severe. In this work for a very simple dynamical system driven by one out of three input systems is investigated. Numerical evidence is presented, that all the combined systems are prac-tically unshadowable due to the same mechanism, although only two of them can have unstable dimension variability, the third being a quasiperiodic map which has no periodic orbits. In order to show numerically for the first and second input system that both singly and doubly unstable periodic orbits are embedded into the attractor, a new method is applied to one of the systems to show that the attractor fills a region of the phase space densely. This method consists of iterating particular lines which are known to be subsets of the attractor instead of points and consecutively applying a Poincaré surface-of-section-like technique. For one of the studied maps this can reduce the dimensionality of the system by one. For the three model systems, the probability distribution of the shadowing times is inve-stigated through simulation. Additionally, a new deterministic measure to quantify the severeness of nonshadowability due to unstable dimension variability is introduced and applied to the model systems. This quantity estimates by how many <b>digits</b> the calculus <b>precision</b> has to exceed the required closeness to a true trajectory on average for a given trajectory length. It is argued and verified numerically that for the case of unstable dimen-sion variability the number of additionally needed calculus <b>precision</b> <b>digits</b> is proportional to the logarithm of the trajectory length. Thereby even pseudo-trajectories with arbitrarily small one step errors cannot be shadowed by true trajectories for arbitrarily long time. The nonshadowability can however in the same time be rigorous and very small, so that for some practical purposes this system can be regarded as almost shadowable. On the other hand, the same mechanism can produce similar results for systems where unstable dimension variability does not occur. In those systems there is an upper limit to the addi-tionally needed calculus precision. This limit can be so large that for practical purposes this system behaves as a nonshadowable one although it is shadowable in the sense of the shadowing lemma...|$|R
40|$|The {{shape of}} a target object could {{influence}} maximum grip aperture in human grasping movements in several different ways. Maximum grip aperture could {{be influenced by the}} required <b>precision</b> of <b>digit</b> placement, by the aim to avoid colliding with the wrong parts of the target objects, by the mass of the target objects, or by (mis) judging the width or the volume of the target objects. To examine the influence of these five factors, we asked subjects to grasp five differently shaped target objects with the same maximal width, height and depth and compared their maximum grip aperture with what one would expect for each of the five factors. The five target objects, a cube, a three-dimensional plus sign, a rectangular block, a cylinder and a sphere, were all grasped with the same final grip aperture. The experimentally observed maximum grip apertures correlated poorly with the maximum grip apertures that were expected {{on the basis of the}} required precision, the actual mass, the perceived width and the perceived volume. They correlated much better with the maximum grip apertures that were expected on the basis of avoiding unintended collisions with the target object. We propose that the influence of target object shape on maximum grip aperture might primarily be the result of the need to avoid colliding with the wrong parts of the target object...|$|R
40|$|The second-order {{extended}} stability Factorized Runge-Kutta-Chebyshev (FRKC 2) {{class of}} explicit schemes for {{the integration of}} large systems of PDEs with diffusive terms is presented. FRKC 2 schemes are straightforward to implement through ordered sequences of forward Euler steps with complex stepsizes, and easily parallelised for large scale problems on distributed architectures. Preserving 7 digits for accuracy at 16 <b>digit</b> <b>precision,</b> the schemes are theoretically capable of maintaining internal stability at acceleration factors in excess of 6000 with respect to standard explicit Runge-Kutta methods. The stability domains have approximately the same extents as those of RKC schemes, and are a third longer than those of RKL 2 schemes. Extension of FRKC methods to fourth-order, by both complex splitting and Butcher composition techniques, is discussed. A publicly available implementation of the FRKC 2 class of schemes may be obtained from maths. dit. ie/frk...|$|R
500|$|A key {{tool that}} enabled the {{practical}} use of logarithms before calculators and computers was {{the table of}} logarithms. The first such table was compiled by Henry Briggs in 1617, immediately after Napier's invention. Subsequently, tables with increasing scope were written. These tables listed the values of [...] and [...] for any number x in a certain range, at a certain precision, for a certain base b (usually [...] ). For example, Briggs' first table contained the common logarithms of all integers in the range 1–1000, with a <b>precision</b> of 14 <b>digits.</b> As the function [...] is the inverse function of logb'x, it {{has been called the}} antilogarithm. The product and quotient of two positive numbers c and d were routinely calculated as the sum and difference of their logarithms. The product cd or quotient c/d came from looking up the antilogarithm of the sum or difference, also via the same table: ...|$|R
40|$|In formal {{analogy with}} Gutzwiller's semiclassical trace formula, {{the density of}} zeros of the Riemann zeta {{function}} zeta(z= 1 / 2 -iw) can be written as a non-convergent series rho(w) =-pi^{- 1 } sum_p sum_{m= 1 }^infty ln(p) p^{-m/ 2 } cos(wm ln(p)) with p running over the prime numbers. We obtain zeros and poles of the zeta function by harmonic inversion of the time signal which is a Fourier transform of rho(w). More than 2500 zeros have been calculated to about 12 <b>digit</b> <b>precision</b> as eigenvalues of small matrices using the method of filter-diagonalization. Due to formal analogy of the zeta function with Gutzwiller's periodic orbit trace formula, the method {{can be applied to}} the latter to accurately calculate individual semiclassical eigenenergies and resonance poles for classically chaotic systems. The periodic orbit quantization is demonstrated on the three disk scattering system as a physical example...|$|R
