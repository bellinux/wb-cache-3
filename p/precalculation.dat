82|14|Public
50|$|<b>Precalculation</b> of aggregates, complex {{calculations}} {{and application of}} complex business logic may {{be done in a}} staging area to support highly responsive service level agreements (SLAs) for summary reporting in target systems.|$|E
50|$|Several {{attacks and}} {{attempts}} at cryptanalysis of E0 and the Bluetooth protocol have been made, {{and a number}} of vulnerabilities have been found.In 1999, Miia Hermelin and Kaisa Nyberg showed that E0 could be broken in 264 operations (instead of 2128), if 264 bits of output are known. This type of attack was subsequently improved by Kishan Chand Gupta and Palash Sarkar. Scott Fluhrer, a Cisco Systems employee, found a theoretical attack with a 280 operations <b>precalculation</b> and a key search complexity of about 265 operations. He deduced that the maximal security of E0 is equivalent to that provided by 65-bit keys, and that longer keys do not improve security. Fluhrer's attack is an improvement upon earlier work by Golic, Bagini and Morgari, who devised a 270 operations attack on E0.|$|E
3000|$|The channel {{preprocessing}} {{is about}} the <b>precalculation</b> of equalization coefficient matrices from the estimated channel matrix [...]...|$|E
3000|$|... values during {{read-out}} {{and taking}} care of the padding. This leads to a relatively large number of scalar <b>precalculations,</b> causing a lower efficiency.|$|R
40|$|GF (2 m). ???????? ??????????? ??????????????? ??????? ? ???????????? ???????????? ??????????? ??????????????, ??? ???????????? ???? ???? ???. ???????? ????????? ????????????? ?????????? ????????? ??????????????, ???????? ????????. ??????????, ?? ?? ?????????? ????????? ?????????? ?????? ?? ????? ????? GF (2 m). ????????, ?? ????????????? ?????????? O(m) ?????????? ??????? ??????? ????? ?? ?????????? ??????? ????????, ??? ????????? O(m?). In article {{the method}} of {{accelerated}} calculation of square root on Galois fields GF (2 m) has been proposed. The main feature of proposed method is using results of <b>precalculations</b> many times, which are calculated only once. The technology of executing of <b>precalculations</b> is given in details, examples are given. It is researched how proposed technology accelerates calculation of square root on Galois fields GF (2 m). It is proved, that calculation complexity O(m) of proposed method is much smaller then complexity of known methods, which equals O(m?) ...|$|R
30|$|Gonzalez et al. use the {{hierarchy}} of roads for partitioning the network into areas and make <b>precalculations</b> of shortest path in these areas (Gonzalez et al. 2007). This approach uses {{the fact that some}} roads are more traveled than others and drivers usually use the largest roads.|$|R
40|$|A {{neural network}} {{structure}} {{has been developed}} which is capable of solving deterministic job-shop scheduling problems, part of the large class of np-complete problems. The problem was translated in an integer linear programming format which facilatated translation in an adequate neural network structure. Use of the presented structure eliminated the need for integer adjustments. Elementary <b>precalculation</b> is performed with the objective to reduce the search space allowing more rapid calculation of feasible solutions. In this <b>precalculation</b> the earliest possible starting times of the operations are calculated and set as tresholds in the network. The neural network structure was reliable in simulated operation and its performance was superior to structures which have been presented previously. The network structure always produces feasible solutions, in less time, without the application of integer adjustments...|$|E
40|$|Main aim {{of these}} work was analyse the idle {{potential}} of the rural tourism in the region. After analysis propose the possibilities of development for specific potential. For this product was needed to implement questionary investigation, whether exist raely interest to its. Then <b>precalculation</b> was worked, whether the company might function...|$|E
40|$|A {{new method}} for {{computation}} of gas cooling for Lagrange approach is suggested. The method {{is based on}} <b>precalculation</b> of cooling law for known cooling function. Unlike implicit methods, this method is very efficient, it is an one-step method which is even more accurate than implicit methods of the same order. Comment: submitted to JCompPhys, 5 pages, 1 figur...|$|E
30|$|Bast et al. define an {{approach}} based on relevant nodes (transit nodes) for long-distance travel (Bast et al. 2007). It consists of making <b>precalculations</b> of shortest path between all pairs of transit nodes and from each potential source or destination to its access transit nodes. This approach needs an effective notion of “far away” and the optimal results are guaranteed {{depending on the}} local filter selected.|$|R
40|$|RSA {{encryption}} {{and digital}} signature algorithm is considered secure if keys are 1024 - 4096 bits long. Since it requires modular exponentiation on numbers of this length, embedded systems need either a cryptographic co-processor or a fast CPU to calculate ciphertexts and signatures. In many applications, the sender is resource-scare, so optimization is necessary. In our paper we show {{a method for}} <b>precalculations</b> that accelerates the real-time performance of the sender in the expense of additional calculations at the receiver. When completed, the receiver gets an RSA-equivalent ciphertext for the encryption algorithm...|$|R
40|$|The EPS stage, {{the second}} upper {{stage of the}} Ariane 5 {{launcher}}, was tested in the launcher test stand in Lampoldshausen, Germany {{during the second half}} of 1994. The <b>precalculations</b> of its structural dynamic behaviour revealed the possibility of the occurrence of severe so-called POGO vibrations. In order to monitor and control the occurrence of these unstable variations, a so-called "red-line" system was developed based on modal data. Structural identification tests were performed by DLR to acquire a reliable data basis for POGO risk control. The tests comprised frequency response functions and free decay measurements. This report describes the test performance, data evaluation, and test results...|$|R
40|$|Sea wave {{behavior}} calculations {{require the}} <b>precalculation</b> of wave elements {{as well as}} consideration of the spectral functions of ocean wave formation. The spectrum of the random wave process is largely determined by the distribution {{of energy in the}} actual wind waves observed {{on the surface of the}} sea as expressed in statistical and spectral characteristics of the sea swell...|$|E
40|$|Wireless Sensor Networks (WSNs) {{have been}} a growing {{research}} domain during {{the past couple of}} years. One of the most challenging tasks of WSN research is still location estimation. As a well performing fine grained localization approach, Distributed Least Squares (DLS) was introduced, splitting the localization process in a complex global <b>precalculation</b> and a simple local postcalculation. Nevertheless, as size of <b>precalculation</b> and cost of computation and communication are increasing with the WSN dimensions, it was shown that this algorithm is unsuitable for large ones. This constraint has been overcome by scalable DLS (sDLS). Further, the computational costs of sDLS have been improved by using sDLSne. Unfortunately, sDLSne comes along with decreased localization accuracy and thus represents a tradeoff. The presented hybrid solution combines sDLSne with various coarse grained localization techniques to avoid this drawback. The resulting localization accuracy overcomes the efficient sDLSne approach as well as the more precise sDLS approach, while computational costs still outperforms sDLS. ...|$|E
40|$|Namen te naloge je prilagoditi obstoječo metodo predračunavanja, da bo le-ta obnavljajoča. Za ta namen je bila izbrana analiza praga pokritja, ki je predstavljena v prvem delu naloge in v nadaljevanju postopoma spremenjena. Spremembe izhajajo iz zahtev predračuna, opisanih v prvem delu naloge. Prilagoditev izbrane metode je bila preverjena s teoretičnim primerom in nato uporabljena na primeru projekta, za katerega smo določili potek sprememb v proizvodnji. The {{purpose of}} this thesis is to adapt an {{existing}} <b>precalculation</b> method {{for it to be}} recurring. For this purpose, we have chosen the break-even method, which is presented {{in the first part of}} the thesis, and subsequently gradually changed. The changes originate from the <b>precalculation</b> requirements, described in the first part of the thesis. The adaptation of the selected method has been done with a theoretical example and then used on an example project for which we have determined the course of changes in production...|$|E
40|$|Determining early {{specular}} reflection paths {{is essential for}} room acoustics modeling. Beam tracing algorithms {{have been used to}} calculate these paths efficiently, thus allowing modeling of acoustics in real-time with a moving listener in simple, or complex but densely occluded, environments with a stationary sound source. In this paper it is shown that beam tracing algorithms can still be optimized by utilizing the spatial coherence in path validation with a moving listener. Since the <b>precalculations</b> required for the presented technique are relatively fast, the acoustic reflection paths can be calculated even for a moving source in simple cases. Simulations were performed to show how the accelerated algorithm compares with the basic algorithm with varying scene complexity and occlusion. Up to two orders of magnitude speed-up was achieved. Key words: beam tracing PACS: 43. 55. Ka, 43. 58. Ta...|$|R
40|$|A {{computer}} application that renders a virtual environment, for example an architectural model {{for use in}} a walkthrough scenario, can suffer from low performance due to the complexity of the environment. Visibility algorithms are concerned with determining the part of the environment that is visible and therefore necessary to render while discarding the rest, thereby reducing the workload of the graphics hardware. One group of visibility algorithms is concerned with determining which objects are blocked from view by other objects; this is called occlusion culling. Occlusion culling can be applied to for example the interiors of buildings or the contents of containers. In this thesis, the general prob-lem of visibility in three-dimensional scenes will be presented as well as algorithms that attempt to solve it, especially methods to perform occlusion culling and in particular algo-rithms that perform occlusion culling online, without significant <b>precalculations.</b> Among these, several algorithms that take advantage of a recently developed graphics hardware extension will be described in detail, implemented and their performance and complexity analyzed...|$|R
40|$|In {{order to}} improve a miner's {{operational}} reliability and to lower its loss risk, the flexible hose's form {{as well as its}} behaviour have been theoretically and experimentally examined and the loads caused by the flexible hose and acting on the ship and on the miner have been determined. A flexible hose with lifting floats (system 'garland') is proposed as most favourable solution. This system provides that given a great cruising range of the miner the forces acting on the suspension points are very low. Though, due to the lifting floats which have to be attached, there are additional handling problems to cope with. For the test purpose a deep sea crawler was provided and during the vehicle's initial operation its electric, electronic and hydraulic components have been examined under water with regard to their safe function under deep sea pressure conditions. All components have been tested one by one as well as part of the whole system. Also relating to the operational reliability, tests for determining the vehicle's inner running resistance have been conducted. Inner and outer running resistance in combination with the sensoric monitoring are the basic elements of a monitoring system which allows to determine respectively avoid critical operations states for the purpose of <b>precalculations.</b> (orig.) SIGLEAvailable from TIB Hannover: F 95 B 612 +a / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekBundesministerium fuer Forschung und Technologie (BMFT), Bonn (Germany) DEGerman...|$|R
40|$|Abstract: Wireless Sensor Networks (WSNs) {{have been}} a growing {{research}} domain during {{the past couple of}} years. One of the most challenging tasks of WSN research is still location estimation. As a well performing fine grained localization approach, Distributed Least Squares (DLS) was introduced, splitting the localization process in a complex global <b>precalculation</b> and a simple local postcalculation. Nevertheless, as size of <b>precalculation</b> and cost of computation and communication are increasing with the WSN dimensions, it was shown that this algorithm is unsuitable for large ones. This constraint has been overcome by scalable DLS (sDLS). Further, the computational costs of sDLS have been improved by using sDLS ne. Unfortunately, sDLS ne comes along with decreased localization accuracy and thus represents a tradeoff. The presented hybrid solution combines sDLS ne with various coarse grained localization techniques to avoid this drawback. The resulting localization accuracy overcomes the efficient sDLS ne approach as well as the more precise sDLS approach, while computational costs still outperforms sDLS. Copyright © 2011 IFSA...|$|E
40|$|Calculation of {{transfer}} {{prices of the}} individual performance means the calculation {{of the price of}} a product, service, work or other kind, expressed unit of output. Kind is usually expressed in the unit such as hours, kolograms, etc. The transfer price is a toll that is used for performance appraisals for the centers but is also used for other awards such as repair services, etc. This price is determined on the basis of <b>precalculation.</b> In the <b>precalculation</b> are listed the estimated cost of the product and the calculation shall be drawn up before the start of production, repectively {{at the beginning of the}} period. Individual performance is generally defined as the results of operations and as an external performance and internal performance. External performance are services such as goods, services or goods that are sold to consumers in the market at market prices. Internal performance are those services that are transmitted in particular within the enterprise between departments...|$|E
40|$|Abstract — An online posture {{modification}} method termed Jacobi Compensation {{is proposed}} which is suitable to modify precalculated step trajectories for a humanoid robot in certain task coordinate directions. This method {{can account for}} modeling errors in trajectory <b>precalculation</b> by shifting e. g. the center of mass (CoM) or {{certain parts of the}} humanoid mechanism to increase walking stability and performance. A theoretical analysis of stability properties is given. I...|$|E
40|$|Simulating hydrodynamics {{can require}} {{extensive}} calculations which becomes {{a problem when}} doing interactive simulations. This thesis investigates an efficient method for hydrodynamic simulations {{with the effects of}} buoyancy, drag, lift and added mass that is implementedand tested with the help of AgX Dynamics using triangulated meshes. For buoyancy, drag and lift a method of numerical integration over triangles was used to calculate the forces and torques acting on each triangle of a mesh. For added mass {{a large part of the}} calculations could be done before the simulation starts using a Boundary Element Method (BEM). The final value for the added mass was calculated each time step based on how the object was submerged. The method of triangle integration produced results that were close to the analytical values with a certain mesh dependence. The results had an increasing accuracy when the mesh had a more exact representation of the object. The drag and lift coefficients could however be better adjusted. The added mass results also had a mesh dependence, but with accuracy increasing with number of triangles even for shapes that already had an exact representation, e. g. a cube. For a fully submerged sphere with 4900 triangles the maximum error for the added mass was 0. 65 %. The time required for <b>precalculations</b> using BEM had a rapid growth with increasing number of triangles due to the factorization of a dense matrix that has a complexity of O(n 3). For the hydrodynamic calculations done each time step the time requirement increased linearly with number of triangles...|$|R
40|$|With {{the advent}} of {{reliable}} positioning technologies and prevalence of location-based services, it is now feasible to accurately study the propagation of items such as infectious viruses, sensitive information pieces, and malwares through a population of moving objects, e. g., individuals, mobile devices, and vehicles. In such application scenarios, an item passes between two objects when the objects are sufficiently close (i. e., when they are, so-called, in contact), and hence once an item is initiated, it can penetrate the object population through the evolving network of contacts among objects, termed contact network. In this paper, {{for the first time}} we define and study reachability queries in large (i. e., disk-resident) contact datasets which record the movement of a (potentially large) set of objects moving in a spatial environment over an extended time period. A reachability query verifies whether two objects are "reachable" through the evolving contact network represented by such contact datasets. We propose two contact-dataset indexes that enable efficient evaluation of such queries despite the potentially humongous size of the contact datasets. With the first index, termed ReachGrid, at the query time only a small necessary portion of the contact network which is required for reachability evaluation is constructed and traversed. With the second approach, termed ReachGraph, we precompute reachability at different scales and leverage these <b>precalculations</b> at the query time for efficient query processing. We optimize the placement of both indexes on disk to enable efficient index traversal during query processing. We study the pros and cons of our proposed approaches by performing extensive experiments with both real and synthetic data. Based on our experimental results, our proposed approaches outperform existing reachability query processing techniques in contact n [...] . [truncated]. Comment: VLDB 201...|$|R
40|$|Call {{admission}} control {{is one of}} the key elements in ensuring the quality of serivce in mobile wireless networks. The traditional trunk reservation policy and its numerous variants give preferential treatment to the handoff calls over new arrivals by reserving a number of radio channels exclusively for handoffs. Such schemes, however, cannot adapt to changes in traffic pattern due to the static nature. This paper introduces a novel stable dynamic call {{admission control}} mechanism (SDCA), which can maximize the radio channel utilization subject to a predetermined bound on the call dropping probability. The novelties of the proposed mechanism are: 1) it is adaptive to wide range of system parameters and traffic conditions due to its dynamic nature, 2) the control is stable under overloading traffic conditions, thus can effectively deal with sudden traffic surges; 3) the admission policy is stochastic, thus spreading new arrivals evenly over a control period, and resulting in more effective and accurate control; an 4) the model takes into account the effects of limited channel capacity and time dependence on the call dropping probability, and the influences from nearest and next-nearest neighboring cells, which greatly improve the control precision. In addition, we introduce local control algorithms based on strictly local estimations of the needed traffic parameters, without requiring the status information exchange among different cells, which makes it very appealing in actual implementation. Most of the computational complexities lie in off-line <b>precalculations,</b> except for the nonlinear equation of the acceptance ratio, in which a coarse-grain numerical integration is shown to be sufficient for stochastic control. Extensive simulation results show that our scheme steadily satisfies the hard constraint on call dropping probability while maintaining a high channel throughput...|$|R
40|$|Abstract: It {{is shown}} that the 13 C-NMR {{chemical}} shifts of carbon atoms in substituted sixmembered heteroaromatic compounds correlate with the correponding "additivity parameters" for substituted benzene derivatives. Thus, for <b>precalculation</b> of chemical shifts in such compounds, just one set of parameters can be used. The differences between experimental chemical shifts and those calculated from correlation with the common set may provide insights into intramolecular interactions not reported in the literature...|$|E
40|$|In {{this paper}} we present an {{algorithmic}} framework for spec-tral separation of multispectral images. The proposed itera-tive method inverts the widely used cellular Yule-Nielsen spectral Neugebauer printer model {{so quickly that}} model inversion {{can be considered for}} pixel-by-pixel application. Simplification and <b>precalculation</b> make improvements and small modifications of the algorithm significantly reduce the computational effort. Using to-day’s available standard hardware allows the separation of high resolution multispectral images in reasonable time...|$|E
40|$|System-level {{investigations}} {{are crucial to}} determine the per-formance of transmission strategies on network level. In this paper we derive a novel link measurement model for the eval-uation of Alamouti encoded transmissions. Our model allows for the <b>precalculation</b> of so-called fading parameters which are real valued scalars, thus effectively reducing the compu-tational complexity in system level simulations. Finally, we present fading simulations based on our model and discuss the basic performance characteristics of the transmission scheme. 1...|$|E
40|$|Abstract—Call {{admission}} control {{is one of}} the key elements in ensuring the quality of serivce in mobile wireless networks. The traditional trunk reservation policy and its numerous variants give preferential treatment to the handoff calls over new arrivals by reserving a number of radio channels exclusively for handoffs. Such schemes, however, cannot adapt to changes in traffic pattern due to the static nature. This paper introduces a novel stable dynamic call {{admission control}} mechanism (SDCA), which can maximize the radio channel utilization subject to a predetermined bound on the call dropping probability. The novelties of the proposed mechanism are: 1) it is adaptive to wide range of system parameters and traffic conditions due to its dynamic nature; 2) the control is stable under overloading traffic conditions, thus can effectively deal with sudden traffic surges; 3) the admission policy is stochastic, thus spreading new arrivals evenly over a control period, and resulting in more effective and accurate control; and 4) the model takes into account the effects of limited channel capacity and time dependence on the call dropping probability, and the influences from nearest and next-nearest neighboring cells, which greatly improve the control precision. In addition, we introduce local control algorithms based on strictly local estimations of the needed traffic parameters, without requiring the status information exchange among different cells, which makes it very appealing in actual implementation. Most of the computational complexities lie in off-line <b>precalculations,</b> except for the nonlinear equation of the acceptance ratio, in which a coarse-grain numerical integration is shown to be sufficient for stochastic control. Extensive simulation results show that our scheme steadily satisfies the hard constraint on call dropping probability while maintaining a high channel throughput. Index Terms—Call admission control, mobile wireless networks, QoS guarantee. I...|$|R
3000|$|Limitations {{and future}} areas of {{research}} The limitations of our model point {{to a variety of}} future {{areas of research}}. We follow the general literature on shelf-space management and assume a deterministic and stationary demand for the tactical problem. Because of this, demand is always satisfied. Hence, one area is to further generalize the demand modeling. Some authors argue that demand volatility can be handled with exogenously determined safety stocks. The resulting shelf space for the safety stock needs to be deducted from the total shelf space and only the remaining space can be distributed. However, our modeling approach has the advantage of being flexible enough to determine safety stocks endogenously. As safety stocks protect against uncertainty in demand (demand volatility) and supply (lead time volatility), the impact of both decision variables (i.e., the impact of the number of facings on the demand and the impact of the order frequency on supply) need to be taken into account. Hence, for all precalculated combinations of the decisions variables, one can calculate the safety stocks accordingly within the model. Furthermore, our model and solution approach is a good starting point to account for further demand effects. Focusing on demand volatility would imply the development of a stochastic model for our decision problem with replenishment costs to account for demand variations (cf. e.g., Hübner and Schaal 2016 a). In such cases, out-of-stock substitutions resulting from potentially insufficient shelf and backroom quantities for specific items would need to be taken into consideration as well (cf. e.g., Kök and Fisher 2007; Hübner et al. 2016). A stochastic model would need to balance the trade-offs between understock and overstock situations, which is specifically relevant in the case of perishable items. These additional costs can be included in the <b>precalculations.</b> Apart from stochastic demand, further demand effects, such as item positioning (cf. e.g., Lim et al. 2004; Bianchi-Aguiar et al. 2015 b) or cross-space elasticities (cf. e.g., Corstjens and Doyle 1981), would be worth considering when the model is applied to certain categories with these demand effects.|$|R
40|$|This paper {{describes}} a new algorithm that employs image-based rendering for fast occlusion culling in complex urban environments. It exploits graphics hardware to render and automatically combine {{a relatively large}} set of occluders. The algorithm is fast to calculate and therefore also useful for scenes of moderate complexity and walkthroughs with over 20 frames per second. Occlusion is calculated dynamically and does not rely on any visibility <b>precalculation</b> or occluder preselection. Speed-ups of one order of magnitude can be obtained. 1...|$|E
40|$|In {{this paper}} an online posture {{modification}} method termed Jacobi Compensation is proposed, which modifies precalculated step trajectories for a humanoid robot in certain task coordinate directions. This method can accomodate for modeling errors in trajectory <b>precalculation</b> in that for instance {{the center of}} mass (CoM) or {{certain parts of the}} humanoid mechanism can be shifted to increase walking stability and performance. The efficacy of the concept is shown in simulations with a simplified model and walking experiments with a humanoid robot. ...|$|E
40|$|We {{describe}} an application supporting alternating interaction and animation {{for the purpose}} of exploration in a surround-screen projection-based virtual reality system. The exploration of an environment is a highly interactive and dynamic process in which the presentation of objects of interest can give the user guidance while exploring the scene. Previous systems for automatic presentation of models or scenes need either cinematographic rules, direct human interaction, framesets or <b>precalculation</b> (e. g. <b>precalculation</b> of paths to a predefined goal). We report on the development of a system that can deal with rapidly changing user interest in objects of a scene or model as well as with dynamic models and changes of the camera position introduced interactively by the user. It is implemented as a potential-field based camera data generating system. In this paper we describe the implementation of our approach in a virtual art museum on the CyberStage, our surround-screen projection-based stereoscopic display. The paradigm of guided exploration is introduced describing the freedom of the user to explore the museum autonomously. At the same time, if requested by the user, guided exploration provides just-in-time navigational support. The user controls this support by specifying the current field of interest in high-level search criteria. We also present an informal user study evaluating this approach...|$|E
40|$|Abstract—Wireless Sensor Networks (WSNs) {{have been}} of high {{interest}} during {{the past couple of}} years. One of the most challenging tasks of WSN research is still location estimation. As a well performing fine grained localization approach, Distributed Least Squares (DLS) was introduced, splitting the costly localization process in a complex <b>precalculation</b> and a simple postcalculation, which is performed on constrained sensor nodes. Nevertheless, as size of <b>precalculation</b> and conse-quently, cost of computation and communication are growing with network size, it was shown that this algorithm is unsuitable for large WSNs. This restriction has been overcome by scalable DLS (sDLS), which enables to use the idea of DLS in large WSNs for the first time. Although cost of computation of sDLS is independent of the network size, it was relatively high, due to costly matrix updates. Consequently, this cost was reduced by sDLS with normal equation (sDLSne), circumventing the updates. Unfortunately, sDLSne comes along with a decreased localization accuracy. The approach, presented in this work, combines the efficient sDLSne approach with various coarse grained localization techniques to improve localization accu-racy. The resulting localization accuracy overcomes the efficient sDLSne approach as well as the more precise sDLS approach, while cost of computation still outperforms sDLS. Keywords-wireless sensor networks, localization, scalability. I...|$|E
40|$|Abstract—Wireless Sensor Networks (WSNs) {{have been}} of high {{interest}} during {{the past couple of}} years. One of the most important aspects of WSN research is location estimation. A good solution of fine grained localization is the Distributed Least Squares (DLS) algorithm, which splits the costly localization process in a complex <b>precalculation</b> and a simple postcalculation. The latter is performed on constrained sensor nodes, finalizing the localization by adding locale knowledge. This approach lacks for large WSNs, because cost of communication and computation theoretically increases with network size. In practice the approach is even unusable for large WSNs. An important assumption of DLS is that each blind node is able to communicate with each beacon node to receive the <b>precalculation</b> and to determine distances to beacon nodes. This restriction have been overcome by scalable DLS (sDLS), which enabled to use the idea of DLS in large WSN for the first time. Although, sDLS has lower cost of computation than DLS, for large networks, this cost, caused by matrix updates, is pretty high. In this work an adaptation of sDLS is presented, which dramatically reduces cost of computation by circumventing matrix updates as often as possible. Keywords-wireless sensor networks; localization; scalability; optimization I...|$|E
40|$|A neural net {{structure}} {{has been developed}} which is capable of solving deterministic jobshop scheduling problems, part of the large class of np-complete problems. The problem was translated in an integer linear-programming format which facilitated translation in an adequate neural net structure. Use of the presented structure eliminated the need for integer adjustments. The search space was reduced {{by the use of}} <b>precalculation,</b> allowing the rapid calculation of feasible solutions. The neural net structure was reliable in simulated operation and its performance was superior to structures which have been presented previously...|$|E
30|$|The key concept {{proposed}} by us is to apply advanced, adaptive spectrum shaping algorithms originally considered {{to be used in}} non-contiguous multicarrier transmission schemes [14]. These solutions can guarantee a significant reduction of unwanted out-of-band emission even in a very narrow frequency band at a reasonable complexity. Moreover, these algorithms can be applied {{at the beginning of a}} frame, allowing for a <b>precalculation</b> of the required spectrum masks (filter shapes). The moments when the new spectrum masks have to be changed within the cell are indicated by solid bold vertical lines in Fig. 4.|$|E
