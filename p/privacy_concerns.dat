3391|850|Public
5|$|In March 2016, the New York Civil Liberties Union (NYCLU), the New York City {{office of}} the American Civil Liberties Union, {{wrote a letter to}} Mayor de Blasio {{outlining}} their <b>privacy</b> <b>concerns.</b> In the letter, representatives for the NYCLU wrote that CityBridge could be retaining too much information about LinkNYC users. They also stated that the privacy policy was vague and needed to be clarified. They recommended that the privacy policy be rewritten so that it expressly mentions whether the Links' environmental sensors or cameras are being used by any NYPD or city systems.|$|E
5|$|One {{security}} conscious commenter on the Engadget {{consumer electronics}} blog addressed the privacy {{implications of the}} oversize bills given the limitations of personal paper shredders, by speculating on {{whether it would be}} more practical to dispose of these large bills by burning them to protect personal information. An editor for the libertarian monthly Reason also speculated about the usefulness of the detailed information to government investigators. The original Ars Technica blog posting, on the other hand, dismissed <b>privacy</b> <b>concerns,</b> showing that the detail pages do not contain sensitive information.|$|E
5|$|Windows 10 {{received}} mostly positive reviews {{upon its}} original release in July 2015; critics praised Microsoft's decision {{to provide a}} desktop-oriented interface in line with previous versions of Windows, contrasting the tablet-oriented approach of 8, although Windows 10's touch-oriented user interface mode was panned for containing regressions upon the touch-oriented interface of Windows 8. Critics also praised the improvements to Windows 10's bundled software over Windows 8.1, Xbox Live integration, {{as well as the}} functionality and capabilities of Cortana personal assistant and the replacement of Internet Explorer with Microsoft Edge. However, media outlets have been critical of changes to operating system behaviors, including mandatory update installation, <b>privacy</b> <b>concerns</b> over data collection performed by the OS for Microsoft and its partners, and the adware-like tactics used to promote the operating system on its release.|$|E
40|$|This paper investigates {{to which}} degree privacy and {{security}} knowledge and global information <b>privacy</b> <b>concern</b> of a user influence mobile protection behavior. We performed a survey with 154 participants. The {{results of the}} survey suggest that both privacy and security knowledge and global information <b>privacy</b> <b>concern</b> are influential for mobile protection behavior. We find that low knowledge and low global information <b>privacy</b> <b>concern</b> can serve as predictors for the non-usage of the evaluated protection methods, whereas high knowledge and high concern can serve as predictors for the usage of the evaluated protection methods. 1...|$|R
40|$|Our {{purpose was}} to {{identify}} the behavioral characteristics and determine the attitudes of different customer segments {{in regard to the}} personalization features of e-tailers&# 39; websites as they related to the criteria of <b>privacy</b> <b>concern</b> and willingness to share information. The data of 1, 659 participants were subjected to multivariate analyses of variance and discriminant analysis methods. The results indicated that the customer segment for whom it was most likely to be profitable for companies to establish a personalized e-tail strategy had a high level of <b>privacy</b> <b>concern</b> and considerable online shopping experience, were willing to share personal information, and had a low level of <b>privacy</b> <b>concern.</b> By profiling online consumers falling within these categories, our aim was to fill the gaps and address discrepancies in the current e-personalization literature by adding to the available information about consumer <b>privacy</b> <b>concern</b> and information sharing. Limitations and implications of the findings are discussed...|$|R
40|$|The authors gratefully {{acknowledge}} the research assistance of Jacqueline Chow, {{who was an}} MSc student at the National University of Singapore during the conduct of this study. 1 Regulatory Focus Theory, Trust and <b>Privacy</b> <b>Concern</b> Relationship marketing typically requires organizations to continually collect customer information. Two distinct approaches co-exist to encourage customers to disclose information: reducing <b>privacy</b> <b>concern</b> and building trust, which {{in the past have}} been examined in isolation. In the present study, Regulatory Focus Theory was used to integrate both approaches and examine their distinct response behaviors concurrently. The findings were robust across two studies with different methods and contexts. As suggested in the proposed model, trust and <b>privacy</b> <b>concern</b> were the two central mediating variables with differentiated effects on promotion and prevention-focused behaviors. Specifically, trust mediated fairness perceptions on promotion-focused behaviors (i. e., relational behavior, relationship investment and repatronage intentions), whereas <b>privacy</b> <b>concern</b> mediated fairness perceptions on prevention-focused behaviors (i. e., defensive, deflective and disruptive behaviors). Implications for theory and practice are discussed...|$|R
25|$|Privacy - Teacher {{and student}} <b>privacy</b> <b>concerns</b> must be addressed.|$|E
25|$|In 2010, Facebook's {{security}} team began expanding {{its efforts to}} reduce the risks to users' privacy, but <b>privacy</b> <b>concerns</b> remain.|$|E
25|$|In 2004–2005 the Federal Trade Commission Staff {{conducted}} a workshop and review of RFID <b>privacy</b> <b>concerns</b> {{and issued a}} report recommending best practices.|$|E
40|$|Background:                With the {{increasing}} use of personalized marketing and {{the increasing}} ability to collect information on consumers, the consumers’ <b>concern</b> of <b>privacy</b> is increasing. Therefore {{it is important to understand}} what effects <b>privacy</b> <b>concern,</b> and how marketers can minimize this concern. Previous research suggest that factors such as computer knowledge, internet knowledge, and regulation awareness all affect <b>privacy</b> <b>concern,</b> however we believe that these are all related to each other in a construct we call Privacy Knowledge. Purpose:                        To investigate the construct of Privacy Knowledge and to what degree it influences a consumer’s attitude towards informational privacy. Method:                        In order to validate the Privacy Knowledge construct and measure its relationship to <b>Privacy</b> <b>Concern</b> we employed a deductive methodology which was comprised of questionnaires. The questionnaires were composed of summative Likert Scales, three of which had been previous validated by previous research. We utilized a quota sampling technique in order to gather enough data from each age group. The results were then analyzed by tools such as Factor Analysis, ANOVA tests, and Multiple Regression Analysis. Conclusion:                   Through the Factor Analysis we found that the factors Internet Knowledge, Computer Knowledge, and Regulation Awareness were better organized as Basic IT Knowledge, Advanced IT Knowledge and Regulation Awareness. Privacy Knowledge was found to be positively related to <b>Privacy</b> <b>Concern.</b> However we could only conclude of the three factors which make up Privacy Knowledge, Basic IT Knowledge had an effect on <b>Privacy</b> <b>Concern.</b> We believe this is due to the exclusion of other factors affecting <b>Privacy</b> <b>Concern</b> such as situational factors and suggest conducting further research on the matter including these variables...|$|R
3000|$|... to get {{accurate}} SNAM results. If {{there is}} no <b>privacy</b> <b>concern</b> between different organizations, one can integrate G [...]...|$|R
40|$|Privacy {{risks are}} {{pervasive}} and while considerable work {{is available on}} cognitive aspects of <b>privacy</b> <b>concern,</b> very {{little is known about}} the emotional/affective aspect of privacy risk. Recent experimental evidence, suggests that contextual cues, rather than deliberate evaluation of costs and benefits of privacy, affect people’s privacy behaviors. This finding raises fundamental questions about the role of <b>privacy</b> <b>concern</b> in theory, the measurement of <b>privacy</b> <b>concern</b> and also in its utility in explaining privacy behavior in real-life decisions. Affect, a “faint whisper of emotion ” which occurs automatically in any evaluation of risk and influences risk perception and evaluation, has received lot of attention in the literature. In this research, we examine the relative role of affect and cognition on people’s judgments of privacy risk. An experiment is proposed...|$|R
25|$|On December 5, 2003, Wharton {{enacted a}} policy of declining to {{actively}} participate in the rankings of business school programs, citing student <b>privacy</b> <b>concerns</b> and the methodologies employed.|$|E
25|$|During his brother's 2008 presidential campaign, Malik Obama was a {{spokesman}} for the extended Obama family in Kenya. He dealt with safety and <b>privacy</b> <b>concerns</b> arising from the increased attention from the press.|$|E
25|$|The Department of Homeland Security {{is funding}} {{networks}} of surveillance cameras {{in cities and}} towns {{as part of its}} efforts to combat terrorism. In February 2009, Cambridge, MA rejected the cameras due to <b>privacy</b> <b>concerns.</b>|$|E
40|$|While {{more and}} more {{retailers}} adopt multi-channel presence to communicate with online consumers, there still exists many differences {{in the level of}} channel integration, and accordingly, in the efficiency to reduce online transaction-specific uncertainty and promote online loyalty. This study first examines how online channel media richness affects consumers’ online loyalty directly and indirectly through perceptions of information <b>privacy</b> <b>concern</b> and deception and further investigates how cross-channel integration moderates that effects. Results show that online channel media richness not only alleviates consumers’ information <b>privacy</b> <b>concern</b> and perceived deception, but also enhances online loyalty. The moderating effects reveal that cross-channel integration complements online channel media richness in reducing information <b>privacy</b> <b>concern</b> and perceived deception, as well as strengthening online loyalty. Theoretical and practical implications of this study are discussed...|$|R
40|$|Facebook users share {{information}} with others by creating posts and specifying {{who should be}} able to see each post. Once a user creates a post, those who see it have the ability to copy and re-share the information. But, if the reader has a different understanding of the information in the post than the creator intended, he or she may use the information in ways that are contrary to the intentions of the original creator. This study examined whether post creators (Producers) and readers (Consumers) who are Facebook Friends had similar levels of <b>privacy</b> <b>concern</b> regarding how others might use the information in specific posts, and how their <b>privacy</b> <b>concern</b> about the post varied by whether the imagined audience consisted of Friends, Friends of Friends, or the general Public. The results showed that both Producers and Consumers had similar levels of <b>privacy</b> <b>concern</b> about a post shared with an imagined audience of Friends versus Friends of Friends. However, Consumers believed posts were more private than the Producers themselves did, and showed more <b>privacy</b> <b>concern.</b> This shows that post Consumers care about Producers’ privacy, perceive that they are co-owners of the information, and engage in boundary management with Producers...|$|R
50|$|Some {{forensic}} {{studies are}} under way regarding rules and regulations and warn automakers and crash investigators of <b>privacy</b> <b>concern</b> and unintended use of retrieved EDR data.|$|R
25|$|The ways {{in which}} data mining can be used can in some cases and {{contexts}} raise questions regarding privacy, legality, and ethics. In particular, data mining government or commercial data sets for national security or law enforcement purposes, {{such as in the}} Total Information Awareness Program or in ADVISE, has raised <b>privacy</b> <b>concerns.</b>|$|E
25|$|Photo {{manipulation}} software sometimes {{fails to}} update the embedded thumbnail after an editing operation, possibly causing the user to inadvertently publish compromising information. For example, someone might blank out a licence registration plate of a car (for <b>privacy</b> <b>concerns),</b> {{only to have the}} thumbnail not so updated, meaning the information is still visible.|$|E
25|$|Street View {{garnered}} {{much controversy}} after its release because of <b>privacy</b> <b>concerns</b> about the uncensored {{nature of the}} panoramic photographs. Since then, Google has begun blurring faces and license plates through automatic and face detection. A side effect {{of this is that}} many unrelated objects, such as traffic signs, road information, and street advertising, have often been blurred.|$|E
50|$|Genetic privacy {{involves}} {{the right or}} mandate of personal <b>privacy</b> <b>concerning</b> the storing, repurposing, provision to third parties, and displaying of information pertaining to one's genetic information.|$|R
40|$|A {{large part}} of {{research}} conducted on <b>privacy</b> <b>concern</b> and protection on social networking sites (SNSs) concentrates on children and adolescents. Individuals in these developmental stages are often described as vulnerable Internet users. But how vulnerable are adults in terms of online informational privacy? This study applied a privacy boundary management approach and investigated Facebook use, <b>privacy</b> <b>concern,</b> {{and the application of}} privacy settings on Facebook by linking the results to Erikson’s three stages of adulthood: emerging, young, and middle adulthood. An online survey was distributed among 18 - to 65 -year-old Dutch-speaking adults (N[*]=[*] 508, 51. 8 % females). Analyses revealed clear differences between the three adult age groups in terms of <b>privacy</b> <b>concern,</b> Facebook use, and privacy protection. Results indicated that respondents in young adulthood and middle adulthood were more vulnerable in terms of privacy protection than emerging adults. Clear discrepancies were found between <b>privacy</b> <b>concern</b> and protection for these age groups. More particularly, the middle adulthood group was more <b>concerned</b> about their <b>privacy</b> in comparison to the emerging adulthood and young adulthood group. Yet, they reported to use privacy settings less frequently than the younger age groups. Emerging adults were found to be pragmatic and privacy conscious SNS users. Young adults occupied the intermediate position, suggesting a developmental shift. The impact of generational differences is discussed, as well as implications for education and governmental action...|$|R
50|$|Some mobile {{carriers}} {{offer free}} or cheaper rate plans {{in exchange for}} SMS or other mobile ads. However, mobile TV and mobile search may override this <b>privacy</b> <b>concern,</b> {{as soon as they}} are implemented on a full-blown basis. In a naive way to override <b>privacy</b> <b>concern,</b> however, a user’s prior consent needs to be obtained through membership to join or user account to set up. Both mobile TV and mobile search may supersede the way of getting users’ prior consent through membership or user account because users are free to choose mobile TV channels or mobile search services on a voluntary basis.|$|R
25|$|On June 11, the ACLU filed {{a lawsuit}} against James Clapper, Director of National Intelligence, alleging that the NSA's phone records program was unconstitutional. In December 2013, ten days after Judge Leon's ruling, Judge William H. Pauley III came to the {{opposite}} conclusion. In ACLU v. Clapper, although acknowledging that <b>privacy</b> <b>concerns</b> are not trivial, Pauley found that the potential benefits of surveillance outweigh these considerations and ruled that the NSA's collection of phone data is legal.|$|E
25|$|Features of Dillo include bookmarks, tabbed browsing, {{and support}} for JPEG, PNG (including alpha transparency), and GIF images. Partial support for CSS was {{introduced}} in release 2.1. Settings such as the default fonts, background color, downloads folder, and home page are customizable through configuration files. Cookies are supported but disabled by default due to <b>privacy</b> <b>concerns.</b> While most web browsers retain the web cache and history after the program is closed, Dillo automatically clears them to improve both privacy and performance.|$|E
25|$|In {{response}} to rising concerns about privacy and smart technology, in 2007 the British Government stated it would follow formal Privacy by Design principles when implementing their smart metering program. The program {{would lead to}} replacement of traditional power meters with smart power meters, which could track and manage energy usage more accurately. However the British Computer Society is doubtful these principles were ever actually implemented. In 2009 the Dutch Parliament rejected a similar smart metering program, basing their decision on <b>privacy</b> <b>concerns.</b> The Dutch program later revised and passed in 2011.|$|E
30|$|The {{focus of}} this paper is not on privacy. Nevertheless, to {{alleviate}} the <b>privacy</b> <b>concern,</b> 100 Credit pursues explicit user authorization when collecting data from users’ devices and ensures providing authorized data in response to queries.|$|R
50|$|Another <b>privacy</b> <b>concern</b> {{raised by}} <b>privacy</b> advocates {{such as the}} Electronic Frontier Foundation is that the {{implementation}} of the Real ID Act will make it substantially easier for the government to track numerous activities of Americans and conduct surveillance.|$|R
40|$|Our {{research}} {{examines the}} manner in which Web users choose between participation in the Internet economy and protection of their personal data. We study the influence of various contextual elements (e. g. the privacy policies posted on sites) and individual characteristics (e. g. <b>privacy</b> <b>concern)</b> on willingness to communicate personal data online. An experimental study carried out on a sample of French students provides the framework for testing a conceptual model. The impact of <b>privacy</b> <b>concern</b> on Web users’ attitude is confirmed. Privacy policies and the amount of data requested are also shown to influence willingness to self-disclose. Finally, our findings establish that situational factors have a greater impact on the decision to provide personal data than personal convictions...|$|R
25|$|In October 2004, Google {{acquired}} Keyhole, a 3D mapping company. In February 2004, {{before its}} acquisition by Google, Keyhole received an investment from In-Q-Tel, the CIA's investment arm. And in July 2010 {{it was reported}} that the investment arms of both the CIA (In-Q-Tel) and Google (Google Ventures) were investing in Recorded Future, a company specializing in predictive analytics—monitoring the web in real time and using that information to predict the future. And, while private corporations have been using similar systems since the 1990s, the involvement of Google and the CIA with their large data stores raised <b>privacy</b> <b>concerns.</b>|$|E
25|$|In the post-Stonewall era, {{the role}} of {{libraries}} in providing information and services to LGBTQ individuals has been a topic of discussion among library professionals. Libraries can often {{play an important role}} for LGBTQ individuals looking to find information about coming out, health, and family topics, as well as leisure reading. In the past forty years, advocate organizations for LGBTQ content in libraries have emerged, and numerous theorists have discussed various aspects of LGBTQ library service including <b>privacy</b> <b>concerns,</b> programming, collection development considerations and librarian/staff education needs, as well as special services for juvenile and teen patrons.|$|E
25|$|Besides {{elevating}} <b>privacy</b> <b>concerns,</b> HTML5 {{also adds}} a few tools to enhance user privacy. A mechanism is defined whereby user agents can share blacklists of domains {{that should not}} be allowed to access web storage. Content Security Policy is a proposed standard whereby sites may assign privileges to different domains, enforcing harsh limitations on JavaScript use to mitigate cross-site scripting attacks. HTML5 also adds HTML templating and a standard HTML parser which replaces the various parsers of web browser vendors. These new features formalize previously inconsistent implementations, reducing the number of vulnerabilities though not eliminating them entirely.|$|E
40|$|As the Internet {{grows in}} importance, <b>concerns</b> about online <b>privacy</b> have arisen. The authors {{describe}} {{the development and}} validation of three short Internet administered scales measuring privacy-related attitudes (<b>Privacy</b> <b>Concern)</b> and behaviors (General Caution and Technical Protection). In Study 1, 515 people completed an 82 -item questionnaire from which the three scales were derived. In Study 2, scale validity was examined by comparing scores of individuals drawn from groups considered likely to differ in privacy-protective behaviors. In Study 3, correlations between the scores on the current scales and two established measures of <b>privacy</b> <b>concern</b> were examined. The authors conclude that these scales are reliable and valid instruments suitable for administration via the Internet, and present them for use in online privacy research...|$|R
40|$|Face {{recognition}} {{has been}} employed in various securityrelated {{applications such as}} surveillance, mugshot identification, e-passport, and access control. Despite its recent advancements, <b>privacy</b> <b>concern</b> {{is one of several}} issues preventing its wider deployment. In this paper, we address the <b>privacy</b> <b>concern</b> for a self-exclusion scenario of face recognition, through combining face recognition with a simple biometric encryption scheme called helper data system. The combined system is described in detail with focus on the key binding procedure. Experiments are carried out on the CMU PIE face database. The experimental results demonstrate that in the proposed system, the biometric encryption module tends to significantly reduce the false acceptance rate while increasing the false rejection rate. Index Terms — Face recognition, biometric encryption, security, privacy, watch list...|$|R
40|$|The self-disclosure of {{personal}} information by users on social network sites (SNSs) {{play a vital}} role in the self-sustainability of online social networking service provider platforms. However, people 2 ̆ 7 s levels of <b>privacy</b> <b>concern</b> increases as a direct result of unauthorized procurement and exploitation {{of personal}} information from the use of social networks which in turn discourages users from disclosing their information or encourages users to submit fake information online. After a review of the Theory of Planned Behavior (TPB) and the privacy calculus model, an integrated model is proposed to explain privacy disclosure behaviors on social network sites. Thus, the aim of this paper is to find the key factors affecting users 2 ̆ 7 self-disclosure of personal information. Using privacy calculus, the perceived benefit was combined into the Theory of Planned Behavior, and after some modifications, an integrated model was prescribed specifically for the context of social network sites. The constructs of information sensitivity and perceived benefit were redefined after reviewing the literature. Through a study on the constructs of <b>privacy</b> <b>concern</b> and self-disclosure, this article aims at reducing the levels of <b>privacy</b> <b>concern,</b> while sustaining online transactions and further stimulating the development of social network sites...|$|R
