17|321|Public
5000|$|Kern & Sohn is a German {{manufacturer}} and distributor of <b>precision</b> <b>scales</b> and force gauges.|$|E
50|$|Kern sells {{directly}} to end-users of <b>precision</b> <b>scales</b> and force gauges {{as well as}} distributors throughout the world.|$|E
50|$|The {{company began}} in 1846 {{manufacturing}} <b>precision</b> <b>scales</b> and mainly industrial balances, in Wald, now a district of Solingen in North Rhine-Westphalia. This was the company's principal product {{for the next}} 110 years.|$|E
50|$|Also in {{the early}} 1990s, <b>Precision</b> <b>Scale</b> Models {{imported}} a range of VR Blue and V/Line orange brass locomotives.|$|R
5000|$|Determine the coin's {{weight in}} grams by {{consulting}} a coin collecting book or online guide or by weighing the coin {{yourself with a}} <b>precision</b> <b>scale,</b> i.e., a scale made to weigh coins or jewelry.|$|R
30|$|The user {{must ensure}} that the linear stage was lowered before {{initiating}} the dispense radioactivity routine. The algorithm development for the dispenser system required independent calibration data from the radiation detector {{as well as the}} peristaltic pump. Specifically, the output voltage from the radiation detector was calibrated to known radioactivity concentration, as measured by a dose calibrator and a <b>precision</b> <b>scale.</b> Similarly, the speed control voltage from the peristaltic pump was calibrated to flow rate, as measured by a <b>precision</b> <b>scale</b> and the known density of the liquid solution. Calibration data from the peristaltic pump and radioactivity detector were incorporated into the dispensing algorithm.|$|R
50|$|For {{high-speed}} <b>precision</b> <b>scales,</b> a {{load cell}} using electromagnetic force restoration (EMFR) is appropriate. This kind of system charges an inductive coil, effectively floating the weigh bed in an electromagnetic field. When the weight is added, {{the movement of}} a ferrous material through that coil causes a fluctuation in the coil current proportional to {{the weight of the}} object. Other technologies used include strain gauges and vibrating wire load cells.|$|E
50|$|Sterling Commerce, a B2B {{software}} company, has {{its headquarters}} {{on the northwest}} side. Mettler Toledo, a manufacturer of <b>precision</b> <b>scales</b> and scientific equipment is headquartered in the area known as Polaris {{on the north side}} of the city. Columbus is home to interactive agencies and software development companies, with a concentration in Columbus' downtown and Arena District neighborhoods. Online Computer Library Center (OCLC), a leading library information company, is based in the Columbus area.|$|E
50|$|The {{manufacturing}} sector includes Honda, which operates their largest North American manufacturing {{complex in the}} Marysville area. Also in Marysville is Scotts Miracle-Gro Company, the maker's of Miracle Gro and various other soil and potting fertilizers. Located in downtown Columbus is AEP, {{which is one of}} the largest electric utility companies in the US. Mettler Toledo, a manufacturer of <b>precision</b> <b>scales</b> and scientific equipment, is based in the area known as Polaris. Worthington Industries, a large steel-processing company, is primarily located on the north side of Columbus near Worthington. The Ashland Inc. company has a large office space within Dublin. Anheuser-Busch operates one of their 12 breweries on the north side of Columbus. Hexion Specialty Chemicals (formerly part of Borden) is located in downtown Columbus. The Ross Products Division of Abbott Laboratories, makers of Ensure nutritional drink and Similac infant formula, is also headquartered in Columbus. T. Marzetti Company, a large food manuacturer, is headquartered in North Columbus, and has distribution centers and food manufacturing operations throughout Central Ohio. Homebuilders M/I Homes and Dominion Homes are located in Columbus.|$|E
5000|$|The [...] type {{comprises}} these attributes:The base, <b>scale,</b> <b>precision</b> and <b>scale</b> {{factor of}} the [...] type is encoded within the [...] The mode is specified separately, with the [...] applied {{to both the}} real and the imaginary parts.|$|R
2500|$|The VR K Class {{locomotive}} {{was previously}} available in HO Scale as a brass and Whitemetal kit, by Broad Gauge Models. There {{were also a}} limited production run of brass [...] "Ready-to-Run" [...] models produced by <b>Precision</b> <b>Scale</b> Models in the mid-1990s. A limited production run of brass [...] "Ready-to-Run" [...] models was produced by Trainbuilder in 2013/14.|$|R
2500|$|The VR N Class {{locomotive}} {{was previously}} available in HO Scale as a brass and Whitemetal kit, by Broad Gauge Models. There {{were also a}} limited production run of brass [...] "Ready-to-Run" [...] models produced by <b>Precision</b> <b>Scale</b> Models in the mid-1990s. A plastic version is currently in development by Eureka Models, but no due date has been set.|$|R
40|$|We {{propose a}} {{protocol}} to estimate magnetic fields using a single nitrogen-vacancy (N-V) center in diamond, where the estimate <b>precision</b> <b>scales</b> inversely with time, ~ 1 /T$, {{rather than the}} square-root of time. The method is based on converting the task of magnetometry into phase estimation, performing quantum phase estimation on a single N-V nuclear spin using either adaptive or nonadaptive feedback control, and the recently demonstrated capability to perform single-shot readout within the N-V [P. Neumann et. al., Science 329, 542 (2010) ]. We present numerical simulations to show that our method provides an estimate whose <b>precision</b> <b>scales</b> close to ~ 1 /T (T is the total estimation time), and moreover will give an unambiguous estimate of the static magnetic field experienced by the N-V. By combining this protocol with recent proposals for scanning magnetometry using an N-V, our protocol will provide {{a significant decrease in}} signal acquisition time while providing an unambiguous spatial map of the magnetic field. Comment: 8 pages and 5 figure...|$|E
40|$|The {{advent of}} {{increasingly}} precise gyroscopes {{has played a}} key role in the technological development of navigation systems. Ring-laser and fibre-optic gyroscopes, for example, are widely used in modern inertial guidance systems and rely on the interference of unentangled photons to measure mechanical rotation. The sensitivity of these devices scales with the number of particles used as 1 / √(N). Here we demonstrate how, by using sources of entangled particles, it is possible to do better and even achieve the ultimate limit allowed by quantum mechanics where the <b>precision</b> <b>scales</b> as 1 /N. We propose a gyroscope scheme that uses ultra-cold atoms trapped in an optical ring potential. Comment: 19 pages, 2 figure...|$|E
40|$|This {{experiment}} {{investigated the}} biometric parameters for the enteric tract of eight Southern Caracaras (Polyborus plancus, Miller 1777). The study {{was carried out}} on eight adult animals of both sexes (four males and four females) having different ages and weights. The animals were sacrificed and dissected, and their visceral tracts were placed on a horizontal plane surface. The lengths were measured and the weights were obtained on electronic <b>precision</b> <b>scales.</b> The statistical analysis utilized was Student’s t-test with a significance level p= 0. 05. The {{results showed that the}} Southern Caracara possessed a duodenum and an ileum longer than those of the chicken. It was concluded that the small intestine of the Southern Caracara is relatively extensive, mainly on account of the duodenum that is similar in length to that of the goose. This bird had a vestige of the cecum that it is different to that of the chicken...|$|E
40|$|We {{demonstrate}} that the optimal states in lossy quantum interferometry may be efficiently simulated using low rank matrix product states. We argue that this should be expected in all realistic quantum metrological protocols with uncorrelated noise and {{is related to the}} elusive nature of the Heisenberg <b>precision</b> <b>scaling</b> in presence of decoherence. Comment: 5 pages, 2 figure...|$|R
5000|$|The VR K Class {{locomotive}} {{was previously}} available in HO Scale as a brass and Whitemetal kit, by Broad Gauge Models. There {{were also a}} limited production run of brass [...] "Ready-to-Run" [...] models produced by <b>Precision</b> <b>Scale</b> Models in the mid-1990s. A limited production run of brass [...] "Ready-to-Run" [...] models was produced by Trainbuilder in 2013/14.|$|R
5000|$|The VR N Class {{locomotive}} {{was previously}} available in HO Scale as a brass and Whitemetal kit, by Broad Gauge Models. There {{were also a}} limited production run of brass [...] "Ready-to-Run" [...] models produced by <b>Precision</b> <b>Scale</b> Models in the mid-1990s. A plastic version is currently in development by Eureka Models, but no due date has been set.|$|R
40|$|Quantum-enhanced {{metrology}} aims {{to estimate}} an unknown parameter {{such that the}} <b>precision</b> <b>scales</b> better than the shot-noise bound. Single-shot adaptive quantum-enhanced metrology (AQEM) is a promising approach that uses feedback to tweak the quantum process according to previous measurement outcomes. Techniques and formalism for the adaptive case are {{quite different from the}} usual non-adaptive quantum metrology approach due to the causal relationship between measurements and outcomes. We construct a formal framework for AQEM by modeling the procedure as a decision-making process, and we derive the imprecision and the Cram´er- Rao lower bound with explicit dependence on the feedback policy. We also explain the reinforcement learning approach for generating quantum control policies, which is adopted due to the optimal policy being non-trivial to devise. Applying a learning algorithm based on differential evolution enables us to attain imprecision for adaptive interferometric phase estimation, which turns out to be SQL when non-entangled particles are used in the scheme...|$|E
40|$|This project aims {{to reduce}} {{measurement}} uncertainty in atomic clocks by squeezing the collective spin of atoms. Spin-squeezing reduces noise below the standard quantum limit where <b>precision</b> <b>scales</b> as 1 / [square root of] N, {{allowing us to}} instead approach the Heisenberg limit where it scales as 1 /N. We report spin-squeezing of the (F = 2, mR = 0) [...] > (F = 1, mF = 0) hyperfine transition of the 5 S 1 / 2 level of ⁸⁷Rb. We also demonstrate a viable setup for the spin-squeezing of the magnetically trappable (F = 2, mF = 1) [...] > (F = 1, mF = - 1) transition, which could potentially {{be used as a}} compact frequency standard. This thesis provides a brief theoretical background of spin-squeezing and a summary of the project in its current state. by Adele Ann Schwab. Thesis (S. B.) [...] Massachusetts Institute of Technology, Dept. of Physics, 2008. Includes bibliographical references (p. 55 - 57) ...|$|E
40|$|We {{analyze and}} exploit some scaling {{properties}} of the Affinity Propagation (AP) clustering algorithm proposed by Frey and Dueck (2007). First we observe that a divide and conquer strategy, used on a large data set hierarchically reduces the complexity O(N^ 2) to O(N^(h+ 2) /(h+ 1)), for a data-set of size N and a depth h of the hierarchical strategy. For a data-set embedded in a d-dimensional space, we show that this is obtained without notably damaging the precision except in dimension d= 2. In fact, for d larger than 2 the relative loss in <b>precision</b> <b>scales</b> like N^(2 -d) /(h+ 1) d. Finally, under some conditions we observe {{that there is a}} value s^* of the penalty coefficient, a free parameter used to fix the number of clusters, which separates a fragmentation phase (for ss^*) of the underlying hidden cluster structure. At this precise point holds a self-similarity property which can be exploited by the hierarchical strategy to actually locate its position. From this observation, a strategy based on can be defined to find out how many clusters are present in a given dataset. Comment: 28 pages, 14 figures, Inria research repor...|$|E
40|$|Three-dimensional spin {{models of}} the Ising and XY {{universality}} classes are studied {{by a combination of}} high-temperature expansions and Monte Carlo simulations. Critical exponents are determined to very high <b>precision.</b> <b>Scaling</b> amplitude ratios are computed via the critical equation of state. Our results are compared with other theoretical computations and with experiments, with special emphasis on the lambda transition of 4 He. ...|$|R
40|$|We {{consider}} a general model of unitary parameter estimation in presence of Markovian noise, where the parameter to be estimated {{is associated with}} the Hamiltonian part of the dynamics. In absence of noise, unitary parameter can be estimated with <b>precision</b> <b>scaling</b> as 1 /T, where T is the total probing time. We provide a simple algebraic condition involving solely the operators appearing in the quantum Master equation, implying at most 1 /√(T) <b>scaling</b> of <b>precision</b> under the most general adaptive quantum estimation strategies. We also discuss the requirements a quantum error-correction like protocol must satisfy in order to regain the 1 /T <b>precision</b> <b>scaling</b> in case the above mentioned algebraic condition is not satisfied. Furthermore, we apply the developed methods to understand fundamental precision limits in atomic interferometry with many-body effects taken into account, shedding new light on the performance of non-linear metrological models. Comment: 13 pages, to be published in PRX, see also arXiv: 1706. 0244...|$|R
40|$|Quantum sensors {{based on}} single Nitrogen-Vacancy (NV) defects in diamond are {{state-of-the-art}} tools for nano-scale magnetometry with <b>precision</b> <b>scaling</b> inversely with total measurement time σ_B∝ 1 /T (Heisenberg scaling) {{rather than as}} the inverse of the square root of T, with σ_B = 1 /√(T) the Shot-Noise limit. This scaling {{can be achieved by}} means of phase estimation algorithms (PEAs) using adaptive or non-adaptive feedback, in combination with single-shot readout techniques. Despite their accuracy, the range of applicability of PEAs is limited to periodic signals involving single frequencies with negligible temporal fluctuations. In this Letter, we propose an alternative method for precision magnetometry in frequency multiplexed signals via compressive sensing (CS) techniques. We show that CS can provide for <b>precision</b> <b>scaling</b> approximately as σ_B≈ 1 /T, both in the case of single frequency and frequency multiplexed signals, as well as for a 5 -fold increase in sensitivity over dynamic-range gain, in addition to reducing the total number of resources required. Comment: 5 pages, 4 figure...|$|R
40|$|Abstract—The fluoroBancroft (FB) {{algorithm}} is an analytical {{solution to the}} position estimation problem in single molecule fluorescence microscopy. In this paper we derive a theoretical description of the bias and precision of the estimator for three dimensional estimation based on a stack of charge-coupled device (CCD) images and illustrate the results through realistic simulations. The {{results indicate that the}} algorithm exhibits a small bias that is driven primarily by modeling error and is dependent on the location of the source particle relative to the set of pixels used for estimation. In the shot noise limited case, the <b>precision</b> <b>scales</b> approximately as the inverse square root of the number of photons detected and as the inverse of the number of photons detected in the background noise limited case. The results are compared through simulation to the maximum-likelihood (ML) estimator based on the theoretical point spread function and found to have a similar performance. In general, the ML estimate had lower bias and variance, though at the lowest signal-to-noise ratio (SNR), FB outperformed ML. The FB algorithm executes approximately three to four orders-of-magnitude faster than the ML estimator and is well-suited for applications in which real-time results are needed. Index Terms—Fluorescence microscopy, estimation, generalized inverse. I...|$|E
40|$|Abstract: There are {{two phases}} to the polar {{alignment}} problem. First one must quantify the alignment error for each axis. Once alignment error is known the mount must {{be adjusted to}} correct for this error. Often the adjustment amount must be estimated based on {{the magnitude of the}} error. This is primarily {{due to the fact that}} most mount manufacturers do not provide or calibrate the altitude and azimuth axes with high <b>precision</b> <b>scales.</b> This article will show a simple method utilizing a calculated star offset position to make the mount adjustment. The star offset position is calculated based on the known celestial coordinates of a reference star and the alignment error such that pointing the telescope at this coordinate and adjusting the mount to recenter the reference star will bring the mount into close alignment. This method is called “star offset positioning ” and should greatly reduce the amount of time to perform the alignment procedure. Overview In Measuring Polar Axis Alignment Error [1] we discussed various methods to measure the polar alignment error. If the mount were designed with encoders on the altitude and azimuth adjustment axes, or if these were calibrated with an accurate visual scale, the adjustment to th...|$|E
40|$|A {{sampling}} {{algorithm is}} presented that generates spin glass configurations of the 2 D Edwards-Anderson Ising spin glass at finite temperature, with probabilities proportional to their Boltzmann weights. Such an algorithm overcomes the slow dynamics of direct simulation {{and can be}} used to study long-range correlation functions and coarse-grained dynamics. The algorithm uses a correspondence between spin configurations on a regular lattice and dimer (edge) coverings of a related graph: Wilson's algorithm [D. B. Wilson, Proc. 8 th Symp. Discrete Algorithms 258, (1997) ] for sampling dimer coverings on a planar lattice is adapted to generate samplings for the dimer problem corresponding to both planar and toroidal spin glass samples. This algorithm is recursive: it computes probabilities for spins along a "separator" that divides the sample in half. Given the spins on the separator, sample configurations for the two separated halves are generated by further division and assignment. The algorithm is simplified by using Pfaffian elimination, rather than Gaussian elimination, for sampling dimer configurations. For n spins and given floating point precision, the algorithm has an asymptotic run-time of O(n^{ 3 / 2 }); it is found that the required <b>precision</b> <b>scales</b> as inverse temperature and grows only slowly with system size. Sample applications and benchmarking results are presented for samples of size up to n= 128 ^ 2, with fixed and periodic boundary conditions. Comment: 18 pages, 10 figures, 1 table; minor clarification...|$|E
30|$|In {{the first}} experiment, {{immediately}} after the PET examination, tumors and organs were harvested. Tissue samples were weighed with a <b>precision</b> <b>scale</b> (± 0.01 mg). Tumor radioactivity was counted for 2 min in a cylinder-well counter (Cobra II, Packard, GMI, Inc., MN, USA) and corrected for instrument efficiency and decay. Counts per minute were converted to becquerel and normalized for sample weight, assuming a density of 1 g/mL.|$|R
40|$|The {{surface and}} edge quality of single crystal and {{polycrystalline}} copper workpieces {{has been observed}} to vary significantly {{as a function of}} crystallographic orientation. At the <b>precision</b> <b>scale,</b> the chip formation process is influenced by the microstructure of the material, such as grain boundaries and grain orientation in polycrystalline materials, and crystallographic orientation in single-crystal materials. Such variation in the microstructure has a significant effect on the resulting surface, edge, and burr topography...|$|R
5000|$|... (4) A {{prioritization}} protocol {{which the}} importance {{is determined by}} the <b>precision,</b> magnitude, <b>scale,</b> and spatial location of the wavelet coefficients in order.|$|R
40|$|This is {{the peer}} {{reviewed}} {{version of the}} following article: MICHELETTI, N., CHANDLER, J. H. and LANE, S. N., 2015. Investigating the geomorphological potential of freely available and accessible structure-from-motion photogrammetry using a smartphone. Earth Surface Processes and Landforms, 40 (4), pp. 473 - 486, which has been published in final form at [URL] This article {{may be used for}} non-commercial purposes in accordance with Wiley Terms and Conditions for Self-Archiving. We test the acquisition of high-resolution topographic and terrain data using hand-held smartphone technology, where the acquired images can be processed using technology freely available to the research community. This is achieved by evaluating the quality of digital terrain models (DTM) of a river bank and an Alpine alluvial fan generated with a fully automated, free-to-use, structure-from-motion package and a smartphone integrated camera (5 megapixels) with terrestrial laser scanning (TLS) data used to provide a benchmark. To evaluate this approach a 16. 2 -megapixel digital camera and an established, commercial, close-range and semi-automated software are also employed, and the product of the four combinations of the two types of cameras and software are compared. Results for the river bank survey demonstrate that centimetre-precision DTMs can be achieved at close range (10 m or less), using a smartphone camera and a fully automated package. Results improve to sub-centimetre precision with either higher-resolution images or by applying speciﬁc post-processing techniques to the smartphone DTMs. Application to an entire Alpine alluvial fan system shows the degradation of <b>precision</b> <b>scales</b> linearly with image scale, but that (i) the expected level of precision remains and (ii) difﬁculties in separating vegetation and sediment cover within the results are similar to those typically found when using other photo-based techniques and laser scanning systems...|$|E
40|$|Within palaeoenvironmental studies, high-altitude peatlands of the Andes {{still remain}} {{relatively}} unexploited, although they offer {{an excellent opportunity}} for high-resolution chronologies, on account of their high accumulation rates and abundant carbon for dating. Especially in the central Andes, additional high-quality proxy records are still needed {{due to the lack}} of continuous and well-dated records, which show a significant variability on sub-centennial to decadal <b>precision</b> <b>scales.</b> To widen the current knowledge on climatic and environmental changes in the western Andes of southern Peru, we present a new, high-resolution 8600 year-long record from Cerro Llamoca peatland, a high-altitude Juncaceous cushion peatland in the headwaters of Río Viscas, a tributary to Río Grande de Nasca. A 10. 5 m core of peat with intercalated sediment layers was examined for all kinds of microfossils, including fossil charred particles. We chose homogeneous peat sections for pollen analysis at a high temporal resolution. The inorganic geochemistry was analysed in 2 mm resolution using an ITRAX X-ray fluorescence (XRF) core scanner. We interpret the increase of Poaceae pollen in our record as an expansion of Andean grasslands during humid phases. Drier conditions are indicated by a significant decrease of Poaceae pollen and higher abundances of Asteraceae pollen. The results are substantiated by changes in arsenic contents and manganese/iron ratios, which turned out as applicable proxies for in situ palaeo-redox conditions. The mid-Holocene period of 8. 6 – 5. 6 ka is characterized by a series of episodic dry spells alternating with spells that are more humid. After a pronounced dry period at 4. 6 – 4. 2 ka, conditions generally shifted towards a more humid climate. We stress a humid/relatively stable interval between 1. 8 – 1. 2 ka, which coincides with the florescence of the Nasca culture in the Andean foreland. An abrupt turnover to a sustained dry period occurs at 1. 2 ka, which coincides with the collapse of the Nasca/Wari society in the Palpa lowlands. Markedly drier conditions prevail until 0. 75 ka, providing evidence for the presence of a Medieval Climate Anomaly. Moister but hydrologically highly variable conditions prevailed again after 0. 75 ka, which allowed the re-expansion of tussock grasses in the highlands, increased discharge into the Andean foreland and the re-occupation of the settlements in the lowlands during this so-called Late Intermediate Period. On a supraregional scale, our findings can ideally be linked to and proofed by the archaeological chronology of the Nasca-Palpa region as well as other high-resolution marine and terrestrial palaeoenvironmental records. Our findings show that hydrological fluctuations, triggered by the changing intensity of the monsoonal tropical summer rains emerging from the Amazon Basin in the north-east, have controlled the climate in the study area...|$|E
30|$|In this study, a {{conventional}} glass ionomer cement, GIC (Gold Fuji 9, GC Corp, Japan, Lot Number 1701241), {{was used as}} control (GIC-C). The experimental compound (GIC-THEO) was obtained by incorporating 1 % per weight of theobromine (Sigma-Aldrich, Darmstadt, Germany), weighed on a 0.01  mg <b>precision</b> <b>scale</b> of (ATX 224, Shimadzu, Japan), into the GIC powder. This concentration was used in a pilot study, considering the higher concentration of theobromine incorporated that maintained the shiny appearance of the surface mixture.|$|R
40|$|We {{propose a}} semi-Lagrangian scheme using a {{spatially}} adaptive sparse grid {{to deal with}} non-linear time-dependent Hamilton-Jacobi Bellman equations. We focus in particular on front propagation models in higher dimensions which are related to control problems. We test the numerical efficiency of the method on several benchmark problems up to space dimension d= 8, and give evidence of convergence towards the exact viscosity solution. In addition, we study how the complexity and <b>precision</b> <b>scale</b> with the dimension of the problem...|$|R
50|$|The Diecast Zone {{was founded}} in 1997 by Michael Knab and Jay Olins. Knab had created the website {{on behalf of his}} ad agency client, Revell-Monogram. Revell had created a new brand and scale (Creative Masters, 1:20th), of <b>precision</b> <b>scale</b> model cars to compete against Franklin Mint. Franklin Mint had popularized the hobby of mass-produced collectibles. Knab {{convinced}} Revell that it should be first to exploit the direct marketing advantages of the emerging Internet to gain a “first mover” competitive advantage.|$|R
50|$|Lawrence S. Kazoyan (b. November 7, 1931 - d. April 15, 2000, Palm Beach), {{a retired}} {{aerospace}} engineer, acquired Kemtron in 1970, {{and moved it}} from Fresno to Los Angeles. T. Fredrick Hill and Wayne Lyndon, owners of The Original Whistle Stop Inc., acquired Kemtron in 1978 and moved it to Sacramento. The <b>Precision</b> <b>Scale</b> Company, Inc. acquired Kemtron as a merger in 1986. Former Kemtron employee John Anderson later went on to found Associated Brass Products, Inc., maker of the Cal-Scale line.|$|R
