5580|666|Public
5000|$|... 2. Check that <b>propensity</b> <b>score</b> is {{balanced}} across treatment and comparison groups, and check that covariates are balanced across treatment and comparison groups within strata of the <b>propensity</b> <b>score.</b>|$|E
50|$|Guarantee Policy using <b>Propensity</b> <b>Score</b> Matching”, Small Business Economics 33,335-351.|$|E
50|$|<b>Propensity</b> <b>score</b> {{matching}} {{is often}} used when there are multiple attributes.|$|E
30|$|After {{implementing}} the logit model for cooperative membership, we estimated the <b>propensity</b> <b>scores.</b> The estimated <b>propensity</b> <b>scores</b> {{for the whole}} sample range between 0.0174 and 0.9933 with mean score of 0.4797. The <b>propensity</b> <b>scores</b> for nonmembers vary between 0.0174 and 0.9138, and for members, they vary between 0.1268 and 0.9933. Thus, the common support region, where the values of <b>propensity</b> <b>scores</b> of both treatment and comparison groups can be found, is given in the range between 0.1268 and 0.9138. Observations whose <b>propensity</b> <b>scores</b> lie outside this range are dropped from the sample.|$|R
30|$|The {{balancing}} {{effect of}} the generated <b>propensity</b> <b>scores</b> is shown in Table  1. When adjusted to <b>propensity</b> <b>scores,</b> all baseline characteristics were balanced.|$|R
40|$|Abstract The {{internal}} validity of an observational study {{is enhanced by}} only comparing sets of treated and control subjects which have sufficient overlap in their covariate distributions. Methods {{have been developed for}} defining the study population using <b>propensity</b> <b>scores</b> to ensure sufficient overlap. However, a study population defined by <b>propensity</b> <b>scores</b> is difficult for other investigators to understand. We develop a method of defining a study population in terms of a tree which is easy to understand and display, and that has similar {{internal validity}} as that of the study population defined by <b>propensity</b> <b>scores...</b>|$|R
5000|$|SAS: The macro [...] matches {{observations}} {{based on}} a <b>propensity</b> <b>score.</b>|$|E
5000|$|R: <b>propensity</b> <b>score</b> {{matching}} {{is available}} {{as part of}} the [...] package. It can also easily be implemented manually.|$|E
5000|$|Stata: several {{commands}} implement <b>propensity</b> <b>score</b> matching, {{including the}} user-written [...] Stata version 13 and later also offers the built-in command [...]|$|E
40|$|Standardized means, {{commonly}} used in observational studies in epidemiology to adjust for potential confounders, are equal to inverse probability weighted means with inverse weights equal to the empirical <b>propensity</b> <b>scores.</b> More refined standardization corresponds with empirical <b>propensity</b> <b>scores</b> computed under more flexible models. Unnecessary standardization induces efficiency loss. However, according {{to the theory of}} inverse probability weighted estimation, <b>propensity</b> <b>scores</b> estimated under more flexible models induce improvement in the precision of inverse probability weighted means. This apparent contradiction is clarified by explicitly stating the assumptions under which the improvement in precision is attained. Copyright 2010, Oxford University Press. ...|$|R
30|$|Both the {{cross-sectional}} and panel {{samples are}} used for analysis, with <b>propensity</b> <b>scores</b> estimated separately for each sample. For the panel sample, I construct <b>propensity</b> <b>scores</b> using baseline covariates measured in 2001. For the much larger cross-sectional sample, I use covariates measured in 2002 because baseline covariates are missing for {{approximately half of the}} observations.|$|R
30|$|In {{order to}} assess the quality of sample balance between treated and matched controls, we follow {{recommendations}} by Stuart ([2010]) and test for differences in mean and variances of <b>propensity</b> <b>scores</b> across treated and control groups. We find no significant mean-differences and the ratio of variances of <b>propensity</b> <b>scores</b> (with a value of 1.3) further indicates good sample balance.|$|R
5000|$|Reeve BB, Smith AW, Arora NK, Hays RD. Reducing bias {{in cancer}} research: {{application}} of <b>propensity</b> <b>score</b> matching. Health care financing review. 2008 Jun 1;29(4).|$|E
50|$|Kempthorne's randomization-analysis has {{influenced}} the causal model of Donald Rubin; in turn, Rubin's randomization-based analysis {{and his work}} with Rosenbaum on <b>propensity</b> <b>score</b> matching influenced Kempthorne's analysis of covariance.|$|E
5000|$|Suppose {{that we have}} {{a binary}} {{treatment}} T, an outcome Y, and background variables X. The <b>propensity</b> <b>score</b> is defined as the conditional probability of treatment given background variables: ...|$|E
30|$|An issue {{related to}} the {{corresponding}} inverse probability weights is that <b>propensity</b> <b>scores</b> close to one among the non-participants will result in very large weights that, in turn, may result in increasingly variable estimates (see, e.g. Austin and Stuart 2015). As was already evident in the previous discussion of the <b>propensity</b> <b>scores,</b> this does not pose {{a problem in the}} present setting.|$|R
3000|$|... are the {{estimated}} <b>propensity</b> <b>scores</b> for individuals ‘i’ and ‘j’ {{in the treatment}} and untreated groups, and u the smoothing parameter.|$|R
3000|$|... 13 Including for the {{calculation}} of the <b>propensity</b> <b>scores,</b> although the effect of treatment on the treated is not estimated using weights.|$|R
5000|$|Kaczmarek BF, Tanagho YS, Hillyer SP, Mullins JK, Diaz M, Trinh QD, Bhayani SB, Allaf ME, Stifelman MD, Kaouk JH, Rogers CG. Off-clamp Robot-assisted Partial Nephrectomy Preserves Renal Function: A Multi-institutional <b>Propensity</b> <b>Score</b> Analysis. Eur Urol. 10:16. 2012 ...|$|E
50|$|A <b>propensity</b> <b>score</b> is the {{probability}} of a unit (e.g., person, classroom, school) being assigned to a particular treatment given a set of observed covariates. Propensity scores are used to reduce selection bias by equating groups based on these covariates.|$|E
50|$|TWANG, the Toolkit for Weighting and Analysis of Nonequivalent Groups, {{developed}} by the statistics group of the RAND Corporation, contains a set of functions to support Rubin causal modeling of observational data through the estimation and evaluation of <b>propensity</b> <b>score</b> weights by applying gradient boosting. It has been applied in several studies.|$|E
40|$|In many {{observational}} studies, analysts estimate causal effects using <b>propensity</b> <b>scores,</b> e. g. by matching, sub-classifying, or {{inverse probability}} weighting {{based on the}} <b>scores.</b> Estimation of <b>propensity</b> <b>scores</b> is complicated when some values of the covariates are missing. Analysts can use multiple imputation to create completed data sets from which <b>propensity</b> <b>scores</b> can be estimated. We propose a general location mixture model for imputations that assumes that the control units are a latent mixture of (i) units whose covariates are drawn from the same distributions as the treated units' covariates and (ii) units whose covariates are drawn from different distributions. This formulation reduces the influence of control units outside the treated units' region of the covariate space on the estimation of parameters in the imputation model, which can result in more plausible imputations. In turn, this can result in more reliable estimates of <b>propensity</b> <b>scores</b> and better balance in the true covariate distributions when matching or sub-classifying. We illustrate {{the benefits of the}} latent class modeling approach with simulations and with an observational study of the effect of breast feeding on children's cognitive abilitie...|$|R
3000|$|After {{calculating the}} <b>propensity</b> <b>scores,</b> the nearest {{neighbor}} matching (NNM) method, Kernel Matching, Stratification Matching, and Radius Matching {{were employed to}} match the control group of individuals (non-adapters) to the treated group (adapters) based on similar <b>propensity</b> <b>scores.</b> During the matching process, all the matching methods employed discard the unmatched non-adapters, and hence, they lead to the reduction in sample size for the post-matching impact analysis. The region of common support is [. 01697335, [...]. 99999403] and the balancing property also satisfied.|$|R
5000|$|In {{case the}} {{randomization}} procedure {{seems to be}} defective: can and should one calculate <b>propensity</b> <b>scores</b> and include them as covariates in the main analyses? ...|$|R
50|$|In lieu of {{experimental}} control, multivariate statistical techniques allow the approximation {{of experimental}} control with statistical control, {{which accounts for}} the influences of observed factors that might influence a cause-and-effect relationship. In healthcare and the social sciences, investigators may use matching to compare units that nonrandomly received the treatment and control. One common approach is to use <b>propensity</b> <b>score</b> matching {{in order to reduce}} confounding.|$|E
50|$|Steinberg and Monahan {{questioned}} the statistical method {{in the study}} by Collins and colleagues. In response Collins, Martino, Elliott and Miu reanalyzed the data with <b>propensity</b> <b>score</b> matching. The effects from the reanalysis were not as large as the original data, but were within range. Collins and colleagues concluded that the association does not prove causality, but is sufficient to warrant caution by parents of adolescents.|$|E
50|$|Many {{statistical}} {{methods have been}} developed for causal inference, such as <b>propensity</b> <b>score</b> matching and nearest-neighbor matching (which often uses the Mahalanobis metric, also called Mahalanobis matching). These methods attempt to correct for the assignment mechanism by finding control units similar to treatment units. In the example, matching finds graduates of a public college most similar to graduates of a private college, so that like is compared only with like.|$|E
40|$|In U. S. {{political}} campaigns, {{the use of}} <b>propensity</b> <b>scores</b> of voters, predicted attributes, such as partisanship or turnout likelihood, {{became quite}} popular in recent years. Such applications, often called microtargeting, range from survey sampling to voter contacts via direct mail, phone, or canvassing. To create such models, analysts first recode the original dataset into statistical software and then create statistical models by using data mining tools. When the mining models are validated against validation data, then analysts need to append <b>propensity</b> <b>scores</b> with a database of millions of voters (such databases typically contain information from voter files, census data, and consumer data). While database software offers a strong capacity to store and manipulate a large volume of data, carrying out basic data transformation such as recoding or creating an index by PCA is not easy using database software. I will demonstrate an example of using Stata as a front-end tool to connect to database software, calculate <b>propensity</b> <b>scores</b> using a C++ plug-in, and return the <b>propensity</b> <b>scores</b> back to the database. This approach combines the strengths of three different platforms: the flexibility of Stata as a general statistical package, the speed of C++ to conduct complex calculations, and the capacity of database software to manipulate gigabytes of data with relative ease. ...|$|R
40|$|Methodology for causal {{inference}} {{based on}} <b>propensity</b> <b>scores</b> {{has been developed}} and popularized {{in the last two}} decades. However, the majority of the methodology has concentrated on binary treatments. Only recently have these methods been extended to settings with multi-valued treatments. We propose a number of discrete choice models for estimating the <b>propensity</b> <b>scores.</b> The models di er in terms of exibility with respect to potential correlation between treatments, and, in turn, the accuracy of the estimated <b>propensity</b> <b>scores.</b> We present the e ects of discrete choice models used on performance of the causal estimators through a Monte Carlo study. We also illustrate the use of discrete choice models to estimate the e ect of antipsychotic drug use on the risk of diabetes in a cohort of adults with schizophrenia. Copyright? 2005 John Wiley & Sons, Ltd. KEY WORDS: causal inference; discrete choice models; matching estimator 1...|$|R
3000|$|... hFor the {{logistic}} regression analysis (estimation of <b>propensity</b> <b>scores),</b> we apply a customized and truncated survey weight (for details cf. Sacchi [2011]: 44). For cases with unemployment spells, the panel weight of the first panel wave {{with a record of}} unemployment is used. For the censored cases without unemployment spells up to TREE wave 7 (end of the observation period), we employ the panel weights of this wave. Main results regarding the analysis of scarring effects are the same if no weights are included when estimating the <b>propensity</b> <b>scores.</b>|$|R
50|$|Other {{research}} {{has suggested that}} linking sexuality in media with adolescent sexual behavior is premature. Steinberg and Monahan reanalyzed a dataset of teen sexual behavior (Collins et al.) using <b>propensity</b> <b>score</b> matching and discovered that with other risk factors controlled, viewing sexual media did not predict early onset of sexual behavior in adolescents. The authors concluded that links between media viewing and adolescent sexuality are more tenuous than previous believed.|$|E
5000|$|Since 2000, the Indonesian-German Collaborative Research Center [...] "STORMA" [...] (Stability of the Rainforest Margin in Indonesia) is intensively {{investigating}} Lore Lindu National Park and its buffer zone. [...] STORMA's {{analysis of}} the effect of environmental protection on the level of deforestation in the park, suggests a reduction of the deforestation rate of around 9% as result of the protected areas status of the park. This estimate was based on a methodology involving <b>propensity</b> <b>score</b> matching rather than the conventional satellite image comparison.|$|E
5000|$|Rajeev Dehejia is a {{professor}} of public policy in the Robert F. Wagner Graduate School of Public Service at New York University. He is the author of numerous academic articles in econometrics, labor economics, and development economics, including two widely cited papers on the evaluation of <b>propensity</b> <b>score</b> matching. [...] He graduated in 1988 from Sir Robert Borden High School and in 1992 from Carleton University with the Governor General's Medal. He completed his Ph.D. from Harvard University in 1997.|$|E
40|$|A simple {{shrinkage}} {{method is}} {{proposed to improve}} the performance of weighting estimators of the average treatment effect. As the weights in these estimators can become arbitrarily large for the <b>propensity</b> <b>scores</b> close to the boundaries, three different variants of a shrinkage method for the <b>propensity</b> <b>scores</b> are analyzed. The results of a comprehensive Monte Carlo study demonstrate that this simple method substantially reduces the mean squared error of the estimators in finite samples, and is superior to several popular trimming approaches {{over a wide range}} of settings...|$|R
40|$|Causal {{inference}} with observational studies often {{relies on}} the assumptions of unconfoundedness and overlap of covariate distributions in different treatment groups. The overlap assumption is violated when some units have <b>propensity</b> <b>scores</b> close to 0 or 1, and therefore both practical and theoretical researchers suggest dropping units with extreme estimated <b>propensity</b> <b>scores.</b> However, existing trimming methods ignore the uncertainty in this design stage and restrict inference only to the trimmed sample, due to the non-smoothness of the trimming. We propose a smooth weighting, which approximates the existing sample trimming but has better asymptotic properties. An advantage of the new smoothly weighted estimator is its asymptotic linearity, which ensures that the bootstrap {{can be used to}} make inference for the target population, incorporating uncertainty arising from both the design and analysis stages. We also extend the theory to the average treatment effect on the treated, suggesting trimming samples with estimated <b>propensity</b> <b>scores</b> close to 1. Comment: 21 pages, 1 figures and 3 table...|$|R
40|$|In many {{observational}} studies, researchers estimate causal effects using <b>propensity</b> <b>scores,</b> e. g., {{by matching}} or sub-classifying on the <b>scores.</b> Estimation of <b>propensity</b> <b>scores</b> is complicated when some {{values of the}} covariates are missing. We propose to use multiple imputation to create completed datasets, from which <b>propensity</b> <b>scores</b> can be estimated, with a general location mixture model. The model assumes that the control units are a latent mixture of (i) units whose covariates are drawn from the same distributions as the treated units’ covariates and (ii) units whose covariates are drawn from different distributions. This formulation reduces the influence of control units outside the treated units’ region of the covariate space on the estimation of parameters in the imputation model, which can result in more plausible imputations and better balance in the true covariate distributions. We illustrate the benefits of 1 the latent class modeling approach with simulations and with an observational study {{of the effect of}} breast feeding on children’s cognitive abilities...|$|R
