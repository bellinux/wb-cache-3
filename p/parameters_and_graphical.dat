4|10000|Public
40|$|This thesis {{deals with}} the {{understanding}} of the diffusion tensor imaging and the diffusion kurtosis imaging. In the first part, thesis describes principles of diffusion, estimation of diffusion coefficient with the usage of the MRI and methods DTI and DKI. In practical part, thesis describes simulation model of free and restricted diffusion, the influence of diffusion time and the strength of gradients on diffusion weighted signal. Thesis also describes estimations of confidence intervals of diffusion <b>parameters</b> <b>and</b> <b>graphical</b> representation of them...|$|E
40|$|The chapter {{presents}} {{innovative research}} findings on identification managerial styles {{in the context}} of the leadership based on the Toyota leadership model that was collected in the chosen company from automotive branch. There were used basic statistical <b>parameters</b> <b>and</b> <b>graphical</b> method (box-plot diagrams) to analyze data related to the assessment by the staff of human affairs and production issues in the analysed company. Conceptions of menagerial grids in the scope of directing styles in research object was applied. The results in the scope of classification the importance of human matters and production issues were compared with the so-called Toyota‘s optimum. The purpose of the research was defining whether the examined enterprise is realizng (and in what degree) attempt to leaders improvement (management, managers). Stanisław Borkowsk...|$|E
40|$|ABSTRACT: The {{study focused}} on the {{seasonal}} variation of physiochemical and microbial characteristics of three selected river water in Ebonyi State for human consumption. The three selected rivers studied were Iyioka, Idima and Ubei Rivers. Data were generated using Direct Reading Engineering method (DREM), Gravimetric method, Titrimetric method, Spectrophotometric method, Atomic Absorption Spectrophotometric method, and Total Viable count for physiochemical and microbiological analysis. The generated data was further subjected to statistical analysis using one way analysis of variance (ANOVA) on difference between means of <b>parameters</b> <b>and</b> <b>graphical</b> method to determine the spatial variation of the water quality characteristics. The time variations of the water quality characteristics {{as compared with the}} spatial variations showed that for some variables, there was statistical difference between the means of parameters with respect to time and space at various level...|$|E
40|$|This study {{introduces}} Johnson's SU-normal distribution {{which can}} accommodate {{the flexibility of}} true error distribution to obtain consistent estimates in an endogenous switching regression model. Simulation {{results indicate that the}} SU-normal model outperforms the normal model for the consistency of estimators when the error distribution is nonnormal. Korean housing demand model estimated by the SU-normal model also outperforms the normal model in terms of <b>parameter</b> estimates <b>and</b> <b>graphical</b> predictions. ...|$|R
40|$|In {{this paper}} we {{consider}} two models of quintessence scalar fields with different potentials. Interaction with generalized cosmic Chaplygin gas is also investigated. Cosmological <b>parameters</b> are studied <b>and</b> <b>graphical</b> behavior is analyzed. We find that our model is agree with observational data specially ΛCDM model. Comment: 8 pages, accepted in Int. J. Theor. Phy...|$|R
40|$|In this paper, a {{model for}} {{understanding}} the effects of selection using systems- level computational approaches is introduced. A number of concepts and principles essential for understanding the motivation for constructing the model will be introduced first. This {{will be followed by}} a description of <b>parameters,</b> measurements, <b>and</b> <b>graphical</b> representations used in the model. Four possible outcomes for this model are then introduced and described. In addition, the relationship of relative fitness to selection is described. Finally, the consequences and potential lessons learned from the model are discussed. Comment: 11 pages, 9 figures, 1 tabl...|$|R
40|$|The {{study focused}} on the {{seasonal}} variation of physiochemical and microbial characteristics of three selected river water in Ebonyi State for human consumption. The three selected rivers studied were Iyioka, Idima and Ubei Rivers. Data were generated using Direct Reading Engineering method (DREM), Gravimetric method, Titrimetric method, Spectrophotometric method, Atomic Absorption Spectrophotometric method, and Total Viable count for physiochemical and microbiological analysis. The generated data was further subjected to statistical analysis using one way analysis of variance (ANOVA) on difference between means of <b>parameters</b> <b>and</b> <b>graphical</b> method to determine the spatial variation of the water quality characteristics. The time variations of the water quality characteristics {{as compared with the}} spatial variations showed that for some variables, there was statistical difference between the means of parameters with respect to time and space at various levels of significance. These include Phosphorus (5 %), Copper (1 %), Iron (5 %), Nickel (5 %), Cadmium (1 %), Salinity (1 %), Bacteria (1 %) for time variation; and Sulphate (1 %), Chemical Oxygen (5 %),Nickel (1 %), Arsenic (1 %), Zinc (1 %), Cadmium (1 %), Bacteria (1 %) for spatial variations during dry season and Chemical Oxygen (5 %), Nickel (1 %), for spatial variation during rainy season. Based on the World Health Organization and Standard Organization of Nigeria guidelines for drinking water, the results of microbial analysis also indicated that the selected river waters were polluted with disease causing microorganisms, such as E. Coliform, Salmonella, Bacillus Subtilis. Therefore, the river waters are not good for drinking. The consumers of water obtained from the three rivers are likely to suffer the following: typhoid, fever, intestinal problem, diarrhea, skin rash, cholera. Necessary recommendations such as treating the water with bio-sand filter before use, amongst others, were made...|$|E
40|$|Abstract—This paper {{presents}} a novel Time Varying Dynamic Bayesian Network (TVDBN) {{model for the}} analysis of non-stationary sequences which are of interest in many fields. The changing network structure <b>and</b> <b>parameter</b> in TVDBN are treated as random processes whose values at each time epoch determine a stationary DBN model; this DBN model is then used to specify the distribution of data sequence at the time epoch. Under such a hierarchical formulation, the changing state of network can be incorporated into the Bayesian framework straightforwardly. The network state is assumed to transit smoothly in the joint space of numerical <b>parameter</b> <b>and</b> <b>graphical</b> topology so that we can achieve robust online network learning even without abundant observations. Particle filtering is employed to dynamically update current network state as well as infer hidden data values. We implement our time varying model for data sequences of multinomial and Gaussian distributions, while the general model framework can be used for any other distribution. Simulations on synthetic data and evaluations on video sequences both demonstrate that the proposed TVDBN is effective in modeling non-stationary sequences. Comprehensive comparisons have been made against existing non-stationary models, and our proposed model is shown to be the top performer. Index Terms—Bayesian networks, time varying, particle filters, event recognition. I...|$|R
40|$|Abstract. Based on VB platform, {{a stress}} {{redistribution}} and cutting simulation system of enlarging the hole of coal and rock is developed {{by using the}} computer technology, finite element analysis, the second development, combining with structure <b>parameter</b> selection <b>and</b> Object-Oriented Programming method as well as using VB to encapsulate ANSYS and writing APDL command to call the ANSYS calculation program. The soft provides a convenient <b>parameters</b> input <b>and</b> <b>graphical</b> interface, <b>and</b> has completed the preprocessor simulation solving of the model {{and analysis of the}} results. Even not capable of mastering the finite element theory and FEA soft, users can use the system to perform the stress analysis and simulation when enlarging the hole of coal and rock easily...|$|R
40|$|ParamAP is a {{standalone}} computational {{tool that}} uses a template-free detection algorithm to automatically identify and parameterize sinoatrial myocyte action potentials. ParamAP is written in Python 3 {{and it can be}} run on Windows, Mac OS X, or Ubuntu operating systems. It employs a graphic user interface with automatic and user-editable input modes. ParamAP accepts text input files and returns a total of 16 AP waveform <b>parameters</b> as text <b>and</b> <b>graphical</b> outputs...|$|R
40|$|Theoretical {{part of the}} {{bachelor}} thesis describes ATE systems focused on electrical tests of semiconductor diodes. There are also described key features of measured devices. In the practical part of bachelor thesis, there are described analysis made before design and realization own tester capable of recognizing unknown semiconductor diode and displaying selected static <b>and</b> dynamic <b>parameters</b> via text <b>and</b> <b>graphical</b> output. Whole system is based on Elvis II+ platform. Controlling application is made using MATLAB...|$|R
40|$|Abstract. The {{quantitative}} {{interpretation of}} magnetic anomalies aims at finding out the location, depth, dip, size, and susceptibility contrast of causative geological sources. In this paper an easy method of interpreting magnetic anomalies over simple geometric shapes of dyke, sheet and vertical step {{has been proposed}} by using the easily recognisable characteristic positions on the magnetic anomaly profiles. The method does not require prior knowledge of origin and datum. For determining the source <b>parameters,</b> mathematical expressions <b>and</b> <b>graphical</b> procedure are given...|$|R
40|$|Earthquake risk {{assessment}} {{is probably the}} most effective tool for reducing adverse earthquake effects and for developing pre- and post-event planning actions. The related risk information (data and results) is of interest for persons with different backgrounds and interests, including scientists, emergency planners, decision makers and other stakeholders. Hence, it is important to ensure that this information is properly transferred to all persons involved in seismic risk, considering the nature of the information and the particular circumstances of the source and of the receiver of the information. Some experience-based recommendations about the <b>parameters</b> <b>and</b> the <b>graphical</b> representations {{that can be used to}} portray earthquake risk information to different types of audiences are presented in this work...|$|R
40|$|Abstract Background Quantification of {{ventricular}} volume by Steady State Free Precession (SSFP) cardiovascular {{magnetic resonance}} is accurate and reproducible. Normal values exist for adults, but are lacking for children. We sought to establish normal values for {{left and right}} ventricular volumes, mass and function in healthy children by using SSFP. Methods and results Fifty children (27 females, 23 males) without cardiovascular disease were evaluated. Median age was 11 years (range 7 months – 18 years), weight 35 kg (range 7 – 77 kg), height 146 cm (range 66 – 181 cm). Thirty-six examinations were performed with breath holding, 14 in freely breathing sedated children. Ventricular volumes and mass were measured in the end systolic and end diastolic phase on SSFP cine images acquired in a short axis plane as a stack of 12 contiguous slices covering full length of both ventricles. Regression analysis showed an exponential relationship between body surface area (BSA) and ventricular volumes and mass (normal value = a*BSA b). Normative curves {{for males and females}} are presented in relation to BSA for the enddiastolic volume, endsystolic volume and mass of both ventricles. Intra- and interobserver variability of the measurements was within the limits of 2 % and 7 % respectively, except for right ventricular mass (10 %). Conclusion The exponential equation for calculation of normal values for each ventricular <b>parameter</b> <b>and</b> <b>graphical</b> display of normative curves for data acquired in healthy children by SSFP cardiovascular magnetic resonance are provided. </p...|$|R
40|$|Several {{high-performance}} lab instruments {{suitable for}} manual assembly {{have been developed}} using low-pin-count 32 -bit microcontrollers that communicate with an Android tablet via a USB interface. A single Android tablet app accommodates multiple interface needs by uploading <b>parameter</b> lists <b>and</b> <b>graphical</b> data from the microcontrollers, which are themselves programmed with easily-modified C code. The hardware design of the instruments emphasizes low chip counts and is highly modular, relying on small "daughter boards" for special functions such as USB power management, waveform generation, and phase-sensitive signal detection. In one example, a daughter board provides a complete waveform generator and direct digital synthesizer that fits on a 1. 5 " X 0. 8 " circuit card. Comment: 8 pages, 7 figures. Modified to make minor corrections and remove most mentions of low cost; {{to be published in}} Review of Scientific Instrument...|$|R
40|$|The use of single-receiver single-satellite data {{validation}} <b>parameters</b> for numerical <b>and</b> <b>graphical</b> diagnostics of the multi-frequency observations is presented. This method validates Global Navigation Satellite System (GNSS) measurements {{of a single}} receiver where data from each satellite are independently processed using a geometry-free observation model with a reparameterised form of the unknowns. The method is applicable to any GNSS with any number of frequencies. The diagnostic tools are based on checking agreement of characteristics of the validation test statistics against theory. The use of these diagnostics in static and kinematic modes is demonstrated using multiple-frequency data from the three GNSS constellations; Global Positioning System (GPS), Globalnaya Navigatsionnaya Sputnikovaya Sistema (GLONASS) and Galileo...|$|R
40|$|AbstractThis paper {{reports a}} precise design and {{development}} for ecg signal generator for testing and calibration of the electrocardiogram equipment, ecg signal processing system and heart teaching tool. It can create a guide II signal of time and profile features lead II signal {{across a range of}} ecg drawings of heart rate within 45 to 185 devices in the first device of steps. This can be set up 15 ∼ the QRS 45 years old lady with a lady who resolution. P, T wave amplitude can be adjusted from 1 - 100 % to 1 % of the total of the amplitude QRS complex resolution. A color LCD touch screen is able to provide the user with input parameters facilities, depending on the output waveform <b>parameter</b> <b>and</b> a <b>graphical</b> representation of the output waveform. Signal generator outputting signal of poor precision through digital simulation stage using low noise design provides accurate signal amplitude QRS {{the lower end of the}} technology range...|$|R
40|$|The {{structural}} {{electronic and}} optical properties of intermetallic compound MgRh were investigated {{by using the}} ab-initio technique from CASTEP code. In this study we have carried out the pseudo-potential plane-wave (PP-PW) method based on the density functional theory (DFT), within the generalized gradient approximation (GGA). Our calculated structural <b>parameters</b> <b>and</b> corresponding <b>graphical</b> values fit with other previous available experimental data and other theoretical observations. The calculated electronic band structure reveals metallic conductivity and the major contribution comes from Rh-d states. Comparison between our investigated properties and experimental data shows good agreement. The optical functions (dielectric functions, refractive index, absorption spectrum, conductivity, energy loss spectrum and reflectivity) have been calculated and discussed. This is the first quantitative prediction of the electronic and optical properties of intermetallic compound MgRh alloy, since {{it has not been}} reported yet. The calculated optical functions reveal that the reflectivity is high in the ultraviolet region up to 73 eV for MgRh, showing this to be promising coating materials. Comment: 7 pages, 4 figure...|$|R
40|$|We {{examine the}} {{asymptotic}} efficiency of OLS and IV estimators {{in a simple}} dynamic structural model with a constant and two explanatory variables: the lagged dependent variable and an explanatory variable, which is also autoregressive and may include lagged or instantaneous feedbacks from the dependent variable. The parameter values are such that all variables are stationary. We express the asymptotic efficiency of OLS and various IV estimators via the moments of the data series in the model <b>parameters.</b> Various computational <b>and</b> <b>graphical</b> aids are employed to examine and illustrate the relationships between parameter values, instrument weakness, and estimator efficiency. Symbolic computer algebra and image sequences are used in animations to identify regions in the parameter space where consistent IV estimators may be less efficient than inconsistent OLS estimators, upon comparing the asymptotic approximation to their mean squared errors...|$|R
40|$|We {{present a}} three-part bilingual {{specialized}} dictionary Mexican Sign Language-Spanish / Spanish-Mexican Sign Lan-guage. This dictionary {{will be the}} outcome of a three-years agreement between the Italian “Consiglio Nazionale delle Ricerche ” and the Mexican Conacyt. Although many other sign language dictionaries have been provided to deaf commu-nities, there are no Mexican Sign Language dictionaries in Mexico, yet. We want to stress on the specialized feature of the proposed dictionary: the bilingual dictionary will contain frequently used general Spanish forms along with scholastic course specific specialized words whose meanings warrant comprehension of school curricula. We emphasize that this aspect of the bilingual dictionary can have a deep social impact, since we will furnish to deaf people the possibility to get competence in official language, which is necessary to ensure access to school curriculum and to become full-fledged citizens. From a technical point of view, the dictionary consists of a relational database, where we have saved the sign <b>parameters</b> <b>and</b> a <b>graphical</b> user interface especially designed to allow deaf children to retrieve signs using the relevant parameters and,thus, the meaning of the sign in Spanish. 1...|$|R
40|$|Graphical {{model has}} been widely used to {{investigate}} the complex dependence structure of high-dimensional data, and {{it is common to}} assume that observed data follow a homogeneous graphical model. However, observations usually come from different resources and have heterogeneous hidden commonality in real-world applications. Thus, it is of great importance to estimate heterogeneous dependencies and discover subpopulation with certain commonality across the whole population. In this work, we introduce a novel regularized estimation scheme for learning nonparametric mixture of Gaussian graphical models, which extends the methodology and applicability of Gaussian <b>graphical</b> models <b>and</b> mixture models. We propose a unified penalized likelihood approach to effectively estimate nonparametric functional <b>parameters</b> <b>and</b> heterogeneous <b>graphical</b> <b>parameters.</b> We further design an efficient generalized effective EM algorithm to address three significant challenges: high-dimensionality, non-convexity, and label switching. Theoretically, we study both the algorithmic convergence of our proposed algorithm and the asymptotic properties of our proposed estimators. Numerically, we demonstrate the performance of our method in simulation studies and a real application to estimate human brain functional connectivity from ADHD imaging data, where two heterogeneous conditional dependencies are explained through profiling demographic variables and supported by existing scientific findings...|$|R
40|$|This Project Document Describes The Salient Features And Validation Of A Software Package Called "HELI-HQPACK" Which Has Been Developed At The FMC Division, NAL, Under A Granting- Aid Scheme Of The Operational Problems And Airworthiness Panel, AR&DB, New Delhi. The Software Can Be Used For The Evaluation Of The Quantitative Handling Qualities Requirements Of Helicopters Specified In The Aeronautical Design Standard ADS- 33 E. The Software Package, Developed In MATLAB, Is Modular In Structure And GUI Based. A Demonstration Program And On-Screen Help Messages Are Included In The Software To Help A New User. The Input Data, In The Form Of Input-Output Time Histories, Can Be Loaded Either Manually Or In Automatic Mode. The Numerical Output Comprising Of The Values Of The Handling Qualities <b>Parameters,</b> <b>And</b> The <b>Graphical</b> Output Comprising Of Handling Qualities Level Plots Are Stored Automatically In Specific Files. Using The Software Even A Large Amount Of Flight Test Data Can Be Evaluated Quickly And Efficiently. The Software Has Been Validated Using The BO 105 Helicopter Flight Test Data Obtained From The Rotorcraft Branch, Institute Of Flight Systems, DLR, Germany And The Results Are Documented In This Report...|$|R
40|$|This Project Document {{describes}} the salient features and validation of a software package called quot;HELI-HQPACKquot; {{which has been}} developed at the FMC Division, NAL, under a grant- in-aid scheme of the Operational Problems and Airworthiness Panel, ARamp;DB, New Delhi. The software {{can be used for}} the evaluation of the quantitative handling qualities requirements of helicopters specified in the Aeronautical Design Standard ADS- 33 E. The software package, developed in MATLAB, is modular in structure and GUI based. A demonstration program and on-screen help messages are included in the software to help a new user. The input data, in the form of input-output time histories, can be loaded either manually or in automatic mode. The numerical output comprising of the values of the handling qualities <b>parameters,</b> <b>and</b> the <b>graphical</b> output comprising of handling qualities level plots are stored automatically in specific files. Using the software even a large amount of flight test data can be evaluated quickly and efficiently. The software has been validated using the BO 105 helicopter flight test data obtained from the Rotorcraft Branch, Institute of Flight Systems, DLR, Germany and the results are documented in this report...|$|R
40|$|Geophysical Research Abstracts, Vol. 11, EGU 2009 - 5699, 2009 EGU General Assembly 2009 © Author(s) 2009 A {{new version}} of "Boxer" code for the {{determination}} of seismic source parameters from macroseismic data. P. Gasperini (1), G. Vannucci (2), and D. Tripone (3) (1) Dipartimento di Fisica, Università di Bologna, Viale Berti-Pichat 8, I- 40127 Bologna (Italy), paolo. gasperini@unibo. it, (2) INGV-Istituto Nazionale di Geofisica e Vulcanologia, Via Donato Creti, 12, I- 40128, Bologna (Italy), (vannucci@bo. ingv. it), (3) INGV-Istituto Nazionale di Geofisica e Vulcanologia, Via Donato Creti, 12, I- 40128, Bologna (Italy), (tripone@bo. ingv. it) About {{ten years after the}} first release of the code we implemented new methods of epicentral location and magnitude computation as well as a procedure for the evaluation of uncertainties by the bootstrap technique. We also developed a user-friendly interface for <b>parameter</b> setup <b>and</b> <b>graphical</b> post-processing of the results. The improved code allows to locating epicenters in the sea or in uninhabited areas by minimizing the norm of the residuals of an attenuation equation. The same approach also per-mits, in the most favorable cases, the estimation of the source depth. By the geographical rendering of the bootstrap solutions we give a tool for characterizing the possible multiplicity of the seismic source of historical earthquakes...|$|R
40|$|AbstractFor a given open channel, {{solving the}} {{kinematic}} wave equation with flow depth-independent kinematic wave parameters {{is very common}} due to its simplicity. The kinematic wave parameters cannot be analytically estimated independently of the flow depth, except for some special cross-sections. In this research, approximate depth-independent kinematic parameters are derived, based on Manning equation for trapezoidal, rectangular, and parabolic channels. The estimation method {{is based on the}} kinematic point-sensitivity indicator and regression fitting methods. The estimated <b>parameters</b> were verified <b>and</b> <b>graphical</b> aids for practical applications are presented. Since the presented kinematic wave parameters are independent of the flow depth, they are useful for kinematic wave modeling. For system-specific conditions, such as a desired range of flow depth, the effective-sensitivity method would be preferable to the full range of kinematic wave parameters presented by other researchers as it would easily produce local <b>and</b> more relevant <b>parameters...</b>|$|R
40|$|This {{discussion}} paper {{led to a}} publication in 'Computational Statistics & Data Analysis', 49 (2), 417 - 44. We examine the asymptotic efficiency of OLS and IV estimators in a simple dynamic structural model with a constant and two explanatory variables: the lagged dependent variable and an explanatory variable, which is also autoregressive and may include lagged or instantaneous feedbacks from the dependent variable. The parameter values are such that all variables are stationary. We express the asymptotic efficiency of OLS and various IV estimators via the moments of the data series in the model <b>parameters.</b> Various computational <b>and</b> <b>graphical</b> aids are employed to examine and illustrate the relationships between parameter values, instrument weakness, and estimator efficiency. Symbolic computer algebra and image sequences are used in animations to identify regions in the parameter space where consistent IV estimators may be less efficient than inconsistent OLS estimators, upon comparing the asymptotic approximation to their mean squared errors. asymptotic efficiency comparisons; computational visualization; dynamic simultaneous models; instrument weakness...|$|R
40|$|Background: Two-dimensional data {{colourings}} are {{an effective}} medium {{by which to}} represent three-dimensional data in two dimensions. Such "color-grid" representations have found increasing use in the biological sciences (e. g. microarray 'heat maps' and bioactivity data) as they are particularly suited to complex data sets and offer {{an alternative to the}} graphical representations included in traditional statistical software packages. The effectiveness of color-grids lies in their graphical design, which introduces a standard for customizable data representation. Currently, software applications capable of generating limited color-grid representations can be found only in advanced statistical packages or custom programs (e. g. micro-array analysis tools), often associated with steep learning curves and requiring expert knowledge. Results: Here we describe JColorGrid, a Java library and platform independent application that renders color-grid graphics from data. The software {{can be used as a}} Java library, as a command-line application, and as a color-grid <b>parameter</b> interface <b>and</b> <b>graphical</b> viewer application. Data, titles, and data labels are input as tab-delimited text files or Microsoft Excel spreadsheets and the color-grid settings are specified through the graphical interface or a text configuration file. JColorGrid allows both user graphical data exploration as well as a means of automatically rendering color-grids from data as part of research pipelines. Conclusion: The program has been tested on Windows, Mac, and Linux operating systems, and the binary executables and source files are available for download at [URL]...|$|R
40|$|AbstractIn this paper, we {{introduce}} a nonhomogeneous unreliable multiserver system with Markovian arrival, service, breakdown, and repair processes. First, {{we consider the}} case with only one queue and different servers and the job is assigned to one server. Then, we extend this model {{to more than one}} queue in which the jobs are assigned to different queues. We assume that our system has different servers with different service times and a job is assigned to a server using the following strategies: FFS (fastest free server) or random selection. FFS strategy means that the job is served by the fastest available server, and if this server is busy then the job goes to the next available server and so on. In the random strategy, the job is served by one of the free servers which is chosen randomly. In our problem, we consider a general queuing system (M/M/n) with a finite number of jobs K in the whole system. Our system is unreliable; this means that we need to specify the <b>parameters,</b> mtbf <b>and</b> mttr (mean time between failures and mean time to repair), and we need to consider the possibility that a server might be up or down at some point in time. The performance. modelling of this type, of system is done using the programming language MOSEL (Modelling Specification and Evaluation Language), which contains several constructs to describe the system, the results (performance <b>parameters),</b> <b>and</b> the <b>graphical</b> representation...|$|R
40|$|Abstract Background Two-dimensional data {{colourings}} are {{an effective}} medium {{by which to}} represent three-dimensional data in two dimensions. Such "color-grid" representations have found increasing use in the biological sciences (e. g. microarray 'heat maps' and bioactivity data) as they are particularly suited to complex data sets and offer {{an alternative to the}} graphical representations included in traditional statistical software packages. The effectiveness of color-grids lies in their graphical design, which introduces a standard for customizable data representation. Currently, software applications capable of generating limited color-grid representations can be found only in advanced statistical packages or custom programs (e. g. micro-array analysis tools), often associated with steep learning curves and requiring expert knowledge. Results Here we describe JColorGrid, a Java library and platform independent application that renders color-grid graphics from data. The software {{can be used as a}} Java library, as a command-line application, and as a color-grid <b>parameter</b> interface <b>and</b> <b>graphical</b> viewer application. Data, titles, and data labels are input as tab-delimited text files or Microsoft Excel spreadsheets and the color-grid settings are specified through the graphical interface or a text configuration file. JColorGrid allows both user graphical data exploration as well as a means of automatically rendering color-grids from data as part of research pipelines. Conclusion The program has been tested on Windows, Mac, and Linux operating systems, and the binary executables and source files are available for download at [URL]. </p...|$|R
40|$|This study {{presents}} {{validation of}} BeiDou measurements in un-differenced standalone mode and experimental results of its application for real data. A reparameterized {{form of the}} unknowns in a geometry-free observation model was used. Observations from each satellite are independently screened using a local modeling approach. Main advantages include {{that there is no}} need for computation of inter-system biases and no satellite navigation information are needed. Validation of the triple-frequency BeiDou data was performed in static and kinematic modes, the former at two continuously operating reference stations in Australia using data that span two consecutive days and the later in a walking mode for three hours. The uses of the validation method <b>parameters</b> for numerical <b>and</b> <b>graphical</b> diagnostics of the multi-frequency BeiDou observations are discussed. The precision of the system’s observations was estimated using an empirical method that utilizes the characteristics of the validation statistics. The capability of the proposed method is demonstrated in detection and identification of artificial errors inserted in the static BeiDou data and when implemented in a single point positioning processing of the kinematic test...|$|R
40|$|The {{calibration}} {{and execution}} of large hydrological models, such as SWAT (soil and water assessment tool), developed for large areas, high resolution, and huge input data, need not only quite a long execution time but also high computation resources. SWAT hydrological model supports studies and predictions {{of the impact of}} land management practices on water, sediment, and agricultural chemical yields in complex watersheds. The paper presents the gSWAT application as a web practical solution for environmental specialists to calibrate extensive hydrological models and to run scenarios, by hiding the complex control of processes and heterogeneous resources across the grid based high computation infrastructure. The paper highlights the basic functionalities of the gSWAT platform, and the features of the graphical user interface. The presentation is concerned with the development of working sessions, interactive control of calibration, direct and basic editing of <b>parameters,</b> process monitoring, <b>and</b> <b>graphical</b> <b>and</b> interactive visualization of the results. The experiments performed on different SWAT models and the obtained results argue the benefits brought by the grid parallel and distributed environment as a solution for the processing platform. All the instances of SWAT models used in the reported experiments have been developed through the enviroGRIDS project, targeting the Black Sea catchment area...|$|R
40|$|The {{objective}} {{of this research was}} to develop a building thermal analysis and air quality predictive (BTA-AQP) model to predict indoor climate and long-term air quality (NH 3, H 2 S and CO 2 concentrations and emissions) for swine deep-pit buildings. The paper presents the development of the BTA-AQP model using a building thermal transient model, artificial neural networks, and typical meteorological year (TMY 3) data in predicting long-term air quality trends. The good model performance ratings (MSE/S. D. 3 ̆c 0. 5, CRM˜ 0; IoA˜ 1; and Nash-Sutcliffe EF 3 ̆e 0. 5 for all the predicted <b>parameters)</b> <b>and</b> the <b>graphical</b> presentations reveal that the BTA-AQP model was able to accurately forecast indoor climate and gas concentrations and emissions for swine deep-pit buildings. By comparing the air quality results simulated by the BTA-AQP model using the TMY 3 data set with those from a five-year local weather data set, {{it was found that the}} TMY 3 -based predictions followed the long-term mean patterns well, which indicates that the TMY 3 data could be used to represent the long-term expectations of source air quality. Future work is needed to improve the accuracy of the BTA-AQP model in terms of four main sources of error: (1) Uncertainties in air quality data; (2) Prediction errors of the BTA model; (3) Prediction errors of the AQP model, and (4) Bias errors of the TMY 3 and its limited application...|$|R
40|$|This paper {{answers to}} the {{question}} if is possible to simulate satellite networks in Network Simulator (NS- 2). We describe its functionality such as types of nodes, kinds of satellite links and handoffs. Also are presented two real satellite networks, Iridium and Teledesic, compared their <b>parameters</b> <b>and</b> simulation results. Numerical <b>and</b> <b>graphical</b> outputs are presented to show how satellite networks work...|$|R
40|$|In many cases, it is {{important}} to predict water production performance of oil wells early in, or maybe before, their production life. In as much as oil field water {{is important}} for pressure maintenance purposes and displacement of oil towards the perforation of the producing well, excessive water production leads to increased cost. In the case when no provision is made, it represents a significant liability. The case considered here is a well producing from a monocline with an edge-water aquifer. Although such problems can be computed with reservoir simulation, the objective of this work was to develop an empirical method of making water production predictions. The reservoir model was described as a single well producing from the top of a monocline drainage block with water drive from an infinite-acting aquifer. During the reservoir simulation runs, water would cusp and cone into the well, increasing water production and decreasing oil production. A number of simulation runs were made, varying eleven model variables. Typical model variables include dip angle, formation thickness and production rate. For each run a modified Addington-style plot was made. The relationship between each model <b>parameter</b> <b>and</b> three <b>graphical</b> variables was used to develop the set of empirical correlations. The empirical correlations developed were integrated with some derived equations that relate important reservoir <b>parameters</b> <b>and</b> incorporated into a computer program. The developed correlations and program can be used to carry out sensitivity analysis to evaluate various scenarios at the early planning stages when available reservoir data are limited. This gives a quick and easy method for forecasting production performance with an active edge-water drive. Furthermore, the approach developed in the research can be applied to other water production problems in other fields/reservoirs. The developed program was validated and used to evaluate synthetic and field cases. Overall, a good match was achieved...|$|R
40|$|Learning Dynamics through Computational Experiments (LDCE) is {{a method}} that can achieve better results in basic {{engineering}} Dynamics courses. This method is a Problem Based Learning (PBL) approach, where students seek for knowledge by developing projects during the course. Projects include one or more experiments through which students can learn how a dynamics problem works. They are able to modify <b>parameters</b> <b>and</b> retrieve <b>graphical</b> <b>and</b> numerical results. Their primary task is to develop the theoretical basis of the problems and compare the numerical results with those produced by the experiments. To accommodate {{a large number of}} students simultaneously accessing such experiments, a HPC (High Performance Computing) server cluster will be developed and implemented. The cluster will also help for those experiments that are computational intensive. The students will be using a web browser on their own device, where the parameters of the experiment can be modified by a client application. The client sends input data to a HPC server cluster simulation application that runs the experiment. The server sends output data back to the student’s device where the web browser shows motion and numerical results of the experiment. The implementation of a time-based collision physics engine on the server cluster uses parallel programming techniques for multi core processors. The HPC server cluster approach allows the development of different clients on many different platforms. This paper will show the details of the implementation of both, the client and the server applications as well as how the data interchanges between them. The paper will also illustrate the behavior of the system with some experiments. The development of the system includes only open source free software. The complete software package will be of both free distribution and access...|$|R
40|$|AbstractA {{spirometer}} is {{used for}} basic lung function test for preliminary diagnosis of respiratory diseases. There are significant amount of calculations <b>and</b> <b>graphical</b> analysis required to transform the raw spirometric data into meaningful <b>parameters.</b> This <b>parameters</b> <b>and</b> graphs help the physicians in preliminary patient diagnosis for respiratory disorders like asthma, chronic obstructive pulmonary disease, etc. This study was undertaken {{for the development of}} a software system which can be used with any spirometric instrument to automate the calculations of pulmonary dead space volumes and analysis of raw data. The clinician can feed the raw data from patient testing into the easy to use graphical user interface of the software which will be analyzed instantly <b>and</b> all the <b>parameters,</b> regression slopes, shape analysis plots and the results will be displayed graphically. The estimation of the vital <b>parameters</b> <b>and</b> regression slopes are based on standard protocols and equations. This system will eliminate presently practiced time consuming manual calculations <b>and</b> <b>graphical</b> analysis; will have increased precision, be considerably faster and more versatile...|$|R
