1|1|Public
40|$|In this paper, {{we present}} our {{recently}} developed timesynchronous speech recognition decoder, which adopts {{the idea of}} representing the search space of Large Vocabulary Continuous Speech Recognition (LVCSR) in a single <b>precompiled</b> <b>network.</b> In particular, we outline our approaches for time and memory efficient Viterbi decoding in this scenario. This includes reducing the fast memory needs by keeping the search network on disk and only loading the required parts on demand. Evaluations are carried out on a difficult Japanese LVCSR task which involves a back-off trigram language model and full cross-word dependent triphone acoustic models. Time and memory efficiency enables the real-time Viterbi decoding of entire lecture speeches in a single time-synchronous pass with a search error of less than 1 %...|$|E
40|$|A {{simulator}} for connectionist networks {{which uses}} gradient methods of nonlinear optimization for network learning is described. The simulator (GRADSIM) {{was designed for}} temporal flow model connectionist networks. The complete gradient is computed for networks of general connectivity, including recurrent links. The simulator is written in C, uses simple network and data descriptors for flexibility, and is easily modified for new applications. A version of the simulator which <b>precompiles</b> the <b>network</b> objective function and gradient computations for greatly increased processing speed is also described. Benchmark results for the simulator running on the DEC VAX 8650, SUN 3 / 260 and CYBER 205 are presented...|$|R

