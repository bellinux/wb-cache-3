6861|711|Public
5|$|In 1933 Andrei Kolmogorov {{published}} in German {{his book on}} the foundations of <b>probability</b> <b>theory</b> titled Grundbegriffe der Wahrscheinlichkeitsrechnung, where Kolmogorov used measure theory to develop an axiomatic framework for <b>probability</b> <b>theory.</b> The publication of this book is now widely {{considered to be the}} birth of modern <b>probability</b> <b>theory,</b> when the theories of probability and stochastic processes became parts of mathematics.|$|E
5|$|Random {{matrices}} are matrices whose {{entries are}} random numbers, subject to suitable probability distributions, such as matrix normal distribution. Beyond <b>probability</b> <b>theory,</b> they are applied in domains ranging from number theory to physics.|$|E
5|$|After the {{publication}} of Kolmogorov's book, further fundamental work on <b>probability</b> <b>theory</b> and stochastic processes was done by Khinchin and Kolmogorov {{as well as other}} mathematicians such as Joseph Doob, William Feller, Maurice Fréchet, Paul Lévy, Wolfgang Doeblin, and Harald Cramér.|$|E
5000|$|In {{deductive}} <b>probability</b> <b>theories,</b> <b>probabilities</b> are absolutes, {{independent of}} the individual making the assessment. But deductive probabilities are based on, ...|$|R
50|$|While laws {{might only}} {{describe}} a correlation (with a given <b>probability),</b> <b>theories</b> explain them.|$|R
40|$|AbstractA {{survey of}} the {{algebraic}} and the statistical properties of sharp and unsharp quantum effects is presented. We begin with a discussion and a comparison of four types of <b>probability</b> <b>theories,</b> the sharp and unsharp classical and quantum theories. A structure called an effect algebra that generalizes and unifies all four of these <b>probability</b> <b>theories,</b> is then considered. Finally, we present some recent investigations on tensor products and quotients of effect algebras. Examples and representative results for the various theories are discussed...|$|R
5|$|Author {{of around}} 170 {{scientific}} articles and books, Steinhaus has left his legacy and contribution in many branches of mathematics, such as functional analysis, geometry, mathematical logic, and trigonometry. Notably he {{is regarded as}} one of the early founders of game theory and <b>probability</b> <b>theory</b> which led to later development of more comprehensive approaches by other scholars.|$|E
5|$|In October 1906, Keynes's Civil Service {{career began}} as a clerk in the India Office. He enjoyed his work at first, but by 1908 had become bored and {{resigned}} his position to return to Cambridge and work on <b>probability</b> <b>theory,</b> at first privately funded only by two dons at the university – his father and the economist Arthur Pigou.|$|E
5|$|Martingales {{have many}} {{applications}} in statistics, {{but it has}} been remarked that its use and application are not as widespread as it could be in the field of statistics, particularly statistical inference. They have found applications in areas in <b>probability</b> <b>theory</b> such as queueing theory and Palm calculus and other fields such as economics and finance.|$|E
40|$|Introduction The {{study of}} human {{judgment}} under uncertainty has a history that is almost contemporaneous with that of <b>probability</b> <b>theories.</b> This is not a coincidence. From the outset, {{the idea of using}} probability to describe cognitive states or aspects of subjective judgment has provoked debate, theory construction, and empirical research. It is no exaggeration to say that <b>probability</b> <b>theories</b> have exerted a strong prescriptive influence on the study of judgment and decision making (see Gigerenzer 1994 [21] and Smithson 1989 [41] for overviews). In the modern era, proponents of the Subjective Expected Utility (SEU) framework advocated a version of Bayesianism as the benchmark for rational judgment and decision making, and this viewpoint dominated studies of human judgment and decision making during the 50 's and 60 's. By the late 70 's and early 80 's, some scholars had begun to question whether we should regard deviations from <b>probability</b> <b>theories</b> as "irrational" (cf. Cohen 198...|$|R
50|$|This list {{could be}} {{expanded}} to include most fields of mathematics, including measure <b>theory,</b> ergodic <b>theory,</b> <b>probability,</b> representation <b>theory,</b> and differential geometry.|$|R
40|$|Eventologically multivariate {{extensions}} of <b>probability</b> <b>theory’s</b> limit theorems are proposed. Eventologically multivariate version of limit theorems extends its classical probabilistic interpretation and involves into its structure of dependencies of arbitrary set of events which appears in sequence of independent tests. ...|$|R
5|$|After World War II {{the study}} of <b>probability</b> <b>theory</b> and {{stochastic}} processes gained more attention from mathematicians, with signification contributions made {{in many areas of}} probability and mathematics as well as the creation of new areas. Starting in the 1940s, Kiyosi Itô published papers developing the field of stochastic calculus, which involves stochastic integrals and stochastic differential equations based on the Wiener or Brownian motion process.|$|E
5|$|Applications of {{matrices}} {{are found}} in most scientific fields. In every branch of physics, including classical mechanics, optics, electromagnetism, quantum mechanics, and quantum electrodynamics, {{they are used to}} study physical phenomena, such as the motion of rigid bodies. In computer graphics, they are used to manipulate 3D models and project them onto a 2-dimensional screen. In <b>probability</b> <b>theory</b> and statistics, stochastic matrices are used to describe sets of probabilities; for instance, they are used within the PageRank algorithm that ranks the pages in a Google search. Matrix calculus generalizes classical analytical notions such as derivatives and exponentials to higher dimensions. Matrices are used in economics to describe systems of economic relationships.|$|E
5|$|The {{second part}} expands on enumerative combinatorics, or the {{systematic}} numeration of objects. It {{was in this}} part {{that two of the}} most important of the twelvefold ways—the permutations and combinations that would form the basis of the subject—were fleshed out, though they had been introduced earlier for the purposes of <b>probability</b> <b>theory.</b> He gives the first non-inductive proof of the binomial expansion for integer exponent using combinatorial arguments. On a note more distantly related to combinatorics, the second section also discusses the general formula for sums of integer powers; the free coefficients of this formula are therefore called the Bernoulli numbers, which influenced Abraham de Moivre's work later, and which have proven to have numerous applications in number theory.|$|E
50|$|The {{allowance}} for imprecision, or {{a gap between}} a decision maker's upper and lower previsions, is the primary difference between precise and imprecise <b>probability</b> <b>theories.</b> Interestingly, such gaps arise naturally in betting markets which happen to be financially illiquid due to asymmetric information.|$|R
30|$|In {{order to}} {{implement}} a highly parallelized MV algorithm, <b>probability</b> <b>theories</b> and linear algebra theories were used to optimize the detailed implementation and reduce the computation operations. The integration of the mathematical theories into the implementation will be described in the following three parts.|$|R
5000|$|Alan Hájek (foundations of <b>probability,</b> {{decision}} <b>theory,</b> etc.) ...|$|R
25|$|A lively {{introduction}} to <b>probability</b> <b>theory</b> for the beginner.|$|E
25|$|This {{raises the}} broader {{question}} of the relation of <b>probability</b> <b>theory</b> to inductive reasoning. Karl Popper argued that <b>probability</b> <b>theory</b> alone cannot account for induction. His argument involves splitting a hypothesis, , into a part that is deductively entailed by the evidence, , and another part. This {{can be done in}} two ways.|$|E
25|$|Factorials {{are also}} used {{extensively}} in <b>probability</b> <b>theory.</b>|$|E
40|$|The {{study of}} human {{judgment}} under uncertainty has a history that is almost contemporaneous with that of <b>probability</b> <b>theories.</b> This is not a coincidence. From the outset, {{the idea of using}} probability to describe cognitive states or aspects of subjective judgment has provoked debate, theory construction, and empirica...|$|R
50|$|The {{subject matter}} {{includes}} geometry, combinatorics, counting, <b>probability,</b> number <b>theory,</b> and algebra.|$|R
40|$|AbstractThis paper {{focuses on}} a general setup for obtaining sample size lower bounds for {{learning}} concept classes under fixed distribution laws in an extended PAC learning framework. These bounds do {{not depend on the}} running time of learning procedures and are information-theoretic in nature. They are based on incompressibility methods drawn from Kolmogorov Complexity and Algorithmic <b>Probability</b> <b>theories...</b>|$|R
25|$|An empiricist, Bayesian {{approach}} to the foundations of <b>probability</b> <b>theory.</b>|$|E
25|$|The {{difference}} {{in point of}} view between classic <b>probability</b> <b>theory</b> and sampling theory is, roughly, that <b>probability</b> <b>theory</b> starts from the given parameters of a total population to deduce probabilities that pertain to samples. Statistical inference, however, moves in the opposite direction—inductively inferring from samples to the parameters of a larger or total population.|$|E
25|$|Certain random {{variables}} occur very often in <b>probability</b> <b>theory</b> because they well describe many natural or physical processes. Their distributions therefore have gained special importance in <b>probability</b> <b>theory.</b> Some fundamental discrete distributions are the discrete uniform, Bernoulli, binomial, negative binomial, Poisson and geometric distributions. Important continuous distributions include the continuous uniform, normal, exponential, gamma and beta distributions.|$|E
40|$|Abstract- When Shafer {{introduced}} {{his theory of}} evidence based {{on the use of}} belief functions, he proposed a rule to combine belief functions induced by distinct pieces of evidence. Since then, theoretical justifications of this socalled Dempster’s rule of combination have been produced and the meaning of distinctness has been assessed. We will present practical applications where the fusion of uncertain data is well achieved by Dempster’s rule of combination. It is essential that the meaning of the belief functions used to represent uncertainty be well fixed, as the adequacy of the rule depends strongly on a correct understanding of the context in which they are applied. Missing to distinguish between the upper and lower <b>probabilities</b> <b>theory</b> and the transferable belief model can lead to serious confusion, as Dempster’s rule of combination is central in the transferable belief model whereas it hardly fits with the upper and lower <b>probabilities</b> <b>theory...</b>|$|R
40|$|Language {{models for}} {{automatic}} speech recognition are used for computing <b>probabilities</b> of <b>theories</b> corresponding to partial interpretations of sentences. Algorithms {{have been developed for}} computing these <b>probabilities</b> when <b>theories</b> grow in a strictly left-to-right fashion. This paper introduces a new framework for the computation of <b>probabilities</b> of <b>theories</b> that contain a gap corresponding to an uninterpreted signal segment. Algorithms have been developed and their complexity is here derived. The use of these algorithms in an island-driven parser is also discussed. INTRODUCTION Automatic Speech Understanding (ASU) is based on a search process that generates partial interpretations of a spoken sentence called theories and scores them {{on the basis of their}} likelihood L = O(Pr(A j th) Pr(th)), where Pr(A j th) is the <b>probability</b> that <b>theory</b> th derives the acoustic signal segment A and Pr(th) is the probability of the obtained theory. We are interested in the computation of Pr(th) when [...] ...|$|R
40|$|Typically, human {{decision}} making is emotionally "hot" and does not conform to "cold" classical <b>probability</b> (CP) <b>theory.</b> As quantum <b>probability</b> (QP) <b>theory</b> emphasises order, context, superimposition states, and nonlinear dynamic effects, one of its major strengths may be its power to unify formal modeling and realistic psychological theory (e. g., information uncertainty, anxiety, and indecision, {{as seen in the}} Prisoner's Dilemma) ...|$|R
25|$|Discrete <b>probability</b> <b>theory</b> {{deals with}} events {{that occur in}} {{countable}} sample spaces.|$|E
25|$|A lively {{introduction}} to <b>probability</b> <b>theory</b> for the beginner, Cambridge Univ. Press.|$|E
25|$|Continuous <b>probability</b> <b>theory</b> {{deals with}} events {{that occur in}} a {{continuous}} sample space.|$|E
40|$|This article {{deals with}} the nature of the objective-subjective dichotomy, first from a general {{historical}} point of view, and then with regard to the use of these terms over time to describe <b>theories</b> of <b>probability.</b> The different (metaphysical and epistemological) meanings of “objective” and “subjective” are analyzed, and then used to show that all <b>probability</b> <b>theories</b> can be divided into three broad classes...|$|R
40|$|Quantum <b>probability</b> (QP) <b>theory</b> {{provides}} an alternative account of empirical phenomena {{in decision making}} that classical <b>probability</b> (CP) <b>theory</b> cannot explain. Cognitive architectures combine probabilistic mechanisms with symbolic knowledge-based representations (e. g., heuristics) to address effects that motivate QP. They provide simple and natural explanations of these phenomena based on general cognitive processes such as memory retrieval, similarity-based partial matching, and associative learning...|$|R
40|$|When Shafer {{introduced}} {{his theory of}} evidence based {{on the use of}} belief functions, he proposed a rule to combine belief functions induced by distinct pieces of evidence. Since then, theoretical justifications of this socalled Dempster's rule of combination have been produced and the meaning of distinctness has been assessed. We will present practical applications where the fusion of uncertain data is well achieved by Dempster's rule of combination. It is essential that the meaning of the belief functions used to represent uncertainty be well fixed, as the adequacy of the rule depends strongly on a correct understanding of the context in which they are applied. Missing to distinguish between the upper and lower <b>probabilities</b> <b>theory</b> and the transferable belief model can lead to serious confusion, as Dempster's rule of combination is central in the transferable belief model whereas it hardly fits with the upper and lower <b>probabilities</b> <b>theory.</b> Keywords: belief function, transferable beli [...] ...|$|R
