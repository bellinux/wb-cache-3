0|7268|Public
40|$|This paper explores a {{wide range}} of {{opportunities}} for the interworking of the ATM signaling and routing mechanisms of B-ISUP/BICI-based public and PNNIbased <b>private</b> broadband <b>networks.</b> A spectrum of interworking scenarios is presented that ranges from simple virtual PVC tunneling to evolution of the public network to include PNNI capabilities. 1. Introduction The ATM Forum recently released the PNNI Version 1. 0 [1] specification for a new network signaling and routing protocol for use at the <b>interface</b> between two <b>private</b> <b>network</b> switches. The two switches can be in the same <b>private</b> <b>network</b> or in different public networks, as the acronym has two meanings: <b>Private</b> <b>Network</b> to <b>Network</b> <b>Interface,</b> and <b>Private</b> <b>Network</b> Node <b>Interface.</b> PNNI offers dynamic source routing using a distributed routing function derived from the IETF Open Shortest Path First routing technique. In the private networking context, PNNI is the follow-on to its precursor (the Interim Inter-Switch Protocol) as the prim [...] ...|$|R
40|$|This paper {{presents}} the {{the main features}} of the routing module of a discrete event-driven simulator called SIANET, {{which can be used}} for the design and analysis of Internet Protocol version 6 (IPv 6) over Asynchronous Transfer Mode environments for <b>private</b> <b>networks.</b> The the <b>Private</b> <b>Network</b> to <b>Network</b> <b>Interface</b> (PNNI) specification developed by the ATM Forum. After {{a brief description of the}} simulator, the routing module and the signalling protocol are discussed. The paper finishes with sample simulation results obtained with the presented simulator. simulator, which was constructed in the scope of the MEDIA project (MARS Extension...|$|R
50|$|The company {{established}} a leading {{position in the}} market for ATM switching equipment. FORE created a memory-based ATM switch that captured a strong portion of the ATM market. Other technologies include Internet Protocol, Gigabit Ethernet and Firewall switching. FORE Systems also supported advanced dynamic routing protocols such as the ForeThought <b>Private</b> <b>Network</b> <b>Network</b> <b>Interface</b> (PNNI) and the ATM Forum's PNNI protocol.|$|R
40|$|The <b>Private</b> <b>Network</b> Node <b>Interface</b> (PNNI), {{standardized}} by the ATM Forum (see [1]), {{provides a}} flexible and scaleable routing architecture for ATM networks comprising a routing protocol and a signaling protocol. In PNNI networks PTSEs {{are used to}} distribute topology information through the network. This paper investigates the PTSE rate in PNNI nodes due to flooding. Beside theoretical results, the paper also presents some measurements of example networks. 1 Introduction The <b>Private</b> <b>Network</b> Node <b>Interface</b> (PNNI) defined by the ATM-Forum (see [1]) provides a flexible and scaleable routing architecture for ATM networks comprising a routing protocol and a signaling protocol. PNNI routing includes mechanisms for the autonomous exchange of aggregated topology information to form a hierarchical representation of the network. PNNI signaling {{is based on a}} subset of UNI 4. 0 signaling. To investigate the characteristics of PNNI networks two powerful and versatile tools, a PNNI emulator [...] ...|$|R
40|$|Abstract. Multiprotocol Label Switching (MPLS) is an {{advanced}} forwarding scheme, {{which allows the}} network to achieve the benefits provided by Traffic Engineering (TE) techniques. The establishment of an end-to-end LSP between two IP/MPLS networks interconnected through an ATM backbone is still an open issue. This paper focuses in an MPLS-ATM environment, and addresses the problem of providing a fast LSP establishment, with certain QoS (Band-width guarantee), between two MPLS subnetworks interconnected through an ATM backbone. The <b>Private</b> <b>Network</b> to <b>network</b> <b>Interface</b> (PNNI) is used in ATM backbone as a routing and signaling protocol. In order to achieve the pa-per objectives, new PNNI elements are defined and evaluated. 1...|$|R
40|$|Abstract The <b>Private</b> <b>Network</b> Node <b>Interface</b> (PNNI) {{provides}} a flexible and scaleable routing architecture for ATM networks comprising a routing protocol and a signaling protocol. To obtain more experiences about PNNI, {{we developed a}} PNNI Emulator. We investigated the simple flooding mechanism of the PNNI routing protocol used to distribute topology information through the network. Beside theoretical results, the paper also presents some measurements of example networks...|$|R
50|$|Most ATM {{networks}} supporting SPVPs, SPVCs, and SVCs use the <b>Private</b> <b>Network</b> Node <b>Interface</b> or the Private Network-to-Network Interface (PNNI) protocol. PNNI {{uses the}} same shortest-path-first algorithm used by OSPF and IS-IS to route IP packets to share topology information between switches and select a route through a network. PNNI also includes a very powerful summarization mechanism to allow construction of very large networks, {{as well as a}} call admission control (CAC) algorithm which determines the availability of sufficient bandwidth on a proposed route through a network in order to satisfy the service requirements of a VC or VP.|$|R
40|$|A general {{approach}} is presented for handling the following inverse optimization problem: given solutions to {{each member of}} a family of combinatorial optimization tasks on a common underlying set,. nd a positive linear objective function (weighting) on the common underlying set that simultaneously makes each solution optimal in its own optimization task. Our motivation stems from the inverse shortest path problem that is made practically important in high-speed telecommunication networks by the Asynchronous Transfer Mode Forum’s <b>Private</b> Network– <b>Network</b> <b>Interface</b> architecture, in which route. nding can be based on administrative weights. Di 5 erent variants of the problem are investigated, including uniqueness requirements and reserve routes...|$|R
40|$|Next-generation internetworks {{will require}} a {{flexible}} and scaleable routing architecture. Since ATM networks {{are expected to be}} deployed on a world-wide scale, appropriate architecture has been designed by the ATM Forum: the <b>Private</b> <b>Network</b> Node <b>Interface</b> (PNNI) comprising a dynamic routing and a signalling protocol. PNNI signalling is based on a subset of UNI (User <b>Network</b> <b>Interface)</b> 4. 0 signalling. PNNI routing provides for an arbitrary number of hierarchical levels generated by topology aggregation and support of Quality of Service parameters as required by ATM. Standardisation for PNNI 1. 0 was just recently finished, allowing little experience with this complex routing protocol to be gained. In particular, {{little is known about the}} impact of PNNI protocol parameters on network performance as well as PNNI routing behaviour in large networks. To avoid serious problems eventually faced with the real-time operation of a PNNI implementation, the deployment of PNNI routing should be supp [...] ...|$|R
40|$|This paper {{presents}} congress: a CONnection-oriented Group-address RESolution Service. {{congress is}} an efficient native ATM protocol for resolution {{and management of}} multicast group addresses in an ATM WAN and complements the native ATM multicast mechanisms. congress is not concerned with application data transmission, but only resolves multicast group addresses for applications. Applications can use the resolved addresses, in order to implement a many-tomany communication model. congress employs hierarchically organized servers {{in order to be}} scalable. congress' hierarchy is naturally mapped onto the ATM <b>Private</b> <b>Network</b> to <b>Network</b> <b>Interface</b> peer group hierarchy. congress communication overhead for management of a single multicast group is linear {{in the size of the}} group...|$|R
40|$|Optical {{transport}} networks with automatic switching capabilities (ASON, Automatic Switching Optical Networks) {{appear as a}} potential solution {{to cope with the}} increasingly growth of Internet traffic demands. This paper focuses {{in the context of the}} ASON control plane. In this context, an Optical NNI (O-NNI) has to be defined. For some time it seemed clear that such an O-NNI would be based on Generalised Multiprotocol Label Switching (GMPLS). Nevertheless recently the idea of an O-NNI based on the ATM <b>Private</b> <b>Network</b> to <b>Network</b> <b>Interface</b> (PNNI) paradigm is wining partisans. In this paper a preliminary attempt to adapt the ATM PNNI protocol to be used as the new O-NNI will be done. In particular, this paper will be addressed to define an ATM PNNI based protocol to cope with the routing information exchange in an ASON. We call such a protocol Private Optical NNI (PONNI). We think that PONNI can be more appropriated for this purpose than the OSPF protocol, the one used in the GMPLS paradigm. The main reason for that is that, while OSPF has to be modified in order to achieve the capabilities needed to distribute both internal and external information on the available resources (e. g. remaining bandwidth, wavelengths, etc.), the PNNI has these capabilities by nature. 1...|$|R
40|$|ATM {{networks}} are currently {{moving from the}} experimental stage of test-beds to a commercial state where production {{networks are}} deployed and operated. The ATM Forum PNNI (<b>Private</b> <b>Network</b> to <b>Network</b> <b>Interface)</b> standard introduces an architecture suited for an internetwork which, in principle, {{can also be used}} as an intra-network nodal interface. However, the current PNNI falls short in providing an acceptable solution due to severe performance limitations in intra-network operation, limited functionality and the lack of open interfaces for functional extensions and services. OPENET is a common, open and high-performance network control platform based on performance and functional enhancements to the PNNI platform. It is designed to address the issues of interoperability (being vendor independent), scalability (in terms of network size and volume of calls), high performance (in terms of call processing latency and throughput) and functionality. OPENET is mainly an intra-networking extension to current PNNI. It is compatible with PNNI in the internetwork environment where large networks must be partitioned according to natural topological or organizational boundaries. The major novelty of the OPENET architecture (compared to the current PNNI) is its focus on network control performance. A particular emphasis is given to the increase of the overall rate of connection handling...|$|R
40|$|This paper {{presents}} congress: a CONnection-oriented Group-address RESolution Service, and its applications. Congress is {{an efficient}} native ATM protocol for resolution {{and management of}} multicast group addresses in an ATM WAN. It complements the native ATMmulticast mechanisms. Congress resolves multicast group addresses and maintains their membership for applications. It is not designed to handle the applications' data-exchange. Applications can use the resolved addresses returned by congress, in order to implement a many-to-many communication model. congress employs hierarchically organized servers {{in order to be}} scalable. congress' hierarchy is naturally mapped onto the ATM <b>Private</b> <b>Network</b> to <b>Network</b> <b>Interface</b> peer group hierarchy. congress communication overhead for management of a single multicast group is linear {{in the size of the}} group. Apart from facilitating native ATM multicast applications, congress can be used for the implementation of an IP multicast "cut-through" routing [...] ...|$|R
50|$|Typically, ICS can be {{used when}} there are several <b>network</b> <b>interface</b> cards {{installed}} on the host computer. In this case, ICS makes an Internet connection available on one <b>network</b> <b>interface</b> to be accessible to one other interface that is explicitly designated as the <b>private</b> <b>network.</b> ICS can also share dial-up (including PSTN, ISDN and ADSL connections), PPPoE and VPN connections.|$|R
40|$|Presentation {{overview}} •  Tonight I {{am going}} to give an overview of CentOS cluster server, and describe {{what is needed to}} build a basic HA cluster •  This presentation assumes a basic understanding of network and clustering technology, so make sure to ask questions if you aren’t sure about something What is CentOS cluster server? •  CentOS cluster server is a suite of packages {{that can be used to}} deploy highly available services on CentOS Linux-based servers •  Based on Redhat cluster server •  Provides three main features: –  Cluster management and service failover –  Network load-balancing (LVS) –  Global read-write file system (GFS) What is required to run a cluster? •  Two or more servers that are on the HCL •  Two or more bonded NICs to send cluster heartbeat messages over (this is optional, but highly recommended!) •  Two or more bonded NICs dedicated to public network traffic •  Supported fencing solution •  Shared storage What does a cluster consist of? •  An HA cluster typically consists of the following items: –  Two or more nodes –  One or more fence devices –  Shared storage –  Public and <b>private</b> <b>network</b> <b>interfaces</b> –  One or more resources –  One or more services –  Quorum devices –  Failover Domains Quorum devices •  Quorum is used to ensure that a majority of nodes are available in the cluster •  Needed to avoid split-brain conditions •  Works by assigning one or more votes to each server and quorum device in the cluster •  To ensure quorum, a cluster needs to have 51 % of the available votes to form or continue running an operational cluster •  SCSI disks that support SPR are the most common type of quorum device Fencing devices •  Fencing devices provide a way for the cluster to remove an unresponsive node from the cluster •  Nodes are typically fenced when they are unresponsive, and fencing is done to prevent split brain configurations •  Several supported ways to fence nodes...|$|R
50|$|The Up0-Interface is an {{integrated}} services digital <b>network</b> (ISDN) <b>interface</b> used in <b>private</b> <b>networks.</b> It {{is derived from}} the UK0-Interface used in public networks.|$|R
5000|$|A {{firewall}} is {{a system}} or group of systems (router, proxy, or gateway) that implements a set of security rules to enforce access control between two networks to protect the [...] "inside" [...] network from the [...] "outside" [...] network. It may be a hardware device or a software program running on a secure host computer. In either case, it must {{have at least two}} <b>network</b> <b>interfaces,</b> one for the network it is intended to protect, and one for the network it is exposed to. A firewall sits at the junction point or gateway between the two <b>networks,</b> usually a <b>private</b> <b>network</b> and a public network such as the Internet.|$|R
50|$|Generically, an NID {{may also}} be called a <b>network</b> <b>interface</b> unit (NIU), {{telephone}} <b>network</b> <b>interface</b> (TNI), system <b>network</b> <b>interface</b> (SNI), or telephone network box.|$|R
50|$|A virtual <b>network</b> <b>interface</b> (VIF) is an {{abstract}} virtualized {{representation of a}} computer <b>network</b> <b>interface</b> {{that may or may}} not correspond directly to a <b>network</b> <b>interface</b> controller.|$|R
40|$|The {{motivation}} for inception of this MSc. thesis which follows on from a term {{project of the}} same name was the transfer of the application for building <b>private</b> virtual OpenVPN <b>networks</b> from Windows XP operating system to Windows CE Embedded 6. 0 platform. The project deals with virtual <b>private</b> <b>networks</b> in general and looks more closely at its implementation - OpenVPN. It also introduces the basic features of the Windows CE operating system. The project goes on to describe device drivers in NT-based Windows operating systems, the Windows Driver Model used, the NDIS <b>network</b> <b>interface</b> model and also the model of Windows CE drivers - the Stream Interface Model. The project continues with a~description of communication in OpenVPN application and primarily the role of TUN/TAP virtual <b>network</b> <b>interfaces.</b> This is followed by a proposal for transfer of TUN/TAP adapter drivers together with a description of limitations and necessary modifications between both platforms. As a result a TAP network device driver is implemented whose function is verified by test application that emulates the behaviour of a TUN adapter. The project concludes with an evaluation of the achieved results, the possibilities for further work on this theme and with the overall contribution of this project...|$|R
2500|$|Grids are {{a form of}} {{distributed}} computing whereby a [...] "super virtual computer" [...] is composed of many networked loosely coupled computers acting together to perform large tasks. For certain applications, distributed or grid computing {{can be seen as}} a special type of parallel computing that relies on complete computers (with onboard CPUs, storage, power supplies, <b>network</b> <b>interfaces,</b> etc.) connected to a computer <b>network</b> (<b>private</b> or public) by a conventional <b>network</b> <b>interface,</b> such as Ethernet. This is in contrast to the traditional notion of a supercomputer, which has many processors connected by a local high-speed computer bus.|$|R
5000|$|In a Beowulf system, the {{application}} programs {{never see the}} computational nodes (also called slave computers) but only interact with the [...] "Master" [...] which is a specific computer handling the scheduling {{and management of the}} slaves. In a typical implementation the Master has two <b>network</b> <b>interfaces,</b> one that communicates with the <b>private</b> Beowulf <b>network</b> for the slaves, the other for the general purpose network of the organization. The slave computers typically have their own version of the same operating system, and local memory and disk space. However, the <b>private</b> slave <b>network</b> may also have a large and shared file server that stores global persistent data, accessed by the slaves as needed.|$|R
40|$|Networking servers, such as web servers, {{have been}} widely {{deployed}} in recent years. While developments in the operating system and applications continue to improve server performance, programmable <b>network</b> <b>interfaces</b> with local memory provide new opportunities to improve server performance through extended network services on the <b>network</b> <b>interface.</b> However, due to their embedded nature, programmable processors on the <b>network</b> <b>interface</b> may suffer from inadequate processing power when compared to non-programmable application-specific <b>network</b> <b>interfaces.</b> This thesis first shows that exploiting a multiprocessor architecture and task-level concurrency in <b>network</b> <b>interface</b> processing enables programmable <b>network</b> <b>interfaces</b> to overcome the performance disadvantages over application-specific <b>network</b> <b>interfaces</b> that result from programmability. Then, the thesis presents a network service on a programmable <b>network</b> <b>interface</b> that exploits the storage capacity of the interfaces to alleviate the local I/O interconnect bottleneck, thereby improving server performance. Thus, these two results show that programmable <b>network</b> <b>interfaces</b> can offset the performance disadvantages due to programmability and improve networking server performance through extended network services that exploit their computation power and storage capacity...|$|R
40|$|TCP offload is a {{technique}} to improve TCP/IP networking performance of a network com-puter system by moving (parts of) TCP processing from the host processor to the <b>network</b> <b>interface.</b> There {{are several ways to}} achieve offload. The typical full offload moves all TCP functionalities to the <b>network</b> <b>interface,</b> and TCP processing is performed exclusively on the <b>network</b> <b>interface.</b> However, when the <b>network</b> <b>interface</b> has limited processing power, full offload creates a bottleneck at the <b>network</b> <b>interface</b> and degrades system performance. In contrast, TCP offload based on connection handoff allows the operating system to move a subset of connections to the <b>network</b> <b>interface.</b> This way, both the host processor and the <b>network</b> <b>interface</b> perform TCP processing, and the operating system can control the amount of work performed on the host processor and the <b>network</b> <b>interface.</b> Thus, by us-ing connection handoff, the system can fully utilize the processing power of the <b>network</b> <b>interface</b> without creating a bottleneck in the system. This dissertation presents a design, implementation, and evaluations of handoff-based TCP offload. The design enables the application to transparently exploit offload-capabl...|$|R
50|$|A <b>network</b> <b>interface</b> {{controller}} (NIC, {{also known}} as a <b>network</b> <b>interface</b> card, <b>network</b> adapter, LAN adapter or physical <b>network</b> <b>interface,</b> and by similar terms) is a computer hardware component that connects a computer to a computer network.|$|R
50|$|<b>Network</b> <b>interface</b> - Has API for socket-based <b>network</b> <b>interface,</b> {{including}} IPv6 if the OS supports it.|$|R
5000|$|<b>Network</b> <b>interface</b> layer. The <b>network</b> <b>interface</b> {{layer is}} {{responsible}} for accepting IP datagrams and transmitting them over a specific <b>network.</b> A <b>network</b> <b>interface</b> may consist of a device driver or a complex subsystem that uses its own data link protocol.|$|R
40|$|Distributed-memory {{systems have}} {{traditionally}} had great difficulty performing network I/O at rates proportional to their computational power. The {{problem is that}} the <b>network</b> <b>interface</b> has to support network I/O for a supercomputer, using computational and memory bandwidth resources similar to those of a workstation. As a result, the <b>network</b> <b>interface</b> becomes a bottleneck. We implemented an architecture for network I/O for the iWarp system with the following two key characteristics: first, application-specific tasks are off-loaded from the <b>network</b> <b>interface</b> to the distributed-memory system, and second, these tasks are performed in close cooperation with the application. The <b>network</b> <b>interface</b> has been used by several applications for over a year. In this paper we describe the <b>network</b> <b>interface</b> software that manages the communication between the iWarp distributed-memory system and the <b>network</b> <b>interface,</b> we validate the main features of our <b>network</b> <b>interface</b> architecture based on applicati [...] ...|$|R
5000|$|... #Caption: An ATM <b>network</b> <b>interface</b> in {{the form}} of an {{accessory}} card. A lot of <b>network</b> <b>interfaces</b> are built-in.|$|R
40|$|Networking servers, such as web servers, {{have been}} widely {{deployed}} in recent years. While developments in the operating system and applications continue to improve server performance, programmable <b>network</b> <b>interfaces</b> with local memory provide new opportunities to improve server performance through extended network services on the <b>network</b> <b>interface.</b> However, due to their embedded nature, programmable processors on the <b>network</b> <b>interface</b> may suffer from inadequate processing power when compared to non-programmable application-specific <b>network</b> <b>interfaces...</b>|$|R
40|$|This paper {{proposes a}} novel <b>network</b> <b>interface</b> design method, {{referred}} to as mutual interface definition based method. It decouples resource dependent part (RDP) from resource independent part (RIP) by mutual interface definition. These two parts can be designed independently, thus the design flexibility and reusability of <b>network</b> <b>interface</b> can be enhanced. Moreover, a <b>network</b> <b>interface</b> component library consisting of multiple RDP and RIP components is proposed to be built. The networks-on-chip designers can choose appropriate components from the library to construct <b>network</b> <b>interface</b> design. From the perspective of RDP, the <b>network</b> <b>interface</b> achieves backward compatibility with the existing protocols such as AMBA AHB and OCP. From the perspective of RIP, the <b>network</b> <b>interface</b> provides a configurable structure supporting multicast transfer and adaptive routing algorithm extensions. The proposed <b>network</b> <b>interface</b> designs are implemented in TSMC 90 -nm CMOS standard cell technology and can work at the frequency of 1. 12 GHz to 1. 35 GHz...|$|R
5000|$|<b>Private</b> <b>network</b> IP-addresses {{to be used}} inside <b>private</b> <b>networks</b> ...|$|R
5000|$|... 380Z <b>Network</b> <b>Interface</b> Board (380Z-NET) - a {{proprietary}} 800 kbit/s <b>network</b> <b>interface</b> used to interconnect {{to a network}} of LINK 480Zs.|$|R
40|$|We {{describe}} and evaluate a quad 100 T ethernet <b>network</b> <b>interface</b> built using an Intel IXP 1200 network processor on a commonly available Radisys ENP 2505 PCI board. The <b>network</b> <b>interface</b> exports a raw ethernet interface {{either to the}} host kernel or to user level for cluster computing applications. We describe the firmware architecture and internal design decisions, then evaluate the resulting <b>network</b> <b>interface</b> against 100 T and gigabit <b>network</b> <b>interfaces</b> using CLF, a lightweight reliable datagram layer...|$|R
5000|$|Virtual <b>Private</b> <b>Network</b> (VPN): Extends a <b>private</b> <b>network</b> and the {{resources}} contained in the network across networks like the public Internet. It enables a host computer to send and receive data across shared or public networks {{as if it were}} a <b>private</b> <b>network</b> with the functionality and policies of the <b>private</b> <b>network.</b>|$|R
50|$|More precisely, if {{a device}} has several <b>network</b> <b>{{interface}}s,</b> then each interface must {{have at least}} one distinct IP address assigned to it. For example, a laptop might have a wireless <b>network</b> <b>interface</b> and a wired <b>network</b> <b>interface</b> using a <b>network</b> cable, and this would require a total of two IP addresses, one per interface. Another example is a mobile phone with a 3G <b>network</b> <b>interface</b> and an interface to a wireless LAN. All routers have to have several <b>network</b> <b>interfaces</b> and typically will have several IP addresses associated with them. It is also possible that an interface can be assigned more than one IP address for various reasons.|$|R
