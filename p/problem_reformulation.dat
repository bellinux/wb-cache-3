55|162|Public
40|$|Mixed-initiative systems {{present the}} {{challenge}} of finding an effective level of interaction between humans and computers. Machine learning presents a promising approach to this problem {{in the form of}} systems that automatically adapt their behavior to accommodate different users. In this paper, we present an empirical study of learning user models in an adaptive assistant for crisis scheduling. We describe the problem domain and the scheduling assistant, then present an initial formulation of the adaptive assistant's learning task and the results of a baseline study. After this, we report the results of three subsequent experiments that investigate the effects of <b>problem</b> <b>reformulation</b> and representation augmentation. The results suggest that <b>problem</b> <b>reformulation</b> leads to significantly better accuracy without sacrificing the usefulness of the learned behavior. The studies also raise several interesting issues in adaptive assistance for scheduling. Introduction In recent years, there ha [...] ...|$|E
40|$|Historically, part of Artificial Intelligence's (AI's) roots lie in Operations Research (OR). How AI has {{extended}} the problem solving paradigm developed in OR is explored. In particular, by examining how scheduling problems are solved using OR and AI, it is demonstrated that AI extends OR's model {{of problem solving}} through the opportunistic use of knowledge, <b>problem</b> <b>reformulation</b> and learning...|$|E
40|$|Summary. We {{discuss a}} mixed-integer {{nonlinear}} programming formulation {{for the problem}} of covering a set of points with a given number of slabs of minimum width, known as the bottleneck variant of the hyperplane clustering problem. We derive several linear approximations, which we solve using a standard mixed-integer linear programming solver. A computational comparison {{of the performance of}} the different linearizations is provided. Key words: MINLP, k-line center <b>problem,</b> <b>reformulation,</b> linearization. ...|$|E
50|$|Algorithmic {{approach}} to technical <b>problems</b> <b>reformulation</b> {{was introduced by}} G. S. Altshuller in ARIZ.|$|R
40|$|In this paper, Modelica {{along with}} Optimica {{has been used}} to {{formulate}} and solve a minimum time optimization problem. The problem concerns traversing a given path with a robot in as short time possible under input constraints. Different <b>problem</b> <b>reformulations</b> are discussed that increase the chance of finding optimal solutions. This paper also discusses the use of these optimal solutions for control of industrial robots. A control structure, in which the optimal trajectories are essential, are used on an ABB IRB 140 B to ensure robustness for model errors and disturbances...|$|R
40|$|We propose new {{algorithms}} for computing linear discriminants {{to perform}} data dimensionality reduction from Rn to Rp, with p < n. We propose {{alternatives to the}} classical Fisher’s Distance criterion, namely, we investigate new criterions based on the: Chernoff-Distance, J-Divergence and Kullback-Leibler Divergence. The optimization problems that emerge of using these alternative criteria are non-convex and thus hard to solve. However, despite the non-convexity our algorithms guarantee global optimality for the linear discriminant when p = 1. This is possible due to <b>problem</b> <b>reformulations</b> and recent developments in optimization theory [8],[9]. A greedy suboptimal approach is developed for 1 < p < n...|$|R
40|$|Much {{progress}} has been made in the research and development of automated planning algorithms in recent years. Though incremental improvements in algorithm design are still desirable, complementary approaches such as <b>problem</b> <b>reformulation</b> are important in tackling the high computational complexity of planning. While machine learning and adaptive techniques have been usefully applied to automated planning, these advances are often tied to a particular planner or class of planners that are coded to exploit that learned knowledge. A promising research direction is in exploiting knowledge engineering techniques such as reformulating the planning domain and/or the planning problem to make the problem easier to solve for general, state-of-the-art planners. Learning (outer) entanglements is one such technique, where relations between planning operators and initial or goal atoms are learned, and used to reformulate a domain by removing unneeded operator instances. Here we generalize this approach significantly to cover relations between atoms and pairs of operators themselves, and develop a technique for producing inner entanglements. We present methods for detecting inner entanglements and for using them to do <b>problem</b> <b>reformulation.</b> We provide a theoretical treatment of the area, and an empirical evaluation of the methods using standard planning benchmarks and state-of-the-art planners...|$|E
40|$|We {{present a}} Branch and Cut {{algorithm}} {{of the software}} package LaGO to solve nonconvex mixed-integer nonlinear programs (MINLPs). A linear outer approximation is constructed from a convex relaxation of the problem. Since we do not require an algebraic representation of the <b>problem,</b> <b>reformulation</b> techniques {{for the construction of}} the convex relaxation cannot be applied, and we are restricted to sampling techniques in case of nonquadratic nonconvex functions. The linear relaxation is further improved by mixed-integer-rounding cuts. Also box reduction techniques are applied to improve efficiency. Numerical results on medium size test problems are presented to show the efficiency of the method...|$|E
40|$|Abstract: 2 ̆ 2 This paper {{discusses}} numerical {{issues in}} Differential- Algebraic Equation (DAE) optimization concerning {{the stability and}} accuracy of the discretized Nonlinear Programming Problems (NLP). First, {{a brief description of}} the solution strategy based on reduced-Hessian Successive Quadratic Programming (rSQP) is described, focusing on the decomposition step of the DAE constraints. Next, some difficulties associated with unstable DAE problem formulations are exposed via examples. A new procedure for detecting ill-conditioning and <b>problem</b> <b>reformulation</b> is then presented. Furthermore, some properties of this procedure as well as its limitations are also discussed. Numerical examples are provided, including a flowsheet optimization problem with an unstable reactor. 2 ̆...|$|E
40|$|Abstract: 2 ̆ 2 This paper {{presents}} a general {{overview of the}} global optimization algorithm by Quesada and Grossmann (1993 a) for solving NLP problems involving linear fractional and bilinear terms, and it explores the use of alternative bounding approximations. These are applied in the global optimization of problems arising in different engineering areas and for which different relaxations are proposed depending on the mathematical structure of the models. These relaxations include linear and nonlinear underestimator <b>problems.</b> <b>Reformulations</b> that generate additional estimator functions are also employed. Examples from structural design, batch processes, portfolio investment and layout design are presented. 2 ̆...|$|R
30|$|Note {{that problem}} (1.3) {{may not have}} a {{solution}} in general. There have been proposed three ways to deal with (1.3). One way was suggested by Gürkan et al. [3], who used an expectation of F_ 0 instead of F_ 0 for giving a simple nonlinear complementarity <b>problems</b> <b>reformulation.</b> Another way was presented by Chen and Fukushima [4], who made use of the so-called NCP function to present the expected residual minimization formulation for SNCP. The last was proposed by Lin and Fukushima [5]. They formulated SNCP as a special here-and-now model of stochastic mathematical program with equilibrium constraints. Moreover, Luo and Wang [6] presented the ERM and CVaR reformulation for solving stochastic generalized complementarity problem.|$|R
40|$|Abstract. We {{state and}} solve the query <b>reformulation</b> <b>problem</b> for XML {{publishing}} {{in a general}} setting that allows mixed (XML and relational) storage for the proprietary data and exploits redundancies (materialized views, indexes and caches) to enhance performance. The correspondence between published and proprietary schemas is specified by views in both directions, and the same algorithm performs rewriting-with-views, composition-with-views, or the combined effect of both, unifying the Global-As-View and Local-As-View approaches to data integration. We prove a completeness theorem which guarantees that under certain conditions, our algorithm will find a minimal reformulation if one exists. Moreover, we identify conditions when this algorithm achieves optimal complexity bounds. We solve the <b>reformulation</b> <b>problem</b> for constraints by exploiting a reduction to the <b>problem</b> of query <b>reformulation.</b> ...|$|R
40|$|AbstractWhen solving machine {{learning}} problems, {{there is currently}} little automated support for easily experimenting with alternative statistical models or solution strategies. This is because this activity often requires expertise from several different fields (e. g., statistics, optimization, linear algebra), {{and the level of}} formalism required for automation is much higher than for a human solving problems on paper. We present a system toward addressing these issues, which we achieve by (1) formalizing a type theory for probability and optimization, and (2) providing an interactive rewrite system for applying <b>problem</b> <b>reformulation</b> theorems. Automating solution strategies this way enables not only manual experimentation but also higher-level, automated activities, such as autotuning...|$|E
40|$|In this work, {{we propose}} to train a {{deep neural network}} by {{distributed}} optimization over a graph. Two nonlinear functions are considered: the rectified linear unit (ReLU) and a linear unit with both lower and upper cutoffs (DCutLU). The <b>problem</b> <b>reformulation</b> over a graph is realized by explicitly representing ReLU or DCutLU using a set of slack variables. We then apply the alternating direction method of multipliers (ADMM) to update the weights of the network layerwise by solving subproblems of the reformulated problem. Empirical {{results suggest that the}} ADMM-based method is less sensitive to overfitting than the stochastic gradient descent (SGD) and Adam methods. Comment: 5 page...|$|E
40|$|When solving machine {{learning}} problems, {{there is currently}} little automated support for easily experimenting with alternative statistical models or solution strategies. This is because this activity often requires expertise from several different fields (e. g., statistics, optimization, linear algebra), {{and the level of}} formalism required for automation is much higher than for a human solving problems on paper. We present a system toward addressing these issues, which we achieve by (1) formalizing a type theory for probability and optimization, and (2) providing an interactive rewrite system for applying <b>problem</b> <b>reformulation</b> theorems. Automating solution strategies this way enables not only manual experimentation but also higher-level, automated activities, such as autotuning. Keywords: {{machine learning}}, algorithm derivation, interactive modeling, type theor...|$|E
50|$|The {{solution}} algorithms {{provided by}} FortSP include Benders' decomposition and {{a variant of}} level decomposition for two-stage problems, nested Benders' decomposition for multistage <b>problems</b> and <b>reformulation</b> of the <b>problem</b> as a deterministic equivalent. There is also an implementation of a cutting-plane algorithm for integrated chance constraints.|$|R
40|$|Numerical {{relativity}} is {{the most}} promising tool for theoretically modeling the inspiral and coalescence of neutron star and black hole binaries, which, in turn, {{are among the most}} promising sources of gravitational radiation for future detection by gravitational wave observatories. In this article we review numerical relativity approaches to modeling compact binaries. Starting with a brief introduction to the 3 + 1 decomposition of Einstein’s equations, we discuss important components of numerical relativity, including the initial data <b>problem,</b> <b>reformulations</b> of Einstein’s equations, coordinate conditions, and strategies for locating and handling black holes on numerical grids. We focus on those approaches which currently seem most relevant for the compact binary problem. We then outline how these methods are used to model binary neutron stars and black holes, and review the current status of inspiral and coalescence simulations...|$|R
40|$|Although even propositional STRIPS {{planning}} {{is a hard}} problem in general, many instances of the problem, including many of those commonly used as benchmarks, are easy. In spite of this, they are often hard to solve for domain-independent planners, because the encoding of the problem into a general problem specification formalism such as STRIPS hides structure {{that needs to be}} exploited to solve problems easily. We investigate the use of automatic problem transformations to reduce this “accidental ” problem complexity. The main tool is abstraction: we identify a new, weaker, condition under which abstraction is “safe”, in the sense that any solution to the abstracted problem can be refined to a concrete solution (in polynomial time, for most cases) and also show how different kinds of <b>problem</b> <b>reformulations</b> can be applied to create greater opportunities for such safe abstraction. ...|$|R
30|$|Two robust designs (i.e., Robust-SP and Robust-LPM) are {{developed}} {{to solve the}} “dual” robust min-max power problem. This problem is well-known nonconvex due to the infinitely many SINR constraints. For Robust-SP, we use the S-procedure to convert the problem into a rank-constrained semidefinite program (SDP), and then apply the SDP relaxation technique to find its (near-)optimal solution. Like [15], we give a computable CSI uncertainty bound which ensures the tightness of the SDP relaxation. For Robust-LPM, we consider a slightly conservative <b>problem</b> <b>reformulation.</b> Relying on a linear matrix inequality (LMI) representation for the cone of Lorentz-positive maps (LPMs), the new problem is shown to be equivalently transformed into a convex SDP which can be efficiently solved with guaranteed global optimality.|$|E
40|$|A sparse {{recovery}} {{approach for}} direction finding in partly calibrated arrays composed of subarrays with unknown displacements is introduced. The proposed method {{is based on}} mixed nuclear norm and 1 norm minimization and exploits block-sparsity and low-rank structure in the signal model. For efficient implementation a compact equivalent <b>problem</b> <b>reformulation</b> is presented. The new technique is applicable to subarrays of arbitrary topologies and grid-based sampling of the subarray manifolds. In the special case of subarrays with a common baseline our new technique admits extension to a gridless implementation. As shown by simulations, our new block- and rank-sparse direction finding technique for partly calibrated arrays outperforms {{the state of the}} art method RARE in difficult scenarios of low sample numbers, low signal-to-noise ratio or correlated signals...|$|E
40|$|Finding {{the least}} squares (LS) {{solution}} s {{to a system}} of linear equations Hs = y where H, y are given and s is a vector of binary variables, is a well known NP-hard problem. In this paper, we consider binary LS problems under the assumption that the coefficient matrix H is also unknown, and lies in a given uncertainty ellipsoid. We show that the corresponding worst-case robust optimization problem, although NP-hard, is still amenable to semidefinite relaxation (SDR) -based approximations. However, the relaxation step is not obvious, and requires a certain <b>problem</b> <b>reformulation</b> to be efficient. The proposed relaxation is motivated using Lagrangian duality and simulations suggest that it performs well, offering a robust alternative over the traditional SDR approaches for binary LS problems...|$|E
40|$|The A-B slice <b>problem,</b> a <b>reformulation</b> of the 4 -dimensional topological surgery {{conjecture}} {{for free}} groups, {{is shown to}} admit a link-homotopy+ solution. The proof relies on geometric applications of the group-theoretic 2 -Engel relation. Implications for the surgery conjecture are discussed. Comment: 19 pages. v. 2 : A more detailed exposition, final versio...|$|R
30|$|Many {{important}} <b>problems</b> have <b>reformulations</b> {{which require}} finding solutions of equilibriums (1.3) and (1.4), for instance, image recovery, inverse problems, network allocation, transportation problems and optimization problems; see [3 – 11] and the references therein. For solving solutions of equilibriums (1.3) and (1.4), regularization methods recently have been extensively studied; see [11 – 28] and the references therein.|$|R
40|$|When solving {{optimization}} problems, {{the importance}} of speed can not be emphasized enough for many organizations. One company encountered a major performance difference when solving {{a problem with the}} same integer programming solver, in two different locations. The difference was shown not to be caused by the environment of the solver, but rather a <b>reformulation</b> of the <b>problem.</b> However, the <b>reformulation</b> did not improve the performance of an expanded version of the problem. By analyzing and comparing the two versions one might be able to find the properties  of a problem which enables the reformulation to reduce the solving time. This in turn can be used to identify for which <b>problems</b> the <b>reformulation</b> should be applied to increase the speed at which they are solved...|$|R
40|$|The main {{topic of}} the work is the design and {{development}} of a plan-space planning system FAPE that integrates explicit time reasoning, resource reasoning with discrete resources and reservoirs and hierarchical decompositions. FAPE is the first planning system that accepts the language ANML, supporting most of its major features. We investigate different aspects of the integration, also proposing a new <b>problem</b> <b>reformulation</b> technique for the state-variable representation and discovering a transition of performance between sparse and minimal temporal networks. We further extend FAPE with acting capabilities and evaluate the runtime properties and benefits of its expressiveness. Finally, we present FAPE as a planning and acting system in real world experiments, where FAPE operates a PR 2 robot. Powered by TCPDF (www. tcpdf. org...|$|E
40|$|Constraint {{validation}} has bcc?n {{difficult to}} imple-ment efficiently. The {{major reason for}} this difficulty lies in the state-dependent nature of integrity constraints and the rt~quiremcnt of both high-level spc&fication and cfficirnt runtimc cnforccmcnt. In this paper, we pro-pose a constraint reformulation approach to rfficicnt constraint validation. We also demonstrate how this knowledge-basrd constraint rcfornmlation can be natu-rally accomplished in the gcncral framework of <b>problem</b> <b>reformulation</b> with the technique of antecedent deriva-tion. We formalize thr reformulation of an integrity constraint as a tree-starch process where the search space is thtr set of all semantic-equivalent alternatives of the original constraint. We also develop control strate-gies and mcta-level rules for carrying out the search c?fficicntly. The major contribution of this work is a new promising approach to cfficirnt constraint valida-tiun and a general framework to accomplish it. 1...|$|E
40|$|Restricting {{the search}} space has {{shown to be}} an {{effective}} approach for improving the performance of automated planning systems. A planner-independent technique for pruning the search space is domain and <b>problem</b> <b>reformulation.</b> Recently, Outer Entanglements, which are relations between planning operators and initial or goal predicates, have been introduced as a reformulation technique for eliminating potential undesirable instances of planning operators, and thus restricting the search space. Reformulation techniques, however, have been mainly applied in classical planning, although many real-world planning applications require to deal with numerical information. In this paper, we investigate the usefulness of reformulation approaches in planning with numerical fluents. In particular, we propose and extension of the notion of outer entanglements for handling numeric fluents. An empirical evaluation, which involves 150 instances from 5 domains, shows promising results...|$|E
3000|$|In {{the real}} world, many {{important}} <b>problems</b> have <b>reformulations</b> which require finding zero points of some nonlinear operator, for instance, evolution equations, complementarity problems, mini-max problems, variational inequalities and optimization problems; see [1 – 13] and the references therein. It {{is well known}} that minimizing a convex function f can be reduced to finding zero points of the subdifferential mapping [...]...|$|R
40|$|AbstractAn {{abstract}} existence theorem is proved for variational inequalities of monotone operators with a nonlinear perturbation. It is used {{to prove}} {{the existence of a}} strong {{solution to the problem of}} quasistatic, one dimensional contact in linearized thermoelasticity. The <b>problem,</b> after <b>reformulation,</b> consists of the heat equation with a nonlocal and nonlinear term. The uniqueness and stability of the solution are also established...|$|R
40|$|We {{propose a}} new {{algorithm}} for solving smooth nonlinear equations {{in the case}} where their solutions can be singular. Compared to other techniques for computing singular solutions, a distinctive feature of our approach {{is that we do}} not employ second derivatives of the equation mapping in the algorithm, and do not assume their existence in the convergence analysis. Important examples of once but not twice differentiable equations whose solutions are inherently singular, are smooth equation-based reformulations of the nonlinear complementarity <b>problems.</b> <b>Reformulations</b> of complementarity <b>problems</b> serve both as illustration and motivation for our approach, and one of them we consider in detail. We show that the proposed method possesses local superlinear/quadratic convergence under reasonable assumptions. We further demonstrate that these assumptions are in general not weaker and not stronger than regularity conditions employed in the context of other superlinearly convergent Newton-type algorithms for solving complementarity problems, which are typically based on nonsmooth reformulations. Therefore our approach appears to be an interesting complement to the existing ones...|$|R
40|$|Clinical {{reports about}} clients in {{psychotherapy}} have been greatly under-utilized as research {{data about the}} psychotherapy process. In this exploratory study, reports from a training clinic about clients in long-term therapy were studied to address two main topics: {{the nature and extent}} of descriptions of change in romantic relationships during therapy, and the documentation of <b>problem</b> <b>reformulation</b> over the course of therapy. Findings indicate that within the wealth of clinical material in such reports, specific documentation of these two main topics can be identified. Most cases did reveal changes or transition points in romantic relationships for the set of ninety-two cases analyzed. In addition, specific ways that clients 2 ̆ 7 presenting problems changed over the course of therapy were detailed for a subset of cases. Gender differences in some areas, as well as overall implications for psychotherapy practice and research were discussed. ...|$|E
40|$|This paper {{explores the}} {{relationship}} between certain inverse unitary eigenvalue problems and orthogonal functions. In particular, the inverse eigenvalue problems for unitary Hessenberg matrices and for Schur parameter pencils are considered. The Szego recursion {{is known to be}} identical to the Arnoldi process and can be seen as an algorithm for solving an inverse unitary Hessenberg eigenvalue <b>problem.</b> <b>Reformulation</b> of this inverse unitary Hessenberg eigenvalue problem yields an inverse eigenvalue problem for Schur parameter pencils. It is shown that solving this inverse eigenvalue problem is equivalent to computing Laurent polynomials orthogonal on the unit circle. Efficient and reliable algorithms for solving the inverse unitary eigenvalue problems are given which require only O(mn) arithmetic operations as compared with O(mn 2) operations needed for algorithms that ignore the structure of the problem. Key words. inverse unitary eigenvalue problem, Arnoldi process, Szego polynomials [...] ...|$|E
40|$|The paper {{describes}} one of {{the ways}} of developing pupils’ creative approach to problem solving. The described experiment is a part of a longitudinal research focusing on improvement of culture of problem solving by pupils. It deals with solving of problems using the following heuristic strategies: Analogy, Guess – check – revise, Systematic experimentation, <b>Problem</b> <b>reformulation,</b> Solution drawing, Way back and Use of graphs of functions. Most attention is paid to the question whether short-term work, in this case only over the period of three months, can result in improvement of pupils’ abilities to solve problems whose solving algorithms are easily accessible. It also answers the question which strategies pupils will prefer and with what results. The experiment shows that even short-term work can bear positive results as far as pupils’ approach to problem solving is concerned...|$|E
40|$|Attitude {{control of}} the International Space Station (ISS) is {{critical}} for operations, impacting power, communications, and thermal systems. The station uses gyroscopes and thrusters for attitude control, and reorientations are normally assisted by thrusters on docked vehicles. When the docked vehicles are unavailable, the reduction in control authority in the roll axis results in frequent jet firings and massive fuel consumption. To improve this situation, new guidance and control schemes are desired that provide control with fewer roll firings. Optimal control software was utilized to solve for potential candidates that satisfied desired conditions {{with the goal of}} minimizing total propellant. An ISS simulation too was then used to test these solutions for feasibility. After several <b>problem</b> <b>reformulations,</b> multiple candidate solutions minimizing or completely eliminating roll firings were found. Flight implementation would not only save massive amounts of fuel and thus money, but also reduce ISS wear and tear, thereby extending its lifetime...|$|R
40|$|Abstract. This paper {{addresses}} a multi-period investment model for capacity expansion in an uncertain environment. Using a scenario tree approach {{to model the}} evolution of uncertain demand and cost parameters, and fixed-charge cost functions to model the economies of scale in expansion costs, we develop a multi-stage stochastic integer programming formulation for the <b>problem.</b> A <b>reformulation</b> of the <b>problem</b> is proposed using variable disaggregation to exploit the lot-sizing substructure of the <b>problem.</b> The <b>reformulation</b> significantly reduces the LP relaxation gap of this large scale integer program. A heuristic scheme is presented to perturb the LP relaxation solutions to produce good quality integer solutions. Finally, we outline a branch and bound algorithm that makes use of the reformulation strategy as a lower bounding scheme, and the heuristicas an upper bounding scheme, {{to solve the problem}} to global optimality. Our preliminary computational results indicate that the proposed strategy has significant advantages over straightforward use of commercial solvers...|$|R
40|$|We {{present a}} {{reformulation}} of unsteady turbulent flow simulations. The initial condition is relaxed and information {{is allowed to}} propagate both forward and backward in time. Simulations of chaotic dynamical systems with this reformulation can be proven to be well-conditioned time domain boundary value <b>problems.</b> The <b>reformulation</b> can enable scalable parallel-in-time simulation of turbulent flows. Comment: 11 pages, 17 figures. Accepted for publication in Physics of Fluid...|$|R
