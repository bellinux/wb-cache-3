335|468|Public
5000|$|The pseudo-code for a basic {{binary tree}} <b>parallel</b> <b>reduction</b> {{algorithm}} is shown here:Note that this algorithm stores the partial sums by overwriting {{portions of the}} original array, and the final result {{is found in the}} first element.|$|E
50|$|After a major {{reorganization}} {{which occurred}} in the last decade, which included the transformation of most Infantry formations into Mechanized Brigades and a <b>parallel</b> <b>reduction</b> of personnel, the Hellenic Army's higher command is the Hellenic Army General Staff.|$|E
50|$|A similar {{situation}} occurs considering the homology of morphological structures. For example, many insects possess {{two pairs of}} flying wings. In beetles, the first pair of wings is hardened into elytra, wing covers with little role in flight, while in flies the second pair of wings is condensed into small halteres used for balance. If the two pairs of wings are considered as interchangeable, homologous structures, this may {{be described as a}} <b>parallel</b> <b>reduction</b> in the number of wings, but otherwise the two changes are each divergent changes in one pair of wings.|$|E
40|$|We {{consider}} the deadline problem and budget {{problem of the}} nonlinear time–cost tradeoff project scheduling model in a series–parallel activity network. We develop fully polynomial-time approximation schemes for both problems using K-approximation sets and functions, together with series and <b>parallel</b> <b>reductions.</b> Department of Logistics and Maritime Studie...|$|R
40|$|Reducibility {{has been}} used to prove a number of {{properties}} in the λ-calculus and is well known to offer on one hand very general proofs which can be applied to a number of instantiations, and on the other hand, to be quite mysterious and inflexible. It has, amongst other things, been used along with the so called method of <b>parallel</b> <b>reductions</b> to prove the Church-Rosser property. In this paper, we concentrate on using the methods of reducibility and of <b>parallel</b> <b>reductions</b> for proving Church-Rosser for both β- and βη-reduction. Our contributions are two fold: We give a simple proof of CR for β-reduction which unlike the common proofs in the literature, avoids any type machinery and is solely carried out in a completely untyped setting. We give a new proof of CR for βη-reduction which is a generalisation of our simple proof for β-reduction. Keywords...|$|R
5000|$|Replicated data {{processing}} engine - In addition to caching Coherence provides a rich {{data processing}} model so processing can be farmed {{out to where}} the data is, and results returned to the client. By moving the processing to the data, processing too is highly scalable. This is to some extent similar to a MapReduce framework, but lacks the option of <b>parallel</b> <b>reductions.</b>|$|R
50|$|Wound {{healing is}} an innate {{mechanism}} of action that works reliably most of the time. A key feature of wound healing is stepwise repair of lost extracellular matrix (ECM) that forms the largest component of the dermal skin layer. But in some cases, certain disorders or physiological insult disturbs the wound healing process. Diabetes mellitus is one such metabolic disorder that impedes the normal steps of the wound healing process. Many studies show a prolonged inflammatory phase in diabetic wounds, which causes a delay {{in the formation of}} mature granulation tissue and a <b>parallel</b> <b>reduction</b> in wound tensile strength.|$|E
50|$|A {{recent study}} {{has shown that}} the {{presence}} of Enterobacter cloacae B29 in the gut of a morbidly obese individual {{may have contributed to the}} patient’s obesity. Reduction of the bacterial load within the patient’s gut, from 35% E. cloacae B29 to non-detectable levels, was associated with a <b>parallel</b> <b>reduction</b> in endotoxin load in the patient and a concomitant, significant reduction in weight. Furthermore, the same bacterial strain, isolated from the patient, induced obesity and insulin resistance in germfree C57BL/6J mice that were being fed a high-fat diet. The study concludes that E. cloacae B29 may contribute to obesity in its human hosts through an endotoxin-induced, inflammation-mediated mechanism.|$|E
50|$|Caldera {{also had}} to handle a vertiginous inflationary spiral and a <b>parallel</b> <b>reduction</b> of the Forex reserves, {{employees}} generously {{for the support of}} the bolívar in front of the U.S. dollar. On 27 June, he announced the temporary suspension of some constitutional guarantees, fundamentally related to the private property and the free economic activity, to allow control of the exchange market, the banking system and prices by the State. The financial organizations bankrupted by the draining of deposits and those affected by speculative practices went to be adjusted by the State. The Central Bank of Venezuela announced the suspension of all of its transactions in dollars.|$|E
40|$|The Church-Rosser theorem in the type-free lambda-calculus is well {{investigated}} {{both for}} beta-equality and beta-reduction. We provide a new {{proof of the}} theorem for beta-equality with no use of <b>parallel</b> <b>reductions,</b> but simply with Takahashi's translation (Gross-Knuth strategy). Based on this, upper bounds for reduction sequences on the theorem are obtained as the fourth level of the Grzegorczyk hierarchy. Comment: In Proceedings WPTE 2016, arXiv: 1701. 0023...|$|R
40|$|We {{describe}} {{a model to}} exploit data parallelism present in associative computers for efficient execution of logic programs on associative supercomputers. We present an alternate scheme for logical structure representation which naturally interfaces lists and vectors on associative computers for efficient integration of symbolic and numerical computation on existing associative supercomputers. We also propose a scheme for efficient data <b>parallel</b> goal <b>reduction</b> which is almost independent of number of clauses. The data <b>parallel</b> goal <b>reduction</b> scheme efficiently pruns non unifiable clauses and performs binding of variables with single occurrence in goal and the clauses. The data parallel model reduces the cost of shallow backtracking, deep backtracking and detrailing significantly. The independence of <b>parallel</b> goal <b>reduction</b> scheme from number of clauses has been demonstrated by experimental results...|$|R
40|$|Graph {{reduction}} is an implementation technique for the lazy l-calculus. It {{has been used}} to implement many non-strict functional languages, such as lazy ML, Gofer and Miranda. <b>Parallel</b> graph <b>reduction</b> allows for concurrent evaluation. In this paper, we present <b>parallel</b> graph <b>reduction</b> as a Chemical Abstract Machine, and show that the resulting testing semantics is adequate wrt testing equivalence for the lazy l-calculus. We also present a π-calculus implementation of the graph reduction machine, and show that the resulting testing semantics is also adequate...|$|R
50|$|Caldera {{also had}} to handle a vertiginous inflationary spiral and a <b>parallel</b> <b>reduction</b> of the Forex reserves, {{employees}} generously {{for the support of}} the bolívar in front of the U.S. dollar. On 27 June, he announced the temporary suspension of some constitutional guarantees, fundamentally related to the private property and the free economic activity, to allow control of the exchange market, the banking system and prices by the State. The financial organizations bankrupted by the draining of deposits and those affected by speculative practices went to be adjusted by the State. In fact, the Central Bank of Venezuela announced the suspension of all its transaction in dollars. These economic measures were tolerated by the mass media and the international community, but not by the Venezuelan people.|$|E
50|$|In {{collaboration}} with Peter Wheeler she developed the Expensive Tissue Hypothesis, regarding early humans, {{according to which}} there is an inverse correlation between the increase in brain size during human evolution and the <b>parallel</b> <b>reduction</b> of the digestive tract {{as a result of}} richer protein animal foods. Another idea she posited, was that higher reproductive costs would be the effect of this increase in brain size, which was compensated by the females increasing in size faster than the males. She highlighted that terrestriality (movement of early hominids from forest to savannahs) is the oldest stage that led to human civilization. The second stage was bipedialism and the third is encephalization (evoking larger brains). Aiello identified social implications of meat eating; one of which is food sharing, which does not happen often in primates, which strengthens the bond between female and offspring. The other societal implication is that meat eating likely led to division of labor between males and females (males hunting, females caring for dependent young). Meat eating did not cause larger brains, but simply made them possible.|$|E
40|$|AbstractThe typed λμ-calculus {{is known}} to be {{strongly}} normalizing and weakly Church-Rosser, and hence becomes confluent. In fact, Parigot formulated a <b>parallel</b> <b>reduction</b> to prove confluence of the typed λμ-calculus by “Tait-and-Martin-Löf” method. However, the diamond property does not hold for his <b>parallel</b> <b>reduction.</b> The confluence for type-free λμ-calculus cannot be derived from that of the typed λμ-calculus and is not confirmed yet as far as we know. We analyze granularity of the reduction rules, and then introduce a new <b>parallel</b> <b>reduction</b> such that both renaming reduction and consecutive structural reductions are considered as one step <b>parallel</b> <b>reduction.</b> It is shown that the new formulation of <b>parallel</b> <b>reduction</b> has the diamond property, which yields a correct proof of the confluence for type free λμ-calculus. The diamond property of the new <b>parallel</b> <b>reduction</b> is also applicable to a call-by-value version of the λμ-calculus containing the symmetric structural reduction rule...|$|E
40|$|Thinning and {{shrinking}} algorithms, respectively, {{are capable}} of extracting medial lines and topological kernels from digital binary objects in a topology preserving way. These topological algorithms are composed of reduction operations: object points that satisfy some topological and geometrical constraints are removed until stability is reached. In this work we present some new sufficient conditions for topology preserving <b>parallel</b> <b>reductions</b> and fiftyfour new 2 D parallel thinning and shrinking algorithms {{that are based on}} our conditions. The proposed thinning algorithms use five characterizations of endpoints...|$|R
40|$|Some of {{the most}} common {{parallel}} programming idioms include locks, barriers, and reduction operations. The interaction of these programming idioms with the multiprocessor 's coherence protocol has a significant impact on performance. In addition, the advent of machines that support multiple coherence protocols prompts {{the question of how to}} best implement such parallel constructs, i. e. what combination of implementation and coherence protocol yields the best performance. In this paper we study the running time and communication behavior of (1) centralized (ticket) and MCS spin locks, (2) centralized, dissemination, and treebased barriers, and (3) <b>parallel</b> and sequential <b>reductions,</b> under pure and competitive update coherence protocols; results for write-invalidate protocol are presented mostly for comparison purposes. Our experiments indicate that parallel programming techniques that are well-established for write invalidate protocols, such as MCS locks and <b>parallel</b> <b>reductions,</b> are oft [...] ...|$|R
40|$|We study an {{extension}} of Plotkin 2 ̆ 7 s call-by-value lambda-calculus by means of two commutation rules (sigma-reductions). Recently, it has been proved that this extended calculus provides elegant characterizations of many semantic properties, as for example solvability. We prove a standardization theorem for this calculus by generalizing Takahashi 2 ̆ 7 s approach of <b>parallel</b> <b>reductions.</b> The standardization property allows us to prove that our calculus is conservative {{with respect to the}} Plotkin 2 ̆ 7 s one. In particular, we show that the notion of solvability for this calculus coincides with that for Plotkin 2 ̆ 7 s call-by-value lambda-calculus...|$|R
40|$|Typed λµ-calculus {{is known}} to be {{strongly}} normalizing and weakly Church-Rosser, and hence confluent. In fact, Parigot formulated a <b>parallel</b> <b>reduction</b> to prove confluency of typed λµ-calculus by "Tait-and-Martin-Löf" method. However, the diamond property does not hold for his <b>parallel</b> <b>reduction.</b> The confluency for type-free λµ-calculus cannot be derived from that of typed λµ-calculus and is not known. We analyzed granualities of the reduction rules. We consider a renaming and consecutive structural reductions as one step <b>parallel</b> <b>reduction,</b> and show that the new formulation of <b>parallel</b> <b>reduction</b> has the diamond property, which yields the correct proof of confluency of type free -λµcalculus. The diamond property of new <b>parallel</b> <b>reduction</b> is also shown for the call-by-value version of λµ-calculus contains the symmetric structural reduction rule...|$|E
40|$|The typed Lambda-mu-calculus {{is known}} to be {{strongly}} normalizing and weakly Church-Rosser, and hence becomes confluent. In fact, Parigot formulated a <b>parallel</b> <b>reduction</b> to prove confluence of the typed Lambda-mu-calculus by 2 ̆ 2 Tait-and-Martin-Löf 2 ̆ 2 method. However, the diamond property does not hold for his <b>parallel</b> <b>reduction.</b> The confluence for type-free Lambda-mu-calculus cannot be derived from that of the typed Lambda-mu-calculus and is not confirmed yet as far as we know. We analyze granularity of the reduction rules, and then introduce a new <b>parallel</b> <b>reduction</b> such that both renaming reduction and consecutive structural reductions are considered as one step <b>parallel</b> <b>reduction.</b> It is shown that the new formulation of <b>parallel</b> <b>reduction</b> has the diamond property, which yields a correct proof of the confluence for type free Lambda-mu-calculus. The diamond property of the new <b>parallel</b> <b>reduction</b> is also applicable to a call-by-value version of the Lambda-mu-calculus containing the symmetric structural reduction rule...|$|E
40|$|Typed λμ-calculus {{is known}} to be {{strongly}} normalizing and weakly Church-Rosser, and hence confluent. In fact, Parigot formulated a <b>parallel</b> <b>reduction</b> to prove confluency of typed λμ-calculus by 2 ̆ 2 Tait-and- Martin-Löf 2 ̆ 2 method. However, the diamond property does not hold for his <b>parallel</b> <b>reduction.</b> The confluency for type-free λμ-calculus cannot be derived from that of typed λμ-calculus and is not known. We analyzed granualities of the reduction rules. We consider a renaming and consecutive structural reductions as one step <b>parallel</b> <b>reduction,</b> and show that the new formulation of <b>parallel</b> <b>reduction</b> has the diamond property, which yields the correct proof of confluency of type free λμ-calculus. The diamond property of new <b>parallel</b> <b>reduction</b> is also shown for the call-by-value version of λμ-calculus contains the symmetric structural reduction rule...|$|E
5000|$|Mairson's {{contributions}} {{to the theory of}} programming languages include proving that type inference for the ML programming language, so-called Hindley-Milner type inference, is complete for exponential time and that <b>parallel</b> beta <b>reduction</b> is non-elementary.|$|R
40|$|Algorithms for series-parallel graphs can be {{extended}} to arbitrary two-terminal dags if node reductions are used along with series and <b>parallel</b> <b>reductions.</b> A node reduction contracts a vertex with unit in-degree (out-degree) into its sole incoming (outgoing) neighbor. This paper gives an O(n 2 " 5) algorithm for minimizing node reductions, based on vertex cover in a transitive auxiliary graph. Applications include the analysis of PERT networks, dynamic programming approaches to network problems, and network reliability. For NP-hard problems one can obtain algorithms that are exponential only in the minimum number of node reductions rather {{than the number of}} vertices. This gives improvements if the underlying graph is nearly series-parallel...|$|R
40|$|We study an {{extension}} of Plotkin's call-by-value lambda-calculus via two commutation rules (sigma-reductions). These commutation rules are sufficient to remove harmful call-by-value normal forms from the calculus, so that it enjoys elegant characterizations of many semantic properties. We prove that this extended calculus is a conservative refinement of Plotkin's one. In particular, the notions of solvability and potential valuability for this calculus coincide with those for Plotkin's call-by-value lambda-calculus. The proof rests on a standardization theorem proved by generalizing Takahashi's approach of <b>parallel</b> <b>reductions</b> to our set of reduction rules. The standardization is weak (i. e. redexes are not fully sequentialized) because of overlapping interferences between reductions. Comment: 27 page...|$|R
40|$|<b>Parallel</b> <b>reduction</b> {{algorithms}} {{are frequent}} in high performance computing areas, thus, modern parallel programming toolkits and languages often offer support for these algorithms. This article discusses important implementation aspects of built-in support for <b>parallel</b> <b>reduction</b> found in well-known OpenMP C/C++ language extension. It {{shows that the}} implementation in widely used GCC compiler is not efficient and suggests usage of custom reduction implementation improving the computational performance...|$|E
40|$|AbstractThe {{notion of}} <b>parallel</b> <b>reduction</b> is {{extracted}} from the simple proof of the Church-Rosser theorem by Tait and Martin-Löf. Intuitively, this means to reduce a number of redexes (existing in a λ-term) simultaneously. Thus {{in the case of}} β-reduction the effect of a <b>parallel</b> <b>reduction</b> is same as that of a "complete development" which is defined by using "residuals" of β-redexes. A nice feature of <b>parallel</b> <b>reduction,</b> however, is that it can be defined directly by induction on the structure of λ-terms (without referring to residuals or other auxiliary notions), and the inductive definition provides us exactly what we need in proving the theorem inductively. Moreover, the notion can be easily extended to other reduction systems such as Girard′s second-order system F and Gödel′s system T. In this paper, after reevaluating the significance of the notion of <b>parallel</b> <b>reduction</b> in Tait-and-Martin-Löf type proofs of the Church-Rosser theorems, we show that the notion of <b>parallel</b> <b>reduction</b> is also useful in giving short and direct proofs of some other fundamental theorems in reduction theory of λ-calculus; among others, we give such simple proofs of the standardization theorem for β-reduction (a special case of which is known as the leftmost reduction theorem for β-reduction), the quasi-leftmost reduction theorem for β-reduction, the postponement theorem of η-reduction (in βη-reduction), and the leftmost reduction theorem for βη-reduction...|$|E
40|$|In November 1984 three {{research}} {{groups at the}} universities of Amsterdam, Nijmegen and Utrecht started a cooperative project sponsored by the Dutch Ministry of Science and Education (Science Council). The first phase lasting {{until the end of}} 1987 is a pilot study and has as aim to answer the following question. Is it possible and realistic to construct an efficient <b>parallel</b> <b>reduction</b> machine? The present paper gives an outline of the problems concerning <b>parallel</b> <b>reduction</b> machines and of our research towards their solutions...|$|E
30|$|Rossi et al. [8] {{investigated}} {{the effects of}} Sinupret in an in vivo model of acute inflammation, carrageenan-induced pleurisy in rats. Sinupret significantly reduced exudate volume and leukocyte numbers in the pleural exudate. There were also <b>parallel</b> <b>reductions</b> in {{the expression of the}} enzyme cyclooxygenase- 2, which forms pro-inflammatory prostaglandin E 2. Zhang et al. [7] showed that Sinupret promotes transepithelial chloride transport, and enhances ciliary beat frequency and airway surface liquid depth. Taken together, these activities would tend to enhance mucus clearance. In vitro studies suggest that one underlying mechanism may be the binding of antioxidant components of the herbal medicine to CFTR (cystic fibrosis transmembrane conductance regulator), resulting in direct activation and enhanced chloride transport [11].|$|R
2500|$|... by Peter Kelly, Paul Coddington, and Andrew Wendelborn; {{mentions}} {{graph reduction}} {{as a common}} means of evaluating lambda expressions and discusses the applicability of lambda calculus for distributed computing (due to the Church–Rosser property, which enables <b>parallel</b> graph <b>reduction</b> for lambda expressions).|$|R
40|$|Randomizing polynomials {{allow to}} {{represent}} a function f(x) by a low-degree randomized mapping ˆ f(x, r) whose output distribution on an input x is a randomized encoding of f(x). It is known that any function f in ⊕L/poly (and in particular in NC 1) can be efficiently represented by degree- 3 randomizing polynomials. Such a degree- 3 representation gives rise to an NC 0 4 representation, in which every bit of the output depends on only 4 bits of the input. In this paper, we study the relaxed notion of computationally private randomizing polynomials, where the output distribution of ˆ f(x, r) should only be computationally indistinguishable from a randomized encoding of f(x). We construct degree- 3 randomizing polynomials of this type for every polynomial-time computable function, assuming {{the existence of a}} cryptographic pseudorandom generator (PRG) in ⊕L/poly. (The latter assumption is implied by most standard intractability assumptions used in cryptography.) This result is obtained by combining a variant of Yao’s garbled circuit technique with previous “informationtheoretic” constructions of randomizing polynomials. We then present the following applications: • Relaxed assumptions for cryptography in NC 0. Assuming a PRG in ⊕L/poly, the existence of an arbitrary public-key encryption, commitment, or signature scheme implies the existence of such a scheme in NC 0 4. Previously, one needed to assume the existence of such schemes in ⊕L/poly or similar classes. • New <b>parallel</b> <b>reductions</b> between cryptographic primitives. We show that even some relatively complex cryptographic primitives, including (stateless) symmetric encryption and digital signatures, are NC 0 -reducible to a PRG. No <b>parallel</b> <b>reductions</b> of this type were previously known, even in NC...|$|R
3000|$|Find four extreme {{points that}} have the max or min x and y {{coordinates}} by <b>parallel</b> <b>reduction,</b> denote them as P_minx, P_maxx, P_miny, and P_maxy [...]...|$|E
40|$|ESPRIT Project 415 {{has taken}} what are {{considered}} to be good programming language styles and is developing parallel architectures to support them. Here we describe the part of the project which is developing a distributed memory architecture for functional languages. Designing parallel architectures for evaluating functional languages presents many challenging problems. Firstly a model for the <b>parallel</b> <b>reduction</b> of such languages must be found. An abstract interpretation has been developed which leads to a <b>parallel</b> <b>reduction</b> model. It can be implemented in a compiler so that programs can automatically be annotated with parallelism information. The original COBWEB, a novel distributed memory architecture, is described, along with the conclusions we have drawn from our simulation work. We also briefly describe some of the architectural features of the architecture we are designing to support the <b>parallel</b> <b>reduction</b> model. Many programming languages including functional ones require automatic storage allocation which has to be garbage collected. We present another piece of work from our project which has resulted in the discovery of a distributed reference counting garbage collection algorithm which has very low overheads. ...|$|E
40|$|Skeleton {{programming}} enables programmers {{to build}} parallel programs easier by providing efficient ready-made parallel algorithms. The diffusion skeleton was proposed (associated with {{a method for}} program derivation) to abstract a good combination of primitive skeletons, such as map, <b>parallel</b> <b>reduction</b> and parallel prefix sum (scan) ...|$|E
30|$|This paper details a {{software}} ecosystem comprising three free and open-source Python packages for processing raw ultrafast electron scattering (UES) data and interactively exploring the processed data. The first package, iris, is graphical user-interface program and library for interactive exploration of UES data. Under the hood, iris {{makes use of}} npstreams, an extensions of numpy to streaming array-processing, for high-throughput <b>parallel</b> data <b>reduction.</b> Finally, we present scikit-ued, a library of reusable routines and data structures for analysis of UES data, including specialized image processing algorithms, simulation routines, and crystal structure manipulation operations. In this paper, some of the features or all three packages are highlighted, such as <b>parallel</b> data <b>reduction,</b> image registration, interactive exploration. The packages are fully tested and documented and are released under permissive licenses.|$|R
40|$|Examining committee: Michael Hibbard, chair, Richard MargerumDeclines in {{timber harvest}} and {{changing}} economic opportunities in communities adjacent to National Forest have challenged the traditional socioeconomic fabric of many communities. <b>Paralleling</b> <b>reductions</b> in harvest levels, new resource management activities {{are beginning to}} emerge which may {{have the potential to}} replace parts of this lost economic driver. This report uses the Malheur National Forest as a case study for the opportunity of the new natural resource economy, which includes activities such as restoration, recreation and sustainable natural resource management. As many communities are still struggling to initiate and realize economic benefits, this research hopes to build capacity for communities, stakeholders and land managers to understand and measure the socio-economic effects of new land management activities...|$|R
40|$|AbstractIn {{the simple}} {{assignment}} problem, there are n processors, m tasks, and a {{relation between the}} processors and tasks; this relation indicates {{the ability of the}} processor to perform the task. When the processors fail independently with known probabilities, two performance issues arise. First, with what probability can the operating processors all be kept busy? Second, with what probability can the operating processors perform the same number of tasks that all processors could? We formulate these questions on the underlying transversal matroid. We first prove that counting minimum cardinality circuits in this matroid is # P-complete and, hence, that both questions are also # P-complete. Secondly, we devise a factoring algorithm with series and <b>parallel</b> <b>reductions</b> to compute the exact solutions of the above problems. We then outline some efficient strategies for bounding the probabilities...|$|R
