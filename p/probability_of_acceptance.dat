115|10000|Public
5000|$|Case-based {{evidence}} has proven itself particularly well {{when it comes}} to the investigation of acceptance and trust in products and processes. In this area, forecasts of the probable acceptance of new products, services, processes, or similar can often be made with particular success and indications extracted from isomorphic cases as to how the <b>probability</b> <b>of</b> <b>acceptance</b> can be increased in particular cases. These approaches take into consideration a close cooperation with other academics - both scientists and practitioners - with regard to the following points: ...|$|E
50|$|Now, if z {{is drawn}} from uniform distribution, the {{probability}} that the above algorithm accepts is ≤ 1/2l, since the size of image is 1/2l {{of the size of the}} pre-image. However, if z was drawn from the output of Gl then the <b>probability</b> <b>of</b> <b>acceptance</b> is > ε by assumption of the existence of circuit C. Therefore, the advantage that circuit C has in distinguishing between the uniform U and output of Gl is > ε &minus; 1/2l, which is non-negligible and thus contradicts our assumption of Gl being a pseudorandom generator. Q.E.D.|$|E
5000|$|Now we justify our {{without loss}} of {{generality}} assumption. Let [...] be the polynomial {{upper bound on}} the running time of A on input x. Thus A makes at most [...] random coin flips during its execution. In particular, [...] since the <b>probability</b> <b>of</b> <b>acceptance</b> is an integer multiple of [...] Define a machine A' [...] as follows: on input x, A' [...] runs A as a subroutine, and rejects if A would reject; otherwise, if A would accept, A' [...] flips [...] coins and rejects if they are all heads, and accepts otherwise. Then ...|$|E
40|$|The {{presence}} of special early retirement bonuses {{can change the}} work incentives of older workers. This study applies a pension acceptance model to <b>acceptance</b> <b>of</b> an early retirement pension bonus; <b>probabilities</b> <b>of</b> <b>acceptance</b> range from. 18 to. 33. It also simulates acceptance behavior without the bonus, with <b>probabilities</b> <b>of</b> <b>acceptance</b> ranging from. 11 to. 30. ...|$|R
30|$|It can be {{seen from}} the {{previous}} equations that the joint <b>probability</b> <b>of</b> false rejection increases while the joint <b>probability</b> <b>of</b> false <b>acceptance</b> decreases when using the AND conjunction rule.|$|R
40|$|Canavalia ensiformis, Crotalaria grahamiana, Dolichos lablab, Mucuna pruriens, Tephrosia vogellii and Tithonia diversifolia were {{evaluated}} as potential species for soil fertility replenishment in on-farm adaptive trials, farm visits and field days in Tororo District, eastern Uganda. Farmers used multiple criteria for assessing and selecting those species that fitted within their production systems and production objectives. Farmers also adapted the technologies {{to allow for}} local opportunities and constraints. A preference ranking and logit regression analysis <b>of</b> <b>probabilities</b> <b>of</b> <b>acceptance</b> <b>of</b> the species conducted in 19 farmer groups showed that Mucuna had high, Tithonia and Crotalaria intermediate, and Canavalia, Lablab and Tephrosia low <b>probabilities</b> <b>of</b> being accepted or adopted. The evaluations showed that whilst technologies need to be adapted, a single-use technology had little chance of large-scale adoption. This paper highlights adaptations/innovations by farmers, and opportunities for participatory action research targeting farmers' production objectives. Peer-reviewe...|$|R
5000|$|For {{unbounded}} error logspace machines, unbounded {{time can}} be reduced to polynomial time as follows. Computing acceptance probability {{can be reduced to}} solving a linear system. For each state , add a variable [...] - [...] <b>probability</b> <b>of</b> <b>acceptance</b> if current state is i. If there is no path from i to Accept, set , and otherwise express [...] in terms of states immediately reachable from state i. The system can be solved using determinants, and testing whether [...] is in PL. [...] One complication is that the coefficients are in NL (using NL=coNL). We address it by guessing a 'proof' for each coefficient value, failing if the guess does not work, and ensuring that all paths make the same number of guesses for each coefficient.|$|E
50|$|The Metropolis-Hastings {{algorithm}} {{works by}} generating {{a sequence of}} sample values {{in such a way}} that, as more and more sample values are produced, the distribution of values more closely approximates the desired distribution, P(x). These sample values are produced iteratively, with the distribution of the next sample being dependent only on the current sample value (thus making the sequence of samples into a Markov chain). Specifically, at each iteration, the algorithm picks a candidate for the next sample value based on the current sample value. Then, with some probability, the candidate is either accepted (in which case the candidate value is used in the next iteration) or rejected (in which case the candidate value is discarded, and current value is reused in the next iteration)−the <b>probability</b> <b>of</b> <b>acceptance</b> is determined by comparing the values of the function f(x) of the current and candidate sample values with respect to the desired distribution P(x).|$|E
5000|$|There {{are various}} ways of {{generating}} directed networks with specified trophic coherence, {{all based on}} gradually introducing new edges to the system {{in such a way}} that the probability of each new candidate edge being accepted depends on the expected trophic difference it would have. The preferential preying model is an evolving network model similar to the [...] Barábasi-Albert model of preferential attachment, but inspired on an ecosystem that grows through immigration of new species.One begins with [...] basal nodes and proceeds to introduce new nodes up to a total of [...]Each new node [...] is assigned a first in-neighbour [...] (a prey species in the food-web context) and a new edge is placed from [...] to [...] The new node is given a temporary trophic level [...]Then a further [...] new in-neighbours [...] are chosen for [...] from among those in the network according to their trophic levels. Specifically, for a new candidate in-neighbour , the probability of being chosen is a function of [...] Johnson et al usewhere [...] is a parameter which tunes the trophic coherence: for [...] maximally coherent networks are generated, and increases monotonically with [...] for [...]The choice of [...] is arbitrary. One possibility is to set to ,where [...] is the number of nodes already in the network when [...] arrives, and [...] is a random variable drawn from a [...] Beta distributionwith parameters [...] and( [...] being the desired number of edges).This way, the generalised cascade model is recovered in the limit , and the degree distributions are as in the niche model and generalised niche model.This algorithm, as described above, generates networks with no cycles (except for self-cycles, if the new node [...] is itself considered among its candidate in-neighbours [...] ). In order for cycles of all lengths to be a possible, one can consider new candidate edges in which the new node [...] is the in-neighbour as well as those in which it would be the out-neighbour. The <b>probability</b> <b>of</b> <b>acceptance</b> of these edges, , then depends on [...]|$|E
40|$|Abstract. This paper {{considers}} parallel {{execution of}} the standard simulated an-nealing algorithm using speculative computing. Various heuristics for estimating the <b>probabilities</b> <b>of</b> move <b>acceptance</b> are advanced and their performance compared experimentally. Some {{are found to be}} superior to methods previously published...|$|R
40|$|Results of {{research}} appears {{to indicate that}} peer acceptance is vital to a successful mainstreaming process. If understanding is to be fostered in children, teachers must provide class members with opportunities for building acceptance. One highly effective and inexpensive method of building empathy and increasing the <b>probability</b> <b>of</b> peer <b>acceptance</b> {{is the use of}} Teletherapy...|$|R
40|$|An {{alternate}} {{model for}} rumor spreading over small-world networks is suggested, of which two rumors (termed rumor 1 and rumor 2) have different nodes and <b>probabilities</b> <b>of</b> <b>acceptance.</b> The propagation is not symmetric {{in the sense}} that when deciding which rumor to adopt, high-degree nodes always consider rumor 1 first, and low-degree nodes always consider rumor 2 first. The model is a natural generalization of the well-known epidemic SIS model and reduces to it when some of the parameters of this model are zero. We find that rumor 1 (preferred by high-degree nodes) is dominant in the network when the degree of nodes is high enough and/or when the network contains large clustered groups of nodes, expelling rumor 2. However, numerical simulations on synthetic networks show that it is possible for rumor 2 to occupy a nonzero fraction of the nodes in many cases as well. Specifically, in the NW small-world model a moderate level of clustering supports its adoption, while increasing randomness reduces it...|$|R
40|$|Double Acceptance Sampling Plans (DASP) is {{developed}} for a truncated life test when {{the lifetime of}} an item follows the Marshall-Olkin extended Lomax distribution. <b>Probability</b> <b>of</b> <b>Acceptance</b> (PA) is calculated for different consumer’s confidence levels fixing the producer’s risk at 0. 05. <b>Probability</b> <b>of</b> <b>acceptance</b> and producer’s risk are illustrated with examples...|$|E
40|$|Abstract: The average <b>probability</b> <b>of</b> <b>acceptance</b> (APA) is {{obtained}} {{for a single}} sampling plan assuming a Gamma prior distribution. Formula for inflection point and tangent at the inflection point are also derived. Tables are provided for selection of plan parameters. Key words: Single sampling attributes plan, Gamma prior distribution, average <b>probability</b> <b>of</b> <b>acceptance</b> curve, Bayesian inflection point. ...|$|E
30|$|Eligibility for {{automatic}} admissions {{could also}} {{increase the likelihood of}} applying to a particular school. A number of studies find that as race-based affirmative action policies were eliminated, the decrease in <b>probability</b> <b>of</b> <b>acceptance</b> for minority students led to lower application rates to competitive colleges (Long, 2004 b; Brown and Hirschman, 2006), even though highly qualified minority applicants were less affected (Antonovics and Backes, 2013). By increasing the <b>probability</b> <b>of</b> <b>acceptance</b> to 100 percent for students who are ranked in the top of their class, automatic admission policies should increase the number of applications from TTP students. Even if being in the TTP does not actually increase the <b>probability</b> <b>of</b> <b>acceptance</b> conditional on applying, the TTP Plan makes the admissions guarantee explicit, and this alone could change application behavior if students were not aware that they had a very high probability of being accepted without the highly visible TTP Plan.|$|E
40|$|This article {{proposes a}} simple formal model that can explain {{why and how}} European states engaged in the {{negotiation}} of federalist treaties {{in the fields of}} European defense and security. Using the non-cooperative model of multilateral bargaining derived from the Stahl-Rubinstein game, we show that the specific sequencing of treaty negotiations adopted by federalists explains why, against all odds, states preferred federalist-inspired treaties to intergovernmental treaties. We argue that federalists succeeded in convincing states to sign their treaties, rather than alternative treaties, by spreading the risk of rejection attached to various components of European security treaties into successive periods of negotiations, a process that they repeated in each new round of negotiation. In doing so, we show that Jean Monnet and his transnational network of European federalists had an influence on the process of EU integration because they segmented treaties into components with different <b>probabilities</b> <b>of</b> <b>acceptance,</b> and structured the different rounds of negotiations of these components by starting with the less risky ones, rather than because they convinced states to change their preferences and adopt federalist treaties instead of intergovernmental treaties...|$|R
30|$|In this paper, {{we present}} a new cost-sensitive {{framework}} for customer churn predictive modeling. First we propose a new financial based measure for evaluating {{the effectiveness of a}} churn campaign taking into account the available portfolio of offers, their individual financial cost and <b>probability</b> <b>of</b> offer <b>acceptance</b> depending on the customer profile. Then, using a real-world churn dataset we compare different cost-insensitive and cost-sensitive classification algorithms and measure their effectiveness based on their predictive power and also the cost optimization. The results show that using a cost-sensitive approach yields to an increase in cost savings of up to 26.4 %.|$|R
40|$|This study {{examines}} how audit risk (the <b>probability</b> <b>of</b> false <b>acceptance)</b> and its components change when the auditor obtains audit evidence in an acceptance sampling model. Inherent risk and audit risk increase with audit evidence if the auditee has a sufficiently strong incentive for committing fraud. Detection risk always increases when audit evidence is introduced. If the auditor has a sufficiently strong incentive for avoiding false rejection, audit risk also increases with audit evidence. The analysis indicates that requiring auditors {{to obtain information}} is not effective in preventing material misstatements {{in at least some}} instances. Strategic audits Audit risk Audit evidence Acceptance sampling...|$|R
40|$|In this research, we {{provides}} the investigation over {{the acceptance of}} going concern audit opinion by observing the company’s internal condition such as the audit quality, company’s financial condition, audit opinion prior year, company growth, company size, debt to asset ratio, and opinion shopping. Samples are obtained by purposive sampling method and 138 observation data from 2008 - 2013 at manufacturing companies listed at Indonesia Stock Exchange. The logistic regression {{used to examine the}} factors that are predicted to affect the <b>probability</b> <b>of</b> <b>acceptance</b> of going concern audit opinion. The result of this research indicate that debt to asset ratio affect the <b>probability</b> <b>of</b> <b>acceptance</b> of going concern audit opinion and audit opinion prior year significantly affect the <b>probability</b> <b>of</b> <b>acceptance</b> of going concern audit opinion. On the other hand audit quality, company’s financial condition, company size, opinion shopping, company growth do not significantly acceptance of going concern audit opinion...|$|E
3000|$|In {{this section}} we {{describe}} the dataset {{used to evaluate the}} different cost-insensitive and cost-sensitive classification algorithms. Afterwards, we show the procedure used to estimate the <b>probability</b> <b>of</b> <b>acceptance</b> (γ [...]...|$|E
40|$|Uncertainty {{concerning}} the ultimate outcome of tender offers {{may affect the}} measurement of changes in shareholder wealth. The uncertainty regarding the outcome of tender offers is measured by estimating the <b>probability</b> <b>of</b> <b>acceptance</b> of tender offers during the period when the tender offers are outstanding. The estimated <b>probability</b> <b>of</b> <b>acceptance</b> of tender offers implies {{that the amount of}} uncertainty prior to knowledge of the ultimate outcome is substantial and affects the measurement of expected equity gains. The uncertainty-adjusted measure of the change in shareholder wealth indicates that previous studies may have underestimated the gains expected to result from tender offers...|$|E
40|$|The {{statistical}} {{evaluation of the}} reliability of binary tests and inspections is a challenging endeavor. In this paper, we propose an approach for the common situation where the true condition of the inspected items is unobservable (“gold-standard unavailable”), the <b>probabilities</b> <b>of</b> false <b>acceptance</b> and false rejection vary across items, and rejections are relatively rare. Our approach fits a latent-variable model, where the variability in misclassification probabilities is driven by a continuous property of a part. To deal with the low prevalence of rejections, we propose sampling items from multiple sources. The performance and properties of the estimators are assessed using simulation, asymptotic approximations, and a real-life case at a car-parts manufacturer...|$|R
40|$|Abstract Containers and cargos {{arriving}} at port-of-entry are inspected using sensors and devices to detect drugs, weapons, nuclear materials and other illegal items. Measurement errors {{associated with the}} inspection process may result in higher percentage of misclassification of containers. In this paper, we propose and formulate three inspection policies for containers at port-of-entry assuming the presence of sensor measurement errors. The optimization of the policies is carried out {{and the performance of}} each in terms <b>of</b> misclassification <b>probabilities</b> is compared. In each of the policies, the optimum settings are determined by minimizing the <b>probability</b> <b>of</b> false rejection while limiting the <b>probability</b> <b>of</b> false <b>acceptance</b> at a very low tolerance level. The results show that the policy of repeat inspections improves the performance in terms of correct container classification...|$|R
40|$|This paper {{introduces}} {{the concept of}} Comprehensive Brand Presentation (CBP), a formalized approach to aligning manufacturing and communications functions in the business firm. The lynch pins of the CBP are Total Quality Management (TQM) principles and integration of marketing communications. The CBP enhances success through synergistic execution of the manufacturing and marketing processes via increased focus on measuring customer response to both manufactured product and promotional effort supporting that product. CBP defines the TQM principle of "out of control " as the variance between target product image and actual product image seen by the target customer. CBP's operational objective is to minimize that variance, and, thereby, maximizing the expected <b>probability</b> <b>of</b> product <b>acceptance</b> and subsequent target market brand loyally...|$|R
40|$|In {{analysing}} {{whether there}} is an editorial bias in favour of positive studies, researchers have made implicit assumptions that are implausible. In particular, to justify the conclusion that there is no bias because observed editorial acceptance rates do not favour positive studies, the assumption that the decision to submit an article is based solely on quality would be required. If, on the other hand, submission were based on perceived <b>probability</b> <b>of</b> <b>acceptance,</b> negative and positive studies would not differ in terms of acceptance rates, but in terms of quality. It is shown, using a simple graphical model, how similar underlying situations as regards the relationship between quality and <b>probability</b> <b>of</b> <b>acceptance</b> {{on the one hand and}} study outcome (positive or negative) and <b>probability</b> <b>of</b> <b>acceptance</b> on the other could produce dramatically different results depending on the behaviour of authors. Furthermore, there is, in fact, some evidence that submitted negative studies are, on average, of higher quality than positive ones. This calls into question the standard interpretation of the studies examining editorial bias. It would appear that despite similar probabilities of acceptance for negative and positive studies, editors could be discriminating against negative studies...|$|E
40|$|This paper {{states the}} various methods to {{evaluate}} performance of various Multistage Interconnection Networks. A number of Interconnection Networks are studied {{to get the}} most reliable network. We have implemented three different algorithms to find the reliability of a network and to get the <b>probability</b> <b>of</b> <b>acceptance</b> of a Multistage Interconnection Network. We also {{come to the conclusion that}} the Irregular Multistage Interconnection Networks are more reliable than Regular Multistage Interconnection Network because the number of stages in Irregular Multistage Interconnection Networks are lesser than that of Regular Multistage Interconnection Networks. A Number of Performance factors are used like Bandwidth, <b>Probability</b> <b>of</b> <b>Acceptance</b> and cost of regular and irregular interconnection networks. We will also compute reliability of various Multistage Interconnection Networks with and without repairing of switching elements...|$|E
30|$|Initial {{temperature}} T 0. The {{initial temperature}} must satisfy {{the requirement that}} all proposed models are acceptable solutions for the next iteration of the calculation. We choose a small positive number at first, then multiply by a constant value b >  1, until the <b>probability</b> <b>of</b> <b>acceptance</b> of each proposed model converges to unity.|$|E
40|$|As {{the public}} debate over stem cell {{research}} continues, the observable voting behaviour in Switzerland offers {{a unique opportunity to}} compare the voting behaviour of politicians with that of voters. By analysing the outcomes of a referendum on a liberal new bill regulating such research, we reveal an about 10 percentage point lower conditional <b>probability</b> <b>of</b> the bill being accepted by politicians than by voters. Whereas the behaviour of politicians is driven almost entirely by party affiliation, citizen votes are driven not only by party attachment but also by church attendance. Seldom or never attending church increases the <b>probability</b> <b>of</b> bill <b>acceptance</b> by over 15 percentage points, while supporting the Liberal Party and the Social Democratic Party instead of the Christian Democratic Party makes supporting the bill more likely for voters, suggesting that religious observance is important. The observance of these tendencies in Switzerland - an environment that promotes discussion through direct democratic rights - strongly suggests that citizens see the benefits of stem cell research...|$|R
40|$|Clause 5. 3 of ANSI/NCSL Z 540. 3, "Requirements for the Calibration of Measuring and Test Equipment, " {{contains}} a risk management requirement for {{cases where the}} results of calibration are employed to verify that quantities are within specified tolerances. This requirement limits the <b>probability</b> <b>of</b> incorrect <b>acceptance</b> decisions (false accept risk) {{to a maximum of}} 2 %. Where the estimation <b>of</b> this <b>probability</b> is not feasible, the test uncertainty ratio (TUR) is required to be 4 : 1 or greater. This paper provides the mathematical framework for computing false accept risk and gives guidelines for managing in-tolerance compliance decisions. The latter includes methods for developing test guardbands that correspond to specified risk levels. Included in the paper is a discussion of the impact of measurement reliability and measurement uncertainty on false accept risk. A brief discussion is given on the application of the fallback 4 : 1 uncertainty ratio requirement. 1. Background Measurement decision risk analysis attempts to quantify the <b>probability</b> <b>of</b> falsely accepting, as...|$|R
40|$|International audienceIn Measurement Based Admission Control (MBAC), the {{decision}} of accepting or rejecting a new flow is based on measurements of the current traffic situation. Since MBAC relies on measurements, an in-depth understanding of the measurement error {{and how it is}} affected by the underlying traffic is vital for the design of a robust MBAC. In this work, we study how the measurement error impacts the admission decision, in terms of false rejections and false acceptances, and the consequence this has for the MBAC performance. A slack in bandwidth must be added to reduce the <b>probability</b> <b>of</b> false <b>acceptance.</b> When determining the size of this slack, the service provider is confronted with the trade-off between maximizing useful traffic and reducing useless traffic. We show how the system can be provisioned to meet a predefined performance criteria...|$|R
40|$|Abstract- A {{formula to}} compute the average <b>probability</b> <b>of</b> <b>acceptance</b> of chain {{sampling}} plans (ChSP- 1) by attributes under Beta- Geometric distribution is provided. The performance/ discriminating power of the beta-geometric sampling plans is also discussed by determining the operating characteristic curve. The Average Probabilities of Acceptance are compared with conventional sampling plans...|$|E
40|$|Abstract. Simulated {{annealing}} (SA) converges {{by means}} of a <b>probability</b> <b>of</b> <b>acceptance</b> toward a minimum value of the cost function to a minimum temperature. When the cost function is very high, the <b>probability</b> <b>of</b> <b>acceptance</b> is minimum when temperature descends to a minimum value, for this, the probability is controlled for the temperature. An incorrect tuning of this parameter makes that the distribution of the probabilities of acceptance along the whole process of SA is slanted toward values very low or very high, what cause fall easily in local optimum. In this paper an analysis of correlation between the standard deviation and the distribution of probabilities of Boltzmann is made. The experimental results demonstrate that the standard deviation obtained through a sample of the solutions space of the problem, allow for a good tune of the initial temperature in SA. ...|$|E
3000|$|... where OFV and OFV B [...] are the {{objective}} function values for this iteration {{and are the}} best computed one until this iteration. T is {{the temperature of the}} algorithm in the iteration, and P is the <b>probability</b> <b>of</b> <b>acceptance</b> for each move in the annealing process. The proposed SA pseudo code for QAP is as follows: [...]...|$|E
40|$|Abstract. In Measurement Based Admission Control (MBAC), the {{decision}} of accepting or rejecting a new ow is based on measurements of the current tra c situation. Since MBAC relies on measurements, an in-depth understanding of the measurement error {{and how it is}} a ected by the underlying tra c is vital for the design of a robust MBAC. In this work, we study how the measurement error impacts the admission decision, in terms of false rejections and false acceptances, and the consequence this has for the MBAC performance. A slack in bandwidth must be added to reduce the <b>probability</b> <b>of</b> false <b>acceptance.</b> When determining the size of this slack, the service provider is confronted with the trade-o between maximizing useful tra c and reducing useless tra c. We show how the system can be provisioned to meet a prede ned performance criteria. ...|$|R
40|$|Supply {{chains are}} a current, {{challenging}} problem for agentbased electronic commerce. Motivated by the Trading Agent Competition Supply Chain Management (TAC SCM) scenario, we consider an individual supply chain agent as having three major subtasks: acquiring supplies, selling products, and managing its local manufacturing process. In this paper, {{we focus on}} the sales subtask. In particular, we consider the problem of finding the set of bids to customers in simultaneous reverse auctions that maximizes the agent's expected profit. The key technical challenge we address in this paper is that <b>of</b> determining the <b>probability</b> that a customer will accept a particular bid price. First, we compare several machine learning approaches to estimating the <b>probability</b> <b>of</b> bid <b>acceptance.</b> We then perform experiments in which we apply our learning method during actual gameplay to measure the impact on agent performance...|$|R
40|$|We {{present a}} {{multimodal}} approach to face verification which draws on two distinct knowledge sources of biometric {{information concerning the}} subject. A B-spline lip tracker provides the control information regarding {{the state of the}} lip shape which is used by a conventional eigenface based face verification system to confirm or reject a claimed personal identity. The performance of the system tested on the M 2 VTS database shows a promising improvement over the unimodal approach. This improvement derives from the achieved reduction in the population entropy of the models, thus minimising the <b>probability</b> <b>of</b> imposter <b>acceptance.</b> 1 Introduction Int. Conf. on Audio- and Video-based Biometric Person Authentication, Crans Montana, Switzerland, 1997. The problem of automatic recognition of individuals based on biometric data has received considerable attention over the last decade, with a focus on nonintrusive techniques such as face recognition. Traditionally, the decision making process wou [...] ...|$|R
