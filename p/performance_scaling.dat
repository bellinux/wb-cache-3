230|2815|Public
25|$|LMDB {{may also}} be used {{concurrently}} in a multi-threaded or multi-processing environment, with read <b>performance</b> <b>scaling</b> linearly by design. LMDB databases may have only one writer at a time, however unlike many similar key-value databases, write transactions do not block readers, nor do readers block writers. LMDB is also unusual in that multiple applications on the same system may simultaneously open and use the same LMDB store, {{as a means to}} scale up performance. Also, LMDB does not require a transaction log (thereby increasing write performance by not needing to write data twice) because it maintains data integrity inherently by design.|$|E
5000|$|Close to linear <b>performance</b> <b>scaling</b> from {{reordering}} command buffers onto multiple CPU cores ...|$|E
50|$|IEEE Rebooting Computing has {{established}} a collaborative relationship with the ITRS. The two organizations initiated an exchange of information in 2014. Following the signing of a formal collaboration agreement, IEEE Rebooting Computing and ITRS arranged and held joint international workshops in 2015 {{with the objective of}} identifying computer <b>performance</b> <b>scaling</b> challenges and establishing a roadmap to successfully restart computer <b>performance</b> <b>scaling.</b> IEEE Rebooting Computing further collaborated with ITRS on a new effort, known as ITRS 2.0, that extends beyond traditional Moore's Law scaling of chips to include roadmaps covering systems and applications.|$|E
50|$|And/or <b>performance</b> <b>scale</b> 2: symptomatic, normal activity.|$|R
30|$|Outcome of the {{patients}} was estimated according to the Karnofsky <b>performance</b> <b>scale.</b>|$|R
50|$|And/or <b>performance</b> <b>scale</b> 3: {{bedridden}} < 50% of the {{day during}} last month.|$|R
50|$|Note {{that all}} of the above {{innovations}} for CPU power consumption preceded Barroso and Hölzle's paper on energy proportionality. However, most of them have contributed some combination of the two broad types of power management mentioned above, namely, idle power-down and active <b>performance</b> <b>scaling.</b> These innovations have made CPUs scale their power relatively well in relation to their utilization, making them the most energy-proportional of computer hardware components. Unlike CPUs, most other computer hardware components lack power management controls, especially those that enable active <b>performance</b> <b>scaling.</b> CPUs are touted as a good example of energy-proportional computer engineering that other components should strive to emulate.|$|E
50|$|Distributing objects among {{processing}} units {{is often}} referred to as sort last rendering. It provides good data scaling and can provide good <b>performance</b> <b>scaling,</b> but it requires the intermediate images from processing nodes to be alpha composited to create the final image. As the image resolution grows, the alpha compositing overhead also grows.|$|E
5000|$|Each {{processing}} unit can render an entire frame {{from a different}} point of view or moment in time. The frames rendered from different points of view can improve image quality with anti-aliasing or add effects like depth-of-field and three-dimensional display output. This approach allows for good <b>performance</b> <b>scaling</b> but no data scaling.|$|E
5000|$|Leiter International <b>Performance</b> <b>Scale</b> {{or simply}} Leiter scale is an {{intelligence}} {{test in the}} form of a strict <b>performance</b> <b>scale.</b> It was designed for children and adolescents ages 2 to 18, although it can yield an intelligence quotient (IQ) and a measure of logical ability for all ages. The Leiter series of assessments have been produced and published by Stoelting.|$|R
30|$|HRQOL and <b>performance</b> <b>scales</b> were {{completed}} at baseline for all patients {{regardless of the}} treatment type (chemotherapy, radiotherapy or a combination).|$|R
5000|$|CSS : Servo's {{parallel}} {{style sheet}} system integrated into Gecko. Benchmarks suggest that <b>performance</b> <b>scales</b> linearly with number of CPU cores.|$|R
5000|$|ITRS Chairman Paolo Gargini said, [...] "The ITRS shares IEEE Rebooting Computing’s {{mission to}} restore {{computing}} to its historic exponential <b>performance</b> <b>scaling</b> trends so {{our society and}} future societies can benefit. Our agreement will ensure we help fundamentally shift the computer industry’s focus, resources, time and attention on to new possibilities for computational performance." ...|$|E
50|$|Researchers have {{proposed}} improving the low power idle states of servers, and the wake-up/shutdown latencies between active and idle modes, {{because this is}} an easier optimization goal than active <b>performance</b> <b>scaling.</b> If servers could wake up and shutdown at a very fine time granularity, then the server would become energy proportional, even if active power is constant at all utilizations.|$|E
5000|$|... == History == The <b>performance</b> <b>scaling</b> {{traditionally}} {{associated with}} Moore's Law—dating back to 1965—began to taper off around 2004, as both Intel's Prescott architecture and IBM's Cell processor pushed toward a 4 GHz operating frequency. Here both projects {{ran into a}} thermal scaling wall, whereby heat extraction problems associated with further increases in operating frequency largely outweighed gains from shorter cycle times.|$|E
40|$|This {{study is}} titled The Role of Baitul Maal Wa Tamwil (BMT) in Improving Business <b>Performance</b> <b>Scale</b> Households in Purwokerto, it’s {{carried out in}} order to {{determine}} the role of BMT in improving business <b>performance</b> household <b>scale,</b> the potential of BMT in household-scale enterprises development, and the contribution BMT in household-scale enterprises development From the research result shows that BMT has a strategic role to improve the business <b>performance</b> <b>scale</b> household because the financing needs of TMB bridge between bussiness with financial institutions. BMT has a good potential for business development so that developing domestic scale becomes larger. BMT gives contribute the development of household scale so it can encourage economic growth, employment, and other follow-up impac...|$|R
40|$|Introduction. Epilepsy surgery {{may be a}} {{promising}} alternative therapy for seizure control in patients with refractory seizures, resistant to medication. Cognitive outcome is another important factor {{in favor of the}} surgical decision. Aim. To investigate the correlation between seizure outcome and cognitive outcome after epilepsy surgery in a pediatric population. Patients and methods. A total of 59 pediatric patients were retrospectively assessed with the WISC-III (Full Scale, Verbal <b>Scale</b> and <b>Performance</b> <b>Scale)</b> before and, at least, 6 months after surgery. Patients were divided into two groups according whether or not improvement of seizure control after surgery. Data collected for each child included: epileptic syndrome, etiology, age at epilepsy onset, duration of epilepsy and seizure frequency. Results. Comparison using a MANOVA test revealed significant differences across pre-operative Full Scale, Verbal <b>Scale</b> and <b>Performance</b> <b>Scale</b> (p = 0. 01) with seizure reduction group performing better than no seizure reduction group. Seizure improvement group achieved significant <b>Performance</b> <b>Scale</b> improvement (p = 0. 01) and no seizure improvement group showed significant Verbal Scale worsened after surgery (p = 0. 01). Conclusions. Our results suggest that the success of the epilepsy surgery in childhood when the seizure control is achieved may also provide an improvement in the <b>Performance</b> <b>Scale</b> whereas the seizure maintenance may worsen the Verbal Scale...|$|R
40|$|The Palliative <b>Performance</b> <b>Scale</b> (PPS) uses five observer-rated domains {{correlated}} to the Karnofsky <b>Performance</b> <b>Scale</b> (100 - 0). The PPS is {{a reliable and}} valid tool and correlates well with actual survival and median survival time for cancer patients. It has been found useful for purposes of identifying and tracking potential care needs of palliative care patients, particularly as these needs change with disease progression. Large validation studies are still needed, as is analysis of how the PPS does, or does not, correlate with other available prognostic tools and commonly used symptom scales...|$|R
50|$|Distributing {{interlaced}} {{lines of}} pixels gives good load balancing but makes data scaling impossible. Distributing contiguous 2D tiles of pixels allows for data scaling by culling data {{with the view}} frustum. However, there is a data overhead from objects on frustum boundaries being replicated and data has to be loaded dynamically as the view point changes. Dynamic load balancing is also needed to maintain <b>performance</b> <b>scaling.</b>|$|E
50|$|There are two, often competing, {{reasons for}} using {{parallel}} rendering. <b>Performance</b> <b>scaling</b> allows frames to be rendered more quickly while data scaling allows larger data sets to be visualized. Different methods of distributing the workload {{tend to favor}} one type of scaling over the other. There can also be other advantages and disadvantages such as latency and load balancing issues. The three main options for primitives to distribute are entire frames, pixels, or objects (e.g. triangle meshes).|$|E
50|$|Transactions {{initiated}} via WebTS {{are subject}} to the same authentication as any other transaction and run with the same <b>performance,</b> <b>scaling,</b> and recovery. Such transactions may use the CGI APIs for communications with the client. Transactions developed for OS 2200 using the DPS display manager, typically require no changes or even recompilation to be fully operational with Web interfaces concurrently with terminals. Changes to DPS combined with client-side Java applets make everything transparent to the transaction program.|$|E
40|$|This study {{presents}} the first update of the Cognitive <b>Performance</b> <b>Scale</b> (CPS) in 20 years. Its goals are 3 -fold: extend category options; characterize {{how the new}} scale variant tracks with the Mini-Mental State Examination; and present a series of associative findings. Secondary analysis of data from 3733 older adults from 8 countries was completed. Examination of scale dimensions using older and new items was completed using a forward-entry stepwise regression. The revised scale was validated by examining the scale’s distribution with a self-reported dementia diagnosis, functional problems, living status, and distress measures. Cognitive <b>Performance</b> <b>Scale</b> 2 extends the measurement metric {{from a range of}} 0 to 6 for the original CPS, to 0 to 8. Relating CPS 2 to other measures of function, living status, and distress showed that changes in these external measures correspond with increased challenges in cognitive <b>performance.</b> Cognitive <b>Performance</b> <b>Scale</b> 2 enables repeated assessments, sensitive to detect changes particularly in early levels of cognitive decline...|$|R
30|$|The {{second group}} {{contains}} {{patients with the}} same Karnofsky <b>performance</b> status <b>scale,</b> ten patients (25 % of all patients) ranged from 60 to 90 % of the Karnofsky <b>performance</b> status <b>scale.</b>|$|R
5000|$|The non-verbal <b>performance</b> <b>scale</b> {{was also}} a {{critical}} difference from the Binet scale. Since the [...] "early Binet scale had been persistently and consistently criticized for its emphasis on language and verbal skills," [...] Wechsler made an entire scale that allowed the measurement of nonverbal intelligence. This became known as a <b>performance</b> <b>scale.</b> Essentially, this scale required a subject to do something (such as [...] "copying symbols or point to a missing detail") rather than just answer questions. This was an important development as it attempted to overcome biases that were caused by [...] "language, culture, and education." [...] Further, this scale also provided an opportunity to observe {{a different type of}} behavior because something physical was required. Clinicians were able to observe how a participant reacted to the [...] "longer interval of sustained effort, concentration, and attention" [...] that the performance tasks required. While the Wechsler-Bellevue scale was the first to effectively use the <b>performance</b> <b>scale</b> (meaning that (1) there was a [...] "possibility of directly comparing an individual's verbal and nonverbal intelligence", and (2) that [...] "the results of both scales were expressed in comparable units"), the idea had been around for a while. The Binet <b>scale</b> did have <b>performance</b> tasks (although they were geared towards children) and there were entire tests that were considered supplements or alternatives (an example of such a performance test is the Leiter International <b>Performance</b> <b>Scale).</b>|$|R
50|$|PCI Express (Peripheral Component Interconnect Express), officially {{abbreviated}} as PCIe or PCI-e, is {{a high-speed}} serial computer expansion bus standard, designed {{to replace the}} older PCI, PCI-X, and AGP bus standards. PCIe has numerous improvements over the older standards, including higher maximum system bus throughput, lower I/O pin count and smaller physical footprint, better <b>performance</b> <b>scaling</b> for bus devices, a more detailed error detection and reporting mechanism (Advanced Error Reporting, AER), and native hot-plug functionality. More recent revisions of the PCIe standard provide hardware support for I/O virtualization.|$|E
50|$|In {{computer}} science, a Judy array is a {{data structure}} implementing {{a type of}} associative array with high performance and low memory usage. Unlike most other key-value stores, Judy arrays use no hashing, leverage compression on their keys (which may be integers or strings), and can efficiently represent sparse data, that is, they may have large ranges of unassigned indices without greatly increasing memory usage or processing time. They are designed to remain efficient even on structures with sizes in the peta-element range, with <b>performance</b> <b>scaling</b> {{on the order of}} O(log256n). Roughly speaking, Judy arrays are highly optimized 256-ary radix trees.|$|E
50|$|LMDB {{may also}} be used {{concurrently}} in a multi-threaded or multi-processing environment, with read <b>performance</b> <b>scaling</b> linearly by design. LMDB databases may have only one writer at a time, however unlike many similar key-value databases, write transactions do not block readers, nor do readers block writers. LMDB is also unusual in that multiple applications on the same system may simultaneously open and use the same LMDB store, {{as a means to}} scale up performance. Also, LMDB does not require a transaction log (thereby increasing write performance by not needing to write data twice) because it maintains data integrity inherently by design.|$|E
30|$|Tucker et al.’s (2004) Job <b>Performance</b> <b>scale</b> (Additional file 2) {{measured}} job effectiveness (α = 0.81), and Tucker et al.’s Social Interaction scale (Additional file 3) assessed {{social interaction}} with cultural outgroup members (α = 0.72).|$|R
30|$|The {{first group}} {{contains}} patients with {{improvement of the}} Karnofsky <b>performance</b> status <b>scale,</b> 20 patients (50 % of all patients) improved one degree from (60 %– 70 %) to (70 %– 80 %) of the Karnofsky <b>performance</b> status <b>scale.</b>|$|R
30|$|The {{third group}} {{contains}} patients with {{deterioration of the}} Karnofsky <b>performance</b> status <b>scale,</b> ten patients (25 % of all patients) ranged from one to two degrees of deterioration of the Karnofsky <b>performance</b> status <b>scale,</b> the least scale was 40 %.|$|R
5000|$|Explicitly {{parallel}} instruction computing (EPIC) {{is a term}} coined in 1997 by the HP-Intel {{alliance to}} describe a computing paradigm that researchers had been investigating since the early 1980s. This paradigm is also called Independence architectures. It {{was the basis for}} Intel and HP development of the Intel Itanium architecture, and HP later asserted that [...] "EPIC" [...] was merely an old term for the Itanium architecture. EPIC permits microprocessors to execute software instructions in parallel by using the compiler, rather than complex on-die circuitry, to control parallel instruction execution. This was intended to allow simple <b>performance</b> <b>scaling</b> without resorting to higher clock frequencies.|$|E
5000|$|One of {{the design}} goals for the VSA-100 was scalability. The name of the chip is an {{abbreviation}} for [...] "Voodoo Scalable Architecture." [...] By using one or more VSA-100 chips on a board, the various market segments for graphics cards are satisfied with just a single graphics chip design. Theoretically, anywhere from 1 to 32 VSA-100 GPUs could be run in parallel on a single graphics card, and the fillrate of the card would increase proportionally. On cards {{with more than one}} VSA-100, the chips are linked using 3dfx's Scan-Line Interleave (SLI) technology. A major drawback to this method of <b>performance</b> <b>scaling</b> is that various parts of hardware are needlessly duplicated on the cards and board complexity increases with each additional processor.|$|E
50|$|Although {{conventional}} (annular) Hall thrusters are {{efficient in}} the kilowatt power regime, they become inefficient when scaled to small sizes. This {{is due to}} the difficulties associated with holding the <b>performance</b> <b>scaling</b> parameters constant while decreasing the channel size and increasing the applied magnetic field strength. This led to the design of the cylindrical Hall thruster. The cylindrical Hall thruster can be more readily scaled to smaller sizes due to its nonconventional discharge-chamber geometry and associated magnetic field profile. The cylindrical Hall thruster more readily lends itself to miniaturization and low-power operation than a conventional (annular) Hall thruster. The primary reason for cylindrical Hall thrusters is {{that it is difficult to}} achieve a regular Hall thruster that operates over a broad envelope from ~1 kW down to ~100 W while maintaining an efficiency of 45-55%.|$|E
40|$|To {{investigate}} {{the effects of}} both authentic and transformational leadership on performance a study is conducted among participants from various Dutch organizations. The first goal was to {{investigate the}} effects of authentic and transformational leadership on three different subjective <b>performance</b> <b>scales,</b> namely: team <b>performance,</b> Organizational Citizenship Behaviour (OCB) and the performance of the leader. Secondly, the results were compared with the effects of the traditionally more prevailing transactional leadership on performance. Thirdly, investigated was whether the effects of both authentic and transformational leadership on the subjective <b>performance</b> <b>scales</b> were moderated by the age of the follower. The current study found evidence of positive effects of both authentic and transformational leadership on performance. Furthermore these effects were, on most of the <b>performance</b> <b>scales,</b> larger than the effects of transactional leadership on performance. The current study found only a moderation effect of the age of the followers on the effect of transformational leadership on team performance. The results of the current study give important insights for organizations and their leaders. Furthermore, it contributes to the growing body of literature on the relationship between leadership and performance...|$|R
40|$|Each {{year over}} 1. 5 million health care {{professionals}} attend emergency care courses. Despite high stakes for patients and extensive resources involved, little evidence exists {{on the quality of}} assessment. The aim {{of this study was to}} evaluate the validity and reliability of commonly used formats in assessing emergency care skills. Residents were assessed at the end of a 2 -week emergency course; a subgroup was videotaped. Psychometric analyses were conducted to assess the validity and inter-rater reliability of the assessment instrument, which included a checklist, a 9 -item competency scale and a global <b>performance</b> <b>scale.</b> A group of 144 residents and 12 raters participated in the study; 22 residents were videotaped and re-assessed by 8 raters. The checklists showed limited validity and poor inter-rater reliability for the dimensions "correct" and "timely" (ICC = . 30 and. 39 resp.). The competency scale had good construct validity, consisting of a clinical and a communication subscale. The internal consistency of the (sub) scales was high (α = . 93 /. 91 /. 86). The inter-rater reliability was moderate for the clinical competency subscale (. 49) and the global <b>performance</b> <b>scale</b> (. 50), but poor for the communication subscale (. 27). A generalizability study showed that for a reliable assessment 5 - 13 raters are needed when using checklists, and four when using the clinical competency scale or the global <b>performance</b> <b>scale.</b> This study shows poor validity and reliability for assessing emergency skills with checklists but good validity and moderate reliability with clinical competency or global <b>performance</b> <b>scales.</b> Involving more raters can improve the reliability substantially. Recommendations are made to improve this high stakes skill assessment...|$|R
50|$|Input-sensitive {{profilers}} add {{a further}} dimension to flat or call-graph profilers by relating performance measures to {{features of the}} input workloads, such as input size or input values. They generate charts that characterize how an application's <b>performance</b> <b>scales</b> {{as a function of}} its input.|$|R
