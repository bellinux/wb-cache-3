87|142|Public
25|$|Some {{standard}} {{but rarely}} used options already exist in JPEG {{to improve the}} efficiency of coding DCT coefficients: the arithmetic coding option, and the <b>progressive</b> <b>coding</b> option (which produces lower bitrates because values for each coefficient are coded independently, and each coefficient has a significantly different distribution). Modern methods have improved on these techniques by reordering coefficients to group coefficients of larger magnitude together; using adjacent coefficients and blocks to predict new coefficient values; dividing blocks or coefficients up among {{a small number of}} independently coded models based on their statistics and adjacent values; and most recently, by decoding blocks, predicting subsequent blocks in the spatial domain, and then encoding these to generate predictions for DCT coefficients.|$|E
5000|$|FLIF {{uses the}} {{reversible}} YCoCg color space (unlike [...] that loses {{a bit of}} color information, independently of its use in otherwise lossy JPEG). Not yet implemented are some features, e.g. other [...] "color spaces (CMYK, YCbCr, ...)". The color space conversion is faster, but the overall decoding (and encoding) is still slower than it needs to be, {{or some of the}} competition, even with the better color space as that is {{only a small fraction of}} the overall process. The format supports an optional alpha channel (RGBA) like PNG (but unlike JPEG); and <b>progressive</b> <b>coding,</b> similar to PNG (unlike it, progressive compression doesn't increase file-size), but as FLIF's algorithm is more complex (and partly, may not have had as much tuning of the implementation yet), it has a higher computational cost; at least lower bandwidth requirements can offset some of that extra time. Without the <b>progressive</b> <b>coding,</b> FLIF is faster, than otherwise.|$|E
5000|$|Scalability {{generally}} {{refers to}} a quality reduction achieved by manipulation of the bitstream or file (without decompression and re-compression).Other names for scalability are <b>progressive</b> <b>coding</b> or embedded bitstreams.Despite its contrary nature, scalability also {{may be found in}} lossless codecs, usually in form of coarse-to-fine pixel scans.Scalability is especially useful for previewing images while downloading them (e.g., in a web browser) or for providing variable quality access to e.g., databases.There are several types of scalability: ...|$|E
5000|$|From 1927 to 1932, the <b>progressive</b> <b>code</b> {{was before}} the provincial code on a single line. Then, the <b>progressive</b> <b>code</b> {{was before the}} provincial code in front plates and after it in rear plates. Although Rome had the full name {{displayed}} on the number plates, in documents for practical purposes it uses the unofficial code RM.|$|R
50|$|The Georgian Public Broadcaster has a <b>progressive</b> <b>Code</b> of Conduct, {{as well as}} an {{ombudsman}} {{to receive}} viewers complaints.|$|R
50|$|In 1985, plates become black digits {{on white}} {{reflective}} background. Rear plate remained identical {{as in the}} period 1976-1985. Front plate becomes larger (32.5 × 10.7 cm)but remained slightly smaller than rear plates.The <b>progressive</b> <b>code</b> on it is moved after the provincial code, as it was already for rear plates.|$|R
50|$|Some {{standard}} {{but rarely}} used options already exist in JPEG {{to improve the}} efficiency of coding DCT coefficients: the arithmetic coding option, and the <b>progressive</b> <b>coding</b> option (which produces lower bitrates because values for each coefficient are coded independently, and each coefficient has a significantly different distribution). Modern methods have improved on these techniques by reordering coefficients to group coefficients of larger magnitude together; using adjacent coefficients and blocks to predict new coefficient values; dividing blocks or coefficients up among {{a small number of}} independently coded models based on their statistics and adjacent values; and most recently, by decoding blocks, predicting subsequent blocks in the spatial domain, and then encoding these to generate predictions for DCT coefficients.|$|E
5000|$|... mozjpeg is a fork from libjpeg-turbo done by Josh Aas {{and others}} from Mozilla Research. It aims to speed up loading times of webpages by {{achieving}} a reduction in file size (of about 10%) and therefore transmission time through improvement of coding efficiency at unchanged image quality. To achieve this, it uses more processing power for the encoding (asymmetry) while retaining full compatibility with the JPEG standard and requiring no changes on the decoder side.It is actually done by optimising Huffman trees, using <b>progressive</b> <b>coding</b> with optimised splitting of the spectrum of DCT coefficients into separate scans and {{through the use of}} trellis quantisation. Additionally, the presets are aggressively tuned towards the minimisation of file sizes.Besides libjpeg-turbo, mozjpeg builds also on jpegcrush, a Perl script by Loren Merritt.|$|E
40|$|Files of 3 D {{models are}} often large and {{time-consuming}} to download. Most 3 D viewers need the entire file {{to display a}} 3 D model even when the user is interested only {{in a part of}} or a low-resolution version of the model. Therefore, <b>progressive</b> <b>coding</b> of 3 D models is desired. However, existing work studies either the <b>progressive</b> <b>coding</b> of the geometry only, or <b>progressive</b> <b>coding</b> of the texture only. In this paper, we propose a joint geometry/texture coding technique for 3 D objects. Both of the geometry and the texture are progressively coded and transmitted to the viewer. The most perceptually important bits are sent before the less important bits, allowing the users to stop the download at any time and yet retain the best quality available at that time. 1. Summar...|$|E
5000|$|... a {{sufficiently}} <b>progressive</b> tax <b>code</b> {{to ensure a}} financially strong middle class ...|$|R
40|$|This paper {{proposes a}} novel scheme, based on <b>progressive</b> {{fountain}} <b>codes,</b> for broadcasting JPEG 2000 multimedia. In such a broadcast scheme, progressive resolution levels of images/video have been unequally protected when transmitted using the proposed <b>progressive</b> fountain <b>codes.</b> With <b>progressive</b> fountain <b>codes</b> {{applied in the}} broadcast scheme, the resolutions of images (JPEG 2000) or videos (MJPEG 2000) received by different users can be automatically adaptive to their channel qualities, i. e. the users with good channel qualities are possible to receive the high resolution images/vedio while the users with bad channel qualities may receive low resolution images/vedio. Finally, {{the performance of the}} proposed scheme is evaluated with the MJPEG 2000 broadcast prototype...|$|R
40|$|Kohonen's {{self-organizing}} {{feature map}} (KSOFM) is an adaptive vector quantization (VQ) scheme for <b>progressive</b> <b>code</b> vector update. However, KSOFM approach belongs to unconstrained vector quantization, which suffers from exponential {{growth of the}} codebook. In this paper, a learning tree-structured vector quantization (LTSVQ) is presented for overcoming this drawback, {{which is based on}} competitive learning (CL) algorithm. LTSVQ algorithm is computationally very efficient, easy to implement and provides performance comparable to that of the LBG (Linde, Buzo and Gray) algorithm...|$|R
40|$|The dorsal column nuclei, cuneatus and gracilis, receive {{somesthetic}} information impinging on projection {{cells and}} local inhibitory interneurons. The {{presence of these}} interneurons allows spatio-temporal <b>progressive</b> <b>coding</b> of {{information that can be}} modelled (Sánchez et al., 2004) using their known synaptic connections with projection cells (Mariño et al., 1999; Aguilar et al., 2002, 2003). Here we explore the dependency of the processing time required to complete the <b>progressive</b> <b>coding</b> with regard to cutaneous stimuli varying in size and contras...|$|E
40|$|A {{method for}} {{efficiently}} coding natural images using a vector-quantized variable-blocksized transform source coder is presented. The method, mixture block coding (MBC), incorporates variable-rate coding {{by using a}} mixture of discrete cosine transform (DCT) source coders. Which coders are selected to code any given image region is made through a threshold driven distortion criterion. In this paper, MBC is used in two different applications. The base method is concerned with single-pass low-rate image data compression. The second is {{a natural extension of}} the base method which allows for low-rate progressive transmission (PT). Since the base method adapts easily to <b>progressive</b> <b>coding,</b> it offers the aesthetic advantage of <b>progressive</b> <b>coding</b> without incorporating extensive channel overhead. Image compression rates of approximately 0. 5 bit/pel are demonstrated for both monochrome and color images...|$|E
40|$|Abstract — Wireless data {{gathering}} networks are often tasked to gather correlated data under severe energy constraints. The use of simple channel codes with source-channel decoding can potentially provide good performance with low energy consumption. Here we consider <b>progressive</b> <b>coding</b> in multi-hop networks, where an intermediate node decodes its received noisy codewords. The estimated information is concatenated with the node’s own information word and encoded; the resulting progressively-encoded codeword is then {{transmitted to the}} next node. In non-progressive coding, the node simply forwards the received noisy codewords along with its own encoded data. Here we compare the performance of two codes with low decoding complexity, Repeat-Accumulate (RA) and Low-Density Parity-Check (LDPC) codes, in combination with two <b>progressive</b> <b>coding</b> schemes. Progressive channel coding uses only channel decoding at the intermediate node, while progressive source-channel coding uses source-channel decoding, exploiting the probabilistic dependency of the information words (caused by the correlation structure of the data) jointly with the deterministic dependency induced by channel coding. Two decoding schemes are considered at the data center: channel decoding only and iterative source-channel decoding. In simulation experiments, we consider a line network topology with systematic RA and LDPC coding. Results show that <b>progressive</b> <b>coding</b> performs better than non-progressive coding, and RA codes perform better with lower computational complexity than LDPC codes, both for channeldecoding-only and iterative source-channel decoding. I...|$|E
40|$|Abstract — We {{consider}} multi-hop transmission {{from the}} source to the destination in ad-hoc wireless networks. Cooperative forwarding approaches {{in the framework of}} <b>progressive</b> network <b>coding</b> are proposed which generalize coded cooperation in a multi-hop context. In this framework, the source node and each succeeding relay node progressively decode what they receive from the previous stages and re-encode the messages to different parts of the parity bits from a single (network) codeword hop by hop. The maximal achievable rates for the multi-hop wireless networks using traditional repetition-forward and <b>progressive</b> network <b>coding</b> are analyzed with respect to different transmit power constraint and packet length allocation. The optimal number of relays are derived in each scheme. It is found that <b>progressive</b> network <b>coding</b> with adaptive packet length significantly increases the system throughput and improves the energy efficiency. I...|$|R
5000|$|The American Veterinary Medical Association (AVMA) {{regularly}} {{reviews and}} updates its principles of ethics. The AVMA Judicial Council {{acts as the}} group in charge of insuring the principles are current. Much like the human medical code, veterinarians are expected to [...] "adhere to a <b>progressive</b> <b>code</b> of ethical conduct". Overall there are eight main principles, covering areas such as compentance, animal welfare, the veterinarian-client-patient relationship, standards of professionalism, honesty, compliance with the law, continuing education, acting within boundaries of compentance, and the betterment of public health.|$|R
5000|$|NOFS is {{adjacent}} to Northern Arizona's San Francisco Peaks, on the alpine Colorado Plateau and geographically above the Mogollon Rim.Flagstaff and Coconino County minimize northern Arizona light pollution through legislation of <b>progressive</b> <b>code</b> - which regulates local lighting. Indeed, despite a half-century-young history, NOFS has a rich heritage which {{is derived from}} its parent organization, USNO, the oldest scientific institution in the U.S.At an elevation of approximately 7500 feet, NOFS {{is home to a}} number of astronomical instruments (some also described in the worldwide list of optical telescopes); some additional instrumentation is on nearby Anderson Mesa: ...|$|R
40|$|Abstract—A simple highly-effective {{method for}} {{progressive}} lossy-to-lossless coding of arbitrarily-sampled image data is proposed. This scheme {{is based on}} a recursive quadtree partitioning of the image domain along with an iterative samplevalue averaging process. The proposed method is shown to offer much better <b>progressive</b> <b>coding</b> performance than a previouslyproposed state-of-the-art coding method. Index Terms—image coding, meshes, progressive lossy/lossless. I...|$|E
30|$|Several {{patterns}} for WZ frame splitting {{can be considered}} as long as spatial correlation is maintained between the sets. Motion refinement is performed at the pixel level after inverse DCT transformation and after reconstructing the previous sets. Three different variants of the proposed <b>progressive</b> <b>coding</b> scheme are described below, using respectively two, three, or four sets of (spatially correlated) blocks.|$|E
40|$|The {{paper is}} focused on predications with {{incremental}} arguments, for example, drinking tea, eating ice-cream, but also handing out books or throwing away letters, when these predications are understood in a temporal distributive&# 13; way, that is, when the entities denoted are consecutively involved in the situation. Predications with an incremental argument denote situations {{where there is a}} certain parallelism between the temporal duration of the situation on the one hand, and the increase or the decrease of the amount denoted by the incremental argument on the other. The more time one spends drinking one’s tea, the less tea remains in the cup. Predications denoting an incremental relation have been comprehensively discussed in formal semantics, and also from other perspectives. Here, it has been observed that neither in English nor in Russian the predications with an incremental argument can be coded as “ongoing”, as progressive, if the incremental argument is related to a bounded amount. Indeed, using the progressive form in an example such as Masha is drinking two cups of tea without further context can be understood only {{in such a way as}} to mean that Masha is drinking her tea alternately from both cups. The same is true for Russian if we use the imperfective aspect in its progressive reading. In Russian too, the equivalent example Maša p’et dve čaški čaja cannot be understood in such a way as to mean that Masha is drinking one cup after the other. So it may seem that a <b>progressive</b> <b>coding</b> of a situation and <b>progressive</b> <b>coding</b> of an incremental argument denoting a bounded amount are mutually exclusive. In this paper, I would like to describe in more detail when and why <b>progressive</b> <b>coding</b> of a situation and <b>progressive</b> <b>coding</b> of an incremental argument denoting a bounded quantity are mutually exclusive. In particular, I would like to show and explain why this restriction is not valid if the quantity of the amount denoted is known at the very beginning of the situation. For instance, if in our example Masha is drinking her two cups of tea/Maša p’et svoi dve čaški čaja the incremental argument is introduced with a possessive pronoun such as her/svoi and is thus related to an amount already specified in the context...|$|E
50|$|The <b>{{progressive}}</b> <b>code</b> for {{the first}} 999999 cars of the provinces was just a progressive number, not filled with initial zeroes; in the rear plate the last four digits are in the second row and the first ones (when present) in the first row.For cars from 1000000, it was A00000-A99999, B00000-B99999 etc. Possible letters were, in this order, A B D E F G H K L M N P R S T U V Z X Y W. After that, it was 00000A-99999A, 00000D-99999D etc. Possible letters were, in this order, A D E F G H L M N P R S T V W X Y Z; then, the letter {{was moved to the}} second position, and then to third (same range as in second position).|$|R
50|$|While pre-tax {{income is}} the primary driver of income inequality, the less <b>progressive</b> tax <b>code</b> further {{increased}} the share of after-tax income going to the highest income groups. For example, had these tax changes not occurred, the after-tax income share of the top 0.1% would have been approximately 4.5% in 2000 instead of the 7.3% actual figure.|$|R
50|$|In 1909 {{the city}} also started to buy {{motorized}} equipment for the department. The first motorized vehicle was a car {{at the cost of}} $2,140. By 1919 the department was completely motorized and all horse drawn equipment was withdrawn from service. During these year the department hired its first Fire Marshall and the city begun adopting several <b>progressive</b> fire <b>codes.</b>|$|R
40|$|Abstract. Selective {{encryption}} {{techniques of}} JBIG encoded visual data are discussed. We {{are able to}} show attack resistance against common image processing attacks and replacement attacks even in case of restricting the amount of encryption to 1 % – 2 % of the data. The low encryption effort required {{is due to the}} exploitation of the interdependencies among resolution layers in the JBIG hierarchical <b>progressive</b> <b>coding</b> mode. ...|$|E
40|$|In {{this letter}} we propose a new {{technique}} for <b>progressive</b> <b>coding</b> of hyperspectral data. Specifically, we employ a hybrid 3 D wavelet transform for spectral and spatial decorrelation {{in the framework of}} Part 2 of the JPEG 2000 standard. Both on-board and on-the-ground compression are addressed. The resulting technique is compliant with the JPEG 2000 family of standards, and provides competitive performance with respect to state-of-the-art techniques...|$|E
40|$|In {{this paper}} {{we present a}} novel object based video coder. This coder {{is based on an}} analysis-synthesis {{approach}} which allows for decoupling shape, motion and texture informations. These informations are then coded using wavelets decomposition and <b>progressive</b> <b>coding</b> allowing to have full scalability (object, SNR, temporal, and bitstream scalabilities). Experimental results show the benefits of proposed scheme providing performances close to state of the art video coders while providing scalability...|$|E
40|$|An {{efficient}} {{scheme for}} video coding is presented which utilizes <b>progressive</b> fractal <b>coding,</b> called waveletbased fractal approximation (WBFA), and motion compensation (MC). In the scheme, the MC error frames are encoded by the <b>progressive</b> fractal <b>coding.</b> Considering the severe localization of the MC errors, we use irregular sampling of domain blocks {{in a fine}} step instead of regular sampling of domain blocks in a coarse step that has been conventionally used. It is shown that the fractal video coder presented is competitive with or somewhat superior to H. 263. It also has a relatively simple structure and reveals the characteristics of non-iterative decoding, and relatively fast encoding and decoding. It {{is found to be}} more suitable for low bit rate video coding. 1. INTRODUCTION Fractal coding is an attractive tool for image and video representation. In standard fractal coding [1], [2], an image is represented by the parameters of contractive mapping with a fixed point. In this method [...] ...|$|R
40|$|D. Gollnick, A. Lehn Dresden University of Technology Institute for Operating Systems, Data Bases and Computer Networks email: {gollnick,lehn}@ibdr. inf. tu-dresden. de Tel + 49 351 463 8213 Fax + 49 351 463 8251 01062 Dresden, Germany Dresden, Mai 1997 <b>Progressive</b> Audio <b>Coding</b> 2 1 INTRODUCTION AND MOTIVATION New {{technologies}} {{open the}} possibility of mobile computing. Wireless links allow communications while moving. Various technologies allow the use wired or wireless links to connect to LANs or WANs [RAH 93], [BAB 94], [KRU 92], [LDH 94], [TUT 92]. On the other hand, multimedia applications {{become more and more}} popular. They produce a large amount of data [STN 95]. In a mobile environment the available bandwidth is insufficient in many cases. A lot of compression algorithms exists for audio [ITUG], image ([GIF 89], [JPG 92], [FIS 95]) and video data ([H. 261],. [H. 263], [MPG 1], [MPG 2], [MPG 4]) to reduce the large data amount. One of the most promising solution is the <b>progressive</b> image <b>coding</b> [JPG [...] ...|$|R
40|$|A quad-tree-based {{hierarchical}} {{contour representation}} and coding method is studied. This method {{is based on}} multiscale line segments—beamlets. Simulations are reported {{to evaluate the effectiveness}} of such an approach. This is a proof-of-concept study. The reported compression ratios are not the “best”. However, the idea of tree-based coding is novel; and this idea has good potential to realize a <b>progressive</b> contour <b>coding,</b> which is important in applications such as content-based video transmission. 1...|$|R
40|$|In video compression, <b>progressive</b> <b>coding</b> {{plays an}} {{important}} role in terms of coding efficiency and error resilience and has been an attractive research topic since the standardization of H. 264 /AVC. In this paper, we propose a high-performance <b>progressive</b> <b>coding</b> scheme with the help of bi-level images. Different from progressive H. 264 /AVC and other video standards, we construct image epitomes as coding priors and use them to generate predictions of intra blocks at the encoder. In addition, we reduce the loss during coding and transmit the compressed images to the decoder. We perform compression-oriented video bi-level image analysis and search for the best bi-level images by using the expectation maximization algorithm. The resulting image bilevel for a video sequence can be viewed as the base layer in spatially scalable video coding. Experiments show that our proposed progressive scheme improves the state of the art by an average of 0. 53 dB in PSNR. Simulations under a packet loss environment also demonstrate that intra refresh with bi-level images outperforms random intra refresh by up to 2 dB, leading to better subjective quality...|$|E
40|$|Sub-objects are {{sorted out}} {{according}} to the SceneProfile associated with an actual service. Each sub-object of arbitrary shape and size is generally represented by rectangular stereoscopic images with the right shape and required spatial and temporal resolution. A mask for the sub-object determines the transparency for each pixel. The motivation for this sub-division is to avoid progressive layering, and obtain equalpriority entities that are independent until viewed on the screen by the user. In the case of <b>progressive</b> <b>coding,</b> basic layers are sent as important AppTraNet packets, while higher layers have decreasing priority. At first sight, <b>progressive</b> <b>coding</b> with successive refinement {{seems to be an}} advantage regarding scalability, but in the network where packets are dropped randomly, it is a drawback. Important packets have to be specially protected or prioritized. A flat coding structure is expected to give a simpler and smoother degradation of quality when packets are dropped or lost in the network. The sub-object division also provides unique possibilities for variable resolution over the surface of any object, simply by coding each sub-object of an object with variabl...|$|E
40|$|In {{this paper}} we {{introduce}} {{the use of}} adaptive filter banks in lossless compression of images with <b>progressive</b> <b>coding</b> in resolution. During the decomposition the filter adapts itself automatically to various regions of the image, preserving the perfect reconstruction property. Effects of parameters used in the decomposition have been studied. Simulation results are given and compared with well-known codecs. The proposed scheme gives, on average, smaller lossless compression bit rate. However, This improvement in performance is achieved {{at the expense of}} an increase in computational complexity...|$|E
40|$|Abstract—A {{method for}} the <b>progressive</b> lossy-to-lossless <b>coding</b> of arbitrarily-sampled image data is proposed. Through {{experimental}} results, the proposed method is demonstrated {{to have a}} rate-distortion performance that is vastly superior {{to that of the}} state-of-the-art image-tree (IT) coding scheme. In particular, at intermediate rates (i. e., in progressive decoding scenarios),theproposedmethodyieldsimagereconstructionswith a peak-signal-to-noise ratio that is much higher (sometimes by several dB) than the IT scheme, while simultaneously achieving a slightly lower lossless rate. I...|$|R
40|$|Data {{compression}} {{is useful}} in reducing the storage and/or transmission bandwidth equirements of medical images. In the medical image scenario, lossy compression chemes are not generally used. This {{is due to a}} possible loss of useful clinical information which may influence diagnosis. Hence {{there is a need for}} efficient lossless compression schemes for medical data. We propose a new Shape Adaptive Integer Wavelet Transform (SAIWT) based <b>progressive</b> transmission <b>coding</b> scheme for 2 -D and 3 -D brain MRI...|$|R
40|$|This paper {{examines}} {{the efficiency of}} MPEG- 2 coding for interlaced and progressive video, and compares de-interlacing and picture rate up-conversion before and after coding. We found receiver side de-interlacing and picture rate up-conversion (i. e. after coding) to give better image quality at a given data rate. In contrast with some other publications, we found interlaced video coding {{to be better than}} <b>progressive</b> video <b>coding</b> for many relevant sequences, even when comparing the results on a progressive display...|$|R
