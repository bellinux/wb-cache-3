1809|10000|Public
5|$|The {{classification}} {{suggested by}} the Deep Ecliptic Survey team introduces a formal distinction between scattered-near objects (which could be scattered by Neptune) and scattered-extended objects (e.g. 90377 Sedna) using a Tisserand's <b>parameter</b> <b>value</b> of 3.|$|E
25|$|The {{knot vector}} is a {{sequence}} of parameter values that determines where and how the control points affect the NURBS curve. The number of knots is always equal {{to the number of}} control points plus curve degree plus one. Each time the <b>parameter</b> <b>value</b> enters a new knot span, a new control point becomes active, while an old control point is discarded.|$|E
25|$|However, {{this method}} does not {{directly}} provide a single fixed-parameter-tractable algorithm for computing the <b>parameter</b> <b>value</b> for a given graph with unknown k, {{because of the difficulty}} of determining the set of forbidden minors. Additionally, the large constant factors involved in these results make them highly impractical. Therefore, the development of explicit fixed-parameter algorithms for these problems, with improved dependence on k, has continued to be an important line of research.|$|E
40|$|This paper {{describes}} a novel procedure {{for determining the}} standard value of acquisition distortion of the fingerprint images. Knowledge about the standard value of acquisition distortion of the fingerprint images {{is very important in}} determining the method for improving image quality. In this paper, we propose a model to determine the standard value of acquisition distortion of the fingerprint images {{that can be used in}} classifying the type of distortion of the fingerprint images based on the image quality. The results shown that the standard value of acquisition distortion of the fingerprint images based on the image quality have values of a local clarity score (LCS) are as follows: dry <b>parameter</b> <b>values</b> is 0. 0127 - 0. 0149, neutral <b>parameter</b> <b>values</b> is less than 0. 0127, and oily <b>parameter</b> <b>values</b> is greater than 0. 0149; a global clarity score (GCS) are as follows: dry <b>parameter</b> <b>values</b> is 0. 0117 - 0. 0120, neutral <b>parameter</b> <b>values</b> is less than 0. 0117, and oily <b>parameter</b> <b>values</b> is greater than 0. 0120; and ridge-valley thickness ratio (RVTR) are as follows: dry <b>parameter</b> <b>values</b> is less than 7. 7546 E- 05, neutral <b>parameter</b> <b>values</b> is 7. 7546 E- 05 - 5. 9366 E- 05, and oily <b>parameter</b> <b>values</b> is greater than 5. 9366 E- 05...|$|R
30|$|Key to {{the success}} of the {{mathematical}} model is the choice of <b>parameter</b> <b>values.</b> Obviously this is not a simple task given that there are twenty-one <b>parameter</b> <b>values</b> as well as four initial conditions. Hence we will now describe in detail our procedure for calculating <b>parameter</b> <b>values.</b>|$|R
40|$|Evolutionary {{optimization}} algorithms have parameters {{that are}} used to adapt the search strategy to suit different optimization problems. Selecting the optimal <b>parameter</b> <b>values</b> for a given problem is difficult without a-priori knowledge. Experimental studies can provide this knowledge by finding the best <b>parameter</b> <b>values</b> for a specific set of problems. This knowledge can also be constructed into heuristics (rule-of-thumbs) that can adapt the parameters for the problem. The aim {{of this paper is to}} assess the heuristics of the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) optimization algorithm. This is accomplished by tuning CMA-ES parameters so as to maximize its performance on the CEC' 15 problems, using a bilevel optimization approach that searches for the optimal <b>parameter</b> <b>values.</b> The optimized <b>parameter</b> <b>values</b> are compared against the <b>parameter</b> <b>values</b> suggested by the heuristics. The difference between specialized and generalized <b>parameter</b> <b>values</b> are also investigated...|$|R
2500|$|A common {{incarnation}} of Bayes’ theorem relates the conditional probability (or density) {{of a particular}} <b>parameter</b> <b>value</b> [...] given data [...] to the probability of [...] given [...] by the rule: ...|$|E
2500|$|The Kullback–Leibler {{divergence}} {{is directly}} related to the Fisher information metric. [...] This can be made explicit as follows. [...] Assume that the probability distributions P and Q are both parameterized by some (possibly multi-dimensional) parameter [...] Consider then two close by values of [...] and [...] so that the parameter [...] differs by only a small amount from the <b>parameter</b> <b>value</b> [...] [...] Specifically, up to first order one has (using the Einstein summation convention) ...|$|E
2500|$|The maximum {{likelihood}} estimator selects the <b>parameter</b> <b>value</b> {{which gives the}} observed data the largest possible probability (or probability density, in the continuous case). If the parameter consists {{of a number of}} components, then we define their separate {{maximum likelihood}} estimators, as the corresponding component of the MLE of the complete parameter. Consistent with this, if [...] is the MLE for θ, and if g(θ) is any transformation of θ, then the MLE for α = g(θ) is by definition ...|$|E
40|$|In {{the case}} of {{rational}} Cherednik algebras associated with cyclic groups, we give an alternative proof that the projective object P_KZ representing the KZ-functor is isomorphic to the Δ-module associated with the coinvariant algebra for a subset of <b>parameter</b> <b>values</b> from which all <b>parameter</b> <b>values</b> {{can be obtained by}} integral translations. We also specify the exact <b>parameter</b> <b>values</b> for which this isomorphism occurs. Furthermore, we determine the action of the cyclotomic Hecke algebra on P_KZ for these <b>parameter</b> <b>values,</b> thereby giving a complete algebraic description of the KZ-functor in this case. Comment: 31 page...|$|R
30|$|The {{optimization}} {{framework is}} comprised by two parts. One is SZOA method {{and the other}} is microstrip antenna system. The former decides the <b>parameter</b> <b>values</b> for antenna size and shape and refines the fitness of <b>parameter</b> <b>values</b> in each iteration. The latter builds antenna system based on given <b>parameter</b> <b>values,</b> simulates the working of antenna system, and evaluates the efficiency of the resulting antenna.|$|R
40|$|<b>Parameter</b> <b>values</b> are {{important}} elements for un- derstanding how Application Programming Interfaces (APIs) {{are used in}} practice. In the context of Android, a few number of API methods are used pervasively by millions of apps, where these API methods provide app core functionality. In this paper, we present preliminary insights from ParamHarver, a purely static analysis approach for automatically extracting <b>parameter</b> <b>values</b> from Android apps. Investigations on 100, 000 apps illustrate how an in-depth study of <b>parameter</b> <b>values</b> can be leveraged in various scenarios (e. g., to recommend relevant <b>parameter</b> <b>values,</b> or even, to some extent, to identify malicious apps) ...|$|R
2500|$|All ABC based methods {{approximate}} the likelihood function by simulations, {{the outcomes of}} which are compared with the observed data. More specifically, with the ABC rejection algorithm—the most basic form of ABC—a set of parameter points is first sampled from the prior distribution. Given a sampled parameter point , a data set [...] is then simulated under the statistical model [...] specified by [...] If the generated [...] is too different from the observed data , the sampled <b>parameter</b> <b>value</b> is discarded. In precise terms, [...] is accepted with tolerance [...] if: ...|$|E
2500|$|The {{algorithm}} {{for solving}} vertex cover that achieves the best asymptotic {{dependence on the}} parameter runs in time [...] The klam value of this time bound (an estimate for the largest <b>parameter</b> <b>value</b> that could be solved in {{a reasonable amount of}} time) is approximately 190. That is, unless additional algorithmic improvements can be found, this algorithm is suitable only for instances whose vertex cover number is 190 or less. Under reasonable complexity-theoretic assumptions, namely the exponential time hypothesis, the running time cannot be improved to 2o(k), even when [...] is [...]|$|E
2500|$|If a cmdlet {{receives}} either pipeline input or command-line parameter input, {{there must}} be a corresponding property in the class, with a mutator implementation. PowerShell invokes the mutator with the <b>parameter</b> <b>value</b> or pipeline input, which is saved by the mutator implementation in class variables. These values are then referred to by the methods which implement the functionality. Properties that map to command-line parameters are marked by ParameterAttribute and are set before the call to BeginProcessing (...) [...] Those which map to pipeline input are also flanked by ParameterAttribute, but with the ValueFromPipeline attribute parameter set.|$|E
40|$|In this paper, we analyze two {{possible}} scenarios for food webs with two prey and one predator (a food web {{is similar to}} a food chain except that in a web we have more than one species at some levels). In neither scenario do the prey compete, rather the scenarios differ in the selection method used by the predator. We determine how the dynamics depend on various <b>parameter</b> <b>values.</b> For some <b>parameter</b> <b>values,</b> one or more species dies out. For other <b>parameter</b> <b>values,</b> all species co-exist at equilibrium. For still other <b>parameter</b> <b>values,</b> the populations behave cyclically. We have even discovered <b>parameter</b> <b>values</b> for which the system exhibits chaos and has a positive Lyapunov exponent. Our analysis relies on common techniques such as nullcline analysis, equilibrium analysis and singular perturbation analysis. ...|$|R
3000|$|... are parameters. Depending on <b>parameter</b> <b>values,</b> one may obtain three {{constant}} stationary solutions exhibiting bistability {{as expected}} from Example  4.1. However, {{there are also}} <b>parameter</b> <b>values</b> so that three stationary pulses exhibiting bistability exist.|$|R
30|$|This {{service is}} to {{recommend}} input <b>parameter</b> <b>values</b> {{to obtain the}} output <b>parameter</b> <b>values</b> that we desire to know for a given simulation. The service can assist a user {{to figure out which}} input parameters can be specified for the very first simulation or for the simulation with a specific goal. In the service, we should find input <b>parameter</b> <b>values</b> associated with specified output <b>parameter</b> <b>values</b> as opposed to predicting the output values for the input values. Hence, this problem is totally different from regression analysis. To implement the service, we should develop a new mining algorithm, which may be more challenging than any other service.|$|R
2500|$|The {{value of}} β {{can be found}} by forcing the {{expected}} rate of flux of states to 1. The diagonal entries of the rate-matrix (the Q matrix) represent -1 {{times the rate of}} leaving each state. For time-reversible models, we know the equilibrium state frequencies (these are simply the πi <b>parameter</b> <b>value</b> for state i). Thus we can find the expected rate of change by calculating the sum of flux out of each state weighted by the proportion of sites that are expected to be in that class. Setting β to be the reciprocal of this sum will guarantee that scaled process has an expected flux of 1: ...|$|E
2500|$|Sometimes {{the maximum}} {{likelihood}} estimate {{lies on the}} boundary of the set of possible parameters, or (if the boundary is not, strictly speaking, allowed) the likelihood gets larger and larger as the parameter approaches the boundary. Standard asymptotic theory needs {{the assumption that the}} true <b>parameter</b> <b>value</b> lies away from the boundary. [...] If we have enough data, the maximum likelihood estimate will keep away from the boundary too. But with smaller samples, the estimate can lie on the boundary. In such cases, the asymptotic theory clearly does not give a practically useful approximation. Examples here would be variance-component models, where each component of variance, , must satisfy the constraint [...]|$|E
50|$|For optional/variable-length {{parameter}}s, the parameter type, parameter length, and <b>parameter</b> <b>value</b> fields all behave {{just like}} their chunk counterparts.The minimum size of parameter is 4 bytes and this {{occurs when the}} <b>parameter</b> <b>value</b> field is empty and the parameter consists only of the type & length fields.|$|E
40|$|We study {{abundance}} {{of a special}} class of elliptic islands (called cyclicity one elliptic islands) for the Standard family of area preserving diffeomorphisms for large <b>parameter</b> <b>values,</b> i. e. far from the KAM regime. Outside a bounded set of <b>parameter</b> <b>values,</b> we prove that the Lebesgue measure of the set of <b>parameter</b> <b>values</b> for which {{an infinite number of}} such islands coexist is zero. On the other hand we construct a positive Hausdorff dimension set of arbitrarily large <b>parameter</b> <b>values</b> for which the associated standard map admits infinitely many elliptic islands of cyclicity one, whose centers accumulate on a locally maximal hyperbolic set. Comment: 60 page...|$|R
3000|$|... {{was given}} in [19]. This general {{heuristic}} method, however, may not always produce effective <b>parameter</b> <b>values</b> for all different applications and situations. Expert input and decisions are often needed in determining the actual <b>parameter</b> <b>values</b> of [...]...|$|R
5000|$|Using MLE, we {{call the}} {{probability}} of the observed data for a given set of model <b>parameter</b> <b>values</b> (e.g., a pdf [...] and a matrix [...] ) {{the likelihood of the}} model <b>parameter</b> <b>values</b> given the observed data.|$|R
50|$|The Hall <b>parameter</b> <b>value</b> {{increases}} with {{the magnetic field}} strength.|$|E
5000|$|The {{circumcenter}} has trilinears [...] {{corresponding to}} the <b>parameter</b> <b>value</b> ...|$|E
5000|$|The de Longchamps {{point has}} trilinears [...] {{corresponding}} to the <b>parameter</b> <b>value</b> ...|$|E
30|$|In {{addition}} to the <b>parameter</b> <b>values</b> in Tables  4 and 5 for the step size (Δt), slow speed factor (γ), and fast speed factor (γ) <b>parameter</b> <b>values</b> 0.25, 0.6 and 0.7 were used respectively for all the scenarios.|$|R
40|$|Abstract- Fitting a set {{of points}} with a B-Spline curve is a usual CADG application, which remains an open problem due to the choice of <b>parameter</b> <b>values.</b> The crucial point is to find optimal <b>parameter</b> <b>values</b> which lead to an optimal {{approximation}} curve. Since these <b>parameter</b> <b>values</b> are only a first guess, parameter correction {{can be used to}} improve parameterization. This paper discusses iterative solutions in least-squares B-Spline curve fitting sense. And the initial results are presented. 1...|$|R
40|$|Abstract — Tuning {{parameters}} of an evolutionary algorithm {{is the essential}} phase of a problem solving process since the <b>parameter</b> <b>values</b> significantly influence the algorithm efficiency. A traditional parameter tuning approach finds a setting of <b>parameter</b> <b>values</b> that is then used for solving various problem instances. Clearly, such <b>parameter</b> <b>values</b> may not perform well on specific problem instances. This paper suggests finding several parameter settings which are suitable for specific prob-lem instances. However, this is not aimed {{at the level of}} each individual instance, but rather for specific types of problem instances. A new problem instance can then be solved using the tuned <b>parameter</b> <b>values</b> for its type. We demonstrate the approach by tuning {{parameters of}} an evolutionary algorithm for commodity transportation optimization with very heteroge-neous problem instances. Numerical experiments show that the procedure improves the algorithm performance. Moreover, the analysis of empirical results reveals that there exist relations between the tuned <b>parameter</b> <b>values</b> and that they vary over types of problem instances. I...|$|R
5000|$|RFC 2231, with Keith Moore, MIME <b>Parameter</b> <b>Value</b> and Encoded Word Extensions: Character Sets, Languages, and Continuations, ...|$|E
5000|$|... : the {{likelihood}} function, i.e. the density function for the observed data [...] when the <b>parameter</b> <b>value</b> is ...|$|E
5000|$|Exact {{hypothesis}}: Any {{hypothesis that}} specifies an exact <b>parameter</b> <b>value.</b> [...] Example: μ = 100. Synonym: point hypothesis.|$|E
40|$|Abstract. Finding {{appropriate}} <b>parameter</b> <b>values</b> for Evolutionary Algorithms (EAs) {{is one of}} {{the persistent}} challenges of Evolutionary Computing. In recent publications we showed how the REVAC (Relevance Estimation and VAlue Calibration) method is capable to find good EA <b>parameter</b> <b>values</b> for single problems. Here we demonstrate that REVAC can also tune an EA to a set of problems (a whole test suite). Hereby we obtain robust, rather than problem-tailored, <b>parameter</b> <b>values</b> and an EA that is a ‘generalist, rather than a ‘specialist. The optimized <b>parameter</b> <b>values</b> prove to be different from problem to problem and also different from the values of the generalist. Furthermore, we compare the robust <b>parameter</b> <b>values</b> optimized by REVAC with the supposedly robust conventional values and see great differences. This suggests that traditional settings might be far from optimal, even if they are meant to be robust. Key words: parameter tuning, algorithm design, test suites, robustness 1 Background and Objective...|$|R
3000|$|P can {{be defined}} as a <b>value</b> of the <b>parameter</b> attribute, i.e., P ∈w_p. Let us denote a set of <b>parameter</b> <b>values</b> by P = { P_ 1, [...]..., P_l_p}. By their nature, <b>parameter</b> <b>values</b> enable us to divide M into several submicrofiles [...]...|$|R
40|$|Abstract. This work aimed on the granulometric {{characterization}} of flotation products and {{to analyze the}} effect of the variables (that were investigated in a flotation work) on the particle size distribution parameters. Besides to compare the <b>parameter</b> <b>values</b> of the granulometric analysis for the concentrate and tailing both results were compared with the <b>parameter</b> <b>values</b> of the flotation feed samples. The analyzed <b>parameters</b> showed lower <b>values</b> for the concentrate products as compared with the parameters for tailing and feed samples. For coarse and fine particle size fractions the column height was the variable that more influenced on the <b>parameter</b> <b>values...</b>|$|R
