16|115|Public
25|$|The {{temperature}} and frequency dependencies of electrical parameters for polypropylene film capacitors are very low. Polypropylene film capacitors have a linear, {{negative temperature coefficient}} of capacitance of ±2,5 % within their temperature range. Therefore, polypropylene film capacitors are suitable for applications in Class 1 frequency-determining circuits, filters, oscillator circuits, audio circuits, and timers. They are also useful for compensation of inductive coils in <b>precision</b> <b>filter</b> applications, and for high-frequency applications.|$|E
40|$|A {{method for}} the design of Finite Precision Coefficient (FPC) Peak Constrained Least Squares (PCLS) Finite {{duration}} Impulse Response (FIR) digital filters based on Adams ’ optimality criterion and an efficient local search method is presented. Simple quantization of the infinite <b>precision</b> <b>filter</b> coefficients typically leads to filter designs that fail to meet the frequency response and Passband to Stopband energy Ratio (PSR) specifications. It is shown {{that it is possible to}} implement computationally efficient filters (with reduced filter FPC wordlengths) that meet the passband and stopband attenuation specifications at the expense of a lower PSR energy ratio...|$|E
40|$|The biorthogonal 9 / 7 wavelet is {{used for}} lossy {{compression}} in the JPEG 2000 image coding standard. A hardware implementation of the standard must consider the accuracy and the efficiency with which the quantized filter coefficients are represented; filter structure {{is also an important}} design consideration. A high precision representation ensures compression performance close to the unquantized, infinite <b>precision</b> <b>filter</b> bank, but this comes at the cost of increased hardware resources and processing time. This paper proposes a gain compensation method that significantly improves the performance of the quantized filters without sacrificing efficiency. Our best new method achieves performance close to the unquantized filter case while also realizing a fast, efficient hardware implementation. 1...|$|E
40|$|A new primary {{standard}} for AC voltage based on pulse driven Josephson junction arrays is under development. In this paper, preliminary spectral measurements and simulations are presented {{on a fast}} switching multiplexer unit built for the high precision synthesis of arbitrary waves. First order delta-sigma modulation is used to represent the wave to be synthesized. The first results are promising {{with respect to the}} conditions for high <b>precision</b> <b>filtering</b> of the quantization noise, i. e. a high signal-to-noise ratio is expected for the demodulated signal...|$|R
40|$|Introduction: Black-and-white grating {{patterns}} with 1 - 8 cycles per degree (cpd) can provoke visual illusions and discomfort to which individuals with migraine are particularly susceptible [1]. Because these patterns are epileptogenic [1] the susceptibility {{is consistent with}} evidence from transcranial magnetic stimulation [2] and fMRI BOLD [3] for hyperexcitability of the cerebral cortex in migraine. <b>Precision</b> spectral <b>filters,</b> individually prescribed [4], can reduce some migraine attacks [5]. We hypothesize that the <b>precision</b> spectral <b>filter</b> reduces or alters cortical activation, thereby reduces visual illusions and possibly also frequency of migraine attacks. In thi...|$|R
40|$|This paper {{investigates the}} use of genetic {{algorithm}} {{in the design of}} finite linear phase raised cosine FIR filters. The design of such filters does not only involve meeting a specific amplitude response but also imposes time domain constraints on the impulse response in order to ensure zero ISI. It is shown that genetic algorithm provides simple and effective technique for the design of finite <b>precision</b> <b>filters</b> with both frequency and time domain constraints. Furthermore, the algorithm computational time is low with respect to filter order and is independent of word length. Two filter design examples are included demonstrating the effectiveness of the design method...|$|R
40|$|The {{determination}} of aerosol properties, especially the aerosol optical depth (AOD) in the ultraviolet (UV) wavelength region, {{is of great}} importance for understanding the climatological variability of UV radiation. However, operational retrievals of AOD at the biologically most harmful wavelengths in the UVB are currently only made at very few places. This paper reports on the UVPFR (UV <b>precision</b> <b>filter</b> radiometer) sunphotometer, a stable and robust instrument {{that can be used}} for AOD retrievals at four UV wavelengths. Instrument characteristics and results of Langley calibrations at a high-altitude site were presented. It was shown that due to the relatively wide spectral response functions of the UVPFR, the calibration constants (V 0) derived from Langley plot calibrations underestimate the true extraterrestrial signals. Accordingly, correction factors were introduced. In addition, the instrument's spectral response functions also result in an apparent air-mass-dependent decrease in ozone optical depth used in the AOD determinations. An adjusted formula for the calculation of AOD, with a correction term dependent on total column ozone amount and ozone air mass, was therefore introduced. Langley calibrations performed 13 – 14  months apart resulted in sensitivity changes of ≤  1. 1  %, indicating good instrument stability. Comparison with a high-accuracy standard <b>precision</b> <b>filter</b> radiometer, measuring AOD at 368 – 862  nm wavelengths, showed consistent results. Also, very good agreement was achieved by comparing the UVPFR with AOD at UVB wavelengths derived with a Brewer spectrophotometer, which was calibrated against the UVPFR at an earlier date. Mainly due to non-instrumental uncertainties connected with ozone optical depth, the total uncertainty of AOD in the UVB is higher than that reported from AOD instruments measuring in UVA and visible ranges. However, the precision can be high among instruments using harmonized algorithms for ozone and Rayleigh optical depth as well as for air mass terms. For 4 months of comparison measurements with the UVPFR and a Brewer, the root mean squared AOD differences were found <  0. 01 at all the 306 – 320  nm Brewer wavelengths...|$|E
40|$|A high {{performance}} reverse phase liquid chromatographic method {{was developed for}} the determination of related substances, 6 -Fluoro- 3 -(piperidin- 4 -yl) benzo [d]isoxazole hydrochloride and 1 -(4 -(3 -chloropropoxy) - 3 methoxyphenyl) ethanone of Iloperidone in bulk and dosage form. The separation was eluted on a Zodiac C 18 column (400 mm x 4. 0 mm; 5 µ) using a mobile phase mixture of sodium per chlorate, acetonitrile and methanol in a gradient program at a flow rate of 0. 7 ml/min. The detection was made at 275 nm. The method was validated for Linearity, speficity, LOD, LOQ, accuracy, robustness, ruggedness, <b>precision,</b> <b>Filter</b> paper variation and solution stability. The retention time of Iloperidone {{was found to be}} 4. 8 ± 0. 1 min. The propose method was validated as per the ICH guidelines. The method was accurate, precise, specific and rapid found to be suitable for the quantitative estimation of the impurities in drug and pharmaceutical dosage form...|$|E
40|$|Optimal finite linear-phase impulse {{response}} (FIR) filters {{are most often}} designed using the Remez algorithm, which computes so-called infinite <b>precision</b> <b>filter</b> coefficients. In many practical applications, {{it is necessary to}} represent these coefficients by a finite number of bits. The problem of finite wordlength linear-phase filters is not as trivial as it would seem. The simple rounding of coefficients computed by the Remez algorithm gives us a suboptimal filter. Optimal finite wordlength linear-phase FIR filters are usually designed using integer linear programming, which {{takes a lot of time}} to compute the coefficients. In this paper, we introduce a new approach to the design of finite wordlength FIR filters using very fast Babai's algorithm. Babai's algorithm solves the closest vector problem, and it uses the basis reduced by the LLL algorithm as an input. We have used algorithms which solve the problem in the L 2 norm and then added heuristics that improve the results relative to the L ∞ norm. The design method with Babai's algorithm and heuristics has been tested on filters with different sets of frequency-domain specifications...|$|E
50|$|<b>Precision</b> planar <b>filters</b> are {{manufactured}} using a thin-film process. Higher Q factors {{can be obtained}} by using low loss tangent dielectric materials for the substrate such as quartz or sapphire and lower resistance metals such as gold.|$|R
50|$|Thin {{films are}} used to create optical coatings. Examples include low {{emissivity}} panes of glass for houses and cars, anti-reflective coatings on glasses, reflective baffles on car headlights, and for high <b>precision</b> optical <b>filters</b> and mirrors. Another application of these coatings is spatial filtering.|$|R
40|$|The most {{computationally}} intensive part of wide-band receivers is the IF processing block. Digital filtering is {{the main}} task in IF processing. Infinite <b>precision</b> <b>filters</b> require complicated digital circuits due to coefficient multiplication. This paper presents an efficient method to implement pulse shaping filters for a dual-mode GSM/W-CDMA receiver. We use an arithmetic scheme, known as pseudo floating-point (PFP) representation to encode the filter coefficients. By employing a span reduction technique, we show that the filters can be coded using an optimal entropy scheme employing PFP which requires only considerably fewer bits than conventional 24 -bit and 16 -bit fixed-point filters. Simulation {{results show that the}} magnitude responses of the filters coded in PFP meet the attenuation requirements of GSM/W-CDMA specifications. 1...|$|R
40|$|Reactive pulsed {{magnetron}} sputtering incorporates a high potential to manufacture optical multi layer systems e. g. <b>precision</b> <b>filter</b> components. Only some investigations {{have been performed}} to describe most important properties of such prepared films. A flexible magnetron sputter system using two planar metallic targets supplied with pulsed power equipment was used for reactive deposition of optical coatings. Single layers were investigated as an elementary stage for preparation of multi layer stacks. The pure metallic targets were sputtered in a strictly controlled reactive gas atmosphere. Layers with an optical thickness of ?/ 4 (for ? = 1550 nm) were deposited on Si wafers and glass substrates. The influence of total sputtering pressure and process temperature on optical and mechanical properties, surface topography and film structure were investigated. The special emphasis was put on detection {{of the influence of}} pulse mode and pulse parameters on layer properties. The samples were characterized by spectroscopic ellipsometry (SE), atomic force microscopy (AFM), X-ray diffraction (XRD) and nanoindentation techniques. It was possible to adjust the film properties by fine tuning of the process parameters...|$|E
40|$|In the RF(Radio Frequency) {{front-end}} of Beidou navigation system, {{the high}} <b>precision</b> <b>filter</b> which filtering some noise of receiving signal {{plays an important}} role for the whole system. The designed Filter in this paper is based on the theory foundation of parallel coupled microstrip line band-pass filter which combine the designing method of the traditional filter with microwave circuit simulation software ADS 2009 (Advanced Design System) and HFSS 2013 (High Frequency Structure Simulator), calculated the design parameters of microstrip line size and completed the simulation of ideal model in ADS, and then set up the 3 D model in the HFSS to carry on the simulation which close to the actual production condition. Furthermore, modified and adjusted the design parameters to ensure that the design of radio frequency narrowband parallel coupled microstrip line band-pass filter circuit can conform to the project requirements of the ideal filter. At last analyzed the relevant simulation results and making simple thermal transfer microstrip line circuit board to test effect. From simulation figure {{it can be seen that}} this filter has a high precision, simple design, easy to make, small bandwidth and many other advantages, the design and implementation method possess greater project value...|$|E
40|$|This paper {{presents}} {{the reconstruction of}} a 73 -year time series of the aerosol optical depth (AOD) at 500  nm at the subtropical high-mountain Izaña Atmospheric Observatory (IZO) located in Tenerife (Canary Islands, Spain). For this purpose, we have combined AOD estimates from artificial neural networks (ANNs) from 1941 to 2001 and AOD measurements directly obtained with a <b>Precision</b> <b>Filter</b> Radiometer (PFR) between 2003 and 2013. The analysis is limited to summer months (July–August–September), when the largest aerosol load is observed at IZO (Saharan mineral dust particles). The ANN AOD time series has been comprehensively validated against coincident AOD measurements performed with a solar spectrometer Mark-I (1984 – 2009) and AERONET (AErosol RObotic NETwork) CIMEL photometers (2004 – 2009) at IZO, obtaining a rather good agreement on a daily basis: Pearson coefficient, R, of 0. 97 between AERONET and ANN AOD, and 0. 93 between Mark-I and ANN AOD estimates. In addition, we have analysed the long-term consistency between ANN AOD time series and long-term meteorological records identifying Saharan mineral dust events at IZO (synoptical observations and local wind records). Both analyses provide consistent results, with correlations [*]>[*]  85  %. Therefore, we can conclude that the reconstructed AOD time series captures well the AOD variations and dust-laden Saharan air mass outbreaks on short-term and long-term timescales and, thus, it is suitable {{to be used in}} climate analysis...|$|E
3000|$|... [...]. This online {{decimation}} {{can cause}} the <b>filtering</b> <b>precision</b> degradation. In order to evaluate this phenomenon on our test signal the following procedure is adapted.|$|R
5000|$|For any slowly varying model {{parameters}} of the equations of motion [...] or <b>precision</b> [...] generalized <b>filtering</b> takes the following form (where [...] corresponds to the variational mean of the parameters) ...|$|R
40|$|Graduation date: 2002 Switched-capacitor (SC) {{circuits}} {{are commonly}} used for analog signal processing {{because they can be}} used to realize <b>precision</b> <b>filters</b> and data converters on an integrated circuit (IC). However, for high speed applications SC circuit operating speeds are limited by the internally-compensated opamps found in SC integrators, a common building block of these circuits. This thesis studies gain stages that eliminate the internal compensation, thus allowing the SC circuits to operate at significantly higher operating speeds. An inverter-based SC integrator is presented. The proposed SC integrator is built with a pseudo-differential structure to improve its rejection of common-mode noise, such as charge injection and clock feedthrough. The proposed integrator also incorporates correlated double sampling (CDS) to boost its effective DC gain. Clock-boosting and switch bootstrapping techniques are not used in the proposed circuit, even though it uses a low supply voltage. To verify the speed advantage of the proposed circuit, a high speed delta sigma (Δ∑) modulator was designed in a 1. 8 V, 0. 18 μm CMOS technology. The designed Δ∑ modulator operates at a clock frequency of 500 MHz. Circuit implementation and layout floorplan are described. The design is based on MATLAB and SpectreS simulations...|$|R
40|$|In {{parallel}} with the evolution of large observatory spacecraft such as the Einstein, Copernicus, and IUE, and the yet-to-be-Iaunched Hubble Space Telescope and Gamma Ray Observatory, Increasingly large ground telescopes are In construction which will allow ground astronomy to compete favorably with elaborate and expen!) lve space systems In the quest for new discoveries. Sometimes overlooked In this pursuit of new discoveries, with the limited observational time on the space Instruments, or the oversubscribed large ground Instruments, Is the recent development of smaller, low-cost robotic ground observatories designed for routine- but vital- collection of synoptic data. High-quality stellar observations are now being made by exploitation of new computer and detector technologies In unattended remote ground observatories, typically by modest aperture Instruments tailored to the Job. These Instruments operate In modes similar to those employed In the observatory spacecraft. Recent developments In the small satellite technology, some being reported at this conference, allow a reduced cost of payload delivery Into orbit and suggest that another look Is deserved at the 1960 s ' concept of small astronomical satellites, which would be operable by simple command systems to conduct monitoring of variable, flare, and cataclysmic stars, perhaps limited only to <b>precision</b> <b>filter</b> photometry or simple Imaging In wavelengths not accessible from the ground. These would allow conduct of bread-and-butter astronomy at and accuracies wavelengths available only In space on objects Identified by the larger research Instruments, undertaking science too costly to pursue over long periods with multi-billion dollar systems...|$|E
40|$|Aerosol Optical Depth (AOD) and Ångström {{exponent}} (AE) values derived {{with the}} MODIS retrieval algorithm over land (Collection 5) {{were compared with}} ground based sun photometer measurements in Europe, Asia, Africa, North America and South America. In Finland (Jokioinen and Sodankylä) measurements were done with <b>Precision</b> <b>Filter</b> Radiometer (PFR), while in Estonia (Toravere), Italy (Ispra, Rome Tor Vergata), India (Kanpur), China (Xianghe), GSFC (USA), Mexico (Mexico City), Zambia (Mongu) and Brazil (Alta Floresta) Cimel (AERONET, level 2) measurements were used. Comparison results for AOD were generally good, although {{there seems to be}} room for improvement in the MODIS aerosol model selection, particularly how dust is taken into account. At all studied sites, the MODIS algorithm often selects the dust aerosol model even when dust {{does not seem to be}} present and the air masses are not coming from arid regions. This happens especially when AOD values are relatively small (< 0. 3). The selection of the dust model reduces the correlation between ground based and MODIS AOD measurements in dust-free situations. Moreover, the current aerosol model selection scheme produces unphysical AE values. Our study suggests that the aerosol model combining is sensitive to the ratio of 660 nm and 2130 nm surface reflectances (slope(660 / 2130)). Furthermore, the value of the slope in the algorithm is mainly dependent on the Normalized Difference Vegetation Index (NDVI). The current relationship of these two parameters in the algorithm is not supported by the surface albedo climatology derived from MODIS measurements. The use of a more physical relationship improves the AE retrieval at the studied sites. However, at some sites the AOD correspondence deteriorates when the new relationship is used...|$|E
40|$|This paper {{presents}} the preliminary results of nocturnal Aerosol Optical Depth (&tau;a) and Angström Exponent (α) {{obtained from a}} new lunar photometer prototype, trade name Cimel CE- 318 U. Due to the variation of the moon's illumination inherent to the lunar cycle, the typical Langley-plot Method used in solar photometry to calibrate these instruments cannot be applied. In this paper we propose three different methods {{to carry out the}} lunar-photometer calibration. In order to validate the results we have selected three events, which encompass seven nights and ten days under different atmospheric conditions, including several saharan dust intrusions episodes. Method# 1 is introduced in this work as a modification of the usual Langley Method. This technique, called Lunar-Langley Method, requires the extraterrestrial irradiances from a lunar irradiance model, providing similar accuracies on &tau;a to those of AERONET (± 0. 01 – 0. 02). It makes comparable daytime and nighttime measurements. Method# 2 consists of transferring the current calibration from a master used by sunphotometers. Its results are again within the limit of accuracy expected for the instrument. Method# 3 uses an integrating sphere and the methodology proposed by Li et al. (2008) to determine sky calibration coefficients (Cj) and the instrument's solid angle field-of-view (Ω), respectively. We observe significant &tau;a differences between Method# 1 and # 3 (up to 0. 07), which might be attributed to the errors propagation in Method# 3. The good results obtained from the comparison against a second CE- 318 U prototype, and against daytime data from a <b>precision</b> <b>filter</b> radiometer, constitute a valuable assessment of CE- 318 U performance. Results of α and its spectral variation (&delta;&alpha;) show good agreement between daytime and nighttime, being able to identify the aerosol properties associated with each event...|$|E
40|$|International audienceFreeze casting–i. e. {{directional}} freezing {{of ceramic}} suspensions[1, 2]–is nowadays {{considered one of}} the top candidates to process highly structured porous ceramics for several application domains including <b>precision</b> <b>filters</b> and bone regeneration implants. Here, we present our early studies toward the first tridimensional simulation of the freeze casting process. The goal is not only to provide fundamental understanding of the solidification process, but also to derive theoretical tools to quantitatively master the effect of each of its parameters. The finite element method[3] is used to compute the heat diffusion within the matter. The evolving interface between solid and fluid plays a major role and is tracked using the level set method[4, 5] combined with mesh adaptivity techniques. These developments, adapted from existing research on metal casting, allow to characterize the influence of the cooling rate on the shape of the ice crystals, and then of the ceramic walls. In the future, fluid convection as well as particles motion will be introduced in the simulation to complete the analysis. We will then be in possession of a powerful numerical tool for the quantitative optimization of the freeze casting process, leading to tougher and stronger scaffolds, e. g., for the repair of load-bearing bone defects...|$|R
40|$|Circuit {{designs that}} employ only CMOS {{technology}} {{are becoming more}} desirable than those using traditional bipolar integrated circuit technology. This technology offers a high density of MOS circuitry, good capacitor accuracy and high stability. The availability of techniques for the design and realization of <b>precision</b> <b>filters</b> in fully integrated form has many applications in signal processing VLSI circuits. The design, simulation and compensation of MOS transistor filters are presented. The MOS transistor {{is used as a}} voltage controlled resistor. The resulting "MOSFET-C" filters can then be built of MOS transistors, capacitors and operational amplifiers fabricated in MOS technology. The advantages of MOSFET-C filters over other integrated filters are discussed. Desirable MOS transistor circuit configurations for use in these filter designs are also presented. High-order, high-frequency, narrow-band bandpass filters are designed and simulated to give a systematic step-by-step design procedure for realizing MOSFET-C filters. These steps include modifying existing well established and studied filter building blocks for use in this method. The nonidealities associated with MOS transistors, especially at high frequencies, are studied and modeled for simulation. Compensation techniques for these nonidealities, together with those of operational amplifiers are presented and applied to both RC and MOSFET-C filters. A compensation scheme is developed which cancels the op amp effects in second-order filter building blocks...|$|R
40|$|The cooled {{infrared}} {{filters and}} dichroic beam splitters manufactured for the Mid-Infrared Instrument are key optical components for {{the selection and}} isolation of wavelengths {{in the study of}} astrophysical properties of stars, galaxies, and other planetary objects. We describe the spectral design and manufacture of the <b>precision</b> cooled <b>filter</b> coatings for the spectrometer (7 K) and imager (9 K). Details of the design methods used to achieve the spectral requirements, selection of thin film materials, deposition technique, and testing are presented together with the optical layout of the instrument. (C) 2008 Optical Society of America...|$|R
40|$|The Atmospheric Infrared Sounder (AIRS) {{is a key}} {{facility}} {{instrument in}} the NASA Earth Observing System (EOS) program, being implemented to obtain comprehensive long-term measurements of earth processes affecting global change. The instrument performs passive IR remote sensing using a high resolution grating spectrometer with a wide spectral coverage (3. 7 - 15. 4 m) directing radiation onto a hybrid HgCdTe IRFPA operating at 58 K in a vacuum package cooled to 155 K. The hybrid HgCdTe FPA consists of twelve modules, 10 with multiplexed photovoltaic detectors and two with individually leaded out photoconductive detectors. The complex FPA has a large optical footprint, 53 mm x 66 mm, and receives energy dispersed from the grating through a <b>precision</b> <b>filter</b> assembly containing 17 narrow band filters. The backside illuminated PV detector arrays are fabricated from P-on-n double layer LPE grown heterojunction detectors in a bilinear format of 50 m x 100 m detectors, with from 232 to 420 detectors per module. For the MWIR bands four PV modules cover the 3. 7 m to 8. 22 m region. Low detector capacitance and low noise preamplifiers in the ROIC are key to achieving high sensitivities in these bands. Uniform quantum efficiencies and detectivities exceeding 3 E 13 cm-rtHz/W have been achieved. The LWIR region is covered by six PV modules spanning 8. 8 m to 13. 75 m. High detector resistance and very low ROIC preamplifier input noise are key to achieving high sensitivity. A detectivity exceeding 2 E 11 cm-rtHz/W has been achieved at the longest wavelength. Two additional PC modules cover the longest spectral bands out to 15. 4 m. This high performance multispectral focal plane has been built and integrated with the dewar assembly, and is currently being integrated with the complete AIRS sensor...|$|E
40|$|A 37 -year {{long-term}} {{series of}} monochromatic aerosol optical depth (AOD) has been recovered from solar irradiance measurements {{performed with the}} solar spectrometer Mark-I, deployed at Izaña mountain since 1976. The instrument operation {{is based on the}} method of resonant scattering, which affords wavelength absolute reference and stability (long-term stability and high precision) in comparison to other instruments based purely on interference filters. However, it has been specifically designed as a reference instrument for helioseismology, and its ability to determine AOD from transmitted and scattered monochromatic radiation at 769. 9 nm inside a potassium vapour cell {{in the presence of a}} permanent magnetic field is evaluated in this paper. Particularly, the use of an exposed mirror arrangement to collect sunlight as well as the Sun–laboratory velocity dependence of the scattered component introduces some important inconveniences to overcome when we perform the instrument's calibration. We have solved this problem using a quasi-continuous Langley calibration technique and a refinement procedure to correct for calibration errors as well as for the fictitious diurnal cycle on AOD data. Our results showed similar calibration errors retrieved by means of this quasi-continuous Langley technique applied in different aerosol load events (from 0. 04 to 0. 3), provided aerosol concentration remains constant throughout the calibration interval. It assures the validity of this technique when it is applied in those periods with relatively high aerosol content. The comparative analysis between the recovered AOD data set from the Mark-I and collocated quasi-simultaneous data from the Cimel-AErosol RObotic NETwork (AERONET) and <b>Precision</b> <b>Filter</b> Radiometer (PFR) instruments showed an absolute mean bias ≤ 0. 01 in the 10 - and 12 -year comparison, respectively. High correlation coefficients between AERONET and Mark-I and PFR/Mark-I pairs confirmed a very good linear relationship between instruments, proving that recovered AOD data series from Mark-I can be used together with PFR and AERONET AOD data to build a long-term AOD data series at the Izaña site (1976 –now), suitable for future analysis of aerosols trends and inter-annual variability. Finally, the AOD preliminary trend analysis in the 29 -year period from 1984 to 2012 with Mark-I AOD revealed no significant trends...|$|E
40|$|This paper {{presents}} the new photometer CE 318 -T, {{able to perform}} daytime and night-time photometric measurements using {{the sun and the}} moon as light source. Therefore, this new device permits a complete cycle of diurnal aerosol and water vapour measurements valuable to enhance atmospheric monitoring to be extracted. In this study we have found significantly higher precision of triplets when comparing the CE 318 -T master instrument and the Cimel AErosol RObotic NETwork (AERONET) master (CE 318 -AERONET) triplets {{as a result of the}} new CE 318 -T tracking system. Regarding the instrument calibration, two new methodologies to transfer the calibration from a reference instrument using only daytime measurements (Sun Ratio and Sun-Moon gain factor techniques) are presented and discussed. These methods allow the reduction of the previous complexities inherent to nocturnal calibration. A quantitative estimation of CE 318 -T AOD uncertainty by means of error propagation theory during daytime revealed AOD uncertainties (u D AOD) for Langley-calibrated instruments similar to the expected values for other reference instruments (0. 002 – 0. 009). We have also found u D AOD values similar to the values reported in sun photometry for field instruments ([*]∼[*]  0. 015). In the case of the night-time period, the CE 318 -T-estimated standard combined uncertainty (u N AOD) is dependent not only on the calibration technique but also on illumination conditions and the instrumental noise. These values range from 0. 011 – 0. 018 for Lunar Langley-calibrated instruments to 0. 012 – 0. 021 for instruments calibrated using the Sun Ratio technique. In the case of moon-calibrated instruments using the Sun-Moon gain factor method and sun-calibrated using the Langley technique, we found u N AOD ranging from 0. 016 to 0. 017 (up to 0. 019 in 440 nm channel), not dependent on any lunar irradiance model. A subsequent performance evaluation including CE 318 -T and collocated measurements from independent reference instruments has served to assess the CE 318 -T performance as well as to confirm its estimated uncertainty. Daytime AOD evaluation, performed at Izaña station from March to June 2014, encompassed measurements from a reference CE 318 -T, a CE 318 -AERONET master instrument, a <b>Precision</b> <b>Filter</b> Radiometer (PFR) and a Precision Spectroradiometer (PSR) prototype, reporting low AOD discrepancies between the four instruments (up to 0. 006). The nocturnal AOD evaluation was performed using CE 318 -T- and star-photometer-collocated measurements and also by means of a day/night coherence transition test using the CE 318 -T master instrument and the CE 318 daytime data from the CE 318 -AERONET master instrument. Results showed low discrepancies with the star photometer at 870 and 500 nm channels ([*]≤[*]  0. 013) and differences with AERONET daytime data (1 h after and before sunset and sunrise) in agreement with the estimated u N AOD values at all illumination conditions in the case of channels within the visible spectral range, and only for high moon's illumination conditions in the case of near-infrared channels. Precipitable water vapour (PWV) validation showed a good agreement between CE 318 -T and Global Navigation Satellite System (GNSS) PWV values for all illumination conditions, within the expected precision for sun photometry. Finally, two case studies have been included to highlight the ability of the new CE 318 -T to capture the diurnal cycle of aerosols and water vapour as well as short-term atmospheric variations, critical for climate studies...|$|E
40|$|This paper {{describes}} video coding technology proposal {{submitted by}} Qualcomm Inc. {{in response to}} a joint call for proposal (CfP) issued by ITU-T SG 16 Q. 6 (VCEG) and ISO/IEC JTC 1 /SC 29 /WG 11 (MPEG) in January 2010. Proposed video codec follows a hybrid coding approach based on temporal prediction, followed by transform, quantization, and entropy coding of the residual. Some of its key features are extended block sizes (up to 64 × 64), recursive integer transforms, single pass switched interpolation filters with offsets (single pass SIFO), mode dependent directional transform (MDDT) for intra-coding, luma and chroma high <b>precision</b> <b>filtering,</b> geometry motion partitioning, adaptive motion vector resolution. It also incorporates internal bit-depth increase (IBDI), and modified quadtree based adaptive loop filtering (QALF). Simulation results are presented for a variety of bit rates, resolutions and coding configurations to demonstrate the high compression efficiency achieved by the proposed video codec at moderate level of encoding and decoding complexity. For random access hierarchical B configuration (HierB), the proposed video codec achieves an average BD-rate reduction of 30. 88 ℅ compared to the H. 264 /AVC alpha anchor. For low delay hierarchical P (HierP) configuration, the proposed video codec achieves an average BD-rate reduction of 32. 96 ℅ and 48. 57 ℅, compared to the H. 264 /AVC beta and gamma anchors, respectively...|$|R
5000|$|In {{two tests}} they showed that these common words {{decreased}} the spam <b>filter's</b> <b>precision</b> (the percentage of messages classified as spam that really are spam) from 84% to 67% and from 94% to 84%. Examining their data {{shows that the}} poisoned filter was biased towards believing messages {{were more likely to}} be spam than [...] "ham" [...] (good email), thus increasing the false positive rate.|$|R
30|$|The PHD is {{the first}} moment of the multitarget {{posterior}} probability. Under some assumptions (e.g., Poisson Assumption), the PHD is an approximation of the multitarget posterior probability. Therefore, the PHD filter can be an approximation of the multitarget Bayes filter. Although a PHD algorithm for TBD is proposed in [10], this approach ignores TBD measurements should be modeled by RFSs. In [15], multitarget TBD from image observations is formulated in a Bayesian framework by modeling the collection of states as a multi-Bernoulli RFS. This work use the multi-Bernoulli update to develop a high <b>precision</b> multi-object <b>filtering</b> algorithm for image observations, although its adaptability of low SNR environment is needed to discussed in more detail.|$|R
40|$|The best-basis {{algorithm}} {{has gained}} much importance on textured-based image compression and denoising of signals. In this paper, an architecture for the wavelet-packet based best-basis algorithm for images is proposed. The paper also describes the architecture for best-tree selection from 2 D wavelet packet decomposition. The precision {{analysis of the}} proposed architecture is also discussed and the result shows that increase in the precision of input pixel greatly increases the Signal-to-Noise Ratio (SNR) per pixel whereas increase in the <b>precision</b> of <b>filter</b> coefficient does not greatly help in improving the SNR value. The proposed architecture is described in VHDL at the RTL level, simulated successfully for its functional correctness and implemented in an FPGA. 1...|$|R
40|$|Simplified, a {{chromatic}} confocal triangulation CCT sensor encodes different surface heights {{by different}} wavelengths. A height {{is measured by}} determining the corresponding wavelength of the optical signal. The CCT sensor concept solves this task using a multispectral camera, which is a camera with multiple channels, each characterized by a different optical filter. To measure the wavelength with high <b>precision,</b> these <b>filters</b> need to be optimized. For this purpose a physical model is introduced, which describes the multispectral camera. Based on this model, merit functions are developed that cover two aspects: increased resolution and statistical uniqueness of a measurement. These merit functions {{can be used in}} a next step to optimize a set of filters...|$|R
40|$|Robotic {{assisted}} {{minimally invasive}} surgery systems not only have the advantages of traditional laparoscopic procedures but also restore the surgeon 2 ̆ 7 s hand-eye coordination and improve the surgeon 2 ̆ 7 s <b>precision</b> by <b>filtering</b> hand tremors. Unfortunately, these benefits have {{come at the expense}} of the surgeon 2 ̆ 7 s ability to feel. Several research efforts have already attempted to restore this feature and study the effects of force feedback in robotic systems. The proposed methods and studies have some shortcomings. The main focus of this research is to overcome some of these limitations and to study the effects of force feedback in palpation in a more realistic fashion...|$|R
40|$|Personal users on Twitter {{frequently}} post {{observations about}} their immediate environment {{as part of}} the 500 million tweets posted everyday. These observations and their implicitly associated time and location data are a valuable source of information for monitoring objects and events, such as earthquake, hailstorm, and shooting incidents. However, given the informal and uncertain expressions used in personal Twitter messages, and the various type of accounts existing on Twitter, capturing personal observations of objects and events is challenging. In contrast to the existing supervised approaches, which require significant efforts for annotating examples, in this paper, we propose an unsupervised approach for filtering personal observations. Our approach employs lexical analysis, user profiling and classification components to significantly improve <b>filtering</b> <b>precision.</b> To identify personal accounts, we define and compute a mean user profile for a dataset and employ distance metrics to evaluate the similarity of the user profiles under analysis to the mean. Our extensive experiments with real Twitter data show that our approach consistently improves <b>filtering</b> <b>precision</b> of personal observations by around 22 %. Yihong Zhang, Claudia Szabo, and Quan Z. Shen...|$|R
40|$|Aimed at {{solving the}} problem of {{decreased}} <b>filtering</b> <b>precision</b> while maneuvering target tracking caused by non-Gaussian distribution and sensor faults, we developed an efficient interacting multiple model-unscented Kalman filter (IMM-UKF) algorithm. By dividing the IMM-UKF into two links, the algorithm introduces the cubature principle to approximate the probability density of the random variable, after the interaction, by considering the external link of IMM-UKF, which constitutes the cubature-principle-assisted IMM method (CPIMM) for solving the non-Gaussian problem, and leads to an adaptive matrix to balance {{the contribution of the}} state. The algorithm provides filtering solutions by considering the internal link of IMM-UKF, which is called a new adaptive UKF algorithm (NAUKF) to address sensor faults. The proposed CPIMM-NAUKF is evaluated in a numerical simulation and two practical experiments including one navigation experiment and one maneuvering target tracking experiment. The simulation and experiment results show that the proposed CPIMM-NAUKF has greater <b>filtering</b> <b>precision</b> and faster convergence than the existing IMM-UKF. The proposed algorithm achieves a very good tracking performance, and will be effective and applicable in the field of maneuvering target tracking...|$|R
40|$|We present ENCORE, {{a system}} for entity {{co-reference}} resolution that synthesizes the outputs of several off-the-shelf co-reference resolution systems. To boost <b>precision,</b> we <b>filter</b> the output using a named entity recognition tool called SYNERGY which itself is a synthesis of several off-the-shelf NER systems. ENCORE is designed to work under two conditions: NP-CR which resolves noun phrase co-reference and NE-CR which resolves co-references only for named entities. We report {{the results of our}} experiments with ENCORE that show 2 % to 40 % improvements in precision, recall and F-scores over the underlying systems. This opens a promising approach which leverages the existing “black box ” state-of-the-art tools without attempting to re-create their achievements and focuses the development efforts on the differences in their output. 1...|$|R
