143|284|Public
50|$|The {{concept of}} records and fields was central in some early file sorting and tabulating utilities, such as IBM's Report <b>Program</b> <b>Generator</b> (RPG).|$|E
50|$|Programming {{languages}} for the 1400 series included Symbolic Programming System (SPS, {{an assembly}} language), Autocoder (assembly language), COBOL, FORTRAN, Report <b>Program</b> <b>Generator</b> (RPG), and FARGO.|$|E
50|$|It {{has a long}} history, {{having been}} {{developed}} by IBM in 1959 as the Report <b>Program</b> <b>Generator</b> - a tool to replicate punched card processing on the IBM 1401 then updated to RPG II for the IBM System/3 in the late 1960s, and since evolved into an HLL equivalent to COBOL and PL/I.|$|E
40|$|Sam Kamin Computer Science Dept. University of Illinois at Urbana-Champaign 1304 W. Springfield Urbana, IL 61801 fkaming@cs. uiuc. edu Abstract The {{interpreter}} for {{the functional}} language JR has been constructed by a unique form of bootstrapping. The entire processor {{is written in}} C++, but much of that C++ is produced by <b>program</b> <b>generators.</b> These <b>program</b> <b>generators</b> [...] - a lexer generator, parser generator, etc. [...] - are programmed in JR itself by the method of "lightweight embedding. " This project is intended to demonstrate the viability of this method of constructing <b>program</b> <b>generators.</b> Because the method of embedding yields powerful languages at modest cost, we {{view it as a}} potentially advantageous approach to the production of <b>program</b> <b>generators,</b> which can in turn yield an entirely new method of achieving code reuse. Partially supported by NSF grant CCR 96 [...] 19644 1 Introduction The interpreter for the functional language JR has been constructed by a unique form of bootstrappi [...] ...|$|R
40|$|<b>Program</b> <b>generators</b> are {{languages}} whose programs produce {{programs in}} other languages. We show how <b>program</b> <b>generators</b> {{can be built}} easily as sets of definitions in a functional language. The method we present {{has the potential to}} be a useful application of functional languages in software development projects based on conventional languages. We illustrate the method with two examples: a top-down parser generator; and a version of the "Message Specification Language," developed at Oregon Graduate Institute. In the latter case, we are able to implement substantially the same language in 100 lines of Standard ML code, with no additional tools or optimizing compilers needed...|$|R
5000|$|Screen Sculptor, SoftCode, UI Programmer, and Genifer are {{examples}} of pioneering <b>program</b> <b>generators</b> that arose during the mid-1980s through the early 1990s. They developed and advanced the technology of extendable, template based source code generators on a mass market scale.|$|R
50|$|IBM {{recognized}} {{the problems with}} the Macro Assembler and created an automated <b>program</b> <b>generator</b> named DMS. DMS later became Cross System Product (CSP) on the 8100. DMS was essentially a screen painter; it could do simple edits such as field range checking or numeric tests but more complex logic still had to be coded using the Macro Assembler.|$|E
50|$|RPG {{is one of}} the few {{languages}} {{created for}} punched card machines that are still in common use today. This is because the language has evolved considerably over time. It was originally developed by IBM in 1959. The name Report <b>Program</b> <b>Generator</b> was descriptive of the purpose of the language: generation of reports from data files, including matching record and sub-total reports.|$|E
50|$|The {{software}} was a <b>program</b> <b>generator,</b> {{as distinct from}} an actual programming language, as programs were generated by the user selecting options from menus that would {{form the basis of}} the generated code. This was done in a logical sequence that would eventually cause a program to be generated in BASIC. At any time, the user could elect to view a flow chart showing the current progress of the program's design.|$|E
40|$|Abstract. We {{describe}} {{our efforts}} to use source-level rewriting to optimize run-time <b>program</b> <b>generators</b> written in Jumbo, a run-time program generation system for Java. Jumbo is a compiler written in compositional style, which brings the advantage that any program fragment can be abstracted out and compiled to an intermediate form. These forms can be put together at run-time to build complete programs. This principle provides {{a high level of}} flexibility in writing <b>program</b> <b>generators.</b> However, this comes at the price of inefficient run-time compilation. Using sourcelevel transformations, we optimize the run-time generation of byte code from fragments, achieving speedups of 5 – 15 %. We discuss the optimization process and give several examples. ...|$|R
40|$|<b>Program</b> <b>generators</b> and transformations {{are hard}} to {{implement}} cor-rectly, because the implementation needs to generically describe how to construct programs, for example, using templates or rewrite rules. We apply dynamic analysis to <b>program</b> <b>generators</b> {{in order to support}} developers in finding bugs and identifying the source of the bug. Our analysis focuses on syntactic language constraints and checks that generated programs are syntactically well-formed. To retain a language’s grammar as the unique specification of the lan-guage’s syntax, we devised mechanisms to derive the analysis from the grammar. Moreover, we designed a run-time system to support the modular activation/deactivation of the analysis, so that genera-tors do not require adaption. We have implemented the analysis for the Stratego term-rewriting language and applied it in case studies based on Spoofax and SugarJ...|$|R
40|$|We {{describe}} {{an experiment in}} the use of domain-specific embedded languages for program generation. Specifically, we describe how the processor for the language JR has been built by embedding <b>program</b> <b>generators</b> in Standard ML. The processor is built from four program generators: a lexer generator, a parser generator, an abstract syntax generator, and an abstract syntax tree translation generator. We discuss the specifications given in these embedded languages as well as their implementation. In particular, we show that using the embedded language approach leads to powerful languages at relatively low cost. Keywords: Domain-specific languages, functional languages, <b>program</b> <b>generators</b> 1 Introduction A number of recent studies have explored the design of new special-purpose languages by extension to existing languages. Such extensions have been called embedded domain-specific languages [9, 6]. The embedding seems to work best with functional languages, because the existence of higherorde [...] ...|$|R
5000|$|Mark McCormack helped Tarkenton invest, {{making him}} wealthy enough to [...] "retire this week {{if he wanted}} to", as New York {{magazine}} wrote in 1971. Tarkenton was a pioneer in computer software, and founder of Tarkenton Software, a <b>program</b> <b>generator</b> company. He toured the United States promoting CASE or [...] "computer-aided software engineering" [...] with Albert F. Case, Jr. of Nastec Corporation, but ultimately merged his software firm with James Martin's KnowledgeWare, of which Tarkenton was president until selling the company to Sterling Software in 1994.|$|E
50|$|As {{long as the}} ATE {{manufacturer}} provides {{with the}} test <b>program</b> <b>generator</b> that can use UTSL as an input the cumbersome task of translating a test program from one platform to another can be significantly simplified. In other words, the task of rewriting of the test programs for a specific platform can {{be replaced by the}} automatically generating the code from the UTSL based test specification. Prerequisite for this is that the UTSL description of tests is sufficiently detailed with definition of the test technique as well as the description of all the necessary inputs and outputs.|$|E
50|$|When both {{authentication}} and encryption need to {{be performed}} on a message, a software implementation can achieve speed gains by overlapping the execution of those operations. Performance is increased by exploiting instruction level parallelism by interleaving operations. This process is called function stitching, and while in principle it {{can be applied to}} any combination of cryptographic algorithms, GCM is especially suitable. Manley and Gregg show the ease of optimizing when using function-stitching with GCM. They present a <b>program</b> <b>generator</b> that takes an annotated C version of a cryptographic algorithm and generates code that runs well on the target processor.|$|E
40|$|This paper {{proposes a}} domain-oriented {{software}} process re-engineering method {{that allows for}} efficient software process modeling and cuts overall software development cost. This is achieved by use of a software synthesis shell that supports the development of <b>program</b> <b>generators</b> from input specification syntax and rewrite rules. Application of the proposed method {{to the development of}} a large scale "chain store management system" resulted in the development of a specification checker, two <b>program</b> <b>generators,</b> a specification document generator, and a test data generator. The overall development cost, including re-engineering cost, for this store management system has been reduced by 164 man-months. 1 Introduction Many software synthesis systems have been proposed in order to improve the productivity of software development, and some have succeeded in automating the programming phase [1] [8] as well as the design phase [3] [5] [6] by limiting the application domains. Although software s [...] ...|$|R
40|$|We {{address the}} problem of {{verification}} of implementations of complex processors using architectural level automatic test <b>program</b> <b>generators.</b> A number of automatic test <b>program</b> <b>generators</b> exist, and are widely used for verification of the compliance of complex processors with their architectures. We define a four stage verification process: (1) describing the processor implementation control as a Finite State Machine (2) deriving transition coverage on the FSM using methods from formal verification (3) translation of the covering tours to constraints on test programs (4) generation of test programs for each set of constraints. This process combines a high quality and well defined theoretical method along with tools used in industrial practice. There are a number of advantages of our Method: (a) The last three stages are automated (b) Implementing the FSM model involves relatively little expert designers time (c) The method is feasible for modern superscalar processors and was studied on [...] ...|$|R
40|$|Programmers {{frequently}} write <b>program</b> <b>generators</b> {{using the}} simple model of programs as text. The essence {{of this approach}} is its lack of structure. For this reason, it gets no respect from academic researchers. But the flip side of lacking structure is freedom from restrictions. We argue that the latter is important, and perhaps essential, in finding a willing audience for program generation among working programmers. Jumbo is a system for producing run-time <b>program</b> <b>generators,</b> which is designed to offer the programmer a “programs as strings ” model to as great an extent as possible, though some constraints are inevitable. We show by several examples that these constraints still allow for both a natural and a powerful program generation model. We then discuss how the approach taken by Jumbo, though possessing less structure than some competing methods, still raises scientific problems that ought to be of interest to researchers in this area...|$|R
50|$|Increased {{complexity}} of ASICs lead to requirements of more complex test programs with longer development times. An automated test program generation could simplify and speed up this process. Teradyne Inc. together with Robert Bosch GmbH agreed to developed a concept and a tool chain for an automated test-program generation. To achieve this a tester independent programming language was required. Hence, UTSL, {{a programming language}} that enables detailed description of tests that can be translated into the ATE specific programming language was developed. The ATE manufacturers need to provide a Test <b>Program</b> <b>Generator</b> that uses the UTSL test description as inputs and generates the ATE-specific test code with optimal resource mapping and better practice program code.|$|E
50|$|FB began life in {{the mid-1980s}} as ZBasic, which was created by Andrew Gariepy and envisioned as a {{cross-platform}} development system. Before long, the cross-platform aspects were dropped in favor of focusing on Macintosh development. ZBasic acquired a devoted following of developers who praised its ease of use and the tight, fast code produced by the compiler (a legendary labor involving extensive use of hand-built 68K assembly language code). In 1992 and as the next major step after ZBasic version 5, Zedcor Inc., {{the company of the}} Gariepy brothers Andy, Mike, Peter and friends based in Tucson, Arizona presented FutureBASIC (later called FBI). In 1995 Staz Software, led by Chris Stasny, acquired the rights to market FutureBASIC. Chris Stasny started this business with an upgraded version, namely FBII, and with his own development, the <b>Program</b> <b>Generator</b> (PG PRO), a CASE tool.|$|E
5000|$|... 1961: IBM 7030 StretchIBM {{delivers}} {{its first}} 7030 Stretch supercomputer. Stretch {{falls short of}} its original design objectives, {{and is not a}} commercial success. But it is a visionary product that pioneers numerous revolutionary computing technologies which are soon widely adopted by the computer industry.1961: Thomas J. Watson Research CenterIBM moves its research headquarters from Poughkeepsie, NY to Westchester County, NY, opening the Thomas J. Watson Research Center which remains IBM's largest research facility, centering on semiconductors, computer science, physical science and mathematics. The lab which IBM establish at Columbia University in 1945 was closed and moved to the Yorktown Heights laboratory in 1970.1961: IBM Selectric typewriterIBM introduces the Selectric typewriter product line. Later Selectric models feature memory, giving rise to the concepts of word processing and desktop publishing. The machine won numerous awards for its design and functionality. Selectrics and their descendants eventually captured 75 percent of the United States market for electric typewriters used in business. IBM replaced the Selectric line with the IBM Wheelwriter in 1984 and transferred its typewriter business to the newly formed Lexmark in 1991.1961: Report Program GeneratorIBM offers its Report <b>Program</b> <b>Generator,</b> an application that allows IBM 1401 users to produce reports. This capability was widely adopted throughout the industry, becoming a feature offered in subsequent generations of computers. It {{played an important role in}} the successful introduction of computers into small businesses.1962: Basic beliefsDrawing on established IBM policies, Thomas J. Watson, Jr., codifies three IBM basic beliefs: respect for the individual, customer service, and excellence.1962: SABRETwo IBM 7090 mainframes formed the backbone of the SABRE reservation system for American Airlines. As the first airline reservation system to work live over phone lines, SABRE linked high speed computers and data communications to handle seat inventory and passenger records.1964: IBM System/360In the most important product announcement in company history to date, IBM introduces the IBM System/360: a new concept in computers which creates a [...] "family" [...] of small to large computers, incorporating IBM Solid Logic Technology (SLT) microelectronics and using the same programming instructions. The concept of a compatible [...] "family" [...] of computers transforms the industry.1964: Word processingIBM introduces the IBM Magnetic Tape Selectric Typewriter, a product which pioneered the application of magnetic recording devices to typewriting, and gave rise to desktop word processing. Referred to then as [...] "power typing," [...] the feature of revising stored text improved office efficiency by allowing typists to type at [...] "rough draft" [...] speed without the pressure of worrying about mistakes.1964: New corporate headquartersIBM moves its corporate headquarters from New York City to Armonk, New York.1965: Gemini space flightsA 59-pound onboard IBM guidance computer is used on all Gemini space flights, including the first spaceship rendezvous. IBM scientists complete the most precise computation of the Moon's orbit and develop a fabrication technique to connect hundreds of circuits on a silicon wafer.1965: New York World's FairThe IBM Pavilion at the New York World's Fair closes, having hosted more than 10 million visitors during its two-year existence.1966: Dynamic Random-Access Memory (DRAM)IBM invents one-transistor DRAM cells which permit major increases in memory capacity. DRAM chips become the mainstay of modern computer memory systems: the [...] "crude oil" [...] of the information age is born.1966: IBM System/4 PiIBM ships its first System/4Pi computer, designed to meet U.S. Department of Defense and NASA requirements. More than 9000 units of the 4Pi systems are delivered by the 1980s for use in the air, sea, and space.1966: IBM Information Management System (IMS)IBM designed the Information Management System (IMS) with Rockwell and Caterpillar starting in 1966 for the Apollo program, where it was used to inventory the very large bill of materials (BOM) for the Saturn V moon rocket and Apollo space vehicle.1967: Fractal geometryIBM researcher Benoit Mandelbrot conceives fractal geometry - the concept that seemingly irregular shapes can have identical structure at all scales. This new geometry makes it possible to mathematically describe the kinds of irregularities existing in nature. The concept greatly impacts the fields of engineering, economics, metallurgy, art, health sciences, and computer graphics and animation.1968: IBM Customer Information Control System (CICS)IBM introduces the CICS transaction monitor. CICS remains to this day the industry's most popular transactions monitor.|$|E
40|$|Programs {{executing}} on a private-memory {{parallel system}} exchange data by explicitly sending and receiving messages. Two communication styles {{have been identified}} for such systems: memory communication (each message exchanged between two processors is buffered in memory, e. g. as in message passing) and systolic communication (each word of a message is transmitted directly from the sender processor to receiver processor, without any buffering in memory). The iWarp system supports both communication styles and therefore provides a platform {{that allows us to}} evaluate how the choice of communication style impacts the usage of processor resources. Parallel <b>program</b> <b>generators</b> map a machine independent description of a computation onto a private-memory parallel system. We use two different parallel <b>program</b> <b>generators</b> that employ the two communication styles to map a set of application kernels onto iWarp. By using tools to generate the parallel programs, we are able to obtain realistic data on t [...] ...|$|R
5000|$|... {{specialized}} {{software and hardware}} solutions, as EPG (Electronic <b>Program</b> Guide) <b>generators,</b> conditional access system; ...|$|R
40|$|Writing <b>program</b> <b>generators</b> {{involves}} {{the development of}} programs that manipulate representations of programs, thus offering unlimited possibliities for abstraction. Abstractions not expressable in typed languages can always be expressed as generators. For example generator mechanisms are implicit in the eq-types of Standard ML, and the deriving clauses of Haskel type classes, neither {{of which can be}} encoded within the language. While these mechanisms always generate well typed code, they are "hard coded" into the compiler. Our goal is to incorporate generator like abstraction mechanisms into programming languages, while ensuring that only well typed programs are executed. This can be accomplished by a generate and then type-check approach or an inference mechanism that guarantees that only well typed programs are generated. In this paper we investigate both possibilities. The problems associated with <b>program</b> <b>generators</b> include problems of "hygiene" and the type compatibility of the programs being generated. Naive approaches to typing generators have either been inflexible (giving rigid, invariant types to the meta-level expressions representing programs requiring every object term to have the same type) or undecidable (requiring dependent types with arbitrary equality theories on expression equality). We solve the hygiene problems by the use of syntactic closures and have approached the type problem in two ways. First, by using a two level system (a la Nielson and Nielson[9]) we are able to embed a meta-computation phase which associates invariant code types to object expressions, into a later phase which then indexes these code types with the object expression's type. This ensures that only well-typed programs reach the run-time phase. We guarantee that the meta-computation phase terminates by restricting its expressiveness by the use of catamorphisms as the exclusive mechanism to encode recursion. Second we introduce a theory of dependent types for two-level languages that has a useful, decidable theory due to the use of catamorphisms, rather than arbitrary recursion, in the expressions that may index dependent types. We show that this can give useful types to <b>program</b> <b>generators</b> which detect type problems in generated code at the compile-type of the generator. Third we show that by embedding second level type declarations as values in first level computations we are able to construct polytypic <b>program</b> <b>generators,</b> such as polymorphic equality and generic map using our theory...|$|R
40|$|Abstract. In {{this paper}} {{we argue that}} hand-writing a <b>program</b> <b>{{generator}}</b> generator {{has a number of}} advantages compared to generating a <b>program</b> <b>generator</b> generator by self-application of a partial evaluator. We show the basic principles of how to construct a <b>program</b> <b>generator</b> generator by presenting a <b>program</b> <b>generator</b> generator for a skeletal language, and we argue that it is not more difficult to use the direct approach than the indirect approach. Moreover, we report on some promising experiments made with a prototype implementation of a <b>program</b> <b>generator</b> generator for most of the Standard ML Core Language. To the best of our knowledge, our prototype is the first succesfully implemented hand-written <b>program</b> <b>generator</b> generator for a statically typed language. ...|$|E
40|$|Abstract: In {{a program}} specializer, the Residual <b>Program</b> <b>Generator</b> (RPG) takes as input a source program {{decorated}} with annotations provided by its binding time analyzer and produces a specialized {{version of the}} source program. CILPE is a program specializer dealing with programs written in SOOL, a simple Stack Object-Oriented Language. The paper describes the residual <b>program</b> <b>generator</b> that {{is a part of}} CILPE. Note: Publication language:russia...|$|E
40|$|Program specializers {{improve the}} speed of {{programs}} by performing some of the programs ' reductions at specialization time rather than at runtime. This specialization process can be time-consuming; one common technique for improving {{the speed of}} the specialization of a particular program is to specialize the specializer itself on that program, creating a custom specializer, or <b>program</b> <b>generator,</b> for that particular program. Much research has been devoted to the problem of generating e cient program generators, which do not perform reductions at program generation time which could instead have been performed when the <b>program</b> <b>generator</b> was constructed. The conventional wisdom holds that only o ine program specializers, which use binding time annotations, can be specialized into such e cient program generators. This paper argues {{that this is not the}} case, and demonstrates that the specialization of a nontrivial online program specializer similar to the original MIX &quot; can indeed yield an e cient <b>program</b> <b>generator.</b> The key to our argument is that, while the use of binding time information at <b>program</b> <b>generator</b> generation time is necessary for the construction of an e cient custom specializer, the use of explicit binding time approximation techniques is not. This allows us to distinguish the problem at hand (i. e., the use of binding time information during <b>program</b> <b>generator</b> generation) from particular solutions to that proble...|$|E
40|$|International audienceThis paper {{presents}} MetaScribe, {{a generator}} of transformation engine {{designed to help}} the implementation of <b>program</b> <b>generators</b> or transformation of a specification to another one. MetaScribe defines a meta-data description scheme suitable for the internal representation of various graphical and hierarchical description. MetaScribe is fully implemented in Ada and uses the language facilities to enforce type checking and handling of errors in the manipulated descriptions...|$|R
50|$|The PECAN <b>Programming</b> Environment <b>Generator</b> was an {{incremental}} compiler, developed by Steven P. Reiss {{in the early}} 1980s.|$|R
40|$|Templates are a {{powerful}} but poorly understood {{feature of the}} C++ language. Their syntax resembles the parameterized classes of other languages (e. g., of Java). But because C++ supports template specialization, their semantics is quite di#erent from that of parameterized classes. Template specialization provides a Turing-complete sub-language within C++ that executes at compile-time. Programmers put this power to many uses. For example, templates are a popular tool for writing <b>program</b> <b>generators...</b>|$|R
40|$|Abstract. We {{describe}} {{the design and}} implementation of a <b>program</b> <b>generator</b> that can produce extensions of Fortran that are specialized to support the programming of particular applications. Extensions are specified through parameter structures that {{can be referred to}} in Fortran programs to specify the dependency of program parts on these parameters. By providing parameter values, a parameterized Fortran program can be translated into a regular Fortran program. We describe as a real-world application of this <b>program</b> <b>generator</b> the implementation of a generic inverse ocean modeling tool. The <b>program</b> <b>generator</b> is implemented in Haskell and makes use of sophisticated features, such as multi-parameter type classes, existential types, and generic programming extensions and thus represents the application of an advanced applicative language to a real-world problem...|$|E
40|$|When {{writing a}} <b>program</b> <b>generator</b> {{requires}} considerable intellectual effort, it is valuable to amortize that effort {{by using the}} generator to build more than one application. When a <b>program</b> <b>generator</b> serves multiple clients, however, the implementor must address pragmatic questions that implementors of single-use program generators can ignore. In how many languages should generated code be written? How should code be packaged? What should the interfaces to the client code look like? How should a user control variations? This paper elaborates on these questions by means of case studies of the New Jersey Machine-Code Toolkit, the λ-RTL Translator, and the ASDL <b>program</b> <b>generator.</b> It is hoped that the paper will stimulate the development of better techniques. Most urgently needed are a standard way to support multiple target languages and a simple, clear way to control interfaces to generated code. ...|$|E
40|$|Abstract. Binding-time {{polymorphism}} {{enables a}} highly flexible binding-time analysis for offline partial evaluation. This work provides {{the tools to}} translate this flexibility into efficient program specialization {{in the context of}} a polymorphic language. Following the cogen-combinator approach, a set of combinators is defined in Haskell that enables the straightforward transcription of a binding-time polymorphic annotated program into the corresponding <b>program</b> <b>generator.</b> The typing of the combinators mimics the constraints of the binding-time analysis. The resulting <b>program</b> <b>generator</b> is safe, tag-free, and it has no interpretive overhead. ...|$|E
40|$|Program {{generation}} {{is among the}} most promising techniques in the e#ort to increase the automation of programming tasks. In this paper, we discuss the potential impact and research value of program generation, we give examples of our research in the area, and we outline a future work direction that we consider most interesting. Specifically, we first discuss why <b>program</b> <b>generators</b> have significant applied potential. At the same time we argue that, as a research topic, meta-programming tools (i. e., language tools for writing <b>program</b> <b>generators)</b> may be of greater value. We then illustrate our views on generators and meta-programming tools with our latest work on the Meta-AspectJ metaprogramming language and the GOTECH generator. Finally, we examine the problem of statically determining the safety of a generator and present its intricacies. We limit our focus to one particular kind of guarantee for generated code [...] -ensuring that the generated program is free of compile-time errors. We believe that this research direction will see significant attention and will make a di#erence in the mainstream adoption of meta-programming technology...|$|R
40|$|The {{purpose of}} this review is to (1) ensure that {{the design of the}} steam {{generator}} is adequate for implementing a steam <b>generator</b> <b>program</b> and (2) verify that the steam <b>generator</b> <b>program</b> will result in maintaining tube integrity during operation and postulated accident conditions. The steam <b>generator</b> <b>program</b> is intended to ensure that the structural and leakage integrity of the tubes is maintained at a level comparable to that of the original design requirements. The specific areas of review are as follows: 1. The design of the primary and secondary side of the steam generator is reviewed to ensure that it permits implementation of a steam <b>generator</b> <b>program...</b>|$|R
50|$|The <b>programming</b> {{languages}} the <b>generators</b> recognize.|$|R
