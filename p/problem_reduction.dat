151|1841|Public
5000|$|... "Cross-age peer {{mentoring}} programs utilize structure, meet {{for more than}} ten meetings, do not focus primarily on deficit or <b>problem</b> <b>reduction,</b> and require an age span of at least two years." ...|$|E
50|$|Plaisted's {{research}} interests include term rewriting systems, automated theorem proving, logic programming, and algorithms. His research accomplishments in theorem proving include work on the recursive path ordering, the associative path ordering, abstraction, the simplified and modified <b>problem</b> <b>reduction</b> formats, ground reducibility,nonstandard clause form translations, rigid E-unification, Knuth-Bendix completion, replacement rules in theorem proving, instance-based theorem proving strategies, and semantics in theorem proving.|$|E
40|$|In {{this paper}} we present an axiomatic theory {{for a class}} of algorithms, called <b>problem</b> <b>reduction</b> generators, that {{includes}} dynamic programming, general branch-and-bound, and game tree search as special cases. This <b>problem</b> <b>reduction</b> theory is {{used as the basis}} for a mechanizable design tactic that transforms formal specifications into <b>problem</b> <b>reduction</b> generators. The theory and tactic are illustrated by application to the problem of enumerating optimal binary search trees. Contents 1. Introduction 3 2. Basic Concepts And Notation 3 2. 1. Language................................... 3 2. 2. Signatures and Structures.......................... 4 2. 3. Problem Specifications............................ 5 3. Enumerating Feasible Solutions 6 3. 1. <b>Problem</b> <b>Reduction</b> Theory.......................... 6 3. 2. Design Tactic [...] Enumerating Feasible Solutions............. [...] . ...|$|E
3000|$|Discussion: Shorter {{surgical}} time, Reduced Pain. Reduced Ventilation problems, Reduced Hemodynamic <b>problems,</b> <b>Reduction</b> in surgical complications, More workspace, less {{damage to}} other organs. Avoids herniation, [...]...|$|R
5000|$|Cartesian Method and the <b>Problem</b> of <b>Reduction</b> (1991) Oxford University Press ...|$|R
5000|$|Interpretations of Life and Mind: Essays Around the <b>Problem</b> of <b>Reduction</b> (1971) editor ...|$|R
40|$|This paper {{presents}} a {{design for a}} reactive sys-tem based on the classical planning techniques of <b>problem</b> <b>reduction</b> and state space search. The proposed approach enables a reactive sys-tem to be scaled up to handle larger sets of tasks. <b>Problem</b> <b>reduction</b> synthesizes an ini-tial reactive policy for a given task. When an execution impasse occurs, state space search finds critical choice points, from which control rules are synthesized. These rules alter the policy’s future behavior {{in order to avoid}} the impasse. This technique, called critical choice planning, incrementally debugs the initial pol-icy in the least restrictive way; this "least re-strictive property " makes the technique a per-fect match for <b>problem</b> <b>reduction.</b> Over time, the <b>problem</b> <b>reduction</b> rules are improved via learning from the debugging experiences...|$|E
40|$|This paper {{presents}} {{an approach to}} inductive synthesis of logic programs from examples using problem decomposition and <b>problem</b> <b>reduction</b> principles. This {{is in contrast to}} the prevailing logic program induction paradigm, which relies on generalization of programs from examples. The <b>problem</b> <b>reduction</b> is accomplished as a constrained top-down search process, which eventually is to reach trivial problems...|$|E
40|$|Software {{problems}} – problems whose {{solution is}} software-intensive – come in many forms. Given that software and computers are {{deeply embedded in}} society, one general characteristic of software problems is that their early requirements are expressed “deep into the world”, i. e., in terms that end-users and other stake-holders would recognise and understand. The developer is left with {{the difficult task of}} interpreting such requirements closer to the software solution. In this paper, we introduce <b>problem</b> <b>reduction,</b> a systematic transformation from requirements to specifications by which a software problem with requirements deep in the world becomes a simpler software problem with the same solution. <b>Problem</b> <b>reduction</b> helps the developer because the simpler problem has requirements that are ‘closer to the machine’, i. e., closer to specification. Indeed, repeated application of <b>problem</b> <b>reduction</b> can lead directly to a software specification in certain cases. We reflect on how <b>problem</b> <b>reduction</b> captures certain requirements engineering practices, and provide a set of rules for its application...|$|E
40|$|Abstract: The {{numerical}} {{method of}} 1 D boundary problem's solution for selfadjoint two-order differential operator is considered. The method presented is similar famous K. I. Babenko's algorithm {{and based on}} boundary <b>problem's</b> <b>reduction</b> to some integral equation. One's digitization is selected to aim nonsaturated algorithm for smooth functions with bounded highest derivative. The algorithm's convergence and nonsaturation for functions from classes Wr∞ (M;[a,b]) are proved. Note: Publication language:russia...|$|R
50|$|Investigations of Waiting Time <b>Problems</b> by <b>Reduction</b> to Markov Processes, Acta Math. Acad. Sci. Hung. vol.6, pp. 101-129, 1955.|$|R
50|$|This is {{a useful}} theoretic result. For {{numerical}} <b>problems</b> row <b>reduction</b> with pivots and other methods are more stable and efficient.|$|R
40|$|Given an {{adequate}} {{definition of the}} disease problem in epidemiological terms, {{it is possible to}} measure the epidemiological effectiveness of control measures in terms of <b>problem</b> <b>reduction.</b> This is to be distinguished from the clinical efficacy of the same measures. The practical difficulty in assessing the epidemiological effectiveness of control measures experimentally can be overcome by the construction of simulation models and the use of computers, whereby the <b>problem</b> <b>reduction</b> associated with various control strategies can be estimated numerically...|$|E
40|$|<b>Problem</b> <b>reduction</b> is a {{basic concept}} behind much of AI search. The {{standard}} approach is to view <b>problem</b> <b>reduction</b> in terms of AND/OR graphs and then to concentrate on graph search techniques {{to find a solution}} to the original problem. However these techniques depend upon global graph properties. By taking a more object-oriented approach we can ignore the graphs as a whole and instead need only deal with the local properties of individual <b>problem</b> <b>reduction</b> steps. This paper presents the GAO* algorithm, which is a generalization of the AO* algorithm based on this shift in viewpoint. As well as encompassing the behaviours of existing algorithms (such as A*, AO*, MINIMAX, alphabeta, SSS*, and SCOUT), GAO* goes further. It allows the seamless integration of different problem domains, different search strategies, and even non-search problem-solving techniques, within the same algorithm...|$|E
40|$|In {{this study}} at ‘Tender Youth Foundation’ (Stichting Tender Jeugdzorg), an {{organization}} for youth and parenting help in West-Brabant (the Netherlands), {{the relationship is}} investigated between <b>problem</b> <b>reduction</b> {{and the extent of}} problem behavior {{at the end of the}} intervention on the one hand and client satisfaction on the other. Potential moderators (age, gender, ethnicity, duration of intervention, DSM diagnosis, and adjunct therapy) were examined within these relations. The sample consists of 372 children/ adolescents and/or their parents who received an intervention from Tender. <b>Problem</b> <b>reduction</b> is measured with the Child Behaviour Checklist [CBCL], and the Youth Self Report [YSR]. In order to determine client satisfaction, the C-test or the Exit-questionnaire was filled out by parents and/or the adolescents. The results show that clients and their parents are very satisfied with the given intervention. A weak positive association was found between reduction in internalizing and total problem behavior and client satisfaction for parents of children between two and five years old. For parents of children/adolescents between five and nineteen years old, in addition to a relationship with total <b>problem</b> <b>reduction,</b> a positive relationship was found between externalizing <b>problem</b> <b>reduction</b> and client satisfaction. A remarkable result is that for the adolescents themselves no associations were found between <b>problem</b> <b>reduction</b> and client satisfaction. Adjunct therapy has proved to be a moderator in the relationship between internalizing <b>problem</b> <b>reduction</b> and client satisfaction for parents of children between two and five years old. With respect to the extent of problem behavior at the end of the intervention, no relations were found with client satisfaction for parents of children between two and five years old and the adolescents themselves. For parents of children/ adolescents between five and eighteen years old, it is shown that the smaller the amount of total and externalizing behavior problems at the end of the intervention, the higher the client satisfaction. No moderators were found in these relationships. The meaning of client satisfaction as measure for the effect of an intervention is discussed...|$|E
40|$|This paper {{describes}} {{solutions to}} finding shortest paths in stochastic graphs with partially unknown topologies. We consider graphs which are both static and dynamic. We solve the static <b>problem</b> by <b>reduction</b> to a Markov decision process and solve the dynamic <b>problem</b> by <b>reduction</b> to a partially observable Markov decision process. We show these solutions to be intractable and explore reinforcement learning {{as a method}} of approximation. Finally, we present empirical results of a reinforcement learning approach in this framework...|$|R
50|$|In {{computability theory}} and {{computational}} complexity theory, a many-one reduction is a reduction which converts instances of one decision problem into instances {{of a second}} decision <b>problem.</b> <b>Reductions</b> are thus {{used to measure the}} relative computational difficulty of two problems. It is said that A reduces to B if, in layman's terms, B is harder to solve than A. That is to say, any algorithm that solves B can also be used as part of a (otherwise relatively simple) program that solves A.|$|R
2500|$|M. Plešinger, The Total Least Squares <b>Problem</b> and <b>Reduction</b> of Data in AX ≈ B. Doctoral Thesis, TU of Liberec and Institute of Computer Science, AS CR Prague, 2008.|$|R
40|$|In {{this paper}} we explore the notion of <b>problem</b> <b>reduction</b> as a {{systematic}} transformation from requirements to specifications. We adopt the notion of problem as a requirement in a real-world context for which a software solution is sought, and view the process of software development as a problem solving process, leading ultimately, and hopefully, to a solution which satisfies the requirement in its context. In this paper, we focus on how a solution specification {{can be derived from}} a requirement, and introduce <b>problem</b> <b>reduction</b> as a systematic transformation to achieve this. We reflect on how <b>problem</b> <b>reduction</b> captures requirements engineering practices, express {{it in the context of}} Problem Frames and provide a set of rules for its application. The intention of the work is to increase the understanding of the problem solving process as well as to provide techniques to support sound engineering practices...|$|E
40|$|Many {{real world}} problems, e. g. in {{personnel}} scheduling and transportation planning, can be modeled naturally as Constrained Shortest Path Problems (CSPPs), i. e., as Shortest Path Problems with additional constraints. A well studied {{problem in this}} class is the Resource Constrained Shortest Path <b>Problem.</b> <b>Reduction</b> technique...|$|E
40|$|In {{previous}} work, Korf {{showed that}} by introducing one problem- reduction {{step into a}} state- space search, one could {{reduce the number of}} node generations from 0 ((2 b) 2 d) to 0 (bd), where b and d are the branching factor and search depth. My results are as follows: 1. The 0 (bd) bound is tight, but the 0 ((bd) 2 d) bound is not: the A* procedure does only Q(b 2 d) node generations. Thus, the improvement produced by one problem- reduction step is not always as great as the previous results might suggest. 2. In an AND/OR tree where multiple problem- reduction steps are possible, <b>problem</b> <b>reduction</b> produces a much more dramatic improvement: both the time complexity and the space complexity decrease from doubly exponential to singly exponential. 3. For iterative-deepening procedures like IDA* that only remember the nodes on the current path, the space complexity decreases but the time complexity increases - by exponential amounts in Korf's model, and doubly exponential amounts in the AND/OR-tree model. This is true even for IDAO*, a new procedure that improves IDA*'s performance by combining it with <b>problem</b> <b>reduction.</b> These results lead to the following conclusions: In general, <b>problem</b> <b>reduction</b> can save huge amounts of both time and space.  Whether to use a procedure that remembers every node it has visited, or instead use a limited-memory iterative-deepening procedure, depends on whether the primary objective is to save space or save time. <P...|$|E
40|$|We {{describe}} how Gröbner bases {{can be used}} to solve the <b>reduction</b> <b>problem</b> for Feynman integrals, i. e. to construct an algorithm that provides the possibility to express a Feynman integral of a given family as a linear combination of some master integrals. Our approach is based on a generalized Buchberger algorithm for constructing Gröbner-type bases associated with polynomials of shift operators. We illustrate it through various examples of <b>reduction</b> <b>problems</b> for families of one- and two-loop Feynman integrals. We also solve the <b>reduction</b> <b>problem</b> for a family of integrals contributing to the three-loop static quark potential...|$|R
40|$|A {{branch and}} bound {{algorithm}} is proposed to solve the H 2 -norm model <b>reduction</b> <b>problem</b> and the H 2 -norm controller <b>reduction</b> <b>problem,</b> with conditions assuring convergence to the global optimum in finite time. The lower and upper bounds used in the optimization procedure are obtained through linear matrix inequalities formulations. Examples illustrate the results...|$|R
5000|$|... #Caption: Some NP-complete <b>problems,</b> {{indicating}} the <b>reductions</b> typically used {{to prove their}} NP-completeness ...|$|R
40|$|The Entropy Reduction Engine, an {{architecture}} for {{the integration of}} planning, scheduling, and control, is described. The architecture is motivated, presented, and analyzed {{in terms of its}} different components; namely, <b>problem</b> <b>reduction,</b> temporal projection, and situated control rule execution. Experience with this architecture has motivated the recent integration of learning. The learning methods are described along with their impact on architecture performance...|$|E
40|$|Abstract—An IEC {{technique}} is described for a multi-objective search of conceptual solutions. The survivability of solutions {{is influenced by}} both model-based fitness and subjective human preferences. The concepts ’ preferences are articulated via a hierarchy of sub-concepts. The suggested method produces an objectivesubjective front. Academic example is employed to demonstrate the proposed approach. Keywords—Conceptual solution, engineering design, hierarchical planning, multi-objective search, <b>problem</b> <b>reduction...</b>|$|E
40|$|We {{develop an}} {{efficient}} real-time method of delay control for non-real-time {{data in the}} return link of interactive multimedia satellite networks. Considering multiple delay levels of packets, we mathematically formulate this control problem so that a fair transmission opportunity may be given to satellite interactive terminals. With <b>problem</b> <b>reduction,</b> we promote the computational efficiency in searching for the optimal solution for delay control...|$|E
40|$|Optimization and {{decision}} <b>problems,</b> <b>Reductions,</b> Turing Machine as an acceptor {{and as an}} enumerator—Techniques of Turing Machine construction – parallel tracks and storage in control, subroutine Turing Machine, Church-Turing thesis, Variants of Turing Machine – multitape, nondeterministic—their equivalences with other models. Properties of recursively enumerable and recursive sets. Relations between unrestricted grammars and Turing Machines. Linear Bounded Automata —relation with Context Sensitive Languages Enumeration of Turing Machines, existence of undecidable problems, Undecidable problems involving Turing Machines and CFG’s. Universal Turing Machine {{as a model of}} general purpose computer, Post Correspondence Problem – Applications, valid and invalid computations of Turing Machines. Time and Space complexity of Turing Machines, NP-completeness...|$|R
40|$|AbstractWe {{consider}} solving eigenvalue <b>problems</b> or model <b>reduction</b> <b>problems</b> for a quadratic matrix polynomial Iλ 2 −Aλ−B {{with large}} and sparse A and B. We propose new Arnoldi and Lanczos type processes which {{operate on the}} same space as A and B live and construct projections of A and B to produce a quadratic matrix polynomial with the coefficient matrices of much smaller size, {{which is used to}} approximate the original problem. We shall apply the new processes to solve eigenvalue <b>problems</b> and model <b>reductions</b> of a second order linear input–output system and discuss convergence properties. Our new processes are also extendable to cover a general matrix polynomial of any degree...|$|R
40|$|We {{consider}} {{the solution of}} the balancing-related frequency-weighted model and controller <b>reduction</b> <b>problems</b> using accuracy enhanced numerical algorithms. We propose #rst new stability-enforcing choices of the frequency-weighted grammians which can guarantee the stability of reduced models for two-sided frequency weights. Then we show that for the frequency-weighted controller <b>reduction</b> <b>problems</b> with standard stability and performance-enforcing frequency weights the computation of the frequency-weighted grammians can be done by solving reduced order Lyapunov equations. For both frequency-weighted model and controller <b>reduction</b> <b>problems</b> we indicate how to compute the grammians directly in terms of their Cholesky factors. This allows the extension of the square-root and balancing-free accuracy-enhancing techniques to the frequency-weighted case...|$|R
40|$|We present {{modifications}} of model elimination {{which do not}} necessitate the use of contrapositives. These restart model elimination calculi are proven sound and complete. The corresponding proof procedures are evaluated {{by a number of}} runtime experiments and they are compared to other well known provers. Finally we relate our results to other calculi, namely the connection method, modified <b>problem</b> <b>reduction</b> format and Near-Horn Prolog...|$|E
40|$|In this paper, several <b>problem</b> <b>reduction</b> {{techniques}} are discussed {{that can be}} used to reduce the solution time of set partitioning problems. These techniques can be applied in any solution algorithm for set partitioning problems. Besides a short review of the existing literature on preprocessing set partitioning problems, we also present several new techniques. The value of these techniques is illustrated by various computational experiments. ...|$|E
40|$|We {{consider}} the 0 / 1 Collapsing Knapsack Problem (CKP) and a generalization involving {{more than a}} capacity constraint (M-CKP). We propose a novel ILP formulation and a <b>problem</b> <b>reduction</b> procedure together with an exact approach. The proposed approach compares favorably to the methods available in the literature and manages to solve to optimality very large size instances particularly for CKP and 2 -CKP...|$|E
40|$|The paper {{presents}} the <b>problems</b> related to <b>reduction</b> of {{the duration of}} technical <b>problems</b> optimization. The <b>reduction</b> is achieved {{with the use of}} the genetic algorithm to be run on multiprocessor computers. Exemplary computation tasks are depicted and the methods of parallelization of the optimization process are presented, on the example of the analysis of heavycurrent busducts and luminous flux distribution...|$|R
40|$|NP search <b>problems</b> and <b>reductions</b> {{among them}} Renáta Ševčíková In the thesis we study {{the class of}} Total NP search problems. More {{attention}} is devoted to study the subclasses of Total NP search <b>problems</b> and <b>reductions</b> among them. We combine some known methods: the search trees and their relation to re- ductions, the Nullstellensatz refutation and the degree lower bound based on design to show that two classes of relativized NP search problems based on Mod-p counting principle and Mod-q counting principle, where p and q are different primes, are not reducible to each other. This thesis is finished by a new separation result for p = 2 and q = 3...|$|R
40|$|Dynamic {{computational}} complexity is {{the study}} of resource-bounded ongoing computational processes. We consider the general problem of processing a sequence of inputs, instead of a single input. We introduce a new model for dynamic computation, and investigate the computational complexity of various dynamic problems. ^ The field of computational complexity has previously studied static computation, which takes a single fixed input and computes the desired result. We define a dynamic problem to be the function mapping a stream of data to the desired stream of output, and we investigate the complexity of the dynamic computation required to compute that function. We describe complexity classes of dynamic <b>problems,</b> <b>reductions</b> between dynamic <b>problems,</b> and complete problems for dynamic complexity classes. ...|$|R
