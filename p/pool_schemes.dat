2|161|Public
40|$|Security schemes of {{pairwise}} key establishment, which enable sensors {{to communicate with}} each other securely, play a fundamental role in research on security issue in wireless sensor networks. A general framework for key predistribution is presented, based on the idea of KDC (Key Distribution Center) and polynomial <b>pool</b> <b>schemes.</b> By utilizing nice properties of H 2 (Hierarchical Hypercube) model, a new security mechanism for key predistribution based on such model is also proposed. Furthermore, the working performance of tolerance resistance is seriously inspected in this paper. Theoretic analysis and experimental figures show that the algorithm addressed in this paper has better performance and provides higher possibilities for sensor to establish {{pairwise key}}, compared with previous related works...|$|E
40|$|The present {{research}} deals with car pooling {{as a means}} of making better use of existing infrastructure and {{as a means of}} reducing traffic congestion with all its associated induced effects. Car pooling schemes involve several drivers getting together to share a private vehicle simultaneously, in order to reach their destinations points according to a semi-common route rather than each driver using their own vehicle. The Car Pooling Problem belongs to the non-polynomial computational complexity family of operations problems. In the current literature {{there are only a few}} studies on this optimization problem: the research group has designed several different new automatic and heuristic data processing routines to support efficient matching in car <b>pool</b> <b>schemes.</b> These are based on savings functions and belong to two distinct macro classes of algorithms to give two different modelings of this problem. They offer average savings of more than 50 % in traveled distances demonstrating the effectiveness of a trivial matching scheme for real applications...|$|E
50|$|The land <b>pooling</b> <b>scheme</b> will be {{applicable}} to those farmers {{who are willing to}} voluntarily participate in the scheme. The Government of Maharashtra has recently decided by its resolution dated 14 March 2017, to purchase private land from those farmers who opt out of the land <b>pooling</b> <b>scheme,</b> through direct purchase of lands by private negotiations.|$|R
5000|$|NHS Resolution also manages two non-clinical schemes {{under the}} heading of the Risk <b>Pooling</b> <b>Schemes</b> for Trusts (RPST): ...|$|R
5000|$|If the {{landowner}} agrees to voluntarily {{participate in the}} project by availing the land <b>pooling</b> <b>scheme,</b> {{the landowner}} stands to benefit {{in a number of}} ways: ...|$|R
50|$|By {{implementing}} the land <b>pooling</b> <b>scheme,</b> the Government of Maharashtra hopes {{to set an}} example of land owners being involved and benefiting directly in a development project.|$|R
40|$|Biologically inspired, {{from the}} early HMAX model to Spatial Pyramid Matching, pooling has played an {{important}} role in visual recognition pipelines. Spatial pooling, by grouping of local codes, equips these methods with a certain degree of robustness to translation and deformation yet preserving important spatial information. Despite the predominance of this approach in current recognition systems, we have seen little progress to fully adapt the pooling strategy to the task at hand. This paper proposes a model for learning task dependent <b>pooling</b> <b>scheme</b> [...] including previously proposed hand-crafted <b>pooling</b> <b>schemes</b> as a particular instantiation. In our work, we investigate the role of different regularization terms showing that the smooth regularization term is crucial to achieve strong performance using the presented architecture. Finally, we propose an efficient and parallel method to train the model. Our experiments show improved performance over hand-crafted <b>pooling</b> <b>schemes</b> on the CIFAR- 10 and CIFAR- 100 datasets [...] in particular improving the state-of-the-art to 56. 29 % on the latter...|$|R
3000|$|... 2 {{refer to}} pooling along {{frequency}} and time, respectively (e.g., 1 Ã— 1 <b>pooling</b> <b>scheme</b> {{is equivalent to}} no pooling). The pooling stage has no parameters, and therefore, {{there is also no}} learning.|$|R
50|$|AT&T's PacBell {{no longer}} owns the Baker, California +1-760-733-9XXX block of one {{thousand}} numbers, having relinquished it to competitive local exchange carrier peerlessnetwork.com on March 28, 2013, {{as part of}} a number <b>pooling</b> <b>scheme.</b>|$|R
50|$|After the Second World War, Hill {{returned}} to Hull City where he acted as club scout from 1948 to 1955. He later had a spell at Scarborough, {{where he was}} in charge of their <b>pools</b> <b>scheme.</b>|$|R
40|$|Mobile sinks {{are vital}} in many {{wireless}} sensor applications for efficient data collection, data querying, and localized sensor reprogramming. Mobile sinks prolong {{the lifetime of}} a sensor network. However, when sensor networks with mobile sinks are deployed in a hostile environment, security became a critical issue. They become exposed to varieties of malicious attacks. Thus, anti threats schemes and security services, such as mobile sink?s authentication and pairwise key establishment, are essential components for the secure operation of such networks. Due to the sensors, limited resources designing efficient security schemes with low communication overhead to secure communication links between sensors and MS (Mobile Sink) is not a trivial task. In addition to the sensors limited resources, sink mobility required frequent exchange of cryptography information between the sensors and MS each time the MS updates its location which imposes extra communication overhead on the sensors. In this dissertation, we consider a number of security schemes for WSN (wireless sensor network) with MS. The schemes offer high network?s resiliency and low communication overhead against nodes capture, MS replication and wormhole attacks. We propose two schemes based on the polynomial <b>pool</b> <b>scheme</b> for tolerating nodes capture: the probabilistic generation key pre-distribution scheme combined with polynomial <b>pool</b> <b>scheme,</b> and the Q-composite generation key scheme combined with polynomial <b>pool</b> <b>scheme.</b> The schemes ensure low communication overhead and high resiliency. For anti MS replication attack scheme, we propose the multiple polynomial <b>pools</b> <b>scheme</b> that provide much higher resiliency to MS replication attack {{as compared to the}} single polynomial pool approach. Furthermore, to improve the network resiliency against wormhole attack, two defensive mechanisms were developed according to the MS mobility type. In the first technique, MS uses controlled mobility. We investigate the problem of using a single authentication code by sensors network to verify the source of MS beacons, and then we develop a defensive approach that divide the sensor network into different authentication code?s grids. In the second technique, random mobility is used by MS. We explore the use of different communication channels available in the sensor hardware combined with polynomial <b>pool</b> <b>scheme...</b>|$|R
40|$|Group Self-annuitisation <b>Schemes</b> (GSAs), or <b>Pooled</b> Annuity <b>Schemes,</b> are de-signed {{to share}} {{uncertain}} future mortality experience including systematic im-provements. They {{have been proposed}} because of the significant uncertainty of future mortality improvement on pension and annuity costs. The challenges for designing group <b>pooled</b> <b>schemes</b> include the decreasing average payments when mortality improves significantly, the decreasing numbers in the pool at the older ages and the dependence of systematic mortality improvements across different ages of members in the pool. This paper assesses the impact of systematic de-pendence and reducing numbers in the pool at extreme ages on the efficacy of longevity pooling. Current proposals for <b>pooling</b> <b>schemes</b> are designed to insure against idiosyncratic risk while leaving systematic risk to be borne by individuals. The paper uses a multiple-factor stochastic Gompertz-Makeham model of mor-tality, calibrated to Australian data, to demonstrate {{the significance of these}} is-sues. The model produces analytical results from extreme value theory for surviva...|$|R
40|$|In this paper, we {{implement}} the region-of-influence (ROI) approach for modelling probabilities of heavy 1 -day and 5 -day precipitation amounts in the Czech Republic. The pooling groups are constructed according to (i) the regional homogeneity criterion (assessed by a built-in regional homogeneity test), which requires {{that in a}} pooling group the distributions of extremes are identical after scaling by the at-site mean; and (ii) the 5 T rule, which sets the minimum number of stations {{to be included in}} a pooling group for estimation of a quantile corresponding to return period T. The similarity of sites is evaluated in terms of climatological and geographical site characteristics. We carry out a series of sensitivity analyses by means of Monte Carlo simulations in order to explore the importance of the individual site attributes, including hybrid <b>pooling</b> <b>schemes</b> that combine both types of the site attributes with different relative weights. We conclude that in a dense network of precipitation stations in the Czech Republic (on average 1 station in a square of about 20 &times; 20 km), the actual distance between the sites plays the most important role in determining the similarity of probability distributions of heavy precipitation. There are, however, differences between the optimum <b>pooling</b> <b>schemes</b> depending on the duration of the precipitation events. While in the case of 1 -day precipitation amounts the <b>pooling</b> <b>scheme</b> based on the geographical proximity of sites outperforms all hybrid schemes, for multi-day amounts the inclusion of climatological site characteristics (although with much lower weights compared to the geographical distance) enhances the performance of the <b>pooling</b> <b>schemes.</b> This finding is in agreement with the climatological expectation since multi-day heavy precipitation events are more closely linked to some typical precipitation patterns over central Europe (related e. g. to the varied roles of Atlantic and Mediterranean influences) while the dependence of 1 -day extremes on climatological characteristics such as mean annual precipitation is much weaker. The findings of the paper show a promising perspective for an application of the ROI methodology in evaluating outputs of regional climate models with high resolution: the <b>pooling</b> <b>schemes</b> might serve for defining weighting functions, and the large spatial variability in the grid-box estimates of high quantiles of precipitation amounts may efficiently be reduced...|$|R
40|$|We {{introduce}} a parametric form of pooling, {{based on a}} Gaussian, which can be optimized alongside the features in a single global objective function. By contrast, existing <b>pooling</b> <b>schemes</b> are based on heuristics (e. g. local maximum) and have no clear link to the cost function of the model. Furthermore, the variables of the Gaussian explicitly store location information, distinct from the appearance captured by the features, thus providing a what/where decomposition of the input signal. Although the differentiable <b>pooling</b> <b>scheme</b> can be incorporated {{in a wide range}} of hierarchical models, we demonstrate it in the context of a Deconvolutional Network model (Zeiler et al. [22]). We also explore a number of secondary issues within this model and present detailed experiments on MNIST digits. 1...|$|R
40|$|Pooling {{techniques}} commonly {{are used}} to increase the throughput of samples used for screening purposes. While the advantages of such techniques are increased analytical efficiency and cost savings, the sensitivity of measurements decreases because it is inversely proportional {{to the number of}} samples in the pools. Consequently, uncertainties in estimates of dose and risk which are {{based on the results of}} pooled samples increase as the number of samples in the pools increases in all applications. However, sensitivities may not be seriously degraded, for example, in urinalysis, if the samples in the pools are of known time duration, or if the fraction of some attribute of the grab urine samples to that in a 24 -hour composite is known (e. g., mass, specific gravity, creatinine, or volume, per 24 -h interval). This paper presents square and cube <b>pooling</b> <b>schemes</b> that greatly increase throughput and can considerably reduce analytical costs (on a sample basis). The benefit-cost ratios for 5 {times} 5 square and 5 {times} 5 {times} 5 cube <b>pooling</b> <b>schemes</b> are 2. 5 and 8. 3, respectively. Three-dimensional and higher arrayed <b>pooling</b> <b>schemes</b> would result in even greater economies; however, significant improvements in analytical sensitivity are required to achieve these advantages. These are various other considerations for designing a <b>pooling</b> <b>scheme,</b> where the number of dimensions and of samples in the optimum array are influenced by: (1) the minimal detectable amount (MDA) of the analytical processes, (2) the screening dose-rate requirements, (3) the maximum masses or volumes of the composite samples that can be analyzed, (4) the information already available from results of composite analysis, and (5) the ability of an analytical system to guard against both false negative and false positive results. Many of these are beyond the scope of this paper but are being evaluated...|$|R
50|$|An Australian Wheat Board, {{comprising}} the Prime Minister and a Minister from each wheat growing state is created under the War Precautions Act 1914 to administer a wheat <b>pooling</b> <b>scheme.</b> The scheme {{is designed to}} assist wheat growers and ensure appropriate management of vital foodstuff during World War I.|$|R
40|$|Pooled Genomic Indexing (PGI) {{is a novel}} {{method for}} {{physical}} mapping of clones onto known macromolecular sequences. PGI is carried out by pooling arrayed clones, generating shotgun sequence reads from pools and by comparing the reads against a reference sequence. If two reads from two di#erent pools match the reference sequence at a close distance, they are both assigned (deconvoluted) to the clone {{at the intersection of}} the two pools and the clone is mapped onto the region of the reference sequence between the two matches. A probabilistic model for PGI is developed, and several <b>pooling</b> <b>schemes</b> are designed and analyzed. The probabilistic model and the <b>pooling</b> <b>schemes</b> are validated in simulated experiments where 625 rat BAC clones and 207 mouse BAC clones are mapped onto homologous human sequence...|$|R
40|$|International audienceThe paper compares {{different}} approaches to regional frequency analysis with the main focus on {{the implementation of the}} region-of-influence (ROI) technique for the modelling of probabilities of heavy precipitation amounts {{in the area of the}} Western Carpathians. Unlike the conventional regional frequency analysis where the at-site design values are estimated within a fixed pooling group (region), the ROI approach as a specific alternative to focused pooling techniques makes use of flexible pooling groups, i. e. each target site has its own group of sufficiently similar sites. In this paper, various ROI <b>pooling</b> <b>schemes</b> are constructed as combinations of different alternatives of sites' similarity (pooling groups defined according to climatological characteristics and geographical proximity of sites, respectively) and pooled weighting factors. The performance of the ROI <b>pooling</b> <b>schemes</b> and statistical models of conventional (regional and at-site) frequency analysis is assessed by means of Monte Carlo simulation studies for precipitation annual maxima for the 1 -day and 5 -day durations in Slovakia. It is demonstrated that a) all the frequency models based on the ROI method yield estimates of growth curves that are superior to the standard regional and at-site estimates at most individual sites, and b) the selection of a suitable ROI <b>pooling</b> <b>scheme</b> should be adjusted to the dominant character of the formation of heavy precipitation...|$|R
50|$|Softcat has a 'Green Team' {{managed by}} {{chairman}} Martin Hellawell, which has implemented energy efficient sensor lighting, tea bag recycling {{and a car}} <b>pool</b> <b>scheme.</b> Employees use a fleet of energy efficient 'car pool' cars to attend meetings. Its activity was featured on a Channel 4 documentary covering green credentials of UK businesses.|$|R
30|$|In FNA, the {{resource}} <b>pooling</b> <b>scheme</b> is proposed {{to manage the}} multi-dimensional resources in a centralized manner. Multi-dimensional resource management is processed in the CPE with different optimization goals for different deployment scenarios. A uniform resource allocation strategy can {{take full advantage of}} centralized optimization that can improve {{the resource}} and energy efficiency, where [9] have already provided some results.|$|R
50|$|Spectrum pooling is a {{spectrum}} management strategy in which multiple radio spectrum users can coexist {{within a single}} allocation of radio spectrum space. One use of this technique is for primary users of {{a spectrum}} allocation {{to be able to}} rent out use of unused parts of their allocation to secondary users. Spectrum <b>pooling</b> <b>schemes</b> generally require cognitive radio techniques to implement them.|$|R
5000|$|The {{original}} LNP database {{contract was}} granted in 1996. The number <b>pooling</b> <b>scheme</b> relies on LNP as {{it relies on}} carriers to return blocks of mostly unused numbers. The thousand-number blocks being returned to the pool may be [...] "contaminated" [...] with up to a hundred working numbers which must be ported to a block which the carrier intends to keep.|$|R
40|$|Most {{successful}} {{deep learning}} models for action recognition generate predictions for short video clips, which are later aggregated into a longer time-frame action descriptor by computing a statistic over these predictions. Zeroth (max) or first order (average) statistic are commonly used. In this paper, we explore {{the benefits of}} using second-order statistics. Specifically, we propose a novel end-to-end learnable action <b>pooling</b> <b>scheme,</b> temporal correlation <b>pooling,</b> that generates an action descriptor for a video sequence by capturing {{the similarities between the}} temporal evolution of per-frame CNN features across the video. Such a descriptor, while being computationally cheap, also naturally encodes the co-activations of multiple CNN features, thereby providing a richer characterization of actions than their first-order counterparts. We also propose higher-order extensions of this scheme by computing correlations after embedding the CNN features in a reproducing kernel Hilbert space. We provide experiments on four standard and fine-grained action recognition datasets. Our results clearly demonstrate the advantages of higher-order <b>pooling</b> <b>schemes,</b> achieving state-of-the-art performance...|$|R
40|$|A 128 -member {{specimen}} <b>pooling</b> <b>scheme</b> for acute HIV infection (AHI) detection {{was evaluated}} using 21 AHI specimens (range, 1, 520 to 500, 000 copies/ml) previously identified by RNA testing of 16 -member plasma pools. HIV- 1 RNA was detectable in 128 -member pools for all 21 specimens; however, one pool created from a specimen with 1, 827 copies/ml was nonreactive {{in one of}} three replicates...|$|R
30|$|A {{framework}} for a hybrid method for videos transmitted over {{long term evolution}} (LTE) networks is proposed in[190]. It suggests to include parameters from packet layer (packet loss rate, packet size), bitstream layer (frame error, frame duration), and media layer (blurring, blocking) for estimation of the quality. However, a suitable <b>pooling</b> <b>scheme</b> to integrate these parameters into a quality indication value remains as a future work.|$|R
50|$|During {{the latter}} part of 1992 it became clear that any new scheme would require the joint {{involvement}} of the insurance industry and government. Following extensive dialogue, a suitable structure emerged and the details of the <b>Pool</b> Re <b>scheme</b> were developed. The <b>Pool</b> Re <b>scheme</b> began operations in 1993 and has subsequently been involved in claims arising from thirteen separate terrorism incidents covering losses of over Â£600 million.|$|R
40|$|Discovery of rare {{mutations}} in populations requires methods, such as TILLING (for Targeting Induced Local Lesions in Genomes), for processing and analyzing many individuals in parallel. Previous TILLING protocols employed enzymatic or physical discrimination of heteroduplexed from homoduplexed target DNA. Using mutant populations of rice (Oryza sativa) and wheat (Triticum durum), {{we developed a}} method based on Illumina sequencing of target genes amplified from multidimensionally pooled templates representing 768 individuals per experiment. Parallel processing of sequencing libraries was aided by unique tracer sequences and barcodes allowing flexibility in the number and pooling arrangement of targeted genes, species, and <b>pooling</b> <b>scheme.</b> Sequencing reads were processed and aligned to the reference to identify possible single-nucleotide changes, which were then evaluated for frequency, sequencing quality, intersection pattern in pools, and statistical relevance to produce a Bayesian score with an associated confidence threshold. Discovery was robust both in rice and wheat using either bidimensional or tridimensional <b>pooling</b> <b>schemes.</b> The method compared favorably with other molecular and computational approaches, providing high sensitivity and specificity. Â© 2011 American Society of Plant Biologists...|$|R
40|$|The region-of-influence (ROI) {{approach}} is implemented for modelling the probabilities of heavy 1 -day and 5 -day precipitation amounts in the Czech Republic. Compared {{to the previous}} study for Slovakia (GaÃ¡l et al., 2008), an improved ROI methodology that makes use of a regional homogeneity test for assigning sites to pooling groups, is applied. Two basically different approaches to forming the pooling groups in which groups of sites are gradually built up and cut down, respectively, are combined. A sensitivity analysis, which examines {{the performance of the}} ROI models after changing the set of input site attributes that serve for determining the sites' similarity, is carried out. Finally, several frequency models that include the ROI <b>pooling</b> <b>schemes,</b> a conventional model based on fixed regions, and an at-site analysis are compared by means of Monte Carlo simulations. We conclude that, regardless of the duration of precipitation, the ROI <b>pooling</b> <b>scheme</b> based on the actual proximity of sites (latitude and longitude) outperforms the other frequency models in terms of the root mean square error of the growth curves...|$|R
40|$|Twitter, or {{the world}} of 140 {{characters}} poses serious challenges to the efficacy of topic models on short, messy text. While topic mod-els such as Latent Dirichlet Allocation (LDA) {{have a long history}} of successful application to news articles and academic abstracts, they are often less coherent when applied to microblog content like Twitter. In this paper, we investigate methods to improve topics learned from Twitter content without modifying the basic machin-ery of LDA; we achieve this through various <b>pooling</b> <b>schemes</b> that aggregate tweets in a data preprocessing step for LDA. We empir-ically establish that a novel method of tweet pooling by hashtags leads to a vast improvement in a variety of measures for topic co-herence across three diverse Twitter datasets in comparison to an unmodified LDA baseline and a variety of <b>pooling</b> <b>schemes.</b> An additional contribution of automatic hashtag labeling further im-proves on the hashtag pooling results for a subset of metrics. Over-all, these two novel schemes lead to significantly improved LDA topic models on Twitter content...|$|R
50|$|The most {{important}} {{benefit of the}} land <b>pooling</b> <b>scheme</b> is that developed plots with more amenities are returned to the original landowner. The market price of the developed plot will have increased multi-fold and the plot is expected to become more valuable {{as compared to the}} value of the landowner's original land. The landowner also has options to participate in a number of economic activities and enterprises in the Krushi Samruddhi Kendra.|$|R
30|$|This {{difference}} in the way pooling among time or frequency affects performance has no obvious justification, but we can consider intuitively why pooling as performed in image processing does not work as expected with acoustic spectrograms. In fact, as CNNs were widely adopted first in image processing, pooling is a function that makes much more sense in that domain. Downsampling an image would still maintain the overall shape of the object to be recognized, whereas this is hard to imagine happening in acoustic spectrograms. While this is not in the scope of this work, CNNs for acoustic signal processing might require a pooling function of their own. To illustrate this, imagine downsampling a black-and-white image of a circle or a square. Since the edges of this figure are adjacent, traditional <b>pooling</b> <b>schemes</b> make sense. However, with a note in a phone ringtone as seen in Fig. 2, this does not stand. Harmonic sounds have very specific rules in the spectrum domain, while they are still continuous in the traditional sense in time. In fact, this is exactly what the results show. Traditional pooling in frequency has negative effects as the pooling rules in acoustic spectrograms and in images are different. This opens the door for future investigations of more appropriate <b>pooling</b> <b>schemes</b> for acoustic spectrograms.|$|R
40|$|Most popular deep {{learning}} based models for action recognition {{are designed to}} generate separate predictions within their short temporal windows, which are often aggregated by heuristic means to assign an action label to the full video segment. Given that not all frames from a video characterize the underlying action, <b>pooling</b> <b>schemes</b> that impose equal importance to all frames might be unfavorable. In an attempt towards tackling this challenge, we propose a novel <b>pooling</b> <b>scheme,</b> dubbed SVM <b>pooling,</b> based {{on the notion that}} among the bag of features generated by a CNN on all temporal windows, {{there is at least one}} feature that characterizes the action. To this end, we learn a decision hyperplane that separates this unknown yet useful feature from the rest. Applying multiple instance learning in an SVM setup, we use the parameters of this separating hyperplane as a descriptor for the video. Since these parameters are directly related to the support vectors in a max-margin framework, they serve as robust representations for pooling of the CNN features. We devise a joint optimization objective and an efficient solver that learns these hyperplanes per video and the corresponding action classifiers over the hyperplanes. Showcased experiments on the standard HMDB and UCF 101 datasets demonstrate state-of-the-art performance...|$|R
30|$|The {{vision of}} a future {{transport}} for Europe anticipates a societal transformation towards a sustainable mobility characterised {{by a combination of}} changes of perspectives, values and preferences as well as sharing as new practice of use and multi-level governance. The mobility concept described tries {{to bridge the gap between}} eco-innovation and shared sustainable mobility. While the development of low emissions vehicles (low-energy and material-efficient) requires investment in R&D and infrastructure deployment (e.g., charging stations), the establishment of sharing and <b>pooling</b> <b>schemes</b> available across Europe is dependent on changes of behaviour.|$|R
30|$|The idea of {{the impact}} of distortions on NSS has been used in[104] for {{prediction}} of video quality where each frame of the video is decomposed into a Laplacian pyramid of a number of subbands. Intra-subband statistics including mean, variance, skewness, kurtosis, energy, entropy, and inter-subband statistics, namely, Jensen Shannon divergence, SSIM, and smoothness are computed. A Minkowski <b>pooling</b> <b>scheme</b> is adopted to yield a single value out of the aforementioned statistics. The proposed method is reported to perform better than some FR metrics while tested on the LIVE video quality database.|$|R
40|$|Fuelled by {{the drive}} to {{complete}} the Human Genome Project, many laboratories have developed new methods of screening clone libraries. From PCR-based strategies to <b>pooling</b> <b>schemes</b> and increased automation, the tedious task of library screening has become less labour-intensive and more cost-efficient. Currently, two main screening methods dominate: hybridization and polymerase chain reaction (PCR). In the following article, we present {{a brief overview of}} hybridization and PCR-based screening of yeast and bacterial libraries. Multi-faceted approaches combining different techniques, as well as less frequently employed methods such as fingerprinting are also described...|$|R
40|$|Abstractâ€”We {{consider}} a novel group testing procedure, termed semi-quantitative group testing, {{motivated by a}} class of problems arising in genome sequence processing. Semi-quantitative group testing (SQGT) is a non-binary <b>pooling</b> <b>scheme</b> that {{may be viewed as}} a combination of an adder model followed by a quantizer. For the new testing scheme we define the capacity and evaluate the capacity for some special choices of parameters using information theoretic methods. We also define a new class of disjunct codes suitable for SQGT, termed SQ-disjunct codes. We also provide both explicit and probabilistic code construction methods for SQGT with simple decoding algorithms. I...|$|R
