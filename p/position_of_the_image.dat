80|10000|Public
25|$|The focus spread {{is related}} to the depth of focus. Ray (2000, 56) gives two {{definitions}} of the latter. The first is the tolerance of the <b>position</b> <b>of</b> <b>the</b> <b>image</b> plane for which an object remains acceptably sharp; the second is that the limits of depth of focus are the image-side conjugates of the near and far limits of DOF. With the first definition, focus spread and depth of focus are usually close in value though conceptually different. With the second definition, focus spread and depth of focus are the same.|$|E
2500|$|As {{mentioned}} on a brass plaque {{that covered}} the stone plaque, the obliquity of the ecliptic was 23°28'40".69 in 1744. From 1745 to 1791, Le Monnier visited Saint-Suplice at each summer solstice and, focusing the light with a lens fixed to the opening in the stained-glass window so as to produce a sharp image of the sun on the floor, noted the exact <b>position</b> <b>of</b> <b>the</b> <b>image</b> at noon. From these observations, he calculated {{a variation of the}} obliquity of 45" [...] per century (the exact figure is 46".85 per century).|$|E
60|$|The {{apparatus}} {{consists of}} three parts, A, B, and C. A is rigidly fixed; it contains the dark slide and the contrivances by which the <b>position</b> <b>of</b> <b>the</b> <b>image</b> can be viewed; the eye-hole, e, already mentioned, being part of A. B is a travelling carriage that holds the lens, and is connected by bellows-work with A. In my apparatus it is pushed out and in, and clamped where desired, but {{it ought to be}} moved altogether by pinion and rack-work.[24] The lens I use is a I B Dallmeyer. Its focal length is appropriate {{to the size of the}} instrument, and I find great convenience in a lens of wide aperture when making the adjustments, as I then require plenty of light; but, as to the photography, the smaller the aperture the better. The hole in my stop is only two-tenths of an inch in diameter, and I believe one-tenth would be more suitable.|$|E
40|$|Abstract. The {{equations}} giving <b>the</b> <b>position</b> <b>of</b> <b>the</b> <b>images</b> <b>of</b> a {{point source}} by a rotating point lens are derived by a new, elementary method. It is shown that only two <b>of</b> <b>the</b> three <b>images</b> are visible. It {{is argued that}} <b>the</b> projection <b>of</b> <b>the</b> angular momentum <b>of</b> <b>the</b> lens star on the lens plane can be measured if the lens is a rapidly rotating early type star. This is achieved by performing a series of astrometric measurements <b>of</b> <b>the</b> <b>position</b> <b>of</b> <b>the</b> <b>images...</b>|$|R
5000|$|... #Caption: The Type Ib {{supernova}} Supernova 2008D in galaxy NGC 2770, {{shown in}} X-ray (left) and visible light (right), at <b>the</b> corresponding <b>positions</b> <b>of</b> <b>the</b> <b>images.</b> NASA image.|$|R
50|$|A Buddha {{image in}} Thailand {{typically}} refers to three-dimensional stone, wood, clay, or metal cast <b>images</b> <b>of</b> <b>the</b> Buddha. While {{there are such}} figures in all regions where Buddhism is commonly practiced, the appearance, composition and <b>position</b> <b>of</b> <b>the</b> <b>images</b> vary greatly from country to country.|$|R
5000|$|The {{image to}} the right shows the real case. The <b>position</b> <b>of</b> <b>the</b> <b>image</b> points [...] and [...] cannot be {{measured}} exactly. The reason {{is a combination of}} factors such as ...|$|E
50|$|Specular {{reflection}} forms images. Reflection from a {{flat surface}} forms a mirror image, {{which appears to be}} reversed from left to right because we compare the image we see to what we would see if we were rotated into the <b>position</b> <b>of</b> <b>the</b> <b>image.</b> Specular reflection at a curved surface forms an image which may be magnified or demagnified; curved mirrors have optical power. Such mirrors may have surfaces that are spherical or parabolic.|$|E
5000|$|... #Caption: [...] Top: The {{formation}} of a real image using a convex lens. Bottom: The {{formation of}} a real image using a concave mirror. In both diagrams, f is the focal point, O is the object, and I is the image. Solid blue lines indicate light rays. It {{can be seen that}} the image is formed by actual light rays and thus can form a visible image on a screen placed at the <b>position</b> <b>of</b> <b>the</b> <b>image.</b>|$|E
40|$|The stereo {{analysis}} method {{is similar to}} the human visual system. Due to the way our eyes are positioned and controlled, our brains usually receive similar images of a scene taken from nearby points <b>of</b> <b>the</b> same horizontal level. Therefore <b>the</b> relative <b>position</b> <b>of</b> <b>the</b> <b>images</b> <b>of</b> an object will differ in the two eyes. Our brains are capable of measuring this difference and thus estimating the depth. Stereo analysis tries to imitate this principle...|$|R
40|$|This paper {{contains}} the general data reduction methods used in {{processing the data}} from the Carlsberg Meridian Telescope CCD Drift Scan Survey. An efficient method to calibrate the fluctuations in <b>the</b> <b>positions</b> <b>of</b> <b>the</b> <b>images</b> caused by atmospheric turbulence is described. The external accuracy achieved is 36 mas in right ascension and declination. A description <b>of</b> <b>the</b> recently released catalogue is given. Comment: 13 pages 11 Figures (PS) Accepted for publication in A&A. The catalogue can be found at [URL]...|$|R
40|$|We {{study by}} {{phase-shift}} methods <b>the</b> birefringence properties <b>of</b> total {{reflection of a}} light beam at the separation plane between two isotropic homogeneous media. This includes the Goos-Hänchen longitudinal effect in wich a source of unpolarized light is split into two images, each of them linearly polarized, {{as well as the}} transverse shift recently investigated experimentally by Imbert, where the effect is between left and right circular polarizations. We give a general simple method for determining <b>the</b> polarizations and <b>positions</b> <b>of</b> <b>the</b> <b>images...</b>|$|R
50|$|The focus spread {{is related}} to the depth of focus. Ray (2000, 56) gives two {{definitions}} of the latter. The first is the tolerance of the <b>position</b> <b>of</b> <b>the</b> <b>image</b> plane for which an object remains acceptably sharp; the second is that the limits of depth of focus are the image-side conjugates of the near and far limits of DOF. With the first definition, focus spread and depth of focus are usually close in value though conceptually different. With the second definition, focus spread and depth of focus are the same.|$|E
5000|$|As {{mentioned}} on a brass plaque {{that covered}} the stone plaque, the obliquity of the ecliptic was 23°28'40".69 in 1744. From 1745 to 1791, Le Monnier visited Saint-Suplice at each summer solstice and, focusing the light with a lens fixed to the opening in the stained-glass window so as to produce a sharp image of the sun on the floor, noted the exact <b>position</b> <b>of</b> <b>the</b> <b>image</b> at noon. From these observations, he calculated {{a variation of the}} obliquity of 45" [...] per century (the exact figure is 46".85 per century).|$|E
5000|$|A quite {{different}} mechanism operates in hyperacuity, whose quintessential example {{and the one}} for which the word was initially coined, [...] is vernier acuity: alignment of two edges or lines can be judged with a precision five or ten times better than acuity. A sophisticated circuitry in the brain identifies {{the location of a}} visual feature by assessing the “center of gravity” of the light over several receptors, a task that can be accomplished with much higher precision than the resolution limit set by the receptor spacing. In computer graphics the phrase “sub-pixel resolution” is sometimes used in discussions of anti-aliasing and geometrical superresolution. Though what is in fact involved is not resolution (is it one or two? - a qualitative distinction) but localization (exactly where? - a quantitative judgment) it captures the process. When an image spreads across several pixels, each with graded intensity response but only a single spatial value, the <b>position</b> <b>of</b> <b>the</b> <b>image</b> center can be located more exactly than the width of the pixel, much like the mean of a histogram can be calculated to a fraction of the bin width.|$|E
5000|$|... #Caption: Top: <b>The</b> {{formation}} <b>of</b> {{a virtual}} image using a diverging lens. Bottom: <b>The</b> formation <b>of</b> a virtual image using a convex mirror. In both diagrams, f is the focal point, O {{is the object}} and I is <b>the</b> <b>image,</b> shown in grey. Solid blue lines indicate light rays. It {{can be seen that}} the light rays appear to emanate from <b>the</b> virtual <b>image</b> but do not actually exist at <b>the</b> <b>position</b> <b>of</b> <b>the</b> virtual <b>image.</b> Thus an image cannot be seen by placing a screen at <b>the</b> <b>position</b> <b>of</b> <b>the</b> virtual <b>image.</b>|$|R
40|$|ABSTRACTThis case {{refers to}} a 17 -year old patient who {{underwent}} osteosynthesis <b>of</b> <b>the</b> femur due to middle third fracture following a traffic accident. During the post-op, the patient showed weakness and hypoesthesia <b>of</b> <b>the</b> upper left limb that lead to a diagnosis of brachial plexus neuropraxia. The underlying triggering factor identified was inadequate <b>positioning</b> <b>of</b> <b>the</b> <b>image</b> intensifier during <b>the</b> course <b>of</b> surgery, with extreme abduction <b>of</b> <b>the</b> limb. The evolution and management <b>of</b> <b>the</b> case is shown, together with a review about this perioperative complication...|$|R
40|$|<b>The</b> {{multiple}} <b>images</b> <b>of</b> lensed quasars {{provide evidence}} on <b>the</b> mass distribution <b>of</b> <b>the</b> lensing galaxy. The lensing invariants are constructed from <b>the</b> <b>positions</b> <b>of</b> <b>the</b> <b>images,</b> their parities and their fluxes. They depend only on <b>the</b> structure <b>of</b> <b>the</b> lensing potential. The simplest is the magnification invariant, which is <b>the</b> sum <b>of</b> <b>the</b> signed magnifications <b>of</b> <b>the</b> <b>images.</b> Higher order configuration invariants are <b>the</b> sums <b>of</b> products <b>of</b> <b>the</b> signed magnifications with {{positive or negative}} powers <b>of</b> <b>the</b> <b>position</b> coordinates <b>of</b> <b>the</b> <b>images.</b> We consider <b>the</b> case <b>of</b> <b>the</b> four and five image systems produced by elliptical powerlaw galaxies with / / (x 2 + y 2 q Γ 2) fi= 2. This paper provides simple contour integrals for evaluating all their lensing invariants. For practical evaluation, this offers considerable advantages over the algebraic methods used previously. The magnification invariant is exactly B = 2 =(2 Γ fi) for the special cases fi = 0; 1 and 4 = 3; for other values [...] ...|$|R
30|$|Thus, {{the minimum}} χ 2 {{corresponds}} to the Z <b>position</b> <b>of</b> <b>the</b> <b>image.</b>|$|E
3000|$|... [*]Brightness constancy: {{although}} the 2 D <b>position</b> <b>of</b> <b>the</b> <b>image</b> discriminant characteristics, such as brightness, color, etc., may change, {{they keep their}} value constant over time. Algorithms for estimating optical flow exploit this assumption in various ways to compute a velocity field that describes the horizontal and vertical motions of every pixel in the image.|$|E
40|$|This paper {{discusses}} {{the issues involved}} in measurements made with high-precision multichannel photometers that use cryogenically cooled detectors and optical fibers to bring {{the light from the}} star images to the dewar and then to the detectors. The use of optical fibers introduces photometric errors. Measurements are presented of the errors caused by small changes in the <b>position</b> <b>of</b> <b>the</b> <b>image</b> on the fiber...|$|E
40|$|Abstract — This paper {{presents}} {{a method for}} vision navigation of robot by road recognition based on image processing. By taking advantages <b>of</b> <b>the</b> unique structure in road <b>images,</b> <b>the</b> square <b>images</b> on road can be scanned while the robot is moving. In this paper we focused on <b>the</b> pixel <b>position</b> <b>of</b> <b>the</b> <b>images</b> <b>of</b> <b>the</b> corners <b>of</b> <b>the</b> two squares. Large scale experiments on road sequences shows the road detection method is four coordinate system, road types and scenarios. Finally, the proposed method provides highest road detection accuracy when compared to state-of-the-art methods...|$|R
40|$|Strong {{gravitational}} lensing is {{an important}} tool to probe the universe. In <b>the</b> theoretical analysis <b>of</b> gravitational lensing, {{it is assumed that}} continuous density profile can correctly describe the lens galaxy. But in fact this assumption has never been rigorously tested. In this paper, we discuss this issue, and point out that if we use discrete density profile to model the lens galaxy, then <b>the</b> <b>position</b> <b>of</b> <b>the</b> <b>images</b> does not change, but the magnification will be increased. Strongly lensed gravitational waves could test this conclusion in the future. Comment: 3 pages. Comments welcome...|$|R
5000|$|A 2009 {{article in}} Artforum about Murata's art noted that [...] "the {{artificial}} palette, flashing lights, abstract patterns, and coarsely pixelated texture of Pink Dot and other works by Murata locate him in <b>the</b> tradition <b>of</b> electronic animation pioneered by John Whitney and Lillian Schwartz. But while his predecessors were testing the computer's ability to replicate <b>the</b> cinematic illusion <b>of</b> movement, Murata uses <b>the</b> tools <b>of</b> consumer-level film-editing software to undo that illusion, with trails of pixel dust tracking <b>the</b> changing <b>positions</b> <b>of</b> <b>the</b> <b>image</b> from frame to frame.".|$|R
30|$|Past {{studies have}} used 2 D {{radiographic}} photos {{to analyze the}} condylar position; however, difficulties arose due to overlapping images of both condyles and the <b>position</b> <b>of</b> <b>the</b> <b>image</b> changing with {{the position of the}} patient. However, since the introduction of CT, condyles could be observed without overlap, and the position of the patient had become irrelevant. As a result, analytical errors have reduced over time and more accurate analyses have become possible.|$|E
40|$|Image {{reconstruction}} from Fourier intensity through phase retrieval {{was investigated}} when the intensity was contaminated with Poisson noise. Although different initial conditions and/or {{the instability of}} the iterative phase retrieval process led to different reconstructed images, {{we found that the}} distribution of the resulting images in both the object and Fourier spaces formed spherical shell structures. Averaging of the images over the distribution corresponds to the <b>position</b> <b>of</b> <b>the</b> <b>image</b> at the sphere center...|$|E
40|$|The fuzzy {{representation}} of the edges has been widely studied in different works. Generally, for each pixel, the authors use membership degrees lin-early proportional to {{the magnitude of the}} gradient at that <b>position</b> <b>of</b> <b>the</b> <b>image.</b> This would be equiv-alent to using a triangular membership functions on the gradient magnitude. In this work we study the use of parametric functions in the transformation of the gradient images into fuzzy sets. The results obtained with different parametrical functions are studied using Baddeley’s Delta Metric...|$|E
40|$|In {{this study}} we present a two-step map/reduce {{framework}} to stitch satellite mosaic <b>images.</b> <b>The</b> proposed system enable recognition and extraction of objects whose parts falling in separate satellite mosaic images. However {{this is a time}} and resource consuming process. <b>The</b> major aim <b>of</b> <b>the</b> study is improving <b>the</b> performance <b>of</b> <b>the</b> <b>image</b> stitching processes by utilizing big data framework. To realize this, we first convert <b>the</b> <b>images</b> into bitmaps (first mapper) and then String formats in <b>the</b> forms <b>of</b> 255 s and 0 s (second mapper), and finally, find the best possible matching <b>position</b> <b>of</b> <b>the</b> <b>images</b> by a reduce function...|$|R
40|$|The paper {{describes}} <b>the</b> use <b>of</b> {{an optical}} tracking method for superimposing computer-generated images oriented and positioned in 3 D to augment a real scene. In a medical scenario, a physician may view <b>the</b> <b>images</b> created by an ultrasound device {{directly related to}} the patient. Typically, <b>the</b> <b>position</b> <b>of</b> <b>the</b> <b>images</b> or <b>the</b> <b>position</b> <b>of</b> <b>the</b> pysician changes almost always and <b>the</b> mapping <b>of</b> <b>images</b> has to be recalculated. The optical tracking method in combination with artifical landmarks, is used to get the information about how to transform <b>the</b> superimposed <b>images.</b> After segmenting and tracking the landmarks <b>the</b> perspective transformation <b>of</b> <b>the</b> ultrasonic <b>image</b> can be determined...|$|R
5000|$|Also, by {{expressing the}} fourth-order {{correction}} in the Taylor expansion above as (aCvZ0) / (Z4), where a is some constant, we can define Z0 as <b>the</b> <b>position</b> <b>of</b> <b>the</b> dynamical <b>image</b> plane and obtain ...|$|R
40|$|The aim of {{this study}} was to {{determine}} size, shape and <b>position</b> <b>of</b> <b>the</b> <b>image</b> layer by evaluation of the radiographic image formation in different anatomic positions. A customized phantom was made of a rectangular acrylic plate measuring 14 cm² and 0. 3 cm thick, with holes spaced 0. 5 cm away and arranged in rows and columns. Each column was separately filled with 0. 315 cm diameter metal spheres to acquire panoramic radiographs using the Orthopantomograph OP 100 unit. The customized phantom was placed on the mental support of the device, with its top surface kept parallel to the horizontal plane, and was radiographed at three different heights from the horizontal plane, i. e., the orbital, occlusal and mandibular symphysis levels. The images of the spheres were measured using a digital caliper to locate the image layer. The recorded data were analyzed statistically by the Student'-t test, ANOVA and Tukey' test (?= 0. 05). When the image size of spheres in horizontal and vertical axes were compared, statistically significant differences (p 0. 05). The methodology used in this determined the precise size, shape and <b>position</b> <b>of</b> <b>the</b> <b>image</b> layer and differences in magnification were observed in both the horizontal and vertical axes...|$|E
40|$|High-resolution {{experimental}} {{data for the}} low-energy electron diffraction fine structure in W(110) are analyzed using a one-dimensional model potential barrier used previously for W(001). The measured fine structure is reproduced very well for both surfaces, and the optimum barriers are similar. The <b>position</b> <b>of</b> <b>the</b> <b>image</b> plane in W(110), however, is approximately 0. 2 – 0. 3 a. u. farther from the outermost layer of atoms than in W(001). This is in good agreement {{with the results of}} self-consistent electronic-structure calculations reported by Jepsen and Jones in the preceding paper...|$|E
40|$|The density-functional {{theory is}} applied to {{calculate}} the self-consistent electron density distribution and the surface potential at metal surfaces with different electron densities. The surface potential yields the correct long-range image potential, since a nonlocal exchange-correlation energy functional is used. It is shown that within this scheme {{it is possible to}} calculate the <b>position</b> <b>of</b> <b>the</b> <b>image</b> plane {{as a function of the}} bulk density, the influence of the image potential on the binding energy of the image potential states, and the correct behavior of the interface barrier height for metal–metal tunneling electrons...|$|E
3000|$|When {{the above}} formula {{is applied to}} a {{digitized}} <b>image,</b> <b>the</b> grayscale center <b>position</b> <b>of</b> <b>the</b> target <b>image</b> point can also be calculated. This is the weighted gravity method. The formula is as follows: [...]...|$|R
40|$|We combine X-ray {{magnetic}} circular dichroism (XMCD) and photoelectron emission microscopy {{to obtain}} locally resolved magnetic {{information on a}} microscopic scale. Scanning the photon energy across elemental absorption edges and recording microscopic <b>images</b> <b>of</b> <b>the</b> local secondary electron intensity for both photon helicities at each photon energy step allows to analyze local XMCD spectra at any <b>position</b> <b>of</b> <b>the</b> <b>imaged</b> area <b>of</b> <b>the</b> sample. With <b>the</b> help <b>of</b> magnetic sum-rules local quantitative information about magnetic moments can be extracted from such microspectroscopic measurements. <b>The</b> full power <b>of</b> XMCD as a spectroscopic tool is so maintained, while microscopic spatial resolution is added...|$|R
3000|$|We {{take a look}} at <b>the</b> {{exponential}} terms <b>of</b> Equation (21): <b>the</b> {{first one}} is the term for azimuth-matched filtering; the second one indicates <b>the</b> azimuth <b>position</b> <b>of</b> <b>the</b> <b>imaged</b> target as aforementioned; the third one is the range compression term, which is range dependent; the fourth one indicates the position where the target is located at in the range direction; the fifth one is the bulk RCM term for targets <b>of</b> all ranges; <b>the</b> last one is the residual phase error term, which turns out to be <b>the</b> familiar one <b>of</b> monostatic case when β = 0, h [...]...|$|R
