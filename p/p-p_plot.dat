33|23|Public
2500|$|The term [...] "probability plot" [...] {{sometimes}} refers {{specifically to}} a Q–Q plot, sometimes {{to a more}} general class of plots, and sometimes to the less commonly used <b>P–P</b> <b>plot.</b> The probability plot correlation coefficient is a quantity derived {{from the idea of}} Q–Q plots, which measures the agreement of a fitted distribution with observed data and which is sometimes used as a means of fitting a distribution to data.|$|E
5000|$|<b>P-P</b> <b>plot,</b> [...] "Probability-Probability" [...] or [...] "Percent-Percent" [...] plot; ...|$|E
50|$|A <b>P-P</b> <b>plot</b> {{can be used}} as a {{graphical}} {{adjunct to}} a tests of the fit of probability distributions, with additional lines being included on the plot to indicate either specific acceptance regions or the range of expected departure from the 1:1 line. An improved version of the <b>P-P</b> <b>plot,</b> called the SP or S-P plot, is available, which makes use of a variance-stabilizing transformation to create a plot on which the variations about the 1:1 line should be the same at all locations.|$|E
40|$|<b>P-p</b> <b>plots</b> contain all the {{information}} that is needed for scale-invariant comparisons. Indeed, Empirical Distribution Function (EDF) tests translate sample <b>p-p</b> <b>plots</b> into a single number. In this paper we characterize the set of all distinct <b>p-p</b> <b>plots</b> for two balanced sample of size n absent ties. Distributions of EDF test statistics are embedded in this set. It is thus used to derive the exact finite sample distribution of the L 1 -version of the Fisz-Cram 9 r-von Mises test. Comparing this distribution with the (known) limiting distribution shows that the latter can always be used for hypothesis testing: although for finite samples the critical percentiles of the limiting distribution differ from the exact values, this will not lead to differences in the rejection of the underlying hypothesis...|$|R
30|$|For model {{validation}} quantile- quantile (Q–Q) and probability–probability (<b>P–P)</b> <b>plots</b> are {{most commonly used}} graphical methods to assess whether the fitted model is {{in agreement with the}} given data.|$|R
30|$|Both {{cross-sectional}} and longitudinal {{analyses were}} performed. Cross-sectionally, data were visualized using boxplots and tested using histograms, <b>P–P</b> <b>plots,</b> Kolmogorov–Smirnov test, Kruskal–Wallis, a receiver operating characteristics (ROC) curve and Fisher’s exact test.|$|R
5000|$|The term [...] "probability plot" [...] {{may be used}} {{to refer}} to both of these types of plot, or the term [...] "probability plot" [...] {{may be used to}} refer {{specifically}} to a <b>P-P</b> <b>plot.</b>|$|E
50|$|In statistics, a <b>P-P</b> <b>plot</b> ({{probability}}-probability plot or percent-percent plot) is {{a probability}} plot for assessing how closely two data sets agree, which plots the two cumulative distribution functions against each other. P-P plots are vastly {{used to evaluate}} the skewness of a distribution.|$|E
50|$|As {{the above}} example illustrates, if two {{distributions}} are separated in space, the <b>P-P</b> <b>plot</b> will give very little data - {{it is only}} useful for comparing probability distributions that have nearby or equal location. Notably, it will pass through the point (1/2, 1/2) {{if and only if}} the two distributions have the same median.|$|E
50|$|<b>P-P</b> <b>plots</b> are {{sometimes}} limited to comparisons between two samples, rather than comparison {{of a sample}} to a theoretical model distribution. However, they are of general use, particularly where observations are not all modelled with the same distribution.|$|R
40|$|We derive {{the exact}} finite sample {{distribution}} of the L 1 -version of the Fisz-Cramér-von Mises test statistic (FCvM 1). We first characterize the set of all distinct sample <b>p-p</b> <b>plots</b> for two balanced samples of size n absent ties. Next, we order this set according to the corresponding value of FCvM 1. Finally, we link these values to the probabilities that the underlying <b>p-p</b> <b>plots</b> emerge. Comparing the finite sample distribution with the (known) limiting distribution shows that the latter can always be used for hypothesis testing: although for finite samples the critical percentiles of the limiting distribution differ from the exact values, this will not lead to differences in {{the rejection of the}} underlying hypothesis...|$|R
50|$|One {{use for the}} {{probability}} integral transform in statistical data analysis is to {{provide the basis for}} testing whether a set of observations can reasonably be modelled as arising from a specified distribution. Specifically, {{the probability}} integral transform is applied to construct an equivalent set of values, and a test is then made of whether a uniform distribution is appropriate for the constructed dataset. Examples of this are <b>P-P</b> <b>plots</b> and Kolmogorov-Smirnov tests.|$|R
5000|$|A <b>P-P</b> <b>plot</b> plots two {{cumulative}} distribution functions (cdfs) against each other:given two probability distributions, with cdfs [...] "F" [...] and [...] "G", it plots [...] as z ranges from [...] to [...] As a cdf has range 0,1, {{the domain of}} this parametric graph is [...] and the range is the unit square ...|$|E
5000|$|The term [...] "probability plot" [...] {{sometimes}} refers {{specifically to}} a Q-Q plot, sometimes {{to a more}} general class of plots, and sometimes to the less commonly used <b>P-P</b> <b>plot.</b> The probability plot correlation coefficient is a quantity derived {{from the idea of}} Q-Q plots, which measures the agreement of a fitted distribution with observed data and which is sometimes used as a means of fitting a distribution to data.|$|E
5000|$|Martin Bradbury Wilk, [...] (18 December 1922 - 19 February 2013) was a Canadian statistician, academic, and {{the former}} Chief Statistician of Canada. In 1965, {{together}} with Samuel Shapiro, he developed the Shapiro-Wilk test, which can indicate whether a sample of numbers would be unusual if {{it came from a}} Gaussian distribution. With Ramanathan Gnanadesikan he developed a number of important graphical techniques for data analysis, including the Q-Q plot and <b>P-P</b> <b>plot.</b>|$|E
40|$|This talk will {{describe}} some programs to fit generalized beta {{of the second}} kind, Singh-Maddala, Dagum, and lognormal distributions to data on income or indeed any other skewed variable of interest. The programs allow the key distributional parameters to vary with covariates, and also handle svy data. (The programs use features introduced to ml in version 8. 1.) To assess goodness of fit graphically, one can draw q-q and <b>p-p</b> <b>plots</b> using programs written by Nick Cox. ...|$|R
40|$|This article {{suggests}} a graphic technique that uses <b>P-P</b> <b>plots</b> {{to show the}} extent to which two groups differ on two variables. It can be used even if the variables are measured in completely different, noncomparable units. The comparison is sym-metric with respect to the variables and the groups. It reflects the differences between the groups over the full range of values of each variable. Two examples from educational testing are included; the technique is also applicable to other fields of inquiry...|$|R
40|$|This paper applies {{quantile}} {{data analysis}} to input modeling in simulation. We introduce {{the use of}} QIQ plots to identify suitable distributions fitting the data and comparison distribution <b>P-P</b> <b>plots</b> to test the fit. Two examples illustrate the utility of these quantile statistical methods for input modeling. Popular distribution fitting software often give confusing results, which is usually a set of distributions differing marginally in the test statistic value. The methods discussed in this paper {{can be used for}} further analysis of the software results. ...|$|R
50|$|As an example, {{if the two}} {{distributions}} do not overlap, say F {{is below}} G, then the <b>P-P</b> <b>plot</b> will move {{from left to right}} along the bottom of the square - as z moves through the support of F, the cdf of F goes from 0 to 1, while the cdf of G stays at 0 - and then moves up {{the right side of the}} square - the cdf of F is now 1, as all points of F lie below all points of G, and now the cdf of G moves from 0 to 1 as z moves through the support of G.|$|E
40|$|We {{propose a}} {{quantification}} of the <b>p-p</b> <b>plot</b> that assigns equal weight to all distances between the respective distributions: the surface between the <b>p-p</b> <b>plot</b> and the diagonal. This surface is labeled the Harmonic Weighted Mass (HWM) index. We introduce the diagonal-deviation (d-d) plot {{that allows the}} index to be computed exactly under all circumstances. This two-dimensional d-d plot accommodates a straightforward extension to the k-sample HWM index, with k > 2. A Monte Carlo simulation based on an example involving long-term sovereign credit ratings illustrates {{the power of the}} HWM test...|$|E
40|$|We {{propose a}} {{quantification}} of the <b>p-p</b> <b>plot</b> that assigns equal weight to all distances between the respective distributions: the surface between the <b>p-p</b> <b>plot</b> and the diagonal. This surface is labelled the Harmonic Weighted Mass (HWM) index. We introduce the diagonal-deviation (d-d) plot {{that allows the}} index to be computed exactly under all circumstances. For two balanced samples absent ties the finite sample distribution of the HWM index is derived. Simulations show that in most cases unbalanced samples and ties have little effect on this distribution. The d-d plot allows for a straightforward extension to the K-sample HWM index. As {{we have not been}} able to derive the distribution of the index for K> 2, we simulate significance tables for K= 3, [...] ., 15. An example involving economic growth rates of the G 7 countries illustrates that the HWM test can have better power than alternative Empirical Distribution Function tests. EDF test, <b>p-p</b> <b>plot,</b> power, d-d plot...|$|E
40|$|We {{analyze the}} {{dynamics}} of Chinese comparative advantage as measured by export shares and the Balassa index using 3 -digit and 4 -digit sectors for the period 1970 – 1997. We use novel tools to identify periods of rapid structural change and the persistence of comparative advantage, such as Galtonian regressions, probability-probability (<b>p-p)</b> <b>plots,</b> and the Harmonic Mass index, to supplement the usual descriptive statistical methods and mobility indicators associated with Markov transition matrices. Balassa index; distribution dynamics; Galtonian regression; Markov matrices; P-P plots; HM index...|$|R
40|$|This paper {{describes}} {{and discusses}} graphical techniques, {{based on the}} primitive empirical cumulative distribution function and on quantile (Q-Q) <b>plots,</b> percent (<b>P-P)</b> <b>plots</b> and hybrids of these, which are useful in assessing a one-dimensional sample, either from original data or resulting from analysis. Areas of application include: the comparison of samples; the comparison of distributions; the presentation of results on sensitivities of statistical methods; the analysis of collections of contrasts and of collections of sample variances; the assessment of multivariate contrasts; and the structuring of analysis of variance mean squares. Many of the objectives and techniques are illustrated by examples. 1...|$|R
50|$|After {{two years}} working at Procter & Gamble, {{he was hired}} by John Tukey to work in the nascent {{statistics}} group at Bell TelephoneLaboratories and became a department head shortly afterwards. He worked closely with Martin Wilk with whom he wrote a number of papers on graphical methods for data analysis. The most widely cited of these (Wilk and Gnanadesikan, 1968) describes the Q-q and <b>P-p</b> <b>plots,</b> which are used to compare different statistical distributions. This work arose in part out of work in speaker recognition, as {{it was found that the}} statistical distribution of energy across frequency bands was different for different speakers. His highly-cited 1977 monograph on multivariate data analysis has been translated into Japanese and Russian and a second edition was published in 1997.|$|R
40|$|We {{introduce}} generalized Probability-Probability (P-P) plots {{in order}} to study the one-sample goodness-of-fit problem and the two-sample problem, for real valued data. These plots, that are constructed by indexing with the class of closed intervals, globally preserve the properties of classical P-P plots and are distribution-free under the null hypothesis. We also define the generalized <b>P-P</b> <b>plot</b> process and the corresponding, consistent tests. The behaviour of the tests under contiguous alternatives is studied in detail; in particular, limit theorems for the generalized <b>P-P</b> <b>plot</b> processes are presented. By their structure, the tests perform very well for spike (or pulse) alternatives. We also study the finite sample properties of the tests through a simulation study. ...|$|E
40|$|When using {{incorrect}} or inaccurate signal {{models to}} perform parameter estimation on a gravitational wave signal, biased parameter estimates will in general be obtained. For a single event this bias may {{be consistent with}} the posterior, but when considering a population of events this bias becomes evident as a sag below the expected diagonal line of the <b>P-P</b> <b>plot</b> showing the fraction of signals found within a certain significance level versus that significance level. It would be hoped that recently proposed techniques for accounting for model uncertainties in parameter estimation would, to some extent, alleviate this problem. Here we demonstrate that this is indeed the case. We derive an analytic approximation to the <b>P-P</b> <b>plot</b> obtained when using an incorrect signal model to perform parameter estimation. This approximation is valid in the limit of high signal-to-noise ratio and nearly correct waveform models. We show how the <b>P-P</b> <b>plot</b> changes if a Gaussian process likelihood that allows for model errors is used to analyse the data. We demonstrate analytically and using numerical simulations that the bias is always reduced in this way. These results provide a way to quantify bias in inference on populations and demonstrate the importance of utilising methods to mitigate this bias. Comment: 11 pages, 1 figure, to appear in Phys. Rev. D; v 2 includes minor changes for consistency with accepted versio...|$|E
30|$|Data were {{subjected}} to SPSS Version 16.0 for windows (SPSS Inc., USA), and checked for normal distribution (Shapiro–Wilk’s test) and homogeneity of variances (Levene’s test) using <b>P–P</b> <b>plot</b> analysis. One-way analysis of variance (ANOVA) followed by the NP exposure for each endpoint relative Duncan’s {{test was used to}} examine the effect of the control group and significance was set at P[*]<[*] 0.05.|$|E
40|$|Magister Scientiae - MScThe {{intention}} is to draw more specific connections between certain deconvolution methods and also to demonstrate {{the application of the}} statistical theory of estimation in the presence of measurement error. A parametric methodology for deconvolution when the underlying distribution is of the Pareto form is developed. Maximum likelihood estimation (MLE) of the parameters of the convolved distributions is considered. Standard errors of the estimated parameters are calculated from the inverse Fisher’s information matrix and a jackknife method. Probability-probability (<b>P-P)</b> <b>plots</b> and Kolmogorov-Smirnov (K-S) goodnessof- fit tests are used to evaluate the fit of the posited distribution. A bootstrapping method is used to calculate the critical values of the K-S test statistic, which are not available. South Afric...|$|R
30|$|In the {{selection}} and testing of goodness of fit of the estimated parameters, the Log-likelihood statistics, the Bayesian Information Criterion (BIC) and Akaike Information Criterion (AIC) are used to choose the best model out of the candidate models. A specified likelihood of a parameter points toward a possible result. Log-likelihood forms the basis for which we selected the best fit model. It is worthwhile to take decisions {{that may lead to}} possible results if only the Log-likelihood statistics is high enough. Meanwhile, the Bayesian Information Criterion (BIC) and Akaike Information Criterion (AIC) minimize prediction error and freely estimated parameter. This work seeks to identify a model that does not over fit the data with too many parameters while simultaneously accurately modelling the data. In a model selection application, the optimal fitted model is identified by the minimum value of the BIC and AIC. Based on these tests and the above Q–Q and <b>P–P</b> <b>plots,</b> various regional models for fire occurrences and fatality are fitted.|$|R
3000|$|To test our hypotheses, we {{performed}} OLS regression analysis. We assessed {{the appropriateness of}} OLS regression assumptions of linearity, homoscedasticity and normality according to Keith (2015). The bivariate relationships between interval-scaled independent and dependent variables are linear. All other independent variables are dummy coded. Normality of residuals is assessed using normal <b>p–p</b> <b>plots</b> taken from full models (Model 4 in Tables  2, 3, 4). There is some departure from the 45 ° line, but in acceptable limits. Inspecting scatterplots of residuals obtained from full models and the independent variables indicate that the variance of error terms increases for higher values of the dependent variables. Running Breusch-Pagan tests for homoscedasticity shows that there is significant heteroscedasticity in the sample. For this reason, we use the HC 3 standard error estimator (Hayes and Cai 2007) in our regression models. Furthermore, we used bootstrapping (Efron and Tibshirani 1986) as a robustness check for our OLS regression models with 5000 drawings (Hair et al. 2014) and the bias-corrected and accelerated confidence interval (Efron 1987). The results are fairly consistent. 4 [...]...|$|R
40|$|Description Functions are {{provided}} for the density function,distribution function, quantiles and random number generation for the skew hyperbolic t-distribution. There are also functions that fit the distribution to data. There are functions for the mean, variance, skewness, kurtosis and mode of a given distribution and to calculate moments of any order about any centre. To assess goodness of fit, there are functions to generate a Q-Q plot, a <b>P-P</b> <b>plot</b> and a tail plot...|$|E
30|$|The {{first data}} set {{is given by}} Sylwia (2007) on the {{lifetime}} of a certain device. Table  2 shows the estimated parameters and their standard errors, −ℓ, A*, W*, K-S and its corresponding p-value and AIC values. Based on the figures in Table  2, {{it is clear that}} ZBOLL-GHN model provides the best fit for this data set. Figure  5 a displays the estimated pdfs of the fitted models. Figure  5 b displays the <b>P-P</b> <b>plot</b> of ZBOLL-GHN distribution and its fitted hrf. Figure  5 shows that ZBOLL-GHN distribution provides superior fit to the left-skewed data set.|$|E
30|$|To {{investigate}} {{the ability of}} individual difference factors to predict low prevalence search performance, we performed linear regression models. For all regression models, we ensured that the assumptions of the regression models were met in the following manner. Linearity was assessed through visual inspection of partial regression plots and a plot of studentized residuals against the predicted values. Homoscedasticity was assessed by visual inspection of a plot of studentized residuals versus unstandardized predicted values. Normality was assessed by visual inspection of the <b>P–P</b> <b>plot.</b> Durbin–Watson statistics were all between 2.05 and 2.19, while tolerance values ranged from 0.77 to 0.93, thus showing no violations of independence of residuals or multicollinearity.|$|E
40|$|The error {{characteristics}} of a free-space optical (FSO) channel are signiﬁcantly different from the ﬁber based optical links and thus require a deep physical understanding of the propagation channel. In particular different fog conditions greatly inﬂuence the optical transmissions and thus a channel model is required to estimate the detrimental fog effects. In this paper we shall present the probabilistic model for radiation fog from the measured data over a 80 m FSO link installed at Graz, Austria. The fog events are classiﬁed into thick fog, moderate fog, light fog and general fog based on the international code of visibility range. We applied some probability distribution functions (PDFs) such as Kumaraswamy, Johnson SB and Logistic distribution, to the actual measured optical attenuations. The performance of each distribution is evaluated by Q-Q and <b>P-P</b> <b>plots.</b> It is found that Kumaraswamy distribution is the best ﬁt for general fog, while Logistic distribution is the optimum choice for thick fog. On the other hand, Johnson S B distribution best ﬁts the moderate and light fog related measured attenuation data. The difference in these probabilistic models and the resultant variation in the received signal strength under different fog types needs {{to be considered in}} designing an efﬁcient FSO system...|$|R
40|$|In this paper, {{we propose}} a new scheme of Poincare geometry-characterized ECG {{analysis}} for cardiac disease identification. Based on reliable P-wave detection we created <b>P-P</b> Poincare <b>plot</b> applying <b>P-P</b> intervals of ECG signal. By the new geometric Poincare plot analysis, which combines R-R intervals and P-P intervals, weidentified geometric differences of normal and arrhythmia ECG databases at PhysioBank in Physionet. Poincare descriptors {{show that the}} analysis scheme can classify two ECG signals reliably. Furthermore, we discuss a cardiac disease estimation system that may be applicable to estimate the occurrence of arrhythmia in healthy person...|$|R
40|$|The {{process of}} {{constructing}} impulse-response functions (IRFs) and forecast-error variance decompositions (FEVDs) for a structural vector autoregression (SVAR) usually involves a factorization of {{an estimate of}} the error-term variance-covariance matrix V. Examining residuals from a monetary VAR, this paper finds evidence suggesting that all of the variances in V are infinite. Specifically, this study estimates alpha-stable distributions for the reduced-form error terms. The ML estimates of the residuals' characteristic exponents "alpha" range from 1. 5504 to 1. 7734, with the Gaussian case lying outside 95 percent asymptotic confidence intervals for all six equations of the VAR. Variance-stabilized <b>P-P</b> <b>plots</b> show that the estimated distributions fit the residuals well. Results for subsamples are varied, while GARCH(1, 1) filtering yields standardized shocks that are also all likely to be non-Gaussian alpha stable. When one or more error terms have infinite variance, V cannot be factored. Moreover, by Proposition 1, the reduced-form DGP cannot be transformed, using the required nonsingular matrix, into an appropriate system of structural equations with orthogonal, or even finite-variance, shocks. This result holds with arbitrary sets of identifying restrictions, including even the null set. Hence, with one or more infinite-variance error terms, structural interpretation of the reduced-form VAR within the standard SVAR model is impossible. Structural Vector Autoregression; VAR; Levy-stable Distribution; Infinite Variance; Monetary Policy Shocks; Heavy-tailed Error Terms; Factorization; Impulse Response Function; Transformability Problem...|$|R
