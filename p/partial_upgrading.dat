7|26|Public
25|$|Vapor Extraction Process (VAPEX) is an in situ technology, {{similar to}} SAGD. Instead of steam, {{hydrocarbon}} solvents are injected into an upper well to dilute bitumen and enables the diluted bitumen to flow into a lower well. It {{has the advantage}} of much better energy efficiency over steam injection, and it does some <b>partial</b> <b>upgrading</b> of bitumen to oil right in the formation. The process has attracted attention from oil companies, who are experimenting with it.|$|E
40|$|The {{transportation}} of heavy oil is a pressing problem. Various {{methods have been}} devised to mitigate the reluctance to flow of these highly dense and viscous oils. This study is focused on evaluating a case for post-production <b>partial</b> <b>upgrading</b> of heavy oil. Specifically, we analyze the impact of visbreaking, a mild thermal cracking method, on the economic and energy demands of the post-production process. Using conservative modeling techniques and principles we find significant cost and energy savings can potentially result out of visbreaking. Cost savings result {{as a consequence of}} reduced diluent usage. Even the most conservative modeling scenario under consideration exhibits significant cost savings in the form of reduced diluent usage; these savings not only offset operational costs but provide short payback periods on capital expenditures. Additionally, the lower gravity blend resulting from visbreaking can also bring about energy and cost savings in pipeline transportation and positively impact the heavy oil value chain from the producer to a refinery or regional upgrading facility. From this basic analysis of the potential of visbreaking, we can recommend investing resources to study its viability in the field. Using this analysis as a tipping off point and with a detailed look at the chemistry of the oil in question it is possible to make a very viable case for visbreaking. In a similar vein, this analysis can serve as a guide in making a case for other <b>partial</b> <b>upgrading</b> methods as well...|$|E
30|$|Improved heavy {{crude and}} bitumen {{transportation}} using pipelines {{can be achieved}} through preheating of the heavy crude alongside heating of the pipeline, blending or dilution with light hydrocarbon fluids as well as heavy oil-in-water emulsification, <b>partial</b> <b>upgrading</b> and core-annular flow (Al-Roomi et al. 2004; Saniere et al. 2004). Each of these techniques is aimed at reducing viscosity {{as well as the}} energy required for pumping, to enhance flowability of the oil via pipelines. The objective of this review is to assess the various technologies available for transporting heavy crude oil and bitumen and explore their individual advantages as well as disadvantages, with the aim that the findings would help direct further experiments and research towards providing a practical solution to improve the transportation of heavy oils economically.|$|E
40|$|We {{present the}} results of a <b>partial</b> <b>upgrade</b> to the Monte Carlo event {{generator}} TAUOLA using Resonance Chiral Theory for the two and three meson final states. These modes account for 88 % of total hadronic width of the tau meson. The first results of the model parameters have been obtained using Preliminary BaBar data for 3 pi mode...|$|R
2500|$|A {{goal and}} {{challenge}} pursued by some computer scientists and practitioners in distributed systems is location transparency; however, this goal has {{fallen out of}} favour in industry, as distributed systems are different from conventional non-distributed systems, and the differences, such as network partitions, partial system failures, and <b>partial</b> <b>upgrades,</b> cannot simply be [...] "papered over" [...] by attempts at [...] "transparency" [...] (see CAP theorem).|$|R
40|$|We {{present a}} <b>partial</b> <b>upgrade</b> of the Monte Carlo event {{generator}} TAUOLA {{with the two}} and three hadron decay modes using the theoretical models based on Resonance Chiral Theory. These modes account for 88 % of total hadronic width of the tau meson. First results of the model parameters have been obtained using BaBar data for three pion mode. Comment: 5 pages, 1 figure, contribution to the Proceedings of the QCD@Work 12 Conferenc...|$|R
40|$|With the {{increasing}} energy {{prices and the}} drive to reduce C 02 emission, universities and industries are challenged to find new technologies {{in order to reduce}} energy consumption, to meet legal requirements on emissions, and for cost reduction and increased quality. Traditional methods of transporting heavy crude oils in pipelines are disadvantages from both economic and environmentally perspectives. In this study, the potentials of o/w emulsion technique for transporting viscous crude oils in pipeline as alternative and cost effective method was investigated. The study began with characterisation studies of both types of crude oil and emulsion to provide understanding of fundamental issues such as conventional transportation methods, <b>partial</b> <b>upgrading,</b> pipeline heating, and dilution with lighter crude oils. The aim is to investigate the various factors affecting the preparation of stable crude o/w emulsion, the influence of the emulsion as well as to obtain optimised operating conditions, upon which further developments on pipeline transportation of viscous crudes as concentrated o/w emulsion process could be developed. Two types of crude oil samples were used in this study; heavy oil obtained from Petronas Refinery, Melaka and blend oil was formulated by 60 - 40...|$|E
40|$|The {{performance}} of the THAI™ process has been investigated in numerous 3 D experiments, using heavy crudes and Athabasca oil sands bitumen. The stability of the process is demonstrated by high combustion zone temperatures, absence of gas channelling, insensitivity to large changes in air injection rate, tolerance of an overlying gas cap, increased combustion temperature and faster upgrading response with increasing oil layer thickness, 'controlled gas override', own 'front tracking' capability and steady oil production rate. The most important parameters for upscaling of (stable) experimental scale performance to (stable) field scale operation are combustion front temperature and combustion front velocity. Early stage results from the WHITESANDS THAI™ field pilot at Christina Lake, confirm high combustion zone temperatures (700 - 800 °C), high fluids production of up to 2, 000 barrels per day of gross fluids (50 - 55 % bitumen cut) and signs of significant <b>partial</b> <b>upgrading</b> (up to 8. 2 °API). These measures of field pilot performance {{are consistent with the}} experimental findings from 3 D physical experiments. They are very encouraging indicators for the future development of THAI™ on a commercial scale...|$|E
40|$|The {{socio-economic}} {{problems of}} developing countries, especially Sub-Saharan African cities {{are the result}} of rapid growth, increasing poverty, unequal distribution of resources, civil conflicts and poor governance. These problems have been exacerbated by perennial incidence of civil wars. In Sierra Leone, eleven years of protracted civil war has exacerbated the problems of rural-urban migration, increased poverty, dislocation of urban governance, severe unemployment and lost income opportunities, which all combined have worsened the unequal distribution of resources and poverty. This has led to the collapse of urban infrastructure and of the formal economy, which have combined to accentuate urban poverty and the deterioration of the biophysical environment. These problems have further been compounded by heavy debts burden and structural adjustment programmes imposed on developing countries to facilitate economic diversification, while multilateral aid policies have failed to address the problems of the poor, especially the urban poor. However, the postulation {{of this study is that}} for a pragmatic policy formulation and implementation in aid of poverty alleviation, there must be an adequate understanding of the informal settlement problem. To this effect, two combined survey methods of investigation were employed to access both primary and secondary data on the state of informal settlements in urban areas of Sierra Leone. This consisted of socio-economic and attitudinal survey of residents of three randomly chosen informal settlements two of which have benefited from <b>partial</b> <b>upgrading</b> and one has yet to benefit from any upgrading initiative. The findings from the study clearly presents an understanding of the informal settlement problems, including knowledge poverty, the basic social and economic needs of the residents. Recent efforts by especially international and local aid agencies to improve living conditions in informal settlements have not had significant impact on the quality of life of residents and the biophysical environment. This has been due to bad implementation of programmes and lack of proper co-ordination system among stakeholders rather than choice of strategy. Thus, the central thesis in the present study is that Settlement Upgrading is the appropriate approach to improving the living conditions of residents in informal settlements in Sierra Leone, which can be achieved under the auspices of the Urban Informal Settlement Development Authority as the central coordinating body. Poverty alleviation policies have also been proposed, which are realistic and implementable for better quality of life within the built environment in Sierra Leone...|$|E
5000|$|As {{existing}} K&T wiring gets older, {{insurance companies}} may deny coverage {{due to a}} perception of increased risk. Several companies will not write new homeowners policies at all unless all K&T wiring is replaced, or an electrician certifies that the wiring is in good condition. Also, many institutional lenders are unwilling to finance a home with the relatively low-capacity service typical of K&T wiring, unless the electrical service is <b>upgraded.</b> [...] <b>Partial</b> <b>upgrades,</b> where low demand lighting circuits are left intact, may be acceptable to some insurers.|$|R
40|$|A new tsunami {{detector}} prototype {{designed to}} operate in tsunami generation areas has been tested offshore SW Iberia, in the Gulf of Cadiz. The prototype, hosted on board of GEOSTAR has been deployed, at to 3200 meters depth, in August 2007 and recovered one year later by R/V Urania. After refurbishment and a <b>partial</b> <b>upgrade,</b> the tsunameter has been re-deployed in the same location on November 2009 by R/V Sarmiento de Gamboa. We report samples of the data collected by the pressure sensors and the critical analysis of the achievements and problems faced during these test periods...|$|R
5000|$|The {{ultimate}} advance {{made during}} the closing years of the General War was [...] "X-Technology". This is {{a reference to a}} set of new technologies that started appearing on ships in Y180. By and large, new ships were built with this technology, a few older ships were completely rebuilt to use it, and a few ships had individual systems upgraded to use parts of the new technology. After the end of The General War, more and more ships received these <b>partial</b> <b>upgrades,</b> allowing older designs to stay relevant next to the steadily increasing number of X-ships.|$|R
5000|$|During the 1980s, the Reagan Administration {{chose to}} {{accelerate}} {{production of the}} [...] guided missile cruisers and build the [...] guided missile destroyers, both classes with the Aegis Combat System that was considered more effective than NTU-upgraded ships, to gradually replace all existing destroyer and cruiser classes (especially the expensive nuclear-powered cruisers). The result of this was that only three of Charles F. Adams-class destroyers, , , and [...] received the full upgrade. Other ships, of the class, such as Charles F. Adams, received only <b>partial</b> <b>upgrades,</b> which included the AN/SLQ-32 and Harpoon Missile upgrades, that were intended to extend their service lives until the Arleigh Burke class could reach operational capability.|$|R
5000|$|Installation {{testing is}} a kind of quality {{assurance}} work in the software industry that focuses on what customers will need to do to install and set up the new software successfully. The testing process may involve full, <b>partial</b> or <b>upgrades</b> install/uninstall processes.|$|R
40|$|Abstract—The goal of {{this paper}} is to examine the gains of <b>partial</b> <b>upgrades</b> to {{existing}} FIFO networks, to support delay assurances. Specifically, we try to find the number of hops of FIFO multiplexing after which a latency target is violated. We first examine the effect of multiplexing two flows through successive FIFO schedulers, and for a simple scenario where cross-traffic is assumed to be absent, we derive a worst-case bound on the burstiness increase across n nodes. We use the result to obtain an effective service curve and a worst-case latency bound. We then examine the effect of having a priority scheduler at the entry of the network with FIFO nodes in the core. We provide a basis for determining the number of hops up to which a worst-case latency target is met. I...|$|R
40|$|Commercial {{nuclear power}} plants (NPPs) in the United States need to {{modernize}} their main control rooms (MCR). Many NPPs have done <b>partial</b> <b>upgrades</b> with some success and with some challenges. The Department of Energy’s (DOE) Light Water Reactor Sustainability (LWRS) Program, {{and in particular the}} Advanced Instrumentation and Controls (I&C) and Information Systems Technologies Research and Development (R&D) Pathway within LWRS, is designed to assist commercial nuclear power industry with their MCR modernization efforts. As part of this framework, a survey was issued to utility representatives of the LWRS Program Advanced Instrumentation, Information, and Control Systems/Technologies (II&C) Utility Working Group to obtain their views on a range of issues related to MCR modernization, including: drivers, barriers, and technology options, and the effects these aspects will have on concepts of operations, modernization strategies, and staffing. This paper summarizes the key survey results and discusses their implications...|$|R
40|$|We propose BANANAS, a {{connectionless}} {{framework for}} both intra-domain and inter-domain traffic engineering (TE) in the Internet. The key contributions of this framework are: a) {{it allows the}} source to discover multiple paths and decide on how to split traffic among paths (assuming simple forwarding extensions in a subset of routers). b) {{it does not require}} signaling, or high per-packet overhead. c) it enables an incremental upgrade strategy for both intradomain (OSPF) and inter-domain (BGP) routing to support TE capabilities. d) in a fully upgraded network, every source can control how traffic is mapped to paths and therefore network-wide traffic engineering objectives can be achieved. A path to a destination address is parsimoniously specified in a fixed-length "PathID" field in the packet header. "PathID" is the sum of link weights on the path (or the sum of Autonomous System (AS) numbers for inter-domain paths). This encoding allows efficient connectionless forwarding without using a signaling protocol. We describe extensions to OSPF, and BGP to support the proposed framework. We propose a simple multi-path computation algorithm under <b>partial</b> <b>upgrade</b> assumptions, discuss traffic splitting techniques and forwarding extensions. An ns- 2 based simulation is used to demonstrate the framework and performance improvements...|$|R
40|$|ABSTRACT. Measurements of {{full-scale}} avalanches {{are expensive}} and time con-suming, but are indispensable to gain in-depth {{understanding of the}} flow behavior of avalanches. They are needed to crosscheck the scaling used in small-scale experi-ments and also {{form the basis for}} developing and calibrating numerical models. The recent <b>partial</b> <b>upgrade</b> of NGI’s Ryggfonn test-site is focused on the processes occurring during interaction between avalanches and a catching dam in the runout zone. These processes are crucial for the efficiency of this type of avalanche mitigation measure, which {{has been the focus of}} several small-scale experiments in recent years. But qualitatively and quantitatively good observations from real avalanches for a cross-comparison are rare. Therefore, two new masts were constructed at Ryggfonn. One is located about 10 m upstream of the foot of a catching dam and has a height of 15 m. The other stands on the crown of the dam and is 6 m high. In this way, we also hope to complement the SLF full-scale tests at the Vallée de la Sionne test-site. Instrumentation on the new masts consists of load-cells and LED-velocity sensors, each type with a vertical spacing of 0. 5 m. In addition, flow-height switches are placed with 0. 25 m vertical spacing. Thus, the instrumentation is quite similar to the instrumen-tation used in Vallée de la Sionne, which will hopefully allow better cross-comparison of measurements. We present the upgraded set-up and show preliminary results from the first measure-ments. ...|$|R
40|$|A tool was developed, {{which can}} be used for <b>partial</b> {{automatic}} <b>upgrade</b> of reports in the upgrade process of Microsoft Dynamics NAV. The upgrading of reports from classic to RDLC system of reporting is a complex and time consuming process. The basics of development in Microsoft Dynamics NAV are described as is the classic reporting and RDLC reporting, that was introduced with the adoption of three-tiered architecture. The changes in report creation and visualization of reports in both reporting systems are described. The spacial complexity of flat dataset is also analysed. Described is also the report upgrading process with existing tools. Our focus is primarily on how visualization must be upgraded. The tool that we have developed seeks to eliminate the most time consuming aspects of report upgrading and offers a faster and easier way of upgrade for Microsoft Dynamics NAV. The results of solution, developed in the content of this work, are compared with results from existing solutions...|$|R
40|$|Supermarkets and {{agri-food}} companies increasingly {{dominate the}} production and retailing of food across the global south and north. They operate through global value chains (GVC) within which trade is coordinated by consumer-focused lead firms. This is generating jobs and incomes for workers and smallholders, a significant proportion female. Women contribute to enhancing productivity and quality in GVCs, but outcomes for improving their well-being appear to be mixed. The paper develops a gendered global value chain analysis as a frame for analysing processes {{of economic and social}} upgrading and downgrading in GVCs. It draws on case studies from African traditional and high value agro-exports to highlight three scenarios where: i. economic and <b>partial</b> social <b>upgrading</b> have gone together (floriculture); ii. upgrading and downgrading outcomes are mixed (horticulture); and iii. economic and social downgrading have gone together (cocoa). It considers the intersection of GVCs and gender embeddedness in shaping gender dynamics, and the role of private, civil society and public governance in promoting more gender equitable economic and social upgrading...|$|R
2500|$|In 2000, {{officials}} and transport planners in Greater Manchester {{decided that the}} top public transport priority was a third phase of Metrolink expansion, which would create four new lines along key transport corridors in Greater Manchester: the Oldham and Rochdale Line (routed northeast to Oldham and Rochdale), the East Manchester Line (routed east to East Manchester and Ashton-under-Lyne), the South Manchester Line (routed southeast to Chorlton-cum-Hardy and East Didsbury), and the Airport Line (routed south to Wythenshawe and Manchester Airport). GMPTE and the Association of Greater Manchester Authorities (AGMA) lobbied central government to provide <b>partial</b> funding to <b>upgrade</b> the current network with a new depot, passenger information displays, and construct four new lines in a single Phase 3 contract (dubbed the [...] "Big Bang") worth £489,000,000 (£ as of [...] ).|$|R
25|$|By early 1985 much Macintosh {{software}} required 512K of memory. Apple sold {{an official}} memory upgrade for the Macintosh 128K, {{which included a}} motherboard replacement effectively making it a Macintosh 512K, {{for the price of}} US $995. Additionally, Apple offered an 800KB floppy disk drive kit, including updated 128K ROMs. Finally, a Mac 128K could be upgraded to a Macintosh Plus by swapping the logic board as well as the case back (to accommodate the slightly different port configuration) and optionally adding the Macintosh Plus extended keyboard. Any of the kits could be purchased alone or together at any time, for a <b>partial</b> or full <b>upgrade</b> for the Macintosh 128K. All upgrades were required to be performed by professional Apple technicians, who reportedly refused to work on any Macintosh upgraded to 512K without Apple's official upgrade, which at US$700 was much more expensive than about $300 for third-party versions.|$|R
2500|$|The beltway downgrades from freeway to an {{expressway}} (with some grade separations) {{after it}} passes the Cheyenne Avenue/Cliff Shadows Parkway interchange. From here, the road continues {{north along the}} western foothills of Las Vegas to pass behind Lone Mountain. [...] Soon afterward, the highway curves east and intersects US 95 at a yet to be <b>upgraded</b> <b>partial</b> interchange. From there the beltway continues nearly due east along the alignment of Centennial Parkway before entering northern North Las Vegas at Decatur Boulevard. From there it swings northeast, passing by the large Aliante development before turning east again. Much of the final few miles of the route from here on are in undeveloped land, except near the interchange at 5th Street, with intersections existing primarily as turnarounds, until the beltway swings southeast just past Lamb Boulevard and reaches its ending terminus at I-15 {{just west of the}} Las Vegas Motor Speedway.|$|R
50|$|By early 1985 much Macintosh {{software}} required 512K of memory. Apple sold {{an official}} memory upgrade for the Macintosh 128K, {{which included a}} motherboard replacement effectively making it a Macintosh 512K, {{for the price of}} US $995. Additionally, Apple offered an 800 KB floppy disk drive kit, including updated 128K ROMs. Finally, a Mac 128K could be upgraded to a Macintosh Plus by swapping the logic board as well as the case back (to accommodate the slightly different port configuration) and optionally adding the Macintosh Plus extended keyboard. Any of the kits could be purchased alone or together at any time, for a <b>partial</b> or full <b>upgrade</b> for the Macintosh 128K. All upgrades were required to be performed by professional Apple technicians, who reportedly refused to work on any Macintosh upgraded to 512K without Apple's official upgrade, which at US$700 was much more expensive than about $300 for third-party versions.|$|R
50|$|The beltway downgrades from freeway to an {{expressway}} (with some grade separations) {{after it}} passes the Cheyenne Avenue/Cliff Shadows Parkway interchange. From here, the road continues {{north along the}} western foothills of Las Vegas to pass behind Lone Mountain. Soon afterward, the highway curves east and intersects US 95 at a yet to be <b>upgraded</b> <b>partial</b> interchange. From there the beltway continues nearly due east along the alignment of Centennial Parkway before entering northern North Las Vegas at Decatur Boulevard. From there it swings northeast, passing by the large Aliante development before turning east again. Much of the final few miles of the route from here on are in undeveloped land, except near the interchange at 5th Street, with intersections existing primarily as turnarounds, until the beltway swings southeast just past Lamb Boulevard and reaches its ending terminus at I-15 {{just west of the}} Las Vegas Motor Speedway.|$|R
5000|$|At the Canadian Grand Prix, Honda {{failed to}} deliver a promised engine upgrade. McLaren {{described}} Honda as [...] "they seem a bit lost" [...] and expressed [...] "serious concerns" [...] over whether Honda would ever be capable of building an engine that could win the world championship. A day later, during first practice, the Honda engine broke down with Alonso commenting that [...] "we are used to it". Alonso's engine failed again during the race. Following the latest engine failure, McLaren racing director Boullier described the Honda power plant as [...] "simply, and absolutely, not good enough". The <b>partial</b> engine <b>upgrade</b> was at last delivered to Alonso at the Azerbaijan Grand Prix, however, due to the penalties taken {{to use the new}} engine, Alonso was to start last for the race, as such, Honda decided to use the new engine just during free practice 1 and 2 to validate its effectiveness and save mileage for a GP where they would be in a better position, Alonso was then to revert back to the previous engine spec for qualifying and the race. The test providing encouraging results for the team however it was cut short during FP2 before Alonso could do full pace runs due to a transmission failure. At the British Grand Prix, Alonso's engine broke again forcing Honda to replace it and incur a 30-place grid penalty. The new engine was supposed to have received reliability improvements, however it failed during the race after just one hour of use, leading Alonso to retire. Honda then admitted that it also had problems with the poor design of its testing rigs.|$|R
40|$|The {{advent of}} water pinch {{analysis}} {{as a tool}} for the design of optimal water recovery network {{has been one of the}} most significant advances in the area of water conservation over the last decade. Water pinch analysis is a systematic technique for implementing strategies to maximise water reuse and recycling through integration of water-using activities or processes. In this paper, possibility of achieving complete elimination of wastewater, i. e. zero discharge is assessed through the use of water regeneration units. Water regeneration has been widely accepted as an effective mean to further reduce water targets in water pinch analysis. Water regeneration involves the <b>partial</b> or total <b>upgrading</b> of water purity using any purification techniques. The regenerated water can either be reused in other water-using processes or recycled to the same process to further reduce water consumption and wastewater generation. A case study on a water-intensive paper mill process is used to illustrate how the water network can be optimised to achieve zero discharge. The targeting technique of water cascade analysis is used to locate the various network targets prior to the development of detailed network design. A solution with the minimum capital and annual operating costs was obtained...|$|R
5000|$|In 2000, {{officials}} and transport planners in Greater Manchester {{decided that the}} top public transport priority was a third phase of Metrolink expansion, which would create four new lines along key transport corridors in Greater Manchester: the Oldham and Rochdale Line (routed northeast to Oldham and Rochdale), the East Manchester Line (routed east to East Manchester and Ashton-under-Lyne), the South Manchester Line (routed southeast to Chorlton-cum-Hardy and East Didsbury), and the Airport Line (routed south to Wythenshawe and Manchester Airport). GMPTE and the Association of Greater Manchester Authorities (AGMA) lobbied central government to provide <b>partial</b> funding to <b>upgrade</b> the current network with a new depot, passenger information displays, and construct four new lines in a single Phase 3 contract (dubbed the [...] "Big Bang") worth £489,000,000 (£ as of [...] ).Estimated costs were later revised in 2002 to £820,000,000 (£ as of [...] ), meaning Metrolink required a Government contribution of at least £520,000,000. With costs predicted to rise further, on 20 July 2004, Alistair Darling (the Secretary of State for Transport) announced the Government had withdrawn its share of funding Metrolink due to excessive costs.|$|R
40|$|Downhole {{upgrading}} {{of virgin}} Athabasca Tar Sand bitumen {{has been investigated}} {{in a series of}} 3 -D experiments using THAI-'Toe-to-Heel Air Injection'. The THAI process uses combinations of vertical injection wells and horizontal producer wells, arranged in a direct, or staggered line drive. 3 -D experiments were performed to investigate THAI as a primary recovery method, and also as a secondary recovery method. The latter followed a prior THSF-'Toe-to-Heel Steam Flood'. Oil recovery efficiencies for THAI, using primary and secondary operation modes, were respectively, 80 % and 67 % OOIP. The THSF recovery was much lower, only 23 % OOIP, owing to the low steam temperature in the sandpack. Downhole upgrading of the Athabasca Tar Sand bitumen was very significant, with the API gravity of the produced oil increasing by an average of 8 degrees API, compared to the original bitumen. The produced oil viscosity was also dramatically reduced, to less than 200 mPa s, with a minimum value of 50 mPa s. SARA analysis was used to assess the quality of the produced oil. The original bitumen contained only 15. 5 % saturates, but the amount in the produced oil was increased to 72 %. The high oil recovery factor and <b>partial</b> in situ <b>upgrading</b> achieved by the THAI process could therefore have important economic implications for the future of heavy oil and bitumen production. The first field pilot of the THAI process is scheduled to take place at Christina Lake, Alberta, Canada, in 2006...|$|R
40|$|In {{the past}} century, {{numerous}} iterations of automation have changed our society significantly. In that perspective, {{the professional and}} personal availability of computing devices interconnected through the Internet has {{changed the way we}} eat, live and treat each other. Today, the Internet is a service as crucial to our society as public access to electricity, gas and water supplies. Due to its successful adoption, the Internet now serves applications that were unthinkable {{at the time of its}} initial designs when social media, online global market places and video streaming were still far out of reasonable imaginary reach. Early research initiatives worked on realizing a global network of interconnected computers, an aim clearly realized by the successful implementation of the Internet and the fact that the infrastructure still suffices to provide connectivity to an unforeseen growth and change in usage. The research field of future Internet aims at long-term improvements of the Internet architecture, trying to improve the network infrastructure such that it will also facilitate future growth and applications. In this dissertation, we have contributed to the field of future Internet by proposing, implementing and evaluating infrastructure improvements. Most of our work revolves around Software-Defined Networking (SDN), a network management architecture aiming at logical centralization and softwarization of network control through the separation of data plane and control plane functionality. In particular, we have assessed the feasibility and accuracy of network monitoring through SDN (see chapter 3), as well as contributed to the robustness and recovery of such networks under topology failure by speeding up failure detection and recovery (see chapter 4) and precomputation of network-wide per-failure protection paths (see chapter 5). In addition to SDN, we have contributed to Information-Centric Networking (ICN), a network architecture optimizing content distribution by implementing network-layer forwarding techniques and cache-placement strategies based on content identifiers. We have contributed to this field by introducing a globally-accessible namespace maintaining a feasible global-routing-table size through separation and translation of context-related and location-aggregated name components (see chapter 6). Considering the same demand for centralization and softwarization of network control found in SDN applies to other network architectures, we have designed a protocol-agnostic SDN scheme enabling fine-grained control of application-specific forwarding schemes. With our prototype, we evaluate an implementation of such an SDN-controlled ICN, demonstrating correct functionality in both <b>partial</b> and fully <b>upgraded</b> networks (see chapter 7). Besides working on future Internet topics, we have also taken a step aside and looked at more recent Internet architecture improvements. Specifically, we have performed measurements on the Domain Name System’s Security Extensions (DNSSEC). From these measurements we provide insight into the level of implementation and correctness of DNSSEC configuration. Through categorization of errors we explain their main causes and find the common denominators in misconfiguration (see chapter 8) ...|$|R

