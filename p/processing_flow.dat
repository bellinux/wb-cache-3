285|605|Public
5|$|It {{was clear}} that the planned <b>processing</b> <b>flow</b> could not be {{followed}} and still meet the 1986 launch date. It was decided on Cosmonaut's Day (12 April) 1985 to ship the flight model of the base block to the Baikonur cosmodrome and conduct the systems testing and integration there. The module arrived at the launch site on 6 May, with 1100 of 2500 cables requiring rework {{based on the results of}} tests to the ground test model at Khrunichev. In October, the base block was rolled outside its cleanroom to carry out communications tests. The first launch attempt on 16 February 1986 was scrubbed when the spacecraft communications failed, but the second launch attempt, on 19 February 1986 at 21:28:23 UTC, was successful, meeting the political deadline.|$|E
25|$|As of July 2013, Bioconductor {{contained}} 21 {{software packages}} for <b>processing</b> <b>flow</b> cytometry data.|$|E
25|$|On 12 October 2010, the STS-133 crew {{arrived at}} the Kennedy Space Center to conduct the Terminal Countdown Demonstration Test (TCDT). The TCDT {{consisted}} of training for both the crew and the launch team that simulated the final hours up until launch. During the TCDT, the crew went {{through a number of}} exercises that included rescue training and a launch day simulation that included everything that would happen on launch day â€“ except the launch. Commander Steve Lindsey and Pilot Eric Boe also performed abort landings and other flight aspects in the Shuttle Training Aircraft (STA). For the TCDT, the crew also received a briefing from NASA engineers, outlining the work that had been carried out on Discovery during the STS-133 <b>processing</b> <b>flow.</b> After successfully completing all the TCDT tasks, the crew returned to the Johnson Space Center on 15 October 2010.|$|E
50|$|Example {{applications}} include, but are {{not limited}} to, coating and polymer <b>processing</b> <b>flows,</b> super-alloy <b>processing,</b> welding/soldering, electrochemical processes, and solid-network or solution film drying. A full description of Goma's capabilities can be found in Goma's capabilities document.|$|R
25|$|Develop {{a theory}} of {{information}} <b>processing,</b> information <b>flow,</b> and information generation for evolving systems.|$|R
30|$|Considering the {{limitations}} discussed above, NFV-PEAR presents {{itself as a}} solution to re-adjust the network against demand variations, through the identification of bottlenecks in the <b>processing</b> of <b>flows,</b> reorganization of the placement and chaining of network functions locally/globally, and aiming at the minimization of disruption in the <b>processing</b> of transit <b>flows.</b>|$|R
5000|$|... #Caption: A diagram {{illustrating}} all of {{the basic}} elements and <b>processing</b> <b>flow</b> of a template engine.|$|E
50|$|Rotary {{vacuum drum}} filter (RVDF), {{patented}} in 1872, {{is one of}} the oldest filters used in the industrial liquid-solids separation. It offers a wide range of industrial <b>processing</b> <b>flow</b> sheets and provides a flexible application of dewatering, washing and/or clarification.|$|E
50|$|The Bioconductor {{project is}} a {{repository}} of free open source software, mostly written in the R programming language.As of July 2013, Bioconductor contained 21 software packages for <b>processing</b> <b>flow</b> cytometry data.These packages cover most {{of the range of}} functionality described earlier in this article.|$|E
40|$|Approved {{for public}} release; {{distribution}} is unlimitedInformation concerning {{the processing of}} Navy enlisted applicants was collected and analyzed to determine actual <b>processing</b> <b>flows</b> and {{to determine whether the}} size of a recruiting station, the distance of a recruiting station from the processing AFEES, or the particular AFEES being processed through {{played a significant role in}} the determination of <b>processing</b> <b>flows</b> and <b>processing</b> times. It was found that neither the size of a recruiting station nor the distance from the processing AFEES were significant factors. The particular AFEES being processed through was a significant factor in determining computed times until police checks were returned and times for overall flows after recruiter-responsible events were completed. It was found that the Fresno AFEES recorded a significantly higher percentage of applicants placed in a temporary medical rejection than the other AFEES. It was found that all recruiters process applicants using the same general sequence of events and the recruiters spend about the same amount of time actually processing applicants. [URL] United States Nav...|$|R
30|$|After {{presenting}} the ILP model for adaptive placement and chaining of VNFs, {{in this section}} we introduce NFV-PEAR: an architecture for virtual network function deployment and orchestration 3. NFV-PEAR relies on the proposed ILP model to allow the dynamic reallocation of network functions in response to oscillations in the demands of <b>processing</b> <b>flows.</b> Our architecture was designed {{in line with the}} main building blocks recommended by the ETSI MANO (Management and Orchestration) interface standard [14].|$|R
40|$|The {{current status}} of digital image <b>processing</b> in fluid <b>flow</b> {{research}} is reviewed. In particular, attention is given to a comprehensive approach to the extraction of quantitative data from multivariate databases and examples of recent developments. The discussion covers numerical simulations and experiments, data processing, generation and dissemination of knowledge, traditional image processing, hybrid <b>processing,</b> fluid <b>flow</b> vector field topology, and isosurface analysis using Marching Cubes...|$|R
50|$|BizTalk makes {{processing}} safe by serialization (called dehydration in Biztalk's terminology) - placing messages into {{a database}} {{while waiting for}} external events, thus preventing data loss. This architecture binds BizTalk with Microsoft SQL Server. <b>Processing</b> <b>flow</b> can be tracked by administrators using an Administration Console.BizTalk supports the transaction flow through the whole line from one customer to another. BizTalk orchestrations also implement long-running transactions.|$|E
5000|$|Cameron International Corporation (formerly Cooper Cameron Corporation, CCC) is a Schlumberger {{company and}} a global {{provider}} of pressure control, <b>processing,</b> <b>flow</b> control and compression systems as well as project management and aftermarket services for {{the oil and gas}} and process industries. It employs approximately 23,000 people and is headquartered in Park Towers South, Houston, Texas. In 2006 Cooper Cameron was officially renamed [...] "Cameron." ...|$|E
50|$|The {{formulation}} of queries is mostly done using declarative languages like SQL in DBMS. Since {{there are no}} standardized query languages to express continuous queries, {{there are a lot}} of languages and variations. However, most of them are based on SQL, such as the Continuous Query Language (CQL), StreamSQL and EPL. There are also graphical approaches where each processing step is a box and the <b>processing</b> <b>flow</b> is expressed by arrows between the boxes.|$|E
40|$|This {{investigation}} was undertaken {{to evaluate the}} <b>processing</b> <b>flows</b> needed to obtain vertical and radial post-stack migrated seismic sections from a heavy oil reservoir in Eastern Alberta. The radial filter was found to successfully attenuate shot-generated linear noise on both the vertical and radial components. Gabor deconvolution was found to successfully boost signal to noise in low fold areas of the data. The depth-variant stack has shown to have greater frequency in the near surface data compared to the CCP stack for the radial component...|$|R
40|$|The fast {{development}} of computer networks brings {{the necessity to}} protect those networks against more and more advanced attacks. The security systems require an advanced analysis for their operation which is carried out based on the stateful <b>processing</b> of <b>flows.</b> This Bachelor Thesis focuses on the proposal and simulation of the stateful <b>flow</b> <b>processing</b> system. The proposed system uses a specialized hardware for network operation processing acceleration of high-speed backbone lines. The specific feature {{of the system is}} the flow memory distribution between the hardware and software. The created simulation model will make it possible to test and optimize the stateful <b>flow</b> <b>processing</b> system already in the phase of proposal and thus the possible implementation will be facilitated...|$|R
40|$|International audienceThis paper {{describes}} work {{carried out}} in order to match experimental <b>processing</b> <b>flows</b> to numerical simulation. The work has brought together a consortium that has developed reliable experimental methods by which <b>processing</b> <b>flows</b> can be achieved in the laboratory and then ranked against numerical simulation. A full rheological characterisation of a selected range of polymers was made and the results compared from different laboratories. The data was fitted {{to a number of}} rheological models. Multi-mode parameter fitting was universal for the linear viscoelastic response. Particular attention was paid to the non linear response of the material. Prototype industrial flow experiments were carried out for a number of geometries in different laboratories and the flow birefringence technique was used to map out the experimentally observed stress fields for different polymers in a range of complex flows that contained both extensional and shear flow components. Numerical simulation was carried out using a number of algorithms and a range of constitutive equations. In order to make a quantitative comparison between experiment and simulation, an Advanced Rheological Tool (ART) module was developed that was able in some cases to quantify the level of fit between the numerically predicted and the experimentally observed stress patterns. In addition the ART module was able to optimise certain non-linear parameters in order {{to improve the quality of}} fit between experiment and simulation...|$|R
50|$|The Network-Integrated Multimedia Middleware (NMM) is a {{flow graph}} based {{multimedia}} framework. NMM allows creating distributed multimedia applications: local and remote multimedia devices or software components {{can be controlled}} transparently and integrated into a common multimedia <b>processing</b> <b>flow</b> graph. NMM is implemented in C++, a programming language, and NMM-IDL, an interface description language (IDL). NMM {{is a set of}} cross-platform libraries and applications for the operating systems Linux, OS X, Windows, and others. A software development kit (SDK) is also provided.|$|E
50|$|In {{the next}} step, the {{declarative}} query is {{translated into a}} logical query plan. A query plan is a directed graph where the nodes are operators and the edges describe the <b>processing</b> <b>flow.</b> Each operator in the query plan encapsulates the semantic of a specific operation, such as filtering or aggregation. In DSMSs that process relational data streams, the operators are equal or similar to the operators of the Relational algebra, {{so that there are}} operators for selection, projection, join, and set operations. This operator concept allows the very flexible and versatile processing of a DSMS.|$|E
5000|$|The Act lets banks take {{advantage}} of image technologies and electronic transport while not being dependent on other banks being ready to settle transactions with images instead of paper. The process of removing the paper check from its <b>processing</b> <b>flow</b> is called [...] "check truncation". Paper checks continue to transition to electronic images, with almost 70% of all institutions receiving images as of January 2013. In truncation, {{both sides of the}} paper check are scanned to produce a digital image. If a paper document is still needed, these images are inserted into specially formatted documents containing a photo-reduced copy of the original checks called a [...] "substitute check".|$|E
40|$|Goma 6. 0 is {{a finite}} element program which excels in {{analyses}} of multiphysical processes, particularly those involving the major branches of mechanics (viz. fluid/solid mechanics, energy transport and chemical species transport). Goma {{is based on}} a full-Newton-coupled algorithm which allows for simultaneous solution of the governing principles, making the code ideally suited for problems involving closely coupled bulk mechanics and interfacial phenomena. Example applications include, but are not limited to, coating and polymer <b>processing</b> <b>flows,</b> super-alloy <b>processing,</b> welding/soldering, electrochemical processes, and solid-network or solution film drying. This document serves as a user's guide and reference...|$|R
40|$|The {{equations}} which {{govern the}} nonisothermal flow of reactive fluids are outlined, {{and the means}} by which finite element analysis is used to solve these equations for the sort of arbitrary boundary conditions encountered in industrial practice are described. The performance of the computer code is illustrated by several trial problems, selected more for their value in providing insight to polymer <b>processing</b> <b>flows</b> than as practical production problems. Although a good deal remains to be learned as to the performance and proper use of this numerical technique, it is undeniably useful in providing better understanding of today's complicated polymer processing problems...|$|R
40|$|AbstractIt is complicate {{to process}} the seismic data from the area below a fault, where there is the pull-up and sag {{phenomenon}} in seismic section. And geological processors are difficult to make sure whether the pull-up and sag really exist. So this phenomenon of pull-up and sag makes the fault shadow problem. This paper makes a forward simulation research deeply and presents many different geological models to execute forward numerical simulation. Many common <b>processing</b> <b>flows</b> and migration imaging methods are analyzed and used to overcome the fault shadow problem. At last, this paper concludes one fairly suitable method to resolve the fault shadow problem by comparing the different migration methods...|$|R
50|$|It {{was clear}} that the planned <b>processing</b> <b>flow</b> could not be {{followed}} and still meet the 1986 launch date. It was decided on Cosmonauts Day (12 April) 1985 to ship the flight model of the base block to the Baikonur cosmodrome and conduct the systems testing and integration there. The module arrived at the launch site on 6 May, with 1100 of 2500 cables requiring rework {{based on the results of}} tests to the ground test model at Khrunichev. In October, the base block was rolled outside its cleanroom to carry out communications tests. The first launch attempt on 16 February 1986 was scrubbed when the spacecraft communications failed, but the second launch attempt, on 19 February 1986 at 21:28:23 UTC, was successful, meeting the political deadline.|$|E
50|$|On 12 October 2010, the STS-133 crew {{arrived at}} the Kennedy Space Center to conduct the Terminal Countdown Demonstration Test (TCDT). The TCDT {{consisted}} of training for both the crew and the launch team that simulated the final hours up until launch. During the TCDT, the crew went {{through a number of}} exercises that included rescue training and a launch day simulation that included everything that would happen on launch day - except the launch. Commander Steve Lindsey and Pilot Eric Boe also performed abort landings and other flight aspects in the Shuttle Training Aircraft (STA). For the TCDT, the crew also received a briefing from NASA engineers, outlining the work that had been carried out on Discovery during the STS-133 <b>processing</b> <b>flow.</b> After successfully completing all the TCDT tasks, the crew returned to the Johnson Space Center on 15 October 2010.|$|E
50|$|The town is {{not really}} known for heavy industry, but many {{businesses}} which have started up in Celle and some, such as Rosa Graf Cosmetics, have reached the world market. Celle does have some links to the oil industry, though, particularly firms engineering parts for drilling; notably Baker Hughes (INTEQ and Hughes Christensen divisions; {{oil and gas industry}} service companies specialising in MWD, Wireline, Drill-bits, Drilling Applications Engineering, etc.), Cameron (global provider of pressure control, <b>processing,</b> <b>flow</b> control and compression systems as well as project management and aftermarket services for the oil and gas and process industries), and ITAG (drilling contractors and manufacturing plant). Halliburton, founded in 1919, is one of the worldâ€™s largest providers of products and services to the energy industry and has an office in Celle. There is also a school for advance drilling techniques.|$|E
40|$|Abstract. This paper investigates {{some of the}} {{relationships}} between reengineering and knowledge management, with particular emphasis on sequencing relationships between reengineering and knowledge management. This is done using four basic approaches. First the paper explores how some knowledge management computing artifacts can be reengineered. Second, the paper traces the interaction between reengineering and knowledge management in typical organizational projects, illustrating the importance of sequence, and extending the results with a real world example. Third, the impact of reengineering on ontologies and knowledge bases is briefly reviewed. Fourth, issues that differentiate reengineering knowledge management systems and typical transaction <b>processing</b> <b>flows</b> are analyzed. Finally, simultaneous reengineering and knowledge management are investigated. ...|$|R
30|$|Scalability, {{as pointed}} out in the answer to {{question}} 3, {{is one of the main}} challenges uncovered from early SDN deployment experiences. Approaches leveraging multiple controllers working together in a peer-to-peer or hierarchical manner to reduce performance bottlenecks in <b>flow</b> <b>processing</b> and <b>flow</b> setup time will be particularly useful for large-scale wide area SDN deployments. However, in this case, maintaining a consistent global network view across all controllers is difficult and at the least costly. Strategic placement of the controllers is also relevant here.|$|R
40|$|In Part 2, {{the factors}} {{impacting}} the Claisen rearrangement both in batch and <b>flow</b> <b>processing</b> are analyzed, including {{the choice of}} substituent, catalyst, temperature, pressure, concentration, flow rates, and solvent. Part 1 of this review series discussed the potential of using short-time spectroscopy and quantum mechanical calculations to elucidate the mechanism and transition state of the Claisen rearrangement. <b>Flow</b> <b>processing</b> offers profound opportunities for studying these factors known to impact the Claisen rearrangement done in batch. It is shown that the same impact factors also rule <b>flow</b> <b>processing,</b> yet now superposed by the very different residence and reaction time settings and by novel process windows which go beyond conventional processing. As a result, massive intensification can be reached and a mechanistic analysis {{can be done in}} entirely unpaved processing fields. This links to the analysis given in part 1 : it is likely that <b>flow</b> <b>processing</b> can further promote the understanding of the mechanism and transition state of the Claisen rearrangement and, thereby, promote the achievement of better reaction performance...|$|R
50|$|The ore {{extracted}} from the open pit is crushed in a gyratory crusher after being transported and stored in the crushed ore storage facility located within the processing plant site.The processing plant has a design capacity of 9 millions tones extracted and processed per year, the process being made on 4 technological lines of 7,500 tones per day. The plant was launched between 1985 and 1987. The ore is subsequently processed through a classical <b>processing</b> <b>flow,</b> with a two-stage grinding phase in two autogenous mills and in two ball mills, followed by flotation, which is performed in pneumomechanical cells (abbr=on 17 sqm sq ft) where the primary concentrate is obtained, which subsequently is flotated in cells of abbr=on 5.7 sqm sq ft where a copper concentrate is obtained with a content between 16.5 and 20% copper. The concentrate is thickened in sided thickeners and filtered through a pressure filter (Larox).|$|E
50|$|The user {{interface}} is mainly through the DS's touch screen with the cursors {{serving as a}} supplementary method of moving through the various interface screens. The primary method of navigating through interface screens is by switching the interface screen with the <b>processing</b> <b>flow</b> map and selecting which item to modify. Notes can be played using a 2 octave keyboard or through an interface that detects the X and Y position of the stylus on the touch pad simulating a KORG Kaoss Pad. The Kaoss Pad {{can also be used}} to modify volume and pan as well as being able to assign the X or Y values to any of the parameters that can be modified elsewhere. Users can record twenty-one sessions with sixteen different step patterns with either live input or through a step sequencer. These patterns can then either be selected live or sequenced with the song mode.|$|E
50|$|The {{need for}} {{corporate}} compliance and accountability has also forced large corporations to invest heavily in information backup, storage systems, and compliance solutions. Some corporate mailrooms {{have benefited from}} the development of high-speed automation equipment designed for moving physical mail more efficiently through the system. However, the challenges are daunting, considering that most mailrooms are using one-piece-at-a-time visual identification and manual sorting methods. By digitizing the incoming mail process, and indexing the documents on the fly, companies can not only gain control of their mail processes internally (no more efficiency losses, gaps in document control and loss of valuable mail), but {{will have the opportunity to}} combine electronic mail formats (e-mail, fax) in the same document <b>processing</b> <b>flow.</b> A digital mailroom designed as a central platform for information allows an organization to bring rationality to mail processing and significant gains in productivity and customer service.|$|E
40|$|In this paper, we {{approach}} empirically {{the influence of}} trade union (TU) bargaining power on delocalization strategies by analyzing the determinants of processing trade data {{as a proxy for}} delocalization and using an index that measures TU bargaining power as the main explanatory variable. Trade processing data were collected for European countries for the period 1995 - 2000. In addition to finding that market- and cost-related determinants exert the expected influence on trade <b>processing</b> <b>flows,</b> our results suggest that TU bargaining power had a negative effect on delocalization strategies in the period considered. This result points to the conclusion that deunionization favors delocalization strategies by firms, which is, in fact, the trend observed in most developed countries recently. bargaining power, delocalization, off shoring, processing trade, trade union,...|$|R
40|$|We {{collected}} seismic data along 15 transects {{to characterize}} the geometry of a coastal aquifer in BÃ©nin, West Africa, that is being contaminated by saltwater. We used standard high-resolution seismic methods to image the upper âˆ¼ 200 m using a sledgehammer source and a 120 -channel recording system. Three transects were processed with an iterative updating flow that includes prestack depth migration, residual moveout analysis, and reflection tomography, and the remaining 12 transects were processed with routine <b>processing</b> <b>flows</b> and poststack time migration. We identified one unconfined aquifer and three confined aquifers separated by reflective confining clay layers. Some transects showed areas of missing reflectors, which we interpreted as sand-filled channels that could provide potential high-permeability conduits for saltwater flow to the Godomey well field...|$|R
40|$|In image analysis, {{processing}} and understanding, {{it is highly}} desirable to process the image and feature domains by methods that are specific to these domains. We show how the geometrical framework for scale-space flows is most convenient for this purpose, and demonstrate, as an example, how one can switch continuously between different <b>processing</b> <b>flows</b> of images and color domains. The parameter that interpolates between the norms is the luminance strength, taken here as a local function of the image embedding space. The resulting spatial and/or luminance preserving flow {{can be used for}} conditional denoising, enhancement and segmentation. This example demonstrates that the proposed framework can incorporate context or task dependent data, furnished by either the human user or by an active vision subsystem, in a coherent and convenient way. 1...|$|R
