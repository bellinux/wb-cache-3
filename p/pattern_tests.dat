54|4130|Public
25|$|The 1st was {{equipped}} {{with a mixture of}} medium and heavy bombers. The squadron operated primarily from Brooksville Army Airfield which runways could better accommodate the heavy bombers. Its squadrons trained bomber crews in organization and operations, performed bombing <b>pattern</b> <b>tests,</b> experimented with tactical formations to attack moving ships, and performed equipment tests. The squadron also flew in maneuvers and took part in many experiments at Eglin Field, Florida. During this period, the 1st BS had twelve B-17 Flying Fortresses, two B-25 Mitchells and two L-3Cs observation aircraft assigned.|$|E
50|$|At the AAFSAT, the {{squadron}} trained units at various airfields {{in central and}} Northern Florida, {{the squadron}} trained cadres for 44 bomb groups in organization and operations, performed bombing <b>pattern</b> <b>tests,</b> experimented with 3-plane formations to attack moving ships, and performed over a hundred equipment tests.|$|E
50|$|To {{achieve some}} {{advanced}} design concept {{such as a}} design <b>pattern,</b> <b>tests</b> are written that generate that design. The code may remain simpler than the target pattern, but still pass all required tests. This can be unsettling at first but it allows the developer to focus only on what is important.|$|E
40|$|Abstract. In complex systems, {{embedded}} processors {{may be used}} to {{run software}} routines for <b>test</b> <b>pattern</b> generation and response evaluation. For system components which are not completely random <b>pattern</b> testable, the <b>test</b> programs have to generate deterministic <b>patterns</b> after random <b>testing.</b> Usually the random test part of the program requires long run times whereas the part for deterministic testing has high memory requirements. In this paper it is shown that an appropriate selection of the random <b>pattern</b> <b>test</b> method can significantly reduce the memory requirements of the deterministic part. A new, highly efficient scheme for software-based random <b>pattern</b> <b>testing</b> is proposed, and it is shown how to extend the scheme for deterministic <b>test</b> <b>pattern</b> generation. The entire test scheme may also be used for implementing a scan based BIST in hardware. Keywords: BIST, random <b>pattern</b> <b>testing,</b> deterministic BIST, embedded system...|$|R
5000|$|... #Caption: The Indian-head <b>test</b> <b>pattern</b> TV <b>test</b> <b>pattern,</b> {{close to}} a test film but with out the Indian ...|$|R
40|$|AbstractPresent {{complexity}} of System on Chip (SoC) design is increasing {{rapidly in the}} number of <b>test</b> <b>patterns,</b> huge switching activity and its transition time. This large test data volume is becoming one of the major problems in association with huge switching activity and its corresponding response time. This paper considers the problem of huge <b>test</b> <b>pattern</b> in scan based design. This proposed algorithm is based on reducing <b>test</b> <b>pattern</b> on scan shift in operation. This is achieved by identifying test data transition and equally segmenting the scan based <b>test</b> <b>patterns.</b> Each scan <b>test</b> <b>pattern</b> is considered by its transition and segmented into equal necessary blocks. This finally gives the compressed <b>test</b> <b>patterns</b> in reduced <b>test</b> <b>patterns.</b> Theoretical analysis and experimental results on ISCAS 89 shows that the proposed method reduces <b>test</b> <b>pattern</b> by 37 % when compared to the traditional approaches...|$|R
50|$|The 1st was {{equipped}} {{with a mixture of}} medium and heavy bombers. The squadron operated primarily from Brooksville Army Airfield which runways could better accommodate the heavy bombers. Its squadrons trained bomber crews in organization and operations, performed bombing <b>pattern</b> <b>tests,</b> experimented with tactical formations to attack moving ships, and performed equipment tests. The squadron also flew in maneuvers and took part in many experiments at Eglin Field, Florida. During this period, the 1st BS had twelve B-17 Flying Fortresses, two B-25 Mitchells and two L-3Cs observation aircraft assigned.|$|E
50|$|The 9th Bombardment Group's {{assets were}} {{transferred}} to the 25th Bombardment Group and it was returned without personnel or equipment to the US in October 1942, where it was reconstituted {{as part of the}} Army Air Force School of Applied Tactics at Orlando Army Air Base, Florida. The group's squadrons were assigned as school squadrons, with the 1st located at Brooksville Army Air Field, the 5th at Pinecastle Army Air Field, and the 99th at Montbrook Army Air Field, Florida. These used B-17 Flying Fortress, B-24 Liberator, and B-26 Marauder aircraft to train cadres for 44 bomb groups in organization and operations, performed bombing <b>pattern</b> <b>tests,</b> experimented with 3-plane formations to attack moving ships, and performed over a hundred equipment tests.|$|E
5000|$|The major use for {{hardware}} {{random number}} generators {{is in the}} field of data encryption, for example to create random cryptographic keys to encrypt data. They are a more secure alternative to pseudorandom number generators (PRNGs), software programs commonly used in computers to generate [...] "random" [...] numbers. PRNGs use a deterministic algorithm to produce numerical sequences. Although these pseudorandom sequences pass statistical <b>pattern</b> <b>tests</b> for randomness, by knowing the algorithm and the conditions used to initialize it, called the [...] "seed", the output can be predicted. Because the sequence of numbers produced by a PRNG is predictable, data encrypted with pseudorandom numbers is potentially vulnerable to cryptanalysis. Hardware random number generators produce sequences of numbers that are assumed not to be predictable, and therefore provide the greatest security when used to encrypt data.|$|E
40|$|In complex systems, {{embedded}} processors {{may be used}} to {{run software}} routines for <b>test</b> <b>pattern</b> generation and response evaluation. For system components which are not completely random <b>pattern</b> testable, the <b>test</b> programs have to generate deterministic <b>patterns</b> after random <b>testing.</b> Usually the random test part of the program requires long run times whereas the part for deterministic testing has high memory requirements. In this paper it is shown that an appropriate selection of the random <b>pattern</b> <b>test</b> method can significantly reduce the memory requirements of the deterministic part. A new, highly efficient scheme for software-based random <b>pattern</b> <b>testing</b> is proposed, and it is shown how to extend the scheme for deterministic <b>test</b> <b>pattern</b> generation. The entire test scheme may also be used for implementing a scan based BIST in hardware. 1 Introduction Integrating complex systems into single chips or implementing them as multi-chip modules (MCMs) has become a widespread approach. A var [...] ...|$|R
5000|$|Test patterns: {{standard}} video <b>test</b> <b>patterns</b> that <b>test</b> the display’s {{ability to}} perform as expected.|$|R
40|$|The {{demand and}} the supply are {{increasing}} sharply {{in accordance with}} the growth of the Memory Semiconductor Industry. The Flash Memory above all is being utilized substantially in the Industry of smart phone, the tablet PC and the System on Chip (SoC). The Flash Memory is divided into the NOR-type Flash Memory and the NAND-type Flash Memory. A lot of study such as the Built-In Self Test (BIST), the Built-In Self Repair (BISR) and the Built-In Redundancy Analysis (BIRA), etc. has been progressed in the NOR-type fash Memory, the study for the Built-In Self Test of the NAND-type Flash Memory has not been progressed. At present, the <b>pattern</b> <b>test</b> of the NAND-type Flash Memory is being carried out using the outside test equipment of high price. The NAND-type Flash Memory is being depended on the outside equipment as there is no Built-In Self Test since the erasure of block unit, the reading and writing of page unit are possible in the NAND-type Flash Memory. The Built-In Self Test equipped with 2 kinds of finite state machine based structure is proposed, so as to carry out the <b>pattern</b> <b>test</b> without the outside <b>pattern</b> <b>test</b> equipment from the NAND-type Flash Memory which carried out the test dependant on the outside <b>pattern</b> <b>test</b> equipment of hig...|$|R
40|$|In {{this work}} we propose a novel concept called state tuple to {{represent}} the states of lines in a circuit for the generation of two <b>pattern</b> <b>tests.</b> The proposed approach is described in detail for generating robust two <b>pattern</b> <b>tests</b> for path delay faults in standard scan designs. Using the proposed approach we also report experimental results of a test generator for robust path delay faults in standard scan designs. The {{results show that the}} test generator achieves high efficiency with reduced implementation complexity. 1...|$|E
30|$|Floor {{patterns}} were found lacking {{in many of}} the fire <b>pattern</b> <b>tests</b> where the compartment transitioned to a fully involved state (Shanley et al. 1997; Wood et al. 2012; Mealy et al. 2013). However, some data exists that indicates if a compartment fire does not transition to a fully involved state, then the floor patterns may persist (Putorti 2001; Mealy et al. 2013).|$|E
40|$|Two {{well known}} data sets {{are used in}} this article to show that {{practical}} procedures of statistical process control can be made more effective by drawing on ideas of time series analysis. In particular, time series plots, simple time series modeling, and outlier detection {{are found to be}} useful in identifying possible common and special causes in a process that are likely to be overlooked by traditional control charts and in avoiding false identifications of special causes. We also discuss the use of <b>pattern</b> <b>tests</b> in conjunction with control charts...|$|E
50|$|A notable {{value is}} that the {{architectural}} system consists only of classic <b>patterns</b> <b>tested</b> {{in the real world}} and reviewed by multiple architects for beauty and practicality.|$|R
40|$|Present System on Chip (SOC) {{complexity}} {{has brought}} new challenges in volume of <b>test</b> <b>pattern,</b> low power <b>testing</b> and area complexity. This {{also shows that}} implementing huge <b>test</b> <b>pattern</b> and its corresponding storage space are the major problems. Due to this large number of <b>test</b> <b>patterns</b> the data transition time is also increased. This paper considers this problem in scan based <b>test</b> <b>pattern.</b> This proposed approach {{is based on the}} compression of huge <b>test</b> <b>pattern</b> by weighted bit position. Test patterns with unspecified bits are considered for specified values and partitioned into necessary weighted value. Depending upon weighted bit position specified test bit is compressed. This in turn reduces the <b>test</b> <b>pattern</b> for scan based testing. The proposed technique tested on ISCAS 89 shows significant compression achieved on scan based <b>test</b> <b>pattern...</b>|$|R
50|$|Light spot <b>patterns</b> <b>testing</b> {{the central}} 24 degrees or 30 degrees {{of the visual}} field, are most {{commonly}} used. Most perimeters are also capable of testing up to 80 or 90 degrees.|$|R
30|$|Table 1 {{shows the}} results of <b>pattern</b> <b>tests</b> between the three methods {{presented}} in this article. It {{can be seen that}} all three methods correctly detected the reference image whose content is present on the TV screen. It should be noted that LAE method measured the dissimilarity of the two images, while NCC and NCC-BB methods measure the similarity of the two images. Hence, the correct image has the lowest score under LAE, highest score under NCC and the score closest to 0 under NCC-BB method, because the NCC-BB score is relative to the golden sample which has the score 0.|$|E
40|$|International audienceWhen stuck-at faults are targeted, scan design {{reduces the}} {{complexity}} of the test problem. But for delay fault testing, the standard scan structures are not so efficient, because delay fault testing requires the application of dedicated consecutive two-pattern tests. In a standard scan environment, pre-determined two <b>pattern</b> <b>tests</b> cannot be applied to the circuit under test because of the serial shifting procedure. In the literature, different scan modification possibilities have been proposed for applying delay fault oriented deterministic test patterns. Another issue to the delay fault testing problem in scan-based sequential circuits is presented in this paper. The solution combines a BIST structure with the standard scan design...|$|E
30|$|To {{model the}} {{temporal}} regularity of crime, most approaches {{in the literature}} use time-series analysis and its various tools such as spectral analysis [33 – 37], spatial correlation [38], regression analysis [39 – 57], cross correlation [58], and spatial point <b>pattern</b> <b>tests</b> [59 – 61]. These approaches assume a temporal regularity of crime activity limited within fixed regional localities. In these works, crime regularities {{have been shown to}} exist in city-level and local-level [59 – 68] time series under the common assumption that crime’s temporal regularities are stationary (i.e., the covariance of the time series remains constant over time). This stationary assumption implies that the urban dynamics in all regions across the city remains constant.|$|E
40|$|International audienceThe optical IR-OBIRCh {{technique}} {{is a standard}} failure analysis tool used to localize defects that are located at interconnects layers levels. For a functional logic failure, a failing <b>test</b> <b>pattern</b> is used to condition the device into a particular logic state to generate the failure. Commonly, the defect is detected {{for a set of}} <b>test</b> <b>patterns.</b> All <b>test</b> <b>patterns</b> will not provide the same IR-OBIRCh response. A random selection of <b>test</b> <b>patterns</b> may not lead to localize the defect by IR-OBIRCh technique or give fake results. We have performed an extended study of IR-OBIRCh response of a functional logic failure in function of <b>test</b> <b>patterns.</b> Based on these results a best <b>test</b> <b>pattern</b> failure analysis flow has been developed and implemented in order to localize a functional logic failure with IR-OBIRCh technique...|$|R
5000|$|... #Caption: [...] HD-MAC <b>test</b> <b>pattern</b> {{similar to}} the B-MAC <b>test</b> <b>pattern</b> ...|$|R
50|$|A defect is {{an error}} caused in a device during the {{manufacturing}} process. A fault {{model is a}} mathematical description of how a defect alters design behavior. The logic values observed at the device's primary outputs, while applying a <b>test</b> <b>pattern</b> to some device under test (DUT), are called the output of that <b>test</b> <b>pattern.</b> The output of a <b>test</b> <b>pattern,</b> when <b>testing</b> a fault-free device that works exactly as designed, is called the expected output of that <b>test</b> <b>pattern.</b> A fault {{is said to be}} detected by a <b>test</b> <b>pattern</b> if the output of that <b>test</b> <b>pattern,</b> when <b>testing</b> a device that has only that one fault, is different than the expected output. The ATPG process for a targeted fault consists of two phases: fault activation and fault propagation. Fault activation establishes a signal value at the fault model site that is opposite of the value produced by the fault model. Fault propagation moves the resulting signal value, or fault effect, forward by sensitizing a path from the fault site to a primary output.|$|R
40|$|Preliminary antenna <b>pattern</b> <b>tests</b> were {{conducted}} to determine if catastrophic effects were produced by cables (conducting) in the aperture. This test consisted of an apex feed illuminating a 3 meter solid reflector. A hoop/column configuration was used in positioning the various wires and cables. Radiation patterns were measured at 7 GHz and 10 GHz. No catastrophic effects were observed for this configuration, but additional tests are required {{to determine the effects}} for more precision multiple beam applications. In order to better understand the scattering and blockage effects on multiple beam performance, a 35 GHz model was used to model somewhat a single quad aperture configuration. Experimental results using this models are presented in graphs...|$|E
30|$|The fire testing {{conducted}} for fire patterns has evolved {{with the changing}} definition of the term. As such, a subsection on testing is first presented to describe all fire <b>pattern</b> <b>tests</b> conducted, not just those evaluating the current use of the term. The tests were typically conducted to evaluate multiple aspects of using damage for origin determination and not just {{within the context of}} clusters of damage, therefore, many of these tests will describe fire effects, clusters of fire effects, fire pattern generation and the use of fire patterns to arrive at an area of origin. The tests will be summarized chronologically in this section and will be referred to in other sections of the literature review where the work specifically addresses that subject matter.|$|E
40|$|Approved {{for public}} release; {{distribution}} is unlimitedAn exoskeleton platform was developed, prototyped and tested for mobility {{performance in a}} beachfront environment. New platform, drive-train, motor-controller and wheel design were employed in the experiment. The objective was to improve on the shortcoming of previous NPS research. Three wheel-designs were tested during fixed <b>pattern</b> <b>tests</b> on grass, concrete and sand. Data suggests that, with regard to power consumption, there is a marginal difference on preferred wheel design. The sparse print round wheel showed promise in heavy vegetation; however, the WhegTM wheel {{proved to be the}} most versatile on various terrains. This suggests that a WhegTM wheel with improved round wheel characteristics would be optimal for various beachfront terrains. Lieutenant, United States Nav...|$|E
40|$|Abstract—Modern {{diagnosis}} algorithms {{are able}} to identify the defective circuit structure directly from existing fail data without being limited to any specialized fault models. Such algorithms however require <b>test</b> <b>patterns</b> with a high defect coverage, posing a major challenge particularly for embedded testing. In mixed-mode embedded test, a large amount of pseudo-random (PR) patterns are applied prior to deterministic <b>test</b> <b>pattern.</b> Partial Pseudo-Exhaustive <b>Testing</b> (P-PET) replaces these pseudo-random <b>patterns</b> during embedded <b>testing</b> by partial pseudo-exhaustive <b>patterns</b> to <b>test</b> a large portion of a circuit fault-model independently. The overall defect coverage is optimized compared to random testing or deterministic tests using the stuck-at fault model while maintaining a comparable hardware overhead and the same test application time. This work for the first time combines P-PET with a fault model independent diagnosis algorithm and shows that arbitrary defects can be diagnosed on average much more precisely than with standard embedded testing. The results are compared to random <b>pattern</b> <b>testing</b> and deterministic testing targeting stuck-at faults. Keywords—BIST, Pseudo-Exhaustive Testing, Diagnosis, De-bug I...|$|R
40|$|Programmable mixed–mode BIST schemes combine pseudo–random <b>pattern</b> <b>testing</b> and {{deterministic}} test. This paper {{presents a}} synthesis technique for a mixed–mode BIST scheme which {{is able to}} exploit the regularities of a deterministic <b>test</b> <b>pattern</b> set for minimizing the hardware overhead and memory requirements. The scheme saves more than 50 % hardware costs compared with the best schemes known so far while complete programmability is still preserved...|$|R
40|$|In {{digital system}} design, <b>test</b> <b>pattern</b> {{generation}} requires {{a considerable amount}} of computing time. Using a level-sensitive scan design, <b>test</b> <b>pattern</b> generation can be confined to the combinational circuits. It has been shown that the problem of <b>test</b> <b>pattern</b> generation for combinational circuits is NP-complete. Although many excellent algorithms have been developed to generate <b>test</b> <b>patterns,</b> they still do not keep pace with VLSI technology. Research is ongoing in the development of parallel processing techniques for <b>test</b> <b>pattern</b> generation, but there has been little research into what kind of topology has the greatest potential to speed up <b>test</b> <b>pattern</b> generation. [...] In this work, simulation software was developed for measurement of the speedup, and three topologies are proposed to explore the parallelism for automatic <b>test</b> <b>pattern</b> generation. These topologies are: modified complete binary tree (MCBTA), autonomous modified complete binary tree (AMCBTA), and square array structure (SQARRAY). The empirical results for these topologies show that a special topology has the potential capability to speed up <b>test</b> <b>pattern</b> generation and super-linear speedup can often result if an autonomous structure is adopted...|$|R
40|$|Little {{evidence}} {{exists on the}} possible adverse effects of styrene on {{the central part of}} the auditory system. The present investigation aimed to study the possible association between styrene exposure and temporal processing abilities. Fifty-nine styrene-exposed subjects and 50 nonexposed control subjects were tested. Pure-tone audiometry (125 – 8000 Hz) and 3 temporal processing tests (gaps-in-noise, frequency pattern test and duration pattern test) were carried out. Significant differences between groups were found for most of the audiometric thresholds for both ears. ANCOVA analysis showed that styrene-exposed subjects had significantly poorer performances on the frequency and duration <b>pattern</b> <b>tests</b> than nonexposed subjects, when including hearing level and age as covariates. The results of the present research study suggest an association between styrene exposure and central auditory dysfunction characterized by a temporal processing disorder...|$|E
40|$|We {{propose a}} novel Design for Testability {{technique}} to apply two <b>pattern</b> <b>tests</b> for path delay fault testing. Due to stringent timing requirements of deep-submicron VLSI chips, design-for-test schemes {{have to be}} tailored for detecting stuck-at as well as delay faults quickly and efficiently. Existing techniques such as enhanced scan add substantial hardware overhead, whereas techniques such as scan-shifting or functional justification make the test generation process complex and produce lower coverage for scan based designs as compared to non-scan designs. We exploit the characteristics of CMOS circuitry to enable the application of two-pattern tests. The proposed technique reduces the problem of path delay fault testing for scan based designs to that of path delay fault testing with complete accessibility to the combinational logic, and has minimal area overhead. The scheme also provides significant reduction in power during scan operation. 1...|$|E
40|$|LTE {{deployment}} {{is being}} accelerated {{due to its}} improved radio access structure meeting the requirements of current and next generation of wireless networks. Its low band application presents useful aspects such as low density of base station while providing good in-building penetration. In this work, we design and develop a dual-polarized base station antenna supporting 698 [*]MHz to 960 [*]MHz with an azimuth-plan half-power beam width of 90 ° covering all mainstream LTE 700 / 800 / 900 [*]MHz frequency bands representing the widest low frequency range being actively used in the current mobile communication industry. In the design process, rigorous algorithm based on swarm method is developed to tune the electrical performances under strict base station antenna requirements. Experimental results from <b>pattern</b> <b>tests</b> demonstrate the design analysis and the significant advantages of using swarm method in the antenna development process...|$|E
40|$|The aim of {{this study}} is to {{implement}} enhanced test data compression of conflict bit using clustering technique. Huge <b>test</b> <b>patterns,</b> larger power consumption and more accessing time are the various challenges encountered by present System on Chip (SOC) design. Various compression techniques have been developed to minimize the huge <b>test</b> <b>patterns</b> by reducing the size of the data which saves space and transmission time. Test quality of the <b>test</b> <b>pattern</b> can be improved by test data compression. By finding the proper conflict bit (‘U’) the proposed algorithm generates <b>test</b> <b>patterns</b> having high reduction in test compression. Small numbers of <b>test</b> <b>patterns</b> are generated using clustering technique. With proper <b>test</b> <b>pattern</b> clustering it is possible to achieve high level of compression. Validation of the proposed method is found by experimental results on ISCAS’ 89 and shows that compression ratio is achieved by 79 % with less conflict <b>test</b> <b>pattern...</b>|$|R
40|$|Present System-on-Chip (SoC) {{contains}} various design {{models and}} all the design components are integrated into single Integrated Chip (IC). Thus total volume of SoC <b>test</b> <b>pattern</b> is also growing in complex manner. This huge <b>test</b> <b>pattern</b> also invokes various challenges in switching power, memory space and accessing time. The problem on huge <b>test</b> <b>pattern</b> involved for scan based testing is focused in this research. Coloring algorithm is proposed to compact <b>test</b> <b>pattern.</b> Utilization of unspecified <b>test</b> <b>pattern</b> promises more compaction in coloring algorithm. This proposed method never contains any extra silicon area overhead. Due to this advantage, proposed technique is more suitable for reduction of <b>test</b> <b>pattern.</b> An experimental result produces significant reduction in above said problems and tested with ISCAS 89 benchmark circuits...|$|R
40|$|I {{am pleased}} to submit this {{analysis}} of a new method for nozzle spray <b>pattern</b> <b>testing</b> and some test results obtained using this system. This report consists of recommending an alternative nozzle <b>pattern</b> <b>testing</b> system, that would be both automated and more efficient. The basis for the recommendation comes {{from the results of}} several analyses of criteria I established for a feasible system. The proposed system will collect data faster than the current system while maintaining a relatively low cost. Several tests have already been conducted with the results of these tests are also included. included testing a wide variety of nozzle types for wear on the spray pattern uniformity. the system and The research the effects of Respectfully submitted...|$|R
