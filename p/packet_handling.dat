58|165|Public
5000|$|Packets {{are less}} likely to be re-ordered, while out of order <b>packet</b> <b>handling</b> might be a {{bottleneck}} otherwise.|$|E
5000|$|Hardware {{support for}} <b>packet</b> <b>handling,</b> data buffering, burst transmissions, data encryption, data authentication, clear channel assessment, link quality {{indication}} and packet timing information ...|$|E
50|$|The P3 family {{processors}} {{share the}} same physical package with, and are also software backwards compatible with, P4 and P5. The P3 processors have 1.3 GHz 64-bit DDR3 memory controllers, 18 SerDes lanes for networking, hardware accelerators for <b>packet</b> <b>handling</b> and scheduling, regular expressions, RAID, security, cryptography and RapidIO.|$|E
50|$|Deep packet {{inspection}} {{of all the}} <b>packets</b> <b>handled</b> by ALGs over a given network makes this functionality possible. An ALG understands the protocol used by the specific applications that it supports.|$|R
40|$|Abstract: In general, a <b>packet</b> filter <b>handles</b> {{incoming}} pack-ets {{according to}} a set of rules. This paper show that the order of rules is critical to the performance of filters that use the linear search algorithm to <b>handle</b> <b>packets.</b> To reduce the fil-tering delay, a rule-order optimization problem is formulated. A simple algorithm to solve this problem is also proposed. 1...|$|R
30|$|Runs {{the event}} loop, takes commands, deals out data <b>packets,</b> and <b>handles</b> {{everything}} in the back-end including user interruption and other control and configuration commands.|$|R
50|$|Make a {{reservation}} {{based on the}} request parameters. For this the admission control and policy control process the request parameters and can either instruct the packet classifier to correctly handle the selected subset of data packets or negotiate with the upper layer how the <b>packet</b> <b>handling</b> should be performed. If they cannot support the reservation being requested, they send a reject message to let the listener know about it.|$|E
50|$|As Gerald {{tries to}} {{describe}} the things around him in painstaking detail, he recounts simultaneous conversations and events as they happen by using a format similar to data <b>packet</b> <b>handling.</b> After describing {{a small part of}} a situation or a conversation, he moves on to a small part of a different conversation, then returns to the first conversation, or maybe moves on to a third or a fourth, returning each time to try to be as accurate as possible while recording the events.|$|E
50|$|The P5 {{series is}} based on the high {{performance}} 64-bit e5500 core scaling up to 2.5 GHz and allowing numerous auxiliary application processing units as well as multi core operation via the CoreNet fabric. The P5 series processors share the same physical package and are also software backwards compatible with P3 and P4. The P5 processors have 1.3 GHz 64-bit DDR3 memory controllers, 18 SerDes lanes for networking, hardware accelerators for <b>packet</b> <b>handling</b> and scheduling, regular expressions, RAID, security, cryptography and RapidIO.|$|E
50|$|At nodes where {{multiple}} outgoing links are available, {{the choice}} of which, all, or any to use for forwarding a given packet requires a decision making process that, while simple in concept, is sometimes bewilderingly complex. Since a forwarding decision must be made for every <b>packet</b> <b>handled</b> by a node, the total time required for this can become a major limiting factor in overall network performance. Much of the design effort of high-speed routers and switches {{has been focused on}} making rapid forwarding decisions for large numbers of packets.|$|R
5000|$|Null adjacency: <b>Handles</b> <b>packets</b> {{destined to}} a NULL interface. Packets with FIB entries {{pointing}} to NULL adjacencies will normally be dropped.|$|R
50|$|Protocols such as User Datagram Protocol (UDP) {{provide no}} {{recovery}} for lost packets. Applications that use UDP {{are expected to}} define their own mechanisms for <b>handling</b> <b>packet</b> loss.|$|R
5000|$|The railway {{junction}} {{was destroyed in}} an air raid on 22 February 1945. This failed, however, to damage the station area, except for {{an apartment in the}} station building, the [...] "Lm" [...] signal box and the building of the track master (Bahnmeisterei); these were later rebuilt. However, houses were hit near the station. The air raid killed about 150 people in Ludwigslust. [...] The station’s central signal box [...] "B 1" [...] was opened in 1957. Deutsche Post opened a <b>packet</b> <b>handling</b> facility at the station on 27 May 1962 and, from 31 May 1964, all parcels between the three northern districts of German Democratic Republic, Neubrandenburg, Rostock and Schwerin and the Federal Republic of Germany were handled here. The facility, which had its own railway sidings, operated until 1993. The station post office, established in 1913, was later closed. The second mainline track between Wittenberg and Schwerin was rebuilt after 1980.|$|E
40|$|Currently, {{preferential}} <b>packet</b> <b>handling</b> in {{transport networks}} is based solely upon application-level Quality of Service (QoS) requirements. No preferential <b>packet</b> <b>handling</b> {{is based upon}} the importance of the information being carried by the network. In future transport networks, <b>packet</b> <b>handling</b> should provide preferential transport to important, high precedence traffic, specifically during conditions of resource scarcity, e. g., network overload conditions, while simultaneously satisfying packet scheduling required to meet application QoS needs. We propose and analyze an approach to supporting both Precedence and Preemption (P&P) and QoS handling in common transport infrastructures. Precedence {{has to do with the}} relative importance of the information content while preemption has to do with mechanisms to deny lower precedence traffic access to network resources in favor of higher precedence traffic, when necessary. Our approach to this duality is to enhance Active Queue Management (AQM) techniques to provide P&P capabilities and rely upon standard, well studied QoS schedulers, e. g., Weighted Round Robin, Class-Based Fair Queuing, etc., for handling QoS requirements. We refer to this combination as a Precedence-Enabled Per Hop Behavior (PHB). In this way, when operating under engineered loads, the well known scheduling algorithms support high quality QoS for applications. Under network congestion situations, the enhanced AQM layer provides the necessary P&P preferential <b>packet</b> <b>handling</b> favoring high Precedence-Level (P-L) information. Our scheme allows low order queues (within the context of QoS handling) to plead up to the next higher order queue for help in alleviating queue congestion under periods of communication link overload. We refe...|$|E
40|$|Abstract—This paper proposes {{cooperative}} opportunistic routing (COR), a throughput improvement {{scheme for}} the cooperative opportunistic routing in multi-hop wireless mesh networks (WMNs). We investigate {{the two major}} issues in opportunistic routing, the selection and the prioritization metric for the candidate set. The COR is presented to select and prioritize the candidate node with minimum expected cost. This candidate selection with low expected cost on each transmission constructs a throughput efficient routing path. The COR’s robust <b>packet</b> <b>handling</b> strategy is also proposed to avoid duplicated transmission without forwarding list. With more efficient candidate set and <b>packet</b> <b>handling,</b> the average throughput improves by 76 % and the end-to-end delay is reduced by 15 % in our simulation results. Keywords-wireless mesh network; opportunistic routing; forwarding list; wireless routing. I...|$|E
40|$|Abstract — How are future {{communication}} {{networks to}} cope with everincreasing traffic demands? Currently, data (e. g. IP <b>packets)</b> <b>handled</b> in the back-bone network is transported optically, yet is switched electronically. Being a demanding and power-consuming process, current switches are becoming the bottleneck in the network. More recent techniques, such as Optical Packet Switching (OPS) and Optical Burst Switching (OBS), can alleviate this problem. In the research community’s search for effective architectures, understanding the functioning of optical buffers is crucial. My PhD research focuses on the analysis and performance evaluation of optical buffers. Extensive use of probability generating functions allows to incorporate several environment aspects in a single stochastic model. Results elucidate the behaviour of a specific switch implementation, and lead to optimal constellations of the involved design parameters. Further research aims at results for (i) traffic assumptions that are less stringent and (ii) switch architectures of higher complexity. Keywords—fiber delay lines; optical buffers; stochastic modelling I...|$|R
40|$|In this letter, {{we propose}} a new routing {{strategy}} {{with a single}} free parameter α only based on local information of network topology. In order to maximize the <b>packets</b> <b>handling</b> capacity of underlying structure that can be measured by the critical point of continuous phase transition from free flow to congestion, the optimal value of α is sought out. By investigating the distributions of queue length on each node in free state, we give an explanation why the delivering capacity of the network can be enhanced by choosing the optimal α. Furthermore, dynamic properties right after the critical point are also studied. Interestingly, {{it is found that}} although the system enters the congestion state, it still possesses partial delivering capability which do not depend on α. This phenomenon suggests that the capacity of the network can be enhanced by increasing the forwarding ability of small important nodes which bear severe congestion. Comment: 4 pages, 7 figure...|$|R
50|$|Rule {{that governs}} how <b>packets</b> are <b>handled</b> within a diffserv network {{is called the}} Per-Hop Behavior (PHB).PHBs are defined to support the general {{properties}} controlled by IP precedence. DSCP Contains 6-bits, PHBs are created (one for each combination of the top 3 bits) of the form bbb000 to match the precedence behaviors and leaves the other DSCP values open where each b may take the value zero or 1.|$|R
30|$|The packet sender module {{scans the}} shared {{circular}} output buffer of the <b>packet</b> <b>handling</b> modules and sends packets, which are labeled as ready, to their next hop. It also {{takes care of}} pending packets, which are missing their next hops. It scans the LocT to find an appropriate next hop.|$|E
40|$|The primary {{audiences for}} this {{reference}} architecture (RA) are architects and engineers evaluating Intel ® architecture based solutions for cloud based network services where packet processing performance {{is a key}} requirement. Process affinity and IRQ affinity strategies can have a dramatic impact on <b>packet</b> <b>handling</b> performance including the variability of throughput. This document provides an analysis and of underlying Linux kernel tasks for KVM bridged networks. A generalized affinitization rule set is proposed for a multi-VM environment with Linux KVM. Details for configuring and testing a virtualized packet processing environment are provided. The platform is Linux * KVM on an ATCA Reference Platform with Intel ® Xeon® Processor E 5 - 2600 and Intel ® 82599 10 Gigabit Ethernet Controller. Performance results only apply to the target platform; however the test methodology and optimization learnings are generally applicable to <b>packet</b> <b>handling</b> solutions using Linux * KV...|$|E
30|$|Although DQS and Semi-TCP {{have been}} {{developed}} independently, the joint effect of the two schemes has not been investigated. Some issues remain open in the joint QoS provisioning and congestion control scheme for multi-hop wireless networks. In this section, we discuss {{the issues of the}} delay estimation, overdue <b>packet</b> <b>handling,</b> the ACK mechanism, and the cross-layer design for the joint scheme.|$|E
50|$|Over time, {{there was}} a {{consolidation}} of packet stations. Most routes were transferred to Southampton, which had been linked to London by railway. Other ports <b>handling</b> <b>packets</b> include Liverpool (from 1840) and Plymouth (from 1850).|$|R
40|$|Virtualization {{is the key}} {{technology}} of cloud computing. Network virtualization {{plays an important role}} in this field. Its performance is very relevant to network virtualizing. Nowadays its implementations are mainly based on the idea of Software Define Network (SDN). Open vSwitch is a sort of software virtual switch, which conforms to the OpenFlow protocol standard. It is basically deployed in the Linux kernel hypervisor. This leads to its performance relatively poor because of the limited system resource. In turn, the packet process throughput is very low. In this paper, we present a Cavium-based Open vSwitch implementation. The Cavium platform features with multi cores and couples of hard ac-celerators. It supports zero-copy of <b>packets</b> and <b>handles</b> <b>packet</b> more quickly. We also carry some experiments on the platform. It indicates that we can use it in the enterprise network or campus network as convergence layer and core layer device...|$|R
40|$|Protecting control {{planes in}} {{networking}} hardware from high rate packets {{is a critical}} issue for networks under operation. One common approach for conventional networking hardware is to offload expensive functions onto hard-wired offload engines as ASICs. This approach is inadequate for OpenFlow networks because it restricts {{a certain amount of}} flexibility for network control that OpenFlow tries to provide. Therefore, we need a control plane protection mechanism in OpenFlow switches as a last resort, while preserving flexibility for network control. In this paper, we propose a mechanism to filter out Packet-In messages, which include <b>packets</b> <b>handled</b> by the control plane in OpenFlow networks, without dropping important ones for network control. Switches record values of packet header fields before sending Packet-In messages, and filter out packets that have the same values as the recorded ones. The controllers set the header fields in advance whose values must be recorded, and the header fields are selected based on controller design. We have implemented and evaluated the proposed mechanism on a prototype software switch, concluding that it dramatically reduces CPU loads on switches while passes important Packet-In messages for network control...|$|R
30|$|LocTEs {{are created}} by <b>packet</b> <b>handling</b> modules and {{maintained}} by the LocT management service. The location table management module checks the validity of LocTEs by comparing the timestamp field of the LocTEs with the current timestamp. The location table management module is also responsible of updating the self position information. Basically it gets the position information from the simulation API and applies the cartesian to geodesic conversion, which is discussed in detail, in Section 1.|$|E
40|$|The “Software for CC 1100 /CC 2500 and MSP 430 - Examples and Function Library ” is the {{recommended}} {{starting point for}} developing software for the CC 1100 /CC 2500 and MSP 430 combination. The software demonstrates how {{to use some of}} the many advanced digital features and <b>packet</b> <b>handling</b> capabilities of the CC 1100 /CC 2500. The software examples have been developed for the MSP 430 Experimenter’s Board, but can easily be ported to another hardware platform...|$|E
40|$|We propose FlexNIC, a {{flexible}} network DMA interface {{that can be}} used by operating systems and applications alike to reduce packet processing overheads. The re-cent surge of network I/O performance has put enormous pressure on memory and software I/O processing sub-systems. Yet even at high speeds, flexibility in <b>packet</b> <b>handling</b> is still important for security, performance iso-lation, and virtualization. Thus, our proposal moves some of the packet process-ing traditionally done in software to the NIC DMA con-troller, where it can be done flexibly and at high speed. We show how FlexNIC can benefit widely used data cen-ter server applications, such as key-value stores. ...|$|E
40|$|Software-defined {{networking}} (SDN) is a {{new paradigm}} for oper-ating and managing computer networks. SDN enables logically-centralized control over network devices through a “controller ” — software that operates independently of the network hardware. Net-work operators can run both in-house and third-party SDN programs {{on top of the}} controller, e. g., to specify routing and access control policies. In practice, having the controller handle events limits the network scalability. Therefore, the feasibility of SDN depends on the ability to efficiently decentralize network event-handling by installing forwarding rules on the switches. However, installing a rule too early or too late may lead to incorrect behavior, e. g., (1) packets may be forwarded to the wrong destination or incorrectly dropped; (2) <b>packets</b> <b>handled</b> by the switch may hide vital information from the controller, leading to incorrect forwarding behavior. The second issue is subtle and sometimes missed even by experienced programmers. The contributions of this paper are two fold. First, we formalize the correctness and optimality requirements for decentralizing network policies. Second, we identify a useful class of network policies which permits automatic synthesis of a controller which performs optimal forwarding rule installation...|$|R
30|$|The Channel module of the {{simulator}} <b>handles</b> <b>packet</b> transmissions {{and models}} the propagation loss by means four different phenomena as suggested in[35]: (i) the path loss, (ii) the penetration loss, (iii) the shadowing, and (iv) the fast fading {{due to the}} signal multipath.|$|R
5000|$|Receive adjacency: This type {{of entry}} <b>handles</b> <b>packets</b> whose final {{destinations}} include the router itself. This includes packets whose IP addresses {{are assigned to}} the router itself, broadcast packets, and multicasts that have set up the router itself {{as one of the}} destinations.|$|R
40|$|Alias sctp is {{part the}} SONATA[1] project {{to develop and}} release a BSD {{licensed}} implementation of a Network Address Translation (NAT) module that supports the Stream Control Transmission Protocol (SCTP). Traditional address and port number look ups are inadequate for SCTP’s operation. A design of the operational states and <b>packet</b> <b>handling</b> necessary to achieve SCTP functionality are outlined along with the necessary modifications required to integrate it into FreeBSD’s ipfw/libalias NAT system. Alias sctp version 0. 1 uses unique verification tag and port numbers for NAT, providing support of global multi-homing, T-flagged packets, logging and statistics, timing, and two association shutdown modes...|$|E
40|$|Differentiated {{services}} {{architecture is}} receiving wide attention as a scalable mechanism for providing {{different levels of}} Quality-of-Service (QOS). Recent studies, both analytical and simulation-based, {{have shown that the}} provided bandwidth in such an architecture may differ from the contracted rates. In this paper, we propose an active resource management approach that brings the provided service closer to the target rates. The proposed approach, SACRIO, actively allocates available excess bandwidth through localized packet remarking within a router. It is shown that SACRIO is simple to implement within the diff-serv architecture. It is also shown that the <b>packet</b> <b>handling</b> cost remains O(1) with SACRIO. SACRIO is shown to be quite effective through simulations...|$|E
30|$|The {{prioritized}} video <b>packet</b> <b>handling</b> {{is accomplished}} by placing the incoming video packets into the video queues based on their type (e.g., SVC BL or EL) with a packet classifier, and triggering the video scheduler every time the video category is granted access to the medium by EDCA. The number of additional video queues used depends {{on the level of}} video packet differentiation required in the system. When invoked, the video scheduler selects the next video packet for transmission considering factors like the type of each Head of Line (HOL) video packet, the time the packet has spent in the queue, and whether there are higher priority video packets currently stored in the queues.|$|E
5000|$|Error {{recovery}} procedures at {{the packet}} layer {{assume that the}} data link layer is responsible for retransmitting data received in error. <b>Packet</b> layer error <b>handling</b> focuses on resynchronizing the information flow in calls, as well as clearing calls that have gone into unrecoverable states: ...|$|R
40|$|Routing {{is a black}} art in today's Internet. End {{users and}} ISPs alike have little control over how their <b>packets</b> are <b>handled</b> outside of their networks, {{stemming}} in part from limitations of the current wide-area routing protocol, BGP. We believe {{that many of these}} constraints are due to policy-based restrictions on route exportation. Separating forwarding policy from route discovery would allow users to select among the possibly many inter-AS paths available to them and enable ISPs to more effectively manage the end-to-end behavior of their customers' traffic...|$|R
50|$|The IP-MPLS {{approach}} aims at providing guaranteed services {{over the}} Internet Protocol using {{a multitude of}} networking protocols to create, maintain and <b>handle</b> <b>packet</b> data streams. While this approach solves the problem, it inevitably also creates {{a great deal of}} complexity, as well as what some argue is poorer network utilization.|$|R
