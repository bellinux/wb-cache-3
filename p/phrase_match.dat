3|133|Public
50|$|Negative {{keywords}} {{are often}} necessary for paid search campaigns that contain keywords on either broad match or <b>phrase</b> <b>match.</b> These match types will display your ad for additional search queries (i.e. search queries {{other than the}} actual keyword that {{was added to the}} account). Thus, removing irrelevant terms often becomes necessary.|$|E
50|$|When the ad spot {{is part of}} {{a search}} engine results page (SERP), the {{automated}} auction takes place whenever a search for the keyword that is being bid upon occurs. All bids for the keyword that target the searcher's Geo-location, the day and time of the search, etc. are then compared and the winner determined. In situations where there are multiple ad spots, a common occurrence on SERPs, there can be multiple winners whose positions on the page are influenced by the amount each has bid. The bid and Quality Score are used to give each advertiser's advert an ad rank. The ad with the highest ad rank shows up first. The predominant three match types for both Google and Bing are broad, exact and <b>phrase</b> <b>match.</b> Google also offers the broad modifier match type which differs from broad match in that the keyword must contain the actual keyword terms in any order and doesn't include relevant variations of the terms.|$|E
40|$|A unification-based grammar {{is a type}} of {{language}} description well suited for the implementation on a computer. As many other contemporary grammar theories, almost all the unification-based ones advocate the usage of a set of phrase structure rules to describe how acceptable utterances are formed in a particular language. The constituents of the rules are annotated with a set of features. Rules may be applied to phrases only if the structure of a rule and a <b>phrase</b> <b>match</b> each other, or in other words, if they unify. That is, if their features only take on values of the same types and within the same ranges. The thesis describes the implementation of a large-scale unification-based grammar for Swedish. Part of the text is devoted to the more theoretical and linguistic sides, discussing all the different grammar rules, while concentrating the main effort on the treatment of verb phrases. Another part addresses a range of different application areas in which a language processing system eq [...] ...|$|E
40|$|We {{present a}} system that enables {{flexible}} and efficient <b>phrase</b> <b>matching</b> in XML documents. Since XML allows structured and unstructured information to be interleaved, <b>phrase</b> <b>matching</b> in XML raises new challenges. Our system, named PIX, permits <b>phrase</b> <b>matching</b> in XML documents that contain "mixed content". A key feature of PIX is that users can specify which element and content to ignore when <b>matching</b> a <b>phrase.</b> PIX uses inverted indices and an efficient evaluation algorithm to compute the set of matches and returns answers where phrases, ignored tags and content are highlighted. In addition, query answers are sorted using a ranking function. PIX is implemented {{as an extension of}} GALAX, a full-fledged XQuery engine. The functionality of PIX is fully integrated into XQuery and permits a natural combination of XPath-based structure <b>matching</b> with <b>phrase</b> <b>matching...</b>|$|R
40|$|<b>Phrase</b> <b>matching</b> is {{a common}} IR {{technique}} to search text and identify relevant documents in a document collection. <b>Phrase</b> <b>matching</b> in XML presents new challenges as text may be interleaved with arbitrary markup, thwarting search techniques that require strict contiguity or close proximity of keywords. We present a technique for <b>phrase</b> <b>matching</b> in XML that permits dynamic specification of both the <b>phrase</b> to be <b>matched</b> and the markup to be ignored. We develop an effective algorithm for our technique that utilizes inverted indices on phrase words and XML tags. We describe experimental results comparing our algorithm to an indexed-nested loop algorithm that illustrate our algorithm's efficiency...|$|R
40|$|Abstract. Traditional <b>phrase</b> <b>matching</b> approaches, {{which can}} {{discover}} documents containing {{exactly the same}} phrases, fail to detect documents including phrases that are semantically relevant, but not exact matches. We propose a correlation-based <b>phrase</b> <b>matching</b> (CPM) model that can detect RSS news articles which contain not only phrases that {{are exactly the same}} but also semantically relevant, which dictate the degrees of similarity of any two articles. As the number of RSS news feeds continue to increase over the Internet, our CPM approach becomes more significant, since it minimizes the workload of the user who is otherwise required to scan through huge number of news articles to find related articles of interest, which is a tedious and often an impossible task. Experimental results show that our CPM model on matching bigrams and trigram...|$|R
40|$|INTRODUCTION XML {{permits the}} {{interleaving}} of text with structural and semantic markup in documents. Markup {{is added to}} a document by tagging {{a portion of the}} text or by augmenting the text with annotations. The example below is inspired from the XML documents published by the Library Of Congress (www. loc. gov). It describes legislative bills where bill sponsors are marked up using the tag , and an annotation is added to demarcate parenthetical remarks in the text. 110 th CONGRESS H. R. 133 Mr. English For himself and Mr. Coyne introduced this bill. In the absence of markup, <b>phrase</b> <b>matching</b> is a common technique to search text and identify relevant documents. <b>Phrase</b> <b>matching</b> typically requires that words in a phrase be contiguous or in close proximity. For example, searching for the phrase "Mr. English introduced this bill" could return very different results than searching fo...|$|R
40|$|Abstract. In {{this paper}} {{we present a}} textual {{retrieval}} system based on clustering and tiered indexes. Our system {{can be used for}} exact <b>phrase</b> <b>matching</b> and also for improved keyword search by employing term prox-imity weighting in the similarity measure. The document retrieval process is constructed in an efficient way, so that not all the documents in the database need to be compared against the searched query. 1...|$|R
50|$|Unlike {{some other}} chatterbots, Cleverbot's {{responses}} are not pre-programmed. Instead, it learns from human input: Humans type {{into the box}} below the Cleverbot logo and the system finds all keywords or an exact <b>phrase</b> <b>matching</b> the input. After searching through its saved conversations, it responds to the input by finding how a human responded to that input when it was asked, in part or in full, by Cleverbot.|$|R
40|$|In this paper, we {{describe}} an algorithm that employs syntactic and statistical analysis to extract bilingual collocations from a parallel corpus. The preferred syntactic patterns are obtained from idioms and collocations in a machine-readable dictionary. <b>Phrases</b> <b>matching</b> the patterns are extract from aligned sentences {{in a parallel}} corpus. Those <b>phrases</b> are subsequently <b>matched</b> up via cross-linguistic statistical association. Statistical association between the whole collocations as well as words in collocations is used jointly to link a collocation and its counterpart collocation in the other language. We experimented with an implementation of the proposed method on a very large Chinese-English parallel corpus with satisfactory results. 1...|$|R
40|$|The {{fundamental}} {{function of}} an information retrieval {{system is to}} retrieve texts or documents from a database {{in response to a}} user’s request for information, such that the content of the retreived documents will be relevant to the user’s original information need. This is accomplished through matching the user’s information request against the texts in the database in order to estimate which texts are relevant. In this thesis I propose a method for using current natural language processing techniques {{for the construction of a}} text representation to be used in an information retrieval system. In order to support this proposal I have designed a matching algorithm specifically for performing the retrieval task of matching user queries against texts in a database, using the proposed text representation. Having designed this text representation and matching algorithm, I then constructed an experiment to investigate the effectiveness of the algorithm at <b>matching</b> <b>phrases.</b> This experiment involved the use of standard statistical methods to compare the <b>phrase</b> <b>matching</b> capabilities of the proposed matching algorithm to a sample of information retrieval users performing the same task. The results of this evaluation experiment allow me to comment first of all on the effectiveness of the <b>phrase</b> <b>matching</b> algorihtm that I have designed and more generally, on the usefulness of incorporating natural language processing techniques into information retrieval systems...|$|R
40|$|One of {{the major}} {{components}} of the NASA/STI processing system is machine-aided indexing (MAI). MAI is a computer process that generates a set of indexing terms selected from NASA's thesaurus, is used for indexing technical reports, is based on text, and is reviewed by indexers. This paper summarizes the MAI objectives and discusses the NASA Lexical Dictionary, subject switching, and <b>phrase</b> <b>matching</b> or natural languages. The benefits of using MAI are mentioned, and MAI production improvement {{and the future of}} MAI are briefly addressed...|$|R
40|$|This paper {{presents}} a recognizer for identifying references to user interface components in online documentation. The recognizer first extracts <b>phrases</b> <b>matching</b> {{a list of}} known components, then employs a classifier to reject coincidental matches. We describe why this seemingly straightforward problem is challenging, then show how informal conventions in documentation writing can be leveraged to perform classification. Using the features identified in this paper, our approach achieves an average F 1 score of 0. 81, and can correctly distinguish between actual command references and coincidental matches in 93. 7 % of test cases...|$|R
40|$|Text {{structuring}} {{systems that}} provide links between text portions {{have been widely}} proposed as aids for text preparation and text manipulation. In principle, {{it is easy to}} follow available links between related text portions; it is much harder, however, to put in place useful links that relate document sections with related text content. An approach is described in this note for the automatic generation of content links based on global term and <b>phrase</b> <b>matches</b> between sentence and document texts. Tentative evaluation data are included to demonstrate the usefulness of the proposed procedures...|$|R
25|$|Elgar's {{personal}} {{identification with}} the theme is evidenced by his use of its opening <b>phrase</b> (which <b>matches</b> the rhythm and inflection of his name) as a signature in letters to friends.|$|R
40|$|This paper {{presents}} a noun phrase driven two-level {{statistical machine translation}} system. Noun phrases (NPs) are used as the unit of decomposition to build a two level hierarchy of phrases. English noun phrases are identified using a parser. The corresponding translations are induced using a statistical word alignment model. Identified noun phrase pairs in the training corpus are replaced with a tag to produce a NP tagged corpus. This corpus is then used to extract phrase translation pairs. Both NP translations and NP-tagged phrases are used in a two-level translation decoder: NP translations tag NPs in the first level, where NP-tagged <b>phrases</b> <b>match</b> across NPs to produce translations in the second level. The two-level system shows significant improvements over a baseline SMT system. It also produces longer <b>matching</b> <b>phrases</b> due to the generalization introduced by tagging NPs. 1...|$|R
40|$|No Fault Found (NFF) {{is a well}} {{discussed}} phenomenon {{within the}} maintenance sector but which requires work to quantify {{how much of an}} issue it may be and provide metrics by which it may be tracked and various approaches to its reduction evaluated. Previous studies have relied on expert classification to identify NFF, however this approach is time consuming and costly. Maintainer classification (MC), expert classification (RC), <b>phrase</b> <b>matching</b> (PM), and Bayesian matching (NBPM) are all evaluated and contrasted as methods to identify NFF. The results demonstrate the utility of all 4 methods and discusses their place within a maintenance ecosystem...|$|R
40|$|We {{demonstrate}} an XML {{full-text search}} engine that implements the TeXQuery language. TeXQuery {{is a powerful}} fulltext search extension to XQuery that provides a rich set of fully composable full-text primitives, such as <b>phrase</b> <b>matching,</b> proximity distance, stemming and thesauri. TeXQuery enables users to seamlessly query over both structure data and text, by embedding full-text primitives in XQuery and vice versa. TeXQuery also supports a flexible scoring construct that scores query results based on full-text predicates and permits top-k queries. TeXQuery is the precursor of the full-text language extension to XPath 2. 0 and XQuery 1. 0 currently being developed by W 3 C. 1...|$|R
40|$|Abstract. The paper {{presents}} several {{techniques for}} selecting noun phrases for interactive query expansion following pseudo-relevance feedback {{and a new}} phrase search method. A combined syntactico-statistical method {{was used for the}} selection of phrases. First, noun phrases were selected using a part-ofspeech tagger and a noun-phrase chunker, and secondly, different statistical measures were applied to select phrases for query expansion. Experiments were also conducted studying the effectiveness of noun phrases in document ranking. We analyse the problems of phrase weighting and suggest new ways of addressing them. A new method of <b>phrase</b> <b>matching</b> and weighting was developed, which specifically addresses the problem of weighting overlapping and non-contiguous word sequences in documents. ...|$|R
40|$|Exact <b>phrase</b> <b>matching</b> is a {{powerful}} tool to quickly retrieve results when a sufficient section of the text is accurately provided as the query. If {{the section of the}} text is not completely accurate, phrase searching will fail. A method must be used which will enforce strict enough conditions to achieve high accuracy while allowing for mistakes in the text provided. Here we develop a method using proximity conditions to search for quotes from movies and compare the results against the Vector Space Model. Initial results show a promising accuracy in excess of 78 % for documents being successfully ranked within the top ten results. 1...|$|R
5000|$|For example, {{a search}} {{could be used}} to find [...] "red brick house", and <b>match</b> <b>phrases</b> such as [...] "red house of brick" [...] or [...] "house made of red brick". By {{limiting}} the proximity, these <b>phrases</b> can be <b>matched</b> while avoiding documents where the words are scattered or spread across a page or in unrelated articles in an anthology.|$|R
40|$|This paper {{presents}} our ongoing work {{to automatically}} generate lyrics {{for a given}} melody, for phonetic languages such as Tamil. We approach the task of identifying the required syllable pattern for the lyric as a sequence labeling problem and hence use the popular CRF++ toolkit for learning. A corpus comprising of 10 melodies was used to train the system to understand the syllable patterns. The trained model is then used to guess the syllabic pattern for a new melody to produce an optimal sequence of syllables. This sequence is presented to the Sentence Generation module which uses the Dijkstra's shortest path algorithm {{to come up with}} a meaningful <b>phrase</b> <b>matching</b> the syllabic pattern. ...|$|R
40|$|UIC) {{participate}} in the robust track, which is a traditional ad hoc retrieval task. The emphasis is based on average effectiveness {{as well as individual}} topic effectiveness. Noun phrases in the query are identified and classified into 4 types: proper names, dictionary phrases, simple phrases and complex phrases. A document has a phrase if all content words in a phrase are within a window of a certain size. The window sizes for different types of phrases are different. We consider phrases to be more important than individual terms. As a consequence, documents in response to a query are ranked with <b>matching</b> <b>phrases</b> given a higher priority. WordNet is used to disambiguate word senses and bring in useful synonyms and hyponyms once the correct senses of the words in a query have been identified. The usual pseudo-feedback process is modified so that the documents are also ranked according to phrase and word similarities with <b>phrase</b> <b>matching</b> having a higher priority. Five runs which use either title or title and description have been submitted. 1...|$|R
40|$|Abstract. Many {{multimedia}} applications use {{the concept}} of hypertext {{as a means of}} relating textual components with associated data in a vanety of media forms. The hypertext concept facilitates one-to-one matching between lexical items (words) in text with equivalences in other data sources. User interface software thus provides access to related data by means of keyword or <b>phrase</b> <b>matching</b> techniques which are essentially lexical in nature. The problem with this approach is that a user is generally presented with a vast amount of information across a wider domain than is really required and which is often difficult to interpret. In this paper, we descnbe four natural language processing (NLP) techniques {{to improve the quality of}} the information presented to the user in a hypertext application called CDWord&trade;...|$|R
40|$|This {{paper is}} {{concerned}} with the use of linguistically motivated phrases as indexing terms in Information Retrieval applications. Apart from the conventional noun phrases, we propose to use verb phrases as index terms for text classification. Techniques for <b>phrase</b> <b>matching</b> through syntactic normalization and semantical matching are described. In particular, we show how to perform syntactic normalization of phrases in order to enhance recall. Semantical normalization is based on lexico-semantical relations, taking into account certain properties of the classification algorithms used. The ideas described here are being implemented in the Document Routing system DORO, in which statistical learning algorithms are applied to document profiles consisting of phrases. This paper describes the rationale behind work in progress, rather than presenting final results...|$|R
30|$|Pattern matching: <b>Phrase</b> that <b>matches</b> with “should”, “could”, “include”, “could have” or {{some with}} similar intent phrases are {{indicators}} of suggestions. We {{came up with}} a list of phrases, a thesaurus as shown in Table  2 through empirically observing students’ comments, similar to Brun and Hagege (2013).|$|R
40|$|Our {{system for}} the Japanese BC/EXAM subtasks in NTCIR- 10 RITE 2 is an {{extension}} of our previous system for NTCIR- 9 RITE. The new techniques are (1) Case-aware noun <b>phrase</b> <b>matching</b> using ontologies: The motivation of the feature is to capture finer syntactic structures than simple word matching. We uses ontologies to allow flexible <b>matching</b> of noun <b>phrases.</b> (2) Temporal expression matching after mapping historical entities to specific time intervals: The motivation of historical entity mapping is to expand the ca-pabilities of the temporal expression matching. From the experimental results, we found that the coverage {{is more important than the}} accuracy in the temporal entity map-ping. The scores of the formal runs were 74. 9 % (accuracy in BC) and 64. 5 % (accuracy in EXAM), which outperformed the baselines provided by the organizer...|$|R
50|$|A melody {{with good}} prosody will not assign long notes to {{relatively}} insignificant syllables, {{nor will it}} {{put them on the}} beat or give them any sort of accentuation. The musical <b>phrases</b> will <b>match</b> the grammatical <b>phrases,</b> so that musical pauses happen in places that would be natural for a speaker.|$|R
40|$|We present {{evidence}} that head-driven parsing strategies lead to efficiency gains over standard parsing strategies, for lexicalist, concatenative and unification-based grammars. A head-driven parser applies a rule {{only after a}} <b>phrase</b> <b>matching</b> the head has been derived. By instantiating {{the head of the}} rule important information is obtained about the left-hand-side and the other elements of the right-hand-side. We have used two different head-driven parsers and a number of standard parsers to parse with lexicalist grammars for English and for Dutch. The results indicate that for important classes of lexicalist grammars it is fruitful to apply parsing strategies which are sensitive to the linguistic notion `head'. 1 Introduction Lexicalist grammar formalisms, such as Head-driven Phrase Structure Grammar (HPSG) and Categorial Unification Grammar (CUG) have two characteristic properties. Lexical elements and phrases are associated with categories that have considerable internal structure. [...] ...|$|R
40|$|We {{describe}} {{a method to}} align ASL video subtitles with a closed-caption transcript. Our alignments are partial, based on spotting words within the video sequence, which consists of joined (rather than isolated) signs with unknown word boundaries. We start with windows known to contain {{an example of a}} word, but not limited to it. We estimate the start and end of the word in these examples using a voting method. This provides a small number of training examples (typically three per word). Since there is no shared struc-ture, we use a discriminative rather than a generative word model. While our word spotters are not perfect, they are suffi-cient to establish an alignment. We demonstrate that quite small numbers of good word spotters results in an alignment good enough to produce simple English-ASL translations, both by <b>phrase</b> <b>matching</b> and using word substitution. Key...|$|R
40|$|Previous {{studies using}} {{alphabetic}} materials {{have shown that}} syntax-related manipulation resulted in brain activation while performing implicit syntax tasks. However, it is still an open {{question as to whether}} this conclusion can be applied to logographic Chinese, differing drastically from alphabetic languages. For example, in Chinese words do not generally have explicit grammatical markers, and syntax and semantics are relatively closely inter-related. Because previous studies adopting Chinese materials mainly employed violation paradigms to investigate the neural networks of Chinese syntactic, further studies are needed to investigate how the different tasks modulate the neural bases of Chinese syntactic, especially under the implicit syntax tasks. The present study used high spatial resolution fMRI technique to investigate Chinese two-word phrase processing. The factors of syntactic construction and task demand were orthogonally manipulated. Specifically, 120 phrases were constructed and were evenly divided into four syntactic construction types while phrase familiarity, frequency and visual complexity (i. e., number of strokes) were matched across types: 30 nounadjective argument, 30 verb-noun argument, 30 adjective-noun modification and 30 adjective-adjective parallel constructions. Participants were asked to finish two tasks for each of these phrases, i. e., 1 -back syntactic construction task and 1 -back word task. For the 1 -back syntactic construction task, they should respond if the syntactic construction of the current <b>phrase</b> <b>matched</b> with the previous phrase, and, for the 1 -back word task, they should respond if either word in the current <b>phrase</b> <b>matched</b> with a word in the previous phrase. Each task consisted of 3 blocks and the order of the task was counterbalanced across participants. Each trial lasted 10 s on average, consisting of fixation cross (0. 5 s), blank interval (0. 3 s), phrase (2. 2 s) and blank interval (3 s, 5 s, 7 s, 9 s or 11 s). The whole fMRI recording for each participant lasted around 55 min. The representation dissimilar matrices (RDM) of syntactic construction was created for representation similar analysis (RSA). The RSA searchlight results of 18 participants revealed that the activity patterns in the left middle fronta...|$|R
40|$|One {{of the key}} {{benefits}} of XML {{is its ability to}} represent a mix of structured and unstructured (text) data. Although current XML query languages such as XPath and XQuery can express rich queries over structured data, they can only express very rudimentary queries over text data. We thus propose TeXQuery, which is a powerful full-text search extension to XQuery. TeXQuery provides a rich set of fully composable full-text search primitives, such as Boolean connectives, <b>phrase</b> <b>matching,</b> proximity distance, stemming and thesauri. TeXQuery also enables users to seamlessly query over both structured and text data by embedding TeXQuery primitives in XQuery, and vice versa. Finally, TeXQuery supports a flexible scoring construct {{that can be used to}} score query results based on full-text predicates. TeX- Query is one of the proposals submitted to the W 3 C Full-Text Task Force, whose charter is to extend XQuery with full-text search capabilities...|$|R
25|$|He mistook {{an editor}} and re-publisher for the {{original}} author. Sutton cites Wilkin (1852) which is an edited collected works, within which the <b>matching</b> <b>phrase</b> occurs, in Browne (1658).|$|R
40|$|An {{implementation}} of a non-structural Example-Based Machine Translation system that translates sentences from Arabic to English, using a parallel corpus aligned at the paragraph level, is described. Each new input sentence is fragmented into phrases and those <b>phrases</b> are <b>matched</b> to example patterns, using various levels of morphological data. The system has been implemented and automatically evaluated. Results are encouraging. ...|$|R
40|$|MIT’s Audio Notebook added {{great value}} to the note-taking process by {{retaining}} audio recordings, e. g. during lectures or interviews. The key was to provide users ways to quickly and easily access portions of interest in a recording. Several non-speech-recognition based techniques were employed. In this paper we present a system to search directly the audio recordings by key phrases. We have identified the user requirements as accurate ranking of <b>phrase</b> <b>matches,</b> domain independence, and reasonable response time. We address these requirements by a hybrid word/phoneme search in lattices, and a supporting indexing scheme. We will introduce the ranking criterion, a unified hybrid posterior-lattice representation, and the indexing algorithm for hybrid lattices. We present results for five different recording sets, including meetings, telephone conversations, and interviews. Our results show an average search accuracy of 84 %, which is dramatically better than a direct search in speech recognition transcripts (less than 40 % search accuracy). ...|$|R
40|$|Advances in {{computational}} {{resources and}} the communications infrastructure, and the rapid rise of the World Wide Web, {{have led to the}} increasingly widespread availability of scientific papers in electronic form. Scientific papers usually contain citations to previous work, and indices of these citations are valuable for literature search, analysis, and evaluation. Current citation indices of the scientific literature are constructed using manual effort and are typically expensive. Part of the reason for using manual effort is the great variability of citation syntax [...] {{it can be difficult to}} autonomously determine if two citations refer to the same article because citations can be written in many different formats. We present machine learning techniques that identify variant forms of citations to the same paper. A number of algorithms are presented. An algorithm based on word and <b>phrase</b> <b>matching</b> is found to perform best, and is sufficiently accurate for unassisted use in an autonomous c [...] ...|$|R
