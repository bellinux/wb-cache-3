3|64|Public
40|$|Abstract — Sorting {{is one of}} {{the most}} basic {{problems}} of computer science and has been discussed continuously since the evolution of computer science. Several algorithms have been devised and applied and the work is still unfinished. For the parallel computing sorting is of same relevance as for sequential and very <b>primitive</b> <b>problem</b> domain too. Grain size is very important aspect of any parallel algorithm and is decisive in term of complexity. For the sorting problems minimum unit for sorting is two elements, since we apply a swap operation if required, and the two elements are sorted. This is considered to be the single step operation. In this paper we will increase primitive unit to four elements and four elements will be sorted in a single step. By applying this technique we can improve the performance of many parallel algorithms. Keywords—Parallel sorting; Bitonic; shear sort; Direct mapping...|$|E
40|$|In Eurocrypt' 98 [1], Okamoto et al. {{exhibited}} a new trapdoor function {{based on the}} use of a special moduli (p q) allowing easy discrete logarithm computations. The authors proved that the scheme's resistance to chosen-plaintext attacks is equivalent to factoring n. Unfortunately, the proposed scheme su#ers from not being a permutation (the expansion rate is = 3), and hence cannot be used for public-key signatures. In this paper, we show how to refine the function into a trapdoor permutation {{that can be used for}} signatures. Interestingly, our variant still remains equivalent to factoring and seems to be the second known trapdoor permutation (Rabin-Williams' scheme [3] being the first) provably as secure as a <b>primitive</b> <b>problem.</b> 1 The Okamoto-Uchiyama Cryptosystem In Eurocrypt' 98, Okamoto and Uchiyama proposed a new public-key cryptosystem based on the ability of computing discrete logarithms in a particular subgroup. Namely, if p is a large prime and # p Z # p 2 is # p = {x < p | x = 1 mod p}, then # p has a group structure with respect to the multiplication modulo p ## p = p. The function log(.) : # p -# Z p which associates (x 1) /p to x is clearly well-defined on # p and presents interesting homomorphic properties. In particular, #x, y # p log(xy mod p) = log(x) + log(y) mod p whereby, as a straightforward generalization, #g # # p, m Z p log(g) = m log(g) mod p. Key Setup. Generate two k-bit primes p and q (typically 3 k = 1023) and set n = p q. Randomly select and publish a number g < n such that g p = g is of order p in Z # p 2 and keep g p secret (note that g p # p). Similarly, choose g # < n at random and publish h = g # mod n...|$|E
40|$|Abstract. In Eurocrypt' 98 [1], Okamoto et al. {{exhibited}} a new trapdoor function {{based on the}} use of a special moduli (p 2 q) allowing easy discrete logarithm computations. The authors proved that the scheme's resistance to chosen-plaintext attacks is equivalent to factoring n. Unfortunately, the proposed scheme suffers from not being a permutation (the expansion rate is, = 3), and hence cannot be used for public-key signatures. In this paper, we show how to refine the function into a trapdoor permutation {{that can be used for}} signatures. Interestingly, our variant still remains equivalent to factoring and seems to be the second known trapdoor permutation (Rabin-Williams ' scheme [3] being the first) provably as secure as a <b>primitive</b> <b>problem.</b> 1 The Okamoto-Uchiyama Cryptosystem In Eurocrypt' 98, Okamoto and Uchiyama proposed a new public-key cryptosys-tem based on the ability of computing discrete logarithms in a particular subgroup. Namely, if p is a large prime and flp ae Z*p 2 is flp = {x < p 2 | x = 1 mod p}, then flp has a group structure with respect to the multiplication modulo p 2 and]flp = p. The function log(.) : flp-! Zp which associates (x- 1) /p to x isclearly well-defined on flp and presents interesting homomorphic properties. Inparticular, 8 x, y 2 flp log(xy mod p 2) = log(x) + log(y) mod p whereby, as a straightforward generalization, 8 g 2 flp, m 2 Zp log(gm mod p 2) = m log(g) mod p. 2 Pascal Paillier Key Setup. Generate two k-bit primes p and q (typically 3 k = 1023) and set n = p 2 q. Randomly select and publish a number g < n such that gp = gp- 1 mod p 2 is of order p in Z*p 2 and keep gp secret (note that gp 2 flp). Similarly, choose g 0 < n at random and publish h = g 0 n mod n. The triple (n, g, h) forms the public key. The secret key is (p, q). Encryption. Pick r < n uniformly at random and encrypt the k-bit message m by: c = gmhr mod n. Decryption. Proceed as follows: 1. c 0 = cp- 1 mod p 2 = gm(p- 1) g 0 nr(p- 1) = gmp mod p 2, 2. m = log(c 0) log(gp) - 1 mod p...|$|E
30|$|The {{finite element}} method is {{essentially}} a discretization method for the approximate solution of partial differential equations. It has the natural advantage of keeping the physical properties of the <b>primitive</b> <b>problems.</b> There are many papers {{that have already been}} published to study the {{finite element method}} for a fourth-order nonlinear parabolic equation (see [1 – 6]).|$|R
3000|$|The {{spectral}} {{methods are}} essentially discretization methods for the approximate solution of partial differential equations. They have the natural advantage {{in keeping the}} physical properties of <b>primitive</b> <b>problems.</b> During the past years, many papers have already been published to study the spectral methods, for example, [11 – 14]. However, for the other boundary condition, can we also use the Fourier spectral method? The answer is ‘Yes’. Choose a good finite dimensional subspace [...]...|$|R
40|$|Abstract. We {{introduce}} content-aware steganography {{as a new}} paradigm. As {{opposed to}} classic steganographic algorithms that only embed information in the syntactic representation of a datagram, content-aware steganography embeds secrets in the semantic interpretation which a human assigns to a datagram. In this paper, we outline two constructions for content-aware stegosystems, which employ, as {{a new kind of}} security <b>primitive,</b> <b>problems</b> that are easy for humans to solve, but difficult to automate. Such problems have been successfully used in the past to construct Human Interactive Proofs (HIPs), protocols capable of automatically distinguishing whether a communication partner is a human or a machine...|$|R
40|$|AbstractThis paper refines Lovasz's duality {{theory for}} the linear matroid parity problem by: 1. (1) characterizing a minimum cover {{in terms of}} maximum {{matchings}}, 2. (2) characterizing maximum matchings {{in terms of a}} minimum cover and 3. (3) characterizing critical structures called hypomatchable components. We describe a naturally arising lattice of minimum covers for <b>primitive</b> parity <b>problems</b> and characterize the least and greatest elements in this lattice. For not necessarily <b>primitive</b> parity <b>problems,</b> we introduce a class of minimum covers whose members form a lattice and show that the critical components in the least element of this lattice exhibit a special property called “hypermatchability”...|$|R
40|$|A running {{system is}} {{presented}} which provides powerful {{support to the}} user while designing programs This system automatically constructs program schemas by decomposition of the datas involved in the specification. Datas are specified within a knowledge-base as data types having associated decomposition patterns. The user may combine different data-decomposition strategies with any of its decomposition patterns. So {{it is possible to}} build several program schemas for the same problem. Once a program schema is built the user can instantiate or adapt it by hand. He can also apply the system repetitively until he obtains <b>primitive</b> <b>problems</b> which can be solved directly. Key-words: Running system. Data types. Decomposition patterns. Powerful support. Progam schema. Strategies of decomposition. ...|$|R
5000|$|The {{name was}} coined by László Kalmár, {{in the context}} of {{recursive}} functions and undecidability; most problems in it are far from elementary. Some natural recursive problems lie outside ELEMENTARY, and are thus NONELEMENTARY. Most notably, there are <b>primitive</b> recursive <b>problems</b> that are not in ELEMENTARY. We know ...|$|R
40|$|Abstract. The {{main problem}} when solving a Thue {{equation}} is the computation {{of the unit}} group of a certain number field. In this paper we show that the knowledge of a subgroup of finite index is actually sufficient. Two examples linked with the <b>primitive</b> divisor <b>problem</b> for Lucas and Lehmer sequences are given. 1...|$|R
40|$|Recursion is {{nowadays}} {{taught to}} students since their first programming days {{in order to}} embed it deeply in their brains. However, students' first impact on Prolog programs execution sometimes weakens their faith in recursive programming thus invalidating our initial efforts. The selection and computation rules implemented by all Prolog systems, although clearly explained in textbooks, are hard to be interiorized by students also due to the poor system debugging <b>primitives.</b> <b>Problems</b> increase in Constraint Logic Programming when unification is replaced by constraint simplification in a suitable constraint domain. In this paper, we extend PrettyProlog, a light-weight Prolog interpreter written in Java capable of system primitives for SLD tree visualization, to deal with Constraint Logic Programming over Finite Domains. The user, in particular, can select the propagation strategies (e. g. arc consistency vs bound consistency) and can view the (usually hidden) details of the constraint propagation stage...|$|R
5000|$|Another {{generalisation}} is {{to calculate}} the number of coprime integer solutions m, n to the inequalityThis problem {{is known as the}} <b>primitive</b> circle <b>problem,</b> as it involves searching for primitive solutions to the original circle problem. It can be intuitively understood as the question of how many trees within a distance of r are visible in the Euclid's orchard, standing in the origin. If the number of such solutions is denoted V(r) then the values of V(r) for r taking small integer values are ...|$|R
40|$|We {{extend the}} {{character}} sum method for the computation of densities in Artin <b>primitive</b> root <b>problems</b> developed by H. W. Lenstra and the authors {{to the situation}} of radical extensions of arbitrary rank. Our algebraic set-up identifies the key parameters of the situation at hand, and obviates the lengthy analytic multiplicative number theory arguments that used {{to go into the}} computation of actual densities. It yields a conceptual interpretation of the formulas obtained, and enables us to extend their range of application in a systematic way. Comment: 18 pp, to appear in Acta Arithmetic...|$|R
50|$|Using {{the same}} ideas as the usual Gauss circle {{problem and the}} fact that the {{probability}} that two integers are coprime is 6/π2, it is relatively straightforward to show thatAs with the usual circle problem, the problematic part of the <b>primitive</b> circle <b>problem</b> is reducing the exponent in the error term. At present the best known exponent is 221/304 + ε if one assumes the Riemann hypothesis. Without assuming the Riemann hypothesis, the best known upper bound isfor a positive constant c. In particular, no bound on the error term of the form 1 &minus; ε for any ε > 0 is currently known that does not assume the Riemann Hypothesis.|$|R
40|$|Let k => 1, m => 1 {{be small}} fixed integers, gcd(k, m) = 1. This note {{develops}} some techniques for proving {{the existence of}} infinitely many primes solutions x = p, and y = q of the linear Diophantine equation y = mx + k. Comment: Fifteen Pages. Sharpen the Proof of Theorem 1. Keywords: Prime Diophantine Equations, Primes Pairs, DePolignac <b>Problem,</b> <b>Primitive</b> Roo...|$|R
50|$|In {{a futuristic}} Manhattan, AIs have become {{intelligent}} and independent of humans. Able {{to think and}} communicate with both great precision and speed, they find humans and their <b>problems</b> <b>primitive,</b> backward, and largely uninteresting. The 19,940 existing humans are kept on a reserve, out of the AIs' way, and are largely ignored except for when they wander into the surrounding domain of the machines.|$|R
40|$|Throughout our lives, {{below the}} level of our consciousness, each of us {{develops}} values, intuitions, expectations, and needs that powerfully affect both our perceptions and our judgments. Placed in situations in which we feel threatened, or which implicate our values, our brains, relying on those implicitly learned, emotionally weighted, memories, may react automatically, without reflection or the opportunity for reflective interdiction. We can 2 ̆ 2 downshift, 2 ̆ 2 to <b>primitive,</b> self-protective <b>problem</b> solving techniques. Because these processes operate below the radar of our consciousness, automatic, 2 ̆ 2 emotional 2 ̆ 2 reaction, rather than thoughtful, reasoned analysis may drive our responses to stressful questions of ethics and professional responsibility...|$|R
2500|$|His lectures from 1902 to 1903 were {{collected}} into a [...] "Borel tract" [...] Leçons sur l'intégration et la recherche des fonctions <b>primitives.</b> The <b>problem</b> of integration {{regarded as the}} search for a primitive function is the keynote of the book. Lebesgue presents the problem of integration in its historical context, addressing Augustin-Louis Cauchy, Peter Gustav Lejeune Dirichlet, and Bernhard Riemann. Lebesgue presents six conditions which it is desirable that the integral should satisfy, the last of which is [...] "If the sequence fn(x) increases to the limit f(x), the integral of fn(x) tends to the integral of f(x)." [...] Lebesgue shows that his conditions lead to the theory of measure and measurable functions and the analytical and geometrical definitions of the integral.|$|R
40|$|Abstract—The {{emergence}} of {{wireless sensor networks}} (WSN) and RFID technology are starting to make the ubiquitous computing vision a reality, as they provide the means to obtain information about physical phenomena and entities. However, {{there is a great}} need for higher abstraction levels, as the inte-gration of these technologies into current ubiquitous computing systems is still <b>primitive.</b> This <b>problem</b> is addressed by TinySOA, a service-oriented architecture that allows programmers to build their applications by using a simple API provided by language independent Web services. TinySOA contributes to the develop-ment of ubiquitous computing applications by facilitating the means to obtain primary context mainly through WSN and RFID. We describe the development of an application using our implementation into a production line scenario...|$|R
40|$|Abstract—We {{consider}} the Continuous Delivery Message Dissemination (CDMD) problem over the n-processor single-port complete (all links are present and are bidirectional) static network with the multicasting communication <b>primitive.</b> This <b>problem</b> {{has been shown}} to be NP-complete, even when all messages have the same length. For the CDMD problem, we present an efficient approximation algorithm to construct a message-routing schedule with a total communication time of at most 3 : 5 d, where d is the total length of the messages that each processor needs to send or receive. The algorithm takes OðqnÞ time, where n is the number of processors and q is the total number of messages that the processors receive. Index Terms—Network communications, multicasting, message routing, approximation algorithms, message forwarding. Ç...|$|R
5000|$|His lectures from 1902 to 1903 were {{collected}} into a [...] "Borel tract" [...] Leçons sur l'intégration et la recherche des fonctions <b>primitives.</b> The <b>problem</b> of integration {{regarded as the}} search for a primitive function is the keynote of the book. Lebesgue presents the problem of integration in its historical context, addressing Augustin-Louis Cauchy, Peter Gustav Lejeune Dirichlet, and Bernhard Riemann. Lebesgue presents six conditions which it is desirable that the integral should satisfy, the last of which is [...] "If the sequence fn(x) increases to the limit f(x), the integral of fn(x) tends to the integral of f(x)." [...] Lebesgue shows that his conditions lead to the theory of measure and measurable functions and the analytical and geometrical definitions of the integral.|$|R
40|$|We derive {{conditions}} {{that must be}} satisfied by the <b>primitives</b> of the <b>problem</b> in order for an equilibrium in linear Markov strategies to exist in some common property natural resource differential games. These conditions impose restrictions on the admissible form of the natural growth function, given a benefit function, or on the admissible form of the benefit function, given a natural growth function. common orty, natural resources, differential games, linear Markov strategies...|$|R
40|$|AbstractWe prove a braided {{version of}} Kostant–Cartier–Milnor–Moore theorem: The {{category}} of connected τ-cocommutative (τ 2 =id) braided Hopf algebras over {{a field of}} zero characteristic is equivalent via the enveloping construction to the category of generalized Lie algebras. This statement includes an embedding of any generalized Lie algebra into its universal enveloping algebra, the isomorphism H≅U(PrimH), and primitive generation results. The embedding theorem may be derived from the Poincaré–Birkhoff–Witt theorem for quadratic algebras of Koszul type (Remark C). We also provide a direct proof that uses neither Koszul cohomologies nor the algebraic deformation theory. We consider the <b>primitive</b> generation <b>problem</b> for subalgebras, biideals and homomorphic images of connected braided Hopf algebras in much more general context, when the braiding is not necessary involutive, and even {{it is not necessary}} invertible...|$|R
40|$|The {{programming}} approach to computability {{presented in the}} textbook by Kfoury, Moll, and Arbib in 1982 has been embedded into a programming course following the textbook by Abelson and Sussman. This leads to a course concept teaching good programming practice and clear theoretical concepts simultaneously. Here, we {{explain some of the}} main points of this approach: the halting <b>problem,</b> <b>primitive</b> and µ-recursive functions and the operational counterpart of these functions, i. e., the Loop and the While programs. ...|$|R
40|$|Quadrics are {{a compact}} {{mathematical}} formulation {{for a range}} of <b>primitive</b> surfaces. A <b>problem</b> arises when there are not enough data-points to compute the model but knowledge of the shape is available. This paper presents a method for fitting a quadric with a Bayesian prior. We use a matrix normal prior in order to favour ellipsoids on ambiguous data. The results show the algorithm to cope well when there are few points in the point cloud, competing with contemporary techniques in the area...|$|R
40|$|A Lehmer number modulo a prime p is {{an integer}} a with 1 ≤ a ≤ p- 1 whose inverse a̅ {{within the same}} range has {{opposite}} parity. Lehmer numbers that are also primitive roots have been discussed by Wang and Wang in an endeavour to {{count the number of}} ways 1 can be expressed as the sum of two primitive roots that are also Lehmer numbers (an extension of a question of S. Golomb). In this paper we give an explicit estimate for the number of Lehmer primitive roots modulo p and prove that, for all primes p ≠ 2, 3, 7, Lehmer primitive roots exist. We also make explicit the known expression for the number of Lehmer numbers modulo p and improve the Wang [...] Wang estimate for the number of solutions to the Golomb [...] Lehmer <b>primitive</b> root <b>problem.</b> Comment: 11 page...|$|R
40|$|A {{critical}} {{challenge in}} robot learning from demonstration {{is the ability}} to map the behavior of the trainer onto a robot’s existing repertoire of basic/primitive capabilities. In part, this problem {{is due to the fact}} that the observed behavior of the teacher may consist of a combination (or superposition) of the robot’s individual <b>primitives.</b> The <b>problem</b> becomes more complex when the task involves temporal sequences of goals. We introduce an autonomous control architecture that allows for learning of hierarchical task representations, in which: 1) every goal is achieved through a linear superposition (or fusion) of robot primitives and 2) sequencing across goals is achieved through arbitration. We treat learning of the appropriate superposition as a state estimation problem over the space of possible linear fusion weights, inferred through a particle filter. We validate our approach in both simulated and real world environments with a Pioneer 3 DX mobile robot...|$|R
40|$|UnrestrictedThis {{dissertation}} {{addresses a}} problem {{associated with the}} relative strength analysis and comparison of security protocols that use cryptographic <b>primitives.</b> The <b>problem</b> relates to the relativism of strength relations under different assumptions, where {{the goal is to}} develop comparison methods for non-quantifiable abstract properties associated with security systems. We address the problem by developing a lattice-theoretic model for the analysis of the relative strength of security protocols.; In this dissertation, we describe a model where certain known rankings in several dimensions are used to model a range of systems using a Hasse diagram. Then, we come up with the relative strength of security protocols that go beyond the known, but which are generally accepted to be the case. We show how the dimensions and environment allow one to make a statement regarding the relative strengths of the two systems under a particular set of assumptions...|$|R
40|$|Applications {{that involve}} {{watermarking}} schemes are typically composed of both watermarks and cryptographic primitives. The entire application {{is required to}} meet speci c application-dependant security properties, which critically depend on both {{the properties of the}} watermarking scheme and the security of cryptographic primitives. Although the design of secure cryptographic protocols is more or less wellunderstood, the combination of watermarks and cryptographic <b>primitives</b> poses new <b>problems.</b> This paper reviews some of the fallacies and pitfalls that occur during the design of secure watermarking applications, and provides some practical guidelines for secure watermarking protocols...|$|R
40|$|Dupin cyclides are {{algebraic}} surfaces introduced for {{the first}} time in 1822 by the French mathematician Pierre-Charles Dupin. They have a low algebraic degree and have been proposed as a solution to a variety of geometric modeling problems. The circular curvature line's property facilitates the construction of the cyclide (or the portion of a cyclide) that blends two circular quadric primitives. In this context of blending, the only drawback of cyclides is that they are not suitable for the blending of elliptic quadric <b>primitives.</b> This <b>problem</b> requires the use of non circular curvature blending surfaces. In this paper, we present another formulation of cyclides: Scaled cyclides. A scaled cyclide is the image of a Dupin cyclide under an affine scaling application. These surfaces are well suited for the blending of elliptic quadrics primitives since they have elliptical lines of curvature. We also show how one can convert a scaled cyclide into a set of rational quadric B ezier patches...|$|R
40|$|This note {{investigates the}} problem of the {{relation}} between the initial conditions for the primitive equations and the full set of initial conditions for the Euler equations of adiabatic motion. We formulate for the <b>primitive</b> equations a <b>problem</b> analogous to the one that was considered by Rossby (1938) concerning the quasi geostrophic approximation: a problem which is now well known as the adjustment to geostrophy. The major conclusion is that the initial conditions for the primitive equations may be derived from a full set of initial conditions by solving a one-dimensional unsteady problem of vertical motion. 1...|$|R
40|$|This paper {{presents}} {{the properties of}} the discrete analytical simulators [9]. There are two main ways of obtaining a DR of a real world object. One is by acquisition with a hyperplanes. They are defined analytically in the discrete do- physical device like a camera for a 2 D DR, a CT or MR main by Diophantine equations. We show that the discrete hyperplane is a generalization of the classical digital hyperplanes. We present original properties such as exact point localization and space tiling. The main result is the links made between the arithmetical thickness of a hyperplane and its topology. © 1997 Academic Press scanner for a 3 D DR, a PET scanner for a 4 D DR, etc. The second one is by digitizing the primitives forming its CAR. Although many papers have dealt with the digitization of <b>primitives,</b> the <b>problems</b> we have in handling the geome-try and topology of the discrete world resulted in a predominant approach: ‘‘a digital primitive {{is the result of a}} local 1...|$|R
40|$|There are {{two main}} philosophies for {{addressing}} the motion planning problem, in Formulation 4. 1 from Section 4. 3. 1. This chapter presents one of the philosophies, sampling-based motion planning, which is outlined in Figure 5. 1. The main idea is to avoid the explicit construction of Cobs, as described in Section 4. 3, and instead conduct a search that probes the C-space with a sampling scheme. This probing is enabled by a collision detection module, which the motion planning algorithm considers as a “black box. ” This enables the development of planning algorithms that are independent of the particular geometric models. The collision detection module handles concerns such as whether the models are semi-algebraic sets, 3 D triangles, nonconvex polyhedra, and so on. This general philosophy has been very successful in recent years for solving problems from robotics, manufacturing, and biological applications that involve thousands and even millions of geometric <b>primitives.</b> Such <b>problems</b> would be practically impossible to solve using techniques that explicitly represent Cobs. Notions of completeness It is useful to define several notions of completenes...|$|R
40|$|Techniques are {{examined}} for replicating data and execution in directly distributed systems: systems in which multiple processes interact directly {{with one another}} while continuously respecting constraints on their joint behavior. Directly distributed systems are often required to solve difficult problems, ranging from management of replicated data to dynamic reconfiguration in response to failures. It is shown that these problems reduce to more <b>primitive,</b> order-based consistency <b>problems,</b> which can be solved using primitives such as the reliable broadcast protocols. Moreover, given a system that implements reliable broadcast primitives, a flexible set of high-level tools can be provided for building {{a wide variety of}} directly distributed application programs...|$|R
40|$|Data {{and tools}} for the {{autonomous}} rotorcraft guidance benchmarking framework. The {{elements of the}} framework consist {{of a set of}} spatial geometries, flight tasks, performance metrics, a flightdynamic model and baseline solutions. The spatial benchmarks consist of six tasks in simple geometrical environments and ten tasks in more complex urban environments based on a real digital terrain elevation map. The performance baselines used in the proposed framework are near-optimal solutions computed using one of two trajectory optimization methods: numerical optimization basedon Nonlinear Programming for the simple geometric environments, and a Motion <b>Primitive</b> Automaton for <b>problems</b> involving the urban environments. The framework also includes a set of performance metrics used to compare trajectories...|$|R
40|$|Multiresolution {{models are}} widely {{employed}} in computer graphics applications {{in order to}} reduce the traffic of information between the CPU and the GPU. The present tendency towards the usage of triangle strips in these models is based on its low cost and high rendering speed. But using this <b>primitive</b> poses the <b>problem</b> of the degeneration of the strips as the level of detail changes. Degenerated triangles are those that have no mathematical area and imply sending information for triangles that will not be rendered. We present a strip generation algorithm to solve this problem, where strips are constructed in such a way as to maintain their quality through all levels of detail...|$|R
