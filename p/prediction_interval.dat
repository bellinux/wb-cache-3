488|1040|Public
25|$|For example, to {{calculate}} the 95% <b>prediction</b> <b>interval</b> for a normal distribution with a mean (µ) of 5 and a standard deviation (σ) of 1, then z is approximately 2. Therefore, the lower limit of the <b>prediction</b> <b>interval</b> is approximately 5‒(21) = 3, and the upper limit is approximately 5+(21) = 7, thus giving a <b>prediction</b> <b>interval</b> of approximately 3 to 7.|$|E
25|$|Prediction {{intervals}} {{are commonly}} used as definitions of reference ranges, such as reference ranges for blood tests to give an idea of whether a blood test is normal or not. For this purpose, {{the most commonly used}} <b>prediction</b> <b>interval</b> is the 95% <b>prediction</b> <b>interval,</b> and a reference range based on it can be called a standard reference range.|$|E
25|$|In a {{log-normal}} distribution, {{the geometric}} standard deviations and geometric mean more accurately estimate the 95% <b>prediction</b> <b>interval</b> than their arithmetic counterparts.|$|E
40|$|<b>Prediction</b> <b>intervals</b> {{provide a}} measure of the {{probable}} interval in which the outputs of a regression model can be expected to occur. Subsequently, these <b>prediction</b> <b>intervals</b> can be used to determine if the observed output is anomalous or not, conditioned on the input. In this paper, a procedure for determining <b>prediction</b> <b>intervals</b> for outputs of nonparametric regression models using bootstrap methods is proposed. Bootstrap methods allow for a non-parametric approach to computing <b>prediction</b> <b>intervals</b> with no specific assumptions about the sampling distribution of the noise or the data. The asymptotic fidelity of the proposed <b>prediction</b> <b>intervals</b> is theoretically proved. Subsequently, the validity of the bootstrap based <b>prediction</b> <b>intervals</b> is illustrated via simulations. Finally, the bootstrap <b>prediction</b> <b>intervals</b> are applied to the problem of anomaly detection on aviation data...|$|R
40|$|This work {{considers}} {{the problem of}} constructing <b>prediction</b> <b>intervals</b> in log-Gaussian random fields. New <b>prediction</b> <b>intervals</b> are derived that are shorter than the standard <b>prediction</b> <b>intervals</b> of common use, where the reductions in length can be substantial in some situations. We consider both the case when the covariance parameters are known and unknown. For the latter case we propose a bootstrap calibration method to obtain <b>prediction</b> <b>intervals</b> with better coverage properties than the plug-in (estimative) <b>prediction</b> <b>intervals.</b> The methodology is illustrated using a spatial dataset consisting of cadmium concentrations from a potentially contaminated region in Switzerland. ...|$|R
40|$|New {{simultaneous}} <b>prediction</b> <b>intervals</b> {{for multiple}} forecasts from ARIMA models {{based on the}} Bonferroni-type and the product-type inequalities are introduced. These <b>prediction</b> <b>intervals</b> are compared with the marginal <b>prediction</b> <b>intervals</b> used in forecasting. Autoregressive Integrated Moving Average models Bonferroni-type inequalities product-type inequalities simultaneous confidence interval estimation...|$|R
25|$|The {{t-distribution}} {{can be used}} {{to construct}} a <b>prediction</b> <b>interval</b> for an unobserved sample from a normal distribution with unknown mean and variance.|$|E
25|$|A {{method to}} {{estimate}} the reference range for a parameter with log-normal distribution is to logarithmize all the measurements with an arbitrary base (for example e), derive the {{mean and standard deviation}} of these logarithms, determine the logarithms located (for a 95% <b>prediction</b> <b>interval)</b> 1.96 standard deviations below and above that mean, and subsequently exponentiate using those two logarithms as exponents and using the same base as was used in logarithmizing, with the two resultant values being the lower and upper limit of the 95% <b>prediction</b> <b>interval.</b>|$|E
25|$|Alternatively, in Bayesian terms, a <b>prediction</b> <b>interval</b> can be {{described}} as a credible interval for the variable itself, rather than for a parameter of the distribution thereof.|$|E
40|$|In {{this paper}} we {{construct}} <b>prediction</b> <b>intervals</b> for ARCH models using the bootstrap. We use both a parametric and non-parametric bootstrap, which {{take account of}} parameter uncertainty. We compare our <b>prediction</b> <b>intervals</b> to traditional asymptotic <b>prediction</b> <b>intervals,</b> and find that the bootstrap leads to improved accuracy. The accuracy of the bootstrap is empirically demonstrated with the Yen/$US exchange rate...|$|R
40|$|Theoretical {{approaches}} to computing <b>prediction</b> <b>intervals</b> require strong assumptions {{that do not}} appear to hold in practice. This paper presents an empirical approach to <b>prediction</b> <b>intervals</b> that assumes very little. During model-fitting, variances of the errors are computed at different forecast leadtimes. Using these variances, the Chebyshev inequality is applied to determine <b>prediction</b> <b>intervals.</b> Empirical evidence is presented to show that this approach gives reasonable results. For example, using the 111 series in the M-competition, 95 % <b>prediction</b> <b>intervals</b> actually contain 95. 8 % of post-sample observations. forecasting: time series...|$|R
40|$|A {{proposed}} {{technique for}} forming reliable <b>prediction</b> <b>intervals</b> {{for the future}} demand rate of existing products with observed demand of zero is illustrated using methodology adapted from software reliability. By using the demand information {{from a group of}} products which includes slow-moving products, <b>prediction</b> <b>intervals</b> for the future demand rate of the products with an observed demand of zero are constructed. A simulation study examined the reliability of these <b>prediction</b> <b>intervals</b> across experimental conditions that included product group size, mean time between demand, and Type I error levels. The proposed <b>prediction</b> <b>intervals</b> had empirical Type I errors closer to their nominal values when there were a sufficient number of products with no sales and also with some sales. Intermittent demand <b>Prediction</b> <b>intervals</b> Simulation Poisson process...|$|R
25|$|In {{statistical}} inference, specifically predictive inference, a <b>prediction</b> <b>interval</b> is {{an estimate}} of an interval in which future observations will fall, with a certain probability, given what has already been observed. Prediction intervals are often used in regression analysis.|$|E
25|$|The {{probability}} that a value is of a certain distance from the mean can subsequently be calculated from the relation between standard score and prediction intervals. For example, a standard score of 2.58 corresponds to a <b>prediction</b> <b>interval</b> of 99%, corresponding to a probability of 0.5% that a result is at least such far from the mean {{in the absence of}} disease.|$|E
25|$|Prediction {{intervals}} {{are used}} in both frequentist statistics and Bayesian statistics: a <b>prediction</b> <b>interval</b> bears the same relationship to a future observation that a frequentist confidence interval or Bayesian credible interval bears to an unobservable population parameter: prediction intervals predict the distribution of individual future points, whereas confidence intervals and credible intervals of parameters predict the distribution of estimates of the true population mean or other quantity of interest that cannot be observed.|$|E
40|$|The {{bootstrap}} method {{is one of}} the most widely used methods in literature for construction of confidence and <b>prediction</b> <b>intervals.</b> This paper proposes a new method for improving the quality of bootstrap-based <b>prediction</b> <b>intervals.</b> The core of the proposed method is a prediction interval-based cost function, which is used for training neural networks. A simulated annealing method is applied for minimization of the cost function and neural network parameter adjustment. The developed neural networks are then used for estimation of the target variance. Through experiments and simulations it is shown that the proposed method can be used to construct better quality bootstrap-based <b>prediction</b> <b>intervals.</b> The optimized <b>prediction</b> <b>intervals</b> have narrower widths with a greater coverage probability compared to traditional bootstrap-based <b>prediction</b> <b>intervals.</b> <br /...|$|R
40|$|Successfully {{determining}} competitive optimal schedules {{for electricity}} generation intimately {{hinges on the}} forecasts of loads. The nonstationarity and high volatility of loads make their accurate prediction somewhat problematic. Presence of uncertainty in data also significantly degrades accuracy of point predictions produced by deterministic load forecasting models. Therefore, operation planning utilizing these predictions will be unreliable. This paper aims at developing <b>prediction</b> <b>intervals</b> rather than producing exact point <b>prediction.</b> <b>Prediction</b> <b>intervals</b> are theatrically more reliable and practical than predicted values. The delta and Bayesian techniques for constructing <b>prediction</b> <b>intervals</b> for forecasted loads are implemented here. To objectively and comprehensively assess quality of constructed <b>prediction</b> <b>intervals,</b> a new index based on length and coverage probability of <b>prediction</b> <b>intervals</b> is developed. In experiments with real data, and through calculation of global statistics, it is shown that neural network point prediction performance is unreliable. In contrast, <b>prediction</b> <b>intervals</b> developed using the delta and Bayesian techniques are satisfactorily narrow, with a high coverage probability...|$|R
40|$|We {{construct}} <b>prediction</b> <b>intervals</b> for {{the linear}} regression model with IID errors with a known distribution, not necessarily Gaussian. The coverage probability of our <b>prediction</b> <b>intervals</b> {{is equal to}} the nominal confidence level not only unconditionally but also conditionally given a natural σ-algebra of invariant events. This implies, in particular, the perfect calibration of our <b>prediction</b> <b>intervals</b> in the online mode of prediction. 1...|$|R
25|$|In humans, {{ovulation}} occurs about {{midway through}} the menstrual cycle, after the follicular phase. The few days surrounding ovulation (from approximately days 10 to 18 of a 28-day cycle), constitute the most fertile phase. The time {{from the beginning of}} the last menstrual period (LMP) until ovulation is, on average, 14.6 days, but with substantial variation between females and between cycles in any single female, with an overall 95% <b>prediction</b> <b>interval</b> of 8.2 to 20.5 days.|$|E
25|$|One can {{visualize}} this {{by drawing}} the n samples on a line, which divides {{the line into}} nnbsp&+nbsp&1 sections (nnbsp&minus&nbsp&1 segments between samples, and 2 intervals going to infinity at both ends), and noting that X'n+1 has an equal chance of landing {{in any of these}} nnbsp&+nbsp&1 sections. Thus one can also pick any k of these sections and give a k/(nnbsp&+nbsp&1) <b>prediction</b> <b>interval</b> (or set, if the sections are not consecutive). For instance, if nnbsp&=nbsp&2, then the probability that X3 will land between the existing two observations isnbsp&1/3.|$|E
2500|$|For example, if n=19, then [...] {{gives an}} 18/20 =90% <b>prediction</b> <b>interval</b> – 90% of the time, the 20th {{observation}} falls between the smallest and largest observation seen heretofore. Likewise, n=39 gives a 95% <b>prediction</b> <b>interval,</b> and n=199 gives a 99% <b>prediction</b> <b>interval.</b>|$|E
40|$|The delta {{technique}} {{has been proposed}} in literature for constructing <b>prediction</b> <b>intervals</b> for targets estimated by neural networks. Quality of constructed <b>prediction</b> <b>intervals</b> using this technique highly depends on neural network characteristics. Unfortunately, literature is void of information about how these dependences can be managed in order to optimize <b>prediction</b> <b>intervals.</b> This study attempts to optimize length and coverage probability of <b>prediction</b> <b>intervals</b> through modifying structure and parameters of the underlying neural networks. In an evolutionary optimization, genetic algorithm is applied for finding the optimal values of network size and training hyper-parameters. The applicability and efficiency of the proposed optimization technique is examined and demonstrated using a real case study. It is shown that application of the proposed optimization technique significantly improves quality of constructed <b>prediction</b> <b>intervals</b> in term of length and coverage probability. <br /...|$|R
30|$|In a {{subsequent}} step, WSN traffic features are {{in real time}} processed by the proposed anomaly detection solution that indicates possible anomaly/attack when {{the value of the}} online calculated traffic feature is outside an interval determined by two <b>prediction</b> <b>intervals.</b> When values for a given traffic feature are inside 80  % <b>prediction</b> <b>intervals,</b> we assume that there is no anomaly/attack for a given traffic feature. When WSN traffic features lie inside interval described by 80 to 95  % of <b>prediction</b> <b>intervals,</b> we treated this traffic as suspicious where an anomaly or attack can be present. Traffic features with values outside 95  % <b>prediction</b> <b>intervals</b> triggers anomaly/attack by anomaly detection algorithm.|$|R
40|$|Abstract Background <b>Prediction</b> <b>intervals</b> can be {{calculated}} for predicting cancer incidence {{on the basis of}} a statistical model. These intervals include the uncertainty of the parameter estimates and variations in future rates but do not include the uncertainty of assumptions, such as continuation of current trends. In this study we evaluated whether <b>prediction</b> <b>intervals</b> are useful in practice. Methods Rates for the period 1993 – 97 were predicted from cancer incidence rates in the five Nordic countries for the period 1958 – 87. In a Poisson regression model, 95 % <b>prediction</b> <b>intervals</b> were constructed for 200 combinations of 20 cancer types for males and females in the five countries. The coverage level was calculated as the proportion of the <b>prediction</b> <b>intervals</b> that covered the observed number of cases in 1993 – 97. Results Overall, 52 % (104 / 200) of the <b>prediction</b> <b>intervals</b> covered the observed numbers. When the <b>prediction</b> <b>intervals</b> were divided into quartiles according to the number of cases in the last observed period, the coverage level was inversely proportional to the frequency (84 %, 52 %, 46 % and 26 %). The coverage level varied widely among the five countries, but the difference declined after adjustment for the number of cases in each country. Conclusion The coverage level of <b>prediction</b> <b>intervals</b> strongly depended on the number of cases on which the predictions were based. As the sample size increased, uncertainty about the adequacy of the model dominated, and the coverage level fell far below 95 %. <b>Prediction</b> <b>intervals</b> for cancer incidence must therefore be interpreted with caution. </p...|$|R
2500|$|A <b>prediction</b> <b>{{interval}}</b> instead {{gives an}} interval {{in which one}} expects y'd to fall; this is not necessary if the actual parameters α and β are known (together with the error term εi), but if one is estimating from a sample, then one may use the standard error of the estimates for the intercept and slope ( [...] and [...] ), {{as well as their}} correlation, to compute a <b>prediction</b> <b>interval.</b>|$|E
2500|$|Thus, {{denoting}} {{the sample}} maximum and minimum by M and m, this yields an [...] <b>prediction</b> <b>interval</b> of [...]|$|E
2500|$|A <b>prediction</b> <b>interval</b> [...] for {{a future}} {{observation}} X in a normal distribution N(µ,σ2) with known mean and variance may be calculated from ...|$|E
40|$|Many {{researchers}} have used time series models to construct population forecasts and <b>prediction</b> <b>intervals</b> {{at the national}} level, but few have evaluated the accuracy of their forecasts or the out-of-sample validity of their <b>prediction</b> <b>intervals.</b> Fewer still have developed models for subnational areas. In this study, we develop and evaluate six ARIMA time series models for states in the United States. Using annual population estimates from 1900 to 2000 {{and a variety of}} launch years, base periods, and forecast horizons, we construct population forecasts for four states chosen to reflect a range of population size and growth rate characteristics. We compare these forecasts with population counts for the corresponding years and find precision, bias, and the width of <b>prediction</b> <b>intervals</b> to vary by state, launch year, model specification, base period, and forecast horizon. Furthermore, we find that <b>prediction</b> <b>intervals</b> based on some ARIMA models provide relatively accurate forecasts of the distribution of future population counts but <b>prediction</b> <b>intervals</b> based on other models do not. We conclude that there is some basis for optimism regarding the possibility that ARIMA models might be able to produce realistic <b>prediction</b> <b>intervals</b> to accompany population forecasts, but a great deal of work remains to be done before we can draw any firm conclusions. Copyright Springer Science+Business Media B. V. 2007 ARIMA, Forecast accuracy, Forecast uncertainty, Population forecasts, <b>Prediction</b> <b>intervals,...</b>|$|R
40|$|In {{this paper}} we {{consider}} a sieve bootstrap method for constructing nonparametric <b>prediction</b> <b>intervals</b> {{for a general}} class of linear processes. We show that the sieve bootstrap provides consistent estimators of the conditional distribution of future values given the observed data. Sieve bootstrap <b>Prediction</b> <b>intervals</b> Linear processes...|$|R
40|$|In {{this paper}} we propose a new {{technique}} that uses the bootstrap to estimate confidence and <b>prediction</b> <b>intervals</b> for neural network (regression) ensembles. Our proposed technique can be applied to any ensemble technique that uses the bootstrap to generate the training sets for the ensemble, such as bagging [1] and balancing [5]. Confidence and <b>prediction</b> <b>intervals</b> are estimated that include a significantly improved estimate of underlying model uncertainty (i. e.) the uncertainty of our estimate of the "true" regression. Unlike existing techniques, this estimate of uncertainty will vary according to which ensemble technique is used [...] if the effect of using a specific ensemble technique is to produce less model uncertainty than using another ensemble technique, then this will be reflected in the confidence and <b>prediction</b> <b>intervals.</b> Preliminary results illustrate how our technique can provide more accurate confidence and <b>prediction</b> <b>intervals</b> (intervals that better reflect th [...] ...|$|R
2500|$|The {{answer is}} exactly 50%, {{regardless}} of the underlying population – the probability of picking 3 and then 7 {{is the same as}} picking 7 and then 3, {{regardless of the}} particular probability of picking 3 or7. Thus, if one picks a single sample X1, then 50% of the time the next sample will be greater, which yields (X1,+∞) as a 50% <b>prediction</b> <b>interval</b> for X2. [...] Similarly, 50% of the time it will be smaller, which yields another 50% <b>prediction</b> <b>interval</b> for X2, namely (∞,X1). Note that the assumption of a continuous distribution avoids the possibility that values might be exactly equal; this would complicate matters.|$|E
2500|$|More generally, if X(j) and X(k) are order {{statistics}} {{of the sample}} with j < k and j + k = n + 1, then [...] is a <b>prediction</b> <b>interval</b> for X'n+1 with coverage probability (significance level) equal to [...]|$|E
2500|$|However, in {{the real}} world, neither the {{population}} mean nor the population standard deviation are known. They both need to be estimated from a sample, whose size can be designated n. The population standard deviation is estimated by the sample standard deviation and the population mean is estimated by the sample mean (also called mean or arithmetic mean). To account for these estimations, the 95% <b>prediction</b> <b>interval</b> (95% PI) is calculated as: ...|$|E
30|$|Final {{models for}} {{estimating}} density, MFA and MOE {{were presented with}} both confidence and <b>prediction</b> bands. Confidence <b>intervals</b> contained within the confidence bands indicate the likely location of the true population mean, whereas <b>prediction</b> <b>intervals</b> account for both the uncertainty in the population mean as well as data scatter. For this reason, <b>prediction</b> <b>intervals</b> are always wider than confidence intervals.|$|R
40|$|The chapter {{opens with}} an {{introduction}} to regression and its implementation within the maximum-likelihood framework. This {{is followed by a}} general introduction to classical confidence <b>intervals</b> and <b>prediction</b> <b>intervals.</b> We set the scene by first considering confidence and <b>prediction</b> <b>intervals</b> based on univariate samples, and then we progress to regarding these intervals in the context of linear regression and logistic regression. Since a feed-forward neural network is a type of regression model, the concepts of confidence and <b>prediction</b> <b>intervals</b> are applicable to these networks, and we look at several techniques for doing this via maximum-likelihood estimation. An alternative to the maximum-likelihood framework is Bayesian statistics, and we examine the notions of Bayesian confidence and <b>predictions</b> <b>intervals</b> as applied to feed-forward networks. This includes a critique on Bayesian confidence intervals and classification...|$|R
40|$|Predicting {{the future}} demand rate of retail {{merchandise}} {{that has not}} experienced consumer demand over a specific interval of time is a challenging problem that has not received sufficient attention in the literature. A methodology is proposed to estimate the future demand rate of “slow ” moving products. The distribution of the estimator used in constructing the proposed <b>prediction</b> <b>intervals</b> has previously been illustrated to be skewed for certain parameters. This paper investigates the range of underlying demand rates that allow the proposed <b>prediction</b> <b>intervals</b> to have valid confidence levels. The interval of time selected to observe the demand rate of slow moving merchandise is selected to be 100 time periods to approximate 3 quarters with the time periods representing days. A simulation study reveals that two-sided <b>prediction</b> <b>intervals</b> are valid over a wider set of parameter values for the underlying demand rates of the products than one-sided <b>prediction</b> <b>intervals.</b> <b>Prediction</b> <b>intervals</b> are investigated at the 90 %, 95 %, and 99 % confidence levels. CONSTRUCTION OF PROPOSED PREDICTION INTERVALS FOR FUTURE LOW DEMAND RATE...|$|R
