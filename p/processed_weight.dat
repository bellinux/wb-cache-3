1|891|Public
50|$|Today, {{dried fruit}} is {{produced}} in most regions of the world, and consumption occurs in all cultures and demographic segments. In the United States, Americans consumed an average of 2.18 lb (<b>processed</b> <b>weight)</b> of dried fruit in 2006. Raisins accounted for about two thirds of this. California produces {{the largest percentage of}} the US and the world's dried fruit crop. It accounts for over 99% of the US crop of raisins and dried plums, 98% of dried figs, 96% of dried peaches, 92% of apricots and over 90% of dates. Most of California dried fruit production is centered in the San Joaquin Valley where the soil and climate, especially the hot, dry summers, provide ideal growing conditions. While these fruits were commonly dried in the sun in the past, now only raisins are almost entirely naturally sun-dried.|$|E
40|$|This article {{presents}} a computational {{model of the}} process through which the human visual system transforms reflectance spectra into perceptions of color. Using physical reflectance spectra data and standard human cone sensitivity functions we describe the transformations necessary for predicting the location of colors in the Munsell color space. These transformations include quantitative estimates of the opponent <b>process</b> <b>weights</b> needed to transform cone activations into Munsell color space coordinates. Using these opponent <b>process</b> <b>weights,</b> the Munsell position of specific colors can be predicted from their physical spectra with a mean correlation of 0. 989...|$|R
40|$|To {{minimise}} nonresponse bias most large-scale social surveys undertake nonresponse weighting. Traditional nonresponse weights {{adjust for}} demographic information only. This paper assesses the effect and added value of weights based on fieldwork process {{data in the}} European Social Survey (ESS). The reduction of relative nonresponse bias in estimates of political activism, trust, happiness and human values was examined. The effects of process, frame and post-stratification weights, {{as well as of}} weights combining several data sources, were examined. The findings demonstrate that <b>process</b> <b>weights</b> add explanatory power to nonresponse bias adjustments. Combined demographic and <b>process</b> <b>weights</b> were most successful at removing nonresponse bias. ...|$|R
50|$|Food {{and drink}} are often paired {{together}} {{to enhance the}} taste experience. This primarily happens with wine and a culture has grown up around the <b>process.</b> <b>Weight,</b> flavors and textures can either be contrasted or complemented. In recent years, food magazines began to suggest particular wines with recipes and restaurants would offer multi-course dinners matched with a specific wine for each course.|$|R
30|$|During the <b>process</b> of <b>weight</b> calculation, the {{accumulation}} of the total sum of weights is {{carried out in the}} weight calculation engine.|$|R
40|$|This paper {{explores the}} use of {{subdivision}} algorithms {{for the production of}} three-dimensional ornament. In a first step, this paper presents modifications to the Catmull Clark and Doo Sabin <b>processes</b> <b>weighting</b> schemes. In a second step, it proposes how these modified processes can be applied specifically to the generation of ornament. It presents methods for specifying weights using parameters both intrinsic and extrinsic to the mesh. Strategies for working with both very uniform and more differentiated input meshes are considered...|$|R
40|$|In {{this paper}} we study convex {{stochastic}} optimization problems where a noisy objective function value is observed after {{a decision is}} made. There are many stochastic optimization problems whose behavior depends on an exogenous state variable which affects {{the shape of the}} objective function. Currently, there is no general purpose algorithm to solve this class of problems. We use nonparametric density estimation to take observations from the joint state-outcome distribution and use them to infer the optimal decision for a given query state s. We propose two solution methods that depend on the problem characteristics: function-based and gradient-based optimization. We examine two weighting schemes, kernel based <b>weights</b> and Dirichlet <b>process</b> based <b>weights,</b> for use with the solution methods. The weights and solution methods are tested on a synthetic multi-product newsvendor problem and the hour ahead wind commitment problem. Our results show that in some cases Dirichlet <b>process</b> <b>weights</b> offer substantial benefits over kernel based weights and more generally that nonparametric estimation methods provide good solutions to otherwise intractable problems. ...|$|R
30|$|For {{the actual}} <b>weighting</b> <b>process</b> cells are {{aggregated}} when necessary to reach sufficient case numbers.|$|R
40|$|This paper {{explores the}} context of {{environmental}} justice (EJ) in Scotland, and presents a case study whereby the main attributes for an indicator of EJ were identified, encompassing procedural and distributive aspects of justice. Through a participatory <b>process,</b> <b>weights</b> were assigned using a Multi-Criteria Analysis tool, the Analytical Hierarchy Process (AHP). Results show that overall, environmental injustices are mostly associated by respondents to unequal distribution of health burdens due to pollution, yet greater weight is attached to procedural justice by community environmental activists. The paper suggests that AHP may be applied to many situations and could form {{a basis for the}} development of tools to address and deliver EJ in Scotland. Environmental justice, indicator, Analytical Hierarchy Process...|$|R
40|$|Amongst all {{the design}} modules {{employed}} in aircraft design <b>process,</b> <b>weight</b> module {{is the most}} significant one. Evaluating aircraft performance is dependent on a suitable aircraft weight in order to carry out its intended mission. In interactive design <b>process,</b> the <b>weight</b> design engineers usually follow one particular published methodology such as that proposed by Roskam or Torenbeek or etc. The main drawback of these methodologies is their limited accuracy to be applied to the vast variation of civilian aircraft. Furthermore, the non-availability of component-weight data, which may be used in evaluating maximum take-off weight, makes the design process difficult. Hence, new weight module has been applied to interactive design process. It suggests that many equations of different methodologies are applied to each aircraft component instead of applying one analyst???s methodology. Simultaneously, any formula that has secondary variables, which may not be available {{in the early stages of}} aircraft design, is rejected. The equation that gives the lowest average value is selected. The new module results show that the accuracy of the estimated operating empty weight and the maximum take-off weight is better than 5 %...|$|R
40|$|This paper {{describes}} {{a method for}} E-commerce website evaluation. Fuzzy AHP and neural network were applied to solve the problem. The proposed system consists of four components: hierarchical structure development for fuzzy analytic hierarchy <b>process</b> (FAHP), <b>weights</b> determination, data collection, and decision making...|$|R
50|$|This {{is called}} the zero forcing solution. It {{attempts}} to drive interference between the symbols to zero by a <b>process</b> of <b>weighting</b> linear combinations of the received signals at the two time samples and works perfectly {{in the absence of}} errors and noise.|$|R
5000|$|The sample [...] "It's down so low," [...] in {{the song}} [...] "Aurora" [...] was unknowingly {{provided}} by Donna during the recording <b>process.</b> The <b>weight</b> of the microphone she was using caused the stand to lower {{over the course of}} the vocal take.|$|R
50|$|Glass rollers {{hold the}} ribbon {{throughout}} {{various parts of}} the <b>process,</b> supporting its <b>weight</b> and continuing the drawing process.|$|R
40|$|THIS PHD FOCUSES TO PARALLEL PROGRAMMING PLATFORMS. A PLATFORM FOR PARALLEL PROGRAMMING WAS IMPLEMENTED GIVING EMPHASIS ON PORTABILITY. THE UNIT OF PARALLELISM IS THE LIGHT <b>WEIGHT</b> <b>PROCESS</b> IT SUPPORTS TRANSPARENT COMMUNICATION, TRANSPARENT LIGHT <b>WEIGHT</b> <b>PROCESS</b> ALLOCATION, GLOBAL SYNCHRONIZATION, MULTICASTING AND AN OBJECT ORIENTED DSM SYSTEM. ON TOP OF THE PLATFORM A PARALLEL PARSER FORTHE GREEK LANGUAGE WAS IMPLEMENTED AS WELL AS A SET OF TOOLS FOR PIECEWISE LINEAR APPROXIMATION OF DIGITIZED CURVES. ...|$|R
50|$|Building a System for Obesity Management: {{to learn}} the <b>process</b> of {{creating}} <b>weight</b> management programs that review and assess weight problems.|$|R
40|$|We {{investigate}} security enforcement {{mechanisms that}} {{run in parallel}} with a system; {{the aim is to}} check and modify the run-time behaviour of a possible attacker in order to guarantee that the system satisfies some security policies. We focus on a CSP-like quantitative process-algebra to model such <b>processes.</b> <b>Weights</b> on actions are modelled with semirings, which represent a parametric structure where to cast different metrics. The basic tools are represented by a quantitative logic and a model checking function. First, the behaviour of the system is removed from the parallel computation with respect to some security property to be satisfied. Secondly, what remains is refined in two formulas with respect to the given operator executed by a controller. The result describes what a controller has to do to prevent a given attack...|$|R
30|$|During fuzzy TOPSIS <b>process,</b> the {{importance}} <b>weights</b> {{assigned to the}} selected criteria using FAHP {{will be used as}} input to evaluate and rank alternatives.|$|R
5000|$|The {{subscript}} i {{represents the}} zigzag-scanning {{order of the}} coefficients. Furthermore, notice that is possible to weight the coefficients (w) in order to adjust {{the performance of the}} matching <b>process.</b> These <b>weights</b> let us give to some components of the descriptor more importance than others. Observing the formula, it can be extracted that: ...|$|R
40|$|Abstract: The {{importance}} of good weighting methodology in information retrieval methods – the method {{that affects the}} most useful features of a document or query representative- is examined. Good weighting methodologies {{are supposed to be}} more important than the feature selection <b>process.</b> <b>Weighting</b> features is the thing that many information retrieval systems are regarding as being of minor importance as compared to find the features; but the experiments suggest that weighting is noticeably more important than feature selection. There are different methods for the term weighting such as TF*IDF and Information Gain Ratio which have been used in information retrieval systems. In this paper we aim to explore a new algorithm for using GA in term weighting for text summarization process and then by deploying it as an appropriate developed prototype, the outcomes are analyzed and some conclusions for Information Retrieval are considered...|$|R
40|$|Abstract- This article {{describes}} {{an important step}} in the global project of gradual transition to hydrogen energy, namely, the creation of highly efficient on-board vehicle hydrogen generator that allows recycle hardly used thermal energy. Authors proposed a new approach to creating a hydrogen generator based on the process of decomposition of water in an artificial centrifugal field. A question of the opportunities of practical implementation of creating a centrifugal hydrogen generator and its use on board the vehicle are theoretically considered. The article presents the results of calculations of the current <b>processes,</b> <b>weight</b> and size of the proposed hydrogen generator. Some conclusions are drawn about the possibility and economic efficiency of its use in road transport. The results obtained allow conclude about the prospects of the proposed centrifugal hydrogen generator. Keywords- hydrogen generation, electrolytic cell, centrifugal field, water decomposition. 1...|$|R
40|$|This paper {{addresses}} the mixed analog-digital hardware {{implementation of a}} Hamming artificial neural network with on-chip learning. The developed integrated circuit architecture consists of a charge-based variable-weight neural network, and a digital module implementing the chip control, {{as well as the}} on-chip learning algorithm as a hardwareoriented adaptation of the well-known error-correction algorithm. Both the analog and the digital parts interact with each other to perform a pattern recognition task. A dedicated digital memory unit acts as the interface to temporarily hold the newly <b>processed</b> <b>weights.</b> We describe the actual realization as well as the design-flow which led to this development, including C software simulation, full-custom design and automated VHDL-based synthesis. 1. INTRODUCTION Hardware realization of artificial neural networks aims at efficiently accelerating the processing speed of neural network specific tasks such as pattern classification, system control, a [...] ...|$|R
40|$|Studies {{indicate}} that even short-term exposure to {{high concentrations of}} fine atmospheric particulate matter (PM 2. 5) can lead to long-term health effects. In this paper, we propose a random effects model for PM 2. 5 concentrations. In particular, we anticipate urban/rural differences with regard to both mean levels and variability. Hence we introduce two random effects components, one for rural or background levels and the other as a supplement for urban areas. These are specified {{in the form of}} spatio-temporal <b>processes.</b> <b>Weighting</b> these <b>processes</b> through a population density surface results in nonstationarity in space. We analyze daily PM 2. 5 concentrations in three Midwestern U. S. states for the year 2001. A fully Bayesian model is implemented, using MCMC techniques, which enables full inference with regard to process unknowns as well as predictions in time and space...|$|R
5000|$|... #Caption: 1890s {{wedding dress}} made from {{weighted}} silk. The splits and damage {{visible on the}} sleeve are caused by the <b>weighting</b> <b>process</b> of the fabric.|$|R
5000|$|At each {{iteration}} of {{the training}} <b>process,</b> a <b>weight</b> [...] is assigned to each sample in the training set equal to the current error [...] on that sample. These weights {{can be used to}} inform the training of the weak learner, for instance, decision trees can be grown that favor splitting sets of samples with high weights.|$|R
40|$|In survey sampling, {{the final}} sample weight {{assigned}} to each sampled unit reflects different steps of weighting adjustments such as frame integration, nonresponse and calibration. The analysis of the design effects {{for each of these}} adjustments casts light on their effects on the precision of survey estimates. In this paper, we limit our scope to the Canadian Community Health Survey (CCHS), briefly describe the <b>weighting</b> <b>process</b> of this survey and examine design effects at different steps of the <b>weighting</b> <b>process</b> to quantify how the overall variability in estimates {{can be attributed to the}} complex survey design and to each of the individual adjustments in the <b>weighting</b> <b>process.</b> As expected, the results suggest that the use of unequal person-selection probabilities and the nonresponse adjustment have the most negative impact on the design effect of the CCHS while calibration and winsorization decrease the design effect and improve the precision of the estimates...|$|R
40|$|The {{objective}} of this work was to perform a metric study of the reproductive system of the species Achantina fulica and Achatina monochromatica, establishing comparative parameters between both, to improve {{the knowledge of the}} species. After the selective <b>process,</b> <b>weighting</b> and measures of the shell, the specimens were frozen in freezer to - 2 (0) C for approximately 10 min as a sacrificing form. For each segments the measures proceeded after the retrieval of the reproductive system through a longitudinal incision. The statistical analysis showed that, in spite of the specimens be maintained under the same environmental and alimentary conditions and submitted to the same selection type, variations happened in the development and size of the reproductive organs. The morphologic aspect of the reproductive system in both species differs macroscopically in several segments; however, the disposition and the location of those segments are identical...|$|R
40|$|The {{goal of this}} {{research}} is to study the dynamics changing of temperature, weight and volume of wastes during composting process in Cakung Slaughterhouse. The composting process was done using windrow system for 65 days. Windrow was turned mechanically using compost turning machine once a week. Composition of input wastes was calculated based on its volume and specific weight. Regularly, windrows were measured of their volume, weight and temperature. The composting shows that weight and volume reduction was exponentially done in the two of the first weeks. The temperature also exponentially increased in that time. Those indicated that the increasing of metabolisms and development of microbiology during composting <b>process.</b> <b>Weight</b> and volume reduction reached about 80 percent, and their temperature reached above 55 oC during first weeks. The dynamics changing of the temperature and volume/weight reduction was the key parameter for evaluating composting process...|$|R
3000|$|..., Chaubey et al. [21] {{studied the}} smooth {{estimation}} of survival and density functions for a stationary-associated <b>process</b> using Poisson <b>weights.</b> In this paper, for x ∈ [ξ [...]...|$|R
30|$|A set of degummed and {{weighted}} silks {{was prepared}} {{in order to}} recognize the vibrational profile associated with the processes used. On this basis, the Raman and ATR-IR spectral information allowed {{the identification of the}} <b>weighting</b> <b>process</b> and also the dyes used in some of the different historic silk objects studied. The different spectra also allowed infer about the deterioration observed in the samples. The silk fibroin displays slight conformational modifications by the <b>weighting</b> <b>process.</b> The degumming process seems to have no chemical effect on the fibroin stability.|$|R
40|$|This paper prcscnts an {{efficient}} poslprocessin~correction method capable 0 1 rcducing visual artificts introduccd during the color filler array interpolation <b>process.</b> Edge-sensing <b>weights</b> {{and the original}} color lilter array data are uscd to detect structural elements in the original image and correct prcviously interpolated color components accordingly. The method produces excellent results in tcrms of both objective and subjective image quality measures. 1...|$|R
40|$|Adult {{obesity is}} {{associated}} with increased morbidity and mortality. Increasing success in weight loss maintenance will decrease the prevalence of overweight and obesity, and therefore help control the adverse health effects of excess weight. Much {{is known about the}} behavioral characteristics of successful long-term weight loss maintenance, but less is known about the cognitive <b>processes</b> behind <b>weight</b> loss maintenance. The purposes of this study were to (1) identify differences in visual attention to high-energy dense foods between individuals who are normal weight, weight loss maintainers, and overweight/obese in a high-risk (food-buffet) situation; (2) to evaluate differences in food choices from a food buffet between weight status groups; (3) to analyze correlations between food attention and food choice across weight status groups. No {{significant differences were found between}} groups with respect to food attention or food choice. Overall, findings from this study may have been limited by methodology, technology, and sample size. Future research is needed to better understand the interaction of cognitive <b>processes</b> and <b>weight</b> loss maintenance...|$|R
30|$|After {{carbonization}} process at 800 [*]°C, {{the size of}} R 800 (Fig.  1 b) barely shrank (17 [*]mm to 12 [*]mm in diameter) and the thickness changed hugely (800 [*]μm to 240 [*]μm) with the weight loss of 74 %. Figure  1 c shows the R 800 turned into black indicating that R was successfully transformed into carbon. After activation <b>process,</b> the <b>weight</b> of R 800 continued to decrease ~[*] 9 %. However, after Se impregnation <b>process,</b> the <b>weight</b> of R 800 A (Fig.  1 d) increased 90 % to transform into the Se-R 800 A as shown in Fig.  1 e. It is noteworthy that the R 800 A films suspended in midair right above the Se powder were surrounded by Se vapor. This is an original idea of melt diffusion and vapor deposition due to avoiding isolated stray of Se in carbon matrixes [20]. Finally, the Se-R 800 A maintains well mechanical strength as a free-standing electrode for Na-Se batteries.|$|R
40|$|Human {{vision is}} able to {{immediately}} recognize novel visual categories after seeing just {{one or a few}} training examples. We describe how to add a similar capability to ConvNet classifiers by directly setting the final layer weights from novel training examples during low-shot learning. We call this <b>process</b> <b>weight</b> imprinting as it directly sets weights for a new category based on an appropriately scaled copy of the embedding layer activations for that training example. The imprinting process provides a valuable complement to training with stochastic gradient descent, as it provides immediate good classification performance and an initialization for any further fine-tuning in the future. We show how this imprinting process is related to proxy-based embeddings. However, it differs in that only a single imprinted weight vector is learned for each novel category, rather than relying on a nearest-neighbor distance to training instances as typically used with embedding methods. Our experiments show that using averaging of imprinted weights provides better generalization than using nearest-neighbor instance embeddings...|$|R
40|$|This paper {{proposes a}} novel time series {{forecasting}} method {{based on a}} weighted self-constructing clustering technique. The weighted self-constructing clustering processes all the data patterns incrementally. If a data pattern is not similar enough to an existing cluster, it forms a new cluster of its own. However, if a data pattern is similar enough to an existing cluster, it {{is removed from the}} cluster it currently belongs to and added to the most similar cluster. During the clustering <b>process,</b> <b>weights</b> are learned for each cluster. Given a series of time-stamped data up to time t, we divide it into a set of training patterns. By using the weighted self-constructing clustering, the training patterns are grouped into a set of clusters. To estimate the value at time t + 1, we find the k nearest neighbors of the input pattern and use these k neighbors to decide the estimation. Experimental results are shown to demonstrate the effectiveness of the proposed approach...|$|R
40|$|This paper {{proposes a}} weight-based self-constructing {{clustering}} method for time series data. Self-constructing clustering processes {{all the data}} points incrementally. If a data point is not similar enough to an existing cluster, then (1) if the point currently {{does not belong to}} any cluster, it forms a new cluster of its own; (2) otherwise, the point is removed from the cluster it currently belongs to before a new cluster is formed. However, if a data point is similar enough to an existing cluster, then (1) if the point currently does not belong to any cluster, it is added to the most similar cluster; (2) otherwise, it is removed from the cluster it currently belongs to and added to the most similar cluster. During the clustering <b>process,</b> <b>weights</b> are learned and considered in the calculations of similarity between data points and clusters. Experimental results show that our proposed approach performs more effectively than other methods for real world time series datasets...|$|R
