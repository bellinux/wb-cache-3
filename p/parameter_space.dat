10000|2583|Public
5|$|There {{are certain}} distributions, {{especially}} those with three or more parameters, whose likelihoods may become infinite along certain paths in the <b>parameter</b> <b>space.</b> Using maximum likelihood to estimate these parameters often breaks down, with one parameter tending to the specific value that causes the likelihood to be infinite, rendering the other parameters inconsistent. The method of maximum spacings, however, being dependent on the difference between points on the cumulative distribution function and not individual likelihood points, does not have this issue, and will return valid results over a much wider array of distributions.|$|E
25|$|The large <b>parameter</b> <b>space</b> of pMSSM makes {{searches}} in pMSSM extremely {{challenging and}} makes pMSSM difficult to exclude.|$|E
25|$|In fact, {{this gives}} a {{correspondence}} between the entire <b>parameter</b> <b>space</b> of the logistic family {{and that of the}} Mandelbrot set.|$|E
5000|$|... #Subtitle level 3: Applications to multidimensional <b>parameter</b> <b>spaces</b> ...|$|R
5000|$|... with C. Henriksen: Julia sets in <b>parameter</b> <b>spaces,</b> Communications in Mathematical Physics, vol. 220, 2001, pp. 333-375 ...|$|R
5000|$|In {{the context}} of statistics, <b>parameter</b> <b>spaces</b> form the {{background}} for parameter estimation.As Ross describes in his book: ...|$|R
25|$|In mathematics, {{assembly}} {{maps are}} an important concept in geometric topology. From the homotopy-theoretical viewpoint, an assembly map is a universal approximation of a homotopy invariant functor by a homology theory from the left. From the geometric viewpoint, assembly maps correspond to 'assemble' local data over a <b>parameter</b> <b>space</b> together to get global data.|$|E
25|$|Mandelbrot {{studied the}} <b>parameter</b> <b>space</b> of {{quadratic}} polynomials {{in an article}} that appeared in 1980. for complex , Annals of the New York Academy of Sciences 357, 249/259 The mathematical study of the Mandelbrot set really began with work by the mathematicians Adrien Douady and John H. Hubbard, who established many of its fundamental properties and named the set in honor of Mandelbrot.|$|E
25|$|After {{the first}} year of data collection, the LHC {{experimental}} collaborations started to release their preliminary results concerning searches for new physics beyond the Standard Model in proton-proton collisions. No evidence of new particles was detected in the 2010 data. As a result, bounds were set on the allowed <b>parameter</b> <b>space</b> of various extensions of the Standard Model, such as models with large extra dimensions, constrained versions of the Minimal Supersymmetric Standard Model, and others.|$|E
40|$|If new {{physics is}} {{found at the}} LHC (and the ILC) the {{reconstruction}} of the underlying theory should not be biased by assumptions about high [...] scale models. For the mapping of many measurements onto high [...] dimensional <b>parameter</b> <b>spaces</b> we introduce SFitter with its new weighted Markov chain technique. SFitter constructs an exclusive likelihood map, determines the best [...] fitting parameter point and produces a ranked list of the most likely parameter points. Using the example of the TeV [...] scale supersymmetric Lagrangian we show how a high [...] dimensional likelihood map will generally include degeneracies and strong correlations. SFitter allows us to study such model [...] <b>parameter</b> <b>spaces</b> employing Bayesian as well as frequentist constructions. We illustrate in detail how {{it should be possible to}} analyze high [...] dimensional new [...] physics <b>parameter</b> <b>spaces</b> like the TeV [...] scale MSSM at the LHC. A combination of LHC and ILC measurements might well be able to completely cover highly complex TeV [...] scale <b>parameter</b> <b>spaces.</b> Comment: 43 pages, 55 figures, 13 tables; version to appear in EPJ...|$|R
40|$|The compresive and rarefactive ion-acoustic solitary wave of {{arbitrary}} amplitude {{which have}} been found to coexist in two-electron temperature plasmas, are investigated by the pseudo potential approach. An expression of this pseudo potential have been derived and the range of the <b>parameters</b> <b>space</b> Ms, ® and ¹ for the coexistence of these solitary structures are found for the case of cold ion plasma. Aditionally, the effect of the <b>parameters</b> <b>space</b> on wave amplitude was studied...|$|R
40|$|By {{introducing}} linear cross-diffusion for a two-component reaction-diffusion {{system with}} activator-depleted reaction kinetics (Gierer and Meinhardt, Kybernetik 12 : 30 - 39, 1972; Prigogine and Lefever, J Chem Phys 48 : 1695 - 1700, 1968; Schnakenberg, J Theor Biol 81 : 389 - 400, 1979), we derive cross-diffusion-driven instability conditions {{and show that}} they are a generalisation of the classical diffusion-driven instability conditions in the absence of cross-diffusion. Our most revealing result is that, in contrast to the classical reaction-diffusion systems without cross-diffusion, it is no longer necessary to enforce that one of the species diffuse much faster than the other. Furthermore, it is no longer necessary to have an activator-inhibitor mechanism as premises for pattern formation, activator-activator, inhibitor-inhibitor reaction kinetics as well as short-range inhibition and long-range activation all have the potential of giving rise to cross-diffusion-driven instability. To support our theoretical findings, we compute cross-diffusion induced <b>parameter</b> <b>spaces</b> and demonstrate similarities and differences to those obtained using standard reaction-diffusion theory. Finite element numerical simulations on planary square domains are presented to back-up theoretical predictions. For the numerical simulations presented, we choose parameter values from and outside the classical Turing diffusively-driven instability space; outside, these are chosen to belong to cross-diffusively-driven instability <b>parameter</b> <b>spaces.</b> Our numerical experiments validate our theoretical predictions that <b>parameter</b> <b>spaces</b> induced by cross-diffusion in both the (Formula presented.) and (Formula presented.) components of the reaction-diffusion system are substantially larger and different from those without cross-diffusion. Furthermore, the <b>parameter</b> <b>spaces</b> without cross-diffusion are sub-spaces of the cross-diffusion induced <b>parameter</b> <b>spaces.</b> Our results allow experimentalists to have a wider range of <b>parameter</b> <b>spaces</b> from which to select reaction kinetic parameter values that will give rise to spatial patterning in the presence of cross-diffusion...|$|R
25|$|In 1984, Peter Diggle and Richard Gratton {{suggested}} using {{a systematic}} simulation scheme to approximate the likelihood function {{in situations where}} its analytic form is intractable. Their method was based on defining a grid in the <b>parameter</b> <b>space</b> and using it to approximate the likelihood by running several simulations for each grid point. The approximation was then improved by applying smoothing techniques to the outcomes of the simulations. While {{the idea of using}} simulation for hypothesis testing was not new, Diggle and Gratton seemingly introduced the first procedure using simulation to do statistical inference under a circumstance where the likelihood is intractable.|$|E
25|$|Like B-splines, NURBS {{control points}} {{determine}} {{the shape of}} the curve. Each point of the curve is computed by taking a weighted sum of a number of control points. The weight of each point varies according to the governing parameter. For a curve of degree d, the influence of any control point is only nonzero in d+1 intervals (knot spans) of the <b>parameter</b> <b>space.</b> Within those intervals, the weight changes according to a polynomial function (basis functions) of degree d. At the boundaries of the intervals, the basis functions go smoothly to zero, the smoothness being determined by the degree of the polynomial.|$|E
25|$|In LEED {{the exact}} atomic {{configuration}} of a surface {{is determined by}} a trial and error process where measured I-V curves are compared to computer-calculated spectra under the assumption of a model structure. From an initial reference structure a set of trial structures is created by varying the model parameters. The parameters are changed until an optimal agreement between theory and experiment is achieved. However, for each trial structure a full LEED calculation with multiple scattering corrections must be conducted. For systems with a large <b>parameter</b> <b>space</b> the need for computational time might become significant. This {{is the case for}} complex surfaces structures or when considering large molecules as adsorbates.|$|E
50|$|For tangents {{chosen to}} bea Catmull-Rom spline is obtained, being {{a special case}} of a {{cardinal}} spline. This assumes uniform <b>parameter</b> <b>spacing.</b>|$|R
30|$|A {{stochastic}} process with discrete state and <b>parameter</b> <b>spaces</b> which exhibits Markov dependency as in (3) {{is known as}} a Markov Process.|$|R
3000|$|The proof follows by {{applying}} Theorem 3.7 to the <b>parameter</b> <b>spaces</b> Φ_ 0 and Φ_ 1 given by (1.3) and (1.4). □ [...]...|$|R
25|$|Between July and August 2011, {{results of}} {{searches}} for the Higgs boson and for exotic particles, based on the data collected {{during the first half}} of the 2011 run, were presented in conferences in Grenoble and Mumbai. In the latter conference it was reported that, despite hints of a Higgs signal in earlier data, ATLAS and CMS exclude with 95% confidence level (using the CLs method) the existence of a Higgs boson with the properties predicted by the Standard Model over most of the mass region between 145 and 466 GeV. The searches for new particles did not yield signals either, allowing to further constrain the <b>parameter</b> <b>space</b> of various extensions of the Standard Model, including its supersymmetric extensions.|$|E
25|$|Also, for {{the first}} time, the limits of {{mathematics}} were explored. Niels Henrik Abel, a Norwegian, and Évariste Galois, a Frenchman, proved {{that there is no}} general algebraic method for solving polynomial equations of degree greater than four (Abel–Ruffini theorem). Other 19th-century mathematicians utilized this in their proofs that straightedge and compass alone are not sufficient to trisect an arbitrary angle, to construct the side of a cube twice the volume of a given cube, nor to construct a square equal in area to a given circle. Mathematicians had vainly attempted to solve all of these problems since the time of the ancient Greeks. On the other hand, the limitation of three dimensions in geometry was surpassed in the 19th century through considerations of <b>parameter</b> <b>space</b> and hypercomplex numbers.|$|E
25|$|In {{mathematical}} statistics, Haar {{measures are}} used for prior measures, which are prior probabilities for compact groups of transformations. These prior measures are used to construct admissible procedures, by appeal to the characterization of admissible procedures as Bayesian procedures (or limits of Bayesian procedures) by Wald. For example, a right Haar measure {{for a family of}} distributions with a location parameter results in the Pitman estimator, which is best equivariant. When left and right Haar measures differ, the right measure is usually preferred as a prior distribution. For the group of affine transformations on the <b>parameter</b> <b>space</b> of the normal distribution, the right Haar measure is the Jeffreys prior measure. Unfortunately, even right Haar measures sometimes result in useless priors, which cannot be recommended for practical use, like other methods of constructing prior measures that avoid subjective information.|$|E
30|$|Theorem 3.10, {{applied to}} the <b>parameter</b> <b>spaces</b> Φ_ 0 and Φ_ 1 given by (3.2) and (3.3), gives back (1.8) in [7], Theorem  1.1.|$|R
40|$|The minimax {{theory for}} {{estimating}} linear functionals is {{extended to the}} case of a finite union of convex <b>parameter</b> <b>spaces.</b> Upper and lower bounds for the minimax risk can still be described in terms of a modulus of continuity. However in contrast to the theory for convex <b>parameter</b> <b>spaces</b> rate optimal procedures are often required to be nonlinear. A construction of such nonlinear procedures is given. The results developed in this paper have important applications to the theory of adaptation...|$|R
3000|$|The summit abscissae of the {{different}} shapes are calculated with the same principle of <b>parameter</b> <b>spacing</b> used in {{the determination of the}} grid nodes and the points coordinates in the decision table derivation. The FLC input/output variables MFs <b>spacing</b> <b>parameters</b> are, respectively, denoted by PSF [...]...|$|R
2500|$|... {{a visual}} {{map of the}} <b>parameter</b> <b>space</b> of Gray-Scott {{reaction}} diffusion.|$|E
2500|$|This {{makes any}} phenomenological {{analysis}} (e.g. finding regions in <b>parameter</b> <b>space</b> consistent ...|$|E
2500|$|Because such models {{may have}} as many as [...] parameters, {{overfitting}} may be an issue. [...] Some common choices that reduce the <b>parameter</b> <b>space</b> are: ...|$|E
30|$|Theorem 3.22, {{applied to}} the <b>parameter</b> <b>spaces</b> Φ_ 0 and Φ_ 1 given by (3.2) and (3.3), gives back (1.10) in [7], Theorem  1.1, for (θ, p)∈Γ_ 1.|$|R
40|$|Abstract Bayesian model {{selection}} and parameter estimation is attracting {{a lot of}} interest in the astronomical community because of its power and logical consis-tency. Markov chain Monte Carlo provides the computational power for Bayesian parameter estimation problems in large <b>parameter</b> <b>spaces</b> but needs to be supported with other numerical techniques for efficient exploration of multi-modal probabil-ity distributions. Bayesian model selection is easy in concept but remains a difficult challenge for large <b>parameter</b> <b>spaces.</b> My comments are based on lessons learned from developing a controlled statistical fusion approach to some of these issues...|$|R
40|$|We provide general {{compactness}} {{results for}} many commonly used <b>parameter</b> <b>spaces</b> in nonparametric estimation. We consider {{three kinds of}} functions: (1) functions with bounded domains which satisfy standard norm bounds, (2) functions with bounded domains which do not satisfy standard norm bounds, and (3) functions with unbounded domains. In all three cases we provide two kinds of results, compact embedding and closedness, which together allow one to show that <b>parameter</b> <b>spaces</b> defined by a -norm bound are compact under a norm. We apply these results to nonparametric mean regression and nonparametric instrumental variables estimation...|$|R
2500|$|... must be {{positive}} semidefinite. Letting [...] vary (and dropping the subindex 0) the Hessian [...] defines a (possibly degenerate) Riemannian metric on the [...] <b>parameter</b> <b>space,</b> called the Fisher information metric.|$|E
2500|$|... where [...] is a continuous, {{strictly}} decreasing and {{convex function}} such that [...] [...] is a parameter within some <b>parameter</b> <b>space</b> [...] [...] {{is the so-called}} generator function and [...] is its pseudo-inverse defined by ...|$|E
2500|$|The free-space diagram {{between two}} curves {{for a given}} {{distance}} threshold ε is a two-dimensional region in the <b>parameter</b> <b>space</b> that consist of all point pairs on the two curves at distance at most ε: ...|$|E
40|$|Estimation of a {{quadratic}} functional over <b>parameter</b> <b>spaces</b> {{that are}} not quadratically convex is considered. It is shown, {{in contrast to the}} theory for quadratically convex <b>parameter</b> <b>spaces,</b> that optimal quadratic rules are of-ten rate suboptimal. In such cases minimax rate optimal procedures are constructed based on local thresholding. These nonquadratic procedures are sometimes fully efficient even when optimal quadratic rules have slow rates of convergence. Moreover, it is shown that when estimating a quadratic func-tional nonquadratic procedures may exhibit different elbow phenomena than quadratic procedures. 1. Introduction. The Gaussia...|$|R
30|$|For (θ, p)∈Γ_ 2, {{the result}} (1.9) in [7], Theorem  1.1, follows from Theorem  3.16, {{applied to the}} <b>parameter</b> <b>spaces</b> Φ_ 0 and Φ_ 1 given by (3.2) and (3.3).|$|R
30|$|By {{applying}} Theorem 3.13 to the <b>parameter</b> <b>spaces</b> Φ_ 0 and Φ_ 1 {{given by}} (3.2) and (3.3), {{we get back}} (1.9) in [7], Theorem  1.1, for (θ, p)∈Γ_ 1.|$|R
