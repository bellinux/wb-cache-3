141|431|Public
5000|$|Part 1723 - <b>Physical</b> <b>node</b> {{requirement}} to implementing component allocation ...|$|E
5000|$|Object id’s are {{guaranteed}} to be unique across all physical nodes. Objects could be [...] "moved" [...] from one <b>physical</b> <b>node</b> to another without any application code changes required.|$|E
5000|$|... {{ability of}} {{grouping}} together hosts ( [...] a <b>physical</b> <b>node</b> - connection point - or software program [...] ) and processes ( [...] computer {{program that is}} running [...] ) that are similar ...|$|E
30|$|The above {{formulation}} {{guarantees that}} all <b>physical</b> <b>nodes</b> are observable and controllable under normal conditions. For reliability, {{it is necessary}} for all <b>physical</b> <b>nodes</b> to be observable and controllable even when one set of PMUs is malfunctioning or is in outage. To meet the N[*]−[*] 1 criterion, the right part of (3) should be replaced with “ 2 ” which represents redundancy allocation.|$|R
3000|$|... {{represents}} {{the set of}} <b>physical</b> <b>nodes</b> of the <b>physical</b> network (every <b>node</b> of which provides a physical resource such as CPU and memory capacity with corresponding geographic coordinates) and L [...]...|$|R
40|$|The {{design of}} an energy {{efficient}} IP network {{is one of}} the most important challenge that researchers have begun to address in the last decades. A promising resource consolidation technique to improve the energy efficiency of Internet is based on the virtual router migration: when traffic decreases virtual routers are moved and consolidated in fewer nodes of the underlying physical network in order to turn off empty <b>physical</b> <b>nodes.</b> In this paper we propose the extension of an heuristic previously defined. The main change consists in the possibility of turning off <b>physical</b> <b>nodes</b> hosting more than one virtual router with the consequence to increase the number of candidate <b>physical</b> <b>nodes</b> to be turned off. Further we show whether the virtual router migration is also effectiveness in the case in which the <b>physical</b> <b>nodes</b> are equipped with line cards implementing the Adaptive Link Rate (ALR) technique and whose power consumption is traffic dependent. We show how the energy efficiency of the virtual router migration technique decreases as both the traffic reduction and the base power consumption of the line cards decrease...|$|R
50|$|Unlike in {{most other}} network {{protocols}} like IP, the address is not attached to an interface but to the whole <b>physical</b> <b>node.</b> Also a node can only possess one single address which identifies it throughout the whole network.|$|E
50|$|A Groom Server (shortly {{referred}} to as groom) {{is a process that}} performs bsp tasks assigned by BSPMaster. Each groom contacts the BSPMaster, and it takes assigned tasks and reports its status by means of periodical piggybacks with BSPMaster. Each groom is designed to run with HDFS or other distributed storages. Basically, a groom server and a data node should be run on one <b>physical</b> <b>node.</b>|$|E
5000|$|An {{administrator}} uses {{a utility}} to define replication channels. Channels are named entities that define a scope of replication within a <b>physical</b> <b>node.</b> The [...] "scope" [...] {{can be anything}} from full database replication to something as fine grained as anything definable by a Versant query. Once the channels are defined, applications can register as listeners on these channels, at which point changes from those channel begin to flow to the respective clients.|$|E
3000|$|... p {{represents}} {{the set of}} physical links, and A_p^n and A_p^l are the attributes of the <b>physical</b> <b>nodes</b> and links, respectively.|$|R
30|$|IPs {{typically}} {{build the}} infrastructure and offer access to virtual resources, with a VM being the main component. VMs reside on <b>physical</b> <b>nodes</b> of heterogeneous capabilities where the performance characteristics of compute, storage and network vary. Demand for recourses varies {{over time as}} users consume and release these resources. As more resources are used, power consumption in the data centre increases and IPs may choose to optimise the allocation of VMs to <b>physical</b> <b>nodes.</b> In the next section, we will cover IPs objectives and approaches used to optimise this allocation.|$|R
40|$|Abstract. This paper proposes {{an optimal}} {{placement}} strategy of <b>physical</b> <b>nodes</b> of DHT-based systems {{to minimize the}} lookup latency and improve the throughput of system. The main idea of our approach {{is to create a}} new hierarchy named link space between logical space and physical space of DHT overlay. We firstly give an assignment of link space and then present the optimal placement strategy of placing <b>physical</b> <b>nodes</b> on it based on the given lookup traffic matrix. At last, we use genetic algorithm to solve the optimization problem...|$|R
5000|$|Formally, we {{represent}} each event in a distributed flow as a quadruple {{of the form}} (x,t,k,v), where x is the location (e.g., the network address of a <b>physical</b> <b>node)</b> at which the event occurs, t is the time at which this happens, k is a version, or a sequence number identifying the particular event, and v is a value that represents the event payload (e.g., all the arguments passed in a method call). Each distributed flow is a (possibly infinite) set of such quadruples that satisfies the following three formal properties.|$|E
3000|$|... {{represents}} {{the set of}} physical links of the physical network (with every physical link providing physical bandwidth resources to satisfy the communication demand between physical nodes). Furthermore, when a <b>physical</b> <b>node</b> fails, the corresponding physical links also fail. Hence, the virtual nodes mapped onto the failed <b>physical</b> <b>node</b> need to be migrated to another <b>physical</b> <b>node</b> that is not failed, and the corresponding virtual links also need to migrate. In this paper, there is at most only one <b>physical</b> <b>node</b> that fails at all times in the physical network of edge-of-things computing.|$|E
3000|$|... {{physical}} link. Equation (4) restricts {{a virtual}} node to map {{to only one}} <b>physical</b> <b>node.</b> Equation (5) indicates that the same virtual node cannot be mapped to the same <b>physical</b> <b>node,</b> NN [...]...|$|E
40|$|Abstract—Virtualization {{can provide}} {{significant}} benefits in data centers, such as dynamic resource configuration, live virtual machine migration. Services are deployed in virtual machines (VMs) and resource utilization can be greatly im-proved. In this paper, we present VScheduler, {{a system that}} dynamically adjusts processor resource configuration of virtual machines, including the amount of virtual resource and a new mapping of virtual machines and <b>physical</b> <b>nodes.</b> VScheduler implements a two-level resource configuration scheme – local resource configuration (LRC) for an individual virtual machine and global resource configuration (GRC) for a whole cluster or data center. GRC especially takes variation tendency of workloads into account when remapping virtual machines to <b>physical</b> <b>nodes.</b> We implement our techniques in Xen and conduct a detailed evaluation using RUBiS and dbench. The experimental results show that VScheduler not only satisfies resource demands of services, but also reduces the number of virtual machines migration, which can provide a stable VM distribution on <b>physical</b> <b>nodes</b> in data centers...|$|R
30|$|Interdependence connection: Cyber layer nodes have {{at least}} one energy {{interdependence}} or are equipped with backup uninterrupted power source (UPS). <b>Physical</b> <b>nodes</b> are observable and controllable by the cyber layer.|$|R
40|$|A <b>physical</b> network <b>node</b> {{controls}} allocation and/or deallocation {{of resources}} of an interconnected hardware infrastructure. The <b>physical</b> network <b>node</b> determines {{a number of}} requests currently queued at a first service node of a plurality of serially-connected service nodes at a current time. The plurality of serially-connected service nodes supports a packet flow using resources of the interconnected hardware infrastructure. The <b>physical</b> network <b>node</b> also determines a packet flow rate of the packet flow into the first service <b>node.</b> The <b>physical</b> network <b>node</b> also determines a future time to control allocation or deallocation of a resource of the interconnected hardware infrastructure to a second service node of the plurality of serially-connected service nodes based on the determined number of requests and the determined packet flow rate. The <b>physical</b> network <b>node</b> controls allocation or deallocation of the resource to the second service node at the future time...|$|R
30|$|Discrete ABC for VN embedding. We first label each <b>physical</b> <b>node</b> with {{a unique}} index. Let the vector X {{represent}} one possible mapping method. Each dimension of this vector is the index of the corresponding <b>physical</b> <b>node.</b> Take the X=(1, 3, 7, 9) for example. The four virtual nodes of a virtual request is mapped to the first, the third, the seventh, and the ninth <b>physical</b> <b>node</b> in the PN, respectively.|$|E
3000|$|The backup node mapping cost: {{the total}} {{expenses}} of using <b>physical</b> <b>node</b> resources {{to host the}} backup virtual nodes. It can be calculated as follows: [...]...|$|E
30|$|For {{the purpose}} of this paper, the {{configured}} system has one Thor process per <b>physical</b> <b>node</b> and the term node is used interchangeably with the term process and worker.|$|E
50|$|If {{the network}} in {{question}} is the Internet or an Intranet, many <b>physical</b> network <b>nodes</b> are host computers, also known as Internet nodes, identified by an IP address, and all hosts are <b>physical</b> network <b>nodes.</b> However, some data link layer devices such as switches, bridges and wireless access points {{do not have an}} IP host address (except sometimes for administrative purposes), and are not considered to be Internet nodes or hosts, but as <b>physical</b> network <b>nodes</b> and LAN nodes.|$|R
40|$|Traditionally, the {{performance}} of a distributed system or a telecommunication network is taken into account only in the last step of its design and is seen as a final improvement. Recent attempts to incorporate performance considerations in the mainstream design rely on the development of a functional model consisting of entities that must be optimally distributed over a network of <b>physical</b> <b>nodes.</b> In this paper we start from a rather informal methodology and refine it in order to convert it into a rather strict and well-defined method, taking into account the various parameters that influence the system design and emphasizing mainly a cost-effective placement of functionality in the <b>physical</b> <b>nodes.</b> (C) 1998 by John Wiley & Sons, Ltd...|$|R
40|$|Distributed {{systems with}} {{multi-stage}} workflows {{are characterized by}} multiple logical stages which can either execute sequentially or concurrently and a single stage can be executed on one or more <b>physical</b> <b>nodes.</b> Knowing the mapping of logical stages to <b>physical</b> <b>nodes</b> is important to characterize performance and study resource bottlenecks. Often due to the physical magnitude of such systems {{and complexity of the}} software, it is difficult to get detailed information about all the system parameters. We show that under light load conditions, the system can be well approximated using first order models and the hence simplifying the system identification problem. For general load, we develop a parameter estimation technique using maximum likelihood and propose a heuristic to solve it efficiently. ...|$|R
3000|$|Equations (2) and (3) {{represent}} the capacity constraints, where ReqCPU(i) indicates the CPU resource requests for i virtual node, CPU(j) represents the total CPU resource for j <b>physical</b> <b>node,</b> ReqBWL(l [...]...|$|E
30|$|There is at most one <b>physical</b> <b>node</b> {{failure at}} any time, {{and if there}} is a virtual node mapped onto it, the virtual node and {{adjacent}} links need to be migrated and recovered.|$|E
30|$|In this section, CPPS network {{models are}} {{established}} {{based on the}} standard IEEE RTS- 1996 system [39], which is a three-area IEEE RTS- 1979 system connected through five tie lines. The node load is set as 200 % of the default load given in [39]. The cyber layers are a scale-free network generated from the Barabási–Albert model, with two control center nodes, namely main and backup, in the cyber layer. There are bidirectional interdependencies between the physical and cyber layers, which mean that the cyber node provides 3 C-function support to the <b>physical</b> <b>node,</b> while the <b>physical</b> <b>node</b> supplies power to the same cyber node. Then, the dynamic development of cascading failures is simulated based on the improved percolation theory. Different scenarios are further simulated and compared for the CPPS network model.|$|E
30|$|Modern SPEs are {{designed}} to run on a multitude of <b>physical</b> <b>nodes.</b> In this setting, the probability of failure {{of at least one}} node is not negligible. Thus, SPEs include fault tolerance mechanisms to keep processing and producing results even in the presence of some failures.|$|R
50|$|The nodes {{appear as}} boxes, and the {{artifacts}} allocated to each node appear as rectangles within the boxes. Nodes may have subnodes, which appear as nested boxes. A single node in a deployment diagram may conceptually represent multiple <b>physical</b> <b>nodes,</b> {{such as a}} cluster of database servers.|$|R
30|$|Intra-link connection: Cyber layer nodes {{should be}} able to access the control center or backup control center. <b>Physical</b> <b>nodes</b> belong either to the giant {{functioning}} cluster or to the self-supply small cluster, which means that the generators in the small cluster can satisfy either a portion of or the total load within the island.|$|R
30|$|In the Chabok architecture, the {{information}} about mapping dimension fields of fact table and dimension tables is stored in the MetaDimension. This table also saves information about the <b>physical</b> <b>node,</b> which stores dimension information. The MetaDimension is used to translate an MHBQL query into a comprehensible query for FactMapper nodes.|$|E
30|$|Replication at the {{instance}} {{layer is}} helpful for forensic purposes. It {{is also possible}} to move the compromised service {{in conjunction with the}} underlying instance to a HoneyCloud. This is done instead of moving the <b>physical</b> <b>node,</b> ceasing all services on it, and changing the network configuration in order to restrict the compromised node communication.|$|E
40|$|This paper surveys HPF {{extensions}} in the Rice dHPF compiler that {{implement a}} general mechanism for overpartitioning data. In this approach, each <b>physical</b> <b>node</b> is allocated multiple tiles for which communication and computation are carefully scheduled to address multiple performance concerns while obeying scheduling and communication constraints. Overpartioning {{is the key}} enabling technology for a diverse set of advanced optimizations...|$|E
50|$|Rancher is a {{management}} platform for Docker containers. It includes a Kubernetes distribution {{as well as}} the option to choose from Docker Swarm and Apache Mesos. These all use Docker as the underlying container runtime and coordinate running containers between multiple discrete <b>physical</b> <b>nodes.</b> Rancher also includes modular infrastructure services including networking, load balancing, service discovery, monitoring and recovery.|$|R
3000|$|We note, however, {{that such}} {{heuristic}} approaches {{do not address}} {{the objective of the}} problem directly. Here, the goal is to meet SLAs while conserving energy, but the focus of the heuristics, that determine when adaptations should take place and which VMs should be moved, is on the load on <b>physical</b> <b>nodes.</b> Clearly, the load on <b>physical</b> <b>nodes</b> is relevant to this problem, but it is effectively a proxy for the goal. In this paper, we adopt what is referred to as a utility-based approach to adaptive energy-aware virtual machine placement. In the utility-based approach to adaptive systems [5 – 7], a utility function is defined that specifies the goal of the adaptation, and an optimization algorithm explores alternative adaptations, to identify the adaptation that maximizes utility. In this paper, the utility of an assignment a over a time interval t is defined as: U [...]...|$|R
50|$|While Xeround {{uses the}} open source version of MySQL, the cloud {{database}} software {{itself is not}} open source. Another distinction is that while Xeround offers MySQL as a front-end, on the back-end it is a NoSQL data storage system distributed on {{a large number of}} <b>physical</b> <b>nodes</b> - so it is not subject to the scalability limitations of regular MySQL databases.|$|R
