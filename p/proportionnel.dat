10|4|Public
40|$|International audienceThis paper {{deals with}} the problem of fault {{detection}} and identiﬁcation in noisy systems. A proportional integral observer with unknown inputs is used in order to reconstruct state and sensors faults. A mathematical transformation is made to conceive an augmented system, in which the initial sensor fault appear as an unknown input. This reconstruction is made by the use of a <b>proportionnel</b> integral observer. The noise effect on the state and fault estimation errors is also minimized. The obtained results are then extended to nonlinear systems described by nonlinear Takagi-Sugeno models...|$|E
40|$|Abstract- We briefly {{recall the}} concept of {{absorption}} in classical mechanics and we show that the quantum analogue is an imaginary potential proportional to h. The quantum phase shifts corresponding to this potential are calculated asymptotically to order fi ABSORPTION IN CLASSICAL DYNAMICS The concept of absorption is not contained in classical system dynamics. In this case, {{the state of the}} system is described by a point x in the appropriate phase space E. No probability concept allows to speak about any kind of decay law of the system itself. The appropriate framework is classical statistical mechanics. The state is a pro-bability density Wt in the phase space. Without absorption and for Harailtonian dynamics we have the Liouville (sometimes called Vlasov) equation (1) where h is the Harailtonian and, the Poisson bracket. This reversible equation insures conservation of the total probability. If t is the Harailtonian flow [1] associated to h, the solutions of eq. (1) may be written as (2) The current Jt is related to (S< {{in such a way that}} the current flow lines coincide with the orbits of 0 t: (3) In this scheme the knowledge of Jt is sufficient to predict the change of the state. Résumé- Nous rappelons rapidement le concept d'absorption en mécanique classique et nous montrons que l'analogue quantique est un potentiel ima-ginaire <b>proportionnel</b> à n. Les déphasages quantiques correspondant à ce potentiel sont calculés asymptotiquement à l'ordre n. Article published online by EDP Sciences and available a...|$|E
40|$|This study {{investigated}} an important {{dimension of the}} performance of students in two of the universities in British Columbia. Specifically, it examined rates of degree completion, time taken to earn the degrees and the final academic standing attained by graduates. The study involved all students who enrolled between 1973 and 1978, both directly from secondary school and as transfer students from the community colleges in the province. Results were reported by faculty, by department in which students majored, and by sex. The results revealed wide variations by faculty and department. Furthermore, results were not consistent between the two universities concerned. For example, female students performed far better than males at one university but not at the other. Finally, the study exposed many differences in performances between direct entry and transfer students, but again, the differences varied by university and faculty. Finally, the study invited both speculation and further research on the reasons for the inconsistent results. Particular attention was drawn to the need {{to assess the impact of}} rising admission standards upon students ' withdrawals, degree completion rates and final academic standing. RÉSUMÉ Cette étude examine une dimension importante de la performance des étudiants à deux universités de la Colombie-Britanique. Précisément, nous examinons le nombre <b>proportionnel</b> d'étudiants qui a réussi à obtenir un grade universitaire, le temps pris pour obtenir ce grade et le résultat académique atteint par les diplômés. L'étude inclut tous les étudiants qui étaient inscrits entre 1973 et 1978, soit en provenance des écoles secondaires ou des collèges publics de la province. Les résultats font mention de la faculté et du département dans lesquels les étudiants ont obtenu leurs diplômes de même que le sexe de l'étudiant. * The three authors are respectively working for The University of British Columbia, B. C...|$|E
5000|$|Haros, Charles. Comptes faits à la manière de Darême, sur les nouveaux poids et measures, aves les pris <b>proportionnels,</b> à l’usage et autres. Paris:Frimin Didot, 1806.|$|R
40|$|The authors {{consider}} {{the problem of}} Bayesian variable selection for proportional hazards regression models with right censored data. They propose a semi-parametric approach in which a nonparametric prior is specified for the baseline hazard rate and a fully parametric prior is specified for the regression coe#cients. For the baseline hazard, they use a discrete gamma process prior, and for the regression coe#cients and the model space, they propose a semi-automatic parametric informative prior specification {{that focuses on the}} observables rather than the parameters. To implement the methodology, they propose a Markov chain Monte Carlo method to compute the posterior model probabilities. Examples using simulated and real data are given to demonstrate the methodology. R ESUM E Les auteurs abordent d'un point de vue bayesien le problemedelaselection de variables dans les modeles de regression des risques <b>proportionnels</b> en presence de censure a droite. Ils proposent une approche semi-p [...] ...|$|R
40|$|Dans cette thématique {{concernant}} le transport solide des cours d’eau, il nous semble opportun de résumer le cadre général et d’y situer notre approche. Les formules classiques du transport solide évaluent le débit en matériaux du lit (charriage et suspension) à partir de ses déformations. Elles ne permettent pas d’estimer le débit des matériaux provenant directement du lessivage des versants et qui transite sans interaction avec le lit. Dans cet article, nous considérons uniquement la phase en suspension "MES" mesurée sans distinction à priori de l’origine des grains qui la constitue : provenance directe du bassin versant (phase directe) et (ou) reprise des stocks disponibles dans le lit (phase différée). Le bassin hydrographique du Timis-Béga (Roumanie) est particulièrement bien équipé pour le suivi des débits de 28 sous bassins et le contrôle des flux de MES de douze d’entre eux. De plus, son contexte physiographique nous {{permet de}} penser que la phase directe est prépondérante. Le protocole de mesure des flux de MES prévoit, entre autres, une densification variable des observations selon l’intensité des crues liquides. Ces considérations précédentes nous permettent d’envisager une modélisation statistique des apports solides en MES des sous-bassins du Timis-Béga. Celle-ci est directement inspirée des connaissances acquises sur la modélisation statistique "QdF" des régimes hydrologiques des bassins versants. Sur l’exemple du sous-bassin du Béga à Balint, qui draine une superficie de 1064 km 2, nous retiendrons deux principaux résultats issus de la transposition du concept QdF aux débits solides QMESdF : Les analyses statistiques des régimes liquide et solide montrent que les débits solides de MES ne sont pas simplement <b>proportionnels</b> aux débits liquides mais croissent plus rapidement. Les deux lois de distributions privilégiées, Pareto généralisée pour les MES et exponentielle pour les débits, permettent de le justifier. Le temps de montée des hydrogrammes de projet liquide ou solide est quasiment identique, autrement dit nous vérifions la quasi concomitance de leurs débits de pointe. Ce résultat n’est possible que si le débit solide de MES provient essentiellement du lessivage des versants, ce qui était supposé à priori. With respect to sediment transport, we detailed the general framework and how our approach contributes to these developments. Starting from the single traditional relation for the bed material load, specialists in river hydraulics cannot assess sediment yield of basins, when {{it involves the}} auto-suspension of fine sediments coming mainly from slope erosion (wash load). This latter estimate is needed for simulating the transfer of sediments and possible deposition in certain areas, particularly when a strong slowing down occurs. The Timis-Bega drainage basin (Romania) is fairly well equipped for the monitoring of discharge and suspended materials (sediment discharge). The hydrometric network includes 28 stations, of which 12 allow a monitoring of wash load. Moreover, its physiographic characteristics led us {{to think that the}} wash load dominates. Thus we assumed that sediment discharge was correlated with the physiographic features of the catchment area. The protocol for the measurement of the suspended sediment load was intensified during the floods. Thus, statistical modelling of the sub-basin sediment yields could be performed. The current study was directly inspired by the knowledge obtained in the domain of statistical modelling that describes hydrological regimes. The approach adopted was based on the flood-duration-frequency (QdF) analysis that takes into account the temporal variability of floods. The QdF approach analyses maximum average flows (Vd) over various durations (d), equivalent to intensity-duration-frequency (IdF) curves commonly used for rainfall analysis. The proposed model allows QdF curves V(d, T) for a given basin to be estimated using a minimum number of parameters. When the statistical law is the exponential law, this model contains only three parameters, due to observed scale invariance properties. The ∆ parameter that informs about the shape of the flood hydrograph is consequently the flood characteristic duration of the studied basin. The two parameters of the exponential maximum flood distribution for d= 0 (a 0 and x 0) and ∆ were fitted to sample discharges (Vd). This model is called a converging QdF model because of the observed convergence of distributions towards small return periods. This model is also useful for the determination of threshold discharges (Qd). The analytical formulation of the V(d,T) model can be derived according to d, in order to obtain a Q(d,T) model. This model then permits the calculation of the hydrograph for any return period (T) and any duration (d). The regionalization of the sediment yield was achieved {{within the framework of the}} Riverlife European project, in collaboration with NIHWM (National Institute of Hydrology and Water Management of Romania). Initially, local models were built. As an example, starting from the Bega sub-basin at Balint, with a surface of 1, 064 km 2, our intent was to present the transposition of the discharge-duration-frequency analysis concept (or QdF) to the wash load QMES dF. The latter relates to the measurement procedure, the statistical processing of the observed data QMES (t), and to the building of the discharge hydrographs of the associated projects. The main results were:- The statistical analyses of floods and sediment discharges show that the wash loads were not simply proportional to the discharge, but rather they increased more rapidly. The selection of the appropriate distribution laws (Pareto generalised for the QMESdF model (four parameters) and exponential for the QdF model) reinforced this result. - The lag-time was the same for both hydrographs with respect to flood and sediment discharge. This result can be achieved if the sediment transport comes primarily from the scrubbing of the slopes (wash load), which was hypothesised a priori. However, falling limb of the sediment hydrograph decreases more quickly than for the discharge hydrograph (∆MES is lower than ∆). The Bega sub-basin example at Balint was a first test towards the regional modelling of the contributions to sediment discharge in the catchment area of Timis-Béga. This flood and sediment discharge regionalization is necessary for the study of the protection of the town of Timisoara against flooding...|$|R
40|$|Nous étudions dans cet article la {{relation}} entre inégalité et conflits inter-groupes. L'approche mobilisée est l'économie expérimentale. Le jeu expérimental est un jeu en deux étapes. Dans une première étape, les participants jouent un « rent seeking » <b>proportionnel</b> afin de se partager un prix. Les inégalités sont modélisées de sorte que certains agents (les joueurs de type A, favorisés) reçoivent davantage du prix pour un même montant investi que d'autres joueurs (les joueurs de type D, défavorisés). En deuxième étape, les joueurs de chaque type peuvent se coordonner afin de réduire le gain des membres de l'autre groupe. Nous observons que les conflits diminuent avec le degré d'inégalité entre les groupes. Ces résultats semblent s'expliquer par des préférences compétitives fortes et des effets de résignation. We {{study the}} relationship between inequality and inter-groups conflicts (riots), focussing on social inequality. Disadvantaged societal groups experience discrimination and thus have limited access to some social and labour resources like education or employment. First, we experimentally investigate whether social inequality is a driving force of inter-group conflicts. Second, we investigate the factors that make preferences for riot translate into actions. Riots require coordination. Our experiment consists of a two-stage game. First, subjects play a proportional rent-seeking game to share a prize. Social inequality is modelled exogenously by attributing to some subjects (the advantaged group) {{a larger share of}} the price than other subjects (the disadvantaged group) for the same amount of effort. In a second stage players can coordinate with the other members of their group to reduce ("burn") the other group members' payoff. Treatments differ in the degree of social inequality set between the two groups. We observe frequent social conflicts, where, as expected, disadvantaged groups riot more than advantaged groups. Surprisingly, the frequency of riots decreases with the degree of inequality. A control treatment allows us to identify resignation as the driving force behind this phenomenon...|$|E
40|$|L'AJOUT D'IMPURETES POUR TESTER LES PROPRIETES DES MATERIAUX EST UNE TECHNIQUE BIEN CONNUE, ET A ETE UTILISEE DES LA DECOUVERTE DE LA SUPRACONDUCTIVITÉ DANS LES CUPRATES. DES EXPERIENCES DE RMN (RESONNANCE MAGNETIQUE NUCLEAIRE) MONTRENT QU'UNE IMPURETE NON MAGNÉTIQUE INDUIT UNE AIMANTATION DANS LE VOISINAGE DE L'IMPURETÉ, DONT LES OSCILLATIONS RÉVÈLENT LA PRÉSENCE DE FORTES CORRÉLATIONS ANTIFERROMAGNÉTIQUES. AFIN DE DÉCRIRE MICROSCOPIQUEMENT CE PHÉNOMÈNE, J'AI UTILISÉ, GUIDÉ PAR LES RESULTATS EXPERIMENTAUX, UN MODÈLE DE CORRÉLATIONS FORTES, LE HAMILTONIEN t-t'-J, SUR RESEAU CARRÉ (REPRESENTANT LES PLANS CUIVRE OXYGÈNE DES CUPRATES). CET HAMILTONIEN, TRANSFORMÉ VIA LE FORMALISME DES BOSONS ESCLAVES, A ETE DÉCOUPLÉ PAR CHAMP MOYEN. LE MODÈLE DÉVELOPPÉ CONSIDÈRE UNE IMPURETÉ UNIQUE REPRÉSENTÉE PAR UN SITE EXCLU, CONFORMÉMÉNT AUX EXPÉRIENCES QUI TENDENT A MONTRER QUE LES EFFETS LIÉS À LA PRÉSENCE D'IMPURETÉS SONT PROPORTIONNELS À LEUR CONCENTRATIONS (PAS D'INTERACTION ENTRE ELLES). SOUS CETTE FORME, LE PROBLÈME EST CELUI DES DEUX GAZ SANS INTERACTION (GAZ DE DEGRÉ DE LIBERTÉS DE SPINS OU " SPINONS " ET GAZ DE DEGRÉ DE LIBERTÉS DE CHARGES OU " HOLONS ") MAIS INTERDÉPENDANTS; LES PARTICULES DE CE GAZ DIFFUSANT SUR L'IMPURETÉ. L'AIMANTATION INDUITE DANS LE VOISINAGE DE L'IMPURETÉ EST DÉTERMINÉE PAR UN SYSTÈME D'ÉQUATIONS AUTOCOHÉRENTES, L'OUTILS DE BASE ÉTANT LES FONCTIONS DE GREEN, CARACTÉRISANTS LA PROPAGATION DES SPINONS ET HOLONS D'UN SITE À L'AUTRE SUR LE RÉSEAU CARRÉ. LES RÉSULTATS QUE J'OBTIENT SONT EN BON ACCORD AVEC LES EXPÉRIENCES. JE RETROUVE UNE AIMANTATION ALTERNÉE, DONT L'ENVELOPPE DÉCROIT COMME UNE FONCTION DE BESSEL. LA LONGUEUR CARACTÉRISTIQUE DE CETTE DÉCROISSANCE, ASSIMILÉE À LA LONGUEUR DE CORRÉLATIONS MAGNÉTIQUES LIÉE À LA PRÉSENCE DE L'IMPURETÉ, A POUR ORDE DE GRANDEUR QUELQUES PARAMÈTRES DE MAILLES, ET SON COMPORTEMENT EN TEMPÉRATURE ET DOPAGE EST SIMILAIRE À CE QUI EST EXPÉRIMENTALEMENT OBSERVÉ. IL EN VA DE MÊME POUR LES AUTRES GRANDEURS PHYSIQUES DÉTERMINÉES (TEMPÉRATURE DE CURIE-WEISS, SUSCEPTIBILITÉ, ETC [...] .) THE ADJONCTION OF IMPURITIES TO TEST THE PROPERTIES OF MARERIALS IS A WELLKNOWN TECHNIC, AND IS USED SINCE THE DISCOVERY OF SUPERCONDUCTIVITY IN CUPRATES. NMR EXPERIMENTS SHOW THAT A NON MAGNETIC IMPURITY LEAD TO A MAGNETIZATION AROUND THE IMPURITY. ITS OSCILLATIONS IS A MANFESTATION OF STRONG ANTIFERROMAGNETIC CORELATIONS. THE MODEL I HAVE USED IS THE t-t'-J HAMILTONIEN ON SCARE LATTICE, WHICH REPRESENTS THE CuO 2 PLAN. THIS HAMILTONIEN, TRANSFORMED BY THE USE OF THE SLAVE-BOSONS FORMALISM, IS TREATED BY A MEAN FIELD APPROXIMATION. THE DEVELOPPED MODEL CONSIDERS AN UNIQUE IMPURITY REPRESENTED BY AN EXCLUDE SITE, IN ACCORDANCE WITH EXPERIMENTS SHOWING THAT THE EFFETCS OF THE PRESENCE OF IMPURITIES ARE <b>PROPORTIONNEL</b> TO THE IMPURITIES CONCENTRATION (NO INTERACTION BEETWEN THE IMPURITIES). IN THIS FORM, THE PROBLEM IS EXPRESSED AS A TWO FREE GAZES PROBLEM, A " SPINONS " GAZ (SPINS DEGREES OF FREDOM) AND AN " HOLONS " GAZ (CHARGES DEGREES OF FREDOM), WITCH INTERACTED ONE WITH THE OTHER. THE PARTICULES DIFFUSE ON THE IMPURITY. THE MAGNETIZATION IS FOUND BY SOLVING A SELF-CONSISTENT EQUATIONS SYSTEM. THE MEAN MATHEMATIC TOOL IS THE GREEN FUNCTION, WHICH IS THE PROPAGATOR OF SPINONS AND HOLONS BEETWEN TWO SITES ON THE SCARE LATTICE. THE RESULTS I HAVE OBTAINED ARE IN GOOD AGREEMENT WITH EXPERIMENTS. I FIND A STAGGERED MAGNETIZATION AROUND THE IMPURITY, WITH AN ENVELOP THAT DECREASES AS A BESSEL FUNCTION. THE TYPICAL LENGHT ASSOCIATED WITH THIS BESSEL FUNCTION, ASSIMILATED TO THE MAGNETIC CORRELATION LENGHT, IS OF ORDER OF FEW LATTICE PARAMETER, AND ITS VARIATION WITH DOPING AND TEMPERATURE ARE SIMILAR TO EXPERIMENTS. THE SAME ACCORDANCES ARE FOUND FOR THE OTHERS PHYSICAL QUANTITIES (CURIE-WEISS TEMPERATURE, SUSCEPTIBILITY, [...] .) ORSAY-PARIS 11 -BU Sciences (914712101) / SudocSudocFranceF...|$|E
40|$|In 2012 a new {{particle}} {{was discovered}} at the Large Hadron Collider (LHC) by the ATLAS and CMS experiments,that {{is likely to}} be the Brout-Englert-Higgsboson, hereafter called Higgs boson for simplicity, predicted by the Standard Model (SM) of particle physics. To asses if this newly discovered particle is indeed the one predicted by the SM, the measurement of itsproperties is necessary. One of the most important properties to be measured is itscoupling to the top quark. This is because the coupling ofthe Higgs boson to fermions is proportional to fermions' masses. As the top-quark is the heaviest known elementary particle, the strength of this coupling is of the order of 1. A precise measurement of this parameter can give hints on the energy scale where physics beyond the SM can manifest itself. A direct test of this parameter is the measurement of the Higgs boson production cross section in association with a pair of top anti-top quarks (ttH). In this doctoral thesis the search of the ttH (H→ bb) process is presented in the topology where the two top quarks are decaying hadronically. The combination of all ttH searches performed by ATLAS in Run 1 is also presented. The fully hadronic analysis uses 20. 3 fb^- 1 at √(s) = 8 TeV, collected withthe ATLAS detector during Run 1 of the LHC. The search uses events with at least five energetic jetsand uses a boosted decision tree to discriminate the signal from the overwhelming multijetbackground which is estimated using a new data driven technique. Moreover, for this analysis, new techniques have been developed for the estimation of trigger efficiencies and scale factors. For a Higgs Boson mass of 125 GeV, a 95 % CL upper limit of 6. 5 (resp. 5. 4) times the SM cross section is observed (resp. expected). A ttH signal strength μ = 1. 6 ± 2. 6 times the SM value is obtained. After combination of allttH searches carried out by ATLAS in Run 1, an 95 % CL upper limitof 3. 12 (resp. 1. 44) is observed (resp. expected) with a signal strength of μ = 1. 7 ± 0. 8. The fully hadronic ttH (H→ bb) analysis presented in this doctoral thesis is the first oneperformed in this channel at the LHC. En 2012, une nouvelle particule a été découverte au Grand Collisionneur de Hadrons (LHC) qui est susceptible d'être identifié comme le boson de Brout-Englert-Higgs,ci-après appelée boson de Higgs, prévu par le Modèle Standard (SM) de la physique des particules. Pour déterminer si cette particule est bien celle prévue par le SM, les mesures de ses propriétés sont nécessaires. Une des propriétés les plus importantes à mesurer est le couplage avec le quark top. Le couplage du boson de Higgs aux fermions est <b>proportionnel</b> aux masses des fermions. Etant donné que le quark top, est la particule élémentaire connue la plus lourde, l'intensité de ce couplage est de l'ordre de 1. Une mesure précise de ce paramètre peut donner des renseignements sur l'échelle d'énergie où la physique au-delà du SM peut se manifester. Un test direct de ce paramètre est la mesure de la section efficace deproduction du boson de Higgs en association avec une paire de quarks top anti-top (ttH). Dans cette thèse de doctorat la recherche du processus ttH (H→ bb) est présentée dans la topologie où les deux quarks topse désintègrent hadroniquement. La combinaison de toutes les recherches effectuées par ATLAS au Run 1 est également présentée. L'analyse dans le canal de désintégration complètementhadronique utilise 20, 3 fb^- 1 à √(s) = 8 TeV, recueillies avecle détecteur ATLAS au cours du Run 1 du LHC. La recherche utilise des événements avec au moins cinq jets énergiqueset utilise la technique du "boosted decision tree" pour discriminer les événement dusignal de ceux provenant du dominant fond multijet qui est estiméà partir des données grâce à une nouvelle technique basée sur des donnés non simulée. En plus, pour cette analyse, de nouvelles techniques ont été développéespour l'estimation de l'efficacité du trigger utilisé et des facteurs d'échelle. Pour une masse du boson de Higgs de 125 GeV, une limite supérieure à 95 % CL de 6. 5 (resp. 5. 4) fois la section efficace du SMest observée (resp. attendue). Une intensité du signal ttH, μ = 1. 6 ± 2. 6 fois la valeur du SM est obtenue. Après combinaison desrecherches ttH effectuées par ATLAS dans le Run 1, un limite supérieure à 95 % CL est observée (resp. attendue) de 3. 12 (resp. 1. 44) avec une intensité du signal de μ = 1. 7 ± 0. 8. L'analyse du canal ttH (H→ bb) complètement hadronique présentée dans cette thèse de doctorat est la première effectuée dans ce canal au LHC...|$|E
40|$|Les auteurs de cet article proposent une évaluation empirique de facteurs qui favoriseraient la longévité des expériences des travailleuses et des travailleurs autonomes canadiens et concourraient ainsi à l’explication de la forte {{croissance}} de ce statut d’emploi ces dernières décennies. S’appuyant sur un cadre théorique original et utilisant le modèle de régression à risques <b>proportionnels</b> de Cox, ils estiment les prédicteurs de la probabilité de sortie des expériences de travail autonome suivies sur une période de 72 mois avec les données longitudinales de l’Enquête sur la dynamique du travail et du revenu. Leur étude révèle des différences notables entre les prédicteurs de la pérennité des expériences des hommes et des femmes, mais souligne aussi l’importance des conditions économiques des expériences de ces deux groupes pour en comprendre le succès. The {{challenge of}} explaining the {{rapid increase in}} self-employment {{over the last few}} decades lies not only in understanding what is attracting more people to this type of work, but also in the ability to determine those conditions which support the retention of individuals who venture into this type of work. This article presents a first empirical evaluation of the factors that foster the continuity of self-employment experiences in Canada and contribute to an explanation of its growth. Particular attention is paid to the distinct cases of women and of men. We propose that the decision to proceed further with a self-employment experience at a given point in time depends on the worker’s capacity to meet or go beyond minimal economic results. Given the type of services offered by the self-employed worker, this expected minimal result is easier to achieve during a economic upswing or during a period of economic expansion and also when the self-employed worker has the human capital, the financial resources and the necessary means of production {{to take full advantage of}} this favourable economic situation or to compensate for insufficient economic profitability during an unfavourable economic situation. The model suggests that the continuity of the experience may also be favoured by the particular hopes and preferences of the worker who is willing to accept a lower economic result since he or she finds this employment status a more satisfactory response, especially with regards to autonomy and to creativity within work, variety among tasks to accomplish and challenges to be met or a greater use of his competencies. In order to evaluate the influence of the variables in our theoretical framework on the continuity of self-employment, the authors used the Cox proportional risk regression model and estimated the probability of a worker leaving, within a specific month, self-employment status for a salaried job or for a full-time search for such a job (unemployment). The regression model was applied to a sample of some 3, 000 persons ranging in age from 16 to 65 from the first panel of SLID (Survey of Labour and Income Dynamics) from Statistics Canada. The model was also applied in a distinct manner to the 1, 595 men and 1, 237 women in this sample. The follow-up on their businesses was carried out on a monthly basis and only deals with the first experience undertaken by these individuals between January  1, 1993 and December  31, 1998. The average length of these self-employment experiences was 14. 4 months for women, and 17. 6 months for men. The survival analyses also reveal that after the first year’s experience, the probability of women leaving is higher than for men. However, when one takes into account the set of relevant variables with the Cox regression model, the risk of leaving self-employment for salaried employment or for a job search is 16 percent lower for women. In keeping with the hypotheses found in the theoretical framework, the regression analyses reveal that the risks of leaving self-employment increase when market conditions and specific conditions of the worker’s experience deteriorate. The self-employed worker’s occupational group also allows to predict the precariousness or longevity of his experience depending if salaried employment prospects seem to be relatively attractive or rather limited for his or her occupation. Self-employed workers who work in a rural setting or in small towns also have a lesser risk of leaving their enterprise because of the fewer salaried employment prospects than in larger municipalities. The human capital of the self-employed worker as seen in educational background and workplace experience has a rather mitigated effect on the continuity of his or her enterprise. His financial resources seem, however, to contribute more greatly to his success, particularly investment income and owning one’s own home. Finally, sociodemographic variables turned out to be secondary predictors and difficult to interpret. These imprecise results do not allow to confirm a link between the career aspirations of sociodemographic groups and the longevity of their experience. This continuity of self-employment model applies more to men than to women. Several predictors of the length of self-employment for men seem less relevant when predicting the continuity of women’s experience. Education, experience and investment income for female self-employed workers are resources which are slightly or not at all associated with the permanence of their employment status, while a dependence on government transfers increases the precariousness of this employment status. The conditions of their self-employed work experience also play a less important role. The explanation for the longevity of their enterprise seems to lie elsewhere: a spouse’s financial support, self-employment experience or business management experience; fewer alternatives to self-employment which are the result of reduced employment market mobility and increased concentration in certain occupational groups; career aspirations different from those of men, and a smaller and less profitable job market integration which results partly from their difficulty in reconciling the demands of family responsibilities with those of work. Los autores de este artículo proponen una evaluación empírica de los factores que podrían favorecer la longevidad de las experiencias de las trabajadoras y trabajadores autónomos canadienses, factores que contribuirían a la explicación del fuerte crecimiento de este estatuto de empleo en las últimas décadas. Los autores se basan en un esquema teórico original y utilizan el modelo de regresión de riesgos proporcionales de Cox para estimar los factores predicativos de la probabilidad del resultado de las experiencias de trabajo autónomo observadas, en un periodo de 72 meses, a partir de los datos longitudinales de la Encuesta sobre la dinámica del trabajo y del ingreso. El estudio revela diferencias notables entre los factores predicativos de la perennidad de las experiencias de los hombres y de las mujeres pero también recalca la importancia de las condiciones económicas de las experiencias de estos dos grupos para la comprensión de su éxito...|$|R
40|$|The Oman {{ophiolite}} {{offers a}} unique opportunity to observe a piece of oceanic lithosphere formed at a paleo fast spreading ridge, obducted on the continent and dissected by erosion, whereas oceanic rocks are difficult to study directly in situ in modern ridges. After considering how to discriminate preserved high temperature, ridge related structures from low temperature structures related to the obduction, we present the general structure of the Oman ophiolite. It shows that the ridge of origin itself was obducted. The paleoridge axis is characterised by an alignment of small mantle diapirs questioning the popular 2 D passive mantle model proposed for fast spreading ridges. In the next chapters we present a detailed structural mapping of 2 of these on axis diapirs (Maqsad and Nakhl) and another one which seems aside the paleoridge axis (Mansah diapir). The Maqsad diapir is the best exposed, steep flow lineations are scattered in a 100 km 2 area. Cross-sections show that the vertical flow rotates to the horizontal within a 500 meters thick melt impregnated transition zone {{and that there is a}} bulge of the Moho above this area. Horizontal radial flow is expelled from the diapir, including in a ridge strike direction. This with other lines of evidence such as the coupling between mantle and lower crustal structures demonstrate the existence of an active mantle flow at the ridge axis. Calculations predict that the diverging flow should become passive 10 km past the diapir limits, as illustrated by field data. Whereas the Nakhl diapir shares similar characteristics, the Mansah diapir is different in several points confirming the idea that this one was off axis. In particular, it displays discontinuous structures and shear zones on its sides, and diabase injections in its periphery, suggesting that it was intruding a pre-existing lithosphere. In a second part of the thesis, we study melt topology fossilised in Oman mantle rocks, with image analysis of several thin sections for each sample to get a 3 D view. We show that " melt pockets " can be approximated by ellipsoids with a clear preferred orientation parallel to the lineation, and the aspect ratio between the 3 ellipsoid axis depending on the intensity of the deformation recorded in the olivine matrix. These data combined with measurements of petrofabrics are used to calculate anisotropic seismic properties of oceanic mantle rocks with various melt fractions. These calculations show the importance of the anisotropy in these dry and melt impregnated mantle rocks and suggest that melt fractions at the Moho level might be underestimated by seismic surveys, provided that this zone is studied with horizontal seismic rays. The last chapter of the thesis exposes the preliminary results of a " seismic modelling " of mantle diapirs using our structural observations and the anisotropic seismic velocities calculated. This leads to a discussion of how far our interpretation of Oman is applicable to the East Pacific Rise. L'ophiolite d'Oman permet d'étudier un morceau de lithosphère océanique formé à une dorsale rapide et échoué sur le continent. La structure générale permet de reconnaître la présence de plusieurs diapirs dont certains alimentaient la dorsale d'origine, partiellement obductée avec l'ophiolite. Le diapir de Maqsad est l'exemple type d'un diapir à l'axe. Les linéations verticales couvrent 100 km 2 et tournent à l'horizontale au sein d'une zone de transition riche en magma, épaisse de 500 m, juste sous le Moho. Un flux forcé et radial est issu du diapir. Un calcul prédit que ce flux divergent devient passif à 10 km du diapir, comme le suggèrent nos données de terrain. Le diapir de Nakhl a des caractères similaires, tandis que le diapir de Mansah, éloigné de l'axe de la paleodorsale, est bordé par des zones de cisaillement et des injections de diabase qui attestent qu'il poinçonnait une lithosphère refroidie. Dans une seconde partie, les traces de magma dans les péridotites sont étudiées par analyse d'image sur des lames minces. On montre que les poches de liquide ont un allongement préférentiellement parallèle à la linéation et <b>proportionnel</b> à la force de la fabrique cristallographique de l'olivine. Ces données sont utilisées pour calculer les propriétés sismiques des échantillons. Nos résultats suggèrent que la quantité de liquide au Moho de la dorsale Est Pacifique peut être sous estimée à cause de l'anisotropie des roches. Enfin, une modélisation sismique d'un diapir, à partir de nos données structurales et des vitesses sismiques calculées permet de comparer les données d'Oman et de l'EPR...|$|E
40|$|Sur le fleuve Niger, les {{relations}} entre concentrations en Matières En Suspension (MES) et débits liquides montrent, à l'échelle d'une crue annuelle, des cycles d'hystérésis orthogrades. Le modèle présenté dans cet article reproduit les variations saisonnières de ces MES à partir du seul débit liquide. Il suppose que les MES proviennent de deux sources distinctes : le système " versants + réseau hydrographique secondaire ", siège d'une érosion saisonnière temporaire et le réseau hydrographique principal, siège d'une érosion permanente. Le modèle représente schématiquement la production de MES provenant de ces deux sources par le biais de deux réservoirs de MES. Le premier contient un stock en MES temporaire et limité. Ce stock, maximum au début de la crue annuelle (stock initial), est mobilisé et entraîné au cours de la saison pluvieuse en produisant un flux journalier, supposé être, à un instant donné, <b>proportionnel</b> au stock restant et à une fonction de puissance du débit. Le second, contient un stock de MES illimité et disponible en permanence. La mobilisation de ce stock produit un flux journalier, supposé être aussi une fonction de puissance du débit, et dont l'importance sera limité par la capacité du cours d'eau. Les cinq paramètres du modèle sont calibrés à l'aide des données acquises durant huit années hydrologiques (1991 / 92 à 1998 / 99) sur deux stations du Niger amont (Banankoro et Douna). Malgré les limites d'utilisation actuelles liées à la détermination du stock initial, le modèle présenté reconstitue de façon satisfaisante les variations annuelles des concentrations en MES et offre des perspectives intéressantes pour modéliser l'évolution temporelle des MES observées tant pour les fleuves tropicaux unimodaux que pour les petits bassins versants africains. En termes de flux annuels, le modèle n'apporte pas d'amélioration sensible {{par rapport}} à un ajustement statistique simple entre les volumes écoulés et les flux de MES. Cependant, il permet aussi de déterminer les variations de flux au cours de l'année, information qui ne peut être obtenue avec un modèle de régression statistique. Estimating temporal variability of suspended sediment concentrations in a watershed {{is important for}} a number of reasons (e. g., sediment yield estimation, provision of input data for reservoir sediment-deposition models and water quality models). Three different approaches have been adopted for modelling erosion and sediment transport: physical erosion models (Wicks and Bathurst, 1996); conceptual models (Negev, 1967; Pinheiro and Caussade, 1996); and empirical models (Walling, 1977; Asselman, 1977). Physical and conceptual models usually require rainfall intensity data. In African tropical river catchments, however, temporal and spatial variability of rainfall are not well known; in case of the Niger, water discharge is the only reliable hydrological parameter. This study proposes a model of temporal changes in suspended sediment concentrations using only water discharge data, thereby eliminating the need for rainfall parameters. Daily discharge and weekly suspended sediment concentration data (from 1991 / 92 to 1998 / 99) gathered at two monitoring stations of the Upper Niger (Banankoro and Douna) (Figure 1) were used to study relationships between suspended sediment concentration and river discharge. At each gauging station on the Niger, the relationship between water discharge and suspended sediment concentration during the annual flood is characterized by clockwise hysteresis (Figure 3). Moreover, several other African single-annual-flood rivers-unimodal rivers-also exhibit this type of relationship (Kattan et al., 1987; Olivry et al., 1988; Orange, 1992). This cyclicity suggests a three-stage description of sediment transport dynamics: (1) At the beginning of the rainfall season, sediments are imported by hill-slope surface runoff, re-entrainment of deposits in the channel network, and riverbed erosion. The first two sources consist of easily mobilizable material available throughout the catchment at the beginning of the hydrological year. (2) Sediment availability decreases with time as the soil becomes stabilised by vegetation during the rainy season. Erosion is consequently reduced, despite increased discharge. (3) During the period represented by the falling limb of the flood hydrograph, mobilizable material has been depleted or cannot be entrained; what suspended sediment there is originates upstream and from bank and bed erosion-permanently available sources. Non-seasonal sediment sources are grouped under the label of "continuous erosion. "We propose a lumped conceptual model of suspended-sediment concentration variations over the hydrological year. The model divides the erosion, transport and deposition processes into those acting on hill-slopes and those acting in the channel network, and assumes that both are explainable by water discharge Q(t) alone. The hill-slope/channel distinction is based on the fact that suspended sediment transport in a river depends not only on transport, bank and bed-erosion capacity, but also on the amount of available material in the drainage catchment. Sediment transport (in tons per day) for the hydrological year is thus computed as the sum of two independent daily contributions of sediment discharge. The first, Fmob(t), originates from a limited reservoir which is full at the beginning of the flood and available only temporarily, during the rainy season. At a given time t, the sediment input Fmob(t) is proportional to the amount remaining in the limited reservoir and to a power function of water discharge (Eq. (1), Eq. (2)). The second reservoir, temporally and quantitatively unlimited, injects a daily sediment discharge Fec(t) which is a power function of water discharge (Eq. (3)); Fec(t) is limited only by river capacity. The final concentration is obtained from Equation (4). The five model parameters were calibrated with concentration and discharge data from hydrological years 1991 / 92 to 1995 / 96. The unlimited reservoir parameters were estimated using Equation (6) with data taken during the decreasing stage. Initial sediment in the limited reservoir was estimated with Equation (7), using observed concentrations and concentrations derived from continuous erosion (Eq. (3)). Two parameters related to the decrease in initial sediment loads were obtained by optimization of the mean Nash criterion between observed and calculated concentrations (Figure 6). Some physical interpretations were ascribed to coefficients related to the limited reservoir. Despite the limitations of assuming a single initial mobilizable reservoir, predictions of temporal sediment-concentration patterns during the annual flood were satisfactory (Figure 7, Table 2). The model also simulated some observed sediment concentration peaks associated with sudden water discharge variations during the rising limb of the annual flood. Best results were obtained by varying initial sediment reservoir estimates for different hydrological years (Table 3) -the model could therefore be improved by highlighting parameters that determine sediment loads at the beginning of the hydrological year. The model does not give better estimates of annual sediment yield than simple regression of annual water volume (Table 4). However, it is able to reproduce the temporal variability of the sediment flux during the annual flood. The small size of the data set makes evaluation of the performance of this model difficult; for better assessment, it should applied to other data gathered on the same catchments or on other large tropical rivers. Model parameter values could also be explained by drainage basin characteristics...|$|E
40|$|L'étude de la réponse hydrologique de deux bassins versants de l'agglomération de Bordeaux en France a montré que les pertes initiales au ruissellement sur les {{surfaces}} imperméables étaient responsables des écarts entre {{le volume}} ruisselé et le volume prévu <b>proportionnel</b> à la lame d'eau tombée sur un bassin versant. Les pertes initiales, qui n'excèdent pas 2 à 3 mm, dépendent essentiellement de l'état de saturation des surfaces imperméables au début de la pluie. Cet état initial des surfaces imperméables dépend lui-même des antécédents pluvieux, notamment des conditions hydrologiques et météorologiques depuis la dernière pluie qui précède l'événement pluvieux considéré. Afin d'estimer quantitativement les pertes au ruissellement au cours d'une pluie, un modèle d'évaporation nommé EVA a été développé. Les données météorologiques sont utilisées afin d'évaluer, à partir d'un bilan énergétique simplifié entre l'eau et l'air, la lame d'eau évaporée des surfaces imperméables entre deux pluies successives. Après une pluie, il faut de un à trois jours selon la saison pour que l'eau stockée dans les dépressions de surface soit totalement évaporée, sur les bassins testés. Le modèle a été testé avec les mesures disponibles sur deux bassins versants urbains de la région bordelaise dont la surface totale n'excède pas 6 hectares. Quantitativement, on montre qu'il est possible de prédire les pertes au ruissellement avec une précision de 0, 5 mm dans 65 % des cas étudiés. Les 35 % d'épisodes où l'on se heurte à des difficultés sont des séquences de faibles épisodes pluvieux séparés par quelques heures et n'excédant pas 3, 0 mm. La modélisation du remplissage partiel des dépressions de surface des terrains imperméables est alors trop sommaire. The {{subject of this}} article is runoff losses in an urban environment, specifically initial losses through impermeable surface depressions directly connected to the network. For this purpose the hydrological behavior of two urban watersheds (Batany and Trianon) of about 5 hectares each, in the Bordeaux region of France, have been studied to observe that the fluctuations around the "Rainfall Amount versus Runoff Volume" law essentially derive from initial runoff losses which differ from one rainfall event to another. The fluctuations around this law make it impossible to precisely estimate runoff volume based on rainfall. Improved knowledge of initial losses would result in better estimation of the runoff volume of more regular (monthly or bi-monthly) rainfall events, which must increasingly be treated at water treatment plants {{in order to be able}} to better control the overflows. If the involvement of permeable surfaces is assumed to be negligible, we can postulate that the initial losses from a given rainfall event are directly linked to the water stored on the impervious surfaces connected to the network. The moisture content prior to the event is dependent upon the occurrence of a previous rainfall event and on the meteorological conditions prevailing between the previous rainfall event and the one under study. A model, called the EVA model, has been developed with the objective of predicting runoff losses corresponding to a rainfall event as a function of the previously prevailing watershed moisture conditions. The model evaluates the amount of evaporation from the water contained in the surface depressions between two successive rainfall events, called the initial rainfall event and the final rainfall event. The initial rainfall event represents the previous rainfall event, and the final rainfall event is the event for which the losses are to be estimated. The application of the model requires a very good record of the small rainfall events which have occurred during the modelling periods, and which are called the intermediate rainfall events. In practice, this constraint implies the need to monitor the dispersed rainfall events which, even if they cause only very light runoff, nonetheless contribute to a partial filling of the surface depressions present on the impervious terrain. The equations used in the model are those which correspond to the energy balance between air and water using the net radiation, the latent, sensible and storage heat (the soil heat flux is considered negligible). The EVA model uses meteorological data such as the air temperature, relative humidity, wind speed and solar radiation. The model evaluates two variables: water depth and water temperature. Since water depth after evaporation is known, the losses of a rainfall event can be estimated by subtracting the total volume of water which has evaporated during the dry period from a maximum value of the losses. The modeled losses are then compared with the measured losses. In order to simplify the resolution of the problem, the total water volume contained in the thousands of surface depressions present in the watershed is considered to be contained in a single depression called a representative depression. This representative depression can take different forms and have different initial heights, which have been tested while the work was in progress. The model is found to be coherent in terms of the variations in water depth in the surface depressions. The total water volume contained in the surface depressions takes from 1 to 3 days to evaporate depending on the season. The variation in water depth is caused by differences in evaporation rates occurring during the months close to the summer solstice and during the cooler months. The first version of the model was created in 1992 and tested on two watersheds of about 250 hectares each in the Paris area. The model was modified and the new results were compared with the measurements obtained in two watersheds in the city of Bordeaux. The performance of the model was evaluated for 17 rainfall events, of which 10 were in the Batany watershed and 7 in the Trianon basin. The model accurately predicts the losses corresponding to a rainfall event within 0. 5 mm, in two cases out of three. The problem encountered in the remaining one-third of the cases was essentially that it is difficult to account for runoff during intermediate rainfall events because of very low flow rates and small rainfall depth measurements. Experimental equipment installed in two watersheds in Bordeaux has made it possible to obtain relatively precise pluviometric and discharge measurements. However, there is uncertainty concerning these measurements, which is inherent in this field, when it comes to validating a model like EVA because such a model is used for regular rainfall events for which the initial losses directly influence the runoff volume. However the a priori knowledge of initial runoff losses should enable better use of a model which, for example, assumes that the runoff coefficient increases progressively at the beginning of the rainfall event. The validation of such a model was attempted while the work was under way, but ran into the difficulty of selecting a set of rainfall events characterized by constant rainfall intensity. The development of a model like EVA requires rainfall and flow measurements which are free of uncertainties and accessible within experimental watersheds which are perfectly monitored and where the measurement uncertainties are the same for all observable measurement ranges (in particular for the discharge measurements). These requirements currently constitute a technical barrier in terms of measurement that will be difficult to surmount. However, the work carried out in this research hints at the possible improvement of the classical hydrological models used in urban hydrology, particularly those used for forecasting the runoff volumes of regular rainfall events...|$|E
40|$|SUMMARYThis methodological {{study of}} {{quantitative}} electroencephalography {{starts with the}} history of EEG methods of analysis and of their applications. This thesis is basically focused on a comparative study of the most important methods of analysis. In the presentation of methods I first present the analysis of the instantaneous amplitude histograms of EEGs which is dependent upon the sampling frequency. Considering now the Fourier spectral analysis this method implies to take quite a number of precautions before being properly applied to EEG. For instance, it is necessary to compute enough measures to allow later on the statistical validation of a power spectrum analysis G(f). Then, I propose the example of spectral multiple EEG channels analysis, which is based on the method of spectral regression. This method of analysis gives more precisely the relations of causality at specific frequencies by finding their sources across EEG channels and determining if those sources are based on real signals source or random noise. I have later specified the mathematical relations between the integrative method of Drohocki and spectral analysis. The mean value l of n measures of successive epochs of an EEG signal, which is rectified and integrated: l is proportional to the root­mean­square (rms) value of the analyzed signal and also to its standard error. The coefficient of variation CV(l) of the integrated measures is proportional to the spectral coefficient of variation CV(k), which for a first approximation is equal to k/√T, with T being the time epoch of analysis and k a “coefficient of spectral regression” that I have defined by the formula (k 2 = ∑G 2 /(∑G) 2) in reference to Blackman and Tuckey. This presentation of methods is achieved with the period analysis and its relations to spectral analysis, followed by a brief survey of new heuristic methods, which are mimicking the electroencephalographist practitioner in his way and are applying methods of linear prediction. My results are divided into three chapters. In the first chapter I present first Applications of quantitative EEG recorded in rat. Then I give three examples of applying the integrative method of Drohocki. First by computing the ratio of integrated values of ECoG/EMG for quantifying the phases of wakefulness and sleep. When this ratio is above or below an experimentally first computed predetermined threshold, this ratio can well determine the state of wakefulness or sleep. I have applied this technique {{to the study of the}} hypovariability of the ECoG and of the neck muscles EMG recorded in rats before and after administration of neuroleptics. The ECoG/EMG ratio provides the time­course of the electro­pharmacokinetic effect through hours of the neuroleptic treatment. Secondly I have studied the statistical decomposition of the observed polymodal composite distributions of values of integrated ECoG signals computed over successive periods of one­hour time span. Such an analysis provides a decomposition of these polymodal distributions into a sum of elementary Gaussian distributions. Each elementary Gaussian distribution being specific of a homogeneous state of vigilance. Thirdly, this chapter is mainly concerned with the comparative study between the three different tracings of occipital ECoG in the rat for quantifying homogeneous phases of wakefulness, slow wave sleep and REM sleep (paradoxical sleep). The four principal methods of EEG analysis previously compared theoretically, have then been now compared experimentally, based on the three different states of vigilance. I have first verified the precedent mathematical relationships established between the integrative method and spectral analysis. By correlation analysis and multi­linear regression, I have been able to obtain pertinent information which has been reduced to 5 independent parameters. Step-by­step discriminant analysis has shown that the mean frequency of the spectral peak and the mean integrated amplitude are sufficient for a good discrimination between the three analyzed states of vigilance. The second chapter of results is based on EEG recordings in man. in order to give Applications of quantitative EEG recorded in man. I describe a program of statistical spectral analysis, which works in real time based on four EEG channels simultaneously recorded with a double rejection of artifacts and a pre­treatment of the sampled EEGs. After longitudinal studies of different quantified recordings I have computed a four factor variance analysis on a transversal study sample of EEG recordings for a group of 7 subjects receiving two different treatments (placebo at the beginning of the night before and nitrazépam 5 mg, p. o. the day after), 2 sequences (eyes open followed by eyes closed EEG recordings), 4 posterior EEG channels, and computed characteristic spectral parameters. Results of variance analysis reveal that only sequences and parameters appear to be statistically different. Later further 3 factor variance analyses over the 32 computed spectral parameters have found, which parameters are the best discriminant parameters between EEG sequences : the spectral peak, the coefficient of resonance and of complexity, the fast mean frequencies. etc. These factorial analyses have allowed me to compare spectral differences between two mean power spectra by applying Student t tests in different conditions : between treatments, sequences, EEG channels and between subjects. Finally, in the third chapter of results, I have presented a first modulation analysis of EEG by applying Hilbert transform to EEG. Starting from an EEG signal x(t) we can evaluate a signal y(t), which is characterized by a Gaussian random narrow band process, from an analysis of modulation y(t) = m(t) cos(ω 0 t + φ(t)), with m(t) being the amplitude modulation and φ(t) the frequency modulation around a broadcasting frequency ω 0 = 2 πfo. This modulation analysis is based on the Hilbert transform ˆx(t) obtained from the Fourier transform X(f) of x(t), by a multiplication by (­j. sign(f)) followed by inverse transformation. This gives directly the computation of the “envelope” m(t) of x(t), in the radioelectric sense of the word envelope. The frequency modulation is obtained directly by derivation of the phase modulation. I have applied this analysis to the precedent three tracings of states of vigilance in rat. I have found that the hippocampal theta rhythm is characteristic of a specific amplitude modulation during the REM state of sleep in rat together with a frequency modulation, which is not present in the two other states of wakefulness and of slow wave sleep in rat. This last method can be applied in case of non­stationary EEG tracings and it keeps all the signal information. The amplitude and frequency modulations are specific respectively of the instantaneous amplitude and frequency and we know the difficulty to obtain directly this last instantaneous frequency. This is why I have attempted to apply the techniques of statistical radioelectricity in quantitative electroencephalography. In this thesis, which is based on 15 articles, I have wanted to illustrate the theory of analysis of electrobiological signal by some various examples of applications in animal and in man. I have wished to show also how new methods of analyses may lead and drive to new applications. Cette étude méthodologique de l'électroencéphalographie quantitative fait d'abord l'historique des méthodes d'analyse de l'EEG et de leurs applications. Cette thèse est centrée principalement autour de la comparaison des principales méthodes d'analyse. Dans l'exposé des méthodes, je présente tout d'abord l'analyse des histogrammes d'amplitudes instantanées de l'EEG, qui dépend de la fréquence d'échantillonnage. L'analyse spectrale exige un certain nombre de précautions pour être correctement utilisée. C'est ainsi qu'il convient de moyenner suffisamment les mesures effectuées si l'on veut procéder à une validation statistique d'un spectre de puissance G(f). Je propose ensuite l'exemple d'une analyse multivoies appliquée à quatre dérivations enregistrées simultanément et qui utilise la méthode de "régression spectrale". Cette analyse permet de préciser les relations de causalité de fréquences particulières, en déterminant leur origine parmi les dérivations et s'il s'agit d'une source ou d'un bruit. J'énonce ensuite les relations mathématiques qui relient particulièrement la méthode intégrative de DROHOCKI et l'analyse spectrale. La moyenne I de n mesures successives d'EEG redressé et intégré, est proportionnelle à la valeur efficace du signal analysé, ou bien encore à son écart type. Le coefficient de variation des mesures intégrées CV(I) est <b>proportionnel</b> à un coefficient de variation spectral CV(k) qui est égal en première approximation à k/√T. où T est la période d'analyse et k est un "coefficient de résonance spectral" que j'ai défini (k 2 = ∑G 2 /(∑G) 2) en référence aux travaux de BLACKMAN et TUKEY. L'exposé des méthodes s'achève par l'analyse de période et ses relations avec l'analyse spectrale, puis par un bref aperçu des nouvelles méthodes d'analyse, heuristiques, imitant la démarche de l'électro encéphalographiste ou utilisant des méthodes de prédiction linéaire. Mes résultats sont divisés en trois chapitres. Dans le premier chapitre, je présente des applications de l’électroencéphalographie quantitative chez le rat. Je donne ainsi trois exemples d'utilisation du rapport des valeurs intégrées ECoG/EMG; pour la quantification des phases d’évei 1 et de sommeil, par rapport à un dépassement de seuil prédéterminé et pour l'étude de l'hypovariabilité des tracés observée après administration de substance neuroleptique. Puis, j'étudie la décomposition statistique des distributions composites polymodales des valeurs intégrées d'ECoG, calculées pour des périodes successives d'une heure. Cette analyse permet de décomposer simplement en une somme de distributions gaussiennes élémentaires les distributions polymodales. Chaque distribution élémentaire correspond alors à un état de vigilance homogène. Enfin, ce chapitre est surtout consacré à l'étude comparée de trois tracés d'ECoG occipital pour des phases homogènes d'éveil, de sommeil à ondes lentes et de sommeil paradoxal. Les quatre principales méthodes d'analyse de l'EEG ont été ainsi comparées à partir de ces trois tracés. J'ai tout d'abord vérifié les relations mathématiques établies au préalable entre la méthode intégrative et l'analyse spectrale. Par analyse de corrélation et de régression multilinéaire, j'ai pu réduire l'information pertinente à 5 paramètres indépendants entre eux. Une analyse discriminante pas à pas a alors montré que la fréquence dominante du pic spectral et l'amplitude moyenne I suffisaient à bien discriminer entre eux les trois états de vigilance analysés. Le deuxième chapitre de résultats fait état d'applications de l’électroencéphalographie quantitative chez l’homme. J'expose le programme d'analyse spectrale statistique qui fonctionne en temps réel, à partir de quatre dérivations enregistrées simultanément et qui utilise un double rejet d'artéfacts ainsi qu'un prétraitement des EEG échantillonnés. Après des études longitudinales de divers enregistrements quantifiés, j'ai effectué une analyse de variance à quatre facteurs pour l'étude transversale d'un ensemble de tracés de 7 sujets: 2 traitements (placebo la veille au soir et nitrazépam 5 mg, p. o. le lendemain), 2 séquences (yeux ouverts ou fermés), 4 dérivations postérieures, et les paramètres spectraux caractéristiques. Seuls, les séquences et les paramètres apparaissent significativement différents. Puis des analyses de variance à trois facteurs pour chacun des 32 paramètres spectraux caractéristiques calculés révèlent quels sont ceux qui discriminent le mieux entre les traitements: pic spectral, coefficient de résonance et de complexité, fréquences rapides, etc. Ces analyses factorielles m'ont permis de valider l'utilisation de l'épreuve du t de Student appliquée aux différences spectrales que je préconise afin de comparer entre eux deux spectres moyens de puissance dans différentes conditions: intertraitements, interséquences, interdérivations, intra et intersujets. Enfin, dans le troisième chapitre de résultats, j'ai présenté l’analyse de modulation de l’EEG, qui partant d'un signal x(t), permet d'évaluer un signal y(t), caractérisant un processus aléatoire gaussien à bande étroite à partir d'une analyse de modulation: y(t) = m(t) cos(ω 0 t + φ(t)), où m(t) est alors la modulation d'amplitude et φ(t) la modulation de phase autour d'une fréquence porteuse ω 0 = 2 πfo. Cette analyse de modulation utilise la transformée de Hilbert ˆx(t) obtenue à partir de la transformée de Fourier X(f) de x(t), par multiplication par (-j. signef) et transformation de Fourier inverse. Cela conduit directement au calcul de "l'enveloppe" m(t) de x(t), au sens radioélectrique du terme. La modulation de fréquence est obtenue directement par dérivation de la modulation de phase. J'ai appliqué cette analyse aux tracés des trois états de vigilance chez le rat. J'ai trouvé pour le rythme thêta hippocampique caractéristique du tracé de sommeil paradoxal, une modulation d'amplitude particulière ainsi qu'une modulation de fréquence qui n'apparaît pas pour les deux autres tracés analysés. Cette dernière méthode est susceptible d'être appliquée dans le cas de tracés non-stationnaires, elle conserve toute l'information du signal. Les modulations d'amplitude et de fréquence caractérisent respectivement l'amplitude et la fréquence instantanée, on connaît la difficulté de l'obtention directe de cette dernière. J'ai ainsi tenté d'élaborer une première utilisation des techniques de radioélectricité statistique en électroencéphalographie quantitative. Dans cette thèse, qui s'appuie sur 15 publications, j'ai voulu illustrer la théorie de l'analyse du signal électrobiologique par des exemples d'applications variées pris chez l’homme et l'animal. J'ai souhaité montrer en retour que de nouvelles méthodes d'analyse peuvent conduire à de nouvelles applications...|$|E

