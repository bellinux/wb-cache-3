17|82|Public
5000|$|... 2012: Shortlisted for the Deutsche Börse Photography Prize, for <b>Permanent</b> <b>Error.</b>|$|E
5000|$|... 2010: <b>Permanent</b> <b>Error,</b> Michael Stevenson, Cape Town, South Africa, 2010; Brodie Stevenson, Johannesburg, South Africa, 2010; Scotiabank CONTACT Photography Festival, Toronto, Canada, 2011; Yossi Milo Gallery, New York, 2011 ...|$|E
50|$|In {{some cases}} {{hardware}} components have specific features to assist a diagnostic program to test it. For example, most modern hard drives have commands that {{provide information about}} some <b>permanent</b> <b>error</b> conditions. Also, some systems with ECC memory will log memory failures that were automatically corrected.|$|E
40|$|We propose link {{structures}} for NoC that have properties for tolerating efficiently transient, intermittent and <b>permanent</b> <b>errors.</b> The protection against transient errors is realized using Hamming coding and interleaving for error detection and retransmission as the recovery method. We introduce two approaches for tackling the intermittent and <b>permanent</b> <b>errors.</b> In the first approach, spare wires are introduced together with reconfiguration circuitry. The other approach uses time redundancy, the transmission is {{split into two}} parts, where the data is doubled. In both structures the presence of <b>permanent</b> or intermittent <b>errors</b> is monitored by analysing previous error syndromes. The links are based on self-timed signaling in which the handshake signals are protected using triple modular redundancy. 1...|$|R
40|$|Analysis of the {{substrate}} coupling in integrated circuits is done {{taking into account}} technology and layout parameters for different types and location of transistors using a device-level simulator. The noise coupling tendencies of IC scaling are analysed, following interest in advanced technologies. The potential for <b>permanent</b> <b>errors</b> {{is shown in the}} case of a RAM cell. A circuit-level model for the coupling mechanism is proposed. The implementation of an IC for experimentation, and the measurements obtained, are discussedPeer ReviewedPostprint (published version...|$|R
40|$|Abstract—Fault-tolerance {{has become}} an {{essential}} concern for processor designers due to increasing transient and permanent fault rates. In this study we propose SymptomTM, a symptombased error detection technique that recovers from errors by leveraging the abort mechanism of Transactional Memory (TM). To {{the best of our}} knowledge, this is the first architectural fault-tolerance proposal using Hardware Transactional Memory (HTM). SymptomTM can recover from 86 % and 65 % of catastrophic failures caused by transient and <b>permanent</b> <b>errors</b> respectively with no performance overhead in error-free executions. I...|$|R
5000|$|... 2012 winner John Stezaker for his self-titled {{exhibition}} at Whitechapel Gallery, London. Also shortlisted were Pieter Hugo, for the publication <b>Permanent</b> <b>Error</b> (Prestel, 2011); Rinko Kawauchi, for the publication Illuminance (Kehrer, 2011); and Christopher Williams for his exhibition Kapitalistischer Realismus at Dům umění České Budějovice, Budweis, Czech Republic.|$|E
5000|$|Hugo's {{first major}} work Looking Aside (2006) is portraits of people [...] "whose {{appearance}} makes us look aside" [...] - the blind, people with albinism, the aged, {{his family and}} himself. Each man, woman and child poses in a sterile studio setting, under crisp light against a blank background. His Rwanda 2004: Vestiges of a Genocide (2011) was described by the Rwanda Genocide Institute as offering [...] "a forensic view {{of some of the}} sites of mass execution and graves that stand as lingering memorials to the many thousands of people slaughtered." [...] Hugo's most recognized work is The Hyena & Other Men (2007), which has received a great deal of attention. His series Messina/Mussina (2007) was made in the town of Musina on the border between Zimbabwe and South Africa, after Colors magazine asked Hugo to work on an AIDS story. Nollywood (2009) consists of pictures of the Nigerian film industry. For <b>Permanent</b> <b>Error</b> (2011) Hugo photographed the people and landscape of an expansive dump of obsolete technology in Ghana. Sean O'Toole writes [...] "if Nollywood was playfully over-the-top, a smart riposte to accusations of freakishness and racism levelled at his photography..., <b>Permanent</b> <b>Error</b> marks Hugo’s return to a less self-reflexive mode of practice." ...|$|E
50|$|Arrow took on {{approximately}} 16,000 tons (10 million litres) of bunker C oil in Aruba, off {{the coast}} of Venezuela under charter to Imperial Oil Limited, bound for the Stora paper mill in Point Tupper, Nova Scotia.On February 4, 1970 in Chedabucto Bay, off the east coast of Nova Scotia in a gale and only 14.6 nautical miles from her destination, she ran hard aground on Cerberus Rock, a known, well-charted hazard to navigation. The tanker ran aground mid-morning, halfway between high and low tide, being driven by 60 knot southwesterly winds and blinded by a heavy mist. The impact drove the forward section of the tanker onto the rock formation wedging it with the starboard side hard against the rock pinnacle. Efforts to free her from the rock failed as did efforts to pump her cargo into salvage vessels and pounded by wind and wave action broke in two on February 8, 1970 spilling about two-thirds of her cargo. The subsequent inquiry revealed that Arrow's depth sounder had not been operational for two months, her autogyro compass showed a <b>permanent</b> <b>error</b> of three degrees west and her radar failed about an hour before she ran aground.|$|E
40|$|International Conference on Control, Decision and Information Technologies (CoDIT), Ecole Natl Ingenieurs Metz, Metz, FRANCE, NOV 03 - 05, 2014 International audienceIn this paper, a self-organized {{reliability}} {{technique is}} presented to test the Network on Chip (NoC) parts of networked reconfigurable MPSoC. We propose a new mechanism based on delocalized offline tests to detect and locate <b>permanent</b> <b>errors</b> in the NoC through networked multi-nodes system. Concepts and mechanisms of the proposed approach are detailed {{in the case of}} a network system based on Zigbee wireless communication where error detections and timing performance are giving...|$|R
40|$|FPGA-based {{designs are}} more {{susceptible}} to single-event upsets (SEUs) compared to ASIC designs, since SEUs in configuration bits of FPGAs result in <b>permanent</b> <b>errors</b> in the mapped design. Moreover, the number of sensitive configuration bits is two orders of magnitude more than user bits in typical FPGA-based circuits. In this paper, we present a high-reliable low-cost mitigation technique which can significantly improve the availability of designs mapped into FPGAs. Experimental results show that, using this technique, the availability of an FPGA mapped design can be increases to more than 99 %. ...|$|R
50|$|<b>Permanent</b> Fatal <b>Error's</b> {{music can}} be {{described}} as folk, post-rock, alternative, experimental, free-rock, indie, post-punk but mostly deaf-blues. They produce soundtracks and play rock with acoustic guitars with electronic sounds.|$|R
40|$|Abstract—This paper {{presents}} a reliability-configurable coarse-grained reconfigurable array for signal processing, which offers flexible reliability to soft error. A notion of cluster is introduced {{as a basic}} element of the proposed reconfigurable array, each of which can select one of four operation modes with different levels of spatial redundancy and area-efficiency. Evaluation of <b>permanent</b> <b>error</b> rates demonstrates that four different reliability levels {{can be achieved by}} a cluster of the reconfigurable array. A fault-tolerance evaluation of Viterbi decoder mapped on the proposed reconfigurable array demonstrates that there is a considerable trade-off between reliability and area overhead. I...|$|E
40|$|This paper {{proposes a}} {{coarse-grained}} dynamically reconfigurable architecture, which offers flexible reliability to soft errors and aging. A notion of cluster is introduced {{as a basic}} element of the proposed architecture, each of which can select four operation modes with different levels of spatial redundancy and area-efficiency. Evaluation of <b>permanent</b> <b>error</b> rates demonstrates that four different reliability levels {{can be achieved by}} the proposed architecture. We also evaluate aging effect due to NBTI, and illustrate that alternating active cells with resting ones periodically will greatly mitigate the aging process with negligible power overhead. The area of additional circuits to attain immunity to soft errors and reliability configuration is 26. 6 % of the proposed reconfigurable device. Finally, a fault-tolerance evaluation of Viterbi decoder mapped on the proposed architecture suggests that there is a considerable trade-off between reliability and area overhead. 1...|$|E
40|$|The {{controller}} {{area network}} (CAN) protocol was initially developed for the automotive industry to support low-level communication services between modules in distributed car control systems. Nowadays CAN is used in many other real-time applications, some of them requiring dependable behavior. When designing CAN based dependable systems the bus topology of CAN is a {{single point of failure}} {{that needs to be addressed}} either through bus replication or by adopting alternative topologies with better fault-tolerance capabilities, e. g., star topologies. This paper proposes a set of components, an architecture and protocols to enable the dynamic management of the topology of CAN networks made of several replicated buses, both to increase the total available bandwidth and to reconfigure the network upon bus <b>permanent</b> <b>error.</b> In many operational scenarios, the proposed solution could be plugged into existing systems to improve its resilience to bus permanent errors, without changing the code running in the nodes. DET...|$|E
40|$|Voting schemes {{are widely}} used in {{fault-tolerant}} systems, mainly systems which imply temporal or component redundancy. We present a voting scheme for multithreaded environments {{which is based on}} the observation that a faulttolerant system which does not know its history can not distinguish between transient (SEUs) and <b>permanent</b> <b>errors,</b> caused by use of a faulty component. The history of errors is used to predict future errors and to determine if a <b>permanent</b> or transient <b>error</b> occurred. Only in the former case a repair is necessary; in the latter case recovery is sufficient. Using prediction and credibility points we are able to tell if a system failure is likely to occur soon. The more credibility a version has, the more likely it will compute a correct result. Therefore we can use credibility points in connection with thread priorisation to increase performance. ...|$|R
30|$|Time based {{errors are}} {{generated}} {{due to the}} applications that do not complete the execution within a specified deadline, or the problems faced by the applications in different time intervals in a distributed environment. Transient, intermittent, and <b>permanent</b> <b>errors</b> are classified as time based errors (Arshad 2006). The probability of occurrence of a transient error is very less and they occur either very seldom or once in {{the life cycle of}} an application and then disappear. On the other hand, intermittent errors can be observed many times in an irregular fashion (Siva Sathya and Syam Babu 2010).|$|R
40|$|Abstract—We {{propose to}} {{partition}} links in a network-on-chip into multiple segments and use spare wires {{at the level}} of each segment to address <b>permanent</b> <b>errors</b> due to manufacturing or wearout defects. Because different segments of the spare wires address different errors from different segments, the proposed reconfigurable link structure can tolerate a larger number of errors with a reduced number of spare wires. The proposed self-repairing segmented link structure is implemented and simulated in Verilog and verified on a Virtex 5 FPGA. Experimental results on area, power consumption, delay, and reliability show that the optimal link is achieved when the link is partitioned into two segments. I...|$|R
40|$|This study {{addresses}} {{an issue}} of global concern in skills training, namely, the rapid and permanent eradication of persistent habit errors, and bad or unsafe working practices. This article offers an alternative human factors explanation for the profound difficulties and low transfer of training experienced during error pattern retraining, and the correction of habitual performance faults. It describes Old Way New Way, a metacognitive strategy for achieving rapid and <b>permanent</b> <b>error</b> and technique correction and habit unlearning, and {{presents the results of}} an experimental trial of this behaviour change methodology. Vocational education students, representing a broad range of skill types, were recruited and randomised to one of two error correction modes, or to a control group. One Old Way New Way correction session with students yielded 80 % or higher performance improvement that was maintained over three post-test periods. Students and teachers reacted positively to the Old Way New Way c. The high level of transfer of learning obtained is consistent with results in other settings. Implications for education, training, coaching and other performance enhancement settings are discussed...|$|E
40|$|Steering a Satellite-Launch Vehicle (SLV) to {{strictly}} {{follow a}} predefined trajectory imposes unnecessary {{load on the}} control loop, and may, possibly, saturate servos. This If may introduce a <b>permanent</b> <b>error</b> in the vehicle-destination position and velocity vectors. Consequently, the payload (the satellite) would be deployed in a wrong orbit. The orbital-error correction utilizes onboard energy, which reduces the operational life of the satellite. Therefore, it is desirable that SLV is capable of altering its trajectory {{according to the new}} operating conditions, in order to achieve the required destination position and velocity vectors. In this paper, an innovative adaptive scheme is presented, which is based on “the Multi-Stage-Q System”. Using the control laws expressed in the elliptic-astrodynamical-coördinate mesh (the normal-component-cross-product steering and the normal-component-dot-product steering) this scheme proposes a design of autopilot, which achieves the pre-decided destination position and velocity vectors for a multi-stage rocket, when each stage is detached from the main vehicle after it burns out, completely. In “the Inverse-Q System”, one applies the extended-cross-product steering to the vector sum of velocity vectors of spacecraft and interceptor...|$|E
40|$|Filled with startling {{portraits of}} Africa’s raw and tragic beauty, this first {{retrospective}} of Peter Hugo’s award-winning work collects {{the most important}} images from the photographer’s career to date. Pieter Hugo has been documenting his native continent of Africa since his late teens. An autodidact, he was eventually drawn to portraiture, an interest that culminated with his hugelypopular book, The Hyena and Other Men. Since that book, Hugo has continued to earn high praise while testing {{the limits of the}} traditional portrait. As Aperture magazine observes, “Hugo maneuvers through the muddy waters of political engagement, documentary responsibility, and the relationship of these to his own aesthetic. ” In the books Nollywood and <b>Permanent</b> <b>Error</b> he suffuses a journalist’s perspective and a voyeur’s theatricality into images of Africa’s people and environment. This retrospective volume collects photographs from each of his earlier series as well as portraits and landscapes that have never been shown or published before. Essays by three esteemed photographic critics contextualize Hugo’s career within the realm of contemporary photography. Full-page color illustrations highlight Hugo’s extraordinary talent for teasing out the subtleties in otherwise stark images...|$|E
40|$|This paper {{provides}} a human capital theory-based {{explanation for the}} presence of a permanent component in earnings levels as well as individual heterogeneity in earnings slopes. We incorporate uncertainty about the future rental rates of human capital into a life-cycle human capital investment model and obtain an earnings equation implied by the solution to the worker's optimal investment decision. While heterogeneous growth stems from individual heterogeneity in the ability of human capital production, <b>permanent</b> <b>errors</b> are induced by the response of optimal investments to transitory rental rate shocks. We empirically show that both components are present. (c) 2010 by The University of Chicago. All rights reserved [...] ...|$|R
50|$|Law Speed is {{the first}} album by French/Italian post-rock band <b>Permanent</b> Fatal <b>Error,</b> a project by Olivier Manchion, founder member of the band Ulan Bator. The album was {{recorded}} in Italy at URS studio (Villa Minozzo, Emilia-Romagna).|$|R
40|$|Electronic {{equipment}} {{operating in}} harsh environments such as space {{is subjected to}} a range of threats. The most important of these is radiation that gives rise to <b>permanent</b> and transient <b>errors</b> on microelectronic components. The occurrence rate of transient errors is significantly more than <b>permanent</b> <b>errors.</b> The transient errors, or soft errors, emerge in two formats: control flow errors (CFEs) and data errors. Valuable research results have already appeared in literature at hardware and software levels for their alleviation. However, there is the basic assumption behind these works that the operating system is reliable and the focus is on other system levels. In this paper, we investigate the effects of soft errors on the operating system components and compare their vulnerability with that of application level components. Results show that soft errors in operating system components affect both operating system and application level components. Therefore, by providing endurance to operating system level components against soft errors, both operating system and application level components gain tolerance...|$|R
40|$|Today 2 ̆ 7 s {{military}} and industry increasingly uses human-robot system to perform complex tasks, such as firefighting. Automated systems that support or even make important decisions require human operators {{to understand and}} trust automation in order to rely on it appropriately. This study used a real human-telerobot system performing a firefighting task in an unknown welding room {{to examine the effects}} of two different levels of automation associated with intermittent and permanent visual system degradation on human performance, trust in automation, mental workload and situation awareness. Twenty-four participants were divided into two groups based on the level of automation use. Each participant completed a series of three 30 -minutes sessions in which he or she was required to explore the threat targets in an unknown 2 ̆ 2 hazard 2 ̆ 2 welding room. Results indicated a significant difference between low and high level of control in collision rate when <b>permanent</b> <b>error</b> occurred. And in low level automation group the type of error had a significant effect on the collision rate, while it had a significant effect on situation awareness dimensions in both groups. Generally, in the experiment high level of automation had better performance than low level of automation especially if it is more reliable, suggesting that subjects in the high level of automation group could rely on the automatic implementation to perform the task more effectively and more accurately...|$|E
40|$|O presente artigo explora um diálogo entre a história e a filosofia da ciência. Nesta perspectiva, apresenta uma articulação entre a história da óptica e as principais características da filosofia histórica de Gaston Bachelard, dando ênfase: aos períodos de rupturas e descontinuidades presentes no constante confronto entre o modelo corpuscular e ondulatório da luz; à permanente retificação do erro - e ao novo conceito de verdade presente na construção da concepção sobre a natureza da luz -; à noção de recorrência histórica articulada à análise dos estudos sobre reflexão e refração; ao uso do recurso analógico na estruturação da hipótese ondulatória da luz, proposta por Huygens; e à dialética racionalismo-empirismo no exemplo da natureza dual dos elétrons. The present article {{explores the}} {{interaction}} between History and the Philosophy of Science. In this way, it presents an articulation between the History of Optics and the main characteristics of Gaston Bachelard´s historical philosophy. It emphasizes: firstly, the periods of rupture and discontinuities present in the confrontation between the light corpuscular and wave models; secondly, the <b>permanent</b> <b>error</b> rectification, {{in the sense that}} one knowledge abuts another, and the new concept of truth, present {{in the construction of the}} conception about the nature of light; thirdly, the notion of historical recurrence, articulated in the analysis of studies about reflection and refraction particularly Arquimedes' polemic of incandescent mirrors; fourthly, the use of analogical reasoning in the structuring of the light wave hypothesis proposed by Huygens; and finally, the rationalismempiricism dialectics in the example of the dual nature of the electron...|$|E
40|$|M. Comm. (International Accounting) The study {{investigates the}} {{potential}} effect of applying a fair value model after the grant date to employee share options. The research assesses {{the appropriateness of}} the requirements of IFRS 2 Share-Based Payment transactions with a specific focus on equity-settled Employee Share Options. The researcher has calculated the percentage movements or changes of fair value between each financial year including the overall percentage change. The study was mainly triggered by the IFRS 2 Share-Based Payment rules and various arguments from different authors challenging the appropriateness of IFRS 2 Share-Based Payment on employee share options (ESOs) transactions in capturing the full economic value transferred to the option holder at exercise date when applying a grant date accounting model. The study provides insights into whether a grant date accounting model is appropriate in measuring ESOs and capturing the full economic value transferred to the option holder. The application of a static fair value model in measuring the value of ESOs has the potential for both positive and negative effects on the compensation cost recognised in the financial statements over the vesting period. After analysing the descriptive financial data on fair value per option over the six year period included in the sample selection, a conclusion was reached that, IASB should consider to true-up or make a restatement of the opening balance of the fair value reserves account in order to minimise the potential <b>permanent</b> <b>error</b> in equity accounts and to minimise the potential effect of understating or overstating the compensation cost. The IASB should further consider the proper classification of equity instruments issued to employee ESOs which comply with other financial instrument accounting standards such as the IAS 32 – Financial Instruments: Presentation, and IFRS 9 Financial Instruments. This will ensure that transactions viewed as economic equivalents of each other are treated in the same way from an accounting perspective, and the correct measurement basis of ESOs may be achieved...|$|E
40|$|We have {{developed}} Argus, {{a novel approach}} for providing low-cost, comprehensive error detection for simple cores. The key to Argus is that the operation of a von Neumann core consists of four fundamental tasks—control flow, dataflow, computation, and memory access—that can be checked separately. We prove that Argus can detect any error by observing whether any of these tasks are performed incorrectly. We describe a prototype implementation, Argus- 1, based on a single-issue, 4 -stage, in-order processor to illustrate the potential of our approach. Experiments show that Argus- 1 detects transient and <b>permanent</b> <b>errors</b> in simple cores with much lower impact on performance (< 4 % average overhead) and chip area (< 17 % overhead...|$|R
40|$|License, which permits {{unrestricted}} use, distribution, {{and reproduction}} in any medium, provided the original work is properly cited. Electronic equipment operating in harsh environments such as space {{is subjected to}} a range of threats. Themost important of these is radiation that gives rise to <b>permanent</b> and transient <b>errors</b> onmicroelectronic components. The occurrence rate of transient errors is significantly more than <b>permanent</b> <b>errors.</b> The transient errors, or soft errors, emerge in two formats: control flow errors (CFEs) and data errors. Valuable research results have already appeared in literature at hardware and software levels for their alleviation. However, there is the basic assumption behind these works that the operating system is reliable and the focus is on other system levels. In this paper, we investigate the effects of soft errors on the operating system components and compare their vulnerability with that of application level components. Results show that soft errors in operating system components affect both operating system and application level components. Therefore, by providing endurance to operating system level components against soft errors, both operating system and application level components gain tolerance. 1...|$|R
40|$|Abstract—We {{propose a}} roll-forward error {{recovery}} technique based on multiple scan chains for TMR systems, called Scan chained TMR (ScTMR). ScTMR reuses the scan chain flip-flops employed for testability purposes {{to restore the}} correct state of a TMR system {{in the presence of}} transient or <b>permanent</b> <b>errors.</b> In the proposed ScTMR technique, we present a voter circuitry to locate the faulty module and a controller circuitry to restore the system to the fault-free state. As a case study, we have implemented the proposed ScTMR technique on an embedded processor, suited for safety-critical applications. Exhaustive fault injection experiments reveal that the proposed architecture has the error detection and recovery coverage of 100 % with respect to Single Event Upset (SEU) while imposing a negligible area and performance overhead as compared to traditional TMR-based techniques. I...|$|R
40|$|Recently, {{we witness}} a {{significant}} amount of effort be-ing put into a research of robustness of complex computer systems. Computer scientists noticed that, despite decades of investigations into dependability, computer systems still lack the degree of resilience which can be seen in biological systems. In the biological context, one of the main aspects that stand behind a system’s robustness is degeneracy [1] also known as distributed robustness [2]. We say that a system has a high degree of degener-acy if a high number of the system’s parts functionally overlap. A system designer can harness degeneracy and provide fault-tolerance through procedural (in contrast to structural) redundancy. A system element is structurally redundant if another element in the system provides iden-tical functionality. However, an element is procedurally redundant if various system parts can interact {{in such a way that}} it is possible to reproduce the element’s functionality. For illustration, consider a hypothetical calculator which was designed for degeneracy. Such a calculator does not have a central CPU, but its functionality is rather dis-tributed among number of function blocks which provide basic arithmetic operations (plus, minus, multiplication, and division). If one of the function blocks is affected by a <b>permanent</b> <b>error,</b> there is no other functionally identical element which could take over the lost function. Yet, the blocks functionally overlap. If, for example, the multipli-cation operator failed, the calculator could transform any multiplication into a sequence of additions and use the plus operator. If the plus operator failed, the minus operator can be used in a similar fashion. Dependable computer system of today are still clumsily “inorganic”, with a nonexistent or very low degree of adaptability. Procedural redundancy due to degeneracy is a promising way to achieve highly robust and adaptable systems. But designing for degeneracy, and that is where we want to make our point, requires a paradigm shift in the way computing is done. We argue for a novel model of computation which enables a design for degeneracy...|$|E
40|$|My MFA project {{consists}} of sculptural installations, videos and images that, {{together with the}} written text, comment {{on the impact of}} information technology on society. In both the written and practical components, I refer to my own experience and developments in fashion and access to information technology (IT) in my home country, the Democratic Republic of the Congo (DRC), with a focus on Kinshasa. I also explore aspects of the consumerist nature of IT in Africa more broadly and how this generates trends relating to ‘FOMO’, an internet slang acronym for the Fear Of Missing Out. My primary reason for connecting African fashion with contemporary computer technology is because both concern Western products being utilised in Africa in the context of self-determination. The African continent is a source of mining wealth, for example coltan (short for columbite-tantalite), a mineral widely used in technology. The DRC {{is one of the major}} coltan-producing countries, and yet it is technologically underdeveloped or limited itself because of an oppressive capitalist system (Pole Institute – blood minerals [PI], 2010 : 8 - 9), (PI, 2010). However, some of these minerals return to Africa in the form of products and create new consumers, desires and services in emerging contemporary technology contexts. In the process of upgrading to higher levels of technology, the developed world often uses Africa as a dumping zone for electronic waste (e-waste), with no regard for the environmental and human impact. For example, the UN environment programme's 2012 and 2013 report under the Waste for Electrical and Electronic Equipment (WEEE) legislation showed that thirty percent of the allegedly second-hand products imported to Ghana were useless (African WEEE Report by the UN Environment Programme [AWRUNEP], 2012). Pieter Hugo's photographs in the book <b>Permanent</b> <b>Error</b> (2011) provide strong visual evidence of this. Although I’m aware of the debate around issues of representation and ‘afro pessimism’ generated by Hugo’s images, my motivation in using them is that they provide sufficient documentation of the realities of disposing of electronic waste and the impact on people and the environment pertaining to those particulars zones of Africa. I draw an analogy between the consumption of IT and African fashion, and specifically with my own country's culture of dressing-up, which has developed into a kind of doctrine (the ‘cult of the cloth’) and an expression of resistance. The analogy is linked to the desire to stay up to date with IT, which can lead to addiction. I also consider it useful to compare the symbolic and aesthetic aspects of African customs of hairdressing, the wearing of hats and jewellery, and even body modification as a social identification with today's society, within which ‘personal media’ are additional accessories for urban status. My reference and use of computer parts critique the way that contemporary technology has become an extension of our personal style, as in the fashion sense described above: a virtual identification which could also suggest a tendency towards an alienation of the body (because of the virtual social interaction and virtual identity) from its immediate environment that has manifested in our current psychological landscape. Consequently, I suggest the consumption of contemporary media in urban spaces opens up the notion of virtual anthropology or virtual cultural anthropology, related to the electronic personality or e-personality...|$|E
40|$|Fault {{attacks are}} one of the most severe attacks against secure {{embedded}} cryptographic implementations. Block ciphers such as AES, DES or public key algorithms such as RSA can be broken with as few as a single or a handful of erroneous computation results. Many countermeasures have been proposed both at the algorithmic level and using ad-hoc methods. In this paper, we address the problem of finding efficient countermeasures for RSA signature computations based on the Chinese Remainder Theorem for which one uses the inverse operation (verification) in order to secure the algorithm against fault attacks. We propose new efficient methods with associated security proofs in two different models; our methods protect against run-time errors, computation <b>errors,</b> and most <b>permanent</b> <b>errors</b> in the key parameters as well. We also extend our methods with infective computation strategies to secure the algorithm against doublefaults...|$|R
40|$|Abstract — Given {{the spatial}} and {{temporal}} randomness of soft and <b>permanent</b> <b>errors</b> in the state-of-the-art system-on-chips (SoCs), dynamic routing algorithms that can adapt themselves accordingly are highly required for network-on-chip (NoC) ap-plications. In this paper, we present a new dynamic routing algo-rithm for NoC applications that {{has the ability to}} locate and deal with both static and dynamic permanent failures and distinguish them from soft errors. In addition, our presented algorithm has the advantage of distributing the load over the whole network by considering the stress factors. Simulation results demonstrate the advantage of our routing algorithm in terms of functionality, latency, and energy consumption compared to directed flooding based fault tolerant routing algorithms in the presence of both soft <b>errors</b> and <b>permanent</b> faults. Our algorithm can achieves 1. 95 × less latency and consumes 3. 15 × less energy consumption on average. I...|$|R
40|$|Continued {{scaling of}} CMOS {{technology}} {{has led to}} increasing working temperature of VLSI circuits. High temperature brings a greater probability of <b>permanent</b> <b>errors</b> (failure) in VLSI circuits, which is a critical threat for real-time systems. As the multi-core architecture is gaining in popularity, this research proposes an adaptive workload assignment approach for multi-core real-time systems to balance thermal stress among cores. While previously developed scheduling algorithms use temperature as the criterion, the proposed algorithm uses reliability of each core in the system to dynamically assign tasks to cores. The simulation {{results show that the}} proposed algorithm gains as large as 10 % benefit in system reliability compared with commonly used static assignment while algorithms using temperature as criterion gain 4 %. The reliability difference between cores, which indicates the imbalance of thermal stress on each core, is as large as 25 times smaller when proposed algorithm is applied...|$|R
40|$|Abstract—Memory {{errors are}} {{a major source of}} {{reliability}} problems in current computers. Undetected errors may result in program termination, or, even worse, silent data corruption. Recent {{studies have shown that the}} frequency of <b>permanent</b> memory <b>errors</b> is an order of magnitude higher than previously assumed and regularly affects everyday operation. Often, neither additional circuitry to support hardware-based error detection nor downtime for performing hardware tests can be afforded. In the case of <b>permanent</b> memory <b>errors,</b> a system faces two challenges: detecting errors as early as possible and handling them while avoiding system downtime. To increase system reliability, we have developed RAMpage, an online memory testing infrastructure for commodity x 86 - 64 -based Linux servers, which is capable of efficiently detecting memory errors and which provides graceful degradation by withdrawing affected memory pages from further use. We describe the design and implementation of RAMpage and present results of an extensive qualitative as well as quantitative evaluation. Keywords-Fault tolerance, DRAM chips, Operating systems I...|$|R
