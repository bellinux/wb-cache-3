1144|409|Public
25|$|One {{possible}} {{solution to this}} anchor point <b>placement</b> <b>problem</b> is to remove the histogram binning grid completely. In the left figure below, a kernel (represented by the grey lines) is centred {{at each of the}} 50 data points above. The result of summing these kernels is given on the right figure, which is a kernel density estimate. The most striking difference between kernel density estimates and histograms is that the former are easier to interpret since they do not contain artifices induced by a binning grid.|$|E
500|$|A {{number of}} exact and {{approximate}} algorithms for the automatic label <b>placement</b> <b>problem</b> {{are based on}} 2-satisfiability. This problem concerns placing textual labels on the features of a diagram or map. Typically, the set of possible locations for each label is highly constrained, {{not only by the}} map itself (each label must be near the feature it labels, and must not obscure other features), but by each other: every two labels should avoid overlapping each other, for otherwise they would become illegible. In general, finding a label placement that obeys these constraints is an NP-hard problem. However, if each feature has only two possible locations for its label (say, extending to the left and {{to the right of the}} feature) then label placement may be solved in polynomial time. For, in this case, one may create a 2-satisfiability instance that has a variable for each label and that has a clause for each pair of labels that could overlap, preventing them from being assigned overlapping positions. If the labels are all congruent rectangles, the corresponding 2-satisfiability instance can be shown to have only linearly many constraints, leading to near-linear time algorithms for finding a labeling. [...] describe a map labeling problem in which each label is a rectangle that may be placed in one of three positions with respect to a line segment that it labels: it may have the segment as one of its sides, or it may be centered on the segment. They represent these three positions using two binary variables in such a way that, again, testing the existence of a valid labeling becomes a 2-satisfiability problem.|$|E
2500|$|When the Uhlan gear was {{incorporated}} in the Mark 14 design, the pressure sensing port for the depth mechanism was moved from its position on the cylindrical body to the cone-shaped tail section; the designers {{did not realize that}} move would affect the pressure readings. This repositioning meant that when the torpedo was moving, a hydrodynamic flow effect created a substantially lower pressure at the port than hydrostatic depth pressure. [...] The torpedo's depth control engine therefore thought the torpedo was too shallow depth and responded by trimming the torpedo to run deeper. A laboratory test (such as immersing a non-moving torpedo in a pool of water) would not be subject to the flow-induced pressure change and would show the torpedo trimmed at the desired depth. Dynamic tests using exercise heads with depth and roll recorders would have shown the depth problem, but the depth measuring port suffered from the same <b>placement</b> <b>problem</b> and gave consistent (though incorrect) measurements. The problem was also exacerbated by higher speeds. The depth problem was finally addressed in the last half of 1943 by relocating the sensor point to the midbody of the torpedo where hydrodynamic effects were minimized.|$|E
40|$|In {{this note}} we {{describe}} the solution of perfect square <b>placement</b> <b>problems</b> with CHIP. A set of 207 perfect square <b>placement</b> <b>problems</b> from [BD 92] is used. We present the constraint model in CHIP, which uses the global constraints diffn and cumulative together with a specific labeling routine for perfect <b>placement</b> <b>problems.</b> We show that all problems can be solved and present backtracking count and execution times for finding the first solution and for exploring the complete search space...|$|R
40|$|Although circuit {{placement}} {{has been}} studied for decades, it continuously attracts re-search attentions. The <b>placement</b> <b>problems</b> grow rapidly in both problem size and complexity. Some industry <b>placement</b> <b>problems</b> contain multi-million gates and ex-cessive number of blockages [1] [2]. In this chapter, we introduce DPlace, an ancho...|$|R
30|$|For most formulations, node <b>placement</b> <b>problems</b> {{are shown}} to be {{computationally}} hard to solve to optimality [4]–[7], and therefore heuristic and meta-heuristic approaches are useful approaches {{to solve the problem}} for practical purposes. Several heuristic approaches are found in the literature for node <b>placement</b> <b>problems</b> in WMNs [8]–[12].|$|R
50|$|ILP solvers, such as CPLEX, can {{compute the}} exact optimal {{solution}} for large instances of protein design problems. These solvers use a linear programming relaxation of the problem, where qi and qij {{are allowed to}} take continuous values, in combination with a branch and cut algorithm to search {{only a small portion}} of the conformation space for the optimal solution. ILP solvers have been shown to solve many instances of the side-chain <b>placement</b> <b>problem.</b>|$|E
50|$|Quadratic {{placement}} later outperformed combinatorial {{solutions in}} both quality and stability. GORDIAN formulates the wirelength cost as a quadratic function while still spreads cells apart through recursive partitioning. The algorithm in first models placement density as a linear term into the quadratic cost function, and solves the <b>placement</b> <b>problem</b> by pure quadratic programming. Majority {{of the modern}} quadratic placers (KraftWerk, FastPlace, SimPL) are following this framework, each with different heuristics on how to determine the linear density force.|$|E
5000|$|... where [...] {{represents}} any parameters used {{to describe}} this model, including sequence information, temperature etc. Frequently the backbone {{is assumed to be}} rigid with a known conformation, and the problem is then transformed to a side-chain <b>placement</b> <b>problem.</b> The structure of the graph is also encoded in [...] This structure shows which two variables are conditionally independent. As an example, side chain angles of two residues far apart can be independent given all other angles in the protein. To extract this structure, researchers use a distance threshold, and only pair of residues which are within that threshold are considered connected (i.e. have an edge between them).|$|E
40|$|Node <b>placement</b> <b>problems,</b> {{such as the}} {{deployment}} of radio-frequency identification systems or wireless sensor networks, are important problems encountered in various engineering fields. Although evolutionary algorithms have been successfully applied to node <b>placement</b> <b>problems,</b> their fixed-length encoding scheme limits the scope to adjust the number of deployed nodes optimally. To solve this problem, we develop a flexible genetic algorithm in this paper. With variable-length encoding, subarea-swap crossover, and Gaussian mutation, the flexible genetic algorithm is able to adjust the number of nodes and their corresponding properties automatically. Offspring (candidate layouts) are created legibly through a simple crossover that swaps selected subareas of parental layouts and through a simple mutation that tunes the properties of nodes. The flexible genetic algorithm is generic and suitable for various kinds of node <b>placement</b> <b>problems.</b> Two typical real-world node <b>placement</b> <b>problems,</b> i. e., the wind farm layout optimization and radio-frequency identification network planning problems, are used to investigate {{the performance of the}} proposed algorithm. Experimental results show that the flexible genetic algorithm offers higher performance than existing tools for solving node <b>placement</b> <b>problems...</b>|$|R
40|$|This study {{presents}} a novel optimisation methodology, optimal placement of monitors (OPMPower), for optimal device/monitor placement in distribution networks. OPMPower is developed based on gradient search and particle swarm optimisation. The proposed method integrates network topology into search process via spanning trees {{and uses the}} historical experience for search guidance. The method is particularly suited for optimal <b>placement</b> <b>problems</b> in power systems. The application is illustrated {{on the problem of}} optimal monitor placement for estimation of voltage unbalance in a section of existing UK distribution network and in a generic distribution network. It is demonstrated that the proposed methodology outperforms generic integer optimisation algorithms which are widely used for optimal <b>placement</b> <b>problems</b> in the literature, for example genetic algorithms...|$|R
40|$|International audienceEvery day, {{numerous}} VMs are migrated {{inside a}} datacenter {{to balance the}} load, save energy or prepare production servers for maintenance. Despite VM <b>placement</b> <b>problems</b> are carefully studied, the underlying migration scheduler relies on vague adhoc models. This leads to unnecessarily long and energy-intensive migrations...|$|R
50|$|One {{possible}} {{solution to this}} anchor point <b>placement</b> <b>problem</b> is to remove the histogram binning grid completely. In the left figure below, a kernel (represented by the grey lines) is centred {{at each of the}} 50 data points above. The result of summing these kernels is given on the right figure, which is a kernel density estimate. The most striking difference between kernel density estimates and histograms is that the former are easier to interpret since they do not contain artifices induced by a binning grid.The coloured contours correspond to the smallest region which contains the respective probability mass: red = 25%, orange + red = 50%, yellow + orange + red = 75%, thus indicating that a single central region contains the highest density.|$|E
50|$|When the Uhlan gear was {{incorporated}} in the Mark 14 design, the pressure sensing port for the depth mechanism was moved from its position on the cylindrical body to the cone-shaped tail section; the designers {{did not realize that}} move would affect the pressure readings. This repositioning meant that when the torpedo was moving, a hydrodynamic flow effect created a substantially lower pressure at the port than hydrostatic depth pressure. The torpedo's depth control engine therefore thought the torpedo was too shallow depth and responded by trimming the torpedo to run deeper. A laboratory test (such as immersing a non-moving torpedo in a pool of water) would not be subject to the flow-induced pressure change and would show the torpedo trimmed at the desired depth. Dynamic tests using exercise heads with depth and roll recorders would have shown the depth problem, but the depth measuring port suffered from the same <b>placement</b> <b>problem</b> and gave consistent (though incorrect) measurements. The problem was also exacerbated by higher speeds. The depth problem was finally addressed in the last half of 1943 by relocating the sensor point to the midbody of the torpedo where hydrodynamic effects were minimized.|$|E
5000|$|A {{number of}} exact and {{approximate}} algorithms for the automatic label <b>placement</b> <b>problem</b> {{are based on}} 2-satisfiability. This problem concerns placing textual labels on the features of a diagram or map. Typically, the set of possible locations for each label is highly constrained, {{not only by the}} map itself (each label must be near the feature it labels, and must not obscure other features), but by each other: every two labels should avoid overlapping each other, for otherwise they would become illegible. In general, finding a label placement that obeys these constraints is an NP-hard problem. However, if each feature has only two possible locations for its label (say, extending to the left and {{to the right of the}} feature) then label placement may be solved in polynomial time. For, in this case, one may create a 2-satisfiability instance that has a variable for each label and that has a clause for each pair of labels that could overlap, preventing them from being assigned overlapping positions. If the labels are all congruent rectangles, the corresponding 2-satisfiability instance can be shown to have only linearly many constraints, leading to near-linear time algorithms for finding a labeling. [...] describe a map labeling problem in which each label is a rectangle that may be placed in one of three positions with respect to a line segment that it labels: it may have the segment as one of its sides, or it may be centered on the segment. They represent these three positions using two binary variables in such a way that, again, testing the existence of a valid labeling becomes a 2-satisfiability problem.|$|E
40|$|This article {{presents}} the main {{results of a}} PhD thesis that deals with two families of NP-hard orthogonal <b>placement</b> <b>problems.</b> We develop a common combinatorial framework for compaction problems in graph drawing and for labeling problems in computational cartography. Compaction problems are concerned with performing the conversion from a dimensionless description of the orthogonal shape of a graph to an area-efficient drawing in the grid. Map labeling is the task of attaching labels to point-features so that the resulting placement is legible. On the basis of new combinatorial formulations for these problems we develop exact algorithms. Extensive computational studies on real-world benchmarks show that our linear programming-based algorithms solve large instances of the <b>placement</b> <b>problems</b> to provable optimality within short computation time. Often, our algorithms are the first exact algorithms for the respective problem variant...|$|R
25|$|Surveys for {{the purpose}} of {{providing}} a certificate of building location on a particular parcel of land may be undertaken by a BCLS. These surveys are normally carried out for the protection of an owner, and are generally accepted as proof that there are no encroachment or zoning <b>placement</b> <b>problems.</b>|$|R
40|$|A new {{approximation}} {{algorithm is}} presented for the efficient handling of large macro-cell <b>placement</b> <b>problems.</b> The algorithm combines simulated annealing with new features {{based on a}} hierarchical approach and a divide-and-conquer technique. Numerical results show that these features {{can lead to a}} considerable increase in efficiency of the placement algorithm without loss of effectiveness...|$|R
40|$|As markers {{for visual}} sensor {{networks}} have become larger, {{interest in the}} optimal camera <b>placement</b> <b>problem</b> has continued to increase. The most featured solution for the optimal camera <b>placement</b> <b>problem</b> is based on binary integer programming (BIP). Due to the NP-hard characteristic of the optimal camera <b>placement</b> <b>problem,</b> however, {{it is difficult to}} find a solution for a complex, real-world problem using BIP. Many approximation algorithms have been developed to solve this problem. In this paper, a two-phase algorithm is proposed as an approximation algorithm based on BIP that can solve the optimal camera <b>placement</b> <b>problem</b> for a placement space larger than in current studies. This study solves the problem in three-dimensional space for a real-world structure...|$|E
40|$|SDN is the {{new trend}} in networks, for next Mobile and optical networks. Dimensioning, design and {{optimization}} of Software Defined Optical Networks. To be done at Technical University Munich (TUM) In this work the Controller <b>Placement</b> <b>Problem</b> (CPP) for SDN architecture is studied when it is applied to industrial networks. En este trabajo se estudia el problema CPP (controller <b>placement</b> <b>problem)</b> para la arquitectura SDN, aplicado a redes industriales. En aquest treball s'estudia el problema CPP (controller <b>placement</b> <b>problem)</b> per l'arquitectura SDN, aplicat a xarxes industrials...|$|E
30|$|Theorem 1 : The fake sinks' <b>placement</b> <b>problem</b> is NP-hard.|$|E
40|$|In {{this paper}} {{we present a}} novel force-directed {{placement}} algorithm, {{which is used to}} solve macro-cell <b>placement</b> <b>problems.</b> A new wire model replaces the traditional clique model and makes possible early awareness of routing congestion. Issues such as cell orientation, overlap elimination, and pad positioning are also considered. Experiments show satisfactory performance and fast run time. 1...|$|R
40|$|This paper {{discussed}} on how particle swarmoptimization {{could be}} applied for solving theemployee <b>placement</b> <b>problems</b> in the competencybased human resource management. The employeeplacement problems are the problems tosimultaneously place many people to many jobs inan organization. After the particle swarmmechanism {{to solve the problem}} is defined andexplained, simple case study is presented toillustrate the capability of the proposed metho...|$|R
40|$|In this paper, we mainly {{present a}} fast, stable and {{efficient}} module placement algorithm {{which is based}} on PROUD algorithm and its improved modified version. The PROUD algorithm uses a hierarchical decomposition technique and the solution of sparse linear systems based on a resistive network analogy. It has been shown that the PROUD algorithm can achieve a comparable design of the <b>placement</b> <b>problems</b> for very large circuits with the best placement algorithm based on simulated annealing, but with several order of magnitude faster. The modified PROUD, namely MPROUD algorithm by perturbing the coefficient matrices performs much faster that the original PROUD algorithm. Due to the instability and unguaranteed convergence of MPROUD algorithm, we propose a new convergent and numerically stable PROUD, namely Improved PROUD algorithm, denoted as IPROUD with attractive computational costs to solve the module <b>placement</b> <b>problems</b> by making use of the MINRES method based on Lanczos process. Experime [...] ...|$|R
40|$|Abstract — The {{relay node}} <b>placement</b> <b>problem</b> for {{wireless}} sensor networks is concerned with placing a minimum number of relay nodes into a wireless sensor network to meet certain connectivity and survivability requirements. In this paper, we study constrained versions of the relay node <b>placement</b> <b>problem,</b> where relay nodes can only be placed at a subset of candidate locations. In the connected relay node <b>placement</b> <b>problem,</b> we want to place a minimum number of relay nodes to ensure the connectivity of the sensor nodes and the base stations. In the survivable relay node <b>placement</b> <b>problem,</b> we want to place a minimum number of relay nodes to ensure the biconnectivity of the sensor nodes and the base stations. For {{each of the two}} problems, we discuss its computational complexity, and present a framework of polynomial time O(1) -approximation algorithms with small approximation ratios...|$|E
40|$|Large-scale {{optimization}} of combinatorial {{problems is}} one of the most challenging areas. These problems are characterized by large sets of data (variables and constraints). In this thesis, we study large-scale optimization of the data <b>placement</b> <b>problem</b> with zero storage cost. The goal in the data <b>placement</b> <b>problem</b> is to find the placement of data objects in a set of fixed capacity caches in a network to optimize the latency of access. Data <b>placement</b> <b>problem</b> arises naturally in the design of content distribution networks. We report on an empirical study of the upper bound and the lower bound of this problem for large sized instances. We also study a semi-Lagrangean relaxation of a closely related k-median problem. In this thesis, we study the theory and practice of approximation algorithm for the data <b>placement</b> <b>problem</b> and the k-median problem...|$|E
40|$|This study {{considers}} several computational {{techniques for}} solving one {{formulation of the}} wells <b>placement</b> <b>problem</b> (WPP). Usually the wells <b>placement</b> <b>problem</b> is tackled through the combined efforts of many teams using conventional approaches, which include gathering seismic data, con-ducting real-time surveys, and performing production interpretations in order to define the sweet spots. This work considers one formulation of the wells <b>placement</b> <b>problem</b> in heterogeneous re-servoirs with constraints on inter-well spacing. The performance of three different types of algo-rithms for optimizing the well <b>placement</b> <b>problem</b> is compared. These three techniques are: ge-netic algorithm, simulated annealing, and mixed integer programming (IP). Example case studies show that integer programming is the best approach in terms of reaching the global optimum. However, in many cases, the other approaches can often reach a close to optimal solution with much more computational efficiency...|$|E
40|$|Iterative {{improvement}} techniques {{based on}} module interchange {{are the most}} robust, simple and successful heuristics in solving the partitioning and <b>placement</b> <b>problems.</b> Interchange methods fail to converge to "optimal" or "near optimal" solutions unless they initially begin from "good" initial starting points [1]. In this paper we compare the performance of several constructive based techniques for the circuit partitioning problem...|$|R
30|$|Wireless Mesh Networks (WMNs) are {{applicable}} in deployment of medical, transport and surveillance applications in urban areas, metropolitan, neighboring communities and municipal area networks. At {{the heart of}} WMNs are the issues of achieving network connectivity and stability as well as QoS in terms of user coverage. These issues are very {{closely related to the}} family of node <b>placement</b> <b>problems</b> in WMNs, such as mesh router nodes <b>placement.</b> Node <b>placement</b> <b>problems</b> have been long investigated in the optimization field due to numerous applications in location science (facility location, logistics, services, etc.) and classification (clustering). In such problems, we are given a number of potential facilities to serve costumers that are connected to facilities aiming to find locations such that the cost of serving all customers is minimized. In traditional versions of the problem, facilities could be hospitals, polling centers, fire stations serving to a number of clients and aiming to minimize some distance function in a metric space between clients and such facilities.|$|R
40|$|Recursive bisection is {{a popular}} {{approach}} for large scale circuit <b>placement</b> <b>problems,</b> combining {{a high degree of}} scalability with good results. In this paper, we present a bisection-based approach for both standard cell and mixed block placement; in contrast to prior work, our horizontal cut lines are not restricted to row boundaries. This technique, which we refer to as a fractional cut, simplifies mixed block placement and also avoids a narrow region problem encountered in standard cell placement. Our implementation of these techniques in the placement tool Feng Shui 2. 6 retains the speed and simplicity for which bisection is known, while making it competitive with leading methods on standard cell designs. On mixed block <b>placement</b> <b>problems,</b> we obtain substantial improvements over recently published work. Half perimeter wire lengths are reduced by 29 % on average, compared to a flow based on Capo and Parquet; compared to mPG-ms, wire lengths are reduced by 26 % on average...|$|R
40|$|The {{relay node}} <b>placement</b> <b>problem</b> for {{wireless}} sensor networks is concerned with placing a minimum number of relay nodes into a wireless sensor network to meet certain connectivity and survivability requirements. In this paper, we study constrained versions of the relay node <b>placement</b> <b>problem,</b> where relay nodes can only be placed at a subset of candidate locations. In the connected relay node <b>placement</b> <b>problem,</b> we want to place a minimum number of relay nodes to ensure the connectivity of the sensor nodes and the base stations. In the survivable relay node <b>placement</b> <b>problem,</b> we want to place a minimum number of relay nodes to ensure the biconnectivity of the sensor nodes and the base stations. For {{each of the two}} problems, we discuss its computational complexity, and present a framework of polynomial time O(1) -approximation algorithms with small approximation ratios...|$|E
30|$|An {{application}} of the utility-based approach to the VM <b>placement</b> <b>problem.</b>|$|E
30|$|Controller placement: The {{controller}} placement heavily {{affects the}} network performance. Controller <b>placement</b> <b>problem</b> [63] aims at finding the optimal number of SDN controllers {{as well as}} their location in order to minimize the overhead latency and enhance the network reliability. As stated before, SDMN architecture will introduce additional constraints and requirements in the controller <b>placement</b> <b>problem.</b>|$|E
40|$|We study two {{families}} of NP-hard orthogonal <b>placement</b> <b>problems</b> {{that arise in}} the area of information visualization both from a theoretical and a practical point of view. This thesis contains a common combinatorial framework for compaction problems in orthogonal graph drawing and for point-feature labeling problems in computational cartography. Compaction problems are concerned with performing the conversion from a dimensionless description of the orthogonal shape of a graph to an area-efficient drawing in the orthogonal grid with short edges. The second family of problems deals with the task of attaching rectangular labels to point-features such as cities or mountain peaks on a map so that the placement results in a legible map. We present new combinatorial formulations for these problems employing a path- and cycle-based graph-theoretic property in an associated problem-specific pair of constraint graphs. The reformulation allows us to develop exact algorithms for the original problems. Extensive computational studies on real-world benchmarks show that our linear programming–based algorithms are able to solve large instances of the <b>placement</b> <b>problems</b> to provable optimality within short computation time. Furthermore...|$|R
40|$|Abstract—This letter {{presents}} a simple optimal placement algorithm of phasor measurement units (PMU) by using integer linear programming. Cases {{with and without}} conventional power flow and injection measurements are considered. The measurement <b>placement</b> <b>problems</b> under those cases are formulated as an integer linear programming which saves the CPU computation time greatly. Simulation {{results show that the}} proposed algorithm can be used in practice. Index Terms—phasor measurement units, integer linear programming, observability analysis...|$|R
40|$|Pole <b>placement</b> <b>problems</b> are {{especially}} important for disturbance rejection and stabilization of dynamical systems and regarded as algebraic inverse eigenvalue problems. In this paper, we propose gain formulae of state feedback through PID-elements to achieve desired pole placement for a delay-free LTI system with single input. Real and complex stable poles can be assigned with the proposed compact gain formulae. Numerical examples show that our proposed gain formulae can be used effectively resulting in very satisfactory responses...|$|R
