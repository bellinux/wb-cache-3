9|39|Public
50|$|Words, Signs & Vibes (W,S&V) {{works with}} deaf, <b>partially</b> <b>hearing</b> and hearing young people, both Quaker and non-Quaker. They run a weekly drama group for young people, and also hold 1 or 2 week-long {{projects}} each year, usually during school holidays.|$|E
50|$|Mary Jane Owen {{was named}} Catholic Woman of the Year in 2002 by the Catholic Daughters of the Americas and has {{received}} numerous other awards. She {{has appeared on}} radio talk shows and local television and has written thousands of published articles. She {{is a leader in}} the national disability community and draws from a background as a professor, federal administrator, consultant, writer, businesswoman, and social worker. She is <b>partially</b> <b>hearing,</b> uses a wheelchair and recently regained her sight after 30 years of blindness.|$|E
50|$|P. was {{a member}} of several {{scientific}} societies and served on a number of commissions, committees and councils of the Government and other institutions such as the South African Broadcasting Corporation (SABC), the Department of Education, the Film Council, the Department of Health, the South African Academy of Arts and Science, the Transoranje Institute for Special Education, the South African Council for the Deaf, and others. Noteworthy, he served on the Language Advisory Committee of the SABC (1957-1968); the Advisory Committee for Language Laboratories of the Government Department of Education, Arts and Science; the Film Board of the Republic of South Africa since its inception; the Board of the Transoranje Institute for Special Education as representative of the Department of National Education; the Editorial Board of Folia Phoniatrica, the journal published by the International Logopedic and Phoniatric Society; the Commission appointed by the Department of Health to investigate the use and abuse of hearing aids in South Africa; clinical and technical committees of the South African Council for the Deaf, the Transoranje School for <b>Partially</b> <b>Hearing</b> Children, the National Committee for Noise Control in South Africa, and the South African Speech and Hearing Association. He advised several national and international universities on the training of therapists in the field of communication pathology. Others asked his advice on setting up language laboratories.|$|E
50|$|From {{the early}} 1980s, Van Wagoner lost his hearing due to otosclerosis; he {{received}} a cochlear implant in 2001, which <b>partially</b> restored his <b>hearing.</b>|$|R
40|$|C can <b>partially</b> <b>hear</b> {{the voices}} of G 4 over the partition, and also {{perceives}} that Agents in Group G 4 are quarreling {{by looking at the}} shapes of the chat word balloon. (c) C is looking at Group G 3. We know that agents in Group G 3 are happily laughing, since pink balloons above them represent laughter in AVACHAT. (d) C is looking at GroupG 2. One agent in GroupG 2 is talking loudly. So we can hear (see) the voice (text in balloon) though we can not hear (see) clearly the voice of other avatars. C only perceives they are talking about a subject. We propose AVACHAT, a new comic-stylized communication in-terface for avatar agents. We show that the 3 -D word balloon could be successfully exploited to depict chat dialogues and the atmo-sphere of groups talking, such as cheerful laughing or loud quar-relling without adding any multimedia functions. Finally, we pro-pose a new data structure to manage the chat dialogues among vir-tual avatars. It can be used to reconstruct the social-graph for chat agents in a virtual world...|$|R
5000|$|On Sinfield's {{first day}} in office, Judge Dredd lodged a formal {{complaint}} against him with the Council of Five, accusing Sinfield of gross negligence in failing to provide him with sufficient resources, almost leading {{to the death of}} one of the judges under Dredd's command, Judge Munn. However, Dredd's hopes of receiving even a <b>partially</b> sympathetic <b>hearing</b> before the Council were soon dashed when Sinfield simply replaced the more moderate Council members with hardliners like himself.|$|R
40|$|The {{relationship}} between verbal behavior and stimulus equivalence was examined using {{three sets of}} children differing in chronological age and verbal ability: (1) non-hearing impaired three and four year olds who had verbal skills generally consistent with their chronological ages; (2) <b>partially</b> <b>hearing</b> (severe to profoundly deaf) children who were rated with verbal ages of above 2 years; and (3) <b>partially</b> <b>hearing</b> children (also severely to profoundly deaf) who were rated with verbal ages of below 2 years. All children were taught a series of four conditional discriminations using unfamiliar stimuli. The children were then tested to determine whether classes of equivalent stimuli had formed. Although all the children were able to learn the conditional discriminations equally well and all the verbally-able children (normal and <b>partially</b> <b>hearing)</b> formed equivalence classes, {{only one of the}} verbally-impaired children reliably demonstrated stimulus equivalence formation. These results are consistent with the suggestion that stimulus equivalence and human verbal behavior are closely related...|$|E
40|$|This is a {{preliminary}} report of a study of some linguistic and interactive aspects available in a adult-child dyad where the child is <b>partially</b> <b>hearing</b> impaired, during the ages 8 - 20 months. The investigation involves a male child, born with Hemifacial Microsomia. Audio and video recordings are used {{to collect data on}} child vocalization and parent-child interaction. Eye-tracking is used to measure eye movements when presented with audio-visual stimuli. SECDI forms are applied to observe the development of the child’s lexical production. Preliminary analyses indicate increased overall parental interactive behaviour. As babbling is somewhat delayed due to physical limitations, signed supported Swedish is used to facilitate communication and language development. Further collection and analysis of data is in progress in search of valuable information of the linguistic development from a pathological perspective of language acquisition...|$|E
40|$|The study {{examined}} the differences in defense, protective reactions, and expression of primary emotions between deaf or <b>partially</b> <b>hearing</b> impaired adolescents and their peers with normal hearing. Participants {{in the two groups}} were assessed by means of The Profile Emotions, The Life Style Index, and Non-verbal Scale of Suffering. Deaf adolescents tended more towards uncontrolled and oppositional behaviour, and had a weaker sense of self-protection and deprivation. Moreover, their defense mechanisms (intellectualization, projection and negation) were more intensively expressed. A higher level of defense mechanisms of intellectualization was observed in hearing adolescents. On the basis of the obtained results and analyses we may conclude that deaf adolescents demonstrated some characteristics of lower level of adjustment: negative emotional responses, lower degree of control (more uncontrolled and oppositional behaviour, weakened sense of self-protection) and several simple, evolutionary more primitive defense mechanisms (excluding intellectualization). Our interpretation also takes into account that adolescents need to develop a new adjustment system as the old one ceased to function...|$|E
40|$|Aim of {{this report}} is to explain the current concept of hearing {{restoration}} using hearing aids. At present the main issues of conventional hearing aids are the relative benefits of analogue versus digital devices and different strategies {{for the improvement of}} hearing in noise. Implantable hearing aids provide a better sound quality and less distortion. The lack of directional microphones is the major disadvantage of the <b>partially</b> implantable <b>hearing</b> aids commercially available. Two different clinical studies about fully implantable hearing aids have been started in 2004. One of the most-promising developments seems to be the electric-acoustic stimulation...|$|R
50|$|Wireless home safety {{solutions}} are available that link carbon monoxide detectors to vibrating pillow pads, strobes or a remote warning handset. This allows those with impediments such as hard of <b>hearing,</b> <b>partially</b> sighted, heavy sleepers or the infirm the precious minutes {{to wake up}} and get out in the event of carbon monoxide in their property.|$|R
40|$|Cochlear {{implants}} (CIs) <b>partially</b> restore <b>hearing</b> sensation to {{profoundly deaf}} people by electrically stimulating the surviving auditory neurons. However, CI users perform poorly in challenging listening {{tasks such as}} speech recognition in noise and Cochlear implants (CIs) <b>partially</b> restore <b>hearing</b> sensation to profoundly deaf people by electrically stimulating the surviving auditory neurons. However, CI users perform poorly in challenging listening tasks such as speech recognition in noise and music perception, possibly due to {{the small number of}} implanted electrodes and the large current spread of electric stimulation. Although current spread may be reduced using partial tripolar (pTP) stimulation mode, the number of electrodes may not be sufficient to preserve fine spectral details. Here, we propose to introduce current steering and electrode spanning to pTP mode to create additional spectral channels for CI users. Loudness and pitch perception with steered and spanned pTP modes were simulated using a computational model of CI stimulation and were tested in CI users. The excitation pattern of each stimulation mode was also measured at the physical (i. e., intra-cochlear electrical potential distribution), neural (i. e., spatial profile of evoked compound action potential), and perceptual levels (i. e., psychophysical forward masking pattern). Consistent with the model predictions, pitch-ranking results verified the feasibility and efficacy of the proposed stimulation modes in eliciting distinctive pitches for CI users. Pitch increased when the centroid of excitation pattern was shifted basally. When the centroid of excitation pattern did not move, higher pitches were perceived for narrower excitation patterns. These results suggest that in pTP-mode CI processing strategies, current steering and electrode spanning may provide additional spectral channels for better coding of spectral fine structures and for handling the cochlear dead region and defective electrode contact. ...|$|R
40|$|This paper {{discusses}} {{issues related}} to the training and provision of interpreters for deaf students 'at institutions of higher education in the United Kingdom. Background information provided notes the increasing numbers of deaf and <b>partially</b> <b>hearing</b> students, the existence of funding to pay for interpreters, and trends in the availability of interpreters. Financial support through the Disabled Students Allowance is discussed as are concerns about this allowance including eligibility, means-testing, special problems of students with multiple disabilities, and payment methods. Establishment by some universities of special support services for deaf students is noted. A survey of 46 deaf students at the University of Bristol (England) is summarized for type of secondary school attended, communication mode preferred, communication mode in their previous school, and support needs. The survey found that none of the students had used interpreters in elementary/secondary education settings. A final section reviews trends in training and qualifyint interpreters for the deaf. Other issues considered include social implications of interpreter use, the university experience, and alternatives to interpreting in the higher education setting. (DB) * Reproductions supplied by EDRS are the best that can be made * * from the original document. * Higher education interpretin...|$|E
40|$|The work {{presented}} in this thesis forms part of a research project which attempts to generate a visualisation of a speaker's mouth from purely acoustic speech signals. The aim is to provide an aid for <b>partially</b> <b>hearing</b> impaired people in which visual information is presented alongside limited acoustic signals, facilitating easier use of the telephone. The system is essentially a low-level speech recogniser in which phonemic information is extracted from the speech waveform and mapped onto visemes generated on a synthetic facial image. This thesis presents {{a description of a}} major part of this project, that is, the development of an accurate phoneme discriminator which is capable of speaker independent operation, on continuous speech. The recognition process is realised in three stages: a pre-processor to convert the speech into a suitable parametric form; a pattern recogniser to identify the possible phoneme classes and a post-processor to produce the viseme information. The pattern recognition stage uses a self-organising Kohonen network, followed by a Learning Vector Quantiser (LVQ) to further improve the recognition accuracy. The performance of this stage is highly dependent on the choice of pre-processor used at the input to the network and it is the design of the pre-processor stage that forms a significant part of this work. A novel technique known as the pseudo-cepstrum forms the basis of this pre-processor. Extensive investigations have been conducted into the dependence of performance on a range of parameters, both at the pre-processor stage and within the Kohonen classifier. In particular, a performance comparison of several preprocessor techniques, including the pseudo-cepstrum, has been carried out. Factors affecting both the training and operation of the classifier are also described here, with the sensitivity of recognition performance to the input data, being a major issue. Overall recognition accuracies of 80 % have been achieved...|$|E
40|$|This thesis {{sets out}} to {{investigate}} aspects {{of the development of}} phonological awareness in relation to word reading in children aged between 5 - and 7 -years. The principal aim has been to establish how, for these children, phonological awareness relates to other cognitive factors that might jointly support the development of early reading skills. Data derives from children in their first three years of formal education (aged 5 - to 7 -years) and a group of partially-hearing children aged 7 -years. The children's performance in a measure of categorical speech have been compared with their levels of implicit phonological awareness. The results do not indicate that phonological awareness is significantly associated with children's ability to categorise speech sounds. Following this investigations have been conducted {{to determine the extent to}} which implicit phonological awareness is affected by working memory and lexical knowledge. It emerges that memory is implicated in the phonological awareness tasks, but is not a developmental antecedent. The phonological similarity effect is also studied and not found to relate to age or reading ability in hearing or partially-hearing children. Aspects of the working memory model are discussed in relation to children's performance in tests of word recognition and phonological awareness. In the penultimate chapter children's lexical knowledge (vocabulary) is found to interact with their performance in the measure of memory span. It appears that the development of the awareness of initial phonemes may be facilitated by having limited memory processing space. Overall it was found that lexical knowledge was predictive of phonological awareness. This conclusion was supported by a finding that the partially-hearing children had poorer lexical knowledge than younger hearing children with levels of phonological awareness similar to the partially-hearing children. The findings in that chapter also indicate that phonological awareness and lexical knowledge may make separable contributions to word reading. In the final chapter structural equation modelling of 'Reading' is undertaken in order to establish how phonological awareness, memory span and lexical knowledge together relate to word reading. The findings there confirm the covariance of phonological awareness, memory span and lexical knowledge, but also suggest that, in contrast to other research findings, these factors may not always be clearly related to word reading. The study has also elicited some information about the likely difficulties of <b>partially</b> <b>hearing</b> children who were here not found to have good levels of phonological awareness or lexical knowledge. In the final chapter it is suggested that further work should be undertaken to study partially-hearing children to establish how reading develops in the absence of age-appropriate levels of phonological awareness and lexical knowledge...|$|E
40|$|Occupational {{hearing loss}} {{is one of}} the most common {{occupational}} illnesses in the United States. When control technologies have not eliminated hazardous noise exposures or are not feasible, using personal hearing protection devices (HPDs) becomes the only true means of protecting a worker. Currently, there is no requirement that HPDs be fit-tested in the workplace, <b>partially</b> because <b>hearing</b> protector fit-testing technology has historically been impractical for use in the field. To address this issue, the National Institute for Occupational Safety and Health (NIOSH) developed a hearing protector fit-testing system called HPD WellFit(TM). The portable PC-based system is fast, accurate, and can be used as a stand-alone instrument in any workplace setting or as part of an annual audiometric monitoring or hearing conservation program. NIOSH is actively field testing HPD Well Fit(TM) with the US Army, the US Department of Interior (Bureau of Reclamation), and several universities. Prevention and ControlOccupational Healt...|$|R
40|$|Cochlear Implants (CIs) {{have long}} been used to <b>partially</b> restore <b>hearing</b> in profoundly deaf {{individuals}} through direct electrical stimulation of the auditory nerve. Changes in pitch due to electrode selection {{have been shown to}} conform to the tonotopic organisation of the cochlea; i. e., each electrode corresponds to a localised band of the human hearing spectrum. Studies have shown that {{it may be possible to}} produce intermediate place percepts in some patients by stimulating pairs of adjacent electrodes simultaneously. Tone vocoder simulations with 2 - 16 output channels were used to evaluate the effect of producing place cues similar to spectral subband centroids of each spectral analysis band. Signals were generated as a sum of sine waves positioned at the spectral subband centroid (rather than the usual centre frequency) of the frequency band relevant to each channel. Results showed improved vowel and consonant intelligibility, even with as low as 4 - 6 output channels. Griffith Sciences, Griffith School of EngineeringNo Full Tex...|$|R
50|$|A cyclist, Mike, with {{a camera}} affixed on his helmet, is riding through a state park, when he runs into a hysterical and bloody woman, asking for help with her boyfriend. Mike then sees several zombies {{approaching}} them, before he is suddenly attacked and bitten on the throat by the woman, whom he kills. Mike staggers through the park, heavily bleeding, before finally collapsing and apparently dying. A pair of bikers come across him and attempt to help, but he reanimates, attacks, and <b>partially</b> devours them. <b>Hearing</b> noise in the distance, the three zombies head off towards it.|$|R
5000|$|Prompted by a {{documentary}} he watched at Uncle Pat's farm, Tony {{returns to the}} Bada Bing and initiates a discussion of terrorist threats tied to unexamined cargo containers at the ports. When Georgie Santorelli remarks that [...] "you have to live for today," [...] Tony suddenly explodes in fury and gives him a beating that sends {{him to the hospital}} and makes him <b>partially</b> lose his <b>hearing.</b> Afterwards, Tony is remorseful, and gives Paulie a wad of bills and insists that he make sure Georgie receives the best care. Paulie then informs Tony that Georgie is quitting his job at the Bada Bing and doesn't want to see him again.|$|R
5000|$|Herman Carl Andersen {{was born}} in Newcastle, Washington. He {{was the son of}} Charles Carl Andersen (1858-1940?) and Lorena Nielson (1868-1946). Charles C. Andersen had emigrated from Denmark to the United States in the late 1870s. The family moved to a farm near Tyler, Minnesota in 1901. Andersen's father {{returned}} to mining and became superintendent of a large coal mine owned by Northern Pacific Railway at Red Lodge, Montana, where Andersen {{graduated from high school in}} 1913. He attended the University of Washington and later the U.S. Naval Academy. While aboard the battleship [...] in 1917, a gun blast <b>partially</b> impaired his <b>hearing</b> and he was unable to qualify for further service.|$|R
40|$|A {{concept for}} a <b>partially</b> implantable <b>hearing</b> device, {{for which the}} power supply and signal {{transmission}} are provided by an optical transmission path, is evaluated. The actuator is designed {{to fit into the}} round-window niche and to couple directly to the round-window membrane. Implantable hearing aids can be a suitable solution in the case of severe hearing loss, where conventional hearing aids often fail. However, the surgical effort for an implantation is comparatively high. Therefore, the objective of our work was to provide a hearing system which combines reliable coupling to the auditory system with an easy implantation technique. The actuator was designed as a piezoelectric thin-film cantilever. The optical transmission path was realised using an infrared light-emitting diode combined with an active receiver circuit. For a voltage of 1 V, the unloaded actuator presents displacement amplitudes of 1 µm up to a stimulus frequency of 25 kHz and forces up to 0. 2 mN. Proportionally larger forces can be achieved by stacking single actuators. The overall transmission loss from the electrical input of the light-emitting diode driver to the mechanical output of the unloaded actuator was less than 25 dB at 1 kHz and maximum output...|$|R
40|$|AbstractOsseous atresia {{and chronic}} otitis media are {{diseases}} benefit with middle ear implants. Surgery for atresia is technically complicated, has {{significant number of}} complications and functional results are often poor. The osseointegrated hearing aids are an alternative. They provide a very good functional gain, but have many problems with the skin and osseointegration. In chronic otitis media, the ossiculoplasty solved <b>partially</b> the <b>hearing</b> problem. Unfortunately in some cases of otitis media and in open cavities fitted with conventional hearing aids the gain is unsatisfactory. AimTo determine the usefulness of an active middle ear implant. Material and methodLongitudinal Study. Vibrant-Soundbrigde was implanted in 8 patients with severe mixed hearing loss. 4 patients had chronic otitis media and 4 had unilateral atresia. The placement of the stimulator (FMT or Floating Mass Transducer) was in 5 patients on round window, 2 in stapes {{and one in the}} oval window. ResultsFunctional gain was 35 dB, 40 dB, 48. 7 dB and 50 dB for the frequencies 500, 1000, 2000 and 4000 Hz, respectively. ConclusionVibrant-Soundbrigde is an excellent option in hearing recovery in severe and profound mixed hearing loss. It also provides an excellent functional gain in diseases difficult to treat with conventional hearing aids...|$|R
40|$|The aim of {{this work}} is to explore parts of the human {{auditory}} pathway {{that are involved in}} encoding of acoustic stimuli to the neural activity in cochlear nerve. This knowledge is exploited in cochlear implant design. Cochlear implant bypasses the middle ear, and substitutes the inner ear by converting the mechanical energy (sound) to electric stimuli that evoke the sequence of impulses (action potentials) in cochlear nerve. Cochlear implants are used to <b>partially</b> restore <b>hearing</b> for patients with hearing loss caused by the damage of the inner ear. Today, we do not know exactly how the sound is encoded in cochlear nerve neural activity. However, there are methods used to stimulate the cochlear nerve, which are used in cochlear implants. Another {{aim of this}} work is to explore sound encoding methods used in present cochlear implants, and implementation of cochlear implant software simulation that uses one of these coding strategies. Simulation is implemented in Matlab environment that supports digital signal processing, which is the fundamental part of the cochlear implant. The result of this work is application that can encode and decode sound, configure and adjust cochlear implant parameters, and visualize basic acoustic parameters of the input and output sound. Results of the simulation for different [...] ...|$|R
40|$|SummaryAuditory Brainstem Implants were {{developed}} to <b>partially</b> restore the <b>hearing</b> capabilities of patients without cochlear nerves bilaterally. Aimthis paper aims to discuss the clinical and surgical findings of four ABI patients. Materials and methodfour patients diagnosed with bilateral schwannomas received auditory brainstem implants (ABI) and had one of their tumors resected in the same surgical procedure. Clinical aspects, surgical technique, anatomic landmarks, and outcomes were analyzed. Resultsthe anatomic landmarks were identified in all four patients {{in relation to the}} foramina of Luschka. Two patients had CSF leaks. The electrodes were well positioned and hearing sensation was good enough to allow for sound recognition and assist patients perform lip reading. Conclusionthe outcomes observed in our patients were quite encouraging and offer great perspectives for those suffering from deep bilateral deafness and impaired central auditory pathways...|$|R
40|$|Since {{more and}} more {{children}} with special needs are included in preschool programs, educators are more often in contact with deaf and partially deaf children. They have to provide optimal conditions for their development. The graduate thesis titled Sociopragmatic skills of <b>hearing,</b> deaf and <b>partially</b> deaf preschool children included in the kindergarten is focused on possible differences in sociopragmatic skills of the hearing and the deaf and partially deaf children. It consists of a theoretical and an empirical part. In the theoretical part, concepts as communication, pragmatics, sociopragmatic skills are presented and the phenomenon of hearing loss is described. Some ways of adjustment for deaf and partially deaf children in the kindergarten are stated. In the empirical part, a survey on sociopragmatic skills in deaf, <b>partially</b> deaf and <b>hearing</b> preschool children included in the kindergarten is presented. The survey was conducted through a questionnaire including the scale of sociopragmatic skills filled out by parents and educators of deaf, <b>partially</b> deaf and <b>hearing</b> children. The sociopragmatic skills in the scale are divided into two subgroups: the skill of assertiveness and the skill of responsiveness. I found that there were differences in sociopragmatic skills between hearing and deaf or partially deaf children. The hearing children had higher scores of their sociopragmatic skills than their deaf or partially deaf counterparts. However, only the differences {{in the development of the}} responsiveness skill were statistically important. In the hearing children, both the assertivness skill and responsiveness skill are present, whereas the responsiveness is well developed, and assertiveness is poorly developed or nascent. In most deaf and partially deaf children, the responsiveness is nascent or well developed, and assertiveness is nascent. Since parents see children in a different environment as educators, there were higher scores in scales filled out by parents than by educators, both for the responsiveness skill as for the assertiveness skill, however, they are statistically unimportant. ...|$|R
30|$|Silver {{nanoparticles}} (AgNPs) {{were shown}} to temporarily impair the biological barriers in {{the skin of the}} external ear canal, mucosa of the middle ear, and inner ear, causing <b>partially</b> reversible <b>hearing</b> loss after delivery into the middle ear. The current study aimed to elucidate the molecular mechanism, emphasizing the TLR signaling pathways in association with the potential recruitment of macrophages in the cochlea and the modulation of inflammation by ubiquitin-editing protein A 20. Molecules potentially involved in these signaling pathways were thoroughly analysed using immunohistochemistry in the rat cochlea exposed to AgNPs at various concentrations through intratympanic injection. The results showed that 0.4  % AgNPs but not 0.02  % AgNPs upregulated the expressions of CD 68, TLR 4, MCP 1, A 20, and RNF 11 in the strial basal cells, spiral ligament fibrocytes, and non-sensory supporting cells of Corti’s organ. 0.4  % AgNPs had no effect on CD 44, TLR 2, MCP 2, Rac 1, myosin light chain, VCAM 1, Erk 1 / 2, JNK, p 38, IL- 1 β, TNF-α, TNFR 1, TNFR 2, IL- 10, or TGF-β. This study suggested that AgNPs might confer macrophage-like functions on the strial basal cells and spiral ligament fibrocytes and enhance the immune activities of non-sensory supporting cells of Corti’s organ through the upregulation of CD 68, which might be involved in TLR 4 activation. A 20 and RNF 11 played roles in maintaining cochlear homeostasis via negative regulation of the expressions of inflammatory cytokines.|$|R
60|$|Old Martha did {{not hear}} John Potter's remark, but she saw his kindly smile, and nodded her head with much gravity in reply. Martha had grown intellectually slow when she <b>partially</b> lost her <b>hearing,</b> and {{although}} she was not sad she had evidently become solemn. An English Dictionary and the Bible were the only books that Martha would look at now. She {{did not use the}} former as a help {{to the understanding of the}} latter. No one knew why she was so partial to the dictionary; but as she not unfrequently had it on her knee upside down while poring over it, her grandchild, little Nora, took up the idea that she had resolved to devote the latter days of her life to learning to read backwards! Perhaps the fact that the dictionary had once belonged to her son James who was wrecked and drowned on the Norfolk coast, may have had something to do with it.|$|R
50|$|Second Brother (Orange) (二娃): Has {{enhanced}} {{hearing and}} sight. He {{is the most}} intelligent out of all his brothers, often coming up with effective strategies against enemy forces. Due to him not having a physical ability, he is easily caught compare {{to the rest of}} his siblings. He fell victim to the spirits' enchanted mirror, and was blinded for part of the series. He also <b>partially</b> lost his <b>hearing,</b> but was able to recover it along with his sight. He was able to use his recovered abilities and quick thinking to work with his Sixth Brother in a plan to free all their brothers that were trapped in the fortress. In the second series, the third demon uses a special fan to blind him with hurricane winds and capture him with a net. Right after the moment of him coming out of his rock, he seems to be the only one to be supposedly still asleep.|$|R
40|$|Ototoxic {{drugs can}} be used to produce a loss of {{cochlear}} hair cells to create animal models of deafness. However, {{to the best of our}} knowledge, there is no report on the establishment of a rat deafness model through the combined application of aminoglycosides and loop diuretics. The aim of this study was to use single or combined administration of furosemide and kanamycin sulfate to establish rat models of deafness. The rats received intravenous injections of different doses of furosemide and/or intramuscular injections of kanamycin sulfate. The auditory brainstem response was measured to determine the hearing threshold after drug application. Immunocytochemistry and confocal microscopy were performed to evaluate inner ear morphology. In the group receiving combined administration of furosemide and kanamycin, the auditory brainstem response threshold showed significant elevation 3 days after administration, higher than that produced by furosemide or kanamycin alone. The hair cells showed varying degrees of injury, from the apical turn to the basal turn of the cochlea and from the outer hair cells to the inner hair cells. The spiral ganglion cells maintained a normal morphology during the first week after the hair cells completely disappeared, and then gradually degenerated. After 2 months, the majority of spiral ganglion cells disappeared, but a few remained. These findings demonstrate that the combined administration of furosemide and kanamycin has a synergistic ototoxic effect, and that these drugs can produce hair cell loss and hearing loss in rats. These findings suggest that even in patients with severe deafness, electronic cochlear implants may <b>partially</b> restore <b>hearing...</b>|$|R
40|$|Approximately 30 % of {{patients}} with sudden hearing loss show complete recovery. Researchers have long questioned whether extensive evaluation is necessary in these cases. Recently, however, with the increasing widespread application of magnetic reso-nance imaging, {{a higher rate than}} expected of acoustic neuromas has been detected in patients with sudden hearing loss. Two studies have suggested that affected patients may even <b>partially</b> regain <b>hearing.</b> The aim of the present clinical study was to determine whether acoustic neuroma-induced hearing loss may be associated with full recovery. The files of 67 patients evaluated for sudden hearing loss at Rabin Medical Center from 1989 to 2000 were reviewed. All patients underwent pure tone audiometry, acoustic reflex tests, and auditory brain stem evoked response tests. Hearing evaluation was followed by magnetic resonance imaging scan and, I month later, a second hearing test. Findings were compared between patients with and without evidence of tumor on imaging, and between patients with tumor with and without full recovery. Twenty-four patients (36 %) had a diagnosis of acoustic tumor, of whom 4 (16. 7 %) recovered hearing after I month. All 4 tumors were intracanalicular, Two of these patients had low-tone hearing loss, and 2 had flat curves; 3 had a pathological auditory brain stem evoked response. Of the 43 patients without tumors, 26 (60 %) showed complete resolution of the hearing loss. We conclude that complete recovery of hearing loss does not exclude acoustic tumor, and these patients therefore require full evaluation. The reason for the recovery remains unclear. KEY WORDS- acoustic neuroma, magnetic resonance imaging, sudden hearing loss...|$|R
40|$|Silver {{nanoparticles}} (AgNPs) {{were shown}} to temporarily impair the biological barriers in {{the skin of the}} external ear canal, mucosa of the middle ear, and inner ear, causing <b>partially</b> reversible <b>hearing</b> loss after delivery into the middle ear. The current study aimed to elucidate the molecular mechanism, emphasizing the TLR signaling pathways in association with the potential recruitment of macrophages in the cochlea and the modulation of inflammation by ubiquitin-editing protein A 20. Molecules potentially involved in these signaling pathways were thoroughly analysed using immunohistochemistry in the rat cochlea exposed to AgNPs at various concentrations through intratympanic injection. The results showed that 0. 4 % AgNPs but not 0. 02 % AgNPs upregulated the expressions of CD 68, TLR 4, MCP 1, A 20, and RNF 11 in the strial basal cells, spiral ligament fibrocytes, and non-sensory supporting cells of Corti’s organ. 0. 4 % AgNPs had no effect on CD 44, TLR 2, MCP 2, Rac 1, myosin light chain, VCAM 1, Erk 1 / 2, JNK, p 38, IL- 1 β, TNF-α, TNFR 1, TNFR 2, IL- 10, or TGF-β. This study suggested that AgNPs might confer macrophage-like functions on the strial basal cells and spiral ligament fibrocytes and enhance the immune activities of non-sensory supporting cells of Corti’s organ through the upregulation of CD 68, which might be involved in TLR 4 activation. A 20 and RNF 11 played roles in maintaining cochlear homeostasis via negative regulation of the expressions of inflammatory cytokines. Springer Ope...|$|R
40|$|A {{cochlear}} implant is a prosthetic device {{that can provide}} severe-to-profoundly deaf individuals with <b>partially</b> restored <b>hearing.</b> It emulates the function of a normal cochlea through combined functioning of externally situated electronics and an electrode array surgically implanted into the cochlea. Speech coding strategies implemented in speech processors aim to stimulate the auditory nerve in a way {{similar to that of}} a normal working cochlea by modelling the way the cochlea processes sound. Current speech processing strategies rely on the tonotopicity of the cochlea, i. e. the relation between distance {{from the base of the}} cochlea and the specific frequency that causes the highest amplitude of deflection at the specific point. The phenomenon of the travelling wave on the basilar membrane is thus reduced to its point or points of maximal deflection. In this study, the behaviour along the full length of the basilar membrane will be investigated in the time domain, i. e. the deflection along the whole membrane for any point in time, in order to evaluate the relevance of the travelling wave in coding sound in a {{cochlear implant}} system. The additional information acquired by emulating the motion of the fluid and the basilar membrane in the cochlea, will be transmitted to the recipient in electrical stimulus patterns, to assess whether it provides recipients of cochlear implants with better pitch perception. It will be shown that for the individuals that partook in the experiments, improvement of discrimination around 100 Hz were obtained when compared to current speech coding strategies like the advanced combination encoder (ACE) speech coding strategy in the same recipient. Dissertation (MEng (Bio-Engineering)) [...] University of Pretoria, 2007. Electrical, Electronic and Computer Engineeringunrestricte...|$|R
40|$|Deaf is {{the loss}} of <b>hearing</b> <b>partially</b> or even totally and could happen congenitally or acquired. The purpose of this {{research}} was to find out the information on the caries prevalence, def-t and DMF-T index of Deaf children at the Primary School of Special Education in Kota Kinabalu, Sabah year 2008. This study was a descriptive research with survey technique. All samples, 43 primary students of Primary School of Special Education in Kota Kinabalu, Sabah from kindergarten to primary six. The def-t and DMF-T index standard used the WHO criteria, namely, very low (0. 1 - 1), low (1. 2 - 2. 6), moderate (2. 7 - 4. 4), high (4. 5 - 6. 5), and very high (> 6. 5). The results of this research indicate that the caries prevalence of the Deaf children year 2008 was 95. 3 %. the def-t index was 2. 81 and DMF-T index was 1. 67. The conclusion of this research was that the average def-t index included in moderate criteria and the DMF-T index was low...|$|R
5000|$|On 5 February 2014, it was {{publicly}} {{revealed that}} music attributed to Samuragochi since 1996 {{had actually been}} ghostwritten by Takashi Niigaki, a musician, composer, and part-time lecturer at the Toho Gakuen School of Music in Tokyo. Niigaki also said Samuragochi was not deaf and states that Samuragochi has normal hearing and was posing as a deaf man to generate a mystique around his image as a composer. Niigaki also said that Samuragochi {{did not need to}} use his cane, and that most of his biography printed in album liner notes was fiction. Niigaki went to the press because one of Samuragochi's [...] "compositions" [...] would be used by Japanese figure skater Daisuke Takahashi, at the 2014 Winter Olympics in Sochi. On 12 February 2014, Samuragochi released a handwritten statement in which he revealed that he had a Grade 2 physical disability certificate after losing his hearing and to have <b>partially</b> regained his <b>hearing</b> three years previously. He also added that he was [...] "deeply ashamed of living a lie." ...|$|R
40|$|Electrical {{stimulation}} (ES) of {{the brain}} has been performed for over 100 years, and although some might {{say it is a}} crude technique for understanding the detailed mechanisms underlying different neural computations, microstimulation has made significant contributions to our knowledge in both basic and clinical research. Recently there has been resurgence in its use in the context of electrotherapy and neural prostheses. For example, ES has made it possible to at least <b>partially</b> restore <b>hearing</b> to deaf patients by delivering pulses via implanted electrodes to different regions of the cochlea. Stimulation of the basal ganglia is remarkably effective in restoring motor function to Parkinson’s patients, and microstimulation of the geniculostriate visual pathway is regarded by some as a very promising (future) method for making the blind see again. Yet, the methodology still suffers from at least two fundamental problems; (a) we do not always know exactly what is being stimulated when we pass currents through the tissue; and (b) stimulation causes activation in a large number of areas even outside the stimulation site, making it difficult to isolate and evaluate the behavioral effects of the stimulated area itself. Microstimulation during fMRI (esfMRI) could provide a unique opportunity to visualize the networks underlying electrostimulation-induced behaviors, to map neuromodulatory systems, or to develop electrotherapy and neural prosthetic devices. Moreover esfMRI is an excellent tool {{for the study of the}} effects of regional synaptic plasticity, e. g. LTP in hippocampus, on cortical connectivity. Last but not least, esfMRI can offer important insights into the functional neurovascular coupling. In my talk, I shall discuss findings from recent and on-going work on signal propagation during electrical stimulation, as well as data related to effective connectivity...|$|R
40|$|In {{difficult}} listening situations, e. g. in {{a cocktail}} party scenario, speech signal that a listener is interested in decoding is often masked by unwanted noise, disrupting bottom-up signalling. A normal hearing (NH) listener is able to withstand {{a reasonable amount of}} such disruption and can still achieve good speech perception. This is possible partially because the information encoded in human speech is redundant at various levels like phonetic, morphemic, sentential, discourse, etc. In addition, NH listeners employ various cognitive mechanisms to reconstruct the lost information from disrupted speech signal. Some of these mechanisms are: application of the knowledge of the speaker’s language and its grammatical conventions, expectation formulated {{on the basis of the}} information collected previously in the discourse, tracking the auditory information within the speech stream, etc. As a result, (i) some loss of information can be tolerated without loss of meaning, and (ii) some information can be reconstructed on the basis of the leftover information. A cochlear implant (CI) is an implantable electronic device that <b>partially</b> reconstructs <b>hearing</b> for individuals with profound or total sensorineural hearing loss. CI users have greater difficulty in understanding speech than NH listeners in challenging listening scenarios where target speech signals are disrupted, e. g. with multiple individuals talking simultaneously or in noisy surroundings. This thesis explores if various factors inherent to the signal, and deficits of hearing impairment and/or characteristic of CI signal transmission may be at least partially responsible for the CI users having reduced ability of understanding speech in difficult listening scenarios. I conclude in the thesis that CI users can effectively use top-down restoration mechanisms but the nature and/or extent of the working of these mechanisms may be different in CI users than in NH listeners due to certain factors that may themselves vary among the CI users...|$|R
