0|1432|Public
40|$|We {{present a}} {{systematic}} analysis of a lexical-tree based <b>parallel</b> <b>search</b> algorithm for multi-core desktop processors. We introduce an analytical model that predicts the speedup from parallelization after accounting for load imbalance among the cores. Various sources of overhead in the <b>parallel</b> <b>search</b> algorithm are described, benchmarked and analyzed. Besides load imbalance, these include the inherently serial steps of the <b>parallel</b> <b>search</b> algorithm {{and an increase in}} main memory access latency. 1...|$|R
40|$|In this paper, we {{describe}} the design and implementation of a reusable load balancer for <b>parallel</b> <b>search</b> problems. <b>Parallel</b> <b>search</b> problems are a significant research topic in the parallel processing area: these applications expose irregularities that require dynamic load balancing techniques. status: publishe...|$|R
40|$|Parallelism and {{distribution}} are two distinct concepts that are confusingly close. <b>Parallel</b> <b>Search</b> refers {{in this work}} to {{the distribution of the}} search space and Distributed Asynchronous Search to the distribution of the constraint predicates. A certain amount of parallelism exists in any Distributed Asynchronous Search and it increases with the degree of asynchronism. However, in comparison to <b>Parallel</b> <b>Search</b> [10], the <b>parallel</b> effort in Distributed Asynchronous Search can be more redundant. Moreover, agents in Asynchronous Search can have periods of inactivity which are less frequent in <b>Parallel</b> <b>Search.</b> Since Distributed Search is the only solution for certain classes of naturally distributed problems, we show here how one can integrate the idea of <b>Parallel</b> <b>Search</b> in Distributed Asynchronous Search. A technique for dynamic reallocation of search space is then presented. This technique builds on the procedure for marking concurrent proposals for conflicting resources, that we have formalized in [11]. ...|$|R
40|$|Abstract — This work {{examines}} a novel {{method that}} provides a <b>parallel</b> <b>search</b> {{of a very large}} network space consisting of fisheries management data. The <b>parallel</b> <b>search</b> solution is capable of determining global maxima of the search space using brute force search, compared to local optima located by machine learning solutions such as evolutionary computation. The actual solutions from the best machine learning technique, called Probabilistic Adaptive Mapping Developmental Genetic Algorithm, are compared by a fisheries expert to the global maxima solutions returned by <b>parallel</b> <b>search.</b> In addition, the time required for <b>parallel</b> <b>search,</b> for both CPU and GPU-optimized solutions, are compared to those required for machine learning solutions. The GPU parallel computing solution was found to have a speedup of over 10, 000 x, in excess of most similar performance comparison studies in the literature. An expert found that overall the machine learning solutions pro-duced more interesting results by locating local optima than global optima determined by parallel processing. I...|$|R
50|$|YouTorrent was a BitTorrent {{search engine}} which allowed <b>parallel</b> <b>searches</b> on {{different}} torrent search engines.|$|R
40|$|Many {{artificial}} intelligence techniques rely on heuris-tic search through large spaces. Because the compu-tational effort required to search through these spaces reduces {{the applicability of}} the techniques, a number of parallel and distributed approaches to search have been introduced to improve the performance of certain aspects of the search process. However, theoretical and experimental results have shown that the effec-tiveness of <b>parallel</b> <b>search</b> algorithms can vary greatly from one search problem to another. In this paper we investigate the use of uncertainty rea-soning to choose the <b>parallel</b> <b>search</b> techniques that maximize the speedup obtained by <b>parallel</b> <b>search.</b> The approach described here is implemented in the EUREKA system, an architecture that includes diverse approaches <b>parallel</b> <b>search.</b> When a new search task is input to the system, EUREKA gathers information about the search space and automatically selects the appropriate search strategy. Because the gathered in-formation is uncertain and incomplete, we use a belief network to model the influence of problem features on speedup and select strategies that will yield the best performance. We present preliminary results on search problems drawn from the Fifteen Puzzle domain...|$|R
40|$|We {{present a}} survey of <b>parallel</b> local <b>search</b> {{algorithms}} in which we review the concepts {{that can be used}} to incorporate parallelism into local search. For this purpose we distinguish between single-walk and multiple-walk <b>parallel</b> local <b>search</b> and between asynchronous and synchronous parallelism. Within the class of single-walk algorithms we differentiate between multiple-step and single-step parallelism. To describe <b>parallel</b> local <b>search</b> we introduce the concepts of hyper neighborhood structures and distributed neighborhood structures. Furthermore, we present templates that capture most of the <b>parallel</b> local <b>search</b> algorithms proposed in the literature. Finally, we discuss some complexity issues related to <b>parallel</b> local <b>search...</b>|$|R
40|$|Abstract. In {{this paper}} we discuss methods for {{predicting}} the performance of any formulation of randomized <b>parallel</b> <b>search,</b> and propose a new performance prediction method {{that is based on}} obtaining an accurate estimate of the k-processor run-time distribution. We show that the k-processor prediction method delivers accurate performance predictions and demonstrate the validity of our analysis on several robot motion planning problems. Key words: randomized path planning, randomized <b>parallel</b> <b>search,</b> performance evaluation, <b>parallel</b> computers...|$|R
40|$|The {{problem of}} searchability in {{decentralized}} complex networks {{is of great}} importance in computer science, economy and sociology. We present a formalism that is able to cope simultaneously {{with the problem of}} search and the congestion effects that arise when <b>parallel</b> <b>searches</b> are performed, and obtain expressions for the average search cost [...] written in terms of the search algorithm and the topological properties of the network [...] both in presence and abscence of congestion. This formalism is used to obtain optimal network structures for a system using a local search algorithm. It is found that only two classes of networks can be optimal: star-like configurations, when the number of <b>parallel</b> <b>searches</b> is small, and homogeneous-isotropic configurations, when the number of <b>parallel</b> <b>searches</b> is large. Comment: 4 pages. Final version accepted in PR...|$|R
40|$|One of the {{principal}} advantages of parallelizing a rule-based system, or more generally, any A. I. system, {{is the ability to}} pursue alternate search paths concurrently. Conventional memory representations for production systems cannot easily or efficiently support <b>parallel</b> <b>search</b> because of the essentially flat structure of working memory and the combinatorics of pursuing pattern matching in a large memory space. A further obstacle to the effective exploitation of parallelism is the problem of maintaining the internal consistency of each search space while performing parallel activities in other spaces. This paper presents an approach to <b>parallel</b> <b>search</b> for rule-based systems which involves maintaining multiple separate worlds, each representing a search space. Constructs for creating, manipulating, and merging separate spaces are discussed. We describe how the addition of a language mechanism for specifying multiple worlds simplifies the design of <b>parallel</b> <b>search</b> algorithms, increases [...] ...|$|R
40|$|Program parallelization becomes {{increasingly}} important when new multi-core architectures provide {{ways to improve}} performance. One {{of the greatest challenges}} of this development lies in programming parallel applications. Declarative languages, such as constraint programming, can make the transition to parallelism easier by hiding the parallelization details in a framework. Automatic parallelization in constraint programming has mostly focused on <b>parallel</b> <b>search.</b> While search and consistency are intrinsically linked, the consistency part of the solving process is often more time-consuming. We have previously looked at parallel consistency and found it to be quite promising. In this paper we investigate how to combine <b>parallel</b> <b>search</b> with <b>parallel</b> consistency. We evaluate which problems are suitable and which are not. Our results show that parallelizing the entire solving process in constraint programming is a major challenge as <b>parallel</b> <b>search</b> and <b>parallel</b> consistency typically suit different types of problems...|$|R
40|$|This is the author's peer-reviewed final manuscript, as {{accepted}} by the publisher. The published article is copyrighted by Springer {{and can be found}} at: [URL] (2004) proposed that stimulus-driven capture occurs primarily for salient stimuli that fall within the observer's attentional window, such as when performing a <b>parallel</b> <b>search.</b> This proposal, supported by some studies, can explain many seemingly discrepant results in the literature. The present study tested this proposal using a modified pre-cuing paradigm. Search mode was manipulated via target-distractor similarity in color space. In the <b>parallel</b> <b>search</b> condition, the orange target “popped out” from a set of distantly colored distractors (blue and green). In the serial search condition, the orange target was more difficult to find amongst a set of similarly colored distractors (yellow and red). In Experiments 1 and 2, cue validity effects for irrelevant color singleton cues were greater under <b>parallel</b> <b>search</b> than serial search, at least partially replicating previous studies favoring the attentional window account (e. g., Belopolsky et al., 2007). We found the opposite pattern, however, for capture by abrupt onsets (Experiments 3 and 4). Here, capture effects were actually greater under serial <b>search.</b> In sum, <b>parallel</b> <b>search</b> appears to facilitate capture by color singletons, yet inhibit capture by abrupt onsets...|$|R
40|$|Artificial {{intelligence}} techniques often rely on {{heuristic search}} through large spaces. Because the computational effort required to search these spaces limits the scalability of the techniques, {{a number of}} parallel and distributed approaches to search have been introduced. However, theoretical and experimental results {{have shown that the}} effectiveness of <b>parallel</b> <b>search</b> algorithms can vary greatly from one search problem to another. In this paper we investigate the use of machine learning techniques to automatically choose the <b>parallel</b> <b>search</b> techniques that maximize the resulting speedup. The approach described here is implemented in the Eureka system, an architecture that includes diverse approaches to <b>parallel</b> <b>search.</b> When a new search task is input to the system, Eureka gathers information about the search space and automatically selects the appropriate search strategy. We compare the effectiveness of a decision tree learner and a Bayesian network to model the [...] ...|$|R
40|$|This {{extended}} abstract summarizes two {{contributions from}} ongoing work on <b>parallel</b> <b>search</b> in theorem proving. First, we give {{a framework of}} definitions for parallel theorem proving, including inference system, communication operators, <b>parallel</b> <b>search</b> plan, subdivision function, parallel strategy, parallel derivation, fairness and propagation of redundancy for parallel derivations. A notion of a parallel strategy being a parallelization of a sequential strategy, and a theorem establishing a general relation between sequential fairness and parallel fairness are also given. Second, we extend our approach to the modelling of <b>search</b> to <b>parallel</b> <b>search,</b> covering inferences (expansion and contraction), behaviour of the search plan, subdivision of the search space and communication among the processes. This model allows us to study the behavior of many search processes on a single marked search graph. In the full paper, we plan to extend our methodology for {{the measure of the}} complex [...] ...|$|R
500|$|Huerta, Robert. Giants of Delft: Johannes Vermeer and the Natural Philosophers: The <b>Parallel</b> <b>Search</b> for Knowledge {{during the}} Age of Discovery. Lewisburg, PA: Bucknell University Press, 2003.|$|R
40|$|The five-stage {{switching}} {{system with a}} <b>parallel</b> <b>search</b> is considered in the paper. It {{can be used in}} data networks and multiprocessor computer systems. The algorithm of a <b>parallel</b> <b>search</b> of free communication channels in the five- stage {{switching system}}, based on a theoretical and multiple model and representation {{of the structure of the}} switching system in the form of the data array is offered. The algorithm enables to fulfill a parallel adjustment of the switching system along with information transmission, and the search of connecting ways occurs inside this switching field...|$|R
40|$|In this paper, {{we propose}} a new multi-comparand {{associative}} machine (MCA-machine) and {{its application to}} relational algebra operations. We first offer a new efficient associative algorithm for the multi-comparand <b>parallel</b> <b>search.</b> It generalizes the Falkoff associative algorithm that performs a <b>parallel</b> <b>search</b> in a matrix based on the exact match with a given pattern. Then we apply the new associative algorithm to implement a group of the relational algebra operations on the MCA-machine. The proposed algorithms are represented as corresponding procedures for the MCA-machine. We prove their correctness and evaluate their time complexity...|$|R
40|$|Many of the {{artificial}} intelligence techniques developed to date rely on heuristic search through large spaces. Unfortunately, {{the size of}} these spaces and the corre-sponding computational effort reduce the applicability of otherwise novel and effective algorithms. Because automated theorem provers rely on heuristic search through the space of possible inferences, they are sub-ject to the same difficulties. A number of parallel and distributed approaches to ~arch have considerably improved {{the performance of the}} search process. Our goal is to develop an architec-ture that automatically selects <b>parallel</b> <b>search</b> strate-gies for a ~riety of search problems. We describe one such architecture realized in the EUREKA system, which uses machine learning techniques to select the <b>parallel</b> <b>search</b> strategy for a given problem space. Although EUREKA has successfully improved <b>parallel</b> <b>search</b> for problem solving and planning, parallelizing theorem proving systems introduces several new challenges. We inv~tigate the application of the EUREKA system to a parallel version of the OTTER theorem prover and show results from a subset of TPTP library problems...|$|R
40|$|The {{performance}} of four algorithms using pseudonoise matched filters (PNMFs), for direct-sequence spread-spectrum systems, is analyzed. They are: <b>parallel</b> <b>search</b> with fix dwell detector (PL-FDD), <b>parallel</b> <b>search</b> with sequential detector (PL-SD), parallel-serial search with fix dwell detector (PS-FDD), and parallel-serial search with sequential detector (PS-SD). The operation characteristic for each detector {{and the mean}} acquisition time for each algorithm are derived. All the algorithms are studied {{in conjunction with the}} noncoherent integration technique, which enables the system to operate in the presence of data modulation. Several previous proposals using PNMF are seen as special cases of the present algorithms...|$|R
40|$|The {{purpose of}} the work is to carry out imitating {{modeling}} of switching systems and to compare their characteristics. The subject of the research is the switching system with <b>parallel</b> <b>search</b> of communication channels and switching systems with consecutive principle of connection making. Imitating modeling is realized {{on the basis of the}} engineered program. The program allows modeling the structure and the algorithm of switching systems functioning. The results of modeling and comparing the received characteristics drew to the conclusion that the use of the switching system with <b>parallel</b> <b>search</b> of communication channels considerably decreases the traffic delays...|$|R
40|$|Abstract. Search in {{constraint}} {{programming is}} a time consuming task. Search can be speeded up by exploring subtrees of a <b>search</b> tree in <b>parallel.</b> This paper presents distributed search engines that achieve parallelism by distribution across networked computers. The main point of the paper is a simple design of the <b>parallel</b> <b>search</b> engine. Simplicity comes as an immediate consequence of clearly separating search, concurrency, and distribution. The obtained distributed search engines are simple yet offer substantial speedup on standard network computers. 1 Introduction Search in constraint programming {{is a time}} consuming task. Search can bespeeded up by exploring several subtrees of a <b>search</b> tree in <b>parallel</b> by cooperating <b>search</b> engines called workers. The paper develops search engines that achieve parallelism by distributing workers across standard networked computers. The paper has two main points. The first point {{is to provide a}} simple, high-level, and reusable design for <b>parallel</b> <b>search.</b> The second point is to obtain good speedup rather than good resourceutilization. Simple and Reusable Design <b>Parallel</b> <b>search</b> is made simple by separating threeissues: search, concurrency, and distribution. Search Workers are search engines that explicitly manipulate their state. Thestate corresponds to yet to be explored subtrees of the search tree. Explici...|$|R
40|$|It {{is only in}} {{the last}} five years that {{researchers}} have begun to use disk-based search techniques on a large scale. The primary examples of its use come from symbolic algebra and from artificial intelligence. In the field of <b>parallel</b> <b>search,</b> disk-based search has been forced on researchers because the historical growth in the amount of RAM per CPU core has now stopped. Indeed, the current trend toward multi-core CPUs now threatens to take us backwards. This article makes an original contribution to the design of disk-based <b>parallel</b> <b>search</b> algorithms. It presents a survey of disk-based techniques side-by-side, for the first time. This allows researchers to choose from a menu of techniques, and also to create new hybrid algorithms from the building blocks presented here...|$|R
40|$|Abstract. Umko is {{a strong}} {{open-source}} chess program developed to collect good concepts from literature and other open-source projects. Using these concepts, we want to implement an optimally chess program. To do this, Umko has implemented a bitboard representation, move generator, <b>parallel</b> <b>search</b> algorithm, multiple principal variation search, transposition table, universal chess interface, evaluation function, usage of endgame tablebases and usage of the opening book. The paper provides details of these concepts. Umko is a program running on several platforms inside different graphical user interfaces and using the modern processor technology. It has a <b>parallel</b> <b>search</b> algorithm allowing its program to simultaneously use more processors or cores and the new SSE 4. 2 CPU instruction set. Both the <b>parallel</b> <b>search</b> algorithm and the new instruction set enable the program to be a faster and stronger player. Having been tested on different independent rating lists, the program is rated among the top ten open-source chess programs. Key words: chess program, bitboard representation, evaluation function, search algorithm, move generator, transposition table, endgame tablebases, opening book...|$|R
40|$|The {{increasing}} {{availability of}} “utility computing ” {{resources such as}} clouds, grids, and massively parallel shared clusters can provide practically unlimited processing and memory capacity on demand, at some cost per unit of resource usage. This requires a new perspective {{in the design and}} evaluation of <b>parallel</b> <b>search</b> algorithms. Previous work in <b>parallel</b> <b>search</b> implicitly assumed ownership of a cluster with a static amount of CPU cores and RAM, and emphasized wallclock runtime. With utility computing resources, trade-offs between performance and monetary costs must be considered. This paper considers dynamically increasing the usage of utility computing resources until a problem is solved. Efficient resource allocation policies are analyzed in comparison with an optimal allocation strategy. We evaluate our iterative allocation strategy by applying it to the HDA * <b>parallel</b> <b>search</b> algorithm. The experimental results validate our theoretical predictions. They show that, in practice, the costs incurred by iterative allocation are reasonably close to an optimal (but a priori unknown) policy, and are significantly better than the worst-case analytical bounds. ...|$|R
50|$|Distributed.net has {{completed}} distributed massively <b>parallel</b> <b>searches</b> for optimal order-24 through order-27 Golomb rulers, each time confirming the suspected candidate ruler. In February 2014, distributed.net began the search to find optimal Golomb rulers (OGRs) of order-28.|$|R
40|$|A <b>parallel</b> <b>search</b> {{strategy}} {{based on}} sparse representation (PS-L 1 tracker) is {{proposed in the}} particle filter framework. To obtain the weights of state particles, target templates are represented linearly with the dictionary of target candidates. Sparse constraints on the coefficient guarantee that only true target candidates can be selected, and the nonnegative entries denote the associate weights of efficient target states. Then the optimal target state can be estimated by the linear combination of above weighted states. In this way, efficient target states are selected simultaneously from all the particles, which we call a <b>parallel</b> <b>search</b> strategy. Experimental results demonstrate excellent performance of the proposed method on challenging infrared images...|$|R
40|$|Information <b>storage</b> and {{database}} <b>search</b> {{are attractive}} {{areas in the}} field of nuclear magnetic resonance. Among the notable works reported earlier, an implementation of a <b>parallel</b> <b>search</b> algorithm in a dipolar coupled spin cluster has gained considerable attention [A. Khitrin, V. L. Ermakov, and B. M. Fung, Phys. Rev. Lett. 89, 277902 (2002) ]. In this paper, we propose and exemplify that spatial encoding can be successfully utilized in realizing such parallel algorithms. We also introduce an improved protocol of the <b>parallel</b> <b>search</b> algorithm, which can be realized using spatial encoding. The methods have been demonstrated to perform a search operation using 215 bits...|$|R
40|$|The {{purpose of}} work is to develop {{circuits}} of switching elements of system with parallel adjustment. The objects of the research are switching blocks and switching cells of switching system using <b>parallel</b> <b>search</b> of communication channels. The developed function circuits of switching elements allow to realize algorithm of adjustment of switching system when the process of establishment of connections occurs on {{the background of the}} information transfer. The method of <b>parallel</b> <b>search</b> of communication channels, realized in the switchboard, allows to make the process of parallel establishment of connections together with the information transfer due to that capacity of computing systems grows in 2 – 3 times...|$|R
40|$|In this paper, {{we review}} <b>parallel</b> <b>search</b> {{techniques}} for approximating the global optimal solution of combinatorial optimization problems. Recent developments on parallel implementation of genetic algorithms, simulated annealing, tabu search, and greedy randomized adaptive search procedures (GRASP) are discussed...|$|R
30|$|The second-ranked {{algorithm}} was smoothing and auxiliary function-based cooperative coevolution {{for global}} optimization (SACC) [26]. In SACC, a <b>parallel</b> <b>search</b> is done first using CC. After that, the local solutions {{worse than the}} better ones are eliminated using a smoothing function.|$|R
40|$|Tree searching is a {{fundamental}} and computationally intensive problem in artificial intelligence. Parallelization of tree-searching algorithms is one method of improving the speed of these algorithms. However, a high-performance <b>parallel</b> two-player game-tree <b>search</b> algorithm has eluded researchers. Most <b>parallel</b> game-tree <b>search</b> approaches follow synchronous methods, where the work is concentrated within a specific part of the tree, or a given search depth. This thesis shows that asynchronous gametree search algorithms can be as efficient as synchronous methods in determining the minimax value. A taxonomy of previous work in <b>parallel</b> game-tree <b>search</b> is presented. A theoretical model is developed for comparing the efficiency of synchronous and asynchronous search algorithms under realistic assumptions. APHID, a portable <b>parallel</b> game-tree <b>search</b> library, has been built based on the asynchronous <b>parallel</b> game-tree <b>search</b> algorithm proposed in the comparison. The library is easy to imple [...] ...|$|R
40|$|By two {{different}} cue paradigms to cue target’s location or locations of all stimuli, {{this study is}} to discuss the search efficiency in different search modes. The research includes three experiments. The main results are as follows: The first experiment explores whether cueing target’s location has impact on vis-ual search performance under different <b>search</b> modes (<b>parallel</b> <b>search</b> and serial search). The results are: cueing target’s location has no facilitation effect in <b>parallel</b> <b>search</b> condition while has facilitation effect in serial search condition, the effect reflects the diffidence in slope of reaction time. In the second experiment, we want to explore whether cueing all stimuli’s loca-tions has impact on visual search performance under different search modes. The re-sults show that: cueing all stimuli’s locations has no facilitation effect in <b>parallel</b> <b>search</b> condition but has facilitation effect in serial search condition, the effect reflects the diffidence in intercept of reaction time. The third experiment is to explore the time course of facilitation effect in serial search. The result shows that only a 50 ms which cueing all stimuli’s locations has fa-cilitation effect, with the longer cueing time, the more facilitation effect. 本研究采用两种不同的线索范式，提示目标位置或所有刺激的位置，探讨线索位置对平行搜索和序列搜索绩效的影响。本研究包括三个实验，主要结果如下： 实验一探讨经典线索范式（线索只提示目标的位置）下的视觉搜索绩效。结果发现：线索对平行搜索条件下的目标识别没有影响；但对序列搜索条件下的目标识别有明显的促进作用，即有线索下的目标识别快于无线索下的目标识别，主要表现在有线索下的反应时斜率小于无线索下的反应时斜率。 实验二探讨同时线索范式（线索提示所有刺激的位置）下的视觉搜索绩效。结果表明：线索对平行搜索条件下的目标识别没有影响；但对序列搜索条件下的目标识别有显著的促进作用，即有线索下的目标识别快于无线索下的目标识别，主要表现在有线索下的反应时截距小于无线索下的反应时截距。 实验三探讨序列搜索条件下，同时线索范式下的空间注意线索效应的时程特点。研究发现：呈现 50 ms的线索就能促进对目标的识别，随着线索呈现时间的延长，促进作用越明显...|$|R
40|$|We {{present in}} this paper {{a new model of}} {{artificial}} ants foraging behavior based on a population of primitive ants (Pachycondyla apicalis) and its application to the general problem of optimization. These ants are characterized by a relatively simple but efficient strategy of prey search where individuals hunt alone and try to cover uniformly a given area around their nest. This is performed by <b>parallel</b> local <b>searches</b> on hunting sites with a sensitivity to successful sites. Also, the nest is moved periodically. This corresponds in optimization to an algorithm performing several random <b>parallel</b> <b>searches</b> which are localized uniformly in a sub-space centered around a point. Moving the nest corresponds to a restart operator of the <b>parallel</b> <b>searches</b> where the central point is moved. Furthermore, these ants are able to perform some form of recruitment called "tandem-running" where one leading ant is followed by another one to a given interesting site. We have applied this algorithmic model, called API, to combinatorial and numerical optimization problems...|$|R
40|$|Abstract. The {{most popular}} {{architecture}} for <b>parallel</b> <b>search</b> is work stealing: threads that {{have run out}} of work (nodes to be searched) steal from threads that still have work. Work stealing not only allows for dynamic load balancing, but also determines which parts of the search tree are searched next. Thus the place from where work is stolen has a dramatic effect on the efficiency of a <b>parallel</b> <b>search</b> algorithm. This paper examines quantitatively how optimal work stealing can be performed given an estimate of the relative solution densities of the subtrees at each search tree node and relates it to the branching heuristic strength. An adaptive work stealing algorithm is presented that automatically performs different work stealing strategies based on the confidence of the branching heuristic at each node. Many <b>parallel</b> depth-first <b>search</b> patterns arise naturally from this algorithm. The algorithm produces near perfect or super linear algorithmic efficiencies on all problems tested. Real speedups using 8 threads range from 7 times to super linear. ...|$|R
5000|$|The Sword Project and Olive Tree Bible Software {{both have}} modules {{for both the}} New Chinese Version and the Union Version of the Bible. More {{recently}} (as of January 2014) these bibles were made available for <b>parallel</b> <b>searching</b> at BibleHunter.com & Holy-Bibles.net [...]|$|R
40|$|Many of the articial {{intelligence}} techniques {{developed to}} date rely on heuristic search through large spaces. Unfortunately, {{the size of}} these spaces and the corresponding com-putational eort reduce the applicability of otherwise novel and eective algorithms. A number of parallel and distributed approaches to search have considerably improved {{the performance of the}} search process. Our goal is to develop an architecture that automatically selects <b>parallel</b> <b>search</b> strate-gies for optimal performance on a variety of search problems. In this paper we describe one such architecture realized in the Eureka system, which combines the benets of many dierent approaches to <b>parallel</b> heuristic <b>search.</b> Through empirical and theoretical anal-yses we observe that features of the problem space directly aect the choice of optimal <b>parallel</b> <b>search</b> strategy. We then employ machine learning techniques to select the optimal <b>parallel</b> <b>search</b> strategy for a given problem space. When a new search task is input to the system, Eureka uses features describing the search space and the chosen architecture to automatically select the appropriate search strategy. Eureka has been tested on a MIMD parallel processor, a distributed network of workstations, and a single workstation using multithreading. Results generated from fteen puzzle problems, robot arm motion prob-lems, articial search spaces, and planning problems indicate that Eureka outperforms any of the tested strategies used exclusively for all problem instances and is able to greatly reduce the search time for these applications. 1...|$|R
