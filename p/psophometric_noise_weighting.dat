0|231|Public
40|$|This paper {{describes}} {{the development of}} a novel three-phase phase-locked loop (PLL) used to compensate for mains variations by being incorporated as part of a feedforward loop in a three-phase telecommunications power converter. A telecommunications converter must comply with industry standards, in particular the <b>psophometric</b> <b>noise</b> standard CCIF- 1951; this is achieved by controlling the output voltage ripple from the dc-dc converter. It is required that psophometric compliance is maintained under expected mains variations documented in the EN 50160 power quality standard. The software PLL is simulated and performance characteristics show a high degree of noise rejection while also maintaining good dynamic performance...|$|R
40|$|This paper {{describes}} {{the development of}} a new generation of power converter, used to power telecommunications equipment. A telecommunications converter must comply with the <b>psophometric</b> <b>noise</b> standard CCIF- 1951 and the IEC 1000 - 3 - 2 harmonic standard. While the IEC 1000 - 3 - 2 standard is easily met with active power factor correction techniques, a high degree of effort is usually required to meet with the psophometric standard. Therefore, a control methodology utilising a three-phase phase-locked loop is introduced as a method of complying with the psophometric standard under distorted mains conditions. Simulations show that combining this with a novel feedback controller, results in an improved load step response over using a traditional proportional integral type controller...|$|R
2500|$|... dB Q: {{sometimes}} used to denote weighted noise level, commonly using the ITU-R 468 <b>noise</b> <b>weighting</b> ...|$|R
40|$|Abstract—While <b>weight</b> <b>noise</b> {{injection}} {{during training}} {{has been adopted}} in attaining fault tolerant neural networks (NNs), theoretical and empirical studies on the online algorithms developed based on these strategies {{have yet to be}} complete. In this paper, we present results on two important aspects in online learning algorithms based on combining <b>weight</b> <b>noise</b> injection and <b>weight</b> decay. Through intensive computer simulations, the convergence behaviors of those algorithms and the performance of the NNs generated by these algorithms are elucidated. It is found that (i) the online learning algorithm based on purely multiplicative <b>weight</b> <b>noise</b> injection does not converge, (ii) the algorithms combining <b>weight</b> <b>noise</b> injection and <b>weight</b> decay exhibit better convergence behaviors than their pure <b>weight</b> <b>noise</b> injection counterparts, and (iii) the neural networks attained by those algorithms combining <b>weight</b> <b>noise</b> injection and <b>weight</b> decay show better fault tolerance abilities than the neural networks attained by the pure <b>weight</b> <b>noise</b> injection-based algorithms. These empirical results not just can supplement our recent work done on the convergence behaviors of the <b>weight</b> <b>noise</b> injection-based learning algorithms [16], but also provide new information on effect of <b>weight</b> <b>noise</b> and <b>weight</b> decay on the neural networks that are generated by these algorithms...|$|R
5000|$|Not {{reliant on}} a moving mirror and shutter, which {{otherwise}} adds <b>noise,</b> <b>weight,</b> design complexity, and cost.|$|R
50|$|The {{absolute}} {{power of the}} noise measured or calculated at a receive point. The related bandwidth and the <b>noise</b> <b>weighting</b> must also be specified.|$|R
5000|$|In a noise-measuring set, flat <b>weighting</b> is a <b>noise</b> <b>weighting</b> {{based on}} an amplitude-frequency {{characteristic}} that is flat over a frequency range that must be stated.|$|R
40|$|Abstract—Injecting <b>weight</b> <b>noise</b> during {{training}} {{has been proposed}} {{for almost two decades}} as a simple technique to improve fault tolerance and generalization of a multilayer perceptron (MLP). However, little has been done regarding their convergence behaviors. Therefore, we presents in this paper the convergence proofs of two of these algorithms for MLPs. One is based on combining injecting multiplicative <b>weight</b> <b>noise</b> and <b>weight</b> decay (MWN-WD) {{during training}}. The other is based on combining injecting additive <b>weight</b> <b>noise</b> and <b>weight</b> decay (AWN-WD) during training. Le...|$|R
40|$|This paper {{describes}} an initial {{investigation into the}} development of a new generation of power converter, used to power telecommunications equipment. The traditional topology for such power converters is a single-phase two-stage design, with a boost converter providing power factor correction at the input to the first stage and an isolated dc-dc converter making up the second stage. A two-stage design results in the output power being processed twice and this cascade effect results in an overall reduction in efficiency. Each converter must comply with the <b>psophometric</b> <b>noise</b> standard CCIF- 1951 and the IEC 1000 - 3 - 2 standard, as well as having output isolation. A power converter solution is sought that meets with all the requirements of the telecommunications industry, while not displaying the inherent weaknesses associated with a boost-derived topology, and which can be realised by a single-stage design. A number of common three-phase topologies exist that could be realised as telecommunication power supplies, however they do not completely satisfy all the requirements. A new converter, which is a three-phase single-stage buck-derived topology, is proposed. Simulation shows that if this topology is combined with a three-phase phase locked loop controller it can potentially meet the compliance standards...|$|R
50|$|A <b>noise</b> <b>weighting</b> is a {{specific}} amplitude-vs.-frequency characteristic {{that is designed to}} allow subjectively valid measurement of noise. It emphasises the parts of the spectrum that are most important.|$|R
40|$|Injecting <b>weight</b> <b>noise</b> during {{training}} {{has been a}} simple strategy to improve the fault tolerance of multilayer perceptrons (MLPs) for almost two decades, and several online training algorithms have been proposed in this regard. However, there are some misconceptions about the objective functions being minimized by these algorithms. Some existing results misinterpret that the prediction error of a trained MLP affected by <b>weight</b> <b>noise</b> {{is equivalent to the}} objective function of a <b>weight</b> <b>noise</b> injection algorithm. In this brief, we would like to clarify these misconceptions. Two <b>weight</b> <b>noise</b> injection scenarios will be considered: one is based on additive <b>weight</b> <b>noise</b> injection and the other is based on multiplicative <b>weight</b> <b>noise</b> injection. To avoid the misconceptions, we use their mean updating equations to analyze the objective functions. For injecting additive <b>weight</b> <b>noise</b> {{during training}}, we show that the true objective function is identical to the prediction error of a faulty MLP whose weights are affected by additive <b>weight</b> <b>noise.</b> It consists of the conventional mean square error and a smoothing regularizer. For injecting multiplicative <b>weight</b> <b>noise</b> during training, we show that the objective function is different from the prediction error of a faulty MLP whose weights are affected by multiplicative <b>weight</b> <b>noise.</b> With our results, some existing misconceptions regarding MLP training with <b>weight</b> <b>noise</b> injection can now be resolved...|$|R
50|$|The {{value of}} noise power, from all sources, {{measured}} at the line terminals of a telephone set's receiver.' Either flat weighting or some other specific amplitude-frequency characteristic or <b>noise</b> <b>weighting</b> characteristic must {{be associated with the}} measurement.|$|R
25|$|Frequency {{sensitivity}} underwater also differs {{significantly to}} that in air, with a consistently higher threshold of hearing underwater, but also significantly skewed. An underwater <b>noise</b> <b>weighting</b> scale is available to assess noise hazard according to frequency sensitivity for wet conduction.|$|R
50|$|The {{subjective}} loudness of noise is best measured using a noise-meter to the ITU-R 468 <b>noise</b> <b>weighting</b> standard. The chart below shows, on this basis, the real range of live music, {{and then the}} level capabilities of various stages in the audio chain, from microphone to loudspeaker.|$|R
40|$|A user's manual is {{presented}} {{for a computer}} program for predicting the performance (static, flight, and reverse), <b>noise,</b> <b>weight</b> and cost of propellers for advanced general aviation aircraft of the 1980 time period. Complete listings of this computer program with detailed instructions and samples of input and output are included...|$|R
5000|$|The ITU-R 468 <b>noise</b> <b>weighting</b> was devised {{specifically}} for this purpose, and {{is widely used}} in broadcasting, especially in the UK and Europe. A-weighting is also used, especially in the USA, though this is only really valid for the measurement of tones, not noise, and is widely incorporated into sound level meters.|$|R
40|$|Injecting <b>weight</b> <b>noise</b> during {{training}} {{is a simple}} technique that has been proposed for almost two decades. However, {{little is known about}} its convergence behavior. This paper studies the convergence of two <b>weight</b> <b>noise</b> injectionbased training algorithms, multiplicative <b>weight</b> <b>noise</b> injection with <b>weight</b> decay and additive <b>weight</b> <b>noise</b> injection with <b>weight</b> decay. We consider that they are applied to multilayer perceptrons either with linear or sigmoid output nodes. Let w(t) be the weight vector, let V(w) be the corresponding objective function of the training algorithm, let α > 0 be the weight decay constant, and let μ(t) be the step size. We show that if μ(t) → 0, then with probability one E[w(t) 22] is bound and limt→∞ w(t) 2 exists. Based on these two properties, we show that if μ(t) → 0, t μ(t) = ∞, and t μ(t) 2 < ∞, then with probability one these algorithms converge. Moreover, w(t) converges with probability one to a point where ∇wV(w) = 0...|$|R
5000|$|In other words, each {{coefficient}} [...] in {{the original}} filter is simply multiplied by [...] in the bandwidth-expanded filter. The simplicity of this transformation makes it attractive, especially in CELP coding of speech, where it is often used for the perceptual <b>noise</b> <b>weighting</b> and/or to stabilize the LPC analysis. However, {{when it comes to}} stabilizing the LPC analysis, lag windowing is often preferred to bandwidth expansion.|$|R
50|$|A major use of <b>noise</b> <b>weighting</b> {{is in the}} {{measurement}} of residual noise in audio equipment, usually present as hiss or hum in quiet moments of programme material. The purpose of weighting here is to emphasise {{the parts of the}} audible spectrum that ears perceive most readily, and attenuate the parts that contribute less to perception of loudness, {{in order to get a}} measured figure that correlates well with subjective effect.|$|R
5000|$|The master {{recording}} process, using current 24-bit techniques, offers around 99 dB of [...] "true" [...] dynamic range (based on the ITU-R 468 <b>noise</b> <b>weighting</b> standard); {{identical to the}} dynamic range of a good studio microphone, though very few recordings will use just one microphone, and so the noise on most recordings {{is likely to be}} the sum of several microphones after mixing, and probably at least 6 dB worse than shown.|$|R
40|$|The {{purpose of}} this thesis is to study the coding of {{wideband}} speech and to improve on previous Code-Excited Linear Prediction (CELP) coders in terms of speech quality and bit rate. To accomplish this task, improved coding techniques are introduced and the operating bit rate is reduced while maintaining and even enhancing the speech quality. the first approach considers the quantization of Liner Predictive Coding (LPC) parameters and uses a three way split vector quantization. Both scalar and vector quantization are initially studied; results show that, with adequate codebook training, the second method generates better results while using a fewer number of bits. Nevertheless, the use of vector quantizers remain highly complex in terms of memory and number of computations. A new quantization scheme, split vector quantization (split VQ), is investigated to overcome this complexity problem. Using a new weighted distance measure as a selection criterion for split VQ, the average spectral distortion is significantly reduced to match the results obtained with scalar quantizers. The second approach introduces a new pitch predictor with an increased temporal resolution for periodicity. This new technique {{has the advantage of}} maintaining the same quality obtained with conventional multiple coefficient predictors at a reduced bit rate. Furthermore, the conventional CELP <b>noise</b> <b>weighting</b> filter is modified to allow more freedom and better accuracy in the modeling of both tilt and formant structures. Throughout this process, different <b>noise</b> <b>weighting</b> schemes are evaluated and the results show that the new filter greatly contributes in solving the problem of high frequency distortion. The final wideband CELP coder is operational at 11. 7 kbits/s and generates a high perceptual quality of the reconstructed speech using the fractional pitch predictor and the new perceptual <b>noise</b> <b>weighting</b> filter...|$|R
40|$|Issues & Topics Discussed: a) Aviation Week {{reported}} shortfall In LPT efficiency due to {{the application}} of "high lift airfoils". b) Progress in the design technologies in LPTs during the last 20 years: 1) Application of RANS based CFD codes. 2) Integration of recent experimental data and modeling of LPT airfoil specific flows into design methods. c) Opportunities to further enhance LPT efficiency for commercial aviation and military transport application and to impact emissions, <b>noise,</b> <b>weight</b> & cost...|$|R
50|$|The ITU-R 468 <b>noise</b> <b>weighting</b> curve, {{originally}} {{proposed in}} CCIR recommendation 468, but later adopted by numerous standards bodies (IEC, BSI, JIS, ITU) {{was based on}} the research, and incorporates a special Quasi-peak detector to account for our reduced sensitivity to short bursts and clicks. It is widely used by Broadcasters and audio professionals when they measure noise on broadcast paths and audio equipment, so they can subjectively compare equipment types with different noise spectra and characteristics.|$|R
40|$|Abstract — Although many {{analytical}} {{works have}} been done to investigate the change of prediction error of a trained NN if its weights are injected by noise, seldom of them has truly investigated on the dynamical properties (such as objective functions and convergence behavior) of injecting <b>weight</b> <b>noise</b> during training. In this paper, four different online <b>weight</b> <b>noise</b> injection training algorithms for multilayer perceptron (MLP) are analyzed and their objective functions are derived. Most importance, the objective function of injecting multiplicative <b>weight</b> <b>noise</b> during training is shown {{to be different from}} the prediction error of a trained MLP if its weights are injected by the same multiplicative <b>weight</b> <b>noise.</b> It provides a firm response to a question being posed for 14 years [8]: Can deterministic penalty terms model the effects of synaptic <b>weight</b> <b>noise</b> on network fault-tolerance?. Besides, we show that the objective function of injecting additive <b>weight</b> <b>noise</b> during training is equivalent to adding a regularizer penalizing the magnitude of the gradient vector of the MLP output with respect to its weight vector. Finally, the issue on their convergence proofs will be discussed. ...|$|R
2500|$|It is {{also used}} when {{measuring}} low-level noise in audio equipment, especially in the United States. In Britain, Europe and {{many other parts of}} the world, broadcasters and audio engineers more often use the ITU-R 468 <b>noise</b> <b>weighting,</b> which was developed in the 1960s based on research by the BBC and other organizations. [...] This research showed that our ears respond differently to random noise, and the equal-loudness curves on which the A, B and C weightings were based are really only valid for pure single tones.|$|R
50|$|Though they {{represent}} what we truly hear, ITU-R 468 <b>noise</b> <b>weighting</b> gives figures that are typically some 11dB worse than A-weighted, {{a fact that}} brought resistance from marketing departments reluctant to put worse specifications on their equipment than the public had been used to. Dolby tried to get round this by introducing a version of their own called CCIR-Dolby which incorporated a 6dB shift into the result (and a cheaper average reading rectifier), but this only confused matters, and was very much disapproved of by the CCIR.|$|R
40|$|Recently, sparse unmixing has {{received}} particular {{attention in the}} analysis of hyperspectral images (HSIs). However, traditional sparse unmixing ignores the different noise levels in different bands of HSIs, making such methods sensitive to different noise levels. To overcome this problem, the noise levels at different bands are assumed to be different in this paper, and a general sparse unmixing method based on noise level estimation (SU-NLE) under the sparse regression framework is proposed. First, the noise in each band is estimated {{on the basis of the}} multiple regression theory in hyperspectral applications, given that neighboring spectral bands are usually highly correlated. Second, the <b>noise</b> <b>weighting</b> matrix can be obtained from the estimated noise. Third, the <b>noise</b> <b>weighting</b> matrix is integrated into the sparse regression unmixing framework, which can alleviate the impact of different noise levels at different bands. Finally, the proposed SU-NLE is solved by the alternative direction method of multipliers. Experiments on synthetic datasets show that the signal-to-reconstruction error of the proposed SU-NLE is considerably higher than those of the corresponding traditional sparse regression unmixing methods without noise level estimation, which demonstrates the efficiency of integrating noise level estimation into the sparse regression unmixing framework. The proposed SU-NLE also shows promising results in real HSIs...|$|R
40|$|Methods for {{predicting}} the performance, <b>noise,</b> <b>weight,</b> {{and cost of}} propellers for advanced general aviation aircraft of the 1980 time period were developed and computerized. This basic program was refined to incorporate a method of including the blade shape parameter, integrated design lift coefficient. This method and a reverse thrust computational procedure {{were included in the}} computer program. The weight equation was refined and also incorporated in the computer program. A User's Manual which includes a complete listing of this computer program with detailed instructions on its use has been written...|$|R
50|$|In acoustics, noise {{measurement}} {{can be for}} the purpose of measuring environmental noise, or part of a test procedure using white noise, or some other specialised form of test signal. In audio systems and broadcasting, specific methods are used to obtain subjectively valid results in order that different devices and signal paths may be compared regardless of the differing spectral distribution and temporal properties of the noise that they generate. In particular, the ITU-R 468 <b>noise</b> <b>weighting</b> was devised specifically for this purpose, and is widely used for professional audio and broadcast measurements.|$|R
50|$|In {{audio quality}} measurement, {{quasi-peak}} rectifiers are specified in several standards. For example ITU-R 468 <b>noise</b> <b>weighting</b> uses a special rectifier incorporating two cascaded charging time constants. The PPM or peak programme meter {{used to measure}} programme levels is actually a quasi-peak reading meter, again with precisely defined dynamics. Flutter measurement also involves a standardised quasi-peak reading meter. In every case the dynamics are chosen to reflect the sensitivity of human hearing to brief sounds, ignoring those so brief {{that we do not}} perceive them, and weighting those of intermediate duration according to audibility.|$|R
5000|$|ITU-R 468 <b>noise</b> <b>weighting</b> with {{quasi-peak}} detection {{is widely}} used in Europe, especially in telecommunications, and in broadcasting particularly after it {{was adopted by the}} Dolby corporation who realised its superior validity for their purposes. Its advantages over A-weighting seem to be less well appreciated in the USA and in consumer electronics, where the use of A-weighting predominates—probably because A-weighting produces a 9 to 12 dB [...] "better" [...] specification, see specsmanship. It is commonly used by broadcasters in Britain, Europe, and former countries of the British Empire such as Australia and South Africa.|$|R
40|$|We {{study the}} impact of {{stochastic}} <b>noise</b> and connection <b>weight</b> matrices uncertainty on global exponential stability of hybrid BAM neural networks with reaction diffusion terms. Given globally exponentially stable hybrid BAM neural networks with reaction diffusion terms, the question to be addressed here is how much stochastic <b>noise</b> and connection <b>weights</b> matrices uncertainty the neural networks can tolerate while maintaining global exponential stability. The upper threshold of stochastic <b>noise</b> and connection <b>weights</b> matrices uncertainty is defined by using the transcendental equations. We find that the perturbed hybrid BAM neural networks with reaction diffusion terms preserve global exponential stability if the intensity of both stochastic <b>noise</b> and connection <b>weights</b> matrices uncertainty is smaller than the defined upper threshold. A numerical example is also provided to illustrate the theoretical conclusion...|$|R
40|$|Abstract. While injecting <b>weight</b> <b>noise</b> during {{training}} {{has been proposed}} {{for more than a}} decade to improve the convergence, generalization and fault tolerance of a neural network, not much theoretical work has been done to its convergence proof and the objective function that it is minimizing. By applying the Gladyshev Theorem, it is shown that the convergence of injecting <b>weight</b> <b>noise</b> {{during training}} an RBF network is almost sure. Besides, the corresponding objective function is essentially the mean square errors (MSE). This objective function indicates that injecting <b>weight</b> <b>noise</b> during training an radial basis function (RBF) network is not able to improve fault tolerance. Despite this technique has been effectively applied to multilayer perceptron, further analysis on the expected update equation of training MLP with <b>weight</b> <b>noise</b> injection is presented. The performance difference between these two models by applying weight injection is discussed. ...|$|R
50|$|Estimates {{of sound}} {{annoyance}} typically rely on weighting filters, which consider some sound frequencies {{to be more}} important than others based on their presumed audibility to humans. The older dB(A) weighting filter described above is used widely in the U.S., but underestimates the impact of frequencies around 6000 Hz and at very low frequencies. The newer ITU-R 468 <b>noise</b> <b>weighting</b> filter is used more widely in Europe. The propagation of sound varies between environments; for example, low frequencies typically carry over longer distances. Therefore, different filters, such as dB(B) and dB(C), may be recommended for specific situations.|$|R
50|$|ITU-R 468 <b>noise</b> <b>weighting</b> was {{therefore}} developed to more accurately reflect the subjective loudness {{of all types}} of noise, as opposed to tones. This curve, which came out of work done by the BBC Research Department, and was standardised by the CCIR and later adopted by many other standards bodies (IEC, BSI/) and, , is maintained by the ITU. Noise measurements using this weighting typically also use a quasi-peak detector law rather than slow averaging. This also helps to quantify the audibility of bursty noise, ticks and pops that might go undetected with a slow rms measurement.|$|R
40|$|This paper investigates fault {{tolerance}} in feedforward neural networks, for a realistic fault model based on analog hardware. In our previous work with synaptic <b>weight</b> <b>noise</b> [26] we showed significant {{fault tolerance}} enhancement over standard training algorithms. We proposed that when introduced into training, <b>weight</b> <b>noise</b> distributes the network computationmore evenly across the weights and thus enhances fault tolerance. Here we compare those results with an approximation to the mechanisms induced by stochastic <b>weight</b> <b>noise,</b> incorporated into training deterministicallyvia penalty terms. The penalty terms are an approximation to weight saliency and therefore, in addition, we assess {{a number of}} other weight saliency measures and perform comparison experiments. The results show that the first term approximation is an incomplete model of <b>weight</b> <b>noise</b> in terms of fault tolerance. Also the error hessian is shown to be the most accurate measure of weight saliency. 1 Introduction The presenc [...] ...|$|R
