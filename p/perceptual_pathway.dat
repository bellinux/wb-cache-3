13|13|Public
40|$|Dijkerman & de Haan (D&dH) {{propose a}} {{somatosensory}} <b>perceptual</b> <b>pathway</b> that informs a consciously accessible body image, and an action pathway that provides {{information to a}} body schema, which is not consciously accessible. We argue that the body schema may become accessible to consciousness in some circumstances, possibly resulting from cross talk, but {{that this may be}} detrimental to skilled movement production. © 2007 Cambridge University Press. link_to_subscribed_fulltex...|$|E
40|$|Abstract. We {{will present}} a Bayesian {{hierarchical}} framework for multimodal active perception, devised to be emergent, scalable and adaptive, together with some representative experimental results. This framework, while not strictly neuromimetic, finds {{its roots in the}} role of the dorsal <b>perceptual</b> <b>pathway</b> of the human brain. Its composing models build upon a common spatial configuration that is naturally fitting for the integration of readings from multiple sensors using a Bayesian approach devised in previous work...|$|E
40|$|In this text, {{we use a}} Bayesian {{framework}} for active multimodal perception of 3 D structure and motion — which, while not strictly neuromimetic, finds {{its roots in the}} role of the dorsal <b>perceptual</b> <b>pathway</b> of the human brain — to implement a strategy of active exploration based on entropy. The computational models described in this text support a robotic implementation of multimodal active perception to be used in real-world applications, such as human-machine interaction or mobile robot navigation...|$|E
40|$|In many neural systems, {{information}} about stimulus variables is often represented in a distributed manner {{by means of}} a population code. It is generally assumed that the responses of the neural population are tuned to the stimulus statistics, and most prior work has investigated the optimal tuning characteristics of one or a small number of stimulus variables. In this work, we investigate the optimal tuning for diffeomorphic representations of high-dimensional stimuli. We analytically derive the solution that minimizes the L 2 reconstruction loss. We compared our solution with other well-known criteria such as maximal mutual information. Our solution suggests that the optimal weights do not necessarily decorrelate the inputs, and the optimal nonlinearity differs from the conventional equalization solution. Results illustrating these optimal representations are shown for some input distributions that may be relevant for understanding the coding of <b>perceptual</b> <b>pathways.</b> ...|$|R
40|$|The {{perception}} of luminosity {{is thought to}} depend upon {{the intensity of the}} stimulus: a surface begins to appear self-luminous when it emits or reflects a certain amount of light. This is known as the luminosity threshold. It is a common opinion among vision scientists that such a threshold is correlated to the intensity of a perceptually white surface, in the sense that only an area of the visual field with luminance higher than perceived surface-white will appear lumi- nous. Here we show grey colours that appear luminous in virtue of surrounding luminance ramps. These ramps are intended to mimic halos seen around light sources in natural environments. The results of three experiments indicate that the phenomenon is in direct contradiction to the aforementioned assumptions and suggest the existence of separate <b>perceptual</b> <b>pathways</b> for self-luminosity perception and for surface-colour perception...|$|R
40|$|This study {{examined}} the effect of stimulus movement on localization probability and latency during attention and inattention. Forty infants, 10 each at 8, 14, 20, and 26 weeks of age were presented with a central stimulus. Then, a peripheral stimulus was presented (static or dynamic checkerboard). Stim-ulus movement did not affect localization probability. Infants localized the dynamic peripheral stimu-lus more quickly than the static peripheral stimulus {{when there was no}} focal stimulus. Focal stimulus attention attenuated this difference in localization latency between static and dynamic stimuli. Signal detection analysis showed that sensitivity to the peripheral stimulus increased over this age range along with a decrease in the bias against responding. The effects of attention were on response bias rather than stimulus sensitivity. These results imply attention affected the localization response to the peripheral stimulus but did not affect the sensitivity of the sensory and <b>perceptual</b> <b>pathways</b> to periph-eral stimuli. peripheral stimulus movement signal detection analysis peripheral stimulus localization attention heart rate electrooculogram infant...|$|R
40|$|In {{a series}} of studies we have been {{investigating}} how multisensory training affects unisensory perceptual learning with speech stimuli. Previously, we reported that Aaudiovisual training with speech stimuli can promote auditory-only perceptual learning in normal-hearing adults but can impede learning in congenitally deaf adults with late-acquired cochlear implants. Here, impeder and promoter effects were sought in normal-hearing adults who participated in lipreading training. In Experiment 1, visual-only (VO) training on paired associations between CVCVC nonsense word videos and nonsense pictures demonstrated that VO words could be learned to a high level of accuracy even by poor lipreaders. In Experiment 2, visual-auditory (VA) training in the same paradigm but with the addition of synchronous vocoded acoustic speech impeded VO learning of the stimuli in the paired-associates paradigm. In Experiment 3, the vocoded auditory-only (AO) stimuli were shown to be less informative than the VO speech. Experiment 4 combined vibrotactile speech stimuli with the visual stimuli during training. Vibrotactile stimuli were shown to promote visual perceptual learning in participants whose training scores were similar. In Experiment 5, no-training controls were used to show that training with visual speech carried over to consonant identification of untrained CVCVC stimuli but not to lipreading words in sentences. Across this and previous studies, multisensory training effects depended on the functional relationship between pathways engaged during training. Two principles are proposed to account for stimulus effects: (1) Stimuli presented to the trainee’s primary <b>perceptual</b> <b>pathway</b> will impede learning by a lower-rank pathway. (2) Stimuli presented to the trainee’s lower rank <b>perceptual</b> <b>pathway</b> will promote learning by a higher-rank pathway. The mechanisms supporting these principles are discussed in light of multisensory reverse hierarchy theory...|$|E
40|$|Multimodal active perception, {{hierarchical}} Bayes models, bioinspired robotics, Human-Robot Interaction In this article, {{we present}} a hierarchical Bayesian framework for multimodal active perception, devised to be emergent, scalable and adaptive. This framework, while not strictly neuromimetic, finds {{its roots in the}} role of the dorsal <b>perceptual</b> <b>pathway</b> of the human brain. Its composing models build upon a common spatial configuration that is naturally fitting for the integration of readings from multiple sensors using a Bayesian approach devised in previous work. The framework presented in this article is shown to adequately model human-like active perception behaviours, namely by exhibiting the following desirable properties: high-level behaviour results from low-level interaction of simpler building blocks; seamless integration of additional inputs is allowed by the Bayesian Programming formalism; initial "genetic imprint " of distribution parameters may be changed "on the fly " through parameter manipulation, thus allowing for the implementation of goal-dependent behaviours (i. e. top-down influences). Note: The following files were submitted by the author for peer review, but cannot be converted to PDF. You must view these files (e. g. movies) online. AdaptiveBehavior 2011. tex ActivePerception. te...|$|E
40|$|International audienceIn this text, {{we present}} a Bayesian {{framework}} for active multimodal perception of 3 D structure and motion. The design of this framework finds its inspiration {{in the role of}} the dorsal <b>perceptual</b> <b>pathway</b> of the human brain. Its composing models build upon a common egocentric spatial configuration that is naturally fitting for the integration of readings from multiple sensors using a Bayesian approach. In the process, we will contribute with efficient and robust probabilistic solutions for cyclopean geometry-based stereovision and auditory perception based only on binaural cues, modelled using a consistent formalisation that allows their hierarchical use as building blocks for the multimodal sensor fusion framework. We will explicitly or implicitly address the most important challenges of sensor fusion using this framework, for vision, audition and vestibular sensing. Moreover, interaction and navigation requires maximal awareness of spatial surroundings, which in turn is obtained through active attentional and behavioural exploration of the environment. The computational models described in this text will support the construction of a simultaneously flexible and powerful robotic implementation of multimodal active perception to be used in real-world applications, such as human-machine interaction or mobile robot navigation...|$|E
50|$|Sympathy is a {{stepping}} stone in both social and moral development. It generally arises between 2-3 years old, although some instances of empathic emotion {{can be seen as}} early as 18 months. Basic sharing of emotions, a precursor for sympathy, can be seen in infants. For example, babies will often begin to cry when they hear another baby crying nearby. This emphasizes the infant's ability to recognize emotional cues in his or her environment, even if not able to fully comprehend the emotion. Another milestone in child rearing is the development of the ability to mimic facial expressions. Both of these processes act on sensory and <b>perceptual</b> <b>pathways,</b> yet executive functioning for empathic emotions does not begin during these early stages. Decety and Michalska (2010) believe that early affective development and later development of executive functions create a disparity between how children and young adults experience another person's pain. Young children tend to be negatively aroused more often in comparison to the older subjects.|$|R
30|$|The current {{findings}} {{demonstrate that}} running with LMMF and mild EIMD caused medium-sized physiological and large-sized perceptual effects that were associated with discrete and poignant onset of unintended alteration in performance fatigability and observed pacing behaviour, thereby closely resembling defining {{characteristics of the}} ‘hitting the wall’ phenomenon [77, 78]. It is further suggested {{that much of the}} variance in response to running with LMMF and mild EIMD {{can be explained by the}} dynamic and complex interactions between the investigated psychophysiological determinants of pacing behaviour and performance during prolonged endurance exercise. Both physiological and <b>perceptual</b> <b>pathways</b> are proposed to impact performance fatigability during running with LMMF and mild EIMD via (1) amplified physiological strain and non-adaptive endocrinological distress response and (2) increase in perceived fatigability. Specifically with regards to the latter, it is hypothesised that an increase in perceived physical strain antecedes a decrease in valence, which in turn antecedes an increase in action crisis, eventually dissolving the initially aspired goal. The applied three-dimensional framework of perceived fatigability therefore provides a more comprehensive understaning of strain-perception-thinking-action coupling in centrally regulated and goal-directed exercise behvaiour than the traditional Gestalt concept of perceived exertion [79].|$|R
40|$|Wellbeing and {{sustainability}} are often presented as separate issues. At best, sustainable practises {{might have some}} beneficial side-effects on wellbeing (e. g., less air pollution means less respiratory ailments); at worst, the two are presented as mutually exclusive (i. e., sustainability necessarily means a lower standard of living). But I think the argument {{can be made for}} an opposite view: that if we focus on being well, we will find that sustainability emerges from that state. While there is still debate over definitions of wellbeing, it can be generally seen as a state in which our basic, universal needs are met (objective wellbeing), where we experience a predominance of positive mood in our lives (subjective or hedonic wellbeing) and, perhaps most important of the three aspects, where we feel autonomously purposeful, part of something greater that offers meaning to our lives (eudaimonic wellbeing). Drawing on ecopsychological research and theory – including the author's own experimental studies linking personal and environmental health via <b>perceptual</b> <b>pathways</b> – this paper shows how a garden designed to promote these three aspects of wellbeing (a “restorative environment”) would also be a microcosm model for sustainable practise...|$|R
40|$|The {{rapid and}} {{efficient}} selection of emotionally salient or goal-relevant stimuli {{in the environment}} is crucial for flexible and adaptive behaviors. Converging data from neuroscience and psychology have accrued {{during the last decade}} to identify brain systems involved in emotion processing, selective attention, and their interaction, which together act to extract the emotional or motivational value of sensory events and respond appropriately. An important hub in these systems is the amygdala, which may not only monitor the emotional value of stimuli, but also readily project to several other areas and send feedback to sensory pathways (including striate and extrastriate visual cortex). This system generates saliency signals that modulate perceptual, motor, as well as memory processes, and thus in turn regulate behavior appropriately. Here, we review our current views on the function and properties of these brain systems, with an emphasis on their involvement in the rapid and/or preferential processing of threat-relevant stimuli. We suggest that emotion signals may enhance processing efficiency and competitive strength of emotionally significant events through gain control mechanisms similar to those of other (e. g. endogenous) attentional systems, but mediated by distinct neural mechanisms in amygdala and interconnected prefrontal areas. Alterations in these brain mechanisms might be associated with psychopathological conditions, such as anxiety or phobia. We conclude that attention selection and awareness are determined by multiple attention gain control systems that may operate in parallel and use different sensory cues but act on a common <b>perceptual</b> <b>pathway...</b>|$|E
40|$|Vestibular {{velocity}} storage {{enhances the}} efficacy of the angular vestibulo-ocular reflex (VOR) during relatively low-frequency head rotations. This function is modulated by GABA-mediated inhibitory cerebellar projections. Velocity storage also exists in <b>perceptual</b> <b>pathway</b> and has similar functional principles as VOR. However, it is not known whether the neural substrate for perception and VOR overlap. We propose two possibilities. First, there is the same velocity storage for both VOR and perception; second, there are nonoverlapping neural networks: one might be involved in perception and the other for the VOR. We investigated these possibilities by measuring VOR and perceptual responses in healthy human subjects during whole-body, constant-velocity rotation steps about all three dimensions (yaw, pitch, and roll) before and after 10  mg of 4 -aminopyridine (4 -AP). 4 -AP, a selective blocker of inward rectifier potassium conductance, can lead to increased synchronization and precision of Purkinje neuron discharge and possibly enhance the GABAergic action. Hence 4 -AP could reduce the decay time constant of the perceived angular velocity and VOR. We found that 4 -AP reduced the decay time constant, but the amount of reduction in the two processes, perception and VOR, was not the same, suggesting the possibility of nonoverlapping or partially overlapping neural substrates for VOR and perception. We also noted that, unlike the VOR, the perceived angular velocity gradually built up and plateau prior to decay. Hence, the perception pathway may have additional mechanism that changes the dynamics of perceived angular velocity beyond the velocity storage. 4 -AP had no effects on the duration of build-up of perceived angular velocity, suggesting that the higher order processing of perception, beyond the velocity storage, might not occur under the influence of mechanism that could be influenced by 4 -AP...|$|E
40|$|Humans use various sensory cues {{to extract}} crucial {{information}} from the environment. With a view of having robots as human companions, we are motivated towards helping to develop a knowledge representation system {{along the lines of}} what we know about us. While recent research has shown interesting results, we are still far from having concepts and algorithms that interpret space, coping with the complexity of the environment. By understanding how animals (humans) navigate and build their own spatial representation, the observed phenomena can be applied in robotics. In order to have a robust and reliable framework for navigation (i. e. in order to move within an environment, manipulate objects in it, avoid undesirable mishaps | e. g. collisions | etc.) space representation, localisation, mapping and perception are all needed. The goal of this work was to research Bayesian models to deal with fusion, multimodality, con icts, and ambiguities in perception, while simultaneously drawing inspiration upon human perceptual processes and respective behaviours. We will present a Bayesian framework for active multimodal perception of 3 D structure and motion which, while not strictly neuromimetic, nds its roots {{in the role of the}} dorsal <b>perceptual</b> <b>pathway</b> of the human brain. Its composing models build upon a common egocentric spatial con guration that is naturally tting for the integration of readings from multiple sensors using a Bayesian approach. At its most basic level, these models present efficient and robust probabilistic solutions for cyclopean geometry-based stereovision and auditory perception based only on binaural cues, de ned using a consistent formalisation that allows their use as building blocks for the multimodal sensor fusion framework, both explicitly or implicitly addressing the most important challenges of sensor fusion, for vision, audition and proprioception (including vestibular sensing). Parallely, baseline research on human multimodal motion perception presented in this text provides the support for future work in new sensor models for the framework. This framework is then extended in a hierarchical fashion by incrementally implementing active perception strategies, such as active exploration based on entropy of the perceptual map that constitutes the basis of the framework and sensory saliency-based behaviours. The computational models described herewith support a real-time robotic implementation of multimodal active perception to be used in real-world applications, such as human-machine interaction or mobile robot navigation. With this work, we also hope to be able to address questions such as: Where are the limits on optimal sensory integration behaviour? What are the temporal aspects of sensory integration? How do we solve the problem" for sensory integration? How to answer the combination versus integration debate? How to answer the switching versus weighing controversy? What are the limits of crossmodal plasticity?Tese de doutoramento em Engenharia Electrotécnica, na especialidade de Instrumentação e Controlo, apresentada à Faculdade de Ciências e Tecnologia da Universidade de Coimbr...|$|E
40|$|Research in {{artificial}} intelligence and autonomous agents envisions that future robots will accompany humans {{in their daily}} lives. The aim is to provide support not only for routine, challenging, or dangerous tasks, but also to improve quality of life through personal assistance and coaching. In order to allow artificial agents to communicate sensibly {{and to participate in}} human society, it is important to equip them with the ability to perceive and appreciate aesthetic features of design in a humanlike manner. The present study investigates how methods from anthropocentric biocybernetic computing (ABC) can be assembled in an intelligent control module for architectural design evaluation. Central to the system is an abstract model of aesthetic experience, which is established through statistical learning. For the experiments, a database of images of house façades is employed. The learning algorithm extracts line distributions, which characterise façade design, and represents them abstractly {{in the form of a}} non-linear manifold. Each point on the manifold corresponds to one façade. The proposed module includes two additional affective <b>perceptual</b> <b>pathways,</b> which are implemented using paradigms that are believed to reflect responses of the human emotional system. One paradigm involves concepts of facial expression recognition, and the other is based on calculating the fractal dimension of the skyline of cityscapes. Future applicability of the proposed system for design evaluation will rely on suitable data preparation and calibration of the associated algorithms using test subjects. The article describes characteristic details of the system’s architecture and discusses whether it would be able to acquire the level of sophistication required to provide aesthetic judgment that is convincing for humans...|$|R
40|$|Many {{studies have}} shown that {{individuals}} with anxiety have a bias towards attending to and processing objects that are threatening in nature when compared to individuals with low levels of anxiety. Fewer studies, however, have assessed the presence of biases in visual processing during various stages of visual sensory encoding. To this end, the current study investigated the effects of state and trait anxiety on preconscious selective attention towards threat, by employing attentional blink (AB) and object-substitution masking (OSM) paradigms, in which participants viewed neutral or angry face targets. A second area that has received little attention is how threat processing occurs in anxious children compared to their adult counterparts. To investigate this issue, we tested both adult (Study 1) and child (Study 2) participants. Study 1 involved one hundred 1 st year psychology students who completed a self report scale (STAI) yielding scores of Trait and State anxiety. Study 2 involved seventy-four children aged between 7 - 12 years who completed the STAI-C. Results indicated that adults with High State Anxiety displayed a reduced attentional blink (AB) which was not affected by target type. However, a reliable AB was not found for children in the current study, a finding that was most likely impacted by the task difficulty and age group used, rather than by anxiety per se. Results from the OSM task indicated that adults and children, irrespective of anxiety level, were generally more vigilant for threat than neutral faces. Moreover, in the adult sample, increased State and Trait Anxiety was linked with more masking overall. By contrast, in the child sample, there was no effect of anxiety on OSM. These findings suggest that adults engage in early level suppression of threatening information while children do not, perhaps broadly indicating that anxiety may shape perception, rather than visual <b>perceptual</b> <b>pathways</b> shaping anxiety development...|$|R
40|$|Effective perceptual {{decisions}} {{rely upon}} combining sensory information {{with knowledge of}} the rewards available for different choices. However, it is not known where reward signals interact with the multiple stages of the <b>perceptual</b> decision-making <b>pathway</b> and by what mechanisms this may occur. We combined electrical microstimulation of functionally specific groups of neurons in visual area V 5 /MT with performance-contingent reward manipulation, while monkeys performed a visual discrimination task. Microstimulation was less effective in shifting perceptual choices towards the stimulus preferences of the stimulated neurons when available reward was larger. Psychophysical control experiments showed this result was not explained by a selective change in response strategy on microstimulated trials. A bounded accumulation decision model, applied to analyse behavioural performance, revealed that the interaction of expected reward with microstimulation can be explained if expected reward modulates a sensory representation stage of perceptual decision-making, in addition to the better-known effects at the integration stage...|$|R
40|$|We {{perceive}} the three-dimensional (3 D) environment that surrounds us with deceptive effortlessness. In fact, we {{are far from}} comprehending how the visual system provides us with this stable perception of the (3 D) world around us. This thesis {{will focus on the}} interplay between visual perception of depth and its closely related action system, eye movements in depth. The human visual system is comprised of a sensory (input) and an output (motor) system. Processed information from the sensory system can result in two explicit measurable response types: conscious visual perception and ocular motor behavior. It is still a matter of debate whether conscious visual perception and action (including hand- and arm-movements) use the same information or whether the visual system has separate channels processing information for perception and action. In this thesis, we study (1) if separate channels, one for eye movements and one for conscious visual perception, indeed exist, and (2) if so, if there is a direct input from the <b>perceptual</b> <b>pathway</b> to the motor pathway. Assuming that either eye movements and conscious visual perception are based on information from a common source (a negative answer to issue 1) or perception can directly influence, or guide, eye movements (an affirmative answer to research question 2), (eye) movements reflect our conscious visual perception. If so, eye movements could provide us with an alternative method to probe our conscious visual perception, making explicit perceptual reports superfluous. In this thesis we focus on depth perception and the two types of eye movements that are closest related to depth perception, namely vergence (an eye movement that gets a certain depth plane into focus) and saccades (a rapid eye movement to change gaze direction). Over the last 20 years {{it has been shown that}} depth perception is based on a weighted combination of depth cues available such as linear perspective, occlusion and binocular disparity. How eye movements are planned, however, is still unclear. Several studies have reported that eye movements are, to varying degrees, correlated with perception and thus concluded that perception guides eye movements. However, in most of these studies depth perception was correlated to the depth cues and a clear distinction between cues and perception could not be made. A way to make a dissociation between cues and perception, is to make use of depth reversal illusions: stimuli that can induce multiple equally likely depth interpretations while the stimulus cues remain the same. That means that perception can alternate, while cues remain constant leading to a dissociation between perception and cues. In several different studies we show that in the case of vergence, eye movements are planned based on depth cues (mainly disparity) and are uncorrelated to perception. In the case of saccades, we show that the direction of saccades is highly correlated to perception, but seems to be subserved by a separate system combining cues using very similar weights as for perception...|$|E
40|$|Housing {{interior}} walls are decorated {{and finished with}} various decorative materials of paints of varying properties ranging from texture to coloration. In choosing the preferred finishing and decorative materials, housing owners, users and prospective owners have attendant underlying factors and reasons for their choices. These choice activities usually provoke and invoke certain perceptual orientations that underlie the choices. These perceptual orientations are normally very complex and can only be disentangled by elicitation. This paper presents perceptual orientations of prospective house owners‟ choice and preference for {{interior walls}} finishes in Yola, Nigeria. The study was conducted within the theoretical and conceptual framework of means-end chain (MEC) model. 15 prospective house owners were interviewed using the laddering interviewing technique after a structured questionnaire survey was carried out. The results showed that twelve (12) identified unique <b>perceptual</b> orientation <b>pathways</b> were established, motivated by four (4) user values, and intervened by four (4) expected functional affordances. The findings disentangled the design expectations of housing users/owners for finishing their housing interiors which can be pointers for designers and Architects for their design processes and decisions...|$|R
40|$|Our {{experience}} {{the world is}} dependent on both the surroundings and the brain. In other words, perception is a synthesis of incoming signals, internal state, and previous knowledge rather than a mere reflection of the environment. Prior knowledge can be engendered from cues in the present context, from previous experiences, or in a wider sense by evolutionary processes effected {{in the organization of}} the brain. Knowing {{what is going to happen}} modulates the extent to which aversiveness induces stress and anxiety. Predictability is also of importance since it may improve the accuracy and speed of sensory processing as well as behavioral responses. As for evolutionary relevant threats, a perceptual and behavioral system has been organized around a fear module generating instant responses even outside of awareness. Accordingly, brain regions with altered activities and functions complement each other in constituting a system that allows for perceptions, reactions and behavioral planning at different time scales. In this thesis, we investigate the influence of prediction on perception of somatosensory and aversive events and the differential neural processing of phobic and fear-relevant stimuli, as measured by functional magnetic imaging (fMRI) and positron emission tomography (PET). The network of activation and deactivation during anticipation of an expected somatosensory stimulus was found to be similar to that engaged during the actual sensory stimulation. These overlapping patterns of change furthers the idea that predictions are subserved by a neuronal network similar to that which subserves the processing of the actual sensory input. It also infers that anticipation may invoke a tonic top-down modulation of neural activity and in this way favor selective processing of relevant information. Correspondingly, predictive cues of painful stimuli that allowed for correct temporal estimation enhanced activity in relevant sensorydiscriminative processing areas. Absence of cues predicting painful stimuli augmented the negative experience as well as neuronal activity in areas associated with the affective component of pain processing, such as the anterior insula, the caudal anterior cingulate cortex, and the orbitofrontal cortex. This context also prompted increased activity in the posterior parietal cortex and lateral prefrontal cortex that we attribute to enhanced alertness and sustained attention during unpredictability. An affective cortical network along with the amygdala and the periaqueductal gray was also active in response to phobic relative to fear relevant (but nonfeared) stimuli. However, with non-conscious stimulus presentation only the amygdala was activated both to the phobic and fear relevant stimuli. With time to decide that the fear relevant stimuli in effect were not dangerous the dorsolateral prefrontal cortex was engaged, a region included in a system that has been identified in strategic selection of behavior and in inhibiting environmentally cued responses. These results thus reflect fast <b>perceptual</b> <b>pathways</b> favoring rapid responses to threat, top-down direction of attention contributing to enhancement of relevant information processing along with attenuation of anxiety and finally, activity in regions mediating goal-directed perception and behavior...|$|R
40|$|This {{doctoral}} thesis examines the conceptions of interpersonal relationships {{in a major}} UK sporting organization's electronic community (MUSO). Focusing on one text-based bulletin board, the research explores the meanings a sample of 25 heavy users (insiders) attribute to their interactions with fellow members. Adopting an interpretivist / social constructionist perspective and a virtual ethnographic research strategy this research draws from George Kelly's Personal Construct Theory and Means-End-Chain analysis to explore these meanings as expressed in attributes of interactions, consequences and personal values. The research is split into two main sections, community and sample selection, and the main study. Working {{with one of the}} UK's leading moderating organizations, construct elicitation techniques revealed the means by which a sample of electronic communities could be differentiated on the basis of relational activity. Hinde's (1979) model of describing relationships together with a number of practical and ethical considerations were used as a means of identifying a suitable electronic community for the main study. Using a three stage electronic Delphi process, Moderators with experience in managing MUSO were canvassed for their opinions on heavy users (insiders). The main study comprises two approaches. The first involves a wider community interview drawing responses from over 500 members and identifying seven key themes of electronic community use. These are; conflict within the community, debates, entertainment, friendship, interaction, sharing and support. The second involves a number of in-depth electronic interviews exploring the conceptions of meanings of interpersonal relationships amongst insiders. Using a web based construct elicitation software package (WebGridIII) over 400 constructs from 25 participants on relational activity are identified. These are then explored using laddering and pyramiding techniques over instant messenger and email, revealing central attributes, consequences and personal values associated with their use of electronic community. The study identifies over 600 ladders comprising 1800 data points which are used to create hierarchical value maps for electronic community use across the seven key themes previously identified. The thesis makes several contributions to knowledge. To theory, it demonstrates the application of the means-end chain model to interpersonal relationships in electronic environments. It identifies the core values underpinning electronic community use of heavy users and the dominant <b>perceptual</b> <b>pathways</b> connecting the attributes of community use with personal values across the seven key themes. A contribution is further made in the categorization and selection process of electronic communities on the basis of relational activity, practical and ethical considerations. To methodology, the thesis explores the process of conducting virtual ethnography and presents a first hand day by day reflexive account of its activities and experience. The thesis also demonstrates the richness and abundance of data that can be collected using electronic research methods alone. Further contributions are made in the field of ethics identifying the means of safeguarding the integrity of the research process and the safety of participants. Finally practical managerial contributions are made in identifying the role and importance of interpersonal relationships in electronic community in the perceptions of its heavy users...|$|R
40|$|AbstractSo far, {{it remains}} largely {{unresolved}} {{to what extent}} neuronal noise affects behavioral responses. Here, we investigate, where in the human visual motion pathway noise originates that limits {{the performance of the}} entire system. In particular, we ask whether perception and eye movements are limited by a common noise source, or whether processing stages after the separation into different streams limit their performance. We use the ocular following response of human subjects and a simultaneously performed psychophysical paradigm to directly compare perceptual and oculomotor system with respect to their speed discrimination ability. Our results show that on the open-loop condition the perceptual system is superior to the oculomotor system and that the responses of both systems are not correlated. Two alternative conclusions can be drawn from these findings. Either the <b>perceptual</b> and oculomotor <b>pathway</b> are effectively separate, or the amount of post-sensory (motor) noise is not negligible in comparison to the amount of sensory noise. In view of well-established experimental findings and due to plausibility considerations, we favor the latter conclusion...|$|R

