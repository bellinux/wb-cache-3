0|10000|Public
5000|$|... or <b>by</b> <b>bisection,</b> {{leading to}} (among others) the Vincent-Collins-Akritas (VCA) bisection method.|$|R
40|$|Semi-infinite {{programs}} will be solved <b>by</b> <b>bisections</b> {{within the framework of}} LPs. No gradient information is needed, contrary to the usual Newton-Raphson type methods for solving semi-infinite programs. The rate of convergence is linear. The method has a stable convergence feature derived from the bisection rule...|$|R
40|$|Abstract. A simple {{criterion}} {{that allows}} the efficient local coarsening of triangulations created <b>by</b> <b>bisections</b> is devised and analyzed. Under a mild condition on the initial triangulation the proposed criterion allows to gradually reverse the entire refinement without employing its history explicitly. Numerical experiments underline {{the efficiency of the}} resulting algorithm. 1...|$|R
30|$|Similar to the {{solution}} of (40), (43) is solved <b>by</b> the <b>bisection</b> search procedure.|$|R
5000|$|... {{which can}} be, for example, {{computed}} <b>by</b> the <b>bisection</b> method. The corresponding eigenvectors are equal to ...|$|R
40|$|Semi-infinite {{programs}} {{as related to}} DEA with infinitely many DMUs will be solved <b>by</b> <b>bisections</b> {{within the framework of}} LPs. No gradient Information Is needed, contrary to the usual Newton-Raphson type methods for solving semi-Infinite programs. The rate of convergence is linear. The method has a stable convergency feature derived from the bisection rule. Reprinted from Research Report CCS 561, Center for Cybernetic Studies, The University of Texas, at Austin...|$|R
3000|$|... can {{be found}} <b>by</b> using <b>bisection</b> algorithm, which can {{decrease}} the complexity to find the solution of problem (25).|$|R
40|$|A {{comparative}} study of three enucleation methods; enucleation by pushing out small amount of cytoplasm beneath the first polar body, enucleation <b>by</b> <b>bisectioning</b> of oocytes, and enucleation by aspiration were carried out using the oocytes of Indian buffaloes. The statistical analysis of the results revealed that, {{there is no significant}} difference between the three enucleation methods. This information would be helpful for optimization of enucleation of recipient oocyte during somatic cell nuclear transfer...|$|R
2500|$|All the arithmetical {{expressions}} and formulas {{make sense for}} hyperreals and hold true if they are true for the ordinary reals. It turns out that any finite (that is, such that [...] for some ordinary real [...] ) hyperreal [...] will be of the form [...] where [...] is an ordinary (called standard) real and [...] is an infinitesimal. It can be proven <b>by</b> <b>bisection</b> method used in proving the Bolzano-Weierstrass theorem, the property (1) of ultrafilters {{turns out to be}} crucial.|$|R
40|$|This paper {{describes}} a program, called NEW TON, that finds approximate symbolic solutions to parameterized equations in one variable. NEWTON derives an initial approximation by solving for the dominant {{term in the}} equation, or if this fails, <b>by</b> <b>bisection.</b> It refines this approximation by a symbolic version of Newton's method. It tests whether the first Newton iterate lies closer to the solution than does the initial solution. If so, it returns this iterate; otherwise, it chooses a new initial solution and tries again. ...|$|R
3000|$|... {{can be done}} <b>by</b> {{applying}} <b>bisection</b> {{method to}} (7), after setting ε D[*]=[*]ε th, Γ SR[*]=[*]Γ th,R, w SD h SD[*]=[*]σ 2 Γ i,SD, [...]...|$|R
3000|$|..., can be {{calculated}} <b>by</b> applying <b>bisection</b> method to (7) as in the TCR scheme. Good TR,NC values under different channel settings will be obtained via simulations.|$|R
30|$|For the {{adaptive}} division and bisection the computational time of solving examples with larger N ranging from 600 to 1500 {{are listed in}} Table  2. We can see that even if it takes about seventeen minutes to solve problem (P) of size (n,N)=(3, 1500), {{the adaptive}} division takes less time required <b>by</b> <b>bisection</b> for each N, which confirms the feasibility and availability of the proposed algorithm. We can draw a conclusion that the algorithm has more than enough performance, at least for three dimensions.|$|R
40|$|AbstractA front {{tracking}} finite difference {{method is}} developed for a two phase one dimensional classical Stefan problem. The method, to start with, requires two time step sizes needed for the front to move a fixed spatial distance each. Two equations are derived applying Green's theorem of vector calculus for two regions {{of the problem and}} solved <b>by</b> <b>bisection</b> method to obtain these time steps. Subsequent steps are obtained, one by one, <b>by</b> applying <b>bisection</b> method to the discrete form of the Stefan condition. This front tracking method is much simpler and natural than the methods based on enthalpy formulation and can take care of source or sink terms on the front. Enthalpy formalism overlooks the Stefan condition which is a vital ingredient in the development of our method, Problem of freezing of a slab as well as freezing of a spherical droplet is presented as examples...|$|R
40|$|In a {{preceding}} paper Jacobsen [Jacobsen, S. 1971. On marginal allocation {{in single}} constraint min-max problems. Management Sci. (July). ] shows that marginal allocation solves {{a class of}} discrete, single constraint, min-max allocation problems. A dual approach, to this problem is presented, based on a generalization of Jacobsen's P condition, which should prove more efficient when many marginal improvement iterations would be required. A variant of sequential search <b>by</b> <b>bisection</b> is applied, possibly augmented by an accelerated marginal allocation scheme, in which finite convergence to an optimum solution is guaranteed. ...|$|R
50|$|The second prs is {{obtained}} {{by applying the}} modified Euclidean algorithm. The modification consists in negating at each iteration of the Euclidean algorithm the polynomial remainder and using the negated polynomial in the next iteration. The modified Euclidean algorithm is of great importance because, when applied to , where , the derivative of , we obtain Sturm's theorem and the Sturm sequence of , {{which can be used}} to isolate <b>by</b> <b>bisection</b> its real roots. To agree with the spirit of the Pell-Gordon article, the polynomial remainder sequence obtained this way is called modified Euclidean prs.|$|R
40|$|This paper {{proves the}} {{approximate}} intermediate value theorem, constructively and from notably weak hypotheses: from pointwise rather than uniform continuity, without assuming that reals {{are presented with}} rational approximants, and without using countable choice. The theorem {{is that if a}} pointwise continuous function has both a negative and a positive value, then it has values arbitrarily close to 0. The proof builds on the usual classical proof <b>by</b> <b>bisection,</b> which repeatedly selects the left or right half of an interval; the algorithm here selects an interval of half the size in a continuous way, interpolating between those two possibilities...|$|R
25|$|The method converges on all zeros in the {{starting}} region. Division by zero can lead to separation of distinct zeros, though the separation may not be complete; it can be complemented <b>by</b> the <b>bisection</b> method.|$|R
30|$|The joint {{optimization}} problem is non-convex. To solve this issue, the primal {{optimization problem}} is first decomposed into two subproblems, and then, we solve the two subproblems alternatively. For the first subproblem, we prove it is convex and then solve it <b>by</b> the <b>bisection</b> method. For the second subproblem, we decomposed it into two sub-subproblems again, and then, we solve the two sub-subproblems alternatively. For the first sub-subproblem, we {{transform it into}} concave function by using the nonlinear fractional programming, which can be effectively solved by the Dinkelbach method [22]. For the second sub-subproblem, we first prove it is convex and then solve it <b>by</b> the <b>bisection</b> method.|$|R
40|$|AbstractWe {{explain why}} information-based {{complexity}} uses the real number model. Results {{in the real}} number model are {{essentially the same as}} in floating point arithmetic with fixed precision modulo two important assumptions, namely • we use only stable algorithms, • the approximation error is not too small, compared to the product of the condition number, the roundoff unit of floating point arithmetic, and the accumulation constant of a stable algorithm. We illustrate this by an example of solving nonlinear equations <b>by</b> <b>bisection.</b> We also indicate the possible tradeoffs between complexity and stability, and the need of using multiple or varying precision for ill-conditioned problems...|$|R
40|$|The {{nonlinear}} {{stability of}} laminar sinuously bent streaks is studied for the plane Couette ﬂow at Re= 500 in a nearly minimal box {{and for the}} Blasius boundary layer at Re_d*= 700. The initial perturbations are nonlinearly saturated streamwise streaks of amplitude AU perturbed with sinuous perturbations of amplitude AW. The local boundary of the basin of attraction of the linearly stable laminar ﬂow is computed <b>by</b> <b>bisection</b> and projected in the AU – AW plane providing a well deﬁned critical curve. Different streak transition scenarios are seen to correspond to {{different regions of the}} critical curve. The modal instability of the streaks is responsible for transition for AU 25...|$|R
5000|$|... and {{the second}} one is given <b>by</b> the <b>bisection</b> methodIf {{the result of the}} secant method, s, lies {{strictly}} between bk and m, then it becomes the next iterate (bk+1 = s), otherwise the midpoint is used (bk+1 = m).|$|R
50|$|The only {{evidence}} {{that seemed to}} support the Lamarckian hypothesis were the experiments of Charles Brown-Séquard, who produced epilepsy in guinea-pigs <b>by</b> <b>bisection</b> of the large nerves or spinal cord, which led him to believe that, in rare instances, the artificially-produced epilepsy and mutilation of the nerves was transmitted. The record of Brown-Séquard's original experiments was unsatisfactory, and attempts reproduce them were unsuccessful. Conversely, the vast number of experiments in the cropping of the tails and ears of domestic animals, {{as well as of}} similar operations on man, had negative results. Stories of tailess kittens, puppies, and calves, born from parents one of whom had been thus injured, are abundant, but failed to stand experimental examination.|$|R
30|$|Under the {{constraint}} β < 1 /p_n^opt + P_c given above, optimal β can {{be obtained}} when the fronthaul link capacity is tight in problem (27). The optimal βopt could be obtained <b>by</b> a <b>bisection</b> algorithm, {{as a solution to}} problem (27).|$|R
40|$|Abstract. We {{have studied}} the {{chromosome}} condensation activity of mouse oocytes that have been inseminated during meiotic maturation. These oocytes remain unactivated, and in those penetrated by up {{to three or four}} sperm, each sperm nucleus is transformed, without prior development of a pronucleus, into metaphase chromosomes. However, those penetrated by more than four sperm never transform any of the nuclei into metaphase chromosomes (Clarke, H. J., and Y. Masui, 1986, £ Cell Biol. 102 : 1039 - 1046). We report here that, when the cytoplasmic volume of oocytes was doubled or tripled by cell fusion, up to five or eight sperm nuclei, respectively, could be transformed into metaphase chromosomes. Conversely, when the cytoplasmic volume was reduced <b>by</b> <b>bisection</b> of oocyte...|$|R
40|$|Day 7 bovine somatic nuclear {{transfer}} (NT) embryos recon-structed from granulosa cells were examined for numerical chromosome aberrations {{as a potential}} cause of the high em-bryonic and fetal loss observed in such embryos after transfer. The NT embryos were reconstructed using a zona-free manip-ulation method: half-cytoplasts were made from zona-free oo-cytes <b>by</b> <b>bisection,</b> after which two half-oocytes and one gran-ulosa cell (serum-starved primary culture) were fused together and activated. The NT embryos were cultured in modified syn-thetic oviductal fluid containing essential and nonessential ami-no acids, myoinositol, sodium citrate, and 5 % cattle serum in microwells for 7 days, at which time nuclei from all blastocysts were extracted and chromosome aberrations were evaluated us-ing dual-color fluorescent in situ hybridization with bovin...|$|R
40|$|We {{design and}} analyze optimal {{additive}} and multiplicative multilevel methods for solving H 1 problems on graded grids obtained <b>by</b> <b>bisection.</b> We deal with economical local smoothers: after a global smoothing in the finest mesh, local smoothing for each added node during the refinement {{needs to be}} performed only for three vertices- the new vertex and its two parent vertices. We show that our methods lead to optimal complexity for any dimensions and polynomial degree. The theory hinges on a new decomposition of bisection grids in any dimension, which is of independent interest and yields a corresponding decomposition of spaces. We use the latter {{to bridge the gap}} between graded and quasi-uniform grids, for which the multilevel theory is well-established...|$|R
40|$|The grid {{generator}} amatos {{has been}} developed for adaptive modeling of ocean and atmosphere circulation. It features adaptive control of planar, spherical, and volume grids with triangular or tetrahedral elements refined <b>by</b> <b>bisection.</b> The user interface (GRID API), a Fortran 90 module, shields the application programmer from {{the technical aspects of}} mesh adaptation like amatos hierarchical data structure, the OpenMP parallelization, and the effective calculation of a domain decomposition by a space filling curve (SFC) approach. This article presents the basic structure and features of amatos, the powerful SFC ordering and decomposition of data, and two example applications, namely the modeling of tracer advection in the polar vortex and the development of the adaptive finite element atmosphere model PLASMA (parallel large scale model of the atmosphere) ...|$|R
5000|$|During each {{iteration}} of the algorithm, {{a hypothesis}} is selected with some advantage over random guessing. The weight of this hypothesis [...] and the [...] "amount of time passed" [...] during the iteration are simultaneously solved {{in a system}} of two non-linear equations ( [...] 1. uncorrelate hypothesis w.r.t example weights and 2. hold the potential constant) with two unknowns (weight of hypothesis [...] and time passed [...] ). This can be solved <b>by</b> <b>bisection</b> (as implemented in the JBoost software package) or Newton's method (as described in the original paper by Freund). Once these equations are solved, the margins of each example ( [...] in the algorithm) and the amount of time remaining [...] are updated appropriately. This process is repeated until there is no time remaining.|$|R
30|$|Based on Proposition 2, the {{solution}} to the problem (40)–(43) can be obtained <b>by</b> using a <b>bisection</b> search algorithm.|$|R
40|$|Abstract. A {{generalized}} {{procedure of}} bisection of n–simplices is introduced, where the bisection point {{can be an}} (almost) arbitrary point {{at one of the}} longest edges. It is shown that nested sequences of simplices generated <b>by</b> successive generalized <b>bisection</b> converge to a singleton, and an exact bound of the convergence speed in terms of diameter reduction is given. For regular simplices, which mark the worst case, the edge lengths of each worst and best simplex generated <b>by</b> successive <b>bisection</b> are given up to depth n. Forn= 2 and 3, the sequence of worst case diameters is provided until it is halved. 1...|$|R
3000|$|The Algorithm 1 {{consists}} of two loops to find the optimal power allocation. The outer loop {{is used for the}} bisection search of β, and the inner loop is used to solve f(P(t))=β for a given β. In addition, the convergence of Algorithm 1 is ensured <b>by</b> the <b>bisection</b> search, where ε [...]...|$|R
40|$|Nowadays, multiresolution {{visualization}} methods {{become an}} indispensable ingredient of real time interactive post processing. We will here present an efficient approach for tetrahedral grids recursively generated <b>by</b> <b>bisection,</b> {{which is based}} on a more general method for arbitrary nested grids. It especially applies to regular grids, the hexahedra of which are procedurally subdivided into tetrahedra. Besides different types of error indicators, we especially focus on improving the algorithm's performance and reducing the memory requirements. Furthermore, parallelization combined with an appropriate load balancing on multiprocessor workstations is discussed. 1 Introduction A variety of multiresolution visualization methods has been designed to serve as tools for interactive visualization of large data sets. The local resolution of the generated visual objects, such as isosurfaces, is thereby steered by error indicators which measure the error due to a locally coarser approximation of the [...] ...|$|R
40|$|Given a set V {{of voter}} ideal {{points in the}} plane, a point x is in the epsilon core if for any other point y, x is within epsilon of being as close as y is to {{at least half the}} voters in V. The idea is that under {{majority}} rule x cannot be dislodged <b>by</b> any other <b>point</b> y if x is given an advantage of epsilon. This paper provides a finite algorithm, given V,x, and epsilon, to determine whether x is in the epsilon core. <b>By</b> <b>bisection</b> search, this yields a convergent algorithm, given V and x, to compute the least epsilon for which x is in the epsilon core. We prove by example that the epsilon core is in general not connected because the least epsilon function has multiple local minima. Epsilon core Algorithm Spatial model Voting...|$|R
40|$|Floating point {{computation}} {{presents a}} number of problems for formal verification. Should one treat the actual details of floating point operations, or accept them as imprecisely defined, or should one ignore round-off error altogether and behave as if floating point operations are perfectly accurate. There is the further problem that a numerical algorithm usually only approximately computes some mathematical function, and we often do not know just how good the approximation is, {{even in the absence of}} round-off error. ORA has developed a theory of asymptotic correctness which allows one to verify floating point software with a minimum entanglement in these problems. This theory and its implementation in the Ariel C verification system are described. The theory is illustrated using a simple program which finds a zero of a given function <b>by</b> <b>bisection.</b> This paper is presented in viewgraph form...|$|R
40|$|In the {{beginning}} we provide a brief {{introduction to the}} basic concepts of optimization and global optimization, evolutionary computation and swarm intelligence. The necessity of solving optimization problems is outlined and various types of optimization problems are discussed. A rough classfication of established optimization algorithms is provided, followed by Particle Swarm Optimization (PSO) and different types of PSO. Change in velocity component using velocity clamping techniques <b>by</b> <b>bisection</b> method and golden search method are discussed. We have discussed advantages of Using Self-Accelerated Smart Particle Swarm Optimization (SAS-PSO) technique which was introduced. Finally, the numerical values of the objective function are calculated which are optimal solution for the problem. The SAS-PSO and Standard Particle Swarm Optimization technique is compared as a result SAS-PSO does not require any additional parameter like acceleration coefficient and inertia-weight as in case of other standard PSO algorithms...|$|R
