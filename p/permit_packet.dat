1|43|Public
30|$|In-network caching {{seems not}} to be {{attractive}} for some content providers since it may cause copyright problems or legal issues [6]. In open mobile system, security and privacy has been a long-run challenge of much concern, especially in the cooperative caching system where mobile nodes cache contents due to their own limited cache space and energy. In other words, a mobile node {{can act as a}} content subscriber which requests contents from cooperative nodes and also play a role of content publisher or a relay node which provides contents to cooperative nodes. The process of cooperative caching brings about severe privacy issues, which is the reason why some mobile users would not like {{to take part in the}} caching cooperation. In ICN, content name is required to be included in requests, which would lead to privacy issues. In MANETs, connectivity provided over access points would offer an acceptable level of privacy for users who trust their access points [52]. This is particularly challenging in densely connected networks that easily <b>permit</b> <b>packet</b> sniffing. For ubiquitous mobile cache deployment, it is apparent that security and privacy problem needs to be addressed, and it is also worth discussion on combination of technical mechanism and new laws on content propagation during the evolution of ICN and information centric caching.|$|E
50|$|This {{can help}} {{identify}} incorrect routing table definitions or firewalls {{that may be}} blocking ICMP traffic, or high port UDP in Unix ping, to a site. Note that a firewall may <b>permit</b> ICMP <b>packets</b> but not <b>permit</b> <b>packets</b> of other protocols.|$|R
50|$|During the 1800s, the Maury River was {{developed}} {{with a series}} of locks and dams which <b>permitted</b> <b>packet</b> boats to transport goods such as agricultural and iron products and passengers from Lexington to the James River at Glasgow and on to Richmond, Virginia if desired.|$|R
5000|$|While IPv4 has no {{facilities}} to exceed its theoretical IP MTU limit, the designers of IPv6 {{have provided a}} protocol extension to <b>permit</b> <b>packets</b> of larger size. Thus, {{in the context of}} IPv6, a jumbogram is understood as an IPv6 packet carrying a payload larger than [...]|$|R
30|$|One of {{the main}} focuses of {{research}} in CR-VANETs is to design specific spectrum management techniques which take into account spectrum sensing and access as well as mobility for CR-enabled vehicles. Spectrum management should also aim at providing QoS support in CR-VANETs scenario. QoS guarantees are important for messages and signals related to vehicular safety. QoS guarantees can be in terms of maximum permitted delay and reliability in terms of <b>permitted</b> <b>packet</b> loss, etc. For example, {{in the event of}} an emergency brake, the vehicles that follow should be notified as quickly as possible in order to leave some time for other drivers to react.|$|R
50|$|Application layer {{firewalls}} {{are generally}} slower than stateful inspection. Application-layer firewalls are sometimes implemented using application proxies. Two TCP connections are established: one between the packet source and the firewall, another between the firewall and the packet destination. Application proxies intercept arriving packets {{on behalf of}} the destination, examine application payload, and then relay <b>permitted</b> <b>packets</b> to the destination. Suspicious data is dropped and the client and server never communicate directly with each other.Proxies necessarily involve more protocol stack overhead than inspecting packets at the network layer. Furthermore, because a unique proxy is required for each application, proxy firewalls can be less flexible and slower to upgrade than stateful inspection firewalls. Nevertheless, because application-level proxies are application-aware, the proxies can more easily handle complex protocols like H.323 or SIP, which are used for videoconferencing and VoIP (Voice over IP).|$|R
40|$|In many cases, each network {{imposes a}} maximum <b>permitted</b> <b>packet</b> size called payload size. Hence, some {{protocols}} such as TCP specify a message segmentation function allows a sender to divide a single message {{greater than the}} payload size into multiple packets. In this report, we derive an analytical form of a covariance of a packet size sequence for an environment where message segmentations happen. We show that when message sizes are exponentially distributed, the packet sizes are uncorrelated, that is, the covariance is always zero because of the memoryless property of an exponential distribution, even though the message segmentations happen. However, from numerical results where HTTP messages are lognormally distributed according to an actual traffic measurement, we demonstrate that TCPpacket sizes exhibit heavily-correlated property in cases of payload sizes used commonly for TCP. Key words – Covariance, packet sizes, message segmentation, TCP, HTTP, correlation...|$|R
40|$|The Cranium Network Interface Architecture: Support for Message Passing on Adaptive Packet Routing Networks by Neil R. McKenzie Chairperson of Supervisory Committee: Professor Carl Ebeling Department of Computer Science and Engineering Cranium is {{a network}} {{interface}} architecture for message passing in a scalable parallel computer system. Cranium provides the following features: ffl Support for adaptive networks. Cranium {{is compatible with}} adaptive networks that <b>permit</b> <b>packets</b> to overtake other packets in transit. The network interface notifies the processor after an entire message is received, independent of the arrival order of its individual packets. ffl User-level bus-master DMA for both low latency and high throughput. Cranium connects at the processor-memory bus to bypass the bottleneck at the I/O bus, without incurring the complexity of a design that is tightly coupled to the processor. Direct access by user programs avoids the overhead of operating system calls. ffl Su [...] ...|$|R
40|$|Firewalls are {{critical}} security devices handling all traffic {{in and out}} of a network. When under heavy load of both malicious and legitimate traffic, firewalls may be overloaded and start discarding or <b>permitting</b> <b>packets</b> without checking firewall rules, which can cause huge revenue losses or security breaches. In this paper, we study Denial of Firewalling attacks, where attackers use well-crafted traffic to effectively overwhelm a firewall. We first investigate firewall implementation characteristics that can be exploited for such attacks while treating the firewall as a black box. We conducted our studies on a testbed with three popular firewall devices. Second, given a remote firewall, we propose methods for attackers to infer the implementation of the firewall. We develop firewall fingerprinting techniques based on firewall decisions on a sequence of TCP packets with unusual flags and machine learning techniques for inferring firewall implementation. Finally, we present methods that attackers can use to generate the traffic that can effectively overload an identified remote firewall. We show that some firewalls can be easily overloaded by a small volume of carefully crafted traffic...|$|R
30|$|Since MUD {{technology}} <b>permits</b> simultaneous <b>packet</b> reception {{from multiple}} sources, compound signals, which were previously {{treated as a}} collision event in conventional wireless networks, are now preferred {{for their ability to}} enhance the achievable throughput performance [10 – 16]. However, how {{to take advantage of the}} MUD technique and how to adjust its tunable parameters in designing the medium access control (MAC) for multi-packet reception (MPR) capable wireless networks and maximize the achievable throughput have yet to be sufficiently studied.|$|R
40|$|In latest {{years the}} Internet has been altered from an unusual purpose network to a {{ubiquitous}} platform for an extensive {{range of a}} daily basis communication services. The demands on Internet consistency and accessibility have improved consequently. A new recovery scheme called Numerous Routing Configurations (NRC) is proposed to guarantee RAPID recovery from link and node failures in IP networks. Our proposed scheme assures the recovery in all single failure scenarios, to handle both link and node failures using a single mechanism, and without knowing {{the root cause of}} the failure. NRC is strictly connectionless and imagines only target based hop-by-hop forwarding. NRC is based on keeping further routing information in the routers and <b>permits</b> <b>packet</b> forwarding to continue on a substitute output link instantaneously after the discovery of a failure. It can be executed with only slight changes to the presented solutions. In this paper, with respect to scalability we study and present its performance approval path lengths and load sharing after a breakdown. We also show how an approximation of the traffic demands in the network can be used to develop the sharing of the recovered traffic, and thus decrease the chances of congestion when NRC is used. </p...|$|R
40|$|In Delay Tolerant Networks (DTNs), {{there is}} a {{fundamental}} tradeoff between the aggregate transport cost of a packet and the delay in its delivery. We study this tradeoff in the context of geographical routing in wireless DTNs. We ?rst specify the optimal cost/delay tradeoff, i. e., the tradeoff under optimal network operation, using a dynamic network construction termed the Cost/Delay Evolving Graph (C/DEG) and the Optimal Cost/Delay Curve (OC/DC), a function that gives the minimum possible aggregate transportation cost versus the maximum permitted delivery delay. We proceed to evaluate the performance of two known delay tolerant geographic routing rules, i. e., MOVE and AeroRP, a delay tolerant version of the geographic routing rule that selects as next relay the node for which the cost-per-progress ratio is minimized, and ?nally two novel rules, the Balanced Ratio Rule (BRR) and the Composite Rule (CR). The evaluation is in terms of the aggregate packet transmission cost {{as a function of the}} maximum <b>permitted</b> <b>packet</b> delivery delay. Simulations show that CR achieves a cost/delay tradeoff that is overall the closest to the optimal one speci?ed by the OC/DC, while BRR achieves the smallest aggregate transmission costs for large packet delays and a ?xed transmission cost model...|$|R
40|$|The {{demands on}} Internet {{reliability}} and user-friendliness have increased consequently as internet {{has been transformed}} from an extraordinary purpose network to universal platform for {{a broad range of}} day by day communication services. Internet takes a progressively added fundamental responsibility in our communications infrastructure as the slow convergence of routing protocols following a network breakdown becomes an increasing trouble. A new approach called numerous routing conﬁgurations  is presented in order to achieve speedy recovery in IP networks and that  guarantees recovery in all single failure circumstances, by means of a single mechanism to hold both link and node failures, and devoid of knowing the source reason of the breakdown. Numerous Routing Configurations is stringently connectionless, and believes only destination based hop-by-hop forwarding and is based on maintenance of supplementary routing information in the routers, and <b>permits</b> <b>packet</b> forwarding to carry on a substitute output link instantaneously after the finding of a failure. A minute set of endorsement routing configurations are based on numerous routing configurations which are used to direct improved traffic on alternating paths after a breakdown. Numerous routing conﬁgurations necessitates the routers to accumulate additional routing configurations. While routing in endorsement configuration is constrained, numerous routing conﬁgurations will potentially give endorsement paths that are longer than the optimal paths. </p...|$|R
5000|$|... filter engine, which spans both kernel-mode and user-mode, {{providing}} basic filtering capabilities. It {{matches the}} data within a packet - as exposed by the shims - against filtering rules, and either blocks or <b>permits</b> the <b>packet.</b> A callout may implement any other action as required. The filters {{operate on a}} per-application basis. To mitigate conflicts between filters, they are given weights (priorities) and grouped into sublayers which also have weights. Filters and callouts may be associated to providers which may be given a name and description and are essentially associated to a particular application or service.|$|R
50|$|Policy-based routing {{may also}} {{be based on the}} size of the packet, the {{protocol}} of the payload, or other information available in a packet header or payload. This <b>permits</b> routing of <b>packets</b> originating from different sources to different networks even when the destinations are the same and can be useful when interconnecting several private networks.|$|R
50|$|Wilkes {{proceeded}} in San Jacinto to {{a narrow}} part of the Old Bahama Channel, some 230 miles east of Havana, and waited there to waylay Trent. On 8 November, two shots across the mail packet's bow persuaded her master to heave to. A boarding party from San Jacinto seized the Confederate diplomats and their secretaries and then <b>permitted</b> the <b>packet</b> to resume her voyage. A week later, when San Jacinto reached Norfolk with the prisoners, the exultant North hailed the news as a great Union triumph. The incident strained United States relations with Britain almost {{to the breaking point}} and {{came to be known as}} the Trent Affair.|$|R
40|$|In this paper, we solve {{a type of}} {{shortest}} queue problem, {{which is}} related to multibeam satellite systems. We assume that the packet interarrival times are independently distributed according to an arbitrary distribution function, that the service times are Markovian with possibly different service rates, {{that each of the}} servers has its own buffer for packet waiting, and that jockeying among buffers is <b>permitted.</b> <b>Packets</b> always join the shortest buffer(s). Jockeying takes place as soon as the difference between the longest and shortest buffers exceeds a pre-set number (not necessary 1). In this case, the last packet in a longest buffer jockeys instantaneously to the shortest buffer(s). We prove that the equilibrium distribution of packets in the system is modified vector-geometric. Expressions of main performance measures, including the average number of packets in the system, the average packet waiting time in the system and the average number of jockeying, are given. Based on the above solutions, numerical results are computed. By comparing the results for jockeying and non-jockeying models, we show that a significant improvement of the system performance is achieved for the jockeying model. The performance study of a great number of satellite systems basically depends on the analysis of the related queueing systems. The major interesting measures of such analysis includes the system throughput, the average packet delay on the satellite, and the buffer overflow probability for the case of finite buffer size. Multibeam satellite systems have been studied extensively (for example, see Chlamtac and Ganz 1986, and Chang 1983), and {{it has been shown that}} they provide a greater system flexibility and a better performance. In such a system, all earth stations are organize [...] ...|$|R
50|$|The Berkeley Packet Filter (BPF) {{provides}} a raw interface to data link layers, <b>permitting</b> raw link-layer <b>packets</b> {{to be sent}} and received. It is available on most Unix-like operating systems. In addition, if the driver for the network interface supports promiscuous mode, it allows the interface {{to be put into}} that mode so that all packets on the network can be received, even those destined to other hosts.|$|R
40|$|We {{present a}} {{detailed}} {{investigation of the}} coherence properties of beam splitters and Mach-Zehnder interferometers for guided atoms. It is demonstrated that such a setup <b>permits</b> coherent wave <b>packet</b> splitting and leads to the appearance of interference fringes. We study single-mode and thermal input states and show that even for thermal input states interference fringes can be clearly observed, thus demonstrating the multimode operation and the robustness of the interferometer. Comment: 4 pages, 4 figure...|$|R
5000|$|The {{schooner}} {{was built}} {{by a group of}} Halifax merchants with government support as the Nova Scotia Packet, to establish a reliable packet service of mail and passengers between Halifax and Boston in 1765. The managing owner was, Joseph Grey, the son in law of the commissioner of the Halifax Naval Yard where the schooner was likely built. Launched in late September 1765, the schooner made her first voyage on 15 October 1765 under the command of Benjamin Green Jnr. Weather <b>permitting,</b> the <b>packet</b> sailed every eight days between Halifax and Boston and made 23 round trips during her merchant career. In July 1768, the Nova Scotia Packet was chartered by Commodore Samuel Hood in Halifax to take dispatches to Portsmouth, England. Hood also recommended that the schooner be purchased by the British Royal Navy.|$|R
30|$|Additional {{findings}} Each platform disallows the use {{of certain}} protocols: Google’s Compute Engine does not allow SMTP (port 25) or SMTP over SSL (465 and 587); Azure does not <b>permit</b> ICMP <b>packets</b> to be sent or received. In a similar way, EC 2 also blocks sending of SMTP mail by default, though this can be enabled by submitting a support request and using a set of Amazon APIs (SES). None of the services responded to either crafted UDP packets or to a UDP scan using the Nmap port scanning tool. The result were the same no matter if the ports were opened or closed in the firewall. We see from this that the firewall does not send an ICMP “Port Unreachable” notification when the port is closed. This is expected for Azure, which completely disallows {{the use of}} ICMP, but perhaps less so for Amazon EC 2 and Google Compute Engine.|$|R
50|$|The {{computer}} being awakened {{does not}} know whether the wakeup signal comes from another machine on the same network or from anywhere else. If the magic packet {{can be made to}} reach a computer, it can originate anywhere (e.g., from the Internet). This can be achieved by a virtual private network (VPN), which makes the remote computer appear {{to be a member of}} the local area network (LAN). In the absence of a VPN, a computer connected to a router can be awakened if a magic packet sent over the Internet is routed to it. This requires any firewall to be set up to allow entry of the Wake-on-LAN signal to a specified port. The port can be forwarded to the computer to be awakened; or some routers <b>permit</b> the <b>packet</b> to be broadcast to the entire LAN. However, some routers do not support this as they will not forward broadcast packets.|$|R
40|$|This paper {{introduces}} the virtualization of a Quality of Service Packet Scheduler. Virtualization {{in terms of}} resource sharing among multiple processes of virtual packet schedulers implementing the DWCS algorithm on an FPGA is implemented in the ShareStreams- V architecture. This work builds on the previous work in ShareStreams, which implemented the Dynamic Window-Constrained Scheduler algorithm. This implementation is parametric, <b>permitting</b> tradeoffs between <b>packet</b> decision latency, decision throughput, {{and the number of}} virtual packet schedulers supported. ShareStreams-V is able to schedule minimal size packets faster than one decision per 51. 2 ns for up to 64 streams, the throughput required for 10 Gbps Ethernet...|$|R
30|$|In {{practical}} applications, {{in addition}} to erasure/error recovery capability of the code, another important aspect to consider is {{the complexity of the}} encoding and decoding processes [9]. This aspect motivates the investigations in this paper, where the only operations <b>permitted</b> on <b>packets</b> are arithmetic packet shifts and binary additions. Particularly, this paper focuses on systematic codes with coefficient matrices based on the Vandermonde or NonVandermonde structures. Both designs, by incorporating packet shifts, facilitate fast matrix-vector multiplication and efficient inversion of submatrices involved in the erasure or erroneous packet recovery processes. In contrast to other systematic erasure codes based on Vandermonde matrices, the proposed codes are not using Vandermonde matrices to manipulate elements (packet fragments) from the Galois field (GF), but rather use them to operate on whole packets by working with their shifts. The benefit of this approach is the lower encoding and decoding complexities of the designs presented in this paper. The proposed codes are maximum distance separable (MDS) and, while maintaining comparable performance as in the more conventional ones, are also quite flexible in the choice of the code rate.|$|R
40|$|We {{propose a}} {{progressively}} reliable transport protocol for delivery of delay-sensitive multimedia over Internet connections with wireless access links. The protocol, termed "Leaky" ARQ, initially <b>permits</b> corrupt <b>packets</b> to be {{leaked to the}} receiving application and then uses retransmissions to progressively refine the quality of subsequent packet versions. A Web server would employ Leaky ARQ to quickly deliver a possibly corrupt first version of an image over a noisy bandlimited wireless link for immediate display by a Web browser. Later, Leaky ARQ's retransmissions would enable the browser to eventually display a cleaner image. Forwarding and displaying corrupt error-tolerant image data: (1) lowers the perceptual delay compared to fully reliable packet delivery, and (2) can be shown to produce images with lower distortion than aggressively compressed images when the delay budget only permits weak forward error correction. Leaky ARQ supports delaying of re-transmissions so that initial packet transmissions can be expedited, and cancelling of retransmissions associated with "out-of-date" data. Leaky ARQ can be parameterized to partially retransmit audio and video. We propose to implement Leaky ARQ by modifying Type-II Hybrid/"code combining" ARQ...|$|R
40|$|In this thesis, I {{contribute}} to the design and implemention of a new TCP-like protocol, CTCP, that uses network coding to provide better network use of the network bandwidth in a wireless environment. CTCP provides the same guarantees as TCP whilst providing significant enhancements to previous TCP implementations, such as <b>permitting</b> multipath <b>packet</b> delivery. CTCP's flow and congestion control policies are based on those of TCP Reno and TCP Vegas, which allow for prompt recovery from packet erasures and cope with congested networks. Unlike previous attempts at using network coding with TCP, this implementation uses block coding schemes, which are better suited to delay sensitive applications. As a result, CTCP permits content streaming. Overall, the efficient integration of network coding into CTCP allows for improved robustness against erasures as well as efficient content delivery over multiple paths. by Leonardo Andrés Urbina Tovar. Thesis (M. Eng.) [...] Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2012. Cataloged from PDF version of thesis. Includes bibliographical references (p. 93 - 94) ...|$|R
40|$|Larger Packets for Remote RADIUS over TCP draft-hartman-radext-bigger-packets- 00. txt The RADIUS over TLS {{experiment}} {{described in}} RFC 6614 has opened RADIUS to new use {{cases where the}} 4096 -octet maximum RADIUS packet proves problematic. This specification extends the RADIUS over TCP experiment to <b>permit</b> larger RADIUS <b>packets.</b> This specification compliments other ongoing work to permit fragmentation of RADIUS authorization information. Status of this Memo This Internet-Draft is submitted in full conformance with the provisions of BCP 78 and BCP 79. Internet-Drafts are working documents of the Internet Engineering Task Force (IETF). Note that other groups may also distribute working documents as Internet-Drafts. The list of current Internet-Drafts is a...|$|R
40|$|We {{address the}} problem of energy {{efficient}} scheduling for the loss tolerant applications by exploiting the multiuser diversity. The proposed scheduling scheme allows dropping of a certain predefined proportion of data packets on the transmitter side. However, there is a hard constraint on the maximum number of successively dropped packets. The scheduler exploits average data loss tolerance to reduce the average system energy expenditure while fulfills the hard constraint on successively dropped packets. We analyze the scheme using asymptotically large user limit. The numerical results illustrate the energy efficiency of the scheme {{as a function of the}} average packet drop probability and the maximum <b>permitted</b> successively dropped <b>packets</b> parameters...|$|R
40|$|Abstract: We {{propose a}} {{progressively}} reliable transport protocol for delivery of delay-sensitive multimedia over Internet connections with wireless access links. The protocol, termed “Leaky ” ARQ, initially <b>permits</b> corrupt <b>packets</b> to be {{leaked to the}} receiving application and then uses retransmissions to progressively refine the quality of subsequent packet versions. A Web server would employ Leaky ARQ to quickly deliver a possibly corrupt first version of an image over a noisy bandlimited wireless link for immediate display by a Web browser. Later, Leaky ARQ’s retransmissions would enable the browser to eventually display a cleaner image. Forwarding and displaying corrupt error-tolerant image data: (1) lowers the perceptual delay compared to fully reliable packet delivery, and (2) can be shown to produce images with lower distortion than aggressively compressed images when the delay budget only permits weak forward error correction. Leaky ARQ supports delaying of re-transmissions so that initial packet transmissions can be expedited, and cancelling of retransmissions associated with “out-of-date” data. Leaky ARQ can be parameterized to partially retransmit audio and video. We propose to implement Leaky ARQ by modifying Type-II Hybrid/“code combining ” ARQ...|$|R
40|$|Abstract. In large-scale, heavy loaded sensor {{networks}} {{the hidden}} node problem significantly restricts the attainable throughput. This paper examines {{this issue and}} depicts why most TDMA as well as dedicated hybrid MAC protocols are still negatively affected by this phenomenon. The concept of probabilistic self-stabilization is adopted to {{provide a framework for}} implementable reservation MAC protocols that avoid packet loss caused by signal interferences even under high load. These protocols base upon two main primitives: continuity in channel access, allowing predictability, and acknowledgments, <b>permitting</b> to discover <b>packet</b> loss. The designed TDMA and CSMA protocols are able to cope with the hidden node problem and with topology changes and achieve a high throughput in a steady state. The protocols are simulated and compared with IEEE’s 802. 15. 4 unslotted CSMA/CA protocol. ...|$|R
40|$|By {{combining}} the Open Kernel Environment, a Click-like software model known as Corral and basic concepts of active networking, we allow third-party code {{to control the}} code organisation of a network node at any level, including kernel and network card. We show how an active network environment was implemented and how this environment allows slow active code to control the code organisation of the fast path. The underlying code is structured much like components in a 'Click'-router that may be connected or disconnected at runtime. Not only are active <b>packets</b> <b>permitted</b> to reconfigure predefined native components in the networking code, by using the safe programming model of the open kernel environment they are also able to load and link their own native components at any place in the datapath and at any level in the processing hierarchy. © 2006 Elsevier B. V. All rights reserved...|$|R
40|$|Abstract—A parser’s {{job is to}} take unstructured, opaque {{data and}} convert it to a structured, semantically {{meaningful}} format. As such, parsers often operate at the border between untrusted data sources (e. g., the Internet) and the soft, chewy center of computer systems, where performance and security are paramount. A firewall, for instance, is precisely a trust-creating parser for Internet protocols, <b>permitting</b> valid <b>packets</b> to pass through and dropping or actively rejecting malformed packets. Despite the prevalence of finite state machines (FSMs) in both protocol specifications and protocol implementations, they have gained little traction in parser code for such protocols. Typical reasons for avoiding the FSM computation model claim poor performance, poor scalability, poor expressibility, and difficult or time-consuming programming. In this research report, we present our motivations for and designs of finite state machines to parse a variety of existing Internet protocols, both binary and ASCII. Our hand-written parsers explicitly optimize around L 1 cache hit latency, branch misprediction penalty, and program-wide memory overhead to achieve aggressive performance and scalability targets. Our work demonstrates that such parsers are, contrary to popular belief, sufficiently expressive for meaningful protocols, sufficiently performant for high-throughput applications, and sufficiently simple to construct and maintain. We hope that, in light of other research demonstrating the security benefits of such parsers over more complex, Turing-complete codes, our work serves as evidence that certain “practical ” reasons for avoiding FSM-based parsers are invalid. I...|$|R
40|$|International audienceRecently several {{multicast}} mechanisms were {{proposed that}} scale {{better with the}} number of multicast groups than traditional multicast does. These proposals are known as small group multicast (SGM) or explicit multicast (Xcast). Explicit multicast protocols, such as the Xcast protocol, encode the list of group members in the Xcast header of every packet. If the number of members in a group increases, routers may need to fragment an Xcast packet. Fragmented packets may not be identified as Xcast packets by routers. In this paper, we show that the Xcast protocol does not support the IP fragmentation. We show also that avoiding fragmentation limits the group size that can be handled by the Xcast protocol. First, we describe the Xcast protocol, the Xcast+ protocol (which is an extension of Xcast) and we compare these two protocols with traditional multicast protocols. We propose then a generalized version of the Xcast protocol, called GXcast, intended to <b>permit</b> the Xcast <b>packets</b> fragmentation and to support the increasing number of members in a multicast group. The behavior of the GXcast protocol is analyzed according to several criteria. Finally, we present and evaluate with simulations an improvement to GXcast and we conclude that GXcast is a feasible and promising protocol...|$|R
40|$|The Network Mobility (NEMO) {{protocol}} {{is needed}} to support the world-wide mobility of aircraft mobile networks across different access networks in the future IPv 6 based aeronautical telecommunications network (ATN). NEMO suffers from the constraint that all traffic has to be routed via the home agent though. The already existing correspondent router (CR) protocol solves this triangular routing problem and <b>permits</b> to route <b>packets</b> on a direct path between the mobile network and the ground based correspondent nodes. We identify security deficiencies of this protocol that make it unsuitable for use within the ATN. We therefore propose a new route optimization procedure based on the CR protocol that provides {{a higher level of}} security. We evaluate our new protocol in three ways. We first conduct a simulation based handover performance study using an implementation of a realistic aeronautical access technology. We then investigate the mobility signaling overhead. Finally, we specify a threat model applicable for the aeronautical environment and use it to perform a security analysis of both the old and our new protocol. It is shown that our protocol is not only more secure but also provides better handover latency, smaller overhead in the aeronautical scenario and a higher level of resilience when compared to the original CR protocol...|$|R
40|$|Recently several {{multicast}} mechanisms were {{proposed that}} scale {{better with the}} number of multicast groups than traditional multicast does. These proposals are known as small group multicast (SGM) or explicit multicast (Xcast). Explicit multicast protocols, such as the Xcast protocol, encode the list of group members in the Xcast header of every packet. If the number of members in a group increases, routers may need to fragment an Xcast packet. Fragmented packets may not be identified as Xcast packets by routers. In this paper, we show that the Xcast protocol does not support the IP fragmentation. We show also that avoiding fragmentation limits the group size that can be handled by the Xcast protocol. First, we describe the Xcast protocol, the Xcast+ protocol (which is an extension of Xcast) and we compare these two protocols with traditional multicast protocols. We propose then a generalized version of the Xcast protocol, called GXcast, intended to <b>permit</b> the Xcast <b>packets</b> fragmentation and to support the increasing number of members in a multicast group. The behavior of the GXcast protocol is analyzed according to several criteria. Finally, we present and evaluate with simulations an improvement to GXcast and we conclude that GXcast is a feasible and promising protocol...|$|R
40|$|A Mobile Ad Hoc Network (MANET) is {{a network}} {{consisting}} {{of a collection of}} nodes capable of communicating with each other without aid from a network infrastructure. Each node participating in the network works both as host and a router and must therefore is willing to forward packets for other nodes. For this purpose, a routing protocol is needed. The most important characteristics of MANET is the dynamic topology, nodes can change position dynamically therefore a need of a routing protocol that quickly adapts to topology changes. In this paper for experimental purpose, Investigators considered 150 m x 150 m, 250 m x 250 m, 350 m x 350 m, 450 m x 450 m, 550 m x 550 m, 650 m x 650 m & 750 m x 750 m terrain area and illustrate the Drop packet analysis using DSR protocol parameters for wireless network scenario. The Dynamic Source Routing protocol, a simple as well as an efficient routing protocol is designed particularly for use in multi-hop wireless ad hoc networks, allows the network to be entirely self-organizing and self-configuring, without the requirement of any presented network infrastructure or the administration. All aspects of the protocol work entirely on-demand, <b>permitting</b> the routing <b>packet</b> overhead to scale automatically to only which needed to respond to various changes in the different routes currently in use...|$|R
