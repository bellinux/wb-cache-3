166|35|Public
50|$|Gasum Oy is an {{integrated}} gas company located in Espoo, Finland. It is the transmission system operator {{of the natural}} gas grid of Finland, and also the natural gas importer and seller. Gasum refines biogas in Finland and Sweden, and imports, transfers and delivers it for energy consumption, industry and transport. Gasum owns 12 biogas refineries in Finland and Sweden, and is the largest <b>processer</b> of biodegradable waste in the Nordic countries. Gasum’s subsidiary Skangas is the largest liquefied natural gas (LNG) operator in the Nordic countries.|$|E
30|$|We run 10 K MC {{simulations}} {{to approximate}} the AIS of seed set S resulted by the above algorithms. All the experiments are {{run on a}} PC with a 2.6 -Ghz <b>processer</b> and 6 -GB memory.|$|E
30|$|A {{case study}} of PPM {{optimization}} problem for the notebook computer products is reported to demonstrate {{the potential of the}} hierarchical joint optimization model. The product structure of notebook computer mainly consists of display, hard disk, graphics card, <b>processer,</b> battery and memory, etc.|$|E
3000|$|... <b>processers</b> are used, each may be {{assigned}} to evaluate the cost function of each frequency estimate, as in (18), which can be done separately and in parallel. As analyzed in this investigation, the computational complexity of the proposed scheme is [...]...|$|R
30|$|The results speak clearly for {{the second}} approach. In all {{reported}} cases the efficiency lowers with increasing number of processors and increases {{with the number of}} nodes. The shared memory approach is superior to message passing on every instance. The difference is remarkably high for the lowest number of nodes and eight <b>processers.</b> Note also that the efficiency raises significantly with the increase of node number.|$|R
40|$|Mathematical and {{physical}} simulation of the temperature {{fields of the}} <b>processers</b> of structure formation and risering has been used, a metallographic analysis has been accomplished, and temporary and residual stresses have been analysed. New numerical models of the temperature field of an intricate casting and a combination casting mould have been developed; new solutions of the inverse problems of cooling flat and cylindrical castings have been achieved. The work has been used at the plants of heavy engineering industry, high-quality metallurgy industry and machnine-tool industry. Available from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|Industries {{consists}} of processes {{where hundreds of}} products are produced every day. This means that small flaws within {{the flow of the}} information or process can show up relatively fast. This creates an interesting question: how different forms of information flaws can affect processes. A few previous studies have been conducted regarding this area. This {{purpose of this study is}} to research the different forms of information flaws that can affect a flow of information between two processes. An information and process map has been created through a case study at Kubal. The researched process has been the flow of material between two processes. The conclusions of this research has been that the information flow between processes has to be tied together in every area, so that every relevant process owner is aware of the whole process. Failure to do so implies that the flow of information works sub-optimally. Another important point is to be consistent with what system is being used; lack of certain functions within a system generates additional systems that acts as complements to the main system, which implies that another problem arises within the flow of informationIndustrier består av <b>processer</b> där hundratals produkter produceras per dag. Detta betyder att små brister inom process- eller informationsflödet ger stora utslag relativt snabbt. Detta gör att en intressant frågeställning uppstår: hur olika former av informationsbrister påverkar <b>processer.</b> Ett fåtal tidigare studier diskuterar detta problem. Syftet med denna studie är att undersöka hur olika former av informationsbrister kan påverka ett informationsflöde mellan två <b>processer.</b> En informations- och processkartläggning har skett genom en fallstudie på Kubal. Den undersökta processen har varit det materialflödet mellan två <b>processer.</b> De slutsatser som tagits fram är att informationsflödet inom <b>processer</b> måste knytas på en generell nivå, så att alla relevanta delprocessägare är med inom flödet. Misslyckandet av att motverka detta leder till att informationsflödet agerar suboptimalt. En annan viktig punkt är att vara konsistent med de system som används; funktionsbrister inom dessa system leder till att ytterligare system genereras för att agera som komplement, vilket implicerar ytterligare problem inom informationsflödet...|$|E
40|$|This paper {{proposes a}} method of {{generating}} a schema manager and database language <b>processer</b> {{in order to support}} the data models and the database language. To this end, four kinds of specifications are used. These are the structure, the database language, the semantics, and the operation specifications. Users can customize the data model and database language by tailoring these specifications...|$|E
40|$|Abstract: This paper {{brings the}} {{preliminary}} results {{of interviews with}} Scandinavian managers and engineers asking questions regarding their previous experiences and knowledge on diverse continuous education methods and further encourages them to gaze into the crystal ball to identify requests and expectations to future methods of continuous education. The interviews have been done within a project titled: <b>Processer</b> til håndtering af skræddersyede efteruddannelsesforløb (PHASE), finance...|$|E
40|$|Research of the LEI Wageningen UR and NMI (Nutriënten Management Instituut) how {{the market}} for {{reclaimed}} nutrients would develop if harmonised product specifications were to apply to organic fertilisers and if substitutes for artificial fertilisers made from animal manure were to be considered legally equivalent to artificial fertiliser. The influence of the scrapping of such regulations is limited. The scale of the processing of manure into mineral concentrates will increase a little, the costs of exporting manure products {{will be a little}} lower, and the gate fees for manure <b>processers</b> could decline by 1 - 2 euros per tonne of manure (5 - 10 %) ...|$|R
40|$|Dissipation {{of energy}} in micro- and nano-electromechanical {{resonators}} governs their dynamical response and limits their potential use in device applications. Quantified by the quality factor Q, dissipation (Q− 1) usually occurs by energy loss mechanisms that are linear, appearing as a damping term proportional to the velocity. Mechanisms of linear dissipation in micro- and nano-mechanical resonators are well studied both theoretically and experimentally. Mechanisms of nonlinear dissipation of energy, however, are rarely studied, though their effects could be fundamentally important to the operation of numerous devices based on nonlinear resonators such as switches, signal <b>processers,</b> sensors, and energy harvesting systems. Here, we report experimental observation of nonlinear dissipation in diamond nanoelectromechanical resonators...|$|R
40|$|This {{document}} provides style {{guidelines for}} papers {{submitted to the}} annual ORSNZ Conference. Guidelines for ORSNZ Conference papers include fonts and margins, section headings and numbering, diagrams, tables, and images, math models, submission format, and references. Word users can use this document {{as the basis for}} their article. Those using other word <b>processers</b> should follow these guidelines as closely as possible. Place a solid line above and below the abstract, with the word “Abstract ” centred in 14 -point font bold. The abstract body should be even-justified in 12 -point font, using a line spacing of “at least ” 15 points. If you cannot get 15 point line spacing, please use single spacing. Key words: An optional comma separated list of list of key words formatted as per the abstract body can be included. This list (if present) is to be preceeded by the words “Key words: ” in bold...|$|R
40|$|This work {{describes}} a language for writing interactive {{systems that are}} independent of the applications that they service. This generality is based on application-specific information describing the command set of the application to the interactive <b>processer.</b> The model for this command set description is the procedure mechanism of a strongly-typed language called GINTAC, {{which is based on}} PASCAL and ADA. ^ GINTAC allows the compiler 2 ̆ 7 s symbol table information to be made available at run time via a construct called a symbolic expression. This information which describes procedures, variables and data types can then be used as the comand set definition by an interactive <b>processer.</b> In addition, interaction-specific information can be attached to declared symbols to enrich the expressiveness of this interface. ^ Primitives are provided in the language to obtain access to the information supplied by a symbolic expression. It is also possible to create expressions at run time which can be used to execute the application 2 ̆ 7 s commands. ^ Two such general interactive processers were designed based on the GINTAC language. The first is a general expression parser. It is shown how the command languages of several timesharing systems could be implemented using it. The second interactive <b>processer</b> supports a graphical interaction. It provides automatic menu generation, function button management and automatic user feedback. It is shown how the picking of objects from a display screen can be used to specify operands for expressions. In addition, it is shown how the strong typing of the expressions can resolve ambiguity that occurs when pointing at heirarchicly defined pictures. It is also shown how this system can be used to implement several graphical applications drawn from the literature. These two systems serve only to demonstrate this technique not to define the full extent of its capabilities. ...|$|E
40|$|This is an Open Access Article. It is {{published}} by Elsevier under the Creative Commons Attribution 4. 0 International Licence (CC BY). Full details of this licence are available at: [URL] {{aim of the research}} outlined in this paper is to demonstrate the implementation of a Cyber-Physical System (CPS) within the End of Life (EoL) processing of Electrical and Electronic Equipment (EEE). The described system was created by reviewing related areas of research, capturing stakeholder’s requirements, designing system components and then implementing within an actual EoL EEE <b>processer.</b> The research presented in this paper details user requirements, relevant to any EoL EEE <b>processer,</b> and provides information of the challenges and benefits of utilising CPSs systems within this domain. The system implemented allowed an EoL <b>processer</b> to attach passive Ultra High Frequency (UHF) Radio Frequency Identification (RFID) tags to cores (i. e. mobile phones and other IT assets) upon entry to the facility allowing monitoring and control of the core’s refurbishment. The CPS deployed supported the processing and monitoring requirements of PAS 141 : 2011, a standard for the correct refurbishment of both used and waste EEE for reuse. The implemented system controls how an operator can process a core, informing them which process or processes should be followed based upon the quality of the core, the recorded results of previous testing and any repair efforts. The system provides Human-Computer Interfaces (HCIs) to aid the user in recording core and process information which is then used to make decisions on the additional processes required. This research has contributed to the knowledge of the advantages and challenges of CPS development, specifically within the EoL domain, and documents future research goals to aid EoL processing through more advanced decision support on a core’s processes...|$|E
40|$|In {{the last}} decades {{there has been a}} growing {{interest}} in studying processes in improvement work. A particular interest has been the improvement process that the organisation undergoes and why events evolve in the way they do. By better understanding improvement processes and identifying supporting and hindering forces, the possibilities successfully to plan and implement improvement work in a systematic way increases. The focus of this thesis is organisation processes in schools and the relations that hold between planned and emergent improvement, when using a research-based strategy. The aim of the study is to describe and understand how processes are initiated, developed and completed when using a strategy called ‘Scope for Action Model’(frirumsstrategin). The empirical material of the study was organised and analysed according to Van de Ven’s and Poole’s four ideal types for process studies. Within each type, motors have been identified, which contain generative mechanisms that are a key to how actions, events and activities emerge and are driven forward. The results of the study show that the emergent initiatives are more frequent than the planned ones and that {{they are more likely to}} generate an improvement – in the study defined as something new in the organisation. However, on several occasions the planned improvement work inspires emergent initiatives for improvement and in some cases seems to be a fundamental condition for their existence. The different motors, which in the analysis are seen as driving forces, support or challenge each other, making the process develop and produce a result. The study shows that the participants reshape the strategy to make it fit into the organisation of the school. The results also show that teachers and principals have to be well-informed of how to work with a strategy in a practical and constructive way. They have to be able to translate crucial moments in the strategy to stimulate the participants to creative actions. The strategy for school improvement is not shown to be a solution which itself can create improvement, but in combination with the participant’s creative goal settings it can be a contributory factor. Denna avhandling riktar intresset mot skolförbättring och de <b>processer</b> som uppstår när en planerad förändring genomförs på skolor med stöd av en forskningsbaserad strategi. Syftet med avhandlingen är att beskriva och förstå hur dessa <b>processer</b> - i arbetet med frirumsstrategin - initieras, fortlöper och avslutas. Studien visar att det finns relationer mellan planerade och framväxande <b>processer.</b> De framväxande processerna är mest frekventa och har sin grund i deltagarnas egna målformuleringar. De förmår skapa utveckling i skolverksamheterna, något de planerade processerna inte lyckas med. Det planerade förbättringsarbetet tycks bidra genom att vara en inspirationskälla eller i vissa fall en förutsättning för de framväxande initiativ som tas av deltagare från olika delar av organisationen. Studien pekar på att en strategi kan vara igångsättare av förbättringsarbete och utgöra en grund för skolor att utgå från. Av resultatet framgår att det är viktigt att rektorer och lärare har goda kunskaper om förbättringsarbetets <b>processer</b> för att kunna använda strategin på ett konstruktivt sätt. Genom att ha insikt i vilka mekanismer som påverkar <b>processer</b> kan ett förbättringsarbete ledas medvetet samt tillåtas innehålla både de konflikter och den samstämmighet som kan bidra till att utveckling sker...|$|E
40|$|Security was not {{considered}} when current wireless sensor nodes were designed. As a result, providing high level of security on current WSNs platforms is unattainable, especially against attacks based on key resolving and node compromise. In this paper, we scrutinize the security holes in current WSNs platforms and compare the main approaches to implementing their cryptographic primitives in terms of security, time, and energy efficiency. To secure these holes and provide more efficiency, we propose SN-SEC, a 32 -bit RISC secure wireless sensor platform with hardware cryptographic primitives. The choice of cryptographic primitives for SN-SEC is based on their compatibility with the constrained nature of WSNs and their security. SN-SEC is implemented using very high-speed integrated circuit hardware description language. Experimental results using synthesis for Spartan- 6 low-power FPGA show that the proposed design has a very reasonable computational time and energy consumption compared to well-known WSN <b>processers...</b>|$|R
40|$|AbstractThe {{integration}} of functions in business networks requires {{a high level}} of {{integration of}} the information processes. Based on file transfers, these networks respond to the requirements of collaborative processes. There is an effective need for a strategy of integration among the members of the network. In the ICT era, the collaborative company needs to reach and maintain agility in the dynamics of their collaborative processes. Within the frame of a collaborative network, the developments of a web platform permit the growth of an area that integrates collaborative processes, in which several companies participate, each supplying their own data. The Fruit-and-Vegetable Collaborative Network studied in this paper is formed by producers, <b>processers,</b> packaging companies, marketers, transporters, and distributors. It has been developed under a web platform (Virtual Office) that allows the network to carry out processes in a collaborative way, and helps the network in its process of confidence-building and in the interactions among the actors of the network...|$|R
40|$|Abstract. Cache {{optimizations}} typically include code transformations {{to increase}} the locality of memory accesses. An orthogonal approach is to enable for latency hiding by introducing prefetching techniques. With software prefetching, cache load instructions have to be inserted into the program code. To overcome this complexity for the programmer, modern <b>processers</b> are equipped with hardware prefetching units which predict future memory accesses in order to automatically load data into cache before its use. For optimal performance, it seems advantageous to combine both prefetching approaches. In this contribution, we first use a cache simulation enhanced with a simple hardware prefetcher to run code for a 3 D multigrid solver. Cache misses which are not predicted by the prefetcher can be located in simulation results, and selectively, software prefetch instructions can be inserted. However, when performance of a code section is limited by available bandwidth to main memory, this simple strategy will fail. Thus, we use Block Prefetching, {{an extension of the}} standard blocking strategy. Meassurements show its potential. ...|$|R
40|$|All of the {{required}} files have been supplied. A zip with all the files is supplied, {{as well as individual}} filesMultidist is a new, exciting distortion effects <b>processer</b> developed by Trentone. The Multidist software offers users the freedom and variety that other processors do not. It has optional multiband capabilities, six separate distortion options, graphical user interfaces and it all runs in under 10 seconds! The software is evolving and it is shaping up to become very, very powerfu...|$|E
40|$|This {{paper is}} made to {{consider}} a condition on the application of personal computer for the guidance of junior high school mathematics. At first, we consider a relation between mathemtics of junior highschool and education using personal computers. Next, under this condition, we aim to make materials for "Equivalent Deformations". We have used FCAI (Frame style Computer Assisted I nstruction, which is convenient for developing CAI materiales, because it can use ready-made program and word <b>processer...</b>|$|E
40|$|Det här examensarbetet har utförts på uppdrag av Logica part of CGIoch i samarbete med deras kund Thermoprodukter. Syftet med arbetetär att undersöka om Thermoprodukters verkliga <b>processer</b> stämmeröverens med Microsoft Dynamics NAV Process Flows. Genom att först göra en analys av Microsoft Dynamics NAV ProcessFlows har den tänkta arbetsprocessen identifierats. Sedan harThermoprodukters <b>processer</b> identifierats samt ritats upp i ett flödes-­‐‑schema. För att slutligen kunna jämföra processerna och få ut ett resultatom dessa stämmer överens eller inte. Resultatet visar att processerna stämmer bra överens med varandra menatt det självklart finns skillnader då Thermoprodukter har en delspecialbyggda moduler. This thesis {{has been}} carried out on behalf of Logica part of CGI and incooperation with their {{customer}} Thermoprodukter. The purpose of thiswork is to analyze whether Thermoprodukter´s actual processes isconsistent with Microsoft Dynamics NAV Process Flows. By first doing an analysis of Microsoft Dynamics NAV Process Flows,the ideal processes have been identified. Then Thermoprodukter’sactual processes was identified and drawn up in a flow diagram. Eventually a comparison was carried out between these processes. The results show that the processes are consistent with one another butnaturally there are differences {{due to the fact that}} Thermoprodukterhave some custom built modules...|$|E
40|$|This thesis {{describes}} research {{directed toward}} the development of general English speech understanding systems. The relatively unconstrained grammars and large vocabularies characterizing such systems require them to eliminate most of the words found in their vocabularies by using only acoustic information. In particular, we present the design and performance of a bottom-up word hypothesizer capable of handling large vocabularies (> 10, 000 words) which takes segmented and labeled speech as input and produces word hypotheses. The primary concerns of the thesis are the problems involved with large vocabularies {{and the effect of}} large vocabularies on word hypothesization. The thesis deals with the following problems: 1) Knowledge Representation: storing the acoustic knowledge of words efficiently for fast retrieval; 2) Knowledge Acquisition: obtaining the acoustic knowledge for a large number of words easily; 3) Flexibility: permitting improvements to be made to the acoustic <b>processers</b> of the speech system (e. g., segmenter-labeler) without requiring an expensive reacquisition o...|$|R
40|$|This paper {{describes}} {{the exploration of}} design parameters for widely used Digital Signal Processing (DSP) algorithms and techniques. In this paper, some of the DSP algorithms and techniques are considered and executed them on soft core processors like General Purpose Processors, Digital Signal Processing <b>processers</b> and also on hard core processor Field Programmable Gate Array (FPGA). After execution, the design parameters like execution time, area (number of slices required on FPGA) of the DSP techniques are acquired for the computing architectures. The acquired parameters play crucial role in selection of resources for their optimum execution in real time. In this paper, the acquired design parameters are represented as DSP techniques resource utilization chart for hardware software co-design. The resource utilization chart could help in designing optimized computing architecture for DSP applications. Finally, the described methodology has been evaluated by considering OFDM transmitter, a real time DSP application, {{as a case study}} and proposed optimized computing platform for OFDM transmitter...|$|R
40|$|With {{commercial}} scale cellulosic ethanol in the formative stages of building large-scale feedstock supply chains {{there is a}} requirement for biomass harvesting equipment {{to be capable of}} increasing the densification of agricultural residue. The current technologies in use are large square balers, which were not specifically designed for the harvesting of agricultural residues such as corn stover. With the growing demand for corn stover harvesting, the equipment needs to be improved and refined to overcome the challenges that corn stover harvesting presents, while meeting and exceeding industry standards for custom harvesting. The harvest capacity of this equipment set is greatly decreased in corn stover biomass harvesting because of increases in maintenance and downtime caused by the harsh operating conditions. The objective of this research was to discover correlations between harvesting equipment 2 ̆ 7 s downtime and productivity. Results of this work analyzed a comprehensive corn stover harvesting data set from an 8000 -acre commercial corn stover harvest. The outcome of this research will benefit both the cellulosic <b>processers,</b> as well as the growers and custom harvesters of agricultural biomass...|$|R
40|$|This study aims {{to examine}} {{potential}} efficiency gains within a manufacturing unit by implementing processes for knowledge and information distribution. A specialized software tool, implementing processes for knowledge and information distribution, was developed and then examined {{to see if any}} efficiency gains could be accomplished. The scientific questions to be addressed were: Will well-defined strategies and processes for information and knowledge management lead to higher efficiency within a manufacturing unit? Is a specialized software a useful tool and how should it be designed to facilitate efficient information and knowledge management? With the help of information management theories, interviews and a field study five main problem areas were found. To counter the problem areas and approach the technical aspect of this study human-computer interactions theories were used to develop three prototypes in an iterative process. The third and final prototype was evaluated by using user testing and interview questions. We found that well-defined strategies and processes for information and knowledge management lead to higher efficiency within a manufacturing unit. By using the specialized software tool it will be easier to facilitate efficient information and knowledge management and that general rules on how to create such a software exists. Due to the result and reactions from the employees our recommendations is for FLIR Systems AB to conduct an implementation study using our software as the frontend.  Denna studies mål är att undersöka eventuella effektivitetsvinster inom en tillverkningsenhet genom att implementera <b>processer</b> för kunskaps- och informationsspridning. Ett specialiserat verktyg, som implementera de <b>processer</b> för kunskap och informationsspridning, har utvecklats och sedan granskas för att se om några effektivitetsvinster kan åstadkommas. De vetenskapliga frågor som skall besvaras är: Kommer väldefinierade strategier och <b>processer</b> för informations- och kunskapsspridning att leda till ökad effektivitet inom en tillverkningsenhet? Är en specialiserad mjukvara ett användbart verktyg och hur ska den designas för att uppmuntra effektiv informations- och kunskapshantering? Fem problemområden identifierade med hjälp av teorier om informationshantering, intervjuer och en fältstudie. För att förbättra de problemområden och närma den tekniska aspekten av denna studie användes människa-datorinteraktionsteorier för att utveckla tre prototyper i en iterativ process. Den tredje och sista prototypen utvärderades med hjälp av användartester och intervjufrågor. Vi fann att väldefinierade strategier och <b>processer</b> för information och kunskapshantering leder till högre effektivitet inom en tillverkningsenhet. Genom att använda ett specialiserat verktyg underlättar det för en effektiv informations- och kunskapshantering. Vi fann även att allmänna regler för hur man designar en sådan mjukvara existerar. Utifrån resultatet och reaktionerna från de anställda är våra rekommendationer för FLIR Systems AB att genomföra en implementationsstudie med hjälp av vår programvara som interface. ...|$|E
30|$|Some major concerns, like {{whenever}} CPU is {{not doing}} useful work it must have to execute at least one process called idle process, during the execution of that process CPU consumes 5  % of the energy, which is overhead. No efficient techniques are developed so for which can minimize this loss. However, different techniques are developed which let <b>processer</b> sleep when it’s not doing useful work. This not only saves energy but also improves {{the performance of the}} computer system.|$|E
40|$|Abstract. The paper {{adopts a}} method of a low speed <b>processer</b> and FPGA based {{hardware}} accelerator SOC units to develop the MP 3 player, added with some peripheral devices. The experimental {{results show that the}} system has implemented the basic functions of the MP 3 player, having its own advantage on increasing the decoding speed and reducing the system consumption. The system is convenient to redesign for more function in the future because it’s designed based on FPGA. In conclusion, it has a wide application prospect...|$|E
40|$|Purpose – Price {{satisfaction}} is an influential factor in competitive performance and business success. Strong price satisfaction enhances and sustains high quality business relationships, leading to improved profits for chain participants. The {{purpose of this}} paper is to explore the dimensions of price satisfaction in the context of the Malaysian dairy industry. The aim is to determine which dimensions of price satisfaction affect relationship performance between Malaysian dairy producers and the dairy <b>processers</b> who purchase their milk. Design/methodology/approach – In total, eight hypotheses are tested using partial least square methods on survey results from 133 dairy producers in Malaysia. Findings – The study results suggest that relative price, price-quality ratio and price fairness influence producers’ loyalty and improved business relationship performance. Practical implications – To achieve long-term, sustainable business relationships involving consistent high quality supplies, milk buyers need to understand and capture the price satisfaction dimensions. Originality/value – The paper provides insights into the important linkages between price satisfaction and business performance in an agriculture industry. Bonaventure Boniface, Amos Gyau, Randy Stringe...|$|R
30|$|A {{great effort}} has been given {{in the past few}} years in the {{worldwide}} range on developing novel biosensors with high sensitivity and selectivity. The recent, fast development of nanomaterials has made a profound influence on the development of biosensors. The application of nanomaterials has been given to all technical components of biosensors from recognition components to signal <b>processers.</b> When the material’s size is reduced to nanoscale, the interesting changes in chemical and physical properties are happened due to two principal factors: surface effect and quantum effect. The surface to volume ratio of nanomaterials increases dramatically compared to their bulk form and is able to improve the sensitivity of biosensors through increasing the interface for recognition element allocation. The quantum confinement phenomenon can lead to an increase in the band-gap energy and a blue shift in light emission with decreasing size. As a result, the electrical and optical properties of nanomaterials become size and shape dependent. These essential features of nanomaterials make it possible to turn chemical and physical properties to specific biosensor applications by controlling their size, shape, and chemical composition [5].|$|R
40|$|The {{safety of}} the food that we process and serve to the public is very important. Keeping our food safe in the production, packaging, and {{distribution}} and until it reaches the consumer is critical. The Food Safety Modernization Act (FSMA) Preventive Controls for Human Food (PCHF) rule focuses on the preventive approach in enhancing {{the safety of our}} food system. The rule provides the food processors numerous tools and options to implement controls that can help ensure the {{safety of the}} food in acquiring the raw ingredients, processing the raw ingredients, and packaging and distributing them to the consumer or to secondary and tertiary processors. The four major preventive controls that the <b>processers</b> can utilize include: process, allergen, sanitation, and supply chain preventive controls. Each of these preventive controls provide ways to ensure that the various hazards including; biological, physical, chemical and radiological hazards are controlled or minimized effectively. The various tools will assist us in maintaining the safety of the food as it changes hands across the supply chain...|$|R
40|$|Abstract — This paper {{describes}} a two-stage algorithm for landmine detection with a {{ground penetrating radar}} (GPR) system. First, 3 -D data sets are processed using a computationally inexpensive pre-screening algorithm which flags potential locations of interest. These flagged locations are then passed to a feature-based <b>processer</b> which further discriminates target-like anomalies from naturally occurring clutter. Current field trial (over 6500 square meters) and blind test results (over 39000 square meters) are presented and these show at least {{an order of magnitude}} improvement over other radar system-based detection algorithms on the same test lanes...|$|E
40|$|Abstract|We {{developed}} the system which can estimate the face-direction {{of a person}} with two cameras using stereo vision. In this system, the eyes and the mouth are extracted in each image for measurement of their 3 D position by matching the each feature in the one image with in the other. Then, face direction is obtained from the normal of the plane which {{is determined by the}} 3 D coordinates of the features. This system can track face-direction in semi-realtime. PC Image <b>Processer</b> camera 1 camera 2 I...|$|E
40|$|Traffic {{monitoring}} from space, day and night, {{from more}} than 500 kilometers up above; is that possible? Indeed it is! At the DLR Microwaves and Radar Institute a special traffic processor for the German TerraSAR-X / TanDEM-X radar satellite constellation has been developed. With the traffic <b>processer</b> vehicles moving on open land and on open sea can be detected and their parameters geographical position, velocity and heading can be estimated. In the paper {{the principle of the}} traffic processor is explained and first measurement result are presented and discussed...|$|E
40|$|The serial {{communication}} is very commonly used communication protocol between various peripherals and processor. The current trend is all high speed buses are built with {{serial communication}} interface. The ALTERA’s NIOS II soft processor and PowerPC hard processor {{are widely used}} in FPGA based CSOC (configurable system on chip) applications. These <b>processers</b> don’t have programmable serial links for interfacing with embedded peripherals which are mostly off chip. In this project it is proposed to implement dynamically configurable serial communication block in Verilog. The developed module shall be interfaced with NIOS II soft processor as a general purpose IO port. The serial interface blocks shall be implemented to handle high data rate serial links and provide parallel interface to the processor. The Nios II IDE (EDK) shall be used for developing the test application in C programming language. The serial interface blocks which are coded in Verilog shall be synthesized using QUARTUS II EDA tool. The CYCLONE III family FPGA board shall be used for verifying the results on board. I...|$|R
40|$|First paragraph: Mortalities of larger, more {{valuable}} cockle 2 and 3 year-classes have recurred on the Burry Inlet (Loughour) Estuary (BI) since 2002 {{and on the}} nearby Three Rivers Estuary (TR) since 2005. The aim of this report is to estimate {{the economic impact of}} the mortality on the south Wales cockle industry, related businesses and wider Welsh economy. Stakeholder interviews, direct observation, secondary literature, production and price data supplied by industry and government agencies is used to characterise value-chains, historic livelihood, regulatory and production trends. Lack of intermediate expenditure data (wages, energy rents etc.) prevented estimates of losses on foregone gross value added (GVA) across the Welsh cockle value chain. Analysis was instead focused on estimation of first-sale value losses for whole cockle from the BI using a range of baseline output and price scenarios (lack of historic value data precluded the assessment for the TR). Value-chain analysis indicated that the burden of mortality losses fell most heavily on independent gatherers; whilst <b>processers</b> are able to source much of their raw materials needs from other Welsh, English and European fisheries, gatherer access to other cockle fisheries is much more restricted...|$|R
40|$|In {{the race}} between DNA {{sequencing}} throughput and computer speed, sequencing is winning by a mile. Sequencing throughput {{has recently been}} improving {{at a rate of}} about 5 -fold per year 1, while computer performance generally follows “Moore's Law, ” doubling only every 18 or 24 months 2. As this gap widens, the question of how to design higher-throughput analysis pipelines becomes critical. If analysis throughput fails to turn the corner, research projects will continually stall until analyses catch up. How do we close the gap? One option is to invent algorithms that make better use of a fixed amount of computing power. Unfortunately, algorithmic breakthroughs of this kind, like scientific breakthroughs, are difficult to plan or foresee. A more practical option is to concentrate on developing methods that make better use of multiple computers and <b>processers.</b> When many computer processors work together in parallel, a software program can often finish in significantly less time. While parallel computing has existed for decades in various forms 3 – 5, a recent manifestation called “cloud computing ” holds particular promise. Cloud computing is a model whereby users access compute resources from a vendor over the Internet 1, such as from th...|$|R
