5501|1531|Public
25|$|Principal {{component}} regression (PCR) is {{used when}} the number of <b>predictor</b> <b>variables</b> is large, or when strong correlations exist among the <b>predictor</b> <b>variables.</b> This two-stage procedure first reduces the <b>predictor</b> <b>variables</b> using principal component analysis then uses the reduced variables in an OLS regression fit. While it often works well in practice, there is no general theoretical reason that the most informative linear function of the <b>predictor</b> <b>variables</b> should lie among the dominant principal components of the multivariate distribution of the <b>predictor</b> <b>variables.</b> The partial least squares regression is the extension of the PCR method which does not suffer from the mentioned deficiency.|$|E
25|$|Under the {{condition}} that the errors are uncorrelated with the <b>predictor</b> <b>variables,</b> LLSQ yields unbiased estimates, but even under that condition NLLSQ estimates are generally biased.|$|E
25|$|For {{continuous}} outcome data, {{analysis of}} covariance (e.g., for changes in blood lipid levels after receipt of atorvastatin after acute coronary syndrome) tests the effects of <b>predictor</b> <b>variables.</b>|$|E
30|$|In step three, {{mediation}} {{analysis was}} conducted when a <b>predictor</b> <b>variable</b> was correlated to the proposed outcome variable and another dependent variable. Mediation analysis measures {{the significance of the}} indirect effect {{and the extent to which}} the mediator variable accounts for the relationship between the predictor and the outcome variable. Mediation analysis is particularly appropriate to use when (A) the <b>predictor</b> <b>variable</b> is experimentally manipulated and the mediator variable measured and (B) the dynamic change in the <b>predictor</b> <b>variable</b> precedes the dynamic change in the mediator variable; and both precede the outcome variable [23, 26].|$|R
3000|$|A clear {{pattern in}} {{reduction}} of RMSPE {{can be seen}} by including more diverse combinations of <b>predictor</b> <b>variable</b> datasets (Table  5). Across models, ĈĈ_HEMI alone is a better predictor of AGB than models that use only Landsat 8 OLI predictor variables; however, the exponential model that uses Landsat 8 OLI has a slight edge over ĈĈ_HEMI (RMSPE 45.9 vs. 46.6, respectively). The <b>predictor</b> <b>variable</b> combination of environmental and disturbance data alone and ĈĈ_HEMI alone are comparable with two of the three combinations that have two <b>predictor</b> <b>variable</b> datasets (Landsat[*]+[*]Env/Dist and ĈĈ_HEMI + Landsat), with a difference in mean RMSPE [...]...|$|R
30|$|This {{analysis}} used a {{logistic regression}} predicting {{the proportion of}} trials where a participant selected a particular method from a <b>predictor</b> <b>variable</b> coding whether that method was horizontal or reductive. The regression included a random effect of subject on {{the slope of the}} <b>predictor</b> <b>variable</b> to account for repeated trials per subject. B =  0.40, SE =  0.07, z =  5.65, p < . 001.|$|R
25|$|The arrangement, or {{probability}} {{distribution of the}} <b>predictor</b> <b>variables</b> x has {{a major influence on}} the precision of estimates of β. Sampling and design of experiments are highly developed subfields of statistics that provide guidance for collecting data in such a way to achieve a precise estimate of β.|$|E
25|$|At a restart marker, block-to-block <b>predictor</b> <b>variables</b> are reset, and the {{bitstream}} is synchronized to a byte boundary. Restart markers provide {{means for}} recovery after bitstream error, such as transmission over an unreliable network or file corruption. Since the runs of macroblocks between restart markers may be independently decoded, these runs may be decoded in parallel.|$|E
500|$|Reiss {{concluded}} that Sexual Preference [...] "has value for suggesting directions and the likely worth of ideas", but that given its shortcomings {{there was no}} way in which its authors could definitively resolve the issues they explored, despite their claim to [...] "once and for all" [...] discredit some theoretical ideas about homosexuality. Reiss wrote that Bell et al. asked questions that were [...] "vague" [...] and [...] "open-ended", had an [...] "arbitrary and rigid conception" [...] of what could be done with their data and lacked [...] "theoretical development" [...] in its handling, and deliberately minimized the importance of the <b>predictor</b> <b>variables</b> they used to test psychoanalytic and other theories. He found their conclusion that sexual orientation has a biological basis unconvincing. DeLamater wrote that Sexual Preference benefited from Bell et al.′s [...] "eclectic theoretical basis", which drew from the psychodynamic model, social learning theory, sociological models that emphasize the importance of peer relationships, and labeling theory. However, while he accepted Bell et al.′s claim that their study was methodologically superior to prior work on homosexuals, he still found it problematic for many reasons and hesitated to endorse its conclusions. In his view, the path analysis involved [...] "arbitrary classification and sequencing of variables".|$|E
5000|$|Large {{changes in}} the {{estimated}} regression coefficients when a <b>predictor</b> <b>variable</b> is added or deleted ...|$|R
5000|$|... #Caption: Cox {{proportional}} hazards regression output for melanoma data. <b>Predictor</b> <b>variable</b> is sex 1: female, 2: male.|$|R
3000|$|... {{possible}} states. For analysis purposes, we {{establish a}} bijection between this finite state {{space and a}} single <b>predictor</b> <b>variable</b> [...]...|$|R
2500|$|Weak exogeneity. [...] This {{essentially}} {{means that}} the <b>predictor</b> <b>variables</b> x can be treated as fixed values, rather than random variables. [...] This means, for example, that the <b>predictor</b> <b>variables</b> {{are assumed to be}} error-free—that is, not contaminated with measurement errors. Although this assumption is not realistic in many settings, dropping it leads to significantly more difficult errors-in-variables models.|$|E
2500|$|The {{meaning of}} the {{expression}} [...] "held fixed" [...] may depend on how {{the values of the}} <b>predictor</b> <b>variables</b> arise. If the experimenter directly sets the values of the <b>predictor</b> <b>variables</b> according to a study design, the comparisons of interest may literally correspond to comparisons among units whose <b>predictor</b> <b>variables</b> have been [...] "held fixed" [...] by the experimenter. Alternatively, the expression [...] "held fixed" [...] can refer to a selection that takes place in the context of data analysis. In this case, we [...] "hold a variable fixed" [...] by restricting our attention to the subsets of the data that happen to have a common value for the given predictor variable. This is the only interpretation of [...] "held fixed" [...] {{that can be used in}} an observational study.|$|E
2500|$|... {{are called}} regressors, {{exogenous}} variables, explanatory variables, covariates, input variables, <b>predictor</b> <b>variables,</b> or independent variables (see dependent and independent variables, {{but not to}} be confused with independent random variables). The matrix [...] is sometimes called the design matrix.|$|E
30|$|In our {{resource}} selection function (RSF) analysis, we used RSF modeling {{to identify}} a specific predictor variable—selection of fire-altered habitats—while allowing other habitat components to compete as predictors in model selection and comparison of effect sizes. We constructed a single model from data gathered throughout the study and tested for significance of an interaction between pre-fire or post-fire location data (discrete binary <b>predictor</b> <b>variable)</b> and the distance to treated areas (continuous <b>predictor</b> <b>variable).</b>|$|R
30|$|RP is a {{moderator}} and {{it affects}} the direction and/or strength {{of the relationship between}} a <b>predictor</b> <b>variable</b> and protective action.|$|R
5000|$|In {{the case}} where the {{independent}} (<b>predictor)</b> <b>variable</b> [...] is [...] and the dependent (outcome) variable is binary, Somers’ D equals ...|$|R
2500|$|In {{order for}} the lack-of-fit sum of squares to differ from the sum of squares of residuals, there must {{be more than one}} value of the {{response}} variable for {{at least one of the}} values of the set of <b>predictor</b> <b>variables.</b> [...] For example, consider fitting a line ...|$|E
2500|$|Errors-in-variables models (or [...] "measurement error models") {{extend the}} {{traditional}} linear regression model {{to allow the}} <b>predictor</b> <b>variables</b> X to be observed with error. This error causes standard estimators of β to become biased. Generally, the form of bias is an attenuation, meaning that the effects are biased toward zero.|$|E
2500|$|Scaling ecosystem-level GPP estimations {{based on}} eddy {{covariance}} measurements of net ecosystem exchange (see above) to regional and global values using spatial details of different <b>predictor</b> <b>variables,</b> such as climate variables and remotely sensed fAPAR or LAI {{led to a}} [...] terrestrial gross primary production of 123±8 Gt carbon (NOT carbon dioxide) per year during 1998-2005 ...|$|E
40|$|The Cox {{proportional}} hazards {{model is}} {{the most widely used}} survival prediction model for analysing time-to-event data. To measure the discrimination ability of a survival model the concordance probability index is widely used. In this work we studied and compared the performance of two different estimators of the concordance probability when a continuous <b>predictor</b> <b>variable</b> is categorised in a Cox proportional hazards regression model. In particular, we compared the c-index and the concordance probability estimator. We evaluated the empirical performance of both estimators through simulations. To categorise the <b>predictor</b> <b>variable</b> we propose a methodology which considers the maximal discrimination attained for the categorical variable. We applied this methodology to a cohort of patients with chronic obstructive pulmonary disease, in particular, we categorised the <b>predictor</b> <b>variable</b> forced expiratory volume in one second in percentage...|$|R
40|$|Previous {{deception}} {{research on}} repeated interviews found that liars are not less consistent than truth tellers, presumably because liars use a repeat strategy {{to be consistent}} across interviews. The goal {{of this study was}} to design an interview procedure to overcome this strategy. Innocent participants (truth tellers) and guilty participants (liars) had to convince an interviewer that they had performed several innocent activities rather than committing a mock crime. The interview focused on the innocent activities (alibi), contained specific central and peripheral questions, and was repeated after one week without forewarning. Cognitive load was increased by asking participants to reply quickly. The liars’ answers in replying to both central and peripheral questions were significantly less accurate, less consistent, and more evasive than the truth tellers’ answers. Logistic regression analyses yielded classification rates ranging from around 70 % (with consistency as the <b>predictor</b> <b>variable),</b> 85 % (with evasive answers as the <b>predictor</b> <b>variable),</b> to over 90 % (with an improved measure of consistency that incorporated evasive answers as the <b>predictor</b> <b>variable,</b> as well as with response accuracy as the <b>predictor</b> <b>variable).</b> These classification rates were higher than the interviewers’ accuracy rate (54 %) ...|$|R
40|$|The Cox proportionalhazards {{model is}} {{the most widely used}} su rvival {{prediction}} model for analysing time-to-event data. To measure the discrimination ability of a survival model the concordance probability index is widely used. In this work we studied and compared the performance of two different estimators of the concordance probability when a continuous <b>predictor</b> <b>variable</b> is cate- gorised in a Cox proportional hazards regression model. In p articular, we compared the c-index and the concordance probability estimator. We evaluated th e empirical performance of both es- timators through simulations. To categorise the <b>predictor</b> <b>variable</b> we propose a methodology which considers the maximal discrimination attained for th e categorical variable. We applied this methodology to a cohort of patients with chronic obstructiv e pulmonary disease, in particular, we categorised the <b>predictor</b> <b>variable</b> forced expiratory volu me in one second in percentagePeer Reviewe...|$|R
2500|$|Linearity. [...] This {{means that}} {{the mean of the}} {{response}} variable is a linear combination of the parameters (regression coefficients) and the <b>predictor</b> <b>variables.</b> [...] Note that this assumption is much less restrictive than it may at first seem. [...] Because the <b>predictor</b> <b>variables</b> are treated as fixed values (see above), linearity is really only a restriction on the parameters. [...] The <b>predictor</b> <b>variables</b> themselves can be arbitrarily transformed, and in fact multiple copies of the same underlying predictor variable can be added, each one transformed differently. [...] This trick is used, for example, in polynomial regression, which uses linear regression to fit the response variable as an arbitrary polynomial function (up to a given rank) of a predictor variable. This makes linear regression an extremely powerful inference method. [...] In fact, models such as polynomial regression are often [...] "too powerful", in that they tend to overfit the data. [...] As a result, some kind of regularization must typically be used to prevent unreasonable solutions coming out of the estimation process. [...] Common examples are ridge regression and lasso regression. [...] Bayesian linear regression can also be used, which by its nature is more or less immune to the problem of overfitting. (In fact, ridge regression and lasso regression can both be viewed as [...] special cases of Bayesian linear regression, with particular types of prior distributions placed on the regression coefficients.) ...|$|E
2500|$|Lack {{of perfect}} {{multicollinearity}} in the predictors. [...] For standard least squares estimation methods, the design matrix X must have full column rank p; otherwise, {{we have a}} condition known as perfect multicollinearity in the <b>predictor</b> <b>variables.</b> [...] This can be triggered by having two or more perfectly correlated <b>predictor</b> <b>variables</b> (e.g. if the same predictor variable is mistakenly given twice, either without transforming one of the copies or by transforming one of the copies linearly). It can also happen if there is too little data available compared {{to the number of}} parameters to be estimated (e.g. fewer data points than regression coefficients). In the case of perfect multicollinearity, the parameter vector β will be non-identifiable—it has no unique solution. [...] At most {{we will be able to}} identify some of the parameters, i.e. narrow down its value to some linear subspace of Rp. See partial least squares regression. [...] Methods for fitting linear models with multicollinearity have been developed; some require additional assumptions such as [...] "effect sparsity"—that a large fraction of the effects are exactly zero. Note that the more computationally expensive iterated algorithms for parameter estimation, such as those used in generalized linear models, do not suffer from this problem.|$|E
2500|$|Standard linear {{regression}} models with standard estimation techniques make {{a number of}} assumptions about the <b>predictor</b> <b>variables,</b> the response variables and their relationship. [...] Numerous extensions have been developed that allow each of these assumptions to be relaxed (i.e. reduced to a weaker form), {{and in some cases}} eliminated entirely. [...] Some methods are general enough that they can relax multiple assumptions at once, and in other cases this can ns. [...] Generally these extensions make the estimation procedure more complex and time-consuming, and may also require more data in order to produce an equally precise model.|$|E
3000|$|Diameter, as a <b>predictor</b> <b>variable,</b> {{recorded}} good accuracy metrics {{amongst the}} validation dataset. Prediction accuracy with D {{was better than}} prediction accuracy with V [...]...|$|R
3000|$|... 2 (or V), {{has been}} found to be a highly {{significant}} <b>predictor</b> <b>variable</b> in linear models. Yet the strength of the relationship between MOE and V [...]...|$|R
30|$|RP is a {{mediator}} and {{it accounts for}} the relationship between a <b>predictor</b> <b>variable</b> (e.g., other human factors) and protective action decision-making (See Section The mediator hypothesis).|$|R
2500|$|The {{notion of}} a [...] "unique effect" [...] is {{appealing}} when studying a complex system where multiple interrelated components influence the response variable. In some cases, it can literally be interpreted as the causal effect of an intervention that {{is linked to the}} value of a predictor variable. However, {{it has been argued that}} in many cases multiple regression analysis fails to clarify the relationships between the <b>predictor</b> <b>variables</b> and the response variable when the predictors are correlated with each other and are not assigned following a study design. A commonality analysis may be helpful in disentangling the shared and unique impacts of correlated independent variables.|$|E
2500|$|The very {{simplest}} case of {{a single}} scalar predictor variable x and a single scalar response variable y is known as simple linear regression. [...] The extension to multiple and/or vector-valued <b>predictor</b> <b>variables</b> (denoted with a capital X) is known as multiple linear regression, also known as multivariable linear regression. [...] Nearly all real-world regression models involve multiple predictors, and basic descriptions of linear regression are often phrased {{in terms of the}} multiple regression model. [...] Note, however, that in these cases the response variable y is still a scalar. Another term multivariate linear regression refers to cases where y is a vector, i.e., the same as general linear regression.|$|E
2500|$|A fitted linear {{regression}} {{model can be}} used to identify the relationship between a single predictor variable x'j and the response variable y when all the other <b>predictor</b> <b>variables</b> in the model are [...] "held fixed". Specifically, the interpretation of β'j is the expected change in y for a one-unit change in x'j when the other covariates are held fixed—that is, the expected value of the partial derivative of y with respect to x'j. This is sometimes called the unique effect of x'j on y. In contrast, the marginal effect of x'j on y can be assessed using a correlation coefficient or simple {{linear regression}} model relating only x'j to y; this effect is the total derivative of y with respect to x'j.|$|E
5000|$|Suppose {{that the}} <b>predictor</b> <b>{{variable}}</b> [...] takes three values, , , or , and outcome variable [...] takes two values, [...] or [...] The table below contains observed combinations of [...] and : ...|$|R
3000|$|... {{involves}} a response variable Y {{and more than}} one <b>predictor</b> <b>variable.</b> It addresses questions about the relationship between a set of independent variables and a dependent variable. The general equation is written as Y[*]=[*]b [...]...|$|R
30|$|The Awareness and Perception {{variables}} {{showed a}} statistical significant {{relationship with the}} <b>predictor</b> <b>variable</b> CLAS. These results are not surprising since {{it is expected that}} upper division students would have had more experiences related to research than freshmen or sophomores.|$|R
