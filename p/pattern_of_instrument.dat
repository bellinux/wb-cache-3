1|10000|Public
40|$|Abstract. A {{new model}} of university-enterprise {{cooperation}} is explored. As a case, the building energy saving test qualification is declared jointly by the university and enterprise. The key making the success of cooperation is fully guaranteeing the core benefit of both parties. Using the <b>pattern</b> <b>of</b> <b>instrument</b> and equipment and the teacher's professional technical knowledge as the shares and enterprise is responsible for business and market to develop. It can fully arouse the enthusiasm of both university and enterprise. In the process of cooperation, the discipline and team construction level of the university has been improved, and the efficiency of enterprises has been increased. This will become the outward service platform and the resources sharing are realized...|$|E
40|$|The SPARC Data Initiative aims {{to produce}} trace gas climatologies {{for a number}} of species from a number <b>of</b> <b>instruments.</b> In order to {{properly}} compare these climatologies, and interpret differences between them, it is necessary to know the uncertainty in each calculated climatological mean field. The inhomogeneous and finite temporal-spatial sampling <b>pattern</b> <b>of</b> each <b>instrument</b> can lead to biases and uncertainties in the mean climatologies. Sampling which is unevenly weighted in time and space leads to biases between a data set's climatology and the truth. Furthermore, the systematic sampling <b>patterns</b> <b>of</b> some <b>instruments</b> may mean that uncertainties in mean fields calculated through traditional methods that assume random sampling may be inappropriate. We aim to address these issues through an exercise wherein high resolution chemical fields from a coupled Chemistry Climate Model are sub-sampled based on the sampling <b>pattern</b> <b>of</b> each <b>instrument.</b> Climatologies based on the sub-sampled data can be compared to those calculated with the full data set, in order to assess sampling biases. Furthermore, investigating the ensemble variability of climatologies based on subsampled fields will allow us to assess the proper methodology for estimating the uncertainty in climatological mean fields...|$|R
5000|$|Many wind {{instruments}} {{have some}} kind of flaring bell shape. These are generally not exponential in configuration, and are used to modify the standing wave <b>patterns</b> <b>of</b> the <b>instrument,</b> and thereby the musical notes which can be produced.|$|R
40|$|Static {{directivity}} <b>patterns</b> <b>of</b> musical <b>instruments</b> {{have been}} mapped somewhat extensively, but {{little research has}} been done in analyzing the directivity <b>patterns</b> <b>of</b> musical <b>instruments</b> over time as they play. Directivity patterns can be affected by variables such as instrument, frequency, dynamics, and style. This thesis proposes a set of quantification methods of time varying directivity, all derived from the maximum Directivity Index analyzed at consecutive short-duration time windows comprising the musical excerpt. The instrumental recordings used in this paper are taken in an anechoic chamber using either a 5, 13, or 32 multichannel setup. From the values of maximum Directivity Index evaluated using the windowing technique, quantifiers including Average Maximum Directivity Index, Average Change in Maximum Directivity Index, Location Change Ratio, Dominance Ratio, and Dominating Location are calculated. In addition to establishing time varying directivity metrics, this thesis looks at how factors such as instrument family, orchestral excerpt, and number of microphone channels used in data acquisition affect the values of the proposed metrics. The importance of understanding time varying directivity <b>patterns</b> <b>of</b> musical <b>instruments</b> as well as architectural acoustic applications connected to this research are also discussed. Advisor: Lily M. Wan...|$|R
40|$|International audienceIn reverberant {{acoustic}} environments {{the perception}} of timbre at a listeners position depends on the radiation characteristics of the sound source. Numerous {{studies have shown that}} radiation <b>patterns</b> <b>of</b> acoustic <b>instruments</b> vary with frequency and time. Thus, one area of large concern that is a topic of ongoing research is the measurement, reproduction, and compact description of sound source radiation patterns. A simple and efficient physical model for calculating the directional <b>pattern</b> <b>of</b> woodwind <b>instruments</b> with curved tubes is presented in this study. It calculates the far-field sound pressure on a sphere surrounding the instrument, also taking into account the directivity of the openings (holes and the bell). Simulation results are compared to the radiation <b>patterns</b> <b>of</b> a saxophone measured in an anechoic chamber with a surrounding spherical microphone array...|$|R
40|$|A {{survey of}} {{agricultural}} price and trade policy <b>instruments</b> <b>of</b> Central European countries {{since the beginning}} of economic transition indicates several similar <b>patterns</b> <b>of</b> <b>instrument</b> choice among the transition economies. We find that the common <b>pattern</b> <b>of</b> agricultural policy choices in Central European countries mirrors many important features of the Western European experience. In addition, we also find that free trade associations and international agreements have and will increasingly limit the set of agricultural price and trade policy instruments available to governments. We would like to thank Goedele De Nolf for research assistance. We gratefully acknowledge financial support from the FAIR 1995 Programme of the EU Commission (No. FAIR 1 -CT 95 - 0029) and from the Belgian National Science Foundation (NFWO). This paper has benefited from comments of Harry de Gorter, Erik Mathijs, and Mona Habash. All views expressed and any remaining errors are our responsibilit...|$|R
5000|$|The {{instruments}} used {{to measure}} orange peel simulate visual perception. Like our eyes, the instruments optically scan the wavy light/dark <b>pattern.</b> Two types <b>of</b> <b>instruments</b> are available to quantify the texture or waviness of a surface: ...|$|R
5000|$|Ben Harper - 3 × Overdrive Specials (50w head + 2×12" [...] Cabinet, 100/50w 1×12" [...] Combo, 100/40w Head + {{matching}} 1×12" [...] Cabinet) [...] In March 2016, Harper {{explained that}} Dumble had him plug his guitar {{directly into the}} oscilloscope, {{in order to take}} notes about how the frequency <b>patterns</b> <b>of</b> Harper's <b>instruments</b> was shaped and voice his Overdive Special accordingly.|$|R
40|$|The {{spread of}} {{privatization}} {{in almost every}} country {{over the last decade}} reflects a rapid and fundamental change in <b>patterns</b> <b>of</b> policy <b>instrument</b> usage. Yet the literature on policy instruments has almost nothing to say on this perhaps most significant development in public policy in recent times. This paper's objective is to aid {{in the development of a}} theory <b>of</b> policy <b>instrument</b> choice which is capable of dealing with instances of long-term, cross-national changes in policy instrument usage. It will be argued that reconceptualization <b>of</b> <b>instrument</b> choices in terms of policy learning can aid in this theoretical project. Copyright 1993 by The Policy Studies Organization. ...|$|R
40|$|In {{order to}} {{facilitate}} the coincidence calculations, the coordinates {{of the ship and}} the satellite were transformed to the ECO system in which the equatorial plane is the plane of the satellite's orbit. The transformation matrices for each step are presented. The ship could be observed when it was in a band about the equator in the ECO system. The width of the band was determined by the scan <b>pattern</b> <b>of</b> the <b>instrument...</b>|$|R
40|$|International audienceThe {{directionality}} of the radiated {{sound is}} very specific to each musical instrument. The underlying radiation mechanisms may, for instance, {{depend on the}} structure of the vibrating body (e. g., string and percussion instruments) or on the spatial distribution of the opening holes (e. g., bells and open finger holes for wind instruments). A good knowledge <b>of</b> the radiation <b>pattern</b> <b>of</b> <b>instruments</b> is essential for many applications, such as orchestration, room acoustics, microphone techniques for live sound and recording, and virtual acoustics. In the first part, we will review previous works on sound source radiation measurement and analysis, discuss the underlying acoustic principles, and try to identify common mechanisms of radiation in musical instruments. In the second part, we will illustrate various projects undertaken at IRCAM and dedicated to the measurement and modeling of the directivity <b>of</b> <b>instruments,</b> to the objective and perceptual characterization of room acoustics, and to the real-time synthesis of virtual source radiation for musical performances. For this latter, several approaches are discussed according to the underlying physical formalisms and associated electroacoustic setups (e. g., spherical loudspeaker arrays, wave field synthesis) ...|$|R
5000|$|The berimbau toques {{follow the}} <b>pattern</b> <b>of</b> the {{supporting}} <b>instruments,</b> {{but with a}} broad arena for improvising. The above on syncopation also follows with the berimbau. In {{the case of the}} Angola toque (the half notes below in this case represent unmuted quarter notes): ...|$|R
50|$|Canter time, canter timing or canter rhythm is a two-beat regular rhythmic <b>pattern</b> <b>of</b> {{a musical}} <b>instrument</b> or in dance steps within 3/4 time music. The term is {{borrowed}} from the canter horse gait, which sounds three hoof beats followed by a pause, i.e., 3 accents in 4/4 time.|$|R
50|$|Timba rhythm {{sections}} {{differ from}} their salsa counterparts in many integral ways from the instruments themselves, {{to the individual}} <b>patterns</b> <b>of</b> each <b>instrument,</b> to the way those patterns are combined into gears, {{to the way the}} group navigates between those gears. The areas where salsa and timba are most similar are the tempo range and the part of the largest bell, played by the bongosero in salsa and, depending on the band, by either the bongosero, timbalero or drummer in timba.|$|R
30|$|CinBalada is {{a system}} for {{automatic}} creation of polyphonic rhythmic performances by mixing elements from different musical styles. This system is based on agents that act as musicians playing percussion instruments in a drum circle. Each agent has to choose from a database the rhythm <b>pattern</b> <b>of</b> its <b>instrument</b> that satisfies the “rhythmic role” assigned to him {{in order to produce}} a collectivelyconsistent rhythmic performance. A rhythmic role is a concept that we proposed here with the objective of representing culture-specific rules for creation of polyphonic performances.|$|R
40|$|Abstract. This paper {{presents}} a new sparse representation for polyphonic music signals. The {{goal is to}} learn the time-varying spectral <b>patterns</b> <b>of</b> musical <b>instruments,</b> such as attack of the piano or vibrato of the violin in polyphonic music signals without any prior information. We model the spectrogram of music signals {{under the assumption that}} they are composed of a limited number of components which are composed <b>of</b> Markov-chained spectral <b>patterns.</b> The proposed model is an extension of nonnegative matrix factorization (NMF). An efficient algorithm is derived based on the auxiliary function method...|$|R
40|$|This study {{examines}} sets of original English performing material for concerted music – for instruments and voices together – {{during the period}} c. 1660 to 1800. Sets of original performing materials have been neglected as sources despite the advantages they offer over full scores in some respects, and as a resource in both historical and performance practice studies despite the wealth of information they offer on a diverse range of subjects. These include creative practices in the early musical ode; ensemble size and composition and <b>patterns</b> <b>of</b> <b>instrument</b> use in late seventeenth-century and eighteenth-century concerted music; seventeenth- and eighteenth century copying practices and data on copyists; and ensemble-leading practice. Parts can also include notated examples of ‘free’ ornamentation such as cadenzas and data such as names of performers. A series of case studies examines the performing sets of the Oxford Music School of 1660 to c. 1713, under the successive professorships of Edward Lowe and Richard Goodson senior; the surviving performing parts linked to G. F. Handel, and other eighteenth-century performing sets for his music; the parts for the court odes of William Boyce; and the performing sets for Boyce’s other works. Changes in both the physical appearance of the sets and the copying processes that produced them, and in the performance practice they reveal, such as ensemble size and <b>patterns</b> <b>of</b> woodwind use, are tracked throughout the period. ...|$|R
40|$|Four bearing assemblies, {{lubricated}} with Apiezon C {{oil with}} 5 % lead naphthenate (PbNp), were life tested {{in support of}} the Advanced Microwave Sounding Unit-A (AMSU-A). These assemblies were tested continuously for five to six years using the scanning <b>pattern</b> <b>of</b> the flight <b>instrument.</b> A post-life-test analysis was performed on two of the assemblies to evaluate the lubricant behavior and wear in the bearings...|$|R
30|$|There {{have been}} some {{attempts}} in literature to TF quantification by removing the redundancy and keeping only the representative parts of the TFD. In [9], the authors consider the TF representation of music signals as texture images, and then they look for the repeating <b>patterns</b> <b>of</b> a given <b>instrument</b> as the representative feature <b>of</b> that <b>instrument.</b> This approach is useful for music signals; however, it is not very efficient for environmental sound classification, where we can not assume the presence of such a structured TF patterns.|$|R
40|$|A {{method for}} Binaural In-Ear Monitoring (Binaural IEM) <b>of</b> {{acoustic}} <b>instruments</b> in live music is presented. Spatial rendering {{is based on}} four considerations: the directional radiation <b>patterns</b> <b>of</b> musical <b>instruments,</b> room acoustics, binaural synthesis with Head-Related Transfer Functions (HRTF), and the movements of both the musician's head and <b>instrument.</b> The concepts <b>of</b> static and dynamic sound mixes are presented and discussed according to the emotional involvement and musical <b>instruments</b> <b>of</b> the performers, {{as well as the}} use of motion capture technology. Pilot experiments of BIEM with dynamic mixing were done with amateur musicians performing with wireless headphones and a motion capture system in a small room. Listening tests with professional musicians evaluating recordings under conditions of dynamic sound mixing were carried out, attempting to find an initial reaction to BIEM. Ideas for further research in static sound mixing, individualized HRTFs, tracking techniques, as well as wedge-monitoring schemes are suggested. QC 20130204 </p...|$|R
40|$|Within the {{framework}} of the cooperation between TU Ilmenau, the Fraunhofer Institute for Digital Media Technology (IDMT) and TU Delft, new sound recording concepts are developed dedicated to sound reproduction by Wave Field Synthesis (WFS). It is intended to also take the directivity characteristics <b>of</b> musical <b>instruments</b> into account in this process, instead <b>of</b> representing these <b>instruments</b> as omnidirectional point sources or plane wave generators, as usual in WFS practice until now. As an introductory experiment, the frequency-dependent directivity <b>patterns</b> <b>of</b> five brass <b>instruments,</b> together forming a quintet, have been measured in an anechoic chamber and in a studio by means of a circularly arranged microphone setup. Characteristics have been recorded <b>of</b> the individual <b>instruments</b> {{as well as of the}} ensemble. The data give ample information about the influence of the acoustic environment on the recorded radiation properties <b>of</b> the different <b>instruments,</b> as a functio n of frequency and radiation angle. Besides, the data give insight inhowfar the radiation <b>pattern</b> <b>of</b> a group <b>of</b> <b>instruments</b> can be resynthesized from the characteristics <b>of</b> the individual <b>instruments</b> in the two researched environments. In the paper it will also be considered how the results can be implemented in WFS music reproduction...|$|R
40|$|In {{this paper}} {{high-quality}} model-based sound synthesis of plucked string and woodwind instruments {{is combined with}} room simulation and auralization techniques. The result is a real-time virtual three-dimensional room where the listener and multiple virtual instruments can be moved. The system was designed using signal processors in a multiprocessing environment. Sound radiation <b>patterns</b> <b>of</b> musical <b>instruments</b> were measured and direction-dependent filtering was applied to instrument simulation models. Auralization is achieved by measuring and using head-related transfer functions. The binaural three-dimensional audio output of the virtual environment is directed to headphone listening. The environment is controlled by a mouse-operated user interface while the virtual instruments are played via MIDI. 1 Introduction Digital waveguide and delay line modeling of wave propagation has been an interesting and rewarding field in computer music technology. Artificial reverberation gene [...] ...|$|R
40|$|European {{governments have}} {{during the last}} couple of decades shown an {{interest}} in new types <b>of</b> environmental policy <b>instruments</b> (EPIs) such as environmental taxes, tradable permit schemes and voluntary approaches, as opposed to relying on traditional forms of regulation. The interest in so-called ‘new’ EPIs (NEPIs) has led many governments to commit both to a more diverse EPI mix and to a policy process characterised by procedural rationality, in terms of considering a wide range <b>of</b> alternative <b>instruments</b> and assessing them in a systematic and transparent way. The first aim of this thesis is to examine the success of the quest for NEPIs at the national level in the field of municipal waste policy in two countries; the UK (England) and Sweden. In addition to mapping out EPI diversity, two contrasting theories on the <b>pattern</b> <b>of</b> adoption <b>of</b> <b>instruments</b> over time are evaluated, specifically focusing on the degree of coercion associated with EPIs. It is found that the waste policy mix in England has become more diverse, while the Swedish mix is characterised by a higher degree of coercion. The second aim is to analyse whether the instrument choice process has become more procedurally rational, and, if so, conducive to the adoption of NEPIs. A range <b>of</b> <b>instrument</b> choice theories at the macro-, meso- and micro-levels drawn from the public policy and political science literature are used to explain whether the ideal of procedural rationality is achievable or not. A case study methodology is used, in which the processes leading to the landfill allowance trading scheme (LATS) in England and and the waste incineration tax in Sweden are studied. It is found that the procedural rationality was higher in the England case, but {{that it is not a}} necessary nor sufficient cause for adoption of a NEPI...|$|R
40|$|This paper {{presents}} a new extension to the variable duration Hid-den Markov model, capable of classifying musical pattens {{that have been}} extracted from raw audio data, into a set predefined classes. Each musical pattern is converted into a sequence of music inter-vals {{by means of a}} fundamental frequency tracking procedure and it is subsequently given as input to a set of variable duration Hidden Markov models. Each of these models has been trained to recognize <b>patterns</b> <b>of</b> the respective predefined class. Classification is deter-mined based on the highest recognition probability. This new type of variable duration Hidden Markov model provides increased clas-sification accuracy because a) it deals effectively with errors orig-inating during the feature extraction stage and b) it accounts for variations due to the expressive performance <b>of</b> <b>instrument</b> players. To demonstrate its effectiveness, the novel classification scheme has been employed in the context of Greek traditional music, to mono-phonic musical <b>patterns</b> <b>of</b> a popular <b>instrument,</b> the Greek Tradi-tional clarinet. The classification results demonstrate that the new approach outperforms previous work based on conventional Hidden Markov models. 1...|$|R
40|$|Because of {{interactions}} between the signal processing and acoustic input, cochlear implant (CI) users’ melodic pitch perception {{may be influenced by}} instrument timbre. In the present study, CI listeners’ melodic contour identification was measured for six instruments (organ, glockenspiel, trumpet, clarinet, violin, and piano). While performance was generally best with the organ and poorest with the piano, individual CI subjects exhibited different <b>patterns</b> <b>of</b> results across <b>instruments.</b> CI subjects with the most music experience were less susceptible to timbre effects, suggesting that music training may help less experienced CI users extract melodic pitch from a variety of sound sources...|$|R
40|$|The paper {{presents}} a time-series-based classification approach to identify similarities in pairs <b>of</b> simulated human-generated <b>patterns.</b> An example for a pattern is a time-series representing a heart rate during a specific time-range, wherein the time-series is {{a sequence of}} data points that represent {{the changes in the}} heart rate values. A bio-medical simulator system was developed to acquire a collection of 7, 871 price <b>patterns</b> <b>of</b> financial <b>instruments.</b> The financial instruments traded in real-time on three American stock exchanges, NASDAQ, NYSE, and AMEX, simulate bio-medical measurements. The system simulates a human in which each price pattern represents one bio-medical sensor. Data provided during trading hours from the stock exchanges allowed real-time classification. Classification is based on new machine learning techniques: self-labeling, which allows the application of supervised learning methods on unlabeled time-series and similarity ranking, which applied on a decision tree learning algorithm to classify time-series regardless of type and quantity. Comment: arXiv admin note: text overlap with arXiv: 1303. 007...|$|R
40|$|International audienceSurrounding spherical {{microphone}} arrays {{can capture}} the radiation <b>pattern</b> <b>of</b> sound sources placed inside the array. Depending {{on the exact}} positioning of the sound source, the obtained measurement results vary, as amplitude and phase differences arise due to the different traveling time of the radiated sound. Using the spherical harmonic decomposition of the sound field, it is noticeable that displaced sound sources need a much higher number of modal components for an accurate description. As surrounding spherical microphone arrays are severely limited in their spatial resolution correct centering is crucial for higher frequencies. In practice, however, a precise alignment to the physical center of the array is impossible. With the help of re-alignment algorithms {{it is possible to}} virtually shift the sound source {{to the center of the}} array to allow a more accurate description in the spherical harmonic domain. Alternatively, a magnitude only approach can be employed, resulting in a more robust representation regarding incorrect centering in the array. In this contribution different post-processing strategies are presented with the goal to provide directivity <b>patterns</b> <b>of</b> musical <b>instruments</b> for application in both measurement and simulation...|$|R
40|$|In most languages, {{nominals}} generally {{occur with}} a determiner. In contrast, musical instrument constructions in Dutch {{can often be}} bare: {{not just in the}} presence of a verb, noun or preposition, but also on their own in subject position. Musical instrument constructions that are not bare are also interesting. The non-bare noun phrase can denote more than just the physical object: for example, it can also denote the music being made by an instrument. We have looked at referential and lexical properties of nouns in general, and showed how a referential and a lexical framework can account for the <b>patterns</b> <b>of</b> determination <b>of</b> musical <b>instrument</b> nouns. We propose a lexical structure modified from Pustejovsky (1995), where his qualia structure is replaced by relational properties, that are not tied to specific lexical items. These relational properties involve the relation between the arguments of a lexical item. For musical instruments, the relation between the two arguments, physical object and the music is an agentive relation, since the physical object is needed to produce the music. Our structure can account for the <b>patterning</b> <b>of</b> musical <b>instrument</b> constructions in Dutch. Constructions that cannot be bare denote one of the arguments (i. e. the physical object or the music), constructions that are obligatorily bare denote the agentive reading of the relational properties. Finally, constructions that can both occur bare and non-bare refer to either the music or the agentive reading...|$|R
40|$|Climatologies of {{atmospheric}} observations are often produced by binning measurements according to latitude and calculating zonal means. The uncertainty in these climatological means is characterised {{by the standard}} error of the mean (SEM). However, the usual estimator of the SEM, i. e., the sample standard deviation divided by the square root of the sample size, holds only for uncorrelated randomly sampled measurements. Measurements of the atmospheric state along a satellite orbit cannot always be considered as independent because (a) the time-space interval between two nearest observations is often smaller than the typical scale of variations in the atmospheric state, and (b) the regular time-space sampling <b>pattern</b> <b>of</b> a satellite <b>instrument</b> strongly deviates from random sampling. We have developed a numerical experiment where global chemical fields from a chemistry climate model are sampled according to real sampling <b>patterns</b> <b>of</b> satellite-borne <b>instruments.</b> As case studies, the model fields are sampled using sampling <b>patterns</b> <b>of</b> the Michelson Interferometer for Passive Atmospheric Sounding (MIPAS) and Atmospheric Chemistry Experiment Fourier-Transform Spectrometer (ACE-FTS) satellite instruments. Through an iterative subsampling technique, and by incorporating information on the random errors of the MIPAS and ACE-FTS measurements, we produce empirical estimates of the standard error of monthly mean zonal mean model O 3 in 5 ° latitude bins. We find that generally the classic SEM estimator is a conservative estimate of the SEM, i. e., the empirical SEM is often less than or approximately equal to the classic estimate. Exceptions occur only when natural variability {{is larger than the}} random measurement error, and specifically in instances where the zonal sampling distribution shows non-uniformity with a similar zonal structure as variations in the sampled field, leading to maximum sensitivity to arbitrary phase shifts between the sample distribution and sampled field. The occurrence of such instances is thus very sensitive to slight changes in the sampling distribution, and to the variations in the measured field. This study highlights the need for caution in the interpretation of the oft-used classically computed SEM, and outlines a relatively simple methodology {{that can be used to}} assess one component of the uncertainty in monthly mean zonal mean climatologies produced from measurements from satellite-borne instruments...|$|R
40|$|Investigations {{under way}} in this {{laboratory}} required a microrespirometer {{which could be used}} for a considerable period of time in one set of measurements, and which also avoided some of the difficulties of manipulation encountered with previous models (Cunningham and Kirk, 1940; Barth and Kirk, 1942). Accordingly, an instrument was designed and built which had the following advantages as compared with earlier models: (1) It was more rapidly and conveniently assembled without leakage; (2) it could be employed for measurements over a longer time without opening; and (3) less difficulty was encountered in adjusting the indicator droplet. In addition, it was designed to allow operation with controlled gas mixtures and mixing of reagents after sealing. These were features of the one earlier model (Cunningham and Kirk, 1940) which were not present in the simplified form described later (Barth and Kirk, 1942). The basic <b>pattern</b> <b>of</b> the <b>instrument</b> {{is similar to that of}} Barth and Kirk (1942), the chief deviations from that design being a different method of sealing, a considerably longer capillar...|$|R
40|$|International audienceRoom {{acoustic}} simulation algorithms {{have evolved}} to powerful tools in recent years. Additionally to traditional tasks, such as prediction of room acoustic parameters (e. g. reverberation time, strength etc.), they are commonly used for auralizations nowadays. For a lively and natural virtual representation of real sound sources, {{it is important to}} include their individual characteristics in terms <b>of</b> directivity <b>patterns</b> and spatial dynamics. For a high quality auralization of a full orchestra, the radiation <b>patterns</b> <b>of</b> symphonic <b>instruments</b> were captured using a surrounding spherical array and stored in the free openDaff directional file format. Using a hybrid image sources and ray tracing method, room impulse responses (IRs) were calculated for each orchestra instrument. The players movements were simulated by applying an artificial humanization to the position and orientation vectors. The simulation generates binaural signals as well as spatial impulse responses in spherical harmonics (SH) format, which can then be convolved with anechoic recordings of each part. Using the flexible SH representation and head-tracking, a dynamical and immersive auralization can be achieved that reacts on the listeners head movements...|$|R
40|$|The {{automatic}} {{extraction of}} the notes that were {{played in a}} digital musical signal (automatic music transcription) is an open problem. A number of techniques have been applied to solve it without concluding results. This work tries to pose it through the identification <b>of</b> the spectral <b>pattern</b> <b>of</b> a given <b>instrument</b> in the signal spectrogram using time-delay neural networks. We will work in the monotimbrical polyphonic version of the problem: more than one note can sound {{at the same time}} but always played by just one instrument. Our purpose is to discover wether a neural network fed only with an spectrogram can detect the notes of a polyphonic music score. In this paper our preliminary but promising results using synthetic instruments are presented. ...|$|R
40|$|Background/purpose: The {{assessment}} of colors {{is essential for}} melanoma (MM) diagnosis, both for pattern analysis on dermoscopic images, and when using semiquantitative methods. Our aim {{was to provide a}} simple, precise characterization and reproducible calibration of the color response for dermoscopic instruments. Methods: Three processes were used to correct the non-uniform illumination <b>pattern</b> <b>of</b> the <b>instrument,</b> to easily estimate the camera gamma settings and to describe the color space conversion matrices required to produce standard images, in any color space. A specific color space was also developed to optimize the representation of dermatoscopic colors. The calibration technique was tested both on synthetic reference surfaces and on real images by comparing the difference between the images colors obtained with two different equipments. Results: The differences between the images acquired by means <b>of</b> the two <b>instruments,</b> calculated on the reference patterns after calibration, were up to 10 times lower then before, while comparison of histograms referring to real images provided an improvement of about seven times on average. Conclusions: A complete workflow for dermatologic image calibration, which allows the user to continue using his own software and algorithms, but with a much higher informative content, is presented. The technique is simple and may improve cooperation between different research centers, in teleconsulting contexts or for result comparisons...|$|R
40|$|The timing <b>of</b> rhythm section <b>instruments</b> in prototypical {{early period}} funk and jazz-funk tracks (1967 - 1971) was {{investigated}} in order to gauge to what extent ‘swing’ might be a vital rhythmic quality in funk-based grooves. Swing was defined as consecutive note pairings of the same subdivision level with long-short ratios between on- and off-beat equal to or higher than a theoretical threshold of 1. 2 : 1. Sixteenth notes <b>of</b> <b>instruments</b> were measured {{both in terms of}} overall swing per measure (‘global’ mean swing) as well as per sixteenth-note pair (‘local’ mean swing). In nearly all excerpts analysed (twelve out of thirteen), either global or local swing was found in at least one instrument. Such findings suggest that {{it is not so much}} the clear-cut use of regular swinging subdivisions that seems to define the general microrhythmic character of classic funk grooves, but rather a subtle juxtaposition of straight and swung sixteenths which is manifested both within the fluctuating local swing <b>patterns</b> <b>of</b> single individual <b>instruments,</b> as well between the interaction of globally swinging and non-swinging <b>instruments</b> <b>of</b> the rhythm section. Utilizing the empirical results from the swing analyses, various ways in which swung sixteenth-note pickups and syncopation gestures may be perceived to interact with virtual referential metric structures, as well as counter-rhythmic patterns, were explored in light of interpretive and affective rhythmic theories of jazz and funk...|$|R
40|$|The use of {{high-density}} loudspeaker arrays (HDLAs) {{has recently}} experienced {{rapid growth in}} a wide variety of technical and aesthetic approaches. Still less explored, however, are applications to interactive music with live acoustic instruments. How can immersive spatialization accompany an instrument already with its own rich spatial diffusion pattern, like the grand piano, in the context of a score-based concert work? Potential models include treating the spatialized electronic sound in analogy to the diffusion <b>pattern</b> <b>of</b> the <b>instrument,</b> with spatial dimensions parametrized as functions of timbral features. Another approach is to map the concert hall as a three-dimensional projection <b>of</b> the <b>instrument’s</b> internal physical layout, a kind of virtual sonic microscope. Or, the diffusion of electronic spatial sound can be treated as an independent polyphonic element, complementary to but not dependent upon the instrument’s own spatial characteristics. Cartographies (2014), for piano with two performers and electronics, explores each of these models individually and in combination, as well as their technical implementation with the Meyer Sound Matrix 3 system of the Su ̈ dwestrundfunk Experimentalstudio in Freiburg, Germany, and the 43. 4 -channel Klangdom of the Institut fu ̈ r Musik und Akustik at the Zentrum fu ̈ r Kunst und Media in Karlsruhe, Germany. The process of composing, producing, and performing the work raises intriguing questions, and invaluable hints, for the composition and performance of live interactive works with HDLAs in the future...|$|R
40|$|The piano was an {{important}} cultural symbol in colonial New Zealand, yet {{although there is a}} significant body of international scholarship on the social and cultural history <b>of</b> the <b>instrument</b> in Britain, America, Canada, Norway, Spain and India there is a dearth of scholarly criticism relating to New Zealand. Research to redress this absence has revealed that the piano was central to settler culture, demonstrating a migrant desire to replicate the known and familiar but also highlighting settler innovations and an emerging nationalism. International connections between New Zealand, Britain, Western Europe, America and Australia are also apparent in relation to migrant <b>patterns,</b> the importation <b>of</b> <b>instruments</b> and sheet music and networks of musical performance and study. The instrument {{played a role in the}} complex dynamic of cultural encounter between Maori and settler, with an initial indigenous negativity and bemusement giving way to an interest in the piano and an appropriation <b>of</b> the <b>instrument</b> into Maori cultural contexts and spaces, including the marae. Prevailing perceptions of gender roles and identity are also challenged by research on the piano. Likewise, an examination of piano and class reveals that the instrument was popular with New Zealanders from all socio-economic backgrounds...|$|R
