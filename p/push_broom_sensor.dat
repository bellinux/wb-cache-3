5|88|Public
40|$|This {{research}} {{presents a}} method of rectification for the image flow acquired by UAV. The sensor on the UAV is a multi-channel <b>push</b> <b>broom</b> <b>sensor.</b> The linear array can cover a stripe with approximately 6 Km on the ground. The motions (roll, pitch, yaw, etc) of the UVA platform {{are influenced by the}} relatively low-altitude flying so that have the attitude changed which are terrible to produce severe distortion of image. Therefore, a three-step rectification method is developed by means of the DEM and GCPs (ground control points) of study area, as well as data of the positioning instruments (GPS, INS) on the UVA platform. Firstly, The external orientation parameters (position, attitude, six for each image line) of each linear array are calculated with data provided by the positioning instruments (GPS, INS), and then, the collinearity equation for multi-lens sensors is adopted with combining with the DEM data, therefore, the original image can be rectified to level one (L 1) image, which meets the requirements for accepted visibility. Secondly, a reference image is used and several GCPs are selected in order to produce Level two (L 2) image with enhanced polynomials. The third step of the rectification is an essential process using partial distortion model which geometrically stretch the local image. Many experiments have been carried out in different conditions and areas using the method mentioned above. The results present the three step rectification is feasible and effective...|$|E
40|$|Hard bottom marine biocoenoses {{constitute}} one of {{the most}} important and productive ecosystems in the world. The continuous observation of these complex systems is therefore of major international relevance in times of global environmental change. The marine nature reserve of the island of Helgoland is located in the German part of the southern North Sea and comprises a large amount of the species representative for Northern European rocky coasts. The recording of spatial changes of the major intertidal biotopes by remote sensing techniques provides a tool to assess biodiversity change on a high hierarchical level and enables a synoptic view of the system. This complements detailed ground based biodiversity studies which are traditionally restricted in area and serves as basis for decisions, e. g. in coastal zone management, nature preservation, and monitoring of the water quality. In July 2002 and September 2003, two data sets of Heligolands coast were acquired with the hyperspectral <b>push</b> <b>broom</b> <b>sensor</b> ROSIS at about 1 m pixel size. The data were radiometrically, atmospherically, and geometrically corrected. Based on ground truth data and detailed spectral analysis, a supervised hierarchical classification scheme was developed to classify the different major biotopes of the intertidal zone which are rather small and often overlap, thus creating a complex spatial picture difficult to resolve. Comparison between the 2002 and 2003 data shows the potential and the limitations of this spectral approach and suggestions for improvement are presented. The difference in results between the hyperspectral classification of the biotopes and a recent ground based biotope mapping will be discussed...|$|E
40|$|In this study, we assess two {{push broom}} hyper{{spectral}} sensors as carried by small (10 – 15  kg) multi-rotor Unmanned Aircraft Systems (UAS). We used a Headwall Photonics micro-Hyperspec <b>push</b> <b>broom</b> <b>sensor</b> with 324 spectral bands (4 – 5  nm FWHM) and a Headwall Photonics nano-Hyperspec sensor with 270 spectral bands (6  nm FWHM) {{both in the}} VNIR spectral range (400 – 1000  nm). A gimbal was used to stabilise the sensors {{in relation to the}} aircraft flight dynamics, and for the micro-Hyperspec a tightly coupled dual frequency Global Navigation Satellite System (GNSS) receiver, an Inertial Measurement Unit (IMU), and Machine Vision Camera (MVC) were used for attitude and position determination. For the nano-Hyperspec, a navigation grade GNSS system and IMU provided position and attitude data. This study presents the geometric results of one flight over a grass oval on which a dense Ground Control Point (GCP) network was deployed. The aim being to ascertain the geometric accuracy achievable with the system. Using the PARGE software package (ReSe – Remote Sensing Applications) we ortho-rectify the push broom hyperspectral image strips and then quantify the accuracy of the ortho-rectification by using the GCPs as check points. The orientation (roll, pitch, and yaw) of the sensor is measured by the IMU. Alternatively imagery from a MVC running at 15  Hz, with accurate camera position data can be processed with Structure from Motion (SfM) software to obtain an estimated camera orientation. In this study, we look at which of these data sources will yield a flight strip with the highest geometric accuracy...|$|E
50|$|<b>Push</b> <b>broom</b> <b>sensors</b> {{either have}} a {{sufficiently}} large IFOV, or the scan moves fast enough {{with respect to}} the forward speed of the sensor platform, that an entire swath width is recorded without movement artifacts. These sensors are also known as survey or wide field devices, comparable to wide angle lenses on conventional cameras.|$|R
50|$|In orbital <b>push</b> <b>broom</b> <b>sensors,</b> a line {{of sensors}} {{arranged}} perpendicular to the flight direction of the spacecraft is used. Different areas of the surface are imaged as the spacecraft flies forward. A <b>push</b> <b>broom</b> scanner can gather more light than a whisk broom scanner because it looks at a particular area for a longer time, like a long exposure on a camera. One drawback of pushbroom sensors is the varying sensitivity of the individual detectors. These sensors are also known as survey or wide field devices, comparable to wide angle lenses on conventional cameras.|$|R
40|$|The present {{technology}} {{does not}} permit the 7 -m CCD <b>push</b> <b>broom</b> optical <b>sensor</b> to image a region of 70 km. Therefore the IRS [...] 1 C satellite use three separate 4096 CCD <b>push</b> <b>broom</b> optical <b>sensor</b> resulting in three array images. Two different methods to ortho-rectify and mosaic the three IRS- 1 array images are presented. Results using the CCRS modelling show an accuracy of about one pixel. Future research at CCRS to integrate {{the parameters of the}} three sensors in to a single geometric modelling should give better results (less than one pixel) with also less GCPs...|$|R
40|$|Some {{remote sensing}} {{applications}} are relatively time insensitive, for others, near-real-time processing (results 30 - 180 minutes after data reception) offer a viable solution. There are, however, a few applications, such as active wildfire monitoring or ship and airplane detection, where real-time processing and image interpretation offers a distinct advantage. The objective of real-time processing {{is to provide}} notifications before the complete satellite pass has been received. This paper presents an automated system for real-time, stream–based processing of data acquired from direct broadcast push-broom sensors for applications that require {{a high degree of}} timeliness. Based on this system, a processing chain for active fire monitoring using Landsat 8 live data streams was implemented and evaluated. The real-time processing system, called the FarEarth Observer, is connected to a ground station’s demodulator and uses its live data stream as input. Processing is done on variable size image segments assembled from detector lines of the <b>push</b> <b>broom</b> <b>sensor</b> as they are streamed from the satellite, enabling detection of active fires and sending of notifications within seconds of the satellite passing over the affected area, long before the actual acquisition completes. This approach requires performance optimized techniques for radiometric and geometric correction of the sensor data. Throughput of the processing system is kept well above the 400 Mbit/s downlink speed of Landsat 8. A latency of below 10 seconds from sensor line acquisition to anomaly detection and notification is achieved. Analyses of geometric and radiometric accuracy and comparisons in latency to traditional near-real-time systems are also presented...|$|E
40|$|Modelling th# {{push broom}} sensors {{commonly}} used in satellite imagery is quite di#cult and computationally intensive due to th# complicated motion ofth# orbiting satellite with respect to th# rotating earth# In addition, th# math# 46 tical model is quite complex, involving orbital dynamics, andh#(0 k is di#cult to analyze. Inth#A paper, a simplified model of apush broom sensor(th# linear push broom model) is introduced. Ith as th e advantage of computational simplicity wh#A 9 atth# same time giving very accurate results compared with th# full orbitingpush broom model. Meth# ds are given for solving th# major standardph# togrammetric problems for th e linear <b>push</b> <b>broom</b> <b>sensor.</b> Simple non-iterative solutions are given for th# following problems : computation of th# model parameters from groundcontrol points; determination of relative model parameters from image correspondences between two images; scene reconstruction given image correspondences and ground-control points. In addition, th# linearpush broom model leads toth# 0 retical insigh ts th# t will be approximately valid for th# full model as well. Th# epipolar geometry of linear push broom cameras in investigated and sh own to be totally di#erent from th at of a perspective camera. Neverth eless, a matrix analogous to th e essential matrix of perspective cameras issh own to exist for linear push broom sensors. Fromth# 0 it is sh# wn th# t a scene is determined up to an a#ne transformation from two viewswith linearpush broom cameras. Keywords :push broom sensor, satellite image, essential matrixph# togrammetry, camera model The research describ ed in this paper hasb een supportedb y DARPA Contract #MDA 97291 -C- 0053 1 Real Push broom sensors are {{commonly used in}} satellite cameras, notably th# SPOT satellite forth# generatio [...] ...|$|E
50|$|A whisk <b>broom</b> or {{spotlight}} <b>sensor</b> (also {{known as}} an across track scanner) is a technology for obtaining satellite images with optical cameras. It is used for passive remote sensing from space. In a whisk <b>broom</b> <b>sensor,</b> a mirror scans across the satellite’s path (ground track), reflecting light into a single detector which collects data one pixel at a time. The moving parts make this type of sensor expensive and more prone to wearing out. Whisk broom scanners {{have the effect of}} stopping the scan, and focusing the detector on one part of the swath width. Because the detector is only focused on a subsection of the full swath at any time, it typically has a higher resolution than a <b>push</b> <b>broom</b> design for the same size of scan swath.|$|R
50|$|OLI uses 4-mirror {{telescope}} with fixed mirrors. The OLI is a <b>Push</b> <b>broom</b> scanner.|$|R
50|$|A <b>push</b> <b>broom</b> scanner (also {{known as}} an {{along-track}} scanner) is a device for obtaining images with spectroscopic sensors. The scanners are regularly used for passive remote sensing from space, and in spectral analysis on production lines, for example with near-infrared spectroscopy used to identify contaminated food and feed. The moving scanner line in a traditional photocopier (or a scanner or facsimile machine) is also a familiar, everyday example of a <b>push</b> <b>broom</b> scanner. <b>Push</b> <b>broom</b> scanners and the variant whisk broom scanners (also known as across-track scanners) are often contrasted with staring arrays (such as found in a digital camera or phone), which images objects without scanning, and are more familiar to most people.|$|R
50|$|RTTOV - {{the fast}} {{radiative}} transfer model for calculations of radiances for satellite infrared or microwave nadir scanning radiometers (see <b>push</b> <b>broom</b> scanner).|$|R
50|$|Ned the Janitor: A skin changed of Xiao Long to {{look like}} a Janitor. He replaces Xiao Long on the {{character}} select screen through a cheat code. He is armed with a <b>push</b> <b>broom.</b>|$|R
40|$|International audienceThe {{retrieval}} of both height and velocity of a volcanic plume {{is an important}} issue in volcanology. As an example, it is known that large volcanic eruptions can temporarily alter the climate, causing global cooling and shifting precipitation patterns; the ash/gas dispersion in the atmosphere, their impact and lifetime around the globe, greatly depends on the injection altitude. Plume height information is critical for ash dispersion modelling and air traffic security. Furthermore, plume height during explosive volcanism is the primary parameter for estimating mass eruption rate. Knowing the plume altitude is also important to get the correct amount of SO 2 concentration from dedicated spaceborne spectrometers. Moreover, the distribution of ash deposits on ground greatly depends on the ash cloud altitude, which has an impact on risk assessment and crisis management. Furthermore, a spatially detailed plume height measure {{could be used as a}} hint for gas emission rate estimation and for ash plume volume researches, which both have an impact on climate research, air quality assessment for aviation and finally for the understanding of the volcanic system itself as ash/gas emission rates are related to the state of pressurization of the magmatic chamber. Today, the community mainly relies on ground based measurements but often they can be difficult to collect as by definition volcanic areas are dangerous areas (presence of toxic gases) and can be remotely situated and difficult to access. Satellite remote sensing offers a comprehensive and safe way to estimate plume height. Conventional photogrammetric restitution based on satellite imagery fails in precisely retrieving a plume elevation model as the plume own velocity induces an apparent parallax that adds up to the standard parallax given by the stereoscopic view. Therefore, measurements based on standard satellite photogrammeric restitution do not apply as there is an ambiguity in the measurement of the plume position. Standard spaceborne along-track stereo imagers (e. g. SPOT 5, ASTER or Quickbird among the others) present a long temporal lag between the two stereo image acquisitions. It can reach tens of seconds for baseline-to-height ratios (B/H) between 0. 2 and 0. 5, during which time the surface texture of the plume may have changed due to the plume fast displacement (i. e. velocities larger than 10 m/s) biasing automatic cross correlation offset measurements. For the purpose of the plume surface elevation model extraction, the ideal is as small as possible time lag, with still a B/H ratio large enough to provide a stereoscopic view for restituting the height. In this study we present a method to restitute a detailed map of the surface height of a volcanic eruptive column from optical satellite imagery. We call it the volcanic Plume Elevation Model (PEM). As the volcanic plume is moving rapidly, conventional satellite based photogrammetric height restitution methods do not apply as the epipolar offset due to plume motion adds up to the one generated by the stereoscopic view. This is because there are time-lags of tens of seconds between conventional satellite stereoscopic acquisitions, depending on the stereo acquisition mode. Our method is based on a single satellite pass. We exploit the short time lag and resulting baseline that exist between the multispectral (MS) and the panchromatic (PAN) bands to jointly measure the epipolar offsets and the perpendicular to the epipolar (P 2 E) offsets. The former are proportional to plume height plus the offsets due to plume velocity in the epipolar direction. The latter, are proportional to plume velocity in the P 2 E direction only. The latter is used to compensate the effect of plume velocity in the stereoscopic offsets by projecting it on the epipolar direction assuming a known plume direction, thus improving the height measurement precision. We apply the method to Landsat 8 data taking into account the specificities of the focal plane modules. We focus on the Holuhraun 2014 fissure eruption (Iceland) and on Mount Etna (Italy) 2013 episode. We validate our measurements against ground based measurements. The method has potential for detailed high resolution routine measurements of volcanic plume height/velocity. The method can be applied both to other multi focal plane modules <b>push</b> <b>broom</b> <b>sensors</b> (such as the ESA Sentinel 2) and potentially to other push-broom systems such as the CNES SPOT family and Pléiades...|$|R
50|$|Examples of {{spacecraft}} cameras using <b>push</b> <b>broom</b> imagers include Mars Express's High Resolution Stereo Camera, Lunar Reconnaissance Orbiter Camera NAC, Mars Global Surveyor's Mars Orbiter Camera WAC, and the Multi-angle Imaging SpectroRadiometer {{on board}} the Terra satellite.|$|R
50|$|The floor {{squeegee}} {{is similar}} to the window squeegee but has a long handle like a <b>push</b> <b>broom,</b> used to clean floors after they have been sprayed with water or soap, to push the water into drains.|$|R
50|$|Linescan {{cameras are}} also {{extensively}} used in imaging from satellites (see <b>push</b> <b>broom</b> scanner). In {{this case the}} row of sensors is perpendicular to the direction of satellite motion. Linescan cameras are widely used in scanners. In this case, the camera moves horizntally.|$|R
5000|$|Shortly {{after he}} sold Marysville Rotary Broom Service, Inc., Drumm would {{start a new}} company, Drumm Industries, where he would {{manufacture}} <b>push</b> <b>brooms</b> {{for a short period}} until a no-compete contract would expire. In 1988 he would receive a patent for a <b>push</b> <b>broom</b> head of the channel-mounted bristle type. He would then focus a considerable amount of time innovating a replaceable strip brush. This changed the whole process of manufacturing tube-brooms, as one tube could be recycled simply by replacing the brush through replaceable slide-on strips, versus the old method of wrapping the brush around the tube, welding it together, and shipping the tube back for a replacement wrap when it was worn out, or scrapping the tube altogether. Drumm would obtain several patents relating to the strip brush innovation.|$|R
5000|$|POLDER {{utilizes}} a <b>push</b> <b>broom</b> scanner. The device's {{optical system}} uses a telecentric lens and a charged coupled device matrix with {{a resolution of}} 242x548 pixels. [...] The focal length is 3.57 mm with a focal ratio of 4.6. The field of view ranges from ±43° to ±57°, depending on the tracking method.|$|R
40|$|BIRD {{mission was}} {{launched}} in October 2001 and is an exemplary demonstrator for small satellite projects dedicated to the fire hazard detection and monitoring. The main payload {{is devoted to the}} observation of high temperature events and consists mainly of a bi-spectral infrared <b>push</b> <b>broom</b> scanner (with spectral bands at 3. 4 - 4. 2 µm and 8. 5 - 9. 3 µm), a <b>push</b> <b>broom</b> imager for the visible and near infrared and a neural networks classification signal processor. The outstanding feature of the IR cameras is an advanced real time processing control allowing an autonomously adaptation of the dynamic range to scenarios containing high temperature events without any degradation of the sensor sensitivity to the background signal. The on board neural network classificator can support the on ground data processing by a pre-classification procedure. Currently BIRD has been used in the ESA project FUEGOSAT to demonstrate the utilisation of innovative space technologies for fire risk management...|$|R
40|$|In May 2001 {{was planned}} {{to launch the}} small {{satellite}} BIRD, but the launch was shifted to August/September 2001. The main payload {{is dedicated to the}} observation of high temperature events and consists mainly of a Bi-Spectral IR <b>Push</b> <b>Broom</b> Scanner and a <b>Push</b> <b>Broom</b> Imager in the Visible. Solid state detector arrays with adaptive high dynamic front end electronics and advanced digital signal processing capabilities are the key element of IR imaging devices. With respect to the main mission objectives besides the high radiometric requirements to the detectors their mutual geometrical alignment is essential. The main problem of the radiometric calibration is the required high dynamic range which makes necessary to consider the non linear characteristic of the detector elements. On the other hand the application of special bi-spectral methods requests a carefully geometrical calibration. Besides the alignment of the different spectral channels the knowledge of the PSF is necessary. The laboratory radiometric and geometrical calibration procedures are described in this paper...|$|R
40|$|The two {{time-of-flight}} {{imaging techniques}} that {{are commonly used}} are as follows: • 1 D line scanner with forward velocity to produce a push-broom raster scan • 2 D scanner with orthogonal scan axes 6. 1. 1. <b>Push</b> <b>Broom</b> Scanner A rotating prism scans the laser (or radar) beam {{at right angles to}} the direction of travel. The laser produces between 2000 and 8000 pulses every second. Each pulse strikes the ground and because it is rough, some power is reflected back to the receiver where it is detected. By registering the forward motion of the aircraft using GPS/INS and the beam angle, a 2 D raster is produced as shown in the figure below. Range and /or reflected signal amplitude are logged to produce an image of the ground. (a) (b) Figure 6. 1 : <b>Push</b> <b>broom</b> scan principles showing (a) generation of a raster image and (b) rotating prism mechanism to produce the scanned bea...|$|R
40|$|The {{spatial and}} time variant effects in high {{resolution}} satellite <b>push</b> <b>broom</b> imaging are analyzed. A spatial and time variant imaging model is established. A moving target information extraction method is proposed {{based on a}} single satellite remote sensing image. The experiment computes two airplanes' flying speed using ZY- 3 multispectral image and proves the validity of spatial and time variant model and moving information extracting method...|$|R
50|$|LAPAN-A3 or LAPAN-IPB {{will perform}} {{experimental}} remote sensing mission. In addition to that, the satellite will support global AIS mission and amateur radio communication. The satellite payload is a four-band <b>push</b> <b>broom</b> multi-spectral imaging camera (Landsat band: B, G, R, NIR), {{which will give}} resolution of 18 m and coverage of 120 km from 650 km altitude. The satellite has been launched in June 2016.|$|R
50|$|Clark is {{the first}} Afro-American painter {{credited}} with working on a shaped canvas, an innovation that influenced contemporary art through the 1950s and 1960s. He is also known for his powerful brush stroke achieved with a <b>push</b> <b>broom,</b> large-scale canvases, and his vibrant use of color. He arrives in Paris each summer and returns to New York City. He had number of well received exhibitions in both continents.|$|R
50|$|Hyper{{spectral}} imaging, {{like other}} spectral imaging, collects and processes information {{from across the}} electromagnetic spectrum. The goal of hyperspectral imaging is to obtain the spectrum for each pixel {{in the image of}} a scene, with the purpose of finding objects, identifying materials, or detecting processes. There are two general branches of spectral imagers. There are <b>push</b> <b>broom</b> scanners and the related whisk broom scanners, which read images over time, and snapshot hyperspectral imaging, which uses a staring array to generate an image in an instance.|$|R
40|$|Exterior {{orientation}} parameters’ (EOP) estimation using space resection {{plays an}} important role in topographic reconstruction for <b>push</b> <b>broom</b> scanners. However, existing models of space resection are highly sensitive to errors in data. Unfortunately, for lunar imagery, the altitude data at the ground control points (GCPs) for space resection are error-prone. Thus, existing models fail to produce reliable EOPs. Motivated by a finding that for <b>push</b> <b>broom</b> scanners, angular rotations of EOPs can be estimated independent of the altitude data and only involving the geographic data at the GCPs, which are already provided, hence, we divide the modeling of space resection into two phases. Firstly, we estimate the angular rotations based on the reliable geographic data using our proposed mathematical model. Then, with the accurate angular rotations, the collinear equations for space resection are simplified into a linear problem, and the global optimal solution for the spatial position of EOPs can always be achieved. Moreover, a certainty term is integrated to penalize the unreliable altitude data for increasing the error tolerance. Experimental results evidence that our model can obtain more accurate EOPs and topographic maps not only for the simulated data, but also for the real data from Chang’E- 1, compared to the existing space resection model...|$|R
40|$|The DLR micro {{satellite}} BIRD was piggy-back {{launched on}} 22 October 2001. The BIRD mission, fully {{funded by the}} DLR, answers topical technological and scientific questions related to the operation of a compact infra-red push-broom sensor system on board of a micro satellite and demonstrates new spacecraft bus technologies. The payload {{is dedicated to the}} observation of high temperature events and consists mainly of a Bi-Spectral Infrared <b>Push</b> <b>Broom</b> Scanner and a <b>Push</b> <b>Broom</b> Imager for the Visible and Near Infrared. With respect to this payload BIRD is a precursor mission for small satellite projects dedicated to the hazard detection and monitoring. BIRD demonstrates new small satellite technologies like on-board processing technologies based on COTS high performance components, high precision reaction wheels, a low-cost star sensor and an on-board navigation system. These technological experiences will be studied now in detail to reduce the costs for related future missions. Further more, the aspect of the cost reduction is not only restricted to the technology, but is also driven by the efficiency of the implementation and mission management. The BIRD mission has served all these fields and can be used now as a case study. The paper will describe the first attempts to optimise the overall BIRD mission scenario making future missions more cost-effective...|$|R
40|$|The {{verification}} of a multi-sensor aircraft system developed to study soil moisture applications is discussed. This system {{consisted of a}} three beam <b>push</b> <b>broom</b> L band microwave radiometer, a thermal infrared scanner, a multispectral scanner, video and photographic cameras and an onboard navigational instrument. Ten flights were made of agricultural sites in Maryland and Delaware {{with little or no}} vegetation cover. Comparisons of aircraft and ground measurements showed that the system was reliable and consistent. Time series analysis of microwave and evaporation data showed a strong similarity that indicates a potential direction for future research...|$|R
40|$|Since 1977, Martin Marietta Denver Aerospace has aggressively pursued {{development}} of deployable structural systems applicable {{to a wide}} variety of Shuttle-transportable large space system requirements. This effort has focused on the deployable box truss, mechanisms and materials development, mesh reflector design and fabrication, gate frame truss design and fabrication, and offset-fed antenna design and analysis. The activities discussed are: box truss design; metal matrix composites; precision joints; enhanced passive damping design; mesh reflector development; gate frame truss for solar arrays; 15 -meter spinning radio meter; and 60 x 120 meter <b>push</b> <b>broom</b> antenna...|$|R
40|$|Scheduled {{for launch}} {{on board the}} BepiColombo Mercury Planetary Orbiter (MPO) in 2014, the Mercury Radiometer and Thermal Infrared Spectrometer (MERTIS) is an {{innovative}} instrument for studying the surface composition and mineralogy of planet Mercury. MERTIS combines an uncooled grating <b>push</b> <b>broom</b> IR-spectrometer (TIS) with a radiometer (TIR), which will operate in the wavelength region of 7 - 14 and 7 - 40 μm, respectively. The spatial resolution of the MERTIS observations will be about 500 m globally and better than 500 m for approximately 5 - 10...|$|R
40|$|The {{linear array}} <b>push</b> <b>broom</b> imaging mode {{is widely used}} for high {{resolution}} optical satellites (HROS). Using double-cameras attached by a high-rigidity support along with <b>push</b> <b>broom</b> imaging is one method to enlarge {{the field of view}} while ensuring high resolution. High accuracy image mosaicking is the key factor of the geometrical quality of complete stitched satellite imagery. This paper proposes a high accuracy image mosaicking approach based on the big virtual camera (BVC) in the double-camera system on the GaoFen 2 optical remote sensing satellite (GF 2). A big virtual camera can be built according to the rigorous imaging model of a single camera; then, each single image strip obtained by each TDI-CCD detector can be re-projected to the virtual detector of the big virtual camera coordinate system using forward-projection and backward-projection to obtain the corresponding single virtual image. After an on-orbit calibration and relative orientation, the complete final virtual image can be obtained by stitching the single virtual images together based on their coordinate information on the big virtual detector image plane. The paper subtly uses the concept of the big virtual camera to obtain a stitched image and the corresponding high accuracy rational function model (RFM) for concurrent post processing. Experiments verified that the proposed method can achieve seamless mosaicking while maintaining the geometric accuracy...|$|R
40|$|The High Resolution Stereo Camera (HRSC) {{has been}} {{orbiting}} the planet Mars since January 2004 onboard the ESA Mars Express mission and delivers imagery {{which is being}} used for topographic mapping of the planet. The HRSC team is currently conducting a systematic inter-comparison of different alternatives {{for the production of}} high resolution Digital Terrain Models (DTMs) from the multilook HRSC <b>push</b> <b>broom</b> imagery. Based on carefully chosen test sites the test participants have produced DTMs which have been subsequently analysed in a quantitative and a qualitative manner. This paper reports on the results obtained in this test...|$|R
40|$|The {{maturity}} of self-scanned, solid-state, multielement photosensors makes {{the realization of}} "real time" reconnaissance photography viable and practical. A system built around these sensors which can be constructed {{to satisfy the requirements}} of the tactical reconnaissance scenario is described. The concept chosen is the <b>push</b> <b>broom</b> strip camera system [...] RECON 6 [...] which represents the least complex and most economical approach for an electronic camera capable of providing a high level of performance over a 140 deg wide, continuous swath at altitudes from 200 to 3, 000 feet and at minimum loss in resolution at higher altitudes...|$|R
50|$|In 1954, when Beamer {{was seven}} years old, he used a <b>push</b> <b>broom</b> to help keep a pile of burning trash in place. When the job was done he {{returned}} the broom to the garage not knowing that its bristles were still smoldering. A spark ignited a nearby can of gasoline, which exploded in front of him. His 11-year-old brother Barnett saved him by rolling him around on the ground, but Frank was left with burns on his shoulders, chest, and {{the right side of}} his neck. He underwent dozens of skin graft procedures that left him with permanent scarring.|$|R
40|$|<b>Push</b> <b>broom</b> scanners, such as video spectrometers (also called hyperspectral sensors), {{are widely}} used in the present. Usage of scanned images {{requires}} accurate geometric correction, which becomes complicated when imaging platform is airborne. This work contains detailed description of a new algorithm developed for processing of such images. The algorithm requires only user provided control points {{and is able to}} correct distortions caused by yaw, flight speed and height changes. It was tested on two series of airborne images and yielded RMS error values on the order of 7 meters (3 - 6 source image pixels) as compared to 13 meters for polynomial-based correction...|$|R
