44|814|Public
5000|$|... λProlog, {{also written}} lambda Prolog, is a logic {{programming}} language featuring <b>polymorphic</b> <b>typing,</b> modular programming, and higher-order programming. These extensions to Prolog {{are derived from}} the higher-order hereditary Harrop formulas used to justify the foundations of λProlog. Higher-order quantification, simply typed λ-terms, and higher-order unification gives λProlog the basic supports needed to capture the λ-tree syntax approach to higher-order abstract syntax, an approach to representing syntax that maps object-level bindings to programming language bindings. Programmers in λProlog need not deal with bound variable names: instead various declarative devices are available to deal with binder scopes and their instantiations. Since 1986, λProlog has received numerous implementations. As of 2013, the language and its implementations are still actively being developed.|$|E
5000|$|In {{the context}} of {{computer}} programming, magic is an informal term for abstraction; {{it is used to}} describe code that handles complex tasks while hiding that complexity to present a simple interface. The term is somewhat tongue-in-cheek and carries bad connotations, implying that the true behavior of the code is not immediately apparent. For example, Perl's <b>polymorphic</b> <b>typing</b> and closure mechanisms are often called [...] "magic". The term implies that the hidden complexity is at least in principle understandable, in contrast to black magic and deep magic (see Variants), which describe arcane techniques that are deliberately hidden or extremely difficult to understand. The action of such abstractions is described as being done [...] "automagically", a portmanteau of [...] "automatically" [...] and [...] "magically".|$|E
40|$|Projet FORMELThe {{polymorphic}} type discipline, {{as in the}} ML language, fits {{well within}} purely applicative languages, but does not extend naturally to the main feature of algorithmic languages : in-place update of data structures. Similar typing difficulties arise with other extensions of applicative languages : logical variables, communication channels, continuation handling. This work studies (in the setting of relational semantics) two new approaches to the <b>polymorphic</b> <b>typing</b> of these non-applicative features. The first one relies on a restriction of generalization over types (the notion of dangerous variables), and on a refined typing of functional values (closure typing). The resulting type system {{is compatible with the}} ML core language, and is the most expressive type systems for ML with imperative features proposed so far. The second approach relies on switching to "by-name" semantics for the constructs of polymorphism, instead of the usual "by-value" semantics. The resulting language differs from ML, but lends itself easily to <b>polymorphic</b> <b>typing.</b> Both approaches smoothly integrate non-applicative features and <b>polymorphic</b> <b>typing...</b>|$|E
40|$|In {{this paper}} we present {{construction}} of <b>polymorphic</b> <b>type</b> theory and its model {{in terms of}} category theory. We extend the notion of many-typed signature to <b>polymorphic</b> <b>type</b> signature. We define <b>polymorphic</b> <b>type</b> calculi for first-, second- and higher-order types and set-theoretical semantics of first-order polymorphism. Semantics for higher-order <b>polymorphic</b> <b>type</b> calculi we construct in categorical terms. Then we can build a logical system over <b>polymorphic</b> <b>type</b> theory as composed polymorphic fibration with double indexing...|$|R
40|$|AbstractWe {{propose a}} modest {{conservative}} extension to ML that allows semi-explicit first-class polymorphism while preserving the essential properties of type inference. In our proposal, {{the introduction of}} <b>polymorphic</b> <b>types</b> is fully explicit, that is, both introduction points and exact <b>polymorphic</b> <b>types</b> are to be specified. However, the elimination of <b>polymorphic</b> <b>types</b> is semi-implicit: only elimination points are to be specified as <b>polymorphic</b> <b>types</b> themselves are inferred. This extension is particularly useful in objective ML where polymorphism replaces subtyping...|$|R
40|$|We have {{constructed}} {{an explanation}} system for <b>polymorphic</b> <b>types,</b> motivated by analysis of human type explanations. Qualitative and quantitative comparison of human expert and our computer generated explanations of <b>polymorphic</b> <b>type</b> errors {{suggests that they}} are very similar. Keywords <b>Polymorphic</b> types; <b>type</b> error explanation; mechanical explanation. 1...|$|R
40|$|This is {{the third}} report on TyCO, a (still) {{experimental}} strongly and implicitly typed concurrent object based programming language based on a predicative polymorphic calculus of objects, featuring asynchronous messages, objects, and procedures, together with a predicative <b>polymorphic</b> <b>typing</b> assignment system, assigning monomorphic types to variables and polymorphic types to procedure...|$|E
40|$|International audienceThis paper {{presents}} a program transformation that allows languages with <b>polymorphic</b> <b>typing</b> (e. g. ML) {{to be implemented}} with unboxed, multi-word data representations, more efficient than the conventional boxed representations. The transformation introduces coercions between various representations, based on a typing derivation. A prototype ML compiler utilizing this transformation demonstrates important speedups...|$|E
40|$|In {{the last}} ten years declaration-free {{programming}} languages with a <b>polymorphic</b> <b>typing</b> discipline (ML, B) have been developed to approximate the flexibility and conciseness of dynamically typed languages (LISP, SETL) while retaining the safety and execution efficiency of conventional statically typed languages (Algol 68, Pascal). These polymorphic languages can be type checked at compile time, yet allow functions whose arguments range over a variety of types. We investigate several polymorphic type systems, the most powerful of which, termed Milner-Mycroft Calculus, extends the so-called let-polymorphism found in, e. g., ML with a <b>polymorphic</b> <b>typing</b> rule for recursive definitions. We show that semi-unification, the problem of solving inequalities over firstorder terms, characterizes type checking in the Milner-Mycroft Calculus to polynomial time, even in the restricted case where nested definitions are disallowed. This permits us to extend some infeasibility results for related combinato [...] ...|$|E
40|$|Abstract. We {{propose a}} modest {{conservative}} extension to ML that al-lows semi-explicit higher-order polymorphism while preserving the essen-tial properties of ML. In our proposal, {{the introduction of}} <b>polymorphic</b> <b>types</b> remains fully explicit, that is, both the introduction and the exact <b>polymorphic</b> <b>type</b> must be specied. However, the elimination of poly-morphic types is now semi-implicit: only the elimination itself must be speci ed as the <b>polymorphic</b> <b>type</b> is inferred. This extension is particu-larly useful in Objective ML where polymorphism replaces subtyping...|$|R
40|$|AbstractUsing {{ideas and}} results from Barendrecht (1983) and Coppo (1984) on {{intersection}} types, a comparable theory is developed for (second order) <b>polymorphic</b> <b>types.</b> The set of filters constructed with <b>polymorphic</b> <b>type</b> forms, with inclusion, a continuous lattice which yields {{a model of}} what we call βη-expansion (i. e. the value of a term increases under βη-reduction), but not of β-conversion. Combining intersection with <b>polymorphic</b> <b>types</b> does give filter λ-models, but the two standard ways of interpreting λ-terms do not coincide...|$|R
40|$|Three {{languages}} with <b>polymorphic</b> <b>type</b> disciplines are discussed, {{namely the}} *-calculus with Milner's <b>polymorphic</b> <b>type</b> discipline; a language with imperative features (polymorphic references); and a skeletal module language with structures, signatures and functors. In {{each of the}} two first cases we show that the type inference system is consistent with an operational dynamic semantics. On the module level, <b>polymorphic</b> <b>types</b> correspond to signatures. There is a notion of principal signature. So-called signature checking is the module level equivalent of type checking. In particular, there exists an algorithm which either fails or produces a principal signature...|$|R
40|$|This paper {{presents}} a call-by-need polymorphically typed lambda-calculus with letrec, case, constructors and seq. The typing of the calculus is modelled in a system-F style. Contextual equivalence {{is used as}} semantics of expressions. We also define a call-by-name variant without letrec. We adapt several tools and criteria for recognizing correct program transformations to <b>polymorphic</b> <b>typing,</b> in particular an inductive applicative simulation...|$|E
40|$|Abstract. This paper studies continuations {{by means}} of a {{polymorphic}} type system. The traditional call-by-name continuation passing style transform admits a typing in which some answer types are polymorphic, even in the presence of first-class control operators. By building on this <b>polymorphic</b> <b>typing,</b> and using parametricity reasoning, we show that the call-by-name transform satisfies the eta-law, and is in fact isomorphic to the more recent CPS transform defined by Streicher. ...|$|E
40|$|In {{this case}} study we {{investigate}} the use of PVS for developing type theoretical concepts and verifying the correctness of a typing algorithm. PVS {{turns out to be}} very useful for efficient development of a sound basic theory about <b>polymorphic</b> <b>typing.</b> This research contributes to the PoplMark challenge on mechanizing metatheory. The correctness of the typing algorithm is expressed as the so-called Contextual Principal Type Property, which is interesting in its own right...|$|E
40|$|In this paper, {{we first}} {{introduce}} {{a notion of}} polymorphic abstract interpretation that formalises a polymorphic analysis as a generalisation of possibly infinitely many monomorphic analyses {{in the sense that}} the results of the monomorphic analyses can be obtained as instances of that of the polymorphic analysis. We then present a <b>polymorphic</b> <b>type</b> analysis of logic programs in terms of an abstract domain for <b>polymorphic</b> descriptions of <b>type</b> information and two operators on the abstract domain, namely the least upper bound operator and the abstract unification operator. The domains for similar purposes. The abstract unification operator for the <b>polymorphic</b> <b>type</b> analysis is designed by lifting the abstract unification operator for a monomorphic type analysis in logic programs, which simplifies the proof of the safeness of the <b>polymorphic</b> <b>type</b> analysis. Some experimental results with a prototype implementation of the <b>polymorphic</b> <b>type</b> analysis are also presented...|$|R
40|$|<b>Polymorphic</b> <b>types</b> in {{programming}} languages facilitate code reuse, increase {{reliability and}} reduce semantic errors in programs. Hindley-Milner type inference forms a strong basis for checking <b>polymorphic</b> <b>types</b> but is less {{well suited to}} explaining them, as it introduces intermediate constructs that relate poorly to a programmer's understanding of the program...|$|R
40|$|AbstractIn this paper, {{we first}} {{introduce}} {{a notion of}} polymorphic abstract interpretation that formalises a polymorphic analysis as a generalisation of possibly infinitely many monomorphic analyses {{in the sense that}} the results of the monomorphic analyses can be obtained as instances of that of the polymorphic analysis. We then present a <b>polymorphic</b> <b>type</b> analysis of logic programs in terms of an abstract domain for <b>polymorphic</b> descriptions of <b>type</b> information and two operators on the abstract domain, namely the least upper bound operator and the abstract unification operator. The abstract domain captures type information more precisely than other abstract domains for similar purposes. The abstract unification operator for the <b>polymorphic</b> <b>type</b> analysis is designed by lifting the abstract unification operator for a monomorphic type analysis in logic programs, which simplifies the proof of the safeness of the <b>polymorphic</b> <b>type</b> analysis. Some experimental results with a prototype implementation of the <b>polymorphic</b> <b>type</b> analysis are also presented...|$|R
40|$|International audienceWe {{present a}} new {{approach}} to the <b>polymorphic</b> <b>typing</b> of data accepting in-place modification in ML-like languages. This approach is based on restrictions over type generalization, and a refined typing of functions. The type system given here leads to a better integration of imperative programming style with the purely applicative kernel of ML. In particular, generic functions that allocate mutable data can safely be given fully polymorphic types. We show the soundness of this type system, and give a type reconstruction algorithm...|$|E
40|$|This paper {{shows how}} a non-strict {{functional}} programming language with <b>polymorphic</b> <b>typing</b> {{can be used to}} define grammar rules and semantic evaluation along the lines of Montague. This approach provides a unified formalism needing no preprocessing or postprocessing to the functional language itself: parsing and semantics are declared naturally using function definition and evaluation is done by lambda application. We show that by changing only the model we can, after parsing, compute either the truth value of a sentence or its parse tree...|$|E
40|$|We {{present a}} new {{approach}} to the <b>polymorphic</b> <b>typing</b> of data accepting in-place modi cation in ML-like languages. This approach is based on restrictions over type generalization, and a re ned typing of functions. The type system given here leads to a better integration of imperative programming style with the purely applicative kernel of ML. In particular, generic functions that allocate mutable data can safely be given fully polymorphic types. We show the soundness of this type system, and give a type reconstruction algorithm...|$|E
5000|$|In a predicative {{parametric}} <b>polymorphic</b> system, a <b>type</b> [...] {{containing a}} type variable [...] {{may not be}} used {{in such a way that}} [...] is instantiated to a <b>polymorphic</b> <b>type.</b> Predicative type theories include Martin-Löf Type Theory and NuPRL.|$|R
40|$|In {{this article}} we {{consider}} the <b>polymorphic</b> <b>type</b> checking of an imperative language. Our language contains variables, first-class references (pointers), and first-class functions. Variables, as in traditional imperative languages, are implicitly dereferenced, and their addresses (L-values) are not first-class values. Variables are easier to type check than references and, in many cases, lead to more general <b>polymorphic</b> <b>types.</b> We present a <b>polymorphic</b> <b>type</b> system for our language and prove that it is sound. Programs that use variables sometimes require weak types, as in Tofte's type system for Standard ML, but such weak types arise far less frequently with variables than with reference...|$|R
5000|$|System F<: — a <b>polymorphic</b> <b>typed</b> lambda {{calculus}} with bounded quantification ...|$|R
40|$|This paper {{extends the}} {{termination}} proof techniques based on reduction orderings to a higher-order setting, by adapting the recursive path ordering definition to higher-order simply-typed lambda-terms. The main {{result is that}} this ordering is well-founded, compatible with beta-reductions, and with <b>polymorphic</b> <b>typing.</b> We also restrict the ordering so as to obtain a new ordering operating on higher-order terms in eta-long beta-normal form. Both orderings are powerful enough to allow for complex examples, including the polymorphic version of Gödel's recursor for simple inductive types. Postprint (published version...|$|E
40|$|This paper {{presents}} an object-oriented, reflective, ap-plication framework for C++, {{with an emphasis}} on real-time signal processing. The Jamoma Foundation and DSP Library provide a runtime environment and an expand-ing collection of unit generators for synthesis, processing, and analysis. It makes use of <b>polymorphic</b> <b>typing,</b> dy-namic binding, and introspection to create a cross-platform API pulling ideas from languages such as Smalltalk and Objective-C while remaining within the bounds of the portable and cross-platform C++ context. Over the past sev-eral years this library has been used in both open source and commercial software projects in the sound and music com-puting field...|$|E
40|$|We {{describe}} a denotational, intensional semantics for programs with polymorphic types with bounded quantification, in which phenomena such as inheritance between stateful objects may be represented and studied. Our model is developed from a game semantics for unbounded polymorphism, by establishing dinaturality properties of generic strategies, {{and using them}} to give a new construction for interpreting subtyping constraints and bounded quantification. We use this construction to give a denotational semantics for a programming language with general references and an expressive <b>polymorphic</b> <b>typing</b> system. We show that full abstraction fails in general in this model, but that it holds for all terms at a rich collection of bounded types...|$|E
40|$|We {{present an}} {{extension}} of the Hindley/Milner <b>polymorphic</b> <b>type</b> system that deals with overloading. The system uses a kind of bounded <b>polymorphic</b> <b>type</b> to describe the nonuniform polymorphism resulting from the use of overloaded identifiers. We consider the type inference problem for our system and show that it is undecidable. Restrictions are proposed to cope with this limitation...|$|R
40|$|We {{propose a}} modest {{conservative}} extension to ML that allows semi-explicit first-class polymorphism while preserving the essential properties of type inference. In our proposal, {{the introduction of}} <b>polymorphic</b> <b>types</b> is fully explicit, that is, both introduction points and exact <b>polymorphic</b> <b>types</b> are to be specified. However, the elimination of <b>polymorphic</b> <b>types</b> is semi-implicit: only elimination points are to be specified as <b>polymorphic</b> <b>types</b> themselves are inferred. This extension is particularly useful in Objective ML where polymorphism replaces subtyping. Introduction The success of the ML language is due to its combination of several attractive features. Undoubtedly, the polymorphism of ML [Damas and Milner, 1982] [...] -or polymorphism `a la ML [...] - with the type inference it allows, is a major advantage. The ML type system stays in close correspondence with the rules of logic, following the Curry-Howard isomorphism between types and formulas, which provides a simple intuition, [...] ...|$|R
40|$|Higher-order {{programming}} languages, such as ML, {{permit a}} flexible programming style by using compile-time type inference {{together with the}} concept of type polymorphism, which allows to specify the types of generic functions. In ML, however, recursive functions must always be given a unique (monomorphic) type inside their definition. Giving <b>polymorphic</b> <b>types</b> to recursive functions is known as the problem of polymorphic recursion which has been shown equivalent to the problem of semi-unification, known as undecidable. We show that the absence of a decidable specification to give <b>polymorphic</b> <b>types</b> for recursive definitions lies on the non-adequacy of representing type polymorphism by using type variables as primitive elements. We introduce the notion of syntactic type polymorphism to relate <b>polymorphic</b> <b>types</b> with syntactic information. We formulate a decidable calculus which gives <b>polymorphic</b> <b>types</b> to recursive functions in ML. We present an inference algorithm which we prove the term [...] ...|$|R
40|$|International audienceLanguages with {{polymorphic}} types (e. g. ML) {{have traditionally}} been implemented using Lisp-like data representations—everything has to fit in one word, if necessary by being heap-allocated and handled through a pointer. The reason is that, in contrast with conventional statically-typed languages such as Pascal, {{it is not possible}} to assign one unique type to each expression at compile-time, an absolute requirement for using more efficient representations (e. g. unallocated multi-word values). In this paper, we show how to take advantage of the static <b>polymorphic</b> <b>typing</b> to mix correctly two styles of data representation in the implementation of a polymorphic language: specialized, efficient representations are used when types are fully known at compile-time; uniform, Lisp-like representations are used otherwise...|$|E
40|$|The use of {{labels for}} {{argument}} passing {{has proved to be}} a useful extension to programming languages, particularly when we introduce optional arguments. We propose here an adaptation of such a system, as can be found in Common LISP, to strongly-typed curried functional languages. For this we extend ML-style <b>polymorphic</b> <b>typing</b> to labeled arguments, out-of-order application, and optional arguments. We also provide a compilation method towards polymorphic lambdacalculus, which is proved syntactically sound for free reduction, and semantically correct for call-by-name semantics. We implemented it, and showed the overhead caused by using this extension to be negligible when out-of-order parameter passing is used, and null when it is not. Topics: language design, compilation methods, type theory. ...|$|E
40|$|The expressiveness {{of logic}} {{programs}} can be greatly increased over first-order Horn clauses through a stronger emphasis on logical connectives and by admitting various forms of higher-order quantification. The logic of hereditary Harrop formulas {{and the notion of}} uniform proof have been developed to provide a foundation for more expressive logic programming languages. The λ-Prolog language is actively being developed on top of these foundational considerations. The rich logical foundations of λ-Prolog provides it with declarative approaches to modular programming, hypothetical reasoning, higher-order programming, <b>polymorphic</b> <b>typing,</b> and meta-programming. These aspects of λ-Prolog have made it valuable as a higher-level language for the specification and implementation of programs in numerous areas, including natural language, automated reasoning, program transformation, and databases...|$|E
5000|$|Robin Milner, {{inventor}} of ML, and sharing credit for Hindley-Milner <b>polymorphic</b> <b>type</b> inference.|$|R
40|$|AbstractStudies of the {{mathematical}} properties of impredicatively <b>polymorphic</b> <b>types</b> {{have for the}} most part focused on the polymorphic lambda calculus of Girard-Reynolds, which is a calculus of total polymorphic functions. This paper considers <b>polymorphic</b> <b>types</b> from a functional programming perspective, where the partialness arising from the presence of fixpoint recursion complicates the nature of potentially infinite (‘lazy’) datatypes. An operationally-based approach to Reynolds' notion of relational parametricity is developed for an extension of Plotkin's PCF with ∀types and lazy lists. The resulting logical relation is shown to be a useful tool for proving properties of <b>polymorphic</b> <b>types</b> up to a notion of operational equivalence based on Morris-style contextual equivalence...|$|R
40|$|AbstractYokouchi, H., F-semantics {{for type}} {{assignment}} systems, Theoretical Computer Science 129 (1994) 39 – 77. This paper develops F-semantics for type systems that assign types to untyped λ-terms. Curry's system is complete for F-semantics, but a <b>polymorphic</b> <b>type</b> assignment {{system is not}} so. We introduce two additional rules (FI) and (FE), and show that a <b>polymorphic</b> <b>type</b> assignment system becomes complete for F-semantics if we add these two rules. Furthermore, we apply the same method to a <b>polymorphic</b> <b>type</b> assignment system without the β-equality rule and obtain a similar completeness result. We also show that an intersection type assignment system is complete for F-models if we add two rules defined {{on the basis of}} (FI) and (FE) ...|$|R
