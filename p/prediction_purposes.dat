313|276|Public
5000|$|Financial signal {{processing}} analyzing financial data using {{signal processing}} techniques, especially for <b>prediction</b> <b>purposes.</b>|$|E
5000|$|The Meteorological Satellite Center (...) , which {{receives}} {{and analyses}} weather satellite data for observation and <b>prediction</b> <b>purposes.</b>|$|E
5000|$|<b>Prediction</b> <b>purposes,</b> {{for example}} to {{identify}} 'at risk' students {{in terms of}} drop out or course failure ...|$|E
40|$|This paper {{proposes a}} {{methodology}} to model an electronic board {{according to a}} bottom-up approach. This method is applied to build the model of a synchronous buck DC-DC converter board for conducted emission <b>prediction</b> <b>purpose.</b> The different steps to select the model terminals {{and the construction of}} the component and PCB interconnect models are described...|$|R
40|$|International audienceThis paper {{deals with}} {{off-shore}} wind park model identification for output power <b>prediction</b> <b>purpose.</b> The investigated solution {{is based upon}} identifying the so-called wind deficiency factor for each turbine and for each wind direction sector. This is done by employing the effective wind speed concept that can establish a link between output power of a wind turbine and the meteorological mast measures. Numerical simulations show the feasibility of the proposed approach...|$|R
40|$|Flashover is {{damaging}} to the power transmission and distribution system. In this paper, correlation coefficient {{as a measure of}} nonlinearity is employed to analyze the leakage current signals generated from heavily polluted insulators for flashover <b>prediction</b> <b>purpose.</b> Data is generated with dry and wet conditions together with various supply voltages. By calculating the correlation coefficients between the supply voltages and the leakage currents, some patterns are found which may help identify the status of insulators...|$|R
5000|$|Nearly any {{regression}} {{model can be}} used for <b>prediction</b> <b>purposes.</b> Broadly speaking, there are two classes of predictive models: parametric and non-parametric. A third class, semi-parametric models, includes features of both. Parametric models make [...] "specific assumptions with regard to {{one or more of the}} population parameters that characterize the underlying distribution(s)", while non-parametric regressions make fewer assumptions than their parametric counterparts.|$|E
5000|$|The partial {{least squares}} path {{modeling}} (PLS-PM, PLS-SEM) [...] method to {{structural equation modeling}} allows estimating complex cause-effect relationship models with latent variables. It is a component-based estimation approach that differs from the covariance-based structural equation modeling. Unlike covariance-based approaches to structural equation modeling, PLS-PM does not fit a common factor model to the data, it rather fits a composite model In doing so, it maximizes the amount of variance explained (though what this means from a statistical {{point of view is}} unclear and PLS users do not agree on how this goal might be achieved). In addition, by an adjustment PLS is capable to consistently estimate common factor models as well. This new approach is called consistent PLS (PLSc). Furthermore, PLS-PM can be used for out-sample <b>prediction</b> <b>purposes.</b>|$|E
40|$|Most {{papers on}} {{predictive}} control use either state space models with an observer or transfer function models with output realignment for <b>prediction</b> <b>purposes.</b> Here it is shown {{that this approach}} can have weaknesses, {{especially with regard to}} noise rejection and the independent model approach should soften be preferred...|$|E
40|$|We {{present a}} novel {{adaptive}} random subspace learning algorithm (RSSL) for <b>prediction</b> <b>purpose.</b> This new framework is flexible {{where it can}} be adapted with any learning technique. In this paper, we tested the algorithm for regression and classification problems. In addition, we provide a variety of weighting schemes to increase the robustness of the developed algorithm. These different wighting flavors were evaluated on simulated as well as on real-world data sets considering the cases where the ratio between features (attributes) and instances (samples) is large and vice versa. The framework of the new algorithm consists of many stages: first, calculate the weights of all features on the data set using the correlation coefficient and F-statistic statistical measurements. Second, randomly draw n samples with replacement from the data set. Third, perform regular bootstrap sampling (bagging). Fourth, draw without replacement the indices of the chosen variables. The decision was taken based on the heuristic subspacing scheme. Fifth, call base learners and build the model. Sixth, use the model for <b>prediction</b> <b>purpose</b> on test set of the data. The results show the advancement of the adaptive RSSL algorithm in most of the cases compared with the synonym (conventional) machine learning algorithms...|$|R
30|$|Standard user-based CF {{approach}} {{which uses}} cosine-based k-nearest neighbour method, and simple CBF approach which uses TF-IDF method were employed as baselines {{to compare the}} performance of AHP-MCR approach with other recommendation approaches [12]. In order to obtain evaluation results for user-based CF approach, random data was selected for <b>prediction</b> <b>purpose.</b> In the literature, there are numerous evaluation metrics for measuring recommender performance [62] such as Mean Absolute Error (MAE), Precision, F-measure, ROC. In this paper, we focus on using popular evaluation metrics: MAE and Precision@Top-N.|$|R
30|$|Data in {{real-world}} applications are often collected {{from many different}} data sources. Such a heterogeneous dataset requires a mixture of individual data descriptions. A mixture of experts refers {{to the problem of}} using and combining many experts (e.g., classification or regression models) for classification or <b>prediction</b> <b>purpose</b> [12]. Two challenging obstacles {{that need to be addressed}} include: (1) how to automatically discover the appropriate number of experts in use or automatically do model selection; (2) how to train an individual expert with reference to others.|$|R
40|$|The {{most common}} solar, ionospheric and {{geomagnetic}} indices are here presented with particular reference to their application for radiocommunication <b>prediction</b> <b>purposes.</b> Summary tables of practical use are also included concerning {{the method of}} derivation of the indices, their time interval, their drawbacks, their time-history and the INTERNET node addresses where they are available...|$|E
40|$|Data on {{evaporation}} {{to be used}} in agriculture, hydrology, forestry, etc. {{are usually}} supplied by meteorologists. Meteorologists themselves also use evaporation data. Air mass properties determining weather are strongly dependent on the input of water vapour from the surface. So for weather <b>prediction</b> <b>purposes</b> evaporation data, or rather methods to compute evaporation are needed...|$|E
30|$|Note {{that the}} {{constant}} average incorporates knowledge “from the future”, i.e., the whole year. As such {{it could not}} be used for actual <b>prediction</b> <b>purposes.</b> However, it still helps to shed light on the relative difference in difficulty between the two tasks-it is much harder to gain any improvement for the unemployment setting than for the flu setting.|$|E
40|$|We {{tackle the}} problem of {{representing}} association rules for a <b>prediction</b> <b>purpose.</b> We approach this problem by introducing a novel data structure for representing association rules (now seen as classification/regression rules). Unseen cases are fitted into a graph like structure that avoids any type of sorting procedure. The graph indexes the items present in the rules so that only rules with the antecedent covered by the new case are visited. A {{detailed description of the}} data structures to store the association rules is given along with the most important steps of the algorithm. Benchmarking and discussion on the main features is also presented...|$|R
40|$|In this paper, {{we propose}} a novel {{prevention}} strategy to alert citizens when water is contaminated by estro-gen. Epidemiological {{studies have shown}} that chronic exposure to high blood level of estrogen is associated with the development of breast cancer. The preventive strategy proposed in this paper is based on the predic-tion of estrogen effects on human living cells. Based on first principle insights, we develop in this work, a mathematical model for this <b>prediction</b> <b>purpose.</b> Dynamic measurements of cell proliferation response to es-trogen stimulation were continuously monitored by a real-time cell electronic sensor (RT-CES) and used in order to estimate the parameters of the model developed...|$|R
40|$|Water {{is known}} as an {{important}} resource. Many factors influencing the water consumption, identifying the factors influencing the water consumption is an active area of research work. This research aims at studying the relationship among the climatic variables such as rainfall and temperature & its influence on water consumption using regression technique. For this purpose rainfall, maximum and minimum temperature and water consumption data were collected on monthly basis and it {{is divided into two}} parts training and testing. Model performance is evaluated using correlation coefficient (CC), Prediction error (PE), Root mean square error (RMSE) and Accuracy. From the result it is cleared that regression technique can be used effetely for the <b>prediction</b> <b>purpose</b> and rainfall and temperature variables is influences the water consumption...|$|R
40|$|In this paper, the {{different}} existing propagation mechanisms in integrated circuit substrates are characterized and analytical models are provided for interference <b>prediction</b> <b>purposes.</b> The different propagation modes are described, identifying the ones dominating for each technology option. A {{study of the}} validity range of the proposed model in terms of frequency and substrate physical parameters is also provided...|$|E
40|$|In {{this chapter}} we first {{introduce}} the background related to Set of Experience knowledge representation and then provide {{a case study}} in the area of renewable energy. In the case study, several Sets of Experience of geothermal energy were collected {{for the construction of a}} geothermal decisional experience. This experience is then implemented in an ontology model aiming at <b>prediction</b> <b>purposes...</b>|$|E
40|$|The {{performance}} of a QPSK (quadrature phase-shift keying) lock detector is described, {{taking into account the}} degradation due to carrier phase jitter. Such an analysis is necessary for accurate performance <b>prediction</b> <b>purposes</b> in scenarios where both the loop SNR is low and the estimation period is short. The derived formulas are applicable to several QPSK loops and are verified using computer simulations...|$|E
40|$|Association mining {{techniques}} {{search for}} groups of frequently co-occurring items in a market-basket type of data and turn this data into rules. Previous {{research has focused on}} how to obtain list of these associations and use these ―frequent item sets ‖ for <b>prediction</b> <b>purpose.</b> This paper proposes a technique which uses partial information about the contents of the shopping carts for the prediction of what else the customer is likely to buy. Using Fast Updated Frequent Pattern Tree (FUFP-Tree) instead of Item set Trees (IT-Tree) and Frequent Pattern Tree (FP-Tree), all the rules whose antecedents contain at least one item from the incomplete shopping cart can be obtained in efficient manner. Rules are then combined and Prediction is done using Bayesian Decision Theory and DS-ARM algorithm based on the Dempster-Shafter theory of evidence combination...|$|R
40|$|This report {{describes}} the methodologies and procedures developed through {{a contract to}} the University of Texas at Austin, {{in collaboration with the}} University of Maryland, to address these essential needs. Specifically, a simulation-assignment methodology has been developed to describe user's path choices in the network in response to real-time information, and the resulting flow patterns that propagate through the network, yielding information about overall quality of service and effectiveness, as well as localized information pointing to problem spots and opportunities for improvement. This methodology is intended for use off-line for evaluation purposes, or on-line for <b>prediction</b> <b>purpose</b> in support of advanced traffic management functions. In additional, algorithmic procedures have been developed to determine the best paths to which users should be directed so as to optimize overall system performance. Powerful extensio...|$|R
40|$|In {{this paper}} an {{approach}} is proposed for location estimation, tracking and mobility prediction in cellular networks in dense urban areas using neural and neuro-fuzzy networks. In urban areas with high buildings, {{due to the}} effects of multipath fading and Non-Line-of-Sight conditions, the accuracy of positioning methods based on direction finding and ranging degrades significantly. Also in these areas, due to high user traffic there's a need for network resources management. Knowing the next possible position of user would be helpful in this case. Here using fingerprint positioning concept, after choosing appropriate parameters for fingerprinting in GSM cellular networks, MLP and RBF neural networks were used for position estimation. Then by the use of neuro-fuzzy networks a tracking and post-processing method is applied to estimated locations. For mobility <b>prediction</b> <b>purpose</b> the use of ANFIS neuro-fuzzy is implemented...|$|R
40|$|PaperPg. 165 - 180. Two {{groups of}} pumps were {{investigated}} {{in great detail}} and the analysis showed that large variations in QcR, for the same design specific speed, {{can be obtained by}} modifying the design of the rotating channels. An attempt was made to condense the different design parameters into a global parameter, relating the design concept and the critical flow rate, for analysis and <b>prediction</b> <b>purposes...</b>|$|E
40|$|The Split-Symbol Moments Estimator (SSME) is an {{algorithm}} that {{is designed}} to estimate symbol signal-to-noise ratio (SNR) in the presence of additive white Gaussian noise (AWGN). The performance of the SSME algorithm in band-limited channels is examined. The effects of the resulting inter-symbol interference (ISI) are quantified. All results obtained are in closed form and can be easily evaluated numerically for performance <b>prediction</b> <b>purposes.</b> Furthermore, they are validated through digital simulations...|$|E
30|$|The {{number of}} {{interruption}} prediction {{has been done}} by the neural network method using historical weather data from ten MAs [18, 19]. Neural network has been already used for biomedical <b>prediction</b> <b>purposes</b> [20]. The results illustrate that by increasing the geographic area and predicting the number of interruptions for the total region, the accuracy of the prediction decreases. Weather data considered as input and output represents the interruption prediction based on weather data.|$|E
40|$|Application of uncertaity {{analysis}} of mathematical model <b>predictions</b> for <b>purposes</b> of estimation of radiological impact of radioactive release on population is described. A new probabilistic consequence assesment metodology enables {{to generate more}} informative probabilistic answers on assessment question on radiation events. Illustration of the new approach is given for hypotetical release with local rain meteorological forecast...|$|R
40|$|Mathematical {{models are}} the best tools {{available}} for <b>prediction</b> <b>purpose</b> {{in the field of}} air quality management. In the present study a Gaussian Plume Model is developed to determine the concentration of pollutants from point source emissions. The model is applied to the Industrial zone of Manali region, Chennai. Based on the emission inventory, Meteorological parameters, the concentration of SO 2 is determined for three different seasons. Three months of wind speed, wind direction and cloud cover data recorded by India Meteorological Department (IMD) were used for concentration computations. The computed concentrations were compared with the observed concentration in the study area. The statistical evaluation of the model indicates satisfactory performance. Comparison of numerical result with observed data showed a marked seasonal trend along the study period, which is characterized by high levels of SO 2 in winter and decreased progressively through the, monsoon and summer seasons...|$|R
40|$|Buildings can be poorly {{maintained}} {{due to lack}} {{of understanding}} towards the role of building maintenance in achieving organisation's objective and long-term profitability. The maintenance management is the agent that provides maintenance services to fulfil the needs of the organisation. However, involvement of all the key participants is the key to enhance maintenance planning, execution, and outcome. Whereby, participative mechanism involves the key participants to deal with the maintenance issues. Thus, this paper seeks to identify the participative mechanisms through literature review; then, establish relationship between the mechanisms and maintenance performance through questionnaire survey and interview; and finally produce a regression model for <b>prediction</b> <b>purpose.</b> The findings reveal that effective communication among the key participants is vital to enhance the maintenance performance. Therefore, this paper recommends that the management should develop an effective communication platform involving all key participants with contribution and commitment toward the maintenance activities...|$|R
40|$|After a short {{description}} of the national German laminar flow research program, {{the design of a}} laminar flow glove on the ATTAS/VFW 614 aircraft of DLR is discussed. This glove is specially designed to allow, by flight testing in combination with stability calculation, the evaluation of limiting N-factors due to Tollmien-Schlichting- and due to crossflow-instability for transition <b>prediction</b> <b>purposes</b> on swept wings. The stability behaviour of the glove is analysed in details...|$|E
40|$|Abstract. This paper {{demonstrates}} how {{the selection of}} Prediction Strategy {{is important in the}} Long-Term Prediction of Time Series. Two strategies are already used in the <b>prediction</b> <b>purposes</b> called Recursive and Direct. This paper presents a third one, DirRec, which combines the advantages of the two already used ones. A simple k-NN approximation method is used and all three strategies are applied to two benchmarks: Santa Fe and Poland Electricity Load time series. ...|$|E
30|$|Data mining {{is a key}} {{tool for}} dealing with complex data {{analysis}} and classification. It identifies valuable events that are hidden in large amounts of data for analysis, and summarizes the data in a structured model to provide a reference for decision-making. Data mining has many different functions, such as classification, association, clustering and forecasting (Seifert 2004). The classification function is used most frequently. The classification results {{can be used as}} the basis for decision-making and for <b>prediction</b> <b>purposes.</b>|$|E
40|$|This paper {{describes}} the non-linear {{identification of a}} progressively damaged reinforced concrete beam-column node. The aims are the detection and identification of the different sources of damping and their dependence from the damage level. To this end a specially formulated non-linear identification method is proposed, based on a time-varying polynomial approximation of the system dynamics, suitable {{for use in the}} presence of excitations of any form. A minimum condition imposed to the identified dissipated energy leads to the distinction of the linear viscous component from the other damping mechanisms. The estimated values obtained from the experimental tests show a significant influence of the damage level on the linear viscous damping coefficient. This suggests that, in a non-linear dynamic time-history analysis, the use of Rayleigh damping model with proportionality to the initial stiffness is basically in contrast with experimental evidence and more refined viscous damping models are needed for <b>prediction</b> <b>purpose...</b>|$|R
40|$|Abstract — Neural networks, as an {{intelligent}} data mining method, {{have been used}} in many different challenging pattern recognition problems such as stock market prediction. However, there is no formal method to determine the optimal neural network for <b>prediction</b> <b>purpose</b> in the literatur. In this paper, two kinds of neural networks, a feed forward multi layer Perceptron (MLP) and an Elman recurrent network, are used to predict a company’s stock value based on its stock share value history. The experimental results show that the application of MLP neural network is more promising in predicting stock value changes rather than Elman recurrent network and linear regression method. However, based on the standard measures that will be presented in the paper we find that the Elman recurrent network and linear regression can predict the direction of the changes of the stock value better than the MLP. Keywords- Stock market prediction; Data mining; neural network...|$|R
40|$|Typically, the {{operation}} {{condition of the}} batch process is changed frequently, following different recipes or manufacturing various production grades. For quality <b>prediction</b> <b>purpose,</b> the <b>prediction</b> model should also be updated or rebuilt, {{which leads to a}} significant model maintenance effort, especially for those processes which have various phases. To reduce such effort, a maintenance-free method is proposed in this article, which incorporates the setting information of the batch process for modeling. The whole process variations are separated into two parts: setting information related and other quality related variations. By constructing a relationship between setting variables and other process variables, the data variations explained by the setting information can be efficiently removed. Then, a robust regression model connecting process variables to the quality variable is developed in different phases of the batch process. The feasibility and effectiveness of the proposed method is evaluated through an industrial injection molding process. (C) 2012 American Institute of Chemical Engineers AIChE J, 59 : 772 - 779, 201...|$|R
