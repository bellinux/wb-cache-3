1|5|Public
40|$|Different {{techniques}} to automatically generate unit tests for object oriented classes have been proposed, {{but how to}} integrate these tools into the daily activities of software development is a little investigated question. In this paper, we report on our experience in supporting industrial partners in introducing the EVOSUITE automated JUnit test generation tool in their software development processes. The first step consisted of providing a plugin to the Apache Maven build infrastructure. The move from a research-oriented <b>point-and-click</b> <b>tool</b> to an automated step of the build process has implications on how developers interact with the tool and generated tests, and therefore, we produced a plugin for the popular IntelliJ Integrated Development Environment (IDE). As build automation is a core component of Continuous Integration (CI), we provide a further plugin to the Jenkins CI system, which allows developers to monitor the results of EVOSUITE and integrate generated tests in their source tree. In this paper, we discuss the resulting architecture of the plugins, and the challenges arising when building such plugins. Although the plugins described are targeted for the EVOSUITE tool, they can be adapted and their architecture can be reused for other test generation tools as well...|$|E
40|$|We {{present a}} {{thorough}} study to evaluate different light field editing interfaces, tools and workflows from a user perspective. This is of special relevance given the multidimensional nature of light fields, which may make common image editing tasks become complex in light field space. We additionally investigate {{the potential benefits}} of using depth information when editing, and the limitations imposed by imperfect depth reconstruction using current techniques. We perform two different experiments, collecting both objective and subjective data from a varied number of editing tasks of increasing complexity based on local <b>point-and-click</b> <b>tools.</b> In the first experiment, we rely on perfect depth from synthetic light fields, and focus on simple edits. This allows us to gain basic insight on light field editing, and to design a more advanced editing interface. This is then used in the second experiment, employing real light fields with imperfect reconstructed depth, and covering more advanced editing tasks. Our study shows that users can edit light fields with our tested interface and tools, even in the presence of imperfect depth. They follow different workflows depending on the task at hand, mostly relying on a combination of different depth cues. Last, we confirm our findings by asking a set of artists to freely edit both real and synthetic light fields...|$|R
40|$|Why {{we should}} scrap penetrate-and-patch In the {{commercial}} sector, security analysis {{has traditionally been}} applied at the network system level, after release, using tiger team approaches. After a successful tiger team penetration, specific system vulnerabilities are patched. I {{make a case for}} applying software engineering analysis techniques that have proven successful in the software safety arena to security-critical software code. This work is based on the generally held belief that a large proportion of security violations result from errors introduced during software development. 1. Moving security analysis into development Most computer security analysis is currently performed using penetrate-and-patch tactics. Security is assessed by attempting to break into an installed system by exploiting well-known vulnerabilities. If a break-in attempt is successful, the vulnerability that permitted the security breach is patched. Traditionally, penetrate-and-patch tactics were the domain of elite security professionals and consultants whose methods and tools were as secretive as their services were expensive. More recently, many of their methods and tools have been captured in several public domain security tools. These tools have been hailed as bringing computer security analysis to the average desktop computer user. However, they have also been criticized for putting years of security experience into the hands of computer crackers in the form of simple <b>point-and-click</b> <b>tools.</b> Penetrate and patch, and the tools that help automate it...|$|R
40|$|Figure 1 : Example {{results of}} light fields edited by {{different}} users. Top: A synthetic light field (vase), with ground truth depth information. Bottom: Two real light fields (toys and motorbike) captured with the Lytro camera. In this work we evaluate {{the benefits of}} different light field interaction paradigms and tools, and draw conclusions to help guide future interface designs for light field editing. We present a thorough study to evaluate different light field edit-ing interfaces, tools and workflows from a user perspective. This is of special relevance given the multidimensional nature of light fields, which may make common image editing tasks become com-plex in light field space. We additionally investigate {{the potential benefits of}} using depth information when editing, and the limita-tions imposed by imperfect depth reconstruction using current tech-niques. We perform two different experiments, collecting both ob-jective and subjective data from a varied number of editing tasks of increasing complexity based on local <b>point-and-click</b> <b>tools.</b> In the first experiment, we rely on perfect depth from synthetic light fields, and focus on simple edits. This allows us to gain basic in-sight on light field editing, and to design a more advanced editing interface. This is then used in the second experiment, employing real light fields with imperfect reconstructed depth, and covering more advanced editing tasks. Our study shows that users can edit light fields with our tested interface and tools, even in the presence of imperfect depth. They follow different workflows depending on the task at hand, mostly relying on a combination of different depth cues. Last, we confirm our findings by asking a set of artists to freely edit both real and synthetic light fields...|$|R
5000|$|Arch Linux {{focuses on}} {{simplicity}} of design, {{meaning that the}} main focus involves creating {{an environment that is}} straightforward and relatively easy for the user to understand directly, rather than providing polished <b>point-and-click</b> style management <b>tools</b> â€” the package manager, for example, does not have an official graphical front-end. This is largely achieved by encouraging the use of succinctly commented, clean configuration files that are arranged for quick access and editing. This has earned it a reputation as a distribution for [...] "intermediate and advanced Linux users who aren't afraid of the command line".|$|R
40|$|The World-Wide Web (W 3) {{is a way}} {{of viewing}} all the online {{information}} available on the Internet as a seamless, browsable continuum. Using hypertext jumps and searches, the user navigates through an information world partly hand-authored, partly computer -generated from existing databases and information systems. The web today incorporates all information from more basic information systems such as Gopher as WAIS, as well as sophisticated multimedia and hypertext information from many organizations. As a user interface tool, W 3 clients provides a comprehensive <b>point-and-click</b> network access <b>tools,</b> while W 3 servers provide an efficient, friendly method of providing data to real users. This paper answers some commonly asked questions about W 3, such as those comparing it with other systems, and about recent developments and future directions global hypermedia will take. I. What is the World-Wide Web? If you haven't come across the web before, the best way to find out about it is to try [...] ...|$|R

