655|2527|Public
25|$|The {{adoption}} of high power fiber lasers as an industrial material <b>processing</b> <b>tool</b> has been ongoing {{for several years}} and is now expanding into other markets including the medical and scientific markets. One key enhancement enabling penetration into the scientific market has been the improvements in high finesse fiber amplifiers, which are now capable of delivering single frequency linewidths (<5nbsp&kHz) together with excellent beam quality and stable linearly polarized output. Systems meeting these specifications, have steadily progressed {{in the last few years}} from a few Watts of output power, initially to the 10s of Watts and now into the 100s of Watts power level. This power scaling has been achieved with developments in the fiber technology, such as the {{adoption of}} stimulated brillouin scattering (SBS) suppression/mitigation techniques within the fiber, along with improvements in the overall amplifier design. The latest generation of high finesse, high power fiber amplifiers now deliver power levels exceeding what is available from commercial solid-state single frequency sources and are opening up new scientific applications as a result of the higher power levels and stable optimized performance.|$|E
50|$|Qmaster 3 - a {{distributed}} <b>processing</b> <b>tool.</b>|$|E
5000|$|MeshLab an {{open source}} mesh <b>processing</b> <b>tool</b> that {{is able to}} {{accurately}} simplify 3D polygonal meshes.|$|E
2500|$|... signal - Signal <b>processing</b> <b>tools,</b> {{including}} filtering, windowing {{and display}} functions ...|$|R
5000|$|... “Digital <b>Processing</b> <b>Tools</b> Present Design Challenges,” May 13, 1981, pps. 103-109 ...|$|R
5000|$|Standard Word <b>Processing</b> <b>Tools</b> - spell-checking, special {{character}} insertion, find/change, redo/undo ...|$|R
50|$|VirtualDubMod was an {{open source}} video capture and <b>processing</b> <b>tool</b> for Microsoft Windows, based on Avery Lee's VirtualDub.|$|E
5000|$|... {{a credit}} card <b>processing</b> <b>tool,</b> Payments by Wave, built {{initially}} on an integration with Stripe credit card processing.|$|E
5000|$|MeshLab an {{open source}} mesh <b>processing</b> <b>tool</b> that {{includes}} a GNU General Public License implementation of the ICP algorithm.|$|E
5000|$|... signal - Signal <b>processing</b> <b>tools,</b> {{including}} filtering, windowing {{and display}} functions ...|$|R
5000|$|... 2007 IKIS {{automation}} on Linux, and Xtools film-specific native <b>processing</b> <b>tools</b> introduced.|$|R
40|$|Increasingly {{available}} high-resolution brain imaging data require specialized <b>processing</b> <b>tools</b> {{that can}} leverage their anatomical detail and handle their size. Here, we present user-friendly Python tools for cortical depth resolved analysis in such data. Our implementation {{is based on}} the CBS High-Res Brain Processing framework, and aims to make high-resolution data <b>processing</b> <b>tools</b> available to the broader community...|$|R
5000|$|MeshLab [...] - [...] a {{cross-platform}} {{open source}} mesh <b>processing</b> <b>tool</b> that allows to import point clouds reconstructed by Photosynth ...|$|E
50|$|Ecasound is a hard-disk {{recording}} and audio <b>processing</b> <b>tool</b> for Unix-like computer operating systems including Linux, Mac OS X, and FreeBSD.|$|E
5000|$|CloudCompare an {{open source}} point and model <b>processing</b> <b>tool</b> that {{includes}} an {{implementation of the}} ICP algorithm. Released under the GNU General Public License.|$|E
5000|$|Opticks {{participated in}} GSoC 2011 under the OSGeo {{organization}} with three students. The titles of the accepted projects were [...] "Photography <b>processing</b> <b>tools</b> for Opticks", [...] "Development {{of a ship}} detection and classification toolkit for SAR imagery in Opticks", and [...] "Astronomical <b>processing</b> <b>tools</b> for Opticks. Extensions for the projects are available here, here, and here.|$|R
5000|$|... #Caption: Advanced {{friction}} stir welding and <b>processing</b> <b>tools</b> by MegaStir shown {{upside down}} ...|$|R
40|$|International audienceResearch in {{neuroscience}} {{makes an}} {{extensive use of}} modern neuroimaging data. The ability to share such data as well as <b>processing</b> <b>tools</b> to analyze them becomes a key factor of success of future research. This paper reports about works {{carried out in the}} context of the Neurobase project, a collaborative exploratory action supported by the French Ministry of Research. The partners have studied the design of a system suitable for sharing heterogeneous data and image <b>processing</b> <b>tools,</b> according to a federated approach, based on a common ontology. A demonstrator has been implemented, providing basic services for querying data and launching <b>processing</b> <b>tools</b> distributed at several sites...|$|R
5000|$|Multilinear PCA may {{be applied}} to compute the causal factors of data formation,or as signal <b>processing</b> <b>tool</b> on data tensors whose {{individual}} observation have either been vectorized ...|$|E
5000|$|... 2004, Laser Processing (LP) system, a rapid thermal <b>processing</b> <b>tool</b> which overcame a {{potential}} technology gap in Moore's Law, by allowing semiconductor manufacturers to advance beyond the 65-nm node.|$|E
5000|$|... a title {{number or}} a list item number {{difference}} {{can be of}} no interest if these numbers will be re-calculated afterward before printing or publishing by a text <b>processing</b> <b>tool,</b> ...|$|E
40|$|International audienceCollaborative {{biomedical}} imaging research raises {{the issue of}} coherently sharing data and <b>processing</b> <b>tools</b> involved in multi-centric studies. Federative approaches are gaining increasing credibility and success to build distributed collaborative platforms. In {{the context of the}} NeuroLOG project, we designed the OntoNeuroLOG ontology as a cornerstone of our mediation layer. This contribution focuses on <b>processing</b> <b>tools</b> and is two-fold. We propose an extension of the OntoNeuroLOG ontology to conceptualize shared <b>processing</b> <b>tools</b> and enable their semantic annotation. Leveraging this modeling, we propose a set of semantic treatments aimed at easing their sharing, their reuse and their invocation in the context of neuro-data processing workflows...|$|R
5000|$|... #Caption: Mosaic {{of all the}} Zond 3 images {{created with}} modern image <b>processing</b> <b>tools.</b>|$|R
40|$|BackgroundToday, {{manufacturing}} companies are facing greater demands regarding customer customization leading to higher competition regarding meeting demands for high quality, low {{cost of production}} with short lead times. It is vital that companies prioritize and make the right trade-offs between resource utilization, capitalization and delivery service. With a well desired inventory management, the lowest possible inventory levels can be developed to meet the desired customer service policy. Lower inventory levels also contribute to reduced capitalization and inventory costs. The study was carried out at O-fabriken, at VCE Skövde, where end-processing and assembly of valve seats and valve guide in the cylinder heads are installed. O-fabriken has experienced some uncertainties regarding how many <b>processing</b> <b>tools</b> {{that needs to be}} in circulation, given a certain volume of production. At the company there is currently no detailed plan for how the inventory control should be carried out. The inventory control is carried out largely by experience, which means that the number of <b>processing</b> <b>tools</b> in circulation is difficult to estimate. PurposeThe {{purpose of this study was}} to investigate how the inventory control of <b>processing</b> <b>tools</b> can be rationalized in order to reduce costs and secure management of tools. The study aimed further to: 1. Identify which factors affect the handling and storage of cutting <b>processing</b> <b>tools.</b> 2. Describe how cutting <b>processing</b> <b>tools</b> can be protected to avoid damage of personnel and tools. 3. Develop an inventory control model that highlights the input parameters that effect the turnover of the number of <b>processing</b> <b>tools.</b> MethodThe study has been conducted using a qualitative research approach. A deductive research approach has been used as the starting point was taken in an already existing theory within inventory control, inventory planning, Tool Management, safety and safekeeping. The research strategy in this study consists of a case study and has during the period January to June 2012 been performed at O-fabriken, VCE. The data collection has been gathered through data observations, interviews and benchmarking. ConclusionThe result of the study demonstrates that many of the factors that affect the handling of a storage of cutting <b>processing</b> <b>tools</b> also exist within inventory control of items. However, there are some changes that are needed to be done in order to adapt inventory control to <b>processing</b> <b>tools</b> and avoid damage to personnel and tools. Following factors have been found to be important to consider when handling and storing tools: service levels, inventory turnover, storage systems, ABC-classification, repair capacity, safety, 5 S, speed of refill, system availability, maintenance scheduling and information exchange. <b>Processing</b> <b>tools</b> should be stored in sealed storage system with high capacity and high reliability. When designing the inventory management model a first step was to develop the parameters that affect inventory control of <b>processing</b> <b>tools.</b> Subsequently, information was gathered about each parameter in order to perform calculations regarding the number of <b>processing</b> <b>tools</b> in turnover and associated costs with savings opportunity. Validerat; 20120619 (anonymous...|$|R
50|$|As of version 6, Lotus {{established}} an XML programming interface {{in addition to}} the options already available. The Domino XML Language (DXL) provides XML representations of all data and design resources in the Notes model, allowing any XML <b>processing</b> <b>tool</b> to create and modify IBM Notes and Domino data.|$|E
50|$|We {{will try}} to remove the {{artefacts}} by applying a low-pass filter on the trace of figure 3. We used MATLABS signal <b>processing</b> <b>tool</b> and created a low-passfilter (Zero-phase IIR-filter) on fig.4 with cutoff frequency at 120 Hz. The amplitude response of the filter is in blue and the phase in green.|$|E
50|$|Helicon Focus is a {{proprietary}} commercial digital image <b>processing</b> <b>tool,</b> first released in 2003, developed {{and published by}} Helicon Soft Limited. Like programs such as CombineZ or Zerene Stacker, Helicon Focus is designed to blend the focused areas of several partially focused digital photographs to increase the depth of field (DOF) in an image.|$|E
5000|$|Grepable: output that is {{tailored}} to line-oriented <b>processing</b> <b>tools</b> such as grep, sed or awk.|$|R
50|$|There is no {{definite}} list {{of poison}} words which all natural language <b>processing</b> <b>tools</b> incorporate.|$|R
5000|$|Incorporation of data <b>processing</b> <b>tools</b> (such as {{specific}} applications) and documents (such as office products) ...|$|R
5000|$|It will be {{implemented}} as a portal that includes a Web-based word <b>processing</b> <b>tool</b> akin to GoogleDocs, a wiki-based intelligence community encyclopedia and access to three [...] "huge, terabyte databases" [...] of [...] "raw" [...] (i.e., not yet evaluated) data for analysts to examine. It will be scaled for 10,000 users at day one.|$|E
50|$|Structural applications: Quek et al. 2003 {{illustrate}} {{the feasibility of}} the HHT as a signal <b>processing</b> <b>tool</b> for locating an anomaly {{in the form of}} a crack, delamination, or stiffness loss in beams and plates based on physically acquired propagating wave signals. Using HHT, Li et al. 2003 analyzed the results of a pseudodynamic test of two rectangular reinforced concrete bridge columns.|$|E
5000|$|Aurora HDR is a High Dynamic Range (HDR) {{editing and}} <b>processing</b> <b>tool</b> {{released}} in November, 2015. It was made through {{a collaboration between}} software developer Macphun and HDR photographer Trey Ratcliff. [...] HDR image editing techniques are designed to overcome difficult lighting situations where highlights and shadows are prevalent in the same image, but have also been used to create highly processed, fanciful images as well.|$|E
40|$|Complex {{interfaces}} for audio <b>processing</b> <b>tools</b> {{can prevent}} novices from achieving their desired modifications. Here we adapt a correlational method used widely in psychoacoustics to quickly map from high-level language-based descriptors (such as ‘‘warm’’) to audio processing parameters. This allows automated construction of simpler interfaces for audio <b>processing</b> <b>tools.</b> This approach {{was applied to}} and evaluated on an audio equalizer and an artificial reverberator. ...|$|R
50|$|A {{new class}} of raw file <b>processing</b> <b>tools</b> {{appeared}} {{with the development of}} HTML5 - rich Internet applications.|$|R
50|$|Voxy has pioneered {{numerous}} {{innovations in}} contextual learning, {{including the use}} of natural language <b>processing</b> <b>tools</b> and geo-location.|$|R
