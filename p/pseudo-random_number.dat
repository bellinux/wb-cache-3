560|207|Public
25|$|<b>Pseudo-random</b> <b>number</b> {{sampling}} algorithms {{are used}} to transform uniformly distributed pseudo-random numbers into numbers that are distributed according to a given probability distribution.|$|E
25|$|Inverse {{transform}} sampling (also {{known as}} inversion sampling, the inverse probability integral transform, the inverse transformation method, Smirnov transform, golden rule) {{is a basic}} method for <b>pseudo-random</b> <b>number</b> sampling, i.e. for generating sample numbers at random from any probability distribution given its cumulative distribution function.|$|E
25|$|Variant A {{generates a}} list of 250 domain names every day across five TLDs. The domain names are {{generated}} from a <b>pseudo-random</b> <b>number</b> generator (PRNG) seeded with the current date to ensure that every copy of the virus generates the same names each day. The virus then attempts an HTTP connection to each domain name in turn, expecting from any of them a signed payload.|$|E
40|$|Given {{the recent}} {{explosion}} {{of interest in}} human authentication, verification based on tokenized <b>pseudo-random</b> <b>numbers</b> and the user-specific biometric feature has received much attention. These methods have significant functional advantages over solely biometrics, i. e. zero equal error rate. The main drawback of the methods proposed in the literature relies in exhibiting low performance when an ''impostor''B steals the <b>pseudo-random</b> <b>numbers</b> of A and he tries to authenticate as A. In this paper, we show that a multimodal fusion, where only one biometric characteristic is combined with the <b>pseudo-random</b> <b>numbers,</b> permits to obtain a zero equal error rate when nobody steals the <b>pseudo-random</b> <b>numbers,</b> and good performance when an ''impostor''B steals the <b>pseudo-random</b> <b>numbers</b> of A and he tries to authenticate as A. In this paper, we study the fusion among the score obtained by a Face Recognizer (where the face features are combined with <b>pseudo-random</b> <b>numbers)</b> and the scores of the systems submitted to FVC 2004...|$|R
40|$|Given {{the recent}} {{explosion}} {{of interest in}} human authentication, verification based on tokenised <b>pseudo-random</b> <b>numbers</b> and the user specific biometric feature has received much attention. These methods have significant functional advantages over solely biometrics i. e. zero equal error rate (EER). The main drawback of the methods proposed in the literature relies in exhibiting low performance when an ''impostor''B steals the <b>pseudo-random</b> <b>numbers</b> of A and he tries to authenticate as A. In this paper, we show that a fusion among on-line signature matchers, where only half the matchers use biometric characteristics combined with the <b>pseudo-random</b> <b>numbers,</b> permits to obtain a very low EER when nobody steals the <b>pseudo-random</b> <b>numbers,</b> and good performance when an ''impostor''B steals the <b>pseudo-random</b> <b>numbers</b> of A and he tries to authenticate as A...|$|R
40|$|Generation of Laplace-distributed (double exponential) <b>pseudo-random</b> <b>numbers</b> using GAUSS (version 3. 6 or later). That is, {{generation}} of random variates {{that come from}} a density proportional to: exp(-abs(x) /b). Laplace distribution, Double exponential, random <b>numbers,</b> <b>pseudo-random</b> <b>numbers,</b> Laplace variates, GAUSS...|$|R
25|$|The Box–Muller transform, by George Edward Pelham Box and Mervin Edgar Muller, is a <b>pseudo-random</b> <b>number</b> {{sampling}} method for generating pairs of independent, standard, normally distributed (zero expectation, unit variance) random numbers, given {{a source of}} uniformly distributed random numbers. The method was in fact first mentioned by Raymond E. A. C. Paley and Norbert Wiener in 1934, and {{it is more likely}} than not that this source was well known to Box and Muller, which, however, failed to cite it in their article of 1958.|$|E
25|$|LFSRs {{have long}} been used as <b>pseudo-random</b> <b>number</b> {{generators}} for use in stream ciphers (especially in military cryptography), due to the ease of construction from simple electromechanical or electronic circuits, long periods, and very uniformly distributed output streams. However, an LFSR is a linear system, leading to fairly easy cryptanalysis. For example, given a stretch of known plaintext and corresponding ciphertext, an attacker can intercept and recover a stretch of LFSR output stream used in the system described, and from that stretch of the output stream can construct an LFSR of minimal size that simulates the intended receiver by using the Berlekamp-Massey algorithm. This LFSR can then be fed the intercepted stretch of output stream to recover the remaining plaintext.|$|E
25|$|Chaos {{theory has}} been used for many years in cryptography. In the past few decades, chaos and {{nonlinear}} dynamics have been used in the design of hundreds of cryptographic primitives. These algorithms include image encryption algorithms, hash functions, secure <b>pseudo-random</b> <b>number</b> generators, stream ciphers, watermarking and steganography. The majority of these algorithms are based on uni-modal chaotic maps and a big portion of these algorithms use the control parameters and the initial condition of the chaotic maps as their keys. From a wider perspective, without loss of generality, the similarities between the chaotic maps and the cryptographic systems is the main motivation for the design of chaos based cryptographic algorithms. One type of encryption, secret key or symmetric key, relies on diffusion and confusion, which is modeled well by chaos theory. Another type of computing, DNA computing, when paired with chaos theory, offers a way to encrypt images and other information. Many of the DNA-Chaos cryptographic algorithms are proven to be either not secure, or the technique applied is suggested to be not efficient.|$|E
50|$|The CLCG {{provides}} an {{efficient way to}} calculate <b>pseudo-random</b> <b>numbers.</b> The LCG algorithm is computationally inexpensive to use. The results of multiple LCG algorithms are combined through the CLCG algorithm to create <b>pseudo-random</b> <b>numbers</b> with a longer period than is achievable with the LCG method by itself.|$|R
50|$|The {{generation}} of <b>pseudo-random</b> <b>numbers</b> having an approximately normal distribution is sometimes accomplished by computing {{the sum of}} a <b>number</b> of <b>pseudo-random</b> <b>numbers</b> having a uniform distribution; usually {{for the sake of}} simplicity of programming. Rescaling the Irwin-Hall distribution provides the exact distribution of the random variates being generated.|$|R
5000|$|... and [...] {{they produce}} a variable-length stream of <b>pseudo-random</b> <b>numbers.</b>|$|R
2500|$|... the (<b>pseudo-random)</b> <b>number</b> {{generator}} produces {{values that}} pass tests for randomness ...|$|E
2500|$|Inversive congruential {{generator}} - a <b>pseudo-random</b> <b>number</b> generator {{that uses}} modular multiplicative inverses ...|$|E
2500|$|... the (<b>pseudo-random)</b> <b>number</b> {{generator}} {{has certain}} characteristics (e.g., a long [...] "period" [...] before the sequence repeats) ...|$|E
40|$|Generation of heteroskedastic normal <b>pseudo-random</b> <b>numbers</b> using GAUSS (version 3. 6 or later). Drawings from a Chi-square with nu {{degrees of}} freedom are done first. Standard normal random numbers are next generated, and then they are {{transformed}} to have variances equal {{to the values of}} the Chi-square deviates. heteroskedastic normal distribution, heteroskedastic normal random <b>numbers,</b> <b>pseudo-random</b> <b>numbers,</b> variates, GAUSS...|$|R
40|$|Generation of <b>pseudo-random</b> <b>numbers</b> {{from the}} {{standard}} Exponential Power Distribution (EPD), {{also known as the}} standard Generalized Error Distribution (GED). The density function of the standard EPD is proportional to exp(-abs(x) ^tau), with "x" a real number and "tau" a shape parameter greater or equal to 1. exponential power distribution, generalized error distribution, <b>pseudo-random</b> <b>numbers,</b> variates, GAUSS...|$|R
5000|$|The {{expansion}} of the reciprocal 1/q in any base can also act [...] {{as a source of}} <b>pseudo-random</b> <b>numbers,</b> if q is a [...] "suitable" [...] safe prime, a prime of the form 2p + 1 where p is also a prime. A sequence of <b>pseudo-random</b> <b>numbers</b> of length q &minus; 1 will be produced by the expansion.|$|R
2500|$|A simple {{algorithm}} {{to generate}} random Poisson-distributed numbers (<b>pseudo-random</b> <b>number</b> sampling) {{has been given}} by Knuth (see References below): ...|$|E
2500|$|The {{number of}} points [...] in the window, denoted here by , needs to be simulated, which is done by using a (<b>pseudo)-random</b> <b>number</b> {{generating}} function capable of simulating Poisson random variables.|$|E
2500|$|Randomness {{intrinsically}} {{generated by}} the system. This is also called pseudorandomness and is the kind used in <b>pseudo-random</b> <b>number</b> generators. There are many algorithms (based on arithmetics or cellular automaton) to generate pseudorandom numbers. The behavior of the system can be determined by knowing the seed state and the algorithm used. These methods are often quicker than getting [...] "true" [...] randomness from the environment.|$|E
50|$|The {{following}} program generates <b>pseudo-random</b> <b>numbers</b> {{within the}} range of 1 to 6.|$|R
40|$|Generation of Pareto-distributed <b>pseudo-random</b> <b>numbers</b> using GAUSS (version 3. 6 or later), by the {{inversion}} method. That is, {{generation of}} random variates {{that come from}} a density proportional to x^(-a- 1), where a> 0 and x>=b for some location parameter b> 0. Zipf distribution is obtained when a= 1. Pareto distribution, Zipf distribution, Pareto random numbers, Zipf random <b>numbers,</b> <b>pseudo-random</b> <b>numbers,</b> variates, GAUSS...|$|R
40|$|Enigma {{machines}} are devices that perform cryptography using <b>pseudo-random</b> <b>numbers.</b> The original enigma machine code {{was broken by}} detecting hidden patterns in these <b>pseudo-random</b> <b>numbers.</b> This paper proposes {{a model for a}} quantum optical enigma machine and shows that the phenomenon of quantum data locking makes such quantum enigma machines provably secure even in the presence of noise and loss. Comment: 9 pages, plain Te...|$|R
2500|$|This stretching-and-folding {{does not}} just produce a gradual {{divergence}} of the sequences of iterates, but an exponential divergence (see Lyapunov exponents), evidenced {{also by the}} complexity and unpredictability of the chaotic logistic map. [...] In fact, exponential divergence of sequences of iterates explains the connection between chaos and unpredictability: a small error in the supposed initial state of the system will tend to correspond to a large error later in its evolution. [...] Hence, predictions about future states become progressively (indeed, exponentially) worse when there are even very small errors in {{our knowledge of the}} initial state. This quality of unpredictability and apparent randomness led the logistic map equation {{to be used as a}} <b>pseudo-random</b> <b>number</b> generator in early computers.|$|E
50|$|A cryptographically secure <b>pseudo-random</b> <b>number</b> {{generator}} (CSPRNG) or cryptographic <b>pseudo-random</b> <b>number</b> generator (CPRNG) is a <b>pseudo-random</b> <b>number</b> generator (PRNG) with {{properties that}} make it suitable for use in cryptography.|$|E
5000|$|<b>Pseudo-random</b> <b>number</b> generation, {{including}} Mersenne Twister MT19937.|$|E
50|$|Safe primes obeying certain congruences {{can be used}} to {{generate}} <b>pseudo-random</b> <b>numbers</b> of use in Monte Carlo simulation.|$|R
3000|$|... [...]) to be Mersenne Twister <b>pseudo-random</b> <b>numbers</b> {{given by}} the random-real {{function}} of srfi- 27, Gauche.a We also set [...]...|$|R
3000|$|... shared; additionally, two arrays whose size {{equal the}} number of threads in a block are {{allocated}} for uniform <b>pseudo-random</b> <b>numbers</b> U [...]...|$|R
5000|$|<b>Pseudo-random</b> <b>number</b> {{generator}} (PRNG) which generates {{session keys}} ...|$|E
50|$|This <b>pseudo-random</b> <b>number</b> {{system is}} much weaker {{than the usual}} system of {{superencipherment}} but as an emergency backup system {{it would have been}} adequate and certainly better than using a transposition or simple substitution cipher. Like any other cipher system, breaking a <b>pseudo-random</b> <b>number</b> system just requires a sufficient amount of intercepted ciphertext.|$|E
50|$|For the {{generation}} of non-uniform random variates, see <b>Pseudo-random</b> <b>number</b> sampling.|$|E
25|$|Applications of LFSRs include {{generating}} <b>pseudo-random</b> <b>numbers,</b> pseudo-noise sequences, fast digital counters, and whitening sequences. Both {{hardware and}} software implementations of LFSRs are common.|$|R
40|$|Given {{the recent}} {{explosion}} {{of interest in}} human authentication, verification based on tokenised <b>pseudo-random</b> <b>numbers</b> and user-specific biometric feature (BioHashing) has received much attention. The purpose of our paper is to investigate the pros and the cons of BioHashing. In particular we study: how to combine BioHashing in a multi-modal fusion approach based on the integration of face and fingerprint data; how to combine BioHashing and user specific Iris features. The results of this paper confirm that a multi-modal biometric can overcome some {{of the limitations of}} a single biometric resulting in a substantial performance improvement. Moreover, we show that a multi-matcher system based on the fusion between “BioHashed” Iris features and a “standard” Iris matcher permits to obtain good performance when an “impostor” steals the <b>pseudo-random</b> <b>numbers,</b> and a near zero Equal Error Rate when nobody steals the <b>pseudo-random</b> <b>numbers...</b>|$|R
40|$|The {{generation}} of <b>pseudo-random</b> <b>numbers</b> {{is one of}} the interesting problems in Monte Carlo simulations, mostly because the common computer generators produce periodic numbers. We used simple <b>pseudo-random</b> <b>numbers</b> generated with the simplest chaotic system, the logistic map, with excellent results. The numbers generated in this way are non-periodic, which we demonstrated for 10 $^{ 13 }$ numbers, and they are obtained in a deterministic way, which allows to repeat systematically any calculation. The Monte Carlo calculations are the ideal field to apply these numbers, and we did it for simple and more elaborated cases. Chemistry and Information Technology use this kind of simulations, and the application of this numbers to Quantum Monte Carlo and Cryptography is immediate. I present here the techniques to calculate, analyze and use these <b>pseudo-random</b> <b>numbers,</b> show that they lack periodicity up to 10 $^{ 13 }$ numbers and that they are not correlated...|$|R
