230|79|Public
5000|$|Out-of-core {{rendering}} mode for visualizing large <b>point-cloud</b> datasets ...|$|E
50|$|On November 8, 2011, Bentley {{acquired}} Pointools Ltd., an England {{developer of}} <b>point-cloud</b> software technology.|$|E
5000|$|... 3D Body Scanning is an {{application}} of various technologies such as Structured-light 3D Scanner, 3D depth sensing, stereoscopic vision and others for ergonomic and anthropometric investigation of the human form as a <b>point-cloud.</b> The technology and practice within research has found 3D Body scanning measurement extraction methodologies to be comparable to traditional anthropometric measurement techniques.|$|E
40|$|AbstractThe {{advent of}} {{high-performance}} terrestrial laser scanners {{has made it}} possible to capture dense <b>point-clouds</b> of engineering facilities. 3 D shape acquisition from engineering facilities is useful for supporting maintenance and repair tasks. In this paper, we discuss methods to reconstruct box shapes and polygonal prisms from large-scale <b>point-clouds.</b> Since many faces may be partly occluded by other objects in engineering plants, we estimate possible box shapes and polygonal prisms and verify their compatibility with measured <b>point-clouds.</b> We evaluate our method using actual <b>point-clouds</b> of engineering plants...|$|R
40|$|This paper {{introduces}} a new visibility model for 3 -D <b>point-clouds,</b> {{such as those}} obtained from multiple time-of-flight or lidar scans. The scene is represented {{by a set of}} random particles, statistically distributed around the available surface-samples. Visibility is de-fined as the appropriate conjunction of occupancy and vacancy probabilities, along any visual ray. These probabilities are subsequently derived, in relation to the statistical scene structure. The resulting model can be used to assign probabilistic visibilities to any col-lection of scene-points, with respect to any camera position. Moreover, these values can be compared between different rays, and treated as functions of the camera and scene pa-rameters. No surface mesh or volumetric discretization is required. The model is tested by decimating 3 -D <b>point-clouds,</b> and estimating the visibility of randomly selected tar-gets. These estimates are compared to reference values, computed by standard methods, from the original full-resolution <b>point-clouds.</b> Applications of the new visibility model to multi-view stereo are discussed. ...|$|R
40|$|The {{field of}} {{research}} connected to mobile robot navigation is much broader than {{the scope of this}} thesis. Hence in this report, the navigation topic is narrowed down to primarily concerning mapping and scan matching techniques that were used to achieve the overall task of navigation nature. Where the work presented within this report is based on an existing robot platform with technique for providing 3 D <b>point-clouds,</b> as result of 3 D scanning, and functionality for planning for and following a path. In this thesis it is presented how a scan matching algorithm is used for securing the alignment between provided succession <b>point-clouds.</b> Since the computational time of nearest neighbour search is a commonly discussed aspect of scan matching, suggestions about techniques for decreasing the computational time are also presented within this report. With secured alignment, the challenge was within representing provided <b>point-clouds</b> by a map model. Provided <b>point-clouds</b> were of 3 D character, thus a mapping technique is presented that provides rough 3 D representations of the environment. A problem that arose with a 3 D map representation was that given functionality for path planning required a 2 D representation. This is addressed by translating the 3 D map at a specific height level into a 2 D map usable for path planning, where this report suggest a novel traversability analysis approach {{with the use of a}} tree structure. ...|$|R
50|$|Using a set {{of points}} taken from a 3-dimensional space and put into a BSP tree, and given a query point taken from the same space, a {{possible}} {{solution to the problem}} of finding the nearest <b>point-cloud</b> point to the query point is given in the following description of an algorithm. (Strictly speaking, no such point may exist, because it may not be unique. But in practice, usually we only care about finding any one of the subset of all <b>point-cloud</b> points that exist at the shortest distance to a given query point.) The idea is, for each branching of the tree, guess that the closest point in the cloud resides in the half-space containing the query point. This may not be the case, but it is a good heuristic. After having recursively gone through all the trouble of solving the problem for the guessed half-space, now compare the distance returned by this result with the shortest distance from the query point to the partitioning plane. This latter distance is that between the query point and the closest possible point that could exist in the half-space not searched. If this distance is greater than that returned in the earlier result, then clearly there is no need to search the other half-space. If there is such a need, then you must go through the trouble of solving the problem for the other half space, and then compare its result to the former result, and then return the proper result. The performance of this algorithm is nearer to logarithmic time than linear time when the query point is near the cloud, because as the distance between the query point and the closest <b>point-cloud</b> point nears zero, the algorithm needs only perform a look-up using the query point as a key to get the correct result.|$|E
50|$|Computer Aided Inspection (CAI) {{is a new}} {{technology}} that enables one to develop a comparison of a physical part to a 3D CAD model. This process is faster, more complete, and more accurate than using a Coordinate Measuring Machine (CMM) or other more traditional methods. An automatic inspection method and apparatus using structured light and machine vision camera is used to inspect an object {{in conjunction with the}} geometric model of the object. Camera images of the object are analyzed by computer to produce the location of points on the object's surfaces in three dimensions. <b>Point-cloud</b> data is taken from a laser scanner or other 3-D scanning device. During a setup phase before object inspection, the points are analyzed with respect to the geometric model of the object. The software provides a graphical comparison of the manufactured part compared to the CAD model. Many points are eliminated to reduce data-taking and analysis time to a minimum and prevent extraneous reflections from producing errors. When similar objects are subsequently inspected, points from each surface of interest are spatially averaged to give high accuracy measurements of object dimensions. The inspection device uses several multiplexed sensors, each composed of a camera and a structured light source, to measure all sides of the object in a single pass.|$|E
40|$|In this paper, {{we propose}} {{a method for}} {{panoramic}} <b>point-cloud</b> rendering-based polygon extraction from indoor mobile LiDAR data. Our aim was to improve region-based <b>point-cloud</b> clustering in modeling after <b>point-cloud</b> registration. First, we propose a <b>point-cloud</b> clustering methodology for polygon extraction on a panoramic range image generated with point-based rendering from a massive point cloud. Next, we describe an experiment that was conducted to verify our methodology with an indoor mobile mapping system in an indoor environment. This experiment was wall-surface extraction using a rendered <b>point-cloud</b> from 64 viewpoints over a wide indoor area. Finally, we confirmed that our proposed methodology could achieve polygon extraction through <b>point-cloud</b> clustering from a complex indoor environment. 1...|$|E
40|$|This letter {{presents}} a novel algorithm for automated building detection from {{light detection and ranging}} (lidar) <b>point-clouds.</b> The algorithm {{takes advantage of}} a marked point process to model the locations of buildings and their geometries. A Bayesian paradigm is used to obtain a posterior distribution for the marked point process. A Reversible Jump Markov Chain Monte Carlo (RJMCMC) algorithm is implemented for simulating the posterior distribution. Finally, the maximum a posteriori (MAP) scheme is used to obtain an optimal building detection. The results obtained on a set of lidar <b>point-clouds</b> demonstrate the efficiency of the proposed algorithm in automated detection of buildings in complex residential areas. ? 2013 Taylor and Francis...|$|R
40|$|Many visually-guided robotic systems rely on stereo {{video data}} streams to obtain surface models of environ-mental structure. However stereo video-based 3 D <b>point-clouds</b> are noisier than those {{produced}} from laser-based scanners and {{are subject to}} areas of sparse point informa-tion corresponding to textureless or specular surfaces. This complicates the process of constructing polygonal meshes from these <b>point-clouds.</b> This paper develops an approach to meshing for stereo video surface reconstruction that ad-dresses these issues and, by exploiting the known egomotion of the sensor, obtains surface normal and texture render-ing information. This widens the range of applications for which stereo video reconstruction can be applied and opens {{the possibility of using}} stereo video to generate models for real-time rendering applications. ...|$|R
40|$|International audienceThis paper {{presents}} {{a tool that}} enables the direct editing of surface features in large <b>point-clouds</b> or meshes. This is {{made possible by a}} novel multi-scale analysis of unstructured <b>point-clouds</b> that automatically extracts the number of relevant features together with their respective scale all over the surface. Then, combining this ingredient with an adequate multi-scale decomposition allows us to directly enhance or reduce each feature in an independent manner. Our feature extraction is based on the analysis of the scale-variations of locally fitted surface primitives combined with unsupervised learning techniques. Our tool may be applied either globally or locally, and millions of points are handled in real-time. The resulting system enables users to accurately edit complex geometries with minimal interaction...|$|R
40|$|Abstract. The {{reconstruction}} of 3 D objects from a <b>point-cloud</b> {{is based on}} sufficient separation of the points representing objects of interest from the points of other, unwanted objects. This operation called segmentation is discussed in this paper. We present an interactive unstructured <b>point-cloud</b> segmentation based on graph cut method where the cost function is derived from euclidean distance of <b>point-cloud</b> points. The graph to-pology and direct 3 D <b>point-cloud</b> segmentation are the novel parts of our work. The segmentation is presented on real application, the terrain {{reconstruction of}} a complex miniature paper model, the Langweil model of Prague...|$|E
40|$|Due to the {{intrinsic}} property of B-Spline surface, the surface reconstruction with scattered and chaos <b>point-cloud</b> is a challenging problem. This paper proposed a skinning surface algorithm of B-spline for scattered <b>point-cloud.</b> First, raw data was preprocessed including denoising, simplifying and slicing to obtain section data. Second, approximating cross section data into B-spline curves and resampling {{to ensure the}} common knot vector. Then the new data would be parameterized and interpolated into B-spline curves. Finally, surface of scatter <b>point-cloud</b> would be reconstructed by skinning. Experiments demonstrate that this method is easy to implement and provides an accurate surface model...|$|E
40|$|Abstract—Segmentation of <b>point-cloud</b> {{is still}} a {{challenging}} problem, regarding observation noise and various constraints defined by applications. These difficulties do not concede to its necessity for almost all kinds of modeling approaches using <b>point-cloud.</b> However, the criteria to justify {{the quality of a}} clustering result are not much studied. In this paper, we first propose a <b>point-cloud</b> segmentation algorithm using adapted k-means to cluster normal vectors obtained from tensor voting. Then we concentrate on how to use a non-parametrical criterion to validate the clustering results, which is an approximation of the information introduced by the clustering process. Compared with other approaches, we use noisy <b>point-cloud</b> obtained from moving laser range finders directly, instead of reconstruction of 3 d grid-cells or meshing. Moreover, the criterion does not rely on the assumption of distributions of points. We show the distinguishable characteristics using the proposed criteria, as well as the better performance of the novel clustering algorithm against other approaches. I...|$|E
40|$|A {{mobile robot}} that accomplishes high level tasks {{needs to be}} able to {{classify}} the objects in the environment and to determine their location. In this paper, we address the problem of online object detection in 3 D laser range data. The object classes are represented by 3 D <b>point-clouds</b> that can be obtained from a set of range scans. Our method relies on the extraction of point features from range images that are computed from the <b>point-clouds.</b> Compared to techniques that directly operate on a full 3 D representation of the environment, our approach requires less computation time while retaining the robustness of full 3 D matching. Experiments demonstrate that the proposed approach is even able to deal with partially occluded scenes and to fulfill the runtime requirements of online applications. © 2009 IEEE...|$|R
40|$|Abstract—A {{mobile robot}} that accomplishes high level tasks {{needs to be}} able to {{classify}} the objects in the environment and to determine their location. In this paper, we address the problem of online object detection in 3 D laser range data. The object classes are represented by 3 D <b>point-clouds</b> that can be obtained from a set of range scans. Our method relies on the extraction of point features from range images that are computed from the <b>point-clouds.</b> Compared to techniques that directly operate on a full 3 D representation of the environment, our approach requires less computation time while retaining the robustness of full 3 D matching. Experiments demonstrate that the proposed approach is even able to deal with partially occluded scenes and to fulfill the runtime requirements of online applications. Index Terms—Object detection, point clouds, range images I...|$|R
40|$|Goal of {{this thesis}} is to {{implement}} interactive 3 D editor {{able to work}} with unorganized <b>point-clouds.</b> Nontraditional graphics primitive needs nontraditional editing tools, author should propose and implement several instruments and verify their behavior in real editing tasks. Particular problems to be solved: efficient data representation and persistence, normal vector computation, dynamic level-of-detail, isotropic point density, etc...|$|R
40|$|International audienceIn this paper, {{we present}} {{the results of the}} SHREC' 17 Track: <b>Point-Cloud</b> Shape Retrieval of Non-Rigid Toys. The aim of this track is to create a fair {{benchmark}} to evaluate the performance of methods on the non-rigid <b>point-cloud</b> shape retrieval problem. The database used in this task contains 100 3 D <b>point-cloud</b> models which are classified into 10 different categories. All point clouds were generated by scanning each one of the models in their final poses using a 3 D scanner, i. e., all models have been articulated before scanned. The retrieval performance is evaluated using seven commonly-used statistics (PR-plot, NN, FT, ST, E-measure, DCG, mAP). In total, there are 8 groups and 31 submissions taking part of this contest. The evaluation results shown by this work suggest that researchers are in the right way towards shape descriptors which can capture the main characteristics of 3 D models, however, more tests still need to be made, since {{this is the first time}} we compare non-rigid signatures for <b>point-cloud</b> shape retrieval...|$|E
40|$|We are {{describing}} a fully automatic in-line shape inspection system for controlling {{the shape of}} moving objects on a conveyor belt. The shapes of the objects are measured using a full-field optical shape measurement method based on photogrammetry. The photogrammetry system consists of four cameras, a flash, and a triggering device. When an object to be measured arrives at a given position relative to the system, the flash and cameras are synchronously triggered to capture images of the moving object. From the captured images a <b>point-cloud</b> representing the measured shape is created. The <b>point-cloud</b> is then aligned to a CAD-model, which defines the nominal shape of the measured object, using a best-fit method and a feature-based alignment method. Deviations between the <b>point-cloud</b> and the CAD-model are computed giving {{the output of the}} inspection process. The computational time to create a <b>point-cloud</b> from the captured images is about 30 seconds and the computational time for the comparison with the CAD-model is about ten milliseconds. We report on recent progress with the shape inspection system. SIVPR...|$|E
40|$|In many multi-view stereo (MVS) algorithms, a <b>point-cloud</b> {{evolution}} is performed, {{based on the}} matching process. For most of them, an assumption is usually employed for the matching, which indicates that the matching windows have the same shape. This assumption lays a great limit {{to the quality of}} the reconstructed result. To improve the pointcloud obtained from other algorithms, and break the limit laid by the regular matching, we propose our refinement method using exact matching. The exact matching enables more accurate matching windows for the points, by taking the normal vector into consideration. By maximizing the exact matching result, the point’s coordinate and normal vectors are optimized, and we can thus make the original <b>point-cloud</b> much better. Index Terms — MVS, <b>point-cloud,</b> exact matching 1...|$|E
40|$|Laser {{scanning}} {{is dependent}} on georeferencing by satellite positioning and inertial navigation to give orientation of each laser shot. An adjustment strategy is proposed for doing that simultaneously fitting laser scanner strips in 3 D. This paper presents the mathematical model used, that performs the covariance propagation for associate homologous points in the <b>point-clouds</b> created by Lidar (LIght Detection And Ranging). Pages: 3689 - 369...|$|R
40|$|Terrestrial laser {{scanning}} {{can be used}} in road safety analysis by providing flexible and fast 3 D documentation. The collected 3 D <b>point-clouds</b> data can be used as input to any CAD system. The data on sight, drainage and geometric design features can be extracted from the TLS models. Its accuracy makes it easy to check drainage conditions in difficult positions such as curbs and islands...|$|R
40|$|Conference Name: 5 th International Conference on Geo-Information Technologies for Natural Disaster Management, GiT 4 NDM 2013. Conference Address: Mississauga, ON, Canada. Time:October 9, 2013 - October 11, 2013. This paper {{presents}} a novel algorithm for detecting road manhole covers from mobile LiDAR <b>point-clouds.</b> This algorithm {{takes advantage of}} a marked point process of discs and rectangles to model the locations and geometric structures of the manhole and sewer well covers. The algorithm also uses the Bayesian paradigm to obtain a posterior distribution for the marked point process conditional on the geo-referenced intensity image. A Reversible Jump Markov Chain Monte Carlo (RJMCMC) algorithm is implemented to simulate the posterior distribution. Finally, the maximum a posteriori (MAP) scheme is used to obtain an optimal detection. This algorithm has been examined {{by a set of}} mobile LiDAR <b>point-clouds</b> acquired by a RIEGL VMX- 450 mobile laser scanning system. The results demonstrate the efficiency and feasibility of the proposed algorithm for automatically detecting road manhole and sewer well covers. ? 2013 IEEE...|$|R
40|$|Terrestrial Laser Scan (TLS) {{data are}} seeing {{increasing}} use in geology, geomorphology, forestry and urban mapping. The ease of use, affordability and operational flexibility of TLS suggests that demand {{for it is}} likely to increase in large scale mapping studies. However, its advantages may remain restricted to specific environments, due to difficulties in defining bare-ground level in the presence of ground level vegetation. This paper seeks to clarify the component contributions to TLS elevation error deriving from vegetation occlusion, scan co-registration error, <b>point-cloud</b> georeferencing error and target position-definition in TLS <b>point-cloud</b> data. A very high-resolution (c. 250 points/m 2) multi-scan single-returns TLS <b>point-cloud</b> data-set is acquired for an 11 -hectare area of open, substantially flat and 100 % vegetated coastal saltmarsh, providing data for the empirica...|$|E
40|$|Abandoning the scale-model {{concept in}} favor of an {{abstract}} representation led us {{to the development of a}} digital design model based on point-clouds as design media. In this paper we examine the potential usage of point-clouds as design media. Extending the <b>point-cloud</b> model with a forth dimension represented as a numeric pointer to generative algorithms provides a parametric interface for the regeneration and alteration of the extended <b>point-cloud</b> model referred to as “Smart Cloud of Points”...|$|E
40|$|Abstract – A {{method for}} {{detecting}} urban structures in an irregularly spaced <b>point-cloud</b> {{of an urban}} landscape is proposed. The method is especially designed for detecting structures that are extensions to the bare-earth (e. g., bridges, ramps, etc.,). The method involves a segmentation of a <b>point-cloud</b> followed by a classification. Both the segmentation and classification of the data {{are based on the}} analysis of a data structure in which the pointcloud is represented as an orthogonal set of profiles. Also proposed is a conceptual and logical model of the Landscape for the structure detection problem...|$|E
40|$|The {{scenario}} used {{focuses on}} object recognition {{in an office}} environment scene {{with the goal of}} classifying office equipment that is located on a table. The recognition system operates on three-dimensional <b>point-clouds</b> of objects on a loosely covered table where no previous information about the precise position of the table is given. As the <b>point-clouds</b> do not cover the complete objects and the data is noisy, especially for smaller objects a robust detection of special features is difficult. The workflow employed is a three step process: In a first step the table plane is detected and the point clouds of the objects are extracted from the surface. In the second step an object-oriented bounding-box is calculated to get the geometric dimensions, i. e. the properties measured. During a learning phase these simple features are used to calculate the parameters of Bayesian networks. The trained networks are used in the third step, i. e. the classification step. The dimensions of an unknown object form the input for a Bayesian network that yields the most probable object type...|$|R
40|$|Abstract. Spherical {{targets are}} useful for {{registration}} of <b>point-clouds.</b> In this paper we discuss the positioning uncertainty by laser scanners. We measured spheres of relatively large diameter from about 9 m distance, and calculated their positions by the least-squares fitting. The scanning was iterated thirty times and the standard deviations of fitting result were calculated to indicate positioning uncertainty. The result shows smaller positioning uncertainty {{in comparison with the}} range noise listed in the specifications...|$|R
40|$|The {{aim of this}} {{dissertation}} was {{the integration}} of a fringe projection system in a coordinate measuring machine. As a result large and complex workpieces can be digitalized fast, flexible and accurate. By digitalization of complex or large workpieces with the fringe projection system {{it is not possible}} to get the measuring data of the complete surface in one view. So it is necessary to merge sub-measuring fields respectively the <b>point-clouds.</b> In this dissertation workpiece surfaces are considered large or complex, if the workpiece that has to be digitalized is larger than the measuring field of the fringe projection system. If workpieces cannot be digitalized in one view because of reflection or shadowing effects, they are also considered large or complex. The registration (merging) of the sub-measuring fields results from the defined sensor position to the measuring object in the coordinate measuring machine. For this procedure it is necessary to know the relative position of the sensor coordinate system and the coordinate system of the CMM to each other. This is warranted by a special, that was developed in this dissertation, calibration procedure of the fringe projection system referring to the coordinate measuring machine. The digitalization of complex shaped workpieces demands a high flexibility in the positioning of the sensor to the measuring object. In this way all surface areas can be touched with the sensor in an optimal way. Therefore, the calibration procedure is realized in five degrees of freedom: three translatory degrees of freedom to implement the linear movement of the fringe projection system in three orthogonal directions inside the measuring volume of the CMM as well as two rotational degrees of freedom. On the one hand the rotational degrees of freedom allow the possibility of rotation of a clamped measuring object. On the other hand the rotation of the fringe projection system around the measuring object can be realized. The calibration procedure is afflicted with an uncertainty, which has an effect on the precision of the registration process. The resulting residual error in the total <b>point-clouds</b> results in height offsets between the partial <b>point-clouds.</b> Based on the residual error of the registered <b>point-clouds,</b> the concept of roughly-registered <b>point-clouds</b> was introduced in the framework of this dissertation. The minimization of the existing residual error in the roughly-registered point clouds was reached with an additional fine registration on basis of an iterative-closest-point algorithm. In particular different minimization methods based on simulated annealing, simplex procedure or conjugate-gradient method were examined regarding attainable precision. The fine registration was realised sucessfully both for norm-geometries like spheres or planes and for free form surfaces and was successfully implemented in the registration software. The present work makes a contribution to the multi-sensor application of coordinate measuring machines. For integration of the optical 3 D-sensor a multi-sensor-coordinate measuring machine of the company "Werth Messtechnik" was used. Factory-made it consists of a tactile sensing device, an image processing unit and a video autofocus sensor. By the integration of the fringe projection system it could be expanded the functionality of the multi-sensor coordinate measuring machine with the objective of the flexible and exact three-dimensional surface digitalization...|$|R
40|$|Abstract — This paper {{presents}} a novel <b>point-cloud</b> descriptor for robust and real-time tracking of multiple objects with-out any object knowledge. Following with {{the framework of}} incremental model-free multiple object tracking from our previous work [5][7][6], 6 DoF pose of each object is firstly estimated with input <b>point-cloud</b> data which is then segmented according to the estimated objects, and incremental model of each object is updated from the segmented point-clouds. Here, we propose Joint Color-Spatial Descriptor (JCSD) to enhance the robustness of the pose hypothesis evaluation to the <b>point-cloud</b> scene in the particle filtering framework. The method outperforms widely used point-to-point comparison methods, especially in the partially occluded scene, which is frequently happened in the dynamic object manipulation cases. By means of the robust descriptor, we achieved unsupervised multiple object segmentation accuracy higher than 99 %. The model-free multiple object tracking was implemented by using a particle filtering with JCSD as a likelihood function. The robust likelihood function is implemented with GPU, thus facilitating real-time tracking of multiple objects. I...|$|E
40|$|ABSTRACT: This paper {{presents}} a small drone-based laser-scanner system for rice monitoring at low altitudes. The system uses a DJI S 800 as the flight platform, with a 3 -axis gimbal system {{to stabilize the}} laser-scanner attitude. The laser scanner obtains 3 D <b>point-cloud</b> data of rice plants. A single-frequency GPS receiver and a small motion-logger are also installed to record the platform position and nose direction. The laser scanner and the GPS receiver are controlled by a Raspberry Pi, which also records the relevant data. The GPS receiver uses a u-blox module that can output raw GPS data, so its positioning error (in the horizontal coordinates) is about 1 m when applying post-kinematic processing. The mapping accuracy of the 3 D <b>point-cloud</b> data from the proposed system {{is found to be}} 1. 56 ± 0. 12 m without ground control point (GCP) correction and 0. 23 ± 0. 10 m using only one GCP. The results show that this system has the potential to map 3 D <b>point-cloud</b> data with sub-meter accuracy. In addition, observations of paddy rice indicate that the proposed system produces high reproducibility of relative height. 1...|$|E
40|$|We {{focus on}} the {{potential}} of a camera {{to act as a}} location sensor, assisting other location sensors to improve positioning accuracy. A camera is installed in almost all mobile devices. Moreover, the camera {{can be used as a}} location sensor without additional transmitters or receivers. However, if the camera is used as a location sensor, reliable maps will be required. Although there are some location-matching approaches that use maps, the success rate of location detection depends on the representation of a 3 -D model and its information content. Compared with a model representation based on Computer-Aided Design (CAD), a <b>point-cloud</b> representation is more photorealistic. We therefore focus on <b>point-cloud</b> data being used for reliable maps. Our proposed locationmatching methodology is based on image matching using images from a digital camera and panoramic images generated from a massive <b>point-cloud</b> in an image-based Geographic Information System (GIS). We conducted experiments in location matching using a digital camera to supply the input data for location detection and a point cloud taken from a terrestrial laser scanner. We have confirmed that our approach can detect locations using a digital camera that is restricted to horizontal movement...|$|E
40|$|ABSTRACT: In {{architectural}} {{and cultural}} heritage documentation, laser scanning technology today offers several opportunities {{to approach the}} object to study and to extract manifold information levels from it. These account for <b>point-clouds,</b> 3 -D models, and other data {{about the state of}} conservation. Georeferenced <b>point-clouds</b> can be adopted as the spatial framework of a Space Information System for Architecture, integrating all spatial information acquired by TLS, photogrammetry, geodetic surveying and direct survey, but also from other investigation techiques (e. g. GPR, thermal cameras, etc.). Such information system allows to make assessments that are important for the classification of structural elements or for the determination of the state of decay or preservation of each architectural element. With reference to the survey of two wooden domes of San Marco Basilica in Venice (Italy), the completion of the 3 -D model of their complex structure is presented here through the description of its main stages, i. e. data acquisition, registration and modelling. The final 3 -D model is then assumed as a 3 -D database which clarifies the shape, the composition, the state of conservation and the structural function of the wooden beams of the domes...|$|R
40|$|Spherical {{harmonic}} cross-correlation is {{a robust}} registration algorithm that brings two <b>point-clouds</b> {{of the same}} scene into coarse rotational alignment. The found rotation however may not give the desired alignment, as misalignments can occur {{if there is not}} enough overlap between <b>point-clouds,</b> or if they contain a form of symmetry. We propose a verification method whose purpose is to determine if registration has failed for a priori unknown registration. The rotational transformation between multiple clouds must satisfy internal consistency, namely multiple rotational transformations are transitive. The rotation verification is performed using triplets of images, which are cross-referenced with each other to classify rotations individually. Testing is performed on a dataset of a priori known registrations. It is found that when the number of images or the percentage of correct rotations is increased, the number of correct rotation classifications improves. Even when tested with only four images and a correct rotation percentage of 17 %, the rotation verification is still considered a viable method for classifying rotations. Spherical harmonic cross-correlation is benefited by rotation verification as it provides an additional approach for checking whether found rotations are correct...|$|R
40|$|This thesis {{deals with}} the topic of simple {{geometric}} shapes detection from <b>point-clouds</b> with {{a special interest in}} the influence of point normals on speed and quality of produced results. Its main product is an application that demonstrates detection of planes, spheres and cylinders. Detection is done using the RANSAC paradigm that is modified in this thesis to allow it to work with multiple models simultaneously. Another modification presented in this thesis focuses on enforcing stricter candidate shapes selection conditions for detection models...|$|R
