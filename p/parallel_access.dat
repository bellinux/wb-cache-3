243|484|Public
25|$|The {{development}} of high-speed serial data interfaces such as USB made semiconductor memory systems with serially accessed storage viable, and the simultaneous {{development of}} small, high-speed, low-power microprocessor systems allowed {{this to be}} incorporated into extremely compact systems. Serial access requires far fewer electrical connections for the memory chips than does <b>parallel</b> <b>access,</b> which has simplified the manufacture of multi-gigabyte drives.|$|E
2500|$|Theories {{derived from}} early unilingual {{research}} relied mainly upon generalizations without precise specification {{of how these}} specific systems of lexical access works. Due {{to the advancement of}} medical science within the last decade, the field of Psycholinguistics has evolved immensely, resulting in more detailed research and therefore, {{a deeper understanding of the}} mechanisms behind language production. [...] "Many early studies of second language acquisition focused on the morphosyntactic development of learners, and the general findings was that bound morphemes appear in the same order in the first and second language"(Bardovi-Harlig 1999. In addition, [...] "second language learners are also able to produce and process simple sentences before complex sentences" [...] (Pienemann et al.2005), just like first language learners. For example, the theory of serial search models and <b>parallel</b> <b>access</b> models. Serial Search Models propose that when monolinguals encounter a word, they will look through all the lexical entries to distinguish whether the input item is a word not, and then they will only retrieve the necessary information about that word (i.e., its semantics or orthography). They also propose that the lexical access would process sequentially by activating only one lexical entry at a time. In contrast, the <b>Parallel</b> <b>Access</b> Models believe that multiple entries can be activated at once, which means that the perceptual input from a word would activate all lexical items directly, even though some of them might not be necessary. In this way, numbers of potential candidates would be activated simultaneously and then the lexical candidates which are most consistent with the input stimulus would be chosen. [...] Later, the researchers addressed that both the serial and parallel process are accounted for the lexical organization and lexical access.|$|E
2500|$|There is a {{trend in}} academia for {{universities}} to be their own drug discovery enterprise. These facilities, which normally are found only in industry, are now increasingly found at universities as well. UCLA, for example, features an open access HTS laboratory Molecular Screening Shared Resources (MSSR, UCLA), which can screen more than 100,000 compounds a day on a routine basis. The open access policy ensures that researchers {{from all over the}} world can take advantage of this facility without lengthy intellectual property negotiations. With a compound library of over 200,000 small molecules, the MSSR has one of the largest compound deck of all universities on the west coast. Also, the MSSR features full functional genomics capabilities (genome wide siRNA, shRNA, cDNA and CRISPR) which are complementary to small molecule efforts: Functional genomics leverages HTS capabilities to execute genome wide screens which examine the function of each gene in the context of interest by either knocking each gene out or overexpressing it. <b>Parallel</b> <b>access</b> to high-throughput small molecule screen and a genome wide screen enables researcher to perform target identification and validation for given disease or the mode of action determination on a small molecule. The most accurate results can be obtained by use of [...] "arrayed" [...] functional genomics libraries, i.e. each library contains a single construct such as a single siRNA or cDNA. Functional genomics is typically paired with high content screening using e.g. epifluorescent miscroscopy or laser scanning cytometry.|$|E
50|$|Cilk++ {{differs from}} Cilk in several ways: support for C++, support for loops, and hyperobjects a new {{construct}} designed to solve data race problems created by <b>parallel</b> <b>accesses</b> to global variables. Cilk++ was proprietary software. Like its predecessor, it was implemented as a Cilk-to-C++ compiler. It supported the Microsoft and GNU compilers.|$|R
40|$|AbstractWe {{introduce}} new latin squares called perfect latin squares which have desirable properties for <b>parallel</b> array <b>access.</b> These squares provide conflict {{free access to}} various subsets of an n 2 ×n 2 array using n 2 memory modules. We present a general construction method for building perfect latin squares of order n 2 for all n. Some useful properties of the latin squares built by our construction method for <b>parallel</b> array <b>access</b> are also identified...|$|R
25|$|One {{theoretical}} {{model is the}} <b>parallel</b> random <b>access</b> machines (PRAM) that are used. However, the classical PRAM model assumes synchronous access to the shared memory.|$|R
5000|$|Unit Control Block, for a {{description}} how WLM controls dynamic <b>Parallel</b> <b>Access</b> Volumes (PAVs) ...|$|E
50|$|Other ways of <b>parallel</b> <b>access</b> to data include: Parallel Virtual File System, Lustre, GFS etc.|$|E
5000|$|Data: By {{splitting}} {{a single}} sequential file into smaller data files to provide <b>parallel</b> <b>access</b> ...|$|E
50|$|With a {{clustered}} file system, each node mounts the file system in <b>parallel</b> and <b>access</b> to the files goes {{directly from the}} node to the file system.|$|R
40|$|This paper {{considers}} {{a novel approach}} for supporting <b>parallel</b> <b>accesses</b> to a data cache. We explore the possibility of explicitly managing cache accesses using a static compile-time analysis. First we perform a limit study on dynamic instruction traces to discover an upper bound {{on the amount of}} memory parallelism that is exploitable at compile time. Then we introduce compiler controlled split caches, or cc-split caches, and discuss our initial implementation. Our results suggest this architecture has potential, but we question whether moving complexity from the hardware to software is a profitable trade-off in this case. ...|$|R
30|$|<b>Parallel</b> data <b>access</b> {{that allows}} {{increasing}} data access bandwidth by partitioning data into multiple chunks, according to different methods, and accessing several data elements in parallel to meet high throughput requirements.|$|R
50|$|The PZB 90 {{intermittent}} cab {{signalling system}} {{is used on}} the freight rail bypass. This contrasts with the <b>parallel</b> <b>access</b> line to the central station, which is protected by the LZB train protection system.|$|E
50|$|NFS version 4.1 (RFC 5661, January 2010) aims {{to provide}} {{protocol}} support {{to take advantage}} of clustered server deployments including the ability to provide scalable <b>parallel</b> <b>access</b> to files distributed among multiple servers (pNFS extension). NFS version 4.2 (RFC 7862) was published in November 2016.|$|E
50|$|<b>Parallel</b> <b>access</b> schemes used to {{accelerate}} transfers by {{taking advantage of}} HTTP range requests to initiate connections to multiple servers of a replicated content, are not equivalent to Multipath TCP as they involve the application layer and are limited to content of known size.|$|E
50|$|A {{number of}} {{mathematical}} {{models have been}} developed for general concurrent computation including Petri nets, process calculi, the <b>Parallel</b> Random <b>Access</b> Machine model, the Actor model and the Reo Coordination Language.|$|R
5000|$|DirectFlow is the <b>parallel</b> data <b>access</b> {{protocol}} {{designed by}} Panasas and delivered on ActiveStor products. DirectFlow avoids traditional protocol I/O bottlenecks by allowing compute clients to access Panasas storage directly and in parallel ...|$|R
25|$|An {{algorithm}} {{is said to}} run in polylogarithmic time if T(n) = O((log n)k), for some constant k. For example, matrix chain ordering can be solved in polylogarithmic time on a <b>Parallel</b> Random <b>Access</b> Machine.|$|R
50|$|On 18 April 2017 the CompactFlash Association {{published}} the CFexpress 1.0 specification. Version 1.0 {{will use the}} XQD form-factor (38.5 mm × 29.8 mm × 3.8 mm) with two PCIe 3.0 lanes for speeds up to 2 GB/s. NVMe 1.2 is used for low-latency access, low overhead and highly <b>parallel</b> <b>access.</b>|$|E
50|$|VxFS {{file system}} can run in single {{instance}} mode or in a <b>parallel</b> <b>access</b> / cluster mode. The parallel mode allows for multiple servers (also known as cluster nodes) to simultaneously access the same file system. When run in this mode, VxFS {{is referred to}} as Veritas Cluster File System.|$|E
50|$|The {{development}} of high-speed serial data interfaces such as USB made semiconductor memory systems with serially accessed storage viable, and the simultaneous {{development of}} small, high-speed, low-power microprocessor systems allowed {{this to be}} incorporated into extremely compact systems. Serial access requires far fewer electrical connections for the memory chips than does <b>parallel</b> <b>access,</b> which has simplified the manufacture of multi-gigabyte drives.|$|E
40|$|We propose an {{interleaved}} memory organization supporting multi-pattern <b>parallel</b> <b>accesses</b> in twodimensional (2 D) addressing space. Our proposal targets computing systems with high memory bandwidth demands such as vector processors, multimedia accelerators, etc. We substantially extend prior research on {{interleaved memory}} organizations introducing 2 D-strided accesses along with additional parameters, which define a large variety of 2 D data patterns. The proposed scheme guarantees minimum memory latency and efficient bandwidth utilization for arbitrary configuration {{parameters of the}} data pattern. We provide mathematical descriptions and proofs of correctness for the proposed addressing schemes. The design complexity and the critical paths are evaluated using technology independent resource count...|$|R
40|$|PC {{clusters}} {{have emerged}} as viable alternatives for high-performance, low-cost computing. In such an environment, sharing data among processes is essential. Accessing the shared data, however, may often stall parallel executing threads. We propose a novel data representation scheme where an application data entity can be incarnated into a set of objects that are distributed in the cluster. The runtime support system manages the incarnated objects and data access is possible only via an appropriate interface. This distributed data representation facilitates <b>parallel</b> <b>accesses</b> for updates. Thus, tasks are subject to few limitations and application programs can harness high degrees of parallelism. Our PC cluster experiments prove the effectiveness of our approach...|$|R
40|$|This paper {{gives an}} {{overview}} of some models of computation which have proved successful in laying a foundation for a general theory of parallel computation. We present three models of parallel computation, namely boolean and arithmetic circuit families, and <b>Parallel</b> Random <b>Access</b> Machines. They represent different viewpoints on parallel computing: boolean circuit families are useful for in-depth theoretical studies on the power and limitations of parallel computers; <b>Parallel</b> Random <b>Access</b> Machines are the most general vehicle for designing highly parallel algorithms; arithmetic circuit families are an important tool for undertaking studies related {{to one of the}} most active areas in parallel computing, i. e. parallel algebraic complexity...|$|R
50|$|The Ministry of Road Transport & Highways, Government of India has {{proposed}} a greenfield (i.e., new and <b>parallel)</b> <b>access</b> controlled expressway corridor connecting the port cities of Mangalore-Karwar-Panaji {{as part of the}} Indian National Expressway Network. This expressway will be parallel to NH-66 and will be mainly located in coastal Karnataka. It {{is expected to be a}} 6/8 lane access-controlled 3D right-of-way designed expressway.|$|E
50|$|Ceph-FS is a {{distributed}} {{file system}} that provides excellent performance and reliability. It answers {{the challenges of}} dealing with huge files and directories, coordinating the activity of thousands of disks, providing <b>parallel</b> <b>access</b> to metadata on a massive scale, manipulating both scientific and general-purpose workloads, authenticating and encrypting on a large scale, and increasing or decreasing dynamically due to frequent device decommissioning, device failures, and cluster expansions.|$|E
50|$|Dual Channel memory {{controllers}} are memory controllers {{where the}} DRAM devices are separated on to two different buses to allow two memory controllers to access them in parallel. This doubles the theoretical amount of bandwidth of the bus. In theory, more channels {{can be built}} (a channel for every DRAM cell would be the ideal solution), but due to wire count, line capacitance, {{and the need for}} <b>parallel</b> <b>access</b> lines to have identical lengths, more channels are very difficult to add.|$|E
50|$|Much {{expansion}} {{took place}} during the late nineteenth century, as the village sought to accommodate its workforce, with rows of terraced properties serving that purpose. However, in the early 1960s, modern housing began to be built in quantity, with the first estate roads being built on the old field known as the Fleet, named after the streams running through it. This gave its name to one of the roads constructed at this time, with John Bold Avenue running <b>parallel</b> <b>accessed</b> by Clint Hill Drive. Further development was to follow and still continues, the village expanding onto former industrial sites and fields along the perimeter.|$|R
50|$|In the <b>parallel</b> random <b>access</b> machine {{model of}} computing, prefix sums {{can be used}} to {{simulate}} parallel algorithms that assume the ability for multiple processors to access the same memory cell at the same time, on parallel machines that forbid simultaneous access. By means of a sorting network, a set of <b>parallel</b> memory <b>access</b> requests can be ordered into a sequence such that accesses to the same cell are contiguous within the sequence; scan operations can then be used to determine which of the accesses succeed in writing to their requested cells, and to distribute the results of memory read operations to multiple processors that request the same result.|$|R
50|$|Similarly, {{the data}} bus is often {{designed}} to suit specific needs such as serial or <b>parallel</b> data <b>access,</b> {{and the memory}} may be designed to provide for parity error detection or even error correction in expensive business systems.|$|R
50|$|An MPPA {{application}} is developed by expressing it as a hierarchical block diagram or workflow, whose basic objects run in parallel, each {{on their own}} processor. Likewise, large data objects may be broken up and distributed into local memories with <b>parallel</b> <b>access.</b> Objects communicate over a parallel structure of dedicated channels. The objective is to maximize aggregate throughput while minimizing local latency, optimizing performance and efficiency. An MPPA's model of computation {{is similar to a}} Kahn process network or communicating sequential processes (CSP).|$|E
50|$|Culverts and drains occur {{frequently}} {{along the}} Main Range Railway. At varying depths beneath the rail, they direct {{water from the}} north side of the track, passing under the length of the railway and <b>parallel</b> <b>access</b> road and drain to the south east. The culverts and drains vary greatly in size shape and composition. Materials for culverts and drains include cut stone, mortared rocks, brick, concrete and corrugated iron piping. The following descriptions are of entrances situated on {{the north side of}} the track.|$|E
50|$|In the People's Republic of China mainland, roads running next to expressways, taking {{outgoing}} traffic and feeding incoming traffic, are called either service roads or auxiliary roads (fudao locally). Where expressways cross larger urban areas, such frontage roads may run {{next to the}} expressway itself. Much of the Beijing portion of the Jingkai Expressway, for example, has, in fact, China National Highway 106 acting as a split-direction frontage road. Many newer urban highways are entirely elevated, with <b>parallel</b> <b>access</b> roads running beneath the entire length.|$|E
50|$|A {{number of}} {{computational}} models based on concurrency have been developed, including the <b>Parallel</b> Random <b>Access</b> Machine and the Petri net. These models of concurrent computation {{still do not}} implement any mathematical functions that cannot be implemented by Turing machines.|$|R
50|$|The {{cross-platform}} {{library for}} <b>parallel</b> port <b>access,</b> libieee1284, also {{is available on}} many Linux distributions and provides an abstract interface to the parallel ports of the system. Access is handled in an open-claim-release-close sequence, which allows for concurrent access in userspace.|$|R
5000|$|Together {{with the}} {{register}} machine, the RAM, and the pointer machine the RASP {{makes up the}} four common sequential machine models, called this to distinguish them from the [...] "parallel" [...] models (e.g. <b>parallel</b> random <b>access</b> machine) van Emde Boas (1990).|$|R
