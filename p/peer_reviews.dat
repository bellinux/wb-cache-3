651|10000|Public
25|$|In {{the social}} sciences, {{there have been}} {{experiments}} with wiki-style, signed <b>peer</b> <b>reviews,</b> for example in an issue of the Shakespeare Quarterly.|$|E
25|$|Small sample {{studies on}} the {{potential}} of loving-kindness meditation approach on patients suggest potential benefits. However, <b>peer</b> <b>reviews</b> question the quality and sample size of these studies, then suggest caution.|$|E
25|$|Of course, review sites, such as Yelp, {{also help}} small {{businesses}} {{to build their}} reputation beyond just brand visibility. Positive customer <b>peer</b> <b>reviews</b> help to influence new prospects to purchase goods and services more than company advertising.|$|E
50|$|Professional <b>peer</b> <b>review</b> {{is common}} {{in the field of}} health care, where it is usually called {{clinical}} <b>peer</b> <b>review.</b> Further, since <b>peer</b> <b>review</b> activity is commonly segmented by clinical discipline, there is also physician <b>peer</b> <b>review,</b> nursing <b>peer</b> <b>review,</b> dentistry <b>peer</b> <b>review,</b> etc. Many other professional fields have some level of <b>peer</b> <b>review</b> process: accounting, law, engineering (e.g., software <b>peer</b> <b>review,</b> technical <b>peer</b> <b>review),</b> aviation, and even forest fire management.|$|R
50|$|A {{technical}} <b>peer</b> <b>review</b> {{may also}} be called a engineering <b>peer</b> <b>review,</b> a product <b>peer</b> <b>review,</b> a <b>peer</b> review/inspection or an inspection.|$|R
50|$|Clinical <b>Peer</b> <b>Review</b> is {{the process}} by which health care {{professionals}} evaluate each other’s clinical performance. Clinical <b>peer</b> <b>review</b> is segmented by discipline. No inter-disciplinary models for clinical <b>peer</b> <b>review</b> have been described. Physician <b>Peer</b> <b>Review</b> is most common and is found in virtually all hospitals. <b>Peer</b> <b>review</b> is also done in some settings by other clinical disciplines including nursing and pharmacy. Initially used by Dans, Clinical <b>Peer</b> <b>Review</b> is the best term to collectively refer to all such activity.|$|R
25|$|In 2011, Peerage of Science, and {{independent}} peer review service, was launched with several non-traditional approaches to academic peer review. Most prominently, {{these include the}} judging and scoring of the accuracy and justifiability of <b>peer</b> <b>reviews,</b> and concurrent usage of a single peer review round by several participating journals.|$|E
25|$|As {{with other}} safety-critical systems, the {{development}} of the A330/A340 flight control system during 1991 and 1992 had many elements to minimise the risk of a design error. These included <b>peer</b> <b>reviews,</b> a system safety assessment (SSA), and testing and simulations to verify and validate the system requirements. None of these activities identified the design limitation in the FCPC’s AOA algorithm.|$|E
25|$|Those who {{maintain}} that sham peer review is a pervasive problem {{suggest that the}} Healthcare Quality Improvement Act (HCQIA) of 1986 allows sham reviews by granting significant immunity from liability to doctors and others who participate in <b>peer</b> <b>reviews.</b> This immunity extends to investigative activities {{as well as to}} any associated peer review hearing, whether or not it leads to a disciplinary (or other) action.|$|E
40|$|For the August 2014 talk, we {{discussed}} traditional <b>peer</b> <b>review.</b> We outlined {{the origins and}} history of <b>peer</b> <b>review,</b> {{as well as the}} process, ethics, and problems of tradition single and double-blind <b>peer</b> <b>review.</b> We discussed the responsibilities of authors and reviewers during the <b>peer</b> <b>review</b> process, and we reviewed case studies to discuss some of the complexities that can arise during <b>peer</b> <b>review...</b>|$|R
2500|$|Sham <b>peer</b> <b>review</b> or {{malicious}} <b>peer</b> <b>review</b> {{is a name}} {{given to}} the abuse of a medical <b>peer</b> <b>review</b> process to attack a doctor for personal or other non-medical reasons. [...] The American Medical Association conducted an investigation of medical <b>peer</b> <b>review</b> in 2007 and concluded that while {{it is easy to}} allege misconduct and 15% of surveyed physicians indicated that they were aware of <b>peer</b> <b>review</b> misuse or abuse, cases of malicious <b>peer</b> <b>review</b> able to be proven through the legal system are rare.|$|R
40|$|<b>Peer</b> <b>Review</b> (also {{known as}} Peer Assessment) is an {{important}} technique in learning, but {{can be difficult to}} support through e-learning due to the complexity and variety of <b>peer</b> <b>review</b> processes. In this paper we present PeerPigeon, a Web 2. 0 style application that supports generalised <b>Peer</b> <b>Review</b> by using a canonical model of <b>Peer</b> <b>Review</b> based on a <b>Peer</b> <b>Review</b> Pattern consisting of <b>Peer</b> <b>Review</b> Cycles, each defined in terms of <b>Peer</b> <b>Review</b> Transforms. We also demonstrate how PeerPigeon makes use of a Domain Specific Language based on Ruby to define these plans, and thus cope with the irreducible complexity of the flow of documents around a peer network...|$|R
25|$|Starting in the 1990s, several {{scientific}} journals (including the high impact journal Nature in 2006) started experiments with hybrid peer review processes, allowing the open <b>peer</b> <b>reviews</b> in {{parallel to the}} traditional model. The initial evidence {{of the effects of}} open <b>peer</b> <b>reviews</b> was mixed. Identifying reviewers to the authors does not negatively impact, and may potentially have a positive impact upon, the quality of reviews, the recommendation regarding publication, the tone of the review and the time spent on reviewing. However, more of those who are invited to review decline to do so. Informing reviewers that their signed reviews might be posted on the web and available to the wider public did not {{have a negative impact on}} quality of reviews and recommendations regarding publication, but it led to a longer time spent on reviewing, besides a higher reviewer decline rate. The results suggest that open peer review is feasible, and does not lead to poorer quality of reviews, but needs to be balanced against the increase in review time, and higher decline rates among invited reviewers.|$|E
500|$|As the Farrar {{children}} grew old enough, {{they were}} enrolled in The Pembroke Hill School, a private school in Kansas City. Green was reportedly a good mother who wanted the best for her children and encouraged them in their activities of choice. Though she attempted to resume her medical career after her last maternity leave, her practice faltered and her chronic pain increased. In 1992, she gave up her practice and became a homemaker, working part-time from the family's house on medical <b>peer</b> <b>reviews</b> and Medicaid processing. Medical professionals who worked with her during this time described her as being distant and cold [...] towards her patients and displaying obsessive behavior towards her husband.|$|E
500|$|On 19 February the Royal Society {{publicly}} {{announced that}} a committee would review his work. World in Action reporters Laurie Flynn [...] and [...] Michael Sean Gillard claimed {{that this was an}} unusual step, as the Royal Society did not normally conduct <b>peer</b> <b>reviews.</b> The data were sent to six anonymous reviewers and the resulting review was published in June 1999. It stated that Pusztai's experiments were poorly designed, contained uncertainties in the composition of diets, tested too few rats, used incorrect statistical methods and lacked consistency within experiments. Pusztai responded by saying the reviewers had reviewed only internal Rowett reports, which did not include the design or methodology of the experiments.|$|E
40|$|Abstract. <b>Peer</b> <b>review</b> is an {{accepted}} educational practice and most educators acknowledge its value. Online <b>peer</b> <b>review</b> systems ease classroom administration, but instructors beyond the <b>peer</b> <b>review</b> research community seem reluctant to embrace this technology. Instructors {{might be more}} motivated to use online <b>peer</b> <b>review</b> systems if the systems were explicitly designed to assist with student grading. This paper analyzes an online <b>peer</b> <b>review</b> system’s instructor interface and suggests features {{that would make the}} system easier to use and more viable for supporting instructor grading. Because most online <b>peer</b> <b>review</b> systems have similar administration features, these ideas generalize to other online <b>peer</b> <b>review</b> systems...|$|R
40|$|Abstract: <b>Peer</b> <b>Review</b> (also {{known as}} Peer Assessment) is an {{important}} technique in learning, but {{can be difficult to}} support through e-learning due to the complexity and variety of <b>peer</b> <b>review</b> processes. In this paper we present PeerPigeon, a Web 2. 0 style application that supports generalised <b>Peer</b> <b>Review</b> by using a canonical model of <b>Peer</b> <b>Review</b> based on a <b>Peer</b> <b>Review</b> Pattern consisting of <b>Peer</b> <b>Review</b> Cycles, each defined in terms of <b>Peer</b> <b>Review</b> Transforms. We also demonstrate how PeerPigeon makes use of a Domain Specific Language based on Ruby to define these plans, and thus cope with the irreducible complexity of the flow of documents around a peer network...|$|R
40|$|In {{computer}} science, {{conferences and}} journals conduct <b>peer</b> <b>review</b> {{in order to}} decide what to publish. Many have pointed out the inherent weaknesses in <b>peer</b> <b>review,</b> including those of bias, quality, and accountability. Many have suggested and adopted refinements of <b>peer</b> <b>review,</b> for instance, double blind <b>peer</b> <b>review</b> with author rebuttals. In this essay, I argue that <b>peer</b> <b>review</b> as currently practiced conflates the sensible idea of getting comments on a paper with the irrevocably-flawed one that we either accept or reject the paper, which I term gatekeeping. If we look at the two separately, then {{it is clear that the}} ills associated with current <b>peer</b> <b>review</b> systems are not due to the practice of getting comments, but due to the practice of gatekeeping. True <b>peer</b> <b>review</b> constitutes my proposal for replacing existing <b>peer</b> <b>review</b> systems. It embraces the idea of open debate on the merits of a paper; however, it rejects unequivocally the exercise of gatekeeping. True <b>peer</b> <b>review</b> offers all the benefits of current <b>peer</b> <b>review</b> systems but has none of its weaknesses. True <b>peer</b> <b>review</b> will lead to a truly engaged community of researchers and therefore better science...|$|R
500|$|Under the {{provisions}} of the Civil Aviation Act aircraft in flight are specifically exempted from trespass and nuisance controls, which denies any form of redress to those living near airports who are disturbed by noise. Government sanctioned measurements of noise near airports take an average sound level, measured in decibels (dB), over a 16‑hour day, and are expressed as an LAeq figure. Officially, 57dB LAeq is the threshold at which noise levels become disturbing, 63dB LAeq represents moderate disturbance, whilst 69dB LAeq represents high disturbance. Technological improvements in aircraft design means that aircraft are becoming quieter. Taking Heathrow as an example, between 1990 and 2004 the area around the airport affected by noise levels of 57 db LAeq and above fell by 60 per cent, whilst the number of people similarly affected fell by 51 per cent. Campaign groups dispute the methodology used to measure noise, asserting that it is flawed in a number of ways. Amongst other issues they point to the World Health Organisation view that annoyance begins at 50 db LAeq whilst serious annoyance begins at 55dB LAeq, and they assert that the LAeq measurement does not give sufficient weight to the increasing incidence of noise events. Their conclusion is that noise levels, and the number of people affected, have increased rather than decreased. This is borne out by the latest survey of attitudes to noise published in November 2007 which reports that, compared with over 20years ago, more people today are annoyed by the same level of noise as measured by LAeq. Whilst this may be attributable to changing attitudes, the report concludes that the contribution of aircraft numbers to annoyance has increased, and that an alternative method of estimating levels of annoyance that takes this into account would appear to be more relevant than the LAeq measurement. The report has attracted criticism in <b>peer</b> <b>reviews,</b> and one such review, characterising the survey as inconclusive, counsels [...] "...against using the detailed ...|$|E
2500|$|Jung's {{theory has}} become {{enormously}} influential in management theory; {{not just because}} managers and executives have to create an appropriate [...] "management persona" [...] (a corporate mask) and a persuasive identity, {{but also because they}} have to evaluate what sort of people the workers are, in order to manage them (for example, using personality tests and <b>peer</b> <b>reviews).</b>|$|E
2500|$|The [...] "great rabbis experiment" [...] {{went through}} several iterations, and was {{eventually}} published in 1994, in the peer-reviewed journal Statistical Science. Prior to publication, the journal's editor, Robert Kass, subjected {{the paper to}} three successive <b>peer</b> <b>reviews</b> by the journal's referees, who according to Kass were [...] "baffled". Though still skeptical, none of the reviewers had found any flaws. Understanding that the paper was certain to generate controversy, it was presented to readers {{in the context of}} a [...] "challenging puzzle." [...] Witztum and Rips also performed other experiments, most of them successful, though none were published in journals.|$|E
5000|$|The <b>peer</b> <b>review</b> Bulletin {{provides}} detailed {{guidelines for}} <b>peer</b> <b>review</b> of influential scientific information. The Bulletin applies more stringent <b>peer</b> <b>review</b> requirements to [...] "highly influential scientific assessments," ...|$|R
40|$|Changes in {{scholarly}} publishing {{have resulted in}} a move toward openness. To this end, new, open models of <b>peer</b> <b>review</b> are emerging. While the scholarly literature has examined and discussed open <b>peer</b> <b>review,</b> no established definition of it exists, nor are there uniform implementations of open <b>peer</b> <b>review</b> processes. This article examines the literature discussing open <b>peer</b> <b>review,</b> identifies common open <b>peer</b> <b>review</b> definitions, and describes eight common characteristics of open <b>peer</b> review: signed <b>review,</b> disclosed review, editor-mediated review, transparent review, crowdsourced review, prepublication review, synchronous review, and post-publication review. This article further discusses benefits and challenges to the scholarly publishing community posed by open <b>peer</b> <b>review,</b> and concludes that open <b>peer</b> <b>review</b> can and should exist within the current scholarly publishing paradigm...|$|R
40|$|The {{potential}} of the constructor <b>peer</b> <b>review</b> process is examined based on a consulting study involving three separate contractors who undertook to perform <b>peer</b> <b>review</b> analysis of their operations. The stages involving <b>peer</b> <b>review</b> are examined including planning, team selection, data development, site visit, <b>peer</b> <b>review</b> report, report implementation and secondary advantages. Important fundamentals of the <b>peer</b> <b>review</b> process including construction practice examination by non-market competition is covered along with other recommendations based on the study. <b>Peer</b> <b>review</b> as a technique is just that, a technique upon which its success depends on significant resource commitments including time by the contractor sponsor...|$|R
2500|$|On October 19, 2005, Defense Secretary Donald Rumsfeld {{announced}} that an independent panel of experts, {{under the direction}} of the National Academy of Sciences, would convene to evaluate the performance of the New Orleans levee system, and issue a final report in eight months. The panel would study the results provided by the two existing teams of experts that had already examined the levee failures. The academy concluded that “the engineering of the levee system was not adequate. The procedures for designing and constructing hurricane protection systems will have to be improved, and the designing organizations must upgrade their engineering capabilities. The levees must be seen not as a system to protect real estate but as a set of dams to protect people. There must be independent <b>peer</b> <b>reviews</b> of future designs and construction.” ...|$|E
50|$|<b>Peer</b> <b>reviews</b> are {{considered}} an industry best-practice for detecting software defects early {{and learning about}} software artifacts. <b>Peer</b> <b>Reviews</b> are composed of software walkthroughs and software inspections and are integral to software product engineering activities. A collection of coordinated knowledge, skills, and behaviors facilitates the best possible practice of <b>Peer</b> <b>Reviews.</b> The elements of <b>Peer</b> <b>Reviews</b> include the structured review process, standard of excellence product checklists, defined roles of participants, and the forms and reports.|$|E
50|$|In engineering, {{technical}} {{peer review}} {{is a type}} of engineering review. Technical <b>peer</b> <b>reviews</b> are a well defined review process for finding and fixing defects, conducted by a team of peers with assigned roles. Technical <b>peer</b> <b>reviews</b> are carried out by peers representing areas of life cycle affected by material being reviewed (usually limited to 6 or fewer people). Technical <b>peer</b> <b>reviews</b> are held within development phases, between milestone reviews, on completed products or completed portions of products.|$|E
40|$|<b>Peer</b> <b>review</b> is {{a family}} of {{instructional}} techniques. Historically, these have been employed in writing and many other educational domains. Modern computer technologies facilitate the use of <b>peer</b> <b>review,</b> which is especially relevant to educational settings where it is not practical to administer <b>peer</b> <b>review</b> manually. The use of computer support for <b>peer</b> <b>review</b> has shed light on many important scientific questions, some of which we summarize. These findings set the context for the papers in this special issue, which demonstrate how computer support for <b>peer</b> <b>review</b> enables research on <b>peer</b> <b>review</b> itself and on its pedagogical significance. © Earli...|$|R
5000|$|Open-identity or {{attributed}} <b>peer</b> <b>review</b> (as {{opposed to}} anonymous <b>peer</b> <b>review)</b> ...|$|R
40|$|In a {{previous}} article, we described {{an overview of}} the <b>peer</b> <b>review</b> process of the JABFM editorial office. 1 <b>Peer</b> <b>reviewing</b> is most often learned “on the job ” without formal training. Reviewers occa-sionally ask for clarification about the biomedical publishing process and what editors expect from reviewers. Here we provide more detail about the JABFM <b>peer</b> <b>review</b> policies and procedures, out-line the ethics of <b>peer</b> <b>review,</b> and discuss the qual-ities of a good <b>peer</b> <b>review...</b>|$|R
5000|$|In CMMI, <b>peer</b> <b>reviews</b> {{are used}} as a {{principal}} means of verification in the Verification process area and as an objective evaluation method in the Process and Product Quality Assurance process area. The results of technical <b>peer</b> <b>reviews</b> can be reported at milestone reviews. (See Milestone (project management).) ...|$|E
5000|$|... 1998-1999 Chairman, NASA Life Sciences Decompression Research <b>Peer</b> <b>Reviews</b> ...|$|E
5000|$|... 2002. <b>Peer</b> <b>Reviews</b> in Software: A Practical Guide. Addison-Wesley.|$|E
40|$|This article {{examines}} how attitude and law firm culture affect <b>peer</b> <b>review</b> and principal accountability by using empirical {{data obtained from}} a survey of Texas law firms. Part I briefly describes the research design and the general profiles of respondents of the survey. Part II discusses the <b>peer</b> <b>review</b> measures used by the firms surveyed for this article. Part III analyzes attitudes about <b>peer</b> <b>review.</b> Part IV focuses on the obstacles to <b>peer</b> <b>review.</b> Part V considers the connection between firm culture and the implementation of <b>peer</b> <b>review</b> measures. Finally, the conclusion explains how firm managers can reshape attitudes to address the resistance to <b>peer</b> <b>review</b> and institute <b>peer</b> <b>review</b> measures which serve the firm, its attorneys, its clients, and the community...|$|R
25|$|Gaudet, {{provides}} a social science {{view of the}} history of <b>peer</b> <b>review</b> carefully tending to what is under investigation, here <b>peer</b> <b>review,</b> and not only looking at superficial or self-evident commonalities among inquisition, censorship, and journal <b>peer</b> <b>review.</b> It builds on historical research by Gould, Biagioli, Spier, and Rip. The first <b>Peer</b> <b>Review</b> Congress met in 1989. Over time, the fraction of papers devoted to <b>peer</b> <b>review</b> has steadily declined, suggesting that as a field of sociological study, it has been replaced by more systematic studies of bias and errors. In parallel with 'common experience' definitions based on the study of <b>peer</b> <b>review</b> as a 'pre-constructed process', some social scientists have looked at <b>peer</b> <b>review</b> without considering it as pre-constructed. Hirschauer proposed that journal <b>peer</b> <b>review</b> can be understood as reciprocal accountability of judgements among peers. Gaudet proposed that journal <b>peer</b> <b>review</b> could be understood as a social form of boundary judgement - determining what can be considered as scientific (or not) set against an overarching knowledge system, and following predecessor forms of inquisition and censorship.|$|R
5000|$|Open-disclosure {{or public}} <b>peer</b> <b>review,</b> where the <b>peer</b> <b>review</b> {{contents}} are publicly available ...|$|R
