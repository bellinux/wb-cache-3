0|10000|Public
5000|$|... #Caption: Calculation <b>of</b> <b>Point</b> <b>of</b> Total <b>assumption</b> (the {{case when}} EAC exceeds PTA {{that should be}} treated as a risk trigger, is shown) ...|$|R
5000|$|Rapaport, D., Gill, M.M. (1959). The <b>Points</b> <b>of</b> View and <b>Assumptions</b> <b>of</b> Metapsychology. Int. J. Psycho-Anal., 40:153-162.|$|R
40|$|In this paper, {{we shall}} discuss the bounds for the optimal value of {{recourse}} problems from the <b>point</b> <b>of</b> view <b>of</b> <b>assumptions</b> and <b>of</b> possible generalizations. We shall concentrate on bounds {{based on the}} first order moment conditions and to those based on sample information. We shall indicate when {{it is possible to}} remove the convexity assumptions, when there is a hope for extensions to multistage problems and we shall <b>point</b> out reflections <b>of</b> bounds and stability results...|$|R
3000|$|... [...]. From a {{financial}} <b>point</b> <b>of</b> view, the <b>assumption</b> provides {{a possibility of}} calling the bond back from the firm (see Section 2 or [2]). Furthermore, we suppose that [...]...|$|R
3000|$|By the {{definition}} of the operator S, the positive ω-periodic solution of Equation (1) is equivalent to the nontrivial fixed <b>point</b> <b>of</b> A. From <b>assumption</b> (F 0), Lemma  2.1 and Lemma  2.2, we easily see that [...]...|$|R
2500|$|... →Assuming for {{simplicity}} no {{technological progress}} or labor force growth, diminishing returns implies {{that at some}} <b>point</b> the amount <b>of</b> new capital produced is only just enough {{to make up for}} the amount of existing capital lost due to depreciation. At this <b>point,</b> because <b>of</b> the <b>assumptions</b> <b>of</b> no technological progress or labor force growth, we can see the economy ceases to grow.|$|R
5000|$|For cost {{reimbursable}} contract, the <b>Point</b> <b>of</b> Total <b>Assumption</b> {{does not}} exist, since the buyer agrees {{to cover all}} costs. However, a similar incentive arrangement with similar components, called a Cost-Plus-Incentive Fee (CPIF) contract sometimes is used. The CPIF includes both a minimum fee and a maximum fee. The share line {{in combination with the}} Target Fee, Maximum Fee and Minimum Fee can be used to easily calculate the points at which the incentive arrangement affects fee. The range between these points is called the [...] "range of incentive effectiveness." ...|$|R
40|$|Condensation of {{microcavity}} polaritons and {{the substantial}} influence of pair-breaking disorder and decoherence {{leading to a}} laser regime has been recently considered using two different models: a model for direct two band excitons in a disordered quantum well coupled to light and a model where the cavity mode couples instead to a medium of localised excitons, represented by two-level oscillators {{in the presence of}} dephasing processes. Even if complementary from the <b>point</b> <b>of</b> view <b>of</b> <b>assumptions,</b> the models share most of the main conclusions and show similar phase diagrams. The issue whether excitons are propagating or localised seems secondary for the polariton condensation {{and the way in which}} pair-breaking disorder and decoherence processes influence the condensation and drive the microcavity into a lasing regime is, within the approximations used in each model, generic. The reasons for the similarities between the two physical situations are analysed and explained. Comment: Proceeding of the First International Conference on Spontaneous Coherence in Excitonic Systems (ICSCE' 04); 7 pages, 2 eps figure...|$|R
3000|$|As {{mentioned}} above, the {{gamma distribution}} {{was chosen for}} performance issues. From an economic <b>point</b> <b>of</b> view, this <b>assumption</b> may be questionable. Instead of a gamma distribution, one can also use a lognormal distribution, which is more heavy tailed and therefore more conservative compared to a gamma distribution. However, the lognormal distribution also possesses only two parameters. Therefore, using mean and variance 4 to parametrize the distribution of S [...]...|$|R
40|$|Global {{optimization}} problems, {{derived from}} high complexity industrial applications (see, e. g., [1, 2, 17, 19, 21, 22]), are often “black box ” and determined by multiextremal objective functions. Solving efficiently {{this type of}} problems is a great challenge, since they present {{a high number of}} local minima, often with extremely different function values, and do not present a simple mathematical description of the global optima. One of the natural and powerful (from both the theoretical and the applied <b>points</b> <b>of</b> view) <b>assumptions</b> on these problems is that the objective function has bounded slopes. In this case, the methods of the Lipschitz global optimization can be applied (see, e. g., [2, 5, 10, 17, 22, 23]). This kind of global optimization problems is ver...|$|R
40|$|Contrary to the {{national}} financial reporting standards the International Financial Reporting Standards (IFRSS) have a unique international character. The paper starts {{with a description of}} the historical development of the IFRSS followed by a list of the most important institutions linked to IFRSS such as the International Accounting Committee Foundation (IASC Foundation), International Accounting Standards Board (IASB) and International Financial Reporting Interpretations Committee (IFRIC). Next is a presentation of the relations between IFRSS and EU accounting Directives followed by the goals and a possible application of the Regulation on the Application of International Accounting Standards in the EU. The last part of the paper focuses on the basic characteristics of the IFRSS from the <b>point</b> <b>of</b> underlying <b>assumptions,</b> qualitative characteristics, contents and the scope of financial statements...|$|R
50|$|The <b>point</b> <b>of</b> total <b>assumption</b> (PTA) is a {{point on}} the cost line of the profit-cost curve {{determined}} by the contract elements associated with a fixed price plus incentive-Firm Target (FPI) contract above which the seller effectively bears all the costs of a cost overrun. The seller bears all of the cost risk at PTA and beyond, due to a dollar for dollar decrease in profit beyond the costs at the PTA. In addition, once the costs on an FPI contract reach PTA, the maximum amount the buyer will pay is the ceiling price. Note, however, that between the cost at PTA and when the cost equals the ceiling price, the seller is still in a profitable position; only after costs exceed the ceiling price is the seller in a loss position.|$|R
40|$|Good {{requirements}} {{are the first}} step for good communications, and good communications are central to insure an understanding between the customer and contractor. Failure to generate good requirements is unfortunately commonplace and repeated. Waivers to {{requirements are}} discussed from a risk based <b>point</b> <b>of</b> view. The <b>assumption</b> that every requirement will eventually be waived is used to establish a critical review of a draft safety requirement. Validation methods of requirements are addressed. Value added that safety requirements contribute to the Project is estimated to further our critical review of draft requirements...|$|R
40|$|Title of the work: Childern and teen-agers {{basketball}} lead-up Work objektiv: To {{bring up}} gereral view {{on children and}} teen-agers sports lead-up from their ontogeny <b>point</b> <b>of</b> view. Work methods: Literatures sources analysis and knowledge from my trainer practise with pre- school children and teen-agers training in Basketball academy in Roudnice nad Labem. Results: This thesis brings general view on training young sport beginners from sport and psychological ontogeny <b>point</b> <b>of</b> view. Theoretical <b>assumptions</b> correspond with practicat experience with children in the bottom category of ages. We can't specialize only in personal working out during children and teen-agers training but also medicine and psychological aspekt of organism progress. Keywords: basketball, children and teen-agers, medicine and psychological aspect...|$|R
5000|$|The {{basic input}} {{that we use}} {{in order to learn}} a {{distribution}} is an number of samples drawn by this distribution. For the computational <b>point</b> <b>of</b> view the <b>assumption</b> is that such a sample is given in a constant amount of time. So its like having access to an oracle [...] that returns a sample from the distribution [...] Sometimes the interest is, apart from measuring the time complexity, to measure the number of samples that have to be used in order to learn a specific distribution [...] in class of distributions [...] This quantity is called sample complexity of the learning algorithm.|$|R
40|$|Workstations and {{personal}} computers {{are increasingly being}} delivered {{with the ability to}} handle multimedia data; more and more of us are linked by high-speed digital networks. With multimedia communication environments becoming more commonplace, what have we learned from earlier experiences with prototype media environments? This paper reports on some of our experiences as developers, researchers and users of flexible, networked, multimedia computer environments, or "media spaces". It focusses on the lessons we can learn from extended, long-term use of media spaces, with connections that last not hours or days, but months or years. We take as our starting <b>point</b> a set <b>of</b> <b>assumptions</b> which differ from traditional analytical perspectives. In particular, we begin from the position that that a real-world baseline is not always an appropriate <b>point</b> <b>of</b> comparison for new media technologies; that a set of complex and intricate communicative behaviours arise over time; and that media spaces c [...] ...|$|R
40|$|The article {{presents}} main {{problems of the}} reform of {{the territorial division of}} the state from the <b>point</b> <b>of</b> view of the decision-ma king process. Using subjective and objective criteria, the author analysed various forms of social participation (active and passive) in the said process. Attention was also paid to legal instruments regulating the forms and scope of the participation of local communes in the process of changing the territorial division. The article contains various examples of the role of a human factor in shaping the administrative borderlines in Poland and Western Europe. The last part of the article focuses on the evaluation of the contemporary reform of public administration in Poland, taking as a <b>point</b> <b>of</b> reference the <b>assumptions</b> <b>of</b> the participative reform. The author discusses various forms of social activity in the process of shaping a new territorial structure of the state. Digitalizacja i deponowanie archiwalnych zeszytów RPEiS sfinansowane przez MNiSW w ramach realizacji umowy nr 541 /P-DUN/ 201...|$|R
5000|$|According to George Landow, who {{developed}} Holloway's model, sage writing {{can be distinguished}} from traditional wisdom literature in that [...] "Whereas the pronouncements of traditional wisdom literature always take as their <b>point</b> <b>of</b> departure the <b>assumption</b> that they embody the accepted, received wisdom of an entire society, the pronouncements of the biblical prophet and Victorian sage begin with the assumption that, however traditional their messages may once have been, they are now forgotten or actively opposed by society." [...] The sage borrows from the Old Testament prophets what Landow identifies as a four-part strategy of [...] "interpretation, attack upon the audience (or those in authority), warning, and visionary promise." ...|$|R
40|$|Abstract. Let (Xn) be a {{strictly}} stationary sequence with a marginal distribution function F such that 1 − F (x) = x −α L(x), x> 0, where α> 0 and L(x) is a slowly varying function. We assume that only observations of (Xn) {{are available at}} certain <b>points.</b> Under <b>assumption</b> <b>of</b> weak dependency we proved the consistency of Hill’s estimator of the tail index α based on an incomplete sample from {X 1, X 2 [...] ., Xn}. This {{is an extension of}} the results of Hsing [15] and Mladenović and Piterbarg [19]...|$|R
40|$|In {{common pool}} models fiscal {{outcomes}} {{are determined by}} the decision-making rule that is used to aggregate conflicting interests into a single budget. The rules according through which the budget is prepared, approved and carried out can affect spending bias. This paper analyses a model in which the minister of finance internalizes the common pool externality of the budget. From an institutional <b>point</b> <b>of</b> view, this <b>assumption</b> is realistic because he takes in account the budget equilibrium. Formally, this is reflected in the assumption that the minister of finance maximizes à la Stackelberg his utility function. In Stackelberg equilibrium, leader's expenditure choice is grater than in Cournot-Nash result, while the deficit bias is lower due to agenda setting power over spending ministers...|$|R
40|$|For {{more than}} two decades, there have been {{extensive}} studies of experience-based neural plasticity exploring effective applications of brain plasticity for cognitive and motor development. Research suggests that human brains continuously undergo structural reorganization and functional changes in response to stimulations or training. From a developmental <b>point</b> <b>of</b> view, the <b>assumption</b> <b>of</b> lifespan brain plasticity has been extended to older adults {{in terms of the}} benefits of cognitive training and physical therapy. To summarize recent developments, first, we introduce the concept of neural plasticity from a developmental perspective. Secondly, we note that motor learning often refers to deliberate practice and the resulting performance enhancement and adaptability. We discuss the close interplay between neural plasticity, motor learning and cognitive aging. Thirdly, we review research on motor skill acquisition in older adults with, and without, impairments relative to aging-related cognitive decline. Finally, to enhance future research and application, we highlight the implications of neural plasticity in skills learning and cognitive rehabilitation for the aging population...|$|R
3000|$|From (3) we obtain that d(f^n+ 1 (x_ 0),f^n(x_ 0))≠∞ for all n∈N, since d(f(x_ 0),x_ 0)≠∞. The {{fact that}} (X,τ (d),≤) has the finite-≤ {{property}} {{shows that the}} sequence (f^n(x_ 0))_n∈N is decreasing. Since (X,τ (d),≤) is ≤-τ(d)-complete we deduce {{the existence of a}} lower bound x^∗ of (f^n(x_ 0))_n∈N such that (f^n(x_ 0))_n∈N converges to x^∗ with respect to τ(d). Whence we have x^∗∈↓_≤x_ 0. By assumption (4) we see that (f^n+ 1 (x_ 0))_n∈N converges to f(x^∗) with respect to τ(d). The fact that (X,τ(d)) is Hausdorff provides us with the result that x^∗ is a fixed <b>point</b> <b>of</b> f. Finally, <b>assumption</b> (5) shows the uniqueness <b>of</b> the fixed <b>point</b> in ↓_≤x_ 0 following the same argument as those given in Theorem  9. □ [...]...|$|R
5000|$|The {{concept of}} ionic radii {{is based on}} the <b>assumption</b> <b>of</b> a spherical ion shape. However, from a group-theoretical <b>point</b> <b>of</b> view the <b>assumption</b> is only {{justified}} for ions that reside on high-symmetry crystal lattice sites like Na and Cl in halite or Zn and S in sphalerite. A clear distinction can be made, when the <b>point</b> symmetry group <b>of</b> the respective lattice site is considered, which are the cubic groups Oh and Td in NaCl and ZnS. For ions on lower-symmetry sites significant deviations of their electron density from a spherical shape may occur. This holds in particular for ions on lattice sites of polar symmetry, which are the crystallographic point groups C1, C1h, Cn or Cnv, n = 2, 3, 4 or 6. A thorough analysis of the bonding geometry was recently carried out for [...] pyrite-type compounds, where monovalent chalcogen ions reside on C3 lattice sites. It was found that chalcogen ions have to be modeled by ellipsoidal charge distributions with different radii along the symmetry axis and perpendicular to it.|$|R
50|$|The Catholic Church <b>of</b> the <b>Assumption</b> is a focal <b>point</b> <b>of</b> {{the area}} along Booterstown Avenue.|$|R
40|$|ABSTRACT. This {{paper is}} {{concerned}} with the fracture of composite materials containing stress concentration features such as notches and holes. In particular, it addresses the question of the use of the Theory of Critical Distances (TCD) – a method which is widely used for predicting notch effects in fatigue and fracture. The TCD makes use of a length constant, L, known as the critical distance, which is normally assumed to be a material property. However, many workers in the field of composite materials have suggested that the critical distance is not a constant, but rather is a function of notch size. I examined the evidence for this assertion, and concluded that it arises for four different reasons, two of which (process zone size and constraint) are real material effects whilst the other two (choice of test specimen and estimation of the stress field) arise due to errors in making the assessments. From a practical <b>point</b> <b>of</b> view, the <b>assumption</b> <b>of</b> a constant value for L leads to only small errors, so it is recommended for engineering design purposes...|$|R
40|$|We {{present an}} {{alternate}} {{approach to the}} problem of structure from motion (SfM) with noisy point measurements. With no information available about the joint density <b>of</b> three-dimensional <b>points,</b> the <b>assumption</b> <b>of</b> independence is the only reasonable one. With this assumption alone, the process of the factorization of the observed projections of inaccurately measured 3 dimensional points into motion and shape matrices is a blind source separation (demixing) problem in the presence of noise. This approach is very general, allowing the extension of all previous work on source separation to be applied to SfM in an information theory context. A significant reduction in the error of the estimation of the motion and shape matrices over other methods is possible. 1...|$|R
40|$|Abstract: It {{is still}} common {{practice}} in industry to handle the thickness control problem of a rolling mill around a working <b>point.</b> The <b>assumption</b> <b>of</b> linearity is no longer valid if the mill is operated in a wider working range. In a reversing mill this is especially the case when the plate enters and leaves the mill stand from pass to pass. A non-linear control strategy is proposed to improve the regularity of the thickness {{at the ends of}} the plate in order to decrease the amount of the plate to be cut off by the crop shear. The performance of the controller is examined using an advanced simulation model of a finishing mill. Copyright c ° 2005 IFA...|$|R
40|$|This paper {{addresses}} {{the problem of}} recovering relative structure, {{in the form of}} an invariant, from two views of a 3 D scene. The invariant structure is computed without any prior knowledge of camera geometry, or internal calibration, and with the property that perspective and orthographic projections are treated alike, namely, the system makes no assumption regarding the existence of perspective distortions in the input images. We show that, given the location of epipoles, the projective structure invariant can be constructed from only four corresponding points projected from four non-coplanar points in space (like in the case of parallel projection). This result leads to two algorithms for computing projective structure. The first algorithm requires six corresponding <b>points,</b> four <b>of</b> which are assumed to be projected from four coplanar points in space. Alternatively, the second algorithm requires eight corresponding <b>points,</b> without <b>assumptions</b> <b>of</b> coplanarity <b>of</b> object <b>points.</b> Our stud [...] ...|$|R
40|$|We study {{a general}} {{asymptotic}} behavior <b>of</b> critical <b>points</b> <b>of</b> a diffused interface energy with a fixed contact angle condition defined on a domain Ω⊂R^n. We {{show that the}} limit varifold derived from the diffused energy satisfies a generalized contact angle condition on the boundary under a set <b>of</b> <b>assumptions.</b> Comment: 11 page...|$|R
40|$|An {{analysis}} of the Lorentz transformation shows that the unchangeability of the space-time coordinates of the inertial systems under consideration {{and the possibility of}} a direct projection of those coordinates onto another are the underlying assumptions as to its unlimited validity. It is demonstrated that from a empiric-physical <b>point</b> <b>of</b> view these <b>assumptions</b> are not given in the case of inertial systems separated by very large distances. Analogous to the impossibility to measure motion relative to absolute space, {{it turns out to be}} physically non feasible to extend the coordinate system of any reference frame considered at rest relative to a distantly moving system for a direct comparision of the coordinates, and vice versa. The extended Lorentz transformation strictly based on first physical principles predicts the possibility of superluminal propagation of very distant material bodies and, in this case, the generation of Cerenkov radiation out of the quantum vacuum. For many astrophysical phenomena and their experimentally verified properties this yields a novel view. Comment: 11 page...|$|R
40|$|The Antarctic cold {{stratosphere}} {{in winter}} plays an importance role in ozone-hole formation since appearance of Polar Stratospheric Clouds (PSCs) which convert inert chlorine compounds to active ones is common under the cold atmospheric condition. Many investigators {{have discussed the}} relation between coldness in winter and scale of spring ozone depletion; however, few have discussed the relation between duration of cold time and ozone hole activity. It {{is essential for the}} formation of PSCs that the atmospheric temperature is lower than the frost <b>point</b> <b>of</b> H_ 2 O and/or HNO_ 3. Here, we analyzed the duration of the period when the stratospheric temperature is lower than the estimated frost <b>point</b> <b>of</b> PSCs on <b>assumption</b> <b>of</b> content of HNO_ 3 and H_ 2 O, and use the number of days with temperature lower than the frost point temperature as an index indicating the length of the cold period. The following points are suggested from the analysis : (1) At about 15 km height, the number of days with temperature lower than - 76 ℃ in one year is about 70 in 1980; it increased at the rate of 0. 8 days/year from 1967 to 1990. (2) Increasing length of the cold period is due to cold days in winter season at 20 km height, in late winter at 15 km height. (3) Year to year changes in monthly mean total ozone show good correlation with the variation in number of days with temperature lower than the estimated frost <b>point</b> <b>of</b> PSCs...|$|R
40|$|A {{breakdown}} frontier is {{the boundary}} between the set <b>of</b> <b>assumptions</b> which lead to a specific conclusion and those which do not. In a potential outcomes model with a binary treatment, we consider two conclusions: First, that ATE is at least a specific value (e. g., nonnegative) and second that the proportion of units who benefit from treatment is at least a specific value (e. g., at least 50 %). For these conclusions, we derive the breakdown frontier for two kinds of assumptions: one which indexes deviations from random assignment of treatment, and one which indexes deviations from rank invariance. These classes <b>of</b> <b>assumptions</b> nest both the <b>point</b> identifying <b>assumptions</b> <b>of</b> random assignment and rank invariance and the opposite end of no constraints on treatment selection or the dependence structure between potential outcomes. This frontier provides a quantitative measure of robustness of conclusions to deviations from the point identifying assumptions. We derive √(N) -consistent sample analog estimators for these frontiers. We then provide two asymptotically valid bootstrap procedures for constructing lower uniform confidence bands for the breakdown frontier. As a measure of robustness, estimated breakdown frontiers and their corresponding confidence bands can be presented alongside traditional point estimates and confidence intervals obtained under point identifying assumptions. We illustrate this approach in an empirical application to the effect of child soldiering on wages. We find that the conclusions we consider are fairly robust to failure of rank invariance, when random assignment holds, but these conclusions are much more sensitive to both assumptions for small deviations from random assignment...|$|R
40|$|Abstract. Workstations and {{personal}} computers {{are increasingly being}} delivered {{with the ability to}} handle multimedia data; more and more of us are linked by high-speed digital networks. With multimedia communication environments becoming more commonplace, what have we learned from earlier experiences with prototype media environments? This paper reports on some of our experiences as developers, researchers and users of flexible, networked, multimedia computer environments, or “media spaces”. It focusses on the lessons we can learn from extended, long-term use of media spaces, with connections that last not hours or days, but months or years. We take as our starting <b>point</b> a set <b>of</b> <b>assumptions</b> which differ from traditional analytical perspectives. In particular, we begin from the position that that a real-world baseline is not always an appropriate <b>point</b> <b>of</b> comparison for new media technologies; that a set of complex and intricate communicative behaviours arise over time; and that media spaces connect not only individuals, but the wider social groups of which they form part. We outline a framework based on four perspectives—individual, interactional, communal and societal—from which to view the behaviour of individuals and groups linked by multimedia environments. On the basis of our long-term findings, we argue for a view of media spaces which, first, focuses on a wider interpretation of media space interaction than the traditional view of persont-to-person connections, and, second, emphasises emergent communicative practices, rather than looking for the transfer of face-to-face behaviours. ...|$|R
40|$|A {{finite element}} {{analysis}} that focused on elastic buckling of columns is presented. The key <b>points</b> <b>of</b> interest for the study were the affect of the wandering neutral axis and the assumed effective length of the column. The veracity <b>of</b> <b>assumptions</b> such as {{the movement of the}} neutral axis is counteracted by the effects of the fixed end are considered...|$|R
40|$|At the {{macroeconomic}} level, {{the persistence}} of innovation allows sustainable growth. But does growth {{come from the same}} set of firms or originate always from different innovators? On this <b>point,</b> the <b>assumptions</b> <b>of</b> endogenous growth models differ and innovation persistence at the macroeconomic level can be supported by different firm-level behavioral <b>assumptions.</b> The aim <b>of</b> this article is twofold. First, we evaluate the empirical pertinence of the different views of the dynamics of the innovative process by estimating the degree of innovation persistence at the firm level. Secondly, we explore the determinants of innovation persistence by testing the empirical implications of three theoretical models. We show that the innovation persistence is essential at the firm level and that the origin of the persistence depends {{on the size of the}} firm...|$|R
40|$|In {{his first}} 1941 paper Kolmogorov {{assumed that the}} {{velocity}} has increments which are homogeneous and independent of the velocity at a suitable reference <b>point.</b> This <b>assumption</b> <b>of</b> local homogeneity {{is consistent with the}} nonlinear dynamics only in an asymptotic sense when the reference point is far away. The inconsistency is illustrated numerically using the Burgers equation. Kolmogorov's derivation of the four-fifths law for the third-order structure function and its anisotropic generalization are actually valid only for homogeneous turbulence, but a local version due to Duchon and Robert still holds. A Kolomogorov [...] Landau approach is proposed to handle the effect of fluctuations in the large-scale velocity on small-scale statistical properties; it is is only a mild extension of the 1941 theory and does not incorporate intermittency effects. Comment: 4 pages, 2 figure...|$|R
