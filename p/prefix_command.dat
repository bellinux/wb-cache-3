1|21|Public
40|$|A new set {{of tools}} is {{described}} for performing analyses of an ensemble of datasets that includes multiple copies of the original data with imputations of missing values, as required for the method of multiple imputation. The tools replace those originally developed by the authors. They {{are based on a}} simple data management paradigm in which the imputed datasets are all stored along with the original data in a single dataset with a vertically stacked format, as proposed by Royston in his ice and micombine commands. Stacking into a single dataset simplifies the management of the imputed datasets compared with storing them individually. Analysis and manipulation of the stacked datasets is performed with a new <b>prefix</b> <b>command,</b> mim, which can accommodate data imputed by any method as long as a few simple rules are followed in creating the imputed data. mim can validly fit most of the regression models available in Stata to multiply imputed datasets, giving parameter estimates and confidence intervals computed according to Rubin’s results for multiple imputation inference. Particular attention is paid to limiting the available postestimation commands to those that are known to be valid within the multiple imputation context. However, the user has flexibility to override these defaults. Features of these new tools are illustrated using two previously published examples. Copyright 2008 by StataCorp LP. mim, mimstack, ice, micombine, miset, mifit, multiple imputa- tion, missing data, missing at random...|$|E
50|$|The equal signs at the {{beginning}} of the lines provide space for line numbers if desired, and a place to enter XEDIT <b>prefix</b> <b>commands</b> that may operate on blocks of lines.|$|R
5000|$|In Tcl, {{applying}} the anonymous squaring function to 2 looks as follows:apply {x {expr {$x*$x}}} 2# returns 4This example involves two candidates {{for what it}} means to be a function in Tcl. The most generic is usually called a <b>command</b> <b>prefix,</b> and if the variable f holds such a function, then the way to perform the function application f(x) would be{*}$f $xwhere [...] is the expansion prefix (new in Tcl 8.5). The <b>command</b> <b>prefix</b> in the above example is apply [...] Command names can be bound to <b>command</b> <b>prefixes</b> by means of the [...] <b>command.</b> <b>Command</b> <b>prefixes</b> support currying. <b>Command</b> <b>prefixes</b> are very common in Tcl APIs.|$|R
5000|$|Some {{3rd party}} {{suppliers}} would get around this by <b>prefixing</b> their star <b>commands</b> with other letters for example Watford Electronics ROMS {{would have their}} star <b>commands</b> <b>prefixed</b> with [...] "W" [...] therefore making them unique.|$|R
5000|$|Maglor is a Sindarin {{rendering}} of his Quenya mother name Makalaurë (or Macalaurë), which means [...] "Gold-cleaver" [...] — alluding to his skill with the harp, {{and possibly the}} power of his voice. (He was also known as [...] "Strong-voiced" [...] and [...] "the Mighty Singer".) The meaning behind Maglor's father name, Kanafinwë (or Canafinwë), is uncertain, but probably contains the <b>prefix</b> kana/o (<b>commanding)</b> + Finwë.|$|R
40|$|When {{a binary}} or ordinal {{regression}} model incorrectly assumes that error variances {{are the same}} for all cases, the standard errors are wrong and (unlike OLS regression) the parameter estimates are biased. Heterogeneous choice/ location-scale models explicitly specify the determinants of heteroskedasticity in an attempt to correct for it. These models are also useful when the variability of underlying attitudes is itself of substantive interest. This paper illustrates how Williams’ user-written routine oglm (Ordinal Generalized Linear Models) can be used to estimate heterogeneous choice and related models. It further shows how two other models that have appeared in the literature – Allison’s (1999) model for comparing logit and probit coefficients across groups, and Hauser and Andrew’s (2006) logistic response model with partial proportionality constraints (LRPPC) – are special cases of the heterogenous choice model and/or algebraically equivalent to it, and can also be estimated with oglm. Other key features of oglm that are illustrated include support for linear constraints, the use of <b>prefix</b> <b>commands</b> such as svy and stepwise, and the computation of predicted probabilities and marginal effects. ...|$|R
50|$|The Hayes {{command set}} is modal, {{switching}} from command mode to online mode. This {{is not appropriate}} in the case where the commands and data will switch back and forth rapidly. An example of a non-modal escape sequence control language is the VT100, which used a series of <b>commands</b> <b>prefixed</b> by a Control Sequence Introducer.|$|R
5000|$|... mIRC scripts {{make use}} of sigils. Identifiers (whether custom or built-in) are preceded by , binary {{variables}} are preceded by , and other variables (whether local or global) are preceded by [...] Commands and aliases are not preceded by any particular character (although when entered from a window's command line they must be preceded by the <b>command</b> <b>prefix,</b> usually [...] ).|$|R
5000|$|The other {{candidate}} for [...] "function" [...] in Tcl is usually called a lambda, and appears as the [...] {{part of the}} above example. This is the part which caches the compiled form of the anonymous function, but {{it can only be}} invoked by being passed to the [...] command. Lambdas do not support currying, unless paired with an [...] to form a <b>command</b> <b>prefix.</b> Lambdas are rare in Tcl APIs.|$|R
2500|$|Hayes added a {{requirement}} of his own, that the modem {{be able to}} automatically detect what speed the computer's serial port was set to when first powered on. This was not simple unless the modem [...] "knew" [...] what data were initially being sent, allowing it to time the bits and thereby guess the speed. Heatherington eventually suggested {{the use of a}} well-known character sequence for this purpose, recommending AT for [...] "attention", which is <b>prefixed</b> on all <b>commands.</b>|$|R
5000|$|Relay ran on {{a special}} ID using several BITNET hosts. To use it, a message {{was sent to a}} user ID called RELAY. The Relay program running on that user ID would then provide {{multi-user}} chat functions, primarily in the form of [...] "channels" [...] (chat rooms). The message could contain either a command for Relay (preceded by the popular [...] "/" [...] slash character <b>command</b> <b>prefix,</b> still in use today), or a message at the remote host (typically a mainframe computer).|$|R
25|$|Hayes's slow {{entry into}} the {{high-speed}} market led to a fracturing of the command set. In order {{to set up the}} modem to accept or reject certain types of connections, Hayes had added a number of new <b>commands</b> <b>prefixed</b> by & (the ampersand) to the Smartmodem 2400. When they moved to the Smartmodem 9600, they simply extended the set further, using the same syntax. The other companies involved all used their own syntax; USR used an incompatible set of &-prefixed commands, Microcom used \, and Telebit was based on setting a series of registers. All of these survived for some time into the early 1990s.|$|R
40|$|We {{provide a}} {{collection}} of linear algebra commands that operate on explicit matrices (the commands with names that start with mat) and on "implied matrices" formed by variables and selected observations (the commands that start with the <b>prefix</b> var). Various <b>commands</b> are in (early stages of) development: matlp linear programming matnnls non-negative least squares matqp quadratic programming matqr QR-decomposition matspec special matrices (Pascal,Wilkinson,Rosset, [...] .) Please contact the author about details, {{and if you want}} to help in creating these commands and in making a fuller set. For those with Stata v 6 on an internet-accessible machine, install by typing. net cd [URL] then. net install matfunc...|$|R
50|$|Hayes's slow {{entry into}} the {{high-speed}} market led to a fracturing of the command set. In order {{to set up the}} modem to accept or reject certain types of connections, Hayes had added a number of new <b>commands</b> <b>prefixed</b> by & (the ampersand) to the Smartmodem 2400. When they moved to the Smartmodem 9600, they simply extended the set further, using the same syntax. The other companies involved all used their own syntax; USR used an incompatible set of &-prefixed commands, Microcom used \, and Telebit was based on setting a series of registers. All of these survived for some time into the early 1990s.|$|R
5000|$|A United States Navy {{ship that}} is not in active {{commission}} does not hold the title of United States Ship with simply the name without prefix used before and after commissioned service. Vessels, such as yard and harbor craft that are not commissioned and [...] "in service" [...] are officially referred to by name or hull number without <b>prefix.</b> Military Sealift <b>Command</b> (MSC) civilian manned ships [...] "in service" [...] are given the prefix United States Naval Ship (USNS). Prior to commissioning, ships may be described as a pre-commissioning unit or PCU; for example, the uncommissioned [...] has been described as the [...] "pre-commissioning unit (PCU) Gerald R. Ford." [...] However, the vessel's official name is Gerald R. Ford without any prefix, and will be known as USS Gerald R. Ford once commissioned.|$|R
5000|$|During {{the first}} year of World War II, Ouragan served with the 4th Destroyer Division with the destroyers Bourrasque and Orage, based at Brest. At the time of the German {{invasion}} of France in 1940, she was undergoing engine repairs at Brest. The Royal Navy towed her to Devonport where the repairs were completed. After the French surrender in June, the British commandeered her on 3 July and she was transferred to the Polish Navy on 17 July 1940. Until 30 April 1941 she sailed under the Polish ensign (using pennant number H16) but as OF Ouragan (OF - Okręt Francuski - [...] "French ship"), instead of the usual ORP <b>prefix.</b> She was <b>commanded</b> by Lieutenant Commander T. Gorazdowski; most of Ouragans crew were transferred from Grom, which had been sunk on 4 May 1940, during the Battle of Narvik.|$|R
50|$|If line {{numbers are}} {{not present in}} the {{original}} file, the editor supplies a pseudo-line number for use in editing each line. Because of the ISAM file format which supports an 8-character index key, line numbers consist of a floating-point number {{in the range of}} 0.0000 to 9999.9999. The usual line number supplied by EDT starts at 1.000 and is incremented by 1 as each new line was added. Lines can be inserted between other lines by using a fractional number as a <b>command</b> <b>prefix.</b> For example, line 1 of a file would be 1.0000, line 2 would be 2.0000, and to insert a line between 1 and 2, one could type @1.5: followed by the text of the line; the colon would be discarded and the line would be inserted at 1.5000, between 1 and 2. A renumber command is available to renumber {{all or part of the}} file.|$|R
2500|$|BASIC, other {{languages}} and utility ROM chips resided {{in any of}} four 16KB paged ROM sockets, with OS support for sixteen sockets via expansion hardware. The five (total) sockets were located partially obscured under the keyboard, with the leftmost socket hard-wired for the OS. [...] While the original usage for the perforated panel on {{the left of the}} keyboard was for a Serial ROM or Speech ROM, a ZIF socket or edgecard connector could be installed in that location instead. [...] The socket could be connected to one of the empty Sideways/PagedROM sockets via a header cable. The paged ROM system was essentially modular. [...] A language-independent system of star <b>commands,</b> <b>prefixed</b> with an asterisk, provided the ability to select a language (for example *BASIC, *PASCAL), a filing system (*TAPE, *DISC), change settings (*FX, *OPT) or carry out ROM-supplied tasks (*COPY, *BACKUP) from the command line. The MOS recognised a handful of built-in commands, and polled the paged ROMs in descending order for service otherwise; if none of them claimed the command then the OS returned a Bad command error. Connecting an external EPROM programmer, one could write extensive programs, copy to programmable ROM (PROM) or EPROM, then invoke them without taxing user memory.|$|R
40|$|Summary of Changes This release {{implements}} {{a number}} of bug fixes and allows site managers to customize contact information for their site(s). Administrators: Note important upgrade instructions below. New Features Customization Site managers can now customize the contact information—the e-mail address and phone number—that appears in the footer of every page. This e-mail address is also used as an administrative contact e-mail address (additional {{to those found in}} the database's users table) for automatically-generated messages. Bug Fixes Partial Fix for Issue # 332 For deployments where the URLs for the BETYdb site and the PEcAn site are [URL] Name]/[bety path] and [URL] Name]/pecan respectively, the "Results" links on the "Listing Workflows" pages should now work. (Note that bety path need not necessarily be the literal bety, but the PEcAn path must be pecan.) Fix for Issue # 355 It used to be that adding a new BETYdb user would result in an error if no administrative users (users with page_access_level = 1) had been added to the database because the application would attempt to send a sign-up notification e-mail to an empty list of administrators. The new contact information customization feature now ensures there is always at least one administrative e-mail address in the "To:" list, so this error will no longer occur. Fix for Issue # 362 The "CF Guidelines" link on the "New Variables" page should now work, even for sub-URI deployments. (Prior to this, the link only worked for root-path deployments such as [URL] Partial Fix for Issue # 374 Up until now, the BETYdb Web application only supported editing Point geometries. Moreover, updating a sites row via the Web app would silently convert non-Point geometries to Point geometries using the centroid function even if only fields unrelated to the geometry (or no fields at all) were updated! This fix prevents the Web app from changing the geometry data of non-point sites in order to prevent data loss. Fix for Issue # 377 Existing users can now request changes to their own access levels. Steps Needed for Upgrade Custom Configuration Once you have pulled the new code from GitHub and restarted your Rails server, the site should be up and running. But unless you create the new customization file config/application. yml, the footer of all pages will show bogus contact information in place of what has, up until now, been the hard-coded default (namely, phone number (217) 300 - 0266 and e-mail address betydb@gmail. com). Even more importantly, unless you have been using 'thisisnotasecret' as the value of REST_AUTH_SITE_KEY in the config initializer file config/initializers/site_keys. rb, none of your users will be able to log in. To address these issues, you must create an appropriate YAML config file. Here are step-by-step instructions for doing so: cd to the Rails root directory. Copy the default configuration file to application. yml: cp config/defaults. yml config/application. yml Do a copy, not a move! You want to keep defaults. yml as is. (For more elaborate set-ups having per-environment configuration values, you may want to copy config/application. yml. template instead. These instructions are for the simplest case.) Edit the string values for admin_phone and admin_email to the appropriate ones for your site. Open config/initializers/site_keys. rb and find the value for REST_AUTH_SITE_KEY. If it is anything other than 'thisisnotasecret', copy the value and use it as the value of rest_auth_site_key in application. yml. Otherwise, simply delete (or comment out) the line in application. yml that sets rest_auth_site_key. You now no longer need the file config/initializers/site_keys. yml, but don't delete it just yet! We want to be sure the site is working first: in case you mis-copied the site key value, we don't want the correct value to be lost forever. Instead, rename it: mv config/initializers/site_keys. rb config/initializers/site_keys. rb-disable Now the application will use and only use the value set in the application. yml file (or the value in defaults. yml if you aren't overriding the default value). Restart your Rails server. If you are using PhusionPassenger with Apache, you can just do touch tmp/restart. txt Go to your site page. You should see your custom contact information in the footer. If you still see the old hard-coded values ((217) 300 - 0266 and e-mail address betydb@gmail. com), you may not have actually restarted the server. Log out if you aren't already and then try logging in as any user. If you were able to log in, and you are sure that you actually did restart the server, it is now safe to delete config/initializers/site_keys. rb (which you renamed to config/initializers/site_keys. rb-disable above). Status of RSpec Tests There are now 246 RSpec tests that don't involve Javascript. These pass consistently, and may be run with the command bundle exec rspec -t ~js There are 28 RSpec tests that involve Javascript. Most of these pass consistently, but occassionally one of these tests will fail intermittently. (This may be a timing-related issue.) These tests may be run with the command bundle exec rspec -t js If one of these tests fails, the output will show the command needed to re-run the failing test. (If you aren't using RVM, you may need to <b>prefix</b> the <b>command</b> shown with bundle exec.) Often, the test will pass on a second try. (Complete details for running the RSpec tests are on the Wiki pages at [URL]. ...|$|R
40|$|New value {{constraints}} for database {{tables and}} validations for corresponding models; new RSpec tests; several bug fixes. Many new values constraints {{have been added}} to ensure database-integrity. Consistency checks {{have been added to}} the dbfiles table to ensure the referred-to containers exist. Restrictions on editing variables associated with traits or covariates that violate the range restriction for the variable value have been relaxed. Many bug fixes have been implemented. Changes Pertinent to PEcAn Users Administrators need to do a database migration. See "Database Changes" below. Summary of Changes Implemented values constraints, both at the database level and and the Web user-interface (Rails app) level The addition of value constraints is a major step toward helping to ensure data-integrity. It should no longer be possible, for example, to enter a site with a longitude value of 2000 (which has happened!) or genuses that aren't capitalized. Not only will these constraints help prevent gross errors, they will also help standardize the set of allowable values. When used to constrain values in columns comprising a candiate key, this will make it less likely that duplicate rows for the same entity will occur. To give one example, a uniqueness constraint on species. scientificname will not by itself prevent the occurrence of two species rows that are identical except that the first has scientificname "Abies alba" and the second has scientificname "Abies alba ". Requiring values in this column to be "whitespace-normalized" (no leading or trailing space, no double-spaces) will prevent this sort of duplicate from occurring. Implemented integrity constraints on references to inputs, models, and posteriors in dbfiles table A row having container_type = 'Input' must have a value for container_id that matches the id column value of some row in the inputs table. Similarly for container types "Model" and "Posterior". Allowing "lazier" approach to fixing variable range violations It used to be a variable could not be edited if any trait or covariate row that referred to the variable had a variable value that violated the range restriction for the variable. One first had to fix all the range violations in the traits and/or covariates rows before the variable could be edited, even if the update only involved, say, changing the notes. Now the trigger that checks for range violations is only run when an attempt is made to change the value of the min or max attribute. Thus all other attributes are now freely editable, regardless of any range violations in associated rows. Bug Fixes Some of the fixes include: Corrected text of mis-labelled buttons Fix for issue # 282 : Can't create two new managements in a row for a given treatment. Eliminated duplicate fields from New Species form Fixed layout of Species and Covariate "Edit" pages (GH # 280) Fixed trait-search action used on Covariate "Edit" page Eliminated vestigial obsolete code and routes Restored the change-password checkbox to the edit-user page to make this page clearer and more user-friendly Re-aligned and rearranged fields in species/show page (GH # 135) Restored some routes that were eliminated when wildcard routes were eliminated. Corrected title for Machine "Show" page (GH # 294) Allow Managers to delete Yield records; also allow Creators to delete Yield records they themselves created (part of Redmine issue # 2334) Made treatments on Listing Treatments page sortable Restyled Listing Treatments page to make it more readable, and added delete buttons to rows that user is allowed to delete (part of Redmine issue # 2334) Better error message when treatment is missing in bulk upload file (GH # 287) Better error message for violation of foreign key constraint (GH # 306) Fixed "CF Guidelines" link on Variables "Edit" page (GH # 308) Fixed Variable update form so that variable type can be updated (GH # 309) Fixed Management "Edit" page so that citation is not inadvertently changed (GH # 313) Fixed "map" links on Site listing page that were broken in certain deployment configurations and removed "map" link from "Show" pages (GH # 305) On "Edit" pages for traits and yields, preselect the current access level so that it isn't inadvertently changed (GH # 302) Fixed display of incorrect QA/QC values on yields listing page (part of GH # 303) Fixed bug in data access filter so that Views and Creators can once again see all records that they themselves created Changed criteria for displaying the edit control for QA/QC values on the yields list page (part of GH # 303) Re-styled "New File" page (GH # 304) Removed "Show" button from "New Site" page (GH # 321) Changed "Back" buttons on all "New" pages to say "All Records" like all the edit pages do (GH # 322) Steps Needed for Upgrade Database Changes Administrators need to do database migrations! There are three database migrations included in this release. The first and most extensive of these involves the addition of several new value constraints. The following set of SQL commands may prove helpful in applying this migration, especially if a data synchronization has not been done recently: update ensembles set notes = '', updated_at = now() at time zone 'utc' where notes is null; update runs set outprefix = '', updated_at = now() at time zone 'utc' where outprefix is null; update runs set setting = '', updated_at = now() at time zone 'utc' where setting is null; update users set state_prov = '', updated_at = now() at time zone 'utc' where state_prov is null; update users set postal_code = '', updated_at = now() at time zone 'utc' where postal_code is null; update workflows set params = '', updated_at = now() at time zone 'utc' where params is null; If further trouble-shooting of migrations is required, the following may be helpful in finding the source of migration problems: bundle exec rake db:migrate 2 >& 1 | grep ERROR (If you run BETYdb in the production environment, and your production database differs from you development database, <b>prefix</b> this <b>command</b> with RAILS_ENV=production.) The database version for this release is 20150521211114. Gem Installation No new Gems need be installed for this release. Status of RSpec Tests All tests continue to pass when run in the default environment and can be run using the command bundle exec rspec Complete details for running the rspec tests are on the updated Wiki page at [URL]...|$|R

