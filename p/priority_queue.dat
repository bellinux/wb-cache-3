881|769|Public
25|$|This {{implementation}} {{is used in}} the heapsort algorithm, {{where it}} allows the space in the input array to be reused to store the heap (i.e. the algorithm is done in-place). The implementation is also useful for use as a <b>Priority</b> <b>queue</b> where use of a dynamic array allows insertion of an unbounded number of items.|$|E
25|$|A* is also optimally {{efficient}} for any heuristic h, {{meaning that}} no optimal algorithm employing the same heuristic will expand fewer nodes than A*, except {{when there are}} multiple partial solutions where h exactly predicts {{the cost of the}} optimal path. Even in this case, for each graph there exists some order of breaking ties in the <b>priority</b> <b>queue</b> such that A* examines the fewest possible nodes.|$|E
25|$|Heaps {{where the}} parent key {{is greater than}} or equal to (≥) the child keys are called max-heaps; those where it is less than or equal to (≤) are called min-heaps. Efficient (logarithmic time) {{algorithms}} are known for the two operations needed to implement a <b>priority</b> <b>queue</b> on a binary heap: inserting an element, and removing the smallest (largest) element from a min-heap (max-heap). Binary heaps are also commonly employed in the heapsort sorting algorithm, which is an in-place algorithm owing to the fact that binary heaps can be implemented as an implicit data structure, storing keys in an array and using their relative positions within that array to represent child-parent relationships.|$|E
50|$|From a computational-complexity standpoint, <b>priority</b> <b>queues</b> are {{congruent}} to sorting algorithms. The {{section on}} the equivalence of <b>priority</b> <b>queues</b> and sorting algorithms, below, describes how efficient sorting algorithms can create efficient <b>priority</b> <b>queues.</b>|$|R
5000|$|Generic {{methods of}} {{arriving}} at double-ended <b>priority</b> <b>queues</b> from normal <b>priority</b> <b>queues</b> are: ...|$|R
40|$|<b>Priority</b> <b>queueing</b> {{systems are}} oftentimes {{set up so}} that {{arriving}} customers are placed into one of N distinct priority classes. Moreover, to determine the order of service, each customer (upon arriving to the system) is assigned a priority level that is unique to the class to which it belongs. In static <b>priority</b> <b>queues,</b> the <b>priority</b> level of a class-k (k= 1, 2, [...] .,N) customer {{is assumed to be}} constant with respect to time. This simple prioritization structure is easy to implement in practice, and as such, various types of static <b>priority</b> <b>queues</b> have been analyzed and subsequently applied to real-life queueing systems. However, the assumption of constant priority levels for the customers may not always be appropriate. Furthermore, static <b>priority</b> <b>queues</b> can often display poor system performance as their design does not provide systems managers the means to balance the classical trade-off inherent in all <b>priority</b> <b>queues,</b> that is: reducing wait times of higher priority customers consequently increases the wait times for those of lower priority. An alternative to static <b>priority</b> <b>queues</b> are accumulating <b>priority</b> <b>queues,</b> where the <b>priority</b> level of a class-k customer is assumed to accumulate linearly at rate b_k> 0 throughout the class-k customer's time in the system. The main benefit of accumulating <b>priority</b> <b>queues</b> is the ability, through the specification of the accumulating priority rates {b_k}_k= 1 ^N, to control the waiting times of each class. In the past, due to the complex nature of the accumulating prioritization structure, the control of waiting times in accumulating <b>priority</b> <b>queues</b> was limited [...] - being administered only through their first moments. Nowadays, with the advent of a very useful tool called the maximal priority process, it is possible to characterize the waiting time distributions of several types of accumulating <b>priority</b> <b>queues.</b> In this thesis, we incorporate the concept of accumulating priority to several previously analyzed static <b>priority</b> <b>queues,</b> and use the maximal priority process to establish the corresponding steady-state waiting time distributions. In addition, since static <b>priority</b> <b>queues</b> may be captured from accumulating <b>priority</b> <b>queues,</b> useful comparisons between the considered accumulating <b>priority</b> <b>queues</b> and their static priority counterparts are made throughout this thesis. Thus, in the end, this thesis results in a set of extensive analyses on these highly flexible accumulating <b>priority</b> <b>queueing</b> models that provide a better understanding of their overall behaviour, as well as exemplify their many advantages over their static priority equivalents...|$|R
25|$|The {{difficulties}} {{for individuals to}} be discharged from debt in bankruptcy proceedings and the awfulness of debtors prison made the introduction of modern companies legislation, and general availability of limited liability, all the more urgent. The first step was the Joint Stock Companies Act 1844, which allowed companies to be created through registration rather than a Royal Charter. It was accompanied by the Joint Stock Companies Winding-Up Act 1844, which envisaged a separate procedure to bring a company {{to an end and}} liquidate the assets. Companies had legal personality separate from its incorporators, but only with the Limited Liability Act 1855 would a company's investors be generally protected from extra debts upon a company's insolvency. The 1855 Act limited investors' liability to the amount they had invested, so if someone bought shares in a company that ran up massive debts in insolvency, the shareholder could not be asked for more than he had already paid in. Thus, the risk of debtors' prison was reduced. Soon after, reforms were made for all indebted people. The Bankruptcy Act 1861 was passed allowing all people, not just traders, to file for bankruptcy. The Debtors Act 1869 finally abolished imprisonment for debt altogether. So the legislative scheme of this period came to roughly resemble the modern law. While the general principle remained pari passu among the insolvent company's creditors, the claims of liquidators expenses and wages of workers were given statutory priority over other unsecured creditors. However, any creditor who had contracted for a security interest would be first in the <b>priority</b> <b>queue.</b> Completion of insolvency protection followed UK company law's leading case, Salomon v A Salomon & Co Ltd. Here a Whitechapel bootmaker had incorporated his business, but because of economic struggles, he had been forced into insolvency. The Companies Act 1862 required a minimum of seven shareholders, so he had registered his wife and children as nominal shareholders, even though they played little or no part in the business. The liquidator of Mr Salomon's company sued him to personally pay the outstanding debts of his company, arguing that he should lose the protection of limited liability given that the other shareholders were not genuine investors. Salomon's creditors were particularly aggrieved because Salomon himself had taken a floating charge, over all the company's present and future assets, and so his claims for debt against the company had ranked in priority to theirs. The House of Lords held that, even though the company was a one-man venture in substance, anybody who duly registered would have the protection of the Companies Acts in the event of insolvency. Salomon's case effectively completed the process 19th century reforms because any person, even the smallest business, could have protection from destitution following business insolvency.|$|E
500|$|Instead {{of using}} an integer <b>priority</b> <b>queue</b> in a sorting algorithm, it is {{possible}} to go the other direction, and use integer sorting algorithms as subroutines within an integer <b>priority</b> <b>queue</b> data structure. [...] used this idea to show that, if {{it is possible}} to perform integer sorting in time [...] per key, then the same time bound applies to the time per insertion or deletion operation in a <b>priority</b> <b>queue</b> data structure. Thorup's reduction is complicated and assumes the availability of either fast multiplication operations or table lookups, but he also provides an alternative <b>priority</b> <b>queue</b> using only addition and Boolean operations with time [...] per operation, at most multiplying the time by an iterated logarithm.|$|E
500|$|A <b>priority</b> <b>queue</b> is a data {{structure}} for maintaining {{a collection of}} items with numerical priorities, having operations for finding and removing the item with the minimum priority value. Comparison-based priority queues such as the binary heap take logarithmic time per update, but other structures such as the van Emde Boas tree or bucket queue may be faster for inputs whose priorities are small integers. These {{data structure}}s {{can be used in}} the selection sort algorithm, which sorts a collection of elements by repeatedly finding and removing the smallest element from the collection, and returning the elements in the order they were found. A <b>priority</b> <b>queue</b> can be used to maintain the collection of elements in this algorithm, and the time for this algorithm on a collection of [...] elements can be bounded by the time to initialize the <b>priority</b> <b>queue</b> and then to perform [...] find and remove operations. For instance, using a binary heap as a <b>priority</b> <b>queue</b> in selection sort leads to the heap sort algorithm, a comparison sorting algorithm that takes [...] time. Instead, using selection sort with a bucket queue gives a form of pigeonhole sort, and using van Emde Boas trees or other integer priority queues leads to other fast integer sorting algorithms.|$|E
5000|$|Certificate {{failures}} {{can occur}} in the <b>priority</b> <b>queues</b> and the sorted lists. Swaps in the ordering of the points will cause changes to T (which will take O (...) time), and may cause insertions/deletions in the <b>priority</b> <b>queues.</b>|$|R
50|$|Monotone <b>priority</b> <b>queues</b> are {{specialized}} queues {{that are}} optimized {{for the case}} where no item is ever inserted that has a lower priority (in the case of min-heap) than any item previously extracted. This restriction is met by several practical applications of <b>priority</b> <b>queues.</b>|$|R
40|$|On packet marking at <b>priority</b> <b>queues</b> Abstract — This note {{concerns}} charging, {{rate control}} and routing for {{a communication network}} using <b>priority</b> mechanisms at <b>queues.</b> It is argued that by appropriately marking packets at overloaded resources, end-systems can be provided with the information necessary to balance load across different routes and priorities. Keywords—Congestion pricing, differentiated services, <b>priority</b> <b>queues,</b> rate control, routing. I...|$|R
500|$|... by a {{technique}} that overlays a quadtree-based <b>priority</b> <b>queue</b> data structure {{on top of the}} distance matrix and uses it to perform the standard greedy clustering algorithm.|$|E
500|$|A Van Emde Boas tree {{may be used}} as a <b>priority</b> <b>queue</b> to sort a set of [...] keys, each in {{the range}} from [...] to , in time [...] This is a {{theoretical}} improvement over radix sorting when [...] is sufficiently large. However, in order to use a Van Emde Boas tree, one either needs a directly addressable memory of [...] words, or one needs to simulate it using a hash table, reducing the space to linear but making the algorithm be randomized. Another <b>priority</b> <b>queue</b> with similar performance (including the need for randomization in the form of hash tables) is the Y-fast trie of [...]|$|E
500|$|An early {{result in}} this {{direction}} was provided by [...] using the cell probe model of computation (an artificial model in which the complexity of an algorithm is measured only {{by the number of}} memory accesses it performs). Building on their work, [...] described two data structures, the Q-heap and the atomic heap, that are implementable on a random access machine. The Q-heap is a bit-parallel version of a binary trie, and allows both <b>priority</b> <b>queue</b> operations and successor and predecessor queries to be performed in constant time for sets of [...] items, where [...] is the size of the precomputed tables needed to implement the data structure. The atomic heap is a B-tree in which each tree node is represented as a Q-heap; it allows constant time <b>priority</b> <b>queue</b> operations (and therefore sorting) for sets of [...] items.|$|E
5000|$|... 1995-1996: <b>Priority</b> <b>Queues,</b> Dictionaries, and Multidimensional Point Sets ...|$|R
40|$|<b>Priority</b> <b>queues</b> and {{double-ended}} <b>priority</b> <b>queues</b> {{are fundamental}} data types in Computer Science, and various data structures {{have been proposed}} to implement them. In particular, diamond deques, interval heaps, min-max-pair heaps, and twin-heaps provide implicit structures for double-ended <b>priority</b> <b>queues.</b> Although these heap-like structures are essentially the same when they are presented in an abstract manner, they possess different implementations and thus have different construction algorithms. In this paper, we present a fast algorithm for building these data structures. Our results improve over previously fast known algorithms. Godkänd; 1995; 20070408 (ysko...|$|R
40|$|A three {{preemptive}} <b>priority</b> <b>queuing</b> {{system is}} considered where customers with three <b>priorities</b> joined a <b>queue</b> {{according to a}} Poisson process. A customer with higher priority needs to enter the service immediately upon arrival. The recursive formulas approach was extended to determine the steady state probabilities of such a <b>priority</b> <b>queuing</b> system. Key words: Poisson process, recursive formulas based approach, steady state probabilities, thre...|$|R
500|$|However, the single-linkage {{clustering}} can {{be found}} more efficiently by an alternative algorithm that computes the minimum spanning tree of the input distances using Prim's algorithm, and then sorts the minimum spanning tree edges and uses this sorted list to guide the merger of pairs of clusters. Within Prim's algorithm, each successive minimum spanning tree edge {{can be found}} by a sequential search through an unsorted list of the smallest edges connecting the partially constructed tree to each additional vertex. This choice saves {{the time that the}} algorithm would otherwise spend adjusting the weights of vertices in its <b>priority</b> <b>queue.</b> Using Prim's algorithm in this way would take time [...] and space , matching the best bounds that could be achieved with the nearest-neighbor chain algorithm for distances with constant-time calculations.|$|E
500|$|If {{the edges}} are sorted by their weights, then a {{modified}} version of Dijkstra's algorithm can compute the bottlenecks between a designated start vertex and every other vertex in the graph, in linear time. The key idea behind the speedup over a conventional version of Dijkstra's algorithm is that the sequence of bottleneck distances to each vertex, in the order that the vertices are considered by this algorithm, is a monotonic subsequence of the sorted sequence of edge weights; therefore, the <b>priority</b> <b>queue</b> of Dijkstra's algorithm can be implemented as a bucket queue: an array indexed by the numbers from 1 to [...] (the number of edges in the graph), where array cell [...] contains the vertices whose bottleneck distance is the weight of the edge with position [...] in the sorted order. This method allows the widest path problem to be solved as quickly as sorting; for instance, if the edge weights are represented as integers, then the time bounds for integer sorting a list of [...] integers would apply also to this problem.|$|E
2500|$|Typical {{implementations}} of A* use a <b>priority</b> <b>queue</b> {{to perform}} the repeated selection of minimum (estimated) cost nodes to expand. This <b>priority</b> <b>queue</b> {{is known as the}} open set or fringe. At each step of the algorithm, the node with the lowest [...] value is removed from the queue, the [...] and [...] values of its neighbors are updated accordingly, and these neighbors are added to the queue. The algorithm continues until a goal node has a lower [...] value than any node in the queue (or until the queue is empty). The [...] value of the goal is then the length of the shortest path, since [...] at the goal is zero in an admissible heuristic.|$|E
5000|$|... #Subtitle level 2: Equivalence of <b>priority</b> <b>queues</b> and sorting {{algorithms}} ...|$|R
40|$|Abstract [...] In this paper, {{we present}} an {{admission}} control scheme which provides per-flow delay and bandwidth guarantees based solely upon simple class-based strict <b>priority</b> <b>queueing.</b> We derive basic {{properties of the}} worst-case behaviour in strict <b>priority</b> <b>queueing</b> systems using network calculus. Building upon these properties the flow admission control scheme is devised. The rationale behind this work is the appealing simplicity {{as well as the}} almost ubiquitous availability of strict <b>priority</b> <b>queueing</b> in today’s routers and the thus promising applicability of our results for practical purposes in providing quality of service (QoS) in the Internet...|$|R
40|$|Abstract: In this paper, we derive {{worst case}} bounds on delay and backlog for non-preemptive <b>priority</b> <b>queueing</b> systems using network calculus. There are known {{results for the}} average {{behaviour}} of non-preemptive <b>priority</b> <b>queueing</b> systems from traditional queueing theory. By use of numerical investigations, we compare our worst case bounds to those average behaviour results {{in order to give}} a feel as to how conservative the worst case bounds are. A practical application of our results is given for DiffServ-based networks which use simple <b>priority</b> <b>queueing</b> to differentiate several traffic classes by assigning them different delay targets...|$|R
2500|$|When a path is {{required}} {{at the end}} of the search, it is common to keep with each node a reference to that node's parent. [...] At the end of the search these references can be used to recover the optimal path. [...] If these references are being kept then it can be important that the same node doesn't appear in the <b>priority</b> <b>queue</b> more than once (each entry corresponding to a different path to the node, and each with a different cost). [...] A standard approach here is to check if a node about to be added already appears in the <b>priority</b> <b>queue.</b> [...] If it does, then the priority and parent pointers are changed to correspond to the lower cost path. A standard binary heap based <b>priority</b> <b>queue</b> does not directly support the operation of searching for one of its elements, but it can be augmented with a hash table that maps elements to their position in the heap, allowing this decrease-priority operation to be performed in logarithmic time. Alternatively, a Fibonacci heap can perform the same decrease-priority operations in constant amortized time.|$|E
2500|$|The -ary heap or -heap is a <b>priority</b> <b>queue</b> data structure, a {{generalization}} of the binary heap {{in which the}} nodes have [...] children instead of 2. Thus, a binary heap is a 2-heap, and a ternary heap is a 3-heap. According to Tarjan and Jensen et al., -ary heaps were invented by Donald B. Johnson in 1975.|$|E
2500|$|There are {{a number}} of simple {{optimizations}} or implementation details that can significantly affect the performance of an A* implementation. [...] The first detail to note is that the way the <b>priority</b> <b>queue</b> handles ties can {{have a significant effect on}} performance in some situations. [...] If ties are broken so the queue behaves in a LIFO manner, A* will behave like depth-first search among equal cost paths (avoiding exploring more than one equally optimal solution).|$|E
40|$|Abstract: One key {{component}} in the Network Based Defence (NBD) concept is a robust high capacity radio network. Several different types of services will be provided through the network, such as group calls and situation awareness services. As all services place specific demands on packet delays and packet losses {{in order to be}} fully functional, {{there is a need for}} a Quality of Service (QoS) mechanism in the network. In this paper we examine the effect of employing <b>priority</b> <b>queues</b> in the MAC layer in a TDMA network. We compare the performance of two different <b>priority</b> <b>queues,</b> namely fixed <b>priority</b> <b>queuing</b> and weighted fair queuing. Our simulations show that fixed <b>priority</b> <b>queuing</b> provides a sharp delay differentiation between service classes, whereas weighted fair queuing provides the ability to control the delay differentiation. One of those queuing schemes alone might not be the best solution for providing QoS. Instead we suggest that a combination of them be used. 1...|$|R
5000|$|Compactness: {{compactness}} {{follows from}} the compactness of the kinetic sorted lists and kinetic <b>priority</b> <b>queues</b> ...|$|R
40|$|This paper {{presents}} a new implementation technique for <b>priority</b> search <b>queues.</b> This {{abstract data type}} is an amazing blend of finite maps and <b>priority</b> <b>queues.</b> Our implementation supports logarithmic access to a binding with a given key and constant access to a binding with the minimum value. <b>Priority</b> search <b>queues</b> can be used, for instance, to give a simple, purely functional implementation of Dijkstra's single-source shortest-paths algorithm...|$|R
2500|$|Divide {{and conquer}} {{algorithms}} {{can also be}} implemented by a non-recursive program that stores the partial sub-problems in some explicit data structure, such as a stack, queue, or <b>priority</b> <b>queue.</b> [...] This approach allows more freedom {{in the choice of}} the sub-problem that is to be solved next, a feature that is important in some applications — e.g. in breadth-first recursion and the branch and bound method for function optimization. [...] This approach is also the standard solution in programming languages that do not provide support for recursive procedures.|$|E
2500|$|However, Dijkstra's {{algorithm}} uses a <b>priority</b> <b>queue</b> to greedily {{select the}} closest vertex {{that has not}} yet been processed, and performs this relaxation process on all of its outgoing edges; by contrast, the Bellman–Ford algorithm simply relaxes all the edges, and does this [...] times, where [...] is the number of vertices in the graph. In each of these repetitions, the number of vertices with correctly calculated distances grows, from which it follows that eventually all vertices will have their correct distances. This method allows the Bellman–Ford algorithm to be applied to a wider class of inputs than Dijkstra.|$|E
2500|$|For the stack, <b>priority</b> <b>queue,</b> deque, and DEPQ types, peek can be {{implemented}} in terms of pop and push (if done at same end). For stacks and deques this is generally efficient, as these operations are O(1) in most implementations, and do not require memory allocation (as they decrease {{the size of the}} data) – the two ends of a deque each functioning as a stack. For priority queues and DEPQs, however, dequeuing and enqueuing often take O(log n) time (for example if implemented as a binary heap), while O(1) performance of [...] "peek" [...] (here generally called [...] "find-min" [...] or [...] "find-max") is a key desired characteristic of priority queues, and thus peek is almost invariably implemented separately.|$|E
5000|$|Repeat {{the above}} steps for the plane rotated , to get kinetic <b>priority</b> <b>queues</b> on [...] and [...] respectively.|$|R
40|$|We {{present a}} new input-queued switch {{architecture}} designed to support deadline-ordered scheduling at extremely high-speeds. In particular, deadline-ordered scheduling is enabled {{through a combination}} of hardware-based sorted <b>priority</b> <b>queues</b> called P-heaps and a round-robin crossbar scheduler. The <b>priority</b> <b>queues</b> are implemented using a novel scalable pipelined heap-based architecture. Using a 0. 35 micron CMOS standard-cell technology, we demonstrate a 32 -port switch capable of sustaining 10 Gb/s line rates...|$|R
40|$|Brodal {{recently}} introduced the first implementation of imperative <b>priority</b> <b>queues</b> to support findMin, insert, and meld in O(1) worst-case time, and delete Min in O(log n) worst-case time. These bounds are asymptotically optimal among all comparison-based <b>priority</b> <b>queues.</b> In this paper, we adapt Brodal’s data structure to a purely functional setting. In doing so, we both simplify the data structure and clarify {{its relationship to}} the binomial queues of Vuillemin, which support all four operations in O(log n) time. Specifically, we derive our implementation from binomial queues in three steps: first we reduce the running time of insert to O(1) by eliminating the possibility of cascading links; second, we reduce the running time of find Min to O(1) by adding a global root to hold the minimum element; and finally, we reduce the running time of meld to O(1) by allowing <b>priority</b> <b>queues</b> to contain other <b>priority</b> <b>queues.</b> Each of these steps is expressed using ML-style functors. The last transformation, known as data-structural bootstrapping, is an interesting application of higher-order functors and recursive structures. 1...|$|R
