198|418|Public
2500|$|The {{beans in}} the bag are the population. The handful are the sample. The null {{hypothesis}} is that the sample originated from the population. The criterion for rejecting the null-hypothesis is the [...] "obvious" [...] difference in appearance (an informal difference in the mean). The interesting result is that consideration of a real population and a real sample produced an imaginary bag. The philosopher was considering logic rather than probability. To be a real statistical hypothesis test, this example requires the formalities of a <b>probability</b> <b>calculation</b> and a comparison of that probability to a standard.|$|E
5000|$|Principles and {{classical}} formulas for <b>probability</b> <b>calculation</b> (1925) ...|$|E
5000|$|A {{treaty on}} <b>probability</b> <b>calculation</b> and its {{applications}} (1924-1934) ...|$|E
5000|$|<b>Probability</b> <b>calculations</b> {{are neither}} {{frightening}} nor mysterious ...|$|R
3000|$|... {{satisfies}} (1) and is {{sent by the}} source. This assumption {{helps to}} make the <b>probability</b> <b>calculations</b> in Section 4.3 less tedious.|$|R
40|$|In {{this paper}} the {{computational}} aspects of <b>probability</b> <b>calculations</b> for dynamical partial sum expressions are discussed. Such dynamical partial sum expressions have many important applications, and examples {{are provided in}} the fields of reliability, product quality assessment, and stochastic control. While these <b>probability</b> <b>calculations</b> are ostensibly of a high dimension, and consequently intractable in general, it is shown how a recursive integration methodology can be implemented to obtain exact calculations as a series of two-dimensional calculations. The computational aspects of the implementaion of this methodology, with the adoption of Fast Fourier Transforms, are discussed...|$|R
50|$|Being reputed as {{specialist}} in <b>probability</b> <b>calculation,</b> {{he was invited}} to different countries to give lectures in this field.|$|E
5000|$|... have {{vanished}} from the transition <b>probability</b> <b>calculation.</b> The decoherence has irreversibly converted quantum behaviour (additive probability amplitudes) to classical behaviour (additive probabilities).|$|E
5000|$|Traité du calcul des probabilités et de ses applications, avec Emile Borel (1939)/Work on <b>probability</b> <b>calculation</b> and its applications, with Emile Borel ...|$|E
5000|$|... 1997 SAPHIRE for Windows, version 6.x, is released. Use of a Windows user-inferface makes SAPHIRE easy to learn. The new [...] "plug-in" [...] feature allows {{analysts to}} expand on the {{built-in}} <b>probability</b> <b>calculations.</b>|$|R
50|$|It is well {{established}} that humans find logic hard, mathematics harder, and probability even more challenging. Psychologists have discovered systematic violations of <b>probability</b> <b>calculations</b> and behavior by humans. Consider, for example, the Monty Hall problem.|$|R
50|$|By {{assessing}} {{the state of}} the second level influences, the quality of information, organisation and personal factors, the overall likelihood of either success or failure of the task can be calculated by means of conditional <b>probability</b> <b>calculations.</b>|$|R
50|$|From {{the autumn}} of 1962 he was again professor, head of the {{department}} of <b>probability</b> <b>calculation</b> and mathematical statistics (successor to professor Onicescu).|$|E
50|$|In 1948, {{after the}} reform of {{education}} in all degrees, he was appointed {{head of the department}} of <b>probability</b> <b>calculation</b> and mathematical statistics at the Faculty of mathematics and physics of Bucharest University, then as professor head of department of applied mathematics.|$|E
5000|$|How {{likely is}} it that the DNA found on the {{forensic}} scene belongs to Mr X? What is the chance that you are wrong? Could you in your <b>probability</b> <b>calculation</b> take into account the other evidence that points towards the identification of Mr X? ...|$|E
50|$|As {{a summer}} student in 1975 and 1976, Hui worked at I. P. Sharp Associates (IPSA) in Calgary, on workspaces for {{statistical}} and <b>probability</b> <b>calculations.</b> The major {{attraction of the}} job was the unlimited computer time with access to APL.|$|R
50|$|Random graphs by Antonsen: Spacetime is {{described}} by dynamical graphs with points (associated with vertices) and links (of unit length) that are created or annihilated according to <b>probability</b> <b>calculations.</b> The parameterization of graphs in a metaspace gives rise to time.|$|R
40|$|Order-Statistic {{solutions}} {{make use}} of Logarithmic-Normal Distribution in hydrologic statistics. In this paper, the author presents practical Tabulations to the very simplification in <b>probability</b> <b>calculations</b> {{in order to facilitate}} rapid computations. Furthermore, the author considers on basic plotting position in these computations...|$|R
50|$|Fisher and Neyman were {{separated}} by attitudes and perhaps language. Fisher was a scientist and an intuitive mathematician. Inductive reasoning was natural. Neyman was a rigorous mathematician. He was convinced by deductive reasoning rather by a <b>probability</b> <b>calculation</b> based on an experiment. Thus there was an underlying clash between applied and theoretical, between science and mathematics.|$|E
5000|$|At the hip, a DXA-equivalent T-score may be {{calculated}} for {{comparison to the}} WHO classiﬁcation at the proximal femur as normal, osteopenia (T-Score < -1.0 and > -2.5) or osteoporosis (T-Score < -2.5). This T-Score may {{also be used for}} fracture risk <b>probability</b> <b>calculation</b> in the WHO FRAX® tool with [...] "T-Score" [...] as the appropriate DXA setting.|$|E
5000|$|In another Sardinian study {{confined}} to {{towns in the}} northern sector of the island, 14% of 100 samples were all found to be G2a (P15+) based only on a <b>probability</b> <b>calculation.</b> The G2 category as represented by P15 became G2a in {{the period in which}} this study was conducted. The men were predicted just [...] "G2" [...] in the study. But P15 (now G2a) was probably the intended category.|$|E
50|$|Méré {{claimed that}} he had {{discovered}} probability theory himself, a claim not taken seriously by the mathematicians involved. He also claimed that his <b>probability</b> <b>calculations</b> showed that mathematics was inconsistent, and argued elsewhere that mathematicians were wrong in thinking that lines are infinitely divisible.|$|R
5000|$|The {{coherency}} {{principle in}} Bayesian decision theory {{is the assumption}} that personal probabilities follow the ordinary rules for <b>probability</b> <b>calculations</b> (where the validity of these rules corresponds to the self-consistency just referred to) and thus that consistent decisions can be obtained from these probabilities.|$|R
40|$|The Classical Interpretation of <b>Probability</b> <b>Calculations.</b> The {{classical}} {{interpretation of}} <b>probability</b> <b>calculations</b> (e. 1660 - 1840) {{was characterized by}} a goal—describing the intuitions of reasonable men in situations of uncertainty —as well as by three hidden oppositions: between the concurrent meanings of the word "reasonable", between description and prescription, and between the subjective and objective meanings of probability. This goal determined the applications of calculation up {{until the beginning of}} the nineteenth century, at which time such oppositions were recognized and typically classical applications were rejected. The new probabilists moved from the rationality of the few to the irrationality of the many. Daston Lorraine. L'interprétation classique du calcul des probabilités. In: Annales. Économies, Sociétés, Civilisations. 44 ᵉ année, N. 3, 1989. pp. 715 - 731...|$|R
5000|$|While stellar {{collisions}} {{may occur}} very frequently {{in certain parts}} of the galaxy, the likelihood of a collision involving the Sun is very small. A <b>probability</b> <b>calculation</b> predicts the rate of stellar collisions involving the Sun is 1 in 1028 years.For comparison, {{the age of the universe}} is of the order 1010 years. The likelihood of close encounters with the Sun is also small. The rate is estimated as follows: ...|$|E
50|$|The only {{evidence}} against Adams was the DNA evidence. His age was substantially {{different from that}} reported by the victim, the victim did not identify him and he had an alibi which was never disproved. The 1 in 200 million match <b>probability</b> <b>calculation</b> did not allow {{for the fact that}} the perpetrator might be a close relative of the defendant - an important point, since the defendant had a half-brother in his 20s whose DNA was never tested.|$|E
5000|$|A more {{complete}} treatment would consider {{all of the}} choices, not only the choices of high card from two equals. In the example spades suit, we must incorporate the choice of low card by West from 32 and from Q32. The 2 and 3 are manifestly equivalent cards which West should play uniform randomly from both original holdings [...] - [...] that is, randomly {{on the first two}} tricks, always retaining the queen from Q32. The preceding <b>probability</b> <b>calculation</b> depends on West doing so.|$|E
50|$|From 1937, Mihoc {{went to the}} University of Bucharest as {{assistant}} to Octav Onicescu, first at mechanics, then at algebra and <b>probabilities</b> <b>calculation</b> (1937-1942). That same year (1937) he also taught general mathematics with the students from the preparation year of the Polytechnic University of Bucharest.|$|R
50|$|If {{there is}} no reason to prefer a {{specific}} card (for example to signal to partner), a player holding two or more equivalent cards should sometimes randomize their order of play (see the note on Nash equilibrium). The <b>probability</b> <b>calculations</b> in coverage of restricted choice often take uniform randomization for granted but that is problematic.|$|R
30|$|The three probabilities serve more as {{comparative}} than absolute values. A {{change in}} the standard deviations of these <b>probability</b> <b>calculations</b> would similarly affect all probabilities thus calculated, with the most probable detection still having the highest probability ranking. Empirical values thus are assigned to the standard deviations, and parameter selections in the experiment produce insignificant effects.|$|R
50|$|Sword of the Stars {{consists}} of turn based strategic gameplay highlighted by real time battles. Each {{of the four}} races has a unique method of strategic movement among other differentiators. Also the game provides a high amount of randomness from technology availability, to map features, to large scale independent threats. Sword of the Stars is fully multiplayer capable allowing players to leave and enter the game at-will. Finally a detailed ship design system and the simulation of combat using a physics based engine instead of <b>probability</b> <b>calculation,</b> provides a large variety in combat engagements.|$|E
5000|$|The {{beans in}} the bag are the population. The handful are the sample. The null {{hypothesis}} is that the sample originated from the population. The criterion for rejecting the null-hypothesis is the [...] "obvious" [...] difference in appearance (an informal difference in the mean). The interesting result is that consideration of a real population and a real sample produced an imaginary bag. The philosopher was considering logic rather than probability. To be a real statistical hypothesis test, this example requires the formalities of a <b>probability</b> <b>calculation</b> and a comparison of that probability to a standard.|$|E
50|$|Through their {{correspondence}} in 1654, Fermat and Blaise Pascal helped lay {{the foundation}} for the theory of probability. From this brief but productive collaboration on the problem of points, they are now regarded as joint founders of probability theory. Fermat is credited with carrying out the first ever rigorous <b>probability</b> <b>calculation.</b> In it, he was asked by a professional gambler why if he bet on rolling at least one six in four throws of a die he won in the long term, whereas betting on throwing at least one double-six in 24 throws of two dice resulted in his losing. Fermat showed mathematically why this was the case.|$|E
40|$|Depends R (> = 1. 8. 0), paramlink Description This package {{represents}} a bare-bones implementation of an interface {{to the core}} Familias functions (www. familias. name),which are programmed in C++. The package itself functions {{as a kind of}} database, where information about persons, pedigrees,allele systems and observations for persons are entered stepwise. In the end, <b>probability</b> <b>calculations</b> are made...|$|R
40|$|The {{objective}} {{of this paper is}} to illustrate, analytically and quantitatively, the effect of high-order temporal correlations on steady-state and transition <b>probability</b> <b>calculations</b> in Finite State Machines (FSMs) analysis. As the main theoretical contribution, it is shown that, if the sequence feeding the target circuit has temporal correlations of order k, then a lag-k Markov chain model of the sequence will suffice to model correctly the joint transition probabilities of the primary inputs and internal states in the target circuit. From the experimental point of view, it is shown that assuming temporal independence or using firstorder temporal models is not sufficient, that is, the inaccuracies induced in steady-state and transition <b>probability</b> <b>calculations</b> are significant for most of the analyzed benchmarks. I. INTRODUCTION In the last decade, probabilistic approaches have received a lot of attention as a viable alternative to deterministic techniques for analyzing complex digital [...] ...|$|R
40|$|We {{show that}} the {{microscopic}} TDHF approach provides an important tool to {{shed some light on}} the nuclear dynamics leading to the formation of superheavy elements. In particular, we discuss studying quasifission dynamics and calculating ingredients for compound nucleus formation <b>probability</b> <b>calculations.</b> Comment: Submitted to the proceedings of the 6 th International Conference on Fission and Properties of Neutron-Rich Nuclei (ICFN 6...|$|R
