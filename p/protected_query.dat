1|33|Public
30|$|Users {{are more}} and more {{concerned}} about the privacy risks of querying search engines. In this paper, we analyze the robustness of popular private Web search solutions. We considered three categories of solutions: unlinkability solutions, indistinguishability solutions, and indistinguishability solutions over unlinkability solutions. In our approach, we assumed an adversary which aims to retrieve for each <b>protected</b> <b>query,</b> both the content of the initial query and the identity of the associated user. Moreover, we assumed an adversary which was able to collect preliminary information about the interests of each user in the system. This preliminary information are stored in user profile structures. Preliminary information of users can be collected in different manners, from their social networks activity, from their posts on blogs or discussions on forums 1. In this paper, we considered as preliminary information a part of the history of query of users.|$|E
30|$|Dynamically {{evaluating}} <b>protected</b> <b>queries</b> {{in order}} to measure their level of protection over time represents an interesting research agenda for future works. For instance, thanks to this dynamic assessment, {{it will be possible to}} adapt the queries protection before sending them, and to reinforce the user awareness.|$|R
40|$|Privacy <b>Protected</b> spatial <b>queries</b> {{refer to}} spatial queries whose answers {{rely on the}} {{location}} of theinquirer. Efficient processing of Privacy <b>Protected</b> spatial <b>query</b> is of critical importance with the everincreasingdeployment and use of mobile technologies. We show that Privacy <b>Protected</b> spatial <b>query</b> havecertain unique characteristics that the traditional spatial query processing in centralized databases does notaddress. For example, a significant challenge is presented by wireless broadcasting environments, whichhave excellent scalability but often exhibit high latency database access. We present a novel query processingtechnique that, though maintaining high scalability and accuracy, manages to reduce the latencyconsiderably in answering Privacy <b>Protected</b> spatial <b>query.</b> Our approach is based on peer-to-peer sharing,which enables us to process queries without delay at a mobile host by using query results cached in itsneighboring mobile peers. We demonstrate the feasibility of our approach through a probabilistic analysis,and we illustrate the appeal of our technique through extensive simulation results...|$|R
30|$|In practice, our adversary {{model can}} be seen as a search engine {{receiving}} <b>protected</b> <b>queries</b> from users who just start to adopt a private Web search solution. In this use case, the preliminary information represent the non-protected queries sent by the users to the search engine before the exploitation of a private Web search solution. Consequently, the most active users have exposed more preliminary information to the search engine through their past querying activity.|$|R
30|$|As {{shown in}} the three {{previous}} sections, both unlinkability and indistinguishability approaches fail to properly <b>protect</b> user <b>queries.</b> Therefore, we carried out two further experiments which combine these two approaches (i.e., TrackMeNot and GooPIR over an unlinkability solution).|$|R
40|$|A digital {{certificate}} based remote {{data access control}} scheme is proposed for safe authentication of accessor in wireless sensor network (WSN). The scheme is founded on the access control scheme {{on the basis of}} characteristic expression (named CEB scheme). Data is divided by characteristics and the key for encryption is related to characteristic expression. Only the key matching with characteristic expression can decrypt the data. Meanwhile, three distributed certificate detection methods are designed to prevent the certificate from being misappropriated by hostile anonymous users. When a user starts query, the key access control method can judge whether the query is valid. In this case, the scheme can achieve public certificate of users and effectively <b>protect</b> <b>query</b> privacy as well. The security analysis and experiments show that the proposed scheme is superior in communication overhead, storage overhead, and detection probability...|$|R
40|$|Abstract — User {{authentication}} {{is essential}} for customized services and privileged access control in wireless sensor network. In 2009, Das proposed a novel two-factor authentication scheme for wireless sensor network, where a user must prove the possession of both a password and a smart card. His scheme is well-designed for sensor nodes which typically have limited resources {{in the sense that}} its authentication procedure requires no public key operations but it utilizes only cryptographic hash function. In this letter, we point out that Das’s protocol is vulnerable to an offline password guessing attack, and also show a countermeasure to overcome the vulnerability without sacrificing any efficiency and usability. Besides the patch, we suggest a method to <b>protect</b> <b>query</b> response messages from wireless a sensor node to a user, which is necessary in serving a user in a confidential and authentic way. Index Terms — Wireless sensor network, authentication, password, smart car...|$|R
40|$|Many {{database}} {{applications and}} environments, such as mediation over heterogeneous database sources and data warehousing for decision support, lead to complex queries. Queries are often nested, defined over previously defined views, and may involve unions. There {{are good reasons}} why one might want to "remove" pieces (sub-queries or sub-views) from such queries: some sub-views of a query may be effectively cached from previous queries, or may be materialized views; some may be known to evaluate empty, by reasoning over the integrity constraints; and some may match <b>protected</b> <b>queries,</b> which for security cannot be evaluated for all users. In this paper, we present a new evaluation strategy with respect to queries defined over views, which we call tuple-tagging, that allows for an efficient "removal" of sub-views from the query. Other approaches to this are to rewrite the query so the sub-views to be removed are effectively gone, then to evaluate the rewritten query. With the tuple [...] ...|$|R
30|$|In this section, we {{evaluate}} {{the capacity of}} SimAttack to compromise the anonymity of users’ <b>queries</b> <b>protected</b> by an unlinkability solutions. More precisely, we assess the sensitivity of SimAttack on unlinkability solutions over various parameters. Finally, we compare the performance provided by SimAttack against {{the performance of the}} concurrent machine learning approach.|$|R
30|$|SimAttack {{is able to}} de-anonymize a {{large number}} of <b>queries</b> <b>protected</b> by unlinkability solutions. Nevertheless, the SimAttack’s {{capacity}} of de-anonymizing queries depends on the number of users in the system, and both the number {{and the quality of the}} preliminary user profiles collected by the adversary. While SimAttack provides similar performances than the concurrent machine learning attack, SimAttack is much more faster.|$|R
40|$|International audienceSeveral private Web search {{solutions}} {{have been}} proposed to preserve the user privacy while querying search engines. However, most of these solutions are costly in term of processing, network overhead and latency as they mostly rely on cryptographic techniques and/or the generation of fake requests. Furthermore, all these solutions <b>protect</b> all <b>queries</b> similarly, ignoring whether the original request contains sensitive content (e. g., religious, political or sexual orientation) or not. Based on an analysis of a real dataset of Web search requests, we show that queries related to sensitive matters are in practice a minority. As a consequence, <b>protecting</b> all <b>queries</b> similarly results in poor performance as {{a large number of}} queries get overprotected. In this paper, we propose a request sensitivity assessment module that we use for improving the practicability of existing private web search solutions. We assess the sensitivity of a request in two phases: a semantic sensitivity analysis (based on the topic of the query) and a request linkability analysis (based on the similarity between the current query and the query history of the requester). Finally, the sensitivity assessment is used to adapt the level of protection of a given query according to its identified degree of sensitivity: the more sensitive a query is, the more protected it will be. Experiments with a real dataset show that our approach can improve the performance of state-of-the-arts private Web search solutions by reducing the number of queries overpro-tected, while ensuring a similar level of privacy to the users, making them more likely to be used in practice...|$|R
40|$|Traditionally, the {{declarative}} {{nature of}} SQL {{is viewed as}} a major strength. It allows database users to simply describe what they want to retrieve without worrying about how the answer to their question is actually computed. However, in a decentralized setting, two different approaches to evaluating the same query may reveal vastly different information about the query being asked (and, hence, about the user) to participating servers. In the case that a user's query contains sensitive or private information, this is clearly problematic. In this dissertation, we address the problem of <b>protecting</b> <b>query</b> issuer privacy. We hypothesize that by extending SQL to allow for declarative specification of constraints on the attributes of query evaluation plans and accounting for such constraints during query optimization, users can produce efficient query evaluation plans that protect the private intensional regions of their queries without explicit server-side support. Towards supporting this hypothesis, we formalize a notion of intensional query privacy that we call (I, A) -privacy, and present PASQL, a set of extensions to SQL that allows users to specify (I, A) -privacy constraints to a query optimizer. We explore tradeoffs between the expressiveness of several PASQL variants, optimization time requirements, and the optimality of plans produced. We present two algorithms for optimizing queries with attached (I, A) -privacy constraints and formally establish their time and space complexities. We prove that one is capable of producing optimal results, though at the cost of greatly increased time and space requirements. We use the other as the basis of PAQO, our implementation of an (I, A) -privacy-aware query optimizer. We present an extensive experimental evaluation of PAQO to show that is is capable of efficiently generating plans to evaluate PASQL queries, and to confirm the results of our formal complexity analysis...|$|R
30|$|For instance, we {{leverage}} SimAttack {{to evaluate the}} privacy protection offered by GooPIR. We succeed to identify at least 50.6 % of initial <b>queries</b> <b>protected</b> by this solution {{even if they were}} protected by 7 fake queries. Last but not least, as we show in our study that the previous aforementioned solutions (i.e., Tor-based, TrackMeNot, and GooPIR) do not protect properly the user privacy, we also analyze hybrid private Web search solutions: GooPIR over an unlinkability solution and TrackMeNot over an unlinkability solution.|$|R
40|$|Abstract — Peer Data Management Systems (PDMSs) {{promise to}} extend the {{classical}} data integration approach to the Internet scale. Unfortunately, some challenges remain before realizing this promise. One {{of the biggest challenges}} is preserving the privacy of the exchanged data while passing through several intermediate peers. Another challenge is protecting the mappings used for data translation. Achieving privacy preservation without being unfair to any of the peers is yet a third challenge. This paper presents a novel query answering protocol in PDMSs to address these challenges. The protocol employs a technique based on noise selection and insertion to <b>protect</b> the <b>query</b> results, and a commutative encryption-based technique to protect the mappings and ensure fairness among peers. An extensive security analysis of the protocol shows that it is resilient to seven possible types of attacks, assuming a maliciou...|$|R
30|$|Web Search engines {{have become}} an {{indispensable}} online service to retrieve content on the Internet. However, using search engines raises serious privacy issues as the latter gather large amounts of data about individuals through their search queries. Two main techniques have been proposed to privately query search engines. A first category of approaches, called unlinkability, aims at disassociating the query and the identity of its requester. A second category of approaches, called indistinguishability, aims at hiding user’s queries or user’s interests by either obfuscating user’s queries, or forging new fake queries. This paper presents {{a study of the}} level of protection offered by three popular solutions: Tor-based, TrackMeNot, and GooPIR. For this purpose, we present an efficient and scalable attack – SimAttack – leveraging a similarity metric to capture the distance between preliminary information about the users (i.e., history of query) and a new query. SimAttack de-anonymizes up to 36.7 % of <b>queries</b> <b>protected</b> by an unlinkability solution (i.e., Tor-based), and identifies up to 45.3 and 51.6 % of <b>queries</b> <b>protected</b> by indistinguishability solutions (i.e., TrackMeNot and GooPIR, respectively). In addition, SimAttack de-anonymizes 6.7 % more queries than state-of-the-art attacks and dramatically improves the performance of the attack on TrackMeNot by 23.6 %, while retaining an execution time faster by two orders of magnitude.|$|R
40|$|Web Search engines {{have become}} an {{indispensable}} online service to retrieve content on the Internet. However, using search engines raises serious privacy issues as the latter gather large amounts of data about individuals through their search queries. Two main techniques have been proposed to privately query search engines. A first category of approaches, called unlinkability, aims at disassociating the query and the identity of its requester. A second category of approaches, called indistinguishability, aims at hiding user’s queries or user’s interests by either obfuscating user’s queries, or forging new fake queries. This paper presents {{a study of the}} level of protection offered by three popular solutions: Tor-based, TrackMeNot, and GooPIR. For this purpose, we present an efficient and scalable attack – SimAttack – leveraging a similarity metric to capture the distance between preliminary information about the users (i. e., history of query) and a new query. SimAttack de-anonymizes up to 36. 7 % of <b>queries</b> <b>protected</b> by an unlinkability solution (i. e., Tor-based), and identifies up to 45. 3 and 51. 6 % of <b>queries</b> <b>protected</b> by indistinguishability solutions (i. e., TrackMeNot and GooPIR, respectively). In addition, SimAttack de-anonymizes 6. 7 % more queries than state-of-the-art attacks and dramatically improves the performance of the attack on TrackMeNot by 23. 6 %, while retaining an execution time faster by two orders of magnitude...|$|R
40|$|Abstract. We {{consider}} {{the problem of}} answering queries against an EL knowledge base (KB) using secrets, whenever {{it is possible to}} do so without compromising secrets. We provide a polynomial time algorithm that, given an EL KB Σ, asetS of secrets to be <b>protected</b> and a <b>query</b> q, outputs “Yes ” whenever Σ � q and the answer to q, together with the answers to any previous queries answered by the KB, does not allow the querying agent to deduce any of the secrets in S. This approach allows more flexible information sharing than is possible with traditional access control mechanisms. ...|$|R
40|$|We {{consider}} {{the problem of}} answering queries against a knowledge base (KB) using secrets, whenever {{it is possible to}} do so without compromising secrets. We study query answering against EL knowledge bases. We provide a polynomial time algorithm that, given an EL KB Sigma, a set S of secrets to be <b>protected</b> and a <b>query</b> q or the form C(a) or r(a,b), outputs "Yes 2 ̆ 72 ̆ 7 whenever Sigma entails q and the answer to q, together with the answers to any previous queries answered by the KB, does not allow the querying agent to deduce any of the secrets in S. This approach allows more flexible information sharing than is possible with traditional access control mechanisms...|$|R
40|$|Peer-to-peer data {{integration}} - a. k. a. Peer Data Management Systems (PDMSs) - promises {{to extend the}} classical {{data integration}} approach to the Internet scale. Unfortunately, some challenges remain before realizing this promise. One {{of the biggest challenges}} is preserving the privacy of the exchanged data while passing through several intermediate peers. Another challenge is protecting the mappings used for data translation. Protecting the privacy without being unfair to any of the peers is yet a third challenge. This paper presents a novel query answering protocol in PDMSs to address these challenges. The protocol employs a technique based on noise selection and insertion to <b>protect</b> the <b>query</b> results, and a commutative encryption-based technique to protect the mappings and ensure fairness among peers. An extensive security analysis of the protocol shows that it is resilient to several possible types of attacks. We implemented the protocol within an established PDMS: the Hyperion system. We conducted an experimental study using real data from the healthcare domain. The results show that our protocol manages to achieve its privacy and fairness goals, while maintaining query processing time at the interactive level...|$|R
40|$|Part 2 : Challenges to Privacy, Security, and IdentityInternational audienceTo {{preserve}} {{data confidentiality}} in database outsourcing scenarios, various techniques {{have been proposed}} that preserve {{a certain degree of}} confidentiality while still allowing to efficiently execute certain queries. Typically, several of those techniques have to be combined to achieve a certain degree of confidentiality. However, finding an appropriate combination is not a trivial task, as expert knowledge is required and interdependencies between the techniques exist. Securus, an approach we previously proposed, addresses this problem. Securus allows users to model their requirements regarding the information in the outsourced dataset that has to be <b>protected.</b> Furthermore, <b>queries</b> that have to be efficiently executable on the outsourced data can be specified. Based on these requirements, Securus uses Integer Linear Programming (ILP) to find a suitable combination of confidentiality enhancing techniques and generates a software adapter. This software adapter transparently applies the techniques to fulfill the specified requirements and can be used to seamlessly outsource and query the data. In this paper, we present an outline of Securus and extend our previous work by highlighting the differences to other approaches in the field. Furthermore, we show how Securus can be extended to allow for more efficient solutions if the attacker’s capabilities can be modeled by the user...|$|R
40|$|Data mining has {{wide variety}} of real time {{application}} in many fields such as financial, telecommunication, biological, and among government agencies. Classification is {{the one of the}} main task in data mining. For the past few years, due to the increment in various privacy problem, many conceptual and feasible so-lution to the classification problem have been proposed under different certainty prototype. With the increment of cloud com-puting users have an opportunity to offload the data and pro-cessing to the cloud, in an encrypted form. The data in the cloud are in encrypted form, existing privacy preserving clas-sification systems are not relevant. This paper reviews how to perform privacy preserving k-NN classification over encrypted data in the cloud. The recommended protocol preserves pri-vacy of data, <b>protect</b> the user <b>query,</b> and hide the access mode...|$|R
40|$|International audienceQuerying Web {{search engines}} {{is by far}} the most {{frequent}} activity performed by online users and consequently the one in which they are likely to reveal a significant amount of personal information. Protecting the privacy of Web requesters is thus becoming increasingly important. This is often done by using systems that guarantee unlinkability between the requester and her query. The most effective solution to reach this objective is the use of anonymous communication protocols (e. g., onion routing). However, anonymity might not resist to machine learning attacks. Thus, an adversary could link a query to her requester’s public profile. Other approaches guarantee unidentifiability of the user interests by generating noise (e. g., creating covert queries or adding extra keywords). However, these solutions overload the network and decrease the accuracy of the results. We present in this paper the first contribution that combines both approaches. It allows a user to perform a private Web search resistant to machine learning attacks while slightly decreasing the relevance of the results. Our three stage architecture contains: (1) a Privacy Proxy that relies on two non-colluding servers to hide the requester identity from the search engine; (2) a Linkability Assessment that analyses the risk that a request is reassociated with the identity of the requester; (3) an Obfuscator that <b>protects</b> the <b>queries</b> which have been flagged linkable by the linkability assessment...|$|R
40|$|Abstract—Data {{privacy is}} a major concern when users query public online data services. The privacy of {{millions}} of people has been jeopardized in numerous user data leakage incidents in many popular online applications. To address the critical problem of personal data leakage through queries, we enable private querying on public data services so that the contents of user queries and any user data are hidden and therefore not revealed to the online service provider. We propose two protocols for processing private database queries, namely BHE and HHE. BHE provides complete query privacy by using Paillier’s homomorphic encryption along with the bucketization of public data. In contrast to traditional Private Information Retrieval (PIR) proposals, BHE only incurs one round of client server interaction for processing one query. Built upon BHE, HHE is a hybrid protocol that applies BHE computation and communication on a subset of the data buckets, such that this subset covers the actual requested data but also mimics frequent query patterns of common users, thus achieving practical query performance while providing proper privacy protection. Because of the use of frequent query patterns and data specific privacy protection, HHE is not vulnerable to traditional attacks on k-Anonymity that explore data similarity and skewness. Moreover, HHE consistently <b>protects</b> user <b>query</b> privacy for a sequence of queries in a query session. I...|$|R
40|$|Thesis (M. S.) [...] Wichita State University, College of Engineering, Dept. of Electrical Engineering and Computer ScienceQuery {{privacy is}} a {{critical}} concern to users of location-based services. A majority of existing query privacy protection techniques {{are based on the}} notion of k-anonymity, wherein a user's exact location is obfuscated into a spatial range containing at least k users, called the cloaking region. Thus, the user who issues the query cannot be distinguished from k- 1 other users. However, when mobile users issue continuous queries using such a k-anonymity scheme, an adversary can exploit the overlapped areas of the corresponding cloaking regions to determine the query issuer with a significantly higher probability. This thesis proposes a query-based memorizing algorithm to specifically address this issue. The main idea in this thesis is to memorize the identity of the users in an anonymity set or cloaking region. When a user issues sequential location-based queries, the cloaking regions are determined such that they include a maximum number of users that have appeared in the past cloaking regions. The query-based memorizing approach is empirically evaluated by means of simulation experiments and a detailed comparative analysis with three other popular privacy protection algorithms using standard privacy metrics is performed. The results show that the proposed algorithm efficiently <b>protects</b> users' <b>query</b> privacy against the overlapped area attack, especially when users are highly mobile...|$|R
40|$|A {{wireless}} {{sensor network}} (WSN) is an ad-hoc network composed of small sensor nodes deployed in large numbers to sense the physical world. Wireless sensor networks have very broad application prospects including both military and civilian usage. They include surveillance, tracking at critical facilities, or monitoring animal habitats. Sensor networks {{have the potential to}} radically change the way people observe and interact with their environment. With current {{wireless sensor network}} technology, people will gain advanced knowledge of physical and social systems, and the advent of a ubiquitous sensing era is coming. In-network processing or data aggregation is an essential function of WSNs to collect raw sensory data and get aggregated statistics about the measured environment, and help queries capture the major feature or changes of the measured systems. As more and more applications of WSNs collect sensitive measurements of people’s everyday life, privacy and security concerns draw more and more attention. If privacy of sensory content is not preserved, it is not feasible to deploy the WSNs for information collection. On the other hand, if integrity of the collected sensory information is not <b>protected,</b> no <b>queries</b> or users can trust and/or use the collected information. Hence, two important issues should be addressed before wireless sensor network systems can realize their promise in civilian applications: (1) protect data privacy, so the deployment of the wireless sensor network systems is feasible; (2) enforce integrity, so users can trust the collected or aggregated information. 1...|$|R
40|$|XML (eXtendible Markup Language) has {{recently}} {{emerged as the}} most relevant standardization effort {{in the area of}} markup languages, and it is increasingly used as the language for information representation and exchange over the Web. An important feature of XML is that information on document structures is available on the Web together with the document contents. This information can be exploited to improve document handling and query processing. At the same time, XML databases on the Web are proliferating. The possibility of associating a kind of schema (either a DTD, an XML schema or others), allows one {{to take advantage of the}} knowledge about document structures for storing, <b>querying,</b> <b>protecting</b> and indexing a set of documents. An important feature that should be guaranteed is the possibility of exchanging information among XML databases on the Web in order to share data dealing with the same topic. However, in an heterogeneous environment as the Web, it is not reasonable to assume tha...|$|R
40|$|During {{the last}} few years, the {{technological}} progress in collecting, storing and processing a large quantity of data for a reasonable cost has raised serious privacy issues. Privacy concerns many areas, but is especially important in frequently used services like search engines (e. g., Google, Bing, Yahoo!). These services allow users to retrieve relevant content on the Internet by exploiting their personal data. In this context, developing solutions to enable users to use these services in a privacy-preserving way is becoming increasingly important. In this thesis, we introduce SimAttack an attack against existing protection mechanism to query search engines in a privacy-preserving way. This attack aims at retrieving the original user query. We show with this attack that three representative state-of-the-art solutions do not protect the user privacy in a satisfactory manner. We therefore develop PEAS a new protection mechanism that better protects the user privacy. This solution leverages two types of protection: hiding the user identity (with a succession of two nodes) and masking users' queries (by combining them with several fake queries). To generate realistic fake queries, PEAS exploits previous queries sent by the users in the system. Finally, we present mechanisms to identify sensitive queries. Our goal is to adapt existing protection mechanisms to <b>protect</b> sensitive <b>queries</b> only, and thus save user resources (e. g., CPU, RAM). We design two modules to identify sensitive queries. By deploying these modules on real protection mechanisms, we establish empirically that they dramatically improve {{the performance of the}} protection mechanisms...|$|R
40|$|Inmany {{applications}} of networked information systems, {{the need to}} share information often has to be balanced against {{the need to protect}} secret information from unintended disclosure, e. g., due to copyright, privacy, security, or commercial considerations. We study the problem of secrecy-preserving reasoning, that is, answering queries using secret information, whenever it is possible to do so, without compromising secret information. In the case of a knowledge base that is queried by a single querying agent, we introduce the notion of a secrecy envelope. This is a superset of the secret part of the knowledge base that needs to be concealed from the querying agent {{in order to ensure that}} the secret information is not compromised. We establish several important properties of secrecy envelopes and present an algorithm for computing minimal secrecy envelopes. We extend our analysis of secrecy preserving reasoning to the setting where different parts of the knowledge base need to be <b>protected</b> from different <b>querying</b> agents that are subject to certain restrictions on the sharing of answers supplied to them by the knowledge base...|$|R
40|$|Abstract—With {{the growing}} {{awareness}} of data privacy, more and more cloud users choose to encrypt their sensitive data before outsourcing them to the cloud. Search over encrypted data is therefore a critical function facilitating efficient cloud data access given the high data volume that each user has to handle nowadays. Inverted index {{is one of the}} most efficient searchable index structures and has been widely adopted in plaintext search. However, securing an inverted index and its associated search schemes is not a trivial task. A major challenge exposed from the existing efforts is the difficulty to <b>protect</b> user’s <b>query</b> privacy. The challenge roots on two facts: 1) the existing solutions use a deterministic trapdoor generation function for queries; and 2) once a keyword is searched, the encrypted inverted list for this keyword is revealed to the cloud server. We denote this second property in the existing solutions as one-time-only search limitation. Additionally, conjunctive multi-keyword search, which is the most common form of query nowadays, is not supported in those works. In this paper, we propose a public-key searchable encryption scheme based on the inverted index. Our scheme preserves the high search efficiency inherited from the inverted index while lifting the one-time-only search limitation of the previous solutions. Our scheme features a probabilistic trapdoor generation algorithm and protects the search pattern. In addition, our scheme supports conjunctive multi-keyword search. Compared with the existing public key based schemes that heavily rely on expensive pairing operations, our scheme is more efficient by using only multiplications and exponentiations. To meet stronger security requirements, we strengthen our scheme with an efficient oblivious transfer protocol that hides the access pattern from the cloud. The simulation results demonstrate that our scheme is suitable for practical usage with moderate overhead. I...|$|R
40|$|Due to the {{development}} of global navigation satellite systems (GNSS), people are able to obtain their precise locations in real time. This in turn leads {{to a wide range of}} location-based services (LBS), through which a user can acquire information customised to locations. However, the vulnerabilities of GNSS systems and the exposure of information such as locations and queries in LBS requests impose a strong need from users on security. In this thesis, we study two security requirements in LBSs: location assurance and privacy. Location assurance expresses users’ requirement for trustworthy locations in terms of correctness and precision while privacy addresses users’ concern about personal information leakage in LBSs. First, we present a trust framework to detect spoofing by evaluating the integrity of GNSS signals. The framework combines existing spoofing detection methods to generate an overall quantitative evaluation of the integrity of received signals. Based on this evaluation, users can determine the extent to which they can trust their locations. We implement a prototype based on our framework and develop a public service called location assurance certification. In this service, a trusted agent is introduced to issue certificates for users’ locations according to the integrity of their received signals. Second, we propose a general approach to <b>protect</b> users’ <b>query</b> privacy when the adversary has access to various contextual information. We present a probabilistic framework, in which we formally define the attacks to infer the issuers of LBS queries by exploring various contextual information. With this framework, we propose a series of query privacy metrics. These metrics not only measure query privacy from different perspectives but also enable users to express their requirements for query privacy flexibly and precisely. Our framework finally allows us to develop new mechanisms which provide protection for users’ query privacy satisfying their requirements. Third, we address location privacy. Many location privacy preserving methods (LPPM) have been proposed to protect users’ location privacy. A user will make use of them to break the link between his identity and his locations when requesting LBSs. We propose a new attack on location privacy based on the adversary’s observation on users’ locations protected by LPPMs. Compared to existing attacks which target at where users went, our attack provides the adversary with sufficient information to infer what users did, i. e., their activities. Specifically, through our attack, the adversary learns the places where users performed activities and their beginning and ending time of each activity. To achieve this goal, we explore the patterns of users with respect to movements and requesting LBSs, i. e., user profiles...|$|R
40|$|With the {{emergence}} of cloud computing, outsourcing data services to cloud servers {{is becoming more and}} more prevalent. Along with this arise also security and privacy concerns. Particularly, it is an important concern to the user that the service provider itself may be malicious and breach the secrecy and privacy of users. Although encrypting data content has been a common practice, it does not relieve the concerns, because users data access pattern is not preserved and researchers have found that a wide range of private information could be conveniently revealed by observing the access pattern. It is, therefore, critical to investigate the problem of protecting users access pattern privacy in untrusted storage. Existing solutions that provide strict protection to the privacy of access pattern incur very high overhead, such as high bandwidth cost, long round-trip delay and/or large user side storage. The high overhead is a major barrier that hampers the adoption of these solutions in practice. Although strict protection of access pattern privacy is attractive, less strict protection, such as protecting the privacy of long-term access pattern, is also very useful in practice. Based on these considerations, we investigate the problem of protecting the long-term access pattern privacy in un-trusted storage and propose two light-weight schemes to preserve the privacy of long-term access pattern. We conduct rigorous proofs and extensive evaluations to demonstrate that the proposed schemes can hide the data access pattern in the long run, and the number of accesses required to preserve the access pattern privacy is reasonable in many situations. With outsourced data storage, keyword based query is a critical and primitive function for the users to access the data of their interest. Similar to access pattern, exposure of query pattern also leads to the leakage of sensitive information about the queried keyword and data. We show that without proper protection of both the query trapdoor and the access pattern, the query pattern may be exposed readily. Based on the framework of our access pattern privacy protection schemes, we propose a novel defense solution that <b>protects</b> the <b>query</b> privacy in a light-weight manner. One important benefit offered by cloud storage is its convenience for data sharing among multiple users. But when not all users are trusted, it is important to hold malicious users accountable for their misconduct. Due to conflicting goals of user accountability and access pattern privacy preservation, existing user accountability solutions cannot be readily integrated with ORAM constructions. As the last part of this dissertation, we investigate the problem of introducing support of user accountability into hash-based ORAM. We propose a scheme that can detect misconduct by malicious users and identify the attackers, while not interfering with the access pattern preservation mechanisms inherent from the underlying ORAM. Security and overhead analysis shows that the proposed scheme has achieved the design goals of providing accountability support to ORAM and preservation of data access pattern privacy, at the cost of slightly increased storage, communication, and computational overheads...|$|R
40|$|Applications of ontologies/knowledge bases (KBs) in many domains (healthcare, {{national}} security, intelligence) {{have become}} increasingly important. In this dissertation, we focus on developing techniques for answering queries posed to KBs under the open world assumption (OWA). In {{the first part of}} this dissertation, we study the problem of query answering in KBs that contain epistemic information, i. e., knowledge of different experts. We study ALCKm, which extends the description logic ALC by adding modal operators of the basic multi-modal logic Km. We develop a sound and complete tableau algorithm for answering ALCKm queries w. r. t. an ALCKm knowledge base with an acyclic TBox. We then consider answering ALCKm queries w. r. t. an ALCKm knowledge base in which the epistemic operators correspond to those of classical multi-modal logic S 4 m and provide a sound and complete tableau algorithm. Both algorithms can be implemented in PSpace. In the second part, we study problems that allow autonomous entities or organizations (collectively called querying agents) to be able to selectively share information. In this scenario, the KB must make sure its answers are informative but do not disclose sensitive information. Most of the work in this area has focused on access control mechanisms that prohibit access to sensitive information (secrets). However, such an approach can be too restrictive in that it prohibits the use of sensitive information in answering queries against knowledge bases even when it is possible to do so without compromising secrets. We investigate techniques for secrecy-preserving query answering (SPQA) against KBs under the OWA. We consider two scenarios of increasing difficulty: (a) a KB queried by a single agent; and (b) a KB queried by multiple agents where the secrecy policies can differ across the different agents and the agents can selectively communicate the answers that they receive from the KB with each other subject to the applicable answer sharing policies. We consider classes of KBs that are of interest from the standpoint of practical applications (e. g., description logics and Horn KBs). Given a KB and secrets that need to be <b>protected</b> against the <b>querying</b> agent(s), the SPQA problem aims at designing a secrecy-preserving reasoner that answers queries without compromising secrecy under OWA. Whenever truthfully answering a query risks compromising secrets, the reasoner is allowed to hide the answer to the query by feigning ignorance, i. e., answering the query as 2 ̆ 2 Unknown 2 ̆ 2. Under the OWA, the querying agent is not able to infer whether an 2 ̆ 2 Unknown 2 ̆ 2 answer to a query is obtained because of the incomplete information in the KB or because secrecy protection mechanism is being applied. In each scenario, we provide a general framework for the problem. In the single-agent case, we apply the general framework to the description logic EL and provide algorithms for answering queries as informatively as possible without compromising secrecy. In the multiagent case, we extend the general framework for the single-agent case. To model the communication between querying agents, we use a communication graph, a directed acyclic graph (DAG) with self-loops, where each node represents an agent and each edge represents the possibility of information sharing in the direction of the edge. We discuss the relationship between secrecy-preserving reasoners and envelopes (used to protect secrets) and present a special case of the communication graph that helps construct tight envelopes in the sense that removing any information from them will leave some secrets vulnerable. To illustrate our general idea of constructing envelopes, Horn KBs are considered...|$|R

