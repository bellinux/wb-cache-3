7056|5100|Public
5|$|Many {{recently}} developed SGDs include <b>performance</b> <b>measurement</b> and analysis tools to help monitor the content used by an individual. This raises concerns about privacy, and {{some argue that}} the device user {{should be involved in}} the decision to monitor use in this way. Similar concerns have been raised regarding the proposals for devices with automatic content generation, and privacy is increasingly a factor in design of SGDs. As AAC devices are designed to be used in all areas of a user’s life, there are sensitive legal, social, and technical issues centred on a wide family of personal data management problems that can be found in contexts of AAC use. For example, SGDs may have to be designed so that they support the user's right to delete logs of conversations or content that has been added automatically.|$|E
25|$|The {{theory of}} {{performance}} paradox {{is grounded in}} three characteristics of <b>performance</b> <b>measurement.</b> Firstly, there are many performance metrics, and the number continues to grow. Secondly, most measures of performance, even those that are used most frequently, exhibit little to no correlation with one another. And thirdly, the dominant performance measures at any given point in time change continuously.|$|E
25|$|In {{the context}} of {{investment}} <b>performance</b> <b>measurement,</b> there is sometimes ambiguity in terminology between the periodic rate of return, such as the {{internal rate of return}} as defined above, and a holding period return. The term internal rate of return or IRR or Since Inception Internal Rate of Return (SI-IRR) is in some contexts used to refer to the unannualized return over the period, particularly for periods of less than a year.|$|E
40|$|Abstract—There were {{extensive}} researches on {{the topic}} of performance management in various organizations across multiple fields. Literature on <b>performance</b> <b>measurements</b> in logistics can be divided into specific measures and their application in the context or complete framework for <b>performance</b> <b>measurements.</b> In this paper, the focus of the discussion will be the formulation of the framework which handles <b>performance</b> <b>measurements</b> for package delivery service and how the metrics measure the performance and their application in the context of package delivery service...|$|R
5000|$|With {{additional}} sensors, other <b>performance</b> <b>measurements</b> are available: ...|$|R
50|$|The {{control of}} the {{production}} (and other) processes is achieved by visual <b>performance</b> <b>measurements</b> at the shop-floor and value stream level. These measurements {{eliminate the need for}} the shop-floor tracking and variance reporting favored by traditional cost accounting systems. There are (at least) three levels of operational <b>performance</b> <b>measurements.</b>|$|R
25|$|Several other {{performance}} evaluation {{models in the}} academic literature also describe <b>performance</b> <b>measurement.</b> What distinguishes performance paradox from these other models is {{that they tend to}} restrict their scopes either to explanations for changing performance criteria or to endorsements of maximizing on a specific, defined set of static criteria. Performance paradox alone predicts that maximizing on a set of predictably shifting criteria generates positive outcomes for organizations, most accurately describing most actual organizations' behavior.|$|E
25|$|Performance appraisals present two strong {{benefits}} for organizations. First, reviewing an employee's performance {{in his or}} her responsibilities helps employers keep a consistent record of professional developments and recognize ways to improve an employee's productivity. Second, appraisals enable the relationships between managers, supervisors and their employees, to be based on open communication and consistent constructive criticism. As a result, many managers have emphasized the value of using different <b>performance</b> <b>measurement</b> systems based on either financial and operational measures of performance.|$|E
25|$|Nowadays Scotland {{is one of}} the world's biggest fund {{management}} centres {{with over}} £300bn worth of assets directly serviced or managed in the country. Scottish fund management centres have a major presence in areas such as pensions, property funds and investment trusts, as well as in retail and private client markets. Similarly asset servicing on behalf of fund managers has become an increasingly important component of the financial services industry in Scotland, with Scottish-based companies providing expertise in securities servicing, investment accounting, <b>performance</b> <b>measurement,</b> trustee and depositary services and treasury services.|$|E
50|$|End User Systems, and End To End <b>performance</b> <b>measurements.</b>|$|R
5000|$|Also, network <b>performance</b> <b>measurements</b> on the {{following}} were made: ...|$|R
5000|$|IEC 61400-12-1:2005 Power <b>performance</b> <b>measurements</b> of {{electricity}} producing wind turbines ...|$|R
25|$|Under {{the final}} of these models, the {{business}} model, as with the constituency model, there are several different metrics incorporated in <b>performance</b> <b>measurement.</b> However, whereas the different measures came from different competing factions under the constituency model – meaning that constituents prioritize between fulfilling the various measures and that the measures themselves {{are at odds with}} each other – these measures are generally sequential in nature (e.g., ensuring good product quality leads to a rise in the second metric of customer satisfaction, which improves the third measure of financial performance), with each considered as important to be maximized as the others. Again, as with the maximizing model, these measures are not expected to change.|$|E
25|$|Individuals and {{organizations}} have designed numerous ways to measure performance {{and continue to}} do so at an increasing rate. Evidence for this observation can be found by tracking changes in performance measures over time. In the 19th century, companies measured their performance via industry-specific output and cost measures, such as newspaper circulation. By the 1920s, companies also began utilizing accounting-based returns measures, such as return on investment. And the 1960s and 1970s saw the emergence of purely financial measures of performance relating information on dividends and return on equity. This dependence on performance measures has not diminished in recent years – on the contrary, the number of metrics that exist is growing at an even more accelerated rate. Today, in addition to financial measures, organizations examine nonfinancial metrics regarding leadership, information, planning, human resource utilization, and customer satisfaction. This proliferation in performance measurements has led to corresponding growth in the <b>performance</b> <b>measurement</b> industry – there has been a notable {{increase in the number of}} personnel {{and organizations}} devoted to examining performance-related metrics, such as certified public accountants and financial analysts.|$|E
2500|$|Bruce J. Feibel. Investment <b>Performance</b> <b>Measurement.</b> New York: Wiley, 2003.|$|E
5000|$|Physicians' {{voluntary}} {{engagement in}} <b>performance</b> <b>measurements</b> to continuously gauge quality improvement.|$|R
40|$|The {{supply chain}} is an {{important}} element in logistics development for all industries. It can improve efficiency and effectiveness of not only product transfer, but also information sharing between the complex hierarchy of all the tiers. There is no systematic grouping of the different performance measures in the existing literatures. This paper presents the formulisation of both quantitative and qualitative <b>performance</b> <b>measurements</b> for easy representation and understanding. Apart from the common criteria such as cost and quality, five other <b>performance</b> <b>measurements</b> are defined: resource utilisation; flexibility; visibility; trust; and innovativeness. In particular, new definitions are developed for visibility, trust, and innovativeness. Details of choices of these <b>performance</b> <b>measurements</b> are listed and suggested solutions are given, with the hope that a full picture of supply chain <b>performance</b> <b>measurements</b> is developed. In addition, a multi-attribute decision-making technique, an analytic hierarchy process (AHP), is used to make decisions based on the priority of performance measures. This paper outlines the application and particularly the pairwise comparison which helps to identify easily the importance of different <b>performance</b> <b>measurements.</b> An example from the electronic industry is used to demonstrate the AHP technique. link_to_subscribed_fulltex...|$|R
40|$|<b>Performance</b> <b>measurements</b> are an {{important}} part in the design of applications for High Performance Computing environments found in research or industry. For the op-timization of applications in these environments in-depth <b>performance</b> <b>measurements</b> are needed to achieve the optimum of optimization possible for a given computer architecture. PAPI is a framework for <b>performance</b> <b>measurements</b> based on <b>performance</b> counter registers found in modern computer architectures. Using PAPI developers and re-searchers can get an insight of the processor internal execution of applications and based on this feedback optimize applications. PAPI simplifies the task of <b>performance</b> <b>measurements</b> at this layers as it adapts to different platforms through backends called substrates. The Sun UltraSPARC T 2 processor, code named Niagara 2, is a computer architecture built for modern computing demands based on a thread-level parallelism approach using a direct mapping of software threads to up to 64 hardware threads executed o...|$|R
2500|$|In 1990 Art Schneiderman {{participated in}} an {{unrelated}} research study led by Robert S. Kaplan in conjunction with US management consultancy Nolan-Norton, and during this study described his work on <b>performance</b> <b>measurement.</b> [...] Subsequently, Kaplan and David P. Norton included anonymous details of this balanced scorecard design in a 1992 article. Kaplan and Norton's article wasn't the only paper on the topic published in early 1992 but the 1992 Kaplan and Norton paper was a popular success, and was quickly followed by a second in 1993. In 1996, the two authors published a book The Balanced Scorecard. [...] These articles and the first book spread knowledge {{of the concept of}} balanced scorecard widely, and has led to Kaplan and Norton being seen as the creators of the concept.|$|E
2500|$|Consideration {{has been}} given to the effect of {{organisation}} size on Balanced Scorecard effectiveness. [...] For large organisations this work has focused on how to translate aggregate corporate strategies into performance management tools relevant to individual teams / units within the organisation. [...] In SMEs, while Balanced Scorecard {{has been found to be}} effective, it is noted that focus is required on balancing design complexity and relevance with the availability of resource to do the design work. [...] Others have argued that the Balanced Scorecard is unsuitable for SMEs because of their lack of a longer-term strategic focus (Hvolby and Thorstenson (2000), McAdam (2000)), or the frequency of changes in the organisation’s strategy. [...] Others have suggested that SMEs have limited knowledge about <b>performance</b> <b>measurement</b> in general (Rantanen and Holtari 2000) and do not understand the beneﬁts of PMS implementation (McAdam 2000; Bourne 2001), but none of these studies attempts to theorise the reasons behind their ﬁndings.|$|E
2500|$|Critics {{claim that}} the on-time {{performance}} (OTP) calculated by the LIRR is manipulated to be artificially high. Because the LIRR does not release any raw timing data nor does it have independent (non-MTA) audits {{it is impossible to}} verify this claim, or the accuracy of the current On Time <b>Performance</b> <b>measurement.</b> The [...] "percentage" [...] measure is used by many other US passenger railroads but the criticism over accuracy is specific to the LIRR. As defined by the LIRR, a train is [...] "on time" [...] if it arrives at a station within 5 minutes and 59 seconds of the scheduled time. The criterion was 4 minutes and 59 seconds until the LIRR changed it because of a bug in their computer systems. Critics believe the OTP measure does not reflect what commuters experience on a daily basis. The LIRR publishes the current OTP in a monthly booklet called TrainTalk. TrainTalk was previously known as [...] "Keeping Track." ...|$|E
40|$|Detecting feature {{interactions}} {{is imperative}} for accurately predicting performance of highly-configurable systems. State-of-the-art performance prediction techniques rely on {{supervised machine learning}} for detecting feature interactions, which, in turn, relies on time consuming <b>performance</b> <b>measurements</b> to obtain training data. By providing information about potentially interacting features, we can {{reduce the number of}} required <b>performance</b> <b>measurements</b> and make the overall performance prediction process more time efficient. We expect that the information about potentially interacting features can be obtained by statically analyzing the source code of a highly-configurable system, which is computationally cheaper than performing multiple <b>performance</b> <b>measurements.</b> To this end, we conducted a qualitative case study in which we explored the relation between control-flow feature interactions (detected through static program analysis) and performance feature interactions (detected by performance prediction techniques using <b>performance</b> <b>measurements).</b> We found that a relation exists, which can potentially be exploited to predict performance interactions...|$|R
5000|$|Doesn’t {{consider}} {{the issue of}} <b>performance</b> <b>measurements,</b> which is vital for business modelling.|$|R
40|$|A {{model is}} {{developed}} for estimating {{the performance of}} a thermally adaptive application. The goal of this model is to allow a user to estimate the performance impact of adjusting the thermal budget allotted an application for a given thermal condition. The model is developed by applying a multiple linear regression approach to experimentally obtained <b>performance</b> <b>measurements.</b> The thermal conditions used during the collection of <b>performance</b> <b>measurements</b> were a small subset of the large number of possible thermal conditions. The model is validated by comparing the performance predicted by the model against a set of <b>performance</b> <b>measurements</b> obtained using thermal conditions not included in the regression data set...|$|R
2500|$|There {{is little}} {{reliable}} quantitative information available concerning {{the performance of}} Pakistani water and sewer utilities, including on their efficiency. The Asian Development Bank (ADB) prepared a document, which includes data for the cities of Rawalpindi, Karachi and Lahore. Furthermore, data from six major cities were reported during a 2005 workshop in Karachi. Beginning in 2005, the first systematic performance benchmarking for water and sewer utilities in Pakistan was initiated by the World Bank's Water and sanitation program {{as part of a}} regional project that also covered India and Bangladesh. Eight utilities participated, including five WASAs in Punjab as well as the utilities of Karachi, Peshawar and Islamabad. The benchmarking project found that data were not very reliable and that benchmarking was [...] "largely externally driven than internally motivated" [...] and that the organizational culture of utilities was [...] "often slow to accept <b>performance</b> <b>measurement,</b> accountability to customers and to government, and improved service outcomes." ...|$|E
2500|$|While the [...] "corporate scorecard" [...] {{terminology}} {{was coined}} by Art Schneiderman, {{the roots of}} performance management as an activity run deep in management literature and practice. [...] Management historians such as Alfred Chandler suggest the origins of performance management {{can be seen in}} the emergence of the complex organisation – most notably during the 19th Century in the USA. [...] More recent influences may include the pioneering work of General Electric on <b>performance</b> <b>measurement</b> reporting in the 1950s and the work of French process engineers (who created the tableau de bord – literally, a [...] "dashboard" [...] of performance measures) in the early part of the 20th century. [...] The tool also draws strongly on the ideas of the 'resource based view of the firm' proposed by Edith Penrose. [...] However it should be noted that none of these influences is explicitly linked to original descriptions of balanced scorecard by Schneiderman, Maisel, or Kaplan & Norton.|$|E
2500|$|There is no {{official}} Federal or State standard for response {{times in the}} United States. Response time standards frequently do exist {{in the form of}} contractual obligations between communities and EMS provider organizations, however. [...] As a result, there is typically considerable variation between standards in one community and another. [...] New York City, for example, mandates a 10-minute response time on emergency calls, while some communities in California have moved response time standards to 12–15 minutes. It is generally accepted within the field that an 'ideal' response time for emergency calls would be within eight minutes, ninety-percent of the time, but this objective is rarely achieved, and current research results question the validity of that standard. [...] As call volumes increase and resources and funding fail to keep pace, even large EMS systems such as Pittsburgh, Pennsylvania struggle to meet these standards. Individuals who live in rural areas far from emergency services also may expect a longer wait due to the distance involved. [...] This issue is further complicated by differing <b>performance</b> <b>measurement</b> methodologies. Some services count response time beginning at the moment that the telephone call is answered and running until an ambulance or response resource arrives at the scene, while others measure only the time from the notification of EMS personnel of the call, which is considerably shorter. [...] Another issue which arises in urban areas is that the response time 'clock' almost universally stops when the unit arrives in front of the address; in large office or apartment buildings, actually accessing the patient may take several minutes longer, but this is not considered in response time calculation or reporting.|$|E
40|$|Subject {{headings}} IP <b>performance</b> monitoring, active <b>measurements,</b> passive measurements, measurement tools, measurement platform. This publication {{gives an}} introduction to IP <b>performance</b> <b>measurements,</b> and {{is the result of}} work done in the PMM (Platform for <b>Performance</b> Monitoring and <b>Measurements)</b> project. <b>Performance</b> <b>measurements</b> are carried out to get information on important parameters, like delay, throughput, utilization, etc. These parameters are used as input network planning and dimensioning, SLA monitoring, traffic engineering, accounting, fault management and security management. The publication presents an overview of the actors involved, the uses of measurement data, some high level requirements, methods and tools, platforms for <b>performance</b> monitoring and <b>measurement,</b> relevant activities in standardization an...|$|R
50|$|More {{detailed}} <b>performance</b> <b>measurements</b> {{on modern}} processor architectures {{are given in}} the table below.|$|R
5000|$|Communication Bandwidth and Latency - MPI-centric <b>performance</b> <b>measurements</b> {{based on}} the b_eff bandwidth/latency benchmark.|$|R
5000|$|<b>Performance</b> <b>Measurement</b> and Reporting: Objectives {{and uses}} of <b>performance</b> <b>measurement</b> and reporting, elements, {{characteristics}} and other aspects. (15%) ...|$|E
5000|$|<b>Performance</b> <b>measurement</b> {{is not a}} new concept, {{but rather}} an old concept of renewed {{importance}} today. In 1943, the International City Management Association published an article on measuring the performance of municipal activities. During the Kennedy administration, systems analysis processes were introduced to the Department of Defense which fueled interest in <b>performance</b> <b>measurement</b> in the federal government. Other agencies began experimenting in <b>performance</b> <b>measurement</b> when the Johnson administration introduced what they called planning-programming-budgeting system (PPB). Eventually more and more state and local governments began using <b>performance</b> <b>measurement</b> to improve their management and budgeting. The use of <b>performance</b> <b>measurement</b> became a common practice in the 1970s with the introduction of new social programs that needed to be assessed. However, interest in <b>performance</b> <b>measurement</b> did dwindle in the 1980s, as people did not perceive benefits of using performance measurements in making decisions. In the 1990s, <b>performance</b> <b>measurement</b> was reenergized as the demands for holding government entities accountable to public increased. A number of resolutions were passed by associations such as the National Academy for Public Administration, urging government to set goals and measure their performance and in 1993, The Government Performance and Results Act was passed by the federal government requiring their agencies to become involved in strategic planning, goal-setting, and <b>performance</b> <b>measurement.</b>|$|E
50|$|A <b>performance</b> <b>measurement</b> {{period is}} {{determined}} by required confidence limits and may vary {{as a function of}} the observed parameter values. User time is divided into consecutive <b>performance</b> <b>measurement</b> periods to enable measurement of user information transfer reliability.|$|E
30|$|The CLT says that, {{even if a}} {{distribution}} of <b>performance</b> <b>measurements</b> is not normal, {{the distribution of the}} sample mean tends to a normal distribution as the sample size increases. For practical purposes, it is usually accepted that the resulting distribution is normally distributed when n ≥[*] 30 [30]. Experimenters often mistake distribution of <b>performance</b> <b>measurements</b> and distribution of sample means.|$|R
5000|$|For a [...] "starter set" [...] of lean {{performance}} measurements: Lean <b>Performance</b> <b>Measurements</b> Starter Set ...|$|R
50|$|Promotional {{reports were}} {{commissioned}} from the Enterprise Strategy Group in 2014 and 2015 including <b>performance</b> <b>measurements.</b>|$|R
