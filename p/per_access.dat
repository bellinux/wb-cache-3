108|402|Public
5000|$|Netscape Publishing System, {{for running}} a {{commercial}} site with news articles and charging users <b>per</b> <b>access</b> ...|$|E
50|$|Ingenu is {{a leading}} {{provider}} of machine-exclusive wireless networks via both the public Machine Network™ and also private networks for multiple vertical markets. Ingenu's networks are based on proprietary RPMA (Random Phase Multiple Access) technology which allow for greater coverage <b>per</b> <b>access</b> point, more robust communication technology, and industry leading network longevity. Ingenu focuses on machine to machine (M2M) communication by enabling devices to become Internet of Things (IoT) devices. Ingenu provides the entire stack of wireless connectivity, including RPMA radio modules, RPMA wireless access points, and other associated hardware and software.|$|E
5000|$|The scheme abused a [...] "containment" [...] {{feature of}} a Wi-Fi {{monitoring}} system {{which was designed}} for the nominally lawful purpose of removing unwanted [...] "rogue access points" [...] from corporations' own local area networks. Marriott misused the system to send spurious de-authentication packets to client-owned wireless access points, which is unlawful as these {{are not part of}} Marriott's network but are owned by individual mobile subscribers. The fraudulent packets, which dissociate consumers’ devices from their own Wi-Fi hotspot access points, were sent deliberately as a means to force convention-goers to buy wireless Internet access from the hotel at rates from $250-1000 <b>per</b> <b>access</b> point.|$|E
2500|$|DDR SDRAM's {{prefetch}} {{buffer size}} is 2n (two datawords <b>per</b> memory <b>access)</b> ...|$|R
2500|$|DDR2 SDRAM's {{prefetch}} {{buffer size}} is 4n (four datawords <b>per</b> memory <b>access)</b> ...|$|R
2500|$|DDR3 SDRAM's {{prefetch}} {{buffer size}} is 8n (eight datawords <b>per</b> memory <b>access)</b> ...|$|R
50|$|With stack machines, in contrast, {{results can}} be stored in one of two ways: A {{temporary}} variable in memory. Storing and subsequent retrievals cost additional instructions and additional data cache cycles. Doing this is only a win if the subexpression computation costs more in time than fetching from memory, which in most stack CPUs, almost always is the case. It is never worthwhile for simple variables and pointer fetches, because those already have the same cost of one data cache cycle <b>per</b> <b>access.</b> It is only marginally worthwhile for expressions like X+1. These simpler expressions make up the majority of redundant, optimizable expressions in programs written in non-concatenative languages. An optimizing compiler can only win on redundancies that the programmer could have avoided in the source code.|$|E
50|$|Since {{the passage}} of the federal Americans with Disabilities Act, {{disability}} access violations count among the practices that run afoul of the Unruh act. Combined with the California Disabled Persons Acts, disability access plaintiffs are allowed to tack on state claims for money damages onto requests for injunctive relief in ADA lawsuits. The act allows plaintiffs to claim treble damages with a minimum of $4000 <b>per</b> <b>access</b> violation plus attorneys fees. In most states, plaintiffs are entitled to only injunctive relief, having the disability access issue fixed. As a result of the damages claimed under Unruh Act, California accounts for 42% of all ADA litigation nationwide. However, in California, damages may be reduced in certain cases to $2,000 or $1,000 if construction related accessibility violations are corrected within 30-60 days of being served with a complaint.|$|E
50|$|Since {{launching}} its fiber to {{the home}} service FiOS, industry insiders and experts have noted that Verizon has neglected its copper local loop infrastructure footprint-wide, including in areas yet to receive FiOS. Verizon's copper network maintenance and upgrade budget (which includes DSL and POTS services) {{was estimated to be}} roughly $3.50 <b>per</b> <b>access</b> line by the Communications Workers of America. The CWA filed a letter of concern with 11 public utility regulators regarding Verizon's lack of concern for the copper local loop and associated infrastructure. Rural communities in New Jersey filed a joint petition of complaint with the NJ Board of Public Utilities in order to investigate Verizon's apparent discontinuation of copper local loop maintenance; issues reported by the towns residents include loss of service during poor weather, static on the line, lack of audible voice transmission, and interruption or loss of DSL service.|$|E
5000|$|DDR SDRAM's {{prefetch}} {{buffer size}} is 2n (two datawords <b>per</b> memory <b>access)</b> ...|$|R
5000|$|DDR2 SDRAM's {{prefetch}} {{buffer size}} is 4n (four datawords <b>per</b> memory <b>access)</b> ...|$|R
5000|$|DDR3 SDRAM's {{prefetch}} {{buffer size}} is 8n (eight datawords <b>per</b> memory <b>access)</b> ...|$|R
5000|$|... 1T SRAM {{is built}} as {{an array of}} small banks (typically 128 rows × 256 bits/row, 32 kilobits in total) coupled to a bank-sized SRAM cache and an {{intelligent}} controller. Although space-inefficient compared to regular DRAM, the short word lines allow much higher speeds, so the array can do a full sense and precharge (RAS cycle) <b>per</b> <b>access,</b> providing high-speed random access. Each access is to one bank, allowing unused banks to be refreshed at the same time. Additionally, each row read out of the active bank is copied to the bank-sized SRAM cache. In the event of repeated accesses to one bank, which would not allow time for refresh cycles, there are two options: either the accesses are all to different rows, in which case all rows will be refreshed automatically, or some rows are accessed repeatedly. In the latter case, the cache provides the data and allows time for an unused row of the active bank to be refreshed.|$|E
5000|$|All {{access to}} the system is via a few basic methods that can store or {{retrieve}} in order one variable-length 'Item' or 'tuple' at a time at a speed {{which is on the}} order of 1M operations/second aggregated over multiple threads when in memory. The operations are either the standard Map API for get (...) , put (...) , iterators, and so on, or at the lower level, insert (...) , delete (...) , update (...) , first (...) , next (...) , last (...) , and previous (...) [...] Typical Items are about 30 bytes uncompressed in memory, but LOB's for example use 1KB Items. Because each operation affects only one Item, small data structures are fast to access. This is in contrast to chunked access, such as for example formatting and parsing entire JSON or XML texts or entire Java Object serialization graphs. The space and performance scaling of an ItemSpace is smooth as any size of client-imposed multi-Item structure is created, grows, shrinks, or disappears. On-storage performance is like any block-oriented B-Tree, with blocks of about 4KB, which is O(log(n)) <b>per</b> <b>access.</b> There is a block cache of 2.5MB by default, which is of unlimited size but which is often about 100MB. The cache grows only as needed.|$|E
40|$|In certain {{data base}} {{organization}} schemes the cost <b>per</b> <b>access</b> may increase due to structural inefficiencies caused by updates. By reorganizing the data base the cost <b>per</b> <b>access</b> may be reduced. However, {{the high cost}} of a reorganization prohibits frequent reorganizations. This paper examines strategies for selecting the optimum reorganization points. Key Words and Phrases: data base, reorganization, files, information retrieva...|$|E
5000|$|... {{two free}} return {{journeys}} for islanders {{to visit the}} mainland <b>per</b> year (<b>access</b> via vouchers sent to cardholders).|$|R
50|$|Liberdade {{is served}} by the São Paulo Metro (Liberdade Station), a station on Line 1 (Blue). The station opened in 1975 and {{receives}} 21,000 passengers <b>per</b> day. <b>Access</b> to the station is via Praça da Liberdade.|$|R
5000|$|Multiple {{arithmetic}} units {{may require}} memory architectures to support several <b>accesses</b> <b>per</b> instruction cycle ...|$|R
40|$|Require {{only one}} [secondary] {{containment}} access door <b>per</b> <b>access</b> opening to be closed. Justification: NLJREG- 1433 SR 3. 6. 4. 1. 3 has been modified to only require one secondary containment access door <b>per</b> <b>access</b> opening to be closed. This {{is consistent with}} the intent of NUREG- 1434 (BWR/ 6 STS) since the BWRI 6 secondary containment design only includes one door <b>per</b> <b>access</b> opening. The BWR/ 2 - 5 designs normally include two doors <b>per</b> <b>access</b> opening. Verifying tat one door in each access opening is closed ensures that the infiltration of outside air of such a magnitude as to prevent maintaining the desired negative pressure does not occur. The Bases is modified to include a bracketed insert to provide additional description for those plants, which have airlocks with multiple inner or outer doors. The Bases will also be modified to state that the normal condition of the plant is to keep both doors closed, except during entry and exit or when maintenance is being performed on the access. The Bases description is consistent with flx BWR/ 2 - 5 practice. NUREG- 1434 SR 3. 6. 4. 1. 3 has also been modified to allow the one door option, similar to that described above fo...|$|E
40|$|We {{introduce}} {{the concept of}} energy per operation {{as a measure of}} performance of an asynchronous circuit. We show how to model energy consumption based on the high-level language specification. This model is independent of voltage and timing considerations. We apply this model to memory design. We show first how to dimension a memory array, and how to break up this memory array into smaller arrays to minimize the energy <b>per</b> <b>access.</b> We then show how to use cache memory and pre-fetch mechanisms to further reduce energy <b>per</b> <b>access...</b>|$|E
3000|$|... 3 CACTI 6.5 is an {{analytical}} tool {{that takes a}} set of SPM, cache, or DRAM parameters as inputs and calculates memory data – like access time, static power, dynamic energy spent <b>per</b> <b>access,</b> and area [28].|$|E
5000|$|Two hours {{internet}} <b>access</b> <b>per</b> day per membership account (additional {{time can}} be requested) ...|$|R
25|$|Under an {{assumption}} of homogeneity, {{the number of}} times a web server is <b>accessed</b> <b>per</b> minute.|$|R
5000|$|March 15 2006 - Niki Westerberg, press {{secretary}} of the Liberal Party, informs party secretary Johan Jakobsson that she thinks <b>Per</b> Jodenius has <b>access</b> to the Social Democrats' intranet. Jakobsson says he told Jodenius to reveal it to a reporter and stop the illegal <b>access.</b> <b>Per</b> Jodenius contacts Niklas Svensson on Expressen who does not reveal the story, but uses the log-in himself instead.|$|R
30|$|User <b>Per</b> <b>Access</b> Load: We {{investigate}} how {{the number of}} intruding users influences the detection rate. We select a set of users to inject three intruding accesses into. We perform this analysis over the range of 2 to 20 intruding users.|$|E
40|$|The {{concept of}} stack distance, {{applicable}} to the important class of inclusion replacement policies for the memory hierarchy, enables to efficiently compute the number of misses incurred on a given address trace, for all cache sizes. The concept was introduced by Mattson, Gecsei, Sluts, and Traiger (Evaluation techniques for storage hierarchies, IBM System Journal, (9) 2 : 78 - 117, 1970), together with a Linear-Scan algorithm, which takes time O(V) <b>per</b> <b>access,</b> in the worst case, where V {{is the number of}} distinct (virtual) items referenced within the trace. While subsequent work has lowered the time bound to O(log V) <b>per</b> <b>access</b> in the special case of the Least Recently Used policy, no improvements have been obtained for the general case. This work introduces a class of inclusion policies called policies with nearly static priorities, which encompasses several of the policies considered in the literature. The Min-Tree algorithm is proposed for these policies. The performance of the Min-Tree algorithm is very sensitive to the replacement policy {{as well as to the}} address trace. Under suitable probabilistic assumptions, the expected time <b>per</b> <b>access</b> is O(log 2 V). Experimental evidence collected on a mix of benchmarks shows that the Min-Tree algorithm is significantly faster than Linear-Scan, for interesting policies such as OPT (or Belady), Least Frequently Used (LFU), and Most Recently Used (MRU). As a further advantage, Min-Tree can be parallelized to run in time O(log V) using O(V/log V) processors, in the worst case. A more sophisticated Lazy Min-Tree algorithm is also developed which achieves O(v log V) worst-case time <b>per</b> <b>access.</b> This bound applies, in particular, to the policies OPT, LFU, and Least Recently/Frequently Used (LRFU), for which the best previously known bound was O(V) ...|$|E
3000|$|... d, where a and b are the {{fraction}} {{increase of the}} voice and data backhaul bitrate <b>per</b> <b>access</b> network connection due to the backhaul overhead, respectively. If compression schemes are implemented, then the required backhaul bitrate may not increase linearly {{with the number of}} connections, as assumed in [19].|$|E
40|$|In this paper, standard-cell based {{memories}} (SCMs) {{are proposed}} {{as an alternative}} to full-custom sub-VT SRAM macros for ultra-low-power systems requiring small memory blocks. The energy <b>per</b> memory <b>access</b> as well as the maximum achievable throughput in the sub-VT domain of various SCM architectures are evaluated by means of a gate-level sub-VT characterization model, building on data extracted from fully placed, routed, and back-annotated netlists. The reliable operation at the energy-minimum voltage of the various SCM architectures in a 65 -nm CMOS technology considering within-die process parameter variations is demonstrated by means of Monte Carlo circuit simulation. Finally, the energy <b>per</b> memory <b>access,</b> the achievable throughput, and the area of the best SCM architecture are compared to recent sub-VT SRAM designs...|$|R
50|$|If a TLB hit takes 1 clock cycle, a miss takes 30 clock cycles, and {{the miss}} rate is 1%, the {{effective}} memory cycle rate is {{an average of}} 1 × 0.99 + (1 + 30) × 0.01 = 1.30 (1.30 clock cycles <b>per</b> memory <b>access).</b>|$|R
50|$|Liberdade (Portuguese: Estação Liberdade) is {{a station}} on Line 1 (Blue) of the São Paulo Metro, serving the Liberdade district. The station opened in 1975 and {{receives}} 21,000 passengers <b>per</b> day. <b>Access</b> {{to the station}} is via Praça da Liberdade, {{the center of the}} historically Japanese-Brazilian neighborhood.|$|R
40|$|Abstract. Trace caches {{deliver a}} high number of {{instructions}} per cycle to wide-issue superscalar processors. To overcome complex control flow, multiple branch predictors have to predict up to 3 conditional branches per cycle. These multiple branch predictors sometimes predict completely wrong paths of execution, degrading the average fetch bandwidth. This paper shows that such mispredictions can be detected by monitoring trace cache misses. Based on this observation, a new technique called trace substitution is introduced. On a trace cache miss, trace substitution overrides the predicted trace with a cached trace. If the substitution is correct, the fetch bandwidth increases. We show that trace substitution consistently improves the fetch bandwidth with 0. 2 instructions <b>per</b> <b>access.</b> For inaccurate predictors, trace substitution can increase the fetch bandwidth with up to 2 instructions <b>per</b> <b>access.</b> ...|$|E
40|$|DAシンポジウム 2008 : システムLSI設計技術とDA : 2008 年 8 月 26 日(火) - 27 日(水) : 静岡本稿では，組込みシステムにおけるメモリシステムの消費エネルギー削減を目的として，一回あたりのアクセスエネルギーが不均一な二種類のキャッシュメモリを持つキャッシュアーキテクチャを提案する．提案アーキテクチャはアドレス空間を二種類の領域に分割する．一つの領域をMulti-Cache 領域といい，両方のキャッシュメモリを利用できる．もう一つの領域をSingle-Cache 領域といい，アクセスエネルギーが大きいキャッシュメモリのみ利用できる．アクセス頻度が高いコード／データをMulti-Cache 領域に配置することでメモリシステムの消費エネルギーを削減する．例を用いた評価では実行サイクル数の悪化なく約 35 %のエネルギーを削減できた．This paper {{proposes a}} cache {{architecture}} for energy efficient embedded systems. The cache architecture has two non-uniform cache memories, small cache and normal cache, {{in terms of}} the energy consumption <b>per</b> <b>access.</b> The cache architecture partitions address spaces into two regions. One is Multi-Cache region allowed to use the both of cache memories. The other is Single-Cache region allowed to use only normal cache memory which consumes larger energy <b>per</b> <b>access.</b> The energy of memory subsystems can be reduced through assigning frequently accessed code/data into Multi-Cache region. Evaluation using a simple example demonstrated that the proposed architecture reduced the energy consumption of memory subsystem approximately 35 % with no performance overhead...|$|E
40|$|Trace caches {{deliver a}} high number of {{instructions}} per cycle to wide-issue superscalar processors. To overcome complex control flow, multiple branch predictors have to predict up to 3 conditional branches per cycle. These multiple branch predictors sometimes predict completely wrong paths of execution, degrading the average fetch bandwidth. This paper shows that such mispredictions can be detected by monitoring trace cache misses. Based on this observation, a new technique called trace substitution is introduced. On a trace cache miss, trace substitution overrides the predicted trace with a cached trace. If the substitution is correct, the fetch bandwidth increases. We show that trace substitution consistently improves the fetch bandwidth with 0. 2 instructions <b>per</b> <b>access.</b> For inaccurate predictors, trace substitution can increase the fetch bandwidth with up to 2 instructions <b>per</b> <b>access...</b>|$|E
25|$|The default {{distribution}} {{does not}} provide root <b>access</b> <b>per</b> default, {{but it is possible}} to install a root terminal through the software manager.|$|R
50|$|In Israel, Gilat Satellite Networks {{provides}} multi-gigabit <b>per</b> second broadband <b>access</b> {{to consumers}} {{and the defense}} industry by means of High throughput satellites.|$|R
50|$|The default {{distribution}} {{does not}} provide root <b>access</b> <b>per</b> default, {{but it is possible}} to install a root terminal through the software manager.|$|R
