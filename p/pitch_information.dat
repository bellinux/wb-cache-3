231|125|Public
25|$|Studies {{suggest that}} the {{analysis}} of pitch is primarily controlled by the right temporal region of the brain. The right secondary auditory cortex processes pitch change and manipulation of fine tunes; specifically, this region distinguishes the multiple pitches that characterize melodic tunes as contour (pitch direction) and interval (frequency ratio between successive notes) information. The right superior temporal gyrus recruits and evaluates contour information, while both right and left temporal regions recruit and evaluate interval information. In addition, the right anterolateral part of Heschl's gyrus (primary auditory cortex) is also concerned with processing <b>pitch</b> <b>information.</b>|$|E
2500|$|... {{has shown}} that {{short-term}} memory for the pitch of a tone is subject to highly specific effects produced by other tones, which depend on the pitch relationship between the interfering tones and the tone to be remembered. It appears, therefore, that memory for pitch is the function of a highly organized system that specifically retains <b>pitch</b> <b>information.</b>|$|E
5000|$|Three {{non-rotating}} {{control rods}} transmit <b>pitch</b> <b>information</b> {{to the lower}} swashplate ...|$|E
40|$|Our key finding system {{consists}} {{of a series of}} O(n) realtime algorithms for determining key from polyphonic audio. The system comprises of two main parts as shown in Figure 1 [1]. The first part (the upper dashed box) generates <b>pitch</b> class <b>information</b> from audio using the standard FFT and a fuzzy analysis technique. The second component (the lower dashed box) uses the <b>pitch</b> class <b>information</b> to determine the key using Chew’s Spiral Array model and Center of Effect Generator (CEG) key finding algorithm [2, 3]. A cleanup procedure uses key information to clarify the inpu...|$|R
40|$|An {{apparatus}} {{for processing}} an audio signal having associated therewith a <b>pitch</b> lag <b>information</b> and a gain information, comprises a domain converter (100) for converting a first domain epresentation of the audio signal {{into a second}} domain representation of the audio signal; and a harmonic post-filter (104) for filtering the second domain representation of the audio signal, wherein the post-filter {{is based on a}} transfer function comprising a numerator and a denominator, wherein the numerator comprises a gain value indicated by the gain information, and wherein the denominator comprises an integer part of a pitch lag indicated by the <b>pitch</b> lag <b>information</b> and a multi-tap filter depending on a fractional part of the pitch la...|$|R
40|$|This paper {{describes}} our submitted {{method for}} MIREX 2009 audio tag classification task. We extract features to capture different musical information aspects, including dynamics, rhythm, timbre, <b>pitch,</b> tonal <b>information.</b> An ensemble classifier for each tag is exploited to predict on the testing music clips. 1...|$|R
50|$|The hydrostat is a {{mechanism}} that senses pressure; the torpedo's depth {{is proportional to}} pressure. However, with only a hydrostat controlling the depth fins, the torpedo tends to oscillate around the desired depth rather than settling to the desired depth. The addition of a pendulum allows the torpedo to sense the pitch of the torpedo. The <b>pitch</b> <b>information</b> is combined with the depth information to set the torpedo's depth control fins. The <b>pitch</b> <b>information</b> provides a damping term to the depth control response and suppresses the depth oscillations.|$|E
50|$|Spatial {{hearing loss}} can be {{diagnosed}} using the Listening in Spatialized Noise - Sentences test (LiSN-S), {{which was designed}} to assess the ability of children with central auditory processing disorder (CAPD) to understand speech in background noise. The LiSN-S allows audiologists to measure how well a person uses spatial (and <b>pitch</b> <b>information)</b> to understand speech in noise. Inability to use spatial information {{has been found to be}} a leading cause of CAPD in children.|$|E
50|$|Studies {{suggest that}} the {{analysis}} of pitch is primarily controlled by the right temporal region of the brain. The right secondary auditory cortex processes pitch change and manipulation of fine tunes; specifically, this region distinguishes the multiple pitches that characterize melodic tunes as contour (pitch direction) and interval (frequency ratio between successive notes) information. The right superior temporal gyrus recruits and evaluates contour information, while both right and left temporal regions recruit and evaluate interval information. In addition, the right anterolateral part of Heschl's gyrus (primary auditory cortex) is also concerned with processing <b>pitch</b> <b>information.</b>|$|E
50|$|The Collaboratory {{is not a}} {{place for}} {{political}} debate, but is a place for <b>pitching</b> ideas and <b>information</b> with legitimate scientific backing that inform adaptation decisions.|$|R
5|$|Furthermore, Peterson, who {{had failed}} an {{instrument}} checkride nine {{months before the}} accident, had received his instrument training on airplanes equipped with a conventional artificial horizon as source of aircraft attitude information, while N3794N was equipped with an older-type Sperry F3 attitude gyroscope. Crucially, {{the two types of}} instruments display the same aircraft <b>pitch</b> attitude <b>information</b> in graphically opposite ways.|$|R
30|$|The system {{described}} in this paper attempts to separate solo instruments from music accompaniment in polyphonic music using <b>pitch</b> as prior <b>information.</b> This approach will {{be referred to as}} pitch-informed solo/accompaniment separation.|$|R
50|$|Feedback {{interactions}} are particularly relevant in playing an instrument {{such as a}} violin, or in singing, where pitch is variable and must be continuously controlled. If auditory feedback is blocked, musicians can still execute well-rehearsed pieces, but expressive aspects of performance are affected. When auditory feedback is experimentally manipulated by delays or distortions, motor performance is significantly altered: asynchronous feedback disrupts the timing of events, whereas alteration of <b>pitch</b> <b>information</b> disrupts the selection of appropriate actions, but not their timing. This suggests that disruptions occur because both actions and percepts depend on a single underlying mental representation.|$|E
5000|$|It is {{important}} to note that music unfolds over time, thus the [...] "auditory cognitive system must depend to a large degree on mechanisms that allow a stimulus to be maintained on-line to be able to relate one element in a sequence to another that occurs later" [...] (Peretz 2005). Research has shown that working memory mechanisms for <b>pitch</b> <b>information</b> over a short period of time may be different from those involved in speech. In addition to the role that auditory cortices play in working memory for music, neuroimaging and lesion studies prove that frontal cortical areas also play an important role.|$|E
5000|$|When {{it comes}} to memory for pitch, {{there appears to be}} a dynamic and {{distributed}} brain network subserves pitch memory processes. Gaab, Gaser, Zaehle, Jancke and Schlaug (2003) examined the functional anatomy of pitch memory using functional magnetic resonance imaging (fMRI). [...] An analysis of performance scores in a pitch memory task resulted in a significant correlation between good task performance and the supramarginal gyrus (SMG) as well as the dorsolateral cerebellum. Findings indicate that the dorsolateral cerebellum may act as a pitch discrimination processor and the SMG may act as a short-term <b>pitch</b> <b>information</b> storage site. The left hemisphere was found to be more prominent in the pitch memory task than the right hemispheric regions.|$|E
30|$|In this work, {{we propose}} two {{modifications}} of Mixdorff’s automatic method of parameter model extraction. One modification {{is related to}} the construction of a prototype for initialization, and the second modification is related to eliminate restrictions in model parameter values. The prototypes will be built from lexical stress or <b>pitch</b> accent <b>information.</b> They will be herein called lexically motivated or L-ME method, and tonally motivated or T-ME method.|$|R
500|$|... "John" [...] or [...] "John the {{bookmaker}}" [...] is {{the name}} given to an Indian bookmaker who in 1994–95 gave money to Australian cricketers Mark Waugh and Shane Warne, in return for <b>pitch</b> and weather <b>information.</b>|$|R
40|$|This paper {{presents}} a multi-modal approach to automat- Guitar ically identifying guitar chords using {{audio and video}} of the performer. Chord identification is typically performed Guitar by analyzing the audio, using a chroma based feature toGuitar extract <b>pitch</b> class <b>information,</b> then identifying the chordGuitar with the appropriate label. Even if this method proves perfectly accurate, stringed instruments add extra ambiguityGuitar as a single chord or melody may be played in differentGuitar positions on the fretboard. Preserving this information i...|$|R
50|$|Music {{training}} {{leads to}} superior understanding of speech in noise across age groups and musical experience protects against age-related degradation in neural timing. Unlike speech (fast temporal information), music (<b>pitch</b> <b>information)</b> is primarily processed by {{areas of the}} brain in the right hemisphere. Given that {{it seems likely that the}} right ear advantage (REA) for speech is present from birth, it would follow that a left ear advantage for music is also present from birth and that MOC efferent inhibition (of the right ear) plays a similar role in creating this advantage. Does greater exposure to music increase conscious control of cochlear gain and inhibition? Further research is needed to explore the apparent ability of music to promote an enhanced capability of speech in noise recognition.|$|E
5000|$|Cyclic {{controls}} {{are used to}} change a helicopter's roll and pitch. Push rods or hydraulic actuators tilt the outer swashplate {{in response to the}} pilot's commands. The swashplate moves in the intuitively expected direction, tilting forwards to respond to a forward input, for instance. However [...] "pitch links" [...] on the blades transmit the <b>pitch</b> <b>information</b> way ahead of the blade's actual position, giving the blades time to [...] "fly up" [...] or [...] "fly down" [...] to reach the desired position. That is, to tilt the helicopter forward, the difference of lift around the blades should be maximum along the left-right plane, creating a torque that, due to the gyroscopic effect, will tilt the rotor disc forward and not sideways.|$|E
50|$|Interference {{occurs when}} {{information}} in short-term memory interferes with or obstructs the retrieval of other information. Some {{researchers believe that}} interference in memory for pitch {{is due to a}} general limited capacity of the short-term memory system, regardless of the type of information that it retains. However, Deutsch has shown that memory for pitch is subject to interference based on the presentation of other pitches but not by the presentation of spoken numbers. Further workhas shown that short-term memory for the pitch of a tone is subject to highly specific effects produced by other tones, which depend on the pitch relationship between the interfering tones and the tone to be remembered. It appears, therefore, that memory for pitch is the function of a highly organized system that specifically retains <b>pitch</b> <b>information.</b>|$|E
50|$|The neurons of {{the primary}} {{auditory}} cortex can be considered to have receptive fields covering a range of auditory frequencies and have selective responses to harmonic <b>pitches.</b> Neurons integrating <b>information</b> from the two ears have receptive fields covering a particular region of auditory space.|$|R
40|$|To date, {{research}} exploring {{experiences of}} diagnosing autism spectrum disorder (ASD) has largely focused on parental perspectives. In {{order to obtain}} a more complete account of the ASD diagnostic process, {{it is essential that}} the views and experiences of professionals are heard. In the current study, 116 multidisciplinary professionals involved in diagnosing ASD in the United Kingdom completed an online questionnaire exploring their experiences and opinions of three key areas of service: accessibility; the diagnostic process; and postdiagnostic support. Although professionals were largely satisfied with service accessibility, around 40 % of services were failing to provide timely assessments. Standardised diagnostic tools were perceived as helpful and were used consistently, but concerns were raised about their validity in detecting atypical ASD presentations (e. g., females). Several challenges regarding giving ASD diagnoses were reported; these included making sure caregivers understood the diagnosis, <b>pitching</b> <b>information</b> at the correct level, and managing distress. Further, the practice of ‘upgrading’ to a diagnosis of ASD in uncertain or complex cases was reported by many, albeit infrequently, and reasons for this varied widely. Professionals expressed dissatisfaction with post-diagnostic provision, especially onward and long-term support options. They also felt that service improvements were required across populations and across the three key areas of service...|$|R
3000|$|Case 2 {{requires}} the <b>pitch</b> and voiced-unvoiced <b>information.</b> We used SPTK- 3.0 [14] with default parameters to obtain this data. Case 4 requires estimating the noise spectrum. In this experiment, the noise spectrum was continuously updated within the noise segments based on oracle VAD information as [...]...|$|R
50|$|Additional {{studies of}} change {{deafness}} have generated {{evidence in support}} of the prediction that undetected changes are successfully encoded at the sensory level in the auditory cortex, but do not trigger later change-related cortical responses that would produce conscious perception of change. EEG analysis during a change-detection task using changes in pitch revealed that responses previously shown to be involved with sensory extraction of <b>pitch</b> <b>information</b> increased during both detected and undetected pitch changes in auditory input, however only in cases where the pitch change was detected were later processing stages triggered, originating from hierarchically higher non-sensory brain regions. These findings suggest that change deafness does not arise from a deficit in initial sensory encoding of changed stimulus features in auditory cortex but occurs at a higher level of stimulus processing in auditory cortex, resulting in a failure to trigger auditory change detection mechanisms.|$|E
5000|$|The first [...] "commercial development" [...] {{automatic}} landings (as {{opposed to}} pure experimentation) were achieved through realising that the vertical and lateral paths had different [...] "rules". Although the localiser signal would be present throughout the landing, the glide slope {{had to be}} disregarded before touchdown in any event. It was recognised that if the aircraft had arrived at Decision Height (200 ft) on a correct, stable approach path - a prerequisite for a safe landing - it would have momentum along that path. Consequently, the autoland system could discard the glideslope information when it became unreliable (i.e. at 200 ft), and use of <b>pitch</b> <b>information</b> derived from the last several seconds of flight would ensure to the required degree of reliability that the descent rate (and hence adherence to the correct profile) would remain constant. This [...] "ballistic" [...] phase would end at the height when it became necessary to increase pitch and reduce power to enter the landing flare. The pitch change occurs over the runway in the 1000 horizontal feet between the threshold and the glide slope antenna, and so can be accurately triggered by radio altimeter.|$|E
40|$|This paper {{describes}} {{security of}} speaker verification systems against imposture using synthetic speech. We propose a text-prompted speaker verification technique which utilizes <b>pitch</b> <b>information</b> {{in addition to}} spectral information, and investigate whether synthetic speech is rejected. Experimental results show that <b>pitch</b> <b>information</b> is not necessarily useful for rejection of synthetic speech, and it is required to develop techniques to discriminate synthetic speech from natural speech...|$|E
40|$|Query-by-Humming {{involves}} retrieving {{music with}} a melody that matches the hummed query. An improved Query-by-Humming system for extracting <b>pitch</b> contour <b>information</b> based on a fuzzy inference model is introduced. In addition, an improved content-based music repeating pattern extraction model is introduced. Our bar-indexing method can extract the melody, identify repeating patterns and handle polyphonic MIDI files. To verify {{the effectiveness of the}} system, 15 volunteers recorded queries that were fed as input to the system and the longest common subsequence (LCS) was used to identify the most related top N matches. The system achieves 70 % accuracy among the top 5 items retrieved...|$|R
50|$|While the {{inconsistent}} airspeed data {{caused the}} disengagement of the autopilot, {{the reason the}} pilots {{lost control of the}} aircraft remains something of a mystery, in particular because pilots would normally try to lower the nose in case of a stall. Multiple sensors provide the <b>pitch</b> (attitude) <b>information</b> and there was no indication that any of them were malfunctioning. One factor may be that since the A330 does not normally accept control inputs that would cause a stall, the pilots were unaware that a stall could happen when the aircraft switched to an alternate mode due to failure of the airspeed indication.|$|R
50|$|In all variants, the {{aircraft}} gyro system provides <b>pitch</b> and roll <b>information</b> for the processor, which drives the projection system {{to keep the}} line parallel to the earth horizon. The subliminal effect on the pilot's peripheral vision aids them in retaining attitude awareness and quickly correcting the onset of {{the aircraft}} deviating from the desired attitude.|$|R
40|$|Abstract. In this paper, the {{performance}} of the pitch detection algorithm in ETSI ES- 202 - 212 XAFE standard is evaluated on a Mandarin digit string recognition task. Experimental results showed that {{the performance}} of the pitch detection algorithm degraded seriously when the SNR of speech signal was lower than 10 dB. This makes the recognizer using <b>pitch</b> <b>information</b> perform inferior to the original recognizer without using <b>pitch</b> <b>information</b> in low SNR environments. A modification of the pitch detection algorithm is therefore proposed to improve {{the performance of}} pitch detection in low SNR environments. The recognition performance can be improved for most SNR levels by integrating the recognizers with and without using <b>pitch</b> <b>information.</b> Overall recognition rates of 82. 1 % and 86. 8 % were achieved for clean and multi-condition training cases. Keywords: distributed speech recognition, Extended Advanced Front-end, tonal language speech recognition...|$|E
40|$|Amplitude modulations of pulsitile {{stimulation}} {{can be used}} {{to convey}} <b>pitch</b> <b>information</b> to cochlear implant users. One variable in designing cochlear implant speech processors is the choice of modulation waveform used to convey <b>pitch</b> <b>information.</b> Modulation frequency discrimination thresholds were measured for 100 Hz modulations with four waveforms (sine, sawtooth, a sharpened sawtooth, and square). Just-noticeable differences (JNDs) were similar for all but the square waveform, which often produced larger JNDs. The results suggest that a sine, sawtooth, and sharpened sawtooth waveforms are likely to provide similar pitch discrimination within a speech processing strategy...|$|E
40|$|The time-span tree of Jackendoff and Lehrdahl’s Generative Theory of Tonal Music {{is one of}} {{the most}} {{promising}} representations of our human cognition of music. In order to show this, we compare the distance in trees and our psychological dissimilarity, using variations of Ah vous dirais-je, maman by Mozart. Since pitch and chord sequence also affect the time-spans, we first amend the time-span analysis to include <b>pitch</b> <b>information.</b> Then, we introduce the pitch distance based on Lerdahl’s theory, and renovate the tree distance. We compare the analyses with/without the <b>pitch</b> <b>information,</b> and show its efficacy...|$|E
50|$|The pitch {{process is}} blind: service {{providers}} {{do not know}} who the client is and must <b>pitch</b> solely on <b>information</b> available in the brief. Once the pitch deadline has passed, the blur team reviews the pitches and presents the top three providers to the client. The client then selects the winning candidate and the project begins.|$|R
40|$|ABSTRACT- The {{prosodic}} {{structure of}} Japanese polysyllabic words {{is defined by}} patterns {{of high and low}} pitch accents. The present study investigated whether the accent level of a single syllable extracted from its word context can be reliably identified by listeners. 96 tokens of the same CV sequence, extracted from the utterances of 32 words by three speakers, were presented to 24 listeners; their correct identification rates were high. Scores were higher for word-initial than for word-final syllables, and acoustic correlates of accent level were stronger in word-initial syllables, which is consistent with a role for <b>pitch</b> accent <b>information</b> in lexical access in Japanese...|$|R
40|$|In {{order to}} {{represent}} musical content, <b>pitch</b> and timing <b>information</b> is utilized {{in the majority}} of existing work in Symbolic Music Information Retrieval (MIR). Symbolic representations such as MIDI allow the easy calculation of such information and its manipulation. In contrast, most of the existing work in Audio MIR uses timbral and beat information, which can be calculated using automatic computer audition techniques...|$|R
