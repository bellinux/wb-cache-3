7|24|Public
40|$|Both texture {{maps and}} {{procedural}} shaders suffer from rendering artifacts during minification. Unlike texture maps, there exist no good automatic method to antialias procedural shaders. Given a <b>procedural</b> <b>shader</b> for a surface, {{we present a}} method that automatically creates an antialiased version of the <b>procedural</b> <b>shader.</b> The new <b>procedural</b> <b>shader</b> maintains the original shader’s details but reduces artifacts (aliasing or noise) due to minification. This new algorithm creates a pyramid similar to a MIP-Map in order to represent the shader. Instead of storing per-texel color, pyramid stores weighted sums of reflectance functions, allowing {{a wider range of}} effects to be antialiased. The stored reflectance functions are automatically selected based on an analysis of the different reflectances found over the surface. When the rendered surface is viewed at close range, the original shader is used, but as the texture footprint grows, the algorithm gradually replaces the shader’s result with an antialiased one...|$|E
40|$|In {{interactive}} or real-time applications, naturally {{the complexity}} of tasks that can be performed on the fly is limited. For that reason {{it is likely that}} even with the current rate of development in graphics hardware, the more complex shaders will not be feasible in this kind of application for some time to come. One solution to this problem seems to be a precomputation approach, where the <b>procedural</b> <b>shader</b> is evaluated (sampled), and the resulting values are stored in texture maps, which can then be applied in interactive rendering. A closer look, however, reveals several technical difficulties with this approach. These will be discussed in this section, and hints towards possible solutions will be given. ...|$|E
40|$|Procedural content {{generation}} is {{the act of}} creating video game content automatically, through algorithmic means. In online procedural generation, content is generated as the game is running on the consumer's computer. Online procedural generation of terrains has become an important feature in many recent video games. The technique enhances the replayability and vastness of virtual worlds by offering a unique and endless terrain for each play session. Procedural terrain {{generation is}} commonly achieved through noise synthesis. Adding, multiplying and filtering layers of noise at different frequencies and amplitudes, can lead to complex and realistic terrain models. This process of filtering and combining noise and other functions to create a final terrain function is usually done by issuing calls to a noise generating library in a programming or scripting language, such as C++ or Lua. The process requires a programmer to write code, compile the code, run the program, observe the results, and then start over editing the code. This is a tedious, non-intuitive and time-consuming design process. Consequently, game designers are often forced to accept sub-optimal results because of time constraints or lack {{of control over the}} generation process. Our framework, Noise Modeler, consists of a GUI application and a library for modeling terrains for endless-world creation. In this project, noise and other functions are composited through a visual flow-graph editor similar to the ones used by <b>procedural</b> <b>shader</b> editors and offline terrain generators. This novel framework enables non-programmers to edit models for procedural heightmap terrains while observing the effect of changes immediately in a real-time preview. Designed terrains can be serialized to human-readable text files, consuming only a few kilobytes. By using our library, a game engine can load these text files in order to generate terrain data on-demand on the GPU. To our knowledge the Noise Modeler framework is therefore unique in its cause. It may be limited in features, and rough around the edges in terms of usability, but it clearly outperforms existing noise libraries, and has terrain specific features and heightmap previews not present in <b>procedural</b> <b>shader</b> editors...|$|E
50|$|The program {{featured}} a 32-bit Phong rendering engine, a key-frame animation system, 'layered' <b>procedural</b> <b>shaders</b> {{and a wide}} variety of 'transformations', or modifications, that may be used on a model. Mechanisto featured QuickTime integration for outputting animation, a grouped, hierarchical scene graph and subdivision surfaces.|$|R
40|$|Celtic art {{contains}} {{mysterious and}} fascinating aesthetic elements including complex knot work motifs. The {{problem is that}} creating and exploring these motifs require substantial human effort. One {{solution to this problem}} is to create a process that collaboratively uses interactive and procedural methods within a computer graphic environment. Spline models of Celtic knot work can be interactively modeled and used as input into <b>procedural</b> <b>shaders.</b> <b>Procedural</b> <b>shaders</b> are computer programs that describe surface, light, and volumetric appearances to a renderer. The control points of spline models can be used to drive shading procedures such as the coloring and displacement of surface meshes. The result of this thesis provides both an automated and interactive process that is capable of producing complex interlaced structures such as Celtic knot work within a three-dimensional environment...|$|R
40|$|Complex <b>procedural</b> <b>shaders</b> are {{commonly}} used to enrich the appearance of high-quality computer animations. In traditional rendering architectures the shading computation is performed independently for each animation frame which leads to significant costs. In this paper we propose an approach which eliminates redundant computation between subsequent frames by exploiting temporal coherence in shading. The shadin...|$|R
40|$|International audienceWe {{recently}} {{worked on}} a snow sparkle effect for a AAA console title. Due {{to a number of}} practical considerations we implemented a procedural grid based sparkle, which intersects the snow surface with a jittered 3 D grid of sparkle shapes. While this worked well for simple scenes and depth ranges, it took a thorough analysis and some deep thinking to make it robust and suitable for use in production. In particular aliasing was a significant issue and required specific treatment to ensure the frequency content was suitable at every pixel independent of depth. In this talk we will illustrate the various sources of aliasing and present solutions for each case. The lines of thought that led us to our final solution are general in nature and are likely to apply to other <b>procedural</b> <b>shader</b> effects. The end result of our work is an anti-aliased, stable sparkle over the entire range of depths. The artists could comfortably drive down the sparkle size to the order of ~ 1 pixel without worrying about noisy flickering or other aliasing problems...|$|E
40|$|Procedural shaders are a {{vital part}} of modern {{rendering}} systems. Despite their prevalence, however, procedural shaders remain sensitive to aliasing any time they are sampled at a rate below the Nyquist limit. Antialiasing is typically achieved through numerical techniques like supersampling or precomputing integrals stored in mipmaps. This paper explores the problem of analytically computing a band-limited version of a <b>procedural</b> <b>shader</b> as a continuous function of the sampling rate. There is currently no known way of analytically computing these integrals in general. We explore the conditions under which exact solutions are possible and develop several approximation strategies for when they are not. Compared to supersampling methods, our approach produces shaders that are less expensive to evaluate and closer to ground truth in many cases. Compared to mipmapping or precomputation, our approach produces shaders that support an arbitrary bandwidth parameter and require less storage. We evaluate our method on a range of spatially-varying shader functions, automatically producing antialiased versions that have comparable error to 4 x 4 multisampling but can be over an order of magnitude faster. While not complete, our approach is a promising first step toward this challenging goal and indicates a number of interesting directions for future work...|$|E
40|$|This paper {{introduces}} a general method to approximate the convolution of an arbitrary {{program with a}} Gaussian kernel. This process {{has the effect of}} smoothing out a program. Our compiler framework models intermediate values in the program as random variables, by using mean and variance statistics. Our approach breaks the input program into parts and relates the statistics of the different parts, under the smoothing process. We give several approximations {{that can be used for}} the different parts of the program. These include the approximation of Dorn et al., a novel adaptive Gaussian approximation, Monte Carlo sampling, and compactly supported kernels. Our adaptive Gaussian approximation is accurate up to the second order in the standard deviation of the smoothing kernel, and mathematically smooth. We show how to construct a compiler that applies chosen approximations to given parts of the input program. Because each expression can have multiple approximation choices, we use a genetic search to automatically select the best approximations. We apply this framework to the problem of automatically bandlimiting <b>procedural</b> <b>shader</b> programs. We evaluate our method on a variety of complex shaders, including shaders with parallax mapping, animation, and spatially varying statistics. The resulting smoothed shader programs outperform previous approaches both numerically, and aesthetically, due to the smoothing properties of our approximations. Comment: 13 pages, 6 figure...|$|E
40|$|<b>Procedural</b> <b>shaders</b> {{have become}} popular tools for {{describing}} surface reflectance functions and other material properties. In comparison to fixed resolution textures {{they have the}} advantage of being resolution independent and storage efficient. While <b>procedural</b> <b>shaders</b> provide an interface for evaluating the shader at a single point in parameter space, it is not easily possible to obtain an average value of the shader together with accurate error bounds over a finite area. Yet the ability to compute such error bounds is crucial for several interesting applications, most notably hierarchical area sampling for global illumination computations using the finite element approach and for the generation of textures used in interactive computer graphics. Using affine arithmetic for evaluating the shader over a finite area yields a tight, conservative error interval for the shader function. Compilers can automatically generate code for utilizing affine arithmetic from within shaders implemented i [...] ...|$|R
5000|$|The {{roots of}} the effort are in Inigo's [...] "Shadertoy" [...] section [...] in his {{computer}} graphics educational website. With {{the arrival of the}} initial WebGL implementation by Mozilla's Firefox in 2009, Quilez created the first online live coding environment and curated repository of <b>procedural</b> <b>shaders.</b> This content was donated by 18 authors from the Demoscene and showcased advanced real-time and interactive animations never seen in the Web before, such as raymarched metaballs, fractals and tunnel effects.|$|R
50|$|Shading {{complexity}}: Much of {{the visual}} complexity in a scene is generated by {{the way in which}} light rays interact with solid object surfaces. Generally, in computer graphics, this is modelled using textures. Textures can be colored arrays of pixels, describe surface displacements or transparency or surface reflectivity. Reyes allows users to incorporate <b>procedural</b> <b>shaders</b> whereby surface structure and optical interaction is achieved using computer programs implementing procedural algorithms rather than simple look-up tables. A good portion of the algorithm is aimed at minimising the time spent by processors fetching textures from data stores.|$|R
40|$|Figure 1. Solid texture {{coordinates}} {{stored as}} vertex colors {{of a model}} (a) are rasterized into a texture atlas (b). A <b>procedural</b> <b>shader</b> replaces the interpolated solid texture coordinates with colors (c), which are applied to the object using texture mapping. Shortly after its introduction in 1985, procedural solid texturing became a must-have tool in the production-quality graphics of the motion-picture industry. Now, over fifteen years later, we are finally able to provide this feature for the real-time consumer graphics used in videogames and virtual environments. A texture atlas is {{used to create a}} 2 -D texture map of the 3 -D solid texture coordinates for a given surface. Applying the procedural texture to this atlas results in a view-independent procedural solid texturing of the object. Texture atlases are known to suffer from sampling problems and seam artifacts. We discovered that the quality of this texturing method is independent of the continuity and distortion of the atlas, which have been focal points of previous atlas techniques. We instead develop new meshed atlases that ignore continuity and distortion in favor of a balanced distribution of as many texture samples as possible. These atlases are seam-free due to careful attention to their rasterization in the texture map, and can be MIPmapped using a balanced mesh-clustering algorithm. Techniques for fast procedural synthesis are also investigated, using either the host processor or with multipass graphics processor operations on the texture map. We used these atlas and synthesis techniques to create a real-time procedural solid texture design system. CR Categories: I. 3. 7 [Computer Graphics] Three-Dimensional Graphics and Realism (color, shading and texture) ...|$|E
40|$|Noise {{functions}} are an essential building block for writing <b>procedural</b> <b>shaders</b> in 3 D computer graphics. The original noise function introduced by Ken Perlin {{is still the}} most popular because it is simple and fast, and many spectacular images have been made with it. Nevertheless, it is prone to problems with aliasing and detail loss. In this paper we analyze these problems and show that they are particularly severe when 3 D noise is used to texture a 2 D surface. We use the theory of wavelets to create a new class of simple and fast noise functions that avoid these problems...|$|R
40|$|We {{present a}} {{framework}} based on Genetic Programming (GP) for automatically simplifying <b>procedural</b> <b>shaders.</b> Our approach com-putes {{a series of}} increasingly simplified shaders that expose the in-herent trade-off between speed and accuracy. Compared to exist-ing automatic methods for pixel shader simplification [Olano et al. 2003; Pellacini 2005], our approach considers a wider space of code transformations and produces faster and more faithful results. We further demonstrate how our cost function can be rapidly evaluated using graphics hardware, which allows {{tens of thousands of}} shader variants to be considered during the optimization process. Our approach is also applicable to multi-pass shaders and perceptual-based error metrics...|$|R
40|$|Recent {{advances}} in algorithms and graphics hardware {{have opened the}} possibility to render large terrain fields at interactive rates on commodity PCs. Due to these advances it is possible today to interactively synthesize artificial terrains using procedural descriptions. Our paper extends on this work by presenting a new GPU method for real-time editing, synthesis, and rendering of infinite landscapes exhibiting {{a wide range of}} geological structures. Our method builds upon the concept of projected grids to achieve near-optimal sampling of the landscape. We describe the integration of <b>procedural</b> <b>shaders</b> for multifractals into this approach, and we propose intuitive options to edit the shape of the resultin...|$|R
40|$|Existing {{bidirectional}} reflectance {{distribution function}} (BRDF) models {{are capable of}} capturing the distinctive highlights produced by the fibrous nature of wood. However, capturing parameter textures for even a single specimen remains a laborious process requiring specialized equipment. In this paper we take a procedural approach to generating parameters for the wood BSDF. We characterize the elements of trees that are important for the appearance of wood, discuss techniques appropriate for representing those features, and present a complete <b>procedural</b> wood <b>shader</b> capable of reproducing the growth patterns responsible for the distinctive appearance of highly prized ``figured'' wood. Our <b>procedural</b> wood <b>shader</b> is random-access, 3 D, modular, and is fast enough to generate a preview for design. Comment: This version: Increased resolution of images and added YouTube link to vide...|$|R
40|$|We {{present a}} {{real-time}} rendering scheme that reuses shading samples from earlier time frames to achieve practical antialiasing of <b>procedural</b> <b>shaders.</b> Using a reprojection strategy, we maintain several sets of shading estimates at subpixel precision, and incrementally update these such {{that for most}} pixels only one new shaded sample is evaluated per frame. The key difficulty is to prevent accumulated blurring during successive reprojections. We present a theoretical analysis of the blur introduced by reprojection methods. Based on this analysis, we introduce a nonuniform spatial filter, an adaptive recursive temporal filter, and a principled scheme for locally estimating the spatial blur. Our scheme is appropriate for antialiasing shading attributes that vary slowly over time. It works in a single rendering pass on commodity graphics hardware, and offers results that surpass 4 × 4 stratified supersampling in quality, {{at a fraction of}} the cost. ...|$|R
40|$|Displacement {{maps and}} <b>procedural</b> {{displacement}} <b>shaders</b> are a widely used approach of specifying geometric detail {{and increasing the}} visual complexity of a scene. While it is relatively straightforward to handle displacement shaders in pipeline based rendering systems such as the Reyes-architecture, it is much harder to efficiently integrate displacement-mapped surfaces in ray-tracers. Many commercial ray-tracers tessellate the surface into a multitude of small triangles. This introduces a series of problems such as excessive memory consumption and possibly undetected surface detail. In this paper we describe a novel way of ray-tracing <b>procedural</b> displacement <b>shaders</b> directly, that is, without introducing intermediate geometry. Affine arithmetic is used to compute bounding boxes for the shader over any range in the parameter domain. The method {{is comparable to the}} direct ray-tracing of B'ezier surfaces and implicit surfaces using B'ezier clipping and interval methods, respectively. Keyw [...] ...|$|R
40|$|Current {{graphics}} hardware can render objects using simple <b>procedural</b> <b>shaders</b> in real-time. However, detailed, highquality shaders {{will continue}} to stress the resources of hardware {{for some time to}} come. Shaders written for film production and software renderers may stretch to thousands of lines. The difficulty of rendering efficiently is compounded when there is not just one, but a scene full of shaded objects, surpassing the capability of any hardware to render. This problem has many similarities to the rendering of large models, a problem that has inspired extensive research in geometric level-of-detail and geometric simplification. We introduce an analogous process for shading, shader simplification. Starting from an initial detailed shader, shader simplification produces a new shader with extra level-of-detail parameters that control the shader execution. The resulting level-of-detail shader, can automatically adjust its rendered appearance based on measures of distance, size, or importance as well as physical limits such as rendering time budget or texture usage...|$|R
40|$|This paper {{introduces}} a procedural approach to non-photorealistic line drawing from 3 D models. The approach is inspired both by <b>procedural</b> <b>shaders</b> in classical rendering {{and by the}} power of procedural modeling. We propose a new image creation model where all operations are controlled procedurally. A view map describing all relevant support lines in the drawing is first created from the 3 d model; a number of style modules operate on this map, by procedurally selecting and chaining lines before creating strokes and assigning drawing attributes. Two different levels of user control are provided, ranging from a low-level programming API to a parameteri- zed building-block assembly mechanism. The resulting drawing system allows very flexible control of all elements of drawing style: first, different style modules can be applied to different types of lines in a view; second, stroke attributes are assigned procedurally and can be correlated at will with various scene or view properties. We illustrate the components of our system and show results of its application...|$|R
40|$|Thanks to an {{increase}} in rendering efficiency, indirect illumination has recently begun to be integrated in cinematic lighting design, an application where physical accuracy is less important than careful control of scene appearance. This paper presents a comprehensive, efficient, and intuitive representation for artistic control of indirect illumination. We encode user’s adjustments to indirect lighting as scale and offset coefficients of the transfer operator. We take advantage of the nature of indirect illumination and of the edits themselves to efficiently sample and compress them. A major benefit of this sampled representation, compared to encoding adjustments as <b>procedural</b> <b>shaders,</b> is the renderer-independence. This allowed us to easily implement several tools to produce our final images: an interactive relighting engine to view adjustments, a painting interface to define them, and a final renderer to render high quality results. We demonstrate edits to scenes with diffuse and glossy surfaces and animation. Categories and Subject Descriptors (according to ACM CCS) ...|$|R
40|$|This work {{deals with}} {{procedural}} texture generation using programmable graphics pipeline in OpenGL. It describes basics of OpenGL operation and programmable shading. The main contribution is {{the analysis of}} methods used for generating procedural textures using various algorithms and noise functions, with focus on Perlin noise. The examples of <b>procedural</b> texture <b>shaders</b> are demonstrated by a C++ application, displaying 3 D model of Božetěchova building...|$|R
40|$|We {{present a}} {{framework}} and supporting algorithms to automate {{the use of}} temporal data reprojection as a general tool for optimizing <b>procedural</b> <b>shaders.</b> Although the general strategy of caching and reusing expensive intermediate shading calculations across consecutive frames has previously been shown to provide an effective trade-off between speed and accuracy, the critical choices of what to reuse and at what rate to refresh cached entries have been left to a designer. The fact that these decisions require a deep understanding of a procedure's semantic structure makes it challenging to select optimal candidates among possibly hundreds of alternatives. Our automated approach relies on parametric models of the way possible caching decisions affect the shader's performance and visual fidelity. These models are trained using a sample rendering session and drive an interactive profiler in which the user can explore the error/performance trade-offs associated with incorporating temporal reprojection. We evaluate the proposed models and selection algorithm with a prototype system used to optimize several complex shaders and compare our approach to current alternatives...|$|R
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references (leaves 44 - 45). Issued also on microfiche from Lange Micrographics. In this thesis two computational approaches for creating Chinese painting are developed. The first approach uses an expressive paint tool that enables anyone to paint 2 D Chinese paintings in real-time. The realistic rendering of paint strokes is achieved by creating a software model that mimics real ink and brushes. The input devices are a pressure-sensitive pen and tablet. This interface design is similar to painting with a real brush on paper. The second approach uses <b>procedural</b> <b>shaders</b> and commercially available 3 D modeling and animation packages to create the look of ink on paper. This approach facilitates the efficient production of 3 D Chinese painting animations as well as the ability to create stereoscopic Chinese paintings...|$|R
40|$|Since the {{introduction}} of programmable Graphics Processing Units (GPUs) and <b>procedural</b> <b>shaders,</b> hardware vendors have each developed their own individual real-time shading language standard. None of these shading languages is fully platform independent. Although this real-time programmable shader technology could be developed into 3 D application on a single system, this platform dependent limitation keeps the shader technology away from 3 D Internet applications. The primary purpose of this dissertation is to design a framework for translating different shader formats to platform independent shaders and embed them into the eXtensible 3 D (X 3 D) scene for 3 D web applications. This framework includes a back-end core shader converter, which translates shaders among different shading languages with a middle XML layer. Also included is a shader library containing a basic set of shaders that developers can load and add shaders to. This framework will then be applied to some applications in Biomolecular Visualization. We first defined a minimal set of shaders for common elements in protein molecules such as “Carbon”, “Nitrogen”, “Oxygen”, “Hydrogen”, “Phosphorus”, “Sulphur”, and “Other”, whic...|$|R
40|$|Several {{optimization}} results {{produced with}} our system. Each image compares (top) an input pixel shader to (bottom) a version modified to cache and reuse some partial shading computations over consecutive frames. Our system automatically selects the intermediate values {{to be reused}} and {{the rate at which}} cached entries are refreshed so as to maximize performance improvement while minimizing (inset) the visual error injected into the final shading. We present a framework and supporting algorithms to automate the use of data reprojection as a general tool for optimizing <b>procedural</b> <b>shaders.</b> Although the general strategy of caching and reusing expensive intermediate shading calculations across consecutive frames has previously been shown to provide an effective trade-off between speed and accuracy, the critical choices of what to reuse and at what rate to explicitly refresh cached entries have always been left to a designer. The fact that these decisions require a deep understanding of a procedure’s semantic structure makes it challenging to select optimal candidates among possibly hundreds of alternatives. Our automated approach relies on parametric models of the way possible caching decisions affect the shader’s performance and visual fidelity. These models are trained using a sample rendering session and drive an interactive profiler in which the user can explore the error/performance trade-offs associated with incorporating temporal reprojection. We evaluate the proposed models and selection algorithm with a prototype system used to optimize several complex shaders; in each case we observed a significant performance improvement. We also compare our approach to current alternatives...|$|R
40|$|Figure 1 : Images {{rendered}} by Lpics relighting engine versus software renderer. Times reported are {{the time}} a lighting artist must wait for feedback after moving one light. In computer cinematography, the process of lighting design involves placing and configuring lights to define the visual appearance of environments and to enhance story elements. This process is labor intensive and time consuming, primarily because lighting artists receive poor feedback from existing tools: interactive previews have very poor quality, while final-quality images often take hours to render. This paper presents an interactive cinematic lighting system used {{in the production of}} computer-animated feature films containing environments of very high complexity, in which surface and light appearances are described using <b>procedural</b> RenderMan <b>shaders.</b> Our system provides lighting artists with high-quality previews at interactive framerates with only small approximations compared to the final rendered images. This is accomplished by combining numerical estimation of surface response, image-space caching, deferred shading, and the computational power of modern graphics hardware. Our system has been successfully used in the production of two feature-length animated films, dramatically accelerating lighting tasks. In our experience interactivity fundamentally changes an artist’s workflow, improving both productivity and artistic expressiveness...|$|R
50|$|The RenderMan shading {{language}} allows material {{definitions of}} surfaces {{to be described}} not only by adjusting a small set of parameters, but in an arbitrarily complex fashion by using a C-like programming language to write shading procedures commonly known as <b>procedural</b> textures and <b>shaders.</b> Lighting, and displacements on the surface, are also programmable using the shading language. The shading language allows each statement to be executed in a SIMD manner, but does not insist on it. Another feature that sets renderers based on the RISpec apart from many other renderers {{is the ability to}} output arbitrary variables as an image: surface normals, separate lighting passes and pretty much anything else can be output from the renderer in a single pass.|$|R
40|$|Figure 1 : Two scenes {{rendered}} {{under different}} lighting configurations, relit at 10 - 20 fps with multiple bounces of indirect illumination. These scenes include up to 2. 1 million polygons, diffuse and glossy materials and <b>procedural</b> light <b>shaders.</b> This paper presents an interactive GPU-based system for cinematic relighting with multiple-bounce indirect illumination from a fixed view-point. We use a deep frame-buffer containing {{a set of}} view samples, whose indirect illumination is recomputed from the direct illumination on a large set of gather samples, distributed around the scene. This direct-to-indirect transfer is a linear transform which is particularly large, given {{the size of the}} view and gather sets. This makes it hard to precompute, store and multiply with. We address this problem by representing the transform as a set of sparse matrices encoded in wavelet space. A hierarchical construction is used to impose a wavelet basis on the unstructured gather cloud, and an image-based approach is used to map the sparse matrix computations to the GPU. We precompute the transfer matrices using a hierarchical algorithm and a variation of photon mapping in less than three hours on one processor. We achieve high-quality indirect illumination at 10 - 20 frames per second for complex scenes with over 2 million polygons, with diffuse and glossy materials, and arbitrary direct lighting models (expressed using shaders). We compute perpixel indirect illumination without the need of irradiance caching or other subsampling techniques...|$|R
40|$|This thesis {{explores the}} topic of recreating Chinese ink-and-brush {{painting}} in 3 D computer graphics and introducing film lighting aesthetics into the result. The method is primarily based on non-photorealistic shader development and digital compositing. The goal {{of this research is}} to study how to bing the visual aesthetics of Chinese ink-and-brush painting into 3 D computer graphics as well as explore the artistic possibility of using film lighting principles in Chinese painting for visual story telling by using 3 D computer graphics. In this research, we use the Jiangnan water country paintings by renowned contemporary Chinese artist Yang Ming-Yi as our primary visual reference. An analysis of the paintings is performed to study the visual characteristics of Yang's paintings. These include how the artist expresses shading, forms, shadow, reflection and compositing principles, which will be used as the guidelines for recreating the painting in computer graphics. 3 D meshes are used to represent the subjects in the painting like houses, boats and water. Then <b>procedural</b> non-photorealistic <b>shaders</b> are developed and applied on 3 D meshes to give the models an ink-look. Additionally, different types of 3 D data are organized and rendered into different layers, which include shading, depth, and geometric information. Those layers are then composed together by using 2 D image processing algorithms with custom artistic controls to achieve a more natural-looking ink-painting result. As a result, a short animation of Chinese ink-and-brush painting in 3 D computer graphics will be created in which the same environment is rendered with different lighting designs to demonstrate the artistic intention...|$|R

