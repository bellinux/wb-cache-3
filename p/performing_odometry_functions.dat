0|12|Public
30|$|The GRAIL {{consortium}} {{funded by}} the 6 th Framework Program attempted to achieve common specifications (agreed by users and industry) for the GNSS subsystem dedicated to the <b>odometry</b> <b>function</b> [10]. The objective was to examine how GNSS can complement an odometry system.|$|R
40|$|Abstract — We {{propose a}} {{real-time}} method for odometry and mapping using range measurements from a 2 -axis lidar moving in 6 -DOF. The problem is hard because the range measurements are received at different times, and errors in motion estimation can cause mis-registration {{of the resulting}} point cloud. To date, coherent 3 D maps can be built by off-line batch methods, often using loop closure to correct for drift over time. Our method achieves both low-drift and low-computational complexity with-out the need for high accuracy ranging or inertial measurements. The key idea in obtaining this level of performance is {{the division of the}} complex problem of simultaneous localization and mapping, which seeks to optimize a large number of variables simultaneously, by two algorithms. One algorithm <b>performs</b> <b>odometry</b> at a high frequency but low fidelity to estimate velocity of the lidar. Another algorithm runs at a frequency of an order of magnitude lower for fine matching and registration of the point cloud. Combination of the two algorithms allows the method to map in real-time. The method has been evaluated by a large set of experiments {{as well as on the}} KITTI odometry benchmark. The results indicate that the method can achieve accuracy at the level of state of the art offline batch methods. I...|$|R
40|$|We {{describe}} a novel and robust minimal solver for <b>performing</b> online visual <b>odometry</b> with a stereo rig. The proposed method can compute the underlying camera motion given any arbitrary, mixed combination of point and line correspondences across two stereo views. This facilitates a hybrid visual odometry pipeline that {{is enhanced by}} welllocalized and reliably-tracked line features while retaining the well-known advantages of point features. Utilizing trifocal tensor geometry and quaternion representation of rotation matrices, we develop a polynomial system from which camera motion parameters can be robustly extracted {{in the presence of}} noise. We show how the more popular approach of using direct linear/subspace techniques fail in this regard and demonstrate improved performance using our formulation with extensive experiments and comparisons against the 3 -point and line-sfm algorithms. 1...|$|R
40|$|A novel closed-form {{solution}} for pose-graph SLAM is presented. It optimizes pose-graphs of particular structure called pose-chains by employing an extended version of trajectory bending. Our solution is {{designed as a}} back-end optimizer to be used within systems whose front-end <b>performs</b> state-of-the-art visual <b>odometry</b> and appearance based loop detection. The optimality conditions of our closed-form method and that of state-of-the-art iterative methods are discussed. The practical relevance of their theoretical differences is investigated by extensive experiments using simulated and real data. It is shown using 49 kilometers of challenging binocular data that the accuracy obtained by our {{closed-form solution}} is {{comparable to that of}} state-of-the-art iterative solutions while the time it needs to compute its solution is a factor 50 to 200 times lower. This makes our approach relevant to a broad range of applications and computational platforms...|$|R
40|$|Abstract—Visual {{solution}} methods, like monocular {{visual odometry}} and monoSLAM, have attracted increasingly interests in robotics area. However, {{due to the}} large computational burden around volume sequential images processing, it is still hard to make numerous visual-based algorithms applying in highly agile platforms like Micro Aerial Vehicle (MAV) in real-time circumstance. In this paper, we present a method, which combines the direct image information from monocular camera and the measurements from inertial sensor in an Extend Kalman Filter (EKF) framework to <b>perform</b> an effective <b>odometry</b> solution. In contrast to other odometry methods, our solution gets rid of traditional feature extraction and expression, using the mutual in-formation between images to perform the tracking. This entropy based tracking method enhances the robustness to illumination variation. The result of our method has been tested on real data. Index Terms—Visual inertial odometry, Tracking, Pose estima-tion, Entropy, Mutual informatio...|$|R
40|$|Abstract – In {{this paper}} {{we present a}} dense visual odometry system for RGB-D cameras {{performing}} both photometric and geometric error minimisation to estimate the camera motion between frames. Contrary to most works in the literature, we parametrise the geometric error by the inverse depth instead of the depth, which translates into a better fit {{of the distribution of}} the geometric error to the used robust cost functions. To improve the accuracy we propose to use a keyframe switching strategy based on a visibility criteria between frames. For the comparison of our approach with state-of-the-art approaches we use the popular datasets from the TUM for RGB-D benchmarking as well as two synthetic datasets. Our approach shows to be competitive with state-of-the-art methods in terms of drift in meters per second, even compared to methods performing loop closure too. When comparing to approaches <b>performing</b> pure <b>odometry</b> like ours, our method outperforms them in the majority of the tested datasets. Additionally we show that our approach is able to work in real time and we provide a qualitative evaluation on our own sequences showing a low drift in the 3 D reconstructions. We have implemented this method within the scope of PCL (Point Cloud Library) as a branch of the code for large scale KinectFusion, where the original ICP system for odometry estimation has been completely substituted by our method. A PCL fork including the modified method is available for download. ...|$|R
40|$|Stereo imaging is a {{technique}} commonly employed for vision-based navigation. For such applications, two images are acquired from different vantage points and then compared using transformations to extract depth information. The technique is commonly used in robotics for obstacle avoidance or for Simultaneous Localization And Mapping, (SLAM). Yet, the process requires a number of image processing steps and therefore tends to be CPU-intensive, which limits the real-time data rate and use in power-limited applications. Evaluated here is {{a technique}} where a monocular camera is used for vision-based odometry. In this work, an optical flow technique with feature recognition is <b>performed</b> to generate <b>odometry</b> measurements. The visual odometry sensor measurements are intended {{to be used as}} control inputs or measurements in a sensor fusion algorithm using low-cost MEMS based inertial sensors to provide improved localization information. Presented here are visual odometry results which demonstrate the challenges associated with using ground-pointing cameras for visual odometry. The focus is for rover-based robotic applications for localization within GPS-denied environments...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedA novel approach for dead reckoning, heading reference, obstacle detection, and obstacle avoidance using only one optical mouse sensor {{was presented in}} this thesis. Odometry, position tracking, and obstacle avoidance are important issues in mobile robotics. Traditional odometry and motion-tracking sensors provide relative displacement data on a frame-to-frame basis, and they are usually mounted in arrays to provide accurate measurements with small estimation errors. Optical flow sensors stand as a tempting solution for robot self-localization and dead reckoning. In this work, using only one inexpensive optical mouse sensor, {{we were able to}} <b>perform</b> optical <b>odometry,</b> dead reckoning, and heading reference. Also, obstacle detection and avoidance remains a challenging area of research. Most of the existing works are based on stereo imaging and computation of the time-to-contact. These techniques are complex and usually require the use of more than one vantage point. The use of one optical mouse sensor as an obstacle-detection sensor was proposed in this work. The detection process is simple and is based on the surface-quality factor variation. As far as we know, no one has ever used this technique to perform obstacle-detection and avoidance. Using one sensor for motion tracking and one sensor for object detection in association with an Arduino microcontroller, we built an indoor ground robot capable of environment sensing, obstacle avoidance, and position tracking. The behavior of the robot can be monitored from a remote station. The experimental results obtained were promising and can be further improved. Captain, Tunisia Air Forc...|$|R
40|$|Several {{examples}} of insects using visual motion to measure distance have been documented, from locusts peering {{to gauge the}} proximity of prey, to honeybees <b>performing</b> visual <b>odometry</b> en route between the hive and a flower patch. However, whether the use of parallax information is confined to specialised behaviours like these or represents a more general purpose sensory capability, is an open question. We investigate this issue in the foraging swallowtail butterfly Papilio xuthus, which we trained to associate a target presented on a monitor with a food reward. We then tracked the animal 2 ̆ 7 s flight in real-time, allowing us to manipulate the size and/or position of the target in a closed-loop manner {{to create the illusion}} that it is situated either above or below the monitor surface. Butterflies are less attracted to (i. e. slower to approach) targets that appear, based on motion parallax, to be more distant. Furthermore, we found that the number of abortive descent manoeuvres performed prior to the first successful target approach varies according to the depth of the virtual target, with expansion and parallax cues having effects of opposing polarity. However, we found no evidence that Papilio modulate the kinematic parameters of their descents according to the apparent distance of the target. Thus, we argue that motion parallax is used to identify a proximal target object, but that the subsequent process of approaching it is based on stabilising its edge in the 2 D space of the retina, without estimating its distance...|$|R
40|$|In this paper, we {{analyze and}} extend the {{recently}} proposed closed-form online pose-chain simultaneous localization and mapping (SLAM) algorithm. Pose-chains are {{a specific type of}} extremely sparse pose-graphs and a product of contemporary SLAM front-ends, which <b>perform</b> accurate visual <b>odometry</b> and reliable appearance-based loop detection. They are relevant for challenging robotic applications in large-scale 3 -D environments for which frequent loop detection is not desired or not possible. Closed-form online pose-chain SLAM efficiently and accurately optimizes pose-chains by exploiting their Lie group structure. The convergence and optimality properties of this solution are discussed in detail and are compared against state-of-the-art iterative methods. We also provide a novel solution space, that of similarity transforms, which has not been considered earlier for the proposed algorithm. This allows for closed-form optimization of pose-chains that exhibit scale drift, which is important to monocular SLAM systems. On the basis of extensive experiments, specifically targeting 3 -D pose-chains and using a total of 60 km of challenging binocular and monocular data, it is shown that the accuracy obtained by closed-form online pose-chain SLAM is comparable with that of state-of-the-art iterative methods, while the time it needs to compute its solution is orders of magnitudes lower. This novel SLAM technique thereby is relevant to a broad range of robotic applications and computational platforms...|$|R
40|$|International audienceAlthough {{already used}} in USA in the Positive Train Control (PTC) system, in China {{for the high}} {{velocity}} and low capacity lines and in Russia, the GNSS technology is still not used in the European Train Control System (ETCS). ETCS will progressively replace the different systems {{that are used in}} Europe for an improved interoperability. In ETCS level 2 and 3, the train has to self-estimate its position by propagating the position of reference given by Eurobalises with wheel speed sensors (WSS). A large amount of balise must be settled on the rail tracks in order to bound the error on the position estimation that is growing {{as a function of the}} distance travelled since the last Eurobalise due to the WSS scale factor error and sliding effects. The current trend adopted by the rail community would consist in using the GNSS as a virtual balise. The first main challenge for the introduction of the GNSS in ETCS is the very low Tolerable Hazard Risk (THR), which, for the whole signaling system, shall not be over 2. 10 - 9 /h to fulfill the Safety Integrity Level (SIL) 4 requirement [1]. Therefore, the tolerable uncertainty on the GNSS sensor shall be even lower. Depending on the risk allocation in the ETCS fault tree, the integrity risk allowed for GNSS can reach 1. 10 - 11 /h. Because the requirements are key in the design of the virtual balise platform, a proposition of accuracy and alert limit requirements is discussed in the paper. The second main challenge for the introduction of the GNSS in ETCS is related to the operational environment of the vehicle. Indeed the trains are likely to operate in suburban and in dense urban environments, where the GNSS satellites can be masked by the buildings, or where the GNSS receiver can be affected by large multipath errors, interference or Non Line-Of-Sight signals (NLOS). This paper proposes a complete positioning module that is designed to fulfill the tight integrity requirements for a virtual balise in ETCS. The navigation solution proposed is based on a combination of GNSS, Inertial Navigation Sensor (INS) and a track database that are tightly coupled through an extended Kalman filter (EKF). The widely used WSS that are present onboard are purposely not used to avoid safety issues related to the joint dependency of the <b>odometry</b> <b>function</b> and virtual balise with respect to the same sensor. Together with the positioning algorithm, it is necessary to design an integrity monitoring algorithm that will ensure that the positioning requirements are fulfilled. This paper proposes such an algorithm, which can be seen as an adaptation of Aircraft Autonomous Integrity Monitoring (AAIM) techniques that were developed for tightly coupled GPS/IRS systems in civil aviation. The considered nominal case and fault modes are described in the paper, including the presence of a major (GNSS) service failure, the presence of large multipath errors and the reception of NLOS signals. The problem caused by large multipath errors and NLOS signals on the integrity monitoring is lightened by the use of an a priori exclusion of some GNSS measurements that are likely to be faulty. The exclusion decision is based on different criteria including GNSS signal quality indicators based on the assessment of the distortion of the correlation function, the estimated C/N 0 or the satellite elevation. The proposed integrity monitoring algorithm assumes that all sensors are fault free. It is thus necessary to ensure that this condition is met. Considering this, and since the Mean Time Between Failure (MTBF) of the considered MEMS IMU is not sufficiently high to neglect the probability of failure of the IMU, a fault detection algorithm based on the redundancy of the IMUs is proposed in the paper. This algorithm, which can detect sensor failures before any use of the sensor in the position computation, is based on Kalman filtering and on a hypothesis test based on Weighted Sum of Squared Residuals (WSSR). The fault modes of the sensors are also detailed in the paper. The next step is to prove that the proposed positioning system will be able to meet an integrity risk of 1. 10 - 11 /h. In a usual system, this means that it is necessary to characterize the nominal error model of each error sources using an extremely large amount of data (to know the error model down to an extremely low percentile). To overcome this issue, the paper proposes to divide the problem in two independent ones. It thus proposed to use two different GPS/Galileo dual constellation receivers. The idea consists in dividing the available satellites into two independent subsets of satellites. The measurements from each subset are integrated with two independent IMUs. Due to the division into two separate subsets, it is likely to have less than 4 satellites available which reinforce the interest of using tight integration. The two EKF are monitored by two AAIM algorithms that provide protection levels in real time. A new estimated position and protection level is formed from the two independent positions and protection levels. As shown in the paper, this separation of the whole system into two independent sub-systems reduces the integrity risk of each subsystem down to ? 10 - 11 /h, which appears much more manageable based on the current knowledge of the GNSS error sources. Finally, this paper assesses the nominal accuracy and integrity performances of the proposed architecture by realistic simulations. Starting from a typical rail trajectory and velocity profile, ideal inertial sensor, GNSS and track database outputs are generated. Typical error models are then added based on the manufacturer specifications for the IMU and on realistic values for the GNSS. Performances of the proposed solution are finally assessed on a real measurement campaign in urban environment. The reference trajectory is given by a NovAtel SPAN equipment hybridizing a tactical-grade IMU with a high accuracy GNSS solution. The outline of this paper is the following: • The first chapter focuses on the operational requirements that must be fulfilled by the studied solution • The second chapter discusses the architecture of the hybridized solution and on the integration approach by EKF. • The third chapter addresses the failures modes and the fault detection algorithm proposed to detect them before integration of the measurements in the filter. • The fourth chapter addresses the failure modes of the GNSS. The way to lighten the burden of the integrity monitoring algorithm by using signal quality indicators and external information is discussed. The method that is used to set the integrity requirement to ? 10 - 11 /h instead of 10 - 11 /h is discussed. • The fifth chapter provides nominal fault free performances of the system in terms of accuracy and integrity based on realistic simulations. The error models of each sensors are detailed. • The last chapter assesses the performances of the solution on a real measurement campaign...|$|R

