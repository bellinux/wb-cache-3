105|228|Public
25|$|Metaphysical naturalists {{hold that}} {{reason is the}} {{refinement}} and improvement of naturally evolved faculties. The certitude of deductive logic remains unexplained by this essentially <b>probabilistic</b> <b>view.</b> Nevertheless, naturalists believe anyone who wishes to have more beliefs that are true than are false should seek to perfect and consistently employ their reason in testing and forming beliefs. Empirical methods (especially those of proven use in the sciences) are unsurpassed for discovering the facts of reality, while methods of pure reason alone can securely discover logical errors.|$|E
5000|$|In {{the years}} to follow, Ludwig Boltzmann {{translated}} these [...] "alterations" [...] into that of a <b>probabilistic</b> <b>view</b> of order and disorder in gas-phase molecular systems.|$|E
50|$|Although Boltzmann's H-theorem {{turned out}} not to be the {{absolute}} proof of the second law of thermodynamics as originally claimed (see Criticisms below), the H-theorem led Boltzmann in the last years of the 19th century to more and more probabilistic arguments about the nature of thermodynamics. The <b>probabilistic</b> <b>view</b> of thermodynamics culminated in 1902 with Josiah Willard Gibbs's statistical mechanics for fully general systems (not just gases), and the introduction of generalized statistical ensembles.|$|E
50|$|By nature, {{behavioural}} therapies are empirical (data-driven), contextual (focused on {{the environment}} and context), functional (interested in the effect or consequence a behaviour ultimately has), <b>probabilistic</b> (<b>viewing</b> behaviour as statistically predictable), monistic (rejecting mind-body dualism and treating the person as a unit), and relational (analysing bidirectional interactions).|$|R
40|$|The {{nineteenth century}} Russian author Leo Tolstoy based his egalitarian views on {{sociology}} and history on mathematical and <b>probabilistic</b> <b>views,</b> {{and he also}} proposed a mathematical theory of waging war. Comment: LaTeX, 12 pages, Preliminary version appeared in a Liber Amicorum at the occasion of Johan van Benthem's fiftieth birthda...|$|R
25|$|Behavior therapies use {{behavioral}} techniques, including applied behavior analysis (also {{known as}} behavior modification), to change maladaptive {{patterns of behavior}} to improve emotional responses, cognitions, and interactions with others. Functional analytic psychotherapy is one form of this approach. By nature, behavioral therapies are empirical (data-driven), contextual (focused {{on the environment and}} context), functional (interested in the effect or consequence a behavior ultimately has), <b>probabilistic</b> (<b>viewing</b> behavior as statistically predictable), monistic (rejecting mind-body dualism and treating the person as a unit), and relational (analyzing bidirectional interactions).|$|R
50|$|Metaphysical naturalists {{hold that}} {{reason is the}} {{refinement}} and improvement of naturally evolved faculties. The certitude of deductive logic remains unexplained by this essentially <b>probabilistic</b> <b>view.</b> Nevertheless, naturalists believe anyone who wishes to have more beliefs that are true than are false should seek to perfect and consistently employ their reason in testing and forming beliefs. Empirical methods (especially those of proven use in the sciences) are unsurpassed for discovering the facts of reality, while methods of pure reason alone can securely discover logical errors.|$|E
40|$|The two {{experiments}} {{described here}} {{were intended to}} investigate the empirical issues that arise from the <b>probabilistic</b> <b>view</b> of security assessment discussed in the previous paper. Specifically, they investigated the problems of measureing effort and reward associated with security attacks and breaches...|$|E
40|$|This model {{allows us}} to find TAD {{hierarchy}} • A penalty parameter controls model complexity • <b>Probabilistic</b> <b>view</b> generates TAD hierarchies based on many distances equally, and eliminates low distance skews • Six parameter model x 60 distances • Can be compressed to genome-wide power laws • A power law model fo...|$|E
40|$|We {{perform a}} {{stability}} {{analysis for the}} utility maximization problem in a general semimartingale model where both liquid and illiquid assets (random endowments) are present. Small misspecifications of preferences (as modeled via expected utility), as well as views of the world or the market model (as modeled via subjective probabilities) are considered. Simple sufficient conditions are given for the problem to be well posed, {{in the sense that}} the optimal wealth and the marginal utility-based prices are continuous functionals of preferences and <b>probabilistic</b> <b>views...</b>|$|R
50|$|Behavior therapies use {{behavioral}} techniques, including applied behavior analysis (also {{known as}} behavior modification), to change maladaptive {{patterns of behavior}} to improve emotional responses, cognitions, and interactions with others. Functional analytic psychotherapy is one form of this approach. By nature, behavioral therapies are empirical (data-driven), contextual (focused {{on the environment and}} context), functional (interested in the effect or consequence a behavior ultimately has), <b>probabilistic</b> (<b>viewing</b> behavior as statistically predictable), monistic (rejecting mind-body dualism and treating the person as a unit), and relational (analyzing bidirectional interactions).|$|R
40|$|We {{describe}} a decision-theoretic method that an autonomous agent {{can use to}} model multiagent situations and behave rationally based on its model. Our approach, which we call the Recursive Modeling Method, explicitly accounts for the recursive nature of multiagent reasoning. Our method lets an agent recursively model another agent's decisions based on <b>probabilistic</b> <b>views</b> of how that agent perceives the multiagent situation, which in turn are derived from hypothesizing how that other agent perceives the initial agent's possible decisions, and so on. Further, we show how the possibility of multiple interactions can affect the decisions of agents, allowing cooperative behavior to emerge as a rational choice of selfish agents that otherwise might behave uncooperatively...|$|R
40|$|Three-valued {{accounts}} of conditionals frequently promise (a) {{to conform to}} the <b>probabilistic</b> <b>view</b> that conditionals are evaluated by conditional probabilities, and (b) to yield a plausible account of compounds of conditionals. However, McGee (1981) shows that probabilistic validity, the conception of validity most naturally associated with the <b>probabilistic</b> <b>view,</b> cannot be characterized by a finite matrix. Adams (1995) indicates a further generalization of this result. Nevertheless, Adams (1986) provides a description of probabilistic validity in three-valued terms by going beyond the standard framework. Yet the language Adams considers is severely restricted: it does not contain compounds of conditionals. Thus, a natural question arises: Is there a plausible three-valued account of compounds of conditionals which agrees with probabilistic validity on the restricted language? In this note, I develop a general framework in which to address this question. The answer will be negative. ...|$|E
40|$|Felsenthal/Machover’s 1998 celebrated {{monograph}} on The Measurement of Voting Power set off {{a renewed}} impetus on the analysis of weighted voting systems. Their presentation strikes {{a balance between the}} game-theoretic and the probabilistic approaches to the subject. The present paper holds that the <b>probabilistic</b> <b>view</b> may be profitably extended even further, in providing helpful language as well as motivating new results...|$|E
40|$|International audienceIn {{this work}} we suggest an {{approach}} to comparing fuzzy numbers motivated by a <b>probabilistic</b> <b>view</b> of the underlying uncertainty. An {{important aspect of the}} method suggested is its context dependency, the numbers being compared affect the process. We discuss the effect of decision attitude and show that this approach is particularly useful for aiding decision makers having a temperate decision attitude, optimism in the face of adversity and conservatism in the face plenty...|$|E
40|$|DMAPS (Distributed Multi-Agent Planning System) is a {{planning}} system developed for distributed multi-robot teams based on MAPS (Multi-Agent Planning System). MAPS assumes that each agent {{has the same}} global view of the environment {{in order to determine}} the most suitable actions. This assumption fails when perception is local to the agents: each agent has only a partial and unique view of the environment. DMAPS addresses this problem by creating a <b>probabilistic</b> global <b>view</b> on each agent by fusing the perceptual information from each robot. The experimental results on consuming tasks show that while the <b>probabilistic</b> global <b>view</b> is not identical on each robot, the shared view is still effective in increasing performance of the team...|$|R
40|$|In this article, we characterize, using postulates, whole {{classes of}} {{strategies}} for conjunction, disjunction, and negation, meaningful {{from the viewpoint}} of probability theory. (1) We propose a probabilistic relational data model and a generic probabilistic relational algebra that neatly captures various strategies satisfying the postulates, within a single unified framework. (2) We show {{that as long as the}} chosen strategies can be computed in polynomial time, queries in the positive fragment of the probabilistic relational algebra have essentially the same data complexity as classical relational algebra. (3) We establish various containments and equivalences between algebraic expressions, similar in spirit to those in classical algebra. (4) We develop algorithms for maintaining materialized <b>probabilistic</b> <b>views.</b> (5) Based on these ideas, we have develope...|$|R
3000|$|... or more nonzero entries, {{uniqueness}} is violated. In {{this paper}} we study {{the behavior of}} overcomplete representations beyond the above bound. While tight from a worst-case standpoint, a <b>probabilistic</b> point of <b>view</b> leads to uniqueness of representations satisfying [...]...|$|R
40|$|Abstract. Process Mining uses event logs to {{discover}} and analyse busi-ness processes, typically assumed to be static. However as businesses adapt to change, processes {{can be expected to}} change. Since one application of process mining is ensuring conformance to prescribed processes or rules, timely detection of change is important. We consider process mining in such non-stationary environments and show that using a <b>probabilistic</b> <b>view</b> of processes, timely and confident detection of change is possible. ...|$|E
40|$|In {{this work}} we suggest an {{approach}} to comparing fuzzy numbers motivated by a <b>probabilistic</b> <b>view</b> of the underlying uncertainty. An {{important aspect of the}} method suggested is its context dependency, the numbers being compared affect the process. We discuss the effect of decision attitude and show that this approach is particularly useful for aiding decision makers having a temperate decision attitude, optimism in the face of adversity and conservatism in the face plenty. < 3 2001 Elsevier Science Inc. All rights reserved...|$|E
40|$|Today’s plan Least {{squares and}} ridge {{regression}}: a <b>probabilistic</b> <b>view</b> Bayesian linear models for regression Sparse extensions Maximum likelihood, maximum a posteriori, type II ML, variational inference Regression problem Given {{a finite number}} of noisy observations {tn}Nn= 1 associated to some input data {xn}Nn= 1, we would like to predict the outcome of an unseen input xnew. This process is called generalisation and the input-target pairs {xn, tn}Nn= 1 are the training data. ! 10 ! 8 ! 6 ! 4 ! 2 0 2 4 6 8 10 ! 0. ...|$|E
50|$|Previous {{theories}} have supposed that genes are static unchanging code for specific developmental outcomes. However, new {{research suggests that}} genes may be triggered by both environmental and behavioral influences. This <b>probabilistic</b> epigenesis <b>view</b> of development, suggests that instead of following a predetermined path to expression, genes are modified by the behavior and environment of an organism. Furthermore, these modifications can then act on the environment, creating a causal circle in which genes influencing the environment are re-influenced by these changes in the environment.|$|R
40|$|Abstract — Uncertain {{data are}} {{inherent}} in many important applications. Recently, considerable research efforts have been put into the field of managing uncertain data. In this paper, we summarize existing techniques to query and model uncertain data and systems that effectively manage uncertain data, mainly from a <b>probabilistic</b> point of <b>view.</b> I...|$|R
40|$|<b>Views</b> over <b>probabilistic</b> data contain {{correlations}} between tuples, {{and the current}} approach is to capture these correlations using explicit lineage. In this paper we propose an alternative approach to materializing <b>probabilistic</b> <b>views,</b> by giving conditions under which a view can be represented by a block-independent disjoint (BID) table. Not all views can be represented as BID tables and so we propose a novel partial representation that can represent all views but may not define a unique probability distribution. We then give conditions on when a query’s value on a partial representation will be uniquely defined. We apply our theory to two applications: query processing using views and information exchange using views. In query processing on probabilistic data, we can ignore the lineage and use materialized views to more efficiently answer queries. By contrast, if the view has explicit lineage, the query evaluation must reprocess the lineage to compute the query resulting in dramatically slower execution. The second application is information exchange when we {{do not wish to}} disclose the entire lineage, which otherwise may result in shipping the entire database. The paper contains several theoretical results that completely solve the problem of deciding whether a conjunctive view can be represented as a BID and whether a query on a partial representation is uniquely determined. We validate our approach experimentally showing that representable views exist in real and synthetic workloads and show over three magnitudes of improvement in query processing versus a lineage based approach. 1...|$|R
40|$|A major {{challenge}} in developing models for hypertext retrieval is to effectively combine content {{information with the}} link structure available in hypertext collections. Although several link-based ranking methods {{have been developed to}} improve retrieval results, none of them can fully exploit the discrimination power of contents as well as fully exploit all useful link structures. In this paper, we propose a general relevance propagation framework for combining content and link information. The framework gives a probabilistic score to each document defined based on a probabilistic surfing model. Two main characteristics of our framework are our <b>probabilistic</b> <b>view</b> on the relevance propagation model and propagation through multiple sets of neighbors. We compare eight different models derived from the probabilistic relevance propagation framework on two standard TREC Web test collections. Our results show that all the eight relevance propagation models can outperform the baseline content only ranking method {{for a wide range of}} parameter values, indicating that the relevance propagation framework provides a general, effective and robust way of exploiting link information. Our experiments also show that using multiple neighbor sets outperforms using just one type of neighbors significantly and taking a <b>probabilistic</b> <b>view</b> of propagation provides guidance on setting propagation parameters...|$|E
40|$|This PhD {{thesis is}} about the {{integration}} of different methods to fit a statistical model of human faces to a single image. I propose to take a <b>probabilistic</b> <b>view</b> on the problem and implement and evaluate an integrative framework for face image explanation based on a class of methods known as Data-Driven Markov Chain Monte Carlo. The framework {{is based on the}} propose-and-verify architecture of the Metropolis-Hastings algorithm. Probabilistic inference replaces traditional optimization methods and conceptually shifts the goal of face explanation from obtaining the optimal parameter set to extracting measures of the posterior distribution. The <b>probabilistic</b> <b>view</b> opened the process for deeper insights like the need of a background model and richer likelihood models. Within this framework, different methods are implemented and evaluated specifically for face image explanation with the 3 D Morphable Model and face and feature point detection. The Markov Chain Monte Carlo integration method is able to algorithmically reproduce existing fitting algorithms as well as capable of dealing with unreliable and differently shaped information sources. The integration of Bottom-Up information into the adaption process leads to more robust results than a simple feed-forward combination of the methods and culminates into a fully automatic face image explanation method, independent of user-provided initialization. A full-system application leads to a fully automatic and general face recognition application with state of the art results. ...|$|E
40|$|Nineteenth-century {{studies of}} {{harmonic}} analysis were closely {{linked with the}} work of Joseph Fourier on the theory of heat and with that of P. S. Laplace on probability. During the 1920 s, the Fourier transform developed {{into one of the most}} effective tools of modern probabilistic research; conversely, the demands of the probability theory stimulated further research into harmonic analysis. Mathematician Salomon Bochner wrote a pair of landmark books on the subject in the 1930 s and 40 s. In this volume, originally published in 1955, he adopts a more <b>probabilistic</b> <b>view</b> and emphasizes stochastic pr...|$|E
40|$|Abstract. In {{this paper}} we give various {{equivalent}} characterizations of upper estimates of heat kernels of regular, conservative and local Dirichlet forms on doubling spaces, {{from both the}} analytic and <b>probabilistic</b> points of <b>view.</b> The {{first part of this}} paper uses purely analytic arguemtn, while the second part focuses on the probabilistic aspects where the exit time plays an important role...|$|R
40|$|In {{this note}} we propose {{a version of}} the {{classical}} Stone-Weierstrass theorem in the context of quantum operations, by introducing a particular class of quantum operations, dubbed polynomial quantum operations. This result permits to interpret from a <b>probabilistic</b> point of <b>view,</b> and up to a certain approximation, any continuous function from the real cube [0, 1] n to the real interval [0, 1] as a quantum operation...|$|R
40|$|Ideas from {{probability}} can be {{very useful}} to understand and motivate frac-tional calculus models for anomalous diffusion. Fractional derivatives in space are related to long particle jumps. Fractional time derivatives code particle sticking and trapping. This <b>probabilistic</b> point of <b>view</b> also leads to some inter-esting extensions, including vector fractional derivatives, and tempered frac-tional derivatives. This paper reviews the basic ideas along with some practica...|$|R
40|$|We {{discuss a}} {{hierarchical}} probabilistic model whose predictions {{are similar to}} those of the popular language modelling procedure known as 'smoothing'. A number of interesting differences from smoothing emerge. The insights gained from a <b>probabilistic</b> <b>view</b> of this problem point towards new directions for language modelling. The ideas of this paper are also applicable to other problems such as the modelling of triphomes in speech, and DNA and protein sequences in molecular biology. The new algorithm is compared with smoothing on a two million word corpus. The methods prove to be about equally accurate, with the hierarchical model using fewer computational resources. ...|$|E
40|$|This work {{combines}} pattern search optimization with {{a statistical}} emulator based on Treed Gaussian Processes (TGP) {{to create a}} new hybrid algorithm. The goal is to use the global <b>probabilistic</b> <b>view</b> provided by TGP to inform the local pattern search and form a more intelligent optimization algorithm. We also propose ways in which the emulator can be used to gain information about the objective function, inform the algorithm stopping rules and provide a probabilistic analysis of the type of convergence. We present the algorithm, a framework for statistically informed optimization, and illustrate the work with numerical results...|$|E
40|$|Draft for Stephen Gaukroger (ed.), Knowledge in Modern Philosophy (Bloomsbury). Gassendi and Hobbes {{knew each}} other, and their {{approaches}} to philosophy often seem similar. They both criticized the Cartesian epistemology of clear and distinct perception. Gassendi engaged at length with skepticism, and also rejected the Aristotelian notion of scientia, arguing instead for a <b>probabilistic</b> <b>view</b> that shows us {{how we can}} move on {{in the absence of}} certain and evident knowledge. Hobbes, in contrast, retained the notion of scientia, which is the best sort of knowledge and involves causal explanation. He thought, however, that this sort of knowledge was only available in geometry and political philosophy...|$|E
40|$|The wind {{characteristics}} {{which should be}} required for the estimation of wind-inducedfailure of bridge structures were discussed from the statistic and <b>probabilistic</b> point of <b>view.</b> Furthermore, the method {{for the evaluation of}} bridge reliability was developed here in use ofdata of {{wind characteristics}} and aerodynamical behavior predicted from wind tunnel test. Finally, some numerical examples on reliability evaluation were shown for a certain box-girder bridge...|$|R
40|$|The {{epidemiological}} literature {{contains an}} ongoing and diversified {{discussion of the}} Hill criteria. This article offers a philosophical analysis of the criteria, showing that the criteria are related to two different views of causality. The authors argue that the criteria of strength, specificity, consistency, experiment, and biological gradient are related to a <b>probabilistic</b> regularity <b>view</b> of causality, whereas the criteria of coherence, plausibility, and analogy are related to a generative view of causality. The criterion of temporality {{is not related to}} either view, but may in contrast be central in inferring direction from cause to effect. The authors illuminate the aim and limitations of the various criteria that need to be included when discussing them...|$|R
40|$|The great {{randomness}} {{involved in}} the masonry decay phenomenon, due to environmental attacks, suggests studying it from a <b>probabilistic</b> point of <b>view.</b> Here, the study of evolution of the stone masonry decay {{has been carried out}} applying two different approaches on experimental data collected on on-site models. Results are very close, therefore the choice of the approach appears depending on the available data and the monitoring time only...|$|R
