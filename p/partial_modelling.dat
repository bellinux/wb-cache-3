9|4806|Public
40|$|AbstractThis paper {{presents}} {{an approach to}} ensure correctness of composed systems. It takes into consideration that correctness can usually be achieved only {{to a certain degree}} (except for some small and very mission-critical applications) and complete specifications are usually not practicable. By modelling the parts, the composition activities and the requirements specification we automise the checking procedures using model checking. An important issue hereby is that our approach allows <b>partial</b> <b>modelling</b> and specification...|$|E
40|$|The H to tau tau decays {{form the}} prime channel for the {{measurement}} of the Higgs boson state and tests of the CP invariance of Higgs boson couplings. A previous study has shown the viability of deep learning techniques for the measurement. In this paper, the study is expanded. Effects due to the <b>partial</b> <b>modelling</b> of experimental effects are discussed. Furthermore, systematics due to ? decay modelling for complex cascade decays to tau^pm to a_ 1 ^pm nu_tau to rho^ 0 pi^pm nu_tau to 3 pi^± nu_tau are also addressed. Various parameterisations are considered using low-energy collision data. Comment: 13 pages, 4 figure...|$|E
40|$|Abstract: The Foundation for Intelligent Physical Agents (FIPA) {{provides}} a {{rich set of}} standards for implementing industrial scale multi-agent infrastructures. Despite its manifold possibilities for achieving coordinated action execution based on interaction protocols, it still lacks direct support of multi-agent planning and scheduling for goal directed action execution. In this paper, we discuss a design strategy to integrate Design-to-Criteria (DTC) scheduling using the Framework for Task Analysis, Environment Modeling and Simulation (TÆMS) for explicit <b>partial</b> <b>modelling</b> of coordination issues into FIPA infrastructures, as represented by the Java Agent DEvelopment Framework (JADE). Following the notion of “coordination as a service”, we exploit the infrastructural facilities of the FIPA multi-agent platform, and re-use FIPA interaction protocols for exchange of partial TÆMS structures, {{as well as for}} committing to action execution. ...|$|E
40|$|The {{process of}} {{analysis}} and design in structural engineering requires {{the consideration of}} different <b>partial</b> <b>models,</b> for example loading, structural materials, structural elements, and analysis types. The various <b>partial</b> <b>models</b> are combined by coupling several of their components. Due to {{the large number of}} available <b>partial</b> <b>models</b> describing similar phenomena, many different model combinations are possible to simulate the same aspects of a structure. The challenging task of an engineer is to select a model combination that ensures a sufficient, reliable prognosis. In order to achieve this reliable prognosis of the overall structural behavior, a high individual quality of the <b>partial</b> <b>models</b> and an adequate coupling of the <b>partial</b> <b>models</b> is required. Several methodologies have been proposed to evaluate the quality of <b>partial</b> <b>models</b> for their intended application, but a detailed study of the coupling quality is still lacking. This paper proposes a new approach to assess the coupling quality of <b>partial</b> <b>models</b> in a quantitative manner. The approach is based on the consistency of the coupled data and applies for uni- and bidirectional coupled <b>partial</b> <b>models.</b> Furthermore, the influence of the coupling quality on the output quantities of the <b>partial</b> <b>models</b> is considered. The functionality of the algorithm and the effect of the coupling quality are demonstrated using an example of coupled <b>partial</b> <b>models</b> in structural engineering...|$|R
40|$|Uncertainty is {{pervasive}} in Model-based Software Engineering. In previous work, we have proposed <b>partial</b> <b>models</b> {{as a way}} to explicate uncertainty during <b>modeling.</b> Using <b>partial</b> <b>models,</b> modelers can perform certain forms of reasoning, like checking properties, without the having to prematurely resolve uncertainty. In this paper, we present a strategy for encoding <b>partial</b> <b>models</b> into different reasoning formalisms and conduct an empirical study aimed to compare the effectiveness of these formalisms for checking properties of <b>partial</b> <b>models.</b> 1...|$|R
40|$|Abstract. In Model Driven Engineering a {{model is}} a graph of objects that {{conforms}} to a meta-model {{and a set of}} constraints. The meta-model and the constraints declaratively restrict models to a valid set. Models are used to represent the state and behaviour of software systems. They are specified in visual modelling environments or automatically synthesized for program testing. In such applications, a modeller is interested in specifying a <b>partial</b> <b>model</b> or a set of <b>partial</b> <b>models</b> which has a structure and associated properties that interests him/her. Completing a <b>partial</b> <b>model</b> manually can be an extremely tedious or an undecidable task since the modeller has to satisfy tightly-coupled and arbitrary constraints. We identify this to be a problem and present a methodology to solve (if a solution can be found within certain time bounds) it using constraint logic programming. We present a transformation from a <b>partial</b> <b>model,</b> its meta-model, and additional constraints to a constraint logic program. We solve/query the CLP to obtain value assignments for undefined properties in the <b>partial</b> <b>model.</b> We then complete the <b>partial</b> <b>model</b> using the value assignments {{for the rest of the}} properties. ...|$|R
40|$|We propose an {{estimating}} function {{method for}} two related applications, matched pair studies and studies with errors in covariates under a functional model, where a mismeasured unknown scalar covariate {{is treated as}} a fixed nuisance parameter. Our method addresses the severe inferential problem that is posed by an abundance of nuisance parameters in these two applications. We propose orthogonal locally ancillary estimating functions for these two applications that depend on merely the mean model and <b>partial</b> <b>modelling</b> of the variances of the observations (and observed mismeasured covariate, if applicable), and we achieve first-order bias correction of inferences under a 'small dispersion and large sample size' asymptotic. Simulation results confirm that the estimator proposed is largely improved over that using a regular profile estimating function. We apply the approach proposed to a length of hospital stay study with a mismeasured covariate. Copyright 2007 Royal Statistical Society. ...|$|E
40|$|The general {{problem of}} {{managing}} a remotely situated vehicle or manipulator system is discussed, {{from the point}} of view of what level of autonomy is feasible. Assuming continued presence of a human operator (HO) in the loop, the advantages of Director / Agent (D/A) control are discussed, as a means of alleviating the tedium of conventional continuous manual teleoperation. In order to realise a viable D/A system, the HO must be able to communicate accurate quantitative 3 D task related data to the robot controller. In an unstructured environment, such information is typically neither available a priori nor readily obtainable during task execution. An Augmented Reality display system is introduced as a means to obtain such quantitative measurement data online, via <b>partial</b> <b>modelling</b> of the remote site using a Virtual Tape Measure. Some of the design considerations for this system are discussed and sample measurement accuracy and precision data are presented. I. INTRODUCTION: DIRECTOR/AGE [...] ...|$|E
40|$|The work {{carried out}} for this thesis {{represents}} {{part of a larger}} study being followed in the Department of Chemical Engineering, University of Surrey into the processes of heat transfer taking place in rotary kilns with particular emphasis being placed on those in the Cement Industry. A widely used method of investigation of the performance of furnaces is that of <b>partial</b> <b>modelling</b> of the flow taking place within the system. This approach allows predictions to be made from model work concerning the shape and length of the flame within the real furnace. In cases such as the rotary kiln, where the flame may be defined as a turbulent jet diffusion flame, the mixing of the oxidant (air) with the fuel is of the utmost importance in dictating the flame characteristics. Consequently the approach of isothermal <b>partial</b> <b>modelling</b> has been applied to an accurate model of a specific industrial installations from which general conclusions concerning flow patterns in kiln systems can be made. The two most important aspects of such modelling procedures are firstly to obtain an accurate geometric model, and, secondly, to ensure that the flows produced in the model system are representative of actual practice. The first of these is relatively simple to attain; the second is more difficult. In order to overcome the limitations of published literature concerning flowrates in kiln systems, original industrial data was obtained and analysed in some detail, using relevant jet theories to produce a range of operating conditions suitable for use in the model. Isothermal model systems operating on air and water have been designed and constructed. Prom these flow pattern diagrams have been produced and presented in the results. The model studies indicate that the degree of recirculation in kilns is low to moderate and does not take place symmetrically about the kiln axis. The primary jet is deflected by the asymmetry of the secondary flow, the distribution of which is determined by the inlet geometry to the kiln. Jet deflection increases as the velocity ratio, uo /ua is decreased. The flow patterns are of sufficient generality for wide application for within the limits of the rules of isothermal modelling...|$|E
40|$|Simulating and {{controlling}} physiological phenomena are notoriously complex tasks to tackle and require accurate {{models of the}} phenomena of interest. Currently, most physiological processes are described {{by a set of}} <b>partial</b> <b>models</b> capturing specific aspects of the phenomena, and usually their composition does not produce effective comprehensive models. A current open issue is thus the development of techniques able to effectively describe a phenomenon starting from <b>partial</b> <b>models.</b> This is particularly relevant for heart rate regulation modeling where a large number of heterogeneous <b>partial</b> <b>models</b> exists. In this paper we make the original proposal of adopting a multiagent paradigm, called anthropic agency, to provide a powerful and flexible tool for combining <b>partial</b> <b>models</b> of heart rate regulation for adaptive cardiac pacing applications. The <b>partial</b> <b>models</b> are embedded in autonomous computational entities, called agents, that cooperatively negotiate in order to smooth their conflicts on the values of the variables forming the global model the multiagent system provides. We experimentally evaluate our approach and we analyze its properties...|$|R
40|$|Abstract—Model transformations are {{traditionally}} designed {{to operate on}} models that do not contain uncertainty. In previous work, we have developed <b>partial</b> <b>models,</b> i. e., models that explicitly capture uncertainty. In this paper, we study the transformation of <b>partial</b> <b>models.</b> We define the notion of correct lifting of transformations {{so that they can}} be applied to <b>partial</b> <b>models.</b> For this, we encode transformations as transfer predicates and describe the mechanics of applying transformations using logic. We demonstrate the approach using two example transformations (addition and deletion) and outline a method for testing the application of transformations using a SAT solver. Reflecting on these preliminary attempts, we discuss the main limitations and challenges and outline future steps for our research on <b>partial</b> <b>model</b> transformation. I. INTRODUCTION AND MOTIVATING EXAMPL...|$|R
40|$|AI {{planning}} research typically {{assumes that}} complete action models are given. On the other hand, popular approaches in reinforcement learning such as Q-learning completely eschew models and planning. Neither {{of these approaches}} is satisfactory to achieve robust human-level AI that includes planning and learning in rich structured domains. In this paper, we introduce the idea of planning with <b>partial</b> <b>models.</b> While complete action models may be exponentially large, some domains may still have polynomial size <b>partial</b> <b>models</b> which are adequate for hierarchical planning. We describe algorithms for planning with <b>partial</b> <b>models</b> {{in the context of}} serializable domains, and for learning them from observation. Empirically, we demonstrate the effectiveness of <b>partial</b> <b>models</b> for learning and hierarchical planning in versions of the taxi domain. ...|$|R
40|$|System {{dynamics}} is {{a method}} enabling simulation and subsequent analysis of various socio-economic problems. Even though it was founded about fifty years ago, it is relatively new and little used in the Czech Republic. It has a good practice {{to make use of}} molecules, standard <b>partial</b> <b>modelling</b> structures which make the modelling processes easier and more effective. The objective {{of this article is to}} introduce and provide such molecule of an aging chain for the Czech Republic population. To increase its usefulness the aging chain is disaggregated and divided into two chains, one for each sex. The aging chain molecule consists of stock and flow diagram, a system of differential equations and parameters quantified on the basis of demographic data for Czech Republic. Proposed model of aging chain also capture a special phenomenon of the Czech population – the postponing of motherhood and thus the increase in average age of mothers. This fact led to special model structure that is uncommon for existing aging chains of different populations. The model is constructed on the basis of official demographic data of the Czech Statistical Office and the results of the simulation are compared with the surveyed data. The intersection of data sources resulted into disaggregation of population into twelve age cohorts. The chain is created to serve as a molecule for more complex models. Therefore, variables functioning as interface for implementation into such models are indicated in the text...|$|E
40|$|By using non-dimensional Navier–Stokes {{equations}} {{in systems}} where <b>partial</b> <b>modelling</b> complications can be avoided, it is shown that geometrically similar systems can exhibit identical behaviour {{but according to}} different time scales where the latter are also within our own control. These models indicate that the physical nature of time {{is not related to}} a fundamental constant, but the passage of time can have a different but still constant value in a particular system of our own choosing. This observation also adds to our knowledge relat-ing to the dichotomy of interpreting time either as a flowing parameter or, alternatively, just accepting it as a part of space-time. The observation adds evidence in favour of both viewpoints. The conclusions also seem relevant to biological species, chemical processes in general and other branches of physics. Using earlier work of Prigogine and others, it also appears that instantaneous time has important properties dividing past and future time into two segments which differ fundamentally in physical characteristics. This seems to explain the ‘raison d’tre ’ of the second law of thermodynamics and the necessarily asymmetrical nature of time in our own world where mathematical symmetry of physical laws is the norm. This entropic time barrier also seems to explain the physically intangible nature of past events and their possible natural importance as former lower entropy forms of existence. It is concluded that these physical features of time are necessary for the existence of any form of life and Darwinian evolution, in particular. The conclusions may also help to throw further light on other suggested theories and observations in physics and the role of quantum decoherence in life and its adaptive ability...|$|E
40|$|Purpose As {{highlighted}} in recent reviews, {{there is a}} need to harmonise the way life cycle assessment (LCA) of perennial crops is conducted. In most published LCA on perennial crops, the modelling of the agricultural production is based on data sets for just one productive year. This may be misleading since performance and impacts of the system may greatly vary year by year. The purposes of this study are to analyse how <b>partial</b> <b>modelling</b> of the perennial cycle through non-holistic data collection may affect LCA results and to make recommendations. Methods Three modelling choices for the perennial crop cycle were tested in parallel in two contrasted LCA case studies: oil palm fruits from Indonesia, and small citrus from Morocco. Modelling choices tested were as follows: (i) a chronological modelling over the complete crop cycle of orchards, (ii) a 3 -year average from the productive phase, and (iii) various single years from the productive phase. In both case studies, the system boundary was a cradle-to-farm gate with a functional unit of 1 kg fresh fruits. LCA midpoint impacts were calculated with ReCiPe 2008 in Simapro©V. 7. We first analysed how inputs, yields and potential impacts varied over time. We then analysed process contributions in the baseline model, i. e. the chronological modelling, and finally compared LCA results for the various perennial modelling choices. Results and discussion Agricultural practices, yields and impacts varied over the years especially during the first 3 – 9 years depending on the case study. In both case studies, the modelling choices to account or not for the whole perennial cycle drastically influenced LCA results. The differences could be explained by the inclusion or not of the yearly variability and the accounting or not of the immature phase, which contributed to 7 – 40 or 6. 5 – 29 % of all impact categories for oil palm fruit and citrus, respectively. Conclusions The chosen approach to model the perennial cycle influenced the final LCA results for two contrasted case studies and deserved specific attention. Although data availability may remain the limiting factor in most cases, assumptions can be made to interpolate or extrapolate some data sets or to consolidate data sets from chronosequences (i. e. modular modelling). In all cases, we suggest that the approach chosen to model the perennial cycle and the representativeness of associated collected data should be made transparent and discussed. Further research work is needed to improve the understanding and modelling of perennial crop functioning and LCA assessment. (Résumé d'auteur...|$|E
40|$|The {{problem of}} <b>partial</b> <b>model</b> {{matching}} is studied {{for the case}} of multi-input/multi-output linear time-invariant systems. Using a regular static state feedback law, the necessary and sufficient conditions for the problem to have a solution are established. The general analytic expressions of the controller matrices are derived. For the case of single-input/single-output systems sufficient conditions are derived for {{the solution of the}} <b>partial</b> <b>model</b> matching problem with simultaneous stabilizability For the same type of systems the necessary and sufficient conditions for the solution of the <b>partial</b> <b>model</b> matching problem with simultaneous regulation of the free response of the closed-loop system are established. Finally, the problem of <b>partial</b> <b>model</b> matching,,ia regular static measurement output feedback, is solved for the case of multi-input/multi-output systems...|$|R
40|$|The {{geometry}} of the diesel fuel injection nozzle and fuel flow characteristics in the nozzle significantly affects the processes of fuel atomisation, combustion and formation of pollutant emissions in a diesel engine. To improve the processes of fuel injection and spray formation CFD packages are commonly used. Since CPU times are often high, <b>partial</b> <b>models</b> are used for analysis. The results of the analysis by using <b>partial</b> <b>models</b> are model dependent, so {{the differences between the}} results using different models can occur. In this paper CFD analysis for different <b>partial</b> <b>models</b> of a 4 -hole nozzle were made. The objective of the research was to find the proper model to be used for fast analysis of existing nozzle geometry. Several <b>partial</b> <b>models</b> of the nozzle were made. The results were compared with the results of measurements at steady state conditions...|$|R
5000|$|The unit clauses {{that are}} present {{in a set of}} clauses or can be derived from it can be stored in form of a <b>partial</b> <b>model</b> (this <b>partial</b> <b>model</b> may also contain other literals, {{depending}} on the application). In this case, unit propagation is performed based on the literals of the <b>partial</b> <b>model,</b> and unit clauses are removed if their literal is in the model. In the example above, the unit clause [...] would be added to the partial model; the simplification of the set of clauses would then proceed as above with the difference that the unit clause [...] is now removed from the set. The resulting set of clauses is equivalent to the original one under the assumption of validity of the literals in the <b>partial</b> <b>model.</b>|$|R
40|$|Abstract — Simulating and {{controlling}} physiological phenomena are notoriously complex tasks to tackle and require accurate {{models of the}} phenomena of interest. Currently, most physiological processes are described {{by a set of}} <b>partial</b> <b>models</b> capturing specific aspects of the phenomena, and usually their composition does not produce effective comprehensive models. A current open issue is thus the development of techniques able to effectively describe a phenomenon starting from <b>partial</b> <b>models.</b> This is particularly relevant for heart rate regulation modelling where a large number of heterogeneous <b>partial</b> <b>models</b> exists. In this paper we make the original proposal of adopting a multiagent paradigm, called anthropic agency, to provide a powerful and flexible tool for combining <b>partial</b> <b>models</b> of heart rate regulation for adaptive cardiac pacing applications. The <b>partial</b> <b>models</b> are embedded in autonomous computational entities, called agents, that cooperatively negotiate in order to smooth their conflicts on the values of the variables forming the global model the multiagent system provides. We experimentally evaluate our approach and we analyze its properties...|$|R
40|$|Abstract—Simulating and {{controlling}} physiological phenomena are notoriously complex tasks to tackle and require accurate mod-els of the phenomena of interest. Currently, most physiological processes are {{described by a}} set of <b>partial</b> <b>models</b> capturing spe-cific aspects of the phenomena, and usually their composition does not produce effective comprehensive models. A current open issue is thus the development of techniques able to effectively describe a phenomenon starting from <b>partial</b> <b>models.</b> This is particularly rel-evant for heart rate regulation modeling where a large number of heterogeneous <b>partial</b> <b>models</b> exists. In this paper we make the orig-inal proposal of adopting a multiagent paradigm, called anthropic agency, to provide a powerful and flexible tool for combining <b>partial</b> <b>models</b> of heart rate regulation for adaptive cardiac pacing appli-cations. The <b>partial</b> <b>models</b> are embedded in autonomous compu-tational entities, called agents, that cooperatively negotiate in order to smooth their conflicts on the values of the variables forming the global model the multiagent system provides. We experimentally evaluate our approach and we analyze its properties. Index Terms—Cooperative negotiation, multiagent systems, multisensor pacemakers, rate-adaptive cardiac pacing. I...|$|R
40|$|The {{principal}} {{contributions of}} this work are (1) that the alternating fixpoint <b>partial</b> <b>model</b> {{is identical to the}} well-founded <b>partial</b> <b>model,</b> and (2) that alternating fixpoint logic is at least as expressive as fixpoint logic on all structures. Also, on finite structures, fixpoint logic is as expressive as alternating fixpoint logic...|$|R
40|$|An {{agent in}} an unknown {{environment}} {{may wish to}} learn a model that allows it to make predictions about future events and anticipate the consequences of its actions. Such a model can greatly enhance the agent's ability to make good decisions. However, in environments {{like the one in}} which we live, which is stochastic, partially observable, and high dimensional, learning a model is a challenge. One approach when faced with a difficult model learning problem is not to model the entire system. Instead, one might focus on the most important aspects of the environment and give up on modeling complicated, irrelevant phenomena. This intuition can be formalized using <b>partial</b> <b>models,</b> which are models that make only a restricted set of predictions in only a restricted set of circumstances. Because a <b>partial</b> <b>model</b> has limited prediction responsibilities, it may be significantly simpler than a complete <b>model.</b> <b>Partial</b> <b>models</b> have been studied in many contexts, mostly under the Markov assumption, where the agent is assumed to have access to the full state of the world. In this setting, predictions can be learned directly as functions of state and the process of learning a <b>partial</b> <b>model</b> is often as simple as estimating only the desired predictions and omitting the rest from the model. As such, much of the relevant work has focused on the challenging question of which <b>partial</b> <b>models</b> should be learned (rather than how to learn them). In the partially observable case, however, where state is assumed to be hidden from the agent, the basic problem of how to learn a <b>partial</b> <b>model</b> poses significant challenges. The goal of this thesis is to provide general results and methods for learning <b>partial</b> <b>models</b> in partially observable systems. The main challenges posed by partial observability are formalized and learning methods are developed to address these issues. The methods presented are demonstrated empirically to learn <b>partial</b> <b>models</b> in systems that are too complex for standard, complete model learning methods. Finally, many <b>partial</b> <b>models</b> are learned and composed to form complete models that are used for model-based planning in high dimensional arcade game examples...|$|R
40|$|Summary {{statistics}} of historical fit (Sterman, 1984) {{have become a}} standard validity test for system dynamics models. These statistics, however, are also useful to analyze and diagnose the results of <b>partial</b> <b>model</b> calibrations. <b>Partial</b> <b>model</b> calibration normally requires an iterative process of structure formulation, parameter estimation, analysis of fit and residuals, and mode...|$|R
40|$|In {{this note}} we {{consider}} <b>partial</b> <b>model</b> categories, {{by which we}} mean relative categories that satisfy a weakened version of the model category axioms involving only the weak equivalences. More precisely, a <b>partial</b> <b>model</b> category will be a relative category that has the two out of six property and admits a 3 -arrow calculus. We then show that Charles Rezk's result that the simplicial space obtained from a simplicial model category by taking a Reedy fibrant replacement of its simplicial nerve is a complete Segal space also holds for these <b>partial</b> <b>model</b> categories. We also note that conversely every complete Segal space is Reedy equivalent to the simplicial nerve of a <b>partial</b> <b>model</b> category and in fact of a homotopically full subcategory of a category of diagrams of simplicial sets. Comment: 12 pages. Comments always welcom...|$|R
5000|$|Calculates {{value of}} {{external}} criterion for <b>partial</b> <b>models</b> using sample B.|$|R
40|$|Modeling of {{ultrasonic}} processes {{is typically}} {{characterized by a}} high degree of complexity. Different domains and size scales must be regarded, so that it is rather difficult to build up a single detailed overall <b>model.</b> Developing <b>partial</b> <b>models</b> is a common approach to overcome this difficulty. In this paper a generic but simple software framework is presented which allows to coupe arbitrary <b>partial</b> <b>models</b> by slave modules with well-defined interfaces and a master module for coordination. Two examples are given to present the developed framework. The first one is the parameterization of a load model for ultrasonically-induced cavitation. The piezoelectric oscillator, its mounting, and the process load are described individually by <b>partial</b> <b>models.</b> These <b>partial</b> <b>models</b> then are coupled using the framework. The load model is composed of spring-damper-elements which are parameterized by experimental results. In the second example, the ideal mounting position for an oscillator utilized in ultrasonic assisted machining of stone is determined. <b>Partial</b> <b>models</b> for the ultrasonic oscillator, its mounting, the simplified contact process, and the workpiece's material characteristics are presented. For both applications input and output variables are defined to meet the requirements of the framework's interface...|$|R
40|$|Scalable systems reconstructing {{arbitrary}} {{shapes in}} real time need a cluster of computers and an efficient strategy to share information. Optimizing the performances of the system requires considering how to spread the complexity over the nodes of the cluster. It means {{taking into account the}} kind of information to share between nodes, how to transmit it, and how to merge it given the available bandwidth and the impact of those steps on performances. We present a distributed and scalable volumetric architecture based on an efficient exploitation of interframe redundancy and on an efficient merging of <b>partial</b> <b>models.</b> The architecture is composed of acquisition nodes reconstructing <b>partial</b> <b>models</b> from multiple views and of a master node merging <b>partial</b> <b>models.</b> The master node updates local copies of the <b>partial</b> <b>models</b> with nonredundant information from the acquisition nodes. Then it merges the <b>partial</b> <b>models</b> to produce the volumetric description of the scene. The test of this architecture with a single feature coding visibility, occupancy, and subdivision of space proves its efficiency. The chosen feature allows each camera to see only part of the volume of interest. We show real-time results on a cluster of usual PC platforms...|$|R
5000|$|Estimates {{coefficients}} of <b>partial</b> <b>models</b> using Least squares method and sample A.|$|R
40|$|International audienceThis paper {{presents}} a constrained decomposition methodology with output injection to obtain decoupled <b>partial</b> <b>models.</b> Measured process outputs and decoupled <b>partial</b> <b>model</b> outputs {{are used to}} generate structured residuals for Fault Detection and Isolation (FDI). An algebraic framework is chosen to describe the decomposition method. The constraints of the decomposition ensure that the resulting <b>partial</b> <b>model</b> is decoupled from a given subset of inputs. Set theoretical notions are {{used to describe the}} decomposition methodology in the general case. The methodology is then detailed for discrete-event model decomposition using pair algebra concepts, and an extension of the output injection technique is used to relax the conservatism of the decomposition...|$|R
5000|$|... 1951, 250 (all body styles) 4,640 units (Introduced in March 1951, <b>partial</b> <b>model</b> year tally) ...|$|R
50|$|In {{order to}} find the best {{solution}} GMDH algorithms consider various component subsets of the base function (1) called <b>partial</b> <b>models.</b> Coefficients of these models are estimated by the least squares method. GMDH algorithms gradually increase the number of <b>partial</b> <b>model</b> components and find a model structure with optimal complexity indicated by the minimum value of an external criterion. This process is called self-organization of models.|$|R
40|$|Gödel’s incompleteness {{results show}} that if ZF is consistent, it is {{impossible}} to construct within ZF itself a single object (set) that represents a complete and precise semantic model of ZF. Nevertheless, it has also become clear since then that many kinds of <b>partial</b> <b>models</b> can be constructed within ZF that reveal interesting characteristics of ZF and related formal systems. We develop here one particular class of <b>partial</b> <b>models</b> of ZF, which rely on an extreme form of impredicative reasoning that nevertheless follow the accepted rules of set theory and first-order logic and are constructible within exactly the same variant of ZF as the one being modelled. Some study of these <b>partial</b> <b>models</b> yields interesting results...|$|R
40|$|Abstract—Models {{are good}} at expressing {{information}} that is known but do not typically have support for representing what information a modeler does not know or does not care about at a particular stage in the software development process. <b>Partial</b> <b>models</b> address this {{by being able to}} precisely represent uncertainty about model content. In previous work, we have defined a general approach for defining <b>partial</b> <b>model</b> semantics using a first order logic encoding. In this paper, we use this FO encoding to formally define the conditions for <b>partial</b> <b>model</b> refinement in the manner of the refinement of algebraic specifications. We use this approach to verify both manual refinements and automated transformation-based refinements. We illustrate our approach using example models and transformations. I...|$|R
40|$|Colloque avec actes et comité de lecture. internationale. International audienceWe {{present a}} method for the {{temporal}} properties verification of complex systems. Its interest lies in a coordinated use of both exhaustive analyze and simulation techniques. The model {{is based on a}} unique formalism, called TIOSM (Timed Input output State Machine) which is a specialization of Timed Automata. The exhaustive analysis is done by model checking and concerns only <b>partial</b> <b>models</b> that represent critical parts of the whole system. The results obtained on these <b>partial</b> <b>models</b> are inserted in the global model that can be then simulated. In the paper, we give rules for defining <b>partial</b> <b>model,</b> analyzing them and integrating the results in the global model, that can therefore simulated...|$|R
5000|$|... #Caption: <b>Partial</b> <b>models</b> of features, {{projected}} into 3D, {{constructed from}} nearby {{views of a}} teddy-bear. Taken from et al. 2004.|$|R
5000|$|A <b>Partial</b> <b>Model</b> for Quines [...] "New Foundations", The Journal of Symbolic Logic, Vol. 19, No. 3, pp. 197-200, September 1954 ...|$|R
