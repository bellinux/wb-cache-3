518|26|Public
25|$|Wirth {{was born}} <b>profoundly</b> <b>deaf.</b> He {{is the founder}} and President of CABSS Assistance Center for Deaf and Deafblind Children / Centro Assistenza per Bambini Sordi e Sordociechi Onlus (CABSS), a {{non-profit}} association dedicated to supporting deaf and deafblind children and their families.|$|E
25|$|Glennie {{has been}} <b>profoundly</b> <b>deaf</b> {{since the age}} of 12, having started to lose her hearing from the age of 8. This does not inhibit her ability to perform at an {{international}} level. She regularly plays barefoot during both live performances and studio recordings to feel the music better.|$|E
25|$|On November 17, 1956, Sills married {{journalist}} Peter Greenough, of the Cleveland, Ohio, newspaper The Plain Dealer {{and moved}} to Cleveland. She had two children with Greenough, Meredith ("Muffy") in 1959 and Peter, Jr. ("Bucky") in 1961. Muffy (died July 3, 2016) was <b>profoundly</b> <b>deaf</b> and had multiple sclerosis; Peter, Jr. is severely mentally disabled. Sills restricted her performing schedule {{to care for her}} children.|$|E
5000|$|... and the {{acquisition}} of reading by deaf children and adults. In this work, she demonstrated the surprising degree to which reading success among the <b>profoundly</b> and prelingually <b>deaf</b> was coupled to the existence and use of phonological mental representations, representations that were formed {{without the benefit of}} ever having heard spoken language ...|$|R
40|$|Publisher’s {{permission}} requested and denied. Over {{the last}} two decades many have contributed to the understanding of how to help <b>profoundly</b> and totally <b>deaf</b> patients understand speech through electrical stimulation of the auditory nerve. We have referred to some of the work in a review of speech processing for cochlear implant prostheses. Restricted Access: This resource is not available from the Digital Repository for copyright reasons. This is a citation and abstract only record...|$|R
40|$|Tinnitus {{management}} in the <b>profoundly</b> and totally <b>deaf</b> Terms and Conditions: Terms and Conditions: Copyright in works deposited in Minerva Access is retained by the copyright owner. The work may not be altered without permission from the copyright owner. Readers may only, download, print, and save electronic copies of whole works for their own personal non-commercial use. Any use that exceeds these limits requires permission from the copyright owner. Attribution is essential when quoting or paraphrasing from these works...|$|R
25|$|In May 2015, Wirth {{published}} his book “Il silenzio è stato il mio primo compagno di giochi » (translation: Silence {{was my first}} playmate), an autobiography that tells of the complex life of a man born <b>profoundly</b> <b>deaf</b> and forced to confront the prejudices of others, starting with those of his own family. The copyright fees are donated to non-profit CABSS (Assistance Center for Deaf and Deafblind Children), the association founded by Roberto Wirth dedicated to the support of deaf and deafblind children.|$|E
25|$|There {{are mixed}} results in how {{important}} phonological information is to deaf individuals when reading {{and when that}} information is obtained. Alphabets, abugidas, abjads, and syllabaries all seem to require the reader/writer {{to know something about}} the phonology of their target language prior to learning the system. <b>Profoundly</b> <b>deaf</b> children {{do not have access to}} the same auditory base that hearing children do. Orally trained deaf children do not always use phonological information in reading tasks, word recognition tasks or homophonic tasks; however, deaf signers who are not orally trained do utilize phonological information in word-rhyming tasks. Furthermore when performing on tasks with phonologically confusable initial sounds, hearing readers made more errors than deaf readers. Yet when given sentences that are sublexically confusable when translated into ASL, deaf readers made more errors than hearing readers. The body of literature clearly shows that skilled deaf readers can employ phonological skills, even if they don’t all the time; without additional longitudinal studies it is uncertain if a <b>profoundly</b> <b>deaf</b> person must know something about the phonology of the target language to become a skilled reader (less than 75% of the deaf population) or if by becoming a skilled reader a deaf person learns how to employ phonological skills of the target language.|$|E
25|$|Special needs {{students}} {{are entitled to}} Ongoing Resource Scheme (ORS) funding, which is used for facilitating the adaption of the curriculum to fit the student, funding of teacher aides and specialists, and procuring any special equipment required. There are three levels of funding based on the student's needs: very high, high or combined moderate. For example, a student who is totally blind or deaf is classified as very high needs, while a student who is partially sighted (6/36 or worse) or severely or <b>profoundly</b> <b>deaf</b> (71dB loss or worse) is classified as high needs. ORS funding is permanent, so it continues until the student leaves school.|$|E
25|$|Bell's father, grandfather, {{and brother}} {{had all been}} {{associated}} with work on elocution and speech and both his mother and wife were <b>deaf,</b> <b>profoundly</b> influencing Bell's life's work. His research on hearing and speech further led him to experiment with hearing devices which eventually culminated in Bell being awarded the first U.S. patent for the telephone in 1876. Bell considered his invention an intrusion on his real work as a scientist and refused to have a telephone in his study.|$|R
40|$|In hearing people, silent speechreading generates {{bilateral}} activation in superior temporal regions specialised for {{the perception}} of auditory speech [Science 276 (1997) 59; Neuroreport 11 (2000) 1729; Proceedings of the Royal Society London B 268 (2001) 451]. In the present study, FMRI {{data were collected from}} deaf and hearing volunteers while they speechread numbers and during a control task in which they counted nonsense mouth movements (gums). Brain activation for silent speechreading in oral deaf participants was found primarily in posterior cingulate cortex and hippocampal/lingual gyri. In contrast to the pattern observed in the hearing group, deaf participants showed no speechreading-specific activation in left lateral temporal regions. These data suggest that acoustic experience shapes the functional circuits for analysing speech. We speculate on the functional role, the posterior cingulate gyros may play in speechreading by <b>profoundly</b> congenitally <b>deaf</b> people...|$|R
40|$|Copyright {{permission}} {{has been}} sought but has not been received, therefore this material will remain restricted. In the recent ministerial report on deaf education in Victoria, the predicted outcome of deaf school leavers was that they would only achieve a grade three or four level of reading. One hundred and ninety five <b>profoundly,</b> prelingually <b>deaf</b> students from grade four to year twelve in Victoria were tested using the Stanford Reading Comprehension test. Although the results showed {{a wide range of}} reading ability among the students, the overall mean reading grade equivalent was grade 5. 0 and over 40 % were reading at average or above average levels. Sixty-nine percent of deaf "school leavers " were reading at higher levels than the grade four level assumed in the Victorian ministerial report and the average "school leaver" reading grade equivalent was at a grade 6. 0 level. Restricted Access: This resource is not available from the Digital Repository for copyright reasons. This is a citation and abstract only record...|$|R
25|$|Usher {{syndrome}} {{has three}} clinical subtypes, denoted as I, II, and III. People with Usher I are born <b>profoundly</b> <b>deaf,</b> {{and begin to}} lose their vision {{in the first decade}} of life. They also exhibit balance difficulties, and learn to walk slowly as children, due to problems in their vestibular system. People with Usher II are not born deaf, but do have hearing loss. They do not seem to have noticeable problems with balance; they also begin to lose their vision later (in the second decade of life) and may preserve some vision even into middle age. People with Usher syndrome III are not born deaf, but experience a gradual loss of their hearing and vision; they may or may not have balance difficulties.|$|E
25|$|Usher {{syndrome}} is a variable condition; {{the degree of}} severity is not tightly linked to whether it is Usher I, II, or III. For example, someone with type III may be unaffected in childhood, but go on to develop a profound hearing loss and a very significant loss of sight by early to midadulthood. Similarly, someone with type I, who is therefore <b>profoundly</b> <b>deaf</b> from birth, may keep good central vision until the sixth decade of life, or even beyond. People with type II, who have useful hearing with a hearing aid, can experience {{a wide range of}} severity of the RP. Some may maintain good reading vision into their 60s, while others cannot see to read while still in their 40s.|$|E
2500|$|Dame Evelyn Elizabeth Ann Glennie, [...] (born 19 July 1965) is a Scottish virtuoso percussionist. She {{has been}} <b>profoundly</b> <b>deaf</b> {{since the age}} of 12 and claims to have taught herself to hear with parts of her body other than her ears.|$|E
25|$|Born in Edinburgh, Scotland, Bell {{moved to}} Canada {{with his family}} in 1870 {{following}} the deaths of his brothers, and a year later moved to Boston to teach at a special day school for deaf children. Both Bell's mother and wife were <b>deaf,</b> <b>profoundly</b> influencing his life's work. He became a renowned educator by opening a private normal class to train teachers of speech to the deaf and as a professor of vocal physiology and the mechanics of speech at Boston University. During this time he also invented an improved phonautograph, the multiple telegraph, the speaking telegraph, or telephone, and numerous other devices.|$|R
40|$|A {{cochlear}} implant restores some hearing by electrically stimulating residual auditory nerve fibers in the cochlea. The {{cochlear implant}} represents a major {{scientific and technological}} breakthrough and is now providing hearing for thousands of <b>profoundly</b> and totally <b>deaf</b> people around the world. In this paper, we review the present multiple-channel cochlear implant technology and explores potential applications of micro-electro-mechanical system (MEMS) technology. A new generation of electrode arrays based on the silicon micromachining technology is presented. Approaches {{in the use of}} MEMS technology for a middle ear acoustic sensor in a totally implantable prosthesis is also discussed, with key issues for its development highlighted. 29 - 30 OctoberOpen Acces...|$|R
40|$|Contemporary {{auditory}} prostheses (Bcochlear im-plants^) employ {{arrays of}} stimulating electrodes {{implanted in the}} scala tympani of the cochlea. Such arrays have been implanted in some 100, 000 <b>profoundly</b> or severely <b>deaf</b> people worldwide and arguably are the most successful of present-day neural prostheses. Never-theless, most implant users show poor understanding of speech in noisy backgrounds, poor pitch recognition, and poor spatial hearing, even when using bilateral implants. Many of these limitations {{can be attributed to}} the remote location of stimulating electrodes relative to excitable cochlear neural elements. That is, a scala tympani electrode array lies within a bony compartment filled with electrically conductive fluid. Moreover, scal...|$|R
2500|$|He {{has been}} <b>profoundly</b> <b>deaf</b> since age 17, which he blamed on working in noisy conditions. In December 2009 he was {{fitted with a}} {{cochlear}} implant. He is the Ambassador for [...] and is instrumental in raising awareness for the Deaf and Hard of Hearing communities.|$|E
2500|$|Leah Coleman as Leah, one of {{the main}} {{children}} in the show. Leah is the inspiration behind the creation of Signing Time! Diagnosed as <b>profoundly</b> <b>deaf</b> at 14 months old. Leah is now [...] In fourth grade, she garnered national attention for winning first place in her school spelling bee. Leah received a cochlear implant in January 2004.|$|E
2500|$|The {{simplest}} {{approach to}} diagnosing Usher syndrome is {{to test for}} the characteristic chromosomal mutations. An alternative approach is electroretinography, although this is often disfavored for children, since its discomfort can also make the results unreliable. Parental consanguinity is {{a significant factor in}} diagnosis. [...] Usher syndrome I may be indicated if the child is <b>profoundly</b> <b>deaf</b> from birth and especially slow in walking.|$|E
40|$|Processes {{underlying}} {{reading in}} <b>profoundly</b> congenitally <b>deaf</b> children were investigated in three experiments using the Stroop paradigm, where subjects {{were required to}} respond to coloured letter strings displayed on a video-monitor. Each experiment examined two response measures: A manual one where subjects pressed the button corresponding to the appropriate colour, and a colour-naming task. Unpronounceable letter strings, pronounceable non-words, colour related and unrelated words were displayed as well as colour words. In both deaf and hearing children of similar reading skill the pattern was very similar. Colour words generated most interference in the vocal, least in the manual task, suggesting automatic access to word meaning (the manual task) and, additionally, to word pronunciation (the vocal task). In a second experiment, where unique letter strings were presented in different colours, the same general pattern was observed: These results {{are not limited to}} repeated associative pairings of colours and their names, suggesting that the deaf, like hearing children, have automatic access to word pronunciations in reading. In a third experiment, non-words that were homophones of incongruent colour words also produced interference with output forms for pronounceable letter strings. Taken together, these results indicate that access to orthographic, semantic and even phonological information can occur automatically when deaf children are presented with written words. FLWNAinfo:eu-repo/semantics/publishe...|$|R
40|$|Only <b>profoundly,</b> bilaterally <b>deaf</b> {{adults are}} {{considered}} for evaluation. It {{is necessary to}} determine that the patient's communication ability cannot be improved to any significant degree with conventional hearing aids currently available. Initial assessment consists of audiometry, hearing aid evaluation(s), otological and medical examination, and for patients with no recent experience with hearing aids, a hearing aid trial. Polytome x-rays of temporal bones is carried out to ensure that cochlea structures are not grossly abnormal. Electrical stimulation of the promontory is used to confirm the presence of residual auditory nerve fibers. Where there is an audiometric difference between ears, the poorer ear is chosen for implantation provided {{there are no other}} contraindications. Intensive counselling is carried out to enable patients to make a fully informed decision about implantation. Patients undergo a battery of speech discrimination and lipreading tests with their hearing aid after their hearing aid trial. This is to provide a baseline for comparison with postoperative results and to assess the benefit obtained from the hearing aid. Any significant improvement in test results when using a hearing aid over lipreading alone would be a contraindication for implantation. Medical assessment is carried out as for any major surgery, including pathology, respiratory function tests and cardiovascular assessment. Particular emphasis is placed on infection prevention immediately preoperatively and during surgery. 22 - 24 June 1983 Open Acces...|$|R
40|$|This is a publisher’s {{version of}} an article {{published}} in Annals of Otology, Rhinology & Laryngology published by Annals Publishing Company. This version is reproduced with permission from Annals Publishing Company. [URL] discrimination testing was carried out under clinical trial conditions for eight <b>profoundly</b> postlingually <b>deaf</b> adults to assess the efficacy of a newly developed 22 -channel cochlear prosthesis and speech processor. Three months postoperatively, these patients showed significantly better results with the cochlear prosthesis than for preoperative testing with a conventional hearing aid or vibrotactile aid (following a 6 -month trial with the aid) on each of a series of tests from the Minimal Auditory Capabilities battery. Assessment of lipreading enhancement using standard speech tests, consonant recognition studies, and speech tracking showed significant improvements for each patient when using the cochlear prosthesis. Six patients showed a significant amount of open set speech discrimination without lipreading at levels which have not been reported for single electrode cochlear prostheses. The two patients who performed poorly on these tests both had restricted multiple channel systems due to their disease, one patient being restricted to virtually a single channel system and the other to only ten of the 22 electrodes. These results indicate that this multiple channel cochlear prosthesis has potential as a treatment for profound postlingual deafness over a wide range of etiologies and ages. Open Acces...|$|R
2500|$|Being <b>profoundly</b> <b>deaf</b> since birth, Roberto Wirth {{has always}} been very active in {{associations}} for the deaf. While in Hawaii, he was the Chairman of [...] "Silent Aloha", an association which published a monthly newsletter for the deaf, distributed in the United States. He also served on the Committee for the Disabled of the City of Honolulu and held several speeches on deafness [...] at various conferences of the Governor of Hawaii.|$|E
2500|$|Children who are {{deaf and}} employ a sign {{language}} {{as their primary}} language learn to read in slightly different ways than their hearing counterparts. Much as speakers of oral languages most frequently achieve spoken fluency before they learn to read and write, the most successful <b>profoundly</b> <b>deaf</b> readers first learn to communicate in a sign language. Research {{suggests that there is}} a mapping process, in which features from the sign language are accessed as a basis for the written language, Similar to the way hearing unimodal bilinguals access their primary language when communicating in their second language. <b>Profoundly</b> <b>deaf</b> ASL signers show that fluency in ASL is the best predictor of high reading skills in predicting proficiency in written English. In addition, highly proficient signing deaf children use more evaluative devices when writing than less proficient signing deaf children, and [...] the relatively frequent omission of articles when writing in English by proficient signers may suggest a stage in which the transfer effect (that normally facilitates deaf children in reading) facilitates a mix of the morphosyntactic systems of written English and ASL. Deaf children then appear to map the new morphology, syntax, and lexical choices of their written language onto the existing structures of their primary sign language.|$|E
2500|$|A {{cochlear}} implant (CI) is a surgically implanted electronic device {{that provides a}} sense of sound {{to a person who}} is <b>profoundly</b> <b>deaf</b> or severely hard of hearing in both ears; as of 2014 they had been used experimentally in some people who had acquired deafness in one ear after learning how to speak. Cochlear implants bypass the normal hearing process; they have a sound processor that resides {{on the outside of the}} skin (and generally worn behind the ear) which contains microphones, electronics, battery, and a coil which transmits a signal to the implant. [...] The implant has a coil to receive signals, electronics, and an array of electrodes which is placed into the cochlea, which stimulate the cochlear nerve.|$|E
40|$|Twenty-two {{children}} (5 - 12 years old) {{who were}} <b>profoundly,</b> prelingually <b>deaf</b> were given two tests designed to tap their "theory of mind, " that is, {{their ability to}} attribute indepen-dent mental states to other people. The tests were versions of Baron-Cohen, Leslie, and Frith's Sally-Anne task and of Baron-Cohen's breakfast task. Seventy percent of the chil-dren were successful on all questions requiring belief attribu-tion, a considerably and significantly larger percentage than the 29 % obtained by Peterson and Siegal for a similar sam-ple, though it is still lower than would be expected on the basis on chronological age. Children were universally suc-cessful on questions requiring the attribution of desire. We discuss implications of the findings. A child credited with having a "theory of mind " is able to attribute independent mental states to himself or herself and others in order to predict and explain be-havior (Premack & Woodruff, 1978). Despite the some-what misleading term, this child need only take ac-count of another person's beliefs, desires, and thoughts; it is not assumed {{that he or she}} conceives of these men-tal states as unobservable entities. In other words, a child with a theory of mind need not have postulated any theoretical constructs (quasi-scientifically). For convenience, the term theory of mind will be used in this article as it has frequently been used in the litera-We think the staff and pupils at Elmfidd School in Bristol and the Fran...|$|R
40|$|During {{a visual}} rhyming task, deaf {{participants}} traditionally perform more poorly than hearing participants in making rhyme judgements for written words {{in which the}} rhyme and the spelling pattern are incongruent (e. g. hair/bear). It {{has been suggested that}} deaf participants' low accuracy results from their tendency to rely on orthographic similarity. To test this interpretation more directly, we compared <b>profoundly</b> and prelingually <b>deaf,</b> orally educated participants and hearing participants' accuracy during a visual rhyming judgement task in which the two words of a pair share the orthographic rime, in order to discourage usage of a purely orthographic strategy. Accuracy was lower in deaf than in hearing participants. The gradient of difficulty between items, together with the finding of a significant correlation between accuracy and the consistency of the grapheme to rhyme, suggest that difference in accuracy between groups might be explained by an over regularization in deaf people, which is probably linked to less diversified phonological representations. © 2013 Springer Science+Business Media Dordrecht. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|This is a publisher’s {{version of}} an article {{published}} in The Australian Journal of Otolaryngology 1993. This version is reproduced with permission from Australian Society of Otolaryngology Head and Neck Surgery. Journal also known as: Australian Journal of Oto-laryngologyTinnitus is a common symptom of many cochlear or auditory system pathologies. Since tinnitus is frequently associated with a sensorineural hearing loss, {{it is not surprising that}} a large proportion of <b>profoundly</b> and totally <b>deaf</b> patients describe tinnitus as a symptom. The clinical management of severe tinnitus in these patients is discussed with particular emphasis on the use of electrical stimulation. While cochlear implants appear to provide a measure of relief when being used, significant improvements in the management of severe tinnitus will only occur when we have a greater understanding of the underlying pathophysiology, diagnostic procedures that can accurately establish the site of tinnitus generation, and more objective clinical trial procedures that include the use of controls. Open Acces...|$|R
2500|$|Taylor was <b>profoundly</b> <b>deaf</b> and communicated on-field {{with his}} {{teammates}} in sign language. [...] He {{is credited with}} helping to expand and make universal the use of sign language throughout the modern baseball infield, including {{but not limited to}} the use of pitching signs. [...] According to Sean Lahman in his biography of Taylor, [...] "The Giants didn't just add Taylor to their roster; they embraced him {{as a member of the}} family. [...] Player-manager George Davis learned sign language and encouraged his players to do the same. [...] John McGraw did likewise when he took over as Giants manager in July 1902." [...] In Lawrence Ritter's The Glory of Their Times, Taylor's teammate, Fred Snodgrass, recalled:We could all read and speak the deaf-and-dumb sign language, because Dummy Taylor took it as an affront if you didn't learn to converse with him. [...] He wanted to be one of us, to be a full-fledged member of the team. [...] If we went to the vaudeville show, he wanted to know what the joke was, and somebody had to tell him. [...] So we all learned. [...] We practiced all the time.|$|E
60|$|Miss Miggs replied (still being <b>profoundly</b> <b>deaf)</b> that if Miss Haredale {{stood in}} the way at all, he might make himself quite easy on that score; as she had gathered, from what passed between Hugh and Mr Tappertit when they were last there, that she was to be removed alone (not by them, but by {{somebody}} else), to-morrow night.|$|E
60|$|Of these, {{one was a}} man of six {{or eight}} and fifty, who sat on a chair near one of the entrances of the booth, with his hands folded {{on the top of his}} stick, and his chin {{appearing}} above them. He was a tall, fat, long-bodied man, buttoned up to the throat in a light green coat, which made his body look still longer than it was. He wore, besides, drab breeches and gaiters, a white neckerchief, and a broad-brimmed white hat. Amid all the buzzing noise of the games, and the perpetual passing in and out of the people, he seemed perfectly calm and abstracted, without the smallest particle of excitement in his composition. He exhibited no indication of weariness, nor, to a casual observer, of interest either. There he sat, quite still and collected. Sometimes, but very rarely, he nodded to some passing face, or beckoned to a waiter to obey a call from one of the tables. The next instant he subsided into his old state. He might have been some <b>profoundly</b> <b>deaf</b> old gentleman, who had come in to take a rest, or he might have been patiently waiting for a friend, without the least consciousness of anybody's presence, or fixed in a trance, or under the influence of opium. People turned round and looked at him; he made no gesture, caught nobody's eye, let them pass away, and others come on and be succeeded by others, and took no notice. When he did move, it seemed wonderful how he could have seen anything to occasion it. And so, in truth, it was. But there was not a face that passed in or out, which this man failed to see; not a gesture at any one of the three tables that was lost upon him; not a word, spoken by the bankers, but reached his ear; not a winner or loser he could not have marked. And he was the proprietor of the place.|$|E
40|$|The Nucleus 22 -channel {{cochlear}} implant has been implanted in over 10, 500 patients in 79 countries. {{and used for}} more than 25 languages. It arose {{as a result of}} our early physiological, behavioral and biological research on experimental animals. The historical development of the Nucleus device has been outlined in detail by Clark. Our ongoing research has led to improvements in the way speech is processed with the 22 -channel device that are now resulting in improved speech perception for <b>profoundly</b> totally <b>deaf</b> people that is, on average, better than the speech perception obtained by many deaf people with hearing aids. The multiple-channel {{cochlear implant}} was first approved by the US Food and Drug Administration (FDA) for use in postlinguistically deaf adults in 1985. It was subsequently approved for use in children in 1990. The proportion of children (18 years of age and under) to have now received it is approximately 439 C (4, 500 out of 10. 500). In evaluating improvements in speech processing it is important to design well-controlled studies, and a number of important ones which have previously been published are summarized in this paper. In addition, speech perception results for all the Nucleus speech processing strategies have been obtained four to six months postoperatively from unselected patients presenting to the Cochlear Implant Clinic at the Royal Victorian Eye & Ear Hospital (RVEEH), Melbourne, and are presented in this paper. As results can vary greatly with different durations of experience it is essential to make comparisons at the same time postoperatively. These clinical data are the most complete to date for comparing the Nucleus speech processing strategies. 10 - 14 JuneOpen Acces...|$|R
40|$|This is a publisher’s {{version of}} an article {{published}} in Annals of Otology, Rhinology & Laryngology published by Annals Publishing Company. This version is reproduced with permission from Annals Publishing Company. [URL] sample of 64 postlinguistically <b>profoundly</b> to totally <b>deaf</b> adult cochlear implant patients were tested without lipreading by means of the Central Institute for the Deaf (CID) sentence test 3 months postoperatively. Preoperative promontory stimulation results (thresholds, gap detection, and frequency discrimination), age, duration of profound deafness, cause of deafness, lipreading ability, postoperative intracochlear thresholds and dynamic ranges for electrical stimulation, depth of insertion of the electrode array into the scala tympani, and number of electrodes in use were considered as possible factors that might be related to the postoperative sentence scores. A multiple regression analysis with stepwise inclusion of independent variables Indicated that good gap detection and frequency discrimination during preoperative promontory testing, larger numbers of electrodes in use, and greater dynamic ranges for intracochlear electrical stimulation were associated with better CID scores. The CID scores tended to decrease with longer periods of profound deafness. Open Acces...|$|R
40|$|International audienceFollowing {{auditory}} deprivation, {{the remaining}} sense of vision has shown selective enhancement in visual cognition, {{especially in the}} area of near peripheral vision. Visual acuity is poor in the far periphery and may be an area where sound confers the greatest advantage in hearing persons. Experience with a visuospatial language such as British Sign Language (BSL) makes additional demands on the visual system. To test the different and separable effects of deafness and use of a visuo-spatial language on far peripheral visual processing, we investigated visual reaction times (RTs) and response accuracy to visual stimuli, between 30 ° and 85 ° along the four cardinal and four inter-cardinal meridians. We used three luminances of static, briefly illuminated stimuli in visually normal adults. The cohort tested included <b>profoundly</b> congenitally <b>deaf</b> adults (N = 17), hearing fluent BSL users (N = 8) and hearing non-signing adults (N = 18). All participants were tested using a peripheral forced choice paradigm designed previously to test deaf and hearing children (Codina et al., 2011 a). Deaf adults demonstrated significantly faster RTs to all far peripheral stimuli and exceeded the abilities of both signing and non-signing hearing adults. Deaf adults were significantly faster than BSL interpreters, who in turn were significantly faster than hearing non-signing adults. The differences in RT demonstrated between groups were consistent across all visual field meridians and were not localized to any one region of the visual field. There were no differences found between any groups in accuracy of detecting these static stimuli at any retinal location. Early onset auditory deprivation appears to lead to a response time visual advantage in far peripheral responses to briefly presented, static LED stimuli, especially in the right visual field. Fluency in BSL facilitates faster visuo-motor responses in the peripheral visual field, but to a lesser extent than congenital, profound deafness...|$|R
