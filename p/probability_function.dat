1475|10000|Public
25|$|The <b>probability</b> <b>function,</b> {{mean and}} {{variance}} {{are given in}} the adjacent table.|$|E
25|$|The <b>probability</b> <b>function</b> and {{a simple}} {{approximation}} to the mean are given to the right. Better approximations to the mean and variance are given by McCullagh and Nelder (1989).|$|E
25|$|The {{calculation}} {{time for}} the <b>probability</b> <b>function</b> can be high when the sum in P0 has many terms. The calculation time can be reduced by calculating the terms in the sum recursively relative to the term for y = x and ignoring negligible terms in the tails (Liao and Rosen, 2001).|$|E
40|$|We {{consider}} {{the problem of}} induction over languages containing binary relations and outline a way of interpreting and constructing a class of <b>probability</b> <b>functions</b> on the sentences of such a language. Some principles of inductive reasoning satisfied by these <b>probability</b> <b>functions</b> are discussed, leading in turn to a representation theorem for a more general class of <b>probability</b> <b>functions</b> satisfying these principles...|$|R
40|$|A new {{approach}} {{is used to}} determine the transient <b>probability</b> <b>functions</b> of Markov processes. This new solution method is a sample path counting approach and uses dual processes and randomization. The approach is illustrated by determining transient <b>probability</b> <b>functions</b> for a three-state Markov process. This approach also provides a way to calculate transient <b>probability</b> <b>functions</b> for Markov processes which have specific sample path characteristics...|$|R
40|$|We generalize the Kolmogorov axioms for {{probability}} calculus {{to obtain}} conditions defining, {{for any given}} logic, a class of <b>probability</b> <b>functions</b> relative to that logic, coinciding with the standard <b>probability</b> <b>functions</b> in the special case of classical logic but allowing consideration of other classes of “essentially Kolmogorovian ” <b>probability</b> <b>functions</b> relative to other logics. We take a broad view of the Bayesian approach as dictating inter alia that {{from the perspective of}} a given logic, rational degrees of belief are those representable by <b>probability</b> <b>functions</b> from the class appropriate to that logic. Classical Bayesianism, which fixes the logic as classical logic, is only one version of this general approach. Another, which we call Intuitionistic Bayesianism, selects intuitionistic logic as the preferred logic and the associated class of <b>probability</b> <b>functions</b> as the right class of candidate representions of epistemic states (rational allocations of degrees of belief). Various objections to classical Bayesianism are, we argue, best met by passing to intuitionistic Bayesianism – in which the <b>probability</b> <b>functions</b> are taken relative to intuitionistic logic – rather than by adopting a radically non-Kolmogorovian, e. g. non-additive, conception of (or substitute for) <b>probability</b> <b>functions,</b> in spite of the popularity of the latter response amongst those who have raised these objections. The interest of intuitionistic Bayesianism is further enhanced by the availability of a Dutch Book argument justifying the selection of intuitionistic <b>probability</b> <b>functions</b> as guides to rational betting behaviour when due consideration is paid to the fact that bets are settled only when/if the outcome betted on becomes known...|$|R
2500|$|To {{find the}} {{parameter}} λ that maximizes the <b>probability</b> <b>function</b> for the Poisson population, {{we can use}} the logarithm of the likelihood function: ...|$|E
2500|$|A {{simple way}} to {{generate}} a bivariate Poisson distribution [...] is to take three independent Poisson distributions [...] with means [...] and then set [...] The <b>probability</b> <b>function</b> of the bivariate Poisson distribution is ...|$|E
2500|$|The <b>probability</b> <b>function</b> [...] must be {{positive}} even when [...] {{is greater than}} [...] [...] This feature prevents the method from becoming stuck at a local minimum that is worse than the global one.|$|E
30|$|The {{method of}} {{comparative}} assessment is based on, firstly, establishing a reference, {{in the case}} of this paper the reference is the track circuit and its specific <b>probability</b> <b>functions,</b> and secondly to compare two <b>probability</b> <b>functions</b> associated with those two different types of track circuit.|$|R
40|$|AbstractWe prove de Finetti style {{representation}} theorems {{covering the}} class of all <b>probability</b> <b>functions</b> satisfying spectrum exchangeability in polyadic inductive logic and give an application by characterizing those <b>probability</b> <b>functions</b> satisfying spectrum exchangeability which can be extended to a language with equality whilst still satisfying that property...|$|R
40|$|In {{this paper}} we study {{intersection}}s of ruin <b>probability</b> <b>functions</b> for two risk models. The number of intersection points is determined {{for some of}} the most widely used models. It is also shown that there exist risk processes with ruin <b>probability</b> <b>functions</b> intersecting in an arbitrary large number of points...|$|R
2500|$|... {{which is}} the {{negative}} of n times the reciprocal of {{the average of the}} ki. This expression is negative when the average is positive. If this is satisfied, then the stationary point maximizes the <b>probability</b> <b>function.</b>|$|E
2500|$|Using the {{expansion}} {{for the joint}} <b>probability</b> <b>function</b> [...] and the conditional probabilities from the conditional probability tables (CPTs) stated in the diagram, one can evaluate each term in the sums in the numerator and denominator. For example, ...|$|E
2500|$|... so gauge {{invariance}} {{is equivalent}} to the well known fact that changes in the phase of a wavefunction are unobservable, and only changes in the magnitude of the wavefunction result in changes to the <b>probability</b> <b>function</b> [...] [...] This is the ultimate theoretical origin of charge conservation.|$|E
40|$|The paper {{deals with}} three {{generalized}} dependent setups arising from an independent sequence of Bernoulli trials. Various distributional properties, such as <b>probability</b> generating <b>function,</b> <b>probability</b> mass <b>function</b> and moments are discussed for these setups and their waiting time. Also, explicit forms of <b>probability</b> generating <b>function</b> and <b>probability</b> mass <b>function</b> are obtained. Finally, an application {{to demonstrate the}} relevance of the results is given. Comment: 12 page...|$|R
40|$|International audienceIn this paper, {{we study}} second-order differentiability {{properties}} of <b>probability</b> <b>functions.</b> We present {{conditions under which}} <b>probability</b> <b>functions</b> involving nonlinear systems and Gaussian (or Student) multi-variate random vectors are twice continuously differentiable. We provide an expression for their Hessian that {{can be useful in}} numerical methods for solving probabilistic constrained optimization problems...|$|R
5000|$|A 2-EPT <b>probability</b> density <b>function</b> is a <b>probability</b> density <b>function</b> on [...] with a {{strictly}} proper rational characteristic function. On either [...] or [...] these <b>probability</b> density <b>functions</b> are exponential-polynomial-trigonometric (EPT) functions.|$|R
2500|$|The {{probability}} {{of making the}} transition from the current state [...] to a candidate new state [...] is specified by an acceptance <b>probability</b> <b>function</b> , that depends on the energies [...] and [...] of the two states, and on a global time-varying parameter [...] called the temperature.|$|E
2500|$|That is, the <b>{{probability}}</b> <b>function</b> f(x) {{lies between}} zero {{and one for}} every value of x in the sample space Ω, and the sum of f(x) over all values x in the sample space Ω is equal to 1. An event is defined as any subset [...] of the sample space [...] The probability of the event [...] is defined as ...|$|E
2500|$|Formally, Bayesian {{networks}} are DAGs whose nodes represent random {{variables in the}} Bayesian sense: they may be observable quantities, latent variables, unknown parameters or hypotheses. Edges represent conditional dependencies; nodes that are not connected (there is no path {{from one of the}} variables to the other in the Bayesian network) represent variables that are conditionally independent of each other. Each node is associated with a <b>probability</b> <b>function</b> that takes, as input, a particular set of values for the node's parent variables, and gives (as output) the probability (or probability distribution, if applicable) of the variable represented by the node. For example, if [...] parent nodes represent [...] Boolean variables then the <b>probability</b> <b>function</b> could be represented by a table of [...] entries, one entry for each of the [...] possible combinations of its parents being true or false. Similar ideas may be applied to undirected, and possibly cyclic, graphs; such as Markov networks.|$|E
40|$|Pruss (Thought 1 : 81 – 89, 2012) uses {{an example}} of Lester Dubins to argue against the claim that {{appealing}} to hyperreal-valued probabilities saves probabilistic regularity from the objection that in continuum outcome-spaces and with standard <b>probability</b> <b>functions</b> all save countably many possibilities must be assigned probability 0. Dubins’s example seems to show that merely finitely additive standard <b>probability</b> <b>functions</b> allow reasoning to a foregone conclusion, and Pruss argues that hyperreal-valued <b>probability</b> <b>functions</b> are vulnerable to the same charge. However, Pruss’s argument relies on the rule of conditionalisation, but I show that in examples like Dubins’s involving nonconglomerable probabilities, conditionalisation is self-defeating...|$|R
40|$|In this paper, {{we discuss}} an {{incorrect}} example that a Markov process does not satisfy strong Markov property, and analyzes the reason of mistake. In the end, we point out {{it is not}} reasonable to define strong Markov property by using transition <b>probability</b> <b>functions</b> since transition <b>probability</b> <b>functions</b> might not be one and only...|$|R
2500|$|It {{is common}} for <b>probability</b> density <b>functions</b> (and <b>probability</b> mass <b>functions)</b> to ...|$|R
2500|$|In {{order to}} apply the SA method to a {{specific}} problem, one must specify the following parameters: the state space, the energy (goal) function E (...) , the candidate generator procedure neighbour (...) , the acceptance <b>probability</b> <b>function</b> P (...) , and the annealing schedule temperature (...) AND initial temperature >. These choices can {{have a significant impact}} on the method's effectiveness. [...] Unfortunately, there are no choices of these parameters that will be good for all problems, and there is no general way to find the best choices for a given problem. [...] The following sections give some general guidelines.|$|E
2500|$|In an {{alternative}} {{formulation of the}} birthday problem, one asks {{the average number of}} people required to find a pair with the same birthday. If we consider the <b>probability</b> <b>function</b> Pr, this average is determining the Mean of the distribution, as opposed to the customary formulation which determines the Median. [...] The problem is relevant to several hashing algorithms analyzed by Donald Knuth in his book The Art of Computer Programming. It may be shown that if one samples uniformly, with replacement, from a population of size M, the number of trials required for the first repeated sampling of some individual has expected value , where ...|$|E
2500|$|... and [...] {{representing}} the spin {{direction of the}} particle. In this formulation, according to Esposito, quantum mechanics must necessarily be interpreted in probabilistic terms, {{for the reason that}} a system's initial motion condition cannot be exactly determined. Esposito explained that [...] "the quantum effects present in the Schrödinger equation are due to the presence of a peculiar spatial direction associated with the particle that, assuming the isotropy of space, can be identified with the spin of the particle itself". Esposito generalized it from matter particles to gauge particles, in particular photons, for which he showed that, if modelled as , with <b>probability</b> <b>function</b> , they can be understood in a quantum potential approach.|$|E
50|$|<b>Probability</b> <b>functions</b> (combinations and permutations) are available, {{as well as}} random numbers.|$|R
40|$|<b>Probability</b> <b>functions</b> {{depending}} upon parameters are represented as integrals over sets given by inequalities. New derivative formulas for the intergrals over a volume are considered. Derivatives {{are presented as}} sums of integrals over a volume and over a surface. Two examples are discussed: <b>probability</b> <b>functions</b> with linear constraints (random right-hand sides), and a dynamical shut-down problem with sensors...|$|R
3000|$|... is, its <b>probability</b> {{distribution}} <b>function</b> {{will never}} converge to some <b>probability</b> distribution <b>function.</b>|$|R
2500|$|To {{investigate}} {{the behavior of}} simulated annealing on a particular problem, it can be useful to consider the transition probabilities that result from the various design choices made {{in the implementation of}} the algorithm. [...] For each edge [...] of the search graph, the transition probability is defined as the probability that the SA algorithm will move to state [...] when its current state is [...] [...] This probability depends on the current temperature as specified by temperature (...) , on the order in which the candidate moves are generated by the neighbour (...) function, and on the acceptance <b>probability</b> <b>function</b> P (...) [...] (Note that the transition probability is not simply , because the candidates are tested serially.) ...|$|E
2500|$|Generally, quantum {{mechanics}} does not assign definite values. Instead, {{it makes a}} prediction using a probability distribution; that is, it describes the probability of obtaining the possible outcomes from measuring an observable. Often these results are skewed by many causes, such as dense probability clouds. Probability clouds are approximate (but better than the Bohr model) whereby electron location is given by a <b>probability</b> <b>function,</b> the wave function eigenvalue, such that the probability is the squared modulus of the complex amplitude, or quantum state nuclear attraction. Naturally, these probabilities {{will depend on the}} quantum state at the [...] "instant" [...] of the measurement. Hence, uncertainty is involved in the value. There are, however, certain states that are associated with a definite value of a particular observable. These are known as eigenstates of the observable ("eigen" [...] can be translated from German as meaning [...] "inherent" [...] or [...] "characteristic").|$|E
2500|$|In the {{formulation}} of the method by Kirkpatrick et al., the acceptance <b>probability</b> <b>function</b> [...] was defined as 1 if , and [...] otherwise. This formula was superficially justified by analogy with the transitions of a physical system; it corresponds to the Metropolis-Hastings algorithm, in the case where T=1 and the proposal distribution of Metropolis-Hastings is symmetric. However, this acceptance probability is often used for simulated annealing even when the neighbour (...) function, which {{is analogous to the}} proposal distribution in Metropolis-Hastings, is not symmetric, or not probabilistic at all. [...] As a result, the transition probabilities of the simulated annealing algorithm do not correspond to the transitions of the analogous physical system, and the long-term distribution of states at a constant temperature [...] need not bear any resemblance to the thermodynamic equilibrium distribution over states of that physical system, at any temperature. Nevertheless, most descriptions of SA assume the original acceptance function, which is probably hard-coded in many implementations of SA.|$|E
40|$|A new {{approach}} {{is used to}} determine the transient <b>probability</b> <b>functions</b> of the classical queueing systems: M/M/ 1, M/M/ 1 /H, and M/M/ 1 /H with catastrophes. This new solution method uses dual processes, randomization and lattice path combinatorics. The method reveals that the transient <b>probability</b> <b>functions</b> for M/M/ 1 /H and M/M/ 1 /H with catastrophes have the same mathematical form...|$|R
3000|$|..., are <b>probability</b> <b>functions</b> formulating {{the random}} {{dispersal}} {{of individuals and}} satisfy the following assumptions: [...]...|$|R
5000|$|Substituting {{the latent}} {{variables}} [...] and [...] in the <b>probability</b> <b>functions</b> and taking logs gives ...|$|R
