418|1328|Public
25|$|A more {{complicated}} example {{is given by}} recursive descent parsers, which can be naturally implemented by having one function for each <b>production</b> <b>rule</b> of a grammar, which then mutually recurse; this will in general be multiple recursion, as production rules generally combine multiple parts. This can also be done without mutual recursion, for example by still having separate functions for each <b>production</b> <b>rule,</b> but having them called by a single controller function, or by putting all the grammar in a single function.|$|E
25|$|A {{probabilistic}} context free grammar {{consists of}} terminal and nonterminal variables. Each feature to be modeled has a <b>production</b> <b>rule</b> that is assigned a probability estimated from a training set of RNA structures. Production rules are recursively applied until only terminal residues are left.|$|E
25|$|An L-system is {{context-free}} if each <b>production</b> <b>rule</b> refers only to {{an individual}} symbol and not to its neighbours. Context-free L-systems are thus specified by a context-free grammar. If a rule depends not only on a single symbol but also on its neighbours, it is termed a context-sensitive L-system.|$|E
5000|$|In formal {{language}} theory, a context-free grammar (CFG) {{is a certain}} type of formal grammar: a set of <b>production</b> <b>rules</b> that describe all possible strings in a given {{formal language}}. <b>Production</b> <b>rules</b> are simple replacements. For example, the rule ...|$|R
40|$|This paper {{discusses}} scattered context grammars (SCG) {{and considers}} {{the application of}} scattered context grammar <b>production</b> <b>rules.</b> We use function that represents single derivation step over the given sentential form. Moreover, we define this function in such a way, so that it represents the delayed execution of scattered context grammar <b>production</b> <b>rules</b> using the same principles as a lazy evaluation in functional programming. Finally, we prove equivalence of the usual and the delayed execution of SCG <b>production</b> <b>rules...</b>|$|R
40|$|C 4. 5 is {{the most}} {{well-known}} inductive learning algorithm. It {{can be used to}} build decision trees as well as <b>production</b> <b>rules.</b> <b>Production</b> <b>rules</b> are a very common formalism for representing and using knowledge in many real-world domains. C 4. 5 generates <b>production</b> <b>rules</b> from raw trees. It has been shown that the set of <b>production</b> <b>rules</b> is usually both simpler and more accurate than the decision tree from which the ruleset was formed. This research shows that generating <b>production</b> <b>rules</b> from pruned trees usually results in significantly simpler rulesets than generating rules from raw trees. This reduction in complexity is achieved without reducing prediction accuracies. Furthermore, the new approach uses significantly less induction time than the latter. This paper uses experiments {{in a wide variety of}} natural domains to illustrate these points. It also shows that the new method scales up better than the old one in terms of ruleset size, the number of rules, and learning time when the tr [...] ...|$|R
2500|$|A <b>production</b> <b>rule</b> in [...] is formalized mathematically {{as a pair}} , where [...] is a nonterminal and [...] is {{a string}} of {{variables}} and/or terminals; rather than using ordered pair notation, production rules are usually written using an arrow operator with [...] as its left hand side and [...] as its right hand side: ...|$|E
2500|$|In {{context-free}} grammars, all {{rules are}} one-to-one, one-to-many, or one-to-none. These rules {{can be applied}} regardless of context. The left-hand side of the <b>production</b> <b>rule</b> is always a nonterminal symbol. This means that the symbol {{does not appear in}} the resulting formal language. So in our case, our language contains the letters [...] and [...] but not [...]|$|E
2500|$|... to turn [...] into [...] We {{can then}} apply {{one of the}} two later rules. For example, if we apply [...] to the first [...] we get [...] If we then apply [...] to the second [...] we get [...] Since both [...] and [...] are {{terminal}} symbols, and in context-free grammars terminal symbols never appear on the left hand side of a <b>production</b> <b>rule,</b> there are no more rules that can be applied. This same process can be used, applying the second two rules in different orders in order to get all possible strings within our simple context-free grammar.|$|E
5000|$|R is {{a finite}} set of string-transforming <b>rules</b> (called <b>production</b> <b>rules),</b> each rule {{being of the}} {{following}} form: ...|$|R
25|$|Generate <b>production</b> <b>rules</b> for the sequences.|$|R
50|$|Here again, such {{strategies}} may vary from the simple—use {{the order in}} which <b>production</b> <b>rules</b> were written; assign weights or priorities to <b>production</b> <b>rules</b> and sort the conflict set accordingly—to the complex—sort the conflict set according to the times at which <b>production</b> <b>rules</b> were previously fired; or according to the extent of the modifications induced by their RHSs. Whichever conflict resolution strategy is implemented, the method is indeed crucial to the efficiency and correctness of the production system. Some systems simply fire all matching productions.|$|R
2500|$|The {{types of}} various {{structure}} {{that can be}} modeled by a PCFG include long range interactions, pairwise structure and other nested structures. However, pseudoknots can not be modeled. PCFGs extend CFG by assigning probabilities to each <b>production</b> <b>rule.</b> A maximum probability parse tree from the grammar implies a maximum probability structure. Since RNAs preserve their structures over their primary sequence; RNA structure prediction can be guided by combining evolutionary information from comparative sequence analysis with biophysical knowledge about a structure plausibility based on such probabilities. Also search results for structural homologs using PCFG rules are scored according to PCFG derivations probabilities. Therefore, building grammar to model the behavior of base-pairs and single-stranded regions starts with exploring features of structural multiple sequence alignment of related RNAs.|$|E
2500|$|The inside {{algorithm}} calculates [...] probabilities for all [...] of a parse subtree rooted at [...] for subsequence [...] Outside algorithm calculates [...] {{probabilities of}} a complete parse tree for sequence [...] from root excluding the calculation of [...] The variables [...] and [...] refine the estimation of probability parameters of an PCFG. It is possible to reestimate the PCFG algorithm by finding the expected number of times a state is used in a derivation through summing all the products of [...] and [...] divided by the probability for a sequence [...] given the model [...] It is also possible to find the expected number of times a <b>production</b> <b>rule</b> is used by an expectation-maximization that utilizes the values of [...] and [...] The CYK algorithm calculates [...] {{to find the most}} probable parse tree [...] and yields [...]|$|E
5000|$|OMG <b>Production</b> <b>Rule</b> Representation (PRR): Represents {{rules for}} <b>production</b> <b>rule</b> systems {{that make up}} most BRMS' {{execution}} targets ...|$|E
5000|$|... #Subtitle level 2: Matching <b>production</b> <b>rules</b> against {{working memory}} ...|$|R
5000|$|In {{computer}} science, {{terminal and}} nonterminal symbols are the lexical elements used in specifying the <b>production</b> <b>rules</b> constituting a formal grammar. Terminal symbols are the elementary {{symbols of the}} [...] language defined by a formal grammar. Nonterminal symbols (or syntactic variables) are replaced by groups of terminal symbols according to the <b>production</b> <b>rules.</b>|$|R
40|$|Abstract. We {{show that}} <b>production</b> <b>rules</b> and persis-tent queues {{together}} provide a convenient mechanism for maintaining consistency in semantically heterogeneous multi-database environments. We describe a specification language and methods for automatically deriving <b>production</b> <b>rules</b> that maintain (1) existence dependencies, {{in which the}} presence of data in one database implies the presence of related data in another, and (2) value dependencies, in which the value of data in one database is baaed {{on the value of}} related data in another. The <b>production</b> <b>rules</b> derived from dependency specifications use persistent queues to monitor and maintain the dependencies automatically, asynchronously, incremen-tally, and correctly. ...|$|R
5000|$|<b>Production</b> <b>Rule</b> Representation - {{comparable}} to the dialect of RIF called <b>Production</b> <b>Rule</b> Dialect, although targeting modeling not run-time interchange.|$|E
50|$|A {{compiler}} parses {{input from}} {{a programming language}} to an internal representation by matching the incoming symbols to production rules. Production rules are commonly defined using Backus-Naur form. An LL parser {{is a type of}} parser that does top-down parsing by applying each <b>production</b> <b>rule</b> to the incoming symbols, working from the left-most symbol yielded on a <b>production</b> <b>rule</b> and then proceeding to the next <b>production</b> <b>rule</b> for each non-terminal symbol encountered. In this way the parsing starts on the Left of the result side (right side) of the <b>production</b> <b>rule</b> and evaluates non-terminals from the Left first and, thus, proceeds down the parse tree for each new non-terminal before continuing to the next symbol for a <b>production</b> <b>rule.</b>|$|E
5000|$|In the {{transformation}} {{portion of the}} <b>production</b> <b>rule,</b> the parameters as well as entire modules can be affected. In the above example, the module b(x,y) {{is added to the}} string, with initial parameters (2,3). Also, the parameters of the already existing module are transformed. Under the above <b>production</b> <b>rule,</b> ...|$|E
40|$|AbstractWe begin a {{systematic}} {{study of the}} enumerative combinatorics of mixed succession rules, i. e. succession rules such that, in the associated generating tree, nodes are allowed to produce sons at several different levels according to different <b>production</b> <b>rules.</b> Here we deal with a specific case, namely that of two different <b>production</b> <b>rules</b> whose rule operators commute. In this situation, {{we are able to}} give a general formula expressing the sequence associated with the mixed succession rule in terms of the sequences associated with the component <b>production</b> <b>rules.</b> We end by providing examples illustrating our approach...|$|R
40|$|We begin a {{systematic}} {{study of the}} enumerative combinatorics of mixed succession rules, which are succession rules such that, in the associated generating tree, the nodes are allowed to produce their sons at several different levels according to different <b>production</b> <b>rules.</b> Here we deal with a specific case, namely that of two different <b>production</b> <b>rules</b> whose rule operators commute. In this situation, {{we are able to}} give a general formula expressing the sequence associated with the mixed succession rules in terms of the sequences associated with the component <b>production</b> <b>rules.</b> We end by providing some examples illustrating our approach. Comment: 28 pages, submitte...|$|R
40|$|<b>Production</b> <b>rules</b> {{and logic}} {{programs}} can be combined in a single logic-based framework. The framework gives both an operational and modeltheoretic semantics to <b>production</b> <b>rules,</b> {{as well as to}} logic programs extended with a database of facts that is modified by destructive assignment. The model-theoretic semantics is obtained by separating the production system working memory into facts and goals. Logic programs are used to define ramifications of the facts and to reduce goals to sub-goals, including actions. The execution of actions generates a sequence of states, which serves as a candidate model of the <b>production</b> <b>rules.</b> ...|$|R
5000|$|... {{a finite}} set of {{terminal}} symbols (indicating that no <b>production</b> <b>rule</b> can be applied) ...|$|E
5000|$|In many contexts, each <b>production</b> <b>rule</b> {{has only}} one antecedent, thus taking the simpler form ...|$|E
5000|$|... {{a finite}} set of nonterminal symbols (indicating that some <b>production</b> <b>rule</b> can yet be applied) ...|$|E
5000|$|Support for: Integrity <b>rules,</b> Derivation <b>rules,</b> <b>Production</b> <b>rules</b> and Reaction rules; ...|$|R
50|$|The most {{successful}} form of symbolic AI is expert systems, which use {{a network of}} <b>production</b> <b>rules.</b> <b>Production</b> <b>rules</b> connect symbols in a relationship similar to an If-Then statement. The expert system processes the rules to make deductions and to determine what additional information it needs, i.e. what questions to ask, using human-readable symbols.|$|R
5000|$|Production {{systems may}} vary on the {{expressive}} power of conditions in <b>production</b> <b>rules.</b> Accordingly, the {{pattern matching algorithm}} which collects <b>production</b> <b>rules</b> with matched conditions may range from the naive—trying all rules in sequence, stopping at the first match—to the optimized, in which rules are [...] "compiled" [...] into a network of inter-related conditions.|$|R
5000|$|A <b>production</b> <b>rule</b> {{can also}} include a {{sequence}} of terminals or nonterminals, each separated by a comma: ...|$|E
5000|$|Rule Interchange Format by W3C {{especially}} its <b>Production</b> <b>Rule</b> Dialect, which is nominally {{compatible with the}} PRR metamodel.|$|E
5000|$|Note that in {{the case}} of a <b>production</b> <b>rule</b> like this (where the {{operator}} can only appear once): ...|$|E
5000|$|Production {{system which}} {{describes}} the typical rule engine that executes <b>production</b> <b>rules</b> ...|$|R
50|$|A {{recursive}} grammar is a grammar {{that contains}} <b>production</b> <b>rules</b> that are recursive. For example, a grammar for a context-free language is left-recursive if {{there exists a}} non-terminal symbol A that can be put through the <b>production</b> <b>rules</b> to produce a string with A as the leftmost symbol.All types of grammars in the Chomsky hierarchy can be recursive.|$|R
50|$|Following is {{the set of}} <b>production</b> <b>rules</b> {{corresponding}} to {{the first set of}} rules.|$|R
