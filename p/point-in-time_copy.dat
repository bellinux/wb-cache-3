5|7|Public
50|$|A {{snapshot}} is a read-only <b>point-in-time</b> <b>copy</b> of the volume. Snapshots {{allow the}} creation of consistent backups of a volume, ensuring that the contents do not change and are not locked while the backup is being made.|$|E
5000|$|FlashCopy Version 2 {{introduced}} {{the ability to}} flash individual data sets and then added support for “consistency groups”. FlashCopy consistency groups {{can be used to}} help create a consistent <b>point-in-time</b> <b>copy</b> across multiple volumes, and even across multiple ESSs, thus managing the consistency of dependent writes.|$|E
5000|$|Modern {{data storage}} {{replication}} technologies may {{be applied to}} PACS information, including the creation of local copies via <b>point-in-time</b> <b>copy</b> for locally protected copies, along with complete copies of data on separate repositories including disk and tape based systems. Remote copies of data should be created, either by physically moving tapes off-site, or copying data to remote storage systems. Whenever HIPAA protected data is moved, it should be encrypted, which includes sending via physical tape or replication technologies over wide area networks (WAN) to a secondary location.|$|E
50|$|The meta-data {{management}} {{also has}} implications on performance. Any virtualization software or device {{must be able}} to keep all the copies of the meta-data atomic and quickly updateable. Some implementations restrict the ability to provide certain fast update functions, such as <b>point-in-time</b> <b>copies</b> and caching where super fast updates are required to ensure minimal latency to the actual I/O being performed.|$|R
5000|$|Walrus, {{also written}} in Java, is the Eucalyptus {{equivalent}} to AWS Simple Storage Service (S3). Walrus offers persistent storage {{to all of}} the virtual machines in the Eucalyptus cloud and {{can be used as a}} simple HTTP put/get storage as a service solution. There are no data type restrictions for Walrus, and it can contain images (i.e., the building blocks used to launch virtual machines), volume snapshots (i.e., <b>point-in-time</b> <b>copies),</b> and application data. Only one Walrus can exist per cloud.|$|R
5000|$|<b>Point-In-Time</b> Snapshots to <b>copy</b> or clone {{data for}} diverse uses ...|$|R
40|$|This paper {{describes}} the functionality of a <b>point-in-time</b> <b>copy</b> facility and describes both {{the benefits and}} drawbacks of providing this facility on the storage subsystem. While there are other benefits, the biggest benefit of providing this facility on the storage subsystem is performance; we do not needlessly add load to the storage network or host as part of making the copy. The biggest drawback is that the storage subsystem in today's world is only aware of data {{at the level of}} logical units and blocks; this makes it hard to meaningfully perform copies at a granularity of less than an entire logical uni...|$|E
40|$|Storage {{systems are}} the next {{frontier}} for providing protection against intrusion. Since storage systems see changes to persistent data, {{several types of}} intrusions can be detected by storage systems. Intrusion detection (ID) techniques can be deployed in various storage systems. In this paper, we study how intrusions can be detected at the block storage level and in SAN environments. We propose novel approaches for storagebased intrusion detection and discuss how features of state-of-the-art block storage systems {{can be used for}} intrusion detection and recovery of compromised data. In particular we present two prototype systems. First we present a real time intrusion detection system (IDS) which has been integrated within a storage management and virtualization system. In this system incoming requests for storage blocks are examined for signs of intrusions in real time. We then discuss how intrusion detection schemes can be deployed as an appliance loosely coupled with a SAN storage system. The major advantage of this approach {{is that it does not}} require any modification and enhancement to the storage system software. In this approach, we use the space and time efficient <b>point-in-time</b> <b>copy</b> operation provided by SAN storage devices. We also present performance results showing that the impact of ID on the overall storage system performance is negligible. Recovering data in compromised systems is also discussed. 1...|$|E
40|$|Abstract—Designing storage {{systems to}} provide {{business}} continuity {{in the face}} of failures requires the use of various data protection techniques, such as backup, remote mirroring, <b>point-in-time</b> <b>copies</b> and vaulting, often in concert. Predicting the dependability provided by such compositions of techniques is difficult, yet necessary for dependable system design. We present a framework for evaluating the dependability of data storage systems, including both individual data protection techniques and their compositions. Our models estimate storage system recovery time, data loss, normal mode system utilization and operational costs under a variety of failure scenarios. We demonstrate the effectiveness of these modeling techniques through a case study using real-world storage system designs and workloads. ...|$|R
5000|$|Snapshot {{technology}} - known formally as [...] "delta snapshot technology" [...] - {{gives the}} ability to use the same dataset multiple times for multiple reasons, while storing only the changes between each dataset. Some storage vendors integrate their snapshot capabilities at the operating system and/or application level, enabling access to the data the snapshots are holding at the system and/or application management layers. Terminology around snapshots and [...] "clones" [...] is currently confusing, and care must be taken when evaluating vendor claims. In particular, some vendors call full <b>point-in-time</b> <b>copies</b> [...] "snapshots" [...] or [...] "clones", while others use the same terms to refer to shared-block [...] "delta" [...] snapshots or clones. And some implementations can only do read-only snapshots, while others are able to provide writable ones as well.|$|R
50|$|Tier 4 {{solutions}} {{are used by}} businesses that require both greater data currency and faster recovery than users of lower tiers. Rather than relying largely on shipping tape, as is common on the lower tiers, Tier 4 solutions begin to incorporate more disk based solutions. Several hours of data loss is still possible, but {{it is easier to}} make such <b>point-in-time</b> (PiT) <b>copies</b> with greater frequency than tape backups even when electronically vaulted.|$|R
40|$|Protecting data on {{primary storage}} often {{requires}} creating secondary copies by periodically replicating {{the data to}} external target systems. We analyze over 100, 000 traces from 125 customer block-based primary storage systems to gain a high-level understanding of I/O characteristics and then perform an in-depth analysis of over 500 traces from 13 systems that span at least 24 hours. Our analysis has the twin goals of minimizing overheads on primary systems and improving data replication efficiency. We compare our results with a study a decade ago [20] and provide fresh insights into patterns of incremental changes on primary systems over time. Primary storage systems often create snapshots as <b>point-in-time</b> <b>copies</b> {{in order to support}} host I/O while replicating changed data to target systems. However, creating standard snapshots on a primary storage system incurs overheads in terms of capacity and I/O, and we present a new snapshot technique called a replication snapshot that reduces these overheads. Replicated data also requires capacity and I/O on the target system, and we investigate techniques to significantly reduce these overheads. We also find that highly sequential or random I/O patterns have different incremental change characteristics. Where applicable, we present our findings as advice to storage engineers and administrators. ...|$|R

