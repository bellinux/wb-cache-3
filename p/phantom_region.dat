26|28|Public
40|$|Choosing various natural {{forms for}} the equation-of-state {{parameter}} w and the bulk viscosity ζ, we discuss {{how it is}} possible for a dark energy fluid to slide from the quintessence region across the divide w = − 1 into the <b>phantom</b> <b>region,</b> and thus into a Big Rip future singularity. Different analytic forms for ζ, as powers of the scalar expansion, are suggested and compared with experiments...|$|E
40|$|Singularities in {{the dark}} energy {{universe}} are discussed, assuming {{that there is a}} bulk viscosity in the cosmic fluid. In particular, it is shown how the physically natural assumption of letting the bulk viscosity be proportional to the scalar expansion in a spatially flat FRW universe can drive the fluid into the <b>phantom</b> <b>region</b> (w - 1) in the non-viscous case. Comment: 11 pages. Printing error in eq. (23) corrected. To appear in Gen. Rel. Gra...|$|E
40|$|We study {{effects of}} cosmic fluids on finite-time future {{singularities}} in modified f(R,G) -gravity, where R and G are the Ricci scalar and the Gauss-Bonnet invariant, respectively. We consider the fluid {{equation of state}} in the general form, ω=ω(ρ), and we suppose {{the existence of a}} bulk viscosity. We investigate quintessence region (ω>- 1) and <b>phantom</b> <b>region</b> (ω<- 1) and the possibility to change or avoid the singularities in f(R,G) -gravity. Finally, we study the inclusion of quantum effects in large curvatures regime. Comment: 14 page...|$|E
40|$|In {{this paper}} we {{introduce}} a new deep learning based approach to detect and remove phantom objects from point clouds produced by mobile laser scanning (MLS) systems. The phantoms are caused {{by the presence of}} scene objects moving concurrently with the MLS platform, and appear as long, sparse but irregular point cloud segments in the measurements. We propose a new 3 D CNN framework working on a voxelized column-grid to identify the <b>phantom</b> <b>regions.</b> We quantitatively evaluate the proposed model on real MLS test data, and compare it to two different reference approaches...|$|R
40|$|Estimating {{the number}} of people in a crowded {{environment}} is a central task in civilian surveillance. Most vision-based counting techniques depend on detecting individuals in order to count, an unrealistic proposition in crowded settings. We propose an alternative approach that directly estimates {{the number of}} people. In our system, groups of image sensors segment foreground objects from the background, aggregate the resulting silhouettes over a network, and compute a planar projection of the scene’s visual hull. We introduce a geometric algorithm that calculates bounds on the number of persons in each region of the projection, after <b>phantom</b> <b>regions</b> have been eliminated. The computational requirements scale well with the number of sensors and {{the number of people}}, and only limited amounts of data are transmitted over the network. Because of these properties, our system runs in real-time and can be deployed as an untethered wireless sensor network. We describe the major components of our system, and report preliminary experiments with our first prototype implementation. 1...|$|R
30|$|Quantitative {{analysis}} on phantom datasets {{was carried out}} on unfiltered images. Circular regions of interest (ROIs) were drawn onto the hot spheres, on the widest slice of the sphere. ROIs of diameters equal {{to those of the}} hot spheres were drawn in the background region, positioned concentrically on three slices: one near the top, the bottom, and the middle of the <b>phantom.</b> The <b>regions</b> were drawn onto transaxial slices of the CT image and copied across to the aligned SPECT images.|$|R
40|$|We {{consider}} {{the effects of}} Gravity's Rainbow on the self-sustained equation which is responsible to find new traversable wormholes configurations powered by their own gravitational quantum fluctuations. The form of the shape function considered is obtained by imposing the equation of state p_r=ωρ. We investigate {{the size of the}} wormhole {{as a function of the}} parameter ω in the <b>phantom</b> <b>region.</b> We discover that a wormhole which is traversable in principle, but not in practice, can be produced. Comment: 6 pages. Prepared for the Proceedings of the Karl Schwarzschild meeting 201...|$|E
40|$|We {{study the}} {{evolution}} of the dark energy parameter within the scope of a spatially non-flat and isotropic Friedmann-Robertson-Walker (FRW) model filled with barotropic fluid and bulk viscous stresses. We have obtained cosmological solutions which exhibit without a big rip singularity. It is concluded that in both non-interacting and interacting cases non-flat open universe crosses the <b>phantom</b> <b>region.</b> We find that during {{the evolution of}} the universe, the equation of state (EoS) for dark energy ω_D changes from ω^eff_D - 1, which is consistent with recent observations. Comment: 10 Pages, 4 Figure...|$|E
40|$|Although {{generalized}} Chaplygin phantom models do {{not show}} any big rip singularities, we investigated k-essence models together with noncanonical kinetic energy for which {{there might be a}} big rip future singularity in the <b>phantom</b> <b>region.</b> We present our results by finely tuning the parameter (β) which is closely related to the canonical kinetic term in k-essence formalism. The scale factor a(t) could be negative and decreasing within a specific range of β during the initial evolutional period. There will be no singularity for the scale factor for all times once β is carefully selected. Comment: 4 pages; 1 figur...|$|E
40|$|A small positron-generating {{branch in}} 90 -Yttrium (90 Y) decay enablespost-therapy dose {{assessment}} in liver cancer radioembolization treatment. The {{aim of this}} study was to validate clinical 90 Y PET quantification, focusing on scanner linearity as well as acquisition and reconstruction parameter impact on scanner calibration. Data from three dedicated phantom studies (total activity range: 55. 2 MBq  2. 1 GBq) carried out on a Philips Gemini TF 16 PET/CT scanner were analyzed after reconstruction with up to 361 parameter configurations. Foractivities above 200 MBq, scanner linearity could be confirmed withrelative error margins < 4 %. An acquisition-time-normalized calibration factor of 1. 04 MBq s / CNTS was determined for the employed scanner. Stable activity convergence was found in hot <b>phantom</b> <b>regions</b> with relative differences in summed image intensities between - 3. 6 % and + 2. 4 %. Absolute differences in background noise artefacts between- 79. 9 % and + 350 % were observed. Quantitative accuracy was dominatedby subset size selection in the reconstruction. Using adequate segmentation and optimized acquisition parameters, the average activityrecovery error induced by the axial scanner sensitivity profile wasreduced to + 2. 4 % ± 3. 4 % (mean ± standard deviation). We therefore conclude that post-therapy dose assessment in 90 Y PET can be improvedusing adapted parameter setups...|$|R
30|$|Quantitative {{accuracy}} {{was assessed}} in a NEMA NU 2 phantom {{with the same}} acquisition and reconstruction parameters used for patients. The phantom (volume 9340  cm 3) was filled with 42.3  MBq of 68 Ga in aqueous solution measured at the image acquisition start time, resulting in an activity concentration of 4.52  kBq/mL which mimics the typical average activity concentration present in patient organs. In 10 <b>phantom</b> background <b>regions</b> of 3 [*]×[*] 3  cm 2, an average activity concentration of 4.25  kBq/mL was measured, which is 6 % lower than the actual value. Such discrepancy {{is compatible with the}} accuracy of the well counter used for the 68 Ga activity measurement before filling the phantom.|$|R
40|$|Abstract. Diffusion Tensor Imaging (DTI) and its {{successor}} High Angular Resolution Diffusion Imaging (HARDI) {{are emerging}} MRI techniques for depicting in-vivo white brain matter anatomy and connectivity. There {{is a wide}} variety of utilizations of DTI and HARDI, ranging from characterizing the local structure of tissues to fiber tracking and segmentation. However, thorough validation is needed in order to apply any of the above mentioned methods in a clinical setting. The lack of knowledge about ground truth in brain white matter leads to developments of synthetic, software generated, phantoms and use of hardware phantoms. The goal of the present work is to validate DTI and HARDI software <b>phantoms,</b> in <b>regions</b> of single and crossing fiber bundles, in relation to hardware phantom data and in-vivo data from human brain. Knowledge of the accuracy of the synthetic data can improve the evaluation of data modeling and processing, and advance the employment of DTI and HARDI in clinical applications...|$|R
40|$|We show explicitly, {{by using}} astrophysical data plus {{reasonable}} assumptions {{for the bulk}} viscosity in the cosmic fluid, how {{the magnitude of this}} viscosity may be high enough to drive the fluid from its position in the quintessence region at present time $t= 0 $ across the barrier $w=- 1 $ into the <b>phantom</b> <b>region</b> in the late universe. The phantom barrier is accordingly not a sharp mathematical divide, but rather a fuzzy concept. We also calculate the limiting forms of various thermodynamical quantities, including the rate of entropy production, for a dark energy fluid near the future Big Rip singularity. Comment: 11 pages, latex, no figures, to appear in Entrop...|$|E
40|$|We {{consider}} a modified form of gravity {{in which the}} action contains a power alpha of the scalar curvature. It is shown how {{the presence of a}} bulk viscosity in a spatially flat universe may drive the cosmic fluid into the <b>phantom</b> <b>region</b> (w - 1) in the non-viscous case. The condition for this to occur is that the bulk viscosity contains the power (2 alpha- 1) of the scalar expansion. Two specific examples are discussed in detail. The present paper is a generalization of the recent investigation dealing with barrier crossing in Einstein's gravity: I. Brevik and O. Gorbunova, Gen. Relativ. Grav. 37 (2005) 2039...|$|E
40|$|Singularities in {{the dark}} energy late {{universe}} are discussed, {{under the assumption that}} the Lagrangian contains the Einstein term R plus a modified gravity term of the form R^α, where α is a constant. It is found, similarly {{as in the case of}} pure Einstein gravity [I. Brevik and O. Gorbunova, Gen. Rel. Grav. 37 (2005), 2039], that the fluid can pass from the quintessence region (w>- 1) into the <b>phantom</b> <b>region</b> (w<- 1) as a consequence of a bulk viscosity varying with time. It becomes necessary now, however, to allow for a two-fluid model, since the viscosities for the two components vary differently with time. No scalar fields are needed for the description of the passage through the phantom barrier. Comment: 16 pages latex, no figure...|$|E
30|$|The {{fundamental}} {{concept of}} measuring/deriving the estimated amount {{of activity in}} the tissue with SPECT/CT {{is the same as}} measuring the standardized uptake value (SUV) with PET/CT. However, we feel more work {{needs to be done to}} determine the accuracy and precision of such measurements in SPECT/CT. In particular, potential errors due to scatter correction, system dead-time, collimator detector response, attenuation correction, and partial volume need further exploration. In addition, other radioisotopes, geometries, and the manufacturer’s calibration procedures need to be considered. While this paper focuses on the overall stability and calibration factors of SPECT/CT using 99 mTc and the DQA flood 57 Co phantom, in order to tackle these other issues, we are currently collecting data using 131 I, 123 I, 111 In, 67 Ga, 90 Y, and 201 Tl, along with continued 99 mTc scans. These studies are being done with a variety of phantoms including an anthropomorphic phantom and varying sizes of liter cylinders with and without TEM. Furthermore, we are also looking into the validity of conversation factors for quantification along with reconstruction methods/algorithms through continued studies in a lung <b>phantom</b> including <b>regions</b> with and without injected activity.|$|R
40|$|In CT colonography (CTC), orally {{administered}} positive-contrast tagging {{agents are}} often used for differentiating residual bowel contents from native colonic structures. However, tagged materials can sometimes hyperattenuate observed CT numbers of their adjacent untagged materials. Such pseudoenhancement complicates the differentiation of colonic soft-tissue structures from tagged materials, because pseudoenhanced colonic structures may have CT numbers {{that are similar to}} those of tagged materials. The authors developed a nonlinear regression-based (NLRB) method for performing a local image-based pseudoenhancement correction of CTC data. To calibrate the correction parameters, the CT data of an anthropomorphic reference phantom were correlated with those of partially tagged phantoms. The CTC data were registered spatially by use of an adaptive multiresolution method, and untagged and tagged partial-volume soft-tissue surfaces were correlated by use of a virtual tagging scheme. The NLRB method was then optimized to minimize the difference in the CT numbers of soft-tissue regions between the untagged and tagged phantom CTC data by use of the Nelder-Mead downhill simplex method. To validate the method, the CT numbers of untagged regions were compared with those of registered pseudoenhanced <b>phantom</b> <b>regions</b> before and after the correction. The CT numbers were significantly different before performing the correction (p< 0. 01), whereas, after the correction, the difference between the CT numbers was not significant. The effect of the correction was also tested on the size measurement of polyps that were covered by tagging in phantoms and in clinical cases. In phantom cases, before the correction, the diameters of 12 simulated polyps submerged in tagged fluids that were measured in a soft-tissue CT display were significantly different from those measured in an untagged phantom (p< 0. 01), whereas after the correction the difference was not significant. In clinical cases, before the correction, the diameters of 29 colonoscopy-confirmed 3 – 14 mm polyps affected by tagging that were measured in a soft-tissue CT display were significantly different from those measured in a lung CT display (p< 0. 0001) or in colonoscopy (p< 0. 05), whereas after the correction the difference was not significant. Finally, the effect of the correction was tested on automated detection of 25 polyps ≥ 6 mm affected by tagging in 56 clinical CTC cases. The application of the correction increased the detection accuracy from 60 % with 5. 0 FP detections per patient without correction to 96 % with 2. 9 FP detections with correction. This improvement in detection accuracy was statistically significant (p< 0. 05). The results indicate that the proposed NLRB method can yield an accurate pseudoenhancement correction with potentially significant benefits in clinical CTC examinations...|$|R
40|$|Inhomogeneity of the {{transmitted}} or received B 1 field {{leads to}} intensity variations in MR images and spatial dependence in apparent concentration in MR spectra. We describe a simple method for investigating such variations. The transmitted B 1 field {{can be measured}} both in vivo and in vitro which allows investigation of sample dependent effects {{that can not be}} measured on <b>phantoms.</b> For homogeneous <b>regions</b> the method also allows the received B 1 field to be measured both in vivo and in vitro. Our method uses only a standard spin echo pulse sequence and simple region of interest analysis and should be implementable on any commercial scanner. The method is demonstrated using a variety of transmission and reception radiofrequency coils both in vivo and in vitro...|$|R
40|$|Choosing various natural {{forms for}} the equation-of-state {{parameter}} w and the bulk viscosity ζ, we discuss {{how it is}} possible for a dark energy fluid to slide from the quintessence region across the divide w = − 1 into the <b>phantom</b> <b>region,</b> and thus into a Big Rip future singularity. Different analytic forms for ζ, as powers of the scalar expansion, are suggested and compared with experiments. © 2013 Brevik. This is an open-access article distributed {{under the terms of the}} Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms...|$|E
40|$|Analytic {{properties}} of physical quantities in the cosmic fluid such as energy density ρ(t) and Hubble parameter H(t) are investigated near the future singularity (Big Rip). Both 4 D and 5 D cosmologies are considered (the Randall-Sundrum II {{model in the}} 5 D case), and the fluid is assumed to possess a bulk viscosity ζ. We consider both Einstein gravity and modified gravity, where {{in the latter case}} the Lagrangian contains a term R α with α a constant. If ζ is proportional to the power (2 α − 1) of the scalar expansion, the fluid can pass from the quintessence region into the <b>phantom</b> <b>region</b> {{as a consequence of the}} viscosity. A property worth noticing is that the 4 D singularity on the brane becomes carried over to the bulk region. ...|$|E
40|$|Anisotropic {{dark energy}} model with dynamic {{pressure}} anisotropies along different spatial directions is constructed at {{the backdrop of}} a spatially homogeneous diagonal Bianchi type V (BV) space-time {{in the framework of}} General Relativity. A time varying deceleration parameter generating a hybrid scale factor is considered to simulate a cosmic transition from early deceleration to late time acceleration. We found that the pressure anisotropies along the y- and z- axes evolve dynamically and continue along with the cosmic expansion without being subsided even at late times. The anisotropic pressure along the x-axis becomes equal to the mean fluid pressure. At a late phase of cosmic evolution, the model enters into a <b>phantom</b> <b>region.</b> From a state finder diagnosis, it is found that the model overlaps with ΛCDM at late phase of cosmic time...|$|E
30|$|Methods: 26 {{patients}} underwent PET/CT imaging on {{a conventional}} system (Philips Gemini TF 64, cPET) approximately 75 minutes post-injection of 480 MBq 18 F-FDG and 55 minutes on a pre-commercial release digital photon counting PET/CT system (Philips Vereos, DPC dPET). Listmode data were reconstructed with default settings: cPET – 4 mm isometric voxel, 3 iterations, 33 subsets; DPC dPET – 2 mm isometric voxel, 3 iterations, 11 subsets, point spread function correction and 4.1 mm Gaussian filter applied. DPC dPET data were further reconstructed with an EARL-compliant protocol – 4 mm isometric voxel, 3 iterations 13 subsets, 5 mm Gaussian filter which was previously validated with <b>phantom</b> data (1). <b>Regions</b> of interest (ROIs) were placed over target lesions {{and in a}} variety of background tissues for quantitative comparison.|$|R
40|$|The need {{of image}} (frame) {{acquisitions}} within short time intervals is of major importance for preclinical SPECT imaging. The short frame times enable higher temporal resolution which {{is required in}} bio-distribution and pharmacokinetic studies where fast dynamic imaging is performed. The present study evaluates and compares the performance of two different preclinical multipinhole SPECT systems (NanoScan, VECTor) for short frames acquisitions. Prior to the systems comparison, the comparison and selection of the best performing fast imaging mode provided by NanoScan system (Mediso) was performed. The fast imaging modes of this system provide acquisitions with 1, 2 and 3 detector position around the animal bed. This comparison was performed by using uniform phantoms (syringes) and the rods of the NEMA NU 4 IQ phantom (frames: 6 - 30 s). The down-sized version of NU 4 IQ phantom (SPECTIQ phantom) {{was used in this}} study to compare the performance of VECTor (MILabs) and NanoScan when performing acquisitions with short frame times (18 s- 600 s, whole body scans). The quality of the acquired images was assessed in terms of absolute quantification (recovery coefficient), noise levels and visual evaluation. The quantification with the NanoScan was accurate (± 5 %) regardless of times frames duration and activity concentrations when imaging large structures. The increase in number of detector positions yielded images with lower noise levels. In the case of small structures, acquisition with 3 detector positions (Semi- 3 mode) appeared to provide more accurate activity recovery compared to acquisitions with 1 (stationary mode) and 2 detector positions (Semi- 2 mode). Especially {{in the case of the}} 2 mm diameter rod of the NU 4 IQ phantom, the Semi- 3 mode appears to provide significantly more accurate activity recovery (30 s frame). The systems comparison showed activity recovery with up to 5 % deviation from the dose calibrator measurement when imaging the uniform <b>region</b> of SPECTIQ <b>phantom</b> (d = 21 mm). Both systems could recover the three largest rods (d = 1. 5, 1. 0, 0. 75 mm) for the longest frames used(180, 360, 600 s). None of the systems could recover the two smallest rods of the phantom (d= 0. 5, 0. 35 mm). As the frame time decreased, both systems could recover less number of rods. VECTor appeared to provide higher activity recovery than NanoScan for the three largest rods of the phantom. However, as the frame time decreased the differences became less significant. Furthermore, VECTor provided and 22. 2 % and 46. 6 % less spillover in airand water-filled <b>phantom</b> <b>regions</b> (after reaching convergence) than NanoScan did. The performances of two preclinical SPECT systems (NanoScan, VECTor) for short time acquisitionswere compared. The conducted experiments showed that the systems perform equally when conducting short frames imaging. Furthermore, the fast imaging mode of NanoScan employing three detector positions showed better performance than the other two fast imaging modes provided by this system. Biomedical Engineerin...|$|R
40|$|The {{holographic}} principle {{is applied to}} a flat Friedmann-Robertson-Walker space-time dominated by dark energy when {{this is due to}} the presence of a k-essence scalar field, both for dark energy and phantom scenarios. In this framework, a geometrical covariant approach permits the construction of holographic hypersurfaces. The resulting covariant preferred screens, both for <b>phantom</b> and non-phantom <b>regions,</b> are then compared with those obtained by using the holographic dark energy model with the future event horizon as the infrared cut-off. In the phantom case, one of the two obtained holographic screens is placed on the big rip hypersurface, both for the covariant holographic formalism and the holographic phantom model. It is also analysed whether this covariant formalism allows a mathematically consistent formulation of fundamental theories based on the existence of a S-matrix at infinite distances. Comment: 14 pages, 6 figures. Accepted for publication in General Relativity and Gravitation. arXiv admin note: substantial text overlap with arXiv: 1407. 842...|$|R
40|$|We {{consider}} a modified gravity fluid on a Randall-Sundrum II brane situated at y = 0, the action containing a power α of the scalar curvature. As is known from 4 D spatially flat modified gravity, {{the presence of}} a bulk viscosity may drive the cosmic fluid into the <b>phantom</b> <b>region</b> (w − 1). The condition for this to occur is that the bulk viscosity contains the power (2 α − 1) of the scalar expansion. We combine this with the 5 D RS II model, and find that the Big Rip, occurring for α> 1 / 2, carries over to the metric for the bulk metric, |y |> 0. Actually, the scale factors on the brane and in the bulk become simply proportional to each other. Keywords: modified gravity; viscous cosmology; Randall-Sundrum model. ...|$|E
40|$|We {{perform a}} {{detailed}} confrontation of various oscillating dark-energy parame-trizations {{with the latest}} sets of observational data. In particular, we use data from Joint Light Curve analysis (JLA) sample from Supernoave Type Ia, Baryon Acoustic Oscillations (BAO) distance measurements, Cosmic Microwave Background (CMB) observations, redshift space distortion, weak gravitational lensing, Hubble parameter measurements from cosmic chronometers, and the local Hubble constant value, and we impose constraints on four oscillating models. We find that all models are bent towards the <b>phantom</b> <b>region,</b> nevertheless in {{the three of them}} the quintessential regime is also allowed within 1 σ confidence-level. Furthermore, the deviations from ΛCDM cosmology are small, however for two of the models they could be visible at large scales, through the impact on the temperature anisotropy of the CMB spectra and on the matter power spectra. Comment: 22 pages, 5 Tables, 18 figure...|$|E
40|$|Here, we peruse cosmological {{usage of}} the most {{promising}} candidates of dark energy in the framework of $f(T) $ gravity theory. We reconstruct the different $f(T) $ modifed gravity models in the spatially flat FRW universe according to entropy-corrected versions of the holographic and new agegraphic dark energy models in power-law and logarithmic corrections, which describe accelerated expansion history of the universe. We conclude that the equation of state parameter of the entropy-corrected models can transit from quintessence state to phantom regime as indicated by recent observations or can lie entirely in the <b>phantom</b> <b>region.</b> Also, using these models, we investigate the different erase of the stability {{with the help of the}} squared speed of sound. Comment: 20 pages, 40 figures, Accepted in EPJC. arXiv admin note: text overlap with arXiv: 1004. 1805 by other author...|$|E
40|$|The aim is {{to study}} the density, isodose depths, and doses at {{different}} points in slab-pinewood-slab (SPS) phantom, solid phantom SP 34 (made up of polystyrene), and chest level of actual patient for developing heterogeneous chest <b>phantom</b> mimicking thoracic <b>region</b> of human body. A 6 MV photon beam of field size of 10 cm× 10 cm was directed perpendicular to the surface of computed tomography (CT) images of chest level of patient, SPS phantom, and SP 34 phantom. Dose was calculated using anisotropic analytical algorithm. Hounsfield units were used to calculate the density of each medium. Isodose depths in all the three sets of CT images were measured. Variations between planned doses on treatment planning system (TPS) and measured on linear accelerator (LA) were calculated for three points, namely, near slab-pinewood interfaces (6 and 18 cm depths) and 10 cm depth in SPS phantom and at the same depths in SP 34 phantom. Density of pinewood, SP 34 slabs, chest wall, lung, and soft tissue behind lung was measured as 0. 329 ± 0. 08, 0. 999 ± 0. 02, 0. 898 ± 0. 02, 0. 291 ± 0. 12, and 1. 002 ± 0. 03 g/cc, respectively. Depths of 100 % and 90 % isodose curves in all the three sets of CT images were found to be similar. Depths of 80 %, 70 %, 60 %, 50 %, and 40 % isodose lines in SPS phantom images were found to be equivalent to that in chest images, while it was least in SP 34 phantom images. Variations in doses calculated at 6, 10, and 18 cm depths on TPS and measured on LA were found to be 0. 36 %, 1. 65 %, and 2. 23 %, respectively, in case of SPS phantom, while 0. 24 %, 0. 90 %, and 0. 93 %, respectively, in case of SP 34 slab phantom. SPS phantom seemed equivalent to the chest level of human body. Dosimetric results {{of this study indicate that}} patient-specific quality assurance can be done using chest <b>phantom</b> mimicking thoracic <b>region</b> of human body, which has been fabricated using polystyrene and pinewood...|$|R
40|$|Background and purpose: In {{lung cancer}} patients, the {{accuracy}} of dose calculation by radiotherapy treatment planning systems may be reduced {{by the presence of}} tissue inhomogeneities. Intensity-Modulated Radiotherapy (IMRT) and Volumetric Modulated Arc Therapy (VMAT) commonly include the use of small field segments which can exacerbate these issues. A multicentre dosimetry audit was undertaken to verify {{the accuracy of}} treatment delivery at participating centres. Materials and methods: An inhomogeneous <b>phantom</b> with <b>regions</b> of lung equivalent materials was used. The audit consisted of two parts: basic beam model tests and clinical trial plan measurements. An ArcCheck diode array was used to measure fluences from the treatment delivery. Ion chamber and film planar dose readings near the interface were acquired. Results: Nine centres were visited, with a total of eleven distinct combinations of planning and delivery system. Significant differences were found in ion chamber dose measurements in basic beam model tests between treatment planning system algorithms. For the clinical trial plan test, gamma analysis of the entry and exit dose fluence showed good agreement, with mean pass rates of 97. 2 % (95 % CI: 95. 3 – 99. 1) and 99. 0 % (95 % CI: 98. 3 – 99. 7) for tolerances of 3 %/ 2  mm and 3 %/ 3  mm respectively. No {{significant differences were found between}} treatment planning system algorithms, delivery techniques and linac manufacturers. Conclusion: This multi-centre dosimetry audit of complex IMRT/VMAT delivery provides confidence in the accuracy of modern planning and delivery systems in inhomogeneous tissues. The findings from this study can be used as a reference for future dosimetry audits...|$|R
40|$|The aim of {{this study}} was to {{investigate}} the extent to which measurements made in an ADC (apparent diffusion coefficient) calibration phantom could be shown to correlate with accuracies of measurements made in normal liver. Ideally, a strong correlation might be used in the future in order to perform an assessment of scanner performance based entirely on the phantom. Several metrics of image quality were automatically extracted from the <b>phantom</b> and ROI’s (<b>regions</b> of interest) were identified manually for human livers. Analysis was performed in two stages, firstly looking at correlations between metrics measured in the phantom in order to gain an understanding of reliability, and secondly looking at the reproducibility of human data. Correlations in phantom measurements help to identify which of the possible summary statistics are likely to be best measured and meaningful. This has allowed us to refine our definitions of the parameters which are most useful for summarising phantom data. It has also allowed us to identify phantom design weaknesses which might be improved. Repeatability in humans sets a limit for realistic clinical performance and also highlights potential problems in current methodology...|$|R
40|$|The {{proposal}} of pilgrim dark energy {{is based on}} the speculation that phantom-like dark energy possesses enough resistive force to preclude the black hole formation in the later universe. We explore this phenomenon by assuming the generalized ghost version of pilgrim dark energy. We find that most of the values of the interacting (ξ^ 2) as well as pilgrim dark energy (u) parameters push the equation of state parameter towards <b>phantom</b> <b>region.</b> The squared speed of sound shows that this model remains stable in most of the cases of ξ^ 2 and u. We also develop ω_Λ-ω'_Λ plane and observe that this model corresponds to thawing as well as freezing regions. Finally, it is shown that the non-interacting and interacting generalized ghost versions of pilgrim dark energy correspond to ΛCDM limit on the statefinder plane. Comment: 17 pages, 8 figure...|$|E
40|$|We {{compute the}} {{graviton}} one loop {{contribution to a}} classical energy in a traversable wormhole background. The form of the shape function considered is obtained by the equation of state p=ωρ. We investigate {{the size of the}} wormhole {{as a function of the}} parameter ω. The investigation is evaluated by means of a variational approach with Gaussian trial wave functionals. A zeta function regularization is involved to handle with divergences. A renormalization procedure is introduced and the finite one loop energy is considered as a self-consistent source for the traversable wormhole. The case of the <b>phantom</b> <b>region</b> is briefly discussed. Comment: Uses RevTeX 4. 21 pages. Submitted to Classical and Quantum Gravity. Extended version of the talk given at ERE 2006 (Palma de Mallorca, September 4 - 8, 2006) and of the talk given at MG 11 -GT 5, Berlin, 23 - 29 July, 200...|$|E
40|$|Singularities in {{the dark}} energy late {{universe}} are discussed, {{under the assumption that}} the Lagrangian contains the Einstein term R plus a modified gravity term R α, where α is a constant. The 4 D fluid is taken to be viscous and composed of two components, one Einstein component where the bulk viscosity is proportional to the scalar expansion θ, and another modified component where the bulk viscosity is proportional to the power θ 2 α− 1. Under these conditions it is known from earlier that the bulk viscosity can drive the fluid from the quintessence region (w> − 1) into the <b>phantom</b> <b>region</b> (w 1 / 2, carries over to the 5 D metric in the bulk, |y |> 0. The present investigation generalizes that of an earlier paper [I. Brevik, arXiv: 0807. 1797; to appear in Eur. Phys. J. C] in which only a one-component modified fluid was present...|$|E
40|$|The {{biological}} tissue has been mimicked {{and replaced by}} other materials, which have shown cer-tain radiological similarity determined by attenuation coefficient (μ), density and atomic number. Specifically, in molecular imaging and radiation therapy have been developed multifunctional ra-diopharmaceuticals which contain beta/gamma and/or light emitters to chronic degenerative diseases treatment. Therefore, {{it is necessary to}} develop phantoms that allow optical and radi-ometric characterization. Since the agar gel has shown to be a medium which allows to model bio-logical tissue in phototherapy studies, the aim {{of this study is to}} determine whether the agar gel may be used as {{biological tissue}} substitutes in 99 mTc dosimetry. Agar gel was prepared to 1 % and 2. 3 % (water:agar) and its radiologicalproperties as: linear attenuation coefficient obtained by narrow beam geometry and XCOM software, density and effective atomic number (Zeff) were deter-mined. Using the determined μ, photontransmission was calculated by Monte Carlosimulation. The 99 mTc source region was immersed in a water <b>phantom,</b> two source <b>regions</b> were used, one source region was filled with water and another with agar gel. For both cases; the cumulated activity (A) by conjugate view method, the absorbed doseper unitcumulated activity (S) and absorbed dose (D...|$|R
40|$|Proceeding of: 2007 IEEE Nuclear Science Symposium Conference Record (NSS' 07), Honolulu, Hawaii, USA, Oct. 27 - Nov. 3, 2007 PET/CT {{has become}} the most {{comprehensive}} diagnostic tool in oncology imaging providing improved lesion identification and localization. Bone is a common site of metastasis and the quantitative accuracy of PET images in bone tissue is important for assessing response to therapy. The use of CT images for attenuation correction is becoming a standard procedure in these scanners. However the impact of CT-based attenuation correction (CTAC) on the accuracy of PET tracer uptake values measured in bone has not been carefully evaluated, having only been carefully studied in soft tissue. We investigated the accuracy of CTAC on PET bone images by comparing the attenuation coefficients with PET transmission scans. For this, we imaged frozen bovine femur segments in a 20 x 20 cm cylindrical <b>phantom.</b> Different <b>regions</b> of the bones in both images were segmented by using thresholding and erosion methods to get equivalent volume masks. Differences in linear attenuation coefficients between the two images were then calculated. We repeated this analysis using patient images from the same patient imaged on the GE Advance PET scanner and the GE Discovery STE PET/CT scanner. The impact of the errors in the linear attenuation coefficients on PET SUV measurements was evaluated by simulations using the patent images with known bone disease and elevated levels of FDG uptake in bone (e. g. SUV = 5) at disease sites. The impact of the errors in the linear attenuation coefficients was then estimated by forward projection and reconstruction, after including the effects of attenuation and attenuation correction. This work was supported in kart by Agencia Antidroga de la Comunidad de Madrid (S-SAL 2007), Ministerio de Sanidad y Consumo (CIBER CB 06 / 01 / 0079), and Ministerio de Industria (Programa CENIT). It was also supported in part by NIH grants R 01 - CA 124573 and R 01 -CA 115870...|$|R
40|$|Total scalp {{irradiation}} is {{a treatment}} technique {{used for a}} variety of supercial malignancies. Helical tomotherapy is an effective technique used for total scalp irradiation. Recent publishedwork has shown the TomoTherapy planning system to overestimate the supercial dose. In thisstudy, the supercial doses for a helical tomotherapy total scalp irradiation have been measured onan anthropomorphic phantom using radiochromic and radiographic lm as well as a new skindosimeter, the MOSkin. The supercial dose was found to be accurately calculated by the Tomo-Therapy planning system. This is in contrast to recent reports, probably due to a combination of thesmaller dose grid resolution used in planning and this particular treatment primarily consisting ofbeamlets tangential to the scalp. The supercial dose was found to increase from 33. 6 to 41. 2 Gyand 36. 0 to 42. 0 Gy over the rst 2 mm depth in the <b>phantom</b> in selected <b>regions</b> of the PTV,measured with radiochromic lm. The prescription dose was 40 Gy. The supercial dose was at theprescription dose or higher in some regions due to the bolus effect of the thermoplastic head maskand the head rest used to aid treatment setup. It is suggested that to achieve the prescription dose atthe surface 2 mm depth bolus or a custom thermoplastic helmet is use...|$|R
