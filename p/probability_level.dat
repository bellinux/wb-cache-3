867|810|Public
2500|$|According to Prof. Feuerverger, {{the goal}} of the {{statistical}} analysis is to assess the <b>probability</b> <b>level</b> of a null hypothesis: ...|$|E
50|$|The {{two main}} types of array gain when {{combining}} signals are average power of combined signals {{relative to the}} individual average power and the diversity gain related to the <b>probability</b> <b>level</b> of outage. The diversity gain is dependent on spatial correlation coefficients between antenna signals.|$|E
50|$|Once the {{criticality}} {{assessment is}} completed for each failure mode of each item, the FMECA matrix may be sorted by severity and qualitative <b>probability</b> <b>level</b> or quantitative criticality number. This enables the analysis to identify critical items and critical failure modes for which design mitigation is desired.|$|E
40|$|Monthly {{and annual}} {{distributions}} of precipitation were analyzed for a 103 -year record station. A gamma probability distribution with maximum likelihood {{estimates of the}} parameters gave the best fit. For 97 stations throughout Colombia a computer program was written to calculate 13 <b>probability</b> <b>levels</b> of precipitation using the gamma distribution. Potential evapotranspiration was calculated from climatic data at 43 of these stations using the Christiansen and Hargreaves formula. The difference between potential evapotranspiration and five <b>probability</b> <b>levels</b> of precipitation were calculated as an index of irrigation requirements...|$|R
30|$|One way ANOVA was {{analyzed}} using PSAW Statistics 18, and all values {{are presented as}} the mean ± standard deviation. The <b>probability</b> <b>levels</b> used for statistical significance were P < 0.05.|$|R
5000|$|At this point, {{in order}} to simplify the expression, the protagonist takes the limit as , i.e. as the <b>probability</b> <b>levels</b> go from grainy {{discrete}} values to smooth continuous values. Using Stirling's approximation, she finds ...|$|R
50|$|Tail {{value at}} risk (TVaR), {{also known as}} tail {{conditional}} expectation (TCE) or conditional tail expectation (CTE), is a risk measure associated with the more general value at risk. It quantifies the expected value of the loss given that an event outside a given <b>probability</b> <b>level</b> has occurred.|$|E
50|$|K, is {{a factor}} {{dependent}} on the preferred <b>probability</b> <b>level.</b> Usually, it is set at 2.77, which reflects a 95% prediction interval, in which case there is less than 5% probability that a test result would become higher or lower than the critical difference by test-retest variability {{in the absence of}} other factors.|$|E
50|$|The <b>probability</b> <b>level</b> {{is about}} equally often {{specified}} as one minus {{the probability of}} a VaR break, so that the VaR in the example above would be called a one-day 95% VaR instead of one-day 5% VaR. This generally does not lead to confusion because the probability of VaR breaks is almost always small, certainly less than 50%.|$|E
40|$|In {{order to}} {{evaluate}} interference of different growth period weeds such as Amarant (Amaranthus roflexus L.) and Lambs Quarter (Chanopodium album) on cultivars of oilseed rape, a factorial based on randomized complete block design with three replication {{was conducted in}} Agricultural Experiments at station the Islamic Azad University, Tabriz Branch in 2008. The factors were three oilseed rape fall cultivars (SLM 046, Opera, Okapi) and six controlling methods at different growth period (complete weed control, controlling weeds at 3 - 5 leaves, at 5 - 8 leaves, at the beginning flowering, at 50 % flowering, and competition of weeds {{in all of the}} time). Analysis of data revealed that effect of interference weeds on height, number of pod, oil yield was significant at 1 % <b>level</b> of <b>probability</b> and on number of grains per pod, 1000 -grains weight and grain at 5 % <b>probability</b> <b>levels.</b> The effect of oilseed rape cultivars on height, number of grains per pod, oil yield was significant at 1 % <b>probability</b> <b>levels</b> and number of pod and weight of 1000 -grain in 5 % <b>probability</b> <b>levels.</b> The highest grain yield and oil yield were found to be 54 % and 55 %, respectively as compared with those of control. Also, grain yield was correlated with number of pod(r= 0. 886), weight of 1000 -grain(r= 0. 513), number of grain in pod(r= 0. 783) significantly at 1 % <b>probability</b> <b>levels.</b> In order to increase grain yield, control with SLM 046, recommend to farmers...|$|R
30|$|The {{data were}} {{presented}} as means ± SD (n[*]=[*] 3). Moreover, SPSS software (ver. 20, USA) was used; {{the data were}} analyzed for significant differences at <b>probability</b> <b>levels</b> of *p[*]<[*] 0.05 (significant) using one-way analysis of variation (ANOVA).|$|R
30|$|In {{order to}} measure the {{goodness}} of fit of proposed model, paper present several error analyses. Mean, standard deviation (SD) and root mean square (RMS) values of error probability, ε(P), are gathered, where they are compared {{to the performance of}} the ITU-R P. 837 - 6 (2012) model. Data for comparison of prediction methods are tabulated at fixed <b>probability</b> <b>levels</b> over decades where preferred values are 0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05, and 0.1  % of time. Furthermore, mean, SD and RMS error values have been weighted over the <b>probability</b> <b>levels</b> of 0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05, and 0.1  % of time, as recommended in ITU-R P. 311 - 15 (2015).|$|R
50|$|Because {{these two}} probabilities {{are so close}} together, {{especially}} for large n, even if we run it {{a large number of}} times {{it is very difficult to}} tell whether we are operating on a YES instance or a NO instance. Attempting to achieve a fixed desired <b>probability</b> <b>level</b> using a majority vote and the Chernoff bound requires a number of repetitions that is exponential in n.|$|E
5000|$|... #Caption: A thermal {{ellipsoid}} {{model of}} one stable conformation {{of the organic}} molecule, diphenyl ether, formulaeC12H10O or (C6H5)2O, abbreviated Ph2O. Carbons (C [...] ) are shown in black, hydrogens (H) in grey-white, and the oxygen (O) in red. The thermal ellipsoids are set at a 50% <b>probability</b> <b>level,</b> and the positions of atoms and the anisotropies of position reflected in the ellipsoids derive from a crystal structure of the molecule.|$|E
50|$|The {{multiple}} comparisons problem {{also applies}} to confidence intervals. A single confidence interval with a 95% coverage <b>probability</b> <b>level</b> will contain the population parameter in 95% of experiments. However, if one considers 100 confidence intervals simultaneously, each with 95% coverage probability, the expected number of non-covering intervals is 5. If the intervals are statistically independent from each other, the probability {{that at least one}} interval does not contain the population parameter is 99.4%.|$|E
40|$|AbstractIn this paper, {{we propose}} an {{interactive}} decision making method for hierarchical multiobjective fuzzy random linear pro- gramming problems (HMOFRLP), in which multiple decision makers in a hierarchical organization {{have their own}} multiple objective linear functions with fuzzy random variable coefficients. To adress HMOFRLP, {{it is assumed that}} each decision maker has fuzzy goals for permissible <b>probability</b> <b>levels</b> in a fractile optimization model. Through a fuzzy decision, two types of membership functions of the original objective functions and the corresponding permissible <b>probability</b> <b>levels</b> are integrated, and a Pareto optimal solution concept is defined. A satisfactory solution is obtained from among a Pareto optimal solution set through the interaction with the decision makers, in which the hierarchical decision structure is reflected through the decision powers...|$|R
40|$|Cahier de {{recherche}} du Groupe HEC Paris n° 944 This paper study decision-making under {{risk and}} decision-making over time made by couples. We performed a joint experimental elicitation {{of risk and}} time preferences both for couples and for their individual members. We used general behavioral models of decision under risk and over time and measured utility, probability weighting, and discounting. Under risk, our main result is that probabilistic risk attitude for couples lay {{within the boundaries of}} individual attitudes: couples are less risk-averse than individuals at high <b>probability</b> <b>levels</b> and also less risk-seeking at low <b>probability</b> <b>levels.</b> In decision over time, couples discounted less future amounts of money than individuals. This result suggests that making joint decisions signicantly reduces revealed impatience...|$|R
30|$|Ask the {{decision}} makers {{to specify the}} <b>probability</b> <b>levels</b> β_i, i= 1, 2,...,m, weighting factor θ, target interval C^I and optimism degree of the upper level decision maker γ. Generate the initial population Pop(0) with population size N comprised by the upper level decision variable. Let t = 0.|$|R
50|$|There are dual {{interpretations of}} a p-box. It can be {{understood}} as bounds on the cumulative probability associated with any x-value. For instance, in the p-box depicted at right, the probability that the value will be 2.5 or less is between 4% and 36%. A p-box can also be understood as bounds on the x-value at any particular <b>probability</b> <b>level.</b> In the example, the 95th percentile is sure to be between 9 and 16.|$|E
5000|$|According to Prof. Feuerverger, {{the goal}} of the {{statistical}} analysis is to assess the <b>probability</b> <b>level</b> of a null hypothesis:A 'null hypothesis' can be thought of here as asserting that this cluster of names arose purely by chance under random sampling from the [...] The alternative hypothesis is the opposite of this, in some sense. It is not in the purview of statistics to conclude whether or not this tombsite is that of the New Testament family.|$|E
50|$|An {{analogous}} Bayesian {{structure is}} called a Bayesian p-box, which encloses all distributions having parameters within a subset of parameter space corresponding to some specified <b>probability</b> <b>level</b> from a Bayesian analysis of the data. This subset is the credible region for the parameters given the data, which could {{be defined as the}} highest posterior probability density region, or the lowest posterior loss region, or in some other suitable way. To construct a Bayesian p-box one must select a prior distribution, in addition to specifying the credibility level (analogous to a confidence level).|$|E
5000|$|All {{that remains}} for the protagonist {{to do is}} to {{maximize}} entropy under the constraints of her testable information. She has found that the maximum entropy distribution is the most probable of all [...] "fair" [...] random distributions, in the limit as the <b>probability</b> <b>levels</b> go from discrete to continuous.|$|R
40|$|An {{algorithm}} and code {{is provided}} for computing percentiles of skew-normal distributions with parameter λ using Monte Carlo methods. A critical values table {{was created for}} various parameter values of λ at various <b>probability</b> <b>levels</b> of α. The table will be useful to practitioners as it is not available in the literature...|$|R
5000|$|... is the {{transition}} <b>probability</b> between <b>level</b> i and level j (in s−1) ...|$|R
5000|$|Failure mode {{criticality}} assessment may be qualitative or quantitative. For qualitative assessment, a mishap probability code {{or number}} is assigned and entered on the matrix. For example, MIL - STD - 882 uses five probability levels:The failure mode may then be charted on a criticality matrix using severity code as one axis and <b>probability</b> <b>level</b> code as the other.For quantitative assessment, modal criticality number [...] is {{calculated for each}} failure mode of each item, and item criticality number [...] is calculated for each item. The criticality numbers are computed using the following values: ...|$|E
50|$|By {{combining}} eye diagramming techniques with precisely positioned BER measurements, Jim Waschura {{invented a}} technique of sweeping {{the interior of}} an eye diagram to curve-fit measurements to mathematical models representing the interior slopes of the eye diagram for random and deterministic effects. This technique is notable because many performance criteria are {{defined in terms of}} the eye opening at a specified <b>probability</b> <b>level</b> (e.g. 1E-12), that requires an impossible amount of data acquisition to measure directly. This technique allows for modest extrapolations to be performed to evaluate the 1E-12 eye opening with measurements that are acquired in only a few minutes.|$|E
5000|$|When {{delivering}} {{bad news}} the speaker {{has a lot}} to consider regarding his or her own face and the face of the hearer. In 2015, Miroslav Sirota and Marie Juanchich conducted a study on uncertainty communication with negative outcomes. The authors suggest [...] "First, speakers making a prediction may intend not only to inform about a <b>probability</b> <b>level,</b> but also to manage the hearer's faces or their own...Second, speakers perform face-managing intentions by altering (e.g. lessening or magnifying) the explicitly communicated probablility of a negative outcome...Thus, politeness theory posits that speakers use uncertainty quantifiers to pursue informative intentions and also to sugar-coat threatening news to manage the hearers' or their own faces." ...|$|E
30|$|All {{the data}} were {{subjected}} to mean averages and standard deviation. t test (test of significance) was applied to analyze the significant differences among different treatments for studied parameters. The <b>probability</b> <b>levels</b> used for statistical significance were p <  0.05 for the tests. The values shown in the figures are the mean values of three replicates with standard deviation.|$|R
30|$|This {{study was}} done as {{factorial}} base experiment in completely randomized design with two factors (different concentrations of colchicine and growth stages of treated plantlets) and ten replicates. Data analyses {{were carried out}} with the SAS 9.1 for windows software package (Statistical). Means were compared using Tukey’s Honestly Significant Difference (HSD) at the 1 % and 5 % <b>probability</b> <b>levels.</b>|$|R
40|$|Abstract—In {{this paper}} we propose new method for {{simultaneous}} generating multiple quantiles corresponding to given <b>probability</b> <b>levels</b> from data streams and massive data sets. This method provides a basis for development of single-pass low-storage quantile estimation algorithms, which differ in complexity, storage requirement and accuracy. We demonstrate that such algorithms may perform well even for heavy-tailed data. Keywords—Quantile estimation, data stream, heavy-tailed distribution, tail index. I...|$|R
40|$|A {{factorial}} {{test in the}} framework of designing complete random blocks with 3 replications was conducted in 2011 in Bandar-Anzali (North of Iran) to study the effect of assimilating stabilizer bacteria of nitrogen (Azetobacter, Azorhizobioum and Azospirilium) on the yield and yield components of rice. Given factors of this study include Azetobacter, Azorhizobioum,Azospirilium bacterium in two levels each (with and without bacteria). Results showed that Azospirilium treatment had a meaningful effect on the weight qualifications of a thousand grains rice with 5 % <b>probability</b> <b>level.</b> Reciprocal effect of Azetobacter and Azospirilium on the qualification of the grain number in a rice cluster in 1 % <b>probability</b> <b>level</b> was meaningful. Reciprocal effect of Azetobacter and Azorhizobioum on the length of the stem and number of grains in the rice cluster in 5 % <b>probability</b> <b>level</b> became meaningful. Reciprocal effect of Azospirilium and Azorhizobioum on the nitrogen content of the rice grain in 5 % <b>probability</b> <b>level</b> was meaningful. Reciprocal effect of Azetobacter, Azospirilium and Azorhizobioum on the operation of the grain and rice harvest index in 5 % <b>probability</b> <b>level</b> and on the nitrogen content of rice grain in 1 % <b>probability</b> <b>level</b> became meaningful...|$|E
30|$|The <b>probability</b> <b>level</b> for {{statistical}} significance was p[*]<[*] 0.05 throughout the study.|$|E
30|$|Two-tailed {{independent}} t-test {{was used}} to analyse differences in micromotion between the two cement groups. A <b>probability</b> <b>level</b> of P <  0.05 indicated statistical significance.|$|E
40|$|Subjects made binary {{choices of}} events which were {{generated}} by a time-vaving process which varied in a random sequence of step changes. Sizes of step change and <b>probability</b> <b>levels</b> of the generators were studied. Subjects who knew the onset of a step change responded more rapidly and had a more optimal asymptotic choice frequency than subjects who did not. Matching behavior was not observed for most conditions...|$|R
40|$|Enhancement {{of random}} {{finite element method}} in {{reliability}} analysis and risk assessment of soil slopes using Subset Simulation Abstract Random finite element method (RFEM) provides a rigor-ous tool to incorporate spatial variability of soil properties into reliability analysis and risk assessment of slope stability. However, it suffers from a common criticism of requiring extensive computa-tional efforts {{and a lack of}} efficiency, particularly at small <b>probability</b> <b>levels</b> (e. g., slope failure probability Pf< 0. 001). To address this prob-lem, this study integrates RFEM with an advanced Monte Carlo Simulation (MCS) method called “Subset Simulation (SS) ” to devel-op an efficient RFEM (i. e., SS-based RFEM) for reliability analysis and risk assessment of soil slopes. The proposed SS-based RFEM expresses the overall risk of slope failure as a weighed aggregation of slope failure risk at different <b>probability</b> <b>levels</b> and quantifies the relative contributions of slope failure risk at different <b>probability</b> <b>levels</b> to the overall risk of slope failure. Equations are derived for integrating SS with RFEM to evaluate the probability (Pf) and risk (R) of slope failure. These equations are illustrated using a soil slope example. It is shown that the Pf and R are evaluated properly using the proposed approach. Compared with the original RFEM with direct MCS, the SS-based RFEM improves, significantly, the compu-tational efficiency of evaluating Pf and R. This enhances the applica-tions of RFEM in the reliability analysis and risk assessment of slope stability. With the aid of improved computational efficiency, a sen-sitivity study is also performed to explore effects of vertical spatial variability of soil properties on R. It is found that the vertical spatial variability affects the slope failure risk significantly...|$|R
40|$|International audienceWe {{consider}} optimal {{experimental design}} for parameter estimation in nonlinear {{situations where the}} optimal experiment depends {{on the value of}} the parameters to be estimated. Setting a prior distribution for these parameters, we construct criteria based on quantiles and <b>probability</b> <b>levels</b> of classical design criteria and show how their derivatives can easily be approximated, so that classical algorithms for local optimal design can be used for their optimisation...|$|R
