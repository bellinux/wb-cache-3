1233|2823|Public
25|$|In {{social science}} research, snowball {{sampling}} {{is a similar}} technique, where existing study subjects are used to recruit more subjects into the sample. Some variants of snowball sampling, such as respondent driven sampling, allow calculation of selection probabilities and are <b>probability</b> <b>sampling</b> methods under certain conditions.|$|E
25|$|As {{long as the}} {{starting}} point is randomized, systematic sampling is a type of <b>probability</b> <b>sampling.</b> It is easy to implement and the stratification induced can make it efficient, if the variable by which the list is ordered is correlated with the variable of interest. 'Every 10th' sampling is especially useful for efficient sampling from databases.|$|E
2500|$|<b>Probability</b> <b>sampling</b> includes: Simple Random Sampling, Systematic Sampling, Stratified Sampling, Probability Proportional to Size Sampling, and Cluster or Multistage Sampling. These {{various ways}} of <b>probability</b> <b>sampling</b> have {{two things in}} common: ...|$|E
5000|$|In a <b>probability</b> <b>sample</b> (also called [...] "scientific" [...] or [...] "random" [...] sample) {{each member}} of the target {{population}} has a known and non-zero probability of inclusion in the sample. A survey based on a <b>probability</b> <b>sample</b> can in theory produce statistical measurements of the target population that are: ...|$|R
40|$|Kremling uses {{data from}} the Drug Use Forecasting (DUF) and the Arrestee Drug Abuse Monitoring (ADAM) {{programs}} to explore whether the drug estimates of DUF, using a non-probability sample, and the drug use estimates of ADAM, using a <b>probability</b> <b>sample,</b> yield different results. She finds that the drug use information in DUF and ADAM is not substantially different for marijuana, cocaine, and opiates for all sites analyzed together. Her main conclusion is that a <b>probability</b> <b>sample</b> does not produce results that are substantially different from a convenience sample. While a researcher can attempt to draw a <b>probability</b> <b>sample,</b> it is still volunteers who agree to participate just as in a convenience sample...|$|R
40|$|Since {{their first}} {{description}} by Hoeffding in 1948, U-statistics {{have been an}} important area of research and application. Their extension to simple random sampling without replacement was explored by Nandi and Sen in 1963. In 1984, Folsom developed the framework for U-statistics under a general unequal <b>probability</b> <b>sample</b> from a finite population. This research builds upon the work cited above to develop a large sample theory for U-statistics in an unequal <b>probability</b> <b>sample.</b> A projection approach is {{used to determine the}} limiting distribution. The projection {{in the case of a}} general unequal <b>probability</b> <b>sample</b> from a finite population is determined. It is shown that the U statistic and its projection are asymptotically equivalent i...|$|R
2500|$|ASTM E105 Standard Practice for <b>Probability</b> <b>Sampling</b> Of Materials ...|$|E
2500|$|ASTM E141 Standard Practice for Acceptance of Evidence Based on the Results of <b>Probability</b> <b>Sampling</b> ...|$|E
5000|$|<b>Probability</b> <b>sampling</b> includes: Simple Random Sampling, Systematic Sampling, Stratified Sampling, Probability Proportional to Size Sampling, and Cluster or Multistage Sampling. These {{various ways}} of <b>probability</b> <b>sampling</b> have {{two things in}} common: ...|$|E
40|$|The Sample Survey {{is today}} {{one of the}} most {{important}} methods for collecting information about the social and economic world. The success of the method can be attributed in part to probability selection of the <b>sample.</b> <b>Probability</b> <b>samples</b> can be complex in design, and require careful attention to detail to assure correct execution. In the SAS ® world, one tool, PROC SURVEYSELECT, is widely used for <b>probability</b> <b>sample</b> selection (se...|$|R
5000|$|Post-survey adjustments. Various robust {{procedures}} {{have been developed}} for situations where <b>sampling</b> deviate from <b>probability</b> selection, or, when we face non-coverage and non-response problems. The standard statistical inference procedures (e.g. confidence interval calculations and hypothesis testing) still require a <b>probability</b> <b>sample.</b> The actual survey practice, particularly in marketing research and in public opinion polling, which massively neglects the principles of <b>probability</b> <b>samples,</b> increasingly requires from the statistical profession to specify the conditions where non-probability samples may work.|$|R
3000|$|Our estimators of the {{parameters}} are random because a <b>probability</b> <b>sample</b> is selected {{according to some}} sampling design, such as simple random sampling [...]...|$|R
50|$|Within <b>probability</b> <b>sampling,</b> {{there are}} {{specialized}} {{techniques such as}} stratified sampling and cluster sampling that improve the precision or efficiency of the sampling process without altering the fundamental principles of <b>probability</b> <b>sampling.</b>|$|E
5000|$|... {{sampling}} techniques including {{invention of}} Area <b>Probability</b> <b>Sampling</b> ...|$|E
5000|$|ASTM E105 Standard Practice for <b>Probability</b> <b>Sampling</b> Of Materials ...|$|E
40|$|In a {{national}} field experiment, the same questionnaires were administered simultaneously by RDD telephone interviewing, by the Internet with a <b>probability</b> <b>sample,</b> {{and by the}} Internet with a non-probability sample of people who volunteered to do surveys for money. The <b>probability</b> <b>samples</b> were more representative of the nation than the non-probability sample in terms of demographics and electoral participation, even after weighting. The non-probability sample was biased toward being highly engaged in and knowledgeable about the survey’s topic (politics). The telephone data manifested more random measurement error, more survey satisficing, and more social desirability response bias than did the Internet data, and the <b>probability</b> Internet <b>sample</b> manifested more random error and satisficing than did the volunteer Internet sample. Practice at completing surveys increased reporting accuracy among the <b>probability</b> Internet <b>sample,</b> and deciding only to do surveys of on topics of personal interest enhanced reporting accuracy in th...|$|R
5000|$|Many {{surveys are}} {{not based on}} <b>probability</b> <b>samples,</b> but rather on finding a {{suitable}} collection of respondents to complete the survey. Some common examples of non-probability sampling are: ...|$|R
40|$|Abstract This study {{assessed}} {{the accuracy of}} telephone and Internet surveys of <b>probability</b> <b>samples</b> and Internet surveys of non-probability samples of American adults by comparing aggregate survey results against benchmarks. The <b>probability</b> <b>sample</b> surveys were consistently more accurate than the non-probability sample surveys, even after post-stratification with demographics. The non-probability sample survey measurements were much more variable in their accuracy, both across measures within a single survey and across surveys with a single measure. Post-stratification improved the overall accuracy {{of some of the}} non-probability sample surveys but decreased the overall accuracy of others...|$|R
5000|$|ASTM E141 Standard Practice for Acceptance of Evidence Based on the Results of <b>Probability</b> <b>Sampling</b> ...|$|E
5000|$|Partition [...] into [...] subsets [...] {{with each}} element of [...] {{belonging}} {{to one of}} the [...] with equal <b>probability</b> (<b>sampling</b> with replacement) ...|$|E
50|$|Common {{methods of}} {{conducting}} a probability {{sample of the}} household population in the United States are Area <b>Probability</b> <b>Sampling,</b> Random Digit Dial telephone sampling, and more recently, Address-Based Sampling.|$|E
40|$|OBJECTIVE: The {{design and}} {{implementation}} of a nationally representative <b>probability</b> <b>sample</b> of persons with a low-prevalence disease, HIV/AIDS. DATA SOURCES/STUDY SETTING: One {{of the most significant}} roadblocks to the generalizability of primary data collected about persons with a low-prevalence disease is the lack of a complete methodology for efficiently generating and enrolling <b>probability</b> <b>samples.</b> The methodology developed by the HCSUS consortium uses a flexible, provider-based approach to multistage sampling that minimizes the quantity of data necessary for implementation. STUDY DESIGN: To produce a valid national <b>probability</b> <b>sample,</b> we combined a provider-based multistage design with the M. D. -colleague recruitment model often used in non-probability site-specific studies. DATA COLLECTION: Across the contiguous United States, reported AIDS cases for metropolitan areas and rural counties. In selected areas, caseloads for known providers for HIV patients and a random sample of other providers. For selected providers, anonymous patient visit records. PRINCIPAL FINDINGS: It was possible to obtain all data necessary to implement a multistage design for sampling individual HIV-infected persons under medical care with known probabilities. Taking account of both patient and provider nonresponse, we succeeded in obtaining in-person or proxy interviews from subjects representing over 70 percent of the eligible target population. CONCLUSIONS: It is possible to design and implement a national <b>probability</b> <b>sample</b> of persons with a low-prevalence disease, even if it is stigmatized...|$|R
5000|$|In another study, Krosnick and a collaborator, LinChiat Chang, {{compared}} <b>probability</b> <b>samples</b> {{interviewed by}} telephone and via the Internet to an opt-in Internet sample. This study found {{the latter to}} be less representative {{of the population in}} terms of demographics and to over-represent people with high interest in the topic of the survey. http://www.knowledgenetworks.com/insights/docs/mode-04_2.pdf. To further explore the generalizability of these findings, Krosnick, along with David Yeager and other colleagues, collected data on a variety of topics via an RDD telephone survey, an Internet survey of a <b>probability</b> <b>sample,</b> and Internet surveys of seven non-probability opt-in samples of American adults. The estimates from each survey were then compared to benchmarks from official government records or high-quality federal surveys with very high response rates http://www.knowledgenetworks.com/insights/docs/mode-04_2.pdf. Using a sample of 1,000 participants, the results showed that all of the non-probability sample Internet surveys were significantly less accurate than the <b>probability</b> <b>sample</b> Internet survey in terms of primary demographics, and {{all but one of the}} non-probability sample Internet surveys were significantly less accurate than the telephone survey. http://www.knowledgenetworks.com/insights/docs/mode-04_2.pdf ...|$|R
5000|$|Sampling. The {{difference}} between <b>probability</b> <b>samples</b> (where the inclusion probabilities for all {{units of the}} target population is known in advance) and non-probability samples (which often require less time and effort but generally do not support statistical inference) is crucial. <b>Probability</b> <b>samples</b> are highly affected by problems of non-coverage (not {{all members of the}} general population have Internet access) and frame problems (online survey invitations are most conveniently distributed using e-mail, but there are no e-mail directories of the general population that might be used as a sampling frame). Because coverage and frame problems can significantly impact data quality, they should be adequately reported when disseminating the research results.|$|R
5000|$|Standard {{techniques}} like <b>probability</b> <b>sampling,</b> {{and concepts}} like focus groups, were either developed at National Analysts or {{saw some of}} their earliest application. Select other contributions to the industry include: ...|$|E
50|$|Surveys {{that are}} not based on <b>probability</b> <b>sampling</b> have greater {{difficulty}} measuring their bias or sampling error. Surveys based on non-probability samples often fail to represent {{the people in the}} target population.|$|E
50|$|All PRRI {{surveys are}} based on <b>probability</b> <b>sampling</b> methods. For all {{national}} surveys, interviews are conducted in English and Spanish. Telephone surveys are conducted by professional interviewers on both cell phones and landlines.|$|E
40|$|Abstract. Estimation of {{the ratio}} of two totals is considered, when a <b>probability</b> <b>sample</b> from the finite {{population}} is available. Four estimators of the ratio are examined. The first one – called “simple ” – is {{the ratio of}} the Horvitz–Thompson estimators of totals; the second – the ratio of two ratio estimators of totals; the third one – the ratio of two regression estimators of totals. The fourth one is a calibrated estimator of the ratio. The variances of these estimators are compared. The properties of such estimators of the ratio are studied. The simulation results are presented. Key words: finite population, <b>probability</b> <b>sample,</b> ratio of two totals, calibrated estimator. 1...|$|R
40|$|Data {{obtained}} from national <b>probability</b> <b>sample</b> surveys provide important {{information on the}} prevalence of various health conditions and distributions of physical and biochemical characteristics of the U. S. population. The sample design of a survey specifies how sampling from a designated population over a stated period is to be accomplished. A survey's analytical objectives and interests-in particular subpopulations-affect the sample design strategy. Selected subdomains of the population often must be oversampled so that estimates {{can be made with}} acceptable precision. This article addresses sample design considerations for a national <b>probability</b> <b>sample</b> for human tissue monitoring and specimen banking. Among the sampling issues addressed are the oversampling of special populations e. g., minority groups and at-risk groups such as low income or elderly persons; geographic coverage; and sample size considerations. The sample design for a major health survey, the Third National Health and Nutrition Examination Survey (NHANES ll), is used to illustrate a complex, multistage <b>probability</b> <b>sample</b> design and to highlight some of the sampling issues discussed in this article. - Environ Health Perspect 1 03 (Suppl 3) : 55 - 60 (1995) Key words: survey design, oversampling, stratification, multistage samplin...|$|R
40|$|Since the {{inception}} of the American National Election Study (ANES) in the 1940 s, data have been collected via face-to-face interviewing in the homes of members of area <b>probability</b> <b>samples</b> of American adults, the same gold-standard approach used by the U. S. Census Bureau, other federal agencies, and some nongovernment researchers for many of the most high-profile surveys conducted today. This paper explores whether comparable findings about voters and elections would be obtained by a different, considerably less expensive method: Internet data collection from nonprobability samples of volunteer respondents. Comparisons of the 2000 and 2004 ANES data (collected via face-to-face interviewing with national <b>probability</b> <b>samples)</b> with simultaneous Internet surveys of volunteer samples yielded many differences in the distributions of variables and in the associations between variables (even controlling for differences between the samples in reported interest in pol-itics). Accuracy was higher for the face-to-face/probability sample data than for the Internet/ volunteer sample data in 88 % of the possible comparisons. This suggests that researchers interested in assuring the accuracy of their findings in describing populations should rely on face-to-face surveys of <b>probability</b> <b>samples</b> rather than Internet samples of volunteer respondents. ...|$|R
50|$|The {{project is}} {{organized}} through {{a partnership between}} Princeton University, the University of Michigan, and the Arab Reform Initiative. Results are based on face-to-face interviews using multi-stage <b>probability</b> <b>sampling</b> to select respondents eighteen {{years of age or}} older.|$|E
50|$|In {{social science}} research, snowball {{sampling}} {{is a similar}} technique, where existing study subjects are used to recruit more subjects into the sample. Some variants of snowball sampling, such as respondent driven sampling, allow calculation of selection probabilities and are <b>probability</b> <b>sampling</b> methods under certain conditions.|$|E
50|$|Conceptually, simple random {{sampling}} is the simplest of the <b>probability</b> <b>sampling</b> techniques. It requires a complete sampling frame, {{which may not be}} available or feasible to construct for large populations. Even if a complete frame is available, more efficient approaches may be possible if other useful information is available about the units in the population.|$|E
30|$|As the {{popularity}} of classroom observations has increased, they have been implemented in many longitudinal studies with large <b>probability</b> <b>samples.</b> Given the complexity of longitudinal measurements, {{there is a need}} for tools to investigate both growth and the properties of the measurement scale.|$|R
30|$|Despite {{the rise}} in their numbers, there is limited data and {{understanding}} of life satisfaction in Asian American adolescents. Our study aims to explore the relationship between extensive demographic and contextual factors and global life satisfaction among this specific population using nationally representative <b>probability</b> <b>sample.</b>|$|R
40|$|American Institutes for Research This study uses a {{national}} <b>probability</b> <b>sample</b> of 1, 027 {{mathematics and science}} teachers to provide the first large-scale empirical comparison of ef-fects of different characteristics of professional development on teachers’ learning. Results, based on ordinary least squares regression, indicate thre...|$|R
