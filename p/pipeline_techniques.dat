12|421|Public
40|$|Most modern {{processors}} rely on <b>pipeline</b> <b>techniques</b> {{to achieve}} high throughput. This work reports {{the development of}} scalable, floating-point (FP) arithmetic operators with variable number of pipeline stages. A new algorithm for pipeline insertion was developed and used for FP Multiplication and FP Addition. The use of this algorithm enables operating frequencies up to 175 MHz when implemented on a Xilinx Virtex II FPGA. Future work includes the automation {{of the process and}} the inclusion of the algorithm into FP square root and division units. <b>Pipeline</b> <b>techniques</b> allow operating a circuit at high clock rates by dividing a large task into smaller non...|$|E
40|$|FPGA {{technology}} {{has been used for}} {{the development and implementation of}} a prototype input queuing module of the Illinois Pulsar-based Optical INTconnect (iPOINT) Asynchronous Transfer Mode (ATM) testbed. <b>Pipeline</b> <b>techniques</b> were extensively used to solve timing problems and increase throughput. This prototype queuing module has been fully tested for bandwidth of 100 Mbps...|$|E
40|$|Parallel {{compositing}} {{techniques have}} traditionally focused on distributed memory architectures with communication of pixel values usually being the main bottleneck. On shared memory architectures, communication is handled through memory accesses, obviating {{the need for}} explicit communication steps. Shared memory architectures with multiple graphics accelerators provide the capability for parallel rendering while combining the partial results from multiple graphics adaptors requires compositing. For this reason, in this paper shared memory architectures are considered for compositing operations. A number of previously introduced parallel compositing algorithms are compared on a shared memory machine, including the binary swap and parallel <b>pipeline</b> <b>techniques...</b>|$|E
40|$|Abstract. This paper {{describes}} a SRAM design using the <b>pipelining</b> <b>technique</b> {{which has been}} used in many microprocessors extensively. The main purpose to design SRAM with the <b>technique</b> of <b>pipelining</b> is to improve the whole performance of the SRAM based on the characteristic of the <b>pipelining</b> <b>technique</b> that it can incease exponentially the circuit performance. A 2 -stage pipelining 4 K SRAM has been verified by simulation, and the results demonstrate that the performance of the read operation can be improved twice if the <b>pipelining</b> <b>technique</b> has been used compared with the conventional SRAM operation...|$|R
40|$|In today’s modern world, people {{needs the}} {{fastness}} and efficiency in any {{system that we}} considered. So, {{there is a need}} for a mechanism which satisfied the needs of network users. <b>Pipelining</b> is a <b>technique</b> that allows the execution of many jobs to overlap in time. Overlapping is accomplished by dividing each job into stages. This study presents concepts of medium access control layer in the IEEE 802. 11 Distributed Coordinated Function (DCF). Also, it modifies the medium access control layer mechanism and implementing it in the <b>pipelining</b> <b>technique.</b> The <b>pipelining</b> <b>techniques</b> used are partial <b>pipelining</b> <b>technique</b> and total <b>pipelining</b> <b>technique.</b> In the existing technique one control channel and one data channels are used. The control channel is for contention resolution and the data channel is for transmitting data and to receive acknowledgment. But in the proposed technique two contention resolution channels and one data channel is used...|$|R
5000|$|A deep {{familiarity}} with post-production <b>pipelines,</b> <b>techniques,</b> and software ...|$|R
40|$|This paper {{describes}} {{the design of}} a 17 bit 4 stage pipelined Reduced Instruction Set Computer (RISC) processor using Verilog HDL in Xilinx. The processor implements the Harvard memory architecture, so the instruction and data memory spaces are both physically and logically separate. There is 5 bit opcode with totally 23 set of instructions. The CPU designed by using the pipelining and it will increase speed of processor with CPI= 1. The pipeline stages such as fetch, decode, execute and store are used. The RISC processor architecture presented in this paper is designed by using Registers, arithmetic and logical unit, Memory with <b>pipeline</b> <b>techniques.</b> Memory access is done only by using Load and Store instructions...|$|E
40|$|This thesis {{described}} {{the process of}} creating a full Performance Animation pipeline from motion capture to virtual character animation. In this <b>pipeline,</b> <b>techniques</b> are discussed to detect and handle mislabeled motion capture markers, reduce data noise by means of a Kalman filter, extrapolate and interpolate, as well as skeleton reconstruction and inverse kinematics by means of the Cyclic Coordinate Descent Algorithm. The animations are created using different setups of markers and joint freedom, in order to test the effects markers and joints have on the perceived naturalness and determine the optimal configuration. An alternative way of indicating naturalness is described using objective error metrics, which show a moderately strong correlation to perceived naturalness data obtained through a user case study...|$|E
40|$|In {{high-speed}} printed media inspection environments, {{image restoration}} pipelines {{play a critical}} role in establishing and continually evaluating performance. A key role of such systems is to understand, mitigate (and possibly remove) artifacts introduced by motion blur. An approach is proposed that uses barcodes to help calibrate a one-dimensional blur restoration <b>pipeline.</b> <b>Techniques</b> are demonstrated whereby the structure of barcode markings may be leveraged to estimate motion blur parameters, even under extreme blur conditions or when the barcode is unknown. In addition, a framework for comparing blur estimation procedures based on barcode readability is introduced. These techniques can be applied independently of one another, but together form a set of useful tools for blur restoration pipeline calibration. Within this framework, it is shown that a low-complexity blur estimation strategy demonstrates performance competitive with state-of-the-art approaches in term of speed and accuracy...|$|E
40|$|Abstract: In {{this paper}} the adding up and {{subtraction}} problem of two floating figures is described with using <b>pipeline</b> <b>technique.</b> <b>pipeline</b> <b>technique</b> models {{construction in the}} form of Colored Petri Net is introduced. For the simulation and analysis of the model the Design/CPN tool is used and its modeling with CPN Tools. Key words: Exponent Floating point Pipeline Petri net CPN Manti...|$|R
5000|$|Consider a {{condition}} {{that we are able}} to apply both parallel processing and <b>pipelining</b> <b>techniques,</b> it is better to choose parallel processing techniques with the following reasons ...|$|R
40|$|FIR {{filters are}} being {{designed}} using HDL languages {{to enhance the}} speed of the system. In the whole system if {{the speed of the}} individual block is enhanced, the overall speed of the system is enhanced. In order to obtain effective utilization hardware is done by applying the <b>pipelining</b> <b>technique.</b> <b>Pipelining</b> is an implementation technique in which multiple instructions are overlapped in execution. The proposed design of this paper is an attempt to optimize the system speed with minimal cost and hardware. In a filter the pipelining of multiplication is achieved by shifts and addition method. <b>Pipelined</b> <b>technique</b> may reduce area, delay and enhance speed as compared to common sub-expression elimination algorithm...|$|R
40|$|Our current {{understanding}} of the low surface brightness universe is quite incomplete, {{not only in the}} optical, but also in other wavelength regimes. As a demonstration of the type of science which is facilitated by a virtual observatory, we have undertaken a project utilizing both images and catalogs to explore the multi-wavelength, low surface brightness universe. Here, we present some initial results of this project. Our techniques are complimentary to normal data reduction <b>pipeline</b> <b>techniques</b> in that we focus on the diffuse emission that is ignored or removed by more traditional algorithms. This requires a spatial filtering which must account for objects of interest, in addition to observational artifacts (e. g., bright stellar halos). With this work we are exploring the intersection of the catalog and image domains in order to maximize the scientific information we can extract from the federation of large survey data. 1...|$|E
40|$|This work {{presents}} an approach for accelerating arbitrary-precision arithmetic on high-performance reconfigurable computers (HPRCs). Although faster and smaller, fixed-precision arithmetic has inherent rounding and overflow {{problems that can}} cause errors in scientific or engineering applications. This recurring phenomenon is usually referred to as numerical nonrobustness. Therefore, there is an increasing interest in the paradigm of exact computation, based on arbitrary-precision arithmetic. There {{are a number of}} libraries and/or languages supporting this paradigm, for example, the GNU multiprecision (GMP) library. However, the performance of computations is significantly reduced in comparison to that of fixed-precision arithmetic. In order to reduce this performance gap, this paper investigates the acceleration of arbitrary-precision arithmetic on HPRCs. A Convolve-And-MErge approach is proposed, that implements virtual convolution schedules derived from the formal representation of the arbitrary-precision multiplication problem. Additionally, dynamic (nonlinear) <b>pipeline</b> <b>techniques</b> are also exploited in order to achieve speedups ranging from 5 x (addition) to 9 x (multiplication), while keeping resource usage of the reconfigurable device low, ranging from 11 % to 19 %...|$|E
40|$|The {{first part}} of this work {{discusses}} scientific visualization in terms of its <b>pipeline,</b> <b>techniques</b> and applications. This is followed by the analysis of program visualization with respect to program visualization systems. To understand the code structure of an existing program, scientific visualization techniques such as glyphs and orthoslice are investigated {{in the creation of a}} graphical model of a program. The second part of this work systematically investigates the characterization of scientific and program data. A Program Scientific Visualization (PSV) model, the primary contribution of this thesis, is developed to reflect a framework for the adopted systematic approach of characterizing scientific and program data. This model provides a possible solution to the scalability and navigation issues that the present program visualization systems are facing. It defines the process of mapping program data to scientific data, which is further complemented with a formalized notation. The approach considered in this thesis is novel. The third part of this work is the application of scientific visualization techniques to program data. The approach is innovative in applying mature scientific visualization techniques to visualize the structure of programs. (Abstract shortened by UMI.) ...|$|E
30|$|Modulo {{scheduling}} is {{a software}} <b>pipelining</b> <b>technique,</b> exploiting ILP to schedule multiple iterations of a loop in an overlapped form, initiating iterations {{at a constant}} rate called the initiation interval.|$|R
40|$|The work aims the {{designing}} and implementing an efficient HDLC chip. We use <b>pipelining</b> <b>technique</b> in HDLC register module {{which increases the}} throughput {{of the system and}} also helps in decreasing the delay of the system. In <b>pipeline</b> <b>technique,</b> number of instructions has been executed at the same time. The HDLC chip designed here supports two way communications means it supports full duplex communications which means that it can transmit and receive continuously. In this paper we adopt Xilinx’s Spartan- 3 E for HDLC implementation and for hardware simulation we use Modelsim SE 6. 2 C...|$|R
40|$|This article aims to {{describe}} a model to accelerate the execution of a parallel algorithm implemented on a Cell B. E. processor. The algorithm implements a technique of finding a moving target in a maze with dynamic architecture, using another <b>technique</b> of <b>pipelining</b> the data transfers between the PPU and SPU threads. We have shown that by using the <b>pipelining</b> <b>technique,</b> we can achieve an improvement of the computing time (around 40 %). It can be also seen that the <b>pipelining</b> <b>technique</b> with one SPU is {{about as good as}} the parallel technique with four SPUs...|$|R
40|$|Valid {{measurement}} of voter turnout {{is crucial to}} electoral studies. One major problem in obtaining valid turnout measurements is over-reporting, i. e. survey respondents who did not vote report having voted. Aiming to identify effective solutions to turnout over-reporting, this doctoral thesis consists of four separate but interrelated papers, plus introductory and concluding chapters. The introductory chapter reviews the causes and consequences of turnout over-reporting, providing the basis for an in-depth research into solutions. Each of the papers then addresses a question about solutions. Paper 1 critically re-examines an influential study of turnout over-reporting. The examination results highlight the need for better solutions to over-reporting. Addressing the question of "What is out there?", Paper 2 conducts a meta-analysis of studies that have experimented on innovative solutions to turnout over-reporting. Addressing the question of "What works?", Paper 3 experimentally compares two promising solutions – item-count and <b>pipeline</b> <b>techniques</b> – and finds that the former is, overall, better than the latter for preventing turnout over-reporting. Addressing the question of "Can we do better?", Paper 4 improves the design {{and analysis of the}} item-count technique, making it an even better solution to turnout over-reporting. From the results of these research papers, the concluding chapter considers the implications for developing effective solutions to turnout over-reporting, and laying the foundations for future advances in the {{measurement of}} turnout. Furthermore, the concluding chapter also discusses how the results of this doctoral research can contribute beyond election studies, towards scientific studies {{on a wide range of}} topics on which people often misreport...|$|E
40|$|Fig. 1 : Grid {{systems in}} typographic layout, UI design and {{an example of}} our {{proposed}} grid layout for a power-graph. With graphic designers playing an increasing role {{in the design of}} user interfaces for phone, tablet and desktop operating systems, this traditional grid-based design aesthetic is becoming more popular in these media. A case in point is Microsoft’s “Modern ” interface which seeks to unify app-design across devices. This resurgence of the grid-design aesthetic in new media leads us to re-examine some of the aesthetic assumptions that have been made in designing layout methods for network diagrams. Abstract — Prior research into network layout has focused on fast heuristic techniques for layout of large networks, or complex multi-stage pipelines for higher quality layout of small graphs. Improvements to these <b>pipeline</b> <b>techniques,</b> especially for orthogonal-style layout, are difficult and practical results have been slight in recent years. Yet, as discussed in this paper, there remain significant issues in the quality of the layouts produced by these techniques, even for quite small networks. This is especially true when layout with additional grouping constraints is required. The first contribution {{of this paper is to}} investigate an ultra-compact, grid-like network layout aesthetic that is motivated by the grid arrangements that are used almost universally by designers in typographical layout. Since the time when these heuristic and pipeline-based graph-layout methods were conceived, generic technologies (MIP, CP and SAT) for solving combinatorial and mixed-integer optimization problems have improved massively. The second contribution of this paper is to reassess whether these techniques can be used for high-quality layout of small graphs. While they are fast enough for graphs of up to 50 nodes we found these methods do not scale up. Our third contribution is a large-neighborhood search meta-heuristic approach that is scalable to larger networks. Index Terms—Network visualization, graph drawing, power graph, optimization, large-neighborhood search...|$|E
40|$|The energy {{consumption}} of large-scale high-performance computer (HPC) systems {{has become one}} of the foremost concerns of both data-center operators and computer manufacturers. This has renewed interest in alternative computer architectures that could offer substantially better energy-efficiency. Yet, the for the evaluation of the potential of these architectures necessary well-optimized implementations of typical HPC benchmarks are often not available for these for the HPC industry novel architectures. The in this work presented LU factorization benchmark implementation aims to provide such a high-quality tool for the HPC industry standard high-performance LINPACK benchmark (HPL) for the eight-core Texas Instruments TMS 320 C 6678 digitalsignal processor (DSP). The presented implementation could perform the LU factorization at up to 30. 9 GF/s at 1. 25 GHz core clock frequency by using all the eight DSP cores of the System-on-Chip (SoC). This is 77 % of the attainable peak double-precision floating-point performance of the DSP, a level of efficiency that is comparable to the efficiency expected on traditional x 86 -based processor architectures. A presented detailed performance analysis shows that this is largely due to the optimized implementation of the embedded generalized matrix-matrix multiplication (GEMM). For this operation, the on-chip direct memory access (DMA) engines were used to transfer the necessary data from the external DDR 3 memory to the core-private and shared scratchpad memory. This allowed to overlap the data transfer with computations on the DSP cores. The computations were in turn optimized by using software <b>pipeline</b> <b>techniques</b> and were partly implemented in assembly language. With these optimization the performance of the matrix multiplication reached up to 95 % of attainable peak performance. A detailed description of these two key optimization techniques and their application to the LU factorization is included. Using a specially instrumented Advantech TMDXEVM 6678 L evaluation module, described in detail in related work, allowed to measure the SoC’s energy efficiency of up to 2. 92 GF/J while executing the presented benchmark. Results from the verification of the benchmark execution using standard HPL correctness checks and an uncertainty analysis of the experimentally gathered data are also presented. Energiförbrukningen av storskaliga högpresterande datorsystem (HPC) har blivit ett av de främsta problemen för såväl ägare av dessa system som datortillverkare. Det har lett till ett förnyat intresse för alternativa datorarkitekturer som kan vara betydligt mer effektiva ur energiförbrukningssynpunkt. För detaljerade analyser av prestanda och energiförbrukning av dessa för HPC-industrin nya arkitekturer krävs väloptimerade implementationer av standard HPC-bänkmärkningsproblem. Syftet med detta examensarbete är att tillhandhålla ett sådant högkvalitativt verktyg i form av en implementation av ett bänkmärkesprogram för LU-faktorisering för den åttakärniga digitala signalprocessorn (DSP) TMS 320 C 6678 från Texas Instruments. Bänkmärkningsproblemet är samma som för det inom HPC-industrin välkända bänkmärket “high-performance LINPACK” (HPL). Den här presenterade implementationen nådde upp till en prestanda av 30, 9 GF/s vid 1, 25 GHz klockfrekvens genom att samtidigt använda alla åtta kärnor i DSP:n. Detta motsvarar 77 % av den teoretiskt uppnåbara prestandan, vilket är jämförbart med förväntningar på effektivteten av mer traditionella x 86 -baserade system. En detaljerad prestandaanalys visar att detta tillstor del uppnås genom den högoptimerade implementationen av den ingående matris-matris-multiplikationen. Användandet av specialiserade “direct memory access” (DMA) hårdvaruenheter för kopieringen av data mellan det externa DDR 3 minnet och det interna kärn-privata och delade arbetsminnet tillät att överlappa dessa operationer med beräkningar. Optimerade mjukvaruimplementationer av dessa beräkningar, delvis utförda i maskinspåk, tillät att utföra matris-multiplikationen med upp till 95 % av den teoretiskt nåbara prestandan. I rapporten ges en detaljerad beskrivning av dessa två nyckeltekniker. Energiförbrukningen vid exekvering av det implementerade bänkmärket kunde med hjälp av en för ändamålet anpassad Advantech TMDXEVM 6678 L evalueringsmodul bestämmas till maximalt 2, 92 GF/J. Resultat från verifikationen av bänkmärkesimplementationen och en uppskattning av mätosäkerheten vid de experimentella mätningarna presenteras också...|$|E
50|$|The {{most recent}} approach—the over-claiming technique—assesses the {{tendency}} to claim knowledge about non-existent items. More complex methods to promote honest answers include the randomized response and unmatched count techniques, {{as well as the}} bogus <b>pipeline</b> <b>technique.</b>|$|R
50|$|The promise <b>pipelining</b> <b>technique</b> (using futures to {{overcome}} latency) {{was invented by}} Barbara Liskov and Liuba Shrira in 1988, and independently by Mark S. Miller, Dean Tribble and Rob Jellinghaus {{in the context of}} Project Xanadu circa 1989.|$|R
40|$|Prior {{work has}} shown that {{collapsible}} <b>pipelining</b> <b>techniques</b> {{have the potential to}} significantly reduce clocking activity, which can consume up to 70 % of the dynamic power in modern high performance microprocessors. Previous collapsible pipeline proposals either rely on single phase clocking (by forcing latches into transparent state) or do not discuss the mechanisms by which stages are merged. In this work two flip-flop designs featuring an additional transparent state suitable for collapsing stages are presented. Transparency is achieved either by decoupling the master and slave clocks to keep both latches transparent, or by using a bypass mux that routes around the flip-flop. Both of these designs are evaluated in the context of transparently gated pipelines, an ad-hoc collapsible <b>pipelining</b> <b>technique.</b> Detailed analysis shows that the decoupled clock flipflop is the most attractive in terms of energy and delay. 1...|$|R
40|$|This paper {{presents}} a hardware-software partitioning algorithm that exploits a loop <b>pipelining</b> <b>technique.</b> The partitioning algorithm {{is based on}} iterative improvement. The algorithm tries to minimize hardware cost through hardware sharing and hardware implementation selection without violating given performance constraint. The proposed loop <b>pipelining</b> <b>technique,</b> which is an adaptation of a compiler optimization technique for instruction level parallelism, increases parallelism within a loop by transforming the structure of an input system description. By combining this technique with our partitioning algorithm, we can further reduce the hardware cost and/or improve {{the performance of the}} partitioned system. Experiments show about 19 % performance improvement and 44 % reduced hardware for a JPEG encoder design, compared to the results without loop pipelining. 1. Introduction Mixed hardware and software implementation is common in the design of digital systems such as communication syste [...] ...|$|R
40|$|In this paper, {{we propose}} a Bi-directional Fragmental <b>Pipelining</b> (BFP) <b>technique</b> and its {{variable}} buffer size data-caching scheme BFPV {{to reduce the}} disk I/O bandwidth requirement for multimedia servers. Our mathematical analysis shows that the BFP technique is superior to the traditional unidirectional <b>pipelining</b> <b>technique</b> in terms of memory buffer space requirement. We further demonstrate that the memory buffer management using BFPV is better than that of using the fixed buffer size approach BFPF. We have mathematically proved that BFPV saves more disk I/O bandwidth than BFPF does using the same memory buffer space. Our simulation results have quantitatively confirmed our analysis...|$|R
30|$|State-of-the-art <b>pipelining</b> <b>techniques</b> in chip multi-processors (CMP) design are {{utilized}} and simulated, {{and their}} power and performance results are presented. It {{should be noted that}} so far, these techniques have mostly been tested on simple and well-known theoretical functions. To the best of our knowledge, earlier studies on power and performance on real time implementation are rare.|$|R
40|$|The {{major problem}} in {{wormhole}} routing networks is related with the contention due to message blocking. Reconfigurable networks are an alternative to reduce the negative effect that congestion produces {{on the performance of}} the network. Our work is focused on dynamic reconfiguration. This technique consists basically of placing the different processors in the network in those positions which, at each computational moment and according to the existing communication pattern among them, are more adequate for the development of such computation. In a reconfigurable architecture, the clock period is determined by the transmission time across the switch. To increase this frequency the channel <b>pipelined</b> <b>technique</b> is used. In this paper we present the foundations of reconfigurable network architecture. We show the general structure of the reconfigurable systems and we indicate the characteristics of the channel <b>pipelining</b> <b>technique.</b> Finally, we evaluate the performance of a reconfigurable system. 1...|$|R
40|$|Data-driven array {{architectures}} seem to {{be important}} alternatives for coarse-grained reconfigurable computing platforms. Their use has provided performance improvements over microprocessors and shorter programming cycles than FPGA-based platforms. As with other architectures, in data-driven architectures loop pipelining {{plays an important role}} to improve performance. Usually this kind of pipelining can be achieved using the dataflow software <b>pipelining</b> <b>technique</b> or other software pipelining approaches. Although performance improvements are achieved, those techniques heavily depend on the insertion of pipelining stages and thus require complex balancing efforts. Furthermore, those techniques statically define the pipelining and do not take fully advantage of the dynamic scheduling attainable by the data-driven concept. This paper presents a novel scheme to pipeline loops in data-driven architectures, orchestrated by a handshaking protocol. Using the new approach, self loop pipelining is naturally achieved. The scheme is based on duplicating cyclic hardware structures, in order they are autonomously executed, with synchronization being achieved by the data flow. It can be applied to nested loops, requires less aggressive pipeline balancing efforts than usual software <b>pipelining</b> <b>techniques,</b> and innermost loops with conditional structures can be pipelined without conservative pipelining implementations. We show results of using the proposed technique when mapping algorithms in imperative programming languages to the PACT eXtreme Processing Platform (XPP). The results confirm improvements over the use of conventional loop <b>pipelining</b> <b>techniques.</b> Better performance and fewer resources are achieved in a number of cases...|$|R
40|$|ABSTRACT: This Research paper {{includes}} {{designing a}} area efficient and low error Discrete Cosine Transform. This area efficient and low error DCT is obtained by using shifters and adders {{in place of}} multipliers. The main technique used here is CSD (Canonical Sign Digit) technique. CSD technique efficiently reduces redundant bits. <b>Pipelining</b> <b>technique</b> is also introduced here which reduces the processing time. I...|$|R
40|$|We {{propose a}} novel {{delivery}} mechanism called 2 -Phase Service Model to deliver video data to home users {{connected to the}} Internet through a low-bandwidth device such as a modem. In our scheme, non-adjacent fragments of the requested video file are first downloaded to the client during Initialization Phase. The missing fragments are transmitted to the client as the video is being played out, using a novel <b>pipelining</b> <b>technique.</b> This scheme offers several benefits as follows. First, it allows the user to perform a quick preview through the video with minimal delay. Second, it naturally supports VCR functionality with almost no delay {{as demonstrated by the}} simulation results shown in the paper. Finally, our mathematical analysis shows that despite the desirable features it offers, 2 -Phase Service Model does not incur any more initialization delay than that of the conventional <b>pipelining</b> <b>technique.</b> KEYWORDS: Video player, VCR functions, home users, World-Wide-Web, digital libraries, pipelin [...] ...|$|R
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references: p. 46 - 47. Issued also on microfiche from Lange Micrographics. In this thesis, we study the applicability of <b>pipelining</b> <b>techniques</b> to the development of parallel algorithms for scientific computation. General principles for <b>pipelining</b> <b>techniques</b> are discussed and two applications, Gram-Schmidt orthogonalization and chasing algorithms, are considered. For each application, the pipelined parallel implementation is discussed and performance analysis is presented. For Gram-Schmidt orthogonalization, we investigate pipelined parallel algorithms based on various columnwise partitioning schemes. For chasing algorithms, in addition to the pipelining, we apply block-cyclic partitioning, group message-passing techniques to enhance the performance of the pipelined parallel algorithms. The numerical results for the use of these techniques are also presented and compared...|$|R
40|$|We {{specify the}} ARM 2 RISC {{microprocessor}} using the Gurevich Abstract State Machine methodology, and prove the correctness of its <b>pipelining</b> <b>techniques.</b> The Gurevich Abstract State Machine (ASM) methodology, {{formerly known as}} the evolving algebra or ealgebra methodology, first proposed by Yuri Gurevich in [5], is a simple yet powerful methodology for specifying and verifying software and hardware systems. ASMs have been applied {{to a wide variety of}} software and hardware systems: programming languages, distributed protocols, architectures, and so on. See [2, 8] for numerous examples. The ARM 2 [1, 4] is one of the early commercial RISC microprocessors. Key features of this processor include a load/store architecture, a 32 -bit datapath, conditional execution of every instruction, and a small but powerful instruction set. In this paper, we specify the ARM 2 microprocessor and prove the correctness of its <b>pipelining</b> <b>techniques.</b> We begin with a self-contained introduction to sequential ASMs in [...] ...|$|R
40|$|The {{performance}} of the <b>pipelining</b> <b>technique</b> is highly dependent on the data dependency between instructions. In this paper, a pipeline scheduling algorithm, called hazards minimization with rotation scheduling (HAMMRS), is proposed to reduce pipeline hazards imposed by the data dependencies of the instructions in a loop. The HAMMRS algorithm {{is based on an}} architecture sensitive graph model, pipeline data- ow graph. Several important scheduling properties of our model are derived. The algo-rithm applies a loop <b>pipelining</b> <b>technique,</b> called rotation scheduling, to a non-optimized initial schedule table and shorten the length of the schedule table by implicitly reducing data-dependent hazards. The best position of a re-scheduling node is selected by a simple formula we derived and proved. Experimen-tal results, from several pipeline architectures, such as those having di erent pipeline types, and using or not using forwarding techniques exhibit the e ciency of the method, and show that each schedule length of benchmarks can be signi cantly reduced. ...|$|R
40|$|FIR {{filters are}} being {{designed}} using HDL languages {{to enhance the}} speed of the system. In the whole system if {{the speed of the}} individual block is enhanced, the overall speed of the system is enhanced. In order to attain effective utilization hardware is done by applying the <b>pipelining</b> <b>technique.</b> <b>Pipelining</b> is an implementation technique in which multiple instructions are overlapped in execution. The proposed design of this paper is an attempt to optimize the system speed with minimal cost and hardware. The central design concept is to build filters with higher operating frequency without sacrificing the performance of original filters. To enhance system speed and reducing implementation complexity, a lot of work has been done in the process of achieving digital signal processing by use of the FPGA. In a filter the pipelining of multiplication is achieved by shifts and addition method. This paper describes the design of Third order low pass FIR filter with pipelined architecture. The design synthesis is done using Xilinx ISE 12. 1 and implemented in Spartan- 3 E FPGA. By pipelining the delay of FIR filters can be reduced. <b>Pipelined</b> <b>technique</b> may reduce delay and enhances speed as compared to non-pipelined technique...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimited. This thesis presents a new <b>technique</b> for loop <b>pipelining</b> of perfectly-nested for-loop structures {{which is designed}} to optimize loop execution on VLIW machines. Previously implemented loop <b>pipelining</b> <b>techniques</b> provide limited performance because they explicitly include the constraints imposed by a loop's cyclic dependences in their loop pipelining process. Some loop <b>pipelining</b> <b>techniques</b> have also ignored the realistic constraint of finite resource availability in the creation of final pipelined execution schedules. The new approach presented in this thesis eliminates the problem of cyclic dependences by first applying a linear transformation to the nested loop index space to ensure a cycle-free innermost loop, which is then pipelined using modulo scheduling for a known set of resources. The transformation guarantees that the target machine's available resources are the only limit to the amount of exploitable fine-grained parallelism within the innermost loop. This results in pipelined execution schedules having near-optimal, Inter-Iteration Initiation Intervals (IMu) with the achievable performance being scalable with the addition of resources. Consequently. our loop pipelining method' utilizes more fine-grained parallelism than other loop <b>pipelining</b> <b>techniques</b> which directly incorporate a loop's cyclic dependences in their pipelinlng process. We also explicitly provide a procedure for creating the resultant pipelied execution schedules. In addition, we investigate the negative effect that the transformation has on data locality and the cache miss rate, as well as the use of iteration space tiling to restore data locality and cache miss rate to the levels expected from sequential loop execution. Lieutenant, United States Nav...|$|R
