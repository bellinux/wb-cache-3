65|601|Public
5000|$|Also keep in {{mind that}} {{convolution}} is commutative, so that the order of the two kernels does not matter and it is also possible to insert a second order derivative as well as a first order derivative kernel. These kernels are derived from the fact that any spline surface can be fitted over a square <b>pixel</b> <b>region,</b> compare to Bezier surfaces. Hast proves that such a surface can be performed as a separable convolution ...|$|E
5000|$|Spatial-taxons are {{information}} granules, {{consisting of}} a crisp <b>pixel</b> <b>region,</b> stationed at abstraction levels within a hierarchical nested scene architecture. They {{are similar to the}} Gestalt psychological designation of figure-ground, but are extended to include foreground, object groups, objects and salient object parts. Edge detection methods {{can be applied to the}} spatial-taxon region, in the same manner they would be applied to a silhouette. This method is particularly useful when the disconnected edge is part of an illusory contour ...|$|E
40|$|A {{method and}} {{apparatus}} for generating an enhanced image is provided. The method includes receiving (101) an image to be enhanced. A set of sub images is generated (103) from the image where the different sub images correspond to different spatial frequency bands for the image. A pixel value variation is determined (107) {{in a neighborhood}} region of the first <b>pixel</b> <b>region</b> {{for at least a}} first <b>pixel</b> <b>region</b> of the image. An enhanced <b>pixel</b> <b>region</b> is then generated (109) for the enhanced image by combining the first <b>pixel</b> <b>region</b> and corresponding pixel regions of sub images in response to the pixel value variation. Specifically, a weighted summation of the input image and sub images may be generated with the weights being determined in response to the luminance variance in the neighborhood region. The invention may e. g. provide improved contrast enhancement with reduced artifacts and/or noise...|$|E
3000|$|... -pixel {{region by}} the {{substrate}} deformation. Between these <b>pixel</b> <b>regions,</b> 70 <b>pixels</b> sharing 18 % {{of the region}} were not identical. We ignored the error resulting from this difference because the [...]...|$|R
40|$|Proposed circuit, called "neighborhood {{comparison}} operator," compares {{data from}} neighboring picture elements (pixels) to find peaks, ridges, and valleys in picture data. Circuit {{also able to}} expand or shrink <b>pixel</b> <b>regions.</b> Circuit concept developed for image-processing computers. Circuit handles data stream of 12 -bit pixels rather than conventional 8 or 16 bits. Consist entirely of standard logic chips...|$|R
50|$|The {{graphic display}} {{software}} {{was based upon}} software originally developed in the 1960s by Corning Glass Works for their Type 904 graphics terminal. The display for this system had characteristics to the {{similar to those of}} Tektronix storage tube display. It used small <b>pixel</b> <b>regions</b> composed of photochromic glass, which could be darkened (forming a black line image) by writing, and would display this persistently until the entire display was erased. When Corning left the market this software base was sold to Tektronix.|$|R
30|$|In Wallflower [15], a 3 -stage {{algorithm}} {{that operates}} respectively at <b>pixel,</b> <b>region</b> and frame level is presented.|$|E
30|$|T 3.9 Mx and T 11 Mx are the pixel {{values that}} exhibit the maximum pixel-integrated {{temperatures}} in the 7 [*]×[*] 7 <b>pixel</b> <b>region</b> in the 3.9 and 11 μm images, respectively.|$|E
30|$|R 1.6 Mx and R 2.3 Mx are the pixel {{values that}} exhibit the maximum {{spectral}} radiance {{values in the}} 7 [*]×[*] 7 <b>pixel</b> <b>region</b> in the 1.6 and 2.3 μm images, respectively.|$|E
40|$|We {{consider}} {{the problem of}} classifying textured regions. First, several artificial and natural textures {{will be used to}} describe the frequency and orientation multiresolution sub-band filtering. Next, Magnetic Resonance images will be used to discriminate anatomical structures. A high resolution MR data of a knee is filtered with the proposed second orientation pyramid of several levels. The filtered results were used as feature vectors as input to a supervised k-means. Results of the segmented <b>pixel</b> <b>regions</b> that represent bone, tissue, muscle and background are finally presented. ...|$|R
50|$|The {{original}} ZX Spectrum has {{a screen}} resolution of 256×192 pixels. Colour information is overlaid onto {{this as a}} grid of 8×8 <b>pixel</b> <b>regions</b> known as attribute blocks; within each attribute block, only two colours may be used out of a palette of 8 (black, blue, red, magenta, green, cyan, yellow and white). Additionally, the entire attribute block may be designated as 'bright', {{resulting in a total}} of 15 possible colours (because both bright and dark black is the same color #000000). In many programs this limitation was evident as attribute clash.|$|R
5000|$|... x11vnc keeps {{a copy of}} the X server's {{frame buffer}} in RAM. The X11 {{programming}} interface XShmGetImage is used to retrieve the frame buffer pixel data. x11vnc compares the X server's frame buffer against its copy to see which <b>pixel</b> <b>regions</b> have changed (and hence need to be sent to the VNC viewers.) Reading pixel data from the physical frame buffer can be much slower than writing to it (because graphics devices are not optimized for reading) and so a sequential pixel by pixel check would often be too slow.|$|R
30|$|In this study, we {{adopted the}} {{following}} indexes {{to examine the}} time-series variations in the thermal anomalies for each band. The calculations of these thermal anomalies were performed by examining a 7 [*]×[*] 7 <b>pixel</b> <b>region</b> exhibiting the summit of Mt Raung at its center.|$|E
40|$|In {{recent day}} for {{security}} purpose biometric authentication is used. The fingerprint geometry {{is one of}} the most recently usedtechniques of biometric authentication. This is an algorithm for matching a fingerprint image with previously given fingerprint images. The main criteria are that, this algorithm is applicable only on binary form of fingerprint image. For fixing up a <b>pixel</b> <b>region</b> near the centre the dividend rule is taken. I. e. for selecting an image segment, we made four segments of the image using the centre position of the image, and we continued that technique until the certain criteria not be full filled. After reaching the criteria, using the fixed <b>pixel</b> <b>region</b> the traversing of DB Image would be started. After traversing the DB Image if we get the satisfactory result (that means, if the value above threshold value) it will proceed further and if in the next, it will give the positive result finally we can easily say that the fingerprints are matched...|$|E
40|$|Recent work in object {{localization}} {{has shown}} that the use of contextual cues can greatly improve accuracy over models that use appearance features alone. Although many of these models have successfully explored different types of contextual sources, they only consider one type of contextual interaction (e. g., <b>pixel,</b> <b>region</b> or object level interactions), leaving open questions about the true potential contribution of context. Furthermore, contributions across object classes and over appearance features still remain unknown. In this work, we introduce a novel model for multiclass object localization that incorporates different levels of contextual interactions. We study contextual interactions at <b>pixel,</b> <b>region</b> and object level by using three different sources of context: semantic, boundary support and contextual neighborhoods. Our framework learns a single similarity metric from multiple kernels, combining pixel and region interactions with appearance features, and then uses a conditional random field to incorporate object level interactions. We perform experiments on two challenging image databases: MSRC and PASCAL VOC 2007. Experimental results show that our model outperforms current state-ofthe-art contextual frameworks and reveals individual contributions for each contextual interaction level, as well as the importance of each type of feature in object localization. 1...|$|E
5000|$|If {{only one}} {{neighbor}} fits the criterion assign <b>pixel</b> to that <b>region.</b>|$|R
30|$|The <b>pixels</b> on {{homogeneous}} <b>regions</b> are smoothed along {{all possible}} directions (isotropic smoothing).|$|R
30|$|A {{histogram}} {{of local}} color distribution is also formed {{similar to the}} HOG descriptors to characterize local color distributions in each traffic sign. For each template window which contains a candidate traffic sign, the image patch is divided into dx[*]×[*]dy non-overlapping <b>pixel</b> <b>regions.</b> A similar procedure is followed to characterize color in each cell, resulting a histogram representation of local color distributions. To minimize the effect of varying brightness in images, hue and saturation color channels are chosen and values are ignored. Normalized hue and saturation colors are histogrammed and vector-quantized. These color histograms are then concateneated with HOG to form the HOG[*]+[*]Color descriptors.|$|R
40|$|An {{adaptive}} geometric features based filtering (AGFF) technique {{with a low}} computational complexity {{is proposed}} for removal of impulse noise in corrupted color images. The effective and efficient detection is based on geometric characteristics and features of the corrupted pixel and/or the <b>pixel</b> <b>region.</b> A progressive restoration mechanism is devised using multi-pass non-linear operations. Through extensive experiments conducted using {{a wide range of}} test color images, the proposed filtering technique has demonstrated superior performance to that of well-known benchmark techniques, in terms of objective measurements, the visual image quality and the computational complexity...|$|E
40|$|This paper {{presents}} {{recent work}} on a new framework for non-blind document bleed-through removal. The framework includes image preprocessing to remove local intensity variations, <b>pixel</b> <b>region</b> classification based on a segmentation of the joint recto-verso intensity histogram and connected component analysis on the subsequent image labelling. Finally restoration of the degraded regions is performed using exemplar-based image inpainting. The proposed method is evaluated visually and numerically on a freely available database of 25 scanned manuscript image pairs with ground truth, and is shown to outperform recent non-blind bleed-through removal techniques. 1...|$|E
40|$|We {{consider}} the lossy image compression problem and propose a model-residual approach. Polynomial basis images encode the model image and powerful new trellis codes quantize the residual part. A simple bit allocation scheme determines the residual bit rates {{and a variety}} of rates are attainable without entropy coding. The trellis structure is also used to form a joint source and channel coding scheme for the residual components. Results are shown for the 0. 4 - 1. 6 bits per <b>pixel</b> <b>region.</b> Comparisons are made to several state-of-the-art techniques and show that the proposed scheme is very competitiv...|$|E
40|$|In a {{previous}} paper an adaptive transform-based coding method was introduced {{and used for}} the particular application of compressing the monochrome images of video conference sequences [1]. In the present paper the results of applying this adaptive scheme to compress still color images are presented. The basic principle of the algorithm is to encode those larger 2 N x 2 N -pixel regions featuring low image activity with a single 2 N- point transform, and code high activity 2 N x 2 N- <b>pixel</b> <b>regions</b> with four N- point transform operations. Regarding the implementation issues, a strategy to reduce the computational complexity of the algorithm is also discussed...|$|R
5000|$|Fat-tail {{distributed}} or [...] "impulsive" [...] {{noise is}} sometimes called salt-and-pepper noise or spike noise. An image containing salt-and-pepper noise will have dark <b>pixels</b> in bright <b>regions</b> and bright <b>pixels</b> in dark <b>regions.</b> This type of noise {{can be caused by}} analog-to-digital converter errors, bit errors in transmission, etc. It can be mostly eliminated by using dark frame subtraction, median filtering and interpolating around dark/bright pixels.|$|R
40|$|Multicolor {{fluorescence}} in-situ hybridization (M-FISH) technique provides color karyotyping {{that allows}} simultaneous analysis of numerical and structural abnormalities of whole human chromosomes. Currently available M-FISH systems exhibit misclassifications of multiple <b>pixel</b> <b>regions</b> {{that are often}} larger than the actual chromosomal rearrangement. This paper presents a novel unsupervised classification method based on fuzzy logic classification and a prior adjusted reclassification method. Utilizing the chromosome boundaries, the initial classification results improved significantly after the prior adjusted reclassification while keeping the translocations intact. This paper also presents a new segmentation method that combines both spectral and edge information. Ten M-FISH images from a publicly available database were used to test our methods. The segmentation accuracy was more than 98 % on average...|$|R
40|$|Abstract—A new lip-synchronization (lip-sync) {{test method}} using {{audio and video}} signals for DTV is presented. The {{proposed}} method does not interfere with or {{have any effect on}} the program being broadcast, as the time-indexed lip-sync test signals (TILTS) are embedded in a hidden region. The video TILTS is embedded into transient effect areas outside the active <b>pixel</b> <b>region,</b> making it invisible on-screen. Experimental results confirm that the time difference between audio and video signals can be easily measured at any time from the TILTS in the decoder outputs. Index Terms—DTV, lip-sync, TATS (transient effect area test signal), TILTS (time indexed lip-sync test signal). I...|$|E
40|$|Abstract—We {{describe}} {{a system for}} content-based retrieval and classifi-cation of multispectral images. Our system models images on <b>pixel,</b> <b>region</b> and scene levels. To reduce the gap between low-level features and high-level user semantics, and to support complex query scenarios that consist of many regions with different feature characteristics, we propose a prob-abilistic visual grammar that includes automatic identification of region prototypes and modeling of their spatial relationships. A Bayesian frame-work is used to automatically classify scenes based on these models. We demonstrate our system with query scenarios that cannot be expressed by traditional region or scene level approaches but where the visual grammar provides accurate classifications and effective retrieval. I...|$|E
30|$|Himawari- 8 AHI {{data are}} {{received}} at the Meteorological Satellite Center of the Japan Meteorological Agency {{and transferred to}} distribution servers at several institutes (Japan Meteorological Agency 2015 a). We downloaded the AHI full-disk data from the science web cloud of the National Institute of Information and Communication Technology (NICT, sc-web.nict.go.jp/himawari/). Radiance values {{were obtained from the}} downloaded AHI data using the correction coefficients given in each file header (Japan Meteorological Agency 2015 b), and we extracted each 101 [*]×[*] 101 <b>pixel</b> <b>region</b> that contained a volcano in its center using the geometric relationship defined by the normalized geostationary projection (Coordination Group for Meteorological Satellites 1999); these were the areas used for further analysis.|$|E
40|$|Here we {{investigate}} the automatic detection of fire <b>pixel</b> <b>regions</b> in conventional video (or still) imagery within realtime bounds. As an extension to prior, established approaches within this field we specifically look {{to extend the}} primary use of threshold-driven colour spectroscopy to the combined use of colour-texture feature descriptors as an input to a trained classification approach that is independent of temporal information. We show the limitations of such spectroscopy driven approaches on simple, real-world examples and propose our novel extension as a robust, real-time solution within this field by combining simple texture descriptors to illustrate maximal ~ 98 % fire region detection. Index Terms — fire detection, texture, real-time, nontemporal 1...|$|R
5000|$|If {{multiple}} neighbors {{match and}} are {{all members of}} the same <b>region,</b> assign <b>pixel</b> to their <b>region.</b>|$|R
40|$|MRF {{model is}} {{recognized}} as one of efficient tools for image classification. However, traditional MRF model prove to be limited for high resolution image classification. This paper presents a joint <b>pixel</b> and <b>region</b> based multi-scale MRF model for high resolution image classification. Based on initial image segmentation, the region shape information is integrated into MRF model to consider the <b>pixel</b> and <b>region</b> information simultaneously. The region shaped information is used to complement spectral signature for alleviating spectral signature ambiguity of different classes. The paper describes the unified multi-scale MRF model and classification algorithm. The qualitative and quantitative comparison with traditional MRF model demonstrates that the proposed method can improve the classification performance for regular shaped objects in high resolution image...|$|R
40|$|A {{two-dimensional}} 128 x 128 detector array for the 1. 0 - 1. 7 micron {{spectral region}} {{has been demonstrated}} with indium gallium arsenide. The 30 micron square pixels had 60 micron spacing in both directions and were designed to be compatible with a 2 D Reticon multiplexer. Dark currents below 100 pA, capacitance near 0. 1 pF, and quantum efficiencies above 80 percent were measured. Probe maps of dark current and quantum efficiency are presented along with pixel dropout data and wafer yield which was as high as 99. 89 percent (7 dropouts) {{in an area of}} 6528 pixels and 99. 37 percent (103 dropouts) over an entire 128 x 128 <b>pixel</b> <b>region...</b>|$|E
40|$|This paper {{introduces}} a monocular optical flow algorithm {{that has been}} shown to perform well at nearly real-time frame rates (1 FPS) on natural image sequences. The system is completely bottom-up, using pixel region-matching techniques. A conjugate gradient descent method is broken down into two stages; <b>pixel</b> <b>region</b> matching error measures are locally minimized, and flow field consistency constraints apply non-linear adaptive diffusion, causing confident measurements to influence their less confident neighbors. Convergence is usually accomplished with one iteration for an image frame pair. Temporal integration and Kalman filtering predicts upcoming flow fields and figure/ground separation. The algorithm is designed for flexibility: large displacements are tracked as easily as sub-pixel displacements, and higher-level information can feed flow field predictions into the measurement process...|$|E
40|$|This {{paper is}} about an attempt to unravel the {{classical}} problem of automated human face recognition. A near realtime, fully automated computer vision system was developed to detect and recognise expressionless, frontalview human faces in static images. In the implemented system, automated face detection was achieved using a deformable template algorithm based on image invariants. The natural symmetry of human faces was utilised to improve {{the efficiency of the}} face detection model. The deformable template was run down the line of symmetry of the face in search of the exact face location. Once the location of the face in an image was known, this <b>pixel</b> <b>region</b> was extracted and the test subject was recognized using principal component analysis, also known as the eigenface approach...|$|E
40|$|Abstract- Online quality {{assessment}} of various horticultural products using machine vision provides not only quick but also objective, consistent and quantitative measurement. Horticultural products {{of different sizes}} and shapes (circular or elliptical) are classified based on the area occupied, which is calculated by known geometrical method. Another factor in the classification is the detection of defects. Based on the average pixel intensity value, the horticulture product is graded as defected or healthy. The images of different horticulture products are captured using digital camera in the same illumination condition and with same background. The images of different products like potatoes, apples, oranges, tomatoes, lemons are used {{for the implementation of}} the technique. Index Terms- Horticulture products, Intensity value, machine vision, <b>pixels,</b> <b>region</b> of interest (ROI). ...|$|R
40|$|This paper {{describes}} a novel methodology for implementing video search {{functions such as}} retrieval of near-duplicate videos and recognition of actions in surveillance video. Videos are divided into half-second clips whose stacked frames produce 3 D space-time volumes of <b>pixels.</b> <b>Pixel</b> <b>regions</b> with consistent color and motion properties are extracted from these 3 D volumes by a threshold-free hierarchical space-time segmentation technique. Each region is then described by a high-dimensional point whose components represent the position, motion and, when possible, color of the region. In the indexing phase for a video database, these points are assigned labels that specify their video clip of origin. All the labeled points for all the clips are stored into a single binary tree for efficient k-nearest neighbor retrieval. The retrieva...|$|R
40|$|Several {{approaches}} to real-time video object tracking are reviewed. A new alternative approach for fast real-time object tracking based on colour thresholding is presented. Tracking is performed on non-rigid objects {{in a sequence}} of video frames based on a user-selected region of the initial frame. Details of the tracking algorithm, including colour cluster representation and <b>pixels</b> <b>region</b> grouping using run-length and noise filtering algorithm are discussed in detail. The exact contours of the tracked objects are then extracted by minimizing snake energy of thresholding results. We also experimented alpha blending the thresholding results with Canny filter edge maps to achieve more robust tracking. Foreground object colour cluster extraction at the initial frame using K-means algorithm and filtering via Foreground Extraction Mask is also discussed...|$|R
