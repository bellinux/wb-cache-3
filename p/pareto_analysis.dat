227|99|Public
50|$|ABC {{analysis}} is frequently combined with <b>Pareto</b> <b>analysis.</b>|$|E
5000|$|<b>Pareto</b> <b>Analysis</b> or Pareto chart is a {{technique}} for separating important potential causes from trivial issues. The following steps should be taken: ...|$|E
50|$|The {{application}} of the <b>Pareto</b> <b>analysis</b> in risk management allows management to focus on those risks that have {{the most impact on}} the project.|$|E
40|$|The current {{idea of the}} ‘representative agent’ {{cannot be}} readily applied to Vilfredo <b>Pareto’s</b> <b>analysis,</b> which is {{predicated}} on the heterogeneity of individuals. Indeed, recognition {{of the importance of}} heterogeneity leads Pareto to introduce statistical equilibrium as a complement to the theoretical equilibrium that results from a balance of economic forces. The {{purpose of this paper is}} to highlight the implications of Pareto’s views on heterogeneity for the study of political economy and to draw attention to the largely Italian literature that stresses Pareto’s anticipation of aspects of statistical equilibrium developed in the physical sciences...|$|R
40|$|ABSTRACT: This article {{discusses}} {{the use of}} Taguchi’s method and <b>Pareto</b> ANOVA <b>analysis</b> for optimizing the cutting parameters in turning glass fiber reinforced plastic (GFRP) composites using a poly crystalline diamond (PCD) tool for minimizing surface roughness. The cutting parameters evaluated are cutting speed, feed rate, and depth of cut. An L 27 orthogonal array, signal to noise ratio, and <b>Pareto</b> ANOVA <b>analysis</b> are {{used to analyze the}} effect of cutting parameters and its interactions. The experimental results suggest that the most significant process parameter is feed rate followed by cutting speed. The study shows that the Taguchi method and Pareto ANOVA are suitable for optimizing the cutting parameters with the minimum number of trials...|$|R
40|$|This thesis mainly {{focuses on}} {{gathering}} data regarding {{the production process}} and processes closely related in firm HART Tašky s. r. o. Based on the gathered data consideres {{ways to improve the}} firms business through rationalizing the given processes. The thesis consists of two parts: theoretical and aplication part. The theoretical part focuses mainly on operational management, production and production processes. It also focusess on Overall Equipment Effectivnes and also contains brief description of <b>Pareto's</b> <b>analysis.</b> The aplication part familiarizes the reader with the business of firm HART Tašky s. r. o. Within this firm analyses the production process and its effectivness. It also contains the calculation of the Overall Equipment Effectivnes coeficient and aplies the Paretos principle on the firms products. In case of finding inefficient processes suggests a way of racionalization and increase of effectivness of these processes...|$|R
50|$|Analyse-it Quality Control & Improvement edition {{provides}} the standard Analyse-it statistical analyses above, plus procedures for statistical process control, including Shewhart, Levey-Jennings, CUSUM, and EWMA control charts, process capability analysis, and <b>pareto</b> <b>analysis.</b>|$|E
50|$|In {{profitability}} analysis {{it is possible}} to perform a <b>Pareto</b> <b>analysis</b> by ranking output units from most profitable to least profitable. By doing so {{it is possible to}} create a so-called 'Whale Curve', graphically showing the potential margin of an organisation.|$|E
50|$|Methods {{engineers}} typically work {{on projects}} involving new product design, products with a high cost of production to profit ratio, and products associated with having poor quality issues. Different methods of project selection include the <b>Pareto</b> <b>analysis,</b> fish diagrams, Gantt charts, PERT charts, and job/work site analysis guides.|$|E
50|$|Most cycle {{counting}} frequencies are determined first by <b>Pareto</b> frequency <b>analysis,</b> and then changing the count frequency, or ABC code, as needed per item {{is based on}} per piece value, how critical the part may be, or other factors. This method requires manual arrangement and is not statistically pure since arbitrary adjustments can be made.|$|R
40|$|International audienceSetting and formulating {{system design}} {{problems}} into mathematical optimization problems {{is not always}} straightforward especially when constraints associated with the system components are not clearly defined or well known. In this paper, the authors propose a methodology based on the <b>Pareto</b> front <b>analysis</b> {{in order to help}} designers to solve this kind of problems. This approach is directly applied to the optimization of an aircraft electrical system...|$|R
40|$|We analyze {{an economy}} with inside {{financial}} assets and outside money. Households have differing restricted access on {{both types of}} assets and, according to a well-known approach, they use money to pay taxes. Since competitive equilibria are generically inefficient, we perform a <b>Pareto</b> improvability <b>analysis</b> through a monetary intervention. It results that, if the government modifies {{the amount of money}} endowments for just one consumer in period one, then Pareto improvements upon the market equilibrium are possible. ...|$|R
50|$|<b>Pareto</b> <b>analysis</b> is {{a formal}} {{technique}} useful where many possible {{courses of action}} are competing for attention. In essence, the problem-solver estimates the benefit delivered by each action, then selects a number of the most effective actions that deliver a total benefit reasonably close to the maximal possible one.|$|E
50|$|<b>Pareto</b> <b>analysis</b> is a {{creative}} {{way of looking}} at causes of problems because it helps stimulate thinking and organize thoughts. However, it can be limited by its exclusion of possibly important problems which may be small initially, but which grow with time. It should be combined with other analytical tools such as failure mode and effects analysis and fault tree analysis for example.|$|E
50|$|This is {{the idea}} 80% of tasks can be {{completed}} in 20% of the disposable time. The remaining 20% of tasks will take up 80% of the time. This principle is used to sort tasks into two parts. According to this form of <b>Pareto</b> <b>analysis</b> {{it is recommended that}} tasks that fall into the first category be assigned a higher priority.|$|E
40|$|The area {{burned in}} the {{brazilian}} Amazon during June-October 2000 was mapped using SPOT-VGT images. The burned area estimate was calibrated with Landsat TM data. <b>Pareto</b> boundary <b>analysis</b> {{was used to evaluate}} the best achievable classification accuracy, for 1. 1 km and 8 km spatial resolution imagery. Finally, we present preliminary results from an analysis of the performance of three active fire products for detecting understory fires in the Acre rainforest during 2005. Pages: 4541 - 454...|$|R
40|$|This {{research}} {{described the}} optimization {{of the process}} parameters for clad coating of alumina (Al 2 O 3) powder on AISI 1018 mild steel utilizing plasma non-transferred arc cladding process using Taguchi method and <b>Pareto</b> ANOVA <b>analysis.</b> Four factors were selected which were plasma arc current, plasma torch velocity, distance between nozzle and layer and ratio of alumina powder to binder. The analysis of {{the results showed that}} the optimal combination for high microhardness were distance between nozzle and layer at 3 mm and plasma torch velocity at 0. 03 mm...|$|R
40|$|Electrical {{distribution}} system reconfiguration is frequently addressed as a multi-objective problem, typically {{taking into account}} the system losses together with other objectives, among which reliability indicators are widely used. In the multi-objective context, <b>Pareto</b> front <b>analysis</b> enables the operator handling conflicting and even non-commensurable objectives without needing the use of additional hypotheses or weights. This paper provides advances on the application of <b>Pareto</b> front <b>analysis</b> to multi-objective distribution network reconfiguration. Starting from previous results in which genetic algorithms were effectively adopted to find the best-known Pareto front, a version of the multi-objective binary particle swarm optimization (MOBPSO) customized for distribution network reconfiguration has been developed by exploiting the internal ranking of the solutions (based on a multi-criteria decision making method in the selection of the local best) and the network topology. Furthermore, the Pareto front mismatch metric (already used by the authors to compare different methods for small networks for which the complete Pareto front can be calculated) has been generalized to be used with large systems for which only the best-known Pareto front is found. Applications to a test network and to a real urban distribution network are discussed, showing the consistent superiority of the customized MOBPSO version with respect to the application of genetic algorithms and of a more classical version of the particle swarm optimization method...|$|R
50|$|The {{multiple}} objective optimization problems involve computing the tradeoff {{between the}} costs and benefits resulting in a set of solutions {{that can be used for}} sensitivity analysis and tested in different scenarios. But there is no single optimal solution that will satisfy the global optimality of both objectives. As both objectives are to some extent contradictory, it is not possible to improve one objective without sacrificing the other. It is necessary in some cases use a different approach,(e.g. <b>Pareto</b> <b>Analysis),</b> and choose the best combination.|$|E
50|$|Cost to Serve is a process-driven {{accountancy}} tool {{to calculate}} the profitability of a customer account, based on the actual business activities and overhead costs incurred to service that customer.In the context of supply chain management {{it can be used}} to analyse how costs are consumed throughout the supply chain. It shows that each product and customer demands different activities and has a different cost profile. The product and customer profiles are often illustrated using a <b>Pareto</b> <b>analysis</b> curve which highlights those that contribute most to the company's profit and those that erode it.Unlike Activity Based Costing (ABC), Cost to Serve is not resource-intensive and focuses on aggregate analyses around a blend of cost drivers.|$|E
40|$|This bachelor's thesis {{deals with}} the {{realization}} of <b>Pareto</b> <b>analysis</b> in the system COMES Modeller. The first part describes the <b>Pareto</b> <b>analysis</b> and Lorenz curve, together with instructions, how to properly apply the <b>Pareto</b> <b>analysis</b> on data obtained from the manufacturing process. Furthermore, they are also mentioned other methods, which have applications in industry. <b>Pareto</b> <b>analysis</b> is then compared with them. The second part of this thesis focused on the system COMES and design implementation and realization Pareto chart in this system...|$|E
40|$|AbstractBest Available Techniques {{encompass}} preventive and end-of-pipe solutions {{aimed to}} contribute to the sustainability of the European industry. They are determined by the official Sevilla Process based on extensive data collection and analysis, supporting formal negotiation steps. This article presents a statistical multicriteria method applied to the dairy sector to help determine reference sites likely to use BATs. This 5 -step methodology is based on two classifications: representative or performant sites. Performant sites selected by the <b>Pareto</b> front <b>analysis</b> are better than representative sites. In the representative analysis, the size of installations seems to be inversely proportional to their environmental impacts...|$|R
40|$|The welfare {{analysis}} of P. A. Diamond's overlapping generations model is often restricted to a steady-state comparison. This paper demonstrates that a simple diagrammatic technique {{is useful for}} a <b>Pareto</b> welfare <b>analysis.</b> In particular, it shows that capital saving technological progress could make all generations (including those which level during the transition period) worse off whenever the economy is dynamic inefficient. On the other hand, technological progress always makes some generations better off {{when the economy is}} dynamic efficient. Copyright 1991 by Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association. ...|$|R
40|$|The massive {{scale and}} {{variability}} of microarray gene data creates new and challenging problems of signal ex-traction, gene clustering, and data mining, especially for temporal studies. Most data mining methods for nding interesting gene expression patterns {{are based on}} thresholding a single discriminant, e. g. a ratio of between-class to within-class variation or correlation to a template. We introduce a dierent approach for extracting information from gene microarrays {{which is based on}} a Bayesian formulation of multi-objective optimization which we call posterior <b>Pareto</b> front <b>analysis.</b> We will illustrate our methods by applying it to Fred Wright's GeneChip study. I...|$|R
40|$|The diploma thesis {{focuses on}} {{streamlining}} sales of choosen retail using <b>Pareto</b> <b>analysis.</b> Theoretical part specifies using <b>Pareto</b> <b>analysis</b> in academic thesis and mentions example of its application. The merit of this thesis is an invention of a methodology {{that could be}} used for evaluation of the assortment. This methodology helps to identify the most profitable goods which are sold in the highest numbers and thus bring the highest profit to the retail. On base of performed analysis is presented suggestion of streamlining assortment...|$|E
40|$|This paper {{presents}} a methodology for applying the Lean Six Sigma method on the educational process. After defining defects that have negative {{influence on the}} final quality evaluation of higher education and how these defects can be remedied, the <b>Pareto</b> <b>analysis</b> is done, and that is used for establishing a vital minority of the exams that are critical for examination of faculty. The next step is the Statistical Process Control (SPC) analysis that is performed on the exams that are classified as vital minority in <b>Pareto</b> <b>analysis.</b> Ishikawa diagram shows a relation between considered consequence (small number of passed exams) and all factors that influence this consequence. Based {{on the results of}} implementation of the Lean Six Sigma method in the educational process and implementation of all suggested improvements, the comparative overview of <b>Pareto</b> <b>analysis</b> is given for 2009 / 2010 and 2012 / 2013 academic year at the Faculty of Mechanical Engineering, University of Niš...|$|E
40|$|This paper {{discusses}} {{the application of}} enhanced maintenance problem recognition techniques. The main contribution {{of this study is}} the proposed combined techniques, namely snapshot model, failure mode, effect and criticality analysis (FMECA), <b>Pareto</b> <b>analysis,</b> and decision analysis by using information technology (IT). The snapshot model is part of the maintenance modelling technique while FMECA, <b>Pareto</b> <b>analysis,</b> and decision analysis are part of maintenance reliability techniques. Each of the techniques and the proposed combined techniques is explained. The case study used for this enhanced technique was the palm oil mills maintenance problem. The result and possible further enhancement is also discussed...|$|E
40|$|Keywords-dry turning; flood turning; minimum {{quantity}} lubrication (MQL); Pareto ANOVA analysis; Taguchi methods Abstract—This paper {{presents the}} experimental and analytical results of different cutting fluid supply strategies—dry, minimum quantity lubrication (MQL) and flood turning {{in terms of}} the surface finish of turned parts. Subsequently, the influence of independent input parameters on surface finish is investigated in order to optimize their effects. Three techniques—traditional <b>analysis,</b> <b>Pareto</b> ANOVA <b>analysis,</b> and the Taguchi method—are employed. Initially mild steel AISI 1030 has been selected as the work material. The results indicate that the cutting fluid supply strategy has insignificant influence on the surface finish of turned parts. However, the amount of cutting fluid in MQL showed some influence. Further research on two additional materials, aluminum 6061 and alloy steel AISI 4340, reveals that the surface roughness for different work materials is influenced differently by the cutting fluid supply strategies and there is a scope for optimizing the cutting fluid supply strategy in terms of both method and the amount of cutting fluid. This will reduce the amount of cutting fluids used and consequently, their negative impact on the environment, by avoiding unnecessary applications...|$|R
40|$|Abstract – Design Space Exploration (DSE) {{is one of}} {{the most}} {{important}} stages in High Level Synthesis designing methodology. This paper presents a novel DSE approach for the current generation of systems with heterogeneous multi parametric optimization objectives. The method introduced in this paper is capable of concurrently resolving multiple conflicting issues encountered during DSE, such as maximization of accuracy needed in the evaluation of design space with minimization in time expended to explore the best architecture. Results of the proposed method for different benchmarks indicated significant acceleration in exploration process compared to another existing approach that is also based on <b>Pareto</b> optimal <b>analysis.</b> I...|$|R
40|$|The {{thesis is}} focused on the identification, {{analysis}} and assessment of risks in three key areas (quality, environment, occupational safety and health). The paper made a risk analysis according to ISO 31000 : 2010 Risk Management - Principles and guidelines. The risk assessment of selected construction technologies were chosen following methods - analysis methods and consequences of failures (FMEA), <b>Pareto</b> diagram, <b>analysis</b> of the causes and consequences (Ishikawa) and analysis of the type of butterfly. Using these methods are evaluated selected risks to propose action to reduce its value and impact. The aim of this thesis is to identify, assess and analyze the risks and handle simple tools for the management and elimination...|$|R
40|$|Published January 2002. Reviewed December 2013. Facts and {{recommendations}} in this publication {{may no longer}} be valid. Please look for up-to-date information in the OSU Extension Catalog: [URL] 1 in this series introduced the reader to Statistical Process Control, and Part 2 provided an overview of how and why SPC works. Part 3 begins the step-by-step process of building the practical skills necessary for hands-on implementation of SPC. This report discusses <b>Pareto</b> <b>analysis,</b> a tool we can use to help decide how and where to begin using SPC. We also discuss check sheets, which are data collection tools that may be used in <b>Pareto</b> <b>analysis...</b>|$|E
40|$|The Paper {{is focused}} on risk {{analysis}} of composite bumper Arway S production process. The bumper is produced by Composite Components company for Iveco bus producer. According to discussions of expert team, several types of quality discrepancies were discovered. By using FTA analysis we discovered causes of those discrepancies. FMEA method and <b>Pareto</b> <b>Analysis</b> helped to set most dangerous discrepancies which cumulative seriousness reached 54 %. In discussion, the expert team set corrective action. In parallel with FMEA and <b>Pareto</b> <b>Analysis</b> 8 D method was used. It's results were in line with other methods and complete the whole image of the issue. Arway S is a key product and so some of those proposed corrective actions were realized immediately. As a result, the appearance of rejections with specific defect almost vanished...|$|E
30|$|From the <b>Pareto</b> <b>analysis</b> {{it could}} be {{possible}} that only CMC {{had a significant impact}} at 95 % as compared to other parameters at activity level. The parameter values were also compared with enzyme (AVICEL) and the conditions were validated here in this work as evinced by Goldbeck et al. (2013).|$|E
40|$|The {{problem of}} robust {{estimation}} of the common scale parameter of several Pareto distributions with unknown and possibly unequal shape parameters is considered. In this paper, a wide class of estimators dominating the maximum likelihood estimator (MLE) is derived under a class of convex loss functions. The problem discussed in this paper arises quite frequently in socio-economics, reliability, life testing, and survival <b>analysis.</b> <b>Pareto</b> distribution Common scale parameter Convex loss function...|$|R
40|$|Most {{methods for}} finding {{interesting}} gene expression profiles from gene microarray data {{are based on}} a single discriminant, e. g. the classical paired t test. Here a different approach is introduced based on gene ranking according to Pareto depth in multiple discriminants. The novelty of our approach, which is an extension of our previous work on <b>Pareto</b> front <b>analysis</b> (PFA), is that a gene’s relative rank is determined according to the ordinal theory of multiple objective optimization. Furthermore, the distribution of each gene’s rank, called Pareto depth, is determined by resampling over the microarray replicates. This distribution is called the Pareto depth sampling distribution (PDSD) and it is used to assess the stability of each ranking. We illustrate and compare the PDSD approach with both simulated and real gene microarray experiments...|$|R
40|$|Network {{appliances}} perform different functions {{on network}} flows and constitute {{an important part}} of an operator's network. Normally, a set of chained network functions process network flows. Following the trend of virtualization of networks, virtualization of the network functions has also become a topic of interest. We define a model for formalizing the chaining of network functions using a context-free language. We process deployment requests and construct virtual network function graphs that can be mapped to the network. We describe the mapping as a Mixed Integer Quadratically Constrained Program (MIQCP) for finding the placement of the network functions and chaining them together considering the limited network resources and requirements of the functions. We have performed a <b>Pareto</b> set <b>analysis</b> to investigate the possible trade-offs between different optimization objectives...|$|R
