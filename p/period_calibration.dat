11|540|Public
40|$|In {{this paper}} we {{describe}} our experiments on a real-time system design, focusing on design alternatives such as scheduling jittel; sensor-to-output latency, intertask com-munication schemes {{and the system}} utilization. The prime objective of these experiments was to evaluate a real-time design produced using the <b>period</b> <b>calibration</b> method [2] and thus identify {{the limitations of the}} method. We chose a computerized numerical control (CNC) machine as our target real-time system and built a realistic Controller and a plant simulatol: Our results were extracted from a con-trolled series of more than hundred test controllers obtained by varying four test variables. This study unveils many interesting facts: (I) average sensor-to-output latency {{is one of the most}} dominating fac-tors in determining control quality; (2) the effect of schedul-ing jitter appears only when the average sensor-to-output latency is suficiently small; and (3) loop processing periods are another dominating factor of pe?formance. Based on these results, we propose a new communication scheme and a new objective function for the <b>period</b> <b>calibration</b> method. ...|$|E
40|$|This paper {{proposes a}} simple and {{theoretically}} clear approach to the estimation of technological change in a multisector general equilibrium framework. This study employs the Multiple Calibration Decomposition Analysis (MCDA) to evaluate technological change {{that is responsible for}} changes in energy use and carbon dioxide emissions in the Japanese economy in the oil crises period from 1970 to 1985. The MCDA serves as an elementary way of separating structural change due to technological change from that due to price substitution effects, capturing the interdependence among economic sectors. The empirical result provides {{a better understanding of the}} effects on the economy of technological change in that significant <b>period.</b> <b>Calibration</b> Carbon dioxide emissions Energy use General equilibrium model Technological change...|$|E
40|$|This paper {{presents}} an automatic approach to synthesizing schedulable timing constraints for real-time control systems. Given the performance specifications and schedulability constraints of a real-time control system, the approach derives task-level timing constraints which can guarantee these requirements. The control performance is specified {{in terms of}} control output responses such as steady state error, maximum overshoot, settling time, and rise time, and the task-level timing constraints include task periods and deadlines. The approach consists of two components with a clean interface. The first component translates the performance specifications into a set of system-level timing constraints such as loop processing periods and input-to-output latency, via control theoretic modeling and optimization. The second then derives task-level timing constraints from the intermediate system-level timing constraints optimizing the system schedulability using <b>period</b> <b>calibration</b> method [4, 17 [...] ...|$|E
40|$|Bias {{correction}} (BC) {{has become}} a standard procedure in climate change impact studies, since climate model output often shows a bias when compared to observed data. Especially for daily precipitation, we expect {{the performance of the}} BC to depend on the length of the period used for the BC calibration. In this study we analyzed how the length of the <b>calibration</b> <b>period</b> affects the BC performance of quantile mapping (QM). We subsequently reduced the length of the <b>calibration</b> <b>period,</b> starting with a <b>calibration</b> <b>period</b> length of 30  years, and analyzed the effect on the BC performance based on three skill scores. The results show that already a small reduction in the length of the <b>calibration</b> <b>period</b> can result in a significant decrease of the BC performance. However, the critical <b>calibration</b> <b>period</b> length at which this decrease occurs, varies strongly. Nevertheless, it is larger than ten years in all experiments for all skill scores. Furthermore, the critical <b>calibration</b> <b>period</b> length is found to depend on the choice of the control period and especially on the choice of the QM method. But it has to be noted that these results are slightly different for the three skill scores. Overall, the results indicate that QM methods with many degrees of freedom, especially the empirical QM, are more vulnerable to a reduction of the <b>calibration</b> <b>period</b> length. Based on our results, we recommend to use a <b>calibration</b> <b>period</b> as long as possible and to apply QM methods with few degrees of freedom, when using QM for the BC of data that was not used in the calibration...|$|R
40|$|The {{influence}} {{of the length of}} the <b>calibration</b> <b>period</b> and observation frequency on the predictive uncertainty in time series modeling of groundwater dynamics is investigated. Studied series are from deltaic regions with predominantly shallow groundwater tables in a temperate maritime climate where heads vary due to precipitation and evaporation. Response times vary over a wide range from ∼ 60 to ∼ 1200 days. A Transfer Function-Noise model is calibrated with the Markov Chain Monte Carlo method to both synthetic series and measured series of heads. The model fit and uncertainty are evaluated for various <b>calibration</b> <b>periods</b> and observation frequencies. It is often assumed that the required length of the <b>calibration</b> <b>period</b> is related to the response time of the system. In this study, no strong relationship was observed. Results indicate, however, that the required length of the <b>calibration</b> <b>period</b> is related to the decay time of the noise. Furthermore, the length of the <b>calibration</b> <b>period</b> was much more important than the total number of observations. For the measured series, the credible intervals could commonly be reduced to ∼ 10 % of the measured head range and the prediction intervals to ∼ 50 % of the measured head range with <b>calibration</b> <b>periods</b> of 20 years with approximately two observations per month. </p...|$|R
40|$|Abstract—In {{this paper}} we analyze {{the effect of}} the <b>calibration</b> <b>period,</b> or lack of, on {{self-interference}} channel estimation in the digital domain of in-band full-duplex radio transceivers. In particular, we consider a scenario where the channel estimation must be performed without a separate <b>calibration</b> <b>period,</b> which means that the received signal of interest will act as an additional noise source from the estimation perspective. We will explicitly analyze its effect, and quantify the increase in the parameter estimation variance, or sample size, if similar accuracy for the channel estimate is to be achieved as with a separate <b>calibration</b> <b>period.</b> In addition, we will analyze how the <b>calibration</b> <b>period,</b> or its absence, affects the overall achievable rates. Full waveform simulations are then used to determine the validity of the obtained results, as well as provide numerical results regarding the achievable rates. It is shown that, even though a substantial increase in the parameter sample size is required if there is no <b>calibration</b> <b>period,</b> the achievable rates are still comparable for the two scenarios. I...|$|R
40|$|In {{this paper}} we present an {{experimental}} {{evaluation of the}} <b>period</b> <b>calibration</b> method (PCM) which was developed in (Gerber et al., 1994; Gerber et al., 1995) as a systematic design methodology for real-time systems. The objective of this experimental study is to assess design alternatives integrated into the method and their performance implication on resultant systems built via the PCM. Such design alternatives include scheduling jitter, sensor-to-output latency, intertask communication schemes, and system utilization. For this study, we have chosen a computerized numerical control (CNC) machine as our target real-time system, and built a realistic controller and a plant simulator. We show the detailed development process of the CNC controller and report its performance. The performance results were extracted from a controlled series of more than hundred test controllers obtained by varying four test variables. This study unveils several weaknesses of the PCM: (1) the communication s [...] ...|$|E
40|$|This paper {{presents}} a hardware-software (HW-SW) partitioning algorithm {{to be used}} in HW-SW codesign of an embedded real-time system. The algorithm interacts with the <b>period</b> <b>calibration</b> method proposed in [4, 5, 6] such that the period assignment and HWSW partitioning of real-time tasks are considered in a single framework. The partitioning algorithm makes use of three heuristics and one random transformation rule in order to quickly find a feasible HW-SW partition which most likely leads to the minimum HW cost design. As an experimental study, two partitioning algorithms, one that is based on the proposed heuristics and the other based on simulated annealing have been implemented. We have performed preliminary experiments and present the result. 1 Introduction Hardware-software partitioning is an important problem in designing an embedded real-time system where the design specification is implemented with both HW (ASIC, ASIP, etc) and SW (microprocessor, controller, etc) components. [...] ...|$|E
40|$|Analysis of {{anthraquinone}} secondary metabolites {{produced by}} Geosmithia spp. Zdena Křesinová Geosmithia species are little known fungal symbionts of bark beetles. Secondary metabolites from lilac colored species G. lavendula (strain MK 1008) and nine other Geosmithia species were investigated {{in order to}} elucidate their structures and quantify their production during submerged cultivation. Five hydroxylated anthraquinones (HAs) were isolated from culture media during submerged cultivation of the fungi and {{three of them were}} identified using NMR and MS techniques as 1, 3, 6, 8 - tetrahydroxyanthraquinone (1), rhodolamprometrin (1 -acetyl- 2, 4, 5, 7 - tetrahydroxyanthraquinone; 2), and 1 -acetyl- 2, 4, 5, 7, 8 -pentahydroxyanthraquinone (3). Preparation, quantification and identification of HAs in fungal samples involved a SPE step, semi-preparative HPLC/UV and UPLC/UV methods. For optimization of analytical methods, separation qualities of two types of reversed phase sub- 2 -micron particle sized columns and one 5 -micron particle sized column were tested. The most efficient Sheild RP C 18 column filled with 1. 7 µm particles was then used for quantification of HAs production during the cultivation <b>period.</b> <b>Calibration</b> curves for metabolites 2 and 3 (representing the majority of produced metabolites) were determined in [...] ...|$|E
40|$|In {{this paper}} we analyze {{the effect of}} the <b>calibration</b> <b>period,</b> or lack of, on {{self-interference}} channel estimation in the digital domain of in-band full-duplex radio transceivers. In particular, we consider a scenario where the channel estimation must be performed without a separate <b>calibration</b> <b>period,</b> which means that the received signal of interest will act as an additional noise source from the estimation perspective. We will explicitly analyze its effect, and quantify the increase in the parameter estimation variance, or sample size, if similar accuracy for the channel estimate is to be achieved as with a separate <b>calibration</b> <b>period.</b> In addition, we will analyze how the <b>calibration</b> <b>period,</b> or its absence, affects the overall achievable rates. Full waveform simulations are then used to determine the validity of the obtained results, as well as provide numerical results regarding the achievable rates. It is shown that, even though a substantial increase in the parameter sample size is required if there is no <b>calibration</b> <b>period,</b> the achievable rates are still comparable for the two scenarios. Comment: 8 pages, to be presented in the Asilomar Conference on Signals, Systems, and Computers in November 201...|$|R
40|$|To {{determine}} the quantitative {{relation between the}} Therapeutic Intervention Scoring System (TISS) {{in combination with other}} relevant clinical variables and the real costs of (paediatric) intensive care. A prospective, observational study. A Ten-bed paediatric intensive care unit in a university children's hospital. In a 17 -months registration period we collected patient- and treatment-related data for all 611 consecutive admissions. A 21 -day <b>calibration</b> <b>period</b> was used to collect detailed data to calculate the real costs of 33 consecutive admissions, in addition to the same data as in the registration period. We used the Multi Moment Measurement method to measure time spent by nurses and physicians and medication used in the 21 -day <b>calibration</b> <b>period.</b> The <b>calibration</b> <b>period</b> data set with explanatory variables including TISS was used to build a regression model to estimate nurse and physician time, which were converted to personnel costs, and to estimate medication costs. The regression models built from the <b>calibration</b> <b>period</b> were subsequently used to estimate the total costs per day and per admission in different patient groups in the registration period. It was feasible to calculate total direct medical costs based on a limited number of readily available clinical variables related to patient characteristics and treatment, of which TISS was the most important determinant. The proposed methods provide further tools for assessment of (paediatric) intensive care unit performanc...|$|R
40|$|We {{focus on}} a {{collection}} of stochastic mortality models, applied to two age buckets (20 - 89 and 60 - 89) of Dutch and Belgian mortality data. Recent literature relies on the standard ARIMA-framework (in particular: a random walk with drift) to project mortality rates. As a result the projections can be highly sensitive to the <b>calibration</b> <b>period.</b> We present a modelling strategy for the time-dependent parameters that allows for objective, statistical detection {{of one or more}} structural changes in the time series. By comparing projections based on different <b>calibration</b> <b>periods</b> and different time series specifications, we show that the proposed methodology leads to more robust mortality projections with respect to the <b>calibration</b> <b>period</b> used...|$|R
40|$|The Joint Polar Satellite System (JPSS) {{will launch}} its first JPSS- 1 {{satellite}} in early 2017. The JPSS- 1 and follow-on satellites will carry aboard {{an array of}} instruments including the Visible Infrared Imaging Radiometer Suite (VIIRS), the Cross-track Infrared Sounder (CrIS), the Advanced Technology Microwave Sounder (ATMS), and the Ozone Mapping and Profiler Suite (OMPS). These instruments {{are similar to the}} instruments currently operating on the Suomi National Polar-orbiting Partnership (S-NPP) satellite. In preparation for the JPSS- 1 launch, the JPSS program at the Center for Satellite Applications and Research (JSTAR) Calibration/Validation (Cal/Val) teams, have laid out the Cal/Val plans to oversee JPSS- 1 science products’ algorithm development efforts, verification and characterization of these algorithms during the pre-launch <b>period,</b> <b>calibration</b> and validation of the products during post-launch, and long-term science maintenance (LTSM). In addition, the team has developed the necessary schedules, deliverables and infrastructure for routing JPSS- 1 science product algorithms for operational implementation. This paper presents an overview of these efforts. In addition, this paper will provide insight into the processes of both adapting S-NPP science products for JPSS- 1 and performing upgrades for enterprise solutions, and will discuss Cal/Val processes and quality assurance procedures...|$|E
40|$|Groundwater is a {{sensitive}} component affected by climate change. Modelling {{the dynamics of}} groundwater levels is inherently difficult particularly as the response to climate change. Given this complexity, most of the current studies using long term groundwater time series were conducted by statistical analysis or using over simplified assumptions to represent the physical processes in hydrological system. With the objective of providing an improved physically based groundwater modelling approach to support climate change impact assessment, a dataset of long term time series of groundwater levels from two different soil types (sand and till) were selected from the Tärnsjö area located in southeast of Sweden. The CoupModel was chosen to perform the simulation since it offers a physically based representation on groundwater recharge processes. A two-step strategy for calibration with first short-term calibration followed by long-term testing was adopted. Simulated groundwater levels followed the general patterns of measured groundwater level dynamics; however, auto-correlations and periodicities were observed in residuals for all sites of which two sandy soil sites with deeper groundwater tables maintained strong auto-correlations in long time lags and an extra 15. 4 -year periodicity. The long memory of the system rendered it more susceptible to climate change. Uncertainty arises if different initial condition had been applied in short term <b>period</b> <b>calibration...</b>|$|E
40|$|Development of new {{automatic}} sensor-based techniques {{has expanded}} {{the possibilities for}} intensive monitoring of water quality in small catchments. In this study turbidity and concentration of nitrate-N were monitored with probes in the Savijoki catchment, which has been observed with traditional methods for decades. Particular {{attention was paid to}} implementation of the equipment, calibration of the probes and calculation methods. All equipment functioned technically well during the one year monitoring <b>period.</b> <b>Calibration</b> of turbidity and nitrate-N proved that the sampled values agree well with the probe results. However, it seems that loading estimates made with the traditional method are not very reliable for individual years. The research period in this study was exceptional with its many runoff peaks in winter. It is not possible to catch the peaks with traditional monitoring, why the results and comparisons between automatic probes and traditional monitoring cannot be generalized. However, the results proved that novel monitoring techniques have to be continued and extended. In further studies the calculation methods need developed and improved to be to get reliable loading estimations from the sensor data as simply as possible. In a changing climate, the monitoring, loading estimations, and consequently the assessment of the effect of agricultural water protection measures will probably turn even more difficult and challenging. ...|$|E
30|$|Thus {{the results}} {{indicate}} that overall prediction of DSRO by the GGIUH model during the <b>calibration</b> <b>period</b> is satisfactory and therefore may be accepted for further analysis.|$|R
40|$|The Mekong River is {{the most}} {{important}} river in Southeast Asia. It has increasingly suffered from water-related problems due to economic development, population growth and climate change in the surrounding areas. In this study, we built a distributed Geomorphology-Based Hydrological Model (GBHM) of the Mekong River using remote sensing data and other publicly available data. Two numerical experiments were conducted using different rainfall data sets as model inputs. The data sets included rain gauge data from the Mekong River Commission (MRC) and remote sensing rainfall data from the Tropic Rainfall Measurement Mission (TRMM 3 B 42 V 7). Model calibration and validation were conducted for the two rainfall data sets. Compared to the observed discharge, both the gauge simulation and TRMM simulation performed well during the <b>calibration</b> <b>period</b> (1998 - 2001). However, the performance of the gauge simulation was worse than that of the TRMM simulation during the validation period (2002 - 2012). The TRMM simulation is more stable and reliable at different scales. Moreover, the <b>calibration</b> <b>period</b> was changed to 2, 4, and 8 years to test the impact of the <b>calibration</b> <b>period</b> length on the two simulations. The results suggest that longer <b>calibration</b> <b>periods</b> improved the GBHM performance during validation periods. In addition, the TRMM simulation is more stable and less sensitive to the <b>calibration</b> <b>period</b> length than is the gauge simulation. Further analysis reveals that the uneven distribution of rain gauges makes the input rainfall data less representative and more heterogeneous, worsening the simulation performance. Our results indicate that remotely sensed rainfall data may be more suitable for driving distributed hydrologic models, especially in basins with poor data quality or limited gauge availability...|$|R
40|$|Most {{mortality}} models {{proposed in}} recent literature {{rely on the}} standard ARIMA-framework (in particular: a random walk with drift) to project mortality rates. As a result the projections are highly sensitive to the <b>calibration</b> <b>period.</b> We apply a modelling strategy for the time-dependent parameters in a large collection of mortality models that allows for objective, statistical detection {{of one or more}} structural changes. By comparing projections based on dierent <b>calibration</b> <b>periods</b> and dierent time series specications, we show that our proposed methodology leads to more robust mortality projections. status: publishe...|$|R
40|$|This is {{the author}} {{accepted}} manuscript. The final version is available from AGU via the DOI in this record. The lack of long-term, highly resolved (annual to sub-annual) and absolutely dated baseline records of marine variability extending beyond the instrumental period (last ~ 50 - 100 years) hinders our ability to develop a comprehensive {{understanding of the role}} the ocean plays in the climate system. Specifically, without such records, it remains difficult to fully quantify the range of natural climate variability mediated by the ocean, and to robustly attribute recent changes to anthropogenic or natural drivers. Here we present a 211 -year (1799 - 2010 CE; all dates hereafter are common era) seawater temperature (SWT) reconstruction from the northeast Atlantic Ocean derived from absolutely dated, annually resolved, oxygen isotope ratios recorded in the shell carbonate (δ 18 Oshell) of the long-lived marine bivalve mollusc Glycymeris glycymeris. The annual record was calibrated using sub-annually resolved δ 18 Oshell values drilled from multiple shells covering the instrumental <b>period.</b> <b>Calibration</b> verification statistics and spatial correlation analyses indicate that the δ 18 Oshell record contains significant skill at reconstructing Northeast Atlantic Ocean mean summer SWT variability associated with changes in sub-polar gyre (SPG) dynamics and the North Atlantic Current. Reconciling differences between the δ 18 Oshell data and corresponding growth increment width chronology demonstrates that 68 % of the variability in G. glycymeris shell growth {{can be explained by the}} combined influence of biological productivity and SWT variability. These data suggest G. glycymeris can provide seasonal to multi-centennial absolutely dated baseline records of past marine variability that will lead to the development of a quantitative understanding of the role the marine environment plays in the global climate system. This work was supported by the NERC-funded CLAM project; (Project No. NE/N 001176 / 1) ...|$|E
40|$|The {{purpose of}} this work is to study the annual {{patterns}} in climate parameters and to evaluate how these influence the quality of reference evapotranspiration (ETo) estimates obtained from the Hargreaves Samani (HS) equation, since the method only uses the measured temperature parameter directly. To conclude, the work evaluates how these patterns {{can be used to}} improve the HS ETo estimates. Ten year moving averages from a set of CIMIS stations were used to evaluate the relations between solar radiation (Rs), temperature (T) and ETo. The results indicate that T treads behind solar radiation and its value peaks some 25 days later. As a result, the main irrigation season in the Mediterranean climate (May 1 -September 30) can be divided into three phases: increasing Rs and T; decreasing Rs with increasing T; decreasing Rs and T. Non univocal annual cycles were observed between Rs and T, ETo and Rs, and ETo and T. These annual patterns result in important seasonal changes in the ratio between the Hargreaves Samani and Penman Monteith (FAO PM) ETo estimates. The changes are particularly important during the irrigation season, where the FAO PM initially calculates greater ETo values than the HS methodology and from the end of May to early September, the HS equation overestimates the ETo values. The total overestimation by the HS equation during this period is 17 mm, or 3 %. These patterns obtained from 2000 - 2009 data were used to calibrate and improve HS ETo estimates at new sites during the 2010 - 2011 <b>period.</b> <b>Calibration</b> based on the proposed seasonal region-wide FAO PM/ HS ETo ratios improved both the bias, which decreased from 0. 40 to 0. 36 mm day − 1, and r 2, which increased from 0. 67 to 0. 87 of the ETo estimates during the irrigation season. The proposed methodology can be easily applied to other regions, even when the existing weather stations are sparse...|$|E
3000|$|Pyrene {{inclusion}} formation constants {{were calculated}} using the 2  day time points obtained {{since it was}} determined that the system reached saturation through fluorescence studies within that time <b>period.</b> A <b>calibration</b> curve was derived which related the pyrene concentration in water to its fluorescence intensity (Monaco et al. 2013). The inclusion formation constant was derived from the following equation: [...]...|$|R
40|$|Specific {{problems}} {{arising from}} the use of an electric hygrometer for measurement of water activity (aw) are the equilibration <b>period,</b> the <b>calibration</b> of the sensors and the influence of temperature on the values measured in saturated salt solutions and meat products. The instrument proved to be a simple, rapid and reliable means of measuring aw values, provided some precautions are taken...|$|R
30|$|The mean CGM {{duration}} was 74.9 (54.4; 93.7) h. The {{data from}} initial 2  h of monitoring, {{which is considered}} to be an unstable <b>calibration</b> <b>period,</b> were excluded from analysis (Hirsch et al. 2008).|$|R
40|$|To {{identify}} the most applicable {{technology for the}} short-term assessment of domestic radon levels, comparative assessments {{of a number of}} integrating detector types, including track-etch, electret and activated charcoal were undertaken. Thirty-four unremediated dwellings in a high-radon area were monitored using track-etch detectors exposed for one-month and three-month periods. In parallel, one-week measurements were made in the same homes at one-month intervals, using co-located track-etch, charcoal and electret detectors exposed simultaneously, while three of the homes were also monitored by continuous-sampling detectors at hourly intervals over extended <b>periods.</b> <b>Calibration</b> of dose-integrating devices against each other and against continuous-monitoring systems confirmed good responsivity and linearity. Although track-etch, charcoal and electret devices are suitable in principle for one-week measurements, zero-exposure offset and natural radon variability cause many one-week results to be equivocal, necessitating repetition of the measurement. One-week exposures can be reliable indicators in low-radon areas or for new properties, but in high-radon areas, the use of three-month exposures is indicated. This analysis also established confidence limits for short-term measurements...|$|R
40|$|The Berlin Brain-Computer Interface (BBCI) {{has been}} {{developed}} to transfer the main load of learning from the user to the machine. After a short <b>calibration</b> <b>period</b> of approx. 30 minutes, even untrained users with no previous BCI experience can achieve bit-rates of more than 35 bits/min. In some of these experiments, however, the classifier from the <b>calibration</b> <b>period</b> needs to be slightly adapted by adding a constant bias term to its output {{in order to maintain}} a stable performance throughout the feedback session. In this paper, we will provide evidence that a change in the brain states between <b>calibration</b> and feedback <b>periods</b> probably causes this need for adaptation. 1...|$|R
40|$|We {{present a}} compact, portable, and {{mechanically}} robust instrument for measuring optical wavelength {{based on an}} arrangement of four Wollaston prisms that forms spatially localised fringes in a plane perpendicular to the optic axis. The wavelength is determined from the fringe <b>period.</b> After <b>calibration,</b> the instrument had an accuracy of c. 1 of 10 6, and was immune to fluctuations in output intensity of a light source of up to 10 dB...|$|R
40|$|Paired {{watershed}} {{studies have}} historically been used to quantify hydrologic effects of land use and management practices by concurrently monitoring two neighboring watersheds (a control and a treatment) during the calibration (pre-treatment) and post-treatment periods. This study characterizes seasonal water table and flow response to rainfall during the <b>calibration</b> <b>period</b> and tests a change detection technique of moving sums of recursive residuals (MOSUM) to select <b>calibration</b> <b>periods</b> for each control-treatment watershed pair when the regression coefficients for daily water table elevation (WTE) were most stable to reduce regression model uncertainty. The control and treatment watersheds included 1 – 3 year intensively managed loblolly pine (Pinus taeda L.) with natural understory, same age loblolly pine intercropped with switchgrass (Panicum virgatum), 14 – 15 year thinned loblolly pine with natural understory (control), and switchgrass only. Although monitoring during the <b>calibration</b> <b>period</b> spanned 2009 to 2012, silvicultural operational practices that occurred during this period such as harvesting of existing stand and site preparation for pine and switchgrass establishment may have acted as external factors, potentially shifting hydrologic calibration relationships between control and treatment watersheds. Results indicated that MOSUM was able to detect significant changes in regression parameters for WTE due to silvicultural operations. This approach also minimized uncertainty of calibration relationships which could otherwise mask marginal treatment effects. All calibration relationships developed using this MOSUM method were quantifiable, strong, and consistent with Nash–Sutcliffe Efficiency (NSE) greater than 0. 97 for WTE and NSE greater than 0. 92 for daily flow, indicating its applicability for choosing <b>calibration</b> <b>periods</b> of paired watershed studies...|$|R
40|$|The virtual {{lysimeter}} {{concept was}} tested {{in comparison with}} a real lysimeter and found to be suitable for quantifying effective deep seepage dynamics in sandy soils. Discharge measurements and calculation results agreed well. Preconditions are accurate water content and tension measurements with high temporal resolution below the zero flux plane and an error free water balance of the <b>calibration</b> <b>period.</b> The <b>calibration</b> procedure has resulted in an effective unsaturated hydraulic conductivity function which allows to perform deep seepage calculations {{based on the measured}} water content dynamics only. The assumption of the unit gradient produced adequate results in sandy soils. The calculation results are exponentially sensitive to errors of water content measurements and linearly sensitive to water balance errors. However, a single incorrect water content produces only a single incorrect deep seepage value, whereas the water balance error sums up. Therefore, the quality of the water balance estimation is of crucial importance...|$|R
30|$|For the {{comparison}} of the models’ in-sample fit, we have made sure that the calibration methodologies for the two models are similar (see Appendix 1). The <b>calibration</b> <b>period</b> is from 1960 until 2014 and for ages zero to 100.|$|R
50|$|A {{period of}} one year between {{standard}} tile recalibration should be regarded as a minimum <b>period.</b> If a <b>calibration</b> standard becomes permanently scratched or damaged at any time it will require immediate recalibration or replacement as the glossmeter may give incorrect readings.|$|R
40|$|A {{simplified}} {{soil moisture}} budgeting model was developed. The {{sensitivity of the}} soil moisture budgeting model to the method used for the calculation of potential evapotranspiration (PET), actual evapotranspiration (AET), and soil moisture movement was evaluated. Using the soil moisture budgeting model as a basis, a forage yield prediction model was also developed. Four methods for quantifying plant water stress {{were used to determine}} soil moisture deficit factors for critical growth periods. Stepwise multiple regressions were used to produce prediction equations from these factors. Data for calibration and validation of the models were obtained from the Santa Rita Experimental Range in southeastern Arizona. The PET method employed had a negligible effect, however, the AET method selected was important to soil moisture estimation, with the more complex methods giving the most accurate results. The soil moisture budgeting inodel explained 85 percent (r= 0. 92) of the variation in observed values over the <b>period</b> of <b>calibration</b> and 64 percent (r= 0. 80) of the variation in observed values over the period of validation. The forage prediction model explained 85 percent (r=. 92) of the variation in average perennial grass production over the <b>period</b> of <b>calibration,</b> but produced essentially no correlation over the period of validation...|$|R
30|$|While modeling, {{the monthly}} {{temperature}} (Min., Max., and Avg.), relative humidity (Min. and Max.), average wind speed, sunshine hours and rainfall data from 1980 to 2013 (i.e. 408 datasets) {{were divided into}} <b>calibration</b> <b>period</b> 1980 – 2004 (300 datasets) and validation period 2005 – 2013 (108 datasets).|$|R
40|$|Abstract. The goal of {{this paper}} is to specify dynamic term {{structure}} models with discrete tenor structure for credit portfolios in a top-down setting driven by time-inhomogeneous Lévy processes. We provide a new framework, conditions for absence of arbitrage, explicit examples, an affine setup which includes contagion and pricing formulas for STCDOs and options on STCDOs. A calibration to iTraxx data with an extended Kalman filter shows an excellent fit over the full observation <b>period.</b> The <b>calibration</b> is done on a set of CDO tranche spreads ranging across six tranches and three maturities. 1...|$|R
40|$|We {{used the}} Soil and Water Assessment Tool (SWAT) to {{simulate}} point and non-point source pollution of nitrate in a mesoscale mountainous catchment. The {{results show that}} the model efficiency for daily discharge is 0. 81 for the <b>calibration</b> <b>period</b> (November 1990 to December 1993) and 0. 56 for the validation period (April 2000 to January 2003). The model efficiency for monthly nitrate load is 0. 66 and 0. 77 for the <b>calibration</b> <b>period</b> (April 2000 to March 2002) and validation period (April 2002 to January 2003), respectively. However, the model efficiency for daily loads is low (0. 15), which cannot only be attributed to the quality of input data of point source effluents. An analysis of the internal fluxes and cycles of nitrogen pointed out considerable weaknesses in the models conceptualisation of the nitrogen modules which will be improved in future research...|$|R
40|$|The State of Oregon Department of Environmental Quality (DEQ) is {{developing}} a TMDL for temperature in the Willamette River basin shown in Figure 1. The study area included the Willamette River and all major tributaries (except the Tualatin River where a TMDL process was already concluded). A large section of the Columbia River was also modeled to provide adequate boundary representation of tidal flows in the lower Willamette River. The Willamette River below the Oregon City Falls in the Portland metropolitan area has a typical diurnal tidal range of 1 m. The development of a dynamic model of temperature and hydrodynamics of the entire river basin incorporating shading were primary requirements of this modeling study. The model would be used by DEQ to set temperature limits on point source dischargers and to evaluate the impact of management strategies on river temperatures to improve fish habitat. Some of these strategies included modifications of the dam at the Willamette River Falls south of Portland and channel reconfigurations. Once the models were set-up for each section of the Willamette basin, the model was calibrated to field data and management strategies were evaluated. These are the subjects of two other reports: Annear et al. (2004 b) and Berger et al. (2004). This report outlines the model development {{of each of these}} model sections or elements for both the <b>calibration</b> time <b>periods</b> and the management scenario time <b>periods.</b> The <b>calibration</b> <b>period</b> for each model section differs due to the availability of boundary condition data. The model simulation periods used to investigate management scenarios (Annear et al, 2004 b) also required boundary condition data that extended past the <b>calibration</b> <b>periods...</b>|$|R
50|$|The {{primary purpose}} of these {{instruments}} is to monitor clouds and to measure the thermal emission of the Earth. These sensors have proven useful {{for a number of}} other applications, however, including the surveillance of land surfaces, ocean state, aerosols, etc. AVHRR data are particularly relevant to study climate change and environmental degradation because of the comparatively long records of data already accumulated (over 20 years). The main difficulty associated with these investigations is to properly deal with the many limitations of these instruments, especially in the early <b>period</b> (sensor <b>calibration,</b> orbital drift, limited spectral and directional sampling, etc.).|$|R
