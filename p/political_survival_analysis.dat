0|9813|Public
40|$|Drawing on Alchianâ€Ÿs and Schumpeterâ€Ÿs {{theories}} about the market selection of entrepreneurs and on theories of the political class, {{we focus on the}} features characterizing the Italian post-war democratic Parliament, from 1946 to 2010. We analyse the survival {{of the members of the}} Italian Parliament, taking into account all available information concerning their individual characteristics and political affiliation. We apply the stratified Cox model, taking into consideration the order of re-election of the 15, 357 repeated observations (representing 7, 127 members of the Italian Parliament since 1946), who are followed as if they were â€œpatientsâ€ in order to study their parliamentary <b>survival.</b> <b>Political</b> enterprise, <b>political</b> class, <b>survival</b> <b>analysis,</b> Italian Parliament. ...|$|R
50|$|<b>Survival</b> <b>analysis</b> {{includes}} Cox regression (Proportional hazards model) and Kaplan-Meier <b>survival</b> <b>analysis.</b>|$|R
30|$|The {{most crucial}} goal for local cadres {{is to ensure}} their <b>political</b> <b>survival.</b> This goal is {{sometimes}} compatible with but sometimes also {{in conflict with the}} incentive to protect property rights because good policies can threaten <b>political</b> <b>survival</b> but bad policies can consolidate <b>political</b> <b>survival</b> (Bueno de Mesquita et al. 2003). 5 We argue that the political power configurations in which local cadres were embedded determined their motivation. In a centralized political system, higher-level officials have the power to appoint and remove a subordinate official. Therefore, local officials are expected to be more inclined toward satisfying the needs of their superior officials rather than protecting the interests of grassroots cadres and the masses. What kind of political power configurations led local cadres to distribute benefits to their subordinate officials or the masses? Drawing on the history of Zhejiang province, this article addresses this question from the logic of <b>political</b> <b>survival,</b> which is briefly summarized below.|$|R
40|$|<b>Survival</b> <b>{{analysis}}</b> is {{the analysis}} of data involving times to some event of interest. The distinguishing features of survival, or time-to-event, data and the objectives of <b>survival</b> <b>analysis</b> are described. Some fundamental concepts of <b>survival</b> <b>analysis</b> are introduced and commonly used methods of analysis are described...|$|R
40|$|Abstract—Survival {{analysis}}, {{also known}} as failure time analysis or time-to-event analysis, {{is one of the}} most significant advancements of mathematical statistics in the last quarter of the 20 th century. It has become the de facto standard in biomedical data analysis. Although reliability was conceived as a major application field by the mathematicians who pioneered <b>survival</b> <b>analysis,</b> <b>survival</b> <b>analysis</b> failed to establish itself as a major tool for reliability analysis. In this paper, we attempt to demonstrate, by reviewing and comparing the major mathematical models of both fields, that <b>survival</b> <b>analysis</b> and reliability theory essentially address the same mathematical problems. Therefore, <b>survival</b> <b>analysis</b> should become a major mathematical tool for reliability analysis and related fields such as Prognostics and Health Management (PHM). This paper is the first in a four part series in which we review state-of-the-art studies in <b>survival</b> (univariate) <b>analysis,</b> competing risks <b>analysis,</b> and multivariate <b>survival</b> <b>analysis,</b> with focusing on their applications to reliability and computer science. The present article discusses the univariate <b>survival</b> <b>analysis</b> (<b>survival</b> <b>analysis</b> hereafter) ...|$|R
5000|$|Sonia Alonso, [...] "Enduring Ethnicity: the <b>Political</b> <b>Survival</b> of Incumbent Ethnic Parties in Western Democracies". Estudios/Working Paper 2005/221, Madrid: Juan March Institute ...|$|R
40|$|<b>Survival</b> <b>analysis</b> {{is one of}} {{the main}} areas of focus in medical {{research}} in recent years. <b>Survival</b> <b>analysis</b> involves the concept of 'Time to event'. The event may be mortality, onset of disease, response to treatment etc. Purpose of this paper is to provide overview of frequentist and Bayesian Approaches to <b>Survival</b> <b>Analysis.</b> The paper starts with the overview of the basic concepts of <b>survival</b> <b>analysis</b> and then discusses the frequentist and Bayesian approaches to <b>survival</b> <b>analysis</b> in the biomedical domain with help of hypothetical survival dataset. The <b>survival</b> <b>analysis</b> of the hypothetical data sets showed that for the specific dataset and specific hypothesis, Bayesian approach provided direct probability that the null hypothesis is true or not and the probability that the unknown parameter (mean survival time) lies in a given credible interval wherein the frequentist approach provided p-values and confidence interval for interpreting whether the null hypothesis is true or not and the percentage of intervals which will contain the parameter when the experiment is repeated under same condition. The use of Bayesian <b>survival</b> <b>analysis</b> in biomedical domain has increased due to the availability of advanced commercial and free software, its ability to handle design and <b>analysis</b> issues in <b>survival</b> model and the ease of interpretation of the research findings...|$|R
40|$|<b>Survival</b> <b>analysis</b> and {{graphical}} {{presentation of}} the <b>survival</b> <b>analysis</b> result are not uncommon in pharmaceutical industry. In this paper we use simulated survival data to demonstrate the graphical presentation of Kaplan-Meier <b>survival</b> <b>analysis</b> result by using Proc Lifetest, Proc Gplot and Proc Greplay. if mod(pat, 7) then censor = 0; else censor = 1; surv =-log(ranuni(0)) * 10; end; drop pat; patient = put(pat, z 5.); output; end; end; run...|$|R
40|$|The {{electronic}} {{health record}} (EHR) provides an unprecedented opportunity to build actionable tools to support physicians {{at the point}} of care. In this paper, we investigate <b>survival</b> <b>analysis</b> in the context of EHR data. We introduce deep <b>survival</b> <b>analysis,</b> a hierarchical generative approach to <b>survival</b> <b>analysis.</b> It departs from previous approaches in two primary ways: (1) all observations, including covariates, are modeled jointly conditioned on a rich latent structure; and (2) the observations are aligned by their failure time, rather than by an arbitrary time zero as in traditional <b>survival</b> <b>analysis.</b> Further, it (3) scalably handles heterogeneous (continuous and discrete) data types that occur in the EHR. We validate deep <b>survival</b> <b>analysis</b> model by stratifying patients according to risk of developing coronary heart disease (CHD). Specifically, we study a dataset of 313, 000 patients corresponding to 5. 5 million months of observations. When compared to the clinically validated Framingham CHD risk score, deep <b>survival</b> <b>analysis</b> is significantly superior in stratifying patients according to their risk. Comment: Presented at 2016 Machine Learning and Healthcare Conference (MLHC 2016), Los Angeles, C...|$|R
40|$|ABSTRACT The <b>survival</b> <b>analysis</b> was {{originally}} proposed for data analysis related to {{time before the}} occurrence of a specific event of interest and has been widely used in studies of biomedical data (<b>survival</b> <b>analysis),</b> industrial research (reliability analysis) and financial data (credit scoring). In this study, we presented {{a new approach to}} modeling the market value of urban lots based on <b>survival</b> <b>analysis</b> considering the left censoring mechanism, which allows estimating the probability for sale and the hazard associated with sales at the lot market value. The modeling is made from the <b>survival</b> <b>analysis</b> that introduces greater flexibility when compared to the usual linear models as it allows including the effectively traded lots (not censored) and lots in negotiation (censored) into the process, however, {{it is not enough to}} affirm the effective improvement of models based on the <b>survival</b> <b>analysis...</b>|$|R
40|$|Graduation date: 1991 Economic {{methodology}} is revisited {{to address}} issues in fishery management, and <b>survival</b> <b>analysis</b> is suggested as an analytical tool to solve the uncertainty problem in evolutionary economics. <b>Survival</b> <b>analysis</b> can clarify in statistical terms the impacts of fishery regulation and economic and biological changes on the fisherman's final decisions of entry and exit from the fishery. Two types Of framework for <b>survival</b> <b>analysis</b> in fishery management are presented to show how this {{can be applied to}} fishery management. One type is the framework of the typical regression analysis for market competition and the other type is an extension to the dynamic fishery model. The evaluation of <b>survival</b> <b>analysis</b> in fishery management is provideded. An empirical application of the <b>survival</b> <b>analysis,</b> through the Icelandic trawl fishery data, is given to show how to apply the survival technique to fishery regulation...|$|R
40|$|Abstract: Introduction: R is a {{statistical}} and graphics language and environment. Although it is extensively used in command line, {{graphical user interfaces}} exist to ease the accommodation with it for new users. Rcmdr is an R package providing a basic-statistics graphical user interface to R. <b>Survival</b> <b>analysis</b> interface is not provided by Rcmdr. The AIM {{of this paper was}} to create a plug-in for Rcmdr to provide <b>survival</b> <b>analysis</b> user interface for some basic R <b>survival</b> <b>analysis</b> functions...|$|R
40|$|Reliability and <b>survival</b> <b>analysis</b> are {{important}} applications of stochastic mathematics (probability, statistics and stochastic processes) {{that are usually}} covered separately {{in spite of the}} similarity of the involved mathematical theory. This title aims to redress this situation: it includes 21 chapters divided into four parts: <b>Survival</b> <b>analysis,</b> Reliability, Quality of life, and Related topics. Many of these chapters were presented at the European Seminar on Mathematical Methods for <b>Survival</b> <b>Analysis,</b> Reliability and Quality of Life in 2006...|$|R
40|$|An Introduction to <b>Survival</b> <b>Analysis</b> Using Stata, Third Edition is {{the ideal}} {{tutorial}} for professional data analysts who want to learn <b>survival</b> <b>analysis</b> {{for the first time}} or who are well versed in <b>survival</b> <b>analysis</b> but are not as dexterous in using Stata to analyze survival data. This text also serves as a valuable reference to those readers who already have experience using Stata’s <b>survival</b> <b>analysis</b> routines. The third edition has been updated for Stata 11, and it includes a new chapter on competing-risks analysis. This chapter describes the problems posed by competing events (events that impede the failure event of interest), and covers estimation of cause-specific hazards and cumulative incidence functions. Other enhancements include the handling of missing values by multiple imputation in Cox regression, a new-to-Stata- 11 system for specifying categorical (factor) variables and their interactions, three additional diagnostic measures for Cox regression, and a more efficient syntax for obtaining predictions and diagnostics after Cox regression. Stata, <b>survival</b> <b>analysis,</b> hazard models...|$|R
40|$|<b>Survival</b> <b>analysis</b> {{concerns}} sequential {{occurrences of}} events governed by probabilistic laws.   Recent decades have witnessed many applications of <b>survival</b> <b>analysis</b> in various disciplines. This book introduces both classic survival models and theories along with newly developed techniques. Readers will {{learn how to}} perform <b>analysis</b> of <b>survival</b> data by following numerous empirical illustrations in SAS. Survival Analysis: Models and Applications: Presents basic techniques before leading onto {{some of the most}} advanced topics in <b>survival</b> <b>analysis.</b> Assumes only a minimal knowledge of SAS whilst enabli...|$|R
40|$|AbstractSurvival {{analysis}} is {{the analysis of}} data involving times to some event of interest. The distinguishing features of survival, or time-to-event, data and the objectives of <b>survival</b> <b>analysis</b> are described. Some fundamental concepts of <b>survival</b> <b>analysis</b> are introduced and commonly used methods of analysis are described...|$|R
40|$|As use of time-to-event data in {{clinical}} trials is becoming more frequent, <b>survival</b> <b>analysis</b> and the graphical presentation of the <b>survival</b> <b>analysis</b> {{are more and more}} popular. In order to aid correct interpretation, overall summary statistics and some reflection of statistical uncertainty should be added in the survival plots. In this paper, Proc Lifetest, Proc Gplot and Proc Greplay are used to present the results of <b>survival</b> <b>analysis</b> with annotated +/-standard errors on the curve for selected time points on the Kaplan-Meier estimates; the numbers of patients at risk are displayed under the time axis...|$|R
5000|$|More generally, <b>survival</b> <b>analysis</b> {{involves}} the modelling {{of time to}} event data; in this context, death or failure is considered an [...] "event" [...] in the <b>survival</b> <b>analysis</b> literature - traditionally only a single event occurs for each subject, after which the organism or mechanism is dead or broken. Recurring event or repeated event models relax that assumption. The study of recurring events is relevant in systems reliability, and {{in many areas of}} social sciences and medical research. <b>Survival</b> <b>analysis</b> has many applications such as risk analysis and computer networks.|$|R
40|$|Although land {{changes are}} {{characterized}} by dimensionality in both space and time, and a multitude of methods and techniques {{have been developed to}} model them, the temporal dimension has seldom been adequately addressed by commonly used methods. In the context of temporal complexities represented in different space– time data models, this study aims to establish a framework for applying <b>survival</b> <b>analysis</b> theory and techniques to geographical land change modeling. Our efforts focus on (1) introducing basic concepts in <b>survival</b> <b>analysis</b> and their connections to space–time data commonly used in land change <b>analysis,</b> (2) using <b>survival</b> metrics to describe temporal patterns that are not easily detected by other methods, and (3) applying <b>survival</b> <b>analysis</b> methods to disclose effects of varying temporal patterns and uncertainties. Our findings suggest that <b>survival</b> <b>analysis,</b> coupled with geographic information systems (GIS) and remote sensing data, can effectively disclose relationships in land changes, and in many instances excel in shedding light on the temporal patterns of land changes. Key Words: geographic information systems, land change modeling, remote sensing, <b>survival</b> <b>analysis,</b> temporal complexity...|$|R
40|$|This {{study was}} focused on genetic {{evaluation}} of longevity in Croatian Simmental cattle using linear and survival models. The main objective {{was to create a}} genetic model that is most appropriate to describe the longevity data. <b>Survival</b> <b>analysis,</b> using piecewise Weibull proportional hazards model, used all information on the length of productive life including censored as well as uncensored observations. Linear models considered culled animals only. The relative milk production within herd had a highest impact on cows’ longevity. In comparison of estimated genetic parameters among methods, <b>survival</b> <b>analysis</b> yielded higher heritability value (0. 075) than linear sire (0. 037) and linear animal model (0. 056). When linear models were used, genetic trend of Simmental bulls for longevity was slightly increasing over the years, unlike a decreasing trend in case of <b>survival</b> <b>analysis</b> methodology. Average reliability of bulls’ breeding values was higher in case of <b>survival</b> <b>analysis.</b> The rank correlations between <b>survival</b> <b>analysis</b> and linear models bulls’ breeding values for longevity were ranged between 0. 44 and 0. 46 implying huge differences in ranking of sires. ...|$|R
40|$|Traditionally, {{credit scoring}} aimed at {{distinguishing}} good payers from bad payers {{at the time}} of the application. The timing when customers default is also interesting to investigate since it can provide the bank with the ability to do profit scoring. Analysing when customers default is typically tackled using <b>survival</b> <b>analysis.</b> In this paper, we discuss and contrast statistical and neural network approaches for <b>survival</b> <b>analysis.</b> Compared to the proportional hazards model, neural networks may offer an interesting alternative because of their universal approximation property and the fact that no baseline hazard assumption is needed. Several neural network <b>survival</b> <b>analysis</b> models are discussed and evaluated according to their way of dealing with censored observations, time-varying inputs, the monotonicity of the generated survival curves and their scalability. In the experimental, we contrast the performance of a neural network <b>survival</b> <b>analysis</b> model with that of the proportional hazards model for predicting both loan default and early repayment using data from a U. K. financial institution. credit scoring, <b>survival</b> <b>analysis,</b> neural networks...|$|R
40|$|<b>Survival</b> <b>analysis</b> is {{a branch}} of {{statistics}} concerned with the time elapsing before "failure," with diverse applications in medical statistics and {{the analysis of the}} reliability of electrical or mechanical components. We introduce a parametric accelerated life <b>survival</b> <b>analysis</b> model based on kernel learning methods that, at least in principal, is able to learn arbitrary dependencies between a vector of explanatory variables and the scale of the distribution of survival times. The proposed kernel <b>survival</b> <b>analysis</b> method is then used to model the growth domain of Clostridium botulinum, the food processing and storage conditions permitting the growth of this foodborne microbial pathogen, leading to the production of the neurotoxin responsible for botulism. A Bayesian training procedure, based on the evidence framework, is used for model selection and to provide a credible interval on model predictions. The kernel <b>survival</b> <b>analysis</b> models are found to be more accurate than models based on more traditional <b>survival</b> <b>analysis</b> techniques but also suggest a risk assessment of the foodborne botulism hazard would benefit from the collection of additional data...|$|R
5000|$|... #Subtitle level 3: Lifetime analysis: <b>Survival</b> <b>analysis</b> and {{reliability}} ...|$|R
5000|$|... #Subtitle level 3: Definitions {{of common}} terms in <b>survival</b> <b>analysis</b> ...|$|R
40|$|Censored targets, such as {{the time}} to events in <b>survival</b> <b>analysis,</b> can {{generally}} be represented by intervals on the real line. In this paper, we propose a novel support vector technique (named SVCR) for regression on censored targets. Interestingly, this approach provides a general formulation for both standard regression and binary classification tasks. SVCR inherits the strengths of support vector methods, such as a globally optimal solution by convex programming, fast training speed and strong generalization capacity. In contrast to ranking approaches to <b>survival</b> <b>analysis,</b> our approach is able not only to achieve superior ordering performance but also to predict the survival time very well. Controlled experiments show the significant performance improvement when majority of the training data is censored. Experimental results on several <b>survival</b> <b>analysis</b> datasets verify that SVCR is very competitive against classical <b>survival</b> <b>analysis</b> models...|$|R
40|$|<b>Survival</b> <b>analysis</b> can {{be applied}} to build models for time of default on debt. In this paper we report an {{application}} of <b>survival</b> <b>analysis</b> to model default on a large data set of credit card accounts. We show that <b>survival</b> <b>analysis</b> is competitive for prediction of default in comparison with logistic regression. We explore the hypothesis that probability of default is affected by general conditions in the economy over time. These macroeconomic variables cannot readily be included in logistic regression models. However, <b>survival</b> <b>analysis</b> provides a framework for their inclusion as time-varying covariates. Various macroeconomic variables, such as interest rate and unemployment index, are included in the survival model as time-varying covariates. We show that inclusion of these indicators improves model fit and affects probability of default and provides a statistically significant improvement in predictions of default on an independent test set...|$|R
40|$|One of the {{prevailing}} applications of machine learning {{is the use of}} predictive modelling in clinical <b>survival</b> <b>analysis.</b> In this work, we present our view of the current situation of computer tools for <b>survival</b> <b>analysis,</b> stressing the need of transferring the latest results in the field of machine learning to biomedical researchers. We propose a web based software for <b>survival</b> <b>analysis</b> called OSA (Online <b>Survival</b> <b>Analysis),</b> which has been developed as an open access and user friendly option to obtain discrete time, predictive survival models at individual level using machine learning techniques, and to perform standard <b>survival</b> <b>analysis.</b> OSA employs an Artificial Neural Network (ANN) based method to produce the predictive survival models. Additionally, the software can easily generate survival and hazard curves with multiple options to personalise the plots, obtain contingency tables from the uploaded data to perform different tests, and fit a Cox regression model from a number of predictor variables. In the Materials and Methods section, we depict the general architecture of the application and introduce the mathematical background of each of the implemented methods. The study concludes with examples of use showing the results obtained with public datasets...|$|R
40|$|The goal of {{this thesis}} is to model and predict the {{probability}} of default (PD) for a mortgage portfolio. In order to achieve this goal, logistic regression and <b>survival</b> <b>analysis</b> methods are applied to a large dataset of mortgage portfolios recorded {{by one of the}} national banks. While logistic regression has been commonly used for modeling PD in the banking industry, <b>survival</b> <b>analysis</b> has not been explored extensively in the area. Here, <b>survival</b> <b>analysis</b> is offered as a competitive alternative to logistic regression. ^ The results of the final modeling for both methods show very similar fit in terms of the ROC with the survival model having slightly better performance than logistic regression in the training dataset and almost the same performance in the testing dataset. In term of prediction of defaulted and non-defaulted mortgage portfolios, the logistic regression model outperforms <b>survival</b> <b>analysis</b> in the training dataset, while survival model outperforms logistic regression in the testing dataset. ^ Overall, the results support that the <b>survival</b> <b>analysis</b> approach is competitive with the logistic regression approach traditionally used in the banking industry. In addition, the survival methodology offers a number of advantages useful for both credit risk management and capital management. ...|$|R
40|$|Although {{continuous}} <b>survival</b> <b>analysis</b> differs {{much from}} the discrete <b>survival</b> <b>analysis,</b> there is certain link between the two modeling approach. By selecting a set of knots and grouping the con-tinuous survival time into bins, we can build a discrete hazard model on continuous survival data. For example, put piecewise constant baseline hazard in Cox’s semi-parametric proportional hazar...|$|R
40|$|The <b>survival</b> <b>analysis</b> {{is a type}} of {{statistical}} technique to deal with data that has upper or lower limits. In this work, I demonstrate an example of applying the <b>survival</b> <b>analysis</b> to re-derive the Cepheid period-luminosity relation at 70 μm, because about 2 / 3 of the currently available data only contains upper limits in flux...|$|R
40|$|<b>Survival</b> <b>analysis</b> is a {{supervised}} learning technique {{that in the}} context of microarray data is most frequently used to identify genes whose expression levels are correlated with patient <b>survival</b> prognosis. <b>Survival</b> <b>analysis</b> is generally applied to diseased samples for the purpose of analyzing time to event, where the event can be any milestone of interest (e. g., metastases...|$|R
40|$|BACKGROUND: We {{recently}} published PROGgene, {{a tool that}} can be used to study prognostic implications of genes in various cancers. The first version of the tool had several areas for improvement. In this paper we present some major enhancements we have made on the existing tool in the new version, PROGgeneV 2. RESULTS: In PROGgeneV 2, we have made several modifications to enhance <b>survival</b> <b>analysis</b> capability of the tool. First, we have increased the repository of public studies catalogued in our tool by almost two folds. We have also added additional functionalities to perform <b>survival</b> <b>analysis</b> in a variety of new ways. <b>Survival</b> <b>analysis</b> can now be performed on a) single genes b) multiple genes as a signature, c) ratio of expression of two genes, and d) curated/published gene signatures in new version. Users can now also adjust the <b>survival</b> <b>analysis</b> models for available covariates. Users can study prognostic implications of entire gene signatures in different cancer types, which are searchable by keywords. Also, unique to our tool, in the new version, users will be able to upload and use their own datasets to perform <b>survival</b> <b>analysis</b> on genes of interest. CONCLUSIONS: We believe, like its predecessor, PROGGeneV 2 will continue to be useful for the scientific community for formulating research hypotheses and designing mechanistic studies. With added datasets PROGgeneV 2 is the most comprehensive <b>survival</b> <b>analysis</b> tool available. PROGgeneV 2 is available at [URL]...|$|R
50|$|ONS {{data can}} also be used in {{epidemiologic}} studies such as <b>survival</b> <b>analysis.</b>|$|R
40|$|In {{prevention}} studies, it {{is often}} of interest to investigate the incidence of initial drug experimentation or other drug use milestones {{and their relationship to}} individual attributes such as the level of parental monitoring or rebelliousness. Thus <b>survival</b> <b>analysis</b> is the methodology of choice. <b>Survival</b> <b>analysis</b> methods deal e ciently with data from individuals who leave the study prematurely and do not return. However often individuals do return to the study. The application of <b>survival</b> <b>analysis</b> to a situa-tion in which individuals miss assessments and later return is nonstandard. This paper examines the use of multiple imputation as a methodology for utilizing information from assessments following a missed assessment...|$|R
40|$|<b>Survival</b> <b>analysis</b> is a {{statistical}} approach {{used to study}} time to an event of interest. The approach is highly applicable to the manual therapy discipline, yet is rarely used. This masterclass aims to present a simple overview of <b>survival</b> <b>analysis</b> aimed at both clinicians and researchers in the manual therapy field. Specifically the masterclass aims to 1) describe situations where <b>survival</b> <b>analysis</b> is appropriate to use 2) describe unique characteristics of survival data including censoring of participants 3) describe <b>analysis</b> methods for <b>survival</b> data including log rank test and Cox regression 4) describe the interpretation of results from survival analyses including survival plots and hazard ratios. 6 page(s...|$|R
50|$|<b>Survival</b> <b>analysis</b> {{shows that}} hsa-miR-101 is {{associated}} with survival in multiple breast cancer datasets.|$|R
