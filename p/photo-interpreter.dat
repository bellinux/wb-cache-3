13|25|Public
40|$|On thermal {{infrared}} pictures, {{the density of}} the film is related to the temperature of the corresponding point in the scene. These heat pictures give very useful information to the <b>photo-interpreter,</b> if they are combined with normal photographs. In this way it is even possible to obtain information about structures below the surface, where applications in the field of geology and oceanography are obvious...|$|E
40|$|Abstract—In this paper, {{we present}} a new {{framework}} for high-level processing of time series images, with particular reference to Sentinel- 1 data. The proposed methodology has the goal of enhancing the interpretation of SAR imagery through the production of physical-based RGB composites, which are par-ticularly suited for being easily interpreted by the human <b>photo-interpreter,</b> lowering the expertise level required for managing SAR data. I...|$|E
40|$|Abstract — This paper {{investigates the}} {{application}} of a knowledge-based approach, founded on semantic networks, to the automatic land use mapping assisted by low resolution satellite images. Alike the visual photo-interpretation, the automatic image interpretation considers scene and sensors knowledge, delivered by an expert <b>photo-interpreter,</b> as well as additional information about the region like the digital elevation model, the position of the emergent rocks, the mapping of the water bodies and the road-network. By this means, the analysis of a scene can be automatically performed, mimicking the reasoning of the <b>photo-interpreter.</b> The implementation of such proposal employed the GEOAIDA [1] system, a flexible environment for image interpretation developed at the University of Hanover, which exploits semantic networks to structure the domain specific knowledge. In the reported experiments, a multispectral SPOT 3 XS image was analysed resulting in a land use map. The automatically obtained results were evaluated and compared with a manually made reference map of the investigated scene. The experimental results demonstrate the potential of a knowledge-based approach for low resolution satellite images interpretation. I...|$|E
40|$|A 17 {{year old}} white spruce {{plantation}} with a {{current rate of}} white pine weevil infestation of 23 % was photographed using 70 null colour photography at scales of 1 : 500 and 1 : 650. The two photo-scales were then interpreted by two different sets of <b>photo-interpreters,</b> with vaI) 'ing degrees of experience, and compared to ground surveys. Results showed {{that the use of}} skilled <b>photo-interpreters</b> improved the accuracy of interpretation of current weevil attacks by 18 % to 79 % over the use of unskilled interpreters. A significant relationship was also observed between the amount of red foliage remaining on the leader and the accuracy of interpretation of current attacks. Large-scale 70 mm photography can detect currently attacked spruce leaders as small as 35 by 30 cm with an accuracy approaching 90 % providing at least 30 % of the red needles remain on the damaged leader and experienced <b>photo-interpreters</b> assess the results. Key words: white pine weevil, Pissodes strobi, colour photography, aerial surve...|$|R
40|$|The {{document}} {{summarizes the}} steps, procedures, information infrastructure used for collecting built up information from satellite imagery. The document is {{intended as a}} reference for visual interpreters. The document also summarizes the lessons learned by <b>photo-interpreters</b> for imagery covering Europe. JRC. G. 2 -Global security and crisis managemen...|$|R
50|$|U.S. mapping and {{charting}} efforts {{remained relatively}} unchanged until World War I, when aerial photography {{became a major}} contributor to battlefield intelligence. Using stereo viewers, <b>photo-interpreters</b> reviewed thousands of images. Many of these were of the same target at different angles and times, giving rise to what became modern imagery analysis and mapmaking.|$|R
40|$|Ten {{visibility}} {{tests have}} been made on a fusion of panchromatic and multi-spectral SPOT 5 images. The tests differ {{in the type of}} regions (sub-urban versus rural) and in the panchromatic image resolution (5 m versus 2, 5 m). For the first of these ten tests, two independent photo-interpreters had to extract the road network and the built-up area on part of a georeferenced image, while only the most experimented <b>photo-interpreter</b> worked on the nine other tests. The resulting shapes were analyzed and compared with the current database. Two methods were used for this comparison. It appears that the visibility is highly dependent on the experience of the <b>photo-interpreter.</b> The expert reaches a rate of approximately 85 % of road detection in all regions, more than 85 % of the built-up area in the sub-urban regions, and approximately 75 % in the rural ones. As the two available SPOT 5 images, respectively characterized by a 5 m and 2, 5 m resolution, partly overlapped, one zone was also chosen to directly measure the effect of the resolution on the visibility of the concerned cartographic objects...|$|E
30|$|A small field {{campaign}} was conducted {{for this study}} to acquire height and crown diameter for a small set of sample trees. However, a complete census of tree locations over a test area may be desirable to assess and compare the delineation assumptions which should rely not only on TP rate {{but also on the}} False Positive rate (reporting on false alarms, i.e., segments that do not correspond to any actual tree). Manual crown delineation as done by a <b>photo-interpreter</b> based on an orthophoto could also be useful, even though overlapping crowns may be hard to correctly digitize.|$|E
40|$|As of October 2013, some 59 {{states and}} four other areas were {{confirmed}} to bemine‐affected. Large "Suspected Hazardous Areas'', often overestimated, prevent thepopulation to use the land. In this context, aerial images provide an asset for a betterdelineation, based on indicators of mine presence (IMP) or of mine absence. Trenchesdetected thanks to their shadows are good examples of IMP. Their sparse presence over thehuge amount of images makes their detection by a <b>photo‐interpreter</b> an overwhelming task. We therefore propose an automatic tool based on dark line detection. In various envisagedscenarios, the most suspicious images and the detected objects are proposed to photointerpretersfor further analysis or for pre‐processing such as ortho‐photo production. Thetool {{is applied to the}} Suspected Hazardous Area of Bihac in Bosnia and Herzegovina. info:eu-repo/semantics/publishe...|$|E
50|$|Perennial {{problems}} {{included the}} shortage of trained and experienced <b>photo-interpreters,</b> the difficulty in distributing timely and interpreted prints to exactly the commanders needing them, a lack of overall coordination of effort and centralized interpretation (a common air picture), and the tendency of field commanders to demand risky, repeated flights for objectives only for the photos to languish in files somewhere along the process.|$|R
50|$|RAAF C-130 {{aircraft}} from No. 36 and No. 37 Squadrons {{provided a}} shuttle service between Australia and the Persian Gulf. Boeing 707 aircraft from No. 33 Squadron and VIP aircraft from No. 34 Squadron also {{flew to the}} Middle East. A small team of RAAF <b>photo-interpreters</b> was posted to Saudi Arabia. Intelligence analysts from the RAAF and Defence Intelligence Organisation were also posted to Saudi Arabia.|$|R
5000|$|In {{addition}} to the naval contingent, Australian service personnel were seconded to British and United States ground troops. The government position was not to deploy ground troops with [...] "no boots in the sand". The RAAF deployed a unit of <b>photo-interpreters</b> which were based in Saudi Arabia. Four medical teams were also deployed. At the end of Desert Storm, 75 ADF personnel were deployed to Northern Iraq {{to assist in the}} provision of humanitarian aid to the Kurds living in the UN-declared exclusion zone.|$|R
40|$|Abstract — The present paper {{presents}} the preliminary {{results of a}} research aiming at evaluating the potential of knowledge-based approaches for the interpretation of low-resolution satellite images. This work applies a knowledge-based image interpretation system, so-called GEOAIDA, developed at the University of Hannover, Germany, which hires semantic networks and external operators to model the knowledge basis as well as takes advantage of additional data from Geographic Information Systems, GIS. Herein, GEOAIDA is used to perform automatically the post-editing, one of the steps of visual interpretation, aiming at mimicking the reasoning of a trained <b>photo-interpreter</b> when he refines {{the result of a}} pixel classification procedure. The results obtained hitherto show that the use of knowledge-based approaches for this purpose is promising and, in the future, can be used to automate the post-editing...|$|E
40|$|ISBN 90 - 5410 - 933 - 5 International audienceThis paper {{presents}} {{a new strategy}} to extract, fully or semi-automatically, quadrangular urban network from high spatial resolution imagery. A quadrangular network is generally composed of different classes of streets in a hierarchical system. The developed strategy is based both on the multiresolution analysis and on the wavelet transform. The multiresolution analysis allows a multiscale analysis of images and thus {{to focus on the}} streets of one class at once. The wavelet transform enables the modelling of information at different characteristic scales. In the problem, it allows to model the topology of streets. These two mathematical tools are combined in the "a trous" algorithm; The application of this algorithm to images of urban areas is used to develop fully or semi-automatic multiresolution processing in order to extract a hierarchical urban network from high spatial resolution imagery. These methods will bring a help to the <b>photo-interpreter</b> in his work...|$|E
40|$|In {{this paper}} we {{describe}} the fusion of various data and knowledge sources for intelligent SAR sea ice classification, thereby addressing the weaknesses of each information source while improving the overall reasoning power of the classifier. We equip our ice classification system, ARKTOS, with the capability of analyzing and classifying images unsupervised by emulating how a human geophysicist or <b>photo-interpreter</b> classifies SAR images. To imitate human visual inspection of raw images, we have designed and implemented a data mining application that first categorizes pixels into regions, and then extracts for each region a complex feature set of more than 30 attributes. In addition, we have incorporated other sea ice data and knowledge products such as ice concentration maps, operational ice charts, and land masks. Finally, we solicited human sea ice expertise as classification rules through interviews, and collaborative refinements during the earlystage evaluations. Using a Dempster-Shafer belief system, {{we are able to}} perform multisource data and knowledge fusion in ARKTOS' rule-based classification. ARKTOS has been installed at the National Ice Center and Canadian Ice Service...|$|E
25|$|The job {{training}} of women was so completely {{integrated with the}} entire AAF training program that virtually no separate statistics are available {{as a basis for}} comparing the record of the women with male trainees. Obviously, this policy meant that the Wacs had to be as well qualified as men to enroll in and graduate from a training course. It is known only that approximately 2,000 women completed courses in AAF technical schools, including those for Link-trainer instructors, airplane mechanics, sheet-metal workers, weather forecasters, weather observers, electrical specialists of several kinds, teletype operators, control-tower specialists, cryptographers, radio mechanics, parachute riggers, bombsight-maintenance specialists, clerks, photo-laboratory technicians, and <b>photo-interpreters.</b>|$|R
40|$|We {{present a}} new {{evaluation}} methodology and a feature extraction scheme for segmentation algorithms {{in the context}} of photo-interpretation. The novelty of the proposed methodology is that subjective evaluation marks are involved in the determination of the feature subspace. In fact, our aim is to determine features in alignment with the perception of <b>photo-interpreters,</b> alternatively called psychovisual features. The proposed methodology was applied to the detection of building targets in aerial images. More specifically we considered the delineation of polygonal buildings in semiurban areas on IKONOS images (1 meter resolution). We determined from the images, concurrently, various objective performance measures and collected votes of a jury of evaluators. The methodology to find the concordance between objective features and subjective marks was the canonical analysis of tables. ...|$|R
40|$|International audienceThis paper {{presents}} a new method to extract, semi-automatically, quadrangular {{urban road network}} from high spatial resolution imagery. A quadrangular network is generally composed of different classes of streets in a hierarchical system. The developed method is based both on the multiresolution analysis and on the wavelet transform. The multiresolution analysis allows a multiscale analysis of images and thus the extraction of the streets in a class-by-class way. The wavelet transform enables the modeling of information at different characteristic scales. In the problem, it allows the extraction of the topography of streets. These two mathematical tools are combined in the "à trous" algorithm. The application of this algorithm to images of urban areas {{has been used to}} develop semi-automatic multiresolution processing. This method will help <b>photo-interpreters</b> in their cartographic works by a partial automation of tasks...|$|R
40|$|A {{methodology}} {{was designed}} for the extraction of bajadas from the 15 min US Geological Survey digital elevation models and Landsat Thematic Mapper imagery. The method was demonstrated for the Death Valley-California where progressive eastward tilting has enabled the west-side fans to coalesce and form bajadas. First, the drainage that crossed the uplands and the bajadas was extracted from the DEM. The drainage pixels were successively grown by checking the surrounding pixels {{on the basis of}} their gradient. It was concluded that for gradient in the interval [2 degrees, 11 degrees] the upslope bajadas border was segmented. In order to eliminate the drainage pixels that belonged to the uplands. the drainage pixels were subtracted. Then, the isolated small 8 -connected foreground pixels were identified and subtracted too. Finally, region growing was performed again to the remaining pixels with the same growing criterion. Isolated 8 -connected background pixels, representing almost flat regions inside bajadas, were identified and merged to the segmented pixels. At the end, by taking into account the spectral response in the satellite image, the downslope border of bajadas was segmented. The extracted polygon was in agreement with the information depicted on (a) the US Geological Survey topographic map of scale 1 : 100, 000 and (b) the satellite image and (c) the polygon classified manually by a <b>photo-interpreter.</b> (C) 2001 Elsevier Science Ltd. All rights reserved...|$|E
40|$|This {{research}} project proposes {{to provide an}} aid to the <b>photo-interpreter</b> {{so that he can}} determine more easily objects of importance Kodak Ektachrome Infrared Aero Film, Type 8443, is utilized by this project as the medium through which this aid will be carried out. Films, such as this one, are visibility and near infrared sensitive color films. The wavelength region of the film 2 ̆ 7 s sensitivity is 0. 5 to 0. 9 nm. This film, therefore, is very useful, since it uses its near infrared capability to discriminate between objects that have nearly the same visual appearance but different near infrared characteristics. The infrared sensitive layer produces a cyan positive image which means that the image will appear to vary in different amounts of red in the final image. The method employed is all theoretical in nature, since this is a new type of study. Determining the image transmittance under a known set of conditions is the major portion of the theory. The remainder of the theory is devoted to C I. E. and Munsell Color coordinate determinations. Image formation theory in a color material is on the surface an easy task, but actually is a difficult process. Under the circumstances, determination of the image is accurately done. Theory involving the two types of coordinate determination is straight-forward, and was accomplished easily. Three minor problems were encountered, and they were: image formation, too limited conversion table between coordinate systems, and a small selection of available Munsell color chips. Despite these problems, data was collected and assembled. The results are plausible, but a practical study or test must be conducted to really see if the theory set forth in this project is indeed workable...|$|E
40|$|The {{objective}} of the chapter is to describe the major satellite techniques by using both SAR and optical images, for mapping damage caused by seismic events in urban areas. These type of techniques have revealed themselves a suitable monitoring tool for disaster management since they provide a quick detection of land changes in wide areas, especially in remote areas or where the infrastructures are not well developed to ensure the necessary communication exchanges. In fact, {{in the aftermath of}} these severe disastrous events the most urgent needs is to estimate with sufficient reliability and rapidity the amount of population and infrastructures affected for different degrees of damage. The contribution of space technologies has been demonstrated to be effective for regional/continental damage assessment using low- or medium-resolution remotely sensed data (ranging from 30 m to 1 km), and both automatic and manual interpretation approaches have been successfully used for extraction of information at a nominal scale ranging from 1 : 100 000 to 1 : 1 000 000. Today’s challenge for space technologies is also to demonstrate their effectiveness for damage assessment at local scale, ranging from 1 : 10 000 to 1 : 25 000 nominal scales. The information extracted at this level is crucial for calibration and estimation of the reliability of low- and medium-resolution assessment, for planning logistics for relief action on the field immediately after the event, and for planning the resources needed for recovery and reconstruction. Local or detailed damage assessment can also be addressed using Very High Resolution (VHR) satellite data with a spatial resolution ranging from 0. 6 to 1 m. At this level, the operational methodology for extracting the information was based on manual photo-interpretation of the satellite images which are processed on the screen by the <b>photo-interpreter</b> as for any other aerial imagery. The drawbacks of traditional photo-interpretation methodology are firstly linked to the time (and cost) needed for manual processing of the data and, secondly, to the difficulty in maintaining coherent interpretation criteria in case a large number of photo-interpreters, working in parallel in wide areas in a short time, is available. The long required processing time is in conflict with the need for rapid damage estimation, and the solution to involve parallel <b>photo-interpreter</b> teams often leads to an increase of time-consuming organizational problems and additional coherency lack in the information produced. Accordingly, some automatic procedures for exploiting these kind of data are developing in order to give information at this scale of detail. The most innovative automatic approaches will be described in this chapter. The major limitation, the availability of the images within a short time to manage the crisis, for an operational use of this kind of techniques will be highlighted. This is a key point for Civil Protections who needs a fast and draft overview of the epicentral area, quick information relative to the extension and distribution of damages, and the evaluation of infrastructure (roads, bridges) conditions. A single satellite can provide access time to a specific site in the order of some days, as a result the necessity to use any type of satellites data available and an integration of those data is mandatory to increase the chance to collect information on near real time. A description of the major satellite missions, SAR and optical, that provide data for this application will be done, paying particular attention to satellite constellations which may reduce the access time to 12 hours using the same sensor, {{as in the case of}} the COSMO-Skymed system. The work is addressed to the analysis of the different aspects leading to obtain maps representative of damage caused by earthquakes. At this aim some case studies will be considered, being representative of some severe earthquakes occurred in the past: Izmit (Turkey) on 1999, Bam (Iran) on 2003, Pakistan on 2005 and Sichuan (China) on 2008...|$|E
40|$|Abstract. Image {{databases}} and benchmarks are precious tools {{to assess the}} qual-ity of competing algorithms and to fine tune their parameters. In some cases, how-ever, quality cannot be captured by a single measure, and several of them, pro-viding typically contrasting indications, must be computed and analyzed. This is certainly {{the case for the}} SAR despeckling field, also {{because of the lack of}} clean reference images, which forces one to compute the measures of interest on simple canonical scenes. We present here the first results of an ongoing work aimed at selecting a suitable combination of benchmark measures to assess com-peting SAR despeckling techniques and rank them. The full validation of the pro-posed methodology will require the involvement of a reasonable number of expert <b>photo-interpreters</b> for a large-scale experimental campaign. Here, we present only a sample experiment to provide some insight about the approach...|$|R
40|$|This paper {{summarizes}} {{the results of}} an investigation aimed at evaluating the potential advantages of state-of-the-art airborne remote sensing for highway siting and planning tasks, specifically in wetlands areas. The basic objectives of the study were to develop methodologies using remotely sensed data for mapping wetlands soils and drainage, to evaluate the relative merits and usefulness of the various methods developed, to generate a selection of output products from the remote sensor data for display to highway planners and <b>photo-interpreters,</b> and to provide recommendations for implementation of remote sensing techniques in the highway planning and siting process. To accomplish these objectives, remote sensor and ground truth data were acquired for selected test sites in Florida, Michigan, and Minnesota. One of several test sites in Michigan has been selected as representative of the study objectives and methodology...|$|R
40|$|Sahara is a WEU funded project. Its {{aim is to}} {{show the}} {{potential}} usefulness of image interpretation techniques to help <b>photo-interpreters.</b> Typically, this could include drawing a sketch of the airport, looking for changes {{with respect to a}} reference geographic database, etc. The need for tools that fasten satellite imagery interpretation will become even more stringent with the next generation of satellites that will provide a very high amount of high resolution data. We therefore used aerial multi-sensor imagery with resolution expected in the near future for commercial satellite imagery (VIS 2 m, SAR 5 m, etc.). As a test case, the project was dedicated to the interpretation of airports. In this scope the main objects of interest like runways, taxiways, shelters, airplanes and buildings are searched for. In this paper, we show that object-related detectors are not able to solve the problem by their own. We then propose a scheme in which high level knowledge may be introduced in an effi [...] ...|$|R
40|$|The main {{objective}} ofthe Crop Forecasting Project is to obtain, at national level, information {{of the land}} occupation related to the spatial and temporal distribution of the agricultural land. With this in mind and considering the huge amount of land to be examined {{it was necessary to}} use non-conventional technology in order of becoming acquainted with the area of work. Among them it was selected the techniques of visual and automatic interpretation of sattelite data. One sattelite image is a composition of patterns which are indicators of things and events related to the physical, biological and cultural conditions of the land occupation. The type and the amount of information which one can extract from an image are proportional to the knowledge, experience, hability and dedication to the work of the analyst-interpreter responsible for one particular area. The map legend shows the subject matter and indicates the analyst's point of view in defining the nature of work. Besides that the legend orients the <b>photo-interpreter</b> in his work giving uniformity in the identification of the homogeneity of the land utilization in the studied area. Due to the experience obtained in the surveys carried on in the Distrito Federal and in the States of Paraná, Santa Catarina, and São Paulo the Crop Forecasting Project developed an improved procedure of constructing a map legend. The analysis and the study of the correlation between visual interpretation, field information and statistical data have been used as subsidies in the pattern definition during this phase of the work giving the conditions for regrouping or subdividing the legend before the final definition. In the search for a betterwork and considering the great achievements in the areas of hardware, software and remote sensing, the Project is trying to use more extensively automatization procedures in certain phases of the work through the utilization of the software ERDAS running in SUN workstations. Compared to the past work this is one step further in terms of legend construction since the use of this technology makes possible to apraisal the difficulties and possibilities of the system, providing the ways for a better work considering the principal objectives of the survey. Pages: 79 - 8...|$|E
40|$|We {{present an}} {{intelligent}} system for satellite sea ice image analysis named ARKTOS (Advanced Reasoning using Knowledge for Typing Of Sea ice). The underlying methodology of ARKTOS is to perform fully automated analysis of sea ice images by mimicking the reasoning process of sea ice experts and <b>photo-interpreters.</b> Hence, our approach is feature-based, rule-based classification supported by multisource data fusion and knowledge bases. A feature {{can be an}} ice floe, for example. ARKTOS computes a host of descriptors for that feature and then applies expert rules to classify the floe into one of several ice classes. ARKTOS also incorporates information derived from other sources, fusing different data towards more accurate classification. This modular, flexible, and extensible approach allows ARKTOS be refined and evaluated by expert users. As a software package, ARKTOS comprises components in image processing, rule-based classification, multisource data fusion, and GUI-based knowledge engineering and modification. As a research project over the past 10 years, ARKTOS has undergone phases such as knowledge acquisition, prototyping, refinement, evaluation and deployment, and finally operationalization at the National Ice Center (NIC). In thi...|$|R
40|$|The {{design of}} {{automatic}} systems dedicated to satellite image classification has received considerable attention. However, the current systems still cannot compare with human <b>photo-interpreters.</b> A promising approach consists in integrating structural knowledge into the classification process, i. e., using {{information about the}} shape of and the spatial relations between the regions {{that are to be}} determined. The present work tackles this issue, and relies on soft computing techniques. First, a fuzzy classifier produces a fuzzy partition of the image. Then, the defuzzified (crisp) partition is tried to be improved. According to the membership degrees in the fuzzy partition, the system selects a set of pixels and associates a set of candidate classes with each of them. The initial crisp partition is improved by reassigning each selected pixel to one of the classes it may belong to. This is performed by a combinatorial optimization strategy. The aim is to maximize the adequacy between the regions defined by the crisp partition and the structural knowledge which is available. First experiments on remote sensing data show the applicability of our approach...|$|R
40|$|To perform {{classification}} on remotely sensed imagery data, a {{small number}} of pixels or fields need to be labelled. It has been found that this labelling task requires many auxiliary materials such as crop calendar, soil data, cropping practice and a weather summary. This task is at the present time manually performed by <b>photo-interpreters.</b> It is time-consuming and liable to human error. The paper describes a computer based interactive color display system for assisting photointerpreters. Its objective is to reduce contact time and to increase labelling accuracy. This system has been designed to extract features from a temporal series of MSS data and to display these features using color graphic techniques. Special attention was paid to convert crop calendar information to quantitative information consistent with observed data. More specifically, descriptive crop phenology on a crop calendar was converted into quantitative growth index curves, to which observed features derived from MSS data are directly comparable. This system has been designed for feasibility demonstration only and although it is still in the evolutionary stage, it has already demonstrated that the method to be presented offers an effective solution to alleviating many problems associated with the current manual labelling process...|$|R
40|$|The main {{objective}} of Geographic Information and Visual Perception project (GI&VP), {{and of the}} present study, was to offer a device composed of a suite of tools and based on gaze integration to support the work of <b>photo-interpreters</b> involved in remotely sensed imagery exploration for rapid crisis response and damage assessment applications. The system based on eye tracking technology was conceived to improve the interpreter accuracy and effectiveness. Our research challenge was to test the accuracy and the effectiveness during a non-standard photo-interpretation procedure: {{in the case of}} accuracy, we were interested in the number of clicks and in their correct assignment; in the case of effectiveness, we evaluated the interpreter’s ocular behavior and the actions performed using the tools at his/her disposal, designed in the prototype. This experiment, and the theoretic perspective in which it was conceived, expressed the attempt to carry out a collaborative work scenario combining human and computer cooperation in order to minimize each others limitations. Therefore, an important research challenge was trying to assess how much the human relies on the computer automatic extraction, and, on the other hand, how much the computer can be a support to the human. JRC. G. 2 -Global security and crisis managemen...|$|R
40|$|Ancient Rural Space in South-East France: Archeological Ambitions and Realities. J. -L. Fiches. In {{the field}} of Narbonnaise antiquity, archeologists, <b>photo-interpreters,</b> prospectors, and earth science specialists have {{recently}} been meeting to forge a common approach to Gallo-Roman rural space. This article reports on new practices, their first results, and the conditions allowing for their implementation, attesting that an archeology of rural space is possible. Reflection about this region has advanced because of increased knowledge of the Iron Age and notably of the oppida, the setting up of thematic programs concerning agricultural products (eg. wine and oil) and programmed digs, and renewed study of Roman cadastres. This reflection continues to develop {{within the framework of}} micro-regional studies; the first benefits, albeit partial, concern campaign organization in the Roman Empire and its origin in the dynamic of indigeneous societies, urban creations and the development of the forces of production. Our approach aims at grasping the interconnections between local forms and the processes which simultaneously renew and transform them, so as to understand the Roman system of cultivation not as a pre-established, uniform and fixed structure, but rather as a unifying movement. Fiches Jean-Luc. L'espace rural antique dans le Sud-Est de la France : ambitions et réalités archéologiques. In: Annales. Économies, Sociétés, Civilisations. 42 ᵉ année, N. 1, 1987. pp. 219 - 238...|$|R
40|$|Despite the title, this {{engineer}} intelligence guide (EIG) is a photo-interpretation handbook. It {{was intended to}} help <b>photo-interpreters</b> recognize streams, rivers, lakes, and other hydrologic features. The introduction says that the purpose is: a) To give “the officer responsible for furnishing hydrologic and hydraulic data in an assigned area … {{an understanding of the}} usefulness and limitations of photography in furnishing the type of information needed …,” and to assist in planning requests for photographic coverages of the assigned area. b) To give “photo-interpreters sufficient knowledge of hydrology and hydraulics to be able to satisfy requests for information that can be secured from photographs and become aware of the need for communicating changes in … conditions, such as, breaks in levees, sudden drawdown or filling of reservoirs, rising water in rivers, and formation and breakup of ice jams…” It contains extensive guidance in preparation of requests for photographic missions. It contains detailed information on the value of photographs as sources of hydrologic and hydraulic data. This EIG contains detailed information with extensive illustrations to assist in interpretation of hydraulic characteristics of watershed, hydraulic characteristics of streams, and of hydraulic structures such as dams, hydroelectric plants, canals, irrigation systems, flood control structures, etc. It contains a bibliography of literature related to military hydrology and the application of aerial photography to understanding hydrologic features. It contains an lengthy distribution list of officials and organizations within the Army interested in military engineering...|$|R
40|$|Abstract- Sahara is a WEU funded project. Its {{aim is to}} {{show the}} {{potential}} usefulness of image interpretation techniques to help <b>photo-interpreters.</b> Typically, this could include drawing a sketch of the airport, looking for changes {{with respect to a}} reference geographic database, etc. The need for tools that fasten satellite imagery interpretation will become even more stringent with the next generation of satellites that will provide a very high amount of high resolution data. We therefore used aerial multi-sensor imagery with resolution expected in the near future for commercial satellite imagery (VIS 2 m, SAR 5 m, etc.). As a test case, the project was dedicated to the interpretation of airports. In this scope the main objects of interest like runways, taxiways, shelters, airplanes and buildings are searched for. In this paper, we show that object-related detectors are not able to solve the problem by their own. We then propose a scheme in which high level knowledge may be introduced in an efficient way. This knowledge is used to steer the interpretation and to enforce a coherent result. A GUI allows the user to follow the evolution of the interpretation and to have {{a clear view of the}} high level knowledge that is used. The user may also intervene at any moment to help the interpretation, by correcting errors, stopping the research in a non promising areas, etc. Key words- 3 D scene analysis, artificial intelligence, expert system, blackboard system, fuzzy production rules, road detection, building detection, shelter detection, airport interpretation. F I...|$|R
40|$|Woody {{vegetation}} cover interpreted from aerial photography requires assessment against field data as {{the signature of}} woody {{vegetation cover}} may differ between photoscales, vegetation types and <b>photo-interpreters.</b> Measurements of aerial woody cover taken from aerial photography of four different photoscales were compared with a field dataset from Eucalyptus- and Acacia-dominated landscapes of semi-arid Queensland. Two interpreters employed a method that utilises a stereoscope and sample-point graticule for manual quantified measurements of aerial woody cover. Both interpreters generated highly significant models accounting for 77 and 78 % of deviance. Photoscale {{appears to have a}} consistent effect whereby the signature of woody cover increases as the photoscale decreases from 1 : 25 000 to 1 : 80 000, although the magnitude of this effect was different between interpreters. The results suggest no substantial differences in the shape of models predicting crown cover between Acacia- and Eucalyptus-dominated land types, although the precision of the models was greater for the Acacia (90 – 91 % of residual deviance) than for the Eucalyptus (50 – 56 % of residual deviance) land type. The reduced accuracy in the Eucalyptus land type probably reflects the relatively diffuse crowns of the dominant trees. The models generated for this dataset are within the range of those from other calibration studies employing photography of a range of scales and methodologies. The effect of photoscale is verified between the available studies, but there may also be variations arising from methodological differences or image properties. The present study highlights the influence of photoscale and interpreter bias for assessing woody crown cover from aerial photography. Studies that employ aerial photography should carefully consider potential biases and cater for them by calibrating assessments with field measurements...|$|R
40|$|International audienceManagement and {{conservation}} planning of any ecosystem requires knowledge of species composition. This {{is a real}} challenge in tropical rain forests that are characterised by very high species richness and canopy access limitations. The possibility of approaching trees from remote sensing on large-scale aerial photographs, takes on its full significance in this context. Results of tree species identification by photo-interpretation in a French Guianan forest canopy are discussed, {{as well as an}} overview of the part of the forest accessible from the photographs. Two sets of aerial photographs were used. One set (1 : 3700 colour slides) covers 15 ha of primary forest, divided into a training set (TS, 5 ha) and a validation set (VS 1 : 10 ha). Another validation set, taken in different conditions of acquisition, scale and season, is available for an adjacent area (VS 2 : 6. 5 ha). Aerial photographs captured a quarter of the tree community (dbh ! 10 cm) on average, and about 45 % of the SGS (Species or Group of Species) on the training set. The crown appearance of 12 major canopy SGS, including commercial species and species of ecological interest, had been described in a previous work on the same training set. Following these descriptions, two <b>photo-interpreters</b> separately identified 309 tree crowns overall on VS 1, with a good agreement in their respective judgements. After their interpretations were checked in the field, the overall average identification success was high (87 %) but the results varied according to the SGS. The results on VS 2 showed that some species displayed major seasonal and scale variations and were hardly recognized, whereas some others could be identified without modifying the learning process. The results are encouraging and this work will be extended as the identification of tropical rain forest trees from remote sensing has many applications, ranging from fundamental ecological knowledge of canopy species to the management {{and conservation}} of such highly diverse and hardly inventoried ecosystems...|$|R
40|$|JRC is {{exploring}} {{the improvement of}} the human assessment of building damage by applying image enhancement processing before photo-interpretation phase. The JRC has designed a set of experiments to assess the effect of such processing on recognition mechanisms. In the frame of the Geo-Information and Visual Perception project, we apply a cognitive approach to the remotely sensed imagery photo-interpretation process, exploring the possibility to improve the assessment of building damage, traditionally carried out by the time consuming and error prone human interpretation. This task is often performed following disasters to support the information needs of emergency rescue for humanitarian relief intervention. Therefore, while on the one hand there is a high pressure to deliver a result as quickly as possible, on the other hand it is of the highest importance to ensure the quality of the assessment. The ISFEREA action (Globesec Unit, IPSC, JRC) has developed several algorithms aimed at promoting the salience of targets in complex backgrounds, with the purpose of improving semi and fully automatic image information extraction. As a rich plethora of different processing methods could be at the <b>photo-interpreter’s</b> disposal, it becomes increasingly useful to test if different processing methods {{have an effect on the}} subjective task performance (quality and speed) of identifying building damage. There are severe limits on our capacity to process visual information, due to the limits of the brain energy and the neuronal activity. Stimuli compete, attention filters. The more a stimulus is attractive, the more likely the information incorporated will be processed. Therefore a processing method should support the interpreter - involved in a damage assessment - in visually filtering the huge amount of information at her/his disposal. As study case, we chose the magnitude 7. 0 earthquake in Haiti on 12 January 2010, because of the availability of i) airborne imagery, which resolution allows for visual buildings damage assessment and ii) an official damage assessment, which can be the starting point to measure the task performance. JRC. G. 2 -Global security and crisis managemen...|$|R
40|$|Thesis (M. A.) [...] Boston UniversityA {{study was}} {{previously}} made by Dr. Duncan E. Macdonald {{and his group}} at the Optical Research Laboratory of Boston University. This study dealt with the determination of photographic image quality by edge analysis, where an edge here was defined as B {{greater than or equal}} to ten percent occurring between a successive trough and peak of a micro-densitometer trace across the photograph. ∆ B is defined as the brightness change across the edge and B is the minimum absolute brightness where this change took place. This thesis is a further study into the work done by Dr. Macdonald. The analysis of his data was done from direct measurements of the paper recorded micro-densitometer traces, but in this study it was proposed that the same or similar data could be recorded automatically using electronic equipment. This thesis presupposes no quantitative definition of an edge, but suggests that with further work a quantitative definition of an edge may be determined. An edge is simply defined as the boundary which separates a picture element from its surroundings on a photograph so that the object is discernible to the eye. We assume that the quality of the picture is a function of its edges and that the edge can be described by two variables; 1) the slope or rate of change of brightness across the edge, and 2) the relative brightness difference across the edge. The equipment used was designed to measure the magnitude of the relative slope, and count the number of slopes of given magnitude in a unidirectional scan across the photograph. Other equipment was designed to measure the magnitude of the reflectivity difference across the edge and count the number of occurences for a given magnitude per linescan. An edge is defined electronically as the change in reflectivity from black to white of a uni-directional scan between any two points where the derivative of this linescan waveform is zero. In this definition no notice is taken as to whether an observer can detect the edge. Five aerial photographs were used in this study graded by impartial observers. Three of the photos are aerial photographs of trees graded as (A) unus~ble, (B) just usuable, (C) excellent. The other two pictures are aerial photos of the Boston suburban area graded as (P) unusable and (G) excellent. These photographs were mounted on a rotating drum which can be adjusted so that any part of the drum can be scanned. The drum was illuminated from a suitable light source. The target is imaged on a pinhole through an optical system. Behind the pinhole is a photo-multiplier tube. The output of the photo-tube serves as the input to a D. C. amplifier. The output of the amplifier is then a voltage scan of a line on the target. To work with the derivative of this waveform the voltage function is then differentiated and level selected. All derivatives above the level selected are counted on an electronic counter. By varying the level selector from zero to maximum level all derivatives are counted and magnitudes recorded. To get the reflectivity difference across an edge a circuit is used which allows an output of the linescan signal to appear only when the derivative is positive. Thus the reflectivity difference across an edge appears relative to a common base line irrespective of what background reflectivity the edge occurred. This in turn was electronically level selected and counted in the same manner as was the derivative. The data consisted of between 1, 500 and 2, 000 counts for every curve drawn. This data was reworked and presented in graphical form, as shown in figures XVII through XX, as cumulative frequency of counts plotted against the magnitude of the relative derivative of the edge in one case and the magnitude of relative reflectivity across an edge in the other. These curves show quite clearly that a difference exists between the good and poor pictures. The excellent photos have slopes that are much greater than the just usuable or unusable pictures. The higher magnitude slopes seem to indicate the quality of the photograph, the lower value slopes being fairly uniform throughout. Similarly the higher reflectivity across an edge appears on the best quality photographs with commensurate degrading for poorer quality pictures. With the knowledge that the edge criterion chosen can lead to objective results for picture quality, it would be interesting to carry on this work in experimentally determining a definition for the threshold photographic edge. This threshold edge is defined as the minimum observable boundary permitting a picture element to be seen in a photograph by a human observer. This could be done by using a large sample from <b>photo-interpreters</b> and the apparatus already perfected for this thesis...|$|R
