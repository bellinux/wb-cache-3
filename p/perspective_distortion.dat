262|173|Public
2500|$|Gilliam's {{films have}} a {{distinctive}} look, {{not only in}} mise-en-scène but even more so in photography, often recognisable from just a short clip; to create a surreal atmosphere of psychological unrest and a world out of balance, he frequently uses unusual camera angles, particularly low-angle shots, high-angle shots, and Dutch angles. Roger Ebert said that [...] "his world is always hallucinatory in its richness of detail." [...] Most of his movies are shot almost entirely with rectilinear ultra-wide-angle lenses with focal lengths of 28mm or less to achieve a distinctive style defined by extreme <b>perspective</b> <b>distortion</b> and extremely deep focus. Gilliam's long-time director of photography Nicola Pecorini has said, [...] "with Terry and me, a long lens means something between a 40mm and a 65mm." [...] This attitude markedly differs from the common definition in photography, by which 40 to 65mm is the focal length of a normal lens, resembling the natural human field of view, unlike Gilliam's signature style, defined by extreme <b>perspective</b> <b>distortion</b> due to his usual choice of focal length. The 14-mm lens has become informally known as [...] "The Gilliam" [...] among filmmakers because of his frequent use of it at least since Brazil. Gilliam has explained his preference for using wide-angle lenses in his films: ...|$|E
5000|$|... #Caption: Perspective control: {{original}} (left), <b>perspective</b> <b>distortion</b> removed (right).|$|E
5000|$|... #Caption: Picture of Notre Dame de Reims showing <b>perspective</b> <b>distortion</b> ...|$|E
40|$|In this paper, {{we propose}} an affine-invariant method for {{describing}} and matching curves. This is important since affine transformations {{are often used}} to model <b>perspective</b> <b>distortions.</b> More specifically, we propose a new definition of {{the shape of a}} curve that characterizes a curve independently of the effects introduced by affine distortions. By combining this definition with a rotation-invariant shape descriptor, we show how it is possible to describe a curve in an intrinsically affineinvariant manner. To validate our procedure we built a database of shapes subject to <b>perspective</b> <b>distortions</b> and plotted the precision-recall curve for this dataset. Finally an application of our method is shown in the context of wide baseline matching. ...|$|R
50|$|During {{the years}} of the Second World War and {{immediately}} after the war, 1945-1948, he floods his projects with inspiration and expression drawn from post-war ruins, disasters and <b>perspective</b> <b>distortions.</b> His work clearly reveals his psychological state influenced by the historical events. This period can be identified as expressionistic.|$|R
50|$|There are {{additional}} optical phenomena that can degrade image quality {{but are not}} considered aberrations. For example, the oblique cos4θ light falloff, sometimes called natural vignetting, and lateral magnification and <b>perspective</b> <b>distortions</b> seen in wide angle lenses are really geometric effects of projecting three-dimensional objects down into two-dimensional images, not physical defects.|$|R
5000|$|... #Caption: A {{people mover}} at Frankfurt International Airport showing <b>perspective</b> <b>distortion</b> as {{parallel}} lines appear to converge.|$|E
5000|$|In the {{two images}} {{shown to the}} right, the first suffers from <b>perspective</b> <b>{{distortion}}</b> [...] - [...] in the second that distortion has been corrected.|$|E
5000|$|Each {{convolutional}} neuron processes data {{only for}} its receptive field. Tiling allows CNNs to tolerate translation of the input image (eg. translation, rotation, <b>perspective</b> <b>distortion)</b> [...]|$|E
5000|$|The {{origin of}} the globe effect {{initially}} remained unclear after its discovery {{in the first half}} of the past century. Koehler speculated about an [...] "unnatural perspective generated by the binocular while panning over a three dimensional scenery", thereby ignoring the fact that the globe effect was observable at the night sky as well, where <b>perspective</b> <b>distortions</b> were absent.|$|R
40|$|Abstract—Mobile optical {{wireless}} has so {{far been}} limited to very short ranges for high data rate systems. It may be feasible to overcome the data rate limitations over large transmission range in optical wireless through camera receivers and light emitting transmitter arrays through a concept what we call ”visual MIMO”. In this concept multiple transmit elements of a light emitting array (LEA) are used as transmitters to communicate to the individual pixel elements of the camera which act as multiple receive elements to create the visual MIMO channel. Multiplexing information over parallel data channels albeit be very similar to RF MIMO in concept, the visual MIMO approach dramatically differs in its characterization. In visual MIMO since the received signal is essentially the image of the transmitting element, the <b>perspective</b> <b>distortions</b> in the visual channel dominate over some of the important properties of a RF wireless channel such as distance based attenuation and multipath fading. Some of the prominent <b>perspective</b> <b>distortions</b> include the reduction {{in the size of the}} image with distance and skew/rotation in the image due to angular view. Further lens blur (typically due to focus imperfection or jerks while capturing the image) can also significantly depreciate the image quality. In this paper we will detail how MIMO techniques such as multiplexing and diversity are characterized based on the effect of <b>perspective</b> <b>distortions.</b> Based our visual MIMO channel model we will derive the analytical channel capacity of the visual MIMO channel and using the same we illustrate the significance of parameters such as distance, viewing angle and blur in characterizing multiplexing and diversity in visual MIMO. I...|$|R
40|$|This paper {{addresses}} {{the problem of}} recovering relative structure, {{in the form of}} an invariant, from two views of a 3 D scene. The invariant structure is computed without any prior knowledge of camera geometry, or internal calibration, and with the property that perspective and orthographic projections are treated alike, namely, the system makes no assumption regarding the existence of <b>perspective</b> <b>distortions</b> in the input images. We show tha...|$|R
5000|$|Note Capture took a {{photographs}} of some text or graphics {{on a page}} or a whiteboard and fixed the <b>perspective</b> <b>distortion</b> to produce the original rectangle.|$|E
5000|$|Tabularism is a destroyer. It {{shakes the}} shell of space und subverts what {{contains}} all visible things. It breaks <b>perspective</b> <b>distortion.</b> It is at war with every line.|$|E
5000|$|... #Caption: How {{focal length}} affects perspective: Varying focal lengths at {{identical}} field size achieved by different camera-subject distances. Notice that the shorter the focal length {{and the larger}} the angle of view, <b>perspective</b> <b>distortion</b> and size differences increase.|$|E
40|$|The fast radial {{symmetry}} (FRS) transform {{has been}} very popular for detecting interest points based on local radial symmetry 1. Although FRS delivers good performance at a relatively low computational cost and is very well suited {{for a variety of}} real-time computer vision applications, it is not invariant to <b>perspective</b> <b>distortions.</b> Moreover, even perfectly (radially) symmetric visual patterns in the real world are perceived by us after a perspective projection. In this paper, we propose a systematic extension to the FRS transform to make it invariant to (bounded) cases of perspective projection- we call this transform the generalized FRS or GFRS transform. We show that GFRS inherits the basic characteristics of FRS and retains its computational efficiency. We demonstrate the wide applicability of GFRS by applying it to a variety of natural images to detect radially symmetric patterns that have undergone significant <b>perspective</b> <b>distortions.</b> Subsequently, we build a nucleus detector based on the GFRS transform and apply it to the important problem of digital histopathology. We demonstrate superior performance over state-of-the-art nuclei detection algorithms, validated using ROC curves. 1...|$|R
25|$|The {{interest}} points {{obtained from}} the scale-adapted Laplacian blob detector or the multi-scale Harris corner detector with automatic scale selection are invariant to translations, rotations and uniform rescalings in the spatial domain. The images that constitute the input to a computer vision system are, however, also subject to <b>perspective</b> <b>distortions.</b> To obtain interest points that are more robust to perspective transformations, a natural approach is to devise a feature detector that is invariant to affine transformations.|$|R
5000|$|One part of {{the overall}} drawing state was the gxMapping. This was a 3-by-3 matrix which could express {{arbitrary}} linear transformations in two dimensions, including <b>perspective</b> <b>distortions.</b> All GX objects had an associated mapping as part of its drawing state, which allowed for things like rotations and translations. Although all of this state was held in the gxMapping for that object, GX also provided [...] "wrapper" [...] commands like [...] "rotate" [...] to make the API simpler to use.|$|R
50|$|<b>Perspective</b> <b>distortion</b> is {{influenced}} by the relationship between two factors: the angle of view at which the image is captured by the camera and the angle of view at which the photograph of the subject is presented or viewed.|$|E
50|$|Rectilinear ultra-wide angle lenses {{are used}} in {{photography}} and cinematography sometimes to achieve three-dimensional <b>perspective</b> <b>distortion</b> instead of simply two-dimensional barrel distortion. A notable, signature employment for this purpose is frequently seen in the films of Terry Gilliam, for instance.|$|E
5000|$|In {{photography}} and cinematography, <b>perspective</b> <b>distortion</b> is a warping or transformation {{of an object}} and its surrounding area that differs significantly from what the object would look like with a normal focal length, due to the relative scale of nearby and distant features. <b>Perspective</b> <b>distortion</b> {{is determined by the}} relative distances at which the image is captured and viewed, and is due to the angle of view of the image (as captured) being either wider or narrower than the angle of view at which the image is viewed, hence the apparent relative distances differing from what is expected. Related to this concept is axial magnification -- the perceived depth of objects at a given magnification.|$|E
40|$|Detection of curled textline is {{important}} for dewarping of hand-held camera-captured document images. Then baselines and the lines following the top of x-height of characters (x-lines) are estimated for dewarping. Existing curled textline segmentation approaches are sensitive to outlier points and <b>perspective</b> <b>distortions.</b> Furthermore these approaches use regression over top and bottom points of a segmented textline to estimate its x-line and baseline separately, which may results in inaccurate estimation. Here we propose a novel curled textline segmentation approach based on active contours (snakes) in which we perform segmentation by estimating the pairs of x-line and baseline; solving both problems together. Starting form a connected component we jointly trace a pair of x-line and baseline using coupled snakes and external energies of neighboring top-bottom points. We grow neighborhood region iteratively during tracing, which results in robustness to <b>perspective</b> <b>distortions,</b> and maintain a natural property of similar distance within the pair of x-line and baseline pair, which results in robustness to outlier points. We achieved 90. 76 % of one-to-one match-score recognition accuracy of curled textline segmentation on CBDAR 2007 Document Image Dewarping Contest dataset, with good estimation of pairs of x-line and baseline. ...|$|R
5000|$|Two-point <b>perspective</b> reduces <b>distortion</b> by viewing objects at an angle, {{with all}} the {{horizontal}} lines receding {{to one of two}} vanishing points, both located on the horizon.|$|R
40|$|International audienceThis paper {{presents}} a method named Depth-Assisted Rectification of Patches (DARP), which exploits depth information available in RGB-D consumer devices to improve keypoint matching of perspectively distorted images. This {{is achieved by}} generating a projective rectification of a patch around the keypoint, which is normalized with respect to <b>perspective</b> <b>distortions</b> and scale. The DARP method runs in real-time {{and can be used}} with any local feature detector and descriptor. Evaluations with planar and non-planar scenes show that DARP can obtain better results than existing keypoint matching approaches in oblique poses...|$|R
5000|$|... #Caption: How {{focal length}} affects perspective: 18mm (wide-angle), 34mm (normal), and 55mm (modest telephoto) at {{identical}} field size achieved by different camera-subject distances. Notice that the shorter the focal length {{and the wider}} the angle of view, <b>perspective</b> <b>distortion</b> and size differences change.|$|E
50|$|Shape-from-texture Suppose such {{an object}} with smooth surface covered by {{replicated}} texture units, and its projection from 3D to 2D causes distortion and <b>perspective.</b> <b>Distortion</b> and perspective measured in 2D images provide the hint for inversely solving depth of normal information {{of the object}} surface.|$|E
50|$|Lenses {{suited for}} {{traditional}} portrait photography are medium telephoto lenses, in the 85mm-135mm range, which provide the desired <b>perspective</b> <b>distortion</b> in {{head and shoulders}} shots (compressing facial features), and have fast aperture, of 2.8 or faster, to allow shallow depth of field, focusing attention on the subject.|$|E
40|$|The method {{based on}} Panini {{projection}} to reduce <b>perspective</b> <b>distortions</b> of images with {{wide viewing angle}} is considered. The analysis {{of the features of}} construction of Panini projection is provided. A realization of the effect on the graphic accelerators as a result of post-processing is proposed. The results of using the described effect in computer graphics were obtained. A comparison of images in the perspective projection and Panini projection was carried out. It is shown that perspective projection of a three-dimensional scene onto the surface of a parabolic cylinder reduces distortions. </p...|$|R
40|$|Scientific {{applications}} {{often require}} an exact reconstruction of object positions and distances from digital images. Therefore, the images {{need to be}} corrected for <b>perspective</b> <b>distortions.</b> We present CameraTransform, a python package that performs a perspective image correction whereby the height, tilt/roll angle and heading of the camera can be automatically obtained from the images if additional information such as GPS coordinates or object sizes are provided. We present examples of images of penguin colonies that are recorded with stationary cameras and from a helicopter. Comment: 8 pages, 5 figure...|$|R
50|$|In addition, tracks by Lemon Kittens {{appear on}} the {{compilation}} albums Snatch 2, Hoisting the Black Flag, <b>Perspectives</b> and <b>Distortion,</b> The Wonderful World of Glass vol 1, and Terra Serpentes.|$|R
5000|$|... #Caption: How {{focal length}} affects perspective: 18 mm (ultra wide-angle), 34 mm (wide-angle), and 55 mm (normal lens) at {{identical}} field size achieved by different camera-subject distances. Notice that the shorter the focal length {{and the wider}} the angle of view, <b>perspective</b> <b>distortion</b> and size differences change.|$|E
50|$|Theodor Scheimpflug (October 7, 1865 - August 22, 1911) was an Austrian army Captain who {{elaborated}} {{a systematic}} method and apparatus for correcting <b>perspective</b> <b>distortion</b> in aerial photographs, {{now known as}} the eponymous Scheimpflug principle. He disclaimed inventing it however, citing an English patent of the early French photographic engineer Jules Carpentier.|$|E
50|$|A {{darkroom}} technician can correct <b>perspective</b> <b>distortion</b> in {{the printing}} process. It is usually done by exposing the paper {{at an angle}} to the film, with the paper raised toward the part of the image that is larger, therefore not allowing the light from the enlarger to spread as much as {{the other side of the}} exposure.|$|E
40|$|Abstract: In {{this paper}} {{we present a}} hybrid {{technique}} for correcting distortions that appear when projecting images onto geometrically complex, colored and textured surfaces. It analyzes the optical flow that results from <b>perspective</b> <b>distortions</b> during motions of the observer and tries to use this information for computing the correct image warping. If this fails due to an unreliable optical flow, an accurate –but slower and visible – structured light projection is automatically triggered. Together with an appropriate radiometric compensation, view-dependent content can be projected onto arbitrary everyday surfaces. An implementation mainly on the GPU ensures fast frame rates...|$|R
40|$|In this paper, {{we propose}} an {{adaptive}} stereo matching algorithm to encompassing stereo matching problems in projective distortion region. Since the projective distortion region {{can not be}} estimated in terms of fixed-size block matching algorithm, we tried to use adaptive window warping method in hierarchical matching process to compensate the <b>perspective</b> <b>distortions.</b> In addition, probability theory was adopted to encompass uncertainty of disparity of points over the window in this study. The proposed stereo matching algorithm has tested on both disparity map and 3 D model view. The experimental result shows that remarkable improvement is obtained in the projective distortion region. 1...|$|R
40|$|In {{this paper}} {{we present a}} hybrid {{technique}} for correcting distortions that appear when projecting images onto geometrically complex, colored and textured surfaces. It analyzes the optical flow that results from <b>perspective</b> <b>distortions</b> during motions of the observer and tries to use this information for computing the correct image warping. If this fails due to an unreliable optical flow, an accurate -but slower and visible- structured light projection is automatically triggered. Together with an appropriate radiometric compensation, view-dependent content can be projected onto arbitrary everyday surfaces. An implementation mainly on the GPU ensures fast frame rates...|$|R
