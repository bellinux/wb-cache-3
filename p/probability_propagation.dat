73|169|Public
5000|$|... "Every {{denunciation}} of existing law tends {{in some measure}} to increase the probability {{that there will be}} violation of it. Condonation of a breach enhances the probability. Expressions of approval add to the <b>probability.</b> <b>Propagation</b> of the criminal state of mind by teaching syndicalism increases it. Advocacy of lawbreaking heightens it still further. But even advocacy of violation, however reprehensible morally, is not a justification for denying free speech where the advocacy falls short of incitement..." ...|$|E
40|$|Until recently, {{artificial}} intelligence researchers have frowned upon {{the application of}} <b>probability</b> <b>propagation</b> in Bayesian belief networks that have cycles. The <b>probability</b> <b>propagation</b> algorithm is only exact in networks that are cycle-free. However, it has recently been discovered that the two best error-correcting decoding algorithms are actually performing <b>probability</b> <b>propagation</b> in belief networks with cycles...|$|E
3000|$|..., {{denoting}} {{the property}} <b>probability</b> <b>propagation</b> matrix, {{is also a}} null matrix because no direct relations exist between properties.|$|E
40|$|AbstractPartial abductive {{inference}} in Bayesian belief networks (BBNs) {{is intended}} {{as the process}} of generating the K most probable configurations {{for a set of}} unobserved variables (the explanation set). This problem is NP-hard and so exact computation is not always possible. In previous works genetic algorithms (GAs) have been used to solve the problem in an approximate way by using exact <b>probabilities</b> <b>propagation</b> as the evaluation function. However, although the translation of a partial abductive inference problem into a (set of) <b>probabilities</b> <b>propagation</b> problem(s) enlarges the class of solvable problems, it is not enough for large networks. In this paper we try to enlarge the class of solvable problems by reducing the size of the graphical structure in which <b>probabilities</b> <b>propagation</b> will be carried out. To achieve this reduction we present a method that yields a (forest of) clique tree(s) from which the variables of the explanation set have been removed, but in which configurations of these variables can be evaluated. Experimental results show a significant speedup of the evaluation function when propagation is performed over the obtained reduced graphical structure...|$|R
40|$|Abstract — As {{the feature}} size shrinks to the {{nanometer}} scale, SRAM-based FPGAs {{will become increasingly}} vulnerable to soft errors. Existing reliability-oriented placement and routing approaches primarily focus on reducing the fault occurrence probability (node error rate) of soft errors. However, our analysis shows that, besides the fault occurrence <b>probability,</b> the <b>propagation</b> <b>probability</b> (error <b>propagation</b> <b>probability)</b> {{plays an important role}} and should be taken into consideration. In this paper, we first propose a cube-based analysis algorithm to efficiently and accurately estimate the error <b>propagation</b> <b>probability.</b> Based on such a model, we propose a novel reliability-oriented placement and routing algorithm that combines both the fault occurrence probability and the error <b>propagation</b> <b>probability</b> together to enhance system-level robustness against soft errors. Experimental results show that, compared with the baseline versatile place and route technique, the proposed scheme can reduce the failure rate by 20. 73 %, and increase the mean time between failures by 39. 44 %. Index Terms — Cube-based analysis, failure rate, field-programmable gate arrays (FPGAs), mean time between failures (MTBFs), placement and routing, soft error mitigation. I...|$|R
30|$|The decay factor γ at hop N {{represents}} the ratio between the <b>propagation</b> <b>probability</b> at hop N and the <b>propagation</b> <b>probability</b> at hop N− 1. In practice, the <b>propagation</b> <b>probability</b> might decay exponentially as the cascades spread {{away from the}} information source. Here, one possible explanation {{would be that the}} freshness of the information would drop as the time goes on.|$|R
40|$|Jointree {{computation}} {{continues to}} be central to the {{theory and practice of}} probabilistic expert systems. Recent research has incorporated granular structures to facilitate propagation in the jointree. In this paper, we propose a method for granular jointree <b>probability</b> <b>propagation.</b> Our method extends the previous works by allowing the granular levels to communicate with each other. It is explicitly demonstrated that our granular approach increases the amount of parallelism during <b>probability</b> <b>propagation...</b>|$|E
3000|$|..., {{denoting}} the property-tag <b>probability</b> <b>propagation</b> matrix, is a null matrix as {{a result}} of the lack of direct relations between properties and tags.|$|E
3000|$|... is {{the item}} <b>probability</b> <b>propagation</b> matrix, and the {{similarities}} between items are set {{as the number of}} the initial propagation matrixes. When item I [...]...|$|E
40|$|AbstractIn this work, {{we propose}} a dynamic {{graphical}} model {{as a tool}} for Bayesian inference and forecasting in dynamic systems described by a series which is dependent on a state vector evolving according to a Markovian law. We build sequential algorithms for the <b>probabilities</b> <b>propagation.</b> This sequentiality turns out to be represented by the dynamic graphical structure after carrying out several goal-oriented sequential graphical transformations...|$|R
30|$|Finally, we {{normalize}} to 1 each {{line of the}} <b>propagation</b> <b>probability</b> matrix.|$|R
40|$|Relevance Feedback {{consists}} in automatically formulating a new query {{according to the}} relevance judgments provided by the user after evaluating a set of retrieved documents. In this article, we introduce several relevance feedback methods for the Bayesian Network Retrieval Model. The theoretical frame on which our methods are based uses the concept of partial evidences, which summarize the new pieces of information gathered after evaluating the results obtained by the original query. These partial evidences are inserted into the underlying Bayesian network and a new inference process (<b>probabilities</b> <b>propagation)</b> is run to compute the posterior relevance probabilities of the documents in the collection given the new query. The quality of the proposed methods is tested using a preliminary experimentation with different standard document collections...|$|R
3000|$|... is the user-property <b>probability</b> <b>propagation</b> matrix. We {{employ the}} TF-IDF {{approach}} {{to measure the}} similarity between items and tags. The more often item I [...]...|$|E
40|$|We propose margin {{propagation}} as {{an alternative}} to <b>probability</b> <b>propagation</b> in forward decoding. In contrast to sumproduct <b>probability</b> <b>propagation,</b> margin propagation only incurs addition and subtraction in the computation and thus leads to reduced complexity of implementation. Simulations indicate that margin based forward decoding is more robust to input noise and parameter mismatch than sumproduct probability decoding, and offers superior decoding performance. We also present an analog VLSI implementation of the margin propagation network independent of MOS device models, and provide experimental results from a prototype fabricated in a process. 1...|$|E
3000|$|... is the user-tag <b>probability</b> <b>propagation</b> matrix. We {{employ the}} term frequency–inverse {{document}} frequency (TF-IDF) approach {{to measure the}} similarity between users and tags. The more often user u [...]...|$|E
3000|$|... {{during the}} random walking, we can either proceed to another node at the <b>propagation</b> <b>probability</b> between node v [...]...|$|R
40|$|Abstract. We {{propose a}} {{probabilistic}} document retrieval model based on Bayesian networks. The network {{is used to}} compute the posterior probabilities of relevance of the documents in the collection given a query. These computations {{can be carried out}} efficiently, because of the specific network topology and conditional probability tables being considered, which allow the use of a fast and exact <b>probabilities</b> <b>propagation</b> algorithm. In the initial model, only direct relationships between the terms in the glossary and the documents that contain them are considered, giving rise to a Bayesian network with two layers. Next, we consider an extended model that also includes direct relationships between documents, using a network topology with three layers. We also report the results of a set of experiments with the two models, using several standard document collections. ...|$|R
40|$|A markovian {{model of}} the error {{probability}} density for decision feedback equalizer is proposed and its application to the error <b>propagation</b> <b>probability</b> computation is derived. The model is a generalization of the Lutkemeyer and Noll model proposed in [1]. It is obtained by {{the analysis of the}} gaussian mixture distribution of the errors which follows a Markov Process. The analysis of this process shows that the error <b>propagation</b> <b>probability</b> of the Weighted DFE [2] is less than the one of the classical DFE...|$|R
3000|$|... is {{the user}} <b>probability</b> <b>propagation</b> matrix, and the {{similarities}} between users are set {{as the number of}} the initial propagation matrixes. When users grade the same item, the improved Pearson coefficient will be used to measure {{the similarities between}} them.|$|E
40|$|The graph {{isomorphism}} {{problem is}} to determine whether two given graphs are iso-morphic or not. In this paper, we present a new graph invariant, called the <b>probability</b> <b>propagation</b> matrix. By means of this graph invariant, we present a heuristic algorithm for the problem. The algorithm is easy to implement and highly parallelizable...|$|E
40|$|We {{propose a}} {{probabilistic}} case-space metric {{for the case}} matching and case adaptation tasks. Central to our approach is a <b>probability</b> <b>propagation</b> algorithm adopted from Bayesian reasoning systems, which allows our case-based reasoning system to perform theoretically sound probabilistic reasoning. The same <b>probability</b> <b>propagation</b> mechanism actually offers a uniform solution to both the case matching and case adaptation problems. We also show how the algorithm can be implemented as a connectionist network, where efficient massively parallel case retrieval is an inherent property of the system. We argue that using {{this kind of an}} approach, the difficult problem of case indexing can be completely avoided. Pp. 144 [...] 154 in Topics in Case-Based Reasoning, edited by Stefan Wess, Klaus-Dieter Althoff and Michael M. Richter. Volume 837, Lecture Notes in Artificial Intelligence. Springer Verlag, 1994. 1 Introduction In case-based reasoning (CBR) paradigm the dynamic case memory is central to [...] ...|$|E
3000|$|... is {{computed}} for expanding {{the seeds and}} for propagating the ‘skinness’, we consider two variants of our method. This cost may be computed using the raw skin probability obtained from the global model (termed raw <b>probability</b> (RP)-based <b>propagation)</b> or alternatively, the DSPF skin map {{may be used for}} this purpose as outlined in Section 3.3 (termed DSPF-based propagation).|$|R
40|$|Adder {{architectures}} {{are presented}} here by an unified formalism, and analysed from the delay, complexity and power consumption points of view. An analytical {{model for the}} power consumption is derived, assuming that it {{is proportional to the}} transition density [DHNT 95]. The model is subsequently validated by simulation using a signal transition <b>probabilities</b> <b>propagation</b> tool [Cra 89]. Finally, glitches are taken into account when transitions at the input of a cell are separated by one or more cell delays. A redundant to total power ratio is also derived. Keywords Adder, BDD, glitch threshold, low power, spurious transition, switching activity 1 INTRODUCTION Addition is the most frequently used arithmetic primitive, involved not only in simple addition but also in more complex operations like multiplication and division. The present study covers the linear ripple carry adder and different architectures of carry select and carry lookahead adders. Designing low-power high-speed circuits r [...] ...|$|R
40|$|In this paper, we derive the {{probability}} distributions of difference <b>propagation</b> <b>probabilities</b> and input-output correlations for random functions and block ciphers, for {{several of them}} for the first time. We show that these parameters have distributions that are well-studied in the field of probability such as the normal, Poisson, Gamma and extreme value distributions. For Markov ciphers there exists a solid theory that expresses bounds on the complexity of differential and linear cryptanalysis in terms of average difference <b>propagation</b> <b>probabilities</b> and average correlations, where the average is taken over the keys. The <b>propagation</b> <b>probabilities</b> and correlations exploited in differential and linear cryptanalysis actually depend on the key and hence so does the attack complexity. The theory of Markov ciphers does not make statements on the distributions of these fixed-key properties but rather makes the assumption that their values will be close to the average {{for the vast majority of}} keys. This assumption is made explicit in the form of the hypothesis of stochastic equivalence...|$|R
40|$|Given a problem, a case-based {{reasoning}} (CBR) system will search its case memory {{and use the}} stored cases to find the solution, possibly modifying retrieved cases {{to adapt to the}} required input specifications. In this paper we introduce a neural network architecture for efficient {{case-based reasoning}}. We show how a rigorous Bayesian <b>probability</b> <b>propagation</b> algorithm can be implemented as a feedforward neural network and adapted for CBR. In our approach the efficient indexing problem of CBR is naturally implemented by the parallel architecture, and heuristic matching is replaced by a probability metric. This allows our CBR to perform theoretically sound Bayesian reasoning. We also show how the <b>probability</b> <b>propagation</b> actually offers a solution to the adaptation problem in a very natural way. I. Introduction Artificial intelligence research has focused on finding methods that allow computer programs to incorporate knowledge by manipulating high-level representations of relevant informat [...] ...|$|E
3000|$|BN sub-structure, was {{set equal}} to 9, 11, 7 and 10, for the tennis, news, volleyball-I and volleyball-II domains, respectively. These values {{led to the}} best overall {{inferential}} results, as {{will be discussed in}} detail in Section 6.4. 1. The developed BN was trained using the Expectation Maximization (EM) approach, while <b>probability</b> <b>propagation</b> was realized using a junction tree mechanism [54].|$|E
40|$|We analyse Gallager codes by {{employing}} a simple mean-field approximation that distorts the model geometry and preserves important interactions between sites. The method naturally recovers the <b>probability</b> <b>propagation</b> decoding algorithm as a minimization of a proper free-energy. We find a thermodynamical phase transition that coincides with information theoretical upper-bounds {{and explain the}} practical code performance {{in terms of the}} free-energy landscape...|$|E
40|$|To {{investigate}} the robustness of {{the output of}} a Bayesian network, a sensitivity analysis can be performed in which {{the relation between the}} output and each of the (probability) parameters of the network is established. This relation is given as a quotient of two linear functions in a parameter under study. Current methods for computing the coefficients of these functions relies on a large number of <b>probability</b> <b>propagations.</b> In this paper, we present a method which only requires a single outward propagation in a junction tree for computing the coefficients associated with all the parameters, in addition to an inward propagation for processing evidence. Conversely, the method also only requires a single outward propagation for computing the coefficients associated with a single parameter and all possible outputs. We show that these results also hold for the analysis of the effects of joint variations of sets of parameters, known as n-way sensitivity analysis...|$|R
3000|$|Phase 2 The Tree Building phase, {{during which}} the nodes are entered {{sequentially}} and the sub-trees are built, <b>propagation</b> <b>probabilities</b> are set, and sub-trees are marked if changed; and [...]...|$|R
40|$|The {{propagation}} of wideband signals through a tropospheric ducting medium is examined analytically. A three layer troposphere {{on a flat}} earth model is employed. By considering only the guided modes a channel model is derived for the ducting medium. The performance of a phase shift keying (PSK) system is analyzed in detail. The dependence of the bit error <b>probability</b> on <b>propagation</b> characteristics is examined...|$|R
40|$|ABSTRACT: The {{uncertainty}} {{evaluation process}} of imperfect experimental data {{is presented in}} this paper. In the process, data neither in steady state nor under normal distribution compared with the conventional assumptions are considered. Results of the evaluation show that the uncertainty is asymmetry to {{the mean of the}} data while symmetry in conventional way. Furthermore, three ways to deal with the uncertainty propagation are discussed, and the <b>probability</b> <b>propagation</b> is simulated by Monte Carlo method. ...|$|E
40|$|This {{project will}} {{address the problem of}} {{estimating}} the shape of an object from estimated surface normals. The surface normals can be estimated for example using multiple images made under different lighting conditions, better known as photometric stereo. We will particulary address the problem of integrability of finite differences of surface at two dimensional grid. We {{will address the}} problem using new techniques for inference by <b>probability</b> <b>propagation</b> across the graphs. Thi...|$|E
40|$|We {{propose a}} model-based {{tracking}} method, called appearance-guided particle filtering (AGPF), which integrates both sequential motion transition information and appearance information. A <b>probability</b> <b>propagation</b> model {{is derived from}} a Bayesian formulation for this framework, and a sequential Monte Carlo method is introduced for its realization. We apply the proposed method to articulated hand tracking, and show that it performs better than methods that only use either sequential motion transition information or only use appearance information. 1...|$|E
30|$|Alshahrani et al. [21] {{proposed}} a new algorithm PrKatz for selection of top-K influential users based on Katz centrality and the <b>propagation</b> <b>probability</b> threshold that permits {{to compute the}} influence over all the paths and select the one that maximizes the influence. The algorithm PrKatz relies {{on the use of}} a combination of Katz centrality and <b>propagation</b> <b>probability</b> threshold tested over each edge for each user in the network. Then top-K influential users are extracted in a decreasing order following the new formulated Katz centrality. Their algorithm outperforms {{the state of the art}} algorithms in term of influence coverage.|$|R
40|$|With the {{explosion}} of smartphones and social network services, location-based social networks (LBSNs) are increasingly seen as tools for businesses (e. g., restaurants and hotels) to promote their products and services. In this article, we investigate the key techniques that can help businesses promote their locations by advertising wisely through the underlying LBSNs. In order to maximize the benefit of location promotion, we formalize it as an influence maximization problem in an LBSN, i. e., given a target location and an LBSN, a set of k users (called seeds) should be advertised initially such that they can successfully propagate and attract many other users to visit the target location. Existing studies have proposed different ways to calculate the information <b>propagation</b> <b>probability,</b> that is, how {{likely it is that}} a user may influence another, in the setting of a static social network. However, it is more challenging to derive the <b>propagation</b> <b>probability</b> in an LBSN since it is heavily affected by the target location and the user mobility, both of which are dynamic and query dependent. This article proposes two user mobility models, namely the Gaussian-based and distance-based mobility models, to capture the check-in behavior of individual LBSN users, based on which location-aware <b>propagation</b> <b>probabilities</b> can be derived. Extensive experiments based on two real LBSN datasets have demonstrated the superior effectiveness of our proposals compared with existing static models of <b>propagation</b> <b>probabilities</b> to truly reflect the information propagation in LBSNs...|$|R
40|$|In {{this work}} an {{overview}} of the potential rock fall source areas and propagation assessment in the Province of Potenza territory has been presented. The rock fall process is characterized by two steps: the detachment of blocks and subsequently their propagation along the slope. The adopted methodology, used {{for the first time in}} the study area, and the software Histofit and FlowR have been very useful tools for the preliminary assessment of rock fall susceptibility at a regional scale, in particular because they have required low data of the study area. Only the DEM may be sufficient together with an appropriate choice of the input parameters and algorithms, that is to say: calculation method, directions algorithm, inertial algorithm and friction loss function. The output of the model is a map of the rock fall source areas, the <b>propagation</b> <b>probabilities</b> and the <b>propagation</b> kinetic energy. The results show that the adopted methodology is successful for the identification of rock fall source areas at a regional scale and the <b>propagation</b> <b>probability</b> obtaining an interesting rock fall susceptibility map...|$|R
