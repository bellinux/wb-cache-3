43|76|Public
2500|$|The name Prolog {{was chosen}} by Philippe Roussel as an {{abbreviation}} for [...] (French for programming in logic). [...] It was created around 1972 by Alain Colmerauer with Philippe Roussel, based on Robert Kowalski's procedural interpretation of Horn clauses. [...] It was motivated {{in part by the}} desire to reconcile the use of logic as a declarative knowledge representation language with the <b>procedural</b> <b>representation</b> of knowledge that was popular in North America in the late 1960s and early 1970s. [...] According to Robert Kowalski, the first Prolog system was developed in 1972 by Colmerauer and Phillipe Roussel. The first implementations of Prolog were interpreters. However, David H. D. Warren created the Warren Abstract Machine, an early and influential Prolog compiler which came to define the [...] "Edinburgh Prolog" [...] dialect which served {{as the basis for the}} syntax of most modern implementations.|$|E
50|$|For example, in CAD/Computer-aided {{manufacturing}} milling applications, an offset {{surface is}} a <b>procedural</b> <b>representation</b> {{because it is}} defined as the surface which is a fixed distance from another surface. Another well-known procedural edge on a 3D body is the silhouette edge. This edge {{is defined as the}} collection of points on a surface whose outwards surface normal is perpendicular to the view vector.|$|E
5000|$|The name Prolog {{was chosen}} by Philippe Roussel as an {{abbreviation}} for [...] (French for programming in logic). It was created around 1972 by Alain Colmerauer with Philippe Roussel, based on Robert Kowalski's procedural interpretation of Horn clauses. It was motivated {{in part by the}} desire to reconcile the use of logic as a declarative knowledge representation language with the <b>procedural</b> <b>representation</b> of knowledge that was popular in North America in the late 1960s and early 1970s. According to Robert Kowalski, the first Prolog system was developed in 1972 by Colmerauer and Phillipe Roussel. The first implementations of Prolog were interpreters. However, David H. D. Warren created the Warren Abstract Machine, an early and influential Prolog compiler which came to define the [...] "Edinburgh Prolog" [...] dialect which served {{as the basis for the}} syntax of most modern implementations.|$|E
25|$|Logic {{programming}} {{in its present}} form {{can be traced back to}} debates in the late 1960s and early 1970s about declarative versus <b>procedural</b> <b>representations</b> of knowledge in Artificial Intelligence. Advocates of declarative representations were notably working at Stanford, associated with John McCarthy, Bertram Raphael and Cordell Green, and in Edinburgh, with John Alan Robinson (an academic visitor from Syracuse University), Pat Hayes, and Robert Kowalski. Advocates of <b>procedural</b> <b>representations</b> were mainly centered at MIT, under the leadership of Marvin Minsky and Seymour Papert.|$|R
40|$|The article {{investigates the}} {{relation}} between declarative and procedural working memory (WM; Oberauer, 2009). Two experiments test the assumption that representations in the two subsystems are selected for processing in analogous ways. Participants carried {{out a series of}} decisions on memorized lists of digits. For each decision, they had to select declarative and <b>procedural</b> <b>representations.</b> Regarding declarative representations, participants selected a memory set and a digit within this set as the input to each decision. With respect to the <b>procedural</b> <b>representations,</b> they selected a task set to be applied to the selected digit and a response within that task set. We independently manipulated the number of lists and the number of tasks to be switched among (one, two, or three; Experiment 1) and preparation time for a list switch (Experiment 2). For three effects commonly observed in task-switch studies, analogues in declarative WM were found: list-switch costs, mixing costs, and residual switch costs. List- and task-switch costs were underadditive, suggesting that declarative and <b>procedural</b> <b>representations</b> are selected separately and in parallel. The findings support the hypothesis of two analogous WM subsystems...|$|R
25|$|The {{fact that}} Horn clauses {{can be given}} a {{procedural}} interpretation and, vice versa, that goal-reduction procedures {{can be understood as}} Horn clauses + backward reasoning means that logic programs combine declarative and <b>procedural</b> <b>representations</b> of knowledge. The inclusion of negation as failure means that logic programming is a kind of non-monotonic logic.|$|R
40|$|Knowledge-representation {{languages}} {{have been}} classified traditionally as declarative or procedural, {{depending on whether}} their basic features come from mathematical logic or data structures on one hand, or from programming languages on the other hand. <b>Procedural</b> <b>representation</b> languages are particularly well suited for heuristic knowledge, and their use can lead to efficient searching {{on the part of}} an expert system. Many {{attempts have been made to}} integrate features of declarative and <b>procedural</b> <b>representation</b> languages. PSN is one attempt that focuses on the integration of semantic network and procedural notion...|$|E
40|$|Abstract. Evolutionary designs {{based upon}} Artificial Ontogenies are {{beginning}} to cross from virtual to real environments. In such systems the evolved genotype is an indirect, <b>procedural</b> <b>representation</b> of the final structure. To date, most Artificial Ontogenies have relied upon an error-free development process to generate their phenotypic structure. In this paper we explore the effects and consequences of developmental error on Artificial Ontogenies. In a simple evolutionary design task, and using an indirect <b>procedural</b> <b>representation</b> that lacks the ability to test intermediate results of development, we demonstrate the emergence of ontogenic mechanisms which are {{able to cope with}} developmental error. ...|$|E
40|$|One of {{the most}} basic {{problems}} in attempting to use computers for architectural applications has been the generation of design alternatives. In order to approach this problem, it is claimed in the paper that in reality it is two basic problems: a methodological problem and a data and <b>procedural</b> <b>representation</b> problem. Diagrammatic Production Rules (DPR's), developed previously by the author, have been proposed for dealing with methodological problem and TM, an object based language, is proposed in the paper for dealing with the data and <b>procedural</b> <b>representation</b> problem. An example of a DPR and a'program'in TM are included to illustrate the relationship between the tw...|$|E
40|$|<b>Procedural</b> <b>representations</b> {{of control}} {{policies}} have two advantages when facing the scale-up problem in learning tasks. First they are implicit, with potential for inductive generalization over {{a very large}} set of situations. Second they facilitate modularization. In this paper we compare several randomized algorithms for learning modular <b>procedural</b> <b>representations.</b> The main algorithm, called Adaptive Representation through Learning (ARL) is a genetic programming extension that relies on the discovery of subroutines. ARL is suitable for learning hierarchies of subroutines and for constructing policies to complex tasks. ARL was successfully tested on a typical reinforcement learning problem of controlling an agent in a dynamic and nondeterministic environment where the discovered subroutines correspond to agent behaviors. Introduction The interaction of a learning system with a complex environment represents an opportunity to discover features and invariant properties of the problem th [...] ...|$|R
40|$|We {{investigate}} interference between declarative and <b>procedural</b> <b>representations</b> {{in working}} memory (WM). Declarative representations are objects of thought, whereas <b>procedural</b> <b>representations</b> provide the (cognitive) actions to work upon these objects. In eight dual-task experiments we varied {{the number of}} representations to be maintained in WM (memory load). In Experiments 1 – 4, we varied declarative and procedural load separately in the two tasks used. In Experiments 5 – 8, only declarative or procedural load was manipulated in both tasks employed. We measured how much performance in the currently relevant task was impaired by increasing the load in the currently irrelevant task. These cross-task load effects were larger for Experiment 5 – 8 compared to Experiment 1 – 4. Yet, in task-switch trials we also obtained cross-task load effects in Experiment 1 – 4. Our findings support the distinction of declarative and procedural WM as largely independent sub-systems or distinct representational spaces...|$|R
40|$|Relatively few evolved designs {{have made}} the {{transition}} to the real world. Of those that have, all have been built by hand based upon descriptive representations (i. e. blueprints) of the evolved object. As such, human effort is transferred from the design to the assembly domain. In this paper we suggest harnessing the <b>procedural</b> <b>representations</b> provided by Artificial Ontogenies to fully automate both design and assembly...|$|R
40|$|Résumé Representation in {{the civil}} {{proceedings}} In my thesis I deal with the representation {{in the civil}} proceedings. The aim of my work is to summarize basic conditions of the <b>procedural</b> <b>representation.</b> The structure of my thesis is divided into five chapters. In the introduction I shortly deal with the basic concepts of the issue, the definition of representation, constitutional background and {{the interpretation of the}} procedural relationship. The second chapter is dedicated to the brief historical overview of the development of <b>procedural</b> <b>representation,</b> in particular in Roman law and the representation under the Act No. 142 / 1950 Coll, on civil proceedings. The third chapter provides with the valid concept of representation pursuant to the Act. No. 99 / 1963 Coll, civil procedure code. I analyze in details elements of each type of <b>procedural</b> <b>representation</b> which I divided in the representation under the law, representation under the decision of a court which is further internally divided into representation with the character of legal representation and representation with the character of representation by agent, and representation under the power of attorney. In the forth chapter I deal with the obligatory representation by the attorney and notary when required by law, especially representation [...] ...|$|E
40|$|Evolutionary designs {{based upon}} Artificial Ontogenies are {{beginning}} to cross from virtual to real environments. In such systems the evolved genotype is an indirect, <b>procedural</b> <b>representation</b> of the final structure. To date, most Artificial Ontogenies have relied upon an error-free development process to generate their phenotypic structure...|$|E
40|$|A recent paper [Hanks 19851 {{examines}} temporal rea-soning as {{an example}} of default reasoning. They conclude that all current systems of default reasoning, including non-monotonic logic, default logic, and circumscription, are inadequate for reasoning about persistence. I present a way of representing persistence in a framework based on a generalization of circumscription, which captures Hanks and McDermott’s <b>procedural</b> <b>representation...</b>|$|E
40|$|Intelligent {{behavior}} for robotic agents requires a careful balance of fast reactions and deliberate consideration of long-term ramifications. The {{need for this}} balance is particularly acute in space applications, where hostile environments demand fast reactions, and remote locations dictate careful management of consumables that cannot be replenished. However, fast reactions typically require <b>procedural</b> <b>representations</b> with limited scope and handling long-term considerations in a general fashion is often computationally expensive. ...|$|R
40|$|This {{course is}} an {{introduction}} to a theory that tries to explain how minds are made from collections of simpler processes. The subject treats such aspects of thinking as vision, language, learning, reasoning, memory, consciousness, ideals, emotions, and personality. Ideas incorporate psychology, artificial intelligence, and computer science to resolve theoretical issues such as whole vs. parts, structural vs. functional descriptions, declarative vs. <b>procedural</b> <b>representations,</b> symbolic vs. connectionist models, and logical vs. common-sense theories of learning...|$|R
40|$|<b>Procedural</b> <b>representations</b> provide {{powerful}} {{means for}} generating complex geometric structures. They are also notoriously difficult to control. In this paper, we present an algorithm for controlling grammar-based procedural models. Given a grammar and a high-level specification {{of the desired}} production, the algorithm computes a production from the grammar that conforms to the specification. This production is generated by optimizing over the space of possible productions from the grammar. The algorithm supports specifications of many forms, including geometric shapes and analytical objectives. We demonstrate the algorithm on procedural models of trees, cities, buildings, and Mondrian paintings...|$|R
40|$|In {{management}} {{theory of}} the last decades, much importance has been attached to a process-oriented perspective on organizational (re) structuring. Yet to date, organizations still experience difficulties in applying this process-oriented perspective to the design and maintenance information systems. The {{root of the problem}} lies with a <b>procedural</b> <b>representation</b> of business processes that contains inadequate information for computer systems to provide flexible automated business process support. The counterpart of a <b>procedural</b> <b>representation</b> is a declarative one that explicitly takes into account the business concerns that govern business processes. Recently, a number of process modeling languages have appeared that could be identified as declarative languages. These modeling languages have very distinct knowledge representation backgrounds, often lack a formal execution model and often only model one aspect of the many business concerns that exist in reality. What is needed are meaningful ways to combine several kinds of expressions, called business rule types, independently of the used methods for knowledge representation and reasoning. In this paper, we present th...|$|E
40|$|In complex, dynamic environments, an agent's domain {{knowledge}} will rarely be complete and correct. Existing deliberate approaches to domain theory correction are signi cantly restricted in the environments {{where they can}} be used. These systems are typically not used in agent-based tasks and rely on declarative representations to support non-incremental learning. This research investigates the use of procedural knowledge to support deliberate incremental error correction in complex environments. We describe a series of domain properties that constrain the error correction process and that are violated by existing approaches. We then present a <b>procedural</b> <b>representation</b> for domain knowledge which is su ciently expressive, yet tractable. We develop a general framework for error detection and correction and then describe an error correction system, IMPROV, that uses our <b>procedural</b> <b>representation</b> to meet the constraints imposed by complex environments. Finally, we test the system in two sample domains and empirically demonstrate that it satis es many of the constraints faced by agents in complex and challenging environments...|$|E
40|$|This paper {{presents}} an analysis conducted on a corpus of software instructions in French {{in order to}} establish whether task structure elements (the <b>procedural</b> <b>representation</b> of the users' tasks) are alone sufficient to control the grammatical resources of a text generator. We show that the construct of genre provides a useful additional source of control enabling us to resolve undetermined cases. Comment: 8 pages, Latex file [...] uses aclap. st...|$|E
40|$|JAM is {{a hybrid}} {{intelligent}} agent architecture that draws upon the theories and {{ideas of the}} Procedural Reasoning System (PRS), Structured Circuit Semantics (SCS), and Act plan interlhtgua. Furthermore, JAM draws upon the implementation pragmatics of the University of Michigan’s and SRI Internatlonal’s implementation of PRS (UMPRS and PRS-CL, respectively). JAM provides rich and extensive plan and <b>procedural</b> <b>representations,</b> metalevel and utility-based reasoning over multiple simultaneous goals, and goal-driven and event-driven behavior that are an amalgam {{of all of the}} sources listed above. The JAM agent architecture also provides an agentGo primitive function utilizing Java’s object serialization mechanism to provide widely-supported mobility capabilities...|$|R
40|$|A new {{taxonomy}} of {{issues related to}} CAD model quality is presented, which distinguishes between explicit and procedural models. For each type of model, morphologic, syntactic, and semantic errors are characterized. The taxonomy was validated successfully when used to classify quality testing tools, which are aimed at detecting and repairing data errors that may affect the simplification, interoperability, and reusability of CAD models. The study shows that low semantic level errors that hamper simplification are reasonably covered in explicit representations, although many CAD quality testers are still unaffordable for Small and Medium Enterprises, {{both in terms of}} cost and training time. Interoperability has been reasonably solved by standards like STEP AP 203 and AP 214, but model reusability is not feasible in explicit <b>representations.</b> <b>Procedural</b> <b>representations</b> are promising, as interactive modeling editors automatically prevent most morphologic errors derived from unsuitable modeling strategies. Interoperability problems between <b>procedural</b> <b>representations</b> are expected to decrease dramatically with STEP AP 242. Higher semantic aspects of quality such as assurance of design intent, however, are hardly supported by current CAD quality testers. This work was supported by the Spanish Ministry of Economy and Competitiveness and the European Regional Development Fund, through the ANNOTAproject (Ref. TIN 2013 - 46036 -C 3 - 1 -R). The authors also wish to thank the editor and reviewers for their valuable comments and suggestions that helped us improve the quality of the paper...|$|R
40|$|In {{explicit}} sequence learning tasks, {{an improvement}} in performance (skill) typically occurs after sleep—leading to the recent literature on sleep-dependent motor consolidation. Consolidation can also be facilitated during wakefulness if declarative knowledge for the sequence is reduced through a secondary cognitive task. Accordingly, declarative and procedural consolidation processes appear to mutually interact. Here we used TMS {{to test the hypothesis}} that functions in the dorsolateral prefrontal cortex (DLPFC) that support declarative memory formation indirectly reduce the formation of <b>procedural</b> <b>representations.</b> We hypothesize that disrupting the DLPFC immediately after sequence learning would degrade the retention or the consolidation of the sequence within the declarative memory system and thus facilitate consolidation within procedural memory systems...|$|R
40|$|The Interactive Electronic Technology Manual is a core {{element of}} the {{equipment}} support, and using in formal means to express automatic reasoning and consistency check ing of knowledge systems {{that can not be}} carried through by process knowledge. This paper, in cognizance of the high frequency of procedure description in IETM, taking troubleshooting process as an example, puts forward a <b>procedural</b> <b>representation</b> based on labeling transition system, and realizes the XML file storage in procedure description. As a result, the machine can read and operate these data. Meanwhile, this paper designs a quantitative calculating method of process semantic proximity to provid e a candidate set of semantic proximity sorting as the result of procedural knowledge retrieval. Compared with existing methods, this method uses status to express the program node information, characterizes change of state by action, and comprehensively considers human-computer interactions. The XML-based <b>procedural</b> <b>representation</b> and storage facilitate interoperability between multiple systems. The formal representation of process knowledge well characterizes the fault diagnosis process in the project of Interactive Electronic Technology Manual. </span...|$|E
40|$|Abstract. In this paper, a novel genetically-inspired visual {{learning}} {{method is}} proposed. Given the training images, this general approach induces a sophisticated feature-based recognition system, by using cooperative coevolution and linear genetic programming for the <b>procedural</b> <b>representation</b> of feature extraction agents. The paper describes the learning algorithm {{and provides a}} firm rationale for its design. An extensive experimental evaluation, on the demanding real-world task of object recognition in synthetic aperture radar (SAR) imagery, shows the competitiveness of the proposed approach with human-designed recognition systems. ...|$|E
40|$|ABSTRACT: This article {{addresses}} the central impediment to the wide-spread {{exploration of the}} potential of Local Composition Control (LCC) in Solid Freeform Fabrication (SFF), and presents a Feature-Based Design (FBD) approach for modeling complex components with LCC. The approach will allow the designer to simultaneously edit geometry and composition until a satisfactory result is attained. The concise and machine-general <b>procedural</b> <b>representation</b> will be maintained throughout the design process and will be evaluated {{for the purpose of}} visual feedback to the designer and for post-processing, i. e., the creation of machine-specific instructions for fabrication. 1...|$|E
40|$|Computer {{programs}} {{are being developed}} to aid the design of physical systems ranging from individual mechanical parts to entire buildings or ships. These efforts highlight the importance of computer models of three dimensional objects. Issues and alternatives in geometric modelling are discussed and illustrated with comparisons of 11 existing modelling systems, in particular coherently-structured models of polyhedral solids where the faces may be either planar or curved. Four categories of representation are distinguished: data representations that store full, explicit shape information, definition languages with which the user can enter description of shapes into the system, and which can constitute <b>procedural</b> <b>representations,</b> special subsets of the information produced by application programs, and conceptual models that define the logical structure of the dada representation and/or definition languag...|$|R
40|$|In {{the present}} study we examine the {{mechanism}} underlying the human ability to implement newly instructed stimulus-response mappings for their future application. We introduce a novel procedure {{in which we can}} investigate the processes underlying such implementation while controlling for more general working-memory demands. The results indicate that a region within the dorso-lateral prefrontal cortex (DLPFC) {{in the vicinity of the}} inferior frontal sulcus (IFS) is specifically recruited when new instructions are implemented compared to when new instructions are memorised. In addition, we observed that this area is more strongly activated when task performance is effective. Together, these findings suggest that the DLPFC, and more specific the IFS, plays an important role during the formation of <b>procedural</b> <b>representations</b> in working memory...|$|R
40|$|Intelligent {{behavior}} for robotic agents requires a careful balance of fast reactions and deliberate consideration of long-term ramifications. The {{need for this}} balance is particularly acute in space applications, where hostile environments demand fast reactions, and remote locations dictate careful management of consumables that cannot be replenished. However, fast reactions typically require <b>procedural</b> <b>representations</b> with limited scope and handling long-term considerations in a general fashion is often computationally expensive. In this paper, we describe three major areas for autonomous systems for space exploration: free-flying spacecraft, planetary rovers, and ground communications stations. In each of these broad applications areas, we identify operational considerations requiring rapid response and considerations of long-term ramifications. We describe these issues {{in the context of}} ongoing efforts to deploy autonomous systems using planning and task execution systems. ...|$|R
40|$|In {{this paper}} I {{will present a}} {{detailed}} ACT-R model of how the task-specific knowledge for a new, complex task is learned. The model is capable of acquiring its knowledge through experience, using a declarative representation that is gradually compiled into a <b>procedural</b> <b>representation.</b> The model exhibits several characteristics that concur with Fitts theory of skill learning, {{and can be used}} to show that individual differences in working memory capacity initially have a large impact on performance, but that this impact diminished after sufficient experience. Some preliminary experimental data support these findings...|$|E
40|$|This article {{addresses}} the central impediment to the wide-spread {{exploration of the}} potential of Local Composition Control (LCC) in Solid Freeform Fabrication (SFF), and presents a Feature-Based Design (FBD) approach for modeling complex components with LCC. The approach will allow the designer to simultaneously edit geometry and composition until a satisfactory result is attained. The concise and machine-general <b>procedural</b> <b>representation</b> will be maintained throughout the design process and will be evaluated {{for the purpose of}} visual feedback to the designer and for post-processing, i. e., the creation of machine-specific instructions for fabrication. 1...|$|E
40|$|We {{propose a}} new {{approach}} to modelling heterogeneous objects containing internal spatial geometric structures with size of details orders of magnitude smaller than the overall size of the object. The proposed function-based <b>procedural</b> <b>representation</b> provides a compact, precise, and arbitrarily parameterized model allowing for modelling coherent microstructures, which can undergo blending, offsetting, deformations, and other geometric operations, and can be directly rendered and fabricated without generating any auxiliary representations. In particular, modelling of regular lattices and porous media is discussed and illustrated. Examples of microstructure models rendering and fabrication using a variety of digital fabrication machines and materials are presented...|$|E
40|$|International audienceCurvature is {{commonly}} employed for enhancing details in textured 3 D models, or to modulate shading at the rendering or compositing stage. However, existing methods that compute curvature in object space rely on mesh-based surfaces {{and work at}} the vertex level. Consequently, they are not well adapted to production-quality models that rely on either subdivision surfaces with displacement and bump maps, or on implicit and <b>procedural</b> <b>representations.</b> In practice they would require a view-dependent scene discretization at each frame, to adapt geometry to visible details and avoid aliasing artifacts. Our approach is independent of both scene complexity and the choice of surface representations since it computes mean curvature from scratch at each frame in screen-space. It works without any pre-process and provides a controllable screen-space scale parameter, which makes it ideal for production requirements, either during rendering or compositing...|$|R
40|$|Evolutionary {{computation}} (EC) {{consists of}} the design and analysis of probabilistic algorithms inspired by the principles of natural selection and variation. Genetic Programming (GP) is one subfield of EC that emphasizes desirable features {{such as the use}} of <b>procedural</b> <b>representations,</b> the capability to discover and exploit intrinsic characteristics of the application domain, and the flexibility to adapt the shape and complexity of learned models. Approaches that learn monolithic representations are considerably less likely to be effective for complex problems, and standard GP is no exception. The main goal of this dissertation is to extend GP capabilities with automatic mechanisms to cope with problems of increasing complexity. Humans succeed here by skillfully using hierarchical decomposition and abstraction mechanisms. The translation of such mechanisms into a general computer implementation is a tremendous challenge, which requires a firm understanding of the interplay between repr [...] ...|$|R
40|$|This paper {{investigates the}} power of first-order {{probabilistic}} logic (FOPL) as a representation language for complex dynamic situations. We introduce a sublanguage of FOPL {{and use it to}} provide a first-order version of dynamic belief networks. We show that this language is expressive enough to enable reasoning over time and to allow <b>procedural</b> <b>representations</b> of conditional probability tables. In particular, we define decision tree representations of conditional probability tables {{that can be used to}} decrease the size of the created belief networks. We provide an inference algorithm for our sublanguage using the paradigm of knowledge-based model construction. Given a FOPL knowledge base and a particular situation, our algorithm constructs a propositional dynamic belief network, which can be solved using standard belief network inference algorithms. In contrast to common dynamic belief networks, the structure of our networks is more flexible and better adapted to the given [...] ...|$|R
