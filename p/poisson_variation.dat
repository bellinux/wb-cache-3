20|27|Public
5000|$|An {{extension}} to this law for small samples {{has been proposed}} by Hanski. For small samples the <b>Poisson</b> <b>variation</b> (P) - the variation that can be ascribed to sampling variation - may be significant. Let S be the total variance and let V be the biological (real) variance. Then ...|$|E
40|$|Tumour {{multiplicity}} is a frequently measured phenotype {{in animal}} studies of cancer biology. <b>Poisson</b> <b>variation</b> of this measurement represents a biological and statistical reference point {{that is usually}} violated, even in highly controlled experiments, owing to sources of variation in the stochastic process of tumour formation. A recent experiment on murine intestinal tumours presented conditions which seem to generate Poisson-distributed tumour counts. If valid, this would support a claim about mechanisms by which the adenomatous polyposis coli gene is inactivated during tumour initiation. In considering hypothesis testing strategies, model choice and Bayesian approaches, we quantify the positive evidence favouring <b>Poisson</b> <b>variation</b> in this experiment. Statistical techniques used include likelihood ratio testing, the Bayes and Akaike information criteria, negative binomial modelling, reversible jump Markov chain Monte Carlo methods and posterior predictive checking. The posterior approximation {{that is based on}} the Bayes information criterion is found to be quite accurate in this small "n" case-study. Copyright 2006 Royal Statistical Society. ...|$|E
40|$|International audienceIt is 100 {{years since}} Gini {{noted that in}} some samples of litters of mice and rabbits, the variances of the {{distributions}} of the combinations of the sexes are sub-binomial. In other words, in contrast with binomial expectation, {{there are too many}} litters in which the sexes are equally balanced, and there are too few unisexual litters. In the intervening years, this finding has been replicated in a number of further species, but no explanation has become established. Potential explanations are reviewed here, and it is suggested that the most likely cause is that, at the time of formation of the zygotes, p, the probability that a zygote will be male, varies from one zygote to another within litters, thus constituting an example of <b>Poisson</b> <b>variation.</b> And it is a standard result in probability theory that such variation causes sub-binomial variance...|$|E
40|$|An 11 hr {{sample of}} air traffic, {{comprising}} 584 tracks recorded at Atlanta during peak periods of August 1967, is analyzed {{to examine the}} statistical characteristics of range-guard intrusions and airspace conflicts in a terminal area. The number of intrusions (of an imaginary 3 -naut mile, 500 -ft range guard surrounding each aircraft) and number of conflicts (of the projected airspace for two aircraft) for a track exhibit <b>Poisson</b> <b>variations</b> with track duration. The hourly rate of intrusions follows the gas model square-law variation with traffic density, but the hourly conflict rate, contrary to the gas model, decreases with greater traffic density...|$|R
40|$|Many cosmological {{models of}} gamma-ray bursts (GRBs) {{assume that a}} single {{relativistic}} shell carries kinetic energy away from the source and later converts it into gamma rays, perhaps by interactions with the interstellar medium or by shocks within the shell. We investigate methods of achieving the observed variability using symmetry. Since our model emphasizes geometric and statistical considerations, rather than the detailed physics of the shell, it is applicable to any theory that relies on relativistic shells. In order to achieve the observed variability in GRBs using a single-shell model, {{we have found that}} the gamma-ray emission must occur from small patches on the shell (entities). We have derived two significant characteristics of the time histories expected from such a model. First, the average number of entities contributing to the signal remains constant throughout much of the time history, although the overall photon flux decreases due to relativistic effects. Second, the "peaks" in a time history can be ascribed to <b>Poisson</b> <b>variations</b> in the actual number of entities contributing to the signal at any given time. Taken together, these properties imply that the relative variations in a GRB (i. e. the heights of the peaks relative to the average envelope of the signal) should remain constant throughout a time history. Comment: 5 pages, latex, to appear in Gamma-Ray Bursts, 4 -th Huntsville Symposium, eds Meegan, Preece, Koshu...|$|R
40|$|The {{distribution}} of the sum of independent nonidentically distributed Bernoulli random vectors inRkis approximated by a multivariate Poisson distribution. By using a multivariate adaption of Kerstan's (1964,Z. Wahrsch. verw. Gebiete 2, 173 - 179) method, we prove a conjecture of Barbour (1988,J. Appl. Probab. 25 A, 175 - 184) on removing a log-term in the upper bound of the total variation distance. Second-order approximations are included. Bernoulli random vectors multivariate <b>Poisson</b> approximation total <b>variation</b> distance...|$|R
40|$|Making {{use of the}} National Travel Survey dataset (NTS) for Great Britain, {{this paper}} {{analyses}} the influence of various socio-economic and accessibility factors on trip rates, and whether these trip rates are stable over time. The motivation of the research was: i. to examine whether the current variables in use within the UK Department for Transport's National Trip End Model (NTEM) are sufficient to explain the observed pattern of variations in trip rates, ii. to provide advice on how NTEM could be improved. Various home based, non home based and escort trip purposes were individually analysed making innovative use of negative binomial regression, a method designed specifically {{for the analysis of}} count data. Negative binomial is an extension to Poisson regression, which can account for greater than <b>Poisson</b> <b>variation</b> and is based on the negative binomial distribution. It has been shown that using Poisson regression for analysing trip rates may overestimate the importance of some of the variables within the model as th...|$|E
40|$|A novel {{exploratory}} {{approach is}} developed {{to the analysis of}} a large table of counts. It uses random-effects models where the cells of the table (representing types of individuals) form the higher level in a multilevel model. The model includes <b>Poisson</b> <b>variation</b> and an offset to model the ratio of observed to expected values thereby permitting the analysis of relative rates. The model is estimated as a Bayesian model through MCMC procedures and the estimates are precision-weighted so that unreliable rates are down-weighted in the analysis. Once reliable rates have been obtained graphical and tabular analysis can be deployed. The analysis is illustrated through a study of the occupational class distribution for people of different age, birthplace-origin and generation in Australia. The case is also made that even where there is a full census {{there is a need to}} move beyond a descriptive analysis to a proper inferential and modelling framework. We also discuss the relative merits of Full and Empirical Bayes approaches to model estimation. 21 page(s...|$|E
40|$|To access {{publisher}} {{full text}} {{version of this}} article. Please click on the hyperlink in Additional Links field. Mutations generate sequence diversity and provide a substrate for selection. The rate of de novo mutations is therefore of major importance to evolution. Here we conduct a study of genome-wide mutation rates by sequencing the entire genomes of 78 Icelandic parent-offspring trios at high coverage. We show that in our samples, with an average father's age of 29. 7, the average de novo mutation rate is 1. 20 [*]×[*] 10 (- 8) per nucleotide per generation. Most notably, the diversity in mutation rate of single nucleotide polymorphisms {{is dominated by the}} age of the father at conception of the child. The effect is an increase of about two mutations per year. An exponential model estimates paternal mutations doubling every 16. 5 [*]years. After accounting for random <b>Poisson</b> <b>variation,</b> father's age is estimated to explain nearly all of the remaining variation in the de novo mutation counts. These observations shed light on the importance of the father's age on the risk of diseases such as schizophrenia and autism...|$|E
40|$|We {{present the}} results of a 200 ks Chandra {{observation}} of part of the Groth Strip region, using the ACIS-I instrument. We present a relatively simple method for the detection of point-sources and calculation of limiting sensitivities, which we argue is at least as sensitive and more self-consistent than previous methods presented in the literature. 158 distinct X-ray sources are included in our point-source catalogue in the ACIS-I area. The number counts show a relative dearth of X-ray sources in this region. For example at a flux limit of 1 E- 15 (cgs) around 20 per cent more soft band sources are detected in the HDF-N and almost 50 per cent more in the ELAIS-N 1 field, which we have analysed by the same method for comparison. We find, however, that these differences are consistent with <b>Poisson</b> <b>variations</b> at 2 sigma significance, and therefore there is no evidence for cosmic variance based on these number counts alone. We determine the average spectra of the objects and find a marked difference between the soft-band selected sources, which have Gamma= 1. 9 typical of unobscured AGN, and the hard-band selected sources, which have Gamma= 1. 0. Reassuringly, the sample as a whole has a mean spectrum of Gamma= 1. 4 ± 0. 1, the same as the X-ray background. Nonetheless, our results imply that the fraction of sources with significant obscuration is only 25 per cent, much less than predicted by standard AGN population synthesis models. This is confirmed by direct spectral fitting, with only a handful of objects showing evidence for absorption. After accounting for absorption, all objects are consistent with mean intrinsic spectrum of Gamma= 1. 76 ± 0. 08, very similar to local Seyferts (abridged) ...|$|R
40|$|Consider a sum of Markov {{dependent}} lattice variables. The normal approximation is trivial {{for this}} sum if the total variation distance is considered. Replacement {{of the normal}} approximation by its Poisson structured analogue changes the situation radically. Moreover, considering the Markov binomial distribution we prove that signed Poisson approximation can be more accurate than both the normal and Poisson approximations. Possible improvements due to asymptotic expansions are discussed. Signed Poisson approximation Compound <b>Poisson</b> law Total <b>variation</b> norm Markov chain...|$|R
40|$|This {{article is}} {{directed}} toward situations where individuals can experience repeated events during an interval of time. A common difficulty when using Poisson and Erlang models is that the estimates of the variance based on the mean/variance structures of the models are often untrustworthy due to overdispersion. In this article a generalized Erlang distribution is described, which introduces parameters that control the variance independently of the mean and generate different degrees of overdispersion. Compound model Exponential distribution Extra-Poisson <b>variation</b> <b>Poisson</b> process Waiting time...|$|R
40|$|This paper {{introduces}} a new framework for modelling the joint development over time of mortality rates {{in a pair}} of related populations with the primary aim of producing consistent mortality forecasts for the two populations. The primary aim is achieved by combining a number of recent and novel developments in stochastic mortality modelling, but these, additionally, provide us with a number of side benefits and insights for stochastic mortality modelling. By way of example, we propose an Age-Period-Cohort model which incorporates a mean-reverting stochastic spread that allows for different trends in mortality improvement rates in the short-run, but parallel improvements in the long run. Second, we fit the model using a Bayesian framework that allows us to combine estimation of the unobservable state variables and the parameters of the stochastic processes driving them into a single procedure. Key benefits of this include dampening down of the impact of <b>Poisson</b> <b>variation</b> in death counts, full allowance for paramater uncertainty, and the flexibility to deal with missing data. The framework is designed for large populations coupled with a small sub-population and is applied to the England & Wales national and Continuous Mortality Investigation assured lives males populations. We compare and contrast results based on the two-population approach with single-population results...|$|E
40|$|Mutations {{generate}} sequence {{diversity and}} provide a substrate for selection. The rate of de novo mutations is therefore of major importance to evolution. We conducted a study of genomewide mutation rate by sequencing the entire genomes of 78 Icelandic parent-offspring trios at high coverage. Here we show that in our samples, with an average father’s age of 29. 7, the average de novo mutation rate is 1. 20 × 10 − 8 per nucleotide per generation. Most strikingly, the diversity in mutation rate of single-nucleotide polymorphism (SNP) {{is dominated by the}} age of the father at conception of the child. The effect is an increase of about 2 mutations per year. After accounting for random <b>Poisson</b> <b>variation,</b> father’s age is estimated to explain nearly all of the remaining variation in the de novo mutation counts. These observations shed light on the importance of the father’s age on the risk of diseases such as schizophrenia and autism. The rate of de novo mutations and factors that influence it have always been a focus of genetics research 1. However, investigations of de novo mutations through direct examinations of parent-offspring transmissions were previously mostly limited to studying specific genes 2, 3 or regions 4 – 7. Recent studies that employed whole genome sequencing 8,...|$|E
40|$|Background: The {{objective}} was to study if an association exists between the incidence of malaria and some weather parameters in tropical Maputo province, Mozambique. Methods: A Bayesian hierarchical model to malaria count data aggregated at district level over a two years period is formulated. This model {{made it possible to}} account for spatial area variations. The model was extended to include environmental covariates temperature and rainfall. Study period was then divided into two climate conditions: rainy and dry seasons. The incidences of malaria between the two seasons were compared. Parameter estimation and inference were carried out using MCMC simulation techniques based on <b>Poisson</b> <b>variation.</b> Model comparisons are made using DIC. Results: For winter season, in 2001 the temperature covariate with estimated value of- 8. 88 shows no association to malaria incidence. In year 2002, the parameter estimation of the same covariate resulted in 5. 498 of positive level of association. In both years rainfall covariate determines no dependency to malaria incidence. Malaria transmission is higher in wet season with both covariates positively related to malaria with posterior means 1. 99 and 2. 83 in year 2001. For 2002 only temperature is associated to malaria incidence with estimated value 2. 23. Conclusions: The incidence of malaria in year 2001, presents an independent spatial pattern for temperature i...|$|E
40|$|The Markov {{binomial}} distribution is approximated by the Poisson distribution {{with the same}} mean, by a translated Poisson distribution and by two-parametric Poisson type signed measures. Using an adaptation of LeÂ Cam's operator technique, estimates of accuracy are proved for the total variation, local and Wasserstein norms. In a special case, asymptotically sharp constants are obtained. For some auxiliary results, we used Stein's method. Markov {{binomial distribution}} Poisson approximation Translated Poisson distribution Signed compound <b>Poisson</b> measure Total <b>variation</b> norm Local norm Wasserstein norm...|$|R
40|$|We {{introduce}} a new method to determine the relative contributions {{of different types of}} stars to the integrated light of nearby early-type galaxies. As is well known, the surface brightness of these galaxies shows pixel-to-pixel fluctuations due to <b>Poisson</b> <b>variations</b> in the number of giant stars. Differential spectroscopy of pixels as a function of fluctuation strength ("fluctuation spectroscopy") effectively measures the spectral variation of stars as a function of their luminosity, information that is otherwise difficult to obtain for individual stars outside of the Local Group. We apply this technique to the elliptical galaxy NGC 4472, using HST/ACS imaging in six narrow-band ramp filters tuned to spectral features in the range 0. 8 - 1. 0 micron. Pixels with +- 5 % broad-band variations show differential color variations of 0. 1 % - 1. 0 % in the narrow-band filters. These variations are primarily due to the systematic increase in TiO absorption strength with increasing luminosity on the upper giant branch. The data are very well reproduced by the same Conroy & van Dokkum (2012) stellar population synthesis model that is the best fit to the integrated light, with residuals in the range 0. 03 % - 0. 09 %. Models with ages or metallicities that are significantly different from the integrated-light values do not yield good fits. We can also rule out several modifications to the underlying model, including the presence of a significant (> 3 % of the light) population of late M giants. The current observations constitute a powerful test of the expected luminosities and temperatures of metal-rich giants in massive early-type galaxies. Studies of pixels with much larger (negative) fluctuations will provide unique information on main sequence stars and the stellar initial mass function. Comment: Accepted for publication in the Astrophysical Journal. 19 pages, 22 figures. Fig. 1 illustrates the concept; Fig. 16 is the key science plo...|$|R
40|$|Stansfield and Carlton [Human Biology 79 : 255 – 260 (2007) ] {{reported}} that the distributions of the combinations of the sexes in human sibships are binomial. They inferred that the probabilities of male births are equal and independent within and across all sibships. Here I argue that their argument is both invalid and false. Contrary to their inference, a binomial distribution may result when equal and counterbalancing measures of <b>Poisson</b> and Lexis <b>variation</b> are simultaneously present. These conditions are approximately met with respect to human births...|$|R
40|$|Abstract Background Assessing the {{reliability}} of experimental replicates (or global alterations corresponding to different experimental conditions) is a critical step in analyzing RNA-Seq data. Pearson’s correlation coefficient r has been widely used in the RNA-Seq field even though its statistical characteristics may be poorly suited to the task. Results Here we present a single-parameter test procedure for count data, the Simple Error Ratio Estimate (SERE), that can determine whether two RNA-Seq libraries are faithful replicates or globally different. Benchmarking shows that the interpretation of SERE is unambiguous regardless of the total read count or the range of expression differences among bins (exons or genes), a score of 1 indicating faithful replication (i. e., samples are affected only by <b>Poisson</b> <b>variation</b> of individual counts), a score of 0 indicating data duplication, and scores > 1 corresponding to true global differences between RNA-Seq libraries. On the contrary the interpretation of Pearson’s r is generally ambiguous and highly dependent on sequencing depth {{and the range of}} expression levels inherent to the sample (difference between lowest and highest bin count). Cohen’s simple Kappa results are also ambiguous and are highly dependent on the choice of bins. For quantifying global sample differences SERE performs similarly to a measure based on the negative binomial distribution yet is simpler to compute. Conclusions SERE can therefore serve as a straightforward and reliable statistical procedure for the global assessment of pairs or large groups of RNA-Seq datasets by a single statistical parameter. </p...|$|E
40|$|RT-qPCR {{is used to}} {{quantify}} minimal residual disease (MRD) in chronic myeloid leukaemia (CML) {{in order to make}} decisions on treatment, but its results depend on the level of BCR-ABL 1 expression as well as leukaemic cell number. The aims of the study were {{to quantify}} inter-individual differences in expression level, to determine the relationship between expression level and response to treatment, and to investigate the effect of expression level on interpretation of the RT-qPCR result. BCR-ABL 1 expression was studied in 248 samples from 65 patients with CML by determining the difference between MRD quantified by RT-qPCR and DNA-qPCR. The results were analysed statistically and by simple indicative modelling. Inter-individual levels of expression approximated a normal distribution with an SD of 0. 36 log. Expression at diagnosis correlated with expression during treatment. Response to treatment, as measured by the number of leukaemic cells after 3, 6 or 12  months of treatment, was not related to the level of expression. Indicative modelling suggested that interpretation of RT-qPCR results in relation to treatment guidelines could be affected by variation in expression when MRD was around 10 % at 3  months and by both expression variation and <b>Poisson</b> <b>variation</b> when MRD was around or below the limit of detection of RT-qPCR. Variation between individuals in expression of BCR-ABL 1 can materially affect interpretation of the RT-qPCR when this test is used to make decisions on treatment. Susan Latham, Paul A Bartley, Bradley Budgen, David M Ross, Elizabeth Hughes, Susan Branford, Deborah White, Timothy P Hughes, Alexander A Morle...|$|E
40|$|A second {{international}} {{collaborative study}} on bacteriophages in bathing waters was organised in March 1998. Fifteen European laboratories (including the organising laboratory) {{participated in the}} study. It consisted of two parts: (1) Analysis of naturally polluted standard samples for the enumeration of somatic coliphages (SOMCPH), F-specific phages (including {{the total number of}} the F-specific phages, FTOTPH, and the F-specific DNA phages, FDNAPH) as well as phages of Bacteroides fragilis (BFRPH); (2) Application of a concentration technique (based on flocculation) to a mixture of phage reference materials (oX 174 for SOMCPH, MS 2 for FTOTPH and B 40 - 8 for BFRPH). In agreement with the participating laboratories, some of the data were excluded for further analysis because of technical problems in several laboratories. Analysis of the remaining data for the part of the study dealing with the naturally polluted standard samples resulted in values for the repeatability (r) varying from 1. 63 - 2. 34, and for the reproducibility (R) from 3. 10 - 5. 72 for the different groups of bacteriophages. The variation in these results was greater than those in which reference materials (with pure cultures of standard phages) were analysed. This was probably caused by a combination of extra <b>Poisson</b> <b>variation</b> in phage numbers in naturally polluted standard samples and the difficulties of interpreting plates of natural samples. Analysis of the results from the concentration technique showed low recovery of phage oX 174 (2. 2 % - 16. 4 %), and variable recovery of phages MS 2 (12. 7 % - 99. 4 %) and B 40 - 8 (42. 5 % - 142. 9 %) ...|$|E
40|$|Let [xi] 1, [xi] 2, [...] . be a {{sequence}} of independent identically distributed lattice variables, E[xi] 12 +[delta] x [infinity], Sn = [xi] 1 + [xi] 2 + Â·Â·Â· + [xi]n. The classical approach is to approximate the distribution of Sn by the normal law. We show that for a suitably centered Sn the Poisson approximation also can be applied. Moreover, this approximation holds for all Borel sets which is impossible for the normal distribution. The rate of accuracy is determined by Ibragimov's necessary and sufficient conditions. <b>Poisson</b> approximation Total <b>variation</b> norm Integer centering...|$|R
40|$|Abstract. We {{propose a}} new variational model to denoise an image {{corrupted}} by Poisson noise. Like the ROF model described in [1] and [2], {{the new model}} uses total-variation regularization, which preserves edges. Unlike the ROF model, our model uses a data-fidelity term that is suitable for Poisson noise. The {{result is that the}} strength of the regularization is signal dependent, precisely like Poisson noise. Noise of varying scales will be removed by our model, while preserving low-contrast features in regions of low intensity. Keywords: image reconstruction, image processing, image denoising, total <b>variation,</b> <b>Poisson</b> noise, radiograph...|$|R
40|$|Under very mild conditions, we {{prove that}} the number of {{components}} in a decomposable logarithmic combinatorial structure has a distribution which is close to <b>Poisson</b> in total <b>variation.</b> The conditions are satisfied for all assemblies, multisets and selections in the logarithmic class. The error in the Poisson approximation is shown under marginally more restrictive conditions to be of exact order O 1 / log n, by exhibiting the penultimate asymptotic approximation; similar results have previously been obtained by Hwang [20], under stronger assumptions. Our method is entirely prob-abilistic, and the conditions can readily be verified in practice...|$|R
40|$|Aims: Traditionally, roadway safety {{analyses}} {{have used}} univariate distributions to model crash data for {{each level of}} severity separately. This paper uses the multivariate Poisson lognormal (MVPLN) models to estimate the expected crash frequency by two levels of severity and then compares those estimates with the univariate Poisson-lognormal (UVPLN) and the univariate Poisson (UVP) models. Materials and Methods: The parameters estimation is done by Bayesian method for crash data at two levels of severity {{at the intersection of}} Isfahan city for 6 months. Results: The results showed that there was over-dispersion issue in data. The UVP model is not able to overcome this problem while the MVPLN model can account for over-dispersion. Also, the estimates of the extra <b>Poisson</b> <b>variation</b> parameters in the MVPLN model were smaller than the UVPLN model that causes improvement in the precision of the MNPLN model. Hence, the MVPLN model is better fitted to the data set. Also, results showed effect of the total Average annual daily traffic (AADT) on the property damage only crash was significant in the all of models but effect of the total left turn AADT on the injuries and fatalities crash was significant just in the UVP model. Hence, holding all other factors fixed more property damage only crashes were expected on more the total AADT. For example, under MVPLN model an increase of 1000 vehicles in (average) the total AADT was predicted to result in 31 % more property damage only crash. Conclusion: Hence, reduction of total AADT was predicted to be highly cost-effective, in terms of the crash cost reductions over the long run...|$|E
40|$|The Gamma-Ray Burst (GRB) 021211 {{detected}} by the High Energy Transient Explorer (HETE) II had a simple light-curve in the x-ray and gamma-ray energy bands containing one peak and little temporal fluctuation {{other than the}} expected <b>Poisson</b> <b>variation.</b> Such a burst offers the best chance for a unified understanding of the gamma-ray burst and afterglow emissions. We provide a detailed modeling of the observed radiation from GRB 021211 both during the burst and the afterglow phase. The consistency between early optical emission (prior to 11 minutes), which presumably comes from reverse shock heating of the ejecta, and late afterglow emission from forward shock (later than 11 minutes) requires the energy density in the magnetic field in the ejecta, expressed as fraction of the equipartition value or ǫB, to be larger than the forward shock at 11 minutes {{by a factor of}} about 10 3. We find that the only consistent model for the gamma-ray emission in GRB 021211 is the synchrotron radiation in the forward shock; to explain the peak flux during the GRB requires ǫB in forward shock at deceleration to be larger than the value at 11 minutes by a factor of about 10 2. These results suggest that the magnetic field in the reverse shock and early forward shock is most likely frozen-in-field from the explosion, and therefore a large fraction of the energy in the explosion was initially stored in magnetic field. We can {{rule out the possibility that}} the ejecta from the burst for GRB 021211 contained more than 10 electron-positron pairs per proton. Subject headings: gamma-rays: bursts, theory, methods: analytical – radiation mechanisms: non-thermal- shock waves 1...|$|E
40|$|Abstract Background The {{objective}} was to study if an association exists between the incidence of malaria and some weather parameters in tropical Maputo province, Mozambique. Methods A Bayesian hierarchical model to malaria count data aggregated at district level over a two years period is formulated. This model {{made it possible to}} account for spatial area variations. The model was extended to include environmental covariates temperature and rainfall. Study period was then divided into two climate conditions: rainy and dry seasons. The incidences of malaria between the two seasons were compared. Parameter estimation and inference were carried out using MCMC simulation techniques based on <b>Poisson</b> <b>variation.</b> Model comparisons are made using DIC. Results For winter season, in 2001 the temperature covariate with estimated value of - 8. 88 shows no association to malaria incidence. In year 2002, the parameter estimation of the same covariate resulted in 5. 498 of positive level of association. In both years rainfall covariate determines no dependency to malaria incidence. Malaria transmission is higher in wet season with both covariates positively related to malaria with posterior means 1. 99 and 2. 83 in year 2001. For 2002 only temperature is associated to malaria incidence with estimated value 2. 23. Conclusions The incidence of malaria in year 2001, presents an independent spatial pattern for temperature in summer and for rainfall in winter seasons respectively. In year 2002 temperature determines the spatial pattern of malaria incidence in the region. Temperature influences the model in cases where both covariates are introduced in winter and summer season. Its influence is extended to the summer model with temperature covariate only. It is reasonable to state that with the occurrence of high temperatures, malaria incidence had certainly escalated in this year. </p...|$|E
40|$|We {{present a}} new scheme of {{defining}} invariant observables for general relativistic systems. The scheme {{is based on}} the introduction of an observer which endowes the construction with a straightforward physical interpretation. The observables are invariant with respect to spatial diffeomorphisms which preserve the observer. The limited residual spatial gauge freedom is studied and fully understood. A full canonical analysis of the observables is presented: we analyze their <b>variations,</b> <b>Poisson</b> algebra and discuss their dynamics. Lastly, the observables are used to solve the vector constraint, which triggers a possible considerable reduction of the degrees of freedom of general relativistic theories. Comment: 33 pages, 1 figur...|$|R
40|$|This {{research}} models {{the geographic}} variation in lead poisoning among {{children living in}} Massachusetts between 1990 and 1991. Elevated levels of blood lead, which reduce educational performance, arise because children are exposed to unnaturally concentrated sources of lead in the built environment. A Poisson regression model indicates {{that a large number}} of children with lead poisoning may be detected in towns with a high proportion of older housing, female headed households, African-Americans, and an industrial heritage. Our results suggest links between the processes of urbanization and industrialization in Massachusetts and today's lead poisoned landscapes. lead poisoning community scale <b>variation</b> <b>Poisson</b> regression Massachusetts industrial heritage...|$|R
40|$|A bivariate Poisson shock model {{resulting}} from two devices receiving shocks from two independent sources {{is shown to}} preserve certain bivariate dependent structures such as total positivity of order 2 (TP 2), stochastic increasing (SI), right tail increasing (RTI) etc. However, when two devices are subjected to the same source of shocks it is observed through a counter example {{that some of these}} preservation results do not hold any more. In such cases sufficient conditions are given under which the bivariate random vector denoting the life lengths of two devices is shown to have the above-mentioned bivariate dependent structures. Bivariate homogeneous <b>Poisson</b> shock models <b>Variation</b> diminishing property Stochastic increasing Right tail increasing Left tail decreasing Positively quadrant dependent...|$|R
40|$|In two-child {{families}} containing {{at least}} one boy, the expected probability that such a family has two boys is 1 / 3, provided that the boy/girl (B/G) ratio is 1. 0 and the population to which they belong has a binomial distribution of BB, (BG + GB), and GG families. It is commonly known that in most human populations the sex ratio at birth (i. e., {{the ratio of the}} number of boys to the number of girls) is greater than 1. 0. Teachers and textbook writers seldom discuss the more realistic expected distributions in populations where the sex ratio is greater than 1. 0. We present data from two federal surveys with sex ratios greater than 1. 0 and find that the observed proportions of two boys in families of size 2 with {{at least one}} boy range from 0. 3335 to 0. 3941. It has been reported in the literature that the probability (p) of a male birth is subject to both within-sibship variation (<b>Poisson</b> <b>variation),</b> for which our data are suggestive, and possibly also between-sibship variation (Lexis variation). These deviations (biases) from the assumptions of a simple binomial distribution are involved in the calculation of values of p and standard 95 % confidence intervals, thereby foiling attempts to make reliable statistical inferences from the data. Analysis of the data is also complicated by family planning that falsifies the assumption of randomness in the binomial gender distribution model. Families of size 2 (and their sex composition) are often discussed in a wider context. Overpopulation {{in some parts of the}} world has caused mass starvation and threatens to do the same worldwide unless the birth rate drops to agriculturally sustainable levels. Even if every woman of fertile age has only two children on average from now on, the world’s population is predicted to continue growing toward 9 billion people by 2050. Other sociological problems are bound to follow. Although the birth rate in China has recently dropped, the average age of the population has risen, so that by 2035 it is projected that for each person over age 65 there will be just three working-age people. Furthermore, China’s one-child policy has already led to a sex imbalance where there is a large excess of men for whom marriage and parentage is denied...|$|E
40|$|In {{numerous}} intervention {{studies and}} education field trials, random assignment to treatment occurs in clusters {{rather than at}} the level of observation. This departure of random assignment of units may be due to logistics, political feasibility, or ecological validity. Data within the same cluster or grouping are often correlated. Application of traditional regression techniques, which assume independence between observations, to clustered data produce consistent parameter estimates. However such estimators are often inefficient as compared to methods which incorporate the clustered nature of the data into the estimation procedure (Neuhaus 1993). 1 Multilevel models, also known as random effects or random components models, can be used to account for the clustering of data by estimating higher level, or group, as well as lower level, or individual variation. Designing a study, in which the unit of observation is nested within higher level groupings, requires the determination of sample sizes at each level. This study investigates the design and analysis of various sampling strategies for a 3 -level repeated measures design on the parameter estimates when the outcome variable of interest follows a Poisson distribution. ^ Results study suggest that second order PQL estimation produces the least biased estimates in the 3 -level multilevel Poisson model followed by first order PQL and then second and first order MQL. The MQL estimates of both fixed and random parameters are generally satisfactory when the level 2 and level 3 variation is less than 0. 10. However, as the higher level error variance increases, the MQL estimates become increasingly biased. If convergence of the estimation algorithm is not obtained by PQL procedure and higher level error variance is large, the estimates may be significantly biased. In this case bias correction techniques such as bootstrapping should be considered as an alternative procedure. For larger sample sizes, those structures with 20 or more units sampled at levels with normally distributed random errors produced more stable estimates with less sampling variance than structures with an increased number of level 1 units. For small sample sizes, sampling fewer units at the level with <b>Poisson</b> <b>variation</b> produces less sampling variation, however this criterion is no longer important when sample sizes are large. ^ 1 Neuhaus J (1993). “Estimation efficiency and Tests of Covariate Effects with Clustered Binary Data”. Biometrics, 49, 989 – 996...|$|E
40|$|Abstract Background Several {{criteria}} {{have been}} used to assess agreement between replicate slide readings of malaria parasite density. Such criteria may be based on percent difference, or absolute difference, or a combination. Neither the rationale for choosing between these types of criteria, nor that for choosing the magnitude of difference which defines acceptable agreement, are clear. The current paper seeks a procedure which avoids the disadvantages of these current options and whose parameter values are more clearly justified. Methods and Results Variation of parasite density within a slide is expected, even when it has been prepared from a homogeneous sample. This places lower limits on sensitivity and observer agreement, quantified by the Poisson distribution. This means that, if a criterion of fixed percent difference criterion is used for satisfactory agreement, the number of discrepant readings is over-estimated at low parasite densities. With a criterion of fixed absolute difference, the same happens at high parasite densities. For an ideal slide, following the Poisson distribution, a criterion based on a constant difference in square root counts would apply for all densities. This can be back-transformed to a difference in absolute counts, which, as expected, gives a wider range of acceptable agreement at higher average densities. In an example dataset from Tanzania, observed differences in square root counts correspond to a 95 % limits of agreement of - 2, 800 and + 2, 500 parasites/μl at average density of 2, 000 parasites/μl, and - 6, 200 and + 5, 700 parasites/μl at 10, 000 parasites/μl. However, there were more outliers beyond those ranges at higher densities, meaning that actual coverage of these ranges was not a constant 95 %, but decreased with density. In a second study, a trial of microscopist training, the corresponding ranges of agreement are wider and asymmetrical: - 8, 600 to + 5, 200 /μl, and - 19, 200 to + 11, 700 /μl, respectively. By comparison, the optimal limits of agreement, corresponding to <b>Poisson</b> <b>variation,</b> are ± 780 and ± 1, 800 parasites/μl, respectively. The focus of this approach on the volume of blood read leads to other conclusions. For example, no matter how large a volume of blood is read, some densities are too low to be reliably detected, which in turn means that disagreements on slide positivity may simply result from within-slide variation, rather than reading errors. Conclusions The proposed method defines limits of acceptable agreement in a way which allows for the natural increase in variability with parasite density. This includes defining the levels of between-reader variability, which are consistent with random variation: disagreements within these limits should not trigger additional readings. This approach merits investigation in other settings, in order to determine both the extent of its applicability, and appropriate numerical values for limits of agreement. </p...|$|E
40|$|This paper uses data {{collected}} by a consultant paediatrician to examine variations in the prevalence of neural tube and cardiovascular malformations within the Fylde region of North West England. Results at the district scale indicate contrasts in the geographical distributions of the two classes of malformation and these are then further assessed via a case-control study which standardises for factors such as date of conception, age of mother and parity. The {{results of this study}} suggest that there were wards in Blackpool and Fleetwood with unusually high prevalences of neural tube defects. Further research is being undertaken to identify the causes of these concentrations. congenital malformations prevalence geographical <b>variations</b> <b>Poisson</b> probabilities case- control study...|$|R
40|$|Poisson {{approximation}} {{in total}} variation can be successfully established {{in a wide}} variety of contexts, involving sums of weakly dependent random variables which usually take the value 0, and occasionally the value 1. If the random variables can take other positive integer values, or if there is stronger dependence between them, compound Poisson approximation may be more suitable. Stein's method, which is so effective in the Poisson context, turns out to be much more difficult to apply for compound Poisson approximation, because the solutions of the Stein equation have undesirable properties. In this paper, we prove new bounds on the absolute values of the solutions to the Stein equation and of their first differences, over certain ranges of their arguments. These enable compound Poisson approximation in total variation to be carried out with almost the same efficiency as in the Poisson case. Even for sums of independent random variables, which have been exhaustively studied in the past, new results are obtained, effectively solving a problem discussed by Le Cam (1965, Bernoulli, Bayes, Laplace. Springer, New York, pp. 179 - 202), in the context of nonnegative integer valued random variables. Stein's method Compound <b>Poisson</b> Total <b>variation...</b>|$|R
50|$|In {{the systems}} {{described}} so far, {{it has been}} assumed that the occupation of a site or bond is completely random—this is the so-called Bernoulli percolation. For a continuum system, random occupancy corresponds to the points being placed by a <b>Poisson</b> process. Further <b>variations</b> involve correlated percolation, such as percolation clusters related to Ising and Potts models of ferromagnets, in which the bonds are put down by the Fortuin-Kasteleyn method. In bootstrap or k-sat percolation, sites and/or bonds are first occupied and then successively culled from a system if a site does not have at least k neighbors. Another important model of percolation, in a different universality class altogether, is directed percolation, where connectivity along a bond depends upon {{the direction of the}} flow.|$|R
