347|822|Public
50|$|The Nikon Expeed {{is based}} on the Socionext Milbeaut imaging {{processors}} with 16-bit per pixel multi-core FR-V processor architecture, using a highly parallel <b>pipelined</b> <b>architecture</b> which allows efficient hardware use, increasing throughput and reducing power consumption. Each core uses an eight-way 256-bit very long instruction word (VLIW, MIMD) and is organized in a four-unit superscalar <b>pipelined</b> <b>architecture</b> (Integer (ALU)-, Floating-point- and two media-processor-units) giving a peak performance of up to 28 instructions per clock cycle and core. Due to the used four-way single instruction, multiple data (SIMD) vector processor units, data is processed with up to 112 data operations per cycle and core.|$|E
50|$|The Bellmac 32 has a <b>pipelined</b> <b>architecture</b> with an {{instruction}} fetch unit that serves to control access to main memory, and an execution unit which serves {{to monitor the}} process and manipulate data.|$|E
50|$|Solace Virtual Message Router {{software}} provides {{message routing}} and persistence functionality. The VMR features a multi-threaded, parallel <b>pipelined</b> <b>architecture,</b> optimized for modern multi-core processor architectures {{so it can}} scale {{in proportion to the}} number of processor cores.|$|E
3000|$|The {{processing}} latency on parallel {{applications in}} such <b>pipeline</b> <b>architecture</b> {{depends on the}} execution time of the slowest pipeline stage. Consequently, the processing time for the proposed <b>pipeline</b> <b>architecture</b> {{is equal to the}} execution time of the first stage [...]...|$|R
5000|$|C V Ramamoorthy and Hon Fung Li. <b>Pipeline</b> <b>Architecture.</b> ACM Comput. Surv. (...) , 9(1):61-102, 1977.|$|R
5000|$|Elimination of {{the cost}} of a branch misprediction which can be high on deeply <b>pipelined</b> <b>architectures.</b>|$|R
50|$|The pipelined {{datapath}} is {{the most}} commonly used datapath design in microarchitecture today. This technique is used in most modern microprocessors, microcontrollers, and DSPs. The <b>pipelined</b> <b>architecture</b> allows multiple instructions to overlap in execution, much like an assembly line. The pipeline includes several different stages which are fundamental in microarchitecture designs. Some of these stages include instruction fetch, instruction decode, execute, and write back. Some architectures include other stages such as memory access. The design of pipelines is one of the central microarchitectural tasks.|$|E
50|$|The {{goal of a}} <b>pipelined</b> <b>architecture</b> is to {{complete}} an instruction every clock cycle. To maintain this rate, the pipeline must be full of instructions at all times. The branch delay slot is {{a side effect of}} pipelined architectures due to the branch hazard, i.e. the fact that the branch would not be resolved until the instruction has worked its way through the pipeline. A simple design would insert stalls into the pipeline after a branch instruction until the new branch target address is computed and loaded into the program counter. Each cycle where a stall is inserted is considered one branch delay slot. A more sophisticated design would execute program instructions which are not dependent on the result of the branch instruction. This optimization can be performed in software at compile time by moving instructions into branch delay slots in the in-memory instruction stream, if the hardware supports this. Another side effect is that special handling is needed when managing breakpoints on instructions as well as stepping while debugging within branch delay slot.|$|E
40|$|Current {{techniques}} used in pipelining recursive filters require high hardware complexity. These techniques attempt {{to preserve the}} exact frequency response of the original circuit while seeking to construct a <b>pipelined</b> <b>architecture.</b> We present a technique that relaxes the need to preserve the exact frequency response and instead considers a least-squares formulation {{in conjunction with the}} <b>pipelined</b> <b>architecture.</b> The benefit of this design is that it reduces the complexity of the pipelined circuit immensely, while enabling a simple <b>pipelined</b> <b>architecture</b> based on a polyphase decomposition of the original filter...|$|E
40|$|In this paper, {{efficient}} <b>pipelined</b> <b>architectures</b> for {{the implementation}} of the Transform Domain LMS algorithm, are presented. Pipelining of the TD-LMS algorithm is achieved byintroducing an amountoftime delayinto the original adaptivescheme. The adaptation delayintroduced to the TD-LMS algorithm allows for the development of <b>pipelined</b> <b>architectures.</b> By retiming the delays existing in the error feedbackloop, two efficient pipelined implementations of the delayed TD-LMS algorithm are developed...|$|R
40|$|The {{majority}} of existing language generation systems have a <b>pipeline</b> <b>architecture</b> which offers efficient sequential execution of modules, {{but does not}} allow decisions about text content to be revised in later stages. However, as exemplified in this paper, in some cases choosing appropriate content can depend on text length and formatting, which in a <b>pipeline</b> <b>architecture</b> are determined after content planning is completed. Unlike pipelines, interleaved and revision-based architectures can deal with such dependencies but {{tend to be more}} expensive computationally. Since our system needs to generate acceptable hypertext explanations reliably and quickly, the <b>pipeline</b> <b>architecture</b> was modified instead to allow additional content to be requested in later stages of the generation process if necessary. ...|$|R
5000|$|MIPS M6200 and M6250 cores (MIPS32 Release 6): six-stage <b>pipeline</b> <b>architecture,</b> microMIPS ISA, {{dedicated}} DSP and SIMD module ...|$|R
40|$|We {{propose a}} {{heuristic}} {{for the construction}} of variable-stride multibit tries. These multibit tries are suitable for one-dimensional packet classification using a <b>pipelined</b> <b>architecture.</b> The variable-stride tries constructed by our heuristic require significantly less per-stage memory than required by optimal pipelined fixed-stride tries. We also develop a tree packing heuristic, which dramatically reduces per-stage memory required by fixed- and variable-stride multibit tries constructed for <b>pipelined</b> <b>architecture...</b>|$|E
40|$|Abstract — In this paper, a novel tool (System Generator for DSP) from Xilinx {{has been}} used to {{implement}} LMS algorithm for System Identification in Matlab Simulink. The Algorithm has been implemented using a <b>pipelined</b> <b>architecture</b> to increase throughput of the system without incrementing multipliers. The system fairly models the desired patterns to recognize it adequately. Additionally, a timeline diagram is also provided to visualize the <b>pipelined</b> <b>architecture...</b>|$|E
30|$|Getting {{the insight}} from the FPGA architecture, 16 DFPA {{butterflies}} arranged in an array topology {{are used to}} compute FFT up to 2, 048 points, instead of the <b>pipelined</b> <b>architecture</b> used in the conventional FFT processor. In <b>pipelined</b> <b>architecture,</b> one butterfly is employed for one stage of computation and the hardware utilization of a pipelined processor is not 100 % except for the higher FFT points. But in this methodology, all the butterflies are used even for small FFT size.|$|E
40|$|In this paper, {{based on}} word-serial <b>pipeline</b> <b>architecture,</b> a new {{efficient}} distributed arithmetic (NEDA) technique is introduced. This architecture increases {{the speed and}} reduced the time of 2 -D discrete wavelet transform (DWT). In this design, word-serial <b>pipeline</b> <b>architecture</b> able to compute a complete 2 -D discrete wavelet transforms (DWT) binary tree in an on-line fashion, and easily configurable in order to compute any required 2 -D DWT sub tree is proposed. In this architecture, free of ROM, multiplication and subtraction, 9 high-pass and 7 low-pass NEDA techniques are used concurrently. The proposed NEDA architecture is 30 % faster than compare the exiting architecture and 27 % reduced the area. The word-serial <b>pipelines</b> <b>architecture</b> has 100 % hardware utilization efficiency...|$|R
40|$|Abstract—To {{meet the}} performance, area and power require-ment {{constraints}} of H. 264 /AVC, we propose a hybrid <b>pipeline</b> <b>architecture,</b> and a data reuse mechanism to reduce off-chip memory access. A 4 x 4 sub-macroblock <b>pipeline</b> <b>architecture</b> is optimized for low power {{as well as}} performance. The proposed H. 264 /AVC decoder architecture can support CIF(352 × 288) 30 fps videos at 6 MHz with 1. 8 mW @ 1. 65 V, implemented in 0. 18 um technology. I...|$|R
40|$|Multiresolution pyramid {{techniques}} {{can improve the}} efficiency of basic vision algorithms by orders of magnitude. They will be key to developing practical vision systems to perform challenging tasks in real time. However, these efficiencies cannot be fully realized when pyramid-based algorithms are implemented on machines with conventional SIMD mesh and <b>pipeline</b> <b>architectures.</b> We describe a segmented <b>pipeline</b> <b>architecture</b> that can support pyramid processing. We illustrate this architecture with an application to image motion analysis for vehicle guidance...|$|R
40|$|Abstract—In this paper, {{we develop}} a {{parallel}} {{structure for the}} time-delay neural network used in some speech recognition applications. The effectiveness of the design is illustrated by 1) extracting a window computing model from the time-delay neural systems; 2) building its <b>pipelined</b> <b>architecture</b> with parallel or serial processing stages; and 3) applying this parallel window computing to some typical speech recognition systems. An analysis {{of the complexity of}} the proposed design shows a greatly reduced complexity while maintaining a high throughput rate. Index Terms—Parallel computing, <b>pipelined</b> <b>architecture,</b> timedelay neural networks, speech recognition. characteristics of such neural speech recognition systems. A model for time-delay window computing and its corresponding architecture definition are described in Section II. Two kinds of processing stages used in <b>pipelined</b> <b>architecture</b> and their building elements are explained in Section III. In Section IV, some mapping strategies from window computing model into systolic array structures are defined. Three typical speech recognition applications and their performance analysis by parallel window computing are given in Sections V and VI, respectively. A brief conclusion is included in Section VII. I...|$|E
30|$|So, as to {{maximize}} {{the performance of the}} system and to exploit the inherent parallelism on the programmable device selected for the implementation we chose a <b>pipelined</b> <b>architecture,</b> able to process a pixel every clock cycle.|$|E
40|$|A new <b>pipelined</b> <b>architecture</b> for {{autonomous}} and semiautonomous space robotics {{systems is}} described. The architecture uses new concepts which significantly facilitate the overall system performance {{and leads to}} an effective functional partitioning between base and remote parts of the system. The base system {{which is based on}} a set of parameterized primitives, provides detailed planning and the remote site provides final command binding and resource management. The primitives are then directed to the intelligent manipulation controllers that perform the required manipulation. A proof-of-principle implementation at the JPL Telerobotic laboratory demonstrated the practical efficiency of the <b>pipelined</b> <b>architecture</b> in the context of supervised autonomous robotics operations...|$|E
40|$|<b>Pipeline</b> <b>architecture</b> with {{parallel}} multipliers and adders speeds {{calculation of}} weighted sums. Picture-element values and partial sums flow through delay-adder modules. After each cycle or time unit of calculation, each value in filter moves one position right. Digital integrated-circuit chips with <b>pipeline</b> <b>architecture</b> rapidly move 35 X 35 two-dimensional convolutions. Need for such circuits in image enhancement, data filtering, correlation, pattern extraction, and synthetic-aperture-radar image processing: all require repeated calculations of weighted sums of values from images or two-dimensional arrays of data...|$|R
40|$|Providing {{ground command}} {{software}} for constellations of spacecraft is a challenging problem. Reliable command delivery requires a feedback loop; for a constellation there {{will likely be}} an independent feedback loop for each constellation member. Each command must be sent via the proper Ground Station, which may change from one contact to the next (and may be different for different members). Dynamic configuration of the ground command software is usually required (e. g. directives to configure each member's feedback loop and assign the appropriate Ground Station). For testing purposes, {{there must be a}} way to insert command data at any level in the protocol stack. The <b>Pipeline</b> <b>architecture</b> described in this paper can support all these capabilities with a sequence of software modules (the pipeline), and a single self-identifying message format (for all types of command data and configuration directives). The <b>Pipeline</b> <b>architecture</b> is quite simple, yet it can solve some complex problems. The resulting solutions are conceptually simple, and therefore, reliable. They are also modular, and therefore, easy to distribute and extend. We first used the <b>Pipeline</b> <b>architecture</b> to design a CCSDS (Consultative Committee for Space Data Systems) Ground Telecommand system (to command one spacecraft at a time with a fixed Ground Station interface). This pipeline was later extended to include gateways to any of several Ground Stations. The resulting pipeline was then extended to handle a small constellation of spacecraft. The use of the <b>Pipeline</b> <b>architecture</b> allowed us to easily handle the increasing complexity. This paper will describe the <b>Pipeline</b> <b>architecture,</b> show how it was used to solve each of the above commanding situations, and how it can easily be extended to handle larger constellations...|$|R
5000|$|Fixed {{pipelines}} {{are being}} {{done away with}} in favor of fully programmable pipelines (often referred to as unified <b>pipeline</b> <b>architecture),</b> which can be programmed to emulate the same.|$|R
40|$|<b>Pipelined</b> <b>architecture</b> for S-Box is {{proposed}} in this paper. ROM based look-up table implementation of S-Box requires more memory and introduce unbreakable delay for its access. Pipelined S-Box of combinational logic based implementation gives higher throughput and less delay {{as compared to}} that of no pipelined S-Box. 5, 6 and 7 stages of <b>pipelined</b> <b>architecture</b> has been simulated using Xilinx 9. 2 i for SPARTAN- 3 FPGA. The result from Place and Route reports shows increase in maximum clock frequency at the cost of increased number of used slices. However the total delay calculated for the SubByte substitution for large amount of data is reduced considerably...|$|E
30|$|The Virtex- 4 SX 55 is a high-resource FPGA {{that allowed}} for the {{implementation}} of the FFT blocks without a resource-optimized design, hence a <b>pipelined</b> <b>architecture</b> was used allowing for continuous data processing. However, the Virtex-II V 2000 is resource limited, which forced us to optimize the FEC design.|$|E
40|$|The Question Answering (QA) {{track in}} the Text Retrieval Conferences (TREC) is {{designed}} to foster development of techniques for answering questions from an open topic domain. Systems submitted for the track display {{a wide variety of}} implementation techniques, but also a central theme in a modular <b>pipelined</b> <b>architecture...</b>|$|E
5000|$|MIPS M5100 and MIPS M5150 cores (MIPS32 Release 5): five-stage <b>pipeline</b> <b>architecture,</b> microMIPS ISA, the MIPS DSP Module r2, fast {{interrupt}} handling, advanced debug/profiling {{capabilities and}} power management.|$|R
30|$|Weidong and Wanhammar [14] {{proposed}} an pipeline ASIC for pipeline FFT processor. Here we prove {{our discussion in}} Section 3, the <b>pipeline</b> <b>architecture</b> have a higher throughput but loss on power efficiency.|$|R
5000|$|Proliferation of mass-market {{software}} {{meant that}} programmers {{would not want}} to compile for a specific pipeline structure. The algorithm can function with any <b>pipeline</b> <b>architecture</b> and thus software requires few architecture-specific modifications.|$|R
40|$|The Viterbi Algorithm for {{decoding}} convolutional {{codes and}} Trellis Coded Modulation is suited to VLSI implementation but contains a feedback loop which limits {{the speed of}} <b>pipelined</b> <b>architecture.</b> The feedback loop is circumvented by decoding independent sequences simultaneously, resulting in a 5 - 9 fold speed-up with a two-fold hardware expansion...|$|E
40|$|The main {{objective}} {{of this paper is}} to design and implement the VLSI architecture for Mixed Radix FFT. This architecture is proposed for memory based Fast Fourier transform (FFT) to support less memory size and area reduction. The <b>pipelined</b> <b>architecture</b> would cost more area and power than memory based architecture...|$|E
40|$|Abstract — A Novel super-pipelined Architecture {{including}} viterbi algorithm {{for implementation}} of {{fast fourier transform}} (FFT) Processors for multiple-input multiple-output Orthogonal frequency division multiplexing (MIMO-OFDM) systems. The super <b>pipelined</b> <b>architecture</b> is capable of achieving high throughput in an area efficient manner. A <b>pipelined</b> <b>architecture</b> is proposed to realize the Viterbi algorithm for moderate speed applications. This architecture can effectively reduce the silicon area necessary for the VLSI implementation of the Viterbi algorithm with the large constraint length. The existing system is a variable length FFT processor for MIMO-OFDM based SDR systems in which butterfly diagram is used in every stage of internal processing. So it will increase the processing time at result it will reduce the speed and take memory to store the each value in butterfly process. Finally it increases the memory size. It consists of only pipelined architectures. A reduce...|$|E
40|$|Analog-to-Digital {{converters}} (ADC) are key {{building blocks}} of analog and mixed-signal processing that link the natural world of analog signals {{and the world of}} digital processing. This work describes the analysis, design, development and test of novel high-resolution (≥ 12 -bit), moderate speed (10 - 100 MS/s), energy-efficient ADCs. Such ADCs are typically used for communication, imaging and video applications. CMOS process scaling is typically aimed at enabling fast, low-power digital circuits. Scaling leads to lower supply voltages, and to short channel devices with low gain and poor matching between small devices. On the other hand, to process and amplify analog signals analog circuits rely on wide signal swing, large transistor gain and good component matching. Hence, analog circuit performance has lagged far behind digital performance. Analog circuits such as ADCs are therefore nowadays performance bottlenecks in many electronic systems. The pipeline ADC is a popular architecture for implementing ADCs {{with a wide range of}} speed and resolution. This work aims to improve the accuracy and energy efficiency of the <b>pipeline</b> <b>architecture</b> by combining it with more accurate or more energy efficient architectures such as Sigma-Delta and Successive-Approximation (SAR). Such novel, hybrid architectures are investigated in this work. In the first design, a new architecture is developed which combines a low-OSR resetting Sigma-Delta modulator <b>architecture</b> with the <b>pipeline</b> <b>architecture.</b> This architecture enhances the accuracy and energy efficiency of the <b>pipeline</b> <b>architecture.</b> A prototype 14 -bit 23 MS/s ADC, based on this new architecture, is designed and tested. This ADC achieves calibration-free 14 -bit linearity, 11. 7 -bit ENOB and 87 dB SFDR while dissipating only 48 mW of power. In the second design, new hybrid architecture based on SAR and <b>pipeline</b> <b>architecture</b> is developed. This architecture significantly improves the energy efficiency of the <b>pipeline</b> <b>architecture.</b> A prototype 12 -bit 50 MS/s ADC is designed based on this new architecture. “Half-gain” and “half-reference” pipeline stages are also introduced in this prototype for the first time to further reduce power dissipation. This ADC dissipates only 3. 5 mW power...|$|R
50|$|RESTHeart {{inherits}} {{the same}} Undertow's <b>pipeline</b> <b>architecture,</b> where specialized handlers are chained together {{to serve the}} requests. In order to provide additional application logic, custom handlers can be bound under the /_logic URL.|$|R
50|$|The main {{features}} of the MCS-296 family is 50 MHz operation, MCS-96 compatibility, <b>pipeline</b> <b>architecture,</b> 6 MB addressable space, 2 KB code/data RAM, 40-bit accumulator, fast hardware multiplier and accumulator, and 512 Byte register RAM.|$|R
