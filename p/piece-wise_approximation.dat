10|89|Public
50|$|They {{have also}} {{recently}} {{been used in}} a method (advanced by Valve Corporation) to render smooth fonts at large sizes (or alternatively at high DPI) using GPU acceleration. Valve's method computed signed distance fields in raster space {{in order to avoid}} the computational complexity of solving the problem in the (continuous) vector space. More recently <b>piece-wise</b> <b>approximation</b> solutions have been proposed (which for example approximate a Bézier with arc splines), but even this way the computation can be too slow for real-time rendering, and it has to be assisted by grid-based discretization techniques to approximate (and cull from the computation) the distance to points that are too far away.|$|E
40|$|A {{model for}} the motor-unit action-potential train is developed, based on {{previously}} obtained empirical information. The auto and cross-correlation functions are calculated. The autocorrelation function is used to derive the mean rectified value. the variance and the root-mean-squared value of a motor-unit action-potential train. These parameters are solved by using two approximations for the motor-unit action-potential; a <b>piece-wise</b> <b>approximation</b> and 'a Dirac Delta function approximation. The Dirac Delta function. approximation sufficiently simplifies the mathematics so that the model can be extended to myoelectric signals. The cross-correlation function contains information about the synchronization of motor unit action-potential trains that may be useful as an objective indicator of muscle fatigue. ...|$|E
40|$|Abstract: It is {{well known}} that energy {{balancing}} control is stymied by the presence of pervasive dissipation. To overcome this problem in electrical circuits, the authors recently proposed the alternative paradigm of power shaping—where, as suggested by its name, stabilization is achieved shaping a function akin to power instead of the energy function. In this paper we extend this technique to general nonlinear systems and apply it for the stabilization of the benchmark tunnel diode circuit. It is shown that, in contrast with other techniques recently reported in the literature, e. g. <b>piece–wise</b> <b>approximation</b> of nonlinearities, power shaping yields a simple linear static state feedback that ensures (robust) global asymptotic stability of the desired equilibrium. Copyright c© 2006 IFA...|$|E
50|$|The {{efficient}} algorithm for minimization {{is based on}} <b>piece-wise</b> quadratic <b>approximation</b> of subquadratic growth (PQSQ).|$|R
40|$|Abstract:- A new {{algorithm}} for {{the estimation}} of probability density functions has been considered in the paper. This founds {{a large number of}} applications in the context of statistical signal processing problems, such as detection, estimation, filtering or pattern recognition and classification. The proposed approach relies on the QQ-plot technique. The estimates of the first and second order statistics of the observed random data are used together with a suboptimal <b>piece-wise</b> linear <b>approximation</b> of the QQ-plot, yielding a new class of pdfs estimators. The feasibility of the proposed approach is demonstrated by simulations. With respect to the obtained results, this approach provides better or comparable results related to the other commonly used techniques. Key-Words:- qq-plot technique, probability density function estimation, <b>piece-wise</b> linear <b>approximation...</b>|$|R
40|$|Abstract. We {{consider}} piecewise polynomial nite elements {{method for}} a singular perturbation problem. The nite elements method of [9] for {{a problem with}} non-constant coecients was adapted by introducing <b>piece-wise</b> polynomial <b>approximation.</b> We generate the tridiagonal dierence schemes which are second order accurate in uniform norm. 1...|$|R
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references. Issued also on microfiche from Lange Micrographics. This thesis describes a <b>piece-wise</b> <b>approximation</b> of transient current response of the digital BiCMOS gate. Based on the detailed transient analysis of the conventional digital BiCMOS gate, a new circuit model for digital BiCMOS gate is derived which is very useful in characterizing the current response of the BiCMOS gate. By the new circuit model, the piece-wise current response expression is derived which shows good agreement with SPICE simulation...|$|E
40|$|Abstract. The {{histogram}} {{method is}} a very classical test technique for Analog to Digital Converters (ADCs), but only used for external testing {{because of the large}} amount of required hardware resources. This paper discusses the viability of a BIST implementation for this technique. An original approach is developed that permits to extract the ADC parameters with a reduced area overhead. This approach involves (i) the calculation of the parameters using approximations and (ii) the decomposition of the global test in a code-after-code test procedure. These two features allow a significant reduction of the required operative resources and memory dedicated to the storage of experimental data. In addition, the use of a <b>piece-wise</b> <b>approximation</b> for computing the ideal histogram also permits to minimize the memory dedicated to the storage of reference data...|$|E
40|$|Let z be a {{stochastic}} exponential, i. e., z_t= 1 +∫_ 0 ^tz_s-dM_s, {{of a local}} martingale M with jumps M_t>- 1. Then z is a nonnegative local martingale with z_t< 1. If z_T= 1, then z is a martingale on {{the time}} interval [0,T]. Martingale property {{plays an important role}} in many applications. It is therefore of interest to give natural and easy verifiable conditions for the martingale property. In this paper, the property z__T= 1 is verified with the so-called linear growth conditions involved in the definition of parameters of M, proposed by Girsanov Girs. These conditions generalize the Beneŝ idea, Benes, and avoid the technology of <b>piece-wise</b> <b>approximation.</b> These conditions are applicable even if Novikov, Novikov, and Kazamaki, Kaz, conditions fail. They are effective for Markov processes that explode, Markov processes with jumps and also non Markov processes. Our approach is different to recently published papers CFY and MiUr. Comment: 26 page...|$|E
40|$|The paper {{discusses}} the numerico-analytical {{features of a}} <b>piece-wise</b> surface-fit <b>approximation</b> used in Contemporary exact computer-oriented calculation procedures for subsonic potential fiow past aerodynamic configurations. The approximation does not demand continuity with adjacent surface patches but is still able to predict aerodynamic characteristics accurately with significant reduction in computer time...|$|R
40|$|A Galerkin's {{finite element}} {{approach}} based on weighted-residual formulation {{is presented to}} find approximate solutions to obstacle, unilateral and contact second-order boundary-value problems. The approach utilizes a <b>piece-wise</b> linear <b>approximations</b> utilizing linear Langrange polynomials. Numerical studies have shown the superior accuracy and lesser computational cost of this scheme in comparison to collocation, finite-difference and spline methods...|$|R
40|$|The paper {{shows the}} {{elementary}} {{use of a}} computer algebra system (CAS) to avoid the algebraic complexities involved in extending <b>piece-wise</b> linear <b>approximations</b> to parabolic ones and points the way forward to spline or to Taylor series approximations. The discussion encourages students to view function values as outputs from possibly complex algorithms rather than simple algebraic formulae...|$|R
40|$|Filtering non-terrain {{points from}} raw laser {{scanning}} data {{is the most}} important goal to improve productivity in DTM generation. Filtering algorithms are built on assumptions about what discriminates terrain points from points on other objects (e. g. buildings and vegetation). In most cases, a single measure is used to accept or reject points. In this paper a three-stage raw data classification algorithm is presented. After a preliminary interpolation to a grid, a region growing based on height differences is applied. Segments from the region growing are classified as terrain, building or vegetation, based on their geometric and topological description. Terrain grid cells are conditionally low-pass filtered, to remove low vegetation. A <b>piece-wise</b> <b>approximation</b> of the terrain surface is computed, built from the grid cells classified as terrain. Finally, raw data are accepted as terrain within a given distance from the surface. Results obtained on a ISPRS filter test data set are shown to illustrate the effectiveness of the procedure. 1...|$|E
40|$|Distributed {{computation}} of Voronoi {{cells in}} sensor networks, i. e. computing {{the locus of}} points in a sensor field closest to a given sensor, is a key building block that supports a number of applications in both the data and control planes. For example, knowledge of Voronoi cells facilitates efficient methods for computing the <b>piece-wise</b> <b>approximation</b> of a field, whereby each sensor acts as a representative for the set of points in its Voronoi cell; awareness of Voronoi boundaries and Voronoi neighbors is also useful in load balancing and energy conservation. The methods currently advocated for distributed Voronoi computation in sensor networks are heuristic approximations that can introduce significant inaccuracies {{that are difficult to}} rigorously quantify; we demonstrate that these methods may err by a factor of 5 or more in some circumstances. We present and prove an exact method which eliminates these inaccuracies, at the cost of increased messaging overhead, but without necessitating contact with the entire network. To our knowledge, this is the first distributed algorithm that computes accurate Voronoi cells without requiring all-to-all communication. We implement it as a TinyOS module and quantitatively analyze its performance...|$|E
40|$|Widespread {{adoption}} of structural control systems {{has been limited}} by the perception that systems might prove to be unreliable over their operational life spans. To address this concern, a novel decentralized control implementation that is responsive to actuation failures is proposed. Termed energy market-based control (EMBC), a control system is modeled as a free market economy where actuators act as market buyers and system energy supplies are modeled as market sellers. At every time step, each market participant simultaneously optimizes their respective utility functions resulting in a Pareto optimal control solution. As a <b>piece-wise</b> <b>approximation</b> of a dynamic optimization control solution, such as centralized linear quadratic regulation (LQR), energy market-based control is responsive {{to changes in the}} underlying system including possible failures in the initial actuation configuration. To illustrate the robustness of the EMBC control solution to actuation failures, a 20 -story benchmark structure controlled by semi-active variable dampers is selected. Using cost functions as measures of optimality, changes in cost function final values are tracked during scenarios of failed actuation configurations for both an LQR and EMBC controller. Based on cost function changes, the EMBC control solution is shown to be responsive to failed actuators resulting in greater solution reliability...|$|E
40|$|A surface {{reconstruction}} algorithm {{takes as}} input {{a set of}} sample points from an unknown closed and smooth surface in 3 -d space, and produces a <b>piece-wise</b> linear <b>approximation</b> of the surface that contains the sample points. Recently, several algorithms with a correctness guarantee have been proposed. They have unfortunately a worst-case running time that is quadratic {{in the size of}} the input because they are based on the construction of 3 -d Voronoi diagrams or Delaunay tetrahedrizations which can have quadratic size. In this paper, we describe a new algorithm that also has a correctness guarantee but whose worst-case running time is ¢¤£¦¥¨§�©���¥� � where ¥ is the input size. This is actually optimal. As in some of the previous algorithms, the <b>piece-wise</b> linear <b>approximation</b> produced by the new algorithm is a triangulation which is a subset of the 3 -d Delaunay tetrahedrization. ...|$|R
40|$|The {{well known}} {{chemical}} equilibrium problem {{is expressed in}} the form of minimizing the free energy of a mixture in order to compute the chemical composition at equilibrium. By <b>piece-wise</b> linear <b>approximations</b> to the free energy function, the problem becomes a linear program which can be solved by a standard code on a computing machine. Successive approximations give any degree of accuracy. ...|$|R
40|$|Due {{to their}} {{simplicity}} {{and ease of}} handling quadrarcs {{have been used to}} provide a <b>piece-wise</b> circular <b>approximation</b> to ellipses for many hundreds of years. Like biarcs there are many possible criteria for choosing joint positions between the arcs. This paper provides an alge-braic formulation of 10 of these quadrarc constructions. For a range of ellipse eccentricities these quadrarcs are assessed quantitatively in terms of Euclidean distance error and tangent discontinuity...|$|R
40|$|Abstract Sensor nodes {{are small}} devices that “measure” their {{environment}} and communicate feeds of low-level data values to a base station for further processing and archiv-ing. Dissemination of these multi-valued feeds is challeng-ing {{because of the}} limited resources (processing, bandwidth, energy) available in the nodes of the network. In this pa-per, we first describe the SBR algorithm for compressing multi-valued feeds containing historical data from each sen-sor. The key to our technique is the base signal, a series of values extracted from the real measurements {{that is used to}} provide <b>piece-wise</b> <b>approximation</b> of the measurements. While our basic technique exploits correlations among mea-surements taken on a single node, we further show how it can be adapted to exploit correlations among multiple nodes in a localized setting. Sensor nodes may form clusters and, within a cluster, a group leader identifies and coalesces sim-ilar measurements taken by different nodes. This localized mode of operation further improves the accuracy of the ap-proximation, typically by a factor from 5 to 15. We pro-vide detailed experiments of our algorithms and make direct comparisons against standard approximation techniques like Wavelets, Histograms and the Discrete Cosine Transform, on a variety of error metrics and for real data sets from dif-ferent domains...|$|E
40|$|Applications of mesh {{adaption}} techniques {{could be}} found in the numerical solution of PDE’s or in the optimal triangulation of surfaces for shape represen-tation or graphic display. The scope of this work is to verify through numerical experiments the effectiveness of some algorithms for the control of the L ∞ error norm for <b>piece–wise</b> linear <b>approximation</b> on 2 D unstructured triangular meshes. The analysis could be extended to parametric surfaces and to the 3 D case...|$|R
40|$|In this paper, {{we discuss}} the {{numerical}} approximation of a distributed optimal control problem governed by the von Karman equations, defined in polygonal domains with point-wise control constraints. Conforming finite elements are employed to discretize the state and adjoint variables. The control is discretized using <b>piece-wise</b> constant <b>approximations.</b> A priori error estimates are derived for the state, adjoint and control variables under minimal regularity assumptions on the exact solution. Numerical results that justify the theoretical results are presented...|$|R
40|$|This thesis {{investigates the}} {{application}} of Dynamic Pricing strategies at a manufacturer of continuous replenishment perishable goods. I begin {{with a discussion of}} Dynamic Pricing models, and select a mixed integer programming formulation as most applicable to the available systems and data of the target company. Cost formulations are built through a detailed analysis of current cost allocations within the company and actual costs when available. Revenue and price elasticity models are built from existing formulations. The continuous functions are then discretized through <b>piece-wise</b> <b>approximations</b> and input into a mixed integer program using production and pricing as the decision variables. The results were not entirely conclusive as sensitivity around the base values, particularly the price elasticity value, can create very different price path solutions. Greater stability is achieved through tightening the price ranges, but the suggested policy of always charging the maximum allowable price is not practical within the company's existing policies. For actual implementation, a much more thorough understanding of the price elasticity mechanism would be required. by William M. Driegert. Thesis (M. Eng. in Logistics) [...] Massachusetts Institute of Technology, Engineering Systems Division, 2003. Includes bibliographical references (leaves 63 - 64) ...|$|R
40|$|Abstract: A {{class of}} semi-recursive kernel type {{estimates}} of functions depending on multivariate density functionals and their derivatives is considered. The <b>piece-wise</b> smoothed <b>approximations</b> of these estimates are proposed. The convergence with probability {{one of the}} estimates is proved. The main parts of the asymptotic mean square errors of the estimates are found. The examples of estimation of the production function, the marginal productivity and the marginal rate of technical substitution of inputs are given. Copyright c © 2007 IFA...|$|R
40|$|In {{this paper}} {{we present a}} novel and {{efficient}} depthimage representation and warping technique based on a <b>piece-wise</b> linear <b>approximation</b> of the depth-image as a textured and simplified triangle mesh. We describe {{the application of a}} hierarchical triangulation method to generate view-dependent triangulated depth-meshes efficiently from reference depth-images, and propose a new hardware accelerated depth-image rendering technique that supports per-pixel weighted blending of multiple depth-images in real-time. Applications of our technique include imagebased object representations and the use of depth-images in large scale walk-through visualization systems...|$|R
3000|$|... l 0 -norm {{minimization}} in {{the context}} of <b>piece-wise</b> constant function <b>approximation,</b> which indeed their adaptation to the problem of sparse linear prediction analysis can be beneficial (particularly the stepwise jump penalization algorithm, which is shown to be highly efficient and reliable in detection of sparse events).|$|R
40|$|Kink-pair {{generation}} in three-fold screw dislocations in the bcc lattice is investigated {{within the framework}} of the generalised Peierls-Nabarro model. Using a <b>piece-wise</b> plane strain <b>approximation,</b> the apparent activation energy is predicted to vary with stress in a parabolic manner which is in good agreement with experimental findings. link_to_subscribed_fulltex...|$|R
40|$|We {{present the}} first exact {{simulation}} method for multidimensional reflected Brownian motion (RBM). Exact simulation {{in this setting}} is challenging {{because of the presence}} of correlated local-time-like terms in the definition of RBM. We apply recently developed so-called ε-strong simulation techniques (also known as Tolerance-Enforced Simulation) which allow us to provide a <b>piece-wise</b> linear <b>approximation</b> to RBM with ε (deterministic) error in uniform norm. A novel conditional acceptance/rejection step is then used to eliminate the error. In particular, we condition on a suitably designed information structure so that a feasible proposal distribution can be applied...|$|R
40|$|We {{reduce a}} problem of pricing {{continuously}} monitored defaultable securities (barrier options, corporate debts) in a stochastic interest rate framework to calculations of boundary crossing probabilities (BCP) for Brownian Motion (BM) with stochastic boundaries. In the case when the interest rate is governed by a linear stochastic equation (Vasicek model) we suggest a numerical algorithm for calculation of BCP based on a <b>piece-wise</b> linear <b>approximation</b> for the stochastic boundaries. We also find an estimation of the rate of convergence of the suggested approximation and illustrate results by numerical examples...|$|R
40|$|XCSF is an {{extension}} of XCS in which classier prediction is computed as a linear combination of classier inputs and a weight vector associated to each classier. XCSF can adjust the weight vector of classiers to evolve accurate piecewise linear approximations of functions. The Widrow-Ho rule, used to update the weight vectors, prevents (when some conditions hold) XCSF from exploiting the expected <b>piece-wise</b> linear <b>approximation.</b> In this paper we replace the Widrow-Ho rule with linear least-squares and we show that with this improvement XCSF can fully exploit its general-ization capabilities...|$|R
40|$|We {{reduce the}} problem of pricing {{continuously}} monitored defaultable securities (namely, barrier type options, corporate debts) under a stochastic interest rate framework to calculations of boundary crossing probabilities (BCP) for Brownian Motion (BM) with stochastic boundaries. For the case when the interest rate is governed by linear stochastic equation (Vasicek model) we suggest a numerical algorithm for calculation of BCP based on a <b>piece-wise</b> linear <b>approximation</b> for the stochastic boundaries. We also provide an estimation for a rate of convergence of the suggested approximation {{as a function of}} number of nodes and illustrate the results by numerical examples. ...|$|R
40|$|This thesis {{analyzes}} {{usage data}} from nanoHUB. org, {{which is a}} web-based infrastructure for e-collaboration among nanotechnology simulation community. Previous analysis of nanoHUB database showed he nanoHUB usage data follows an unknown, heavy-tailed distributions. This thesis extends the analysis and develops an automatic anomaly detection method based on <b>piece-wise</b> linear <b>approximation.</b> The anomaly here refers to collective user behaviors different from others. The result shows that the method can accurately detect the anomalies in the unknown, heavily detailed distribution. This thesis also applies anomaly detection method and principal component analysis to other databases in nanoHUB and successfully reveals differences between different categories...|$|R
40|$|A new {{algorithm}} {{based on}} a nonlinear programming technique to correct the geometrical distortions of one digital image with respect to another is discussed. This algorithm promises to be superior to existing ones {{in that it is}} capable of treating localized differential scaling, translational and rotational errors over the whole image plane. A series of <b>piece-wise</b> 'rubber-sheet' <b>approximations</b> are used, constrained in such a manner that a smooth approximation over the entire image can be obtained. The theoretical derivation is included. The result of using the algorithm to register four channel S 065 Apollo IX digitized photography over Imperial Valley, California, is discussed in detail...|$|R
40|$|For {{reducing}} {{impulsive noise}} without degrading image contours, median filtering {{is a powerful}} tool. In multiband images, as for example color images or vector fields obtained by optic flow computation, a vector median filter can be used. Vector median filters are defined {{on the basis of}} a suitable distance, the best performing distance being the Euclidean. Euclidean distance is evaluated by using the Euclidean norm which is quite demanding from the point of view of computation given that a square root is required. In this paper an optimal <b>piece-wise</b> linear <b>approximation</b> of the Euclidean norm is presented which is applied to vector median filterin...|$|R
40|$|In {{this paper}} we {{consider}} {{a fragment of}} the first-order theory of the real numbers that includes systems of equations of continuous functions in bounded domains, and for which all functions are computable {{in the sense that}} it is possible to compute arbitrarily close <b>piece-wise</b> interval <b>approximations.</b> Even though this fragment is undecidable, we prove that there is a (possibly non-terminating) algorithm for checking satisfiability such that (1) whenever it terminates, it computes a correct answer, and (2) it always terminates when the input is robust. A formula is robust, if its satisfiability does not change under small perturbations. As a basic tool for our algorithm we use the notion of degree from the field of (differential) topology. ...|$|R
40|$|The Fourier Modal Method (FMM, {{also called}} the Rigorous Coupled Wave Analysis, RCWA) is a {{numerical}} discretization method which {{is often used to}} calculate a scattered field from a periodic diffraction grating. For 1 D periodic gratings in FMM the electromagnetic field is presented by a truncated Fourier series expansion {{in the direction of the}} grating periodicity. The grating’s material properties are assumed to be piece-wise constant (called slicing), and next per slice the scattered field is approximated by a truncated Fourier series expansion. The truncation representation of the scattered field and the <b>piece-wise</b> constant <b>approximation</b> of the grating’s material properties cause the error in FMM. This paper presents an analytical estimate/bound for the FMM error caused by slicing...|$|R
40|$|We analyze {{dynamical}} {{properties of}} a "gap-tent map" - {{a family of}} 1 D maps with a symmetric gap, which mimics the presence of noise in physical realizations of chaotic systems. We demonstrate that the dependence of the topological entropy {{on the size of}} the gap has a structure of the devil's staircase. By integrating over a fractal measure, we obtain analytical, <b>piece-wise</b> differentiable <b>approximations</b> of this dependence. Applying concepts of the kneading theory we find the position and the values of the entropy for all leading entropy plateaus. Similar properties hold also for the dependence of the fractal dimension of the invariant set and the escape rate. Comment: 20 pages in LaTex + 3 figures in ps, submitted to Physica...|$|R
