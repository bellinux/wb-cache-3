4708|3928|Public
5|$|By {{moving the}} pan-tilt {{units of the}} laser range finders, it is also {{possible}} to obtain a <b>point</b> <b>cloud</b> in three dimensions. Technical readjustment between the model of the aircraft and the scene <b>point</b> <b>cloud</b> is already used in navigation to estimate the static placement of the robot. It is planned to make targeted acquisitions, simpler in terms of movement, to verify the absence of chocks in front of the landing gear wheels, or the proper closing of engine cowling latches.|$|E
5|$|Near the aircraft, a <b>point</b> <b>cloud</b> {{in three}} {{dimensions}} is acquired by changing {{the orientation of the}} laser scanning sensors fixed on pan-tilt units. After filtering data to remove floor- or insufficiently large dot clusters, a registration technique with the model of the aircraft is used to estimate the static orientation of the robot. The robot moves and holds this orientation by considering its wheel odometry, its inertial unit and visual odometry.|$|E
25|$|This form of data {{manipulation}} allows for rapid computer visualisation and analysis, with data presented as <b>point</b> <b>cloud</b> data with additional information, such as each ion's mass to charge (as computed from the velocity equation above), voltage or other auxiliary measured quantity or computation therefrom.|$|E
30|$|Outlier removal {{outside the}} bundle {{adjustment}} in completely built SfM <b>point</b> <b>clouds</b> {{has not been}} addressed explicitly before. However, there are some approaches designed for laser-scanned <b>point</b> <b>clouds.</b> Such clouds are usually more accurate and consist of a higher number of points. We believe, nevertheless, that the principles of outlier removal in laser-scanned <b>point</b> <b>clouds</b> also work for SfM <b>point</b> <b>clouds</b> and, therefore, review here some approaches designed for laser-scanned <b>point</b> <b>clouds.</b>|$|R
30|$|The {{problem of}} outlier removal in photogrammetric <b>point</b> <b>clouds</b> {{in the context}} of image-guided {{localization}} has not been studied exhaustively before. This study encourages using outlier removal in the applications, where matching time and storage requirements are important constraints for usage. Within our study, two approaches initially designed for <b>point</b> <b>clouds</b> generated with a laser scanner have been implemented and shown applicable for photogrammetric <b>point</b> <b>clouds,</b> too. Hence, we assume that our distance-based approach designed and tested with photogrammetric <b>point</b> <b>clouds</b> is also applicable for laser-scanned <b>point</b> <b>clouds.</b>|$|R
40|$|Over {{the past}} few years, <b>point</b> <b>clouds</b> have {{attracted}} attention as a new shape model, {{because they can be}} easily created using 3 D-digitizers, which have seen rapid development lately. Correspondingly, there has been an increase in research on <b>point</b> <b>clouds</b> in the field of CG and CAD. Generally, <b>point</b> <b>clouds</b> include many noises and defects. Therefore, it’s so difficult to apply existing CG methods for polygon mesh to <b>point</b> <b>clouds</b> such as rendering, modeling, visualization, etc. This paper introduces one of my research works of geometry reconstruction for <b>point</b> <b>clouds</b> modeling...|$|R
25|$|Typically {{the sweep}} takes the simple {{form of an}} {{advancement}} of the surface, such that the surface is expanded in a symmetric manner about its advancement axis, with the advancement rate set by a volume attributed to each ion detected and identified. This causes the final reconstructed volume to assume a rounded-conical shape, similar to a badminton shuttlecock. The detected events thus become a <b>point</b> <b>cloud</b> data with attributed experimentally measured values, such as ion time of flight or experimentally derived quantities, e.g. time of flight or detector data.|$|E
50|$|There {{are many}} {{techniques}} for converting a <b>point</b> <b>cloud</b> to a 3D surface. Some approaches, like Delaunay triangulation, alpha shapes, and ball pivoting, build {{a network of}} triangles over the existing vertices of the <b>point</b> <b>cloud,</b> while other approaches convert the <b>point</b> <b>cloud</b> into a volumetric distance field and reconstruct the implicit surface so defined through a marching cubes algorithm.|$|E
5000|$|Optionally, the {{received}} disparity map {{is projected}} into a 3d <b>point</b> <b>cloud.</b> By utilising the cameras' projective parameters, the <b>point</b> <b>cloud</b> can be computed {{such that it}} provides measurements at a known scale.|$|E
40|$|We {{propose a}} new {{technique}} for enhancing high frequency geometric features and geometric texture for scatter <b>point</b> <b>clouds.</b> We generalize the classical High-Boost filtering of signal and image processing to the geometric feature manipulation for 3 D <b>point</b> <b>clouds.</b> We get a smoothed version of the input <b>point</b> <b>clouds</b> by Adaptive Moving Least Squares (MLS) based <b>point</b> <b>clouds</b> smoothing operator. The distance fields between the <b>point</b> <b>clouds</b> and their corresponding smoothed version are regarded as the high frequency geometric features and geometric textures intuitively. High Boost operations are performed by iteratively updating {{the position of the}} input points along the normal direction which is proportion to the distance between the <b>point</b> <b>clouds</b> and their corresponding smoothed versions with given geometric enhancement scale factor. The effectiveness of the proposed method is demonstrated by several examples with both synthetic and real scanned <b>point</b> <b>clouds...</b>|$|R
30|$|Composed of <b>point</b> <b>clouds.</b> The {{intersection}} line consists of 3 D <b>point</b> <b>clouds</b> since the Y-axis coordinates of these points are the same; {{the perimeter of}} the 3 D <b>point</b> <b>clouds</b> can be reduced to {{the perimeter of the}} 2 D point, which can be solved by a 2 D plane algorithm.|$|R
40|$|International audienceIn {{this paper}} {{we present a}} {{methodology}} for nonlocal processing of 3 D colored <b>point</b> <b>clouds</b> using regularization of functions defined on weighted graphs. To adapt it to nonlocal processing of 3 D data, a new definition of patches for 3 D <b>point</b> <b>clouds</b> is introduced and used for nonlocal filtering of 3 D data such as colored <b>point</b> <b>clouds.</b> Results illustrate the benefits of our non-local approach to filter noisy 3 D colored <b>point</b> <b>clouds</b> (either on spatial or colorimetric information) ...|$|R
5000|$|The {{persistent}} homology group [...] of a <b>point</b> <b>cloud</b> is {{the persistence}} module defined as , where [...] is the Čech complex of radius [...] of the <b>point</b> <b>cloud</b> [...] and [...] is the homology group.|$|E
50|$|Regardless of the {{methodology}} of the data acquisition, the resulting <b>point</b> <b>cloud</b> is usually filtered and cleaned from unwanted objects, e.g. vegetation. Decrease of the overall <b>point</b> <b>cloud</b> density might be required depending on the outcrop surface complexity {{and size of the}} dataset.|$|E
50|$|Point clouds may {{be created}} by 3D scanners. These devices measure {{a large number of}} points on an object's surface, and often output a <b>point</b> <b>cloud</b> as a data file. The <b>point</b> <b>cloud</b> {{represents}} the set of points that the device has measured.|$|E
50|$|<b>Point</b> <b>clouds</b> {{can also}} be used to {{represent}} volumetric data used for example in medical imaging. Using <b>point</b> <b>clouds</b> multi-sampling and data compression are achieved.|$|R
50|$|Memory {{efficient}} <b>point</b> <b>clouds.</b> Like brick maps, <b>point</b> <b>clouds</b> {{are organized}} in a spatial data structure and are loaded lazily, keeping the memory requirements {{as low as}} possible.|$|R
40|$|An {{efficient}} {{method of}} feature image generation of <b>point</b> <b>clouds</b> to automatically classify dense <b>point</b> <b>clouds</b> into different categories is proposed, such as terrain points, building points. The method first uses planar projection to sort points into different grids, then calculates the weights and feature values of grids {{according to the}} distribution of laser scanning points, and finally generates the feature image of <b>point</b> <b>clouds.</b> Thus, the proposed method adopts contour extraction and tracing means to extract the boundaries and <b>point</b> <b>clouds</b> of man-made objects (e. g. buildings and trees) in 3 D based on the image generated. Experiments show that the proposed method provides a promising solution for classifying and extracting man-made objects from vehicle-borne laser scanning <b>point</b> <b>clouds...</b>|$|R
5000|$|For {{each point}} (from the {{whole set of}} {{vertices}} usually referred to as dense or a selection of pairs of vertices from each model) in the source <b>point</b> <b>cloud,</b> Match the closest point in the reference <b>point</b> <b>cloud</b> (or a selected set).|$|E
50|$|One {{application}} in which point clouds are directly usable is industrial metrology or inspection using industrial computed tomography. The <b>point</b> <b>cloud</b> of a manufactured part can {{be aligned to}} a CAD model (or even another <b>point</b> <b>cloud),</b> and compared to check for differences. These differences can be displayed as color maps that give a visual indicator of the deviation between the manufactured part and the CAD model. Geometric dimensions and tolerances can also be extracted directly from the <b>point</b> <b>cloud.</b>|$|E
5000|$|If [...] is a <b>point</b> <b>cloud,</b> replace [...] with a nested {{family of}} simplicial {{complexes}} [...] (such as the Čech or Vietoris-Rips complex). This process converts the <b>point</b> <b>cloud</b> into a filtration of simplicial complexes. Taking the homology of each complex in this filtration gives a persistence module ...|$|E
40|$|This paper {{presents}} a {{data acquisition system}} consisting of multiple RGB-D sensors and digital single-lens reflex (DSLR) cameras. A systematic data processing procedure for integrating these two kinds of devices to generate three-dimensional <b>point</b> <b>clouds</b> of indoor environments is also developed and described. In the developed system, DSLR cameras are used to bridge the Kinects and provide a more accurate ray intersection condition, which {{takes advantage of the}} higher resolution and image quality of the DSLR cameras. Structure from Motion (SFM) reconstruction is used to link and merge multiple Kinect <b>point</b> <b>clouds</b> and dense <b>point</b> <b>clouds</b> (from DSLR color images) to generate initial integrated <b>point</b> <b>clouds.</b> Then, bundle adjustment is used to resolve the exterior orientation (EO) of all images. Those exterior orientations are used as the initial values to combine these <b>point</b> <b>clouds</b> at each frame into the same coordinate system using Helmert (seven-parameter) transformation. Experimental results demonstrate that the design of the data acquisition system and the data processing procedure can generate dense and fully colored <b>point</b> <b>clouds</b> of indoor environments successfully even in featureless areas. The accuracy of the generated <b>point</b> <b>clouds</b> were evaluated by comparing the widths and heights of identified objects as well as coordinates of pre-set independent check points against in situ measurements. Based on the generated <b>point</b> <b>clouds,</b> complete and accurate three-dimensional models of indoor environments can be constructed effectively...|$|R
40|$|This paper proposes {{movement}} {{detection method}} between <b>point</b> <b>clouds</b> created by SFM software, without setting any onsite georeferenced points. SfM software, like Smart 3 DCaputure, PhotoScan, and Pix 4 D, are convenient for non-professional operator of photogrammetry, because these systems require simply specification of sequence of photos and output <b>point</b> <b>clouds</b> with colour index which {{corresponds to the}} colour of original image pixel where the point is projected. SfM software can execute aerial triangulation and create dense <b>point</b> <b>clouds</b> fully automatically. This is useful when monitoring motion of unstable slopes, or loos rocks in slopes along roads or railroads. Most of existing method, however, uses mesh-based DSM for comparing <b>point</b> <b>clouds</b> before/after movement and it cannot be applied in such cases that part of slopes forms overhangs. And in some cases movement is smaller than precision of ground control points and registering two <b>point</b> <b>clouds</b> with GCP is not appropriate. Change detection method in this paper adopts CCICP (Classification and Combined ICP) algorithm for registering <b>point</b> <b>clouds</b> before / after movement. The CCICP algorithm {{is a type of}} ICP (Iterative Closest Points) which minimizes point-to-plane, and point-to-point distances, simultaneously, and also reject incorrect correspondences based on point classification by PCA (Principle Component Analysis). Precision test shows that CCICP method can register two <b>point</b> <b>clouds</b> up to the 1 pixel size order in original images. Ground control points set in site are useful for initial setting of two <b>point</b> <b>clouds.</b> If there are no GCPs in site of slopes, initial setting is achieved by measuring feature points as ground control points in the <b>point</b> <b>clouds</b> before movement, and creating <b>point</b> <b>clouds</b> after movement with these ground control points. When the motion is rigid transformation, in case that a loose Rock is moving in slope, motion including rotation can be analysed by executing CCICP for a loose rock and background slope independently...|$|R
40|$|We {{present a}} novel {{framework}} to compute geodesics on implicit surfaces and <b>point</b> <b>clouds.</b> Our framework {{consists of three}} parts, particle based approximate geodesics on implicit surfaces, Cartesian grid based approximate geodesics on <b>point</b> <b>clouds,</b> and geodesic correction. The first two parts can effectively generate approximate geodesics on implicit surfaces and <b>point</b> <b>clouds,</b> respectively. By introducing the geodesic curvature flow, the third part produces smooth and accurate geodesic solutions. Differing {{from most of the}} existing methods, our algorithms can converge to a given tolerance. The presented computational framework is suitable for arbitrary implicit hypersurfaces or <b>point</b> <b>clouds</b> with high genus or high curvature...|$|R
5000|$|... #Caption: Geo-referenced <b>point</b> <b>cloud</b> of Red Rocks, Colorado (by DroneMapper) ...|$|E
50|$|The <b>Point</b> <b>Cloud</b> Library (PCL) is an {{open-source}} {{library of}} algorithms for <b>point</b> <b>cloud</b> processing tasks and 3D geometry processing, such as occur in three-dimensional computer vision. The library contains algorithms for feature estimation, surface reconstruction, registration, model fitting, and segmentation. It {{is written in}} C++ and released under the BSD license.|$|E
50|$|In the <b>point</b> <b>cloud</b> {{georeferencing}} {{process a}} 3D transformation is computed between the local project coordinate {{system and a}} geodetic coordinate system. In order to complete that action minimum three points are required, that can {{be located in the}} <b>point</b> <b>cloud</b> and their coordinates in the geodetic system are known (measured using surveying methods or GNSS).|$|E
40|$|Both {{airborne}} and terrestrial laser scanners {{are used}} to capture large <b>point</b> <b>clouds</b> of the objects under study. Although for some applications, direct measurements in the <b>point</b> <b>clouds</b> may already suffice, most applications require an automatic processing of the <b>point</b> <b>clouds</b> to extract information on {{the shape of the}} recorded objects. This processing often involves the recognition of specific geometric shapes or more general smooth surfaces. This paper reviews several techniques {{that can be used to}} recognise such structures in <b>point</b> <b>clouds.</b> Applications in industry, urban planning, water management and forestry document the usefulness of these techniques. 1...|$|R
40|$|Abstract. To {{ensure the}} {{security}} and integrity of three dimensional <b>point</b> <b>clouds</b> model during transmission in the network, {{according to their own}} characteristics, after the pretreatment of PCA (Primary Component Analysis), three dimensional <b>point</b> <b>clouds</b> watermarking embedding algorithm based on sphere degenerated octree was proposed, and the octree that contained the original <b>point</b> <b>clouds</b> model was subdivided multilevel from top to bottom, and the nodes of the octree were ordered. And three dimensional <b>point</b> <b>clouds</b> watermarking extraction algorithm was proposed, and the original <b>point</b> <b>clouds</b> model and the watermarked model were registered accurately, and the occurrence of synchronization error was avoided. Experimental results showed that the presented algorithm was robust to many attacks such as rotation, translation, uniform scaling, vertices reordering, simplifying, noise and cropping under blind detection...|$|R
40|$|Recently, by Mobile Mapping System (MMS) with laser scanners, a GPS and IMU (Inertial Measurement Unit), 3 D <b>point</b> <b>clouds</b> {{of urban}} areas (MMS <b>point</b> <b>clouds)</b> are easily acquired. When the same areas are scanned several {{times by the}} MMS, the <b>point</b> <b>clouds</b> often have {{differences}} {{in the range of}} several hundreds of millimetres. Such differences are caused by inertial drifts of IMU and losses of GPS signals in urban areas. In this paper, we propose an automatic accurate registration method of MMS <b>point</b> <b>clouds</b> using a new variant of ICP (Iterative Closest Point) algorithm for MMS <b>point</b> <b>clouds</b> and trajectory modification. Our method consists of four steps. Firstly, some trajectory points are automatically extracted by analyzing the trajectory. Secondly, the differences of <b>point</b> <b>clouds</b> are derived at the extracted trajectory points in the overlapping scan region by our new ICP algorithm which minimizes pointto- plane and point-to-point distances simultaneously and filters incorrect correspondences based on a point classification by PCA (Principle Component Analysis). Thirdly, the modified positions and rotation parameters at all extracted trajectory points are derived by a least squares method for positioning and registration constraints. Finally, each point in the <b>point</b> <b>clouds</b> is modified by coordinate transformations which are derived from linear interpolation of the modified positions and rotation parameters of the extracted trajectory points. Our method was applied to MMS <b>point</b> <b>clouds</b> and trajectory and the performances were evaluated...|$|R
50|$|A <b>point</b> <b>cloud</b> {{is a set}} of {{data points}} in some {{coordinate}} system.|$|E
5000|$|... #Caption: Dr. Douglas Maxwell Captured by 80 Cameras and Rendered as <b>Point</b> <b>Cloud</b> ...|$|E
5000|$|PDAL, an {{open source}} library for <b>point</b> <b>cloud</b> data {{translation}} and format abstraction ...|$|E
40|$|Indoor {{reconstruction}} from <b>point</b> <b>clouds</b> is a {{hot topic}} in photogrammetry, computer vision and computer graphics. Reconstructing indoor scene from <b>point</b> <b>clouds</b> is challenging due to complex room floorplan and line-of-sight occlusions. Most of existing methods deal with stationary terrestrial laser scanning <b>point</b> <b>clouds</b> or RGB-D <b>point</b> <b>clouds.</b> In this paper, we propose an automatic method for reconstructing indoor 3 D building models from mobile laser scanning <b>point</b> <b>clouds.</b> The method includes 2 D floorplan generation, 3 D building modeling, door detection and room segmentation. The main idea behind our approach is to separate wall structure into two different types as the inner wall {{and the outer wall}} based on the observation of point distribution. Then we utilize a graph cut based optimization method to solve the labeling problem and generate the 2 D floorplan based on the optimization result. Subsequently, we leverage an -shape based method to detect the doors on the 2 D projected <b>point</b> <b>clouds</b> and utilize the floorplan to segment the individual room. The experiments show that this door detection method can achieve a recognition rate at 97...|$|R
40|$|Abstract. Data {{collection}} and processing of human faces are hot spots of reverse engineering. This paper studies {{the data collection}} of human faces, the pre-treatment of <b>point</b> <b>clouds,</b> and analyzes the error of data collection at the same time. Data collection mostly uses proper system parameters to get desired <b>point</b> <b>clouds.</b> Pretreatment of <b>point</b> <b>clouds</b> deletes the desultory points first, then merge the <b>point</b> <b>clouds.</b> Finally, analyze the errors that are caused {{in the process of}} data collection, mostly analyze the effects of equipment, ambient light, and system parameters on accuracy of data collection, then find the best treatment to get a desirable experimental result...|$|R
40|$|Although many filter {{algorithms}} {{have been}} presented over past decades, these algorithms are usually designed for the Lidar <b>point</b> <b>clouds</b> and can’t separate the ground points from the DIM (dense image matching, DIM) <b>point</b> <b>clouds</b> derived from the oblique aerial images owing to the high density and variation of the DIM <b>point</b> <b>clouds</b> completely. To solve this problem, a new automatic filter algorithm is developed {{on the basis of}} adaptive TIN models. At first, the differences between Lidar and DIM <b>point</b> <b>clouds</b> which influence the filtering results are analysed in this paper. To avoid the influences of the plants which can’t be penetrated by the DIM <b>point</b> <b>clouds</b> in the searching seed pointes process, the algorithm makes use of the facades of buildings to get ground points located on the roads as seed points and construct the initial TIN. Then a new densification strategy is applied {{to deal with the problem}} that the densification thresholds do not change as described in other methods in each iterative process. Finally, we use the DIM <b>point</b> <b>clouds</b> located in Potsdam produced by Photo-Scan to evaluate the method proposed in this paper. The experiment results show that the method proposed in this paper can not only separate the ground points from the DIM <b>point</b> <b>clouds</b> completely but also obtain the better filter results compared with TerraSolid. 1...|$|R
