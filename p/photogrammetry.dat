5067|1|Public
5|$|Sechin, A.; Parallel Computing in <b>Photogrammetry.</b> GIM International. #1, 2016, pp.21–23.|$|E
5|$|The Fujita {{scale and}} the Enhanced Fujita Scale rate tornadoes by damage caused. An EF0 tornado, the weakest category, damages trees but not {{substantial}} structures. An EF5 tornado, the strongest category, rips buildings off their foundations and can deform large skyscrapers. The similar TORRO scale ranges from a T0 for extremely weak tornadoes to T11 for the most powerful known tornadoes. Doppler radar data, <b>photogrammetry,</b> and ground swirl patterns (cycloidal marks) may also be analyzed to determine intensity and award a rating.|$|E
5|$|The Fujita {{scale and}} the Enhanced Fujita Scale rate tornadoes by damage caused. The Enhanced Fujita (EF) Scale was an update to the older Fujita scale, by expert elicitation, using {{engineered}} wind estimates and better damage descriptions. The EF Scale was designed so that a tornado rated on the Fujita scale would receive the same numerical rating, and was implemented starting in the United States in 2007. An EF0 tornado will probably damage trees but not substantial structures, whereas an EF5 tornado can rip buildings off their foundations leaving them bare and even deform large skyscrapers. The similar TORRO scale ranges from a T0 for extremely weak tornadoes to T11 for the most powerful known tornadoes. Doppler weather radar data, <b>photogrammetry,</b> and ground swirl patterns (cycloidal marks) may also be analyzed to determine intensity and award a rating.|$|E
5|$|There {{are several}} scales for rating the {{strength}} of tornadoes. The Fujita scale rates tornadoes by damage caused and has been replaced in some countries by the updated Enhanced Fujita Scale. An F0 or EF0 tornado, the weakest category, damages trees, but not substantial structures. An F5 or EF5 tornado, the strongest category, rips buildings off their foundations and can deform large skyscrapers. The similar TORRO scale ranges from a T0 for extremely weak tornadoes to T11 for the most powerful known tornadoes. Doppler radar data, <b>photogrammetry,</b> and ground swirl patterns (cycloidal marks) may also be analyzed to determine intensity and assign a rating.|$|E
5|$|The characters' {{body and}} facial {{movements}} were recorded using motion capture: these included capturing static figures for dialogue segments, and full-body capture for action sequences. The motion actors provided {{the basis for}} their characters' appearance: the actors were chosen based on how well they fitted with the staff's vision for the characters. The motion actors' facial expressions were captured using a special head-mounted rig the team had previously developed for the 2012 tech demo. When the character designs were being created, Nozue needed to regularly consult professional hairstylists to ensure that their chosen hairstyles for characters would be feasible in real life. For characters who appeared in the game, the team tried to keep their facial features {{as close as possible to}} their in-game counterpart. As with other Japanese CGI films aiming for a realistic tone, the team relied on <b>photogrammetry</b> and an extensive 3D scanning process combined with motion capture. Character clothing was created in a similar way to real-life clothing, with a number of different design variations being tested using paper cutouts. Something that both in-house and external staff contended with was making character movements realistic without being symmetrical; the biggest example was Libertus's need to walk on crutches for much of the movie, shifting his weight balance and movement speed.|$|E
25|$|<b>Photogrammetry</b> also {{overlaps}} with computer vision, e.g., stereophotogrammetry vs. computer stereo vision.|$|E
25|$|Surface {{exploration}} {{can include}} geologic mapping, geophysical methods, and <b>photogrammetry,</b> {{or it can}} be as simple as a geotechnical professional walking around on the site to observe the physical conditions at the site.|$|E
25|$|Rich, P.M., R. Dubayah, W.A. Hetrick, and S.C. Saving. 1994. Using viewshed {{models to}} {{calculate}} intercepted solar radiation: applications in ecology. American Society for <b>Photogrammetry</b> and Remote Sensing Technical Papers. pp 524–529.|$|E
25|$|Galo, A.T., P.M. Rich, and J.J. Ewel. 1992. Effects {{of forest}} edges on the solar {{radiation}} regime {{in a series}} of reconstructed tropical ecosystems. American Society for <b>Photogrammetry</b> and Remote Sensing Technical Papers. pp 98–108.|$|E
25|$|The project {{exhibits}} {{a replica of}} a vintage New York City subway entrance that transports visitors to downtown Zurich, Switzerland’s largest city. It uses augmented reality and <b>photogrammetry</b> technologies to display 3D models of Zurich’s old town and the historic ″Augustinergasse.″ MetroNeX+ is presented by ETH Zurichhttps, Digital Art Week International, and Virtuale Switzerland.|$|E
25|$|Due to data {{transmission}} problems, structural health monitoring of wind turbines is usually performed using several accelerometers and strain gages {{attached to the}} nacelle to monitor the gearbox and equipments. Currently, digital image correlation and stereophotogrammetry are used to measure dynamics of wind turbine blades. These methods usually measure displacement and strain to identify location of defects. Dynamic characteristics of non-rotating wind turbines have been measured using digital image correlation and <b>photogrammetry.</b> Three dimensional point tracking has also been used to measure rotating dynamics of wind turbines.|$|E
25|$|Computer {{graphics}} are {{now used}} to build virtual 3D models of sites, such as the throne room of an Assyrian palace or ancient Rome. <b>Photogrammetry</b> is also used as an analytical tool, and digital topographical models have been combined with astronomical calculations to verify whether or not certain structures (such as pillars) were aligned with astronomical {{events such as the}} sun's position at a solstice. Agent-based modeling and simulation can be used to better understand past social dynamics and outcomes. Data mining can be applied to large bodies of archaeological 'grey literature'.|$|E
25|$|Photography and {{videography}} are the mainstays of recording, {{which has}} become much more convenient with the advent of reasonably priced digital still and HD video cameras. Cameras, including video cameras can be provided with special underwater housings that enable them to be used for underwater videography. Low visibility underwater and distortion of image due to refraction mean that perspective photographs can be difficult to obtain. However, it is possible to take a series of photographs at adjacent points and then combined into a single photomontage or photomosaic image of the whole site. 3D <b>photogrammetry</b> has also become a very popular way to image underwater cultural materials and shipwreck sites.|$|E
25|$|By {{the end of}} Carlos P. Romulo's term as UP President in 1968, UP {{had also}} become not only an {{institution}} of education, but also a center of research, a veritable think tank, while many of its faculty served as advisers and consultants in the national government. Romulo's administration was marked by {{the establishment of the}} Population Institute, the Law Center and the Applied Geodesy and <b>Photogrammetry</b> Training Center in 1964, the Institute of Mass Communication (now College of Mass Communication), the College of Business Administration, and the Institute of Planning in 1965, the UP Computer Center, the Institute for Small-Scale Industries in 1966, the Institute of Social Work and Community Development in 1967 and the Asian Center in 1968.|$|E
25|$|Characters' facial {{animations}} {{were created}} with a custom <b>photogrammetry</b> facial scanner, which utilized 44 DSLR cameras with 50mm fixed lenses. Character Art Lead Brendan George stated that 16 facial expressions were captured {{to create a}} single character; the 16 scans then took {{two to three days}} to process through their workstations. The data from their new scanner allowed the artists to produce a more advanced facial rig. All motion capture was performed in-house at NetherRealm Studios in Chicago, Illinois. According to Senior Technical Artist for Cinematics Andy Senesac, the animation team used four head-mounted camera systems in its motion capture shoots, each equipped with a choice of three different 4mm, 5mm, or wide-angled lenses that were used depending on the actor's head shape. The motion capture was then tweaked with manual animations in order to obtain the final result.|$|E
25|$|Tornado {{intensity}} can {{be measured}} by in situ or remote sensing measurements, but since these are impractical for wide scale use, intensity is usually inferred via proxies, such as damage. The Fujita scale and the Enhanced Fujita scale rate tornadoes by the damage caused. The Enhanced Fujita Scale was an upgrade to the older Fujita scale, with engineered (by expert elicitation) wind estimates and better damage descriptions, but was designed so that a tornado rated on the Fujita scale would receive the same numerical rating. An EF0 tornado will probably damage trees but not substantial structures, whereas an EF5 tornado can rip buildings off their foundations leaving them bare and even deform large skyscrapers. The similar TORRO scale ranges from a T0 for extremely weak tornadoes to T11 for the most powerful known tornadoes. Doppler radar data, <b>photogrammetry,</b> and ground swirl patterns (cycloidal marks) may also be analyzed to determine intensity and award a rating.|$|E
25|$|By the 1990s, {{some of the}} {{previous}} research topics became more active than the others. Research in projective 3-D reconstructions led to better understanding of camera calibration. With the advent of optimization methods for camera calibration, it was realized {{that a lot of}} the ideas were already explored in bundle adjustment theory from the field of <b>photogrammetry.</b> This led to methods for sparse 3-D reconstructions of scenes from multiple images. Progress was made on the dense stereo correspondence problem and further multi-view stereo techniques. At the same time, variations of graph cut were used to solve image segmentation. This decade also marked the first time statistical learning techniques were used in practice to recognize faces in images (see Eigenface). Toward the end of the 1990s, a significant change came about with the increased interaction between the fields of computer graphics and computer vision. This included image-based rendering, image morphing, view interpolation, panoramic image stitching and early light-field rendering.|$|E
500|$|The {{game was}} {{directed}} by Koshi Nakanishi, who previously helmed , leading a development team numbering at about 120 staff. For {{the first time in}} the series, the narrative designer was a westerner—Richard Pearsey, writer of the two expansion packs of F.E.A.R. and one of the narrative designers of [...] At the time of the game's reveal, development was around 65% complete. Some of the creature models in Resident Evil 7 were first created in physical form – a number of them from actual meat – by make-up artists, to then be scanned through the employment of <b>photogrammetry.</b> This technology developed over half of the general assets of the game, but posed a problem in researching the setting of Louisiana because its considerable demand for equipment made it unviable for transport, which required Capcom to model by hand. The game's original score was composed primarily by Capcom's Akiyuki Morimoto, Miwako Chinone, and Satoshi Hori, with additional contributions from Brian D'Oliveira and Cris Velasco. Its theme song, an arranged version of the traditional American folk song [...] "Go Tell Aunt Rhody", was written by Michael A. Levine and performed by Jordan Reyne. Levine's step-daughter Mariana Barreto was the original choice, but ended up doing the background vocals. The song went through about 20 versions until completion. A soundtrack was released digitally by Sumthing Else Music Works alongside the game on January 24.|$|E
2500|$|Fournier, R.A., P.M. Rich, Y.R. Alger, V.L. Peterson, R. Landry, and [...] N.M. [...] August. [...] 1995. Canopy {{architecture}} of boreal forests: links between remote sensing and ecology. American Society for <b>Photogrammetry</b> and Remote Sensing Technical Papers 2:225-235.|$|E
2500|$|Lin, T., P.M. Rich, D.A. Heisler, and F.J. Barnes. [...] 1992. Influences of canopy {{geometry}} on near-ground {{solar radiation}} and water balances of pinyon-juniper and ponderosa pine woodlands. American Society for <b>Photogrammetry</b> and Remote Sensing Technical Papers. [...] pp.285–294.|$|E
2500|$|Rich, P.M. [...] 1988. [...] Video image {{analysis}} of hemispherical canopy photography. [...] In: [...] P.W. Mausel (ed), First Special Workshop on Videography. [...] Terre Haute, Indiana. [...] May 19–20, 1988, 'American Society for <b>Photogrammetry</b> and Remote Sensing', pp.84–95.|$|E
2500|$|This method {{requires}} an SEM image obtained in oblique low angle lighting. The grey-level is then {{interpreted as the}} slope, and the slope integrated to restore the specimen topography. This method is interesting for visual enhancement and the detection of the shape and position of objects however the vertical heights cannot usually be calibrated, contrary to other methods such as <b>photogrammetry.</b>|$|E
2500|$|... 3D {{printable}} models may {{be created}} with a computer-aided design (CAD) package, via a 3D scanner, or by a plain digital camera and <b>photogrammetry</b> software. 3D printed models created with CAD result in reduced errors {{and can be}} corrected before printing, allowing verification {{in the design of}} the object before it is printed. The manual modeling process of preparing geometric data for 3D computer graphics is similar to plastic arts such as sculpting. 3D scanning is a process of collecting digital data on the shape and appearance of a real object, creating a digital model based on it.|$|E
2500|$|The above {{relation}} which {{defines the}} essential matrix {{was published in}} 1981 by H. Christopher Longuet-Higgins, introducing the concept to the computer vision community. Richard Hartley and Andrew Zisserman's book reports that an analogous matrix appeared in <b>photogrammetry</b> long before that. Longuet-Higgins' paper includes an algorithm for estimating [...] from a set of corresponding normalized image coordinates {{as well as an}} algorithm for determining the relative position and orientation of the two cameras given that [...] is known. Finally, it shows how the 3D coordinates of the image points can be determined with the aid of the essential matrix.|$|E
2500|$|Remote sensing, {{as used in}} meteorology, is {{the concept}} of {{collecting}} data from remote weather events and subsequently producing weather information. The common types of remote sensing are Radar, Lidar, and satellites (or <b>photogrammetry).</b> Each collects data about the atmosphere from a remote location and, usually, stores the data where the instrument is located. Radar and Lidar are not passive because both use EM radiation to illuminate a specific portion of the atmosphere. [...] Weather satellites along with more general-purpose Earth-observing satellites circling the earth at various altitudes have become an indispensable tool for studying a wide range of phenomena from forest fires to El Niño.|$|E
2500|$|According {{to local}} reports, heavy rains {{combined}} with three earthquakes exposed the formation {{from the surrounding}} mud in May 19, 1948. It was discovered by a Kurdish shepherd named Reshit Sarihan. It was subsequently identified by Turkish Army Captain İlhan Durupınar— for whom it was subsequently named— in a Turkish Air Force aerial photo while on a mapping mission for NATO in October 1959. Durupınar informed the Turkish government of his discovery and a group from the Archeological Research Foundation which included George Vandeman, İlhan Durupınar, and Arthur Brandenberger, professor of <b>photogrammetry,</b> surveyed the site in September 1960. After two days of digging and dynamiting inside the [...] "boat-shaped" [...] formation, the expedition members found only soil and rocks. Their official news release concluded that [...] "there were no visible archaeological remains" [...] and that this formation [...] "was a freak of nature and not man-made".|$|E
2500|$|Geodetic {{methods are}} an {{indirect}} method for {{the determination of}} mass balance of glacier. Maps of a glacier made at two different points in time can be compared and the difference in glacier thickness observed {{used to determine the}} mass balance over a span of years. This is best accomplished today using Differential Global Positioning System. Sometimes the earliest data for the glacier surface profiles is from images that are used to make topographical maps and digital elevation models. Aerial mapping or <b>photogrammetry</b> is now used to cover larger glaciers and icecaps such found in Antarctica and Greenland, however, because of the problems of establishing accurate ground control points in mountainous terrain, and correlating features in snow and where shading is common, elevation errors are typically not less than 10m (32ft). Laser altimetry provides a measurement of the elevation of a glacier along a specific path, e.g., the glacier centerline. The difference of two such measurements is the change in thickness, which provides mass balance over the time interval between the measurements. [...] Again a good method over a span of time but not for annual change detection. The value of geodetic programs is providing an independent check of traditional mass balance work, by comparing the cumulative changes over ten or more years.|$|E
50|$|IMAGINE <b>Photogrammetry</b> (formerly LPS and Leica <b>Photogrammetry</b> Suite) is a {{software}} application for performing photogrammetric operations on imagery and extracting information from imagery. IMAGINE <b>Photogrammetry</b> {{is significant because}} it is a leading commercial <b>photogrammetry</b> application that is used by numerous national mapping agencies, regional mapping authorities, various DOTs, as well as commercial mapping firms. Aside from commercial and government applications, IMAGINE <b>Photogrammetry</b> is widely used in academic research. Research areas include landslide monitoring, cultural heritage studies, and more.|$|E
50|$|SOCET SET is a {{software}} application that performs functions related to <b>photogrammetry.</b> It is developed {{and published by}} BAE Systems. SOCET SET {{was among the first}} commercial digital <b>photogrammetry</b> software programs. Prior to the development of digital solutions, <b>photogrammetry</b> programs were primarily analog or custom systems built for government agencies.|$|E
50|$|The chief {{competitor}} to SOCET SET is the Leica <b>Photogrammetry</b> Suite (aka LPS, {{owned by}} ERDAS), INPHO, PHOTOMOD and Intergraph, {{which are also}} leaders {{in the field of}} <b>photogrammetry.</b>|$|E
50|$|PhotoModeler is {{now being}} used more {{regularly}} with drone, UAV, and UAS photography (Unmanned aerial vehicle). These vehicles produce photos that are closer to the subject (the ground) than traditional aerial <b>photogrammetry</b> (taken by fixed wing aircraft with high resolution cameras at higher altitude). Software packages suited to this other type of aerial <b>photogrammetry</b> are packages such as SOCET SET, or LPS (Leica <b>Photogrammetry</b> Suite).|$|E
50|$|The American Society for <b>Photogrammetry</b> and Remote Sensing (ASPRS) is an American {{learned society}} devoted to <b>photogrammetry.</b> It is the United States' member {{organization}} of the International Society for <b>Photogrammetry</b> and Remote Sensing. Founded in 1934, the ASPRS is a scientific association serving over 7,000 professional members around the world. As a professional body with oversight of specialists in the arts of imagery exploitation and photographic cartography.|$|E
5000|$|... 3D data {{acquisition}} and object reconstruction {{can be performed}} using stereo image pairs. Stereo <b>photogrammetry</b> or <b>photogrammetry</b> based on a block of overlapped images is the primary approach for 3D mapping and object reconstruction using 2D images. Close-range <b>photogrammetry</b> has also matured to the level where cameras or digital cameras {{can be used to}} capture the close-look images of objects, e.g., buildings, and reconstruct them using the very same theory as the aerial <b>photogrammetry.</b> An example of software which could do this is Vexcel FotoG 5. This software has now been replaced by Vexcel GeoSynth. Another similar software program is Microsoft Photosynth.|$|E
5000|$|ISPRS Journal of <b>Photogrammetry</b> and Remote Sensing is the {{official}} peer-reviewed publication of the Society on <b>photogrammetry</b> and remote sensing. It is published by Elsevier twelve times per year and contains scientific and technical articles and reviews.|$|E
5000|$|Vertical {{photographs}} are taken straight down. [...] They are mainly used in <b>photogrammetry</b> and image interpretation. Pictures {{that will be}} used in <b>photogrammetry</b> are traditionally taken with special large format cameras with calibrated and documented geometric properties.|$|E
50|$|<b>Photogrammetry</b> and Remote Sensing Lab.|$|E
