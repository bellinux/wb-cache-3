15|15|Public
40|$|The main {{objective}} {{of this research is}} to determine {{through the use of a}} CAD-BIM system, the emission of CO 2 in the <b>pre-operational</b> <b>phase</b> of construction. Based on a case study in quantitative analysis of materials and the BIM system, it was possible to quantify the amount of CO 2 emitted during the pre-operational life cycle of a building. By using this feature you can provide, before the begining of construction, the total CO 2 that will released to the environment, and other analysis...|$|E
40|$|A GPSPAC/LANDSAT-D Interface (GLI) Ground Support System {{was built}} to {{validate}} the performance and to calibrate {{the accuracy of the}} experimental navigation package, GPSPAC, flown on the LANDSAT- 4 and 5 spacecraft. Although the GLI system operated successfully to give the orbit information needed to validate the GPSPAC, it also detected two anomalies: one is characteristic of the GLI system and the other is characteristic of the <b>pre-operational</b> <b>phase</b> of GPS. Several methods were applied to resolve or reduce the anomalies. This paper presents a description of the problems, the methods applied to resolve or reduce them, and the results...|$|E
40|$|The main {{objective}} of the report is to assess whether images produced by Sentinel- 2 B sensor are suitable for usage in Control with Remote Sensing programme, specifically in the Common Agriculture Policy (CAP). The benchmarking presented herein aims at evaluating the usability of Sentinel- 2 B images for the CAP checks through an estimation of its geometric (positional) accuracy. Tests have been performed on Sentinel- 2 B data from the first <b>pre-operational</b> <b>phase</b> (June 2017), subsequently on data from the pre-operational hub (July 2017). For that purpose, the External Quality Control of Sentinel- 2 B orthoimagery conforms to the standard method developed by JRC and follows a procedure already adopted in the validation of previous high and very-high resolution products. JRC. D. 5 -Food Securit...|$|E
40|$|Abstract. Security {{analysis}} {{is growing in}} complexity {{with the increase in}} functionality, connectivity, and dynamics of current electronic business processes. To tackle this complexity, the application of models in <b>pre-operational</b> <b>phases</b> is becoming standard practice. Runtime models are also increasingly applied to analyze and validate the actual security status of business process instances. In this paper we present an approach to support not only model-based evaluation of the current security status of business process instances, but also to allow for decision support by analyzing close-future process states. Our approach is based on operational formal models derived from development-time process and security models. This paper exemplifies our approach utilizing real world processes from the logistics domain and demonstrates the systematic development and application of runtime models for situational security analysis...|$|R
40|$|International audienceThe Internet today {{provides}} {{the environment for}} novel applications and processes which may evolve way beyond pre-planned scope and purpose. Geographically dispersed real and virtual infrastructures, services and resources are the elementary components of such processes within large-scale, massively interconnected systems of systems. However, this evolving environment also enables new threats and scales up the risks of financial and also physical impact. Elevating dependability of applications in this ambient environment requires the monitoring of a system's operation using process information. Analysis of this information with respect to security and dependability aspects is growing in complexity {{with the increase in}} functionality, connectivity, and dynamics of current information technology and industrial control systems. To tackle this complexity, the application of models is becoming standard practice. Considering today's frequent changes to processes, model-based support for security and dependability analysis is not only needed in <b>pre-operational</b> <b>phases</b> but also at runtime...|$|R
40|$|An {{integrated}} approach for forest fire risk assessment {{over a wide}} geographical area is presented in this paper. Such an assessment is finalized to support decisions regarding long-term planning and <b>pre-operational</b> <b>phases.</b> Risk assessment is carried out both in dynamical and in static situations. The information used for risk assessment is relevant to hazard, and to vulnerability and cost of the exposed elements. Hazard assessment is carried out, in the dynamic case, by use of a cascade of two models, the former tracking the moisture content of the available dead fine fuel, and the second providing {{an estimate of the}} potential spread and of the linear intensity of a fire possibly ignited in the cell. The two models are driven by meteorological information (real-time and forecast) and by territorial information stored in a GIS database. Instead, in the static case, hazard assessment is based on a deep analysis of the fires historically occurred in each cell...|$|R
40|$|A key success {{factor of}} the Copernicus {{programme}} {{is to ensure}} the acceptance of services by users. This acceptance and further adoption is based on high quality products that meet the specific information requirements of the user. In the realm of biodiversity monitoring and reporting on conservation status of Natura 2000 habitats, such products must meet different needs of local site manager and national environmental agencies, up to European authorities. Hence, the quality of these upcoming Earth observation based technologies must be validated in a <b>pre-operational</b> <b>phase.</b> The case of the MS. MONINA project shows the necessity to streamline the role of different stakeholders in the whole service delivery process. This process is described in depth, taken from the service validation in Sierra Nevada and Andalusia (Spain), showing potentials and limitations of the developed validation protocol and highlighting methodological, technical and scientific achievements obtained during this process...|$|E
40|$|In late 2009, the National Aeronautics and Space Administration (NASA) and the U. S. Nuclear Regulatory Commission (NRC) jointly {{organized}} a workshop to discuss technical {{issues associated with}} application of risk assessments to early phases of system design. The workshop, which was coordinated by the Idaho National Laboratory, involved invited presentations {{from a number of}} PRA experts in the aerospace and nuclear fields and subsequent discussion to address the following questions: (a) What technical issues limit decision-makers' confidence in PRA results, especially at a <b>pre-operational</b> <b>phase</b> of the system life cycle? (b) What is being done to address these issues'? (c) What more can be done ? The workshop resulted in participant observations and suggestions on several technical issues, including the pursuit of non-traditional approaches to risk assessment and the verification and validation of risk models. The workshop participants also identified several important non-technical issues, including risk communication with decision makers, and the integration of PRA into the overall design process...|$|E
40|$|The {{problems}} {{concerning the}} development of show caves are here considered by taking into account {{different aspects of the}} problem. A procedure to carry out an Environmental Impact Assessment (EIA) has been established in the last decade and it is now currently applied. Such an assessment starts with a <b>pre-operational</b> <b>phase</b> to obtain sufficient information on the undisturbed status of a cave to be developed into a show cave. Successively a programme for its development is established with the scope to optimise the intervention on the cave at the condition that its basic environmental parameters are not irreversibly modified. The last phase of the assessment is focussed to assure a feedback through a monitoring network in order to detect any unforeseen difference or anomaly between the project and the effective situation achieved after the cave development. Some data on {{some of the most important}} show caves in the world are reported and a tentative evaluation of the economy in connection with the show caves business is eventually made...|$|E
40|$|Enforcing {{security}} in process-aware information systems at runtime requires the monitoring of systems' operation using process information. Analysis {{of this information}} with respect to security and compliance aspects is growing in complexity {{with the increase in}} functionality, connectivity, and dynamics of process evolution. To tackle this complexity, the application of models is becoming standard practice. Considering today's frequent changes to processes, model-based support for security and compliance analysis is not only needed in <b>pre-operational</b> <b>phases</b> but also at runtime. This paper presents an approach to support evaluation of the security status of processes at runtime. The approach is based on operational formal models derived from process specifications and security policies comprising technical, organizational, regulatory and cross-layer aspects. A process behavior model is synchronized by events from the running process and utilizes prediction of expected cl ose-future states to find possible security violations and allow early decisions on countermeasures. The applicability of the approach is exemplified by a misuse case scenario from a hydroelectric power plant...|$|R
40|$|Cloud Computing {{has risen}} a great {{interest}} {{over the last}} years as it represents an enabling technology for flexible and ubiquitous access over the network to a set of shared computing resources. This work comes from an industrial experience aiming at exploiting the cloud potential for virtualizing complex infrastructures such as an entire Air Traffic Center (ATC), a clear example of complex SoS (System of Systems). The use of virtualization is convenient because industry can leverage in-house test-beds to perform distributed testing campaigns in <b>pre-operational</b> <b>phases</b> or to design new automatic fail-over mechanisms for fully distributed systems. In order to realize such mitigation and recovery techniques in the ATC field, indeed, a cloud platform is required to guarantee a low VM provisioning time with the objective of minimizing the service disruption. In this perspective, after having introduced the principal concepts and factors of the provisioning time, we propose a deep analysis and comparison for two different Infrastructure-as-a-Service (IaaS) platforms, namely Open Stack and Open Nebula (using KVM as hypervisor), that were selected through a preliminary scouting phase...|$|R
40|$|The Internet today {{provides}} {{the environment for}} novel applications and processes which may evolve way beyond pre-planned scope and purpose. Security analysis is growing in complexity {{with the increase in}} functionality, connectivity, and dynamics of current electronic business processes. Technical processes within critical infrastructures also have to cope with these developments. To tackle the complexity of the security analysis, the application of models is becoming standard practice. However, model-based support for security analysis is not only needed in <b>pre-operational</b> <b>phases</b> but also during process execution, in order to provide situational security awareness at runtime. This cumulative thesis provides three major contributions to modelling methodology. Firstly, this thesis provides an approach for model-based Analysis and verification of security and safety properties in order to Support fault prevention and fault removal in system design or redesign. Further- more, some construction principles for the design of well-behaved scalable systems are given. The second topic is the analysis of the exposition of vulnerabilities in the software components of networked systems to exploitation by internal or external threats. This kind of fault forecasting allows the security assessment of alternative system configurations and security policies. Validation and deployment of security policies that minimise the attack surface can now improve fault tolerance and mitigate the impact of successful attacks. Thirdly, the approach is extended to runtime applicability. An observing system monitors an event stream from the observed system with the aim to detect faults deviations from the specified behaviour or security compliance violations at runtime. Furthermore, knowledge about the expected behaviour given by an operational model is used to predict faults in the near future. Building on this, a holistic security management strategy is proposed. The architecture of the observing system is described and the applicability of model-based security analysis at runtime is demonstrated utilising processes from several industrial scenarios. The results of this cumulative thesis are provided by 19 selected peer-reviewed papers...|$|R
40|$|Since {{the launch}} of ERS- 1 in 1991 and ERS- 2 in 1995, {{carrying}} a C-band Scatterometer, a data set of more than thirteen years of backscattered signal from the Earth surface is available for exploitation. With its global coverage, day or night and all-weather operation, ERS Scatterometer data offer a unique opportunity for long-term studies and research. To fulfill {{the needs of the}} scientific community, the European Space Agency (ESA) has developed the project: Advanced Scatterometer Processing System (ASPS). Main scope of the project is to provide with state of the art algorithm, high quality and homogenous Scatterometer measurements (sigma nought) of the Earth surface and high quality wind field over the Oceans by re-processing the entire ERS mission. Additional scope is to provide on experimental basis scientific products in high resolution tailored for the emerging Scatterometer application on Ice and Land. The ASPS project is now in a <b>pre-operational</b> <b>phase</b> and the scope of the paper is to give to the scientific community an overview of the ASPS system. Those new data, available in the next years, hopefully will help the scientific community to better understand and monitor the Earth's climate changes and to protect our environmen...|$|E
40|$|This study {{explores the}} {{influence}} of romantically themed media on children 2 ̆ 7 s understanding of love and romantic relationships. By reviewing literature on relevant media influence theories, learning theories, {{and the consequences of}} learning through media, I review how children gain understandings of their world through the media. I then argue that as children identify and internalize meanings through exposure to romantically themed media, such as iconic Disney films, understandings of romantic relationships are shaped. By engaging in qualitative interviews of young children, this thesis investigates whether children can identify iconic Disney images and explores the ways children explain {{what it means to be}} in love. The findings of this study reveal that children ages 4 to 5 not only overwhelmingly identify iconic Disney images but discussed love in terms of closeness, commitment, affection, attractiveness, and amiable personality traits. Additionally, girls’ and boys’ responses about love differed in the areas of affection and commitment. Gaining insight into how children understand romantic love is essential for recognizing how relational meanings are being developed among young children, and the findings of this study may encourage scholars of media effects to study children in the <b>Pre-Operational</b> <b>phase</b> and to consider more fully how girls and boys identify and internalize meanings in different ways...|$|E
40|$|Since {{the launch}} of ERS- 1 in 1991 and ERS- 2 in 1995, {{carrying}} a C-band Scatterometer, a data set of more than thirteen years of backscattered signal from the Earth surface is available for exploitation. With its global coverage, day or night and all-weather operation, ERS Scatterometer data offer unique opportunity for long-term studies and research. To fulfill {{the needs of the}} scientific community, the European Space Agency (ESA) has developed the project: Advanced Scatterometer Processing System (ASPS). Main scope of the project is to provide with state-of-the-art algorithm, high quality and homogenous Scatterometer measurements (sigma nought) of the Earth surface and high quality wind field over the Oceans by re-processing the entire ERS mission. Additional scope is to provide on experimental basis scientific products in high resolution tailored for the emerging Scatterometer application on Ice and Land. The ASPS project is now in a <b>pre-operational</b> <b>phase</b> and the scope of the paper is to give to the scientific community an overview of the ASPS data and show the assimilation of the data into the ECMWF weather analysis system. ASPS data hopefully will help the scientific community to better understand and monitor the Earth's climate changes and to protect our environment...|$|E
40|$|International audienceSoil {{moisture}} is {{an important}} component of the hydrological cycle. In the framework of modern flood warning systems, the knowledge of soil moisture is crucial, due to the influence on the soil response in terms of infiltration-runoff. Precipitation-runoff processes, in fact, are related to catchment's hydrological conditions before the precipitation. Thus, an estimation of these conditions is of significant importance to improve the reliability of flood warning systems. Combining such information with other weather-related satellite products (i. e. rain rate estimation) might represent a useful exercise in order to improve our capability to handle (and possibly mitigate or prevent) hydro-geological hazards. Remote sensing, in the last few years, has supported several techniques for soil moisture/wetness monitoring. Most of the satellite-based techniques use microwave data, thanks to the all-weather and all-time capability of these data, as well as to their high sensitivity to water content in the soil. On the other hand, microwave data are unfortunately highly affected by the presence of surface roughness or vegetation coverage within the instantaneous satellite field of view (IFOV). Those problems, consequently, strongly limit the efficiency and the reliability of traditional satellite techniques. Recently, using data coming from AMSU (Advanced Microwave Sounding Unit), flying aboard NOAA (National Oceanic and Atmospheric Administration) satellites, a new methodology for soil wetness estimation has been proposed. The proposed index, called Soil Wetness Variation Index (SWVI), developed by a multi-temporal analysis of AMSU records, seems able to reduce the problems related to vegetation and/or roughness effects. Such an approach has been tested, with promising results, on the analysis of some flooding events which occurred in Europe in the past. In this study, results achieved for the HYDROPTIMET test cases will be analysed and discussed in detail. This analysis allows us to evaluate the reliability and the efficiency of the proposed technique in identifying different amounts of soil wetness variations in different observational conditions. In particular, the proposed indicator was able to document the actual effects of meteorological events, in terms of space-time evolution of soil wetness changes, for all the analysed HYDROPTIMET test cases. Moreover, in some circumstances, the SWVI was able to identify the presence of a sort of "early" signal in terms of soil wetness variations, which may be regarded as a timely indication of an anomalous value of soil water content. This evidence suggests the opportunity to use such an index in the <b>pre-operational</b> <b>phases</b> of the modern flood warning systems, in order to improve their forecast capabilities and their reliability...|$|R
40|$|To {{determine}} whether the failure of an item relied on for safety (IROFS) {{was the result of}} a deficient quality-affecting item (QAI) procurement process (10 CFR Part 21) or a commercial-grade item (CGI) dedication process. 88114 - 02 INSPECTION REQUIREMENTS 02. 01 Reactive Inspection Requirements (to be performed after the failure of a QAI or CGI dedicated for safety-related applications during the <b>pre-operational</b> or operational <b>phases).</b> a. Initial Evaluation After reviewing the licensee's evaluation of the failed item, determine if the failed item was procured as a QAI or CGI and dedicated for safetyrelated applications. If the failed item was dedicated, review the complete procurement and dedication records to determine if the commercial-grade dedication process was sufficiently thorough. b. Further Assessments If it is determined that the dedicated item failed as the result of certain critical characteristics not being identified and/or properly verified, perform the following assessments: 1. Determine if other QAIs or CGIs from the same accepted lot or batch as th...|$|R
40|$|This section {{presents}} the pre-application, pre-operational, and operational thermal monitoring programs for Callaway Plant Unit 2. The objective of thermal monitoring during each phase is {{to comply with}} state and federal water quality criteria and to assess potential and actual environmental impacts within the area of influence of the facility. ER Chapter 6. 0 Pertinent site and plant features, including boundaries and bathymetry of the Missouri River adjacent to the site are described and shown in FSAR Section 2. 1. 1 and Section 2. 3. 1. The existing thermal monitoring station is shown in Figure 6. 1 - 1. Additional information related to field water temperature measurement is described in Section 2. 3. 1. Data analysis is described in Section 2. 3. 1. Hydrological and biological monitoring stations are described in Section 6. 3 and 6. 5. The extent of the predicted thermal plume is described in Section 5. 3. 2. 1. Temperature monitoring is described in each subsection below corresponding with the pre-application, <b>pre-operational,</b> and operational <b>phases</b> of the project. Thermal program acceptance criteria are based on relevant federal, state, and local requirements...|$|R
40|$|The {{summer of}} 2003 was characterised by very {{warm and dry}} {{conditions}} in Europe, especially in Western Europe. In particular, it was the short-lived heatwave {{that occurred in the}} first fortnight of August that was responsible for the worst fire occurrences ever recorded in Continental Portugal. According to official data, the burnt area reached a total amount of 453, 097 ha, 304, 182 ha of which (i. e. 66 % of the total) were recorded in the first 2 weeks of August, and 91, 439 ha (i. e. 22 % of the total) were recorded in August 4. It is worth emphasizing that wildfires in August were {{responsible for the death of}} 21 human beings and an estimated loss of 15. 5 million euros. The LSA SAF is now in its <b>pre-operational</b> <b>phase</b> and MSG data are currently being processed and archived at its facilities. During the current and the next years data from NOAA and Metop will also become part of the LSA SAF processing chain and new perspectives will be opened in what respects to the real time monitoring of wildfire activity. In such a context, an assessment of the added value provided by a synergic use of data from geostationary and polar orbiters is of particular interest. Accordingly we present a first study on wildfire activity over Continental Portugal based on MSG and NOAA data for the fire season of 2003 focusing on August 3 and 4. 1...|$|E
40|$|The {{operational}} ocean {{prediction model}} for the North and Baltic Seas of the German Maritime and Hydrographic Agency (BSH) is augmented with a multivariate data assimilation (DA) system. We report on the implementation and performance of the scheme {{which is based on}} ensemble forecasting. Here we apply the localised Singular Evolutive Interpolated Kalman (SEIK) filter for assimilating the NOAA AVHRR-derived sea surface temperature (SST) data. Results are presented for two periods: October 2007 is used for calibration and March 2011 for the analysis of the performance in a <b>pre-operational</b> <b>phase.</b> The major forecast improvement is found to be a reduction in the local temperature bias. As compared with the regular BSH forecast without assimilation, the root mean square difference between the predicted SST and satellite observations is reduced on average from 0. 87 degC to 0. 53 degC for March 2011. The quality of the predicted fields that were not assimilated (velocities, sea level and salinity) is preserved as is confirmed by independent data. The results have required adjustment of the conditional data error statistics. The experiments conducted with different timing and frequency of data assimilation and variable forecasting periods show that the DA system corrects systematic model uncertainties and, due to memory to the corrections, improves prediction over periods of up to 5 days. The results also explicitly illustrate a lower quality of the AVHRR daytime product and reveal low informative influence of the data on the forecasting system when daytime SSYs are assimilated additionally to midnight observations...|$|E
40|$|The {{field of}} animal syndromic {{surveillance}} (SyS) is growing, with many systems being developed worldwide. Now {{is an appropriate}} time to share ideas and lessons learned from early SyS design and implementation. Based on our practical experience in animal health SyS, with additions from the public health and animal health SyS literature, we put forward for discussion a 6 -step approach to designing SyS systems for livestock and poultry. The {{first step is to}} formalise policy and surveillance goals which are considerate of stakeholder expectations and reflect priority issues (1). Next, it is important to find consensus on national priority diseases and identify current surveillance gaps. The geographic, demographic, and temporal coverage of the system must be carefully assessed (2). A minimum dataset for SyS that includes the essential data to achieve all surveillance objectives while minimizing the amount of data collected should be defined. One can then compile an inventory of the data sources available and evaluate each using the criteria developed (3). A list of syndromes should then be produced for all data sources. Cases can be classified into syndrome classes and the data can be converted into time series (4). Based on the characteristics of the syndrome-time series, the length of historic data available and the type of outbreaks the system must detect, different aberration detection algorithms can be tested (5). Finally, it is essential to develop a minimally acceptable response protocol for each statistical signal produced (6). Important outcomes of this <b>pre-operational</b> <b>phase</b> should be building of a national network of experts and collective action and evaluation plans. While some of the more applied steps (4 and 5) are currently receiving consideration, more emphasis should be put on earlier conceptual steps by decision makers and surveillance developers (1 - 3) ...|$|E
40|$|Theory of {{knowledge}} according to Piaget. Resumen Para hacer un acercamiento a las formulaciones piagetianas sobre el sujeto, hay que comenzar aclarando que Piaget no es un psicólogo sino un “epistemólogo genético” como el mismo se autodenomina, con lo que podemos entender que se interesa por conocer e investigar el origen y la naturaleza del conocimiento, y como se da éste a través del desarrollo; lo cual muestra claramente sus prioridades intelectuales como biólogo y filosofo. Para lograr estos objetivos, Piaget partió de modelos básicamente biológicos, aunque su sistema de ideas se relaciona de igual forma con la filosofía –en especial con la teoría del conocimiento- y con otras ciencias, como la biología, la lógica y la matemática. Palabras clave: etapa sensorio-motriz, preoperacional, operaciones concretas, operaciones formales. Abstract For exposition of the Piaget formulations about the subject, we start by clarifying that Piaget {{is not a}} psychologist but a "genetic epistemologist" as it describes itself, with what we can understand he is interested in knowing and investigate the origin and the nature {{of knowledge}} and how this occurs through development; which clearly shows their intellectual priorities as biologist and philosopher. To achieve these objectives, Piaget departed basically biological models, although his system of ideas is related in the same way philosophy — especially with knowledge - theory and other sciences, such as biology, logic and mathematics. Key words: sensorial and mortitional <b>phase,</b> <b>pre-operational</b> stage, concrete operations stage, formal operations stage...|$|R
40|$|In North America, the {{migration}} corridors of passerine birds between breeding and non-breeding grounds are relatively well documented, and along these corridors passerines generally {{move in a}} broad-front fashion interspersed with stopover periods in which to rest and replenish fuel stores. Understanding movement patterns at individual locations along these routes is required to identify whether anthropogenic developments, such as wind energy installations, can lead to disruption or collision risk during migrations. Wind energy installations are becoming more numerous in the corridors along migration routes as they use the same wind resources exploited by migratory birds. Documenting collision risk to nocturnal migrants, particularly passerines, through the collection of accurate data on the movement patterns and flight altitudes at wind energy sites during both <b>pre-operational</b> and operational <b>phases</b> is needed to correctly assess the level of risk to these birds. Using standard marine radar units equipped with an inexpensive digital interface system, I automated the detection and extraction of radar echo signatures or target information for nocturnal migrants (Chapter 2) at a wind energy site in northeast British Columbia. Using the open source software program radR, I identified optimal values for input criteria to automatically detect and track these migrants with high accuracy from the digital radar data, when compared to known, manually-tracked targets (R²= 0. 94). The program was also effective in {{reducing the amount of}} insects that were detected and tracked. Use of the auto-tracking software also increased the number of detected targets by over 500 % compared to the real-time collection of radar data. Using radR, I analyzed the micro-scale movements of nocturnal migrants during the pre-operational and operational periods of the wind energy project (Chapter 3). Despite variations in wind conditions between seasons, migrants showed consistent directionality and general trends of broad-front migration at aThe original print copy of this thesis may be available here: [URL]...|$|R
40|$|The {{principal}} {{mission of}} the West Valley Demonstration Project (WVDP) is to meet a series of objectives defined in the West Valley Demonstration Project Act (Public Law 96 - 368). Chief among these is the objective to solidify liquid high-level waste (HLW) at the WVDP site into a form suitable for disposal in a federal geologic repository. In 1982, the Secretary of Energy formally selected vitrification as the technology {{to be used to}} solidify HLW at the WVDP. One of the first steps in meeting the HLW solidification objective involved designing, constructing and operating the Vitrification (Vit) Facility, the WVDP facility that houses the systems and subsystems used to process HLW into stainless steel canisters of borosilicate waste-glass that satisfy waste acceptance criteria (WAC) for disposal in a federal geologic repository. HLW processing and canister production began in 1996. The final step in meeting the HLW solidification objective involved ending Vit system operations and shut ting down the Vit Facility. This was accomplished by conducting a discrete series of activities to remove as much residual material as practical from the primary process vessels, components, and associated piping used in HLW canister production before declaring a formal end to Vit system operations. Flushing was the primary method used to remove residual radioactive material from the vitrification system. The inventory of radioactivity contained within the entire primary processing system diminished by conducting the flushing activities. At the completion of flushing activities, the composition of residual molten material remaining in the melter (the primary system component used in glass production) consisted of a small quantity of radioactive material and large quantities of glass former materials needed to produce borosilicate waste-glass. A special system developed during the <b>pre-operational</b> and testing <b>phase</b> of Vit Facility operation, the Evacuated Canister System (ECS), was deployed at the West Valley Demonstration Project to remove this radioactively dilute, residual molten material from the melter before Vit system operations were brought to a formal end. The ECS consists of a stainless steel canister of the same size and dimensions as a standard HLW canister that is equipped with a special L-shaped snorkel assembly made of 304 L stainless steel. Both the canister and snorkel assembly fit into a stainless steel cage that allows the entire canister assembly to be positioned over the melter as molten glass is drawn out by a vacuum applied to the canister. This paper describes the process used to prepare and apply the ECS to complete molten glass removal before declaring a formal end to Vit system operations and placing the Vit Facility into a safe standby mode awaiting potential deactivation...|$|R
40|$|In the {{atmosphere}} {{supercooled liquid water}} (SLW) exists as droplets in clouds and precipitation at subfreezing temperatures down to - 40 C. If supercooled droplets get in contact with aircraft, they freeze and the resulting ice accretion {{may lead to a}} significant modification of aircraft aerodynamics. Supercooled large droplets (SLD) with radii greater than 30 #mu#m are extremely hazardous in that respect. Since current numerical weather prediction models do not forecast SLW and drop-size distributions with sufficient accuracy, the expert systems rely on other methods to deduce the potential icing threat combining numerical model data with observational data. Following the concept of the US-expert system IIDA (Integrated Icing Diagnostic Algorithm) ADWICE, the advanced diagnosis and warning system for aircraft ICing environments, has been developed in joint cooperation of the DLR (Deutsches Zentrum fuer Luft- und Raumfahrt), the DWD and the Institut fuer Meteorologie und Klimatologie (IMUK) at the University of Hannover. Preliminary experiences of the <b>pre-operational</b> <b>phase</b> at the DWD reveal weaknesses. This can be attributed to hardly optimized adaptation of ADWICE to european weather and data sources. Further research and development is needed to improve the system, which is the topic of the dissertation. ADWICE V 2 (version 2), the advanced system of ADWICE V 1 (version 1), provides a forecast and a diagnosis of inflight-icing hazards by the newly developed algorithms using model data of the Lokal-Modell (LM) of the DWD, weather observations and radar data. The developed algorithms potentiate to classify the weather and cloud situation into four different icing scenarios, which make it possible to deduce a drop-size distribution in order to determine icing severity. Further more, ADWICE V 2 processes all available data from the radar and weather observation network using a methodology, which so far has not been used in such a complex way by other systems. (orig.) SIGLEAvailable from TIB Hannover / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|E
40|$|International audienceResearch {{addressing}} air pollution, {{the maintenance}} of the stratospheric ozone layer, and global climate change requires global and long-term monitoring of the vertical distribution of atmospheric ozone at ever-improving resolution and accuracy. Global tropospheric and stratospheric ozone profile measurement capabilities from space have therefore improved substantially over the last two decades, among others with new generation hyperspectral instruments measuring backscattered UV-visible sunlight (GOME, SCIAMACHY, OMI, GOME- 2) and thermal emission (TES, IASI) at the nadir of the satellite. Enhanced versions of those instruments are now being developed within EU’s Copernicus Earth Observation programme: the UV-visible-NIR TROPOMI instrument on board of the mid-afternoon satellite Sentinel- 5 P, to be launched in 2016, and both UV-visible and infrared instruments of the GOME and IASI types on board of the geostationary Sentinel- 4 and polar orbiting Sentinel- 5, to be launched {{at the end of the}} decade. Additionally, stringent climate research user requirements like e. g. the Global Climate Observing System (GCOS) targets call for continuous quality assessment and evolution of ozone data and their associated retrieval algorithms over the whole relevant spatial domain, vertical range, and mission lifetime. The fitness-for-purpose of tropospheric ozone column and ozone profile data products must thus be warily verified by means of in-depth QA/validation studies of the satellite data and associated retrieval algorithms before being used in scientific research and operational applications. To that purpose, an extensive validation system has been developed on the heritage of various validation activities, starting in the 1990 s with the first GOME ozone profile validations and progressively extending up to the current ESA Multi-TASTE Phase F data evolution and Ozone_cci production of multi-mission climate data records on ozone. Currently this validation system is being further consolidated with metrological traceability practices and with generic QA guidelines established within the FP 7 QA 4 ECV project. The end-to-end approach of this system combines preliminary QA/QC procedures, data content studies, in-depth information content studies, information-content based co-location procedures, data homogenisation, and the more traditional data comparisons with respect to reference measurements acquired by ground-based networks of ozonesondes and lidars (NDACC, SHADOZ, WMO GAW). An OSSE system with detailed metrology of the remote sensing data is thereby used to assess the propagation of errors associated with differences in smoothing and with mismatches in space and time between the various measurements. In this paper we briefly describe the principles and implementation of this QA/validation system, now in <b>pre-operational</b> <b>phase.</b> Through illustrative evaluation activities from ESA’s Ozone_cci project we demonstrate its broad applicability to virtually all ozone (partial) column and profile datasets. We conclude with a perspective on current developments of this system required to address the specific challenges of the upcoming TROPOMI ozone data validation as envisaged in the S 5 PVT AO project CHEOPS- 5 p (Validation of Copernicus HEight-resolved Ozone data Products from Sentinel- 5 P TROPOMI) ...|$|E

