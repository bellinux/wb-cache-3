19|40|Public
50|$|A <b>panorama</b> <b>camera</b> {{and a voice}} {{guide on}} camera for self-portrait were {{introduced}} in a new update that rolled out in April,2014.This update also brought a paternal control for the apps installed in the phone.|$|E
50|$|Pillsbury's career {{spilled over}} into nearly every kind of {{application}} for photography. His career began in 1895 when as a student he documented in one hour with 60 different images the first fraternity rush at Stanford University. Pillsbury studied Mechanical Engineering at Stanford University and is credited with the invention of a specimen slicer (for microscopy) and a circuit <b>panorama</b> <b>camera</b> before leaving college. Two years later he invented the first circuit <b>panorama</b> <b>camera</b> and soon after {{took it to the}} Yukon to capture the opening of the mining fields and towns. By 1900 he had photographed many of the notable features of the Western United States.|$|E
50|$|Since 1986 Neumann photographed {{for various}} {{publishing}} houses in Germany, Austria, France and Switzerland. Neumann mainly {{worked for the}} publisher C. J. Bucher (Munich) while often using the Russian <b>panorama</b> <b>camera</b> Horizont. Several panorama illustrated books were published, including Paris, Vienna, Switzerland, Munich, Germany, Tuscany und Sicily.|$|E
5000|$|... #Caption: Technical {{drawing of}} one of Neubronner's <b>panorama</b> <b>cameras.</b>|$|R
50|$|Luc Vincent, {{director}} of engineering at Google {{and head of}} the team responsible for Street View for the Art Project, stated concern over the quality of <b>panorama</b> <b>cameras</b> his team used to capture gallery and artwork images. In particular, he believes that improved aperture control would enable more consistent quality of gallery images.|$|R
5000|$|Niche camera {{manufacturers}} typically use DNG in new cameras (including a digiscope, <b>panorama</b> <b>cameras,</b> and {{at least}} one movie camera). The article on raw image formats illustrates the complicated relationship between new raw image formats and third-party software developers. Using DNG provides immediate support for these cameras by a large range of software products.|$|R
50|$|He {{arrived in}} Yosemite {{for the first}} time by bicycle in 1895 while still a student in {{mechanical}} engineering at Stanford University. He had been drawn there by stories from an old friend of his mother's Susan B. Anthony, who was then making a tour through California speaking on the issue of women's suffrage. The young man fell in love with Yosemite and in 1897 bought a studio there. But his young wife refused to spend summers in the wilderness and left him. Despondent, he took his newly finished senior project, the first circuit <b>panorama</b> <b>camera,</b> and went to the Yukon where he photographed the opening of the mining towns and fields.|$|E
5000|$|Some {{football}} teams also have songs which are traditionally sung by their fans. The song [...] "You'll Never Walk Alone" [...] from Carousel is associated heavily with Liverpool F.C. and Celtic F.C.. In 1963, {{the song was}} covered by Liverpool group Gerry & The Pacemakers, which in fact prompted the song's adoption by the Kop. At this time, supporters standing on the Spion Kop terrace at Anfield began singing popular chart songs of the day. The mood was captured on camera by a BBC <b>Panorama</b> <b>camera</b> crew in 1964. One year later, when Liverpool faced Leeds in the FA Cup final, the travelling Kop sang the same song and match commentator Kenneth Wolstenholme commended the [...] "Liverpool signature tune". Since the late 1920s, fans of West Ham United F.C. have sung the song [...] "I'm Forever Blowing Bubbles" [...] at both home and away matches. Supporters of Hibernian F.C. are known for singing [...] "Sunshine on Leith" [...] due to the song's composers and performers The Proclaimers being well known Hibernian supporters and the song's reference to Hibernian's home in Leith and as such the song has become an unofficial club anthem. The club {{has in the past}} also played other songs by the pair at its home ground Easter Road, such as [...] "I'm on My Way", though none have the same association with the team that [...] "Sunshine on Leith" [...] does.|$|E
40|$|Verti-Pan Alpha, (vertical <b>panorama</b> <b>camera</b> alpha model) {{constructed}} using {{components of}} a vintage Polaroid MP copy camera, sheet metal, a 65 mm f 5. 6 Rodenstock grandagon-n lens, and a Horseman 6 x 12 black. An exhibition of this series of sculptural cameras, plus a selection {{of black and white}} images that they produced, were featured in a McLean County Art Center exhibit in January 2014. [URL]...|$|E
40|$|SUMMARY: This study {{developed}} a panorama image {{database management system}} (PIDMS) to manage construction-related records. A set of <b>panorama</b> <b>cameras</b> was used to record panorama images and videos for the inspection and management of working schedule, manpower, materials, or machinery. Users can log in as construction site managers, contractors, general users, designers, draftspersons, or system managers through a browsing interface. The system is made according to functions, such as real-time monitoring, image labelling, working drawing browsing, video indexing, and construction recording. Three levels of application were developed...|$|R
50|$|As New York Times art {{reviewer}} Roberta Smith said: “Art Project is {{very much}} a work in progress, full of bugs and information gaps, and sometimes blurry, careering virtual tours.” Though the second generation platform solved some technological issues, Google plans to continue developing additional enhancements for the site. Future improvements currently under consideration include: upgrading <b>panorama</b> <b>cameras,</b> more detailed web metrics, and improved searchability through metatagging and user-generated metatagging. Google is also considering the addition of an experimental page to the platform, to highlight emerging technologies that artists are using to showcase their works.|$|R
40|$|Discussion {{of some of}} the {{procedures}} employed and results obtained in using photogrammetry in the Apollo lunar geology exploration program. The most modern approach to lunar photogrammetry came from orbit. The introduction into lunar orbit operations of precision metric and <b>panorama</b> <b>cameras</b> and laser altimeters provided the photographs and data through which many of the thitherto unsolvable local and lunar-wide control problems became amenable to solution. From the results obtained, there is shown to have emerged a described pattern of evolutionary sequence through which the moon has passed over the last 4. 5 billion years...|$|R
40|$|Title from {{label on}} back of print.; This {{photograph}} {{was taken as}} part of John Meredith's "Real Folk" Australian folklore recording project.; P 1 / 104 B; Also available in an electronic version via the Internet at: [URL] P 1 / 104 B. "Talented Rex divides his spare time between playing his accordions and making mural-sized colour photographs with an antique Kodak <b>panorama</b> <b>camera.</b> Like the other Schillers, he is descended from Germanic stock. " [...] Typed on card enclosed with print...|$|E
40|$|In {{order to}} solve the {{automation}} of 3 D indoor mapping task, a low cost multi-sensor robot laser scanning system is proposed in this paper. The multiple-sensor robot laser scanning system includes a <b>panorama</b> <b>camera,</b> a laser scanner, and an inertial measurement unit and etc., which are calibrated and synchronized together to achieve simultaneously collection of 3 D indoor data. Experiments are undertaken in a typical indoor scene and the data generated by the proposed system are compared with ground truth data collected by a TLS scanner showing an accuracy of 99. 2...|$|E
40|$|The paper {{describes}} the acquisition and rectification of high-resolution {{images of a}} valuable stone mosaic {{in the city of}} Oldenburg. The piece of art is located on an outer wall of a school building, hence image recording had to be done under daylight conditions. We have used a 16 mega-pixel camera Kodak DCS 645 M for the acquisition of nine overlapping images of the whole object. In addition, the <b>panorama</b> <b>camera</b> KST EyeScan M 3 was used to acquire the complete mosaic in one scan. For the Kodak camera the image resolution in object space was about 0. 6 mm per pixel while the panoramic image yields 1. 4 mm per pixel. The geometric accuracy of the mosaic reconstruction is specified to about 2 mm. Previous investigations have shown that the digital camera provides a geometric accuracy potential of better than 1 : 100000 if an appropriate camera model and calibration is available and well-defined point targets are used. The color quality of the camera is excellent. The geometric accuracy of the <b>panorama</b> <b>camera</b> is lower since the mechanical drives are less accurate and harder to calibrate. However, since the accuracy specifications of the project are not very high both cameras should provide a sufficient precision. The object is assumed to be flat within a few millimeters. A number of control points have been measured by theodolite observations. They are used to calculate image orientations and/or parameters for projective transformations. The images of the digital camera were processed individually, each resulting in a separate rectification with respect to a global object coordinate system. The panorama image could be oriented by space resection. The final image mosaic was then generated by stitching the separate image...|$|E
40|$|The author {{shows the}} {{enhancement}} of abstract and “sterile” VRML-scenes by integration of panoramas, made from stitched photographs or special <b>panorama</b> <b>cameras.</b> The problem of having only one {{point of view in}} a photograph taken from a fixed point can be solved by using a defined, invisible “box” in vrml, which allows a movement of just a few meters, but also turning around and getting a kind of Augmented Reality. The next development of interaction not only in movement is the interactive integration of vr-objects by using EAI-Java-Tools...|$|R
50|$|Mi-4 with <b>Panorama</b> 360 cin <b>camera</b> system {{produced}} by conversion.|$|R
5000|$|... #Caption: Valbray EL1 {{limited edition}} in black for 100th anniversary of Leica <b>camera</b> <b>panorama.</b>|$|R
40|$|Abstract:- Video {{compression}} {{is vital}} for efficient storage and transmission of digital video signal. The hybrid video coding techniques based on predicative and transform coding are adopted by many video-coding standards such as ISO MPEG- 1 / 2 and ITU-T H. 261 / 262 / 263, owing to its high compression efficiency. Motion compensation is a predictive technique for exploiting the temporal redundancy between successive frames of video sequence. Block matching is a simple and effective motion estimation method to obtain the motion compensation prediction. In <b>panorama</b> <b>camera</b> motion, we can enhance the bit rate and minimize the encoding time by calculating the largest block This minimizes the number of motion vectors required for P picture coding which improves the bit rate by average ratio 1 : 975, which is the ratio between the largest block and the equivalent blocks in the standard MPE...|$|E
40|$|Efficient and {{comfortable}} acquisition of large 3 D scenes {{is an important}} topic for many current and future applications like cultural heritage, web applications and 3 DTV and therefore it is a hot research topic. In this paper we present a new mobile 3 D model acquisition platform. The platform uses 2 D laser range scanners for both self localization by scan matching and geometry acquisition and a digital <b>panorama</b> <b>camera.</b> 3 D models are acquired just by moving the platform around. Thereby, geometry is acquired continuously and color images are taken in regular intervals. After matching, the geometry is represented as unstructured point cloud which can then be rendered in several ways, for example using splatting with view dependent texturing. The work presented here is still "in progress", but {{we are able to}} present some first reconstruction results of indoor and outdoor scenes...|$|E
40|$|Imagine a 3 D Television {{system where}} the user can freely choose {{his point of}} view in {{real-time}} during watching three-dimensional movies or documentaries. Clearly, one key component to 3 D movie making will be the 3 D model acquisition process for background models where the actors can be put to life in 3 D. In this paper we present a new mobile 3 D model acquisition platform to reach this dream. The platform uses 2 D laser range scanners for both self localization by scan matching and geometry acquisition and a <b>panorama</b> <b>camera.</b> 3 D models are acquired just by moving the platform through the scene to be captured. Thereby, geometry is acquired continuously and color images are taken in regular intervals. Two data processing flows are presented, a laser range scanner based flow and an omnidirectional stereo vision flow based on graph cuts. Both flows result in textured 3 D point clouds – various examples and a comparison are given in this paper...|$|E
5000|$|The {{surveying}} {{activities in}} 1921 allowed {{the creation of}} maps which were a pre-condition for the 1922 expedition. John Noel took {{on the role of}} official expedition photographer. He took with him three movie <b>cameras,</b> two <b>panorama</b> <b>cameras,</b> four sheet cameras, one stereo camera and five so called [...] "vest pocket Kodaks". The last named were small cameras that were of light weight and size to be taken by the mountaineers to great heights. These cameras were intended to allow climbers to document a possible summit success. Additionally they had on their way a special [...] "black tent" [...] for photographic works. Thanks to Noel's efforts, many photographs and one movie chronicled the expedition.|$|R
40|$|In the future, {{new kinds}} of ultrahigh-resolution sensors and ultralarge {{displays}} will be available that will enable new production methods and immersive services in the home. At the Fraunhofer Heinrich Hertz Institute (HHI), a 6000 x 2000 (6 k) pixels multicamera system (Omnicam) and a 7000 x 2000 pixels multiprojection system have been developed and different ultrahigh-resolution productions can already be viewed at the HHI's Tomorrow's immersive Media Experience (Time) Lab. The philosophy behind these activities is a “format agnostic” production system, which enables the merging of video signals from different sensors with different spatial and temporal resolution, such as from <b>panorama</b> <b>cameras</b> at 6 k resolution and from high-speed cameras at high-definition resolution. Sophisticated three-dimensional image processing, in combination with appropriate metadata, will then allow combination of these different sources and subsequent extraction of sections from the complete image at a desired size and spatial/temporal resolution. This work will be continued within the Format-Agnostic Script-based Interactive Experience, a project of the European Union's Seventh Framework Programme...|$|R
40|$|The <b>panorama</b> <b>cameras</b> onboard the Yutu Rover of the Chang&# 39;E- 3 lunar mission {{acquired}} {{hundreds of}} high-resolution color {{images of the}} lunar surface and captured the first in situ lunar opposition effect (OE) since the Apollo era. We extracted the phase curve and the color ratio in three bands with the phase angle range from 2 degrees to 141 degrees. Photometric inversions using the Hapke model reveal that submicroscopic dusts {{are present in the}} landing area and both the coherent backscattering and the shadow hiding are responsible for the strong OE. Compared with spaceborne measurements, the grains in the landing site are brighter, more transparent, and appear to be better crystallized than the average maria basaltic grains. The results show that the phase-reddening effect appears to be present in the in situ phase curves. The current phase curve can be used as the ground-truth validations of any future spaceborne phase curve measurement over the landing site region...|$|R
40|$|This paper proposes an {{approach}} for solving the parameter determination {{problem for a}} stereoscopic <b>panorama</b> <b>camera.</b> Image acquisition parameters have to be calculated under given constraints defined by application requirements, the image acquisition model, and specifications of the targeted 3 D scenes. Previous studies on stereoscopic panorama imaging, such as [IYT 92, MB 95 b, WHK 99 b, PPB 00, SKS 99, HWK 01, Sei 01, WP 01], pay great attention on how a proposed imaging approach supports a chosen area of application. The image acquisition parameter determination problem {{has not yet been}} dealt with in these studies. The lack of guidance in selecting image acquisition parameters affects the validity of results obtained for subsequent processes [WHK 00]. Our approach towards parameter determination allows to satisfying commonly demanded 3 D scene visualization/reconstruction application requirements: proper scene composition in resultant images; adequate sampling at a particular scene distance; and desired stereo quality (i. e. depth levels) over a diversity of scenes of interest. The paper details the models, constraints and criteria used for solving th...|$|E
40|$|The {{purpose of}} this study was to examine the {{effectiveness}} of a technology-enhanced unit on slope in algebra. The technology used in the study was the Topological <b>Panorama</b> <b>Camera</b> (Topocam). The research questions explored the learning and transfer of knowledge about slope and the engagement level of students during Topocam learning activities. The Topocam is a computer-controlled camera that moves on a modular track while it scans a scene through a vertical slit. Students can program the speed of the camera and frequency of pictures. They then witness the results of time and motion in the image created by the camera. Data for this study were collected from a pretest/posttest, as well as from observations of indicators of engaged learning. The research population consisted of 46 students from three classes of Algebra I students. Three classroom teachers each taught a unit on slope, while a fourth teacher conducted the activities with the Topocam for all the classes. The classroom activities focused on the concept of slope as a rate of change utilizing coordinate grids. The Topocam activities involved students in collaborativel...|$|E
40|$|The paper {{presents}} a historical review of panorama image techniques with {{special emphasis on}} photogrammetric applications. The {{first part of the}} paper deals with the anatomic and visual properties of human vision where the use of panoramic views is evident for monitoring the environment, recognition, avoidance of collision etc. Naturally, the use of photographic panoramic images became very popular already in the 19 th century. The paper presents some interesting panorama image acquisition and viewing facilities of the beginning of panorama photography. Several photogrammetric applications are known in the field of close-range imaging and aerial imagery as well. They have always been used in very few and specific fields only. Analog <b>panorama</b> <b>camera</b> have been developed which have been used for photogrammetry and other professional applications. Different techniques are known for the acquisition of cylindrical and spherical images which are addressed by the report. Today’s increasing interest in panorama imagery is mainly initiated by simple digital cameras and simple stitching methods for generating panorama images. The fields of application vary from in-room monitoring, video conferencing, tourist purposes, weather forecast to mobile mapping and 3 -D reconstruction. Today's high-level panorama scanners can produce images of highest resolution and superb quality. The combination with 3 -D laser-scanners offers new potentials and applications. ...|$|E
50|$|To take a <b>panorama,</b> the <b>camera</b> is rotated at fixed angular increments, {{taking an}} image at each point. These images {{can then be}} {{assembled}} (stitched) using stitching software, which allows the images to be aligned and combined into a single seamless panoramic image, either automatically (using image analysis) or manually (with user supplied control points). The final panoramic image can then be viewed or printed as a flat image or viewed interactively using specific playback software.|$|R
40|$|Abstract: The paper aims {{to present}} work of {{partners}} {{within the scope}} of group of problems under the common title “Audiovisual scene rendering and interaction”. First section covers the Rendering Engine software with capabilities of rendering complex hybrid scenes for immersive environments. The client-server architecture of the engine is described and then a number of standard plug-ins extending the functions of the system are presented. Section 2 describes an interactive system for navigation through highresolution cylindrical panoramas. Topics such as acquisition of <b>panoramas,</b> <b>camera</b> calibration and occluding objects removal, are covered in detail. Next section provides a short description of the specialized VRML viewer – a piece of software to visualize large environments. And finally last section is devoted to a novel algorithm for spatialisation of sound sources in 3 D space. Unlike known techniques e. g. finite elements or beam tracing and radiosity, the proposed algorithm is based on a geometric pre-computation of a tree-like topological representation of the reflections in the environment (beam tree) through spatial subdivision techniques. The beam tree is then used for real-time auralization through a simple look-up of which beams pass through the auditory points...|$|R
5000|$|After {{leaving the}} Royal Marines in 1947, Wheeler joined the BBC, {{initially}} as a sub-editor at the Latin American {{division of the}} World Service. Wheelers long career as a foreign correspondent began with a three-year posting to Berlin in 1950, partly thanks to his fluency in German. He subsequently returned to the UK, becoming a producer on the fledgling current affairs series Panorama in 1956. As part of Panoramas team, he travelled to Hungary to cover what would {{become known as the}} Hungarian Uprising. Taking <b>Panoramas</b> <b>camera</b> into the country, despite being told not to, he filmed the jubilant Hungarian reaction to the rebellion. Just hours after Wheeler returned to Britain, Russia re-entered Hungary and crushed the revolt. [...] Having declined an offer to become the programmes editor, he was later assigned to New Delhi (where he reported extensively on the 1959 Tibetan uprising) and Washington, D.C., where he covered the American Civil Rights Movement and the Watergate scandal between 1965 and 1973. In the later years of his television career he was the American correspondent of Newsnight. He returned to Berlin when the Wall was built and remained there for several years with his Indian-born wife.|$|R
40|$|Photogrammetric {{imaging and}} {{measurement}} techniques {{are widely used}} for capturing three-dimensional scenes in sciences and arts. Traditional approaches performing extensive calculations on multiple images {{are more and more}} replaced by higher integrated and faster operating measurement devices. This paper presents a MEMS-based system for distance measurement that can be integrated into a commercially available <b>panorama</b> <b>camera</b> and will add three-dimensional measuring capabilities. This combination is very suitable to displace the current procedural manner using different instruments to acquire three-dimensional data {{on the one hand and}} texture on the other hand. The data acquisition is simplified and extensive calibration and data transformations is no longer needed. Thereby the accurate allocation between texture and distance data is firmed by design. This work outlines the optical concept to couple both measuring systems into one optical path. While texture is captured line wise, the distance is acquired sequentially. Integration of both functionalities into one housing and one optical system design requires miniaturized components for deflection of the measurement beam. One solution is to use a resonant MEMS scanning mirror. The paper describes the resulting optical setup in detail. The integrated construction principle induces special requirements for the LIDAR distance measuring method used here. In order to ensure eye safety, the measuring light beam is limited to low power signals. The contribution also will present an approach for processing low level signals and performing high measuring rates...|$|E
40|$|This paper {{improves}} {{the method of}} the traditional 5 -point relative pose estimation algorithm, and proposes a relative pose estimation algorithm which is suitable for spherical panoramic images. The algorithm firstly computes the essential matrix, then decomposes the essential matrix to obtain the rotation matrix and the translation vector using SVD, and finally the reconstructed three-dimensional points are used to eliminate the error solution. The innovation of the algorithm lies the derivation of panorama epipolar formula {{and the use of}} the spherical distance from the point to the epipolar plane as the error term for the spherical panorama co-planarity function. The simulation experiment shows that when the random noise of the image feature points is within the range of pixel, the error of the three Euler angles is about 0. 1 &# 176;, and the error between the relative translational displacement and the simulated value is about 1. 5 &# 176;. The result of the experiment using the data obtained by the vehicle <b>panorama</b> <b>camera</b> and the POS shows that:the error of the roll angle and pitch angle can be within 0. 2 &# 176;, the error of the heading angle can be within 0. 4 &# 176;, and the error between the relative translational displacement and the POS can be within 2 &# 176;. The result of our relative pose estimation algorithm is used to generate the spherical panoramic epipolar images, then we extract the key points between the spherical panoramic images and calculate the errors in the column direction. The result shows that the errors is less than 1 pixel...|$|E
40|$|Microscopic imaging allows {{to study}} the fine-scale texture and {{morphology}} of the cometary surface. The analysis supplements the surface mapping by the orbital Narrow Angle Camera at the landing site of the Rosetta lander systems. The microstructure of the cometary surface is almost unknown and of high interest. The texture influences several physical properties of the comet like surface temperature, heat and gas flow through the surface, density of the surface layer, thermal diffusion and activity behavior. From theoretical models {{about the origin of}} comets and from GIOTTO measurements one can expect dust grains containing organic components in the micron to millimeter range. These particles can becemented and form a coherent crust. Although it will be less likely to see exposed ice deposits at the non-active surface, the presence of ice grains cannot be excluded. Also, low density dust deposits coud be present. For this reason, monitoring of the texture and small scale features with a spatial resolution better than 100 m is recommended. In addition to microscopic study, wide-field imaging of areas {{in the vicinity of the}} lander is necessary both for giving context to the close-up measurements and for supporting other experiments. For this reason a certain panorama imaging capability is also recommended. We propose for the Rosetta lander systems a camera concept which allows to obtain images of the surface with high spatil resolution (better than 50 m/pix) and a moderate field of view at infinity. Spectral capabilities can be achieved by means of spectral filters in the VIS-NIR range. As possible alternatives, a stand-alone telemicroscope and a stand-alone <b>panorama</b> <b>camera</b> will be discussed...|$|E
40|$|Image-based mobile mapping systems {{enable the}} {{efficient}} acquisition of georeferenced image sequences, which can later be exploited in cloud-based 3 D geoinformation services. In {{order to provide}} a 360 ° coverage with accurate 3 D measuring capabilities, we present a novel 360 ° stereo panoramic camera configuration. By using two 360 ° <b>panorama</b> <b>cameras</b> tilted forward and backward in combination with conventional forward and backward looking stereo camera systems, we achieve a full 360 ° multi-stereo coverage. We furthermore developed a fully operational new mobile mapping system based on our proposed approach, which fulfils our high accuracy requirements. We successfully implemented a rigorous sensor and system calibration procedure, which allows calibrating all stereo systems with a superior accuracy {{compared to that of}} previous work. Our study delivered absolute 3 D point accuracies in the range of 4 to 6 cm and relative accuracies of 3 D distances in the range of 1 to 3 cm. These results were achieved in a challenging urban area. Furthermore, we automatically reconstructed a 3 D city model of our study area by employing all captured and georeferenced mobile mapping imagery. The result is a very high detailed and almost complete 3 D city model of the street environment...|$|R
2500|$|Some stock {{applications}} in AOSP code that were formerly used by {{earlier versions of}} Android, such as Search, Music, and Calendar, have been abandoned by Google in favor of non-free replacements distributed through Play Store (Google Search, Google Play Music, and Google Calendar) that are no longer open-source. Moreover, open-source variants of some applications also exclude functions that are present in their non-free versions, such as Photosphere <b>panoramas</b> in <b>Camera,</b> and a Google Now page on the default home screen (exclusive to the proprietary version [...] "Google Now Launcher", whose code is embedded within that of the main Google application).|$|R
40|$|Cities are {{invaded by}} a variety of {{synthetic}} representations, as they can be explorer or virtually visited by the omnipresent Google Earth, as well as interactive maps, digital reconstructions, photographed ours or <b>panoramas,</b> RT <b>cameras,</b> etc. Furthermore, they can be hosted at websites complemented by multimedia, which allow, with little time and effort, have a preview that conditions us before the in situ experience of the real places. Besides the general use that can be made of these powerful media, we consider the potential influence that they cause in the disciplines that are involved with the urban space...|$|R
