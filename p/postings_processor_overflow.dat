0|14|Public
40|$|Detecting {{arithmetic}} overflow during summation {{operations is}} vital to ensuring correct and secure behavior of many types of code. For example, applying transformations to signed integer pixel co-ordinates without any overflow detection may result in pixels rendering at unexpected negative co-ordinates, summing a large array of signed or unsigned integers without overflow detection can result in bogus totals, or performing arithmetic operations on packed bitfields without overflow detection could result in corruption of data in adjacent bitfields. A traditional way to detect arithmetic overflow is to insert specific checks of the host <b>processor’s</b> <b>Overflow</b> arithmetic condition flag after each arithmetic operation to detect signed integer overflow, or {{a check of the}} host processor’...|$|R
5000|$|The [...] "SO" [...] input pin, when asserted, {{will set}} the <b>processor's</b> <b>{{overflow}}</b> status bit (deasserting it does not clear the overflow bit, however). This {{can be used by}} a high-speed polling device driver, which can poll the hardware once in only three cycles by using a Branch-on-oVerflow-Clear (BVC) instruction that branches to itself. For example, the Commodore 1541 and other Commodore floppy disk drives use this technique to detect without delay whether the serializer is ready to accept or provide another byte of disk data. Obviously great care must be used in the device driver and the associated system design, as spurious assertion of the overflow bit could ruin arithmetic processing.|$|R
5000|$|At {{one time}} {{this sort of}} hybrid {{approach}} was common in disk and network drivers where there was not DMA or significant buffering available. Because the desired transfer speeds were faster even than could tolerate the minimum four-operation per-datum loop (bit-test, conditional-branch-to-self, fetch, and store), the hardware would often be built with automatic wait state generation on the I/O device, pushing the data ready poll out of software and onto the processor's fetch or store hardware and reducing the programmed loop to two operations. (In effect using the processor itself as a DMA engine.) The 6502 processor offered an unusual means to provide a three-element per-datum loop, as it had a hardware pin that, when asserted, would cause the <b>processor's</b> <b>Overflow</b> bit to be set directly. (Obviously {{one would have to}} take great care in the hardware design to avoid overriding the Overflow bit outside of the device driver!) ...|$|R
50|$|In {{computer}} <b>processors,</b> the <b>overflow</b> flag (sometimes called V flag) {{is usually}} a single bit in a system status register used to indicate when an arithmetic overflow has occurred in an operation, indicating that the signed two's-complement result would not fit {{in the number of}} bits used for the operation (the ALU width). Some architectures may be configured to automatically generate an exception on an operation resulting in overflow.|$|R
40|$|Efficient task {{management}} in a hypercube multiprocessor becomes difficult due to system overflow, where an incoming job cannot be allocated {{in spite of}} a sufficient number of free <b>processors.</b> <b>Overflow</b> occurs either due to the inability of recognizing a free subcube or due to external fragmentation. Previous research has been devoted to enhance the subcube recognition ability, but the consequent performance improvement is not significant. Alternatively, task migration and different job scheduling disciplines like scan and lazy have been proposed to boost the hypercube performance. Despite the performance enhancement, however, they either incur tremendous overhead or violate the fairness rule. In this paper, we propose an allocation strategy that tries to scale down an incoming job size if it cannot fit into a fragmented hypercube. We call it limit allocation. We discuss three simple schemes, Limit-k, Greedy and Average. We conduct both analysis and simulation to characterize and compare various allocation policies. An M/M/m queueing model is developed to predict the behavior of buddy, free list and limit-k policies. Simulation study shows that the two adaptive schemes, greedy and average, outperforms all other schemes reported so far in literature. Index terms - Hypercube multiprocessor, job scheduling, M/M/m queueing model, performance evaluation, processor allocation. 1 This research {{was supported in part by}} the National Science Foundation under Grant No. MIP- 9104485. ...|$|R
50|$|The {{overflow}} flag {{is typically}} changed by all arithmetic operations, including compare instructions (equivalent to a subtract instruction without storing the result). In many <b>processor</b> architectures, the <b>overflow</b> flag is cleared by bitwise operations (and, or, xor, not), possibly including shifts and rotates, {{but it may}} also be left undefined by these. Instructions such as multiply and divide often leave the flag undefined, or affected by the last partial result.|$|R
40|$|The {{quest to}} make Residue Number System (RNS) based {{processors}} a reality, has made researchers to continue seeking solutions {{to some of}} the limiting factors of RNS based <b>processor</b> realization. <b>Overflow</b> detection and Reverse Conversion are some of the limiting factors in RNS implementation. In this paper, we propose an overflow detection scheme with a residue to binary converter for the moduli set {,}. Our proposal detects overflow for the sum of operands by distributing the numbers in the system dynamic range into groups. In the conversion segment, the proposal utilizes the Remainder Theorem (RT) in order to convert any RNS number into its decimal equivalent. Our scheme performs dual function, i. e., it detects overflow and does reverse conversion. Theoretical analysis shows that the proposed scheme performs reverse conversion and detects overflow faster than previously proposed schemes and requires lesser hardware resources...|$|R
40|$|AbstractWe offer a {{reference}} model for nested transactions {{at the level}} of memory accesses, and sketch possible hardware architecture designs that implement that model. We describe both closed and open nesting. The model is abstract in that it does not relate to hardware, such as caches, but describes memory as seen by each transaction, memory access conflicts, and the effects of commits and aborts. The hardware sketches describe approaches to implementing the model using bounded size caches in a <b>processor</b> with <b>overflows</b> to memory. In addition to a model that will support concurrency within a transaction, we describe a simpler model that we call linear nesting. Linear nesting supports only a single thread of execution in a transaction nest, but may be easier to implement. While we hope that the model is a good target to which to compile transactions from source languages, the mapping from source constructs to nested transactional memory {{is beyond the scope of}} the paper...|$|R
40|$|We offer a {{reference}} model for nested transactions {{at the level}} of memory accesses, and sketch possible hardware architecture designs that implement that model. We describe both closed and open nesting. The model is abstract in that it does not relate to hardware, such as caches, but describes memory as seen by each transaction, memory access conflicts, and the effects of commits and aborts. The hardware sketches describe approaches to implementing the model using bounded size caches in a <b>processor</b> with <b>overflows</b> to memory. In addition to a model that will support concurrency within a transaction, we describe a simpler model that we call linear nesting. Linear nesting supports only a single thread of execution in a transaction nest, but may be easier to implement. While we hope that the model is a good target to which to compile transactions from source languages, the mapping from source constructs to nested transactional memory {{is beyond the scope of}} the paper. c ○ 2006 Elsevier B. V. All rights reserved...|$|R
40|$|The floating-point {{division}} bug in Intel's Pentium <b>processor</b> and the <b>overflow</b> flag erratum of the FIST {{instruction in}} Intel's Pentium Pro and Pentium II processor {{have demonstrated the}} importance {{and the difficulty of}} verifying floating-point arithmetic circuits. In this paper, we present a "black box" version of verification of FP adders. In our approach, FP adders are verified by an extended word-level SMV using reusable specifications without knowing the circuit implementation. Word-level SMV is improved by using Multiplicative Power HDDs (*PHDDs), and by incorporating conditional symbolic simulation as well as a short-circuiting technique. Based on a case analysis, the adder specification is divided into several hundred implementation-independent sub-specifications. We applied our system and these specifications to verify the IEEE double precision FP adder in the Aurora III Chip from the University of Michigan. Our system found several design errors in this FP adder. Each specifica [...] ...|$|R
40|$|A minimal, bounded {{hardware}} transactional memory im-plementation significantly improves synchronization perfor-mance {{when used}} in an operating system kernel. We add HTM to Linux 2. 4, a kernel with a simple, coarse-grained synchronization structure. The transactional Linux 2. 4 ker-nel can improve performance of user programs {{by as much as}} 40 % over the non-transactional 2. 4 kernel. It closes 68 % of the performance gap with the Linux 2. 6 kernel, which has had significant engineering effort applied to improve scala-bility. We then extend our minimal HTM to a fast, unbounded transactional memory with a novel technique for coordi-nating hardware transactions and software synchronization. Overflowed transactions run in software, with only a mini-mal coupling between hardware and software systems. There is no performance penalty for overflow rates of less than 1 %. In one instance, at 16 <b>processors</b> and an <b>overflow</b> rate of 4 %, performance degrades from an ideal 4. 3 × to 3. 6 ×...|$|R
40|$|The floating-point (FP) {{division}} bug in Intel’s Pentium <b>processor</b> and the <b>overflow</b> flag erratum of the FIST {{instruction in}} Intel’s Pentium Pro and Pentium II processor {{have demonstrated the}} importance {{and the difficulty of}} verifying FP arithmetic circuits. In this paper, we present the verification of FP adders with reusable specifications, using extended wordlevel SMV, which is improved by using the Multiplicative Power HDDs (*PHDDs), and by incorporating conditional symbolic simulation as well as a shortcircuiting technique. Based on the case analysis, the specifications of FP adders are divided into several hundreds of implementation independent subspecifications. We applied our system and these specifications to verify the IEEE double precision FP adder in the Aurora III Chip at the University of Michigan. Our system found several design errors in this FP adder and generated one counterexample for each error within several minutes. A variant of the corrected FP adder is created to illustrate the capability of our system to handle different FP adder designs. For each of FP adders, the verification task finished in 2 CPU hours on a Sun UltraSPARCII server...|$|R

