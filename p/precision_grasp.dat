34|85|Public
30|$|The {{objects are}} usually picked through {{prismatic}} or circular precision grasps [24]. The prismatic <b>precision</b> <b>grasp</b> is a grasp {{in which the}} opposing faces of the target object are grasped with two fingers (or virtual fingers; as there are cases where one surface may be grasped {{by more than one}} fingers, all those fingers can be considered as one virtual finger). The circular <b>precision</b> <b>grasp</b> is a grasp in which the circumference of a spherical or cylindrical object is grasped using three fingers (or virtual fingers).|$|E
40|$|Abstract—Planning a <b>precision</b> <b>grasp</b> for a {{robot hand}} is usuallydecomposedintotwomainsteps. First,asetofcontact pointsovertheobjectsurfacemustbedetermined,ensuring theyallowastablegrasp. Second,theinversekinematicsof therobothandmustbesolvedtoverifywhetherthecontact pointscanactuallybereached. Whereasthefirstproblemhas beenlargelysolvedinageneralposing,thesecondonehasonly beentackledwithlocalconvergencemethods. Thesemethods only provide one {{solution}} to the problem, even if many are possible,anddependingontheinitialestimationtheyuse,they may fail to converge, which results in grasp re-planning in situationswhereitcouldbeavoided. Thispaperovercomesboth issuesbyprovidingacompletemethodtosolvethekinematics ofhuman-likehands. Themethodisabletofindallpossible configurationsthatreachthespecifiedcontactpoints,evenwhen positive-dimensionalsetsofsuchconfigurationsarepossible. I...|$|E
40|$|Does {{the mirror}} system affect {{the control of}} speech? This issue was {{addressed}} in behavioral and Transcra- nial Magnetic Stimulation (TMS) experiments. In behavioral experiment 1, participants pronounced the syllable /da/ while observing (1) a hand grasping large and small objects with power and precision grasps, respectively, (2) a foot interacting with large and small objects and (3) differently sized objects presented alone. Voice formant 1 was higher when observing power as compared to <b>precision</b> <b>grasp,</b> whereas it remained unaffected by observation of {{the different types of}} foot interaction and objects alone. In TMS experiment 2, we stimulated hand motor cortex, while participants observed the two types of grasp. Motor Evoked Potentials (MEPs) of hand muscles active during the two types of grasp were greater when observing power than <b>precision</b> <b>grasp.</b> In experiments 3 – 5, TMS was applied to tongue motor cortex of participants silently pronouncing the syllable /da/ and simultaneously observing power and precision grasps, pantomimes of the two types of grasps, and differently sized objects presented alone. Tongue MEPs were greater when observing power than <b>precision</b> <b>grasp</b> either executed or pantomimed. Finally, in TMS experiment 6, the observation of foot interaction with large and small objects did not modulate tongue MEPs. We hypothesized that grasp observation activated motor commands to the mouth {{as well as to the}} hand that were congruent with the hand kinematics implemented in the observed type of grasp. The commands to the mouth selectively affected postures of phonation organs and consequently basic features of phonological units...|$|E
5000|$|... #Caption: Thumb {{and index}} finger during pad-to-pad <b>precision</b> <b>grasping.</b>|$|R
5000|$|... #Caption: Thumb {{and index}} finger of right hand during pad-to-pad <b>precision</b> <b>grasping</b> in ulnar view.|$|R
40|$|In {{the past}} decade, {{functional}} neuroimaging has proved extremely useful in mapping the human motor circuits involved in skilled hand movements. However, one major drawback {{of this approach}} is the impossibility to determine the exact contribution of each individual cortical area to <b>precision</b> <b>grasping.</b> Because transcranial magnetic stimulation (TMS) makes it possible to induce a transient 'virtual' lesion of discrete brain regions in healthy subjects, it has been extensively used to provide direct insight into the causal role of a given area in human motor behaviour. Recent TMS studies have allowed us to determine the specific contribution, as well as the timing and the hemispheric lateralisation, of distinct parietal and frontal areas to the control of both the kinematics and dynamics of <b>precision</b> <b>grasping.</b> Moreover, recent researches have shown that the same cortical network may contribute to language and number processing, supporting the existence of tight interactions between processes involved in cognition and actions. The aim {{of this paper is to}} offer a concise overview of recent studies that have investigated the neural correlates of <b>precision</b> <b>grasping</b> and the possible contribution of the motor system to higher cognitive functions such as language and number processing...|$|R
40|$|This paper {{presents}} the graspability map, {{a novel approach}} to represent for a particular object the positions and orientations that a given mechanical hand can adopt to achieve a force closure <b>precision</b> <b>grasp.</b> The algorithm {{is based on the}} intersection between the fingertip workspaces and the object, plus the verification of a necessary condition for force closure grasps. The maps are computed offline and can be used for comparing the grasp capabilities of different mechanical hands with respect to some benchmark objects. The maps have also potential applications in online grasp and manipulation planning...|$|E
40|$|Abstract—This paper {{addresses}} a largely open problem in haptic simulation and rendering: contact force and deformation modeling for haptic simulation of grasping a deformable object with a realistic virtual human hand, especially in power grasps. The virtual hand model consists of meshes of realistic shapes for the finger links and palm of a hand. We tackle {{the problem by}} adopting the non-linear contact force model and the beam-skeleton model for global shape deformation introduced in [5]. The results verify the efficiency of contact force and deformation modeling for both power grasp and <b>precision</b> <b>grasp</b> of deformable objects with reasonable realism. M I...|$|E
30|$|As {{shown in}} Fig.  3, typical {{patterns}} {{can be found}} in the arrangement of objects (shelved, C_h; stacked, C_v; displayed, C_f). With these arrangement patterns, because objects are in contact with or in close proximity to each other, the picking surfaces of the object (for the prismatic <b>precision</b> <b>grasp)</b> are hidden. Therefore, when humans are picking an object for a specific arrangement pattern, a specific picking strategy is often observed as shown in Fig.  4. First, to obtain the picking surfaces, the target object is manipulated through a grasp-less manipulation (tilting for shelved and displayed objects, and sliding for stacked objects). Then the picking surfaces obtained are grasped.|$|E
40|$|In humans, both {{clinical}} and functional imaging studies have evidenced {{the critical role}} played by the posterior parietal cortex, and particularly by the anterior intraparietal area (AIP), in skilled hand movements. However, the exact contribution of AIP to <b>precision</b> <b>grasping</b> remains debated. Here we used transcranial magnetic stimulation (TMS) to induce virtual lesions of the left and/or right AIP in subjects performing a grip-lift task with either hand. We found that, during movement preparation, a virtual lesion of AIP had distinct consequences on <b>precision</b> <b>grasping</b> of either hand depending on its time of occurrence: TMS applied 270 - 220 ms before the fingers contacted the manipulandum altered specifically the hand shaping, whereas lesions induced 170 - 120 ms before contact time only affected the grip force scaling. The lateralization of these two processes in AIP is also strikingly different: whereas a bilateral lesion of AIP was necessary to impair hand shaping, only a unilateral lesion of the left AIP altered the grip force scaling in either hand. The present study shows that, during movement preparation, AIP is responsible for processing two distinct, temporally dissociated, <b>precision</b> <b>grasping</b> parameters, regardless of the hand in use. This indicates that the contribution of AIP to hand movements is "effector-independent," a finding that may explain the invariance of grasping movements performed with either hand...|$|R
40|$|Subcortical lesions {{have been}} {{simultaneously}} implicated in both real and simulated movement deficits. However, {{the analysis of}} the simulated opposition axis in <b>precision</b> <b>grasping</b> reveals that, in individuals with idiopathic bilateral Parkinson's disease motor imagery is impaired and that execution of overt movements is spared. This constitutes the first lesion observation congruent with the anatomical and functional dichotomy between real and simulated movements seen in experimental studies. These results underline the modality-specific nature of motor imagery and show that subcortical damage differentially impacts on motor activity...|$|R
40|$|Deep {{learning}} is an established framework for learning hierarchical data representations. While compute power is in abundance, {{one of the}} main challenges in applying this framework to robotic grasping has been obtaining the amount of data needed to learn these representations, and structuring the data to the task at hand. Among contemporary approaches in the literature, we highlight key properties that have encouraged the use of deep learning techniques, and in this paper, detail our experience in developing a simulator for collecting cylindrical <b>precision</b> <b>grasps</b> of a multi-fingered dexterous robotic hand...|$|R
40|$|Abstract This paper {{investigates the}} {{possibility}} of converting grasped objects from precision grasps to power grasps using a variable transmission ratio for an underac-tuated finger. Reconfiguration happens when the <b>precision</b> <b>grasp</b> converts to a power grasp, {{because the number of}} contact points changes which changes the topology of the grasp. To this effect, a variable radius pulley was designed. A simulation study is presented to analyse grasping behaviour and a potential energy method is used to predict the equilibrium positions of finger and object. With this method stable and unstable equilibrium positions are determined. This is followed by an experiment to verify the theory. This paper is a first step in dextrous manipulation with large movements of objects using underactuated fingers...|$|E
40|$|There {{have been}} {{numerous}} attempts to develop anthropomorphic robotic hands with varying levels of dexterous capabilities. However, these robotic hands often suffer {{from a lack of}} comprehensive understanding of the musculoskeletal behavior of the human thumb with integrated foldable palm. This paper proposes a novel kinematic model to analyze the importance of thumb-palm embodiment in grasping objects. The model is validated using human demonstrations for five <b>precision</b> <b>grasp</b> types across five human subjects. The model is used to find whether there are any co-activations among the thumb joint angles and muskuloskeletal parameters of the palm. In this paper we show that there are certain pairs of joints that show stronger linear relationships in the torque space than in joint angle space. These observations provide useful design guidelines to reduce control complexity in anthropomorphic robotic thumbs...|$|E
40|$|Abstract — Dexterous in-hand {{manipulation}} of objects bene-fits from {{the ability of}} a robot system to generate precision grasps. In this paper, we propose a concept of Fingertip Space and its use for <b>precision</b> <b>grasp</b> synthesis. Fingertip Space is a representation that takes into account both the local geometry of object surface as well as the fingertip geometry. As such, it is directly applicable to the object point cloud data and it establishes a basis for the grasp search space. We propose a model for a hierarchical encoding of the Fingertip Space that enables multilevel refinement for efficient grasp synthesis. The proposed method works at the grasp contact level while not neglecting object shape nor hand kinematics. Experimental evaluation is performed for the Barrett hand considering also noisy and incomplete point cloud data. I. INTRODUCTION AND CONTRIBUTION...|$|E
40|$|Grasp quality {{measures}} have been studied for long time, given their importance to evaluate the goodness/convenience of a grasp made with a robotic hand. However, the application of these quality measures to the grasps made by humans has just recently received some attention. This paper presents an experimental evaluation and comparison of different measures, using data obtained with a sensorized object. The experiment compares power <b>grasps</b> and <b>precision</b> <b>grasps</b> obtained with different number of fingers. The results intend to be {{a guide to the}} application of such qualities in the evaluation of robotic grasp actions. ...|$|R
40|$|The {{purpose of}} this paper is to analyze in some depth the {{kinematic}} behaviour of the human hand, in order to obtain simplified human hand models with the minimum and optimal number of Degrees of Freedom (DoF), and thus achieving an efficient manipulation task. The statistical analysis is carried out using Principal Components Analysis (PCA). Power and <b>precision</b> <b>grasps</b> are obtained with the use of a Cyberglove and a human hand model with 24 DoF. Finally, these experiments are used to evaluate the best DoF for an appropriate manipulation...|$|R
40|$|Small-object {{manipulation}} {{is essential}} in numerous human activities, although its neural bases are still essentially unknown. Recent functional imaging {{studies have shown that}} <b>precision</b> <b>grasping</b> activates a large bilateral frontoparietal network, including ventral (PMv) and dorsal (PMd) premotor areas. To dissociate the role of PMv and PMd in the control of hand and finger movements, we produced, by means of transcranial magnetic stimulation (TMS), transient virtual lesions of these two areas in both hemispheres, in healthy subjects performing a grip-lift task with their right, dominant hand. We found that a virtual lesion of PMv specifically impaired the grasping component of these movements: a lesion of either the left or right PMv altered the correct positioning of fingers on the object, a prerequisite for an efficient grasping, whereas lesioning the left, contralateral PMv disturbed the sequential recruitment of intrinsic hand muscles, all other movement parameters being unaffected by PMv lesions. Conversely, we found that a virtual lesion of the left PMd impaired the proper coupling between the grasping and lifting phases, as evidenced by the TMS-induced delay in the recruitment of proximal muscles responsible for the lifting phase; lesioning the right PMd failed to affect dominant hand movements. Finally, an analysis of the time course of these effects allowed us to demonstrate the sequential involvement of PMv and PMd in movement preparation. These results provide the first compelling evidence for a neuronal dissociation between the different phases of <b>precision</b> <b>grasping</b> in human premotor cortex...|$|R
40|$|Previous {{research}} has demonstrated a tight link between object perception and action: viewing an object primes the action needed to interact with it, while priming an action can affect the speed and accuracy with which we perceive the object. However, {{it is not yet}} known whether motor information can qualitatively change what object we actually perceive. We investigated this issue by having participants view or perform an action before viewing an ambiguous object. Results showed that viewing an action (a picture of a hand displaying a power or <b>precision</b> <b>grasp)</b> biased participants to interpret the ambiguous object as congruent with the action prime (Experiments 1 and 2). Conversely, performing an action (moving small or large balls from one tray to another) biased participants to interpret the object as incongruent with the motor action. Together, these results suggest viewing and performing actions can actually change what we see...|$|E
40|$|Planning a <b>precision</b> <b>grasp</b> for a {{robot hand}} is usually {{decomposed}} into two main steps. First, {{a set of}} contact points over the object surface must be determined, ensuring they allow a stable grasp. Second, the inverse kinematics of the robot hand must be solved to verify whether the contact points can actually be reached. Whereas the first problem has been largely solved in a general posing, the second one has only been tackled with local convergence methods. These methods only provide one solution to the problem, even if many are possible, and depending on the initial estimation they use, they may fail to converge, which results in grasp re-planning in situations where it could be avoided. This paper overcomes both issues by providing a complete method to solve the kinematics of human-like hands. The method is able to find all possible configurations that reach the specified contact points, even when positive-dimensional sets of such configurations are possible. Peer Reviewe...|$|E
40|$|Usually, grasp {{planning}} can {{be split}} up into two phases: In {{the first phase}} one tries to find a set of contacts that allow for stable grasping of an object. This phase has been of major research interest, which is also reflected in the (reasonable) definition of a grasp {{as a set of}} contact points. In the second phase a feasible hand pose that realizes the grasp with a given hand is calculated. While this point is important for a practical grasp planning system, it has either been considered trivial or been solved by crude heuristics in most cases. Here we present an approach for calculating the hand and finger pose for a given grasp. The problem is formulated as a constraint satisfaction problem and then solved using optimization techniques. The method is applied to two different grasp types: To the well known <b>precision</b> <b>grasp</b> and to the pinch grasp which is the grasp type preferred by men when grasping small objects. ...|$|E
40|$|Abstract — We {{investigate}} {{the use of}} five dimension reduction and manifold learning techniques to estimate a 2 D subspace of hand poses {{for the purpose of}} generating motion. Our aim is to uncover a 2 D parameterization from optical motion capture data that allows for transformation sparse user input trajectories into desired hand movements. The use of shape descriptors for representing hand pose is additionally explored for dealing with occluded parts of the hand during data collection. We present early results from uncovering 2 D parameterizations of power and <b>precision</b> <b>grasps</b> and their use to drive a physically simulated hand from 2 D mouse input. I...|$|R
40|$|AbstractThis paper {{presents}} {{the design of}} an anthropomorphic robotic hand of low-budget, achieving basic grasps similar to the human hand. The hand has an anthropomorphic design with 16 degrees of freedom (DOFs). With 14 Mckibben style pneumatic air muscles (PAM) implemented as the power actuator of the tendon-driven fingers, the actuator offers the robotic hand a compliant, soft grasp for manipulating objects in open-loop control. Besides, this work reports the force transmission layout that enables underactuation which allowed the use of fewer actuators to control the DOFs of the hand. The performance of the hand was accessed through testings using power and <b>precision</b> <b>grasps...</b>|$|R
40|$|Subcortical lesions {{have been}} {{simultaneously}} implicated in both real and simulated movement deficits, suggesting that as with frontal le- sions, self action representation and programmation {{are the same}} process. We have analyzed the simulated <b>precision</b> <b>grasping</b> in subjects with idiopathic bilateral PD compared to a healthy control group. Re- sults showed that individuals with PD are impaired in the mental rep- resentation of a grasp orientation but are still capable of normally ex- ecuting this movement. These observations reveal that programmation and execution of movements is spared and that motor representation is selectively impaired. Thus, programmation of real acts and representa- tion of motor action are distinct processes...|$|R
40|$|Preparing {{to grasp}} objects {{facilitates}} visual processing of object location, orientation and size, compared to preparing actions such as pointing. This influence of action on perception reflects mechanisms of selection in visual perception tuned to current action goals, such that action relevant sensory information is prioritized relative to less relevant information. In three experiments, rather than varying movement type (grasp vs. point), {{the magnitude of}} a prepared movement (power vs. precision grasps) was manipulated while visual processing of object size, as well as local/global target detection was measured. Early event-related potentials elicited by task-irrelevant visual probes were enhanced for larger probes during power grasp preparation and smaller probes during <b>precision</b> <b>grasp</b> preparation. Local targets were detected faster following precision, relative to power grasp cues. The results demonstrate a direct influence of grasp preparation on sensory processing of size and suggest that the hierarchical dimension of objects may be a relevant perceptual feature for grasp programming. To our knowledge, {{this is the first}} evidence that preparing different magnitudes of the same basic action has systematic effects on visual processing...|$|E
40|$|Abstract—In this paper, {{we propose}} {{a method that}} enables a robot to learn not only the {{existence}} of affordances provided by objects, but also the behavioral parameters required to actualize them, and the prediction of effects generated on the objects in an unsupervised way. In a previous study, it was shown that through self-interaction and self-observation, analogous to an infant, an anthropomorphic robot can learn object affordances in a completely unsupervised way, and use this knowledge to make plans in its perceptual space. This paper extends the affordances model proposed in that study by using parametric behaviors and including the behavior parameters into affordance learning and goal-oriented plan generation. Furthermore, for handling complex behaviors and complex objects (such as execution of <b>precision</b> <b>grasp</b> on a mug), the perceptual processing is improved by {{using a combination of}} local and global features. Finally, a hierarchical clustering algorithm is used to discover the affordances in non-homogenous feature space. In short, object affordances for object manipulation are discovered together with behavior parameters based on the monitored effects. I...|$|E
40|$|The {{present study}} asks when infants {{are able to}} {{selectively}} anticipate the goals of observed actions, and how this ability relates to infants ’ own abilities to produce those specific actions. Using eye-tracking technology to measure on-line anticipation, 6 -, 8 - and 10 -month-old infants and a control group of adults were tested while observing an adult reach with a whole hand grasp, a <b>precision</b> <b>grasp</b> or a closed fist towards one of two different sized objects. The same infants were also given a comparable action production task. All infants showed proactive gaze to the whole hand grasps, with increased degrees of proactivity in the older groups. Gaze proactivity to the precision grasps, however, was present from 8 months of age. Moreover, the infants ’ ability in performing precision grasping strongly predicted their ability in using the actor’s hand shape cues to differentially anticipate {{the goal of the}} observed action, even when age was partialled out. The results are discussed in terms of the specificity of action anticipation, and the fine-grained relationship between action production and action perception...|$|E
5000|$|In {{addition}} to fixing satellites, Rollin' Justin has many unique abilities which separate it from other robots. For example, Justin {{has the ability}} to catch flying objects with an 80 percent success rate. It can do this because of the cameras on its head, tracking software, and <b>precision</b> <b>grasping.</b> Justin's arms are made of carbon-fiber, which allow up to 31 pounds to be lifted on each arm. [...] Justin is also able to make tea and coffee and hold a paper cup without splashing the liquid all over its hands. Not only can it make coffee, Justin can also do a dance from Pulp Fiction.|$|R
5000|$|Species of Paranthropus had smaller braincases than Homo, {{yet they}} had {{significantly}} larger braincases than Australopithecus. Paranthropus {{is associated with}} stone tools both in southern and eastern Africa, although there is considerable debate whether they were made and utilized by these robust australopithecines or contemporaneous Homo. Most believe that early Homo was the tool maker, but hand fossils from Swartkrans, South Africa, indicate that the hand of Paranthropus robustus was also adapted for <b>precision</b> <b>grasping</b> and tool use. [...] Most Paranthropus species seem almost certainly not to have used language nor to have controlled fire, although they are directly associated with the latter at Swartkrans.|$|R
40|$|PURPOSE. Visual defects {{associated}} with amblyopia have been extensively studied, but {{their impact on}} the performance of everyday visuomotor tasks is unclear. This study evaluates eye–hand coordination (prehension) skills in adult amblyopes compared with normal subjects. METHODS. Twenty amblyopes (10 strabismic, 10 nonstrabismic) with different degrees of visual acuity loss (mild, moderate, or severe) and stereodeficiency (reduced or undetectable) partic-ipated, along with 20 matched control subjects. Subjects reached, <b>precision</b> <b>grasped,</b> and lifted cylindrical household objects (two sizes, four locations) using binocular vision or just the dominant or amblyopic (nondominant) eye, while the actions of the preferred hand were recorded. Various indices of prehension planning and online control were quantified for all trials (n 48) performed under each viewing condition...|$|R
40|$|Several recent {{psychological}} {{investigations have}} demonstrated that planning an action biases visual processing. Symes et al. (2008) for example, reported faster target detection for a changing object amongst several non-changing objects following the planning of a targetcongruent grasp. The current experimental work investigated how this effect might compare to, and indeed integrate with, effects of language cues. Firstly a cuing effect was established {{in its own right}} using the same change-detection scenes. Sentences cued object size (e. g., “Start looking for a change in the larger objects”), and these successfully enhanced detection of size-congruent targets. Having thereby established two effective sources of bias (i. e., action primes and language cues), the remaining three experiments explored their co-occurrence within the same task. Thus an action prime (participants planned a power or <b>precision</b> <b>grasp)</b> and a language cue (a sentence) preceded stimulus presentation. Based on the tenets of the biased competition model (Desimone and Duncan, 1995), various predictions were made concerning the integration of these different biases. All predictions were supported by the data, and these included reliably stronger effects of language, and concurrent biasing effects that were mutually suppressive and additive...|$|E
40|$|<b>Precision</b> <b>grasp</b> {{synthesis}} {{has received}} a lot of attention in past few last years. However, real mechanical hands can hardly assure that the fingers will precisely touch the object at the computed contact points. The concept of independent contact regions (ICRs) was introduced to provide robustness to finger positioning errors during an object grasping: A finger contact anywhere inside each of these regions assures a force-closure grasp, despite the exact contact position. This paper presents an efficient algorithm to compute ICRs with any number of frictionless or frictional contacts on the surface of any 3 -D object. The proposed approach generates the independent regions by growing them around the contact points of a given starting grasp. A two-phase approach is provided to find a locally optimal force-closure grasp that serves as the starting grasp, considering as grasp quality measure the largest perturbation wrench that the grasp can resist, independently of the perturbation direction. The proposed method can also be applied to compute ICRs when several contacts are fixed beforehand. The approach has been implemented, and application examples are included to illustrate its performance. Peer Reviewe...|$|E
40|$|Abstract—This paper {{presents}} a procedure to synthesize highquality grasps for objects {{that need to}} be held and manipulated in a specific way, characterized by a pre-specified set of contact constraints to be satisfied. Due to the multi-modal nature of typical grasp quality measures, approaches that resort to local optimization methods are likely to get trapped into local extrema on such problem. An additional difficulty {{of the problem is that}} the set of feasible grasps is a highly-dimensional manifold, implicitly defined by a system of non-linear equations. The proposed procedure finds a way around these issues by focusing the exploration on a relevant subset of grasps of lower dimension, and tracing this subset exhaustively using a higher-dimensional continuation technique. A detailed atlas of the subset is obtained as a result, on which the highest-quality grasp according to any desired criterion, or a combination of criteria, can be readily identified. Examples are included that illustrate the application of the method to a three-fingered planar hand and to the Schunk anthropomorphic hand grasping several objects, using several quality indices. Index Terms—Grasp synthesis, <b>precision</b> <b>grasp,</b> grasp planning, contact constraint, anthropomorphic hand, grasp quality index. I...|$|E
40|$|Abstract—Passive {{linkages}} {{were developed}} to improve grasp functionality and minimize a prosthetic terminal device’s num-ber of user-controlled inputs. The linkages act to stabilize grasped objects and substitute for the palp of normal anatomi-cal fingers. The Southampton Hand Assessment Procedure {{was used to compare}} the normal anatomical hand, this prototype, and a commercially available (Hosmer) hook. In testing, pros-thetic terminal devices took three times as long as the normal anatomical hand to perform tasks. Nevertheless, heavyweight power and spherical grasps were improved {{with the use of the}} new mechanism compared with the commercial hook. Con-versely, <b>precision</b> <b>grasps</b> were worsened because of the lack of a high-friction surface on the distal end of the prototype...|$|R
40|$|Event-related {{potentials}} {{were recorded}} while infants observe congruent or incongruent grasping actions {{at the age}} when organized grasping first emerges (4 - 6 months of age). We demonstrate that the event-related potential component P 400 encodes the congruency of power grasps {{at the age of}} 6 months (Experiment 1) and in 5 -month-old infants that have developed the ability to use power grasps (Experiment 2). This effect does not extend to <b>precision</b> <b>grasps,</b> which infants cannot perform (Experiment 3). Our findings suggest that infants' encoding of the relationship between an object and a grasping hand (the action-perception link) is highly specialized to actions and manual configurations of actions that infants are able to perfor...|$|R
40|$|La bo ra to r y o f MTA- SZTAKI The {{majority}} {{of studies on}} <b>precision</b> <b>grasps</b> agree that tactile sensing is indispensable for the fine, gentle grasping of unknown, fragile objects. Still only a few papers deal with tactile sensors capable of sensing not only normal forces, but shear forces, and toques as well. This study concerns soft finger contact, where the friction allows it to resist tangential forces and moments up to a friction limit. An experimental system is presented, comprising: (1) Two 3 D tactile arrays (2 * 2 taxels (tactile pixels) each) mounted on a two-fingered robot hand, (2) a closed loop controller. This arrangement allows detection and classification of typical tactile events, improving the control of grasping...|$|R
