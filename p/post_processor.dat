142|15|Public
5000|$|The {{proposed}} {{capabilities of}} the <b>post</b> <b>processor</b> can be summarized in the following: ...|$|E
50|$|By using a <b>Post</b> <b>processor</b> and Off-line {{programming}} (robotics) software it {{is possible}} to handle brand-specific robot programming language from a universal programming language, such as Python (programming language).|$|E
50|$|Since 2009 a new pre- and <b>post</b> <b>processor</b> called Z88Aurora is {{developed}} by a team around Prof. Rieg and was released in June 2010. Z88Aurora uses the technology of Z88 V14.0 combined with an intuitive user prompting (contains boundary conditions, several free FE-mesher, material database with data fitting).|$|E
50|$|Different {{types of}} files can be {{imported}} including step and iges files. RoboDK <b>post</b> <b>processors</b> allow for programs to be exported to an actual robot including, ABB Rapid (mod/prg), Fanuc LS (LS/TP), Kuka KRC/IIWA (SRC/java), Motoman Inform (JBI), Universal Robots (urscript), and more.|$|R
40|$|The Mission Payloads Subsystem (MPLS) which {{utilizes}} {{a simplified}} trajectory model {{to generate a}} list of missions for the Scheduling Algorithm for Mission Planning and Logistics Evaluation (SAMPLE) program is described. The MPLS is the mechanism that forms the basis of input for the other subsystems of SAMPLE and various <b>post</b> <b>processors...</b>|$|R
40|$|The NASTRAN thermal {{analyzer}} (NTA) which performs large-scale unified thermo-structural analyses {{with the}} NASTRAN (NASA structural analysis) computer program is described. The mathematical similitude {{between these two}} distinct disciplines of thermal and structure is examined. It serves as the theoretical basis upon which {{the implementation of the}} thermal capability in NASTRAN was accomplished. The program structure, the functional flow, the solution algorithms, the organization of an input data deck and the solution capabilities of NTA are summarized. Emphasis is placed on the interface of the unified approach in thermo-structural analyses where stresses, deflections, vibrations and bucklings induced by the effect of temperature change are of concern. Attentions are also directed to the preprocessor and <b>post</b> <b>processors.</b> As a specially designed preprocessor, the VIEW program is capable of generating exchange factors which can be output, at user's option, in formats compatible with that required by NTA. Two <b>post</b> <b>processors</b> that serve specific objectives are included. They are the thermal variance analysis and the graphical displaying capability of temperatures in color or black and white...|$|R
5000|$|A <b>Post</b> <b>Processor</b> is {{a unique}} [...] "driver" [...] {{specific}} to a CNC machine, robot or mechanism; some machines start at different locations or require extra movement between each operation, the Post-Processor works with the CAM software or off-line programming software {{to make sure the}} G-Code output or program is correct for a specific machine build.|$|E
5000|$|MADYMO/MADpost - MADPost is a {{multi-platform}} <b>post</b> <b>processor</b> for the MADYMO solver. It {{has been}} designed to facilitate optimal use of the MADYMO solver output - both for viewing animations and creating time-history plots. MADPost also supports import and display of some foreign FE code output formats and physical test data formats, such as video formats and ISO formatted data.|$|E
50|$|The OpenFX featureset {{includes}} a full renderer and raytracing engine, NURBS support, kinematics-based animation, morphing, and an extensive plugin API. Plugin capabilities include image <b>post</b> <b>processor</b> effects such as lens flare, fog {{and depth of}} field. Animation effects such as explosions, waves and dissolves add to {{the flexibility of the}} program. Version 2.0 also features support for modern graphics cards with hardware GPU acceleration.|$|E
50|$|NEi Nastran is an {{engineering}} analysis and simulation software product of NEi Software (formerly known as Noran Engineering, Inc.) Based on NASA's Structural Analysis program NASTRAN, {{the software is}} a finite element analysis (FEA) solver used to generate solutions for linear and nonlinear stress, dynamics, and heat transfer characteristics of structures and mechanical components. NEi Nastran software is used with all major industry pre and <b>post</b> <b>processors</b> including Femap, a product of Siemens PLM Software, in house brands NEi Nastran in-CAD, NEi Fusion, and NEi Works for SolidWorks.This software was acquired by Autodesk in May 2014.|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedNumerous cracks and leaks in the superheater header tube attachment welds in the LHA- 1 class of amphibious assault ships have prompted {{an investigation by}} the Naval Sea Systems Command (NAVSEA). This thesis describes the stress analysis of the superheater header tube attachment region using a three dimensional axisymmetric Finite Element model. The SAP 80 structural analysis program was utilized to conduct the analysis. Both pre and <b>post</b> <b>processors</b> were employed to obtain graphical representations of the model as well as the results of the stress analysis. This thesis focuses primarily on thermally induced stresses produced in the header. Some results obtained for a nominal 100 Degree F temperature drop across the thickness of the superheater header wall yielded a maximum hoop stress of 19. 01 (Ksi) and a maximum in plane stress of 1. 58 (Ksi). [URL] United States Nav...|$|R
40|$|A {{deterrent}} to practical use of many feature extraction systems {{is that they}} are difficult to maintain, either because they depend on the use of a library of featuretypes which must be updated when the underlying manufacturing resources change (e. g. tools and fixtures), or they rely on the use of task-specific <b>post</b> <b>processors,</b> which must also be updated. For such systems to become practical, it must be easy for a user to update the system to match the current resources. This paper presents MEDIATOR (Maintainable, Extensible Design and manufacturing Integration Architecture and TranslatOR). MEDIATOR is a resource adaptive feature extraction and early process planning system for 3 -axis milling. A resource adaptive system is one that changes its behavior as the manufacturing resources in a shop change. MEDIATOR allows users to select from a standard set of tools and fixtures, and automatically identifies any changes in the features that result. It attains its resource adaptive behavior by [...] ...|$|R
50|$|Before {{the books}} {{are added to the}} Faded Page book archive, {{the books are}} placed in a final round called 'Smooth Reading'. While in this phase, members of DP Canada are {{encouraged}} to download the books and read them. While the books are in this phase, comments about the book for possible improvements can be sent to the <b>post</b> <b>processor.</b> Once past the Smooth Reading process, the publication is posted on Faded Page.|$|E
5000|$|CAM {{software}} uses geometry from a CAD {{model and}} converts it to G-code. The CAM software analyzes the CAD model, determines what tooling and toolpaths {{will be used}} to mill the desired features.  Doing so requires a CAM <b>post</b> <b>processor</b> that generates the exact g-code dialect used by the machine that is being targeted. An instance of such a translation {{is often referred to as}} a [...] "post". There will be a different “post” for each g-code dialect the CAM software supports. Post Processors usually do not convert g-code from one dialect to the next, rather the “post” uses an intermediate format that captures the G-code commands in a dialect-independent form. Most CAM software accomplishes this with an intermediate format called [...] "CL Data." ...|$|E
50|$|KIVA-3V uses a block-structured {{mesh with}} {{connectivity}} defined through indirect addressing. The departure {{from a single}} rectangular structure in logical space allows complex geometries to be modeled with significantly greater efficiency because large regions of deactivated cells are no longer necessary. Cell-face boundary conditions permit greater flexibility and simplification {{in the application of}} boundary conditions. KIVA-3V also contains a number of significant improvements over its predecessors. New features enhanced the robustness, efficiency, and usefulness of the overall program for engine modeling. Automatic restart of the cycle with a reduced timestep in case of iteration limit or temperature overflow effectively reduced code crashes. A new option provided automatic deactivation of a port region when it is closed from the cylinder and reactivation when it communicates with the cylinder. Extensions to the particle-based liquid wall film model made the model more complete and a split injection option was also added. A new subroutine monitors the liquid and gaseous fuel phases and energy balance data and emissions are monitored and printed. In addition, new features were added to the LANL-developed grid generator, K3PREP, and the KIVA graphics <b>post</b> <b>processor,</b> K3POST.|$|E
40|$|GTOSS {{represents}} a tether analysis complex which {{is described by}} addressing its family of modules. TOSS is a portable software subsystem specifically designed to be introduced into the environment of any existing vehicle dynamics simulation to add the capability of simulating multiple interacting objects (via multiple tethers). These objects may {{interact with each other}} {{as well as with the}} vehicle into whose environment TOSS is introduced. GTOSS is a stand alone tethered system analysis program, representing an example of TOSS having been married to a host simulation. RTOSS is the Results Data Base (RDB) subsystem designed to archive TOSS simulation results for future display processing. DTOSS is a display <b>post</b> <b>processors</b> designed to utilize the RDB. DTOSS extracts data from the RDB for multi-page printed time history displays. CTOSS is similar to DTOSS, but is designed to create ASCII plot files. The same time history data formats provided for DTOSS (for printing) are available via CTOSS for plotting. How these and other modules interact with each other is discussed...|$|R
40|$|A chip is {{described}} that will perform lossless compression and decompression using the Rice Algorithm. The chip set {{is designed to}} compress and decompress source data in real time for many applications. The encoder is designed to code at 20 M samples/second at MIL specifications. That corresponds to 280 Mbits/second at maximum quantization or approximately 500 Mbits/second under nominal conditions. The decoder is designed to decode at 10 M samples/second at industrial specifications. A wide range of quantization levels is allowed (4 [...] . 14 bits) and both nearest neighbor prediction and external prediction are supported. When the pre and <b>post</b> <b>processors</b> are bypassed, the chip set performs high speed entropy coding and decoding. This frees the chip set from being tied to one modeling technique or specific application. Both the encoder and decoder are being fabricated in a 1. 0 micron CMOS process that has been tested to survive 1 megarad of total radiation dosage. The CMOS chips are small, only 5 mm on a side, and both are estimated to consume less than 1 / 4 of a Watt of power while operating at maximum frequency...|$|R
40|$|A {{nonlinear}} {{mathematical model}} (Zarnick, 1978) {{has been extended}} to calculate the motions of a variable deadrise planing boat in waves, using Zamick's low aspect ratio strip theory. It is assumed that the wavelengths are large relative to boat length and that the wave slope is small. The acceleration in the x-direction is assumed small and therefore set to zero enabling the program to solve for the required thrust. A third order polynomial {{may be used to}} vary the deadrise of a hull from bow to stern. Several <b>post</b> <b>processors</b> have been written to analyze the motions and accelerations. &&Planing dynamics in a seaway is a complex, nonlinear problem. The Zarnick paper (1978) was the first to formulate the time domain approach for planing hull seakeeping though several authors have duplicated and extended the approach since then (e. g. Payne, 1990 and Keunung, 1992). An extensive bibliography and comparison with experimental data can be found in Payne (1995). &&This report describes the validation of the program and a preliminary variable deadrise study. In the deadrise variation comparison, hull forms are evaluated for reduced drag and operability (i. e. rideability) enhancement...|$|R
40|$|The <b>post</b> <b>processor</b> {{program was}} {{developed}} to view Large Angle Transient Dynamics (LATDYN) output data in predefined, predetermined formats. The <b>post</b> <b>processor</b> is used for plotting data, creating and maintaining a data base of plotting requests, comparing and manipulating data sets in the data base, and the preparing plots for documentation...|$|E
40|$|Interleaved Division Multiple Access (IDMA) {{is a new}} {{access scheme}} that has been {{proposed}} in the literature to increase the capacity of wireless channels. The performance of such systems depends on {{the accuracy of the}} channel state information at the receiver. In this paper, a Noisy-Independent Component Analysis (N-ICA) based IDMA receiver for multiple access communication channels is proposed. The N-ICA component is applied as a <b>post</b> <b>processor.</b> Unlike other IDMA receivers, the proposed scheme detects and separates the transmitted symbols without channel state information tracking. The performance of the proposed technique is presented in terms of raw bit error rate (BER) without channel coding for different signal to noise ratios (SNR). Simulation results demonstrate that N-ICA <b>post</b> <b>processor</b> provides an improvement in performance in BER in loaded systems. When the system is not loaded, the proposed <b>post</b> <b>processor</b> has the same performance as conventional IDMA receiver with less iterations leading to a complexity reduction...|$|E
40|$|This report {{documents}} CURRENT, {{a computer}} code for modeling two- dimensional, chemically reacting, low Mach number flows including {{the effects of}} surface chemistry. CURRENT is a finite volume code based on the SIMPLER algorithm. Additional convergence acceleration for low Peclet number flows is provided using improved boundary condition coupling and preconditioned gradient methods. Gas-phase and surface chemistry is modeled using the CHEMKIN software libraries. The CURRENT user-interface {{has been designed to}} be compatible with the Sandia-developed mesh generator and <b>post</b> <b>processor</b> ANTIPASTO and the <b>post</b> <b>processor</b> TECPLOT. This report describes the theory behind the code and also serves as a user`s manual...|$|E
40|$|The {{focus of}} the work is on the {{development}} and utilization of a self-assembling Fuzzy logic controller for the purpose of improving short term natural gas load forecasts generated by artificial neural networks (ANN) and linear regression (LR) models. The approach is to form a matrix of dynamic <b>post</b> <b>processors</b> (DPP), composed of ARMAX models, which use load estimates generated by ANNs and LRs as inputs. The problem is to then determine the performance of each DPP under different operating conditions, and to generate a final load estimate using a Fuzzy logic controller. The contributions of this research are as follows. First, as part of a residuals analysis, prefiltering and nonlinear transforms are explored for the purpose of increasing the correlation of environmental input factors with gas load, while decreasing multicollinearity. This has the effect of reducing the covariance of model parameters and increasing forecast confidence. The result of this analysis will be used to develop ARMAX models to postfilter the ANN and LR forecast model estimates. The gas operating regions will be characterized by an adaptive clustering algorithm that will partition operating conditions into distinct patterns with unique consumption characteristics. Finally, an adaptive online Fuzzy controller identifies the characteristics of each DPP under different operating conditions, and generates a weighted average of the DPP estimators to produce the final gas load estimate...|$|R
40|$|At {{the end of}} 2012, GRiSP {{initiated}} a process to review and revise its gender strategy. The main purpose is to strengthen its effectiveness by establishing a results-based performance system {{in line with the}} overall recommendations included in the CGIAR "Strategy and Results Framework Action Plan" which was approved by the CGIAR Fund Council October 2012. GRiSP’s revised gender strategy will be based on a solid impact pathway and theory of change on how ‘empowerment’ of women in the agricultural research for development (AR 4 D) arena and in the rice value chain (women farmers, <b>post</b> harvest operators, <b>processors)</b> accelerates the delivery of GRiSP’s intermediate development outcomes and thus contributes to the delivery of the CGIAR system level outcomes...|$|R
40|$|Trails {{are a long}} {{established}} {{concept of}} assisting users in searching and navigating hypertexts. However, existing trailbased systems are focusing on browsers only and therefore do not fully exploit the notion of trails. We propose trailbased systems {{to be open to}} any application and to any activity. For instance, printing a document from a word <b>processor,</b> <b>posting</b> a message in a newsgroup, or forwarding an attachment to a friend — using one’s favorite e-mail client — may well be part of a trail. “Trailist ” is a framework supporting the development of these trail-based systems. Its name indicates that, similar to the way “Tour-ists ” travel on tours, “Trail-ists ” make their ways through vast information spaces...|$|R
40|$|AbstractThe {{software}} package of GeoStudio, which is developed {{and supported by}} GEOSLOPE inc., {{is one of the}} most popular {{software package}} in the field of geotechnical engineering. However, the software SIGMA/W for deformation and stresses computing currently absents Duncan-Chang E-B constitutive model that has been widely used in the domestic field of geotechnical engineering. The shortage limits the software's application scopes. In this paper, with the further developing platform, Duncan- Chang E-B constitutive model is developed in GeoStudio 2007 with C# environment, and the stress level, which is often used in the result analysis, is connected to the <b>post</b> <b>processor.</b> Through a series of numerical simulation of routine and stress path triaxial compression test, the correctness of the compiled model is verified. Through a stress level computing of a stage constructed dam, the goodness of connection between the model and the <b>post</b> <b>processor</b> is verified. According to the experience of developing Duncan-Chang E-B constitutive model, this paper shows the basic procedures, programming essential and connecting with <b>post</b> <b>processor</b> for constitutive model developing in GeoStudio 2007, and this supplies a reference for other developers to build a user-defined constitutive model...|$|E
40|$|Bachelor thesis {{contains}} {{a summary of}} CAD / CAM software Edgecam, setting the <b>post</b> <b>processor</b> for use in manufacturing machine ZPS VMC 1060 with the control system DynaPath Delta MU Control 50. Description of manufacturing strategies, cutting tools, experimental verification of CNC code for manufacturing equipment...|$|E
30|$|Since {{the dynamic}} {{characteristics}} of the offshore platform are explicitly portrayed through modal analysis, it {{was carried out in}} OpenSees <b>Post</b> <b>Processor</b> (OSP) before each transient analysis to represent natural frequencies. Then, the results were compared with the periods computed during the assessment stage using the Structural Analysis Computer System (SACS) software.|$|E
40|$|Current age {{has been}} {{primarily}} revolutionized by {{the increased use}} of rotary machines in our everyday tasks. We are technologically civilized society; everything we see, do or even imagine cannot be realized without the machines. At present, and in the future, the comfort and existence of technologically advance life heavily relies on reliable performance of countless machines around us. To avoid the catastrophic consequences associated with machine failures, research in Machine Health Monitoring (MHM) has attracted many researchers and engineers all over the world. In machines, domain knowledge is required to model parts of the system to find characteristic features for faults detection. Thus, it readily demands a detailed investigation of known and potential faults to obtain their mathematical models which is financially inefficient, cumbersome and nearly impossible for a large number of different existing and future machines, operating in different environments. This thesis identifies stated research problems and proposes a novel self-learning and adaptive modular solution, which attunes to diverse machine applications and is a vital contribution towards Machine Independent Condition Monitoring (MICM) framework. Using Gaussians models over the frequency contents of captured vibrations from the machines, the proposed research continuously monitors the machines for steady state operating conditions; and anomalous situations are detected as soon as anomaly score crosses a certain threshold. To address different application environments and fault scenarios, different size and weightage based bin formation of frequencies representing vibration generated by the machines has been proposed. Fuzzy logic inspired fault memberships to track the growth of the fault and complex anomaly plot to investigate the anomalous contents (either they belong to amplitude anomaly or amplitude anomaly) have been introduced to select transform parameters for fault diagnostic at the later stages. After anomaly detection the next stage is fault diagnosis. Translation invariant features obtained from spectral transform of captured vibrations are used with Artificial Neural Network (ANN) for the autonomous fault diagnosis. To consider the faults signatures with different degrees of non-stationarity, originating from different fault sources Wavelet Transform (WT) and vibration imaging techniques have been introduced to enhance spectral features suiting different transients’ operating conditions. Finally, MICM framework has been devised for autonomous fault detection and classification. Proposed framework comprises of essential and optional modules. Optional modules can be enabled autonomously and selected to obtain improved and reliable fault classification. Using essential modules, translation invariant spectral features are obtained and presented to ANN for autonomous selection of appropriate features based upon the trained Weights and Feature Weight Profile (FWP) of input layer of the network. Optional modules are used as pre and <b>post</b> <b>processors</b> and are autonomously selected by trying different combinations with essential modules during FWP selection. The selection of the parameters of the optional and essential modules depends upon the nature of fault source and is vital to reliable fault classification under worst noise conditions. The presented work in the thesis, with classification accuracies surpassing the existing techniques, signifies the contributions of the conducted research and opens up a new area of research...|$|R
40|$|The APT code {{is one of}} {{the most}} widely used {{software}} tools for complex numerically controlled (N/C) machining. APT is an acronym for Automatically Programmed Tool and is used to denote the programming language. Development of the APT language and software system was begun in the late 1950 's as a U. S. government sponsored industry and university research effort. APT is a "problem oriented" language that was developed for the explicit purpose of aiding the N/C machine tools. The original APT program contained undocumented nonstandard FORTRAN, thus making porting of the processor to different operating systems difficult. P-APT (Portable APT) is a revised version of APT that was written to conform to the FORTRAN 77 standard. All machine-dependent code has either been replaced or isolated and documented. Machine-tool instructions and geometry definitions are written in the APT language to constitute a "part program". The APT part program is processed by the P-APT software to produce a cutter location (CL) file. This CL file may then be processed by user supplied <b>post</b> <b>processors</b> to convert the CL data into a form suitable for a particular N/C machine tool. This current offering of the P-APT system represents an adaptation, with enhancements, of the public domain version of APT IV/SSX 8. Enhancements include the super pocket feature that allows concave pockets with curved sides and islands. The P-APT system software is organized into two separate programs: the load complex and the APT processor. The load complex handles the table initiation phase and is usually only run when changes to the P-APT processor capabilities are made. This phase initializes character recognition and syntax tables for the P-APT processor by creating FORTRAN block data programs. The P-APT processor consists of four components: the translator, the execution complex, the subroutine library, and the CL editor. The translator examines each APT statement in the part program for recognizable structure and generates a new statement, or series of statements, in an intermediate language. The execution complex processes all of the definition, motion, and related statements to generate cutter location coordinates. The subroutine library contains routines defining the algorithms required to process the sequenced list of intermediate language commands generated by the translator. The CL editor re-processes the cutter location coordinates according to user supplied commands to generate a final CL file. The APT language is a statement oriented, sequence dependent language. With the exception of such programming techniques as looping and macros, statements in an APT program are executed in a strict first-to-last sequence. In order to provide programming capability for the broadest possible range of parts and machine tools, APT input (and output) is generalized, as represented by 3 -dimensional geometry and tools, and is arbitrarily uniform, as represented by the moving tool concept and output data in absolute coordinates. P-APT is written in FORTRAN 77 for execution on Sun 4 series computers running SunOS. Although P-APT is written in standard FORTRAN 77 and was designed to be readily portable code, it has only been fully tested on a Sun 4 series computer running SunOs. By making documented modifications to the source code, it may also be ported to a DEC VAX series computer running VMS. P-APT required 3. 1 Mb of RAM for execution. A minimum of 16 Mb of RAM and 32 Mb of disk space used for swap space is recommended. The standard distribution medium for this program is a. 25 inch streaming magnetic tape cartridge in UNIX tar format. P-APT is available by license for a period of ten (10) years to approved licensees. The licensed program product includes the P-APT source code, makefiles, examples, and one set of supporting documentation. Additional copies of the documentation may be purchased at the price indicated below. P-APT was developed in 1992...|$|R
40|$|Research on {{learning}} from instruction has focused primarily on semantic and procedural rather than episodic memories by students. Martin (1993) hypothesized that episodic memories of students mediate {{learning from instruction}}al interventions because of the personal associations carried with them. The present research investigated the role of episodic memories of Grade 6 students in mathematics instruction, especially {{with respect to the}} possible mediation of student learning. Individual differences in learning style, attitude toward learning, and knowledge were investigated as possible factors that affect recall of episodic memories from classroom instruction. Study 1 assessed the suitability of two learning style inventories for use with a Grade 6 sample. The Individual Differences Questionnaire was found to be a good measure for verbal/imaginal encoding, and the Inventory of Learning Processes was found to be an adequate measure of learning style related to theories of information processing. In Study 2, students completed an attitude toward mathematics inventory, tests of prior knowledge and achievement, and were required to list their episodic memories for classroom instruction. Initial support for the mediational hypothesis was not seen in Study 2. Although expected, encoding preference did not affect scores on the posttests. Instruction may not have varied enough to allow students with either preference to benefit. As a result, Study 3 manipulated the amount of imagery used during instruction to determine if such a manipulation affected recall of information presented. Students completed the same battery of tests as in Study 2 in a controlled setting with instruction in mathematics presented via videotape. Students who preferred to encode verbally did better on posttests of achievement in the verbal condition. Students who preferred to encode imaginally recalled more episodic memories in the imaginal condition. Although the predicted main and interaction effects of imagery were not significant, limited support for the mediational hypothesis was found {{in the form of a}} correlation between recall of instructionally relevant episodes and score on the <b>posttest.</b> Deep <b>processors</b> tended to perform well on the posttests and elaborative processors tended to perform poorly. Implications for episodic memory in classroom instructional research and practice are discussed in light of the findings from all three studies...|$|R
40|$|Text line {{segmentation}} {{is a basic}} step in any OCR sys-tem. Its failure deteriorates {{the performance}} of OCR en-gines. This {{is especially true for}} the Indian languages {{due to the nature of}} scripts. Many segmentation algorithms are proposed in literature. Often these algorithms fail to adapt dynamically to a given page and thus tend to yield poor seg-mentation for some specific regions or some specific pages. In this work we design a text line segmentation <b>post</b> <b>processor</b> which automatically localizes and corrects the segmentation errors. The proposed segmentation <b>post</b> <b>processor,</b> which works in a “learning by examples ” framework, is not only independent to segmentation algorithms but also robust to the diversity of scanned pages. We show over 5 % improvement in text line segmentation on a large dataset of scanned pages for multiple Indian lan-guages. 1...|$|E
40|$|A user {{controlled}} interactive {{computer graphics}} postprocessor for two-dimensional static and dynamic finite element analysis is developed. This <b>post</b> <b>processor</b> is a menu driven interactive program. This <b>post</b> <b>processor</b> supports more than 50 graphics devices. This program can manipulate the original finite element mesh data, displacement, stress, strain and up to four other values such as temperature. The user can choose {{any one of the}} following methods to display the values: Deformed mesh, Vector flow, Color Contours or Curved Contours. With this postprocessor, an improved contouring algorithm is proposed specially for finite element method. This algorithm uses the same isoparametric element representation as used in the analysis stage. That means the contour curves are accurate assuming that the nodal values are accurate and the real values inside the element can be interpolated by the element shape functions. So, this algorithm provides a continuity as the same order as that of the shape functions used for the finite element...|$|E
40|$|This paper {{describes}} {{the work done}} to develop a bolometer <b>post</b> <b>processor</b> that converts volumetric radiated power values taken from a UEDGE solution, to a line integrated radiated power along chords of the bolometers in the DIII-D tokamak. The UEDGE code calculates plasma physics quantities, such as plasma density, radiated power, or electron temperature, and compares them to actual diagnostic measurements taken from the scrape off layer (SOL) and divertor regions of the DIII-D tokamak. Bolometers are devices measuring radiated power within the tokamak. The bolometer interceptors {{are made up of}} two complete arrays, an upper array with a vertical view and a lower array with a horizontal view, so that a two dimensional profile of the radiated power may be obtained. The bolometer <b>post</b> <b>processor</b> stores line integrated values taken from UEDGE solutions into a file in tabular format. Experimental data is then put into tabular form and placed in another file. Comparisons can be made between the UEDGE solutions and actual bolometer data. Analysis has been done to determine the accuracy of the plasma physics involved in producing UEDGE simulations...|$|E
40|$|Abstract. In {{the current}} paper the Particle Finite Element Method (PFEM), an inno-vative {{numerical}} method for solving {{a wide spectrum}} of problems involving the interaction of fluid and structures, is briefly presented. Many examples of the use of the PFEM with GiD support are shown. GiD framework provides a useful pre and <b>post</b> <b>processor</b> for the specific features of the method. Its advantages and shortcomings are pointed out in the present work. ...|$|E
40|$|The {{approach}} to thermal analysis described by {{this paper is}} a technique that incorporates Computer Aided Design (CAD) and Computer Aided Engineering (CAE) to develop a thermal model that has the advantages of Finite Element Methods (FEM) without abandoning the unique advantages of Finite Difference Methods (FDM) {{in the analysis of}} thermal systems. The incorporation of existing CAD geometry, the powerful use of a pre and <b>post</b> <b>processor</b> and the ability to do interdisciplinary analysis, will be described...|$|E
40|$|Abstract. This paper {{proposed}} a systematic approach to optimize J 2 ME KVM running directly on NAND flash memories (XIP). The refined KVM generated cache misses 96 % {{less than the}} original version did. The approach appended a <b>post</b> <b>processor</b> to the compiler. The <b>post</b> <b>processor</b> relocates and rewrites basic blocks within the VM interpreter using a unique mathematical model. This approach analyzed not only static control flow graph but also the pattern of bytecode instruction streams, since we found the input sequence drives the program flow of the VM interpreter. The proposed mathematical model is used to express the execution flows of Java instructions of real applications. Furthermore, we concluded the mathematical model {{is a kind of}} graph partition problem, and this finding helped the relocation process to move program blocks to proper NAND flash pages. The refinement approach dramatically improved the locality of the virtual machine thus reduced cache miss rates. Our technique can help J 2 ME-enabled devices to run faster and extend longer battery life. The approach also brings potential for designers to integrate the XIP function into System-on-Chip thanks to lower demand for cache memory...|$|E
