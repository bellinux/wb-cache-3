5|35|Public
2500|$|He {{invented the}} first {{automatic}} card-feed mechanism {{and the first}} keypunch. [...] The 1890 Tabulator was hardwired to operate on 1890 Census cards. A control panel in his 1906 Type I Tabulator simplified rewiring for different jobs. [...] The 1920s removable control panel supported <b>prewiring</b> and near instant job changing. These inventions were among {{the foundations of the}} data processing industry and Hollerith's punched cards (later used for computer input/output) continued in use for almost a century.|$|E
50|$|Expeditions {{equipped}} with the heavy-duty trailer towing package are prepped and readied, at the factory, for towing. The package includes a VESC (Vehicle Equipment Safety Commission) V-5 (or SAE J684) Class IV (Class 4) rated trailer hitch with weight distribution capability, heavy-duty radiator, heavy-duty auxiliary transmission fluid cooler, hitch mounted 4 and 7-pin trailer electrical connector and factory <b>prewiring</b> for an electronic trailer brake controller module. The brake controller wiring harness is located under the dash on the driver's side for easy installation of the brake controller.|$|E
40|$|We {{describe}} an {{autonomous mobile robot}} that employs a simple sensorimotor learning algorithm at three different behavioral levels to achieve coherent goal-directed behavior. The robot autonomously navigates to a goal destination within an obstacleridden environment by using the learned behaviors of obstacle-detection, obstacle-avoidance, and beaconfollowing. These reactive behaviors are learned in a hierarchical manner by using a hillclimbing routine that attempts to find the optimal transfer function from perceptions to actions for each behavior. We present experimental results that show that each behavior was successfully learned by the robot within a reasonably short period of time. We conclude by discussing salient features of our approach and possible directions for future research. 1. Introduction Traditionally, the task of developing a sensorimotor control architecture for a situated autonomous robot has been left to the human programmer of the robot. <b>Prewiring</b> robot behaviors [...] ...|$|E
2500|$|One {{hotly debated}} {{issue is whether}} the {{biological}} contribution includes capacities specific to language acquisition, {{often referred to as}} universal grammar. For fifty years, linguist Noam Chomsky has argued for the hypothesis that children have innate, language-specific abilities that facilitate and constrain language learning. [...] In particular, he has proposed that humans are biologically <b>prewired</b> to learn language at a certain time and in a certain way, arguing that children are born with a language acquisition device (LAD). However, since he developed the minimalist program, his latest version of theory of syntactic structure, Chomsky has reduced the elements of universal grammar, which he believes are <b>prewired</b> in humans to just the principle of recursion, thus voiding most of the nativist endeavor.|$|R
40|$|We {{present a}} new {{neural network model}} for {{processing}} of temporal patterns. This model, the gamma neural model, is as general as a convolution delay model with arbitrary weight kernels w(t). We show that the gamma model can be formulated as a (partially <b>prewired)</b> additive model. A temporal hebbian learning rule is derived and we establish links to related existing models for temporal processing. ...|$|R
40|$|Two major {{problems}} exist in studying development: Similar behaviors {{do not need}} to reflect the same underlying process 2 ̆ 7 different behaviors can reflect the same process; earlier behaviors do not necessarily lead to later behaviors. Empathy, rather than social contagion, is supported by different processes; contagion supported by <b>prewired</b> species behavior, empathy by cognitions, in particular, the cognitions about the self - a meta-representation...|$|R
40|$|Present neural {{models of}} {{classical}} conditioning all {{suffer from the}} same shortcoming: local representation of information (therefore, very precise neural <b>prewiring</b> is necessary). As an alternative we develop two neural models of classical conditioning which rely on distributed representations of information. Both models are of the Hopfield type. In the first model the existence of transmission delays is used to store temporal relations. The second model is based on interactions between spatially separated neural fields. Using tools from statistical mechanics we show that behavioural constraints can be met only if the Hebb rule is extended with inter- or intrasynaptic competition. 2 3 1. Introduction Connectionism has redirected the attention of cognitive scientists to learning and to the neural substrate in which cognitive processes are implemented. Conditioning has become an important field in which ideas from neural networks, behavioural science and neurophysiology are combined. [...] ...|$|E
40|$|There {{exists a}} theory of a single {{general-purpose}} learning algorithm which could explain the principles its operation. It assumes the initial rough architecture, a small library of simple innate circuits which are <b>prewired</b> at birth. and proposes that all significant mental algorithms are learned. Given current understanding and observations, this paper reviews and lists the ingredients of such an algorithm from architectural and functional perspectives. Comment: 18 page...|$|R
5000|$|Snap Circuits {{is a line}} of {{electronic}} kits manufactured by Elenco Electronics and aimed at children eight years and older. [...] The kits {{come in a variety}} of sizes, offering a range of building experience for the user, and may include motors, lamps and speakers. The kits consist of a breadboard with <b>prewired</b> interconnections, into which the various components can be snapped to easily create a working circuit.|$|R
40|$|This study {{examined}} newborns’ face preference using images {{of natural and}} scrambled faces in which {{the location of the}} inner features was distorted. The results demonstrate that newborns’ face preference is not confined to schematic configurations, but can be obtained also with veridical faces. Moreover, this phenomenon is not produced by a specific bias toward the face geometry, but derives from a domain-general bias toward configurations with more elements in the upper than in the lower half (i. e., top-heavy patterns). These results suggest that it may be unnecessary to assume the existence of a <b>prewired</b> tendency to orient toward the face geometry, and support the idea that faces do not possess a special status in newborns’ visual world...|$|R
5000|$|Affective responses, on {{the other}} hand, are more basic and may be less problematical in terms of assessment. Brewin has {{proposed}} two experiential processes that frame non-cognitive relations between various affective experiences: those that are <b>prewired</b> dispositions (i.e., non-conscious processes), able to [...] "select from the total stimulus array those stimuli that are casually relevant, using such criteria as perceptual salience, spatiotemporal cues, and predictive value in relation to data stored in memory" [...] (Brewin, 1989, p. 381), {{and those that are}} automatic (i.e., subconscious processes), characterized as [...] "rapid, relatively inflexible and difficult to modify... (requiring) minimal attention to occur and... (capable of being) activated without intention or awareness" [...] (1989 p. 381).|$|R
5000|$|Affective responses, on {{the other}} hand, are more basic and may be less problematical in terms of assessment. Brewin has {{proposed}} two experiential processes that frame non-cognitive relations between various affective experiences: those that are <b>prewired</b> dispositions (i.e., non-conscious processes), able to [...] "select from the total stimulus array those stimuli that are causally relevant, using such criteria as perceptual salience, spatiotemporal cues, and predictive value in relation to data stored in memory" [...] (Brewin, 1989, p. 381), {{and those that are}} automatic (i.e., subconscious processes), characterized as [...] "rapid, relatively inflexible and difficult to modify... (requiring) minimal attention to occur and... (capable of being) activated without intention or awareness" [...] (1989 p. 381).But a note should be considered on the differences between affect and emotion.|$|R
40|$|Connectionist models {{inherently}} include {{features and}} exhibit behaviors which {{are difficult to}} achieve with traditional logic-based models. Among the more important of such characteristics are 1) the ability to compute nearest match rather than requiring unification or exact match; 2) learning; 3) fault tolerance through the integration of overlapping modules, each {{of which may be}} incomplete or fallible, and 4) the possibility of scaling up such systems by many orders of magnitude, to operate more rapidly or to handle much larger problems, or both. However, it is unlikely that connectionist models will be able to learn all of language from experience, because it is unlikely that a full cognitive system could be built via learning from an initially random network; any successful large-scale connectionist learning system will have to be to some degree "genetically" <b>prewired...</b>|$|R
40|$|Odor hedonic {{perception}} {{relies on}} decoding the physicochemical properties of odorant molecules {{and can be}} influenced in humans by semantic knowledge. The effect of semantic knowledge on such <b>prewired</b> hedonic processing over the life span has remained unclear. The present study measured hedonic response to odors in different age groups (children, teenagers, young adults, and seniors) and found that children and seniors, two age groups characterized by either low level of (children) or weak access to (seniors) odor semantic knowledge, processed odor hedonics more {{on the basis of}} their physicochemical properties. In contrast, in teenagers and young adults, who show better levels of semantic odor representation, the role of physicochemical properties was less marked. These findings demonstrate for the first time that the biological determinants that make an odor pleasant or unpleasant are more powerful at either end of the life span...|$|R
40|$|AbstractPsychogenic non-epileptic {{seizures}} (PNES) {{consist of}} paroxystic events facilitated by a dysfunction in emotion processing. Models explaining the pathogenic mechanisms leading to these seizure-like episodes are limited. In this article, evidence that supports dysfunction {{at the level}} of arousal tolerance, cognitive-emotional information processing and volitional control is reviewed. A hypothetical pathophysiological mechanism is discussed based on functional neuroimaging evidence from PNES-related conditions and traits. This pathophysiological model suggests an alteration in the influence and connection of brain areas involved in emotion processing onto other brain areas responsible for sensorimotor and cognitive processes. Integrating this information, PNES are conceptualized as brief episodes facilitated by an unstable cognitive-emotional attention system. During the episodes, sensorimotor and cognitive processes are modified or not properly integrated, allowing the deployment of autonomous <b>prewired</b> behavioral tendencies. Finally, I elaborate on how therapeutic applications could be modified based on the proposed hypothetical model, potentially improving clinical outcomes...|$|R
40|$|Humans {{and most}} other animals have a dual origin. One of these origins {{is defined by the}} genetic {{background}} that assembles brains, thereby implanting <b>prewired</b> expectations about the sensory and causal regularities {{of the world in which}} we are born. The second origin is the organized system of experiences that provides a plethora of feedback and instructions that slowly shape the brain into its final status. In humans, these experiences start especially early to modify the newborn brain and provide an unusually variable tapestry. For decades, scientists have tried to disentangle the impact of nature and nurture, and have proposed mental territories that are mostly governed by one or the other. Here, I argue that genetic predispositions and environmentally dependent learning processes interact continuously at every neural and mental entity, from cortical development to social customs. Not a single territory of our mind is outside the scope of this interaction. PRELUD...|$|R
40|$|We explore an {{unconventional}} route {{in the search}} for multiferroicity investigating the magnetic doping of La 2 Ti 2 O 7 (LTO), a ferroelectric layered perovskite, by density functional calculations. We find that substitution of Ti (in the 3 d 0 configuration) by V (3 d 1) produces: (i) robust ferromagnetic (FM) order, achieving multiferroicity; (ii) structural and magnetic anisotropy, as the dopants cluster in magnetic chains. Moreover, the FM V-chains possess antiferro orbital ordering. We show that the origin of the strong FM coupling lies in the fruitful host-dopant combination: the layered structure of the host <b>prewires</b> the orbitals t 2 g with dxy and dxz lower in energy, the V dopants provide the full occupancy of the bonding levels. We further address the stability of chains vs. temperature and the role of oxygen vacancies in undoped as well as Sc-doped and V-doped LT...|$|R
40|$|This paper {{describes}} {{one model}} of school reconstruction, {{which includes a}} professional development school, being implemented at Celebration School in Celebration, Florida. The description highlights the educational practices and daily learning experiences of students at Celebration. The narrative provides {{a picture of the}} philosophical foundation and direction that the school's founders intended it to take. The community is a new town in which all homes have been <b>prewired</b> for technology. The school is divided into upper and lower school neighborhoods, with neighborhoods containing K- 5 students on the first floor, and 6 - 12 neighborhoods on the second floor. Classrooms are referred to as neighborhoods where a community of learners work, create, and discover together. In each neighborhood, approximately 100 multiage students are taught by 4 to 5 full-time teachers, a teaching assistant, and many adult volunteers. The school's philosophy stresses that everyone can learn, an...|$|R
40|$|Biological neural systems must {{grow their}} own {{connections}} and maintain topological relations between {{elements that are}} related to the sensory input surface. Artificial systems have traditionally <b>prewired</b> such maps, but the sensor arrangement is not always known and can be expensive to specify before run time. Here we present a method for learning and updating topographic maps in systems comprising modular, event-based elements. Using an unsupervised neural spike-timing-based learning rule combined with Hebbian learning, our algorithm uses the spatiotemporal coherence of the external world to train its network. It improves on existing algorithms by not assuming a known topography of the target map and includes a novel method for automatically detecting edge elements. We show how, for stimuli that are small relative to the sensor resolution, the temporal learning window parameters can be determined without using any user-specified constants. For stimuli that are larger relative to the sensor resolution, we provide a parameter extractio...|$|R
40|$|In {{this paper}} we present {{an example of}} the {{application}} of a technique, which we call robot shaping, to designing and building learning autonomous robots. Our autonomous robot (called HAMSTER 1) is a multi-sensor mobile robot that performs the task of collecting "food" and bringing it to its "nest". Its control architecture is based on the behavioral paradigm. The behavioral modules are implemented as classifier systems and are learned by a reinforcement learning technique exploiting the Bucket Brigade and an extended version of the Genetic Algorithm. The chief features of HAMSTER are that it combines innate (i. e., <b>prewired)</b> and learned behaviors, and that training was carried out in a simulated environment and then transferred to the real robot. KEYWORDS: Learning; classifier systems; autonomous robots 1. INTRODUCTION Our work is concerned with designing and building learning autonomous robots. Programming an autonomous robot so that it reliably acts in a dynamic environment is a d [...] ...|$|R
40|$|Abstract This study {{develops}} a neurocomputational architec-ture for grammatical processing in language production and language comprehension (grammatical encoding and decoding, respectively). It seeks to answer two questions. First, how is online syntactic structure {{formation of the}} complexity required by natural-language grammars possible in a fixed, preexisting neural network {{without the need for}} online creation of new connections or associations? Second, is it realistic to assume that the seemingly disparate instantiations of syntactic structure for-mation in grammatical encoding and grammatical decoding can run on the same neural infrastructure? This issue is prompted by accumulating experimental evidence for the hypothesis that the mechanisms for grammatical decoding overlap with those for grammatical encoding to a considerable extent, thus inviting the hypothesis of a single “grammatical coder. ” The paper answers both questions by providing the blueprint for a syntactic struc-ture formation mechanism that is entirely based on <b>prewired</b> circuitry (except for referential processing, which relies on the rapid learning capacity of the hippocampal complex), and can subserve decoding as well as encoding tasks. The model builds on the “Unification Space”model of syntactic parsing develope...|$|R
40|$|In this paper, {{we propose}} an unorthodox {{topology}} for datacenters that eliminates all hierarchical switches {{in favor of}} connecting nodes at random according to a small-worldinspired distribution. Specifically, we examine topologies where the underlying nodes are connected at the small scale in a regular pattern, such as a ring, torus or cube, such that every node can route efficiently to nodes in its immediate vicinity, and amended {{by the addition of}} random links to nodes throughout the datacenter, such that a greedy algorithm can route packets to far away locations efficiently. Coupled with geographical address assignment, the resulting network can provide content routing in addition to traditional routing, and thus efficiently implement key-value stores. The irregular but self-similar nature of the network facilitates constructing large networks easily using <b>prewired,</b> commodity racks. We show that Small-World Datacenters can achieve higher bandwidth and fault tolerance compared to both conventional hierarchical datacenters as well as the recently proposed CamCube topology. Coupled withhardware acceleration for packetswitching, small-world datacenters can achieve an order of magnitude higher bandwidth than a conventional datacenter, dependingon the network traffic...|$|R
50|$|In 1949, ADC {{sold its}} {{audiometer}} product line and Ralph Allison {{left the company}} {{to form a new}} business in California. ADC diversified and focused its efforts in the area of transformers and filters for power lines, military electronics, telephone jacks and plugs. In 1961, ADC merged with Magnetic Controls Company, a manufacturer of power supplies and magnetic amplifiers with strong ties to the U.S. space program. The resulting company, ADC Magnetic Controls, had a decade of mixed success. Although transformer sales boomed during the 1960s, other new product initiatives failed to materialize. Perhaps the most significant product innovation during this period was the bantam jack, a miniaturized component that eventually became the standard for telephone circuit access and patching. Building on its growing sales of jacks and plugs in the early 1970s, ADC introduced <b>prewired,</b> connectorized jackfields, wired assemblies and test equipment for telephone operating companies. By 1974 the company was on solid ground, and by 1976, ADC had become the largest independent supplier of test boards in the United States.|$|R
40|$|A {{system based}} on {{low-power}} radio transponders and associated analog and digital electronic circuitry has been developed for locating firefighters and other emergency workers deployed in a building or other structure. The system has obvious potential for saving lives and {{reducing the risk of}} injuries. The system includes (1) a central station equipped with a computer and a transceiver; (2) active radio-frequency (RF) identification tags, each placed in a different room or region of the structure; and (3) transponder units worn by the emergency workers. The RF identification tags can be installed in a new building as built-in components of standard fire-detection devices or ground-fault electrical outlets or can be attached to such devices in a previously constructed building, without need for rewiring the building. Each RF identification tag contains information that uniquely identifies it. When each tag is installed, information on its location and identity are reported to, and stored at, the central station. In an emergency, if a building has not been <b>prewired</b> with RF identification tags, leading emergency workers could drop sequentially numbered portable tags in the rooms of the building, reporting the tag numbers and locations by radio to the central station as they proceed...|$|R
40|$|How {{language}} and cognition interact in thinking? Is language just used for communication of completed thoughts, {{or is it}} fundamental for thinking? Existing approaches have not led to a computational theory. We develop a hypothesis that {{language and}} cognition are two separate but closely interacting mechanisms. Language accumulates cultural wisdom; cognition develops mental representations modeling surrounding world and adapts cultural knowledge to concrete circumstances of life. Language is acquired from surrounding language “ready-made” and therefore can be acquired early in life. This early acquisition of language in childhood encompasses the entire hierarchy from sounds to words, to phrases, and to highest concepts existing in culture. Cognition is developed from experience. Yet cognition cannot be acquired from experience alone; language is a necessary intermediary, a “teacher. ” A mathematical model is developed; it overcomes previous difficulties and leads to a computational theory. This model is consistent with Arbib's “language <b>prewired</b> brain” built on top of mirror neuron system. It models recent neuroimaging data about cognition, remaining unnoticed by other theories. A number of properties of language and cognition are explained, which previously seemed mysterious, including influence of language grammar on cultural evolution, which may explain specifics of English and Arabic cultures...|$|R
40|$|The study {{develops}} a neurocomputational architecture for grammatical processing in language production and language comprehension (grammatical encoding and decoding, respectively). It seeks to answer two questions. First, how is online syntactic structure {{formation of the}} complexity required by natural-language grammars possible in a fixed, preexisting neural network {{without the need for}} online creation of new connections or associations? Second, is it realistic to assume that the seemingly disparate instantiations of syntactic structure formation in grammatical encoding and grammatical decoding can run on the same neural infrastructure? This issue is prompted by accumulating experimental evidence for the hypothesis that the mechanisms for grammatical decoding overlap with those for grammatical encoding to a considerable extent, thus inviting the hypothesis of a single “grammatical coder. ” The paper answers both questions by providing the blueprint for a syntactic structure formation mechanism that is entirely based on <b>prewired</b> circuitry (except for referential processing, which relies on the rapid learning capacity of the hippocampal complex), and can subserve decoding as well as encoding tasks. The model builds on the “Unification Space” model of syntactic parsing developed by Vosse & Kempen (2000, 2008, 2009). The design includes a neurocomputational mechanism for the treatment of an important class of grammatical movement phenomena...|$|R
40|$|Although already William James and, more explicitly, Donald Hebb's {{theory of}} cell {{assemblies}} {{have suggested that}} activity-dependent rewiring of neuronal networks is the substrate of learning and memory, {{over the last six}} decades most theoretical work on memory has focused on plasticity of existing synapses in <b>prewired</b> networks. Research in the last decade has emphasized that structural modification of synaptic connectivity is common in the adult brain and tightly correlated with learning and memory. Here we present a parsimonious computational model for learning by structural plasticity. The basic modeling units are "potential synapses" defined as locations in the network where synapses can potentially grow to connect two neurons. This model generalizes well-known previous models for associative learning based on weight plasticity. Therefore, existing theory can be applied to analyze how many memories and how much information structural plasticity can store in a synapse. Surprisingly, we find that structural plasticity largely outperforms weight plasticity and can achieve a much higher storage capacity per synapse. The effect of structural plasticity on the structure of sparsely connected networks is quite intuitive: Structural plasticity increases the "effectual network connectivity", that is, the network wiring that specifically supports storage and recall of the memories. Further, this model of structural plasticity produces gradients of effectual connectivity in the course of learning, thereby explaining various cognitive phenomena including graded amnesia, catastrophic forgetting, and the spacing effect...|$|R
40|$|Synesthesia is {{commonly}} {{thought to be}} a phenomenon of fixed associations between an outside inducer and a vivid concurrent experience. Hence, it has been proposed that synesthesia occurs due to additional connections in the brain with which synesthetes are born. Here we show that synesthesia can be a much richer and more flexible phenomenon with a capability to creatively construct novel synesthetic experiences as events unfold in people’s lives. We describe here cases of synesthetes who occasionally generate novel synesthetic experience, called one-shot synesthesias. These synesthetic experiences seem to share all the properties with the classical synesthetic associations except that they occur extremely rarely, people recalling only a few events over the lifetime. It appears that these one-shots are not created at random but are instead responses to specific life events. We contrast the properties of those rare synesthetic events with other, more commonly known forms of synesthesia that also create novel synesthetic experiences, but at a high rate—sometimes creating novel experiences every few seconds. We argue that one-shot synesthesias indicate that synesthetic associations are by their nature not <b>prewired</b> at birth but are dynamically constructed through mental operations and according to the needs of a synesthetic mind. Our conclusions have implications for understanding the biological underpinnings of synesthesia and the role the phenomenon plays in the lives of people endowed with synesthetic capacities...|$|R
40|$|Copyright © 2011 Leonid Perlovsky. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. How language and cognition interact in thinking? Is language just used for communication of completed thoughts, or is it fundamental for thinking? Existing approaches have not led to a computational theory. We develop a hypothesis that language and cognition are two separate but closely interacting mechanisms. Language accumulates cultural wisdom; cognition develops mental representations modeling surrounding world and adapts cultural knowledge to concrete circumstances of life. Language is acquired from surrounding language “ready-made ” and therefore can be acquired early in life. This early acquisition of language in childhood encompasses the entire hierarchy from sounds to words, to phrases, and to highest concepts existing in culture. Cognition is developed from experience. Yet cognition cannot be acquired from experience alone; language is a necessary intermediary, a “teacher. ” A mathematical model is developed; it overcomes previous difficulties and leads to a computational theory. This model is consistent with Arbib’s “language <b>prewired</b> brain ” built on top of mirror neuron system. It models recent neuroimaging data about cognition, remaining unnoticed by other theories. A number of properties of language and cognition are explained, which previously seemed mysterious, including influence of language grammar on cultural evolution, which may explain specifics of English and Arabic cultures. 1. Linguistics and Mathematical Model...|$|R
40|$|GRAMMAR {{coordinated by}} DLR {{represents}} a highly innovative EU-funded research project aiming at developing a prototype Global Navigation Satellite Systems receiver using a single chip dual frequency front-end. The prototype is targeted at mass market applications, with the widest potential exploitation. Within the two year project duration and a firm fixed budget, {{we planned to}} manufacture three chips to mitigate the risks involved in developing a chip (quality, time, costs). Unfortunately, the project was hit by the financial crisis in an unexpected way: The dates for chip manufacturing were delayed for several months by the external manufacturer. This was an external-unpredictable risk. At the same time, the identified risk of a non-functional chip occurred. What next? First, the project management team investigated {{the impact of the}} two risks on the project goals and constraints and updated the risk register. Second, we developed alternative solutions which are reduced scope to accept risk, change scope to mitigate risk, or change schedule to mitigate risk. Third, we evaluated the consequences of the alternative solutions. Our conclusion was that the most favorable solution is a project extension. Fourth, we <b>prewired</b> with the sponsor and stakeholders on the solutions and discussed further steps. We reached consensus with the stakeholders to go for a project extension. This resulted in executing a formal change process as a fifth step. Outcome: The project extension by six months was approved by the sponsor without change of scope, budget, and quality but significantly reducing the risks. ...|$|R
40|$|Adolescence, {{defined as}} a {{transition}} phase toward autonomy and independence, is a natural time of learning and adjustment, particularly {{in the setting of}} long-term goals and personal aspirations. It also is a period of heightened sensation seeking, including risk taking and reckless behaviors, which is a major cause of morbidity and mortality among teenagers. Recent observations suggest that a relative immaturity in frontal cortical neural systems may underlie the adolescent propensity for uninhibited risk taking and hazardous behaviors. However, converging preclinical and clinical studies do not support a simple model of frontal cortical immaturity, and there is substantial evidence that adolescents engage in dangerous activities, including drug abuse, despite knowing and understanding the risks involved. Therefore, a current consensus considers that much brain development during adolescence occurs in brain regions and systems that are critically involved in the perception and evaluation of risk and reward, leading to important changes in social and affective processing. Hence, rather than naive, immature and vulnerable, the adolescent brain, particularly the prefrontal cortex, should be considered as <b>prewired</b> for expecting novel experiences. In this perspective, thrill seeking may not represent a danger but rather a window of opportunities permitting the development of cognitive control through multiple experiences. However, if the maturation of brain systems implicated in self-regulation is contextually dependent, {{it is important to understand}} which experiences matter most. In particular, it is essential to unveil the underpinning mechanisms by which recurrent adverse episodes of stress or unrestricted access to drugs can shape the adolescent brain and potentially trigger life-long maladaptive responses...|$|R
40|$|In this article, {{we present}} an {{isotropic}} unsupervised algorithm for temporal sequence learning. Nospecial reward signal is used such that all inputs are completely isotropic. All input signals are bandpass filtered before converging onto a linear output neuron. All synaptic weights change {{according to the}} correlation of bandpass-filtered inputs with the derivative of the output. We investigate the algorithm in an open- and a closed-loop condition, the latter being defined by embedding the learning system into a behavioral feedback loop. In the open-loop condition, {{we find that the}} linear structure of the algorithm allows analytically calculating the shape of the weight change, which is strictly heterosynaptic and follows the shape of the weight change curves found in spike-time-dependent plasticity. Furthermore, we show that synaptic weights stabilize automatically when no more temporal differences exist between the inputs without additional normalizing measures. In the second part of this study, the algorithm is is placed in an environment that leads to closed sensormotor loop. To this end, a robot is programmed with a <b>prewired</b> retraction reflex reaction in response to collisions. Through isotropic sequence order (ISO) learning, the robot achieves collision avoidance by learning the correlation between his early range-finder signals and the later occurring collision signal. Synaptic weights stabilize at the end of learning as theoretically predicted. Finally, we discuss the relation of ISO learning with other drive reinforcement models and with the commonly used temporal difference learning algorithm. This study is followed up by a mathematical analysis of the closed-loop situation in the companion article in this issue, “ISO Learning Approximates a Solution to the Inverse-Controller Problem in an Unsupervised Behavioral Paradigm” (pp. 865 – 884) ...|$|R
40|$|Biological neural systems must {{grow their}} own {{connections}} and maintain topological relations between {{elements that are}} related to the sensory input surface. Artificial systems have traditionally <b>prewired</b> such maps, but the sensor arrangement is not always known and can be expensive to specify before run time. Here we present a method for learning and updating topographic maps in systems comprising modular, event-based elements. Using an unsupervised neural spike-timing-based learning rule combined with Hebbian learning, our algorithm uses the spatiotemporal coherence of the external world to train its network. It improves on existing algorithms by not assuming a known topography of the target map and includes a novel method for automatically detecting edge elements. We show how, for stimuli that are small relative to the sensor resolution, the temporal learning window parameters can be determined without using any user-specified constants. For stimuli that are larger relative to the sensor resolution, we provide a parameter extraction method that generally outperforms the small-stimulus method but requires one user-specified constant. The algorithm was tested on real data from a 64 × 64 -pixel section of an event-based temporal contrast silicon retina and a 360 -tile tactile luminous floor. It learned 95. 8 % of the correct neighborhood relations for the silicon retina within about 400 seconds of real-world input from a driving scene and 98. 1 % correct for the sensory floor after about 160 minutes of human pedestrian traffic. Residual errors occurred in regions receiving little or ambiguous input, and the learned topological representations were able to update automatically in response to simulated damage. Our algorithm has applications in the design of modular autonomous systems in which the interfaces between components are learned during operation rather than at design time...|$|R
40|$|Abstract-We {{introduce}} a new multilayer routing strategy for high-performance MCMs {{whose objective is to}} route all nets optimizing routing performance and to satisfy various design constraints (e. g., minimizing coupling between vias as well as between signal lines and minimizing discontinuities such as vias and bends). First we introduce the Pin Pre-wiring and Redktnbution Problem, which redistributes the pins or <b>prewired</b> subnets uniformly over the MCM substrate using pin redistribution layers. Pin redistribution is very important in MCM design. Our experience shows that it not only provides a global distribution for the pins congested in the chip site over the chip layer so as to ease the future routing difficulty, but also reduces the capacitive coupling between vias induced by many layers (up to 63 layers) by separating the pins far apart. The goal of the problem is to minimiie the number of layers required to redistribute the entire set. An. effective approach is proposed for solving this problem. Next we develop four effective algorithms for signal distribution, i. e., two variations on both singlelayer routing and xy plane-pair routing paradigms. Based on these algorithms, a mixed version of single-hyer routing and xy phne-pair routing techniques is proposed to establish a good trade-off between them to favor circuit performance and/or design objective instead of overemphasizing on the area minimization. One strategy is to apply single-layer routing iteratively until a % of the nets are routed, then route the remaining (100 - a) % nets by xy planepair routing process. This provides the designer with a trade-off (e. g., between the number of layers and total number of vias) and shows the versatility of the proposed techniques. Various strategies are compared using practical MCM examples (each MCM has 25 - 100 ICs, 25 - 60 YOs per IC, and 50 - 1,ZOO nets). I...|$|R
40|$|National audiencePrimates {{can learn}} complex {{sequences}} {{that can be}} represented {{in the form of}} abstract categories, and even more abstract hierarchical structures such as language. In order to study how these abstractions are formed and because of the highly recurrent connectivity in prefrontal cortex (PFC) we model part of it using recurrent neural networks. Particularly, we use the Reservoir Computing paradigm to model PFC and part of the basal ganglia: a recurrent neural network with random connections kept constant models the prefrontal cortex, and a read-out layer (i. e. output layer) models the striatum. This model was trained to perform language syntactic processing; in particular, thematic role assignment: for a given sentence this corresponds to answer the question "Who did what to whom?". Inspiring from language acquisition theories (Tomasello 2003), the model processes categories (i. e. abstractions) of sentences which are called "grammatical constructions" (Goldberg 1995). After training, it is able to (1) process correctly the majority of the grammatical constructions that were not learned, demonstrating generalization capabilities, and (2) to make online predictions (of thematic roles) while processing a grammatical construction. Moreover, we observed that when the model processes less frequent constructions an important shift in output predictions occurs. It is proposed that a significant modification of predictions {{in a short period of}} time is responsible for generating Evoked-Related Potentials (ERP) such as the P 600 which typically occurs when unusual sentences structures are processed (Hinaut & Dominey 2013). Subsequently, to show the ability of the model to deal with a real-world application, the model was successfully applied in the framework of human-robot interaction for both sentence comprehension and production (Hinaut et al, 2014). Recently, we showed that the very same instance of reservoir could learn both English and French sentences at the same time, suggesting that a common "output" (striatal) representations could be used even in the case of different languages (Hinaut et al, 2015). Moreover, the model is able to learn small corpora in fifteen European or Asian languages with different word order (Hinaut et al, in revision). In a nutshell, this suggests that a random neural network with no <b>prewired</b> structure seems enough to learn the syntax of languages different in structure and in word order...|$|R
40|$|Response {{inhibition}} is {{the ability}} to suppress inadequate but automatically activated, prepotent or ongoing response tendencies. In the framework of motor inhibition, two distinct operating strategies have been described: “proactive” and “reactive” control modes. In the proactive modality, inhibition is recruited in advance by predictive signals, and actively maintained before its enactment. Conversely, in the reactive control mode, inhibition is phasically enacted after the detection of the inhibitory signal. To date, ample evidence points to a core cerebral network for reactive inhibition comprising the right inferior frontal gyrus (rIFG), the presupplementary motor area (pre-SMA) and the basal ganglia (BG). Moreover, fMRI studies showed that cerebral activations during proactive and reactive inhibition largely overlap. These findings suggest that {{at least part of the}} neural network for reactive inhibition is recruited in advance, priming cortical regions in preparation for the upcoming inhibition. So far, proactive and reactive inhibitory mechanisms have been investigated during tasks in which the requested response to be stopped or withheld was an “overt” action execution (AE) (i. e., a movement effectively performed). Nevertheless, inhibitory mechanisms are also relevant for motor control during “covert actions” (i. e., potential motor acts not overtly performed), such as motor imagery (MI). MI is the conscious, voluntary mental rehearsal of action representations without any overt movement. Previous studies revealed a substantial overlap of activated motor-related brain networks in premotor, parietal and subcortical regions during overtly executed and imagined movements. Notwithstanding this evidence for a shared set of cerebral regions involved in encoding actions, whether or not those actions are effectively executed, the neural bases of motor inhibition during MI, preventing covert action from being overtly performed, in spite of the activation of the motor system, remain to be fully clarified. Taking into account this background, we performed a high density EEG study evaluating cerebral mechanisms and their related sources elicited during two types of cued Go/NoGo task, requiring the execution or withholding of an overt (Go) or a covert (MI) action, respectively. The EEG analyses were performed in two steps, with different aims: 1) Analysis of the “response phase” of the cued overt and covert Go/NoGo tasks, for the evaluation of reactive inhibitory control of overt and covert actions. 2) Analysis of the “preparatory phase” of the cued overt and covert Go/NoGo EEG datasets, focusing on cerebral activities time-locked to the preparatory signals, for the evaluation of proactive inhibitory mechanisms and their related neural sources. For these purposes, a spatiotemporal analysis of the scalp electric fields was applied on the EEG data recorded during the overt and covert Go/NoGo tasks. The spatiotemporal approach provide an objective definition of time windows for source analysis, relying on the statistical proof that the electric fields are different and thus generated by different neural sources. The analysis of the “response phase” revealed that key nodes of the inhibitory circuit, underpinning inhibition of the overt movement during the NoGo response, were also activated during the MI enactment. In both cases, inhibition relied on the activation of pre-SMA and rIFG, but with different temporal patterns of activation in accord with the intended “covert” or “overt” modality of motor performance. During the NoGo condition, the pre-SMA and rIFG were sequentially activated, pointing to an early decisional role of pre-SMA and to a later role of rIFG in the enactment of inhibitory control of the overt action. Conversely, a concomitant activation of pre-SMA and rIFG emerged during the imagined motor response. This latter finding suggested that an inhibitory mechanism (likely underpinned by the rIFG), could be <b>prewired</b> into a prepared “covert modality” of motor response, as an intrinsic component of the MI enactment. This mechanism would allow the rehearsal of the imagined motor representations, without any overt movement. The analyses of the “preparatory phase”, confirmed in both overt and covert Go/NoGo tasks the priming of cerebral regions pertaining to putative inhibitory network, reactively triggered in the following response phase. Nonetheless, differences in the preparatory strategies between the two tasks emerged, depending on the intended “overt” or “covert” modality of the possible incoming motor response. During the preparation of the overt Go/NoGo task, the cue primed the possible overt response programs in motor and premotor cortex. At the same time, through preactivation of a pre-SMA-related decisional mechanism, it triggered a parallel preparation for the successful response selection and/or inhibition during the subsequent response phase. Conversely, the preparatory strategy for the covert Go/NoGo task was centred on the goal-oriented priming of an inhibitory mechanism related to the rIFG that, being tuned to the instructed covert modality of the motor performance and instantiated during the subsequent MI enactment, allowed the imagined response to remain a potential motor act. Taken together, the results of the present study demonstrate a substantial overlap of cerebral networks activated during proactive recruitment and subsequent reactive enactment of motor inhibition in both overt and covert actions. At the same time, our data show that preparatory cues predisposed ab initio a different organization of the cerebral areas (in particular of the pre-SMA and rIFG) involved with sensorimotor transformations and motor inhibitory control for executed and imagined actions. During the preparatory phases of our cued overt and covert Go/NoGo tasks, the different adopted strategies were tuned to the “how” of the motor performance, reflecting the intended overt and covert modality of the possible incoming action...|$|R
