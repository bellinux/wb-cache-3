7|176|Public
40|$|Cost {{and power}} {{consumption}} {{are two of}} the most important design factors for many embedded systems, particularly consumer devices. Products such as Personal Digital Assistants, pagers with integrated data services, and smart phones have fixed performance requirements but unlimited appetites for reduced cost and increased battery life. <b>Program</b> <b>compression</b> is one technique {{that can be used to}} attack both of these problems. Compressed programs require less memory, thus reducing the cost of both direct materials and manufacturing. Furthermore, by relying on compressed memory, the total number of memory references is reduced. This reduction saves power by lowering the traffic on high capacitance buses. This paper will discuss a new approach to implementing transparent <b>program</b> <b>compression</b> that requires little or no hardware support. Procedures are compressed individually, and a directory structure is used to bind them together at runtime. Decompressed procedures are explicitly cached in ordin [...] ...|$|E
40|$|Trigram {{language}} {{models are}} compressed using a Golomb coding method {{inspired by the}} original Unix spell <b>program.</b> <b>Compression</b> methods trade off space, time and accuracy (loss). The proposed HashTBO method optimizes space {{at the expense of}} time and accuracy. Trigram language models are normally considered memory hogs, but with HashTBO, it is possible to squeeze a trigram language model into a few megabytes or less. HashTBO made it possible to ship a trigram contextual speller in Microsoft Office 2007...|$|E
40|$|Program code size {{has become}} a {{critical}} design constraint of embedded systems. Code compression {{is one of the}} approaches to reduce the program code size; it results in smaller memories and reduced cost of the chip. In this paper, bitwise and dictionary modeling schemes for code compression are evaluated on transport triggered architec-ture processors, designed for four applications taken from different application domains. Results of the bitwise mod-eling scheme are promising, whereas the dictionary mod-eling scheme needs further improvements to be profitable. KEY WORDS transport triggered architecture, customizable processor ar-chitecture, digital signal processing, <b>program</b> <b>compression,</b> bitwise modeling, dictionary modeling...|$|E
40|$|Intermittent <b>programmed</b> <b>compression</b> of {{the chronically}} ischemic limb is {{associated}} with arteriogenesis. However, progenitor cell elements contributing to this neovascularization are typically diminished in number and function in the elderly dysvascular patient, particularly {{in the presence of}} diabetes, renal insufficiency, and cardiac disease. Granulocyte-colony stimulation factor (G-CSF) dramatically boosts the circulating progenitor cell count. G-CSF was administered in 2 patients being treated for ischemic wounds with an intermittent <b>programmed</b> pneumatic <b>compression</b> device (PPCD). Both had comorbidities associated with diminished circulating progenitor cell counts. Remarkable clinical, hemodynamic, and angiographic improvement was observed. Further study of this synergistic strategy is warranted...|$|R
50|$|A precompressor is a {{computer}} program, which alters file content so that a real lossless <b>compression</b> <b>program</b> will achieve better results than without precompressing. This is possible by creating such patterns that <b>compression</b> <b>programs</b> will recognize.|$|R
50|$|The <b>compression</b> <b>programs</b> of the {{following}} are available from external links.|$|R
40|$|We {{address the}} problem of {{performance}} improvement of a processor array in a multiuser environment. We assume that the array can be dynamically partitioned into subarrays that can be allocated to independent programs. When a program completes, it releases its subarray for future use. Since programs require subarrays of various sizes, an allocation method should be used that reduces array fragmentation and, as a result, improves processor utilization. If, before the allocation, the processor requirements of programs are minimized, then more programs can be placed on the array concurrently. This results in lower turnaround times for incoming programs. In this paper we present <b>program</b> <b>compression,</b> a compile-time method that minimizes processor requirements of programs, and subarray allocation, an allocation method that reduces array fragmentation. Experimental results show that eOEciency of the computation on processor arrays can be considerably improved if compiler and operating system ma [...] ...|$|E
40|$|Code-size {{reduction}} {{is an important}} area of investigation for computer system developers due to {{the increasing use of}} technologies such as communication networks and embedded systems for which program size is an important factor. A new software-based method of <b>program</b> <b>compression</b> for languages with interpreter-based runtime systems is described. The method employs a modified version of a standard dictionary-based text compression algorithm to produce a shorter encoding for a given program and a runtime system tailored for it. In comparison with previous software-based code-size reduction methods the new method is simpler to implement and imposes lower overhead at compile time. Its performance on a representative suite of Haskell programs is analysed. Executable space savings of 16 – 26 % are achieved as a result of code compression, exclusion of unused instructions from the runtime, and inclusion of the standard library in the optimisation. To the best of the authors’ knowledge, this is the first work on running compressed code for a purely declarative and functional language. 15 page(s...|$|E
40|$|In an {{embedded}} system, {{the cost}} of storing a program on-chip can {{be as high as}} {{the cost of}} a microprocessor. Compressing an application’s code {{to reduce the amount of}} memory required is an attractive way to decrease costs. In this paper, we examine an executable form of <b>program</b> <b>compression</b> using echo instructions. With echo instructions, two or more similar, but not necessarily identical, sections of code can be reduced to a single copy of the repeating code. The single copy is left in the location of one of the original sections of the code. All the other sections are replaced with a single echo instruction that tells the processor to execute a subset of the instructions from the single copy. We present results of using echo instructions from a full compiler and simulator implementation that takes input programs, compresses them with echo instructions, and simulates their execution. We apply register renaming and instruction scheduling to expose more similarities in code, use profiles to guide compression, and propose minor architectural modifications to support echo instructions. In addition, we compare and combine echo instructions with two prior compression techniques: procedural abstraction and IBM’s CodePack...|$|E
50|$|Pack is a (now deprecated) Unix shell <b>compression</b> <b>program</b> {{based on}} Huffman coding.|$|R
5000|$|... xz is a {{lossless}} data <b>compression</b> <b>program</b> {{and file}} format which incorporates the LZMA/LZMA2 compression algorithms.|$|R
40|$|We {{introduce}} {{the problem of}} compressing partially ordered strings: given string 2 and a binary independence relation I over, how can we compactly represent an input if the decompressor is allowed to reconstruct any string that {{can be obtained from}} by repeatedly swapping adjacent independent symbols? Such partially ordered strings are also known as Mazurkiewicz traces, and naturally model executions of concurrent <b>programs.</b> <b>Compression</b> techniques have been applied with much success to sequential program traces not only to store them compactly but to discover important pro ling patterns within them. For compression to achieve similar aims for concurrent program traces we should exploit the extra freedom provided by the independence relation. Many popula...|$|R
40|$|This paper {{describes}} {{the design and}} implementation of a method for producing compact, bytecoded instruction sets and interpreters for them. It accepts a grammar for programs written using a simple bytecoded stack-based instruction set, {{as well as a}} training set of sample programs. The system transforms the grammar, creating an expanded grammar that represents the same language as the original grammar, but permits a shorter derivation of the sample programs and others like them. A program's derivation under the expanded grammar forms the compressed bytecode representation of the program. The interpreter for this bytecode is automatically generated from the original bytecode interpreter and the expanded grammar. Programs expressed using compressed bytecode can be substantially smaller than their original bytecode representation and even their machine code representation. For example, compression cuts the bytecode for lcc from 199 KB to 58 KB but increases the size of the interpreter by just over 11 KB. Categories and Subject Descriptors D. 3. 3 [Programming Languages]: Processors [...] -optimization, run-time environments. General Terms Algorithms, Performance, Design, Economics, Experimentation, Languages, Theory. Keywords <b>Program</b> <b>compression,</b> bytecode interpretation, variable-to-fixed length codes, context-free grammars. 1...|$|E
50|$|The PAQ {{series of}} data <b>compression</b> <b>programs</b> use context mixing to assign probabilities to {{individual}} {{bits of the}} input.|$|R
5000|$|GNU tar {{lets you}} {{implement}} your own filters https://www.gnu.org/software/tar/manual/tar.html#index-use_002dcompress_002dprogram-460, {{allowing you to}} use other <b>compression</b> <b>programs</b> (p7zip, ...) and filters (GPG, ...).|$|R
50|$|The Sobig worm {{was written}} using the Microsoft Visual C++ compiler, and {{subsequently}} compressed using a data <b>compression</b> <b>program</b> called tElock.|$|R
50|$|This <b>program</b> {{includes}} <b>compression</b> and encryption features. It creates compatible zip files, and it {{is possible}} to choose whether to protect zip files with a password or synchronize the zip file content. Iperius Backup can create unlimited-size zip archives (Zip 64) and it fully supports unicode and long paths.|$|R
50|$|In 1993-94, Stac Electronics {{successfully}} sued Microsoft for infringement of LZS patents in the DoubleSpace disk <b>compression</b> <b>program</b> {{included with}} MS-DOS 6.0.|$|R
5000|$|The Archive Comparison Test (ACT) by Jeff Gilchrist {{included}} 162 DOS/Windows and 8 Macintosh lossless <b>compression</b> <b>programs,</b> but it {{was last}} updated in 2002.|$|R
50|$|Generated sounds can {{be stored}} in WAV or MP3 format and can be used as samples in other <b>programs.</b> For MP3 <b>compression</b> the open source LAME encoder is used.|$|R
5000|$|The {{technical}} {{concept was}} first described by Malcolm Taylor in his data <b>compression</b> <b>program</b> RK (or WinRK). By QUAD -Compressor of Ilia Muraviev {{there is a}} free implementation (under LGPL) ...|$|R
5000|$|... iLabs led the {{development}} of Artificial Intelligence tools in Italy: the first relational database (1984), a self-monitoring and self-modifying application for production planning (1985), <b>programs</b> for data <b>compression</b> (1980), visual recognition (1983), cryptography (1987).|$|R
40|$|Internet {{computing}} is {{facilitated by}} the remote execution methodology in which programs transfer to a destination for execution. Since transfer time can substantially degrade performance of remotely executed (mobile) <b>programs,</b> file <b>compression</b> is used {{to reduce the amount}} that transfers. Compression techniques however, must trade off compression ratio for decompression time due to the algorithmic complexity of the former since the latter is performed at runtime in this environment...|$|R
50|$|MediaCoder uses various {{open source}} (and several proprietary) {{audio and video}} codecs to transcode media files to {{different}} audio/video formats. Common uses for the <b>program</b> include <b>compression,</b> file type conversion, remuxing and extraction of audio from video files. Many formats are supported, including MP3, Vorbis, Opus, Advanced Audio Coding (AAC), Windows Media Audio (WMA), RealAudio, WAV, H.264/MPEG-4 AVC, MPEG-4 Part 2, MPEG-2, Audio Video Interleave (AVI), Video CD and DVD-Video.|$|R
40|$|Abstract. We {{present a}} method {{to speed up the}} dynamic program {{algorithms}} used for solving the HMM decoding and training problems for discrete time-independent HMMs. We discuss the application of our method to Viterbi’s decoding and training algorithms [21], {{as well as to the}} forward-backward and Baum-Welch [4] algorithms. Our approach is based on identifying repeated substrings in the observed input sequence. We describe three algorithms based alternatively on byte pair encoding (BPE) [19], run length encoding (RLE) and Lempel-Ziv (LZ 78) pars-ing [22]. Compared to Viterbi’s algorithm, we achieve a speedup of Ω(r) using BPE, a speedup of Ω (r log r) using RLE, and a speedup of Ω (log n k) using LZ 78, where k is the number of hidden states, n is the length of the observed sequence and r is its compression ratio (under each compression scheme). Our experimental results demonstrate that our new algorithms are indeed faster in practice. Furthermore, unlike Viterbi’s algorithm, our algorithms are highly parallelizable. Key words: HMM, Viterbi, dynamic <b>programming,</b> <b>compression...</b>|$|R
50|$|The table below {{shows the}} {{compressed}} sizes of the 14 file Calgary corpus using both methods for some popular <b>compression</b> <b>programs.</b> Options, when used, select best compression. For a more complete list, see the above benchmarks.|$|R
50|$|The {{contest is}} open ended. It {{is open to}} everyone. To enter, a {{competitor}} must submit a <b>compression</b> <b>program</b> and a decompressor that decompresses to the file enwik8. It is also possible to submit a compressed file instead of the <b>compression</b> <b>program.</b> The total size of the compressed file and decompressor (as a Win32 or Linux executable) must not be larger than 99% of the previous prize winning entry. For each one percent improvement, the competitor wins 500 euros. The decompression program must also meet execution time and memory constraints, currently 10 hours on a 2 GHz Pentium 4 with 1 GB memory. These constraints may be relaxed in the future.|$|R
5000|$|Due to the {{possibility}} to use pax in a cpio-like fashion, {{it is possible to}} use whatever <b>compression</b> <b>program,</b> as an example xz is used here: pax -w [...] | xz > archive.tar.xzand listing an xz-compressed archive: xzcat archive.tar.xz | pax ...|$|R
5000|$|... {{compress}} is a Unix shell <b>compression</b> <b>program</b> {{based on}} the LZW compression algorithm. Compared to more modern compression utilities such as gzip and bzip2, compress performs faster and with less memory usage, {{at the cost of}} a significantly lower compression ratio.|$|R
25|$|USC {{is home to}} the world’s most {{powerful}} quantum computer, which is presently housed in a super-cooled, magnetically shielded facility at the USC Information Sciences Institute. The only other commercially available quantum computing system is operated jointly by NASA and Google. USC {{was also one of the}} earliest nodes on ARPANET and is the birthplace of the Domain Name System. Other technologies invented at USC include DNA computing, dynamic <b>programming,</b> image <b>compression,</b> VoIP, and antivirus software.|$|R
50|$|It {{follows the}} Unix {{philosophy}} that each program should accomplish a single task to perfection, {{as opposed to}} attempting to accomplish everything with one tool. As compression technology progresses, users may use different <b>compression</b> <b>programs</b> without having to modify or abandon their archiver.|$|R
50|$|Published {{research}} on this family of algorithms can be found {{as far back as}} the mid-1980s. Software implementations were not popular until the early 1990s because PPM algorithms require a significant amount of RAM. Recent PPM implementations are among the best-performing lossless <b>compression</b> <b>programs</b> for natural language text.|$|R
50|$|Tools such as PuCrunch, an LZ77 {{data and}} {{executable}} self extracting <b>compression</b> <b>program,</b> {{are also available}} released under GNU LGPL. Sprite editors like Sprite Pad allow you to design C64 Sprites and animations using Windows. GoatTracker allows you to write music using modern OSs and uses the ReSID engine.|$|R
40|$|While {{achieving}} a compression ratio of 2. 0 bits/base, the new algorithm codes non-N bases in fixed length. It dramatically reduces {{the time of}} coding and decoding than previous DNA compression algorithms and some universal <b>compression</b> <b>programs.</b> Comment: 2 pages, 2 tables,using Bioinformatics Latex template,no more relationship between us and that magazin...|$|R
40|$|Abstract:- In {{this paper}} novel {{compression}} techniques are developed for portable heart-monitoring equipment that could also {{form the basis}} for more intelligent diagnostic systems thanks to the way the compression algorithms depend on signal classification. There are two main categories of compression which are employed for electrocardiogram signals: lossless and lossy. Design of an optimal Wiener filter is implemented to remove noise from a signal, considering that the signal is statistically stationary and the noise is a stationary random process that is statistically independent of the signal. Two <b>programs</b> for <b>compression</b> and Wiener optimal filtering are realised in MATLAB...|$|R
5000|$|Most {{lossless}} <b>compression</b> <b>programs</b> do {{two things}} in sequence: the first step generates a statistical model for the input data, and the second step uses this model to map input data to bit sequences {{in such a way}} that [...] "probable" [...] (e.g. frequently encountered) data will produce shorter output than [...] "improbable" [...] data.|$|R
