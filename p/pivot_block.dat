8|59|Public
5000|$|... #Caption: Sneferu Pyramid waste {{limestone}} block. Hole in bottom, used as <b>pivot</b> <b>block</b> to turn heavy levers on {{in moving}} stones. 4th Dynasty. From Meidum, Egypt. The Petrie Museum of Egyptian Archaeology, London ...|$|E
40|$|Many {{scheduling}} and synchronization problems for large-scale multiprocessing {{can be overcome}} using functional (or applicative) programming. With this observation, it is strange that so much attention within the functional programming community {{has focused on the}} "aggregate update problem" [10]: essentially how to implement FORTRAN arrays. This situation is strange because in-place updating of aggregates belongs more to uniprocessing than to mathematics. Several years ago functional style drew me to treatment of d-dimensional arrays as 2 ^d-ary trees; in particular, matrices become quaternary trees or quadtrees. This convention yields efficient recopying-cum-update of any array; recursive, algebraic decomposition of conventional arithmetic algorithms; and uniform representations and algorithms for both dense and sparse matrices. For instance, any nonsingular subtree is a candidate as the <b>pivot</b> <b>block</b> for Gaussian elimination; the restriction actually helps identification of pivot b [...] ...|$|E
40|$|This study {{examines}} the block lower-triangular preconditioner with element-wise Schur complement as the lower diagonal block applied on matrices arising from an application in geophysics. The element-wise Schur complement {{is a special}} approximation of the exact Schur complement that can be constructed in the finite element framework. The preconditioner, the exact Schur complement and the element-wise Schur complement are analyzed mathematically and experimentally. The preconditioner is developed specifically for the glacial isostatic adjustment (GIA) model in its simplified flat Earth variant, but it is applicable to linear system of equations with matrices of saddle point form. In this work we investigate {{the quality of the}} element-wise Schur complement for symmetric indefinite matrices with positive definite <b>pivot</b> <b>block</b> and show spectral bounds that are independent of the problem size. For non-symmetric matrices we use generalized locally Toeplitz (GLT) sequences to construct a function that asymptotically describes the spectrum of the involved matrices. The theoretical results are verified by numerical experiments for the GIA model. The results show that the so-obtained preconditioned iterative method converges to the solution in constant number of iterations regardless of the problem size or parameters...|$|E
50|$|In a tilting or <b>pivoting</b> <b>block</b> action, the {{breechblock}} is hinged at the rear. When {{the lever}} is operated, the block tilts down and forward, exposing the chamber. The best-known <b>pivoting</b> <b>block</b> designs are the Peabody, the Peabody-Martini, and Ballard actions.|$|R
50|$|In a tilting <b>block</b> or <b>pivoting</b> <b>block</b> action, the {{breechblock}} is {{hinged on}} a pin mounted at the rear. When the lever is operated, the block tilts down and forward, exposing the chamber. The best-known <b>pivoting</b> <b>block</b> designs are the Peabody, the Peabody-Martini, and Ballard actions.|$|R
5000|$|The Connemara currach is also {{distinguished}} by a double gunwale {{and by a}} particular form of <b>pivoting</b> <b>block</b> or [...] "bull" [...] attached {{to one side of}} the squared region of the loom of the oar.|$|R
40|$|We {{consider}} the discrete system resulting from mixed finite element approximation of a second-order elliptic {{boundary value problem}} with Crouzeix-Raviart nonconforming elements for the vector valued unknown function and piece-wise constants for the scalar valued unknown function. Since the mass matrix corresponding to the vector valued variables is diagonal, these unknowns can be eliminated exactly. Thus, the problem of designing an efficient algorithm for {{the solution of the}} resulting algebraic system is reduced to one of constructing an efficient algorithm for a system whose matrix is a graph-Laplacian (or weighted graph-Laplacian). We propose a preconditioner based on an algebraic multilevel iterations (AMLI) algorithm. The hierarchical two-level transformations and the corresponding 2 2 block splittings of the graph-Laplacian needed in an AMLI algorithm are introduced locally on macroelements. Each macroelement is associated with an edge of a coarser triangulation. To define the action of the preconditioner we employ polynomial approximations of the inverses of the pivot blocks in the 2 2 splittings. Such approximations are obtained via the best polynomial approximation of 1 in norm on a finite interval. Our construction provides sufficient accuracy and moreover, guarantees that each <b>pivot</b> <b>block</b> is approximated by a positive definite matrix polynomial. One possible application of the constructed efficient preconditioner is in the numerical solution of unsteady Navier-Stokes equations by a projection method. It {{can also be used to}} design efficient solvers for problems corresponding to other mixed finite element discretizations...|$|E
40|$|The {{state of}} Bahia {{is the newest}} {{frontier}} of coffee in Brazil. The state park features a coffee with an area of 139, 550 hectares in production, which represent 4. 9 % of the Brazilian disseminated by 167 counties. There are three consolidated areas in coffee production: the Highlands, Atlantic and Savannah, this last cultivated using irrigation techniques. The irrigated coffee {{is located in the}} Extreme West of Bahia, which advances every year on the savannah plateau and represents the most competitive of the world and can achieve high levels of productivity. However, even with its economic and social importance, the coffee plantations of Bahia savannah needs additional information related to its extent and spatial distribution. For crop mapping, images from the satellite sensor LISS 3 from ResourceSat with a 23. 5 m of spatial resolution. The use of GIS has identified 13, 200 hectares of coffee in the middle region of the Extreme West of Bahia, which mapping resulted in increase of 7. 7 % in the areas of coffee compared to the area estimated by the IBGE, and 7. 5 % of the area published by CONAB/GEASA. The image sensor LISS 3 were effective in mapping the region's coffee and besides, the coffee showed different spectral behaviors, related to age and form of cultivation (or <b>pivot</b> <b>block).</b> However, no significant impairment of the mapping. Samples of georeferenced points with cultivation of coffee, made available by IBGE, contributed significantly to give more attention to certain areas. Pages: 25 - 3...|$|E
40|$|The paper {{deals with}} a general {{framework}} for constructing preconditioners for saddle point matrices, in particular as arising in the discrete linearized Navier-Stokes equations (Oseen’s problem). We utilize the so-called augmented Lagrangian approach, where the original linear system of equations is first transformed to an equivalent one, which latter is then solved by a preconditioned iterative solution method. The matrices in the linear systems, arising after the discretization of Oseen’s problem, are of two-by-two block form as are the best known preconditioners for these. In the augmented Lagrangian formulation, a scalar regularization parameter is involved, which strongly influences {{the quality of the}} block-preconditioners for the system matrix (referred to as outer), as well as the conditioning and the solution of systems with the resulting <b>pivot</b> <b>block</b> (referred to as inner) which, in the case of large scale numerical simulations has also to be solved using an iterative method. We analyse the impact {{of the value of the}} regularization parameter on the convergence of both outer and inner solution methods. The particular preconditioner used in this work exploits the inverse of the pressure mass matrix. We study the effect of various approximations of that inverse on the performance of the preconditioners, in particular that of a sparse approximate inverse, computed in an element-by-element fashion. We analyse and compare the spectra of the preconditioned matrices for the different approximations and show that the resulting preconditioner is independent of problem, discretization and method parameters, namely, viscosity, mesh size, mesh anisotropy. We also discuss possible approaches to solve the modified pivot matrix block. Keywords: Navier-Stokes equations, saddle point systems, augmented Lagrangian, finite elements, approximation of mass matrixiterative methods, preconditioning...|$|E
5000|$|The {{original}} Peabody rifles, {{manufactured by}} the Providence Tool Company, used a manually cocked side-hammer. Swiss gunsmith Friedrich Martini developed a <b>pivoting</b> <b>block</b> action by modifying the Peabody, that incorporated a hammerless striker which was cocked by the operating lever {{with the same}} single, efficient motion that also <b>pivoted</b> the <b>block.</b> The 1871 Martini-Henry which replaced the [...] "trapdoor" [...] Snider-Enfield was the standard British Army rifle of the later Victorian era, and the Martini was also a popular action for civilian rifles.|$|R
5000|$|<b>Pivot</b> on Apex <b>Block</b> Right Leg - Skate around corner, <b>pivot</b> around apex <b>block,</b> don't put hand on ice, keep legs at 90°, looking {{inside the}} track and keep {{shoulders}} square ...|$|R
40|$|AbstractWe {{present the}} {{recurrence}} formulas for computing the approximate inverse factors of tridiagonal and pentadiagonal matrices using bordering technique. Resulting algorithms {{are used to}} approximate the inverse of <b>pivot</b> <b>blocks</b> needed for constructing block ILU preconditioners for solving the block tridiagonal linear systems, arising from discretization of partial differential equations. Resulting preconditioners are suitable for parallel implementation. Comparison with other methods are also included...|$|R
40|$|In this work, {{prestressed}} elasticity {{problem as}} a model of the so-called glacial isostatic adjustment (GIA) process is studied. The model problem is described by a set of partial differential equations (PDE) and discretized with a mixed finite element (FE) formulation. In the presence of prestress the so-constructed system of equations is non-symmetric and indefinite. Moreover, the resulting system of equations is of the saddle point form. We focus on a robust and efficient block lower-triangular preconditioning method, where the lower diagonal block is and approximation of the so-called Schur complement. The Schur complement is approximated by the so-called element-wise Schur complement. The element-wise Schur complement is constructed by assembling exact local Schur complements on the cell elements and distributing the resulting local matrices to the global preconditioner matrix. We analyse the properties of the element-wise Schur complement for the symmetric indefinite system matrix and provide proof of its quality. We show that the spectral radius of the element-wise Schur complement is bounded by the exact Schur complement and that the quality of the approximation is not affected by the domain shape. The diagonal blocks of the lower-triangular preconditioner are combined with inner iterative schemes accelerated by (numerically) optimal and robust algebraic multigrid (AMG) preconditioner. We observe that on distributed memory systems, the top <b>pivot</b> <b>block</b> of the preconditioner is not scaling satisfactorily. The implementation of the methods is further studied using a general profiling tool, designed for clusters. For nonsymmetric matrices we use the theory of Generalized Locally Toeplitz (GLT) matrices and show the spectral behavior of the element-wise Schur complement, compared to the exact Schur complement. Moreover, we use the properties of the GLT matrices to construct a more efficient AMG preconditioner. Numerical experiments show that the so-constructed methods are robust and optimal...|$|E
40|$|Robust preconditioners on block-triangular and block-factorized {{form for}} {{three types of}} linear systems of two-by-two block form are studied in this thesis. The first type of linear systems, which are dense, arise from a {{boundary}} element type of discretization of crack propagation problems. Numerical experiment show that simple algebraic preconditioning strategies results in iterative schemes that are highly competitive with a direct solution method. The second type of algebraic systems, which are sparse, indefinite and nonsymmetric, arise from a finite element (FE) discretization of the partial differential equations (PDE) that describe (visco) elastic glacial isostatic adjustment (GIA). The Schur complement approximation in the block preconditioners is constructed by assembly of local, exactly computed Schur matrices. The quality of the approximation is verified in numerical experiments. When the block preconditioners for the indefinite problem are combined with an inner iterative scheme preconditioned by a (nearly) optimal multilevel preconditioner, the resulting preconditioner is (nearly) optimal and robust with respect to problem size, material parameters, number of space dimensions, and coefficient jumps. Two approaches to mathematically formulate the PDEs for GIA are compared. In the first approach the equations are formulated in their full complexity, whereas in the second their formulation is confined to the features and restrictions of the employed FE package. Different solution methods for the algebraic problem {{are used in the}} two approaches. Analysis and numerical experiments reveal that the first strategy is more accurate and efficient than the latter. The block structure in the third type of algebraic systems is due to a fine-coarse splitting of the unknowns. The inverse of the <b>pivot</b> <b>block</b> is approximated by a sparse matrix which is assembled from local, exactly inverted matrices. Numerical experiments and analysis of the approximation show that it is robust with respect to problem size and coefficient jumps...|$|E
40|$|AbstractThis paper {{introduces}} several {{strategies to}} deal with <b>pivot</b> <b>blocks</b> in multi-level block incomplete LU factorization (BILUM) preconditioning techniques. These techniques are aimed at increasing the robustness and controlling the amount of fill-ins of BILUM for solving large sparse linear systems when large-size blocks are used to form block-independent set. Techniques proposed in this paper include double-dropping strategies, approximate singular-value decomposition, variable size blocks and use of an arrowhead block submatrix. We point out {{the advantages and disadvantages}} of these strategies and discuss their efficient implementations. Numerical experiments are conducted to show the usefulness of the new techniques in dealing with hard-to-solve problems arising from computational fluid dynamics. In addition, we discuss the relation between multi-level ILU preconditioning methods and algebraic multi-level methods...|$|R
2500|$|In the 1982 phase, at a {{depth of}} 2.2 m, a large number of tiles were {{discovered}} from the site of the east corridor, including circular eave-end tiles of the [...] "Yamada-dera type", deeply moulded, with eight double lotus petals and a ring of six seeds around the centre. Beneath, a 1.7 bay section of the wooden outer wall was uncovered, including base stones with lotus designs; columns, with marked entasis; base and head penetrating tie-beams; middle non-penetrating tie-beams; latticed windows; sections of lath for plastering; and bracket blocks. Additional elements discovered the following year include bracket arms, rainbow beams, rafters and purlins. Traces of red paint on the timbers and fragments of plaster were also uncovered. Further discoveries in 1984 included better-preserved windows and ground plates and <b>pivot</b> <b>blocks</b> for doors.|$|R
40|$|This paper {{introduces}} several {{strategies to}} deal with <b>pivot</b> <b>blocks</b> in multi-level block incomplete LU factorization (BILUM) preconditioning techniques. These techniques are aimed at increasing the robustness and controlling the amount of fill-ins of BILUM for solving large sparse linear systems when large size blocks are used to form block independent set. Techniques proposed in this paper include double dropping strategies, approximate singular value decomposition, variable size blocks and use of arrowhead block submatrix. We point out {{the advantages and disadvantages}} of the new techniques and discuss their efficient implementations. Numerical experiments are conducted to show the usefulness of the new techniques in dealing with hard-to-solve problems arising from computational fluid dynamics. In addition, we discuss the relation between multi-level ILU preconditioning methods and algebraic multi-level methods. Key words: Incomplete LU factorization, multi-level ILU precondi [...] ...|$|R
40|$|There {{has been}} much {{excitement}} recently {{over the use of}} approximate inverses for parallel preconditioning. The preconditioning operation is simply a matrix-vector product, and in the most popular formulations, the construction of the approximate inverse seems embarassingly parallel. However, difficulties arise in practical parallel implementations. This paper will survey approximate inverse preconditioners, and discuss the wide variety of options, such as for sparsity pattern selection. We address {{the pros and cons of}} each method, and put the methods into perspective. 1 Introduction Direct approximations to the inverse of a matrix have been developed in the past decade for preconditioning iterative methods. Their main advantage in the context of parallelism is that the preconditioning operation is a matrix-vector product. They are also essential in block incomplete factorization preconditioners, where large, sparse <b>pivot</b> <b>blocks</b> need to be inverted, possibly in parallel. A requi [...] ...|$|R
40|$|We {{prove that}} {{standard}} Gaussian random multipliers {{are expected to}} stabilize numerically both Gaussian elimination with no <b>pivoting</b> and <b>block</b> Gaussian elimination and that they also are expected to support the celebrated randomized algorithm for low-rank approximation of a matrix even without customary oversampling. Our tests show similar results where we apply random circulant and Toeplitz multipliers instead of standard Gaussian ones...|$|R
50|$|Block: This is {{an element}} where the skaters are lined up {{in at least three}} {{parallel}} lines. Five lines is the maximum a block can have. The block should travel over the entire ice surface. The lines should be straight and evenly spaced. To increase the difficulty of the block teams can add step sequences, <b>pivot</b> the <b>block,</b> or change the configuration.|$|R
40|$|As the {{standard}} method for solving systems of linear equations, Gaussian elimination (GE) {{is one of}} the most important and ubiquitous numerical algorithms. However, its successful use relies on understanding its numerical stability properties and how to organize its computations for efficient execution on modern computers. We give an overview of GE, ranging from theory to computation. We explain why GE computes an LU factorization and the various benefits of this matrix factorization viewpoint. Pivoting strategies for ensuring numerical stability are described. Special properties of GE for certain classes of structured matrices are summarized. How to implement GE in a way that efficiently exploits the hierarchical memories of modern computers is discussed. We also describe block LU factorization, corresponding to the use of <b>pivot</b> <b>blocks</b> instead of <b>pivot</b> elements, and explain how iterative refinement can be used to improve a solution computed by GE. Other topics are GE for sparse matrices and the role GE plays in the TOP 50...|$|R
5000|$|Often, bosses are {{not present}} on non-circular shields {{due to the}} {{differences}} in technique; with a round shield, one makes a punching motion towards an oncoming blow, while with a heater or kite shield, attacks are <b>blocked</b> by <b>pivoting</b> the shield about the body. A boss provides a significant advantage for deflecting blows when using a punching motion, but is not very effective when using a <b>pivot</b> to <b>block</b> an attack.|$|R
5000|$|The Kord-12.7 mm heavy {{machine gun}} is a Russian design that entered service in 1998 {{replacing}} the older NSV machine gun. Externally the weapon resembles the NSV; however, the internal mechanism has been extensively reworked, changing from a horizontally <b>pivoting</b> breech <b>block</b> to a rotating bolt design. Additionally the gas system has been changed and the muzzle baffle redesigned. These changes give the weapon reduced recoil compared with the NSV, allowing greater accuracy during sustained fire.|$|R
5000|$|The {{original}} Peabody rifles, {{manufactured by}} the Providence Tool Company, used a manually cocked side-hammer. Swiss gunsmith Friedrich Martini devised {{an action that}} resembled the Peabody but incorporated a hammerless striker cocked by the operating lever with the same motion that <b>pivoted</b> the <b>block.</b> The 1871 Martini-Henry which replaced the [...] "trapdoor" [...] Snider-Enfield was the standard British Army rifle of the later Victorian era, and the Martini was also a popular action for civilian rifles.|$|R
40|$|We {{prove that}} {{standard}} Gaussian random multipliers {{are expected to}} numerically stabilize both Gaussian elimination with no <b>pivoting</b> and <b>block</b> Gaussian elimination. Moreover we prove that such a multiplier (even without the customary oversampling) is expected to support low-rank approximation of a matrix. Our test results are in good accordance with this analysis. Empirically random circulant or Toeplitz multipliers are as efficient as Gaussian ones, but their formal support is more problematic. Comment: 34 pages; 7 figures appeared separately from legends, but in correct orde...|$|R
40|$|General {{software}} for preconditioning the iterative solution of linear systems is greatly lagging behind the literature. This {{is partly because}} specific problems need specific matrix and preconditioner data structures {{in order to be}} solved efficiently; i. e., multiple implementations of a preconditioner with specialized data structures are required. This article presents a framework to support preconditioning with various, possibly user-defined, data structures for matrices that are partitioned into blocks. The main idea is to define data structures for the blocks, and an upper layer of software which uses these blocks transparently of their data structure. This transparency can be accomplished by using an object-oriented language. Thus various preconditioners, such as block relaxations and block incomplete factorizations, only need to be defined once, and will work with any block type. In addition, it is possible to transparently interchange various approximate or exact techniques for inverting <b>pivot</b> <b>blocks,</b> or solving systems whose coefficient matrices are diagonal blocks. This leads to a rich variety of preconditioners that can be selected. Operations with the blocks are performed with optimized libraries or fundamental data types. Comparisons with an optimized Fortran 77 code on both workstations and Cray supercomputers show that this framework can approach the efficiency of Fortran 77, as long as suitable block sizes and block types are chosen...|$|R
40|$|We propose {{efficient}} parallel algorithms and implementations on {{shared memory}} architectures of LU factorization over a finite field. Compared to the corresponding numerical routines, {{we have identified}} three main difficulties specific to linear algebra over finite fields. First, the arithmetic complexity could be dominated by modular reductions. Therefore, it is mandatory to delay {{as much as possible}} these reductions while mixing fine-grain parallelizations of tiled iterative and recursive algorithms. Second, fast linear algebra variants, e. g., using Strassen-Winograd algorithm, never suffer from instability and can thus be widely used in cascade with the classical algorithms. There, trade-offs are to be made between size of blocks well suited to those fast variants or to load and communication balancing. Third, many applications over finite fields require the rank profile of the matrix (quite often rank deficient) rather than the solution to a linear system. It is thus important to design parallel algorithms that preserve and compute this rank profile. Moreover, as the rank profile is only discovered during the algorithm, block size has then to be dynamic. We propose and compare several block decomposition: tile iterative with left-looking, right-looking and Crout variants, slab and tile recursive. Experiments demonstrate that the tile recursive variant performs better and matches the performance of reference numerical software when no rank deficiency occur. Furthermore, even in the most heterogeneous case, namely when all <b>pivot</b> <b>blocks</b> are rank deficient, we show that it is possbile to maintain a high efficiency...|$|R
40|$|It is {{well known}} that random {{matrices}} tend to be well conditioned, and we employ this property to advance some fundamental matrix computations. We prove effectiveness of our novel techniques of randomized preconditioning, estimate the condition numbers of random Toeplitz and circulant matrices, numerically stabilize Gaussian elimination with no <b>pivoting</b> and <b>block</b> Gaussian elimination, compute 2 × 2 matrix factorization where both diagonal blocks are better conditioned than an ill conditioned input matrix, and apply our dual variation of the Sherman–Morrison–Woodbury formula to low-rank matrix approximation. Our formal study and numerical tests show significant progress versus the known algorithms and should motivate further research efforts...|$|R
40|$|We present {{formulas}} for computations involving companion matrix pencils as {{may arise}} in considering polynomial eigenvalue problems. In particular, we provide explicit companion matrix pencils for matrix polynomials {{expressed in a}} variety of polynomial bases including monomial, orthogonal, Newton, Lagrange, and Bernstein/Bézier bases. Additionally, we give a pair of explicit LU factors associated with each pencil and a prescription for <b>block</b> <b>pivoting</b> when required...|$|R
40|$|AbstractA {{family of}} {{algorithms}} which solve the complementarity problem (and certain generalized complementarity problems) is introduced. In these algorithms <b>block</b> <b>pivots</b> (multiple exchanges of basic and nonbasic variables) are permitted. The geometry of complementarity points is studied. The proof that these algorithms converge in {{a finite number}} of steps is based on certain elementary results from group theory, and does not rely on monotonicity arguments...|$|R
40|$|AbstractWe present {{formulas}} for computations involving companion matrix pencils as {{may arise}} in considering polynomial eigenvalue problems. In particular, we provide explicit companion matrix pencils for matrix polynomials {{expressed in a}} variety of polynomial bases including monomial, orthogonal, Newton, Lagrange, and Bernstein/Bézier bases. Additionally, we give a pair of explicit LU factors associated with each pencil and a prescription for <b>block</b> <b>pivoting</b> when required...|$|R
40|$|We develop {{scalable}} {{methods for}} fitting penalized regression spline based generalized additive models with {{of the order}} of 104 coefficients to up to 108 data. Computational feasibility rests on: (i) a new iteration scheme for estimation of model coefficients and smoothing parameters, avoiding poorly scaling matrix operations; (ii) parallelization of the iteration’s <b>pivoted</b> <b>block</b> Cholesky and basic matrix operations; (iii) the marginal discretization of model covariates to reduce memory footprint, with efficient scalable methods for computing required crossproducts directly from the discrete representation. Marginal discretization enables much finer discretization than joint discretization would permit. We were motivated by the need to model four decades worth of daily particulate data from the UK Black Smoke and Sulphur Dioxide monitoring network. Although reduced in size recently, over 2000 stations have at some time been part of the network, resulting in some 10 million measurements. Modelling at a daily scale is desirable for accurate trend estimation and mapping, and to provide daily exposure estimates for epidemiological cohort studies. Because of the data set size, previous work has focussed on modelling time or space averages pollution levels, but this is unsatisfactory from a health perspective, since it is often acute exposure locally and on the time scale of days that is of most importance in driving adverse health outcomes. If computed by conventional means our black smoke model would require a half terabyte of storage just for the model matrix, whereas we are able to compute with it on a desktop workstation. The best previously available reduced memory footprint method would have required three orders of magnitude more computing time than our new method...|$|R
40|$|This work {{deals with}} {{proposal}} and calculation a crane hook block with two pulleys for lifting capacity of 8 tons. It contains description individual parts a crane hook block and proposal their construction solutions. In {{the next part}} work solves proposal rope, rope pulleys, cross member of the hook <b>block,</b> <b>pivot</b> pulleys, sidewalls, nut of crane hook and ball bearings. Work is finished with assembly drawing, pieces list and production drawing...|$|R
40|$|AbstractIn {{recently}} proposed quadratic optimization algorithms, copositivity detection {{procedures are}} frequently employed which deliver a feasible direction yielding a negative {{value of the}} considered quadratic form, {{if the answer is}} negative. To improve the computational performance of this routine, here (1) recursive characterizations of copositivity are presented which enable efficient reduction of the dimension of the problem using <b>block</b> <b>pivoting</b> techniques, and (2) shortcut strategies are described which are connected with diagonalization...|$|R
40|$|We {{present the}} block LU {{factorization}} with panel rank revealing <b>pivoting</b> (<b>block</b> LU_PRRP), a decomposition algorithm based on strong rank revealing QR panel factorization. Block LU_PRRP is {{more stable than}} Gaussian elimination with partial pivoting (GEPP), with a theoretical upper bound of the growth factor of (1 + τ b) ^(n/ b) - 1, where b {{is the size of}} the panel used during the block factorization, τ is a parameter of the strong rank revealing QR factorization, and n is the number of columns of the matrix. For example, if the size of the panel is b = 64, and τ = 2, then (1 + 2 b) ^(n/b) - 1 = (1. 079) ^n- 64 ≪ 2 ^n- 1, where 2 ^n- 1 is the upper bound of the growth factor of GEPP. Our extensive numerical experiments show that the new factorization scheme is as numerically stable as GEPP in practice, but it is more resistant to pathological cases. The block LU_PRRP factorization does only O(n^ 2 b) additional floating point operations compared to GEPP. We also present block CALU_PRRP, a communication avoiding version of block LU_PRRP that minimizes communication. Block CALU_PRRP is based on tournament pivoting, with the selection of the pivots at each step of the tournament being performed via strong rank revealing QR factorization. Block CALU_PRRP is more stable than CALU, the communication avoiding version of GEPP, with a theoretical upper bound of the growth factor of (1 + τ b) ^n b(H+ 1) - 1, where H is the height of the reduction tree used during tournament pivoting. The upper bound of the growth factor of CALU is 2 ^n(H+ 1) - 1. Block CALU_PRRP is also more stable in practice and is resistant to pathological cases on which GEPP and CALU fail...|$|R
50|$|There are a {{total of}} 8 {{mutations}} that account for the disorder in 8 of 14 studied families. These mutations are clustered in four regions throughout the channel: the linker between domains 2 and 3 (D2-3), the intracellular segment linking segments 4 and 5 in domain 3 (D3S4-5), the linker between domains 3 and 4 (D3-4) and the intracellular segment linking segments 4 and 5 in domain 4 (D4S4-5). The mutations in the D3S4-5 region (I1461T, F1462V and T1461I) are located in or next to an IFM motif that is conserved across all voltage-gated sodium channels. Mutagenesis studies of this region have shown that it acts {{as part of the}} inactivation gate, <b>pivoting</b> to <b>block</b> the central pore. Not surprisingly then, the two of these mutations that have received further study show incomplete inactivation. When the IFM motif <b>pivots</b> to <b>block</b> the central pore it interacts with residues in the D3S4-5 region. There are three mutations in this region (V1298F, F1298D and V1299F) that are believed to alter the interaction with the inactivation gate. While this region has been studied by mutagenesis these specific mutations have not all received attention, though they are expected to produce changes similar to the aforementioned IFM region mutations. The M1627K mutation in the D4S4-5 region may also affect a residue involved in interacting with the IFM inactivation motif. This would explain the observed alteration of inactivation and the broadening of a window current. One of the affected families with the R996C mutation, pedigree 12, has a single individual who also has the V1298D mutation. The individual in this family with the compound mutation is the most severely affected, suggesting that the R996C mutation may cause a less severe phenotype. The less severe phenotype of the pedigree 4 family is in concordance with this theory. It is unclear how the R996C mutation affects channel function.|$|R
