1244|234|Public
25|$|A deep <b>predictive</b> <b>coding</b> network (DPCN) is a <b>predictive</b> <b>coding</b> {{scheme that}} uses {{top-down}} information to empirically adjust the priors {{needed for a}} bottom-up inference procedure {{by means of a}} deep, locally connected, generative model. This works by extracting sparse features from time-varying observations using a linear dynamical model. Then, a pooling strategy is used to learn invariant feature representations. These units compose to form a deep architecture and are trained by greedy layer-wise unsupervised learning. The layers constitute a kind of Markov chain such that the states at any layer depend only on the preceding and succeeding layers.|$|E
25|$|In <b>predictive</b> <b>coding,</b> {{optimising}} model parameters {{through a}} gradient ascent {{on the time}} integral of free energy (free action) reduces to associative or Hebbian plasticity and is associated with synaptic plasticity in the brain.|$|E
25|$|Optimising the {{precision}} parameters corresponds to optimising the gain of prediction errors (c.f., Kalman gain). In neuronally plausible implementations of <b>predictive</b> <b>coding,</b> this corresponds to optimising the excitability superficial pyramidal cells {{and has been}} interpreted in terms of attentional gain.|$|E
40|$|International Telemetering Conference Proceedings / November 14 - 16, 1978 / Hyatt House Hotel, Los Angeles, CaliforniaAn {{overview}} of recent applications of source coding theory and techniques to Linear <b>Predictive</b> <b>Coded</b> Coded speech compression systems is presented. Several distortion measures proposed {{for use in}} speech compression systems are described and compared. These distortion measures are then combined with an algorithm for computing "optimum" (minimum distortion) vector quantizers to obtain optimum quantizers for reflection coefficient vectors in Linear <b>Predictive</b> <b>Coded</b> speech systems. The quality {{of the system is}} evaluated via the speech distortion measures and listening to demonstration tapes. Some implications for speech compression theory and practice are discussed...|$|R
40|$|A new {{numerical}} solver for stiff transport predictions {{has been}} developed and implemented in the PTRANSP <b>predictive</b> transport <b>code.</b> The TGLF and GLF 23 <b>predictive</b> <b>codes</b> have been incorporated in the solver, verified by comparisons with predictions from the XPTOR code, and validated by comparing predicted and measured profiles. Predictions for ITER baseline plasmas are presented...|$|R
40|$|Multiple Description (MD) coding of predictively coded {{sources is}} of {{practical}} interest in several multimedia {{applications such as}} redundant storage of videolaudio data. and real-time videolaudio telephony. A key problem associated with <b>predictive</b> MD <b>coding</b> is the occurrence of predictive mismatch. In the present paper, we pose the problem of <b>predictive</b> MD <b>coding</b> as {{a variant of the}} Wyner-Ziv decoder side-information problem. We propose an approach based on the use of coset <b>codes</b> for <b>predictive</b> MD <b>coding,</b> which avoids <b>predictive</b> mismatch without requiring restrictive channel assumptions or high latency. We specifically consider two-channel <b>predictive</b> MD <b>coding</b> of a first-order Gauss-Markov process. Results indicate that the proposed approach significantly out-performs alternative approaches in terms of rate-distortion performance. 1...|$|R
25|$|Later, {{in early}} 1980s, {{listening}} tests {{were carried out}} on synthetic speech stripped of acoustic cues to assess their significance. Time-varying formant frequencies and amplitudes derived by linear <b>predictive</b> <b>coding</b> were synthesized additively as pure tone whistles. This method is called sinewave synthesis. Also the composite sinusoidal modeling (CSM) used on a singing speech synthesis feature on Yamaha CX5M (1984), is known to use a similar approach which was independently developed during 19661979. These methods are characterized by extraction and recomposition {{of a set of}} significant spectral peaks corresponding to the several resonance modes occurred in the oral cavity and nasal cavity, in a viewpoint of acoustics. This principle was also utilized on a physical modeling synthesis method, called modal synthesis.|$|E
2500|$|Usually, the {{generative}} {{models that}} define free energy are non-linear and hierarchical (like cortical hierarchies in the brain). Special cases of generalised filtering include Kalman filtering, which is formally equivalent to <b>predictive</b> <b>coding</b> [...] â€“ a popular metaphor for message passing in the brain. Under hierarchical models, <b>predictive</b> <b>coding</b> involves the recurrent exchange of ascending (bottom-up) prediction errors and descending (top-down) predictions [...] {{that is consistent}} with the anatomy and physiology of sensory [...] and motor systems.|$|E
2500|$|... {{is a form}} of {{synthesis}} {{that uses}} a series of bandpass filters or Fourier transforms to analyze the harmonic content of a sound. The results are then used to resynthesize the sound using a band of oscillators. The vocoder, linear <b>predictive</b> <b>coding,</b> and some forms of speech synthesis are based on analysis/resynthesis.|$|E
40|$|This article {{deals with}} {{numerical}} simulation of air flow and heat transfer in an electric junction box comprising conductive metal wire rods each having a cylinder shape in cross section. Results obtained by a commercial CFD package widely used for electronic system temperature predictions. The paper gives considerable {{insight into the}} nature of the enclosure heat transfer and an indication of the accuracy of a widely used <b>predictive</b> <b>code...</b>|$|R
40|$|The paper {{presents}} {{a comparison of}} a previous and {{a new approach to}} shape quantization noise in low bit rate <b>predictive</b> audio <b>coding.</b> The previous approach uses an adaptation of the step size of a uniform quantizer, the new approach uses a quantizer with clipping. Both approaches are evaluated using a <b>predictive</b> audio <b>coding</b> scheme. The presented results of a listening test show the improved performance of the new approach...|$|R
40|$|Experimental {{results of}} the {{quantization}} of Linear <b>Predictive</b> <b>Coded</b> (LPC) coefficients using two general approaches, scalar coefficient quantization and vector quantization, are presented. The LPC coefficients were quantized in several domains: Line Spectral Frequency (LSF), cepstral, predictor, reflection and autocorrelation. Two distortion measures were {{used to evaluate the}} quantizers; Itakura-Saito and RMS log spectral distortion measure. The vector quantizers showed good results for only 9 bits per frame of 150 speech samples. 1...|$|R
2500|$|The psychoacoustic masking codec {{was first}} {{proposed}} in 1979, apparently independently, by Manfred R. Schroeder, et al. from Bell Telephone Laboratories, Inc. in Murray Hill, New Jersey, and M. A. Krasner {{both in the}} United States. [...] Krasner {{was the first to}} publish and to produce hardware for speech (not usable as music bit compression), but the publication of his results as a relatively obscure Lincoln Laboratory Technical Report, did not immediately influence the mainstream of psychoacoustic codec development. Manfred Schroeder was already a well-known and revered figure in the worldwide community of acoustical and electrical engineers, but his paper was not much noticed, since it described negative results due to the particular nature of speech and the linear <b>predictive</b> <b>coding</b> (LPC) gain present in speech.|$|E
5000|$|Here, [...] is the {{precision}} of random fluctuations at the i-th level. This is known as generalized <b>predictive</b> <b>coding</b> 11, with linear <b>predictive</b> <b>coding</b> as a special case.|$|E
50|$|Evaluating the {{empirical}} evidence that suggests a neurologically plausible basis for <b>predictive</b> <b>coding</b> {{is a broad}} and varied task. For one thing, {{and according to the}} model, <b>predictive</b> <b>coding</b> occurs at every iterative step in the perceptual and cognitive processes; accordingly, manifestations of <b>predictive</b> <b>coding</b> in the brain include genetics, specific cytoarchitecture of cells, systemic networks of neurons, and whole brain analyses. Due to this range of specificity, different methods of investigating the neural mechanisms of <b>predictive</b> <b>coding</b> have been applied, where available; more generally, however, and at least as it relates to humans, there are significant methodological limitations to investigating the potential evidence and much of the work is based on computational modeling of microcircuits in the brain. Notwithstanding, there has been substantial theoretical work that has been applied to understanding <b>predictive</b> <b>coding</b> mechanisms in the brain. This section will focus on specific evidence {{as it relates to the}} <b>predictive</b> <b>coding</b> phenomenon, rather than analogues, such as homeostasis (which are, nonetheless, integral to our overall understanding of Bayesian inference but already supported heavily; see Clark, 2012 for a review).|$|E
5000|$|P {{picture or}} P frame (<b>predictive</b> <b>coded</b> picture) - {{contains}} motion-compensated difference information relative to previously decoded pictures. In older designs such as MPEG-1, H.262/MPEG-2 and H.263, each P picture can only reference one picture, and that picture must precede the P picture in display order {{as well as}} in decoding order and must be an I or P picture. These constraints do not apply in the newer standards H.264/MPEG-4 AVC and HEVC.|$|R
40|$|Abstract- Network {{impairments}} such as {{delay and}} packet losses have severe {{impact on the}} presentation quality of many predictive video sources. Interleaved Source Coding (ISC) [5][6][7] {{is one of the}} error resilient <b>coding</b> methods for <b>predictive</b> video <b>coded</b> frames transmitted over a single erasure channel. ISC has shown to significantly improve the overall quality of <b>predictive</b> <b>coded</b> video stream over a lossy channel [5][6][7]. In this paper, ISC is evaluated over channels with memory. In particular, we analyze the impact of packet correlation [11][13] of the popular Gilbert model on ISC-based packet video over a wide range of packet loss probabilities. Simulations have shown that ISC advances the traditional method as either the loss rate increases or the packet correlation decreases. Keywords-Interleaving; packet correlation; markov decision process; dynamic programming I...|$|R
40|$|Abstract â€” Packet losses over {{unreliable}} {{networks have}} a severe {{impact on the}} playback quality of many <b>predictive</b> <b>coded</b> sources such as compressed video. Prior efforts (e. g., [1]-[5] [7]-[9][11]-[13]) have developed a variety of coding methods that are resilient to packet losses. We propose a new packet-loss resilient coding approach, interleaved source coding (ISC), {{which is based on}} an optimum interleaving of <b>predictive</b> video <b>coded</b> frames transmitted over a single erasure channel. We develop a Markov Decision Process (MDP) and a corresponding dynamic programming algorithm for identifying the optimal interleaving pattern for a given channel model. This method improves the overall quality of <b>predictive</b> video <b>coded</b> stream over a lossy channel without complex modifications to standard video coders. ISC provides a viable alternative to (or it could be combined with) path-diversity based approaches, and hence, ISC eliminates (or reduces) the need for content distribution, path diversity routing, and related synchronization issues. Simulations {{of a wide range of}} video sequences over practical traces of Markov erasure channels showed significant improvements (up to 4 dB) when compared with traditional predictive video over the same channels...|$|R
50|$|Observing {{this new}} trend, some {{practitioners}} predict {{the development of}} the utilisation of <b>predictive</b> <b>coding</b> in English courts. As the court in this judgment has approved such use despite the existence of a contested party - there might be a case where the court directs the disclosing parties to use the <b>predictive</b> <b>coding</b> software against their wishes. When that situation occurs, experts believe that using <b>predictive</b> <b>coding</b> in the electronic disclosure will be regarded as the standard rather than the exemption.|$|E
5000|$|... #Subtitle level 3: Generalized {{filtering}} and <b>predictive</b> <b>coding</b> ...|$|E
5000|$|... #Subtitle level 2: Relationship to Bayesian {{filtering}} and <b>predictive</b> <b>coding</b> ...|$|E
40|$|Rissanen's Minimum Description Length (MDL) {{principle}} is a statistical modeling principle motivated by coding theory. For exponential families we obtain pathwise expansions, {{to the constant}} order, of the <b>predictive</b> and mixture <b>code</b> lengths used in MDL. The results are useful for understanding different MDL forms. Key words: minimum description length, mixture <b>code,</b> <b>predictive</b> <b>code,</b> two-stage code, law of iterated logarithm 1 Introduction and background The Minimum Description Length (MDL) {{principle is}} introduced by Rissanen as a fundamental principle to model data, see [15, 17] and the reference list in [18]. If we encode data from a source by prefix codes, the best code {{is the one that}} achieves the minimum description length among all prefix codes {{if there is such a}} one. Because of the equivalence between a prefix codelength and the negative logarithm of the corresponding probability distribution (via Kraft's inequality), this in turn gives us a modeling principle, namely, the MDL p [...] ...|$|R
40|$|The goal of <b>predictive</b> sparse <b>coding</b> is {{to learn}} a {{representation}} of examples as sparse linear combinations of elements from a dictionary, such that a learned hypothesis linear in the new representation performs well on a predictive task. <b>Predictive</b> sparse <b>coding</b> has demonstrated impressive performance {{on a variety of}} supervised tasks, but its generalization properties have not been studied. We establish the first generalization error bounds for <b>predictive</b> sparse <b>coding,</b> in the overcomplete setting, where the number of features k exceeds the original dimensionality d. The learning bound decays as Ã•(âˆšdk/m) with respect to d, k, and the size m of the training sample. It depends intimately on stability properties of the learned sparse encoder, as measured on the training sample. Consequently, we also present a fundamental stability result for the LASSO, a result that characterizes the stability of the sparse codes with respect to dictionary perturbations. 1...|$|R
40|$|This paper {{presents}} an approach towards {{the development of}} an integrated design environment with design optitimization capabilities wherein the projectile design, geometry, or changes to those of an existing projectile, will be optimized with respect to performance requirement(s). Additionally, the design process will be simplified by the integration between <b>predictive</b> <b>codes</b> in this environment. This environment will include a procedure for making first cut or rough estimates in the initial stages of design so that lengthy and expensive design code runs can be reserved for promising design configurations...|$|R
5000|$|LPC-10, FIPS Pub 137, 2400 bit/s, {{which uses}} linear <b>predictive</b> <b>coding</b> ...|$|E
50|$|Speech data {{is stored}} through pitch-excited linear <b>predictive</b> <b>coding</b> (PE-LPC), where words {{are created by}} a lattice filter, selectably fed by either an {{excitation}} ROM (containing a glottal pulse waveform) or an LFSR (linear feedback shift register) noise generator. Linear <b>predictive</b> <b>coding</b> achieves a vast reduction in data volume needed to recreate intelligible speech data.|$|E
50|$|Bishnu S. Atal (born 1933) is a noted {{researcher}} in linear <b>predictive</b> <b>coding.</b>|$|E
30|$|<b>Predictive</b> {{inference}} <b>coding</b> {{procedures were}} identical to experiment 1. Experiments 2 a and 2 b had high interrater reliability. For both Cohenâ€™s Kappa[*]=[*] 0.954, p[*]<[*] 0.001. Discrepancies were resolved through discussion.|$|R
40|$|Abstractâ€”For many {{recognition}} systems, {{the feature}} extraction unit forms the most computationally intensive and power consuming component. In this paper, {{we present a}} design of an analog-to-information converter that directly produces a pulse-encoded representation of linear <b>predictive</b> <b>coded</b> (LPC) features corresponding to an input analog signal. At the core of proposed design is a sigma-delta modulation procedure that is embedded within a learning step. Measured results from a fabricated prototype in a 0. 5 Âµm CMOS technology demonstrate the real-time functionality of the learner in extracting 6 -dimensional online LPC features from input speech signal while consuming only 450 ÂµW. I...|$|R
40|$|In this paper, unequal error {{protection}} (UEP) of H. 264 /AVC coded video using hierarchical quadrature {{amplitude modulation}} (HQAM), which takes into consideration the non-uniformly distributed importance of intracoded frame (I-frame) and <b>predictive</b> <b>coded</b> frame (P-frame) is proposed. In order to optimally assign the hierarchical QAM high priority (HP) and low priority (LP) bits to the H. 264 /AVC coded video, a low-complexity optimal allocation algorithm is also proposed. The proposed low-complexity algorithm reduces the computational complexity of the optimal allocation problem, compared with the exhaustive search process. Simulation results demonstrate that our UEP scheme outperforms the conventional UEP scheme...|$|R
50|$|There {{have been}} several {{competing}} models {{for the role of}} <b>predictive</b> <b>coding</b> in interoception.|$|E
50|$|Warped linear <b>predictive</b> <b>coding</b> (warped LPC or WLPC) is {{a variant}} of linear <b>predictive</b> <b>coding</b> in which the {{spectral}} representation {{of the system is}} modified, for example by replacing the unit delays used in an LPC implementation with first-order allpass filters. This can have advantages in reducing the bitrate required for a given level of perceived audio quality/intelligibility, especially in wideband audio coding.|$|E
50|$|General Instrument SP0250, LPC (linear <b>predictive</b> <b>coding)</b> speech {{synthesis}} chip {{used in the}} Sega G80 arcade system board.|$|E
40|$|Streaming of precoded video, {{which is}} both source- and channelcoded, over packet-loss {{networks}} faces challenges of the timevarying packet loss rate and fluctuating bandwidth. Rate shaping has been proposed to reduce the bit rate of a precoded video bitstream {{to adapt to the}} real-time bandwidth variation. In our earlier work, rate shaping was extended to consider not only the bandwidth but also the packet loss rate variations. In practice, the reconstructed result of the previous frame will affect the following frames if the video is <b>predictive</b> <b>coded,</b> and/or the error concealment method performed at the receiver utilizes temporal information...|$|R
40|$|A {{comprehensive}} model rotor aeroacoustic {{data base}} was {{collected in a}} large anechoic wind tunnel in 1986. Twenty-six microphones were positioned around the azimuth to collect acoustic data for approximately 150 different test conditions. A dynamically scaled, blade-pressure-instrumented model of the forward rotor of the BH 360 helicopter simultaneously provided blade pressures for correlation with the acoustic data. High-speed impulsive noise, blade-vortex interaction noise, low-frequency noise, and broadband noise were all captured in this extensive data base. Trends are presentes for each noise source, with important parametric variations. The {{purpose of this paper}} is to introduce this data base and illustrate its potential for <b>predictive</b> <b>code</b> validation...|$|R
30|$|PHPâ€”the server side {{scripting}} {{programming language}} that is used for interfacing the RVS machine <b>predictive</b> algorithm <b>codes</b> with the internet services in order to access other e-accessories used for analysing and interpreting the offline RVS machine performance data.|$|R
