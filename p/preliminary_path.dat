11|36|Public
5000|$|The {{first level}} has three subdivisions that all require {{specific}} testing. The {{first is a}} Professional Animal Scientist (PAS) who must hold a B.S., M.S. or PhD in Animal Science or a closely related field. The second is a Registered Animal Specialist (RAS) {{and the third is}} a Registered Animal Product Specialist (RAPS). <6> [...] While neither of these require a degree, both require six years of experience and testing, and must be nominated by a PAS. All the subdivisions offer an Associate level of certification as a <b>preliminary</b> <b>path</b> to full certification.|$|E
5000|$|In 2004, The Nation {{reported}} {{that if the}} planned construction of the Israeli West Bank barrier continued along its designated course, [...] "the 1,200 residents of Budrus—the vast majority of whom depend on agriculture for work—will lose {{a large portion of}} their fields. An Israeli bulldozer has already carved a <b>preliminary</b> <b>path,</b> and uprooted trees lie in its wake. According to the official map released by Israel's Defense Ministry, the proposed route of the separation barrier will not only pass through this patch of land but will also loop around to encircle Budrus and eight nearby villages, creating a closed enclave with a population of 25,000. Once the area is sealed, access to fields, offices, construction sites, university classrooms, friends and relatives outside the enclave will be restricted." [...] In response, the residents began to hold non-violent protests. Haaretz stated that although curfews were established to prevent the protests, [...] "mainly young men violated the curfew and walked to the olive grove, to prevent the bulldozers from doing their work. Up to this week, the bulldozers have not returned to work - after they already uprooted about 60 olive trees." ...|$|E
40|$|Abstract. Path Relaxation is {{a method}} of {{planning}} safe paths around obstacles for mobile robots. It works in two steps: a global grid starch that finds a rough path, followed by a local relaxation step that adjusts each node {{on the path to}} lower the overall path cost. The representation used by Path Relaxation allows an explicit tradeoff among length of path, clearance away from obstacles, and distance traveled through unmapped areas. 1. Int reduction Path Relaxation is a two-step path-pl;lr~ning process for mobile robots. It finds a safe path for a robot to traverse a field of obstacles and arrive at its destination. The first step of path relaxation finds a <b>preliminary</b> <b>path</b> on an eight-connected grid of points. The second step adjusts, or “relaxes”, the position of each <b>preliminary</b> <b>path</b> point to improve the path. One advantage of path relaxation is that it allows many differen...|$|E
2500|$|To {{summarize}} the arguments against feasibility: [...] First, {{critics argue that}} a primary barrier to achieving molecular nanotechnology {{is the lack of}} an efficient way to create machines on a molecular/atomic scale, especially {{in the absence of a}} well-defined path toward a self-replicating assembler or diamondoid nanofactory. Advocates respond that a <b>preliminary</b> research <b>path</b> leading to a diamondoid nanofactory is being developed.|$|R
40|$|This study {{addresses}} the flight-path planning problem for multirotor aerial vehicles (AVs). We consider the specific features and requirements of real-time flight-path planning {{and develop a}} rapidly-exploring random tree (RRT) algorithm to determine a <b>preliminary</b> flight <b>path</b> in three-dimensional space. Since the path obtained by the RRT may not be optimal due {{to the existence of}} redundant waypoints. To reduce the cost of energy during AV’s flight, the excessive waypoints need to be refined. We revise the A-star algorithm by adopting the heading of the AV as the key indices while calculating the cost. Bezier curves are finally proposed to smooth the flight path, making it applicable for real-world flight...|$|R
40|$|We present {{distributed}} query scheduling algorithms that minimize network utilization for spatial {{joins in}} the Sky-Query federation of Astronomy databases. Unlike existing works that measure {{the quality of}} join schedules based on query response time, our metric both minimizes network utilization and balances the utilization of heterogeneous network <b>paths.</b> <b>Preliminary</b> experiments show that our algorithms reduce network utilization dramatically when compared with SkyQuery’s existing scheduling algorithm. ...|$|R
40|$|The authors {{hypothesized}} that felt responsibility mediated {{the relationship between}} support and interdependence variables (perceived coworker support, task interdependence) and work outcome variables (job satisfaction, inrole performance, extrarole performance). <b>Preliminary</b> <b>path</b> analysis testing shows support for the proposed relationships. Additionally, the authors’ propose that once that once the analysis is complete, perceived co-worker support will be found to moderate the relationship between task interdependence and felt responsibility...|$|E
40|$|In {{this paper}} we {{introduce}} a novel method for obtaining good quality paths for autonomous road vehicles (e. g., cars or buses) in narrow environments. There are many traffic situations in urban scenarios where nontrivial maneuvering in narrow places is necessary. Navigating in cluttered parking lots or having to avoid obstacles blocking {{the way and}} finding a detour even in narrow streets are challenging, especially if the vehicle has large dimensions like a bus. We present a combined approximation-based approach to solve the path planning problem in such situations. Our approach consists of a global planner which generates a <b>preliminary</b> <b>path</b> consisting of straight and turning-in-place primitives and a local planner {{which is used to}} make the <b>preliminary</b> <b>path</b> feasible to car-like vehicles. The approximation methodology is well known in the literature; however, both components proposed in this paper differ from existing similar planning methods. The approximation process with the proposed local planner is proven to be convergent for any preliminary global paths. The resulting path has continuous curvature which renders our method well suited for application on real vehicles. Simulation experiments show that the proposed method outperforms similar approaches in terms of path quality in complicated planning tasks...|$|E
40|$|Looking at the {{mobility}} of robots and their chassis most are limited to fairly flat environments. In urban environments common structures such as steps or stairs pose invincible obstacles for such systems. When it comes to unstructured outdoor environments a vast variety of obstacles is imaginable which are not traversable by common robots, for instance boulders, debris, rocks or trunks of fallen or chopped trees. However, there are mobile robots with adjustable chassis providing {{a higher degree of}} mobility and enabling them to overcome such obstacles. This paper presents first results on our motion planning algorithm which aims at utilizing the enhanced capabilities of those robots. It takes into account the chassis configuration and the system stability to propose the best path. We use a high level planner to quickly generate a <b>preliminary</b> <b>path</b> by considering the platform's operating limits. We then distinguish between path segments on flat and rough terrain. For each hard segment we restrict the search space to a tube around the initial path. A subsequent planner is used to refine the <b>preliminary</b> <b>path</b> by considering the actuator positions, the robot's stability and a ground contact factor. Our planning algorithm is general {{in the sense that we}} do not categorize obstacles and do not use predefined motion sequences for those obstacle classes. Finally, we present a discussion including an analysis of the time complexity and a simulation application in ROS and Gazebo as proof of feasability...|$|E
40|$|An {{empirical}} relation for {{path diversity}} gain {{as a function}} of terminal separation distance and single site fade depth is presented. This relation is based on existing 15. 3 GHz ATS- 5 attenuation data and 16. 0 GHz radiometric temperature data for earth-space propagation <b>paths.</b> <b>Preliminary</b> 30 GHz ATS- 6 diversity data are presented and are found to agree well with this empirical relation...|$|R
40|$|This paper {{considers}} the inverse shortest paths problem where arc costs {{are subject to}} correlation constraints. The motivation for this research arises from applications in traffic modelling and seismic tomography. A new method is proposed for solving this class of problems. It is constructed as a generalization of the algorithm presented in [1] for uncorrelated inverse shortest <b>paths.</b> <b>Preliminary</b> numerical experience with the new method is presented and discussed...|$|R
40|$|The paper {{presents}} an algorithm and methodologies for the {{direct numerical control}} (NC) cutter path generation from a point cloud. Different from the testing approach, it will generate the cutter path without any reconstruction of the surface patch. Based on the scanned data, a ball nose cutter is assumed to move over the points with a specific cutter diameter. A sphere (shape of cutter) with a specific radius is formed by two or more digitized points. The approach combines point pairs to form rows of spheres. By joining the centre of spheres with arc splines, the <b>preliminary</b> tool <b>path</b> is calculated. Finally, the exact tool path is found {{by means of a}} general compensation algorithm. Department of Industrial and Systems Engineerin...|$|R
40|$|We {{report the}} results of an LDRD effort to {{investigate}} new technologies for the identification of small-sized (mm to cm) debris in low-earth orbit. This small-yet-energetic debris presents a threat to the integrity of space-assets worldwide and represents significant security challenge to the international community. We present a nonexhaustive review of recent US and Russian efforts {{to meet the challenges of}} debris identification and removal and then provide a detailed description of joint US-Russian plans for sensitive, laser-based imaging of small debris at distances of hundreds of kilometers and relative velocities of several kilometers per second. Plans for the upcoming experimental testing of these imaging schemes are presented and a <b>preliminary</b> <b>path</b> toward system integration is identified...|$|E
40|$|AbstractA <b>preliminary</b> <b>path</b> {{tracking}} {{experiment was}} done and a mapping system was developed in this study. Data collection of human activities {{in this study was}} focused on different shape of hand drawings. Five subjects were required to draw three types of shapes (circle, square and triangle) according to their convenience pace. A sensor consists of accelerometer, gyroscope and compass was attached firmly on subject's wrist with special designed holder. PCA and double integration technique were used to process and analyze the data. The tracking path was mapped and presented in GUI developed by MATLAB. The developed GUI is capable to display the tracking with animation starting from the first stroke until the end. The GUI is managed to trace the upper-limbs tiny motion accurately and presented well in graphic form...|$|E
40|$|We propose {{alternative}} methods for performing FE-based computational fracture: a mixed mode extrinsic cohesive law and crack evolution by edge rotations and nodal reposition. Extrinsic plastic cohesive laws {{combined with the}} discrete version of equilibrium form a nonlinear complementarity problem. The complementarity conditions are smoothed with the Chen-Mangasarian replacement functions which naturally turn the cohesive forces into Lagrange multipliers. Results can be made as close as desired to the pristine strict complementarity case, {{at the cost of}} convergence radius. The smoothed problem is equivalent to a mixed formulation (with displacements and cohesive forces as unknowns). In terms of geometry, our recently proposed edge-based crack algorithm is adopted. Linear control is adopted to determine the displacement/load parameter. Classical benchmarks in computational fracture as well as newly proposed tests are used in assessment with accurate results. In this sense, the proposed solution has algorithmic and accuracy advantages, at a slight penalty in the computational cost. The Sutton crack path criterion is employed in a <b>preliminary</b> <b>path</b> determination stage...|$|E
40|$|This {{research}} project examines the misreading of satire in some productions of Neil LaBute’s play, Fat Pig. This practice led project aims to investigate why such misinterpretations occur {{and explore the}} theatrical styles that emphasise the satire in the text via rehearsal processes and production. There will be three <b>preliminary</b> <b>paths</b> undertaken in this research heading toward a new production of Fat Pig; {{an exploration of the}} responses of audiences and critics to past productions; an analysis of the background to Neil LeBute and his work; and an examination of theatrical expressions of satire, experimental theatre, contemporary theatre, and their practitioners. The overall aim of this {{research project}} is to find ways, as a director, to experiment with theatrical styles as a means to expand the play’s complex issues and ironic take on society’s narrow view of female beauty. This study will explore the following questions: what is the correlation between staging and design (the director’s influence and how an audience interprets meaning; and what forms of theatrical expression will highlight and emphasise the satire and irony present in the text? In what ways can critical reviews and feedback from previous productions indicate the understanding (or lack of understanding) of the ironic content in the script? Can situating LaBute in the context of his satiric writing style that straddles literary elements from opposing absurd and realism genres shed light on how irony can be exposed in Fat Pig? The project’s new production aims to underscore the play’s social commentaries by combining various forms of theatrical styles, philosophies, and methodologies. I wish to extend my directorial practice by investigating strategies to emphasis and highlight what I see as the underlying focus of Fat Pig; society’s discriminating behaviour to those who sit outside mainstream ideas of physical beaut...|$|R
40|$|Abstract. We {{propose a}} {{practical}} technique for {{the identification of}} lossy network links from end-to-end measurements. Our scheme {{is based on a}} function that computes the likelihood of each link to be lossy. This function depends on the number of times a link appears in lossy paths and on the relative loss rates of these <b>paths.</b> <b>Preliminary</b> simulation results show that our algorithm achieves accuracy higher than previously proposed heuristic methods and comparable to statistical methods at significantly lower running time. ...|$|R
40|$|Design for Six Sigma (DFSS) {{has evolved}} as a worthy {{predecessor}} {{to the application}} of Six-Sigma principles to production, process control, and quality. At Livermore National Laboratory (LLNL), we are exploring the interrelation of our current research, development, and design safety standards as they would relate {{to the principles of}} DFSS and Six-Sigma. We have had success in prioritization of research and design using a quantitative scalar metric for value, so we further explore the use of scalar metrics to represent the outcome of our use of the DFSS process. We use the design of an automotive component as an example of combining DFSS metrics into a scalar decision quantity. We then extend this concept to a high-priority, personnel safety example representing work that is toward the mature end of DFSS, and begins the transition into Six-Sigma for safety assessments in a production process. This latter example and objective involves the balance of research investment, quality control, and system operation and maintenance of high explosive handling at LLNL and related production facilities. Assuring a sufficiently low probability of failure (reaction of a high explosive given an accidental impact) is a Critical-To-Quality (CTQ) component of our weapons and stockpile stewardship operation and cost. Our use of DFSS principles, with quantification and merging of CTQ metrics, provides ways to quantify clear (<b>preliminary)</b> <b>paths</b> forward for both the automotive example and the explosive safety example. The presentation of simple, scalar metrics to quantify the path forward then provides a focal point for qualitative caveats and discussion for inclusion of other metrics besides a single, provocative scalar. In this way, carrying a scalar decision metric along with the DFSS process motivates further discussion and ideas for process improvement from the DFSS into the Six-Sigma phase of the product. We end with an example of how our DFSS-generated scalar metric could be improved given success of our future research investments in impact safety scenarios...|$|R
40|$|The current {{emphasis}} on performance outcomes in schools {{has threatened to}} eclipse {{the importance of social}} connectedness as an antecedent to student success. Presented is an instrument designed to measure student sense of connectedness with school based on relevant dimensions provided in the literature: student sense of belonging, engagement, expected learning, and trust. Drawing on data from over 3, 000 US students from six high schools, exploratory factor analysis yielded six latent factors based on 31 of 46 original items: students’ sense of belonging with peers; teacher support; fairness and safety; academic engagement; engagement in the broader community; and relatedness of self with school. Confirmatory factor analysis yielded acceptable preliminary fit measures. <b>Preliminary</b> <b>path</b> analyses suggest that students’ sense of relatedness with school mediates their relative propensity toward academic engagement, with the other factors antecedent. Schools seeking to obtain reliable measures of students’ sense of connectedness with school will find the instrument a valuable resource for prioritizing their efforts...|$|E
40|$|In {{this paper}} we give account of an {{experience}} {{which has been}} carried on starting from a master degree dissertation and then transferred upon a Bac level third year class in "Innovative Instruments for Design Representation" during the first semester of academic year 2012 - 2013. As a <b>preliminary</b> <b>path,</b> the students {{have been given a}} workshop where different techniques and semantic results in picture taking has been shown and discussed. Document or interpretation? The debate is still alive and more heated than ever, especially given the new opportunities offered by the advent of digital - from the eighties - which actually coincided with the death of historical photography: it is missing the negative - The real "deus ex machina" of the photographic representation has disappeared and {{has been replaced by a}} sequence of numerical data. There is no more similarity between reality and its representation, as both were attributable to the negative, the image has been transformed from loyal into disloyal. The digital technology has also brought a great revolution constituted by the merger between the still camera and the camera: the decisive moment and the whole motion share the same instrument. Between documents and interpretation in the work of contemporary photographers of architecture today it preveals the category of the story, achieved through the series of images in sequence. The goal of this experience is to let the students learn to build up a set of pictures which could give a complete coverage of the outstanding details of each architecture they have to deal with. This is important for two different aims: survey for preservation and preparation of a data set for semantic analisys, towards a possible project in the area...|$|E
40|$|Abstract: A 3 D {{interactive}} data exploration {{system was}} developed to aid users segmenting the small intestine using haptic feedback with visual and auditory information. Several evaluations have been or are currently carried out to determine the usability of the system. In work to improve the fidelity of the haptic feedback for the small intestine segmentation system, we have arrived at two feasible scenarios using <b>preliminary</b> automatic partial <b>path</b> extraction. In addition, a study in collaboration with UBIRM is outlined in order to evaluate the degree of user dependency on visual and haptic feedback during 3 D navigation...|$|R
30|$|A {{research}} question concerning initiative, independence, and self-guidance, hypothesized to be proximal antecedents of part-time job willingness and apprenticeship willingness was answered. A survey of ninth-grade students in Finnish comprehensive school was conducted after {{implementation of a}} work-orientation program. At the local school system level, 649 subjects of the mean ages of 16.0 years participated in a web-based survey in two {{school districts in the}} south-west of Finland in 2010. The observed variables were inserted for Path Analysis conducted in IBM Analysis of Moment Structures. Factor Analysis was used as a <b>preliminary</b> step for <b>Path</b> Analysis.|$|R
40|$|Algorithmic {{storytelling}} over Linked Data on the Web is {{a challenging}} task {{in which many}} graph-based pathfinding approaches experience issues with consistency regarding the resulting path {{that leads to a}} story. In order to mitigate arbitrariness and increase consistency, we propose to improve the semantic relatedness of concepts mentioned in a story by increasing the relevance of links between nodes through additional domain delineation and refinement steps. On top of this, we propose the implementation of an optimized algorithm controlling the pathfinding process to obtain more homogeneous search domain and retrieve more links between adjacent hops in each <b>path.</b> <b>Preliminary</b> results indicate the potential of the proposal...|$|R
40|$|On obstacle-cluttered {{construction}} sites where heavy equipment is in use, safety issues are of major concern. The main {{objective of this}} paper is to develop a framework with algorithms for obstacle avoidance and path planning based on real-time three-dimensional job site models to improve safety during equipment operation. These algorithms have the potential to prevent collisions between heavy equipment vehicles and other on-site objects. In this study, algorithms were developed for image data acquisition, real-time 3 D spatial modeling, obstacle avoidance, and shortest path finding and were all integrated to construct a comprehensive collision-free <b>path.</b> <b>Preliminary</b> research results show that the proposed approach is feasible and has the potential to be used as an active safety feature for heavy equipment...|$|R
40|$|Abstract—In this paper, a new {{theoretical}} approach for {{the classification of}} multiple reflections in time-domain e. m. inverse scattering of multi-layered media is presented. The existence of multiples limits the capabilities of inversion algorithms, thus suitable identification and suppression techniques should be applied to reduce this undesired effect. Assuming a scenario composed of loss-less and non-dispersive media, and providing an accurate time delay estimation (TDE) of backscattered signals, the proposed method allows not only to evaluate the presence of multiples and discriminate them from primary reflections, but also to determine their propagation <b>paths.</b> <b>Preliminary</b> tests performed on FDTD simulated data have shown its potentialities to effectively handle multiple reflections and therefore to enhance the e. m. signals backscattered by primary reflectors. 1...|$|R
40|$|The delay {{boundary}} prediction algorithms currently {{implemented by}} transport protocols are lowpass filters based on autoregressive and moving average (ARMA) models. However, {{recent studies have}} revealed a fractal-like structure of delay sequences, {{which may not be}} well suited to ARMA models. In this paper we propose a novel delay boundary prediction algorithm based on a deviation-lag function (DLF) to characterize end-toend delay variations. Compared to conventional algorithms derived from ARMA models, the new algorithm can adapt to delay variations more rapidly and share delay's robust high-order statistical information (jitter deviation) among competing connections along a common network <b>path.</b> <b>Preliminary</b> experiments show it outperforms Jacobson's algorithm, which is based on an ARMA model, by significantly reducing the prediction error rate. To show the practical feasibility of the DLF algorithm, we also propose a skeleton implementation model...|$|R
40|$|Some {{theory on}} Lévy {{processes}} and stochastic differential equations driven by Lévy processes is reviewed. Inverse Fast Fourier Transform routines {{are applied to}} compute {{the density of the}} increments of Lévy processes. We look at exact and approximate path integration operators to compute the probability density function of the solution process of a given stochastic differential equation. The numerical path integration method is shown to converge under the transition kernel backward convergence assumption. The numerical path integration method is applied on several examples with non-Brownian driving noises and nonlinearities, and shows satisfactory results. In the case when the noise is of additive type, a general code written for Lévy driving noises specified by the Lévy-Khintchine formula is described. A <b>preliminary</b> result on <b>path</b> integration in Fourier space is given. </p...|$|R
40|$|Abstract. Motion {{planning}} under {{uncertainty is}} an important problem in robotics. Although probabilistic sampling is highly successful for motion planning of robots with many degrees of freedom, sampling-based algorithms typically ignore uncertainty during planning. We introduce {{the notion of a}} bounded uncertainty roadmap (BURM) and use it to extend samplingbased algorithms for planning under uncertainty in environment maps. The key idea of our approach is to evaluate uncertainty, represented by collision probability bounds, at multiple resolutions in different regions of the configuration space, depending on their relevance for finding a best <b>path.</b> <b>Preliminary</b> experimental results show that our approach is highly effective: our BURM algorithm is at least 40 times faster than an algorithm that tries to evaluate collision probabilities exactly, and it is not much slower than classic probabilistic roadmap planning algorithms, which ignore uncertainty in environment maps. ...|$|R
40|$|Locating arteries {{hidden beneath}} {{superficial}} tissue {{can be a}} difficult task in minimally invasive surgery. This paper reports {{the development of a}} system that finds the paths of arteries using tactile sensing. The surgeon begins by using the surgical robot to place the tactile sensor instrument on a known artery location. Signal processing algorithms locate the artery from its pulsatile pressure variation. An adaptive extrapolation algorithm then generates predicted locations for the artery based on previous measurements. After moving to the predicted location, if the artery is not located then a backtracking mechanism moves the sensor towards previously detected locations. Tests with model arteries show good tracking ability for circular arcs with curvatures as small as 80 mm, although problems with compliance in the system result in occasional loss of the artery <b>path.</b> <b>Preliminary</b> tests demonstrate the ability to transcutaneously track the radial artery in the human wrist...|$|R
40|$|In this paper, <b>preliminary</b> {{study on}} <b>path</b> loss {{characterization}} of in-vivo communication channel at 2. 45 GHz using numerical modeling is presented. One of the antennas is implanted inside {{the chest and}} the second antenna {{is placed on the}} surface of body at certain distance. The on-body antenna is rotated at different angles with respect to the inbody antenna and path loss is calculated at certain fixed distance. The body-centric path loss is compared with the free space path loss as well. Results show that there is almost 10 - 15 dB variation in path loss in case of in-vivo channel as compared to free space. Also a degradation in path loss and channel response with respect to the orientation angle between implanted transmitter and on-body receiver is observed, which highlights the importance of carefully considering the location of on-body receiver for optimal system performance...|$|R
40|$|This paper {{considers}} the inverse shortest paths problem where arc costs {{are subject to}} correlation constraints. The motivation for this research arises from applications in tra#c modelling and seismic tomography. A new method is proposed for solving this class of problems. It is constructed as a generalization of the algorithm presented in # 1 # for uncorrelated inverse shortest <b>paths.</b> <b>Preliminary</b> numerical experience with the new method is presented and discussed. yBelgian National Fund for Scienti#c Research Department of Mathematics Facult#es Universitaires ND de la Paix B- 5000 Namur, Belgium zDepartment of Mathematics Facult#es Universitaires ND de la Paix B- 5000 Namur, Belgium Keywords : graph theory, shortest paths, inverse problems, quadratic programming, tra#c modelling. On {{the use of an}} inverse shortest paths algorithm for recovering linearly correlated costs by D. Burtony and Ph. L. Tointz Report 91 # 09 June 10, 1997 Abstract. This paper {{considers the}} inver [...] ...|$|R
40|$|Objectives The robotic totally {{endoscopic}} {{coronary artery}} bypass graft (TECAB) surgery reduces patients' recovery time. The present trial investigated the feasibility and safety of an initial enhanced recovery after surgery (ERAS) path for patients undergoing robotic beating-heart TECAB and compared it with both conventional surgery and traditional perioperative care. It was hypothesized that the preliminary ERAS pathway associated with a beating-heart TECAB procedure could have a synergistic effect on postoperative patient care. Design Observational retrospective study. Setting University hospital. Participants Patients scheduled for {{coronary artery bypass}} graft and undergoing robotic beating-heart TECAB (n = 38) were compared with those undergoing standard surgery and perioperative care (n = 33). The outcomes were the possibility of tracheal extubation {{at the end of the}} surgery and the incidence of postoperative complications. Measurements and Main Results The main comorbidities were similar between the 2 groups. Extubation on the operating table in the TECAB group was possible in all cases without requiring prompt endotracheal tube reinsertion. The proportion of patients transfused was significantly lower in the TECAB group (p = 0. 009). In addition, the duration of intensive care unit and hospital stay were reduced significantly by 24 hours and by 4 days, respectively, in the TECAB group compared with the standard group (p< 0. 05). Conclusions The present results suggested that a program coupling a beating-heart TECAB with a <b>preliminary</b> ERAS <b>path</b> for patients requiring a single coronary revascularization is feasible and safe. This approach could reduce postoperative mechanical ventilation time, transfusion rate, and both intensive care unit and hospital stay. SCOPUS: ar. jSCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|We {{investigate}} {{the feasibility of}} reconstructing an arbitrarily-shaped specular scene (refractive or mirror-like) cameras from one or more viewpoints. By reducing shape recovery {{to the problem of}} reconstructing individual 3 D light paths that cross the image plane, we obtain three key results. First, we show how to compute the depth map of a specular scene mirror reference point light path from a single viewpoint, when the scene redirects incoming light just once. Second, for scenes where incoming light light path undergoes two refractions or reflections, we show that three viewpoints are sufficient to enable reconstruction in the general case. Third, we show {{that it is impossible to}} recon-camera water reference point struct individual light paths when light is redirected more than twice. Our analysis assumes that, for every point on the image plane, we know at least one 3 D point on its light path. This leads to reconstruction algorithms that rely on an “environment matting ” procedure to establish pixel-to-point correspondences along a light <b>path.</b> <b>Preliminary</b> results for a variety of scenes (mirror, glass, etc) are also presented...|$|R
40|$|Non-CO 2 gas (CH 4, N 2 O and F gas) {{emissions}} {{account for}} 25 {{percent of all}} greenhouse gas {{in the year of}} 2000. Main sources of CH 4 and N 2 O emissions are agriculture-related activities such as enteric fermentation, paddy rice cultivation, soil management. A recursive dynamic CGE (Computer General Equilibrium) model has been developed to analyze greenhouse gas reduction options including non-CO 2 gas abatement technologies. Multi-regional, multisectoral and multi-gas CGE model and simple climate change model simulated long-term climate stabilization emission <b>path.</b> <b>Preliminary</b> results showed that multi gas mitigation options including CH 4 and N 2 O abatement technologies will reduce GDP loss more than CO 2 only mitigation options for long-term climate stabilization, even though CO 2 mitigation options will reduce not only CO 2 emissions but non-CO 2 gas emissions simultaneously. It is necessary to collect regional non-CO 2 gas data (emission, technology options, and so on) and conduct more sensitivity analysis with computer simulation model to reduce uncertainty of non-CO 2 gas. ...|$|R
40|$|High {{performance}} {{integrated circuits}} {{suffer from a}} permanent increase of the dissipated power per square millimeter of silicon, over the past years. This phenomenon {{is driven by the}} miniaturization of CMOS processes, increasing packing density of transistors and increasing clock frequencies of microchips, thus pushing heat removal and power distribution to the forefront of the problems confronting the advance of microelectronics. In the opposite direction is the market growth of mainstream portable devices, which require extremely low power consumption. These evolving factors brought power dissipation into play and transformed it into a major design metric. This thesis comprises those knowledge and methodological tools that can offer a <b>preliminary</b> safe <b>path</b> toward less power-hungry SoC and MPSoC designs, thus contributing towards a holistic approach of power-related effects. This is accomplished by providing the essential theoretical background of CMOS power dissipation, investigating a vast range of power saving techniques and plotting their classifications, according to the power components each technique is meant to suppress and, the level of abstraction that it can be applied at, thus facilitating proper decision making about which power saving techniques to apply on a certain design. Moreover, this thesis implements, demonstrates and evaluates generic power analysis and optimization flows that are based on the ASIC industry’s de facto standard Synopsys tools. The tools’ actual capabilities are contrasted to the theoretical expectations and the chief tradeoffs that are involved in terms of speed versus accuracy and attainable power savings versus abstraction level are stressed. Our extracted power results, for an Ericsson’s large ASIC block, show that by putting emphasis on coping with power early, thus enhancing typical synthesis flows with an appropriate set of techniques, significant savings can be achieved for both dynamic and static power components in the front-end synthesis domain...|$|R
40|$|Commercial, scientific, {{and social}} {{activities}} are increasing becoming dependent on Web database applications. New testing techniques that handle the unique features {{of these systems}} are needed. To that end, we have extended AGENDA, a tool set for testing relational database applications, to test web database applications. Application source code is analyzed to extract relevant information about the URLs and their parameters. This information is used to construct and simplify a graph in which nodes represent URLs and edges represent links between URLs. A set of paths through the graph is selected and test cases are generated for each path. The extracted information about the parameters to each URL (e. g., values that an application user would enter into a form), is used to guide AGENDA to generate inputs for the URLs. The URLs on a path and their inputs are stored in an XML file, which is then automatically executed. The current implementation is targeted toward web applications written as Java Servlets and uses an algorithm based on cyclomatic complexity to generate <b>paths.</b> <b>Preliminary</b> empirically evaluation based on the TPC-W benchmark is presented. 1...|$|R
