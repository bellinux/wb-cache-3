19|962|Public
40|$|As part of NASA s Intelligent Flight Control Systems <b>program,</b> <b>parameter</b> {{identification}} {{experiments were}} carried out with NASA Dryden s F- 15 B TN 837 aircraft. The canard control surfaces, whose movement is highly correlated with aircraft angle of attack, and the aircraft s aerodynamic instability in the pitch axis contribute to making parameter identification challenging. The equation-error method of analysis is applied to several longitudinal parameter identification maneuvers and a new approach for compensating for flight-data signal time lags is developed, which improves the accuracy and consistency of the results...|$|E
40|$|In {{the present}} paper the effects of {{different}} loading procedures on the response of rate-sensitive inelastic materials are analysed. The elasto/viscoplastic model problem is developed {{by taking advantage of}} the postulate of maximum dissipation in order to derive an associated formulation of the evolutive laws. A non-dimensional loading <b>program</b> <b>parameter</b> is introduced which accounts for the loading procedure and the intrinsic properties of the material. An appropriate solution method is applied and specific numerical examples are reported so that the implications due to different loading programs on the inelastic behaviour of rate-sensitive materials are suitably illustrated...|$|E
40|$|The {{effects of}} {{different}} loading {{programs on the}} elasto-/viscoplastic behavior of rate-sensitive materials are analyzed with specific numerical examples. An appropriate solution scheme and a consistent tangent operator are applied which are capable of being adopted for general computational procedures. Numerical computations and results are reported which illustrate the rate-dependence of the elasto-/viscoplastic constitutive model in use. In the numerical analysis the loading is applied by increasing the pressure and accordingly a nondimensional loading <b>program</b> <b>parameter</b> is introduced. In the numerical results {{the significance of the}} loading program is thus emphasized with reference to the nonlinear response of the elasto-/viscoplastic material behavior of solids...|$|E
40|$|For {{phase change}} {{random access memory}} applications, the scaling {{perspective}} of the 3 main <b>programming</b> <b>parameters</b> is essential. The programming time will largely determine the obtainable data rate. The required programming current will largely determine the transistor size and hence the obtainable memory density. Finally, the programming voltage should preferably not exceed the transistor driving voltage. In this paper, the scaling perspective for these 3 main <b>programming</b> <b>parameters</b> is investigated for doped Sb 2 Te PCRAM line cells...|$|R
50|$|There {{were also}} some higher-level {{messages}} corresponding to advanced <b>program</b> <b>parameters,</b> such as modulation, envelopes and 3D spatialization of voices, {{as well as}} instrument-specific messages for guitar, wind, and drum controllers.|$|R
50|$|In {{computer}} <b>programming,</b> <b>Parameter</b> Value Language (PVL) is a {{markup language}} similar to XML. It is commonly employed for {{entries in the}} Planetary Database System used by NASA to store mission data, among other uses.|$|R
40|$|Abstract. We {{present a}} model of multithreaded {{computation}} {{with an emphasis on}} estimating parallelism overheads of programs written for modern many-core archi-tectures. We establish a Graham-Brent theorem so as to estimate execution time of programs running on a given number of streaming multiprocessors. We evaluate the benefits of our model with fundamental algorithms from scientific computing. For two case studies, our model is used to minimize parallelism overheads by determin-ing an appropriate value range for a given <b>program</b> <b>parameter.</b> For the others, our model is used to compare different algorithms solving the same problem. In each case, the studied algorithms were implemented and the results of their experimental comparison are coherent with the theoretical analysis based on our model...|$|E
40|$|The vehicle {{movement}} simulation program FASIMA {{developed by}} Guehrer and Jauch {{has been extended}} to integrate infinitely variable speed transmissions. Using the extended FASIMA <b>program,</b> <b>parameter</b> examinations were carried out as {{a contribution to the}} optimization of infinitely variable mechanical speed gears concerning fuel consumption, driving performance and comfort. Three-dimensional roadway profiles, vehicle velocity and additional traffic informations obtained by satellite positioning have been used as starting parameters for vehicle movement simulation and traffic flow simulation programs. Compared with conventional gears, 2 - 11 % of the full can be economized by the application of the infinitely variable mechanical speed gears. (WEN) SIGLEAvailable from TIB Hannover: RN 2441 (57) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|E
40|$|We {{present a}} model of multithreaded {{computation}} {{with an emphasis on}} estimat-ing parallelism overheads of programs written for modern many-core architectures. We establish a Graham-Brent theorem for this model so as to estimate execution time of programs running on a given number of streaming multiprocessors. We evaluate the benefits of our model with fundamental algorithms from scientific com-puting. For two case studies, our model is used to minimize parallelism overheads by determining an appropriate value range for a given <b>program</b> <b>parameter.</b> For the others, our model is used to compare different algorithms solving the same prob-lem. In each case, the studied algorithms were implemented and the results of their experimental comparison are coherent with the theoretical analysis based on our model. ...|$|E
40|$|This work {{deals with}} the {{optimization}} of computer programs targeting Graphics Processing Units (GPUs). The goal is to lift, from programmers to optimizing compilers, the heavy burden of determining program details that are dependent on the hardware characteristics. The expected benefit is to improve robustness, portability and efficiency of the generated computer programs. We address these requirements by: (1) treating machine and <b>program</b> <b>parameters</b> as unknown symbols during code generation, and (2) generating optimized programs {{in the form of}} a case discussion, based on the possible values of the machine and <b>program</b> <b>parameters.</b> By taking advantage of recent advances in the area of computer algebra, preliminary experimentation yield promising results...|$|R
50|$|The Chroma {{control panel}} {{consists}} of 71 membrane switches. Most {{of them are}} multi-purpose and are used to select sound programs or sound <b>program</b> <b>parameters,</b> when in edit mode. A single slider is used to change parameter values.|$|R
30|$|The federal government’s {{fiscal year}} is the year ending September 30. The fiscal year {{indicates}} when safety net benefit <b>program</b> <b>parameters</b> are reset, {{and the nature of}} the federal budgeting, but not the time frame for performing the income test.|$|R
40|$|An {{improved}} Automated Mixed Traffic Vehicle (AMTV) {{speed control}} system employing a microprocessor and transistor chopper motor current controller is described and its performance {{is presented in}} terms of velocity versus time curves. The on board computer hardware and software systems are described as is the software development system. All of the programming used in this controller was implemented using FORTRAN. This microprocessor controller made possible a number of safety features and improved the comfort associated with starting and shopping. In addition, most of the vehicle's performance characteristics can be altered by simple <b>program</b> <b>parameter</b> changes. A failure analysis of the microprocessor controller was generated {{and the results are}} included. Flow diagrams for the speed control algorithms and complete FORTRAN code listings are also included...|$|E
40|$|Survey and mapping {{potassium}} {{status on}} wet rice {{have been in}} irrigation area Bahal Gajah/TigaBolon in kecamatan Sidamanik. This research purpose to make a map potassium status on wet ricefield in irrigation area Bahal Gajah/Tiga Bolon. The research was started on April until December 2012. Sampling method use free grid survey method with semi detail survey scale. Result ofanalysis process using correlation method, with Geographical Information System (GIS) <b>program.</b> <b>Parameter</b> that analysis in laboratory is exchange of potassium. The result of research showed thatpotassium exchange available devided by 5 status such as; lowest 0, 118 ha (0, 03 %), low 1, 542 ha(0, 36 %), medium 35, 203 ha (8, 24 %), high 90, 114 ha (21, 08 %), and highest 300, 473 ha (70, 29 %) ...|$|E
40|$|Survey and mapping {{phosphorus}} {{status on}} irrigated rice field at Bahal Gajah and Tiga Bolonvillage in Sidamanik Subdistrict. This research purpose {{to make a}} map phosphate status on wet ricefield in irrigation area Bahal Gajah/Tiga Bolon. The research start to do on May until December 2012. Method of sample take use free grid survey method with semi detail survey scale. Result ofanalysis process using regreation method, with Geografis Information System (GIS) <b>program.</b> <b>Parameter</b> that analysis in laboratory is phosphate available and phosphate total. The result ofresearch showed that phosphate available divided by 3 status such as; medium (6, 087 ha), high(136, 005 ha), and highest (286, 101 ha). Phosphate total divided by 3 status such as; medium(48, 393 ha), high (109, 445 ha), and highest (269, 263 ha) ...|$|E
40|$|A future {{bilateral}} SAR {{program was}} studied. The requirements supporting a SAR mission posed by science and operations in sea-ice-covered waters, oceanography, renewable resources, and nonrenewable resources are addressed. The instrument, mission, and <b>program</b> <b>parameters</b> were discussed. Research investigations supporting a SAR flight {{and the subsequent}} overall mission requirements and tradeoffs are summarized...|$|R
40|$|This paper {{demonstrates}} {{the feasibility of}} constructing faultcontaining, self-stabilizing protocols that allow the user to fine-tune {{the performance of the}} protocols, via the choice of values for certain <b>program</b> <b>parameters.</b> Based on the fault-history of the protocol, the user can choose appropriate values for <b>program</b> <b>parameters</b> and select desirable performance guarantees from various classes of faults. As an example, parameterized versions of Dijkstra's K-state mutual exclusion protocol are presented and these allow the user to trade off between performance measures such as stabilization time, k-fault-containment time, and token size. 1 Introduction Informally, a self-stabilizing protocol is called fault-containing if in addition to ensuring eventual convergence to a legitimate state from an arbitrary state, the protocol provides extra guarantees during convergence from states with "limited" faults. For example, an extra guarantee that a fault-containing self-stabilizing protocol ma [...] ...|$|R
50|$|Some vectorizers are {{standalone}} programs, {{but many}} have interactive interfaces that allow a user {{to adjust the}} <b>program</b> <b>parameters</b> and quickly see the result. PowerTRACE, for example, can display the original image and preview the converted image so the user may compare them; the program also reports information such {{as the number of}} curves.|$|R
40|$|Models of {{the labor}} supply of an {{individual}} family member's response to a Negative Income Tax (NIT) have often ignored family labor-supply interactions. This paper presents results indicating that, accounting for cross-substitution effects, an NIT has different impacts on the labor supply of family members. The female tends to reduce her labor supply {{at all levels of}} tax rate and guaranteed income, while the male increases his labor supply at certain <b>program</b> <b>parameter</b> levels. This seems to suggest that the work disincentive effect and the aggregate cost of an NIT may be less than has previously been thought for males. The empirical results also show that an NIT has different effects on the labor supply of family members working in different segments {{of the labor}} market, and that the measured effects are sensitive to choice of functional form. Labor Supply...|$|E
40|$|Thermal management, {{multifunctional}} structuresThe multifunctional {{support structure}} (MFSS) technology is promising {{a reduction of}} overall mass and packing volume for spacecraft (S/C) electronic components. This technology eliminates the electronic box chassis and the cabling between the boxes by integrating the electronics, thermal control and the structural support into one single element. The ultimate goal of the MFSS technology is to reduce size, weight, power consumption, cost and production time for future spacecraft components. The paper focus on the main challenges and solutions related to the thermal management within the MFSS technology based on the selected charge regulator (CR) application. Starting with the main set of thermal requirements for the CR the paper will include: Conceptual and detailed design based on highconductivity carbon fibre CFRP, Description and results of the thermal material sample test <b>program,</b> <b>Parameter</b> and results for the performed first thermal simulatio...|$|E
40|$|International audienceIn this article, we {{describe}} a knowledge-based controlled platform using program supervision techniques. This platform eases {{the creation and}} the configuration of video surveillance systems. Several issues {{need to be addressed}} to provide a correct system configuration: (1) to choose, among a library of programs, those which are best satisfying a given user request, (2) to assign a correct value for each <b>program</b> <b>parameter,</b> (3) to evaluate performances and to guarantee a performance rate which is satisfactory regarding end-user requirements. This platform is composed of three main components: the library of programs, the knowledge base and the control component. The knowledge is either given by experts or learnt by the system. The control is generic {{in the sense that it}} is independent of any application. To validate this platform, we have built and evaluated six video surveillance systems which are featured with three properties: adaptability, reliability and real-time processing...|$|E
40|$|By <b>programming</b> <b>parameters,</b> {{implementation}} of VSD reference CFW- 11, {{and conducting}} starts with electric induction motors, with different characteristics, we analyze the {{behavior of the}} variables: voltage, current, torque and engine velocity to verify that the starting VSD method is the ideal. System graphs are obtained by implementing the tool "Trend" from SuperDriveG 2 software, which are analyzed to determine {{the behavior of the}} application...|$|R
40|$|Summary: Multiple (BLAST) Annotation System Viewer (MASV) {{is a tool}} {{designed}} {{to aid in the}} annotation of genomic sequences. MASV enables the researcher to compare and analyse differences in annotation and analysis, resulting from changes in databases, analysis <b>program</b> <b>parameters</b> and results. This provides a unique capability for the user to conduct further bioinformatics analysis from the information obtained...|$|R
40|$|In this paper, {{we present}} the {{accelerator}} model ofMetaFork {{together with the}} software framework that allows automatic generation of CUDA code from annotated MetaFork pro-grams. One of the key features of this CUDA code gen-erator is that it supports the generation of CUDA kernel code where <b>program</b> <b>parameters</b> (like number of threads per block) and machine parameters (like shared memory size) are allowed. These parameters need not to be known at code-generation-time: machine <b>parameters</b> and <b>program</b> <b>parameters</b> can be respectively determined and optimized when the generated code is installed on the target machine. This generation of parametricCUDA kernels requires from the MetaFork framework to deal with non-linear polyno-mial expressions during the dependence analysis and tiling phase of the MetaFork code. To achieve these algebraic calculations, we take advantage of quantifier elimination and its implementation in the RegularChains in Maple. Vari-ous illustrative examples are provided together with perfor-mance evaluation. 1...|$|R
40|$|We {{implemented}} a fortran code that determine fundamental parameters of solar type stars {{from a list}} of Fe line equivalent widths. The solution should verify 3 conditions in the standard method: ionization equilibrium, excitation equilibrium and independence between metallicity and equivalent widths. We added the condition that the input metallicity of the model atmosphere should be similar to the output metallicity derived with equivalent widths. Solar-scaled Kurucz model atmospheres with NEWODF opacities are calculated with an independent <b>program.</b> <b>Parameter</b> files control different details, such as the mixing-length parameter, the overshooting, the damping of the lines and the weight factors in the definition of the chi 2 function. FUNDPAR derive the uncertainties following 2 methods: the criteria of Gonzalez & Vanture (1998) and the dispersion using the chi 2 function. The code use the 2009 version of the MOOG program. The results derived with FUNDPAR are in agreement with previous determinations in the literature. In particular we obtained the fundamental parameters of 58 exoplanet host stars. The program is freely available from the web ([URL] 16 pages, 5 figures, accepte...|$|E
40|$|Past SGA Changes as a Natural Experiment The {{number of}} American adults {{receiving}} {{benefits from the}} Social Security Disability Insurance (SSDI) program has increased dramatically {{over the past several}} decades. A proposed solution to rising program costs is to change program rules to encourage fully or partially recovered SSDI beneficiaries to return to work. One such option is a benefit offset policy, which would reduce SSDI benefits by $ 1 for every $ 2 of earned income. While a benefit offset could generate savings from increased labor supply and program exit among current beneficiaries, it could also generate unintended costs if the more generous work rules induce significant numbers of working individuals to apply for benefits. In this paper we examine how past changes in a closely related <b>program</b> <b>parameter,</b> the Substantial Gainful Activity (SGA) threshold, have affected SSDI applications. We exploit changes over time and across states in real relative SGA levels, relative to local average wages. We find that a 7 percentage point (30 %) increase in the real relative SG...|$|E
40|$|Working Paper: WP 2012 - 262 The {{number of}} American adults {{receiving}} {{benefits from the}} Social Security Disability Insurance (SSDI) program has increased dramatically {{over the past several}} decades. A proposed solution to rising program costs is to change program rules to encourage fully or partially recovered SSDI beneficiaries to return to work. One such option is a benefit offset policy, which would reduce SSDI benefits by $ 1 for every $ 2 of earned income. While a benefit offset could generate savings from increased labor supply and program exit among current beneficiaries, it could also generate unintended costs if the more generous work rules induce significant numbers of working individuals to apply for benefits. In this paper we examine how past changes in a closely related <b>program</b> <b>parameter,</b> the Substantial Gainful Activity (SGA) threshold, have affected SSDI applications. We exploit changes over time and across states in real relative SGA levels, relative to local average wages. We find that a 7 percentage point (30 %) increase in the real relative SGA (on par with the 1999 increase from $ 500 to $ 700 per month) was associated with a 4. 7 % increase in applications...|$|E
40|$|The Nucleus 24 Cochlear Implant {{system with}} the SPrint {{processor}} provides access to multiple speech processing strategies and {{a wide range of}} <b>programming</b> <b>parameters.</b> Strategy comparison studies have suggested that the optimal parameter set and coding strategy varies from individual to individual. It is necessary, however, to establish some default <b>programming</b> <b>parameters</b> and fitting guidelines. Therefore we have investigated the effect of stimulation rate and the number of channels or maxima in the ACE or CIS strategies, as well as the optimal programming strategy for subjects with a limited number of available electrodes. Speech perception was tested using monosyllabic words and sentences in noise, with the evaluation protocol designed to take into account learning effects. Take-home experience was provided with all programs, and subjects were asked to complete a comparative performance questionnaire regarding program preference. Six or eight subjects were enrolled in each study. 29 August - 3 SeptemberOpen Acces...|$|R
40|$|Abstract. Statistical {{techniques}} for designing and analysing experiments {{are used to}} evaluate the individual and combined effects of genetic <b>programming</b> <b>parameters.</b> Three binary classification problems are investigated in a total of seven experiments consisting of 1108 runs of a machine code genetic <b>programming</b> system. The <b>parameters</b> having the largest effect in these experiments are the population size and the number of generations. A large number of parameters have negligible effects. The experiments indicate that the investigated genetic programming system is robust to parameter variations, {{with the exception of a}} few important parameters. ...|$|R
40|$|Cardiac {{resynchronization}} {{therapy is}} a non-pharmacological treatment {{for patients with}} dilated cardiomyophaty and congestive heart failure. The success of this therapy depends of permanent biventricular stimulation. We report an 84 year-old man, with intermittent loss of biventricular pacemaker stimulation despite having adequate sensing and stimulation thresholds in the right atrium and both ventricles. The problem was solved after correcting some <b>programming</b> <b>parameter...</b>|$|R
40|$|The visual {{assessment}} of tendency (VAT) technique, for visually finding {{the number of}} meaningful clusters in data, developed by J. C. Bezdek, R. J. Hathaway and J. M. Huband, is very useful, but {{there is room for}} improvements. Instead of displaying the ordered dissimilarity matrix (ODM) as a 2 D gray-level image for human interpretation as is done by VAT, we trace the changes in dissimilarities along the diagonal of the ODM. This changes the 2 D data structure (matrices) into 1 D arrays, displayed as what we call the tendency curves, which enables one to concentrate only on one variable, namely the height. One of these curves, called the d-curve, clearly shows the existence of cluster structure as patterns in peaks and valleys, which can be caught not only by human eyes but also by the computer. Our numerical experiments showed that the computer can catch cluster structures from the d-curve even in some cases where the human eyes see no structure from the visual outputs of VAT. And success on all numerical experiments was obtained us- ing the same (fixed) set of <b>program</b> <b>parameter</b> values...|$|E
40|$|Optimal {{engineering}} design specifications are usually derived from an iterative design process. Here, different mathematical programs, each representing {{a particular problem}} assumption, are solved {{in order to gain}} insight into how and why an ideal design changes as model parameters vary. The mathematical technique used in this process is termed sensitivity analysis. The focus of this study is on techniques for performing such analysis on optimization problems which can be modeled as geometric programs. A dual based computationally attractive numerical procedure was developed to generate the locus of optimal solutions to prototype geometric programs corresponding to a large set of <b>program</b> <b>parameter</b> trajectories. Coefficient variation can include individual or simultaneous changes in any or all cost and exponent values. Sensitivity analysis is accomplished by numerically solving a specially constructed nonlinear initial value differential equation problem. Computational procedures were developed for computing an intitial value point, differential equation construction and solution, primal/dual conversion and problem reconstruction {{in the event of a}} primal constraint status change. A computer program written to carry out this scheme was described and used in the design of a batch process chemical plant. Preliminary results show the sensitivity analysis procedure developed in this study is attractive in terms of required computation time and perturbation flexibility of model coefficients...|$|E
40|$|In {{this thesis}} {{contingent}} claims techniques {{have been applied}} to various specifications of the economic problem of optimizing the expected value of a welfare function. In paper I we consider the relationship between financial market completeness, corn production, and the corn target price program. Using the observation that the program {{is similar to a}} government issued put option, we found that the per acre program benefit, at around 20 /acre was quite large, that the program encourages producers to trade options, and that the existence of contingent markets facilitates the policy maker in decoupling agricultural support. In paper II we proposed a method for estimating the expected cost to the government of the corn target price program. The model is rational expectations in orientation. It allows the government to understand the implications for output and budget control of different <b>program</b> <b>parameter</b> choices. This model may be adapted to other economic problems, such as the effects of wage or rent control laws on production and factor use. In paper III we suggest that there is an inconsistency between the structure of existing contingent claims markets and how economists would seem to prefer to approximate demand functions. We propose an alternative structure that is consistent with the preferred approach to demand function approximation, and with the moment based foundations of Statistics and Probability; In the final paper we propose an alternative perspective on problems involving the maximization of the expected value of a welfare function. We reformulate the objective function in terms of options. We then show that existing techniques from economics, statistics, and finance theory may be applied to better understand the economic effects of uncertainty. Three standard economic problems are considered; valuation of a risky investment, production under price uncertainty, and the effects of price uncertainty on expected profit...|$|E
40|$|Abstract. The uniformly {{accelerated}} {{motion in}} NC systems is analysed based on the constitution and realization of a {{uniformly accelerated motion}}, in order to implementing the uniformly accelerated motion, the corresponding means is explained, the conversion of <b>program</b> <b>parameters</b> is calculated, the rule of uniformly accelerated motion is analyzed and some factors, and {{the effect on the}} uniformly accelerated motion is illuminated...|$|R
25|$|CoSort was {{released}} for CP/M in 1978, DOS in 1980, Unix in the mid-eighties, and Windows {{in the early}} nineties, and received a readership award from DMReview magazine in 2000, CoSort was initially designed as a file sorting utility, and added interfaces to replace or convert the sort <b>program</b> <b>parameters</b> used in IBM Infosphere DataStage, Informatica, Micro Focus COBOL, JCL, NATURAL, SAS, and SyncSort Unix.|$|R
40|$|The {{most popular}} multithreaded {{languages}} {{based on the}} fork-join concurrency model (CIlkPlus, OpenMP) are currently being extended to support other forms of parallelism (vectorization, pipelining and single-instruction-multiple-data (SIMD)). In the SIMD case, {{the objective is to}} execute the corresponding code on a many-core device, like a GPGPU, for which the CUDA language is a natural choice. Since the programming concepts of CilkPlus and OpenMP are very different from those of CUDA, it is desirable to automatically generate optimized CUDA-like code from CilkPlus or OpenMP. In this thesis, we propose an accelerator model for annotated C/C++ code together with an implementation that allows the automatic generation of CUDA code. One of the key features of this CUDA code generator is that it supports the generation of CUDA kernel code where <b>program</b> <b>parameters</b> (like number of threads per block) and machine parameters (like shared memory size) are treated as unknown symbols. Hence, these parameters need not to be known at code-generation-time: machine <b>parameters</b> and <b>program</b> <b>parameters</b> can be respectively determined when the generated code is installed on the target machine. In addition, we show how these parametric CUDA programs can be optimized at compile-time {{in the form of a}} case discussion, where cases depend on the values of machine parameters (e. g. hardware resource limits) and <b>program</b> <b>parameters</b> (e. g. dimension sizes of thread-blocks). This generation of parametric CUDA kernels requires to deal with non-linear polynomial expressions during the dependence analysis and tiling phase. To achieve these algebraic calculations, we take advantage of techniques from computer algebra, in particular in the RegularChains library of Maple. Various illustrative examples are provided together with performance evaluation...|$|R
