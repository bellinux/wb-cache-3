750|1083|Public
25|$|After the bug is reproduced, {{the input}} of the program {{may need to be}} {{simplified}} {{to make it easier to}} debug. For example, a bug in a compiler can make it crash when parsing some large source file. However, after simplification of the test case, only few lines from the original source file can be sufficient to reproduce the same crash. Such simplification can be made manually, using a divide-and-conquer approach. The programmer will try to remove some parts of original test case and check if the problem still exists. When debugging the problem in a GUI, the programmer can try to skip some user interaction from the original <b>problem</b> <b>description</b> and check if remaining actions are sufficient for bugs to appear.|$|E
2500|$|This is a {{multistage}} {{stochastic programming}} problem, where stages are numbered from [...] to [...] Optimization is performed over all implementable and feasible policies. To complete the <b>problem</b> <b>description</b> one {{also needs to}} define the probability distribution of the random process [...] This {{can be done in}} various ways. For example, one can construct a particular scenario tree defining time evolution of the process. If at every stage the random return of each asset is allowed to have two continuations, independent of other assets, then the total number of scenarios is [...]|$|E
50|$|A partial-order planner is an {{algorithm}} {{or program}} which will construct a partial-order plan {{and search for}} a solution. The input is the <b>problem</b> <b>description,</b> consisting of descriptions of the initial state, the goal and possible actions.|$|E
50|$|Read and {{understand}} a <b>problem's</b> <b>description,</b> purpose, and goals.|$|R
40|$|Control Network Programming (CNP) is a {{style of}} {{high-level}} programming created to be especially convenient for solving problems with natural graph-like representation. Showing that this goal has been achieved {{is the purpose of}} the current report. CNP solutions to four problems representative of four important problem classes are presented. Most of the <b>problem</b> <b>descriptions</b> are nondeterministic and declarative, without specifying an algorithmic solution. These natural <b>problem</b> <b>descriptions</b> are easily converted into working Control Network programs. 1...|$|R
50|$|There is no {{connection}} between Meta-IV, and Schorre's Meta-II language, or its successor Tree Meta; these were compiler-compiler systems rather than being suitable for formal <b>problem</b> <b>descriptions.</b>|$|R
5000|$|The <b>problem</b> <b>description</b> {{implies that}} [...] that [...] and , that [...] and that [...] where A and B are {{the heights of}} the walls where sides of lengths b and a {{respectively}} lean (as in the above graph).|$|E
5000|$|In {{conventional}} logic, the programmer rapidly {{discovers that}} neither the input nor the output structures {{can be used to}} drive the call hierarchy of control flow. In FBP, on the other hand, the <b>problem</b> <b>description</b> itself suggests a solution: ...|$|E
50|$|The data in CDMS {{are then}} {{transferred}} {{for the data}} validation. Also, in these systems during validation the data clarification from sites are done through paper forms, which are printed with the <b>problem</b> <b>description</b> {{and sent to the}} investigator site and the site responds by answering on forms and mailing them back.|$|E
50|$|The Department of State, with CIA assistance, prepares {{an annual}} volume called Patterns in Terrorism. FBI {{reporting}} is more irregular, but does do <b>problem</b> <b>descriptions</b> {{as well as}} specific reports.|$|R
40|$|Abstract. We have {{developed}} an interactive query refinement tool that helps users search a knowledge base for solutions to problems with electronic equipment. The system is targeted towards non-technical users, who are often unable to formulate precise <b>problem</b> <b>descriptions</b> on their own. Two distinct but interrelated functionalities support the refinement of a vague, non-technical initial query into a more precise problem description: a synonymy mechanism that allows the system to match non-technical words in the query with corresponding technical terms in the knowledge base, and a novel refinement mechanism that helps the user build up successively longer and more precise <b>problem</b> <b>descriptions</b> starting from the seed of the initial query. A natural language parser is used both {{in the application of}} context-sensitive synonymy rules and the construction of the refinement tree. ...|$|R
5000|$|... where [...] {{denotes the}} size of the <b>problem</b> instance's <b>description.</b>|$|R
50|$|In {{traditional}} computation, a human {{employs a}} computer to solve a problem; a human provides a formalized <b>problem</b> <b>description</b> and an algorithm to a computer, and receives a solution to interpret. Human-based computation frequently reverses the roles; the computer asks a person or {{a large group of}} people to solve a problem, then collects, interprets, and integrates their solutions.|$|E
50|$|Perhaps {{the most}} {{important}} open problem in all of computer science {{is the question of}} whether a certain broad class of problems denoted NP can be solved efficiently. This is discussed further at Complexity classes P and NP, and P versus NP problem is one of the seven Millennium Prize Problems stated by the Clay Mathematics Institute in 2000. The Official <b>Problem</b> <b>Description</b> was given by Turing Award winner Stephen Cook.|$|E
5000|$|This was the {{official}} language of the 1st and 2nd IPC in 1998 and 2000 respectively.It separated {{the model of the}} planning problem in two major parts: (1) domain description and (2) the related <b>problem</b> <b>description.</b> Such a division of the model allows for an intuitive separation of those elements, which are (1) present in every specific problem of the problem-domain (these elements are contained in the domain-description), and those elements, which (2) determine the specific planning-problem (these elements are contained in the problem-description). Thus several problem-descriptions may be connected to the same domain-description (just like several instances may exist of a class in OOP (Object Oriented Programming) or in OWL (Ontology Web Language) for example). Thus a domain and a connecting <b>problem</b> <b>description</b> forms the PDDL-model of a planning-problem, and eventually this is the input of a planner (usually domain-independent AI planner) software, which aims to solve the given planning-problem via some appropriate planning algorithm. The output of the planner is not specified by PDDL, but it is usually a totally or partially ordered plan (a sequence of actions, some of which may be executed even in parallel sometimes). Now lets {{take a look at the}} contents of a PDDL1.2 domain and <b>problem</b> <b>description</b> in general...(1) The domain description consisted of a domain-name definition, definition of requirements (to declare those model-elements to the planner which the PDDL-model is actually using), definition of object-type hierarchy (just like a class-hierarchy in OOP), definition of constant objects (which are present in every problem in the domain), definition of predicates (templates for logical facts), and also the definition of possible actions (operator-schemas with parameters, which should be grounded/instantiated during execution). Actions had parameters (variables that may be instantiated with objects), preconditions and effects. The effects of actions could be also conditional (when-effects).(2) The <b>problem</b> <b>description</b> consisted of a problem-name definition, the definition of the related domain-name, the definition of all the possible objects (atoms in the logical universe), initial conditions (the initial state of the planning environment, a conjunction of true/false facts), and the definition of goal-states (a logical expression over facts that should be true/false in a goal-state of the planning environment). Thus eventually PDDL1.2 captured the [...] "physics" [...] of a deterministic single-agent discrete fully accessible planning environment.|$|E
40|$|This change {{concerns}} {{a small number}} of Market Participants who have had problems with their message exchange API. An upgrade to Java version 1. 5. 0. 1 will fix these <b>problems.</b> <b>Description</b> of the Results: Message Exchange users will be prompted to download a new Java version. The new version fixes problems with the MPs Message Exchange API. Release Plannin...|$|R
50|$|A solver is a {{piece of}} {{mathematical}} software, possibly {{in the form of a}} stand-alone computer program or as a software library, that 'solves' a mathematical problem. A solver takes <b>problem</b> <b>descriptions</b> in some sort of generic form and calculates their solution. In a solver, the emphasis is on creating a program or library that can easily be applied to other problems of similar type.|$|R
40|$|This thesis uses {{discourse}} analysis to compare systemic and cognitive-behavioural therapies, in terms of, {{the process of}} initial negotiation between client and therapist over therapeutic parameters, {{and the development of}} new <b>problem</b> <b>descriptions.</b> It also compares the theoretical description of the application of each therapy with the actual application of each therapy. The first section develops an argument for an approach to process research which is based on bottom-up naturalistic analysis of the way language is used in therapy. In doing so, it highlights the limitations of the positivist process and outcome research traditions, and provides an account of the range of established approaches to {{discourse analysis}}. The approach to analysis used draws on traditions of conversation analysis and discourse analysis. Several sub-themes are discussed within each of the two main analytic foci; negotiation of parameters and development of <b>problem</b> <b>descriptions.</b> The final section summarises the findings according to the analytic foci, and discusses the implications of the findings for clinical practice, and topical professional and political developments. Further indicated research and validity issues are also discussed...|$|R
50|$|Any farmer, {{agriculturist}} or hobbyist can {{register and}} post questions and {{a panel of}} Agriculture Experts answers questions based on the <b>problem</b> <b>description</b> and photos if any. Contextual Information such as geographical location, weather, season are retrieved automatically and made available to experts. Apart from agriculture, aAQUA is a forum for questions regarding education, healthcare and other issues important to a developing population. Currently questions may be asked in one of four languages - Hindi, Marathi, Kannada and English.|$|E
5000|$|This is a {{multistage}} {{stochastic programming}} problem, where stages are numbered from [...] to [...] Optimization is performed over all implementable and feasible policies. To complete the <b>problem</b> <b>description</b> one {{also needs to}} define the probability distribution of the random process [...] This {{can be done in}} various ways. For example, one can construct a particular scenario tree defining time evolution of the process. If at every stage the random return of each asset is allowed to have two continuations, independent of other assets, then the total number of scenarios is [...]|$|E
50|$|James Chase (2002) {{argues that}} the second {{argument}} is correct because it does correspond to the way to align two situations (one in which we gain, the other in which we lose), which is preferably indicated by the <b>problem</b> <b>description.</b> Also Bernard Katz and Doris Olin (2007) argue this point of view. In the second argument, we consider the amounts {{of money in the}} two envelopes as being fixed; what varies is which one is first given to the player. Because that was an arbitrary and physical choice, the counterfactual world in which the player, counterfactually, got the other envelope to the one he was actually (factually) given is a highly meaningful counterfactual world and hence the comparison between gains and losses in the two worlds is meaningful. This comparison is uniquely indicated by the <b>problem</b> <b>description,</b> in which two amounts of money are put in the two envelopes first, and only after that is one chosen arbitrarily and given to the player. In the first argument, however, we consider the amount of money in the envelope first given to the player as fixed and consider the situations where the second envelope contains either half or twice that amount. This would only be a reasonable counterfactual world if in reality the envelopes had been filled as follows: first, some amount of money is placed in the specific envelope that will be given to the player; and secondly, by some arbitrary process, the other envelope is filled (arbitrarily or randomly) either with double or with half of that amount of money.|$|E
40|$|This article {{presents}} a class library for detecting typical performance problems in event traces of MPI applications. The library is implemented using the powerful high-level trace analysis language EARL and {{is embedded in}} the extensible tool component EXPERT described in this paper. One of EXPERT's essential features is a flexible plug-in mechanism which allows the user to easily integrate performance <b>problem</b> <b>descriptions</b> specific to a distinct parallel application without modifying the tool component...|$|R
40|$|The authors {{provide a}} method to {{systematically}} develop enterprise application architectures from <b>problem</b> <b>descriptions.</b> From these descriptions, they derive two kinds of specifications: a behavioral specification describes how the automated business process is carried out. It can be expressed using activity or sequence diagrams. A structural specification describes the classes to be implemented and the operations they provide. The structural specification is created in three steps. All the diagrams are expressed in UML...|$|R
40|$|An ambulatory-care patient-tracking {{system has}} been {{implemented}} that records non-categorical <b>problem</b> <b>descriptions</b> in the outpatient problem list. The system does not restrict physicians {{to the use of}} predefined diagnostic categories. Instead, the system stores patient problems in a database as free-text records. Subsequent diagnostic categorization and coding is accomplished through prompted free-text input and appropriate reference databases. This system design allows an outpatient problem-list summary to reflect non-categorical health-status information in addition to coded medical diagnoses...|$|R
50|$|After the bug is reproduced, {{the input}} of the program {{may need to be}} {{simplified}} {{to make it easier to}} debug. For example, a bug in a compiler can make it crash when parsing some large source file. However, after simplification of the test case, only few lines from the original source file can be sufficient to reproduce the same crash. Such simplification can be done manually, using a divide-and-conquer approach. The programmer will try to remove some parts of original test case and check if the problem still exists. When debugging the problem in a GUI, the programmer can try to skip some user interaction from the original <b>problem</b> <b>description</b> and check if remaining actions are sufficient for bugs to appear.|$|E
50|$|An abductive {{explanation}} {{of a problem}} G {{is a set of}} positive (and sometimes also negative) ground instances of the abducible predicates, such that, when these are added to the logic program P, the problem G and the integrity constraints IC both hold. Thus abductive explanations extend the logic program P by the addition of full or partial definitions of the abducible predicates. In this way, abductive explanations form solutions of the problem according to the description of the problem domain in P and IC. The extension or completion of the <b>problem</b> <b>description</b> given by the abductive explanations provides new information, hitherto not contained in the solution to the problem. Quality criteria to prefer one solution over another, often expressed via integrity constraints, can be applied to select specific abductive explanations of the problem G.|$|E
5000|$|In Russia, a {{group led}} by Yablonsky {{had the idea that}} {{combinatorial}} problems are hard in proportion to the amount of brute-force search required to find a solution. In particular, they noticed that for many problems they could not find a useful way to organize the space of potential solutions so as to avoid brute force search. They began to suspect that these problems had an inherently unorganized solution space, and the best method for solving them would require enumerating an exponential (in the size of the problem instance) number of potential solutions. That is, the problems seem to require [...] "shots in the dark" [...] (for some constant [...] ) when the length of the <b>problem</b> <b>description</b> is [...] However, despite their [...] "leading-edge" [...] taste in mathematics, Yablonsky's group never quite formulated this idea precisely.|$|E
40|$|The aim of {{this thesis}} is to {{translate}} selected chapters from the book "Letters" by Kurt Vonnegut, edited and with an introduction by Dan Wakefield, from English into Czech and to lay out {{an analysis of the}} source text and the translation. The theoretical part includes the source text analysis, typology of translation <b>problems,</b> <b>description</b> of the selected translation method and typology of translation shifts. Key words: annotated translation, translation analysis, translation problems, shifts, Kurt Vonnegut, correspondence, American literatur...|$|R
40|$|The present {{contribution}} discusses three related {{problems that}} combine task scheduling and personnel rostering. Common {{elements in the}} <b>problem</b> <b>descriptions</b> include qualification requirements {{and the need to}} assign all tasks. However, the scope of the decisions to be made differs. We first consider shift assignments to be fixed, then we consider only a single isolated day, and finally we consider a planning period of multiple days. Efficient algorithms for all problems are presented and evaluated. status: publishe...|$|R
40|$|One aim of {{intelligent}} tutoring systems is to tailor lessons to each individual student’s needs. To do this a tutoring system requires {{a model of}} the student’s knowledge. Cognitive modelling aims to produce a detailed explanation of the student’s progress. Feature Based Modelling forms a cognitive model of the student by creating aspects of <b>problem</b> <b>descriptions</b> and of students’ responses. This paper will discuss Feature Based Modelling and show the results of an evaluation carried out in the domain of elemental subtraction. ...|$|R
50|$|Software process {{simulation}} starts with identifying {{a question that}} we want to answer. The question could be, for example, related to assessment of an alternative, incorporating a new practice in the software development process. Introducing such changes in the actual development process will be expensive and if the consequences of change are not positive the implications can be dire for the organization. Thus, through the use of simulation we attempt to get an initial assessment of such changes on the model instead of an active development project. Based on this <b>problem</b> <b>description</b> an appropriate scope of the process is chosen. A simulation approach is chosen to model the development process. Such a model is then calibrated using empirical data and then used to conduct simulation based investigations. A detailed description of each step in general can be found in Balci's work, and in particular for software {{process simulation}} a comprehensive overview can be found in Ali et al.|$|E
5000|$|Byeong-Uk Yi (2009), on {{the other}} hand, argues that {{comparing}} the amount you would gain if you would gain by switching with the amount you would lose if you would lose by switching is a meaningless exercise from the outset. [...] According to his analysis, all three implications (switch, indifferent, do not switch) are incorrect. He analyses Smullyan's arguments in detail, showing that intermediate steps are being taken, and pinpointing exactly where an incorrect inference is made according to his formalization of counterfactual inference. An important difference with Chase's analysis {{is that he does}} not take account of the part of the story where we are told that the envelope called Envelope A is decided completely at random. Thus, Chase puts probability back into the <b>problem</b> <b>description</b> in order to conclude that arguments 1 and 3 are incorrect, argument 2 is correct, while Yi keeps [...] "two envelope problem without probability" [...] completely free of probability, and comes to the conclusion that there are no reasons to prefer any action. This corresponds to the view of Albers et al., that without probability ingredient, {{there is no way to}} argue that one action is better than another, anyway.|$|E
40|$|Conversational ease-based {{reasoning}} (CCBR) a form {{of interactive}} case-based reasoning where users input a partial <b>problem</b> <b>description</b> (in text). The CCBR system responds with ranked solution display, which lists the solutions of stored cases whose problem descriptions best match the user’s, and a ranked question display, which lists the unanswered questions in these cases. Users interact with these displays, ei-ther refining their <b>problem</b> <b>description</b> by answer-ing selected questions, or selecting a solution to apply. CCBR systems should support dialogue inferencing; they should infer answers to ques-tions that are implied by the <b>problem</b> <b>description...</b>|$|E
40|$|Heuristic {{search is}} a {{state-of-the-art}} approach to classical planning. Several heuristic families were {{developed over the}} years to automatically estimate goal distance information from <b>problem</b> <b>descriptions.</b> Orthogonally to the development of better heuristics, recent years have seen an increasing interest in symmetry-based state space pruning techniques that aim at reducing the search effort. However, little work has dealt with how the heuristics behave under symmetries. We investigate the symmetry properties of existing heuristics and reveal that many of them are invariant under symmetries...|$|R
40|$|The {{use of a}} bipolar donor-recipient {{model of}} medical {{technology}} transfer is presented. That methodology is designed to: (1) identify medical problems and aerospace technology that in combination constitute opportunities for successful medical products; (2) obtain the early participation of industry in the transfer process; and (3) obtain acceptance by the medical community of new medical products based on aerospace technology. <b>Problem</b> <b>descriptions</b> and activity reports {{and the results of}} a market study on the tissue freezing device are presented...|$|R
40|$|Relaxed {{models are}} {{abstract}} <b>problem</b> <b>descriptions</b> generated by ignoring constraints that {{are present in}} base-level problems. They {{play an important role}} in planning and search algorithms, as it has been shown that the length of an optimal solution to a relaxed model yields a monotone heuristic for an A ? search of a base-level problem. Optimal solutions to a relaxed model may be computed algorithmically or by search in a further relaxed model, leading to a search that explores a hierarchy of relaxed models...|$|R
