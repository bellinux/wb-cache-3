1062|152|Public
25|$|In {{the late}} 1980s Judea Pearl's text <b>Probabilistic</b> <b>Reasoning</b> in Intelligent Systems and Richard E. Neapolitan's text <b>Probabilistic</b> <b>Reasoning</b> in Expert Systems {{summarized}} {{the properties of}} Bayesian networks and established Bayesian networks as a field of study.|$|E
25|$|Mark Colyvan, Jay Garfield and Graham Priest (2005) {{have argued}} that a theistic {{explanation}} for fine tuning is faulted due to fallacious <b>probabilistic</b> <b>reasoning.</b>|$|E
25|$|And {{even if the}} <b>probabilistic</b> <b>reasoning</b> were rigorous, {{this would}} still imply only that the {{conjecture}} is almost surely true for any given integer, which does not necessarily imply that it is true for all integers.|$|E
5000|$|<b>Probabilistic</b> (Bayesian) <b>reasoning</b> for concept {{recognition}} {{with the}} model of observation.|$|R
40|$|This paper proposes <b>probabilistic</b> default <b>reasoning</b> as a {{suitable}} approach to inheritance and recognition in uncertain and fuzzy object-oriented models. Firstly, we introduce an uncertain and fuzzy object-oriented model where a class property (i. e., an atu'ibute or a method) can contain fuzzy sets interpreted as families of probability distributions, and uncertain class membership and property applicability are measured by lower and upper bounds on probability. Each uncertainly applicable property is {{interpreted as a}} default probabilistic logic rule, which is defeasible. In {{order to reduce the}} computational complexity of general <b>probabilistic</b> default <b>reasoning,</b> we propose to use Jeffrey's rule for a weaker notion of consistency and for local inference, then apply them to uncertain inheritance of properties. Using the same approach but with inverse Jeffrey's rule, uncertain recognition as <b>probabilistic</b> default <b>reasoning</b> is also presented. The approach is illustrated by an example in Fril++, the uncertain and fuzzy object-oriented logic programming language that we have been developing...|$|R
50|$|<b>Probabilistic</b> abductive <b>reasoning</b> {{is a form}} of abductive validation, and is used {{extensively}} in areas where conclusions about possible hypotheses need to be derived, such as for making diagnoses from medical tests.|$|R
2500|$|Nickerson, Raymond (2004). Cognition and Chance: The {{psychology}} of <b>probabilistic</b> <b>reasoning,</b> Lawrence Erlbaum. Ch. 5, [...] "Some instructive problems: Three cards", pp.157160.|$|E
50|$|In {{the late}} 1980s Judea Pearl's text <b>Probabilistic</b> <b>Reasoning</b> in Intelligent Systems and Richard E. Neapolitan's text <b>Probabilistic</b> <b>Reasoning</b> in Expert Systems {{summarized}} {{the properties of}} Bayesian networks and established Bayesian networks as a field of study.|$|E
50|$|<b>Probabilistic</b> <b>reasoning</b> is a {{foundational}} {{technology of}} machine learning. It {{is used by}} companies such as Google, Amazon.com and Microsoft. <b>Probabilistic</b> <b>reasoning</b> {{has been used for}} predicting stock prices, recommending movies, diagnosing computers, detecting cyber intrusions and image detection.|$|E
50|$|In {{intelligence}} analysis, {{analysis of}} competing hypotheses and Bayesian networks, <b>probabilistic</b> abductive <b>reasoning</b> is used extensively. Similarly in medical diagnosis and legal reasoning, the same methods are being used, {{although there have}} been many examples of errors, especially caused by the base rate fallacy and the prosecutor's fallacy.|$|R
40|$|Probabilistic logic {{programs}} (PLPs) [NS 92] {{have been}} proposed as a paradigm for <b>probabilistic</b> logical <b>reasoning</b> with no independence assumptions. PLPs used a possible worlds model based on prior work by [Hai 84], [FHM 90], and [Nil 86] to induce a set of probability distributions on a space of possible worlds. Pas...|$|R
40|$|This paper {{presents}} TraumaSCAN, {{a prototype}} computer system {{for assessing the}} effects of penetrating trauma to the chest and abdomen. TraumaSCAN combines geometric reasoning about potentially injured anatomic structures with (<b>probabilistic)</b> diagnostic <b>reasoning</b> {{about the consequences of}} these injuries. We also present results obtained from testing TraumaSCAN retrospectively on 26 actual gunshot wound cases...|$|R
5000|$|<b>Probabilistic</b> <b>Reasoning</b> in Intelligent Systems, Morgan-Kaufmann, 1988 ...|$|E
5000|$|... #Subtitle level 3: Activity {{recognition}} through <b>probabilistic</b> <b>reasoning</b> ...|$|E
50|$|Probabilistic {{programming}} creates {{systems that}} help make {{decisions in the}} face of uncertainty. <b>Probabilistic</b> <b>reasoning</b> combines knowledge of a situation with the laws of probability. Until recently, <b>probabilistic</b> <b>reasoning</b> systems have been limited in scope, and have not successfully addressed real world situations. Probabilistic programming is a new approach that makes <b>probabilistic</b> <b>reasoning</b> systems easier to build and more widely applicable. Reasoning about variables as probability distributions causes difficulties for novice programmers, but these difficulties can be addressed through use of Bayesian network visualisations and graphs of variable distributions embedded within the source code editor.|$|E
40|$|<b>Probabilistic</b> {{and logical}} <b>reasoning</b> are the {{cornerstones}} of many developments in artificial intelligence. Over the past 20 years, {{there has been a}} lot of attention to combining these two forms of reasoning. This has resulted in a rich variety of representations, languages and systems for dealing with <b>probabilistic</b> logical <b>reasoning.</b> These approaches have also been applied in machine learning context. In the first part of this talk, I shall provide a gentle introduction to such logics using ProbLog and ProPPR. In the second part, I shall illustrate their use and promise on two challenging applications : in bioinformatics and in recommender systems. The first is based on ongoing work in Leuven with Dries Van Daele, the second on ongoing work with Sirawit Sopchoke and Prof. Masayuki Numao from ISIR, Osaka. status: publishe...|$|R
40|$|The aim of {{the present}} is to {{ascertain}} the impact of both cognitive and non-cognitive factors on <b>probabilistic</b> and statistics <b>reasoning</b> in psychology students enrolled in introductory statistics courses. It was hypothesised that performance {{was related to the}} studentâ€™s general and mathematical background (cognitive factors), math self-efficacy and attitudes toward statistics (non-cognitive factors). A structural equation model was specified in which cognitive and noncognitive factors were considered as the exogenous latent variables having an impact on both <b>probabilistic</b> and statistics <b>reasoning.</b> Results stressed the role of both cognitive and non cognitive factors suggesting that competence as well as attitudes and self-efficacy should be the focus in planning interventions to help students in increasing performance...|$|R
40|$|We present {{probabilistic}} {{logic programming}} under inheritance with overriding. This approach {{is based on}} new notions of entailment for reasoning with conditional constraints, which are obtained from the classical notion of logical entailment by adding inheritance with overriding. This is done by using recent approaches to <b>probabilistic</b> default <b>reasoning</b> with conditional constraints. We analyze the semantic properties of the new entailment relations. We also present algorithms for probabilistic logic programming under inheritance with overriding, and we analyze its complexity in the propositional case. ...|$|R
5000|$|Probability and <b>Probabilistic</b> <b>Reasoning</b> for Electrical Engineering, Pearson/Prentice-Hall, 2006.|$|E
5000|$|An {{implementation}} of a <b>probabilistic</b> <b>reasoning</b> engine based on probabilistic logic networks (PLN).|$|E
50|$|In 2007, Krivelevich and Alan Frieze won the Pazy Memorial Award for {{research}} into <b>probabilistic</b> <b>reasoning</b> in combinatorics.|$|E
40|$|We {{present an}} {{implementation}} of a probabilistic first-order logic called TensorLog, in which classes of logical queries are compiled into differentiable functions in a neural-network infrastructure such as Tensorflow or Theano. This leads to a close integration of <b>probabilistic</b> logical <b>reasoning</b> with deep-learning infrastructure: in particular, it enables high-performance deep learning frameworks {{to be used for}} tuning the parameters of a probabilistic logic. Experimental results show that TensorLog scales to problems involving hundreds of thousands of knowledge-base triples {{and tens of thousands of}} examples...|$|R
40|$|Abstract. This paper proposes assumption-based {{systems as}} an {{efficient}} and convenient way to encode uncertain information. Assumptionbased systems are obtained from propositional logic by including a special type of propositional symbol called assumption. Assumptions {{are needed to}} express {{the uncertainty of the}} given information. Assumptionbased systems can be used to judge hypotheses qualitatively or quantitatively. This paper shows how assumption-based systems are obtained from causal networks, it describes how symbolic arguments for hypotheses can be computed efficiently, and it presents ABEL, a modeling language for assumption-based systems and an interactive tool for <b>probabilistic</b> assumption-based <b>reasoning.</b> ...|$|R
40|$|Abstract. This paper {{describes}} a <b>probabilistic</b> logic <b>reasoning</b> system for traffic scenes based on Markov logic network, whose {{goal is to}} provide a high-level interpretation of localisation and behaviour of a vehicle on the road. This information can be used by a lane assistant agent within driver assistance systems. This work adopted an egocentric viewpoint for the vision and the reasoning tasks of the vehicle and a qualitative approach to spatial representation. Results with real data indicate good performance compared to the common sense interpretation of traffic sit-uations. ...|$|R
50|$|Mark Colyvan, Jay Garfield and Graham Priest (2005) {{have argued}} that a theistic {{explanation}} for fine tuning is faulted due to fallacious <b>probabilistic</b> <b>reasoning.</b>|$|E
50|$|The {{principal}} {{constituents of}} Soft Computing (SC) are Fuzzy Logic (FL), Evolutionary Computation (EC), Machine Learning (ML) and <b>Probabilistic</b> <b>Reasoning</b> (PR), {{with the latter}} subsuming belief networks and parts of learning theory.|$|E
50|$|Polytrees {{have been}} used as a {{graphical}} model for <b>probabilistic</b> <b>reasoning.</b> If a Bayesian network has the structure of a polytree, then belief propagation may be used to perform inference efficiently on it.|$|E
40|$|In {{this paper}} we study a {{probabilistic}} logic {{based on the}} notion of coherence of de Finetti. We first recall the notion of coherence for precise conditional probability assessments, then we consider its generalization to the case of imprecise assessments. We examine conditional probabilistic knowledge bases associated with imprecise probability assessments defined on arbitrary families of conditional events. In our probabilistic logic the notion of probabilistic interpretation is directly defined in terms of precise conditional probability assessments. Then, we give in our approach new proofs of some results obtained in <b>probabilistic</b> default <b>reasoning...</b>|$|R
40|$|Summary. The authors {{previous}} work on <b>probabilistic</b> constraint <b>reasoning</b> assumes {{the uncertainty of}} numerical variables within given bounds, characterized by a priori probability distributions. It propagates such knowledge through a network of constraints, reducing the uncertainty and providing a posteriori probability distributions. An inverse problem aims at estimating parameters from observed data, based on some underlying theory about a system behavior. This paper describes how nonlinear inverse problems can be cast into the probabilistic constraint framework, highlighting its {{ability to deal with}} all the uncertainty aspects of such problems. ...|$|R
40|$|The role of <b>probabilistic</b> and {{statistical}} <b>reasoning</b> in two murder trials in England is described. Sug-gestions are made {{as to what}} is required of statisticians who wish to become involved in the judi-cial process and {{as to what is}} required of lawyers who wish to present probabilistic ideas into the courtroom...|$|R
50|$|And {{even if the}} <b>probabilistic</b> <b>reasoning</b> were rigorous, {{this would}} still imply only that the {{conjecture}} is almost surely true for any given integer, which does not necessarily imply that it is true for all integers.|$|E
50|$|Probabilistic soft logic (PSL) is a {{framework}} for collective, <b>probabilistic</b> <b>reasoning</b> in relational domains. PSL uses first order logic rules as a template language for graphical models over random variables with soft truth values from the interval 0,1.|$|E
5000|$|Uncertainty: These are precise {{concepts}} with uncertain values. For example, {{a patient}} might present {{a set of}} symptoms that correspond {{to a number of}} different distinct diagnoses each with a different probability. <b>Probabilistic</b> <b>reasoning</b> techniques are generally employed to address uncertainty.|$|E
40|$|This paper {{introduces}} a self-training automatic algorithm selection {{system based on}} experimental methods and <b>probabilistic</b> learning and <b>reasoning</b> techniques. The system aims to select the most appropriate algorithm according to {{the characteristics of the}} input problem instance. The general methodology is described, the system framework is presented, and key research problems are identified...|$|R
40|$|Abduction is {{inference}} to {{the best}} explanation of a given set of evidence. It is important for plan or intent recognition systems. Traditional approaches to abductive reasoning have either used first-order logic, which is unable to reason under uncertainty, or Bayesian networks, which can handle uncertainty using probabilities but cannot directly handle an unbounded number of related entities. This paper proposes a new method for <b>probabilistic</b> abductive <b>reasoning</b> that combines the capabilities of first-order logic and graphical models by using Markov logic networks. Experimental results on a plan recognition task demonstrate {{the effectiveness of this}} method. ...|$|R
40|$|We present {{probabilistic}} {{logic programming}} under inheritance with overriding. This approach {{is based on}} new notions of entailment for reasoning with conditional constraints, which are obtained from the classical notion of logical entailment by adding the principle of inheritance with overriding. This is done by using recent approaches to <b>probabilistic</b> default <b>reasoning</b> with conditional constraints. We analyze the semantic properties of the new entailment relations. We also present algorithms for probabilistic logic programming under inheritance with overriding, and program transformations for an increased efficiency. Comment: Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI 2001...|$|R
