7|10000|Public
2500|$|On October 2, 1968, a mouse device named [...] (German for [...] "rolling ball") was {{described}} as an optional device for its SIG-100 terminal {{was developed by the}} German company Telefunken. As the name suggests and unlike Engelbart's mouse, the Telefunken model already had a ball. It was based on an earlier trackball-like device (also named [...] ) that was embedded into radar flight control desks. This trackball had been developed by a team led by Rainer Mallebrein at Telefunken [...] for the German Bundesanstalt für Flugsicherung as part of their TR86 <b>process</b> <b>computer</b> <b>system</b> with its SIG100-86 vector graphics terminal.|$|E
40|$|We have {{developed}} the <b>process</b> <b>computer</b> <b>system</b> with Linux operating system and relational database, {{which leads to the}} drastic decrease of the costs for the hardware and the software compared to the conventional systems. The system has been applied to the blast furnace process and working effectively without any troubles. 1...|$|E
40|$|In {{the renewal}} of old <b>process</b> <b>computer</b> <b>system</b> of the {{continuous}} casting plant, Nippon Steel Corporation has attained cost reduction {{by the introduction of}} general-purpose PC server and OS, and middleware (NS SEMI SYSTEM) originally developed in the activity of open system solution. Also the adopting general purpose RDB to the continuous casting plant has been realized in the first time. The reduction of cost and period in AP software development has been achieved by the program code generator tool originally developed. 1...|$|E
40|$|Technical {{systems are}} {{becoming}} more and more complex due to increasing demands, nevertheless they have to be of high reliability and good maintenability. This is especially true for multi <b>process</b> <b>computer</b> <b>systems.</b> Availability and reliability cannot be reached by means of perfection, fault-tolerance has to be added. With the RDC-Process <b>Computer</b> <b>System</b> a fault-tolerant system is presented, which allows full performance of all computer components (with different tasks) being in the normal state and with high system availability by means of dynamical functional redundancy, fault diagnosis (error detection and error location) and automatic reconfiguration...|$|R
5000|$|Method and {{apparatus}} {{for testing}} a <b>process</b> in a <b>computer</b> <b>system</b> - (Jul 15, 2003) ...|$|R
50|$|Self-Management is the <b>process</b> {{by which}} <b>computer</b> <b>systems</b> shall {{manage their own}} {{operation}} without human intervention. Self-Management technologies are expected to pervade {{the next generation of}} network management systems.|$|R
40|$|In today’s scenario, {{most of the}} {{organizations}} provide the services through the web. This makes the web service an important research area. In addition, early design and building web services, {{it is necessary to}} concentrate on the quality of web services. Performance is an important quality attributes that to be considered during the designing of web services. The expected performance can be achieved by proper scheduling of resources and scalability of the system. Scalability is a desirable attribute of a <b>process</b> <b>computer</b> <b>system</b> or network. Poor scalability can result in lacking system performance. Hence, in this paper, we have reviewed the literature available for the quality attributes of performance and scalability and identified the issues that affect the quality attributes related to Web Services...|$|E
40|$|In {{order to}} reduce the wear of the tool edge and to reduce the costs of manufacturing, set-up {{conditions}} in milling and circular sawing of wooden materials have been optimized. In the frame of this work an on-line device for measuring the edge roughness of wooden materials at machining has been developed. A <b>process</b> <b>computer</b> <b>system</b> has been built, and the software for measuring and control has been implemented. On the basis of an established mathematical model a computer program for the process control has been written and tested. The construction of a device for laser optical tool edge wear control is in progressSIGLEAvailable from TIB Hannover: FR 6584 / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDeutsche Forschungsgemeinschaft (DFG), Bonn (Germany) DEGerman...|$|E
40|$|A digital {{signature}} is a cryptographic method for verifying {{the identity of}} an individual. It can be a <b>process,</b> <b>computer</b> <b>system,</b> or any other entity, {{in much the same}} way as a handwritten signature verifies the identity of a person. Digital signatures use the properties of public-key cryptography to produce pieces of information that verify the origin of the data. Several digital schemes have been proposed as on date based on factorization, discrete logarithm and elliptical curve. However, the Swati Verma and Birendra Kumar Sharma [8] {{digital signature}} scheme which combines factorization and discrete logarithm together making it difficult for solving two hard problems from the hackers point of view. This paper presents the implementation of same, with the help of different tools and further analyzes them from different perceptions...|$|E
50|$|Computer software, {{or simply}} software, {{is a part}} of a <b>computer</b> <b>system</b> that {{consists}} of data or computer instructions, in contrast to the physical hardware from which the system is built. In computer science and software engineering, computer software is all information <b>processed</b> by <b>computer</b> <b>systems,</b> programs and data. Computer software includes computer programs, libraries and related non-executable data, such as online documentation or digital media. Computer hardware and software require each other and neither can be realistically used on its own.|$|R
50|$|Cache invalidation is a <b>process</b> in a <b>computer</b> <b>system</b> whereby {{entries in}} a cache are {{replaced}} or removed. It {{can be done}} explicitly, {{as part of a}} cache coherence protocol. In such a case, a processor changes a memory location and then invalidates the cached values of that memory location across the rest of the <b>computer</b> <b>system.</b>|$|R
40|$|As legal {{information}} is <b>processed</b> by <b>computer</b> <b>systems,</b> computation is increasingly {{contributing to the}} functioning of legal systems. Consequently, legal informatics has a large role to play, providing theories and models supporting computable law, as well as critical reflections on it. Indeed, in recent decades research on legal informatics has expanded to address multiple operations and aspects of the law, including text retrieval, virtual documents, the deductive derivation of legal conclusions, conceptual structures, argumentation, case-based reasoning, interpretation, dialogues, theory construction, adaptive attitudes, and institutions...|$|R
40|$|Abstract: The various {{questions}} of creation of {{integrated development environment}} for <b>computer</b> training <b>systems</b> are considered in the given paper. The information technologies {{that can be used}} for creation of the integrated development environment are described. The different didactic aspects of realization of such systems are analyzed. The ways to improve the efficiency and quality of learning <b>process</b> with <b>computer</b> training <b>systems</b> for distance education are pointe...|$|R
50|$|Hoare's most {{significant}} {{work has been}} in the following areas: his sorting and selection algorithm (Quicksort and Quickselect), Hoare logic, the formal language Communicating Sequential Processes (CSP) used to specify the interactions between concurrent <b>processes,</b> structuring <b>computer</b> operating <b>systems</b> using the monitor concept, and the axiomatic specification of programming languages.|$|R
40|$|Key {{developments}} of instrumentation, control and automation (ICA) applications in wastewater systems {{during the past}} 40 years are highlighted in this paper. From the first ICA conference in 1973 through to today {{there has been a}} tremendous increase in the understanding of the <b>processes,</b> instrumentation, <b>computer</b> <b>systems</b> and control theory. However, many developments have not been addressed here, such as sewer control, drinking water treatment and water distribution control. It is hoped that this review can stimulate new attempts to more effectively apply control and automation in water systems in the coming years...|$|R
40|$|Life long {{learning}} is essential today. To support learner {{as well as}} the teacher in this learning <b>process</b> by <b>computer</b> <b>systems</b> is a logical consequence. This paper describes the new approach in keeping the learning history, by getting and storing the data of the learning history or learning profile. It tries to show the conclusions that can be drawn out of the learning history. Afterwards it is shown what the next steps in learning system design are and what potential the learning history has, when it is used in the best way...|$|R
40|$|The {{use of the}} <b>Process</b> Monitoring <b>Computer</b> <b>System</b> (PMCS) at the Idaho Chemical Processing Plant (ICPP) {{relating}} to Operations and Safeguards concerns is discussed. Measures taken to assure {{the reliability of the}} system data are outlined along with the measures taken to assure the continuous availability of that data for use within the ICPP. The integration of process and safeguards information for use by the differing organizations is discussed. The PMCS successfully demonstrates the idea of remote Safeguards surveillance and the need for sharing of common information between different support organizations in an operating plant...|$|R
40|$|The {{fundamental}} {{challenge of}} e-commerce is enabling companies {{to do business}} with one another across a network, despite different business <b>processes</b> and <b>computer</b> <b>systems.</b> Traditionally, these problems were overcome through custom point-to-point integration or Electronic Data Interchange (EDI) networks. These expensive, time-consuming approaches make economic sense only when companies do a lot of business together. The promise of the Internet, by contrast, is an open e-business platform where companies can do business spontaneously with anyone, anywhere, anytime. Business Services Networks fulfill that vision. This vision paper also presents CommerceNet’s role in catalyzing industrial adoption. 1...|$|R
50|$|In writing {{structured}} {{documents the}} focus is on encoding the logical structure of a document, with no explicit concern in the structural markup for its presentation to humans by printed pages, screens or other means. Structured documents, especially well formed ones, can easily be <b>processed</b> by <b>computer</b> <b>systems</b> to extract and present metadata about the document. In most Wikipedia articles for example, a table of contents is automatically generated from the different heading tags {{in the body of the}} document. Popular word processors can have such a function available.|$|R
40|$|INTRODUCTION Computer {{scientists}} {{should have}} a knowledge of abstract statistical thermodynamics. First, <b>computer</b> <b>systems</b> are dynamical systems, much like physical systems, and therefore {{an important first step}} in their characterization is in finding properties and parameters that are constant over time (i. e., constants of motion). Second, statistical thermodynamics successfully reduces macroscopic properties of a system to the statistical behavior of large numbers of microscopic <b>processes.</b> As <b>computer</b> <b>systems</b> become large assemblages of small components, an explanation of their macroscopic behavior may also be obtained as the aggregate statistical behavior of its component parts. If not, the elegance of the statistical thermodynamical approach can at least provide inspiration for new classes of models. 1 Third, the components of <b>computer</b> <b>systems</b> are approaching {{the same size as the}} microscopic p...|$|R
40|$|The {{peculiarities of}} open source, free and closed {{commercial}} software in research work and teaching <b>process</b> of the <b>Computer</b> <b>Systems</b> and Networks department of Ternopil Ivan Pul’uj National Technical University are analyzed. The basic constraints of open source software, {{and examples of}} successful implementation of open source software are submitted. The main advantages of using open source software for teaching specialists according the specialty <b>computer</b> <b>systems</b> and networks and in the scientific research projects are analyzed...|$|R
40|$|This paper {{provides}} {{useful information}} to build availability models for <b>computer</b> <b>systems</b> used in airspace control centers, based on analytical models provided by queuing theories. A general model is first presented, referencing a published case study, where the authors described {{the use of}} queuing models to establish availability parameters related to a data center operation and its management issues. In addition, some considerations are introduced to extend this general model in order to propose its application for the specific <b>computer</b> <b>systems</b> used in integrated airspace control centers, where operational control could depend on human controllers, responsible for civil air traffic control or military air defense operations. This model could also be applicable where process controls require intensive use of human-machine interfaces (HMI). From this study, further extensions could be also developed, intended to similar applications on other specific cases of <b>process</b> control <b>computer</b> <b>systems...</b>|$|R
40|$|CERN Accelerators and Services have an {{existing}} large investment in control networks, fieldbuses, front-end <b>process</b> <b>computers,</b> workstations, <b>system</b> {{software and application}} programs. Increasingly, industrial equipment and complete Distributed Control Systems (DCS) are being installed to rejuvenate old and obsolete systems and new projects for LHC are taking shape. The object {{of this paper is}} to report experience of CERNs control engineers on integration of industrial equipment and systems. Several projects are described covering a vast area of applications. The paper presents several interfacing issues such as network connection of industrial equipment, software integration, homogeneous equipment access and alarm retrieval compatible with the existing Accelerators and Services Control System...|$|R
40|$|Exceptions, {{situations}} that cannot be correctly <b>processed</b> by <b>computer</b> <b>systems,</b> occur frequently in computer-based information processes. Five perspectives on exceptions provide insights into why exceptions occur {{and how they}} might be eliminated or more efficiently handled. We investigate these perspectives using an in-depth study of an operating information process that has frequent exceptions. Our results {{support the use of}} a total quality management (TQM) approach of eliminating exceptions for some exceptions, in particular, those caused by <b>computer</b> <b>systems</b> that are poor matches to organizational processes. However, some exceptions are explained better by a political system perspective of conflicting goals between subunits. For these exceptions and several other types, designing an integrated human-computer process will provide better performance than will eliminating exceptions and moving toward an entirely automated process...|$|R
40|$|The present {{research}} {{work has been}} carried out to show the benefits of the use of the COBIT system in the auditing <b>processes</b> of the <b>computer</b> <b>systems,</b> the problem is related to: How does it affect the process of audits in the institutions, use of the COBIT system? The main objective is to identify the incidence of the use of the COBIT system in the auditing <b>process</b> used by <b>computer</b> <b>systems</b> within both public and private organizations; In order to achieve our stated objectives of the research will be developed first with the conceptualization of key terms for an easy understanding of the subject, as a conclusion: we can say the COBIT system allows to identify the methodology by using information from the IT departments, to determine the resources of the (IT) Information Technology, specified in the COBIT system, such as files, programs, computer networks, including personnel that use or manipulate the information, with the purpose of providing information that the organization or company requires to achieve its objectives...|$|R
40|$|Abstract. Brower based system {{provides}} a regular mechanism to reflect real world human browser-based systems. Supply chains are {{the network of}} corporation including a variety of human browser-based in connected but different <b>processes.</b> Browser-based <b>computer</b> <b>systems</b> can help and replace human-based interaction and decide in the supply chain, {{but there is no}} need to focus on heavy or top-down management plans. The Task Based on Browser (TPBB) construction uses techniques inspired by both human institutions and insect colonies. The probability density over time the ability to use the allocation of resources is committed to providing an agent for these surfaces can be a stroll in looking for opportunities to optimize...|$|R
40|$|In {{information}} systems development and usage the correspondence between concepts used at business level and data structures <b>processed</b> at <b>computer</b> <b>systems</b> level {{is to be}} established and maintained. The complexity of this task depends on enterprise and {{information systems}} architectures that underlie a particular information system as well as dynamic properties of information systems envi-ronment. In cases of heterogeneous domain ontologies and complex enterprise and information systems architectures the fractal approach to information systems de-sign can support a balanced change propagation from business domain to com-puter systems domain that, in turn, allows to define and maintain a flexible infor-mation architecture that supports business goals and processes...|$|R
40|$|The early {{phase of}} the design process is a {{seemingly}} chaotic, complex process, involving many methods and representations. In supporting this <b>process,</b> a <b>computer</b> <b>system</b> that can follow the architect in his/her actions may be helpful. Such a system should assist architects in maintaining {{an overview of the}} development of their ideas over time, show {{the current state of the}} process, and support and stimulate the generation of new associations whenever required. This paper will discuss the rich information structure in the design process and cognitive processes handling this structure. Further there will be a discussion on the features of a system that can handle this rich information...|$|R
40|$|Early {{verification}} of {{the adequacy of}} fault tolerance mechanisms, and the subsequent removal of fault tolerance deficiency faults (ftd-faults), are essential tasks in the design <b>process</b> of dependable <b>computer</b> <b>systems.</b> The paper is centred on the description and application of the new features of MEFISTO-L, the fault injection tool for VHDL models, being developed at LAAS for supporting the strategy that we have proposed for testing fault tolerance mechanisms. The paper firs...|$|R
40|$|Abstract: The {{proposed}} method allows {{determining the}} level of wear of the bearings of electric machines by means of rotor radial displacement during operation. Measurement is effected by non-contact method and optoelectronic sensor which converts the rotor mechanical motion into electric signal. Received informational signal is recorded and <b>processed</b> by <b>computer</b> <b>system.</b> Based on the processed input signal it is possible by means of mathematical algorithm to calculate the amplitude of rotor angular vibration. Then the revolution and the inherent vibration frequency of the rotor are compared followed by estimation {{the level of}} bearings wear. This evaluation {{can be used to}} forecast the residual operation margine of the machine. Keywords:; vibration,measurement, electrical machines, diagnostic,rotor, optoelectronic sensors I...|$|R
40|$|This article {{states that}} the {{development}} <b>process</b> of <b>computer</b> <b>systems</b> for task support of planning and scheduling is no unique activity that must be performed from scratch each time. Reuse of previously created conceptual and technical products is possible. We claim that adequate computer support starts with a task analysis. This analysis reveals general as well as unique aspects. The general aspects can in principle be reused. However, a taxonomy is necessary that separates general from unique aspects in the problem domain and task performance. We propose the Scheduling Expertise Concept (SEC) as such a concept for planning and scheduling tasks. This taxonomy is implemented in a <b>computer</b> <b>system,</b> the SEC-system. The SEC-model and SEC-system enable faster and more accurate development processes in the planning and scheduling domain. Reuse of conceptual and technical information that is obtained during the development process of software gains increased attention (van Genuchten...|$|R
40|$|The {{development}} <b>process</b> of <b>computer</b> <b>systems</b> for task {{support of}} planning and scheduling is not a unique activity that must be performed from scratch each time. Reuse of previously created conceptual and technical products is possible and recommendable. We claim that adequate computer support starts with a (cognitive) task analysis which reveals general as well as unique aspects. The general aspects can be reused. However, a conceptual framework is necessary that separates general from unique aspects in the task domain and task performance. We propose the Scheduling Expertise Concept (SEC) as such a framework for planning and scheduling. The framework is domain independent and takes into account organisational and task performance characteristics. This generic framework is implemented in a <b>computer</b> <b>system,</b> the SEC-system. The SEC-models and SEC-system enable faster development processes in the planning and scheduling domain. (C) 1999 Elsevier Science B. V. All rights reserved...|$|R
40|$|Abstract. According to the user’s high {{technical}} requirement in papermaking process, advanced control {{system has been}} supplied to satisfy the performances. Meanwhile, energy consumption and cost are considered. The <b>computer</b> integrated <b>process</b> <b>system</b> (CIPS) of process industry which could effectively integrate enterprise resource planning, management execution system and process control system information is necessary and suitable for papermaking process. Here based on the analysis of pulp and paper process, we put forward the papermaking <b>process</b> <b>computer</b> integrated <b>process</b> <b>system</b> and try to obtain the optimal control project and execution system. And a novel optimized application project based on SIMATIC PCS 7 distributed control system proves the excellence of <b>computer</b> integrated <b>process</b> <b>system...</b>|$|R
40|$|Software processes, their {{modeling}} and execution (or enactment) {{continue to be}} an active research area worldwide. A {{great deal of the}} work has been invested in devising improved process model formalisms for expressing various aspects of a software process. However, since process models have so many different uses (e. g., to understand or analyze a process or enact a <b>process</b> with a <b>computer</b> <b>system),</b> we feel that even today no single model formalism is good enough for all purposes. In t [...] ...|$|R
40|$|Approved {{for public}} release, {{distribution}} is unlimitedThis thesis attempts {{to document the}} events environment, decisions, and personnel involved in the development, implementation and life cycle management of a computer software application. The computer application is developed using a prototyping methodology and a third generation software language for a Department of the Navy Headquarters Command. The data are presented in a case study format and are analyzed in accordance with software life cycle development principles and change management principles. The case methodology was considered the most applicable tool to showcase the complexity of decisions and <b>processes</b> of <b>computer</b> <b>systems</b> management. The case studies demonstrate the importance of adhering to proven software development principles throughout the life cycle management of a computer application. Lieutenant, United States Nav...|$|R
40|$|The {{automation}} of {{a discrete}} production process is difficult due {{to at least}} the following reasons: individuality of the work pieces with complex transportation demands and needs for quick repair of faults in the production system. A solution is described which allows qualitative instead of quantitative progress of automation and works "information-oriented" instead of "signal-oriented". The automation system contains a distributed, bus-coupled, fault-tolerant <b>process</b> control <b>computer</b> <b>system</b> for extensive decentralized data collection and extensive centralized data evaluation {{by the use of}} the real-time data base systems BAPAS-DB as well as the computer-driven colour screen system EAF-P 2 A for centralized monitoring and control of the distribution production process. As a prospect an integrated system for production automation is outlined. (IITB...|$|R
