289|10000|Public
5000|$|Modern {{architectures}} typically {{allow for}} {{many hundreds of}} different kinds of peephole optimizations, and it is therefore often appropriate for compiler programmers to implement them using a <b>pattern</b> <b>matching</b> <b>algorithm.</b>|$|E
5000|$|The Rete {{algorithm}} ( [...] or [...] , rarely [...] or [...] ) is a <b>pattern</b> <b>matching</b> <b>algorithm</b> {{for implementing}} production rule systems. It {{is used to}} determine which of the system's rules should fire based on its data store.|$|E
5000|$|To {{decide which}} rule should [...] "fire" [...] {{on a given}} {{constraint}} store, a CHR implementation must use some <b>pattern</b> <b>matching</b> <b>algorithm.</b> Candidate algorithms include RETE and TREATS, but most implementation use a lazy algorithm called LEAPS.|$|E
40|$|The {{preliminary}} {{research in}} the area of applications of neural networks and <b>pattern</b> <b>matching</b> <b>algorithms</b> in species classification is presented. Artificial neural networks for classification and different <b>pattern</b> <b>matching</b> <b>algorithms</b> for <b>matching</b> the given DNA patterns or strings with the existing DNA sequences available in the databases are specifically studied. A set of local searching algorithms were experimented for different test string lengths and their time complexity is tabulated. Conclusions and future directions are also presented...|$|R
40|$|Abstract: With the {{remarkable}} {{increase in the}} number of DNA and proteins sequences, it is very important to study the performance of multiple <b>pattern</b> <b>matching</b> <b>algorithms</b> when querying sequence patterns in biological se-quence databases. In this paper, we present a performance study of the running time of well known multiple <b>pattern</b> <b>matching</b> <b>algorithms</b> on widely used biological sequence databases containing the building blocks of nucleotides (in the case of nucleic acid sequence databases) and amino acids (in the case of protein sequence databases). ...|$|R
40|$|We {{propose a}} {{framework}} for the exact probabilistic analysis of window-based <b>pattern</b> <b>matching</b> <b>algorithms,</b> such as Boyer–Moore, Horspool, Backward DAWG Matching, Backward Oracle Matching, and more. In particular, we develop an algorithm that efficiently computes the distribution of a <b>pattern</b> <b>matching</b> <b>algorithm’s</b> running time cost (such {{as the number of}} text character accesses) for any given pattern in a random text model. Text models range from simple uniform models to higher-order Markov models or hidden Markov models (HMMs). Furthermore, we provide an algorithm to compute the exact distribution of differences in running time cost of two <b>pattern</b> <b>matching</b> <b>algorithms.</b> Methodologically, we use extensions of finite automata which we call deterministic arithmetic automata (DAAs) and probabilistic arithmetic automata (PAAs) [1]. Given an algorithm, a pattern, and a text model, a PAA is constructed from which the sought distributions can be derived using dynamic programming. To our knowledge, {{this is the first time}} that substring- or suffix-based <b>pattern</b> <b>matching</b> <b>algorithms</b> are analyzed exactly by computing the whole distribution of running time cost. Experimentally, we compare Horspool’s <b>algorithm,</b> Backward DAWG <b>Matching,</b> and Backward Oracle <b>Matching</b> on prototypical <b>patterns</b> of short length and provide statistics on the size of minimal DAAs for these computations...|$|R
5000|$|Production {{systems may}} vary on the {{expressive}} power of conditions in production rules. Accordingly, the <b>pattern</b> <b>matching</b> <b>algorithm</b> which collects production rules with matched conditions may {{range from the}} naive—trying all rules in sequence, stopping at the first match—to the optimized, in which rules are [...] "compiled" [...] into a network of inter-related conditions.|$|E
50|$|Pratt was an Assistant Professor at MIT (1972 to 1976) {{and then}} Associate Professor (1976 to 1982). In 1974, working in {{collaboration}} with Knuth and Morris, Pratt completed and formalized work he had begun in 1970 {{as a graduate student}} at Berkeley; the coauthored result was the Knuth-Morris-Pratt <b>pattern</b> <b>matching</b> <b>algorithm.</b> In 1976, he developed the system of dynamic logic, a modal logic of structured behavior.|$|E
50|$|Google AdSense was {{the first}} major contextual {{advertising}} network. It works by providing webmasters with JavaScript code that, when inserted into webpages, displays relevant advertisements from the Google inventory of advertisers. The relevance is calculated by a separate Google bot, Mediabot, that indexes the content of a webpage. Recent technology/service providers have emerged with more sophisticated systems that use language-independent proximity <b>pattern</b> <b>matching</b> <b>algorithm</b> to increase matching accuracy.|$|E
40|$|A {{very fast}} {{parallel}} approach to <b>pattern</b> <b>matching</b> is presented. The approach {{is based on}} the bit-parallel approach and we use two-dimensional bitwise memory matrix which helps to achieve very fast parallel <b>pattern</b> <b>matching</b> <b>algorithms.</b> The parallel <b>pattern</b> <b>matching</b> takes O(1) time for the exact <b>pattern</b> <b>matching</b> and O(k) for the approximate <b>pattern</b> <b>matching,</b> where k is the number of errors...|$|R
30|$|String <b>matching</b> <b>algorithms</b> can be {{categorized}} into single and multiple <b>pattern</b> <b>matching</b> <b>algorithms.</b> In the single <b>pattern</b> <b>matching,</b> one <b>pattern</b> is <b>matched</b> against the entire text at a time [14]. In contrast, the multiple <b>pattern</b> <b>matching</b> approach compares the text sequence against all signatures all at once [15]. Obviously, the multiple matching approach is a better choice for intrusion detection to avoid sweeping the packet many times. However, it consumes more memory and requires a pre-processing phase to program the <b>patterns</b> before <b>matching</b> can commence.|$|R
40|$|Two new <b>pattern</b> <b>matching</b> <b>{{algorithm}}s</b> {{based on}} the Boyer-Moore algorithm are presented. Their performance is {{compared to that of}} earlier relevant variants {{in terms of the number}} of character comparisons and the required running time by exhaustive simulation. Experimental results show the efficiency of both these two new algorithms...|$|R
50|$|An {{attacker}} can exhaust the IDS's CPU {{resources in}} a number of ways. For example, signature-based intrusion detection systems use pattern matching algorithms to match incoming packets against signatures of known attacks. Naturally, some signatures are more computational expensive to match against than others. Exploiting this fact, an attacker can send specially-crafted network traffic to force the IDS to use the maximum amount of CPU time as possible to run its <b>pattern</b> <b>matching</b> <b>algorithm</b> on the traffic. This algorithmic complexity attack can overwhelm the IDS with a relatively small amount of bandwidth.|$|E
50|$|Due to {{different}} speaking rates, a non-linear fluctuation occurs in speech pattern versus time axis which {{needs to be}} eliminated. DP-matching is a dynamic programming (DP) based <b>pattern</b> <b>matching</b> <b>algorithm</b> which uses a time normalization effect where the fluctuations in the time axis are modeled using a non-linear time-warping function. Considering any two speech patterns, we {{can get rid of}} their timing differences by warping the time axis of one so that the maximum coincidence is attained with the other. Moreover, if the warping function is allowed to take any possible value, very less distinction can be made between words belonging {{to different}} categories. So, to enhance the distinction between words belonging to different categories, restrictions were imposed on the warping function slope.|$|E
50|$|Many {{commercial}} rule engines {{provide the}} Rete algorithm, a proprietary algorithm that embodies {{many of the}} principles of Rete. However, there are other execution algorithms such as the sequential algorithm (ILOG and Blaze Advisor terminology), algorithms for evaluating decision tables/trees, and algorithms tuned for hierarchical XML. The Rete algorithm is a stateful <b>pattern</b> <b>matching</b> <b>algorithm</b> designed to minimize the evaluation of repetitive tests across many objects/attributes and many rules. Different fields of usage are best for Rete-based and non-Rete-based execution algorithms. For simple stateless applications with minimal sharing of conditions across rules, a non-Rete-based execution algorithm (such as the sequential algorithm) may be preferable. For evaluating decision tables and trees, an algorithm that exploits the hierarchical relationships between the rule conditions may perform better than a simple Rete or sequential algorithm tuned for discrete rules.|$|E
50|$|Variations in {{refractive}} index cause {{the light from}} the target to refract as it passes through the fluid, which causes a distortion of the pattern in the image seen by the camera. <b>Pattern</b> <b>matching</b> <b>algorithms</b> can measure this distortion and calculate a qualitative density field of the flow.|$|R
40|$|We {{present a}} new {{taxonomy}} and toolkit of keyword <b>pattern</b> <b>matching</b> <b>algorithms.</b> The new taxonomy {{is an extension}} of a prior taxonomy of such algorithms. It includes a number of algorithms (including factor- and factor oracle-based and bit-parallel prefix-based <b>pattern</b> <b>matching</b> <b>algorithms)</b> that have been published or received a lot of attention in the last decade. Based on the new taxonomy, we developed a <b>pattern</b> <b>matching</b> toolkit. This toolkit is a revision and extension of the SPARE Parts toolkit that had been developed based on the original taxonomy. We present the architecture of the new toolkit, which is named SPARE Time. Samenvatting We presenteren een nieuwe taxonomie en toolkit van algorithmen voor keyword <b>pattern</b> <b>matching.</b> De nieuwe taxonomie vormt een uitbreiding van een eerdere taxonomie van zulke algorithmen. Ze bevat een aantal algorithmen (waaronder algorithmen gebaseerd op factoren en factor oracles en bit-parallelle algorithmen gebaseerd op prefixen) die in de afgelopen tien jaar gepubliceerd zijn of veel aandacht gekregen hebben...|$|R
40|$|Abstract—Compressed <b>pattern</b> <b>matching</b> is an {{emerging}} research area {{that addresses the}} following problem: given a file in compressed format and a pattern, report the occurrence(s) of the pattern in the file with minimal (or no) decompression. In this paper, we report our work on compressed <b>pattern</b> <b>matching</b> in LZW compressed files. The reported work is based on Amir’s well-known “almost-optimal ” algorithm but has been improved to search not only the first occurrence of the pattern but also all other occurrences. The improvements also include the multi-pattern matching and a faster implementation for so-called “simple patterns”. Extensive experiments have been conducted to test the search performance and to compare with the BWT-based compressed <b>pattern</b> <b>matching</b> <b>algorithms.</b> The results showed that our method is competitive among the best compressed <b>pattern</b> <b>matching</b> <b>algorithms.</b> LZW {{is one of the}} most efficient and popular compression algorithms used extensively and our method requires no modification on the compression algorithm. The work reported in this paper, therefore, has great economical and market potential...|$|R
5000|$|If the {{compressed}} file uses a variable width encoding {{it could be}} present a problem: for example, let “100” be the codeword for a and let “110100” be the codeword for b. If {{we are looking for}} an occurrence of a in the text we could obtain as result also an occurrence that is within the codeword of b: we call this event false match. So we have to verify if the occurrence detected is effectively aligned on a codeword boundary. However we could always decode the entire text and then apply a classic string matching algorithm, but this usually requires more space and time and often is not possible, for example if {{the compressed}} file is hosted online. This problem of verifying the match returned by the compressed <b>pattern</b> <b>matching</b> <b>algorithm</b> is a true or a false match together with the impossibility of decoding an entire text is called the compressed matching problem.Many strategies exist for finding the boundaries of codewords and avoiding full decompression of the text, for example: ...|$|E
40|$|In this paper, {{counting}} objects {{techniques are}} proposed for fast <b>pattern</b> <b>matching</b> <b>algorithm</b> based on normalized cross correlation and convolution technique which {{are widely used}} in image processing application. Pattern matching {{can be used to}} recognize and/or locate specific objects in an image. It is one of the emerging areas in computational object counting. In this paper, introduces a new pattern matching technique called convolution based on <b>pattern</b> <b>matching</b> <b>algorithm.</b> Many different pattern matching techniques have been developed but more efficient and robust methods are needed. The <b>pattern</b> <b>matching</b> <b>algorithm</b> is used to identify the patterns similar present in image. With the patterns, identify the similarity measures of the given pattern to count the object present in the given image. An experimental evaluation is carried out to estimate the performance of the proposed efficient <b>pattern</b> <b>matching</b> <b>algorithm</b> for remote sensing as well as common images in terms of estimation of execution times, efficiency and compared the results with an existing conventional methods...|$|E
3000|$|... -anonymity model {{which states}} that any <b>pattern</b> <b>matching</b> <b>algorithm</b> cannot {{differentiate}} an entry in a large dataset from at least [...]...|$|E
40|$|The {{discipline}} of Algebraic Dynamic Programming {{is a powerful}} method to design and implement versatile <b>pattern</b> <b>matching</b> <b>algorithms</b> on sequences; here we consider mixed sequence and secondary structure motifs in RNA. A recurring challenge when designing new pattern matchers {{is to provide a}} statistical analysis of pattern significance. We demonstrat...|$|R
40|$|Abstract. We review some <b>pattern</b> <b>matching</b> <b>algorithms</b> and {{techniques}} {{motivated by the}} discrete theory of image processing. The problem inspiring this research is that of searching an aerial photograph for all appearances of some object. The issues we discuss are digitization, local errors, rotation and scaling. We review deterministic serial techniques that are used for multidimensional <b>pattern</b> <b>matching</b> and discuss their strengths and weaknesses...|$|R
40|$|Modern network {{security}} applications, such as network-based intrusion detection systems (NIDS) and firewalls, routinely employ deep packet inspection to identify malicious traffic. In deep packet inspection, {{the contents of}} network packets are <b>matched</b> against <b>patterns</b> of malicious traffic to identify attack-carrying packets. The <b>pattern</b> <b>matching</b> <b>algorithms</b> employed for deep packet inspection must satisfy two requirements. First, the algorithms must be fast. Network security applications are often implemented as middleboxes that reside on high-speed Gbps links, and the algorithms are expected to perform at such speeds. Second, the algorithms must be space-efficient. The middleboxes that perform <b>pattern</b> <b>matching</b> are often implemented as hardware components, they employ fast but expensive SRAM technology to ensure good performance. Unfortunately, existing <b>pattern</b> <b>matching</b> <b>algorithms</b> suffer from a fundamental timespace tradeoff. The large majority of patterns are regular expressions, and there are three prior approaches for matching such patterns: deterministic finite automaton (DFAs), non-deterministic finite automaton (NFAs), and recursive backtracking-base...|$|R
40|$|AbstractOne of {{the main}} reasons for the high {{efficiency}} of the fast <b>pattern</b> <b>matching</b> <b>algorithm</b> of Boyer and Moore is preprocessing. The Boyer–Moore <b>pattern</b> <b>matching</b> <b>algorithm</b> utilizes two preprocessing algorithms: one on single characters and the other one on substrings. It is the latter which makes the <b>pattern</b> <b>matching</b> <b>algorithm</b> extremely fast (especially on natural language text). In the current paper we present a formal correctness proof of the program describing the substring-preprocessing algorithm. The proof is carried out within linear time temporal logic. During the process of our verification we found that indices of auxiliary arrays, as used in published high-level descriptions of the preprocessing algorithm, may run out of bounds. We demonstrate that this is the case and correct that undesirable aspect in the current paper...|$|E
40|$|AbstractPattern {{matching}} algorithm is usually used in intrusion detection system. During the detection process, {{the efficiency of}} <b>pattern</b> <b>matching</b> <b>algorithm</b> determines {{the performance of the}} intrusion detection system. However the low efficiency has became the main shortcomings in the <b>pattern</b> <b>matching</b> <b>algorithm.</b> Based on this point, this paper proposed an improved algorithm, increased the skip distance of the text string pointer, and reduced the number of comparisons. Experimental results show that the algorithm can effectively improved the efficiency of string matching...|$|E
40|$|This paper {{considers}} {{the use of}} text signatures and of parallel computer hardware {{to increase the efficiency}} of text scanning in serial document files. After a review of software and hardware techniques for text scanning, the characteristics of text signature systems for document retrieval are discussed, in particular the relationship between text signature length and both the efficiency and the effectiveness of searching. A parallel <b>pattern</b> <b>matching</b> <b>algorithm</b> is then described for use with the ICL Distributed Array Processor, a highly parallel SIMD array processor. The efficiency of this algorithm is compared with that of the Aho-Corasick <b>pattern</b> <b>matching</b> <b>algorithm</b> when implemented on a conventional minicomputer. Microprocessor-based multiprocessing networks are becoming widely available as a means of implementing MIMD parallelism. Experiments with the Boyer-Moore <b>pattern</b> <b>matching</b> <b>algorithm</b> on a network of INMOS transputers demonstrate near-linear speed-ups for networks containing up to 11 transputers. ...|$|E
40|$|In event <b>pattern</b> <b>matching,</b> various {{selection}} {{strategies have}} been proposed to impose additional constraints on the events that participate in a match. The skip-till-next-match selection strategy is used in scenarios where some incoming events are noise and therefore should be ignored. Skip-till-next-match is prone to blocking noise, i. e., noise that prevents the detection of matches. In this paper, we propose the robust skip-till-next-match selection strategy, which is robust against noise and finds matches that are missed by skip-till-next-match when blocking noise occurs in the input stream. To implement the new strategy in automaton-based <b>pattern</b> <b>matching</b> <b>algorithms,</b> we propose a backtracking mechanism. Extensive experiments using real-world data and different event <b>pattern</b> <b>matching</b> <b>algorithms</b> show that with skip-till-next-match the number of matches not detected due to blocking noise can be substantial, and that our backtracking mechanism outperforms alternative solutions that first produce a superset of the result followed by a post processing step to filter out non-compliant matches...|$|R
40|$|In this paper, I {{present a}} new family of Commentz-Walter-style multiple-keyword string <b>pattern</b> <b>matching</b> <b>{{algorithms}}.</b> The algorithms share a common algorithmic skeleton, which is significantly optimized {{when compared to the}} original Commentz- Walter skeleton and subsequently derived improvements. The new skeleton is derived via correctness-preserving stepwise algorithmic improvements, in the Eindhoven style of programming...|$|R
40|$|Abstract—Network Intrusion Detection System (NIDS) is {{a system}} {{developed}} for identifying attacks by using a set of rules. NIDS is {{an efficient way to}} provide the security protection for today’s internet. <b>Pattern</b> <b>match</b> <b>algorithm</b> {{plays an important role in}} NIDS that performs searches against multiple patterns for a string <b>match.</b> <b>Pattern</b> <b>matching</b> is a computationally expensive task. Traditional software-based NIDS solutions usually can not achieve a high-speed required for ever growing Internet attacks. In order to satisfy high-speed packet content inspection, hardware-implementable <b>pattern</b> <b>match</b> <b>algorithm</b> is required. In this paper, we propose a hardware-based <b>pattern</b> <b>match</b> architecture that employs a multi-character processor array. The proposed multi-character processor array is a parallel and pipelined architecture which can process multiple characters of the input stream per cycle. The proposed architecture can reduce a lot of unnecessary computations and thus it is power efficient. We use Snort pattern sets and DEFCON packet traces to perform our simulations. Our experiment results show that, with a 3 -character processor array, we can reduce 83 % of the computations compared with the brute force approach...|$|R
40|$|We {{introduce}} a <b>pattern</b> <b>matching</b> <b>algorithm</b> and a bitmap reconstruction method used in document image compression. This <b>pattern</b> <b>matching</b> <b>algorithm</b> uses the cross entropy between two patterns as {{the criterion for}} a match. We use a physical model {{which is based on}} the finite resolution of the scanner (spatial sampling error) to estimate the probability values used in cross entropy calculation. The matching algorithm is enhanced by the bitmap reconstruction method which infers a good high resolution image from a series of poor low resolution images. This bitmap reconstruction method is based on the Naive Image Averaging method, but it uses a preprocessing smoothing filter and it is done in a higher resolution than the original image. Experimental results show that this <b>pattern</b> <b>matching</b> <b>algorithm</b> and this bitmap reconstruction method compare favorably to previous techniques. 1 INTRODUCTION Document image compression is targeted at compressing scanned document images. Traditional methods of [...] ...|$|E
40|$|In this paper, we {{introduce}} a <b>pattern</b> <b>matching</b> <b>algorithm</b> used in document image compression. This <b>pattern</b> <b>matching</b> <b>algorithm</b> uses the cross entropy between two patterns as {{the criterion for}} a match. We use a physical model {{which is based on}} the finite resolution of the scanner (spatial sampling error) to estimate the probability values used in cross entropy calculation. Experimental results show this <b>pattern</b> <b>matching</b> <b>algorithm</b> compares favorably to previous algorithms. 1. INTRODUCTION Document image compression is targeted at compressing scanned document images. Traditional methods of facsimile data compression based on run-length coding fail to provide good performance. On the other hand, document image compression based on pattern matching is a method particularly effective for text pages. It was originally proposed in [1] and further studied in [4],[3],and [6]. Document image compression based on pattern matching works in this way: patterns, connected blobs of ink, which are expec [...] ...|$|E
40|$|Since {{frequent}} {{communication between}} applications {{takes place in}} high speed networks, deep packet inspection (DPI) {{plays an important role}} in the network application awareness. The signature-based network intrusion detection system (NIDS) contains a DPI technique that examines the incoming packet payloads by employing a <b>pattern</b> <b>matching</b> <b>algorithm</b> that dominates the overall inspection performance. Existing studies focused on implementing efficient pattern matching algorithms by parallel programming on software platforms because of the advantages of lower cost and higher scalability. Either the central processing unit (CPU) or the graphic processing unit (GPU) were involved. Our studies focused on designing a <b>pattern</b> <b>matching</b> <b>algorithm</b> based on the cooperation between both CPU and GPU. In this paper, we present an enhanced design for our previous work, a length-bounded hybrid CPU/GPU <b>pattern</b> <b>matching</b> <b>algorithm</b> (LHPMA). In the preliminary experiment, the performance and comparison with the previous work are displayed, and the experimental results show that the LHPMA can achieve not only effective CPU/GPU cooperation but also higher throughput than the previous method...|$|E
30|$|There was an approach [17] to {{analyzing}} provenance {{data and}} then predicting future demands on grid and cloud computing resources. The authors applied <b>pattern</b> <b>matching</b> <b>algorithms</b> {{on the most}} recent provenance data to foresee subsequent requests. That is, their work predicts a next demand by <b>matching</b> similar <b>patterns</b> to a recent usage pattern based on provenance data.|$|R
40|$|Most {{traditional}} <b>pattern</b> <b>matching</b> <b>algorithms</b> {{solve the}} problem of finding all occurrences of a given pattern string P in a given text T. Another important paradigm is the dictionary matching problem. Let D = {P 1, [...] ., P k } be the dictionary. We seek all locations of dictionary patterns that appear in a given text T...|$|R
40|$|Abstract. In this paper, I outline a new {{algorithm}} {{for regular}} tree <b>pattern</b> <b>matching.</b> The Boyer-Moore family of string <b>pattern</b> <b>matching</b> <b>algorithms</b> {{are considered to}} be among the most ecient. The Boyer-Moore idea of a shift dis-tance was generalized by Commentz-Walter for multiple keywords, and general-izations for regular expressions have also been found. The existence of a further generalization to tree <b>pattern</b> <b>matching</b> was rst mentioned in the statements accompanying my dissertation, [Wats 95]. Key words: tree <b>pattern</b> <b>matching,</b> tree parsing, code selection, Boyer-Moor...|$|R
