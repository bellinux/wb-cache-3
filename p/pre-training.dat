1367|63|Public
25|$|Multilayer kernel {{machines}} (MKM) {{are a way}} {{of learning}} highly nonlinear functions by iterative application of weakly nonlinear kernels. They use the kernel principal component analysis (KPCA), as a method for the unsupervised greedy layer-wise <b>pre-training</b> step of the deep learning architecture.|$|E
25|$|As of 2011, {{the state}} of the art in deep and {{feedforward}} networks, particularly convolutional neural networks, alternated convolutional layers and max-pooling layers, topped by several fully or sparsely connected layers followed by a final classification layer. Learning is usually done without unsupervised <b>pre-training.</b>|$|E
25|$|Researchers {{approach}} {{the study of}} sleep and memory from different angles. Some studies measure the effects of sleep deprivation after a novel task is taught (the subject learns the task and is sleep deprived afterwards). This {{is referred to as}} post-training sleep deprivation. Conversely, other experiments have been conducted that measure the effects of sleep deprivation before a task has been taught (the subject is sleep-deprived and then learns a task). This is referred to as <b>pre-training</b> sleep deprivation.|$|E
30|$|We {{propose to}} {{mitigate}} the problem stated {{in the previous section}} by using a generative neural model for appliance load sequence generation. We <b>pre-train</b> this model using a Generative Adversarial Network (GAN) (Goodfellow et al., 2014) architecture and integrate it into the Neural NILM disaggregation process.|$|R
40|$|Pedestrian {{detection}} is {{a problem}} of considerable prac-tical interest. Adding to the list of successful applications of deep learning methods to vision, we report state-of-the-art and competitive results on all major pedestrian datasets with a convolutional network model. The model uses a few new twists, such as multi-stage features, connections that skip layers to integrate global shape information with local distinctive motif information, and an unsupervised method based on convolutional sparse coding to <b>pre-train</b> the filters at each stage. 1...|$|R
25|$|A DBN {{can be used}} to generatively <b>pre-train</b> a DNN {{by using}} the learned DBN weights as the initial DNN weights. Backpropagation or other discriminative {{algorithms}} can then tune these weights. This is particularly helpful when training data are limited, because poorly initialized weights can significantly hinder model performance. These pre-trained weights are in a region of the weight space that is closer to the optimal weights than were they randomly chosen. This allows for both improved modeling and faster convergence of the fine-tuning phase.|$|R
25|$|Early on, deep {{learning}} was also applied to sequence learning with recurrent neural networks (RNNs) which are general computers and can run arbitrary programs to process arbitrary sequences of inputs. The depth of an RNN is unlimited and {{depends on the}} length of its input sequence. RNNs can be trained by gradient descent but suffer from the vanishing gradient problem. In 1992, it was shown that unsupervised <b>pre-training</b> of a stack of recurrent neural networks can speed up subsequent supervised learning of deep sequential problems.|$|E
25|$|Igor Aizenberg {{and colleagues}} {{introduced}} it to Artificial Neural Networks in 2000. The first functional Deep Learning networks were published by Alexey Grigorevich Ivakhnenko and V. G. Lapa in 1965. These networks are trained one layer at a time. Ivakhnenko's 1971 paper describes {{the learning of}} a deep feedforward multilayer perceptron with eight layers, already much deeper than many later networks. In 2006, a publication by Geoffrey Hinton and Ruslan Salakhutdinov introduced another way of <b>pre-training</b> many-layered feedforward neural networks (FNNs) one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then using supervised backpropagation for fine-tuning. Similar to shallow artificial neural networks, deep neural networks can model complex non-linear relationships. Over the last few years, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.|$|E
500|$|Newkirk was {{credited}} with seven air-to-air victories, during his time with the Flying Tigers, and 10.5 kills overall by CAMCO. In 1942, the [...] "Scarsdale Jack Unit" [...] was named in his memory at the U.S. Navy <b>pre-training</b> camp in Chapel Hill, North Carolina. He was awarded the British Distinguished Flying Cross, posthumously, in August 1943.|$|E
40|$|We {{propose a}} robust {{classifier}} to predict buying intentions based on user behaviour within a large e-commerce website. In this work we compare traditional machine learning techniques {{with the most}} advanced deep learning approaches. We show that both Deep Belief Networks and Stacked Denoising auto-Encoders achieved a substantial improvement by extracting features from high dimensional data during the <b>pre-train</b> phase. They prove also to be more convenient to deal with severe class imbalance. Comment: 21 pages, 3 figures. arXiv admin note: text overlap with arXiv: 1412. 6601, arXiv: 1406. 1231, arXiv: 1508. 03856 by other author...|$|R
40|$|Prepositions {{are very}} common and very ambiguous, and {{understanding}} their sense {{is critical for}} understanding {{the meaning of the}} sentence. Supervised corpora for the preposition-sense disambiguation task are small, suggesting a semi-supervised approach to the task. We show that signals from unannotated multilingual data can be used to improve supervised preposition-sense disambiguation. Our approach <b>pre-trains</b> an LSTM encoder for predicting the translation of a preposition, and then incorporates the pre-trained encoder as a component in a supervised classification system, and fine-tunes it for the task. The multilingual signals consistently improve results on two preposition-sense datasets. Comment: 12 pages; COLING 201...|$|R
40|$|In {{this paper}} we {{describe}} our attempt at producing a state-of-the-art Twitter sentiment classifier using Convolutional Neural Networks (CNNs) and Long Short Term Memory (LSTMs) networks. Our system leverages {{a large amount}} of unlabeled data to <b>pre-train</b> word embeddings. We then use a subset of the unlabeled data to fine tune the embeddings using distant supervision. The final CNNs and LSTMs are trained on the SemEval- 2017 Twitter dataset where the embeddings are fined tuned again. To boost performances we ensemble several CNNs and LSTMs together. Our approach achieved first rank on all of the five English subtasks amongst 40 teams. Comment: Published in Proceedings of SemEval- 2017, 8 page...|$|R
2500|$|Earlier {{challenges}} in training deep neural networks were successfully addressed with {{methods such as}} unsupervised <b>pre-training,</b> while available computing power increased {{through the use of}} GPUs and distributed computing. Neural networks were deployed on a large scale, particularly in image and visual recognition problems. This became known as [...] "deep learning", although deep learning is not strictly synonymous with deep neural networks.|$|E
2500|$|The renovations of the Camp des Loges were {{completed}} on 4 October 2008. The entire process cost €5 million and was inaugurated on 4 November 2008. Guillaume Hoarau was named Player of the Month for October by the UNFP with 55% of the votes. Charles Villeneuve announced that Pauleta would become ambassador and {{supervisor of the}} capital club. Paul Le Guen won the UNECATEF Fidelidade Mundial [...] "Le Coup du Coach." [...] Stéphane Sessègnon was named Player of the Month for December by the UNFP with 55% of the votes. Paris Saint-Germain announced that Charles Villeneuve would resign from his mandate as president-general manager ahead of the General Assembly. The Camp des Loges was recognised by the FFF {{as one of the}} best <b>pre-training</b> centers in France, being classified as Elite, Class 1 and Class A in recent seasons. Sébastien Bazin was named the new president of Paris Saint-Germain. Péguy Luyindula was named Player of the Month for January by the UNFP with 55% of the votes. Guillaume Hoarau was named Player of the Month for February by the UNFP with 71% of the votes. Paul Le Guen left Paris Saint-Germain at the end of the season after the capital club decided not to renew his contract. Jean-Eudes Maurice signed a new three-year contract extension until 2012.|$|E
5000|$|... #Subtitle level 3: <b>Pre-training</b> vs post-training sleep {{deprivation}} ...|$|E
40|$|Training deep Convolutional Neural Networks (CNN) {{is a time}} {{consuming}} task that may take weeks to complete. In this article we propose a novel, theoretically founded method for reducing CNN training time without incurring any loss in accuracy. The basic idea is to begin training with a <b>pre-train</b> network using lower-resolution kernels and input images, and then refine the results at the full resolution by exploiting the spatial scaling property of convolutions. We apply our method to the ImageNet winner OverFeat and to the more recent ResNet architecture and show a reduction in training time of nearly 20 % while test set accuracy is preserved in both cases...|$|R
40|$|This paper {{describes}} a procedure {{for the creation}} of large-scale video datasets for action classification and localization from unconstrained, realistic web data. The scalability of the proposed procedure is demonstrated by building a novel video benchmark, named SLAC (Sparsely Labeled ACtions), consisting of over 520 K untrimmed videos and 1. 75 M clip annotations spanning 200 action categories. Using our proposed framework, annotating a clip takes merely 8. 8 seconds on average. This represents a saving in labeling time of over 95 % compared to the traditional procedure of manual trimming and localization of actions. Our approach dramatically reduces the amount of human labeling by automatically identifying hard clips, i. e., clips that contain coherent actions but lead to prediction disagreement between action classifiers. A human annotator can disambiguate whether such a clip truly contains the hypothesized action in a handful of seconds, thus generating labels for highly informative samples at little cost. We show that our large-scale dataset can be used to effectively <b>pre-train</b> action recognition models, significantly improving final metrics on smaller-scale benchmarks after fine-tuning. On Kinetics, UCF- 101 and HMDB- 51, models pre-trained on SLAC outperform baselines trained from scratch, by 2. 0 %, 20. 1 % and 35. 4 % in top- 1 accuracy, respectively when RGB input is used. Furthermore, we introduce a simple procedure that leverages the sparse labels in SLAC to <b>pre-train</b> action localization models. On THUMOS 14 and ActivityNet-v 1. 3, our localization model improves the mAP of baseline model by 8. 6 % and 2. 5 %, respectively. Comment: CVPR submissio...|$|R
30|$|Inspired by the {{existing}} CNN model, we use ResNet (a further comparison during the experiment) to <b>pre-train</b> {{the data in}} the coco 2017 image classification task. The data collected from the collected power component inspection data is used to improve and eventually build a complete CNN model. The CNN model {{is the basis of}} the proposed method, and it provides the feature map required for subsequent RPN networks and detection networks [24]. The feature map contains features from the deep convolution of the input image, and Euclidean distances between features of objects are proportional to the differences between those objects. That is to say that the feature map can differentiate objects well [25].|$|R
5000|$|The <b>pre-training</b> {{that preceded}} these Myanmar {{discrimination}} experiments involved learning {{to remove a}} lid from a bucket or to displace a box to uncover {{a hole in the}} ground. On average, [...] "the 20 elephants taking part in these experiments required 3.4 sessions to gradually master the <b>pre-training</b> task." ...|$|E
5000|$|Implement {{four levels}} of {{training}} (awakening, initiation, orientation and <b>pre-training)</b> ...|$|E
5000|$|Before {{training}} commences participants complete <b>pre-training</b> {{verbal and}} visuo-spatial tasks, which are additionally {{completed in the}} study's follow-up as post-training tasks. <b>Pre-training</b> and post-training tasks vary, some studies use verbal and visuo-spatial tasks along with slightly different tasks; referred to as [...] "nontrained tasks." [...] Klingberg et al. used visuo-spatial tasks, a Span board, the Stroop task, Raven's coloured progressive matrices, and a choice reaction time task, during <b>pre-training</b> and post-training. Holmes et al. used a nonword recall task, mazes memory task, listening recall, and the [...] "odd one-out" [...] task. By using tasks that differ from ones in the study, laboratory results can demonstrate transfer effects if high scores are achieved, since these were not learned during training.|$|E
40|$|We {{focus on}} the task of human {{detection}} using unsupervised pre-trained neutral networks. The goal is to use multi-task feature learning to <b>pre-train</b> the network to identify people given image data. Intuitively, by learning features to identify subparts of human figures, such as arms, legs or torsos, these features can then be used for the learning task of classifying people. We train smaller convolutional networks on a dataset comprising of annotated video data of people in a variety of environments and poses and on existing datasets of labeled body part data in still images. The shared features that are learnt {{as a result of the}} multi-task feature learning are then applied to learning humans in an object classification task...|$|R
40|$|Significant {{progress}} has been achieved in Computer Vision by leveraging large-scale image datasets. However, large-scale datasets for complex Computer Vision tasks beyond classification are still limited. This paper proposed a large-scale dataset named AIC (AI Challenger) with three sub-datasets, human keypoint detection (HKD), large-scale attribute dataset (LAD) and image Chinese captioning (ICC). In this dataset, we annotate class labels (LAD), keypoint coordinate (HKD), bounding box (HKD and LAD), attribute (LAD) and caption (ICC). These rich annotations bridge the semantic gap between low-level images and high-level concepts. The proposed dataset is an effective benchmark to evaluate and improve different computational methods. In addition, for related tasks, others can also use our dataset as a new resource to <b>pre-train</b> their models...|$|R
40|$|Words {{in natural}} {{language}} follow a Zipfian distribution whereby some words are frequent {{but most are}} rare. Learning representations for words in the "long tail" of this distribution requires enormous amounts of data. Representations of rare words trained directly on end-tasks are usually poor, requiring us to <b>pre-train</b> embeddings on external data, or treat all rare words as out-of-vocabulary words with a unique representation. We provide a method for predicting embeddings of rare words on the fly from small amounts of auxiliary data with a network trained against the end task. We show that this improves results against baselines where embeddings are trained on the end task in a reading comprehension task, a recognizing textual entailment task, and in language modelling...|$|R
5000|$|During the week-long {{audition}} {{process known}} as <b>pre-training,</b> hopefuls {{are not allowed to}} wear make-up, all wear their hair in a pony tail, and all wear the same style clothing while performing in front of the directors and upperclassmen. Compared by many former team members to military basic training, the organization defends its process, believing that <b>pre-training</b> sets all hopefuls on equal footing, shows who has the desired amount of showmanship and dedication necessary, and insures new members are selected solely on their abilities. While the audition process itself is harsh and intimidating, former team members and other supporters are often overheard saying [...] "if they think <b>pre-training</b> is hard, wait until they make the team." ...|$|E
5000|$|<b>Pre-Training</b> (equatable to USEA Novice): XC: fences {{maximum height}} 0.91 m ditch 1.50 m drops 1.10 m; Stadium fences: 0.96 m ...|$|E
5000|$|... ‘Barree Stud’, {{set over}} some 400 acres and located in Willowmavin in north eastern Victoria {{originally}} {{served as the}} breeding, spelling and <b>pre-training</b> centre for the company {{when it was first}} purchased. As the company has developed, Barree has been redeveloped into a world-class <b>pre-training,</b> spelling and rehabilitation centre. During this process, the company’s breeding operations have moved elsewhere. Facilities include a 2000m sand track for workouts, equine water walker and swimming pool, treadmill, hyperbaric chamber and hydrotherapy equipment.|$|E
50|$|After the American Revolution {{and early}} 1800s the Canal {{proved to be}} a boom for the Oakland Valley-Forestburg area in that it {{provided}} the quarries, tanneries, coal mines, and lumber with easy access to the great metropolitan areas much more cheaply in the <b>pre-train</b> era. The Canal Company bought literally all the water rights of brooks ponds, and streams along its route to supply it with water. It is here that Reservation figured prominently. Beaver Dam Pond at the time was only a 5-acre beaver pond. D&H bought the flow rights and dammed up the pond until it reached its present size. Then as water was needed for locks, boards were taken out of the dam and within 4 hours the canal was receiving water from Beaver Dam Pond.|$|R
40|$|We {{propose a}} {{scalable}} Gaussian process model for regression by applying a {{deep neural network}} as the feature-mapping function. We first <b>pre-train</b> the deep neural network with a stacked denoising auto-encoder in an unsupervised way. Then, we perform a Bayesian linear regression on {{the top layer of}} the pre-trained deep network. The resulting model, Deep-Neural-Network-based Gaussian Pro-cess (DNN-GP), can learn much more meaningful representation of the data by the finite-dimensional but deep-layered feature-mapping function. Unlike standard Gaussian processes, our model scales well with the size of the training set due to the avoidance of kernel matrix inversion. Moreover, we present a mixture of DNN-GPs to further improve the re-gression performance. For the experiments on three representative large datasets, our proposed models significantly outperform the state-of-the-art algo-rithms of Gaussian process regression. ...|$|R
40|$|In this paper, we {{implement}} {{the method of}} proper orthogonal decomposition (POD) to generate a reduced order model (ROM) of an optimization-based mesh movement scheme. In this study it is shown that POD can be used effectively to generate an ROM, that accurately reproduces the full order mesh movement algorithm, with a decrease in computational time of over 99 %. We further introduce a novel training procedure whereby the POD models are generated in a fully automated fashion. The technology is applicable to any mesh movement method and enables potential reductions of up to four orders of magnitude in mesh movement related costs. The proposed model can be implemented without having to <b>pre-train</b> the POD model, to any fluid-structure interaction code with an existing mesh movement scheme. [URL]...|$|R
50|$|In 1992, Schmidhuber used {{unsupervised}} <b>pre-training</b> {{for deep}} hierarchies of data-compressing recurrent neural networks, and showed its benefits for speeding up supervised learning.|$|E
50|$|In 2006, {{during a}} <b>pre-training</b> camp workout with the Browns, Minter {{suffered}} a season-ending knee injury. On September 1, 2007, {{he was released}} by the Browns.|$|E
50|$|Sean Buckley is owner at Ultra Thoroughbred Racing {{which is}} a primary and <b>pre-training</b> stud which has had huge success {{with a variety of}} winning {{thoroughbred}} horses.|$|E
40|$|The {{surge of}} {{social media use}} brings huge demand of {{multilingual}} sentiment analysis (MSA) for unveiling cultural difference. So far, traditional methods resorted to machine translation [...] -translating texts in other languages to English, and then adopt the methods once worked in English. However, this paradigm is conditioned {{by the quality of}} machine translation. In this paper, we propose a new deep learning paradigm to assimilate the differences between languages for MSA. We first <b>pre-train</b> monolingual word embeddings separately, then map word embeddings in different spaces into a shared embedding space, and then finally train a parameter-sharing deep neural network for MSA. The experimental results show that our paradigm is effective. Especially, our CNN model outperforms a state-of-the-art baseline by around 2. 1 % in terms of classification accuracy...|$|R
40|$|Whole brain {{segmentation}} from structural {{magnetic resonance}} imaging {{is a prerequisite for}} most morphological analyses, but requires hours of processing time and therefore delays the availability of image markers after scan acquisition. We introduce QuickNAT, a fully convolution neural network that segments a brain scan in 20 seconds. To enable training of the complex network with limited annotated data, we propose to <b>pre-train</b> on auxiliary labels created from existing segmentation software and to subsequently fine-tune on manual labels. In an extensive set of evaluations on eight datasets that cover a wide age range, pathology, and different scanners, we demonstrate that QuickNAT achieves superior performance to state-of-the-art methods, while being about 700 times faster. This drastic speed up greatly facilitates the processing of large data repositories and supports the translation of imaging biomarkers by making them almost instantaneously available. Comment: Under Revie...|$|R
40|$|Abstract A novel {{supervised}} Actor–Critic (SAC) {{approach for}} {{adaptive cruise control}} (ACC) problem is proposed in this paper. The key elements required by the SAC algorithm namely Actor and Critic, are approximated by feed-forward neural networks respectively. The output of Actor and the state are input to Critic to approximate the performance index function. A Lyapunov stability analysis approach has been presented to prove the uniformly ultimate bounded property of the estimation errors of the neural networks. Moreover, we use the supervisory controller to <b>pre-train</b> Actor to achieve a basic control policy, which can improve the training con-vergence and success rate. We apply this method to learn an approximate optimal control policy for the ACC problem. Experimental results in several driving scenarios demonstrate that the SAC algorithm performs well, so it is feasible and effective for the ACC problem...|$|R
