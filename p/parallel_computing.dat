7007|1716|Public
5|$|Sechin, A.; <b>Parallel</b> <b>Computing</b> in Photogrammetry. GIM International. #1, 2016, pp.21–23.|$|E
5|$|Automatic parallelization of a {{sequential}} {{program by}} a compiler is {{the holy grail}} of <b>parallel</b> <b>computing.</b> Despite decades of work by compiler researchers, automatic parallelization has had only limited success.|$|E
5|$|<b>Parallel</b> <b>computing</b> {{is a type}} of {{computation}} {{in which}} many calculations or the execution of processes are carried out simultaneously. Large problems can often be divided into smaller ones, which can then be solved at the same time. There are several different forms of parallel computing: bit-level, instruction-level, data, and task parallelism. Parallelism has been employed for many years, mainly in high-performance computing, but interest in it has grown lately due to the physical constraints preventing frequency scaling. As power consumption (and consequently heat generation) by computers has become a concern in recent years, <b>parallel</b> <b>computing</b> has become the dominant paradigm in computer architecture, mainly in the form of multi-core processors.|$|E
50|$|Standard Portable Intermediate Representation (SPIR) is an {{intermediate}} language for <b>parallel</b> <b>compute</b> and graphics by Khronos Group, originally developed {{for use with}} OpenCL. The current version, SPIR-V, was announced in March 2015.|$|R
40|$|Today’s {{graphics}} processors {{are highly}} programmable, massively <b>parallel</b> <b>compute</b> engines. With {{the development of}} open, industry standards, parallel programming languages such as OpenCL ™ 1 and the continued evolution of heterogeneous computing, general-purpose graphics processing units (GPGPUs) offer exciting new capabilities for the embedded market. This paper examines some of the industry factor...|$|R
5000|$|It {{has been}} the basis for pathbreaking {{research}} in <b>parallel</b> statistical <b>computing.</b>|$|R
5|$|<b>Parallel</b> <b>computing</b> {{is closely}} related to {{concurrent}} computing—they are frequently used together, and often conflated, though the two are distinct: it is possible to have parallelism without concurrency (such as bit-level parallelism), and concurrency without parallelism (such as multitasking by time-sharing on a single-core CPU). In <b>parallel</b> <b>computing,</b> a computational task is typically broken down in several, often many, very similar subtasks that can be processed independently and whose results are combined afterwards, upon completion. In contrast, in concurrent computing, the various processes often do not address related tasks; when they do, as is typical in distributed computing, the separate tasks may have a varied nature and often require some inter-process communication during execution.|$|E
5|$|Within <b>parallel</b> <b>computing,</b> {{there are}} {{specialized}} parallel devices that remain niche areas of interest. While not domain-specific, {{they tend to}} be applicable to only a few classes of parallel problems.|$|E
5|$|Grid {{computing}} is {{the most}} distributed form of <b>parallel</b> <b>computing.</b> It makes use of computers communicating over the Internet {{to work on a}} given problem. Because of the low bandwidth and extremely high latency available on the Internet, distributed computing typically deals only with embarrassingly parallel problems. Many distributed computing applications have been created, of which SETI@home and Folding@home are the best-known examples.|$|E
40|$|This paper {{describes}} the APEmille project, jointly {{carried out by}} INFN and DESY. It mainly focuses on the architectural features of this massively <b>parallel</b> <b>compute</b> engine that matches the computational requirements of LGT. In the paper I briefly cover {{the story of the}} APE projects, discuss the requirements of any efficient LGT engine and finally describe the APEmille machine...|$|R
5000|$|For an {{arbitrary}} query q, <b>parallel</b> comparison <b>computes</b> the index i such that ...|$|R
50|$|OVPsim {{is being}} used by {{multiple}} educational establishments to provide a simulation infrastructure for the research of <b>parallel</b> <b>compute</b> platforms, hardware software co-design, performance analysis of embedded systems, and {{as the basis of}} other embedded tool developments. It is also leveraged for educational courses to allow students to develop and debug application software and create virtual platforms and new models.|$|R
5|$|Moore's {{law is the}} {{empirical}} observation {{that the number of}} transistors in a microprocessor doubles every 18 to 24months. Despite power consumption issues, and repeated predictions of its end, Moore's law is still in effect. With the end of frequency scaling, these additional transistors (which are no longer used for frequency scaling) can be used to add extra hardware for <b>parallel</b> <b>computing.</b>|$|E
5|$|<b>Parallel</b> <b>computing</b> {{can also}} {{be applied to the}} design of {{fault-tolerant}} computer systems, particularly via lockstep systems performing the same operation in parallel. This provides redundancy in case one component should fail, and also allows automatic error detection and error correction if the results differ. These methods can be used to help prevent single event upsets caused by transient errors. Although additional measures may be required in embedded or specialized systems, this method can provide a cost effective approach to achieve n-modular redundancy in commercial off-the-shelf systems.|$|E
5|$|<b>Parallel</b> <b>computing,</b> on {{the other}} hand, uses {{multiple}} processing elements simultaneously to solve a problem. This is accomplished by breaking the problem into independent parts so that each processing element can execute its part of the algorithm simultaneously with the others. The processing elements can be diverse and include resources such as a single computer with multiple processors, several networked computers, specialized hardware, or any combination of the above.|$|E
5000|$|SuperPascal—A {{publication}} {{language for}} <b>parallel</b> scientific <b>computing,</b> Concurrency—Practice and Experience 6, 5 (August 1994), 461-483 ...|$|R
5000|$|Numerical Recipes in Fortran 90. The Art of <b>Parallel</b> Scientific <b>Computing,</b> 2nd Edition, 1996, [...]|$|R
40|$|The {{past decade}} has shown {{explosive}} growth in the performance and capability of computer systems, driven by advances in VLSI technology that have allowed an ever greater number of components to fit onto a silicon chip. Computer architectures have evolved to harness this growth and translate it into increasingly powerful computer systems. To {{take advantage of the}} larger volume of resources available to designers, <b>parallel</b> <b>compute...</b>|$|R
5|$|Folding@home {{can use the}} <b>parallel</b> <b>computing</b> {{abilities}} of modern multi-core processors. The ability to use several CPU cores simultaneously allows completing the full simulation far faster. Working together, these CPU cores complete single work units proportionately faster than the standard uniprocessor client. This method is scientifically valuable because it enables much longer simulation trajectories to be performed in {{the same amount of}} time, and reduces the traditional difficulties of scaling a large simulation to many separate processors. A 2007 publication in the Journal of Molecular Biology relied on multi-core processing to simulate the folding of part of the villin protein approximately 10 times longer than was possible with a single-processor client, in agreement with experimental folding rates.|$|E
5|$|Because an ASIC is (by definition) {{specific}} {{to a given}} application, it can be fully optimized for that application. As a result, for a given application, an ASIC tends to outperform a general-purpose computer. However, ASICs are created by UV photolithography. This process requires a mask set, which can be extremely expensive. A mask set can cost over a million US dollars. (The smaller the transistors required for the chip, the more expensive the mask will be.) Meanwhile, performance increases in general-purpose computing over time (as described by Moore's law) tend to wipe out these gains in {{only one or two}} chip generations. High initial cost, and the tendency to be overtaken by Moore's-law-driven general-purpose computing, has rendered ASICs unfeasible for most <b>parallel</b> <b>computing</b> applications. However, some have been built. One example is the PFLOPS RIKEN MDGRAPE-3 machine which uses custom ASICs for molecular dynamics simulation.|$|E
25|$|In <b>parallel</b> <b>computing,</b> all {{processors}} {{may have}} access to a shared memory to exchange information between processors.|$|E
50|$|A team {{headed by}} Babayan {{designed}} Elbrus-3 computer using an architecture named Explicitly <b>Parallel</b> Instruction <b>Computing</b> (EPIC).|$|R
40|$|Increasing {{demand for}} perfor-mance on data-intensive {{parallel}} workloads has driven {{the design of}} throughput-oriented <b>parallel</b> <b>compute</b> accelerators. For this work, we consider programmable accelerators in contrast to fixed-function or hardwired application-specific accelerator units. Cur-rent programmable accelerators generally expose restricted programming models that yield high performance for data-parallel applications with regular computation and memory-access patterns, but present a more difficult target for less-regular parallel appli-cations. Generally, existing compute ac-celerators provide higher throughput vi...|$|R
40|$|Both {{fuzzy logic}} and {{computed}} fuel ratio can compensate the steady-state error of proportional-derivative (PD) method. This paper presents <b>parallel</b> <b>computed</b> fuel ratio compensation for fuzzy plus PID control management with application to internal combustion (IC) engine. The asymptotic stability of fuzzy plus PID control methodology with first-order computed fuel ratio estimation in the parallel structure is proven. For the parallel structure, the finite time convergence with a super-twisting second-order sliding-mode is guaranteed...|$|R
25|$|MATLAB {{supports}} GPGPU acceleration {{using the}} <b>Parallel</b> <b>Computing</b> Toolbox and MATLAB Distributed Computing Server, and third-party packages like Jacket.|$|E
25|$|Programming {{standards}} for <b>parallel</b> <b>computing</b> include OpenCL (vendor-independent), OpenACC, and OpenHMPP. Mark Harris, {{the founder of}} GPGPU.org, coined the term GPGPU.|$|E
25|$|Because APL's core {{objects are}} arrays, it lends itself well to {{parallel}}ism, <b>parallel</b> <b>computing,</b> massively parallel applications, and very-large-scale integration or VLSI.|$|E
50|$|Yang {{specializes in}} {{parallel}} and distributed systems, Internet search, and <b>parallel</b> scientific <b>computing.</b> He has co-authored over eighty journal and conference papers.|$|R
50|$|RaftLib is a {{portable}} parallel processing system {{that aims to}} provide extreme performance while increasing programmer productivity. It enables a programmer to assemble a massively parallel program (both local and distributed) using simple iostream-like operators. RaftLib handles threading, memory allocation, memory placement, and auto-parallelization of compute kernels. It enables applications to be constructed from chains of compute kernels forming a task and pipeline <b>parallel</b> <b>compute</b> graph. Programs are authored in C++ (although other language bindings are planned).|$|R
3000|$|..., {{and finally}} an inverse FFT {{to obtain the}} result of the integral. We wish to employ a <b>parallel</b> <b>compute</b> cluster for rapid {{computation}} over large grids, and hence use the free software package FFTW  3.3 [42], which includes a parallel MPI-C version. Note that the use of Fourier methods implies that the discretization grid has periodic boundaries, or in other words, the solution is effectively computed on a torus. We use a grid spacing of about 0.03 or better in our computations here.|$|R
25|$|The Fibonacci cube is an {{undirected graph}} with a Fibonacci number of nodes {{that has been}} {{proposed}} as a network topology for <b>parallel</b> <b>computing.</b>|$|E
25|$|Breakthroughs in {{high-performance}} computing, {{including the}} development of novel concepts for massively <b>parallel</b> <b>computing</b> and the design and application of computers that can carry out hundreds of trillions of operations per second.|$|E
25|$|Opened in 2013 is the $40 million, 138,000-square-foot (12,800 m2) Center for Science and Business, {{which houses}} the {{departments}} of accounting, biology, chemistry, economics, mathematics & computer science, physics, psychology and political economy & commerce. The new facility introduces a cadaver lab, the Adolphson Observatory with research-grade 20-inch reflecting telescope, nuclear physics lab, two <b>parallel</b> <b>computing</b> facilities, a moot boardroom, tax preparation facilities, one-way observation labs, and an FDA approved nutrition lab.|$|E
50|$|Superscalar execution, VLIW, and the {{closely related}} {{explicitly}} <b>parallel</b> instruction <b>computing</b> concepts, in which multiple execution units {{are used to}} execute multiple instructions in parallel.|$|R
40|$|Motivated by {{the idea}} of {{imposing}} <b>paralleling</b> <b>computing</b> on solving stochastic differential equations (SDEs), we introduce a new Domain Decomposition Scheme to solve forward-backward stochastic differential equations (FBSDEs) parallely. We reconstruct the Four Step Scheme in {MaProtterYong: 1994 :SFB} with some different conditions and then associate it with the idea of Domain Decomposition Methods. We also introduce a new technique to prove the convergence of Domain Decomposition Methods for systems of quasilinear parabolic equations and use it to prove the convergence of our scheme for the FBSDEs...|$|R
40|$|AbstractMotivated by {{the idea}} of {{imposing}} <b>paralleling</b> <b>computing</b> on solving stochastic differential equations (SDEs), we introduce a new domain decomposition scheme to solve forward–backward stochastic differential equations (FBSDEs) parallel. We reconstruct the four step scheme in Ma et al. (1994) [1] and then associate it with the idea of domain decomposition methods. We also introduce a new technique to prove the convergence of domain decomposition methods for systems of quasilinear parabolic equations and use it to prove the convergence of our scheme for the FBSDEs...|$|R
