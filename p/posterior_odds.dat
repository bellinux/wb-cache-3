202|26|Public
25|$|So {{the rule}} {{says that the}} <b>{{posterior}}</b> <b>odds</b> are the prior odds times the Bayes factor, or in other words, posterior is proportional to prior times likelihood.|$|E
2500|$|Initially, the car {{is equally}} likely to be behind {{any of the three}} doors: the odds on door 1, door 2, and door 3 are [...] This remains the case after the player has chosen door 1, by independence. According to Bayes' rule, the <b>posterior</b> <b>odds</b> on the {{location}} of the car, given that the host opens door 3, are equal to the prior odds multiplied by the Bayes factor or likelihood, which is, by definition, the probability of the new piece of information (host opens door 3) under each of the hypotheses considered (location of the car). Now, since the player initially chose door 1, the chance that the host opens door 3 is 50% if {{the car is}} behind door 1, 100% if the car is behind door 2, 0% if the car is behind door 3. Thus the Bayes factor consists of the ratios [...] or equivalently , while the prior odds were [...] Thus, the <b>posterior</b> <b>odds</b> become equal to the Bayes factor [...] Given that the host opened door 3, the probability that the car is behind door 3 is zero, and it is twice as likely to be behind door 2 than door 1.|$|E
2500|$|It {{can be more}} {{intuitive}} {{to present}} this argument using Bayes' rule rather than Bayes' theorem. Having seen a black face we can rule out the white card. We {{are interested in the}} probability that the card is black given a black face is showing. Initially it is equally likely that the card is black and that it is mixed: the prior odds are 1:1. Given that it is black we are certain to see a black face, but given that it is mixed we are only 50% certain to see a black face. The ratio of these probabilities, called the likelihood ratio or Bayes factor, is 2:1. Bayes' rule says [...] "posterior odds equals prior odds times likelihood ratio". Since the prior odds are 1:1 the <b>posterior</b> <b>odds</b> equals the likelihood ratio, 2:1. It is now twice as likely that the card is black than that it is mixed.|$|E
40|$|The aim of {{this paper}} is to {{construct}} Bayesian model comparison tests between discrete distributions used for claim count modeling in the actuarial field. We use advanced compu-tational techniques to estimate the <b>posterior</b> model <b>odds</b> amongst different distributions for claim counts. We construct flexible reversible jump Markov Chain Monte Carlo algorithms and implement them in various illustrated examples. 1...|$|R
40|$|Parameters in AutoRegressive Moving Average (ARMA) {{models are}} locally nonidenti ed, {{due to the}} problem of root cancellation. Parameters can be {{constructed}} which represent this identi cation problem. We argue that ARMA parameters should be analyzed conditional on these identifying parameters. Priors exploiting this feature result in regular posteriors, while priors which neglect it result in posteriori favor of nonidenti ed parameter values. By considering the implicit AR representation of an ARMA model a prior with the desired proporties is obtained. The implicit AR representation also allows to construct easily implemented algorithms to analyze ARMA parameters. As a byproduct, <b>posteriors</b> <b>odds</b> ratios can be computed to compare (nonnested) parsimonious ARMA models. The procedures are applied to two datasets, the (extended) Nelson-Plosser data and monthly observations of US 3 -month and 10 year interest rates. For approximately 50 % of the series in these two datasets an ARMA model is favored above an AR model...|$|R
40|$|Strong Lagrangian {{theory is}} used to {{illuminate}} {{the properties of the}} profile log likelihood. General conditions are given which lead to a simplification of the computations required to plot this function or calculate interval estimates based upon it. The results presented are rather general with a variety of possible applications. In particular, it is shown that they provide a simple solution to the important practical problem of obtaining an interval estimate for the <b>posterior</b> log <b>odds</b> ratio in the two population discrimination problem. The results are applied to the multivariate normal unequal covariance matrix case and are illustrated by an application...|$|R
2500|$|Richard Gill (2011) {{analyzes}} the likelihood for the host to open door 3 as follows. Given {{that the car}} is not behind door 1, it is equally likely that it is behind door 2 or 3. Therefore, the chance that the host opens door 3 is 50%. Given that the car is behind door 1, the chance that the host opens door 3 is also 50%, because, when the host has a choice, either choice is equally likely. Therefore, {{whether or not the}} car is behind door 1, the chance that the host opens door 3 is 50%. The information [...] "host opens door 3" [...] contributes a Bayes factor or likelihood ratio of , on whether or not the car is behind door 1. Initially, the odds against door 1 hiding the car were [...] Therefore, the <b>posterior</b> <b>odds</b> against door 1 hiding the car remain the same as the prior odds, [...]|$|E
50|$|<b>Posterior</b> <b>Odds</b> Testing for a Unit Root with Data-Based Model Selection (with Peter C. B. Phillips), Econometric Theory, Vol.10, No. 3-4, 1994, pp 771-808.|$|E
50|$|So {{the rule}} {{says that the}} <b>{{posterior}}</b> <b>odds</b> are the prior odds times the Bayes factor, or in other words, posterior is proportional to prior times likelihood.|$|E
40|$|With the {{increased}} use of continuous testing in computerized adaptive testing, new concerns about test security have evolved, such as how to ensure that items in an item pool are safeguarded from theft. In this article, procedures to detect test takers using item preknowledge are explored. When test takers use item preknowledge, their item responses deviate from the underlying item response theory (IRT) model, and estimated abilities may be inflated. This deviation may be detected through the use of person-fit indices. A Bayesian <b>posterior</b> log <b>odds</b> ratio index is proposed for detecting the use of item preknowledge. In this approach to person fit, the estimated probability that each test taker has preknowledge of items is updated after each ite...|$|R
40|$|The paper {{develops}} {{a class of}} priors which leads to equivalent <b>posterior</b> inference for <b>odds</b> ratio parameters based on prospective and retrospective models for categorical response data. The results are applicable to both unmatched and matched case-control studies. The proposed method can accommodate multiple and possibly ordered disease status {{as well as any}} arbitrary link function and is not restricted to the conventional logit link. The results are applied to the analysis of an ongoing case-control study on colorectal cancer...|$|R
40|$|Abstract Green’s {{well-known}} area theorem establishes an equivalence {{between the}} area under the yes-no ROC curve and the percent correct of an unbiased observer in a two-alternative forced-choice (2 AFC) task with equivalent stim-uli. In this article, {{we show that}} this conversion from yes-no detection data to hypothetical performance in a 2 AFC task is unnecessary: The same yes-no detection data {{that are used to}} compute the area statistic can always be used to compute the percent correct of an unbiased observer in the yes-no detection task itself. We also show that the ROC curve may not be the ideal graphical device for many inves-tigators. A more natural representation of the difficulty of a discrimination task is obtained by plotting the distribution of the <b>posterior</b> betting <b>odds</b> under equal base rates, which can be estimated from their distributions under unequa...|$|R
5000|$|It is in {{this context}} that the term model {{evidence}} is normally used. This quantity is important because the <b>posterior</b> <b>odds</b> ratio for a model M1 against another model M2 involves a ratio of marginal likelihoods, the so-called Bayes factor: ...|$|E
5000|$|Initially, the car {{is equally}} likely to be behind {{any of the three}} doors: the odds on door 1, door 2, and door 3 are 1 : 1 : 1. This remains the case after the player has chosen door 1, by independence. According to Bayes' rule, the <b>posterior</b> <b>odds</b> on the {{location}} of the car, given that the host opens door 3, are equal to the prior odds multiplied by the Bayes factor or likelihood, which is, by definition, the probability of the new piece of information (host opens door 3) under each of the hypotheses considered (location of the car). Now, since the player initially chose door 1, the chance that the host opens door 3 is 50% if {{the car is}} behind door 1, 100% if the car is behind door 2, 0% if the car is behind door 3. Thus the Bayes factor consists of the ratios [...] : 1 : 0 or equivalently 1 : 2 : 0, while the prior odds were 1 : 1 : 1. Thus, the <b>posterior</b> <b>odds</b> become equal to the Bayes factor 1 : 2 : 0. Given that the host opened door 3, the probability that the car is behind door 3 is zero, and it is twice as likely to be behind door 2 than door 1.|$|E
5000|$|What are {{the odds}} a posteriori, {{at the moment of}} truth in our example play of the spade suit? If East does with KQ win the first trick uniformly at random with the king or the queen [...] - [...] and with K win the first trick with the king, having no choice [...] - [...] the <b>posterior</b> <b>odds</b> are 3.39 to 6.22, a little more than 1:2, in {{percentage}} terms a little more than 35% for KQ. To play the ace A from North on the second round should win about 35% while to finesse again with the ten 10 wins about 65%.|$|E
40|$|The paper {{develops}} {{a class of}} priors that leads to equivalent <b>posterior</b> inference for <b>odds</b> ratio parameters based on prospective and retrospective models for categorical response data. The results are applicable to both unmatched and matched case-control studies. The results hold for a general class of link functions for categorical response. The proposed method can accommodate multiple and possibly ordered disease states. The results are applied {{to the analysis of}} discrete subtypes in an ongoing case-control study of colorectal cancer. A simulation study illustrates the need for carefully considering prior choices in Bayesian analysis of data collected under retrospective design...|$|R
40|$|Abstract. —We review Bayesian {{approaches}} to model testing {{in general and}} to the assessment of topological hypotheses in particular. We show that the standardway of setting up Bayes factor tests of themonophyly of a group, or the {{placement of a sample}} sequence in a known reference tree, can be misleading. The reason for this is related to the well-known dependency of Bayes factors on model-specific priors. Specifically, when testing tree hypotheses it is important that each hypothesis is associated with an appropriate tree space in the prior. This can be achieved by using appropriately constrained searches or by filtering trees in the posterior sample, but in a more elaborate way than typically implemented. If it is difficult to find the appropriate tree sets to be contrasted, then the <b>posterior</b> model <b>odds</b> may be more informative than the Bayes factor. We illustrate the recommended techniques using an empirical test case addressing the issue of whether two genera of diving beetles (Coleoptera: Dytiscidae), Suphrodytes and Hydroporus, should be synonymized. Our refined Bayes facto...|$|R
40|$|We review Bayesian {{approaches}} to model testing {{in general and}} to the assessment of topological hypotheses in particular. We show that the standard way of setting up Bayes factor tests of the monophyly of a group, or the {{placement of a sample}} sequence in a known reference tree, can be misleading. The reason for this is related to the well-known dependency of Bayes factors on model-specific priors. Specifically, when testing tree hypotheses it is important that each hypothesis is associated with an appropriate tree space in the prior. This can be achieved by using appropriately constrained searches or by filtering trees in the posterior sample, but in a more elaborate way than typically implemented. If it is difficult to find the appropriate tree sets to be contrasted, then the <b>posterior</b> model <b>odds</b> may be more informative than the Bayes factor. We illustrate the recommended techniques using an empirical test case addressing the issue of whether two genera of diving beetles (Coleoptera: Dytiscidae), Suphrodytes and Hydroporus, should be synonymized. Our refined Bayes factor tests, in contrast to standard analyses, show that there is strong support for Suphrodytes nesting inside Hydroporus, and the genera are therefore synonymized...|$|R
5000|$|The {{formula is}} read as the {{probability}} of the parameter (or hypothesis =h, as used in the notation on axioms) “given” the data (or empirical observation), where the horizontal bar refers to [...] "given". The right hand side of the formula calculates the prior probability of a statistical model (Pr Parameter) with the likelihood (Pr | Parameter) to produce a posterior probability distribution of the parameter (Pr | Data). The posterior probability is {{the likelihood that the}} parameter is correct given the observed data or samples statistics. Hypotheses can be compared using Bayesian inference by means of the Bayes factor, which is the ratio of the <b>posterior</b> <b>odds</b> to the prior odds. It provides a measure of the data and if it has increased or decreased the likelihood of one hypotheses relative to another.|$|E
50|$|In steps 6 and 7 of the {{switching}} argument, {{the writer}} imagines that that Envelope A contains {{a certain amount}} a, and then seems to believe that given that information, the other envelope would be equally likely to contain twice or half that amount. That assumption can only be correct, if prior to knowing what was in Envelope A, the writer would have considered the following two pairs of values for both envelopes equally likely: the amounts a/2 and a; and the amounts a and 2a. (This follows from Bayes' rule in odds form: <b>posterior</b> <b>odds</b> equal prior odds times likelihood ratio). But now we can apply the same reasoning, imagining not a but a/2 in Envelope A. And similarly, for 2a. And similarly, ad infinitum, repeatedly halving or repeatedly doubling {{as many times as}} you like. (Falk and Konold, 1992).|$|E
5000|$|Suppose, {{that the}} {{proposition}} {{to be proven}} is that defendant {{was the source of}} a hair found at the crime scene. Before learning that the hair was a genetic match for the defendant’s hair, the factfinder believes that the odds are 2 to 1 that the defendant was the source of the hair. If she used Bayes’ theorem, she could multiply those prior odds by a “likelihood ratio” in order to update her odds after learning that the hair matched the defendant’s hair. The likelihood ratio is a statistic derived by comparing the odds that the evidence (expert testimony of a match) would be found if the defendant was the source with the odds that it would be found if defendant was not the source. If it is ten times more likely that the testimony of a match would occur if the defendant was the source than if not, then the factfinder should multiply her prior odds by ten, giving <b>posterior</b> <b>odds</b> of 20 to one.|$|E
40|$|The genomic era {{brought by}} recent {{advances}} in the next-generation sequencing technology makes the genome-wide scans of natural selection a reality. Currently, almost all the statistical tests and analytical methods for identifying genes under selection {{was performed on the}} individual gene basis. Although these methods have the power of identifying gene subject to strong selection, they have limited power in discovering genes targeted by moderate or weak selection forces, which are crucial for understanding the molecular mechanisms of complex phenotypes and diseases. Recent availability and rapid completeness of many gene network and protein-protein interaction databases accompanying the genomic era open the avenues of exploring the possibility of enhancing the power of discovering genes under natural selection. The aim of the thesis is to explore and develop normal mixture model based methods for leveraging gene network information to enhance the power of natural selection target gene discovery. The results show that the developed statistical method, which combines the <b>posterior</b> log <b>odds</b> of the standard normal mixture model and the Guilt-By-Association score of the gene network in a naïve Bayes framework, has the power to discover moderate/weak selection gene which bridges the genes under strong selection and it helps our understanding the biology under complex diseases and related natural selection phenotypes. ...|$|R
40|$|Introduction: Cardioprotective {{properties}} of volatile agents and of remote ischemic preconditioning have survival effects in patients undergoing cardiac surgery. We performed a Bayesian network meta-analysis {{to confirm the}} beneficial effects of these strategies on survival in cardiac surgery, to evaluate {{which is the best}} strategy and if these strategies have additive or competitive effects. Methods: Pertinent studies were independently searched in BioMedCentral, MEDLINE/PubMed, Embase, and the Cochrane Central Register (updated November 2013). A Bayesian network meta-analysis was performed. Four groups of patients were compared: total intravenous anesthesia (with or without remote ischemic preconditioning) and an anesthesia plan including volatile agents (with or without remote ischemic preconditioning). Mortality was the main investigated outcome. Results: We identified 55 randomized trials published between 1991 and 2013 and including 6, 921 patients undergoing cardiac surgery. The use of volatile agents (<b>posterior</b> mean of <b>odds</b> ratio = 0. 50, 95 % CrI 0. 28 - 0. 91) and the combination of volatile agents with remote preconditioning (<b>posterior</b> mean of <b>odds</b> ratio = 0. 15, 95 % CrI 0. 04 - 0. 55) were associated with a reduction in mortality when compared to total intravenous anesthesia. Posterior distribution of the probability of each treatment to be the best one, showed that the association of volatile anesthetic and remote ischemic preconditioning is the best treatment to improve shortand long-term survival after cardiac surgery, suggesting an additive effect of these two strategies. Conclusions: In patients undergoing cardiac surgery, the use of volatile anesthetics and the combination of volatile agents with remote preconditioning reduce mortality when compared to TIVA and have additive effects. It is necessary to confirm these results with large, multicenter, randomized, double-blinded trials comparing these different strategies in cardiac and non-cardiac surgery, to establish which volatile agent is more protective than the others and how to best apply remote ischemic preconditioning...|$|R
40|$|This is a {{study of}} the process of {{diagnosis}} in family medicine (FM) in four practice populations from the Netherlands, Malta, Serbia and Japan. Diagnostic odds ratios (ORs) for common reasons for encounter (RfEs) and episode titles are used to study the process of diagnosis in international FM and to test the assumption that data can be aggregated across different age bands, practices and years of observation. Participating family doctors (FDs) recorded details of all their patient contacts in an episode of care (EoC) structure using the International Classification of Primary Care (ICPC). RfEs presented by the patient and the diagnostic labels (EoC titles) recorded for each encounter were classified with ICPC. The relationships between RfEs and episode titles were expressed as ORs using Bayesian probability analysis to calculate the <b>posterior</b> (post-test) <b>odds</b> of an episode title given an RfE, {{at the start of a}} new EoC. The distributions of diagnostic ORs from the four population databases are tabled across age groups, years of observation and practices. There is a lot of congruence in diagnostic process and concepts between populations, across age groups, years of observation and FD practices, despite differences in the strength of such diagnostic associations. There is particularly little variability of diagnostic ORs across years of observation and between individual FD practices. Given our findings, it makes sense to aggregate diagnostic data from different FD practices and years of observation. Our findings support the existence of common core diagnostic concepts in international F...|$|R
5000|$|Richard Gill (2011) {{analyzes}} the likelihood for the host to open door 3 as follows. Given {{that the car}} is not behind door 1, it is equally likely that it is behind door 2 or 3. Therefore, the chance that the host opens door 3 is 50%. Given that the car is behind door 1, the chance that the host opens door 3 is also 50%, because, when the host has a choice, either choice is equally likely. Therefore, {{whether or not the}} car is behind door 1, the chance that the host opens door 3 is 50%. The information [...] "host opens door 3" [...] contributes a Bayes factor or likelihood ratio of 1 : 1, on whether or not the car is behind door 1. Initially, the odds against door 1 hiding the car were 2 : 1. Therefore, the <b>posterior</b> <b>odds</b> against door 1 hiding the car remain the same as the prior odds, 2 : 1.|$|E
5000|$|Given {{that the}} shown face is black, the other face is black if {{and only if}} the card is the black card. If the black card is drawn, a black face is shown with {{probability}} 1. The total probability of seeing a black face is the total probability of drawing the black card is [...] By Bayes' theorem, the conditional probability of having drawn the black card, given that a black face is showing, isIt can be more intuitive to present this argument using Bayes' rule rather than Bayes' theorem. Having seen a black face we can rule out the white card. We are interested in the probability that the card is black given a black face is showing. Initially it is equally likely that the card is black and that it is mixed: the prior odds are 1:1. Given that it is black we are certain to see a black face, but given that it is mixed we are only 50% certain to see a black face. The ratio of these probabilities, called the likelihood ratio or Bayes factor, is 2:1. Bayes' rule says [...] "posterior odds equals prior odds times likelihood ratio". Since the prior odds are 1:1 the <b>posterior</b> <b>odds</b> equals the likelihood ratio, 2:1. It is now twice as likely that the card is black than that it is mixed.|$|E
5000|$|The {{posterior}} {{function is}} given by , i.e., the posterior function {{is proportional to the}} product of the likelihood function and the prior distribution, and can be understood as a method of updating information, with the difference between [...] and [...] being the information gain concerning [...] after observing new data. The choice of the prior distribution is used to impose restrictions on , e.g. , with the beta distribution as a common choice due to (i) being defined between 0 and 1, (ii) being able to produce a variety of shapes, and (iii) yielding a posterior distribution of the standard form if combined with the likelihood function [...] Based on the properties of the beta distribution, an ever-larger sample size implies that the mean of the posterior distribution approximates the maximum likelihood estimator The assumed form of the likelihood function is part of the prior information and has to be justified. Different distributional assumptions can be compared using <b>posterior</b> <b>odds</b> ratios if a priori grounds fail to provide a clear choice. Commonly assumed forms include the beta distribution, the gamma distribution, and the uniform distribution, among others. If the model contains multiple parameters, the parameter can be redefined as a vector. Applying probability theory to that vector of parameters yields the marginal and conditional distributions of individual parameters or parameter groups. If data generation is sequential, Bayesian principles imply that the posterior distribution for the parameter based on new evidence will be proportional to the product of the likelihood for the new data, given previous data and the parameter, and the posterior distribution for the parameter, given the old data, which provides an intuitive way of allowing new information to influence beliefs about a parameter through Bayesian updating. If the sample size is large, (i) the prior distribution plays a relatively small role in determining the posterior distribution, (ii) the posterior distribution converges to a degenerate distribution at the true value of the parameter, and (iii) the posterior distribution is approximately normally distributed with mean [...]|$|E
40|$|OBJECTIVE: To {{systematically}} {{review the}} medical literature reporting on ultrasound factors that can be predictive for the outcome of an attempt at external cephalic version (ECV). METHODS: MEDLINE, EMBASE and Cochrane Central Register of Controlled Trials were searched. Studies reporting on potential ultrasound prognosticators and ECV success rates that allowed construction of a 2 x 2 table were selected. RESULTS: We selected 37 primary articles reporting on 7709 women. <b>Posterior</b> placental location (<b>odds</b> ratio (OR), 1. 9; 95 % CI, 1. 5 - 2. 4), complete breech position (OR, 2. 3; 95 % CI, 1. 9 - 2. 8) and an amniotic fluid index > 10 (OR, 1. 8; 95 % CI, 1. 5 - 2. 1) were predictors of successful ECV. CONCLUSION: Success of an ECV attempt is associated with ultrasound parameters such as fetal position, amniotic fluid and placental location. This knowledge {{can be used to}} develop a prognostic model to predict successful ECV. Copyright (c) 2008 ISUOG. Published by John Wiley & Sons, Lt...|$|R
40|$|Objective To compare antimüllerian hormone (AMH) and antral {{follicle}} count (AFC) {{separately and}} {{in combination with}} clinical characteristics for the prediction of live birth after controlled ovarian stimulation. Design Retrospective development and temporal external validation of prediction model. Setting Outpatient IVF clinic. Patient(s) We applied the boosted tree method to develop three prediction models incorporating clinical characteristics plus AMH or AFC or the combination on 2, 124 linked IVF cycles from 2006 to 2010 and temporally externally validated predicted live-birth probabilities with an independent data set comprising 1, 121 cycles from 2011 to  2012. Intervention(s) None. Main Outcome Measure(s) Predictive power (<b>posterior</b> log of <b>odds</b> ratio compared to age, or PLORA), reclassification, receiver operator characteristic analysis, calibration, dynamic range. Result(s) Predictive power, was highest for the AMH model (PLORA = 29. 1), followed by the AMH-AFC model (PLORA = 28. 3) and AFC model (PLORA = 22. 5). The prediction errors were 1...|$|R
40|$|Introduction. This is a {{study of}} the process of {{diagnosis}} in family medicine (FM) in four practice populations from the Netherlands, Malta, Serbia and Japan. Diagnostic odds ratios (ORs) for common reasons for encounter (RfEs) and episode titles are used to study the process of diagnosis in international FM and to test the assumption that data can be aggregated across different age bands, practices and years of observation. Methodology. Participating family doctors (FDs) recorded details of all their patient contacts in an episode of care (EoC) structure using the International Classification of Primary Care (ICPC). RfEs presented by the patient and the diagnostic labels (EoC titles) recorded for each encounter were classified with ICPC. The relationships between RfEs and episode titles were expressed as ORs using Bayesian probability analysis to calculate the <b>posterior</b> (post-test) <b>odds</b> of an episode title given an RfE, {{at the start of a}} new EoC. Results. The distributions of diagnostic ORs from the four population databases are tabled across age groups, years of observation and practices. Conclusions. There is a lot of congruence in diagnostic process and concepts between populations, across age groups, years of observation and FD practices, despite differences in the strength of such diagnostic associations. There is particularly little variability of diagnostic ORs across years of observation and between individual FD practices. Given our findings, it makes sense to aggregate diagnostic data from different FD practices and years of observation. Our findings support the existence of common core diagnostic concepts in international FM...|$|R
40|$|This paper {{establishes}} a correspondence in large samples between classical hypothesis tests and Bayesian <b>posterior</b> <b>odds</b> tests for models without trends. More specifically, tests of point null hypotheses and one- or two-sided alternatives are considered (where nuisance parameters {{may be present}} under both hypotheses). It is shown that for certain priors the Bayesian <b>posterior</b> <b>odds</b> test is equivalent in large samples to classical Wald, Lagrange multiplier, and likelihood ratio tests for some significance level and vice versa. Asymptotics, Bayesian, classical, hypothesis test, likelihood ratio, <b>posterior</b> <b>odds,</b> prior...|$|E
40|$|The {{problem of}} {{approximating}} an interval null or imprecise hypothesis test by a point null or precise hypothesis test under a Bayesian framework is considered. In the literature, {{some of the}} methods for solving this problem have used the Bayes factor for testing a point null and justified it as an approximation to the interval null. However, many authors recommend evaluating tests through the <b>posterior</b> <b>odds,</b> a Bayesian measure of evidence against the null hypothesis. It is of interest then to determine whether similar results hold when using the <b>posterior</b> <b>odds</b> as the primary measure of evidence. For the prior distributions under which the approximation holds {{with respect to the}} Bayes factor, it is shown that the <b>posterior</b> <b>odds</b> for testing the point null hypothesis does not approximate the <b>posterior</b> <b>odds</b> for testing the interval null hypothesis. In fact, in order to obtain convergence of the <b>posterior</b> <b>odds,</b> a number of restrictive conditions need to be placed on the prior structure. Furthermore, under a non- symmetrical prior setup, neither the Bayes factor nor the <b>posterior</b> <b>odds</b> for testing the imprecise hypothesis converges to the Bayes factor or <b>posterior</b> <b>odds</b> respectively for testing the precise hypothesis. To rectify this dilemma, it is shown that constraints need to be placed on the priors. In both situations, the class of priors constructed to ensure convergence of the <b>posterior</b> <b>odds</b> are not practically useful, thus questioning, from a Bayesian perspective, the appropriateness of point null testing in a problem better represented by an interval null. The theories developed are also applied to an epidemiological data set from White, LaFaunce, and Mohammed (1989) in order to illustrate and study priors for which the point null hypothesis test approximates the interval null hypothesis test...|$|E
40|$|In {{this study}} we suggest a Bayesian {{approach}} to fuzzy clustering analysis – the Bayesian fuzzy regression. A. Bayesian <b>Posterior</b> <b>Odds</b> analysis is employed to select the correct number of clusters for the fuzzy regression analysis. In this study, we use a natural conjugate prior for the parameters, and {{we find that the}} Bayesian <b>Posterior</b> <b>Odds</b> provide a very powerful tool for choosing the number of clusters. The results from a Monte Carlo experiment and two real data applications of Bayesian fuzzy regression are very encouraging. Keywords: Bayesian <b>posterior</b> <b>odds,</b> model selection, fuzzy regression, fuzzy clusterin...|$|E
40|$|Background: Iran is a Middle Eastern {{country with}} a 70 million population. There are 3 million Iranians with {{diabetes}} mellitus (DM) {{and there is a}} high incidence of non traumatic amputation in this population. Amputation is often preceded by foot deformity or ulceration. We evaluated the routine foot examination of persons with diabetes (PWD) attending an outpatient Diabetic Clinic to identify the clinical characteristics that might be early warning signs of individuals at a high risk of developing a foot ulcer or having a subsequent non traumatic amputation. Methods: A prospective, descriptive, clinic-based study was conducted on 247 patients with diabetes mellitus in 2005. The objectives of the study were to define the abnormal features of the foot examination in PWD which could be risk factors for ulceration or amputation. Results: The mean age of patients with diabetes was 52 ± 12. The prevalence of callus in the enrolled patients was 12 % and heel fissures were noted in 50 %. There was a significant relationship between callus formation and the absence of tibialis <b>posterior</b> pulse (<b>odds</b> ratio 5), the presence of the hammer toe deformity (odds ratio 4), and foot ulceration (odds ratio 3). The prevalence of foot ulcers in PWD was 4 %. Conclusion: A diabetic screening program identifying callus formation, absent pulses, and hammer toe are important early signs of individuals at an increased risk for foot ulcers. This program will facilitate early treatment to decrease the loss of limbs. Key words: Case studies • Diabetic foot ulcer • Iran • Prospective • Woun...|$|R
40|$|In {{the field}} of quality of health care measurement, one {{approach}} to assessing patient sickness at admission involves a logistic regression of mortality within 30 days of admission on a fairly large number of sickness indicators (on the order of 100) to construct a sickness scale, employing classical variable selection methods to find an ""optimal"" subset of 10 - 20 indicators. Such ""benefit-only"" methods ignore the considerable differences among the sickness indicators in cost of data collection, {{an issue that is}} crucial when admission sickness is used to drive programs (now implemented or under consideration in several countries, including the U. S. and U. K.) that attempt to identify substandard hospitals by comparing observed and expected mortality rates (given admission sickness). When both data-collection cost and accuracy of prediction of 30 -day mortality are considered, a large variable-selection problem arises in which costly variables that do not predict well enough should be omitted from the final scale. In this paper (a) we develop a method for solving this problem based on <b>posterior</b> model <b>odds,</b> arising from a prior distribution that (1) accounts for the cost of each variable and (2) results in a set of posterior model probabilities that corresponds to a generalized cost-adjusted version of the Bayesian information criterion (BIC), and (b) we compare this method with a decision-theoretic cost-benefit approach based on maximizing expected utility. We use reversible-jump Markov chain Monte Carlo (RJMCMC) methods to search the model space, and we check the stability of our findings with two variants of the MCMC model composition (MC 3) algorithm. We find substantial agreement between the decision-theoretic and cost-adjusted-BIC methods; the latter provides a principled approach to performing a cost-benefit trade-off that avoids ambiguities in identification of an appropriate utility structure. Our cost-benefit approach results in a set of models with a noticeable reduction in cost and dimensionality, and only a minor decrease in predictive performance, when compared with models arising from benefit-only analyses. © Institute of Mathematical Statistics, 2009...|$|R
40|$|For frequentist {{settings}} in which parameter randomness represents variability rather than uncertainty, the ideal {{measure of the}} support for one hypothesis over another is {{the difference in the}} posterior and prior log odds. For situations in which the prior distribution cannot be accurately estimated, that ideal support may be replaced by another measure of support, which may be any predictor of the ideal support that, on a per-observation basis, is asymptotically unbiased. Two qualifying measures of support are defined. The first is minimax optimal with respect to the population and is equivalent to a particular Bayes factor. The second is worst-sample minimax optimal and is equivalent to the normalized maximum likelihood. It has been extended by likelihood weights for compatibility with more general models. One such model is that of two independent normal samples, the standard setting for gene expression microarray data analysis. Applying that model to proteomics data indicates that support computed from data for a single protein can closely approximate the estimated difference in <b>posterior</b> and prior <b>odds</b> that would be available with the data for 20 proteins. This suggests the applicability of random-parameter models to other situations in which the parameter distribution cannot be reliably estimated. Comment: Errors in the first version were corrected, and the methodology is now applied to more interesting dat...|$|R
