25|10|Public
50|$|A {{subfield}} of Knowledge Acquisition within Artificial Intelligence, Knowledge Collection from Volunteer Contributors (KCVC) {{attempts to}} drive down the cost of acquiring the knowledge required to support automated reasoning by having the public enter knowledge in computer <b>processable</b> <b>form</b> over the internet. KCVC might be regarded as similar in spirit to Wikipedia, although the intended audience, Artificial Intelligence systems, differs.|$|E
40|$|Arrays of oriented, {{crystalline}} Si wires {{are transferred}} into flexible, transparent polymer films. The polymer-supported Si wire arrays in liquid-junction photoelectrochemical cells yield current-potential behavior {{similar to the}} Si wires attached to the brittle growth substrate. These systems offer the potential for attaining high solar energy-conversion efficiencies using modest diffusion length, readily grown, crystalline Si in a flexible, <b>processable</b> <b>form...</b>|$|E
40|$|Arrays of Si rods are {{embedded}} in PDMS and removed from the rigid growth substrate, resulting in a composite material that merges the benefits of single-crystalline silicon with the flexibility of a polymer. With this technique, solar cell absorber materials {{with the potential to}} achieve high efficiency can be prepared by high-temperature processing and transformed into a flexible, <b>processable</b> <b>form...</b>|$|E
40|$|Graphene, a nanocarbon with {{exceptional}} {{physical and}} electronic properties, {{has the potential}} to be utilized in a myriad of applications and devices. However, this will only be achieved if scalable, <b>processable</b> <b>forms</b> of graphene are developed along with ways to fabricate these forms into material structures and devices. In this review, we provide a comprehensive overview of the chemistries suitable for the development of aqueous and organic solvent graphene dispersions and their use for the preparation of a variety of polymer composites, materials useful for the fabrication of graphene-containing structures and devices. Fabrication of the processable graphene dispersions or composites by printing (inkjet and extrusion) or spinning methods (wet) is reviewed. The preparation and fabrication of liquid crystalline graphene oxide dispersions whose unique rheologies allow the creation of graphene-containing structures by a wide range of industrially scalable fabrication techniques such as spinning (wet and dry), printing (ink-jet and extrusion) and coating (spray and electrospray) is also reviewed...|$|R
40|$|Third-generation {{profilometer}} {{for inspection}} of butt welds includes hand-held probe unit operating {{in conjunction with}} computer. Unit positioned across weld, in contact with workpiece, to obtain profile. Increases precision by reducing subjective inputs and concomitant variations in outputs among different operators. Computerization retains capabilities of first- and second-generation profilometers to measure peak angles and mismatches of butt welds and extends measurement capabilities into field of image analysis. Output data more readily <b>processable</b> into <b>forms</b> used by same or another computer...|$|R
40|$|This PDF {{has been}} {{designed}} to help you navigate your way through the Payment and Reimbursement process. SOVA is providing this information in an effort to decrease the turn-a-round time for processing claims. Included are eligibility criteria for the Compensation Program, the SAP/CAP Program, payments and reimbursements at a glance and <b>processable</b> and unprocessable <b>forms...</b>|$|R
3000|$|Electronic {{health record}} (EHR) It is a {{repository}} of information regarding the health status of patient, in computer <b>processable</b> <b>form.</b> In fact, an EHR is supposed to contain all the necessary information about the patients collected from several providers plus evidence-based tools to make intelligent decisions. Thus, EHR maintains the total health of the patients. Note that it may store data in structured or unstructured or in both format.|$|E
40|$|We {{provide a}} novel {{framework}} and implementation which integrates tools {{to support the}} acquisition of mass, distribu-tive, incremental, dynamic, argumentative knowledge in nat-ural language. With the Attempto Controlled English (ACE) system, natural language statements are automatically trans-lated to a machine <b>processable</b> <b>form.</b> A discussion forum allows the specication of argumentation theoretic relation-ships among statements. Statements and their relationships are input to a formal, implemented argumentation system, which calculates inferences from asserted premises...|$|E
40|$|This {{work was}} created to review the {{evidence}} for lexical borrowing from the Tocharian languages to the Chinese languages. The used methodology relies on lexical lists, previous etymological findings, linguistic typology and anthropological input. For preparatory data manipulation, a set of semi- automatic scripts has been created. Presented is a qualitative research based on previous findings assisted by raw data. The outcome of this work should be testable findings which could be extracted to a computer <b>processable</b> <b>form...</b>|$|E
40|$|International audienceThe data {{warehousing}} and OLAP technologies are now moving onto handling complex data that mostly originate from the Web. However, intagrating such data into a decision-support process requires their representation under a <b>form</b> <b>processable</b> by OLAP and/or data mining techniques. We present {{in this paper}} a complex {{data warehousing}} methodology that exploits XML as a pivot language. Our approach includes the integration of complex data in an ODS, under the form of XML documents; their dimensional modeling and storage in an XML data warehouse; and their analysis with combined OLAP and data mining techniques. We also address the crucial issue of performance in XML warehouses...|$|R
40|$|Corresponding authors Abstract: Data {{warehousing}} and Online Analytical Processing (OLAP) {{technologies are}} now moving onto handling complex data that mostly originate from the web. However, integrating such data into a decision-support process requires their representation in a <b>form</b> <b>processable</b> by OLAP and/or data mining techniques. We present {{in this paper}} a complex data warehousing methodology that exploits eXtensible Markup Language (XML) as a pivot language. Our approach includes the integration of complex data in an ODS, {{in the form of}} XML documents; their dimensional modelling and storage in an XML data warehouse; and their analysis with combined OLAP and data mining techniques. We also address the crucial issue of performance in XML warehouses...|$|R
40|$|Solution-processable non-polymeric organic {{semiconductors}} {{are attractive}} for opto-electronic applications {{due to their}} relatively simple synthetic reproducibility and characterization, and enhanced capability for fine-tuning of their properties. We report the synthesis, charge transport, photophysics, and photovoltaic properties of three non-polymeric materials based upon bisarylthiophenyl diketopyrrolopyrrole [DPP(ThAr) (2) ]. The DPP(ThAr) (2) molecules are comprised of solubilizing alkyl groups, 2 -ethylhexyl (for 1 a) and 2 -octyldodecyl (for 1 b and 2), which are capped with "electron accepting" moieties -fluorenone (1) or benzothiadiazole (2). While the materials could be prepared under standard SuzukiMiyaura cross-coupling conditions, a simple direct arylation afforded 2 and 1 b in good yields. We found 1 a with a short alkyl chain lacked sufficient solubility for solution processing but 1 b and 2 are solution <b>processable</b> and <b>form</b> good quality films. All three materials exhibited ambipolar charge transport in field effect transistors, with 1 b showing balanced charge mobilities of about 10 (- 3) cm(2) V- 1 s(- 1). Bulk heterojunction solar cells of 1 b or 2 with PC 71 BM {{were found to have}} high opencircuit voltages (up to 0. 9 V) with power conversion efficiencies of up to 4. 5 % and 2. 6 %, respectively. (C) 2017 Elsevier B. V. All rights reserved...|$|R
40|$|With the {{invention}} of high throughput methods, researchers are capable of producing large amounts of biological data. During the analysis of such data {{the need for a}} functional grouping of genes arises. In this paper, we propose a new method based on spectral clustering for the partitioning of genes according to their biological function. The functional information is based on Gene Ontology annotation, a mechanism to capture functional knowledge in a shareable and computer <b>processable</b> <b>form.</b> Our functional cluster method promises to automatize, speed up and therefore improve biological data analysis...|$|E
40|$|Ontologies can {{formally}} {{describe the}} semantics {{of the medical}} domain in an unambiguous and machine <b>processable</b> <b>form,</b> acting as a conceptual interface between different applications that must interoperate. In this paper we present an ontology of cancer therapies originally developed {{to bridge the gap}} between an oncologic Electronic Patient Record (EPR) and a guideline-based decision support system. We show an application of the ontology complemented by rules to classify therapies recorded in the EPR. The results show how such an ontology can be used also to discover possible problems of data consistency in the EPR...|$|E
40|$|It {{has long}} been {{realised}} that the web could benefit from having its content understandable and available in a machine <b>processable</b> <b>form,</b> and it is widely agreed that ontologies will {{play a key role}} in providing much enabling infrastructure to support this goal. In this chapter we review briefly a selected history of description logics in web-based information systems, and the more recent developments related to OIL, DAML+OIL and the semantic web. OIL and DAML+OIL are ontology languages specifically designed for use on the web; they exploit existing web standards (XML, RDF and RDFS), adding the formal rigor of a description logic and the ontological primitives of object oriented and frame based systems...|$|E
40|$|The {{curve and}} surface based {{description}} of a ship's geometry created through fairing programmes {{is the basis for}} CAD Systems employed in the various subsequent ship design activities. It is however necessary to convert the specialised representation of the fairing geometry in a <b>form</b> <b>processable</b> through CAD systems. A solutions is offered based on a dedicated neutral representation of the ship geometry as a standardised exchange format between fairing programmes and CAD systems. As part of the overall development of such a standardised exchange format a detailed requirements analysis was performed. Selected fairing programmes and CAD systems used in the German shipbuilding industry were evaluated with respect to their functionality, external interfaces, mathematical representations, data structures and geometry elements. The evaluation was performed, based on questionnaires, partly in written form and partly in direct interviews. Two phases were conducted: a coarse survey, and a subsequent detailed study of the above mentioned features. The evaluation showed that a dedicated functionality with respect to ship geometry was missing in a number of systems. The internal representation of geometry elements and relationships were to a large extent divergent. Nevertheless it was concluded that a neutral representation dedicated to the ship geometry can be derived from most proprietary representations without loss of essential information. (orig.) SIGLEAvailable from TIB Hannover: DtF QN 1 (24, 15) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekBundesministerium fuer Forschung und Technologie (BMFT), Bonn (Germany) DEGerman...|$|R
40|$|In recent years, {{there has}} been an {{increasing}} interest on renewable energy sources as substitute to fossil fuels. Among various processes of energy generation, electrochemical methods such as storage and conversion systems, electrolysis of water (production of H 2 and O 2), fuel cells, batteries, supercapacitors and solar cells have received great attention. The core of these energy technologies is a series of electrochemical processes, which directly depend on the nature of ‘electro catalyst’. The design and preparation of an electro catalyst is based on new concepts such as controlled surface roughness, atomic topographic profiles, defined catalytic sites, atomic rearrangements, and phase transitions during electrochemical reactions. Good electro catalysts should possess low over potential, high exchange current density, high stability, low cost and high abundance. The most fundamental reactions in the area of electrochemistry are hydrogen evolution (HER) and oxygen reduction (ORR) reactions. They are important in different energy systems such as fuel cells and batteries. Platinum has been a favoured electro catalyst due to its high activity, favourable density of states at Fermi level and chemical inertness. The low abundance, however, limits its large scale applications. Alternate materials with high catalytic activities are always required. In this particular direction, metal chalcogenides such as sulphides and selenides have attracted attention in recent years. The present thesis describes the synthesis of different phases of palladium and nickel chalcogenides and their applicability in various electrochemical reactions, both in aqueous and organic media. First part includes the synthesis of highly crystalline palladium selenide phases namely Pd 17 Se 15, Pd 7 Se 4 and Pd 4 Se by employing facile single source molecular precursor method. Pure palladium selenide phases are prepared by thrombolysis of highly <b>processable</b> intermediate complexes <b>formed</b> from metal and selenium precursors. Continuous films of different dimensions on various substrates (glass, ITO, FTO etc.) could be prepared (figure 1). This is one of the requirements for processing any new material. Thickness of the films could be altered by changing the volume of precursor complex coated on the substrate. All the phases are found to be metallic in nature with resistivity values in the range of 30 to 180 µΩ. cm. Figure 1. (a) Scanning electron micrograph and (b) photographic image of Pd 17 Se 15 prepared on different substrates glass (1), Si (2), fluorine doped tin oxide (FTO) (3) and DSSC solar cell fabricated using FTO coated Pd 17 Se 15 as the counter electrode (4). Other components of DSSC are given in the experimental section. All the palladium selenides phases are shown to be catalytically active towards electrochemical reactions such as HER and ORR. It is observed that the activities of the phases depend on the stoichiometric ratio of palladium to selenium. Higher the palladium content in the phase, higher is the catalytic activity observed. Therefore, the activities of the chalcogenides can be easily tuned by varying the ratio of metal to chalcogen. Tafel slopes of 50 – 60 mV/decade are observed for all three phases towards HER indicating that Volmer- Heyrovsky mechanism is operative. The exchange current densities are in the range of 2. 3 x 10 - 4 A cm- 2 to 6. 6 x 10 - 6 A cm- 2 (figure 2 a). Figure 2. (a) Linear sweep voltammograms of Pd 17 Se 15, Pd 7 Se 4 and Pd 4 Se in 0. 5 M H 2 SO 4 (HER) and (b) 0. 1 M KOH (ORR) at a scan rate of 2 mVs- 1. These phases are found to be highly robust and stable under different pH conditions. Stability of the phases is confirmed by characterizing the catalysts post-HER process, using various techniques such as XPS, XRD and SEM. High activities observed for Pd 4 Se is explained based on electrochemically active surface area values determined from under potential deposition studies and also based on DFT calculations. Computational studies reveal the presence of different charge distribution on palladium in all the three phases which is likely to be another reason for varied activities. Palladium selenides are also explored as catalysts towards ORR in alkaline medium. Kinetic parameters and reaction mechanism are determined using RDE studies. All the three phases are found to be active and Pd 4 Se shows the highest activity, following a direct 4 electron reduction pathway (figure 2 b). Other two phases follow 2 electron pathway terminating at hydrogen peroxide stage. Catalytic activity of Pd 17 Se 15 is further improved by Nano structuring of the material and by synthesizing the material on active supports such as rGO, acetylene black and today carbon. ORR {{plays an important role in}} metal-air batteries. The palladium chalcogenides are used as electrodes in metal-air batteries. Specific energy density observed in the case of Mg-air primary batteries is higher for Pd 4 Se than the other two phases (figure 3 a). Figure 3. (a) Discharge curves of Mg-O 2 battery with different phases of palladium selenides as cathodes. Constant current density of 0. 5 mA cm- 2 is used for discharge. (b) Characteristic J–V curves of DSSCs with Pd 17 Se 15, Pd 7 Se 4 and Pt as counter electrodes. Versatility of these phases is further studied towards redox reaction in non-aqueous medium (I 3 -/I-). This reaction plays a crucial role in the regeneration of the dye in dye-sensitized solar cells (DSSC). Palladium selenide phases prepared on FTO plates are employed as counter electrodes in DSSC. The solar light conversion efficiencies are found to be 7. 45 and 6. 8 % for Pd 17 Se 15 and Pd 7 Se 4 respectively and are comparable to that of platinum (figure 3 b). The reason for high activities may be attributed to high electronic conductivity and low work function of the phases. The following chapter deals with the synthesis of palladium sulphide phases (Pd 4 S and Pd 16 S 7) using both hydrothermal and single source precursor methods. Electro catalytic activities of the phases are shown towards HER and ORR and Pd 4 S exhibits better catalytic activities than that of Pd 16 S 7 phase. Direct electrochemistry of cytochrome c is achieved on Pd 4 S with ∆E of ~ 64 mV (figure 4 a). Electrochemical oxidation of ethanol, ethylene glycol (EG) and glycerol are also studied on the Pd 4 S phase and the activity is found to follow the order, glycerol > ethylene glycol > ethanol (figure 4 b). Figure 4. (a) Cyclic voltammograms of Pd 4 S in (1) 0. 1 M phosphate buffer solution (pH 7. 0) and (2) in presence of 0. 2 mM cytochrome c at a scan rate of 50 mVs- 1 and (b) Voltammograms of Pd 4 S in presence of different alcohols (ethanol, EG and glycerol) in 1 M KOH solution at sweep rate of 50 mVs- 1. Concentration of alcohols used is 0. 1 M. The effect of dimensionality on the electro catalytic activity of nickel selenide phases forms part of the next chapter. Nickel selenide (NiSe) nanostructures possessing diﬀerent morphologies of wires, spheres and hexagons are synthesized by varying the selenium precursors namely, selenourea, selenium dioxide (SeO 2) and potassium selenocyanate (KSeCN), respectively using hydrothermal method. The diﬀerent selenium precursors result in morphologies that are probably dictated by the by-products as well as relative rates of amorphous selenium formation and dissolution. The three diﬀerent morphologies are used as catalysts for HER, ORR and glucose oxidation reactions. The wire morphology is found to be better than that of spheres and hexagons for all the reactions. Among the reactions studied, NiSe is found to be good for HER and glucose oxidation while ORR seems to terminate at the peroxide stage. In alkaline medium, nickel forms hydroxides and oxy-hydroxides and these oxyhydroxides are catalytically active towards the oxidation of glucose. Therefore, nickel	selenides	are	employed	as	highly selective	non-enzymatic	glucose	sensors	and detection limit of 5 µM is observed. Electrical measurements on a single nanowire and a hexagon morphology of NiSe are carried out on devices fabricated by focused ion beam (FIB) technique (figure 5). The semiconducting nature of NiSe is revealed in the I-v measurements. The band gap of the material is found to be 1. 9 eV and hence the single nanowire and hexagon are shown to act as visible light photodetector. Figure 5. SEM images of (a) single NiSe nanowire and (b) single NiSe hexagon with Pt contacts fabricated by FIB technique. Figure 6. Cyclic voltammograms of NiSe nanowires in 0. 5 M aqueous NaOH in the (i) absence and (ii) the presence of 0. 5 mM glucose, at a scan rate of 20 mVs- 1 and (b) Galvanostatic discharge performance of Ni 3 Se 2 with different morphologies (A, B and C represent Ni 3 Se 2 prepared from SeO 2, selenourea and KSeCN respectively). The next chapter includes the synthesis of different morphologies of Ni 3 Se 2 using three different selenium precursors (SeO 2, KSeCN and selenourea) and the study of their activities towards electrochemical reactions such as HER and glucose oxidation (figure 6 a). Electrical measurements demonstrated the metallic behaviour of the material. These are also shown to be efficient electrode materials in energy storage devices such as supercapacitors with high specific capacitance of 2200 F/g (figure 6 b). The studies are summarized in the last chapter with scope for further work. The appendixes show preliminary studies on electrooxidation of glycerol and propanol on Pd supported on TiN, synthesis of other selenides of Ni, Cu, Ag and Ti, and electro synthesis of metal-organic frameworks. (For figures pl refer the abstract pdf file...|$|R
40|$|Handwritten pattern {{recognition}} involves conversion of scanned images of handwritten patterns {{into a computer}} <b>processable</b> <b>form.</b> To recognize handwritten patterns is an easy and trivial task for human beings, but for a machine it is a cumbersome and a difficult task due to high variations {{in the shape of}} characters and writing style. Although complicated to train, yet machines can be useful in providing solution to the recognition problem. They save time and money and eliminate the requirement of execution of repetitive tasks by humans. In order to have better recognition the image should be properly pre-processed. Pre-processing reduces and eliminates noise and irregularities. The present paper focuses on different approaches to pre-processing and an insight to general methodology for the recognition process...|$|E
40|$|The Systematized Nomenclature of Medicine, Third Edition, SNOMED International, is a {{comprehensive}} structured nomenclature of human and veterinary medicine, the terms of which are detailed, fine grained and semantically typed. Terms are assigned to eleven independent modules (fields), {{each of which is}} systematized. Terms may be linked to on another to represent complex entities or manifestations or alternately complex terms dissected into their elemental parts. Terms are illustrated utilizing a frame representation. Efforts are in progress to build both a conceptual graph and a frame-based semantic network encompassing each SNOMED term, effectively building a knowledge base. In this way, the knowledge contained in each alphanumeric representation is made explicit. SNOMED is a linked data structure capable of faithfully representing the activities, observations and diagnoses found in the medical record in a computer <b>processable</b> <b>form...</b>|$|E
40|$|In 1997, the American Medical Informatics Association {{proposed}} a US information strategy {{that included a}} population health record (PopHR). Despite subsequent progress on the conceptualization, development, and implementation of electronic health records and personal health records, minimal progress has occurred on the PopHR. Adapting International Organization for Standarization electronic health records standards, we define the PopHR as a repository of statistics, measures, and indicators regarding the state of and influences {{on the health of}} a defined population, in computer <b>processable</b> <b>form,</b> stored and transmitted securely, and accessible by multiple authorized users. The PopHR is based upon an explicit population health framework and a standardized logical information model. PopHR purpose and uses, content and content sources, functionalities, business objectives, information architecture, and system architecture are described. Barriers to implementation and enabling factors and a three-stage implementation strategy are delineated...|$|E
40|$|Clinical {{questions}} are often studied by randomized clinical trials (RCTs) of heterogeneous design. Systematic reviewers and trial designers need {{to compare the}} design and results across these trials. If trial information is available in computer <b>processable</b> <b>form,</b> computer-based visualization techniques can provide cognitive support for such comparisons. CTeXplorer offers systematic reviewers and trial designers a tool to better and more quickly understand design heterogeneity in RCTs. CTeXplorer supports dynamic queries on eligibility criteria, interventions, and outcomes in three linked views. We tested CTeXplorer for displaying 12 RCTs on prevention of mother-to-child transmission of HIV. Three target users found the representation and organization of information intuitive and easy to learn. They {{were able to use}} CTeXplorer to achieve a quick cognitive overview of a heterogeneous group of RCTs. This work shows the benefit of capturing trial information in computable form. Future work includes leveraging ontologies to enhance CTeXplorer visualizations...|$|E
40|$|Abstract—There {{are many}} {{problems}} associated with the World Wide Web: getting lost in the hyperspace; the web content is still accessible only to humans and difficulties of web administration. The solution to these problems is the Semantic Web which is considered to be the extension for the current web presents information in both human readable and machine <b>processable</b> <b>form.</b> The aim {{of this study is to}} reach new generic foundation architecture for the Semantic Web because there is no clear architecture for it, there are four versions, but still up to now there is no agreement for one of these versions nor is there a clear picture for the relation between different layers and technologies inside this architecture. This can be done depending on the idea of previous versions as well as Gerber’s evaluation method as a step toward an agreement for one Semantic Web architecture...|$|E
40|$|The {{everyday}} {{programming and}} maintenance activities {{make use of}} knowledge about programming-related tech-nologies such as graphical interfaces (GUIs) or XML. Hav-ing this knowledge in a machine <b>processable</b> <b>form</b> supports the automation of typical maintenance activities such as concept location and raise the abstraction level at which the current code analyses are performed. In this paper we promote our current project of building a repository of on-tologies 1 that contain knowledge about programming tech-nologies. We propose a method for extracting these on-tologies by analyzing the commonalities of different APIs that address the same domain. We discuss the motivation for such a repository in form of possible usage directions and present our experience with building and using ontolo-gies that share technical knowledge about GUIs and XML. Based on our experience we discuss the challenges of build-ing and evolving the repository and discuss how can the se-mantic web technologies contribute to this endeavor. ...|$|E
40|$|The International Standards Organization (ISO) {{has defined}} a {{protocol}} test language called TTCN (Tree and Tabular Combined Notation) to specify abstract test suites for Open Systems Interconnection (OSI) protocols. TTCN combines a tree notation for dynamic behaviour description with a tabular representation of various language constructs. TTCN allows tabular constraints to enforce values on the Abstract Service Primitive (ASP) or Protocol Data Unit (PDU) parameters. For application layer protocols, Abstract Syntax Notation One (ASN. 1) constraints are used. Dynamic behaviour description in TTCN {{is shown to}} address many important aspects of conformance testing such as modularity support in terms of test cases, steps and default behaviour tables and sophisticated timer management. TTCN has a machine <b>processable</b> <b>form</b> called TTCN-MP that defines all the TTCN syntax using BNF. Semantics of the tests specified in TTCN is operationally defined rendering TTCN almost a formal notation. © 1992...|$|E
40|$|Abstract. Digital Libraries {{organized}} {{collections of}} multimedia objects {{in a computer}} <b>processable</b> <b>form.</b> They also comprise services and infrastructures to manage, store, retrieve and share objects. Among these services, personalization services represent an active and broad area of digital library research. A popular way to realize personalization is by using information filtering techniques aiming to remove redundant or unwanted information from data. In this paper we propose to use a probabilistic framework based on uncertain graphs {{in order to deal}} with information filtering problems. Users, items and their relationships are encoded in a probabilistic graph that can be used to infer the probability of existence of a link between entities involved in the graph. The goal of the paper is to extend uncertain graphs definition to multigraphs and to study whether uncertain graphs could be used as a valuable tool for information filtering problems. The performance of the proposed probabilistic framework is reported when applied to a real-world domain. ...|$|E
40|$|It {{has long}} been {{realized}} that the web could benefit from having its content understandable and available in a machine <b>processable</b> <b>form.</b> The Semantic Web aims to achieve this via annotations that use terms defined in ontologies to give well defined meaning to Web accessible information and services. OWL, the ontology language recommended by the W 3 C for this purpose, was heavily influenced by Description Logic research. In this chapter we review briefly some early efforts that combine Description Logics and the Web, including predecessors of OWL such as OIL and DAML+OIL. We {{then go on to}} describe OWL in some detail, including the various influences on its design, its relationship with RDFS, its syntax and semantics, and a range of tools and applications. 1 14. 1 Background and history The World Wide Web, while wildly successful in growth, may be viewed as being limited by its reliance on languages such as HTML that are focuse...|$|E
40|$|Since its {{emergence}} in the 1990 s the World Wide Web (WWW) has rapidly {{evolved into}} a huge mine of global information and it is growing in size everyday. The presence of huge amount of resources on the Web thus poses a serious problem of accurate search. This is mainly because today's Web is a human-readable Web where information cannot be easily processed by machine. Highly sophisticated, efficient keyword based search engines that have evolved today {{have not been able}} to bridge this gap. So comes up the concept of the Semantic Web which is envisioned by Tim Berners-Lee as the Web of machine interpretable information to make a machine <b>processable</b> <b>form</b> for expressing information. Based on the semantic Web technologies we present in this paper the design methodology and development of a semantic Web search engine which provides exact search results for a domain specific search. This search engine is developed for an agricultural Website which hosts agricultural information about the state of West Bengal. Comment: 9 pages, 11 figures, MSPT 2007 - 7 th International Workshop on MSPT Proceeding...|$|E
40|$|Social web content such as blogs, videos, {{and other}} user-generated content present a vast source of rich "digital-traces" of individuals&# 039; experiences. The use of digital traces to {{provide insight into}} human {{behavior}} remains underdeveloped. Recently, ontological approaches have been exploited for tagging and linking digital traces, with progress made in ontology models for well-defined domains. However, the process of conceptualization for ill-defined domains remains challenging, requiring interdisciplinary efforts to understand the main aspects and capture them in a computer <b>processable</b> <b>form.</b> The primary contribution {{of this article is}} a theory-driven approach to ontology development that supports semantic augmentation of digital traces. Specifically, we argue that (a) activity theory can be used to develop more insightful conceptual models of ill-defined activities, which (b) can be used to inform the development of an ontology, and (c) that this ontology can be used to guide the semantic augmentation of digital traces for making sense of phenomena. A case study of interpersonal communication is chosen to illustrate the applicability of the proposed multidisciplinary approach. The benefits of the approach are illustrated through an example application, demonstrating how it may be used to assemble and make sense of digital traces...|$|E
40|$|More {{information}} {{is now being}} published in machine <b>processable</b> <b>form</b> on the web and, as de-facto distributed knowledge bases are materializing, partly encouraged by {{the vision of the}} Semantic Web, the focus is shifting from the publication of this information to its consumption. Platforms for data integration, visualization and analysis that are based on a graph representation of information appear first candidates to be consumers of web-based information that is readily expressible as graphs. The question is whether the adoption of these platforms to information available on the Semantic Web requires some adaptation of their data structures and semantics. Ondex is a network-based data integration, analysis and visualization platform which has been developed in a Life Sciences context. A number of features, including semantic annotation via ontologies and an attention to provenance and evidence, make this an ideal candidate to consume Semantic Web information, as well as a prototype for the application of network analysis tools in this context. By analyzing the Ondex data structure and its usage, we have found a set of discrepancies and errors arising from the semantic mismatch between a procedural approach to network analysis and the implications of a web-based representation of information. We report in the paper on the simple methodology that we have adopted to conduct such analysis, and on issues that we have found which may be relevant for a range of similar platformsComment: Presented at DEIT, Data Engineering and Internet Technology, 2011 IEEE: CFP 1113 L-CD...|$|E
40|$|This {{dissertation}} {{examines the}} consequences of Electronic Data Interchange (EDI) use on interorganizational relations (IR) in the retail industry. EDI {{is a type of}} interorganizational information system that facilitates the exchange of business documents in structured, machine <b>processable</b> <b>form.</b> The research model links EDI use and three IR dimensions [...] structural, behavioral, and outcome. Based on relevant literature from organizational theory and marketing channels, fourteen hypotheses were proposed for the relationships among EDI use and the three IR dimensions. ^ Data were collected through self-administered questionnaires from key informants in 97 retail companies (19 % response rate). The hypotheses were tested using multiple regression analysis. The analysis supports the following hypothesis: (a) EDI use is positively related to information intensity and formalization, (b) formalization is positively related to cooperation, (c) information intensity is positively related to cooperation, (d) conflict is negatively related to performance and satisfaction, (e) cooperation is positively related to performance, and (f) performance is positively related to satisfaction. The results support the general premise of the model that the relationship between EDI use and satisfaction among channel members has to be viewed within an interorganizational context. ^ Research on EDI is still in a nascent stage. By identifying and testing relevant interorganizational variables, this study offers insights for practitioners managing boundary-spanning activities in organizations using or planning to use EDI. Further, the thesis provides avenues for future research aimed at understanding {{the consequences of}} this interorganizational information technology. ...|$|E
40|$|Context-aware systems being a {{component}} of ubiquitous or pervasive computing environment sense the users’ physical and virtual surrounding to adapt their behaviour accordingly. To achieve activity context tracking devices are common practice. Service Oriented Architecture is based on collections of services that communicate with each other. The communication between users and services involves data {{that can be used}} to sense the activity context of the user. SOAP is a simple protocol to let applications exchange their information over the web. Semantic Web provides standards to express the relationship between data to allow machines to process data more intelligently. This work proposes an approach for supporting context-aware activity sensing using software sensors. The main challenges in the work are specifying context information in a machine <b>processable</b> <b>form,</b> developing a mechanism that can understand the data extracted from exchanges of services, utilising the data extracted from these services, and the architecture that supports sensing with software sensors. To address these issues, we have provided a bridge to combine the traditional web services with the semantic web technologies, a knowledge structure that supports the activity context information in the context-aware environments and mapping methods that extract the data out of exchanges occurring between user and services and map it into a context model. The Direct Match, the Synonym Match and the Hierarchical Match methods are developed to put the extracted data from services to the knowledge structure. This research will open doors to further develop automated and dynamic context-aware systems that can exploit the software sensors to sense the activity of the user in the context-aware environments. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|The work {{described}} in this paper was undertaken {{with the objective of}} simplifying the process of clinical research data acquisition to enable researchers to analyze data conveniently, economically and comprehensively. Though the Clinical Center differs from the community general hospitals, and even the university medical centers in many respects, its day-to-day operations are closely parallel to those in other hospitals. Therefore, it was felt that it would be worthwhile to consider the installation of the type of computerized medical information system used in the general hospitals and to tailor it to the specific research data capture needs which are characteristic of the NIH. After describing areas of similarity and difference in comparisons between the general hospital and the Clinical Center from the data processing perspective, consideration is given to the research data capture needs for Clinical Center patients. Discussions of systems involving data capture while the patient is undergoing active treatment, as well as those which are best captured in batch processes, are discussed. Finally, the state of development and use of the comprehensive Clinical Information Utility for the NIH researchers is described, including examples of its use. The system {{described in}} the paper represents one of the first attempts to make post-discharge use of inpatient medical care data derived from an on-line real-time hospital-wide information system. Already the results obtained from the initial exercises using the Clinical Information Utility have shown that the availability of all patient care information in computer <b>processable</b> <b>form,</b> generated {{as a result of the}} clinical efforts, will have tremendous impact on the quality and timeliness of research data processing at the NIH...|$|E
40|$|A Doctoral Thesis. Submitted in partial {{fulfilment}} of {{the requirements}} for the award of Doctor of Philosophy of Loughborough University. The increasing use of computers for document preparation and publishing coupled with a growth in the general information management facilities available on computers has meant that most documents exist in computer <b>processable</b> <b>form</b> during their lifetime. This {{has led to a}} substantial increase in the demand for data storage facilities, which frequently seems to exceed the provision of storage facilities, despite the advances in storage technology. Furthermore, there is growing demand to transmit these textual documents from one use to another, rather than use a printed form for transfer between sites which then needs to be re-entered into a computer at the receiving site. Transmission facilities are, however, limited and large documents can be difficult and expensive to transmit. Problems of storage and transmission capacity can be alleviated by compacting the textual information beforehand, providing that there is no loss of information in this process. Conventional compaction techniques have been designed to compact all forms of data (binary as well as text) and have, predominantly, been based on the byte as the unit of compression. This thesis investigates the alternative of designing a compaction procedure for natural language texts, using the textual word as the unit of compression. Four related alternative techniques are developed and analysed in the thesis. These are designed to be appropriate for different circumstances where either maximum compression or maximum point to point transmission speed is of greatest importance, and where the characteristics of the transmission, or storage, medium may be oriented to a seven or eight bit data unit. The effectiveness of the four techniques is investigated both theoretically and by practical comparison with a widely used conventional alternative. It is shown that {{for a wide range of}} textual material the word based techniques yield a greater compression and require substantially less processing time...|$|E

