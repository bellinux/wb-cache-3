95|231|Public
25|$|Absolute {{pitch is}} the ability to {{perceive}} pitch class and to mentally categorize sounds according to perceived pitch class. A pitch class is a set of all pitches that are a whole number of octaves apart. While the boundaries of musical pitch categories vary among human cultures, the recognition of octave relationships is a natural characteristic of the mammalian auditory system. Accordingly, absolute pitch is not the ability to estimate a <b>pitch</b> <b>value</b> from the dimension of pitch evoking frequency (30–5000Hz), but to identify a pitch class category within the dimension of pitch class (e.g., C-C-D... B-C).|$|E
50|$|Screw threads {{are almost}} never made {{perfectly}} sharp (no truncation {{at the crest}} or root), but instead are truncated, yielding a final thread depth that can be expressed as {{a fraction of the}} <b>pitch</b> <b>value.</b> The UTS and ISO standards codify the amount of truncation, including tolerance ranges.|$|E
50|$|The musical forms {{within the}} Cantigas, {{and there are}} many, are still being studied. There have been many false leads, {{and there is little}} beyond <b>pitch</b> <b>value</b> that is very reliable. Mensuration is a {{particular}} problem in the Cantigas, and most attempts at determining meaningful rhythmic schemes have tended, with some exceptions, to be unsatisfactory. This remains a lively topic of debate and study. Progress, while on-going, has nevertheless been significant {{over the course of the}} last 20 years.|$|E
3000|$|... (y) are the {{standard}} deviations of the source and target <b>pitch</b> <b>values,</b> respectively. In this case, the {{mean and standard deviation}} of the converted pitch contour match the mean and standard deviation of the <b>pitch</b> <b>values</b> of the target speaker.|$|R
30|$|Standard Deviation (SD) is the {{standard}} deviation of the absolute differences between the estimated and reference <b>pitch</b> <b>values.</b>|$|R
50|$|The {{precision}} <b>pitch</b> <b>values</b> {{may be used}} in microtonal music, just intonation, meantone temperament, {{or other}} alternative tunings.|$|R
50|$|When {{continuous}} {{white noise}} (with a frequency content below about 2000 Hz) is presented by headphones {{to the left}} and right ear of a listener, and given a particular interaural phase relationship between the left and right ear signals, a sensation of pitch (psychophysics) may be observed. Thus, stimulation of either ear alone gives rise to the sensation of white noise only, but stimulation of both ears together produces pitch. Therefore, as a special case of dichotic listening, such a pitch is called dichotic pitch or binaural pitch. Generally, a dichotic pitch is perceived somewhere in the head amidst the noisy sound filling the binaural space. To be more specific, the dichotic pitch is characterized by three perceptual properties: <b>pitch</b> <b>value,</b> timbre, and in-head position (lateralization). Experiments on dichotic pitch were motivated {{in the context of the}} study of pitch in general, and of the binaural system in particular, relevant for sound localization and separation of competing sound sources (see cocktail party effect). In the past, various configurations of dichotic pitch were studied and several auditory models were developed. The great challenge for psychophysical and physiological acoustics is to predict both the <b>pitch</b> <b>value</b> and pitch-image position in one model. For more information, references, audio demos etc. see more.|$|E
5000|$|Absolute {{pitch is}} the ability to {{perceive}} pitch class and to mentally categorize sounds according to perceived pitch class. A pitch class is a set of all pitches that are a whole number of octaves apart. While the boundaries of musical pitch categories vary among human cultures, the recognition of octave relationships is a natural characteristic of the mammalian auditory system. Accordingly, absolute pitch is not the ability to estimate a <b>pitch</b> <b>value</b> from the dimension of pitch evoking frequency (30-5000 Hz), but to identify a pitch class category within the dimension of pitch class (e.g., C-C-D ... B-C).|$|E
5000|$|The basic {{principles}} of the ISO metric screw thread are defined in international standard ISO 68-1 and preferred combinations of diameter and pitch are listed in ISO 261. The smaller subset of diameter and pitch combinations commonly used in screws, nuts and bolts is given in ISO 262. The most commonly used <b>pitch</b> <b>value</b> for each diameter is the coarse pitch. For some diameters, one or two additional fine pitch variants are also specified, for special applications such as threads in thin-walled pipes. ISO metric screw threads are designated by the letter M followed by the major diameter of the thread in millimeters (e.g. M8). If the thread does not use the normal coarse pitch (e.g. 1.25 mm {{in the case of}} M8), then the pitch in millimeters is also appended with a multiplication sign (e.g. [...] "M8×1" [...] if the screw thread has an outer diameter of 8 mm and advances by 1 mm per 360° rotation).|$|E
3000|$|... where f_ 0 ^(x),t and f̂_ 0 ^(y),t are the <b>pitch</b> <b>values</b> of {{the source}} and {{converted}} signals at the tth frame, respectively. The parameters μ [...]...|$|R
50|$|The TIA also {{provides}} two channels of one-bit sound. Each channel provides for 32 <b>pitch</b> <b>values</b> and 16 possible bit sequences. There is a 4 bit volume control.|$|R
40|$|In {{order to}} {{properly}} represent pitch accent patterns of word/phrases in sentence utterances of Japanese, {{we proposed a}} new approach of representing a pitch pattern as a sequence of F 0 s in mora unit (F 0 mora). Several candidates for F 0 mora were defined, and their distributions were obtained for each accent type, and these distributions were used to recognition task. Then, the candidates of F 0 mora were checked how they were related to perceived mora <b>pitch</b> <b>values.</b> For this purpose, MIDI sounds were used as references to be compared with perceived mora <b>pitch</b> <b>values,</b> and a tool (software) was constructed to allow subjects to adjust MIDI sound pitch. We used syllables segmented from natural utterances, and asked subjects to adjust MIDI sound pitch to the perceived pitch of a syllable. For each syllable, a value was calculated as an average of MIDI sound <b>pitch</b> <b>values</b> among subjects and {{was used as the}} human-perceived mora <b>pitch.</b> Then, this <b>value</b> was compared with the candidates of the corresponding F 0 mora...|$|R
5000|$|After {{the initial}} launch the Numark units {{received}} mixed reviews, with several flaws and inadequate quality assurance being pointed out. Some found the tonearm as supplied was not accurately calibrated or properly {{aligned with the}} platter, {{but it can be}} tweaked and adjusted to perform well. The platter in some cases exhibited noticeable warp or axial run-out, which appears to be in part due to the ceramic ring magnetic that secures the platter to the spindle not being glued correctly to the underside of the platter. Some reviewers complained that the pitch system was not calibrated accurately, although not off by much. On later production models, probably the Pro TT-2 only, it is reported that access holes are provided {{on the bottom of the}} turntable base to permit pitch calibration using a screwdriver. Others considered the LCD display to be of little practical value since the <b>pitch</b> <b>value</b> shown is not precise. Also, in some cases the stylus pressure ring on the tonearm counterbalance weight assembly turns much too freely. And, unfortunately, the dust cover hinges eventually fail due to cracking at the bottom of the plastic housing for the counterbalance spring which is under the constant load of the stiff spring. One failed hinge keeps the dust cover from staying open when raised.|$|E
3000|$|In general, the humming {{and music}} data are {{represented}} as magnitude values on a time axis. By using short time Fourier transform (STFT), the pitch (fundamental frequency) can be {{extracted from the}} humming and music data. Although the <b>pitch</b> <b>value</b> corresponds to musical notes (e.g., the pitch values 440 and 494 Hz represent the musical notes [...] "la" [...] and [...] "ti" [...] respectively [1]), there exist fluctuations in the <b>pitch</b> <b>value</b> caused by the errors in pitch extraction (tracking) due to background noise. To overcome these problems, the note-based method was introduced, where the pitch sequence is segmented into (musical) notes [2]. Since the notes have characteristics of discrete values (i.e., [...] "do", [...] "re", [...] "mi", etc.), the note-based method {{is similar to that}} representing continuous pitch values as quantized ones. Through representation as discrete values, fluctuation in the <b>pitch</b> <b>value</b> can be reduced, and the possibility of the existence of the same note in some period is increased. Thus, additional features such as the musical interval, duration, and tempo can be used in the note-based method [3 – 8]. However, inaccurate note segmentation from the <b>pitch</b> <b>value</b> can degrade the matching accuracy. Thus, the frame-based method, which uses the original pitch values as features, has also been studied [2, 9 – 12].|$|E
30|$|The {{speech signal}} is {{processed}} in overlapping frames. Each frame is further divided into several nonoverlapping subframes. A <b>pitch</b> <b>value</b> is determined for each subframe. These pitch values are obtained using a robust pitch tracking algorithm described in [41]. In {{order to get}} the pitch rate of a given frame, we first calculate the median value of the subframe pitch values for the frame to set a threshold: if any subframe <b>pitch</b> <b>value</b> is larger than twice this threshold, it is divided by 2; if any <b>pitch</b> <b>value</b> is smaller than half the threshold, it is multiplied by 2. By this, octave confusions are largely eliminated. Then, a straight line was fitted to all the corrected pitch values in this frame. The pitch rate is taken as the slope of this fitted line. For unvoiced speech, the transform order will be 1 because no pitch is detected.|$|E
50|$|This application: http://equal.meteor.com/ calculates the frequencies, {{approximate}} cents, and MIDI <b>pitch</b> bend <b>values</b> for any {{systems of}} equal {{division of the}} octave. Note that 'rounded' and 'floored' produce the same MIDI <b>pitch</b> bend <b>value.</b>|$|R
50|$|In digital recording, pitch {{shifting}} {{is accomplished}} through digital signal processing. Older digital processors could often only shift pitch in post-production, whereas many modern devices using computer processing technology can change <b>pitch</b> <b>values</b> virtually in real time.|$|R
5000|$|... #Caption: Fig. 1: An {{example of}} how {{multiple}} samples can be arranged across a keyboard range. In this example, four different recordings of a violin are distributed across 12 notes. Each sample will play back at three different <b>pitch</b> <b>values</b> ...|$|R
40|$|Absolute {{pitch in}} music means an ability of {{long-term}} auditory memory to store pitch stan-dards corresponding to within-octave musical pitch classes, {{based on a}} generally recognized reference pitch. Such an ability, extremely rare among Western musicians, appears much more commonly among musicians of Asiatic countries. Hypothetically, it is due to either the special forms and early beginnings of musical education (Japan), or {{to a sort of}} preconditioning of the pitch-memory system in infants and very young children, to treat <b>pitch</b> <b>value</b> as a mean-ingful element of speech communication (countries with tone languages). Similarities and differences between absolute pitch in music and the memory for <b>pitch</b> <b>value</b> in tone languages will be discussed in detail...|$|E
30|$|In Carnatic music, each music note (swara) can {{represent}} {{more than one}} <b>pitch</b> <b>value,</b> usually two, according to the raga followed by the composition. Because of this characteristic, they are called “note varieties” as each swara note provides many colors to choose from.|$|E
40|$|Traditionally the {{interest}} in voice-gender conversion was of a more theoretical nature rather than founded in real–life applications. However, {{with the increase in}} biometric security applications, mobile and automated telephonic communication and the resulting limitation in transmission bandwidth, practical applications of gender recognition have increased many folds. In this paper, using various speech processing techniques and algorithms, two models were made, one for generating Formant values of the voice sample and the other for generating <b>pitch</b> <b>value</b> of the voice sample. These two models were to be used for extracting gender biased features, i. e. Formant 1 and <b>Pitch</b> <b>Value</b> of a speaker. A preprocessing model was prepared in LabView for filtering out the noise components and also to enhance the high frequency formants in the voice sample. To calculate the mean of formants and pitch of all the samples of a speaker, a model containing loop and counters were implemented which generated a mean of Formant 1 and <b>Pitch</b> <b>value</b> of the speaker. Using nearest neighbor method, calculating Euclidean distance from the Mean value of Males and Females of the generated mean values of Formant 1 and Pitch, the speaker was classified between Male and Female. The algorithm was implemented in real time using NI LabVIEW...|$|E
30|$|The {{calibration}} of the Multibeam {{data has}} been carried out through the acquisition of some lines. Heading and <b>pitch</b> <b>values</b> have been easily found, whereas the roll values have been difficult to obtain due to the roughness of the sea bottom morphology.|$|R
40|$|In low {{bit rate}} speech coders, pitch is usually {{transmitted}} once per frame and, when needed, the intermediate <b>pitch</b> <b>values</b> are obtained by interpolation between 2 adjacent <b>pitch</b> <b>values.</b> Although <b>pitch</b> usually evolves slowly, sometimes it has irregular variations and the estimated pitch differs from the real one. In addition, some speech coders, e. g., waveform interpolation coders, rely on smooth pitch-cycle evolutions to extract speech model parameters in the analysis stage. However, non-stationary characteristics of speech may lead to inaccurate estimation of the parameters. This affects the synthesised speech quality. We propose a pre-processor, which modifies the residual speech signal to provide smooth pitch vari-ations and pitch-cycle evolutions, without distorting perceptual speech quality. Thus, the pitch and the voicing level can be more accurately determined...|$|R
5000|$|Although gears can be {{made with}} any pitch, for {{convenience}} and interchangeability standard pitches are frequently used. Pitch is a property associated with linear dimensions and so differs whether the standard values are in the Imperial (inch) or Metric systems. Using inch measurements, standard diametral <b>pitch</b> <b>values</b> with units of [...] "per inch" [...] are chosen; the diametral pitch is the number of teeth on a gear of one inch pitch diameter. Common standard values for spur gears are 3, 4, 5, 6, 8, 10, 12, 16, 20, 24, 32, 48, 64, 72, 80, 96, 100, 120, and 200. Certain standard pitches such as 1/10 and 1/20 in inch measurements, which mesh with linear rack, are actually (linear) circular <b>pitch</b> <b>values</b> with units of [...] "inches" ...|$|R
40|$|The musical staff notates <b>Pitch</b> <b>Value</b> Vectors whereas tablature, using fret {{numbers on}} string lines, denotes Position Value Vectors, forming a {{commuting}} algebra of Hilbert Spaces. In 2001 I demonstrated {{that music is}} semi-algebraic (Allen and Goudessenue). <b>Pitch</b> <b>Value</b> Space is undefined without a connection to pitch, and when connected to pitch by a barycenter, becomes defined and complete. A defined musical system must have at least 2 functions, the chromatic f(x) and the harmonic function g(x) that form a composite function with at most 1 common center (Music Multicentricity Theorem). Thus tonality {{is defined by the}} line of tonal projection that marries pitch to position to make a musical tone. Since musical systems must have a tone generator (instrument or device) the music topos must be the triple composite function f⋅g⋅h where f(x) is a + b + c = 0 and g(x) > 0 is a scale center and h(x) > 0 an instrument center. A music cipher as defined here as an affine projection that marries R:Z pitch to position to compose a note [tone point as an orthonormal pair (position value, <b>pitch</b> <b>value)</b> ]. The harmonic message is embedded in a musical system by the ciphe...|$|E
30|$|As {{shown in}} Figure 8, the pitch values of - 4.53 and 5.00 are {{represented}} as 000000000 and 111111111, respectively. The <b>pitch</b> <b>value</b> of - 2.12 is represented as 000000011. The optimal {{number of the}} section shown in Figure 8 was experimentally determined to be 10.|$|E
40|$|Memory {{behavior}} in the ferroelectric liquid crystal � FLC � material, Felix 17 / 100, has been investigated by electro-optical, dielectric, and hysteresis methods at different temperatures ranging from room temperature to near ferro-paraelectric phase transition. Memory effect has been observed in the studied material near the transition temperature in Sm C � phase in the cells having thickness greater than the <b>pitch</b> <b>value</b> of the material. This {{is in contrast to}} the memory effect observed in conventional FLCs where thickness of the cell has to be less than the <b>pitch</b> <b>value</b> of the material. Electrical conductivity measurements elucidate that the steep increase in the conductivity near the transition temperature in Sm C* phase enhances the motion of free ions and probably weakens the depolarization field in the material, thereby showing memory effect...|$|E
30|$|In this study, two open {{databases}} {{were used}} to compare accuracy like [13]: the 2006 MIREX QBSH corpus and 2009 MIR-QBSH corpus. These two are {{the most commonly used}} for performance comparisons [26, 27]. They include 48 MIDI files as original music melodies. The 2006 MIREX QBSH corpus was used for the Query by Singing and Humming (QBSH) International Contest (MIREX 2006, 2007 and 2008). There are 2, 797 singing and humming queries, and they are stored in the wave file format. The 2009 MIR-QBSH corpus was used in MIREX 2009. Although the number of MIDI files is the same to that of the 2006 MIREX QBSH corpus, the number of singing and humming queries was increased to 4, 431. Both the 2006 MIREX QBSH corpus and 2009 MIR-QBSH corpus were collected from 118 persons using telephones, microphones, etc. to consider various recording conditions. In the first experiment, the pitch vector (PV) files of the databases were used for performance comparisons. The <b>pitch</b> <b>values</b> in the PV files were manually extracted; they were mainly used for the matching performance excluding the performance of the pitch extractor. The sampling period of <b>pitch</b> <b>values</b> in the PV file was 32 ms, and there were 250 <b>pitch</b> <b>values</b> in each query file since the recording time was 8 s [13, 14, 17].|$|R
3000|$|For pitch-normalization of the {{children}} test set [...] "CH 1 ", the signals are transformed to seven different <b>pitch</b> <b>values</b> ranging from 70 [*]Hz to 250 [*]Hz with a step size of 30 [*]Hz. Such pitch range has been chosen based on the pitch distribution of the training data as shown in Figure 2.|$|R
30|$|Interestingly, {{the gender}} {{dependencies}} {{observed in the}} previous experiments also arise in Figure 8. Indeed, listeners seem to prefer the female voices of STRAIGHT and the male voices of HMPD- σ. As mentioned in Section 4, this phenomenon {{is due to the}} inherent limitations of harmonic modeling at high <b>pitch</b> <b>values.</b> Forthcoming works will address this issue.|$|R
40|$|Multi-pitch {{estimation}} of co-channel speech is especially challenging when the underlying pitch tracks are close in <b>pitch</b> <b>value</b> (e. g., when pitch tracks cross). Building on our previous work in [1], we demonstrate {{the utility of}} a two-dimensional (2 -D) analysis method of speech for this problem by exploiting its joint representation of pitch and pitch-derivative information from distinct speakers. Specifically, we propose a novel multi-pitch estimation method consisting of 1) a datadriven classifier for pitch candidate selection, 2) local pitch and pitch-derivative estimation by k-means clustering, and 3) a Kalman filtering mechanism for pitch tracking and assignment. We evaluate our method on a database of allvoiced speech mixtures and illustrate its capability to estimate pitch tracks in cases where pitch tracks are separate {{and when they are}} close in <b>pitch</b> <b>value</b> (e. g., at crossings) ...|$|E
30|$|Therefore, on {{noting the}} high degree of {{variation}} in the average pitch values of the children's and the adults' speech data and the effect of high <b>pitch</b> <b>value</b> on the smooth spectrum corresponding to MFCC feature, it is hypothesized that pitch-normalization would significantly improve the ASR performance for children's speech due to reduction in the pitch-dependent distortions observed in the spectral envelope.|$|E
30|$|According to the observations, we may {{compute the}} average opening angle, the maximum and minimum leg pitch values for normal walking and walking upstairs/downstairs during offline phase. The related angle values {{can be seen}} as the <b>pitch</b> <b>value</b> pattern. During online phase, the {{pattern-matching}} process comparing the related angles as seen in (2) and (3) may be carried to distinguish between normal walking and walking upstairs/downstairs.|$|E
40|$|We {{present a}} study of the prosody – seen in a broader sense – that {{supports}} the theory of the interrelationship function of speech. “Pure emotions ” show a relationship of the speaker with the general context. The analysis goes beyond the basic prosody, as related to <b>pitch</b> <b>values,</b> <b>pitch</b> trajectory, sound duration and pauses; the analysis also aims to determine the change in higher formants. The refinement in the analysis asks for finer tools. Methodological aspects are discussed, including limitations of the currently available tools. Some conclusions are drawn...|$|R
2500|$|The Captain {{ordered a}} Go Around at 12:56 {{with a call}} of [...] "Go Around, Flaps 8‟. At that time, the {{aircraft}} was at , with speed of [...] For the Go Around, thrust was opened to about 89–90%; pitch attitude was increased initially to about 8 degrees nose up which came down subsequently to lower <b>pitch</b> <b>values.</b> Landing gear was not selected up.|$|R
40|$|Zinc oxide nanorod films {{produced}} by glancing angle deposition were fabricated within the parameter space {{defined by the}} process variables pitch (nanorod growth per substrate rotation), deposition rate, and throw distance to investigate the effect these parameters have on morphology and crystallinity. Statistical {{analysis was used to}} identify important relationships. Final film morphology depends on both pitch and deposition rate, where two growth regimes distinguished by deposition rate are observed and interpreted as arising from competition between geometric shadowing and crystalline growth kinetics. Optimal growth conditions for nanostructured films of isolated zinc oxide nanorods occurred for <b>pitch</b> <b>values</b> of approximately 1 nm to 10 nm. Pole-figure measurements confirm that the films consist of oriented single-crystal nanorods. Films deposited at all <b>pitch</b> <b>values</b> between 0. 001 nm to 6. 5 3 ̆bcm are crystalline and textured, and greater texturing is achieved for conditions of decreased surface diffusion. 9 2011 Elsevier B. V. All rights reserved. Peer reviewed: YesNRC publication: Ye...|$|R
