15|688|Public
5000|$|... 1451.1-1999 IEEE Standard for a Smart Transducer Interface for Sensors and Actuators - Network Capable Application <b>Processor</b> <b>Information</b> Model ...|$|E
50|$|Since {{the value}} {{reported}} by PECI {{takes into account}} internal <b>processor</b> <b>information</b> about safe operating temperatures, it alleviates {{the need for the}} BIOS or operating system to make potentially incorrect assumptions about this limit. Furthermore, it supports dynamic fan control {{with a high degree of}} accuracy, where fan speed can be progressively increased as the value approaches zero.|$|E
5000|$|Often {{memory is}} {{understood}} as an informational processing system with explicit and implicit functioning that {{is made up of}} a sensory processor, short-term (or working) memory, and long-term memory (Baddely, 2007) [...] The sensory processor allows information from the outside world to be sensed in the form of chemical and physical stimuli and attended to with various levels of focus and intent. Working memory serves as an encoding and retrieval <b>processor.</b> <b>Information</b> in the form of stimuli is encoded in accordance with explicit or implicit functions by the working memory processor. The working memory also retrieves information from previously stored material. Finally, the function of long-term memory is to store data through various categorical models or systems (Baddely, 2007) [...]|$|E
50|$|An <b>information</b> <b>processor</b> or <b>information</b> {{processing}} system, as {{its name}} suggests, is a system (be it electrical, mechanical or biological) which takes information (a sequence of enumerated symbols or states) in one form and processes (transforms) it into another form, e.g. to statistics, by an algorithmic process.|$|R
5000|$|If {{computers}} do ultimately prove {{incapable of}} original thought—of discovery and invention—as Searle infers, {{then it will}} likely be for lack of what Bolesław Prus discerned as the motive force behind such creativity: needs. [...] It may be natural organisms' responses to their needs that will provide a clew {{to the mystery of}} the epiphenomenon that is consciousness, whose absence from electronic computers, in Searle's view, disqualifies contemporary artificial intelligence as an autonomous creative power. [...] All intelligences are <b>processors</b> of <b>information,</b> but not all <b>processors</b> of <b>information</b> are intelligences.|$|R
5000|$|... <b>processor</b> {{contains}} state <b>information</b> for one <b>processor</b> in {{the system}} ...|$|R
30|$|When {{we start}} a Cloud {{instance}}, we might enquire in the instance as regards reported <b>processor</b> <b>information</b> (for example in /proc/cpuinfo). However {{there is a}} possibility that such information has been modified.|$|E
40|$|Teleoperator {{components}} include manipulators and end effectors, sensors, a mobility unit, {{radio or}} hard-wire communications receiver and information <b>processor,</b> <b>information</b> display, {{man in the}} control loop at various levels of sophistication, the controls, and the transmitter. Possible applications of teleoperators in space cover a wide spectrum from various research and operational missions in earth orbit {{in conjunction with the}} space shuttle, space stations, and satellites to vehicles to explore the moon, planets and their moons, asteroids and comets...|$|E
40|$|In this paper. we {{describe}} a technique for optimizing com-munication for out-of-core distributed memory stencil prob-lems. In these problems, communication may require both inter-processor communication and file 1 / 0. We {{show that in}} certain cases, extra file 1 / 0 incurred in communication can be completely eliminated by reordering in-core compu-tations. The in-core computation pattern is decided by: (1) how the out-of-core data distributed into in-core slabs (tiling) and (2) how the slabs are accessed. We show that a compiler using the stencil and <b>processor</b> <b>information</b> can choose the tiling parameters and schedule the tile accesses so that theextra file I/O is eliminated and overall performance is improved. ...|$|E
5000|$|LOGODI Rules on the Installation of Image <b>Information</b> <b>Processors</b> (지방행정연수원 영상정보처리기기 설치운영규정) ...|$|R
40|$|This report {{presents}} a perspective for addressing {{one of our}} enterprises main future issues, the environment. The decision production system perspective re{{presents a}} product development organization as a network of decision-makers and <b>information</b> <b>processors</b> through which <b>information</b> flows. This representation {{can be used to}} improve product development processes by providing a deeper understanding of information flows and key decisions...|$|R
5000|$|An object may be {{considered}} an <b>information</b> <b>processor</b> if it receives information from another object and in some manner changes the information before transmitting it. This broadly defined term {{can be used to}} describe every change which occurs in the universe. As an example, a falling rock could {{be considered}} an <b>information</b> <b>processor</b> due to the following observable facts: ...|$|R
40|$|This paper {{presents}} {{a class of}} parallel numerical integration methods for stiff systems of ordinary differential equations which can be partitioned into loosely coupled sub-systems. The formulas are called decoupled backward differentiation formulas, and they are derived from the classical formulas by restricting the implicit part to the diagonal sub-system. With one or several sub-systems allocated to each <b>processor,</b> <b>information</b> only has to be exchanged after completion of a step but not during {{the solution of the}} nonlinear algebraic equations. The main emphasis is on the formula of order 1, the decoupled implicit Euler formula. It is proved that this formula even {{for a wide range of}} multirate formulations has an asymptotic global error expansion permitting extrapolation. Besides, sufficient conditions for absolute stability are presented. ...|$|E
40|$|Partitioned {{systems of}} {{ordinary}} differential equations are in qualitative terms characterized as monotonically max-norm stable if each sub-system is stable {{and if the}} couplings from one sub-system to the others are weak. Each sub-system of the partitioned system may be discretized independently by the backward Euler formula using solution values from the other sub-systems corresponding to the previous time step. The monotone max-norm stability guarantees this discretization to be stable. This so-called decoupled implicit Euler method is ideally suited for parallel computers. With one or several sub-systems allocated to each <b>processor,</b> <b>information</b> only has to be exchanged after completion of a step but not during {{the solution of the}} nonlinear algebraic equations. This paper considers strategies and techniques for partitioning a system into a monotonically max-norm stable system. It also presents error bounds to be used in controlling stepsize, relaxation between sub-systems and the v [...] ...|$|E
40|$|Abstract. Partitioned {{systems of}} {{ordinary}} differential equations are in qualitative terms characterized as monotonically max-norm stable if each sub-system is stable {{and if the}} couplings from one sub-system to the others are weak. Each sub-system of the partitioned system may be discretized independently by the backward Euler formula using solution values from the other sub-systems corresponding to the previous time step. The monotone max-norm stability guarantees this discretization to be stable. This so-called decoupled implicit Euler method is ideally suited for parallel computers. With one or several sub-systems allocated to each <b>processor,</b> <b>information</b> only has to be exchanged after completion of a step but not during {{the solution of the}} nonlinear algebraic equations. This paper considers strategies and techniques for partitioning a system into a monotonically max-norm stable system. It also presents error bounds to be used in controlling stepsize, relaxation between sub-systems and the validity of the partitioning. Finally a realistic example is presented. ...|$|E
40|$|We {{introduce}} {{and analyze}} different {{strategies for the}} parallel-in-time integration method PFASST to recover from hard faults and subsequent data loss. Since PFASST stores solutions at multiple time steps on different <b>processors,</b> <b>information</b> from adjacent steps {{can be used to}} recover after a processor has failed. PFASST’s multi-level hierarchy allows to use the coarse level for correcting the reconstructed solution, which can help to minimize overhead. A theoretical model is devised linking overhead to the number of additional PFASST iterations required for convergence after a fault. The potential efficiency of different strategies is assessed in terms of required additional iterations for examples of diffusive and advective type...|$|R
40|$|Abstract. Digital signal {{processing}} is {{the processing of}} digitized discrete-time samp-led signals. Processing is done by general-purpose computers or by digital circuits such as ASICs, field-programmable gate arrays or specialized digital signal <b>processors.</b> <b>Information</b> science focuses on understanding problems {{from the perspective of}} the stakeholders involved and then applying information and other technologies as needed. The definition of multiple pseudofames for subspaces with integer translation is proposed. The notion of a generalized multiresolution structure (GMS) of 2 () L R is also introduced. The construction of a generalized multiresolution structure of Paley- Wiener subspaces of 2 () L R is investigated. The pyramid decomposition scheme is derived based on a generalized multiresolution structure...|$|R
40|$|The {{decision}} {{production system}} perspective represents a product development organization as {{a network of}} decision-makers and <b>information</b> <b>processors</b> through which <b>information</b> flows. This representation {{can be used to}} improve product development processes by providing a deeper understanding of information flows and key decisions. This paper reviews the decision production system approach and provides an example of its use to improve product development. 1...|$|R
40|$|In this paper, we {{describe}} a technique for optimizing communication for out-of-core distributed memory stencil problems. In these problems, communication may require both inter-processor communication and file I/O. We {{show that in}} certain cases, extra file I/O incurred in communication can be completely eliminated by reordering in-core computations. The in-core computation pattern is decided by: (1) how the out-of-core data distributed into in-core slabs (tiling) and (2) how the slabs are accessed. We show that a compiler using the stencil and <b>processor</b> <b>information</b> can choose the tiling parameters and schedule the tile accesses so that the extra file I/O is eliminated and overall performance is improved. 1 Introduction The use of parallel computers to solve large scale scientific problems has increased considerably in recent times. Majority of these problems exhibit large memory requirements (of order of GBytes). Since main memories are not {{large enough to hold}} such large amount of d [...] ...|$|E
40|$|This is a publisher’s {{version of}} an article {{published}} in Annals of Otology, Rhinology & Laryngology published by Annals Publishing Company. This version is reproduced with permission from Annals Publishing Company. [URL] processors extracting either the fundamental frequency (F 0) alone, or the fundamental frequency combined with second formant information (F 0 -F 2), have been evaluated on a totally deaf patient using a multiple-channel cochlear implant. A closed set test using 16 spondees and a modified rhyme test showed that for electrical stimulation alone the F 0 -F 2 speech processor was significantly better than the F 0 processor. The open set tests using phonetically balanced words and Central Institute for the Deaf everyday sentences showed that for electrical stimulation alone and electrical stimulation combined with lipreading, the results with the F 0 -F 2 speech processor were all significantly better than with the F 0 <b>processor.</b> <b>Information</b> transmission for consonant speech features was also better when using the F 0 -F 2 processor. Open Acces...|$|E
40|$|Presently, it is {{a matter}} of {{discussion}} that, library and librarian will become redundant in the tech-based education system. Some may thinks that library without wall and library without librarian are the same. Practically these two are quite different from each other. In the virtual library era it is somehow possible to have a library without wall. The role of the librarian and library professional just changes their identity, e. g. Cybrarian, Information <b>Processor,</b> <b>Information</b> Consultant, etc. To cope with the rapid changes of the technology and to control the ephemeral rate of information generation, librarians along with his professional colleagues should have to equip themselves as per the requirement of the electronic information society. In the light of the above, the present paper would like to highlight the reasons why library and librarian is essential in the modern technology based library service era. The paper also tries to point out the role of the librarian in the changing society, services offered by the e-library, e-learning and issues faced by the librarian...|$|E
50|$|Please see the {{individual}} products' articles for further information, and comparison of text editors {{for information on}} text editors, and comparison of word <b>processors</b> or <b>information</b> on word <b>processors,</b> {{many of which have}} features to assist with writing HTML.|$|R
5000|$|... "A {{high flow}} rate synchronizer/scheduler {{apparatus}} for a multiprocessor system during program run-time, comprises a connection matrix for monitoring and detecting computational tasks which are allowed for execution containing a task map {{and a network}} of nodes for distributing to the <b>processors</b> <b>information</b> or computational tasks detected to be enabled by the connection matrix. The network of nodes possesses the capability of decomposing information on a pack of allocated computational tasks into messages of finer sub-packs to be sent towards the processors, {{as well as the}} capability of unifying packs of information on termination of computational tasks into a more comprehensive pack. A method of performing the synchronization/scheduling in the multiprocessor system of this apparatus is also described." ...|$|R
40|$|The {{first chapter}} of WilheLn Wundt’s text, An Introduction to Psychokogy, {{is devoted to the}} topic of attention. This {{reflects}} attention’s prominent role in the history of investigatio:ls of cognition and perception. And deservedly so. Humans and other animals are limited <b>processors</b> of <b>information.</b> l...|$|R
40|$|Recent price {{movements}} have put food supply chains under pressure. On the one side, upward price tendencies on commodity markets result in higher costs to processing firms. On the other side, these firms {{are confronted with}} a strong retail sector that is able to prevent compensation to protect consumersâ€™ and own economic interests. Regulatory impediments of European law, especially with respect to foodstuffs, can adversely be utilized as barriers to protect the interest downstream the supply chain. The problem is that legal-economic instruments which can serve to smooth price volatility in supply markets can also opportunistically be used {{at the expense of}} the middlesection in food supply chains (i. e., mainly small and medium sized producers). The aim of this article is to identify the legal-economic mechanisms that effect price transfers in food supply chains in the European Union and define policy adjustments to improve pricing mechanisms, while safeguarding the interests of the processing industry. Policy alternatives to improve the smooth functioning of notably intermediate markets in food supply chains are the restructuring of competition law, improved <b>processor</b> <b>information</b> management and creating transparency of value added in the supply chain by means of labelling devices...|$|E
40|$|Traceability is {{the ability}} to track any food, feed, food-producing animal or {{substance}} that will be used for consumption, through all the stages of production, processing, and distribution (European Union, 2002). In this study, an analysis of the traceability systems of three bulk commodities, corn, feed, and milk, was conducted to analyze the internal traceability system of each respective entity, the external traceability system among all entities, and the information exchange and communication between each entity. The objectives of this study were to create a model/map for tracing these commodities, to identify gaps in the internal and external traceability systems, and to provide quality control/quality management strategies to improve the external traceability system. The first step of analysis involved comparing the ISO 22005 traceability standard to the current tracing and tracking system used by the dairy processor. Only 2 of the 9 design components of the Standard were met by the processor due to lack of specified objectives. A concept map was created using supplier/recipient records from the dairy processor and dairy farm. Using records from the <b>processor,</b> <b>information</b> gaps were identified in the traceability system. After identifying gaps, quality control and quality management strategies were developed to help close the gaps and strengthen the external traceability system. A product flow model was also created to determine the location of products from corn to processed milk and to determine what records are kept at each point in the chain. The study showed that once the dairy processor has developed specific objectives to serve as the foundation for their traceability system, the established safety and quality programs that have been implemented and executed can be easily integrated into an ISO 22005 certified traceability system. Since making the decision to fully implement an ISO certified traceability system will require additional information such as risk and cost-benefit analyses, small changes that will yield timely results can be made in the area of quality control...|$|E
40|$|In many {{industrial}} plants materials {{have to be}} transported between several processing stations, {{where they have to}} be processed {{with a high level of}} accuracy and precision. In the last years, linear electrical drives, especially the long-stator linear motors are used for these types of applications for both processing and transportation tasks. They have higher dynamics and processing precision and lower maintenance costs compared to conventional systems, which require additional mechanical gears. The linear drive system must be modular and highly scalable in order to cover a wide range of applications. For this reason, the track of the plant is made of several stator segments. The excitation part of the motor is represented by permanent magnets (passive vehicles). Each stator segment has a dedicated inverter (Power Processing Unit) and <b>processor</b> (<b>Information</b> Processing Unit). Cheap IPMs (Intelligent Power Modules) are nowadays a good solution for implementing the inverter. A DSP was used as processor. The DSP and the IPM are the main components of the designed servo-controller, which together with a stator segment represents a module of the system. The DSP controls the inverter and is also used for the communication with the DSPs of the adjacent modules. By connecting the ground potential of all servo-controllers to the negative DC-link rail (ca. - 280 V), a significant reduction in the implementation costs of the servo-controller was achieved. When a vehicle crosses from one stator segment to the adjacent one, the control tasks migrate physically in that respective adjacent DSP. Data exchange is therefore required within each cycle of the current control loop (100 µs) between the adjacent modules. For an arbitrary scalable modular system, there will be also an arbitrary high communication demand. This demand can only be solved by a direct (Point-to-Point) connection between the adjacent DSPs. This connection was realised by means of the cost-effective RS 485 data transmission protocol. A central control unit is responsible then for the cyclical (1 - 10 ms) generation of new position reference values for the vehicles, according to a predefined schedule. The monitoring (assessment of internal variables of the distributed servo-controllers) of the entire system is realised also in real-time. Off-line download and upload actions of firmware or general data is also possible. For these tasks, the communication between the central unit (PC) and the distributed servocontrollers was realised by means of the Ethernet-based fieldbus EtherCAT. Inside the processing stations of the system, the positioning accuracy and precision as well as the dynamic have to be very good. For this reason, inside those stations, position sensors must be used. Outside those stations, for material transportation only, an EMF-based sensorless control was implemented. This will further reduce the overall system costs. A small section of such modular and highly scalable system was realised as an experimental set-up in the context of this work, in order to test the functionality and the reliability of the proposed system...|$|E
5000|$|Who are the {{responsible}} and authorised <b>processors</b> of the <b>information</b> systems and databases, {{and who are}} the contact persons; ...|$|R
50|$|The <b>processors</b> receive <b>{{information}}</b> from input modules, {{process the}} information and decide control actions to be performed by the output modules. The input modules receive information from sensing instruments in the process (or field) and the output modules transmit instructions to the final control elements, such as control valves.|$|R
40|$|We {{report an}} {{ensemble}} {{nuclear magnetic resonance}} (NMR) implementation of a quantum lattice gas algorithm for the diffusion equation. The algorithm employs an array of quantum <b>information</b> <b>processors</b> sharing classical <b>information,</b> a novel architecture {{referred to as a}} type-II quantum computer. This concrete implementation provides a test example from which to probe the strengths and limitations of this new computation paradigm. The NMR experiment consists of encoding a mass density onto an array of 16 two-qubit quantum <b>information</b> <b>processors</b> and then following the computation through 7 time steps of the algorithm. The results show good agreement with the analytic solution for diffusive dynamics. We also describe numerical simulations of the NMR implementation. The simulations aid in determining sources of experimental errors, and they help define the limits of the implementation. Comment: 20 pages, 3 figure...|$|R
5000|$|In 1978, a {{stand-alone}} CPU (without magnetic card and printing capabilities) {{was added to}} the product line, the IBM 6/420 <b>Information</b> <b>Processor</b> ...|$|R
40|$|We {{propose a}} new {{parallel}} performance visualization scheme, {{based on a}} simple moment analysis of processor utilization data. This method combines the scalability advantages of statistical summaries with the more revealing <b>processor</b> utilization <b>information</b> of Gantt charts. It scales well to large numbers of processors, requiring only storage constant in execution time...|$|R
40|$|Two ESOP <b>processors</b> using <b>information</b> from {{proportional}} chambers, scintillation hodoscopes and calorimeter ADCs {{have been}} used in a second stage trigger to improve the sensitivity and decrease the tape handling problems of an experiment to study the hadronic production of charmed particles. Details of the trigger and the results obtained are given. (4 refs) ...|$|R
50|$|Spintronics {{is used in}} {{disk drives}} for data storage and in {{magnetic}} random-access memory. Electronic spin is generally short-lived and fragile, but the spin-based information in current devices needs to travel only a few nanometers. However, in <b>processors,</b> the <b>information</b> must cross several tens of micrometers with aligned spins. Graphene is the only known candidate for such behavior.|$|R
5000|$|The <b>processors</b> receive <b>{{information}}</b> from input modules, {{process the}} information and decide control actions to be signalled by the output modules. The field inputs and outputs can be analog signals e.g. 4~ 20mA dc current loop or 2 state signals that switch either [...] "on" [...] or [...] "off", such as relay contacts or a semiconductor switch.|$|R
40|$|We {{propose a}} new {{parallel}} performance visualization scheme, {{based on a}} simple moment analysis of processor utilization data. This method combines the scalability advantages of statistical summaries with the more revealing <b>processor</b> utilization <b>information</b> of Gantt charts. It scales well to large numbers of processors, requiring only storage constant in execution time. 1. Introduction Processor idling can strongly affect the performance of parallel code. Consequently, many parallel performance tools [2, 4, 7, 9, 11] include one or more utilities, such as Gantt charts [3] or statistical summaries, to measure and display <b>processor</b> utilization <b>information.</b> Statistical summaries provide integrated totals of processor use [5]. Summary-based tools scale well to massively parallel computations, since they store and display only a few parameters per processor. However, summaries reveal little about the time dependence of resource use. A programmer, for example, {{might be able to}} identify unde [...] ...|$|R
