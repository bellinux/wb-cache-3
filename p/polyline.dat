307|207|Public
25|$|While the photocopier-generated {{technique}} is sensitive, reliable, and inexpensive, new methods involving digital overlays {{have proven to}} be more accurate. Two recent technological developments include the 2D <b>polyline</b> method and the painting method. Both methods use Adobe Photoshop. Use of the 2D <b>polyline</b> method entails drawing straight lines between two fixed points in the arch and between incisal edges to indicate the tooth width. Use of the painting method entails coating the incisal edges of a dental model with red glossy paint and then photographing the model. Adobe Photoshop is then used to make measurements on the image. A total of 13 variables were used in analysis. Identification for both methods were based on canine-to-canine distance (1 variable), incisor width (4 variables), and rotational angles of the incisors (8 variables). The 2D <b>polyline</b> method relies heavily on accurate measurements, while the painting method depends on precise overlaying of the images. Although both methods were reliable, the 2D <b>polyline</b> method gave efficient and more objective results.|$|E
25|$|It is {{important}} that edges have shapes that are as simple as possible, {{to make it easier}} for the eye to follow them. In <b>polyline</b> drawings, the complexity of an edge may be measured by its number of bends, and many methods aim to provide drawings with few total bends or few bends per edge. Similarly for spline curves the complexity of an edge may be measured by the number of control points on the edge.|$|E
50|$|Describes the {{geometry}} of the site/phase if <b>polyline</b> information is available.|$|E
40|$|Abstract. We {{introduce}} two new related metrics, the geodesic {{width and}} the link width, {{for measuring the}} “distance ” between two nonintersecting <b>polylines</b> in the plane. If the two <b>polylines</b> have n vertices in total, we present algorithms to compute the geodesic width of the two <b>polylines</b> in O(n 2 log n) time using O(n 2) space and the link width in O(n 3 log n) time using O(n 2) working space where n is {{the total number of}} edges of the <b>polylines...</b>|$|R
40|$|In this paper, we {{describe}} a {{hidden line removal}} scheme for 2 D cartoon images. The depths are introduced to the <b>polylines</b> of the image. The surfaces of the image are classified and their depths updated according to the depths of <b>polylines</b> forming the surfaces. The hidden lines are identified by comparing {{the depths of the}} <b>polylines</b> with the depths of the surfaces. This algorithm has been applied successfully to our cartoon development system...|$|R
5000|$|Graphic markers: For placing arrows, circles, {{squares and}} <b>polylines</b> (with {{straight}} line segments).|$|R
50|$|Equidistant {{is a line}} {{of equal}} {{distance}} from a given point, line, <b>polyline.</b>|$|E
50|$|While the photocopier-generated {{technique}} is sensitive, reliable, and inexpensive, new methods involving digital overlays {{have proven to}} be more accurate. Two recent technological developments include the 2D <b>polyline</b> method and the painting method. Both methods use Adobe Photoshop. Use of the 2D <b>polyline</b> method entails drawing straight lines between two fixed points in the arch and between incisal edges to indicate the tooth width. Use of the painting method entails coating the incisal edges of a dental model with red glossy paint and then photographing the model. Adobe Photoshop is then used to make measurements on the image. A total of 13 variables were used in analysis. Identification for both methods were based on canine-to-canine distance (1 variable), incisor width (4 variables), and rotational angles of the incisors (8 variables). The 2D <b>polyline</b> method relies heavily on accurate measurements, while the painting method depends on precise overlaying of the images. Although both methods were reliable, the 2D <b>polyline</b> method gave efficient and more objective results.|$|E
50|$|By using {{a similar}} layout, every convex {{curve in the}} plane can be shown to contain an n-point subset that is {{universal}} for <b>polyline</b> drawing with at most one bend per edge. This set contains only the vertices of the drawing, not the bends; larger sets are known {{that can be used}} for <b>polyline</b> drawing with all vertices and all bends placed within the set.|$|E
40|$|We {{are proposing}} an {{algorithm}} for tracing <b>polylines</b> that are oriented by a direction field defined on a triangle mesh. The {{challenge is to}} ensure that two such <b>polylines</b> cannot cross or merge. This property is fundamental for mesh segmentation and is impossible to enforce with existing algorithms. The core of our contribution is to determine how <b>polylines</b> cross each triangle. Our solution is inspired by EdgeMaps where each triangle boundary is decomposed into inflow and outflow intervals such that each inflow interval is mapped onto an outflow interval. To cross a triangle, we find the inflow interval that contains the entry point, and link it to the corresponding outflow interval, with the same barycentric coordinate. To ensure that <b>polylines</b> cannot merge or cross, we introduce a new direction field representation, we resolve the inflow/outflow interval pairing with a guaranteed combinatorial algorithm, and propagate the barycentric positions with arbitrary precision number representation. Using these techniques, two streamlines crossing the same triangle cannot merge or cross, but only locally overlap when all streamline extremities are located on the same edge. Cross-free and merge-free <b>polylines</b> can be traced on the mesh by iteratively crossing triangles. Vector field singularities and polyline/vertex crossing are characterized and consistently handled...|$|R
5000|$|... 3D Model: The perfect tool {{to model}} stopes, {{geological}} models, faults and other 3D objects from <b>polylines.</b>|$|R
40|$|International audienceMesh {{simplification}} {{has received}} tremendous attention {{over the past}} years. Most of the previous works deal with a proper choice of error measures to guide the simplification. Preserving the topological characteristics of the mesh and possibly of data attached to the mesh is a more recent topic, the present paper is about. We introduce a new topology preserving simplification algorithm for triangular meshes, possibly non-manifold, with embedded <b>polylines.</b> In this context embedded means that {{the edges of the}} <b>polylines</b> are also edges of the mesh. The paper introduces a robust test to detect if the collapse of an edge in the mesh modifies either the topology of the mesh or the topology of the embedded <b>polylines.</b> This validity test is derived using combinatorial topology results. More precisely we define a so-called extended complex from the input mesh and the embedded <b>polylines.</b> We show that if an edge collapse of the mesh preserves the topology of this extended complex, then it also preserves both the topology of the mesh and the embedded <b>polylines.</b> Our validity test can be used for any 2 -complex mesh, including non-manifold triangular meshes. It can be combined with any previously introduced error measure. Implementation of this validity test is described. We demonstrate the power and versatility of our method with scientific data sets from neuroscience, geology and CAD/CAM models from mechanical engineering...|$|R
5000|$|Selection: by point, by rectangle, by polygon, by layer, by <b>polyline,</b> by circle, {{by buffer}} zone, {{alphanumeric}} search, invert selection, delete selection.|$|E
50|$|Toolkit {{features}} {{also include}} support for complex linetypes, multiline text, lightweight <b>polyline,</b> draworder, audit & recover, ADS support in most applications and raster image tools.|$|E
5000|$|The [...] "Line" [...] and [...] "Polyline" [...] messages, {{which both}} use Point, {{demonstrate}} how composition works in Protocol Buffers. <b>Polyline</b> has a repeated field, which behaves like a vector.|$|E
40|$|This paper {{presents}} {{a new approach}} to the problem of building a global map from laser range data, utilizing shape based object recognition techniques originally developed for tasks in computer vision. In contrast to classical approaches, the perceived environment is represented by polygonal curves (<b>polylines),</b> possibly containing rich shape information yet consisting of {{a relatively small number of}} vertices. The main task, besides segmentation of the raw scan point data into <b>polylines</b> and denoising, is to find corresponding environmental features in consecutive scans to merge the polylinedata to a global map. The correspondence problem is solved using shape similarity between the <b>polylines.</b> The approach does not require any odometry data and is robust to discontinuities in robot position, e. g., when the robot slips. Since higher order objects in the form of <b>polylines</b> and their shape similarity are present in our approach, it provides a link between the necessary low-level and the desired high-level information in robot navigation. The presented integration of spatial arrangement information, illustrates the fact that high level spatial information can be easily integrated in our framework...|$|R
30|$|We {{can create}} new forms on our computers: <b>polylines,</b> nurbs and blob-volumes hold no secrets for {{the architects of}} our day.|$|R
40|$|This paper {{presents}} an arc-length preserving axial deformation along a B-spline curve based on arc-length parameterization of the axial curve. Space spanned by arc length and rotation minimizing frame on the axis {{is taken as}} the embedded space. As in real life, the length of an object's skeleton usually remains constant when it is axially deformed such as a swimming fish, a swaying tree etc, An length preserving axial curve deformation is presented. Keyframe skeleton B-spline curves are approximated by <b>polylines</b> after adaptive subdivisions. The edge lengths and the directional vertex angles of the keyframe polylines(or unit edge vectors) are then interpolated to generate the intermediate <b>polylines.</b> These interpolated <b>polylines</b> are intermediate axes in the discreted form. Experiments show our method is very useful, intuitive and easy to control...|$|R
5000|$|Because {{the shape}} type precedes each {{geometry}} record, a shapefile is physically capable of storing {{a mixture of}} different shape types. However, the specification states, [...] "All the non-Null shapes in a shapefile are required {{to be of the}} same shape type." [...] Therefore, this ability to mix shape types must be limited to interspersing null shapes with the single shape type declared in the file's header. A shapefile must not contain both <b>polyline</b> and polygon data, for example, and the descriptions for a well (point), a river (<b>polyline),</b> and a lake (polygon) would be stored in three separate datasets.|$|E
5000|$|For example, after a C++ {{version of}} the {{protocol}} buffer schema above is produced, a C++ source code file, polyline.cpp, can use the message objects as follows:// polyline.cpp#include [...] "polyline.pb.h" [...] // generated by calling [...] "protoc polyline.proto"Line* createNewLine(const std::string& name) { // create a line from (10, 20) to (30, 40) Line* line = new Line; line->mutable_start (...) ->set_x(10); line->mutable_start (...) ->set_y(20); line->mutable_end (...) ->set_x(30); line->mutable_end (...) ->set_y(40); line->set_label(name); return line;}Polyline* createNewPolyline (...) { // create a <b>polyline</b> with points at (10,10) and (20,20) Polyline* <b>polyline</b> = new Polyline; Point* point1 = polyline->add_point (...) point1->set_x(10); point1->set_y(10); Point* point2 = polyline->add_point (...) point2->set_x(20); point2->set_y(20); return polyline;} ...|$|E
5000|$|Graphical editing: add event layers, snapping, grid, flatness, command stack, undo/redo, copy, move, symmetry, rotate, scale, edit vertex, {{internal}} polygon, matrix, explode, split, join, autocomplete polygon, insert point, multipoint, line, arc, <b>polyline,</b> polygon, rectangle, square, circle, ellipse.|$|E
40|$|International audienceWe {{are proposing}} an {{algorithm}} for tracing <b>polylines</b> that are oriented bya direction field defined on a triangle mesh. The {{challenge is to}} ensure thattwo such <b>polylines</b> cannot cross or merge. This property is fundamental formesh segmentation and is impossible to enforce with existing algorithms. The core of our contribution is to determine how <b>polylines</b> cross eachtriangle. Our solution is inspired by EdgeMaps where each triangle boundaryis decomposed into inflow and outflow intervals such that each inflowinterval is mapped onto an outflow interval. To cross a triangle, we find theinflow interval that contains the entry point, and link it to the correspondingoutflow interval, with the same barycentric coordinate. To ensure that polylinescannot merge or cross, we introduce a new direction field representation,we resolve the inflow/outflow interval pairing with a guaranteed combinatorialalgorithm, and propagate the barycentric positions with arbitraryprecision number representation. Using these techniques, two streamlinescrossing the same triangle cannot merge or cross, but only locally overlapwhen all streamlines extremities are located on the same edge. Cross-free and merge-free <b>polylines</b> can be traced on the mesh by iterativelycrossing triangles. Vector field singularities and polyline/vertexcrossing are characterized and consistently handled...|$|R
40|$|Morphing is {{a process}} of shape {{transformation}} between two objects. This paper focuses on morphing of simple polygons. In general, the key part of most morphing methods is to find correspondence between vertices of both objects. We present a new algorithm trying to avoid this step. Using an idea of intersection of two polygons (called core) the problem of morphing polygons is decomposed to several sub-problems of morphing <b>polylines.</b> We describe a solution of morphing problem for the case when the core consists of one polygon. The proposed solution of morphing two <b>polylines</b> does not bring results smooth enough for all polygons, but it has satisfying results for polygons of spiral type which are usually problematic for correspondence based approaches. The algorithm is designed in a way keeping the doors open for other methods of morphing two <b>polylines...</b>|$|R
40|$|We {{introduce}} a measure for computing {{the similarity between}} multiple <b>polylines</b> and a polygon, that can be computed in O(km 2 n 2) time with a straightforward dynamic programming algorithm. We then present a novel fast algorithm that runs in time O(kmn logmn). Here, m denotes the number of vertices in the polygon, and n is {{the total number of}} vertices in the k <b>polylines</b> that are matched against the polygon. The effectiveness of the similarity measure has been demonstrated in a part-based retrieval application with known ground-truth...|$|R
5000|$|The maximum allowed {{distance}} between the planar approximation polygon and the surface (known as [...] "sag"). This parameter ensures that mesh is similar enough to the original analytical surface (or the <b>polyline</b> {{is similar to the}} original curve).|$|E
5000|$|Ways {{are ordered}} lists of nodes, {{representing}} a <b>polyline,</b> or possibly a polygon if {{they form a}} closed loop. They are used both for representing linear features such as streets and rivers, and areas, like forests, parks, parking areas and lakes.|$|E
50|$|To show a set {{of points}} in an n-dimensional space, a {{backdrop}} is drawn consisting of n parallel lines, typically vertical and equally spaced. A point in n-dimensional space is represented as a <b>polyline</b> with vertices on the parallel axes; {{the position of the}} vertex on the i-th axis corresponds to the i-th coordinate of the point.|$|E
40|$|Abstract. This paper {{addresses}} computational efficiency {{issues of}} a new algebraic method for imagery registration/conflation. An algebraic approach to conflation/registration of images {{does not depend on}} identifying common points. It uses the method of algebraic invariants to provide a common set of coordinates to images using chains of line segments formally described as <b>polylines</b> with possible gaps between segments. The original design of the method operates with matrixes and has complexity O(n 3) for entire matrixes and complexity O(n 5) for individual binary comparisons. This paper shows that this polynomial complexity can be significantly reduced by converting each matrix to the special linear structures with n elements. Generation of the special linear structure itself requires n log n binary comparisons for sorting, and the complexity of comparing two <b>polylines</b> overall is O(n 3 logn). The ability to perform these matching computations quickly is essential in correlating images containing large quantities of <b>polylines...</b>|$|R
5000|$|Geocoded {{data are}} {{represented}} by entities, which act as points, lines, <b>polylines</b> or areas. 2D and 3D. All information contained in the information service is geocoded. e.g. displayed on map.|$|R
25|$|The {{language}} also includes: {{low level}} modeling constructions (variables, equations, parameters, events etc.), presentation shapes (lines, <b>polylines,</b> ovals etc.), analysis facilities (datasets, histograms, plots), connectivity tools, standard images, and experiments frameworks.|$|R
50|$|In {{simultaneous}} geometric embedding each graph must {{be drawn}} as a planar graph with line segments representing its edges {{rather than more}} complex curves restricting the two given graphs to subclasses of the planar graphs.Many results on simultaneous geometric embedding {{are based on the}} idea that the Cartesian coordinates of the two given graphs' vertices can be derived from properties of the two graphs. One of the most basic results of this type is the fact that any two path graphs on the same vertex set always have a simultaneous embedding. To find such an embedding, one can use the position of a vertex in the first path as its x-coordinate, and the position of the same vertex in the second path as its y-coordinate. In this way, the first path will be drawn as an x-monotone <b>polyline,</b> a type of curve that is automatically non-self-crossing, and the second path will similarly be drawn as a y-monotone <b>polyline.</b>|$|E
50|$|HL7 Clinical Document Architecture {{also has}} a subset of {{mechanisms}} similar to (and intended to be compatible with) DICOM for referencing image-related spatial coordinates as observations; it allows for a circle, ellipse, <b>polyline</b> or point to be defined as integer pixel-relative coordinates referencing an external multi-media image object, which may be of a consumer rather than medical image format (e.g., a GIF, PNG or JPEG).|$|E
50|$|The {{user can}} interactively segment 3D {{entities}} (with a 2D <b>polyline</b> drawn on screen), interactively rotate/translate one ore several entities relatively to the others, interactively pick single points or couples of points (to get the corresponding segment length) or triplets of points (to get the corresponding angle and plane normal). The latest version also supports {{the creation of}} 2D labels attached to points or rectangular areas annotations.|$|E
30|$|GIS {{has been}} {{historical}} two-dimensional (2 D), modeling the geometries of objects into georeferenced points, <b>polylines,</b> and polygons. Buried utilities are predominantly modeled as 2 D <b>polylines</b> in GIS, missing vertical location information. Some utilities might have their buried depths (e.g. “depth of cover”) stored as attributes and their vertical location might be derived by consulting the reference surface. However, utility depths are rarely referenced to a recognized elevation datum (Federal Highway Administration (FHWA) 1999;Anspach 1995) and any {{changes of the}} reference surface make the buried depth a very unreliable source for deriving vertical utility locations.|$|R
25|$|Straight-line {{paths and}} paths {{made up of}} a series of {{connected}} straight-line segments (<b>polylines),</b> as well as closed polygons, circles, and ellipses can be drawn. Rectangles and round-cornered rectangles are also standard elements.|$|R
40|$|Several {{algorithms}} {{have been}} developed to automatically detect the bare earth in LIDAR point clouds referred to as filtering. Previous experimental study on filtering algorithms determined that in flat and uncomplicated landscapes, algorithms tend to do well. Significant differences in accuracies of filtering appear in landscapes containing steep slopes and discontinuities. A solution for this problem is the segmentation of ALS point clouds. In this paper a new segmentation has been developed. The algorithm starts with first slicing a point cloud into contiguous and parallel profiles in different directions. Then the points in each profile are segmented into <b>polylines</b> based on distance and elevation proximity. The segmentation in each profile yields <b>polylines.</b> The <b>polylines</b> are then linked together through their common points to obtain surface segments. At the final stage, the data is partitioned into some windows in which the strips are exploited to analysis the points with regard to the height differences through them. In this case the whole data could be fully segmented into ground and non-ground measurements, sequentially via the strips which make the algorithm fast to implement...|$|R
