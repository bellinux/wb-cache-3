34|146|Public
5000|$|Also, other {{patterns}} {{have been}} described that refer to the progressive frame rate conversion required to display 24 frame/s video (e.g., from a DVD player) on a <b>progressive</b> <b>display</b> (e.g., LCD or plasma): ...|$|E
5000|$|PNG is {{designed}} to work well in online viewing applications like web browsers and can be fully streamed with a <b>progressive</b> <b>display</b> option. PNG is robust, providing both full file integrity checking and simple detection of common transmission errors.|$|E
50|$|A flicker fixer or scan doubler is a {{piece of}} {{computer}} hardware that de-interlaces an output video signal. The flicker fixer accomplishes this by adjusting the timing of the natively interlaced video signal to suit the needs of a <b>progressive</b> <b>display</b> Ex: CRT computer monitor. Flicker fixers in essence create a progressive frame of video from two interlaced fields of video.|$|E
5000|$|Software Video Deinterlacing - ensures a {{smoother}} and clearer video image on <b>progressive</b> <b>displays</b> ...|$|R
50|$|EDTV {{broadcasts}} {{use less}} digital bandwidth than HDTV, so TV stations can broadcast several EDTV stations at once. Like SDTV, EDTV signals are broadcast with non-square pixels. Since {{the same number}} of horizontal pixels are used in 4:3 and 16:9 broadcasts, the 16:9 mode is sometimes referred to as anamorphic widescreen. Most EDTV displays use square pixels, yielding a resolution of 852 &times; 480. However, since no broadcasts use this pixel count, such displays always scale anything they show. The only sources of 852 &times; 480 video are Internet downloads, such as some video games. Unlike 1080i and SDTV formats, <b>progressive</b> <b>displays</b> (such as plasma displays and LCDs) can show EDTV signals without the need to de-interlace them first. This can result in a reduction of motion artifacts. However to achieve this most <b>progressive</b> <b>displays</b> require the broadcast to be frame doubled (i.e., 25 to 50 and 30 to 60) to avoid the same motion flicker issues that interlacing fixes.|$|R
50|$|Interestingly, the Hanabi games can {{actually}} be played in both PAL60 (480i) and 480p modes. This makes these releases look significantly better on <b>progressive</b> <b>displays</b> such as LCD TVs. The fast moving sprites in NES and SNES games generally create {{a significant amount of}} interlace artifacts on such displays that the 480p option resolves. However Hanabi Mega Drive titles still run in 50 Hz with the usual PAL conversion problems, despite not been released in PAL.|$|R
5000|$|Flicker fixers {{sample the}} NTSC/PAL output from the output device and store each scan {{line from the}} field {{currently}} being displayed in RAM while simultaneously outputting the line alternately with the corresponding neighboring lines from the field stored previously (weaving). Some more advanced flicker fixers integrated in add-on graphics cards use more sophisticated methods. Outputting the image at double scan rate essentially composes a <b>progressive</b> <b>display</b> with all lines from both fields at full vertical refresh rate. This promotes the horizontal frequency of the signal from 15.734 kHz to 31.47 kHz (in the NTSC case, numbers for PAL are slightly lower), which can be the used to drive a VGA monitor from an output device.|$|E
50|$|Interlacing can be {{exploited}} to produce 3D TV programming, {{especially with a}} CRT display and especially for color filtered glasses by transmitting the color keyed picture for each eye in the alternating fields. This does not require significant alterations to existing equipment. Shutter glasses can be adopted as well, obviously with the requirement of achieving synchronisation. If a progressive scan display is used to view such programming, any attempt to deinterlace the picture will render the effect useless. For color filtered glasses the picture has to be either buffered and shown {{as if it was}} progressive with alternating color keyed lines, or each field has to be line-doubled and displayed as discrete frames. The latter procedure {{is the only way to}} suit shutter glasses on a <b>progressive</b> <b>display.</b>|$|E
5000|$|In {{the case}} of most media, such as DVD movies and video games, the video is blurred during the {{authoring}} process itself to subdue interline twitter when played back on interlace displays. As a consequence, recovering the sharpness of the original video is impossible when the video is viewed progressively. A user-intuitive solution to this is when display hardware and video games come equipped with options to blur the video at will, or to keep it at its original sharpness. This allows the viewer to achieve the desired image sharpness with both interlaced and progressive displays. An example of a video game with this feature is Super Smash Bros. Brawl, where a [...] "Deflicker" [...] option exists. Ideally, [...] "Deflicker" [...] would be turned on when played on an interlaced display to reduce interline twitter, and off when played on a <b>progressive</b> <b>display</b> for maximum image clarity.|$|E
50|$|Modern HDTV plasma {{televisions}} {{usually have}} a resolution of 1,024×768 found on many 42 inch plasma screens, 1,280×768, 1,366×768 found on 50 in, 60 in, and 65 in plasma screens, or 1,920×1,080 found in plasma screen sizes from 42 inch to 103 inch. These <b>displays</b> are usually <b>progressive</b> <b>displays,</b> with non-square pixels, and will up-scale and de-interlace their incoming standard-definition signals to match their native display resolution. 1024x768 resolution requires that 720p content be downscaled {{in one direction and}} upscaled in the other.|$|R
40|$|The {{purpose of}} this paper is to present a gender focused reading of the novel Moi, Tituba sorcière [...] . Noire de Salem(1986), from Antillean writer Maryse Condé. With this aim, we will resort to the {{theoretical}} back ground from the gender studies. First we will analyze the ideological implications put in play by the dichotomy «male / female» on the narrative level. Secondly, we will take into account the <b>progressive</b> <b>displaying</b> of a certain insular aesthetics / poetics in the story. We will try to propose some key strategies to answer the main question: why the island?...|$|R
50|$|For <b>progressive</b> scan <b>display</b> modes, {{the signal}} {{processing}} stops here, and the frame buffer is immediately {{written to the}} display device. In its simplest form, this processing may take several microseconds to occur.|$|R
40|$|Network-conscious image {{compression}} {{has been shown}} to provide faster <b>progressive</b> <b>display</b> than traditional compression algorithms, when images are transmitted over lossy low-bandwidth packet-switched networks. In this paper, we combine the advantages of wavelet-based, network-conscious {{image compression}} with a blind digital image signature technique. Together these two approaches investigate <b>progressive</b> <b>display</b> where each progressive image can be authenticated by the receiver in real time. ...|$|E
40|$|Two {{well-known}} wavelet zerotree encoding algorithms, Embedded Zerotree Encoding (EZW) and Set Partitioning in Hierarchical Trees (SPIHT), provide excellent <b>progressive</b> <b>display</b> when {{images are}} transmitted over reliable networks. However, both algorithms are state-dependent and can perform poorly over unreliable networks. In this paper, we apply {{the concept of}} networkconscious image compression to the SPIHT wavelet zerotree encoding algorithm, to improve its performance over unreliable networks. Experimental results confirm that for non-negligible network loss rates and low bandwidths, network-conscious image compression provides faster <b>progressive</b> <b>display.</b> Keywords: Application level framing, image compression, transport protocol, zerotree encoding, wavelet encoding, SPIHT. An abbreviated {{version of this paper}} appeared in Proc. of Data Compression Conference (DCC ' 2000). 1 I. INTRODUCTION Wavelet zerotree encoding is an algorithm that utilizes the correlation between coeffi [...] ...|$|E
40|$|Network-conscious image {{compression}} {{has been shown}} to provide faster <b>progressive</b> <b>display</b> than traditional compression algorithms, when images are transmitted over lossy battlefield packetswitched networks. In this paper, we combine the advantages of wavelet-based, network-conscious {{image compression}} with a blind digital image signature technique. Together these two approaches investigate <b>progressive</b> <b>display</b> where each progressive image can be authenticated by the receiver in real time. 1 INTRODUCTION Image transmission over battlefield networks requires special attention mainly for two reasons. (1) Battlefield networks typically provide very low bandwidth and unreliable communication. Image data, on the other hand, by its nature, requires high bandwidth. Therefore, transmitting images over these low bandwidth networks takes much more time than it would over a typical Internet connection. Typical military image transmission applications, such as telemedicine and intelligence gathering [...] ...|$|E
5000|$|... 512×512 virtual (320×480 <b>display,</b> <b>progressive)</b> @ 32,768 colors - overlay not {{supported}} ...|$|R
50|$|Interlacing was {{ubiquitous}} in displays until the 1970s, when {{the needs of}} computer monitors resulted in the reintroduction of progressive scan. Interlace is still used for most standard definition TVs, and the 1080i HDTV broadcast standard, but not for LCD, micromirror (DLP), or most plasma displays; these displays do not use a raster scan to create an image, and so cannot benefit from interlacing: in practice, {{they have to be}} driven with a progressive scan signal. The deinterlacing circuitry to get progressive scan from a normal interlaced broadcast television signal can add to the cost of a television set using such <b>displays.</b> Currently, <b>progressive</b> <b>displays</b> dominate the HDTV market.|$|R
5000|$|... 256×512 virtual (256×240 <b>display,</b> <b>progressive)</b> @ 32,768 colors - overlay {{support with}} mode 11 ...|$|R
40|$|This paper {{examines}} {{the efficiency of}} MPEG- 2 coding for interlaced and progressive video, and compares de-interlacing and picture rate up-conversion before and after coding. We found receiver side de-interlacing and picture rate up-conversion (i. e. after coding) to give better image quality at a given data rate. In contrast with some other publications, we found interlaced video coding {{to be better than}} progressive video coding for many relevant sequences, even when comparing the results on a <b>progressive</b> <b>display...</b>|$|E
40|$|Abstract: The eciency of MPEG- 2 coding {{has been}} studied for {{interlaced}} and progressive video. Also de-interlacing and picture rate up-conversion before and after coding are compared. Receiver side de-interlacing and picture rate up-conversion {{were found to be}} superior in terms of resulting im-age quality at a given data rate. In contrast to some other publications, we found coding of inter-laced video superior to coding of progressive video for many relevant sequences, even when comparing the results on a <b>progressive</b> <b>display...</b>|$|E
40|$|Abstract: This paper {{examines}} the coding e-ciency of MPEG- 2 coding for interlaced and pro-gressive video, and also compares de-interlacing and picture rate up-conversion {{before and after}} coding. We found receiver side de-interlacing and picture rate up-conversion (i. e. after coding) to give better image quality at a given data rate. In contrast with some other publications, we found in-terlaced video coding {{to be better than}} progressive video for many relevant sequences, even when com-paring the results on a <b>progressive</b> <b>display...</b>|$|E
50|$|Doubling {{the frame}} rate of {{interlaced}} footage without duplicating or morphing frames is possible using the tfields filter to create two different frames {{from each of}} the two fields in one frame of interlaced video. This allows playback on <b>progressive</b> <b>displays,</b> while preserving the full resolution and framerate of interlaced video, unlike other deinterlacing methods. It also makes the video stream usable for framerate conversion, and creating slow-motion scenes from streams taken at standard video/TV frame rates, e.g. using cheap consumer camcorders. If the filter gets incorrect information about the top/bottom field order, the resulting output will have juddering motion, because the two frames created would be displayed in the wrong order.|$|R
5000|$|For {{quality control}} purposes, it is {{necessary}} for a broadcast reference monitor to produce (reasonably) consistent images from facility to facility, to reveal any flaws in the material, and also not to introduce any image artifacts (such as aliasing) that is not in the source material. Broadcast monitors will try to avoid post processing such as a video scaler, line doubling and any image enhancements such as dynamic contrast. However, display technologies with fixed pixel structures (e.g. LCD, plasma) must perform image scaling when displaying SD signals as the signal contains non-square pixels while the display has square pixels. [...] LCDs and plasmas are also inherently <b>progressive</b> <b>displays</b> and may need to perform deinterlacing on interlaced video signals.|$|R
50|$|To display {{interlaced}} {{video on}} a <b>progressive</b> scan <b>display</b> requires {{a process called}} deinterlacing. This is an imperfect technique, and generally lowers resolution and causes various artifacts—particularly in areas with objects in motion. Providing the best picture quality for interlaced video signals requires expensive and complex devices and algorithms. For television displays, deinterlacing systems are integrated into progressive scan TV sets that accept interlaced signal, such as broadcast SDTV signal.|$|R
40|$|We {{present an}} {{irregular}} simplical grid for the <b>progressive</b> <b>display</b> and transmission of CFD-simulation datasets of arbitrary dimension. Spatial and temporal dimensions are treated equally {{to exploit the}} coherencies between different timeframes of a simulation. The data is hierarchically arranged by its importance to minimize the amount of data to be stored or transmitted. We use a recursive partitioning scheme for the grid cells, which tests a number of candidate partitionings by their quality. Furthermore a progressive encoding scheme is proposed, which minimizes the effort to store the topology of the grid. Possible applications stretch beyond progressive transmission into areas of data compression and visualization based on multiple levels-of-detail...|$|E
40|$|We {{apply the}} concept of network-consciousness to image compression, an {{approach}} that does not simply optimize compression, but which optimizes overall performance when compressed images are transmitted over a lossy packet-switched network such as the Internet. Using an Application Level Framing philosophy, an image is compressed into path MTU-size Application Data Units #ADUs# at the application layer. Each ADU carries its semantics, that is, it contains enough information to be processed independently of all other ADUs. Therefore each ADU can be delivered to the receiving application out-of-order, thereby enabling faster <b>progressive</b> <b>display</b> of images. We explain why this approach is useful in general and speci#cally for wireless#heterogeneous environments. ...|$|E
40|$|This paper {{introduces}} a high-quality, low-cost video converter for {{the conversion of}} interlaced TV signals into <b>progressive</b> <b>display</b> formats of the same or higher frame repetition rate. This conversion is performed by motion compensated filtering which is preceded by motion estimation. The applied motion estimation algorithm operates on blocks sized 4 × 4 pixels. For each of these blocks, a candidate vector is chosen out of temporal and spatial predecessors using a displayed field differences error criterion. The optimal candidate is updated {{by a series of}} pixel recursive steps. The filter algorithm employs a motion compensating median filter whose shape depends on the motion vector. A fallback mode is implemented to deal with areas for which no accurate motion vectors could be derived. Single-chip integration of the whole format conversion system is feasible...|$|E
50|$|Ainsi la nuit <b>displays</b> <b>progressive</b> growth, a {{technique}} frequently used by Dutilleux and through which musical motifs can both recall music that was heard in earlier sections or hint at music {{that will be}} fully developed in later movements.|$|R
40|$|We {{present an}} MPEG- 2 to H. 263 {{transcoder}} that accepts an interlaced MPEG- 2 bitstream as the input and produces a lower-bitrate progressive H. 263 bitstream as the output. As both DVD and digital television may use MPEG- 2 interlaced sequences, a potential application {{of such a}} transcoder is the transmission of a digital television signal over a wireless medium. Another application is transcoding interlaced DVD content for use on lower-resolution thin clients with <b>progressive</b> <b>displays.</b> The proposed algorithm exploits {{the properties of the}} MPEG- 2 and H. 263 compression standards to perform interlaced to progressive (eld to frame) conversion with spatial downsampling and frame-rate reduction in a CPU and memory ecient manner, while additionally minimizing picture quality degradation as measured by PSNR. This is the rst algorithm to our knowledge that eectively uses both spatial and temporal downsampling in an MPEG- 2 to H. 263 eld to frame transcoder in order to achieve substantial bitrate reduction. This paper discusses recoding experiments used to determine appropriate source and target coding parameters for the transcoder, provides {{a detailed description of the}} transcoding algorithm, and describes the performance of a software implementation of the transcoder...|$|R
40|$|This {{bachelor}} {{thesis is}} about progressive graphic formats, design of <b>progressive</b> algorithm to <b>display</b> image {{and implementation of}} this algorithm in Android appli-cation. This thesis describes possibilities of application development for Android and also progressive rendering methods used by known graphic formats...|$|R
30|$|In this paper, {{a spatial}} saliency-guided motion-compensated method for video deinterlacing is proposed. Our {{approach}} is an efficient deinterlacing tool, {{being able to}} adapt the interpolation method depending both on region of interest and its texture content. Experiments show that the proposed algorithm generates high-quality results, having more than 4.5 dBs PSNR gain, in average, compared to other deinterlacing approaches. Furthermore, the proposed method acknowledges the possibility of improving image quality and simultaneously reducing execution time, based on the saliency map. Finally, we have presented two models: the first one for storage applications (in this case, deinterlacing time is not a critical issue, so it is mainly designed for high-quality conversion from interlaced cameras to <b>progressive</b> <b>display</b> devices), {{and the other one}} with less but still acceptable video quality performances, which can be adapted for real-time deinterlacers.|$|E
40|$|NETCICATS is a {{software}} system for empirically evaluating network-conscious image compression, {{an approach that}} does not simply optimize compression, but which optimizes overall performance when compressed images are transmitted over a lossy packet-switched network such as the Internet. Based on Application Level Framing, an image is compressed into path-MTU-size Application Data Units #ADUs# at the application layer. Each ADU contains enough information to be processed independently of all other ADUs. Each ADU can be delivered to the receiving application out-of-order, thereby enabling faster <b>progressive</b> <b>display</b> of images. NETCICATS allows the empirical investigation of the combination of transport protocol features and compression algorithms that perform best over a lossy packet-switched network. It includes software components from the network layer #e. g., lossy router#, transport layer #e. g., innovative transport protocols#, and application layer #e. g., compression [...] ...|$|E
40|$|Introduction Triangular meshes {{have become}} a {{standard}} way of representing objects in computer graphics and geometric modeling. Unfortunately, highly complex triangular meshes, easily generated by laser scanning systems, can be both frustrating to edit and expensive to store, transmit, and render. Multiresolution representations of meshes, developed by Lounsbery et al. [3, 4] and extended by others [2, 5], address these problems. A multiresolution representation of a mesh consists of a simple base mesh plus a series of local correction terms, wavelet coefficients, that capture the represented object's detail at increasing levels of resolution. Multiresolution mesh representations are therefore useful for applications such as compression and the <b>progressive</b> <b>display</b> and transmission of three-dimensional graphics [2]. The one noted drawback to the Lounsbery et al. multiresolution analysis is that this method can only be applied to meshes displaying...|$|E
50|$|A Phase Alternating Line (PAL)-based {{television}} set display, for example, scans 50 fields every second (25 odd and 25 even). The {{two sets of}} 25 fields work {{together to create a}} full frame every 1/25 of a second (or 25 frames per second), but with interlacing create a new half frame every 1/50 of a second (or 50 fields per second). To display interlaced video on <b>progressive</b> scan <b>displays,</b> playback applies deinterlacing to the video signal (which adds input lag).|$|R
50|$|On an EDTV display, or on HDTVs in 480p mode, DVD {{players can}} <b>display</b> <b>progressive</b> disc content without needing {{to convert it}} to {{interlaced}} format. Various signal processing tricks are then used to fake the progressive scan; the quality of this depends {{on the quality of}} the upconversion process.|$|R
50|$|With 57 MHz pixel clock, AA+ could <b>display</b> <b>progressive</b> 800 x 600 @ 72 Hz in 256 colors, or even {{interlaced}} 1024 x 768 screens. Perhaps {{the most}} significant advancement was the addition of 16-bit Chunky mode, although the max resolution for 16-bit pixels would be 640 x 480.|$|R
