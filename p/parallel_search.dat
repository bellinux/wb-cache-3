528|683|Public
25|$|Any search {{strategy}} {{can be used}} to search this space. Prolog uses a sequential, last-in-first-out, backtracking strategy, in which only one alternative and one sub-goal is considered at a time. Other search strategies, such as <b>parallel</b> <b>search,</b> intelligent backtracking, or best-first search to find an optimal solution, are also possible.|$|E
500|$|Huerta, Robert. Giants of Delft: Johannes Vermeer and the Natural Philosophers: The <b>Parallel</b> <b>Search</b> for Knowledge {{during the}} Age of Discovery. Lewisburg, PA: Bucknell University Press, 2003.|$|E
50|$|The {{methods used}} for {{generating}} and-or trees are propositional logic programs (without variables). In {{the case of}} logic programs containing variables, the solutions of conjoint sub-problems must be compatible. Subject to this complication, sequential and <b>parallel</b> <b>search</b> strategies for and-or trees provide a computational model for executing logic programs.|$|E
50|$|YouTorrent was a BitTorrent {{search engine}} which allowed <b>parallel</b> <b>searches</b> on {{different}} torrent search engines.|$|R
40|$|We {{present a}} survey of <b>parallel</b> local <b>search</b> {{algorithms}} in which we review the concepts {{that can be used}} to incorporate parallelism into local search. For this purpose we distinguish between single-walk and multiple-walk <b>parallel</b> local <b>search</b> and between asynchronous and synchronous parallelism. Within the class of single-walk algorithms we differentiate between multiple-step and single-step parallelism. To describe <b>parallel</b> local <b>search</b> we introduce the concepts of hyper neighborhood structures and distributed neighborhood structures. Furthermore, we present templates that capture most of the <b>parallel</b> local <b>search</b> algorithms proposed in the literature. Finally, we discuss some complexity issues related to <b>parallel</b> local <b>search...</b>|$|R
40|$|The {{problem of}} searchability in {{decentralized}} complex networks {{is of great}} importance in computer science, economy and sociology. We present a formalism that is able to cope simultaneously {{with the problem of}} search and the congestion effects that arise when <b>parallel</b> <b>searches</b> are performed, and obtain expressions for the average search cost [...] written in terms of the search algorithm and the topological properties of the network [...] both in presence and abscence of congestion. This formalism is used to obtain optimal network structures for a system using a local search algorithm. It is found that only two classes of networks can be optimal: star-like configurations, when the number of <b>parallel</b> <b>searches</b> is small, and homogeneous-isotropic configurations, when the number of <b>parallel</b> <b>searches</b> is large. Comment: 4 pages. Final version accepted in PR...|$|R
50|$|Any search {{strategy}} {{can be used}} to search this space. Prolog uses a sequential, last-in-first-out, backtracking strategy, in which only one alternative and one sub-goal is considered at a time. Other search strategies, such as <b>parallel</b> <b>search,</b> intelligent backtracking, or best-first search to find an optimal solution, are also possible.|$|E
5000|$|Edax is a {{regularly}} updated Computer Othello program {{written by}} Richard Delorme in 1998. The main algorithms applied {{by the program}} are bitboard move generator, negascout tree search, multi-probcut selective search, <b>parallel</b> <b>search</b> using the Young Brother Wait concept, and pattern based evaluation function. [...] Edax's source code is available {{under the terms of}} the GNU General Public License.|$|E
50|$|Due to {{the absence}} of side effects, a {{functional}} logic program can be executed with different strategies. To evaluate expressions, Curry uses a variant of the needed narrowing strategy which combines lazy evaluation with non-deterministic search strategies. In contrast to Prolog, which uses backtracking to search for solutions, Curry does not fix a particular search strategy. Hence, there are implementations of Curry, like KiCS2, where the user can easily select a search strategy, like depth-first search (backtracking), breadth-first search, iterative deepening, or <b>parallel</b> <b>search.</b>|$|E
50|$|Distributed.net has {{completed}} distributed massively <b>parallel</b> <b>searches</b> for optimal order-24 through order-27 Golomb rulers, each time confirming the suspected candidate ruler. In February 2014, distributed.net began the search to find optimal Golomb rulers (OGRs) of order-28.|$|R
40|$|Tree searching is a {{fundamental}} and computationally intensive problem in artificial intelligence. Parallelization of tree-searching algorithms is one method of improving the speed of these algorithms. However, a high-performance <b>parallel</b> two-player game-tree <b>search</b> algorithm has eluded researchers. Most <b>parallel</b> game-tree <b>search</b> approaches follow synchronous methods, where the work is concentrated within a specific part of the tree, or a given search depth. This thesis shows that asynchronous gametree search algorithms can be as efficient as synchronous methods in determining the minimax value. A taxonomy of previous work in <b>parallel</b> game-tree <b>search</b> is presented. A theoretical model is developed for comparing the efficiency of synchronous and asynchronous search algorithms under realistic assumptions. APHID, a portable <b>parallel</b> game-tree <b>search</b> library, has been built based on the asynchronous <b>parallel</b> game-tree <b>search</b> algorithm proposed in the comparison. The library is easy to imple [...] ...|$|R
40|$|We {{present in}} this paper {{a new model of}} {{artificial}} ants foraging behavior based on a population of primitive ants (Pachycondyla apicalis) and its application to the general problem of optimization. These ants are characterized by a relatively simple but efficient strategy of prey search where individuals hunt alone and try to cover uniformly a given area around their nest. This is performed by <b>parallel</b> local <b>searches</b> on hunting sites with a sensitivity to successful sites. Also, the nest is moved periodically. This corresponds in optimization to an algorithm performing several random <b>parallel</b> <b>searches</b> which are localized uniformly in a sub-space centered around a point. Moving the nest corresponds to a restart operator of the <b>parallel</b> <b>searches</b> where the central point is moved. Furthermore, these ants are able to perform some form of recruitment called "tandem-running" where one leading ant is followed by another one to a given interesting site. We have applied this algorithmic model, called API, to combinatorial and numerical optimization problems...|$|R
50|$|In Mexico in September 2007 Zappa won a {{match against}} Rybka by {{a score of}} 5½ - 4½. Many {{commentators}} had predicted a slew of draws based {{on the strength of}} the engines, but the differences in style provided an interesting match with several decisive games and many fighting draws. For some time, Zappa was considered one of the two strongest commercially available chess programs; see engine rating lists like CCRL for current rankings. Some speculate that Zappa's more efficient SMP <b>parallel</b> <b>search</b> could make it stronger on enough processors.|$|E
50|$|Once memory traces {{corresponding}} to specific memory {{are stored in}} the matrix, to retrieve the memory for the recall process one must cue the memory matrix with a specific probe, which {{would be used to}} calculate the similarity between the test vector and the vectors stored in the memory matrix. Because the memory matrix is constantly growing with new traces being added in, one would have to perform a <b>parallel</b> <b>search</b> through all the traces present within the memory matrix to calculate the similarity, whose result can be used to perform either associative recognition, or with probabilistic choice rule, used to perform a cued recall.|$|E
5000|$|A second main {{function}} of preattentive processes is to direct focal {{attention to the}} most [...] "promising" [...] information in the visual field. There are two ways in which these processes {{can be used to}} direct attention: bottom-up activation (which is stimulus-driven) and top-down activation (which is user-driven). In the guided search model by Jeremy Wolfe, information from top-down and bottom-up processing of the stimulus is used to create a ranking of items in order of their attentional priority. In a visual search, attention will be directed to the item with the highest priority. If that item is rejected, then attention will {{move on to the next}} item and the next, and so forth. The guided search theory follows that of <b>parallel</b> <b>search</b> processing.|$|E
5000|$|The Sword Project and Olive Tree Bible Software {{both have}} modules {{for both the}} New Chinese Version and the Union Version of the Bible. More {{recently}} (as of January 2014) these bibles were made available for <b>parallel</b> <b>searching</b> at BibleHunter.com & Holy-Bibles.net [...]|$|R
40|$|The article {{introduces}} {{three models}} describing <b>parallel</b> <b>searching</b> of multiple resources: a model unifying user interface, a model with centralized search engine, {{and a model}} based on a preharvested central index. The aim is to provide factual basis for proposals of Czech terminology {{in this type of}} information retrieval...|$|R
5000|$|Dimension agnostic, <b>parallel</b> {{geometric}} <b>search</b> (for contact related applications) ...|$|R
50|$|An {{activation}} map is {{a representation}} of visual space in which the level of activation at a location reflects {{the likelihood that the}} location contains a target. This likelihood is based on preattentive, featural information of the perceiver. According to the guided search model, the initial processing of basic features produces an activation map, with every item in the visual display having its own level of activation. Attention is demanded based on peaks of activation in the activation map in a search for the target. Visual search can proceed efficiently or inefficiently. During efficient search, performance is unaffected by the number of distractor items. The reaction time functions are flat, and the search is assumed to be a <b>parallel</b> <b>search.</b> Thus, in the guided search model, a search is efficient if the target generates the highest, or one of the highest activation peaks. For example, suppose someone is searching for red, horizontal targets. Feature processing would activate all red objects and all horizontal objects. Attention is then directed to items depending on their level of activation, starting with those most activated. This explains why search times are longer when distractors share one or more features with the target stimuli. In contrast, during inefficient search, the reaction time to identify the target increases linearly with the number of distractor items present. According to the guided search model, this is because the peak generated by the target {{is not one of the}} highest.|$|E
40|$|We {{present a}} {{systematic}} analysis of a lexical-tree based <b>parallel</b> <b>search</b> algorithm for multi-core desktop processors. We introduce an analytical model that predicts the speedup from parallelization after accounting for load imbalance among the cores. Various sources of overhead in the <b>parallel</b> <b>search</b> algorithm are described, benchmarked and analyzed. Besides load imbalance, these include the inherently serial steps of the <b>parallel</b> <b>search</b> algorithm {{and an increase in}} main memory access latency. 1...|$|E
40|$|In this paper, we {{describe}} the design and implementation of a reusable load balancer for <b>parallel</b> <b>search</b> problems. <b>Parallel</b> <b>search</b> problems are a significant research topic in the parallel processing area: these applications expose irregularities that require dynamic load balancing techniques. status: publishe...|$|E
40|$|Researchers {{have been}} {{actively}} pursuing load balancing schemes for <b>parallel</b> <b>searches</b> {{in an attempt}} to achieve linear or near linear speedups. Most of the approaches have used message based distributed models. Although, they have been successfully ported to shared-memory systems, their designs and approaches are counter intuitive and cumbersome for symmetric multiprocessing architectures. Here, we present an asynchronous load balancing scheme that is a natural programming model for symmetric multiprocessor machines. We test the scheme on two classic problems using different search strategies and find it effective in obtaining linear or near linear speedups. Keywords: load balancing, threads, parallelism. 1. INTRODUCTION <b>Parallel</b> <b>searches</b> have proven to be very beneficial for the Artificial Intelligence and Operations Research communities [1][2][3]. Large combinatorial problems, which otherwise are impractical for a single processor, can be solved by exploiting the parallelism of m [...] ...|$|R
40|$|AbstractIn {{this paper}} we {{investigate}} <b>parallel</b> <b>searching</b> {{in the plane}} using robots as searchers. We show that {{a huge number of}} robots are not necessary for several problems and under different assumptions. This corresponds to real situations since, actually, the number of processors of parallel machines is fixed and independent of the dimension of the problem to be solved...|$|R
40|$|In {{this paper}} {{we present a}} new {{optimization}} algorithm based on {{a model of the}} foraging behavior of a population of primitive ants (Pachycondyla apicalis). These ants are characterized by a relatively simple but efficient strategy for prey search in which individuals hunt alone and try to cover a given area around their nest. The ant colony search behavior consists of a set of <b>parallel</b> local <b>searches</b> on hunting sites with a sensitivity to successful sites. Also, their nest is periodically moved. Accordingly, the proposed algorithm performs <b>parallel</b> random <b>searches</b> in the neighborhood of points called hunting sites. Hunting sites are created in the neighborhood of a point called nest. At constant intervals of time the nest is moved, which corresponds to a restart operator which re-initializes the <b>parallel</b> <b>searches.</b> We have applied this algorithm, called API, to numerical optimization problems with encouraging results. 2000 Elsevier Science B. V...|$|R
40|$|Parallelism and {{distribution}} are two distinct concepts that are confusingly close. <b>Parallel</b> <b>Search</b> refers {{in this work}} to {{the distribution of the}} search space and Distributed Asynchronous Search to the distribution of the constraint predicates. A certain amount of parallelism exists in any Distributed Asynchronous Search and it increases with the degree of asynchronism. However, in comparison to <b>Parallel</b> <b>Search</b> [10], the parallel effort in Distributed Asynchronous Search can be more redundant. Moreover, agents in Asynchronous Search can have periods of inactivity which are less frequent in <b>Parallel</b> <b>Search.</b> Since Distributed Search is the only solution for certain classes of naturally distributed problems, we show here how one can integrate the idea of <b>Parallel</b> <b>Search</b> in Distributed Asynchronous Search. A technique for dynamic reallocation of search space is then presented. This technique builds on the procedure for marking concurrent proposals for conflicting resources, that we have formalized in [11]. ...|$|E
40|$|Abstract — This work {{examines}} a novel {{method that}} provides a <b>parallel</b> <b>search</b> {{of a very large}} network space consisting of fisheries management data. The <b>parallel</b> <b>search</b> solution is capable of determining global maxima of the search space using brute force search, compared to local optima located by machine learning solutions such as evolutionary computation. The actual solutions from the best machine learning technique, called Probabilistic Adaptive Mapping Developmental Genetic Algorithm, are compared by a fisheries expert to the global maxima solutions returned by <b>parallel</b> <b>search.</b> In addition, the time required for <b>parallel</b> <b>search,</b> for both CPU and GPU-optimized solutions, are compared to those required for machine learning solutions. The GPU parallel computing solution was found to have a speedup of over 10, 000 x, in excess of most similar performance comparison studies in the literature. An expert found that overall the machine learning solutions pro-duced more interesting results by locating local optima than global optima determined by parallel processing. I...|$|E
40|$|Many {{artificial}} intelligence techniques rely on heuris-tic search through large spaces. Because the compu-tational effort required to search through these spaces reduces {{the applicability of}} the techniques, a number of parallel and distributed approaches to search have been introduced to improve the performance of certain aspects of the search process. However, theoretical and experimental results have shown that the effec-tiveness of <b>parallel</b> <b>search</b> algorithms can vary greatly from one search problem to another. In this paper we investigate the use of uncertainty rea-soning to choose the <b>parallel</b> <b>search</b> techniques that maximize the speedup obtained by <b>parallel</b> <b>search.</b> The approach described here is implemented in the EUREKA system, an architecture that includes diverse approaches <b>parallel</b> <b>search.</b> When a new search task is input to the system, EUREKA gathers information about the search space and automatically selects the appropriate search strategy. Because the gathered in-formation is uncertain and incomplete, we use a belief network to model the influence of problem features on speedup and select strategies that will yield the best performance. We present preliminary results on search problems drawn from the Fifteen Puzzle domain...|$|E
50|$|In {{order to}} explain the IOR mechanism, Anne Treisman and Gary Gelade's theory of visual search was expounded. This theory, known as the feature {{integration}} theory proposes {{that there are two}} types of visual searches: <b>parallel</b> <b>searches</b> and serial searches. According to Treisman and Gelade, attention is only required for serial searches. IOR is a mechanism that is specific for serial searches.|$|R
50|$|An and-or tree {{specifies}} {{only the}} search space for solving a problem. Different search strategies for searching the space are possible. These include searching the tree depth-first, breadth-first, or best-first using {{some measure of}} desirability of solutions. The search strategy can be sequential, searching or generating one node at a time, or <b>parallel,</b> <b>searching</b> or generating several nodes in parallel.|$|R
40|$|Biological applications, from {{genomics}} to ecology, {{deal with}} graphs {{that represents the}} structure of interactions. Analyzing such data requires searching for subgraphs in collections of graphs. This task is computationally expensive. Even though multicore architectures, from commodity computers to more advanced symmetric multiprocessing (SMP), offer scalable computing power, currently published software implementations for indexing and graph matching are fundamentally sequential. As a consequence, such software implementations (i) do not fully exploit available parallel computing power and (ii) they do not scale {{with respect to the}} size of graphs in the database. We present GRAPES, software for <b>parallel</b> <b>searching</b> on databases of large biological graphs. GRAPES implements a parallel version of well-established graph searching algorithms, and introduces new strategies which naturally lead to a faster <b>parallel</b> <b>searching</b> system especially for large graphs. GRAPES decomposes graphs into subcomponents that can be efficiently <b>searched</b> in <b>parallel.</b> We show the performance of GRAPES on representative biological datasets containing antiviral chemical compounds, DNA, RNA, proteins, protein contact maps and protein interactions networks...|$|R
40|$|Abstract. In {{this paper}} we discuss methods for {{predicting}} the performance of any formulation of randomized <b>parallel</b> <b>search,</b> and propose a new performance prediction method {{that is based on}} obtaining an accurate estimate of the k-processor run-time distribution. We show that the k-processor prediction method delivers accurate performance predictions and demonstrate the validity of our analysis on several robot motion planning problems. Key words: randomized path planning, randomized <b>parallel</b> <b>search,</b> performance evaluation, parallel computers...|$|E
40|$|One of the {{principal}} advantages of parallelizing a rule-based system, or more generally, any A. I. system, {{is the ability to}} pursue alternate search paths concurrently. Conventional memory representations for production systems cannot easily or efficiently support <b>parallel</b> <b>search</b> because of the essentially flat structure of working memory and the combinatorics of pursuing pattern matching in a large memory space. A further obstacle to the effective exploitation of parallelism is the problem of maintaining the internal consistency of each search space while performing parallel activities in other spaces. This paper presents an approach to <b>parallel</b> <b>search</b> for rule-based systems which involves maintaining multiple separate worlds, each representing a search space. Constructs for creating, manipulating, and merging separate spaces are discussed. We describe how the addition of a language mechanism for specifying multiple worlds simplifies the design of <b>parallel</b> <b>search</b> algorithms, increases [...] ...|$|E
40|$|Program parallelization becomes {{increasingly}} important when new multi-core architectures provide {{ways to improve}} performance. One {{of the greatest challenges}} of this development lies in programming parallel applications. Declarative languages, such as constraint programming, can make the transition to parallelism easier by hiding the parallelization details in a framework. Automatic parallelization in constraint programming has mostly focused on <b>parallel</b> <b>search.</b> While search and consistency are intrinsically linked, the consistency part of the solving process is often more time-consuming. We have previously looked at parallel consistency and found it to be quite promising. In this paper we investigate how to combine <b>parallel</b> <b>search</b> with parallel consistency. We evaluate which problems are suitable and which are not. Our results show that parallelizing the entire solving process in constraint programming is a major challenge as <b>parallel</b> <b>search</b> and parallel consistency typically suit different types of problems...|$|E
40|$|Abstract. In {{this paper}} we prove global {{convergence}} for asynchronous <b>parallel</b> pattern <b>search.</b> In standard pattern search, decisions regarding the update of the iterate and the step-length control parameter are synchronized implicitly across all search directions. We lose this feature in asynchronous <b>parallel</b> pattern <b>search</b> since the search along each direction proceeds semi-autonomously. By bounding {{the value of}} the step-length control parameter after any step that produces decrease along a single search direction, we can prove that all the processes share a common accumulation point and, if the function is continuously differentiable, that such a point is a stationary point of the standard nonlinear unconstrained optimization problem. Key words. asynchronous <b>parallel</b> optimization, pattern <b>search,</b> unconstrained optimization, global convergence analysis 1. Introduction. Asynchronous <b>parallel</b> pattern <b>search</b> (APPS) was introduced in [5] as a way to solve in a parallel or distributed computing environment nonlinear optimization problems of the form (1. 1...|$|R
40|$|We {{show how}} node {{ordering}} {{can be combined}} with <b>parallel</b> window <b>search</b> to quickly find a nearly optimal solution to single-agent problems. First, we show how node ordering by maximum g among nodes with equal / = g + h values can improve the performance of IDA*. We then consider a window search where different processes perform IDA * simultaneously on the same problem but with different cost thresholds. Finally, we combine the two ideas to produce a <b>parallel</b> window <b>search</b> algorithm in which node ordering information is shared among the different processes. <b>Parallel</b> window <b>search</b> {{can be used to}} find a nearly optimal solution quickly, improve the solution until it is optimal, and then finally guarantee optimality, depending on the amount of time available. ...|$|R
40|$|We {{presented}} a <b>parallel</b> tabu <b>search</b> (PTS) algorithm for the traveling salesman problem (TSP), which is NP-hard. To parallelize tabu search (TS) algorithm efficiently, the search space decomposition based on partition principle {{was used to}} balance the computing load, while exploitation in subspace had been boosted by an adaptive search strategy of intensification and diversification. Numerical results illustrated this algorithm was efficient and easy to implement. Key words: <b>Parallel</b> Tabu <b>Search,</b> Meta-heuristic, TS...|$|R
