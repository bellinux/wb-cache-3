7|512|Public
5000|$|Paging. The network sends a RR <b>Paging</b> <b>Request</b> message (GSM 04.08 Sections 9.1.22-9.1.23) {{over the}} PCH, using the subscriber's IMSI or TMSI as an address. GSM {{does not allow}} paging by IMEI (GSM 04.08 Section 10.5.1.4). This paging step occurs only for a {{transaction}} initiated by the network.|$|E
50|$|If the {{subscriber}} {{does not}} respond to the <b>paging</b> <b>request,</b> either due to being out of coverage, or their battery has gone flat/removed, then the Visited MSC routes the call to a pre-determined Call Forward Not Reachable (CFNRc) number. Once again, the operator may decide to set this value by default to the voice mail of the mobile so that callers can leave a message.|$|E
50|$|If the {{location}} areas are very large, {{there will be}} many mobiles operating simultaneously, resulting in very high paging traffic, as every <b>paging</b> <b>request</b> has to be broadcast to every base station in {{the location}} area. This wastes bandwidth and power on the mobile, by requiring it to listen for broadcast messages too much of the time. If on the other hand, there are too many small location areas, the mobile must contact the network very often for changes of location, which will also drain the mobile's battery. A balance has therefore to be struck.|$|E
50|$|A clickstream is {{a series}} of <b>page</b> <b>requests,</b> every <b>page</b> <b>requested</b> generates a signal. These signals can be {{graphically}} represented for clickstream reporting. The main point of clickstream tracking is to give webmasters insight into what visitors on their site are doing.|$|R
40|$|Wireless data {{broadcasting}} is a promising way of disseminating {{information to a}} massive number of clients in an asymmetric communication environment where client-to-server communication is infeasible. An important issue {{to be addressed in}} {{data broadcasting}} is how to organize the data in the broadcast {{in such a way that}} the access latency of client <b>page</b> <b>requests</b> is minimized. Due to the lack of communication from clients to the server, the server cannot know what a client needs at the current slot. We consider a broadcasting policy in which the server transmits, at each slot, the page which is most likely to be requested by the client, given the history of previous broadcasts. The policy is easily implementable since a simple recursive algorithm provides the conditional distribution of <b>page</b> <b>requests</b> at slot n from the same distribution at slot n- 1. The policy derives broadcasting sequences which are periodic in steady state and incurs low latency for <b>page</b> <b>requests</b> as it is verified by extensive numerical experiments with a wide variety of <b>page</b> <b>request</b> processes. Hence, it provides a valuable method for designing broadcasting schedules for both correlated and uncorrelated <b>page</b> <b>request</b> sequences...|$|R
50|$|Kevin <b>Page</b> <b>requested</b> {{that the}} DND present a {{breakdown}} of the $9-billion acquisition cost cited by the government.|$|R
50|$|Virtual memory {{compression}} (also {{referred to}} as RAM compression and memory compression) is a memory management technique that utilizes data compression {{to reduce the size}} or number of paging requests to and from the auxiliary storage. In a virtual memory compression system, paging requests are compressed and stored in physical memory, which is usually random-access memory (RAM), or sent as compressed to auxiliary storage such as a hard disk drive (HDD) or solid-state drive (SSD). In both cases the virtual memory range whose contents has been compressed during the <b>paging</b> <b>request</b> is marked inaccessible so that attempts to access compressed pages can trigger page faults and reversal of the process (retrieval from auxiliary storage and decompression). The footprint of the data being paged is reduced by the compression process; in the first instance, the freed RAM is returned to the available physical memory pool, while the compressed portion is kept in RAM. In the second instance, the compressed data is sent to auxiliary storage but the resulting I/O operation is smaller and therefore takes less time.|$|E
5000|$|Paging Success by far is {{the most}} complex KPI to deal with as the process of paging touches almost all the nodes in GSM system and is {{influenced}} by performance of each of them. That’s the reason why this write up on paging looks too interwoven and cross refers to too many things. But the plus point with paging is by the time paging success rate in a network gets improved; almost all the other KPIs too stand improved. In response to an incoming call, the MSC initiates the paging process by broadcasting a [...] "paging request" [...] message on the paging sub channel (IMSI or TMSI of the MS and its Paging Group) and starts timer T3113. A [...] "paging message" [...] consists of the mobile identity (IMSI or TMSI) of the MS being paged and its [...] "paging group number". A <b>Paging</b> <b>Request</b> Message may include more than one MS identification. The maximum number of paged MS per message is 4 when using [...] "TMSI" [...] for identification of the MS (maximum number of paged MS per message is 2 when using IMSI). The BSC receives this page and processes the <b>paging</b> <b>request</b> and schedules it for transmission on the PCH at appropriate time. The MS on its part will analyse the paging messages (and immediate assignment messages) sent on the paging sub channel corresponding to its paging group. Upon receipt of a [...] "paging request" [...] message, MS will initiate within 0.7s an immediate assignment procedure. Upon receipt of a page at the MS, the MS responds by transmitting a channel request on the RACH. BSS {{in response to the}} received [...] "channel request", will process it and immediately assign the MS a SDCCH (immediate assignment / assignment reject; done over AGCH). MS Paging response- After receiving the immediate assignment command, MS switches to the assigned [...] "SDCCH" [...] and transmits a [...] "Paging Response". The establishment of the main signalling link is then initiated with information field containing the [...] "PAGING RESPONSE" [...] message and the [...] "paging response" [...] is sent to the MSC. Upon receipt of the [...] "Paging Response" [...] MSC stops the timer T3113. If the timer T3113 expires and a [...] "Paging Response"message has not been received, the MSC may repeat the [...] "Paging Request" [...] message and start T3113 all over again. The number of successive paging attempt is a network dependent choice.|$|E
40|$|In this paper, {{we propose}} a cost {{effective}} IP paging protocol, {{which can be}} used for terminal paging in next-generation wireless IP networks. In the existing IP paging protocols, a <b>paging</b> <b>request</b> packet is delivered to access routers belonging to a paging area by unicast or multicast. However, unicast and multicast result in higher cost, so that we present a selective paging algorithm utilizing explicit multicast (xcast). Xcast is a new kind of multicast scheme for small sized groups which uses unicast with low maintenance overhead. In terms of the paging algorithm, we use a selective paging algorithm to minimize the paging cost, by dividing a paging area into several sub-paging areas, while meeting the paging delay bound. In addition, we propose flexible grouping algorithms. For the performance analysis, we develop analytical paging cost and delay models based on the random walk model. Using the models, we compare the selective IP paging scheme using xcast with the existing paging schemes that use unicast or multicast. The results indicate that the proposed scheme significantly reduces the paging cost compared with traditional schemes, especially when the transmission cost is relatively less than the processing cost and the delivery path is not long. In addition, our flexible grouping algorithms, which are adaptive to the session-to-mobility ratio, provide less paging cost and guarantee equal to or less paging delay compared with the existing schemes...|$|E
30|$|Web <b>page</b> <b>request.</b> The {{web client}} {{retrieves}} {{information about the}} structure of the web content. The cellular air interface is used sporadically.|$|R
3000|$|... is the {{proportion}} of page d among <b>pages</b> <b>requested</b> by user i; it shows how much user {{i was interested in}} page d of the server.|$|R
25|$|Wikimedia Foundation data (based on user agent) for September 2013 {{shows that}} Ubuntu {{generated}} the most <b>page</b> <b>requests</b> to Wikimedia sites, including Wikipedia, among recognizable Linux distributions.|$|R
40|$|Multi-step paging {{has been}} widely {{proposed}} in personal communications services (PCS) systems to reduce the signaling overheads. Similar ideas {{can be applied to}} Mobile IP to provide IP paging services. However, current proposed multi-step paging schemes are user dependent under which the partition of paging areas and the selection of paging sequence are different for each user. The performance of a user dependent paging scheme for individual users may be affected by many factors. It is often difficult to achieve perfect performance for each user. In addition, when multiple users are paged at the same time, user dependent paging schemes may consume significant system resources. This paper introduces a user independent paging scheme where the paging criterion is not based on individual user information. The goal of user independent paging is to provide satisfactory overall performance of the whole system, when personalized optimal performance for each user is hard to obtain. The user independent paging scheme is proposed for IP mobility for its easy implementation and convenient combination with <b>paging</b> <b>request</b> aggregation. The paging criterion adopted is the mobility rate of each subnet determined by the aggregated movements of all mobile users. In order to implement the proposed scheme, a concept of “semi-idle state ” is introduced and the detailed solution for obtaining mobility rate is presented. Analytical results show that when paging one user at a time, the performance of the proposed user independent paging scheme is comparable to that of the paging schemes based on perfect knowledge of user movement statistics. When paging multiple users simultaneously and when the knowledge on individual user behavior is not perfectly accurate, the proposed scheme has remarkable advantages in terms of reducing the overall paging cost...|$|E
40|$|In {{communications}} systems, mobile units must {{be found}} before information may be routed to them. The process of finding each unit, called paging, {{requires the use of}} limited radio and fixed network resources. Thus, the rate at which units can be found on average and the rate at which <b>page</b> <b>requests</b> can be satisfied subject to a delay criterion is intimately tied to the polling discipline employed by the system. Here we consider simple polling schemes which can greatly increase the rate at which <b>page</b> <b>requests</b> can be processed while maintaining acceptable average delay...|$|R
2500|$|Wikipedia {{receives}} between 25,000 and 60,000 <b>page</b> <b>requests</b> per second, {{depending on}} time of day. [...] <b>page</b> <b>requests</b> are first passed to a front-end layer of Squid caching servers. Further statistics, {{based on a}} publicly available 3-month Wikipedia access trace, are available. Requests that cannot be served from the Squid cache are sent to load-balancing servers running the Linux Virtual Server software, which in turn pass them {{to one of the}} Apache web servers for page rendering from the database. The web servers deliver <b>pages</b> as <b>requested,</b> performing <b>page</b> rendering for all the language editions of Wikipedia. To increase speed further, rendered pages are cached in a distributed memory cache until invalidated, allowing page rendering to be skipped entirely for most common page accesses.|$|R
50|$|In December 2016, Da Corte wrote {{a comment}} on a post made by the Halt Action Group Instagram <b>page</b> <b>requesting</b> that Ivanka Trump remove his artwork from her home.|$|R
50|$|Pull {{requests}} {{form the}} foundation of network computing, where many clients request data from centralised servers. Pull is used extensively on the Internet for HTTP <b>page</b> <b>requests</b> from websites.|$|R
50|$|Google Web Accelerator sent <b>requests</b> for web <b>pages,</b> {{except for}} secure web pages (HTTPS), to Google, which logged these <b>requests.</b> Some web <b>pages</b> {{embedded}} personal information in these <b>page</b> <b>requests.</b>|$|R
50|$|As for readers: it is 134th {{of about}} 290 {{in number of}} page requests: half a million <b>page</b> <b>requests</b> per month, but not {{possible}} {{to know how many}} human readers.|$|R
5000|$|Intercepts {{requests}} to any static or dynamically generated HTML <b>page</b> <b>requested</b> through the web-server, processes {{the content and}} then merges it {{with one or more}} decorators to build the final result.|$|R
40|$|This paper {{presents}} a Page Rank based prefetching technique for accesses to web page clusters. The approach uses the link {{structure of a}} <b>requested</b> <b>page</b> to determine the “most important ” linked pages and to identify the page(s) to be prefetched. The underlying premise of our approach {{is that in the}} case of cluster accesses, the next <b>pages</b> <b>requested</b> by users of the web server are typically based on the current and previous <b>pages</b> <b>requested.</b> Furthermore, if the <b>requested</b> <b>pages</b> have a lot of links to some “important ” page, that page has a higher probability of being the next one requested. An experimental evaluation of the prefetching mechanism is presented using real server logs. The results show that the Page-Rank based scheme does better than random prefetching for clustered accesses, with hit rates of 90 % in some cases...|$|R
50|$|A typical {{example is}} a web server log which {{maintains}} a history of <b>page</b> <b>requests.</b> The W3C maintains a standard format (the Common Log Format) for web server log files, but other proprietary formats exist. More recent entries are typically appended {{to the end of}} the file. Information about the request, including client IP address, <b>request</b> date/time, <b>page</b> <b>requested,</b> HTTP code, bytes served, user agent, and referrer are typically added. This data can be combined into a single file, or separated into distinct logs, such as an access log, error log, or referrer log. However, server logs typically do not collect user-specific information.|$|R
5000|$|The {{value of}} a cookie can be {{modified}} by the server by including a [...] header {{in response to a}} <b>page</b> <b>request.</b> The browser then replaces the old value with the new value.|$|R
3000|$|Altruistic behavior. Each {{device is}} sharing its {{cellular}} link {{even if it}} is not interested in web browsing. In this case, neglecting the <b>page</b> <b>request</b> phase due to the small amount of data, [...]...|$|R
5000|$|The {{site also}} {{collects}} IP addresses and [...] "information such as <b>page</b> <b>requests,</b> browser type, operating system, average {{time spent on}} the website, and pixel codes (i.e. which pages you visit on the website)".|$|R
5000|$|Peripheral memory paging can be {{supported}} by an IOMMU. A peripheral using the PCI-SIG PCIe Address Translation Services (ATS) <b>Page</b> <b>Request</b> Interface (PRI) extension can detect and signal the need for memory manager services.|$|R
40|$|Background The Primary Care Electronic Library (PCEL) is a {{collection}} of indexed and abstracted internet resources. PCEL contains a directory of quality-assured internet material with associated search facilities. PCEL has been indexed, using metadata and established taxonomies. Site development requires an understanding of usage; this paper reports the use of open source tools to evaluate usage. This evaluation was conducted during a six-month period of development of PCEL. Objective To use open source to evaluate changes in usage of an electronic library. Method We defined data we needed for analysis; this included: <b>page</b> <b>requests,</b> visits, unique visitors, <b>page</b> <b>requests</b> per visit, geographical location of users, NHS users, chronological information about users and resources used. Results During the evaluation period, <b>page</b> <b>requests</b> increased from 3500 to 10 000; visits from 1250 to 2300; and unique visitors from 750 to 1500. Up to 83 % of users come from the UK, 15 % were NHS users. The <b>page</b> <b>requests</b> of NHS users are slowly increasing but not as fast as requests by other users in the UK. PCEL is primarily used Monday to Friday, 9 a. m. to 5 p. m. Monday is the busiest day with use lessening through the week. NHS users had a different list of top ten resources accessed than non-NHS users, with only four resources appearing in both. Conclusions Open source tools provide useful data which can be used to evaluate online resources. Improving the functionality of PCEL has been associated with increased use...|$|R
40|$|This paper {{presents}} {{a framework for}} increasing the relevancy of the web pages retrieved by the search engine. The approach introduces a Predictive Prefetching Engine (PPE) which makes use of various data mining algorithms on the log maintained by the search engine. The underlying premise of the approach {{is that in the}} case of cluster accesses, the next <b>pages</b> <b>requested</b> by users of the Web server are typically based on the current and previous <b>pages</b> <b>requested.</b> Based on same, rules are drawn which then lead the path for prefetching the desired pages. To carry out the desired task of prefetching the more relevant pages, agents have been introduced. Comment: 9 page...|$|R
50|$|Slovenia {{is noted}} {{as one of}} the leading European {{countries}} by the percentage of users who browse the web using Mozilla Firefox. In 2007, 47.9% <b>page</b> <b>requests</b> were made with Firefox, more than in any other European country.|$|R
50|$|The yearly {{summary report}} {{provides}} such information {{as the number}} of hits, file and <b>page</b> <b>requests,</b> hosts and visits, as well as daily averages of these counters for each month. The report is accompanied by a yearly summary graph.|$|R
50|$|This way, any {{subsequent}} <b>page</b> <b>request</b> {{from this}} user {{will carry the}} same query string , {{making it possible to}} establish that all these pages have been viewed by the same user. Query strings are often used in association with web beacons.|$|R
40|$|We {{propose a}} provably {{efficient}} application-controlled global strategy for organizing {{a cache of}} size k shared among P application processes. Each application has access to information about its own future <b>page</b> <b>requests,</b> and by using that local information along with randomization {{in the context of}} a global caching algorithm, we are able to break through the conventional H k ln k lower bound on the competitive ratio for the caching problem. If the P application processes always make good cache replacement decisions, our online application-controlled caching algorithm attains a competitive ratio of 2 HP Γ 1 + 2 2 ln P. Typically, P is much smaller than k, perhaps by several orders of magnitude. Our competitive ratio improves upon the 2 P + 2 competitive ratio achieved by the deterministic application-controlled strategy of Cao, Felten, and Li. We show that no online application-controlled algorithm can have a competitive ratio better than minfHP Γ 1; H k g, even if each application process has perfect knowledge of its individual <b>page</b> <b>request</b> sequence. Our results are with respect to a worst-case interleaving of the individual <b>page</b> <b>request</b> sequences of the P application processes...|$|R
40|$|Abstract. Before user {{modeling}} servers can be deployed to real-world application environments with potentially millions of users, their runtime behavior must be experimentally verified under realistic workload conditions to ascertain their satisfactory {{performance in the}} target domain. This paper discusses performance experiments which systematically vary the number of profiles available in the {{user modeling}} server, {{and the frequency of}} <b>page</b> <b>requests</b> that simulated users submit to a hypothetical personalized website. The parameters of this simulation are based on empirical web usage research. For small to medium sized test scenarios, the processing time for a representative mix of user modeling operations was found to only degressively increase with the frequency of <b>page</b> <b>requests.</b> The distribution of the user modeling server across a network of computers additionally accelerated those operations that are amenable to parallel execution. A large-scale test with several million active user profiles and a <b>page</b> <b>request</b> rate that is representative of major websites confirmed that the user modeling performance of our server will not impose a significant overhead for a personalized website. It also corroborated our earlier finding that directories provide a superior foundation for user modeling servers than traditionally used data bases and knowledge bases. ...|$|R
40|$|Application Layer Distributed Denial of Service (ALDDoS) {{attacks have}} been {{increasing}} rapidly {{with the growth}} of Botnets and Ubiquitous computing. Differentiate to the former DDoS attacks, ALDDoS attacks cannot be efficiently detected, as attackers always adopt legitimate requests with real IP address, and the traffic has high similarity to legitimate traffic. In spite of that, we think, the attackers 2 ̆ 7 browsing behavior will have great disparity from that of the legitimate users 2 ̆ 7. In this paper, we put forward a novel user behavior-based method to detect the application layer asymmetric DDoS attack. We introduce an extended random walk model to describe user browsing behavior and establish the legitimate pattern of browsing sequences. For each incoming browser, we observe his <b>page</b> <b>request</b> sequence and predict subsequent <b>page</b> <b>request</b> sequence based on random walk model. The similarity between the predicted and the observed <b>page</b> <b>request</b> sequence is used as a criterion to measure the legality of the user, and then attacker would be detected based on it. Evaluation results based on real collected data set has demonstrated that our method is very effective in detecting asymmetric ALDDoS attacks. © 2014 IEEE...|$|R
40|$|Response {{time delays}} caused by I/O {{are a major}} problem in many systems and {{database}} applications. Prefetching and cache replacement methods are attracting renewed attention because of their success in avoiding costly I/Os. Prefetching can be looked upon as a type of online sequential prediction, where the predictions must be accurate as well as made in a computationally efficient way. Unlike other online problems, prefetching cannot admit a competitive analysis, since the optimal offline prefetcher incurs no cost when it knows the future <b>page</b> <b>requests.</b> Previous analytical work on prefetching [J. Assoc. Comput. Mach., 143 (1996), pp. 771 – 793] consisted of modeling the user as a probabilistic Markov source. In this paper, we look at the much stronger form of worst-case analysis and derive a randomized algorithm for pure prefetching. We compare our algorithm for every <b>page</b> <b>request</b> sequence with the important class of finite state prefetchers, making no assumptions as to how the sequence of <b>page</b> <b>requests</b> is generated. We prove analytically that the fault rate of our online prefetching algorithm converges almost surely for every <b>page</b> <b>request</b> sequence to the fault rate of the optimal finite state prefetcher for the sequence. This analysis model can be looked upon as a generalization of the competitive framework, in that it compares an online algorithm in a worst-case manner over all sequences with a powerful yet nonclairvoyant opponent. We simultaneously achieve the computational goal of implementing our prefetcher in optimal constant expected time per prefetched page using the optimal dynamic discrete random variate generator of Matias, Vitter, and Ni [Proc. 4 th Annual SIAM/AC...|$|R
3000|$|Page reading. After waiting {{the whole}} web <b>page</b> <b>request</b> and web <b>page</b> {{download}} phases the content {{is ready to}} be displayed. Now the cellular air interface is idle. The user is now busy consuming the information out of the web page (mean duration [...]...|$|R
