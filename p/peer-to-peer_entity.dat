1|9|Public
40|$|A major {{performance}} {{challenge in}} developing a massively multi-user virtual world is network scalability. This is because the network over which entities communicate can quickly develop into a bottleneck. Three critical factors: bandwidth usage, packets per second, and network-related CPU usage, should be governed {{by the number of}} entities a given user is interested in, not the total number of entities in the world. The challenge then is to allow a virtual world to scale to any size without an appreciable drop in system performance. To address these concerns, this thesis describes a novel Area of Interest Manager (AOIM) built atop the NPSNET-V virtual environment system. It is a dynamically sized, geographical region based, senderside interest manager that supports dynamic entity discovery and <b>peer-to-peer</b> <b>entity</b> communication. The AOIM also makes use of tools provided by the NPSNET-V system, such as variable resolution protocols and variable data transmission rate. Performance tests have shown conclusively that these interest management techniques are able to produce dramatic savings in network bandwidth usage in a peer-to-peer virtual environment. In one test, this AOIM produced a 92 % drop in network traffic, with a simultaneous 500 % increase in world population. US Navy (USN) autho...|$|E
5000|$|SPI-4.1 [...] - [...] System Physical Interface Level 4 (SPI-4) Phase 1: A System Interface for Interconnection Between Physical and Link Layer, or <b>Peer-to-Peer</b> <b>Entities</b> Operating at an OC-192 Rate (10 Gbit/s).|$|R
40|$|Abstract—This paper {{presents}} a massively shared virtual reality {{system based on}} a network of peers. It does not rely on any server nor on IP multicast, and intends to be scalable to an unlimited number of participants. Following a <b>peer-to-peer</b> scheme, <b>entities</b> collaborate {{to build up a}} common virtual world. The behavior of entities, running algorithms in order to maintain local properties, ensures the consistency of the virtual world and the connexity of the network. The paper also describes how entities join the network and enter the virtual world at a particular position...|$|R
40|$|International audienceLack of {{scalability}} is a {{key issue}} for virtual-environment technology, and more generally for any large-scale online experience because it prevents {{the emergence of a}} truly massive virtual-world infrastructure (Metaverse). The Solipsis project tackles this issue through the use of peer-to-peer technology, and makes it possible to build and manage a world-scale Metaverse in a truly distributed manner. Following a <b>peer-to-peer</b> scheme, <b>entities</b> collaborate to build up a common set of virtual worlds. In this paper, we present a first draft of the architecture as well as the communication protocol used to share data between peers. The protocol is based on Raynet, an n-dimensional Voronoi-based overlay network. Its data-dissemination policy takes advantage of the view-depedent representation of 3 D contents. Moreover, the protocol effectively distributes the execution of computationally intensive tasks that are usually executed on the server-side, such as collision detection and physics computation. Finally, we also present our web component, a 3 D navigator that can easily run on terminals with scarce resources, and that provides solutions for smooth transitions between 3 D Web and Web 2. 0...|$|R
40|$|Abstract — With the {{widespread}} availability of inexpensive broadband Internet connections for home-users, {{a large number}} of bandwidth-intensive applications previously not feasible have now become practical. This is the case for multimedia live streaming, for which end-user’s dial-up/ISDN modem connections once were the bottleneck. The bottleneck is now mostly found on the server side: the bandwidth required for serving many clients at once is large and thus very costly to the broadcasting <b>entity.</b> <b>Peer-to-peer</b> systems for on-demand and live streaming have proved to be an encouraging solution, since they can shift the burden of content distribution from the server to the users of the network. In this work we introduce PULSE, a P 2 P system for live streaming whose main goals are flexibility, scalability, and robustness. We present the fundamental concepts of PULSE along with its intended global behavior and describe in detail the main algorithms running on its nodes. I...|$|R
40|$|With the {{widespread}} availability of inexpensive broadband Internet connections for homeusers, {{a large number}} of bandwidth-intensive applications which were not possible before have now become practical. This is the case for multimedia live streaming, for which enduser’s dial-up/ISDN modem connections once were the bottleneck. The bottleneck is now found on the server side, since the bandwidth required for serving many clients at once is huge and very costly for the broadcasting <b>entity.</b> <b>Peer-to-peer</b> systems for live streaming, shifting the task of content distribution from the server to the users of the network, have been proposed {{in the last few years}} and provide very encouraging results. In this work we examine and compare the various approaches used so far to solve this problem and describe some of the actual systems that implement those general guidelines: we point to the weaknesses we perceive in the existing proposals and try to get some inspiration for improving the areas that still show poor performances. We then present PULSE, a massively multiuser p 2 p system whose main goals are scalability, robustness and flexibility. PULSE is an unstructured network where all peers autonomousl...|$|R
5000|$|... it was {{determined}} that current data modeling methods were imparting data isolation into every data architecture in the form of islands of disparate data and information silos. This data isolation is an unintended artifact of the data modeling methodology that results in the development of disparate data models. Disparate data models, when instantiated as databases, form disparate databases. Enhanced data model methodologies have been developed to eliminate the data isolation artifact and to promote the development of integrated data models. One enhanced data modeling method recasts data models by augmenting them with structural metadata in the form of standardized data entities. As a result of recasting multiple data models, the set of recast data models will now share one or more commonality relationships that relate the structural metadata now common to these data models. Commonality relationships are a <b>peer-to-peer</b> type of <b>entity</b> relationships that relate the standardized data entities of multiple data models. Multiple data models that contain the same standard data entity may participate in the same commonality relationship. When integrated data models are instantiated as databases and are properly populated from a common set of master data, then these databases are integrated.|$|R
40|$|Abstract — Over {{the last}} few years, {{there has been an}} {{unprecedented}} growth in residential broadband access, and number of public hotspots. But, the average broadband bandwidth utilization at each home remains low for majority of the subscribers compared to the bandwidth provided to each. The price of the broadband connection is high, but residents feel the need for it for the infrequent surges in bandwidth demand by some common applications. The public hotspot business model has also not taken off primarily due to additional cost of access for the user outside home, and having to take service from separate hotspot <b>entities.</b> <b>Peer-to-peer</b> systems have created a storm in recent years, by facilitating robust decentralized systems for file sharing. We envision a peer-to-peer broadband bandwidth sharing system, to address the limitations pointed out in the previous paragraph. In our model, peers with already established broadband connection will share their connection with their neighboring peers either for recovering their cost or for profit. The neighboring peers without broadband access will have on-demand shared broadband access for a low usage-based fee. The system will enable a ubiquitous wireless broadband connectivity for the peers, by providing access on demand at competitive rates. We back up our technology with details of the business model that will make this competitive bandwidth sharing possible. Index terms—p 2 p, hotspot, broadband A...|$|R
40|$|Conventional web {{search engines}} are {{centralised}} in {{that a single}} entity crawls and indexes the documents selected for future retrieval, and the relevance models used to determine which documents are relevant to a given user query. As a result, these search engines suffer from several technical drawbacks such as handling scale, timeliness and reliability, in addition to ethical concerns such as commercial manipulation and information censorship. Alleviating the need to rely entirely on a single <b>entity,</b> <b>Peer-to-Peer</b> (P 2 P) Information Retrieval (IR) has been proposed as a solution, as it distributes the functional components of a web search engine – from crawling and indexing documents, to query processing – across the network of users (or, peers) who use the search engine. This strategy for constructing an IR system poses several efficiency and effectiveness challenges which {{have been identified in}} past work. Accordingly, this thesis makes several contributions towards advancing {{the state of the art}} in P 2 P-IR effectiveness by improving the query processing and relevance scoring aspects of a P 2 P web search. Federated search systems are a form of distributed information retrieval model that route the user’s information need, formulated as a query, to distributed resources and merge the retrieved result lists into a final list. P 2 P-IR networks are one form of federated search in routing queries and merging result among participating peers. The query is propagated through disseminated nodes to hit the peers that are most likely to contain relevant documents, then the retrieved result lists are merged at different points along the path from the relevant peers to the query initializer (or namely, customer). However, query routing in P 2 P-IR networks is considered as one of the major challenges and critical part in P 2 P-IR networks; as the relevant peers might be lost in low-quality peer selection while executing the query routing, and inevitably lead to less effective retrieval results. This motivates this thesis to study and propose query routing techniques to improve retrieval quality in such networks. Cluster-based semi-structured P 2 P-IR networks exploit the cluster hypothesis to organise the peers into similar semantic clusters where each such semantic cluster is managed by super-peers. In this thesis, I construct three semi-structured P 2 P-IR models and examine their retrieval effectiveness. I also leverage the cluster centroids at the super-peer level as content representations gathered from cooperative peers to propose a query routing approach called Inverted PeerCluster Index (IPI) that simulates the conventional inverted index of the centralised corpus to organise the statistics of peers’ terms. The results show a competitive retrieval quality in comparison to baseline approaches. Furthermore, I study the applicability of using the conventional Information Retrieval models as peer selection approaches where each peer can be considered as a big document of documents. The experimental evaluation shows comparative and significant results and explains that document retrieval methods are very effective for peer selection that brings back the analogy between documents and peers. Additionally, Learning to Rank (LtR) algorithms are exploited to build a learned classifier for peer ranking at the super-peer level. The experiments show significant results with state-of-the-art resource selection methods and competitive results to corresponding classification-based approaches. Finally, I propose reputation-based query routing approaches that exploit the idea of providing feedback on a specific item in the social community networks and manage it for future decision-making. The system monitors users’ behaviours when they click or download documents from the final ranked list as implicit feedback and mines the given information to build a reputation-based data structure. The data structure is used to score peers and then rank them for query routing. I conduct a set of experiments to cover various scenarios including noisy feedback information (i. e, providing positive feedback on non-relevant documents) to examine the robustness of reputation-based approaches. The empirical evaluation shows significant results in almost all measurement metrics with approximate improvement more than 56...|$|R

