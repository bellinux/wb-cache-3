0|31|Public
50|$|A list of {{standardized}} illuminants, their CIE chromaticity coordinates (x,y) of a perfectly reflecting (or <b>transmitting)</b> <b>diffuser,</b> and their correlated color temperatures (CCTs) are given below. The CIE chromaticity coordinates are given {{for both the}} 2 degree field of view (1931) and the 10 degree field of view (1964). The color swatches represent the hue of each white point, calculated with luminance Y=0.54 and the standard observer, assuming correct sRGB display calibration.|$|R
40|$|We {{describe}} a procedure {{to estimate the}} calibration function for an experimental setup that contains a <b>transmitting</b> <b>diffuser</b> whose bidirectional transmittance distribution function for light transmitted in normal direction is nearly independent of the incidence angle. This type of diffusing screen {{may be used in}} experimental setups to measure the irradiance distribution in the focal plane of concentrator optics that have large angles of incidence in the focal plane. It is shown that the influence of this screen and of the remaining components on the irradiance distribution may be described empirically by a Gaussian function and thus may be corrected for. Furthermore, it is demonstrated that the correction is necessary to avoid an underestimation of the concentrator optics’ ability to concentrate the incoming radiation...|$|R
30|$|A second {{approximation}} denoted as MMSE-IC 2 [20] {{assumes a}} <b>perfect</b> estimation of <b>transmitted</b> symbols (σ _ŝ^ 2 =σ _s^ 2) {{to overcome the}} matrix inversion at each iteration.|$|R
40|$|ACM Computing Classification System (1998) : E. 4, C. 2. 1. This paper {{investigates the}} ergodic rates of three {{cooperative}} {{strategies for the}} fast Rayleigh fading relay channel, namely, decode-andforward (DF), compress-and-forward (CF) and amplify-and-forward (AF). The transmitter-relay, relay-receiver and transmitter-receiver links experience independent fast Rayleigh fading. Our analysis considers both fullduplex and half-duplex modes of operation of the relay channel, assuming that <b>perfect</b> <b>transmit</b> channel distribution information (CDI) {{is available at the}} transmitter and the relay. The ergodic rates are compared under different channel conditions to the corresponding upper capacity bounds of the relay channel and to the rate of direct transmission in order to investigate when it is beneficial to use a certain cooperative strategy. Cooperative transmission makes the ergodic rates approach or even become identical to the upper capacity bounds if some conditions are satisfied. The results show that DF and CF outperform AF as they are more complex strategies, while AF itself achieves higher rates than direct transmission in most channel scenarios, thus trading performance for implementation simplicity...|$|R
25|$|In optical radiometry, {{sheets of}} PTFE {{are used as}} {{measuring}} heads in spectroradiometers and broadband radiometers (e.g., illuminance meters and UV radiometers) due to PTFE's capability to diffuse a transmitting light nearly perfectly. Moreover, optical properties of PTFE stay constant {{over a wide range}} of wavelengths, from UV down to near infrared. In this region, the relation of its regular transmittance to diffuse transmittance is negligibly small, so light <b>transmitted</b> through a <b>diffuser</b> (PTFE sheet) radiates like Lambert's cosine law. Thus PTFE enables cosinusoidal angular response for a detector measuring the power of optical radiation at a surface, e.g. in solar irradiance measurements.|$|R
40|$|Renaissance bronze {{objects from}} the Rijksmuseum (Amsterdam) col- lection and lead ingots from ancient roman shipwrecks found near Sicily (Italy) were studied by means of neutron tomography. This {{was done with the}} aim to {{visualize}} and to measure the inner structures of the objects. In this way information about the manufacturing processes in the 16 th century and the conservation status from the inside of the bronze sculptures was gained. Inscriptions found under the corrosion layer of the lead ingots gave hints about the trade routes in the past. Neutron imaging was proven <b>perfect</b> to <b>transmit</b> the relatively thick layers of Pb and Cu alloys while ceramic remains, soldering connections and corrosion effects become visible...|$|R
5000|$|Thus, {{of their}} ancient {{writings}} {{we have little}} of major interest left to us by Carthage, or by Phoenicia the country of origin of the city founders. [...] "Of the various Phoenician and Punic compositions alluded to by the ancient classical authors, not a single work or even fragment has survived in its original idiom." [...] "Indeed, not a single Phoenician manuscript has survived in the original language or in translation." [...] We cannot therefore access directly the line of thought or the contour of their worldview as expressed in their own words, in their own voice. Ironically, it was the Phoenicians who [...] "invented or at least <b>perfected</b> and <b>transmitted</b> a form of writing alphabet that has influenced dozens of cultures including our own." ...|$|R
40|$|Abstract—Keyhole multiple-input–multiple-output (MIMO) {{channels}} {{have recently}} received significant attention since they can model, {{to a certain}} extend, some practically important propagation scenarios and also relay channels in the amplify-and-forward mode. This paper investigates instantaneous signal-to-noise ratio (SNR) and outage capacity distributions of spatially correlated keyhole MIMO channels with perfect channel state information (CSI) at the receive end and with or without CSI at the transmit end. For {{a small number of}} antennas, the impact of correlation on the capacity distribution can be characterized by the effective average SNR. This SNR, as well as the outage capacity, decreases with correlation. For a large number of transmit (receive) antennas, the keyhole channel is asymptotically equivalent (in terms of capacity) to the Rayleigh diversity channel with a single transmit (receive) antenna and multiple receive (transmit) antennas. The outage capacity of the keyhole channel is upper-bounded by that of the equivalent Rayleigh diversity channel. When the number of both transmit and receive antennas is large, the outage capacity distribution of the keyhole channel is asymptotically Gaussian. In some cases, the asymptotic Gaussian approximation is accurate already for a reasonably small number of antennas. The <b>perfect</b> <b>transmit</b> CSI is shown to bring a fixed SNR gain. A more general channel model with multiple keyholes is proposed. For a large number of antennas, the capacity of a multikeyhole channel is a normally distributed sum of the capacities of single keyhole channels. The fact that, despite the strong degenerate nature of the keyhole channel, its outage capacity distribution is asymptotically normal indicates that Gaussian distribution has a high degree of universality for the capacity analysis of MIMO channels. Index Terms—Capacity distribution, correlation, keyhole channel, multiple-input–multiple-output (MIMO) system, relay channel, symbol error rate. I...|$|R
50|$|The District Development Committee(DDC) {{had set up}} the {{planning}} bodies, BPC meetings were convened and {{the planning}} procedures were explained to all actors. Panchayats were requested to discuss and decide their resource endowments, identify development problems, the schemes and projects {{to be included in}} their plan and to involve the experts available locally in the execution of the process. Panchayats were able to complete the tasks in two/three meetings. The BPC met again after a month to review the proposals from the Panchayats. They reviewed, modified or supplemented the projects to make them complete or <b>perfect</b> and <b>transmitted</b> those plans to the technical committees at the district. The technical committees held several rounds of discussion to make them conform to the standards of the state level schemes. New proposals were then formulated by the technical committees, whenever needed. The strategies for development of the sector were also evolved by those technical committees.|$|R
40|$|The {{most popular}} method for dynamic soil-structure {{interaction}} analysis is the finite element method. The versatility in problems involving different materials and complex geometries is its main advantage, yet the FEM can not simulate unbounded domains completely. Several schemes {{have been proposed}} to overcome this shortcoming, {{such as the use}} of either imperfect or <b>perfect</b> <b>transmitting</b> boundaries, infinite elements and hybrid techniques. However, most of them were derived on the assumption that the soil mass can be represented as a homogeneous material despite the fact that stratified soil deposits are a common occurrence in nature. A hybrid method is proposed in this research for soil-structure interaction analysis in the frequency domain involving a multilayered linear elastic half-space. The near field region (structure and a portion of soil surrounding it) is modeled by finite elements while the far field formulation is obtained through the classical wave propagation theory based on the assumption that the actual scattered wave fields can be represented by a set of line sources. Traction reciprocity between the two regions is satisfied exactly, while the displacement continuity across the common interface is enforced in a least-squares sense. The two-dimensional system is excited by harmonic body waves (P and SV) propagating with oblique incidence. The structure can be considered either on the surface or deeply embedded in the multilayered half-space. Analytic solutions for the far field domain is obtained through the combined response of four simple problems that take into account the overall effects of the incident, reflected and scattered wave fields. The delta matrix technique is employed in order to eliminate the loss of precision problem associated with the Thomson-Haskell matrix method in its original form. Special numerical schemes are used to transform the solution from the κ- into the ω-plane due to the presence of poles on the path of integration. The few numerical examples studied in this research validate the proposed hybrid technique, but the relatively high computational cost required for evaluation of the Green's functions is still a serious drawback. Some suggestions are made to minimize the problem as well as to extend this technique to cases involving material attenuation and forced vibrations...|$|R
40|$|A quantum {{encryption}} scheme (also called private quantum channel, {{or state}} randomization protocol) is a one-time pad for quantum messages. If two parties share a classical random string, {{one of them}} can transmit a quantum state to the other so that an eavesdropper gets little or no information about the state being <b>transmitted.</b> <b>Perfect</b> encryption schemes leak no information {{at all about the}} message. Approximate encryption schemes leak a non-zero (though small) amount of information but require a shorter shared random key. Approximate schemes with short keys have been shown to have a number of applications in quantum cryptography and information theory [8]. This pape...|$|R
30|$|Poverty {{is another}} barrier. Even if <b>perfect</b> {{information}} is <b>transmitted</b> to farmers, their responses are often constrained {{by a lack}} of adequate resources (material or financial). Moreover, the absence of social security nets, such as savings and risk insurance, in many African rural communities, limit farmers’ readiness to try new practices in responses to climate-related risks (Lallau 2008). Buchanan-Smith et al. (1994) emphasized that the prevention of famine in SSA has not improved since the disasters of the 1980 s, despite better predictive capacity in the Sahel and the Horn of Africa. Regardless of accuracy, information cannot be eaten by famine-inflicted communities. Regrettably, a similar assessment appeared in Bailey’s (2013) report on famine in Africa, published 20  years later.|$|R
30|$|The {{optimized}} {{geometry of}} the capped (5, 5) C-SWNT shows that the atoms at the top pentagon have an average bond length of 1.44 Å {{compared to that of}} 1.42 Å at the sidewall. However, the average C–S bond length was up to 1.80 Å, and the average C–S–C bond angles changed from 120 ° to 112 °, which mean the implant of S atom into C-SWNT made the sp 2 bonding in the <b>perfect</b> hexagonal lattices <b>transmit</b> to sp 3 -like bonding as tetrahedral-like lattices. The S-substitutional position has obvious dramatic local deformation, which should be believed {{to play an important role}} in the electronic properties. The structural changes are very small under applied electric field.|$|R
40|$|Regardless {{of input}} polarization, a linear {{polarizer}} transmits only linearly polarized light. Ideal linear polarizers allow {{the transmission of}} only one polarization state with zero leakage of all other polarization states. Rotating the linear polarizer about the optical axis changes the output plane of polarization. Thus, a <b>perfect</b> linear polarizer <b>transmits</b> only 50 % of an unpolarized input beam and two perfect polarizers with their transmission axes crossed totally extinguish an incident beam. Imperfections in polarizers such as scattering sites, material defects (such as pinholes in thin films) and field-of-view effects reduce ideal polarizers’ contrast. When choosing a linear polarizer, several key factors must be considered including: cost, wavelength range, aperture size, acceptance angle, damage threshold, transmission efficienc...|$|R
40|$|This paper {{presents}} {{results of}} experimental and theoretical studies of light transmission through optical fibers with disorder generated in its germanium-doped core via UV radiation <b>transmitted</b> through a <b>diffuser.</b> The experimental results on {{transmission of the}} radiation of 543 nm wavelength demonstrate {{the presence of the}} disorder in the core of the optical fiber – beyond a certain characteristic length, the transmitted power is observed to be distributed over all modes of the fiber. A theoretical model based on coupled mode theory is developed. An analytical expression for the mixing length is obtained and agrees well with the experiment. For long sections of disordered fiber, the experimentally measured distribution of the near-field intensity at the output surface of the fiber is well described by the Rayleigh negative exponential function. This suggests a statistically uniform distribution of the transmitted power over all modes, that agrees with the prediction of the theoretical model. The reported technique provides an easy way to fabricate different configurations of controlled disorder in optical fibers suitable for such applications as random fiber lasers...|$|R
40|$|Purpose: Several {{recent studies}} have {{demonstrated}} that following short-term monocular deprivation in normal adults, the patched eye, rather than the unpatched eye, becomes stronger in subsequent binocular viewing. However, {{little is known about the}} site and nature of the underlying processes. In this study, we examine the underlying mechanisms by measuring steady-state visual evoked potentials (SSVEPs) as an index of the neural contrast response in early visual areas. Methods: The experiment consisted of three consecutive stages: a pre-patching EEG recording (14 minutes), a monocular patching stage (2. 5 hours) and a post-patching EEG recording (14 minutes; started immediately after the removal of the patch). During the patching stage, a <b>diffuser</b> (<b>transmits</b> light but not pattern) was placed in front of one randomly selected eye. During the EEG recording stage, contrast response functions for each eye were measured. Results: The neural responses from the patched eye increased after the removal of the patch, whilst the responses from the unpatched eye remained the same. Such phenomena occurred under both monocular and dichoptic viewing conditions. Conclusions: We interpret this eye dominance plasticity in adult human visual cortex as homeostatic intrinsic plasticity regulated by an increase of contrast-gain in the patched eye...|$|R
40|$|Characteristics of {{the methods}} for {{detecting}} unauthorized connections to a subscriber telephone line are presented. They ensure the confidentiality of telephone conversations, protect from eavesdropping of rooms and prevent the unauthorized use of telephone connection. The classification of threats of confidentiality violation in telephone channels was done and methodology for eliminating of unauthorized interception of information was proposed. For the most <b>perfect</b> protection of <b>transmitted</b> data channels it is advisable to use cryptographic algorithms for encryption of voice information. However, implementation of this method requires {{the presence of the}} same devices for signal encoding and decoding (scrambler) in all communicating subscribers. Only complex using of a range of listed technical equipment allows to avoid using of communication channels for wiretapping and eavesdropping in rooms through which they are passing. ??????????? ???????? ?????????? ???????, ????????? ? ????????? ?????????? ??????????? ?????? ?????????? ?? ???????? ?????????????? ????????????. ???????? ????? ??????? ? ??????? ??????????? ??????????????????? ??????????? ? ??????????? ?????????? ?????? ? ?????????? ?????? ?????? ? ??????? ??????? ?????????? ? ?????????????? ?????????? ??????????? ????????? ??????...|$|R
30|$|In {{wireless}} {{networks for}} which nodes {{can benefit from}} cooperation and packet-forwarding, {{there is also a}} need to preserve the confidentiality of transmitted information from untrusted nodes. Information privacy in wireless networks has traditionally been the domain of the higher layers of the protocol stack via the use of cryptographically secure schemes. In his seminal paper on the three-node wiretap channel, Wyner showed that <b>perfect</b> secrecy of <b>transmitted</b> data from the source node can be achieved when the physical channel to the eavesdropper is noisier than the channel to the intended destination, that is, when the channel is a degraded broadcast channel [1]. This work was later extended by Csiszár and Körner to all broadcast channels with confidential messages, in which the source node sends common information to both the destination and the wiretapper and confidential information only to the destination [2].|$|R
30|$|An {{implication}} of the present approach is that not all ties that could be added to a network are beneficial for information diffusion. Although the virtue of rewiring or adding random ties has been widely demonstrated (Newman 2000; Kleinberg 2002; Valente and Davis 1999; Pastor-Satorras and Vespignani 2001; Newman 2002; López-Pintado 2008), this article demonstrates that the presumption of full-capacity ties and <b>perfect</b> opportunity to <b>transmit</b> which underlies earlier approaches is necessary for random ties to be beneficial. By accounting for limited opportunities and varying capacity, the findings here help qualify these results. The findings presented here {{are consistent with those}} revealing that network modularity can improve information dissemination via social reinforcement (Centola 2010; Nematzadeh et al. 2014). The results here suggest that modularity is helpful for another reason: insofar as modularity is indicative of strong ties within the communities and weak ties across them, the presence of too many weak ties spanning communities can inhibit information spread within the communities as well.|$|R
40|$|In {{this paper}} new and {{existing}} approaches are developed {{to compute the}} bit error rate for chaos-based communication systems. The multi-user coherent antipodal chaos shift keying system is studied and evaluated in its coherent form, {{in the sense of}} <b>perfect</b> synchronization between <b>transmitted</b> and received chaotic sequences. Transmission is through an additive white Gaussian noise channel. Four methods are interrelated in the paper, three approximate ones and an exact one. The least accurate but most well known is based on simple Gaussian approximation; this is generalized to better reveal its structure. Two accurate and computationally efficient approximate methods are based on conditional Gaussian approximation and the statistical distribution of the typically non-constant bit energy. The most insightful but computationally expensive one is based on exact theory and rests on explicit mathematical results for particular chaotic maps used to spread binary messages. Both upper and lower bounds to the bit error rate are suggested. The relative advantages of the different approaches are illustrated with plots of bit error rate against signal to noise ratio...|$|R
30|$|Recently, {{cooperative}} communications {{emerged as}} an alternative technique to boost the performance of communication systems [5, 6]. The idea behind this strategy is {{to make use of}} one or more nodes, known as relay(s), to help the communication between source and destination. The result is a virtual antenna array formed by single antenna devices. Thus, through cooperation, the same benefits obtained in multiple-input multiple-output (MIMO) systems can be achieved. The relay behavior is governed by cooperative protocols which can operate either on half-duplex (HD) or on full-duplex (FD) modes, using parallel or repetition coding, selective or incremental strategies, etc. [5, 7 – 9]. Specifically, in HD mode, the relay transmits and receives in orthogonal channels, whereas in FD mode, the transmission and reception are performed {{at the same time and}} at the same frequency band. Owing to this fact, HD relays require the use of additional system resources, while FD relays arise as a viable option to alleviate this problem. However, although ideal FD relaying can achieve higher capacity than HD relaying [8], its use introduces self-interference since <b>perfect</b> isolation between <b>transmitted</b> and received signals is hard to be guaranteed [8 – 12].|$|R
40|$|Transmission {{of optical}} signals in today’s {{telecommunication}} system is facing lots of technical problems. The solution lies {{on a particular}} type of light wave known as optical soliton. These light pulses will be the <b>perfect</b> solution for <b>transmitting</b> signals and also digital data in communication systems. Soliton has the ability to travel over long distances without being distorted. Microring resonators are introduced as a filter. Microring could be performed as the device for security purposes. By varying the transmission coefficients from 0. 25 to 0. 75, ring radius from 5 ?m to 15 ?m, and coupling coefficients, ? from 0. 25 to 0. 85, the performance of the ring resonator is examined in terms of free spectral range (FSR), Full Width Half Maximum (FWHM), Finesse (F), Quality Factor (Q) and time-domain at output signal. The conditions and controls to have a better performance of microring resonator were studied. Results obtained showed that to obtain a higher FSR and lower FWHM with maximum transmission are by using the ring radius of 15 ?m, the transmission coefficient of 0. 75 and with the coupling coefficient of 0. 25. In conclusion, the results obtained showed that the performance of the microring resonator are governed by the transmission coefficient, coupling coefficient, ring radius and time-domain factor...|$|R
30|$|Another {{contribution}} of {{the paper is the}} determination of a pilot positioning scheme that improves the equalizer's performance. In the context of our proposed algorithm, the main purpose of the pilots is the enablement of sufficient quality initialization of the EM iterations so that the probability of convergence to a local maximum is minimized. To that end, we propose an initialization scheme based on a small number of pilots and find the optimal pilot positioning such that the initial channel parameters guess is {{as close as possible to}} the channel parameters obtained assuming <b>perfect</b> knowledge of <b>transmitted</b> symbols (this is the channel estimation expected at the end of the BW iterations). It is shown that the pilot positioning depends on the channel's Doppler. For high Doppler rates, our results indicate that spreading the pilot symbols evenly throughout the block leads to the best initial channel guess. This result is surprising as it is different from previous results where the optimal positioning scheme was found to be spreading of groups of pilots whose length depended on the channels delay spread [29, 30]. These previous results, however, were obtained using different criteria and channel model. More importantly, the analysis in these papers was restricted and did not consider pilot groups shorter than the channel's delay spread as done in this paper. Therefore, these previous results do no contradict with our new result.|$|R
40|$|A quantum {{encryption}} scheme (also called private quantum channel, {{or state}} randomization protocol) is a one-time pad for quantum messages. If two parties share a classical random string, {{one of them}} can transmit a quantum state to the other so that an eavesdropper gets little or no information about the state being <b>transmitted.</b> <b>Perfect</b> encryption schemes leak no information {{at all about the}} message. Approximate encryption schemes leak a non-zero (though small) amount of information but require a shorter shared random key. Approximate schemes with short keys have been shown to have a number of applications in quantum cryptography and information theory [8]. This paper provides the first deterministic, polynomial-time constructions of quantum approximate encryption schemes with short keys. Previous constructions [8] are probabilistic—that is, they show that if the operators used for encryption are chosen at random, then with high probability the resulting protocol will be a secure encryption scheme. Moreover, the resulting protocol descriptions are exponentially long. Our protocols use keys of the same length as (or better length than) the probabilistic constructions; to encrypt n qubits approximately, one needs n + o(n) bits of shared key [8], whereas 2 n bits of key are necessary for perfect encryption [3]. An additional contribution of this paper is a connection between classical combinatorial derandomization and constructions of pseudo-random matrix families in a continuous space. ...|$|R
40|$|Abstract — Cloud {{computing}} provides robust {{design with}} reduced cost representation. Cloud computing provides good computational power generation process. Present cloud contains less computational power are not handle large load of distribution process. Each and every resources are provides the file of content {{pay per use}} manner. Those all the cloud data storage files provide the security with high cost and low efficiency results generation. Whenever to start the computational mode {{to get some of}} non confidential environment and insecure environment inside the network. Through insecure environment distribute the data to get the leakage problem inside the network communication or exchanges the resources of content information specification process. Previous system it cannot provides any verification and validation results specification process. There is no perfect encrypted format of data, it can contain less computational resources of information. In present system we are going implement robust design with perfect security constraints. We {{are going to try to}} implement verification mechanism for all kind of customers. We are going to try to implement all kinds of feasible solution in different number of ways. We are going to implement linear programming conditions. Whatever to transfer the data performs decomposition and transfer the information. Decomposition of information allocate in different number of LP solvers. All kinds of users contain high secure implementation. It can <b>transmit</b> <b>perfect</b> transmission of information with exact results specification. It can provides best security with transmission results...|$|R
40|$|The {{formation}} of nonlinear axisymmetric waves on inviscid irrotational liquid jets {{in the presence}} of radial electric fields is considered. Gravity is neglected but surface tension is considered. Electrohydrodynamic waves of arbitrary amplitude and wavelength are computed using finite-difference methods. Particular attention is paid to nonlinear traveling waves. In the first class of problems, an electric field generated by placing the liquid jet inside a hollowcylindrical electrode held at constant voltage, its axis coinciding with that of the jet, is studied. The jet is assumed to be a perfect conductor whose free surface is stressed by the electric field acting in the hydrodynamically passive annulus. In the second class of problems, the annular gas is a <b>perfect</b> conductor that <b>transmits</b> a constant voltage onto the liquid/gas surface. The liquid axisymmetrically wets a constant-radius cylindrical rod electrode placed coaxially with respect to the hollow outer electrode, and held at a different constant voltage. The fluid dynamics and electrostatics need to be addressed simultaneously in the inner region. Axisymmetric interfacial waves influenced by surface tension and electrical stresses are computed in both cases. The computations are capable of following highly nonlinear solutions and predict, for certain parameter values, the onset of interface pinching accompanied with the {{formation of}} toroidal bubbles. For given wave amplitudes, the results suggest that, for the former case, the electric field delays bubble formation and reduces wave steepness, while for the latter case the electric field promotes bubble formation, all other parameters being equal...|$|R
40|$|High speed {{wireless}} access on 60 GHz spectrum relies on high-gain directional antennas {{to overcome the}} severe signal attenuation. However, <b>perfect</b> alignment between <b>transmitting</b> and receiving antenna beams is rare in practice and overheard signals from concurrent transmissions may cause significant interference. In this paper we analyze the impact of antenna beam misalignment on the system performance of 60 GHz {{wireless access}}. We quantify the signal power loss caused by beam misalignment and the interference power accumulated from neighboring concurrent transmissions whose signals are leaked either via the main-beam pointing in the similar direction or via side-lobe emission, and derive the probability distribution of the signal to interference plus noise power ratio (SINR). For scenarios where interfering transmitters are distributed uniformly at random, we derive {{upper and lower bounds}} on the cumulative distribution function (abbreviated as CDF or c. d. f.) of SINR, which can be easily applied to evaluate system performance. We validate our analytical results by simulations where random nodes are uniformly distributed within a circular hall, and evaluate the sensitivity of average throughput and outage probability against two parameters: the half-power (3 dB) beamwidth to main-lobe beamwidth ratio and the beam misalignment deviation to main-lobe beamwidth ratio. Our results indicate that the derived lower bound performs well when the half-power beamwidth to main-lobe beamwidth ratio or the number of concurrent transmission links is small. When the number of active links is high, it is desirable in antenna design to balance the degradation caused by beam misalignment (wider beam is better) and the interference from concurrent transmission (narrower beam is better) ...|$|R
40|$|Code-division multiple-access (CDMA) {{systems with}} random {{spreading}} and channel uncertainty at the receiver are studied.   Frequency selective single antenna, as well as, narrowband multiple antenna channels are considered.   Rayleigh fading is assumed in all cases.   General Bayesian approach {{is used to}} derive both iterative and non-iterative estimators whose performance is obtained in the large system limit via the replica method from statistical physics. The effect of spatial correlation {{on the performance of}} a multiple antenna CDMA system operating in a flat-fading channel is studied.   Per-antenna spreading (PAS) with random signature sequences and spatial multiplexing is used at the transmitter.   Non-iterative multiuser detectors (MUDs) using imperfect channel state information (CSI) are derived.   Training symbol based channel estimators having mismatched a priori knowledge about the antenna correlation are considered.   Both the channel estimator and the MUD are shown to admit a simple single-user characterization in the large system limit.   By using the decoupled channel model, the ergodic spectral efficiency with single-user decoding and quarternary phase shift keying (QPSK) constrained modulation is derived.   In contrast to the case of <b>perfect</b> CSI where <b>transmit</b> correlation has no effect on the ergodic system performance with random PAS, the results show that with channel estimation the ergodic capacity can improve significantly as the correlations between the transmit antennas increase.   This requires that the channel estimator knows the correct long term spatial correlation in advance, while no information is required at the transmitter. Iterative multiuser receivers for randomly spread CDMA over a frequency selective Rayleigh fading channel are analyzed.   General Bayesian approach for iterative channel estimation and data detection and decoding is proposed.   Both linear and non-linear iterative schemes are considered with soft or hard information feedback.   The equivalent single-user representation of the system is derived in the large system limit via the replica method.   The decoupled single-user channel, and density evolution with Gaussian approximation are used to obtain the spectral efficiency and bit error rate (BER) of the system using bit-interleaved coded modulation (BICM) and Gray encoded QPSK mapping.   The results indicate that in the large system limit and under certain threshold loads, near single-user BER performance with perfect CSI can be achieved by using a vanishing training overhead.   This requires, however, an iterative receiver using soft feedbacks only.   For relatively slowly time-varying multipath fading channels, the iterative linear minimum mean square error (LMMSE) based channel estimator is also shown to be near optimal in terms of maximizing the spectral efficiency of the system when combined with iterative LMMSE or maximum a posteriori multiuser detectors. A novel training method based on probability biased signaling is proposed.   By assuming an entropy maximizing biasing scheme and standard BICM, it is shown via numerical examples that the proposed training method can offer superior performance over the conventional training symbol based approach when combined with iterative receivers. </p...|$|R
40|$|La presente tesis {{doctoral}} contribuye a la incesante evolución de las comunicaciones inalámbricas. Se centra en el diseño de protocolos de acceso al medio (MAC) para redes ad hoc y redes inalámbricas cooperativas. En una primera parte introductoria se presenta un minucioso estado del arte y se establecen las bases teóricas de las contribuciones presentadas en la tesis. En esta primera parte introductoria se definen las principales motivaciones de la tesis y se plantean los objetivos. Después, las contribuciones de la tesis se organizan en dos grandes bloques, o partes. En la primera parte de esta tesis se diseña, analiza y evalúa el rendimiento de un novedoso protocolo MAC de alta eficiencia llamado DQMAN (Protocolo MAC basado en colas distribuidas para redes ad hoc). Este protocolo constituye la extensión y adaptación del protocolo DQCA, diseñado para redes centralizadas, para operar en redes sin infraestructura. En DQMAN se introduce un nuevo paradigma en el campo del acceso al medio para redes distribuidas: la integración de un algoritmo de clusterización espontáneo y dinámico basado en una estructura de master y esclavo junto con un protocolo MAC de alta eficiencia diseñado para redes centralizadas. Tanto el análisis teórico como las simulaciones por ordenador presentadas en esta tesis muestran que DQMAN mejora el rendimiento del actual estándar IEEE 802. 11. La principal característica de DQMAN es que se comporta como un protocolo de acceso aleatorio cuando la carga de tráfico es baja y cambia automática y transparentemente a un protocolo de reserva a medida que el tráfico de la red aumenta. Además, su rendimiento es prácticamente independiente del número de usuarios simultáneos de la red, lo cual es algo deseable en redes que nacen para cubrir una necesidad espontánea y no pueden ser planificadas. El hecho de que algoritmo de clusterización se base en un acceso aleatorio permite la coexistencia e intercomunicación de usuarios DQMAN con usuarios basados en el estándar IEEE 802. 11. Este estudio se presenta en esta primera parte de la tesis y es fundamental de cara a una posible explotación comercial de DQMAN. La metodología presentada en esta tesis mediante el cual se logra extender la operación de DQCA a entornos ad hoc sin infraestructura {{puede ser}} utilizada para adaptar cualquier otro protocolo centralizado. Con el objetivo de poner de manifiesto esta realidad, la primera parte de la tesis concluye con el diseño y evaluación de DPCF como una extensión distribuida del modo de coordinación centralizado (PCF) del estándar IEEE 802. 11 para operar en redes distribuidas. La segunda parte de la tesis se centra en el estudio de un tipo específico de técnicas cooperativas: técnicas cooperativas de retransmisión automática (C-ARQ). La idea principal de las técnicas C-ARQ es que cuando un paquete de datos se recibe con bits erróneos, se solicita retransmisión, no a la fuente de datos, si no a cualquiera de los usuarios que escuchó la transmisión original. Estos usuarios se convierten en espontáneos retransmisores que permiten mejorar la eficiencia de la comunicación. A pesar de que este tipo de esquema puede obtener diversidad de cooperación, el hecho de implicar a más de un usuario en una comunicación punto a punto requiere una coordinación que hasta ahora ha sido obviada en la literatura, asumiendo que los retransmisores pueden coordinarse perfectamente para retransmitir uno detrás de otro. En esta tesis se analiza y evalúa el coste de coordinación impuesto por la capa MAC y se identifican los principales retos de diseño que las técnicas C-ARQ imponen al diseño de la capa MAC. Además, se presenta el diseño y análisis de dos novedosos protocolos MAC para C-ARQ: DQCOOP y PRCSMA. El primero se basa en DQMAN y constituye una extensión de este para operar en esquemas C-ARQ, mientras que el segundo constituye la adaptación del estándar IEEE 802. 11 para poder ejecutarse en un esquema C-ARQ. El rendimiento de estos esquemas se compara en esta tesis tanto con esquemas no cooperativos como con esquemas ideales cooperativos donde se asume que el MAC es ideal. Los resultados principales muestran que el diseño eficiente de la capa MAC es esencial para obtener todos los beneficios potenciales de los esquemas cooperativos. This thesis aims at {{contributing to the}} incessant evolution of wireless communications. The {{focus is on the}} design of medium access control (MAC) protocols for ad hoc and cooperative wireless networks. A comprehensive state of the art and a background on the topic is provided in a first preliminary part of this dissertation. The motivations and key objectives of the thesis are also presented in this part. Then, the contributions of the thesis are divided into two fundamental parts. The first part of the thesis is devoted to the design, analysis, and performance evaluation of a new high-performance MAC protocol. It is the Distributed Queueing MAC Protocol for Ad hoc Networks (DQMAN) and constitutes an extension and adaptation of the near-optimum Distributed Queueing with Collision Avoidance (DQCA) protocol, designed for infrastructure-based networks, to operate over networks without infrastructure. DQMAN introduces a new access paradigm in the context of distributed networks: the integration of a spontaneous, dynamic, and soft-binding masterslave clustering mechanism together with a high-performance infrastructure-based MAC protocol. Theoretical analysis and computer-based simulation show that DQMAN outperforms IEEE 802. 11 Standard. The main characteristic of the protocol is that it behaves as a random access control protocol when the traffic load is low and it switches smoothly and automatically to a reservation protocol as the traffic load grows. In addition, its performance is almost independent of the number of users of a network. The random-access based clustering algorithm allows for the coexistence and intercommunication of stations using DQMAN with the ones just based on the legacy IEEE 802. 11 Standard. This assessment is also presented in this first part of the dissertation and constitutes a key contribution {{in the light of the}} commercial application of DQMAN. Indeed, the rationale presented in this first part of the thesis to extend DQCA and become DQMAN to operate over distributed networks can be used to extend the operation of any other infrastructure-based MAC protocol to ad hoc networks. In order to exemplify this, a case study is presented to conclude the first part of the thesis. The Distributed Point Coordination Function (DPCF) MAC protocol is presented as the extension of the PCF of the IEEE 802. 11 Standard to be used in ad hoc networks. The second part of the thesis turns the focus to a specific kind of cooperative communications: Cooperative Automatic Retransmission Request (C-ARQ) schemes. The main idea behind C-ARQ is that when a packet is received with errors at a receiver, a retransmission can be requested not only from the source but also to any of the users which overheard the original transmission. These users can become spontaneous helpers to assist in the failed transmission by forming a temporary ad hoc network. Although such a scheme may provide cooperative diversity gain, involving a number of users in the communication between two users entails a complicated coordination task that has a certain cost. This cost has been typically neglected in the literature, assuming that the relays can attain a <b>perfect</b> scheduling and <b>transmit</b> one after another. In this second part of the thesis, the cost of the MAC layer in C-ARQ schemes is analyzed and two novel MAC protocols for C-ARQ are designed, analyzed, and comprehensively evaluated. They are the DQCOOP and the Persistent Relay Carrier Sensing Multiple Access (PRCSMA) protocols. The former is based on DQMAN and the latter is based on the IEEE 802. 11 Standard. A comparison with non-cooperative ARQ schemes (retransmissions performed only from the source) and with ideal CARQ (with perfect scheduling among the relays) is included to have actual reference benchmarks of the novel proposals. The main results show that an efficient design of the MAC protocol is crucial in order to actually obtain the benefits associated to the C-ARQ schemes...|$|R

