777|428|Public
50|$|In 2009, a memory-intensive key {{strengthening}} algorithm, scrypt, {{was introduced}} {{with the intention}} of limiting the use of custom, highly <b>parallel</b> <b>hardware</b> to speed up key testing.|$|E
5000|$|On {{the other}} side, {{reactive}} programming {{is a form}} of what could be described as [...] "explicit parallelism", and could therefore be beneficial for utilizing the power of <b>parallel</b> <b>hardware.</b>|$|E
50|$|This {{technique}} {{was used for}} {{a few of the}} many fast-load systems made (such as JiffyDOS). Others were simply more efficient in I/O and file handling, offering marginal to good improvement. Other products added <b>parallel</b> <b>hardware.</b>|$|E
50|$|In {{computer}} science, software pipelining is {{a technique}} used to optimize loops, {{in a manner that}} <b>parallels</b> <b>hardware</b> pipelining. Software pipelining is a type of out-of-order execution, except that the reordering is done by a compiler (or in the case of hand written assembly code, by the programmer) instead of the processor. Some computer architectures have explicit support for software pipelining, notably Intel's IA-64 architecture.|$|R
5000|$|ParC C++ {{extended}} for <b>parallel</b> {{processing and}} <b>hardware</b> description ...|$|R
40|$|Abstract: Aparallel line {{clipping}} algorithm and its implementation on a <b>parallel</b> clipping <b>hardware</b> environment are presented. We first develop a simple theory {{to show that}} parallel clipping is possible {{for all types of}} line segments. We then present the architecture of a hardware environment based on which parallel clipping is to be implemented. The parallel line {{clipping algorithm}} and its implementation on the <b>parallel</b> clipping <b>hardware</b> environment are presented finally. Based on our approach, only 141 cycles are required to clip a line segment. The corresponding figure for the famous J. Clark’s Geometry Engine is 160 cycles...|$|R
5000|$|Thirdly, {{compound}} {{approach has}} the same properties as single inversive generators [...] but it also provides period length significantly greater than obtained by a single Inversive Congruential Generator. They seem to be designed for application with multiprocessor <b>parallel</b> <b>hardware</b> platforms.|$|E
50|$|On the {{hardware}} {{side of the}} application, Impulse C library functions and other C statements are compiled to generate equivalent, <b>parallel</b> <b>hardware</b> implementations {{in the form of}} synthesizable HDL files. These files are processed by FPGA tools to create FPGA hardware bitmaps.|$|E
50|$|The Othello 8x8 {{game tree}} size is {{estimated}} at 1054 nodes, {{and the number of}} legal positions {{is estimated at}} less than 1028. Although not mathematically solved yet, a solution could possibly be found using intensive computation with top programs on fast <b>parallel</b> <b>hardware</b> or through distributed computation.|$|E
50|$|The project also {{spun off}} an Open <b>Hardware</b> <b>parallel</b> port JTAG {{interface}} {{board and the}} Blob bootloader.|$|R
30|$|MOCC has an {{inherent}} parallel architecture. The feature detection in MOCC can be processed simultaneously in each scale level, and the 7 group-to-group matching procedures {{can also be}} processed at the same time. Therefore, potential speedup can be achieved using <b>parallel</b> computing <b>hardware.</b>|$|R
2500|$|Rules can {{be solved}} in <b>parallel</b> in <b>hardware,</b> or {{sequentially}} in software. The results of all the rules that have fired are [...] "defuzzified" [...] to a crisp value by one of several methods. There are dozens, in theory, each with various advantages or drawbacks.|$|R
5000|$|LSTM {{units are}} often {{implemented}} in [...] "blocks" [...] containing several units. This design is typical with deep neural networks and facilitates implementations with <b>parallel</b> <b>hardware.</b> In the equations below, each variable in lowercase italics represents a vector with a length {{equal to the}} number of LSTM units in the block.|$|E
50|$|OOP was {{developed}} to increase the reusability and maintainability of source code. Transparent representation of the control flow had no priority and {{was meant to be}} handled by a compiler. With the increasing relevance of <b>parallel</b> <b>hardware</b> and multithreaded coding, developing transparent control flow becomes more important, something hard to achieve with OOP.|$|E
5000|$|... nCUBE was {{a series}} of {{parallel}} computing computers from the company of the same name. Early generations of the hardware used a custom microprocessor. With its final generations of servers, nCUBE no longer designed custom microprocessors for machines, but used server class chips manufactured by a third party in massively <b>parallel</b> <b>hardware</b> deployments, primarily for the purposes of on-demand video.|$|E
40|$|One {{contribution}} of 13 to a Theme Issue ‘Multi-scale systems in fluids and soft matter: approaches, numerics and applications’. Subject Areas: computational chemistry, computational biology, computer modelling and simulation, e-science, electrical engineering Keywords: molecular dynamics simulation, high performance computing, multiscale simulation, scalable <b>parallel</b> system, <b>hardware</b> accelerator Author for correspondence...|$|R
50|$|Personal {{computer}} {{parallel port}} adapters are simple and inexpensive, {{but they are}} relatively slow because they use the host CPU to change each bit ("bit banging"). They have declined in usefulness because newer computers do not have <b>parallel</b> port <b>hardware.</b> Driver support is also a problem, because the adapter electronics varied so widely.|$|R
40|$|Abstract—This paper {{presents}} an efficient approach for implementing spike-timing-dependent plasticity (STDP) on the SpiNNaker neuromorphic hardware. The event-address map-ping and the distributed synaptic weight storage schemes used in <b>parallel</b> neuromorphic <b>hardware</b> such as SpiNNaker make the conventional pre-post-sensitive scheme of STDP implemen-tation inefficient, since STDP is triggered when either a pre- or post-synaptic neuron fires. An alternative pre-sensitive scheme approach {{is presented to}} solve this problem, where STDP is triggered only when a pre-synaptic neuron fires. An associated deferred event-driven model is developed to enable the pre-sensitive scheme by deferring the STDP process until there are sufficient history spike timing records. The paper gives {{detailed description of the}} implementation as well as performance estimation of STDP on multi-chip SpiNNaker machine, along with the discussion on some issues related to efficient STDP implementation on a <b>parallel</b> neuromorphic <b>hardware.</b> I...|$|R
50|$|Since CAs {{are only}} locally connected, they {{are ideal for}} {{implementation}} on purely <b>parallel</b> <b>hardware.</b> When designing the CoDi CA-based neural networks model, the objective was to implement them directly in hardware (FPGAs). Therefore, the CA was kept as simple as possible, by having {{a small number of}} bits to specify the state, keeping the CA rules few in number, and having few cellular neighbors.|$|E
50|$|Cellular EAs {{are very}} {{amenable}} to parallelism, thus usually {{found in the}} literature of parallel metaheuristics. In particular, fine grain parallelism can be use to assign independent threads of execution to every individual, thus allowing the whole cEA to run on a concurrent or actually <b>parallel</b> <b>hardware</b> platform. In this way, large time reductions can be obtained when running cEAs on FPGAs or GPUs.|$|E
50|$|Different {{considerations}} for memory access patterns appear in parallelism beyond locality of reference, namely {{the separation of}} reads and writes. E.g.: even if the reads and writes are 'perfectly' local, it can be impossible to parallelise due to dependencies; separating the reads and writes into separate areas yields a different memory access pattern, maybe initially appear worse in pure locality terms, but desirable to leverage modern <b>parallel</b> <b>hardware.</b>|$|E
30|$|To achieve parallelization {{with high}} {{performance}} and low cost, algorithms should be coordinated with existing <b>parallel</b> processing <b>hardware</b> and software properly. However, for different practical needs and computer configurations, an algorithm {{may need to}} be newly reconstructed and the model may also change a lot, so the design of all-purpose parallel codes becomes much complex.|$|R
40|$|In {{this paper}} a survey on current trends in {{parallel}} computing {{has been studied}} that depicts all the aspects of parallel computing system. A large computational problem {{that can not be}} solved by a single CPU can be divided into a chunk of small enough subtasks which are processed simultaneously by a parallel computer. The parallel computer consists of <b>parallel</b> computing <b>hardware,</b> <b>parallel</b> computing model, software support for parallel programming. Parallel performance measurement parameters and parallel benchmarks are used to measure the performance of a parallel computing system. The hardware and the software are specially designed for parallel algorithm and programming. This paper explores all the aspects of parallel computing and its usefulness...|$|R
50|$|Dennis {{has also}} {{worked as an}} {{independent}} consultant and research scientist on projects related with <b>parallel</b> computer <b>hardware</b> and software since his retirement from MIT in 1987. He {{has worked with the}} NASA Research Institute for Advanced Computer Science as Visiting Scientist, with the Architecture Group of Carlstedt Elektronik (Gothenburg, Sweden), and with Acorn Networks, Inc., as Chief Scientist.|$|R
50|$|MPI {{provides}} <b>parallel</b> <b>hardware</b> vendors with {{a clearly}} defined base set of routines {{that can be}} efficiently implemented. As a result, hardware vendors can build upon this collection of standard low-level routines to create higher-level routines for the distributed-memory communication environment supplied with their parallel machines. MPI provides a simple-to-use portable interface for the basic user, yet one powerful enough to allow programmers to use the high-performance message passing operations available on advanced machines.|$|E
50|$|Parallel {{algorithms}} for prefix sums {{can often}} be generalized to other scan operations on associative binary operations, and {{they can also be}} computed efficiently on modern <b>parallel</b> <b>hardware</b> such as a GPU. Many parallel implementations follow a two pass procedure where partial prefix sums are calculated in the first pass on each processing unit; the prefix sum of these partial sums is then calculated and broadcast back to the processing units for a second pass using the now known prefix as the initial value. Asymptotically this method takes approximately two read operations and one write operation per item.|$|E
50|$|In 2010, under Pentkovski's leadership, Intel and the Moscow Institute of Physics and Technology (MIPT) won {{the contest}} of {{university}} proposals to launch major world-class research initiatives {{with the participation}} of prominent international scientists, conducted by the Ministry of Education and Science of the Russian Federation and received a grant of 150 million rubles. A team of Intel engineers, led by Pentkovski in collaboration with MIPT researchers, launched a lab targeting {{research and development of}} computer-intensive applications. Primarily, the lab iSCALARE was focused on problem-oriented, highly <b>parallel</b> <b>hardware</b> and software architectures for bioinformatics, drug design, and pharmaceuticals.|$|E
40|$|Abstract. Genetic Programming (GP) may {{dramatically}} {{increase the}} performance of software written by domain experts. GP and autotuning are used to optimise and refactor legacy GPGPU C code for modern <b>parallel</b> graphics <b>hardware</b> and software. Speed ups of more than six times on recent nVidia GPU cards are reported compared to the original kernel on the same hardware. ...|$|R
40|$|The {{availability}} of <b>parallel</b> computation <b>hardware</b> and {{the advent of}} standardized programming interfaces has made a new class of beam dynamics problems accessible to numerical simulations. We describe recent progress in code development for simulations of coherent synchrotron radiation and the weak-strong and strong-strong beam-beam interaction. Parallelization schemes will be discussed, and typical results will be presented...|$|R
50|$|In <b>parallel,</b> the <b>hardware</b> {{elements}} are grouped and {{passed through a}} process of logic synthesis, during which performance constraints, such as operational frequency and expected signal delays, are applied. This generates a logical netlist which is a file describing the circuit as a collection of connected silicon gate elements from a library provided by the silicon manufacturer.|$|R
50|$|Parallel metaheuristic is a {{class of}} {{techniques}} {{that are capable of}} reducing both the numerical effort and the run time of a metaheuristic. To this end, concepts and technologies from the field of parallelism in computer science are used to enhance and even completely modify the behavior of existing metaheuristics. Just as it exists a long list of metaheuristics like evolutionary algorithms, particle swarm, ant colony optimization, simulated annealing, etc. it also exists a large set of different techniques strongly or loosely based in these ones, whose behavior encompasses the multiple parallel execution of algorithm components that cooperate in some way to solve a problem on a given <b>parallel</b> <b>hardware</b> platform.|$|E
50|$|In the mid-1990s, Olukotun and his co-authors {{argued that}} {{multi-core}} computer processors {{were likely to}} make better use of hardware than existing superscalar designs.In 2000, while a professor at Stanford, Olukotun founded Afara Websystems, a company that designed and manufactured multi-core SPARC-based computer processors for data centers. Afara was purchased by Sun Microsystems in 2002; at Sun, Olukotun {{was one of the}} architects of the 2005 UltraSPARC T1 processor.In 2008, Olukotun returned to Stanford, and founded the Pervasive Parallelism Laboratory at Stanford after gathering US$6M in funding from several computer-industry corporations. His recent work focuses on domain-specific programming languages that can allow algorithms to be easily adapted to multiple different types of <b>parallel</b> <b>hardware</b> including multi-core systems, graphics processing units, and field-programmable gate arrays.|$|E
5000|$|River Trail was {{announced}} at the Intel Developer Forum in September 2011, and demonstrated using a Firefox extension developed by Intel. Brendan Eich, the original author of JavaScript, promised that he would promote River Trail within Ecma International, saying [...] "The demo shows a 15x speedup over serial JavaScript. It lights up the ridiculously <b>parallel</b> <b>hardware</b> in modern CPUs and GPUs, for audio, video, image processing, automated voice response, computer vision, 3D gaming, etc. - all written in memory-safe, clean, functional JavaScript, without threads and their data races and deadlocks." [...] Because River Trail leverages Intel's OpenCL SDK [...] it can exploit multiple CPU cores as well as data parallel instructions (ex. AVX, SSE) and the speedup can be greater than the CPU core count would imply.|$|E
40|$|Abstract. Current media ISA {{extensions}} such as Sun’s VIS {{consist of}} SIMD-like instructions that operate on short vector registers. In order to exploit more parallelism in a superscalar processor provided with such instructions, the issue width {{has to be}} increased. In the ComplexStreamed Instruction (CSI) set exploiting more parallelism does not involve issuing more instructions. In this paper we study how the performance of superscalar processors extended with CSI or VIS scales {{with the amount of}} <b>parallel</b> execution <b>hardware.</b> Results show that the performance of the CSI-enhanced processor scales very well. For example, increasing the datapath width of the CSI execution unit from 16 to 32 bytes improves the kernel-level performance by a factor of 1. 56 on average. The VISenhanced machine is unable to utilize large amounts of <b>parallel</b> execution <b>hardware</b> efficiently. Due to the huge number of instructions that need to be executed, the decode-issue logic constitutes a bottleneck. ...|$|R
30|$|To {{solve the}} {{computational}} complexity and data BW challenges of ME, various approaches have been proposed, such as <b>parallel</b> full search <b>hardware</b> design and fast ME algorithms.|$|R
50|$|Acceleware Ltd. (abbreviated AXE) is a Canadian {{software}} development company, producing software that enables software vendors to utilize <b>parallel</b> processing, multi-core <b>hardware</b> environments {{without having to}} modify their applications.|$|R
