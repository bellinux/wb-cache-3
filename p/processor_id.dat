4|20|Public
5000|$|The IBM System z {{mainframe}} processors {{support a}} Store CPU ID (...) instruction since the 1983 IBM 4381 for querying the <b>processor</b> <b>ID.</b>|$|E
40|$|We {{present an}} {{implementation}} of Active Messages and four implementations of the Split-C parallel programming language over the Virtual Interface Architecture user-level networking system {{running on the}} Berkeley Millennium cluster. This cluster is composed of 16 2 -way SMP Intel 400 MHz PII processors using Myrinet network interface cards. Results from application benchmarks show that the best Split-C implementation is {{the one with the}} lowest processor send and receive overheads. 1 Introduction Split-C is a parallel extension of the C programming language that supports efficient access to a global address space on distributed memory multiprocessors [Dus 93]. Programs may access data on other processes via global pointers (essentially a normal C pointer combined with a <b>processor</b> <b>ID).</b> One of Split-C's more unique features is the support for explicit split-phase communication through these global pointers. Split-C supports a split-phase read (called get) and two split-phase write (put and [...] ...|$|E
40|$|Abstract [...] - Due to {{the rapid}} growth of Internet users in the last decades and illegal use of {{software}} from piracies without granting authorities from legal vendors, besides expensive of software products and draw backs in distribution, this paper offers a suitable technique to protect software from piracy. It relies on elliptic curve cryptography technique achieved via <b>processor</b> <b>ID</b> of the buyer or user. The bought software after downloading will be protected from illegal distribution through mechanism of elliptic curve with ElGamal cryptographic technique. In order to protect server from piracies and latencies causes from network communication, this paper offers software downloading during virtual computer or VMware. Time consuming for encryption and decryption will be shown. This paper concludes that using Elliptic curve offers equal security for small bit size, thereby reducing processing overhead. Software implemented using Matlab V 7. 14 (R 2012 a) with processor AMD Turion(tm) X 2 Ultra Dual-Core Mobile ZM- 85 2. 30 GHZ with platform Vista...|$|E
5000|$|Hovering {{the cursor}} over any logical processor's graph shows the NUMA node of that <b>processor</b> and its <b>ID.</b>|$|R
40|$|The {{problem of}} electing {{a leader in}} a {{synchronous}} ring of n processon is considered. Both positive and negative results are obtained. On the one hand, if <b>processor</b> <b>IDs</b> are chosen from some countable set, then there is an algorithm that uses only O(n) messages in the wont case. On the other hand, any algorithm that is restricted to use only comparisons of IDs requires fl(n log n) messages in the worst case. Alternatively, {{if the number of}} rounds is required to be bounded by some t in the wont case, and lDs are chosen from any set having at least f(n, t) elements, for a certain very fast-growing functionf then any algorithm requires fl(n log n) messages in the wont case...|$|R
50|$|Hovering {{the cursor}} over any logical processor's data now shows the NUMA node of that <b>processor</b> and its <b>ID.</b>|$|R
40|$|Abstract. elegant is a {{general-purpose}} {{code for}} electron accelerator simulation {{that has a}} worldwide user base. Recently, many of the time-intensive elements were parallelized using MPI. Development has used modest Linux clusters and the BlueGene/L supercomputer at Argonne National Laboratory. This has provided very good performance for some practical simulations, such as multiparticle tracking with synchrotron radiation and emittance blow-up in the vertical rf kick scheme. The effort began with development of a concept that allowed for gradual parallelization of the code, using the existing beamline-element classification table in elegant. This was crucial as it allowed parallelization without major changes in code structure and without major conflicts with the ongoing evolution of elegant. Because of rounding error and finite machine precision, validating a parallel program against a uniprocessor program with the requirement of bitwise identical results is notoriously difficult. We will report validating simulation results of parallel elegant against those of serial elegant by applying Kahan’s algorithm to improve accuracy dramatically for both versions. The quality of random numbers in a parallel implementation {{is very important for}} some simulations. Some practical experience with generating parallel random numbers by offsetting the seed of each random sequence according to the <b>processor</b> <b>ID</b> will be reported...|$|E
50|$|This problem occurs only on {{some models}} of the {{original}} Pentium processor. The bug only existed in some Pentium family processors with a clock speed of less than 120 MHz. On affected models, the Intel <b>Processor</b> Frequency <b>ID</b> Utility checks {{for the presence of}} this bug.|$|R
40|$|Data fields {{provide a}} {{flexible}} and highly general model for indexed collections of data. Data Field Haskell is a Haskell dialect that provides {{an instance of}} data fields. It {{can be used for}} very generic collection-oriented programming, with a special emphasis on multidimensional structures. We give {{a brief description of the}} data field model and its underlying theory. We then describe Data Field Haskell, and an implementation. 1 Introduction Indexed data structures are important in many computing applications. The canonical indexed data structure is the array, but other indexed structures like hash tables and explicitly parallel entities are also common. In many applications the indexing capability provides an important part of the model: when solving partial differential equations, for instance, the index is often closely related to a physical coordinate, and explicitly parallel algorithms often use <b>processor</b> <b>ID's</b> as indices. Since the time of APL [5] it has been recognised [...] ...|$|R
40|$|We {{consider}} {{the problem of}} electing a leader in a synchronous ring of n processors. We obtain {{both positive and negative}} results. On the one hand, we show that if <b>processor</b> <b>ID's</b> are chosen from some countable sot, then there is an algorithm which uses only O(n) messages in the worst case. On the other hand, we obtain two lower bound results: If the algorithm is restricted to use only comparisons of ID's, then we obtain an ~(n log n) lower bound for the number of messages required in the worst case. Alternatively, there is a (very fast-growing) function f with the following property. If the number of rounds is required to be bounded by some t in the worst case, and ID's are chosen from any set having at least f(n,t) elements, then any algolithm requires [~(n log n) messages in the worst case. 1...|$|R
40|$|A {{distributed}} system is self-stabilizing if its behavior is correct {{regardless of its}} initial state. A ring is a {{distributed system}} in which all processors are connected in a cycle and each processor communicates directly with only its two neighbors. A ring is oriented when all processors have a consistent notion of their left and right neighbors. A ring is uniform when all processors run the same program and have no distinguishing attributes, such as <b>processor</b> <b>IDs.</b> A well-known selfstabilizing uniform protocol for ring orientation is that of [IJ 93 b]. For a ring of size n, this protocol will stabilize in expected O(n&sup 2;) processor activations. This assumes that processors are scheduled by a distributed demon [...] {{one in which the}} communication registers between processors can be atomically updated (a read followed by a write), and the processors have the ability to make random choices. This paper generalizes the notion of orienting a ring to that of orienting [...] ...|$|R
40|$|The {{purpose of}} this paper is a study of {{computation}} that can be done locally in a distributed network, where "locally" means within time (or distance) independent of the size of the network. Locally Checkable Labeling (LCL) problems are considered, where the legality of a labeling can be checked locally (e. g., coloring). The results include the following: ffl There are non-trivial LCL problems that have local algorithms. ffl There is a variant of the dining philosophers problem that can be solved locally. ffl Randomization cannot make an LCL problem local; i. e., if a problem has a local randomized algorithm then it has a local deterministic algorithm. ffl It is undecidable, in general, whether a given LCL has a local algorithm. ffl However, it is decidable whether a given LCL has an algorithm that operates in a given time t. ffl Any LCL problem that has a local algorithm has one that is order-invariant (the algorithm depends only on the order of the <b>processor</b> <b>id's)</b> ...|$|R
40|$|The Mobile Thread Task Manager (MTTM) {{is being}} applied to parallelizing {{existing}} flight software {{to understand the}} benefits and to develop new techniques and architectural concepts for adapting software to multicore architectures. It allocates and load-balances tasks {{for a group of}} threads that migrate across processors to improve cache performance. In order to balance-load across threads, the MTTM augments a basic map-reduce strategy to draw jobs from a global queue. In a multicore processor, memory may be "homed" to the cache of a specific processor and must be accessed from that processor. The MTTB architecture wraps access to data with thread management to move threads to the home processor for that data so that the computation follows the data in an attempt to avoid L 2 cache misses. Cache homing is also handled by a memory manager that translates identifiers to <b>processor</b> <b>IDs</b> where the data will be homed (according to rules defined by the user). The user can also specify the number of threads and processors separately, which is important for tuning performance for different patterns of computation and memory access. MTTM efficiently processes tasks in parallel on a multiprocessor computer. It also provides an interface {{to make it easier to}} adapt existing software to a multiprocessor environment...|$|R
50|$|In one of {{the early}} works, Chang and Roberts {{proposed}} a uniform algorithm in which a processor with the highest ID is selected as the leader. Each <b>processor</b> sends its <b>ID</b> in a clockwise direction. A process receiving a message and compares it with its own. If it is bigger, it passes it through, otherwise it will discard the message. They show that this algorithm uses at most O(n^2) messages and O(nlogn) in the average case.Hirschberg and Sinclair improved this algorithm with O(nlogn) message complexity by introducing a 2 directional message passing scheme allowing the processors to send messages in both directions.|$|R
40|$|A snap-stabilizing protocol, {{starting}} from any arbitrary initial configuration, always behaves {{according to its}} specification. In [1], we presented the first snap-stabilizing depth-first search (  ¢¡¤ £) wave protocol for arbitrary rooted networks working under an unfair daemon. However, this protocol needs ¥ (¦¨ §) states per processors (where ¦ {{is the number of}} <b>processors)</b> and needs <b>ids</b> on <b>processors.</b> In this paper, we propose an original snap-stabilizing solution for this problem with a strongly enhanced space complexity, i. e., ¥ (©¢���� ¦) states where © is the degree of the network. Furthermore, this new protocol does not need a completely identified network: only the root needs to be identified...|$|R
40|$|Abstract. A snap-stabilizing protocol, {{starting}} from any arbitrary initial configuration, always behaves {{according to its}} specification. In [4], we presented the first snap-stabilizing depth-first search (DFS) wave protocol for arbitrary rooted networks working under an unfair daemon. However, this protocol needs O(N N) states per processors (where N {{is the number of}} <b>processors)</b> and needs <b>ids</b> on <b>processors.</b> In this paper, we propose an original snap-stabilizing solution for this problem with a strongly enhanced space complexity, i. e., O(∆ 2 × N) states where ∆ is the degree of the network. Furthermore, this new protocol does not need a completely identified network: only the root needs to be identified, i. e., the network is semi-anonymous. ...|$|R
50|$|Unlike {{most other}} CPUID leaves, leaf Bh will return {{different}} values in EDX {{depending on which}} logical processor the CPUID instruction runs; the value returned in EDX is actually the x2APIC id of the logical <b>processor.</b> The x2APIC <b>id</b> space is not continuously mapped to logical processors however; there can be gaps in the mapping, meaning that some intermediate x2APIC ids don't necessarily correspond to any logical processor. Additional information for mapping the x2APIC ids to cores is provided in the other registers. Although the leaf Bh has sub-leaves (selected by ECX as described further below), the value returned in EDX is only affected by the logical processor on which the instruction is running but not by the subleaf.|$|R
40|$|Abstract:- This paper {{presents}} a sublinear, parallel, split-merge block matching, displacement estimation algorithm for video coding that performs a segmentation of the frames into superblocks. All the superblocks are uniquely labelled {{and each of}} the processors knows the label of the superblock to which it belongs. The algorithm identifies the borders of the superblocks and labels each of them with the ID of the smallest-ID processor in the area. The <b>processors</b> having their <b>IDs</b> equal to their labels will participate to the SEND phase, in which the output is sent to the destination. The computation involved takes time proportional to log(n), where n is the number of blocks. The algorithm makes use of the techniques for image labelling on an optical architecture described by Eshaghian in [9], it operates on a parallel architecture with optical connections through free space, or equivalently, on a PRAM...|$|R
40|$|Interesting {{tasks are}} scarce. Yet they are {{essential}} as an investigation material, {{if we are}} to understand the structure of the tasks world. We propose a new family of tasks called 0 - 1 Exclusion tasks, and show it is an interesting family. A 0 - 1 Exclusion task on n processors is specified by a sequence of n − 1 bits b(1), b(2), [...] ., b(n − 1). For participating set of size k, 0 < k < n, each processor is to output 0 or 1 but they should not all output b(k). When the participating set is of size n then they should all output neither all 0 ’s nor all 1 ’s. Only one member of this family, the one specified by b(1) = b(2) = [...] . = b(n − 1) = 1, was implicitly considered in the past and shown to be equivalent to Set-Consensus. In this initial investigation of the whole family we show that not all of its members are created equal. We take the member specified by b(1) = 1, b(2) = [...] . = b(n − 1) = 0, and show that it is read-write unsolvable for all n, but is strictly weaker than Set-Consensus for n odd. We show some general results about the whole family. The family is sandwiched between Set-Consensus from above and Weak-Symmetry-Breaking from below. Any Black-Box of n ports that solves a 0 - 1 Exclusion task, can be used to solve that task for n <b>processors</b> with <b>ids</b> from unbounded domain. Finally we show an intriguing relation between Strong-Renaming and the 0 - 1 Exclusion family, and make few conjectures about the implementations relationships among members of of the family, as well as possibly tasks outside it...|$|R
40|$|AbstractIn {{this paper}} we give {{improved}} bounds for the multisearch problem on a hypercube. This is a parallel search problem where {{the elements in}} the structure S to be searched are totally ordered, but where {{it is not possible}} to compare in constant time any two given queries q and q′. More precisely, we are given on a n-processor hypercube a sorted n-element sequence S, and a set Q of n queries, and we need to find for each query q ∈ Q its location in the sorted S. We present an improved algorithm for the multisearch problem, one that takes O(log n(log log n) 3) time on a n-processor hypercube. This problem is fundamental in computational geometry, for example it models planar point location in a slab. We give as application a trapezoidal decomposition algorithm with the same time complexity on a n log n-processor hypercube. The hypercube model for which we claim our bounds is the standard one, SIMD, with O(1) memory registers per processor, and with one-port communication. Each register can store O(log n) bits, so that a <b>processor</b> knows its <b>ID...</b>|$|R
40|$|Abstract. This paper {{concerns}} {{a number of}} algorithmic problems on graphs and how they may be solved in a distributed fashion. The computational model is such that each node of the graph is occupied by a processor {{which has its own}} <b>ID.</b> <b>Processors</b> are restricted to collecting data from others which are at a distance at most away from them in time units, but are otherwise computationally unbounded. This model focuses on the issue of locality in distributed processing, namely, to what extent a global solution to a computational problem can be obtained from locally available data. Three results are proved within this model: A 3 -coloring of an n-cycle requires time f(log * n). This bound is tight, by previous work of Cole and Vishkin. Any algorithm for coloring the d-regular tree of radius r which runs for time at most 2 r/ 3 requires at least f(x/-) colors. In an n-vertex graph of largest degree A, an O(A 2) -coloring may be found in time O(log * n). Key words, distributed algorithms, graph theory, locality, lower bounds AMS(MOS) subject classifications. 05 C 35, 68 R 10, 68 Q 99 1. Introduction. I...|$|R
40|$|In {{this paper}} we give {{improved}} bounds for the multisearch problem on a hypercube. This is a parallel search problem where {{the elements in}} the structure S to be searched are totally ordered, but where {{it is not possible}} to compare in constant time any two given queries q and q 0. More precisely, we are given on a n-processor hypercube a sorted n-element sequence S, and a set Q of n queries, and we need to nd for each query q 2 Q its location in the sorted S. We present an improved algorithm for the multisearch problem, one that takes O(log n(log log n) 3) time on a n-processor hypercube. This problem is fundamental in computational geometry, for example it models planar point location in a slab. We give as application a trapezoidal decomposition algorithm with the same time complexity on a n log n-processor hypercube. The hypercube model for which we claim our bounds is the standard one, SIMD, with O(1) memory registers per processor, and with one-port communication. Each register can store O(log n) bits, so that a <b>processor</b> knows its <b>ID...</b>|$|R
500|$|Windows Server 2012 {{includes}} {{a new version}} of Windows Task Manager together with the old version. In the new version the tabs are hidden by default, showing applications only. In the new Processes tab, the processes are displayed in varying shades of yellow, with darker shades representing heavier resource use. It lists application names and status, as well as CPU, memory, hard disk and network utilization. The process information found in the older versions are now moved to the new Details tab. The Performance tab shows [...] "CPU", [...] "Memory", [...] "Disk", [...] "Wi-Fi" [...] and [...] "Ethernet" [...] graphs. The CPU tab no longer displays individual graphs for every logical processor on the system by default, although that remains an option. Additionally, it can display data for each non-uniform memory access (NUMA) node. When displaying data for each logical processor for machines with more than 64 logical processors, the CPU tab now displays simple utilization percentages on heat-mapping tiles. The color used for these heat maps is blue, with darker shades again indicating heavier utilization. Hovering the cursor over any logical processor's data now shows the NUMA node of that <b>processor</b> and its <b>ID,</b> if applicable. Additionally, a new Startup tab has been added that lists startup applications, however this tab does not exist in Windows Server 2012. The new task manager recognizes when a Windows Store app has the [...] "Suspended" [...] status.|$|R

