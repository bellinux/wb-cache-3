168|934|Public
50|$|Veejay has {{separated}} the video <b>processing</b> <b>core</b> from the user interface, allowing the user(s) to control (multiple instances of) the application over the network.|$|E
50|$|Nvidia PureVideo {{technology}} is {{the combination of a}} dedicated video <b>processing</b> <b>core</b> and software which decodes H.264, VC-1, WMV, and MPEG-2 videos with reduced CPU utilization.|$|E
50|$|The <b>processing</b> <b>core</b> of the Blue Gene/P {{supercomputer}} {{designed and}} manufactured by IBM. It {{is very similar}} to the PowerPC 440 but few details are disclosed.|$|E
30|$|We observe from Figure 3 {{that the}} {{performance}} of the proposed algorithm with up to eight <b>processing</b> <b>cores</b> reached nearly ideal speedup for the three largest image sizes. From ten <b>processing</b> <b>cores</b> and up, the computation for smaller images, 50 × 50 and 100 × 100, had a reduced speedup, probably due to the overhead of creation of threads only to process a limited amount of data. On the other hand, for images larger than 200 × 200, the speedups obtained by increasing the amount of <b>processing</b> <b>cores</b> were ever increasing. However, for 50 × 50 image size, {{we were not able to}} get linear speedup.|$|R
5000|$|Automotive {{machine vision}} Middleware enables cross {{platform}} execution of ADAS algorithms utilizing various inputs, outputs and multiple <b>processing</b> <b>cores.</b>|$|R
3000|$|... a novel {{architecture}} {{that uses a}} programable array of multiple <b>processing</b> <b>cores</b> that exhibits both flexibility and potential for mobile devices.|$|R
50|$|The {{reflected}} light user {{interactions with the}} interface surface is passed through an infra-red filter and imaged on to a CMOS image sensor in the sensor module. The sensor chip has a custom hardware embedded such as the Virtual Interface <b>Processing</b> <b>Core</b> and {{it is capable of}} making a real-time determination of the location from where the light was reflected. The <b>processing</b> <b>core</b> may track not only one, but multiple light reflections {{at the same time and}} it can support multiple keystrokes and overlapping cursor control inputs.|$|E
50|$|Leif Claesson, the {{inventor}} of audio <b>processing</b> <b>core</b> technology utilized by Octiv and Volume Logic, in 2007 joined with Octiv co-founder Keith Edwards to form a partnership to sell follow-on technology called Breakaway.|$|E
5000|$|A module {{consists}} of a coupling of two [...] "conventional" [...] x86 out of order processing cores. The <b>processing</b> <b>core</b> shares the early pipeline stages (e.g. L1i, fetch, decode), the FPUs, and the L2 cache {{with the rest of}} the module.|$|E
40|$|In this paper, {{we study}} {{the impact of}} {{application}} task mapping on the reliability of multiprocessor system-on-chip (MPSoC) application {{in the presence of}} soft errors. Based on this study, we propose a novel system-level design optimization of an MPSoC application through joint power minimization and reliability improvement. The power minimization is carried out using voltage scaling technique, while reliability improvement is achieved through careful choice of application task mapping on the homogeneous MPSoC <b>processing</b> <b>cores.</b> The overall aim is to minimize the number of single-event upsets (SEUs) experienced by the MPSoC application for suitably identified voltage scaling of the system <b>processing</b> <b>cores</b> such that the power is reduced and the specified real-time constraint is met. We evaluate the effectiveness of the proposed design optimization using a number of different applications, including MPEG- 2 video decoder and synthetic applications. We show that for an MPEG- 2 decoder with four <b>processing</b> <b>cores,</b> the proposed soft error-aware optimization produces a design with 38 % less SEUs than soft error-unaware design optimization for an arbitrary soft error rate of 10 ? 9, while consuming 9 % less power and meeting a given real-time constraint. Furthermore, we investigate the impact of architecture allocation (allocation of <b>processing</b> <b>cores)</b> and show that for an MPSoC with six <b>processing</b> <b>cores</b> and a given real-time constraint, the proposed optimization produces design with up to 7 % less SEUs compared to soft error-unaware designs at the cost of 5. 5 % higher power...|$|R
5000|$|... #Caption: Benchmarking {{results from}} the [...] SIGGRAPH paper, showing {{predicted}} performance as an approximate linear function {{of the number of}} <b>processing</b> <b>cores</b> ...|$|R
50|$|Azul Systems {{released}} the Vega 3 7300 Series in May 2008. The 7300 series contains up to 864 <b>processing</b> <b>cores</b> with 768 GB of memory.|$|R
50|$|The 3D <b>processing</b> <b>core</b> of PICA200 {{consists}} {{of up to}} four programmable vertex pipelines that can be rearranged as four pixel pipelines. The number of IPCs and pipelines {{will depend on the}} target processor core and may change in the future.|$|E
5000|$|Nvidia's Tegra X2 (codenamed [...] "Parker") {{features}} Nvidia’s own custom general-purpose ARMv8-compatible core Denver 2 {{as well as}} code-named Pascal graphics <b>processing</b> <b>core</b> with GPGPU support. The {{chips are}} made using FinFET process technology using TSMC's 16 nm FinFET+ manufacturing process.|$|E
50|$|The {{micro-controller}} in {{the sensor}} module receives the positional information {{corresponding to the}} light flashes from the sensor <b>processing</b> <b>core,</b> interprets the events and then communicates them through the appropriate interface to external devices. By events it is understood any key stroke, mouse or touchpad control.|$|E
40|$|Abstract. Modern HEC systems, such as Blue Gene/P, rely on {{achieving}} high-performance {{by using}} the parallelism of a massive number of low-frequency/low-power <b>processing</b> <b>cores.</b> This means that the local preand post-communication processing required by the MPI stack might not be very fast, owing to the slow <b>processing</b> <b>cores.</b> Similarly, small amounts of serialization within the MPI stack that were acceptable on small/medium systems can be brutal on massively parallel systems. In this paper, we study different non-data-communication overheads within the MPI implementation {{and their impact on}} the performance of the IBM Blue Gene/P system. ...|$|R
40|$|Multi-core CPU {{architectures}} {{have become}} prevalent in recent years. A number of multi-core CPUs consist {{of not only}} multiple <b>processing</b> <b>cores,</b> but multiple different types of <b>processing</b> <b>cores,</b> each with different capabilities and specialisations. These heterogeneous multi-core architectures (HMAs) can deliver exceptional performance; however, they are notoriously difficult to program effectively. This dissertation investigates the feasibility of ameliorating many of the difficulties encountered in application development on HMA processors, by employing a behaviouraware runtime system. This runtime system provides applications with the illusion of executing on a homogeneous architecture, by presenting a homogeneous virtual machine interface. The runtime system uses knowledge of a program’s execution behaviour, gained through explicit code annotations, static analysis or runtime monitoring, to inform its resource allocation and scheduling decisions, such that the application makes best use of the HMA’s heterogeneous <b>processing</b> <b>cores.</b> The goal of this runtime system is to enable non-specialist application developers to write applications that can exploit an HMA, without the developer requiring in-depth knowledge of the HMA’s design...|$|R
50|$|The <b>processing</b> <b>cores</b> feature 64 KB of {{scratchpad memory}} for data (and 16 KB for instructions) and {{communicate}} via a network on a chip, {{instead of having}} a traditional cache hierarchy.|$|R
50|$|Kilocore, from Rapport Inc. and IBM, is a high-performance, {{low-power}} multi-core microprocessor {{that has}} 1,025 cores. It contains a single PowerPC <b>processing</b> <b>core,</b> and 1,024 eight-bit Processing Elements running at 125 MHz each, {{which can be}} dynamically reconfigured, connected by a shared interconnect. It allows high performance parallel processing.|$|E
50|$|The Sony SPC700 is the S-SMP's {{integrated}} 8-bit <b>processing</b> <b>core</b> {{manufactured by}} Sony with an instruction set {{similar to that}} of the MOS Technology 6502 (as used in the Commodore 1541 diskette drive and the Vic 20, Apple II, BBC Micro and in modified form in the original NES).|$|E
50|$|To get {{microwave}} technologies {{ready to}} take up the challenge of being an active part in complex IP transport networks, the company developed its MicrowaveRouter product.3Roam's MicrowaveRouter is the first microwave equipment to incorporate a complete native IP layer 3 <b>processing</b> <b>core,</b> while competing products only support on plain Ethernet switching.|$|E
50|$|<b>Processing's</b> <b>core</b> libraries, {{the code}} {{included}} in exported applications and applets, is licensed under the GNU Lesser General Public License, allowing users to release their original code {{with a choice}} of license.|$|R
5000|$|... 32-way set {{associative}} L3 victim cache sized {{at least}} 2 MB, shared between <b>processing</b> <b>cores</b> {{on a single}} die (each with 512 K of independent exclusive L2 cache), with a sharing-aware replacement policy.|$|R
50|$|Adapteva is a fabless {{semiconductor}} company {{focusing on}} low power many core microprocessor design. The company {{was the second}} company to announce a design with 1,000 specialized <b>processing</b> <b>cores</b> on a single integrated circuit.|$|R
5000|$|Prior to the {{introduction}} of the Apple [...] "A" [...] series of SoCs, Apple used several SoCs in early revisions of the iPhone and iPod touch. They were specified by Apple and manufactured by Samsung. They integrate a single ARM-based <b>processing</b> <b>core</b> (CPU), a graphics processing unit (GPU), and other electronics necessary to provide mobile computing functions within a single physical package.|$|E
50|$|Some of {{the more}} {{traditional}} test and measurement technologies are only able to measure performance and data flow at the input/output (I/O) point on a chip. The real challenge is for the instrument to gain visibility into the processing {{that is going on}} inside the core silicon itself. To do this, embedded instruments are needed between the I/O point on the perimeter of the chip and the <b>processing</b> <b>core.</b>|$|E
5000|$|The CPU core voltage (VCORE) is {{the power}} supply voltage {{supplied}} to the CPU (which is a digital circuit), GPU, or other device containing a <b>processing</b> <b>core.</b> The amount of power a CPU uses, and thus the amount of heat it dissipates, {{is the product of}} this voltage and the current it draws.In modern CPUs, which are made using CMOS,the current is almost proportional to the clock speed, the CPU drawing almost no current between clock cycles. (See, however, subthreshold leakage.) ...|$|E
30|$|To {{accelerate}} the performance on <b>processing</b> <b>cores,</b> parallelization will be demanded. The parallelization {{can take place}} at different levels, such as task, data, and instruction. Furthermore, the specific video processing algorithms performed by IP accelerators or <b>processing</b> <b>cores</b> can improve the execution efficiency significantly. Therefore, the requirements for H. 264 video applications are so demanding that multiple acceleration techniques may be combined to meet the real-time conditions. The programmable, reconfigurable, heterogeneous processors are the preferable choice for an implementation of H. 264 [*]BP video encoder. Architectures with the support for concurrent performance and hardware video IP accelerators are well applicable for achieving the real-time requirement imposed by the H. 264 standard.|$|R
2500|$|AMD Stream SDK and AMD APP SDK (Accelerated Parallel Processing) SDK {{to enable}} AMD {{graphics}} <b>processing</b> <b>cores</b> (GPU), working {{in concert with}} the system’s x86 cores (CPU), to execute heterogeneously to accelerate many applications beyond just graphics ...|$|R
3000|$|..., respectively. The {{priority}} of data transfer packets {{is assumed to}} be equal to the {{priority of}} the runnable sending them. The <b>processing</b> <b>cores</b> can operate under a given set of voltage and frequency levels, but the links have no P-states.|$|R
50|$|Large data loads {{that require}} {{processing}} impose data processing requirements on hardware (such as routers). For example, a gateway router supporting a populated class B subnet, handling 10 x 100 Mbit/s Ethernet channels, must examine 16 bits of address {{to determine the}} destination port for each packet. This translates into 81913 packets per second (assuming maximum data payload per packet) with a table of 2^16 addresses this requires the router {{to be able to}} perform 5.368 billion lookup operations per second. In a worse case scenario, where the payloads of each Ethernet packet are reduced to 100 bytes, this number of operations per second jumps to 520 billion. This router would require a multi-teraflop <b>processing</b> <b>core</b> {{to be able to handle}} such a load.|$|E
50|$|The POWER9 core {{comes in}} two variants, one is four-way {{multithreading}} called SMT4 and one eight-way called SMT8. The SMT4- and SMT8-cores are quite similar, {{in that they}} consist {{of a number of}} so-called slices fed by common schedulers. A slice is a rudimentary 64-bit single threaded <b>processing</b> <b>core</b> with load store unit (LSU), integer unit (ALU) and a vector scalar unit (VSU, doing SIMD and floating point). A super-slice is the combination of two slices. An SMT4-core consists of a 32 KB L1 cache, a 32 KB L1 data cache, an instruction fetch unit (IFU) and an instruction sequencing unit (ISU) which feeds two super-slices. An SMT8-core has two sets of L1 caches and, IFUs and ISUs to feed four super-slices. The result is that the 12-core and 24-core versions of POWER9 each consist of the same amount of slices, i.e. 96 each and the same amount of L1 cache.|$|E
5000|$|After the Phoenix Five {{return to}} Earth {{and start to}} reform the world, X-23 feels that Seyfert's Sentinel should be destroyed, as it still has the {{directive}} to exterminate mutants, but he argues that this directive isn't its primary one, and that it learned to overcome it. As Emma Frost destroys Sentinels all over the world, she eventually arrives at the Academy and demands to either destroy the Sentinel or have its programming erased. Juston refuses, arguing {{that it would be}} like erasing the individual that his Sentinel has become; Giant-Man, X-23 and the other students decide that he is right and attack Emma. As the Academy staff and students fight Emma Frost, both sides discuss the ethics in her attempt to destroy Juston's Sentinel. Finesse asks for Quicksilver's help, but he refuses, stating that Sentinels only exist as mutant-killing machines; nevertheless, instants after Emma destroys Juston's Sentinel, Quicksilver replaces its central <b>processing</b> <b>core</b> with the one from another robot, thus saving the Sentinel's [...] "life" [...] and memories. After Emma leaves the Academy, Giant-Man and Tigra announce that the Academy will be closed, to keep the students away from the war between Avengers and X-Men.|$|E
30|$|A mapping M is a vector of p core locations, M= [π _τ _ 1,...,π _τ _p], {{where each}} element {{corresponds}} {{with the appropriate}} element of Γ (taskset) and can be substituted with any element of set Π (<b>processing</b> <b>cores).</b>|$|R
40|$|Network {{processors}} are processors tailored {{towards the}} computer network space and generally perform packet-processing operations. Network processors address {{the need for}} performance in computer network design while maintaining the flexibility to adapt to future network protocols. This project examines the performance and flexibility of network processor architectures. The architectures examined are chip-multiprocessor architectures—where parallelism in the workload is exploited through one or more on-chip <b>processing</b> <b>cores.</b> Network processor architectures are modeled using discrete event simulation. An abstract workload which bears similarity to current network processor workloads such as IP forwarding, Network Address Translation and Encryption is used. Simulations are run which compare the running time of a workload vs. network processor architectures with different numbers of on-chip <b>processing</b> <b>cores.</b> This project demonstrates the benefit of parallel architectures on the network processor workload. Parallel architectures with 16 <b>processing</b> <b>cores</b> can achieve up to 90 % reduction in execution time over single processor architectures. Simulations are run which compare the running time of different workloads with a varying number of dependencies between packets. Processor utilization is also measured. The limits of performance gain from different network processor architectures and network processor workloads are examined...|$|R
30|$|We {{implemented}} a software GNSS receiver with processes {{implemented a}}s threads and used that {{to analyze the}} GNSS application communication payload for individual links. This analysis indicated that the incoming signal represents the largest part of the communication in the network between <b>processing</b> <b>cores.</b>|$|R
