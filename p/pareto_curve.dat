93|98|Public
40|$|AbstractWe {{consider}} bicriteria optimization {{problems and}} investigate {{the relationship between}} two standard approaches to solving them: (i) computing the <b>Pareto</b> <b>curve</b> and (ii) the so-called decision maker’s approach in which both criteria are combined into a single (usually nonlinear) objective function. Previous work by Papadimitriou and Yannakakis showed how to efficiently approximate the <b>Pareto</b> <b>curve</b> for problems like Shortest Path, Spanning Tree, and Perfect Matching. We wish to determine for which classes of combined objective functions the approximate <b>Pareto</b> <b>curve</b> also yields an approximate solution to the decision maker’s problem. We show that an FPTAS for the <b>Pareto</b> <b>curve</b> also gives an FPTAS for the decision-maker’s problem if the combined objective function is growth bounded like a quasi-polynomial function. If the objective function, however, shows exponential growth then the decision-maker’s problem is NP-hard to approximate within any polynomial factor. In order to bypass these limitations of approximate decision making, we turn our attention to Pareto curves in the probabilistic framework of smoothed analysis. We show that in a smoothed model, we can efficiently generate the (complete and exact) <b>Pareto</b> <b>curve</b> with a small failure probability if there exists an algorithm for generating the <b>Pareto</b> <b>curve</b> whose worst-case running time is pseudopolynomial. This way, we can solve the decision-maker’s problem w. r. t.  any non-decreasing objective function for randomly perturbed instances of, e. g. Shortest Path, Spanning Tree, and Perfect Matching...|$|E
40|$|International audienceWe {{consider}} {{the problem of}} constructing an approximation of the <b>Pareto</b> <b>curve</b> associated with the multiobjective optimization problem _x∈S{ (f_ 1 (x), f_ 2 (x)) }, where f_ 1 and f_ 2 are two conflicting polynomial criteria and S⊂R^n is a compact basic semialgebraic set. We provide a systematic numerical scheme to approximate the <b>Pareto</b> <b>curve.</b> We start by reducing the initial problem into a scalarized polynomial optimization problem (POP). Three scalarization methods lead to consider different parametric POPs, namely (a) a weighted convex sum approximation, (b) a weighted Chebyshev approximation, and (c) a parametric sublevel set approximation. For each case, we have to solve a semidefinite programming (SDP) hierarchy parametrized {{by the number of}} moments or equivalently the degree of a polynomial sums of squares approximation of the <b>Pareto</b> <b>curve.</b> When the degree of the polynomial approximation tends to infinity, we provide guarantees of convergence to the <b>Pareto</b> <b>curve</b> in L^ 2 -norm for methods (a) and (b), and L^ 1 -norm for method (c) ...|$|E
40|$|We {{consider}} {{the problem of}} constructing an approximation of the <b>Pareto</b> <b>curve</b> associated with the multiobjective optimization problem $min_{mathbf{x} in mathbf{S}}{ (f_ 1 (mathbf{x}), f_ 2 (mathbf{x})) }$, where $f_ 1 $ and $f_ 2 $ are two conflicting polynomial criteria and $mathbf{S} subset mathbb{R}^n$ is a compact basic semialgebraic set. We provide a systematic numerical scheme to approximate the <b>Pareto</b> <b>curve.</b> We start by reducing the initial problem into a scalarized polynomial optimization problem (POP). Three scalarization methods lead to consider different parametric POPs, namely (a) a weighted convex sum approximation, (b) a weighted Chebyshev approximation, and (c) a parametric sublevel set approximation. For each case, we have to solve a semidefinite programming (SDP) hierarchy parametrized {{by the number of}} moments or equivalently the degree of a polynomial sums of squares approximation of the <b>Pareto</b> <b>curve.</b> When the degree of the polynomial approximation tends to infinity, we provide guarantees of convergence to the <b>Pareto</b> <b>curve</b> in $L^ 2 $-norm for methods (a) and (b), and $L^ 1 $-norm for method (c) ...|$|E
40|$|In multi-criteria optimization, several {{objective}} {{functions are}} to be optimized. Since the different objective functions are usually in conflict with each other, one cannot consider only one particular solution as optimal. Instead, {{the aim is to}} compute so-called <b>Pareto</b> <b>curves.</b> Since <b>Pareto</b> <b>curves</b> cannot be computed efficiently in general, we have to be content with approximations to them. We are concerned with approximating <b>Pareto</b> <b>curves</b> of multi-criteria traveling salesman problems (TSP). We provide algorithms for computing approximate <b>Pareto</b> <b>curves</b> for the symmetric TSP with triangle inequality (∆-STSP), symmetric and asymmetric TSP with strengthened triangle inequality (∆(γ) -STSP and ∆(γ) -ATSP), and symmetric and asymmetric TSP with weights one and two (STSP(1, 2) and ATSP(1, 2)). We design a deterministic polynomial-time algorithm that computes (1 + γ + ε) -approximate <b>Pareto</b> <b>curves</b> for multi-criteria ∆(γ) -STSP for γ ∈ [1, 1]. We also present two randomized approximation algo- 2 rithms for multi-criteria ∆(γ) -STSP achieving approximation ratios o...|$|R
40|$|Geophysical inverse {{problems}} typically {{involve a}} trade off between data misfit and some prior. <b>Pareto</b> <b>curves</b> trace the optimal trade off {{between these two}} competing aims. These curves are commonly used in problems with two-norm priors where they are plotted on a log-log scale and are known as L-curves. For other priors, such as the sparsity-promoting one norm, <b>Pareto</b> <b>curves</b> remain relatively unexplored. First, we show how these curves provide an objective criterion to gauge how robust one-norm solvers are when they are limited by a maximum number of matrix-vector products that they can perform. Second, we use <b>Pareto</b> <b>curves</b> and their properties to define and compute one-norm compressibilities. We argue this notion is key to understand one-norm regularized inversion. Third, we illustrate {{the correlation between the}} one-norm compressibility and the performance of Fourier and curvelet reconstructions with sparsity promoting inversion...|$|R
40|$|We present {{randomized}} approximation algorithms for multi-criteria traveling salesman problems (TSP), {{where some}} objective functions should be minimized while others should be maximized. For the symmetric multi-criteria TSP (STSP), we present an algorithm that computes (2 / 3 − ε, 4 + ε) approximate <b>Pareto</b> <b>curves.</b> Here, the first parameter is the approximation ratio for the objectives {{that should be}} maximized, and the second parameter is the ratio for the objectives that should be minimized. For the asymmetric multi-criteria TSP (ATSP), we present an algorithm that computes (1 / 2 − ε, log 2 n + ε) approximate <b>Pareto</b> <b>curves.</b> In order to obtain these results, we simplify the existing approximation algorithms for multicriteria Max-STSP and Max-ATSP. Finally, we give algorithms with improved ratios for some special cases...|$|R
40|$|Pareto {{efficiency}} {{is a widely}} used property in solution con-cepts for cooperative and non–cooperative game–theoretic settings and, more generally, in multi–objective problems. However, finding or even approximating (when the objective functions are not convex) the <b>Pareto</b> <b>curve</b> is hard. Most of the literature focuses on computing concise representations to approximate the <b>Pareto</b> <b>curve</b> or on exploiting evolution-ary approaches to generate approximately Pareto efficient samples of the curve. In this paper, we show that the <b>Pareto</b> <b>curve</b> of a bimatrix game can be found exactly in polyno-mial time {{and that it is}} composed of a polynomial number of pieces. Furthermore, each piece is a quadratic function. We use this result to provide algorithms for game-theoretic solution concepts that incorporate Pareto efficiency...|$|E
40|$|This study applies {{recent work}} on the approximability of multiobjective {{optimization}} problems to Internet services that provide dynamic, personalized web content. Changing environmental conditions can prompt such services to make tradeoffs along quality-of-service axes such as response time, throughput, and the "completeness" of the data provided. We propose an approach that uses approximation techniques to generate an &epsilon;-approximate <b>Pareto</b> <b>curve</b> that captures the tradeoffs between QoS objectives. Site designers can then use this approximate <b>Pareto</b> <b>curve</b> to identify the configurations that "best" fit certain environmental situations. We explore [...] ...|$|E
40|$|AbstractWe {{consider}} multiobjective scheduling problems, i. e. scheduling {{problems that}} are evaluated with respect to many cost criteria, and {{we are interested in}} determining a trade-off (<b>Pareto</b> <b>curve)</b> among these criteria. We study two types of bicriteria scheduling problems: single-machine batching problems and parallel machine scheduling problems. Instead of proceeding in a problem-by-problem basis, we identify a class of multiobjective optimization problems possessing a fully polynomial time approximation scheme (FPTAS) for computing an ε-approximate <b>Pareto</b> <b>curve.</b> This class contains a set of problems whose <b>Pareto</b> <b>curve</b> can be computed via a simple pseudo-polynomial dynamic program for which the objective and transition functions satisfy some, easy to verify, arithmetical conditions. Our study is based on a recent work of Woeginger (Electronic Colloquium on Computational Complexity, Report 84 (short version appeared in SODA’ 99, pp. 820 – 829)) for the single criteria optimization ex-benevolent problems. We show how our general result {{can be applied to the}} considered scheduling problems...|$|E
40|$|Abstract. We present {{randomized}} approximation algorithms for multicriteria traveling salesman problems (TSP), {{where some}} objective functions should be minimized while others should be maximized. For the symmetric multi-criteria TSP (STSP), we present an algorithm that computes (2 / 3 −ε, 4 +ε) approximate <b>Pareto</b> <b>curves.</b> Here, the first parameter is the approximation ratio for the objectives {{that should be}} maximized, and the second parameter is the ratio for the objectives that should be minimized. For the asymmetric multi-criteria TSP (ATSP), we present an algorithm that computes (1 / 2 − ε, log 2 n + ε) approximate <b>Pareto</b> <b>curves.</b> In order to obtain these results, we simplify the existing approximation algorithms for multi-criteria Max-STSP and Max-ATSP. Finally, we give algorithms with improved ratios for some special cases. 1 Multi-Criteria TSP 1. 1 Traveling Salesman Problems The traveling salesman problem (TSP) is a basic problem in combinatorial optimization...|$|R
30|$|To {{solve the}} model, we propose NSGA-II, NRGA, and MOPSO algorithms. The {{parameters}} of these algorithms are tuned by Taguchi method, and finally, six performance metrics {{are used to}} analyze the diversity and convergence of proposed algorithms. Based on MADM analysis of these metrics, we have shown that MOPSO has better metric performance to other algorithms and has better uniformity within the solutions of their <b>Pareto</b> <b>curves.</b>|$|R
3000|$|... as margins {{too wide}} may cause {{degenerate}} robustness/performance tradeoffs. Finally, if we analyze the <b>Pareto</b> optimal <b>curves</b> {{as a function}} of [...]...|$|R
40|$|International audienceThis work proposes an {{original}} approach using mutual information and <b>Pareto</b> <b>curve</b> jointly for feature selection. Mutual information {{is used to}} estimate dependency criterion between features and classes and redundancy criterion between features taken two by two. Unlike some studies, these criteria are used simultaneously to compute <b>Pareto</b> <b>curve</b> and determine the optimal feature sets. This approach is tested on more reference data. Several clustering algorithms are used to compute classification accuracy. The obtained results show the importance of our tools {{and its ability to}} select the best feature sets that give the better description...|$|E
40|$|We study {{stochastic}} two-player turn-based {{games in}} which the objective of one player is to ensure several infinite-horizon total reward objectives, while the other player attempts to spoil {{at least one of}} the objectives. The games have previously been shown not to be determined, and an approximation algorithm for computing a <b>Pareto</b> <b>curve</b> has been given. The major drawback of the existing algorithm is that it needs to compute Pareto curves for finite horizon objectives (for increasing length of the horizon), and the size of these Pareto curves can grow unboundedly, even when the infinite-horizon <b>Pareto</b> <b>curve</b> is small. By adapting existing results, we first give an algorithm that computes the <b>Pareto</b> <b>curve</b> for determined games. Then, as the main result of the paper, we show that for the natural class of stopping games and when there are two reward objectives, the problem of deciding whether a player can ensure satisfaction of the objectives with given thresholds is decidable. The result relies on an intricate and novel proof which shows that the Pareto curves contain only finitely many points. As a consequence, we get that the two-objective discounted-reward problem for unrestricted class of stochastic games is decidable...|$|E
40|$|We study {{problems}} in multiobjective optimization, in which solutions to a combinatorial optimization problem are evaluated {{with respect to}} several cost criteria, and {{we are interested in}} the trade-off between these objectives (the so-called <b>Pareto</b> <b>curve).</b> We point out that, under very general conditions, there is a polynomially succinct curve that -approximates the <b>Pareto</b> <b>curve,</b> for any > 0. We give a necessary and sucient condition under which this approximate <b>Pareto</b> <b>curve</b> can be constructed in time polynomial {{in the size of the}} instance and 1 =. In the case of multiple linear objectives, we distinguish between two cases: When the underlying feasible region is convex, then we show that approximating the multi-objective problem is equivalent to approximating the single-objective problem. If, however, the feasible region is discrete, then we point out that the question reduces to an old and recurrent one: How does the complexity of a combinatorial optimization problem change when its feasible region is intresected with a hyperplane with small coefficients; we report some interesting new ndings in this domain. Finally, we apply these concepts and techniques to formulate and solve approximately a cost-time-quality trade-off for optimizing access to the world-wide web, in a model first studied by Etzioni et al [EHJ+] (which was actually the original motivation for this work) ...|$|E
40|$|This paper {{addresses}} {{the problem of}} mapping an application, which is highly dynamic in the future, onto a heterogeneous multiprocessor platform in an energy efficient way. A two-phase scheduling method is used for that purpose. By exploring the <b>Pareto</b> <b>curves</b> and scenarios generated at design time, the run-time scheduler can easily find a good scheduling at a very low overhead, satisfying the system constraints and minimizing the energy consumption. A real-life example from a 3 D quality of service kernel is used to show the effectiveness of our method...|$|R
40|$|In {{a classic}} {{optimization}} problem the complete input data {{is known to}} the algorithm. This assumption {{may not be true}} anymore in optimization problems motivated by the Internet where part of the input data is private knowledge of independent selfish agents. The goal of algorithmic mechanism design is to provide (in polynomial time) a solution to the optimization problem and a set of incentives for the agents such that disclosing the input data is a dominant strategy for the agents. In case of NP-hard problems, the solution computed should also be a good approximation of the optimum. In this paper we focus on mechanism design for multi-objective optimization problems, where we are given the main objective function, and a set of secondary objectives which are modeled via budget constraints. Multi-objective optimization is a natural setting for mechanism design as many economical choices ask for a compromise between different, partially conflicting, goals. Our main contribution is showing that two of the main tools for the design of approximation algorithms for multi-objective optimization problems, namely approximate <b>Pareto</b> <b>curves</b> and Lagrangian relaxation, can lead to truthful approximation schemes. By exploiting the method of approximate <b>Pareto</b> <b>curves,</b> we devise truthful FPTASs for multi-objective optimization problems whose exact version admits a pseudo-polynomial-time algorithm, as for instance the multi-budgeted versions of minimum spanning tree...|$|R
40|$|The key {{challenge}} to improving {{performance in the}} age of Dark Silicon is how to leverage transistors when they cannot all be used at the same time. In modern SOCs, these transistors are often used to create specialized accelerators which improve energy efficiency for some applications by 10 - 1000 X. While this might seem like the magic bullet we need, for most CPU applications more energy is dissipated in the memory system than in the processor: these large gains in efficiency are only possible if the DRAM and memory hierarchy are mostly idle. We refer to this desirable state as Dark Memory, and it only occurs for applications with an extreme form of locality. To show our findings, we introduce <b>Pareto</b> <b>curves</b> in the energy/op and mm$^ 2 $/(ops/s) metric space for compute units, accelerators, and on-chip memory/interconnect. These <b>Pareto</b> <b>curves</b> allow us to solve the power, performance, area constrained optimization problem to determine which accelerators should be used, and how to set their design parameters to optimize the system. This analysis shows that memory accesses create a floor to the achievable energy-per-op. Thus high performance requires Dark Memory, which in turn requires co-design of the algorithm for parallelism and locality, with the hardware. Comment: 8 pages, To appear in IEEE Design and Test Journa...|$|R
40|$|We {{investigate}} {{the problem of}} computing a minimum set of solutions that approximates within a specified accuracy ǫ the <b>Pareto</b> <b>curve</b> of a multiobjective optimization problem. We show that for a broad class of bi-objective problems (containing many important widely studied problems such as shortest paths, spanning tree, and many others), we can compute in polynomial time an ǫ-Pareto set that contains at most twice as many solutions as the minimum such set. Furthermore we show that the factor of 2 is tight for these problems, i. e., it is NP-hard to do better. We present {{upper and lower bounds}} for three or more objectives, {{as well as for the}} dual problem of computing a specified number k of solutions which provide a good approximation to the <b>Pareto</b> <b>curve...</b>|$|E
40|$|We {{investigate}} {{the performance of}} exact algorithms for hard optimization problems under random inputs. In particular, we prove various structural properties that lead to two general average-case analyses applicable to a large class of optimization problems. In the first part we study {{the size of the}} <b>Pareto</b> <b>curve</b> for binary optimization problems with two objective functions. Pareto optimal solutions can be seen as trade-offs between multiple objectives. While in the worst case, the cardinality of the <b>Pareto</b> <b>curve</b> is exponential in the number of variables, we prove polynomial upper bounds for the expected number of Pareto points when at least one objective function is linear and exhibits sufficient randomness. Our analysis covers general probability distributions with finite mean and, in its most general form, can even handle different probability distributions for the coefficients of the objective function. We apply this result to the constrained shortest path problem and to the knapsack problem. There are algorithms for both problems that can enumerate all Pareto optimal solutions very efficiently, so that our polynomial upper bound {{on the size of the}} <b>Pareto</b> <b>curve</b> implies that the expected running time of these algorithms is polynomial as well. For example, we obtain a bound of O(n 4) for uniformly random knapsack instances, where n denotes the number of available items. In th...|$|E
40|$|This paper {{addresses}} tradeoffs between {{pressure sensitivity}} and electronic noise floor in optimizing {{the performance of}} a piezoresistive microphone. A design optimization problem is formulated to find the optimum dimensions of the diaphragm, the piezoresistor geometry and location for two objective functions: maximum pressure sensitivity and minimum electronic noise floor. The <b>Pareto</b> <b>curve</b> of optimum designs for both objectives is generated. The minimum detectable pressure (MDP) was also employed as an objective function, generating a point on the <b>Pareto</b> <b>curve</b> that may be the best compromise between the original two objectives. The results indicated that this application the critical constraints are the linearity and power consumption. The minimized MDP design was less sensitive to uncertainty in design variables. The optimization methodology presented in this paper {{as well as some of}} the conclusions are applicable to other types of piezoresistive sensors...|$|E
40|$|AbstractThe goal of {{this paper}} was to {{describe}} how to find optimal relations between water shortage and hydropower energy based on Risk and Reliability methods. Reservoir simulation model including water losses as well as risk (reliability) model of water demand has been built up. Using NSGA II optimization method the optimization of reservoir operation has been done. For problem solving was used Multi-Objective Optimization. This approach has been applied to a real-life water reservoir called Vir 1 in the Czech Republic. Results were presented in the form of <b>Pareto</b> <b>curves</b> and data sets of reservoir outflows...|$|R
40|$|A novel {{approach}} for performance estimation is described {{which gives the}} designer access to the design space boundaries of a circuit topology so that the tradeoff analysis of competing performances can be evaluated by optimum design points and <b>Pareto</b> <b>curves</b> with an acceptable execution time and transistor-level accuracy can be obtained. Recently, {{there is a strong}} emphasis on numerical techniques for performance estimation models however neither of them satisfies the following three significant issues; accuracy, time-consumption and topology-independent modeling. This new approach allows using different performance estimation methods together in order to speed up the overall design automation system with an acceptable time and accuracy for any given topology...|$|R
40|$|The goal of {{this paper}} was to {{describe}} how to find optimal relations between water shortage and hydropower energy based on Risk and Reliability methods. Reservoir simulation model including water losses as well as risk (reliability) model of water demand has been built up. Using NSGA II optimization method the optimization of reservoir operation has been done. For problem solving was used Multi-Objective Optimization. This approach has been applied to a real-life water reservoir called Vir 1 in the Czech Republic. Results were presented in the form of <b>Pareto</b> <b>curves</b> and data sets of reservoir outflows. This paper was supported by the project CZ. 1. 07 / 2. 3. 00 / 30. 003...|$|R
40|$|Restricted {{complexity}} controller {{design for}} the active suspension benchmark problem call for papers EJC special issue on Design and Optimisation of Restricted Complexity Controllers. Web site [URL] inpg. fr/, 2002 is considered. T he control design specifications of the benchmark is firstly recast intoamixed HI/l 1 optimisation problem, which is solved viaaconvex optimisation approach. A globally optimal <b>Pareto</b> <b>curve</b> is produced via the optimisation. It presents the limits of performance and is served asareference for restricted complexity controller design. Then, controllers with different complexity are designed viaadirect optimisation approach. The performance indices of these controllers are compared with the global <b>Pareto</b> <b>curve.</b> Based on the comparison, the controller with three parameters is determined as the one achieving acceptable performance with lowest complexity. Experimental results on the real system confirm the satisfactory performance achieved by the controller...|$|E
40|$|In this paper, we {{optimize}} the link dimensions of a robot with two serial arms for minimally-invasive surgery, {{to improve its}} kinetostatic performance (force, velocity) and its compactness, under the constraint of reachable space. A <b>Pareto</b> <b>curve</b> is plotted to provide the designer all the optimum possible solutions between transmissible velocity, forces, and compactness...|$|E
40|$|This paper {{proposes a}} compiler-in-the-loop {{exploration}} framework during architectural DSP synthesis. We extend the conventional design space, considering code level transformations together with architectural level optimizations {{and their impact}} on the scheduled datapath. We show that the proposed methodology explores the design space more globally in comparison with existing methods. New trade-off points are revealed and <b>Pareto</b> <b>curve</b> shifting toward...|$|E
40|$|In {{this paper}} we present the DeSiX design space {{exploration}} methodology for software component-based systems on multiprocessor architectures. The proposed technique adopts multi-dimensional quality attribute {{analysis in the}} early design phases {{and is based on}} (1) various types of models for software components, processing nodes, memories and bus links, (2) scenarios of system critical execution, allowing the designer to focus only on relevant static and dynamic system configurations, (3) simulation of tasks automatically reconstructed for each scenario and (4) <b>Pareto</b> <b>curves</b> for identification of optimal architecture alternatives. The feasibility of our methodology is shown by a detailed case study of a car radio navigation system, where te starting point is five candidate system architectures, representing different cost versus performance sensitivity versus reliability tradeoffs...|$|R
40|$|The {{exploration}} of the architectural design space in terms of energy and performance is of mainly importance for {{a broad range of}} embedded platforms based on the System-On-Chip approach. This paper proposes a methodology for the co-{{exploration of}} the design space composed of architectural parameters and source program transformations. A heuristic technique based on Pareto Simulated Annealing (PSA) has been used to efficiently span the multi-objective co-design space composed of the product of the parameters related to the selected program transformations and the configurable architecture. The analysis of the proposed framework has been carried out for a parameterized superscalar architecture executing a selected set of benchmarks. The reported results show the effectiveness of the proposed co-exploration with respect to the independent {{exploration of the}} transformation and architectural spaces to efficiently derive approximate <b>Pareto</b> <b>curves...</b>|$|R
40|$|Oxygen-blown biomass {{integrated}} gasification {{combined cycle}} (IGCC) plants {{are one of}} the most promising options for clean energy generation with CO 2 abatement potential. However, the integrated nature of IGCC leads to difficult design problems. In this study, we present an advanced simulation environment for the preliminary design and retrofit of IGCC plants. We describe the modelling approach, the model validation strategy and the plant behaviour, as determined by sensitivity analyses. The simulation environment uses <b>Pareto</b> <b>curves</b> to examine various co-gasification and co-production case studies in terms of technical, economic and environmental performance. It serves as a decision support tool in the design stage, which can be used to explore ways to improve plant performance and to analyse the influence of raw materials and the unit’s operational parameters. The test and validation results are discussed. Peer ReviewedPostprint (published version...|$|R
40|$|Abstract. We {{consider}} Markov decision processes (MDPs) with mul-tiple long-run average objectives. Such MDPs {{occur in}} design problems where {{one wishes to}} simultaneously optimize several criteria, for exam-ple, latency and power. The possible trade-offs between the different objectives are characterized by the <b>Pareto</b> <b>curve.</b> We show that every Pareto optimal point can be ε-approximated by a memoryless strategy, for all ε> 0. In contrast to the single-objective case, the memoryless strategy may require randomization. We show that the <b>Pareto</b> <b>curve</b> can be approximated (a) in polynomial time {{in the size of}} the MDP for irre-ducible MDPs; and (b) in polynomial space {{in the size of the}} MDP for all MDPs. Additionally, we study the problem if a given value vector is realizable by any strategy, and show that it can be decided in polyno-mial time for irreducible MDPs and in NP for all MDPs. These results provide algorithms for design exploration in MDP models with multiple long-run average objectives. ...|$|E
40|$|Due to low visibility, sewer {{systems are}} {{difficult}} to monitor, maintain and rehabilitate. To prevent failures, environmental pollution, and wastewater treatment overflow, regular rehabilitation of sewage is necessary. However, sewage rehabilitation usually costs an immense amount of money and is hampered by a limited budget. Thus, efficient planning of maintenance and rehabilitation for sewage upkeep is demanded. In this paper, an optimization model has been built to find an appropriate rehabilitation strategy consisting of a rehabilitation method and a substitute material for each pipe failure under a limited budget. The optimization model was designed {{to search for a}} <b>Pareto</b> <b>curve</b> (or trade-off front) consisting of a set of optimal solutions with desirable rehabilitation effectiveness at the least cost. This paper employs genetic algorithms (GA) to obtain a <b>Pareto</b> <b>curve</b> at a low computation cost for large and complex sewer systems. This optimization model was applied to a sewer system in the 15 (th) district of Kaohsiung City, Taiwan. Compared with the experts' manual estimation, the optimization model saved about 20 % of the rehabilitation cost for Kaohsiung City...|$|E
30|$|Monthly {{earnings}} {{are given in}} intervals. I take the midpoint of each interval except when individuals claim less than 500 euros (in which case I assign them the minimum monthly wage) and when they claim 3000 euros or more (in which case I assign them 4205 euros, which is the mean of a <b>Pareto</b> <b>curve</b> fitted to {{the upper end of}} the earnings distribution: Ligon 1994). On average there are 4.3 weeks per month.|$|E
40|$|Abstract. Designing {{architectures}} {{requires the}} balancing of multiple system quality objectives. In this paper, we present techniques {{that support the}} exploration of the quality properties of component-based architectures deployed on multiprocessor platforms. Special attention is paid to real-time properties and efficiency of resource use. The main steps of the process are (1) a simple way of modelling properties of software and hardware components, (2) from the component properties, a model of an execution architecture is composed and analyzed for system-level quality attributes, (3) for the composed system, selected execution scenarios are evaluated, (4) <b>Pareto</b> <b>curves</b> are used for making design trade-offs explicit. The process has been applied to several industrial systems. A Car Radio Navigation system is used to illustrate the method. For this system, we consider architectural alternatives, show their specification, and present their trade-off with respect to cost, performance and robustness. ...|$|R
40|$|A {{hierarchy}} of Lorenz curves {{based on the}} generalized Tukey's Lambda distribution is proposed. Representations of the corresponding distribution and density function are also provided, together with popular inequality measures. Estimation methods are suggested. Finally, a comparison with other parametric families of Lorenz curves is established. Generalized Tukey's Lambda distribution, Classical <b>Pareto</b> Lorenz <b>curve,</b> Gini index, Pietra index,...|$|R
40|$|A multi-objective {{evolutionary}} algorithm {{developed at the}} Laboratory of Industrial Energy Systems is {{used to determine the}} best technological solutions to satisfy the electrical needs of a remote community. Simulations of the community are based on a superstructure in which organic Rankine cycle, diesel engine, photovoltaic and other technology options (heat storage, cogeneration engine, cooling tower, parabolic through, [...] .) are included in the form of modules. These modules model the most significant factors: thermodynamic behaviour, economic trends, gaseous and noise emissions. An objective function including noise level, impact, and location is used to characterise the noise disturbance. Optimising such a superstructure along <b>Pareto</b> <b>curves</b> (optimal trade-off curve between the economic and noise objectives) while simultaneously accounting for time availability is performed by the {{evolutionary algorithm}}. Trends on the optimum power technologies as well as the relation to their geographical location are shown for different situations...|$|R
