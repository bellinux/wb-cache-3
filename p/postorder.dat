60|10|Public
5|$|Topological sorting is the {{algorithmic}} {{problem of}} finding a topological ordering of a given DAG. It can be solved in linear time. Kahn's algorithm for topological sorting builds the vertex ordering directly. It maintains a list of vertices that have no incoming edges from other vertices that have not already {{been included in the}} partially constructed topological ordering; initially this list consists of the vertices with no incoming edges at all. Then, it repeatedly adds one vertex from this list {{to the end of the}} partially constructed topological ordering, and checks whether its neighbors should be added to the list. The algorithm terminates when all vertices have been processed in this way. Alternatively, a topological ordering may be constructed by reversing a <b>postorder</b> numbering of a depth-first search graph traversal.|$|E
2500|$|The same proof idea holds more {{generally}} if u is any vertex, v is any vertex that is maximally far from u, and w is any neighbor of v that is maximally far from u. Further, {{the removal of}} v and w from the graph does not change {{any of the other}} distances from u. Therefore, the process of forming a matching by finding and removing pairs vw that are maximally far from u may be performed by a single <b>postorder</b> traversal of a breadth first search tree of the graph, rooted at u, in linear time. [...] provide an alternative linear-time algorithm based on depth-first search, as well as efficient parallel algorithms for the same problem.|$|E
5000|$|<b>Postorder</b> - This is {{a typical}} {{iteration}} order for backward data-flow problems. In <b>postorder</b> iteration, a node is visited after all its successor nodes have been visited. Typically, the <b>postorder</b> iteration is implemented with the depth-first strategy.|$|E
5000|$|A reverse <b>postordering</b> is {{the reverse}} of a <b>postordering,</b> i.e. {{a list of the}} {{vertices}} in the opposite order of their last visit. Reverse <b>postordering</b> {{is not the same as}} preordering. For example, when searching the directed graph in pre-order ...|$|R
5000|$|A <b>postordering</b> {{is a list}} of the {{vertices}} in {{the order}} that they were last visited by the algorithm. A <b>postordering</b> of an expression tree is the expression in reverse Polish notation.|$|R
5000|$|... {{beginning}} at node A, one visits the nodes in sequence, to produce lists either A B D B A C A, or A C D C A B A (depending upon whether the algorithm chooses to visit B or C first). Note that repeat visits {{in the form}} of backtracking to a node, to check if it has still unvisited neighbours, are included here (even if it is found to have none). Thus the possible preorderings are A B D C and A C D B (order by node's leftmost occurrence in above list), while the possible reverse postorderings are A C B D and A B C D (order by node's rightmost occurrence in above list). Reverse <b>postordering</b> produces a topological sorting of any directed acyclic graph. (Possible <b>postordering</b> are D B C A and D C B A.) This ordering is also useful in control flow analysis as it often represents a natural linearization of the control flows. The graph above might represent the flow of control in a code fragment like ...|$|R
50|$|Like any {{trees that}} can be traversed in {{preorder}} and <b>postorder,</b> the object corresponding to an XML element {{can be added to}} the parent object in preorder or <b>postorder.</b> In the preorder addition, the object is added to the parent before descendant XML elements get processed. In the <b>postorder</b> addition, the object is added to the parent after descendant XML elements get processed.|$|E
50|$|The postfix {{expression}} is {{formed by the}} basic <b>postorder</b> traversal of any binary tree. It does not require parentheses.|$|E
5000|$|Reverse <b>postorder</b> - This is {{a typical}} {{iteration}} order for forward data-flow problems. In reverse-postorder iteration, a node is visited before any of its successor nodes has been visited, except when the successor is reached by a back edge. (Note {{that this is not}} the same as preorder.) ...|$|E
40|$|This paper {{presents}} a novel word reordering model that employs a shift-reduce parser for inversion transduction grammars. Our model uses rich syntax parsing features for word re-ordering and runs in linear time. We {{apply it to}} <b>postordering</b> of phrase-based machine trans-lation (PBMT) for Japanese-to-English patent tasks. Our experimental results show that our method achieves a significant improvement of + 3. 1 BLEU scores against 30. 15 BLEU scores of the baseline PBMT system. ...|$|R
40|$|Reordering is a {{difficult}} task in translating between widely different languages such as Japanese and English. We employ the <b>postordering</b> framework proposed by (Sudoh et al., 2011 b) for Japanese to English translation and improve upon the reordering method. The existing post-ordering method reorders a sequence of target language words in a source language word order via SMT, while our method reorders the sequence by: 1) parsing the sequence to obtain syntax structures similar to a source language structure, and 2) transferring the obtained syntax structures into the syntax structures of the target language. ...|$|R
40|$|Abstract. This paper {{introduces}} {{a new model}} to describe the flow of data from update to frontal matrix in the unsymmetric multifrontal method for solving sparse linear systems. The model {{is based on the}} elimination tree of an unsymmetric matrix and consists of the edges in this tree together with some cross edges. By symmetrically renumbering the rows and columns of the coefficient matrix using a tree-based <b>postordering,</b> we can permute the matrix into a bordered block triangular form while preserving the elimination tree. The model simplifies when the matrix has this form, which suggests that a multifrontal implementation based on it should be simpler as well. We also extend the model to handle pivoting for stability; compare it with others used in the unsymmetric multifrontal method; and point out the implications for parallelism...|$|R
5000|$|Instruction {{selection}} is typically {{carried out by}} doing a recursive <b>postorder</b> traversal on the abstract syntax tree, matching particular tree configurations against templates; for example, the tree [...] might {{be transformed into a}} linear sequence of instructions by recursively generating the sequences for [...] and , and then emitting the instruction [...]|$|E
50|$|The Kleene-Brouwer order generalizes {{the notion}} of a <b>postorder</b> {{traversal}} from finite trees to trees that are not necessarily finite. For trees over a well-ordered set, the Kleene-Brouwer order is itself a well-ordering if and only if the tree has no infinite branch. It is named after Stephen Cole Kleene, Luitzen Egbertus Jan Brouwer, Nikolai Luzin, and Wacław Sierpiński.|$|E
50|$|A tree, in {{descriptive}} set theory, {{is defined}} as a set of finite sequences that is closed under prefix operations. The parent in the tree of any sequence is the shorter sequence formed by removing its final element. Thus, any set of finite sequences can be augmented to form a tree, and the Kleene-Brouwer order is a natural ordering that may be given to this tree. It is a generalization to potentially-infinite trees of the <b>postorder</b> traversal of a finite tree: at every node of the tree, the child subtrees are given their left to right ordering, and the node itself comes after all its children. The fact that the Kleene-Brouwer order is a linear ordering (that is, that it is transitive as well as being total) follows immediately from this, as any three sequences on which transitivity is to be tested form (with their prefixes) a finite tree on which the Kleene-Brouwer order coincides with the <b>postorder.</b>|$|E
40|$|Semiseparable {{matrices}} {{and many}} other rank-structured matrices {{have been widely used}} in developing new fast matrix algorithms. In this paper, we generalize the hierarchically semiseparable (HSS) matrix representations and propose some fast algorithms for HSS matrices. We represent HSS matrices in terms of general binary HSS trees and use simplified <b>postordering</b> notation for HSS forms. Fast HSS algorithms including new HSS structure generation and HSS form Cholesky factorization are developed. Moreover, we provide a new linear complexity explicit ULV factorization algorithm for symmetric positive definite HSS matrices with a low-rank property. The corresponding factors can be used to solve the HSS systems also in linear complexity. Numerical examples demonstrate the efficiency of the algorithms. All these algorithms have nice data locality. They are useful in developing fast-structured numerical methods for large discretized PDEs (such as elliptic equations), integral equations, eigenvalue problems, etc. Som...|$|R
40|$|PDSLin is a {{general-purpose}} algebraic {{parallel hybrid}} (direct/iterative) linear solver {{based on the}} Schur complement method. The most challenging step of the solver is the computation of a preconditioner based on an approximate global Schur complement. We investigate two combinatorial problems to enhance PDSLin’s performance at this step. The first is a multiconstraint partitioning problem to balance the workload while computing the preconditioner in parallel. For this, we describe and evaluate a number of graph and hypergraph partitioning algorithms to satisfy our particular objective and constraints. The second problem is to reorder the sparse right-hand side vectors to improve the data access locality during the parallel solution of a sparse triangular system with multiple right-hand sides. This is {{to speed up the}} process of eliminating the unknowns associated with the interface. We study two reordering techniques: one based on a <b>postordering</b> of the elimination tree and the other based on a hypergraph partitioning. To demonstrate the e↵ect of these techniques on the performance of PDSLin, we present the numerical results of solving large-scale linear systems arising from two applications of our interest: numerical simulations of modeling accelerator cavities and of modeling fusion devices. ...|$|R
40|$|Institut National Polytechnique de Toulouse, RT-APO- 12 - 2 PDSLin is a {{general-purpose}} algebraic {{parallel hybrid}} (direct/iterative) linear solver {{based on the}} Schur complement method. The most challenging step of the solver is the computation of a preconditioner based on an approximate global Schur complement. We investigate two combinatorial problems to enhance PDSLin's performance at this step. The first is a multi-constraint partitioning problem to balance the workload while computing the preconditioner in parallel. For this, we describe and evaluate a number of graph and hypergraph partitioning algorithms to satisfy our particular objective and constraints. The second problem is to reorder the sparse right-hand side vectors to improve the data access locality during the parallel solution of a sparse triangular system with multiple right-hand sides. This is {{to speed up the}} process of eliminating the unknowns associated with the interface. We study two reordering techniques: one based on a <b>postordering</b> of the elimination tree and the other based on a hypergraph partitioning. To demonstrate the effect of these techniques on the performance of PDSLin, we present the numerical results of solving large-scale linear systems arising from two applications of our interest: numerical simulations of modeling accelerator cavities and of modeling fusion devices...|$|R
5000|$|The same proof idea holds more {{generally}} if u is any vertex, v is any vertex that is maximally far from u, and w is any neighbor of v that is maximally far from u. Further, {{the removal of}} v and w from the graph does not change {{any of the other}} distances from u. Therefore, the process of forming a matching by finding and removing pairs vw that are maximally far from u may be performed by a single <b>postorder</b> traversal of a breadth first search tree of the graph, rooted at u, in linear time. [...] provide an alternative linear-time algorithm based on depth-first search, as well as efficient parallel algorithms for the same problem.|$|E
50|$|Topological sorting is the {{algorithmic}} {{problem of}} finding a topological ordering of a given DAG. It can be solved in linear time. Kahn's algorithm for topological sorting builds the vertex ordering directly. It maintains a list of vertices that have no incoming edges from other vertices that have not already {{been included in the}} partially constructed topological ordering; initially this list consists of the vertices with no incoming edges at all. Then, it repeatedly adds one vertex from this list {{to the end of the}} partially constructed topological ordering, and checks whether its neighbors should be added to the list. The algorithm terminates when all vertices have been processed in this way. Alternatively, a topological ordering may be constructed by reversing a <b>postorder</b> numbering of a depth-first search graph traversal.|$|E
50|$|Vertex {{addition}} methods work {{by maintaining}} a data structure representing the possible embeddings of an induced subgraph of the given graph, and adding vertices {{one at a}} time to this data structure. These methods began with an inefficient O(n2) method conceived by Lempel, Even and Cederbaum in 1967. It was improved by Even and Tarjan, who found a linear-time solution for the s,t-numbering step, and by Booth and Lueker, who developed the PQ tree data structure. With these improvements it is linear-time and outperforms the path addition method in practice. This method was also extended to allow a planar embedding (drawing) to be efficiently computed for a planar graph. In 1999, Shih and Hsu simplified these methods using the PC tree (an unrooted variant of the PQ tree) and a <b>postorder</b> traversal of the depth-first search tree of the vertices.|$|E
40|$|In {{this paper}} we improve, reprove, and simplify several theorems on the {{performance}} of data structures based on path compression and search trees. We apply a technique very familiar to computational geometers but still foreign to many researchers in (non-geometric) algorithms and data structures, namely, to bound the complexity of an object via its forbidden substructures. To analyze an algorithm or data structure in the forbidden substructure framework one proceeds in three discrete steps. First, one transcribes the behavior of the algorithm as some combinatorial object M; for example, M may be a graph, sequence, permutation, matrix, set system, or tree. (The size of M should ideally be linear in the running time.) Second, one shows that M excludes some forbidden substructure P, and third, one bounds the size of any object avoiding this substructure. The power of this framework derives from the fact that M lies in a more pristine environment and that upper bounds on the size of a P-free object M may be reused in different contexts. Among our results, we present the first asymptotically sharp bound on the length of arbitrary path compressions on arbitrary trees, improving analyses of Tarjan [35] and Seidel and Sharir [31]. We reprove the linear bound on <b>postordered</b> path compressions, due to Lucas [23] and Loebel and Ne˘set˘ril [22], the linear bound on deque-ordered path compressions, due to Buchsbaum, Sundar, and Tarjan [5], and the sequential access theorem for splay trees, originally due to Tarjan [38]. We disprove a conjecture of Aronov et al. [3] related to the efficiency of their data structure for half-plane proximity queries and provide a significantly cleaner analysis of their structure. With the exception of the sequential access theorem, all our proofs are exceptionally simple. Notably absent are calculations of any kind...|$|R
40|$|We {{investigate}} the rearrangement of the Haar system {{induced by the}} <b>postorder</b> {{on the set of}} dyadic intervals in [0, 1] with length {{greater than or equal to}} 2 ^-N. By means of operator norms on BMO_N we prove that the <b>postorder</b> has maximal distance to the usual lexicographic order. Comment: 21 pages, To appear in Quarterly Journ. Mat...|$|E
40|$|Binary tree {{traversal}} {{refers to}} the process of visiting each node in a specified order. Given the inorder traversal of a binary tree, along with one of its preorder or <b>postorder</b> traversals, the original binary tree can be uniquely identified. Many recursive and non recursive method of construction of the tree from inorder and any of the <b>postorder</b> or preorder traversal have been proposed. In this paper one of the proposed algorithms has been examined. This algorithm computes the wrong tree for some input sequences. We show a particular situation in which the algorithm fails and a solution for this situation is proposed. The proposed a modified non-recursive algorithm for reconstructing a binary tree which generates the correct tree otherwise an error has been reported...|$|E
40|$|Abstract. To use the {{information}} on the web pages effectively, one of the methods is to annotate them to meet with ontology. This paper focuses on the technology of extracting relation triplets automatically by traversing dependency parse tree of a sentence in <b>postorder</b> manner, to build ontology from plain texts. ...|$|E
40|$|Given a set Y of {{decreasing}} plane {{trees and}} a permutation π, how many trees in Y have π as their <b>postorder?</b> Using combinatorial and geometric constructions, we provide a method for answering this question for certain sets Y and all permutations π. We then provide applications of our results {{to the study of}} the deterministic stack-sorting algorithm. Comment: 15 pages, 4 figure...|$|E
40|$|Abstract Given the {{preorder}} traversal {{of a tree}} {{together with}} some additional structure information, the tree can be constructed in linear time with a simple algorithm. The additional information may be the inorder or <b>postorder</b> traversal. In one case, the binary search tree, no additional information is required. We also show how to transform the construction algorithm into a non-recursive algorithm requiring only constant space...|$|E
40|$|ABSTRACT This paper {{presents}} a unified approach to parsing, in which top-down, bottomup and left-corner parsers {{are related to}} preorder, <b>postorder</b> and inorder tree traversals. It is shown that the simplest bottom-up and left-corner parsers are left recursive and must be converted using an extended Greibach normal form. With further partial execution, the bottom-up and left-corner parsers collapse together as in the BUP parser of Matsumoto...|$|E
40|$|We {{build upon}} the {{previous}} {{work on the}} subset of permutations known as stack words and stack-sortable words. We use preorder, inorder and <b>postorder</b> traversals of binary trees to establish multiple bijections between binary trees and these words. We show these operators satisfy a sort of multiplicative cancellation. We further expand the study of these operators by demonstrating how properties on trees are related to properties on words. ...|$|E
40|$|We {{consider}} the following problem. For a binary tree T = (V; E) where V = f 1; 2; :::; ng, given its inorder traversal and either its preorder or its <b>postorder</b> traversal, reconstruct the binary tree. We present a new parallel algorithm for this problem. Our algorithm requires O(n) space. The main idea of our algorithm {{is to reduce the}} reconstruction process to merging two sorted sequences. With the best parallel merging algorithms, our algorithm can be implemented in O(log log n) time using O(n log log n) processors on the CREW PRAM (or in O(log n) time using O(n log n) processors on the EREW PRAM). Our result provides one more example of a fundamental problem which can be solved by optimal parallel algorithms in O(log log n) time on the CREW PRAM. 1 Introduction We {{consider the}} problem of reconstructing a binary tree T = (V; E) with vertices f 1; 2; :::; ng given its inorder traversal and either its preorder or its <b>postorder</b> traversal. It is well-known that a binary tree can [...] ...|$|E
40|$|This paper {{presents}} a unified approach to parsing, in which top-down, bottom-up and left-corner parsers {{are related to}} preorder, <b>postorder</b> and inorder tree traversals. It is shown that the simplest bottom-up and left-corner parsers are left recursive and must be converted using an extended Greibach normal form. With further partial execution, the bottom-up and left-corner parsers collapse together as in the BUP parser of Matsumoto. Comment: COLING 94 paper, Postscript, compressed and uuencode...|$|E
40|$|The stack-size {{of a tree}} T is {{the number}} of cells of a stack needed to {{traverse}} T in <b>postorder.</b> In this paper we show that the average number of proper subtrees having the same stack-size as the whole tree is asymptotically 1 with a variance of 2 +o(1). The total number of subtrees with a stack-size one less than that of the whole tree is identical to 2. Counting only maximal subtrees changes this number to 1 + o(1) with a variance of o(1) ...|$|E
40|$|Colloque avec actes et comité de lecture. internationale. International audienceThis paper {{describes}} an efficient parallel implementation of our previously published LU factorization method for sparse matrices. The main achievement is {{the usage of}} a message-passing paradigm instead of the already implemented shared-memory solver. A necessary presentation of the theoretical context is included first, then we briefly show the symbolic factorization steps (build LU elimination forest, <b>postorder</b> traversal, supernode identification) and the numerical factorization steps (Factor and Update steps and algorithm). The experiments were run on an SGI Origin 2000 multiprocessor with 64 nodes...|$|E
40|$|In {{this paper}} we present {{techniques}} {{that result in}} O(n) time algorithms for computing many properties and functions of an n-node forest stored in an n×n mesh of processors. Our algorithms include computing simple properties like the depth, the height, the number of descendents, the preorder (resp. <b>postorder,</b> inorder) number of every node, and {{a solution to the}} more complex problem of computing the Minimax value of a game tree. Our algorithms are asymptotically optimal since any nontrivial computation will require Ω(n) time on the mesh. All of our algorithms generalize to higher dimensional meshes...|$|E
40|$|An {{efficient}} {{computational method}} is presented for state space analysis of singular systems via Haar wavelets. Singular systems {{are those in}} which dynamics are governed {{by a combination of}} algebraic and differential equations. The corresponding differential-algebraic matrix equation is converted to a generalized Sylvester matrix equation by using Haar wavelet basis. First, an explicit expression for the inverse of the Haar matrix is presented. Then, using it, we propose a combined preorder and <b>postorder</b> traversal algorithm to solve the generalized Sylvester matrix equation. Finally, the efficiency of the proposed method is discussed by a numerical example...|$|E
40|$|In many {{applications}} the desired outcome of satisfiability checking {{is that the}} formula is unsatisfiable: A satisfying assignment essentially exhibits a bug and unsatisfiability implies a lack of bugs, {{at least for the}} property being verified. Current high-performance satisfiability checkers are unable to provide proof of unsatisfiability. Since bugs have been discovered in many solvers long after being put into service, an uncheckable decision poses a significant problem if important economic or safety decisions are to be based upon it. Current tableau-based systems that are able to produce proofs are unable to process propositional formulas of practical size. This paper describes modifications of the classical backtracking-search satisfiability algorithm of Davis, Putnam, Loveland and Logemann (DPLL) that are designed to extract checkable proofs of practical length when the formula is believed to be unsatisfiable. It is known that the purely <b>postorder</b> resolution proofs extractable from standard DPLL (called “tree resolution ” proofs) are exponentially longer than nontree proofs in the worst case. Experience also shows them to be of impractical length. This paper describes an efficient method to integrate <b>postorder</b> resolution with preorder reasoning methods, including binary-clause reasoning, equivalent-literal identification, and variableelimination resolution, to produce nontree proofs. Preliminary experiments show that the resulting proofs are much shorter, but that memory has to be managed extremely carefully and the time is usually longer compared to the best “complete ” programs that do not produce proofs. ...|$|E
