5|50|Public
2500|$|... tvOS {{ships with}} all-new {{development}} tools for developers. tvOS adds {{support for an}} all-new SDK for developers to build apps for the TV including all of the APIs included in iOS 9 such as Metal. It also adds an App Store which allows users to browse, download, and install {{a wide variety of}} applications. In addition, developers can now use their own interface inside of their application rather than only being able to use Apple's interface. Since tvOS is based on iOS, it is easy to port existing iOS apps to the Apple TV with Xcode while making only a few refinements to the app to better suit the larger screen. Apple provides Xcode free of charge to all registered Apple developers. To develop for the new Apple TV, it is necessary to make a <b>parallax</b> <b>image</b> for the application icon. In order to do this, Apple provides a Parallax exporter and previewer in the development tools for the Apple TV.|$|E
40|$|This thesis {{presents}} an image based falling snow rendering method {{which is based}} on spectral synthesis technique. By incorporating the natural falling snow motion property, that is, the image speed and size of the snowflakes are related to the depth, we develop a tent-like surface in frequency domain. We synthesize the power spectrum along the tent-like surface and use IFFT to bring the data function back to space-time domain, thus attain a motion <b>parallax</b> <b>image</b> sequence. Treating the motion parallax as an opacity function, we can composite it with an existing video sequence {{and turn it into a}} snowing scene. Treating the motion parallax as a stimulus for the psychophysical study, it could serve as a complex yet natural scene-like stimulus, and therefore being expected to give a new perspective to the psychophysical study...|$|E
40|$|The {{resolution}} of the <b>parallax</b> <b>image</b> is inversely proportional to the view number in the horizontal direction for the traditional autostereoscopic display based on a parallax barrier. To balance the resolution in the verti-cal and horizontal directions, two parallax interleaved barriers are designed. The {{liquid crystal display panel}} provides the synthetic image with square pixel units, and the pixels in a unit are distributed to different horizontal views. Two parallax interleaved barriers work together to modulate pixels in vertical and horizontal directions. 3 D display with uniform resolution and low crosstalk is demonstrated. OCIS codes: 100. 0100, 100. 6890. doi: 10. 3788 /COL 201412. 121001. A great progress has been made for glasses-free 3 D display and several techniques were demonstrated[1 – 7]. A parallax barrier based 3 D display is a low-cost method to provide multi-views to the observers[8 – 10]. Many meth-ods can be used for changing the pixels ’ arrangement to decrease the aliasing in the boundary[11 – 13]. However, the non-uniform of the vertical and horizontal resolution...|$|E
5000|$|In October 2010, Toshiba {{unveiled}} the Toshiba Regza GL1 21" [...] LED backlit LCD TV glasses-free 3D prototype at CEATEC 2010. This system supports 3D capability without glasses (utilising an integral imaging system of 9 <b>parallax</b> <b>images</b> with vertical lenticular sheet). The retail product {{was released in}} December 2010.|$|R
40|$|Stereoscopic {{scenes of}} the mankind is {{naturally}} caused by synthesizing two images produced by the parallax of the two eyes of human. Such being the case, mankind can distinguish the relative position of the objects. In the study of related stereovision, some persons aim at the framework of taking simulated images with two eyes using one or two cameras from front and back or simultaneously {{at the same time}} to obtain a pair of parallax mages; someone pay more attention to the theoretical analysis of the relative positions of the <b>parallax</b> <b>images,</b> and some others do the work of using <b>parallax</b> <b>images</b> as material to carry out the job of image classification, comparison and analysis. The purpose of this paper is to estimate the distance between the objects and the camera in an outdoor environment using commercial digital camera. Key words: computer vision, machine vision, stereoscopic, object depth, binocular disparity, depth perception. 1...|$|R
40|$|The step barrier {{technology}} with multiple <b>parallax</b> <b>images</b> has overcome {{the problem of}} conventional parallax barrier system that the image quality of each image deteriorates only in the horizontal direction. The step barrier distributes the resolution problem both to the horizontal and the vertical directions. The system has a simple structure, which consists of a flat-panel display and a step barrier. The apertures of the step barrier are not stripes but tiny rectangles that are arranged {{in the shape of}} stairs, and the sub-pixels of each image have the same arrangement. And three image processes for the system applicable to computer graphics and real image have been proposed. Then, two types of 3 -D displays were developed, 22 -inch model and 50 -inch model. The 22 -inch model employs a very high-definition liquid crystal display of 3840 x 2400 pixels. The number of <b>parallax</b> <b>images</b> is seven and the resolution of one image is 1646 x 800. The 50 -inch model has four viewing points on the plasma display panel of 1280 x 768 pixels. It can provide stereoscopic animations and the resolution of one image is 960 x 256 pixels. Moreover, the structural or electric 2 -D 3 -D compatible system was developed...|$|R
40|$|The typical {{method for}} {{rendering}} falling snow in computer graphics {{is to use}} particle systems. Particle systems can be computationally expensive, however, since each snowflake is modelled. Here we introduce a new, less expensive method for rendering falling snow. The method {{is based on a}} global Fourier transform. It extends a well-known model in visual perception of motion that a pure translational image motion produces a plane of energy in the 3 D frequency domain. We extend this translational image motion model to the case of motion parallax such as occurs in a falling snow image sequence. Specifically the 2 D image speed and the size of each moving snowflake depends on its depth in 3 D because of standard perspective effects. We show that this depth vs. speed vs. size relationship leads to a non-planar motion surface in the 3 D frequency domain. By synthesizing such a surface in the frequency domain and taking the inverse Fourier transform, we obtain a motion <b>parallax</b> <b>image</b> sequence which has the appearance of falling snow. We treat this image sequence as an opacity function and use it to composite white falling snow over a single image frame. This creates visual effect that snow is falling within the scene. 1...|$|E
5000|$|The 35mm MOE Prime lenses are PL-mount {{compatible}} lenses {{that allow}} cinematographers to capture <b>parallax</b> scanned <b>images</b> on 35mm film or {{in a digital}} cinema format (4K).|$|R
40|$|Two {{well-known}} {{problems of}} stereoscopic displays are the accommodation-convergence {{conflict and the}} lack of natural blur for defocused objects. We present a new technique that we name Super Stereoscopy (SS 3 D) to provide a convenient solution to these problems. Regular stereoscopic glasses are replaced by SS 3 D glasses which deliver at least two <b>parallax</b> <b>images</b> per eye through pinholes equipped with light selective filters. The pinholes generate blur-free retinal images so as to enable correct accommodation, while the delivery of multiple <b>parallax</b> <b>images</b> per eye creates an approximate blur effect for defocused objects. Experiments performed with cameras and human viewers indicate that the technique works as desired. In case two, pinholes equipped with color filters per eye are used; the technique can be used on a regular stereoscopic display by only uploading a new content, without requiring any change in display hardware, driver, or frame rate. Apart from some tolerable loss in display brightness and decrease in natural spatial resolution limit of the eye because of pinholes, the technique is quite promising for comfortable and realistic 3 D vision, especially enabling the display of close objects that are not possible to display and comfortably view on regular 3 DTV and cinema. © 2014 Optical Society of America OCIS codes: (330. 1400) Vision- binocular and stereopsis; (330. 7322) Visual optics, accommodation; (120. 2040...|$|R
40|$|International audienceThe human {{vision system}} has visual {{functions}} for viewing 3 D images with a correct depth. These functions are called accommodation, vergence and binocular stereopsis. Most 3 D display system utilizes binocular stereopsis. We {{have developed a}} monocular 3 D vision system with accommodation mechanism, which is useful function for perceiving depth. This vision unit needs an image shift optics for generating monocular <b>parallax</b> <b>images.</b> But conventional image shift mechanism is heavy because of its linear actuator. To improve this problem, we developed a light-weight 3 D vision unit for presenting monocular stereoscopic images using a polypyrrole linear actuator...|$|R
40|$|Abstract — The human {{vision system}} has visual {{functions}} for viewing 3 D images with a correct depth. These functions are called accommodation, vergence and binocular stereopsis. Most 3 D display system utilizes binocular stereopsis. The authors {{have developed a}} monocular 3 D vision system with accommodation mechanism, which is useful function for perceiving depth. This vision unit needs an image shift optics for generating monocular <b>parallax</b> <b>images.</b> But conventional image shift mechanism is heavy because of its linear actuator system. To improve this problem, we developed a light-weight 3 D vision unit for presenting monocular stereoscopic images using a polypyrrole linear actuator. Index Terms—head mounted display, monocular stereoscopic display, real-time stereogram, 3 -D display I...|$|R
30|$|Overlapping {{sections}} of the aerial photographs were carefully trimmed out in order to minimise <b>image</b> <b>parallax,</b> using <b>image</b> subsetting procedures within ERDAS. In order to optimise {{the contrast between the}} light and dark tones, contrast on each trimmed image was enhanced by spreading the digital number (DN) values on the full grey level scale range using a linear stretch. After separately mapping the woody cover on the respective aerial photographs from a given analysis year and study site, using image classification, the photographs were joined into thematic layer mosaics. All the images were carefully examined for presence of burn scars whose dark tone could have introduced error in mapping woody cover. Consequently the 1940 photographs of the Nhlowa site were excluded from the analysis due to extensive burn scars.|$|R
40|$|Satellite jitter (SJ) is an {{important}} error source that affects the geometric accuracy of high resolution satellite imagery. In this paper, the quantitative relationship between the jitter displacement (image displacement caused by SJ) and relative registration error obtained from <b>parallax</b> <b>images</b> is deduced to be theoretical in detail, and the jitter displacement estimation model is built to estimate the jitter displacement. Then, a simulation experiment is carried out to validate the feasibility of using the built jitter displacement estimation model to estimate the jitter displacement. Finally, experiments with real images in DengFeng (China) including multispectral images of Ziyuan- 3 (ZY- 3) satellite and high resolution (HR) images of Ziyuan 1 - 02 C (ZY 1 - 02 C) satellite are used to validate the effectiveness of utilizing the built jitter displacement estimation model to do the jitter estimation. High accuracy ground reference data are further {{used to evaluate the}} accuracy of the estimation. Experimental results show that the average estimated error for jitter displacement of ZY- 3 is 2. 96 % and 0. 11 % in amplitude and frequency respectively, and the estimated error for jitter displacement of ZY 1 - 02 C is 8. 46 % and 0. 35 % in amplitude and frequency, respectively...|$|R
50|$|The images must {{be clear}} and usually have scales. They serve {{to not only}} remind {{investigators}} of the scene, but also to provide a tangible image for the court to better enable them to understand what happened. The use of several views taken from different angles helps to minimise the problem of <b>parallax.</b> Overall <b>images</b> do not have scales and serve to show the general layout, such as {{the house where the}} murder is thought to have occurred. Context images show evidence in context, like how the knife was next to the sofa. Close up images show fine detail of an artifact, such as a bloody fingerprint on the knife.|$|R
50|$|Even after gain {{compensation}} some image {{edges are}} still visible {{due to a}} number of unmodelledeffects, such as vignetting (intensity decreases towards the edge of the <b>image),</b> <b>parallax</b> effects due to unwanted motion of the optical centre, mis-registration errors due to mismodellingof the camera, radial distortion and so on. Due to these reasons they propose a blending strategy called multi band blending.|$|R
50|$|Eventually, {{several other}} inventors, {{including}} Ives' son Herbert, substituted {{an array of}} narrow cylindrical lenses for the simple parallax barrier and incorporated more than two viewpoints, creating lenticular <b>parallax</b> panoramagram 3-D <b>images</b> of the type most familiar from 3-D postcards, trading cards and similar novelties, often confused with holograms. The original parallax barrier method is currently (2017) employed in several no-glasses 3-D video displays.|$|R
40|$|Abstract. Integral Imaging is {{a highly}} {{promising}} technique for delivering full <b>parallax</b> autostereoscopic <b>images.</b> A straight-forward approach for producing high quality photorealistic Integral Images or Integral Image sequences {{is the use of}} Ray-Tracing techniques. However, Ray-Tracing tasks are time consuming and in most cases scene renderings greatly deviate from performing in real time. In this work, we describe an Integral Image specific benchmarking procedure that allows accurate rendering performance evaluation of different parts of the Ray-Tracing process. A correlation based method is used to characterize the Integral Image complexity and finally calculate its actual complexity. Moreover, a number of issues are exposed that should be taken into account in realtime Integral Imaging applications...|$|R
40|$|Satellite {{observations}} of the optical emission features in the aurora and nighttime airglow are usually contaminated by scattering from clouds and snow. It is shown here that this contamination can easily be removed when the emission layer is viewed against a surface of known albedo. The effect of the earth's curvature, <b>parallax,</b> and varying <b>image</b> angle {{are found to be}} significant but can be removed from the observation...|$|R
30|$|The {{determination}} of an <b>image</b> <b>parallax</b> range is obtained through an associated depth map. There {{are several ways}} to obtain a depth map from a stereo image, depending on the computation complexity and accuracy restrictions. As a rule of thumb, it can be stated that complexity is proportional to accuracy, thus, low complexity algorithms such as sum of absolute differences (SAD) can perform well under certain circumstances, as stated in [25, 26]. Scharstein and Szeliski [27] described the procedures to define the Middlebury Database [28], which offers the most complete stereoscopic algorithms benchmark to date, and software to evaluate new algorithms to predict <b>image</b> <b>parallax.</b> SAD-based algorithms are among the least complex and more often used. Census-based algorithms [29 – 32], first introduced in [33], are common in real-time hardware-based systems [34 – 38] and may work better in the homogeneous zones of the image. Its complexity increases when used in software-based systems because of its bit-based nature. Some systems mix both algorithms in order to obtain the best results from each one of them, such as [39], ranked in second place in the Scharstein and Szeliski list, or [40] based on dense stereo matching.|$|R
40|$|This paper {{presents}} a qualitative area-based matching algorithm applied in CCD-CBERS 2 stereopairs images. For achieving this aim, {{it is necessary}} to study the best template size in terms of processing time and number of false match points. Besides, an epipolar resampling in stereopairs images (without using sensor orientation parameters) is proposed for reducing the <b>parallax</b> between the <b>images</b> and ambiguities in automatic stereo matching. Results show that correlation scores range from 0. 76 to 0. 95. Pages: 815 - 82...|$|R
40|$|MRF) –based {{method for}} close-range terrain with large terrain variations, a {{constrained}} dynamic programming method for terrain {{in the far}} range, and a parallax-curve–based method for general terrain. The first two methods are an improvement over the last one, which represents the terrain as a smoothed parallax curve {{and is based on}} assumptions of interest points, epipolar-line constraint, uniqueness in matched pairs, non-increasing <b>parallax,</b> and stereo <b>images</b> of natural terrain acquired by ground vehicles such as a robotic rover. The first method deals with a terrain type that can not be modeled by a curve-based method because of a large terrain variation. It represents the terrain as a MRF and allows for multiple matched pairs of interest points. It then uses Markov Chain Monte Carlo (MCMC) to sample the matched pairs in the X-Y-parallax space and achieves a global-minimization of energy that will correspond to the desired terrain surface. The second method is used for far-range terrain in which both registration accuracy and density of interest points are not high enough to restore terrain details. It uses dynamic programming in a vertical direction to match vertical lines from the left image with the right image. A strong constraint is applied to ensure a non-increasing <b>parallax</b> from <b>image</b> top to image bottom. These techniques are used in the Mars Exploration Rover 2003 mission to match stereo rover images. The matched points are used as tie points to link rover images for rover localization or used for generation of map products such as digital elevation models and orthomaps...|$|R
40|$|Influenced {{by large}} {{elevation}} variation, traditional ortho stereo image production method for complex terrain regions usually results in insufficient local stereoscopic or diplopia, and thus causes visual fatigue. In order {{to solve the}} problem, we introduce a depth mapping model, design a nonlinear mapping function, {{and according to the}} actual area elevations, adaptive preprocess height transformation. And then, through iterative and per-pixel solution with <b>parallax</b> function, stereo <b>images</b> are finally generated. Finally, we provide an algorithm or a process which can adaptive fast generate stereoscopic images...|$|R
40|$|We {{show that}} the {{parallax}} motion resulting from non-nodal rotation in panorama capture can be exploited for light field construction from commodity hardware. Automated panoramic image capture typically seeks to rotate a camera exactly about its nodal point, for which no parallax motion is observed. This can be difficult or impossible to achieve due to limitations of the mounting or optical systems, and consequently {{a wide range of}} captured panoramas suffer from <b>parallax</b> between <b>images.</b> We show that by capturing such imagery over a regular grid of camera poses, then appropriately transforming the captured imagery to a common parameterisation, a light field can be constructed. The resulting four-dimensional image encodes scene geometry as well as texture, allowing an increasingly rich range of light field processing techniques to be applied. Employing an Ocular Robotics REV 25 camera pointing system, we demonstrate light field capture,refocusing and low-light image enhancement...|$|R
50|$|The {{technique}} is principally used when film or video material is not available. Action {{is given to}} still photographs by slowly zooming in on subjects of interest and panning from one subject to another. For example, in {{a photograph of a}} baseball team, one might slowly pan across the faces of the players and come to a rest on the player the narrator is discussing. By employing simulated <b>parallax,</b> a two-dimensional <b>image</b> can appear as 3D, with the viewpoint seeming to enter the picture and move among the figures.|$|R
40|$|Abstract. The “zograscope ” is a “visual aid ” (commonly {{known as}} “optical machine ” in the 18 th century) invented in the mid- 18 th century, {{and in general}} use until the early 20 th century. It was {{intended}} to view single pictures (thus not stereographic pairs) with both eyes. The optics approximately eliminates the physiological cues (binocular disparity, vergence, accommodation, movement <b>parallax,</b> and <b>image</b> blur) that might indicate the flatness of the picture surface. The spatial structure of pictorial space {{is due to the}} remaining pictorial cues. As a consequence, many (or perhaps most) observers are aware of a heightened “plasticity ” of the pictorial content for zograscopic as compared with natural viewing. We discuss the optics of the zograscope in some detail. Such an analysis is not available in the literature, whereas common “explanations ” of the apparatus are evidently nonsensical. We constructed a zograscope, using modern parts, and present psychophysical data on its performance...|$|R
40|$|This paper {{describes}} {{the development of}} a novel gauging computer vision system for murine non-melanoma skin cancer tumours volume imaging. The system utilized binocular stereovision, enhanced through the use of telecentric lenses. These lenses optically compromised for the distortion factors and provided orthographic projection, leading to <b>parallax</b> free <b>image</b> acquisition. In order to improve the resolution of the system, a structured light projector, with 450 nm dominant wavelength, was used to illuminate the target with a custom pattern. Robust image processing algorithms granted accurate segmentation, feature recognition, labeling and correlation between the stereo pairs. Under these premises, the well-known ""matching"" problem was resolved successfully and geometrical interpolation provided an accurate three-dimensional reconstruction of the tumour volume. Through back-projection of the calibration object the resolution of the system was calculated up to 0. 04 mm. The system was applied to measure the induced geometrical alterations of the tumour after PDT by using the Fosgel photosensitizer, excited by a laser diode emitting at 652 nm. The measurement of the volume induced alterations after each PDT treatment and up to the final tumour shrinkage is critical, to compare PDT efficacy between different protocols. © 2007 SPIE-OSA...|$|R
50|$|Crosstalk is the {{interference}} {{that exists between}} {{the left and right}} views in a 3D display. In a display with high crosstalk, each eye is able to see the image intended for the other eye faintly superimposed.The perception of crosstalk in stereoscopic displays has been studied widely. It is generally acknowledged that the presence of high levels of crosstalk in a stereoscopic display is detrimental. The effects of crosstalk in an image include: ghosting and loss of contrast, loss of 3D effect and depth resolution, and viewer discomfort.The visibility of crosstalk (ghosting) increases with increasing contrast and increasing binocular <b>parallax</b> of the <b>image.</b> For example, a stereoscopic image with high contrast will exhibit more ghosting on a particular stereoscopic display than will an image with low contrast.|$|R
40|$|AbstractThis paper {{proposes a}} {{real-time}} HD stereo images rectification hardware design architecture {{in order to}} remove vertical <b>parallax</b> of <b>images</b> caused by distortion within the cameras and alignment between them. After calculating calibration parameters of images using Matlab Toolbox designed by J. Y Bouguet as a prior step for the above purpose, the researcher designed rectification hardware based on the algorithms of Heikkilä and Silven. When stereo cameras are installed, it becomes difficult to find corresponding points owing to geometric errors between the cameras. However, in case corresponding points {{are located in the}} same line in two images, corresponding points can be found only in the line and therefore calculation becomes simple and errors are reduced. The line where the corresponding points are situated is called an epipolar line. In order to make the lines become an epipolar line, geometric image transformation technique called rectification should be used. Here, in order to heighten precision of result images, the researcher employed a floating point calculator generated using a core generator of Xilinx. Through this, it was verified that rectification hardware which has higher precision than other rectification hardware designed using a look-up table and which operates on a real-time basis may be designed...|$|R
40|$|Photogrammetry is {{a science}} which obtains {{reliable}} measurements by a means of pho-tographs, {{and it can be}} aerial or terrestrial. This study is done in KTH main Campus on L building located at Drottning Kristinas väg 30. It assessed the precision of Trim-ble total station S 8 for photogrammetric point measurement relative to the coordi-nates measured with a total station. The steps performed in the study were: planning the measurements (selection of the study area, selection of the instruments, selection of the station points, selection of the software and putting the target points over the facade), data acquisition and finally data processing in TBC software. In the work, sys-tematic error tests were carried out, and the tests results show that there are systematic errors in easting and northing of the measurement result, however it was difficult to say there is or there is no systematic error in the elevation. The most likely source of these errors might be an incorrect orientation of the camera. It was seen that there were some factors influenced the precision of photogrammetric point measurements, such as <b>image</b> redundancy and <b>parallax</b> angle between <b>images.</b> The precision assess-ment was done by calculating photogrammetric points; from different <b>parallax</b> angles between <b>images</b> and from different numbers of images which were taken from differ-ent station points. The better results or smaller differences between the total station and photogrammetric coordinates were detected from five station points relative to four and three station points and from parallax angle in range 60 - 105 degree relative to parallax angles in range 30 - 60 and 0 - 30 degrees. In general, precise photogrammet-ric coordinates were obtained from parallax angle in range 60 - 105 degree and from five station points. Keywords: Photogrammetry; precision; station points, checkpoints, Trimble total sta-tion, Trible Business Center...|$|R
40|$|We have {{developed}} a fully operational PET demonstrator setup which allows true 3 D reconstruction of the 511 keV photons and therefore leads to practically <b>parallax</b> free <b>images.</b> The AX-PET concept is based on thin 100 mm long scintillation crystals (LYSO), axially oriented and arranged in layers around the held of view. Layers of wavelength shifting plastic strips mounted in between the crystal layers give the axial coordinate. Both crystals and WLS strips are individually read out by G-APD (SiPM) photodetectors. The Fully scalable concept overcomes the dilemma of sensitivity versus spatial resolution which is inherent to classical PET designs. A demonstrator set-up based on two axial modules was exhaustively characterized using point-like sources, phantoms filled with radiotracer and finally rats and a mouse. The results entirely meet the performance expectations (< 2 mm FWHM in all three coordinates over the complete held of view) and also demonstrated the ability to include Compton interactions (inter-crystal scatter) in the reconstruction without noticeable performance loss. Our recent studies focus on a TOF extension of the AX-PET concept making use of the novel digital SiPM detectors by Philips. After reproducing comparable energy and spatial resolution on a small digital AX-PET set-up with 100 mm long crystals, we demonstrated a coincidence resolving time of about 210 ps FWHM. (C) 2013 Elsevier B. V. All rights reserved...|$|R
40|$|A robust {{approach}} for joint motion and disparity estimation in stereo sequences to synthesize arbitrary intermediate views is presented. The improved concept for stereo image analysis {{is based on}} a modified block matching algorithm. In which a cost function consisting of area-based correlation together with an appropriately weighted temporal smoothness term is applied. A confidence measure to evaluate the reliability of estimated correspondences is introduced. In occluded image areas and image points with unreliable motion or disparity assignments, considerable improvements are obtained applying an edge-assisted vector interpolation strategy. Two different image synthesis concepts are presented as well. The reported approach is verified by processing a set of sequences taken with stereo cameras having large interaxial distances. Computer simulations show that telepresence illusion with continuous motion <b>parallax</b> and good <b>image</b> quality can be obtained using the methods presented...|$|R
50|$|Founded by Peter Kang and Gene Na in 1999, one of Kioken’s early {{websites}} {{was for the}} R & B singer Brandy, and {{a string}} of entertainment clients followed, most notably including Jennifer Lopez, Motown, and Bad Boy Records. Criticized by some for a lack of usability, contrary to popular opinion, Kioken was resolute in its belief that audiences raised in the video game era were practiced in deciphering interfaces — in fact, they took pleasure in the experience. Taking their cue from TV and video games, Kioken’s websites had a depth and emotional quality absent from their counterparts. Full-bleed <b>images,</b> <b>parallax</b> movement, and floating palettes were used with great effect, all coming together beautifully on Barneys.com. According to Na, it's simple: “You have to think beyond the limits of a page.” Built in Flash 4.|$|R
40|$|International audienceThe {{creation}} of novel views using pre-stored images or image-based rendering has many potential applications, such as visual simulation, virtual reality and telepresence, for which traditional computer graphics based on geometric modeling would be unsatisfactory particularly with very complex 3 D scenes. This paper presents a new image-based rendering system that tackles {{the two most}} difficults problems of image-based modeling: pixel matching and visibility handling. We first introduce the joint view triangulation (JVT), a novel representation for pairs of images that handles the visibility and occlusion problems created by the <b>parallaxes</b> between the <b>images.</b> The joint view triangulation is build from matched planar patches regularized by local smooth constraints encoded by plane homographies. Then, we introduce an incremental edge-constrained construction algorithm. Finally, we present a pseudo-painter's rendering algorithm for the joint view triangulation and demonstrate the performance of these methods experimentally...|$|R
40|$|The {{creation}} of novel views using prestored images or image-based rendering has many potential applications, such as visual simulation, virtual reality, and telepresence, for which traditional computer graphics based on geometric modeling would be unsatisfactory particularly with very complex three-dimensional scenes. This paper presents a new image-based rendering system that tackles {{the two most}} difficult problems of image-based modeling: pixel matching and visibility handling. We first introduce the joint view triangulation (JVT), a novel representation for pairs of images that handles the visibility and occlusion problems created by the <b>parallaxes</b> between the <b>images.</b> The JVT is built from matched planar patches regularized by local smooth constraints encoded by plane homographies. Then, we introduce an incremental edge-constrained construction algorithm. Finally, we present a pseudo-painter's rendering algorithm for the JVT and demonstrate the performance of these methods experimentally...|$|R
5000|$|E. fasciata is {{a highly}} {{successful}} ambush predator. In the course of evolution, it has specialized in preying on fast flying insects, such as flies and bees. One reason for this preference may be that flying insects serve as nutritious food, which {{is important in the}} spring when there is a limited food supply. Adult females often perch on flowers, where they wait to prey on honeybees. Insect prey can be captured upon landing, or even during flight, due to the fast strike of E. fasciata and its ability to rotate its head and the two powerful raptorial forelegs more than 90° laterally, without moving the rest of its body. E. fasciata shows no evidence of being cannibalistic. Distinct rocking and jerking movements are executed, which not only serve as camouflage in moving vegetation, but also facilitate spatial vision with the aid of motion <b>parallax</b> or retinal <b>image</b> displacement.|$|R
40|$|Figure 1 : Parallax {{barriers}} and holograms are {{two forms of}} view-dependent display that are typically considered under distinct physical interpretations, but actually consist of similar underlying features. (left) A <b>parallax</b> barrier <b>image</b> comprised of different discrete tiles of angular content (center-bottom) are usually explained by treating light as a ray. By illuminating one discrete patch of a hologram {{at a time and}} recording the resulting images (center-top), we describe a hologram in light field terminologies commonly applied to parallax displays. In this paper, we develop a framework to explain these similarities and then apply it to the creation of novel display forms. In this paper we explore how light propagates from thin elements into a volume for viewing. In particular, devices that are typi-cally connected with geometric optics, like parallax barriers, differ in treatment with those that obey physical optics, like holograms. However, the two concepts are often used to achieve the same effect of capturing or displaying a combination of spatial and angular in-formation. This paper attempts to connect the two approaches under a general framework based in ray space, from which insights into applications and limitations of both parallax-based and holography-based systems can be observed. We show that each display form can generate a light distribution that can always be expressed as a rank- 1 matrix. Knowledge of this limitation is then discussed in the context of extending the capabilities of current display forms by considering the use of partially coherent light. ...|$|R
