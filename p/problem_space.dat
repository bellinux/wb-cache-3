1397|4264|Public
25|$|The {{remainder}} of this article will use the more common colour terminology and refer to monochromatic cliques. Note that owing to the symmetrical nature of the <b>problem</b> <b>space,</b> R(r, s) is equal to R(s, r).|$|E
25|$|Particle swarm {{optimization}} {{is another}} algorithm widely used {{to solve problems}} related to swarms. It was developed in 1995 by Kennedy and Eberhart and was first aimed at simulating the social behaviour and choreography of bird flocks and fish schools. The algorithm was simplified and it was observed to be performing optimization. The system initially seeds a population with random solutions. It then searches in the <b>problem</b> <b>space</b> through successive generations using stochastic optimization {{to find the best}} solutions. The solutions it finds are called particles. Each particle stores its position as well as the best solution it has achieved so far. The particle swarm optimizer tracks the best local value obtained so far by any particle in the local neighbourhood. The remaining particles then move through the <b>problem</b> <b>space</b> following the lead of the optimum particles. At each time iteration, the particle swarm optimiser accelerates each particle toward its optimum locations according to simple mathematical rules. Particle swarm optimization has been applied in many areas. It has few parameters to adjust, and a version that works well for a specific applications can also work well with minor modifications across a range of related applications. A book by Kennedy and Eberhart describes some philosophical aspects of particle swarm optimization applications and swarm intelligence. An extensive survey of applications is made by Poli.|$|E
25|$|Unsupervised {{learning}} {{is the ability}} to find patterns in a stream of input. Supervised learning includes both classification and numerical regression. Classification is used to determine what category something belongs in, after seeing a number of examples of things from several categories. Regression is the attempt to produce a function that describes the relationship between inputs and outputs and predicts how the outputs should change as the inputs change. In reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent uses this sequence of rewards and punishments to form a strategy for operating in its <b>problem</b> <b>space.</b> These three types of learning can be analyzed in terms of decision theory, using concepts like utility. The mathematical analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory.|$|E
40|$|The {{particle}} swarm algorithm {{has shown}} ability to optimise in continuous <b>problem</b> <b>spaces,</b> {{although it can}} struggle in <b>problem</b> <b>spaces</b> containing multiple optima. A variant, called Waves of Swarm Particles (WoSP), {{has been shown to}} be able to handle <b>problem</b> <b>spaces</b> containing multiple optima by sequentially exploring these optima. In this chapter, the WoSP algorithm is adapted to suit complex quantised <b>problem</b> <b>spaces</b> and applied to a highly constrained problem with many constraint-violating solutions but few constraint-satisfying solutions. The performance obtained is remarkably good and reflects the power of the WoSP algorithm, which combines the search abilities of particle swarm with that of evolution...|$|R
5000|$|Computationally Expensive: While {{certainly}} more feasible than some exhaustive approaches, LCS algorithms can be computationally expensive. For simple, linear learning problems {{there is no}} need to apply an LCS. LCS algorithms are best suited to complex <b>problem</b> <b>spaces,</b> or <b>problem</b> <b>spaces</b> in which little prior knowledge exists.|$|R
5000|$|... #Caption: The {{suspected}} {{relationship of}} BQP to other <b>problem</b> <b>spaces</b> ...|$|R
2500|$|Rabinow {{identifies}} “the contemporary” as {{a temporal}} and ontological <b>problem</b> <b>space.</b> In Marking Time (2007) he distinguishes two senses {{of the term}} contemporary. First, to be contemporary is to exist {{at the same time}} as something else. This meaning has temporal but no historical connotations. The second sense, however, carries both temporal and historical connotations, and it is this meaning that figures in Rabinow’s work. Rabinow takes up the contemporary as a “moving ratio.” Just as “the modern” can be thought of as a moving ratio of tradition and modernity, so the contemporary “is a moving ratio of modernity, moving through the recent past and near future in a (non-linear) space.” ...|$|E
50|$|In {{the seventh}} step, a {{subsumption}} mechanism is typically applied. Subsumption is an explicit generalization mechanism that merges classifiers that cover redundant {{parts of the}} <b>problem</b> <b>space.</b> The subsuming classifier effectively absorbs the subsumed classifier (and has its numerosity increased). This can only happen when the subsuming classifier is more general, just as accurate, and covers all of the <b>problem</b> <b>space</b> of the classifier it subsumes.|$|E
5000|$|... move current (often insoluble) {{problems}} into another, {{more helpful}} and more productive <b>problem</b> <b>space</b> (e.g.: functional fixedness); ...|$|E
40|$|Many of {{our results}} in the {{problem-solving}} literature are from puzzle-game domains. Intuitively, most of us feel that {{there are differences between}} puzzle problems and open-ended, real-world problems. There has been some attempt to capture these differences in the vocabulary of "ill-structured " and "well-structured" problems. However, there seem to be no empirical studies directed at this distinction. This paper examines and compares the task environments and <b>problem</b> <b>spaces</b> of a prototypical well-structured problem (cryptarithmetic) with the task environments and <b>problem</b> <b>spaces</b> of a class of prototypical ill-structured problems (design problems). Results indicate substantive differences, both in the task environments and the <b>problem</b> <b>spaces...</b>|$|R
50|$|By design, {{templates}} can {{be utilized}} in very complex <b>problem</b> <b>spaces,</b> whereas macros are substantially more limited.|$|R
5000|$|Exploring {{possibilities}} and constraints by focusing {{critical thinking skills}} to research and define <b>problem</b> <b>spaces</b> for existing products or services—or {{the creation of new}} categories; (see also Brainstorming) ...|$|R
50|$|The {{original}} {{theory of}} cognition underlying Soar is the <b>Problem</b> <b>Space</b> Hypothesis, which {{is described in}} Allen Newell's book, Unified Theories of Cognition. and dates back {{to one of the}} first AI systems created, Newell, Simon, and Shaw's Logic Theorist, first presented in 1955. The <b>Problem</b> <b>Space</b> Hypothesis contends that all goal-oriented behavior can be cast as search through a space of possible states (a <b>problem</b> <b>space)</b> while attempting to achieve a goal. At each step, a single operator is selected, and then applied to the agent’s current state, which can lead to internal changes, such as retrieval of knowledge from long-term memory or modifications or external actions in the world. (Soar’s name is derived from this basic cycle of State, Operator, And Result; however, it is no longer regarded as an acronym.) Inherent to the <b>Problem</b> <b>Space</b> Hypothesis is that all behavior, even a complex activity such as planning, is decomposable into a sequence of selection and application of primitive operators, which when mapped onto human behavior take ~50ms.|$|E
5000|$|... dPN {{modeling}} {{of a new}} process system starts {{at a high level}} of hierarchical abstraction. To design a complex process system, such as a sophisticated hardware component or a major project, the process architect must first define the <b>problem</b> <b>space.</b> Since the <b>problem</b> <b>space</b> is itself a process system, dPNs can be used for its modeling. Abstract dPNs that are yet to be implemented are specified {{within the context of the}} <b>problem</b> <b>space.</b> These constructs define the solution space within its context network. It is now up to the process architect to traverse down the hierarchical abstraction dimension, proposing new process designs for the solution space in an iterative manner until specifying the actual implementation in the specific implementation language.|$|E
5000|$|... form a question, {{the answer}} to which will divide the <b>problem</b> <b>space</b> into two subspaces of about equal size; ...|$|E
30|$|Even though {{numerous}} palm pose can {{be captured}} and acquired from motion sensing devices, {{there are still}} some theoretically interesting <b>problems,</b> <b>space</b> registration, sensor data filtering, and dynamic response.|$|R
40|$|We {{compared}} entrepreneurs with bankers {{in their}} perception {{and management of}} a variety of risks. Problems included financial risk, risk to human life and health, and risk of a natural disaster. Cluster analysis and content analysis of think-aloud protocols revealed surprising details. Entrepreneurs accept risk as given and focus on controlling the outcomes at any given level of risk; they also frame their <b>problem</b> <b>spaces</b> with personal values and assume greater personal responsibility for the outcomes. Bankers focus on target outcomes — attempting to control risk within structured <b>problem</b> <b>spaces</b> and avoiding situations where they risk higher levels of personal responsibility...|$|R
40|$|We have {{recently}} reported several human/computer discoveries in biology, chemistry and physics that {{have appeared in}} domain science journals. One may ask what accounts for these findings, e. g., whether they share a common pattern. My conclusion is that each finding involves a new representation of the scientific task: the <b>problem</b> <b>spaces</b> searched were unlike previous task <b>problem</b> <b>spaces.</b> Such new representations need not be wholly new {{to the history of}} science; rather, they can draw on useful representational pieces from elsewhere in natural or computer science. This account contrasts with earlier explanations of machine discovery based on the expert-systems view. My analysis also suggests a broader potential role for (AI) computer scientists in the practice of natural science...|$|R
50|$|A {{decision}} boundary is {{the region of}} a <b>problem</b> <b>space</b> in which the output label of a classifier is ambiguous.|$|E
5000|$|He {{also thought}} it would be a fun problem to solve, as a {{solution}} would have many parts and the <b>problem</b> <b>space</b> was quite open-ended.|$|E
5000|$|Formulation: formulates the <b>problem</b> <b>space,</b> by {{transforming}} requirements into {{a function}} state space (R → F), and transforming functions into a behaviour state space (F → Be).|$|E
40|$|Measuring the {{interaction}} between agents and institutions poses a number of challenges. The paper provides data and results from a project in political science aimed at representing the <b>problem</b> <b>spaces</b> described by organization members in depicting decision situations {{with high levels of}} procedural uncertainty...|$|R
30|$|The {{technical}} {{choices for}} the programming language and libraries are described in this section. Genetic algorithms (GA) are a widely used subfamily of EAs, which are stochastic search methods designed for exploring complex <b>problem</b> <b>spaces</b> {{in order to find}} optimal solutions using minimal information on the problem to guide the search.|$|R
40|$|AbstractThe paper {{describes}} a semantic framework for languages used in defining non-deterministic search of <b>problem</b> <b>spaces.</b> The chosen formalism is production system formalism. Semantics is discussed from an operational viewpoint, {{taking into account}} the role of control strategies, and from a denotational viewpoint. Comparisons between operational and denotational semantics are developed...|$|R
5000|$|Divergence - Exploring {{possibilities}} and constraints of inherited situations by applying critical thinking through {{qualitative and quantitative}} research methods to create new understanding (<b>problem</b> <b>space)</b> toward better design solutions ...|$|E
5000|$|Initialization：Initialize {{the private}} {{knowledge}} point [...] {{in the memory}} of each agent , and all knowledge points in the social sharing library , normally at random in the <b>problem</b> <b>space</b> [...]|$|E
5000|$|Let [...] be {{a global}} {{optimization}} problem, where [...] {{is a state}} in the <b>problem</b> <b>space</b> [...] In SCO, each state is called a knowledge point, and the function [...] is the goodness function.|$|E
40|$|Soar is {{a theory}} of {{cognition}} embodied in a computer system. In 1987 it {{was used as the}} central exemplar {{to make the case that}} cognitive science should attempt unified theories of cognition (UTC) [13] 1. Since then, much research has been done to move Soar toward being a real UTC, rather than just an exemplar. Figure 1 lists the relevant studies 2. They have been done by a broad community of researchers in the pursuit of a multiplicity of interests. This symposium presents four of these studies to convey the current state of Soar as a UTC (their names are marked with asterisks in the figure). This short paper provides additional breadth and context. THE SOAR ARCHITECTURE We review here the basic structure of the Soar architecture, which has been described in detail elsewhere [8, 13, 20]. Soar formulates all tasks in <b>problem</b> <b>spaces,</b> in which operators are selectively applied to the current state to attain desired states. <b>Problem</b> <b>spaces</b> appear as triangles in Figure 2 (which describes a Soar system for comprehending natural language). Problem solving proceeds in a sequence of decision cycles that select <b>problem</b> <b>spaces,</b> states, and operators. Each decision cycle accumulates knowledge from a long term recognition memory (realized as a production system). This memory continually matches against working memory, elaborating the current state and retrieving preferences that encode knowledge about th...|$|R
50|$|Grünbaum, A., 1963, Philosophical <b>Problems</b> of <b>Space</b> and Time. Chpt. 3.|$|R
5000|$|Soar {{does not}} include a clear representation-based or process-based {{difference}} between implicit and explicit cognition, or between procedural and declarative memory; {{it is based on}} the ideas of <b>problem</b> <b>spaces,</b> states, and operators. When there is an outstanding goal on the goal stack, different productions propose different operators and operator preferences for accomplishing the goal.|$|R
50|$|The {{remainder}} of this article will use the more common colour terminology and refer to monochromatic cliques. Note that owing to the symmetrical nature of the <b>problem</b> <b>space,</b> R(r, s) is equal to R(s, r).|$|E
50|$|The CoreASM {{language}} emphasizes {{freedom of}} experimentation, and supports the evolutionary nature of design {{as a product}} of creativity. It is particularly suited to Exploring the <b>problem</b> <b>space</b> for the purpose of writing an initial specification. The CoreASM language allows writing of highly abstract and concise specifications by minimizing the need for encoding in mapping the <b>problem</b> <b>space</b> to a formal model, and by allowing explicit declaration of the parts of the specification that are purposely left abstract. The principle of minimality, in combination with robustness of the underlying mathematical framework, improves modifiability of specifications, while effectively supporting the highly iterative nature of specification and design.|$|E
50|$|Executable UML {{also allows}} for {{translation}} of platform-independent models (PIM) into platform-specific models (PSM). The Executable UML method enables valuing the model as intellectual property, since the model is a fully executable solution for the <b>problem</b> <b>space.</b>|$|E
5000|$|Philosophical <b>Problems</b> of <b>Space</b> and Time (first edition, 1963; second edition, 1973) ...|$|R
30|$|In this paper, {{motivated}} by {{these problems and}} results for the <b>problems</b> in Hilbert <b>spaces,</b> we consider the split common null point <b>problem</b> in Banach <b>spaces.</b> Then using the hybrid method and the shrinking projection method in mathematical programming, we prove two strong convergence theorems for finding a solution of the split common null point <b>problem</b> in Banach <b>spaces.</b>|$|R
40|$|Domain experts {{should provide}} {{relevant}} domain knowledge to an Intelligent Tutoring System (ITS) {{so that it}} can assist a learner during problem-solving activities. There are three main approaches for providing such knowledge. The first one is cognitive task analysis that aims at producing effective <b>problem</b> <b>spaces</b> or task models by observing expert and novice users [1] t...|$|R
