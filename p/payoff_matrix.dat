407|114|Public
5|$|There are {{numerous}} applications of matrices, both {{in mathematics and}} other sciences. Some of them merely {{take advantage of the}} compact representation of a set of numbers in a matrix. For example, in game theory and economics, the <b>payoff</b> <b>matrix</b> encodes the payoff for two players, depending on which out of a given (finite) set of alternatives the players choose. Text mining and automated thesaurus compilation makes use of document-term matrices such as tf-idf to track frequencies of certain words in several documents.|$|E
25|$|The {{coordination}} game is {{a classic}} (symmetric) two player, two strategy game, with an example <b>payoff</b> <b>matrix</b> shown to the right. The players should thus coordinate, both adopting strategy A, to receive the highest payoff; i.e., 4. If both players chose strategy B though, {{there is still a}} Nash equilibrium. Although each player is awarded less than optimal payoff, neither player has incentive to change strategy due to a reduction in the immediate payoff (from 2 to 1).|$|E
25|$|If {{this game}} is a {{coordination}} game, then the following inequalities hold in the <b>payoff</b> <b>matrix</b> for player 1 (rows): A>B,D>C, and for player 2 (columns): a>c,d>b. See Fig. 1. In this game the strategy profiles {Left,Up} and {Right,Down} are pure Nash equilibria, marked in gray. This setup can be extended {{for more than two}} strategies (strategies are usually sorted so that the Nash equilibria are in the diagonal from top left to bottom right), as well as for a game with more than two players.|$|E
40|$|For a ﬁnite, well-mixed {{population}} of heterogeneous agents playing evolutionary games choosing to cooperate or defect in each {{round of the}} game, we investigate, when agents update their strategies in each round using the myopic best-response rule, how the number of cooperating agents changes over time and demonstrate how to control that number by changing the agents’ <b>payoff</b> <b>matrices.</b> The agents are heterogeneous in that their <b>payoff</b> <b>matrices</b> may differ from one another; {{we focus on the}} speciﬁc case when the <b>payoff</b> <b>matrices,</b> ﬁxed throughout the evolution, correspond to prisoner’s dilemma or snowdrift games. To carry out stability analysis, we identify the system’s absorbing states when taking the number of cooperating agents as a random variable of interest. It is proven that when all the agents update frequently enough, the reachable ﬁnal states are completely determined by the available types of <b>payoff</b> <b>matrices.</b> As a further step, we show how to control the ﬁnal state by changing {{at the beginning of the}} evolution, the types of the <b>payoff</b> <b>matrices</b> of a group of agents...|$|R
30|$|In this paper, a {{new concept}} of bifuzzy bi-matrix game is {{introduced}} where all elements of the <b>payoff</b> <b>matrices</b> are characterized by bifuzzy variables. The uncertainties of entries of <b>payoff</b> <b>matrices</b> (bifuzzy variables) are measured by bifuzzy measure known as Chance measure. Combining the bifuzzy set theory and bi-matrix game theory, the solution concept of bifuzzy bi-matrix game theory is introduced. The quadratic programming problem plays the major role to solve bifuzzy bi-matrix game. In order to show the applicability and feasibility of our proposed method, a real-life bi-matrix game problem is considered and solved.|$|R
50|$|Unlike {{sequential}} games, simultaneous games do {{not have}} a time axis as players choose their moves without being sure of the other's, and are usually represented in the form of <b>payoff</b> <b>matrices.</b>|$|R
25|$|A typical {{case for}} a {{coordination}} game is choosing {{the sides of the}} road upon which to drive, a social standard which can save lives if it is widely adhered to. In a simplified example, assume that two drivers meet on a narrow dirt road. Both have to swerve in order to avoid a head-on collision. If both execute the same swerving maneuver they will manage to pass each other, but if they choose differing maneuvers they will collide. In the <b>payoff</b> <b>matrix</b> in Fig. 2, successful passing is represented by a payoff of 10, and a collision by a payoff of 0.|$|E
25|$|There {{is an easy}} {{numerical}} way {{to identify}} Nash equilibria on a <b>payoff</b> <b>matrix.</b> It is especially helpful in two-person games where players have more than two strategies. In this case formal analysis may become too long. This rule {{does not apply to}} the case where mixed (stochastic) strategies are of interest. The rule goes as follows: if the first payoff number, in the payoff pair of the cell, is the maximum of the column of the cell and if the second number is the maximum of the row of the cell - then the cell represents a Nash equilibrium.|$|E
25|$|Coordination {{games are}} {{closely linked to}} the {{economic}} concept of externalities, and in particular positive network externalities, the benefit reaped from being in the same network as other agents. Conversely, game theorists have modeled behavior under negative externalities where choosing the same action creates a cost rather than a benefit. The generic term for this class of game is anti-coordination game. The best-known example of a 2-player anti-coordination game is the game of Chicken (also known as Hawk-Dove game). Using the <b>payoff</b> <b>matrix</b> in Figure 1, a game is an anti-coordination game if Bnbsp&>nbsp&A and Cnbsp&>nbsp&D for row-player 1 (with lowercase analogues b > d and c > a for column-player 2). {Down, Left} and {Up, Right} are the two pure Nash equilibria. Chicken also requires that Anbsp&>nbsp&C, so a change from {Up, Left} to {Up, Right} improves player 2's payoff but reduces player 1's payoff, introducing conflict. This counters the standard coordination game setup, where all unilateral changes in a strategy lead to either mutual gain or mutual loss.|$|E
40|$|Each of n players, in an {{infinitely}} repeated game, {{starts with}} subjective beliefs about his opponents' strategies. If the individual beliefs {{are compatible with}} the true strategies chose, then Bayesian updating will lead {{in the long run}} to accurate prediction of the future of play of the game. It follows that individual players, who know their own <b>payoff</b> <b>matrices</b> and choose strategies to maximize their expected utility, must eventually play according to a Nash equilibrium of the repeated game. An immediate corollary is that, when playing a Harsanyi-Nash equilibrium of a repeated game of incomplete information about opponents' <b>payoff</b> <b>matrices,</b> players will eventually play a Nash equilibrium of the real game, as if they had complete information. ...|$|R
40|$|This {{teaching}} case {{focuses on}} the application of decision tools to assist managers making choices in an uncertain business climate. The case considers {{the difficult task of}} introducing a new product into the market. Under consideration is a sophisticated, surface-scanning technology that has applications in the food processing, food retail, and health industry sectors. Management of eMerge Interactive is faced with uncertainties in legislation, demand, and competitor response. The case can be used as part of a course in strategy and/or risk management where tools such as influence diagrams, scenario and <b>payoff</b> <b>matrices,</b> decision trees, and real options are introduced. risk management, influence diagrams, <b>payoff</b> <b>matrices,</b> decision trees, and real options, Marketing,...|$|R
40|$|This paper {{discusses}} {{the use of}} game theory as a method to achieve land and water governance for flood retention and resilience on a catchment scale. Therefore, it addresses flood retention in river catchments by using <b>payoff</b> <b>matrices</b> of game theory. How do <b>payoff</b> <b>matrices</b> between upstream and downstream change when certain property rights are adjusted or institutional conditions are changed? What if liability issues, responsibilities, and externalities of flood protection measures are reframed? Who should pay and who profit from retention measures? Individual scenarios correspond to some basic games from the game theory. The aim of these thought experiments is to develop rules for upstream-downstream agreements on retention and resilience within a river basin area...|$|R
2500|$|Strictly {{dominated}} strategies {{cannot be}} a part of a Nash equilibrium, and as such, it is irrational for any player to play them. [...] On the other hand, weakly dominated strategies may be part of Nash equilibria. [...] For instance, consider the <b>payoff</b> <b>matrix</b> pictured at the right.|$|E
2500|$|In a 2-player, 2-strategy {{game with}} externalities, {{individual}} players' payoffs are {{given by the}} function , where [...] is players i's strategy, [...] is the opponent's strategy, and w is a positive externality from choosing the same strategy. The strategy choices are +1 and 1, {{as seen in the}} <b>payoff</b> <b>matrix</b> in Figure 1.|$|E
2500|$|A formal {{version of}} the game of Chicken {{has been the subject}} of serious {{research}} in game theory. [...] Two versions of the <b>payoff</b> <b>matrix</b> for this game are presented here (Figures 1 and 2). [...] In Figure 1, the outcomes are represented in words, where each player would prefer to win over tying, prefer to tie over losing, and prefer to lose over crashing. [...] Figure 2 presents arbitrarily set numerical payoffs which theoretically conform to this situation. [...] Here, the benefit of winning is 1, the cost of losing is -1, and the cost of crashing is -10.|$|E
40|$|In {{an attempt}} to reduce {{guessing}} during multiple-choice testing, the effects of different <b>payoff</b> <b>matrices</b> were observed in this research. It was hypothesized that a penalty for incorrect answers {{and the existence of}} the alternative “no decision” {{have a significant effect on}} reducing guessing by subjects. Furthermore, this effect should become stronger the higher the risk of an incorrect response and therefore the higher the risk of losing points is. An experimental design with four different <b>payoff</b> <b>matrices</b> and a repeated measurement design with cross over (for the payoff for “no decision”) was realized. A visual discrimination task including three steps (one power condition, two speed conditions), with each item containing three choices plus the “no decision” option, was used. The results showed that the percentage of correct answers is influenced by the different payoff for the choice of “no decision”. Only in groups where “no decision” paid off with 0, was it chosen more often, however, the percentage for correct answers is lower in these groups. The results also indicate that subjects are able to adjust their behaviour according to the different <b>payoff</b> <b>matrices...</b>|$|R
50|$|Often, {{symmetric}} games (where the payoffs do {{not depend}} on which player chooses each action) are represented with only one payoff. This is the payoff for the row player. For example, the <b>payoff</b> <b>matrices</b> {{on the right and}} left below represent the same game.|$|R
40|$|A {{problem of}} {{evaluating}} the non-cooperative game model is {{considered in the}} paper. The evaluation is understood {{in the sense of}} obtaining the game <b>payoff</b> <b>matrices</b> whose entries are single-point values. Experts participating in the estimation procedure make their judgments on all the game situations for every player. A form of expert estimations is suggested. The form is of binary type, wherein the expert’s judgment is either 1 or 0. This type is the easiest to be implemented in social networks. For most social networks, 1 can be a “like” (the currently evaluated situation is advantageous), and 0 is a “dislike” (disadvantageous). A method of processing expert estimations is substantiated. Two requirements are provided for obtaining disambiguous payoff averages along with the clustered <b>payoff</b> <b>matrices...</b>|$|R
2500|$|In the {{biological}} literature, {{this game is}} known as Hawk–Dove. [...] The earliest presentation of a form of the Hawk–Dove game was by John Maynard Smith and George Price in their paper, [...] "The logic of animal conflict". [...] The traditional [...] <b>payoff</b> <b>matrix</b> for the Hawk–Dove game is given in Figure 3, where V {{is the value of}} the contested resource, and C is the cost of an escalated fight. [...] It is (almost always) assumed that the value of the resource is less than the cost of a fight, i.e., C>V>0. If C≤V, the resulting game is not a game of Chicken but is instead a Prisoner's Dilemma.|$|E
2500|$|Some games {{may have}} Nash equilibria {{that are not}} ESSes. For example, in harm thy {{neighbor}} (whose <b>payoff</b> <b>matrix</b> is shown here) both (A, A) and (B, B) are Nash equilibria, since players cannot do better by switching away from either. [...] However, only B is an ESS (and a strong Nash). A is not an ESS, so B can neutrally invade a population of A strategists and predominate, because B scores higher against B than A does against B. [...] This dynamic is captured by Maynard Smith's second condition, since E(A, A) = E(B, A), {{but it is not}} the case that E(A,B) > E(B,B).|$|E
2500|$|The <b>payoff</b> <b>matrix</b> in Figure 1 {{provides}} a simple two-player, two-strategy {{example of a}} game with two pure Nash equilibria. The strategy pair (Hunt,Hunt) is payoff dominant since payoffs are higher for both players {{compared to the other}} pure NE, (Gather, Gather). On the other hand, (Gather,Gather) risk dominates (Hunt,Hunt) since if uncertainty exists about the other player's action, gathering will provide a higher expected payoff. [...] The game in Figure 1 is a well-known game-theoretic dilemma called stag hunt. [...] The rationale behind it is that communal action (hunting) yields a higher return if all players combine their skills, but if it is unknown whether the other player helps in hunting, gathering {{might turn out to be}} the better individual strategy for food provision, since it does not depend on coordinating with the other player. In addition, gathering alone is preferred to gathering in competition with others. Like the Prisoner's dilemma, it {{provides a}} reason why collective action might fail in the absence of credible commitments.|$|E
40|$|A {{major focus}} of any safety program is the {{encouragement}} {{of the use of}} safe practices. Workers must make a decision about the acceptability of risk in any given situation. Where the employee makes the decision not to accept the level of risk, safe procedures may be used to reduce the risk. This decision process is influenced by two factors: 1) perceived probability of an incident occurring, and 2) the perceived costs and benefits associated the use of safe or unsafe behaviours. As the perceived probabilities of incidents is relatively low, workers may have a tendency toward not using safe practices, thus workers must be encouraged to use safe practices by other means. This study examines the use of safety instructions and <b>payoff</b> <b>matrices</b> of rewards and penalties encouraging safe behaviour. Results found that the frequency of safe practices in a simulated fire fighting task was increased more by <b>payoff</b> <b>matrices</b> which reward false alarms, than <b>payoff</b> <b>matrices</b> which penalise misses, or through the use of safety instructions. Undoubtedly, {{the most effective way to}} create a safe working environment is to remove any hazards altogether. Unfortunately, not all hazards can be removed easily, so necessitating the use of safety programs, which reduce the risks to workers. Safety programs often include rules and/or training regardin...|$|R
3000|$|However, {{efficient}} computation of equilibria points, {{as well as}} proving {{uniqueness of}} an equilibrium, {{remains an open question}} for many classes of games. Lemke-Howson (LH) [26] is the most well-known algorithm for the computation of Nash equilibria for bimatrix games and is our algorithm of choice for finding the Nash equilibrium strategies. A bimatrix game requires the game to be fully defined by two <b>payoff</b> <b>matrices</b> (one for each player). Since in our case the immediate payoff of every player in each step depends not only on his own action and the action of the opponent but also on the previous state of the player (influence of the hopping cost), our game as a whole cannot be represented by two deterministic <b>payoff</b> <b>matrices.</b> For this reason, we divide the game into [...]...|$|R
40|$|We use {{techniques}} {{from the}} statistical mechanics of disordered systems to analyse {{the properties of}} Nash equilibria of bimatrix games with large random <b>payoff</b> <b>matrices.</b> By means of an annealed bound, we calculate their number and analyse the properties of typical Nash equilibria, which are exponentially dominant in number. We find that a randomly chosen equilibrium realizes almost always equal payoffs to either player. This value and the fraction of strategies played at an equilibrium point are calculated {{as a function of}} the correlation between the two <b>payoff</b> <b>matrices.</b> The picture is complemented by the calculation of the properties of Nash equilibria in pure strategies. Comment: 6 pages, was "Self averaging of Nash equilibria in two player games", main section rewritten, some new results, for additional information see [URL]...|$|R
5000|$|Taking the <b>PAYOFF</b> <b>MATRIX</b> {{results and}} {{plugging}} {{them into the}} above equation: ...|$|E
5000|$|... #Caption: Mutant Invasion for Rock Paper Scissors <b>payoff</b> <b>matrix</b> - {{an endless}} cycle ...|$|E
50|$|An {{example of}} the <b>payoff</b> <b>matrix</b> for the stag hunt is pictured in Figure 2.|$|E
40|$|In {{this paper}} we {{address the problem of}} {{stability}} in a general class of non-linear systems. We establish a link between the concepts of asymptotic stable interior fixed points of square Quasi-Polynomial systems and evolutionary stable states, a property of some <b>payoff</b> <b>matrices</b> arising from evolutionary games. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|We {{prove the}} {{existence}} of -Nash equilibrium strategies with support logarithmic {{in the number of}} pure strategies. We also show that the payoffs to all players in any (exact) Nash equilibrium can be -approximated by the payoffs to the players in some such logarithmic support -Nash equilib-rium. These strategies are also uniform on a multiset of loga-rithmic size and therefore this leads to a quasi-polynomial al-gorithm for computing an -Nash equilibrium. To our knowl-edge this is the first subexponential algorithm for finding an -Nash equilibrium. Our results hold for any multiple-player game as long as the number of players is a constant (i. e., it is independent of the number of pure strategies). A similar argument also proves that for a fixed number of players m, the payoffs to all players in any m-tuple of mixed strategies can be -approximated by the payoffs in some m-tuple of constant support strategies. We also prove that if the <b>payoff</b> <b>matrices</b> of a two person game have low rank then the game has an exact Nash equi-librium with small support. This implies that if the <b>payoff</b> <b>matrices</b> can be well approximated by low rank matrices, the game has an -equilibrium with small support. It also implies that if the <b>payoff</b> <b>matrices</b> have constant rank we can compute an exact Nash equilibrium in polynomial time...|$|R
40|$|Evolutionary theory often {{resorts to}} weak selection, where {{different}} individuals have very similar fitness. Here, we relate {{two ways to}} introduce weak selection. The first considers evolutionary games described by <b>payoff</b> <b>matrices</b> with similar entries. This approach has recently attracted {{a lot of interest}} in the context of evolutionary game dynamics in finite populations. The second way to introduce weak selection is based on small distances in phenotype space and is a standard approach in kin-selection theory. Whereas both frameworks are interchangeable for constant fitness, frequency-dependent selection shows significant differences between them. We point out the difference between both limits of weak selection and discuss the condition under which the differences vanish. It turns out that this condition is fulfilled by the popular parametrization of the prisoner's dilemma in benefits and costs. However, for general <b>payoff</b> <b>matrices</b> differences between the two frameworks prevail. (C) 2007 Elsevier Ltd. All rights reserved...|$|R
5000|$|The {{canonical}} <b>payoff</b> <b>matrix</b> {{is shown}} below (if only integer inputs {{are taken into}} account): ...|$|E
5000|$|... #Caption: A {{game theory}} approach: the <b>payoff</b> <b>matrix</b> of a transaction. CC BY {{designed}} by crz ...|$|E
5000|$|Moreover, {{when the}} <b>payoff</b> <b>matrix</b> is asymmetric, other factors {{influence}} human behavior {{even when the}} game is not repeated: ...|$|E
40|$|Abstract We {{consider}} Nash equilibria in 2 -player random gamesand analyze {{a simple}} Las Vegas algorithm for finding an equilibrium. The algorithm is combinatorial and alwaysfinds a Nash equilibrium; on m * n <b>payoff</b> <b>matrices,</b> it runsin time O(m 2 n log log n+n 2 m log log m) with high proba-bility. Our main tool is a polytope formulation of equilibria...|$|R
40|$|In constant-payoff finite {{population}} games, when selection is weak and population size is large, the one-third law {{serves as the}} condition for a strategy to be advantageous. We generalize the result to the case where <b>payoff</b> <b>matrices</b> are environment-dependent and provide a more general law. In this way we model feedback from the environment and show {{its impact on the}} dynamics...|$|R
40|$|Three pigeons, {{previously}} {{trained to}} discriminate different numbers of responses (fixed ratios), were tested under different reinforcement contingencies (<b>payoff</b> <b>matrices)</b> at {{two levels of}} sensitivity. For one subject, relative reinforcement magnitude was varied—at first, across sessions and then, at midsession by reversing values—without exteroceptive cues. For another, relative reinforcement magnitude and/or probability was varied every 50 trials with cues by correlating different <b>payoff</b> <b>matrices</b> with different key colors. For the third subject, relative reinforcement probability was varied more frequently with cues—in the limit, at random—to demonstrate stimulus control of response bias on a trial-by-trial basis. A signal-detection analysis showed that bias changed with payoffs, {{for as many as}} seven different matrices, while sensitivity remained unchanged. The obtained functions (receiver operating characteristics) were similar under different payoff conditions, which suggests that a single mechanism controls bias. However, they differed enough in slope to require a relatively complex account (e. g., the general Gaussian model of detection theory) ...|$|R
