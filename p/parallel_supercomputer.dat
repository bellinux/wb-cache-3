213|490|Public
25|$|Felten {{attended}} the California Institute of Technology and {{graduated with a}} degree in Physics in 1985. He worked as a staff programmer at Caltech from 1986 to 1989 on a <b>parallel</b> <b>supercomputer</b> project at Caltech. He then enrolled as a graduate student in Computer Science at the University of Washington. He was awarded a Master of Science degree in 1991 and a Ph.D in 1993. His Ph.D. thesis was on developing an automated protocol for communication between parallel processors.|$|E
25|$|On April 2, 1994, the {{factorization}} of RSA-129 {{was completed}} using QS. It was a 129-digit number, {{the product of}} two large primes, one of 64 digits and the other of 65. The factor base for this factorization contained 524339 primes. The data collection phase took 5000 MIPS-years, done in distributed fashion over the Internet. The data collected totaled 2GB. The data processing phase took 45 hours on Bellcore's (now Telcordia Technologies) MasPar (massively <b>parallel)</b> <b>supercomputer.</b> This was the largest published factorization by a general-purpose algorithm, until NFS was used to factor RSA-130, completed April 10, 1996. All RSA numbers factored since then have been factored using NFS.|$|E
25|$|In {{the early}} 1980s, Cornell {{deployed}} the first IBM 3090-400VF and coupled two IBM 3090-600E systems to investigate coarse-grained parallel computing. In 1984, the National Science Foundation {{began work on}} establishing five new supercomputer centers, including the Cornell Center for Advanced Computing, to provide high-speed computing resources for research within the United States. As an NSF center, Cornell deployed the first IBM Scalable <b>Parallel</b> <b>supercomputer.</b> In the 1990s, Cornell developed scheduling software and deployed the first supercomputer built by Dell. Most recently, Cornell deployed Red Cloud, {{one of the first}} cloud computing services designed specifically for research. Today, the center is a partner on the National Science Foundation XSEDE supercomputing program, providing coordination for XSEDE architecture and design, systems reliability testing, and online training using the Cornell Virtual Workshop learning platform.|$|E
40|$|Resource-intensive {{parallel}} {{applications are}} typically developed to target either workstation clusters or <b>parallel</b> <b>supercomputers.</b> In this paper, we describe {{a strategy that}} leverages the advantages of both types of platforms to improve {{the performance of a}} parallel tomography application. We demonstrate that this strategy promotes superior application performance compared to strategies which target the application either to <b>parallel</b> <b>supercomputers</b> or workstation clusters alone. 1 Introduction Both <b>parallel</b> <b>supercomputers</b> and clusters of workstations are being used successfully to execute <b>parallel</b> applications. <b>Parallel</b> <b>supercomputers</b> offer fast execution performance but are typically space-shared. Jobs wishing to execute must wait in a batch queue until a sufficient number of the machine's processors become available. Once processors are allocated, the execution time of the application may be short, but the queueing delay is often lengthy before execution can begin. Interactive (time [...] ...|$|R
5000|$|NAS Parallel Benchmarks (NPB) were {{developed}} to evaluate highly <b>parallel</b> <b>supercomputers</b> and mimic the characteristics of large-scale CFD applications.|$|R
50|$|Distributed {{memory is}} the {{programming}} style used on <b>parallel</b> <b>supercomputers</b> from homegrown Beowulf clusters {{to the largest}} clusters on the Teragrid.|$|R
2500|$|Anton – A specialized, massively <b>parallel</b> <b>supercomputer</b> {{designed}} to execute MD simulations ...|$|E
2500|$|Its {{centerpiece}} is an 18 rack Blue Gene /L and 2 rack Blue Gene/P massively <b>parallel</b> <b>supercomputer</b> ...|$|E
2500|$|Long continuous-trajectory {{simulations}} {{have been}} performed on Anton, a massively <b>parallel</b> <b>supercomputer</b> designed and built around custom application-specific integrated circuits (ASICs) and interconnects by D. E. Shaw Research. The longest published result of a simulation performed using Anton is a 1.112-millisecond simulation of NTL9 at 355 K; a second, independent 1.073-millisecond simulation of this configuration was also performed (and many other simulations of over 250 µs continuous chemical time). In How Fast-Folding Proteins Fold, researchers Kresten Lindorff-Larsen, Stefano Piana, Ron O. Dror, and David E. Shaw discuss [...] "the results of atomic-level molecular dynamics simulations, over periods ranging between 100 μs and 1 ms, that reveal a set of common principles underlying the folding of 12 structurally diverse proteins." [...] Examination of these diverse long trajectories, enabled by specialized, custom hardware, allow them to conclude that [...] "In most cases, folding follows a single dominant route in which elements of the native structure appear in an order highly correlated with their propensity to form in the unfolded state." [...] In a separate study, Anton was used to conduct a 1.013-millisecond simulation of the native-state dynamics of bovine pancreatic trypsin inhibitor (BPTI) at 300 K.|$|E
50|$|The Amalka Supercomputing {{facility}} {{is the largest}} of the three Czech <b>parallel</b> <b>supercomputers.</b> It is used by Department of Space Physics,Institute of Atmospheric Physics, Academy of Sciences of the Czech Republic.|$|R
25|$|The 21164 and 21264 {{processors}} {{were used}} by NetApp in various network-attached storage systems, while the 21064 and 21164 processors {{were used by}} Cray in their T3D and T3E massively <b>parallel</b> <b>supercomputers.</b>|$|R
5000|$|By {{the end of}} the 20th century, massively <b>parallel</b> <b>supercomputers</b> with {{thousands}} of [...] "off-the-shelf" [...] processors similar to those found in personal computers were constructed and broke through the teraflop computational barrier.|$|R
5000|$|... #Caption: IBM's Blue Gene/P massively <b>parallel</b> <b>supercomputer.</b>|$|E
5000|$|... #Caption: A cabinet from IBM's Blue Gene/L massively <b>parallel</b> <b>supercomputer.</b>|$|E
5000|$|Anton - A specialized, massively <b>parallel</b> <b>supercomputer</b> {{designed}} to execute MD simulations ...|$|E
30|$|To {{evaluate}} {{the behavior of}} the proposed WiNoCs regarding communication in existing parallel applications, we decided to use some of the NPB kernels [25]. This choice was due to these applications being indicated to {{evaluate the}} performance of <b>parallel</b> <b>supercomputers.</b>|$|R
30|$|The NASA Advanced Supercomputing (NAS) Division {{developed}} the NAS Parallel Benchmarksf, {{which is a}} set of programs used to evaluate the performance of <b>parallel</b> <b>supercomputers.</b> This test suite includes 8 benchmarks, which have several implementations, and serve different purposes in evaluating system performance.|$|R
50|$|APE ("ah-pei"), {{an acronym}} for Array Processor Experiment, was the {{collective}} name of several generations of massively <b>parallel</b> <b>supercomputers</b> since 1984, optimized for theoretical physics simulations. The APE machines were massively parallel 3D arrays of custom computing nodes with periodic boundary conditions.|$|R
5000|$|... 1984-1987 Hardware Design Director, Cedar <b>Parallel</b> <b>Supercomputer</b> at Center for Supercomputing Research at University of Illinois ...|$|E
50|$|The massively <b>parallel</b> <b>supercomputer</b> IBM p690 Cluster Jump {{has been}} in {{operation}} {{since the beginning of}} 2004.|$|E
5000|$|The Sunway BlueLight (...) is a Chinese massively <b>parallel</b> <b>supercomputer.</b> It is {{the first}} {{publicly}} announced PFLOPS supercomputer using Sunway processors solely developed by the People's Republic of China.|$|E
5000|$|Empire is a {{computer}} software for semiempirical Molecular Orbital calculations designed to run in parallel on multi-core desktop computers and on massively <b>parallel</b> <b>supercomputers.</b> Empire {{is used to calculate}} chemical structures and is able to calculate large systems such as proteins [...]|$|R
30|$|The {{efforts are}} also aimed at {{improving}} the computational performance in three-dimensional settings {{to have a more}} efficient implementation of the Offine ‘construction stage’ (for example, on high-performance <b>parallel</b> <b>supercomputers)</b> and more and more attractive real-time applications such as the ones currently available on smartphones [82].|$|R
40|$|Abstract A {{state-of-the-art}} ocean model developed originally at MIT {{is currently}} being tested and evaluated for assimilating satellite data here at NASA-JPL. We report on some performance results in running this model on both the SGI Origin 2000 and the HP 2500 V-class <b>parallel</b> <b>supercomputers.</b> Keywords...|$|R
50|$|The Meiko Computing Surface (sometimes {{retrospectively}} {{referred to}} as the CS-1) was a massively <b>parallel</b> <b>supercomputer.</b> The system was based on the INMOS transputer microprocessor, later also using SPARC and Intel i860 processors.|$|E
50|$|In {{addition}} to organizing and leading {{the development of}} several large-scale physics application computer codes, Solem developed a concept for massively <b>parallel</b> <b>supercomputer</b> architecture specialized for Monte Carlo solution of integro-differential equations (1985a, 1985b).|$|E
50|$|The VP2000 was {{the second}} series of vector {{supercomputers}} from Fujitsu. Announced in December 1988, they replaced Fujitsu's earlier FACOM VP Model E Series. The VP2000 was succeeded in 1995 by the VPP300, a massively <b>parallel</b> <b>supercomputer</b> with up to 256 vector processors.|$|E
40|$|Scientific {{applications}} {{are increasingly being}} implemented on massively <b>parallel</b> <b>supercomputers.</b> Many of these applications have intense I/O demands, as well as massive computational requirements. This paper is essentially an annotated bibliography of papers and other sources of information about scientific applications using parallel I/O. It will be updated periodically...|$|R
50|$|OSF/1 AD (Advanced Development) was a {{distributed}} {{version of}} OSF/1 developed for massively <b>parallel</b> <b>supercomputers</b> by Locus Computing Corporation. Variants of OSF/1 AD were used on several such systems, including the Intel Paragon XP/S and ASCI Red, Convex Exemplar SPP-1200 (as SPP-UX) and the Hitachi SR2201 (as HI-UX MPP).|$|R
40|$|We use {{two large}} simulations, the {{chemical}} reaction dynamics of H + H 2 and {{the collision of}} two galaxies to show that current parallel machines are capable of large supercomputer level calculations. We contrast the different architectural tradeoffs for these problems and draw some implications for future production <b>parallel</b> <b>supercomputers...</b>|$|R
50|$|Long continuous-trajectory {{simulations}} {{have been}} performed on Anton, a massively <b>parallel</b> <b>supercomputer</b> designed and built around custom ASICs and interconnects by D. E. Shaw Research. The longest published result of a simulation performed using Anton is a 2.936 millisecond simulation of NTL9 at 355 K.|$|E
5000|$|Illinois {{history in}} {{parallel}} computing stretches more than 40 years. From the first academic <b>parallel</b> <b>supercomputer,</b> the ILLIAC IV started in 1964, to today’s work {{to install the}} first petascale computer, Blue Waters, Illinois has defined the landscape of parallel computing. Contributions from past and current Illinois faculty include: ...|$|E
50|$|DEISA {{produced}} a benchmark suite to help computer scientists assess {{the performance of}} <b>parallel</b> <b>supercomputer</b> systems. The benchmark comprises a number of real applications codes taken {{from a wide range}} of scientific disciplines. A structured framework allows compilation, execution and analysis to be configured and carried out via standard input files.|$|E
50|$|NAS Parallel Benchmarks (NPB) are {{a set of}} {{benchmarks}} targeting {{performance evaluation}} of highly <b>parallel</b> <b>supercomputers.</b> They are developed and maintained by the NASA Advanced Supercomputing (NAS) Division (formerly the NASA Numerical Aerodynamic Simulation Program) based at the NASA Ames Research Center. NAS solicits performance results for NPB from all sources.|$|R
40|$|Scienti c {{applications}} {{are increasingly being}} implemented on massively <b>parallel</b> <b>supercomputers.</b> Many of these applications have intense I/O demands, as well as massive computational requirements. This paper is essentially an annotated bibliography of papers and other sources of information about scienti c applications using parallel I/O. It will be updated periodically. ...|$|R
50|$|The Intel Paragon is a {{discontinued}} {{series of}} massively <b>parallel</b> <b>supercomputers</b> that {{was produced by}} Intel in the 1990s. The Paragon XP/S is a productized version of the experimental Touchstone Delta system that was built at Caltech, launched in 1992. The Paragon superseded Intel's earlier iPSC/860 system, {{to which it is}} closely related.|$|R
