10000|10000|Public
5|$|In {{computer}} vision, {{digital images}} are partitioned into small square <b>pixels,</b> {{each of which}} has its own color. The dual graph of this subdivision into squares has a vertex per pixel and an edge between pairs of <b>pixels</b> that share an edge; it is useful for applications including clustering of <b>pixels</b> into connected regions of similar colors.|$|E
5|$|The {{homepage}} {{featured a}} Web banner with the site's {{name and a}} pixel counter displaying the number of <b>pixels</b> sold, a navigation bar containing nine small links to the site's internal web pages, and an empty square grid of 1,000,000 <b>pixels</b> divided into 10,000 100-pixel blocks. Tew promised customers that the site would remain online {{for at least five}} years – that is, until at least 26 August 2010.|$|E
5|$|The {{production}} of a final combined image at each wavelength was a complex process. Bright <b>pixels</b> caused by cosmic ray impacts during exposures were removed by comparing exposures of equal length taken one after the other, and identifying <b>pixels</b> that were affected by cosmic rays in one exposure but not the other. Trails of space debris and artificial satellites {{were present in the}} original images, and were carefully removed.|$|E
3000|$|... 0 in {{the right}} image, the {{erroneous}} <b>pixel</b> will be marked as mismatched <b>pixel</b> with 255. If the <b>pixel</b> cannot find the matched <b>pixel</b> either with the disparity shift or {{with a range of}} disparity shift, we set this <b>pixel</b> as an occluded <b>pixel</b> with 0.|$|R
40|$|In {{a method}} of {{segmenting}} an image a first seed <b>pixel</b> unit is selected from a first group of <b>pixel</b> units in which the <b>pixel</b> units all have substantially the same grey-level intensity. The grey-level intensity of said first <b>pixel</b> unit is compared with the grey-level intensity of each of selected adjacent <b>pixel</b> units of said image and those <b>pixel</b> units with grey levels within a selected range arm assigned as a <b>pixel</b> unit of the same region as said first <b>pixel</b> unit This comparison process is repeated {{for each of the}} <b>pixel</b> units in the image, those already having been assigned being ignored. A further seed <b>pixel</b> unit is selected from a further group of <b>pixel</b> units in which the <b>pixel</b> units all have substantially the same grey-level intensity and the comparison process repeated for all of the unassigned <b>pixel</b> units. Further seed <b>pixel</b> units are selected and the comparison process repeated until all the <b>pixel</b> units of the image have been assigned. A watershed transform is then applied to provide the segmented imag...|$|R
40|$|Abstract: The {{influence}} of <b>pixel’s</b> spatial characteristics on recognition of isolated Chinese character was investigated us-ing simulated prosthestic vision. The accuracy of Chinese character recognition with 4 kinds of <b>pixel</b> number (6 * 6, 8 * 8, 10 * 10, and 12 * 12 <b>pixel</b> array) and 3 kinds of <b>pixel</b> shape (Square, Dot and Gaussian) and different <b>pixel</b> spacing were tested through head-mounted display (HMD). A captured image of Chinese characters in font style of Hei were pixelized with Square, Dot and Gaussian <b>pixel.</b> Results showed that <b>pixel</b> number {{was the most}} important factor which could affect the recognition of isolated pixelized Chinese Chartars and the accuracy of recognition increased with the addition of <b>pixel</b> number. 10 * 10 <b>pixel</b> array could provide enough information for people to recognize an isolated Chinese character. At low resolution (6 * 6 and 8 * 8 <b>pixel</b> array), there were little difference of recognition accuracy between different <b>pixel</b> shape and different <b>pixel</b> spacing. While as for high resolution (10 * 10 and 12 * 12 <b>pixel</b> array), the fluctuation of <b>pixel</b> shape and <b>pixel</b> spacing could not affect the performance of recognition of isolated pixelized Chinese Character...|$|R
5|$|Alex Tew, {{a student}} from Cricklade in Wiltshire, England, {{conceived}} The Million Dollar Homepage in August 2005 when he was 21 years old. He {{was about to begin}} a three-year Business Management course at the University of Nottingham, and was concerned that he would be left with a student loan that could take years to repay. As a money-raising idea, Tew decided to sell a million <b>pixels</b> on a website for $1 each; purchasers would add their own image, logo or advertisement, and have the option of including a hyperlink to their website. <b>Pixels</b> were sold for US dollars rather than UK pounds; the US has a larger online population than the UK, and Tew believed more people would relate to the concept if the <b>pixels</b> were sold in US currency. In 2005, the pound was strong against the dollar: £1 was worth approximately $1.80, and that cost per pixel may have been too expensive for many potential buyers. Tew's setup costs were €50, which paid for the registration of the domain name and a basic web-hosting package. The website went live on 26 August 2005.|$|E
5|$|MacPaint uses two offscreen memory buffers {{to avoid}} flicker when {{dragging}} shapes or images across the screen. One of these buffers contained the existing <b>pixels</b> of a document, {{and the other}} contained the <b>pixels</b> of its previous state. The second buffer {{was used as the}} basis of the software's undo feature. In April 1983, the software's name was changed from MacSketch to MacPaint. The original MacPaint was programmed as a single-document interface. The palette positions and sizes were unalterable, as was the document window. This was different from other Macintosh software at the time, which allowed the users to move windows and resize them.|$|E
5|$|Of the 640,000 {{individual}} <b>pixels</b> that compose each frame, Earth {{takes up}} less than one (0.12 <b>pixels,</b> according to NASA). The light bands across the photograph are an artifact, the result of sunlight scattering off parts of the camera and its sunshade, due to the relative proximity between the Sun and the Earth. Voyager's point of view was approximately 32° above the ecliptic. Detailed analysis suggested that the camera also detected the Moon, although it is too faint to be visible without special processing.|$|E
30|$|Each <b>pixel</b> has one {{returned}} value {{defined by}} the level of corruption present in the <b>pixel.</b> That is, one says ‘the <b>pixel</b> is corrupted’ if its BIG membership value is 1, and ‘the <b>pixel</b> is low-noise corrupted’ when its BIG membership value is 0. The linguistics ‘the <b>pixel</b> is corrupted’ and ‘the <b>pixel</b> is low-noise corrupted’ indicate the degree of belonging {{to each of the}} possible states in which the <b>pixel</b> can be found.|$|R
5000|$|Do the <b>pixel's</b> North and West {{neighbors have}} {{different}} <b>pixel</b> values than current <b>pixel?</b> ...|$|R
40|$|A {{polysilicon}} transistor based {{active matrix}} organic {{light emitting diode}} (AMOLED) <b>pixel</b> with high <b>pixel</b> to <b>pixel</b> luminance uniformity is reported. The new <b>pixel</b> powers the OLEDS with small constant currents to ensure consistent brightness and extended life. Excellent <b>pixel</b> to <b>pixel</b> current drive uniformity is obtained despite the threshold voltage variation inherent in polysilicon transistors. considerations in the design for high information content displays are discussed...|$|R
5|$|The HTC One is {{equipped}} with a 4.0-megapixel rear-facing camera module that contains a custom image sensor marketed as UltraPixel, which is composed of <b>pixels</b> that are 2.0µm in size. Most high-end smartphones {{at the time of its}} release used 8- or 13-megapixel cameras with pixel sizes ranging from 1.4 to 1.0µm, both of which are considerably smaller in size than the <b>pixels</b> found in the One’s UltraPixel sensor. Although these smaller pixel sizes were typically necessary to ensure that the camera sensor did not compromise the design of the phone, there were concerns that this could result in a loss of dynamic range and sensitivity, and also result in poor performance in low-light environments. As such, HTC stated that its camera design with larger sensor <b>pixels</b> could notably increase overall image quality, especially in low-light environments. The camera also includes optical image stabilization, and is further enhanced by improvements to the Sense camera software and the ImageChip 2 image processor.|$|E
5|$|An {{approximation}} to {{the curve}}-shortening flow can be computed numerically, by approximating the curve as a polygon {{and using the}} finite difference method to calculate the motion of each polygon vertex. Alternative methods include computing a convolution of polygon vertices and then resampling vertices on the resulting curve, or repeatedly applying a median filter to a digital image whose black and white <b>pixels</b> represent the {{inside and outside of}} the curve.|$|E
5|$|Because {{the game}} was {{developed}} during the period when Columbia Pictures owned Gottlieb, the intellectual rights to Q*bert remained with Columbia even after they divested themselves of Gottlieb's assets in 1984. Therefore, the rights have been owned by Sony Pictures Entertainment since its parent Sony acquired Columbia in 1989. Q*bert appeared in Disney's computer-animated film Wreck-It Ralph under license from Sony, and later appeared in Columbia's live-action film <b>Pixels</b> in 2015.|$|E
50|$|Google <b>Pixel</b> {{is a line}} of {{consumer}} electronic devices from Google that run either the Chrome OS or Android operating system. The <b>Pixel</b> line of devices includes the <b>Pixel</b> C tablet, Chromebook <b>Pixel</b> laptops, and the <b>Pixel</b> smartphones and can be bought over the Google Store or at retail stores.|$|R
40|$|A {{method and}} system for extrapolating and interpolating a visual signal {{including}} determining a first motion vector between a first <b>pixel</b> {{position in a}} first image to a second <b>pixel</b> position in a second image, determining a second motion vector between the second <b>pixel</b> position in the second image and a third <b>pixel</b> position in a third image, determining a third motion vector between {{one of the first}} <b>pixel</b> position in the first image and the second <b>pixel</b> position in the second image, and the second <b>pixel</b> position in the second image and the third <b>pixel</b> position in the third image using a non-linear model, determining a position of the fourth <b>pixel</b> in a fourth image based upon the third motion vector...|$|R
40|$|Three related {{innovations}} combine improved non-linear motion estimation, video coding, {{and video}} compression. The first system comprises a method in which side information is generated using an adaptive, non-linear motion model. This method enables extrapolating and interpolating a visual signal, including determining the first motion vector {{between the first}} <b>pixel</b> position in a first image to a second <b>pixel</b> position in a second image; determining a second motion vector between the second <b>pixel</b> position in the second image and a third <b>pixel</b> position in a third image; determining a third motion vector between the first <b>pixel</b> position in the first image and the second <b>pixel</b> position in the second image, the second <b>pixel</b> position in the second image, and the third <b>pixel</b> position in the third image using a non-linear model; and determining a position of the fourth <b>pixel</b> in a fourth image based upon the third motion vector. For the video compression element, the video encoder has low computational complexity and high compression efficiency. The disclosed system comprises a video encoder and a decoder. The encoder converts the source frame into a space-frequency representation, estimates the conditional statistics {{of at least one}} vector of space-frequency coefficients with similar frequencies, and is conditioned on previously encoded data. It estimates an encoding rate based on the conditional statistics and applies a Slepian-Wolf code with the computed encoding rate. The method for decoding includes generating a side-information vector of frequency coefficients based on previously decoded source data and encoder statistics and previous reconstructions of the source frequency vector. It also performs Slepian-Wolf decoding of a source frequency vector based on the generated side-information and the Slepian-Wolf code bits. The video coding element includes receiving a first reference frame having a first <b>pixel</b> value at a first <b>pixel</b> position, a second reference frame having a second <b>pixel</b> value at a second <b>pixel</b> position, and a third reference frame having a third <b>pixel</b> value at a third <b>pixel</b> position. It determines a first motion vector between the first <b>pixel</b> position and the second <b>pixel</b> position, a second motion vector between the second <b>pixel</b> position and the third <b>pixel</b> position, and a fourth <b>pixel</b> value for a fourth frame based upon a linear or nonlinear combination of the first <b>pixel</b> value, the second <b>pixel</b> value, and the third <b>pixel</b> value. A stationary filtering process determines the estimated <b>pixel</b> values. The parameters of the filter may be predetermined constants...|$|R
5|$|Hardware {{requirements}} for the product depend on the operating system; on a computer running Windows Vista or Windows 7, it requires a 1GHz processor, 1GB of RAM, a computer monitor with a display resolution of at least 800 × 600 <b>pixels,</b> 200MB of free hard disk space and an Internet connection.|$|E
5|$|Launched on 26 August 2005, {{the website}} became an Internet phenomenon. The Alexa ranking of web traffic peaked at around 127; , it is 40,044. On 1 January 2006, the final 1,000 <b>pixels</b> were {{put up for}} auction on eBay. The auction closed on 11 January with a winning bid of $38,100 that brought the final tally to $1,037,100 in gross income.|$|E
5|$|The {{circuit board}} of Radar Scope was {{restructured}} for Donkey Kong. The Radar Scope hardware, originally {{inspired by the}} Namco Galaxian hardware, was designed for {{a large number of}} enemies moving around at high speeds, which Donkey Kong did not require, so the development team removed unnecessary functions and reduced the scale of the circuit board. While the gameplay and graphics were reworked for updated ROM chips, the existing CPU, sound hardware and monitor were left intact. The character set, scoreboard, upper HUD display and font are almost identical to Radar Scope, with palette differences. The Donkey Kong hardware had the memory capacity for displaying 128 foreground sprites at 16x16 <b>pixels</b> each and 256 background tiles at 8x8 <b>pixels</b> each. Mario and all moving objects used single sprites, the taller Pauline used two sprites, and the larger Donkey Kong used six sprites.|$|E
50|$|The {{simplest}} form of {{the algorithm}} scans the image one row {{at a time and}} one <b>pixel</b> at a time. The current <b>pixel</b> is compared to a half-gray value. If it is above the value a white <b>pixel</b> is generated in the resulting image.If the <b>pixel</b> is below the half way brightness, a black <b>pixel</b> is generated.The generated <b>pixel</b> is either full bright, or full black, so there is an error in the image.The error is then added to the next <b>pixel</b> in the image and the process repeats.|$|R
50|$|Al Linke led a {{collaborative}} LED art project called <b>PIXEL.</b> <b>Pixel</b> artists {{all over the}} world contributed 32×32 and 64×64 <b>pixel</b> art, mainly in the form of animated gifs which are displayed on the <b>PIXEL</b> LED Display.|$|R
50|$|Holography {{applications}} demand {{even greater}} <b>pixel</b> density, as higher <b>pixel</b> density produces a larger image size and wider viewing angle. Spatial light modulators can reduce <b>pixel</b> pitch to 2.5 μm, giving a <b>pixel</b> density of 10,160 PPI.|$|R
5|$|The device has an Apple A5X SoC with a 1GHz dual-core 32-bit Cortex-A9 CPU and a quad-core PowerVR SGX543MP4 GPU; 1GB of RAM; a 5-megapixel, {{rear-facing}} camera {{capable of}} 1080p video recording; and a VGA front-facing videophone camera designed for FaceTime. The display resolution is 2,048 by 1,536 (QXGA) with 3.1million <b>pixels</b> – {{four times more}} than the iPad 2 – providing even scaling from the prior model.|$|E
25|$|Some LCD panels have {{defective}} transistors, causing permanently lit or unlit <b>pixels</b> {{which are}} {{commonly referred to}} as stuck <b>pixels</b> or dead <b>pixels</b> respectively. Unlike integrated circuits (ICs), LCD panels with a few defective transistors are usually still usable. Manufacturers' policies for the acceptable number of defective <b>pixels</b> vary greatly. At one point, Samsung held a zero-tolerance policy for LCD monitors sold in Korea. As of 2005, though, Samsung adheres to the less restrictive ISO 13406-2 standard. Other companies have been known to tolerate as many as 11 dead <b>pixels</b> in their policies.|$|E
25|$|Without using overscan, the {{graphics}} can be 320 or 640 <b>pixels</b> wide by 200/256 or 400/512 <b>pixels</b> tall.|$|E
5000|$|Display: 5.0" [...] AMOLED display with 1080×1920 <b>pixel</b> {{resolution}} (Pixel); 5.5" [...] AMOLED display with 1440×2560 <b>pixel</b> resolution (<b>Pixel</b> XL) ...|$|R
5000|$|<b>Pixel</b> and <b>Pixel</b> XL {{ship with}} Android 7.1 [...] "Nougat", an update to 7.0 that was {{initially}} exclusive to the <b>Pixel.</b> It was released for existing Nexus devices in December 2016, but certain features remain exclusive to <b>Pixel.</b>|$|R
3000|$|Each {{and every}} <b>pixel</b> {{of the image}} is checked for the {{presence}} of salt and pepper noise <b>pixel.</b> During processing if a <b>pixel</b> element lies between [...] " 0 and 255 ", it is left unchanged. If the value is 0 or 255, then it is a noisy <b>pixel</b> and it is substituted by a substitution <b>pixel.</b>|$|R
25|$|ClearType {{and allied}} {{technologies}} require display hardware with fixed <b>pixels</b> and subpixels. More precisely, {{the positions of}} the <b>pixels</b> and subpixels on the screen must be exactly known to the computer to which it is connected. This is the case for flat-panel displays, on which {{the positions of the}} <b>pixels</b> are permanently fixed by the design of the screen itself. Almost all flat panels have a perfectly rectangular array of square <b>pixels,</b> each of which contains three rectangular subpixels in the three primary colors, with the normal ordering being red, green, and blue, arranged in vertical bands. ClearType assumes this arrangement of <b>pixels</b> when rendering text.|$|E
25|$|Standard-definition {{television}} (SDTV) uses either 720 by 480 <b>pixels</b> (US NTSC 525-line) or 704 by 576 <b>pixels</b> (UK PAL 625-line) for {{the visible}} picture area.|$|E
25|$|Three {{detector}} arrays in the {{far infrared}} (128 × 128 <b>pixels</b> at 24µm, 32 × 32 <b>pixels</b> at 70µm, 2 × 20 <b>pixels</b> at 160µm). The 24µm detector is identical {{to one of the}} IRS short wavelength modules. The 70µm detector uses gallium-doped germanium technology, and the 160µm detector also uses gallium-doped germanium, but with mechanical stress added to each pixel to lower the bandgap and extend sensitivity to this long wavelength. The principal investigator is George H. Rieke of the University of Arizona; the flight hardware was built by Ball Aerospace.|$|E
50|$|Image type 1 and 9: Depending on the <b>Pixel</b> Depth value, {{image data}} {{representation}} is an 8, 15, or 16 bit index into a color map {{that defines the}} color of the pixel.Image type 2 and 10: The image data is a direct representation of the <b>pixel</b> color. For a <b>Pixel</b> Depth of 15 and 16 bit, each <b>pixel</b> is stored with 5 bits per color. If the <b>pixel</b> depth is 16 bits, the topmost bit is reserved for transparency. For a <b>pixel</b> depth of 24 bits, each <b>pixel</b> is stored with 8 bits per color. A 32-bit <b>pixel</b> depth defines an additional 8-bit alpha channel.Image type 3 and 11: The image data is a direct representation of grayscale data. The <b>pixel</b> depth is 8 bits for images of this type.|$|R
5000|$|Resolution: 352×240 <b>pixel</b> for NTSC video, 352×288 <b>pixel</b> for PAL video (VCD); 480×480 <b>pixel</b> for NTSC video, 480×576 for PAL video (SVCD) ...|$|R
40|$|Abstract — We {{propose a}} novel {{method of extracting}} a human {{silhouette}} from a outdoor golf swing movie taken by a mobile phone camera for automatic golf swing diagnosis. At every <b>pixel,</b> we make color and brightness histograms during a swing. Each <b>pixel</b> is classified into three categories:background <b>pixel,</b> human <b>pixel,</b> mixture <b>pixel.</b> Histograms of the ”background <b>pixel</b> ” have only one peak corresponding to the background, histograms of the ”human <b>pixel</b> ” have dispersed dispersed distribution correspond-ing to the various points in the human region, and histograms of the ”mixture <b>pixel</b> ” have a peak and dispersed distribution. Based on this histogram features, we classify each <b>pixel</b> we segment the swing period into background frames and human frames. Then we extract human silhouette at each frame. Experimental results show the validity of our method. I...|$|R
