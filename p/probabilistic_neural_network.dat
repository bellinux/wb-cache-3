680|10000|Public
50|$|A <b>probabilistic</b> <b>neural</b> <b>network</b> (PNN) is a four-layer {{feedforward}} neural network. The layers are Input, hidden, pattern/summation and output. In the PNN algorithm, {{the parent}} {{probability distribution function}} (PDF) of each class is approximated by a Parzen window and a non-parametric function. Then, using PDF of each class, the class probability of a new input is estimated and Bayes’ rule is employed to allocate it to the class with the highest posterior probability. It {{was derived from the}} Bayesian network and a statistical algorithm called Kernel Fisher discriminant analysis. It is used for classification and pattern recognition.|$|E
5000|$|A <b>probabilistic</b> <b>neural</b> <b>network</b> (PNN) is a {{feedforward}} neural network, {{which is}} widely used in classification and pattern recognition problems. In the PNN algorithm, the parent probability distribution function (PDF) of each class is approximated by a Parzen window and a non-parametric function. Then, using PDF of each class, the class probability of a new input data is estimated and Bayes’ rule is then employed to allocate the class with highest posterior probability to new input data. By this method, the probability of mis-classification is minimized. This type of ANN {{was derived from the}} Bayesian network and a statistical algorithm called Kernel Fisher discriminant analysis. It was introduced by D.F. Specht in the 1966. In a PNN, the operations are organized into a multilayered feedforward network with four layers: ...|$|E
40|$|<b>Probabilistic</b> <b>neural</b> <b>network</b> has {{successfully}} solved {{all kinds of}} engineering problems in various fields since it is proposed. In <b>probabilistic</b> <b>neural</b> <b>network,</b> Spread has great influence on its performance, and <b>probabilistic</b> <b>neural</b> <b>network</b> will generate bad prediction results if it is improperly selected. It is difficult to select the optimal manually. In this article, a variant of <b>probabilistic</b> <b>neural</b> <b>network</b> with self-adaptive strategy, called self-adaptive <b>probabilistic</b> <b>neural</b> <b>network,</b> is proposed. In self-adaptive <b>probabilistic</b> <b>neural</b> <b>network,</b> Spread can be self-adaptively adjusted and selected and then the best selected Spread is used to guide the self-adaptive <b>probabilistic</b> <b>neural</b> <b>network</b> train and test. In addition, two simplified strategies are incorporated into the proposed self-adaptive <b>probabilistic</b> <b>neural</b> <b>network</b> {{with the aim of}} further improving its performance and then two versions of simplified self-adaptive <b>probabilistic</b> <b>neural</b> <b>network</b> (simplified self-adaptive probabilistic neural networks 1 and 2) are proposed. The variants of self-adaptive probabilistic neural networks are further applied to solve the transformer fault diagnosis problem. By comparing them with basic <b>probabilistic</b> <b>neural</b> <b>network,</b> and the traditional back propagation, extreme learning machine, general regression neural network, and self-adaptive extreme learning machine, the results have experimentally proven that self-adaptive probabilistic neural networks have a more accurate prediction and better generalization performance when addressing the transformer fault diagnosis problem...|$|E
40|$|In this contribution, novel {{approaches}} are {{proposed for the}} improvement of the performance of <b>Probabilistic</b> <b>Neural</b> <b>Networks</b> as well as the recently proposed Evolutionary <b>Probabilistic</b> <b>Neural</b> <b>Networks.</b> The Evolutionary <b>Probabilistic</b> <b>Neural</b> <b>Network’s</b> matrix of spread parameters is allowed to have different values in each class of neurons, resulting in a more flexible model that fits the data better and Particl...|$|R
40|$|Abstract In this contribution, novel {{approaches}} are {{proposed for the}} improvement of the performance of <b>Probabilistic</b> <b>Neural</b> <b>Networks</b> as well as the recently proposed Evolutionary <b>Probabilistic</b> <b>Neural</b> <b>Networks.</b> The Evolutionary <b>Probabilistic</b> <b>Neural</b> <b>Network’s</b> matrix of spread parameters is allowed to have different values in each class of neurons, resulting in a more flexible model that fits the data better and Particle Swarm Optimization is also employed for the estimation of the <b>Probabilistic</b> <b>Neural</b> Networks’s prior probabilities of each class. Moreover, the bagging technique is used to create an ensemble of Evolutionary <b>Probabilistic</b> <b>Neural</b> <b>Networks</b> in order to further improve the model’s performance. The above approaches have been applied to several well-known and widely used benchmark problems with promising results...|$|R
5000|$|Application of <b>probabilistic</b> <b>neural</b> <b>networks</b> to {{population}} pharmacokineties.|$|R
40|$|One of {{the most}} {{frequently}} used models for classification tasks is the <b>Probabilistic</b> <b>Neural</b> <b>Network.</b> Several improvements of the <b>Probabilistic</b> <b>Neural</b> <b>Network</b> have been proposed such as the Evolutionary <b>Probabilistic</b> <b>Neural</b> <b>Network</b> that employs the Particle Swarm Optimization stochastic algorithm for the proper selection of its spread (smoothing) parameters and the prior probabilities. To further improve its performance, a fuzz...|$|E
40|$|The paper {{proposes a}} wavelet <b>probabilistic</b> <b>neural</b> <b>network</b> (WPNN) for iris {{biometric}} classifier. The WPNN combines wavelet neural network and <b>probabilistic</b> <b>neural</b> <b>network</b> {{for a new}} classifier model which {{will be able to}} improve the biometrics recognition accuracy as well as the global system performance. A simple and fast training algorithm, particle swarm optimization (PSO), is also introduced for training the wavelet <b>probabilistic</b> <b>neural</b> <b>network.</b> In iris matching, the CASIA iris database is used and the experimental results show that the feasibility and performance of the proposed method. 1...|$|E
40|$|Abstract. One of {{the most}} {{frequently}} used models for classification tasks is the <b>Probabilistic</b> <b>Neural</b> <b>Network.</b> Several improvements of the <b>Probabilistic</b> <b>Neural</b> <b>Network</b> have been proposed such as the Evolutionary <b>Probabilistic</b> <b>Neural</b> <b>Network</b> that employs the Particle Swarm Optimization stochastic algorithm for the proper selection of its spread (smoothing) parameters and the prior probabilities. To further improve its performance, a fuzzy class membership function has been incorporated for the weighting of its pattern layer neurons. For each neuron of the pattern layer, a fuzzy class membership weight is computed and it is multiplied to its output in order to magnify or decrease the neuron’s signal when applicable. Moreover, a novel scheme for multi–class problems is proposed since the fuzzy membership function can be incorporated only in binary classification tasks. The proposed model is entitled Fuzzy Evolutionary <b>Probabilistic</b> <b>Neural</b> <b>Network</b> and is applied to several realworld benchmark problem with promising results. ...|$|E
5000|$|<b>Probabilistic</b> <b>Neural</b> <b>Networks</b> in Solving Different Pattern Classification Problems.|$|R
5000|$|... <b>probabilistic</b> <b>neural</b> <b>networks</b> in {{modelling}} structural {{deterioration of}} stormwater pipes.|$|R
5000|$|... <b>probabilistic</b> <b>neural</b> <b>networks</b> {{method to}} gastric {{endoscope}} samples diagnosis based on FTIR spectroscopy.|$|R
40|$|<b>Probabilistic</b> <b>Neural</b> <b>Network</b> {{approach}} used for mobile adhoc network {{is more efficient}} way to estimate the network security. In this paper, we are using an Adhoc On Demand Distance Vector (AODV) protocol based mobile adhoc network. In our Proposed Method we are considering the multiple characteristics of nodes. In this we use all the parameter that is necessary in AODV. For simulation purpose we use the <b>probabilistic</b> <b>neural</b> <b>network</b> approach that gives more efficient and accurate results as comparison to the clustering algorithm in the previous systems was used. The performance of PNN (<b>probabilistic</b> <b>neural</b> <b>network)</b> approach is improved  for identifying the particular attack like as wormholes, black holes  and selfis...|$|E
40|$|A self {{adaptive}} <b>probabilistic</b> <b>neural</b> <b>network</b> {{model is}} proposed. The model incorporates the Particle Swarm Optimization algorithm {{to optimize the}} spread parameter of the <b>probabilistic</b> <b>neural</b> <b>network,</b> enhancing thus its perfor- mance. The proposed approach is tested on two data sets from the eld of bioinformatics, with promising results. The performance of the proposed model is compared to probabilistic neura...|$|E
40|$|Abstract. In fault {{diagnosis}} of three-phase induction motors, traditional methods usually fail {{because of the}} complex system of three-phase induction motors. Short circuit is a very common stator fault in all the faults of three-phase induction motors. <b>Probabilistic</b> <b>neural</b> <b>network</b> {{is a kind of}} artificial neural network which is widely used due to its fast training and simple structure. In this paper, the diagnosis method based on <b>probabilistic</b> <b>neural</b> <b>network</b> is proposed to deal with stator short circuits. First, the principle and structure of <b>probabilistic</b> <b>neural</b> <b>network</b> is studied in this paper. Second, the method of fault setting and fault feature extraction of three-phase induction motors is proposed {{on the basis of the}} {{fault diagnosis}} of stator short circuits. Then the establishment of the diagnosis model based on <b>probabilistic</b> <b>neural</b> <b>network</b> is illustrated with details. At last, training and simulation tests are done for the model. And simulation results show that this method is very practical with its high accuracy and fast speed...|$|E
40|$|<b>Neural</b> <b>networks</b> {{are very}} often {{applied to the}} pattern {{recognition}} problem. In 1990 D. Specht introduced a special class of <b>Probabilistic</b> <b>Neural</b> <b>Networks</b> which were unnoticed in the computational practice due to their extremely large computer memory requirement. In this note we present and discuss results of experiments assessing the usability of <b>Probabilistic</b> <b>Neural</b> <b>Networks</b> to the multifont recognition problem for large size of the training set...|$|R
50|$|Version 4.0 {{incorporates}} Kohonen {{networks that}} can be trained without supervision and <b>probabilistic</b> <b>neural</b> <b>networks.</b>|$|R
5000|$|<b>Probabilistic</b> <b>Neural</b> <b>Networks</b> to the Class Prediction of Leukemia and Embryonal Tumor of Central Nervous System.|$|R
40|$|In this paper, <b>Probabilistic</b> <b>Neural</b> <b>Network</b> with {{image and}} data {{processing}} techniques {{was employed to}} implement an automated brain tumor classification. The conventional method for medical resonance brain images classification and tumors detection is by human inspection. Operator-assisted classification methods are impractical for large amounts of data and are also non-reproducible. Medical Resonance images contain a noise caused by operator performance {{which can lead to}} serious inaccuracies classification. The use of artificial intelligent techniques for instant, neural networks, and fuzzy logic shown great potential in this field. Hence, in this paper the <b>Probabilistic</b> <b>Neural</b> <b>Network</b> was applied for the purposes. Decision making was performed in two stages: feature extraction using the principal component analysis and the <b>Probabilistic</b> <b>Neural</b> <b>Network</b> (PNN). The performance of the PNN classifier was evaluated in terms of training performance and classification accuracies. <b>Probabilistic</b> <b>Neural</b> <b>Network</b> gives fast and accurate classification and is a promising tool for classification of the tumors...|$|E
40|$|Abstract: <b>Probabilistic</b> <b>Neural</b> <b>Network</b> {{approach}} used for mobile adhoc network {{is more efficient}} way to estimate the network security. In this paper, we are using an Adhoc On Demand Distance Vector (AODV) protocol based mobile adhoc network. In our Proposed Method we are considering the multiple characteristics of nodes. In this we use all the parameter that is necessary in AODV. For simulation purpose we use the <b>probabilistic</b> <b>neural</b> <b>network</b> approach that gives more efficient and accurate results as comparison to the clustering algorithm in the previous systems was used. The performance of PNN (<b>probabilistic</b> <b>neural</b> <b>network)</b> approach is improved for identifying the particular attack like as wormholes, black holes and selfish...|$|E
40|$|In this paper, {{we present}} the {{mathematical}} foundations of a <b>probabilistic</b> <b>neural</b> <b>network</b> for gene selection and classification of high-dimensional microarray data. We present {{a catalogue of}} features that a classification system for microarray data should incorporate. We then use this catalogue and compare the theoretical properties of probabilistic neural networks with support vector machines {{with regard to their}} suitability for multiclass cancer prediction. We compare the classification performance of a <b>probabilistic</b> <b>neural</b> <b>network</b> with the performance of a support vector machine on a multiclass microarray data set. The results of the theoretical and practical comparison suggest that the <b>probabilistic</b> <b>neural</b> <b>network</b> approach is to be preferred over support vector machines for multiclass cancer classification using microarray data...|$|E
30|$|In this paper, the <b>probabilistic</b> <b>neural</b> <b>networks</b> (PNNs) and {{generalized}} boosted {{regression model}} (GBM) were employed for lithofacies classification and core permeability estimation, respectively.|$|R
40|$|In {{this paper}} we {{introduce}} a theoretical approach for representing rule based system using <b>Probabilistic</b> <b>Neural</b> <b>Networks</b> (PNN). The proposed scheme is inspired from the statistical algorithm kernel discriminant analysis {{where there are}} four layers and works with feed forward network. This proposed approach is implemented in an algorithm called PNN-RBS. The purpose of the algorithm is to represent rule based systems using <b>probabilistic</b> <b>neural</b> <b>networks.</b> This mechanism {{is used to have}} a rule based system machine learning approach {{and to be able to}} produce results for unknown cases in the knowledge base. Also the approach should be capable of adding or removing new rules without retraining for the <b>neural</b> <b>network...</b>|$|R
40|$|Abstract:- In this paper, {{a system}} for {{automatic}} classification of musical instrument sounds is introduced. As features mel-frequency cepstral coefficients and as classifiers <b>probabilistic</b> <b>neural</b> <b>networks</b> are used. The experimental dataset included 4548 solo tones from 19 instruments of MIS database (The University of Iowa Musical Instrument Samples). Experiments for different system structures (hierarchical and direct classification) were carried out and compared. The best performance in direct classification was 92 % for individual instruments and 97 % for families; and 89 % for individual instruments when hierarchical approach is used. Key-Words:- Musical instrument classification, <b>probabilistic</b> <b>neural</b> <b>networks,</b> PNN...|$|R
40|$|Taking {{into account}} that {{transaction}} prices are realized at the bid or the ask price, we propose a <b>probabilistic</b> <b>neural</b> <b>network</b> model and a Bayesian rule to predict the incoming order signal of a stock and its probability using the buy-sell trade indicator or trade direction sign. We consider {{that if there is}} any private information to be inferred from trade, agents can use a trade equation to form an expectation about the future trade based on the trade and quote revision history. In addition, we use it to analyse the classification and forecasting capacity of various discrete regression and <b>probabilistic</b> <b>neural</b> <b>network</b> models to estimate the probability of an incoming order signal by means of statistical and economic criteria. Our results indicate that the <b>probabilistic</b> <b>neural</b> <b>network</b> classifies and predicts slightly better than linear, Probit and MLP models for short forecast horizons, among other statistical criteria, and reversed trades with respect to the economic assessment of the negotiation for both short and long forecast horizons. Buy-sell trade indicator, Qualitative variable models, <b>Probabilistic</b> <b>neural</b> <b>network</b> model,...|$|E
40|$|Abstract—Probabilistic {{neural network}} {{compared}} with the traditional BP neural network structure is simpler and it is faster to be identificated, so it is widely used {{in the field of}} pattern recognition. This paper is mainly focused on similar gesture recognition research, propose an <b>probabilistic</b> <b>neural</b> <b>network</b> gesture recognition algorithm. The simulation results show that the improved <b>probabilistic</b> <b>neural</b> <b>network</b> algorithm on the recognition rate and training time is better than the traditional BP network...|$|E
40|$|The {{modified}} <b>probabilistic</b> <b>neural</b> <b>network</b> for nonlinear {{time series}} analysis was developed and introduced in 1991. It effectively represents a simple family of clustering methods for reducing the size of Specht's general regression neural network and retaining all its benefits. Three hardware implementation schemes for the most basic form of the modified <b>probabilistic</b> <b>neural</b> <b>network</b> are described. The first is an optoelectronic implementation {{and the other two}} are very large scale integration designs: a virtual implementation and a fully parallel implementation...|$|E
40|$|This paper {{introduces}} Locally Recurrent <b>Probabilistic</b> <b>Neural</b> <b>Networks</b> (LRPNN) as {{an extension}} of the well-known <b>Probabilistic</b> <b>Neural</b> <b>Networks</b> (PNN). A LRPNN, in contrast to a PNN, is sensitive to the context in which events occur, and therefore, identification of time or spatial correlations is attainable. Besides the definition of the LRPNN architecture a fast three-step training method is proposed. The first two steps are identical to the training of traditional PNNs, while the third step is based on the Differential Evolution optimization method. Finally, the superiority of LRPNNs over PNNs on the task of text-independent speaker verification is demonstrated. 1...|$|R
40|$|The {{purpose of}} this paper is to develop an {{intelligent}} diagnosis system for breast cancer classification. Artificial <b>Neural</b> <b>Networks</b> and Support Vector Machines were being developed to classify the benign and malignant of breast tumor in fine needle aspiration cytology. First the features were extracted from 92 FNAC image. Then these features were presented to several <b>neural</b> <b>network</b> architectures to investigate the most suitable network model for classifying the tumor effectively. Four classification models were used namely multilayer perceptron (MLP) using back-propagation algorithm, <b>probabilistic</b> <b>neural</b> <b>networks</b> (PNN), learning vector quantization (LVQ) and support vector machine (SVM). The classification results were obtained using 10 -fold cross validation. The performance of the networks was compared based on resulted error rate, correct rate, sensitivity and specificity. The method was evaluated using six different datasets including four datasets related to our work and two other benchmark datasets for comparison. The optimum network for classification of breast cancer cells was found using <b>probabilistic</b> <b>neural</b> <b>networks.</b> This is followed in order by support vector machine, learning vector quantization and multilayer perceptron. The results showed that the predictive ability of <b>probabilistic</b> <b>neural</b> <b>networks</b> and support vector machine are stronger than the others in all evaluated datasets...|$|R
40|$|Abstract—This paper {{presents}} power disturbance recognition using discrete {{wavelet transform}} (DWT) and <b>probabilistic</b> <b>neural</b> <b>networks</b> (PNN). The DWT is first used {{to extract the}} features of the power disturbances. The Parseval theory is utilized to calculate the energy of each level so that the number of coefficients can be reduced; then, the extracted results are used for recognition by the PNN. Further, the Matlab and LabVIEW are used to generate the power disturbance waveforms for testing. From testing results, the recognition rate is at least 86 %. It proves the feasibility of the proposed method. Index Terms—Discrete wavelet transforms (DWT), <b>probabilistic</b> <b>neural</b> <b>networks</b> (PNN), Parseval theory. I...|$|R
40|$|As a {{recently}} developed and powerful classification tool, <b>probabilistic</b> <b>neural</b> <b>network</b> {{was used to}} distinguish cancer patients from healthy persons according to the levels of nucleosides in human urine. Two datasets (containing 32 and 50 patterns, respectively) were investigated and the total consistency rate obtained was 100 % for dataset 1 and 94 % for dataset 2. To evaluate the performance of <b>probabilistic</b> <b>neural</b> <b>network,</b> linear discriminant analysis and learning vector quantization network, were also applied to the classification problem. The {{results showed that the}} predictive ability of the <b>probabilistic</b> <b>neural</b> <b>network</b> is stronger than the others in this study. Moreover, the recognition rate for dataset 2 can achieve to 100 % if combining, these three methods together, which indicated the promising potential of clinical diagnosis by combining different methods. (C) 2002 Elsevier Science B. V. All rights reserved...|$|E
3000|$|We {{propose a}} method for indoor versus outdoor scene {{classification}} using a <b>probabilistic</b> <b>neural</b> <b>network</b> (PNN). The scene is initially segmented (unsupervised) using fuzzy [...]...|$|E
40|$|A network {{structure}} for segmenting magnetic resonance medical images is proposed. The incorporation of a <b>probabilistic</b> <b>neural</b> <b>network</b> structure into the segmentation process allows decisions regarding {{the characterization of}} each pixel {{to be made in}} a probabilistic manner, thus reducing the effect of an incorrect decision early in the process on the final segmentation result. The <b>probabilistic</b> <b>neural</b> <b>network</b> facilitates the generation of likelihood estimates for use in an iterative segmentation process, which was shown to produce good segmentation results on real magnetic resonance images...|$|E
40|$|This article {{details the}} effect of Gaussian {{smoothing}} parameter (spread) {{on the performance of}} <b>Probabilistic</b> <b>Neural</b> <b>Networks</b> (PNN). Two (2) different Genetic Algorithms (GAs) were used to optimize the PNN spread in order to avoid under and over fitting. In this work there is a novel combination of Cellular <b>Neural</b> <b>Networks</b> (CNN), <b>Probabilistic</b> <b>Neural</b> <b>Networks</b> (PNN) and GA to address the present challenges on automatic identification of plant species. Such problems include misclassification species of plants that are similar in shapes and image segmentation speed. In this work, GA was used in both feature selection and PNN parameter optimization. The GA developed herein improved the performance of the PNN. This work serves as a framework for building image classification or pattern recognition system...|$|R
40|$|Abstract. To improve speaker {{verification}} performance, we {{extend the}} wellknown <b>Probabilistic</b> <b>Neural</b> <b>Networks</b> (PNN) to Locally Recurrent <b>Probabilistic</b> <b>Neural</b> <b>Networks</b> (LRPNN). In contrast to PNNs that possess no feedbacks, LRPNNs incorporate internal {{connections to the}} past outputs of all recurrent neurons, which render them sensitive to {{the context in which}} events occur. Thus, LRPNNs are capable of identifying time and spatial correlations. A fast three-step method is proposed for training an LRPNN. The first two steps are identical to the training of traditional PNNs, while the third step is based on the Differential Evolution optimization method. The performance of the proposed LRPNNs is compared with that of the PNNs on the task of text-independent speaker verification. ...|$|R
40|$|In {{this note}} we present and discuss results of {{experiments}} comparing {{the performance of}} six <b>neural</b> <b>network</b> architectures (back propagation, recurrent network with dampened feedback, network with multiple hidden layers each with a different activation function, jump connection <b>networks,</b> <b>probabilistic</b> <b>neural</b> <b>networks</b> and general regression <b>neural</b> <b>networks)</b> applied to a simplified multi-font recognition problem...|$|R
