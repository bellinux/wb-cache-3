1|29|Public
40|$|Nitric oxide planar laser-induced {{fluorescence}} (NO PLIF) {{has been}} used to visualize the flow on the aft-body of an entry capsule having an activated RCS jet in NASA Langley Research Center's 31 -Inch Mach 10 wind tunnel facility. A capsule shape representative of the Apollo command module was tested. These tests were performed to demonstrate the ability of the PLIF method to visualize RCS jet flow while providing some preliminary input to NASA's Orion Vehicle design team. Two different RCS nozzle designs - conical and contoured - were tested. The conical and contoured nozzles had area ratios of 13. 4 and 22. 5 respectively. The conical nozzle had a half-angle of 10. Low- and high-Reynolds number cases were investigated by changing the tunnel stagnation pressure from 350 psi to 1300 psi, resulting in freestream Reynolds numbers of 0. 56 and 1. 8 million per foot respectively. For both of these cases, three different jet plenum pressures were tested (nominally 56, 250 and 500 psi). A single angle-of-attack was investigated (24 degrees). NO PLIF uses an ultraviolet laser sheet to interrogate a slice in the flow containing seeded NO; this UV light excites fluorescence from the NO molecules which is detected by a high-speed digital camera. The system has spatial resolution of about 200 microns (2 <b>pixel</b> <b>blurring)</b> and has flow-stopping time resolution (approximately 1 microsecond). NO was seeded into the flow two different ways. First, the RCS jet fluid was seeded with approximately 1 - 5 % NO, with the balance N 2. This allowed observation of the shape, structure and trajectory of the RCS jets. Visualizations of both laminar and turbulent flow jet features were obtained. Visualizations were obtained with the tunnel operating at Mach 10 and also with the test section held at a constant pressure similar to the aftbody static pressure (0. 04 psi) obtained during tunnel runs. These two conditions are called "tunnel on" and "tunnel off" respectively. Second, the forebody flow was seeded with a very low flowrate (< 100 standard cubic centimeters per minute) of pure NO. This trace gas was entrained into and allowed visualization of the shear layer forming between the expansion fan on the shoulder of the model and the recirculating separated flow {{in the wake of the}} model. This shear layer was observed to be laminar in the absence of the RCS jet operation and turbulent above a certain RCS jet flowrate. Furthermore, the operation of the RCS jet is seen to push the shear layer out away from the model, with a higher jet pressures resulting in larger deflections. Figures show some data from this test, partially processed. In the final paper, these images will be processed and rendered on a three dimensional visualization of the test hardware for clearer visualization and interpretation of the flowfields...|$|E
50|$|The {{multiplex}} technique does introduce two limitations as well. In {{the case}} of imaging, the signals must not be changing faster than the Nyquist time constant implied by the difference frequency between adjacent pixels. If it does do the <b>pixels</b> <b>blur</b> or alias. (For non-imaging applications—such as when one is simply trying to collect more light but {{is limited by the}} spatial incoherence—that aliasing is not important since it doesn't change the incoherent sum of the pixels.) Additionally, when one is working near the shot noise limit the multiplex approach can raise the noise floor since all of the pixels see the shot noise from the whole array (since they all are connected by the same wire). (Again for non-imaging applications this may not be important).|$|R
5000|$|This script file can {{be opened}} in most media players (such as Windows Media Player). The program {{will play the}} video file [...] "myAvi.avi" [...] cropped down to its top-left 320 pixels by 240 <b>pixels</b> and <b>blurred</b> by a small amount. Operations occur in {{sequential}} order, so the cropping occurs first, then the blurring.|$|R
40|$|Integrated CMOS Active Pixel Sensor (APS) arrays {{have been}} {{fabricated}} and tested using X-ray and electron sources. The 128 by 128 pixel arrays, designed {{in a standard}} 0. 25 micron process, use a {approx} 10 micron epitaxial silicon layer as a deep detection region. The epitaxial layer has a much greater thickness than the surface features used by standard CMOS APS, leading to stronger signals and potentially better signal-to-noise ratio (SNR). On the other hand, minority carriers confined within the epitaxial region may diffuse to neighboring <b>pixels,</b> <b>blur</b> images and reduce peak signal intensity. But for low-rate, sparse-event images, centroid analysis of this diffusion {{may be used to}} increase position resolution. Careful trade-offs involving pixel size and sense-node area verses capacitance must be made to optimize overall performance. The prototype sensor arrays, therefore, include a range of different pixel designs, including different APS circuits and a range of different epitaxial layer contact structures. The fabricated arrays were tested with 1. 5 GeV electrons and Fe- 55 X-ray sources, yielding a measured noise of 13 electrons RMS and an SNR for single Fe- 55 X-rays of greater than 38...|$|R
40|$|Approved {{for public}} release; {{distribution}} in unlimited. Pressure-sensitive paint measurement on a transonic compressor rotor required the prior development of phase-locked cumulative imaging using a disk- rotor {{driven by a}} high-speed Hamilton-Standard turbine as a developmental test- bed. The turbine was installed in a protective housing in the Gas Dynamics Laboratory and connected to an 8000 cu ft, 300 psi air supply. An hydraulic pump provided bearing lubrication. A once per revolution trigger signal was produced from a light-emitting diode and PIN photodiode pair. The imaging system consisted of an intensified CCD video camera externally triggered by the 1 /rev signal via a waveform shaping circuit designed for the present application. Images were captured at camera gate speeds calculated to eliminate <b>pixel</b> <b>blur</b> and image integration times were varied to optimize image intensity and spatial resolution. Structural and modal analyses of the disk-rotor were conducted and a simplified numerical model of the flow was computed. Ratioed, colored images were produced for wheel speeds to 20, 000 RPM. The effect of the radially varying stagnation temperature was evident, underscoring the importance of quantifying and accounting for the PSP temperature sensitivity so that quantitative pressure data may be obtained. Recommendations for a follow-on program are reported[URL] United States Nav...|$|R
50|$|Pixels are {{produced}} by writing characters to the screen of the microfilm recorder with a defocused electron beam.The SC2040 used a charactron tube to expose microfilm. In BEFLIX, the electron beam is defocused todraw <b>pixels</b> as <b>blurred</b> character shapes. Characters are selected to create a range of grayscale values for pixels.The microfilm recorder is not connected directly to the 7090, but communicates through magnetic tape. BEFLIX writesthe magnetic tape output on the 7090 and the film recorder reads the tape to create the film output. BEFLIX alsosupports a preview mode where selected frames of the output are written to the line printer.|$|R
50|$|The {{practice}} of product displacement is also frequently seen on reality television programs {{which do not}} have clearance to display the logos or products of non-sponsor companies. This accounts for the frequent appearance of <b>pixel</b> mosaics and <b>blurring</b> of logo T-shirts and other instances on shows such as America's Next Top Model, Survivor, and The Real World.|$|R
40|$|This thesis {{deals with}} issues of image {{interpolation}} between two key frames. Main objectives of the work are design and implementation of application which interpolates images using optical flow estimation based on Farnebäck method. Application computes pictures by two methods, which use two-way interpolation. The first method selects a pixel with neighborhood and the second method selects only <b>pixel</b> and <b>blurs</b> it into a new frame. Testing was carried out on data describing {{the different types of}} movements. If the estimation of optical flow was correct, interpolation was successful, otherwise the interpolated pictures were inaccurate. Especially it was the key frames with a small gradient or with an indeterminate movement...|$|R
40|$|Astronomical {{instruments}} generally possess spatially variant point-spread functions, which {{determine the}} amount by which an image <b>pixel</b> is <b>blurred</b> {{as a function}} of position. Several techniques have been devised to handle this variability {{in the context of the}} standard image deconvolution problem. We have developed an iterative gravitational lens modeling code called Mirage that determines the parameters of pixelated source intensity distributions for a given lens model. We are able to include the effects of spatially variant point-spread functions using the iterative procedures in this lensing code. In this paper, we discuss the methods to include spatially variant blurring effects and test the results of the algorithm in the context of gravitational lens modeling problems...|$|R
40|$|Fingerprint image {{segmentation}} {{is one of}} the most important steps in automatic fingerprint identification, and it heavily influences the performance of fingerprint identification system. Minutiae are local discontinuities in the fingerprint pattern which represent ends and bifurcations. Because we may extract false minutiae in blurred area, we must classify between foreground and blurred area. In this paper, we propose a novel segmentation algorithm based on three new features which are coherence, contrast and main energy ratio. These three features can present the character of <b>pixels</b> in <b>blurred</b> area and blank area, so we have a significant improvement in fingerprint segmentation performance. We also get the result of classification from a classifier which is a SVM (Support Vector Machine). In order to get an accurate result in classification, a preprocessing is adopted to reduce the influence of noise. Through these three new features we extract and the classifier we select, a robust segmentation of fingerprint images is implemented...|$|R
40|$|Multiframe image superresolution {{has been}} an active {{research}} area for many years. In this approach image processing techniques are used to combine multiple low-resolution (LR) images capturing different views of an object. These multiple images are generally under-sampled, degraded by optical and <b>pixel</b> <b>blurs,</b> and corrupted by measurement noise. We exploit diversities in the imaging channels, namely, the number of cameras, magnification, position, and rotation, to undo degradations. Using an iterative back-projection (IBP) algorithm we quantify the improvements in image fidelity gained by using multiple frames compared to single frame, and discuss effects of system parameters on the reconstruction fidelity. As an example, for {{a system in which}} the pixel size is matched to optical blur size at a moderate detector noise, we can reduce the reconstruction root-mean-square-error by 570 % by using 16 cameras and a large amount of diversity in deployment. We develop a new technique for superresolving binary imagery by incorporating finite-alphabet prior knowledge. We employ a message-passing based algorithm called two-dimensional distributed data detection (2 D 4) to estimate the object pixel likelihoods. We present a novel complexity-reduction technique that makes the algorithm suitable even for channels with support size as large as 5 x 5 object pixels. We compare the performance and complexity of 2 D 4 with that of IBP. In an imaging system with an optical blur spot matched to pixel size, and four 2 x 2 undersampled LR images, the reconstruction error for 2 D 4 is 300 times smaller than that for IBP at a signal-to-noise ratio of 38 dB. We also present a transform-domain superresolution algorithm to efficiently incorporate sparsity as a form of prior knowledge. The prior knowledge that the object is sparse in some domain is incorporated in two ways: first we use the popular L 1 norm as the regularization operator. Secondly we model wavelet coefficients of natural objects using generalized Gaussian densities. The model parameters are learned from a set of training objects and the regularization operator is derived from these parameters. We compare the results from our algorithms with an expectation-maximization (EM) algorithm for L 1 norm minimization and also with the linear minimum mean squared error (LMMSE) estimator...|$|R
40|$|Ubiquitous {{motion blur}} easily fails {{multi-frame}} super-resolution (MFSR). Our method proposed {{in this paper}} tackles this issue by optimally searching least <b>blurred</b> <b>pixels</b> in MFSR. An EM framework is proposed to guide residual blur estimation and high-resolution image reconstruction. To suppress noise, we employ a family of sparse penalties as natural image priors, along with an effective solver. Theo-retical analysis is performed on how and when our method works. The relationship between estimation errors of mo-tion blur {{and the quality of}} input images is discussed. Our method produces sharp and higher-resolution results given input of challenging low-resolution noisy and blurred se-quences. 1...|$|R
40|$|Many {{digital images}} contain blurred regions which {{are caused by}} motion or defocus. Automatic {{detection}} and classification of blurred image regions are very important for different multimedia analyzing tasks. This paper presents a simple and effective automatic image blurred region detection and classification technique. In the proposed technique, blurred image regions are first detected by examining singular value information for each image <b>pixels.</b> The <b>blur</b> types (i. e. motion blur or defocus blur) are then determined based on certain alpha channel constraint that requires neither image deblurring nor blur kernel estimation. Extensive experiments have been conducted over a dataset that consists of 200 blurred image regions and 200 image regions with no blur that are extracted from 100 digital images. Experimental {{results show that the}} proposed technique detects and classifies the two types of image blurs accurately. The proposed technique can be used in many different multimedia analysis applications such as image segmentation, depth estimation and information retrieval. (a) defocus blur image (c) motion blur image (b) image blur map (d) image blur ma...|$|R
30|$|Thus, the upsampled {{depth map}} d(x, y) would be {{affected}} by three major factors with noisy, <b>blurring,</b> and missing <b>pixels</b> [23], where the noise pixels are caused by the distortion of capture devices resulting in unmatched depth, the <b>blurring</b> <b>pixels</b> are produced by interpolation filters mostly along object boundaries, and the missing pixels are mainly originated from the presence of object occlusions and concave objects. Thus, the quality improvement of the upsampled depth map d(x, y) becomes an important task in 3 D visualization applications. In [23], the traditionally enhanced processing generally contains two stages including the suppressing noise and the image-depth enhancement. However, these stages take a high computational complexity and large computational time.|$|R
40|$|Conference Name: 2011 IEEE 3 rd International Conference on Communication Software and Networks, ICCSN 2011. Conference Address: Xi'an, China. Time:May 27, 2011 - May 29, 2011. For the multi-focus image, {{a method}} to {{distinguish}} the focal area and the <b>blur</b> <b>pixels</b> is proposed. The variance of the neighbor pixels of each pixel is calculated and different levels of variance with different weights are denoted where a pixel is in the focal area is estimated by the variance of the neighbor pixels' voting. For the binary matrix, some isolated 0 or 1 to reduce noise is eliminated. Finally, the fusion {{is done by the}} pixels of the focal area of two images. Experimental results show that the proposed method is fast and effective. ? 2011 IEEE...|$|R
40|$|In {{this article}} three {{different}} methods {{for building a}} hierarchical graph from scale space images are discussed. The first method has been suggested by Lifshitz and Pizer [8]. It creates graph structures for image description by defining a linking relationship between <b>pixels</b> in successively <b>blurred</b> versions of the initial image. The second method has been proposed by Kuijper [6]. It uses isointensity surfaces through scale space critical points to find a scale space hierarchy and a ”pre-segmentation ” of the initial image. The third method is a method with similarities to the ”scale space primal sketch ” described by Lindeberg [9]. This algorithm is based on so called attraction areas and it combines the strong points from the two other previously mentioned methods. ...|$|R
40|$|Antialiased {{images are}} delicate; almost any change can cause new {{aliasing}} {{that may be}} visible as ugly artifacts. Localized or non-linear intensity adjustments can cause new image features that are undersampled if applied only to pixels (“pixel distortions”). For example, a threshold function can add jagged edges to any image. Conventional antialiasing methods (distorting the reconstructed image, and then re-sampling) can remove these artifacts, but significantly blur the image, even in regions where no aliasing occurred. Instead, we suppress aliasing by adding “residues ” to distorted pixels. Residues are the antialiased, sampled difference between the distorted continuous image and the reconstructed image made from distorted <b>pixels.</b> Residues never <b>blur</b> needlessly: alias-free <b>pixel</b> distortions produce zero-valued residues. They can improve the final appearance of any nonlinear intensity-modifying operation on images, including gamma correction, NPR processes, and global or local tone mapping methods where intensity changes are severe. OpenGL hardware and short vector libraries can accelerate this antialiasing method for most applications...|$|R
40|$|A Micropattern {{detector}} in {{the focus}} of a grazing incidence telescope is nowadays the most powerful tool to perform a sensitive and reliable measurement of the linear polarization of celestial X-ray sources. The actual implementation of such a completely new device results from a trade-off of various factors and can provide a break-through increase of sensitivity with respect to traditional instrumental approaches. The sensitivity depends on the effective area of the optics and the modulation factor and efficiency of the detector. The latter strongly depends on the filling gas through various factors, including the absorption probability, the length of track versus the <b>pixel</b> size, the <b>blurring</b> introduced by the lateral diffusion during the drift. We discuss the impact of the choice of the filling gas on the sensitivity and on the operative band of the instrument, while the noble gases drive the efficiency, the organic quenching gases impact both in reducing the scattering and producing most straight tracks and on reducing diffusion. Some design solution are discussed both for a low energy oriented and high energy oriented polarimeters...|$|R
40|$|Abstract—Crucial {{information}} {{barely visible}} to the human eye is often embedded {{in a series of}} low resolution images taken of the same scene. Super resolution reconstruction is the process of combining several low resolution images into a single higher resolution image. The ideal algorithm should be fast, and should add sharpness and details, both at edges and in regions without adding artifacts. In this paper we propose a super resolution blind reconstruction technique for linearly degraded images. In our proposed technique the algorithm is divided into three parts an image registration, wavelets based fusion and an image restoration. In this paper three low resolution images are considered which may sub <b>pixels</b> shifted, rotated, <b>blurred</b> or noisy, the sub pixel shifted images are registered using affine transformation model; A wavelet based fusion is performed and the noise is removed using soft thresolding. Our proposed technique reduces blocking artifacts and also smoothens the edges and it is also able to restore high frequency details in an image. Our technique is efficient and computationally fast having clear perspective of real time implementation...|$|R
40|$|End-to-end Electro-Optical system {{performance}} tests such as TOD, MRTD and MTDP require {{the effort of}} several trained human observers, each performing a series of visual judgments on the displayed output of the system. This significantly contributes to the costs of sensor testing. Currently, several synthetic human observer models exist that can replace real human observers in the TOD sensor performance test {{and can be used}} in a TOD based Target Acquisition (TA) model. The reliability that may be expected with such a model is of key importance. In order to systematically test HVS (Human Vision System) models for automated TOD sensor performance testing, two general sets of human observer TOD threshold data were collected. The first set contains TOD data for the unaided human eye. The second set was collected on imagery processed with sensor effects, systematically varying primary sensor parameters such as diffraction <b>blur,</b> <b>pixel</b> pitch, and spatial noise. The set can easily be extended to other sensor effects including dynamic noise, boost, E-zoom, or fused sensor imagery and may serve as a benchmark for competing human vision and sensor performance models...|$|R
30|$|Therefore, {{a robust}} filter for solving both the existed holes and {{flatness}} problems {{is needed to}} improve the performance and reduce the computational complexity as the same time. In this paper, we propose a new algorithm which is called advanced multilateral filter (AMF) to jointly fill the holes and enhance the sharpness of the upsampled depth map d(x, y) and sharpen the image g(x, y) at the same time. Besides, {{the parameters of the}} AMF can be determined according to the accuracy of the depth map and image. The proposed AMF does not require the complicated parameter training, and it is applicable to the practical DIBR applications, which require the robustness against any deformation of images or depth maps. In AMF process, the image and the corresponding depth map are classified based on the designed binary molds first. Excluding the hole regions, the image and the corresponding depth map are smoothed to reduce the noisy and <b>blurring</b> <b>pixels</b> first. Then, the smooth enhancement can degrade the high-frequency noise. Then, the holes are crammed by surrounding neighbors. Finally, after AMF, the rolling guidance refinement (RCR) method is used to sharpen the object edges.|$|R
40|$|Recent {{advances}} in mobile phone cameras have poised {{them to take}} over compact hand-held cameras as the consumer’s preferred camera option. Along with {{advances in}} the number of <b>pixels,</b> motion <b>blur</b> removal, face-tracking, and noise reduction algorithms have significant roles in the internal processing of the devices. An undesired effect of severe noise reduction is the loss of texture (i. e. low-contrast fine details) of the original scene. Current established methods for resolution measurement fail to accurately portray the texture loss incurred in a camera system. The development of an accurate objective method to identify the texture preservation or texture reproduction capability of a camera device is important in this regard. The ‘Dead Leaves’ target has been used extensively as a method to measure the modulation transfer function (MTF) of cameras that employ highly non-linear noise-reduction methods. This stochastic model consists of a series of overlapping circles with radii r distributed as r− 3, and having uniformly distributed gray level, which gives an accurate model of occlusion in a natural setting and hence mimics a natural scene. This target can be used to model the texture transfer through a camera system when a natural scene is captured. In the first part of our study we identify various factors that affect the MTF measured using the ‘Dead Leaves’ chart. These include variations in illumination, distance, exposure time and ISO sensitivity among others. We discuss the main differences of this method with the existing resolution measurement techniques and identify the advantages. In the second part of this study, we propose an improvement to the current texture MTF measurement algorithm. High frequency residual noise in the processed image contains the same frequency content as fine texture detail, and is sometimes reported as such, thereby leading to inaccurate results. A wavelet thresholding based denoising technique is utilized for modeling the noise present in the final captured image. This updated noise model is then used for calculating an accurate texture MTF. We present comparative results for both algorithms under various image capture conditions...|$|R
40|$|High {{resolution}}s {{images can}} be reconstructed from several blurred, noisy and down sampled low resolution images using a computational process know as super resolution reconstruction. The ideal algorithm should be fast, and should add sharpness and details, both at edges and in regions without adding artifacts. In this {{paper we propose a}} super resolution reconstruction technique for linearly degraded images. In our proposed technique the algorithm is divided into three parts an image registration, Lifting wavelet based fusion and an image restoration. Although classical wavelet transform is effective in representing image features, it still encounters problems especially in implementation, e. g. floating-point operation and decomposition speed, which may nicely be solved by lifting scheme. Lifting scheme has such intriguing properties as convenient construction, simple structure, integer-to-integer transform, low computational complexity as well as flexible adaptivity. In this paper three low resolution images are considered which may sub <b>pixels</b> shifted, rotated, <b>blurred</b> or noisy. The images are registered using affine transformation model. A Lifting wavelet based fusion is performed and the noise is removed using soft thresholding. Our proposed technique reduces blocking artifacts and also smoothens the edges and it is also able to restore high frequency details in an image. Our technique is efficient and computationally fast having clear perspective of real time implementation...|$|R
40|$|Images from dual {{detector}} positron emission mammography (PEM) {{systems are}} commonly reconstructed by backprojection methods of classical tomography. Characteristics of three-dimensional (3 -D) PEM images were investigated using analytic models, computer simulations, and experimental acquisitions with compact pixellated detectors, in particular depth resolution normal to the detectors. An analytic formula was developed using circular image <b>pixels</b> that models <b>blurring</b> normal to the detectors. The amount of blurring {{is dependent on}} the acceptance angle for coincidence events and may vary across the field of view due to geometric limitations on the maximum angle of lines of response normal to the detectors. For experimental acquisitions with line sources and a pixellated lutetium gadolinium oxyorthosilicate (LGSO) detector, depth resolution is broader than predicted by numerical simulations, possibly due to uncorrected randoms or scatter within the scintillator arrays. Iterative image reconstruction with the maximum likelihood expectation maximization (MLEM) algorithm of a compressed breast phantom acquisition with a pixellated gadolinium oxyorthosilicate (GSO) detector shows improved contract compared with backprojection reconstruction. Image reconstruction for dual detector PEM with static detectors represents a case of limited angle tomography with truncated projection data, and there is the opportunity to improve three-dimensional PEM imaging by the use of more sophisticated image reconstruction techniques...|$|R
40|$|International audienceSubpixel {{accuracy}} {{image registration}} {{is needed for}} applications such as digital elevation model extraction, change detection, pan-sharpening, and data fusion. In order to achieve this accuracy, the deformation between the two images to be registered is usually modeled by a displacement vector field which can be estimated by measuring rigid local shifts for each pixel in the image. In order to measure subpixel shifts, one uses image resampling. Sampling theory says that, if a continuous signal has been sampled according to the Nyquist criterion, a perfect con- tinuous reconstruction {{can be obtained from}} the sampled version. Therefore, a shifted version of a sampled signal can be obtained by interpolation and resampling with a shifted origin. Since only a sampled version of the shifted signal is needed, the reconstruction needs only to be performed for the new positions of the samples, so the whole procedure comes to computing the value of the signal for the new sample positions. In the case of image registration, the similarity between the reference image and the shifted ver- sions of the image to be registered is measured, assuming that the maximum of similarity determines the most likely shift. The image interpolation step is thus performed a high number of times during the similarity optimization procedure. In order to reduce the computation cost, approximate interpolations are performed. Approximate interpolators will introduce errors in the resampled image which may induce errors in the similarity measure and therefore produce errors in the estimated shifts. In this paper, it is shown that the interpolation has a smoothing effect which depends of the applied shift. This means that, in the case of noisy images, the interpolation has a denoising effect, and therefore, it increases the quality of the similarity estimation. Since this blurring is not the same for every shift, the similarity may be low for a null shift (no blurring) and higher for shifts close to half a <b>pixel</b> (strong <b>blurring).</b> This paper presents an analysis of the behavior of the different interpolators and their effects on the similarity measures. This analysis will be done for the two similarity measures: the cor- relation coefficient and the mutual information. Finally, a strategy to attenuate the interpolation artifacts is proposed...|$|R
40|$|In this work, a {{software}} tool to blur detection was implemented {{in order to}} select the best image-frame {{in a set of}} key frames. The main objective is to allow the detection and measurement of the blurring level of an image without human intervention, i. e. by artificial intelligence trained to detect blur. During the implementation of this Master Thesis, it was necessary to understand the concept of the blur, the causes and the different algorithms to detect local blur. This work uses multiple methods to detect local blur, analysing neighbour's results with different types of filters. Therefore, the solution is a local <b>blur</b> detector at <b>pixel</b> level that generates two images as output, one mask of blurred/sharped pixel areas, and a grey-image with the different levels of <b>blur</b> per <b>pixel.</b> However, the <b>blurring</b> detection is applied in 1 D (one output per single pixel) losing its 2 D position in the image but using the neighbouring pixels' information to convert this method in a 1. 5 D. On the other hand, the decision thresholds to classify the image as blurred or sharp were created by machine learning algorithm based on using Naïve Bayes techniques and Neural Networks solutions, to get a similar result to human blur compression. Finally the result is a stable software able to accomplish the set goals, with an efficiency similar to that of a human person classification...|$|R
40|$|Real world scenes often contain both {{bright and}} dark regions, {{resulting}} in a high contrast ratio, beyond the capabilities of conventional cameras. For these cases, High Dynamic Range or HDR images can be captured with expensive hardware or by taking multiple exposures of the same scene. However, these methods cost extra resources — either spatial or temporal resolution is sacrificed, or more than one piece of hardware is needed. In this thesis, a novel technique is presented {{that is capable of}} capturing High Dynamic Range images in only one exposure of a conventional camera. We observe that most natural HDR images have only 2 – 5 % pixels that are too bright compared {{to the rest of the}} scene to fall inside the dynamic range of a conventional camera. Our method spreads energy from these bright regions into the neighboring unsaturated <b>pixels</b> by defocus <b>blurring.</b> Bright <b>pixels</b> still get clipped in the captured image due to saturation of the sensor; but some information about these clipped pixels gets encoded or multiplexed in the form of superimposed glare patterns in the image. Frequency preservation and decoding of this information can be further improved by using a crossscreen filter instead of using defocus blur. Superimposed glare patterns are recovered with the help of natural image statistics. These glare patterns provide information about how much energy there is in the saturated pixels, which allows a tomography-like reconstruction of the saturated regions. Once the saturated regions are known, the rest of the image can be restored by removing the estimated glare patterns...|$|R
40|$|Abstract- The color visual {{cryptography}} {{methods are}} {{free from the}} limitations of randomness on color images. The two basic ideas used are error diffusion and pixel synchronization. Error diffusion is a simple method, in which the quantization error at each pixel level is filtered and fed as the input to the next pixel. In this way low frequency that is obtained between the input and output image is minimized which in turn give quality images. Degradation of colors are avoided {{with the help of}} pixel synchronization. The proposal of this work presents an efficient color image visual cryptic filtering scheme to improve the image quality on restored original image from visual cryptic shares. The proposed color image visual cryptic filtering scheme presents a deblurring effect on the non-uniform distribution of visual cryptic share <b>pixels.</b> After eliminating <b>blurring</b> effects on the pixels, Fourier transformation is applied to normalize the unevenly transformed share pixels on the original restored image. This in turn improves the quality of restored visual cryptographic image to its optimality. In addition the overlapping portions of the two or multiple visual cryptic shares are filtered out with homogeneity of pixel texture property on the restored original image. Experimentation are conducted with standard synthetic and real data set images, which shows better performance of proposed color image visual cryptic filtering scheme measured in terms of PSNR value (improved to 3 times) and share pixel error rate (reduced to nearly 11 %) with existing grey visual cryptic filters. The results showed that the noise effects such as blurring on the restoration of original image are removed completely...|$|R
40|$|Text, {{as one of}} {{the most}} {{significant}} creations of humankind, has played a vital part in humanoid life, so far from olden periods. High level semantics embodied in the text are beneficial in a wide range of vision-based applications. For example, image understanding, image indexing, geo location, automatic navigation, license plate recognition, assisting blind person and other surveillance applications. There are approaches in the field of content based image retrieval to solve the above mentioned problems. However, these approaches are inadequate to generate annotation based on semantics according to content of video or images due to opening between high level and low level features. Therefore text detection and recognition in videos grow into active and important research areas in computer vision and document analysis, which is capable of understanding the content of video and images at high level with the help of Optical Character Recognizer (OCR). Especially in recent years, the researchers has seen a flow of research efforts and considerable developments in these fields, however many challenges e. g. low resolution, complex background and variations in colors, font, font size, Multi-orientations, Multi-orientation text movements, noise, blur, and distortion still remain. The objectives of this work are in four folds: (1) to introduce a new descriptor called Histogram Oriented Moments (HOM) for detecting multi-oriented text from videos. The HOM is created by considering the orientations calculated with the second order geometrical moments. Further, to verify the detected text, optical flow properties are used to estimate the motion between text candidates in temporal frames. However, the use of temporal information is limited to false positive elimination but not as main features to find text candidates. (2) to propose new models for finding multi-oriented moving text from video and scene images through moments, motion vectors are utilized to identify moving regions that have constant velocity. However, the model is slightly sensitive to window size used for moment‟s calculation and different scripts in video. (3) To develop automatic window size determination for detecting text from videos, the next method explored stroke width transform based on the information that the stroke width remains constant throughout the characters. Further, the temporal frames are used for identifying text candidates based on the fact that caption text stays at the same unchanged location for few frames. However, the performance of the proposed method degrades when there is blur present in the video frames because moments and stroke width transforms are sensitive to blur. (4) To develop a method for text detection and recognition in blur frames, a blind deconvolution model is introduced that enhances the edge sharpness by suppressing <b>blurred</b> <b>pixels.</b> In summary, each work has been tested over benchmark datasets and authors‟ created datasets from different resources using standard measures. Furthermore, the results of the proposed methods are compared with the state of art methods to show that the proposed methods are competent to existing methods...|$|R

