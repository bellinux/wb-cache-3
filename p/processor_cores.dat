1105|1875|Public
5|$|In March 2005, Intel {{announced}} that it was working on a new Itanium processor, codenamed Tukwila, to be released in 2007. Tukwila would have four <b>processor</b> <b>cores</b> and would replace the Itanium bus with a new Common System Interface, which would also be used by a new Xeon processor.|$|E
5|$|Titan has 18,688 nodes (4 nodes per blade, 24 blades per cabinet), each {{containing}} a 16-core AMD Opteron 6274 CPU with 32 GB of DDR3 ECC memory and an Nvidia Tesla K20X GPU with 6 GB GDDR5 ECC memory. There are {{a total of}} 299,008 <b>processor</b> <b>cores,</b> {{and a total of}} 693.6 TiB of CPU and GPU RAM.|$|E
5|$|In 2007, Guinness World Records {{recognized}} Folding@home as {{the most}} powerful distributed computing network. As of September 30, 2014, the project has 107,708 active CPU cores and 63,977 active GPUs for a total of 40.190 x86 petaFLOPS (19.282 native petaFLOPS). At the same time, the combined efforts of all distributed computing projects under BOINC totals 7.924 petaFLOPS. In November 2012, Folding@home updated its accounting of FLOPS, especially for GPUs, and now reports the number of active <b>processor</b> <b>cores</b> and physical processors. Using the Markov state model method, Folding@home achieves strong scaling across its user base and gains a linear speedup for every added processor. This network allows Folding@home to do work that was formerly impractical computationally.|$|E
2500|$|Amber (<b>processor</b> <b>core)</b> – an {{open-source}} ARM-compatible <b>processor</b> <b>core</b> ...|$|R
5000|$|Amber (<b>processor</b> <b>core)</b> - an {{open-source}} ARM-compatible <b>processor</b> <b>core</b> ...|$|R
5000|$|Aptiv: microAptiv (compact, {{real-time}} embedded <b>processor</b> <b>core),</b> interAptiv (multiprocessor, multi-threaded core with a nine-stage pipeline), proAptiv (super-scalar, deeply out-of-order <b>processor</b> <b>core</b> {{with high}} CoreMark/MHz score) ...|$|R
25|$|Samsung - for high-speed, {{low power}} <b>processor</b> <b>cores.</b>|$|E
25|$|An American {{research}} team uses the world's most powerful supercomputer {{at the time}} – the IBM Sequoia – to perform a record-breaking computation, modelling an experimental jet engine on over one million <b>processor</b> <b>cores.</b>|$|E
25|$|Intel's Larrabee {{multicore}} architecture project uses {{a processor}} core {{derived from a}} P5 core (P54C), augmented by multithreading, 64-bit instructions, and a 16-wide vector processing unit. Intel's low-powered Bonnell microarchitecture employed in early Atom <b>processor</b> <b>cores</b> also uses an in-order dual pipeline similar to P5.|$|E
5000|$|... a microcontroller, {{microprocessor}} or {{digital signal}} <b>processor</b> (DSP) <b>core</b> - multiprocessor SoCs (MPSoC) {{have more than}} one <b>processor</b> <b>core</b> ...|$|R
50|$|The above {{method was}} used to {{schedule}} each AMD Phenom <b>processor</b> <b>core</b> in a defined power envelope. The <b>processors</b> <b>core</b> gets suspended when the core exceeds the available power envelope and it becomes available again when enough power becomes available.|$|R
50|$|The NXP LPC1000 family {{consists}} of five series of microcontrollers: LPC1800, LPC1700, LPC1300, LPC1200, LPC1100. The LPC1800, LPC1700, LPC1300 series {{are based on}} the Cortex-M3 ARM <b>processor</b> <b>core.</b> The LPC1200 and LPC1100 {{are based on the}} Cortex-M0 ARM <b>processor</b> <b>core.</b>|$|R
500|$|The Mac Pro {{is in the}} Unix {{workstation}} market. Although {{the high-end}} technical market has not traditionally been an area of strength for Apple, {{the company has been}} positioning itself as a leader in non-linear digital editing for high-definition video, which demands storage and memory far in excess of a general desktop machine. Additionally, the codecs used in these applications are generally processor intensive and highly threadable, which Apple's ProRes white paper describes as scaling almost linearly with additional <b>processor</b> <b>cores.</b> Apple's previous machine aimed at this market, the Power Mac G5, has up to two dual-core processors (marketed as [...] "Quad-Core"), but lacks the storage expansion capabilities of the newer design.|$|E
500|$|The lead {{visual effects}} company was Weta Digital in Wellington, New Zealand, {{at one point}} {{employing}} 900 people {{to work on the}} film. Because of the huge amount of data which needed to be stored, cataloged and available for everybody involved, even {{on the other side of}} the world, a new cloud computing and Digital Asset Management (DAM) system named Gaia was created by Microsoft especially for Avatar, which allowed the crews to keep track of and coordinate all stages in the digital processing. To render Avatar, Weta used a [...] server farm making use of 4,000 Hewlett-Packard servers with 35,000 <b>processor</b> <b>cores</b> with 104 terabytes of RAM and three petabytes of network area storage running Ubuntu Linux, Grid Engine cluster manager, and 2 of the animation software and managers, Pixar's RenderMan and Pixar's Alfred queue management system. The render farm occupies the 193rd to 197th spots in the TOP500 list of the world's most powerful supercomputers. A new texturing and paint software system, called Mari, was developed by The Foundry in cooperation with Weta. Creating the Na'vi characters and the virtual world of Pandora required over a petabyte of digital storage, and each minute of the final footage for Avatar occupies 17.28 gigabytes of storage. Often, it would take each frame of the movie several hours to render. To help finish preparing the special effects sequences on time, a number of other companies were brought on board, including Industrial Light & Magic, which worked alongside Weta Digital to create the battle sequences. ILM was responsible for the visual effects for many of the film's specialized vehicles and devised a new way to make CGI explosions. Joe Letteri was the film's visual effects general supervisor.|$|E
2500|$|The Core Computational Facility has [...] three {{data centers}} occupying over , with over 250 servers totalling over 10.5 TB of RAM, {{distributed}} {{over more than}} 2650 <b>processor</b> <b>cores.</b> It has a storage area network with over 1 PB of disk and 3 PB of tape, expandable to 50 PB.|$|E
50|$|AMD K10, AMD's next {{generation}} <b>processor</b> <b>core.</b>|$|R
5000|$|Superscalar, out-of-order 32-bit/64-bit Power Architecture <b>processor</b> <b>core</b> ...|$|R
40|$|Abstract: Programming {{multicore}} {{systems is}} currently considered very difficult. One {{reason is that}} those are mostly constructed from the hardware point of view. Many of the <b>processor</b> <b>core</b> design solutions in contemporary constructions emphasize execution speed of a single thread. Since the memory access delay is the real bottleneck, such techniques often aim at maximizing cache hits by programmer guided locality of memory references and prefetching memory locations, etc. In this paper, we consider constructing <b>processor</b> <b>core</b> solutions that support easy-to-use programming approach based on the PRAM model. Specifically, we consider a <b>processor</b> <b>core</b> design of a multicore system, where {{the aim is to}} amortize the memory access delays by having multiple simultaneous executable software threads per each <b>processor</b> <b>core.</b> The core switches the executed extremely light-weight thread at each step, and thus the core can wait for pending memory requests to complete without any penalty (as long as it has non-blocked threads). Moreover, we consider the core to support moving threads paradigm instead of traditional moving data paradigm. We present an outline of such a <b>processor</b> <b>core</b> architecture, where we change the traditional pipelined execution model of RISC...|$|R
2500|$|The DSP ASE is an {{optional}} extension to the MIPS32/MIPS64 Release2 and newer instruction sets {{which can be}} used to accelerate a large range of [...] "media" [...] computations—particularly audio and video. The DSP module comprises a set of instructions and state in the integer pipeline and requires minimal additional logic to implement in MIPS <b>processor</b> <b>cores.</b> Revision 2 of the ASE was introduced {{in the second half of}} 2006. This revision adds extra instructions to the original ASE, but is otherwise backwards-compatible with it.|$|E
2500|$|Visual Studio 2010 {{comes with}} [...]NET Framework 4 and {{supports}} developing applications targeting Windows 7. It supports IBM DB2 and Oracle databases, {{in addition to}} Microsoft SQL Server. It has integrated support for developing Microsoft Silverlight applications, including an interactive designer. Visual Studio 2010 offers several tools to make parallel programming simpler: {{in addition to the}} Parallel Extensions for the [...]NET Framework and the Parallel Patterns Library for native code, Visual Studio 2010 includes tools for debugging parallel applications. The new tools allow the visualization of parallel Tasks and their runtime stacks. Tools for profiling parallel applications can be used for visualization of thread wait-times and thread migrations across <b>processor</b> <b>cores.</b> Intel and Microsoft have jointly pledged support for a new Concurrency Runtime in Visual Studio 2010 ...|$|E
2500|$|Although {{the sensor}} unit was {{originally}} planned {{to contain a}} microprocessor that would perform operations such as the system's skeletal mapping, it was revealed in January 2010 that the sensor would no longer feature a dedicated processor. Instead, processing would be handled {{by one of the}} <b>processor</b> <b>cores</b> of Xbox 360's Xenon CPU. According to Alex Kipman, Kinect system consumes about 10-15% of Xbox 360's computing resources. However, in November, Alex Kipman made a statement that [...] "the new motion control tech now only uses a single-digit percentage of Xbox 360's processing power, down from the previously stated 10 to 15 percent." [...] A number of observers commented that the computational load required for Kinect makes the addition of Kinect functionality to pre-existing games through software updates even less likely, with concepts specific to Kinect more likely to be the focus for developers using the platform.|$|E
50|$|Manually {{written and}} {{attached}} to the required <b>processor</b> <b>core.</b>|$|R
5000|$|... four-way superscalar, out-of-order execution, 64-bit MIPS {{architecture}} <b>processor</b> <b>core</b> ...|$|R
50|$|The LPC2200 {{series are}} based on the ARM7TDMI-S <b>processor</b> <b>core.</b>|$|R
5000|$|It has {{multi-core}} {{processors and}} graphics co-processors, with an inter-process communication speed of 40 gigabits per second. According to specifications available of the system, the cluster {{consists of a}} [...] "66 NODE supercomputer with 30,992 <b>processor</b> <b>cores,</b> 2 head nodes (16 <b>processor</b> <b>cores),</b> 32 dual quad core computer nodes (256 <b>processor</b> <b>cores)</b> and 32 Nvidia computing processors. Each processor has 960 <b>processor</b> <b>cores</b> (30,720 <b>processor</b> <b>cores),</b> QDR InfiniBand interconnection and 21.6 TB SAN storage." ...|$|E
50|$|Multi-core {{computers}} are built around {{two or more}} <b>processor</b> <b>cores</b> integrated on a single integrated circuit die. They are widely used across many application domains including general-purpose computing.Explicit Multi-Threading (XMT) is a computing paradigm for building and programming multi-core computers with tens, {{hundreds or thousands of}} <b>processor</b> <b>cores.</b>|$|E
50|$|Customers {{can choose}} to license only {{a subset of the}} <b>processor</b> <b>cores</b> in the Oracle Database Appliance. This is done by {{disabling}} unnecessary <b>processor</b> <b>cores</b> in the BIOS, using a special interface. Cores can be enabled at a later time, allowing customers to increase the capacity of the appliance if required.|$|E
50|$|The LPC2900 {{series are}} based on the ARM968E-S <b>processor</b> <b>core.</b>|$|R
50|$|The LPC3200 {{series are}} based on the ARM926EJ-S <b>processor</b> <b>core.</b>|$|R
5000|$|Amber (<b>processor</b> <b>core)</b> - an ARM-compatible RISC central {{processing}} unit ...|$|R
5000|$|The MIPS <b>processor</b> <b>cores</b> {{are divided}} by Imagination into three major families: ...|$|E
5000|$|Native (all <b>processor</b> <b>cores</b> on {{a single}} die) quad- and octa-core {{processors}} ...|$|E
50|$|Grand Central Dispatch {{uses the}} {{multiple}} <b>processor</b> <b>cores</b> now in every new Macintosh for more efficient performance. Due to the technical difficulties traditionally {{involved in making}} applications optimized for multicore CPUs, the majority of computer applications do not effectively use multiple <b>processor</b> <b>cores.</b> As a result, processing power often goes unused. Grand Central Dispatch includes APIs to help programmers efficiently use these cores for parallel programming.|$|E
5000|$|... #Caption: Microarchitecture of a <b>processor</b> <b>core</b> in the quad-core {{implementation}} ...|$|R
40|$|We {{present a}} {{hardened}} RTL <b>processor</b> <b>core</b> based on Leon 2. Modifications are done at RT-level to achieve high configurability {{in an early}} stage of the development process. The main parts of the <b>processor</b> <b>core</b> can be protected against Single Event Upsets and Single Event Transients. Results and tradeoffs are presented and discussed...|$|R
5000|$|Nordic NRF51 (Series SoC family, 32-bit ARM Cortex M0 <b>processor</b> <b>core)</b> ...|$|R
