13|76|Public
40|$|The average B hadron {{lifetime}} {{was measured}} using data collected with the SLD detector at the SLC in 1993. From a sample of ∼ 50, 000 Z 0 events, a sample enriched in Z 0 → bb was selected by applying an impact <b>parameter</b> <b>tag.</b> The lifetime was extracted from the decay length distribution of inclusive vertices reconstructed in three dimensions. A binned maximum likelihood method yielded an average B hadron lifetime of τB = 1. 577 ± 0. 032 (stat.) ± 0. 046 (syst.) ps...|$|E
40|$|Using {{an impact}} <b>parameter</b> <b>tag</b> to select an enriched sample of @ ~ bb events, we have {{measured}} {{the difference between}} the average charged multiplicity of 2 ° ~ b ~ and 2 ° ~ hadrons to be ~b – ~hd = 2. 24 + 0. 30 (stat.) + 0. 33 (syst.) tracks per event. From this, we have derived ~b – ~tis = 3. 31 + 0. 41 + 0. 79. Comparing this measurement with those at lower center-of-mass energies, we find no evidence that ~b – ~~ ~ depends on energy, in agreement with a precise prediction of perturbative QCD...|$|E
40|$|We have {{measured}} the average B hadron lifetime from 2 ’ + b 6 events using the Mark II detector at the SLC. We use an impact <b>parameter</b> <b>tag,</b> requiring {{two or more}} tracks with significant impact parameter (S) in a hemisphere, to obtain a 40 % efficiency and an 80 % B-purity. The CS distribution from charged tracks in the hemisphere opposite the tag is used to fit for rb. From 53 tagged B decays we find rb = 1. 63 +~:~~(stat) fO. lG(syst) psec (preliminary), consistent with the world average. This method can be competitive with rb measurements using high J’T leptons and has a different sensitivity to r(B+) /r(BO). 1...|$|E
50|$|MPGL—a set {{of tools}} {{designed}} to simplify creation of UNIX manual pages using a lightweight XML syntax consisting of a subset of XHTML plus section <b>tags,</b> <b>parameter</b> <b>tags,</b> etc. HeaderDoc also provides a bridging tool that helps generate manual pages from header comments for functions via HeaderDoc's XML output mode.|$|R
5000|$|Estimating natural {{mortality}} (M) {{is one of}} {{the most}} difficult and critical elements of a stock assessment (Hewitt et al. 2007).There are two basic approaches used to estimate natural mortality: tagging studies and growth <b>parameters.</b> <b>Tagging</b> studies are used in the Brownie Model, where multiyear tagging studies are used to estimate natural mortality based on recaptures: ...|$|R
40|$|We present {{measurements}} of Rb using the SLD at the SLC. The analyses use 2 D and 3 D impact <b>parameter</b> <b>tags</b> and a displaced 3 D vertex tag which all exploit {{the small size}} and stability of the e(+) e(-) interaction point and the precision 3 D CCD pixel vertex detector to achieve high -tagging efficiencies and purities. The combined measurement yields R(b) = 0. 229 +/- 0. 011 and is consistent with standard model predictions...|$|R
40|$|Using {{an impact}} <b>parameter</b> <b>tag</b> to select an enriched sample of Z → b b events, we have {{measured}} {{the difference between}} the average charged multiplicity of Z → b b and Z^ 0 → hadrons to be n_b - n_had = 2. 24 ± 0. 30 (stat.) ± 0. 33 (syst.) tracks per event. From this, we have derived n_b - n_uds = 3. 31 ± 0. 41 ± 0. 79. Comparing this measurement with those at lower center-of-mass energies, we find no evidence that n_b - n_uds depends on energy. This result is in agreement with a precise prediction of perturbative QCD, and supports the notion that QCD remains asymptotically free down to the scale M_b^ 2. Comment: 15 pages (in Phyzzx) and two figures (uuencoded compressed EPS files), Physical Review Letters Volume 72, 3145 (May 1994), SLAC preprint SLAC-PUB- 6372 (as revised for Physical Review Letters...|$|E
40|$|The b b {{forward-backward}} asymmetry {{has been}} determined from the average charge flow measured {{in a sample of}} 3, 500, 000 hadronic Z decays collected with the DELPHI detector in 1992 - 1995. The measurement is performed in an enriched b b sample selected using an impact <b>parameter</b> <b>tag</b> and results in the following values for the b b forward-backward asymmetry: AFBbb (89. 55 GeV) = 0. 068 ± 0. 018 (stat.) ± 0. 0013 (syst.) AFBbb (91. 26 GeV) = 0. 0982 ± 0. 0047 (stat.) ± 0. 0016 (syst.) AFBbb (92. 94 GeV) = 0. 123 ± 0. 016 (stat.) ± 0. 0027 (syst.) The b b charge separation required for this analysis is directly measured in the b tagged sample, while the other charge separations are obtained from a fragmentation model precisely calibrated to data. The effective weak mixing angle is deduced from the measurement to be: sin 2 θeffl= 0. 23186 ± 0. 0008...|$|E
40|$|A novel {{method is}} {{used to measure the}} b quark {{forward-backward}} asymmetry at the Z pole on a sample of 2, 636, 000 hadronic events collected with the DELPHI detector in 1992 to 1995. An enhanced impact <b>parameter</b> <b>tag</b> is applied to the data to obtain a high purity b sample. For each event hemisphere the charge of the corresponding quark or anti-quark is determined using a neural network tag which combines in an optimal way the full available charge information from the vertex charge, the jet charge and from identified leptons and hadrons. The probability to identify b quarks and anti-quarks correctly is calibrated on the data themselves comparing the rates of double hemisphere tagged like-sign and unlike-sign events. The b quark forward-backward asymmetry is determined from the differential asymmetry taking small corrections due to hemisphere correlations and background contributions into account. The result is:     (91. 26 GeV) = 0. 0931 ± 0. 0034 (stat.) ± 0. 0015 (syst.) ± 0. 0039 (inst.) The effective weak mixing angle is deduced from the measurement to be:                       sin 2  Θ l eff = 0. 23287 ± 0. 0009...|$|E
5000|$|In earlier {{versions}} of AmigaOS, if a system call required setting {{a large number of}} parameters, instead of passing them as function arguments, the function would require a pointer to a structure that holds the arguments (for example, intuition.library's [...] required [...] with 17 different <b>parameters).</b> <b>Tags</b> were introduced in AmigaOS 2.0 because they [...] "make it possible to add new parameters to system functions without interfering with the original parameters. They also make specifying parameter lists much clearer and easier." ...|$|R
40|$|Abstract — In this paper, we {{analyze the}} effect of Gen 2 {{protocol}} <b>parameters</b> on RFID <b>tag</b> performance (tag sensitivity and backscatter efficiency). We describe our measurement methodology and perform characterization of several tags with different latest Gen 2 ICs available on the market (Monza, UCODE, and Higgs families). To confirm our findings, we repeat measurements using conducted tag setup. We analyze data and draw conclusions on how the protocol <b>parameters</b> affect the <b>tag</b> performance in forward and reverse links. I...|$|R
40|$|Abstract-We have {{measured}} {{the fraction of}} b 6 events in hadronic Z ” decays, Rbb, using the vertex detector system of the Mark II detector at the SLC. We tag bb events by requiring at least three tracks with significant impact <b>parameters.</b> This <b>tag</b> is 50 % efficient and results {{in a sample of}} 85 % purity We find R,b = 0. 251 f 0. 049 f 0. 030, in good agreement with other measurements and the Standard Model prediction...|$|R
40|$|The Efetimes of B “ and B+ mesons {{have been}} {{measured}} using {{a sample of}} 150, 000 hadronic 20 ’s co~ected by the SLD experiment at the SLC between 1993 and 1995. Two analyses are presented. The first identifies semileptonic decays of B mesons with high (p, pt) leptons and reconstructs the B meson decay length and charge by vertexing the lepton with a partially reconstructed D meson. This method results {{in a sample of}} 428 (549) neutral (charged) decays with high charge purity. A maximum Hkehhood fit procedure finds: TBO = 1. 603 ~:~~(stat) + O. lo(syst) ps, 7 B ~ = 1. 49 ~~:~~(stat) + o. 05 (syst) ps, + o. 07 (syst). The second analysis isolates a sample of B meson decays with a 2 -D impact <b>parameter</b> <b>tag</b> and reconstructs the decay length and charge using a novel topological vertex reconstruction method. This results in a high statistics sample of 3382 (5303) neutral (charged) decays with good charge purity. A maximum likelihood fit procedure finds: TBO = 1. 55 + 0. 07 (stat) + 0. 12 (syst) ps, 7 Bt = 1. 67 + 0. 06 (stat) + 0. 09 (syst) ps...|$|E
40|$|A novel high {{precision}} method measures the b-quark forward-backward asymmetry at the Z pole on {{a sample of}} 3, 560, 890 hadronic events collected with the DELPHI detector in 1992 to 2000. An enhanced impact <b>parameter</b> <b>tag</b> provides a high purity b sample. For event hemispheres with a reconstructed secondary vertex the charge of the corresponding quark or anti-quark is determined using a neural network which combines in an optimal way the full available charge information from the vertex charge, the jet charge and from identified leptons and hadrons. The probability of correctly identifying b-quarks and anti-quarks is measured on the data themselves comparing the rates of double hemisphere tagged like-sign and unlike-sign events. The b-quark forward-backward asymmetry is determined from the differential asymmetry, taking small corrections due to hemisphere correlations and background contributions into account. The results for different centre-of-mass energies are: A(FB) (b) (89. 449 GeV) = 0. 0637 +/- 0. 0143 (stat.) +/- 0. 0017 (syst.), A(FB) (b) (91. 231 GeV) = 0. 0958 +/- 0. 0032 (stat.) +/- 0. 0014 (syst.), A(FB) (b) (92. 990 GeV) = 0. 1041 +/- 0. 0115 (stat.) +/- 0. 0024 (syst.). Combining these results yields the b-quark pole asymmetry A(FB) (b 0) = 0. 0972 +/- 0. 0030 (stat.) +/- 0. 0014 (syst.) ...|$|E
40|$|Using {{an impact}} <b>parameter</b> <b>tag</b> to select an enriched sample of Z 0 → bb events, {{and the net}} momentum-weighted track charge to {{identify}} {{the sign of the}} charge of the underlying b quark, we have measured the left-right forward-backward asymmetry for b quark production as a function of polar angle. Based on 1. 8 pb − 1 of Z 0 decay data produced with a mean electron beam polarization of Pe = 63 %, this yields a direct measurement of the extent of parity violation in the Zbb coupling of Ab = 0. 87 ± 0. 11 (stat.) ± 0. 09 (syst.). 2 Measurements of fermion production asymmetries at the Z 0 pole provide probes of the combination of vector (v) and axial vector (a) couplings Af = 2 vfaf/(v 2 f +a 2 f), which express the extent of parity violation in the Zff coupling. At Born level, the Z 0 peak differential cross section for producing a final state fermion f at an angle z = cos θ from the electron beam direction is σ f (z) ≡ dσf/dz ∝ (1 − AePe) (1 + z 2) + 2 Af(Ae−Pe) z, (1) where Pe is the longitudinal polarization of the electron beam. By manipulatin...|$|E
40|$|International Telemetering Conference Proceedings / October 22 - 25, 1984 / Riviera Hotel, Las Vegas, NevadaThe {{introduction}} of Data Compressors into the NWC Telemetry Ground Station {{has created the}} opportunity to circumvent usage of data distribution patch panels. An array of Word Selectors {{can be used to}} capture telemetry data <b>parameters</b> by <b>tag</b> identification for display on chart recorders. Design goals in the development include: independent operation, resident program storage, variable word length handling, and accommodation of nonstandard data formats. A prototype has been constructed and tested...|$|R
50|$|The click tag {{enables the}} ad serving network to gain metrics {{such as the}} amount of clicks and from which sites these clicks have been made. By reading the data gained by the click <b>tag</b> <b>parameter,</b> an {{advertiser}} can evaluate how effective the ad campaign has been.|$|R
50|$|In programming, a tag is an {{argument}} to a subroutine that determines other arguments passed to it, which {{is used as a}} way to pass indefinite number of <b>tagged</b> <b>parameters</b> to the subroutine; notably, tags are used for a number of system calls in AmigaOS v2.0 and onwards.|$|R
40|$|The bb {{forward-backward}} asymmetry {{has been}} determined from the average charge how measured {{in a sample of}} 3, 500, 000 hadronic Z decays collected with the DELPHI detector in 1992 - 1995. The measurement is performed in an enriched b (b) over bar sample selected using an impact <b>parameter</b> <b>tag</b> and results in the following values for the bl; forward-backward asymmetry: A(FB) (b (b) over bar) (89. 55 GeV) = 0. 068 +/- 0. 016 (stat.) +/- 0. 0013 (syst.) A(FB) (b (b) over bar) (91. 26 GeV) = 0. 0982 +/- 0. 0047 (stat.) +/- 0. 0016 (syst.) A(FB) (b (b) over bar) (92. 94 GeV) = 0. 123 +/- 0. 016 (stat.) +/- 0. 0027 (syst.) The b (b) over bar charge separation required for this analysis is directly measured in the b tagged sample, while the other charge separations are obtained from a fragmentation model precisely calibrated to data. The effective weak mixing angle is deduced from the measurement to be: sin(2) theta(eff) 1 = 0. 23186 +/- 0. 00063. RI De Angelis, Alessandro/B- 5372 - 2009; Gonzalez Caballero, Isidro/E- 7354 - 2010; Krammer, Manfred/A- 6508 - 2010; Muresan, Raluca-Anca/C- 3725 - 2011; Katsanevas, Stavros/A- 4297 - 2011; Ruiz, Alberto/E- 4473 - 2011; Marti-Garcia, Salvador/F- 3085 - 2011; Verzi, Valerio/B- 1149 - 2012; branchini, paolo/A- 4857 - 2011; Shellard, Ronald/G- 4825 - 2012; Monge, Maria Roberta/G- 9127 - 2012; Petrolini, Alessandro/H- 3782 - 2011; Fruhwirth, Rudolf/H- 2529 - 201...|$|E
40|$|We have {{measured}} the bottom hadron lifetime from bb events produced at the 2 ’ resonance. Using the precision vertex detectors of the Mark II detector at the Stanford Linear Collider, we developed an impact <b>parameter</b> <b>tag</b> to identify bottom hadrons. The vertex tracking system resolved impact parameters to 30 l. tm for high momentum tracks, and 70 lrn for tracks with a momentum of 1 GeV. We selected B hadrons with an efficiency of 40 % and a sample purity of 80 %, by requiring there {{be at least}} two tracks in a single jet that significantly miss the 2 ’ decay vertex. From a total of 208 hadronic 2 ’ events collected by the Mark II detector in 1990, we tagged 53 jets, of which 22 came from 11 double-tagged events. The jets opposite the tagged ones, referred as the “untagged ” sample, are rich in B hadrons and unbiased in B decay times. The variable C 6 {{is the sum of}} impact parameters from ‘tracks in the jet, and contains vital information on the B decay time [...] _ We {{measured the}} B lifetime from a one-parameter likelihood fit to the untagged C 6 distribution, obtaining which agrees with the current world average. The first error is statistical and the second is systematic. The systematic error was dominated by uncertainties in the. - track resolution function. As a check, we also obtained consistent results using the C 6 distribution from the tagged jets and from the entire hadronic sample without any bottom enrichment. ii-. I do not know what I may appear to the world, but to myself I seem to have been only like a boy playing on the sea-shore, and diverting myself in now and then finding a smoother pebble or a prettier shell than ordinary, whilst the great ocean of truth lay all undiscovered before me. [...] ...|$|E
40|$|Contents 1 Introduction 2 2 Petri nets 2 3 The toolkit TimeNET 5 3. 1 Objects of the {{graphical}} editor................... 5 3. 1. 1 Graphical objects (Petri net components)......... 5 3. 1. 2 Textual objects (<b>parameter</b> and <b>tags)...........</b> 7 3. 2 The commands........................... 8 3. 3 File operations........................... 10 3. 4 Additional editor features..................... 11 3. 5 Validation.............................. 12 3. 6 Evaluation.............................. 14 3. 7 Further options........................... 24 3. 8 Characteristics of DDSPNs..................... 24 4 Example 26 4. 1 Model of {{cyclic sampling}} of sensor data.............. 26 4. 2 Model construction..................... ...|$|R
40|$|We have {{measured}} {{the fraction of}} bb» events in hadronic Z 0 decays, Rbb», using the vertex detector system of the Mark II detector at the SLAC Linear Collider. We tag bb» events by requiring the coincidence of three or more tracks with significant impact <b>parameters.</b> This <b>tag</b> is 50 % efficient and results {{in a sample of}} 85 % purity. We find Rbb»= 0. 251 + 0. 049 + 0. 030, in good agreement with other measurements and the standard model prediction. © 1991 The American Physical Society...|$|R
5000|$|An {{example of}} a {{multi-function}} LAEME tool is the Concordance. Users begin by selecting a tag type (suffixes, grammatical words, inflection, lexis), entering a search string, and then a position limiter (initial, medial, final). This search {{is followed by a}} filter set allowing users to specify counties, number of words to precede and/or proceed the search string, and sorting <b>parameters</b> (form, <b>tag,</b> date, file). Finally, users may select specific tagged forms generated by the search. Entries in the resulting concordance link to manuscript descriptions and to corresponding text dictionaries. [...] Users are able to view contextualized instances of items indexed to coded sources available in several file types. Similar processes can be used to create Tag and Form Dictionaries with frequency counts, and to generate Feature Maps.|$|R
40|$|Use of tags {{to limit}} partner {{selection}} for playing {{has been shown}} to produce stable cooperation in agent populations playing the Prisoner’s Dilemma game. There is, however, a lack of understanding of how and why tags facilitate such cooperation. We start with an empirical investigation that identifies the key dynamics that result in sustainable cooperation in PD. Sufficiently long tags are needed to achieve this effect. A theoretical analysis shows that multiple simulation <b>parameters</b> including <b>tag</b> length, mutation rate and population size will have significant effect on sustaining cooperation. Experiments partially validate these observations. Additionally, we claim that tags only promote mimicking and not coordinated behavior in general, i. e., tags can promote cooperation only if cooperation requires identical actions from all group members. We illustrate the failure of the tag model to sustain cooperation by experimenting with domains where agents need to take complementary actions to maximize payoff...|$|R
40|$|SUMMARY Radio {{frequency}} identification (RFID) enables everyday {{objects to}} be identified, tracked, and recorded. The RFID tags are must be extremely simple and of low cost to {{be suitable for}} large scale application. An efficient RFID anti-collision mechanism must have low access latency and low power consumption. This paper investigates how to recognize multiple RFID tags within the reader’s interrogation ranges without knowing the number of tags in advance by using framed ALOHA. To optimize power consumption and overall tag read time, a combinatory model was proposed to analyze both passive and active tags with consideration on capture effect over wireless fading channels. By using the model, the <b>parameters</b> on <b>tag</b> set estimation and frame size update were presented. Simulations were conducted to verify the analysis. In addition, {{we come up with}} a proposal to combat capture effect in deterministic anti-collision algorithms. key words: RFID, anti-collision, framed ALOHA, low energy 1...|$|R
40|$|The design, development, installation, and {{operation}} of the test equipment (MRVS) is discussed. The main feature of the MRVS is continuous recording on an instrumentation recorder data of up to 1500 parameters with a total sample rate of up to 10, 000 samples per second. In order to compress the evaluation and calibration time period, the following additional requirements were set for two test systems: (1) recording of selected <b>parameters,</b> time <b>tagged</b> on computer compatible tape (CCT); (2) recording of selected high bandwidth signals and ad hoc parameters on analog tape; (3) onboard presentation of calibrated parameter data, in engineering units, in numerical as well as graphical form for: system checkout during pre-, in- and post-flight, and quick look analysis during in-flight; (4) real time presentation on the ground by telemetry for: flight monitoring, takeoff and landing measurements, and noise measurements; and (5) data processing on the ground on the Fokker-NLR computer network...|$|R
40|$|A {{generalized}} Bayesian {{population dynamics}} model {{was developed for}} analysis of historical mark-recapture studies. The Bayesian approach builds upon existing maximum likelihood methods and is useful when substantial uncertainties exist in the data or little information is available about auxiliary <b>parameters</b> such as <b>tag</b> loss and reporting rates. Movement rates are obtained through Markov-chain Monte-Carlo (MCMC) simulation, which are suitable for use as input in subsequent stock assessment analysis. The mark-recapture model was applied to English sole (Parophrys vetulus) off {{the west coast of}} the United States and Canada and migration rates were estimated to be 2...|$|R
30|$|This {{tag-along}} {{approach has}} a potential {{importance for the}} upcoming VLBI Global Observing System (VGOS), which aims at continuous monitoring of the EOPs. Currently, when the VLBI observations are scheduled, the participating stations are known a priori. When the observations are done in a continuous mode, stations could become available or unavailable at any given time. This dynamical aspect {{needs to be taken}} into account in the scheduling for VGOS observations. Consequently, optimised schedules are only available for the stations that participate regularly and reliably in a given session type. Naturally, rescheduling the observations on-the-fly as stations enter or leave the pool of available sites would yield better results in terms of the optimisation conditions. The concept of dynamical scheduling has been investigated by Lovell et al. (2014). However, this type of dynamic scheduling is still in the future. Furthermore, the observation schedules are optimised to determine a set of target <b>parameters.</b> By <b>tagging</b> along one does not need to interfere with the original purpose of the schedule. This gives prospective stations flexibility in opting in/out in an observing session.|$|R
40|$|A {{road network}} {{is one of}} the core {{elements}} of urban environments, strongly defining their layout. Procedural modeling has been increasingly used to create such road networks. However, many procedural methods are complex and difficult to master by non-experts, often have a limited and hard-to-control expressive range, and require a variety of specialized input data to generate a complex road network. To mitigate this, some methods proposed to use stochastic data on road patches extracted from example maps to design a road network following a given urban style. We propose a novel patch-based method that uses the semantics of individual patches to help guiding the procedural generation. Our approach combines the advantages of patch-based generation with those of conventional parametric-based methods. Due to the intuitive character of semantic <b>parameters</b> and <b>tags,</b> our approach provides for an easy customization of fictive road network creation, allowing a user to easily define various types of road network styles, containing only the desired features and structures of real-world road networks. Electrical Engineering, Mathematics and Computer ScienceIntelligent System...|$|R
40|$|In {{order to}} extract {{results from the}} {{observed}} data {{it is essential to}} accurately model the detector in the Monte Carlo, which requires that the performance of the detector elements be well understood. Of particular concern for the subsequent analyses is the tracking detector system, namely the CDC, DCVD and SSVD. This chapter contains a study of the performance of the combination of the three tracking detectors. The performance of the detectors individually was discussed in Chapter 2. The tracking system characteristics of primary importance in the following analyses are the l impact parameter resolution, and l track finding and reconstruction efficiency, both of which are addressed in this chapter. The impact parameter resolution is of primary importance for determining the efficiency and purity of the enrichment method used for selecting Z ” + bb events. This method, the impact <b>parameter</b> significance <b>tag,</b> is discussed in Chapter 5 and its application to measure the hadronic branching fraction of the Z ” to bb events in Chapter 6. The tracking efficiency is also important, particularly for the multiplicity measurement...|$|R
40|$|The {{study of}} growth and {{distribution}} <b>parameters</b> in <b>tagged</b> carp (Cyprinus carpio) from the canyon-shaped dam reservoirs (Brno and Dalešice) was performed. Altogether, 59 (1. 5 %) and 274 (4. 6 %) individuals from the Brno and Dalešice reservoirs, respectively, were re-captured and documented (by anglers) from originally 4000 and 6000 tagged fish released. The growth performance of tagged fish (two-year-old carp K 2) was only moderate {{during the first year}} after stocking in the Brno reservoir (for time span d 0 -d 360 it corresponds to TL = 304 - 384 mm, w = 497 - 1170 g, and SGR = 0. 2378 %. d- 1), very similar to that in the Dalešice reservoir (d 0 -d 360 TL= 301 - 386 mm, w = 510 - 1215 g and SGR = 0, 2399 %. d- 1). The condition parameters (TL:w and FWC) were very similar as well. Different distributional patterns of the catches were however recorded. The growth performance of carp in the Brno reservoir was lower than expected {{on the basis of its}} altitude and mean annual water temperature...|$|R
5000|$|Their {{software}} utilizes {{log file}} analysis and page tagging. Log analysis reads the files {{in which the}} web server records all its transactions. Via page <b>tagging,</b> <b>parameter</b> name-value pairs are appended (either automatically by a JavaScript [...] "tag" [...] or manual hand-coding) to the query string of a gif image which resides on a data collection server. When a visitor loads the page in a browser, the browser sends a request to the data collection server so that it may load the gif image. The data collection server receives the request and logs the parameters included in the query string of the gif image.|$|R
40|$|In {{the first}} two parts of this study we have {{presented}} a performance analysis of our new Cloud Dynamics and Radiation Database (CDRD) satellite precipitation retrieval algorithm on various convective and stratiform rainfall case studies verified with precision radar ground truth data, and an exposition of the algorithm's detailed design {{in conjunction with a}} proof-of-concept analysis vis-à-vis its theoretical underpinnings. In this third part of the study, we present the underlying analysis used to identify what we refer to as the optimal metrological and geophysical tags, which are the optimally effective atmospheric and geographic parameters that are used to refine the selection of candidate microphysical profiles used for the Bayesian retrieval. These tags enable extending beyond the conventional Cloud Radiation Database (CRD) algorithm by invoking meteorological-geophysical guidance, drawn from a simulated database, which affect and are in congruence with the observed precipitation states. This is guidance beyond the restrictive control provided by only simulated radiative transfer equation (RTE) model-derived database brightness temperature (TB) vector proximity information in seeking to relate physically consistent precipitation profile solutions to individual satellite-observed TB vectors. The first two parts of the study have rigorously demonstrated that the optimal tags effectively mitigate against solution ambiguity, where use of only a CRD framework (TB guidance only) leads to pervasive non-uniqueness problems in finding rainfall solutions. Alternatively, a CDRD framework (TB + tag guidance) mitigates against non-uniqueness problems through improved constraints. It remains to show how these optimal tags are identified. By use of three statistical analysis procedures applied to a database from 120 North American atmospheric simulations of precipitating storms (independent of the 60 simulations for the European-Mediterranean basin region used in the Parts 1 and 2 studies), we examine 25 separate dynamical-thermodynamical-hydrological (DST) and geophysical parameters for their relationships to rainfall variables – specifically, surface rain rate and columnar liquid/ice/total water paths of precipitating hydrometeors. The analysis identifies seven optimal <b>parameter</b> <b>tags</b> which exceed all others in the strengths of their correlations to the precipitation variables but also have observational counterparts in the operational global forecast model outputs. The seven optimal tags are (1 and 2) vertical velocities at 700 and 500 hPa; (3) equivalent potential temperature at surface; (4) convective available potential energy; (5) moisture flux 50 hPa above surface; (6) freezing level height; and (7) terrain height, i. e., surface height...|$|R
40|$|Abstract: The enzymatic {{hydrolysis}} <b>parameters</b> of triacylglycerols (<b>TAGs)</b> in algae oil to get sn- 2 glycerel monostearte including substrate amount, lipase amount and reaction time was studied, and {{the products of}} fatty acid methyl esters (FAMEs) were detected by gas chromatography (GC). The result indicated that the optimum conditions to hydrolyze TAGs in algae oil were as follows: mass ratio of substrate to lipase of 1 : 1, 2 mL Tris-HCl buffer, 0. 2 mL CaCl 2 solution, 0. 5 mL sodium cholate hydrate solution were added in each 30 mg substrate, and reaction time of 1. 5 min with 120 rpm at 40 °C, the highest palmitic acid (PA) content accounted for 9. 1 % of total oil...|$|R
40|$|We compute power {{corrections}} to {{mean values}} of hadronic event shapes - the thrust and the C <b>parameter</b> - of <b>tagged</b> b quark events in electron positron annihilation, using the dispersive approach. We {{find that the}} leading power corrections are of {{the same type of}} 1 /Q corrections as for event shapes in the massless case, with the same non-perturbative coefficient times a perturbatively calculable mass-dependent coefficient. The effect of the mass correction in the power correction is to reduce the latter by 10 - 30 % for tagged b events, for centre-of-mass energies ranging from the Z peak down to 20 GeV. Comment: 14 pages, 4 figures, 1 table, JHEP style a typo in Reference section is correcte...|$|R
40|$|Tag—recapture {{data for}} {{kingfish}} {{obtained from a}} cooperative tagging programme {{were used to assess}} the usefulness of such information for estimating movement and life-history <b>parameters.</b> Numbers <b>tagged</b> and recaptured varied among fishing zones, seasons and years. Recapture rates varied among areas, fishers and sizes of fish. Small fish showed less movement than large fish, but few fish > 1000 mm TL were tagged. The majority of fish were recaptured within 50 km of where they were tagged, although there was an indication that fish that were at large longer moved further. The maximum distance moved was 3000 km and the maximum time at liberty was 1742 days. Quantitative analyses of life-history parameters from data collected in cooperative tagging programmes are generally not possible because there are usually no estimates of fishing effort, tag-related mortality and tag loss. These are likely to vary not only along the coast, but also among taggers. Cooperative tagging programmes provide some useful biological data (e. g. movement from point x to point y, and growth), but dedicated tagging programmes may be needed for estimates of other life-history parameters (e. g. mortality) and of abundance. Bronwyn M. Gillanders, Douglas J. Ferrell and Neil L. Andre...|$|R
