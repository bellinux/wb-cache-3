141|9|Public
25|$|Whenever {{the laptop}} is powered on it can {{participate}} in a mobile ad hoc network (MANET) with each node operating in a <b>peer-to-peer</b> <b>fashion</b> with other laptops it can hear, forwarding packets across the cloud. If a computer in the cloud {{has access to the}} Internet—either directly or indirectly—then all computers in the cloud are able to share that access. The data rate across this network will not be high; however, similar networks, such as the store and forward Motoman project have supported email services to 1000 schoolchildren in Cambodia, according to Negroponte. The data rate should be sufficient for asynchronous network applications (such as email) to communicate outside the cloud; interactive uses, such as web browsing, or high-bandwidth applications, such as video streaming should be possible inside the cloud. The IP assignment for the meshed network is intended to be automatically configured, so no server administrator or an administration of IP addresses is needed.|$|E
5000|$|The Workstation Edition, which {{provides}} remote desktop access directly from one computer {{to another in}} <b>peer-to-peer</b> <b>fashion.</b> It consists of the PROXY Pro Master (viewer) and the PROXY Pro Host (client) and the PROXY Pro Deployment Tool, ...|$|E
50|$|Direct Connect hubs {{are central}} servers to which clients connect, thus the {{networks}} are not as decentralized as Gnutella or FastTrack. Hubs provide information about the clients, as well as file-searching and chat capabilities. File transfers are done directly between clients, in true <b>peer-to-peer</b> <b>fashion.</b>|$|E
40|$|International audienceThe {{efficiency}} of service discovery {{is a crucial}} point {{in the development of}} fully decentralized middlewares intended to manage large scale computational grids. The work conducted on this issue led to the design of many <b>peer-to-peer</b> <b>fashioned</b> approaches. More specifically, the need for flexibility and complexity in the service discovery has seen {{the emergence of a new}} kind of overlays, based on tries, also known as lexicographic trees. Although these overlays are efficient and well designed, they require a costly maintenance and do not accurately take into account the heterogeneity of nodes and the changing popularity of the services requested by users. In this paper, we focus on reducing the cost of the maintenance of a particular architecture, based on a dynamic prefix tree, while enhancing it with some load balancing techniques that dynamically adapt the load of the nodes in order to maximize the throughput of the system. The algorithms developed couple a self-organizing prefix tree overlay with load balancing techniques inspired by similar previous works undertaken for distributed hash tables. After some simulation results showing how our load balancing heuristics perform in such an overlay and compare to other heuristics, we provide a fair comparison of this architecture and similar overlays recently proposed...|$|R
40|$|Also {{available}} as INRIA Research Report 6557 The efficiency of service discovery {{is a crucial}} point {{in the development of}} fully decentralized middlewares intended to manage large scale computational grids. The work conducted on this issue led to the design of many <b>peer-to-peer</b> <b>fashioned</b> approaches. More specifically, the need for flexibility and complexity in the service discovery has seen {{the emergence of a new}} kind of overlays, based on tries, also known as lexicographic trees. Although these overlays are efficient and well designed, they require a costly maintenance and do not accurately take into account the heterogeneity of nodes and the changing popularity of the services requested by users. In this paper, we focus on reducing the cost of the maintenance of a particular architecture, based on a dynamic prefix tree, while enhancing it with some load balancing techniques that dynamically adapt the load of the nodes in order to maximize the throughput of the system. The algorithms developed couple a self-organizing prefix tree overlay with load balancing techniques inspired by similar previous works undertaken for distributed hash tables. After some simulation results showing how our load balancing heuristics perform in such an overlay and compare to other heuristics, we provide a fair comparison of this architecture and similar overlays recently proposed...|$|R
40|$|International audienceSeveral factors still {{hinder the}} {{deployment}} of computational grids over large scale platforms. Among them, the resource discovery is one crucial issue. New approaches, based on peer-to-peer technologies, tackle this issue. Because they efficiently allow range queries, Tries (a. k. a., Prefix Trees) appear to be among promising ways {{in the design of}} distributed data structures indexing resources. Despite their lack of robustness in dynamic settings, trie-structured approaches outperform other <b>peer-to-peer</b> <b>fashioned</b> technologies by efficiently supporting range queries. Within recent trie-based approaches, the fault-tolerance is handled by preventive mechanisms, intensively using replication. However, replication can be very costly in terms of computing and storage resources and does not ensure the recovery of the system after arbitrary failures. Self-stabilization is an efficient approach in the design of reliable solutions for dynamic systems. It ensures a system to converge to its intended behavior, regardless of its initial state, in a finite time. A snap-stabilizing algorithm guarantees that it always behaves according to its specification, once the protocol is launched. In this paper, we provide the first snap-stabilizing protocol for trie construction. We design particular tries called Proper Greatest Common Prefix (PGCP) Tree. The proposed algorithm arranges the n label values stored in the tree, in average, in O(h + h′) rounds, where h and h′ are the initial and final heights of the tree, respectively. In the worst case, the algorithm requires an O(n) extra space on each node, O(n) rounds and O(n 2) actions. However, simulations allow to state that this worst case is far from being reached and to confirm the average complexities, showing the practical efficiency of this protocol...|$|R
5000|$|Microsoft Max was the codename for an {{incubation}} effort {{software application}} developed by Microsoft. It is {{an application for}} creating virtual photograph albums and distributing them online in a <b>peer-to-peer</b> <b>fashion.</b> Features of the Max application included the ability to annotate photos and arrange them in custom layouts, slideshows and a [...] "3D Mantle View," [...] as well as dynamic newspaper-like layouts of RSS feed content.|$|E
5000|$|... iFolder {{operates}} {{on the concept}} of shared folders, where a folder is marked as shared and the contents of the folder are then synchronized to other computers over a network, either directly between computers in a <b>peer-to-peer</b> <b>fashion</b> or through a server. This is intended to allow a single user to synchronize files between different computers (for example between a work computer and a home computer) or share files with other users (for example {{a group of people who}} are collaborating on a project).|$|E
50|$|Koobface {{ultimately}} attempts, upon successful infection, {{to gather}} login information for FTP sites, Facebook, Skype, {{and other social}} media platforms, and any sensitive financial data as well. It then uses compromised computers to build a peer-to-peer botnet. A compromised computer contacts other compromised computers to receive commands in a <b>peer-to-peer</b> <b>fashion.</b> The botnet is used to install additional pay-per-install malware on the compromised computer and hijack search queries to display advertisements. Its peer-to-peer topology {{is also used to}} show fake messages to other users for the purpose of expanding the botnet.It was first detected in December 2008 and a more potent version appeared in March 2009. A study by the Information Warfare Monitor, a joint collaboration from SecDev Group and the Citizen Lab in the Munk School of Global Affairs at the University of Toronto, has revealed that the operators of this scheme have generated over $2 million in revenue from June 2009 to June 2010.|$|E
40|$|International audienceSeveral factors still {{hinder the}} {{deployment}} of computational grids over large scale platforms. Among them, the resource discovery {{is one of the}} crucial issues. New approaches, based on peer- to-peer technologies, tackle this issue. One promising way for indexing resources at large scale is to usetries (a. k. a., prefix trees). Trie-structured approaches outperforms other <b>peer-to-peer</b> <b>fashioned</b> technologies by efficiently supporting range queries. One drawback of using tries is their inherent poor robustness in a dynamic environment, fault-tolerance being a key feature of systems designed to be deployed at large scale. Within re- cent trie-based approaches, the fault-tolerance is handled by preventive mechanisms, intensively using replication. Replication can be very costly in terms of computing and storage resources. Moreover, it does not formally ensure the recovery of the system after arbitrary failures. Self-stabilization is a well known general technique to design distributed systems tolerating arbitrary transient faults. Self-stabilization ensures a system to converge to its intended behavior, regardless of its initial state, in a finite time. Using self-stabilization appears to be a good alternative to inject fault tolerance in peer-to-peer systems. In this purpose, we have designed the first snap-stabilizing distributed algorithm to build a greatest proper common prefix tree (GPCPT) starting from any labeled rooted tree. A snap-stabilizing algorithm guarantees that the system always behaves according to its specification provided that some nodes initiated the algorithm. The proposed algorithm arranges the n label values stored in the tree, in average, in O(h + h′) rounds, where h and h′ are the initial and final heights of the tree, respectively. In the worst case, the algorithm requires an O(n) extra space on a given node, O(n) rounds and O(n 2) operations. However, simulations show that, using relevant data sets, this worst case is far from being reached and confirm the average complexities, making this algorithm efficient in practice...|$|R
40|$|Mobile ad hoc {{networks}} are infrastructure-less networks consisting of wireless, possibly mobile nodes which are organized in <b>peer-to-peer</b> and autonomous <b>fashion.</b> Each node {{is also a}} router that forwards data packets to its proper destination. A new family of algorithms inspired by Swarm Intelligence has come into existence to provide route optimization through routing load distribution. In this paper, we have proposed an Ant based routing algorithm to ensure appropriate load balancing in mobile ad hoc network using AODV and Ant Colony Optimization metaheuristics...|$|R
40|$|International audienceMobile ad hoc {{networks}} are infrastructure-less networks consisting of wireless, possibly mobile nodes which are organized in <b>peer-to-peer</b> and autonomous <b>fashion.</b> The highly dynamic topology, limited bandwidth availability and energy constraints make the routing problem a challenging one. In this paper {{we take a}} novel approach to the routing problem in MANETs by using swarm inteligenceinspired algorithms. The proposed algorithm uses Ant-like agents to discover and maintain paths in a MANET with dynamic topology. We present simulation results that measure the performance of our algorithm {{with respect to the}} characteristics of a MANET, the varying parameters of the algorithm itself as well as performance comparison with other well-known routing protocols...|$|R
50|$|Whenever {{the laptop}} is powered on it can {{participate}} in a mobile ad hoc network (MANET) with each node operating in a <b>peer-to-peer</b> <b>fashion</b> with other laptops it can hear, forwarding packets across the cloud. If a computer in the cloud {{has access to the}} Internet—either directly or indirectly—then all computers in the cloud are able to share that access. The data rate across this network will not be high; however, similar networks, such as the store and forward Motoman project have supported email services to 1000 schoolchildren in Cambodia, according to Negroponte. The data rate should be sufficient for asynchronous network applications (such as email) to communicate outside the cloud; interactive uses, such as web browsing, or high-bandwidth applications, such as video streaming should be possible inside the cloud. The IP assignment for the meshed network is intended to be automatically configured, so no server administrator or an administration of IP addresses is needed.|$|E
50|$|The term live {{distributed}} {{object was}} first used informally {{in a series of}} presentations given in the fall of 2006 at an ICWS conference, STC conference, and at the MSR labs in Redmond, WA, and then formally defined in 2007, in an IEEE Internet Computing article. Originally, the term was used to refer to the types of dynamic, interactive Web content that is not hosted on servers in data centers, but rather stored on the end-user's client computers, and internally powered by instances of reliable multicast protocols. The word live expressed the fact that the displayed information is dynamic, interactive, and represents current, fresh, live content that reflects recent updates made by the users (as opposed to static, read-only, and archival content that has been pre-assembled). The word distributed expressed the fact that the information is not hosted, stored at a server in a data center, but rather, it is replicated among the end-user computers, and updated in a <b>peer-to-peer</b> <b>fashion</b> through a stream of multicast messages that may be produced directly by the end-users consuming the content; a more comprehensive discussion of the live object concept in the context of Web development can be found in Krzysztof Ostrowski's Ph.D. dissertation.|$|E
30|$|Federated domains: {{multiple}} {{actors are}} in charge of managing heterogeneous domains with different loosely integrated SDN controllers interacting to optimize the end-to-end QoS. For instance, telco operators, service providers, and users manage datacenters, access networks, MANETs/VANETs respectively with different SDN controllers interacting in a <b>peer-to-peer</b> <b>fashion.</b>|$|E
40|$|Abstract Updating {{systems for}} {{security}} vulnerabilities {{has become a}} cumbersome yet necessary evil in today’s environment of zero-day exploits and ever-changing threat matrix. The current state of affairs for the vulnerability and threat management functions are {{in dire need of}} a solution that can rapidly assess systems for vulnerabilities and fix them expeditiously. This will guarantee the effective reconnaissance of critical vulnerabilities in a more concise and cohesive fashion throughout all industries affected by the inherent risk in systems and applications, This will also help defend against super-fast worms and other malicious mobile code that can blaze through an organization’s network leaving a path of compromised systems and reduced availability. The top-down centralized model for vulnerability assessment and remediation has proven inefficient and riddled with multiple vulnerabilities itself; the irony is befuddling. In this paper, we propose a framework to enhance an organization’s information security posture by distributedly assessing and remedying system vulnerabilities. By creating and utilizing the proposed framework, we can ensure more vigilance, a progressive and reactive implementation of a patch-management and worm defense strategy, and increased efficiency in the distribution of updates. Malicious mobile code, specifically worms, are very efficient in their distribution, this is because they are able to infect other systems in a <b>peer-to-peer</b> distributed <b>fashion.</b> By utilizing a similar approach to vulnerability assessment and patch management we can ensure a higher coverage and redundancy for all systems within and organization. The framework proposed in this paper is timely since most peer-to-peer distribution models focus more on content delivery and resource allocation. I...|$|R
40|$|Publish/Subscribe (P/S) {{systems and}} file sharing {{applications}} traditionally share the common goal of disseminating data among large populations of users. Despite this similarity, the former focuses on timely dissemination of small-sized notification messages, {{while the latter}} presumes larger types of bulk content with less emphasis on the time needed between release and delivery of data. In this paper, we develop a peer-assisted content dissemination mechanism to {{bridge this gap by}} adopting the P/S model. We propose a hybrid two-layer architecture in which P/S brokers act as coordinators and guide their clients with interest in similar content to engage in direct exchange of data blocks in a <b>peer-to-peer</b> and cooperative <b>fashion.</b> Furthermore, we use network coding in order to facilitate data exchange among clients. Our peer-assisted scheme offloads the burden of disseminating huge volumes of data from P/S brokers to subscribers themselves. As an added advantage of our approach, brokers can employ strategies that helps shape traffic flows in multi-domain network settings. Finally, we have implemented our approach and carried out extensive large-scale experimental evaluation on a cluster with aggregate data transfers of up to 1 TB and involving up to 1000 subscribers. Our results demonstrate good scalability and faster content delivery compared to file sharing protocols such as BitTorrent. 1...|$|R
30|$|Controller {{integration}} {{focuses on}} how multiple SDN controllers, e.g., each one specialized {{for a different}} location, interact on each other to take proper decisions. For instance, SDN controllers can be federated in a tight fashion with a hierarchical architecture or loosely coupled in a <b>peer-to-peer</b> <b>fashion.</b>|$|E
40|$|Mobile device {{communicate}} in <b>peer-to-peer</b> <b>fashion</b> Self-organizing network {{without the need}} of fixed network infrastructure Multi-hop communication Decentralized, mobility-adaptive operation “The art of networking without a network” [Frodigh et al. ] MoMuC 2003 – Tutorial ‚Ad Hoc Networking‘ Chr. Bettstetter, H. Hartenstein, M. MauveApplications: Vehicular Network...|$|E
40|$|The Samoyed project {{deals with}} {{hierarchical}} ad hoc networks, especially ad hoc access networks. In ad hoc access networks, nodes that connect without a preexisting infrastructure in a <b>peer-to-peer</b> <b>fashion</b> form a communicating network that offers wireless mobile devices {{access to a}} fixed network, for example th...|$|E
40|$|Higher {{education}} is not only about transmitting knowledge; it is about becoming {{a member of an}} expert community. Contemporary tools for on-line learning can be used in opening the learning environment and making the learning process more transparent so that the learners can rely on and benefit from each other in <b>peer-to-peer</b> <b>fashion.</b> 1...|$|E
40|$|Web Real-Time Communication (WebRTC) is an {{upcoming}} standard {{that aims to}} enable real-time communication among Web browsers in a <b>peer-to-peer</b> <b>fashion.</b> The IETF RTCWeb and W 3 C WebRTC working groups are jointly defining both the APIs and the underlying communication protocols for setting up and managing a reliable communication channel between any pair of next generation Web browsers...|$|E
3000|$|... {{as in the}} Hyrec {{recommender}} system [54]. Spotify [6] illustrates the reverse case, in which data is indexed on centralized servers (computation) but data transfers occur in a <b>peer-to-peer</b> <b>fashion</b> between users. User interactions may also be exploited to influence data placement, as {{in the work of}} Pujol et al. [55], where the data of a social network is placed according to how users interact with one another.|$|E
3000|$|Federated datacenters: {{multiple}} cloud providers {{manage their}} own datacenters in an independent fashion, but the traffic among datacenters of different cloud providers is engineered by adopting an SDN approach, typically by loosely coupling SDN controllers in a <b>peer-to-peer</b> <b>fashion.</b> In this case, there is the need of opening the borders of datacenters by allowing external cloud vendors to control (or at least to influence) how incoming and outgoing traffic is managed; [...]...|$|E
3000|$|Multiple datacenters with {{distributed}} controllers: {{similarly to}} the previous case, there are multiple datacenters in different locations managed by the same cloud provider. However, each datacenter has its own SDN controller managing the inter-datacenter traffic. SDN controllers are tightly integrated, coordinating one each other to optimize inter-datacenter traffic, e.g., either in a <b>peer-to-peer</b> <b>fashion</b> or adopting a hierarchical architecture, {{in the latter case}} with an SDN controller taking final control decisions; [...]...|$|E
40|$|Peer-reviewedIn {{this paper}} {{we present a}} {{proposal}} of the architecture for a system which allows the deployment of services {{in a group of}} computers, connected in a <b>peer-to-peer</b> <b>fashion.</b> This architecture is divided in layers, and each of them contains some components which offer specific functions. By putting them together, we obtain a system with desirable characteristics such as scalability, decentralization, ability to deal with heterogeneity, fault tolerance, load-balancing, and self-* properties...|$|E
40|$|Abstract—The {{newscast}} algorithm has {{the purpose}} of building a distributed computing system with a random topology where independent nodes can operate in a pure <b>peer-to-peer</b> <b>fashion.</b> The main advantages of this algorithm and the topology it builds are their robustness and efficiency to spread information. This article gives a formal input / output automata model for each node running this algorithm and thus for the entire network. The viability of the algorithm is proved and a solid basis for future development is laid. ...|$|E
40|$|Abstract – Building decentralised Information Retrieval Systems {{is one of}} the key {{challenges}} for the future Internet. These systems will most probably take the shape of open multiagent systems – societies of Information Agents that coordinate in a <b>peer-to-peer</b> <b>fashion.</b> In this paper we first analyse current IR methods so as to identify shortcomings in scalability and personalization of the information services. We then draw upon ideas from peer-to-peer technologies, to determine the requirements, and sketch the structure, of future societies of Information Agents...|$|E
40|$|We {{introduce}} a generic {{framework for the}} distributed execution of combinatorial optimization tasks. Instead of relying on custom hardware (like dedicated parallel machines or clusters), our approach exploits, in a <b>peer-to-peer</b> <b>fashion,</b> the computing and storage power of existing, off-theshelf desktops and servers. Contributions of this paper are {{a description of the}} generic framework, together with a first instantiation based on particle swarm optimization (PSO). Simulation results are shown, proving the efficacy of our distributed PSO algorithm in optimizing a large number of benchmark functions. ...|$|E
40|$|Abstract — We {{propose a}} fault tolerant, {{peer-to-peer}} replication network for synchronizing files across multiple hosts. The proposed topology is constructed by applying existing technologies and tools {{to ensure that}} files are kept synchronized even after subsequent modifications. One of its main advantages {{lies in the fact}} that there is no central authority to coordinate the process, hosts are connected in a <b>peer-to-peer</b> <b>fashion,</b> thus avoiding a single point of failure. Our proposal is intended for use in networks of personal computers where a small number of hosts have to be synchronized...|$|E
40|$|On {{wireless}} computer networks, ad-hoc mode {{is a method}} for wireless devices to directly communicate with each other. Operating in ad-hoc mode allows all wireless devices within range of each other to discover and communicated in <b>peer-to-peer</b> <b>fashion.</b> One main challenge in design of these networks is their vulnerability to security attacks. The growing popularity and widespread applications of wireless networks are directly proportionate to their propensity for security exploitation. In this paper we have discussed about the potential attacks and security issues of routing protocols face by ad-hoc network...|$|E
40|$|The {{collaborative}} {{business process}} can be unreliable when business partners collaborate in a <b>peer-to-peer</b> <b>fashion</b> without central control. An important issue {{that needs to be}} dealt with for any generic solution to manage collaborative business transaction is reliability verification. In this paper, a business collaboration model, choreographical business transaction net (CoBTx-Net) is developed for individual business participants to specify and manage the collaboration. Three reliability properties named time-embedded dead marking freeness, inter-organizational dead marking freeness, and collaborative soundness are defined and exploited to verify reliability based on CoBTx-Net. 8 page(s...|$|E
30|$|Figure 2 also {{illustrates}} {{the fact that}} a large cloud data center may require and be composed of multiple SLA Managers to address issues of scalability. SLA Managers could be distributed across the cloud infrastructure, and also the applications themselves. These managers could communicate, or gossip, in a <b>peer-to-peer</b> <b>fashion,</b> be organized into hierarchies, or into other useful structures. This notion of distributed SLA managers implies that there must also be distributed SLA models by which overall system behavior, and individual application behavior, can be managed. The development and evaluation of such distributed SLA models is an outstanding goal.|$|E
40|$|Virginia, USA We {{introduce}} {{the concept of}} an “open healthcare environment”, which is an electronic domain in which multiple healthcare entities need to interact but do not necessarily have complete knowledge of each other. In this setting, we show that a tool like OC (Open Collaboration), a tool being developed to support a variety of electronic collaboration needs, may be useful. OC is built on the open-source JXTA and MyJXTA toolkits. Group and role information is propagated in a <b>peer-to-peer</b> <b>fashion,</b> and peers can share files and send instant messages to any peer {{who is a member of}} an appropriate group or role...|$|E
40|$|Ad hoc {{networks}} are the special networks formed for specific applications. Operating in ad-hoc mode allows all wireless devices {{within range of}} each other to discover and communicate in a <b>peer-to-peer</b> <b>fashion</b> without involving central access points. Many routing protocols like AODV, DSR etc have been proposed for these networks to find an end to end path between the nodes. These routing protocols are prone to attacks by the malicious nodes. There {{is a need to}} detect and prevent these attacks in a timely manner before destruction of network services. Comment: 14 pages, 7 figures, 1 tabl...|$|E
30|$|Despite the {{hierarchical}} master-slave cluster structure, all the communications {{are done in}} a <b>peer-to-peer</b> <b>fashion</b> between any pair of source and destination stations. Note that the term destination in this context refers to the next-hop destination of a packet (which will be specified by the routing protocol) and not necessarily to its final destination station. Routing {{is out of the}} scope of the basic definition of DQMAN, but any existing routing protocol could be applied on top of DQMAN without any restriction. Therefore, the master just acts as an indirect coordinator of the peer-to-peer communications within the cluster but it has no explicit control on the access to the channel.|$|E
