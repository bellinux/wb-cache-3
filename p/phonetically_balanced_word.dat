6|302|Public
40|$|An {{amplitude}} control technique has been employed {{for use with}} analog voice communication systems, which improves low-level phoneme reception and eliminates the received noise between words and syllables. Tests were conducted on a narrow-band frequency-modulation simplex voice communication channel employing the {{amplitude control}} technique. Presented for both the modified rhyme word tests and the <b>phonetically</b> <b>balanced</b> <b>word</b> tests {{are a series of}} graphical plots of the tests' score distribution, mean, and standard deviation as a function of received carrier-to-noise power density ratio. At low received carrier-to-noise power density ratios, a significant improvement in the intelligibility was obtained. A voice intelligibility improvement of more than 2 dB was obtained for the modified rhyme test words, and a voice intelligibility improvement in excess of 4 dB was obtained for the <b>phonetically</b> <b>balanced</b> <b>word</b> tests...|$|E
40|$|The {{relationship}} between the internal noise environment of helicopters {{and the ability of}} personnel to understand commands and instructions was studied. A test program was conducted to relate speech intelligibility to a standard measurement called Articulation Index. An acoustical simulator was used to provide noise environments typical of Army helicopters. Speech material (command sentences and <b>phonetically</b> <b>balanced</b> <b>word</b> lists) were presented at several voice levels in each helicopter environment. Recommended helicopter internal noise criteria, based on speech communication, were derived and the effectiveness of hearing protection devices were evaluated...|$|E
40|$|Publisher’s {{permission}} requested and denied. Multiple-channel {{electrical stimulation}} of the hearing nerve in conjunction with speech reading has helped two post-lingually deaf patients with total hearing losses understand running speech in every day situations. This has been confirmed using open-set <b>phonetically</b> <b>balanced</b> <b>word</b> tests, where the patients achieved 60 % and 40 % scores with isolated-words and 80 % and 73 % for phonemes-in-isolated words. The tests also showed that the cochlear implant improved word recognition {{by a factor of}} four in one patient and two in another compared with speechreading alone. The speech processor used extracted the voicing frequency and energy and the frequency and energy of the dominant spectral peak in the mid-frequency range. The parameters for voicing determined the rate of stimulation for all electrodes, and the parameters for the dominant spectral peak in the midfrequency range determined the site of electrode stimulation and current level. Restricted Access: This resource is not available from the Digital Repository for copyright reasons. This is a citation and abstract only record...|$|E
40|$|Audiology in general, and {{audiometric}} {{techniques in}} particular, have made commendable {{progress in the}} last few decades. The threshold for pure tones and speech can be accurately established and at subsequent examinations can be confirmed or compared, with a fair amount of precision. The articulation score for <b>phonetically</b> <b>balanced</b> <b>words</b> can be determined and so can the effect of amplification on such scores. The conductive and the cochlear component of hearing loss can be distinguished with a fair amount of reliability from what is called the "sensorineural" or the "retrocochlear component"...|$|R
5000|$|... "Spondee" [...] {{is a piece}} {{composed}} by intelligent dance music (IDM) duo Matmos. It is the third track on their 2001 album A Chance to Cut Is a Chance to Cure. The piece revolves around audio samples from a hearing test: a woman's voice recites two-syllable words, stressing both syllables. Audiologist Rebecca Highlander, CCC-A, reads a list of <b>phonetically</b> <b>balanced</b> <b>words</b> (spondees, with equal stress on {{the first and second}} syllable). Recorded in the hearing test booth at the Jean Weingarden Peninsula Oral School for the Deaf, beeps and tones were generated during the response curve testing of hearing aids.|$|R
30|$|The TMW is Tohoku University-Matsushita Isolated Word Database. It has <b>phonetically</b> <b>balanced</b> 212 <b>words</b> {{that are}} spoken by 60 people (30 males and 30 females). This {{database}} {{was divided into}} the training and testing set. The training set has 40 samples and the test set has 20 samples.|$|R
40|$|Speech {{is one of}} {{the main}} forms of communication, and in {{teaching}} environments is fundamental to transmit the message effectively. Significant amounts of the research that has been undertaken concentrating on measuring and studying the impact of intelligibility on native populations, particularly children. There is also evidence that the acoustic design of a room has impact on the overall student experience. This investigation therefore focuses in the analysis of the possible effects that acoustic design and characteristics of heritage buildings has in higher education environments; with a particular interest in those students whose English is not their first language. Rooms and people with similar characteristics from King's College London; were used as sample for the environmental and subjective evaluation respectively. The speech transmission index was assessed in accordance to BS IEC 60268 - 16 : 2011, while reverberation time was calculated in accordance with the recommendations for precision measurements in accordance to ISO 3382 - 2 : 2008 and ISO 18233 : 2006. The study compares the student experience subjective acoustic evaluation, their test marks with the measured Speech Transmission Index, as well as the result of a <b>phonetically</b> <b>balanced</b> <b>word</b> test. Results will be presented together with analysis as to if intelligibility correlates to student experience...|$|E
40|$|Total {{laryngectomy}} is {{a radical}} procedure that leads to permanent loss of the voice generator {{and a part of}} the voice resonator, the larynx, where the basic laryngeal tone is created. One method of voice and speech rehabilitation is implantation of tracheoesophageal prosthesis. The aim {{of this study was to}} determine the characteristics of tracheoesophageal speech in patients with primary and secondary vocal prosthesis, to analyze the influence of gender and age on characteristics of the tracheoesophageal speech and self-assessment by patients themselves. This paper presents the results of voice and speech rehabilitation in 48 laryngectomized patients aged 44 to 77 years, with implanted vocal prosthesis during the period from 2008 to 2010 at the Clinic for Ear, Nose and Throat of the Clinical Centre of Vojvodina. The assessment of voice and speech characteristics included: maximum phonation time for the sound /a/, the length of phrases, reading of <b>phonetically</b> <b>balanced</b> <b>word</b> lists, intelligibility of words, reading phonetically balanced text and self-assessment of speech quality of patients referred to their communicative needs. Characteristics of voice and speech in patients who underwent primary vocal prosthesis in relation to secondary placement show no statistically significant difference. In patients under the age of 60, statistically significant better result in terms of speech intelligibility was found. There were no statistically significant differences depending on the patients' gender. Only one patient (1 / 48) assessed his speech as unsatisfactory. As developing countries cannot provide adequate number of prostheses and their continuous supply for all laryngectomy patients, the installation of a secondary vocal prosthesis could be an adequate method of rehabilitation. A large percentage of success in education of tracheoesophageal speech recommends the placement of vocal prosthesis...|$|E
40|$|OBJECTIVE: To {{evaluate}} {{the benefit of}} cochlear implantation in patients with Pendred syndrome. DESIGN: Retrospective study. SETTING: Tertiary centre. PARTICIPANTS AND MAIN OUTCOME MEASURES: Speech perception was measured using a <b>phonetically</b> <b>balanced</b> <b>word</b> list at a sound pressure level of 65 dB. Post-operative phoneme scores at 12 -month for adults and 36 -month for children with Pendred syndrome were compared to scores of patients with an enlarged vestibular aqueduct (EVA) and a reference group with an unknown cause of hearing impairment. Quality of life was measured with the Nijmegen Cochlear Implant Questionnaire to {{evaluate the}} differences between pre- and post-implantation. RESULTS: The mean post-operative phoneme scores were as follows: in the Pendred group, 91 % (n = 16; SD = 10) for children and 78 % (n = 7; SD = 14) for adults; in the reference group, 79 % (n = 59; SD = 20) for children and 73 % (n = 193; SD = 18) for adults; and in the EVA group, 84 % (n = 6; SD = 7) for children and 66 % (n = 12; SD = 22) for adults. A significant difference in speech perception {{was found between the}} children of the Pendred group and the reference group of 11. 4 % (SE = 5. 2; P = 0. 031). Between the adults, a difference of 11. 2 % (SE = 6. 7; P = 0. 094) was found. The difference between the Pendred group and the EVA group was 5. 7 %(SE = 4. 5; P = 0. 22) for children and 9. 9 % (SE = 8. 7; P = 0. 28) for adults. A significant improvement post-implantation in four of the six subdomains of the quality of life questionnaire was found: basic sound perception (P = 0. 002), advanced sound perception (P = 0. 004), speech production (P = 0. 018) and activity limitations (P = 0. 018). The two not significant subdomains were self-esteem (P = 0. 164) and social interaction (P = 0. 107). CONCLUSIONS: After cochlear implantation, children with Pendred syndrome performed better than the reference group with respect to speech perception, however, adults performed similar. No {{significant differences were found between}} the Pendred and EVA group. Consequently, during pre-operative counselling, the two groups of patients may be considered comparable in terms of expected speech perception performance after cochlear implantation...|$|E
40|$|The paper {{describes}} {{design and}} process of collection, annotation {{and evaluation of}} a new Slovak mobile-telephone speech database MobilDat-SK, which is a mobile-telephone extension to the SpeechDat-E SK. The MobilDat-SK database contains recordings of 1100 speakers and it is balanced according to the age, accent, and sex of the speakers. Every speaker pronounced 50 files (either prompted or spontaneous) containing numbers, names, dates, money amounts, embedded command <b>words,</b> geographical names, <b>phonetically</b> <b>balanced</b> <b>words,</b> <b>phonetically</b> <b>balanced</b> sentences, Yes/No answers and one longer non-mandatory spontaneous utterance. In the paper {{the structure of the}} database, the hardware and software solution of the automatic recording, the speaker recruitment strategy, the annotation process and evaluation process are described. The MobilDat-SK database has been developed for the “Intelligent Speech Communication Interface ” project in the frame of the State Research and Development Task “Buildin...|$|R
40|$|Conventionally {{the testing}} of hearing aid {{algorithm}} is accomplished by conducting listening test on hearing impaired, but these tests are not only time consuming but also causes exhaustion, especially in aged patients. Simulation based testing proves to be better option for preliminary evaluation of developed algorithm. A novel methodology based on wavelet transform is designed for dichotic presentation. Among different wavelet families, daubechies & symlet are chosen due to their pre-eminence among others. The performance of developed algorithm has been tested on four normal hearing subjects under noisy environment with SNR of 3 db, 0 db,- 3 db &- 6 db in prerecorded <b>phonetically</b> <b>balanced</b> <b>words.</b> Comparative result analysis of performance measures like perception rate and perception time shows the outperformance of processed over unprocessed signals...|$|R
40|$|This paper {{presents}} the results of an assessment of speech discrimination by hearing-impaired listeners (sensori-neural, conductive, and mixed groups) under binaural free-field listening in the presence of background noise. Subjects with pure-tone thresholds greater than 20 dB in 0. 5, 1. 0 and 2. 0 kHz were presented with a version of the W- 22 list of <b>phonetically</b> <b>balanced</b> <b>words</b> under three conditions: (1) 'quiet', with the chamber noise below 28 dB and speech at 60 dB; (2) at a constant S/N ratio of + 10 dB, and with a background white noise at 70 dB; and (3) same as condition (2), but with the background noise at 80 dB. The mean speech discrimination scores decreased significantly with noise in all groups. However, the decrease in binaural speech discrimination scores with an increase in hearing impairment was less for material presented under the noise conditions than for the material presented in quiet...|$|R
40|$|This is a publisher’s {{version of}} an article {{published}} in Annals of Otology, Rhinology & Laryngology published by Annals Publishing Company. This version is reproduced with permission from Annals Publishing Company. [URL] processors extracting either the fundamental frequency (F 0) alone, or the fundamental frequency combined with second formant information (F 0 -F 2), have been evaluated on a totally deaf patient using a multiple-channel cochlear implant. A closed set test using 16 spondees and a modified rhyme test showed that for electrical stimulation alone the F 0 -F 2 speech processor was significantly better than the F 0 processor. The open set tests using <b>phonetically</b> <b>balanced</b> <b>words</b> and Central Institute for the Deaf everyday sentences showed that for electrical stimulation alone and electrical stimulation combined with lipreading, the results with the F 0 -F 2 speech processor were all significantly better than with the F 0 processor. Information transmission for consonant speech features was also better when using the F 0 -F 2 processor. Open Acces...|$|R
40|$|Copyright {{confirmation}} in progress. Any queries to umer-enquiries@unimelb. edu. auA multi-channel {{cochlear implant}} hearing prosthesis providing 22 separate channels of stimulation has been developed. The electronics for the implantable receiver-stimulator have been incorporated {{on a single}} chip, using digital circuits and employing CMOS technology. The chip is enclosed in a titanium capsule with platinum/ceramic electrode feed-throughs. A pocket-sized speech processor and directional microphone extract the following speech parameters: signal amplitude, fundamental frequency and formant frequency. The fundamental frequency is coded as electric pulse rate, and formant frequency by electrode position. The speech processor has been realized using hybrid circuits and CMOS gate arrays. The multi-channel prosthesis has undergone a clinical trial on four postlingually deaf patients with profound-total hearing losses. The speech perception results indicate {{that they were able}} to obtain open-set speech recognition scores for <b>phonetically</b> <b>balanced</b> <b>words,</b> CID sentences and spondees. In all cases the tests showed significant improvements when using the cochlear prosthesis combined with lipreading compared to lipreading alone. Restricted Access: This resource is not available from the Digital Repository for permission reasons. This is a citation and abstract only record...|$|R
40|$|This study {{compared}} the intelligibility of native and foreign-accented American English speechpresented in quiet and mixed with two {{different levels of}} background noise. Two native American English speakers and two native Mandarin Chinese speakers for whom English is a second language read three 50 -word lists of <b>phonetically</b> <b>balanced</b> <b>words</b> (Stuart, 2004). The words were mixed with noise at three different signal-to-noise levels—no noise (quiet), SNR +[*] 10 dB (signal 10 dB louder than noise) and SNR 0 (signal and noise at equal loudness). These stimuli were presented to ten native American English listeners who were simply asked to repeat the words they heard the speakers say. Listener response latencies were measured. The results showed that for both native and accented speech, response latencies increased as the noise level increased. For words identified correctly, response times to accented speech were longer than for native speech but the noise conditions affected both types equally. For words judged incorrectly, however, the noise conditions increased latencies for accented speech more than for native speech. Overall, these results {{support the notion that}} processing accentedspeech requires more cognitive effort than processing native speech...|$|R
40|$|Abstract: Under B. J. Medical College Cochlear and Hearing Implant Programme 45 prelingual deaf {{patients}} who underwent unilateral Cochlear Implantation were selected and divided into five groups on basis of {{age at which}} participants underwent implantation: ≤ 3 years, 3 to 6 years, 6 to 9 years, 9 to 12 years, and 12 to 15 years. Speech perception skills were assessed using <b>phonetically</b> <b>balanced</b> Hindi <b>word</b> list before implantation and at specified post-implant switch-on time periods for upto 2 years. The scores increased significantly in all five groups from pre- to post- CI in every follow-up. Positive effect of time was seen with better results in those implanted at younger age...|$|R
40|$|This paper {{describes}} {{preliminary results}} of automatic recognition of Korean broadcast-news speech. We {{have been working}} on flexible vocabulary isolated-word speech recognition, and the same HMM models are used for broadcast-news continuous speech recognition. The recognizer is trained by using <b>phonetically</b> <b>balanced</b> isolated <b>words</b> speech, rather than the broadcast news speech itself. In this research, we use several different lexica to investigate the recognition performance according to the length of the words. We also propose a long-distance bigram language model, which can be used at the first stage of the search, so that it can reduce the recognition errors caused by earlier pruning of correct hypothesis. 1...|$|R
40|$|The paper {{presents}} a new variant of parameter estimation methods for discrete hidden Markov models(HMM) in speech recognition. This method {{makes use of}} a codeword dependent distribution normalization(CDDN) and a distance weighting by fuzzy contribution {{in dealing with the}} problems of robust state modeling in a FVQ based modeling. The proposed method is compared with the existing techniques using speaker-independent <b>phonetically</b> <b>balanced</b> isolated <b>words</b> recognition. The results have shown that the recognition rate of the proposed method is improved 4. 5 % over the conventional FVQ based method and the distance weighting to the smoothing of output probability is more efficient than the distance based codeword weighting. 1...|$|R
40|$|In {{an earlier}} study we derived robust frequency-weighting {{functions}} for prediction of the intelligibility of short nonsense words. These frequency-weighting functions are applied for prediction of intelligibility such as with the speech transmission index (STI). Six independent experiments revealed essentially similar frequency-weighting functions for the prediction of the nonsense word scores with respect to signal-to-noise ratio and gender [Speech Communication 28 (1999) 109]. Although the frequency weightings do not vary significantly for signal-to-noise ratio or gender, other {{studies have shown that}} using different types of speech material (i. e., nonsense <b>words,</b> <b>phonetically</b> <b>balanced</b> <b>words</b> and connected discourse) resulted in quite different frequency-weighting functions. This {{may be related to the}} distribution of specific phonemes in the test material. In order to obtain a more generic description of the frequency weighting, four relevant groups of phonemes were identified. In situations with reduced intelligibility, a small confusion rate of the phonemes within each group was observed. For each group a specific frequency-weighting function and a good prediction of the phoneme group scores could be obtained. It was shown that from these (weighted) phoneme group scores,word scores could be predicted with a prediction accuracy of ca. 4 %(this corresponds to a signal-to-noise ratio of about 1 dB). Hence,this method provides a more generic way to predict intelligibility scores for different types of speech material. (E...|$|R
40|$|Three related {{studies were}} {{conducted}} to compare different types of human voice warnings. In the first study, a comparison of three LPC-encoded voices, human female, human male, and phoneme-synthesized, by the criteria of pilot flight task performance showed no differences due to the voice type. In the second study, pilots' preferences were investigated, by comparing preference for direct synthesized speech to the LPC-encoded human female speech and to LPC-encoded synthesized speech. Most pilots were found to prefer direct synthesized speech over both LPC-encoded human female speech and the LPC-encoded synthesized speech. In the third study, <b>phonetically</b> <b>balanced</b> (PB) <b>words</b> heard in simulated helicopter noise were {{used to compare the}} intelligibility of direct synthesized and LPC-encoded phoneme-synthesized speech types. PB word intelligibility was found to be better for direct synthesized speech than for the LPC-encodes synthesized speech...|$|R
40|$|The {{full text}} {{of this article is}} not {{available}} in SOAR. Check the journal record [URL] for the paper version of the article in the library. It has been reported that many elderly persons exhibit problems in identifying the location of fused auditory images in a test of the precedence effect in sound localization. The precedence effect involves the neural integration of multiple competing binaural temporal cues, and may reflect subtle age-related neural timing or integration problems. This study investigated whether elderly persons who have difficulty with this test also exhibit problems with speech understanding. The speech measures involved a comparison of performance-intensity functions for <b>phonetically</b> <b>balanced</b> (PB) <b>words</b> and for synthetic sentences presented with ipsilateral speech competition (SSI-ICM). The performance of the elderly subjects on the precedence effect test was significantly correlated with the SSI-max scores but not with PB-max. These findings suggest that age-related difficulties in speech understanding may reflect, at least in part, breakdowns in auditory temporal acuity or resolution. peer reviewe...|$|R
40|$|Silent speech {{recognition}} {{is the process}} of converting motion data of articulators (e. g., tongue, lips, and jaw) into speech in the form of text. The primary objective of this dissertation was to develop new approaches for silent {{speech recognition}} from segmented and continuous input of tongue and lip movement data at three levels of speech units with increasing conceptual complexity—phonemes, words, and sentences. At each level, unique theoretical issues were addressed and plans for use in specific applications were described. This dissertation is motivated by the need for (1) speech movement-based treatment options for people with speech and voice impairments and (2) computational approaches for recognizing speech when acoustic data are not available or extremely noisy. ^ Machine learning and statistical shape analysis were used to classify and quantify the articulatory distinctiveness of phonemes, words, and sentences. The approach is unique in that it maps the motion data directly (instead of articulatory features) to speech units. Procrustes analysis, a statistical shape matching approach, provided an index of articulatory distinctiveness of vowels and consonants, which was used to derive quantitative articulatory vowel and consonant spaces. The derived vowel space resembles long-standing descriptions of articulatory vowel space. The theoretical properties and practical applications in speech pathology (e. g., motor speech decline in amyotrophic lateral sclerosis) of these spaces were also discussed. In addition, support vector machine, Procrustes analysis, and Eigenspace approaches were used to classify a set of <b>phonetically</b> <b>balanced</b> <b>words</b> and functional sentences from articulatory motion. The direct mapping approaches resulted high classification accuracy levels, which were adequate for practical applications. ^ A near-time algorithm (Holistic Articulatory Recognition, HAR) to recognize the whole words and sentences from continuous (unsegmented) articulatory motion was proposed and evaluated. The accuracy and speed of HAR demonstrated its potential for practical applications. HAR is based on classification probabilities and hence any classifier that could estimate them can be incorporated seamlessly. HAR can serve as the recognition component of an articulation-based silent speech interface that may provide an alternate oral communication modality for persons with speech impairments. ...|$|R
40|$|Objectives/Hypothesis: The {{present study}} is a {{long-term}} follow-up of speech perception outcomes and cochlear implant use in three cases of meningitis that occurred after cochlear implantation. Study Design: Case series study. Methods: Study was performed on three children implanted with different models of Clarion (R) devices, two of them with positioner. Recognition and comprehension were assessed via the Italian adaptation of GASP (TAP) test, and <b>phonetically</b> <b>balanced</b> bi-syllabic <b>words</b> in open-set. High resolution computed tomography scan acquisition was performed to obtain axial coronal and oblique multiplanar reconstructions of the cochlea. Results: Two patients were affected by enlarged cochlear acqueduct and Mondini malformation the first carrying positioner. One patient had a normal cochlea, and the positioner {{could have been the}} main cause of bacterial spread. As a consequence of meningitis the child with normal-cochlea and the other with enlarged vestibular acqueduct developed cochlear ossification, increased M-level and worsening of hearing outcomes. The child with Mondini malformation developed facial nerve stimulation. Contralateral implantation was performed in the first two patients. Conclusion: Bacterial meningitis occuring after cochlear implantation may induce cochlear ossification, facial nerve stimulation, and permanent or temporary loss of implant use. Planned follow-up with high resolution computed tomography and evaluation of M-levels could be useful prognostic tools in the management of these patients...|$|R
40|$|AbstractSubjective speech {{intelligibility}} tests {{were carried out}} in order to investigate strategies to improve {{speech intelligibility}} in binaural voice transmission when listening from different azimuth angles under adverse listening conditions. <b>Phonetically</b> <b>balanced</b> bi-syllable meaningful <b>words</b> in Spanish were used as speech material. The speech signal was played back through headphones, undisturbed, and also {{with the addition of}} high levels of disturbing noise or reverberation, with a signal to noise ratio of SNR = – 10 dB and a reverberation time of T 60 = 10 s. Speech samples were contaminated with interaurally uncorrelated noise and interaurally correlated reverberation, which previous studies have shown the more adverse. Results show that, for speech contaminated with interaurally uncorrelated noise, intelligibility scores improve for azimuth angles around ± 30 ° over speech intelligibility at 0 °. On the other hand, for interaurally correlated reverberation, binaural speech intelligibility reduces when listening at azimuth angles around ± 30 °, in comparison with listening at 0 ° or azimuth angles around ± 60 °...|$|R
40|$|This work {{introduces}} a <b>phonetically</b> <b>balanced</b> modi-fied rhyme test (MRT) for evaluating Catalan speech intelligibility. The proposal {{complies with the}} stan-dard MRT restrictions, besides yielding phonetic <b>balanced</b> <b>word</b> ensembles {{so as to avoid}} biasing the test to scarcely representative phonemes. Hence, it allows testing the intelligibility of any communica-tion system delivering Catalan speech by means of a unique phonetic meaningful comparison framework...|$|R
40|$|Binaural {{dichotic}} presentation schemes help {{in increasing}} the intelligibility of speech {{for persons with}} moderate bilateral sensorineural hearing impairment. Spectral splitting, with comb filters has helped in improving the perception of place feature. Temporal splitting, using trapezoidal fading functions, provided improvement {{in the perception of}} duration feature. Splitting of speech using time-varying comb filters, in which the bands of the comb filter are cyclically swept to have spectral and temporal splitting simultaneously, provided improvement in features of place and duration, without affecting the other features. An overall evaluation has been carried out, by conducting listening tests on seven normal hearing subjects with simulated hearing loss, on the three processing schemes: (i) spectral splitting with comb filters based on auditory critical bands designed for minimum spectral distortion and perceptual balance, (ii) temporal splitting with inter-aural switching of 20, 40, and 80 ms with trapezoidal fading functions of 70 % duty cycle and 3 ms transition, and (iii) combined spectral and temporal splitting using time-varying comb filters with sweep cycles of 20, 40, 80, 120 and 160 ms, each with 4, 8, and 16 shiftings. Test material consisted of <b>phonetically</b> <b>balanced</b> monosyllabic <b>words</b> in listener's native language. Hearing loss was simulated by adding broadband noise at different levels to the speech stimuli at constant short-time SNR of 10 ms. At recognition score of 60 %, spectral splitting provided an improvement of 5 dB in SNR. Combined splitting with sweep cycle of 80 ms or greater with 8 and 16 shiftings provided almost the same improvement...|$|R
40|$|International audienceThe {{construction}} of a speech recognition system requires a recorded set of phrases to compute the pertinent acoustic models. This set of phrases must be <b>phonetically</b> rich and <b>balanced</b> {{in order to obtain}} a robust recognizer. By tradition, this set is defined manually implicating a great human effort. In this paper we propose an automated method for assembling a <b>phonetically</b> <b>balanced</b> corpus (set of phrases) from the Web. The proposed method was used to construct a <b>phonetically</b> <b>balanced</b> corpus for the Mexican Spanish language...|$|R
3000|$|The {{test set}} {{consisting}} of 16 individual speakers (8 male, 8 female), each speaking 10 <b>phonetically</b> <b>balanced</b> English sentences, is randomly chosen from the TIMIT training corpus [...]...|$|R
30|$|The {{proposed}} VAD algorithm {{was trained}} and tested using a speech database that is <b>phonetically</b> <b>balanced.</b> The system was evaluated using the error rate and accuracy rate metrics.|$|R
40|$|The {{construction}} of {{automatic speech recognition}} (ASR) systems is fundamentally dependent on the speech corpus used to train the acoustic models. The speech corpus should be <b>phonetically</b> <b>balanced</b> {{to assure that the}} acoustic models are properly trained. This paper presents the design and development of the first <b>phonetically</b> <b>balanced</b> Romanian speech corpus. It describes all the language processing steps taken in order to obtain a proper set of phrases, discusses some important aspects regarding Romanian phonetics and emphasizes the phrase selection mechanism. Index Terms—ASR, corpora acquisition, corpora processing, diacritics restoration 1...|$|R
40|$|We {{present a}} method for {{designing}} a <b>phonetically</b> <b>balanced</b> speech corpus. In this method, we used a phonotactic approach to design the phonetic content of VOXMEX: a <b>phonetically</b> <b>balanced</b> corpus for Mexican Spanish. The transcriptions of VOXMEX contain a complete coverage of phonemes and allophones of Mexican Spanish in every possible context. This corpus is designed for doing phonetic research and acoustic modeling in the speech recognition area. We are recording the readings of the designed text corpus to obtain the speech data of VOXMEX. Our main goal in this project is to construct a phonologically representative speech corpus for Mexican Spanish. 1...|$|R
30|$|The phoneme-level {{language}} {{models were}} trained using the phonetic transcriptions {{of the speech}} database that was used for training the acoustic models. The database contains 1132 <b>phonetically</b> <b>balanced</b> sentences, over 48000 phoneme instances.|$|R
3000|$|... [...]. We assume all {{the models}} {{resulting}} from a given codebook are equally likely. This assumption is valid, in general, if the codebook size is large and derived from a <b>phonetically</b> <b>balanced</b> large training set.|$|R
5000|$|The Harvard {{sentences}} are {{a collection}} of sample phrases that are used for standardized testing of Voice over IP, cellular, and other telephone systems. They are <b>phonetically</b> <b>balanced</b> sentences that use specific phonemes at the same frequency they appear in English.|$|R
30|$|For English, we {{used the}} CSTR US KED Timit {{database}} [30] which contains 453 <b>phonetically</b> <b>balanced</b> utterances spoken by a US male speaker. The database was hand-labelled in phonemes, syllables and words, and carefully corrected. The syllables with lexical stress were also manually labelled.|$|R
40|$|This paper evaluates speech {{perception}} {{testing in}} pediatric cochlear implant users. Using pre-recorded stimulus presentation, the author replicated an earlier experiment comparing the Lexical Neighborhood List (LNT) test to the <b>Phonetically</b> <b>Balanced</b> Kindergarten (PB-K) test in estimating speech perception abilities in hearing impaired children...|$|R
