80|3348|Public
50|$|B-frame is {{the term}} for bidirectionally {{predicted}} pictures. This kind of prediction method occupies less coding data than P-frames (≈25% when compared to I-frame size) {{because they can be}} predicted or interpolated from an earlier and/or later frame. Similar to P-frames, B-frames are expressed as motion vectors and transform coefficients. In order to avoid a growing <b>propagation</b> <b>error,</b> B-frames are not used as a reference to make further predictions in most encoding standards. However, in newer encoding methods (such as AVC), B-frames may be used as reference.|$|E
30|$|The <b>propagation</b> <b>error</b> {{in error}} {{concealment}} is quasi-continuous, while the prior is discrete. Thus, an integration step (32) {{is needed in}} order to discretize the <b>propagation</b> <b>error</b> pdf to obtain the prior. Fortunately, this discretization step can be done during a training process, resulting in a lookup table which nicely reduces the computational complexity [26].|$|E
3000|$|... 18 Oc in planktonic foraminifera entail {{high levels}} of {{uncertainty}} (> 0.2 [*]‰) due to the <b>propagation</b> <b>error</b> of δ [...]...|$|E
40|$|An <b>error</b> <b>propagation</b> {{model has}} been {{developed}} for multimodule computing systems in which the main parameters are the distribution functions of <b>error</b> <b>propagation</b> times. A digraph model is used to represent a multimodule computing system, and <b>error</b> <b>propagation</b> in the system is modeled by general distributions of <b>error</b> <b>propagation</b> times between all pairs of modules. Two algorithms are developed to compute systematically and efficiently the distributions of <b>error</b> <b>propagation</b> times. Experiments are also conducted to measure the distributions of <b>error</b> <b>propagation</b> times with the fault-tolerant microprocessor (FTMP). Statistical analysis of experimental data shows that the <b>error</b> <b>propagation</b> times in FTMP do not follow a well-known distribution, thus justifying the use of general distributions in the present model...|$|R
40|$|The {{standard}} method for the <b>propagation</b> of <b>errors,</b> {{based on a}} Taylor series expansion, is approximate and frequently inadequate for realistic problems. A simple and generic technique is described in which the likelihood is constructed numerically, thereby greatly facilitating the <b>propagation</b> of <b>errors...</b>|$|R
40|$|The {{current work}} {{analyzes}} {{the effect of}} applying different selenopotential models to the propagation of a lunar orbiting spacecraft. A brief evolution history of the selenopotential model is first presented; then, four representative selenopotential models are selected for force modeling. Expected <b>propagation</b> <b>errors</b> are presented with respect to three different circular polar orbits around the Moon. As a result, an expected but rather significant number of orbit <b>propagation</b> <b>errors</b> are discovered. Compared to the solutions obtained using the GRAIL 1500 E model, the overall 3 D <b>propagation</b> <b>errors</b> for a 4 -day period could reach up to several tens of kilometers (50 [*]km altitude case with the GLGM 2 model) and up to several hundreds of meters (50, 100, and 200 [*]km altitude cases even with the GRAIL 660 B model). For each different orbiter’s altitude, the appropriate ranges of the degree and order of the gravitational harmonic coefficients are also suggested to yield the best propagation performances {{with respect to the}} performance obtained with the full harmonic coefficients using the GRAIL 1500 E model. The results of the current work are expected to serve as practical guidelines for the field of system budget analysis, mission design, mission operations, and the analysis of scientific results...|$|R
30|$|Please {{note that}} usually the NLMS {{algorithm}} is employed for calculating the prediction coefficients both in speech enhancement and in error concealment {{due to its}} robustness and low computational complexity. However, there are other algorithms which can also be utilized, as reported in [16]. Please note that the <b>propagation</b> <b>error</b> is also dependent on the algorithm for determining the prediction coefficients, therefore, the change of the algorithm involves a new <b>propagation</b> <b>error</b> pdf training in both disciplines.|$|E
3000|$|... with σ _E̅,ℓ^ 2 (k) {{being the}} <b>propagation</b> <b>error</b> {{variance}} which cannot {{be measured in}} practice, thus, {{it has to be}} estimated [15, 16].|$|E
40|$|Abstract—We {{analyze the}} single and multi-hop {{performance}} of time synchronization mechanisms for challenging environments characterized by high propagation delays, low duty-cycle operation, and imprecise clocks, such as underwater acoustic sensor networks. We find that receiver-receiver based schemes are unsuitable for such environments, and therefore {{focus primarily on}} sender-receiver schemes. According to our analysis, a one-way dissemination approach provides good clock skew estimation but poor offset estimation while a two-way exchange approach provides accurate offset estimation but imprecise clock skew estimation. In average, using one-way scheme can result in significant cumulative <b>propagation</b> <b>error</b> over multiple hops, and using two-way can lead to high variance of <b>propagation</b> <b>error.</b> We develop and analyze a hybrid one-way dissemination/two-way exchange technique, and verify the performance of our hybrid scheme through trace-based experiments. The results suggest that this hybrid approach can provide bounded average error propagation in multi-hop settings and significantly lower variance of <b>propagation</b> <b>error...</b>|$|E
40|$|Abstract. The use of {{land cover}} change map is subject to <b>error</b> <b>propagation</b> from multi-temporal land cover {{classification}} maps. Understanding the factors determining <b>error</b> <b>propagation</b> to land-cover change maps helps to select appropriate classification models and characterize the associated uncertainties. In this paper, we presented a simulation analysis on the rates of <b>error</b> <b>propagation</b> for both non-contextual and contextual classification models. The simulation approach was based on simulated annealing with careful experimental designs to control two related factors including the spatial and temporal patterns on the errors in spectral probability estimation. The {{results showed that the}} two factors had different influences on the <b>error</b> <b>propagation</b> for non-contextual and contextual classification models. For non-contextual models, increasing temporal dependence of errors could reduce the rate of <b>error</b> <b>propagation</b> while spatial dependence of errors did not {{have an impact on the}} <b>error</b> <b>propagation.</b> For contextual classification models, the use of spatialtemporal information significantly reduced the rate of <b>error</b> <b>propagation.</b> However, the utilities of the spatialtemporal information in mitigating <b>error</b> <b>propagation</b> were dependent on the spatial dependence of errors. The impact of the temporal dependence of errors was weakened in the contextual models...|$|R
5000|$|... #Subtitle level 2: Derivation of <b>propagation</b> of <b>error</b> {{equations}} ...|$|R
30|$|The {{integration}} scenarios {{were mostly}} successful, {{and the most}} significant problems arose {{from a lack of}} synchronization among different SDR platforms at the RF physical level. In this context, further work is needed to increase the robustness of the EWF SDR-based network against wireless <b>propagation</b> <b>errors</b> or lack of synchronization.|$|R
3000|$|... +(n) is stationary, the <b>propagation</b> <b>error</b> pdf can be {{determined}} by a histogram measurement in a training process. Moreover, online integration of p_e̅(·) is not necessary if the integrations over I [...]...|$|E
40|$|In this paper, dynamic rate shaping for H. 264 /AVC intracoded {{video streams}} is investigated. An {{analysis}} of the distortion distinguishes different error components {{that lead to the}} degradation of the output video stream. Experimental results show that the <b>propagation</b> <b>error</b> due to intra prediction has a major impact on the visual quality. This results from the highly increased number of dependencies which are invoked by the H. 264 /AVC intra prediction. In order to eliminate the <b>propagation</b> <b>error,</b> we propose to use single-loop compensation techniques. Both objective and subjective results show that the compensation techniques highly improve the visual quality...|$|E
30|$|It can be {{seen from}} (51) that the {{received}} i-th sub-data stream is composed of STBC layer symbols, AWGN noise and the potential <b>propagation</b> <b>error</b> from V-BLAST layer. The equivalent noise is the combination of the last two parts.|$|E
3000|$|... {{represent}} the channel distortion {{due to the}} <b>error</b> concealment, <b>error</b> <b>propagation</b> from the reference frames, and <b>error</b> <b>propagation</b> from the concealment frames, respectively.|$|R
40|$|Although odometry is nonlinear, it yields {{sufficiently}} to linearized analysis {{to produce a}} closed-form transition matrix and a symbolic general solution for both deterministic and stochastic <b>error</b> <b>propagation.</b> Accordingly, <b>error</b> <b>propagation</b> in vehicle odometry can be understood {{at a level of}} theoretical rigor equivalent to the well-known Schuler dynamics of inertial navigation. While response to initial conditions is path-independent, response to input errors can be related to path functionals. These trajectory moments are integral transforms which function like the moment of inertia or the Laplace transform- enabling many <b>error</b> <b>propagation</b> calculations to be performed by hand in closed-form. 1...|$|R
40|$|Abstract [...] Early {{assessment}} of software quality attributes plays {{a central role}} in developing better quality software. <b>Error</b> <b>propagation</b> between software system components is a quantitative factor that reflects on the reliability of a software product. We introduce a framework for experimental <b>error</b> <b>propagation</b> analysis. This framework addresses the problem of estimating <b>error</b> <b>propagation</b> at the architecture design phase. Our approach is based on fault injection and post-simulation trace analysis. We compute <b>error</b> <b>propagation</b> estimates through comparison of faulty-run traces with a reference, faultfree, trace. We use this framework to experimentally study <b>error</b> <b>propagation</b> in a medium-sized real-time system. We believe that this framework can be further extended to allow for experimental analysis of change propagation and requirements propagation...|$|R
3000|$|... with σ _e^ 2 (n) = E { e^ 2 (n) } {{being the}} {{prediction}} error variance and σ _e^+^ 2 (n) = E { (s^+(n) - ŝ^+(n))^ 2 }. Please note that (8) holds {{independently of the}} type of the <b>propagation</b> <b>error</b> pdf.|$|E
40|$|We {{demonstrate}} that {{by adding a}} time-domain window function to the recently developed Fourier series analysis technique can reduce the <b>propagation</b> <b>error</b> in solving the nonlinear soliton propagation equation. With suitable modification of window function parameters, the number of sampling points as well as computational time required for the calculation can be minimized even with higher order dispersion terms taken into consideration. published_or_final_versio...|$|E
40|$|International audienceThe main {{contribution}} {{of this paper}} consists in extending several non-stationary Reinforcement Learning (RL) algorithms and their theoretical guarantees {{to the case of}} discounted zero-sum Markov Games (MGs). As in the case of Markov Decision Processes (MDPs), non-stationary algorithms are shown to exhibit better performance bounds compared to their stationary counterparts. The obtained bounds are generically composed of three terms: 1) a dependency over gamma (discount factor), 2) a concentrability coefficient and 3) a <b>propagation</b> <b>error</b> term. This error, depending on the algorithm, can be caused by a regression step, a policy evaluation step or a best-response evaluation step. As a second contribution, we empirically demonstrate, on generic MGs (called Garnets), that non-stationary algorithms outperform their stationary counterparts. In addition, it is shown that their performance mostly depends {{on the nature of the}} <b>propagation</b> <b>error.</b> Indeed, algorithms where the error is due to the evaluation of a best-response are penalized (even if they exhibit better concentrability coefficients and dependencies on gamma) compared to those suffering from a regression error...|$|E
3000|$|... = 3, 15, 47, and 79, respectively. This {{performance}} degradation {{is due to}} three factors: (i) the CE errors, (ii) the tracking errors, and (iii) imperfect self-information removal due to CE errors. In the case of CE without noise (long-dotted lines in Figure 8), where only the <b>propagation</b> <b>errors</b> due to the channel time selectivity are considered, the [...]...|$|R
5000|$|The <b>propagation</b> of <b>error</b> {{approximation}} {{then can}} be written concisely as the quadratic form ...|$|R
50|$|The {{trade-off}} {{between these}} profiles stands between robustness, resistance {{in regards to}} propagation conditions and useful bit rates for the service. This table presents some values depending on these profiles. The larger the carrier spacing, the more the system is resistant to Doppler effect (Doppler spread). The larger the guard interval, the greater the resistance to long multipath <b>propagation</b> <b>errors</b> (delay spread).|$|R
40|$|AbstractMing-Hua Zhang (1988) has {{proposed}} a new specification method for data types based on second-order logic. Now we show that errors and exceptions are included directly in the specifications from the beginning. In our approach errors are not objects but indicate that some formulas are false. Unlike errors, exceptions are special objects. The error, error <b>propagation,</b> <b>error</b> recovery and exception can all be precisely defined and the fundamental results about them can be deduced from the specification by predicate calculus...|$|E
40|$|Abstract. In {{original}} minority game, each {{agent at}} every time step chooses the highest-score strategy from its {{limited number of}} strategies given arbitrarily {{in the beginning of}} the game. In this paper, agents of the minority game are equipped to a multi-layer perceptron neural network that at every time step learns by back <b>propagation</b> <b>error.</b> Simulation results and the comparison of them with the results from original minority game model indicate that the proposed neural network-based learning technique of agents improves the overall performance of the agents...|$|E
40|$|The CLIC 1 {{components}} {{will have}} to be prealigned within a thirty times more demanding tolerance than the existing CERNmachines. It is a technical challenge and a key issue for the CLIC feasibility. Simulations have been undertaken concerning the <b>propagation</b> <b>error</b> due to the measurement uncertainties of the prealignment systems. The uncertainties of measurement, taken as hypothesis for the simulations, are based on the data obtained on several dedicated facilities. This paper introduces the simulations and the latest results obtained, as well as the facilities...|$|E
2500|$|... can {{be found}} by {{interval}} methods. This provides an alternative to traditional <b>propagation</b> of <b>error</b> analysis.|$|R
30|$|The <b>error</b> <b>propagation</b> {{is the key}} {{component}} of the end-to-end distortion model. Different from the independent estimation in conventional MSE-based end-to-end distortion model, the perceptual <b>error</b> <b>propagation</b> depends on the source distortion or the concealment distortion. In this section, our primary goal is to develop the <b>error</b> <b>propagation</b> models to estimate the overall perceptual quality for given transmission errors of prediction block or concealment block.|$|R
40|$|An {{experimental}} {{analysis to}} study <b>error</b> <b>propagation</b> {{from the gate}} to the chip level is described. The target system is the CPU in the Bendix BDX- 930, an avionic miniprocessor. Error activity data for the study was collected via a gate-level simulation. A family of distributions to characterize the <b>error</b> <b>propagation,</b> both within the chip and at the pins, was then generated. Based on these distributions, measures of <b>error</b> <b>propagation</b> and severity were defined. The analysis quantifies the dependency of the measured <b>error</b> <b>propagation</b> on the location of the fault and the type of instruction/microinstruction executed...|$|R
40|$|Abstract—Recent {{empirical}} evaluation {{has shown}} that the performance of collective classification models can vary based on the amount of class label information available for use during inference. In this paper, we further demonstrate that the relative performance of statistical relational models learned with different estimation methods changes as the availability of test set labels increases. We reason about the cause of this phenomenon from an information-theoretic perspective and this points to a previously unidentified consideration in the development of relational learning algorithms. In particular, we characterize the high <b>propagation</b> <b>error</b> of collective inference models that are estimated with maximum pseudolikelihood estimation (MPLE), and show how this affects performance across the spectrum of label availability when compared to MLE, which has low <b>propagation</b> <b>error.</b> Our formal study leads to a quantitative characterization {{that can be used to}} predict the confidence of local propagation for MPLE models. We use this to propose a mixture model that can learn the best trade-off between high and low propagation models. Empirical evaluation on synthetic and real-world data show that our proposed method achieves comparable, or superior, results to both MPLE and low propagation models across the full spectrum of label availability. Keywords-statistical relational learning; collective classification; probabilistic relational models. I...|$|E
30|$|Although in [26] the {{variance}} E{ (s^+ - ŝ^+)^ 2 } {{is assumed to}} be zero, the non-Gaussianity of the <b>propagation</b> <b>error</b> pdf p_e̅ (e̅=s-ŝ^+) was also observed in the context of error concealment. As can be seen on the right-hand side of Figure 5, p_e̅ in (32), being measured in a training process, turns out to be rather super-Gaussian. Furthermore, in [26] the dependency of p_e̅ (e̅=s-ŝ^+) on ŝ^+ was investigated revealing different shapes and variances dependent on the amplitude of ŝ^+, while ŝ^+=s^+ was assumed there.|$|E
40|$|AbstractWe {{study the}} {{simplifications}} occurring in any likelihood {{function in the}} presence of a large number of small systematic uncertainties. We find that the marginalisation of these uncertainties can be done analytically by means of second-order error <b>propagation,</b> <b>error</b> combination, the Lyapunov central limit theorem, and under mild approximations which are typically satisfied for LHC likelihoods. The outcomes of this analysis are i) a very light treatment of systematic uncertainties ii) a convenient way of reporting the main effects of systematic uncertainties, such as the detector effects occurring in LHC measurements...|$|E
40|$|<b>Error</b> <b>propagation</b> is {{a common}} problem in NLP. Reinforcement {{learning}} explores erroneous states during training and can therefore be more robust when mistakes are made early in a process. In this paper, we apply reinforcement learning to greedy dependency parsing which is known to suffer from <b>error</b> <b>propagation.</b> Reinforcement learning improves accuracy of both labeled and unlabeled dependencies of the Stanford Neural Dependency Parser, a high performance greedy parser, while maintaining its efficiency. We investigate the portion of errors which {{are the result of}} <b>error</b> <b>propagation</b> and confirm that reinforcement learning reduces the occurrence of <b>error</b> <b>propagation...</b>|$|R
40|$|With the {{functionality}} of most {{embedded systems}} based on software (SW), interactions amongst SW modules arise, resulting in <b>error</b> <b>propagation</b> across SW them. During SW development, {{it would be}} helpful to have a framework that clearly demonstrates the <b>error</b> <b>propagation</b> and containment capabilities of the different SW components. In this paper, we assess the impact of inter-modular <b>error</b> <b>propagation.</b> Adopting a white-box SW approach, we make the following contributions: (a) we study and characterize the <b>error</b> <b>propagation</b> process and derive a set of metrics that quantitatively represents the inter-modular SW interactions, (b) we use a real embedded target system used in an aircraft arrestment system to perform fault-injection experiments to obtain experimental values for the metrics proposed, (c) we show how the set of metrics can be used to obtain the required analytical framework for <b>error</b> <b>propagation</b> analysis. We find that the derived analytical framework establishes a very close correla [...] ...|$|R
40|$|Constraints {{imposed on}} {{designing}} the decision feedback equalizers (DFE) are used effectively to mitigate <b>propagation</b> <b>errors.</b> In this paper, we introduce a novel {{design of the}} constrained minimum mean squared error (MMSE) DFE for a multi-input multi-output (MIMO) system under intersymbol interference (ISI) environment. The proposed design results in a significantly improved performance compared to the conventional MIMO MMSE-DFE, especially under the practical situation where the channel is not perfectly estimated and the channel coding is employed...|$|R
