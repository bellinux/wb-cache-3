190|719|Public
50|$|Incident {{management}} {{policies and}} procedures - controls designed to address operational <b>processing</b> <b>errors.</b>|$|E
50|$|In service businesses, {{measures}} of conformance normally focus on accuracy and timeliness and include counts of <b>processing</b> <b>errors,</b> unanticipated delays and other frequent mistakes.|$|E
50|$|Correct {{processing}} in applications {{is essential}} {{in order to prevent}} errors and to mitigate loss, unauthorized modification or misuse of information. Effective coding techniques include validating input and output data, protecting message integrity using encryption, checking for <b>processing</b> <b>errors,</b> and creating activity logs.|$|E
30|$|We {{apologize}} for this <b>processing</b> <b>error.</b>|$|R
30|$|The {{publisher}} apologises {{for this}} <b>processing</b> <b>error.</b>|$|R
5000|$|Technical: Expired authorization, non-sufficient funds, or bank <b>processing</b> <b>error.</b>|$|R
5000|$|If Sitemaps are {{submitted}} {{directly to}} a search engine (pinged), it will return status information and any <b>processing</b> <b>errors.</b> The details involved with submission will vary with the different search engines. The location of the sitemap can also {{be included in the}} [...] file by adding the following line: ...|$|E
5000|$|Less {{explosion}} hazard - Propellant grain is {{more tolerant of}} <b>processing</b> <b>errors</b> such as cracks since the burn rate is dependent on oxidizer mass flux rate. Propellant grain cannot be ignited by stray electrical charge and is very insensitive to auto-igniting due to heat. Hybrid rocket motors can be transported to the launch site with the oxidizer and fuel stored separately, improving safety.|$|E
5000|$|In this experiment, Zurif, Swinney and Garret {{built upon}} {{existing}} research on language <b>processing</b> <b>errors</b> in Broca’s and Wernicke’s aphasia patients. Prior studies indicate that, generally, Broca’s aphasia patients demonstrate a slower-than-normal time course of lexical activation than controls; whereas, lexical activation is relatively unimpaired in Wernicke’s aphasics. This study compared and contrasted selected patients’ capacities for resolving subject-relative constructions {{through a process}} known as gap filling. For example: ...|$|E
30|$|This {{formatting}} error {{has since}} been corrected; however we apologize for this <b>processing</b> <b>error.</b>|$|R
50|$|Finally, <b>processing</b> <b>error</b> {{refers to}} errors that arise during the data <b>processing</b> stage, {{including}} <b>errors</b> in the editing of the data, data encoding, {{the assignment of}} survey weights, and tabulation of the survey data.|$|R
30|$|Due to a <b>processing</b> <b>error,</b> {{the order}} of authors was incorrect. The correct order of authors is given below.|$|R
5000|$|Due to {{the event}} viewer's routine {{reporting}} of minor start-up and <b>processing</b> <b>errors</b> (which do not in fact harm or damage the computer), the software is frequently used by technical support scammers to convince users unfamiliar with Event Viewer that their computer contains critical errors requiring immediate technical support. An example is the [...] "Administrative Events" [...] field under [...] "Custom Views" [...] which can have over a thousand errors or warnings logged over a month's time.|$|E
50|$|Early {{researchers}} explained attribution biases as cognitively driven and {{a product}} of information <b>processing</b> <b>errors.</b> In the early 1980s, studies demonstrated that {{there may also be}} a motivational component to attribution biases, such that our own desires and emotions affect how we interpret social information. Current research continues to explore the validity of both of these explanations by examining the function of specific types of attribution biases and their behavioral correlates through a variety of methods (e.g., research with children or using brain imaging techniques).|$|E
50|$|Excalibur Technologies had {{a history}} of search {{technology}} development dating back to the early 1980s. Founded by Jim Dowe in February 1980, Excalibur sought to exploit neural networks through its proprietary Adaptive Pattern Recognition Processing (APRP). In 1985, the Company entered into a multiyear research, development and royalty contract with Nikkei Information Systems Co., Ltd. ("NIS"), a Japanese company. For the Japanese market, Excalibur packaged the technology for broader adoption. Dowe presented TICOL: A Development Tool For Fifth Generation Programming Environments along with Mr. Toshi Arai of NIS at the 1988 Forth Conference on Programming Environments. The conference was hosted by the College of Engineering and Applied Science at the University of Rochester. In parallel, Excalibur demonstrated several successful applications of APRP pattern matching using multimedia data types (including text data, signal data, and video data) and packaged these as TRS, SRS and VRS targeted to US government agencies. One of those early applications of APRP for text retrieval proved that pattern matching search tolerated spelling variations and optical character recognition (OCR) <b>processing</b> <b>errors</b> over large volumes of scanned/OCR material. This led to the release of Excalibur EFS for electronic filing and search.|$|E
50|$|The survey {{literature}} decomposes nonsampling errors {{into five}} general sources or types: specification error, frame error, nonresponse error, measurement <b>error,</b> and <b>processing</b> <b>error.</b>|$|R
3000|$|Due to a <b>processing</b> <b>error,</b> first author's name {{is missing}} in the HTML {{version of this article}} {{abstract}} page. The correct authors are given below: [...]...|$|R
5000|$|A {{software}} system is called [...] "monolithic" [...] {{if it has}} a monolithic architecture, in which functionally distinguishable aspects (for example data input and output, data <b>processing,</b> <b>error</b> handling, and the user interface) are all interwoven, rather than containing architecturally separate components.|$|R
40|$|We {{study the}} "generalized {{correlated}} equilibria" {{of a game}} when players make information <b>processing</b> <b>errors.</b> It is shown that the assumption of information <b>processing</b> <b>errors</b> is equivalent to that of "subjectivity" (i. e., differences between the players' priors). Hence a bounded rationality justification of subjective priors is provided. We also describe the set of distributions on actions induced by generalized correlated equilibria with common priors. Correlated equilibria, subjective priors, bounded rationality...|$|E
40|$|This thesis {{contains}} {{descriptions of}} current methods of identifying chemical <b>processing</b> <b>errors,</b> {{followed by a}} description of a proposed method for quantitatively identifying chemical <b>processing</b> <b>errors.</b> The goal of this research is to determine the relationships between chemical deviations in the first developer of Kodak Color Reversal Process E- 6 and the resulting changes in the sensitometric parameters of Kodak film type Ektachrome 64 Professional (Daylight). These relationships are presented in graphical form in a section of this thesis entitled 2 ̆ 2 Results and Conclusions 2 ̆ 2...|$|E
30|$|We {{conclude}} that thermal excursions {{of up to}} 1  K are significantly larger than the <b>processing</b> <b>errors</b> due to non-ideal penetrations or to uncertainties caused by an arbitrary selection of time intervals.|$|E
30|$|Notice {{that the}} derived result in [20] for BiSAR {{is exactly the}} same as in (29) for monostatic SAR, which means that the monostatic model is {{directly}} applied to BiSAR case in [20]. This will result in severe azimuth <b>processing</b> <b>error,</b> especially when focusing large-baseline BiSAR data.|$|R
40|$|RESEARCH INTERESTS High {{performance}} and energy-efficient computation, including algorithm enhancements, application mapping/software development on many-core architectures, and VLSI design of ASICs and reconfigurable architectures that support networking and communications, signal <b>processing,</b> <b>error</b> correction, and biomedical applications. Single-chip solutions targeted for low-power embedded systems through a co-design o...|$|R
40|$|AbstractSP-off-RP {{questions}} are a recent innovation in choice modelling that solicits information from respondents {{in a different}} way than standard stated-preference (SP) experiments. In particular, the alternatives and choice of a respondent in a real-world setting are observed, and the respondent is asked whether he/she would choose the same alternative or switch to another alternative if the attributes of the chosen alternative were less desirable in ways specified by the researcher and/or the attributes of non-chosen alternatives were more desirable in specified ways. This construction, called “stated-preference off revealed-preference” (SP-off-RP), is intended to increase the realism of the stated-preference task, relative to standard SP exercises, but creates endogeneity. In this paper, we present a series of Monte Carlo exercises that explore estimation on this type of data, using an estimator that accounts for the endogeneity. The results indicate that, when the variance in the <b>processing</b> <b>error</b> by respondents is the same for SP-off-RP data as for standard SP data, the two solicitation methods provide about the same level of efficiency in estimation, even though the SP-off-RP data contain endogeneity that the estimator must handle while the SP data do not involve endogeneity. For both solicitation methods, efficiency rises, as expected, as the variance of the <b>processing</b> <b>error</b> decreases. These results imply that, if respondents are able to answer SP-off-RP questions more accurately than standard SP questions (and hence have lower variance of <b>processing</b> <b>error),</b> then SP-off-RP data are more efficient that standard SP data. This implication needs to be viewed cautiously, since (i) the actual <b>processing</b> <b>error</b> for each solicitation method is not measured in the current study, and (ii) the results are for the specific data generation processes that are used in the Monte Carlo exercises...|$|R
40|$|There exists {{an inverse}} {{relationship}} between the rate of molecular evolution {{and the level of}} gene expression. Among the many explanations, the “toxic-error” hypothesis is a most general one, which posits that <b>processing</b> <b>errors</b> may often be toxic to the cells. However, toxic errors that constrain the evolution of highly expressed genes are often difficult to measure. In this study, we test the toxic-error hypothesis by using microRNA (miRNA) genes because their <b>processing</b> <b>errors</b> can be directly measured by deep sequencing. A miRNA gene consists of a small mature product (≈ 22 nt long) and a “backbone. ” Our analysis shows that (i) like the mature miRNA, the backbone is highly conserved; (ii) the rate of sequence evolution in the backbone is negatively correlated with expression; and (iii) although conserved between distantly related species, the error rate in miRNA processing is also negatively correlated with the expression level. The observations suggest that, as a miRNA gene becomes more highly (or more ubiquitously) expressed, its sequence evolves toward a structure that minimizes <b>processing</b> <b>errors...</b>|$|E
3000|$|The {{different}} {{experimental and}} <b>processing</b> <b>errors</b> thus justify weighting each data type differently. We {{do not try}} to set realistic variances to each data type, but we rather define weights with the priority order w [...]...|$|E
40|$|Abstract. Signal <b>processing</b> <b>errors</b> are {{considered}} at an estimation of frequency-time parameters. The optimum weight function is proposed, which efficiency is determined {{on the basis}} of the generalized correlation analysis. Opportunities of signals filtration are investigated {{on the basis of}} wavelettransformations...|$|E
50|$|A {{report in}} November 2015 on a 4,500 year old Ethiopian genome had {{originally}} overestimated the genetic {{influence of the}} Eurasian backflow, claiming that signs of the migration {{could be found in}} genomes all over Africa. This mistaken claim was based on a data <b>processing</b> <b>error</b> and was corrected in February 2016.|$|R
40|$|The {{consistent}} end-to-end {{simulation of}} airborne and spaceborne earth remote sensing systems {{is an important}} task and sometimes {{the only way for}} the adaptation and optimization of a sensor and its observation conditions, the choice and test of algorithms for data <b>processing,</b> <b>error</b> estimation and the evaluation of the capabilities of the whole sensor system...|$|R
40|$|Abstract. The {{existing}} {{processes of}} controlling machining error just controlled the maximum error. However, {{it did not}} effectively control {{the distribution of the}} error. The reliability of the assembly precision of the key joint surface did not meet the requirements, thereby affecting the service performance of machine tool. To solve this problem, the error matrix and transformation matrix was used to ascertain the location of joint surface positioning error occurred. The influence of <b>processing</b> <b>error</b> on the the positioning accuracy of machine tool was analyzed. The control objective of milling process was proposed. At the same time, the effects of cutting parameters on the <b>processing</b> <b>error</b> were also studied according to the milling experiments. The process error and its distribution characteristics of joint surface were obtained by analyzing the relationship between deformation of joint surface and cutting parameters. The milling process control methods were proposed...|$|R
40|$|The {{value of}} {{information}} {{and the possibility of}} speculation are examined in an environment with unawareness. Although agents have “correct ” prior beliefs about events they are aware of and have a clear understanding of their available actions and payoffs, their unawareness may lead them to commit information <b>processing</b> <b>errors</b> and to behave suboptimally. As a result, more information is not always valuable and agents can speculate with each other. We identify two specific information <b>processing</b> <b>errors</b> that are responsible for both problems. Moreover, we construct a dynamic model where agents announce their posteriors and update their awareness as soon as they hear a counterfactual announcement. We study how awareness is updated and whether agreement about posteriors is reached. ...|$|E
3000|$|Thanks to TFA tool’s {{ability to}} {{distinguish}} magneto-spheric pulsations from <b>processing</b> <b>errors</b> and / or instrumental noise, the scientific merit {{for the large}} (external and internal field) researchers’ community interested in the Swarm mission would expected to be at various levels: [...]...|$|E
40|$|This {{document}} {{summarizes the}} results from the development of flowsheets to recover from credible <b>processing</b> <b>errors</b> specified in TTR 99 -MNSS/SE- 006. The proposed flowsheets were developed in laboratory scale equipment and will be utilized with minor modifications for full scale demonstrations in the Am/Cm Pilot Facility...|$|E
40|$|The {{quality of}} spatial data depends on many {{elements}} and may affect subsequent processing steps strongly. We can distinguish {{two groups of}} errors (Burrough and McDonnell 1998) : measurement (inherent) and <b>processing</b> <b>error</b> (spatial analyses and modelling). The errors can be evaluated by statistical methods or by other means. The measurement errors are split to random, systematic and gross. Although the rando...|$|R
40|$|Recent {{developments}} in low loss single mode optical fiber waveguides, semiconductor waveguide lasers and waveguide optical and electro-optical components {{have made a}} new class of rotational inertial frame references possible. The subclasses of possible fiber waveguide gyro configurations are discussed and one approach which is under development is reviewed. Signal detection and <b>processing,</b> <b>error</b> sources, expected physical and performance characteristics, and present development status are discussed...|$|R
40|$|Pooling {{biological}} specimens {{prior to}} performing expensive laboratory assays {{has been shown}} to be a cost effective approach for estimating parameters of interest. In addition to requiring specialized statistical techniques, however, the pooling of samples can introduce assay <b>errors</b> due to <b>processing,</b> possibly in addition to measurement error that may be present when the assay is applied to individual samples. Failure to account for these sources of error can result in biased parameter estimates and ultimately faulty inference. Prior research addressing biomarker mean and variance estimation advocates hybrid designs consisting of individual as well as pooled samples to account for measurement and <b>processing</b> (or pooling) <b>error.</b> We consider adapting this approach to the problem of estimating a covariate-adjusted odds ratio (OR) relating a binary outcome to a continuous exposure or biomarker level assessed in pools. In particular, we explore the applicability of a discriminant function-based analysis that assumes normal residual, <b>processing,</b> and measurement <b>errors.</b> A potential advantage of this method is that maximum likelihood estimation of the desired adjusted log OR is straightforward and computationally convenient. Moreover, in the absence of measurement and <b>processing</b> <b>error,</b> the method yields an efficient unbiased estimator for the parameter of interest assuming normal residual errors. We illustrate the approach using real data from an ancillary study of the Collaborative Perinatal Project, and we use simulations to demonstrate the ability of the proposed estimators to alleviate bias due to measurement and <b>processing</b> <b>error...</b>|$|R
