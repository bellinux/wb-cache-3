170|946|Public
2500|$|Murray B. Sachs [...] - [...] Director of the [...] Johns Hopkins University Department of Biomedical Engineering from 1991-2005, [...] and {{a pioneer}} in the field of Biomedical Engineering in Hearing Science winning the 1998 Von Bekesy award. He and members of his laboratory, the Neural Encoding Laboratory at Johns Hopkins, were {{one of the first to}} derive primary {{auditory}} nerve <b>population</b> <b>codes</b> that became the basis of the modern cochlear implant.|$|E
5000|$|Coutanche, M.N., Solomon, S.H., & Thompson-Schill, S.L. (2016). A {{meta-analysis}} of fMRI decoding: Quantifying influences on human visual <b>population</b> <b>codes.</b> Neuropsychologia.|$|E
50|$|Sompolinsky’s {{research}} includes spike-based neural {{learning and}} computation, neuronal <b>population</b> <b>codes,</b> sensory representations, dynamics {{and function of}} sensory and motor cortical circuits, and large-scale structure and dynamics of human brain. He also studies the relation between physics, neuroscience, and human volition, freedom and agency.|$|E
50|$|<b>Population</b> <b>coding</b> is {{a method}} to {{represent}} stimuli by using the joint activities {{of a number of}} neurons. In <b>population</b> <b>coding,</b> each neuron has a distribution of responses over some set of inputs, and the responses of many neurons may be combined to determine some value about the inputs.|$|R
40|$|Abstract. This work investigates whether <b>population</b> vector <b>coding</b> {{could be}} a {{principle}} mechanism for sensorimotor transformations. This paper presents a formal demonstration of how <b>population</b> vector <b>coding</b> can proceed arbitrary 3 -dimensional rotations and translations. The model suggests that <b>population</b> <b>coding</b> {{could be a}} possible mechanism for frames of reference transformations across multiple sensori-motor systems. ...|$|R
40|$|<b>Population</b> <b>coding</b> {{has been}} {{established}} as the key mechanism for decoding sensory information received from periphery organs such as retinas and cochlear. In this paper a novel architecture is presented to embed <b>population</b> <b>coding</b> in neuromorphic hardware. A resonance based mechanism between two layers of neuron is utilised in the presented work. The mechanism discussed in this paper facilitates selective triggering of higher layer neurons which serves as target ensemble for evaluation of a particular input of interest. It {{has been shown that}} presented model can be used to detect any physical quantity (light intensity, temperature, etc) feed to the sensor on the basis of <b>population</b> <b>coding...</b>|$|R
5000|$|With Sachs and Young, Miller {{focussed}} on rate-timing <b>population</b> <b>codes</b> of complex, speech features including voice-pitch and consonant-vowel syllables [...] {{encoded in}} the discharge patterns across the primary auditory-nerve.These neural codes {{formed the basis}} for the discussions at the 1982 New York Academy of Science meeting on efficacy and timeliness of Cochlear implants.|$|E
50|$|The Johns Hopkins University Neural Encoding {{laboratory}} led by Murray Sachs and Eric Young developed place-time <b>population</b> <b>codes,</b> {{termed the}} Averaged-Localized-Synchronized-Response (ALSR) codefor neural representation of auditory acoustic stimuli. This exploits both the place or tuning within the auditory nerve, {{as well as}} the phase-locking within each nerve fiber Auditory nerve.The first ALSR representation was for steady-state vowels;ALSR representations of pitch and formant frequencies in complex, non-steady state stimuliwere demonstrated for voiced-pitch and formant representations in consonant-vowel syllables.The advantage of such representations is that global features such as pitch or formant transition profiles can be represented as global features across the entire nerve simultaneously via bothrate and place coding.|$|E
40|$|We {{study the}} problem of {{statistically}} correct inference in networks whose basic representations are <b>population</b> <b>codes.</b> <b>Population</b> <b>codes</b> are ubiquitous in the brain, and involve thesimultaneous activity ofmany units coding for some low dimensional quantity. A classic example are place cells in the rat hippocampus: these re when the animal is at a particular place in an environment, so the underlying quantity has two dimensions of spatial location. We show howtointerpret the activity as encoding whole probability distributions over the underlying variable rather then just single values, and propose a method of inductively learning mappings between <b>population</b> <b>codes</b> that are computationally tractable and yet o er good approximations to statistically optimal inference. We simulate the method on some simple examples to prove its competence. In a population code, information about some lowdimensional quantity (such as {{the position of a}} visual feature) is represented in the activity of a collection of units, each responding to a limited range of stimuli within this low-dimensional space. Strong evidence exists for this form of coding at the sensory input areas of the brain (eg retinotopic and tonotopic maps) {{as well as at the}} motor output level [Georgopoulos et al., 1986]. Evidence is mounting that many other intermediate neural processing areas also use <b>population</b> <b>codes</b> [Tanaka, 1996]. Certain important questions about <b>population</b> <b>codes</b> have been extensively investigated, including how toextract an optimal underlying value [Salinas and Abbott, 1994 � Snippe, 1996] and how to learn such representations [Kohonen, 1982]. However, two important issues have been almost ignored (with the important exception of [Anderson, 1994]). One is the treatment of <b>population</b> <b>codes</b> as encoding whole probability density functions (PDFs) over the underlying quantities rather than just a singl...|$|E
5000|$|There are two {{different}} HLA-DRA chains in the human <b>population</b> <b>coded</b> by three different DRA alleles: ...|$|R
50|$|<b>Population</b> <b>coding</b> has {{a number}} of other {{advantages}} as well, including reduction of uncertainty due to neuronal variability and the ability to represent a number of different stimulus attributes simultaneously. <b>Population</b> <b>coding</b> is also much faster than rate coding and can reflect changes in the stimulus conditions nearly instantaneously. Individual neurons in such a population typically have different but overlapping selectivities, so that many neurons, but not necessarily all, respond to a given stimulus.|$|R
30|$|In {{the upper}} level {{programming}} model, <b>population</b> <b>coding</b> was adopted for antibody. Based on the decision variable, set two antibodies A and B.|$|R
40|$|Abstract — Information {{processing}} in {{the nervous}} system involves the activity of large populations of neurons. It is difficult to extract information from these <b>population</b> <b>codes</b> because of the noise inherent in neuronal responses. We propose a divisive normalization model to read the <b>population</b> <b>codes.</b> The dynamics of the model are analyzed by continuous attractor theory. Under certain conditions, the model possesses continuous attractors. Moreover, the explicit expressions of the continuous attractors are provided. Simulations are employed to illustrate the theory. Index Terms — Continuous attractor, divisive normalization model, multiple-peaked activity, population decoding. I...|$|E
40|$|We {{study the}} problem of {{statistically}} correct inference in networks whose basic representations are <b>population</b> <b>codes.</b> <b>Population</b> <b>codes</b> are ubiquitous in the brain, and involve the simultaneous activity of many units coding for some low dimensional quantity. A classic example are place cells in the rat hippocampus: these fire when the animal is at a particular place in an environment, so the underlying quantity has two dimensions of spatial location. We show how to interpret the activity as encoding whole probability distributions over the underlying variable rather then just single values, and propose a method of inductively learning mappings between <b>population</b> <b>codes</b> that are computationally tractable and yet offer good approximations to statistically optimal inference. We simulate the method on some simple examples to prove its competence. In a population code, information about some lowdimensional quantity (such as {{the position of a}} visual feature) is represented in the activity of a [...] ...|$|E
40|$|Cortical {{circuits}} {{perform the}} computations underlying rapid perceptual decisions {{within a few}} dozen milliseconds with each neuron emitting only a few spikes. Under these conditions, the theoretical analysis of neural <b>population</b> <b>codes</b> is challenging, as {{the most commonly used}} theoretical tool &#x 2013; Fisher information &#x 2013; can lead to erroneous conclusions about the optimality of different coding schemes. Here we revisit the effect of tuning function width and correlation structure on neural <b>population</b> <b>codes</b> based on ideal observer analysis in both a discrimination and reconstruction task. We show that the optimal tuning function width and the optimal correlation structure in both paradigms strongly depend on the available decoding time in a very similar way. In contrast, <b>population</b> <b>codes</b> optimized for Fisher information do not depend on decoding time and are severely suboptimal when only few spikes are available. In addition, we use the neurometric functions of the ideal observer in the classification task to investigate the differential coding properties of these Fisher-optimal codes for fine and coarse discrimination. We find that the discrimination error for these codes does not decrease to zero with increasing population size, even in simple coarse discrimination tasks. Our results suggest that quite different <b>population</b> <b>codes</b> may be optimal for rapid decoding in cortical computations than those inferred from the optimization of Fisher information...|$|E
40|$|Exposure to faces biases {{perceptions}} of subsequently viewed faces such that normality judgments of similar faces are increased. Simultaneously inducing such an aftereffect ill opposite directions for {{two groups of}} faces might indicate discrete responding of the neural <b>populations</b> <b>coding</b> for those groups. Here we show such "category contingent" aftereffects following exposure to faces differing in eye-spacing (wide versus narrow) for European versus African faces, adult versus infant faces, and human versus monkey faces. As aftereffects reflect changes in responses of neural <b>populations</b> that <b>code</b> faces, our results may then suggest that functionally distinct neural <b>populations</b> <b>code</b> faces of different ages, races and species and that the human brain potentially contains discrete representations of these categories...|$|R
40|$|<b>Population</b> <b>coding</b> is the {{quantitative}} study of which algorithms or representations {{are used by}} the brain to combine together and evaluate the messages carried by different neurons. Here, we review an information-theory-based approach to <b>population</b> <b>coding.</b> We discuss how to quantify the information carried by a neural population and how to quantify the contribution of individual members of the population, or the interaction between them, to the overall information encoded by the considered group of neurons. We present examples of applications of this formalism to simultaneous recordings of multiple spike trains...|$|R
40|$|Introduction Studies of <b>population</b> <b>coding,</b> which {{explore how}} the {{activity}} of ensembles of neurons represent the external world, normally focus on the accuracy and reliability with which sensory information is represented. However, the encoding strategies used by neural circuits have undoubtedly been shaped {{by the way the}} encoded information is used. The point of encoding sensory information is, after all, to generate and guide behavior. The ease and efficiency with which sensory information can be processed to generate motor responses must be an important factor in determining the nature of a neuronal <b>population</b> <b>code.</b> In other words, to understand how populations of neurons encode we cannot overlook how they compute. Gain modulation, which is seen in many cortical areas, is a change in the response amplitude of a neuron that is not accompanied by a modification of response selectivity. Just as <b>population</b> <b>coding</b> is a ubiquitous form of information representation, gain modulat...|$|R
40|$|Cortical {{circuits}} perform computations within few {{dozens of}} milliseconds with each neuron emitting {{only a few}} spikes. In this regime conclusions based on Fisher information, which is commonly {{used to assess the}} quality of <b>population</b> <b>codes,</b> are not always valid. Here we revisit the effect of tuning function width and correlation structure on neural <b>population</b> <b>codes</b> for angular variables using ideal observer analysis in both reconstruction and classification tasks employing Monte-Carlo simulations and analytical derivations. We show that the optimal tuning width of individual neurons and the optimal correlation structure of the population depend on the signal-to-noise ratio for both the reconstruction and the classification task. Strikingly, both ideal observers lead to very similar conclusions at low signal-to-noise ratio. In contrast, Fisher information favors severely suboptimal coding schemes in this regime. To further investigate the coding properties of Fisher-optimal codes, we compute the full neurometric functions of an ideal observer in the stimulus discrimination task, which allows us to evaluate <b>population</b> <b>codes</b> separately for fine and coarse discrimination. We find that codes with Fisher-optimal tuning width show strikingly bad performance for simple coarse discrimination tasks with a ëpedestal errorí, which is independent of population size. We show analytically that this is a necessary consequence of the fact that in such codes only few neurons are activated by each stimulus, irrespective of the population size. Further we show that the initial region of the neurometric function goes to zero with increasing population size. As a consequence, the overall error achieved by Fisher-optimal ensembles saturates for large populations. In summary, based on exact ideal observer analysis for both stimulus reconstruction and discrimination tasks we obtained (1) an accurate assessment of neural <b>population</b> <b>codes</b> at all signal-to-noise ratios and (2) analytical insights into the suboptimal behavior of Fisher-optimal <b>population</b> <b>codes...</b>|$|E
40|$|We discuss {{feed-forward}} architectures that compute with <b>population</b> <b>codes.</b> Using radial basis functions we {{implement a}} layered network of noisy integrate-and-fire neurons which computes {{the sum of}} two population coded quantities. The network performs the computation robustly, accurately and quickly...|$|E
40|$|The {{relative}} {{merits of}} different population coding schemes have mostly been analyzed {{in the framework}} of stimulus reconstruction using Fisher Information. Here, we consider the case of stimulus discrimination in a two alternative forced choice paradigm and compute neurometric functions in terms of the minimal discrimination error and the Jensen-Shannon information to study neural <b>population</b> <b>codes.</b> We first explore the relationship between minimum discrimination error, Jensen-Shannon Information and Fisher Information and show that the discrimination framework is more informative about the coding accuracy than Fisher Information as it defines an error for any pair of possible stimuli. In particular, it includes Fisher Information as a special case. Second, we use the framework to study <b>population</b> <b>codes</b> of angular variables. Specifically, we assess the impact of different noise correlations structures on coding accuracy in long versus short decoding time windows. That is, for long time window we use the common Gaussian noise approximation. To address the case of short time windows we analyze the Ising model with identical noise correlation structure. In this way, we provide a new rigorous framework for assessing the functional consequences of noise correlation structures for the representational accuracy of neural <b>population</b> <b>codes</b> that is in particular applicable to short-time population coding. ...|$|E
40|$|In neuroscience, <b>population</b> <b>coding</b> {{theory has}} {{demonstrated}} that fault-tolerant information processing {{can be achieved by}} neural assemblies. Transposed to nanoelectronics, this strategy could allow computing reliably with ultimately scaled-down, noisy, imperfect devices. This approach requires that the response functions to inputs of the population components form a set of basis functions, thus offering a physical substrate for calculating. For this purpose, the nanodevice responses should be non-linear, and each tuned to different values of the input. These strong requirements have until now prevented a demonstration of <b>population</b> <b>coding</b> with nanodevices. Here we show that nanoscale magnetic tunnel junctions can be assembled to exhibit such neural-like ensemble responses. We demonstrate experimentally that a population of nine junctions can implement a basis set of functions, allowing, for instance, the generation of cursive letters. Through simulations, we show that systems based on interlinked populations of junctions can learn to realize low power, variability-resilient non-linear transformations through <b>population</b> <b>coding.</b> Comment: 4 figure...|$|R
40|$|We {{study the}} impact of {{correlated}} neuronal firing rate variability on the accuracy with which an encoded quantity can be extracted from a population of neurons. Contrary to a widespread belief, correlations in the variabilities of neuronal firing rates do not, in general, limit the increase in coding accuracy provided by using large populations of encoding neurons. Furthermore, in some cases, but not all, correlations improve the accuracy of a <b>population</b> <b>code.</b> Introduction In <b>population</b> <b>coding</b> schemes, the activities {{of a number of}} neurons jointly encode the value of a quantity. A frequently touted advantage of <b>population</b> <b>coding</b> is that it suppresses the effects of neuronal variability. The observation of correlations in the trial-to-trial fluctuations of simultaneously recorded neurons (Gawne & Richmond, 1993; Zohary et al, 1994; Lee et al, 1998) has raised some doubt as to whether this advantage is actually realized in real nervous systems. The dramatic effects of correlated varia [...] ...|$|R
40|$|AbstractMorphological {{differentiation}} of N 2 A nouroblastoma cells {{is associated with}} an altered splicing of the gene of the microtubule-associated protein, tau. Two <b>populations</b> of RNA (<b>coding</b> for tau proteins containing three or four tubulin-binding motifs) are present in a similar proportion in undifferentiated neuroblastoma cells while in differentiated cells the proportion is changed in favour of that <b>population</b> <b>coding</b> for tau protein containing four tubulin-binding motifs. An increase in a high molecular weight tau isoforms correlates {{with the increase in}} the RNA <b>population</b> <b>coding</b> for four tubulin-binding motifs. A possible consequence of expressing a higher proportion of the tau protein containing four tubulin-binding motifs could be an increase in microtubule stability of differentiated neuroblastoma cells...|$|R
40|$|This {{section is}} {{organized}} into three parts. In the first, {{we show that}} when the likelihood function, p(r|s), belongs to the exponential family with linear sufficient statistics, optimal cue combination can be performed by a simple network in which firing rates from two <b>population</b> <b>codes</b> are combined linearly. Moreover, we show that the tuning curves of the two populations don’t need to be identical, and that the responses both within and across populations don’t need to be uncorrelated. In the second part, we consider the specific case of independent Poisson noise, which {{provides an example of}} a distribution belonging to the exponential family with linear sufficient statistics. We also consider a distribution that does not belong to the exponential family with linear sufficient statistics, namely, independent Gaussian noise with fixed variance. We show that, for this case, optimal cue combination requires a nonlinear combination of the <b>population</b> <b>codes.</b> In the third part, we describe in detail the parameters of the network of conductance-based integrate-and-fire neurons. 1. Probabilistic <b>Population</b> <b>Codes</b> for Optimal Cue Combination 1. 1 Bayesian inference through linear combinations for the exponential family Consider two <b>population</b> <b>codes,</b> r 1 and r 2 (both of which are vectors of firing rates), which code for the same stimulus, s. As described in the main text, this coding is probabilistic, so r 1 and r 2 are related to the stimulus via a likelihood function, p(r 1,r 2 |s). In a cue integration experiment, we need to construct a third population code, r 3, related to r 1 and r 2 via some function: r 3 =F(r 1,r 2). Given this function, p(r 3 |s) is given by () = () δ − () p r | s p r, r | s r F r, r drdr...|$|E
40|$|This thesis {{combines}} {{arguments of}} efficient coding with models and constraints of population coding and population dynamics {{in order to}} derive optimal <b>population</b> <b>codes.</b> Starting from the standard model of population coding {{for the study of}} optimal tuning widths, diverging conclusions in the literature are resolved by the introduction of a new independent parameter, namely the dynamic range of a tuning function. The difficulties of applying this standard model to neuronal representations of, say natural images, motivates a more exhaustive search for characteristic features of <b>population</b> <b>codes</b> that are most relevant for coding efficiency. Minimizing the dynamic ranges of the tuning functions turns out to be most important for the maximization of Fisher information. At the same time, however, the optimization of <b>population</b> <b>codes</b> without strong a priori constraints on the shape of tuning functions uncovers severe limitations of Fisher information as a measure for coding efficiency. Direct numerical evaluations of the minimum mean square error are used (for {{the first time in the}} literature) to compare the efficiency of characteristic examples of <b>population</b> <b>codes,</b> confirming the advantage of a small dynamic range. The results on optimal population coding in the first part of this thesis are summarized in the proposal of the Bernoulli coding hypothesis. In short, it states that rate coding at physiologically plausible time scales suggests the use of binary coding rather than analog coding. The Bernoulli coding hypothesis is challenged by criteria other than coding efficiency as well. Additionally to the study of the influence of computational constraints on the neuronal readout, the question of the robustness of a code and the possibility of faithful signal transmission in spite of the neuronal dynamics are investigated in the second part of the thesis. In particular the latter provides an additional, independent argument for the Bernoulli coding hypothesis...|$|E
40|$|We {{report a}} {{mechanism}} for selective routing of population-coded signals ► Spatial rate codes can be reproduced as oscillation amplitude patterns ► A feed-forward interneuron layer can be tuned {{to act as a}} band-pass filter ► We show how multiple <b>population</b> <b>codes</b> can be represented in parallel by oscillation...|$|E
30|$|The ZIP <b>code</b> <b>population</b> {{data are}} {{available}} from Splitwise, which includes ZIP <b>code</b> <b>population</b> data [31] and ZIP <b>code</b> <b>population</b> density data [32]. These datasets were derived from the US Census Bureau [23].|$|R
40|$|The primary {{visual cortex}} is an {{excellent}} model system for investigating how neuronal populations encode information, because of well-documented relationships between stimulus characteristics and neuronal activation patterns. We used two-photon calcium imaging data to relate the performance of different methods for studying <b>population</b> <b>coding</b> (<b>population</b> vectors, template matching and Bayesian decoding algorithms) to their underlying assumptions. We show that the variability of neuronal responses may hamper the decoding of population activity, and that a normalization to correct for this variability may be of critical importance for correct decoding of population activity. Second, by comparing noise correlations and stimulus tuning we find that these properties have dissociated anatomical correlates, even though noise correlations have been previously hypothesized to reflect common synaptic input. We hypothesize that noise correlations arise from large nonspecific increases in spiking activity acting on many weak synapses simultaneously, while neuronal stimulus response properties are dependent on more reliable connections. Finally, this paper provides practical guidelines for further research on <b>population</b> <b>coding</b> and shows that <b>population</b> <b>coding</b> cannot be approximated by a simple summation of inputs, but is heavily influenced by factors such as input reliability and noise correlation structure...|$|R
5000|$|Little, AC, DeBruine, LM, Jones, BC (all 3 authors contributed equally) (2005). Sex-contingent face aftereffects suggest {{distinct}} neural <b>populations</b> <b>code</b> {{male and}} female faces. Proceedings of the Royal Society of London, B, 272(1578): 2283-2287.|$|R
40|$|Most {{theoretical}} and empirical studies of cortical <b>population</b> <b>codes</b> make the assumption that underlying neuronal activities is a unique and unambiguous value of an encoded quantity. We propose an alternative hypothesis, that neural populations represent, and effectively compute probabilities. Under this hypothesis, population activities can contain additional information about such things as multiple values of or uncertainty about the quantity. We discuss methods for recovering this extra information, and show how this approach bears on psychophysical and neurophysiological studies. A natural extension of this probabilistic interpretation hypothesis casts interacting populations as a belief network, a structure which permits the analysis of information propagation from one population to another. This novel framework for <b>population</b> <b>codes</b> opens up new avenues for studying a diverse set of problems, including cue combination, decision-making, and visual attention. 1 Introductio [...] ...|$|E
40|$|Here we show that, {{under certain}} {{realistic}} conditions, we can apply {{the theory of}} optimal decision making to the biologically more plausible probabilistic <b>population</b> <b>codes</b> (PPCs; Ma et al. 2006). Our analysis shows that, with <b>population</b> <b>codes,</b> the optimal decision bounds are {{a function of the}} neural activity of all neurons in the population, rather than a previously postulated bound on its maximum activity. This theory predicts that the bound on the most active neurons would appear to shift depending on the firing rate of other neurons in the population, a puzzling behavior under the drift diffusion model as it would wrongly suggest that subjects change their stopping rule across conditions. This theory also applies to the case of time varying evidence, a case that cannot be handled by drift diffusion models without unrealistic assumptions...|$|E
40|$|Hippocampal <b>population</b> <b>codes</b> play an {{important}} role in representation of spatial environment and spatial navigation. Uncovering the internal representation of hippocampal <b>population</b> <b>codes</b> will help understand neural mechanisms of the hippocampus. For instance, uncovering the patterns represented by rat hippocampus (CA 1) pyramidal cells during periods of either navigation or sleep has been an active research topic over the past decades. However, previous approaches to analyze or decode firing patterns of population neurons all assume the knowledge of the place fields, which are estimated from training data a priori. The question still remains unclear how can we extract information from population neuronal responses either without a priori knowledge or in the presence of finite sampling constraint. Finding the answer to this question would leverage our ability to examine the population neuronal codes under different experimental conditions. Using rat hippocampus as a model system, we attempt to uncover the hidden "spatial topology" represented by the hippocampal <b>population</b> <b>codes.</b> We develop a hidden Markov model (HMM) and a variational Bayesian (VB) inference algorithm to achieve this computational goal, and we apply the analysis to extensive simulation and experimental data. Our empirical results show promising direction for discovering structural patterns of ensemble spike activity during periods of active navigation. This study would also provide useful insights for future exploratory data analysis of population neuronal codes during periods of sleep. status: publishe...|$|E
40|$|This study {{examines}} {{the relationship between}} <b>population</b> <b>coding</b> and spatial connection statistics in networks of noisy neurons. Encoding of sensory information in the neocortex is thought to require coordinated neural populations, because individual cortical neurons respond {{to a wide range}} of stimuli, and exhibit highly variable spiking in response to repeated stimuli. <b>Population</b> <b>coding</b> is rooted in network structure, because cortical neurons receive information only from other neurons, and because the information they encode must be decoded by other neurons, if it is to affect behavior. However, <b>population</b> <b>coding</b> theory has often ignored network structure, or assumed discrete, fully connected populations (in contrast with the sparsely connected, continuous sheet of the cortex). In this study, we modeled a sheet of cortical neurons with sparse, primarily local connections, and found that a network with this structure could encode multiple internal state variables with high signal-to-noise ratio. However, we were unable to create high-fidelity networks by instantiating connections at random according to spatial connection probabilities. In our models, high-fidelity networks required additional structure, with higher cluster factors and correlations between the inputs to nearby neurons...|$|R
40|$|A {{geometric}} {{interpretation of}} <b>population</b> <b>coding</b> is described which gives an intuitive {{understanding of how}} individual sensor/receptor "tunings" define the overall performance of a sensory system based upon such a code. The approach is demonstrated by applying it to biologically realistic, and synthetic olfactory systems. The analytical measures developed {{as part of this}} treatment may be widely to optimize the detection performance of artificial "electronic nose" systems as well as for comparing different tuning scenarios in the biological olfactory pathway. The examples show clearly how a <b>population</b> <b>coded</b> sensory system can deliver both extreme selectivity to compounds of interest without comprising the range of stimuli that may be perceived...|$|R
40|$|The {{superior}} colliculus (SC) and pulvinar {{are thought to}} function as a subcortical visual pathway that bypasses the striate cortex and detects fundamental facial information. We previously investigated neuronal responses in the SC and pulvinar of monkeys during a delayed nonmatching-to-sample task, in which the monkeys were required to discriminate among 35 facial photos of five models and other categories of visual stimuli, and reported that <b>population</b> <b>coding</b> by multiple SC and pulvinar neurons well discriminated facial photos from other categories of stimuli (Nguyen et al., 2013, 2014). However, it remains unknown whether <b>population</b> <b>coding</b> could represent multiple types of facial information including facial identity, gender, facial orientation, and gaze direction. In the present study, to investigate <b>population</b> <b>coding</b> of multiple types of facial information by the SC and pulvinar neurons, we reanalyzed the same neuronal responses in the SC and pulvinar; the responses of 112 neurons in the SC and 68 neurons in the pulvinar in serial 50 -ms epochs after stimulus onset were reanalyzed with multidimensional scaling (MDS). The results indicated that <b>population</b> <b>coding</b> by neurons in both the SC and pulvinar classified some aspects of facial information, such as face orientation, gender, and identity, of the facial photos in the second epoch (50 – 100 ms after stimulus onset). The Euclidean distances between all the pairs of stimuli in the MDS spaces in the SC were significantly correlated with those in the pulvinar, which suggested that the SC and pulvinar function as a unit. However, in contrast with the known <b>population</b> <b>coding</b> of face neurons in the temporal cortex, the facial information coding in the SC and pulvinar was coarse and insufficient. In these subcortical areas, identity discrimination was face orientation-dependent and the left and right profiles were not discriminated. Furthermore, gaze direction information was not extracted in the SC and pulvinar. These results suggest that the SC and pulvinar, which comprise the subcortical visual pathway, send coarse and rapid information on faces to the cortical system in a bottom-up process...|$|R
