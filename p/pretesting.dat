577|9671|Public
2500|$|Cluster {{grouping}} is {{the gathering}} of four to six gifted and talented and/or high achieving students in a single classroom for the entire school day. [...] Cluster teachers are specially trained in differentiating for gifted learners. [...] Clusters are typically used in upper elementary grades. [...] Within a cluster group, instruction may include enrichment and extensions, higher-order thinking skills, <b>pretesting</b> and differentiation, compacting, an accelerated pace, and more complexity in content.|$|E
2500|$|The {{regular school}} {{material}} is compacted by <b>pretesting</b> {{the student to}} establish which skills and content have already been mastered. [...] Pretests can be presented {{on a daily basis}} (pupils doing the most difficult items on a worksheet first and skipping the rest if they are performed correctly), or before a week or longer unit of instructional time. [...] When a student demonstrates an appropriate level of proficiency, further repetitive practice can be safely skipped, thus reducing boredom and freeing up time for the student to work on more challenging material.|$|E
2500|$|The SAT {{has four}} sections: Reading, Writing and Language, Math (no calculator), and Math (calculator allowed). The test taker may {{optionally}} {{write an essay}} which, in that case, is the fifth test section. The total time for the scored portion of the SAT is three hours (or three hours and fifty minutes if the optional essay section is taken). Some test takers who are not taking the essay may also have a fifth section which is used, at least in part, for the <b>pretesting</b> of questions that may appear on future administrations of the SAT. (These questions {{are not included in}} the computation of the SAT score.) Two section scores result from taking the SAT: Evidence-Based Reading and Writing, and Math. Section scores are reported on a scale of 200 to 800, and each section score is a multiple of ten. A total score for the SAT is calculated by adding the two section scores, resulting in total scores that range from 400 to 1600. There is no penalty for guessing on the SAT: scores are {{based on the number of}} questions answered correctly. In addition to the two section scores, three [...] "test" [...] scores on a scale of 10 to 40 are reported, one for each of Reading, Writing and Language, and Math. The essay, if taken, is scored separately from the two section scores.|$|E
2500|$|<b>Pretest</b> odds = (<b>Pretest</b> {{probability}} / (1 - <b>Pretest</b> probability) ...|$|R
40|$|The {{purpose of}} this study was to compare and {{evaluate}} three online <b>pretest</b> item calibration/scaling methods (the marginal maximum likelihood estimate with one EM cycle (OEM) method, the marginal maximum likelihood estimate with multiple EM cycles (MEM) method, and Stocking’s Method B) in terms of item parameter recovery when the item responses to the <b>pretest</b> items in the pool would be sparse. Simulations of computerized adaptive tests (CAT) were used to evaluate results yielded by the three methods. The MEM method produced the smallest average total error in recovering the 240 <b>pretest</b> item characteristic curves. Stocking's Method B yielded the second smallest average total error in parameter estimation. The OEM method yielded a large average total error in parameter estimation. In terms of scale maintenance, the MEM method and Stocking's Method B performed well in keeping the scale of the <b>pretest</b> items on the same scale as that of the true parameters. With the OEM method, the scale of the <b>pretest</b> item parameter estimates deviated from that of the true parameters. 3 Calibrating <b>pretest</b> items is a necessary part of a large computerized adaptive testing (CAT) program. Collecting online <b>pretest</b> item responses and calibrating the <b>pretest</b> items based on those responses are a way of replenishing an item pool. Online <b>pretest</b> item calibration refer...|$|R
3000|$|Not surprisingly, {{students}} {{performed better}} on items {{for which they}} had succeeded on the corresponding item at <b>pretest</b> than on items for which they had not succeeded on the corresponding item at <b>pretest,</b> z[*]=[*] 4.50, p[*]<[*]. 001; including <b>pretest</b> scores in the model significantly improved model fit, χ [...]...|$|R
5000|$|Requires <b>pretesting</b> for {{selecting}} optimum machine setting before starting the normal service.|$|E
5000|$|Lee Weinblatt, {{in tandem}} with <b>PreTesting</b> Company, has filed patents for the following: ...|$|E
5000|$|... <b>pretesting</b> - {{determines the}} {{probable}} {{impact of the}} PSYOP on the target audience ...|$|E
40|$|In {{line with}} the {{cognitive}} theory of multimedia learning by Moreno and Mayer (2007), an interactive, multimodal learning environment was designed for the pretraining of science concepts in the joint area of physics, chemistry, biology, applied mathematics, and computer sciences. In the experimental set up, a <b>pretest</b> was embedded {{in order to increase}} the effect of the treatment. The <b>pretest</b> consisted of short-answer and multiple-choice questions. The results show a high learning gain, especially after applying a <b>pretest.</b> The learning gain was insignificant if no treatment followed the <b>pretest.</b> The <b>pretest</b> effect did not depend on the question type. Time on task was not a significant variable...|$|R
40|$|In {{an earlier}} study {{it was found that}} a <b>pretest</b> {{containing}} positive statements counteracted the development of negative feelings toward a treatment. The present experiment sought both to replicate the earlier study and to answer an additional question: Is the biasing effect general or is it restricted to <b>pretest</b> content? Again, it appeared that a positive <b>pretest</b> acts as a device to counteract the development of negative sentiments. The effect size, small in the original experiment, was even smaller in the present experiment. Moreover, {{it was found that the}} sensitization effect operated only when the <b>pretest</b> and the posttest were identical. Using dissimilar <b>pretest</b> and posttest measures eliminated the biasing effect...|$|R
30|$|Our primary {{dependent}} {{measure was}} {{the change in}} test scores from the <b>pretest</b> to the post-test (post-test number correct – <b>pretest</b> number correct).|$|R
5000|$|The use of {{formative}} {{research in}} product and message {{design and the}} <b>pretesting</b> of these materials ...|$|E
5000|$|Develop Assessment Instruments: Purpose {{of entry}} {{behavior}} testing, purpose of <b>pretesting,</b> purpose of post-testing, purpose of practive items/practive problems ...|$|E
50|$|Before administration, {{the exam}} {{material}} {{is subject to}} two rounds of moderation {{by a panel of}} judges, <b>pretesting</b> and statistical analysis.|$|E
40|$|The folder 'pretest' {{contains}} {{materials and}} {{results of the}} two <b>pretests</b> that were performed on the materials as a web-experiment. Each folder (<b>pretest</b> 1 and <b>pretest</b> 2) contains instructions to participants, an agreement form, and a file with raw results given by participants. In addition, the <b>pretest</b> 1 folder contains a folder with all pictures used in that experiment and a summary file of the results. In this file, MFW stands for most frequent word, that is, the word that was named most frequently by participants. The <b>pretest</b> 2 folder additionally contains files for the four stimulus lists used in the experiment and an R-script that calculates the values reported in the paper per item and creates graphs of the results. The picture stimuli in <b>pretest</b> 2 {{are the same as}} in the main experiment (see Stimuli/Pictures) ...|$|R
40|$|Two studies {{evaluated}} {{communication skills}} training {{by using a}} pretest-posttest design, including retrospective <b>pretest</b> ratings, to control for response shift bias. A response shift {{is a change in}} a subject's internal standard for determining his or her level of functioning on a given dimension. In Exp 1, Ss were 37 hospital employees. Data indicated that the self-report <b>pretest</b> exerted a clear effect on subsequent self-report posttest and retrospective <b>pretest</b> ratings. Training was ineffective and a response shift did not occur. Experimental Ss could not remember and control Ss could remember their pretreatment ratings to a reasonable extent. In Exp 2, Ss were 58 3 rd-year dental students. Results show that the training was effective. A behavioral <b>pretest</b> administered prior to the self-report <b>pretest</b> prevented a response shift from occurring. This finding gives empirical support to the contention that Ss' lack of sufficient information about their level of functioning at <b>pretest</b> may be a causal determinant of the response shift. Data also indicate that the retrospective <b>pretest</b> is robust for procedural differences in administering this instrument...|$|R
40|$|Response-shift bias {{has been}} shown to {{contaminate}} self-reported pretest/posttest evaluations of various interventions. To eliminate the detrimental effects of response shifts, retrospective measures have been employed as substitutes for the traditional self-reported <b>pretest.</b> Informed <b>pretests,</b> wherein subjects are provided information about the construct being measured prior to completing the <b>pretest</b> self-report, are considered in the present studies as an alternative method to retrospective <b>pretests</b> in reducing response-shift effects. In Study 1 subjects were given a 20 -minute presentation on assertiveness, which failed to significantly improve the accuracy of self-reported assertiveness. Other procedural influences hypothesized to improve self-report accuracy-previous experience with the objective measure of assertiveness and previous completion of the self-report measure-also were not related to increased self-report accuracy. In a second study, information about interviewing skills was provided at <b>pretest</b> using behaviorally anchored rating scales to participants in a workshop on interviewing skills. Response-shift bias was not attenuated by providing subjects with information about interviewing prior to the intervention. Change measures which employed retrospective <b>pretest</b> measures demonstrated somewhat higher (although nonsignificant) validity coefficients than measures of change utilizing informed <b>pretest</b> data...|$|R
50|$|<b>PreTesting</b> Company is {{a full-service}} Market {{research}} company founded in 1985 {{that specializes in}} print, television, and radio ad copy testing.|$|E
5000|$|<b>PreTesting</b> Company’s most {{advanced}} innovation {{to date has}} been a recording device that tracks movements of the eye, called saccades. Through saccadic eye tracking, <b>Pretesting</b> Company can determine not only where a viewer is looking as he’s watching an ad, but also how visually stimulating the ad is. These results can help companies gauge whether their ads are visually stimulating {{enough to keep the}} viewers attention, or in contrast, whether they're so visually stimulating that no actual information is absorbed.|$|E
50|$|Actual {{development}} of communication methods and materials are undertaken once {{the communication strategy}} is in place.A useful reminder to planners concerns the importance of <b>pretesting</b> not only the materials themselves, but also the creative idea and the messages. <b>Pretesting</b> allows for adjustments in the communication activities before substantial time, efforts, and resources are spent on their actual production.Pretesting measures potential effectiveness of communication messages, methods, and materials {{in terms of their}} being able to attract attention, to be understood, to be accepted, and to generate the feeling of self-involvement among the stakeholders.|$|E
40|$|This paper {{illustrates}} {{the use of}} laboratory experimental auctions in a <b>pretest</b> market research program for new products. We review the experimental auctions literature, discuss the range of auction mechanisms available and present {{the advantages and disadvantages}} of using a particular mechanism for a laboratory <b>pretest</b> market. We then present a step-by-step example of how a theoretically incentive compatible auction mechanism (fifth-price, sealed-bid) was used in a laboratory <b>pretest</b> market for vacuum-packaged beef. Based on the illustration, we discuss the potential for using laboratory experimental auctions in <b>pretest</b> market research. We present the limitations that may be encountered in such applications and outline research aimed at improving the behavioral properties of the technique. auctions, <b>pretest</b> market...|$|R
40|$|Studied the biasing {{effects of}} a <b>pretest</b> on {{subsequent}} posttest results in 2 experiments. The problem of Exp I, with 119 undergraduates, was the evaluation of a programed textbook used by psychology freshmen. It used a separate-sample pretest-posttest design and showed that a <b>pretest</b> containing mostly negative statements on programed instruction confounded posttest results. Exp II, using a different treatment, studied the <b>pretest</b> effects of positive or negative statements on 162 undergraduates. The positive version counteracted the development of negative feelings toward the treatment. The negative version did not show a similar sensitizing effect. This was considered {{a consequence of the}} controversial character of the treatment and the obligatory participation of Ss. The negative statements perhaps confirmed existing attitudes. Three suggestions to control for <b>pretest</b> sensitization effects are given: Use research designs with control conditions, separate the <b>pretest</b> phase from the posttest phase, and emphasize designs without <b>pretest...</b>|$|R
30|$|Participants {{performed}} {{well on the}} <b>pretest</b> equation-encoding items, but poorly on the <b>pretest</b> graph-encoding items (see Table  1). Thus, the equation items were quite easy for students, whereas the graph items were challenging. Because there was little room for improvement on the equation-encoding items, our analysis of students’ encoding performance focused on the graph-encoding items only. For each problem element (slope or intercept), we included <b>pretest</b> scores on the corresponding element as a potential predictor of posttest performance; these scores ranged from 0 to 2 as there were two <b>pretest</b> graph-encoding items.|$|R
50|$|He founded <b>PreTesting</b> Company in 1985, which {{monitors}} {{the effectiveness of}} advertising by monitoring consumer response to commercials. Clients include Ralston Purina, Planters peanuts, Raid insecticide, Sports Illustrated and The New Yorker.|$|E
5000|$|There {{are five}} {{technical}} components {{in building a}} CAT (the following is adapted from Weiss & Kingsbury, 1984 [...] ). This list does not include practical issues, such as item <b>pretesting</b> or live field release.|$|E
5000|$|... "Merger's reggae {{performance}} of [...] "Soweto"... {{is a serious}} piece of polital pop, whose <b>pretesting</b> lyrics and skilful musicianship are more impressive {{than many of the}} fashion-rock bands" [...] (Dr Ian Inglis, Popular Music And Television In Britain) ...|$|E
30|$|<b>Pretest</b> score. There was no {{significant}} difference among the <b>pretest</b> scores of clusters mix, animations, and problems who used the system. All of these groups had higher <b>pretest</b> scores, as compared to cluster inactive, who did not use the system. However, this difference was significant only for cluster mix and cluster inactive (by Tukey’s post hoc test at p=. 025).|$|R
40|$|Two {{experiments}} were done {{to study the}} biasing effects of a <b>pretest</b> on subsequent posttest results. The problem of the first experiment was the evaluation of a programmed textbook used by psychology freshmen. It used a separate-sample pretest-posttest design and showed that a <b>pretest</b> containing mostly negative statements on programmed instruction confounded posttest results. The second experiment, using a different treatment, studied the <b>pretest</b> effects of positive or negative statements. The positive version counteracted the development of negative feelings towards the treatment. The negative version did not show a similar sensitizing effect. This was considered {{a consequence of the}} rather controversial character of the treatment and the obligatory participation of subjects. The negative statements perhaps confirmed existing attitudes. Three suggestions to control for <b>pretest</b> sensitization effects were given: (1) use research designs with control conditions; (2) separate the <b>pretest</b> phase from the posttest phase; and (3) give more emphasis to designs without <b>pretests...</b>|$|R
30|$|To perform <b>pretest</b> {{and posttest}} evaluation, MWP test and Q-L 2 SRL were {{conducted}} {{before and after}} the intervention. The intervention was taken place about 1  month after conducting the <b>pretest.</b>|$|R
5000|$|In 1985, Weinblatt started <b>PreTesting</b> Company {{in order}} to provide {{advertising}} companies with insights into the effectiveness of their print, radio, and TV ads. The company tests subjects in situations where they are unaware of how - and why - they're being tested, ensuring authentic, unbiased results.|$|E
5000|$|The Engle-Granger {{approach}} {{as described above}} suffers {{from a number of}} weaknesses. Namely it is restricted to only a single equation with one variable designated as the dependent variable, explained by another variable that is assumed to be weakly exogeneous for the parameters of interest. It also relies on <b>pretesting</b> the time series to find out whether variables are I(0) or I(1). These weaknesses can be addressed through the use of Johansen's procedure. Its advantages include that <b>pretesting</b> is not necessary, there can be numerous cointegrating relationships, all variables are treated as endogenous and tests relating to the long-run parameters are possible. The resulting model is known as a vector error correction model (VECM), as it adds error correction features to a multi-factor model known as vector autoregression (VAR). The procedure is done as follows: ...|$|E
50|$|<b>PreTesting</b> Company {{was founded}} in 1985 by American {{inventor}} and market researcher Lee Weinblatt. After beginning his career at Perception Research, Weinblatt started Telcom Research, a company that manufactured recorders that used an infrared beam to track a viewer as he watched a commercial in a research setting. Weinblatt sold the company in 1983.|$|E
40|$|The {{students}} who accomplished Gestalt learning: 1. Is {{there a difference}} in <b>pretest</b> scores {{between them and the}} ones in the control 2. Is there difference in <b>pretest</b> scores between their <b>pretest</b> and end test scores? 3. Is there difference in end test scores between them and the ones in the control 4. Do the <b>pretest</b> scores differ according to their demographic variables?The percentage of the correct and incorrect answers were found out and the items answered incorrectly were found to be the relative velocity, cause and effect law, friction force, mass gravity, momentum and angular momentum...|$|R
40|$|A {{total of}} 262 {{women in the}} USA (161 breast cancer {{survivors}} and 101 controls) were exposed to a video vignette using modeling in which a physician discussed {{the concept of a}} clinical trial (CT) with a woman who {{was in the process of}} making a treatment decision. A pretest-post-test design was used and improvements in clinical trial knowledge and beliefs were assessed. Results indicate that video modeling is a powerful tool for increasing CT knowledge (<b>pretest</b> MEAN= 41. 5 % correct, post-test MEAN= 77. 5 % correct) but not for improving CT beliefs. Increased clinical trial knowledge, as measured by change scores, was associated with white race, lower levels of education and <b>pretest</b> breast cancer knowledge, more negative <b>pretest</b> CT beliefs, and a higher estimate of the lifetime probability that a woman will have breast cancer. When <b>pretest</b> CT knowledge was added to the analysis using hierarchical multiple regression, all variables except white race became nonsignificant; an increase in CT knowledge was associated with having lower <b>pretest</b> CT knowledge. Results indicate that the effects of low education, low breast cancer knowledge, and biased probability assessment were mediated through the <b>pretest</b> score. An increase in post-test positive CT beliefs was associated with older age, thinking about breast cancer less often, and having lower <b>pretest</b> CT knowledge in the total sample. When <b>pretest</b> CT beliefs was added to the analysis using hierarchical multiple regression, all other variables became nonsignificant; an increase in CT beliefs was associated with having lower <b>pretest</b> CT beliefs, again indicating mediation of the effects of other variables. USA Breast cancer Video intervention Clinical trials Knowledge Beliefs...|$|R
30|$|The study {{included}} data from 675 {{students who participated}} in the mandatory exercises and obtained a non-zero amount of points in {{at least one of the}} nine exercise rounds; 563 of them received enough points from the mandatory exercises to pass the course, and 552 students passed both the exercises and the exam. Out of those students, 424 took both the <b>pretest</b> and post-test. There were 25 students whose performance in the post-test was lower than the <b>pretest</b> (negative learning gain). Following a common argument that negative learning does not occur during an active learning process, we hypothesized that these students may not have taken the post-test seriously or had already very high <b>pretest</b> which gives little room to show learning in the post-test given the limitations of the instrument (small set of questions). Indeed, from these 25 discarded cases, 7 were students with very high <b>pretest</b> (above 0.75), and 15 students with lower <b>pretest</b> were not active in Python Grids. Only 3 students were active in the system and have low <b>pretest.</b> At the end, following similar studies with less reliable assessment (Colt et al. 2011), we decided to remove 25 negative learning gain cases, i.e., for analyses that include <b>pretest</b> and post-test (or learning gain), we only consider 399 students.|$|R
