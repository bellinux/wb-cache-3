608|71|Public
50|$|SearchTogether instantiates {{awareness}} in several ways, {{one of which}} is per-user query histories. This is done by showing each group member’s screen name, his/her photo and queries in the “Query Awareness” region. The access to the query histories is immediate and interactive, as clicking on a query brings back the results of that query from when it was executed. The authors identified query awareness as a very important feature in collaborative searching, which allows group members to not only share their query terms, but also learn better <b>query</b> <b>formulation</b> techniques from one another.|$|E
50|$|It {{should be}} {{considered}} that information science grew out of documentation science and therefore has a tradition for considering scientific and scholarly communication, bibliographic databases, subject knowledge and terminology etc. Library science, {{on the other hand}} has mostly concentrated on libraries and their internal processes and best practices. It is also relevant to consider that information science used to be done by scientists, while librarianship has been split between public libraries and scholarly research libraries. Library schools have mainly educated librarians for public libraries and not shown much interest in scientific communication and documentation. When information scientists from 1964 entered library schools, they brought with them competencies in relation to information retrieval in subject databases, including concepts such as recall and precision, boolean search techniques, <b>query</b> <b>formulation</b> and related issues. Subject bibliographic databases and citation indexes provided a major step forward in information dissemination - and also in the curriculum at library schools.|$|E
40|$|Pre-retrieval <b>query</b> <b>formulation</b> is an {{important}} step for identifying local text reuse. Local reuse with high obfuscation, paraphrasing, and translation poses a challenge of finding the reused text in a document. In this paper, three pre-retrieval <b>query</b> <b>formulation</b> strategies for heuristic retrieval in case of low obfuscated, high obfuscated, and translated text are studied. The strategies used are (a) <b>Query</b> <b>formulation</b> using proper nouns; (b) <b>Query</b> <b>formulation</b> using unique words (Hapax); and (c) <b>Query</b> <b>formulation</b> using most frequent words. Whereas in case of low and high obfuscation and simulated paraphrasing, keywords with Hapax proved to be slightly more efficient, initial results indicate that the simple strategy of <b>query</b> <b>formulation</b> using proper nouns gives promising results and may prove better in reducing the size of the corpus for post processing, for identifying local text reuse in case of obfuscated and translated text reuse...|$|E
40|$|Relevance {{feedback}} {{methods have}} been used in information retrieval to generate improved <b>query</b> <b>formulations</b> based on information contained in previously retrieved documents. The relevance feedback techniques have been applied to extended Boolean <b>query</b> <b>formulations</b> as well as to vector <b>query</b> <b>formulations.</b> In this paper, we propose an adaptive way to improve the retrieval performance in an extended Boolean model. We develop a neural network model in which the weights used in extended Boolean queries can be adjusted by users relevance feedback. Experiments are performed on a TREC collection and the results show improved performance even after applying the previous feedback methods...|$|R
40|$|Five {{independently}} generated Boolean <b>query</b> <b>formulations</b> for ten different TREC topics {{were produced}} by ten different expert online searchers. These different formulations were grouped, and the groups, and combinations of them, {{were used as}} searches against the TREC test collection, using the INQUERY probabilistic inference network retrieval engine. Results show that progressive combination of <b>query</b> <b>formulations</b> leads to progressively improving retrieval performance. Results were compared against the performance of INQUERY natural language based queries, and in combination with them. The issue of recall as a performance measure in large databases was raised, since overlap between the searches conducted in this study, and the TREC- 1 searches, was smaller than expected...|$|R
40|$|In {{this paper}} we present FIRE, a {{content-based}} {{image retrieval system}} and the methods we used in the ImageCLEF 2004 evaluation. In FIRE, different features are available to represent images. This diversity of available features allows the user to adapt the system to task specific characteristics. A weighted combination of these features admits very flexible <b>query</b> <b>formulations</b> and helps in processing specific queries. For the ImageCLEF 2004 evaluation [...] ...|$|R
40|$|<b>Query</b> <b>formulation</b> is an {{essential}} part of successful information retrieval. The challenges in formulating effective queries are emphasized in web information search, because the web is used by a diverse population varying in their levels of expertise. In this paper, the factors affecting <b>query</b> <b>formulation</b> in web information search were studied. The data was collected via a questionnaire (32 participants, each formulated 20 queries). The results of the study suggested that experience in using computers, web, and web search engines affect the <b>query</b> <b>formulation</b> process. Surprisingly, domain expertise did not have an effect on the <b>query</b> <b>formulation.</b> Generally, experienced users formulated longer and more specific queries whereas the queries of users with less experience consisted of fewer and more generic terms. Based on the previous studies concerning <b>query</b> <b>formulation</b> and the results from the questionnaire study, three main factors affecting <b>query</b> <b>formulation</b> are suggested: 1. Media expertise, 2. Domain expertise, and 3. Type of search. These factors should be taken into account when studying and designing information search systems...|$|E
40|$|<b>Query</b> <b>formulation</b> {{interface}} {{remained unchanged}} over the years. It is still mainly an input box for {{the user to}} enter the search query and a search button to initiate the search process. This paper explores and implements an interface design that incorporates dynamic and interactive properties during <b>query</b> <b>formulation.</b> It attempts to match user's search strategies rather than force users to accommodate to the current search interface. It proposes interaction elements to support functionalities that assists user during <b>query</b> <b>formulation.</b> These functionalities include domain filter suggestion, query suggestion, and spelling correction functions...|$|E
40|$|Due to the {{complexity}} of graph query languages, the need for visual query interfaces that can reduce the burden of <b>query</b> <b>formulation</b> is fundamental to the spreading of graph data management tools to a wider community. Despite the significant progress towards building such query interfaces to simplify visual subgraph <b>query</b> <b>formulation</b> task, construction of current generation visual interfaces is not data-driven. That is, it does not exploit the underlying data graphs to automatically generate the contents of various panels in the interface. Such data-driven construction has several benefits such as superior support for subgraph <b>query</b> <b>formulation</b> and portability of the interface across different graph databases. In this demonstration, we present a novel data-driven visual subgraph query interface construction engine called DaVinci. Specifically, it automatically generates from the underlying database two key components of the visual interface to aid subgraph <b>query</b> <b>formulation,</b> namely canned patterns and node labels...|$|E
40|$|West Group {{participated in}} the non-English {{monolingual}} retrieval task for French and German. Our primary interest was to investigate whether retrieval of German or French documents was any different from the retrieval of English documents. We focused on two aspects: stemming for both languages and compound breaking for German, and studied several <b>query</b> <b>formulations</b> {{to take advantage of}} compounds. Our results suggest that German retrieval is indeed different from English or French retrieval, inasmuch as breaking compounds can significantly improve performance...|$|R
40|$|This paper explores how {{information}} visualization {{can help}} users {{evaluate the effectiveness}} of different <b>query</b> <b>formulations</b> or the same query submitted to multiple search engines. MetaCrystal is used to visualize the degree of overlap and similarity between the results returned by different queries or engines. It enables users to identify documents found by multiple queries or engines. Such documents tend to be more relevant and users can use their number and distribution patterns as a visual measure of the effectiveness of their search...|$|R
30|$|As future work, {{we intend}} to study PAC and PExact concept learnability in DLs using <b>queries.</b> The <b>formulations</b> given in Sect.  7 are a {{starting}} point.|$|R
40|$|This paper {{reports the}} results of our {{experiments}} performed for the Query Term Expansion Subtask, a subtask of the WEB Task, at the Fifth NTCIR Workshop, and {{the results of}} our further experiments. In this paper we mainly investigated: (i) the effectiveness of <b>query</b> <b>formulation</b> by composing or decomposing compound words and phrases of the Japanese language, which is based on a theoretical framework via Markov random fields, but taking into account special features of the Japanese language; and (ii) the effectiveness of the combination of phrase-based <b>query</b> <b>formulation</b> and pseudo-relevance feedback. We showed that pseudo-relevance feedback worked well, particularly when using <b>query</b> <b>formulation</b> with compound words...|$|E
40|$|Unity is an {{architecture}} for integrating relational databases that performs three processes: metadata capture, semantic integration, and <b>query</b> <b>formulation</b> and execution. The {{foundation of the}} architecture is a naming methodology that allows concepts to be integrated across systems. Semantic naming of schema constructs increases automation during integration and provides users with physical and logical access transparency during <b>query</b> <b>formulation.</b> 1...|$|E
40|$|Abstract Given a {{document}} d, {{the task of}} text reuse detection is to find those passages in d which in identical or paraphrased form also appear in other documents. To solve this problem at web-scale, keywords representing d’s topics have to be combined to web queries. The retrieved web documents can then be delivered to a text reuse detection system for an in-depth analysis. We focus on the <b>query</b> <b>formulation</b> problem as the crucial {{first step in the}} detection process and present a new <b>query</b> <b>formulation</b> strategy that achieves convincing results: compared to a maximal termset <b>query</b> <b>formulation</b> strategy [10, 14], which is the most sensible non-heuristic baseline, we save on average 70 % of the queries in realistic experiments. With respect to the candidate documents ’ quality, our heuristic retrieves documents that are, on average, more similar to the given document than the results of previously published <b>query</b> <b>formulation</b> strategies [4, 8]. ...|$|E
40|$|Abstract—UMKC {{participated in}} the 2007 legal track. Our {{experiments}} focused mainly on evaluating the different <b>query</b> <b>formulations</b> in the negotiated query refinement process of legal e-discovery. For our study, we considered three sets of paired runs in vector space model and language model respectively. Our experiments indicated that although the Boolean query negotiating process was successful for the standard Boolean retrieval model, it did not make statistically significant query improvements in our ranked systems. This result provided us an insight into the query negotiation process and a new direction to refine queries. I...|$|R
40|$|There {{have been}} many claims {{to the effect that}} {{advanced}} information retrieval technologies such as the vector space model (VSM) significantly outperform Boolean search engines in retrieval effectiveness. Most of these claims are anecdotal and rely on arguments such as: queries are difficult to construct or output size is hard to control. In spite of these claims, most operational retrieval systems in use today are Boolean. Some of the popularity derives from the claim that Boolean IR systems are high precision. We compare and contrast Boolean <b>query</b> <b>formulations,</b> including the effect of query expansion, wit...|$|R
40|$|The {{multiple}} query is a query {{that combines}} Boolean and probabilistic query {{on the information}} retrieval inference network system, the system consists of two components i. e. a dokument and a query network, they are joined by links between the representation and query concepts. The document network build an inverted belief list and the query network are evaluated by using canonical matrix. The similarity process between representation and query conceps yields a set of relevant document retrieved. The experiment has showed {{that the use of}} multiple <b>query</b> <b>formulations</b> will significantly improve the retrieval perfomance, compared to either the Boolean or probabilistic query...|$|R
40|$|In this paper, {{we address}} the problem of <b>query</b> <b>formulation</b> in the context of {{multi-domain}} integration of heterogeneous data on the Web. We argue that effectively tackling this problem requires solutions to query specification and refinement, development and organization of domain taxonomies, and designing query templates to incorporate spatial and temporal conditions across multiple domains. We discuss our approaches in designing the <b>query</b> <b>formulation</b> component for InfoMosaic, our proposed framework for multi-domain information integration. ...|$|E
40|$|Abstract — Due to the {{complexity}} of XML query languages, the need for visual query interfaces that can reduce the burden of <b>query</b> <b>formulation</b> is fundamental to the spreading of XML to wider community. We present a RDBMS-based XML query evaluation system, called XBLEND, that takes a novel and non-traditional approach to improving query performance by blend-ing visual <b>query</b> <b>formulation</b> and query processing. It exploits the latency offered by GUI-based visual <b>query</b> <b>formulation</b> to prefetch portions of the query results. The basic idea is that we prefetch constituent path expressions, store the synopsis of intermediary results, reuse them when connective is added or “Run ” is pressed. In our demonstration we show that our system exhibits promising performance in evaluating XML queries and show its usefulness in life sciences domain. I...|$|E
40|$|A {{new model}} named Boolean Latent Semantic Indexing model {{based on the}} Singular Value Decomposition and Boolean <b>query</b> <b>formulation</b> is introduced. While the Singular Value Decomposition alleviates the {{problems}} of lexical matching in the traditional information retrieval model, Boolean <b>query</b> <b>formulation</b> can help users to make precise representation of their information search needs. Retrieval experiments {{on a number of}} test collections seem to show that the proposed model achieves substantial performance gains over the Latent Semantic Indexing model...|$|E
40|$|Abstract: In this paper, we {{document}} our official submissions to the TREC 2007 Legal track. Our main aims were two-fold: First, we {{experimented with}} using different <b>query</b> <b>formulations</b> trying {{to exploit the}} verbose topic statements. Second, we analysed how ranked retrieval methods can be fruitfully combined with traditional Boolean queries. Our main findings can be summarized as follows. First, we got mixed results trying to combine the original search request with terms extracted from the verbose topic statement. Second, by combining Boolean and ranked retrieval allows us to get the high recall of the Boolean retrieval, whilst precision scores show an improvement over both the Boolean and the ranked retrieval runs...|$|R
40|$|A {{clustered}} file organization {{is one where}} related, or similar records are grouped into classes, or clusters of items {{in such a way}} that all items within a cluster are jointly retrievable. Such a file organization is advantageous for interactive searching where tentative <b>query</b> <b>formulations</b> may be used and the records may be specified incompletely or approximately. An inexpensive file clustering method applicable to large files is given together with an appropriate file search method. The method is used to cluster a file of research articles in computer science based on citation similarities between the papers; this leads to the identification of groups of active computer science research topics and of productive computer scientists...|$|R
40|$|We predict {{entity type}} {{distributions}} in Web search queries via probabilistic inference in graphical models that capture how entitybearing queries are generated. We jointly model {{the interplay between}} latent user intents that govern queries and unobserved entity types, leveraging observed signals from <b>query</b> <b>formulations</b> and document clicks. We apply the models to resolve entity types in new queries and to assign prior type distributions over an existing knowledge base. Our models are efficiently trained using maximum likelihood estimation over millions of real-world Web search queries. We show that modeling user intent significantly improves entity type resolution for head queries over {{the state of the}} art, on several metrics, without degradation in tail query performance. ...|$|R
40|$|Abstract. In {{this paper}} we {{describe}} a query paradigm based on ontologies, aggregate table-driven querying {{and expansion of}} QBE. It has two novel features: visually specifying aggregate table queries and table layout in a single process, and providing users with an ontology guide in composing complex analysis tasks as queries. We present {{the role of the}} fundamental concept of ontology {{in the context of the}} content representation of distributed databases with large numbers of multi-valued attributes, and in <b>query</b> <b>formulation</b> and processing. The methods and techniques developed for representing and manipulating ontologies for <b>query</b> <b>formulation</b> and processing make extensive use of XML and DOM. The core functionalities of content representation, <b>query</b> <b>formulation</b> without prior knowledge about databases, statistical summary and result presentation are integrated into a front-end client within the underpinning MVC architecture, which has been implemented in Java and JAXP. ...|$|E
40|$|Visualization is a {{promising}} technique for both enhancing users' perception of {{structure in the}} Internet and providing navigation facilities for its large information spaces. This paper describes an application of the Document Explorer to the visualization of WWW content structure. The system provides visualization, browsing, and <b>query</b> <b>formulation</b> mechanisms based on documents' semantic content. These mechanisms complement text and link based search by supplying a visual search and <b>query</b> <b>formulation</b> environment using semantic associations among documents. The user can view and interact with visual representations of WWW document relations to traverse this derived document space. The relationships among individual keywords in the documents are also represented visually to support <b>query</b> <b>formulation</b> by direct manipulation of content words in the document set. A suite of navigation and orientation tools is provided which focuses on orientation and navigation using the visual representation [...] ...|$|E
40|$|Most {{standard}} {{information retrieval}} models use a single {{source of information}} (e. g., the retrieval corpus) for <b>query</b> <b>formulation</b> tasks such as term and phrase weighting and query expansion. In contrast, in this paper, we present a unified framework that automatically optimizes the combination of information sources used for effective <b>query</b> <b>formulation.</b> The proposed framework produces fully weighted and expanded queries that are both more effective and more compact than those produced by the current state-of-the-art query expansion and weighting methods. We conduct an empirical evaluation of our framework for both newswire and web corpora. In all cases, our combination of multiple information sources for <b>query</b> <b>formulation</b> {{is found to be}} more effective than using any single source. The proposed query formulations are especially advantageous for large scale web corpora, where they also reduce the number of terms required for effective query expansion, and improve the diversity of the retrieved results...|$|E
40|$|Query {{expansion}} {{terms are}} often used to enhance original <b>query</b> <b>formulations</b> in document retrieval. Such terms are usually selected from the entire documents or from windows or passages surrounding query term occurrences. Arguably, the semantic relatedness between terms weakens {{with the increase in}} the distance separating them. In this paper we report a study that was conducted to systematically evaluate different distance functions for selecting query expansion terms. We propose a distance factor that can be effectively combined with the statistical term association measure of mutual information for selecting query expansion terms. Evaluation of the TREC collection shows that distanceweighted mutual information is more effective than mutual information alone in selecting terms for query expansion...|$|R
40|$|Abstract. We {{describe}} FIRE, a content-based image retrieval system, and {{the methods}} we used within this system in the ImageCLEF 2004 evaluation. In FIRE, various features are available to represent images. The diversity of available features allows the user to adapt the system to the task at hand. A weighted combination of features admits flexible <b>query</b> <b>formulations</b> and helps with processing specific queries. For the ImageCLEF 2004 evaluation, we used the image content alone and obtained the best result in the category “only visual features, fully automatic retrieval ” in the medical retrieval task. Additionally, the results compare favorably to other systems, even if they {{make use of the}} textual information in addition to the images. ...|$|R
40|$|The {{conventional}} bibliographic retrieval {{systems are}} based on Boolean <b>query</b> <b>formulations</b> and inverted file implementations. Such systems provide rapid responses in answer to search queries {{but they are not}} easy to use by uninitiated patrons. An extended Boolean retrieval strategy has been devised in which the Boolean operators are treated more or less strictly, depending on the setting of a special parameter, known as the p-value. The extended system is much more forgiving than the conventional system, and provides better retrieval effectiveness. In this study various problems associated with the determination of appropriate p-values are discussed, and suggestions are made for an automatic assignment of p-values. Evaluation output is included to illustrate the operations of the suggested procedures...|$|R
40|$|Abstract. Information {{overload}} {{has led to}} {{a situation}} where users are swamped with too much information, resulting in difficulty sifting through the material in search of relevant content. In this paper, we address this issue from the perspective of collaboration in <b>query</b> <b>formulation.</b> We describe a search assistant that helps users with <b>query</b> <b>formulation</b> by finding related previously submitted queries through mining query logs. The search assistant runs as a reusable software component and can be incorporated into various search engines. We report our approach to designing and implementing the software and evaluation results. ...|$|E
40|$|Thomson Legal and Regulatory {{participated in}} the CLIR task of the NTCIR- 3 workshop. We {{submitted}} formal runs for monolingual retrieval in Japanese and Chinese, and for bilingual retrieval from English to Japanese. Our main focus was in Japanese retrieval. We compared word-based and character-based indexing, as well as <b>query</b> <b>formulation</b> using characters and character bigrams. Our results show that wordbased and bigram-based retrieval show similar performance for most <b>query</b> <b>formulation</b> approaches, while they outperform character-based retrieval. For Chinese retrieval, we compared using single characters with using character bigrams. We also introduced a structured query to leverage both. Our {{results are consistent with}} previous work, where character bigrams were shown to have better performance than single characters. The structured query approach is promising, but requires more analysis. In our bilingual runs, queries were translated using a machine-readable dictionary. Translated terms were resegmented to match indexing units. Our results, so far, are inconclusive, as we experienced unexpected <b>query</b> <b>formulation</b> issues especially in our word-based approach...|$|E
40|$|In this paper, we {{perform an}} {{in-depth}} study into how clinicians represent their information {{needs and the}} influence this has on information retrieval (IR) effectiveness. While much research in IR has considered the effectiveness of IR systems, {{there is still a}} significant gap in the understanding of how users contribute to the effectiveness of these systems. The paper aims to contribute to this by studying how clinicians search for information. Multiple representations of a information need — from verbose patient case descriptions to ad-hoc queries — were considered in order to understand their effect on retrieval. Four clinicians provided queries and performed relevance assessment to form a test collection used in this study. The different <b>query</b> <b>formulation</b> strategies of each clinician, and their effectiveness, were investigated. The results show that <b>query</b> <b>formulation</b> had more impact on retrieval effectiveness than the particular retrieval systems used. The most effective queries were short, ad-hoc keyword queries. Different clinicians were observed to consistently adopt specific <b>query</b> <b>formulation</b> strategies. The most effective queriers were those who, given their information need, inferred novel keywords most likely to appear in relevant documents. This study reveals aspects of how people search within the clinical domain. This can help inform the development of new models and methods that specifically focus on the <b>query</b> <b>formulation</b> process to improve retrieval effectiveness...|$|E
40|$|Results from {{research}} in information retrieval {{have suggested that}} significant improvements in retrieval effectiveness {{can be obtained by}} combining results from multiple index representations, <b>query</b> <b>formulations,</b> and search strategies. The inference net model of retrieval, which was designed from this point of view, treats information retrieval as an evidential reasoning process where multiple sources of evidence about document and query content are combined to estimate relevance probabilities. In this paper, we use a system based on this model to study the retrieval effectiveness benefits of combining the types of document and query information that are found in typical commercial databases and information services. The results indicate that substantial real benefits are possible...|$|R
40|$|This paper {{describes}} and evaluates a retrieval {{model that}} considers {{the problem of}} data fusion and collection fusion as two faces of the same coin. To establish a clear theoretical foundation for combining various sources of evidence provided either by different search schemes (data fusion) or by distributed information services (collection fusion), we have implemented a retrieval model based on the logistic regression methodology. Participation: Category B, ad-hoc automatic Introduction There exist many reasons for considering multiple sources of evidence in information retrieval (Katzer et al., 1982), (Saracevic & Kantor, 1988), (Harman, 1995), and their integration is usually studied in two distinct contexts. Various retrieval strategies or <b>query</b> <b>formulations</b> may operate on the same collection (data fusion problem) (Belkin et al., 1995), (Lee, 1995), subject described in the first part. The second part deals with the collection fusion problem or how distributed information servers may collaborate to answer to a given request (collection fusion problem) (Callan et al., 1995), (Voorhees et al., 1995). - 1. Data Fusion Problem To combine different retrieval schemes (or different <b>query</b> <b>formulations),</b> a retrieval engine might first find the retrieved set associated with each search scheme, and then merge them into a single effective ranked list. To define this underlying merging function, we may consider, for each retrieved record, its rank and / or its retrieval status value. However, the retrieval status values obtained by various weighting schemes {{may not have a}} range of possible similar values, leading to a more complex combination situation. Section 1. 1 outlines our test-collection and some evaluations of individual retrieval schemes based on two distinct query [...] ...|$|R
30|$|Recently, many {{research}} efforts have emerged {{that try to}} take advantage of the knowledge contained within collaborative systems such as Wikipedia in favour of information retrieval. We provide a brief overview of some of the most interesting approaches, which is focused on the corresponding assessment method each approach has followed. In [19], the Koru search interface is introduced that offers WikiSauri, i.e., thesauri extracted from Wikipedia articles, upon which users rely to find alternative <b>query</b> <b>formulations</b> for satisfying their search intentions. Queries are addressed towards an indexed corpus. The designers of Koru evaluated their system using the 2005 TREC HARD track [1]. More specifically, they performed a human study for which they calculated recall, precision and F-measure, averaged over all documents in the underlying index.|$|R
