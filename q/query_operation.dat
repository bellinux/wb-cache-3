58|430|Public
50|$|This section {{describes}} the <b>query</b> <b>operation</b> of a segment {{tree in a}} one-dimensional space.|$|E
5000|$|Google BigTable, Apache HBase and Apache Cassandra, and Postgresql use Bloom filters {{to reduce}} the disk lookups for {{non-existent}} rows or columns. Avoiding costly disk lookups considerably increases {{the performance of a}} database <b>query</b> <b>operation.</b>|$|E
50|$|The status <b>query</b> <b>operation</b> {{allows the}} Push Initiator to request {{the current status}} of a message that has been {{previously}} submitted. If status is requested for a message which is addressed to multiple recipients, the PPG MUST send back a single response containing status query results for each of the recipients.|$|E
5000|$|Tabular <b>query</b> <b>operations</b> {{consist of}} {{standard}} operations on data tables.|$|R
5000|$|Parallel <b>query</b> <b>operations.</b> DB2 9 can {{increase}} the amount of parallel processing and thus use the zIIP more.|$|R
40|$|We {{present an}} {{asymptotically}} optimal and practically efficient multiversion access structure (MVAS) for a versioned timestamped database with step-wise constant data. The structure combines an enhanced B+-tree with access lists {{in a novel}} way. This allows for both key history and version range queries to be answered optimally, while still maintaining linear storage. In our model, three version operations, insertions, updates, and deletes are allowed for the present version, whereas <b>query</b> <b>operations</b> are allowed for any version, present or past. The following <b>query</b> <b>operations</b> are supported optimally: key search, key range search, key history search (or time range search), snapshot of the database, and time range view. The bounds on storage space and <b>query</b> <b>operations</b> are worst case bounds per operation, while those for version operations are amortized over a sequence of version operations. Partially supported by NSF and DARPA Grant CCR 9006300 and NSF Grant CCR 9010366. y Dept. of EC [...] ...|$|R
50|$|In {{computer}} science, a deterministic acyclic finite state automaton (DAFSA),also {{called a}} directed acyclic word graph (DAWG; though that name also {{refers to a}} related data structure that functions as a suffix index)is a data structure that represents a set of strings, and allows for a <b>query</b> <b>operation</b> that tests whether a given string belongs to the set in time proportional to its length. Algorithms exist to construct and maintain such automata, while keeping them minimal.|$|E
50|$|VOD {{supports}} indexes {{on large}} collections. However {{it is not}} necessary to have a collection in order to have a queryable object with a usable index. Unlike other OODB implementations, any object in a Versant database is indexable and accessible via query. Indexes can be placed on attributes of classes and those classes can then be the target of a <b>query</b> <b>operation.</b> Indexes can be hash, b-tree, unique, compound, virtual and can be created online either using a utility, via a graphical user interface or via an API call.|$|E
5000|$|SCPI {{commands}} to an instrument may either perform a set operation (e.g. switching {{a power supply}} on) or a <b>query</b> <b>operation</b> (e.g. reading a voltage). Queries are issued to an instrument by appending a question-mark {{to the end of}} a command. Some commands can be used for both setting and querying an instrument. For example, the data-acquisition mode of an instrument could be set by using the [...] command or it could be queried by using the [...] command. Some commands can both set and query an instrument at once. For example, the [...] command runs a self-calibration routine on some equipment, and then returns the results of the calibration.|$|E
5000|$|Database indexes {{on one or}} more columns are {{typically}} sorted by value, which makes range <b>queries</b> <b>operations</b> (like the above [...] "find all records with salaries between 40,000 and 50,000 example) very fast.|$|R
5000|$|We {{define the}} data {{structure}} to be partially retroactive {{if it can}} perform update and <b>query</b> <b>operations</b> at the current time and support insertion and deletion operations in the past. Thus for partially retroactive {{we are interested in}} the following operations: ...|$|R
50|$|DataObjects.NET has a {{high level}} of {{abstraction}} and is designed to support operations on huge data. Nevertheless, it is designed for performance and has a vast amount of optimizations. It beats other complex ORM Frameworks like NHibernate and ADO.NET Entity Framework in CRUD and <b>Query</b> <b>operations.</b>|$|R
30|$|It can be {{seen from}} the figure above that the {{optimized}} distributed database query method based on genetic algorithm is superior to the general distributed database query and requires less time. In the aspect of data query, traditional centralized database is based on SQL language for data <b>query</b> <b>operation,</b> but in distributed database, the <b>query</b> <b>operation</b> needs to consider several factors; the performance of query algorithms varies greatly between different scenarios. The data query optimization algorithm is based on genetic algorithm which is proposed and researched in this paper. Considering the related factors, the optimal solution is larger. Practical application shows that based on the optimization algorithm, the query time of distributed database can be reduced significantly.|$|E
40|$|There {{are several}} data {{structures}} which can calculate the prefix sums of an array efficiently, while handling point updates on the array, such as Segment Trees and Binary Indexed Trees (BIT). Both these data structures {{can handle the}} these two operations (query and update) in O(n) time. In this paper, we present a data structure similar to the BIT, but with an even smaller constant. To do this, we use Zeckendorf's Theorem, a property of the Fibonacci sequence of numbers. The new data structure achieves the same complexity of O(n), but requires about _ϕ^ 2 n computations for the <b>Query</b> <b>Operation</b> {{as opposed to the}} _ 2 n computations required for a BIT <b>Query</b> <b>Operation</b> in the worst case. Comment: 7 pages, 2 figures, 2 graphs, 4 algorithm...|$|E
40|$|The aim of query optimizers in {{relational}} database systems is {{to select the}} most ecient way among all the possible ways of executing a query. In practice this process requires approximating the cost of possible execution sequences and selecting the cheapest one {{in terms of a}} cost metric, which is usually the resulting size of the <b>query</b> <b>operation.</b> The accuracy of this approximation is crucial to the performance of the databas...|$|E
40|$|We {{consider}} the recently proposed XQL language, {{which is designed}} to query XML documents by content and structure. We show that an already existing model, namely "Proximal Nodes", {{is the only one that}} addresses all the complex <b>querying</b> <b>operations</b> defined by XQL and that suggests an efficient implementation for them...|$|R
40|$|The join {{operation}} {{is one of}} the fundamental relational database <b>query</b> <b>operations.</b> It facilitates the retrieval of information from two different relations based on a CartesIan product of the two relations. The Join {{is one of the}} most difficult operations to implement efficiently, as no predefine links between relations are required to exist (a...|$|R
40|$|EcoCyc is an organism-specific pathway/genome {{database}} {{that describes the}} metabolic and signal-transduction pathways of Escherichia coli, its enzymes, its transport proteins and its mechanisms of transcriptional control of gene expression. EcoCyc is queried using the Pathway Tools graphical user interface, which provides {{a wide variety of}} <b>query</b> <b>operations</b> and visualization tools. EcoCyc is available at [URL]...|$|R
40|$|There is an {{intimate}} correlation between {{rough set theory}} and formal concept analysis theory, so rough set approximations can be realized by means of formal concept analysis. For any given mul-tiple valued information system, the realization of rough set approximation operation has two major steps, firstly convert the information system from multiple valued one to single valued for-mal context, secondly realize rough set approximation operations aided by concept lattice, which is equivalent to a <b>query</b> <b>operation</b> under some necessary conditions...|$|E
40|$|We {{investigate}} dynamic algorithms for {{the interval}} scheduling problem. Our algorithm runs in amortised time O(n) for <b>query</b> <b>operation</b> and O(d^ 2 n) for insertion and removal operations, where n and d are the maximal numbers of intervals and pairwise overlapping intervals respectively. We {{also show that}} for a monotonic set, that is when no interval properly contains another interval, the amortised complexity is O(n) for both query and update operations. We compare the two algorithms for the monotonic interval sets using experiments...|$|E
30|$|The uniform {{interface}} (e.g. JPA) and {{query language}} (e.g. JPQL) allow {{the user to}} abstract his/her application software from the specific database. However, this abstraction comes at a performance overhead cost, which stems from translating operations and data objects to the intended native operations and data structures and vice versa. For example, on write, the object is translated to the intended data structure of the underlying NoSQL database, while on read, the <b>query</b> <b>operation</b> is translated to the native query. Once the result is retrieved, the retrieved data structure is converted back into an object.|$|E
5000|$|To {{illustrate}} {{the basics of}} pivot <b>query</b> <b>operations,</b> consider the Fred and Wilma table (Fig 001). A quick scan of the data reveals that the table has redundant information. This redundancy could be consolidated using an outline or a tree structure or in some other way. Moreover, once consolidated, the data could have many different alternate layouts.|$|R
40|$|In this paper, {{we propose}} a novel mobile agent {{tracking}} mechanism based on hashing. To allow our system {{to adapt to}} variable workloads, dynamic rehashing is supported. The proposed mechanism scales well with both the number of agents {{and the number of}} moving and <b>querying</b> <b>operations.</b> We also report on its implementation in the Aglets platform and present performance results. 1...|$|R
40|$|This paper {{presents}} a multidimensional conceptual Object-Oriented model, its structures, integrity constraints and <b>query</b> <b>operations.</b> It {{has been developed}} {{as an extension of}} UML core metaclasses to facilitate its usage, as well as to avoid the introduction of completely new concepts. YAM 2 allows the representation of several semantically related stars, as well as summarizability and identification constraints. Postprint (published version...|$|R
30|$|Data {{encryption}} is {{a straightforward}} {{way to protect}} security and privacy. However, traditional encryption methods will prevent the commonly used <b>query</b> <b>operation</b> on confidential data. The keyword search becomes difficult when data are encrypted. In 2004, Boneh et al. [1] proposed the first public key encryption scheme with keyword search (PEKS) {{to deal with the}} issue of searching on confidential data. Since then, many efforts are made to improve the efficiency [2 - 4], enhance the security [5 - 7] or provide new flexible properties [8 - 12].|$|E
40|$|Abstract. This paper {{presents}} a cache-aware Bloom Filter algorithm with improved cache behavior {{and a lower}} false positive rates compared to prior work. The algorithm relies on the power-of-two choice principle to provide a better distribution of set elements in a Blocked Bloom Filter. Instead of choosing a single block, we insert new elements into the least-loaded of two blocks to achieve a low false-positive rate while performing only two memory accesses on each insert or <b>query</b> <b>operation.</b> The paper also discusses an optimization technique to trade off cache effectiveness with the false-positive rate to fine-tune the Bloom Filter properties. ...|$|E
40|$|We prove lower bounds on the {{complexity}} of maintaining fully dynamic k-edge or k-vertex connectivity in plane graphs and in (k − 1) -vertex connected graphs. We show an amortized lower bound of �(log n/k(log log n + log b)) per edge insertion, deletion, or <b>query</b> <b>operation</b> in the cell probe model, where b is the word size of the machine and n {{is the number of}} vertices in G. We also show an amortized lower bound of �(log n/(log log n + log b)) per operation for fully dynamic planarity testing in embedded graphs. These are the first lower bounds for fully dynamic connectivity problems...|$|E
50|$|Pivot <b>query</b> <b>operations</b> {{are useful}} for {{summarizing}} a corpus of data in multiple ways, thereby illustrating different representations of the same basic information. Although this type of operation appears prominently in spreadsheets and desktop database software, its flexibility is arguably under-utilized. There are many applications that allow only a 'fixed' hierarchy for representing data, and this represents a substantial limitation.|$|R
50|$|The {{storage and}} <b>querying</b> <b>operations</b> of Hive closely {{resemble}} those of traditional databases. While Hive is a SQL dialect, {{there are a lot}} of differences in structure and working of Hive in comparison to relational databases. The differences are mainly because Hive is built on top of the Hadoop ecosystem, and has to comply with the restrictions of Hadoop and MapReduce.|$|R
40|$|Search queries {{have evolved}} beyond keyword queries. Many complex queries such as verbose queries, natural {{language}} questionqueriesanddocument-basedqueriesarewidelyused inavarietyofapplications. Processingthesecomplexqueries usually requires {{a series of}} <b>query</b> <b>operations,</b> which results in multiple sequences of reformulated queries. However, previous query representations, either the“bag of words”method or the recently proposed “query distribution”method, cannot effectively model these query sequences, since they ignore the relationships between two queries. In this paper, a reformulation tree framework is proposed to organize multiple sequences of reformulated queries as a tree structure, where each path of the tree corresponds to a sequence of reformulated queries. Specifically, a two-level reformulation tree is implemented for verbose queries. This tree effectively combines two <b>query</b> <b>operations,</b> i. e., subset selection and query substitution, within the same framework. Furthermore, a weight estimation approach is proposed to assign weights toeachnodeofthereformulation treebyconsidering the relationships between different nodes and directly optimizing retrieval performance. Experiments on TREC collections show that this reformulation tree based representation significantly outperforms the state-of-the-art techniques...|$|R
40|$|Let V be an array. The range query problem {{concerns}} {{the design of}} data structures for implementing the following operations. The operation update(j,x) has the effect vj ← vj + x, and the <b>query</b> <b>operation</b> retrieve(i,j) returns the partial sum vi + [...] . + vj. These tasks are to be performed on-line. We define an algebraic model – based {{on the use of}} matrices – {{for the study of the}} problem. In this paper we establish as well a lower bound for the sum of the average complexity of both kinds of operations, and demonstrate that this lower bound is near optimal – in terms of asymptotic complexity...|$|E
40|$|Abstract. The {{majority}} of today’s IR systems base the IR task on two main processes: indexing and searching. There exists a special group of dynamic IR systems where both processes (indexing and searching) happen simultaneously; {{such a system}} discards obsolete information, simultaneously dealing with the insertion of new information, while still answering user queries. In these dynamic, time critical text document databases, it is often important to modify index structures quickly, as documents arrive. This paper presents a method for dynamization which {{may be used for}} this task. Experimental results show that the dynamization process is possible and that it guarantees the response time for the <b>query</b> <b>operation</b> and index actualization. ...|$|E
40|$|In {{distributed}} database query optimization, query optimizers {{have traditionally}} relied upon statically estimated table cardinalities when evaluating {{the cost of}} the query plans. This paper analyses static vs. dynamic calculation for selectivity of intermediate relations generated in query processing. The objective of this research is to overcome the disadvantages of previously formulated static methods which are relatively inaccurate in a distributed database environment. A Dynamic selectivity evaluation tool (DSET) has been proposed to optimize cost for a distributed database query processing environment. The results have shown that dynamic evaluation of selectivity factor of sub <b>query</b> <b>operation</b> is feasible and can significantly reduced the total query cost than its static estimation...|$|E
40|$|ECG {{sequences}} databases lack of {{a formal}} way to model analysis and <b>query</b> <b>operations.</b> In the pursuit of such a formal model, the definition of relevant prim-itive operators is necessary. We identify the convo-lution operator of sequences {{as one of those}} primitive operators. We take two QRS detection algorithms and propose a new way to express them formally using the convolution operator of sequences...|$|R
40|$|The n-gram {{analysis}} technique {{breaks up}} a text documentinto several n-character long unique grams, and produces a vector whose components are the counts of these grams. Atypical corpus contains {{hundreds of thousands}} of such grams. Wavelet compression reduces the dimension of the n-gram vectors, and speeds up document <b>query</b> <b>operations.</b> Documentvectors with their dimensions reduced to four components is readily represented in a three dimensional volume...|$|R
50|$|Some set data {{structures}} {{are designed for}} static or frozen sets that do not change after they are constructed. Static sets allow only <b>query</b> <b>operations</b> on their elements — such as checking whether a given value is in the set, or enumerating the values in some arbitrary order. Other variants, called dynamic or mutable sets, allow also the insertion and deletion of elements from the set.|$|R
