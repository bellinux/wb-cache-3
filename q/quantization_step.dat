355|138|Public
25|$|The DCT {{temporarily}} {{increases the}} bit-depth of the data, since the DCT coefficients of an 8-bit/component image {{take up to}} 11 or more bits (depending on fidelity of the DCT calculation) to store. This may force the codec to temporarily use 16-bit numbers to hold these coefficients, doubling {{the size of the}} image representation at this point; these values are typically reduced back to 8-bit values by the <b>quantization</b> <b>step.</b> The temporary increase in size at this stage is not a performance concern for most JPEG implementations, since typically only a very small part of the image is stored in full DCT form at any given time during the image encoding or decoding process.|$|E
2500|$|Note the top-left corner entry {{with the}} rather large magnitude. This is the DC {{coefficient}} (also called the constant component), which defines the basic hue {{for the entire}} block. The remaining 63 coefficients are the AC coefficients (also called the alternating components). [...] The advantage of the DCT is its tendency to aggregate most of the signal {{in one corner of}} the result, as may be seen above. The <b>quantization</b> <b>step</b> to follow accentuates this effect while simultaneously reducing the overall size of the DCT coefficients, resulting in a signal that is easy to compress efficiently in the entropy stage.|$|E
2500|$|Some authors further {{multiply}} the X0 term by 1/ and {{multiply the}} resulting matrix by an overall scale factor of [...] (see below for the corresponding change in DCT-III). This makes the DCT-II matrix orthogonal, but breaks the direct correspondence with a real-even DFT of half-shifted input. [...] This is the normalization used by Matlab, for example. [...] In many applications, such as JPEG, the scaling is arbitrary because scale factors {{can be combined}} with a subsequent computational step (e.g. the <b>quantization</b> <b>step</b> in JPEG), and a scaling can be chosen that allows the DCT to be computed with fewer multiplications.|$|E
40|$|Abstract — In {{this paper}} {{we present a}} {{technique}} of efficacy improvement of speech signal compression algorithm without individual features speech production loss. The compression in this case means to delete, from the digital signal, those <b>quantization</b> <b>steps</b> that can be predicted. We propose to decrease {{the number of those}} <b>quantization</b> <b>steps</b> using a modified linear predication algorithm w ith variable order. That allows to decrease compression time and save computer resource. Index Terms — speech signal compression, <b>quantization</b> <b>steps,</b> linear predication algorithm, computer resource...|$|R
30|$|It is {{worthwhile}} mentioning that the magnitudes of the TMs are {{significantly lower than}} those of the KMs and, therefore, the used <b>quantization</b> <b>steps</b> are smaller. This reduced range makes the process of finding the most appropriate <b>quantization</b> <b>steps</b> a hard task, since more coefficients need to have different strengths.|$|R
3000|$|In {{order to}} {{optimize}} both quality of watermarked audio and robustness of the watermark, this work employs the genetic algorithm {{to search for}} 4 optimal <b>quantization</b> <b>steps.</b> These <b>quantization</b> <b>steps</b> are varied to achieve the most suitable watermarked audio signal for each given audio signal. The details of genetic algorithm optimization process will be described in details in Section 3.3.|$|R
2500|$|Those {{who use the}} World Wide Web may be {{familiar}} with the irregularities known as compression artifacts that appear in JPEG images, which may take the form of noise around contrasting edges (especially curves and corners), or [...] "blocky" [...] images. These are due to the <b>quantization</b> <b>step</b> of the JPEG algorithm. They are especially noticeable around sharp corners between contrasting colors (text is a good example, as it contains many such corners). The analogous artifacts in MPEG video are referred to as mosquito noise, as the resulting [...] "edge busyness" [...] and spurious dots, which change over time, resemble mosquitoes swarming around the object.|$|E
5000|$|JPEG uses {{a single}} <b>quantization</b> <b>step</b> size per DC/AC {{component}} per color plane per image. JPEG XR allows {{a selection of}} DC <b>quantization</b> <b>step</b> sizes on a tile region basis, and allows lowpass and AC <b>quantization</b> <b>step</b> sizes to vary from macroblock to macroblock.|$|E
5000|$|Adaptive DPCM (ADPCM) is {{a variant}} of DPCM that varies {{the size of the}} <b>quantization</b> <b>step,</b> to allow further {{reduction}} of the required bandwidth for a given signal-to-noise ratio.|$|E
30|$|The {{aforementioned}} {{outcomes are}} also {{justified by the}} examination of the selected <b>quantization</b> <b>steps</b> in each case. The <b>quantization</b> <b>steps</b> for the case of the bicycle image (this with the highest performance) are illustrated in Fig. 8. In this figure, the dashed line corresponds to the single step assigned to all moment coefficients and the solid one to those derived by applying the proposed methodology.|$|R
3000|$|... <b>quantization</b> <b>steps,</b> respectively. The {{dynamic range}} {{has been limited}} to 90 dB for the {{amplitude}} values (A [...]...|$|R
30|$|Basically all {{compression}} schemes {{are based}} on the same technical principles using entropy coding, de-correlation and <b>quantization</b> <b>steps.</b>|$|R
50|$|Adaptive {{differential}} pulse-code modulation (ADPCM) is {{a variant}} of differential pulse-code modulation (DPCM) that varies {{the size of the}} <b>quantization</b> <b>step,</b> to allow further reduction of the required data bandwidth for a given signal-to-noise ratio.|$|E
5000|$|As an example, {{rounding}} a {{real number}} [...] {{to the nearest}} integer value forms a very basic type of quantizer - a uniform one. A typical (mid-tread) uniform quantizer with a <b>quantization</b> <b>step</b> size equal to some value [...] can be expressed as ...|$|E
50|$|After the wavelet transform, the {{coefficients}} are scalar-quantized {{to reduce the}} amount of bits to represent them, at the expense of a loss of quality. The output is a set of integer numbers which have to be encoded bit-by-bit. The parameter that can be changed to set the final quality is the quantization step: the greater the step, the greater is the compression and the loss of quality. With a <b>quantization</b> <b>step</b> that equals 1, no quantization is performed (it is used in lossless compression). In contrast to JPEG 2000, PGF uses only powers of two, therefore the parameter value i represents a <b>quantization</b> <b>step</b> of 2i. Just using powers of two makes no need of integer multiplication and division operations.|$|E
3000|$|According to the {{preceding}} theorem, the upper bound, c 1 εrec, is decreased when the <b>quantization</b> <b>steps,</b> Δ [...]...|$|R
3000|$|The resolutions or <b>quantization</b> <b>steps</b> of the {{binaural}} cues (Figure 12) can {{be determined}} by JND experiments. Denote by [...]...|$|R
30|$|Since {{entropy coding}} {{performs}} efficiently on statistical non-uniform distributed data additional processing steps modify {{the distribution of}} the data prior to encoding. Those steps are decorrelation and <b>quantization</b> <b>steps.</b>|$|R
5000|$|This {{can be seen}} as a {{floating}} point number with 4 bits of mantissa , 3 bits of exponent [...] and 1 sign bit [...] formatted as [...] with the decoded linear value [...] given by formulawhich is a 13-bit signed integer in the range ±1 to ±(2 − 2). Note that no compressed code decodes to zero due to the addition of 0.5 (half of a <b>quantization</b> <b>step).</b>|$|E
5000|$|When the <b>quantization</b> <b>step</b> size {{is small}} (relative to the {{variation}} in the signal being measured), it is relatively simple {{to show that the}} mean squared error produced by such a rounding operation will be approximately [...] Mean squared error is also called the quantization noise power. Adding one bit to the quantizer halves the value of Δ, which reduces the noise power by the factor ¼. In terms of decibels, the noise power change is ...|$|E
50|$|After the wavelet transform, the {{coefficients}} are scalar-quantized {{to reduce the}} number of bits to represent them, at the expense of quality. The output is a set of integer numbers which have to be encoded bit-by-bit. The parameter that can be changed to set the final quality is the quantization step: the greater the step, the greater is the compression and the loss of quality. With a <b>quantization</b> <b>step</b> that equals 1, no quantization is performed (it is used in lossless compression).|$|E
40|$|JPEG Image {{steganalysis}} {{has attracted}} great attention recently. In this paper, JPEG quantization-distribution steganalytic method against JSteg using JPEG <b>Quantization</b> <b>Steps</b> is proposed. By deducing the distribution relation of DCT coefficients {{before and after}} quantization in AC channel individually, and investigating the effect of <b>quantization</b> <b>steps</b> on such relation, we present a new method to detect the changes of statistical features derived from JSteg. Experimental results show that our approach can not only estimate the amount of hidden messages exactly, but also achieve {{a high degree of}} adaptivity. Key words: DCT, coefficient distribution, JPEG, quantization, steganalysi...|$|R
30|$|However, the {{aforementioned}} technique {{that leads to}} adaptive <b>quantization</b> <b>steps</b> is applicable only for radial transformations/moments and, therefore, it cannot be used for all moment families such as the discrete, Tchebichef and Krawtchouk ones.|$|R
30|$|The {{proposed}} {{technique is}} divided into two different operation modes, namely the calibration mode where the FIS parameters are optimized through a genetic algorithm and the normal mode where the resulted FIS is used to provide <b>quantization</b> <b>steps</b> in an adaptive sense.|$|R
50|$|In {{contrast}} with older MPEG-1/2/4 standards, the H.264 deblocking filter {{is not an}} optional additional feature in the decoder. It is a feature on both the decoding path and on the encoding path, so that the in-loop effects of the filter {{are taken into account}} in reference macroblocks used for prediction. When a stream is encoded, the filter strength can be selected, or the filter can be switched off entirely. Otherwise, the filter strength is determined by coding modes of adjacent blocks, <b>quantization</b> <b>step</b> size, and the steepness of the luminance gradient between blocks.|$|E
5000|$|Some authors further {{multiply}} the X0 term by 1/ and {{multiply the}} resulting matrix by an overall scale factor of [...] (see below for the corresponding change in DCT-III). This makes the DCT-II matrix orthogonal, but breaks the direct correspondence with a real-even DFT of half-shifted input. This is the normalization used by Matlab, for example. In many applications, such as JPEG, the scaling is arbitrary because scale factors {{can be combined}} with a subsequent computational step (e.g. the <b>quantization</b> <b>step</b> in JPEG), and a scaling can be chosen that allows the DCT to be computed with fewer multiplications.|$|E
5000|$|The <b>quantization</b> <b>step</b> is the {{transformation}} of this classical kinetic energy into a quantum mechanical operator. It is common to follow Podolsky by writing down the Laplace-Beltrami operator in the same (generalized, curvilinear) coordinates s as used for the classical form. The equation for this operator requires the inverse of the metric tensor g and its determinant. Multiplication of the Laplace-Beltrami operator by [...] gives the required quantum mechanical kinetic energy operator. When we apply this recipe to Cartesian coordinates, which have unit metric, the same kinetic energy is obtained as by application of the quantization rules.|$|E
30|$|This paper {{presents}} an efficient audio watermarking technique, which integrates the DWPT, SVD, and adaptive QIM {{subject to the}} auditory masking effect. While the DWPT decomposes the audio signal into critical bands, the exploration of perceptual entropy leads to the derivation of auditory masking thresholds. The thresholds, in turn, determine the <b>quantization</b> <b>steps</b> required by the QIM. In virtue of the robustness of the SVD technique, the proposed watermarking scheme first assembles the DWPT coefficients into a matrix and then manipulates the singular values to satisfy three criteria. As a result, the embedded watermark is guaranteed to restrain underneath the perceptible level. To further improve the overall performance, this study introduces two auxiliary enhancement measures to ensure the recovery of <b>quantization</b> <b>steps.</b>|$|R
40|$|Inertial effects play an {{important}} role in classical mechanics but have been largely overlooked in quantum mechanics. Nevertheless, the analogy between inertial forces on mass particles and electromagnetic forces on charged particles is not new. In this paper, we consider a rotating non-interacting planar two-dimensional electron gas with a perpendicular uniform magnetic field and investigate the effects of the rotation in the Hall conductivity. The rotation introduces a shift and a split in the Landau levels. As a consequence of the break of the degeneracy, the counting of the states fully occupied below the Fermi energy increases, tuning the Hall <b>quantization</b> <b>steps.</b> The rotation also changes the quantum Hall plateau widths. Additionally, we find the Hall <b>quantization</b> <b>steps</b> as a function of rotation at a fixed value of the magnetic field...|$|R
30|$|Probably, {{it is also}} {{desirable}} to adapt to global characteristics (complexity, context) of images to be compressed. For highly textural images, it might be reasonable to set slightly smaller <b>quantization</b> <b>steps.</b> However, {{it is not clear}} yet how such preclassification of images (more or less complicated) can be carried out.|$|R
5000|$|Note the top-left corner entry {{with the}} rather large magnitude. This is the DC {{coefficient}} (also called the constant component), which defines the basic hue {{for the entire}} block. The remaining 63 coefficients are the AC coefficients (also called the alternating components). [...] The advantage of the DCT is its tendency to aggregate most of the signal {{in one corner of}} the result, as may be seen above. The <b>quantization</b> <b>step</b> to follow accentuates this effect while simultaneously reducing the overall size of the DCT coefficients, resulting in a signal that is easy to compress efficiently in the entropy stage.|$|E
5000|$|Those {{who use the}} World Wide Web may be {{familiar}} with the irregularities known as compression artifacts that appear in JPEG images, which may take the form of noise around contrasting edges (especially curves and corners), or [...] "blocky" [...] images. These are due to the <b>quantization</b> <b>step</b> of the JPEG algorithm. They are especially noticeable around sharp corners between contrasting colors (text is a good example, as it contains many such corners). The analogous artifacts in MPEG video are referred to as mosquito noise, as the resulting [...] "edge busyness" [...] and spurious dots, which change over time, resemble mosquitoes swarming around the object.|$|E
50|$|The DCT {{temporarily}} {{increases the}} bit-depth of the data, since the DCT coefficients of an 8-bit/component image {{take up to}} 11 or more bits (depending on fidelity of the DCT calculation) to store. This may force the codec to temporarily use 16-bit numbers to hold these coefficients, doubling {{the size of the}} image representation at this point; these values are typically reduced back to 8-bit values by the <b>quantization</b> <b>step.</b> The temporary increase in size at this stage is not a performance concern for most JPEG implementations, since typically only a very small part of the image is stored in full DCT form at any given time during the image encoding or decoding process.|$|E
30|$|This {{paper is}} {{organized}} as follows. The proposed long-term model {{is described in}} Section 2. The complete long-term coding of LSF vectors is presented in Section 3, including {{the description of the}} fitting algorithm and the <b>quantization</b> <b>steps.</b> Experiments and results are given in Section 4. Section 5 is a discussion/conclusion section.|$|R
30|$|One {{possible}} solution to generalize {{the manipulation of}} all moment types {{is the use of}} an evolutionary optimization procedure to search for optimal <b>quantization</b> <b>steps</b> for each moment coefficient. However, this approach leads to a hard to solve optimization problem in the case of wide length watermark, where the number of moments is too big.|$|R
3000|$|Based on the {{statistical}} {{values of the}} selected coefficients, we have grouped them into 4 groups corresponding to their magnitudes. Each group will be quantizing with different <b>quantization</b> <b>steps.</b> To increase the watermarking security, we order the selected coefficients in a pseudorandom manner. The random numbers can be generated using the same secret key [...]...|$|R
