6631|1730|Public
5|$|An {{elaborated}} APXS {{setup is}} equipped with a sensor head containing six curium sources having the total radioactive decay rate of several tens of millicuries (roughly a gigabecquerel). The sources are collimated on the sample, and the energy spectra of the alpha particles and protons scattered from the sample are analyzed (the proton analysis is implemented only in some spectrometers). These spectra contain <b>quantitative</b> <b>information</b> on all major elements in the samples except for hydrogen, helium and lithium.|$|E
25|$|The {{number of}} words in the British National Corpus (ca 100 million) is {{sufficient}} for many empirical strategies for learning about language for linguists and lexicographers, and is satisfactory for technologies that utilize <b>quantitative</b> <b>information</b> about the behavior of words as input (parsing).|$|E
25|$|In 1975, {{while at}} Princeton, Tufte {{was asked to}} teach a {{statistics}} course {{to a group of}} journalists who were visiting the school to study economics. He developed a set of readings and lectures on statistical graphics, which he further developed in joint seminars he taught with renowned statistician John Tukey, a pioneer in the field of information design. These course materials became the foundation for his first book on information design, The Visual Display of <b>Quantitative</b> <b>Information.</b>|$|E
40|$|We {{propose a}} strong {{coupling}} expansion {{as a possible}} tool to obtain qualitative and <b>quantitative</b> <b>informations</b> about N= 1 SYM theory. We point out {{the existence of a}} mapping between strongly coupled lattice N= 1 SYM theory and a generalized SO(4) antiferromagnetic spin system. Comment: Lattice 2002 (spin), 3 pages, no figure...|$|R
40|$|Elastic light {{scattering}} {{has been used}} for a study of microstructure in amorphous hydrogenated silicon. A simple theory to get <b>quantitative</b> <b>informations</b> on the microstructure has been presented for the first time, both for Rayleigh and Mie scattering. For optimal very high frequency glow discharge amorphous silicon layers, the presence of voids with diameter between 1 and 20 nm is typical...|$|R
40|$|Although {{there are}} {{numerous}} studies on the morphology and physical processes affecting the dune's scarp and many conceptual models describing beach scarps on microtidal and mesotidal environments (Sunamura, 1985 a; Short, 1999), really <b>quantitative</b> <b>informations</b> about the beach scarp formation is lacking, especially along tidal environments where the tide controls the level of wave attack. However, Sherman and Nordstrom (1985) give a qualitative description of beach scarp formations and evolution based on field observations but without data set...|$|R
25|$|Until the 1960s, {{interpretation}} of the igneous rock record was largely qualitative. Ian Carmichael wanted to determine <b>quantitative</b> <b>information</b> such as the temperature and pressure of the magma when crystals were formed as well as dissolved water and oxygen content. For this, thermodynamic models were needed. Although attempts to apply rigorous thermodynamics to igneous processes go back to at least 1949, they were hindered {{by a lack of}} experimental data. Using tools such as a drop calorimeter and wet chemistry, Carmichael and colleagues set out to systematically explore thermodynamic properties of magma at high temperatures.|$|E
25|$|A common way to {{get more}} <b>quantitative</b> <b>information</b> out of a mass {{spectrum}} {{is to create a}} standard curve to compare the sample to. This requires knowing what is to be quantitated ahead of time, having a standard available and designing the experiment specifically for this purpose. A more advanced variation on this is the use of an internal standard which behaves very similarly to the analyte. This is often an isotopically labeled version of the analyte. There are forms of mass spectrometry, such as accelerator mass spectrometry that are designed from the bottom up to be quantitative.|$|E
500|$|Techniques such as Hilbert's {{original}} non-constructive {{solution to}} the finite basis problem {{could not be used}} to get <b>quantitative</b> <b>information</b> about the invariants of a group action, and furthermore, they did not apply to all group actions. In her 1915 paper, Noether found a {{solution to the}} finite basis problem for a finite group of transformations G acting on a finite-dimensional vector space over a field of characteristic zero. Her solution shows that the ring of invariants is generated by homogeneous invariants whose degree is less than, or equal to, the order of the finite group; this is called Noether's bound. Her paper gave two proofs of Noether's bound, both of which also work when the characteristic of the field is coprime to |G|!, the factorial of the order |G| of the group G. The degrees of generators need not satisfy Noether's bound when the characteristic of the field divides the |G|, but Noether was not able to determine whether this bound was correct when the characteristic of the field divides |G|! but not |G|. For many years, determining the truth or falsehood of this bound for this particular case was an open problem, called [...] "Noether's gap". It was finally solved independently by Fleischmann in 2000 and Fogarty in 2001, who both showed that the bound remains true.|$|E
40|$|International audienceThe {{stability}} of (001) ‐oriented 3 C {{silicon carbide crystals}} is studied by a method coupling high resolution x‐ray diffraction and numerical simulations. The analysis of the diffuse scattering intensity distribution along selected directions in reciprocal space allows us to obtain qualitative and <b>quantitative</b> <b>informations</b> regarding the 3 C‐ 6 H transition. Our latest results concerning {{the influence of the}} initial crystal quality (presence of defects) and of annealing time on the 3 C‐ 6 H transition are presented in this article...|$|R
50|$|A {{variety of}} {{approaches}} {{have been suggested}} for high throughput assessment of novel metallic electrocatalysts. One functional, non-SECM approach, enabled the electocatalytic activities {{of a large number}} of catalysts to be assessed optically by employing a technique that detected proton production on deposited arrays of proton-sensitive fluorescent dyes. Though of certain utility, the technique suffers from the failure to extract <b>quantitative</b> electrochemical <b>information</b> from any catalytic system of interest, thus requiring the <b>quantitative</b> electrochemical <b>information</b> to be obtained off-line from the array experiment. Bard et al. have demonstrated assessment of electrocatalytic activities at high volume using the SECM configuration. With this approach, direct <b>quantitative</b> electrochemical <b>information</b> from multicomponent systems can be acquired on a rapid screening platform. Such high throughput screening significantly assists the search for abundant, efficient and cost-effective electrocatalytic materials as substitutes for platinum and other precious metals.|$|R
5000|$|... #Subtitle level 4: <b>Quantitative</b> Methods & <b>Information</b> Technology ...|$|R
2500|$|When an {{appropriate}} model is known, FCS {{can be used}} to obtain <b>quantitative</b> <b>information</b> such as ...|$|E
2500|$|Physical {{properties}} of organic compounds typically of interest include both {{quantitative and qualitative}} features. [...] <b>Quantitative</b> <b>information</b> includes melting point, boiling point, and index of refraction. Qualitative properties include odor, consistency, solubility, and color.|$|E
2500|$|For {{philosophers}} Silvio Funtowicz and Jerome R. Ravetz [...] "... pseudo-science may {{be defined}} as one where the uncertainty of its inputs must be suppressed, lest they render its outputs totally indeterminate". The definition, in the book Uncertainty and quality in science for policy (p.54), alludes {{to the loss of}} craft skills in handling <b>quantitative</b> <b>information,</b> and to the bad practice of achieving precision in prediction (inference) only at the expenses of ignoring uncertainty in the input which was used to formulate the prediction. This use of the term is common among practitioners of post-normal science. Understood in this way, pseudoscience can be fought using good practices to assesses uncertainty in <b>quantitative</b> <b>information,</b> such as NUSAP and - in the case of mathematical modelling - sensitivity auditing.|$|E
40|$|Bentonite suspensions, {{used in the}} {{construction}} industry, are non-Newtonian fluids with a thixotropic behaviour. Sudden releases of bentonite suspensions were systematically investigated down a sloping chute, to quantify the effects of bentonite concentrations and initial rest period on flow motion. Experiments observations highlighted four types of flows, that differ substantially from Newtonian fluid motion. <b>Quantitative</b> <b>informations</b> were documented {{in terms of the}} fluid thickness, wave front position and wave front curvature during motion and after stoppage. It is believed that the present study is the first systematic study of its kind in a large-size facility...|$|R
50|$|Automated {{mineralogy}} {{solutions are}} applied {{in a variety}} of fields requiring statistically reliable, <b>quantitative</b> mineralogical <b>information.</b> These include the following sectors: mining; O&G; coal; environmental sciences; forensic geosciences; archaeology;agribusiness; built environment and planetary geology.|$|R
3000|$|... [...]) of {{the protein}} {{phosphorylation}} sensitivity {{with respect to}} the stimulations from the stimuli in S. This way we get <b>quantitative,</b> direct <b>information</b> on the impact of the inhibitor upon the cellular response to external stimuli.|$|R
2500|$|Tufte's {{writing is}} {{important}} in such fields as information design and visual literacy, which deal with the visual communication of information. [...] He coined the word chartjunk to refer to useless, non-informative, or information-obscuring elements of <b>quantitative</b> <b>information</b> displays. [...] Tufte's other key concepts include {{what he calls the}} lie factor, the data-ink ratio, and the data density of a graphic.|$|E
2500|$|He {{uses the}} term [...] "data-ink ratio" [...] to argue against using {{excessive}} decoration in visual displays of <b>quantitative</b> <b>information.</b> In Visual Display, Tufte explains, [...] "Sometimes decoration can help editorialize about {{the substance of the}} graphic. But it is wrong to distort the data measures—the ink locating values of numbers—in order to make an editorial comment or fit a decorative scheme." ...|$|E
2500|$|One of {{the most}} {{controversial}} issues for PHRs is how the technology could threaten the privacy of patient information. Network computer break-ins are becoming more common, thus storing medical information online can cause fear of the exposure of health information to unauthorized individuals. In addition to height, weight, blood pressure and other <b>quantitative</b> <b>information</b> about a patient's physical body, medical records can reveal very sensitive information, including fertility, surgical procedures, emotional and psychological disorders, and diseases, etc. Various threats exist to patient information confidentiality: ...|$|E
40|$|In {{the risk}} society the {{dimensions}} of social needs have grown, while the crisis of public finances forces the welfare systems to a process of recalibration and a gradual slowdown in the extent of its intervention. From this scenario, the paper analyzes the ways of spread of the occupational welfare in Italy, which is the set of interventions (in the form of benefits or services) to which workers can take advantage by reason of their employment. Using <b>quantitative</b> <b>informations,</b> the article highlights the general dimensions of the phenomenon, the spaces of integration with the public offering, the limits and the problems identified by empirical research on the subject...|$|R
40|$|Abstract. The idea of {{mathematical}} modeling {{is used to}} establish the <b>quantitative</b> model of <b>information</b> system vulnerability assessment, and the model is solved by using the partial differential method. The algorithm is realized by using VB programming, and it obtains the <b>quantitative</b> solution of <b>information</b> system vulnerability. <b>Quantitative</b> assessment of <b>information</b> system security and risk is the difficulty of system vulnerability assessment, and it establishes the risk model of system by means of mathematics modeling idea. The risk model is divided into the actual risk and the potential risk. The paper uses VB programming software, and establishes a <b>quantitative</b> model of <b>information</b> system evaluation by combining with partial differential method, and the algorithm is carried out the experimental verification by using the method of numerical simulation. Through the calculation, the mathematical modeling ideas can effectively obtain the vulnerability quantitative standard and the risk level of information system, which provides the technical reference for the research of information system security evaluation method...|$|R
40|$|To reduce adverse {{customer}} selection, service {{firms are}} empowering employees to use decision latitude {{to decide whether}} to provide a service to a potential customer. Customer selection often requires complex decision making that involves both quantitative and qualitative customer information. The authors introduce service employees’ desire for decision latitude (DDL) as an individual difference construct that influences the processing of <b>quantitative</b> and qualitative <b>information</b> in customer selection decisions. Across several studies, the authors find that individual differences in DDL moderate how service personnel synthesize <b>quantitative</b> and qualitative <b>information</b> in customer selection decisions. Service employees who have relatively higher levels of DDL integrate <b>quantitative</b> and qualitative <b>information</b> such that the cues combine interactively. Thus, they may act as though they are going against organizational norms by allowing qualitative information to override organizational decision-making norms. Conversely, low DDL individuals appear to combine both <b>quantitative</b> and qualitative <b>information</b> in a linear pattern to influence customer selection. These results suggest that managers should employ DDL to match employees with customers so that an optimal fit occurs. Managers should examine procedures for how information should be used and provide employees with clearly defined guidelines for how to employ <b>quantitative</b> and qualitative <b>information</b> when making customer selection decisions...|$|R
2500|$|At low {{energies}} (less than 1 μW) the {{diode current}} {{is proportional to}} the microwave power and the detector is referred to as a square law detector. At higher power levels (greater than 1mW) the diode current {{is proportional to the}} square root of the microwave power and the detector is called a linear detector. In order to obtain optimal sensitivity as well as <b>quantitative</b> <b>information</b> the diode should be operating within the linear region. To ensure the detector is operating at that level the reference arm serves to provide a [...] "bias".|$|E
2500|$|... 13C MRS is {{a special}} type of fMRS {{particularly}} suited for measuring important neurophysiological fluxes in vivo and in real time to assess metabolic activity both in healthy and diseased brains (e.g., in human tumor tissue [...] ). These fluxes include TCA cycle, glutamate-glutamine cycle, glucose and oxygen consumption. 13C MRS can provide detailed <b>quantitative</b> <b>information</b> about glucose dynamics {{that can not be}} obtained with 1H fMRS, because of the low concentration of glucose in the brain and the spread of its resonances in several multiplets in the 1H MRS spectrum.|$|E
2500|$|There {{is little}} {{reliable}} <b>quantitative</b> <b>information</b> available concerning {{the performance of}} Pakistani water and sewer utilities, including on their efficiency. The Asian Development Bank (ADB) prepared a document, which includes data for the cities of Rawalpindi, Karachi and Lahore. Furthermore, data from six major cities were reported during a 2005 workshop in Karachi. Beginning in 2005, the first systematic performance benchmarking for water and sewer utilities in Pakistan was initiated by the World Bank's Water and sanitation program {{as part of a}} regional project that also covered India and Bangladesh. Eight utilities participated, including five WASAs in Punjab as well as the utilities of Karachi, Peshawar and Islamabad. The benchmarking project found that data were not very reliable and that benchmarking was [...] "largely externally driven than internally motivated" [...] and that the organizational culture of utilities was [...] "often slow to accept performance measurement, accountability to customers and to government, and improved service outcomes." ...|$|E
30|$|The {{most common}} method used to {{investigate}} thermal decomposition is thermogravimetric analysis (TGA). TGA {{is a technique}} that provides <b>quantitative</b> decomposition <b>information</b> on a polymeric material {{and can be used}} to study degradation kinetics and char formation (Crompton 1989).|$|R
40|$|Abstract Background The {{assessment}} of myocardial motion with tissue phase mapping (TPM) provides high spatiotemporal resolution and <b>quantitative</b> motion <b>information</b> in three directions. Today, whole volume {{coverage of the}} heart by TPM encoding at high spatial and temporal resolution is limited by long data acquisition times. Therefore, {{a significant increase in}} imaging speed without deterioration of the <b>quantitative</b> motion <b>information</b> is required. For this purpose, the k-t BLAST acceleration technique was combined with TPM black-blood functional imaging of the heart. Different k-t factors were evaluated with respect to their impact on the quantitative {{assessment of}} cardiac motion. Results It is demonstrated that a k-t BLAST factor of two can be used with a marginal, but statistically significant deterioration of the quantitative motion data. Further increasing the k-t acceleration causes substantial alteration of the peak velocities and the motion pattern, but the temporal behavior of the contraction is well maintained up to an acceleration factor of six. Conclusions The application of k-t BLAST for the acceleration of TPM appears feasible. A reduction of the acquisition time of almost 45 % could be achieved without substantial loss of <b>quantitative</b> motion <b>information.</b> </p...|$|R
40|$|PACS. 61. 72. Mm – Grain and twin boundaries. Abstract. – To analyse a {{polycrystalline}} material which has undergone mechanical sollicitations, we quantify the deformation of grain boundaries. We investigate a pattern which records past deformations: a deep ice core, in Dome Concordia, Antarctica. Its ice microstructure (grain boundaries) {{is a key}} feature useful to study ice evolution and to investigate climatic changes. Our method extracts <b>quantitative</b> physical <b>information,</b> such as the anisotropy and the local heterogeneity of the deformation. This leads to a re-examination of current models used in datation. The method also applies to extract <b>quantitative</b> geometrical <b>information</b> from other cellular patterns, ranging from metal processing and biological tissues to foams and granular matter. Motivations. – A picture contains {{a large amount of}} data, from which it is sometimes difficult to extract <b>quantitative,</b> physically relevant <b>information.</b> In this letter, we present a method to characterise a cellular pattern by measuring a geometrical quantity, the “texture tensor ” [1], using local spatial averages. We apply this analysis to the grain boundaries (th...|$|R
2500|$|Wood burning {{creates more}} {{atmospheric}} CO2 than biodegradation of wood {{in a forest}} (in a given period of time) because {{by the time the}} bark of a dead tree has rotted, the log has already been occupied by other plants and micro-organisms which continue to sequester the CO2 by integrating the hydrocarbons of the wood into their own life cycle. Wood harvesting and transport operations produce varying degrees of greenhouse gas pollution. [...] Inefficient and incomplete combustion of wood can result in elevated levels of greenhouse gases other than [...] CO2, which may result in positive emissions where the byproducts have greater Carbon dioxide equivalent values. In an attempt to provide <b>quantitative</b> <b>information</b> about the relative output of CO2 to produce electricity of domestic heating, the United Kingdom Department of Energy and Climate Change (DECC) has published a comprehensive model comparing the burning of wood (wood chip) and other fuels, based on 33 scenarios. The model's output is kilogram of CO2 produced per Megawatt hour of delivered energy. Scenario 33 for example, which concerns the production of heat from wood chips produced from UK small roundwood produced from bringing neglected broadleaf forests back into production, shows that burning oil releases 377kg of CO2 while burning woodchip releases 1501kg of CO2 per MW h delivered energy.|$|E
5000|$|... 1978: Claude E. Shannon, {{creator of}} <b>quantitative</b> <b>Information</b> theory ...|$|E
5000|$|To deliver and refresh all the {{required}} <b>quantitative</b> <b>information,</b> ...|$|E
50|$|Reply {{marketing}} is an inexpensive marketing strategy because less total advertising is used (the {{goal is to}} create an immediate sale). A second advantage includes the fact that response marketing campaigns produce <b>quantitative</b> consumer <b>information</b> and data, which reflects the effectiveness of that campaign.|$|R
40|$|We {{propose a}} strong {{coupling}} expansion {{as a possible}} tool to obtain qualitative and <b>quantitative</b> <b>informations</b> about N= 1 SYM theory. We point out {{the existence of a}} mapping between strongly coupled lattice N= 1 SYM theory and a generalized SO(4) antiferromagnetic spin system. Though far from the scaling regime, the strong coupling limit of lattice gauge theory exhibits confinement and chiral symmetry breaking and has often been used as a computational scheme for understanding qualitative features of continuum theories such as QCD. Strongly coupled lattice gauge theories are intimately related to quantum spin systems [1, 2]. In Ref. [2] Smit showed that the strong coupling effective hamiltonian of QCD regularized with Wilson fermions is a generalized U(4 Nf) antiferromagnet. N= 1 supersymmetric Yang-Mills (SY M) theor...|$|R
40|$|In {{this paper}} are {{summarized}} the recent findings on detection of acoustic emissions {{at very low}} frequencies (i. e. from few Hertz to 10 kHz) in solid materials, such as rock and concrete, under compression until fracture in laboratory tests. These emissions, defined Elastic Emissions (or ELE), are characterized by wavelength greater than the maximum specimen size and by a very important amount of released energy. The ELEs are {{the effect of the}} propagating micro-shock waves due to the macro-cracks forming in the bulk of the materials detected at the specimen surface. A spectral analysis of the ELEs, realized with metrological reliability, provides <b>quantitative</b> <b>informations</b> about the macro-crack effects in terms of released energy, measuring the local acceleration in the accelerometer point of application...|$|R
