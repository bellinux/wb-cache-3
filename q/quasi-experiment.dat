947|166|Public
5000|$|RDD, as a <b>quasi-experiment,</b> {{does not}} require ex ante {{randomization}} and circumvents ethical issues of random assignment.|$|E
50|$|Alessandra Casella, Tom Palfrey, Andrew Gelman, {{and other}} co-authors {{realized}} several laboratory experiments and one <b>quasi-experiment</b> {{in the field}} to test the theoretical predictions of Storable Votes models.|$|E
50|$|A {{procedural}} confounding {{can occur}} in a laboratory experiment or a <b>quasi-experiment.</b> This type of confound occurs when the researcher mistakenly allows another variable to change along with the manipulated independent variable.|$|E
50|$|<b>Quasi-experiments</b> have outcome measures, treatments, and {{experimental}} units, {{but do not}} use random assignment. <b>Quasi-experiments</b> are often the design that most people choose over true experiments. The main reason {{is that they can}} usually be conducted while true experiments can not always be. <b>Quasi-experiments</b> are interesting because they bring in features from both experimental and non experimental designs. Measured variables can be brought in, as well as manipulated variables. Usually <b>Quasi-experiments</b> are chosen by experimenters because they maximize internal and external validity.|$|R
40|$|The {{influential}} piracy {{paper by}} Professors Oberholzer-Gee and Strumpf, although mainly based on proprietary data, contained an 'important complement' {{to the main}} results, consisting of four "quasi-experiments" using publicly available data. This replication examines all of these <b>quasi-experiments,</b> first, by narrowly using identical data and statistical methods, {{as well as in}} a broader sense by extending or augmenting the data or methods. This study concludes that none of the four <b>quasi-experiments</b> provide evidence in support of OS' hypothesis that file-sharing has not harmed record sales...|$|R
40|$|The {{influential}} piracy {{paper by}} Professors Oberholzer-Gee and Strumpf, although mainly based on proprietary data, contained an 'important complement' {{to the main}} results, consisting of four 'quasi-experiments' using publicly available data. This replication examines all of these <b>quasi-experiments</b> by using identical data and statistical methods where possible, as well as sometimes extending or augmenting the data or methods. This study concludes that the <b>quasi-experiments</b> performed by OS each contain important errors, oversights or inconsistencies that most often, but not completely, overturn the results claimed in the original OS article...|$|R
5000|$|Interrupted {{time series}} design (measures on a sample or a series of samples from the same {{population}} are obtained several times before and after a manipulated event or a naturally occurring event) - considered a type of <b>quasi-experiment</b> ...|$|E
5000|$|Some authors {{distinguish}} between a natural experiment and a [...] "quasi-experiment". [...] The {{difference is that}} in a <b>quasi-experiment</b> the criterion for assignment is selected by the researcher, while in a natural experiment the assignment occurs 'naturally,' without the researcher's intervention.|$|E
50|$|Bass (1990) {{suggested}} that autonomous work groups can substitute for formal leadership. In this scenario, employees {{are divided into}} groups {{that are responsible for}} managing their own day-to-day work (i.e. collective control over pace, distribution of tasks, organization of breaks, recruitment, and training; Gulowsen, 1972). A <b>quasi-experiment</b> conducted by Wall, Kemp, Jackson, and Clegg (1986) found that implementing autonomous work groups of 8 to 12 shop-floor employees in a manufacturing setting positively affected both the intrinsic and extrinsic job satisfaction of employees, while obviating some supervisory positions.|$|E
40|$|The {{national}} {{evaluation of}} an early elementary compensatory education program, Follow Through, is used as the context for discussion of design and analysis problems common to many evaluations. Although experiments have well-known advantages over <b>quasi-experiments,</b> the latter are likely to persist for the foreseeable future. It is argued that more careful planning could avoid many unnecessary weaknesses of past <b>quasi-experiments,</b> and that <b>quasi-experiments</b> can provide valuable information for evaluations. The {{strengths and weaknesses of}} several competing analysis strategies for <b>quasi-experiments</b> are considered. The conclusion is that no one strategy is satisfactory. A multiple analysis approach is recommended instead which attempts to capitalize on the unique strengths and control the unique weaknesses of several analysis strategies. he national evaluation of Follow Through (FT) is used as a vehicle for discussing problems of design and analysis that characterize much summary evaluation research. The FT example was chosen for several reasons. First, the evaluation {{is one of the largest}} and most expensive ever undertaken; and second, the evaluation is still in progress. Thus, the design and analysis problems in the FT example are a real concern. Third, the FT evaluation provides a single context for a concrete discussion of design and analysis problems that are typically dealt with separately and abstractly. The paper begins with an illustration of how an inadequate design can compromise evaluation. Next, given the intent of th...|$|R
40|$|We develop {{over-identification}} {{tests that}} use admissions lotteries {{to assess the}} predictive value of regression-based value-added models (VAMs). These tests have degrees of freedom equal {{to the number of}} <b>quasi-experiments</b> available to estimate school effects. By contrast, previously implemented VAM validation strategies look at a single restriction only, sometimes said to measure forecast bias. Tests of forecast bias may be misleading when the test statistic is constructed from many lotteries or <b>quasi-experiments,</b> some of which have weak first stage effects on school attendance. The theory developed here is applied to data from the Charlotte-Mecklenberg School district analyzed by Deming (2014). National Science Foundation (U. S.) Laura and John Arnold FoundationSpencer Foundatio...|$|R
40|$|Objective: To outline {{issues of}} {{importance}} to analytic approaches to the synthesis of <b>quasi-experiments</b> (QEs), {{and to provide a}} statistical model for use in analysis. Study Design and Setting: We drew on the literatures of statistics, epidemiology, and social-science methodology to outline methods for synthesis of QE studies. The design and conduct of <b>quasi-experiments,</b> effect sizes from QEs, and moderator variables for the analysis of those effect sizes were discussed. Results: Biases, confounding, design complexities and comparisons across designs offer serious challenges to syntheses of QEs. Key components of meta-analyses of QEs were identified, including the aspects of QE study design to be coded and analyzed. Of utmost importance are the design and statistical controls implemented in the QEs. Such controls and any potential sources of bias and confounding must be modeled in analyses, along with aspects of the interventions and populations studied. Because of such controls, effect sizes from QEs are more complex than those from randomized experiments. A statistical meta-regression model that incorporates important features of the QEs under review was presented. Conclusion: Meta-analyses of <b>quasi-experiments</b> provide particular challenges, but thorough coding of intervention characteristics and study methods, along with careful analysis, should allow for sound inferences...|$|R
50|$|A {{cohort study}} is a <b>quasi-experiment</b> used in medicine, nursing, psychology, social science, actuarial science, {{business}} analytics, and ecology. For instance: in medicine, it is an analysis of risk factors and follows {{a group of people}} who typically do not have a given disease, and uses correlations to determine the absolute risk of subject contraction. It is one type of clinical study design and should be compared with a cross-sectional study. Cohort studies are largely about the life histories of segments of populations, and the individual people who constitute these segments.|$|E
5000|$|Alternatively, some {{experiments}} are less controlled. Quasi-experiment's {{are those that}} a researcher sets up in a controlled environment, but does not control the independent variable. For example, Michael R. Cunningham used a <b>quasi-experiment</b> to [...] "...measure the physical in physical attractiveness." [...] On the other hand, in field experiments the experimenter controls an independent variable (making it the control variable), but does not control the environment where the experiment takes place. Experimenters sometimes apply fewer controls, {{as a way to}} lessen potential biases. In a true experiment, participants are randomly chosen to remove the chance of experimenter's bias.|$|E
50|$|His work {{includes}} {{analyses of}} the Maastricht Treaty, studies of the European Currency Crises in 1992-93 and the Asian Crisis in the late Nineties, contributions to New Open Economy Macroeconomics, theoretical and empirical work on financial contagion and currency instability, models of exchange rate pass-through and imported inflation, as well as pioneering {{analyses of the}} propagation and stabilization of international business cycles with imperfect capital markets and current account imbalances. His recent work on fiscal policy combines micro- and macroeconomic analysis. His contribution on the government spending multiplier based on a <b>quasi-experiment</b> in Italy involving Mafia infiltration of local municipalities has been discussed in the media.|$|E
40|$|The {{empirical}} {{economic growth}} literature is criticized for {{its lack of}} robustness. For different definitions of robustness, conclusions vary from ?almost every correlation is fragile? to ?a substantial number of explanatory variables are robust. ? We re-analyze the empirical results of the economic growth literature for various alternative definitions of robustness using <b>quasi-experiments.</b> The analysis pertains to sign, size and significance of the effects, and we relax the quasi-experimental procedure by no longer applying a set of ?fixed? variables. Response surface analyses of the <b>quasi-experiments</b> reveal {{that the number of}} robust variables is limited, the effects crucially depend on the specification of conditioning variables, and the default specification based on the convergence/catch-up model is associated with estimated effects of conditioning variables that constitute outliers. ...|$|R
40|$|Formal {{education}} can be improved by transferring responsibility from the teacher to the learner. A simple approach to {{this is the time}} contract. Time contracts have been used successfully in nine <b>quasi-experiments</b> but, despite these successes, some educators see this as subversive research. learning, universities, teachers...|$|R
50|$|A true {{experiment}} would, for example, randomly assign {{children to a}} scholarship, {{in order to control}} for all other variables. <b>Quasi-experiments</b> are commonly used in social sciences, public health, education, and policy analysis, especially when it is not practical or reasonable to randomize study participants to the treatment condition.|$|R
50|$|Matching is a {{statistical}} technique {{which is used}} to evaluate the effect of a treatment by comparing the treated and the non-treated units in an observational study or <b>quasi-experiment</b> (i.e. when the treatment is not randomly assigned). The goal of matching is, for every treated unit, to find one (or more) non-treated unit(s) with similar observable characteristics against whom the effect of the treatment can be assessed. By matching treated units to similar non-treated units, matching enables a comparison of outcomes among treated and non-treated units to estimate the effect of the treatment reducing bias due to confounding. Propensity score matching, an early matching technique, was developed as part of the Rubin causal model.|$|E
50|$|Researches {{have often}} {{conducted}} studies {{to determine whether}} membership to a clique produces positive or negative development. In one 4-year study of 451 children from age nine to twelve, Miranda Witvliet along with Pol A. C. van Lier, Mara Brendgen, Hans M. Koot, and Frank Vitaro examined longitudinal associations between clique membership status and internalizing and externalizing problems during late childhood. In this <b>quasi-experiment</b> the researchers aimed to discover if clique membership status was linked to increases in children's psychopathology. Children from five different elementary schools in northwestern Quebec, Canada were the participants of this particular study. In the study, clique membership status was identified through social network analysis, and peer nominations {{were used to assess}} internalizing and externalizing problems. The study used the program Kliquefinder to identify clique membership status through social network analysis. Through use of behavioural descriptions on the Pupil Evaluation Inventory (PEI), peer nominations of externalizing and internalizing behaviors were obtained.|$|E
50|$|A <b>quasi-experiment</b> is an {{empirical}} study {{used to estimate}} the causal impact of an intervention on its target population without random assignment. Quasi-experimental research shares similarities with the traditional experimental design or randomized controlled trial, but it specifically lacks the element of random assignment to treatment or control. Instead, quasi-experimental designs typically allow the researcher to control the assignment to the treatment condition, but using some criterion other than random assignment (e.g., an eligibility cutoff mark). In some cases, the researcher may have control over assignment to treatment.Quasi-experiments are subject to concerns regarding internal validity, because the treatment and control groups may not be comparable at baseline. With random assignment, study participants have the same chance of being assigned to the intervention group or the comparison group. As a result, differences between groups on both observed and unobserved characteristics would be due to chance, rather than to a systematic factor related to treatment (e.g., illness severity). Randomization itself does not guarantee that groups will be equivalent at baseline. Any change in characteristics post-intervention is likely attributable to the intervention. With quasi-experimental studies, {{it may not be}} possible to convincingly demonstrate a causal link between the treatment condition and observed outcomes. This is particularly true if there are confounding variables that cannot be controlled or accounted for.|$|E
40|$|Angrist and Pischke {{highlight}} {{one aspect}} of the research that has positively transformed econometric practice and teaching. They emphasize the rise of experiments and <b>quasi-experiments</b> as credible sources of identification in microeconometric studies, which they usefully term "design-based research. " But in so doing, they miss {{an important part of the}} story: a second research strand aimed at developing tools for inference that are robust to subsidiary modeling assumptions. My first aim in these remarks therefore is to highlight some key developments in this area. I then turn to Angrist and Pischke's call for adopting experiments and <b>quasi-experiments</b> in macroeconometrics; while sympathetic, I suspect the scope for such studies is limited. I conclude with some observations on the current debate about whether experimental methods have gone too far in abandoning economic theory. ...|$|R
40|$|This paper investigates {{a puzzle}} in the {{literature}} on labor markets in developing countries: labor legislations not only {{have an impact on the}} formal labor market but also an impact on the informal sector. It has even been argued that the impact on the informal sector in the case of the minimum wage is stronger than on the formal sector. Using <b>quasi-experiments</b> of minimum wage changes and thereby exploiting geographical variation of the minimum wage bite, I find evidence for this hypothesis. Informal workers, workers without social security contribution, experienced significant wage increases when the minimum wage was raised while formal workers did not. This result highlights that non-compliance with one labor legislation, the social security contribution, does not necessarily imply non-compliance to other labor laws such as the minimum wage. minimum wages, informal economy, <b>quasi-experiments...</b>|$|R
40|$|This thesis {{explores the}} role of {{selection}} bias in <b>quasi-experiments,</b> which are experiments where the treatment assignment is not random. The first chapter discusses several <b>quasi-experiments</b> from legal and sociological settings in which the detection of a treatment effect may be confounded with inherent pre-treatment differences in the treated and control groups. In the second chapter, {{we see that the}} literature on quasi-experimental designs contains many controversies, not all of them clearly and carefully developed. The third chapter gives a general, formal theory of selection bias in <b>quasi-experiments.</b> ^ In the third chapter, we see that when statistics have a particular property, which I call removable selection bias, the treatment effect is estimable even in the presence of selection bias. The requirements for a statistic to exhibit removable selection bias are quite general and may be expressed in terms of concepts such as independence and conditional independence, without making explicit distributional assumptions. ^ Traditional discussions of <b>quasi-experiments</b> have suggested that designs are free of selection bias only if there is no selection by maturation interaction, defined in terms of a linear model. I show that selection bias is poorly characterized by selection by maturation interaction. Selection bias may be removable in the presence of such an interaction, or {{in the absence of a}} linear model. ^ While selection bias can be removed in a variety of situations, the result can be a statistic with higher variance. In the fourth chapter, numerous tables are given which demonstrate that some good designs yield statistics which remove selection bias with little or no increase in variance, while with other designs, the variance increases sharply. ^ The fifth chapter explores the situation in which bias remains that cannot be removed. In this circumstance, we can gauge the sensitivity of statistics to such bias. In analyses of this sort, we see that factors related to selection but unrelated to the statistic can be ignored. In the sixth chapter, we discuss directions for future research. ...|$|R
40|$|The {{purpose of}} this {{document}} is to describe the design and execution 		 of the <b>quasi-experiment</b> conducted in the Department 		 of Computer Science, Virginia Tech, in accordance 		 with the procedures described in the document, "An 		 Experimental Design for Evaluating SEES" prepared 		 for NASA under contract NASI- 19610, Task 		 17. (Hereafter that report is 		 called the general design document.) The 		 <b>quasi-experiment</b> serves three important 		 purposes. First, the <b>quasi-experiment</b> is the proof 		 of concept of the general experiment design. It shows that 		 the procedures defined in the general experiment 		 design can be implemented. Second, provides details 		 for setting up a true experiment: identifying the 		 research hypothesis, designing the 		 investigation, selecting various variables, 		 procedures, and controls, measuring the variables, 		 and evaluating the results. Third, any insights 		 revealed {{during the course of}} the <b>quasi-experiment</b> 		 can be incorporated in the costly true experiment, 		 thus providing a cost-effective experimental 		 methodology. This report contains sufficient 		 information so that the <b>quasi-experiment</b> can be 		 replicated at an appropriate level of 		 abstraction. We also document and interpret all the 		 results of the <b>quasi-experiment...</b>|$|E
30|$|We had {{to define}} a set of {{requirements}} in order to answer our research questions. Thus, we opted for conducting a <b>quasi-experiment</b> [31]. A <b>quasi-experiment</b> is an empirical study in which the units or groups are not assigned to conditions randomly. This allowed us to assign each participant to different treatments during the experimental steps. The experimental procedure was conducted individually with each participant. They had to perform the <b>quasi-experiment</b> in two steps with four tasks in each one. Both steps comprise {{the same set of}} tasks the only difference between them was regarding the treatment, i.e., usage of agglomerations or non-agglomerated smells.|$|E
30|$|In the {{previous}} section, we proposed the Organic tool, attending to our first goal. The “Study II: Communicability evaluation of Organic” section presents {{a study that}} addresses our third goal. Thus, aiming at achieving our second goal, in this section, we present a <b>quasi-experiment</b> with professional software developers. <b>Quasi-experiment</b> is an empirical interventional study in which the subjects are not randomly assigned to certain conditions [31]. In this study, we investigated whether the use of smell agglomerations improves the precision of developers in identifying design problems.|$|E
40|$|This paper {{describes}} {{the use of}} digital media in a first year undergraduate architectural design studio. It attempts to address the importance of developing a design process that is redefined {{by the use of}} computing, integrating concept and perception. Furthermore, it {{describes the}} theoretical foundations and <b>quasi-experiments</b> of a series of exercises developed for beginning design students...|$|R
40|$|The use of Open Government Data (OGD) has {{not kept}} pace with the {{expectations}} as existing OGD infrastructures mainly serve as data repositories. Many OGD infrastructures do not stimulate or support OGD use processes, {{and there is a}} lack of research regarding which functionalities can stimulate such processes. The objective of this study is to use a design science approach to evaluate whether metadata, interaction mechanisms, and data quality indicators can improve OGD use. OGD use comprises five main activities, namely searching for and finding OGD, OGD analysis, visualizing OGD, interacting about OGD, and OGD quality analysis. We expect that three OGD key infrastructure elements—metadata, interaction mechanisms, and data quality indicators—allow for improving these five OGD use activities. A prototype of an advanced OGD infrastructure was created, which implements the three OGD infrastructure elements. Three <b>quasi-experiments</b> with a pretest posttest control group design were conducted. The <b>quasi-experiments</b> showed that the prototype facilitated the usability of the novel OGD use functionalities. Our <b>quasi-experiments</b> supported our propositions that metadata, interaction mechanisms, and data quality indicators contribute to making OGD use easier and faster, and enhance the user experience. The infrastructure elements improved OGD use by better enabling searching, analyzing, visualizing, discussing, giving feedback on, and assessing the quality of open data. Hence, we plea for integrating metadata, interaction mechanisms, and data quality indicators in open data infrastructures to advance open data usage. First published online: 02 Dec 2015 Information and Communication Technolog...|$|R
25|$|As {{described}} above, I/O {{psychologists are}} trained in the scientist–practitioner model. I/O psychologists rely {{on a variety of}} methods to conduct organizational research. Study designs employed by I/O psychologists include surveys, experiments, <b>quasi-experiments,</b> and observational studies. I/O psychologists rely on diverse data sources including human judgments, historical databases, objective measures of work performance (e.g., sales volume), and questionnaires and surveys.|$|R
30|$|Research {{question}} RQ 1 {{allows us}} to analyze whether code smell agglomerations help developers to identify design problems. To answer this question, we conducted a <b>quasi-experiment</b> with 11 professional developers. In this <b>quasi-experiment,</b> we measured the precision of developers using agglomerations to identify design problems. Precision in our context is measured based on the percentage of true positives indicated by the developers— i.e., the percentage of correctly identified design problems (against a ground truth, as explained later). We have used precision since {{it is an important}} aspect of the identification task.|$|E
30|$|Aiming to {{reinforce}} the experimental results, we replicated the <b>quasi-experiment</b> presented in this section, using the requirements document of the ObasCId-Tool. More information about this are in the Appendix of this work.|$|E
40|$|Our {{on-going}} work {{concerns the}} effectiveness of voice-based task resumption support for smartphone users. This Late-Breaking Work presents results of a prototyping exercise involving a questionnaire-based survey and a <b>quasi-experiment.</b> In the <b>quasi-experiment,</b> participants were required to perform some manual tasks in a controlled environment while being interrupted by various voice calls. The effectiveness of different prototypes of a voice call application was tested. Subjective ratings of the prototypes were collected from the participants as a usability measurement. The results reveal some diverse views {{on the design of}} the dialogue interface for the voice call application...|$|E
40|$|Excerpt] Hospitality {{executives}} have available {{a number of}} different research methodologies and tools to aid them in decision making. Each methodology is valuable in its own way, but no single technique can provide all the answers to decision makers 2 ̆ 7 questions. This article advocates the increased use of experiments and <b>quasi-experiments</b> in hospitality-marketing research. To be as effective as possible, marketers should develop and test several potential courses of action before embarking on any of them. The best way to develop a variety of courses of action is to conduct exploratory or descriptive research. The best way to evaluate those options is to conduct a causal-research study that compares consumers 2 ̆ 7 behavior when faced with various options. Experiments and <b>quasi-experiments</b> are under-used, but are nevertheless powerful research tools that allow hospitality marketers to draw strong causal conclusions about the effects of pricing, design, and other changes on the amount of money customers spend, or the number of visits they make to an establishment...|$|R
40|$|This paper proposes the Active Learning for Classroom Management Model as {{a method}} to struc-ture active {{learning}} experiences. The model was devised and tested in an Introductory Computer Programming course. Stages in the model are explained with examples of classroom activities. The model was evaluated twice in series of <b>quasi-experiments</b> and limited support was provided for improved student performance {{through the use of}} the model...|$|R
50|$|Though <b>quasi-experiments</b> are {{sometimes}} shunned {{by those who}} consider themselves to be experimental purists (leading Donald T. Campbell to coin the term “queasy experiments” for them), they are exceptionally useful in areas where it is not feasible or desirable to conduct an experiment or randomized control trial. Such instances include evaluating the impact of public policy changes, educational interventions or large scale health interventions. The primary drawback of quasi-experimental designs is that they cannot eliminate the possibility of confounding bias, which can hinder one’s ability to draw causal inferences. This drawback {{is often used to}} discount quasi-experimental results. However, such bias can be controlled for using various statistical techniques such as multiple regression, if one can identify and measure the confounding variable(s). Such techniques can be used to model and partial out the effects of confounding variables techniques, thereby improving the accuracy of the results obtained from <b>quasi-experiments.</b> Moreover, the developing use of propensity score matching to match participants on variables important to the treatment selection process can also improve the accuracy of quasi-experimental results.In fact, data derived from quasi-experimental analyses has been shown to closely match experimental data in certain cases, even when different criteria were used. In sum, <b>quasi-experiments</b> are a valuable tool, especially for the applied researcher. On their own, quasi-experimental designs do not allow one to make definitive causal inferences; however, they provide necessary and valuable information that cannot be obtained by experimental methods alone. Researchers, especially those interested in investigating applied research questions, should move beyond the traditional experimental design and avail themselves of the possibilities inherent in quasi-experimental designs.|$|R
