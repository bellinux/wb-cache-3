2483|764|Public
500|$|YouTube {{originally}} offered videos at {{only one}} quality level, displayed at {{a resolution of}} 320×240 pixels using the Sorenson Spark codec (a variant of H.263), with mono MP3 audio. In June 2007, YouTube added an option to watch videos in 3GP format on mobile phones. In March 2008, a high-quality mode was added, which increased the resolution to 480×360 pixels. In November 2008, 720p HD support was added. At {{the time of the}} 720p launch, the YouTube player was changed from a [...] aspect ratio to a widescreen [...] With this new feature, YouTube began a switchover to H.264/MPEG-4 AVC as its default video compression format. In November 2009, 1080p HD support was added. In July 2010, YouTube announced that it had launched a range of videos in 4K format, which allows a resolution of up to 4096×3072 pixels. In June 2015, support for 8K resolution was added, with the videos playing at 7680×4320 pixels. In November 2016, support for HDR video was added which can be encoded with Hybrid Log-Gamma (HLG) or Perceptual <b>Quantizer</b> (PQ). HDR video can be encoded with the Rec. 2020 color space.|$|E
50|$|In general, a Wyner-Ziv {{coding scheme}} is {{obtained}} {{by adding a}} <b>quantizer</b> and a de-quantizer to the Slepian-Wolf coding scheme. Therefore, a Wyner-Ziv coder design could focus on the <b>quantizer</b> and corresponding reconstruction method design. Several <b>quantizer</b> designs have been proposed, such as a nested lattice <b>quantizer,</b> trellis code <b>quantizer</b> and Lloyd quantization method.|$|E
5000|$|The Lloyd-Max <b>quantizer</b> is {{actually}} a uniform <b>quantizer</b> when the input pdf is uniformly distributed over the range [...] However, for a source {{that does not have}} a uniform distribution, the minimum-distortion <b>quantizer</b> may not be a uniform <b>quantizer.</b>|$|E
40|$|The {{parameters}} of non-uniform and uniform <b>quantizers</b> {{up to ten}} bits of quantization, optimum for a Gaussian input probability and for the magnitude-error distortion criterion are computed. Optimum <b>quantizers</b> must be understood as <b>quantizers</b> with minimum distortion. The numerical method used for the optimization converges relatively rapidly. The comparison between optimum non-uniform <b>quantizers</b> and optimum uniform <b>quantizers</b> is made...|$|R
3000|$|... 2 sensor field. For each of 100 {{different}} sensor configurations, {{we design}} uniform <b>quantizers</b> (Unif Q), Lloyd <b>quantizers</b> (Lloyd Q), and several novel <b>quantizers</b> for R [...]...|$|R
40|$|Abstract:- In {{this paper}} an exact and {{complete}} analysis of average design complexities of Lloyd-Max's scalar <b>quantizers,</b> scalar compandors and scalar <b>quantizers</b> designed using the hybrid model is carried out. The average design complexity depends on arithmetic complexity, memory complexity and implementation complexity. It is demonstrated {{that for a}} fixed number of quantizaton levels N, scalar compandors have the smallest and the Lloyd-Max's scalar <b>quantizers</b> have the largest complexity. Furthermore, it is shown that for a fixed number of quantizaton levels N the average design complexity of hybrid scalar <b>quantizers</b> is significantly smaller than the average design complexity of Lloyd-Max's scalar <b>quantizers.</b> Combining this result {{with the fact that}} the performances of hybrid scalar <b>quantizers</b> are almost equal to the optimal performances of Lloyd-Max's scalar <b>quantizers,</b> the usability of recently developed hybrid model is confirmed...|$|R
5000|$|The {{modulator}} {{can also}} be classified {{by the number of}} bits it has in output, which strictly depends on the output of the <b>quantizer.</b> The <b>quantizer</b> can be realized with a N-level comparator, thus the modulator has log2N-bit output.A simple comparator has 2 levels and so is 1 bit quantizer; a 3-level <b>quantizer</b> is called a [...] "1.5" [...] bit quantizer; a 4-level <b>quantizer</b> is a 2 bit quantizer; a 5-level <b>quantizer</b> is called a [...] "2.5 bit" [...] <b>quantizer.</b>|$|E
50|$|In general, a mid-riser or mid-tread <b>quantizer</b> may not {{actually}} be a uniform <b>quantizer</b> - i.e., {{the size of the}} quantizer's classification intervals may not all be the same, or the spacing between its possible output values may not all be the same. The distinguishing characteristic of a mid-riser <b>quantizer</b> is that it has a classification threshold value that is exactly zero, and the distinguishing characteristic of a mid-tread <b>quantizer</b> is that is it has a reconstruction value that is exactly zero.|$|E
50|$|Similar to the {{previous}} lossless coding framework based on Slepian-Wolf theorem, efforts have been taken on lossy cases based on the Wyner-Ziv theorem. Theoretical results on <b>quantizer</b> designs was provided by R. Zamir and S. Shamai, while different frameworks have been proposed based on this result, including a nested lattice <b>quantizer</b> and a trellis-coded <b>quantizer.</b>|$|E
40|$|Abstract—This paper {{studies the}} {{optimization}} of observation channels and <b>quantizers</b> in partially observed stochastic control problems. Continuity {{properties of the}} optimal cost in channels and <b>quantizers</b> are explored. Sufficient conditions for sequential compactness under total variation and setwise convergence are presented. Conditions for existence of optimal channels and <b>quantizers</b> are established. It is shown that <b>quantizers</b> are extreme points of the space of channels in an appropriate sense. I...|$|R
40|$|Scalar <b>quantizers</b> {{with the}} minimum {{mean square error}} are {{designed}} in the case where the input signal and the quantization noise are uncorrelated. The probability density function (pdf) of the stochastic signal is assumed to be known. This design is then generalized to vector <b>quantizers</b> in the case where the expected value of the inner product between the input and quantization noise vector are equal to zero. The results show that the representation levels of the proposed <b>quantizers</b> are scaled versions of the representation levels of the well-known pdf optimized <b>quantizers.</b> The proposed <b>quantizers</b> are useful in subband coding applications. 1...|$|R
40|$|Abstract — Zooming type {{adaptive}} <b>quantizers</b> {{have been}} introduced in the networked control literature as efficient coders for stabilizing open-loop unstable noise-free systems connected over noiseless channels with arbitrary initial conditions. Such <b>quantizers</b> {{can be regarded as}} a special class of the Goodman-Gersho adaptive <b>quantizers.</b> In this paper, we provide a stochastic stability result for such <b>quantizers</b> when the system is driven by an additive noise process. Conditions leading to stability are evaluated when the system is driven by noise with non-compact support for its probability measure. It is shown that zooming <b>quantizers</b> are efficient and almost achieve the fundamental lower bound of the logarithm of the absolute value of an unstable eigenvalue. In particular, such <b>quantizers</b> are asymptotically optimal when the unstable pole of the linear system is large for a weak form of stability. I...|$|R
5000|$|After {{defining}} {{these two}} performance metrics for the <b>quantizer,</b> a typical Rate-Distortion formulation for a <b>quantizer</b> design {{problem can be}} expressed {{in one of two}} ways: ...|$|E
5000|$|Finding {{an optimal}} {{solution}} to the above problem results in a <b>quantizer</b> sometimes called a MMSQE (minimum mean-square quantization error) solution, and the resulting pdf-optimized (non-uniform) <b>quantizer</b> {{is referred to as}} a Lloyd-Max <b>quantizer,</b> named after two people who independently developed iterative methods to solve the two sets of simultaneous equations resulting from [...] and , as follows: ...|$|E
5000|$|Another {{name for}} a mid-tread <b>quantizer</b> with {{symmetric}} behavior around 0 is dead-zone <b>quantizer,</b> and the classification region around the zero output value of such a <b>quantizer</b> {{is referred to as}} the dead zone or deadband. The dead zone can sometimes serve the same purpose as a noise gate or squelch function. Especially for compression applications, the dead-zone may be given a different width than that for the other steps. For an otherwise-uniform <b>quantizer,</b> the dead-zone width can be set to any value [...] by using the forward quantization rule ...|$|E
3000|$|..., {{the average}} system {{distortion}} of CSI <b>quantizers</b> with transformed codebook can be {{upper and lower}} bounded by some multiplicative factors of the distortion of optimal <b>quantizers.</b>|$|R
40|$|The {{effect of}} {{quantization}} of prior probabilities {{in a collection}} of distributed Bayesian binary hypothesis testing problems over which the priors themselves vary is studied. In a setting with fusion of local binary decisions by majority rule, optimal local decision rules are discussed. Quantization is first considered under the constraint that agents employ identical <b>quantizers.</b> A method for design is presented that exploits an equivalence to a single-agent problem with a different likelihood function; the optimal <b>quantizers</b> are thus different than in the single-agent case. Removing the constraint of identical <b>quantizers</b> is demonstrated to improve performance. A method for design is presented that exploits an equivalence between agents having diverse K-level <b>quantizers</b> and agents having identical (3 K − 2) -level <b>quantizers.</b> ...|$|R
3000|$|... g This {{depends on}} the {{characteristic}} of <b>quantizers</b> used at the source node to quantize each message before packet forwarding. Specifically, in our simulations where we used uniform <b>quantizers</b> with step size Δ [...]...|$|R
5000|$|The indices {{produced}} by an -level <b>quantizer</b> can be coded using a fixed-length code using [...] bits/symbol. For example when 256 levels, the FLC bit rate [...] is 8 bits/symbol. For this reason, such a <b>quantizer</b> {{has sometimes been}} called an 8-bit <b>quantizer.</b> However using an FLC eliminates the compression improvement that {{can be obtained by}} use of better entropy coding.|$|E
50|$|At {{asymptotically}} {{high bit}} rates, the 6 dB/bit approximation is supported for many source pdfs by rigorous theoretical analysis. Moreover, {{the structure of}} the optimal scalar <b>quantizer</b> (in the rate-distortion sense) approaches that of a uniform <b>quantizer</b> under these conditions.|$|E
50|$|For {{other source}} pdfs and other <b>quantizer</b> designs, the SQNR may be {{somewhat}} different from that predicted by 6 dB/bit, {{depending on the type}} of pdf, the type of source, the type of <b>quantizer,</b> and the bit rate range of operation.|$|E
40|$|For a team {{of mobile}} agents governed by second-order dynamics, this paper studies how {{different}} <b>quantizers</b> affect the performances of consensus-type schemes to achieve synchronized collective motion. It is shown that when different types of <b>quantizers</b> are used for the exchange of relative position and velocity information between neighboring agents, different collective behaviors appear. Under the chosen logarithmic <b>quantizers</b> and with symmetric neighbor relationships, we prove that the agents' velocities and positions get synchronized asymptotically. We show that under the chosen symmetric uniform <b>quantizers</b> and with symmetric neighbor relationships, the agents' velocities converge to the same value asymptotically while the differences of their positions converge to a bounded set. We also show that when the uniform <b>quantizers</b> are not symmetric, the agents' velocities may grow unboundedly. Through simulations we present richer undesirable system behaviors when different logarithmic and uniform <b>quantizers</b> are used. Such different quantization effects underscore the necessity for a careful selection of quantization strategies, especially for multi-agent systems with higher-order agent dynamics. (C) 2012 Elsevier B. V. All rights reserved...|$|R
40|$|The {{problem of}} finding and characterizing minimal sets of dequantizers and <b>quantizers</b> {{applied in the}} mapping of {{operators}} onto functions is considered, for finite-dimensional quantum systems. The general properties of such sets are determined. An explicit description of all the minimum self-dual sets of dequantizers and <b>quantizers</b> for a qubit system is derived. The connection between some known sets of dequantizers and <b>quantizers</b> and the derived formulae is presented. Comment: 13 pages, no figure...|$|R
40|$|In {{this paper}} we propose the {{gradient}} match fractal vector <b>quantizers</b> (GMFVQs) and the side match fractal vector <b>quantizers</b> (SMFVQs), which are two classes of finite state fractal vector <b>quantizers</b> (FSFVQs), for the image coding framework. In our previous work, we proposed the non-iterative fractal block coding (FBC) technique to improve the decoding speed and the coding performance for conventional FBC techniques. To {{reduce the number of}} bits for denoting the fractal code of the range block, the concepts of the gradient match vector <b>quantizers</b> (GMVQs) and the side match vector <b>quantizers</b> (SMVQs) are employed to the non-iterative FBC technique. Unlike the ordinary vector <b>quantizers,</b> the super codebooks in the proposed GMFVQs and SMFVQs are generated from the affine-transformed domain blocks in the non-iterative FBC technique. The codewords in the state codebook are dynamically extracted from the super codebook with the side-match and gradient-match criteria. The redundancy in the affine-transformed domain blocks is greatly reduced and the compression ratio can be significantly increased. Our simulation results show that 15 %– 20 % of the bit rates in the non-iterative FBC technique are saved by using the proposed GMFVQs. ...|$|R
50|$|The {{difference}} between an input value and its quantized value (such as round-off error) {{is referred to as}} quantization error. A device or algorithmic function that performs quantization is called a <b>quantizer.</b> An analog-to-digital converter {{is an example of a}} <b>quantizer.</b>|$|E
5000|$|As an example, {{rounding}} a {{real number}} [...] {{to the nearest}} integer value forms a very basic type of <b>quantizer</b> - a uniform one. A typical (mid-tread) uniform <b>quantizer</b> with a quantization step size equal to some value [...] can be expressed as ...|$|E
50|$|Additionally, the <b>quantizer</b> (e.g., comparator) used in DM has a {{small output}} {{representing}} a small step {{up and down the}} quantized approximation of the input while the <b>quantizer</b> used in SDM must take values outside of the range of the input signal, as shown in Fig. 3.|$|E
30|$|So far, we have {{considered}} encoding algorithms by fixing <b>quantizers.</b> However, since there exists dependency between quantization and encoding of quantized data {{which can be}} exploited to obtain better performance gain, {{it would be worth}} considering a joint design of <b>quantizers</b> and encoders.|$|R
40|$|We {{consider}} stochastic stationary analog signals. For such signals, {{we consider}} <b>quantizers</b> whose performance remains stable under perturbations in the statistical {{description of the}} signals. Performance {{is defined as the}} induced average distortion, the output entropy, and the asymptotic consistency in the preservation of important signal characteristics. We found that stochastic <b>quantizers</b> can, in general, realize performance stability, while deterministic <b>quantizers</b> do not. We consider block quantization for lower average distortion under fixed output rate, and we propose predictive stochastic quantization for highly correlated signals. The proposed predictive <b>quantizers</b> compress automatically to the output entropy. We also propose nonpredictive block stochastic quantization for weakly correlated or uncorrelated signals. We describe an Elias-type noiseless compressor for channel transmission, and a matching decoder...|$|R
40|$|Quantization of {{sinusoidal}} model parameters is of impor-tance in e. g. low-rate audio coding. In {{this work}} we intro-duce entropy constrained unrestricted spherical quantization, where amplitude, phase and frequency are quantized depen-dently. We derive a high-rate approximation {{of the average}} ` 2 -distortion and use this to analytically derive formulas for optimal spherical scalar <b>quantizers.</b> These <b>quantizers</b> mini-mize the average distortion, while the corresponding quanti-zation indices satisfy an entropy constraint. The <b>quantizers</b> {{turn out to be}} ⁄exible and of low complexity, {{in the sense that they}} can be determined for varying entropy constraints with-out any iterative retraining procedures. As a consequence of minimizing the ` 2 -norm of the (quantization) error signal, the <b>quantizers</b> depend on both the shape and length of the analysis/synthesis window. 1...|$|R
50|$|Contrary {{to popular}} belief, a fixed frame-level <b>quantizer</b> (set by the user) does not deliver a {{constant}} level of quality. Instead, {{it is an}} arbitrary metric that will provide a somewhat varying level of quality, depending on the contents of each frame. Given two files of identical sizes, the one encoded at an average bitrate should look better than the one encoded with a fixed <b>quantizer</b> (variable bitrate). Constant <b>quantizer</b> encoding can be used, however, to accurately determine the minimum and maximum bitrates possible for encoding a given video.|$|E
5000|$|Because {{the set of}} {{possible}} output values of a <b>quantizer</b> is countable, any <b>quantizer</b> can be decomposed into two distinct stages, which {{can be referred to}} as the classification stage (or forward quantization stage) and the reconstruction stage (or inverse quantization stage), where the classification stage maps the input value to an integer quantization index [...] and the reconstruction stage maps the index [...] to the reconstruction value [...] that is the output approximation of the input value. For the example uniform <b>quantizer</b> described above, the forward quantization stage can be expressed as ...|$|E
5000|$|The {{incorporation}} of the decoder inside the encoder allows quantization of the differences, including nonlinear quantization, in the encoder, as long as an approximate inverse <b>quantizer</b> is used appropriately in the receiver. When the <b>quantizer</b> is uniform, the decoder regenerates the differences implicitly, as in this simple diagram that Cutler showed: ...|$|E
30|$|A good erasure {{code for}} our {{proposed}} <b>quantizers</b> should have excellent ability to correct erasures but {{no ability to}} correct errors. This is because the codes that have error correcting ability can improve the performance of not only our proposed <b>quantizers</b> but also the <b>quantizers</b> in [7], and the benefits are equal. Thus, in this section, we focus on SPC code to correct the empty cell index that appears in receivers, in order to approach the lower bound for EOUQ with CNC index assignment.|$|R
40|$|We {{establish}} the optimal quantization problem for probabilities under constrained Rényi-α-entropy of the <b>quantizers.</b> We determine the optimal <b>quantizers</b> and the optimal quantization error of one-dimensional uniform distributions including the known special cases α = 0 (restricted codebook size) and α = 1 (restricted Shannon entropy) ...|$|R
5000|$|... #Subtitle level 2: Mid-riser and mid-tread uniform <b>quantizers</b> ...|$|R
