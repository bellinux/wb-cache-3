3|52|Public
5000|$|... queue-monitor {{coordinator}} process (QMNC): dynamically spawns <b>queue</b> <b>monitor</b> slaves ...|$|E
50|$|In Oracle Data Guard primary {{databases}} the <b>queue</b> <b>monitor</b> process (often {{running as}} qmn0) interacts with AQ.|$|E
40|$|The {{expectation}} of rapid image retrieval from PACS users contributes to increased information technology (IT) infrastructure investments to increase performance {{as well as}} continuing demands upon PACS administrators to respond to “slow” system performance. The ability to provide predicted delivery times to a PACS user may curb user expectations for “fastest” response especially during peak hours. This, in turn, {{could result in a}} PACS infrastructure tailored to more realistic performance demands. A PACS with a stand-alone architecture under peak load typically holds study requests in a queue until the DICOM C-Move command can take place. We investigate the contents of a stand-alone architecture PACS RetrieveSend queue and identified parameters and behaviors that enable a more accurate prediction of delivery time. A prediction algorithm for studies delayed in a stand-alone PACS queue can be extendible to other potential bottlenecks such as long-term storage archives. Implications of a <b>queue</b> <b>monitor</b> in other PACS architectures are also discussed...|$|E
40|$|This paper {{describes}} <b>queue</b> <b>monitoring,</b> {{a policy}} {{for managing the}} effect of delay jitter on audio and video in computer-based conferences. By observing delay jitter over time, this policy dynamically adjusts display latency {{in order to support}} low-latency conferences with an acceptable gap rate. <b>Queue</b> <b>monitoring</b> is evaluated by comparing it with two other policies in an empirical study of a computer-based conferencing system. Our results show that <b>queue</b> <b>monitoring</b> performs well under a variety of observed network loads...|$|R
40|$|Abstract: This paper {{presents}} an empirical study of several policies {{for managing the}} effect of delay jitter on the playout of audio and video in computer-based conferences. The problem addressed is that of managing the fundamental tradeoff between display with low latency and display with few gaps. We describe a particular policy called <b>queue</b> <b>monitoring</b> which observes delay jitter over time and dynamically adjusts display latency {{in order to support}} low-latency conferences with an acceptable gap rate. <b>Queue</b> <b>monitoring</b> is evaluated by comparing it with two policies from the literature in a study based on measurements from a computer-based conferencing system. Our results show that <b>queue</b> <b>monitoring</b> performs as well or better than the other policies over the range of observed network loads. More importantly, we show that <b>queue</b> <b>monitoring</b> performs better on those network loads for which the other policies exhibit poor performance. 1...|$|R
40|$|This paper {{presents}} an empirical study of several policies {{for managing the}} effect of delay jitter on the playout of audio and video in computer-based conferences. The problem addressed is that of managing the fundamental tradeoff between display with low latency and display with few gaps. We describe a particular policy called <b>queue</b> <b>monitoring</b> which observes delay jitter over time and dynamically adjusts display latency {{in order to support}} low-latency conferences with an acceptable gap rate. <b>Queue</b> <b>monitoring</b> is evaluated by comparing it with two policies from the literature in a study based on measurements from a computer-based conferencing system. Our results show that <b>queue</b> <b>monitoring</b> performs as well or better than the other policies over the range of observed network loads. More importantly, we show that <b>queue</b> <b>monitoring</b> performs better on those network loads for which the other policies exhibit poor performance. 1. Introduction This work concerns network and operating system s [...] ...|$|R
40|$|This paper {{describes}} <b>queue</b> <b>monitoring,</b> {{a policy}} {{for managing the}} effect of delay jitter on audio and video in computer-based conferences. By observing delay jitter over time, this policy dynamically adjusts display latency {{in order to support}} low-latency conferences with an acceptable gap rate. <b>Queue</b> <b>monitoring</b> is evaluated by comparing it with two other policies in an empirical study of a computer-based conferencing system. Our results show that <b>queue</b> <b>monitoring</b> performs well under a variety of observed network loads. 1. Introduction Our research is concerned with network and operating system support for computerbased conferencing using today's networks based on asynchronous communications (e. g., ethernet, token ring, FDDI, T 3, etc.). In this environment, transmission times vary, and hence audio and video data may occasionally arrive at their destination "late. " When data arrives after the time at which it should be displayed, a "gap" appears in the display which affects the user's [...] ...|$|R
25|$|Huntleigh USA {{provides}} airport ground {{services in}} the USA. Such services include charter flight and cargo security screening, aircraft search, guard services, airlines' agents, <b>queue</b> <b>monitors,</b> aircraft cleaning, ramp and below-the-wing services, skycap, wheelchair attendants, baggage handling, etc.|$|R
5000|$|Various <b>queue</b> <b>monitoring</b> {{interfaces}} {{that allow}} the application to get feedback on how much data has been sent and received as requested. This allows an application to decrease/increase the amount of data sent {{in accordance with the}} capabilities of the receiver.|$|R
50|$|Talk offers {{flexible}} IVR, group routing, and real-time <b>queue</b> <b>monitoring</b> {{to avoid}} bottlenecks. With analytics that deliver {{insight into what}} is happening, support teams can are equipped to provide flexible, powerful support as businesses evolve. Talk allows businesses to create phone numbers and forward calls to customer representatives’ devices, forgoing the need for physical call centers.|$|R
40|$|Novel {{computer}} vision techniques {{have been developed}} for automatic monitoring of crowed environments such as airports, railway stations and shopping malls. Using video feeds from multiple cameras, the techniques enable crowd counting, crowd flow <b>monitoring,</b> <b>queue</b> <b>monitoring</b> and abnormal event detection. The outcome of the research is useful for surveillance applications and for obtaining operational metrics to improve business efficiency...|$|R
50|$|Western {{values of}} {{consumer}} discipline gradually implemented into Hong Kong's society. Consumers have accepted {{key elements of}} the American fast food formula, but with localized adaptations. The establishment of an American-inspired model of customers queuing was introduced. <b>Queue</b> <b>monitors</b> were sanctioned {{in order to encourage}} the formation of orderly lines at McDonald's, which later became an in-restaurant norm by the 1980s.|$|R
40|$|Abstract: In {{this paper}} a {{methodology}} is put forward {{to create an}} Internet-based infrastructure to service and maintain RP-oriented telemanufacturing. The WWW-based Java-enabled Internet computing model is used for implementing remote part submitting, <b>queuing,</b> <b>monitoring,</b> and managing. Control of different access competences allows manufacturing sites and queues to be maintained respectively in any place. A Java-based software testbed has been developed {{to serve as a}} verification platform. 1...|$|R
40|$|Designers of {{data centers}} and Web servers aim to provide clients {{resources}} on demand {{to decrease the}} initial cost of hosted service deployment models. In addition, they must also minimize operating cost, such as energy consumption, by matching service capacity demand with resource supply. However, since the term “capacity” is typically defined vaguely or inadequately, {{it is difficult to}} assess resource needs in a running system and usually results in oversized server deployment. To address this problem, we first define the capacity of a server cluster as the sustainable throughput subject to a request retransmission ratio constraint. Then, we analyze different approaches of capacity estimation. Various capacity estimation mechanisms, including off-line benchmarking, CPU-utilization-based, and <b>queue</b> <b>monitoring</b> (proposed here), are studied and compared. We also employ several different data-collection methods (application instrumentation, user-space tools, SNMP, and kernel modules) to compare their effects on estimation accuracy. Among these, <b>queue</b> <b>monitoring</b> is found to provide a good and stable estimate of server capacity. To validate our findings we applied our proposed estimation method to server cluster sizing for energy conservation. A good combination of data collection and online capacity estimation is found to make significantly more energy savings than traditional approaches (i. e., static estimation and schedule...|$|R
3000|$|... • The RabbitMQ <b>monitoring</b> <b>queue</b> – used {{to collect}} {{monitored}} values of the job queue workload and workers’ response times.|$|R
40|$|Widespread {{heterogeneous}} parallelism {{is unavoidable}} given {{the emergence of}} General-Purpose computing on graphics processing units (GPGPU). The characteristics of a Graphics Processing Unit (GPU) —including significant memory transfer latency and complex performance characteristics—demand new approaches to ensuring that all available computational resources are efficiently utilised. This paper considers the simple case of a divisible workload based on widely-used numerical linear algebra routines and the challenges that prevent efficient use of all resources available to a naive SPMD application using the GPU as an accelerator. We suggest a possible <b>queue</b> <b>monitoring</b> strategy that facilitates resource usage {{with a view to}} balancing the CPU/GPU utilisation for applications that fit the pipeline parallel architectural pattern on heterogeneous multicore/multi-node CPU and GPU systems. We propose a stochastic allocation technique that may serve as a foundation for heuristic approaches to balancing CPU/GPU workloads...|$|R
25|$|Replicating the newscasts from WWOR, {{the video}} in the <b>queue</b> <b>monitors</b> was real; {{production}} for the audio in the ride work and pre-show videos was handled by John Miceli, Tony Miceli, David Kneupper; Stan Winston; {{at the time}} with Magic Lantern Productions and later Soundelux, who contracted all audio and video design for the ride. Since WWOR had passed from the prior corporate owners (RKO General) to MCA, there were still conflicts in the prior audio from broadcast use, as it was not cleared for location-based entertainment use, and the script was stylized for the ride experience. The announcer for the script as the WWOR reporter was provided by voiceover talent Ron Knight, who also provided voice work {{for many of the}} voices of the chopper pilots, radio dispatch, sheriffs and other characters, as well as voice-over work for two of the other premiere attractions, E.T.'s Adventure, and Jaws. Knight also became the national announcer for Nickelodeon for all show promotion and network branding announcements originating from the Nickelodeon Studios facilities inside the park.|$|R
30|$|Contention {{among the}} nodes {{due to the}} shared medium also leads {{to the problem of}} unfairness; in this regard, Xu et al. [59] {{proposed}} a NRED scheme that is based on the RED [58] algorithm to reduce the impact of unfairness among nodes. The NRED scheme introduced a distributed neighbourhood queue approach which is an aggregation of neighbourhood queues so that each neighbour node holds a portion of the distributed <b>queue.</b> <b>Monitoring</b> the channel usage, a node estimates the size of the neighbourhood-distributed queue and computes its dropping/marking probability to ensure a fair share of dropped/marked packets. The proposed technique is based on the link layer and consists of three sub-schemes called neighbourhood-congestion detection (NCD), neighbourhood-congestion notification (NCN), and distributed neighbourhood packet drop (DNPD). The task of NCD is to compute the average queue size of the distributed queue. Analysing the channel utilization for different time slots, when and how a node informs its neighbouring nodes about the congestion is the task of NCN where DNPD is responsible for computing the local drop probability.|$|R
5000|$|Replicating the newscasts from WWOR, {{the video}} in the <b>queue</b> <b>monitors</b> was real; {{production}} for the audio in the ride work and pre-show videos was handled by John Miceli, Tony Miceli, David Kneupper; Stan Winston; {{at the time}} with Magic Lantern Productions and later Soundelux, who contracted all audio and video design for the ride. Since WWOR had passed from the prior corporate owners (RKO General) to MCA, there were still conflicts in the prior audio from broadcast use, as it was not cleared for location-based entertainment use, and the script was stylized for the ride experience. The announcer for the script as the WWOR reporter was provided by voiceover talent Ron Knight, who also provided voice work {{for many of the}} voices of the chopper pilots, radio dispatch, sheriffs and other characters, as well as VO work for two of the other premiere attractions, [...] "E.T.'s Adventure", and [...] "Jaws". Knight also became the national announcer for Nickelodeon for all show promotion and network branding announcements originating from the Nickelodeon Studios facilities inside the park.|$|R
40|$|In recent year’s {{organizations}} are increasingly utilizing workflow management systems technology, based on queuing models, to automate manual business processes. One {{industry that has}} seen {{one of the most}} rapid implementation and deployment of workflow systems in recent years is the services call center industry. Despite the great promise, workflow <b>queue</b> <b>monitoring</b> and work distribution continue to pose great challenges to organizations in terms of operational efficiency and performance. The primary reason for the inherent performance problems is whether the queues are configured as static or dynamic queues. In this study, static and dynamic queue configurations, based on M/M/c and M/M/I queuing models in the call center context are compared across several performance dimensions. An empirical study was used to compare the performance of a static versus a dynamic configuration in a call center context. Results suggest that dynamic queue configurations perform better than static queue configurations. A simulation model using parameter estimates from the real-life case was used to understand the results further. Overall, the superiority of dynamic workflow systems over static workflow systems in the call center context is confirmed in this study...|$|R
40|$|Similar to wired {{communication}}, Mobile IP {{communication is}} susceptible to various kinds of attacks. Of these attacks, Denial of Service (DoS) attack is considered as a great threat to mobile IP communication. The number of approaches hitherto proposed to prevent DoS attack {{in the area of}} mobile IP communication is much less compared to those for the wired domain and mobile ad hoc networks. In this work, the effects of Denial of Service attack on mobile IP communication are analyzed in detail. We propose to use packet filtering techniques that work in different domains and base stations of mobile IP communication to detect suspicious packets and to improve the performance. If any packet contains a spoofed IP address which is created by DoS attackers, the proposed scheme can detect this and then filter the suspected packet. The proposed system can mitigate the effect of Denial of Service (DoS) attack by applying three methods: (i) by filtering in the domain periphery router (ii) by filtering in the base station and (iii) by <b>queue</b> <b>monitoring</b> at the vulnerable points of base-station node. We evaluate the performance of our proposed scheme using the network simulator NS- 2. The results indicate that the proposed scheme is able to minimize the effects of Denial of Service attacks and improve the performance of mobile IP communication...|$|R
40|$|Abstract. We {{show that}} {{production}} rules and persis-tent queues together provide a convenient mechanism for maintaining consistency in semantically heterogeneous multi-database environments. We describe a specification language and methods for automatically deriving production rules that maintain (1) existence dependencies, {{in which the}} presence of data in one database implies the presence of related data in another, and (2) value dependencies, in which the value of data in one database is baaed {{on the value of}} related data in another. The production rules derived from dependency specifications use persistent <b>queues</b> to <b>monitor</b> and maintain the dependencies automatically, asynchronously, incremen-tally, and correctly. ...|$|R
30|$|Our {{results with}} the FRED queue at the gateway {{are shown in}} Figure 3. It fails to prevent {{starvation}} for TCP flow to node n 3. By <b>monitoring</b> <b>queue</b> drops at the gateway, {{we found that the}} FRED queue did register some proactive packet drops for f 1 and f 2, though it was insufficient to preclude the starvation of f 3.|$|R
40|$|Unprecedented rate {{of growth}} in the number of {{vehicles}} has resulted in acute road congestion problems worldwide. Better traffic flow management, based on enhanced traffic monitoring, is being tried by city authorities. In many developing countries, the situation is worse because of greater skew in growth of traffic vs the road infrastructure. Further, the existing traffic monitoring techniques perform poorly in the chaotic non-lane based traffic here. In this paper, we present Kyun 1 Queue, a sensor network system for real time traffic <b>queue</b> <b>monitoring.</b> Compared to existing systems, it has several advantages: it (a) works in chaotic traffic, (b) does not interrupt traffic flow during its installation and maintenance and (c) incurs low cost. Our contributions in this paper are four-fold. (1) We propose a new mechanism to sense road occupancy based on variation in RF link characteristics, when line of sight between a transmitter-receiver pair is obstructed. (2) We design algorithms to classify traffic states into congested or free-flowing at time scales of 20 seconds with above 90 % accuracy. (3) We design and implement the embedded platforms needed to do the sensing, computation and communication to form a network of sensors. This network can correlate the traffic state classification decisions of individual sensors, to detect multiple levels of traffic congestion or traffic queue length on a given stretch of road, in real time. (4) Deployment of our system on a Mumbai road, after careful consideration of issues like localization and interference, gives correct estimates of traffic queue lengths, validated against 9 hours of image based ground truth. Our system can provide input to several traffic management applications like traffic light control, incident detection, and congestion monitoring. ...|$|R
3000|$|... • Autonomic Manager – this is {{the core}} {{component}} of the framework responsible for collecting and analysing monitored values, detecting/predicting critical conditions, and generating corresponding adaptation actions. By registering appropriate C-SPARQL queries against the <b>monitoring</b> <b>queue,</b> the Autonomic Manager is notified {{as soon as the}} RDF triples in the stream satisfy the WHERE clause of the query. Let us now consider the following queries for each of the monitored metrics: [...]...|$|R
30|$|As {{mentioned}} earlier, {{we developed}} a cloud-based generic and scalable software framework called MCCO[20] for supporting the end-to-end lifecycle operations required for managing content via clouds and the Internet. The MCCO exploit public clouds for offloading computing, storage, network, and content distribution functionalities in a cost effective manner. Cloud computing[3, 4] assembles large networks of virtualized services: hardware resources (CPU, storage, and network) and software resources or appliances (e.g., databases, message <b>queuing</b> systems, <b>monitoring</b> systems, load-balancers). Cloud providers including Amazon Web Services (AWS), Microsoft Azure, Salesforce.com, Google App Engine, and others give users the option to deploy their application over a network of infinite resource pool with practically no capital investment and with modest operating cost proportional to the actual use.|$|R
40|$|We {{apply the}} XMC model checker to the Java metalocking algorithm, a highly {{optimized}} technique for ensuring mutually exclusive access by threads to object <b>monitor</b> <b>queues.</b> Our abstract specification of the meta-locking algorithm is fully parameterized, both on Å, {{the number of}} threads, and Æ, the number of objects. Using XMC, we show that {{for a variety of}} values of Å and Æ, the algorithm indeed provides mutual exclusion and freedom from lockout. ...|$|R
40|$|Abstract—Designers of {{data centers}} and Web servers {{aim to make}} on-demand {{allocation}} of resources to clients in order to lower the deployment cost of hosted services. Moreover, they must also minimize operating costs, such as energy consumption, by matching service-capacity demand with resource supply. However, since the term “capacity ” is typically defined vaguely or inadequately, {{it is difficult to}} assess resource needs and, hence, servers, which are several times larger than needed at runtime, are usually deployed. The time-varying nature of the workload model further complicates the problem and necessitates an online capacity-estimation solution. To address this overprovisioning problem, we first define the capacity of a server cluster as the sustainable throughput subject to a request retransmission ratio constraint and then analyze different approaches to capacity estimation in a running system. Various capacity-estimation mechanisms, such as offline benchmarking and CPU-utilization evaluation, are discussed and compared with our queue-monitoring method. We employ several different data-collection methods (application instrumentation, user-space tools, Simple Network Management Protocol (SNMP), and kernel modules) to compare their effects on estimation accuracy. Of these, <b>queue</b> <b>monitoring</b> is found to provide a good and stable estimate of server capacity. To validate this finding, we propose a simple cluster-resizing mechanism and evaluate the energy-conservation performance. A good combination of data collection and online capacity estimation is found to make significantly more energy savings than traditional approaches (that is, static estimation and scheduled capacity). Our experimental results show that more than 40 percent of energy can be saved for regular daily usage patterns without any prior knowledge of the workload and that long start-up and shutdown delays affect energy savings considerably. Index Terms—Server cluster, Web servers and clients, service-capacity estimation and on-demand resource allocation, cluster resizing and energy savings. Ç...|$|R
50|$|While {{there are}} several {{different}} varieties of virtual queuing systems, a standard First In, First Out that maintains the customer's place in line is set to <b>monitor</b> <b>queue</b> conditions until the Estimated Wait Time (EWT) exceeds a predetermined threshold. When the threshold is exceeded, the system intercepts incoming calls before they enter the queue. It informs customers of their EWT and offers the option of receiving a callback in {{the same amount of}} time as if they waited on hold.|$|R
40|$|We {{show that}} {{production}} rules and persistent queues together provide a convenient mechanism for maintaining consistency in semantically heterogeneous multidatabase environments. We describe a specification language and methods for automatically deriving production rules that maintain (1) existence dependencies, {{in which the}} presence of data in one database implies the presence of related data in another, and (2) value dependencies, in which the value of data in one database {{is based on the}} value of related data in another. The production rules derived from dependency specifications use persistent <b>queues</b> to <b>monitor</b> and maintain the dependencies automatically, asynchronously, incrementally, and correctly. 1 Introduction It is quite common for multiple databases to model overlapping portions of the real world. In such cases it is desirable whenever possible to maintain consistency across databases, i. e. to ensure that they do not contradict each other with respect to the existence or [...] ...|$|R
50|$|If {{customers}} {{choose to}} remain in a queue (also known as que or q for short), their calls are routed directly to the queue. Customers who opt for a callback are prompted to enter their phone number and then hang up the phone. A “virtual placeholder” maintains the customers' position in the queue while the ACD queue is worked off. The virtual <b>queuing</b> system <b>monitors</b> {{the rate at which}} calls in queue are worked off and launches an outbound call to the customer moments before the virtual placeholder is due to reach the top of the queue. When the callback is answered by the customer, the system asks for confirmation that the correct person is on the line and ready to speak with an agent. Upon receiving confirmation, the system routes the call to the next available agent resource, who handles it as a normal inbound call.|$|R
30|$|The airport {{surface is}} {{decomposed}} into blocks and {{represented by the}} graph relation. The state space {{of the system is}} described by identifying all the possible components of the system. The ground and local controls <b>monitor</b> <b>queues</b> of the aircrafts moving from taxiway to take-off. It is insured that once an aircraft is inserted into a queue, it is eventually removed from it after the next queue has become available. The take-off procedure is provided using graph theory and Vienna Development Method Specification Language (VDM-SL) and analyzed using VDM-SL toolbox.|$|R
50|$|On June 21, 2004 Apple {{announced}} Apple Remote Desktop 2 (released in July), {{which was}} designed to use the VNC protocol instead of Apple's original ARD protocol. This allows the ARD administration software to observe and control any computer running VNC-compatible server software (such as Windows and Unix systems) not just Macs and conversely allowing standard VNC viewing software to connect to any Mac with the ARD 2 software installed and VNC access enabled. This version also uses the TCP protocol for most functions (on ports 5900 and 5988), which is designed to be more reliable than the UDP protocol used in ARD 1. Port 3283 may also use UDP protocol. Another significant addition to ARD 2 was the Task List, that allows remote tasks to be <b>queued</b> and <b>monitored,</b> reporting their status (such as Succeeded or Failed). This release also dropped support for older versions of the Mac OS, requiring 10.2.8 or higher.|$|R
40|$|We {{report on}} {{our efforts to}} use the XMC model checker to model and verify the Java metalocking algorithm. XMC [Ramakrishna et al. 1997] is a {{versatile}} and efficient model checker for systems specified in XL, a highly expressive value-passing language. Metalocking [Agesen et al. 1999] is a highly-optimized technique for ensuring mutually exclusive access by threads to object <b>monitor</b> <b>queues</b> and, therefore; plays {{an essential role in}} allowing Java to offer concurrent access to objects. Metalocking {{can be viewed as a}} two-tiered scheme. At the upper level, the metalock level, a thread waits until it can enqueue itself on an object’s <b>monitor</b> <b>queue</b> in a mutually exclusive manner. At the lower level, the monitor-lock level, enqueued threads race to obtain exclusive access to the object. Our abstract XL specification of the metalocking algorithm is fully parameterized, both on the number of threads M, and the number of objects N. It also captures a sophisticated optimization of the basic metalocking algorithm known as extra-fast locking and unlocking of uncontended objects. Using XMC, we show that for a variety of values of M and N, the algorithm indeed provides mutual exclusion and freedom from deadlock and lockout at the metalock level. We also show that, while the monitor-lock level of the protocol preserves mutual exclusion and deadlock-freedom, it is not lockout-free because the protocol’s designers chose to give equal preference to awaiting threads and newly arrived threads...|$|R
40|$|Todays {{scientific}} applications {{have huge}} data requirements which {{continue to increase}} drastically every year. These data are generally accessed by many users from all across the globe. This implies a major necessity to move huge amounts of data around wide area networks to complete the computation cycle, which brings with it the problem of efficient and reliable data placement. The current approach {{to solve this problem}} of data placement is either doing it manually, or employing simple scripts which do not have any automation or fault tolerance capabilities. Our goal is to make data placement activities first class citizens in the Grid just like the computational jobs. They will be <b>queued,</b> scheduled, <b>monitored,</b> managed, and even check-pointed. More importantly, it will be made sure that they complete successfully and without any human interaction. We also believe that data placement jobs should be treated differently from computational jobs, since they may have different semantics and different characteristics. For this purpose, we have developed Stork, a scheduler for data placement activities in the Grid. 1...|$|R
40|$|The HPC 2 N Grid portal is a {{user-centric}} environ-ment {{that provides}} a homogeneous interface {{to a set of}} heterogeneous high-performance computing resources from standard web-browsers. The interface includes support for most everyday activities for a regular user, such as to submit, manipulate and delete jobs, <b>monitor</b> <b>queues</b> and job status, obtain user-, project-, and resource statistics and information, view job output, etc. This contribution reviews the portal functionalities and presents the design and implementation of the underlying system architecture. Some major design considerations, features and limitations are discussed and future extensions are outlined. The portal currently gives access to all major resources at HPC 2 N, in total comprising over 700 CPUs. 1...|$|R
