10000|10000|Public
5|$|An {{optional}} <b>query,</b> {{separated from}} the preceding part by a question mark (?), containing a <b>query</b> string of non-hierarchical data. Its syntax is not well defined, but by convention is most often a sequence of attribute–value pairs separated by a delimiter.|$|E
5|$|The {{right-hand}} {{side of the}} above equation is the sure information, i.e. information which can be certainly extracted from the database regardless of what values are used to replace Nulls in the database. In the example we considered above, it's {{easy to see that}} the intersection of all possible models (i.e. the sure information) of the <b>query</b> selecting WHERE Age = 22 is actually empty because, for instance, the (unlifted) <b>query</b> returns no rows for the relation EmpH37. More generally, it was shown by Imielinski and Lipski that Codd tables are a weak representation system if the <b>query</b> language is restricted to projections, selections (and renaming of columns). However, as soon as we add either joins or unions to the <b>query</b> language, even this weak property is lost, as evidenced in the next section.|$|E
5|$|The {{following}} sample SQL <b>query</b> {{performs a}} left outer join {{on these two}} tables.|$|E
40|$|Abstract. Much of the {{existing}} work on fuzzy <b>queries</b> in relational databases has focused on simple <b>queries,</b> compound <b>queries,</b> multi-relational <b>queries,</b> sub-queries with weights etc. What has received less attention, however, is the fuzzy aggregation <b>querying.</b> In this paper, this kind of fuzzy <b>queries</b> is dealt with. The general forms of fuzzy aggregation <b>queries</b> are presented and the corresponding algorithms are also proposed. Weights are introduced into fuzzy aggregation <b>queries.</b> The calculations of these <b>queries</b> are illustrated by examples in detail...|$|R
40|$|Many <b>queries</b> sent {{to search}} engines refer to {{specific}} {{locations in the}} world. Location-based <b>queries</b> try to find local services and facilities around the user’s environment or in a particular area. This paper reviews the specifications of geospatial <b>queries</b> and discusses {{the similarities and differences}} between location-based <b>queries</b> and other <b>queries.</b> We introduce nine patterns for location-based <b>queries</b> containing either a service name alone or a service name accompanied by a location name. Our survey indicates that at least 22 % of the Web <b>queries</b> have a geospatial dimension and most of these can be considered as location-based <b>queries.</b> We propose that location-based <b>queries</b> should be treated different from general <b>queries</b> to produce more relevant results...|$|R
50|$|Top <b>queries</b> is {{noting the}} most common <b>queries</b> over a fixed amount of time. The top <b>queries</b> list assists in knowing the style of <b>queries</b> entered by users.|$|R
5|$|The key {{difference}} between QA technology and document search is that document search takes a keyword <b>query</b> and returns {{a list of}} documents, ranked in order of relevance to the <b>query</b> (often based on popularity and page ranking), while QA technology takes a question expressed in natural language, seeks to understand it in much greater detail, and returns a precise answer to the question.|$|E
25|$|XQuery (XML <b>Query)</b> is an XML <b>query</b> {{language}} strongly {{rooted in}} XPath and XML Schema. It provides methods to access, manipulate and return XML, and is mainly {{conceived as a}} <b>query</b> language for XML databases.|$|E
25|$|The main mode of {{retrieving}} {{data from}} a SQL Server database is querying for it. The <b>query</b> is expressed using a variant of SQL called T-SQL, a dialect Microsoft SQL Server shares with Sybase SQL Server due to its legacy. The <b>query</b> declaratively specifies {{what is to be}} retrieved. It is processed by the <b>query</b> processor, which figures out the sequence of steps that will be necessary to retrieve the requested data. The sequence of actions necessary to execute a <b>query</b> is called a <b>query</b> plan. There might be multiple ways to process the same <b>query.</b> For example, for a <b>query</b> that contains a join statement and a select statement, executing join on both the tables and then executing select on the results would give the same result as selecting from each table and then executing the join, but result in different execution plans. In such case, SQL Server chooses the plan that is expected to yield the results in the shortest possible time. This is called <b>query</b> optimization and is performed by the <b>query</b> processor itself.|$|E
40|$|This work is {{an initial}} {{study on the}} utility of {{automatically}} generated <b>queries</b> for evaluating known-item retrieval and how such <b>queries</b> compare to real <b>queries.</b> The main advantage of automatically generating <b>queries</b> is that for any given test collection numerous <b>queries</b> can be produced at minimal cost. For evaluation, this has huge ramifications as state-of-the-art algorithms can be tested on different types of generated <b>queries</b> which mimic particular <b>querying</b> styles that a user may adopt. Our approach draws upon previous research in IR which has probabilistically generated simulated <b>queries</b> for other purposes [2, 3]...|$|R
40|$|International audienceWe {{survey results}} about static {{analysis}} of pattern-based <b>queries</b> over XML documents. These <b>queries</b> are analogs of conjunctive <b>queries,</b> their unions and Boolean combinations, in which tree patterns {{play the role}} of atomic formulae. As in the relational case, they can be viewed as both <b>queries</b> and incomplete documents, and thus static analysis problems can also be viewed as finding certain answers of <b>queries</b> over such documents. We look at satisfiability of patterns under schemas, containment of <b>queries</b> for various features of XML used in <b>queries,</b> finding certain answers, and applications of pattern-based <b>queries</b> in reasoning about schema mappings for data exchange...|$|R
40|$|We {{consider}} exact {{learning of}} concepts using {{two types of}} query: extended equivalence <b>queries,</b> and malicious membership <b>queries,</b> that is, membership <b>queries</b> that are permitted to make errors on some arbitrarily chosen set of examples of a bounded cardinality. We present a randomized algorithm to learn ¯-DNF formulas using these <b>queries.</b> The expected running time of the algorithm is polynomial {{in the number of}} variables and the maximum number of strings on which the membership oracle is allowed to make errors. 1 Introduction We continue the investigation begun by Angluin and Krikis [2] concerning the effects of errors in the answers to membership <b>queries</b> in the model of equivalence <b>queries</b> and malicious membership <b>queries.</b> We are interested in the question of whether polynomial-time learnability of a concept class using equivalence <b>queries</b> and (errorfree) membership <b>queries</b> implies polynomial-time learnability in the error model of equivalence <b>queries</b> and malicious membership <b>queries,</b> [...] ...|$|R
25|$|When a {{full text}} <b>query</b> is {{received}} by the SQL Server <b>query</b> processor, it is {{handed over to the}} FTS <b>query</b> processor in the Search process. The FTS <b>query</b> processor breaks up the <b>query</b> into the constituent words, filters out the noise words, and uses an inbuilt thesaurus to find out the linguistic variants for each word. The words are then queried against the inverted index and a rank of their accurateness is computed. The results are returned to the client via the SQL Server process.|$|E
25|$|The generic URL (Uniform Resource Locator) syntax {{allows for}} a <b>query</b> string to be {{appended}} to a file name in a web address so that additional information can be passed to a script; the question mark, or <b>query</b> mark, ?, is used to indicate {{the start of a}} <b>query</b> string. A <b>query</b> string is usually made up of a number of different name–value pairs, each separated by the ampersand symbol, &. For example, http://www.example.com/login.php?username=test=blank.|$|E
25|$|Another {{application}} is in database theory, where a relational {{model of a}} database {{is essentially the same}} thing as a relational structure. It turns out that a conjunctive <b>query</b> on a database can be described by another structure in the same signature as the database model. A homomorphism from the relational model to the structure representing the <b>query</b> is the same thing as a solution to the <b>query.</b> This shows that the conjunctive <b>query</b> problem is also equivalent to the homomorphism problem.|$|E
50|$|Conjunctive <b>queries</b> without {{distinguished}} {{variables are}} called boolean conjunctive <b>queries.</b> Conjunctive <b>queries</b> where all variables are distinguished (and no variables are bound) are called equi-join <b>queries,</b> {{because they are}} the equivalent, in the relational calculus, of the equi-join <b>queries</b> in the relational algebra (when selecting all columns of the result).|$|R
40|$|In {{this paper}} we {{introduce}} {{the notion of}} constrained nearest neighbor <b>queries</b> (CNN) and propose a series of methods to answer them. This class of <b>queries</b> {{can be thought of}} as nearest neighbor <b>queries</b> with range constraints. Although both nearest neighbor and range <b>queries</b> have been analyzed extensively in previous literature, the implications of constrained nearest neighbor <b>queries</b> have not been discussed. Due to their versatility, CNN <b>queries</b> are suitable to a wide range of applications from GIS systems to reverse nearest neighbor <b>queries</b> and multimedia applications...|$|R
30|$|For the EPIC data, {{although}} {{the best performance}} also corresponded to the long <b>queries,</b> a different pattern of behaviour is observed: In general, the medium-length <b>queries</b> outperformed the short <b>queries.</b> This discrepancy with the MAVIR data may rely on the different conditions of each database such as the different number of <b>queries,</b> type of speech, and acoustic conditions. For the I-Text-based STD system, the long-length <b>queries</b> performed slightly better than the short- and medium-length <b>queries,</b> {{probably due to the}} lesser acoustic confusion. For this system, the medium-length <b>queries</b> performed slightly worse than the short-length <b>queries.</b> Although this may be surprising, {{it must be noted that}} some of the short-length <b>queries</b> can contain up to 7 phonemes, and so are not really very short.|$|R
25|$|There is {{also the}} ability to save {{searches}} as a Search Folder where opening the folder will execute a specific search automatically and display the results as a normal folder. A search folder is just an XML file which stores the search <b>query,</b> including the search operators as well. When these files are accessed, the search is run with the saved <b>query</b> string and the results presented as a virtual folder. Windows Vista also supports <b>query</b> composition, where a saved search (called a scope) can be nested within the <b>query</b> string of another search.|$|E
25|$|An {{information}} retrieval process begins when a user enters a <b>query</b> into the system. Queries are formal statements of information needs, for example search strings in web search engines. In {{information retrieval}} a <b>query</b> does not uniquely identify a single {{object in the}} collection. Instead, several objects may match the <b>query,</b> perhaps with different degrees of relevancy.|$|E
25|$|Among {{the leaders}} of the {{organizing}} drive was the stripper Julia <b>Query</b> who documented the efforts on video, resulting in the documentary Live Nude Girls Unite!, written and directed by Vicky Funari and Julia <b>Query.</b>|$|E
40|$|This paper {{compared}} the retrieval {{effectiveness of the}} Google and Yahoo. Both precision and relative recall were considered for evaluating {{the effectiveness of the}} search engines. <b>Queries</b> using concepts in the field of library and information science were tested and were divided into one-word <b>queries,</b> simple multi-word <b>queries</b> and complex multi-word <b>queries.</b> Results of the study showed that the precision of Google was high for simple multi-word <b>queries</b> (0. 97) and Yahoo had comparatively high precision for complex multi-word <b>queries</b> (0. 76). Relative recall of Google was high for simple one-word <b>queries</b> (0. 92) while Yahoo had higher relative recall for complex multi-word <b>queries</b> (0. 61) ...|$|R
40|$|Regular path <b>queries</b> {{are a way}} of declaratively expressing <b>queries</b> on graphs as regular-expression-like {{patterns}} that are matched against paths in the graph. There {{are two kinds of}} queries: existential <b>queries,</b> which specify properties about individual paths, and universal <b>queries,</b> which specify prop-erties about all paths. They provide a simple and conve-nient framework for expressing program analyses as <b>queries</b> on graph representations of programs, for expressing veri-fication (model-checking) problems as <b>queries</b> on transition systems, for <b>querying</b> semi-structured data, etc. Paramet-ric regular path <b>queries</b> extend the patterns with variables, called parameters, which significantly increase the expres-siveness by allowing additional information along single or multiple paths to be captured and related...|$|R
30|$|In {{terms of}} design, we have sought the simplicity. For example, {{although}} OCL {{is a powerful}} language to perform <b>queries</b> over MOF models and meta-models, {{it is not so}} intuitive to manage when we must perform complex <b>queries.</b> That is why our approach uses OCL simple <b>queries</b> and a SQL database to perform complex <b>queries.</b> We argue that people which may maintain the tool will be more familiarized with SQL <b>queries</b> than OCL. It {{is important to note that}} OCL <b>queries</b> are reusable and SQL <b>queries</b> too if the database model is not modified.|$|R
25|$|The {{following}} example <b>query</b> is the snowflake schema {{equivalent of}} the star schema example code which returns {{the total number of}} units sold by brand and by country for 1997. Notice that the snowflake schema <b>query</b> requires many more joins than the star schema version in order to fulfill even a simple <b>query.</b> The benefit of using the snowflake schema in this example is that the storage requirements are lower since the snowflake schema eliminates many duplicate values from the dimensions themselves.|$|E
25|$|The node {{information}} can be augmented with round trip times, or RTT. This information {{will be used to}} choose a time-out specific for every consulted node. When a <b>query</b> times out, another <b>query</b> can be initiated, never surpassing α queries at the same time.|$|E
25|$|The user is also {{provided}} with a link to view the alignment of the <b>query</b> sequence with the genome assembly. The matches between the <b>query</b> and genome assembly are blue and {{the boundaries of the}} alignments are lighter in colour. These exon boundaries indicate splice sites.|$|E
40|$|Temporal logic <b>queries</b> on Datalog and negated Datalog {{programs}} are studied, {{and their relationship}} to Datalog <b>queries</b> on these programs is explored. It is shown that, in general, temporal logic <b>queries</b> have more expressive power than Datalog <b>queries</b> on Datalog and negated Datalog programs. It is also shown that an existential domain-independent fragment of temporal logic <b>queries</b> has the same expressive power as Datalog <b>queries</b> on negated Datalog programs with inflationary semantics. This means that for finite structures this class of <b>queries</b> has the power of the fixpoint logic. ...|$|R
40|$|This paper {{discusses}} {{a framework}} to infer supplemental <b>queries</b> and visualization methods {{in order to}} make the retrieval results into a feasible map using geographic domain hierarchical levels, geographic domain thesauruses and existing example <b>queries.</b> The framework allows users to know mismatches of components in <b>queries,</b> inappropriate <b>queries</b> for maps, and deriving candidates for additional components in <b>queries...</b>|$|R
40|$|Current {{database}} workloads often {{consist of}} a mixture of short online transaction processing (OLTP) <b>queries</b> and large complex <b>queries</b> such as those typical of online analytical processing (OLAP). OLAP <b>queries</b> usually involve multiple joins, arithmetic operations, nested sub-queries, and other system or user-defined functions and they typically operate on large data sets. These resource intensive <b>queries</b> can monopolize the database system resources and negatively impact the performance of smaller, possibly more important, <b>queries.</b> In this thesis, we present an approach to managing the execution of large <b>queries</b> that involves the decomposition of large <b>queries</b> into an equivalent set of smaller <b>queries</b> and then scheduling the smaller <b>queries</b> so that the work is accomplished with less impact on other <b>queries.</b> We describe a prototype implementation of our approach for IBM DB 2 ™ and present a set of experiments {{to evaluate the effectiveness}} of the approach. ii Acknowledgment...|$|R
25|$|Jet {{passes the}} data {{retrieved}} for the <b>query</b> in a dynaset. This {{is a set}} of data that is dynamically linked back to the database. Instead of having the <b>query</b> result stored in a temporary table, where the data cannot be updated directly by the user, the dynaset allows the user to view and update the data contained in the dynaset. Thus, if a university lecturer queries all students who received a distinction in their assignment and finds an error in that student's record, they would only need to update the data in the dynaset, which would automatically update the student's database record without the need for them to send a specific update <b>query</b> after storing the <b>query</b> results in a temporary table.|$|E
25|$|Richard Thomas Snodgrass is an American {{computer}} scientist and writer, currently {{employed as a}} professor at the University of Arizona. He {{is best known for his}} work on temporal databases, <b>query</b> language design, <b>query</b> optimization and evaluation, storage structures, database design, and ergalics (the science of computing).|$|E
25|$|BLAT indexes the genome/protein database, {{retains the}} index in memory, and then scans the <b>query</b> {{sequence}} for matches. BLAST, {{on the other}} hand, builds an index of the <b>query</b> sequences and searches through the database for matches. A BLAST variant called MegaBLAST indexes 4 databases to speed up alignments.|$|E
40|$|This paper {{reports on}} an {{experimental}} {{study on the}} differences between spoken and written <b>queries.</b> A set of written and spontaneous spoken <b>queries</b> are generated by users from written topics. These two sets of <b>queries</b> are compared in qualitative terms {{and in terms of}} their retrieval effectiveness. Written and spoken <b>queries</b> are compared in terms of length, duration, and part of speech. In addition, assuming perfect transcription of the spoken <b>queries,</b> written and spoken <b>queries</b> are compared in terms of their aptitude to describe relevant documents. The retrieval effectiveness of spoken and written <b>queries</b> are compared using three different IR models. The results show that using speech to formulate one’s information need provides a way to express it more naturally and encourages the formulation of longer <b>queries.</b> Despite that, 1 longer spoken <b>queries</b> do not seem to significantly improve retrieval effectiveness compared with written <b>queries.</b> ...|$|R
40|$|Regular path <b>queries</b> {{are a way}} of declaratively expressing <b>queries</b> on graphs as regular-expression-like {{patterns}} that are matched against paths in the graph. There {{are two kinds of}} queries: existential <b>queries,</b> which specify properties about individual paths, and universal <b>queries,</b> which specify properties about all paths. They provide a simple and convenient framework for expressing program analyses as <b>queries</b> on graph representations of programs, for expressing verification (model-checking) problems as <b>queries</b> on transition systems, for <b>querying</b> semi-structured data, etc. Parametric regular path <b>queries</b> extend the patterns with variables, called parameters, which significantly increase the expressiveness by allowing additional information along single or multiple paths to be captured and related. This paper shows how a variety of program analysis and model-checking problems can be expressed easily and succinctly using parametric regular path <b>queries.</b> The paper describes the specification, design, analysis, and implementation of algorithms and data structures for efficiently solving existential and universal parametric regular path <b>queries.</b> Major contributions include the first complete algorithm and data structures for directly and efficiently solving universal parametric regular path <b>queries,</b> detailed complexity analysis of algorithms for solving existential and universal <b>queries,</b> detailed analytical and experimental performance comparison of variations of the algorithms and data structures, and investigation of efficiency tradeoffs between different formulations of <b>queries.</b> 1...|$|R
40|$|Hummingbird {{participated in}} the WebCLEF mixed {{monolingual}} retrieval task of the Cross-Language Evaluation Forum (CLEF) 2006. In this task, the system was given 1939 known-item <b>queries,</b> and {{the goal was to}} find the desired page in the 82 GB EuroGOV collection (3. 4 million pages crawled from government sites of 27 European domains). The 1939 <b>queries</b> included 124 new manually-created <b>queries,</b> 195 manually-created <b>queries</b> from last year, and 1620 automatically-generated <b>queries.</b> In our exper-iments, the results on the automatically-generated <b>queries</b> were not always predictive of the results on the manually-created queries; in particular, our title-weighting and duplicate-filtering techniques were fairly effective on the manually-created <b>queries</b> but were detrimental on the automatically-generated <b>queries...</b>|$|R
