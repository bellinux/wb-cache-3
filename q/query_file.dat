7|178|Public
30|$|UPPAAL (Larsen et al. 1997) is a {{multi-platform}} timed automata model checker {{which is}} used for modeling, simulating and verifying real time systems. Apart from a graphical user interface (Fig. 5) for performing simulation and verification of the model, it also has command line utility, verifyta, for performing verification in a Linux or windows terminal {{with the help of}} a <b>query</b> <b>file.</b> A <b>query</b> <b>file</b> contains the CTL formulas which are required to be checked by the model checker.|$|E
40|$|This support brings {{full and}} proper support for multiallelics. Any {{annotation}} file and field that has Number=A in the header {{can be used}} to correctly annotate a <b>query</b> <b>file</b> with ops=['self']. See: [URL] for more details. v 0. 2. 0 proper support for multi-allelics in query and in annotation with op="self" allow post-annotation to set ID colum...|$|E
40|$|This paper {{describes}} a simulation model {{which is used}} as a tool for designing and evaluating literature searching systems. The simulation program creates a well specified collection of documents and analyzes the effect of changes in <b>query</b> <b>file</b> characteristics on system output performance. First a thesaurus of term relations is generated. Then, employing the thesaurus, routines generate pseudo-documents and pseudo-queries. These pseudo-documents and pseudo-queries are then compared to see the effect of various <b>query</b> <b>file</b> parameter changes on the quantity of material retrieved. Evaluation of the simulation output indicates that there are small differences between the results of the experimental runs. It is concluded that one method for generating pseudo-queries is not deafly better than another. It is believed, however, that the simulation model as an approach to the evaluation of retrieval systems provides a limited but useful framework for the evaluation of information retrieval systems...|$|E
5000|$|... fc-query: <b>Querys</b> font <b>files</b> {{and reports}} {{resulting}} pattern(s).|$|R
5000|$|... {{service can}} be a port number passed as string, such as [...] "80", or a service name, e.g. [...] "echo". In the latter case, gethostbyname (...) is used to <b>query</b> the <b>file</b> /etc/services to resolve the service to a port number.|$|R
40|$|International audienceThis article {{describes}} a new personalization process on decisional queries {{through a new}} approach of triadic association rules mining. This process uses the <b>query</b> log <b>files</b> of users and models them in new way by {{taking into account the}}ir triadic aspect. To validate our approach, we developed a personalization software prototype P-TRIAR (Personalization based on TRIadic Association Rules) which extracts two types of rules from <b>query</b> log <b>files.</b> The first one will serve to query recommendation by taking into account the collaborative aspect of users during their decisional analysis. The second type of rules will enrich user queries. The approach is tested on a real data warehouse to show the compactness of triadic association rules and the refined personalization which we propose...|$|R
30|$|The <b>query</b> <b>file</b> in {{the example}} generates two output files that replace player names using two {{different}} coding approaches. The first uses internally generated random identifier numbers as player identifiers. Doing so relieves the data manager from having to maintain a log relating local suspect identifiers to local suspect names. Note however, that random identifiers are {{not a substitute for}} encrypted names in a federated database because {{there is no guarantee that}} the same suspect will have the same random identifier in the local databases of two or more federation members (see text).|$|E
40|$|Abstract Nowadays, {{with the}} {{development}} of sequencing technologies, more sequencing reads are generated and involved in genomics research, which leads to a critical problem, how do people process these data rapidly and accurately? A data structure named Bloom filter which is initially developed in 1970 has been reused and applied more and more in Bioinformatics field for its relatively high storage efficiency and fast accessing speed. As an application of Bloom filter technique, FACS [1] system is a rapid and accurate sequence classifier. However, several bottlenecks have restricted its usage, for instance, neither supporting large <b>query</b> <b>file</b> nor fastq format files. Hence, in this report, an improved FACS system will be introduced, which includes a hashing system for FACS; making FACS become large query files (> 2 GB) and compressed files supported; making FACS become fastq file supported; making FACS system more user friendly etc. Moreover, the new paralleled FACS system (FACS 2. 0) will be introduced and evaluated to prove that FACS 2. 0 is at least 10 times faster and equally accurate compared with the original FACS system, Fastq_screen [7] and Deconseq [8] when doing sequence decontamination process. Last but not the least, the possibility of developing an adapter trimmer based on FACS system will also be analyzed in this report. Key words: Bloom filter; Decontamination; Adapter trimming; Parallelization; Large <b>query</b> <b>file</b> (compressed and normal) supported...|$|E
40|$|We {{present a}} tool, called sif, for finding all similar files {{in a large}} file system. Files are {{considered}} similar if they have significant number of common pieces, {{even if they are}} very different otherwise. For example, one file may be contained, possibly with some changes, in another file, or a file may be a reorganization of another file. The running time for finding all groups of similar files, even for as little as 25 % similarity, is on the order of 500 MB to 1 GB an hour. The amount of similarity and several other customized parameters can be determined by the user at a post-processing stage, which is very fast. Sif {{can also be used to}} very quickly identify all similar files to a <b>query</b> <b>file</b> using a preprocessed index. Application of sif can be found in file management, information collecting (to remove duplicates), program reuse, file synchronization, data compression, and maybe even plagiarism detection. 1. Introduction Our goal is to identify files that came from the same source [...] ...|$|E
5000|$|... <b>queries</b> {{an online}} <b>file</b> (i.e. database) to {{determine}} the most current versions of the plugin DLLs and AkelPad executable ...|$|R
40|$|Data {{replication}} has {{to reduce}} data file transfer time, bandwidth consumption {{and maintain the}} consistency between the data and replica nodes. The centralized replication that reduces the total data file access delay and caching algorithm is used for any replica server is easily joining and leaving from the main server. An Integrated File Replication and Consistency Maintenance mechanism algorithm is used to achieve high efficiency in data replication and consistency maintenance at a low cost. Each replica server determines data replication and update polling by dynamically adapting to time varying <b>file</b> <b>query</b> and <b>file</b> update rates. Poll reduction process is to avoid unnecessary updates...|$|R
40|$|This paper {{describes}} an effective unsupervised method for query-by-example speaker retrieval. We suppose {{that only one}} speaker is in each audio file or in audio segment. The audio data are modeled using a common universal codebook. The codebook is based on bag-of-frames (BOF). The features corresponding to the audio frames are extracted from all audio files. These features are grouped into clusters using the K-means algorithm. The individual audio files are modeled by the normalized distribution of the numbers of cluster bins corresponding to this file. In the first level the k-nearest to the <b>query</b> <b>files</b> are retrieved using vector space representation. In the second level the second-order statistical measure is applied to obtained k-nearest files to find the final result of the retrieval. The described method is evaluated on the subset of Ester corpus of French broadcast news...|$|R
30|$|In this study, two open {{databases}} {{were used}} to compare accuracy like [13]: the 2006 MIREX QBSH corpus and 2009 MIR-QBSH corpus. These two are {{the most commonly used}} for performance comparisons [26, 27]. They include 48 MIDI files as original music melodies. The 2006 MIREX QBSH corpus was used for the Query by Singing and Humming (QBSH) International Contest (MIREX 2006, 2007 and 2008). There are 2, 797 singing and humming queries, and they are stored in the wave file format. The 2009 MIR-QBSH corpus was used in MIREX 2009. Although the number of MIDI files is the same to that of the 2006 MIREX QBSH corpus, the number of singing and humming queries was increased to 4, 431. Both the 2006 MIREX QBSH corpus and 2009 MIR-QBSH corpus were collected from 118 persons using telephones, microphones, etc. to consider various recording conditions. In the first experiment, the pitch vector (PV) files of the databases were used for performance comparisons. The pitch values in the PV files were manually extracted; they were mainly used for the matching performance excluding the performance of the pitch extractor. The sampling period of pitch values in the PV file was 32 ms, and there were 250 pitch values in each <b>query</b> <b>file</b> since the recording time was 8 s [13, 14, 17].|$|E
50|$|SQL and {{databases}} support (live {{database schema}} refactoring, generation of schema migration scripts, export <b>query</b> result to <b>file</b> or clipboard, editing of stored procedures, etc.).|$|R
50|$|File systems {{supported}} by the software include NTFS, FAT16, FAT32, Ext2, Ext3, ReiserFS, Reiser4 and other. This variety is achieved {{through the use of}} disk imaging module which allows performing sector-based backup which does not <b>query</b> the <b>file</b> system. Though this feature is not primarily designed for hard disk cloning, it can also be used for this purpose.|$|R
40|$|Abstract—We propose in {{this paper}} an {{interactive}} query recommendation system, namely FIMIOQR. It {{is designed to help}} OLAP (On-line Analytical Processing) users in their decision query writing task based on both a set of selected measures and decision <b>queries</b> log <b>file.</b> Our FIMIOQR system is designed to discover associations from decision <b>queries</b> log <b>file.</b> For this end, we use association rules method to extract frequent itemsets from dimensions attributes according to user selected set of measures. This allows end users in OLAP systems to write relevant queries guided by an interactive recommending system and helps them to meet their analysis objectives. In addition, we propose a tool for the automatic implementation of FIMIOQR which provides a visual interface to OLAP users which helps them to write their queries step by step in an interactive way. We also carried out some experimental tests to evaluate our system. The experimental evaluation proves our FIMIOQR framework is efficient in term of recommendation quality. Index Terms—Interactive Recommendation; Data warehouse...|$|R
30|$|Both {{models are}} {{obtained}} using text-to-model transformations. The {{source of the}} structure model is a database schema extracted from the database. While {{the source of the}} workload model is existing or newly created database workload data (e.g., <b>query</b> log <b>files).</b> The metamodels they conform to are common in model-based software modernisation approaches (e.g., [4 – 6]), which ensures the interoperability of the models generated by our method with future technologies.|$|R
40|$|A {{preliminary}} study {{was performed by}} Tomkins comparing 40, 000 chimpanzee genomic sequences against the human genome which indicated that reported levels of human-chimp DNA similarity were significantly lower than commonly reported. The present, follow-up study was then completed in which chimp chromosomes were sliced into new individual <b>query</b> <b>files</b> of varying string lengths and queried against their human chromosome homolog. This allowed for comparisons to be optimized irrespective of the linear order of genes and sequence features. The definition of similarity was the amount (percent) of optimally aligned chimp DNA. For the chimp autosomes, the amount of optimally aligned DNA sequence provided similarities between 66 and 76 percent, depending on the chromosome. Only 69 percent of the chimpanzee X chromosome was similar to human and only 43 percent of the Y chromosome. Genome-wide, only 70 % of the chimpanzee DNA was similar to human under the most optimal alignment conditions. While, chimpanzees and humans share many localized protein-coding regions of high similarity, the overall extreme discontinuity between the two genomes defies evolutionary timescales and dogmatic presuppositions about a common ancestor...|$|R
50|$|Includes {{embedded}} utilities: A PC Audit {{tool that}} performs a basic {{analysis of a}} client PC; Windows Firewall auditor; Encryption software; an Active Directory query tool; an Event Log <b>query</b> tool; a <b>file</b> hasher; SID resolver; Orphaned SID locator; and Ping.|$|R
50|$|The user {{specifies}} {{the items}} that they are looking for, and the database in which to search. After running, the <b>query</b> creates a <b>file</b> in Portable Game Notation (PGN) format that contains all the games or positions matching the query criteria.|$|R
40|$|Abstract. Euler {{diagrams}} {{have been}} used for centuries as a means for conveying logical statements in a simple, intuitive way. They form the basis of many diagrammatic notations used to represent set-theoretic relationships {{in a wide range of}} contexts including software modelling, logical reasoning systems, statistical data representation, database search <b>queries</b> and <b>file</b> system management. In this paper we survey notations based on Euler diagrams with particular emphasis on formalization and the development of software tool support...|$|R
40|$|As storage systems {{reach the}} {{petabyte}} scale, {{it has become}} increasingly difficult for users and storage administrators to understand and manage their data. File metadata, such as inode and extended attributes are a valuable source of information that can aid in locating and identifying files, and can also facilitate administrative tasks, such as storage provisioning and recovery from backups. Unfortunately, most storage systems have no way to quickly and easily search file metadata at large scale. To address these issues, we developed Spyglass, a indexing system that efficiently gathers, indexes and <b>queries</b> <b>file</b> metadata in large-scale storage systems. Our analysis of file metadata from real-world workloads showed that metadata has spatial locality in the storage namespace and that the distribution of metadata is highly skewed. Based on these findings, we designed Spyglass to use index partitioning and signature files to quickly prune the file search space. We also developed techniques to efficiently handle index versioning, facilitating both fast update and queries across historical indexes. Experiments on systems with up to 300 million files show that the Spyglass prototype is as much as several thousand times faster than current database solutions while requiring {{only a fraction of the}} space. ...|$|R
5000|$|Includes {{embedded}} utilities: A PC Audit {{tool that}} performs a basic {{analysis of a}} client PC; Encryption software; Windows Firewall auditor; an Active Directory query tool; an Event Log <b>query</b> tool; Ping; <b>File</b> hashing tool; SID resolver; and an Orphaned SID locator.|$|R
40|$|Euler {{diagrams}} {{have been}} used for centuries as a means for conveying logical statements in a simple, intuitive way. They form the basis of many diagrammatic notations used to represent set-theoretic relationships {{in a wide range of}} contexts including software modelling, logical reasoning systems, statistical data representation, database search <b>queries</b> and <b>file</b> system management. In this paper we consider some notations based on Euler diagrams, in particular Spider Diagrams and Constraint Diagrams, with particular emphasis on the development of reasoning systems...|$|R
50|$|The BSEE {{maintains}} a database containing public information on various topics including leasing information, pipelines, permitting, platform/rig and production information; and statistics. Data {{is available in}} the form of online <b>queries,</b> PDFs, ASCII <b>files</b> and scanned documents. Information may be cross-referenced among different subject headings.|$|R
40|$|Abstract Background The {{increasing}} {{complexity of}} genomic data presents several challenges for biologists. Limited computer monitor views of data complexity and the dynamic nature of {{data in the}} midst of discovery increase the challenge of integrating experimental results with information resources. The use of Gene Ontology enables researchers to summarize results of quantitative analyses in this framework, but the limitations of typical browser presentation restrict data access. Results Here we describe extensions to the treemap design to visualize and query genome data. Treemaps are a space-filling visualization technique for hierarchical structures that show attributes of leaf nodes by size and color-coding. Treemaps enable users to rapidly compare sizes of nodes and sub-trees, and we use Gene Ontology categories, levels of RNA, and other quantitative attributes of DNA microarray experiments as examples. Our implementation of treemaps, Treemap 4. 0, allows user-defined filtering to focus on the data of greatest interest, and these <b>queried</b> <b>files</b> can be exported for secondary analyses. Links to model system web pages from Treemap 4. 0 enable users access to details about specific genes without leaving the query platform. Conclusions Treemaps allow users to view and query the data from an experiment on a single computer monitor screen. Treemap 4. 0 can be used to visualize various genome data, and is particularly useful for revealing patterns and details within complex data sets. </p...|$|R
40|$|Several times {{one came}} across a {{situation}} where efficient searching on XML files needs to be performed. This paper presents an algorithm for retrieval of XML data by querying the various XML nodes in various files. The files can be located at different places {{and some of them}} are on liver server. This algorithm <b>queries</b> the <b>files</b> from various locations and based on the matching result it retrieves whole record and organized the information into proper format. It also shows the name of file from which the data are received so that one can get the exact information for the result and file...|$|R
50|$|The WebDAV {{protocol}} {{provides a}} framework for users to create, change and move documents on a server, typically a web server or web share. The most important features of the WebDAV protocol include the maintenance of properties about an author or modification date, namespace management, collections, and overwrite protection. Maintenance of properties includes {{such things as the}} creation, removal, and <b>querying</b> of <b>file</b> information. Namespace management deals with the ability to copy and move web pages within a server’s namespace. Collections deal with the creation, removal, and listing of various resources. Lastly, overwrite protection handles aspects related to locking of files.|$|R
50|$|Answer/2 was {{a product}} {{released}} in 1979 that was billed as a moderately priced report writer for files on IBM mainframe operating systems.It was followed by Answer/DB, a product introduced in 1981, that allowed end users at terminals to make <b>queries</b> against various <b>files</b> and IMS databases on the same IBM mainframe operating systems.|$|R
40|$|In this paper, we {{characterize}} the user {{behavior in a}} peer-to-peer (P 2 P) file sharing network. Our characterization {{is based on the}} results of an extensive passive measurement study of the messages exchanged in the Gnutella P 2 P file sharing system. Using the data recorded during this measurement study, we analyze which queries a user issues and which files a user shares. The investigation of users queries leads to the characterization of query popularity. Furthermore, the analysis of the files shared by the users leads to a characterization of file replication. As major contribution, we relate <b>query</b> popularity and <b>file</b> replication by an analytical formula characterizing the matching of <b>files</b> to <b>queries.</b> The analytical formula defines a matching probability for each pair of <b>query</b> and <b>file,</b> which depends on the rank of the query with respect to query popularity, but is independent of the rank of the file with respect to file replication. We validate this model by conducting a detailed simulation study of a Gnutella-style overlay network and comparing simulation results to the results obtained from the measurement. Keywords: Traffic measurement and characterization, characterization of user behavior, peer-to-peer systems...|$|R
3000|$|... are not indicated, {{while the}} dashed edges {{connecting}} the query node {{to the rest}} of the network are added at query time. If the text or sound <b>file</b> <b>query</b> is already in the database, then the query node will be connected through the node representing it in the network by a single link of weight zero (meaning equivalence).|$|R
40|$|International audienceENDscript is a {{web server}} {{grouping}} popular {{programs such as}} BLAST, Multalin and DSSP. It uses as <b>query</b> the co-ordinates <b>file</b> of a protein in Protein Data Bank format and generates PostScript and png figures showing: residues conserved after a multiple alignment against homologous sequences, secondary structure elements, accessibility, hydropathy and intermolecular contacts. Thus, the user can relate quickly 1 D, 2 D and 3 D information of a protein of known structure. AVAILABILITY: [URL] is a web server grouping popular programs such as BLAST, Multalin and DSSP. It uses as <b>query</b> the co-ordinates <b>file</b> of a protein in Protein Data Bank format and generates PostScript and png figures showing: residues conserved after a multiple alignment against homologous sequences, secondary structure elements, accessibility, hydropathy and intermolecular contacts. Thus, the user can relate quickly 1 D, 2 D and 3 D information of a protein of known structure. AVAILABILITY: [URL]...|$|R
40|$|This paper {{presents}} an efficient approach for improving file availability in super-peer-based peer-to-peer (P 2 P) file-sharing systems. In the super-peer-based P 2 P file-sharing system, peers are organized into multiple groups. In each group, {{there is a}} special peer called super-peer to serve the regular peers within the same group. With this property, the proposed approach utilizes the super-peer to tolerate the departure (failure) of a regular peer in order to protect shared files. Unlike traditional replication-based approaches, the proposed approach keeps track of the <b>file</b> <b>queries</b> in the super-peer to support fault tolerance. The cost of tracking the <b>file</b> <b>queries</b> is much smaller than the cost of replicating the file contents in advance. Furthermore, the proposed approach uses a logical connection technique to consider the departure (failure) of the super-peer. Finally, simulation experiments are performed to quantify the performance and overhead of the proposed approach...|$|R
40|$|With {{the current}} {{increase}} {{of interest in}} cloud computing, the security of user data stored in remote servers has become an important concern. Hiding access patterns of clients can be crucial in particular applications such as stock market or patent databases. Private Information Retrieval (PIR) is proposed to enable a client to retrieve a file stored in a cloud server without revealing the <b>queried</b> <b>file</b> to the server. In this work, we offer improvements to BddCpir, which is a PIR protocol proposed by Lipmaa. The original BddCpir uses Binary Decision Diagrams (BDD) as the data structure, where data items are stored at the sink nodes of the tree. First of all, we offer the usage of quadratic and octal trees instead, where every non-sink node has four and eight child nodes, respectively, to reduce {{the depth of the}} tree. By adopting more shallow trees, we obtain an improved server implementation which is an order of magnitude faster than the original scheme, without changing the asymptotic complexity. Secondly, we suggest a non-trivial parallelization method that takes advantage of the shared-memory multi-core architectures to further decrease server computation latencies. Finally, we show how to scale the PIR scheme for larger database sizes with only a small overhead in bandwidth complexity, with the utilization of shared-memory many-core processors. Consequently, we show how our scheme is bandwidth-efficient in terms of the data being exchanged in a run of the CPIR protocol, in proportion to the database size...|$|R
40|$|The Miracle-FI {{participation}} at ImageCLEF 2009 photo retrieval task {{main goal}} was to improve the merge of content-based and text-based techniques in our experiments. The global system includes our own implemented tool IDRA (InDexing and Retrieving Automatically), and the Valencia University CBIR system. Analyzing both “topics_part 1. txt ” and “topics_part 2. txt ” task topics files, we have built different <b>queries</b> <b>files,</b> eliminating the negative sentences with the text from title and clusterTitle or clusterDescription, one query for each cluster (or not) of each topic from 1 to 25 and {{one for each of}} the three images of each topic from 26 to 50. In the CBIR system the number of low-level features has been increased from the 68 component used at ImageCLEF 2008 up to 114 components, and in this edition only the Mahalanobis distance has been used in our experiments. Three different merging algorithms were developed in order to fuse together different results lists from visual or textual modules, different textual indexations, or cluster level results into a unique topic level results list. For the five runs submitted we observe that MirFI 1, MirFI 2 and MifFI 3 obtain quite higher precision values than the average ones. Experiment MirFI 1, our best run for precision metrics (very similar to MirFI 2 and MirFI 3), appears in the 16 th position in R-Precision classification and in the 19 th in MAP one (from a total of 84 submitted experiments). MirFI 4 and MirFI...|$|R
40|$|We present Polonium, a novel Symantec {{technology}} that detects malware through large-scale graph inference. Based on the scalable Belief Propagation algorithm, Polonium infers every file’s reputation, flagging files with low reputation as malware. We evaluated Polonium with a billion-node graph constructed from the largest file submissions dataset ever published (60 terabytes). Polonium attained a high true positive rate of 87 % in detecting malware; in the field, Polonium lifted the detection rate of existing methods by 10 absolute percentage points. We detail Polonium’s {{design and implementation}} features instrumental to its success. Polonium has served 120 million people and helped answer more than one trillion <b>queries</b> for <b>file</b> reputation...|$|R
