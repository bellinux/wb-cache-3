28|347|Public
5000|$|... apt-config is the APT Configuration <b>Query</b> <b>program.</b> [...] {{shows the}} configuration.|$|E
5000|$|Based on its findings, {{the court}} issued a {{preliminary}} injunction against BE from [...] "using any automated <b>query</b> <b>program,</b> robot, or similar device to access eBay's computer systems or networks {{for the purpose}} of copying any part of eBay's auction database." ...|$|E
50|$|JumpStation (created in December 1993 by Jonathon Fletcher) used a web robot to find {{web pages}} {{and to build}} its index, and used a web form as the {{interface}} to its <b>query</b> <b>program.</b> It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered.|$|E
40|$|In this paper, we {{describe}} how database instructors can teach Relational Algebra and Structured Query Language together through <b>programming.</b> Students write <b>query</b> <b>programs</b> consisting of sequences of Relational Algebra operations vs. Structured Query Language SELECT statements. The <b>query</b> <b>programs</b> {{can then be}} run interactively, allowing students to compare the results of Relational Algebra and equivalent Structured Query Language commands. In this way, students better understand both Relational Algebra and Structured Query Language—by writing code and watching it run...|$|R
50|$|<b>Program</b> Trace <b>Query</b> Language (PTQL) is a {{language}} based on relational <b>queries</b> over <b>program</b> traces, in which programmers can write expressive, declarative <b>queries</b> about <b>program</b> behavior.|$|R
40|$|<b>Program</b> <b>queries</b> {{can answer}} {{important}} software engineering questions {{that range from}} “which expressions are cast to this type?” over “does my program attempt to read from a closed file? ” to “does my code follow the prescribed design?”. In this paper, we present a comprehensive tool suite for <b>querying</b> Java <b>programs.</b> It consists of the logic <b>program</b> <b>query</b> language SOUL, the CAVA library of predicates for quantifying over an Eclipse workspace and the Eclipse plugin BARISTA for launching queries and inspecting their results. BARISTA allows other Eclipse plugins to peruse <b>program</b> <b>query</b> results which is facilitated by the symbiosis of SOUL with Java – setting SOUL apart from other <b>program</b> <b>query</b> languages. This symbiosis enables the CAVA library to forego the predominant transcription to logic facts of the <b>queried</b> <b>program.</b> Instead, the library queries the actual AST nodes used by Eclipse itself, making it trivial for any Eclipse plugin to find the AST nodes that correspond to a query result. Moreover, such plugins {{do not have to}} worry about having <b>queried</b> stale <b>program</b> information. We illustrate the extensibility of our suite by implementing a tool for co-evolving source code and annotations using <b>program</b> <b>queries...</b>|$|R
40|$|Changes in {{requirements}} for database systems necessitate schema restructuring, database translation, and application or <b>query</b> <b>program</b> conversion. An {{alternative to the}} lengthy manual revision process is proposed by offering a set of 15 transformations keyed to the relational model of data and the relational algebra. Motivations, examples, and detailed descriptions are provided...|$|E
40|$|We {{solve the}} problem of obtaining answers to queries posed to a {{mediated}} integration system under the local-as-view paradigm that are consistent wrt to certain global integrity constraints. For this, the <b>query</b> <b>program</b> is combined with logic programming specifications under the stable model semantics of the class of minimal global instances, and o...|$|E
40|$|A partial test oracle is {{proposed}} {{to verify the}} actual outputs in access testing on XML data. The considered software under test is a <b>query</b> <b>program</b> which receives as input an XML document obtained from an XML repository of any kind, and produces XML data as output. To deal with the actual outputs from this testing process, the partial oracle evaluates the correctness of the test executions according to: (1) a loose specification provided by the tester, and (2) a set of predefined constraints that describe invariant properties of the expected outputs. By means of the loose specification, the oracle can particularize the constraints to the concrete behaviour of the <b>query</b> <b>program</b> to test. This approach enables the oracle to give automatically a response about the correctness of the program under test with a certain precision at feasible cost. To illustrate {{the usefulness of the}} approach a case study is presented. 1...|$|E
40|$|Static Program Analyzers (SPA) are {{interactive}} {{tools that}} enhance program understanding during maintenance by answering <b>queries</b> about <b>programs.</b> Depending on the maintenance task in hand, SPAs must process different source programs and answer {{different types of}} <b>program</b> <b>queries.</b> Flexibility is, therefore, a desirable property of SPAs. In this paper, we describe a <b>program</b> <b>query</b> language, called PQL, that facilitates the design of flexible SPAs. PQL is a conceptual level, source language-independent notation to specify <b>program</b> <b>queries</b> and <b>program</b> views. In PQL, we can <b>query</b> global <b>program</b> design as well as search for detail code patterns. PQL queries are answered automatically by a query evaluation mechanism built into an SPA. Program design models and PQL form the core of an SPA conceptual model. We based the SPA's architecture on this conceptual model. By separating the conceptual model from the implementation decisions, we can design SPAs that are customizable {{to the needs of}} the mainte [...] ...|$|R
40|$|Widely {{available}} and implemented database <b>query</b> and <b>programming</b> languages are first-order today. I User-defined functions merely are units of <b>query</b> and <b>program</b> organization I User-defined functions {{are not considered}} first-class values 2 / 25 Wait! There is XQuery 3. 0 I XQuery 3. 0 takes a major step towards a full-fledged functional languag...|$|R
40|$|Logic-based {{programming}} {{languages are}} increasingly applied as <b>program</b> <b>query</b> languages which allow developers to reason {{about the structure}} and behaviour of programs. To achieve this, the <b>queried</b> <b>programs</b> are reified as logic values such that logic quantification and unification can be used effectively. However, in many cases, standard logic unification is inappropriate for program entities, forcing developers to resort to overly complex queries. In this paper, we argue that such incidental complexity can be reduced significantly by customizing the unification algorithm. We present a practical implementation approach through inter-language reflection and open unification. These techniques are {{at the core of}} the logic <b>program</b> <b>query</b> language SOUL, through which we demonstrate custom unification schemes for reasoning over Smalltalk and Java <b>programs.</b> <b>Queries</b> written in this tailored version of SOUL can exploit advanced program matching strategies without increasing the incidental complexity of the queries. 1...|$|R
40|$|We present {{functional}} database query languages expressing the FO- and PTIME-queries. This framework is a functional analogue of the logical languages of first-order and fixpoint formulas over finite structures, and its formulas consist of: atomic constants of order 0, equality among these constants, variables, application, lambda and let abstraction; all typable in 4 functionality order. In this framework, proposed in [25] for arbitrary functionality order, typed lambda terms {{are used for}} input-output databases and for <b>query</b> <b>program</b> syntax, and reduction is used for <b>query</b> <b>program</b> semantics. We define two families of languages: TLI = i or simply-typed list iteration of order i + 3 with equality and MLI = i or ML-typed list iteration of order i + 3 with equality; we use i + 3 since our list representation of input-output databases requires at least order 3. We show that, over list-represented databases, both TLI = 0 and MLI = 0 exactly express the FO-queries and both TLI = 1 and [...] ...|$|E
40|$|In this section, we show {{a number}} of ideas for using the Web query {{language}} Xcerpt for querying terms and their relations defined in the GeneOntology. Xcerpt is a novel versatile Web query language that provides ample support for querying Web data heterogeneous in structuring and even with regard to representation format used. Xcerpt supports querying of both XML and RDF data, as well as intertwined access to data in these formats. Xcerpt, a versatile Web query language. Xcerpt [9, 8, 15, 2], cf. [URL] org, is a query language designed after principles given in [7] for querying both data on the “standard Web ” (e. g., XML and HTML data) and data on the Semantic Web (e. g., RDF, Topic Maps, etc. data). Xcerpt is “data versatile”, i. e. a same Xcerpt query can access and generate, as answers, data in different Web formats. Xcerpt is “strongly answer-closed”, i. e. it not only gives rise to construct answers in the same data formats as the data queries like, e. g., XQuery [10], but also to further processing in a <b>query</b> <b>program</b> data generated by this same <b>query</b> <b>program.</b> Xcerpt’s queries are pattern-based and give rise to incompletel...|$|E
40|$|Consistent {{answers from}} a {{relational}} database that violates a given set of integrity constraints are ordinary answers {{that can be}} obtained from every repaired version of the database. The database repairs can be specified and interpreted as the stable models of a simple disjunctive normal logic program with database predicates extended with appropriate annotation arguments. The programs can be constructed for any finite set of universal integrity constraints. Programs for referential integrity constraints can also be produced. In consequence, consistent query answers {{can be obtained from}} the repair program combined with an appropriate <b>query</b> <b>program</b> under the cautious or skeptical stable model semantics...|$|E
30|$|In {{addition}} to the <b>query</b> <b>programming</b> interface, all built-in analytics and primary queries can also be accessed from a graphical query interface, which accepts user query specifications via web forms and translates such specifications into SQL statements. The main purpose of designing a graphical interface is to, again, ease the use of DCMS to an extent that users can perform data analysis without writing programs.|$|R
40|$|As {{a greater}} number of {{software}} developers make their source code available, {{there is a need to}} store such open-source applications in a library and facilitate searching over this digital library. To achieve this, we propose the usage of agents in indexing and <b>querying</b> <b>program</b> source code. This paper describes agent roles in building index files for Java <b>programs</b> and users’ <b>queries</b> based on <b>program</b> structure and design patterns. Precision and recall analysis is then undertaken to evaluate the retrieval performance. We believe that such a digital library will permit better sharing of experience amongst developers and facilitate reuse of code segment...|$|R
40|$|We {{propose a}} {{framework}} for modeling uncertainty where both belief and doubt can be given independent, first-class status. We adopt probability theory as the mathematical formalism for manipulating uncertainty. An agent can express the uncertainty in her knowledge about a piece of information {{in the form of}} a confidence level, consisting of a pair of intervals of probability, one for each of her belief and doubt. The space of confidence levels naturally leads to the notion of a trilattice, similar in spirit to Fitting's bilattices. Intuitively, the points in such a trilattice can be ordered according to truth, information, or precision. We develop {{a framework for}} probabilistic deductive databases by associating confidence levels with the facts and rules of a classical deductive database. While the trilattice structure offers a variety of choices for defining the semantics of probabilistic deductive databases, our choice of semantics is based on the truth-ordering, which we find to be closest to the classical framework for deductive databases. In addition to proposing a declarative semantics based on valuations and an equivalent semantics based on fixpoint theory, we also propose a proof procedure and prove it sound and complete. We show that while classical Datalog <b>query</b> <b>programs</b> have a polynomial time data complexity, certain <b>query</b> <b>programs</b> in the probabilistic deductive database framework do not even terminate on some input databases. We identify a large natural class of <b>query</b> <b>programs</b> of practical interest in our framework, and show that programs in this class possess polynomial time data complexity, i. e. not only do they terminate on every input database, they are guaranteed to do so in a number of steps polynomial in the input database size...|$|R
40|$|The paper {{presents}} {{an approach to}} recursive query optimization based upon the integration of partial evaluation and already existing rule transformation based, optimization methods such as Magic Set, Minimagic and Counting. The basic idea is to partially evaluate a logic program {{with respect to a}} query (goal), thus eliminating unnecessary intermediate (IDB) predicates and then further optimize the program, with respect to evaluation, by using one of the mentioned optimization methods. The advantage of the proposal is twofold: on one hand to give the user freedom of using all the power of a logical language to define the <b>query</b> <b>program</b> and, on the other, to keep efficiency into reasonable range...|$|E
40|$|Consistent {{answers from}} a {{relational}} database that violates a given set of integrity constraints (ICs) are characterized as ordinary answers {{that can be}} obtained from every minimally repaired version of the database (a repair). Repairs can be specified and interpreted as the stable models of a simple disjunctive normal logic program with database predicates extended with appropriate annotation arguments. In consequence, consistent query answers can be obtained by running a <b>query</b> <b>program</b> in combination with the repair program under the cautious or skeptical stable model semantics. In this paper we show how to write repair programs for universal and referential ICs; we establish their correctness and show how to run them on top of the DLV system...|$|E
40|$|The {{proposal}} {{selection process}} for the Hubble Space Telescope is assisted by a robust {{and easy to use}} <b>query</b> <b>program</b> (TACOS). The system parses an English subset language sentence regardless of the order of the keyword phases, allowing the user a greater flexibility than a standard command query language. Capabilities for macro and procedure definition are also integrated. The system was designed for flexibility in both use and maintenance. In addition, TACOS can be applied to any knowledge domain that can be expressed in terms of a single reaction. The system was implemented mostly in Common LISP. The TACOS design is described in detail, with particular attention given to the implementation methods of sentence processing...|$|E
40|$|Abstract—Static Program Analyzers (SPA) are {{interactive}} {{tools that}} enhance program understanding during maintenance by answering <b>queries</b> about <b>programs.</b> Depending on the maintenance task in hand, SPAs must process different source programs and answer {{different types of}} <b>program</b> <b>queries.</b> Flexibility is, therefore, a desirable property of SPAs. In this paper, we describe a <b>program</b> <b>query</b> language, called PQL, that facilitates the design of flexible SPAs. PQL is a conceptual level, source language-independent notation to specify <b>program</b> <b>queries</b> and <b>program</b> views. In PQL, we can <b>query</b> global <b>program</b> design as well as search for detail code patterns. PQL queries are answered automatically by a query evaluation mechanism built into an SPA. Program design models and PQL form the core of an SPA conceptual model. We based the SPA’s architecture on this conceptual model. By separating the conceptual model from the implementation decisions, we can design SPAs that are customizable {{to the needs of}} the maintenance project at hand. Depending on criteria such as efficiency of query evaluation or simplicity of the SPA design, we can implement the same functional specifications of an SPA on a variety of program representations to meet the required criteria. Apart from its role in the design of SPAs, the conceptual model also allows us to rigorously study SPA functionality in the context of the underlying maintenance process and programmer behavior models, in isolation from tool implementation detail...|$|R
40|$|Static program analyzers are {{tools that}} enhance program {{understanding}} during maintenance by answering <b>queries</b> about <b>programs.</b> A number of <b>program</b> <b>query</b> languages have been proposed. The design of some static program analyzers {{has been based}} on these languages. However, few of these <b>program</b> <b>query</b> languages have a formal foundation. As a result, the interpretations of many <b>program</b> <b>queries</b> tend to be ambiguous, which often lead to an ambiguous design of static program analyzers. On the other hand, formal semantics of programming language are well studied, however, the traditional semantic models are unstructured and are difficult to reuse to provide a formal design for program analyzers. In this paper, we present an object-oriented model of the static semantics for a COBOL language subset. Based on this highly structured semantic model, a design of a static program analyzer including the models of <b>program</b> <b>queries</b> are formally presented. 1. Introduction It is commonly known that a high pe [...] ...|$|R
40|$|The <b>query</b> <b>programs</b> {{of certain}} {{databases}} report raw statistics for query sets, which are groups of records specified implicitly by a characteristic formula. The raw statistics include query set size and sums of powers of {{values in the}} query set. Many users and designers believe that the individual records will remain confidential as long as <b>query</b> <b>programs</b> refuse to report the statistics of query sets which are too small. It is shown that the compromise of small query sets can in fact almost always be accomplished {{with the help of}} characteristic formulas called trackers. Schlorer’s individual tracker is reviewed, it is derived from known characteristics of a given individual and permits deducing additional characteristics he may have. The general tracker is introduced: It permits calculating statistics for arbitrary query sets, without requiring preknowledge of anything in the database. General trackers always exist if there are enough distinguishable classes of individuals in the database, in which case the trackers have a simple form. Almost all databases have a general tracker, and general trackers are almost always easy to find. Security is not guaranteed by the lack of a general tracker...|$|R
40|$|This paper {{presents}} {{the application of}} a connectionist network to optimize symbolic proofs. By symbolic proofs we understand proofs in first order logic. Prolog interpreters are an implementation of theorem provers for special first order formulas, called horn clauses, based on the resolution principle [Robinson 65]. The usage of Prolog interpreters for symbolic proofs implies a certain proof strategy: first, selection of the leftmost partial goal in the resolvent as goal to be solved and second, selection of the clauses in written order for the resolution of the selected partial goal. In case of failure of a partial goal, the interpreter backtracks systematically to the last choice made without analyzing the cause of failure. Even for simple programs, this implicit control strategy is not sufficient to obtain efficient computations [Naish 84]. Explicit control by using control constructs like cut is, however, contradictory to Prolog as a declarative programming language. The need for the distinction of logic and control has therefore long been recognized [Kowalski 75]. We describe an approach to learn and store control knowledge in a connectionist network. The system utilizes a three-layer backpropagation network. A meta-interpreter generates training patterns encoding successful Prolog proofs. Trained with these examples of proofs the network generalizes a control strategy to select clauses. Another metainterpreter uses the network to compute optimized proofs. 2. TRAINING THE SYSTEM Fig. 1 a shows the generation of the training data. A generating metainterpreter (GMI) containing the Prolog program is asked to prove a goal. PROLOG GMI database Backpropagation NETWORK encoder & decoder <b>query</b> <b>program</b> answer PROLOG OMI database Backpropagation NETWORK <b>query</b> <b>program</b> answer [...] ...|$|E
40|$|Abstract. We {{address the}} problem of {{retrieving}} certain and consistent answers to queries posed to a mediated data integration system under the local-as-view paradigm with open sources and conjunctive and disjunctive view definitions. For obtaining certain answers a <b>query</b> <b>program</b> is run under the cautious stable model semantics on top of a normal deductive database with choice operator that specifies the class of minimal legal instances of the integration system. This methodology works for all monotone Datalog queries. To compute answers to queries that are consistent wrt given global integrity constraints,the specification of minimal legal instances is combined with another disjunctive deductive database that specifies the repairs of those legal instances. This allows to retrieve the answers to any Datalog ¬ query that are consistent wrt global universal and referential integrity constraints. ...|$|E
40|$|Core-ML is a {{basic subset}} of most {{functional}} programming languages. It consists of the simply typed (or monomorphic) -calculus, simply typed equality over atomic constants, and let as the only polymorphic construct. We present a synthesis of recent results which characterize this "toy" language's expressive power {{as well as its}} type reconstruction (or type inference) problem. More specifically: (1) Core-ML can express exactly the ELEMENTARY queries, where a program input is a database encoded as a -term and a <b>query</b> <b>program</b> is a -term whose application to the input normalizes to the output database. In addition, it is possible to express all the PTIME queries so that this normalization process is polynomial in the input size. (2) The polymorphism of let can be explained using a simple algorithmic reduction to monomorphism, and provides flexibility, without affecting expressibility. Algorithms for type reconstruction offer the additional convenience of static typing without type decla [...] ...|$|E
40|$|In this paper, we {{describe}} a custom Relational Algebra Query software environment that enables database instructors to teach relational algebra programming. Instead of defining query operations using mathematical notation (the approach commonly taken in database textbooks), students write <b>query</b> <b>programs</b> as sequences of relational algebra function calls. The {{data to be}} queried can be in any Microsoft Access MDB file. The query processor software executes relational algebra in-structions interactively, allowing students to view intermediate result tables. Thus, students can learn relational algebra {{the same way they}} learn SQL [...] through programming...|$|R
40|$|We {{present a}} tool that helps C/C++ {{developers}} to estimate the effort and automate software porting. Our tool supports project leaders in planning a porting project by showing where a project must be changed, how many changes are needed, what kinds of changes are needed, and how these interact with the code. For developers, we {{provide an overview of}} where a given file must be changed, the structure of that file, and close interaction with typical code editors. To this end, we integrate code <b>querying,</b> <b>program</b> transformation, and software visualization techniques. We illustrate our solution with use-cases on real-world code bases. ...|$|R
40|$|In this paper, we {{describe}} a Relational Algebra Query Language (RAQL) and Relational Algebra Query (RAQ) software product {{we have developed}} that allows database instructors to teach relational algebra through programming. Instead of defining query operations using mathematical notation (the approach commonly taken in database textbooks), students write RAQL <b>query</b> <b>programs</b> as sequences of relational algebra function calls. The RAQ software allows RAQL programs to be run interactively, so that students can view the results of RA operations. Thus, students can learn relational algebra {{in a manner similar}} to learning SQL—by writing code and watching it run...|$|R
40|$|Identifying {{malicious}} software provides great benefit for distributed and networked systems. Traditional real-time malware detection {{has relied on}} using signatures and string matching. However, string signatures ineffectively deal with polymorphic malware variants. Control flow has been proposed as an alternative signature that can be identified across such variants. This paper proposes a novel classification system to detect polymorphic variants using flowgraphs. We propose using an existing heuristic flowgraph matching algorithm to estimate graph isomorphisms. Moreover, we can determine similarity between programs by identifying the underlying isomorphic flowgraphs. A high similarity between the <b>query</b> <b>program</b> and known malware identifies a variant. To demonstrate the effectiveness and efficiency of our flowgraph based classification, we compare it to alternate algorithms, and evaluate the system using real and synthetic malware. The evaluation shows our system accurately detects real malware, performs efficiently, and is scalable. These performance characteristics enable real-time use on an intermediary node such as an Email gateway, or on the endhost...|$|E
40|$|We are {{fortunate}} to have many different tools [...] statistical packages, spreadsheets, or database systems [...] for analysis and presentation of data. But often {{the first step in}} an analysis is manipulating or massaging the original data into a form that can be read by the package. Experienced Unix a users may use sed, awk, or shell scripts for this. Recently a more powerful language, perl, has been made freely available. It provides a superset of the capabilities of sed, awk, and sh as a scripting language. We describe its use for simple data manipulation and for querying a membership directory. Finally we outline a more complicated <b>query</b> <b>program</b> in perl for the Current Index to Statistics. Keywords: sed; awk; shell scripts; database query; Current Index a Unix is a registered trademark of Unix System Laboratories 1. INTRODUCTION Often {{the first step in a}} data analysis consists of manipulating the raw data into a form that can be read by a statistical package or database sys [...] ...|$|E
40|$|As the Semantic Web {{is gaining}} momentum, {{the need for}} truly {{versatile}} query languages becomes increasingly apparent. A Web query language is called versatile if it can access in the same <b>query</b> <b>program</b> data in different formats (e. g. XML and RDF). Most query languages are not versatile: {{they have not been}} specifically designed to cope with both worlds, providing a uniform language and common constructs to query and transform data in various formats. Moreover, most of them do not provide a flexible data model that is powerful enough to naturally convey both Semantic Web data formats (especially RDF and Topic Maps) and XML. This article highlights challenges related to the data model and language constructs for querying both standard Web and Semantic Web data with an emphasis on facilitating sophisticated reasoning. It is shown that Xcerpt’s data model and querying constructs are particularly well-suited for the Semantic Web, but that some adjustments of the Xcerpt syntax allow for even more effective and natural querying of RDF and Topic Maps. ...|$|E
40|$|Abstract. Object Oriented Design Frameworks (OOD frameworks) aregroups of {{interacting}} objects. We have formalised them in computational logic as open systems {{of interacting}} objects. Our formalisation is basedon steadfast logic {{programs in the}} context of open specification frameworks. However, we have considered only the static aspects, namely the specification of constraints and the correctness of <b>queries</b> (<b>programs</b> thatdo not update the current state). In this paper we extend this static model, by introducing actions that update the current state. 1 Introduction In Object Oriented Analysis and Design (OOA&D), the traditional unit of designis of course the class. However, the observation that in the real world, desig...|$|R
40|$|<b>Program</b> <b>query</b> {{languages}} and pattern-detection techniques are {{an essential part}} of program analysis and manipulation systems. Queries and patterns permit the identification of the parts of interest in a program’s implementation through a representation dedicated to the intent of the system (e. g. call-graphs to detect behavioral flaws, abstract syntax trees for transformations, concrete source code to verify programming conventions, etc). This requires that developers understand and manage all the different representations and techniques in order to detect various patterns of interest. To alleviate this overhead, we present a logic-based language that allows the program’s implementation to be queried using concrete source code templates. The queries are matched against a combination of structural and behavioral program representations, including callgraphs, points-to analysis results and abstract syntax trees. The result of our approach is that developers can detect patterns in the <b>queried</b> <b>program</b> using source code excerpts (embedded in logic queries) which act as prototypical samples of the structure and behavior they intend to match...|$|R
40|$|This article gives a {{practical}} introduction into the language Xcerpt, guided by many examples for illustrating language constructs and usage. Xcerpt is a rule-based, declarative query and transformation language for XML data. In Xcerpt, queries and the (re-) structuring of answer (also called "constructions") {{are expressed in}} terms of patterns instead of path navigations (like in XSLT and XQuery). Pattern queries are evaluated against XML documents using a non-standard form of unification (called "simulation unification" [BS 02]). Furthermore, Xcerpt supports so-called rule chaining (with recursion), which makes it suitable even for complex <b>query</b> <b>programs.</b> Due to its foundations in logic programming, Xcerpt can also serve to implement reasoning algorithms for the Semantic Web...|$|R
