186|10000|Public
2500|$|Queries are the {{mechanisms}} that Jet uses to retrieve {{data from the}} database. They can be defined in Microsoft QBE (<b>Query</b> <b>By</b> <b>Example),</b> through the Microsoft Access SQL Window or through Access Basic's Data Access Objects (DAO) language. These are then converted to an SQL SELECT statement. The query is then d [...] this involves parsing the query (involves syntax checking and determining the columns to query in the database table), then converted into an internal Jet query object format, which is then tokenized and organised into a tree like structure. In Jet 3.0 onwards these are then optimised using the Microsoft Rushmore query optimisation technology. The query is then executed and the results passed back to the application or user who requested the data.|$|E
50|$|Typically, {{this type}} of search engine uses {{techniques}} of <b>query</b> <b>by</b> <b>example</b> or Image <b>query</b> <b>by</b> <b>example,</b> which use the content, shape, texture and color of the image to compare them in a database and then deliver the approximate results from the query.|$|E
5000|$|A visual <b>Query</b> <b>by</b> <b>Example</b> {{implementation}} {{that was}} supported by an AI engine.|$|E
40|$|It {{is common}} for humans to {{identify}} some content <b>by</b> listing <b>examples</b> of similar content. Some movies of a Tarantino, a movie producer {{can be used to}} identify more movies of the same producer. <b>Querying</b> <b>by</b> <b>examples</b> is an alternative way of querying which allows to identify more content as well as to expand knowledge. We experimen...|$|R
40|$|We have {{developed}} an original approach for content-based video indexing and retrieval. By introducing a causal Gibbsian modeling of the spatio-temporal distribution of appropriate local motion-related measurements, we have designed a general and efficient statistical framework for non parametric motion modeling, motion recognition and classification, and motion segmentation. It is exploited for motionbased video indexing and video retrieval for both global and partial <b>queries</b> <b>by</b> <b>example...</b>|$|R
5000|$|Other query {{methods include}} {{browsing}} for example images, navigating customized/hierarchical categories, <b>querying</b> <b>by</b> image region (rather {{than the entire}} image), <b>querying</b> <b>by</b> multiple <b>example</b> images, <b>querying</b> <b>by</b> visual sketch, <b>querying</b> <b>by</b> direct specification of image features, and multimodal queries (e.g. combining touch, voice, etc.) ...|$|R
5000|$|... query {{framework}} that supports an object-oriented expression framework, <b>Query</b> <b>by</b> <b>Example</b> (QBE), EJB QL, SQL, and stored procedures ...|$|E
50|$|Image search: Although usually it's used simple {{metadata}} search, increasingly {{is being}} used indexing methods for making the results of users queries more accurate using <b>query</b> <b>by</b> <b>example.</b> For example, QR codes.|$|E
50|$|IBM bought Metaphor Computer Systems {{to utilize}} their GUI {{interface}} and encapsulating SQL platform {{that had already}} been in use since the mid 80's.In parallel with the development of SQL IBM also developed <b>Query</b> <b>by</b> <b>Example</b> (QBE), the first graphical query language.|$|E
40|$|DataPlay is a query {{tool that}} {{encourages}} a trial-and-error approach to query specification. DataPlay uses a graphical query language {{to make a}} particularly challenging query specification task- quantification- easier. It constrains the relational data model to enable the presentation of nonanswers, in addition to answers, to aid query interpretation. TwonovelfeaturesofDataPlayaresuggestingsemanticvariations to a query and correcting <b>queries</b> <b>by</b> <b>example.</b> We introduce DataPlay as a sophisticated query specification tool and demonstrate its unique interaction models. 1...|$|R
40|$|Semantic Web {{technologies}} such as RDF and its query language, SPARQL, offer the possibility of opening up {{the use of public}} datasets to a great variety of ordinary users. However, a key obstacle to the consumption of open data is the unfamiliarity of users with the structure of data, as well as their unfamiliarity with SPARQL. To deal with these issues, we introduce a system for <b>querying</b> RDF data <b>by</b> <b>example.</b> At its core is a technique for reverse-engineering SPARQL <b>queries</b> <b>by</b> <b>example.</b> We demonstrate how reverse engineering along with other techniques, such as query relaxation, enables our system, SPARQLByE, to guide users who are unfamiliar with both the dataset and with SPARQL to the desired query and result set...|$|R
40|$|International audienceIn {{this paper}} we present the Mex-Culture Multimedia platform, {{which is the}} first {{prototype}} of multimedia indexing and retrieval for a large-scale access to digitized Mexican cultural audio-visual content. The platform is designed as an open and extensible architecture of Web services. The different architectural layers and media services are presented, ensuring a rich set of scenarios. The latter comprises summarization of audio-visual content in cross-media description spaces, video <b>queries</b> <b>by</b> actions, key-frame and image <b>queries</b> <b>by</b> <b>example</b> and audio-analysis services. Specific attention is paid to the selection of data to be representative of Mexican cultural content. Scalability issues are addressed as well...|$|R
50|$|<b>Query</b> <b>by</b> <b>example</b> is a query {{technique}} that involves providing the CBIR system with an example image {{that it will}} then base its search upon. The underlying search algorithms may {{vary depending on the}} application, but result images should all share common elements with the provided example.|$|E
5000|$|The Query view {{is similar}} in {{appearance}} to the Pipeline view. Here, the user constructs partial pipelines. When the query is executed, VisTrails identifies the pipeline versions which contain the specified partial pipeline. This {{is analogous to the}} <b>Query</b> <b>By</b> <b>Example</b> method of performing database queries.|$|E
50|$|TeamMate was {{merged with}} Bentley {{development}} and in 1996 MicroStation TeamMate 96 was released. This version {{was focused on}} MicroStation support, but also handled other formats and applications such as Microsoft Office and AutoCAD. TeamMate also had metadata, file history, versions, and <b>Query</b> <b>By</b> <b>Example</b> to locate files.|$|E
40|$|Dynamic {{taxonomies}} and faceted search {{are increasingly}} used {{to organize and}} browse document collections. The main function of dynamic taxonomies is {{to start with the}} full collection, and zoom-in to a small enough subset of items for direct inspection. In this paper, we present other navigation modes than zoom-in for less directed and more exploratory browsing of a document collection. The presented navigation modes are zoom-out, shift, pivot, and <b>querying</b> <b>by</b> <b>examples.</b> These modes correspond to query transformations, and make use of boolean operators. Therefore, the current focus is always clearly specified <b>by</b> a <b>query...</b>|$|R
40|$|The {{integration}} of the Interactive Querying Algorithm [AA 04] into an existing peer-to-peer architecture—called KEx [BBMN 03, BBMN 02] is proposed. The integration improves the KEx’s functionalities {{at the level of}} knowledge peers. In particular, (a) each peer in the role of “the seeker ” is provided with the ability to do <b>queries</b> <b>by</b> <b>example,</b> and (b) each peer in the role of “the provider ” is provided with the ability to answer them. The interrelation between (a) and (b) is managed by a co-evolutive, selectionist process modeled as a kind of language game...|$|R
40|$|International audienceDynamic {{taxonomies}} and faceted search {{are increasingly}} used {{to organize and}} browse document collections. The main function of dynamic taxonomies is {{to start with the}} full collection, and zoom-in to a small enough subset of items for direct inspection. In this paper, we present other navigation modes than zoom-in for less directed and more exploratory browsing of a document collection. The presented navigation modes are zoom-out, shift, pivot, and <b>querying</b> <b>by</b> <b>examples.</b> These modes correspond to query transformations, and make use of boolean operators. Therefore, the current focus is always clearly specified <b>by</b> a <b>query...</b>|$|R
5000|$|In <b>query</b> <b>by</b> <b>example,</b> {{the element}} used to search is a {{multimedia}} content (image, audio, video). In other words, the query is a media. Often, it's used audiovisual indexing. It {{will be necessary}} to choose the criteria we are going to use for creating metadata. The process of search can be divided in three parts: ...|$|E
5000|$|IBM's first {{commercial}} relational database product, SQL/DS, was released for the DOS/VSE and VM/CMS operating systems in 1981. In 1976 IBM released <b>Query</b> <b>by</b> <b>Example</b> for the VM platform where the table-oriented front-end produced a linear-syntax language that drove transactions to its relational database. [...] Later the QMF feature of DB2 produced real SQL {{and brought the}} same [...] "QBE" [...] look and feel to DB2.|$|E
50|$|Microsoft Query is {{a visual}} method of {{creating}} database queries using examples {{based on a}} text string, {{the name of a}} document or a list of documents. The QBE system converts the user input into a formal database query using Structured Query Language (SQL) on the backend, allowing the user to perform powerful searches without having to explicitly compose them in SQL, and without even needing to know SQL. It is derived from Moshé M. Zloof's original <b>Query</b> <b>by</b> <b>Example</b> (QBE) implemented in the mid-1970s at IBM's Research Centre in Yorktown, New York.|$|E
40|$|For image {{database}} applications it {{is desirable}} that functions such as searching, browsing and partial recall be done without the need to totally decompress the image. This {{has the advantage of}} alleviating possible burden and degradation that the network may suffer. Edge images derived from wavelet-compressed images are considered as index that can be <b>queried</b> <b>by</b> <b>example.</b> Zernike moment invariants are used as descriptors for the index edge image and the query sketch image. The descriptions are compared for the purpose of database searching. The query images were allowed to undergo translation, rotation, scaling and some deformation. Simulation results gave 90 % recognition rate...|$|R
40|$|Human-computer {{interaction}} is a decisive factor in effective content-based access to large image repositories. In current image retrieval systems the user refines his <b>query</b> <b>by</b> selecting <b>example</b> images from a relevance ranking. Since the top ranked images are all similar, user feedback {{often results in}} rearrangement of the presented images only...|$|R
40|$|A new {{approach}} to indexing a specialized database by utilizing the color and spatial domain knowledge available for the database is described. This approach is illustrated by using it to provide {{a solution to the}} problem of indexing images of flowers for searching a flower patents database by color. The flower region is isolated from the background by using an automatic iterative segmentation algorithm with domain knowledge-driven feedback. The color of the flower is defined by the color names present in the flower region and their relative proportions. The database can be <b>queried</b> <b>by</b> <b>example</b> and <b>by</b> color names. The system provides a perceptually correct retrieval with natural language <b>queries</b> <b>by</b> using a natural language color classification derived from the ISCC-NBS color system and the X Window color names. The effectiveness of the strategy on a test database is demonstrated. ...|$|R
5000|$|In {{relational}} database theory, the term [...] "sublanguage", first {{used for this}} purpose by E. F. Codd in 1970, refers to a computer language used to define or manipulate the structure and contents of a {{relational database}} management system (RDBMS). Typical sublanguages associated with modern RDBMS's are QBE (<b>Query</b> <b>by</b> <b>Example)</b> and SQL (Structured Query Language). In 1985, Codd encapsulated his thinking in twelve rules which every database must satisfy in order to be truly relational. The fifth rule is known as the Comprehensive data sublanguage rule, and states: ...|$|E
5000|$|<b>Query</b> <b>by</b> <b>Example</b> (QBE) is a {{database}} query language for relational databases. It was devised by Moshé M. Zloof at IBM Research during the mid-1970s, in parallel {{to the development of}} SQL. It is the first graphical query language, using visual tables where the user would enter commands, example elements and conditions. Many graphical front-ends for databases use the ideas from QBE today. Originally limited only for the purpose of retrieving data, QBE was later extended to allow other operations, such as inserts, deletes and updates, as well as creation of temporary tables.|$|E
5000|$|Queries are the {{mechanisms}} that Jet uses to retrieve {{data from the}} database. They can be defined in Microsoft QBE (<b>Query</b> <b>By</b> <b>Example),</b> through the Microsoft Access SQL Window or through Access Basic's Data Access Objects (DAO) language. These are then converted to an SQL SELECT statement. The query is then d [...] - [...] this involves parsing the query (involves syntax checking and determining the columns to query in the database table), then converted into an internal Jet query object format, which is then tokenized and organised into a tree like structure. In Jet 3.0 onwards these are then optimised using the Microsoft Rushmore query optimisation technology. The query is then executed and the results passed back to the application or user who requested the data.|$|E
40|$|This paper {{describes}} {{an approach to}} exploit the implicit user feedback gathered during interactive video retrieval tasks. We propose a framework, where the video is first indexed according to temporal, textual, and visual features and then implicit user feedback analysis is realized using a graph-based methodology. The generated graph encodes the semantic relations between video segments based on past user interaction and is subsequently used to generate recommendations. Moreover, we combine the visual features and implicit feedback information by training a support vector machine classifier with examples generated from the aforementioned graph in order to optimize the <b>query</b> <b>by</b> visual <b>example</b> search. The proposed framework is evaluated by conducting real-user experiments. The results demonstrate that significant improvement in terms of precision and recall is reported after the exploitation of implicit user feedback, while an improved ranking is presented {{in most of the}} evaluated <b>queries</b> <b>by</b> visual <b>example...</b>|$|R
40|$|Abstract — In this article, a {{content-based}} image retrieval and annotation {{architecture is}} proposed. Its attitude is decreasing the semantic gap. To achieve a narrower gap, {{the model is}} based on estimating the relationship between image pixels and image concepts through partitioning the image with unsupervised classifier. Partitioning is executed by dividing the image to its conceptual regions. GMM is the preferred unsupervised classifier and visual features are color and texture of localized windows which sweep the image completely. To decrease the semantic gap, a set of HSV, CIELAB and YCbCr components are used to extract more information as color feature accompanying with dual-tree complex wavelet components as texture feature that can distinguish different patterns more accurately in comparison to other texture extractor. The newly proposed method is evaluated on Corel 5 K database and its performance is compared with <b>query</b> <b>by</b> visual <b>example</b> and <b>query</b> <b>by</b> semantic <b>example</b> methods comprehensively. Index Terms—Conceptual regions, Content-based image retrieval, Gaussian mixtures, semantic annotation, semanti...|$|R
40|$|In this paper, {{a unified}} image {{retrieval}} framework based on both keyword annotations and visual features is proposed. In this framework, {{a set of}} statistical models are built based on visual features of a small set of manually labeled images to represent semantic concepts and used to propagate keywords to other unlabeled images. These models are updated periodically when more images implicitly labeled by users become available through relevance feedback. In this sense, the keyword models serve the function of accumulation and memorization of knowledge learned from user-provided relevance feedback. Furthermore, two sets of effective and efficient similarity measures and relevance feedback schemes are proposed for <b>query</b> <b>by</b> keyword scenario and <b>query</b> <b>by</b> image <b>example</b> scenario, respectively. Keyword models are combined with visual features in these schemes. In particular, a new, entropy-based active learning strategy is introduced to improve the efficiency of relevance feedback for <b>query</b> <b>by</b> keyword. Furthermore, a new algorithm is proposed to estimate the keyword features of the search concept for <b>query</b> <b>by</b> image <b>example.</b> It is shown to be more appropriate than two existing relevance feedback algorithms. Experimental results demonstrate {{the effectiveness of the}} proposed framework...|$|R
30|$|The {{enormous}} {{growth of}} personal and on-line multimedia content has created the need for tools of automatic database management. Such management tools include, for instance, query by humming or <b>query</b> <b>by</b> <b>example,</b> multimedia classification, and speaker recognition. <b>Query</b> <b>by</b> <b>example</b> is an audio retrieval task where a user provides an example signal and the retrieval system returns similar samples from the database. The main problem in the <b>query</b> <b>by</b> <b>example</b> and the other above content management applications {{is to determine the}} similarity between two database items.|$|E
40|$|This paper defines {{and studies}} {{the use of}} <b>query</b> <b>by</b> <b>example</b> (QBE) {{in the context of}} {{photograph}} retrieval. The novelty of our approach lies in considering an automatic indexing process of photographs as well as a representation of the features of image regions in a single knowledge representation formalism. Both symbolic and feature based representation are used during the <b>query</b> <b>by</b> <b>example</b> process. More precisely, the QBE process is able {{to take into account the}} symbolic descriptors of the images but also the extracted features from image under the form of histograms. The aim of this process is to detect the relative importance of the symbolic elements and of the feature elements according to the user's <b>query</b> <b>by</b> <b>example.</b> We experiment the <b>query</b> <b>by</b> <b>example</b> process on two collections of a total of 1100 photographs. The precision measures we have obtained are as good as a baseline defined as explicit textual queries processing...|$|E
40|$|<b>Query</b> <b>by</b> <b>example</b> for {{multimedia}} signals aims at automatic {{retrieval of}} {{samples from the}} media database similar to a userprovided example. This paper proposes a similarity measure for <b>query</b> <b>by</b> <b>example</b> of audio signals. The method first represents audio signals using perceptual audio coding and second estimates the similarity of two signals from the advantage gained by compressing the files together in comparison to compressing them individually. Signals which benefit most from compressing together are considered similar. The low bit rate perceptual audio coding preprocessing effectively retains perceptually important features while quantizing the signals so that identical codewords appear, allowing further inter-signal compression. The advantage of the proposed similarity measure {{is that it is}} parameter-free, thus it is easy to apply in wide range of tasks. Furthermore, users ’ expectations do not affect the results like they do in parameter-laden algorithms. A comparison was made against the other <b>query</b> <b>by</b> <b>example</b> methods and simulation results reveal that the proposed method gives competitive results against the other methods. 1...|$|E
40|$|We {{present a}} {{comprehensive}} strategy for evaluating image retrieval algorithms. Because automated image retrieval is only meaningful in its service to people, performance characterization must be grounded in human evaluation. Thus we have collected a large data set of human evaluations of retrieval results, both for <b>query</b> <b>by</b> image <b>example</b> and <b>query</b> <b>by</b> text. The data {{is independent of}} any particular image retrieval algorithm {{and can be used}} to evaluate and compare many such algorithms without further data collection. The data and calibration software are available on-lin...|$|R
40|$|We {{propose a}} {{structured}} {{approach to the}} problem of retrieval of images by content and present a description logic that has been devised for the semantic indexing and retrieval of images containing complex objects. As other approaches do, we start from low-level features extracted with image analysis to detect and characterize regions in an image. However, in contrast with feature-based ap-proaches, we provide a syntax to describe segmented regions as basic objects and complex objects as compositions of basic ones. Then we introduce a companion extensional seman-tics for defining reasoning services, such as retrieval, classification, and subsumption. These services can be used for both exact and approximate matching, using similarity measures. Using our logical approach as a formal specification, we implemented a complete client-server image retrieval system, which allows a user to pose both <b>queries</b> <b>by</b> sketch and <b>queries</b> <b>by</b> <b>example.</b> A set of experiments has been carried out on a testbed of images to assess the retrieval capabilities of the system in comparison with expert users ranking. Results are presented adopting a well-established measure of quality borrowed from textual information retrieval. 1...|$|R
40|$|Fuzzy set {{methods have}} been already applied to the {{representation}} of flexible queries in databases systems {{as well as in}} information retrieval. This methodology seems to be even more promising in multimedia databases which have a complex structure and from which documents have to be retrieved and selected not only from their contents but also from their appearance, as specified by the user. This paper provides a preliminary investigation of two potential applications of fuzzy logic in multimedia databases querying. The first one concerns the detection of modifications in semi-structured documents and relies on a graph matching procedure where subparts of the graph describing the structures have different levels of importance. The second illustrates another aspect of the fuzzy logic methodology allowing for a <b>querying</b> <b>by</b> <b>examples</b> process. Examples and counterexamples are supposed to be provided by the user with their levels of representativity; attributes used in their descri [...] ...|$|R
