88|11|Public
2500|$|Queries are the {{mechanisms}} that Jet uses to retrieve {{data from the}} database. They can be defined in Microsoft QBE (Query By Example), through the Microsoft Access SQL Window or through Access Basic's Data Access Objects (DAO) language. These are then converted to an SQL SELECT statement. The query is then d [...] this involves parsing the query (involves syntax checking and determining the columns to query in the database table), then converted into an internal Jet query object format, which is then tokenized and organised into a tree like structure. In Jet 3.0 onwards these are then optimised using the Microsoft Rushmore <b>query</b> <b>optimisation</b> technology. The query is then executed and the results passed back to the application or user who requested the data.|$|E
5000|$|O'Connell defines join {{selection}} {{factor as}} [...] "the percentage (or fraction) of records in one file {{that will be}} joined with records of another file". [...] This can be calculated when two database tables are to be joined. It is primarily concerned with <b>query</b> <b>optimisation.</b>|$|E
5000|$|Queries are the {{mechanisms}} that Jet uses to retrieve {{data from the}} database. They can be defined in Microsoft QBE (Query By Example), through the Microsoft Access SQL Window or through Access Basic's Data Access Objects (DAO) language. These are then converted to an SQL SELECT statement. The query is then d [...] - [...] this involves parsing the query (involves syntax checking and determining the columns to query in the database table), then converted into an internal Jet query object format, which is then tokenized and organised into a tree like structure. In Jet 3.0 onwards these are then optimised using the Microsoft Rushmore <b>query</b> <b>optimisation</b> technology. The query is then executed and the results passed back to the application or user who requested the data.|$|E
40|$|International audienceFostering the {{development}} of SPARQL interfaces to heterogeneous databases {{is a key to}} efficiently expose legacy data as RDF on the Web. To deal with the variety of modern database formats and query languages, this paper describes a two-step approach to translate a SPARQL query into an equivalent target database query. First, given an xR 2 RML mapping describing how native database entities can be mapped to RDF, a SPARQL query is translated into a pivot abstract query language independent of the database. In a second step, the pivot query is translated into the target database query language, considering the specific database capabilities. The paper focuses on the first step of the query translation, from SPARQL to a pivot query that takes into account join constraints and SPARQL filters, and embeds conditions entailed by matching SPARQL graph patterns with relevant mappings. It discusses the <b>query</b> <b>optimisations</b> that can be implemented at this level, and briefly describes an application to the case of MongoDB, a NoSQL document store...|$|R
40|$|Augmented Reality (AR) {{provides}} a natural interface to the "calm" pervasive technology anticipated in large-scale Ubiquitous Computing environments. However, {{the range of}} classic AR applications has been limited by the scope, range and cost of sensors used for tracking. Hybrid tracking approaches can go some way to extending this range. We propose an approach, called Ubiquitous Tracking, in which data from widespread and diverse heterogeneous tracking sensors is automatically and dynamically fused, and then transparently provided to applications. A formal model represents spatial relationships between objects as a graph attributed with quality-of-service parameters. This paper presents a software implementation, in which a dynamic data flow network of distributed software components is thereby constructed in response to <b>queries</b> and <b>optimisation</b> criteria specified by applications. This implementation is demonstrated using a small laboratory example, and larger setups modelled in a simulation environment...|$|R
40|$|In this paper, {{we discuss}} the main {{problems}} of inductive <b>query</b> languages and <b>optimisation</b> issues. We present a logic-based inductive query language and illustrate the use of aggregates and exploit a new join operator to model specific data mining tasks. We show how a fixpoint operator works for association rule mining and a clustering method. A preliminary experimental result shows that fixpoint operator outperforms SQL and Apriori methods. The results of our framework could be useful for inductive query language design {{in the development of}} inductive database systems. ...|$|R
40|$|<b>Query</b> <b>optimisation</b> is a {{significant}} unsolved problem {{in the development of}} multidatabase systems. The main {{reason for this is that}} the query cost functions for the component database systems may not be known to the global query optimiser. In this paper, we describe a method, based on a classical clustering algorithm, for classifying queries which allows us to derive accurate approximations of these query cost functions. The experimental results show that the cost functions derived by the clustering algorithm yield a lower average error as compared to the error produced by a manual classification. Keywords: Cost function derivation, Classification, <b>Query</b> <b>optimisation,</b> Multidatabase systems 1 Introduction <b>Query</b> <b>optimisation</b> in multidatabase systems is fundamentally different from distributed <b>query</b> <b>optimisation,</b> for three major reasons [5]: site autonomy, system heterogeneity and semantic heterogeneity. Site autonomy means that the essential information for optimisation, namely cost fu [...] ...|$|E
40|$|Our aim is {{to realise}} an {{agent-based}} Grid simulator for studying "Grid <b>Query</b> <b>Optimisation</b> Strategies", as partially described in [SSS+ 01]. The purposes of this document are the following: • To identify some HEP use cases and, based on these use cases and requirements, to identify some user-level and Grid-level <b>query</b> <b>optimisation</b> opportunities. • To define an architecture for the simulator, in which the components and services identified in the ATF proposal [ATF] are integrated with components and services, specifically targeted to <b>query</b> <b>optimisation.</b> • To define how the components and services in the simulator interact in order to perform optimisation based on the identified optimisation opportunities. Our goal in realising the simulator is twofold: • To stimulate the discussion in the DataGRID project about the important issue of <b>query</b> <b>optimisation</b> and help the gathering of requirements for it by providing a working software tool that allows experimentation, testing, and validation of optimisation strategies. • To promote agent technology for the realisation of "intelligent " and flexible Grid services (of which <b>query</b> <b>optimisation</b> is one) that {{have to take into}} account several dynamically changin...|$|E
40|$|This {{report has}} been {{submitted}} for publication outside of ITC {{and will probably}} be copyrighted if accepted for publication. It has been issued as a Technical Report for early dissemination of its contents. In view of the transfert of copy right to the outside publisher, its distribution outside of ITC prior to publication {{should be limited to}} peer communications and specific requests. After outside publication, material will be available only in the form authorized by the copyright owner. Grid <b>Query</b> <b>Optimisation</b> in the Data Grid <b>Query</b> <b>Optimisation</b> Task - WP 2, European DataGRID Project Paolo Busetta, Mark Carman, Luciano Serafini, Floriano Zini ITC-IRST, Povo, Trento, Italy Kurt Stockinger CERN, Geneva, Switzerland 1 Purpose Our aim is to realise an agent-based Grid simulator for studying "Grid <b>Query</b> <b>Optimisation</b> Strategies", as partially described in [SSS+ 01]. The purposes of this document are the following: To identify some HEP use cases and, based on these use cases and requirements, to identify some user-level and Grid-level <b>query</b> <b>optimisation</b> opportunities. To define an architecture for the simulator, in which the components and services identified in the ATF proposal [ATF] are integrated with components and services, specifically targeted to <b>query</b> <b>optimisation.</b> To define how the components and services in the simulator interact in order to perform optimisation based on the identified optimisation opportunitie...|$|E
40|$|Abstract: A {{technical}} infrastructure for storing, querying and managing RDF data {{is a key}} element in the current semantic web development. Systems like Jena, Sesame or the ICS-FORTH RDF Suite are widely used for building semantic web applications. Currently, none of these systems support the integrated querying of distributed RDF repositories. We consider this a major shortcoming since the semantic web is distributed by nature. In this paper we present an architecture for querying distributed RDF repositories by extending the existing Sesame system. We discuss the implications of our architecture and propose an index structure as well as algorithms for <b>query</b> processing and <b>optimisation</b> in such a distributed context...|$|R
40|$|Most search {{systems for}} {{querying}} large document collections [...] -for example, web search engines [...] -are based on well-understood information retrieval principles. These systems are both {{efficient and effective}} in finding answers to many user information needs, expressed through informal ranked or structured Boolean queries. Phrase querying and browsing are additional techniques that can augment or replace conventional querying tools. In this paper, we propose <b>optimisations</b> for phrase <b>querying</b> with a nextword index, an efficient structure for phrase-based searching. We show that careful consideration of which search terms are evaluated in a <b>query</b> plan and <b>optimisation</b> {{of the order of}} evaluation of the plan can reduce query evaluation costs by more than a factor of five. We conclude that, for phrase querying and browsing with nextword indexes, an ordered query plan should be used for all browsing and querying. Moreover, we show that optimised phrase querying is practical on large text collections...|$|R
40|$|The {{advanced}} data models for PAS that make these systems superior to their table-oriented antecedents (RDBMS) {{have an impact}} on the formalisms that are needed to capture these models and their appropiate query languages (eg. ODMG's OQL). Queries that are nested to arbitrary depth, path expressions, and complex predicates pose challenges on the query translation process. The work package RT 2. 1 will identify generic (algebraic) operators that allow the efficient translation of such queries. These operators will account for the various bulk types the data models feature. Optimisation techniques have to be found, adapted, and validated. PAS query languages allow to mix operations on bulk types and scalars (just like programming languages). Monad calculi treat bulk and scalar types in a uniform way, and allow for reasoning about arithmetics and general computation. This offers the perspective of a hybrid approach to <b>query</b> translation and <b>optimisation,</b> combining the power of algebra and calcu [...] ...|$|R
40|$|Abstract: Semantic <b>Query</b> <b>Optimisation</b> (SQO) in Relational Database Management Systems (RDMSs) is a <b>query</b> <b>optimisation</b> {{approach}} {{which uses}} rules learned from past queries {{in order to}} execute new queries more intelligently without accessing database, whenever possible. The approach is composed of several components: Query Representation, <b>Query</b> <b>Optimisation,</b> Automatic Rule Derivation and Rule Maintenance. This paper focused on the <b>query</b> <b>optimisation</b> component. In RDMSs, during the traditional SQO, different alternative queries of a given query can be constructed using matching rule(s) from the rule set, and then its optimiser selects one of the alternatives as an optimum query which will give the same answer set {{but it can be}} executed faster than the original query. One of the main problems occurs during this process is to have many matched rules e. g., if the number of the rules isN, the number of the alternative queries is 2 N − 1. The construction and the optimisation of these alternatives also take time in addition to the execution of the query. In order to overcome this problem, in this paper we propose a new Rule Evaluation Algorithm. The main goal of the algorithm is to evaluate matching rule(s) and select useful/promising rules. And then use selected rules to construct an optimum query. The algorithm can answer the question of the utility of rules in the <b>query</b> <b>optimisation.</b> The system of the approach based on the algorithm has been implemented and its computational results are given. The experimental results show that the algorithm can trim the number of the rules significantly...|$|E
40|$|Operations on {{abstract}} {{data types}} {{can be classified}} as either queries or updates — those that either query the current state, or update it. Modern object-oriented programming languages require classes/interfaces to support a predefined set of such operations. This presents a challenge for software designers, since a fixed interface can severely restrict the opportunities for optimisation. In this paper, we present two common patterns — Specific <b>Query</b> <b>Optimisation</b> and Generalised <b>Query</b> <b>Optimisation</b> — for optimising such operations. The first requires specific knowledge of which operation to optimise beforehand, whilst the latter provides more leeway in this regard. These patterns are commonly occurring in software, and we find numerous instances of them within the Java standard libraries...|$|E
40|$|Semantic <b>query</b> <b>optimisation</b> uses derived {{rules to}} {{transform}} an original query into a semantically equivalent query {{which is more}} efficient to execute. Derived rules represent a time-dependent property of a database at a particular database state. When updates are made on the database, these rules may become invalid. Therefore the derived rules need to be maintained {{to be consistent with}} the current database state. Although much research work has been done on semantic <b>query</b> <b>optimisation,</b> maintaining a consistent set of derived rules is seldom discussed. In this paper, the database statements INSERT, DELETE and UPDATE, which may lead to a violation of the integrity of derived rules, are discussed and algorithms proposed to solve the problem. ...|$|E
40|$|Spatial join {{is one of}} the {{fundamental}} operations in a Spatial Data Base Management System. Recently, the family of R-tree-based data structures has been adopted to support the execution of spatial joins. This paper introduces an analytical model that efficiently estimates the cost (in terms of disk accesses) of a spatial join query between two spatial datasets. The proposed model is based on an analytical formula that estimates the cost of the range query using Rtrees. In addition, comparison results are presented which show the accuracy of the analytical estimations when compared to actual tests on both synthetic and real datasets. It turns out that the relative error rarely exceeds 15 % for all combinations. KEYWORDS: Spatial Databases, <b>Query</b> Performance and <b>Optimisation,</b> Spatial Join. ACKNOWLEDGEMENTS: This research has been partially supported by a research grant from the General Secretariat of Research and Technology of Greece (YPER' 94) and by the European Commission funded TMR pr [...] ...|$|R
40|$|Abstract—This paper {{presents}} the first parallel implementation of pointer analysis with Context-Free Language (CFL) reacha-bility, an important foundation for supporting demand <b>queries</b> in compiler <b>optimisation</b> and software engineering. Formulated as a graph traversal problem (often with context- and field-sensitivity for desired precision) and driven by queries (issued often in batch mode), {{this analysis is}} non-trivial to parallelise. We introduce a parallel solution to the CFL-reachability-based pointer analysis, with context- and field-sensitivity. We exploit its inherent parallelism by avoiding redundant graph traversals with two novel techniques, data sharing and query scheduling. With data sharing, paths discovered in answering a query are recorded as shortcuts so that subsequent queries will take the shortcuts instead of re-traversing its associated paths. With query scheduling, queries are prioritised according to their statically estimated dependences so that more redundant traversals can be further avoided. Evaluated using a set of 20 Java programs, our parallel implementation of CFL-reachability-based pointer analysis achieves an average speedup of 16. 2 X over a state-of-the-art sequential implementation on 16 CPU cores. I...|$|R
40|$|Sera publié à ICDM 2017 au démo trackInternational audience—Predictive Complex Event Processing (CEP) {{constitutes}} {{the next phase}} of CEP evolution and provides future pre-dictive states of the partially matched complex sequences. In this paper, we demonstrate our novel predictive CEP system and show that this problem can be solved while leveraging existing data modelling, <b>query</b> execution and <b>optimisation</b> frameworks. We model the predictive detection of events over an N-dimensional historical matched sequence space. Hence, a predictive set of events can be determined by answering the range queries over the historical sequence space. In order to take advantage of range search over 1 -dimensional data structures, we transform the N-dimensional space into 1 -dimension using space filling z-order curve. We propose a compressed index structure to store 1 -dimensional data and execute customised range query techniques. Furthermore, we propose an approximate summarisation technique, over the historical space of top-k most infrequent range queries, to cater catastrophic forgetting of older matches. Two real-world datasets are used to demonstrate the feasibility of our proposed techniques. We demonstrate that our system can efficiently predict complex events and it equips a user-friendly interface to fulfil the requirements of user-computer interaction in a real-time...|$|R
40|$|XML-based {{databases}} {{have become}} a major area of interest in database research. Abstractly speaking they {{can be considered as}} a resurrection of complex-value databases using constructors for records, lists, unions plus optionality and references. XQuery has become the standard query language for XML. As XQuery is a declarative query language, the problem of <b>query</b> <b>optimisation</b> arises. In this paper an algebraic approach to <b>query</b> <b>optimisation</b> is introduced. This is based on a translation of XQuery into a query algebra for rational tree types. The algebra uses simple operations on types and structural recursion for lists. The translation exploits linguistic reflection for the type-safe expansion of path expressions. The availability of an algebraic representation of queries permits query rewriting, which in combination with cost heuristics permits queries to be rewritten and thus optimised...|$|E
40|$|The {{importance}} of <b>query</b> <b>optimisation</b> {{has led to}} active {{research in this area}} {{over a number of years}} and the development of optimisation components as a standard feature of large Database Management Systems. More recent work is concerned with semantic <b>query</b> <b>optimisation</b> (SQO) which is guided by derived knowledge (rules), about the data itself, using techniques associated with data mining. Fast, efficient rule generation and maintenance is crucial to achieving high optimiser performance. At the same time it is recognized that most available computing power, in a networked client-server system, resides in the client workstations which are often under-utilized and that this resource is expanding rapidly with each successive new generation of workstation. In this paper we show how this spare capacity may be used to improve optimiser performance by distributing the rule management processes in a parallel virtual machine environment. ...|$|E
40|$|International audienceThis work {{presents}} a genetic approach for <b>query</b> <b>optimisation</b> in information retrieval. The proposed GA is improved y heuristics {{in order to}} solve the relevance multimodality problem and adapt the genetic exploration process to the information retrieval task. Experiments with AP documents and queries issued from TREC show the effectiveness of our GA mode...|$|E
40|$|Semistructured data, in {{particular}} XML, {{has emerged as}} one of the primary means for information exchange and content management. The power of XML allows authors to structure a document in a way which precisely captures the semantics of the data. This, however, poses a substantial barrier to casual and non-expert users who wish to query such data, as it is the structure of the data which forms the basis of all XML query languages. Without an accurate understanding of how the data is structured, users are unable to issue meaningful queries. This problem is compounded when one realises that data adhering to different schema are likely to be contained within the same data warehouse or federated database. This paper proposes a method which enables users to meaningfully query semistructured data with no prior knowledge of its structure. We describe a mechanism for returning approximate answers to a database query when the structure of the underlying data is unknown. Our mechanism also returns useful results to the user if a specific value in the query cannot be matched. We discuss a number of novel <b>query</b> processing and <b>optimisation</b> techniques which enable us to perform our cooperative query answering in an efficient and scalable manner...|$|R
40|$|Recent {{developments}} in mobile communications have brought dramatic and fundamental {{changes to the}} modern world. These developments {{have resulted in a}} great demand for applications that integrate geographic locations and services to fulfill the user’s needs. Different types of spatial queries are used in such applications, however, most studies consider the moving range query to be the most common, and frequently used. The moving range query is used to find all objects of interest within a given radius while the user who invokes the query is moving. During the last decade, some studies in moving range queries considered Euclidean geometry, where the distance between two objects is determined by their relative position in space. Some other studies considered network distance, wherein the trajectory between two objects is specified by the underlying network. The main objective of all the previous studies is to process moving range queries efficiently. However, most of these studies focus on index efficiency and less effort has been made to address the issues of moving <b>query</b> updating and <b>optimisation,</b> which are crucial factors affecting system performance. In this thesis, we attempt to investigate this possibility by proposing four new processing techniques. First, we introduce a new “approximate moving range query” to optimise the query process in two ways: i) we reduce the amount of time needed to obtain the results; and ii) we give the users alternative options in order to avoid another search(es) when searching an empty result or a massive number of objects in the result. The result of our experiments show that our techniques are successful in terms of reducing the number of split points and false hits. Also, the approximate results are of a high quality compared to the exact results. Furthermore, our algorithms reduce the number of communications between the mobile device and the databases server, indicating their performance is better in terms of lower search time and improved search accuracy. Second, we present a technique to deal with the moving range query called “safe region”. The high computation and communication costs of monitoring and updating the location of the moving range query needs to be considered, as the calculation of the range query needs to be re-evaluated whenever the query moves. Our aim is to avoid any communication between the query and the server while the query moves within the specified safe region. We have extended the size of the safe region {{to reduce the amount of}} supplementary communication. Our main objective is to reduce the need for continuous monitoring of the query, and eliminate the need for the user to follow a defined path. Third, we propose a linear model called “monitoring moving range query” to monitor moving queries inside a safe region. Our technique gives the users the ability to monitor themselves and inform the server when leaving the safe region. This will give the user more privacy and reduce the load on the server. Also, our technique will eliminate the need for the user to follow a defined path. We use the time and the concept of the safe region together, hence, if the query makes a sudden turn, the result will not be affected because the query will still be located inside the safe region. Finally, we introduce a novel query processing technique for the moving range query in spatial network databases, called “lookforward moving range query”. Our technique is related to Euclidean and network distance to retrieve related objects and at the same time to exclude unrelated ones. Our technique can distinguish between the significant important objects and the minor important objects inside the range query. Our technique improves the selectivity of the filter step to reduce the number of candidate objects, and consequently, minimise the number of communications between the mobile device and the database server. The lookforward moving range query achieves a better running time and delivers a better performance having fewer split points than the original moving range query as shown on our experiments...|$|R
40|$|We {{present an}} {{extension}} of Logic Programming (LP) which, in addition to ordinary LP clauses, also includes integrity constraints, explicit representation of disjunction in the bodies of clauses and in goals, and suspension of atoms as in concurrent logic languages. The resulting framework aims to unify Constraint Logic Programming (CLP), Abductive Logic Programming (ALP) and Semantic <b>Query</b> <b>Optimisation</b> (SQO) in deductive databases. We present a proof procedure for the new framework, simplifying and generalising previously proposed proof procedures for ALP. We discuss applications of the framework, formulating traditional problems from LP, ALP, CLP and SQO. Keywords: Logic Programming (LP), Constraint Logic Programming (CLP), Abductive Logic Programming (ALP), Semantic <b>Query</b> <b>Optimisation</b> (SQO) in Deductive Databases. 1. Introduction Ordinary LP solves problems by representing problem-solving procedures by means of clauses of the form H / L 1 : : : Lm with m 0, H an atom and each [...] ...|$|E
40|$|The next {{generation}} experiments in High Energy Physics are {{the driving force}} for setting up an International Data Grid at CERN, the European Organization for Nuclear Research. Hundreds of Petabytes of data will be distributed and replicated {{all over the globe}} starting from 2005. In order to analyse this massive set of distributed data efficiently, we propose a hierarchical <b>query</b> <b>optimisation</b> architecture based on multi-agent technology. The architecture is optimised for the High Energy Physics community but is representative also for other data intensive scientific applications that use distributed data stores and mass storage systems. Keywords: <b>query</b> <b>optimisation,</b> distributed computing, agent technology 1 Introduction The idea of building an International Data Grid [1, 2] at CERN, the European Organization for Nuclear Research, was driven by the needs of the {{next generation}} accelerator, the Large Hadron Collider (LHC), which is scheduled to be in operation in 2005. Several Petabyte [...] ...|$|E
40|$|A major {{challenge}} still facing the designers and implementors of database programming languages (DBPLs) {{is that of}} <b>query</b> <b>optimisation.</b> We investigate algebraic <b>query</b> <b>optimisation</b> for DBPLs {{in the context of}} a purely declarative functional language that supports sets as first-class objects. Since the language is computationally complete issues such as non-termination of expressions and construction of infinite data structures can be investigated, whilst its declarative nature allows the issue of side effects to be avoided and a rich set of equivalences to be developed. The language has a well-defined semantics which permits us to reason formally about the properties of expressions, such as their equivalence with other expressions and their termination. The support of a set bulk data type enables much prior work on the optimisation of relational languages to be utilised. In the paper we first give the syntax of an archetypal DBPL and briefly discuss its semantics. We then de [...] ...|$|E
40|$|In a {{previous}} paper [6], we introduced {{the notion of}} using machine learning techniques {{to solve the problem}} of query size estimation in database <b>query</b> <b>optimisation.</b> In this paper, we build on this work by describing a new generic algorithm to correct the training set of queries for our machine learning method in response to updates. The training set correction algorithm is not only useful in the context of our machine learning approach, but is also useful for improving existing query size estimation methods whose performance deteriorates in the presence of high update loads. A by-product of our correction algorithm is that training sets can be fixed-size, allowing the error-level to be set in advance. Experimental results show that our machine learning technique performs well (and better than alternative methods) after the correction algorithm is applied. Keywords Query Size Estimation, <b>Query</b> <b>Optimisation,</b> Machine Learning 1 Introduction A query optimiser for a database system aims t [...] ...|$|E
40|$|Semantic <b>Query</b> <b>Optimisation</b> {{makes use}} of the {{semantic}} knowledge of a database (rules) to perform query transformation. Rules are normally learned from former queries fired by the user. Over time, however, this can result in the rule set becoming very large thereby degrading {{the efficiency of the}} system as a whole. Such a problem is known as the utility problem. This paper seeks to provide a solution to the utility problem through the use of statistical techniques in selecting and maintaining an optimal rule set. Statistical methods have, in fact, been used widely in the field of Knowledge Discovery to identify and measure relationships between attributes. Here we extend the approach to Semantic <b>Query</b> <b>Optimisation</b> using the Chi-square statistical method which is integrated into a prototype query optimiser developed by the authors. We also present a new technique for calculating Chi-square, which is faster and more efficient than the traditional method in this situation. ...|$|E
40|$|International audienceThis paper {{presents}} a new genetic approach for <b>query</b> <b>optimisation</b> in document retrieval. The main {{contribution of the}} paper is to show {{the effectiveness of the}} genetic niching technique to reach multiple relevant regions of the document space. Moreover, suitable merging procedures have been proposed in order to improve the retrieval evaluation. Experimental results obtained using a TREC sub-collection indicate that the proposed approach is promising for applications...|$|E
40|$|Abstract. A {{fundamental}} {{problem to be}} solved in systems which derive rules from database tables to use in <b>query</b> <b>optimisation</b> is the workload involved. If the data server has {{to do the work}} it can interfere with query processing and cause slower query answering, which is the opposite of the required effect. This paper reports our investigation of the use of multiple workstations in the same local network as the data server to derive and maintain sets of rules describing data subsets. These rules are used in <b>query</b> <b>optimisation.</b> In a local area network of workstations, one computer accepts SQL queries and data manipulation commands from networked clients. This computer provides an interface to one or more database management systems located on computers in the network. It uses a collection of subset-descriptor rules for query reformulation before forwarding the semantically optimised query. It manages a set of workstations in the network, to derive and maintain the rules. The workstations are ordinary networked computers whose spare computing capacity is utilized by spawning background programs on them...|$|E
40|$|Preferences {{allow more}} {{flexible}} and personalised queries in database systems. Evaluation {{of such a}} query means to select the maximal elements from the respective database w. r. t. to the preference, which is a partial strict-order. We present a point-free calculus of such preferences and exemplify its use in proving algebraic laws about preferences {{that can be used}} in <b>query</b> <b>optimisation.</b> We show that this calculus can be mechanised using off-the-shelf automated first-order theorem provers...|$|E
40|$|Factorised {{databases}} are relational databases {{that use}} compact factorised representations at the physical layer to reduce data redundancy and boost query performance. This paper introduces FDB, an in-memory query engine for select-project-join queries on factorised databases. Key components of FDB are novel algorithms for <b>query</b> <b>optimisation</b> and evaluation that exploit the succinctness brought by data factorisation. Experiments show that for data sets with many-to-many relationships FDB can outperform relational engines by orders of magnitude. 1...|$|E
40|$|Abstract. This paper {{presents}} a new genetic approach for <b>query</b> <b>optimisation</b> in document retrieval. The main {{contribution of the}} paper is to show {{the effectiveness of the}} genetic niching technique to reach multiple relevant regions of the document space. Moreover, suitable merging procedures have been proposed in order to improve the retrieval evaluation. Experimental results obtained using a TREC sub-collection indicate that the proposed approach is promising for applications. KEY WORDS: Information retrieval, multiple query evaluation, genetic algorithm, niching 1...|$|E
40|$|Abstract. We {{describe}} a {{system designed to}} provide database programming sup-port for Oberon programmers. The system {{is based on a}} generic object-oriented data model which supports rich classification structures and an algebra over col-lections of objects. We describe how support for the constructs and operations of this model is provided to the programmer without changes to the Oberon lan-guage and with minimal changes to the run-time system. In particular, we con-sider issues of support for object evolution, constraint maintenance and <b>query</b> <b>optimisation.</b> ...|$|E
40|$|This paper {{presents}} {{an approach to}} intelligent information retrieval based on genetic heuristics. Recent search has shown that applying genetic models for <b>query</b> <b>optimisation</b> improve the retrieval effectiveness. We investigate ways to improve this process by combining genetic heuristics and information retrieval techniques. More precisely, we propose to integrate relevance feedback techniques to perform the genetic operators and the speciation heuristic to solve the relevance multimodality problem. Experiments, with AP documents and queries issued from TREC, showed the effectiveness of our approach...|$|E
40|$|Abstract. We {{present an}} {{extension}} of Logic Programming (LP) which, in addition to ordinary LP clauses, also includes integrity constraints, explicit representation of disjunction in the bodies of clauses and in goals, and suspension of atoms as in concurrent logic languages. The resulting framework aims to unify Constraint Logic Programming (CLP), Abductive Logic Programming (ALP) and Semantic <b>Query</b> <b>Optimisation</b> (SQO) in deductive databases. We present a proof procedure for the new framework, simplifying and generalising previously proposed proof procedures for ALP. We discuss applications of the framework, formulating traditional problems from LP, ALP, CLP and SQO...|$|E
