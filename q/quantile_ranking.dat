1|35|Public
30|$|As expected, a {{significant}} increase in growth in the second generation was observed compared with the unimproved first generation, as a presumed consequence of selection on growth traits. This accords with the fact that families used in this study were originally selected for Forestal Mininco Company for their superior diameter and height growth. While P. radiata seedlings often reach a height of 2  m in the second year after establishment (Lisboa 1993; Mead 2013), we attribute the low level of growth in this study to the very low soil moisture availability at the planting site. On the other hand, although families used in this study came from contrasting ecological origins, population differences in survival, diameter and height were not obvious, which may be attributable {{to the fact that the}} Chilean tree improvement programme has selected families that perform well across a wide range of sites. Breeders have usually aimed to develop genotypes that are satisfactory for a wide range of conditions (i.e. showing low genotype × environment interaction in field trials); however, care must be taken when maximising growth rates with second- or third-breeding-generation trees in drought-prone sites. This seems to be an adequate long-term strategy only if high growth, leaf areas and transpiration can be supported in years of significantly below-average rainfall. Effects of native-population origins could have also contributed to family differences. As the two regional breeding populations used in our study would both have had some mix of Monterrey and Año Nuevo populations (Burdon 1978), that would tend to not only create some initial difference in adaptive profiles of the regional breeding populations but also create a source of family variation within those populations. On the other hand, the Pearson’s correlation coefficient between nursery and field conditions, based on family mean for height, was moderate and negative (R[*]=[*]− 0.40, P[*]=[*] 0.02), indicating a low correspondence between both environments. Only two families retained the same <b>quantile</b> <b>ranking</b> in the two environments (details not shown).|$|E
40|$|National Institutes of Health; Chinese Academy of Sciences; National Natural Science Foundation 	We {{propose a}} novel method for neurodevelopmental brain mapping that {{displays}} how an individual&# 39;s values for {{a quantity of}} interest compare with age-specific norms. By estimating smoothly age-varying distributions at a set of brain regions of interest, we derive age-dependent region-wise <b>quantile</b> <b>ranks</b> for a given individual, which can be presented {{in the form of}} a brain map. Such <b>quantile</b> <b>rank</b> maps could potentially be used for clinical screening. Bootstrap-based confidence intervals are proposed for the <b>quantile</b> <b>rank</b> estimates. We also propose a recalibrated Kolmogorov-Smirnov test for detecting group differences in the age-varying distribution. This test is shown to be more robust to model misspecification than a linear regression-based test. The proposed methods are applied to brain imaging data from the Nathan Kline Institute Rockland Sample and from the Autism Brain Imaging Data Exchange (ABIDE) sample. </p...|$|R
40|$|We propose new {{concepts}} of statistical depth, multivariate <b>quantiles,</b> <b>ranks</b> and signs, based on canonical transportation maps between a distribution of interest on $R^d$ and a reference distribution on the $d$-dimensional unit ball. The new depth concept, called Monge-Kantorovich depth, specializes to halfspace depth {{in the case}} of spherical distributions, but, for more general distributions, differs from the latter in the ability for its contours to account for non convex features of the distribution of interest. We propose empirical counterparts to the population versions of those Monge-Kantorovich depth contours, <b>quantiles,</b> <b>ranks</b> and signs, and show their consistency by establishing a uniform convergence property for empirical transport maps, which is of independent interest. Comment: 30 pages, 2 figure...|$|R
40|$|Abstract—Recently, {{there have}} been several {{attempts}} to propose definitions and algorithms for ranking queries on probabilistic data. However, these lack many intuitive properties of a top-k over deterministic data. We define several fundamental properties, including exact-k, containment, unique-rank, value-invariance, and stability, which are satisfied by ranking queries on certain data. We argue these properties should also be carefully studied in defining ranking queries in probabilistic data, and fulfilled by definition for ranking uncertain data for most applications. We propose an intuitive new ranking definition based on the observation that the ranks of a tuple across all possible worlds represent a well-founded rank distribution. We studied the ranking definitions based on the expectation, the median and other statistics of this rank distribution for a tuple and derived the expected rank, median <b>rank</b> and <b>quantile</b> <b>rank</b> correspondingly. We are able to prove that the expected rank, median <b>rank</b> and <b>quantile</b> <b>rank</b> satisfy all these properties for a ranking query. We provide efficient solutions to compute such rankings across the major models of uncertain data, such as attribute-level and tuple-level uncertainty. Finally, a comprehensive experimental study confirms the effectiveness of our approach...|$|R
40|$|Abstract. We propose new {{concepts}} of statistical depth, multivariate quan-tiles, ranks and signs, based on canonical transportation maps between a dis-tribution of interest on IRd and a reference distribution on the d-dimensional unit ball. The new depth concept, called Monge-Kantorovich depth, specializes to halfspace depth {{in the case}} of elliptical distributions, but, for more general distributions, differs from the latter in the ability for its contours to account for non convex features of the distribution of interest. We propose empirical coun-terparts to the population versions of those Monge-Kantorovich depth contours, <b>quantiles,</b> <b>ranks</b> and signs, and show their consistency by establishing a uniform convergence property for empirical transport maps, which is of independent in-terest...|$|R
50|$|Typically, the {{modeller}} {{seeks to}} divide the population into <b>quantiles,</b> and <b>rank</b> the <b>quantiles</b> by lift. Organizations can then consider each quantile, and by weighing the predicted response rate (and associated financial benefit) against the cost, they can decide whether to market to that quantile or not.|$|R
40|$|The growth {{incidence}} curve gives {{growth rates}} by <b>quantiles</b> <b>ranked</b> by income. Integrating this curve {{up to the}} headcount index of poverty gives {{a measure of the}} rate of "propoor growth" consistent with the Watts index for the level of poverty. Examples are given using survey data for China during the 1990 s. Key words: Economic growth, poverty measurement, China JEL: D 31, I 32, O 40 These are the views of the authors and should not be attributed to the World Bank or any affiliated organization. For their comments we are grateful to Aart Kraay and Tony Shorrocks. The data used here was were kindly provided by the Rural and Urban Household Survey Teams of China's National Bureau of Statistics. The support of a Dutch Trust Fund is gratefully acknowledged. Address for correspondence: mravallion@worldbank. org and schen@worldbank. org. 1...|$|R
40|$|Please do not cite or circulate– We {{develop a}} unified and {{tractable}} theory of sudden mass movements using a continuum agent timing game. We assume that an underlying payoff-relevant fundamental “ripens”, peaks at an optimal “harvest time”, and then “rots”. These payoffs are multiplied by a hill-shaped <b>quantile</b> <b>rank</b> reward that subsumes “greed” and “fear ” — namely, greed for greater rewards {{that come from}} outlasting others, andthefearof pre-emption. Inthissetting, westudythesymmetricNashequilibria. Three local timing games can occur: a slow war of attrition, a slow pre-emption game, and a sudden pre-emption game, or a “rush”. Rushes always exist, and are late with greedy players and early with fearful players. We relate measures of fear and greed, the timing and size of rushes, and the entry rate before and after rushes. Our theory provides an integrated understanding of seemingly unrelated phenomena, showing how unraveling in matching markets, liquidity runs on companies and financial bubbles all {{are part of the}} same class of problems. JEL Classification: C 73, D 81...|$|R
40|$|Quantile {{regression}} {{has become}} a powerful complement to the usual mean regression. A simple approach to use quantile regression in marginal analysis of longitudinal data is to assume working independence. However, this may incur potential efficiency loss. On the other hand, correctly specifying a working correlation in quantile regression can be difficult. We propose a new quantile regression model by combining multiple sets of unbiased estimating equations. This approach can account for correlations between the repeated measurements and produce more efficient estimates. Because the objective function is discrete and non-convex, we propose induced smoothing for fast and accurate computation of the parameter estimates, {{as well as their}} asymptotic covariance, using Newton-Raphson iteration. We further develop a robust <b>quantile</b> <b>rank</b> score test for hypothesis testing. We show that the resulting estimate is asymptotically normal and more efficient than the simple estimate using working independence. Extensive simulations and a real data analysis show the usefulness of the method...|$|R
40|$|We {{develop a}} unified and {{tractable}} theory of sudden mass movements using a continuum agent timing game. We assume that an underlying payoff-relevant fundamental “ripens”, peaks at an optimal “harvest time”, and then “rots”. These payoffs are multiplied by a hill-shaped <b>quantile</b> <b>rank</b> reward that subsumes “greed” and “fear ” — namely, greed for greater rewards {{that come from}} outlasting others, {{and the fear of}} pre-emption. In this setting, we study the symmetric Nash equilibria. Three local timing games can occur: a slow war of attrition, a slow pre-emption game, and a sudden pre-emption game, or a “rush”. Rushes always exist, and are late with greedy players and early with fearful players. We relate measures of fear and greed, the timing and size of rushes, and the entry rate before and after rushes. Our theory provides an integrated understanding of seemingly unrelated phenomena, showing how unraveling in matching markets, liquidity runs on companies and financial bubbles all are part of the same class of problems...|$|R
40|$|Sample <b>quantile,</b> <b>rank,</b> and outlyingness {{functions}} play long-established {{roles in}} univariate exploratory data analysis. In recent years, various multivariate generalizations have been formulated, among which the “spatial ” approach has become especially well developed, including fully affine equivariant/invariant versions with but modest computational burden (Möttönen and Oja, 1995, Chaudhuri, 1996, Vardi and Zhang, 2002, Serfling, 2010, and Oja, 2010). The only shortcoming of the spatial {{approach is that}} its robustness decreases to zero as the quantile or outlyingness level is chosen farther out from the center (Dang and Serfling, 2010). This is especially detrimental to exploratory data analysis procedures such as detection of outliers and delineation of the “middle ” 50 %, 75 %, or 90 % of the data set, for example. Here we develop suitably robust versions using a trimming approach. The improvements in robustness are illustrated and characterized using simulated and actual data. Also, as a byproduct of the investigation, a new robust, affine equivariant, and computationally easy scatter estimator is introduced...|$|R
40|$|We propose an {{encompassing}} {{test for}} non-nested linear quantile regression models {{and show that}} it has an asymptotic [chi] 2 distribution. It is also shown that the proposed test is a regression rank score test in a comprehensive model under conditional homogeneity. Our simulation {{results indicate that the}} proposed test performs very well in finite samples. Encompassing test Non-nested model <b>Quantile</b> regression <b>Rank</b> score test...|$|R
40|$|The finite-sample {{distributions}} {{of the regression}} quantile and of the extreme regression quantile are derived for a broad class of {{distributions of}} the model errors, even for the non-i. i. d case. The distributions are analogous to the corresponding distributions in the location model; this again confirms that the regression quantile is a straightforward extension of the sample quantile. As an application, the tail behavior of the regression quantile is studied. Order statistic Regression quantile Extreme regression <b>quantile</b> Regression <b>rank</b> scores Score function...|$|R
40|$|BACKGROUND: The Chronic Disease Score is a risk-adjustment metric {{based on}} age, gender, {{and history of}} {{dispensed}} drugs. We compared four versions of the score {{for their ability to}} predict hospitalization among members of eight health maintenance organizations nationwide. METHODS: The study included 29, 247 women age 45 years and older. Logistic regression models were constructed using rank quintile and rank decile indicators for each of four scores as predictors of hospitalization during the year after 1 October 1995. Discrimination and model fit were compared using several model properties including the C statistic and the odds ratio comparing highest with lowest quantiles. RESULTS: All Chronic Disease Score versions performed similarly, with the version that predicts total healthcare cost, proposed by Clark et al. (Med Care 1995; 33 : 783 - 795), performing somewhat better than the other three. The overall risk of hospitalization was 12 %. Individuals with higher <b>quantile</b> <b>ranks</b> had a higher risk of hospitalization. Among the Chronic Disease Score versions, the risk of hospitalization ranged from 4 % for the lowest decile to 27 - 29 % for the highest decile. Odds ratios comparing the highest with the lowest deciles ranged from 8. 9 to 10. 2. CONCLUSIONS: The Chronic Disease Score predicts hospitalization and therefore may be a useful indicator of baseline comorbidity for control of confounding...|$|R
40|$|This paper {{extends the}} concept of {{regression}} and autoregression <b>quantiles</b> and <b>rank</b> scores to a very general nonlinear time series model. The asymptotic linearizations of these nonlinear quantiles are then used to obtain the limiting distributions of a class of L-estimators of the parameters. In particular, the limiting distributions of the least absolute deviation estimator and trimmed estimators are obtained. These estimators {{turn out to be}} asymptotically more ef®cient than the widely used conditional least squares estimator for heavy-tailed error distributions. The results are applicable to linear and nonlinear regression and autoregressive models including self-exciting threshold autoregressive models with known threshold...|$|R
40|$|A drop in dispersion, F-ratio like, {{permutation}} test (D) for linear quantile regression estimates (0 ≤ τ ≤ 1) had relative power ≥ 1 {{compared to}} <b>quantile</b> <b>rank</b> score tests (T) for hypotheses on parameters {{other than the}} intercept. Power was compared for combinations of sample sizes (n = 20 − 300) and quantiles (τ = 0. 50 − 0. 99) where both tests maintained valid Type I error rates in simulations with p = 2 and 6 parameters in homogeneous and heterogeneous error models. The D test required two modifications of permuting residuals from null, reduced parameter models to maintain correct Type I error rates when null models were constrained through the origin or included multiple parameters. A double permutation scheme was used when null models were constrained through the origin and all but 1 of the zero residuals were deleted for null models with multiple parameters. Although there was considerable overlap in sample size, quantiles, and hypotheses where both the D and rank score tests maintained correct Type I error rates, we identified regions at smaller n and more extreme quantiles where {{one or the other}} maintained better error rates. Confidence intervals on parameters for an ecological application relating Lahontan cutthroat trout densities to stream channel width:depth were estimated by test inversion, demonstrating a smoother pattern of slightly narrower intervals across quantiles than those provided by the rank score test...|$|R
40|$|PurposeEnabling {{the quality}} {{assessment}} of radiotherapy {{to be made}} in daily practice, using the new software tool to analyze the simulation and portal images. MethodIn the registration of the anatomical structures as well as the irradiation fields, the features used as landmarks are the edges. The significant edge fragments must be chosen manually, but without showing any specific corresponding points. Field edges marked with wires in the simulation image are found fully automatically with the original combination of a dedicated line edge detector and a version of hierarchical, combined Hough transform. The registration is guided by the robust accuracy criterion using the modified Hausdorff distance measure. The only parameter of the measure – <b>quantile</b> <b>rank,</b> or share of data used in comparison – is not fixed, but evolves from 1 to 0 during the optimization of the accuracy. This has two advantages. 1 : The user can choose the result found for the share corresponding to the actual share of erroneous data in the images, which can be seen only after the results for all the possible ranks are known. 2 : The algorithm can avoid the local minima. The registration takes few seconds on a typical PC. The method has been implemented in a software tool which supports the complete process of measurement, and has been tested in clinical triais with positive result. ConclusionsThe modified Hausdorff distance measure with evolving rank is a good and efficient registration accuracy measure for quality assessment of radiotherapy based on the comparison of portal and simulation images...|$|R
40|$|We propose {{partially}} adaptive estimators of {{the trimming}} proportion [alpha] for the trimmed {{mean in the}} location modeling and for the trimmed least-squares estimator of Koenker and Bassett (1978) in the linear regression model. The adaptive estimators are based on Hájek's (1970) rank-based decision procedure which selects one of a finite family of distribution shapes and on its extension based on regression rank scores of Gutenbrunner and Jurecková (1992). The procedures are invariant to the location and scale in the location model and to the regression and scale in the regression model, respectively; hence {{there is no need}} of estimation of the pertaining parameters. Trimmed mean Trimmed least squares estimator Regression <b>quantile</b> Regression <b>rank</b> scores...|$|R
40|$|Suppose that, under a semiparametric model setting, one is {{interested}} in drawing infer-ences about a finite-dimensional parameter vector /? based on an estimating function. Generally a consistent point estimator /J for /? 0, the true value for /J, can be easily obtained by finding a root of the corresponding estimating equation. To estimate the variance of ft, however, may involve complicated and subjective nonparametric functional estimates. In this paper, a general and simple resampling method for inferences about jS 0 based on pivotal estimating functions is proposed. The new procedure is illustrated with the <b>quantile</b> and <b>rank</b> regression models. For both cases, our proposal can be easily and efficiently implemented with existing statistical software...|$|R
40|$|Government {{agencies}} must simultaneously maintain confidential-ity {{of individual}} records and disseminate useful microdata. We study options for creating full synthetic data files for public release. Specifically, we study combining quantile regression, hot deck impu-tation, and additional confidentiality-preserving methods to produce releasable, usable data. The {{result of the}} implementation of our ideas is a releasable data set containing original values for a few key vari-ables, synthetic values for several variables, and perturbed values for remaining variables. The procedure should simulataneously provide quality data to the user and protect the confidentiality of the respon-dents. In this paper we describe quantile regression, hot deck im-putation, and rank swapping and present results from an application of generating synthetic values using quantile regression for veterans data in the American Community Survey at the U. S. Census Bureau. KEY WORDS: Hot deck imputation; <b>quantile</b> regression; <b>rank</b> swap...|$|R
40|$|Discovering {{a bucket}} order B from a {{collection}} of possibly noisy full rankings is a fundamental problem that relates to various applications involving rankings. Informally, a bucket order is a total order that allows "ties" between items in a bucket. A bucket order B {{can be viewed as}} a "representative" that summarizes a given set of full rankings { 7 1, T 2,..., T m }, or conversely B can be an "approximation" of some "ground truth" G where the rankings {T 1, T 2, [...] ., T m } are the "linear extensions" of G. Current work of finding bucket orders such as the dynamic programming algorithm is mainly developed from the "representative" perspective, which maximizes items' Intra-bucket similarity when forming a bucket. The underlying idea of maximizing intra-bucket similarity is realized via minimizing the sum of the deviations of median ranks within a bucket. In contrast, from the "approximation" perspective, since each observed full ranking T i is simply a linear extension of the given "ground truth" bucket order G, items in a big bucket b in G are forced to have different median ranks, and as a result b will have a big sum of deviations. Thus, minimizing the sum of deviations may result in an undesirable scenario that big buckets are mostly decomposed into small ones. In this paper, we propose a novel heuristic called Abnormal Rank Gap to capture the inter-bucket dissimilarity for better bucket forming. In addition, we propose to use the "closeness" on multiple <b>quantile</b> <b>ranks</b> to determine if two items should be put into the same bucket. We develop a novel bucket order discovering method called the Bucket Gap algorithm. Our extensive experiments demonstrate that the Bucket Gap algorithm significantly outperforms the major related work, i. e., the Bucket Pivot algorithm. In particular, the error distance of the generated bucket order can be reduced by about 30 % on a real paleontological dataset and the noise tolerance can be increased from 30 % to 50 % in the synthetic dataset. © Copyright 2008 ACM...|$|R
40|$|Abstract A method {{called the}} Remainder Method is {{proposed}} for the calculation of sample quantiles of a given order, for example, quartiles, hexatiles, octatiles, deciles and percentiles assuming that all the observations are distinct. Proof is given for a special case of deciles. We propose the criterion of equisegmentation property {{that the number of}} observations below the first quantile, that between the consecutive quantiles, and that above the last quantile are the same. The formulae for quantiles offered by the proposed method satisfy the equisegmentation property, and more interestingly provide the number of <b>quantiles</b> having integer <b>ranks.</b> Some open problems are indicated...|$|R
40|$|Rather than attempt an encyclopedic {{survey of}} nonparametric and robust multivariate methods, we limit to a {{manageable}} scope {{by focusing on}} just two leading and pervasive themes, descriptive statistics and outlier identification. We set the stage with some perspectives, and we conclude {{with a look at}} some open issues and directions. A variety of questions are raised. Is nonparametric inference the goal of nonparametric methods? Are nonparametric methods more important in the multivariate setting than in the univariate case? Should multivariate analyis be carried out componentwise, or with full dimensionality, or pairwise? Do multivariate depth, outlyingness, <b>quantile,</b> and <b>rank</b> functions represent different methodological approaches? Can we have a coherent series of nonparametric multivariate descriptive measures for location, spread, skewness, kurtosis, etc., that are robust and accommodate heavy tailed multivariate data? Can nonparametric outlier identifiers be defined that do not require ellipsoidal contours? What makes an outlier identifier itself robust against outliers? Does outlyingness of a data point with respect to location estimation differ from its outlyingness with respect to dispersion estimation? How do univariate L-functionals extend to the multivariate setting? Does the transformation-retransformation approach pose any issues? How might we conceptualize multivariate descriptive measures and outlier identification methods with respect to arbitrary data spaces, for applications such as functional data analysis, shape fitting, and text analysis...|$|R
40|$|Health is an {{important}} dimension of welfare comparisons across individuals, regions or states. In the following paper {{we focus on the}} question whether the health status between geographical subunits (local communities) converged/diverged in the time period 1969 - 2004 in Austria. We use age standardized mortality rates as indicators for the health status and analyze the convergence/divergence of overall mortality for (i) the whole population, (ii) females, (iii) males and (iv) the gender gap in overall mortality. Convergence/Divergence is studied by applying different concepts of cross-regional inequality (weighted standard deviation, coefficient of variation, Theil-Coefficient of inequality). Various econometric techniques (weighted OLS, <b>Quantile</b> Regression, Kendall’s <b>Rank</b> Concordance) are used to test for absolute and conditional beta-convergence in mortality. We find mixed results for the applied inequality measures. Absolute and conditional beta-convergence are confirmed, both in weighted OLS as well as in Quantile Regression estimations, but we also find strong evidence for the existence of convergence clubs in mortality in Austria. JEL classification: I 10, I 12, I 1...|$|R
40|$|Unlike {{the real}} line, the d-dimensional space Rd, for d ≥ 2, is not canonically ordered. As a consequence, such {{fundamental}} and strongly order-related univariate concepts as quantile and distribution functions, and their empirical counterparts, involving ranks and signs, do not canonically {{extend to the}} multivariate context. Palliating that lack of a canonical ordering has remained an open problem {{for more than half}} a century, and has generated an abundant literature, motivating, among others, the development of statistical depth and copula-based methods. We show here that, unlike the many definitions that have been proposed in the literature, the measure transportation-based ones introduced in Chernozhukov et al. (2017) enjoy all the properties (distribution-freeness and preservation of semiparametric efficiency) that make univariate <b>quantiles</b> and <b>ranks</b> successful tools for semiparametric statistical inference. We therefore propose a new center-outward definition of multivariate distribution and quantile functions, along with their empirical counterparts, for which we establish a Glivenko-Cantelli result. Our approach, based on results by McCann (1995), is geometric rather than analytical and, contrary to the Monge-Kantorovich one in Chernozhukov et al. (2017) (which assumes compact supports or finite second-order moments), does not require any moment assumptions. The resulting ranks and signs are shown to be strictly distribution-free, and maximal invariant under the action of transformations (namely, the gradients of convex functions, which thus are playing the role of order-preserving transformations) generating the family of absolutely continuous distributions; this, in view of a general result by Hallin and Werker (2003), implies preservation of semiparametric efficiency. The resulting quantiles are equivariant under the same transformations, which confirms the order-preserving nature of gradients of convex function. info:eu-repo/semantics/publishe...|$|R
40|$|Several machine {{learning}} tasks require {{to represent the}} data using only a sparse set of interest points. An ideal detector is {{able to find the}} corresponding interest points even if the data undergo a transformation typical for a given domain. Since the task is of high practical interest in computer vision, many hand-crafted solutions were proposed. In this paper, we ask a fundamental question: can we learn such detectors from scratch? Since it is often unclear what points are "interesting", human labelling cannot be used to find a truly unbiased solution. Therefore, the task requires an unsupervised formulation. We are the first to propose such a formulation: training a neural network to rank points in a transformation-invariant manner. Interest points are then extracted from the top/bottom <b>quantiles</b> of this <b>ranking.</b> We validate our approach on two tasks: standard RGB image interest point detection and challenging cross-modal interest point detection between RGB and depth images. We quantitatively show that our unsupervised method performs better or on-par with baselines. Comment: Accepted at CVPR 201...|$|R
40|$|Equivariance and {{invariance}} issues arise as {{a fundamental}} but often problematic aspect of multivariate statistical analysis. For multivariate depth, outlyingness, <b>quantile,</b> and centered <b>rank</b> functions, which are closely related and highly important in modern nonparametric multivariate statistics, we provide coherent definitions of equivariance and invariance that unify and extend the somewhat ad hoc notions in the literature. With focus {{on the role of}} standardization of data in producing equivariant or invariant versions of such functions, we study three types of matrix-valued functional involved in standardizing multivariate data: “weak covariance ” (WC) (or ”shape”) functionals, “transformation-retransformation ” (TR) functionals, and “strong invariant coordinate system ” (SICS) functionals. The square roots of a WC functional are TR functionals, and SICS functionals form an important special case of TR functional. We rigorously clarify a particular well-established TR approach for constructing affine equivariant versions of the sample spatial quantile function and see that any choice of TR functional suffices for this purpose. Also, we see that artifacts of SICSstandardized data are invariant under affine transformation of the original data followed b...|$|R
40|$|Most {{climate models}} do not {{accurately}} reproduce present climate situation with similar statistics. This means that direct application of projected climate variables to hydrological models for impact analysis is implausible. In {{order to reach}} an adequate impact analysis of climate change, the support climate models should provide perturbation factors (PFs) or climate change signals that are consistent and account for the different aggregation dependency. This study uses the quantile perturbation analysis to explore the variation of PFs of rainfall intensities with respect to different aggregations, the model resolution and frequency, for three future IPCC emission scenarios (A 2, A 1 B and B 1) from eighteen Global Climate Models (GCMs). This approach ensures that the perturbations in the observed events are consistent with similarly ranked events in the climate model series. The GCM scenario <b>quantiles</b> are <b>ranked</b> from high to low values from current (1971 - 1990) conditions and compared to ranked data of GCM simulations for future (2049 - 2060 and 2081 - 2100) conditions. These ratios (PFs) were graphically analyzed for consistency, uncertainty, and dependency on frequency (return period) for the different rainfall aggregations. The PFs, derived from three GCMs (CGCM 3. 1 t 63, CM 2. 1 U. H 2 and CM 2. 0) outputs, are highly inconsistent with those derived from the other models for all the different rainfall aggregations considered and for both the 2050 s and 2090 s. Uncertainty in PFs, which depicts uncertainty in a given model, increases with increase in model temporal resolution. For most models, the PFs are above one and depend on the frequency for both the 2050 s and 2090 s and all three emission scenarios. For daily and monthly aggregations, the distributions of PFs tend to cluster around one for most models. The variation in PFs is higher for the lower quantiles for annual aggregation; but increases in the wet months than in the dry months for monthly aggregation. At daily aggregation, there are many outliers in the PFs for higher <b>ranked</b> <b>quantiles</b> {{for most of the}} GCMs. There is no evidence to suggest that the PFs are spatially dependent although CM 4. 1 model has shown significant variation from Katonga to Ruizi catchments. Models such as MK 3. 5, MK 3. 0 and ECHAM 5, with higher spatial resolutions, tend to have PFs close to or lower than one. Future rainfall intensities will be frequently higher than the present rainfall events in Katonga and Ruizi catchments for both the 2050 s and 2090 s. Although PFs can easily be derived from annual and monthly aggregations, the challenge of deriving climate change signals from daily climate model series, especially for dry days, for application to observed series, is still big. The resulting uncertainty is carried to hydrological models; leading to uncertain impact analysis. However, perturbation analysis is important in assessing consistent models and uncertainty in climate projections as given by the different GCMs. status: publishe...|$|R
40|$|With delight we most heartily congratulate Hallin, Paindaveine and Šiman (HPS) on {{a superb}} and {{stimulating}} paper. It uniquely impacts our thinking about regression quantiles, multivariate quantiles, and the halfspace depth. Here we examine this highly significant contribution from the standpoints of some perspectives on multivariate quantile and depth functions, some criteria {{to consider in}} choosing such functions, and some further points about the much-studied halfspace depth. We also raise a few technical issues and questions for consideration. General perspectives on quantile and depth functions. In thinking about any new contribution to multivariate quantile functions, we may draw upon the following perspectives, which also clarify the univariate case in some respects. (P 1) In multivariate analysis, orientation to a “center ” compensates {{for lack of a}} natural order. (P 2) In the context of quantiles, the role of “center ” is naturally given to the “median. ” (P 3) The inverse of a quantile function is not the distribution F but rather the rank function. (P 4) Depth, outlyingness, <b>quantile,</b> and <b>rank</b> functions are equivalent (DOQR paradigm). (P 5) Quantile functions are best viewed as parameters or characteristics of the distribution F. (P 6) Equivalence between distribution and quantile functions is not an essential requirement. Let us briefly elaborate on some of these points. (P 3). In the univariate case, a natural linear order makes it convenient and straightforward to define distribution and quantile functions as mutual inverses, F and F − 1. However, for extension to higher dimension, the equivalent medianoriented formulation is the most appropriate point of departure. That is, via u = 2 p − 1, the usual quantile function F − 1 (p), 0 <p< 1, may be represente...|$|R
40|$|This {{paper is}} {{dedicated}} to Regina Liu, who opened up the view of “depth functions ” as a broad and general approach. Abstract. Depth functions, as an emerging methodology in nonparametric multivariate inference, are reviewed in brief. The special relationships among depth, outlyingness, centered <b>rank,</b> and <b>quantile</b> functions are indicated. 1. Summary In passing from univariate to multivariate statistical analysis, especially {{for the purpose of}} nonparametric approaches, various issues and special considerations come into play. We examine some of these in Section 2 and address the question Where do depth functions fit into nonparametric multivariate inference? Section 3 gives an overview of depth functions with emphasis on their connections with outlyingness functions. We consider depth functions defined not only on the observation space, with orientation to nonparametric multivariate description, but also as defined on the parameter space, for example on the multivariate space of “regression fits ” in univariate multiple regression. Section 4 examines <b>quantile</b> and centered <b>rank</b> functions as entities closely related to each other and connects them with depth and outlyingness functions. Some brief historical notes are provided in Section 5 and a concluding remark in Section 6. 2. Nonparametric Multivariate Analysis To capture the setting for considering depth functions, let us examine some key perspectives that are relevant to the choice of a procedure in nonparametric multivariate analysis. Use of normal model versus nonparametric description. Parametric modeling of multivariate data enjoys few tractable models other than the normal...|$|R
40|$|AbstractMetastatic {{cancer of}} unknown primary (CUP) {{accounts}} {{for up to}} 5 % of all new cancer cases, with a 5 -year survival rate of only 10 %. Accurate identification of tissue of origin would allow for directed, personalized therapies to improve clinical outcomes. Our objective was to use transcriptome sequencing (RNA-Seq) to identify lineage-specific biomarker signatures for the cancer types that most commonly metastasize as CUP (colorectum, kidney, liver, lung, ovary, pancreas, prostate, and stomach). RNA-Seq data of 17, 471 transcripts from a total of 3, 244 cancer samples across 26 different tissue types were compiled from in-house sequencing data and publically available International Cancer Genome Consortium and The Cancer Genome Atlas datasets. Robust cancer biomarker signatures were extracted using a 10 -fold cross-validation method of log transformation, <b>quantile</b> normalization, transcript <b>ranking</b> by area under the receiver operating characteristic curve, and stepwise logistic regression. The entire algorithm was then repeated with {{a new set of}} randomly generated training and test sets, yielding highly concordant biomarker signatures. External validation of the cancer-specific signatures yielded high sensitivity (92. 0 % ± 3. 15 %; mean ± standard deviation) and specificity (97. 7 % ± 2. 99 %) for each cancer biomarker signature. The overall performance of this RNA-Seq biomarker-generating algorithm yielded an accuracy of 90. 5 %. In conclusion, we demonstrate a computational model for producing highly sensitive and specific cancer biomarker signatures from RNA-Seq data, generating signatures for the top eight cancer types responsible for CUP to accurately identify tumor origin...|$|R
40|$|Abstract Introduction Health is an {{important}} dimension of welfare comparisons across individuals, regions and states. Particularly from a long-term perspective, within-country convergence of the health status has rarely been investigated by applying methods well established in other scientific fields. In the following paper we study the relation between initial levels of the health status and its improvement at the local community level in Austria in the time period 1969 - 2004. Methods We use age standardized mortality rates from 2381 Austrian communities as an indicator for the health status and analyze the convergence/divergence of overall mortality for (i) the whole population, (ii) females, (iii) males and (iv) the gender mortality gap. Convergence/Divergence is studied by applying different concepts of cross-regional inequality (weighted standard deviation, coefficient of variation, Theil-Coefficient of inequality). Various econometric techniques (weighted OLS, <b>Quantile</b> Regression, Kendall's <b>Rank</b> Concordance) are used to test for absolute and conditional beta-convergence in mortality. Results Regarding sigma-convergence, we find rather mixed results. While the weighted standard deviation indicates an increase in equality for all four variables, the picture appears less clear when correcting for the decreasing mean in the distribution. However, we find highly significant coefficients for absolute and conditional beta-convergence between the periods. While these results are confirmed by several robustness tests, we also find evidence {{for the existence of}} convergence clubs. Conclusions The highly significant beta-convergence across communities might be caused by (i) the efforts to harmonize and centralize the health policy at the federal level in Austria since the 1970 s, (ii) the diminishing returns of the input factors in the health production function, which might lead to convergence, as the general conditions (e. g. income, education etc.) improve over time, and (iii) the mobility of people across regions, as people tend to move to regions/communities which exhibit more favorable living conditions. JEL classification: I 10, I 12, I 18 </p...|$|R
40|$|In the {{univariate}} set-up, quantiles {{are commonly}} used to describe various features of the distribution. They {{can also be used}} to construct quantile-quantile plots to compare two distributions. But there is no natural ordering in multidimension, and we cannot immediately generalize the definition of quantiles to the multivariate distributions. For Univariate Z, with E|Z | < ∞, the p-th quantile for 0 < p < 1 can be characterized by any value θ minimizing E{|Z − θ | + (2 p − 1) (Z − θ) }. Chaudhuri (1996) extends this definition by re-writing the above as E{|Z − θ | + u(Z − θ) }, where u = (2 p − 1). Thus, re-indexing the univariate p-th quantiles for p ∈ (0, 1) by u in the open interval (− 1, 1). Then d-dimensional quantiles are formulated by extending this index set to the d-dimensional open unit ball B d− 1 of radius 1 and defining the u-th quantile QF (u) of X ∈ R d as any minimizer of E{Φ(U, X − θ) − Φ(u, X) } where Φ(u, t) = ‖t ‖ + uT t, with ‖ · ‖ the usual Euclidian norm. Suppose X ∈ Rd is a random vector with distribution function F, which is absolutely continuous with respect to the Lebesgue measure. The multivariate spatial rank for a d-dimensional vector x with respect to X can be defined as, x − X RF (x) = EF ||x − X|| It can be noted that this rank function is the inverse of the quantile function, that is, and the spatial median solves the equation RF (QF (u)) = u RF (θ) = 0. The empirical versions of the <b>quantiles</b> and the <b>rank</b> functions can be obtained by replacing F by Fn, the empirical distribution function. ...|$|R
40|$|Quantile-quantile plots are in use {{to compare}} {{univariate}} distributions {{for a long}} time, but {{as there is no}} ordering in higher dimension, there is no straight forward generalisation of quantiles for the multivariate data and hence there is no visual tool which can be considered as a generalisation of quantile-quantile plots to compare multivariate distributions. In this work we have considered some notions of multivariate <b>ranks,</b> <b>quantiles</b> and data depths. Based on spatial rank, we have constructed central rank regions and some measures of scale. We proposed a scale-scale plot, which can be used to compare multivariate distributions. Under spherical symmetry, our scale curves have some nice closed form formula, however they are not equivariant under affine transformations. We discussed this issue with illustrations and proposed an affine equivariant version based on data-driven transformations. We established some characterisation results for the proposed affine equivariant scale curves under elliptic symmetry and used the fact to propose some visual test of location and scale in the family of elliptically symmetric distributions. Our proposed scale-scale plot is based on volume functionals of central rank region. We gave some asymptotic results regarding the distribution of the volume functional and constructed a test statistic based on the volume functional. We proposed some asymptotic results regarding the distribution of the test statistic and also studied the power of the proposed test of multivariate normality. As further applications to our scale-scale plots, we discuss the behaviour of our proposed scale-scale plots when the distribution is not elliptically symmetric with illustrations and study the power of the test of for skew elliptic and g and h distribution based on the previously defines test statistic. Among other application of the scale-scale plots, we propose a kurtosis plot, which can be used to study the peakedness and tail behaviour of the multivariate distributions, a visual test of location and scale. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|La loi exponenti{{elle est}} très répandue en hydrologie : elle est faiblement paramétrée, de mise en œuvre aisée. Deux méthodes sont fréquemment utilisées pour estimer son paramètre : la méthode du maximum de vraisemblance et la méthode des moments, qui fournissent la même estimation. A côté de ces deux méthodes, il y a celle des moindres carrés qui est très rarement utilisée pour cette loi. Dans cet article, nous comparons le {{comportement}} asymptotique de l'estimateur de la méthode des moindres carrés avec celui de la méthode du maximum de vraisemblance en partant d'une loi exponentielle à un seul paramètre a connu, puis en généralisant les résultats obtenus à partir de la dérivation des expressions analytiques. L'échantillon historique disponible en pratique étant unique, et de longueur généralement courte par rapport à l'information que l'on désire en tirer, l'étude des propriétés statistiques des estimateurs ne pourra se faire qu'à partir d'échantillons de variables aléatoires représentant des réalisations virtuelles du phénomène hydrologique concerné obtenus par simulations de Monte Carlo. L'étude par simulation de Monte Carlo montre que pour de faibles échantillons, l'espérance mathématique des deux estimateurs tend vers le paramètre réel, et que la variance de l'estimateur des moindres carrés est supérieure à celle de l'estimateur du maximum de vraisemblance. Exponential distributions are frequently applied in hydrology, for example: frequency {{analysis of the}} duration and severity of water flow conditions MATHIEU L. and al. (1991); regional frequency of storm intensities ARNAUD P., LAVABRE J. (1999); partial duration of hydrological droughts KJELDSEN T. R. and al. (1999); and daily rainfall modelling CHAPMAN T. G. (1997); KABAILI Z. (1983). This method has only one parameter, and {{it is easy to}} use. Its parameter is mainly estimated using the maximum likelihood estimator (MLE) or the method of moments estimator (MOME), but the least square estimator (LSE) can also be applied. For the one-parameter exponential distribution, MOME and MLE give the same expression for the parameter:         Ex         Σ xk         k = 1 X^ 0 = ________         ExUsing LSE requires a Ex size sample of exponential variables and involves the following steps: 1. Sorting the Ex variables in the sample in ascending order 2. Associating to each <b>quantile</b> xk whose <b>rank</b> is k in the sorted sample an empirical frequency F^k = k - 0. 5 / Ex 3. Plotting Ex against ln(1 -F^k) and using LSE to calculate x^ 0 by :x^ 0 = - (ExΣk= 1 Xk ln(1 -F^k)) / (ExΣk= 1 [ln(1 -F^k) ] 2 In this paper we compare the asymptotic behaviour of the statistical properties (mean and variance) of the MLE and the LSE. These comparisons must be made by using a great number of sample parameter estimations. In practice, only one historical sample of variables issued from a known exponential distribution was available, from which only one parameter can be calculated. To overcome this difficulty, samples of variables whose original theoretical exponential distribution is known are generated using the Monte Carlo numerical method. Samples of estimated parameters (using the MLE or the LSE) are then created from the above samples of random variables, and the statistical properties of the two estimators are then calculated. These different successive steps are summarised below: 1. Generate sample of finite size Ex for known exponential variables 2. Use this sample to estimate one parameter using MLE or LSE 3. Do steps 1 to 2 Np times to collect a Np size sample of parameter estimations 4. Use this sample to calculate statistical properties (mean and variance) for the two estimators. According to this approach, sizes Ex and Np should influence the statistical properties of the two estimators. We have verified this with a one-parameter exponential law, with a known theoretical parameter X 0 = 1. Samples of estimated parameters of size Np have been generated from virtual samples of size Ex issued from a population following the above statistical distribution. During this operation, one of these sizes, Ex or Np, has been held constant, while the other, Np or Ex, changed with a constant step. Statistical properties of the estimators have then been calculated for each of the two cases. Let Var Ex (x^ 0 (Np)) and EEx (x^ 0 (Np)) be statistical properties (variance and mean) of the two estimators for fixed values of Ex, and VarNp(x^ 0 (Ex)) and ENp(x^ 0 (Ex)), the same statistical properties for fixed values of Np. Plotting VarEx(x^ 0 (Np)) for Ex= 10 and Ex= 100 shows that for large values of Np (1000 to 5000) variance tends towards a constant value, close to 0. 1 for Ex= 10 (Fig. 1 a) and to 0. 01 for Ex= 100 (Fig. 1 b), both equal to 1 /Ex, when the MLE is used. When parameters are estimated with the LSE, variance tends towards a constant value, greater than the preceding ones (Fig. 1 a and Fig. 1 b). Plotting VarNp(x^ 0 (Ex)) when Np= 1000 is constant, the variance decreases as Ex grows whatever the estimator, but for a given value of Ex, the variance is always greater when the LSE is used (Fig. 3). These two calculations show that asymptotic variance depends only on size Ex of samples of known exponential distribution. Plotting EEx(x^ 0 (Np)) when Ex= 10, for important values of Np, the mean is close to the true parameter for the MLE, and greater than this true parameter for the LSE (Fig. 2 a). When Ex= 100, the mean is close to the true parameter for the two estimators (Fig 2 b). From these calculations we notice that the asymptotic mean depends only on the size of Ex for known exponential variables and on the used estimator. The MLE seems to present no bias for the mean, while the LSE presents a bias for small values of Ex, but this bias disappears as Ex increases. To quantify this degree of dependence, we have plotted ENp(x^ 0 (Ex)) for Np= 1000 (Fig. 4). For the two estimators, the mean presents an initial bias, when Ex is low and the bias disappears when Ex becomes higher. The initial bias is more important with the LSE. In summary, the asymptotic statistical properties of the two estimators (mean and variance) depend only on the size of Ex for known exponential distribution variables. Empirical plots are unstable for low sample sizes, are sensitive to sampling, and are very difficult to explain. Analytical expressions for the asymptotic statistical properties of the two estimators are needed for realistic comparison. According to formulae (1) and (2), statistical properties depend on E∞(Xk) and E∞(X 2 k) respectively and the asymptotic mean of Xk and X 2 k. E∞(Xk) and E∞(X 2 k) have been derived using the density of probability of Xk through statistics of rank. Asymptotic statistical properties of the two estimators have then been evaluated using the expressions of E∞(Xk) and E∞(X 2 k). We let E∞[x^ 0 (Ex) ] be the asymptotic mean of estimator, Var∞[x^ 0 (Ex) ] be the asymptotic variance, and x 0 be the theoretical parameter of exponential distribution. By plotting E∞[x^ 0 (Ex) ] for X 0 = 1, we note that this expression has a constant value, equal to unity when the MLE was applied, and that it decreases quickly to unity when the LSE was applied (Fig. 6). By plotting Var∞[x^ 0 (Ex) ] for x 0 = 1, we also note that the theoretical asymptotic variance diminishes as Ex grows, but is greater when the LSE was applied (Fig. 5). By comparing with empirical plots when x 0 = 1, we establish the same trends. Theoretical derivations of asymptotic statistical proprieties have confirmed empirical experiences: · The MLE for a one-parameter exponential presents no bias · The LSE for a one-parameter exponential is a consistent estimator of the simple exponential parameter...|$|R

