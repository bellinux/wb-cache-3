60|92|Public
5000|$|If {{identification}} was uncertain, the Allied patrol {{could make}} a plain language radio query to shore and expect a reply within a few minutes. The <b>query</b> <b>format</b> was: ...|$|E
50|$|Unlike the better-known ODBC, DataLens {{did not use}} SQL in {{the query}} interface. The API {{was based on a}} variety of data {{structures}} that were interpreted by the database drivers into their own internal <b>query</b> <b>format</b> - including SQL in some cases. In contrast, ODBC used SQL as its basic interface, and interpreted and translated it in the driver for those data sources that did not use SQL.|$|E
50|$|Keyword-based data {{aggregation}} services like the Bioinformatic Harvester performs provide reports {{from a variety}} of third-party servers in an as-is format so that users need not visit the website or install the software for each individual component service. This is particularly invaluable given the rapid emergence of various sites providing different sequence analysis and manipulation tools. Another aggregative web portal, the Human Protein Reference Database (Hprd), contains manually annotated and curated entries for human proteins. The information provided is thus both selective and comprehensive, and the <b>query</b> <b>format</b> is flexible and intuitive. The pros of developing manually curated databases include presentation of proofread material and the concept of ‘molecule authorities’ to undertake the responsibility of specific proteins. However, the cons are that they are typically slower to update and may not contain very new or disputed data.|$|E
3000|$|... ● Query Processor and Interface: The module is {{actually}} a human-machine interface. Users’ intension must be properly expressed using some <b>query</b> <b>formats</b> such as SPARQL or XQuery [26] that can query the metadata repository directory. The processor will execute and return the query result back to users. In the module, a ranking mechanism based {{on the nature of}} Semantic Web, which is out of the scope of this article, might be necessary {{in order to determine the}} relevance of results to users’ intension.|$|R
5000|$|When {{a random}} oracle is used within a {{security}} proof, {{it is made}} available to all players, including the adversary or adversaries. A single oracle may be treated as multiple oracles by pre-pending a fixed bit-string {{to the beginning of}} each <b>query</b> (e.g., <b>queries</b> <b>formatted</b> as [...] "1|x" [...] or [...] "0|x" [...] can be considered as calls to two separate random oracles, similarly [...] "00|x", [...] "01|x", [...] "10|x" [...] and [...] "11|x" [...] can be used to represent calls to four separate random oracles).|$|R
40|$|Apache Spark is {{a popular}} {{framework}} for large-scale data analytics. Unfortunately, Spark's performance {{can be difficult to}} optimise, since queries freely expressed in source code are not amenable to traditional optimisation techniques. This article describes Hylas, a tool for automatically optimising Spark queries embedded in source code via the application of semantics-preserving transformations. The transformation method is inspired by functional programming techniques of "deforestation", which eliminate intermediate data structures from a computation. This contrasts with approaches defined entirely within structured <b>query</b> <b>formats</b> such as Spark SQL. Hylas can identify certain computationally expensive operations and ensure that performing them creates no superfluous data structures. This optimisation leads to significant improvements in execution time, with over 10, 000 times improvement observed in some cases...|$|R
40|$|Due to {{the growing}} amount of digital media an {{increasing}} need to automatically categorize media such as music or pictures has been emerged. One of the metadata standards that has been established to search and retrieve media is MPEG- 7. But it does not yet exist a <b>query</b> <b>format</b> that enables the user to query multimedia metadata databases. Therefore the MPEG committee decided to instantiate a call for proposal (N 8220) for an MPEG- 7 <b>query</b> <b>format</b> (MP 7 QF) framework and specified a set of requirements (N 8219). This paper introduces a MP 7 QF framework and describes its main components and associated MP 7 QF XML schema types. The framework makes use of the MPEG- 21 digital item declaration language (DIDL) for exchanging MP 7 QF Items along various MP 7 QF frameworks and client applications. An MP 7 QF Item acts as container for the input <b>query</b> <b>format</b> and output <b>query</b> <b>format</b> of a user query request. This paper concentrates on components of the framework such as session management, service retrieval and its usability and excludes consciously definitions and explanations of the input and output <b>query</b> <b>format.</b> ...|$|E
30|$|H path ς(H[*]=[*](|Y 1 |, |Y 2 |, …|Yn|, ∂(H), σ(H) includes H <b>query</b> <b>format,</b> {{retrieval}} format, and Y file length information.|$|E
40|$|Abstract. This paper {{presents}} a standards-based architecture for {{a complex and}} generic distributed multimedia scenario, which combines content search and retrieval, DRM, and context-based content adaptation together. It is an innovative and totally generic approach trying to narrow the semantic-gap by integrating a flexible language for multimedia search based on MPEG <b>Query</b> <b>Format</b> (MPQF) standard with the application of video analysis algorithms for the automatic extraction of low-level features and {{with the use of}} contextual information. Keywords: Context-based adaptation, Digital Rights Management-Rights Expression Language, Features extraction, MPEG <b>Query</b> <b>Format...</b>|$|E
40|$|NoSQL {{data storage}} systems {{have become very}} popular due to their {{scalability}} and ease of use. This paper examines the maturity of security measures for NoSQL databases, addressing their new query and access mechanisms. For example {{the emergence of new}} <b>query</b> <b>formats</b> makes the old SQL injection techniques irrelevant, but are NoSQL databases immune to injection in general? The answer is NO. Here we present a few techniques for attacking NoSQL databases such as injections and CSRF. We analyze the source of these vulnerabilities and present methodologies to mitigate the attacks. We show that this new vibrant technological area lacks the security measures and awareness which have developed over the years in traditional RDBMS SQL systems. Comment: In Proceedings of the 9 th Workshop on Web 2. 0 Security and Privacy (W 2 SP) 201...|$|R
5000|$|The basic BiblioCore {{search box}} is built with {{automatic}} relevance ranking algorithms, data mapping, faceted searches, natural language detection, and a [...] "did-you-mean?" [...] functionality to make searching the online public library catalog {{easier and more}} intuitive. Advanced searches allow a user to narrow down their <b>query</b> by <b>format,</b> location, availability, topic, publication date, tag, and more.|$|R
40|$|In {{this paper}} a new method for distributing and {{updating}} host name/address information in large computer networks is described. The technique uses datagrams {{to provide a}} simple transaction-based query/response service. A provisional service is being provided by the Arpanet Network Information Center (NIC) and is used by mobile packet radio terminals, {{as well as by}} several Arpanet DEC- 10 hosts. Extensions to the service are suggested that would expand the query functionality to allow more flexible <b>query</b> <b>formats</b> as well as queries for service addresses. Several architectural approaches with potential for expansion into a distributed internet environment are proposed. This technique may be utilized in support of other distributed applications such as user identification and group distribution for computer based mail. 1. INTRODUCTION In large computer networks, such as the Arpanet [1], network-wide standard host-addressing information must be maintained and distributed. To fu [...] ...|$|R
40|$|Abstract. The MPEG <b>Query</b> <b>Format</b> (MPQF) {{is a new}} {{standard}} from the MPEG standardization committee which provides a standardized interface to multimedia document repositories. The {{purpose of this paper}} is describing the necessary modifications which will allow MPQF to manage metadata modelled with Semantic Web languages like RDF and OWL, and query constructs based on SPARQL. The suggested modifications include the definition of a new MPQF query type, and a generalization of the MPQF metadata processing model. As far as we know, this is the first work to apply the MPEG <b>Query</b> <b>Format</b> to semantic-driven search and retrieval of multimedia contents. ...|$|E
40|$|The paper {{presents}} {{an approach to}} achieving interoperability of dialogue act annotations through developing a <b>query</b> <b>format</b> for accessing existing annotated corpora. The interpretation of expressions in the <b>query</b> <b>format</b> implements a mapping from ISO 24617 - 2 concepts to those of several existing annotation schemes. This approach is tested on two important types of existing dialogue corpora: spoken two-person dialogue corpora collected and annotated within the HCRC Map Task paradigm, and multiparty face-to-face dialogues of the AMI corpus. Additionally, we provide a mapping between ISO 24617 - 2 concepts and DAMSL-based taxonomies. We present the results and evaluate them with respect to accuracy and completeness trough statistical comparisons between retrieved and manually constructed reference annotations...|$|E
40|$|In recent years, {{the amount}} of Internet {{accessible}} digital audiovisual media files has vastly increased. Therefore the need to describe the media (by way of metadata) has also increased significantly. MPEG- 7 (finalized in 2001) provides a comprehensive and rich metadata standard for the description of multimedia content. Unfortunately, a standardized <b>query</b> <b>format</b> does not exist for MPEG- 7, or other multimedia metadata. Such a standard would provide for communications between querying clients and databases, supporting cross-modal and cross-media retrieval. The lSO/lEC SC 29 WG 11 committee decided therefore to contribute to this application space by adding such functionality as a new part of the MPEG- 7 series of standards. In response to a Call for Proposals, six proposals were submitted. This paper describes the strengths of each proposal {{as well as the}} resulting draft standard for the MPEG- 7 <b>query</b> <b>format...</b>|$|E
5000|$|Although {{intended}} for the British audience in India, as were numerous other such publications of the time, it was Indians who provided {{almost all of the}} content for the revised Notes and <b>Queries</b> <b>format.</b> One in particular featured heavily: Pandit Ram Gharib Chaube. An eager Indian scholar, Chaube first contributed in 1892 and thereafter his input accounted for around a third of each edition, which was rather more than even Crooke supplied. It initially maintained Temple's coverage of a vast range of subjects, from antiquities through folklore, philology, history, numismatology, ethnology, sociology and religion, as well as examining fields such as arts and manufacture. However, the focus soon narrowed to cover four subject areas, being religion, anthropology, folktales and miscellany. The folktales section had been renamed from [...] "folklore" [...] and its emphasis changed from documenting ancient remedies and suchlike to recording traditional stories.|$|R
40|$|Users of {{information}} retrieval (IR) systems require an interface that is powerful and easy-to-use {{in order to}} fulfill their information requirement. In XML-IR systems this is a non-trivial task since users expect these systems to fulfill both their structural and content requirements. Most existing XML-IR systems accept <b>queries</b> <b>formatted</b> in formal <b>query</b> languages, however, these languages are difficult to use. This paper presents NLPX – an XML-IR system with a natural language interface that is user friendly enough so it can be used intuitively, but sophisticated {{enough to be able to}} handle complex structured queries. NLPX accepts English queries that contain both users’ content and structural requirements. It uses a set of grammar templates to derive the structural and content requirements and translates them into a formal language (NEXI). The formal language queries can then be processed by many existing XML-IR systems. The system was developed for participation in the NLP Track of the INEX 2004 Workshop, and results indicated that natural language interfaces are able to capture users’ structural and content requirements, but not as accurately as some formal language interfaces...|$|R
5000|$|Chaube {{was from}} the eastern North-Western Provinces and an {{intelligent}} scholar with a BA from Presidency College in Calcutta. His first collaboration with William Crooke {{appears to have been}} in 1892 when he provided information for North Indian Notes and Queries. Crooke had recently taken control of that journal from Richard Carnac Temple and had renamed it from the original title of Punjab Notes and Queries. Although intended for the British audience in India, as were numerous other such publications of the time, it was Indians who provided almost all of the content for the revised Notes and <b>Queries</b> <b>format</b> that Sadhana Naithani believes demonstrates [...] "the emergence and growth of that brand of ethnography for which Crooke should be better known and in which he differs from most other colonial ethnographers." [...] The defining feature of the journal, which was based heavily on folklore, was that it considered its subjects {{in the context of the}} popular culture of the present day rather than dwelling on the past.|$|R
40|$|Registration Data Access Protocol (RDAP) <b>Query</b> <b>Format</b> This {{document}} describes uniform {{patterns to}} construct HTTP URLs {{that may be}} used to retrieve registration information from registries (including both Regional Internet Registries (RIRs) and Domain Name Registries (DNRs)) using "RESTful " web access patterns. These uniform patterns define the query syntax for the Registration Dat...|$|E
40|$|MPEG) {{published}} the ISO/IEC 15938 - 12 standard, i. e. the MPEG <b>Query</b> <b>Format</b> (MPQF), providing a uniform search&retrieval interface for multimedia repositories. While the MPQF’s coverage of basic retrieval functionalities is unequivocal, it’s suitability for advanced retrieval tasks {{is still under}} discussion. This paper analyzes how MPQF addresses four of the most relevant approaches fo...|$|E
40|$|Today the {{availability}} of digital media content is well established and widespread. Not only commercial content distribution is a big market, but also user driven digital multimedia content is produced and shared in big communities. One of the metadata standards that has been established to describe multimedia content via metadata is MPEG- 7. This international standard facilitates many application domains and is probably the richest multimedia metadata set available today. However it does not yet exist a common <b>query</b> <b>format</b> that enables the user to query multimedia metadata databases. Therefore the MPEG committee decided to instantiate a call for proposal (N 8220) for an MPEG- 7 <b>query</b> <b>format</b> (MP 7 QF) framework and specified a set of requirements (N 8219). This paper introduces a MP 7 QF query language and describes the background and requirements {{as well as the}} main architectural concepts and associated MP 7 QF XML schema types...|$|E
5000|$|The udisks2 daemon [...] {{serves as}} an {{interface}} to system block devices, implemented via D-Bus. It handles operations such as <b>querying,</b> mounting, unmounting, <b>formatting,</b> or detaching storage devices such as hard disks or USB thumb drives. This package also provides the [...] utility, {{which can be used}} to trigger these operations from the command line (if permitted by PolicyKit).|$|R
40|$|Abstract. Semantic Web {{technologies}} are being widely applied in life sciences. Major bioinformatics data centers started to provide heterogeneous biomedical datasets in RDF and expose them at SPARQL endpoints. SPARQL query {{is used to}} search those endpoints {{and the results are}} obtained as a SPARQL <b>Query</b> Results XML <b>Format</b> or a SPARQL <b>Query</b> Results JSON <b>Format,</b> both are essentially tabular structured data. To effectively represent the SPARQL results, appropriate visualization methods are highly demanded. To create and control dynamic graphical representation of data on the Web, the D 3. js JavaScript library is getting popularity as a generic framework based on the widely accepted Web standards such as SVG, JavaScript, HTML 5 and CSS. A variety of visualization examples implemented with the D 3. js library is already available, however, each of them depends on assumed JSON data structure that differs from the JSON structure returned from SPARQL endpoints. Therefore, it is expected to largely reduce development costs of Semantic Web visualization if a JavaScript library is available which transforms SPARQL <b>Query</b> Results JSON <b>Format</b> into JSON data structures consumed by the D 3. js. D 3 SPARQL is developed as a generic JavaScript library to fill this gap. D 3 SPARQL can be used to query SPARQL endpoints as an AJAX call and provides various callback functions to visualize the obtained results. Biological applications will be shown in this software demo along with our integrated semantic genome database, the TogoGenome application. The D 3 SPARQL library is freely available a...|$|R
40|$|AbstractBiological {{databases}} {{are highly}} decentralized, having {{a high degree}} of difference in terminologies, feature fields, data representation and <b>query</b> <b>formats.</b> This is coupled by the problem of performing multi-database queries manually. Requirement arises therefore to automate the integration of biological databases that do much more than just retrieve and modify data. Speeding up the discovery of new medications and the introduction of new drugs in the market are some additional expectations out of such automation. Feature fields of different biological databases have different formats. To bind a meta-feature to the different feature formats under the same integration platform matching qualifiers is required for the different features. Integration requires binding formats with different databases concurrently, but the high dimensionality and redundancy of the qualifiers makes such integration impossible. Evolutionary selection algorithms have already been applied to reduce high dimensionality in microarray gene expression patterns. Given the similar qualifier redundancy and high qualifier dimensionality for biological databases such as EMBL, GENBANK and DDBJ, multi objective Genetic Algorithm applied to find qualifier reducts is not a misnomer. In feature binding initially Rough set theory is applied to find the initial population of qualifier reduct. Multi Objective Genetic Algorithm (NSGA-II) is run over this population to obtain the exact qualifier reduct. A feature set is categorized with the help of this qualifier reduct. Having done that, the problem of retrieving or manipulating data from a decentralized biological database is addressed in the Search & Retrieve algorithm, where stochastic and machine learning techniques have been used to find high probable warehouses where the data is indexed...|$|R
40|$|One of {{the latest}} {{developments}} of the MPEG committee is the <b>Query</b> <b>Format</b> for search and retrieval of multimedia content. This language constitutes the interface between a client and a search engine for searching multimedia data. Another possible scenario {{is the use of}} a service provider, which accepts and understands a query from a client and forwards parts of the query to one or more specific databases. Furthermore the service provider is able to retrieve the reply from these databases and post processes this result in order to send it to this client. During the last years, the cross-modal search of video and audio signals became more and more important, since using both, the video and the audio signal together turned out to be much more robust for identification of video streams, than the image part of the video alone. This paper describes a cross-modal search based on the MPEG <b>Query</b> <b>Format,</b> using a service provider for splitting and aggregating the query and two different types of databases...|$|E
40|$|ABSTRACT: In recent years, {{the growing}} number of digital {{audiovisual}} media files available over the internet or even on users hard discs is overwhelming. In order to support efficient storage and retrieval of those data, several comprehensive and rich multimedia retrieval systems (MMRS) have been introduced. Unfortunately, a standardized <b>query</b> <b>format</b> does not yet exist and almost every retrieval framework provides its own proprietary solution. Therefore, the ISO/IEC SC 29 WG 11 committee decided to contribute to this application by establishing the MPEG <b>Query</b> <b>Format</b> (MPQF). The MPQF is currently in Final Committee Draft (FCD) status and provides besides the standardization of messages from and to multimedia services also functionalities for service discovery, aggregated services and definition of service capability descriptions. In this context, the paper briefly introduces the MPQF and concentrates thereby on the management part. Based on this, a Web Service based framework is presented that realizes the management functionalities of MPQF. One of its central novel features is the distribution of a MPQF request to multiple multimedia services and the aggregation of individual result sets...|$|E
40|$|Abstract: This paper {{presents}} a standards-based architecture for {{a complex and}} generic distributed multimedia scenario, which combines content search and retrieval, DRM, and contextbased content adaptation together. It is an innovative and totally generic approach trying to narrow the semanticgap by integrating a flexible language for multimedia search based on MPEG <b>Query</b> <b>Format</b> (MPQF) standard with the application of video analysis algorithms for the automatic extraction of lowlevel features and {{with the use of}} contextual information. Categories and Subject Descriptor...|$|E
40|$|We {{describe}} PicASHOW, a {{fully automated}} WWW {{image retrieval system}} {{that is based on}} several link-structure analyzing algorithms. Our basic premise is that a page # displays (or links to) an image when the author of # considers the image to be of value to the viewers of the page. Wethus extend some well known link-based WWW #### ######### schemes to the context of image retrieval. PicASHOW's analysis of the link structure enables it to retrieve relevant images even when those are stored in les with meaningless names. The same analysis also allows it to identify ##### ########## and ##### ####. We dene these as Web pages that are rich in relevant images, or from which many images are readily accessible. PicASHOW requires no image analysis whatsoever and no creation of taxonomies for pre-classication of the Web's images. It can be implemented by standard WWW search engines with reasonable overhead, in terms of both computations and storage, and with no change to user <b>query</b> <b>formats.</b> It can thus be used to easily add image retrieving capabilities to standard search engines. Our results demonstrate that PicASHOW, while relying almost exclusively on link analysis, compares well with dedicated WWW image retrieval systems. We conclude that link analysis, a bona-de eective technique for Web page search, can improve the performance of Web image retrieval, as well as extend its denition to include the retrieval of image hubs and containers. Keywords Image Retrieval; Link Structure Analysis; Hubs and Authorities; Image Hubs. 1...|$|R
40|$|During {{the past}} five years the design, implementation, and {{evaluation}} of joint algorithms that exploit large main memories and parallel processors has received a great deal of attention. However, the methods used to represent join queries and their corresponding effects on performance has received little attention during this same time span. In this paper we examine the tradeoffs imposed by left-deep, right-deep and gushy query trees in a multiprocessor environment. Specifically, we address potential parallelism, memory consumption, support for dataflow processing, and the cost of optimization that are dictated by a particular <b>query</b> tree <b>format.</b> Results indicate that for hash-based join algorithms, right-deep query trees provide the best potential to exploit large multiprocessor database machines...|$|R
5000|$|The FRS is {{available}} through an EPA website called the [...] "Envirofacts Data Warehouse." [...] Facilities can be <b>queried</b> in tabular <b>format,</b> with active links to program databases that contain regulatory data, such as the Discharge Monitoring Report used in the water pollution permit program. FRS, through the Envirofacts site, offers a geospatial download service in various GIS file formats to allow greater access to the facility data.|$|R
40|$|The {{growth of}} {{multimedia}} is increasing {{the need for}} standards for accessing and searching distributed repositories. The moving picture experts group (MPEG) is developing the MPEG <b>query</b> <b>format</b> (MPQF) to standardize this interface as part of MPEG- 7. The objective is to make multimedia access and search easier and interoperable across search engines and repositories. This article describes the MPQF and highlights {{some of the ways}} it goes beyond today&# 039;s query languages by providing capabilities for multimedia query-by-example and spatiotemporal queries...|$|E
40|$|Query-by-humming systems {{attempt to}} address the needs of the {{non-expert}} user, for whom the most natural <b>query</b> <b>format</b> [...] for the purposes of finding a tune, hook or melody of unknown providence [...] is to sing it. While human listeners are quite tolerant of error in these queries, a music retrieval mechanism must explicitly model such errors in order to perform its task. We will present a unifying view of existing models, illuminating the assumptions underlying their respective designs, and demonstrating where such assumptions succeed and fail, through analysis and real-world experiments. ...|$|E
40|$|International audienceBillions of new {{images are}} {{generated}} daily. However, {{the management and}} exchange ofthe associated metadata remains cumbersome. Therefore, the Joint PhotographicExperts Group (JPEG) has recently promoted {{a new set of}} technologies enabling theinteroperability between image repositories and/or their clients to an internationalstandard. JPSearch is a suite of specifications that supports the enrichment withmetadata data stored in JPEG or JPEG 2000 image formats. It addresses schema andontology building blocks, a <b>query</b> <b>format,</b> a file format for metadata embedded in imagedata, and a data interchange format for image repositories...|$|E
2500|$|Queries are the {{mechanisms}} that Jet uses to retrieve {{data from the}} database. They can be defined in Microsoft QBE (Query By Example), through the Microsoft Access SQL Window or through Access Basic's Data Access Objects (DAO) language. These are then converted to an SQL SELECT statement. The query is then d [...] this involves parsing the query (involves syntax checking and determining the columns to query in the database table), then converted into an internal Jet <b>query</b> object <b>format,</b> which is then tokenized and organised into a tree like structure. In Jet 3.0 onwards these are then optimised using the Microsoft Rushmore query optimisation technology. The query is then executed and the results passed back to the application or user who requested the data.|$|R
30|$|Queries {{to search}} engines were {{extracted}} from the BL, by identifying URL requests from search engines. Following [41], (1) we extracted the set of host names from the BL by analyzing all URL requests; (2) we identified the set of hosts relating to search services; (3) for each search service, we identified how <b>queries</b> were <b>formatted</b> in URL requests, and removed any auto-completion and auto-suggestions URLs at this step; (4) we extracted the final queries by using regular expressions and pattern-matching. In total, 345 queries were extracted, served by 15 search engines, including Google, Yahoo, searchmobileonline, Twitter, SMH (Australian Breaking News Headlines & World News Online), Ninemsn, Taobao, Amazon, a search engine of the mall’s own website, saksfifthavenue, Vogue, Ticketek, shuuemura-usa, Vodafone, and Macys.|$|R
5000|$|Queries are the {{mechanisms}} that Jet uses to retrieve {{data from the}} database. They can be defined in Microsoft QBE (Query By Example), through the Microsoft Access SQL Window or through Access Basic's Data Access Objects (DAO) language. These are then converted to an SQL SELECT statement. The query is then d [...] - [...] this involves parsing the query (involves syntax checking and determining the columns to query in the database table), then converted into an internal Jet <b>query</b> object <b>format,</b> which is then tokenized and organised into a tree like structure. In Jet 3.0 onwards these are then optimised using the Microsoft Rushmore query optimisation technology. The query is then executed and the results passed back to the application or user who requested the data.|$|R
