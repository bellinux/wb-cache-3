12|4|Public
40|$|The block Gram–Schmidt method computes the <b>qr</b> <b>factorisation</b> rapidly, {{but this}} is {{dependent}} on block size m. We endeavor to deter-mine the optimalm automatically during one execution. Our algorithm determines m through observing the relationship between computa-tion time and complexity. Numerical experiments show that our pro-posed algorithms compute approximately {{twice as fast as}} the block Gram–Schmidt method for some block sizes, and is a viable option for computing the <b>qr</b> <b>factorisation</b> in a more stable and rapid manner. Subject class: 65 F 10, 65 M 1...|$|E
40|$|International audienceIn 1982, Arjen Lenstra, Hendrik Lenstra Jr. and László Lovász {{introduced}} an efficiently computable notion of reduction of {{basis of a}} Euclidean lattice that is now {{commonly referred to as}} LLL-reduction. The precise definition involves the R-factor of the <b>QR</b> <b>factorisation</b> of the basis matrix. A natural mean of speeding up the LLL reduction algorithm is to use a (floating-point) approximation to the R-factor. In the present article, we investigate the accuracy of the factor R of the <b>QR</b> <b>factorisation</b> of an LLL-reduced basis. Our main contribution is the first fully rigorous perturbation analysis of the R-factor of LLL-reduced matrices under column-wise perturbations. Our results should be very useful to devise LLL-type algorithms relying on floating-point approximations...|$|E
40|$|Abstract. This paper {{describes}} {{the implementation of}} a parallel variant of GMRES on Paragon. This variant builds an orthonormal Krylov basis in two steps: it first computes a Newton basis then orthogonalises it. The first step requires matrix-vector products with a general sparse unsymmetric matrix and the second step is a <b>QR</b> <b>factorisation</b> of a rectangular matrix with few long vectors. The algorithm has been implemented for a distributed memory parallel computer. The distributed sparse matrix-vector product avoids global communications thanks to the initial setup of the communication pattern. The <b>QR</b> <b>factorisation</b> is distributed by using Givens rotations which require only local communications. Results on an Intel Paragon show the efficiency and the scalability of our algorithm...|$|E
40|$|A {{number of}} {{problems}} arising from dynamical systems and other areas leads to problems of computing eigenvalues/vectors and singular value decomposisitions of products of matrices. A number of recent algorithms by Bojanczyk, Golub and Van Dooren; Bojanczyk, Ewerbring and Luk; D. Stewart; and Abarbanel, Brown and Kennel have been devised to compute Schur forms and SVD's of products {{in terms of the}} factors. A common connection between them is the use of recursive <b>QR</b> <b>factorisations</b> and related methods. Relationships between these methods, and their accuracy, is discussed. Generalised eigen- and singular value decompositions can also be understood in this framework. 1. Why product algorithms? Product algorithms are algorithms to compute factorisations of products of matrices that works with the product in terms of its factors. There are a number of reasons why {{this is a good thing}} to do. In terms of the design of an algorithm, by working in terms of the factors, at each stage of the algo [...] ...|$|R
40|$|The {{two most}} {{successful}} methods of estimating {{the distribution of}} NMR relaxation times from two di-mensional data are firstly a data compression stage followed by application of the Butler-Reeds-Dawson (BRD) algorithm, and secondly a primal dual interior point method using a preconditioned conjugate gradient (PCG). Both of these methods have been presented in the literature as requiring a truncated singular value decomposition of matrices representing the exponential kernels. Other matrix factori-sations are applicable {{to each of these}} algorithms, and which demonstrate the different fundamental principles behind the operation of the algorithms. In the case of the data compression approach the most appropriate matrix decomposition specifically designed for this task is the rank-revealing <b>QR</b> (RRQR) <b>factorisation.</b> In the case of the interior point method, the most appropriate method is the LDL factori-sation with diagonal pivoting, also known as the Bunch-Kaufman-Parlett factorisation. The details of these differences are discussed, and the performances of the algorithms are compared numerically. 1...|$|R
40|$|Abstract. Triangular systems play a {{fundamental}} role in matrix computations. It has been prominently {{stated in the}} literature, but is perhaps not widely appreciated, that solutions to triangular systems are usually computed to high accuracy [...] higher than the traditional condition numbers for linear systems suggest. This phenomenon is investigated by use of condition numbers appropriate to the componentwise backward error analysis of triangular systems. Results of Wilkinson are unified and extended. Among the conclusions are that the conditioning of a triangular system depends on the right-hand side as well as the coefficient matrix; that use of pivoting in LU, <b>QR,</b> and Cholesky <b>factorisations</b> can greatly improve the conditioning of a resulting triangular system; and that a triangular matrix may be much more or less ill-conditioned than its transpose...|$|R
40|$|This paper {{describes}} {{the implementation of}} a parallel variant of GMRES on Paragon. This variant builds an orthonormal Krylov basis in two steps: it first computes a Newton basis then orthogonalises it. The first step requires matrix-vector products with a general sparse unsymmetric matrix and the second step is a <b>QR</b> <b>factorisation</b> of a rectangular matrix with few long vectors. The algorithm has been implemented for a distributed memory parallel computer. The distributed sparse matrix-vector product avoids global communications thanks to the initial setup of the communication pattern. The <b>QR</b> <b>factorisation</b> is distributed by using Givens rotations which require only local communications. Results on an Intel Paragon show the e#ciency and the scalability of our algorithm. Key words. GMRES, parallelism, sparse matrix, Newton basis. AMS subject classifications. 65 F 10, 65 F 25, 65 F 50. 1. Introduction. Many scientific applications make use of sparse linear algebra. Because they are quite time [...] ...|$|E
40|$|The {{least squares}} problem is an {{extremely}} useful device to represent an approximate solution to overde-termined systems, and a <b>QR</b> <b>factorisation</b> is a common method for solving {{least squares problem}}s. It {{is often the case}} that multiple least squares solutions have to be computed with only minor changes in the underlying data. In this case, knowledge of the difference between the old data set and the new one can be used to update an existing <b>QR</b> <b>factorisation</b> at a reduced computational cost. However, fairly recent developments have introduced the widespread use of massively parallel computational devices known as GPUs. GPUs have allowed QR factorisations, and subsequently, least squares solutions to be calculated in a greatly reduced time. The purpose of this project is to investigate the viability of the implementation of QR updating algorithms on the GPU and attempt gain speedup with a GPU based updating algorithm over both existing sequential QR updating algorithms, and full GPU QR factorisations. The conclusion of the investigation is that GPU based updating algorithms gain speedups over their sequential analogues for almost all problem sizes, whereas the proposed algorithms only gain speedups over the full GPU <b>QR</b> <b>factorisation</b> under certain conditions. Declaration No portion of the work referred to in the dissertation has been submitted in support of an application for another degree or qualification of this or any other university or other institute of learning. 1 Copyright The author of this dissertation (including any appendices and/or schedules to this dissertation) owns certain copyright or related rights in it (the Copyright) and s/he has given The University of Manch-ester certain rights to use such Copyright, including for administrative purposes...|$|E
40|$|This paper {{considers}} the system architecture and design issues for implementation of on-line Model Predictive Control (MPC) in Field Programmable Gate Arrays (FPGAs) and Application Specific Integrated Circuits (ASICs). In particular, the computationally itensive tasks of fast matrix <b>QR</b> <b>factorisation,</b> and subsequent sequential quadratic programming, are addressed for control law computation. An {{important aspect of}} this work {{is the study of}} appropriate data word-lengths for various essential stages of the overall solution strategy...|$|E
40|$|This paper {{describes}} {{an extension of}} the Brands protocol to incorporate flexibly-divisble k-term Coins via application of Shamir polynomial parameterisation and Feldman-Pedersen zero knowledge (ZK) verification. User anonymity is preserved for up to k sub-Coin Payments per k-term Coin, but revoked for over-Payments with (k+ 1) or more sub-Coins. Poly-cash construction using only discrete logarithm (DL) or elliptic curve (EC) operations enables efficient implementation in terms of the latter; which constitutes an advantage over previous divisble Coin formulations based on quadratic residue (<b>QR)</b> binary-trees, integer <b>factorisation</b> (IF) cryptography or hybrid DL/IF. Comparative analysis of Poly-cash and previous protocols illustrates the advantages of the former for operationally realistic Coin sub-denominations. The advantage of Poly-cash in terms computational overhead is particularly significant, and facilitates implementation on lightweight User Purses and Merchant Payment-terminals. Configurable k-divisibility is also an important consideration for real-world applicability with decimal currency denominations, which is not well addressed by the binarised values of QR-tree divisible Coins...|$|R
40|$|Complex <b>QR</b> <b>factorisation</b> is a {{fundamental}} operation used in various applications such as adaptive beamforming and MIMO signal detection. In this paper, based on Givens rotation scheme, a high-throughput, fully parallel complex-valued <b>QR</b> <b>factorisation</b> (CQRF) design is presented. It features the lowest computing complexity in various factorising schemes and indicates no BER performance loss when applied to a MIMO signal detection system. Via carefully plotted scheduling, one CQRF computation can be completed in eight clock cycles. In hardware design, a low complexity and look-up-table-free CORDIC algorithm is employed to implement the rotation operations. Further design optimisations, such as hardware sharing of common modules and reduction of register usage by shortening the variable's life span, are also applied. Sized 22 and 44 chip designs largely following the IEEE 802. 11 n standard are developed. The implementation results in TSMC 0. 18 um process technology show that the proposed 44 design, with a gate count of only 134. 6 K, is capable of performing 15 M CQRFs per second. The measured power consumption is 196. 3 mW at 120 MHz. Compound performance indexes such as area-time product and energy consumption per CQRF also indicate significant performance edges of the proposed designs...|$|E
40|$|A QR based {{technique}} is presented for estimating the approximate numerical rank and corresponding signal subspace of a matrix {{together with the}} subspace projection of the least squares weights. Theoretical difficulties associated with conventional <b>QR</b> <b>factorisation</b> are overcome by applying the technique of Row-Zeroing QR to the covariance matrix. Thresholding is simplified compared {{with the use of}} the data matrix as the diagonal value spectrum is sharpened and the subspace estimate is improved. An approximation to the minimum norm solution for the projection of the least squares weight onto the signal subspace of the data is obtained simply, without performing an SVD. 1...|$|E
40|$|Matching Pursuit and {{orthogonal}} Matching Pursuit are greedy {{algorithms used}} to obtain sparse signal approximations. Orthogonal Matching Pursuit is known to offer better performance, but Matching Pursuit allows more efficient implementations. In this paper we propose novel greedy Pursuit algorithms based on directional updates. Using a conjugate direction, the algorithm becomes a novel implementation of orthogonal Matching Pursuit, with computational requirements similar to current implementations based on <b>QR</b> <b>factorisation.</b> A significant reduction in memory requirements and computational complexity {{can be achieved by}} approximating the conjugate direction. Further computational savings can be made by using a steepest descent direction. The two resulting algorithms are then comparable to Matching Pursuit in their computational requirements, their performance is however shown to be closer to that of orthogonal Matching Pursuit with the (slightly slower) approximate conjugate direction based approach outperforming the gradient descent method. 1...|$|E
40|$|In this work, {{we propose}} an {{efficient}} parallel {{implementation of the}} nonsymmetric block Lanczos algorithm for the computation of few extreme eigenvalues, and corresponding eigenvectors, of real nonhermitian matrices for distributed memory multicomputers. The reorganisation of the block Lanczos algorithm implemented allows to exploit a coarse-grained parallelism and to harness the computational power of the target architectures. The computational kernels of the algorithm are matrix– matrix multiplications, with dense and sparse factors, <b>QR</b> <b>factorisation</b> and singular value decomposition. To reduce {{the total amount of}} communication involved in the matrix–matrix multiplication with a sparse factor, we substitute each matrix appearing in the algorithm with its transpose. Then, we develop an efficient parallelisation of the matrix–matrix multiplication when the second factor is sparse. Some other linear algebra operations are performed using ScaLAPACK library. The parallel eigensolver has been tested on a cluster of PCs. All reported results show the proposed algorithm is efficient on the target architectures for problems of adequate dimension...|$|E
40|$|Abstract. The {{problem of}} finding a rank-revealing QR (RRQR) factorisation of a matrix A {{consists}} of permuting the columns of A such that the resulting <b>QR</b> <b>factorisation</b> contains an upper triangular matrix whose linearly dependent columns are separated from the linearly independent ones. In this paper a systematic treatment of algorithms for determining RRQR factorisations is presented. In particular, the authors start by presenting precise mathematical formulations for the prob-lem of determining a RRQR factorisation, all of them optimisation problems. Then a hierarchy of "greedy " algorithms is derived to solve these optimisation problems, and it is shown that the existing RRQR algorithms correspond to particular greedy algorithms in this hierarchy. Matrices on which the greedy algorithms, and therefore the existing RRQR algorithms, can fail arbitrarily badly are presented. Finally, motivated by an insight from the behaviour of the greedy algorithms, the authors present "hybrid " algorithms that solve the optimisation problems almost exactly (up to a factor proportional {{to the size of}} the matrix). Applying the hybrid algorithms as a follow-up to the conventional greedy algorithms may prove to be useful in practice...|$|E
40|$|Many recent {{applications}} of computer graphics and human computer interaction have adopted both colour cameras and depth cameras as input devices. Therefore, an effective calibration of {{both types of}} hardware taking different colour and depth inputs is required. Our approach removes the numerical difficulties of using non-linear optimization in previous methods which explicitly resolve camera intrinsics {{as well as the}} transformation between depth and colour cameras. A matrix of hybrid parameters is introduced to linearize our optimization. The hybrid parameters offer a transformation from a depth parametric space (depth camera image) to a colour parametric space (colour camera image) by combining the intrinsic parameters of depth camera and a rotation transformation from depth camera to colour camera. Both the rotation transformation and intrinsic parameters can be explicitly calculated from our hybrid parameters {{with the help of a}} standard <b>QR</b> <b>factorisation.</b> We test our algorithm with both synthesized data and real-world data where ground-truth depth information is captured by Microsoft Kinect. The experiments show that our approach can provide comparable accuracy of calibration with the state-of-the-art algorithms while taking much less computation time (1 / 50 of Herrera’s method and 1 / 10 of Raposo’s method) due to the advantage of using hybrid parameters...|$|E

