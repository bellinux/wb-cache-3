1126|256|Public
2500|$|... {{reviewed}} several alternative {{quality metrics}} and compared their performance based on visual data obtained in 9 psychophysical experiments. It {{was found that}} a geometric mean of the GAI index and the CIE Ra correlated best with naturalness (r=0.85), while a color <b>quality</b> <b>metric</b> based on memory colors (MCRI) correlated best for preference (r=0.88). The differences in performance of these metrics with the other tested metrics (CIE Ra; CRI-CAM02UCS; CQS; RCRI; GAI; geomean(GAI, CIE Ra); CSA; Judd Flattery; Thornton CPI; MCRI) [...] {{were found to be}} statistically significant with p<0.0001.|$|E
50|$|Rate-distortion {{optimization}} {{solves the}} aforementioned problem by {{acting as a}} video <b>quality</b> <b>metric,</b> measuring both the deviation from the source material and the bit cost for each possible decision outcome. The bits are mathematically measured by multiplying the bit cost by the Lagrangian, a value representing the relationship between bit cost and quality for a particular quality level. The deviation from the source is usually measured as the mean squared error, {{in order to maximize}} the PSNR video <b>quality</b> <b>metric.</b>|$|E
5000|$|The {{origins of}} SAE J2450 Translation <b>Quality</b> <b>Metric</b> can be dated back to Fall, 1997. Its initial name was [...] "J2450 Task Force on a <b>Quality</b> <b>Metric</b> for Language Translation of Service Information". J2450 Translation <b>Quality</b> <b>Metric</b> was {{developed}} by Society of Automotive Engineers (SAE), a worldwide association of engineers as well as technical experts in the fields such as aerospace, automotive and commercial-vehicle industries, one of whose aims is consensus standards development. With the purpose of establishing a consistent standard against which the quality of translation of automotive service information can be objectively measured regardless of the source language, regardless of the target language, and regardless of how the translation is performed (i.e., human translation or machine translation)”, it was first co-created by General Motors, Ford as well as Chrysler and released in August, 2001, as a recommended practice.|$|E
30|$|The {{computation}} time for using game-theoretic architecture {{is determined by}} each player's strategies/actions and payoffs. The whole complexity should be examined by calculating each individual visual <b>quality</b> <b>metric's</b> computation.|$|R
30|$|Based on the {{recommendations}} of the developers and Asian studies (Ware et al. 2007; Atif et al. 2013), the standard scoring algorithms (United States weights) were used to obtain the standard norm-based scores (NBS) of eight health domains and the summary components. The <b>Quality</b> <b>Metric’s</b> QM Certified Scoring Software (version 4.5) was used to score the questionnaires.|$|R
3000|$|... is the {{luminance}} {{of virtual}} image generated by processed depth. For better <b>quality,</b> the <b>metric</b> shows low values.|$|R
50|$|The {{residual}} {{bit error}} rate (RBER) is a receive <b>quality</b> <b>metric</b> in digital transmission, one of several used to quantify {{the accuracy of the}} received data.|$|E
50|$|The most {{traditional}} ways of evaluating quality of digital video processing system (e.g. a video codec) are FR-based. Among the oldest FR metrics are signal-to-noise ratio (SNR) and peak signal-to-noise ratio (PSNR), which are calculated between every {{frame of the}} original video signal and the video passed through a system (e.g., an encoder or a transmission channel). PSNR is {{the most widely used}} objective image <b>quality</b> <b>metric,</b> and the average PSNR over all frames can be considered a video <b>quality</b> <b>metric.</b> However, PSNR values do not correlate well with perceived picture quality due to the complex, highly non-linear behavior of the human visual system.|$|E
50|$|Optical {{performance}} (image quality): This is quantified {{by various}} metrics, including encircled energy, modulation transfer function, Strehl ratio, ghost reflection control, and pupil performance (size, location and aberration control); {{the choice of}} the image <b>quality</b> <b>metric</b> is application specific.|$|E
40|$|Objectives: a) Develop an {{asymmetric}} handling <b>qualities</b> <b>metric</b> {{to predict}} cross coupling {{effects of a}} damaged aircraft: 1) Initial use of U. S Army Aeronautical Design Specification ADS- 33; 2) Modification as required based on flight test results. b) Simulation and Flight Validation of proposed metric: 1) F- 16 VISTA (March 2010); 2) F- 18 Full Scale Test bed (Potential Early Experiment); and 3) Flight Simulators (GTM, ACFS, F- 18 HILS). c) Provide flight validated metric and tool box to control law designers...|$|R
40|$|JPEG {{compression}} is {{the most}} prevalent technique or method for image codecs. But it suffers from blocking artifacts. In this paper {{a comparison of the}} perceptual quality of deblocked images based on various <b>quality</b> assessment <b>metric</b> is done. A proposed PSNR including blocking effect factor was used instead of PSNR. Another <b>quality</b> assessment <b>metric</b> SSIM was used which produces results largely in accordance with PSNR –B. We show the simulation results, which prove PSNR-B produces objective judgments. The efficiency of deblocking algorithms were studied. ...|$|R
40|$|Quality {{assessment}} {{is crucial to}} developments of video communication systems. While subjective test yields most accurate results, its expensive cost and human biasness make it an unsatisfactory figure of merit. The peak-signal to noise ratio (PSNR), the most acceptable objective video <b>quality</b> assessment <b>metric,</b> is based on error sensitivity; its failure to capture perceptual errors is well documented. Other perceptual quality metrics fail to detect the localized errors that are common in sequences produced by low bit-rate video communication systems. In this work, a novel perceptual <b>quality</b> assessment <b>metric,</b> the structural similarity (SSIM) metric, is modified to better detect spatial artifacts often seen in video communication systems...|$|R
50|$|Length of stay is {{commonly}} used as a <b>quality</b> <b>metric.</b> The prospective payment system in U.S. Medicare for reimbursing hospital care promotes shorter length of stay by paying the same amount for procedures, regardless of days spent in the hospital.|$|E
50|$|CZD (Czenakowski Distance) as PSNR is a per-pixel <b>quality</b> <b>metric</b> (it {{estimates}} the quality by measuring differences between pixels). Described in literature as being “useful for comparing vectors with strictly non-negative elements” it measures the similarity among different samples. This different approach {{has a better}} correlation with subjective quality assessment than PSNR.|$|E
50|$|The Quality {{portion of}} the OEE Metric {{represents}} the Good Units produced {{as a percentage of}} the Total Units Started. The <b>Quality</b> <b>Metric</b> is a pure measurement of Process Yield that is designed to exclude the effects of Availability and Performance. The losses due to defects and rework are called quality losses.|$|E
3000|$|... [...]. In this paper, we {{adopt the}} total number of {{contacts}} during a period T as the <b>metric</b> of contact <b>quality.</b> The <b>metric</b> is widely used in MONs [4, 5] and has been proved very efficient. If v [...]...|$|R
40|$|A {{closed-loop}} {{handling qualities}} methodology {{is applied to}} an analysis of the flared landing task with pitch-rate flight control systems. A model of pilot behavior throughout approach and flare is developed which postulates {{the manner in which the}} pilot may move from pitch attitude to flight path angle control. Twenty-five configurations flight tested on the NC- 131 H Total In-flight Simulator aircraft are analyzed using a structural pilot model ad a handling qualities methodology previously reported in the literature. Closed-loop simulation of the simplified landing task is undertaken using the structural model. The pilot ratings from flight test extended the data base supporting the utility of a model-based handling <b>qualities</b> <b>metric.</b> A handling <b>qualities</b> sensitivity function is introduced which may have potential as a design tool...|$|R
40|$|The {{capability}} to accurately and rapidly predict aircraft stability derivatives using one comprehensive analysis tool has been created. The PREDAVOR tool has the following capabilities: rapid estimation of stability derivatives using a vortex lattice method, calculation of a longitudinal handling <b>qualities</b> <b>metric,</b> and inherent methodology to optimize a given aircraft configuration for longitudinal handling qualities, including an intuitive graphical interface. The PREDAVOR tool may {{be applied to}} both subsonic and supersonic designs, as well as conventional and unconventional, symmetric and asymmetric configurations. The workstation-based tool uses as its model a three-dimensional model of the configuration generated using a computer aided design (CAD) package. The PREDAVOR tool was applied to a Lear Jet Model 23 and the North American XB- 70 Valkyrie...|$|R
50|$|Video Multimethod Assessment Fusion (VMAF) is a full-reference video <b>quality</b> <b>metric</b> {{developed}} by Netflix {{in cooperation with}} the University of Southern California. It predicts subjective video quality based on a reference and distorted video sequence. The metric can be used to evaluate the quality of different video codecs, encoders, encoding settings, or transmission variants.|$|E
5000|$|In {{objective}} video quality assessment, the outliers ratio (OR) is {{a measure}} of the performance of an objective video <b>quality</b> <b>metric.</b> It is the ratio of [...] "false" [...] scores given by the objective metric to the total number of scores. The [...] "false" [...] scores are the scores that lie outside the interval ...|$|E
5000|$|Connascence (...) is a {{software}} <b>quality</b> <b>metric</b> invented by Meilir Page-Jones to allow reasoning about the complexity caused by dependency relationships in {{object oriented design}} much like coupling did for structured design. In addition to allowing categorization of dependency relationships, connascence also provides a system for comparing different types of dependency. Such comparisons between potential designs can often hint at {{ways to improve the}} quality of the software.|$|E
3000|$|Distance metric: Quality {{score is}} also used to alter the feature space to improve matching. Chen et al.[3] {{incorporate}} their proposed iris <b>quality</b> assessment <b>metric</b> (computed for both gallery and probe) in the formulation of Hamming distance matcher to show improved results when compared to simple Hamming distance.|$|R
40|$|In fact, {{reliability}} as the <b>qualities</b> <b>metric</b> is {{the probability}} success or {{the probability that}} a system or a set of tasks will work without failure for a specified constraints of time and space, as specified in the design and operating conditions specified temperature, humidity, vibration and action. A relatively new methodologies for developing complex software systems engineering is an aspect oriented software systems, that provides the new methods for the separation of concerns multiple module configuration or intervention and automatic integration them with a system. In this paper, a method using fuzzy logic to measure software reliability based on the above aspects is presented. The proposed approach regarding the use of appropriate metrics and low errors in the estimation of reliability has a better performance than other methods...|$|R
50|$|VSIA’s {{mission was}} to enhance the {{productivity}} of the SoC design community dramatically. VSIA has developed an international standard, the QIP <b>metric</b> (<b>Quality</b> Intellectual Property <b>Metric)</b> for measuring SIP quality and examining the practices used to design, integrate and support the IP. This is important and, to have {{a measure of the}} quality, VSIA also works on other issues such as IP protection, IP transfer, IP integration and IP reuse standards (IP hardening is required for easy IP reuse) for Integrated circuit design.|$|R
5000|$|There {{are some}} {{limitations}} to the M2 parameter {{as a simple}} <b>quality</b> <b>metric.</b> It {{can be difficult to}} measure accurately, and factors such as background noise can create large errors in M2. Beams with power well out in the [...] "tails" [...] of the distribution have M2 much larger than one would expect. In theory, an idealized tophat laser beam has infinite M2, although this is not true of any physically realizable tophat beam. For a pure Bessel beam, one cannot even compute M2.|$|E
5000|$|... {{reviewed}} several alternative {{quality metrics}} and compared their performance based on visual data obtained in 9 psychophysical experiments. It {{was found that}} a geometric mean of the GAI index and the CIE Ra correlated best with naturalness (r=0.85), while a color <b>quality</b> <b>metric</b> based on memory colors (MCRI) correlated best for preference (r=0.88). The differences in performance of these metrics with the other tested metrics (CIE Ra; CRI-CAM02UCS; CQS; RCRI; GAI; geomean(GAI, CIE Ra); CSA; Judd Flattery; Thornton CPI; MCRI) {{were found to be}} statistically significant with p<0.0001.|$|E
50|$|Since its publication, SAE J2450 Translation <b>Quality</b> <b>Metric</b> {{has become}} one of the most {{important}} measurements in judging the quality of translation in the automobile industry and has been adopted by many translation service providers and car manufacturers. The advantages of SAE J2450 are quite obvious. To begin with, this simple statistical approach makes comparison of the quality figures of different texts easy; secondly, the examination of the errors in specific categories can assist in the identification of particular problem areas; finally, it helps to eliminate post-translation review processes, as already confirmed in the empirical study carried out by Don (2004).|$|E
30|$|We {{present in}} this paper a <b>quality</b> {{assessment}} <b>metric</b> of image-based biometric raw data using both information: 1) image quality and 2) pattern-based quality using the scale-invariant feature transformation (SIFT) keypoints extracted from the image. The presented metric has the advantages of being multimodal (face, fingerprint, and hand veins) and independent from the used authentication system.|$|R
30|$|In biometrics, {{there is}} an {{international}} consensus {{on the fact that}} the quality of a biometric sample should be related to its recognition performance [8]. Therefore, we present in this paper a utility-based <b>quality</b> assessment <b>metric</b> of biometric raw data. In the rest of this section, we present an overview of the existing image-based quality metrics.|$|R
30|$|The payoffs {{represent}} {{the welfare of}} the players {{at the end of the}} game. They are on the basis of each player choosing his strategy and the payoff function of a player is defined as the total profit/gain. From encoder player point of view, the image quality between the host image and the watermarked image is critical since the encoder need to reserve the highest fidelity after watermark embedding. Based on the <b>quality</b> assessment <b>metric</b> study of Ponomarenko et al [23], we apply four quality assessment metrics that produce reasonably good results from [23], such as MSSIM, VIF, PSNR-HVS-M, and WSNR. In addition, the correlation between the logo watermark and the extracted watermark after attack is also important since the robustness of the watermark embedding technique is critical for the encoder player. Therefore, four image <b>quality</b> assessment <b>metric</b> and correlation functions will be adopted in the payoff function for encoder player.|$|R
50|$|Judged by the {{objective}} <b>quality</b> <b>metric</b> VQM in 2015, x265 delivered video quality {{on par with}} the reference encoder of the royalty-free VP9 format that competes with HEVC.A codec comparison from 2015 found x265 to be a leading HEVC implementation measured by SSIM metric. In August 2016, Netflix published a comparison of x264, VP9, and x265 using video clips from 500 movies and TV shows using 6 different quality metrics and found that both VP9 and x265 have 40-50% better quality at 1080p than x264. Netflix stated that with the VMAF metric (which closely mirrors human visual experience according to the author) x265 performed substantially (19% to 22%) better than VP9.|$|E
50|$|Some {{models that}} are used for video quality {{assessment}} (such as PSNR or SSIM) are simply image quality models, whose output is calculated for every frame of a video sequence. This quality measure of every frame can then be recorded over time to assess the quality of an entire video sequence. While this method is easy to implement, it does not factor in certain kinds of degradations that develop over time, such as the moving artifacts caused by packet loss and its concealment. A video <b>quality</b> <b>metric</b> that considers the temporal aspects of quality degradations, like the MOVIE Index, {{may be able to}} produce more accurate predictions of human-perceived quality.|$|E
50|$|SAE J2450 Translation <b>Quality</b> <b>Metric</b> (2001)'s {{approach}} to quality assurance is quite straightforward, which bases quality scores on seven types of errors, i.e. wrong term, syntactic error, omission, word structure or agreement error, misspelling, punctuation error and miscellaneous error. Errors {{in each category}} can be classified as either major or minor, with a numeric score attached to each error and severity level (ibid.). The composite score, which decides the translation quality of a text, is the weighted sum of the errors normalized {{by the number of}} words in the source text (ibid.). This simple statistical approach makes comparison of the quality figures of different texts easy, while examination of the errors in specific categories can assist in the identification of particular problem areas.|$|E
40|$|Accurate link quality {{estimation}} is {{a fundamental}} building block in quality aware multi hop routing. In an inherently lossy, unreliable and dynamic medium such as wireless, the task of accurate estimation becomes very challenging. Over the years ETX has been widely used as a reliable link <b>quality</b> estimation <b>metric.</b> However, more recently it has been established that under heavy traffic loads ETX performance gets significantly worse. We examine the ETX metric's behavior in detail {{with respect to the}} MAC layer and UDP data; and identify the causes of its unreliability. Motivated by the observations made in our analysis, we present the design and implementation of our link <b>quality</b> measurement <b>metric</b> xDDR – a variation of ETX. This article extends xDDR to support network mobility. Our experiments show that xDDR substantially outperforms minimum hop count, ETX and HETX in terms of end-to-end packet delivery ratio in static as well as mobile scenarios...|$|R
30|$|The quality {{assessment}} of biometric raw data {{is a key}} factor {{to take into account}} during the enrollment step when using biometric systems. Such kind of information may be used to enhance the overall performance of biometric systems, as well as in fusion approaches. However, few works exist in comparison to the performance ones. Toward contributing in this research area, we have presented an image-based <b>quality</b> assessment <b>metric</b> of biometric raw data using two types of information (image and pattern-based <b>quality).</b> The proposed <b>metric</b> is independent from the used matching system and could be used to several kind of modalities. Using six public biometric databases (face, fingerprint, and hand veins), we have shown its efficiency in detecting three kinds of synthetic alterations (blurring, Gaussian noise, and resolution).|$|R
30|$|The RR metric [18] {{has been}} {{developed}} for overall image <b>quality.</b> The <b>metric</b> compares the wavelet coefficient distributions between the reference and distorted images. Equation (2) calculates the overall image quality. Its high performance at predicting sharpness in our pretests relates to the correlation between image contrast and wavelet coefficient energy. Image contrast relates to the perceived sharpness and detail reproduction.|$|R
