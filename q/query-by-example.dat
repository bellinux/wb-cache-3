353|0|Public
5000|$|Text {{retrieval}} tools: Keyword Retrieval, <b>Query-by-Example,</b> Cluster Extraction.|$|E
5000|$|Keyword {{spotting}} in document {{image processing}} {{can be seen}} as an instance of the more generic problem of content-based image retrieval (CBIR).Given a query, the goal is to retrieve the most relevant instances of words in a collection of scanned documents [...]The query may be a text string (Query-by-string keyword spotting) or a word image (<b>Query-by-example</b> keyword spotting).|$|E
40|$|In this paper, we {{extend the}} {{conventional}} {{concept of a}} database {{as a set of}} discrete relations to include a set of piecewise contin-uous functions. We extend the features of <b>Query-by-Example</b> to operations on this piecewise continuous data. Further, we include the concept of iteration in the language, which enhances its capabilities to that of a general programming language. These extensions are accomplished without loss of the simplicity that is usually attributed to Query-by-Example; furthermore, <b>Query-by-Example</b> retains its table-like view of data over these new piecewise continuous functions. We present formal notions of well-formedness and correctness of <b>Query-by-Example</b> pro-grams. 1...|$|E
30|$|The spoken term {{detection}} ALBAYZIN 2014 {{evaluation is}} integrated within {{a more general}} search on speech ALBAYZIN evaluation. This is the second edition of the search on speech ALBAYZIN evaluation, after that held in 2012. Since then, the evaluation has involved different tasks. In the first edition (held in 2012), we organized three different tasks, named <b>query-by-example</b> spoken term detection, keyword spotting, and spoken term detection. In the first evaluation, however, most participants only submitted systems to the <b>query-by-example</b> STD evaluation [37] and only one participant submitted a system for STD and keyword spotting tasks. In this second edition (held in 2014), there was an additional task, named <b>query-by-example</b> spoken document retrieval. However, none of the participants submitted any system to this task, being most of them involved in the STD task. There were also some systems submitted to the <b>query-by-example</b> STD and keyword spotting tasks. Therefore, {{this is the first}} time that we really have an evaluation with several teams working on STD in Spanish.|$|E
40|$|<b>Query-by-example</b> search often uses dynamic {{time warping}} (DTW) for {{comparing}} queries and proposed matching segments. Recent work {{has shown that}} comparing speech segments by representing them as fixed-dimensional vectors [...] - acoustic word embeddings [...] - and measuring their vector distance (e. g., cosine distance) can discriminate between words more accurately than DTW-based approaches. We consider an approach to <b>query-by-example</b> search that embeds both the query and database segments according to a neural model, followed by nearest-neighbor search to find the matching segments. Earlier work on embedding-based <b>query-by-example,</b> using template-based acoustic word embeddings, achieved competitive performance. We find that our embeddings, based on recurrent neural networks trained to optimize word discrimination, achieve substantial improvements in performance and run-time efficiency over the previous approaches. Comment: To appear Interspeech 201...|$|E
40|$|In {{this paper}} we {{describe}} a Pictorial <b>Query-By-Example</b> (PQBE) language {{aimed at the}} retrieval of direction relations from symbolic images. As {{in the case of}} verbal <b>Query-By-Example,</b> PQBE generalises from the example given by the user, but instead of having queries in the form of skeleton tables showing the relation scheme, we have skeleton images which are themselves symbolic images. PQBE provides an intuitive interface for use in geographic applications because of its close correspondence with the structure of space...|$|E
30|$|With {{respect to}} the {{language}}, English is the language with more resources and for which more research has been done. When applying the similar technology to languages with fewer resources or for which less specific research has been devoted, performance decreases are observed. In {{the case of the}} NIST STD 2006 evaluation, very important performance decreases are observed when moving from English to other languages. In the case of our evaluation, we should not expect important decreases due to the use of Spanish since we are conducting a <b>query-by-example</b> evaluation in which language resources are less important and the technology is relatively more language independent. However, we will probably lose some performance due to using a <b>query-by-example</b> setting. In fact, we see that this happens in the particular setting of our evaluation by comparing results of the <b>query-by-example</b> systems with the performance obtained by a text-based spoken term detection system that is more comparable to the systems participating in the NIST STD 2006 evaluation.|$|E
40|$|Abstract — While {{there have}} been {{advances}} in visualization systems, particularly in multi-view visualizations and visual exploration, {{the process of building}} visualizations remains a major bottleneck in data exploration. We show that provenance metadata collected during the creation of pipelines can be reused to suggest similar content in related visualizations and guide semi-automated changes. We introduce the idea of <b>query-by-example</b> {{in the context of an}} ensemble of visualizations, and the use of analogies as first-class operations in a system to guide scalable interactions. We describe an implementation of these techniques in VisTrails, a publiclyavailable, open-source system. Index Terms—visualization systems, <b>query-by-example,</b> analogy...|$|E
40|$|In this paper, we give {{an update}} of recent {{research}} activities in HLT department of I 2 R in <b>query-by-example</b> spoken document retrieval (SDR) and report an evaluation campaign, the Star Challenge 2008, which {{was organized by}} A*STAR, Singapore. It is suggested that low-level feature-based approach, which does not rely on error-prone speech transcripts, is a promising solution to <b>query-by-example</b> multilingual spoken document retrieval. APSIPA ASC 2009 : Asia-Pacific Signal and Information Processing Association, 2009 Annual Summit and Conference. 4 - 7 October 2009. Sapporo, Japan. Oral session: Initiatives in Spoken Document Processing (6 October 2009) ...|$|E
40|$|We {{present a}} new speech {{indexing}} and search scheme called Randomized Acoustic Indexing and Logarithmic-time Search (RAILS) that enables scalable <b>query-by-example</b> spoken term detection in the zero resource regime. RAILS {{is derived from}} our recent investigation into the application of randomized hashing and approximate nearest neighbor search algorithms to raw acoustic features. Our approach permits an approximate search through {{hundreds of hours of}} speech audio in a matter of seconds, and may be applied to any language without the need of a training corpus, acoustic model, or pronunciation lexicon. The fidelity of the approximation is controlled through a small number of easily interpretable parameters that allow a trade-off between search accuracy and speed. Index Terms: speech indexing, zero resource, <b>query-by-example,</b> spoken term detection, locality sensitive hashin...|$|E
40|$|Abstract. We propose an {{automated}} system {{which is based}} on agglomerative hierarchical clustering and automatically organizes a collection of music files according to musical surface characteristics (e. g., zero crossings, short-time energy, etc.) and tempo. The system architecture is based on three distinct yet inter-related processes, namely: (a) Preprocessing (format normalization and extraction of fifteen features per song), (b) Retrieval and (c) Browsing. The organization of music files is visualized via a dendrogram in which every leaf of the tree represents a music file and musical similarity decreases with height. Additionally, our system is complemented by a <b>Query-By-Example</b> (Q. B. E.) retrieval subsystem, the results of which are also returned to the user in dendrogram form. Keywords: Content-based retrieval, musical database, <b>query-by-example...</b>|$|E
40|$|Recent {{efforts on}} the task of spoken {{document}} retrieval (SDR) have made use of speech lattices: speech lattices contain information about alternative speech transcription hypotheses other than the 1 -best transcripts, and this information can improve retrieval accuracy by overcoming recognition errors present in the 1 -best transcription. In this paper, we look at using lattices for the <b>query-by-example</b> spoken document retrieval task – retrieving documents from a speech corpus, where the queries are themselves in the form of complete spoken documents (query exemplars). We extend a previously proposed method for SDR with short queries to the <b>query-by-example</b> task. Specifically, we use a retrieval method based on statistical modeling: we compute expected word counts from document and query lattices, estimate statistical models from these counts, and compute relevance scores as divergences between these models. Experimental results on a speech corpus of conversational English show that the use of statistics from lattices for both documents and query exemplars results in better retrieval accuracy than using only 1 -best transcripts for either documents, or queries, or both. In addition, we investigate the effect of stop word removal which further improves retrieval accuracy. To our knowledge, our work is the first to have used a lattice-based approach to <b>query-by-example</b> spoken document retrieval...|$|E
40|$|Abstract—Effective video {{retrieval}} is {{the result}} of an interplay between interactive query selection, advanced visualization of results, and a goal-oriented human user. Traditional interactive video retrieval approaches emphasize paradigms, such as query-by-keyword and <b>query-by-example,</b> to aid the user in the search for relevant footage. However, recent results in automatic indexing indicate that query-by-concept is becoming a viable resource for interactive retrieval also. We propose in this paper a new video retrieval paradigm. The core of the paradigm is formed by first detecting a large lexicon of semantic concepts. From there, we combine query-by-concept, <b>query-by-example,</b> query-by-keyword, and user interaction into the MediaMill semantic video search engine. To measure the impact of increasing lexicon size on interactive video retrieval performance, we performed two experiments against the 2004 and 2005 NIST TRECVID benchmarks, using lexicons containing 32 and 101 concepts, respectively. The results suggest that from all factors that play a role in interactive retrieval, a large lexicon of semantic concepts matters most. Indeed, by exploiting large lexicons, many video search questions are solvable without using query-by-keyword and <b>query-by-example.</b> In addition, we show that the lexicon-driven search engine outperforms all state-of-the-art video retrieval systems in both TRECVID 2004 and 2005. Index Terms—Benchmarking, concept learning, content analysis and indexing, interactive systems, multimedia information systems, video retrieval. I...|$|E
30|$|The {{ever-increasing}} {{volume of}} heterogeneous speech data stored in audio and audiovisual repositories promotes {{the development of}} efficient methods for retrieving the stored information. Much work has addressed this issue by means of spoken document retrieval (SDR), keyword spotting, spoken term detection (STD), <b>query-by-example</b> (QbE) or spoken query approaches.|$|E
40|$|This work {{describes}} and investigates {{a practical}} use-case for searching in an exploratory fashion for fragments of audio within a small collection, {{in the manner}} of <b>Query-by-Example.</b> Our motivation for this is to help performers, especially of improvised music, to critically assess their own improvisation style and ho...|$|E
30|$|The {{enormous}} amount of information stored in audio and audiovisual repositories promotes the development of efficient methods that aim at retrieving the stored information. For audio content search, significant {{research has been conducted}} in spoken document retrieval (SDR), keyword spotting, spoken term detection (STD), and <b>query-by-example.</b> Spoken term detection aims at finding a list of terms (composed of individual words or multiple words) within audio archives, and has been receiving much interest for years from the likes of IBM [1 – 3], BBN [4], SRI and OGI [5 – 7], BUT [8 – 10], Microsoft [11], QUT [12, 13], JHU [14 – 16], Fraunhofer IAIS/NTNU/TUD [17], NTU [18, 19], IDIAP [20], etc. In addition, several evaluations including SDR, STD, and <b>query-by-example</b> STD have been recently proposed [21 – 31].|$|E
40|$|A {{symbolic}} {{image is}} an array representing {{a set of}} objects {{and a set of}} spatial relations among them. Symbolic images and related structures have been used in a number of applications including image databases, spatial reasoning, path planning and spatial pattern matching. In this paper we describe a pictorial <b>query-by-example</b> (PQBE) language aimed at the retrieval of direction relations from symbolic images. As in the case of verbal <b>query-by-example,</b> PQBE generalizes from the example given by the user, but, instead of having queries in the form of skeleton tables showing the relation scheme, we have skeleton images which are themselves symbolic images. PQBE provides an intuitive interface for use in geographic applications because of its close correspondence with the structure of space. © 1995 Academic Press. All rights reserved...|$|E
40|$|Even {{though there}} is a rapidly growing corpus of {{available}} music recordings, there is still a lack of audio contentbased retrieval systems allowing to explore large music collections without manually generated annotations. In this context, the <b>query-by-example</b> paradigm is commonplace: given an audio recording or a fragment of it (used as query or example), the task is to automatically retrieve all documents from a given music collection containing parts or aspects that are similar to it. Here, the notion of similarity used to compare different audio recordings (or fragments) is of crucial importance, and largely depends on the application in mind as well as the user requirements. In this tutorial, we present and discuss various contentbased retrieval tasks based on the <b>query-by-example</b> paradigm. More specifically, we consider audio identification...|$|E
30|$|The {{huge amount}} of {{heterogeneous}} speech data stored in audio and audiovisual repositories makes it necessary to develop efficient methods for speech information retrieval. There are different speech information retrieval tasks, including spoken document retrieval (SDR), keyword spotting (KWS), spoken term detection (STD), and <b>query-by-example</b> spoken term detection (QbE STD).|$|E
40|$|We {{present a}} novel {{framework}} for intelligent search and retrieval by image content composition. Very {{different from the}} existing <b>Query-by-Example</b> paradigm, logical queries are expressed using categories of similar regions without any starting example region. The set of region category representatives constitutes the "photometric region thesaurus" of the image database...|$|E
40|$|We {{present a}} novel {{framework}} for intelligent search and retrieval by image region composition. Unlike traditional <b>Query-by-Example</b> paradigm, no starting example image is used : the user provides its mental representation of target image {{by means of}} a region photometric thesaurus. It gives an overview of the database content in the query interface...|$|E
40|$|Abstract: A {{detailed}} {{evaluation of}} the use of texture features in a <b>query-by-example</b> approach to image retrieval is presented. Three radically different texture feature types motivated by i) statistical, ii) psychological and iii) signal processing points of view are used. The features were evaluated and tuned on retrieval tasks from the Corel collection and then evaluated and teste...|$|E
40|$|In this article, a {{heuristic}} {{version of}} Multidimensional Scaling (MDS) named - 55 {{is used for}} audio retrieval and browsing. 318, like MDS, maps objects into an Euclidean space, such that similarities are preserved. In addition of being more efficient than MDS it allows <b>query-by-example</b> type of query, which makes it suitable for a content-based retrieval purposes...|$|E
40|$|XML {{is a wide}} used {{general-purpose}} annotation formalism {{for creating}} custom markup languages. XML annotations give structure to plain documents to interpret their content. To extract information from XML documents XPath and XQuery languages can be used. However, the learning of these dialects requires a considerable effort. In this context, the traditional <b>Query-By-Example</b> methodology (for Relational Databases) {{can be an important}} contribute to leverage this learning process, freeing the user from knowing the specific query languages details or even the document structure. This paper describes how we apply the <b>Query-By-Example</b> concept in a Web-application for information retrieval from XML documents, the GuessXQ system. This engine is capable of deducing, from an example, the respective XQuery statement. The example consists of marking the desired components directly on a sample document, picked-up from a collection. After inferring the corresponding query, GuessXQ applies it to the collection to obtain the desired result...|$|E
40|$|As the {{quantity}} of software artifacts, mainly source code and software models, stored in repositories increases, the need for their efficient search becomes more important. In this paper we propose content-based query (a. k. a <b>query-by-example)</b> approach for searching software model repositories, in order to retrieve significant models or model fragments. The <b>query-by-example</b> search conveys the user need in form of a model or pattern specified in a coarse way. Our approach incorporates analysis and indexing of models using textual information retrieval techniques, which exploit {{the knowledge of the}} metamodel the models conform to. This allows us to explore different segmentation granularities on models and different indexing techniques ranging from simple bag of words, to index structures which integrate metamodel information. We detail the proposed theoretical framework, the implementation of the method upon open-source architectures, and we discuss the results of our experiments upon a public dataset of UML models...|$|E
40|$|Specifying event {{sequence}} queries {{is challenging}} even for skilled computer professionals familiar with SQL. Most {{graphical user interfaces}} for database search use a query-by-filters approach, which is often effective, but applies an exact match criteria. We describe a new <b>query-by-example</b> interface, in which users specify a pattern by simply placing events on a blank timeline, producing a similarity-ranked list of results. Users customize the similarity measure by four decision criteria, enabling them to reduce the impact of missing, extra, or swapped events or the impact of time shifts. We describe an example of use with electronic health records based on our ongoing collaboration with hospital physicians. Then we report on a controlled experiment with 18 participants that compared query-by-filters and <b>query-by-example</b> features. We report on {{the advantages and disadvantages}} of each approach and conclude with recommendations for the design of a hybrid approach combining both interfaces...|$|E
40|$|Retrieving {{information}} from the ever-increasing amount of unannotated audio and video recordings requires techniques such as unsupervised pattern discovery or <b>query-by-example.</b> In this paper we focus on queries that are specified {{in the form of}} an audio snippet containing the desired word or expression excised from the target recordings. The task is to retrieve all-and-only the instances whose match score with the query meet an absolute criterion. For this purpose we introduce a distance measure between two acoustic vectors that can be calibrated in a completely unsupervised manner. The use of that measure also allows the use of a fast matching approach, which makes it possible to skip more than 97 % of full-fledged DTW with-out affecting performance in terms of precision and recall. We demonstrate the effectiveness of the proposals with <b>query-by-example</b> experiments conducted on a read speech corpus for English and a spontaneous speech corpus for Dutch...|$|E
40|$|Retrieving spoken {{content with}} spoken queries, or query-by- example spoken term {{detection}} (STD), is attractive {{because it makes}} possible the matching of signals directly on the acoustic level without transcribing them into text. Here, we propose an end-to-end <b>query-by-example</b> STD model based on an attention-based multi-hop network, whose input is a spoken query and an audio segment containing several utterances; the output states whether the audio segment includes the query. The model can be trained in either a supervised scenario using labeled data, or in an unsupervised fashion. In the supervised scenario, {{we find that the}} attention mechanism and multiple hops improve performance, and that the attention weights indicate the time span of the detected terms. In the unsupervised setting, the model mimics the behavior of the existing <b>query-by-example</b> STD system, yielding performance comparable to the existing system but with a lower search time complexity...|$|E
30|$|The most similar {{evaluations}} to our evaluation are the MediaEval 2011 and 2012 Search on Speech evaluations [33, 34]. The task of MediaEval and our {{evaluation is}} the same: a <b>Query-by-Example</b> Spoken Term Detection evaluation {{in which participants}} search for audio content within audio content using an audio content query. However, our evaluation differs from MediaEval evaluations in different ways.|$|E
40|$|Abstract. We {{describe}} {{a method for}} indexing and retrieving high-resolution image regions in large geospatial data libraries. An automated feature extraction method is used that generates a unique and specific structural description of each segment of a tessellated input image file. These tessellated regions are then merged into similar groups and indexed to provide flexible and varied retrieval in a <b>query-by-example</b> environment. ...|$|E
40|$|The paper {{describes}} a Pictorial <b>Query-By-Example</b> (PQBE) {{aimed at the}} retrieval of direction relations from Image Databases. PQBE incorporates several features such as object, image and relation retrieval, union, intersection etc. Unlike verbal query languages it does not presume knowledge of keywords for spatial relations {{on behalf of the}} user, nor familiarity with database models, but complex spatial conditions ar...|$|E
40|$|National audienceTo {{search for}} {{specific}} {{elements in a}} marked up document we have, at least, two options: XPath and XQuery. However, the learning curve of these two dialects is high, requiring a considerable level of knowledge. In this context, the traditional <b>Query-by-example</b> methodology (for Relational Databases) {{can be an important}} contribute to make easier this learning process, freeing the user from knowing the specific query languages details or even the document structure. In this paper, we describe how we implement <b>Query-by-example</b> in a Web-application for information retrieval from a collection of structured documents, the GuessXQ system. In essence, we built an engine capable of deduce, from a specific example, the respective XQuery statement. After inferring the generic statement, the engine applies it to all documents in the collection to perform the desired retrieval. A suitable interface allows the end-user to mark over a sample document, picked up from the collection, the path he wants to selec...|$|E
40|$|Measures of {{acoustic}} {{similarity between}} words or other units {{are critical for}} segmental exemplar-based acoustic models, spoken term discovery, and <b>query-by-example</b> search. Dynamic time warping (DTW) alignment cost {{has been the most}} commonly used measure, but it has well-known inadequacies. Some recently proposed alterna-tives require large amounts of training data. In the interest of finding more efficient, accurate, and low-resource alternatives, we consider the problem of embedding speech segments of arbitrary length into fixed-dimensional spaces in which simple distances (such as cosine or Euclidean) serve as a proxy for linguistically meaningful (pho-netic, lexical, etc.) dissimilarities. Such embeddings would enable efficient audio indexing and permit application of standard distance learning techniques to segmental acoustic modeling. In this paper, we explore several supervised and unsupervised approaches to this problem and evaluate them on an acoustic word discrimination task. We identify several embedding algorithms that match or improve upon the DTW baseline in low-resource settings. Index Terms — Fixed-dimensional embedding, segmental acoustic modeling, <b>query-by-example</b> search, speech indexin...|$|E
40|$|Many {{approaches}} to content based retrieval of images {{have focused on}} <b>query-by-example</b> methods in which the database is searched for all images similar to an example image presented by the user. However, <b>query-by-example</b> techniques tend to quickly converge to a small set of images {{that may not be}} of interest. In this paper, we present an alternative method for content based search which is based on active browsing using a data structure called a similarity pyramid. The similarity pyramid organizes large databases into a three dimensional pyramid structure which the user can move through. During the browsing process, the user can give feed-back through the selection of a set of desirable images which we call a relevance set. Once selected, the relevance set can be used to both prune and reorganize the similarity pyramid to best suit the user's task. A novel cross-validation method is also proposed for effectively performing pruning and reorganization operations. 1 Introduction Many ap [...] ...|$|E
40|$|In {{this paper}} {{we present a}} method for {{automatically}} generating acoustic sub-word units that can substitute conventional phone models in a <b>query-by-example</b> spoken term detection system. We generate the sub-word units with {{a modified version of}} our speaker diarization system. Given a speech recording, the original diarization system generates a set of speaker models in an unsupervised manner without the need for training or development data. Modifying the diarization system to process the speech of a single speaker and decreasing the minimum segment duration constraint allows us to detect speaker-dependent sub-word units. For the task of <b>query-by-example</b> spoken term detection, we show that the proposed system performs well on both broadcast and non-broadcast recordings, unlike a conventional phone-based system trained solely on broadcast data. A mean average precision of 0. 28 and 0. 38 was obtained for experiments on broadcast news and on a set of war veteran interviews, respectively. Index Terms — Spoken term detection, zero resource speech recognition, acoustic sub-word unit generation, speaker diarization 1...|$|E
40|$|This paper proposes {{measures}} for estimating {{the similarity of}} two audio signals, the objective being in <b>query-by-example.</b> Both signals are first represented using a set of features calculated in short intervals, and then probabilistic models are estimated for the feature distributions. Gaussian mixture models and hidden Markov models are tested in this study. The similarity of the signals {{is measured by the}} congruence between the feature distributions or by a cross-likelihood ratio test. We calculate the Kullback-Leibler divergence between the distributions by sampling the distributions at the points of the observations vectors. The cross-likelihood ratio test is evaluated using the likelihood of the first signal being generated by the model of the second signal, and vice versa. Simulations were conducted to test the accuracy of the proposed methods on <b>query-by-example</b> of audio. On a database consisting of of speech, music, and environmental sounds the proposed methods enable better retrieval accuracy than the existing methods. 1...|$|E
