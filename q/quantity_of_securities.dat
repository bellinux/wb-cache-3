2|10000|Public
40|$|To {{increase}} {{the efficiency of}} both local and cross-border transfers and collateral transactions, today the vast <b>quantity</b> <b>of</b> <b>securities</b> are being held, transferred and pledged by entries to securities accounts with intermediaries (eg banks, brokers, clearing and settlement systems, etc), rather than in physical form by the investors or directly with the issuers. Unfortunately, {{more often than not}} choice-of-law and substantive law rules continue to reflect assumptions that securities were held, transferred and pledged by physical delivery and were supposedly mainly purely domestic transaction...|$|E
40|$|Conventional Value at Risk {{models are}} {{severely}} constrained while dealing with liquidity risk. This inevitably {{leads to an}} underestimation of overall risk and consequently misapplication of capital {{for the safety of}} financial institutions. Standard Value at Risk (VaR) model assumes that any <b>quantity</b> <b>of</b> <b>securities</b> can be traded without influencing market prices. In reality, most markets are less than perfectly liquid and many securities cannot be traded with ease in markets. This is especially true for emerging market economies where the process of financial sector reform and deepening is currently taking place. Despite episodic evidences of liquidity crisis in the Indian financial markets, risks associated with market illiquidity have not been effectively incorporated into the VaR models. In the face of sudden and persisting off-market prices of some of the securities in their portfolio, the Indian financial organizations often find it difficult to offload these securities without booking significant trading losses. As a consequence, several securities exhibit very low levels of turnover in the secondary segment of the debt market. Also, in most cases, measures of market risk fail to capture the costs of carrying illiquid assets in their portfolio. This becomes a constraining factor for market growth. In this context, the paper attempts to construct a Liquidity adjusted VaR model (L-VaR model) that incorporates liquidity risk in Value at Risk models. The paper tests the performance of L-VaR model vis-a-vis existing VaR models and finds that in the Indian context, the liquidity risk is {{an important component of the}} aggregate risks absorbed by the financial institutions...|$|E
5000|$|Often {{referred}} to as quantitative easing, large-scale asset purchases involve establishing new reserves for the purpose <b>of</b> purchasing large <b>quantities</b> <b>of</b> <b>securities,</b> for example government bonds or private assets, such as mortgage-backed securities, from the private sector. The benefits to these purchases are three-fold: ...|$|R
50|$|It {{is noted}} that the <b>quantity</b> <b>of</b> the <b>securities</b> to be sold is 26% minus one share.|$|R
40|$|This {{paper is}} review of many {{existing}} {{video surveillance system}}s. With the growing <b>quantity</b> <b>of</b> <b>security</b> video, it becomes vital that video surveillance system {{be able to support}} security personnel in monitoring and tracking activities. The aim of the surveillance applications is to detect, track and classify targets. In this paper is described object modelling, activity analysis and change detection. In this paper we will also describe a design of our video surveillance system...|$|R
40|$|Video {{surveillance}} requires {{keeping the}} human in the loop. Software can aid security personnel in monitoring and using video. We {{have developed a}} set of interface components designed to locate and follow important activity within security video. By recognizing and visualizing localized activity, presenting overviews of activity over time, and temporally and geographically contextualizing video playback, we aim to support security personnel in making use <b>of</b> the growing <b>quantity</b> <b>of</b> <b>security</b> video. ACM Classification: H. 5. 1 [Information Interfaces and Presentation]: Multimedia Information Systems – video...|$|R
50|$|Transition management, in the {{financial}} sense, is a service usually offered by sell side institutions to help buy side firms transition a portfolio <b>of</b> <b>securities.</b> Various events including acquisitions and management changes can cause {{the need for a}} portfolio to be transitioned. A typical example would be a mutual fund has decided to merge two funds into one larger fund. In doing this, large <b>quantities</b> <b>of</b> <b>securities</b> will need to be bought and sold. Another frequent occurrence is a firm wanting to liquidate a large portfolio. The process of doing this can be very expensive. The costs include commissions, market impact, bid-offer spreads, and opportunity costs.|$|R
40|$|Tyt. z ekranu tytułowego. Praca doktorska. Akademia Górniczo-Hutnicza im. Stanisława Staszica (Kraków), 2011. Zawiera bibliogr. Dostępna także w wersji drukowanej. Tryb dostępu: Internet. Steganography, cryptography, symmetric, {{asymmetric}} ciphers, {{basics of}} quantum mechanics, qubit, heisenberg uncertainty principle, quantum cryptography, quantum key distribution, BB 84 protocol, key distillation, area of research, related work, {{current status of}} quantum cryptography, cost of quantum cryptography, motivation, system requirements, end-user requirements, motivation and needs of system end-users, high-level protocol, design, {{construction of a new}} high-level security protocol, low-level parameters, bit error estimation, key reconciliation, privacy amplification, other parameters, <b>quantity</b> <b>of</b> <b>security,</b> information theory, measure, entropy <b>of</b> <b>security,</b> personalization, high-level protocol, verification of the protocol, use cases, federated identity, police databas...|$|R
5000|$|... "A Bull is {{the name}} by which the gentlemen of 'Change Alley choose to call all persons who {{contract}} to buy any <b>quantity</b> <b>of</b> government <b>securities,</b> without an intention or ability to pay for it, and who consequently are obliged to sell it again, either at a profit or a loss, before the time comes when they have contracted to take it".|$|R
40|$|Abstract—The rapid {{technological}} developments in computing {{technology and the}} proliferation of wireless network nodes with light infrastructure, have emerged large <b>quantities</b> <b>of</b> <b>security</b> requirements <b>of</b> informational privacy in cyberspace. Due to the inherent nature of open medium, diversity and variability of network topology, wireless networks are greatly difficult to secure by traditional methods. A physical layer key negotiation mechanism to secure wireless networks is proposed to quickly exchange and establish conventional cryptographic keys by exploiting the wireless channel’s characteristics. The physical layer key negotiation mechanism and its supplementary exception handling caused by the variations in communication paths are both described step by step. The simulation results verify the consistency of the keys of legitimate users, robustness and feasibility of this mechanism. Furthermore this cross-layer security technology is an exemplary complement to existing wireless network protocols to improve their security and enhances the ability to resist replay attacks, brute-force attack and eavesdropping...|$|R
50|$|Sherlock Holmes is {{hired by}} a retired art supply dealer from Lewisham, Josiah Amberley, {{to look into}} his wife’s disappearance. She has left with a neighbour, Dr. Ray Ernest, taking a {{sizeable}} <b>quantity</b> <b>of</b> cash and <b>securities.</b> Amberley wants the two tracked down.|$|R
40|$|In {{order to}} {{minimize}} vulnerabilities and achieve target level <b>security,</b> quantification <b>of</b> <b>security</b> is necessary. Unfortunately, <b>quantities</b> estimation <b>of</b> <b>security</b> in earlier stage of software development life cycle (SDLC) is largely missing. The design phase of software development provides the foundation for secure software. Reducing vulnerability at this phase minimizes rework in subsequent development phases. Currently, no efficient measure or method is available to reduce vulnerability at this stage. In order to address this problem, we have develop a methodology {{which is based on}} multiple existing research work, which can able to provide proper prediction <b>of</b> <b>security</b> vulnerabilities with respect to design properties for an object-oriented design...|$|R
40|$|The {{number and}} the {{importance}} of web applications have increased rapidly over the last years. At the same time, the <b>quantity</b> and impact <b>of</b> <b>security</b> vulnerabilities in such applications have grown as well. Since manual code reviews are time-consuming, errorprone and costly, the need for automated solutions has become evident...|$|R
40|$|Liquidity {{is one of}} {{the crucial}} factors in economy which {{reflects}} smooth operation of the markets. In a liquid market, traders are able to transact large <b>quantities</b> <b>of</b> <b>security</b> quickly with minimal trading cost and price impact. Many researchers have investigated the relationship between market liquidity and trading activity of a financial market. According to the existing literature, liquidity can measure different market characteristics such as trading time, tightness, depth, and resiliency. There is significant number of liquidity measures published in the literature. The main goal {{of this study is to}} use a hierarchical clustering algorithm to classify different liquidity measures. We examine the relationship between liquidity measures in order to detect commonality and idiosyncrasy among them. Then, we estimate the correlation among liquidity measures to quantify similarity between them and this quantity is used to develop a hierarchical clustering algorithm. At the end, we analyze the consistency in the structure of the clusters and we conclude that, clusters hold the same structure for almost 80 % of the stocks in our sample. The data set that we are using for this study is NASDAQ High Frequency Trader (HFT) data. This data set contains trading and quoting activities of 26 HFT firms in 120 stocks on the Nasdaq exchange for various dates (in millisecond timestamp) ...|$|R
5000|$|The U.S. Federal Reserve {{has taken}} {{significant}} action {{to stimulate the}} economy after the 2007-2009 recession. The Fed expanded its balance sheet significantly from 2008 to 2014, meaning it essentially [...] "printed money" [...] to purchase large <b>quantities</b> <b>of</b> mortgage-backed <b>securities</b> and U.S. treasury bonds. This bids up bond prices, helping keep interest rates low, to encourage companies to borrow and invest and people to buy homes. It planned to end its quantitative easing in October 2014 but was undecided on when it might raise interest rates from near record lows. The Fed also tied its actions to its outlook for unemployment and inflation {{for the first time in}} December 2012.|$|R
40|$|In this study, {{we have a}} {{research}} of the evaluation index system establishment <b>of</b> the food <b>security</b> in developing country. The developing country should consider the food production, consumption and storage, food trade and self-support rate, average food amount and the food of the poor, the <b>quantity</b> <b>security</b> <b>of</b> food and the quality <b>security</b> <b>of</b> food, the cost and benefit <b>of</b> food <b>security,</b> the relation between stationary security and dynamic stationary of the food, and establish the food security evaluation index system based on the above. The index should include the gross index of food, the individual index <b>of</b> food <b>security,</b> the fluctuating index <b>of</b> food <b>security,</b> the food’s quality index and the index related to the self-support...|$|R
40|$|As {{the barrage}} <b>of</b> {{information}} <b>security</b> intrusions and losses has escalated, so too has the number <b>of</b> information <b>security</b> reports, laws and regulations. According to Carnegie Mellon University’s CERT Coordination Center, the <b>quantity</b> <b>of</b> cyber <b>security</b> incidents reported has roughly doubled {{every year since}} 2000 – jumping from nearly 22, 000 incidents for all of 2000 to 76, 000 {{in the first half}} of 2003 alone. A survey of the literature reveals that this increase has been mirrored in the growth of reports and guidelines. Congress and state legislatures have responded with several major information security bills and are considering more. Given this activity, why hasn’t more progress been made to secure our information systems? After all, the problem is well known; many solutions have been proposed; the technologies are proven and readily available; and the consequences of inaction are becoming clearer every day. The Business Software Alliance formed the Information Security Governance Task Force with that question in mind. Our goal is to frame a response in terms that organizations can understand and readily implement. We are committed to delivering quality softwar...|$|R
40|$|The Italian Government Security {{primary market}} {{relies on a}} primary dealer system, i. e. the Treasury selects a group of {{intermediaries}} called Specialists, who benefit from a set of obligations and privileges attached to their status. Academic literature paid scant attention {{to one of the}} main privileges, namely the right to participate in reserved auction reopenings. This consists in the right to buy predetermined additional <b>quantities</b> <b>of</b> Government <b>securities</b> at the price settled at the auction. This paper attempts to price this privilege as a call option written on the auctioned bonds in the framework of the Cox – Ingersoll – Ross model. No matter the one-day life, the option has a value significantly different from zero. Moreover, the option value helps explaining part of the mispricing occurring on auction days between the primary and secondary market...|$|R
40|$|Abstract [...] - The {{number and}} the {{importance}} of Rich Internet Applications (RIA) have increased rapidly over the last years. At the same time, the <b>quantity</b> and impact <b>of</b> <b>security</b> vulnerabilities in such rich internet applications (RIA) have increasing as well. Since manual code reviews are time consuming, error prone and costly and it need skilled developers or programmers to review the manual source code review, the need for automated solutions has become evident. In this paper, we address the problem <b>of</b> application <b>security</b> vulnerable detection in Adobe Flex (Rich Internet Applications) platform in web 2. 0 applications by means of static source code analysis. To this end, we present precise analysis targeted at the unique reference semantics commonly found in RIA based web applications or widgets (small applications which will run on fly i. e. drag and drop) developed in Adobe Flex Framework or Action Script 3. 0. Moreover, we enhance the quality and <b>quantity</b> <b>of</b> the generated vulnerability reports...|$|R
40|$|Previous {{empirical}} research {{has attempted to}} quantify the extent of price pressure when major <b>quantities</b> <b>of</b> a <b>security</b> are sold or bought, but most studies suffer {{from the fact that}} the unusually large sales or purchases involve information effects as well. We examine forced selling of fallen angel bonds by insurance companies to estimate price pressure effects. We restrict our sample of downgraded bonds to include only firms whose stock has no significant reaction to the downgrade, making the sale of these fallen angels far more likely to merely represent regulatory pressure to dispose of junk bonds. Once we control for information, we find that price pressure effects are negligible, if not non-existent. To the extent that any price pressure effects show up in these bond sales, they ought to be greater for illiquid bonds. We do not find that bond liquidity explains the variation in bond returns in our information-free sample, further supporting our contention that price pressure is not a major factor in security pricing...|$|R
40|$|This paper {{describes}} a newly developed forensic marker technology, known as Datatrace DNA (Digital Nanoparticle Authentication), {{which offers a}} groundbreaking approach to counterfeit security protection through nanotechnology that is invisibly embedded within the molecular structure of a manufactured product. Extremely tiny <b>quantities</b> <b>of</b> some <b>security</b> compounds (called security markers) {{can be incorporated into}} various sensitive materials, such as explosives, identification documents, printing inks and weapons. Each marker possesses unique or unusual properties that are detected by the Datatrace hand-held electronic reader, known as 2 ̆ 2 The Authenticator 2 ̆ 2. As such, the Datatrace system provides a secure and invisible barcode for authentication. The DatatraceDNA® markers are very stable and cannot be destroyed even at 1000 °C, which provides a life-time protection for the labelled products. Therefore, this novel technology offers the potential to reduce criminal activities by deterring counterfeiting and theft, and assisting in the recovery and return of assets that have been stolen...|$|R
40|$|Major crime drops were {{experienced}} in the United States and most other industrialised countries for a decade from the early to mid- 1990 s. Yet there is little agreement over explanation or lessons for policy. Here it is proposed that change in the <b>quantity</b> and quality <b>of</b> <b>security</b> was a key driver of the crime drop. From evidence relating to vehicle theft in two countries it is concluded that electronic immobilisers and central locking were particularly effective. It is suggested that reduced car theft may have induced drops in other crime including violence. From this platform a broader security hypothesis, linked to routine activity and opportunity theory, is outlined...|$|R
40|$|I study {{a simple}} dynamic general {{equilibrium}} monetary model to interpret key macroeconomic {{developments in the}} U. S. economy both prior to and after the Great Recession. In normal times, when the Feds policy rate is above the zero lower bound, the Fed can control ination and countercylical monetary policy works in a textbook man-ner. When a shock drives the policy rate to the zero lower bound, the economy enters a liquidity trap scenario in which open market pur-chases <b>of</b> government <b>securities</b> have no real or nominal e¤ects, apart from expanding the supply of excess reserves in the banking sector. In a liquidity trap, the Fed loses control of ination, which is now determined by the 8 ̆ 5 scal authority. It is possible for the Fed in this case to lower ination by selling o ¤ su ¢ cient <b>quantities</b> <b>of</b> its <b>security</b> holdings and by refusing to monetize debt. It is not, however, possible for the Fed to raise ination without 8 ̆ 5 scal accommodation. The Fed can, in this case, do no better than to keep its policy rate {{as low as possible}} into the inde 8 ̆ 5 nite future. ...|$|R
40|$|This study aims to (1) {{determine}} the number of optimal raw material purchasing, (2) {{determine the}} optimal order frequency, (3) determine the optimal total inventory cost, (4) determine the <b>quantity</b> <b>of</b> supply <b>security</b> (safety stock), (5) knowing time reordering (re order point). The data were studied in the form of data needs raw materials, and costs incurred in ordering and storage during the year 2011. Techniques of data collection by interview and observation. Discussion of the method used is descriptive discussion is made using a systematic picture of the object studied and the decision optimization techniques to synthesize an optimal decision in the field of industrial management. The approach used is the Economic Order Quantity (EOQ) method. Data analysis techniques were used: (1) determining the <b>quantity</b> <b>of</b> optimal raw material purchasing, (2) determine the optimal frequency of purchase, (3) determine the total cost of inventory, (4) determining the reorder point, (5) determine the time of booking again. Results of analysis of raw material inventory control birdhouse manufacturing company Amanah is concluded as follows: (1) the optimal purchase <b>quantity</b> <b>of</b> 767. 22 kg, the frequency of purchase as many as 13 times, (2) the total inventory cost of Rp 2, 444, 577. 94 (3) safety stock <b>quantity</b> <b>of</b> 525 kg, (4) re-ordering is done at 649 kg. Based on the above conclusions, the author gives advice to UD. Amanah to consider the use of determining the EOQ methods and safety stock and when the company had an order re-order inventory control can be achieved effectively and efficiently. Keywords: Raw Material Inventory EO...|$|R
5000|$|Experts {{are hopeful}} that other assets could {{take the place of}} National Debt as the base asset to back Federal Reserve notes, and Alan Greenspan, long the head of the Federal Reserve, has been quoted as saying, [...] "I am {{confident}} that U.S. financial markets, which are the most innovative and efficient in the world, can readily adapt to a paydown of Treasury debt by creating private alternatives with many of the attributes that market participants value in Treasury securities." [...] In principle, the government could still issue debt securities in significant quantities while having no net debt, and significant <b>quantities</b> <b>of</b> government debt <b>securities</b> are also held by other government agencies.|$|R
40|$|May 26, 2010 The {{financial}} crisis that began {{nearly three years}} ago has caused great hardship for people {{in many parts of}} the world and represented the most profound challenge to central banks since the Great Depression. Faced with unprecedented financial stresses and sharp contractions in economic activity, many central banks, including the Federal Reserve, responded with extraordinary measures. In the United States, we lowered the federal funds rate target to a range of 0 to 1 / 4 percent to help mitigate the economic downturn; we expanded the scale, scope, and maturity of our lending to provide needed liquidity to financial institutions and to address dislocations in financial markets; we jointly established currency swap lines with foreign central banks (including the Bank of Japan) to ensure the global availability of dollar funding; and we purchased a large <b>quantity</b> <b>of</b> longer-term <b>securities</b> to help improve the functioning of financial markets and support economic recovery. 1 Looking to the future, central banks around the world are working with their governments to prevent future crises by strengthening frameworks for financial regulation and supervision...|$|R
40|$|The {{number and}} the {{importance}} of web applications have increased rapidly over the last years. At the same time, the <b>quantity</b> and impact <b>of</b> <b>security</b> vulnerabilities in such applications have grown as well. Since manual code reviews are time-consuming, errorprone and costly, the need for automated solutions has become evident. In this paper, we address the problem of vulnerable web applications by means of static source code analysis. To this end, we present a novel, precise alias analysis targeted at the unique reference semantics commonly found in scripting languages. Moreover, we enhance the quality and <b>quantity</b> <b>of</b> the generated vulnerability reports by employing a novel, iterative two-phase algorithm for fast and precise resolution of file inclusions. We integrated the presented concepts into Pixy [14], a highprecision static analysis tool aimed at detecting cross-site scripting vulnerabilities in PHP scripts. To demonstrate the effectiveness of our techniques, we analyzed three web applications and discovered 106 vulnerabilities. Both the high analysis speed as well as the low number of generated false positives show that our techniques can be used for conducting effective security audits...|$|R
40|$|Main {{goal of the}} diploma {{thesis is}} to {{research}} liquidity management problems of the Federal Reserve System during banking crisis 1929 [...] 1933. Monetary policy implementation based on the implicit reserve targeting was not convenient in times of sharp expansion of the demand for reserves. FED was misled by Real-bills and Riefler-Burgess doctrine and considers monetary condition to be easy. Money interest rates responded very moderately to the shortage of the banking system's liquidity. We can find origin of the first quantitative easing in 1932 when FED first bought larger <b>quantities</b> <b>of</b> the government <b>securities.</b> Expansionary monetary policy during the banking crisis 1929 [...] 1933 was also potentially limited by the conflict among U. S. financial stability and sustainability of the gold standard...|$|R
50|$|The UK {{national}} debt {{is the total}} <b>quantity</b> <b>of</b> money borrowed by the Government of the United Kingdom at any time through the issue <b>of</b> <b>securities</b> by the British Treasury and other government agencies.|$|R
5000|$|Each {{point on}} the LM curve {{reflects}} a particular equilibrium situation in the money market equilibrium diagram, based on a particular level of income. In the money market equilibrium diagram, the liquidity preference function is simply the willingness to hold cash balances instead <b>of</b> <b>securities.</b> For this function, the nominal interest rate (on the vertical axis) is plotted against the <b>quantity</b> <b>of</b> cash balances (or liquidity), on the horizontal. The liquidity preference function is downward sloping. Two basic elements determine the <b>quantity</b> <b>of</b> cash balances demanded (liquidity preference) and therefore the position and slope of the function: ...|$|R
40|$|The value <b>of</b> a firm’s <b>securities</b> {{measures}} {{the value of}} the firm’s productive assets. If the assets include only capital goods and not a permanent monopoly franchise, the value <b>of</b> the <b>securities</b> {{measures the}} value of the capital. Finally, if the price of the capital can be measured or inferred, the <b>quantity</b> <b>of</b> capital is the value divided by the price. A standard model of adjustment costs enables the inference of the price of installed capital. Data from U. S. corporations over the past 50 years imply that corporations have formed large amounts of intangible capital, especially in the past decade. (JEL E 44, G 12) Securities markets—primarily the stock market—measure the value of a firm’s capital stock. The value is the product of the price of installed capital and the <b>quantity</b> <b>of</b> capital. This paper is about inferring the <b>quantity</b> <b>of</b> capital and therefore the amount of capital accumulation from the observed values <b>of</b> <b>securities.</b> In the simplest case, without adjustment costs, the price of capital is observed in capital goods markets and is also the price of installed capital. The <b>quantity</b> <b>of</b> capital is the value observed in the stock market divided by the price. More generally, in the presence of convex adjustment costs, the observed value of capital is the product of the shadow value of installed capital and the <b>quantity</b> <b>of</b> capital. The shadow value can be inferred from the marginal adjustment-cost schedule. Then the <b>quantity</b> <b>of</b> capital is the value of capital divided by the shadow value of capital. The method developed in this paper provides a way to measure intangible capital accumulated by corporations, where both the flow of investment and the stock of capital are not directly observed. There are good reasons to believe that otherwise unmeasurable intangibl...|$|R
40|$|The {{number and}} the {{importance}} of web applications have increased rapidly over the last years. At the same time, the <b>quantity</b> and impact <b>of</b> <b>security</b> vulnerabilities in such applications have grown as well. Since manual code reviews are time-consuming, error prone and costly, the need for automated solutions has become evident. Many web applications written in ASP suffer from injection vulnerabilities, and static analysis makes it possible to track down these vulnerabilities before they are exposed on the web. In this paper, we address the problem of vulnerable web applications by means of static source code analysis. To this end, we propose a new technique to detect XSS attacks and SQL injection vulnerabilities based on taint analysis, It tracks various kinds of external input, tags taint types, constructing control flow graph is constructed based on the use of data flow analysis of the relevant information, taint data propagate to various kinds of vulnerability functions, and detect the XSS or SQL Injection vulnerability in web application’s source code. Results show the benefits of the tool in identifying potential security vulnerabilities...|$|R
5000|$|Though {{it is used}} in kayaks {{of various}} shapes and sizes, it is almost a {{compulsory}} accessory for paddlers with high volume kayaks that have no bulkheads, where the <b>quantity</b> <b>of</b> water filling the kayak could be unmanageable and in [...] "skin-on-frame" [...] kayaks where the construction method makes the adoption of bulkheads impractical. It {{should be used in}} conjunction with flotation bags adding an extra level <b>of</b> <b>security.</b>|$|R
40|$|An {{increasing}} {{focus on}} improved disclosures {{has been the}} regulatory thrust <b>of</b> <b>securities</b> regulations since the great crash of 1929. India gave up the merit based system of a controller regulating the issue <b>of</b> <b>securities</b> in favour <b>of</b> the disclosure based regulatory philosophy in 1988. Since then an increasing focus on public disclosure has been a priority with SEBI, the Indian regulator. However, {{in an attempt to}} improve the quality of disclosure, a necessary waste product has developed – that <b>of</b> the <b>quantity</b> <b>of</b> disclosure. Today with new regulations being added by the legislature, SEBI and stock exchanges, we see an excessive duplication of disclosure particularly of listed companies. There are several areas where net disclosure of information can be maintained even while reducing the <b>quantity</b> <b>of</b> information brought out. This paper examines some areas which require reduction of information flow because the information is already out in the public domain. The paper advocates a transition to a company registration with greater emphasis on continuous disclosures and a relatively easy track for seasoned companies to raise capital without an extensive prospectus centered regulations. ...|$|R
40|$|Increasing {{numbers of}} alerts {{produced}} by network intrusion detection systems (NIDS) have burdened the job <b>of</b> <b>security</b> analysts especially in identifying {{and responding to}} them. The tasks of exploring and analysing large <b>quantities</b> <b>of</b> communication network <b>security</b> data are also difficult. This thesis studied the application of visualisation in combination with alerts classifier to make the exploring and understanding <b>of</b> network <b>security</b> alerts data faster and easier. The prototype software, NSAViz, has been developed to visualise and to provide an intuitive presentation <b>of</b> the network <b>security</b> alerts data using interactive 3 D visuals with an integration of a false alert classifier. The needs analysis of this prototype {{was based on the}} suggested needs <b>of</b> network <b>security</b> analyst's tasks as seen in the literatures. The prototype software incorporates various projections of the alert data in 3 D displays. The overview was plotted in a 3 D plot named as "time series 3 D AlertGraph" which was an extension of the 2 D histographs into 3 D. The 3 D AlertGraph was effectively summarised the alerts data and gave the overview <b>of</b> the network <b>security</b> status. Filtering, drill-down and playback of the alerts at variable speed were incorporated to strengthen the analysis. Real-time visual observation was also included. To identify true alerts from all alerts represents the main task <b>of</b> the network <b>security</b> analyst. This prototype software was integrated with a false alert classifier using a classification tree based on C 4. 5 classification algorithm to classify the alerts into true and false. Users can add new samples and edit the existing classifier training sample. The classifier performance was measured using k-fold cross-validation technique. The results showed the classifier was able to remove noise in the visualisation, thus making the pattern of the true alerts to emerge. It also highlighted the true alerts in the visualisation. Finally, a user evaluation was conducted to find the usability problems in the tool and to measure its effectiveness. The feed backs showed the tools had successfully helped the task <b>of</b> the <b>security</b> analyst and increased the security awareness in their supervised network. From this research, the task of exploring and analysing a large amount <b>of</b> network <b>security</b> data becomes easier and the true attacks can be identified using the prototype visualisation tools. Visualisation techniques and false alert classification are helpful in exploring and analysing network security data. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
60|$|The latter end of July {{the king}} {{received}} advice that the Imperialists {{had formed a}} magazine for provision at a town called Freynstat, twenty miles from Nuremberg. Hither all the booty and contributions raised in the Upper Palatinate, and parts adjacent, was brought and laid up as in a place <b>of</b> <b>security,</b> a garrison <b>of</b> 600 men being placed to defend it; and when a <b>quantity</b> <b>of</b> provisions was got together, convoys were appointed to fetch it off.|$|R
