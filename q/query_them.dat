70|474|Public
50|$|It is {{necessary}} but {{not sufficient to}} have implementations of the map and reduce abstractions in order to implement MapReduce. Distributed implementations of MapReduce require a means of connecting the processes performing the Map and Reduce phases. This may be a distributed file system. Other options are possible, such as direct streaming from mappers to reducers, or for the mapping processors to serve up their results to reducers that <b>query</b> <b>them.</b>|$|E
30|$|However, for the BDI Ontology system, {{since there}} is no easy {{solution}} for structural heterogeneities in the source schemas, it is impossible to execute the query directly. Either we must transform the data so that HAR- 1 & 2 and HAR- 3 share the same structure, or we tag them with different concepts and <b>query</b> <b>them</b> separately.|$|E
40|$|Set-valued {{attributes}} are {{convenient to}} model complex objects {{occurring in the}} real world. Currently available database systems support the storage of set-valued attributes in relational tables but contain no primitives to <b>query</b> <b>them</b> e#ciently. Queries involving set-valued attributes either perform full scans of the source data or make multiple passes over single-value indexes {{to reduce the number}} of retrieved tuples...|$|E
50|$|This {{class is}} the most common base class for Objective-C {{hierarchies}} and provides standard methods for working with objects by managing the memory associated with <b>them</b> and <b>querying</b> <b>them.</b>|$|R
50|$|Oboe {{was limited}} to one {{aircraft}} because the onboard transponder would send pulses every time the ground stations <b>queried</b> <b>them.</b> If more than one aircraft turned on their Oboe, the ground stations would start to receive several return pulses for every query, with no way to distinguish between them.|$|R
40|$|Representing {{descriptions}} of movements in databases and <b>querying</b> <b>them</b> {{is a basic}} capability required in mobile data management. In this demonstration, we show {{for the first time}} a prototype implementing a data model and query language for moving objects (trajectories) completely integrated into a DBMS environment, including query optimization and user interface issues such as animation. 1...|$|R
40|$|To {{unlock the}} full {{potential}} of Linked Data sources, we need flexible ways to <b>query</b> <b>them.</b> Public sparql endpoints aim to fulfill that need, but their availability is notoriously problematic. We there-fore introduce Linked Data Fragments, a publishing method that allows efficient offloading of query execution from servers to clients through a lightweight partitioning strategy. It enables servers to maintain availability rates {{as high as}} any regula...|$|E
30|$|The problem arising {{is how to}} {{deal with}} more than one entry per bucket. A naive {{solution}} is to use E memory backs, one for each possible entry, and <b>query</b> <b>them</b> in parallel. The additional cost is acceptable compared to the saved SRAM. In Section 7 we will discuss this issue in more detail and present techniques that allow multiple entries per bucket but do not require parallel or sequential memory accesses.|$|E
40|$|XML {{itself does}} not support hypermedia, but the XLink {{standard}} has been defined to make XML usable for hypermedia. One of XLinks most interesting features is its support for external links and linkbases, which {{makes it possible to}} create links between resources without having to change the resources. In order to use these links, user agents must access linkbases and <b>query</b> <b>them</b> for relevant links, and we present our approach to create a protocol for linkbase access...|$|E
30|$|The overall rasdaman system {{architecture}} {{is shown in}} Fig.  9. The core functionality of the framework developed consists of the rasdaman Array Database System for storage of remote sensing data and OGC WCPS interface standard for <b>querying</b> <b>them.</b> Rasdaman {{was selected as the}} core system of our implementation due to its proven robustness, novelty and efficiency in handling big imaging data [25, 26].|$|R
40|$|Previous {{authors have}} shown {{how to build}} FM-indexes {{efficiently}} in external memory, but <b>querying</b> <b>them</b> efficiently remains an open problem. Searching naïvely for a pattern P requires (Θ (|P|)) random access. In this paper we show how, by storing a few small auxiliary tables, we can access data only in {{the order in which}} they appear on disk, which should be faster...|$|R
40|$|Inductive {{databases}} {{are usually}} viewed as databases that contain models, next to data, such that mining the data essentially {{boils down to}} <b>querying</b> <b>them</b> for models. This unifies data mining with database querying. In his chapter, we consider experiment databases. Experiment databases are similar to regular inductive databases, but operate {{at a higher level}} of abstraction. They store not necessarily the models themselves, but properties of those models, and of the learners and datasets used to construct <b>them.</b> <b>Querying</b> <b>them</b> will reveal information about the behavior of data mining algorithms and the models they result in, when run on particular datasets. Thus, experiment databases unify meta-learning (learning about data mining systems) with database querying. In this chapter we discuss the advantages that experiment databases can offer in terms of openness of research, collaboration, reproducibility of experiments, thoroughness of analysis of experimental results, and correctness of their interpretation. We also describe the (principled) design of a pilot experiment database, and illustrate its use. status: publishe...|$|R
40|$|Abstract. Within organisations, Information Systems are characterised by heterogeneity. The main {{management}} {{tools are}} different Relational and Object Oriented DataBase Management Systems. Therefore, variety, complexity {{and lack of}} integration {{make it difficult for}} casual users to <b>query</b> <b>them.</b> This paper presents WDBQS (Web DataBase Query System); a Web-interface for querying distant Relational and Object Oriented DataBases. This system, dedicated to casual users, proposes simple Web mechanisms to navigate through database schemas, build queries and display results. ...|$|E
40|$|Database as {{a service}} ” {{paradigm}} has gained {{a lot of interest}} in recent years. This has raised questions about the security of data in the servers. Firms outsourcing their XML databases to untrusted parties started to look for new ways to securely store data and efficiently <b>query</b> <b>them.</b> In this paper, encrypted XML documents, their crypto index structures and query processing using these structures are investigated. A comparison of various algorithms in the literature is given...|$|E
40|$|The {{aim of the}} Typological Database System {{project is}} the {{creation}} of a unified interface to numerous independently developed typological databases, which will allow the user to simultaneously <b>query</b> <b>them</b> from a single gateway. The main challenge behind the project lies in the great variability of the included data. In order to provide a unified interface the system will rely on detailed metadata, which will describe the content of each component database in terms of a common description framework. The common framework will be organized into an ontology of linguistic terms and notions, including alternative definitions, glossing standards, and database specific notions. 1...|$|E
40|$|Introduction: This is an {{observational}} study of emergency departments (ED) in California to identify {{factors related to}} the magnitude of ED utilization by patients with mental health needs. Methods: In 2010, an online survey was administered to ED directors in California <b>querying</b> <b>them</b> about factors related to the evaluation, timeliness to appropriate psychiatric treatment, and disposition of patients presenting to EDs with psychiatric complaints...|$|R
40|$|The Internet {{emerges as}} the largest database. Increasingly, users want to issue complex queries across Internet sources to obtain the data they require. However, finding {{relevant}} information sources and <b>querying</b> <b>them</b> man-ually is problematic: there are numerous sources, and they vary {{in the type of}} information objects they contain and in the interface they present to their users. Some sources contain text documents and support simple quer...|$|R
40|$|With Fusion Tables, Google {{has made}} {{available}} a huge repository that {{allows users to}} share, visualize and manage structured data. Since 2009, thousands of tables have been shared online, encompassing data from virtually any domain and entered by all kinds of users, from professional to non-experts. While Fusion Tables are a potentially precious source of freely available structured information {{for all sorts of}} applications, complex <b>querying</b> and composing <b>them</b> is not supported natively, as it requires understanding both the structure and content of tables’ data, which are heterogeneous and produced "bottom-up". In this paper, we discuss ongoing and future work concerning the integration of Fusion Tables in the aim of efficiently integrating, visualizing, and <b>querying</b> <b>them...</b>|$|R
40|$|The Domain Name System (DNS) is {{the global}} lookup service for network resources. To protect DNS information, the DNS Security Extensions (DNSSEC) have been {{developed}} and deployed on branches of the DNS to provide authentication and integrity protection using digital signatures. However, signed DNS nodes {{have been found to}} have an unfortunate side effect: an attacker can <b>query</b> <b>them</b> as reconnaissance before attacking individual hosts on a particular network. There are different ways a zone administrator can minimize information unwanted leakage while still taking advantage of DNSSEC for integrity and source authentication. This paper describes the risk and examines the protocol and operational options and looks at their advantages and drawbacks...|$|E
30|$|The {{development}} of GEOMAGIA 50 has been {{closely linked to}} the data required to construct global spherical harmonic models of the Holocene geomagnetic field (e.g., Korte et al. (2011)). Additionally, it has become common to compare archeomagnetic, volcanic, or sediment data with the location-dependent output of these models (e.g., Haltia-Hovi et al. (2011); Kapper et al. (2014); Tanaka et al. (2012)). To ease such comparisons, we have incorporated functionality to plot and save model predictions for user defined locations (‘Figures and downloads’ section). A description of the available models is given in Additional file 1 and how to <b>query</b> <b>them</b> is given in section ‘Query, plot, visualize’ and in Additional file 1.|$|E
40|$|The {{process of}} searching and {{understanding}} existing vocab-ularies (terminological artifacts) on the Linked Data Web is an intrinsic activity to the consumption {{and production of}} Linked Data. Data consumers trying to find and understand the vocabularies behind datasets in order to <b>query</b> <b>them,</b> or data producers searching for existing resources to describe their data, {{face the challenge of}} semantically searching exist-ing concepts in vocabularies. Traditional search mechanisms do not address the level of semantic matching necessary to match users ’ information needs to vocabulary elements, bringing an additional barrier to the consumption and pro-duction of Linked Data on the Web. This work describes a terminological search mechanism which uses a distributional semantic model to provide a best-effort semantic matchin...|$|E
40|$|International audienceSemi-structured {{data sets}} {{in the form}} of XML {{documents}} have many practical uses and they have motivated a very large amount of work in theoretical, applied and industrial computing. Their efficient exploitation requires specific methods for filtering and <b>querying</b> <b>them,</b> using techniques that are neither keyword searches nor relational methods. In this paper we survey a large body of recent research on efficient querying methods for XML data. Our analysis of the literature follows the three dimensions of stream-processing, parallel processing and performance variability...|$|R
40|$|This {{paper is}} {{concerned}} with querying annotated speech corpora. A growing number of such corpora is currently being created worldwide; however, their usefulness for a wider research community is restricted {{by the lack of}} standard tools for creating, editing, annotating, storing and <b>querying</b> <b>them.</b> Two solutions for these problems are presented here: the XML-based data format TASX for corpus creation and data format exchange and the NXT search tool for querying corpora. Both tools have been applied to the multi-level annotated LeaP corpus of non-native speech. 1...|$|R
40|$|The {{amount of}} {{digitized}} legacy documents {{has been rising}} dramatically {{over the last years}} due mainly to the increasing number of on-line digital libraries publishing this kind of documents. The vast majority of them remain waiting to be transcribed into a textual electronic format (such as ASCII or PDF) that would provide historians and other researchers new ways of indexing, consulting and <b>querying</b> <b>them.</b> In this work, the state-of-the-art Handwritten Text Recognition techniques are applied for the automatic transcription of these historical documents. We report results for several ancient documents...|$|R
40|$|An {{ontology}} is {{an explicit}} specification of shared conceptualization. The Web Ontology Language (OWL) {{is a family}} of knowledge representation languages for authoring ontologies, and is endorsed by the World Wide Web Consortium. The main operation on ontologies is to <b>query</b> <b>them</b> and to store them so as to answer queries efficiently. By mapping ontologies to relational databases, we can leverage the power of SQL for ontology reasoning over millions of instances. We {{address the problem of}} efficiently mapping and querying OWL ontologies using relational databases. We present an OWL ontology mapping tool, called TRANS which can automatically map OWL ontology to mapped relational schema. Using TRANS, we answer both extensional queries and some intentional queries. We compare our approach with schema-aware OWL-mapping tool, Genea[7]. ...|$|E
40|$|The {{existence}} of {{a vast amount of}} document collections both on-line or off-line leads to an overwhelming experience when users attempt to <b>query</b> <b>them.</b> This emphasises the need to develop collaborative approaches for acquiring data/knowledge from distributed and semantically heterogeneous sources of knowledge/information. Work on user preferences has recently acquired more attention in order to retrieve and rank documents which are relevant to the user’s interests. In this paper, we present a hierarchical modeling of a user’s interests/preferences. The proposed hierarchical structure results in a better semantic handling of the users ’ interests and proper matching of documents over these nodes representing the user preferences. Our preliminary experiments show the merits of such an approach and open new avenues of research in this area. ...|$|E
40|$|Some recent {{initiatives}} {{try to take}} {{profit from}} RDF to make XML documents interoperate at the semantic level. Ontologies are used to establish semantic connections among XML languages, and some mechanisms have been defined to <b>query</b> <b>them</b> with natural XML query languages like XPath and XML Query. Generally structure-mapping approaches define a simple translation between trivial XPath expressions and some RDF query language like RDQL; however some XPath constructs cannot be covered in a structure-mapping strategy. In contrast, our work takes the model-mapping approach, respectful with node order, that allows mapping all XPath axis. The obtained XPath implementation has the properties of schema-awareness and IDREF-awareness, {{so it can be}} used to exploit inheritance hierarchies defined in one or more XML schemas...|$|E
40|$|Open IE methods extract {{structured}} propo-sitions from text. However, these propo-sitions {{are neither}} consolidated nor gen-eralized, and <b>querying</b> <b>them</b> {{may lead to}} insufficient or redundant information. This work suggests an approach to or-ganize open IE propositions using entail-ment graphs. The entailment relation uni-fies equivalent propositions and induces a specific-to-general structure. We create a large dataset of gold-standard proposition entailment graphs, and provide a novel algorithm for automatically constructing them. Our analysis shows that predicate entailment is extremely context-sensitive, and that current lexical-semantic resources do not capture many of the lexical infer-ences induced by proposition entailment. ...|$|R
5000|$|... complexity: How steep is the {{learning}} curve for defining new concepts, <b>querying</b> for <b>them</b> or constraining them? are there appropriate tools for simplifying typical workflows? (See also: ontology editor) ...|$|R
3000|$|Alice {{contacts}} {{a number}} of notary groups with a direct <b>query</b> asking <b>them</b> to report what certificate server SRV is offering. The queried group’s members connect to SRV and get c [...]...|$|R
30|$|Different Cloud {{providers}} {{use different}} authentication policies. Also, different resource types require specific credentials {{in order to}} be created and managed. The credentials are not directly available to the Vendor Agents and therefore the agents should <b>query</b> <b>them</b> from the application deployer at the deployment time. The credentials may no longer be requested at the execution time as the agents are deployed in the Cloud and the CA is decoupled by the deployment tools. A Credentials Service is therefore intended to manage all the needed credentials of the vendor agent in relation with the resource classes and SLAs. The Vendor Module can query the credentials for a resource class defined in relation with a specific SLA in order to perform operations on that resource class or its instances.|$|E
40|$|Introduction Database system {{technology}} {{has reached a}} stage now {{in which there is}} a proliferation of independent systems storing and manipulating enormous amount of data. Unfortunately, these systems typically have their own data models, communication processing protocols, query processing systems, concurrency control protocols, consistency management, and other similar aspects of database systems. There is also an increasing need for Interoperability among these systems. Though considerable amount of research has been done in the area of database interoperability, most of it has resulted in solutions that are ad-hoc and procedural. We have developed a declarative environment in which multiple heterogeneous databases interoperate by sharing, interpreting, and manipulating information, in a uniform way. An important criterion for Interacting with multiple databases is the ability to <b>query</b> <b>them</b> in a manner independent of the disc...|$|E
40|$|To {{be fully}} usable, digital {{multimedia}} contents should {{be supported by}} a set of tools to <b>query</b> <b>them,</b> and more generally to manipulate them. This {{is one of the major}} goals of an audio database management system (DBMS). Existing work related to audio documents, e. g., radio or television archives, generally tackles the signal processing aspects, often leaving the DBMS question open, or focusing on a dedicated audio DBMS. In this paper, we lay the foundations for integrating audio into a general purpose DBMS, in the form of an audio abstract data type. We introduce its properties and associated operators. The practical interest and some technical difficulties are underlined. In particular, through a few query examples, we examine the problem of the complexity of the querying expressions (and of time complexity). ...|$|E
40|$|Computational {{experiments}} {{have become an}} integral part of the scientific method, but reproducing, archiving, and <b>querying</b> <b>them</b> is still a challenge. The first barrier to a wider adoption is the fact that it is hard both for authors to derive a compendium that encapsulates all the components needed to reproduce a result and for reviewers to verify the results. In this tutorial, we will present a series of guidelines and, through hands-on examples, review existing tools to help authors create of reproducible results. We will also outline open problems and new directions for database-related research having to do with querying computational experiments...|$|R
60|$|The {{responses}} at last {{given by}} him to their <b>queries</b> guided <b>them</b> {{to the building}} that offered the best accommodation in Sherton--having been enlarged contemporaneously {{with the construction of}} the railway--namely, the Earl of Wessex Hotel.|$|R
40|$|With the {{ubiquity of}} {{large-scale}} graph data {{in a variety of}} application domains, <b>querying</b> <b>them</b> effectively is a challenge. In particular, reachability queries are becoming increasingly important, especially for containment, subsumption, and connectivity checks. Whereas many methods have been proposed for static graph reachability, many real-world graphs are constantly evolving, which calls for dynamic indexing. In this paper, we present a fully dynamic reachability index over dynamic graphs. Our method, called DAG-GER, is a light-weight index based on interval labeling, that scales to million node graphs and beyond. Our extensive experimental evaluation on real-world and synthetic graphs confirms its effectiveness over baseline methods. 1...|$|R
