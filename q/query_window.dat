57|207|Public
50|$|The Bx-tree uses query-window {{enlargement}} {{technique to}} answer queries. Since the Bx-tree stores an object's location as of sometime after its update time, the enlargement involves two cases: a location must either {{be brought back}} to an earlier time or forward to a later time. The main idea is to enlarge the <b>query</b> <b>window</b> so that it encloses all objects whose positions are not within <b>query</b> <b>window</b> at its label timestamp but will enter the <b>query</b> <b>window</b> at the query timestamp.|$|E
50|$|Report all entries that {{intersect}} the <b>query</b> <b>window</b> w as candidates.|$|E
50|$|Invoke Search {{for every}} entry whose MBR intersects the <b>query</b> <b>window</b> w.|$|E
40|$|Optimizing queries {{that involve}} {{operations}} on spatial data requires estimating the selectivity {{and cost of}} these operations. In this paper, we focus on estimating the cost of spatial selections, or <b>window</b> <b>queries,</b> where the <b>query</b> <b>windows</b> and data objects are general polygons. Cost estimation techniques previously proposed in the literature only handle rectangular <b>query</b> <b>windows</b> over rectangular data objects, thus ignoring the very significant cost of exact geometry comparison (the refinement step in a "filter and refine" query processing strategy). The cost of the exact geometry comparison depends on the selectivity of the filtering step and {{the average number of}} vertices in the candidate objects identified by this step. In this paper, we introduce a new type of histogram for spatial data that captures the complexity and size of the spatial objects as well as their location. Capturing these attributes makes this type of histogram useful for accurate estimation, as we experimentally dem [...] ...|$|R
5000|$|Windows Azure Caching- To cache {{result set}} of <b>queries</b> in <b>Windows</b> Azure ...|$|R
40|$|To support location-based {{services}} in wireless data broadcast systems, a distributed spatial index (called DSI) is proposed in this paper. DSI is highly efficient {{because it has}} a linear yet fully distributed structure that naturally facilitates multiple replications of the index by sharing links in different search trees. Search algorithms for point <b>queries,</b> <b>window</b> <b>queries,</b> and kNN queries, based on DSI are presented. Empirical evaluation of DSI are conducted. Result shows that DSI significantly out-performs R-tree and Hilbert Curve Index, two state-of-the-art spatial indexing techniques for wireless data broadcast. 1...|$|R
50|$|The searching {{algorithm}} {{is similar to}} the one used in other R-tree variants. Starting from the root, it descends the tree and examines all nodes that intersect the query rectangle. At the leaf level, it reports all entries that intersect the <b>query</b> <b>window</b> w as qualified data items.|$|E
50|$|After the enlargement, the {{partitions}} of the Bx-tree {{need to be}} traversed to find objects {{falling in}} the enlarged <b>query</b> <b>window.</b> In each partition, {{the use of a}} space-filling curve means that a range query in the native, two-dimensional space becomes a set of range queries in the transformed, one-dimensional space.|$|E
50|$|If {{there are}} any matches for the user's search string, {{the next step is}} to request those files from the server. The user can copy and paste the {{returned}} match, along with a short trigger command, from the <b>query</b> <b>window</b> directly into the channel window. The request is then placed in a file queue within the serving script, and downloaded on a first-come, first-served basis.|$|E
40|$|This {{dissertation}} {{is about}} developing advanced selectivity and cost estimation techniques for query optimization in database systems. It addresses {{the following three}} issues related to cur-rent trends in database research: estimating the cost of spatial selections, building histograms without looking at data, and estimating the selectivity of XML path expressions. The {{first part of this}} dissertation deals with estimating the cost of spatial selections, or <b>window</b> <b>queries,</b> where the <b>query</b> <b>windows</b> and the data objects are general polygons. Previously proposed cost estimation techniques only handle rectangular <b>query</b> <b>windows</b> over rectangular data objects, thus ignoring the significant cost of exact geometry comparison (the refinement step in a “filter and refine” query processing strategy). The cost of the exact geometry comparison depends on the selectivity of the filtering step and the average number of vertices in the candidate objects identified by this step. We develop a cost model for spatial selections that takes these parameters into account. We also introduce a new type of histogram for spatial data that captures the size, location, and number of vertices of the spatial objects. Capturing these attributes makes this type of histogram useful for accurate cost estimation using our cost model...|$|R
5000|$|Digest SSP for HTTP and LDAP <b>queries</b> between <b>Windows</b> and non-Windows systems where Kerberos is not available.|$|R
40|$|Recent {{announcement}} of the MSN Direct Service has demonstrated the feasibility and industrial interest in utilizing wireless broadcast for pervasive information services. To support location-based services in wireless data broadcast systems, a distributed spatial index (called DSI) is proposed in this paper. DSI is highly efficient {{because it has a}} linear yet fully distributed structure that facilitates multiple search paths to be naturally mixed together by sharing links. Moreover, DSI is very resilient in error-prone wireless communication environments. Search algorithms for two classical location-based <b>queries,</b> <b>window</b> <b>queries</b> and kNN queries, based on DSI are presented. Performance evaluation of DSI shows that DSI significantly outperforms R-tree and Hilbert Curve Index, two state-of-the-art spatial indexing techniques for wireless data broadcas...|$|R
5000|$|A user initiates {{a search}} by typing a 'search command' {{followed}} by a 'search string' within the channel window. Various search commands exist, including '@find', '@search', and '@seek', depending on what serving script is being used. [...] Wildcard characters such as * {{can also be used}} in the search string to simplify a search. The search command will then return a list of files to the user's <b>query</b> <b>window</b> if any servers have a file that matches the search string.|$|E
40|$|Abstract. The use of {{a spatial}} index {{followed}} by an exact geometry check (a filter/refine strategy) is commonly applied in spatial database management systems. Its efficiency in selecting a small subset of geographic features from a large feature collection is undebatable. But {{there is a problem}} with the strategy: For a pure overlap test in the filter phase, the filter/refine strategy gets less optimal as the <b>query</b> <b>window</b> grows larger. Loosely speaken, the reason for this is that the candidates falling completely within the area of the <b>query</b> <b>window</b> are not included in the result although a decision can be made from the filter phase. We argue that an overlap test followed by an inside test will reduce the query costs from quadratic to linear as the <b>query</b> <b>window</b> doubles in north- and east dimension. A study on the Land-use resource data set in Norway (DMK) gives an indication of this. ...|$|E
40|$|Abstract—Decomposing a <b>query</b> <b>window</b> into maximal {{quadtree}} blocks is {{a fundamental}} problem in quadtree-based spatial database. Recently, Proietti presented the first optimal algorithm for solving this problem. Given a <b>query</b> <b>window</b> of size n 1 n 2, Proietti’s algorithm takes OðnlÞ time, where nl maxðn 1;n 2 Þ. Based on a strip-splitting approach, this paper presents a new optimal algorithm for solving the same problem. Experimental results reveal that our proposed algorithm is quite competitive with Proietti’s algorithm. Index Terms—Maximal quadtree blocks, optimal algorithm, spatial database, window queries. ...|$|E
25|$|A central {{feature of}} SQL Server Management Studio is the Object Explorer, {{which allows the}} user to browse, select, and act upon any of the objects within the server. It {{can be used to}} {{visually}} observe and analyze query plans and optimize the database performance, among others. SQL Server Management Studio {{can also be used to}} create a new database, alter any existing database schema by adding or modifying tables and indexes, or analyze performance. It includes the <b>query</b> <b>windows</b> which provide a GUI based interface to write and execute queries.|$|R
40|$|TPR-tree is a {{practical}} index structure for moving object databases. Due to the uniform distribution assumption, TPR-tree’s bulk loading algorithm (TPR) is relatively inefficient in dealing with non-uniform datasets. In this paper we present a histogram-based bottom up algorithm (HBU) along with a modified top-down greedy split algorithm (TGS) for TPR-tree. HBU uses histograms to refine tree structures for different distributions. Empirical studies show that HBU outperforms both TPR and TGS {{for all kinds of}} non-uniform datasets, is relatively stable over varying degree of skewness and better for large datasets and large <b>query</b> <b>windows.</b> 1...|$|R
40|$|In {{pervasive}} computing, location-based services (LBSs) {{are valuable}} for mobile clients {{based on their}} current locations. LBSs use spatial <b>window</b> <b>queries</b> to enable useful applications for mobile clients. Based on skewed access patterns of mobile clients, non-flat wireless broadcast {{has been shown to}} efficiently disseminate spatial objects to mobile clients. In this paper, we consider a scenario in which spatial objects are broadcast to mobile clients over a wireless channel in a non-flat broadcast manner to process <b>window</b> <b>queries.</b> For such a scenario, we propose an efficient spatial air index method to handle <b>window</b> <b>query</b> access in non-flat wireless broadcast environments. The concept of largest empty rectangles is used to avoid unnecessary examination of the broadcast content, thus reducing the processing time for <b>window</b> <b>queries.</b> Simulation results show that the proposed spatial air index method outperforms the existing methods under various settings...|$|R
30|$|Query Request Time (TU): Is {{the amount}} of time taken to {{transform}} the range <b>query</b> <b>window</b> to the Hilbert cell set and send it to the CSP over the network.|$|E
3000|$|... [...]. The {{encrypted}} QR {{is sent to}} the CSP as QR {{along with}} the encrypted <b>query</b> <b>window</b> QW. In Lines 9 − 16, starting from the root, the search descends the tree structure and examines all nodes, n, that have Hilbert values less than the queried values, QR. If n [...]...|$|E
40|$|With new {{developments}} in positioning systems and electronics, various researches for moving objects have progressed [3, 5, 6]. Our paper is related to selection queries considering future positions of moving objects, which {{are referred to as}} future queries [5]. An example of the future query is as follows: “which airplanes will be inside a <b>query</b> <b>window</b> 20 minutes fro...|$|E
50|$|This version {{had several}} changes. The game has {{enhanced}} graphics for all buildings. The buildings will {{change at the}} year of 1950 and 2050. There are also 3D animations displayed for each building in the building <b>query</b> <b>windows.</b> The scenarios from the Great Disasters expansion packs are included. The gameplay remains {{the same for the}} most part. Instead of the Braun Llama Dome, there is a Space Terminal which assist the launching of the Arco. The arco can be seen launching from the city along with a special animated video. There are several new animated videos. The opening sequence displays a scene of the Alien/Monster chasing a Launch Arco in space.|$|R
40|$|Abstract. A {{data stream}} is a real-time, continuous, ordered {{sequence}} of items generated by {{sources such as}} sensor networks, Internet traffic flow, credit card transaction logs, and on-line financial tickers. Processing continuous queries over data streams introduces a number of research problems, one of which concerns evaluating <b>queries</b> over sliding <b>windows</b> defined on the inputs. In this paper, we describe our research on sliding <b>window</b> <b>query</b> processing, {{with an emphasis on}} query models and algebras, physical and logical optimization, efficient processing of multiple <b>windowed</b> <b>queries,</b> and generating approximate answers. We outline previous work in streaming query processing and sliding window algorithms, summarize our contributions to date, and identify directions for future work. ...|$|R
40|$|Location-dependent spatial query in the {{wireless}} environment is that mobile users query the spatial objects {{dependent on their}} current location. The <b>window</b> <b>query</b> {{is one of the}} essential spatial queries, which finds spatial objects located within a given window. In this paper, we propose a Hilbert curve-based distributed index for <b>window</b> <b>queries</b> in {{the wireless}} data broadcast systems. Our proposed algorithm allocates spatial objects in the Hilbert-curve order to preserve the spatial locality. Moreover, to quickly answer <b>window</b> <b>queries,</b> our proposed algorithm utilizes the neighbor-link index, which has knowledge about neighbor objects, to return the answered objects. From our experimental study, we have shown that our proposed algorithm outperforms the distributed spatial index...|$|R
40|$|Figure 2. Mundial {{interface}} {{showing an}} English qeury {{that has been}} submitted to the Infoseek search service, retrieving documents in both English and Spanish. all of the variant equivalents for that term. For current evaluation purposes, the <b>query</b> <b>window</b> also has the TREC- 5 queries built in, and the retrieved document lists are persistent between sessions for each user, bein...|$|E
40|$|Many SAS ® tools {{help you}} {{generate}} code. They can make coding easier and less tedious. This generated code {{can be a}} starting point that you can embellish or enhance. The Reports Window is an interactive application used to produce simple or complex reports online quickly. With minimal effort, you can manipulate the variables and columns, and then capture the code to create the DEFINE statements {{and set up the}} environment. The SQL <b>Query</b> <b>Window</b> is an interactive interface that enables you to build, save, and run queries without knowing SQL or using PROC SQL. The query that you build in the SQL <b>Query</b> <b>Window</b> is passed to PROC SQL for processing when you run the query. The Import/Export Wizards transfer data between external data sources and SAS data sets. The wizards present simple windows that guide you through the process, making a complex or infrequent task simpler to perform. This paper and presentation shows you how to create simple reports and queries, how to write to external data sources, and how to capture the code...|$|E
40|$|Abstract. It is {{frequently}} {{the case that}} spatial queries require a result set of objects whose scale – however this may be more precisely defined – {{is the same as}} that of the <b>query</b> <b>window.</b> In this paper we present an approach which considerably improves query performance in such cases. By adding a scale dimension to the schema we make the index structure explicitly “aware ” of the scale of a spatial object. The additional dimension causes the index structure to cluster objects not only by geographic location but also by scale. By matching scales of the <b>query</b> <b>window</b> and the objects, the query then automatically considers only “relevant ” objects. Thus, for example, a <b>query</b> <b>window</b> encompassing an entire world map of political boundaries might return only national borders. Note that “scale ” is not necessarily synonymous with “size”. This approach improves performance by both narrowing the initial selection criteria and by eliminating the need for subsequent filtering of the query result. In our performance measurements on databases with up to 40 million spatial objects, the introduction of a scale dimension decreased I/O by up to 4 orders of magnitude. The performance gain largely depends on the object scale distribution. We investigate a broad set of parameters that affect performance and show that many typical applications could benefit considerably from this technique. Its scalability is demonstrated by showing that the benefit increases with the size of the query and/or of the database. The technique is simple to apply and can be used with any multidimensional index structure that can index spatial extents and can be efficiently generalized to three or more dimensions. In our tests we have used the BANG index structure. ...|$|E
40|$|The {{processing}} of data streams plays {{a central role in}} emerging applications such as pervasive computing, sensor-based environments, and on-line business processing. Such applications receive unbounded input streams that are processed against a set of standing queries. To overcome the infinite nature of data streams, the <b>queries</b> define <b>windows</b> (scopes of interest) to limit access to the unbounded input data. The <b>window</b> <b>queries</b> are repeatedly evaluated each time a new input arrives, and hence are termed sliding <b>window</b> <b>queries.</b> The straightforward application of traditional pipelined query processing techniques to sliding <b>window</b> <b>queries</b> may result in inefficient and incorrect behavior. ^ In this thesis, I address several research challenges for building a scalable query processing engine for stream database systems. I propose various scheduling techniques that guarantee the correct execution of pipelined sliding <b>window</b> <b>queries.</b> Based on the scheduling techniques, I present new algorithms for correctly evaluating complex window-based query operations. I address scalability issues through sharing the execution of multiple concurrent queries and propose new query evaluation strategies for shared execution. My research on shared execution opens new venues for optimizing multiple sliding-window <b>queries</b> considering the <b>window</b> size as an optimization parameter. I propose new algorithms to evaluate join queries over data streams using general window constraints. Since video is considered a stream of consecutive image frames, video operations may be expressed as queries over video streams. From this viewpoint I used the proposed query engine to express and execute basic video operations such as fast forward and region-based blurring as queries over video streams. ^ I have studied the performance of the proposed techniques both analytically and experimentally, using real streams of retail transactions, medical video data, and synthetic data streams, and {{in the context of a}} prototype stream database system. The performance study demonstrates the superiority and practicality of the proposed techniques in terms of response time and throughput. ...|$|R
40|$|In this paper, we motivate four {{different}} user defined <b>window</b> <b>query</b> classes and derive a probabilistic model {{for each of}} them. For each model, we characterize the efficiency of spatial data structures {{in terms of the}} expected number of data bucket accesses needed to perform a <b>window</b> <b>query.</b> Our analytical approach exhibits the performance phenomena independent of data structure and implementation details and whether the objects are points or non-point objects. ...|$|R
40|$|Sampling {{provides}} fundamental {{support to}} numerous applications that cannot afford to materialize all the objects {{arriving at a}} rapid speed. Existing stream sampling algorithms guarantee small space and query overhead, but all require worst-case update time proportional {{to the number of}} samples. This creates a performance issue when a large sample set is required. In this paper, we propose a new sampling algorithm that is optimal simultaneously in all the three aspects: space, query time, and update time. In particular, the algorithm handles an update in O(1) worst-case time with a very small hidden constant. Our algorithm also ensures a strong independence guarantee: the sample sets of all the queries are mutually independent as long as the overlap between two <b>query</b> <b>windows</b> is small...|$|R
40|$|Features of the VASCO R-tree JAVA TM applet are {{described}} {{to support its}} demonstration. This includes {{an explanation of the}} different R-tree node splitting methods that are implemented in VASCO and of the functionality of the control panel of the applet. The applet enables users to visualize the different variants of the R-tree as well as observe their behavior for finding the nearest neighbors to a query point and the objects within a given <b>query</b> <b>window</b> in an incremental manner. The applet can be foun...|$|E
40|$|Analysis {{of range}} queries on spatial (multidimensional) data is both {{important}} and challenging. Most previous analysis attempts have made certain simplifying {{assumptions about the}} datasets and/or queries to keep the analysis tractable. As a result, {{they may not be}} universally applicable. This paper proposes a set of five analysis techniques to estimate the selectivity and number of index nodes accessed in serving a range query. The underlying philosophy behind these techniques is to maintain an auxiliary data structure called a density file, whose creation is a onetime cost, which can be quickly consulted when the query is given. The schemes differ in what information is kept in the density file, how it is maintained, and how this information is looked up. It is shown that one of the proposed schemes, called Cumulative Density (CD), gives very accurate results (usually less than 5 % error) using a diverse suite of point and rectangular datasets, that are uniform or skewed, and a wide range of <b>query</b> <b>window</b> parameters. The estimation takes a constant amount of time, which is typically lower than 1 % of the time that it would take to execute the query, regardless of dataset or <b>query</b> <b>window</b> parameters. 1...|$|E
40|$|The {{local event}} {{detection}} {{is to use}} posting messages with geotags on social networks to reveal the related ongoing events and their locations. Recent {{studies have demonstrated that}} the geo-tagged tweet stream serves as an unprecedentedly valuable source for local event detection. Nevertheless, how to effectively extract local events from large geo-tagged tweet streams in real time remains challenging. A robust and efficient cloud-based real-time local event detection software system would benefit various aspects in the real-life society, from shopping recommendation for customer service providers to disaster alarming for emergency departments. We use the preliminary research GeoBurst as a starting point, which proposed a novel method to detect local events. GeoBurst+ leverages a novel cross-modal authority measure to identify several pivots in the <b>query</b> <b>window.</b> Such pivots reveal different geo-topical activities and naturally attract related tweets to form candidate events. It further summarises the continuous stream and compares the candidates against the historical summaries to pinpoint truly interesting local events. We mainly implement a website demonstration system Event-Radar with an improved algorithm to show the real-time local events online for public interests. Better still, as the <b>query</b> <b>window</b> shifts, our method can update the event list with little time cost, thus achieving continuous monitoring of the stream. Comment: 10 page...|$|E
40|$|This work {{discusses}} a novel hybrid replacement {{policy to}} adopt {{in the design}} of our cache. According to our hybrid caching strategy, the results of the most frequently accessed queries are maintained in a static cache of fixed size, which is completely rebuilt at fixed time intervals. Only the queries that cannot be satisfied by the static cache compete for the use of a dynamic cache. Our hybrid cache represents an effective and fast way to address both recency, and frequency of occurrences criteria. While the static cache maintains results of queries that are globally frequent, a simple and fast policy like LRU, which only takes into account query reference recency,could be adopted for the dynamic cache. This novel representation and the associated creation algorithm result in more effective EVRs of <b>window</b> <b>queries.</b> In addition, due to the distinct characteristics, a separate index structures, namely EVR-tree and grid index, for NN <b>queries</b> and <b>window</b> <b>queries,</b> respectively are used. To further increase efficiency, an algorithms to exploit the results of NN queries to aid grid index growth, benefiting EWV creation of <b>window</b> <b>queries</b> is developed. Similarly, the grid index is utilized to support NN query answering and EVR updating. Several experiments for performance evaluation are performed. The experimental results show that th...|$|R
40|$|In multi-dimensional {{databases}} {{the essential}} tool for accessing data is the range <b>query</b> (or <b>window</b> <b>query).</b> In this paper we {{introduce a new}} algorithm of processing range query in universal B-tree (UB-tree), which is an index structure for searching in multi-dimensional databases. The new range query algorithm (called the DRU algorithm) works efficiently, even for processing high-dimensional databases. In particular, using the DRU algorithm many of the UB-tree inner nodes need not to be accessed. We explain the DRU algorithm using a simple geometric model, providing a clear insight into the problem. More specifically, the model exploits an interesting relation between the Z-curve and generalized quad-trees. We also present experimental results for the DRU algorithm implementation...|$|R
40|$|Emerging {{data stream}} {{processing}} systems rely on windowing to enable on-the-fly processing of continuous queries over unbounded streams. As a result, several recent e#orts have developed window-aware implementations of query operators such as joins and aggregates. This focus on individual operators, however, ignores {{the larger issue}} of how to coordinate the pipelined execution of such operators when combined into a full <b>windowed</b> <b>query</b> plan. In this paper, we first show how the straightforward application of traditional pipelined query processing techniques to sliding <b>window</b> <b>queries</b> can result in ine#cient and incorrect behavior. We then present three alternative execution techniques that guarantee correct behavior for pipelined sliding <b>window</b> <b>queries</b> and develop new algorithms for correctly evaluating window-based duplicateelimination, Group-By and Set operators in this context. We implemented all of these techniques in a prototype data stream system and report {{the results of a}} detailed performance study of the system...|$|R
