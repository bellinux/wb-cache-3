8|223|Public
3000|$|... = 2.8 K, {{but there}} are {{noticeable}} variations among the samples. The normal residual resistance Rn,res also shows significant variations, ranging from 108 to 394 Ω. These two <b>quantities,</b> <b>T</b> [...]...|$|E
3000|$|... [...]. The <b>quantities</b> <b>T</b> 1, 2 {{represent}} the lifetimes that {{associate with the}} damping in the system. Moreover, the hydrostatic pressure effects are introduced via the pressure dependence of the effective masses and the dielectric constant. In the calculations, we have used [...]...|$|E
40|$|We {{present a}} manually-adaptive {{extension}} of Quasi Monte Carlo (QMC) integration for approximating marginal densities, moments, and quantiles when the joint density is known up to a normalization constant. Randomization and a batch-wise approach involving (0; s) -sequences are {{the cornerstones of}} the technique. By incorporating a variety of graphical diagnostics the method allows the user to adaptively allocate points for joint density function evaluations. Through intelligent allocation of resources to {{different regions of the}} marginal space, the method can quickly produce reliable marginal density approximations in moderate dimensions. We demonstrate by examples that adaptive QMC can be a viable alternative to the Metropolis algorithm. 1 Introduction A common computational problem in statistics is the calculation of marginal densities as well as percentiles and moments of a particular marginal distribution. In many situations the joint density is too complicated for these <b>quantities</b> <b>t</b> [...] ...|$|E
500|$|... i.e., up to a {{constant}} multiple, the quantity G (which measures curvature) is equated with the <b>quantity</b> <b>T</b> (which measures matter content). Here, G is the gravitational constant of Newtonian gravity, and c is {{the speed of}} light from special relativity.|$|R
5000|$|... where N(t) is the <b>quantity</b> at time <b>t,</b> and N0 = N(0) is {{the initial}} quantity, i.e. the <b>quantity</b> at time <b>t</b> = 0.|$|R
2500|$|This <b>quantity</b> <b>t</b> has the Student's {{t-distribution}} with [...] {{degrees of}} freedom, {{and it is}} an ancillary statistic (independent {{of the value of the}} parameters). Inverting the distribution of this t-statistics will allow us to construct the confidence interval for μ; similarly, inverting the χ2 distribution of the statistic s2 will give us the confidence interval for σ2: ...|$|R
40|$|We {{apply the}} parton {{recombination}} approach {{to study the}} energy dependence of the elliptic flow, v_ 2 in heavy ion collisions from AGS to LHC energies. The relevant input <b>quantities</b> (<b>T,</b> μ_B, η_T) at the various center of mass energies are obtained from fits to the available data. The model yields a good description of the integrated v_ 2 data for charged particles at midrapidity from AGS to RHIC energies. In {{stark contrast to the}} current expectations, we observe a decrease of the integrated v_ 2 values above the highest RHIC energy. Thus, we predict a decrease of v_ 2 at LHC energies compared to the RHIC results. This drop is attributed to negative v_ 2 values for the underlying parton distributions at low to moderate transverse momenta that develops if the transverse flow velocity is high enough. At energies above the LHC regime, the present approach predicts even negative values for the integrated v_ 2. Comment: 6 pages, 7 figure...|$|E
40|$|Context. In {{analyses}} of stellar spectra and colours, {{and for the}} analysis of integrated light from galaxies, a homogeneous grid of model atmospheres of late-type stars and corresponding flux spectra is needed. Aims. To construct an extensive grid of spherically symmetric models (supplemented with plane-parallel ones for the highest surface gravities), built on up-to-date atomic and molecular data, and make it available for public use. Methods. The most recent version of the MARCS program is used. Results. We present a grid of about 10 4 model atmospheres for stars with 2500 K ≤ Teff ≤ 8000 K,− 1 ≤ logg = log(GM/R 2) ≤ 5 (cgs) with various masses and radii,− 5 ≤[Me/H]≤+ 1, with [α/Fe]= 0. 0 and 0. 4 and different choices of C and N abundances, including ”CN-cycled ” models with C/N= 4. 07 (solar), 1. 5 and 0. 5, C/O ranging from 0. 09 to (normally) 5. 0 to also represent stars of spectral types R, S and N, and with 1. 0 ≤ξt ≤ 5 km/s. We also list thermodynamic <b>quantities</b> (<b>T,</b> Pg, Pe,ρ, partial pressures of molecules, etc) and provide them on the World Wide Web, as well as calculated fluxes in approximately 108, 000 wavelength points. Underlying assumptions in addition to 1 D stratification (spherical or plane-parallel) include hydrostatic equilibrium, mixing-length convection and LTE. A number of general properties of the models are discussed, in particular in relation to the effects of changing abundances, of blanketing and of sphericity. We have found and illustrate positive and negative feed-backs between sphericity and molecular blanketing. Models are compared with other available grids and excellent agreement is found with plane-parallel models of Castell...|$|E
40|$|The {{increased}} {{signal-to-noise ratio}} available at high magnetic ﬁeld makes possible {{the acquisition of}} clinically useful MR images either at higher resolution or for quantitative methods. The work in this thesis {{is focused on the}} development of quantitative imaging methods used to overcome difﬁculties due to high ﬁeld MRI systems (> 3 T). The protocols developed and presented here have been tested on various studies aiming at discriminating tissues based on their NMR properties. The quantities of interest in this thesis are the longitudinal relaxation time T 1, as well as the magnetization transfer process, particularly the chemical exchange phenomenon involving amide protons which is highlighted particularly well at 7 T under speciﬁc conditions. Both <b>quantities</b> (<b>T</b> 1 and amide proton transfer) are related to the underlying structure of the tissues in-vivo, especially inside the white matter of the brain. While a standard weighted image at high resolution can provide indices of the extent of the pathology, a robust measure of the NMR properties of brain tissues can detect earlier abnormalities. A method based on a 3 D Turbo FLASH readout and measuring reliably the T 1 in-vivo for clinical studies at 7 T is ﬁrst presented. The other major part of this thesis presents magnetization transfer and chemical exchange phenomena. First a quantitative method is investigated at 7 T, leading to a new model for exchange as well as contrast optimization possibility for imaging. Results using those methods are presented and applied in clinical setting, the main focus being to image reliably the brain of both healthy subjects and Multiple Sclerosis patients to look at myelin structures. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|A {{method for}} calculating the {{properly}} calibrated weights for VLA data in AIPS (or AIPS++, {{or any other}} package) is presented, along with some related information on the sensitivity" quantity stored in the VLA archive data. A method of determining the <b>quantity</b> <b>T</b> sys = a for each antenna using the properly calibrated weights is also presented...|$|R
6000|$|Thus, if {{we choose}} as time-variable the {{imaginary}} variable sq. rt. -I [...] . ct {{instead of the}} real <b>quantity</b> <b>t,</b> we can regard the space-time contintium -- accordance with the special theory of relativity -- as a [...] ", Euclidean [...] " [...] four-dimensional continuum, a result which follows from the considerations of the preceding section.|$|R
5000|$|This <b>quantity</b> <b>t</b> has the Student's {{t-distribution}} with (n − 1) {{degrees of}} freedom, {{and it is}} an ancillary statistic (independent {{of the value of the}} parameters). Inverting the distribution of this t-statistics will allow us to construct the confidence interval for μ; similarly, inverting the χ2 distribution of the statistic s2 will give us the confidence interval for σ2: ...|$|R
40|$|We give a {{rigorous}} derivation of Fourier’s law from {{a system of}} closure equations for a nonequilibrium stationary state of a Hamiltonian system of coupled oscillators subjected to heat baths on the boundary. The local heat flux {{is proportional to the}} temperature gradient with a temperature dependent heat conductivity and the stationary temperature exhibits a nonlinear profile. One of the simplest and most fundamental nonequilibrium phenomena is heat conduction in solids. It is described by a macroscopic equation, Fourier’s law, which states that a local temperature gradient is associated with a flux of heat J which is proportional to the gradient: J (x) = −k(T(x)) ∇T(x) (1) where the heat conductivity k(T(x)) is a function only of the temperature at x. Despite its fundamental nature, a derivation of Fourier’s law from first principles, or even within a suitable approximation, such as a Boltzmann type equation, lies well beyond what can be mathematically proven (for reviews on the status of this problem, see [3], [6] and [13]). The <b>quantities</b> <b>T</b> and J in (1) are macroscopic variables, statistical averages of the variables describing the microscopic dynamics of matter. A first principle derivation of (1) entails a definition of T and J in terms of the microscopic variables and a proof of the law in some appropriate limit. In this letter we outline {{a rigorous}} proof [4] of Fourier’s law starting from a closure approximation of the equations for the nonequilibrium stationary state of a Hamiltonian system subjected to boundary heat baths. The physical situation we have in mind is a slab of crystal of linear extension N heated at the two ends by temperatures T 1 and T 2. In this case one would expect ∇T and J to be O(1 /N) and (1) to hold up to corrections of order o(1 /N). This is indeed what we prove in our model together with {{a detailed description of the}} temperature distribution in the bulk. Since (1) is a macroscopic law it is expected to hold for a classical system as well as for a quantum one and the quantum corrections are expected to be small except at low temperatures. A classical toy model describing the above situation which has been intensively discussed i...|$|E
40|$|International audienceContext: In {{analyses}} of stellar spectra and colours, {{and for the}} analysis of integrated light from galaxies, a homogeneous grid of model atmospheres of late-type stars and corresponding flux spectra is needed. Aims: We construct an extensive grid of spherically-symmetric models (supplemented with plane-parallel ones for the highest surface gravities), built on up-to-date atomic and molecular data, and make it available for public use. Methods: The most recent version of the MARCS program is used. Results: We present a grid of about 104 model atmospheres for stars with 2500 K ? T_eff ? 8000 K, - 1 ? log g = log (GM/R^ 2) ? 5 (cgs) with various masses and radii, - 5 ? [Me/H] ? + 1, with [?/Fe] = 0. 0 and 0. 4 and different choices of C and N abundances. This includes ?CN-cycled? models with C/N = 4. 07 (solar), 1. 5 and 0. 5, C/O ranging from 0. 09 to (normally) 5. 0 to also represent stars of spectral types R, S and N, and with 1. 0 ? ?t ? 5 km s- 1. We also list thermodynamic <b>quantities</b> (<b>T,</b> P_g, P_e, ?, partial pressures of molecules, etc.) and provide them on the World Wide Web, as well as calculated fluxes in approximately 108 000 wavelength points. Underlying assumptions in addition to 1 D stratification (spherical or plane-parallel) include hydrostatic equilibrium, mixing-length convection and local thermodynamic equilibrium. We discuss a number of general properties of the models, in particular in relation to the effects of changing abundances, of blanketing, and of sphericity. We illustrate positive and negative feedbacks between sphericity and molecular blanketing. We compare the models with those of other available grids and find excellent agreement with plane-parallel models of Castelli & Kurucz (if convection is treated consistently) within the overlapping parameter range. Although there are considerable departures from the spherically-symmetric NextGen models, the agreement with more recent PHOENIX models is gratifying. Conclusions: The models of the grid show considerable regularities, but some interesting departures from general patterns occur for the coolest models due to the molecular opacities. We have tested a number of approximate ?rules of thumb? concerning effects of blanketing and sphericity and often found them to be astonishingly accurate. Some interesting new phenomena have been discovered and explored, such as the intricate coupling between blanketing and sphericity, and the strong effects of carbon enhancement on metal-poor models. We give further details of line absorption data for molecules, as well as details of models and comparisons with observations in subsequent papers...|$|E
40|$|Suppose a <b>quantity</b> <b>t</b> {{of a given}} {{resource}} is divided among two agents. If an additional quantity becomes available, how shall we share it among the agents ? By looking at the way we can share this increment (or decrement), {{it is possible to}} derive some existing rationing methods but also some new ones. Three new methods seem particularly interesting. They can also be derived following an Equivalent Sacrifice approach. ...|$|R
40|$|The paper {{considers}} {{the hypothesis that}} elliptical galaxies are oblate axisymmetric objects flattened by rotation. It was found that (1) rotation does not flatten axisymmetric elliptical galaxies appreciably and elliptical galaxy models can rotate rapidly and yet show little flattening, (2) several systems remained axisymmetric when the <b>quantity</b> <b>t</b> used {{as a measure of}} rotation was greater than 0. 14, and (3) models with similar shapes can have quite different internal dynamics...|$|R
40|$|Evaluations of the n-th power moments Sn of Kloosterman sums {{are known}} only for n 6 6. We present here {{substantial}} evidence for an eval-uation of S 7 {{in terms of}} Hecke eigenvalues for a weight 3 newform on Γ 0 (525) with quartic nebentypus of conductor 105. We also prove some congruences modulo 3, 5 and 7 for the closely related <b>quantity</b> <b>T</b> 7, where Tn is a sum of traces of n-th symmetric powers of the Kloosterman sheaf. 1...|$|R
2500|$|The {{number at}} the {{beginning}} of each row in the table above is ν, which has been defined above as nnbsp&−nbsp&1. [...] The percentage along the top is 100%(1nbsp&−nbsp&α). [...] The numbers in the main body of the table are tα, ν. [...] If a <b>quantity</b> <b>T</b> is distributed as a Student's t-distribution with ν degrees of freedom, then there is a probability 1nbsp&−nbsp&α that T will be less than tα, ν. (Calculated as for a one-tailed or one-sided test, as opposed to a two-tailed test.) ...|$|R
3000|$|Time of each {{small batch}} for {{shipment}} from manufacturer to retailer, {{which in turn}} depends on the completion of inventory of retailer (variable <b>quantity),</b> where <b>T</b> [...]...|$|R
2500|$|Hence, {{to convert}} the {{numerical}} quantity value of a temperature T in degrees Fahrenheit to a numerical <b>quantity</b> value <b>T</b> in degrees Celsius, this formula may be used: ...|$|R
30|$|In this equation, the {{distances}} a_i + 1 (t) and b_i + 1 (t) are {{the functions of}} the sought <b>quantity</b> S_k (<b>t)</b> according to Eqs. (5) and (6).|$|R
40|$|Abstract. In {{order to}} {{utilization}} the molybdenum tailings which be deposited in large <b>quantities.</b> <b>Test</b> {{used it to}} prepare glass-ceramics as main raw material, TiO 2 as nucleation agents and CaO-Al 2 O 3 -SiO 2 system and wollastonite as the principal crystalline phase. Heat treatment system of glass-ceramics {{was based on the}} differential thermal analysis. The crystalline phase, microstructure and characteristics of glass-ceramics were analysis by XRD, SEM and physical, chemical properties test. The result shows that the performance of glass-ceramics was superior to the other types of building decoration stone...|$|R
5000|$|The {{number at}} the {{beginning}} of each row in the table above is ν, which has been defined above as n − 1. The percentage along the top is 100%(1 − α). The numbers in the main body of the table are tα, ν. If a <b>quantity</b> <b>T</b> is distributed as a Student's t-distribution with ν degrees of freedom, then there is a probability 1 − α that T will be less than tα, ν. (Calculated as for a one-tailed or one-sided test, as opposed to a two-tailed test.) ...|$|R
50|$|Recalling that angles are in radian measure, {{and that}} the value {{being used in the}} example is 30 degrees, this is about 0.524 radians; halved and squared as the {{coefficient}} of the fractional change in θ says, this coefficient is about 0.07. From Eq(12) it can then be readily concluded that the most-to-least influential parameters are T, L, θ. Another way of saying this is that the derived quantity g is more sensitive to, e.g., the measured <b>quantity</b> <b>T</b> than to L or θ. Substituting the example's numerical values, the results are indicated in Table 1, and agree reasonably well with those found using Eq(4).|$|R
50|$|Integrating, we havewhere C is the {{constant}} of integration, and hencewhere the final substitution, N0 = eC, is obtained by evaluating the equation at t = 0, as N0 {{is defined as}} being the <b>quantity</b> at <b>t</b> = 0.|$|R
30|$|For Θ < 0, such {{a result}} with a {{constant}} {{independent of the}} mesh parameter h cannot be obtained. As a consequence, for Θ < 0, the <b>quantity</b> E^h_Θ (<b>t)</b> cannot be used for optimal energy evolution estimates and might become even negative for h small.|$|R
30|$|In {{order to}} cover {{pressure}} dependence and nonlinearity of elastic strains, a generalization of the T-criterion was recently introduced (Andrianopoulos and Boulougouris 2004; Andrianopoulos et al. 2007, 2008; Andrianopoulos and Manolopoulos 2012). The general {{case of an}} isotropic material showing nonlinear elastic behavior was considered, and the total elastic strain energy density T was anticipated as the characteristic quantity for the respective conservative field. This <b>quantity</b> <b>T</b> is path independent and so, a relationship between dilatational TV and distortional part TD of T is obtained (Andrianopoulos and Manolopoulos 2010). This approach proved to be quite successful in predicting the failure behavior of metals under high levels of pressure (Andrianopoulos and Manolopoulos 2012) where {{for the first time}} - according to our best knowledge - the classical experiments of Bridgman (1952) were theoretically justified.|$|R
40|$|AbstractWith a rapid {{increase}} in size and complexity of software today, the scope of software testing is also expanding. The efficiency of software testing needs to be improved {{in order to ensure}} the appropriate delivery deadline and cost of software development. For improving efficiency of software testing, the test needs to be designed {{in a way that the}} number of test cases is sufficient and appropriate in <b>quantity.</b> <b>Test</b> analysis is the activity to refine Application Under Test (AUT) into proper size that test design techniques can be applied to. It is for designing the test properly. However, the classification for proper size depends on individual's own judgments. This paper proposes a test analysis method for the black box testing using a test category that is the classification based on fault and AUT knowledge...|$|R
40|$|This article {{investigates the}} {{interpretation}} of the right-hand side of the relativistic second law of thermodynamics (φ 0 dx^μ/ds) μ(-g) ^(1 / 2) dx^ 1 dx^ 2 dx^ 3 dx^ 4 ≧dQ 0 /T 0 and shows that the quantity dQ 0 can be interpreted as the heat—measured by a local observer at rest in the fluid at the point of interest—which flows relative to the fluid into an element of the fluid having the instantaneous proper volume dV 0 during the proper time dt 0, where these quantities are chosen so as to satisfy the numerical equality dV 0 dt 0 =(-g) ^(1 / 2) dx^ 1 dx^ 2 dx^ 3 dx^ 4 and the <b>quantity</b> <b>T</b> 0 is taken as the temperature ascribed to this heat by the local observer...|$|R
40|$|A set X_N={x_ 1, [...] .,x_N} of N {{points on}} the unit sphere S^d, d≥ 2 is a spherical t-design if the average of any {{polynomial}} of degree at most t over the sphere {{is equal to the}} average value of the polynomial over X_N. This paper extends characterizations of spherical t-designs in previous paper from S^ 2 to general S^d. We show that for N≥(P_t+ 1), X_N is a stationary point set of a certain non-negative <b>quantity</b> A_N, <b>t</b> and a fundamental system for polynomial space over S^d with degree at most t, then X_N is a spherical t-design. In contrast, we present that with N ≥(P_t), a fundamental system X_N is a spherical t-design if and only if non-negative <b>quantity</b> D_N, <b>t</b> vanishes. In addition, the still unanswered questions about construction of spherical t-designs are discussed...|$|R
40|$|For {{an integer}} [various {{formulas}} omitted]. The <b>quantity</b> <b>t(d)</b> {{was introduced by}} Dash, Fukasawa, and Günlük, who showed that [various formulas omitted]. Using the Steinitz lemma, in a quantitative version due to Grinberg and Sevastyanov, we prove an upper bound of [various formulas omitted]. These results contribute to understanding the master equality polyhedron with multiple rows defined by Dash et al. which is a 2 ̆ 2 universal 2 ̆ 2 polyhedron encoding valid cutting planes for integer programs (this line of research was started by Gomory in the late 1960 s). In particular, the upper bound on t(d) implies a pseudo-polynomial running time for an algorithm of Dash et al. for integer programming with a fixed number of constraints. The algorithm consists in solving a linear program, and it provides an alternative to a 1981 dynamic programming algorithm of Papadimitriou...|$|R
40|$|In {{the case}} of a gravitating mass of perfect fluid which has come to {{thermodynamic}} equilibrium, it has previously been shown that the proper temperature T 0 as measured by a local observer would depend in a definite manner on the gravitational potential {{at the point where the}} measurement is made. In the present article the conditions of thermal equilibrium are investigated in {{the case of}} a general static gravitational field which could correspond to a system containing solid as well as fluid parts. Writing the line element for the general static field in the form ds 2 =gijdxidxj+g 44 dt 2 i,j= 1, 2, 3, where the gij and g 44 are independent of the time t it is shown that the dependence of proper temperature on position at thermal equilibrium is such as to make the <b>quantity</b> <b>T</b> 0 sqrt[g 44] a constant throughout the system...|$|R
40|$|International audienceWe {{investigate}} numerically {{the inverse}} participation ratios in a spin- 1 / 2 XXZ chain, computed in the “Ising” basis (i. e., eigenstates of σ^z_i). We consider in particular a <b>quantity</b> <b>T,</b> defined by summing the inverse participation ratios {{of all the}} eigenstates in the zero-magnetization sector of a finite chain of length N, with open boundary conditions. From a dynamical point of view, T {{is proportional to the}} stationary return probability to an initial basis state, averaged over all the basis states (initial conditions). We find that T exhibits an exponential growth, T∼exp(aN), in the gapped phase of the model and a linear scaling, T∼N, in the gapless phase. These two different behaviors are analyzed in terms of the distribution of the participation ratios of individual eigenstates. We also investigate the effect of next-nearest-neighbor interactions, which break the integrability of the model. Although the massive phase of the nonintegrable model also has T∼exp(aN), in the gapless phase T appears to saturate to a constant value...|$|R
40|$|I {{develop a}} stage-structured model that {{incorporates}} the key biological {{features of the}} host-parasitoid system: unidirectional IGP with the IGPrey being the superior resource competitor (i. e., the IGPrey has a higher attack rate than the IGPredator), superparasitism in the IGPredator, and a temporal refuge in the IGPrey. The host has three stages: eggs (E), nymphs (N) and adults (A). The parasitoids each have larval (Li) and adult (Pi) (i = 1, 2) stages. Both parasitoids attack host eggs. Parasitoid 2 (IGPredator) engages in both superparasitism and IGP. Since all three species have overlapping generations a continuous-time model is appropriate. The <b>quantity</b> <b>T</b> is the time period of seasonal variation (one year), TR is the time period during only the IGPrey is present (the refuge), and T − TR is the time period when both IGPrey and IGPredator co-occur. The dynamics are given by: P. Amarasekare Intraguild Predation and Temporal Variation 2 Refuge period (resource and IGPrey) (0 ≤ t ≤ TR) dE d...|$|R
40|$|This paper {{considers}} {{the topic of}} efficiently triangulating a simple polygon with emphasis on practical and easy-to-implement algorithms. It also describes a new adaptive algorithm for triangulating a simple n-sided polygon. The algorithm runs in time O(n(1 +t 0)), with t 0 < n. The <b>quantity</b> <b>t</b> 0 measures the shape-complexity of the triangulation delivered by the algorithm. More precisely t 0 {{is the number of}} triangles contained in the triangulation obtained that share zero edges with the input polygon and is, furthermore, related to the shape-complexity of the input polygon. Although the worst-case complexity of the algorithm is O(n 2), for several classes of polygons it runs in linear time. The practical advantages of the algorithm are that it is simple and does not require sorting or the use of balanced tree structures. On the theoretical side it is of interest because it is the first polygon triangulation algorithm the computational complexity of which is a function of t [...] ...|$|R
40|$|Summary. We {{propose a}} novel method for {{analyzing}} precursory seismic data be-fore an earthquake that treats {{them as a}} Markov process and distinguishes the background noise from real °uctuations due to an earthquake. A short time (on the order of several hours) before an earthquake the Markov time scale tM increases sharply, hence providing an alarm for an impending earthquake. To distinguish a false alarm from a reliable one, we compute a second <b>quantity,</b> <b>T</b> 1, based {{on the concept of}} extended self-similarity of the data. T 1 also changes strongly before an earthquake occurs. An alarm is accepted if both tM and T 1 indicate it simultaneously. 2 M. Reza Rahimi Tabar, et al Calibrating the method with the data for one region provides a tool for predicting an impending earthquake within that region. Our analysis of the data for a large number of earthquakes indicate an essentially zero rate of failure for the method. Short-Term Prediction 3...|$|R
