3315|10000|Public
5|$|Watson {{was created}} as a <b>question</b> <b>answering</b> (QA) {{computing}} system that IBM built to apply advanced natural language processing, information retrieval, knowledge representation, automated reasoning, and machine learning technologies {{to the field of}} open domain <b>question</b> <b>answering.</b>|$|E
5|$|Watson is a <b>question</b> <b>answering</b> {{computer}} system capable of answering questions posed in natural language, developed in IBM's DeepQA project by a research {{team led by}} principal investigator David Ferrucci. IBM Watson's former business chief, Manoj Saxena, says that 90% of nurses in the field who use Watson now follow its guidance.|$|E
5|$|In 2005, a Stanford robot won the DARPA Grand Challenge {{by driving}} {{autonomously}} for 131 miles along an unrehearsed desert trail. Two years later, {{a team from}} CMU won the DARPA Urban Challenge by autonomously navigating 55 miles in an Urban environment while adhering to traffic hazards and all traffic laws. In February 2011, in a Jeopardy! quiz show exhibition match, IBM's <b>question</b> <b>answering</b> system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.|$|E
40|$|This paper {{introduces}} {{a system for}} searching <b>question</b> <b>answer</b> pairs automatically extracted from the discussions in internet communities. The system, named Fora, aggregates discussions from multiple forums and newsgroups in the same domain, automatically extracts <b>question</b> <b>answer</b> pairs from the data, and provides searches of the <b>question</b> <b>answer</b> pairs. The system also offers expert search, query suggestion, page search, and other features. This paper explains the main features and technologies of Fora. It describes how the system extracts and ranks <b>question</b> <b>answer</b> pairs...|$|R
40|$|Record of the {{investigation}} initiated {{by the death of}} 84 Chinese settlers on their way to Cuba in the French ship “Guantanamo” in 1868. is: list of dead Chinese settlers killed by the location (latitude and longitude), date; research (appointment of scribe, translator; <b>questions</b> and <b>answers</b> from the captain; <b>questions</b> and <b>answers</b> from the pilot; <b>questions</b> and <b>answers</b> of several sailors; <b>questions</b> and <b>answers</b> of the translator; <b>questions</b> and <b>answers</b> from the Chinese translator; <b>questions</b> and <b>answers</b> from the ship’s doctor; <b>questions</b> and <b>answers</b> of some Chinese settlers...|$|R
50|$|Letterz: Viewer <b>questions</b> <b>answered.</b>|$|R
5|$|In recent years, the Watson {{capabilities}} {{have been}} extended {{and the way}} in which Watson works has been changed to take advantage of new deployment models (Watson on IBM Cloud) and evolved machine learning capabilities and optimised hardware available to developers and researchers. It is no longer purely a <b>question</b> <b>answering</b> (QA) computing system designed from Q pairs but can now 'see', 'hear', 'read', 'talk', 'taste', 'understand', 'reason', 'interpret', 'learn' and 'recommend'.|$|E
25|$|Natural {{language}} processing gives machines {{the ability to}} read and understand human language. A sufficiently powerful natural {{language processing}} system would enable natural language user interfaces and the acquisition of knowledge directly from human-written sources, such as newswire texts. Some straightforward applications of natural language processing include information retrieval, text mining, <b>question</b> <b>answering</b> and machine translation.|$|E
25|$|Memory {{networks}} are another extension to neural networks incorporating long-term memory. Long-term memory {{can be read}} and written to, {{with the goal of}} using it for prediction. These models have been applied in the context of <b>question</b> <b>answering</b> (QA) where the long-term memory effectively acts as a knowledge base, and the output is a textual response.|$|E
50|$|This is {{when the}} patient’s {{attention}} can be held and he/she can <b>answer</b> <b>questions.</b> When <b>answering</b> <b>questions,</b> the <b>answers</b> may be delayed and/or indicate a level of disorientation or confusion.|$|R
50|$|<b>Questions</b> <b>Answered</b> about Rifle Shooting, 1945.|$|R
5000|$|<b>Question</b> and <b>answer</b> sites (Q&A), {{where there}} is {{typically}} a common forum on which users can post <b>questions,</b> <b>answer</b> <b>questions,</b> comment on <b>answers,</b> and up/down-vote posts. The SLN on Q&A sites is formed entirely through social interaction on these forums.|$|R
2500|$|The {{second major}} area in {{semantic}} analysis is {{the understanding of}} how different sentence and textual elements fit together. Tasks in this area include semantic role labeling, semantic relation analysis, and coreference resolution. Other tasks in this area look at more specialized issues of semantic analysis, such as temporal information processing, metonymy resolution, and sentiment analysis. The tasks in this area have many potential applications, such as information extraction, <b>question</b> <b>answering,</b> document summarization, machine translation, construction of thesauri and semantic networks, language modeling, paraphrasing, ...|$|E
2500|$|Advanced {{statistical}} techniques (loosely {{known as}} deep learning), access to {{large amounts of}} data and faster computers enabled advances in machine learning and perception. By the mid 2010s, machine learning applications were used throughout the world. In a Jeopardy! quiz show exhibition match, IBM's <b>question</b> <b>answering</b> system, Watson, defeated the two greatest Jeopardy champions, Brad Rutter and Ken Jennings, by a significant margin. The Kinect, which provides a 3D body–motion interface for the Xbox 360 and the Xbox One use algorithms that emerged from lengthy AI research as do intelligent personal assistants in smartphones. In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. In the 2017 Future of Go Summit, [...] AlphaGo [...] won a three-game match with Ke Jie, {{who at the time}} continuously held the world No. 1 ranking for two years. This marked the completion of a significant milestone in the development of Artificial Intelligence as Go is an extremely complex game, more so than Chess.|$|E
6000|$|The {{girl was}} tempted to inquire whether her {{grandmother}} called herself [...] "everything"; but she checked this <b>question,</b> <b>answering</b> instead that {{she knew she was}} giving up much.|$|E
5000|$|Lehrer, Steven, New Covenant Theology: <b>Questions</b> <b>Answered</b> (2006) ...|$|R
5000|$|The Bacon/Shakespeare <b>Question</b> <b>Answered</b> (London: T.G. Johnson, 1889).|$|R
5000|$|Theosophical <b>Questions</b> <b>Answered.</b> Chicago: Theo Book Co., 1924.|$|R
50|$|TeLQAS (Telecommunication Literature <b>Question</b> <b>Answering</b> System) is an {{experimental}} <b>question</b> <b>answering</b> system developed for answering English {{questions in the}} telecommunications domain.|$|E
50|$|<b>Question</b> <b>answering</b> heavily {{relies on}} reasoning. There {{are a number}} of <b>question</b> <b>answering</b> systems {{designed}} in Prolog, a logic programming language associated with artificial intelligence.|$|E
50|$|Watson is a <b>question</b> <b>answering</b> (QA) {{computing}} system that IBM built to apply advanced natural language processing, information retrieval, knowledge representation, automated reasoning, and machine learning technologies {{to the field}} of open domain <b>question</b> <b>answering.</b>|$|E
5000|$|Disney Trivia {{from the}} Vault: Secrets Revealed and <b>Questions</b> <b>Answered</b> (...) ...|$|R
50|$|Five {{points are}} awarded for each correct answer, no points are deducted for wrong or {{unanswered}} problems. In addition, starred <b>questions</b> <b>answered</b> correctly receive one bonus point for each star (e.g., a two-star <b>question</b> <b>answered</b> correctly is worth 7 points, 5 base {{points for the}} correct answer plus one point for each star).|$|R
5000|$|Infertility: All Your <b>Questions</b> <b>Answered,</b> By Gab Kovacs, Carl Wood, 1996, ...|$|R
5000|$|... #Subtitle level 2: Temporal <b>question</b> <b>answering</b> (T-QAnswering) ...|$|E
5000|$|Quantitative {{evaluation}} of passage retrieval algorithms for <b>question</b> <b>answering</b> ...|$|E
5000|$|Multilingual <b>Question</b> <b>Answering</b> Track at CLEF (from 2005 to 2013) ...|$|E
5000|$|... #Subtitle level 2: Types of <b>Questions</b> <b>Answered</b> from a Web Strategy ...|$|R
50|$|Hypophora, also {{referred}} to as anthypophora or antipophora, is a figure of speech in which the speaker poses a <b>question</b> and then <b>answers</b> the <b>question.</b> Hypophora can consist of a single <b>question</b> <b>answered</b> in a single sentence, a single <b>question</b> <b>answered</b> in a paragraph or even a section, or a series of <b>questions,</b> each <b>answered</b> in subsequent paragraphs. Hypophora is used (1) as a transitional device, to take the discussion in a new direction, (2) a device to stimulate interest, since a reader's curiosity is stimulated by hearing a question, and (3) to suggest and <b>answer</b> <b>questions</b> the reader might not have thought of.|$|R
5000|$|Fewest <b>questions</b> <b>answered</b> {{correctly}} - 1 by Bayani Agbayani (November 11, 2007) ...|$|R
5000|$|Eric Nyberg is a Professor in the Language Technologies Institute in the School of Computer Science at Carnegie Mellon University. He is Director for the Master's Program in Computational Data Science (formerly {{known as}} the M.S. Program in Very Large Information Systems). Nyberg has made {{significant}} research contributions to the fields of automatic text translation, information retrieval, and automatic <b>question</b> <b>answering.</b> He received his Ph.D. from Carnegie Mellon University (1992), and his BA from Boston University (1983). He has pioneered the Open Advancement of <b>Question</b> <b>Answering,</b> an architecture and methodology for accelerating collaborative research in automatic <b>question</b> <b>answering.</b>|$|E
5000|$|<b>Question</b> <b>answering</b> {{from the}} web using {{knowledge}} annotation and knowledge mining techniques ...|$|E
5000|$|Quiz show: <b>question</b> <b>answering</b> {{although}} the machine {{did not use}} speech recognition ...|$|E
50|$|The {{competition}} round {{consists of}} introduction round, <b>question</b> <b>answer</b> round and catwalk.|$|R
5000|$|Guillebaud J, MacGregor A. Contraception: your <b>questions</b> <b>answered</b> (6th Edition) Elsevier 2013 ...|$|R
5000|$|Most {{number of}} <b>questions</b> <b>answered</b> {{correctly}} in 60 second fast money: 16.|$|R
