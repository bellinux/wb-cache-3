1673|393|Public
25|$|The <b>Logical</b> <b>framework</b> approach, {{which is}} popular in {{international}} development organizations.|$|E
25|$|Bunt (1985), a {{study of}} the {{semantics}} of natural language, shows how mereology can help understand such phenomena as the mass–count distinction and verb aspect. But Nicolas (2008) argues that a different <b>logical</b> <b>framework,</b> called plural logic, should be used for that purpose.|$|E
25|$|In City of God, Augustine {{rejected}} {{both the}} immortality {{of the human}} race proposed by pagans, and contemporary ideas of ages (such as those of certain Greeks and Egyptians) that differed from the Church's sacred writings. In The Literal Interpretation of Genesis, Augustine took the view that everything in the universe was created simultaneously by God, and not in seven calendar days like a literal interpretation of Genesis would require. He argued that the six-day structure of creation presented in the Book of Genesis represents a <b>logical</b> <b>framework,</b> rather than the passage of time in a physical way – it would bear a spiritual, rather than physical, meaning, which is no less literal. One reason for this interpretation is the passage in Sirach 18:1, creavit omnia simul ("He created all things at once"), which Augustine took as proof that the days of Genesis 1 had to be taken non-literally.|$|E
40|$|We {{present and}} discuss various formalizations of Modal Logics in <b>Logical</b> <b>Frameworks</b> based on Type Theories. We {{consider}} both Hilbert- and Natural Deductionstyle proof systems for representing both truth (local) and validity (global) consequence relations for various Modal Logics. We introduce several techniques for encoding the structural peculiarities of necessitation rules, in the typed -calculus metalanguage of the <b>Logical</b> <b>Frameworks.</b> These formalizations yield readily proof-editors for Modal Logics when implemented in Proof Development Environments, such as Coq or LEGO. Keywords: Hilbert and Natural-Deduction proof systems for Modal Logics, <b>Logical</b> <b>Frameworks,</b> Typed -calculus, Proof Assistants. Introduction In this {{paper we address}} the issue of designing proof development environments (i. e. "proof editors" or, even better, "proof assistants") for Modal Logics, in the style of [11, 12]. To this end, we explore the possibility of using <b>Logical</b> <b>Frameworks</b> (LF's) based on Type Theory [...] ...|$|R
40|$|This volume {{constitutes}} {{the proceedings of}} the Sixth International Workshop on <b>Logical</b> <b>Frameworks</b> and Meta-languages: Theory and Practice, LFMTP 2011. <b>Logical</b> <b>frameworks</b> and meta-languages form a common substrate for representing, implementing, and reasoning about a wide variety of deductive systems of interest in logic and computer science. Their design and implementation {{on the one hand and}} their use in reasoning tasks ranging from the correctness of software to the properties of formal computational systems on the other hand have been the focus of considerable research over the last two decades. The LFMTP workshop series, which resulted from the amalgamation of the <b>Logical</b> <b>Frameworks</b> and Meta-languages (LFM) and the Mechanized Reasoning about Languages with Variable Binding (MER?IN) workshop series, is intended to bring together designers, implementors, and practitioners to discuss various aspects impinging on the structure and utility of <b>logical</b> <b>frameworks...</b>|$|R
40|$|<b>Logical</b> <b>frameworks</b> and meta-languages form {{a common}} {{substrate}} for representing, implementing, and reasoning about {{a wide variety}} of deductive systems of interest in logic and computer science. Their design and implementation {{has been the focus of}} considerable research over the last two decades, using competing and sometimes incompatible basic principles. This workshop brings together designers, implementors, and practitioners to discuss all aspects of <b>logical</b> <b>frameworks.</b> The papers in this workshop proceedings were selected but not formally refereed by the following program committee...|$|R
25|$|In the 5th century, Saint Augustine wrote The Literal Meaning of Genesis {{in which}} he argued that Genesis should be {{interpreted}} as God forming the Earth and life from pre-existing matter and allowed for an allegorical interpretation of {{the first chapter of}} Genesis. For example: he argues that the six-day structure of creation presented in the book of Genesis represents a <b>logical</b> <b>framework,</b> rather than the passage of time in a physical way. On the other hand, Augustine called for a historical view of the remainder of the history recorded in Genesis, including the creation of Adam and Eve, and the Flood. Apart from his specific views, Augustine recognizes that the interpretation of the creation story is difficult, and remarks that Christians should be willing to change their minds about it as new information comes up. He also warned believers not to rashly interpret things literally that might be allegorical, as it would discredit the faith.|$|E
25|$|However, Amaryll Beatrice Chanady distinguishes magical realist {{literature}} from fantasy literature ("the fantastic") based on differences between three shared dimensions: {{the use of}} antinomy (the simultaneous presence of two conflicting codes), the inclusion of events that cannot be integrated into a <b>logical</b> <b>framework,</b> {{and the use of}} authorial reticence. In fantasy, the presence of the supernatural code is perceived as problematic, something that draws special attentionwhere in magical realism, the presence of the supernatural is accepted. In fantasy, while authorial reticence creates a disturbing effect on the reader, it works to integrate the supernatural into the natural framework in magical realism. This integration is made possible in magical realism as the author presents the supernatural as being equally valid to the natural. There is no hierarchy between the two codes. The ghost of Melquíades in Márquez's One Hundred Years of Solitude or the baby ghost in Toni Morrison's Beloved who visit or haunt the inhabitants of their previous residence are both presented by the narrator as ordinary occurrences; the reader, therefore, accepts the marvelous as normal and common.|$|E
25|$|In the 3rd century BC, {{the premier}} center of {{mathematical}} {{education and research}} was the Musaeum of Alexandria. It was there that Euclid (c. 300 BC) taught, and wrote the Elements, widely considered the most successful and influential textbook of all time. The Elements introduced mathematical rigor through the axiomatic method and is the earliest example of the format still used in mathematics today, that of definition, axiom, theorem, and proof. Although most {{of the contents of}} the Elements were already known, Euclid arranged them into a single, coherent <b>logical</b> <b>framework.</b> The Elements was known to all educated people in the West until the middle of the 20th century and its contents are still taught in geometry classes today. In addition to the familiar theorems of Euclidean geometry, the Elements was meant as an introductory textbook to all mathematical subjects of the time, such as number theory, algebra and solid geometry, including proofs that the square root of two is irrational and that there are infinitely many prime numbers. Euclid also wrote extensively on other subjects, such as conic sections, optics, spherical geometry, and mechanics, but only half of his writings survive.|$|E
40|$|<b>Logical</b> <b>frameworks</b> {{such as the}} Edinburgh LF or Isabelle are not {{suitable}} for general metatheory, since they do not allow induction. On the other hand {{it is hard to}} encode a logic in an inductive definition-style framework so that it is usable for object theory. We propose a solution to this problem that borrows techniques from the type-theory tradition of <b>logical</b> <b>frameworks</b> for use with a language of inductive definitions, providing us with a notation suitable for practical object and metatheory both...|$|R
40|$|We {{present a}} method for {{defining}} <b>logical</b> <b>frameworks</b> {{as a collection of}} features which are defined and behave independently of one another. Each feature is a set of grammar clauses and rules of deduction such that the result of adding the feature to a framework is a conservative extension of the framework itself. We show how several existing <b>logical</b> <b>frameworks</b> can be so built, and how several much weaker frameworks defined in this manner are adequate for expressing a wide variety of object logics...|$|R
40|$|We {{present and}} discuss various formal]zations of Modal Logics in <b>Logical</b> <b>Frameworks</b> based on Type Theories. We {{consider}} both Hubert- and Natural Deductionstyle proof systems for representing both truth (local) and validity (global) consequence relations for various Modal Logics We introduce several techniques for encoding the structural peculiarities of necessitation rules, in the typed A-calculus metalanguage of the <b>Logical</b> <b>Frameworks.</b> These formalizations yield readily proof-editors for Modal Logics when implemented in Proof Development Environments, such as Coq or LEGO. © 1998 Kluwer Academic Publishers...|$|R
2500|$|Reddy {{concludes that}} the conduit metaphor may {{continue}} to have negative technological and social consequences: mass communications systems that largely ignore the internal, human systems responsible {{for the majority of}} the work in communicating. Because the <b>logical</b> <b>framework</b> of the conduit metaphor indicates people think in terms of [...] "capturing ideas in words"—despite there being no ideas [...] "within" [...] the ever-increasing stream of words—a burgeoning public may be less culturally informed than expected.|$|E
2500|$|The {{core of the}} Propædia is its [...] "Outline of Knowledge", {{which aims}} to provide a <b>logical</b> <b>framework</b> for all human knowledge. Accordingly, the Outline is {{consulted}} by the Britannicas editors to decide which articles {{should be included in}} the Micro- and Macropædia. The Outline is also intended to be a study guide, to put subjects in their proper perspective, and to suggest a series of Britannica articles for the student wishing to learn a topic in depth. However, libraries have found that it is scarcely used, and reviewers have recommended that it be dropped from the encyclopaedia. The Propædia also has color transparencies of human anatomy and several appendices listing the staff members, advisors, and contributors to all three parts of the Britannica.|$|E
2500|$|Structuration {{theory is}} {{relevant}} to research, but does not prescribe a methodology and its use in research has been problematic. Giddens intended his theory to be abstract and theoretical, informing the hermeneutic aspects of research rather than guiding practice. Giddens wrote that structuration theory [...] "establishes the internal logical coherence of concepts within a theoretical network." [...] Giddens criticized many researchers who used structuration theory for empirical research, critiquing their [...] "en bloc" [...] use of the theory's abstract concepts in a burdensome way. [...] "The works applying concepts from the <b>logical</b> <b>framework</b> of structuration theory that Giddens approved of were those that used them more selectively, 'in a spare and critical fashion.'" [...] Giddens and followers used structuration theory more as [...] "a sensitizing device".|$|E
40|$|Abstract. We {{present a}} method for {{defining}} <b>logical</b> <b>frameworks</b> {{as a collection of}} features which are defined and behave independently of one another. Each feature is a set of grammar clauses and rules of deduction such that the result of adding the feature to a framework is a conservative extension of the framework itself. We show how several existing <b>logical</b> <b>frameworks</b> can be so built, and how several much weaker frameworks defined in this manner are adequate for expressing a wide variety of object logics. ...|$|R
40|$|This volume {{constitutes}} {{the proceedings of}} LFMTP 2015, the Tenth International Workshop on <b>Logical</b> <b>Frameworks</b> and Meta-Languages: Theory and Practice, held on August 1 st, 2015 in Berlin, Germany. The workshop was a one-day satellite event of CADE- 25, the 25 th International Conference on Automated Deduction. <b>Logical</b> <b>frameworks</b> and meta-languages form a common substrate for representing, implementing, and reasoning about {{a wide variety of}} deductive systems of interest in logic and computer science. Their design and implementation and their use in reasoning tasks ranging from the correctness of software to the properties of formal computational systems have been the focus of considerable research over the last two decades. This workshop brought together designers, implementors, and practitioners to discuss various aspects impinging on the structure and utility of <b>logical</b> <b>frameworks,</b> including the treatment of variable binding, inductive and co-inductive reasoning techniques and the expressiveness and lucidity of the reasoning process...|$|R
40|$|Abstract. As {{theories}} and proofs in <b>logical</b> <b>frameworks</b> become larger, careful {{control over what}} information within them can safely be omitted or erased becomes useful for efficient implementation. The notion of proof irrelevance provides exactly this control, but requires existing algorithms used in <b>logical</b> <b>frameworks,</b> in particular higher-order pattern unification, to be extended to accommodate the richer type theory. We describe this extended algorithm, whose presentation is simplified by making use of recent developments in explaining unification metavariables as modal variables, which obviates the need for full explicit substitutions...|$|R
2500|$|Feyerabend {{considered}} the possibility of incommensurability, but he was hesitant in his application of the concept. He wrote that [...] "it is hardly ever possible to give an explicit definition of [...] " [...] , because it involves covert classifications and major conceptual changes. He also was critical of attempts to capture incommensurability in a <b>logical</b> <b>framework,</b> since he thought of incommensurability as a phenomenon outside the domain of logic. In the second appendix of Against Method (p.114), Feyerabend states, [...] "I never said... that any two rival theories are incommensurable... What I did say was that certain rival theories, so-called 'universal' theories, or 'non-instantial' theories, if interpreted in a certain way, could not be compared easily." [...] Incommensurability did not concern Feyerabend greatly, because he believed that even when theories are commensurable (i.e. can be compared), {{the outcome of the}} comparison should not necessarily rule out either theory. To rephrase: when theories are incommensurable, they cannot rule each other out, and when theories are commensurable, they cannot rule each other out. Assessments of (in)commensurability, therefore, don't have much effect in Feyerabend's system, and can be more or less passed over in silence.|$|E
60|$|When {{once the}} above general {{doctrine}} is rejected, {{it is obvious}} that, where there is change, {{there must be a}} succession of states. There cannot be change--and motion is only a particular case of change--unless there is something different at one time from what there is at some other time. Change, therefore, must involve relations and complexity, and must demand analysis. So long as our analysis has only gone as far as other smaller changes, it is not complete; {{if it is to be}} complete, it must end with terms that are not changes, but are related by a relation of earlier and later. In the case of changes which appear continuous, such as motions, it seems to be impossible to find anything other than change so long as we deal with finite periods of time, however short. We are thus driven back, by the logical necessities of the case, to the conception of instants without duration, or at any rate without any duration which even the most delicate instruments can reveal. This conception, though it can be made to seem difficult, is really easier than any other that the facts allow. It is a kind of <b>logical</b> <b>framework</b> into which any tenable theory must fit--not necessarily itself the statement of the crude facts, but a form in which statements which are true of the crude facts can be made by a suitable interpretation. The direct consideration of the crude facts of the physical world has been undertaken in earlier lectures; in the present lecture, we have only been concerned to show that nothing in the crude facts is inconsistent with the mathematical doctrine of continuity, or demands a continuity of a radically different kind from that of mathematical motion.|$|E
50|$|In logic, a <b>logical</b> <b>framework</b> {{provides}} a means to define (or present) a logic as a signature in a higher-order type theory {{in such a way}} that provability of a formula in the original logic reduces to a type inhabitation problem in the framework type theory. This approach has been used successfully for (interactive) automated theorem proving. The first <b>logical</b> <b>framework</b> was Automath; however, the name of the idea comes from the more widely known Edinburgh <b>Logical</b> <b>Framework,</b> LF. Several more recent proof tools like Isabelle are based on this idea. Unlike a direct embedding, the <b>logical</b> <b>framework</b> approach allows many logics to be embedded in the same type system.|$|E
50|$|Process {{management}} provides {{engineering and}} project managers with {{a means of}} systemically thinking of project organizations, Semantics concepts and <b>logical</b> <b>frameworks</b> that allow project activities to be planned, executed, analyzed and facilitate learning.|$|R
5000|$|Using one construct, [...] statements, {{to capture}} {{syntactic}} rules, axiom schemas, and rules of inference provides {{a level of}} flexibility similar to higher order <b>logical</b> <b>frameworks</b> without a dependency on a complex type system.|$|R
50|$|In {{the domain}} of <b>logical</b> <b>frameworks,</b> the term higher-order {{abstract}} syntax is usually {{used to refer to}} a specific representation that uses the binders of the meta-language to encode the binding structure of the object language.|$|R
5000|$|We now {{formulate}} {{the basic}} <b>logical</b> <b>framework</b> of nonstandard analysis: ...|$|E
5000|$|To {{describe}} a <b>logical</b> <b>framework,</b> one must provide the following: ...|$|E
5000|$|The <b>Logical</b> <b>framework</b> approach, {{which is}} popular in {{international}} development organizations.|$|E
40|$|Frameworks and Meta-Languages ” and the MERλIN {{workshop}} {{series on}} “MEchanized Reasoning about Languages with variable BInding”. <b>Logical</b> <b>frameworks</b> and meta-languages form a common substrate for representing, implementing, and reasoning about {{a wide variety}} of deductive systems of interest in logic and computer science. Their design and implementation {{has been the focus of}} considerable research over the last two decades, using competing and sometimes incompatible basic principles. This workshop brings together designers, implementors, and practitioners to discuss all aspects of <b>logical</b> <b>frameworks.</b> We received 13 submissions to the workshop of which the committee decided to accept 10. The programme also includes one invited talk by Randy Pollack...|$|R
40|$|AbstractThis volume {{contains}} {{the proceedings of}} the third Workshop on Proof Search in Type-Theoretic Languages, in conjunction with CADE- 15 Conference. It was held in Lindau, Germany, 5 July 1998. Many recent works have been devoted to type theory and its applications to proof and program development in various <b>logical</b> <b>frameworks.</b> This workshop focuses on proof search in type-theoretic languages and their underlying logics. Such languages are <b>logical</b> <b>frameworks</b> to represent proofs and in some cases formalize connections between proofs and programs that support program synthesis. The workshop is intended to bring together researchers interested in all aspects of proof search in type-theoretic languages. The objective is to provide an integrated forum for the presentation of research and the exchange of ideas and experiences in the topics concerned with proof search in type theory, <b>logical</b> <b>frameworks</b> and their underlying (classical, intuitionistic and linear) logics, including, but not limited to, the following topics: foundations and semantics of proof search, techniques and concepts related to proof construction, logic programming as search-based computation, integration of model-theoretic semantics, proof synthesis vs program synthesis, applications, equational theories and rewriting, decision procedures, environments for formal proof development. In this volume including the contributions to the workshop, we consider these topics through different points of view: sequent calculi for proof search, encoding of rewriting systems, proof search and constructive program synthesis, proof nets as automated deduction tools, semantics for provability and for logic programming, treatment of equality and unification in <b>logical</b> <b>frameworks,</b> works based on different type theories (ITT, lambdaP) and underlying logics (lambda-calculi, intuitionistic logic, linear logic) and different <b>logical</b> <b>frameworks</b> (LF, NuPRL, Forum, lambdaPi). This workshop is a good opportunity to discuss recent results on proof search in type-theoretic languages, and to develop views on the relationship between automated theorem proving and program development in <b>logical</b> <b>frameworks.</b> Many thanks {{to the members of the}} Program Committee, namely D. Galmiche (LORIA – UHP, Nancy, France), P. Lincoln (SRI, Stanford, U. S. A.), F. Pfenning (CMU, Pittsburgh, U. S. A.), D. Pym (Queen Mary and Westfield College, London, U. K.) and T. Tammet (Chalmers University, Göteborg, Sweden) for their work during the preparation of the workshop, also to the authors of submitted abstracts, and to the participants for their active participation and their strong interest. We would like also to take this opportunity to thank Maurice Nivat for preliminary discussion and Michael Mislove for his invitation to publish the proceedings in the ENTCS series...|$|R
5000|$|Most {{developmental}} studies, {{regardless of}} whether they employ the experimental, correlational, or case study method, can also be constructed using research designs. Research designs are <b>logical</b> <b>frameworks</b> used to make key comparisons within research studies such as: ...|$|R
5000|$|The <b>Logical</b> <b>Framework</b> Approach {{takes the}} form of a four-by-four project table.|$|E
5000|$|The <b>Logical</b> <b>Framework</b> Approach, Handbook for objectives-oriented planning, Fourth edition, NORAD, 1999, [...]|$|E
50|$|Harper {{made major}} {{contributions}} {{to the design of}} the Standard ML programming language and the LF <b>logical</b> <b>framework.</b>|$|E
40|$|Abstract. Coercive subtyping is a {{powerful}} approach to subtyping in dependent type theories, but its theoretical properties are often difficult to prove. Lambda-free <b>logical</b> <b>frameworks</b> such as TF have shown themselves to be {{a powerful}} tool for investigating the theory of <b>logical</b> <b>frameworks,</b> thanks to the close correspondance between a lambda-free frame and a traditional framework such as LF. We show how a type theory with coercive subtyping may be defined within TF. An operation of typecasting plays the role that coercive application plays in LF. We show that the resulting systems in TF and LF are equivalent, and how several results may be proven more easily in TF and then lifted to LF...|$|R
40|$|AbstractThis issue {{contains}} the Proceedings of the Third International Workshop on <b>Logical</b> <b>Frameworks</b> and Meta-Languages (LFM 2002). The workshop {{was held in}} Copenhagen, Denmark on July 26, 2002 as a FLoC' 02 affiliated workshop, sponsored by the CADE and LICS conferences. <b>Logical</b> <b>frameworks</b> and meta-languages form a common substrate for representing, implementing, and reasoning about {{a wide variety of}} deductive systems of interest in logic and computer science. Their design and implementation {{has been the focus of}} considerable research over the last two decades, using competing and sometimes incompatible basic principles. This workshop brings together designers, implementors, and practitioners to discuss all aspects of <b>logical</b> <b>frameworks.</b> The papers in this volume were selected by the following program committed, although not formally refereed. 				David Basin,University of FreiburgThierry Coquand,Göteborg UniversityAmy Felty,University of OttawaDidier Galmiche,LORIA NancyDale Miller,Penn State UniversityTobias Nipkow,Technical University MunichFrank Pfenning (chair),Carnegie Mellon UniversityBenjamin Pierce,University of PennsylvaniaBenjamin Werner,INRIA RocquencourtPapers were revised after the workshop before inclusion in these proceedings, which will be published as Volume 70, Issue 2 in the series Electronic Notes in Theoretical Computer Science (ENTCS). It can be accessed via the URL[URL] 9, 2002 Frank Pfennin...|$|R
40|$|There is an {{extensive}} literature focused on using logical methods to reason about communities of agents {{engaged in some}} form of social interaction. Much of the work builds upon existing <b>logical</b> <b>frameworks</b> developed by philosophers and computer scientists incorporating insights and ideas from philosophy (especiall...|$|R
