15|559|Public
40|$|We {{present an}} {{automatic}} crest <b>lines</b> <b>extraction</b> method from 3 D triangulated meshes. We use a bivariate polynomial to approximate the surface locally and calculate the principal curvatures and directions on every vertex and a tracing algorithm {{to extract the}} crest lines. We show crest lines on various triangulated meshes and evaluate their invariance under rotation and stability under scaling. Keywords: 3 D triangulation, crest lines, principal curvatures...|$|E
30|$|Simultaneous {{localization}} and mapping systems using low-cost sensors {{have been}} recently designed. Abrate et al.[9] provide an {{implementation of the}} EKF-SLAM algorithm on a Khepera robot. The robot hosts limited range, sparse and noisy IR sensors. Experimental results have shown {{the importance of the}} sensor characteristics, the primitives (<b>lines)</b> <b>extraction</b> and data association. Yap and Shelton[10] use cheap, noisy and sparse sonar sensors embedded in a P 3 -DX robot. To cope with these low-cost sensors, the implemented SLAM algorithm uses a multiscan approach and an orthogonality assumption to map indoor environments.|$|E
40|$|Abstract — Biometrics is now {{associated}} with the use of unique physiological characteristics to identify an individual next association is security and verification. A biometric system is a pattern recognition system that operates on biometric data which is collected from an individual. There are different biometric systems are available and universally accepted. In this paper we have discussed different principal <b>lines</b> <b>extraction</b> techniques. The proposed system is used for recognition. we have proposed a principal line extraction technique based on coarse segmentation. Susan, niblacks methodology are used in combination for feature extraction. In this paper we discussed the region of interest extraction method for principal lines...|$|E
40|$|Omni-vision system {{using an}} omni-mirror is popular 	to acquire {{environment}} information around an autonomous 	mobile robot. In RoboCup soccer middle size robot league in particular, 	self-localization methods based on white <b>line</b> <b>extraction</b> 	on {{the soccer field}} are popular. We have studied a self-localization 	method based on image features, for example, SIFT and SURF, 	so far. Comparative studies with a conventional self-localization 	method based on white <b>line</b> <b>extraction</b> are conducted. Compared 	to the self-localization method based on white <b>line</b> <b>extraction,</b> 	the method based on image feature {{can be applied to}} a general 	environment with a compact database...|$|R
40|$|Generic layout {{analysis}} [...] process of decomposing document image into homogeneous regions for {{a collection of}} diverse document images [...] has many important applications in document image analysis and understanding such as preprocessing of degraded warped, camera-captured document images, high performance {{layout analysis}} of document images containing complex cursive scripts, and word spotting in historical document images at page level. Many areas in this field like generic text <b>line</b> <b>extraction</b> method are considered as elusive goals so far, still {{beyond the reach of}} the state-of-the-art methods [NJ 07, LSZT 07, KB 06]. This thesis addresses this problem in such a way that it presents generic, domain-independent, text <b>line</b> <b>extraction</b> and text and non-text segmentation methods, and then describes some important applications, that were developed based on these methods. An overview of the key contributions of this thesis is as follows. The first part of this thesis presents a generic text <b>line</b> <b>extraction</b> method using a combination of matched filtering and ridge detection techniques, which are commonly used in computer vision. Unlike the state-of-the-art text <b>line</b> <b>extraction</b> methods in the literature, the generic text <b>line</b> <b>extraction</b> method can be equally and robustly applied to a large variety of document image classes including scanned and camera-captured documents, binary and grayscale documents, typed-text and handwritten documents, historical and contemporary documents, and documents containing different scripts. Different standard datasets are selected for performance evaluation that belong to different categories of document images such as the UW-III [GHHP 97] dataset of scanned documents, the ICDAR 2007 [GAS 07] and the UMD [LZDJ 08] datasets of handwritten documents, the DFKI-I [SB 07] dataset of camera-captured documents, Arabic/Urdu script documents dataset, and German calligraphic (Fraktur) script historical documents dataset. The generic text <b>line</b> <b>extraction</b> method achieves 86...|$|R
40|$|In {{this paper}} a {{real-time}} vision based power <b>line</b> <b>extraction</b> solution is investigated for active UAV guidance. The <b>line</b> <b>extraction</b> algorithm starts from ridge points detected by steerable filters. A collinear line segments fitting algorithm is followed up by considering global and local information together with multiple collinear measurements. GPU boosted algorithm implementation is also investigated in the experiment. The experimental result {{shows that the}} proposed algorithm outperforms two baseline line detection algorithms {{and is able to}} fitting long collinear line segments. The low computational cost of the algorithm make suitable for real-time applications...|$|R
40|$|ABSTRACT: This study {{aimed to}} {{evaluate}} the inbreeding depression and average genetic components in seven hybrids and two open pollinated cultivars for green corn production, {{as well as to}} select the best genotypes in order to obtain base populations for inbred <b>lines</b> <b>extraction.</b> The experiment was carried out in a randomized complete block design with four replications, in a split plot design, with inbreeding levels arranged in the plots and the different genotypes distributed over the subplots, in the municipality of Sabáudia - PR, during the 2014 / 15 crop season. Higher values of dominance and inbreeding depression were observed for yield of both unhusked and commercial ears. Higher additive effects were detected on length and diameter of commercial ears. The genotypes AM 811, Cativerde 02 and AG 4051 showed greater probability of obtaining highly productive and higher quality green corn inbred lines...|$|E
40|$|AbstractSurface {{segmentation}} and edge feature <b>lines</b> <b>extraction</b> from fractured {{fragments of}} relics are essential steps for computer assisted restoration of fragmented relics. As these fragments were heavily eroded, it is a challenging work to segment surface and extract edge feature lines. This paper presents a novel method to segment surface and extract edge feature lines from triangular meshes of irregular fractured fragments. Firstly, a rough surface segmentation {{is accomplished by}} using a clustering algorithm based on the vertex normal vector. Secondly, in order to differentiate between original and fracture faces, a novel integral invariant is introduced to compute the surface roughness. Thirdly, an accurate surface segmentation is implemented by merging faces based on face normal vector and roughness. Finally, edge feature lines are extracted based on the surface segmentation. Some experiments are made and analyzed, and {{the results show that}} our method can achieve surface segmentation and edge extraction effectively...|$|E
40|$|The palmprint {{recognition}} {{has become}} a focus in biological recognition and image processing fields. In this process, the features extraction (with particular attention to palmprint principal line extraction) is especially important. Although {{a lot of work}} has been reported, the representation of palmprint is still an open issue. In this paper we propose a simple, efficient, and accurate palmprint principal <b>lines</b> <b>extraction</b> method. Our approach consists of six simple steps: normalization, median filtering, average filters along four prefixed directions, grayscale bottom-hat filtering, combination of bottom-hat filtering, binarization and post processing. The contribution of our work is a new method for palmprint principal lines detection and a new dataset of hand labeled principal lines images (that we use as ground truth in the experiments). Preliminary experimental results showed good performance in terms of accuracy with respect to three methods {{of the state of the}} art...|$|E
40|$|In this {{dissertation}} {{we present}} the research work we have {{carried out on}} melody and bass <b>line</b> <b>extraction</b> from music audio signals using chroma features. First {{an introduction to the}} task at hand is given and important relevant concepts are defined. Next, the scientific background to our work is provided, including results obtained by state of the art melody and bass <b>line</b> <b>extraction</b> systems. We then present a new approach to melody and bass <b>line</b> <b>extraction</b> based on chroma features, making use of the Harmonic Pitch Class Profile (HPCP) [Gómez 06 a]. Based on our proposed approach, several peak tracking algorithms for select-ing the melody (or bass line) pitch classes are presented. Next, the evaluation methodology and music collections and metrics used for evaluation are discussed, followed by the evaluation results. The results show that as a salience function our proposed HPCP based ap-proach has comparable performance to that of other state of the art systems, in some cases outperforming them. The tracking procedures suggested are shown t...|$|R
40|$|An {{algorithm}} {{of effective}} feature <b>line</b> <b>extraction</b> for triangle mesh model is proposed. Feature <b>line</b> <b>extraction</b> of triangle mesh model {{is not only}} the key technology of revere engineering, but also an important research project of computer vision and machine intelligence. In the paper, firstly the principal curvatures and principal directions of vertex of triangle mesh model are analyzed and feature vertex is confirmed, then the method of “seed growth” to extract feature line is proposed. Experiments and applications show that the method is not only simple and extracting feature rapid, but also extract stably and exactly feature line. IEEE Robotics and Automation Societ...|$|R
40|$|Text <b>line</b> <b>extraction</b> {{is one of}} the {{critical}} steps in document analysis and optical character recognition (OCR) systems. The {{purpose of this study is}} to address the problem of text <b>line</b> <b>extraction</b> of ancient Thai manuscripts written on palm leaves, using an Adaptive Partial Projection (APP) technique by integrating a modified partial projection and smooth histogram with recursion. The proposed approach was compared with a Modified Partial Projection (MPP) looking at vowel analysis and touching components of two consecutive lines. The results from this research suggested that the proposed approach for practical data on palm leaf manuscripts has better performance in solving the line segmentation problem...|$|R
40|$|Surface {{segmentation}} and edge feature <b>lines</b> <b>extraction</b> from fractured {{fragments of}} relics are essential steps for computer assisted restoration of fragmented relics. As these fragments were heavily eroded, it is a challenging work to segment surface and extract edge feature lines. This paper presents a novel method to segment surface and extract edge feature lines from triangular meshes of irregular fractured fragments. Firstly, a rough surface segmentation {{is accomplished by}} using a clustering algorithm based on the vertex normal vector. Secondly, in order to differentiate between original and fracture faces, a novel integral invariant is introduced to compute the surface roughness. Thirdly, an accurate surface segmentation is implemented by merging faces based on face normal vector and roughness. Finally, edge feature lines are extracted based on the surface segmentation. Some experiments are made and analyzed, and {{the results show that}} our method can achieve surface segmentation and edge extraction effectively...|$|E
40|$|Two {{experiments}} with 25 maize commercial hybrids {{were carried out}} in a direct sowing system in Southern Brazil in the harvests of 2009 / 2010 and 2010 / 2011. Quantitative descriptors were used {{with the objective of}} determining the genetic divergence and the relative contributions of traits among hybrids for extraction of inbred lines. This study was carried out in Oxisol soil using a randomized block design with four replicates. Data were subjected to combined analysis of variance, and based on the multivariate analyses, Tocher and average linkage (UPGMA) cluster analyses, based on generalized distance of Mahalanobis, to quantify divergence in addition to Singh criterion to validate trait with the most contribution. The multivariate methods were consistent with each other, and the weight of 100 grains was the trait that contributed most to the divergence and had similar behavior in grain yield between hybrids in both years. Furthermore, this descriptor representing significant genetic variability for crossings and <b>lines</b> <b>extraction</b> to hybridization between BM 3061, ATL 200 and P 30 B 39 Y...|$|E
40|$|Abstract—Extracting a {{signature}} from a check with patterned background is a thorny problem in image segmentation. Meth-ods based on threshold techniques often necessitate meticulous postprocessing {{in order to}} correctly capture the handwritten information. In this study, we tackle the problem of extracting handwritten information {{by means of an}} intuitive approach that is close to human visual perception, defining a topological criterion specific to handwritten lines which we call filiformity. This approach was inspired by the existence in the human eye of cells whose specialized task is the extraction of lines. First, we define two topological measures of filiformity for binary objects. Next, we extend these measures to include gray-level images. One of these measures, which is particularly interesting, differentiates the contour lines of objects from the handwritten lines we are trying to isolate. The local value provided by this measure is then processed by global thresholding, taking into account infor-mation about the whole image. This processing step ends with a simple fast algorithm. Evaluation of the extraction algorithm carried out on 540 checks with 16 different background patterns demonstrates the robustness of the algorithm, particularly when the background depicts a scene. Index Terms—Check processing, filiformity, <b>lines</b> <b>extraction,</b> segmentation. I...|$|E
40|$|Abstract. Automatic {{recognition}} of {{the line in the}} image is an important work in the field of machine vision and image processing. Focusing on the problem of the computational cost and large invalid sampling in the <b>line</b> <b>extraction</b> algorithm using standard Hough transform(HT). An improved HT algorithm is proposed to solve these problems. The parameters of the improved algorithm can be reduced to one and the accumulator is operated by setting the tolerance. Then the existence of linear is determined by seting the threshold. The experimental results show that the algorithm not only can effectively solve the problem of local maxima and improves the algorithm speed and reduces the storage space,but also the accuracy of <b>line</b> <b>extraction</b> is improved...|$|R
40|$|In this paper, {{we discuss}} {{straight}} <b>line</b> <b>extraction</b> {{as a part}} of the image interpretation process. Favoring the use of line drawings as intermediate data for the extraction, we survey the current methods, which all achieve a polygonal approximation of lines, and show that they are not appropriate for the identification of straight elements in a scene. We propose a new approach which uses a scale invariant criterion and is based on the characterization of prime segments in a line, and develop an original method for obtaining these prime segments. Results show that we significantly improve the performance of straight <b>line</b> <b>extraction.</b> The methodology we have used here is applicable to a large class of segmentation problems...|$|R
40|$|There are {{numerous}} stylish documents {{which do not}} have the traditional text layouts where printed text regions are not parallel to each other. Such complex layouts make text <b>line</b> <b>extraction</b> challenging due to multi-orientation of paragraphs. This paper introduces a system for the text <b>line</b> <b>extraction</b> from the complex layout documents. Proposed method is based on the concept of dilation and histogram profiling. The text regions are extracted using dilation and food fill based approach, then paragraph orientation is determined and individual text lines are extracted. The accuracy of extracted text lines are evaluated using the new proposed concept that is also based on the histogram profiling. The results of proposed approach on the complex layouts are promising...|$|R
40|$|This {{research}} integrates existing LOD 2 building {{models and}} multiple close-range images for façade structural <b>lines</b> <b>extraction.</b> The major works are orientation determination and multiple image matching. In the orientation determination, Speeded Up Robust Features (SURF) {{is applied to}} extract tie points automatically. Then, tie points and control points are combined for block adjustment. An object-based multi-images matching is proposed to extract the façade structural lines. The 2 D lines in image space are extracted by Canny operator followed by Hough transform. The role of LOD 2 building models is to correct the tilt displacement of image from different views. The wall of LOD 2 model {{is also used to}} generate hypothesis planes for similarity measurement. Finally, average normalized cross correlation is calculated to obtain the best location in object space. The test images are acquired by a nonmetric camera Nikon D 2 X. The total number of image is 33. The experimental results indicate that the accuracy of orientation determination is about 1 pixel from 2515 tie points and 4 control points. It also indicates that line-based matching is more flexible than point-based matching...|$|E
40|$|International audienceWe {{detail in}} this paper the {{numerical}} implementation of the so-called image curvature microscope, an algorithm that computes accurate image curvatures at subpixel resolution, and yields a curvature map conforming with our visual perception. In contrast to standard methods, which would compute the curvature by a finite difference scheme, the curvatures are evaluated directly on the level lines of the bilinearly interpolated image, after their independent smoothing, a step necessary to remove pixelization artifacts. The smoothing step consists in the affine erosion of the level lines through a geometric scheme, and can be applied in parallel to all level lines. The online algorithm allows the user to visualize the image of curvatures at different resolutions, {{as well as the}} set of level lines before and after smoothing. Source Code The ANSI C++ implementation reviewed by IPOL is given in the file curv. cpp. The complete source code, code documentation, and online demo are accessible at the IPOL web page of this article 1. The level <b>lines</b> <b>extraction</b> (files levelLine. cpp, lltree. cpp) and level lines smoothing (file gass. cpp) are independent algorithms, out of the scope of this article, and details for their implementation are planned for separate IPOL publications...|$|E
40|$|Biometrics {{is playing}} an {{important}} role for person recognition. The Biometrics identification of an individual is {{can be done by}} physiological or behavioral characteristics; where the palm print of an individual can be captured by using sensors and is one of among physiological characteristics of an individual. Palm print is a unique and reliable biometric characteristic with high usability. A palm print refers to an image acquired of the palm region of the hand. The biometric use of palm prints uses ridge patterns to identify an individual. Palm print recognition system is most promising to recognize an individual based on statistical properties of palm print image. It is rich in its features: principal lines, wrinkles, ridges, singular points and minutiae points. This paper proposes a Biometric Palm print <b>lines</b> <b>extraction</b> using image processing morphological operation. The proposed work discusses the significance; since both the palm print and hand shape images are proposed to extract from the single hand image acquired from a sensor. The basic statistical properties can be computed and are useful for biometric recognition of individual. This result and analysis will result into Total Success Rate (TSR) of experiment is 100 %. This paper discusses proposed work for biometric recognition of individual by using basic statistical properties of palm print image. The experiment is carried out by using MATLAB software image processing toolbox...|$|E
40|$|We {{present a}} novel scheme for {{automatically}} generating line drawings from 2 D images, aiming to facilitate effective visual communication. In contrast to conventional edge detectors, our technique imitates the human line drawing process {{and consists of}} two parts: <b>line</b> <b>extraction</b> and <b>line</b> rendering. We propose a novel <b>line</b> <b>extraction</b> method based on likelihood-function estimation, which effectively finds the genuine shape boundaries. We consider the feature scale and the blurriness of lines with which the detail and the focus-level of lines are controlled in the rendering. We also employ stroke textures to provide a variety of illustration styles. Experimental results demonstrate that our technique generates various kinds of line drawings from 2 D images enabled by the control over detail, focus, and style. 1...|$|R
40|$|ABSTARCT: The {{digital image}} <b>line</b> <b>extraction</b> and edge {{smoothing}} in general provides abstracted rendering {{of an image}}. It simplifies the visual interpretation of an image and convey certain features of it more effectively. In this paper we are presenting a method using 2 -D adaptive filtering which is used for preserving the edges while extracting the lines from image. Also a colour based edge detection method is proposed using which chromatic components of an image are extracted through cluster analysis. This <b>line</b> <b>extraction</b> and edge detection scheme is shown to be very effective in preserving the important features of an image. The quality analysis part is calculating Mean Square Error (MSE) and consequently Peak Signal to Noise Ratio (PSNR) which is an approximation to human perception of reconstruction quality...|$|R
40|$|Common {{tasks in}} {{document}} analysis, such as binarization, <b>line</b> <b>extraction</b> etc., are still considered difficult for highly degraded text documents. Having reliable fundamental {{information regarding the}} characters of the document, such as the distribution of character dimensions and stroke width, can significantly improve the performance of these tasks. We introduce a novel perspective of the image data which maps the evolution of connected components along the change in gray scale threshold. The maps reveal significant information about the sets of elements in the document, such as characters, noise, stains, and words. The information is further employed to improve {{state of the art}} binarization algorithm, and achieve automatically character size estimation, <b>line</b> <b>extraction,</b> stroke width estimation, and feature distribution analysis, all of which are hard tasks for highly degraded documents...|$|R
40|$|Information Cairo University Text and not-text {{segmentation}} {{and text}} line extraction from document images {{are the most}} challenging problems of information indexing of Arabic document images such as books, technical articles, business letters and faxes in order to successfully process them in systems such as OCR. Researches on Arabic language related to documents digitization have been focusing on word and handwriting recognition. Few approaches have been proposed for layout analysis for Arabic scanned/captured documents. In this paper we present a page segmentation method that deals with {{the complexity of the}} Arabic language characteristics and fonts using the combination between two algorithms. The first method is the Run length Smoothing. The second method is the Connected Component Labeling algorithm for text and non-text classification using SVM. The combination of the two methods is based on Anding and Oring operations between the outputs of the two methods based on certain conditions. Then, dynamic horizontal projection based on dynamic updating of the threshold to commensurate with the noise associated with different documents and in between text lines. The performance evaluation is performed using manually generated ground truth representations from a dataset of Arabic document images captured using cameras and a hardware built for this purpose. Evaluation and experimental results demonstrate that the proposed text extraction method is independent from different document size, text size, font, shape, and is robust to Arabic document segmentation and text <b>lines</b> <b>extraction...</b>|$|E
40|$|The {{objective}} {{of this study was}} to evaluate the combining ability and inbreeding depression of commercial maize hybrids for agricultural traits. Twenty-two commercial maize hybrids, 96 F 1 crosses from a partial diallel scheme, 22 S 1 populations and 4 controls were evaluated in a 12 x 12 simples square lattice experimental setup, totaling 144 treatments, in the municipality of Sabáudia (PR), Brazil, for harvests from 2011 / 2012 and 2012 / 2013. Three traits were evaluated: grain yield, plant height and ear height. The Griffing method (1956) was applied for the evaluation of the general combining ability (GCA) and specific combining ability (SCA). The 30 B 39, 30 K 64 and 30 B 30 hybrids showed increased yield, 30 F 53 and P 1630 showed reduced plant height and AG 9040 and AG 7010 showed reduced ear height. These hybrids can be recommended for the extraction of inbred lines and formation of composites followed by intrapopulation selection. The combinations 30 B 39 x AG 8088, 30 B 39 x AG 9045 and P 1630 x AG 8021 showed desirable SCA effects for grain yield, plant height and ear height and are recommended for use in reciprocal recurrent selection programs. High magnitudes of inbreeding depression were verified for yield and lower values for inbreeding depression for plant and ear heights. Thus, strategies are recommended for interpopulation breeding accompanied by inbred <b>lines</b> <b>extraction.</b> </p...|$|E
40|$|In {{intelligent}} document {{processing system}} and {{geographical information systems}} (GIS), the image processing and recognition play an important role. This thesis deals with various problems in processing images in documents and GIS: image smoothing, filling, linearization and extraction of contour features, extraction of structural points, separation and recognition of spurious segments in handwritten digits, reconstruction and recognition of broken digits, and separation and recognition of colour document and GIS images. These approaches are also called Optical Character Recognition (OCR). A new smoothing technique is developed to smooth follow contours of image. With the new smoothing algorithms, spurious pixels (points) of contours are removed based on smooth patterns, and smooth followed contours are found. Also, skeletons of image can be smoothed between neighboring 'end' and 'junction' points. Smooth following makes linearization of smoothed contours possible based on Freeman codes. A new filling algorithm of contours, project filling, is described based on two kinds of structural patterns. By this method, any complicated contours of images can be filled correctly. Different from other linearization methods, linearization and feature extraction of smoothed contours are based on difference chain codes. Curvature and bend angles of linearized are found. The convexity and concavity of linearized are described. In this way, a series of description features of contours is formed. Structural points are new and useful features to describe morphological structures between neighboring linearized <b>lines.</b> <b>Extraction</b> of structural points is based on structural patterns which are determined by element chain codes. Also, extension Freeman codes are used in this thesis. Structural points make description and recognition of contours possible. In order to recognize handwritten digits in document processing systems, separation of spurious segments, reconstruction of broken digits and recognition of handwritten digits are investigated. Experiments with large number of testing data set show satisfactory results for these algorithms. Separation and recognition of colour document and GIS images are discussed. Object images of document and GIS images are extracted based on the description of shape structures, prior knowledge and color information, which are associated with each other. Color images can be described by {{a limited number of}} colors in color document and GIS images. Therefore, separation of color image is done by color reduction method, and recognition of object images is based on structure patterns, prior knowledge and colour information. It can be seen that specific information should be considered in many practical problems to achieve better processing results...|$|E
40|$|AbstractÐIn this paper, we give {{a formal}} {{definition}} of a document image structure representation and we formulate document image structure extraction as a partitioning problem: Finding an optimal solution partitioning the set of glyphs of an input document image into a hierarchical tree structure where entities within the hierarchy at each level have similar physical properties and compatable semantic labels. We present a unified methodology that is applicable to construction of document structures at different hierarchical levels. An iterative, relaxation-like method is used to find a partitioning solution that maximizes the probability of the extracted structure. All the probabilities used in the partioning process are estimated from an extensive training set of various kinds of measurements among the entities within the hierarchy. The offline probabilities estimated in the training then drive all decisions in the online document structure extraction. We have implemented a text <b>line</b> <b>extraction</b> algorithm using this framework. The algorithm was evaluated on the UW-III database of some 1, 600 scanned document image pages. An area-overlap measure is used to find the correspondence between the detected entities and the ground-truth. For a total of 105, 020 text lines, the text <b>line</b> <b>extraction</b> algorithm identifies and segments 104, 773 correctly, an accuracy of 99. 76 percent. The detail of the algorithm is presented in this paper. Index TermsÐDocument image analysis, statistical pattern analysis, text <b>line</b> <b>extraction,</b> performance evaluation. ...|$|R
40|$|The {{two main}} {{functions}} of the NLC <b>extraction</b> <b>line</b> include: (1) transmission of the outgoing disrupted beam and secondary particles to the dump with minimal losses; and (2) beam diagnostics and control. In this report, we describe the <b>extraction</b> <b>line</b> optics, present the results of tracking studies, and discuss the <b>extraction</b> <b>line</b> instrumentation...|$|R
40|$|International audienceWe {{present in}} this paper a {{digitization}} project of cultural heritage manuscripts and we discuss the underlying problems, particularly those relative to document analysis. Considering the drawbacks of traditionnal methods for text <b>line</b> <b>extraction</b> in handwritten documents, we propose to adopt a new approach for handwritten page segmentation, based on traditional problem solving framework used in Artificial Intelligence...|$|R
40|$|A new {{scheme for}} {{detecting}} edges and lines in multichannel SAR images is proposed. The line detector is constructed {{from the edge}} detector. The latter is based on multivariate statistical hypothesis tests applied to log-intensity SAR images. The raw results are vectorized by a traditional bright <b>line</b> <b>extraction</b> process. The scheme is illustrated by extracting dark linear structures on various fullpolarimetric SAR images...|$|R
40|$|A {{segregant}} bulk population {{derived from}} a single cross between the Carioca MG cultivar and the ESAL 686 line was used to investigate whether the action of natural selection in the direction required by the breeders and the delaying <b>line</b> <b>extraction</b> would increase the chance of obtaining families with greater grain yield. The populations were advanced from F 2 to F 24 and obtained families F 2, F 8 and F 24 from the plants. These families and their parents were assessed for grain yield (kg/ha) in Lavras-MG in three sowing seasons (July 2001, November 2001 and March 2002) in an 18 x 18 lattice design with two replications in the first sowing and three in the other two. The largest mean yield, regardless of sowing season, was among the families derived from the F 24 plants. The frequency of superior families increased when <b>line</b> <b>extraction</b> was delayed to more advanced generations...|$|R
40|$|Tongue line {{refers to}} the surface of the tongue covered with {{fissures}} or lines in deep or shallow shape and is one type of important features in clinical practice of Traditional Chinese Tongue Diagnosis (TCTD). However, it is hard to extract tongue lines completely due to the large variation of the widths of tongue lines and the strong noise caused by the rough surface of tongue and uneven illumination. In this paper, an improved wide line detector (WLD) is presented for tongue <b>line</b> <b>extraction.</b> Based on the characteristics of tongue lines, the original WLD is improved to avoid the undesired separation of a wide line and the influence of uneven lighting conditions. The proposed method has been tested on a total of 286 tongue line images and our experimental results demonstrate that the improved WLD significantly outperforms the original WLD for tongue <b>line</b> <b>extraction</b> by improving the TPR 16. 5 %, FPR 44. 6 % and PM 33. 4 %, respectively. 1...|$|R
40|$|Introduction One of {{the first}} steps often {{required}} in applying machine recognition to unconstrained handwriting is the identification and <b>extraction</b> of each <b>line</b> of text from among other lines. The purpose of text <b>line</b> <b>extraction</b> is to prepare data {{to meet the requirements}} of succeeding processing steps such as size normalization, word segmentation, or feature extraction. These steps typically require the data to be no more than a single row of characters. The goal of text <b>line</b> <b>extraction</b> is to assign correctly each stroke or component to its appropriate text line so that each isolated line may be passed in turn to the following analysis stage. The task is made difficult by the fact that data frequently contain undulations and shifts in the baseline, baseline skew, baseline-skew variability, character-size variability, sparse data, skipped lines and inter-line distance variability. Several of these issues have been addressed in much of the recent work focused on text line extrac...|$|R
40|$|ABSTRACT: A {{segregant}} bulk population {{derived from}} a single cross between the Carioca MG cultivar and the ESAL 686 line was used to investigate whether the action of natural selection in the direction required by the breeders and the delaying <b>line</b> <b>extraction</b> would increase the chance of obtaining families with greater grain yield. The populations were advanced from F 2 to F 24 and obtained families F 2, F 8 and F 24 from the plants. These families and their parents were assessed for grain yield (kg/ha) in Lavras-MG in three sowing seasons (July 2001, November 2001 and March 2002) in an 18 x 18 lattice design with two replications in the first sowing and three in the other two. The largest mean yield, regardless of sowing season, was among the families derived from the F 24 plants. The frequency of superior families increased when <b>line</b> <b>extraction</b> was delayed to more advanced generations...|$|R
40|$|In {{clustering}} {{line segments}} into a straight line, threshold-based {{methods such as}} hierarchical clustering are often used. The line segments comprising a straight line often get misaligned due to noise. Thresholdbased methods have difficulty clustering such line segments. A new cluster extraction method is proposed {{to cope with this}} problem. This method extracts fuzzy clusters one by one using matrix computation. We evaluated our clustering method using hand-written drawings and obtained promising results. 1 Introduction <b>Extraction</b> of <b>lines</b> from an image is an essential task in computer vision. Many authors have reported various algorithms for <b>line</b> <b>extraction,</b> such as Hough Transformation and gradientbased methods[2]. An effective approach to <b>line</b> <b>extraction</b> is by clustering line segments [5, 6]. Line segments are obtained by applying a line fitting process to the output of edge detection process. A line segment is a small geometric structure defined by two end points. In many cases, l [...] ...|$|R
