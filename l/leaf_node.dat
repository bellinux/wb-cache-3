633|948|Public
25|$|The {{previous}} step deleted {{an element}} (the new separator) from a <b>leaf</b> <b>node.</b> If that <b>leaf</b> <b>node</b> is now deficient (has {{fewer than the}} required number of nodes), then rebalance the tree starting from the <b>leaf</b> <b>node.</b>|$|E
25|$|Expand the <b>leaf</b> <b>node</b> {{and choose}} one of its children.|$|E
25|$|The root has {{at least}} two {{children}} {{if it is not}} a <b>leaf</b> <b>node.</b>|$|E
25|$|A {{balanced}} {{binary tree}} has the minimum possible maximum height (a.k.a. depth) for the <b>leaf</b> <b>nodes,</b> because {{for any given}} number of <b>leaf</b> <b>nodes,</b> the <b>leaf</b> <b>nodes</b> are placed at the greatest height possible.|$|R
25|$|Some {{balanced}} trees store values only at <b>leaf</b> <b>nodes,</b> and {{use different}} kinds of <b>nodes</b> for <b>leaf</b> <b>nodes</b> and internal nodes. B-trees keep values in every node in the tree, and may use the same structure for all <b>nodes.</b> However, since <b>leaf</b> <b>nodes</b> never have children, the B-trees benefit from improved performance if they use a specialized structure.|$|R
5000|$|This time, the anamorphism is the {{generation}} of the call tree isomorphic to the tree with <b>leaf</b> <b>nodes</b> [...] and the catamorphism the summation of these <b>leaf</b> <b>nodes.</b>|$|R
25|$|If {{the value}} is in a <b>leaf</b> <b>node,</b> simply delete {{it from the}} node.|$|E
25|$|A subtree {{consisting}} of a single <b>leaf</b> <b>node</b> corresponds to an induced subgraph with a single vertex.|$|E
25|$|Starting at {{root node}} of the tree, select optimal child nodes until a <b>leaf</b> <b>node</b> is reached.|$|E
30|$|In {{the tree}} topology, <b>leaf</b> <b>nodes</b> have an {{important}} advantage over the internal nodes; they have a single neighbor whereas internal nodes have d neighbors. For that reason, <b>leaf</b> <b>nodes</b> face less competition and they can gain higher throughputs than internal <b>nodes.</b> Since the <b>leaf</b> <b>nodes</b> form {{a large portion of}} nodes in the tree, the probing rates of <b>leaf</b> <b>nodes</b> have to be adjusted such that they have the same throughput with internal nodes. Using the analysis in[31], we select the probing rates such that the throughput distribution is long-term fair.|$|R
50|$|The {{number of}} <b>leaf</b> <b>nodes</b> in the {{complete}} game tree {{is the number}} of possible different ways the game can be played. For example, the game tree for tic-tac-toe has 255,168 <b>leaf</b> <b>nodes.</b>|$|R
30|$|Sutheebanjard and Premchaiswadi [21]'s {{algorithm}} {{was used}} to converted the OR-decision table into a decision tree and evaluated the fitness by {{counting the number of}} <b>leaf</b> <b>nodes</b> in order to minimize the number of <b>leaf</b> <b>nodes.</b>|$|R
25|$|To {{add a new}} node after <b>leaf</b> <b>node</b> A, A assigns the new node {{as one of its}} {{children}} and the new node assigns node A as its parent.|$|E
25|$|Nodes can be {{inserted}} into binary trees in between two other nodes or added after a <b>leaf</b> <b>node.</b> In binary trees, a node that is inserted is specified {{as to which}} child it is.|$|E
25|$|Choose a new {{separator}} (either {{the largest}} {{element in the}} left subtree or the smallest element in the right subtree), remove it from the <b>leaf</b> <b>node</b> it is in, and replace the element to be deleted with the new separator.|$|E
2500|$|For example, if the <b>leaf</b> <b>nodes</b> have {{maximum size}} 4 {{and the initial}} {{collection}} is the integers 1 through 24, we would initially construct 4 <b>leaf</b> <b>nodes</b> containing 5 values each and 1 which contains 4 values: ...|$|R
3000|$|... in Figure 4. At {{the bottom}} of the tree, {{there are a couple of}} text nodes. In the DOM {{structure}} model, the text nodes are not allowed to have children, so they are always the <b>leaf</b> <b>nodes</b> of the DOM tree. There are other types of nodes such as CDATASection nodes and comment nodes that can be <b>leaf</b> <b>nodes.</b> Element nodes can also be <b>leaf</b> <b>nodes.</b> Element nodes may have properties. For example, [...] "<tr class="people">" [...] is an Element Node [...] "<tr>" [...] with property [...] "class="people"." [...] Readers may refer to [URL] for a more detailed specification.|$|R
30|$|Since NFV is {{well suited}} for data center {{networks}} (DCN), a DCN scenario is also considered. Here, the flows are primarily between <b>leaf</b> <b>nodes</b> or between core <b>nodes</b> and <b>leaf</b> <b>nodes.</b> The topology used is the fat-tree topology described in [23].|$|R
25|$|Whether as shrubs, trees, or vines, palms {{have two}} methods of growth: solitary or clustered. The common {{representation}} {{is that of}} a solitary shoot ending in a crown of leaves. This monopodial character may be exhibited by prostrate, trunkless, and trunk-forming members. Some common palms restricted to solitary growth include Washingtonia and Roystonea. Palms may instead grow in sparse though dense clusters. The trunk develops an axillary bud at a <b>leaf</b> <b>node,</b> usually near the base, from which a new shoot emerges. The new shoot, in turn, produces an axillary bud and a clustering habit results. Exclusively sympodial genera include many of the rattans, Guihaia, and Rhapis. Several palm genera have both solitary and clustering members. Palms which are usually solitary may grow in clusters, and vice versa. These aberrations suggest the habit operates on a single gene.|$|E
25|$|For {{physical}} storage of a table, its rows {{are divided into}} a series of partitions (numbered 1 to n). The partition size is user defined; by default all rows are in a single partition. A table is split into multiple partitions in order to spread a database over a computer cluster. Rows in each partition are stored in either B-tree or heap structure. If the table has an associated, clustered index to allow fast retrieval of rows, the rows are stored in-order according to their index values, with a B-tree providing the index. The data is in the <b>leaf</b> <b>node</b> of the leaves, and other nodes storing the index values for the leaf data reachable from the respective nodes. If the index is non-clustered, the rows are not sorted according to the index keys. An indexed view has the same storage structure as an indexed table. A table without a clustered index is stored in an unordered heap structure. However, the table may have non-clustered indices to allow fast retrieval of rows. In some situations the heap structure has performance advantages over the clustered structure. Both heaps and B-trees can span multiple allocation units.|$|E
2500|$|All insertions {{start at}} a <b>leaf</b> <b>node.</b> To insert a new element, search the tree {{to find the}} <b>leaf</b> <b>node</b> where the new element should be added. Insert the new element into that node with the {{following}} steps: ...|$|E
40|$|Abstract. We {{propose a}} new {{algorithm}} for learning isotonic classification trees. It relabels non-monotone <b>leaf</b> <b>nodes</b> by performing the isotonic regression on {{the collection of}} <b>leaf</b> <b>nodes.</b> In case two <b>leaf</b> <b>nodes</b> with a common parent have the same class after relabeling, the tree is pruned in the parent node. Since we consider problems with ordered class labels, all results are evaluated {{on the basis of}} L 1 prediction error. We experimentally compare the performance of the new algorithm with standard classification trees. ...|$|R
5000|$|IndustryBuildingBlocks, line-of-business about 15,000 <b>leaf</b> <b>nodes</b> ...|$|R
50|$|The minimax {{function}} returns a heuristic {{value for}} <b>leaf</b> <b>nodes</b> (terminal nodes and nodes at the maximum search depth).Non <b>leaf</b> <b>nodes</b> inherit their value, bestValue, from a descendant leaf node.The heuristic value is a score measuring the favorability of the node for the maximizing player.Hence nodes {{resulting in a}} favorable outcome, such as a win, for the maximizing player have higher scores than nodes more favorable for the minimizing player.The heuristic value for terminal (game ending) <b>leaf</b> <b>nodes</b> are scores corresponding to win, loss, or draw, for the maximizing player.For non terminal <b>leaf</b> <b>nodes</b> at the maximum search depth, an evaluation function estimates a heuristic value for the node.The quality of this estimate and the search depth determine the quality and accuracy of the final minimax result.|$|R
2500|$|In the B+ tree, {{copies of}} the keys are stored in the {{internal}} nodes; the keys and records are stored in leaves; in addition, a <b>leaf</b> <b>node</b> may include a pointer to the next <b>leaf</b> <b>node</b> to speed sequential access [...]|$|E
2500|$|Each {{terminal}} (<b>leaf)</b> <b>node</b> of {{the game}} tree has an n-tuple of payoffs, meaning there is one payoff for each player {{at the end of}} every possible play ...|$|E
2500|$|... (3) Each pattern [...] (i=1,2,…,z) {{corresponds}} to a node , and the path from the root K to the node [...] can exactly correctly spell the string [...] For each <b>leaf</b> <b>node</b> of this K tree, it {{corresponds to}} one of certain patterns of set [...]|$|E
50|$|<b>Leaf</b> <b>nodes</b> of a B*-tree {{are given}} {{evaluations}} that are intervals rather than single numbers. The interval {{is supposed to}} contain the true value of that node. If all intervals attached to <b>leaf</b> <b>nodes</b> satisfy this property, then B* will identify an optimal path to the goal state.|$|R
40|$|Introduction We {{consider}} {{the problem of}} discovering the structure of an unknown hierarchical network by means of measuring the maximum flow between the root and selected subsets of <b>leaf</b> <b>nodes.</b> More precisely, we are given a root node {{and a set of}} n <b>leaf</b> <b>nodes,</b> each identified by a unique label. The <b>leaf</b> <b>nodes</b> are the leaves of a capacirated hierarchical network. We do not have any additional information about the structure of the network, including the degrees of any internal nodes, the edge capacities, or which <b>leaf</b> <b>nodes</b> are in the same subtree. Our goal is to infer the structure of the network (up to certain equivalences discussed below) by using only a simple test operation, in which we "switch on" a selected subset of the <b>leaf</b> <b>nodes,</b> causing these nodes to transmit data to the root at maximum speed, and then measure the total rate of data arriving at the root. We will refer to this operation as a flow test. In this note, we derive upper and lower bounds for the number of flow t...|$|R
30|$|The {{resulting}} {{decision tree}} shown in Figure 15 has only four levels, whereas that of Wu et al. [6] has five levels (see Figure 6). Therefore, the decision tree created from the proposed algorithm {{appears to be}} more optimal than the tree proposed by Wu et al. [6]. But considering the number of <b>leaf</b> <b>nodes,</b> the proposed decision tree has nine <b>leaf</b> <b>nodes,</b> which are more than the eight <b>leaf</b> <b>nodes</b> of the decision tree proposed by Wu et al. [6]. Practically, an optimal decision tree should have a lower number of <b>leaf</b> <b>nodes.</b> So the proposed scan mask might not work well in pixel-based connected components labeling, but we wanted to demonstrate the idea of the proposed scan mask as pixel-based initially so that later in this article, we will apply it to the block-based connected component method. Thus, the proposed algorithm has advantages over existing algorithms in both criteria; the tree height and number of <b>leaf</b> <b>nodes,</b> and eventually it produced an optimal decision tree. The next section describes the concept of the proposed block-based scan mask.|$|R
2500|$|We {{build the}} next level up from the leaves by taking the last element from each <b>leaf</b> <b>node</b> except the last one. Again, each node except the last will contain one extra value. In the example, suppose the {{internal}} nodes contain at most 2 values (3 child pointers). Then {{the next level}} up of internal nodes would be: ...|$|E
2500|$|A tableau {{for a given}} finite set X is {{a finite}} (upside down) tree with root X in which all child nodes are {{obtained}} by applying the tableau rules to their parents. A branch in such a tableau is closed if its <b>leaf</b> <b>node</b> contains [...] "closed". A tableau is closed if all its branches are closed. A tableau is open if at least one branch is not closed.|$|E
2500|$|With an (average or constant) {{branching}} factor of b, and a search depth of d plies, {{the maximum number}} of <b>leaf</b> <b>node</b> positions evaluated (when the move ordering is [...] ) is O(b*b*...*b) = O(b'd) – the same as a simple minimax search. If the move ordering for the search is optimal (meaning the best moves are always searched first), the number of <b>leaf</b> <b>node</b> positions evaluated is about O(b*1*b*1*...*b) for odd depth and O(b*1*b*1*...*1) for even depth, or [...] In the latter case, where the ply of a search is even, the effective {{branching factor}} is reduced to its square root, or, equivalently, the search can go twice as deep with the same amount of computation. The explanation of b*1*b*1*... is that all the first player's moves must be studied to find the best one, but for each, only the best second player's move is needed to refute all but the first (and best) first player move—alpha–beta ensures no other second player moves need be considered. When nodes are ordered at random, ...|$|E
5000|$|FactSet's Revere, line-of-business, about 11,000 <b>leaf</b> <b>nodes,</b> {{acquired}} in 2013 ...|$|R
25|$|A B-tree is kept {{balanced}} by requiring that all <b>leaf</b> <b>nodes</b> {{be at the}} same depth. This depth will increase slowly as elements {{are added to the}} tree, but an increase in the overall depth is infrequent, and results in all <b>leaf</b> <b>nodes</b> being one more node farther away from the root.|$|R
3000|$|At {{the end of}} {{the first}} phase, i.e., when Q is empty and Phase equals 1, the reader has {{identified}} all staying tags and minor arriving tags that can respond in the first phase. Before starting the second phase, the reader uses Equation  3 to predict the number of unrecognized arriving tags, NewEst, by NewCount, which records the number of recognized arriving tags (line 9, Figure  1 b). After obtaining NewEst, the QueryInsertion (...) function operated internally in the reader generates a complete binary tree in which the number of <b>leaf</b> <b>nodes</b> equals ⌈NewEst⌉ and returns all <b>leaf</b> <b>nodes</b> into Q (line 11, Figure  1 b). Based on the characteristics of a complete binary tree, its <b>leaf</b> <b>nodes</b> can cover all possible ID prefixes. Thus, the reader can use these queries of <b>leaf</b> <b>nodes</b> to interrogate arriving tags in the second phase.|$|R
