62|3611|Public
25|$|The {{heart for}} example {{functions}} {{much like a}} pump, the skeleton is like a <b>linked</b> <b>structure</b> with levers, the brain produces electrical signals etc. These similarities {{as well as the}} increasing importance and application of engineering principles in medicine, {{led to the development of}} the field of biomedical engineering that uses concepts developed in both disciplines.|$|E
5000|$|The {{name comes}} from the way that RCU is used to update a <b>linked</b> <b>structure</b> in place.A thread wishing to do this uses the {{following}} steps: ...|$|E
50|$|The winged edge data {{structure}} allows for quick traversal between faces, edges, and vertices {{due to the}} explicitly <b>linked</b> <b>structure</b> of the network. This rich form of specifying an unstructured grid {{is in contrast to}} simpler specifications of polygon meshes such as a node and element list, or the implied connectivity of a regular grid.|$|E
40|$|Conference Name:IEEE International Symposium on IT in Medicine and Education. Conference Address: Xiamen, PEOPLES R CHINA. Time:DEC 12 - 14, 2008. At present, focused crawler usually crawl pages {{using the}} <b>link</b> <b>structure</b> or page contents. But {{both of them}} have some flaws. So we {{designed}} an efficient crawling strategy, which combine the <b>link</b> <b>structure</b> with content similarity. We extracted topic feature vector automatically and judge the topic similarity of a page using combination of <b>link</b> <b>structure</b> and page content. We also forecast the URL similarity using <b>link</b> <b>structure</b> in topic pages. Experiments showed that this strategy effectively increase the precision of fetching topic pages...|$|R
40|$|Hyperlinks are an {{essential}} {{feature of the}} World Wide Web, highly responsible for its success. XLink improves on HTML’s linking capabilities in several ways. In particular, links after XLink can be “out-of-line ” (i. e., not defined at a link source) and collected in (possibly several) linkbases, which considerably ease building complex <b>link</b> <b>structures.</b> Modeling of <b>link</b> <b>structures</b> and processing of linkbases under the Web’s “open world linking ” are aspects neglected by XLink. Adding a notion of “interface ” to XLink, as suggested in this work, considerably improves modeling of <b>link</b> <b>structures.</b> When a <b>link</b> <b>structure</b> is traversed, the relevant linkbase(s) might become ambiguous. We suggest three linkbase management modes governing the binding of a linkbase to a document to resolve this ambiguity...|$|R
40|$|Barabasi and Albert (1) propose an {{improved}} {{version of the}} Erdos-Renyi (ER) theory of random networks {{to account for the}} scaling properties of a number of systems, including the <b>link</b> <b>structure</b> of the World Wide Web (WWW). The theory they present, however, is inconsistent with empirically observed properties of the Web <b>link</b> <b>structure...</b>|$|R
50|$|The {{heart for}} example {{functions}} {{much like a}} pump, the skeleton is like a <b>linked</b> <b>structure</b> with levers, the brain produces electrical signals etc. These similarities {{as well as the}} increasing importance and application of engineering principles in medicine, {{led to the development of}} the field of biomedical engineering that uses concepts developed in both disciplines.|$|E
50|$|There are {{numerous}} microscopy methods for defining gel structures which include SEM and TEM. Use of microscopic techniques can directly determine the physical {{parameters of the}} gel matrix. These include measurements of pore diameter, wall thickness {{and shape of the}} gel network. Use of SEM can distinguish between gels that have a fibrous network as opposed to those that have a three-dimensional cross <b>linked</b> <b>structure.</b> It must be noted that microscopy techniques may not yield quantitatively accurate results. If a high vacuum is used during imaging, the liquid solvent can be removed from the gel matrix-inducing strain to the gel which leads to physical deformation. Use of an environmental SEM, which operates at higher pressures, can yield higher quality imaging.|$|E
5000|$|Beardsley's {{approach}} was refined by Stephen N. Thomas, whose 1973 book Practical Reasoning In Natural Language introduced the term linked to describe arguments where the premises necessarily {{worked together to}} support the conclusion. However, the actual distinction between dependent and independent premises had been made prior to this. The introduction of the <b>linked</b> <b>structure</b> {{made it possible for}} argument maps to represent missing or [...] "hidden" [...] premises. In addition, Thomas suggested showing reasons both for and against a conclusion with the reasons against being represented by dotted arrows. Thomas introduced the term argument diagram and defined basic reasons as those that were not supported by any others in the argument and the final conclusion as that which was not used to support any further conclusion.|$|E
40|$|Model checking, {{which is}} a {{framework}} for automatically verifying a system by enumerating its entire state space, always faces the problem of state space explosion. Although abstract model checking {{is considered to be}} a promising technique for solving the problem, a general method that can abstract <b>link</b> <b>structures,</b> such as memory or network, was not known. In this paper, we propose a method for abstracting <b>link</b> <b>structures</b> independent of their size. By the method, each cell in a <b>link</b> <b>structure</b> is abstracted by whether it satisfies each of the predefined regular expressions. The entire <b>link</b> <b>structure</b> is then abstracted by a set of abstract cells, each of {{which is a}} result of abstracting a cell. For showing the e ectiveness of the method, we did abstract model checking of the safety property of several algorithms for concurrent garbage collection...|$|R
40|$|Abstract Search Engines {{exploit the}} Web’s {{hyperlink}} structure to help infer information content. The new phenomenon of personal Web logs, or ‘blogs’, encourage more extensive annotation of Web content. If their resulting <b>link</b> <b>structures</b> bias the Web crawling applications that search engines depend upon, there are implications for {{another form of}} annotation rapidly on the rise, the Semantic Web. We conducted a Web crawl of 160 000 pages in which the <b>link</b> <b>structure</b> of the Web is {{compared with that of}} several thousand blogs. Results show that the two <b>link</b> <b>structures</b> are significantly different. We analyse the differences and infer the likely effect upon the performance of existing and future Web agents. The Semantic Web offers new opportunities to navigate the Web, but Web agents should be designed {{to take advantage of the}} emerging <b>link</b> <b>structures,</b> or their effectiveness will diminish...|$|R
40|$|Wikipedia {{is one of}} {{the most}} popular {{information}} sources on the Web. The free encyclopedia is densely <b>linked.</b> The <b>link</b> <b>structure</b> in Wikipedia differs from the Web at large: internal links in Wikipedia are typically based on words naturally occurring in a page, and link to another semantically related entry. Our main aim is to find out if Wikipedia’s <b>link</b> <b>structure</b> can be exploited to improve ad hoc information retrieval. We first analyse the relation between Wikipedia links and the relevance of pages. We then experiment with use of link evidence in the focused retrieval of Wikipedia content, based on the test collection of INEX 2006. Our main findings are: First, our analysis of the <b>link</b> <b>structure</b> reveals that the Wikipedia <b>link</b> <b>structure</b> is a (possibly weak) indicator of relevance. Second, our experiments on INEX ad hoc retrieval tasks reveal that if the link evidence is made sensitive to the local context we see a significant improvement of retrieval effectiveness. Hence, in contrast with earlier TREC experiments using crawled Web data, we have shown that Wikipedia’s <b>link</b> <b>structure</b> can help improve the effectiveness of ad hoc retrieval...|$|R
5000|$|The {{ability to}} wait until all readers are done allows RCU readers to use much lighter-weight {{synchronization}} - in some cases, absolutely no synchronization at all. In contrast, in more conventional lock-based schemes, readers must use heavy-weight synchronization {{in order to prevent}} an updater from deleting the data structure out from under them. This is because lock-based updaters typically update data items in place, and must therefore exclude readers. In contrast, RCU-based updaters typically take advantage of the fact that writes to single aligned pointers are atomic on modern CPUs, allowing atomic insertion, removal, and replacement of data items in a <b>linked</b> <b>structure</b> without disrupting readers. Concurrent RCU readers can then continue accessing the old versions, and can dispense with the atomic read-modify-write instructions, memory barriers, and cache misses that are so expensive on modern SMP computer systems, even in absence of lock contention. [...] The lightweight nature of RCU's read-side primitives provides additional advantages beyond excellent performance, scalability, and real-time response. For example, they provide immunity to most deadlock and livelock conditions.|$|E
40|$|This {{extended}} abstract overviews {{work on a}} type {{system for}} lock-free programming based on compare-and-swap. The type system prevents atomicity violations in lock-free programs, where insertion and removal of objects from a <b>linked</b> <b>structure</b> {{would be subject to}} data-races breaking linearity of ownership. The type system has successfully been applied to a small number of lock-free data structures. Structured AliasingUpscaleUPMAR...|$|E
40|$|We {{show that}} a {{mechanical}} model of a pin-jointed <b>linked</b> <b>structure</b> is exactly equivalent to a symplectic Euler discretisation of a Hamiltonian ODE system. The step-size of this discretisation relates to a mechanical quantity which can take arbitrary values. Thus we may explore the behaviour of the symplectic Euler method in regions not normally considered appropriate for a numerical scheme and investigate the use of backward error analysis in describing the behaviour of the pin-jointed structure. ...|$|E
5000|$|... global {{orientation}} support - the system presents {{an overview of}} the whole (<b>link)</b> <b>structure</b> of the hyperspace, ...|$|R
40|$|We {{consider}} a generic configuration of regions, {{consisting of a}} collection of distinct compact regions {Ω_i} in R^n+ 1 which may be either smooth regions disjoint from the others or regions which meet on their piecewise smooth boundaries B_i in a generic way. We introduce a skeletal <b>linking</b> <b>structure</b> for the collection of regions which simultaneously captures the regions' individual shapes and geometric properties as well as the "positional geometry" of the collection. The <b>linking</b> <b>structure</b> extends in a minimal way the individual "skeletal structures" on each of the regions, allowing us to significantly extend the mathematical methods introduced for single regions to the configuration. We prove for a generic configuration of regions the existence of a special type of Blum <b>linking</b> <b>structure</b> which builds upon the Blum medial axes of the individual regions. This requires proving several transversality theorems for certain associated "multi-distance" and "height-distance" functions for such configurations. We show that by relaxing the conditions on the Blum <b>linking</b> <b>structures</b> we obtain the more general class of skeletal <b>linking</b> <b>structures</b> which still capture the geometric properties. In addition to yielding geometric invariants which capture the shapes and geometry of individual regions, the <b>linking</b> <b>structures</b> are used to define invariants which measure positional properties of the configuration such as: measures of relative closeness of neighboring regions and relative significance of the individual regions for the configuration. These invariants, which are computed by formulas involving "skeletal linking integrals" on the internal skeletal structures, are then used to construct a "tiered linking graph," which identifies subconfigurations and provides a hierarchical ordering of the regions. Comment: 135 pages, 36 figures. Version to appear in Memoirs of the Amer. Math. So...|$|R
40|$|Most {{real-world}} data is heterogeneous and richly interconnected. Examples include the Web, hypertext, bibliometric data and social networks. In contrast, most statistical learning methods work with "flat" data representations, forcing us to convert our data {{into a form}} that loses much of the <b>link</b> <b>structure.</b> The recently introduced framework of probabilistic relational models (PRMs) embraces the object-relational nature of structured data by capturing probabilistic interactions between attributes of related entities. In this paper, we extend this framework by modeling interactions between the attributes and the <b>link</b> <b>structure</b> itself. An advantage of our approach is a unified generarive model for both content and relational structure. We propose two mechanisms for representing a probabilistic distribution over link structures: reference uncertainty and existence uncertainty. We describe the appropriate conditions for using each model and present learning algorithms for each. We present experimental results showing that the learned models {{can be used to}} predict <b>link</b> <b>structure</b> and, moreover, the observed <b>link</b> <b>structure</b> can be used to provide better predictions for the attributes in the model...|$|R
40|$|This paper {{addresses}} {{the classification of}} linked entities. We introduce a relational vectnr-space (VS) model (in analogy to the VS model used in information retrieval) that abstracts the <b>linked</b> <b>structure,</b> representing entities by vectors of weights. Given labeled data as background knowledgdtraining data, classification procedures can be defined for this model, including a straightforward, &quot;direct &quot; model using weighted adjacency vectors. Using a large set of tasks from the domain of company affiliation identitication, we demonstrate that such classification proccdurcs can be effective. We then examine the method in more detail, showing that as expected the classification performance correlates with the- relational ~-~~~~~ ~ autocorrelation of the data set. We then turn the tables and use the relational VS scores {{as a way to}} analy 7. dvisualize the relational autocorrelation present in a complex <b>linked</b> <b>structure.</b> The main contribution ofthe paper 1 s to introduce the relational VS model as a potentially useful addition to the toolkit for relational data mining. It could provide useful constructed ~~ ~ ~ ~ ~ ~ features for domains with low to moderate relational autocomelation; it may be effective by itself for domains with high levels of relational autocorrelat~on, and it provides a useful abstraction for analyzing the properties of linked data...|$|E
40|$|Abstract A central {{feature of}} current {{object-oriented}} languages {{is the ability}} to dynami-cally instantiate user-defined container data structures such as lists, trees, and hash tables. Implementations of these data structures typically use references to dynam-ically allocated objects, which complicates reasoning about the resulting program. Reasoning is simplified if data structure operations are specified in terms of abstractsets of objects associated with each data structure. For example, an insertion into a data structure in this approach becomes simply an insertion into a dynamicallychanging set-valued field of an object, as opposed to a manipulation of a dynamically <b>linked</b> <b>structure</b> attached to the object...|$|E
40|$|Abstract:- Wiki is the {{powerful}} hypertext-based collaborative {{systems and the}} conversational knowledge management system. However, some factors interrupt the social interaction needed for collaboration in wiki. At first the linked-structure is hidden and continuously changeable. Furthermore, the <b>linked</b> <b>structure</b> has {{become more and more}} complex. The linked structure’s complexity interrupts collaborative condition monitoring and group collaboration. We develop and test new adaptive measures proposed in this paper {{to decide whether or not}} they satisfy a group’s collaborative condition. The visualization of these scores will support a basis to examine the collaborative status and to decide the starting point of next activity in process-oriented learning. The simulation’s result shows that changes in score values go with collaborative status...|$|E
40|$|Many {{engineering}} {{systems are}} too complex to design {{as a single}} entity. Decomposition-based design optimization methods partition a system design problem into subproblems, and coordinate subproblem solutions toward an optimal system design. Recent work has addressed formal methods for determining an ideal system partition and coordination strategy, but coordination decisions have been limited to subproblem sequencing. An additional element in a coordination strategy is the <b>linking</b> <b>structure</b> of the partitioned problem, i. e., the allocation of constraints that guarantee that the linking variables among subproblems are consistent. There can be many alternative <b>linking</b> <b>structures</b> for a decomposition-based strategy which can be selected for a given partition, and this selection {{should be part of}} an optimal simultaneous partitioning and coordination scheme. This paper develops a <b>linking</b> <b>structure</b> theory for a particular class of decompositionbased optimization algorithms, Augmented Lagrangian Coordination (ALC). A new formulation and coordination technique for parallel ALC implementations is introduced along with a specific <b>linking</b> <b>structure</b> theory, yielding a partitioning and coordination selection method for ALC that includes consistency constraint allocation. This method is demonstrated using an electric water pump design problem. ...|$|R
40|$|Under the {{direction}} of James Damon) The Blum medial axis of a region with smooth boundary in Rn+ 1 is a skeleton-like topological structure that captures shape and geometric properties {{of the region and}} its boundary. We introduce a structure, called the Blum medial <b>linking</b> <b>structure,</b> which extends the advantages of the medial axis to configurations of multiple disjoint regions in order to capture both their individual and “positional ” or relative geometry. We use singularity theory to classify the generic local normal forms of the medial <b>linking</b> <b>structure</b> for generic configurations of regions in dimensions n ≤ 6, which requires proving a transversality theorem for families of “multi–distance functions. ” We show how invariants of the geometry of the regions and their complement may be computed directly from the <b>linking</b> <b>structure.</b> We conclude with applications of the <b>linking</b> <b>structure</b> to the analysis of multiple objects in medical images. ii Acknowledgements First and foremost, I owe my deepest gratitude to my advisor, Jim Damon, for his enthusiasm and guidance throughout the years...|$|R
40|$|Mining {{search engine}} query log {{is a new}} method for {{evaluating}} web site <b>link</b> <b>structure</b> and information architecture. In this {{paper we propose a}} new query-URL co-clustering for a web site useful to evaluate information architecture and <b>link</b> <b>structure.</b> Firstly, all queries and clicked URLs corresponding to particular web site are collected from a query log as bipartite graph, one side for queries and the other side for URLs. Then a new content free clustering is applied to cluster queries and URLs concurrently. Afterwards, based on information entropy, clusters of URLs and queries will be used for evaluating <b>link</b> <b>structure</b> and information architecture respectively. Data sets of different web sites have been extracted from a huge query log to evaluate our method, and experiments show promising result...|$|R
40|$|Abstract. Efficient message {{dissemination}} in ad hoc networks can be {{fostered by}} exploiting stable (sub-) structures. By efficient we mean low network resource usage regarding reachability. In this paper we build a hierarchical protocol. We first create single-hop clusters among stableconnected devices. On top of those clusters, we further determine intercluster relays (ICR), finally providing an overall stable-connected structure. Our proposed stable <b>linked</b> <b>structure</b> flooding (SLSF) protocol efficiently disseminates data among stable nodes. Additional fault recovery mechanisms are employed {{to compensate for}} local intermittent node failures if needed. The experiments show that our approach increases flooding performances with a low bandwidth usage. Furthermore SLSF remains very efficient {{with or without the}} fault recovery mechanism that provides robustness. ...|$|E
40|$|Summary: Jalview Version 2 is {{a system}} for {{interactive}} WYSIWYG editing, analysis and annotation of multiple sequence alignments. Core features include keyboard and mouse based editing, multiple views and alignment overviews, and <b>linked</b> <b>structure</b> display with Jmol. Jalview 2 is available in two forms: a lightweight Java applet for use in web applications, and a powerful desktop application that employs web services for sequence alignment, secondary structure prediction, and the retrieval of alignments, sequences, annotation and structures from public databases and any DAS 1. 53 compliant sequence or annotation server. Availability: The Jalview 2 Desktop application and JalviewLite applet are made freely available under the GPL, and can be downloaded from www. jalview. org Contact...|$|E
40|$|International audienceFor some {{applications}} in ad hoc networks optimal dissemination {{is a key}} issue (e. g. service discovery, network management). In this paper, we are creating and exploiting stable (sub-) structures to achieve an efficient (as far as low network resource usage is concerned) dissemination by building a two-layer protocol. Firstly, single-hop clusters, among stable-connected devices, are created. Secondly, on top of those clusters, inter-cluster relays (ICR) are determined. This leads to an overall stable-connected structure. The {{results show that the}} proposed stable <b>linked</b> <b>structure</b> flooding (SLSF) protocol efficiently disseminates data among stable nodes. Interestingly with growing density both the number of forwarding nodes and the bandwidth used remain comparatively low. Therefore we plan to use SLSF as a basis for a stable service discovery...|$|E
5000|$|... local {{orientation}} support - {{the system}} presents {{an overview of}} {{a part of the}} (<b>link)</b> <b>structure</b> of the hyperspace, ...|$|R
5000|$|... map {{adaptation}} - {{the content}} and presentation of {{a map of the}} <b>link</b> <b>structure</b> of the hyperspace is adapted.|$|R
40|$|Abstract — Method for {{visualization}} of URL <b>link</b> <b>structure</b> and URL retrievals using internal structure of URLs based on brunch and bound method is proposed. Twisting <b>link</b> <b>structure</b> of URLs {{can be solved}} by the proposed visualization method. Also some improvements are observed for the proposed brunch and bound based method {{in comparison to the}} conventional URL retrieval methods. Keywords- {{visualization of}} link structure; URL retrieval; brunch and bound method; serch engine; information collection robot...|$|R
40|$|An {{important}} feature of object-oriented programming languages {{is the ability to}} dynamically instantiate user-defined container data structures such as lists, trees, and hash tables. Programs implement such data structures using references to dynamically allocated objects, which allows data structures to store unbounded numbers of objects, but makes reasoning about programs more difficult. Reasoning about object-oriented programs with complex data structures is simplified if data structure operations are specified in terms of abstract sets of objects associated with each data structure. For example, an insertion into a data structure in this approach becomes simply an insertion into a dynamically changing set-valued field of an object, as opposed to a manipulation of a dynamically <b>linked</b> <b>structure</b> linked to the object. In this paper we explore [...] ...|$|E
40|$|In this paper, a {{semantic}} parser with support to ellipsis resolution in a Chinese spoken language dialogue system is proposed. The grammar and parsing strategy of this parser {{is designed to}} address the characteristics of spoken language and to support the ellipsis resolution. Namely, it parses the user utterance with a domain-specific semantic grammar based on a template-filling approach. Syntactic constraints extracted by a Generalized LR parser are also used in the parsing process. With a paradigm of two-state bottom-up parsing and a scoring scheme, the ellipsis resolution module is integrated into the parser seamlessly. The parsing result is represented by a <b>linked</b> <b>structure</b> of semantic frames, which is convenient to both the parser and its successive components of the dialogue system. 1...|$|E
40|$|The {{original}} publication {{is available}} at www. springerlink. comInternational audienceEfficient message dissemination in ad hoc networks can be fostered by exploiting stable (sub-) structures. By efficient we mean low network resource usage regarding reachability. In this paper we build a hierarchical protocol. We first create single-hop clusters among stable-connected devices. On top of those clusters, we further determine inter-cluster relays (ICR), finally providing an overall stable-connected structure. Our proposed stable <b>linked</b> <b>structure</b> flooding (SLSF) protocol efficiently disseminates data among stable nodes. Additional fault recovery mechanisms are employed to compensate for local intermittent node failures if needed. The experiments show that our approach increases flooding performances with a low bandwidth usage. Furthermore SLSF remains very efficient {{with or without the}} fault recovery mechanism that provides robustness...|$|E
40|$|Web user forums are {{valuable}} means for users to resolve specific information needs, both interactively for participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads {{can make it}} difficult for users to extract relevant information. Thread <b>linking</b> <b>structure</b> has the potential to help tasks such as information retrieval (IR) and threading visualisation of forums, thereby improving information access. Unfortunately, thread <b>linking</b> <b>structure</b> is not always available in forums. This paper proposes an unsupervised approach to predict forum thread <b>linking</b> <b>structure</b> using lexical chaining, a technique which identifies lists of related word tokens within a given discourse. Three lexical chaining algorithms, including one that only uses statistical associations between words, are experimented with. Preliminary experiments lead to results which surpass an informed baseline. ...|$|R
40|$|Di#erent {{models have}} been {{proposed}} for improving the results of Web search by {{taking into account the}} <b>link</b> <b>structure</b> of the Web. The PageRank algorithm models the behavior of a random surfer alternating between random jumps to new pages and following out links with equal probability. We propose to improve on PageRank by using an intelligent surfer that combines <b>link</b> <b>structure</b> and content to decide on its next transition. The intelligent surfer is guided by the textual authority of the web page...|$|R
40|$|The {{paper will}} {{introduce}} an XLinkTime model for time-sensitive <b>linking</b> <b>structures</b> that consist of Web resources and/or portions of Web resources and time-dependent links between them. The paper {{will present the}} way XLinkTime model can be realized by extending the XML Linking Language (XLink) with a timerule namespace. Proof-of-concept implementation {{in the field of}} time-based project management will be described. The paper will discuss in general the way in which time ontology approach could be applied to construct and manage time-sensitive <b>linking</b> <b>structures.</b> ...|$|R
