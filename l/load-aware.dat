103|0|Public
50|$|The concerted {{operational}} mode delivers extra {{benefits such as}} the ability to deliver peak load electricity or <b>load-aware</b> power generation at short notice. Such a VPP can replace a conventional power plant while providing higher efficiency and more flexibility. Note that more flexibility allows the system to react better to ﬂuctuations. However, a VPP is also a complex system requiring a complicated optimization, control, and secure communication methodology.|$|E
40|$|Wireless mesh {{networking}} {{is one of}} the most promising next generation network technologies. A wireless mesh network is a decentralized, self-organizing, self-configuring and self-healing multi-hop wireless network. In this thesis, we introduce the development, architectures, characteristics and applications of wireless mesh networks and present the existing channel assignments and routing protocols for wireless mesh networks. [...] In recent years, many efforts have been taken to better exploit multiple non-overlapping channels for wireless mesh networks, e. g. IEEE 802. 11 a based wireless mesh networks, in which 12 or 24 non-overlapping channels are available. Although the IEEE 802. 11 b/g standards, which govern the unlicensed 2. 4 GHz industrial, scientific and medical (ISM) band, provide 11 channels, only three of them, namely 1, 6 and 11 are non-overlapping. In order to better utilize communication bandwidth and improve quality of service, in this thesis, we propose a channel assignment exploiting partially o overlapping channels (CAEPO). In CAEPO, the interference a node suffers within its interference range is the main metric for channel assignment. It is defined to be a combination of the overlapping degree between channels and busy time proportion, i. e. channel utilization ratio of interfering nodes. In addition to that, packet loss ratio is another major consideration in the implementation of channel assignment. [...] To further improve the aggregated network performance, we propose <b>Load-Aware</b> CAEPO scheme based on the original CAEPO. In <b>Load-Aware</b> CAEPO, instead of using the busy time proportion of interfering nodes, we employ the traffic load as another main factor of the interference metric besides the channel overlapping degree. In addition, the concept of self-interference is introduced to estimate the interference metric. To facilitate the implementation of our channel assignment scheme, we modify the original AODV to be bandwidth-aware, where end-to-end delay and available bandwidth are both used as the routing constraints. Simulation results demonstrate that the proposed scheme can significantly improve the aggregated network performance. [...] For large networks, we introduce a node grouping algorithm in <b>Load-Aware</b> CAEPO and name the new channel assignment scheme <b>Load-Aware</b> CAEPO-G. Compared to <b>Load-Aware</b> CAEPO, <b>Load-Aware</b> CAEPO-G leads to a fairer channel assignment and achieves a minor improvement of the aggregated network performance. [...] Finally, performance of <b>Load-aware</b> CAEPO scheme is studied under voice applications over wireless mesh networks. To address the two challenges in voice over packet (VOP) applications, end-to-end delay and delay jitter, we propose VOP-AODV routing protocol. Along with VOP-AODV routing protocol, <b>Load-aware</b> CAEPO scheme can effectively decrease end-to-end delay and delay jitter...|$|E
40|$|Thesis (M. Eng.) [...] Memorial University of Newfoundland, 2010. Engineering and Applied ScienceIncludes bibliographical {{references}} (leaves 75 - 80) Wireless {{mesh networking}} {{is one of}} the most promising next generation network technologies. A wireless mesh network is a decentralized, self-organizing, self-configuring and self-healing multi-hop wireless network. In this thesis, we introduce the development, architectures, characteristics and applications of wireless mesh networks and present the existing channel assignments and routing protocols for wireless mesh networks. [...] In recent years, many efforts have been taken to better exploit multiple non-overlapping channels for wireless mesh networks, e. g. IEEE 802. 11 a based wireless mesh networks, in which 12 or 24 non-overlapping channels are available. Although the IEEE 802. 11 b/g standards, which govern the unlicensed 2. 4 GHz industrial, scientific and medical (ISM) band, provide 11 channels, only three of them, namely 1, 6 and 11 are non-overlapping. In order to better utilize communication bandwidth and improve quality of service, in this thesis, we propose a channel assignment exploiting partially o overlapping channels (CAEPO). In CAEPO, the interference a node suffers within its interference range is the main metric for channel assignment. It is defined to be a combination of the overlapping degree between channels and busy time proportion, i. e. channel utilization ratio of interfering nodes. In addition to that, packet loss ratio is another major consideration in the implementation of channel assignment. [...] To further improve the aggregated network performance, we propose <b>Load-Aware</b> CAEPO scheme based on the original CAEPO. In <b>Load-Aware</b> CAEPO, instead of using the busy time proportion of interfering nodes, we employ the traffic load as another main factor of the interference metric besides the channel overlapping degree. In addition, the concept of self-interference is introduced to estimate the interference metric. To facilitate the implementation of our channel assignment scheme, we modify the original AODV to be bandwidth-aware, where end-to-end delay and available bandwidth are both used as the routing constraints. Simulation results demonstrate that the proposed scheme can significantly improve the aggregated network performance. [...] For large networks, we introduce a node grouping algorithm in <b>Load-Aware</b> CAEPO and name the new channel assignment scheme <b>Load-Aware</b> CAEPO-G. Compared to <b>Load-Aware</b> CAEPO, <b>Load-Aware</b> CAEPO-G leads to a fairer channel assignment and achieves a minor improvement of the aggregated network performance. [...] Finally, performance of <b>Load-aware</b> CAEPO scheme is studied under voice applications over wireless mesh networks. To address the two challenges in voice over packet (VOP) applications, end-to-end delay and delay jitter, we propose VOP-AODV routing protocol. Along with VOP-AODV routing protocol, <b>Load-aware</b> CAEPO scheme can effectively decrease end-to-end delay and delay jitter...|$|E
40|$|Abstract — <b>Load-aware</b> routing metrics aim {{to address}} {{congestion}} and load-balancing issues in wireless mesh networks by directing traffic either around {{or away from}} loaded regions of the network. However, the fact that load estimates used to choose routes are in turn affected by resulting routing changes in a cyclical manner {{makes it difficult to}} preset the sensitivity of route adaptation to load. On the other hand, desensitizing nodes to traffic load may render them unresponsive, leading to inaccuracies in load estimates and difficulties in achieving proper traffic distribution. To address these issues, we present CLAW, a novel channel <b>load-aware</b> routing metric that handles the routing process in a manner analogous to a feedback control system. Simulations show that CLAW significantly improves network performance in both throughput and delay against hop count and other competing <b>load-aware</b> routing metrics found in the literature...|$|E
40|$|Anycast is a {{powerful}} paradigm for managing and locating resources in decentralized dis-tributed systems. Ideally, an anycast system must be scalable, location-aware and <b>load-aware.</b> Location-awareness means that the anycast system {{should be able to}} locate a re-source that is near the client in the network. Load-awareness means that it must be able to disperse load to avoid overloading group members in the case of high demand in a certain region of the network. Existing anycast systems are either location-aware or <b>load-aware,</b> but not both. We mo-tivate LALA, a generic architecture for doing scalable, location-aware, <b>load-aware</b> anycast that realizes the following anycast functionality: Given a client request, our goal is to select the closest anycast server that has enough resources to satisfy the client’s request. We show how LALA can be designed on some of the existing overlay anycast architectures and close with an evaluation that demonstrates its effectiveness. Acknowledgments The work in this thesis was done under the guidance of my advisor Dr. Peter Drusche...|$|E
40|$|Abstract—We {{propose a}} novel <b>load-aware</b> power-selection {{strategy}} for maximizing the transparent reach in dispersion-uncompensated flexible optical networks with coherent modulation formats, and we quantify the savings in opto-electronic regenerations {{with respect to}} using the standard full-load transparent reach. I...|$|E
40|$|Abstract—Long term user rate in {{cellular}} networks is {{the product}} of spectral efficiency achieved and the resources (time/frequency slots) allocated. The former is related to the received SINR, while the latter is limited by the load of the associated cell. The max-SINR cell association strategy has been used in cellular networks from GSM to LTE. This strategy maximizes the possible achieved spectral efficiency but fails to account for the load imbalance. Recently, there have been several investigations on <b>load-aware</b> cell association as an approach to match the traffic demand with the traffic supply, in which a user may associate to a less loaded cell, even though it does not necessarily provide the maximum SINR. In other words, a user is associated with a cell to get more share of resources at the cost of lower spectral efficiency. This paper goes beyond that by proposing a new load balanc-ing approach that can simultaneously increase the user received SINR and the share of allocated resources. This is achieved by the user-in-the-loop (UIL) paradigm, which encourages the user to move to a new location that maximizes the utility function considering the received SINR, cell load and the probability of moving. Numerical results show that the UIL can increase the mean user rate substantially in comparison to the max-SINR or the <b>load-aware</b> cell association strategy, and also results in a more balanced load across the network. Index Terms—User-in-the-loop, load balancing, cell association, <b>load-aware,</b> heterogeneous cellular networks. I...|$|E
40|$|An {{important}} {{class of}} distributed real-time and embedded (DRE) applications consists predominantly of periodic soft real-time tasks. Timeliness and reliability are both essential {{requirements for the}} correct operation of these applications. Conventional solutions to these challenges tend to use non-adaptive and load-agnostic fault tolerance solutions within a real-time system, which often end up making ad hoc failover decisions that can further overload already strained resources. Potential adverse consequences of these ad hoc actions include excessive delays for real-time tasks and cascades of resource failures. This paper presents FLARe, a middleware that provides a lightweight fault tolerance solution for DRE systems. FLARe uses adaptive and <b>load-aware</b> mechanisms to prevent system overload after failures. We describe the design of FLARe and evaluate its performance on a representative Linux testbed. Our empirical results indicate the effectiveness of our proactive <b>load-aware</b> failover strategy, which significantly reduces client response times and system utilization after failures compared to conventional strategies. 1...|$|E
40|$|In this paper, we {{analyze the}} {{performance}} of random load resampling and migration strategies in parallel server systems. Clients initially attach to an arbitrary server, but may switch servers independently at random instants of time {{in an attempt to}} improve their service rate. This approach to load balancing contrasts with traditional approaches where clients make smart server selections upon arrival (e. g., Join-the-Shortest-Queue policy and variants thereof). Load resampling is particularly relevant in scenarios where clients cannot predict the load of a server before being actually attached to it. An important example is in wireless spectrum sharing where clients try to share a set of frequency bands in a distributed manner. We first analyze the natural Random Local Search (RLS) strategy. Under this strategy, after sampling a new server randomly, clients only switch to it if their service rate is improved. In closed systems, where the client population is fixed, we derive tight estimates of the time it takes under RLS strategy to balance the load across servers. We then study open systems where clients arrive according to a random process and leave the system upon service completion. In this scenario, we analyze how client migrations within the system interact with the system dynamics induced by client arrivals and departures. We compare the <b>load-aware</b> RLS strategy to a load-oblivious strategy in which clients just randomly switch server without accounting for the server loads. Surprisingly, we show that both load-oblivious and <b>load-aware</b> strategies stabilize the system whenever this is at all possible. We further demonstrate, using large-system asymptotics, that the average client sojourn time under the load-oblivious strategy is not considerably reduced when clients apply smarter <b>load-aware</b> strategies...|$|E
30|$|We {{analyze the}} {{behavior}} of DEMON when two different state-of-the-art routing metrics are used for route discovery, ETT and WCIM, which are link quality and load aware, respectively. In most cases, WCIM obtains better results than ETT, since its load awareness leads to better route selection. However, results show that in some cases, the performance of DEMON improves by using the ETT metric for route discovery. This is an interesting feature, since the use of <b>load-aware</b> metrics can lead to network instability under highly variable network conditions. By using DEMON, the routing metric can remain load-unaware, as is ETT, while route recovery can be <b>load-aware</b> {{by means of the}} link quality estimation mechanism based on pETX. In fact, according to the obtained results, we can conclude that the route recovery mechanisms have a greater influence on the performance of the routed flows than the routing metrics used for route discovery. This is remarkable, since the state-of-the-art on preemptive and route recovery solutions is scarce compared to the wide literature on routing metrics and route discovery solutions.|$|E
40|$|In this paper, we {{analyze the}} {{performance}} of random load resampling and migration strategies in parallel server systems. Clients initially attach themselves to an arbitrary server, but may switch servers independently at random instants of time {{in an attempt to}} improve their service rate. This approach to load balancing contrasts with traditional approaches where clients make smart server selections upon arrival (e. g., Join-the-Shortest-Queue policy and variants thereof). Load resampling is particularly relevant in scenarios where clients cannot predict the load of a server before being actually attached to it. An important example is in wireless spectrum sharing where clients try to share a set of frequency bands in a distributed manner. We first analyze the natural Random Local Search (RLS) strategy. Under this strategy, after sampling a new server randomly, clients only switch to it if their service rate is improved. In closed systems, where the client population is fixed, we derive tight estimates of the time it takes under RLS strategy to balance the load across servers. We then study open systems where clients arrive according to a random process and leave the system upon service completion. In this scenario, we analyze how client migrations within the system interact with the system dynamics induced by client arrivals and departures. We compare the <b>load-aware</b> RLS strategy to a load-oblivious strategy in which clients just randomly switch server without accounting for the server loads. Surprisingly, we show that both load-oblivious and <b>load-aware</b> strategies stabilize the system whenever this is at all possible. We use large-system asymptotics to characterize system performance, and augment this with simulations, which suggest that the average client sojourn time under the load-oblivious strategy is not considerably reduced when clients apply smarter <b>load-aware</b> strategies...|$|E
40|$|Query-load (forwarding and answering) {{balancing}} in structured overlays {{is one of}} {{the most}} critical and least studied problems. It has been assumed that caching heuristics can take care of it. We expose that caching, while necessary, is not in itself sufficient. We then provide simple and effective <b>load-aware</b> variants of the standard greedy routing used in overlays, exploiting routing redundancy originally needed for fault-tolerance, to achieve very good query loadbalancing. Keywords: Query-load balancing, Structured overlays 1...|$|E
40|$|When a Mobile Ad Hoc network (MANET) is {{connected}} to the Internet, it is important for mobile nodes to detect available Internet gateway (IGW) providing access to the Internet. Gateway discovery time have strong influence on packet delay and throughput. In most of the cases, a mobile node uses min- hops to the gateway to communicate a fixed host connected to an Internet. However, a minimum hop path may not always be efficient if some nodes along the path have longer interface queue of waiting packets. Thus, the focus of the paper is to first analyse existing <b>load-aware</b> routing protocols in MANET and then based on this analysis, devise a proactive <b>load-aware</b> gateway discovery scheme that takes in to account size of interface queue in addition to the traditional min hop metric. This approach also allows an efficient handoff from one Internet gateway to another Internet gateway and still maintains a seamless connectivity to a fixed host. We examine the impact of traffic load and node mobility in terms of two metrics: throughput and average end-to-end delay to assess the performance of the proposed protocol. Simulation results indicate that our protocol outperforms existing solution...|$|E
30|$|Finally, {{note that}} {{as shown in}} Figure  13, {{the use of the}} DEMON {{extension}} and ETT as the routing metric leads generally to a higher number of route recoveries than DEMON with WCIM. Since the WCIM routing metric is <b>load-aware,</b> it takes into account interference and congestion, which provides a better route selection than ETT, for both route discovery and route recovery. For this reason, in this scenario and also in the following ones, DEMON achieves usually better performance using WCIM than with ETT.|$|E
40|$|Abstract—In {{this work}} we propose anycast routing methods {{to improve the}} {{performance}} of reconfigurable WDM networks under the variations in the IP traffic. We first investigate anycast communication via impairment-aware anycast routing (IAAR); our simulation results show significant improvement in the blocking probability. We also investigate the proposed <b>load-aware</b> anycast routing (LAAR) for the varying traffic model. From the results we observe that LAAR minimizes the lightpath request loss, by dynamically choosing the anycast configuration based on the network load. Keywords: IP-over-WDM, RWA, anycast, unicast, transmission impairments...|$|E
40|$|IP Anycast {{has many}} {{attractive}} features for any service that involve the replication of multiple instances across the Internet. IP Anycast allows multiple instances {{of the same}} service to be “naturally ” discovered, and requests for this service to be delivered to the closest instance. However, while briefly considered as an enabler for content delivery networks (CDNs) when they first emerged, IP Anycast was deemed infeasible in that environment. The main reasons for this decision were the lack of load awareness of IP Anycast and unwanted side effects of Internet routing changes on the IP Anycast mechanism. In this paper we re-evaluate IP Anycast for CDNs by proposing a <b>load-aware</b> IP Anycast CDN architecture. Our architecture is prompted by recent developments in route control technology, as well as {{better understanding of the}} behavior of IP Anycast in operational settings. Our architecture makes use of route control mechanisms to take server and network load into account to realize <b>load-aware</b> Anycast. We show that the resulting redirection requirements can be formulated as a Generalized Assignment Problem and present practical algorithms that address these requirements {{while at the same time}} limiting connection disruptions that plague regular IP Anycast. We evaluate our algorithms through trace based simulation using traces obtained from a production CDN network...|$|E
40|$|Abstract. Supporting {{uninterrupted}} {{services for}} performance-sensitive distributed applications operating in resource-constrained environments is hard. It is even harder when the operating environment is dynamic and processor or process failures and system workload changes are common. Fault-tolerant middleware for these applications must assure high service availability and satisfactory response times for clients. Although passive replication is a promising fault tolerance strategy for resourceconstrained systems, conventional passive replication solutions are nonadaptive and load-agnostic, {{which can cause}} post-recovery system overloads and significantly increase response times. This paper presents Faulttolerant <b>Load-aware</b> and Adaptive middlewaRe (FLARe), which enhances conventional passive replication schemes in three ways. First, its client failover strategy is <b>load-aware,</b> i. e., failover targets are selected at runtime based on current CPU utilizations to maintain satisfactory response times and alleviate CPU overload after failure recovery, and adaptive, i. e., failover targets are proactively adjusted in response to failures, system load fluctuations, and resource availability. Second, its client redirection strategy handles resource overloads that stem from multiple failures and workload fluctuations. Third, FLARe enables effective dissemination of failover decisions and manages CPU utilizations transparently to clients. Empirical evaluations on a distributed testbed demonstrate how FLARe efficiently uses available system resources and maintains satisfactory response times for clients when recovering from failures. ...|$|E
40|$|Because {{it is an}} {{integral}} part of the Internet routing apparatus, and because it allows multiple instances of the same service to be “naturally ” discovered, IP Anycast has many attractive features for any service that involve the replication of multiple instances across the Internet. While briefly considered as an enabler when content distribution networks (CDNs) first emerged, the use of IP Anycast was deemed infeasible in that environment. The main reasons for this decision were the lack of load awareness of IP Anycast and unwanted side effects of Internet routing changes on the IP Anycast mechanism. Prompted by recent developments in route control technology, as well as a better understanding of the behavior of IP Anycast in operational settings, we revisit this decision and propose a <b>load-aware</b> IP Anycast CDN architecture that addresses these concerns while benefiting from inherent IP Anycast features. Our architecture makes use of route control mechanisms to take server and network load into account to realize <b>load-aware</b> Anycast. We show that the resulting redirection requirements can be formulated as a Generalized Assignment Problem and present practical algorithms that address these requirements while at the same time limiting session disruptions that plague regular IP Anycast. We evaluate our algorithms through trace based simulation using traces obtained from a production CDN network...|$|E
30|$|Back-pressure {{algorithm}} {{has been}} considered as an efficient queue length-based scheduling and routing paradigm since its appearance [1]. It has attracted {{a lot of attention}} due to its remarkable advantages, e.g., throughput optimality (i.e., it can stabilize a network when the arrival rates lie within the capacity region of the network), achievable adaptive resource allocation, support to stateless and agile <b>load-aware</b> routing and scheduling, and simplicity. Recently, a lot of work (e.g., [2 - 21]) has been carried out, and much progress has been made to improve the performance of back-pressure scheduling in different network environments.|$|E
40|$|To {{scale to}} {{millions}} of Internet users with good performance, content delivery networks (CDNs) must balance requests between content servers while assigning clients to nearby servers. In this paper, we describe a new CDN design that associates synthetic <b>load-aware</b> coordinates with clients and content servers and uses them to direct content requests to cached content. This approach helps achieve good performance when request workloads and resource availability in the CDN are dynamic. A deployment and evaluation of our system on PlanetLab demonstrates how it achieves low request times with high cache hit ratios {{when compared to other}} CDN approaches. 1...|$|E
40|$|Abstract — Our propose works a <b>load-aware</b> routing {{scheme for}} {{wireless}} networks (WNs). In a WMN, the traffic load {{tends to be}} unevenly distributed over the network. In this situation, the <b>load-aware</b> routing scheme can balance the load, and consequently, enhance the overall network capacity. We design a routing scheme which maximizes the utility, i. e., the router is a primary component in the infrastructure of today’s internet and are consequently are active target for the attackers. The Load balancing is difficult due to dropping, diverting, delaying or manipulating the packets and thereby mount denial of service, surveillance or {{man in the middle}} attach. In this paper. We detect the existence of compromised routers and isolate them from the routing fabric by the degree of user satisfaction, using mobile agents call the Ant-Nets. It is a distributed mobile agent that was inspired by the works on the ant colony metaphor for solving optimization problems. In this paper, when the packets moved from one AP to another AP using default path, if any problem occur in any AP, the AntNet is solved that existence problems to transmit the another shortest path. From that we can conclude avoid the packet loss and reduce the reception time to achieve the load optimization global load balancing. We present the graphical l results showing that the proposed scheme effectively balances the traffic load and outperforms the routing forms using the expected transmission time (ETT) as a routing metric...|$|E
40|$|Abstract We {{investigate}} a wireless system of multiple cells, each having a {{downlink shared channel}} in support of high-speed packet data services. In practice, such a system consists of hierarchically organized entities including a central server, Base Stations (BSs), and Mobile Stations (MSs). Our goal is to improve global resource utilization and reduce regional congestion given asymmetric arrivals and departures of mo-bile users, a goal requiring load balancing among multiple cells. For this purpose, we propose a scalable cross-layer framework to coordinate packet-level scheduling, call-level cell-site selection and handoff, and system-level cell cover-age based on load, throughput, and channel measurements. In this framework, an opportunistic scheduling algorithm—the weighted Alpha-Rule—exploits the gain of multiuser diversity in each cell independently, trading aggregate (mean) down-link throughput for fairness and minimum rate guarantees among MSs. Each MS adapts to its channel dynamics and the load fluctuations in neighboring cells, in accordance with MSs ’ mobility or their arrival and departure, by initiating <b>load-aware</b> handoff and cell-site selection. The central server adjusts schedulers of all cells to coordinate their coverage by prompting cell breathing or distributed MS handoffs. Across the whole system, BSs and MSs constantly monitor their load, throughput, or channel quality {{in order to facilitate}} the overall system coordination. Our specific contributions in such a framework are high-lighted by the minimum-rate guaranteed weighted Alpha-Rule scheduling, the <b>load-aware</b> MS handoff/cell-site selection, and the Media Access Control (MAC) -layer cell breath-ing. Our evaluations show that the proposed framewor...|$|E
40|$|Abstract—The IEEE 802. 16 {{standard}} for wireless metropolitan area networks (WMAN) {{has been created}} to meet the need of wide-range broadband wireless access at low cost. The objective {{of this paper is}} to study how to exploit spectral reuse in an IEEE 802. 16 mesh network through timeslot allocation, bandwidth adaptation, hierarchical scheduling, and routing. To the best of our knowledge, this is the first work which formally quantifies spectral reuse in IEEE 802. 16 mesh networks and which exploits spectral efficiency under an integrated framework. Simulation results show that the proposed spectral reuse scheduling and <b>load-aware</b> routing significantly enhance the network throughput performance in IEEE 802. 16 mesh networks...|$|E
40|$|Because {{energy use}} of single-server systems {{is far from}} being energy proportional, we explore whether or not better energy {{efficiency}} may be achieved by a cluster of nodes whose size is dynamically adjusted to the current workload demand. As data-intensive workloads, we submit specific TPC-H queries against a distributed shared-nothing DBMS, where time and energy use are captured by specific monitoring and measurement devices. We configure various static clusters of varying sizes and show their influence on energy efficiency and performance. Further, using an EnergyController and a <b>load-aware</b> scheduler, we verify the hypothesis that energy proportionality can be well approximated by dynamic clusters. 1...|$|E
40|$|For {{real-time}} traffic, {{the link}} quality and call blocking probability (both derived from coverage probability) are realized {{to be poor}} for cell edge users (CEUs) compared to cell center users (CCUs) as the signal reception in the cell center region is better compared to the cell edge region. In heterogeneous networks (HetNets), the uncoordinated channel access by different types of base stations determine the interference statistics that further arbitrates the coverage probability. Thus, the spectrum allocation techniques have major impact {{on the performance of}} CCU and CEU. In this paper, the performance of CCUs and CEUs in a random two-tier network is studied for two spectrum allocation techniques namely: 1) co-channel (CSA), and 2) shared (SSA). For performance analysis, the widely accepted conception of modeling the tiers of HetNet using independent homogeneous Poisson point process (PPP) is considered to accommodate the spatial randomness in location of BSs. To incorporate the spatial randomness in the arrival of service and to aid the <b>load-aware</b> analysis, the cellular traffic is modeled using spatio-temporal PPP. Under this scenario, we have developed an analytical framework to evaluate the <b>load-aware</b> performance, including coverage and blocking probabilities, of CCUs and CEUs under both spectrum allocation techniques. Further, we provide insight into achievable area energy efficiency for SSA and CSA. The developed analytical framework is validated through extensive simulations. Next, we demonstrate the impact of traffic load and femto access points density on the performance of CCUs/CEUs under CSA and SSA. Comment: 13 pages and 11 figures. This paper is submitted to IEEE Transaction on Vehicular Technolog...|$|E
40|$|Service {{selection}} {{has been}} widely investigated by the SOA research community as an effective adaptation mechanism that allows a service broker, offering a composite service, to bind at runtime each task of the composite service to a corresponding concrete implementation, selecting it from a set of candidates which differ from one another in terms of QoS parameters. In this paper we present a <b>load-aware</b> per-request approach to service selection which aims to combine the relative benefits of the well known per-request and perflow approaches. Our service selection policy represents the core methodology of the Plan phase of a self-adaptive service oriented system based on the MAPE-K reference loop. Since the service broker operates in a variable and uncertain environment where the QoS levels negotiated with the service providers can fluctuate, it requires some mechanism to enforce the QoS constraints with its users. To this end, we also propose an algorithm for the Analyze phase of MAPE-K {{which is based on}} the adaptive Cusum algorithm and allows to determine whether a change in the QoS level requires a service selection replanning. We present experimental results obtained with a prototype implementation of a service broker. Our results show that the proposed <b>load-aware</b> approach is superior to the traditional perrequest one and combines the ability of sustaining large volume of service requests, as the perflow approach, {{while at the same time}} offering a finer customizable service selection, as the per-request approach. Furthermore, the results show that the adaptive Cusum algorithm can quickly detect changes in the execution environment and trigger a new optimization plan before the system performance degrades...|$|E
30|$|In the evaluation, two {{different}} state-of-the-art routing metrics {{are used for}} route discovery. These routing metrics are the expected transmission time metric (ETT) [25] and the weighted contention and interference routing metric (WCIM) [26]. ETT improves the link awareness of the ETX metric by {{taking into account the}} data rate of the links, thus favoring the selection of fast links with low error rates. On the other hand, WCIM is both link- and <b>load-aware,</b> and improves ETT by estimating the available bandwidth of the links. This way, we can analyze the behavior of DEMON when {{two different}} route discovery strategies are used. For a detailed performance comparison between ETT and WCIM routing metrics, the reader may refer to the literature [26].|$|E
40|$|International audienceLoad {{shedding}} is {{a technique}} employed by stream processing systems to handle unpredictable spikes in the input load whenever available computing resources are not adequately provisioned. A load shedder drops tuples to keep the input load below a critical threshold and thus avoid tuple queuing and system trashing. In this paper we propose <b>Load-Aware</b> Shedding (LAS), a novel load shedding solution that drops tuples {{with the aim of}} maintaining queuing times below a tunable threshold. Tuple execution durations are estimated at runtime using efficient sketch data structures. We provide a theoretical analysis proving that LAS is an (ε, δ) -approximation of the optimal online load shedder and show its performance through a practical evaluation based both on simulations and on a running prototype...|$|E
40|$|Computational {{resource}} {{discovery is}} of great importance in grid environments. Existing approaches do not consider the characteristics of application resource requirements. We propose, Resource Category Tree (RCT), which organizes computational resources based on their characteristics represented by primary attributes (PA). RCT adopts a structure of A VL tree, with each node representing a specific range of PA values. Though RCT adopts a hierarchical structure, {{it does not require}} nodes in higher levels maintain more information than those in lower levels, which makes RCT highly scalable. RCT is featured by self-organization, <b>load-aware</b> self-adaptation and fault tolerance. Based on RCT, commonly used queries, such as range queries and multi-attribute queries, are well supported. We conduct performance evaluations through comprehensive simulations. © 2006 IEEE...|$|E
40|$|Distributed Hash Table (DHT) overlay {{networks}} {{offer an}} efficient and robust technique for wire-area data storage and queries. Workload from real applications that use DHT networks will likely exhibit significant skews {{that can result}} in bottlenecks and failures that limit the overall scalability of the DHT approach. In this paper we present the Content and <b>Load-Aware</b> Scalable Hashing (CLASH) protocol that can enhance the load distribution behavior of a DHT. CLASH relies on a variable-length identifier key scheme, where the length of any individual key {{is a function of}} load. CLASH uses variable-length keys to cluster content-related objects on single nodes to achieve processing efficiencies, and minimally disperse objects across multiple servers when hotspots occur. We demonstrate the performance benefits of CLASH through analysis and simulation. 1...|$|E
40|$|Load {{shedding}} is {{a technique}} employed by stream process- ing systems to handle unpredictable spikes in the input load whenever available computing resources are not adequately provisioned. A load shedder drops tuples to keep the input load below a critical threshold and thus avoid tuple queuing and system trashing. In this paper we propose <b>Load-Aware</b> Shedding (LAS), a novel load shedding solution that drops tuples {{with the aim of}} maintaining queuing times below a tunable threshold. Tuple execution durations are estimated at runtime using efficient sketch data structures. We pro- vide a theoretical analysis proving that LAS is an (ε,δ) - approximation of the optimal online load shedder and show its performance through a practical evaluation based both on simulations and on a running prototype...|$|E
40|$|Resource {{discovery}} {{is of great}} importance in grid environments. Most of existing approaches treat all resources equally without any categorizing mechanism. We propose, Resource Category Tree (RCT), which organizes resources based on their characteristics represented by primary attributes (PA). RCT adopts a structure of distributed AVL tree, with each node representing a specific range of PA values. Though RCT adopts a hierarchical structure, {{it does not require}} nodes in higher levels maintain more information than those in lower levels, which makes RCT highly scalable. RCT is featured by self-organization, <b>load-aware</b> self-adaptation and fault tolerance. Based on RCT, commonly used queries, such as range queries and multi-attribute queries, are well supported. We conduct performance evaluations through comprehensive simulations. (C) 2008 Elsevier B. V. All rights reserved...|$|E
30|$|In this paper, {{we propose}} a new packet-scheduling algorithm, <b>load-aware</b> {{weighted}} round robin (LAWRR), for 802.16 {{networks in the}} downlink direction to improve upon the efficiency of WRR. Our algorithm adaptively employs dynamic weighting to adjust the weight of each queue according to the traffic characteristics and the WRR static weight. The goal {{is to reduce the}} delay and packet loss due to input burst traffic as well as to improve throughput. The algorithm is evaluated through discrete-event simulations. The performance of the proposed algorithm is compared and evaluated by means of simulations against WRR[14]. The results show that LAWRR outperforms WRR in terms of delay and packet loss as well as throughput. The effectiveness of our approach is also examined when running with finite buffer sizes, in which it again proves to be successful.|$|E
40|$|Much {{work has}} been done with the primary {{objective}} to reduce interference and increase total throughput of WLANs. Optimal AP placement schemes optimizing power level and network throughput have been proposed in [1]–[3]. Measurement based WLAN deployment schemes have been proposed in [4] and [5]. Unlike our work, these studies all assume that network administrators conduct site surveys and do propagation modeling before network deployment. In [3], the authors propose methods to identify hot spots where high traffic is expected and try to assign channels accordingly. This is a static approach, and any changes or deviation from the expected traffic pattern can lead to suboptimal channel assignment. Athanasiou et al. propose <b>Load-Aware</b> Channel Selection (LAC) [6], a distributed scheme making use of traffic information. However, this scheme cannot dynamicall...|$|E
40|$|Abstract—Router {{virtualization}} enables multiple virtual routers to be hosted on {{a physical}} shared substrate, and hence facilitates network management and experimentation. One critical issue of router virtualization is resource allocation of virtual routers. We explore {{this issue in}} the user-space design {{in order to allow}} extensibility. We develop a user-space <b>load-aware</b> virtual router monitor (LVRM) atop a commodity multi-core architecture, with a key feature that it can dynamically manage CPU core resources among virtual routers based on their traffic loads. Also, LVRM adopts an extensible design so that each component can support different variants of implemen-tation. We implement a proof-of-concept prototype for LVRM and empirically evaluate its performance overhead. Our work provides insights into resource management in user space in the context of router virtualization. Keywords-router virtualization, resource allocation, multi-core I...|$|E
40|$|Abstract- Most current routing {{protocols}} for mobile ad hoc networks consider the shortest path with minimum hop counts as the optimal route. However, the minimum end-to-end delay from source to destination {{may not always}} be achieved through this shortest path. In this paper, we propose an efficient Delay-based <b>Load-Aware</b> On-demand Routing (D-LAOR) protocol, which determines the optimal path based on the estimated total path delay and the hop count. We demonstrate the effectiveness of D-LAOR by integrating it with the Ad hoc On-demand Distance Vector (AODV) routing protocol. Simulation results, obtained using the ns- 2 network simulation platform, show that D-LAOR scheme increases packet delivery fraction and decreases end-toend delay by more than 10 % in a moderate network scenario when compared with the original AODV and other LAOR protocols. I...|$|E
