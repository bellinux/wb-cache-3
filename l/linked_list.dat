840|889|Public
5|$|Linear {{search is}} a simple search {{algorithm}} that checks every record until it finds the target value. Linear search can be done on a <b>linked</b> <b>list,</b> which allows for faster insertion and deletion than an array. Binary search is faster than linear search for sorted arrays except if the array is short. If the array must first be sorted, that cost must be amortized over any searches. Sorting the array also enables efficient approximate matches and other operations.|$|E
5|$|COBOL {{supports}} three file formats, or : sequential, indexed and relative. In sequential files, {{records are}} contiguous {{and must be}} traversed sequentially, similarly to a <b>linked</b> <b>list.</b> Indexed files have one or more indexes which allow records to be randomly accessed and which can be sorted on them. Each record must have a unique key, but other, , record keys need not be unique. Implementations of indexed files vary between vendors, although common implementations, such as C‑ISAM and VSAM, are based on IBM's ISAM. Relative files, like indexed files, have a unique record key, {{but they do not}} have alternate keys. A relative record's key is its ordinal position; for example, the 10th record has a key of 10. This means that creating a record with a key of 5 may require the creation of (empty) preceding records. Relative files also allow for both sequential and random access.|$|E
25|$|An {{unrolled}} <b>linked</b> <b>list</b> is a <b>linked</b> <b>list</b> {{in which}} each node contains an array of data values. This leads to improved cache performance, since more list elements are contiguous in memory, and reduced memory overhead, because less metadata needs to be stored for each element of the list.|$|E
25|$|Difficulties {{arise in}} <b>linked</b> <b>lists</b> {{when it comes}} to reverse traversing. For instance, singly <b>linked</b> <b>lists</b> are {{cumbersome}} to navigate backwards and while doubly <b>linked</b> <b>lists</b> are somewhat easier to read, memory is consumed in allocating space for a back-pointer.|$|R
5000|$|CDR coding, another {{technique}} for decreasing overhead and improving cache locality in <b>linked</b> <b>lists</b> similar to unrolled <b>linked</b> <b>lists.</b>|$|R
3000|$|... [l](i, j) and two link lists: the {{insignificant}} nodes <b>link</b> <b>list</b> LIN and {{the significant}} pixels <b>link</b> <b>list</b> LSP. Both Amplitude Quadtree Q [...]...|$|R
25|$|As {{with most}} choices in {{computer}} programming and design, no method {{is well suited}} to all circumstances. A <b>linked</b> <b>list</b> data structure might work well in one case, but cause problems in another. This {{is a list of}} some of the common tradeoffs involving <b>linked</b> <b>list</b> structures.|$|E
25|$|Backtracking is {{possible}} in two way <b>linked</b> <b>list.</b>|$|E
25|$|Each {{record of}} a <b>linked</b> <b>list</b> is often called an 'element' or 'node'.|$|E
25|$|On {{the other}} hand, dynamic arrays (as well as fixed-size array data structures) allow constant-time random access, while <b>linked</b> <b>lists</b> allow only {{sequential}} access to elements. Singly <b>linked</b> <b>lists,</b> in fact, {{can be easily}} traversed in only one direction. This makes <b>linked</b> <b>lists</b> unsuitable for applications where it's useful to look up an element by its index quickly, such as heapsort. Sequential access on arrays and dynamic arrays is also faster than on <b>linked</b> <b>lists</b> on many machines, because they have optimal locality of reference and thus {{make good use of}} data caching.|$|R
25|$|The {{alternatives}} {{listed above}} may be arbitrarily combined {{in almost every}} way, so one may have circular doubly <b>linked</b> <b>lists</b> without sentinels, circular singly <b>linked</b> <b>lists</b> with sentinels, etc.|$|R
2500|$|Merge sort can {{be adapted}} to operate on singly <b>linked</b> <b>lists</b> with [...] extra space. Heapsort {{can be adapted}} to operate on doubly <b>linked</b> <b>lists</b> with only [...] extra space overhead.|$|R
25|$|There {{is no need}} {{to define}} an initial size for a <b>linked</b> <b>list.</b>|$|E
25|$|Insertion and {{deletion}} node {{operations are}} easily implemented in a <b>linked</b> <b>list.</b>|$|E
25|$|Dynamic data {{structures}} such as stacks and queues can {{be implemented}} using a <b>linked</b> <b>list.</b>|$|E
25|$|Singly <b>linked</b> <b>lists</b> contain nodes {{which have}} a data field as well as 'next' field, which points to the next node in line of nodes. Operations that can be {{performed}} on singly <b>linked</b> <b>lists</b> include insertion, deletion and traversal.|$|R
3000|$|... [l](i, j) and two <b>link</b> <b>lists.</b> Therefore, more {{memory was}} {{required}} for more complex image and higher coding bit rate. These increased {{the complexity of the}} hardware. Although <b>linked</b> <b>lists</b> LIN and LSP were removed from the algorithm in reference [8], Amplitude Quadtree Q [...]...|$|R
40|$|We extend {{state-of-the-art}} lock-free <b>linked</b> <b>lists</b> {{by building}} <b>linked</b> <b>lists</b> with special care for locality of traversals. These <b>linked</b> <b>lists</b> are built of sequences of entries that reside on consecutive chunks of memory. When traversing such lists, subsequent entries typically reside {{on the same}} chunk and are thus close to each other, e. g., in same cache line or on the same virtual memory page. Such cache-conscious implementations of <b>linked</b> <b>lists</b> are frequently used in practice, but making them lock-free requires care. The basic component of this construction is a chunk of entries in the list that maintains a minimum and a maximum number of entries. This basic chunk component is an interesting tool on its own and {{may be used to}} build other lock-free data structures as well. ...|$|R
25|$|Nodes in a <b>linked</b> <b>list</b> must be read {{in order}} from the {{beginning}} as linked lists are inherently sequential access.|$|E
25|$|We {{will use}} a {{representation}} of the graph in which each vertex maintains a circular <b>linked</b> <b>list</b> of adjacent vertices, in clockwise planar order.|$|E
25|$|When {{constructing}} a <b>linked</b> <b>list,</b> one {{is faced with}} the choice of whether to store the data of the list directly in the <b>linked</b> <b>list</b> nodes, called internal storage, or merely to store {{a reference to the}} data, called external storage. Internal storage has the advantage of making access to the data more efficient, requiring less storage overall, having better locality of reference, and simplifying memory management for the list (its data is allocated and deallocated {{at the same time as}} the list nodes).|$|E
25|$|Circularly <b>linked</b> <b>lists</b> can {{be either}} singly or doubly linked.|$|R
5000|$|XOR <b>linked</b> <b>lists</b> do {{not provide}} some of the {{important}} advantages of doubly <b>linked</b> <b>lists,</b> {{such as the ability}} to delete a node from the list knowing only its address or the ability to insert a new node before or after an existing node when knowing only the address of the existing node.|$|R
5000|$|... (See {{links to}} video of sermons in External <b>Links</b> <b>listing</b> below.) ...|$|R
25|$|A <b>linked</b> <b>list</b> can be {{built by}} {{creating}} an array of these structures, and an integer variable to store the index of the first element.|$|E
25|$|A {{degenerate}} (or pathological) tree {{is where}} each parent node {{has only one}} associated child node. This means that performance-wise, the tree will behave like a <b>linked</b> <b>list</b> data structure.|$|E
25|$|Growing a large array {{when it is}} full may be {{difficult}} or impossible, whereas finding space for a new <b>linked</b> <b>list</b> node in a large, general memory pool may be easier.|$|E
40|$|<b>Linked</b> <b>lists</b> {{consist of}} <b>linked</b> nodes. •  Each node {{is a simple}} container, holding some piece of data, which has links(references) {{to one or more}} other nodes. •  There are many {{varieties}} of <b>linked</b> <b>lists.</b> o Forward <b>links</b> o Backward and forward links o Multiple successors o “dummy ” nodes o Circular links o...|$|R
50|$|Compared to <b>linked</b> <b>lists,</b> dynamic arrays have faster {{indexing}} (constant time versus linear time) {{and typically}} faster iteration due to improved locality of reference; however, dynamic arrays require linear time to insert or delete at an arbitrary location, since all following elements must be moved, while <b>linked</b> <b>lists</b> {{can do this}} in constant time. This disadvantage is mitigated by the gap buffer and tiered vector variants discussed under Variants below. Also, in a highly fragmented memory region, it may be expensive or impossible to find contiguous space for a large dynamic array, whereas <b>linked</b> <b>lists</b> do not require the whole data structure to be stored contiguously.|$|R
5000|$|Follow each {{intersection}} clockwise {{around the}} <b>linked</b> <b>lists</b> until the start position is found.|$|R
25|$|The <b>linked</b> <b>list</b> is relocatable, {{meaning it}} can be moved about in memory at will, and {{it can also be}} quickly and {{directly}} serialized for storage on disk or transfer over a network.|$|E
25|$|A {{good example}} that {{highlights}} {{the pros and}} cons of using dynamic arrays vs. linked lists is by implementing a program that resolves the Josephus problem. The Josephus problem is an election method that works by having a group of people stand in a circle. Starting at a predetermined person, you count around the circle n times. Once you reach the nth person, take them out of the circle and have the members close the circle. Then count around the circle the same n times and repeat the process, until only one person is left. That person wins the election. This shows the strengths and weaknesses of a <b>linked</b> <b>list</b> vs. a dynamic array, because if you view the people as connected nodes in a circular <b>linked</b> <b>list</b> then it shows how easily the <b>linked</b> <b>list</b> is able to delete nodes (as it only has to rearrange the links to the different nodes). However, the <b>linked</b> <b>list</b> will be poor at finding the next person to remove and will need to search through the list until it finds that person. A dynamic array, on the other hand, will be poor at deleting nodes (or elements) as it cannot remove one node without individually shifting all the elements up the list by one. However, it is exceptionally easy to find the nth person in the circle by directly referencing them by their position in the array.|$|E
25|$|A <b>linked</b> <b>list</b> whose nodes contain two fields: {{an integer}} value and {{a link to}} the next node. The last node is linked to a {{terminator}} used to signify the end of the list.|$|E
5000|$|The {{two images}} are now {{organized}} in hierarchy of <b>linked</b> <b>lists</b> in following structure : ...|$|R
2500|$|Quicksort also {{competes with}} mergesort, another [...] sorting algorithm. Mergesort is a stable sort, unlike {{standard}} in-place quicksort and heapsort, {{and can be}} easily adapted to operate on <b>linked</b> <b>lists</b> and very large lists stored on slow-to-access media such as disk storage or network attached storage. Although quicksort can be implemented as a stable sort using <b>linked</b> <b>lists,</b> it will often suffer from poor pivot choices without random access. The main disadvantage of mergesort is that, when operating on arrays, efficient implementations require O(n) auxiliary space, whereas the variant of quicksort with in-place partitioning and tail recursion uses only [...] space. (Note that when operating on <b>linked</b> <b>lists,</b> mergesort only requires a small, constant amount of auxiliary storage.) ...|$|R
25|$|NOTE: All {{initials}} {{used are}} {{the same in the}} official NCAA Bracket in External <b>Links</b> <b>listed</b> below.|$|R
