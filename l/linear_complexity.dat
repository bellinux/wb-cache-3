1252|1197|Public
25|$|In {{computer}} graphics bubble sort is popular for its capability {{to detect a}} very small error (like swap of just two elements) in almost-sorted arrays and fix it with just <b>linear</b> <b>complexity</b> (2n). For example, it is used in a polygon filling algorithm, where bounding lines are sorted by their x coordinate at a specific scan line (a line parallel to the x axis) and with incrementing y their order changes (two elements are swapped) only at intersections of two lines. Bubble sort is a stable sort algorithm, like insertion sort.|$|E
5000|$|Several {{of these}} tests, which are of <b>linear</b> <b>complexity,</b> provide {{spectral}} measures of randomness. T. Beth and Z-D. Dai showed that Kolmogorov complexity and <b>linear</b> <b>complexity</b> are practically the same. [...] However, the proofs by Beth and Dai are incorrect as shown inY. Wang. On the other hand, Y. Wang showed that for Martin-Löf random sequences, the Kolmogorov complexity {{is essentially the}} same as <b>linear</b> <b>complexity.</b>|$|E
50|$|Böhm's parsing {{technique}} for expressions had only <b>linear</b> <b>complexity.</b> It generated instructions to a structure {{similar to a}} binary tree.|$|E
40|$|AbstractBased on single cycle T-functions over Z/(2 n), {{two classes}} of {{pseudorandom}} sequences are proposed in this paper. The periods of all their coordinate sequences can reach the maximal value 2 n, and the distribution properties and <b>linear</b> <b>complexities</b> of the sequences are also studied. For the first class of sequences, it is shown that the less significant half of the coordinate sequences are uniformly distributed over F 2 and the exact <b>linear</b> <b>complexities</b> are also derived. For the second class of sequences, lower bounds on the <b>linear</b> <b>complexities</b> of their coordinate sequences are given...|$|R
40|$|We {{report on}} the results of {{computations}} concerning the <b>linear</b> <b>complexities</b> of the NLFSRs deployed in Achterbahn’s keystream generator. We outline a probabilistic algorithm for estimating the <b>linear</b> <b>complexities</b> of binary sequences of period 2 N − 1. We define Achterbahn-Version 2 whose keystream generator consists of ten shift registers. We introduce the new combining function. We discuss recent cryptanalysis results against Achterbahn-Version 1. The last part of the paper is concerned with hardware optimization of the feedback functions of the deployed nonlinear primitive shift registers...|$|R
40|$|AbstractWe give a {{complete}} resolution to a conjecture regarding the characterisation of <b>linear</b> <b>complexities</b> of span 1 de Bruijn sequences over nonprime finite fields. This contrasts with results for prime fields, where the characterisation {{is equivalent to}} an open question concerning permutation polynomials...|$|R
5000|$|One natural {{measure of}} how useful a {{sequence}} may be for cryptographic purposes {{is the size of}} its <b>linear</b> <b>complexity.</b> The <b>linear</b> <b>complexity</b> of an n-element sequence W(x), x = 0,1,2,…,n - 1, over a ring [...] is the length l of the shortest linear recurrence relation W(x + l) = Al−1 W(x +l−1) + … + A0 W(x), x = 0,1,2,…, n - l −1 with A0, …, Al−1 ∈ , which is satisfied by this sequence.|$|E
5000|$|There exists an {{algorithm}} [...] {{which allows}} designing compound generators with predictable period length, predictable <b>linear</b> <b>complexity</b> level, with excellent statistical properties of produced bit streams.|$|E
5000|$|For some [...] > 0,n ≥ (1+ [...] ) , for any , {{sufficiently}} large l, the <b>linear</b> <b>complexity</b> of {{the sequence}} ,0 ≤ x ≤ 2n-1, denoted by [...] satisfies ...|$|E
40|$|Abstract — This paper {{reports the}} {{efficient}} design of Pseudo-Random Pattern Generator () with <b>linear</b> time <b>complexity.</b> The PRPG is developed around the regular structure of non-linear Cellular Automata (). The application of proposed is demonstrated in designing on-chip Test Pattern Generator () for VLSI circuits. The {{quality of the}} {{is as good as}} that designed with the existing schemes, employing maximal length <b>linear</b> incurring <b>complexity.</b> I...|$|R
40|$|Cross-correlation {{functions}} are determined {{for a large}} class of geometric sequences based on m-sequences in characteristic two. These sequences are shown to have low cross-correlation values in certain cases. They are also shown to have signi cantly higher <b>linear</b> <b>complexities</b> than previously studied geometric sequences. These results show that geometric sequences are candidates for use in spread-spectrum communications systems in which cryptographic security is a factor...|$|R
30|$|The {{algorithm}} CFD(BS_G(o)) incurs only <b>linear</b> time <b>complexity,</b> {{which is}} relatively efficient compared to some others in literature.|$|R
50|$|In their paper, Meier and Steffelbach {{prove that}} a LFSR based self-shrinking {{generator}} with a connection polynomial of length L {{results in an}} output sequence period of at least 2L/2, and a <b>linear</b> <b>complexity</b> of at least 2L/2-1.|$|E
50|$|Customarily, the LFSRs use {{primitive}} polynomials {{of distinct}} but close degree, preset to non-zero state, {{so that each}} LFSR generates a maximum length sequence. Under these assumptions, the ASG's output demonstrably has long period, high <b>linear</b> <b>complexity,</b> and even distribution of short subsequences.|$|E
50|$|It passes most, but not all, of the {{stringent}} TestU01 randomness tests. Because it {{is based}} on simple linear (xor) operations, it fails tests based on <b>linear</b> <b>complexity</b> after relatively few bits of output, despite its extremely large state. Passing the output through a simple hash function can remedy this weakness.|$|E
40|$|We {{show that}} the Blokh-Zyablov error {{exponent}} can be arbitrarily approached by concatenated block codes over general discrete-time memoryless channels with <b>linear</b> encoding/decoding <b>complexity</b> in the block length. The key result is an extension to Justesen’s general minimum distance decoding algorithm, which enables a low complexity integration of Guruswami-Indyk’s outer code into Forney’s and Blokh-Zyablov’s concatenated coding schemes. Index Terms Blokh-Zyablov error exponent, concatenated code, <b>linear</b> coding <b>complexity</b> I...|$|R
40|$|In {{this paper}} two {{algorithms}} for register allocation are presented. The first algorithm is a simulated annealing algorithm. The {{core of the}} algorithm is the Metropolis procedure. The algorithm presented in the paper has a <b>linear</b> time asymptotic <b>complexity.</b> The second algorithm is a genetic algorithm. The algorithm has a <b>linear</b> time <b>complexity...</b>|$|R
40|$|Abstract. Assuming the Gowers Inverse {{conjecture}} and the Möbius conjecture for {{the finite}} parameter s, Green-Tao verified Dickson’s conjecture for lattices which are ranges of <b>linear</b> maps of <b>complexity</b> at most s. In this paper, we reformulate Green-Tao’s theorem on Dickson’s conjecture, and prove that, if L is {{the range of}} a <b>linear</b> map of <b>complexity</b> s, and L 1 is a sublattice of L of finite index, then L 1 is the range of a <b>linear</b> map of <b>complexity</b> s. 1...|$|R
50|$|In 1985 Day gave an {{algorithm}} {{based on}} perfect hashing that computes this distance that {{has only a}} <b>linear</b> <b>complexity</b> {{in the number of}} nodes in the trees. A randomized algorithm that uses hash tables that are not necessarily perfect has been shown to approximate the Robinson-Foulds distance with a bounded error in sublinear time.|$|E
50|$|Introsort {{was invented}} by David Musser in , in which he also {{introduced}} introselect, a hybrid selection algorithm based on quickselect (a variant of quicksort), which falls back to median of medians and thus provides worst-case <b>linear</b> <b>complexity,</b> which is optimal. Both algorithms were introduced {{with the purpose of}} providing generic algorithms for the C++ Standard Library which had both fast average performance and optimal worst-case performance, thus allowing the performance requirements to be tightened.|$|E
5000|$|Like DBSCAN, OPTICS {{processes}} {{each point}} once, and performs one -neighborhood query during this processing. Given a spatial index that grants a neighborhood query in [...] runtime, an overall runtime of [...] is obtained. The {{authors of the}} original OPTICS paper report an actual constant slowdown factor of 1.6 compared to DBSCAN. Note {{that the value of}} [...] might heavily influence the cost of the algorithm, since a value too large might raise the cost of a neighborhood query to <b>linear</b> <b>complexity.</b>|$|E
40|$|We use {{polynomial}} quotients modulo an odd prime p, {{which are}} generalized from the Fermat quotients, to define two families of d(≥ 2) -ary sequences of period p 2. If d is a primitive element modulo p 2, we determine the minimal characteristic polynomials of the sequences and hence their <b>linear</b> <b>complexities,</b> which {{depend on whether}} p 1 or 3 (mod 4). Moreover, we generalize the result to the polynomial quotients modulo a power of p. © 2011 Elsevier B. V. All rights reserved...|$|R
40|$|Assuming the Gowers Inverse {{conjecture}} and the Möbius conjecture for {{the finite}} parameter s, Green-Tao verified Dickson's conjecture for lattices which are ranges of <b>linear</b> maps of <b>complexity</b> at most s. In this paper, we reformulate Green-Tao's theorem on Dickson's conjecture, and prove that, if L is {{the range of}} a <b>linear</b> map of <b>complexity</b> s, and L_ 1 is a sublattice of L of finite index, then L_ 1 is the range of a <b>linear</b> map of <b>complexity</b> s. Comment: Revised on Jan. 5, 200...|$|R
40|$|Binary {{sequences}} with optimal autocorrelation {{are needed}} in many applications. Two constructions of binary sequences with optimal autocorrelation of period N ≡ 0 (mod 4) are investigated. The two constructions are powerful and generic {{in the sense that}} many classes of binary sequences with optimal autocorrelation could be obtained from binary sequences with ideal autocorrelation. General results on the minimal polynomials of these binary sequences are derived. Based on the results, both the <b>linear</b> <b>complexities</b> and the minimal polynomials are determined. © 2006 IEEE...|$|R
50|$|In {{computer}} graphics bubble sort is popular for its capability {{to detect a}} very small error (like swap of just two elements) in almost-sorted arrays and fix it with just <b>linear</b> <b>complexity</b> (2n). For example, it is used in a polygon filling algorithm, where bounding lines are sorted by their x coordinate at a specific scan line (a line parallel to the x axis) and with incrementing y their order changes (two elements are swapped) only at intersections of two lines. Bubble sort is a stable sort algorithm, like insertion sort.|$|E
5000|$|In the paper, [...] "A {{weakness}} of the linear part of stream cipher MUGI", by Golic Jovan Dj, Roy Bimal and Meier Willi, the abstract claims: [...] "The linearly updated component of the stream cipher MUGI, called the buffer, is analyzed theoretically by using the generating function method. In particular, it is proven that the intrinsic response of the buffer, without the feedback from the nonlinearly updated component, consists of binary linear recurring sequences with small <b>linear</b> <b>complexity</b> 32 and with extremely small period 48. It is then shown how this weakness can in principle be used to facilitate the linear cryptanalysis of MUGI with two main objectives: to reconstruct the secret key and to find linear statistical distinguishers." ...|$|E
5000|$|There are {{efficient}} algorithms for FCSR synthesis. This is the problem: given a prefix of a sequence, {{construct a}} minimal length FCSR that outputs the sequence. This {{can be solved}} with a variant of Mahler and De Weger's lattice based analysis of N-adic numbers when by {{a variant of the}} Euclidean algorithm when N is prime; and in general by Xu's adaptation of the Berlekamp-Massey algorithm. [...] If L is the size of the smallest FCSR that outputs the sequence (called the N-adic complexity of the sequence), then all these algorithms require a prefix of length about [...] to be successful and have quadratic time complexity. It follows that, as with LFSRs and <b>linear</b> <b>complexity,</b> any stream cipher whose N-adic complexity is low should not be used for cryptography.|$|E
40|$|Guruswami and Indyk {{showed in}} [1] that Forney's error {{exponent}} {{can be achieved}} with <b>linear</b> coding <b>complexity</b> over binary symmetric channels. This paper extends this conclusion to general discrete-time memoryless channels and shows that Forney's and Blokh-Zyablov error exponents can be arbitrarily approached by one-level and multi-level concatenated codes with <b>linear</b> encoding/decoding <b>complexity.</b> The key result is a revision to Forney's general minimum distance decoding algorithm, which enables a low complexity integration of Guruswami-Indyk's outer codes into the concatenated coding schemes. Comment: Submitted to IEEE Communications Letter...|$|R
3000|$|... {{even though}} this is not ML decoding. We {{consider}} this decoding rule to ensure <b>linear</b> decoding <b>complexity</b> and show that COSTBCs achieve maximum diversity gain with this rule.|$|R
40|$|Abstract — In {{this paper}} we study {{families}} of generalized geometric sequences formed by applying a feedforward function to certain sums of decimated m-sequences with {{elements in a}} finite field. We compute their correlation functions, which for certain families {{turn out to be}} close to the square root of the period. The size of these families equals their period. We also show that in the binary case the <b>linear</b> <b>complexities</b> of these sequences are much larger than those of cascaded geometric sequences, although in these cases the maximum correlations are larger...|$|R
50|$|Pyramid match kernel is a fast {{algorithm}} (<b>linear</b> <b>complexity</b> {{instead of}} classic one in quadratic complexity) kernel function (satisfying Mercer's condition) which maps the BoW features, {{or set of}} features in high dimension, to multi-dimensional multi-resolution histograms. An advantage of these multi-resolution histograms is their ability to capture co-occurring features. The pyramid match kernel builds multi-resolution histograms by binning data points into discrete regions of increasing size. Thus, points that do not match at high resolutions {{have the chance to}} match at low resolutions. The pyramid match kernel performs an approximate similarity match, without explicit search or computation of distance. Instead, it intersects the histograms to approximate the optimal match. Accordingly, the computation time is only linear in the number of features. Compared with other kernel approaches, the pyramid match kernel is much faster, yet provides equivalent accuracy. The pyramid match kernel was applied to ETH-80 database and Caltech 101 database with promising results.|$|E
50|$|Runtime verification, if used in {{combination}} with provably correct recovery code, can provide an invaluable infrastructure for program verification, which can significantly lower the latter's complexity. For example, formally verifying heap-sort algorithm is very challenging. One less challenging technique to verify it is to monitor its output to be sorted (a <b>linear</b> <b>complexity</b> monitor) and, if not sorted, then sort it using some easily verifiable procedure, say insertion sort. The resulting sorting program is now more easily verifiable, the only thing being required from heap-sort {{is that it does}} not destroy the original elements regarded as a multiset, which is much easier to prove. Looking at from the other direction, one can use formal verification to reduce the overhead of runtime verification, as already mentioned above for static analysis instead of formal verification. Indeed, one can start with a fully runtime verified, but probably slow program. Then one can use formal verification (or static analysis) to discharge monitors, same way a compiler uses static analysis to discharge runtime checks of type correctness or memory safety.|$|E
5000|$|The page {{segmented}} version {{implemented by}} the authors has the same O(N) operations but reduces the memory requirement to just that required by the base primes below the square root {{of the range of}} O(N1/2/log N) bits of memory plus a minimal page buffer. This is slightly better performance with the same memory requirement as the page segmented sieve of Eratosthenes which uses O(N log log N) operations and the same O(N1/2/log N) bits of memory plus a minimal page buffer. However, such a sieve does not outperform a Sieve of Eratosthenes with maximum practical wheel factorization (a combination of a 2/3/5/7 sieving wheel and pre-culling composites in the segment page buffers using a 2/3/5/7/11/13/17/19 pattern), which although it has slightly more operations than the Sieve of Atkin for very large but practical ranges, has a constant factor of less complexity per operation by about three times in comparing the per operation time between the algorithms implemented by Bernstein in CPU clock cycles per operation. The main problem with the Page Segmented Sieve of Atkin is the difficulty in implementing the [...] "prime square free" [...] culling sequences due to the span between culls rapidly growing far beyond the page buffer span; the time expended for this operation in Bernstein's implementation rapidly grows to many times the time expended in the actual quadratic equation calculations, meaning that the <b>linear</b> <b>complexity</b> of the part that would otherwise be quite negligible becomes a major consumer of execution time. Thus, even though an optimized implementation may again settle to a O(n) time complexity, this constant factor of increased time per operations means that the Sieve of Atkin is slower.|$|E
40|$|Abstract—Guruswami and Indyk {{showed in}} [1] that Forney’s error {{exponent}} {{can be achieved}} with <b>linear</b> coding <b>complexity</b> over binary symmetric channels. This paper extends this conclusion to general discretetime memoryless channels and shows that Forney’s and Blokh-Zyablov error exponents can be arbitrarily approached by one-level and multi-level concatenated codes with <b>linear</b> encoding/decoding <b>complexity.</b> The key result is a revision to Forney’s general minimum distance decoding algorithm, which enables a low complexity integration of Guruswami-Indyk’s outer codes into the concatenated coding schemes. Index Terms — coding complexity, concatenated code, error exponent I...|$|R
40|$|Abstract. In this paper, {{we discuss}} some methods of {{constructing}} frequency/time hopping (FH/TH) sequences over GF (pk) by taking suc-cessive k-tuples of given sequences over GF (p). We {{are able to}} character-ize those p-ary sequences whose k-tuple versions now over GF (pk) have the maximum possible <b>linear</b> <b>complexities</b> (LCs). Next, we consider the FH/TH sequence generators composed of a combinatorial function gen-erator and some buffers. We are able to characterize the generators whose output FH/TH sequences over GF (pk) have the maximum possible LC for the given algebraic normal form. ...|$|R
40|$|Abstract. Nonlinear n-stage {{feedback}} shift-register sequences {{over the}} finite field Fq of period q n − 1 are investigated under linear operations on sequences. We prove that {{all members of}} an easily described class of linear combinations of shifted versions of these sequences possess useful properties for cryptographic applications: large periods, large <b>linear</b> <b>complexities</b> and good distribution properties. They typically also have good maximum order complexity values as has been observed experimentally. A running key generator is introduced based on certain nonlinear feedback shift registers with modifiable linear feedforward output functions. ...|$|R
