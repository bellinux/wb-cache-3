11|10|Public
5000|$|Protective device {{coordination}} is {{the process}} of determining the [...] "best fit" [...] timing of current interruption when abnormal electrical conditions occur. The goal is to minimize an outage to the greatest extent possible. Historically, protective device coordination was done on translucent <b>log-log</b> <b>paper.</b> Modern methods normally include detailed computer based analysis and reporting.|$|E
40|$|It is very {{significant}} to estimate a probable maximum discharge of a flood, which willoccur in the specified river basin, in the sence of prevention of water hazards. Manyformula {{of the specific}} discharge of flood peak have been proposed {{but most of them}} areobtained empirically after plotting observed flood peaks against drainage area on a graphpaper. This paper describes the occurrence condition of flood peak in relation to rainfallpattern and system of stream net, and the curve on a <b>log-log</b> <b>paper,</b> which will give theprobable maximum specific discharge of flood peak because this curve is derived from thepast records of extremely large and heavy rainfalls...|$|E
40|$|Multifractal {{modeling}} of geochemical map data {{can help to}} explain the nature of frequency distributions of element concentration values for small rock samples and their spatial covariance structure. Useful frequency distribution models are the lognormal and Pareto distributions which plot as straight lines on logarithmic probability and <b>log-log</b> <b>paper,</b> respectively. The model of de Wijs is a simple multiplicative cascade resulting in discrete logbinomial distribution that closely approximates the lognormal. In this model, smaller blocks resulting from dividing larger blocks into parts have concentration values with constant ratios that are scale-independent. The approach can be modified by adopting random variables for these ratios. Other modifications include a single cascade model with ratio parameters that depend on magnitude of concentration value. The Turcotte model, which is another variant of the model of de Wijs, results in a Pareto distribution. Often a single straight line on logarithmic probability or <b>log-log</b> <b>paper</b> {{does not provide a}} good fit to observed data and two or more distributions should be fitted. For example, geochemical background and anomalies (extremely high values) have separate frequency distributions for concentration values and for local singularity coefficients. Mixtures of distributions can be simulated by adding the results of separate cascade models. Regardless of properties of background, an unbiased estimate can be obtained of the parameter of the Pareto distribution characterizing anomalies in the upper tail of the element concentration frequency distribution or lower tail of the local singularity distribution. Computer simulation experiments and practical examples are used to illustrate the approach...|$|E
5000|$|<b>Log-log</b> ruled <b>paper</b> {{is similar}} to semi-log ruled except that both the {{horizontal}} and vertical lines are spaced logarithmically.|$|R
50|$|A stream will {{typically}} {{transition from}} section control at lower gauge heights to channel control at higher gauge heights. The transition from section control to channel control {{can often be}} inferred by {{a change in the}} slope of a rating curve when plotted on <b>log-log</b> graph <b>paper.</b>|$|R
40|$|We {{describe}} {{the measurement of}} rheumatoid factor in human sera with a rate nephelometer. The National Ref-erence Preparation for Rheumatoid Factors is used to calibrate the assay in International Units. We used Hyland Positive Control, Level I, as a secondary standard. The standard curve is exponential, but is linear when plotted on <b>log-log</b> graph <b>paper.</b> Aggregated immune globulin (lgG) isthe antigenused to detect rheumatoid factor (1 gM-class antibodyto lgG). The rate reaction measures {{the rate of increase}} in light-scatter by the antigen-antibody com-plexes; the reaction takes place in 17 to 20 s. Precision, linearity, and accuracy are excellent. Results agree well with those for a commonly used latex precipitation test. The advantages of speed, quantification in International Units, and superior discrimination of concentration a...|$|R
40|$|Specimens of Mylar sheet {{were exposed}} to a 20 kV {{electron}} beam. The resulting surface discharge arcs were photographed and the discharge current into a metal backing plate measured {{as a function of}} time. The area of the Mylar sheet was defined by a round aperture in a close-fitting metal mask, and the current pulse characteristics were plotted against area on <b>log-log</b> <b>paper.</b> The plots appear as straight lines (due to power-law behavior) with slopes of 0. 50 for the peak current, 1. 00 for the charge released, 1. 49 for the energy and 0. 55 for the pulse duration. Evidence is presented for the occurrence of banded charge distributions near grounded edges, on both Teflon and Mylar...|$|E
40|$|Observation {{was made}} on the vortex rings {{produced}} by ejecting dyed water into transparent water from a circular orifice of a glass tube of 0. 75 cm in diameter. The translational velocity of the ring at the eight-diameter distance (6. 0 cm) {{was used for the}} calculation of the Reynolds number. First, the graphs of the translational velocity vs. distance traveled by the ring plotted on semi -log paper indicate that in the later stage of the motion there exists an exponential type of dependence of the velocity on the distance, v" - exp (- k y), the value of k depending on the Reynolds number, with k decreasing as the Reynolds number increases. Next, from the relation between the velocity and time elapsed plotted on <b>log-log</b> <b>paper,</b> it is found that when the power law approximation, v - t ^, is adopted for the later part of the motion, the value of bapproximately equals to 1 for each ring regardless the Reynolds number. Finally, our result suggeststs a linear relationship between the maximum distance traveled by the ring before its breakdown and the Reynolds number...|$|E
40|$|Ephemeral {{gully erosion}} in {{cultivated}} land {{is an important}} source of sediment that is frequently being overlooked and not accounted for in soil erosion studies. Furthermore, {{little is known about the}} factors controlling ephemeral gully erosion. In this paper the available information on the initiation and location of (ephemeral) gullies is summarised, focusing on the relationship between the upslope drainage area (A) and the critical slope gradient (S-cr) for ephemeral gully initiation. By plotting the non-linear relationship between critical slope gradient (measured immediately upstream of the incision head) and drainage area (at the incision head) for gullied sites it was possible to draw a straight line on <b>log-log</b> <b>paper</b> through the lower-most points for each of the available datasets, representing a critical slope-area relationship for incision. Consequently, below this line no incision occurs. This line or critical relation can also be written as a power function between critical slope and area. Although many factors vary between the different datasets, the exponent of the drainage area relationship (- 0. 4) showed very little variation. The observed critical slope-area relationship can be related to a simple model of channel initiation by overland flow. Furthermore, this relationship can be used to identify potentially unstable sites where control measures should be undertaken. status: publishe...|$|E
40|$|This {{activity}} uses logarithmic {{plotting to}} show {{the power of a}} straight line in mathematics, science, and engineering. Students will use the slopes of various curves plotted on <b>log-log</b> graph <b>paper</b> to classify stellar objects as binary stars, supernovae, or active galaxies. The data used in this lesson were obtained from X-ray astronomy satellites. It provides an opportunity for students to apply the knowledge of plotting data and obtaining a slope using a log-log coordinate system, determine the line of best fit from a set of data obtained from X-ray astronomy satellites, and discover the relationship between slope and the classification of stellar objects. By displaying the data in a graphic, the relationship of the dependent variable on the independent variable can be seen. The most powerful form of display is when the result is a straight line - which can always be converted quickly into a mathematical equation. This lesson will use both rectangular and logarithmic graphs. Educational levels: High school, Undergraduate lower division...|$|R
40|$|Using x as the {{independent}} variable, draw one graph plotting: x vs A, x vs B, and x vs C. For each plot, connect the corresponding points with a smooth, best fit line or curve. (One graph of a data set by each person in your group is sufficient for now.) The mental power of a linear relationship is our ability {{to use it to}} predict behaviors that we have not measured! So far we have used Cartesian (named for French mathematician René Descartes) graphs (see lab # 3). Most of our labs have consisted of taking data, plotting the data on a Cartesian graph, and then finding the mathematical relationship between the variables by finding the slope and the starting value from the graph. However, not all graphs produce straight lines! The curves at the right are drawn from relationships between y and x called power laws. The general equation would look like y = Axm where A and m have numerical values. On Cartesian graph paper we can only make guesses at A and m. To find them we need to use <b>log-log</b> graph <b>paper...</b>|$|R
40|$|Tutorialpg. 149 - 158 The use of {{statistical}} techniques to investigate machinery failure data {{is one of}} the most powerful troubleshooting tools available to the turbomachinery engineer. This analysis tool can provide a great deal of information and insight concerning causes of failures and the probability of future ones. Using a graphical technique known as a hazard analysis or Weibull analysis, failure data of the type commonly available in the field can be analyzed to determine failure modes, the mean time to failure, the effects of different failure modes and the probability of future failure. The graphical procedure described in this paper is very simple to use, and requires only elementary math. The technique uses such readily available parameters as running hr or installed time of the subject under investigation and can easily handle incomplete or censored data. The method used to construct and interpret a hazard, or Wei bull chart, using either special Wei bull <b>paper</b> or simple <b>log-log</b> graph <b>paper</b> is presented. A simple fictitious example is used to illustrate the method. Eight case histories are then presented to illustrate the procedure and show the many ways that the analysis can be applied to machinery problems...|$|R
40|$|It {{is common}} {{practice}} in atmospheric corrosion to fit the power-law function as a 'model' to help predict longer term corrosion loss or maximum pit depth. This function {{is also known as}} the 'log-log model' since it plots as a straight line on <b>log-log</b> <b>paper.</b> It used extensively including for aluminium alloys. A review of the relatively few data sets for long-term corrosion of aluminium shows systematic variation from the log-log power law model. Instead, in many cases the data can be interpreted as consistent with the multi-phase model previously proposed for steel corrosion in marine exposure conditions. Consideration is given to why the multi-phase model appears to be applicable also to long-term corrosion of aluminium alloys. This includes the important effect of corrosion products on oxygen diffusion, even though corrosion products of aluminium tend to occur in localized areas, that almost always involves pitting rather than general or uniform corrosion. It is proposed that the build-up of corrosion products forces a change to the chemical reactions responsible for aluminium corrosion, specifically forcing a change from cathodic oxidation and polarization in the shorter term to cathodic hydrogen reduction and polarization in the longer-term. The greater possible rate of outward diffusion of hydrogen compared to inward diffusion of oxygen is primarily responsible for the bi-modal character of corrosion loss or maximum pit depth as a function of exposure time...|$|E
40|$|The lung {{has been}} satisfactorily {{modelled}} as a fractal, {{and change in}} lung structure due to disease is assumed to change the fractal dimensionality of the lung. It is hypothesized that those changes in fractal dimension affect perceptually relevant elements (perceived texture) of the lung, and therefore the fractal dimension {{may prove to be}} a predictor of diagnosis. If the fractal dimensionality reflects structure in ways more accurately reflecting changes in lung structure than can be achieved by nuclear medicine physicians, then it may also prove useful as a diagnostic tool. Fractal dimension is linearly related to the slope of the power spectrum (SPS) as plotted on <b>log-log</b> <b>paper,</b> and the SPS was used as the metric reflecting the fractal dimension. Seventy-two cases were selected that were either normal, had congestive heart failure (CHF), chronic obstructive pulmonary disease (COPD), or pulmonary embolism (PE). Five of the cases had both CHF and COPD. The lung scans from these cases were digitized, with appropriate corrections for linearization, edge artifacts, target nonuniformities and film gamma. Fast Fourier Transforms provided the power spectrum from which the SPS was calculated. Four nuclear medicine physicians read the original lung scans and rated their certainty about the presence of two texture elements, the extensiveness of disease involvement, and presence of the three diseases used (CHF, COPD, and PE). The results found the SPS to be significantly related to both texture ratings and diagnostic certainty, but inferior as a predictor of disease to either texture rating or diagnostic certainty. This study reveals the SPS to be a promising but incomplete candidate for machine-algorithm generated diagnosis...|$|E
40|$|This study {{consists}} of collecting and analyzing experimental data {{to determine the}} Darcy-Weisbach friction factor for 6 -inch and 4 -inch PERMASTRAN® pipes and the head losses due to RING-TITE filament-wound 6 -inch 90 ° elbows, a 6 x 6 -inch tee under several modes of operation, and a 6 x 6 x 4 -inch tee with the flow entering a 6 -inch branch and leaving through the 4 -inch branch. The test program consisted of 8 series of individual tests with each series giving data for flow rates for each series ranging from 150 gpm to either 1200 gpm or 1500 gpm depending upon the series. The analyses of data to determine the friction factors head losses in both the 6 -inch and 4 -inch PERMASTRAN® pipe indicate that the values fall on a hydraulically smooth curve of the Moody diagram for the range of Reynolds numbers tested. The same friction factors exist for the PVC pipe used in the tests because each has the same polyvinylchloride inside wall material. Head losses for these 6 -inch and 4 -inch pipes over a range of Reynolds numbers are given in Table 8. The coefficient of head loss due to the 6 -inch RING-TITE filament-wound 90 ° elbow equals 0. 5 and this value is constant over the range of Reynolds numbers of the tests. The average coefficient of head loss caused by the 6 x 6 x 6 -inch RING-TITE filament-wound tee when operating as a 90 ° elbow (i. e. with the pipe in one “straight through” branch plugged) equal 1. 5 with slightly larger values at smaller Reynolds numbers. The average coefficient of head loss caused by the 6 x 6 x 4 -inch RING-TITE filament-wound tee when operating in this same mode (flow leaving through 4 -inch branch) equals 1. 6 when based on the velocity head in the 4 -inch pipe and 6. 9 when based on the velocity head in the 6 -inch pipe. The head losses in the 6 x 6 x 6 -inch tee were also measured with the tee operating to separate the flow coming {{into one of the}} “straight through” branches into two outflows. The head loss coefficients which measure the head loss between the two “straight through” branches plot against Reynolds number as a straight line on <b>log-log</b> <b>paper.</b> The head loss coefficients which measure the head loss between the “straight through: inlet and the branch 90 ° therefrom are larger than the previous coefficients and tend toward constant values at the higher Reynolds number of the tests. A summary of these head loss coefficients is given on Fig. 15. In addition the head losses in the 6 x 6 x 6 -inch tee were measured with the flow coming into two branches of the tee and being combined into a single outflow from one branch. The combined outflow was passes through one of the “straight through: branches with the inflows coming into the other “straight through” branch and the branch at 90 ° therefrom. In this mode of operation the tee becomes a simple two branch manifold. The several head loss coefficients for this mode of operation to combine the flows are summarized on Fig. 16, but also vary with Reynolds number...|$|E
40|$|Two {{physical}} models of component plus supporting substructure are considered. Each model {{consists of a}} rigid body attached to a moving base by means of linear springs and viscous dampers. The second model differs from the first in that its dampers are elastically supported. The first model receives the more extensive treatment. Base motion, assumed a random translational motion parallel to a fixed axis, is prescribed {{only to the extent}} that the power spectral density (PSD) of its acceleration is given; and, as given, its plot on <b>log-log</b> graph <b>paper</b> is a series of straight line segments, each segment having an extremity in common with the adjacent segment. Closed expressions are given for the mean squares of base acceleration, base velocity, and base displacement. The component is restricted to planar motion and allowed two degrees of freedom, one translational and one rotational. Integral expressions are given for the mean squares of component response variables, the transfer functions essential to mean square computation being available via the equations of motion. Closed expressions are given for mean squares of certain of the response variables for the case wherein the base acceleration PSD is constant...|$|R
30|$|As for MFHW {{completed}} in tight oil reservoirs, two dominant flow regimes, transient linear flow regime which may last {{for several months}} or years, even several decades and boundary dominated flow, are widely agreed on in this industry. According to previous researches (Clarkson and Beierle 2010) or case studies (Clarkson and Williams-Kovacs 2013; Anderson et al. 2012) for tight oil or shale gas wells, the flow regime identification is performed to determine which model (corresponding to specific flow regime) {{to be used for}} reservoir parameters estimation. Many theories and methods have been set up to capture the flow regime changes. In this <b>paper,</b> <b>log–log</b> normalized oil rate versus time plot has been used to identify flow regime. This plot has proven to be useful to perform flow regime identification for fractured horizontal wells {{completed in}} tight oil reservoirs (Clarkson 2013; Pinillos and Rong 2015).|$|R
40|$|The ADAPT physics labs were {{arranged}} {{to encourage students}} to develop formal reasoning as explained by Robert Karplus and Jean Piaget. Each lab is organized as a Karplus Learning Cycle. Reference: R. G. Fuller (editor), 2 ̆ 2 A Love of Discovery: Science Education, The Second Career of Robert Karplus 2 ̆ 2, Kluwer Academic/ Plenum Publishers, New York, © 2002 A primary function of the labs was to get the students to develop their skills at finding patterns in the data they would get from the laboratory experiments. This {{is the beginning of the}} data collecting laboratories. The students begin with a series of experiments that can give data that will result in a linear relationship between the variables. Then there follow experiments that yield power law relationships that can be shown as linear on <b>log-log</b> graph <b>paper.</b> Finally, the laboratories are experiments that can be exponential relationships which can be shown a linear on semi-log graphs. Each group of students, in teams of four, are given a set of eight data cards that have numerical data sets on each card. They are asked to sort them into groups by their similarities. The students are encouraged by the instructions to seek the relationship between the two variables. Some students will insist on only looking as the spacing, etc. between the numbers in one set of the numbers. After the groups have sorted their numbers into batches that are similar, the source of the data sets can be given to the groups to help them evaluate their batching proces...|$|R
40|$|An experiment, utilising a {{condensing}} fluid as {{the heat}} source, {{was performed to}} determine the heat flux vs. temperature difference curve for transition pool boiling from a horisontal surface. The boiling cure was determined {{as a function of}} surface roughness, material, and cleanliness for n-pentane at atmospheric pressure. The results of the experiment show that the liquid contacts the solid heating surface in transition boiling. The burnout heat flux and the film boiling curve are independent of surface properties. For commercial heating surfaces, and probably provided that the combination of surface energies which exist do not result in spreading of the liquid on the solid heating surface, the location of the minimum point is independent of surface properties. It is concluded that transition boiling is a combination of unstable nucleate and unstable film boiling alternating at a given location on the heating surface. The heat transfer data in the transition region was found to be correlated by a straight line on <b>log-log</b> graph <b>paper</b> which connects the burnout point and the minimum point. The bubble spacing and growth rates in film pool boiling from a horizontal surface are shown to be determined by Taylor Hydrodynamic Instability for temperature differences near the minimum. An analytical expression for the heat transfer coefficient in film pool boiling from a horizontal surface is derived. Comb [...] aing this equation with the equation for the minimum heat flux yields an analytical expression for the temperature difference at the minimum, which defines the location of the minimum point. The above equations agree with the experimental measurements made on n-pentane and carbon tetrachloride within +/- 10 %. National Science Ffoundation DSR Projec...|$|R

