89|16|Public
5000|$|The soft heap was {{designed}} by Bernard Chazelle in 2000. The term [...] "corruption" [...] in the structure {{is the result of}} what Chazelle called [...] "carpooling" [...] in a soft heap. Each node in the soft heap contains a <b>linked-list</b> of keys and one common key. The common key is an upper bound on the values of the keys in the <b>linked-list.</b> Once a key is added to the <b>linked-list,</b> it is considered corrupted because its value is never again relevant in any of the soft heap operations: only the common keys are compared. This is what makes soft heaps [...] "soft"; you can't be sure whether or not any particular value you put into it will be corrupted. The purpose of these corruptions is effectively to lower the information entropy of the data, enabling the data structure to break through information-theoretic barriers regarding heaps.|$|E
5000|$|Insertions and deletions are {{implemented}} {{much like the}} corresponding <b>linked-list</b> operations, except that [...] "tall" [...] elements must be inserted into or deleted {{from more than one}} linked list.|$|E
50|$|The CRC {{algorithm}} {{serves a}} dual function; {{it provides a}} workload commonly seen in embedded applications and ensures correct operation of the CoreMark benchmark, essentially providing a self-checking mechanism. Specifically, to verify correct operation, a 16-bit CRC is performed on the data contained in elements of the <b>linked-list.</b>|$|E
50|$|Vectors allow random access; that is, {{an element}} of a vector may be {{referenced}} {{in the same manner}} as elements of arrays (by array indices). <b>Linked-lists</b> and sets, on the other hand, do not support random access or pointer arithmetic.|$|R
5000|$|RCS Library Lower Level Utilities : Describes many of {{the lower}} level {{utilities}} used to create the NODE, CMS, and NML components of the RCS Library but which may be useful on their own. Includes timers, semaphores, <b>linked-lists,</b> printing, and windows functions.|$|R
50|$|Cell lists (also {{sometimes}} referred to as cell <b>linked-lists)</b> are a tool for finding all atom pairs within a given cut-off distance of each other in molecular dynamics simulations. These pairs are needed to compute the short-range non-bonded interactions in a system, such as Van der Waals forces or the short-range part of the electrostatic interaction when using Ewald summation.|$|R
5000|$|Since the {{division}} of the plane is decided by the order of point-insertion, the tree's height is sensitive to and dependent on insertion order. Inserting in a [...] "bad" [...] order can lead to a tree of height linear in the number of input points (at which point it becomes a <b>linked-list).</b> If the point-set is static, pre-processing can be done to create a tree of balanced height.|$|E
5000|$|In this paper, he {{described}} {{a new system}} for storing and working with large databases. Instead of records being stored {{in some sort of}} linked list of free-form records as in CODASYL, Codd's idea was to use a [...] "table" [...] of fixed-length records, with each table used for a different type of entity. A <b>linked-list</b> system would be very inefficient when storing [...] "sparse" [...] databases where some of the data for any one record could be left empty. The relational model solved this by splitting the data into a series of normalized tables (or relations), with optional elements being moved out of the main table to where they would take up room only if needed. Data may be freely inserted, deleted and edited in these tables, with the DBMS doing whatever maintenance needed to present a table view to the application/user.|$|E
40|$|The <b>linked-list</b> data {{structure}} is fundamental and ubiquitous. Lockfree {{versions of the}} <b>linked-list</b> are well known. However, {{the existence of a}} practical wait-free <b>linked-list</b> has been open. In this work we designed such a <b>linked-list.</b> To achieve better performance, we have also extended this design using the fast-path-slow-path methodology. The resulting implementation achieves performance which is competitive with that of Harris’s lock-free list, while still guaranteeing non-starvation via wait-freedom. We have also developed a proof for the correctness and the wait-freedom of our design...|$|E
40|$|This work {{introduces}} S-buffer, {{an efficient}} and memory-friendly gpu-accelerated A-buffer architecture for multifragment rendering. Memory is organized into variable contiguous regions for each pixel, thus avoiding limitations set in <b>linked-lists</b> and fixed-array techniques. S-buffer exploits fragment distribution for precise allocation of the needed storage and pixel sparsity (empty pixel ratio) for computing the memory offsets for each pixel {{in a parallel}} fashion. An experimental comparative evaluation of our technique over previous multi-fragment rendering approaches in terms of memory and performance is provided...|$|R
40|$|An {{abstract}} {{data type}} is introduced for general handling of sequences of elements. This ADT features contexts which point between elements of a sequence and is implemented by doubly-linked circular lists with headers. DCLH employs the exclusive-or of two pointers to achieve two-way traversal {{at a cost of}} one access field per node. This ADT and its DCLH implementation are designed as a system of three object classes – Lists, Nodes and Contexts – and programmed in C++. The symmetry of DCLH with respect to forward and backward traversal allows an elegant and compact coding of the lowlevel routines. Mathematical properties of exclusive-or are crucial to the correctness of the implementation. This paper also illustrates the important object-orientied programming concept of linked abstractions. The DCLH Abstract Data Type is composed of three distince Data Abstractions: Lists, Nodes, and Contexts. An earlier paper [1] recommended the use of contexts pointing between elements of a sequence and showed how this idea fit nicely with an old exclusive-or method for achieving two-way traversal of <b>linked-lists</b> at a cost of one access field. To avoid many of the problems that arise in processing <b>linked-lists</b> an implementation was developed using two header nodes, exclusive-or access fields, and contexts consisting of a pair of pointers. This doubly-linked circular list with header...|$|R
40|$|Algorithms that exhibit {{irregular}} {{memory access}} patterns {{are known to}} show poor performance on multiprocessor architectures, particularly when memory access latency is variable. Many common data structures, including graphs, trees, and <b>linked-lists,</b> exhibit these irregular memory access patterns. While FPGA-based code accelerators have been successful on applications with regular memory access patterns, {{they have not been}} further explored for irregular memory access patterns. Multithreading {{has been shown to be}} an e↵ective technique in masking long latencies. We describe the compiler generation of concurrent hardware threads for FPGAs with the objective of masking the memory latency caused by irregular memory access patterns. We extend the ROCCC compiler to generate customized state information for each dynamically generated thread...|$|R
30|$|Figure 20 {{shows the}} Linux Kernal I/O data structures. The “request queue” is a <b>linked-list</b> of {{requests}} structures. Each request structure is a <b>linked-list</b> of BIO (Block I/O) structures, {{which in turn}} are <b>linked-list</b> of “bio vec” structures. As per the Linux Kernel 4.15 source code [69], each “bio vec” represents a page in memory, by default it is 4096 bytes. Each BIO structure can contain a maximum of 256 [69] “bio vec” structures.|$|E
40|$|Data {{structures}} play {{an important}} role to reduce the cost of memory access. First array was introduced which gives fast cache-access, access, as elements are stored in consecutive places. But it has disadvantage also, like, wastage of memory, don’t allow insertion at run-time, time, and most important takes large number of shifting operations to insert or delete an item at any other position excluding last position. After that <b>Linked-List</b> was introduced d to overcome disadvantages of array. It has advantages of quick insertions and incremental growth. At run-time time new data can be inserted and avoid wastage of memory. But it also has some disadvantages, like requirement of extra memory space to store references. nces. For N elements N references are assigned, one for each element. Special type of <b>Linked-List</b> List is introduced which combines the cache advantages of an array but the quick insertions and incremental growth of a linked list. This is Unrolled <b>Linked-List.</b> Actually data field stores an array in place of a single element. As Unrolled <b>Linked-list</b> is a cache-sensitive sensitive data structure, which increases the speed of memory access by using arrays. We’ll implement its all basic operation along with its applications. Basic operations are insertion, deletion, searching, traversing and sorting. Like array and <b>Linked-List</b> it also has applications to implement many other elementary data structures like stack and queue. In future may be more cache-sensitive sensitive and cache cache-obvious vious data structure can be defined and implemented. Also NP-Hard and NP-Complete Complete problems can be solved using these data structures like unrolled <b>linked-list.</b> list...|$|E
40|$|Biological {{sequence}} {{comparison is}} one of the most important and basic problems in computational biology. Due to its high demands for computational power and memory, it is a very challenging task. The well-known algorithm proposed by Smith-Waterman obtains the best local alignments at the expense of very high computing power and huge memory requirements. This paper introduces a new efficient algorithm to locate the longest common subsequences (LCS) in two different DNA sequences. It is based on the convolution between the two DNA sequences: The major sequence is represented in the <b>linked-list</b> X while the minor one is represented in circular <b>linked-list</b> Y. An array of linked lists is established where each linked list is corresponding to an element of the <b>linked-list</b> X and a new node is added to it for each match between the two sequences. If two or more matches in different locations in string Y share the same location in string X, the corresponding nodes will construct a unique <b>linked-list.</b> Accordingly, by the end of processing, we obtain a group of linked-lists containing nodes that reflect all possible matches between the two sequences X and Y. The proposed algorithm has been implemented and tested using C# language. The benchmark test shows very good speedups and indicated that impressive improvements has been achieved...|$|E
50|$|From {{the query}} {{rectangle}} Q, {{we can find}} out which bin its lower-left corner intersects efficiently by simply subtracting the bin's bounding box's lower-left corner from the lower-left corner of Q and dividing the result by the width and height of a bin respectively. We then iterate the bins Q intersects and examine all the candidates in the <b>linked-lists</b> of these bins. For each candidate we check if it does indeed intersect Q. If so and it is not previously reported, then we report it. We can use the convention that we only report a candidate the first time we find it. This can be done easily by clipping the candidate against the query rectangle and comparing its lower-left corner against the current location. If it is a match then we report, otherwise we skip.|$|R
40|$|In this paper, {{we propose}} and {{investigate}} a new neural network architecture called Neural Random Access Machine. It can manipulate and dereference pointers to an external variable-size random-access memory. The model is trained from pure input-output examples using backpropagation. We evaluate {{the new model}} {{on a number of}} simple algorithmic tasks whose solutions require pointer manipulation and dereferencing. Our results show that the proposed model can learn to solve algorithmic tasks of such type and is capable of operating on simple data structures like <b>linked-lists</b> and binary trees. For easier tasks, the learned solutions generalize to sequences of arbitrary length. Moreover, memory access during inference can be done in a constant time under some assumptions. Comment: ICLR submission, 17 pages, 9 figures, 6 tables (with bibliography and appendix...|$|R
40|$|Abstract. Previous shape {{analysis}} algorithms use a memory model where the heap {{is composed of}} discrete nodes that can be accessed only via access paths built from variables and field names, an assumption that is violated by pointer arithmetic. In this paper we show how this assumption can be removed, and pointer arithmetic embraced, by using an analysis based on separation logic. We describe an abstract domain whose elements are certain separation logic formulae, and an abstraction mechanism that automatically transits between a low-level RAM view of memory and a higher, fictional, view that abstracts from the representation of nodes and multiword <b>linked-lists</b> as certain configurations of the RAM. A widening operator is used to accelerate the analysis. We report experimental results obtained from running our analysis {{on a number of}} classic algorithms for dynamic memory management. ...|$|R
40|$|Abstract | In this paper, {{we present}} {{the design of}} a scal-able queue {{management}} for shared buer switch architec-ture by using non-linked-list implementation. In the tradi-tional switch design, <b>linked-list</b> is the widely adopted im-plementation to maintain the packet buer. However, to design a <b>linked-list</b> architecture in hardware increases the size of chip and also limits the operating frequency. By using the non-linked-list design, the proposed architecture not only oers a wire-speed transmission rate, but also pro-vides an eÆcient Shifting Page Queue Manager (SPQM) for queue management. It may fulll the emerging needs for high-speed LAN switches. Moreover, it is feasible in imple-mentation...|$|E
40|$|Abstract—A {{critical}} shortcoming {{of determining}} texture features derived from grey-level co-occurrence matrices (GLCM’s) is the excessive computational burden. This paper describes {{the implementation of}} a <b>linked-list</b> algorithm to determine co-occurrence texture features far more efficiently. Behavior of common co-occurrence texture features across difference grey-level quantizations is investigated. I...|$|E
40|$|Abstract. In {{this paper}} we {{introduce}} a service-oriented {{approach to the}} design of distributed data structures for MPI. Using this approach we present the design of an ordered <b>linked-list</b> structure. The implementation relies on Fine-Grain MPI (FG-MPI) and its support for exposing fine-grain concurrency. We describe the implementation of the service and show how to compose and map it onto a cluster. We experiment with the service to show how its behaviour can be adjusted to match the application and the underlying characteristics of the machine. The advantage of a service-oriented approach is that it enforces low coupling be-tween components with higher cohesion inside components. As a service, the ordered <b>linked-list</b> structure can be easily composed with application code and more generally it is an illustration of how complex data structures can be added to message-passing libraries and languages...|$|E
40|$|Genetic and {{evolutionary}} algorithms, inspired by biological processes, provide a technique for programs to “automatically” improve their parameters. We discuss {{the basics of}} the algorithms and introduce our own hybrid. The development of this hybrid and its application to a simplified problem, evolving the coefficients for the sine function in a Taylor series, presents opportunities for computer science education with respect to model-building, data structures, and language features. Students must decide upon {{the representation of the}} chief mechanisms of genetic algorithms: mutation to alter the values of parameters directly and crossover to vary the groupings of co-evolved parameters in order to break away from local fitness maxima. They must examine the meaning of fitness itself as well as make many other modeling decisions. Ada itself provides both challenges and advantages: <b>linked-lists</b> must be well understood to be updated in an object-oriented context and hard-typing produces mixed reactions in students used to C++, but generics provide a powerful way to generalize the algorithm and incorporating different problem domains,...|$|R
40|$|This {{document}} {{explains how}} {{to construct a}} compiler using lex and yacc. Lex and yacc are tools used to generate lexical analyzers and parsers. I assume you can program in C, and understand data structures such as <b>linked-lists</b> and trees. The introduction describes the basic building blocks of a compiler and explains the interaction between lex and yacc. The next two sections describe lex and yacc in more detail. With this background, we construct a sophisticated calculator. Conventional arithmetic operations and control statements, such as if-else and while, are implemented. With minor changes, we convert the calculator into a compiler for a stack-based machine. The remaining sections discuss issues that commonly arise in compiler writing. Source code for examples may be downloaded from the web site listed below. Permission to reproduce portions of this document is given provided the web site listed below is referenced, and no additional restrictions apply. Source code, when part o...|$|R
40|$|As {{computing}} and {{embedded systems}} evolve towards highly parallel multiprocessors, major {{research and development}} efforts are being focused on network interface (NI) architectures that enable efficient interprocessor communication (IPC). This thesis is focused on NI architecture, prototyping and design issues for cluster and chip multiprocessors. This work includes {{the development of a}} NI queue manager, key NI design issues with respect to IPC and a proposed NI design well suited to chip multiprocessors. The first part of this thesis presents the architecture design and implementation of a NI queue manager that supports Virtual Output Queuing, Variable-Size Multi-Packet Segmentation and QFC flow control. To increase the available network buffer space VOQs can migrate to external memory in the form of memory blocks connected in <b>linked-lists.</b> Free-List Bypass and Free Block Preallocation optimization techniques are employed to minimize the required number of accesses to external memory and achieve higher bandwidth. In addition, a novel packet processing mechanism that converts arbitrary traffic segments into autonomous network packets was implemented. Detailed FPGA hardware cost results ar...|$|R
40|$|A new {{approach}} {{to the implementation of}} object associations is developed. The details of the implementation are discussed, and the idea of the “bi-directional interleaved <b>linked-list</b> ” is introduced. The proposed technique is compared to other techniques by the analysis of appropriate time and space metrics. Data from test runs demonstrates the proposed technique’s advantages...|$|E
3000|$|... “Request” {{structures}} are then staged in a <b>linked-list</b> called request queue. The request queue allows I/O schedulers to sort, merge and coalesce the requests {{depending on the}} locations they access. Appendix (“Conclusion and future works” section) describes {{the relationships between the}} block I/O kernel data-structures used by the block layer to perform I/O operations.|$|E
40|$|The {{following}} {{topics are}} discussed: requirements for dynamic mesh adaption; <b>linked-list</b> data structure; edge-based data structure; adaptive-grid data structure; {{three types of}} element subdivision; mesh refinement; mesh coarsening; additional constraints for coarsening; anisotropic error indicator for edges; unstructured-grid Euler solver; inviscid 3 -D wing; and mesh quality for solution-adaptive grids. The discussion is presented in viewgraph form...|$|E
40|$|International audienceHardware lock-elision (HLE) {{introduces}} concurrency into legacy lock-based code by optimistically executing critical {{sections in}} a fast-path as hardware transactions. Its main limitation {{is that in}} case of repeated aborts, it reverts to a fallback-path that acquires a serial lock. This fallback-path lacks hardware- software concurrency, because all fast-path hardware transactions abort {{and wait for the}} completion of the fallback. Software lock elision has no such limitation, but the overheads incurred are simply too high. We propose amalgamated lock-elision (ALE), a novel lock-elision algorithm that provides hardware-software concurrency and efficiency: the fallback-path executes concurrently with fast-path hardware transactions, while the common-path fast-path reads incur no overheads and proceed without any instrumentation. The key idea in ALE is to use a sequence of fine-grained locks in the fallback-path to detect conflicts with the fast-path, {{and at the same time}} reduce the costs of these locks by executing the fallback-path as a series segments, where each segment is a dynamic length short hardware transaction. We implemented ALE into GCC and tested the new system on Intel Haswell 16 -way chip that provides hardware transactions. We benchmarked <b>linked-lists,</b> hash-tables and red-black trees, as well as converting KyotoCacheDB to use ALE in GCC, and all show that ALE significantly outperforms HLE...|$|R
40|$|We {{show that}} for graphs with {{positive}} edge weights the single-source shortest path planning problem (SSSP) {{can be solved}} using a novel partial ordering over nodes, instead of a full ordering, without sacrificing algorithmic correctness. The partial ordering we investigate is defined with respect to carefully chosen (but easy to calculate) 2 ̆ 2 approximate 2 ̆ 2 level-sets of shortest-path length. We present a family of easy-to-implement 2 ̆ 2 approximate 2 ̆ 72 ̆ 7 priority heaps, based on an array of <b>linked-lists,</b> that create this partial ordering automatically when used directly by Dijkstra 2 ̆ 7 s SSSP algorithm. For graphs G = (E,V) with positive edge lengths, and depending on which version of the heap is used, the resulting Dijkstra variant runs in either time O(|E| + |V | + K) with space O(|E| + |V | + l_max/l_min) or time O((|E| + |V|) log_w(l_max/l_min + 1)) with space O(|E| + log_w(l_max/l_min + 1)), where l_min and l_max are the minimum (non-zero) and maximum (finite) edge lengths, respectively, and w is the word length of the computer being used (e. g., 32 or 64 in most cases), and K {{is a function of}} G such that K = O(|E|) for many common types of graphs (e. g., K = 1 for graphs with unit edge lengths). We also describe a linear time pre-/post-processing procedure that extends these results to undirected graphs with non-negative edge weights. Thus, it possible to solve many instances of SSSP in O(|E| + |V |); for these instances our method ties the fastest known runtime for SSSP, while having smaller constant factor overhead than previous methods. This work can be viewed as an extension of Dial’s SSSP algorithm in order handle floating point edge weights, faster runtimes, and new theoretical results...|$|R
40|$|Verifying the {{correctness}} of executions of concurrent {{and distributed}} programs {{is difficult because}} they show nondeterministic behavior due to different process scheduling order. Predicate detection can alleviate this problem by predicting whether the user-specified condition (predicate) could have become true in any global state of the given concurrent or distributed computation. The method is predictive because it generates inferred global states from the observed execution path and then checks if those global states satisfy the predicate. An {{important part of the}} predicate detection method is global states enumeration, which generates the consistent global states, including the inferred ones, of the given computation. Cooper and Marzullo gave the first enumeration algorithm based on a breadth first strategy (BFS). Later, many algorithms have been proposed to improve the space and time complexity. Among the existing algorithms, the Tree algorithm due to Jegou et al. has the smallest time complexity and requires O(|P|) space, which is linear {{to the size of the}} computation P. In this paper, we present a fast algorithm, QuickLex, to enumerate global states in the lexical order. QuickLex requires much smaller space than O(|P|). From our experiments, the Tree algorithm requires 2 - 10 times more memory space than QuickLex. Moreover, QuickLex is 4 times faster than Tree even though the asymptotic time complexity of QuickLex is higher than that of Tree. The reason is that the worst case time complexity of QuickLex happens only in computations that are not common in practice. Moreover, Tree is built on <b>linked-lists</b> and QuickLex can be implemented using integer arrays. In comparison with the existing lexical algorithm (Lex), QuickLex is 7 times faster and uses almost the same amount of memory as Lex. Finally, we implement a parallel-and-online predicate detector for concurrent programs using QuickLex, which can detect data races and violation of invariants in the programs...|$|R
40|$|Abstract- We have {{developed}} a performance prediction model for non-bonded interaction computations in molecular dynamics simulations, thereby predicting the optimal cell dimension in a <b>linked-list</b> cell method. The model expresses computation time {{in terms of the}} number and unit computation time of key operations. The model accurately estimates the number of operations during the simulations with the maximum standard error of 10. 6 % compared with actual measurements. Then, the unit computation times of the operations are obtained by bisquare regression. Analysis of this model reveals that the optimal cell dimension to minimize the computation time is determined by a trade-off between decreasing search space and increasing <b>linked-list</b> cell access for smaller cells. The model predicts the optimal cell dimension correctly for 80 % of all tested cases, resulting in an average speedup of 10 % and 52 % for the cutoff radius of interaction, 6. 6 and 10. 0 Å, respectively...|$|E
40|$|It is fact universally {{acknowledged}} that discrete computing systems are ill-equipped to process vector-based spatial information: inexact line intersection calculations and similar geometric (co-ordinate) operations can not readily guarantee consistent graphical structures (topology). It is proposed here {{that use of}} Voronoi diagrams, especially euclidean-distance nearest-object Voronoi diagrams of points and line segments in the plane, permits a general-purpose conversion of geometric information to a graphically-structured form amenable thereafter to graph traversal and other fundamental discrete operations appropriate to the computing environment employed. While the divide-and-conquer approach is efficient, object-at-a-time insertion and deletion techniques build on the current adjacency structure: preserve it and are consistent with database updating methodology; and direct comparisons can be used between one and two-dimensional <b>linked-list</b> operations. This approach permits the handling of spatial information {{in a manner consistent}} with computer strengths- by using <b>linked-list,</b> graph-traversal and tree-search algorithms well known to computing science to answer a wide variety of basic geographic queries, including interpolation, spatial ordering and medial-axis transforms...|$|E
40|$|Abstract. We {{present a}} {{formalisation}} of separation logic which, by avoiding {{the use of}} existential quantifiers, allows proofs that only use standard equational rewriting methods as found in off-the-shelf theorem provers. This proof automation is sufficiently strong to free the user from dealing with low-level details in proofs of functional correctness. The work presented here has been implemented in HOL 4 and ACL 2. It is illustrated on a standard example (reversal of a <b>linked-list).</b> ...|$|E
40|$|This book {{presents}} computing {{technologies for}} university {{students enrolled in}} advanced programming classes such as "Algorithms and programming", and software development professionals. It will give the reader an informative, challenging ad entertaining introduction to use C language to solve complex problems. Those problems will include advance algorithms and complex data structures. The book will concentrate on complete working programs, somehow presenting and contrasting several possible solutions. This work assumes a general-purpose knowledge of the C language {{such as the one}} usually learned during basic programming courses delivered at {{the first year of the}} curricula in computer engineering and computer science. The book main highlights are the following: - Extended coverage of pointers, dynamic arrays and matrices, <b>linked-lists,</b> and other basic data structures. - Abstract data types (ADTs). - Recursions and recursive algorithms. Each topic is covered by a rich collection of partial and complete examples, and about 100 fully implemented and debugged programs. The focus is on good software engineering, and on program clarity, such that the reader is guided to learn properties of algorithms and data structures as fast as possible. The content of each chapter is the following: - Chapter 1 presents a revising set of exercise to recall basic C construct and problem solving strategies. This is essentially a very brief summary of Volume I by the same author. Code and programming style follow the same book. - Chapter 2 covers dynamic memory allocation. Pointers, operators on pointers, dynamic arrays, and dynamic matrices are covered into details. - Chapter 3 presents dynamically allocated lists. Simple, ordered, bi-linked, circular, and list-of-lists are described with several figures and code segments. - Chapter 4 describes basic concepts for recursion and it presents simple recursive programs. - Chapter 5 includes standard recursive problems such as merge-sort, quick-sort, the eight queen problems, etc. It also describes combinatorics problems, such as: The multiplication principle, simple arrangements, arrangements with repetitions, simple permutation, permutation with repetitions, simple combination, combinations with repetitions, and the power-set. - Chapter 6 describe how to apply recursion to some hard-to-solve problems. - Chapter 7 describes all required concepts to write programs "in the large", i. e., multi-file programs, with personalized header files. It also illustrates the main concepts of Abstract Data Type (ADTs) and their use in C programming. - Chapter 8 illustrates several ADT-based problems, such as the stack (based on an array or a dynamic list), queues, etc. The book is also covered by online material, as all source codes are available on the editor web page. We would sincerely appreciate any comments, criticisms, corrections and suggestions for improving the text. Please address all correspondence to: stefano. quer@polito. it or visits the following web page: [URL]...|$|R
40|$|Abstract. In this paper, {{we present}} a <b>linked-list</b> based {{encoding}} scheme for multiple objectives based genetic algorithm (GA) to identify clusters in a partition. Our approach obtains the optimal partitions for all the possible numbers of clusters in the Pareto Optimal set returned by a single genetic GA run. The performance of the proposed approach has been tested using two well-known data sets, namely Iris and Ruspini. The obtained results are promising and demonstrate the applicability and effectiveness of the proposed approach...|$|E
40|$|Current C to gates {{synthesis}} tools do {{not support}} programs that make non-trivial use of dynamically-allocated heap (e. g. <b>linked-list</b> C programs that call malloc and free). The problem is that its difficult to determine an a priori bound {{on the amount of}} heap used during the program’s execution, if a bound even exists. In this paper we develop a new method of synthesizing symbolic bounds expressed over generic parameters, thus leading to a C to gates synthesis flow for programs using dynamic allocation and deallocation. 1...|$|E
