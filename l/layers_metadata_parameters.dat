0|123|Public
5000|$|Dialnorm - Dolby Digital <b>metadata</b> <b>parameter</b> {{controlling}} decoder gain ...|$|R
30|$|For each {{service and}} layer Hypermap stores {{temporal}} {{information about the}} depict dates. This information, when not provided by the <b>layer’s</b> <b>metadata,</b> is automatically extracted by parsing textual metadata fields such as the title and the abstract [12].|$|R
50|$|Metadata search: {{the search}} is made on the <b>layers</b> of <b>metadata.</b>|$|R
40|$|ISO 19115 : 2003 Metadata {{standard}} {{allows generating}} {{a set of}} metadata for different hierarchical levels. There are still few attempts to apply this metadata standard to every level. People consider that series and <b>layer</b> <b>metadata</b> are solved correctly using this approach but when the model is tested to feature or attributes type levels it generates a huge degree of redundancy. It is neither clear how {{the definition of the}} feature and attribute types has to be done. A proposal defining father-and-son relationships between series and <b>layer</b> <b>metadata</b> is presented. <b>Layer</b> elements can inherit, modify or extent the series value. Definition of entity and attribute metadata is carried out using another approach based on the pre-standard ISO 19109. The proposal suggests general rules for application schema applied to a vector layer and a set of objects (with necessary metadata) {{that can be used to}} describe a relational database of thematic attributes...|$|R
40|$|International audienceMany {{real world}} systems and {{applications}} require a management tool that provides support {{for dealing with}} imperfect data. The aim {{of this paper is}} to handle the imperfection of spatiotemporal data from the conceptual modeling to the database conception. We propose to add new pictograms in PERCEPTORY in order to build imperfect spatiotemporal class diagrams such as those made using Fuzzy UML. Using those models, we organize the database as a three layer organization: data <b>layer,</b> <b>metadata</b> <b>layer,</b> multivalued layer. Those interlinked layers give a more accurate interaction...|$|R
40|$|Cross-disciplinary collaborations {{potentially}} {{offer the}} diversity of understanding required to answer complex problems. However, barriers to cohort discovery exist because content about people is predominantly only in human-readable form on websites and/or in disparate databases. Notably, many cross-disciplinary collaborations never form {{due to a lack}} of awareness of cross-boundary synergies. This project applies semantic technologies to automate linkages to reveal hidden connections between people from <b>metadata</b> <b>parameters</b> about data, rather than from publication products. The information in metadata, commonly used for data discovery, can be used to link researchers for potential partnerships. The proposed system combines pre-existing and custom ontologies, populated from a number of accessible repositories, to describe the relationships between researchers based on <b>metadata</b> <b>parameters.</b> The system was tested from the researcher's perspective where significant alignments with potential partners were found based on transitive relationships, similar interests (e. g., research fields) and/or other commonalities (e. g., location/time of research) ...|$|R
50|$|Dialnorm is the <b>metadata</b> <b>parameter</b> that {{controls}} playback gain within the Dolby Laboratories Dolby Digital (AC-3) audio compression system. Dialnorm stands for dialog normalization. Dialnorm is an integer value with range 1 to 31 corresponding to a playback gain of -30 to 0 dB (unity) respectively. Higher values afford more headroom and {{are appropriate for}} dynamic material such as an action film.|$|R
40|$|Abstract. Cross-disciplinary collaborations {{potentially}} {{offer the}} diversity of understanding required to answer complex problems. However, barriers to cohort discovery exist because content about people is predominantly only in human-readable form on websites and/or in disparate databases. Notably, many cross-disciplinary collaborations never form {{due to a lack}} of awareness of cross-boundary synergies. This project applies semantic technologies to automate linkages to reveal hidden connections between people from <b>metadata</b> <b>parameters</b> about data, rather than from publication products. The information in metadata, commonly used for data discovery, can be used to link researchers for potential partnerships. The proposed system combines pre-existing and custom ontologies, populated from a number of accessible repositories, to describe the relationships between researchers based on <b>metadata</b> <b>parameters.</b> The system was tested from the researcher's perspective where significant alignments with potential partners were found based on transitive relationships, similar interests (e. g., research fields) and/or other commonalities (e. g., location/time of research) ...|$|R
40|$|Abstract—aceMedia content {{analysis}} capabilities are {{centered around the}} concept of the ACE. The ACE is composed of a content <b>layer,</b> a <b>metadata</b> <b>layer</b> and an intelligence layer. In this paper we show one application of the ACE Intelligence layer and how its proactive conduct can help in the complex task of adding semantic metadata to multimedia content. Index Terms—multimedia {{content analysis}}, proactive content, self-annotation I...|$|R
50|$|Functions in this {{virtual machine}} are a pointer {{to a set}} of {{instructions}} in aprogram with <b>metadata</b> about <b>parameters</b> defined.|$|R
40|$|Copyrighted by American Geophysical Union. Many Earth science {{disciplines}} {{are currently}} experiencing {{the emergence of}} new ways of data publication and the establishment of an information technology infrastructure for data archiving and exchange. Building on efforts to standardize data and metadata publication in geochemistry [Staudigel et al., 2002], here we discuss options for data publication, archiving and exchange. All of these options have to be structured to meet some minimum requirements of scholarly publication, in particular reliability of archival, reproducibility and falsifiability. All data publication and archival methods should strive to produce databases that are fully interoperable and this requires an appropriate data and metadata interchange protocol. To accomplish the latter we propose a new Metadata Interchange Format (. mif) {{that can be used for}} more effective sharing of data and metadata across digital libraries, data archives, and research projects. This is not a proposal for a particular set of <b>metadata</b> <b>parameters</b> but rather of a methodology that will enable <b>metadata</b> <b>parameter</b> sets to be easily developed and interchanged between research organizations. Examples are provided for geochemical data as well as map images to illustrate the flexibility of the approach...|$|R
40|$|Metadata play {{crucial role}} in {{enterprise}} interoperability between business, service and information <b>layers.</b> <b>Metadata</b> in different form, such as the abstract of system structure, aggregation of information, repository and semantic mediation play different role to achieve the integration interoperability, so each type of metadata contribute their value to enterprise integration. As misalignment within enterprise architecture has been ranked {{one of the top}} issues in recent 10 years, to cope with this common issue, we launched metadata based integration framework to enhance the visibility of enterprise alignment and use metadata configuration to construct the mapping between layer. ...|$|R
5000|$|Framework Manager (Semantic <b>metadata</b> <b>layer</b> tool {{which creates}} models or packages) ...|$|R
50|$|The decoded exponents, {{along with}} a set of <b>metadata</b> <b>parameters,</b> is used to derive the bit {{allocation}} pointers (BAPs), which specify the number of bits allocated to each mantissa. Bins which correspond to frequencies in which human hearing is more precise are allocated more bits; bins which correspond to frequencies that humans are less sensitive to are allocated fewer. Anywhere between zero and 16 bits may be allocated for each mantissa; if zero bits are transmitted, a dither function may be optionally applied to generate the frequency coefficient.|$|R
50|$|Design of {{information}} model should include various <b>layers</b> of <b>metadata</b> types to be overlapped {{to create an}} integrated view of the data. Various metadata types should be stitched with related metadata elements in a top down model linking to business glossary.|$|R
30|$|Clinical <b>metadata</b> (physiological <b>parameters,</b> {{clinical}} status, underlying pathology, medications, etc.) {{were recorded}} by the research assistants using our standard monitoring devices and the computerized medical file (ICCA® Philips Healthcare, Amsterdam, the Netherlands).|$|R
30|$|<b>Metadata</b> <b>layer</b> {{consists}} {{of a number of}} APIs. These APIs interact in a way similar to the Google Metadata API concept. Through the use of the HTML 5 markup, javascript and libraries such as JQuery Mobile, the system can access the smartphone and tablet sensors (GPS, camera and microphone) needed to crowdsource information and media which sits on the pedagogical side of the 4 Any framework in Fig.  1. Conversion tools such as PhoneGap can allow compilation of the application to run natively on the application if this is needed. PhoneGap is a free and open source framework that allows you to create mobile apps using standardized web APIs for various platforms such as iOS, Android, Blackberry 10, Firefox, and Windows 8. Dashed lines in Fig.  3 represent no direct access to <b>Metadata</b> <b>layer</b> by the Instructor and Learner Profiles. The access to <b>Metadata</b> <b>layer</b> is through Device and Programmer profiles. Instructor and Learner have access to Information and Media only through Scenario layer utilising the major access line in the <b>metadata</b> <b>layer</b> designed by the programmer. Device records the location information.|$|R
50|$|Search is {{made using}} the <b>layers</b> in <b>metadata</b> which contain {{information}} {{of the content}} of a multimedia file. Metadata search is easier, faster and effective because instead of working with complex material, such as an audio, a video or an image, it searches using text.|$|R
50|$|DPI {{focuses on}} {{recognizing}} {{different types of}} IP traffic {{as part of a}} CSP’s infrastructure. NI provides more granular analysis. It enables vendors to create an information <b>layer</b> with <b>metadata</b> from IP traffic to feed multiple applications for more detailed and expansive visibility into network-based activity.|$|R
40|$|This paper {{examines}} two {{fields that}} contribute to research on digital libraries [...] information systems and orality-literary studies [...] and applies them to a particular digital library domain, botanical taxonomic work. Topics discussed include: (1) an introduction to HOSS (i. e., a computationally-oriented hypermedia system) architecture, including the hyperbase layer, structure processing <b>layer,</b> <b>metadata</b> manager <b>layer,</b> application layer, and other tools; (2) an introduction to orality, literacy, and hyperliteracy; (3) botanical taxonomic scholarship; (4) information systems technology applications, including single/multiple taxonomies, ownership of taxonomies, and definition of taxonomies; and (5) hyperliterate work practices, including single/multiple taxonomies, ownership of taxonomies, and definition of taxonomies. A table presents examples of differences between orality and literacy. Contains 19 references. (Author/DLS) Reproductions supplied by EDRS are the best {{that can be made}} from the original document...|$|R
40|$|We {{present a}} novel form of intra-volume {{directory}} layering with hierarchical, inheritance-like namespace unification. While each layer of an OLFS volume constitutes a subvolume {{that can be}} mounted separately in a fan-in configuration, the entire hierarchy is always accessible (online) and fully navigable through any mounted layer. OLFS uses a relational database to store its <b>layering</b> <b>metadata</b> and either a relational database or any (virtual) host file system as its backing store, along with metadata and block caching for improved performance. Because OLFS runs as a virtual file system in user-space, its capabilities are available to all existing software without modification or special privileges. We have developed a reference implementation of OLFS for FUSE based on MySQL and XFS, and conducted performance benchmarking against XFS by itself. We explore several applications of OLFS, such as enhanced server synchronization, transactional file operations, and versioning...|$|R
40|$|Video {{surveillance}} {{systems are}} growing {{in size and}} complexity. Such systems typically consist of integrated modules of different vendors {{to cope with the}} increasing demands on network and storage capacity, intelligent video analytics, picture quality, and enhanced visual interfaces. Within a surveillance system, relevant information (like technical details on the video sequences, or analysis results of the monitored environment) is described using metadata standards. However, different modules typically use different standards, resulting in metadata interoperability problems. In this paper, we introduce the application of Semantic Web Technologies to overcome such problems. We present a semantic, <b>layered</b> <b>metadata</b> model and integrate it within a video surveillance system. Besides dealing with the metadata interoperability problem, the advantages of using Semantic Web Technologies and the inherent rule support are shown. A practical use case scenario is presented to illustrate the benefits of our novel approach...|$|R
40|$|Kendra's primary {{objective}} is {{to test the hypothesis}} that metadata can be used not only to increase searching effectiveness on the Internet, but also to determine optimisation parameters in internet data distribution and delivery systems. Specifically, we are developing a <b>layered</b> <b>metadata</b> reference model to describe multi-media entertainment data and the architectures supporting it. Further, we are building a prototype distributed multi-media delivery system which utilises intelligent, distributed caching mechanisms to improve accessibility, performance and reliability while minimising storage space and network utilisation. The metadata reference model feeds into the decision making capabilities of the data delivery system to improve system performance, through staging and migration. This allows applications to make more informed choices about what data to retrieve. Furthermore, our experiments make use of real user behavioural data. 1 Introduction More and more companies are moving [...] ...|$|R
40|$|The {{extensive}} and persistent occurrence of clouds and associated shadows over the Amazon basin {{are the major}} constraints {{on the use of}} optical orbital remote sensing data for the systematic and operational monitoring of its vegetative cover. In this study, the temporal and spatial distribution of clouds and shadows over the entire Amazon region were assessed through the analysis of two full hydrologic years of the quality assurance <b>layer</b> (<b>metadata)</b> which accompanies the MOD 13 A 2 product. Our results, although preliminary and not conclusive, indicate that the period from June through September is the most appropriate regarding the use of visible and NIR remote sensing data. On the hand, the most adverse atmospheric conditions were found for the period between November and March, which should be avoided regarding passive orbital observations. Pages: 497 - 50...|$|R
40|$|In this paper, we {{describe}} {{a tool for}} rich annotation of images. This tool allows creation of graphical annotations to identify and describe features in images. It also provides the capability to then catalog the annotation <b>layer</b> in <b>metadata</b> repositories. Application of the annotation tool to describe satellite images {{in the areas of}} meteorology and vegetation will be presented...|$|R
50|$|Knowledge GridA <b>metadata</b> <b>layer</b> (called the Database Knowledge Grid) stores compact {{information}} about the contents and relationships between the data packs, replacing {{the concept of a}} traditional database index.|$|R
40|$|This paper {{presents}} a novel fuzzy inference model based on artificial hydrocarbon networks, a computational algorithm for modeling problems based on chemical hydrocarbon compounds. In particular, the proposed fuzzy-molecular inference model (FIM-model) uses molecular units {{of information to}} partition the output space in the defuzzification step. Moreover, these molecules are linguistic units that can be partially understandable due to the organized structure of the topology and <b>metadata</b> <b>parameters</b> involved in artificial hydrocarbon networks. In addition, a position controller for a direct current (DC) motor was implemented using the proposed FIM-model in type- 1 and type- 2 fuzzy inference systems. Experimental results demonstrate that the fuzzy-molecular inference model can be applied as an alternative of type- 2 Mamdani’s fuzzy control systems because the set of molecular units can deal with dynamic uncertainties mostly present in real-world control applications...|$|R
50|$|OJB uses an XML based Object/Relational mapping. The mapping {{resides in}} a dynamic <b>MetaData</b> <b>layer,</b> {{which can be}} {{manipulated}} at runtime through a simple Meta-Object-Protocol (MOP) to change the behaviour of the persistence kernel.|$|R
40|$|This article {{describes}} the development of Archives Ready To Archival Information Packages (AIP) Transmission a PREMIS Based Project (ARTAT). Following the project approach, the starting phase consisted of prototyping a <b>layer</b> conveying preservation <b>metadata,</b> which can be encoded from the existing archival systems, and exchanged with other repositories. This <b>layer</b> called Preservation <b>Metadata</b> <b>Layer</b> (PML) uses PREMIS semantics as the common language to overcome archival systems differences, and to transmit out of its original context, relevant preservation information about content objects comprising an AIP. Since a repository, following the OAIS reference model, usually provides resources with metadata container objects, the experiment performed an analysis on commonly used container formats, in order to enable the traceability of semantics from a local to extra-local level, and the technological understandability of alien AIPs. The analysis has allowed {{the definition of a}} PML data model, laying the production of prototypes. The adoption of common semantics, like PREMIS, supports the opportunity of preserving correctly alien AIPs, coming from different technological environments, and hopefully enables the overcoming of obstacles to the interoperability among diverse archival systems...|$|R
40|$|Modern {{geospatial}} databases {{are becoming}} increasingly complex, with multiple types of information (e. g. imagery, maps, vector data, video, and text), huge volumes of data (e. g. numerous satellite images continuously captured {{in the span of}} a mission), and distributed storage (e. g. various servers storing different types of information). Furthermore, spatiotemporal analysis is also becoming more complicated, with analysts making use of diverse datasets to make complex decisions. These trends make geospatial queries increasingly complex and challenging. In this paper we introduce non-linear correlations within geospatial databases to better handle user queries in distributed environments. In order to support queries, datasets are typically indexed according to their metadata information. For example, an image may be indexed according to its <b>metadata</b> <b>parameters</b> (e. g. area, scale, time, sensor). This results in defining a multidimensional (MD) space and indexing individual datasets in this space. Each dimension of this space corresponds to an individual <b>parameter</b> in the <b>metadata</b> description. ...|$|R
40|$|The {{organised}} {{storage of}} spectral data described by metadata {{is important for}} long-term use and data sharing with other scientists. Metadata describing the sampling environment, geometry and measurement process serves to evaluate the suitability of existing data sets for new applications. There {{is a need for}} spectral databases that serve as repositories for spectral field campaign and reference signatures, including appropriate <b>metadata</b> <b>parameters.</b> Such systems must be (a) highly automated in order to encourage users entering their spectral data collections and (b) provide flexible data retrieval mechanisms based on subspace projections in metadata spaces. The recently redesigned SPECCHIO system stores spectral and metadata in a relational database based on a non-redundant data model and offers efficient data import, automated metadata generation, editing and retrieval via a Java application. RSL is disseminating the database and software to the remote sensing community in order to foster the use and further development of spectral databases...|$|R
40|$|Part 4 : Applications of Parallel and Distributed ComputingInternational audienceDistributed {{file system}} {{is one of}} the key blocks of cloud {{computing}} systems. With the fast increase of user scale and data amount, metadata management has become a crucial point affecting the overall performance of a distributed file system. In this paper, we design and implement PPMS, a novel metadata management strategy in a peer to peer way. Different from existing metadata management methods, we adopt a two layer structure to achieve high scalability and low latency. The upper <b>layer</b> is <b>metadata</b> index server, which is used to store metadata of directories, while the lower <b>layer</b> consists of <b>metadata</b> servers to store the metadata of files. More importantly, the lower layer is organized in a peer to peer way to further improve scalability. We implement a prototype file system based on PPMS and evaluate its performance via experiments. The results show that our design can achieve high performance with in terms of time latency and system throughput...|$|R
40|$|Abstract — There is {{an urgent}} need for {{metadata}} to accompany and describe media data essence. For the growing amount of personal content, user generated descriptors tend to be vague {{to the point of}} uselessness. Standardization in the metadata format is needed to allow a full and useful description of content that is interoperable between consumer devices. Manufacturers need to ensure that the metadata generated by a device is complete and understood by other products as well as allow for the creation and use of more subjective metadata. This paper provides a background on <b>metadata</b> <b>layers</b> with the aim to create a standard model of <b>metadata</b> <b>layers</b> in consumer devices 1. Index Terms — Metadata, standardization, life log, life recorder, digital storage, physical, physiological...|$|R
40|$|Spectral {{databases}} constitute one of {{the components}} of a complete observing system, storing in situ spectroscopic measurements plus associated metadata and providing data for the validation, calibra- tion, and simulation of imaging spectrometer products. Such databases may be employed by physically or organisationally separate entities. Consequently, methods for data exchange between distributed spectral databases are required, allowing the transfer of defined subsets of spectral data including their full metadata context from a source to a target system. The data exchange comprises generic approaches to the sequential steps of ordered table row export, relational storage in XML files, and nonconflicting import into the target database. The SPECCHIO spectral database system was used as a test bed for the data exchange between databases of identical schemata and according import/export functionality has been added to the SPECCHIO application. Import and export speeds were assessed using test cases of different metadata space densities, a score for the density with which associated metadata are detailed, and the potential utility as a quantitative rating for quality. Future spectral databases should allow the exchange between heterogeneous systems, ideally implementing a common subset of <b>metadata</b> <b>parameters</b> and thus supporting the long-term usability and data sharing between research partners...|$|R
40|$|With {{respect to}} the major role {{information}} warehouses play for the management an approach for specifying management views within the requirements specification phase is presented. Based on a framework relating development phases and abstraction layers the roles of documents within development processes are organised. The importance of using management views as <b>metadata</b> and <b>parameters</b> in later development phases is elaborated. Formally the transformation of management views into logical data mart schemes and report queries is shown by means of algorithms. Development phases are integrated based on meta level relationships. <br/...|$|R
40|$|International audienceOutputs of {{simulation}} codes {{making use}} of the HDF 5 file format are usually and mainly composed of several different attributes and datasets, storing either lightweight pieces of information or containing heavy parts of data. These objects, when written or read through the HDF 5 <b>layer,</b> create <b>metadata</b> and data IO operations of different block sizes, which depend on the precision and dimension of the arrays that are being manipulated. By {{making use of}} simple block redistribution strategies, we present in this paper a case study showing HDF 5 IO performance improvements for "in-memory" files stored in a distributed shared memory buffer using one-sided communications through the HDF 5 API...|$|R
