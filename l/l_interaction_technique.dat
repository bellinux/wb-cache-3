0|4259|Public
40|$|This chapter {{describes}} {{the area of}} human-computer <b>interaction</b> <b>technique</b> research in general and then describes research in several new types of <b>interaction</b> <b>techniques</b> under way at the Human-Computer Interaction Laboratory of the U. S. Naval Research Laboratory: eye movement-based <b>interaction</b> <b>techniques,</b> three-dimensional pointing, and, finally, using dialogue properties in <b>interaction</b> <b>techniques...</b>|$|R
40|$|This paper {{focuses on}} the {{evaluation}} of virtual reality (VR) <b>interaction</b> <b>techniques</b> for exploration of data warehouse (DW). The experimental DW involves hierarchical levels and contains information about customers profiles and related purchase items. A user study {{has been carried out}} to compare two navigation and selection techniques. Sixteen volunteers were instructed to explore the DW and look for information using the <b>interaction</b> <b>techniques,</b> involving either a single WiimoteTM (monomanual) or both WiimoteTM and NunchuckTM (bimanual). Results indicated that the bimanual <b>interaction</b> <b>technique</b> is more efficient in terms of speed and error rate. Moreover, most of the participants preferred the bimanual <b>interaction</b> <b>technique</b> and found it more appropriate for the exploration task. We also observed that males were faster and made less errors than females for both <b>interaction</b> <b>techniques...</b>|$|R
40|$|This chapter {{describes}} {{the area of}} human-computer <b>interaction</b> <b>technique</b> research in general and then describes research in several new types of <b>interaction</b> <b>techniques</b> under way at the Human-Computer Interaction Laboratory of the U. S. Naval Research Laboratory: eye movement-based <b>interaction</b> <b>techniques,</b> three-dimensional pointing, and, finally, using dialogue properties in <b>interaction</b> <b>techniques.</b> Keywords. human-computer <b>interaction,</b> <b>interaction</b> <b>techniques,</b> eye movements, gesture, pointing, dialogue 1 Introduction Tufte [9] has described human-computer interaction as two powerful information processors (human and computer) attempting {{to communicate with each}} other via a narrow-bandwidth, highly constrained interface. A fundamental goal of research in human-computer interaction is, therefore, to increase the useful bandwidth across that interface. A significant bottleneck in the effectiveness of educational systems as well as other interactive systems is this communication path betw [...] ...|$|R
40|$|Abstract—Even though {{interaction}} {{is an important}} part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis <b>interaction</b> <b>techniques</b> exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of <b>interaction</b> <b>techniques</b> widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user’s intent while interacting with a system rather than the low-level <b>interaction</b> <b>techniques</b> provided by a system. The categories can act as a framework to help discuss and evaluate <b>interaction</b> <b>techniques</b> and hopefully lay an initial foundation toward a deeper understanding and a science of interaction. Index Terms—Information visualization, <b>interaction,</b> <b>interaction</b> <b>techniques,</b> taxonomy, visual analytics...|$|R
40|$|Abstract. This paper {{presents}} an analysis, implementation {{and evaluation of}} the physical mobile <b>interaction</b> <b>techniques</b> touching, pointing and scanning. Based on this we have formulated guidelines that show in which context which <b>interaction</b> <b>technique</b> is preferred by the user. Our main goal was to identify typical situations and scenarios in which the different techniques might be useful or not. In support of these aims we have developed and evaluated, within a user study, a low-fidelity and a high-fidelity prototype to assess scanning, pointing and touching <b>interaction</b> <b>techniques</b> within different contexts. Other work has shown that mobile devices can act as universal remote controls for interaction with smart objects but, to date, {{there has been no}} research which has analyzed when a given mobile <b>interaction</b> <b>technique</b> should be used. In this research we analyze the appropriateness of three <b>interaction</b> <b>techniques</b> as selection techniques in smart environments. ...|$|R
40|$|There are two typical {{approaches}} {{to the design of}} three-dimensional (3 D) <b>interaction</b> <b>techniques</b> for immersive virtual environments (VEs). Many 3 D <b>interaction</b> <b>techniques</b> are designed for generic user tasks such as navigation, selection, manipulation, and system control, without consideration of the domain-of-use. Despite a long history in HCI theory and practice of using domain knowledge for system-level design, it has not often been used for the design of <b>interaction</b> <b>techniques.</b> Other 3 D <b>interaction</b> <b>techniques</b> are designed for specific applications. While these techniques may be quite usable and useful in that single application, their reuse is limited. In this paper, we propose a middle ground: domain-specific design (DSD) of 3 D <b>interaction</b> <b>techniques.</b> The goal of DSD is to improve upon current practice so that 3 D <b>interaction</b> <b>techniques</b> are designed to address real-world tasks, while still allowing for reuse of the techniques within a particular domain. A three-level design framework provides a theoretical basis for DSD, and we show how this framework can be used to illustrate multiple paths for the design of domain-specific <b>interaction</b> <b>techniques.</b> We also provide a comprehensive, practical case study of an actual VE system, Virtual-SAP (structure analysis program), to illustrate how the approach is applied. Experimental results demonstrate that the use of the DSD approach increases the usefulness of this application, without sacrificing usability. Keywords: 3 D interaction, domain-specific interaction, design theory, virtual environment...|$|R
50|$|<b>Interaction</b> <b>techniques</b> are {{the glue}} between {{physical}} I/O devices and interaction tasks or domain objects. Different types of <b>interaction</b> <b>techniques</b> {{can be used}} to map a specific device to a specific domain object. For example, different gesture alphabets exist for pen-based text input.|$|R
40|$|This paper {{introduces}} a novel kinesthetic <b>interaction</b> <b>technique</b> for interactive floors. The <b>interaction</b> <b>techniques</b> utilize vision-based limb tracking on an interactive floor – a 12 m² glass surface with bottom projection. The kinesthetic <b>interaction</b> <b>technique</b> {{has been developed}} for an interactive floor implemented in a school square. The paper discusses the kinesthetic <b>interaction</b> <b>technique</b> and its potentials {{in the domain of}} learning applications: Kinesthetic interaction supports body-kinesthetic learning as argued in the learning literature. Kinesthetic interaction is fun and motivating thus encourages children to explore and learn. Kinesthetic interaction on large display surfaces supports collaborative, co-located play and learning through communication and negotiation among the participants. Finally, the paper discusses prospects and challenges in development of kinesthetic interaction for interactive floors...|$|R
50|$|A {{large part}} of {{research}} in human-computer interaction involves exploring easier-to-learn or more efficient <b>interaction</b> <b>techniques</b> for common computing tasks. This includes inventing new (post-WIMP) <b>interaction</b> <b>techniques,</b> possibly relying on methods from user interface design, and assessing their efficiency with respect to existing techniques using methods from experimental psychology. Examples of scientific venues in these topics are the UIST and the CHI conferences. Other research focuses on the specification of <b>interaction</b> <b>techniques,</b> sometimes using formalisms such as Petri nets {{for the purposes of}} formal verification.|$|R
5000|$|From the computer's perspective, an <b>interaction</b> <b>technique</b> involves: ...|$|R
5000|$|... #Subtitle level 2: Comparison {{with other}} <b>interaction</b> <b>techniques</b> ...|$|R
40|$|Background: Our {{previous}} {{studies have shown that}} OX 40 -OX 40 <b>L</b> <b>interaction</b> regulates the expression of nuclear factor of activated T cells c 1 (NFATc 1) in ApoE 2 / 2 mice during atherogenesis. The aim {{of this study was to}} investigate whether OX 40 -OX 40 <b>L</b> <b>interaction</b> promotes Th cell activation via NFATc 1 in ApoE 2 / 2 mice. Methods and Results: The lymphocytes isolated from spleen of ApoE 2 / 2 mice were cultured with anti-CD 3 mAb in the presence or absence of anti-OX 40 or anti-OX 40 L antibodies. The expression of NFATc 1 mRNA and protein in isolated lymphocytes were measured by real time PCR (RT-PCR) and flow cytometry (FCM), respectively. The proliferation of lymphocytes was analyzed by MTT method,and the expression of IL- 2, IL- 4 and IFN-c in the cultured cells and supernatant were measured by RT-PCR and enzyme-linked immunosorbent assary (ELISA), respectively. After stimulating OX 40 -OX 40 L signal pathway, the expression of NFATc 1 and the proliferation of leukocytes were significantly increased. Anti-OX 40 L suppressed the expression of NFATc 1 in lymphocytes of ApoE 2 / 2 mice. Anti-OX 40 L or the NFATc 1 inhibitor (CsA) markedly suppressed the cell proliferation induced by anti-OX 40. Moreover, the expression of IL- 2 and IFN-c was increased in lymphocytes induced by OX 40 -OX 40 <b>L</b> <b>interaction.</b> Blocking OX 40 -OX 40 <b>L</b> <b>interaction</b> or NFATc 1 down-regulated the expression of IL- 2 and IFN-c, but didn’t alter the expression of IL- 4 in supernatants. Conclusion: These results suggest that OX 40 -OX 40 <b>L</b> <b>interaction</b> promotes the proliferation and activation of lymphocytes through NFATc 1...|$|R
40|$|The <b>interaction</b> <b>techniques</b> {{that are}} used in {{tabletop}} groupware systems (such as pick-and-drop or pantograph) can affect the way that people collaborate. However, little is known about these effects, making it difficult for designers to choose appropriate techniques when building tabletop groupware. We carried out an exploratory study to determine how several different types of <b>interaction</b> <b>techniques</b> (pantograph, telepointers, radar views, drag-and-drop, and laser beam) affected coordination and awareness in two tabletop tasks (a game and a storyboarding activity). We found that the choice of <b>interaction</b> <b>technique</b> significantly affected coordination measures, performance measures, and preference – but that the effects were different for the two different tasks. Our study shows that the choice of tabletop <b>interaction</b> <b>technique</b> does indeed matter, and provides insight into how tabletop systems can better support group work...|$|R
40|$|In this {{position}} {{paper we discuss}} the usage of various interaction technologies with focus on the presentations of 3 D visualizations involving a presenter and an audience. While an <b>interaction</b> <b>technique</b> is commonly evaluated from a user perspective, we want to shift the focus from a sole analysis of the naturalness and the ease-of-use for the user, to focus on how expressive and understandable the <b>interaction</b> <b>technique</b> is when witnessed by the audience. The interaction process itself can {{be considered to be}} a communication channel and a more expressive <b>interaction</b> <b>technique</b> might {{make it easier for the}} audience to comprehend the presentation. Thus, while some natural <b>interaction</b> <b>techniques</b> for interactive visualization are easy to perform by the presenter, they may be less beneficial when interacting with the visualization in front of (and for) an audience. Our observations indicate that the suitability of an <b>interaction</b> <b>technique</b> as a communication channel is highly dependent on the setting in which the interaction takes place. Therefore, we analyze different presentation scenarios in an exemplary fashion and discuss how beneficial and comprehensive the involved techniques are for the audience. We argue that <b>interaction</b> <b>techniques</b> complement the visualization in an interactive presentation scenario as they also serve as an important communication channel, and should therefore also be observed from an audience perspective rather than exclusively a user perspective...|$|R
40|$|It has {{recently}} been reported that the CD 40 -CD 40 ligand (CD 40 <b>L)</b> <b>interaction</b> is important in Th 17 development. In addition, transforming growth factor-beta (TGF-β) promotes tumorigenesis as an immunosuppressive cytokine and is crucial {{in the development of}} Th 17 cells. This study investigated the role of CD 40 in breast cancer cells and its role in immunosuppressive function and tumor progression. CD 40 was highly expressed in the breast cancer cell line MDA-MB 231, and its stimulation with CD 40 antibodies caused the up-regulation of TGF-β. Direct CD 40 -CD 40 <b>L</b> <b>interaction</b> between MDA-MB 231 cells and activated T cells also increased TGF-β production and induced the production of IL- 17, which accelerated the proliferation of MDA-MB 231 cells through the activation of STAT 3. Taken together, the direct CD 40 -CD 40 <b>L</b> <b>interaction</b> of breast tumor cells and activated T cells increases TGF-β production and the differentiation of Th 17 cells, which promotes the proliferation of breast cancer cells...|$|R
30|$|In the {{following}} subsections, we firstly describe the related work concerning the chord <b>interaction</b> <b>technique</b> {{and the personal}} windows interface and then, we demonstrate {{the need for a}} toolkit that can handle these multi-user multi-touch techniques and describe what experimental task is needed in order to evaluate this multi-user multi-touch <b>interaction</b> <b>techniques.</b>|$|R
40|$|Researchers have {{developed}} interaction concepts based on mobile projectors. Yet pursuing {{work in this}} area— particularly in building projector-based <b>interactions</b> <b>techniques</b> within an application—is cumbersome and timeconsuming. To mitigate this problem, we contribute ProjectorKit, a flexible open-source toolkit that eases rapid prototyping mobile projector <b>interaction</b> <b>techniques.</b> Author Keywords Mobile projectors, toolkit, rapid prototyping...|$|R
40|$|We {{present a}} set of <b>interaction</b> <b>techniques</b> for {{electronic}} musical performance using a tabletop tangible interface. Our system, the Audiopad, tracks the positions of objects on a tabletop surface and translates their motions into commands for a musical synthesizer. We developed and refi ned these <b>interaction</b> <b>techniques</b> through an iterative design process, in which new <b>interaction</b> <b>techniques</b> were periodically evaluated through performances and gallery installations. Based on our experience refi ning the design of this system, we conclude that tabletop interfaces intended for collaborative use should use <b>interaction</b> <b>techniques</b> designed to be legible to onlookers. We also conclude that these interfaces should allow users to spatially reconfi gure the objects in the interface {{in ways that are}} personally meaningful. Categories and Subject Descriptors H. 5. 2 [User Interfaces]: interaction styles, input devices and strategies J. 5 : [Arts and Humanities]: performing art...|$|R
40|$|<b>Interaction</b> <b>Techniques</b> in Virtual Environments Doug A. Bowman, Chadwick A. Wingrave, Joshua M. Campbell, and Vinh Q. Ly Department of Computer Science (0106) Virginia Tech Blacksburg, VA 24061 USA {bowman, cwingrav, jocampbe, vly}@vt. edu Abstract Usable {{three-dimensional}} (3 D) <b>interaction</b> <b>techniques</b> {{are difficult}} to design, implement, and evaluate. One {{reason for this is}} a poor understanding of {{the advantages and disadvantages of}} the wide range of 3 D input devices, and of the mapping between input devices and <b>interaction</b> <b>techniques.</b> We present an analysis of Pinch Gloves^TM and their use as input devices for virtual environments (VEs). We have developed a number of novel and usable <b>interaction</b> <b>techniques</b> for VEs using the gloves, including a menu system, a technique for text input, and a two-handed navigation technique. User studies have indicated the usability and utility of these techniques. ...|$|R
40|$|International audienceThis paper {{introduces}} a new device model {{and a new}} <b>interaction</b> <b>technique</b> model to deal with plasticity issues for Virtual Reality (VR) and Augmented Reality (AR). We aim to provide developers with solutions to use and create <b>interaction</b> <b>techniques</b> that will fit to the needed tasks of a 3 D application and to the input and output devices available. The device model {{introduces a}} new description of inputs and outputs devices that includes capabilities, limitations and representations in the real world. We also propose {{a new way to}} develop <b>interaction</b> <b>techniques</b> with an approach based on PAC and ARCH models. These techniques are implemented independently of the concrete devices used thanks to the proposed device model. Moreover, our approach aims to facilitate the portability of <b>interaction</b> <b>techniques</b> over different target OS and 3 D framework...|$|R
40|$|BACKGROUND: Our {{previous}} {{studies showed that}} increased levels of cyclophilin A (CyPA) may be a valuable marker for predicting the severity of acute coronary syndromes and that interruption of CD 137 -CD 137 <b>L</b> <b>interactions</b> diminished the formation and progression of atherosclerosis in apolipoprotein E-deficient (ApoE-/-) mice. Here, we sought {{to determine whether the}} proinflammatory factor CyPA is involved in atherosclerosis regulated by CD 137 -CD 137 <b>L</b> <b>interactions.</b> METHODS AND RESULTS: A constrictive collar was placed around the right carotid arteries of ApoE-/- mice that were fed a high-fat diet to induce atherosclerotic plaque formation. After that, the mice were intraperitoneally injected with anti-CD 137 or anti-CD 137 L in {{the presence or absence of}} the recombinant lentiviral vectors LVTHM-CyPA or pGC-FU-CyPA, respectively. Interestingly, activation of CD 137 -CD 137 L was negatively correlated with CyPA expression in vivo and in vitro. Stimulating CD 137 -CD 137 <b>L</b> <b>interaction</b> significantly increased CyPA, which was concurrent with the upregulation of proinflammatory cytokines, chemokines and matrix metalloproteinases and resulted in the promotion of atherosclerosis in ApoE-/- mice. Silencing CyPA could eliminate these effects, and restoration of CyPA effectively and consistently attenuated the atherosclerotic suppression phenotypes elicited by the blockade of CD 137 -CD 137 L. CONCLUSION: These observations suggest that CD 137 -CD 137 <b>L</b> <b>interactions</b> mediated via regulation of CyPA contribute to the progression of atherosclerosis...|$|R
40|$|CD 40 -CD 40 ligand (CD 40 <b>L)</b> <b>interaction</b> is {{required}} for the generation of antibody responses to T-dependent antigens {{as well as for the}} development of germinal centers and memory B cells. The role of the CD 40 -CD 40 <b>L</b> <b>interaction</b> in the induction of antigen-specific Th cells and in mediating Th cell effector functions other than cognate help for B cells is less well understood. Using CD 40 - and CD 40 L-deficient mice together with lymphocytic choriomeningitis virus and vesicular stomatitis virus as viral model antigens, this study corroborates earlier findings that no Ig isotype switching of virus-specific antibodies was measurable upon infection of CD 40 - or CD 40 L-deficient mice. In contrast, in vivo induction of virus-specific CD 4 + T cells measured by proliferation and cytokine secretion of primed virus-specific Th cells in vitro was not crucially dependent on the CD 40 -CD 40 <b>L</b> <b>interaction.</b> In addition, virus-specific Th cells primed in a CD 40 -deficient environment, adoptively transferred into CD 40 -competent recipients, were able to mediate Ig isotype switch. Th-mediated effector functions distinct from and in addition to T-B collaboration were analyzed in CD 40 - and CD 40 L-deficient and normal mice: (a) local inflammatory reactions upon LCMV infection mediated by LCMV-specific Th cells were not dependent on a functional CD 40 -CD 40 <b>L</b> <b>interaction,</b> (b) cytokine-mediate...|$|R
40|$|We {{present a}} study which {{describes}} the power consumption {{characteristics of a}} number of different <b>interaction</b> <b>techniques</b> on a desktop and laptop computer. In total, 8 interactions {{that can be used to}} carry out a single task (navigating a PDF document) were compared for power consumption across both a desktop and a laptop computer and across two different power saver settings. The results suggest that the power consumption of different <b>interaction</b> <b>techniques</b> for a single task vary significantly. Furthermore, the results suggest that a key factor in the power consumption of the <b>interaction</b> <b>technique</b> is the number of screen updates involved...|$|R
40|$|We present 3 dml, a markup {{language}} for 3 D <b>interaction</b> <b>techniques</b> and virtual environment applications that involve non-traditional devices. 3 dml has two main purposes: readability and rapid development. Designers can read 3 dml-based representations of 3 D <b>interaction</b> <b>techniques,</b> compare them, and understand them. 3 dml {{can also be}} used as a front end for any VR toolkit, so designers without programming skills can create VR applications as 3 dml documents that plug together <b>interaction</b> <b>techniques,</b> VR objects, and devices. This paper focuses on the language features and presentation scheme designed in our websit...|$|R
40|$|Mixed-reality {{games have}} the {{potential}} to let users play in the world surrounding them. However, to exploit this new approaches to game content creation, content presentation <b>techniques</b> and <b>interaction</b> <b>techniques</b> are required. In this paper we explore the potential of computer-vision on mobile devices with a camera as an interaction modality. Based on a theoretical review of the available design space potential <b>interaction</b> <b>techniques</b> are discussed. Some of these were implemented in an experimental game to enable practical evaluation. We provide an overview of the game and present intial experiences with the vision-based <b>interaction</b> <b>techniques</b> employed...|$|R
40|$|This paper {{presents}} {{a description of}} the <b>interaction</b> <b>techniques</b> used in the Chapel Hill Immersive Modeling Program (CHIMP). CHIMP is intended for the preliminary stages of architectural design. It is an immersive system; users work directly within a virtual world. The main goal has been to develop <b>interaction</b> <b>techniques</b> that exploit the benefits of working immersed while compensating for its limitations. <b>Interaction</b> <b>techniques</b> described and discussed in this paper include: • Action at a distance • Look-at menus • Remote controls (hand-held widgets) • Constrained object manipulation using twohands • Two-handed control panel interaction • Worlds in miniature • Interactive number...|$|R
40|$|This {{position}} paper presents a model based approach supporting development of advanced user interfaces for the design, simulation, tuning and {{the assessment of}} <b>interaction</b> <b>techniques.</b> It {{is based on a}} double concept: the introduction of additional information in models to allow designer to tune easily the <b>interaction</b> <b>technique</b> and the use of simulation and logging facilities to assess perform performance evaluation of the models. It proposes an alternative to user testing which is very difficult to setup and interpret when advanced <b>interaction</b> <b>techniques</b> are concerned. Author Keywords Model-Based approaches, formal description techniques, performance evaluation, multimodal interfaces, interactive software engineering, tuning...|$|R
40|$|Usable {{three-dimensional}} (3 D) <b>interaction</b> <b>techniques</b> {{are difficult}} to design, implement, and evaluate. One {{reason for this is}} a poor understanding of {{the advantages and disadvantages of}} the wide range of 3 D input devices, and of the mapping between input devices and <b>interaction</b> <b>techniques.</b> We present an analysis of Pinch Gloves™ and their use as input devices for virtual environments (VEs). We have developed a number of novel and usable <b>interaction</b> <b>techniques</b> for VEs using the gloves, including a menu system, a technique for text input, and a two-handed navigation technique. User studies have indicated the usability and utility of these techniques...|$|R
40|$|This article {{summarizes}} the process I have developed to describe, evaluate and facilitate {{the creation of}} novel <b>interaction</b> <b>techniques.</b> First, it presents the CIS model for describing <b>interaction</b> <b>techniques</b> and predicting their effectiveness in real contexts of use. CIS shows {{that there is no}} absolute best technique but that performance depends on the context of use. The article then shows how to improve a technique by optimizing subcomponents of its CIS structure. Finally it describes SwingStates, a toolkit designed to help develop novel <b>interaction</b> <b>techniques</b> by exploring different CIS structures. ACM Classification: D. 2. 2 [Design tools and Techniques]...|$|R
40|$|We {{describe}} {{a demonstration of}} four novel <b>interaction</b> <b>techniques</b> for a cubic head-coupled 3 D display. The interactions illustrated include: viewing a static scene, navigating through a large landscape, playing with colliding objects inside a box, and stylus-based manipulation of objects. Users experience new <b>interaction</b> <b>techniques</b> for 3 D scene manipulation in a cubic display...|$|R
40|$|Designing {{non-traditional}} {{user interfaces}} is a challenging task for designers. NiMMiT, {{a high level}} description for 3 D multimodal interaction in virtual environments, provides a means to design, prototype or communicate about <b>interaction</b> <b>techniques.</b> The focus is on {{making it possible for}} designers to create new <b>interaction</b> <b>techniques</b> while lowering implementation efforts. status: publishe...|$|R
40|$|I present mouse-based, symmetric, bimanual <b>interaction</b> <b>techniques</b> as a {{solution}} to both the lack of spatial input and the lack of natural <b>interaction</b> <b>techniques</b> for direct manipulation in desktop interfaces. I outline the techniques I have implemented and tested thus far and the techniques and interfaces yet to be developed as part of my doctoral thesis...|$|R
40|$|This paper {{introduces}} new <b>interaction</b> <b>techniques</b> for Smart-Skin, {{a sensor}} architecture for freehand manipulation. This sensor recognizes multiple hand positions and shapes and calculates {{the distance between}} the hand and the surface by using capacitive sensing and a mesh-shaped antenna. Our <b>interaction</b> <b>techniques</b> enable the users to use not only their hands, but also their fingers concurrently...|$|R
50|$|In general, {{the less}} {{compatible}} {{the device is}} with the domain object, the more complex the <b>interaction</b> <b>technique.</b> For example, using a mouse to specify a 2D point involves a trivial <b>interaction</b> <b>technique,</b> whereas using a mouse to rotate a 3D object requires more creativity to design the technique and more lines of code to implement it.|$|R
40|$|As {{immersive}} {{virtual environment}} (VE) applications become more complex, {{it is clear}} that we need a firm understanding of the principles of VE interaction. In particular, designers need guidance in choosing three-dimensional <b>interaction</b> <b>techniques.</b> In this paper, we present a systematic approach, testbed evaluation, for the assessment of <b>interaction</b> <b>techniques</b> for VEs. Testbed evaluation uses formal frameworks and formal experiments with multiple independent and dependent variables in order to obtain a wide range of performance data for VE <b>interaction</b> <b>techniques.</b> We present two testbed experiments, covering techniques for the common VE tasks of travel and object selection/manipulation. The results of these experiments allow us to form general guidelines for VE interaction, and to provide an empirical basis for choosing <b>interaction</b> <b>techniques</b> in VE applications. This has been shown to produce measurable usability gains in a real-world VE application. 1. INTRODUCTION Applications of imm [...] ...|$|R
40|$|Gummi is an <b>interaction</b> <b>technique</b> and device concept {{based on}} {{physical}} deformation of a handheld device. The device consists of {{several layers of}} flexible electronic components, including sensors measuring deformation of the device. Users interact with this device {{by a combination of}} bending and 2 D position control. Gummi explores physical <b>interaction</b> <b>techniques</b> and screen interfaces for such a device. Its graphical user interface facilitates a wide range of interaction tasks, focused on browsing of visual information. We implemented both hardware and software prototypes to explore and evaluate the proposed <b>interaction</b> <b>techniques.</b> Our evaluations have shown that users can grasp Gummi's key interaction principles within minutes. Gummi demonstrates promising possibilities for new <b>interaction</b> <b>techniques</b> and devices based on flexible electronic components. Author Keywords Handheld devices, mobile computing, interaction design, GUI, embodied interaction, flexible electronics, smartcards. ACM Classification Keywords H 5. 2. [Information interfaces and presentation (e. g., HCI) ]...|$|R
