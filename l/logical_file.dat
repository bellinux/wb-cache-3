56|39|Public
25|$|A file has event routines. e.g. on <b>logical</b> <b>file</b> end, on {{physical}} file end, on page end, on line end, on format end, on value error, on char error.|$|E
25|$|With {{the advent}} of larger {{removable}} and fixed disk drives, disk de-blocking formulas were employed which resulted in more disk blocks per <b>logical</b> <b>file</b> allocation block. While this allowed for larger file sizes, it also meant that the smallest file which could be allocated increased in size from 1KB (on single-density drives) to 2KB (on double-density drives) and so on, up to 32KB for a file containing only a single byte. This made for inefficient use of disk space if the disk contained {{a large number of}} small files.|$|E
25|$|File settings: this {{category}} contains settings related to files, file handles, record locks, indexes, and log files. The number of open files and <b>logical</b> <b>file</b> handles {{was set in}} here, {{as well as the}} number of record locks per client; index balancing and an option to create files in pre 6.x format are in {{this category}}. It also controlled whether the Microkernel kept a log of operations executed on selected files. In this section the method of file sharing could be set to either MEFS or SEFS. The system transaction hold limit sets the number of system transactions performed during write operations for shared files.|$|E
40|$|A large <b>logical</b> {{register}} <b>file</b> {{is important}} to allow effective compiler transformations or to provide a windowed space of registers to allow fast function calls. Unfortunately, a large <b>logical</b> register <b>file</b> can be slow, particularly {{in the context of}} a wide-issue processor which requires an even larger physical register file, and many read and write ports. Previous work has suggested that a register cache can be used to address this problem. This paper proposes a new register caching mechanism in which a number of good features from previous approaches are combined with existing out-of-order processor hardware to implement a register cache for a large <b>logical</b> register <b>file.</b> It does so by separating the <b>logical</b> register <b>file</b> from the physical register file and using a modified form of register renaming to make the cache easy to implement. The physical register file in this configuration contains fewer entries than the <b>logical</b> register <b>file</b> and is designed so that the physical register fi [...] ...|$|R
50|$|Storage Resource Broker (SRB) was data grid {{management}} {{computer software}} used in computational science research projects. SRB is a <b>logical</b> distributed <b>file</b> {{system based on}} a client-server architecture which presents users with a single global <b>logical</b> namespace or <b>file</b> hierarchy.|$|R
50|$|The {{repository}} stores {{information about}} fields (or data elements) {{in the application}} including descriptions, column headings, edit codes, visualizations, default values, help text, and prompt programs. It holds information about files and application database including physical <b>files,</b> <b>logical</b> <b>files</b> (or views), relationships, file definition attributes, file validation rules, trigger programs, multilingual definitions, virtual fields, and predetermined join fields. Objects and components used for event-driven Windows applications also reside in the repository.|$|R
2500|$|CHKDSK (short for [...] "check disk") is {{a system}} tool in DOS, OS/2 and Windows. It verifies the file system {{integrity}} of a volume and fixes <b>logical</b> <b>file</b> system errors. It {{is similar to the}} fsck command in Unix.|$|E
5000|$|The <b>logical</b> <b>file</b> {{system is}} {{responsible}} for interaction with the user application. It provides the application program interface (API) for file operations [...] - [...] , , , etc., and passes the requested operation to the layer below it for processing. The <b>logical</b> <b>file</b> system [...] "manages open file table entries and per-process file descriptors." [...] This layer provides [...] "file access, directory operations, and security and protection." ...|$|E
5000|$|A {{programmer}} {{who wanted}} {{the benefits of a}} System/38-style <b>logical</b> <b>file</b> would use an Addrout with a RETAIN-S disposition: ...|$|E
50|$|In most {{computers}} {{prior to}} the System/38, and most modern ones, data stored on disk was stored in separate <b>logical</b> <b>files.</b> When data was added to a file {{it was written in}} the sector dedicated to this, or if the sector was full, on a new sector somewhere else. In the case of the S/38, every piece of data was stored separately and could be put anywhere on the system. There {{was no such thing as}} a physically contiguous file on disk, and the operating system managed the storage and recall of all data elements.|$|R
5000|$|Phase 3: <b>Logical</b> {{recovery}} of <b>files,</b> partition, MBR and filesystem structures ...|$|R
5000|$|Archives can be {{organized}} as <b>logical</b> groups of <b>files</b> from directories and subdirectories ...|$|R
50|$|High Sierra Format (HSF) is {{the early}} <b>logical</b> <b>file</b> system used for CD-ROMs in 1985 and 1986. The later ECMA-119 and ISO 9660 {{standards}} are based on revised HSF.|$|E
50|$|Maintaining {{these special}} files on a {{physically}} implemented file system (i.e. harddrive) is inconvenient, {{and as it}} needs kernel assistance anyway, the idea arose of a special-purpose <b>logical</b> <b>file</b> system that is not physically stored.|$|E
5000|$|CHKDSK (short for [...] "check disk") is {{a system}} tool in DOS, OS/2 and Windows. It verifies the file system {{integrity}} of a volume and fixes <b>logical</b> <b>file</b> system errors. It {{is similar to the}} fsck command in Unix.|$|E
5000|$|Copies files in-parallel (multi-threaded): Distributes {{multiple}} threads through <b>logical</b> cores during <b>file</b> copy operations.|$|R
40|$|Prerequisite {{of every}} {{estimation}} technique is effective requirement discovery and planning. FP is observed {{to be good}} source of initial planning. While using Function Point (FP), the whole application is brainstormed. Application is planned with gathering all inputs, outputs, inquiries, external interfaces and files. Whereas use case point (UCP) are limited to identifying actor, and use cases. UCP is not effective in initial planning. Research {{presented in this paper}} takes advantage by combining UCP with FP model in identifying objects like (External Inputs, External Outputs, External Inquiries, External Interface <b>files,</b> Internal <b>Logical</b> <b>files,</b> and others) for each use case. That will help in effective planning of project at initial stages of application. Results show that by combining the FP model and UCP model, component identification enhances by 66 %...|$|R
40|$|We {{present the}} {{architecture}} of a replica management service that manages the copying and placement of files in a high-performance, distributed computing environment to optimize {{the performance of the}} data-intensive applications. This architecture consists of two parts: a replica catalog or repository where information can be registered about <b>logical</b> <b>files,</b> collections of files, and physical locations where subsets of collections are stored; and a set of registration and query operations that are supported by the replica management service. The replica management service can be used by higher-level services such as replica selection and automatic creation of new replicas to satisfy application performance requirements. We describe important design decisions and implementation issues for the replica management service. Design decisions include a strict separation between file metadata and replication information, no enforcement of replica semantics or file consistency, and support for rollback after failures of complex operations. Implementation issues include options for the underlying technology of the replica catalog and the tradeoff between reliability and complexity. ...|$|R
50|$|AdvFS uses a {{relatively}} advanced {{concept of a}} storage pool (called a file domain) and of <b>logical</b> <b>file</b> systems (called file sets). A file domain is composed of any number of block devices, which could be partitions, LVM or LSM devices. A file set is a <b>logical</b> <b>file</b> system created in a single file domain. Administrators can add or remove volumes from an active file domain, providing that there is enough space on the remaining file domain, in case of removal. This {{was one of the}} trickier original features to implement because all data or metadata residing on the disk being removed had to first be migrated, online, to other disks, prior to removal.|$|E
50|$|The DCF {{file system}} adopted by almost all digital cameras since 1998 defines a <b>logical</b> <b>file</b> system with 8.3 filenames {{and makes the}} use of either FAT12, FAT16, FAT32 or exFAT {{mandatory}} for its physical layer {{in order to maximize}} platform interoperability.|$|E
50|$|Of {{course there}} are {{exceptions}} to this, such as cases where severe damage to the hard drive platters may have occurred. However, if the hard drive can be repaired and a full image or clone created, then the <b>logical</b> <b>file</b> structure can be rebuilt in most instances.|$|E
50|$|Some disk {{checkers}} {{can perform}} a whole surface scan {{to attempt to}} find any possible bad sectors, whereas others scan only the <b>logical</b> structure of <b>files</b> on the hard disk.|$|R
40|$|Abstract 1 Data {{distribution}} and replication in distributed systems require special purpose middleware tools for accessing replicated data. Data Grids, special forms of a systems distributed over wide-are networks, need to handle data management issues like {{distribution and}} replication of {{large amounts of}} data in the Tera-and Petabyte scale. Replica catalogues are used for cataloging and locating replicated files in distributed sites all around the globe. We present a novel and scalable approach for distributing a replica catalogue and resolving file location information by using HTTP redirection. HTTP redirection servers managing local file catalogues allow for greater flexibility and local file management autonomy whereas a global replica catalogue provides the necessary mapping of <b>logical</b> <b>files</b> to individual sites. By distributing the catalogues a site can autonomously move files for load balancing within a site without notifying a global replica catalogue. Our approach scales well to {{a large number of}} sites and file entries and thus establishes powerful middleware service. We present the design and implementation of our catalogue redirection servers and report on promising experimental results. ...|$|R
40|$|The paper {{proposes a}} general {{framework}} {{to build a}} model for automatic Function Point Analysis (FPA) from the source code of COBOL system using program slicing technique. The COBOL system source code is scanned by the model to produce Function Point counts. The application's source files are used to define the application's boundary for the count. The model {{takes into account the}} structure of the COBOL language to identify physical files and transactions. Reserved words as FDs, file input/output statements (READ and WRITE) and user interface and data manipulation statements (ACCEPT, DISPLAY and MOVE) are used as basic information for program slicing technique to identify candidate physical files and transactions. Some heuristic rules will be proposed in order to map candidate physical files and transactions into candidate <b>logical</b> <b>files</b> and transactions. These candidate files and transactions are then assessed with regards to the IFPUG' identifying rules in order to identify data function types and transactional function types to be counted. The proposed framework helps to build models for automating Function Point Analysis from source code in compliance with the IFPUG Counting Practices Manual...|$|R
50|$|Byte serving {{can also}} be used by multihomed clients to {{simultaneously}} download a resource over multiple network interfaces. To achieve this type of application-layer link aggregation, multiple HTTP sessions are established and <b>logical</b> <b>file</b> segments are collaboratively downloaded from the server and reassembled at the client. This allows full utilization of several end-to-end paths and therefore leads to an increased download speed.|$|E
50|$|Other formats {{that are}} used in cameras (but not for pictures) are the Design Rule for Camera Format (DCF), an ISO specification, used in almost all camera since 1998, which defines an {{internal}} file structure and naming. Also used is the Digital Print Order Format (DPOF), which dictates what order images are to be printed in and how many copies. The DCF 1998 defines a <b>logical</b> <b>file</b> system with 8.3 filenames and makes the usage of either FAT12, FAT16, FAT32 or exFAT mandatory for its physical layer in order to maximize platform interoperability.|$|E
50|$|With {{the advent}} of larger {{removable}} and fixed disk drives, disk de-blocking formulas were employed which resulted in more disk blocks per <b>logical</b> <b>file</b> allocation block. While this allowed for larger file sizes, it also meant that the smallest file which could be allocated increased in size from 1KB (on single-density drives) to 2KB (on double-density drives) and so on, up to 32KB for a file containing only a single byte. This made for inefficient use of disk space if the disk contained {{a large number of}} small files.|$|E
40|$|Data {{distribution}} and replication in distributed systems require special purpose middleware tools for accessing replicated data. Data Grids, special forms of systems distributed over wide-area networks, need to handle data management issues like {{distribution and}} replication of {{large amounts of}} data in the Tera- and Petabyte scale. Replica catalogues are used for cataloguing and locating replicated files in distributed sites all around the globe. We present a novel and administratively scalable approach for distributing a replica catalogue and resolving file location information by using HTTP redirection. HTTP redirection servers managing local file catalogues allow for greater flexibility and local file management autonomy whereas a global replica catalogue provides the necessary mapping of <b>logical</b> <b>files</b> to individual sites. By distributing the catalogues a site can autonomously move files for load balancing within a site without notifying a global replica catalogue. Our approach scales well in terms of catalogue administration to {{a large number of}} sites and file entries and thus establishes a powerful middleware service. We present the design and implementation of our catalogue redirection servers and report on promising experimental results. Keywords replica catalogue, file replication, Grid, distributed computing. HTTP 1...|$|R
50|$|In computing, file {{virtualization}} {{is a field}} of storage virtualization operating on computer file level. It involves uniting multiple storage devices into a single <b>logical</b> pool of <b>file.</b> It is {{a vital part of}} both file area network (FAN) and network file management (NFM) concepts.|$|R
5000|$|Nirvana is {{the result}} of {{research}} started in 1995 at the San Diego Supercomputer Center (SDSC) (which was founded by and run at the time by General Atomics), in response to a DARPA sponsored project for a Massive Data Analysis System. [...] Led by General Atomics computational plasma physicist Dr. Reagan Moore, development continued through the cooperative efforts of General Atomics and the SDSC on the Storage Resource Broker (SRB), {{with the support of the}} National Science Foundation (NSF). SRB 1.1 was delivered in 1998, demonstrating a <b>logical</b> distributed <b>file</b> system with a single Global Namespace across geographically distributed storage systems.|$|R
50|$|Files in an OS4000 {{filesystem}} are typed, {{which means}} that the filesystem can hold several different types of file, and understands how the contents are structured. Most common are logical files which contain a record structure. These are split into sequential and random files, with random files having all records the same length to enable seeking to record numbers. Finally, text and binary files are distinguished, mainly to prevent applications which expect textual data from accidentally using a binary file. This results in a set of <b>logical</b> <b>file</b> types identified by three letters, e.g. Logical Sequential Text is LST. The <b>logical</b> <b>file</b> types are LST, LSB, LRT, LRB. The converse to logical files are physical files, which are accessed block at a time, and these are known as Physical Random Binary (PRB) files. File types PST, PSB, PRT also exist in theory, but have the same capabilities as PRB and are not generally used. Additionally, there is a Logical Indexed Sequential (LIS) filetype, which is an ISAM file and always appears to be sorted on its key field, and a Byte stream (BYT) filetype, which was added in Rel 6.5 to better support the OS4000 NFS server. A filetype CAT is used to hold catalogues—it is actually the same as an LSB file, but can only be modified by the filesystem itself.|$|E
5000|$|Most {{file storage}} {{utilizes}} layers of redundancy {{to achieve a}} high level of data protection (inability to lose data). Current means of redundancy include replication and parity checks. Such redundancy can be implemented via a RAID array (whereby multiple physical disks appear to a local computer as a single disk, which may include data replication, and/or disk partitioning).Similarly, a grid file system would consist of some level of redundancy (either at the <b>logical</b> <b>file</b> level, or at the block level, possibly including some sort of parity check) across the various disks present in the [...] "Grid".|$|E
5000|$|File settings: this {{category}} contains settings related to files, file handles, record locks, indexes, and log files. The number of open files and <b>logical</b> <b>file</b> handles {{was set in}} here, {{as well as the}} number of record locks per client; index balancing and an option to create files in pre 6.x format are in {{this category}}. It also controlled whether the Microkernel kept a log of operations executed on selected files. In this section the method of file sharing could be set to either MEFS or SEFS. The system transaction hold limit sets the number of system transactions performed during write operations for shared files.|$|E
50|$|The MBR {{holds the}} {{information}} on how the <b>logical</b> partitions, containing <b>file</b> systems, are organized on that medium. The MBR also contains executable code {{to function as a}} loader for the installed operating system—usually by passing control over to the loader's second stage, or in conjunction with each partition's volume boot record (VBR). This MBR code is usually referred to as a boot loader.|$|R
2500|$|The {{original}} reCAPTCHA {{method was}} designed to show the questionable words separately, as out-of-context correction, rather than in use, such as within a phrase of five words from the original document. Also, the control word might mislead context for the second word, such as a request of [...] "/metal/ /fife/" [...] being entered as [...] "metal file" [...] due to the <b>logical</b> connection of <b>filing</b> with a metal tool being considered more common than the musical instrument [...] "fife".|$|R
40|$|Arranging {{characters}} and strings {{in order of}} representation codes is not suitable for application programming. Even when character ordering is <b>logical,</b> the usual <b>filing</b> of words in dictionaries does not correspond with the mathematical lexicographic ordering of strings, but some equivalence relation on characters is involved. As {{a solution to this}} problem, we propose a generic package. The paper also explains the theory behind the solution. Some definitions of classical mathematics are recalled in the appendix...|$|R
