6|20|Public
40|$|In this study, {{the writer}} {{discussed}} about logical connectors showing additive, contrastive, cause and effect, and sequence in the students’ exposition text. This study {{is classified as}} descriptive study. Here, the writer found that {{the most frequently used}} connectors showing additive were ‘and’, ‘also’, ‘such as’, ‘for example’, and the least frequently used connector was ‘in other words’. The writer found that the most frequently used connectors showing contrastive were ‘but’, ‘however’, ‘even though’, ‘although’, and the least frequently used connectors were ‘yet’, ‘though’, ‘instead’. She found that the most frequently used connectors showing cause and effect were ‘because’, ‘if’, ‘so’, ‘because of’, and the least frequently used were ‘as’, ‘due to’, ‘and if’. She also found that the most frequently used connectors showing sequence were ‘when’, ‘while’, ‘after’, and the students applied other various kinds of logical connectors to show sequence in their hortatory exposition text. In her study, the writer found that the most appropriately used connector showing additive was connector ‘and’. The least appropriately used connector was connector ‘in other words’. The most appropriately used connector showing contrastive was connector ‘but’. The students only made mistakes in using connector ‘although’. As a result, the writer concluded that the students could apply logical connectors showing contrastive very well. The writer found that the most appropriately used connector showing cause and effect was ‘because’ and the least appropriately used connector showing cause and effect was connector ‘then’ ix The last category of <b>logical</b> <b>connector</b> that the writer analyzed was logical connectors showing sequence. The most appropriately used <b>logical</b> <b>connector</b> showing sequence was connector ‘when’ and the least appropriately used logical connectors were ‘eventually’, ‘the second’, ‘in the summary’...|$|E
40|$|Event-driven Process Chains (EPCs) {{have been}} helped {{to achieve an}} {{important}} role in business process modeling by the commercial success of SAP and ARIS. Both users and IT experts may describe the process to be modelled from their individual perspectives. Event-driven Process Chains, therefore, create a common platform for communication and the analysis of ideas beyond the boundaries of both application and information-system domains. This is accomplished by a semiformal semantics, which gives the participants greater freedom of expression but leads to unintended ambiguities clearly undesirable in later stages of development such as design and implementation. In the literature, several approaches to this problem have been suggested including definitions of a formal semantics for EPCs. We investigate difficulties with such approaches and suggest two solutions: the introduction of a new <b>logical</b> <b>connector</b> (XORAND) and a slight modification of the OR join. This facilitates the design of cor [...] ...|$|E
40|$|Corrective {{feedback}} (CF), {{the implicit}} or explicit information learners receive indicating {{a gap between}} their current, compared to the desired, performance, has been an area of interest for EFL researchers {{during the last few}} decades. This study, conducted on 139 English-major prospective EFL teachers, assessed the impact of two CF types (implicit vs. explicit) on students ’ ability to detect and correct some “common ” grammatical errors (definite and indefinite article, subject-verb agreement, prepositions, spelling, and <b>logical</b> <b>connector</b> use). The study used a quasi-experimental pretest, posttest with a 12 -week treatment program. The results indicated a statistically significant difference in students ’ performance prior to and after exposure to the intervention, confirming the positive role CF has on students ' performance. However, {{there was no significant difference}} attributed to the type of CF introduced. The paper sets recommendations for both practitioners and researchers and suggests a reconceptualization of the EFL learning process...|$|E
40|$|The {{purpose of}} this section is to explain the meaning of <b>logical</b> <b>connectors</b> with {{specific}} examples. <b>Logical</b> <b>connectors</b> are used in Technical Safety Requirements (TSRs) to discriminate between, and yet connect, discrete Conditions, Required Actions, Completion Times, Surveillances, and Frequencies. The only <b>logical</b> <b>connectors</b> that appear in TSRs are AND and OR. The physical arrangement of these <b>connectors</b> constitutes <b>logical</b> conventions with specific meanings...|$|R
5000|$|In the {{event-driven}} {{process chain}} the logical relationships between {{elements in the}} control flow, that is, events and functions are described by <b>logical</b> <b>connectors.</b> With the help of <b>logical</b> <b>connectors</b> {{it is possible to}} split the control flow from one flow to two or more flows and to synchronize the control flow from two or more flows to one flow.|$|R
5000|$|A {{control flow}} connects events with functions, process paths, or <b>logical</b> <b>connectors</b> {{creating}} chronological sequence and logical interdependencies between them. A control flow is {{represented as a}} dashed arrow.|$|R
40|$|Abstract- Event-driven Process Chains (EPCs) {{have been}} helped {{to achieve an}} {{important}} role in business process modeling by the commercial success of SAP and ARIS. Both users and IT experts may describe the process to be modelled from their individual perspectives. Event-driven Process Chains, therefore, create a common platform for communication and the analysis of ideas beyond the boundaries of both application and information-system domains. This is accomplished by a semiformal semantics, which gives the participants greater freedom of expression but leads to unintended ambiguities clearly undesirable in later stages of development such as design and implementation. In the literature, several approaches to this problem have been suggested including definitions of a formal semantics for EPCs. We investigate difficulties with such approaches and suggest two solutions: the introduction of a new <b>logical</b> <b>connector</b> (XORAND) and a slight modification of the OR join. This facilitates the design of correct EPCs while continuing to allow freedom of expression, thus enabling a smoother transition into the more formal phases of software development such as design and implementation. A comparative experiment validates these results. I...|$|E
40|$|This study {{investigates the}} use of ‘on the other hand’ as a <b>logical</b> <b>connector</b> in the {{academic}} writing of Turkish doctoral students. The learner corpus used is composed of academicallyadvanced non-native students’ doctoral dissertations (applied and theoretical linguistics fields) and the study also compiled the control corpora, {{the first one is}} a corpus of academic essays written by professional native speakers and the second control corpus is The Corpus of Contemporary American English (COCA). Students’ own writings are made comparisons between established writers’ papers in their field and COCA. Despite different genres, established writers’ edited papers are preferred instead of native students’ doctoral dissertations, it gives corpus analysis comparing with genres. The results revealed that the overall frequency of ‘on the other hand’ used by the Turkish doctoral students were greater than that used by the professional writers. However, the Turkish doctoral students did use ‘on the other hand’ in proper manner as natives did, that is, there was not a misused situation from the point of academically-advanced non-native users. The findings also showed that, according to the COCA results, ‘on the other hand’ is more frequent in academic genre, less frequent in spoken, magazine, fiction and newspaper genres, respectively...|$|E
40|$|The aim of {{the present}} study was to analyse leaners’ use of logical {{connectors}} within the EFL classroom setting as well as to provide insights into the effects of instruction on their acquisition process. To this aim, two different types of instructional treatments (i. e. explicit versus implicit) were implemented on two groups of secondary school learners’ to determine progress in the use of logical connectors by comparing the two teaching approaches. The explicit instructional approach was operationalised on the basis of the principles underlying the "focus on form" paradigm providing extensive opportunities for communicative practice together with an explicit type of feedback. In contrast, the implicit one provided learners with exposure to the target items by means of reading comprehension passages and vocabulary work, with fewer opportunities for productive use of the language and an implicit type of feedback. Results showed that both types of instructional treatments proved to be beneficial for learners increasing their use of connectors in written texts. However, the approach that incorporated an explicit focus on form proved to be more effective to enhance learners’ accurate production of the target items. In addition to this, the study also focuses on task demands (free or controlled) regarding accuracy in connector use. Finally, wrong uses of connectors are analysed taking into account aspects such as function and/or type of connector in an attempt to create a taxonomy of <b>logical</b> <b>connector</b> errors. It is suggested that specific types of errors may be found within local or global discourse levels affecting learners’ discourse competence in various ways...|$|E
40|$|Abstract: The tool HENSHIN is an Eclipse plug-in {{supporting}} visual {{modeling and}} execution of rule-based EMF model transformations. This paper describes the recent extensions of HENSHIN by control structures for controlled rule applications. The control structures comprise well-known imperative structures like sequences and conditions on rule applications. Moreover, application conditions for individual rules may now be arbitrarily nested and combined by <b>logical</b> <b>connectors.</b> We present {{the extension of the}} visual EMF model transformation environment HEN-SHIN to edit and perform controlled EMF model transformations along an example modeling a reactive Web service-based application (personal mobility manager) ...|$|R
5000|$|Functions {{are active}} {{elements}} in an EPC. They model the tasks or activities within the company. Functions describe transformations from an initial state to a resulting state. If different resulting states can occur, {{the selection of}} the respective resulting state can be modeled explicitly as a decision function using <b>logical</b> <b>connectors.</b> Functions can be refined into another EPC. In this case it is called a hierarchical function. Examples of functions are [...] "capture requirement", [...] "check material in stock", etc. In the event-driven process chain graph a function is represented as rounded rectangle.|$|R
40|$|AbstractThe role of logical/mathematical {{intelligence}} in SL writing has not clearly been discovered, and linguistic intelligence is {{claimed to be}} the key factor responsible for SL skills. This study attempts to investigate the relationship between quantitative usage of <b>logical</b> <b>connectors</b> in terms of both token and type, in Iranians’ EFL essay writing and their logical/mathematical and linguistic intelligences. The required data was supplied from a corpus of 300 essay-type compositions written by 100 sophomore English major students, as well as an intelligence questionnaire. The findings revealed that EFL students with higher logical/mathematical intelligence tend to use more logical-connectors in their essay writing...|$|R
40|$|We {{develop a}} general study of graded {{consequence}} (of many-valued logic) {{in an institution}} theoretic (in the sense of Goguen and Burstall) style. This means both syntax and semantics are considered fully abstract, {{as well as the}} satisfaction between them. Our approach contrasts to other approaches on many-valued logic in that it is a multi-signature one, in the spirit of institution theory. We consider graded consequence at three different conceptual levels: entailment, semantic, and closure operators, and explore several interpretations between them. We also study <b>logical</b> <b>connectors</b> and quantifiers both at the entailment and semantic level, compactness and soundness properties. 1...|$|R
40|$|As the {{scientific}} pursuit progresses, {{the number of}} tech-nical terms in sciences {{is always on the}} rise. However, the use of knowledge organizers, more or less, remain constant. Knowledge organizers consist of (1) the types of concepts (Metatypes) used in knowledge (2) types of relations used to relate the concepts (Relation types) and (3) <b>logical</b> <b>connectors</b> and quantifiers used to ex-press the knowledge. Representing common sense knowledge using these minimal knowledge organizers is highly challenging, and often impossible since generalizations of common knowledge may not always work. However, much of scientific knowledge uses a small subset of our natural language since scientific language is highly conven-tional and formal. Our attempt is to represent alread...|$|R
50|$|In mathematics, the Tarski-Seidenberg theorem {{states that}} a set in (n + 1)-dimensional space defined by {{polynomial}} equations and inequalities can be projected down onto n-dimensional space, {{and the resulting}} set is still definable in terms of polynomial identities and inequalities. The theorem - {{also known as the}} Tarski-Seidenberg projection property - is named after Alfred Tarski and Abraham Seidenberg. It implies that quantifier elimination is possible over the reals, that is that every formula constructed from polynomial equations and inequalities by <b>logical</b> <b>connectors</b> ∨ (or), ∧ (and), ¬ (not) and quantifiers ∀ (for all), ∃ (exists) is equivalent with a similar formula without quantifiers. An important consequence is the decidability of the theory of real-closed fields.|$|R
40|$|A {{method is}} {{proposed}} for decomposing {{the decision making}} process based on risk factors in product development (e. g., redesign risk, schedule risk). The IDEF 3 methodology is used to capture the macro-decision structure of the design process. Decision sets are identified based on <b>logical</b> <b>connectors</b> in the IDEF 3 model. Each decision set corresponds to alternative paths through the IDEF 3 model. A risk value is calculated for each path, thus, providing a measure of risk for the corresponding decision set. As a result, the paper (1) provides a method for decomposing the complex decision process inherent to concurrent design, and (2) extends the usefulness of IDEF 3 models by integrating IDEF 3 semantics, quantitative data, and a formal analysis procedure...|$|R
40|$|International audienceThis paper {{presents}} a methodology for interoperability testing based on contextual signatures and passive testing with invariants. The concept of contextual signature offers a framework to add {{information on the}} states, the values of parameters, as well as <b>logical</b> <b>connectors</b> that increases the expressive power of invariants. This allows expressing horizontal and vertical interoperability properties, i. e., between layers of a protocol stack or end-to-end communication between distant entities. In order to test interoperability, we have defined a correlation algorithm between the events collected from different network views (client or network side). Once the correlation has been performed, we apply the contextual signatures that characterize interoperability properties to check their validity. To illustrate {{the application of the}} proposed approach, a real case study is proposed: the Wireless Application (WAP) protocol. The results of the experimentation performed on this protocol are also presente...|$|R
40|$|This paper {{sets out}} to {{evaluate}} the effect on learners’ knowledge and use of language of one prominent technique in corpus pedagogy, the data-driven use of corpus concordances with learners as researchers, or Data-Driven Learning (DDL) (Johns 1988, 1991). More specifically, the paper attempts measurement {{of the effect of}} DDL on the achievement of the goal of appropriate production by learners of <b>logical</b> <b>connectors,</b> an important subskill {{in the context of the}} wider objective of the acquisition of basic academic writing skills in English. The evaluation uses learner corpora from experimental and control groups, supported by other methods. The conclusion is that DDL, applied in the context of the communicative teaching of writing skills, is moderately effective, and that there is potential both for the further development of learner corpora in an evaluative role, and for use of a wider range of instrumentation...|$|R
30|$|The {{search string}} was {{developed}} considering {{three groups of}} terms that were joined with the operator AND. The first group includes terms related to SPC. The second includes terms related to measures and the third includes terms related to software. Within the groups, we used the OR operator to allow for synonyms. The following search string was used: (“statistical process control” OR “SPC” OR “quantitative management”) AND (“measurement” OR “measure” OR “metric” OR “indicator”) AND (“software”). To establish this search string, we performed some tests using different terms, <b>logical</b> <b>connectors,</b> and combinations among them. More restrictive strings excluded some important publications identified during the informal literature review that preceded the systematic mapping. These publications were used as control publications, meaning that the search string {{should be able to}} retrieve them. We decided to use a comprehensive string that provided better results in terms of number and relevance of the selected publications, even though it had selected many publications eliminated in subsequent steps.|$|R
3000|$|... {{consisting}} of a finite set of predicate symbols (denoting the table names; for example, Ill, Treat or P), a possibly infinite set dom of constant symbols (denoting the values in table cells; for example, Mary or a), and an infinite set of variables (x or y). A term is either a constant or a variable. The capital letter X denotes a vector of variables; if the order of variables in X does not matter, we identify X with the set of its variables and apply set operators - for example we write y ϵ X. We use the standard <b>logical</b> <b>connectors</b> conjunction ∧, disjunction ∨, negation - and material implication → and universal ∀ as well as existential ∃ quantifiers. An atom is a formula {{consisting of}} a single predicate symbol only; a literal is an atom (a “positive literal”) or a negation of an atom (a “negative literal”); a clause is a disjunction of atoms; a ground formula is one that contains no variables; the existential (universal) closure of a formula ϕ is written as ∃ϕ (∀ϕ) and denotes the closed formula obtained by binding all free variables of ϕ with the respective quantifier.|$|R
40|$|Chinese {{writers of}} {{academic}} texts in English demonstrate a clear tendency to place in sentence-initial position certain topic-fronting devices (beginning For and Concerning), and <b>logical</b> <b>connectors</b> (Besides, Furthermore and Moreover) to introduce new information. When fronted in this way, these items usurp {{the position of}} the information structure element referred to in systemic-functional linguistics as theme. Theme functions in discourse to convey given or known information, but when theme position is occupied by new information, that information may constitute a marked theme. To establish empirically that Chinese subjects utilise theme position in the way described, a non-native speaker (NNS) corpus of academic writing produced by Chinese subjects was tagged to detect occurrences of the two topic-fronting devices and the three thematised connectors. The same phenomena were similarly investigated in three native-speaker (NS) corpora. The findings demonstrate that Chinese subjects do have a greater tendency than native speakers to place the connectors under consideration in theme position, but the findings are less clear for the topic-fronting devices. This empirical study was followed by an exercise in which texts containing marked themes were analysed {{to determine the effects of}} the markedness on information structure. It was found that inappropriate occupation of theme position by the items under consideration here has a deleterious effect on information structure and that this, in turn, has negative effects on both local and global text coherence. © 2000 The American University. Published by Elsevier Science Ltd. All rights reserved. link_to_subscribed_fulltex...|$|R
40|$|The {{compulsory}} subject Life Orientation {{in the school}} curriculum serves {{a central role in the}} socialization of learners into the constitutional imperative of non-discriminatory and democratic values as evidenced by the specific subject aims contained in the CAPS statement. Given the dearth of knowledge in the area of sexuality and the formation of sexual identity through curriculum materials, and framed by the sociological view that sexuality and sexual identity is a social construction, the aim of this study was to investigate the representation/construction of sexualities and sexual identities in a sample of Grade 10 Life Orientation textbooks. The study is informed by critical discourse theory in conjunction with queer theory and examines the vocabulary, grammar and textual structures of language, to expose how representations of sexuality implicitly and explicitly function to a construct and transmit dominant form of sexual identity. A selection of the content of three Life Orientation textbooks was analysed in terms of coverage given to LGBT sexualities and heterosexualities, using a quantitative research approach. The context and quality of those representations was also interrogated using qualitative methods including thematic content analysis and a queer critical discourse analysis to examine the discursive construction of those representations. A standard hegemonic notion of heterosexuality appears to be the all-pervasive and unexamined norm in the Life Orientation textbooks whereas LGBT identities, as revealed by a content and thematic analysis, are virtually invisible. Generally it would appear that Life Orientation textbooks transmit a dominant notion of heterosexuality as the norm, arising out of a common-sense understanding of sexuality which naturalizes a form of heterosexuality that privileges male desire and subordinates women. These underlying ideological meanings are revealed through an examination of the experiential, relational and expressive value of the language such as the lexicalization (connotations and denotations), overlexicalization, classificatory schemes, euphemism and register. Grammatical features for instance active and passive voice, nominalization, modality and the use of <b>logical</b> <b>connectors</b> also serve to bolster a heterosexual sexuality in the Life Orientation textbooks. Frequently, the stated intention of the writers to challenge stereotypes and prejudice would appear to be contradicted or betrayed by the language used and illustrations which further reinforce heterosexuality as a universal norm. Where LGBT identities are mentioned it is usually in the context of human rights, abuse, violation, pathology and emotional disorder...|$|R
40|$|Component-based {{software}} engineering aims to reduce software development effort by reusing established components as {{building blocks of}} complex systems. Defining components in general-purpose programming languages restricts their reuse to platforms supporting these languages and complicates component composition with implementation details. The vision of model-driven engineering {{is to reduce the}} gap between developer intention and implementation details by lifting abstract models to primary development artifacts and systematically transforming these into executable systems. For sufficiently complex systems the transformation from abstract models to platform-specific implementations requires augmentation with platform-specific components. We propose a model-driven mechanism to transform platform-independent <b>logical</b> component & <b>connector</b> architectures into platform-specific implementations combining model and code libraries. This mechanism allows to postpone commitment to a specific platform and thus increases reuse of software architectures and components. Comment: 10 pages, 4 figures, 1 listin...|$|R
40|$|This {{research}} critically analyses {{the different}} types of clinical data representation used in modelling Clinical Information Systems (CIS) and their limitations. It identifies space complexity, information overload, performance degradation, erroneous data retrieval and transmission as some of the main challenges caused by inappropriate data representation. Literature reviewed, indicated that object-oriented Health Level 7 (HL 7), Entity Attribute Value (EAV), Advanced ERD with XML, and ERD –FOL (First Order Logic) are some of the contemporary methods used in modelling and optimising CIS. However, these approaches do not address the space complexity and information overload issues because of the multi-dimensional, complex large-scale nature of clinical datasets. Therefore, this research proposes a unique framework that uses object-oriented (UML) technique and combinatorial multiple attribute utility theory (CMAUT) as a new clinical data re-representation. In the CMAUT framework, the human organs, their multiple attributes and relationships are modelled using classes. The attributes of each organ class are written as logical expressions using CMAUT concepts, which are linked to each other with <b>logical</b> <b>connectors</b> AND for complementary organs such as cardiovascular and OR for substitutable organs like kidneys. The logical expressions are converted into mathematical format, which serves as the utility objective function that is optimised using linear programming method subject to a set of constraint matrix. The constraint matrix is generated by transforming the multiple attributes in the CMAUT expressions into algebraic expressions by applying an algorithm that uses unit matrix and Raman transformation table. The output of the framework gives a set of attribute values, which optimal value maximises the overall utility of the objective function in the combinatorial organs. The algorithm maps the resultant attribute values to the appropriate attributes of the organs to determine the optimal amount of data required to be retrieved for primary health care investigation. The framework retrieves and transmits only needed data for investigation thus reducing the information overload and space complexity in the CIS. The framework was implemented using the MATLAB software and validated with clinical data from the cardiovascular disease survey in England report. Functionality test conducted, revealed that for complementary organs the space complexity is θ (n + 1) using the framework and θ (2 n) without the framework. Substitutable organs gave an exponential expansion of θ (2 n) in both cases. Simulation conducted showed that the mean size of the data retrieved for investigation using the framework is 463. 5 bytes as compared to 1216. 6 bytes without it. Statistical tests carried out using the output data from the framework gave a p-value of 0. 000. Hence the hypothesis that the amount of data required for primary care health investigation can be reduced when the clinical data is re-represented with UML/CMAUT and optimised using LP based algorithm is statistically significant. For hypertension disease, by converting the optimal values from the framework into percentages give results similar to the percentage risk of the user been hypertensive. The output values were benchmarked against Framingham web based heart risk calculators and statistically analysed. Hence, the novelty of the framework is that it can be used for optimising CIS, as a multi-attribute decision tool and as an epidemiological prediction model for detecting high blood pressure diseases...|$|R
40|$|Software {{architecture}} is {{the means to}} cope with the complexity of large software systems. Typically architecture separates different concerns: at development time modules and relationships are in the focus, at deployment time binaries and physical nodes with their hardware constraints are considered. At execution time, runtime structures like communication protocols, threads, processes or sockets are of interest. Understanding the principal units of computation and analyzing certain runtime qualities of a system (e. g., availability or security and certain aspects of efficiency) requires having a Component and Connector view. The Component and Connector view addresses the communication and distribution related concerns at architectural level. It provides abstractions like <b>logical</b> components and <b>connectors,</b> ports, roles and protocols. As a matter of fact this kind of information is frequently missing or outdated in architectural documentation, so systematic reasoning about components and connectors and hence runtime structures and their qualities, is practically impossible. To overcome this issue, a method for reconstructing Component and Connector models from static source code is presented in this thesis. The method provides {{a detailed description of the}} reconstruction process and comes along with an Eclipse based tool support. The tool guides the user through the reconstruction process and automates error-prone, time consuming and complex reconstruction steps. As a proof of concept for the method, the Component and Connector model of a system in the ambient assisted living domain was successfully reconstructed. The applicability and suitability of the CoVeR method was shown and the approach promises to deliver practical relevant reconstruction results in an effort-efficient manner...|$|R
40|$|ScienceDirect {{is not a}} {{standard}} database — subject specific databases have a better range of relevant journals and normally also include books. However: • ScienceDirect is a convenient and prompt source of full-text articles, if you select the “Journals ” option (# 3 page 2). • ScienceDirect is easily searched by keywords or phrases; yet the search software is also capable of sophistication — including full-text searching. • Perhaps expand {{the list of the}} Search Results from mere Citations to Full or Partial Abstracts + Citations & sort by relevance (# 28 - 29 page 6). • Use PDF when printing out a copy of the article (page 7). • Use Full Text + Links to browse an article, or to copy & paste text or diagrams from the current article into other documents (page 7). • Results may be saved directly into an EndNote library (page 8). • An important searches is easily converted into a Search Alert (page 8). • You may arrange to be advised by email as soon as journals you have chosen have new issues added to ScienceDirect (page 10 - 11). When Searching • Use your personal ScienceDirect log-in (page 1). • Normally, use the singular form of the word (page 3). • Consider using truncation! (page 3). • Use relevant, specific search terms (page 4). • Consider alternative spellings and reasonable synonyms (page 4). • Use connectors (page 4 - 5), especially W/nn • Use brackets if you are unsure of the <b>logical</b> priority of <b>connectors</b> (page 5). • Searching is not case-sensitive — i. e., lower & UPPER cases are equivalent...|$|R

