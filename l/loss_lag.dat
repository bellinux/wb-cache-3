0|41|Public
30|$|Finally, we also {{investigated}} the longer run implications of job loss {{for mental health}} by re-estimating our main specifications including a measure of job <b>loss</b> <b>lagged</b> one period. 9 In almost all cases, the substantive effect of recent job loss remains virtually unchanged {{and there is no}} evidence of long-term mental health effects of spousal and parental job loss. The exception is that the negative impact of husbands’ recent job loss with women’s mental health is statistically significant and somewhat larger in absolute magnitude, while <b>lagged</b> job <b>loss</b> is also associated with a significant reduction in women’s mental health.|$|R
50|$|Iowa {{fought a}} good game and scored a late {{touchdown}} to avoid the shutout, but the 17 points assembled by the Cornhuskers sent the Hawkeyes home with a <b>loss</b> and <b>lagging</b> in the series 4-6-2.|$|R
40|$|The {{effect of}} basin size on runoff {{characteristics}} is investigated. The maximum observed floodflow, the maximum annual constant <b>loss,</b> the <b>lag</b> {{time and the}} unitgraph peak for a certain storm duration of basins in the western and northwestern regions of Greece are increasing power functions of the basin size. These functions explain significantly the variation in the runoff characteristics. Fo...|$|R
40|$|This paper aims {{to discuss}} the {{relationship}} among the wave height, wind speed and water depth on muddy coast, to establish the temporal relationship between the on-way loss of the wave power and the vertical power of the suspension sediment on the muddy coast, {{and to try to}} prove the significance of wave-induced current on muddy coast and its remarkable influence on local fluid state. Taking Lianyungang(China) as example, the works have been done as follows: First, the notable relationship between two dimensionless quantities, relative wave height and relative wind speed, is studied through theoretical analysis and verifying base on observation data. And then, the process of the wave power on-way loss was calculated trough the mathematical wave model at Lianyungang in Typhoon Wipha(2007). Both the observation data and the model result show that the process of wave power on-way <b>loss</b> <b>lags</b> behind that of wave height and is in good agreement with the process of suspension sediment concentration...|$|R
50|$|The now-annual grudge match, where Nebraska {{continuously}} {{seemed to}} find futility in their repeated attempts to knock off Minnesota, was {{a repeat of the}} last several contests. Things were looking up for the Cornhuskers when they capitalized on a Golden Gopher error to score first, but a couple of field goals by Minnesota reversed the lead and yet again sent Nebraska home with a <b>loss,</b> seriously <b>lagging</b> in the series 1-6.|$|R
50|$|Although Nebraska and Colorado had met on {{the field}} six times before, {{this was the first}} since a 22-8 Nebraska victory from 1907, and the first time the teams had met as conference foes. The Buffaloes sent Nebraska back to Lincoln with a 6-19 <b>loss,</b> but still <b>lagged</b> in the series at 2-5.|$|R
40|$|Whole {{grains of}} emmer wheat were heated in a {{pre-heated}} tube oven at temperatures ranging from 130 – 700 °C under controlled anoxic conditions for maximum 280 min. For each temperature a separate experiment was carried out. Physical properties including mass <b>loss,</b> thermal <b>lag,</b> {{external and internal}} morphology and the vitrinite reflectance, C and N content, and DTMS under CI (NH 3) and EI conditions were used to monitor changes {{as a function of}} the temperature. The results show remaining starch and protein rich material up to 250 °C. From 310 – 400 °C a secondary, thermally stable, product is formed and at higher temperatures a strongly carbon enriched tertiary product...|$|R
40|$|ABSTRACT The {{effect of}} basin size on runoff {{characteristics}} is investigated. The maximum observed floodflow, the maximum annual constant <b>loss,</b> the <b>lag</b> {{time and the}} unitgraph peak for a certain storm duration of basins in the western and northwestern regions of Greece are increasing power functions of the basin size. These functions explain significantly the variation in the runoff characteristics. For both regions single relationships are derived for the latter two characteristics, whereas for the two former ones they vary regionally in accordance to the climatic conditions. Thus, care is needed in transferring such relationships outside the location of their derivation; besides, the transferability {{of the values of}} their parameters is doubtful. The derivation of the relationships in th...|$|R
40|$|Pipe Transporting 4 fluid are lagged for threereasoris : a. 	To reduce {{transfer}} and los of energy b. 	To Prevent The fluid freezing c. 	To safeguard personnel If to safe guard is the reaason for lagging, then minimal amount of insulation is applied, consitent with safety considerations. For reason to reduce {{transfer and}} loss of energy and prevent the fluid freezing, the whole life cycle cost should be considered : i. e., the savings Affected by reducing the energy losses and cost of insulation should be compared. Lagging is applied, sufficient to Produce a credit balance. Energy loss depends on : -	The difference in temperature between the steam inside and the air outside the pipe -	the pipe thickness The velocity of the steam in the pipe -	The state of the air surrounding the pipe (srill or in motion) -	condition of the steam (saturated or super heated) The loss of energy take place partly by convection, but mainly by radiation. It is greater when the steam is flowing through the pipe and not quiescent. If saturated steam is used, A film of water is deposited {{on the inside of}} the pipe. This aids the transfer of energy, and more energy cost as A result. The fact that the use of superheated steam permits A. Reduction of temperatur without depositing moisture account for some of the ecomo my attending its use. In the majority of cases of heat transmision that arise in engineering practice, heat flows from some medium through a solid retaining wall into some other medium. Percentage saving of energy due to lagging is : Energy loss (unlagged) - Energy <b>loss</b> (<b>lagged)</b> Energy <b>loss</b> (unlagged) ...|$|R
50|$|Rapid {{increases}} in phytoplankton growth, that typically occur {{during the spring}} bloom, arise because phytoplankton can reproduce rapidly under optimal growth conditions (i.e., high nutrient levels, ideal light and temperature, and minimal losses from grazing and vertical mixing). In terms of reproduction, many species of phytoplankton can double at least once per day, allowing for exponential {{increases in}} phytoplankton stock size. For example, the stock size of a population that doubles once per day will increase 1000-fold in just 10 days. In addition, there is a lag in the grazing response of herbivorous zooplankton {{at the start of}} blooms, which minimize phytoplankton <b>losses.</b> This <b>lag</b> occurs because there is low winter zooplankton abundance and many zooplankton, such as copepods, have longer generation times than phytoplankton.|$|R
30|$|The dynamic {{viscoelastic}} {{properties of}} Chinese fir (Cunninghamia lanceolata) with a moisture content of 10.65  % (30  °C, 58  % RH) under cyclical relative humidity (RH) variation (90 – 10  % RH) were examined. After seven-cycle RH changes, moisture content of specimens decreased. The storage modulus and loss factor increased and decreased, respectively. The occurrences of local maximum or minimum {{values of the}} storage modulus and <b>loss</b> factor <b>lagged</b> behind the occurrences of the maximum or minimum values of RH. Both lagged time and changing rate of storage modulus and loss factor decreased with the increasing cyclical times. When RH decreased from 90 to 10  % RH, the increasing rate of the storage modulus decreased with the decreasing of RH, while the loss factor decreased almost linearly. The unsteady effect and its partial recovery were observed during the desorption and the adsorption process, respectively. With the increasing cyclical times, the unsteady effect decreased and wood returned back to the dynamic equilibrium state gradually.|$|R
40|$|We {{analyze the}} {{relationship}} between insurance rate regulation, inflationary cost surges, and incentives for loss control using state-level data on workers' compensation insurance for 24 states during 1984 - 90. Regulators often responded to rapid loss growth during this period by denying rate increases or approving increases that were less than initially requested by insurers. We test whether rate suppression increased loss growth by distorting incentives for loss control. Our regressions indicate a positive and statistically reliable relationship between <b>loss</b> growth and <b>lagged</b> measures of regulatory price constraints, suggesting that rate regulation increased the frequency and/or severity of employee injuries. Copyright 2000 by University of Chicago Press. ...|$|R
40|$|We analyse {{determinants}} of bank credit losses in Australasia. Despite sizeable credit losses {{over the past}} two decades, ours is the first systematic study to do so. Analysis is based on a comprehensive dataset retrieved from original financial reports of 32 Australasian banks (1980 - 2005). Credit losses rise when the macro economy is weak. Asset markets, particularly the equity market, are also important. Larger banks provide more for credit losses while less efficient banks have greater asset quality problems. Strong loan growth translates into significantly higher credit <b>losses</b> with a <b>lag</b> of 2 - 4 years. Finally, the results show strong evidence of income smoothing activities by banks. banking; credit risk; loan loss provisions; Australia; New Zealand...|$|R
40|$|Drivers {{of credit}} losses in Australasian banking Based on a {{comprehensive}} dataset retrieved from original financial reports of 32 Australasian banks (1980 – 2005), this paper explores factors affecting the credit loss experience of these institutions. It is {{found that the}} state of economy as measured by GDP growth and unemployment rate have the expected impact. Asset markets are also important, with the performance of the equity market showing greater explanatory power than property prices. Larger banks, on average, provide more for credit losses while less efficient banks have greater asset quality problems. Strong loan growth translates into significantly higher credit <b>losses</b> with a <b>lag</b> of 2 – 3 years. Finally, the results show strong evidence of income smoothing activities by banks...|$|R
40|$|Thesis (M. S.) University of Alaska Fairbanks, 2007 The Kodiak SuperDARN (Super Dual Auroral Radar Network), {{located on}} Kodiak Island, Alaska, is a coherent-backscatter radar {{sensitive}} to Bragg scatter from ionospheric irregularities. SuperDARN transmitters {{send out a}} sequence of seven pulses that aid {{in the formation of}} complex autocorrelation functions (ACFs). These ACFs allow for estimating the power, velocity and the spectral widths of the scattering plasma waves. However, the multipulse sequence used currently has some characteristics that are not ideal for the intended purpose. In addition, the analysis technique for estimating the properties of the ACF assumes that there is only a single velocity component present in each range cell at one time. In this study, the aperiodic radar technique designed by Dr. John D. Sahr and Dr. Sathyadev. V. Uppala was investigated to design an optimized transmission sequence that would have no repeated lags, a minimum number of inherently missing <b>lags</b> and no <b>loss</b> of <b>lags</b> due to Tx-on/Rx-off conflicts. With the designed transmission sequence, efficient analysis of data is possible {{through the use of a}} standard spectral estimator, the modified covariance technique. The design enhances the ability of the radar to discriminate targets in the same range bin...|$|R
40|$|International audienceEnergy saving {{interventions}} for historical buildings require an accurate study on measures {{to be adopted}} and on the modalities of their application. This {{is in terms of}} energetic renovation with particular reference to historical, artistic and landscape profiles, considering that the substantial character and aesthetic aspects of the buildings are not to be changed. These types of buildings must be preserved and enhanced, beyond a binding adaptation to the regulation requirements. This study analyses the use of an innovative material, the silica aerogel, with the aim of achieving a high level of energy improvement. In many of the cases subject of numerical studies, buildings equipped with the aerogel-based thermal insulation show better hygro-thermal performance than when using other insulating materials. The objective {{of this study is to}} develop numerical models in Energy Plus, based on a targeted case study, to examine different exterior wall structures insulation and related energy behavior, considering defined assessment criteria such as heat <b>losses,</b> time <b>lag,</b> decrement factor, comfort index. The thickness dependency on annual heating set point, the heating and cooling load, and the operating costs are also investigated. The thermal performance of walls with aerogel-based insulation is compared with different insulating materials and configurations, applied on the historical building structure. Finally, a cost analysis for the different solutions, different climates, in retrofitting of historical buildings, is taken into consideration...|$|R
40|$|The 6 -year wind {{archives}} {{from the}} Goddard Institute for Space Studies/Global Climate-Middle Atmosphere Model (GISS/GCMAM) were in- {{put to the}} GISS/Harvard/Irvine Chemical Transport Model (G/H/I CTM) to study the seasonal and interannual variability of the budgets and distributions of nitrous oxide (N 2 O) and trichlorofluoromethane (CCl 3 F), with the corresponding chemical loss frequencies recycled and boundary conditions kept unchanged from year to year. The effects of ozone feedback and quasi-biennial oscillation (QBO) were not included. However, the role of circulation variation in driving the lifetime variability is investigated. It {{was found that the}} global loss rates of these tracers are related to the extratropical planetary wave activity, which drives the tropical upward mass flux. For N 2 O, a semiannual signal in the loss rate variation is associated with the interhemispheric asymmetry in the upper stratospheric wave activity. For CCl 3 F, the semiannual signal is weaker, associated with the comparatively uniform wave episodes in the lower stratosphere. The <b>loss</b> rates <b>lag</b> behind the wave activity by about 1 - 2 months. The interannual variation of the GCM generated winds drives the interannual variation of the annually averaged lifetime. The year-to-year variations of the annually averaged lifetimes can be about 3 % for N 2 O and 4 % for CCl 3 F...|$|R
40|$|The {{phases of}} the {{embodiment}} stage are sequentially conceived and in some domains even cyclic conceived. Nevertheless, there is no seamless integration between these, causing longer development processes, increment of time <b>lags,</b> <b>loss</b> of inertia, greater misunderstandings, and conflicts. Embodiment Discrete Processing enables the seamless integration of three building blocks. 1) Dynamic Discrete Representation: it is capable to concurrently handle the design and the analysis phases. 2) Dynamic Discrete Design: it deals with the needed modeling operations while keeping {{the consistency of the}} discrete shape. 3) Dynamic Discrete Analysis: it efficiently maps the dynamic changes of the shape within the design phase, while streamlining the interpretation processes. These integrated building blocks support the multidisciplinary work between designers and analysts, which was previously unusual. It creates a new understanding of what an integral processing is, whose phases were regarded as independent. Finally, it renders new opportunities toward a general purpose processing...|$|R
40|$|Although an {{extensive}} literature has developed on modeling the loss reserve runoff triangle, {{the estimation of}} severity distributions applicable to claims settled in specific cells of the runoff triangle has received little attention in the literature. This paper proposes {{the use of a}} very flexible probability density function, the generalized beta of the 2 nd kind (GB 2) to model severity distributions in the cells of the runoff triangle and illustrates the use of the GB 2 based on a sample of nearly 500, 000 products liability paid claims. The results show that the GB 2 provides a significantly better fit to the severity data than conventional distributions such as the Weibull, Burr 12, and generalized gamma and that modeling severity by cell is important to avoid errors in estimating the riskiness of liability claims payments, especially at the longer <b>lags.</b> <b>Loss</b> distributions, loss reserves, generalized beta distribution, liability insurance, Risk and Uncertainty, C 16, G 22,...|$|R
40|$|We {{present the}} {{analytical}} {{solution of the}} two-integrals Jeans equations for Miyamoto-Nagai discs embedded in Binney logarithmic dark matter haloes. The equations can be solved (both with standard methods and with the Residue Theorem) for arbitrary choices of the parameters, thus providing a very flexible two-component galaxy model, ranging from flattened discs to spherical systems. A particularly interesting case is obtained when the dark matter halo reduces to the Singular Isothermal Sphere. Azimuthal motions are separated in the ordered and velocity dispersion components by using the Satoh decomposition. The obtained formulae {{can be used in}} numerical simulations of galactic gas flows, for testing codes of stellar dynamics, and to study the dependence of the stellar velocity dispersion and of the asymmetric drift in the equatorial plane as a function of disc and halo flattenings. Here, we estimate the inflow radial velocities of the interstellar medium, expected by the mixing of the stellar mass <b>losses</b> of the <b>lagging</b> stars in the disc with a pre-existing gas in circular orbit. Comment: 13 pages, 6 figures. Accepted for publication in MNRA...|$|R
40|$|Actuator disk {{models can}} have {{internal}} {{degrees of freedom}} as, for example, in the case for models with <b>lagged</b> <b>losses,</b> governed by additional differential equations. Generally, being a system with distributed parameters, flow in the interblade passage has {{an infinite number of}} internal degrees of freedom. An attempt is made to estimate how many of them can be distinguished as the most important. The response of a blade row to time-periodic excitations is modeled by an actuator disk with internal degrees of freedom and by linearized Navier Stokes equations, and the results are compared. It is found {{that in the case of}} subsonic flow one internal degree of freedom can be considered as the most important, both for design and off-design regimes. In the case of transonic flow in off-design regime, two internal degrees of freedom are more important than the rest. However, for the transonic design regime, no internal degrees of freedom could be distinguished as especially significant. The physical mechanisms associated with distinguished internal degrees of freedom are investigated...|$|R
40|$|A Lagrangian {{approach}} {{has been used to}} assess the degree of chemically induced ozone loss inthe Arctic lower stratosphere in winter 1991 / 1992. Trajectory calculations are used to identify airparcels probed by two ozonesondes at different points along the trajectories. A statistical analysisof the measured differences in ozone mixing ratio and the time the air parcel spent in sunlightbetween the measurements provides the chemical ozone loss. Initial results were first describedby von der Gathen et al. [1995]. Here we present a more detailed description of the technique anda more comprehensive discussion of the results. Ozone loss rates of up to 10 ppbv per sunlit hour(or 54 ppbv per day) were found inside the polar vortex on the 475 K potential temperaturesurface (about 19. 5 km in altitude) at the end of January. The period of rapid ozone <b>loss</b> coincidesand slightly <b>lags</b> a period when temperatures were cold enough for type I polar stratosphericclouds to form. It is shown that the ozone loss occurs exclusively during the sunlit portions of thetrajectories. The time evolution and vertical distribution of the ozone loss rates are discussed...|$|R
30|$|The {{estimation}} {{results for}} female workers on work absences show {{clearly that the}} wage effect of a spell of work absence is negative for any type of work absence. This means that for women, a work absence {{is followed by a}} decrease in wages at the mean wage. Notably, the size of the wage loss varies across types and time <b>lags.</b> <b>Losses</b> from unemployment appear to be relatively small and insignificant in the long term. Unemployment during the most recent year decreases wages on return by 1.9 %. We do not find any “scarring” effects in the sense that unemployment in the past affects wages. This shows that those skilled workers who return to a job manage to catch up rather quickly. 24 The non-work variables have significant negative coefficients for up to five years into the past. Recall, that the non-work variable summarizes the residual group of those who are not working. Hence, here we find negative effects that are long-term and a decrease at a declining rate. The loss decreases from 4.7 % on return to the job, to 1.7 % when the spell of non-work is 5  years ago.|$|R
40|$|Assessment of {{injection}} lag transport and uniformity of direct injection boom sprayer {{is an important}} issue for successful variable rate spraying technology. To estimate the boom lag transport and pressure loss, a numerical model is formulated on the basis of fluid hydrodynamic conservation equations. The software is implemented in visual basic. To solve the pressure – velocities equations, control volume finite element method (CV) is used to delimit elementary volumes of the boom. Linearization of the conservation laws is ensured by considering discrete form of the equations and calculating velocity and pressure step by step throughout the whole boom. The flow behaviour is simulated into a boom section divided into N elementary volumes, each of them including one nozzle. To test the model, three boom diameters (5, 6 and 8 mm) and two chemical viscosities (10 - 6 and 10 - 5 m 2 /s) were used. Experimental trials are carried out on boom having 2. 5 m length (5 nozzles) for measuring pressure gradient and lag transport. Results showed that the model can predict the pressure <b>losses</b> and the <b>lag</b> transport accurately (error within 5 %) to optimize boom designs...|$|R
40|$|The paper gives a {{simplified}} {{version of a}} typical dynamic stochastic open economy general equilibrium models used to analyze optimal monetary policy. Then it outlines the chief modifications when dualism in labour and in consumption is introduced to adapt the model to a small open emerging market such as India. The implications of specific labour markets, {{and the structure of}} Indian inflation and its measurement are examined. Simulations give the welfare effects of different types of inflation targeting. Flexible CPI inflation targeting (CIT) without lags works best, especially if the economy is more open. But volatile terms of trade make the supply curve even steeper than in a small open economy despite specific labour markets and higher labour supply elasticity. Exchange rate intervention limits the volatility of the terms of trade and improves outcomes, making the supply curve flatter. As long as such intervention is required, domestic inflation targeting (DIT) continues to be more robust and effective. The welfare <b>losses</b> from the <b>lags</b> in CPI, which prevent the implementation of CIT, are low as long as the dualistic structure dominates. As the economy become...|$|R
40|$|Abstract — Teleoperated robots {{generally}} receive {{high level}} commands from a remote system, while accomplishing motion control through conventional means. We present a teleoperated system that removes the entire motion control structure from the robot, {{in order to}} preserve the availability of crucial onboard resources. The operation of state feedback control is performed by a system remote from the robot. We have designed a computerized motion planning and control system for Mobile Emulab, and in this article, discuss the implementation of trajectory tracking control. A component of the Emulab network testbed, Mobile Emulab is used for wireless network experiments requiring mobility; and is publicly available to remote researchers via the Internet. Medium scale wheeled mobile robot couriers are used to move wireless antennas within a semi-controlled environment. Experimenters use a web-based GUI to specify desired paths and configurations for multiple robots. State feedback is provided by an overhead camera based visual localization system. Kinematic control is used to generate velocity commands, which are sent to robots over a computer network. Data availability is restricted to a low sampling frequency. There is significant noise, <b>loss,</b> and phase <b>lag</b> present in the robot localization data, which our research overcomes to provide an autonomous trajectory tracking mobile robot control system...|$|R
40|$|On-chip optical {{resonators}} {{have the}} promise of revolutionizing numerous fields including metrology and sensing; however, their optical <b>losses</b> have always <b>lagged</b> behind their larger discrete resonator counterparts based on crystalline materials and flowable glass. Silicon nitride (Si 3 N 4) ring resonators open up capabilities for optical routing, frequency comb generation, optical clocks and high precision sensing on an integrated platform. However, simultaneously achieving high quality factor and high confinement in Si 3 N 4 (critical for nonlinear processes for example) remains a challenge. Here, we show that addressing surface roughness enables us to overcome the loss limitations and achieve high-confinement, on-chip ring resonators with a quality factor (Q) of 37 million for a ring with 2. 5 μm width and 67 million for a ring with 10 μm width. We show a clear systematic path for achieving these high quality factors. Furthermore, we extract the loss limited by the material absorption in our films to be 0. 13 dB/m, which corresponds to an absorption limited Q of at least 170 million by comparing two resonators with different degrees of confinement. Our work provides a chip-scale platform for applications such as ultra-low power frequency comb generation, high precision sensing, laser stabilization and sideband resolved optomechanics...|$|R
30|$|Uncertainties {{derived from}} {{parameter}} determination always exist in hydrological modeling, thus {{the estimation of}} parameters should be treated with great caution. Model calibration and validation are the two important processes that can reduce uncertainties in parameters. The hydrological simulation in this study demonstrated that peak flood flow and flood volume were sensitive to initial <b>loss</b> abstraction (I_a), <b>lag</b> time (t_lag), recession constant (k), flood travel time (K), and Muskingum weighting factor (X), and they were often selected for calibrating the HEC-HMS model (Du et al. 2012). The objective of model calibration was {{to find the best}} set of parameter values that produce a best fit between model and observations. The calibration and validation of the HEC-HMS model was conducted with a split sample procedure and streamflow observation records collected at the outlet of the watershed. The model was run for a period of 6  years (2007 – 2012), using the years from 2007 – 2010 as a calibration period. The remaining 2  years (2011 – 2012) were used to validate the model. In this work, flood events with peak discharge greater than 10, 000  m 3 /s are defined as large floods. A total of seven large flood events and four relatively small flood events from 2007 – 2012 —eight for the calibration period and three for the validation period—were obtained to calibrate and validate the HEC-HMS model.|$|R
40|$|Background: Laparoscopic-assisted gastric surgery {{has become}} an option for the {{treatment}} of gastric cancer. In this study we describe our experience with laparoscopic-assisted gastrectomy (LAG) for gastric cancer (GC). Methods: Between January 2000 and September 2008, 115 patients with GC underwent LAG (total gastrectomy: n= 19; distal gastrectomy: n= 96) at our hospital. These patients were compared with 220 patients who had GC and underwent conventional open gastrectomy (OG) (open total gastrectomy: n= 78; open distal gastrectomy: n= 142) during the same period. Results: There was no {{differences between the two groups}} regarding the operation time (161 ± 126 minutes and 212 ± 152 in OG and LAG group, respectively; p=ns). Estimated blood <b>loss</b> in the <b>LAG</b> group was significantly less than in the OG group. The mortality rate was similar. The morbidity rate was were higher in the LAG than in the OG group. The distance of the proximal resection margin showed a significant difference between the two groups (LAG 3. 8 cm versus OG 3 cm). The mean number of nodes resected with LAG was 31 +/- 15, and that with OG was 26 +/- 13 (p = 0. 008). There was no significant differences in overall survival between the two groups. The mean follow-up for the LAG group was 31 months and 40 months in OG. Conclusions: LAG with extended lymphadenectomy for GC is a feasible and safe procedure with a radical oncologic resectio...|$|R
40|$|The {{effects of}} {{proximal}} gastric vagotomy (PGV) and vagotomy with pyloroplasty (V and P) on gastric motility were studied using a solid meal labelled with a radiopharmaceutical agent. In having on-line computer facilities {{it was possible}} not only to record the rate of emptying but also to analyse the relative roles of the fundus and the antrum within the overall framework of gastric emptying. In normal subjects the fundus filled and then emptied in an almost linear pattern. The antrum, however, did not completely fill until well after the meal was eaten and thereafter appeared to maintain a constant volume during the study. The redistribution of contents between fundus and antrum {{was reflected in the}} total stomach emptying curve as a delay, or lag phase before gastric emptying commenced. After both types of vagotomy fundic filling was delayed, representing a slower eating time, which was presumably due to early satiety. Antral filling and volume was disturbed only after V and P, which was also reflected by a <b>loss</b> of the <b>lag</b> phase seen on the total stomach curve. PGV retained antral function but there was significant delay in the redistribution of contents between fundus and antrum, though this did not have clinical significance. The rate of emptying was unaffected by either operation. It was concluded PGV did maintain antral function and a more normal pattern of emptying compared with V and P. After V and P the changes in antral function were considerable and these changes are probably associated with some of the complications resulting from this operation...|$|R
40|$|Background. Physical, emotional, {{and social}} {{functioning}} are impaired in obesity. It is unknown whether and, if so, {{to what extent}} and in which domain obese subjects who lose weight may catch UP to normal-weight levels. Our objective was to compare the health-related quality-of-life (HRQL) of obese subjects {{with that of a}} normal-weight reference group before and I year after a weight loss program that centered around laparoscopic and open gastric banding. Methods. An HRQL questionnaire consisting of a battery of both generic and specific measures was administered to 50 morbidly. obese subjects on 2 occasions and to 100 healthy, normal-weight subjects, matched for age, gender, education, and vocational training. In addition to weight loss and health gain, the influences of achieved weight loss goals, satisfaction with outcome and operative approach (laparoscopy/laparotomy) were assessed. Results. Quality-of-life was significantly impaired in obese subjects. With a substantial weight loss of 35 kg and 42 % loss of excessive weight, and correction of disturbed metabolic parameters, they significantly improved in general well-being, health distress, and perceived attractiveness, approaching halfway the values of a normal-weight reference group. Improvement in values for depression and self-regard lagged behind. In physical activity, they bypassed the reference group. Days of sick leave decreased {{to the level of the}} reference group. Improvements in HRQL paralleled the rate Of weight loss. Personal satisfaction and surgical approach were of minor influence. Conclusions. The obese subjects' impaired physical and social functioning improved considerably, catching up midway to normal-weight reference values after weight <b>loss.</b> Psychologic amelioration <b>lagged</b> behind. Whether the latter will catch up later and physical/social improvements will be maintained is the subject of further studie...|$|R
40|$|Mitochondria from rat epididymal white {{adipose tissue}} were made {{permeable}} to small molecules by toluene treatment and {{were used to}} investigate the effects of Mg 2 + and Ca 2 + on the re-activation of pyruvate dehydrogenase phosphate by endogenous phosphatase. Re-activation of fully phosphorylated enzyme after addition of 0. 18 mM-Mg 2 + showed a marked lag of 5 - 10 min before a maximum rate of reactivation was achieved. Increasing the Mg 2 + concentration to 1. 8 mM (near saturating) or the addition of 100 microM-Ca 2 + resulted in <b>loss</b> of the <b>lag</b> phase, which was also greatly diminished if pyruvate dehydrogenase was not fully phosphorylated. It is concluded that, within intact mitochondria, phosphatase activity is highly sensitive {{to the degree of}} phosphorylation of pyruvate dehydrogenase and that the major effect of Ca 2 + may be to overcome the inhibitory effects of sites 2 and 3 on the dephosphorylation of site 1. Apparent K 0. 5 values for Mg 2 + and Ca 2 + were determined from the increases in pyruvate dehydrogenase activity observed after 5 min. The K 0. 5 for Mg 2 + was diminished from 0. 60 mM at less than 1 nM-Ca 2 + to 0. 32 mM at 100 microM-Ca 2 +; at 0. 18 mM-Mg 2 +, the K 0. 5 for Ca 2 + was 0. 40 microM. Ca 2 + had little or no effect at saturating Mg 2 + concentrations. Since effects of Ca 2 + are readily observed in intact coupled mitochondria, it follows that Mg 2 + concentrations within mitochondria are sub-saturating for pyruvate dehydrogenase phosphate phosphatase and hence less than 0. 5 mM...|$|R
40|$|In {{the present}} studies we have {{explored}} {{the link between}} food hypersensitivity and IgA nephropathy (IgAN) and evaluated treatment options in primary and recurrent disease. Approximately one third of our IgAN patients had a rectal mucosal sensitivity to gluten, as demonstrated by increased local mucosal nitric oxide production and/or myeloperoxidase release after gluten challenge. The gluten sensitivity {{seemed to be an}} innate immune reaction unrelated to the pathogenesis of celiac disease. Approximately half of the patients had a rectal mucosal sensitivity to soy or cow’s milk (CM). The levels of IgG antibodies to alfa-lactalbumin, beta-lactoglobulin and casein were significantly higher in CM sensitive as compared with non-sensitive IgAN patients, indicating that an adaptive immune response might be involved in addition to the innate immune reaction observed. With the knowledge of gastrointestinal reactivity enteric treatment was considered as a potential new treatment approach of IgAN. A 6 -month prospective trial demonstrated proof-of-concept for the use of enteric budesonide targeted to the ileocaecal region of IgAN patients. We observed a modest, but significant reduction in urine albumin, a minor reduction of serum creatinine and a modest increase of eGFR calculated by the MDRD equation. eGFR calculated from the Cockcroft-Gault formula and cystatin C was not changed. In a retrospective study recurrence of IgAN and graft loss was evaluated in Norwegian and Swedish patients having received a primary renal transplant due to IgAN. Adjusting for relevant covariates, a multiple Cox-regression analysis on time to IgAN recurrence showed that use of statins was associated with reduced risk of recurrence and reduced risk of graft <b>loss.</b> The time <b>lag</b> from diagnosis to first transplantation and female gender were also associated with lower risk of recurrence. Improved graft survival was associated with related donor, low donor age and no or low number of acute rejection episodes...|$|R
5000|$|The complex {{dielectric}} constant is , where [...] is the {{dielectric constant}}, [...] is the electrical conductivity, [...] is the field frequency, and [...] is the imaginary unit. [...] This expression has been useful for approximating the dielectrophoretic behavior of particles such as red blood cells (as oblate spheroids) or long thin tubes (as prolate ellipsoids) allowing the approximation of the dielectrophoretic response of carbon nanotubes or tobacco mosaic viruses in suspension.These equations are accurate for particles when the electric field gradients are not very large (e.g., close to electrode edges) or when the particle is not moving along an axis in which the field gradient is zero (such as {{at the center of}} an axisymmetric electrode array), as the equations only take into account the dipole formed and not higher order polarization. When the electric field gradients are large, or when there is a field null running {{through the center of the}} particle, higher order terms become relevant, and result in higher forces.To be precise, the time-dependent equation only applies to lossless particles, because <b>loss</b> creates a <b>lag</b> between the field and the induced dipole. When averaged, the effect cancels out and the equation holds true for lossy particles as well. An equivalent time-averaged equation can be easily obtained by replacing E with Erms, or, for sinusoidal voltages by dividing the right hand side by 2.These models ignores the fact that cells have a complex internal structure and are heterogeneous. A multi-shell model in a low conducting medium can be used to obtain information of the membrane conductivity and the permittivity of the cytoplasm. For a cell with a shell surrounding a homogeneous core with its surrounding medium considered as a layer, as seen in Figure 2, the overall dielectric response is obtained from a combination of the properties of the shell and core.|$|R
40|$|Fluorescence in situ Hybridisation (FISH) revolutionised {{cytogenetics}} using fluorescently labelled probes {{with high}} affinity with target (nuclear) DNA. By the early 1990 s FISH was adopted {{as a means}} of PGD sexing for couples at risk of transmitting X-linked disorders and later for detection of unbalanced translocations. Following a rise in popularity of PGD by FISH for sexing and the availability of multicolour probes (5 - 8 colour), the use of FISH was expanded to the detection of aneuploidy and selective implantation of embryos more likely to be euploid, the rationale being to increase pregnancy rates (referral categories were typically advanced maternal age, repeated IVF failure, repeated miscarriage or severe male factor infertility). Despite initial reports of an increase in implantation rates, reduction in trisomic offspring and spontaneous abortions criticism centred around experimental design (including lack of randomisation), inadequate control groups and lack of report on live births. Eleven randomised control trials (RCTs) (2004 - 2010) showed that PGS with FISH did not increase delivery rates with some demonstrating adverse outcomes. These RCTs, parallel improvements in culturing and cryopreservation and a shift to blastocyst biopsy essentially outdated FISH as a tool for PGS and it has now been replaced by newer technologies (array CGH, SNP arrays, qRT-PCR and NGS). Cell-by-cell follow up analysis of individual blastomeres in non-transferred embryos is however usually prohibitively expensive by these new approaches and thus FISH remains an invaluable resource for the study of mosaicosm and nuclear organization. We thus developed the approach described herein for the FISH detection of chromosome copy number of all 24 human chromosomes. This approach involves 4 sequential layers of hybridization, each with 6 spectrally distinct fluorochromes and a bespoke capturing system. Here we report previously published studies and hitherto unreported data indicating that 24 chromosome FISH is a useful tool for studying chromosome mosaicism, one of the most hotly debated topics currently in preimplantation genetics. Our results suggest that mosaic embryo aneuploidy is not highly significantly correlated to maternal age, probably due, in part, to the large preponderance of post-zygotic (mitotic) errors. Chromosome <b>loss</b> (anaphase <b>lag)</b> appears to be the most common mechanism, followed by chromosome gain (endoreduplication), however 3 : 1 mitotic non- disjunction of chromosomes appears to be rare. Nuclear organisation (i. e. the spatial and temporal topology of chromosomes or sub-chromosomal compartments) studies indicate that human morula or blastocyst embryos (day 4 - 5) appear to adopt a "chromocentric" pattern (i. e. almost all centromeric signals reside in the innermost regions of the nuclear volume). By the blastocyst stage however, a more ordered organisation with spatial and temporal cues important for embryo development appears. We have however found no association between aneuploidy and nuclear organization using this approach despite our earlier studies. In conclusion, while FISH is mostly "dead and buried" for mainstream PGS, it still has a place for basic biology studies; the development of a 24 chromosome protocol extends the power of this analysis...|$|R
40|$|Kuantan {{watershed}} {{located in}} the flood prone area and experienced flood event almost every year due to monsoon season on the Peninsular Malaysia in month of November to February. Based {{on the condition of}} the watershed that has high probability in subjected to the flood occurrence, it shows that there was a need to develop a hydrologic model for the watershed. The study aims to develop the rainfall-runoff relationship using hydrological model and GIS in Kuantan watershed, assess the performance of HEC-HMS model in runoff prediction and evaluate the accuracy of modified SCS-CN in tropical area. HEC-HMS model was used to stimulate the storm event that occurs in the watershed based on the selected event where the calibration and validation also were carried out. The method used in the model was the SCS Unit Hydrograph for the Transform Method, SCS-CN as the <b>Loss</b> Method, and <b>Lag</b> Time as the Flood Routing Method. The simulation was carried out based on two selected storm event which was on the month of December 2006 and month of January 2012. The value of initial abstraction ratio used was 0. 2 and 0. 05 which the result based on both application of the ratio will be compared. The model was calibrated based on the antecedent moisture condition which considering the wet condition in the watershed which was known as AMC III, where the calculated curve number based on the land use and hydrological soil groups criteria was assumed in the normal condition. The efficiency of the simulated result over actual result was access using the Nash-Sutcliffe Efficiency (NSE). For the simulated result based on selected event, the NSE value for the model before and after calibration was range from 0. 7 to 0. 9 for both value of initial abstraction ratio which shows that the model perform well but the model seem to underestimate the actual peak discharge in the watershed. The efficiency for the model based on event on December 2006 was higher without calibration with initial abstraction ratio of 0. 2 while for event on January 2012; the efficiency of the model was higher after the model calibrated which has almost the similar efficiency for both ratio of abstraction use. The application of two different equations to calculate the Lag Time also gives slight changes in the result as the used of Kirpich Equation gives a better result compare to the use of SCS Lag Equation for the prediction of the peak discharge...|$|R
