4306|9|Public
5|$|Logarithms {{also occur}} in <b>log-normal</b> distributions. When the {{logarithm}} of a random variable has a normal distribution, the variable {{is said to}} have a <b>log-normal</b> distribution. <b>Log-normal</b> distributions are encountered in many fields, wherever a variable is formed as the product of many independent positive random variables, for example in the study of turbulence.|$|E
5|$|Uranium {{deposits}} {{seem to be}} <b>log-normal</b> distributed. There is a 300-fold {{increase in}} the amount of uranium recoverable for each tenfold decrease in ore grade.|$|E
25|$|Extreme values like maximum one-day {{rainfall}} and river discharge per month or per year often follow a <b>log-normal</b> distribution. The <b>log-normal</b> distribution, however, needs a numeric approximation. As the log-logistic distribution, {{which can be}} solved analytically, {{is similar to the}} <b>log-normal</b> distribution, it can be used instead.|$|E
25|$|It {{is similar}} in shape to the <b>log-normal</b> {{distribution}} but has heavier tails. Unlike the <b>log-normal,</b> its cumulative distribution function can be written in closed form.|$|E
25|$|The {{length of}} {{comments}} posted in Internet discussion forums follows a <b>log-normal</b> distribution.|$|E
25|$|Cell populations {{detected}} by flow cytometry are {{often described as}} having approximately <b>log-normal</b> expression.|$|E
25|$|The users' {{dwell time}} on the online {{articles}} (jokes, news etc.) follows a <b>log-normal</b> distribution.|$|E
25|$|As {{shown in}} diagram at right, this {{phenomenon}} has relatively small effect if {{the standard deviation}} (as compared to the mean) is relatively small, as it makes the <b>log-normal</b> distribution appear similar to an arithmetical normal distribution. Thus, the arithmetical normal distribution may be more appropriate to use with small standard deviations for convenience, and the <b>log-normal</b> distribution with large standard deviations.|$|E
25|$|<b>Log-normal</b> {{distributions}} are infinitely divisible, {{but they}} are not stable distributions, which can be easily drawn from.|$|E
25|$|A set of {{data that}} arises from the <b>log-normal</b> {{distribution}} has a symmetric Lorenz curve (see also Lorenz asymmetry coefficient).|$|E
25|$|The {{file size}} {{distribution}} of publicly available {{audio and video}} data files (MIME types) follows a <b>log-normal</b> distribution over five orders of magnitude.|$|E
25|$|The <b>log-normal</b> {{distribution}} has no negative values, {{can cover}} {{a wide range}} of values, and fits many observed size distributions reasonably well.|$|E
25|$|Doodson's {{relationship}} was studied by Kendall and Stuart in the <b>log-normal</b> distribution {{for which they}} found an exact relationship close to it.|$|E
25|$|In a <b>log-normal</b> distribution, the {{geometric}} standard deviations and geometric mean more accurately estimate the 95% prediction interval than their arithmetic counterparts.|$|E
25|$|For example, the MLE {{parameters}} of the <b>log-normal</b> distribution {{are the same as}} those of the normal distribution fitted to the logarithm of the data.|$|E
25|$|Consequently, {{reference}} ranges for measurements {{in healthy}} individuals are more accurately estimated by assuming a <b>log-normal</b> distribution than by assuming a symmetric distribution about the mean.|$|E
25|$|In hydrology, the <b>log-normal</b> {{distribution}} {{is used to}} analyze extreme values of such variables as monthly and annual maximum values of daily rainfall and river discharge volumes.|$|E
25|$|In reality, {{biological}} parameters {{tend to have}} a <b>log-normal</b> distribution, {{rather than}} the arithmetical normal distribution (which is generally referred to as normal distribution without any further specification).|$|E
25|$|Methods for {{establishing}} reference ranges are mainly based on assuming a normal distribution or a <b>log-normal</b> distribution, or directly from percentages of interest, as detailed respectively in following sections.|$|E
25|$|An {{alternative}} method {{of establishing a}} reference range with the assumption of <b>log-normal</b> distribution {{is to use the}} arithmetic mean and arithmetic value of standard deviation. This is somewhat more tedious to perform, but may be useful for example in cases where a study that establishes a reference range presents only the arithmetic mean and standard deviation, leaving out the source data. If the original assumption of arithmetically normal distribution is shown to be less appropriate than the <b>log-normal</b> one, then, using the arithmetic mean and standard deviation may be the only available parameters to correct the reference range.|$|E
25|$|The random {{component}} seeks to capture {{certain types of}} signal fading associated with absorption and reflections by obstacles. The fading models in use include Rayleigh (implying exponential random variables for the power), <b>log-normal,</b> Rice, and Nakagami distributions.|$|E
25|$|An {{explanation}} for this <b>log-normal</b> distribution for biological parameters is: The event where a sample has half {{the value of the}} mean or median tends to have almost equal probability to occur as the event where a sample has twice the value of the mean or median. Also, only a <b>log-normal</b> distribution can compensate for the inability of almost all biological parameters to be of negative numbers (at least when measured on absolute scales), with the consequence that there is no definite limit to the size of outliers (extreme values) on the high side, but, on the other hand, they can never be less than zero, resulting in a positive skewness.|$|E
25|$|The {{image on}} the right {{illustrates}} an example of fitting the <b>log-normal</b> distribution to ranked annually maximum one-day rainfalls showing also the 90% confidence belt based on the binomial distribution. The rainfall data are represented by plotting positions {{as part of a}} cumulative frequency analysis.|$|E
25|$|A {{well-known}} {{class of}} distributions {{that can be}} arbitrarily skewed is given by the <b>log-normal</b> distribution. It is obtained by transforming a random variable X having a normal distribution into random variable Y = e'X. Then the logarithm of random variable Y is normally distributed, hence the name.|$|E
25|$|Note {{that the}} Pareto {{distribution}} and <b>log-normal</b> distribution are alternative distributions for describing {{the same types}} of quantities. One of the connections between the two is that they are both the distributions of the exponential of random variables distributed according to other common distributions, respectively the exponential distribution and normal distribution.|$|E
25|$|The normal {{distribution}} is a subclass of the elliptical distributions. The {{normal distribution}} is symmetric about its mean, and is non-zero {{over the entire}} real line. As such {{it may not be}} a suitable model for variables that are inherently positive or strongly skewed, such as the weight of a person or the price of a share. Such variables may be better described by other distributions, such as the <b>log-normal</b> distribution or the Pareto distribution.|$|E
25|$|For example, <b>log-normal</b> {{distributions}} {{are often}} mistaken for power-law distributions: a data set {{drawn from a}} lognormal distribution will be approximately linear for large values (corresponding to the upper tail of the lognormal being close to a power law), but for small values the lognormal will drop off significantly (bowing down), corresponding to the lower tail of the lognormal being small (there are very few small values, rather than many small values in a power law).|$|E
25|$|A {{method to}} {{estimate}} the reference range for a parameter with <b>log-normal</b> distribution is to logarithmize all the measurements with an arbitrary base (for example e), derive the {{mean and standard deviation}} of these logarithms, determine the logarithms located (for a 95% prediction interval) 1.96 standard deviations below and above that mean, and subsequently exponentiate using those two logarithms as exponents and using the same base as was used in logarithmizing, with the two resultant values being the lower and upper limit of the 95% prediction interval.|$|E
25|$|However, the {{reference}} range limits as estimated {{in this way}} have higher variance, and therefore less reliability, than those estimated by an arithmetic or <b>log-normal</b> distribution (when such is applicable), because the latter ones acquire statistical power from the measurements of the whole reference group rather than just the measurements at the 2.5th and 97.5th percentiles. Still, this variance decreases with increasing size of {{the reference}} group, and therefore, this method may be optimal where a large reference group easily can be gathered, and the distribution mode of the measurements is uncertain.|$|E
25|$|Relative species abundances in the UNTB model {{follow a}} zero-sum multinomial {{distribution}}. The shape of this distribution {{is a function}} of the immigration rate, the size of the sampled community (grid), and θ. When the value of θ is small, the relative species abundance distribution is similar to the geometric series (high dominance). As θ gets larger, the distribution becomes increasingly s-shaped (<b>log-normal)</b> and, as it approaches infinity, the curve becomes flat (the community has infinite diversity and species abundances of one). Finally, when θ = 0 the community described consists of only one species (extreme dominance).|$|E
25|$|The log-logistic {{has been}} used as a model for the period of time {{beginning}} when some data leaves a software user application in a computer and the response is received by the same application after travelling through and being processed by other computers, applications, and network segments, most or all of them without hard real-time guarantees (for example, when an application is displaying data coming from a remote sensor connected to the Internet). It has been shown to be a more accurate probabilistic model for that than the <b>log-normal</b> distribution or others, as long as abrupt changes of regime in the sequences of those times are properly detected.|$|E
25|$|The {{reason is}} that the {{logarithm}} of the stock price is undergoing a random walk, so over time its probability distribution will get more and more broad and smooth (see above). (More technically, the central limit theorem says that multiplying more and more random variables will create a <b>log-normal</b> distribution with larger and larger variance, so eventually it covers many orders of magnitude almost uniformly.) To be sure of approximate agreement with Benford's Law, the distribution has to be approximately invariant when scaled up by any factor up to 10; a lognormally distributed data set with wide dispersion would have has this approximate property.|$|E
25|$|The {{meaning of}} the factor of (σ2/2)τ is {{relatively}} subtle. For dminus& and m this corresponds {{to the difference between}} the median and mean (respectively) of geometric Brownian motion (the <b>log-normal</b> distribution), and is the same correction factor in Itō's lemma for geometric Brownian motion. The interpretation of d+, as used in Delta, is subtler, and can be interpreted most elegantly as change of numéraire. In more elementary terms, the probability that the option expires in the money and the value of the underlying at exercise are not independent – the higher the price of the underlying, {{the more likely it is}} to expire in the money and the higher the value at exercise, hence why Delta is higher than moneyness.|$|E
25|$|The uniform {{distribution}} {{as might be}} expected does not obey Benford's law. In contrast, the ratio distribution of two {{uniform distribution}}s is well described by Benford's law. Benford's law also describes the exponential distribution and the ratio distribution of two exponential distributions well. Although the half-normal distribution does not obey Benford's law, the ratio distribution of two half-normal distributions does. Neither the right-truncated normal distribution nor the ratio distribution of two right-truncated normal distributions are well described by Benford's law. This is not surprising as this distribution is weighted towards larger numbers. Neither the normal distribution nor the ratio distribution of two normal distributions (the Cauchy distribution) obey Benford's law. The fit of chi square distribution depends on the degrees of freedom (df) with good agreement with df = 1 and decreasing agreement as the df increases. The F distribution is fitted well for low degrees of freedom. With increasing dfs the fit decreases but much more slowly than the chi square distribution. The fit of the <b>log-normal</b> distribution depends on the mean and the variance of the distribution. The variance has a much greater effect on the fit than does the mean. Larger values of both parameters result in better agreement with the law. The ratio of two log normal distributions is a log normal so this distribution was not examined.|$|E
2500|$|... when {{modeling}} positive quantities (e.g. {{prices or}} populations) that vary {{over a large}} scale—which are better described using a skewed distribution such as the <b>log-normal</b> distribution or Poisson distribution (although GLMs are not used for <b>log-normal</b> data, instead the response variable is simply transformed using the logarithm function); ...|$|E
2500|$|In {{probability}} theory, a <b>log-normal</b> (or lognormal) {{distribution is}} a continuous probability distribution of a random variable whose logarithm is normally distributed. Thus, if the random variable [...] is log-normally distributed, then [...] has a normal distribution. Likewise, if [...] has a normal distribution, then the exponential function of , , has a <b>log-normal</b> distribution. A random variable which is log-normally distributed takes only positive real values. The distribution is occasionally {{referred to as}} the Galton distribution or Galton's distribution, after Francis Galton. The <b>log-normal</b> distribution also has been associated with other names, such as McAlister, Gibrat and Cobb–Douglas.|$|E
