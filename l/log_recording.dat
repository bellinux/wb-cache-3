23|1047|Public
25|$|Director Victor Lobl also planned out the mannerisms {{shown by}} Brooks as Sisko where he talks {{directly}} to the camera. He praised the actor, saying that he delivered exactly what Lobl's written direction had described. All of those sequences were shot almost in direct continuity {{to ensure that the}} audience believed that it was a single <b>log</b> <b>recording.</b> Lobl had those filmed very tightly, and so there were not many options available in editing as only two angles were filmed for those sequences. The script had called for Sisko to get more and more drunk during those sequences as he descends into the flashbacks; Lobl had expected the studio to pull that idea before filming but they did not. Lobl also had Sisko begin to remove various parts of his uniform at the same time, which he felt demonstrated that the character was baring his soul about the story.|$|E
60|$|All the needful {{documents}} {{had been}} preserved and brought home. There was the extract from the captain's <b>log</b> <b>recording</b> the burial at sea of Harold Stanislas Alison, aged fifteen months, and the {{certificate of baptism}} by a colonial clergyman of Harold, son of Ambrose and Alice Alison, while Eustace was entered in the Northchester register, having been born in lodgings, as Mr. Prosser well recollected, while his poor young father lay under sentence of death.|$|E
5000|$|Jersey {{was built}} {{during a time}} of peace in Britain. Length: 44 m; 1,068 bm tons; Crew: 400; Armament: 24x24 pdr, 26x9 pdr, 10x6 pdr; built in 1736. Her first battle was in Admiral Edward Vernon's {{defeated}} attack on the Spanish port of Cartagena, Colombia, around the beginning of the War of Jenkins' Ear in October 1739. She was badly damaged in battle in June 1745, with her captain's <b>log</b> <b>recording</b> the loss of all sails and: ...|$|E
5000|$|Compensation <b>Log</b> <b>Record</b> {{notes the}} {{rollback}} {{of a particular}} change to the database. Each corresponds with exactly one other Update <b>Log</b> <b>Record</b> (although the corresponding update <b>log</b> <b>record</b> is not typically stored in the Compensation <b>Log</b> <b>Record).</b> It includes this extra information: ...|$|R
5000|$|... undoLSN: This is a {{reference}} to the oldest <b>log</b> <b>record</b> of the oldest in-progress transaction. This is the oldest <b>log</b> <b>record</b> needed to undo all in-progress transactions.|$|R
40|$|Log is a {{group of}} {{different}} types of actions that take place in organization. Logs are often compromised by an attacker so providing security to the <b>log</b> <b>record</b> is challenging task. <b>Log</b> <b>record</b> generally contains some sensitive information so confidentiality and integrity are important as the privacy is concerned. So there is need to protect the <b>log</b> <b>records</b> for the proper functioning of any organization. It is observed that over extended period of time introducing the secured logging techniques involves great capital that finds every organization irresistible. Appointing the <b>logs</b> <b>record</b> to the cloud environment saves the cost In this paper we are suggesting the homo morphic encryption scheme that provides a strong security...|$|R
5000|$|Eye of the North focuses {{more heavily}} on PvE accomplishments, such as titles. One of the new {{features}} is an item which acts as similar to a quest <b>log,</b> <b>recording</b> specific feats the player accomplishes in game play. Upon defeating the final boss of the dungeon, a new [...] "page" [...] in the quest log is filled in. Completed log books can later be turned {{into one of the}} allied factions in the game (Norn, Asura, Ebon Vanguard, or Dwarves) for a large experience and reputation bonus.|$|E
50|$|Beginning in 1993, shorter rides were {{arranged}} that lasted in duration {{from one to}} many days, and while the Iron Butt Rally is a large, organized event with a plotted course, the other rides are left up to the competitor to accomplish at their own accord. Some riders prefer to complete a ride solo, while some clubs have arranged rides in groups of up to 30 riders. But while the Rally is a monitored event, the riders of other events must monitor themselves. An example is the Saddle Sore 1000, where thorough documentation of the ride must be made, by collecting time-stamped gas and business receipts along the way, and by keeping a trip <b>log</b> <b>recording</b> mileage and location. These documents are then submitted by mail with a fee to the IBA, where it is then processed and an award given if the requirements are met.|$|E
50|$|Director Victor Lobl also planned out the mannerisms {{shown by}} Brooks as Sisko where he talks {{directly}} to the camera. He praised the actor, saying that he delivered exactly what Lobl's written direction had described. All of those sequences were shot almost in direct continuity {{to ensure that the}} audience believed that it was a single <b>log</b> <b>recording.</b> Lobl had those filmed very tightly, and so there were not many options available in editing as only two angles were filmed for those sequences. The script had called for Sisko to get more and more drunk during those sequences as he descends into the flashbacks; Lobl had expected the studio to pull that idea before filming but they did not. Lobl also had Sisko begin to remove various parts of his uniform at the same time, which he felt demonstrated that the character was baring his soul about the story.|$|E
40|$|Data mining is the {{procedure}} of distinguishing helpful example from expansive measure of information. Web mining is {{the procedure}} of discovering web design from web information. Web connection mining uses information from <b>log</b> <b>record.</b> Web connection mining discovering helpful things from <b>log</b> <b>record.</b> <b>Log</b> <b>record</b> contains all the client activities. In existing framework {{all the information}} are mine by apriori calculation. It is utilized for discovering succession from <b>log</b> <b>record</b> however it doesn't ordered log information as per our need. Bolster vector machine is utilized to group all the information of web log document that examine information and recognize designs. Bolster vector machine order all the information into two classes. It separates two classes by hyper plane. In the wake of applying SVM, We find all th...|$|R
50|$|We create <b>log</b> <b>records</b> of {{the form}} (Sequence Number, Transaction ID, Page ID, Redo, Undo, Previous Sequence Number). The Redo and Undo fields keep {{information}} about the changes this <b>log</b> <b>record</b> saves and how to undo them. The Previous Sequence Number is {{a reference to the}} previous <b>log</b> <b>record</b> that was created for this transaction. In the case of an aborted transaction, it's possible to traverse the log file in reverse order using the Previous Sequence Numbers, undoing all actions taken within the specific transaction.|$|R
50|$|Type: Describes {{the type}} of {{database}} <b>log</b> <b>record.</b>|$|R
40|$|Log kept by Captain Joshua Fergusson of the brig on his voyage from Calcutta to Van Diemen's Land 14 September 1816 to 9 December 1816 {{and from}} Van Diemen's Land to Port Jackson and return January to March 1817. The volume is a {{standard}} ship's <b>log,</b> <b>recording</b> course, winds, latitude and other nautical observations. On the first page is 'A list of the Brig Jupiter's crew' including 'Joshua Fergusson, Captain, English' and 'George Fergusson, 1 st officer, English' and twenty Indian seamen. On the last page is a note (written twice) 'Joshua Fergusson, Tinder Box Bay 2 December 1862 '. RS 4...|$|E
40|$|Increasingly {{information}} systems log historic {{information in a}} systematic way. Workflow management systems, but also ERP, CRM, SCM, and B 2 B systems often provide a so-called event log, i. e., a <b>log</b> <b>recording</b> the execution of activities. Unfortunately, the information in these event logs is rarely {{used to analyze the}} underlying processes. Process mining aims at improving this by providing techniques and tools for discovering process, control, data, organizational, and social structures from event logs. This paper focuses on the mining social networks. This is possible because event logs typically record information about the users executing the activities recorded in the log. To do this we combine concepts from workflow management and social network analysis. This paper introduces the approach, defines metrics, and presents a tool to mine social networks from event logs...|$|E
40|$|This paper {{describes}} the "R'eseau Fut'e (Smart Net) " project whose {{aim is to}} introduce DAI and Multi-Agent techniques in network management and supervision, {{in order to help}} the processing of the large volume of alarms and various event notifications received by network management platforms. Actually, many of these alarms prove to have a user-depending utility and have to be filtered. We have chosen a Chronicle model in order to incorporate temporal reasoning in our experimental platform. Thus some of the tasks (alarm filtering, <b>log</b> <b>recording,</b> fault detection [...] .) can be automated via a chronicle recognition system, letting the supervision operator focus on more important tasks. Although it is possible to have a model-based approach, we will assume {{that we do not have}} a complete knowledge of the network, and that the model can evolve quickly...|$|E
5000|$|The Dynamic Logs—The Vinyl Reunion (Dynamic <b>Log</b> <b>Records,</b> 1985, LP) ...|$|R
30|$|Note that if {{the role}} of Leader is {{frequently}} switched in different members, the <b>log</b> <b>records</b> of committed transactions will be lost. To prevent this, it is not until the backup node ensures that the received <b>log</b> <b>records</b> which are integrated from the committed LSN and whose LSN’s are greater than the local last LSN that Follower can discard <b>log</b> <b>records</b> after the committed LSN. In other words, the Follower buffers the new log entries until these data cover the LSN range (local_committed_LSN, local_last_LSN], and then replaces the corresponding log entries in disk atomically. The main steps are illustrated in Procedure 2.|$|R
30|$|When a {{restarting}} member {{finds the}} status of system is after_election and its election role is Follower, it has {{to ensure that the}} state of local data is consistent with the Leader. Since the Follower cannot judge whether the <b>log</b> <b>records</b> whose LSN is greater than the committed LSN should be applied to the local memory table, it must get necessary information from the Leader. In order to reduce the network overhead, we implement a recovery mechanism as below. To begin with, the Follower scans log file in disk to update local variables, e.g., local last LSN, committed LSN. As described above, the committed LSN is the max committed LSN stored in the log file. Then, it starts to replay local <b>log</b> <b>records</b> whose LSN is not greater than the committed LSN, and it discards the remaining <b>log</b> <b>records.</b> At the same time, the Follower reports its committed LSN to the Leader. When the Leader receives this message, it sends the corresponding <b>log</b> <b>records</b> after that LSN to the Follower. Finally, the Follower can receive new <b>log</b> <b>records</b> and refresh the committed LSN, which triggers itself to replay the log continuously.|$|R
40|$|Stanford Health Information Network for Education (SHINE) {{integrates}} online guideline texts, textbooks, journals, bibliographic systems, medical images, digital video, relational databases, and knowledge-based systems, {{which were}} formerly accessible individually through the Z 39. 50 protocol, SQL language, HTTP protocol, and full-text search engines. We introduce the architecture {{that is used}} to integrate these distributed heterogeneous systems and allows presentation of resources with non-overlapping content as if they were a single volume. We explain how the system will be integrated with electronic medical record systems to support medical decisions. We also discuss SHINE's electronic notebook, and <b>log</b> <b>recording</b> systems that make SHINE a complete system that supports medical decision making and learning. The same concepts can be applied to aggregation of knowledge domains to optimize the functions of other (non-medical) target users. 14. 1 Introduction Keeping pace with th [...] ...|$|E
40|$|Process mining {{techniques}} {{allow for}} the discovery of knowledge based on so-called "event logs", i. e., a <b>log</b> <b>recording</b> the execution of activities in some business process. Many information systems provide such logs, e. g., most WFM, ERP, CRM, SCM, and B 2 B systems record transactions in a systematic way. Process mining techniques typically focus on performance and control-flow issues. However, event logs typically also log the performer, e. g., the person initiating or completing some activity. This paper focuses on mining social networks using this information. For example, {{it is possible to}} build a social network based on the hand-over of work from one performer to the next. By combining concepts from workflow management and social network analysis, it is possible to discover and analyze social networks. This paper defines metrics, presents a tool, and applies these to a real event log within the setting of a large Dutch organization. close 13...|$|E
40|$|Abstract. Increasingly {{information}} systems log historic {{information in a}} systematic way. Workflow management systems, but also ERP, CRM, SCM, and B 2 B systems often provide a so-called “event log”, i. e., a <b>log</b> <b>recording</b> the execution of activities. Thus far, process mining has been focusing on such structured event logs resulting in powerful analysis techniques and tools for discovering process, control, data, organizational, and social structures from event logs. Unfortunately, many work processes are not supported by systems providing structured logs. Instead very basic tools such as a text editors, spreadsheets, and e-mail are used. This report explores the application of process mining to e-mail, i. e., unstructured or semi-structured e-mail messages are converted in event logs suitable {{for the application of}} process mining tools. This report presents the tool EMailAnalyzer which analyzes and transforms e-mail messages in MS Outlook to a format that can be used by our process mining tools. The main innovative aspect of this work is that our analysis is not restricted to the social network, the main goal is to discover interaction patterns and processes...|$|E
50|$|Information {{about the}} actual changes that {{triggered}} the <b>log</b> <b>record</b> to be written.|$|R
50|$|Transaction ID number: A {{reference}} to the database transaction generating the <b>log</b> <b>record.</b>|$|R
30|$|A <b>log</b> <b>record</b> of a frame should {{reside in}} a log {{maintained}} by a node for a maximum {{period of time}} equal to the lifetime of the frame. Lifetime of a frame {{in the case of}} end to end data delivery is only until it is delivered to the destination. Therefore, the longest lifetime of a <b>log</b> <b>record</b> is the time taken by a frame to travel {{from one end to the}} other end of a network with all the delays included. Hence the lifetime of a <b>log</b> <b>record</b> depends both on the diameter of the network in terms of the number of hops and waiting times at each hop.|$|R
40|$|This article tackles {{the problem}} of {{discovering}} a process model from an event <b>log</b> <b>recording</b> the execution of tasks in a business process. Previous approaches to this reverse-engineering problem strike different tradeoffs between {{the accuracy of the}} discovered models and their understandability. With respect to the latter property, empirical studies have demonstrated that block-structured process models are generally more understandable and less error-prone than unstructured ones. Accordingly, several methods for automated process model discovery generate block-structured models only. These methods however intertwine the objective of producing accurate models with that of ensuring their structuredness, and often sacrifice the former in favour of the latter. In this paper we propose an alternative approach that separates these concerns. Instead of directly discovering a structured process model, we first apply a well-known heuristic that discovers accurate but oftentimes unstructured (and even unsound) process models, and then we transform the resulting process model into a structured (and sound) one. An experimental evaluation on synthetic and real-life event logs shows that this discover-and-structure approach consistently outperforms previous approaches with respect to a range of accuracy and complexity measures...|$|E
40|$|Increasingly {{information}} systems log historic {{information in a}} systematic way. Work°ow management systems, but also ERP, CRM, SCM, and B 2 B systems often provide a so-called log 2 ̆ 2, i. e., a <b>log</b> <b>recording</b> the execution of activities. Thus far, process mining has been focusing on such structured event logs resulting in powerful analysis tech- niques and tools for discovering process, control, data, organizational, and social structures from event logs. Unfortunately, many work pro- cesses are not supported by systems providing structured logs. Instead very basic tools such as a text editors, spreadsheets, and e-mail are used. This report explores the application of process mining to e-mail, i. e., un- structured or semi-structured e-mail messages are converted in event logs suitable {{for the application of}} process mining tools. This report presents the tool EMailAnalyzer which analyzes and transforms e-mail messages in MS Outlook to a format that can be used by our process mining tools. The main innovative aspect of this work is that our analysis is not re- stricted to the social network, the main goal is to discover interaction patterns and processes...|$|E
40|$|Increasingly {{information}} systems log historic {{information in a}} systematic way. Workflow management systems, but also ERP, CRM, SCM, and B 2 B systems often provide a so-called 2 ̆ 2 event log 2 ̆ 2 (i. e., a <b>log</b> <b>recording</b> the execution of activities). Thus far, process mining has been mainly focusing on structured event logs resulting in powerful analysis techniques and tools for discovering process, control, data, organizational, and social structures from event logs. Unfortunately, many work processes are not supported by systems providing structured logs. Instead, very basic tools such as text editors, spreadsheets, and e-mail are used. This article explores the application of process mining to e-mail (i. e., unstructured or semi-structured e-mail messages are converted into event logs suitable for application of process mining tools). This article presents the tool EMailAnalyzer, embedded in the ProM process mining framework, which analyzes and transforms e-mail messages to a format that allows for analysis using our process mining techniques. The main innovative aspect of this work is that, unlike most other work in this area, our analysis is not restricted to social network analysis. Based on e-mail logs, we can also discover interaction patterns and processes...|$|E
5000|$|At 2.5pm, the Ships <b>Log</b> <b>records</b> ‘Departed this life, Frank Toovey Lake, Navigating Midshipman.’ ...|$|R
40|$|Much {{information}} biologists need to {{do their}} job comes from fishermen's logbooks. These logbook data are confidential by law. No single <b>log</b> <b>record,</b> or single skipper's log information can be made available to anyone else. What use is made of these <b>log</b> <b>records,</b> and why are they useful is a question often asked by fishermen. " (Introduction) Digitized by an ODFW employee...|$|R
30|$|After {{generating}} the commit log, the Leader needs {{to send the}} <b>log</b> <b>record</b> to all Followers by an asynchronous network function, which does not block the single commit thread held responsible for synchronization and persistence of <b>log</b> <b>records.</b> In other words, the Leader is able to flush the commit log to local disk without waiting for the responses from the Followers.|$|R
40|$|Given {{a process}} model {{representing}} the expected {{behavior of a}} business process, and given an event <b>log</b> <b>recording</b> its actual execution, the problem of business process conformance checking is that of detecting and describing {{the differences between the}} process model and the event log. A desirable feature is to produce a minimal yet complete set of behavioral differences. Existing conformance checking techniques that achieve these properties do not scale up to real-life process models and event logs. This paper presents a technique that addresses this shortcoming by exploiting scalable automata-based techniques. A log is converted into a deterministic automaton in a lossless manner, the input process model is converted into another minimal automaton, and a minimal error- correcting synchronized product of the two automata is calculated using an admissible A* heuristic. The resulting automaton is used to extract alignments between traces produced by the model and traces in the log, or statements describing behavior observed in the log but not captured in the model. An evaluation based on real-life models and logs shows that the proposed technique significantly outperforms a state of the art technique for complete conformance checking...|$|E
40|$|IntroductionThis study {{compared}} {{two different}} applications of Guided Self-rehabilitation Contracts (GSC) in Parkinson's disease, individual (I) or group-wise (C), in a 3 -month intensive training focused on balance. MethodsFourteen patients were randomized into 2 parallel groups (I and C) with one physical therapy session every 10 days for 3 months. Each session associated education and exercise prescription that each patient had to perform daily between sessions. Each patient was {{to complete a}} <b>log</b> <b>recording</b> daily work and wear a pedometer. Evaluations, OFF and ON, included Global Mobility Task (GMT), UPDRS III, proof of effort, 20 -m walk test, 2 -minute endurance test and Functional Reach Test (FRT). ResultsResults {{of the two groups}} were similar. Patients worked alone about 40 minutes a day, 6 days per week. Improvements involved the daily number of steps (+ 19. 2 %, P= 0. 091), UPDRS III-OFF (– 30. 1 %, P= 0. 029), GMT-ON (– 11. 2 %, P= 0. 042) and stride length at comfortable speed (+ 9. 6 %, P= 0. 029). ConclusionAn intensive rehabilitation program {{in the form of a}} GSC is feasible in Parkinson's disease, either individually or collectively; it seems to reduce parkinsonian symptoms and to bring functional benefits...|$|E
40|$|Theoretical and {{research}} models of disability traditionally focus on effects on personality development and interpersonal disturbances. An alternative model analyzes {{the social and}} political implications of disability and recommends modification of the environment as the intervention of choice. Strengthening competence to effect environmental changes may be accomplished through self-advocacy. Self-advocacy is comprised of a set of skills as well as a knowledge base about civil rights legislation such as the Americans with Disabilities Act. As a formative evaluation this project investigated the process involved in providing a self-advocacy skills group to adolescents with physical disabilities. ^ The goals of this group were to increase knowledge of disability rights and legislation, to increase skills needed to secure these rights, and provide a means of social support. The group was conducted as part of a weekend recreation and socialization program for adolescents who have disabilities. ^ Data was collected through a <b>log</b> <b>recording</b> the investigator 2 ̆ 7 s observations during weekly self-advocacy group meetings, participant rating scales, and semi-structured interviews. Qualitative evaluation was conducted to identify themes and categories which emerged from the data and were related to the research questions. Participants 2 ̆ 7 levels of satisfaction, and strengths and needs of the group in meeting its objectives were assessed. Data can be utilized to develop and evaluate future groups. ^ Concerns with attitudinal barriers and social accessibility emerged as salient issues for participants in this group. Social support appeared beneficial to group members. Inconsistent attendance limited the implementation of structured skills training. Entry problems and site negotiation were reviewed as part of this project. Implications for future self-advocacy training groups are discussed. ...|$|E
5000|$|Journald Agent {{provides}} {{access to}} <b>logging</b> <b>records</b> through the standard OpenLMI interface. It is a client of systemd's journald service, accessing the journald records in several ways and providing a way to store new <b>log</b> <b>records.</b> Journald, as a structured logging system, stores supplemental information along each record, {{making it easier to}} find and extract information from the resulting log files.|$|R
40|$|International audienceTraditional {{access control}} {{mechanisms}} prevent illegal access by controlling access right before executing an action; they belong to a class of a priori security solutions and, {{from this point of}} view, they have some limitations, like inflexibility in unanticipated circumstances. By contrast, a posteriori mechanisms enforce policies not by preventing unauthorized access, but rather by deterring it. Such access control needs evidence to prove violations. Evidence is derived from <b>log</b> <b>records,</b> which trace each user's actions. Efficiency of violation detection mostly depends on the compliance of <b>log</b> <b>records</b> with the access and usage control policy. In order to develop an efficient method for finding these violations, we propose restructuring <b>log</b> <b>records</b> according to a security policy model. We illustrate our methodology by applying it to the healthcare domain, taking care of the Integrating the Healthcare Enterprise (IHE) framework, particularly its basic security profile, ATNA (Audit Trail and Node Authentication). This profile defines <b>log</b> <b>records</b> established on the analysis of common health practice scenarios. We analyze and establish how ATNA <b>log</b> <b>records</b> can be refined in order to be integrated into an a posteriori access and usage control process, based on an expressive and contextual security policy like the OrBAC (Organization Based Access Control) policy...|$|R
30|$|<b>Log</b> <b>records</b> {{are stored}} on disk continuously. Therefore, {{there are no}} holes in log files.|$|R
