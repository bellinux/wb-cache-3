30|244|Public
5000|$|... {{find the}} {{corresponding}} color- and video-attribute information for each <b>lexical</b> <b>element,</b> and ...|$|E
5000|$|Many city {{names of}} the Dacians were {{composed}} of an initial <b>lexical</b> <b>element</b> (often the tribe name) affixed to -dava, -daua, -deva, -deba, -daba or -dova (<PIE *dʰeh₁-, [...] "to set, place").|$|E
5000|$|A context {{model can}} {{also apply to}} the {{surrounding}} elements in a gene sequence. Like the context rules of a grammar disambiguating a <b>lexical</b> <b>element,</b> this helps to disambiguate {{the role of the}} gene.|$|E
50|$|The ethnonym Gundangara {{combines}} <b>lexical</b> <b>elements</b> signifying both 'east' and west'.|$|R
40|$|This study {{investigated}} the use of <b>lexical</b> <b>elements</b> of cohesion in the essay writing of students of English as a Second Language. Two hundred essays of final year students of the University of Nigeria, Nsukka were collated and analyzed by the researchers {{in order to identify}} the <b>lexical</b> <b>elements</b> used to achieve cohesion in writing. The result showed that students used three <b>lexical</b> <b>elements</b> as postulated by Gutwinski in varying degrees in their writings. These include: repetition, synonyms, and lexical sets (collocations). Students tended to use more of repetitions and made minimal use of synonyms and lexical sets to achieve cohesion in writing. This has led to poorly written essays by students. It also implies that <b>lexical</b> cohesion <b>elements</b> should be taught in schools to enable students use them appropriately in writing...|$|R
40|$|The {{study is}} written {{in an attempt to}} report on factors that affect {{language}} transfer between Hungarian and English and on the extent 1. 1 and 1. 2 <b>lexical</b> <b>elements</b> are integrated into the speech in either language. An attempt is made to classify the functions of the integrated <b>lexical</b> <b>elements.</b> Furthermore, it is hypothesised that transfer could be interpreted as a production strategy. Data collection included a questionnaire and audio recording of interviews and observations of eleven bilingual participants involved in problem solving tasks...|$|R
5000|$|In the {{situation}} of parsing a grammar, a context model defines the surrounding text of a <b>lexical</b> <b>element.</b> This enables a context sensitive grammar that can have deterministic or stochastic rules. In the latter case, a hidden Markov model can provide the probabilities for the surrounding context.|$|E
5000|$|Ket makes {{significant}} use of incorporation. Incorporation is {{not limited}} to nouns, and can also include verbs, adverbs, adjectives, and bound morphemes found only in the role of incorporated elements. Incorporation also occurs as both a lexicalized process - the combination of verb and incorporate being treated as a distinct <b>lexical</b> <b>element,</b> with a meaning often based around the incorporated element - and a paradigmatic one, where the incorporation is performed spontaneously for particular semantic and pragmatic effect Forms of incorporation include: ...|$|E
50|$|Basque has {{a fairly}} large number of {{compound}} verbs of a type also known as light verb constructions, consisting of two parts. The first component is a <b>lexical</b> <b>element</b> which is often (but not always) an undeclined noun. The second is a common verb which contributes less semantic content to the construction but is the part that is conjugated, thus lending to the whole its verbal character. Details of conjugation depend on the light verb used, which may be one that has synthetic finite forms (e.g. izan), or a verb without synthetic finite forms (e.g. egin or hartu).|$|E
40|$|We {{describe}} and evaluate three systems for automatically predicting the ICD- 9 -CM codes of radiology reports from short excerpts of text. The first system benefits {{from an open}} source search engine, Lucene, and {{takes advantage of the}} relevance of reports to one another based on individual words. The second uses BoosTexter, a boosting algorithm based on n-grams (sequences of consecutive words) and s-grams (sequences of non-consecutive words) extracted from the reports. The third employs a set of hand-crafted rules that capture <b>lexical</b> <b>elements</b> (short, meaningful, strings of words) derived from BoosTexter’s n-grams, and that are enhanced by shallow semantic information in the form of negation, synonymy, and uncertainty. Our evaluation shows that semantic information significantly contributes to ICD- 9 -CM coding with <b>lexical</b> <b>elements.</b> Also, a simple hand-crafted rule-based system with <b>lexical</b> <b>elements</b> and semantic information can outperform algorithmically more complex systems, such as Lucene and BoosTexter, when these systems base their ICD- 9 -CM predictions only upon individual words, n-grams, or s-grams...|$|R
50|$|Oromo - Hamitic {{inhabitants}} of Ethiopia and environs. Also {{known as the}} Galla, they {{are believed to have}} introduced many cultural and <b>lexical</b> <b>elements</b> to communities in the Great Lakes region to the south.|$|R
40|$|The paper {{reports on}} two {{experiments}} {{with the head}} turn preference method which provide evidence that already at 7 to 9 months, but not yet at 6 months, German-learning infants do recognize unstressed closed-class <b>lexical</b> <b>elements</b> in continuous speech. These findings {{support the view that}} even preverbal children are able to compute at least phonological representations for closed-class functional elements. They also suggest that these elements must be available to the language learning mechanisms of the child from very early on, allowing the child {{to make use of the}} distributional properties of closed-class <b>lexical</b> <b>elements</b> for further top-down analysis of the linguistic input, e. g. segmentation and syntactic categorization...|$|R
5000|$|Divergence names a {{state of}} affairs {{subsequent}} to some change, namely {{the result of the}} process called [...] "split" [...] by Heine and Reh. [...] "When a lexical form undergoes grammaticalization to a clitic or affix, the original form may remain as an autonomous <b>lexical</b> <b>element</b> and undergo the same changes as ordinary lexical items." [...] (Hopper 1991: 22) A possible formal distinction between divergence and split would be that the latter seems to be confined to cases where one and the same source has several targets, whereas the former merely refers to the drifting apart of previously more similar items.|$|E
5000|$|Gestures are {{distinct}} from manual signs {{in that they}} do not belong to a complete language system. [...] For example, pointing through the extension of a body part, especially the index finger to indicate interest in an object is a widely used gesture that is understood by many cultures On the other hand, manual signs are conventionalized—they are gestures that have become a <b>lexical</b> <b>element</b> in a language. A good example of manual signing is American Sign Language (ASL)-when individuals communicate via ASL, their signs have meanings that are equivalent to words (e.g., two people communicating using ASL both understand that forming a fist with your right hand and rotating this fist using clockwise motions on the chest carries the lexical meaning of the word [...] "sorry").|$|E
40|$|Two Event-Related Potential (ERP) studies {{contrast}} {{the processing of}} locally ambiguous sentences in the visual and the auditory modality. These sentences are disambiguated by a <b>lexical</b> <b>element.</b> Before this element appears in a sentence, the sentence can also be disambiguated by a boundary marker: a comma in the visual modality, or a prosodic break in the auditory modality. Previous {{studies have shown that}} a specific ERP component, the Closure Positive Shift (CPS), can be elicited by these markers. The results of the present studies show that both the comma and the prosodic break disambiguate the ambiguous sentences before the critical <b>lexical</b> <b>element,</b> despite the fact that a clear CPS is only found in the auditory modality. Comma and prosodic break thus have parallel functions irrespective of whether they do or do not elicit a CPS...|$|E
30|$|As van der Sandt (1988 : 37) says, “The {{oldest and}} best-known test for {{determining}} which syntactic constructions and <b>lexical</b> <b>elements</b> {{give rise to}} presuppositions is embedding under negation”. However, he then (ibid.: 37 – 39) mentions problems with this test.|$|R
40|$|Traditional Authorship Attribution models extract {{normalized}} {{counts of}} <b>lexical</b> <b>elements</b> such as nouns, common words and punctuation and use these normalized counts or ratios as features for author fingerprinting. The text {{is viewed as}} a bag-of-words and the order of words and their position relative to other words is largely ignored. We propose a new method of feature extraction which quantifies the distribution of <b>lexical</b> <b>elements</b> within the text using Kolmogorov complexity estimates. Testing carried out on blog corpora indicates that such measures outperform ratios when used as features in an SVM authorship attribution model. Moreover, by adding complexity estimates to a model using ratios, we were able to increase the F-measure by 5. 2 - 11. 8...|$|R
40|$|Paper {{deals with}} the lexical {{analysis}} of the Old Church Slavonic version of the Apocryphal Questions of Bartholomew, a literary monument written most likely in Greek in the 3 rd century. The analysis shows that the Slavonic version contains not only <b>lexical</b> <b>elements</b> typical for the Preslav redaction, but also some archaic figures. This leads to the conclusion, that the primal Old Church Slavonic translation may be made in Bulgaria in the 10 th century. There are two possibilities of a more exact dating. The text may have been translated in the early 10 th century when the <b>lexical</b> <b>elements</b> of the Preslav redaction weren’t strictly used yet and still there occurred many archaic figures. The second possibility is that the translation was made later in the 10 th century {{in one of the}} distant centers of the Preslav literary school, in which a specific tradition in using Preslav and archaic <b>lexical</b> <b>elements</b> was held. However, a further lexical and language analysis is needed for the confirmation of the stated dating. При поддержке гранта GA ČR P 406 / 12 / 1790 Staroslověnská lexikologie – nové příspěvky ke staroslověnské lexikografii...|$|R
40|$|Lexical and syntactical {{structures}} of French scientific text, presenting difficulties to learners and causing misunderstanding, which {{are associated with}} the relations of lexical units and syntactical structures in the text, are considered. It is found lexical units, e. g. terms, literary language, function words, acquire their meaning due to syntactic structures. One of the text elements ensuring the cohesion of the text is que, a conjunction, adverb and pronoun. The emphasis is placed on the variety of meanings of this <b>lexical</b> <b>element...</b>|$|E
40|$|Grammaticalization {{is a type}} of {{syntactic}} {{change by}} which a semantically contentive <b>lexical</b> <b>element</b> becomes a grammatical element. This paper presents the historical development of the Portuguese verbs haver and ter over time as an example of grammaticalization. It is the contention of this paper that the semantic loss experienced by these lexical items, combined with general principles of grammar, as posited by Chomsky in his Minimalist Program (1995), suffice to account for the fact that such verbal elements have developed from lexical categories into functional ones...|$|E
40|$|The {{status of}} the Malay <b>lexical</b> <b>element</b> in Tetum is contextually {{parallel}} {{to that of the}} Portuguese <b>lexical</b> <b>element</b> in Malay itself: a superstratum transformed into an adstratum by the advent of a new imperialism and a new superstratum (Dutch for Malay and Portuguese for Tetum). What principally distinguishes Malay and Tetum {{is the fact that the}} former, given its more westerly situation on the fringe of the Asian continent, had already been exposed to two potent linguistic influences: Sanskrit, the medium of Hinduism, and Arabic, the language of Islam. Before the fifteenth century the vocabulary of Tetum was entirely indigenous except for an infusion of Old Ambonese words. Whereas the Portuguese influence on Malay was merely one in a series of substrata (Sanskirt and Arabic elements always remaining numerically more important than the Portuguese component), the impact of the Malay superstratum in Tetum was great, reflecting as it did the introduction of a technologically more advanced culture into the island. Moreover, all the historic influences on Malay were condensed in this body of loanwords (apart from the last layer, that of English), with the result that before the mid-nineteenth century whatever there was of Sanskrit, Arabic, Persian, Hindi, Tamil, Chinese and Dutch in the vocabulary of Tetum had entered through the single door of Malay. 41 page(s...|$|E
40|$|This article aims at {{exploring}} the linguistic outcomes of English impact on colloquial, urban variety of Hindi. The {{goal is to}} establish what <b>lexical</b> <b>elements</b> are loaned {{and how they are}} adapted to the structure of UCH. It will also be examined whether UCH has recently undergone any structural interference from English, since such interference occurs in addition to extensive lexical borrowing. This article aims {{at exploring}} the linguistic outcomes of English impact on colloquial, urban variety of Hindi. The goal is to establish what <b>lexical</b> <b>elements</b> are loaned and how they are adapted to the structure of UCH. It will also be examined whether UCH has recently undergone any structural interference from English, since such interference occurs in addition to extensive lexical borrowing...|$|R
50|$|The unidirectionality {{hypothesis}} {{is the idea}} that grammaticalization, the development of <b>lexical</b> <b>elements</b> into grammatical ones, or less grammatical into more grammatical, is the preferred direction of linguistic change, that a grammatical item is much less likely to move backwards rather than forwards on Hopper & Traugott's cline of grammaticalization.|$|R
5000|$|In {{computer}} science, {{terminal and}} nonterminal symbols are the <b>lexical</b> <b>elements</b> used in specifying the production rules constituting a formal grammar. Terminal symbols are the elementary {{symbols of the}} [...] language defined by a formal grammar. Nonterminal symbols (or syntactic variables) are replaced by groups of terminal symbols according to the production rules.|$|R
40|$|Abstract]The {{influence}} of the Scandinavian dialects on English has been often studied though no significant progress {{seems to have been}} achieved. The major aim {{of this paper is to}} offer a methodological approach which can provide a description of the Scandinavian <b>lexical</b> <b>element</b> in Middle English but considering it in its different aspects. Thus, we will undertake a corpus-based analysis where different variables such as semantic field, type of text and dialect among others are taken into consideration. The resulting description will reveal that the linguistic intercourse must have been different from what traditional scholars have always believe...|$|E
40|$|We {{address the}} general problem faced by {{designers}} of computational lexica: that of relating surface forms to underlying lexical forms through the vehicle of a precise linguistic description {{expressed in a}} suitable formalism. For such a description to be useful, it must be possible for the relation to be computable: given a surface element, we need to compute the corresponding <b>lexical</b> <b>element</b> or elements, and vice cersa. Below we concentrate upon the description of a minimal example: prepositional phrases, a reasonably well-defined and compact subset of Maltese surface phenomena that exemplifies many of the di#culties that are typical of Semitic languages...|$|E
40|$|The {{influence}} of the Scandinavian dialects on English has been often studied though no significant progress {{seems to have been}} achieved. The major aim {{of this paper is to}} offer a methodological approach which can provide a description of the Scandinavian <b>lexical</b> <b>element</b> in Middle English but considering it in its different aspects. Thus, we will undertake a corpus-based analysis where different variables such as semantic field, type of text and dialect among others are taken into consideration. The resulting description will reveal that the linguistic intercourse must have been different from what traditional scholars have always believed...|$|E
40|$|Tesnière (1959) {{is often}} {{regarded}} as {{the founder of the}} modern theoretical tradition of dependency grammar, but it is not one well-defined theory. Instead, it comprises several related theories, having some core notions in common. Such a notion is the directed relations between pairs of <b>lexical</b> <b>elements,</b> but the formalism and the criteria fo...|$|R
40|$|The paper {{covers the}} issues related with the {{different}} types (newspapq political, legal, literary, academic etc.) of discourse from the pragmatic and cognitive perspective of the discourse participant. It reveals that the characteristic feature of political, newspaper, academic, legal discourse is argumentation based on cause-effect relations. Grammatical and <b>lexical</b> <b>elements</b> are explicit signals d these relations...|$|R
30|$|In fact, {{support for}} {{including}} larger <b>lexical</b> <b>elements</b> comes from Halliday (1994 : 311), who includes ‘wordings {{having more than}} one lexical item in them, such as maintaining an express locomotive at full steam’ (italics in the original) in his description of what constitutes reiteration and collocation, {{both of which are}} ‘relations between lexical elements’, i.e. features of lexical cohesion.|$|R
40|$|Our study {{focuses on}} how the {{discourse}} markers (DM) participate {{in the construction of}} discursive alterity. In our approach, the DM builds, for an assertion, a guarantor with its own semantics, which is the semantics of the <b>lexical</b> <b>element</b> constituting the basis of DM. Naturellement and bien entendu build referential value which ”disempowers” the speaker as a guarantor of his words. This desubjectivation is realized differently in each case analyzed, and is determined by the semantic identity of the DM. In this article we analyze how the DM build modulated commitment of the speaker in his role as the guarantor, convened by the semantics of the DM in the ”disresponsibilization” of the speaker as a guarantor of his own words...|$|E
40|$|The {{change of}} a <b>lexical</b> <b>element</b> into a {{grammatical}} (closed class) element must necessarily include intermediary stages where the element is considered gradually less lexical and more grammatical. The central assumptions {{in this study}} are the gradualness and gradience of grammaticalization, that natural language change cannot happen overnight, and that the change is driven by individual speakers of a language community (cf. Traugott and Trousdale 2010 : 23, 26). Using a data sample from a questionnaire on spatial grams of the EXTERIOR-REGION (cf. Svorou 1994) in Estonian, Võro and Latvian, an attempt is made to model diachronic gradualness through synchronic gradience. The analysis and the explication thereof are carried out using multidimensional scaling, a statistical modelling method used akin to semantic maps...|$|E
40|$|A lemmatiser-tagger {{must not}} only lemmatise word-forms {{consisting}} of a single <b>lexical</b> <b>element</b> but {{it must also be}} able to detect complex units. In this paper we try to delimit linguistically which complex words deserve to be lemmatised as a unit. Then, we propose a formal description for MultiWord Lexical Units (MWLU) in Basque [...] -resulting of a conscientious analysis of their syntactic and morphological behaviour. Based on that formal description we propose a simple logical formalism to represent those MWLUs {{so that they can be}} automatically processed. 1. Introduction A lemmatiser-tagger is a computational tool used for assigning the correct lemma and grammatical category to each token of a corpus. It is a basic device for corpus analysis, automatic indexation, syntactic and semantic analyses etc. For example, the lemmatiser-tagger for Basque (EUSLEM) (Aduriz et al., 96 a) is essential for the second phase of the Systematic Compilation of Modern Basque 1 (EEBS) project (Urkia et a [...] ...|$|E
50|$|In the twenty-second {{edition of}} the Spanish Royal Academy Dictionary, 2001, AHL made a {{valuable}} contribution to the Spanish-speaking world: 1,950 Hondurans were incorporated. In the twenty-first edition, in 1992, there were 302. Thus, there are about 2,702, including 400 Honduran gentilices, which makes Honduran Spanish speakers {{one of the greatest}} contributors of new <b>lexical</b> <b>elements</b> in that {{edition of the}} dictionary.|$|R
30|$|The {{knowledge}} exchanged in {{a curriculum}} genre is realised by lexical items, and by lexical relations and reference relations between items. Briefly, lexical relations include a) nuclear relations between processes, people, things, places and qualities in an activity; b) activity sequences that construe unfolding series of activities; c) taxonomic relations between <b>lexical</b> <b>elements</b> in a text, including repetition, synonymy, contrast, meronymy (whole-part) and hyponymy (class-member).|$|R
50|$|Below is a table showing both words {{cited as}} being Thracian in {{classical}} sources, and <b>lexical</b> <b>elements</b> {{that have been}} extracted by paleolinguists from Thracian anthroponyms, toponyms, etc. In this table the closest cognates are shown, {{with an emphasis on}} cognates in Bulgarian, Albanian, Baltic, Slavic, Greek, and substratum and/or old-layer words in the Eastern Romance languages: Romanian, Aromanian, et cetera. See also the List of reconstructed Dacian words.|$|R
