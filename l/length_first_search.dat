0|5651|Public
40|$|Multiple {{sequence}} alignment (MSA) is a ubiquitous {{problem in}} computational biology. Although it is NP-hard {{to find an}} optimal solution for an arbitrary number of sequences, due {{to the importance of}} this problem researchers are trying to push the limits of exact algorithms further. Since MSA can be cast as a classical path finding problem, it is attracting a growing number of AI researchers interested in heuristic search algorithms as a challenge with actual practical relevance. In this paper, we first review two previous, complementary lines of research. Based on Hirschberg’s algorithm, Dynamic Programming needs O(kN k− 1) space to store both the search frontier and the nodes needed to reconstruct the solution path, for k sequences of <b>length</b> N. Best <b>first</b> <b>search,</b> on the other hand, has the advantage of bounding the search space that has to be explored using a heuristic. However, it is necessary to maintain all explored nodes up to the final solution in order to prevent the search from re-expanding them at higher cost. Earlier approaches to reduce the Closed list are either incompatible with pruning methods for the Open list, or must retain at least the boundary of the Close...|$|R
2500|$|Each phase {{consists}} of a single breadth <b>first</b> <b>search</b> and a single depth <b>first</b> <b>search.</b> Thus, a single phase may be implemented in [...] time.|$|R
50|$|A strong {{orientation}} {{of a given}} bridgeless undirected graph {{may be found in}} linear time by performing a depth <b>first</b> <b>search</b> of the graph, orienting all edges in the depth <b>first</b> <b>search</b> tree away from the tree root, and orienting all the remaining edges (which must necessarily connect an ancestor and a descendant in the depth <b>first</b> <b>search</b> tree) from the descendant to the ancestor. Although this algorithm is not suitable for parallel computers, due to the difficulty of performing depth <b>first</b> <b>search</b> on them, alternative algorithms are available that solve the problem efficiently in the parallel model. Parallel algorithms are also known for finding strongly connected orientations of mixed graphs.|$|R
5000|$|Each phase {{consists}} of a single breadth <b>first</b> <b>search</b> and a single depth <b>first</b> <b>search.</b> Thus, a single phase may be implemented in [...] time.Therefore, the first [...] phases, in a graph with [...] vertices and [...] edges, take time [...]|$|R
40|$|Abstract. We present {{algorithms}} to efficiently bound {{the depth}} of the state spaces explored by explicit state model checkers. Given a parameter k, our algorithms guarantee finding any violation of an invariant that is witnessed using a counterexample of length k or less from the initial state. Though depth bounding is natural with breadth <b>first</b> <b>search,</b> explicit state model checkers are unable to use breadth <b>first</b> <b>search</b> due to prohibitive space requirements, and use depth <b>first</b> <b>search</b> to explore large state spaces. Thus, we explore efficient ways to perform depth bounding with depth <b>first</b> <b>search.</b> We prove our algorithms sound (in the sense that they explore exactly all the states reachable within a depth bound), and show their effectiveness on large real-life models from Microsoft’s product groups. ...|$|R
50|$|Kosaraju's {{algorithm}} uses two passes {{of depth}} <b>first</b> <b>search.</b> The <b>first,</b> {{in the original}} graph, is used to choose {{the order in which}} the outer loop of the second depth <b>first</b> <b>search</b> tests vertices for having been visited already and recursively explores them if not. The second depth <b>first</b> <b>search</b> is on the transpose graph of the original graph, and each recursive exploration finds a single new strongly connected component. It is named after S. Rao Kosaraju, who described it (but did not publish his results) in 1978; Micha Sharir later published it in 1981.|$|R
50|$|There {{were two}} types of searching {{algorithms}} tried out for this implementation. There was the random search and the depth <b>first</b> <b>search.</b> A random search is where each of the agents go in any direction through the environment {{and try to find}} a pathway out. The depth <b>first</b> <b>search</b> is where agents follow one path as far as it can go then return and try another path if the path they traversed does not contain an exit. If was found that depth <b>first</b> <b>search</b> gave a speed up of 15 times versus a random search.|$|R
40|$|Pengembangan Multimedia Pembelajaran Interaktif dengan Metode Heuristik Tipe Best <b>First</b> <b>Search</b> untuk Mata Pelajaran Desain Grafis SMK” adalah penelitian dan pengembangan yang bertujuan untuk : 1) Mengetahui bagaimana mengembangkan Multimedia Pembelajaran Interaktif dengan Metode Heuristik Tipe Best <b>First</b> <b>Search</b> dan 2) Mengetahui apakah ada pengaruh Multimedia Pembelajaran Interaktif dengan Metode Heuristik Tipe Best <b>First</b> <b>Search</b> terhadap pemahaman siswa dalam Mata Pelajaran Desain Grafis. Hasil dari penelitian ini adalah : 1) Mengembangkan Multimedia Pembelajaran Interaktif Metode Heuristik Tipe Best <b>First</b> <b>Search</b> dilakukan dengan Metode Penelitian Research and Development yang terdiri dari identifikasi potensi masalah, pengumpulan data, desain produk, validasi desain, revisi desain, pengembangan, dan uji coba produk. Multimedia ini menggunakan model perancangan {{waterfall}} yang terdiri dari analisis, desain, kode, dan Tes. 2) Multimedia Pembelajaran Interaktif Metode Heurustik Tipe Best <b>First</b> <b>Search</b> berpengaruh terhadap pemahaman siswa, berdasarkan hasil penelitian terjadi peningkatan dari nilai pretest hingga nilai postest siswa dengan signifikansi indeks gain yang dihasilkan sebesar 0, 6 artinya penilaian indeks gain dalam pengaruhnya terhadap pembelajaran termasuk ke dalam kriteria “sedang”. Adapun hasil angket respon siswa terhadap multimedia menunjukan perolehan persentase sebesar 77, 76...|$|R
5000|$|... #Subtitle level 2: World’s <b>First</b> <b>Search</b> Engine for Golf Courses ...|$|R
5000|$|<b>First,</b> <b>search</b> {{for small}} prime factors of [...]We quickly find that ...|$|R
5000|$|Databases - Online articles, newspapers, maps, etc. (EBSCOhost and <b>First</b> <b>Search)</b> ...|$|R
50|$|Once a 2-SAT {{problem is}} reduced to a graph, then if a depth <b>first</b> <b>search</b> finds a {{strongly}} connected component with both phases of a variable, then the 2-SAT problem is not satisfiable. Likewise, if the depth <b>first</b> <b>search</b> does not find a strongly connected component with both phases of a variable, then the 2-SAT problem is satisfiable.|$|R
30|$|Active node {{for further}} {{branching}} is {{selected based on}} Depth <b>First</b> <b>Search</b> (DFS).|$|R
40|$|Plan Quality {{is defined}} as the sum of the costs {{associated}} with all the actions in a plan. This definition is incorporated into the Partial Order planner, UCPOP. For finding the optimal plans efficiently, he standard Best <b>First</b> <b>Search</b> strategy was compared against two versions of Iterative Deepening that were added to the UCPOP planner. Experiments over several problems in an extended version of blocks world domain and logistics domain show that while the first iterative deepening algorithm, based on the Depth <b>First</b> <b>Search</b> (ID-DEPTH-FS) yielded optimal plans with respect to number of actions in them, the second iterative deepening algorithm, based on the best <b>first</b> <b>search</b> (ID-BEST-FS) was both effective and efficient in finding optimal plans with respect to the total cost of all actions in it. Experiments on various ranking functions have shown that for standard Best <b>First</b> <b>Search</b> and its variants and for the the two iterative deepening algorithms added to UCPOP, ranking function based [...] ...|$|R
40|$|Slide puzzle {{is a game}} {{to compile}} pieces of a picture {{appropriate}} to its position. A piece can only be moved by screp {{it out to the}} empty space, {{and it is going to}} be a difficulty apart to finish the game. Slide puzzle needs an algorithm, way to search for which is used to get the game solution. In this paper is explained about applying of Breadth <b>First</b> <b>Search</b> and Depth <b>First</b> <b>Search</b> algorithm in the slide puzzle game by using Microsoft Visual Basic 6. 0. After that, it would be tested to finishing game manually (using people as player) and finishing game by using Breadth <b>First</b> <b>Search</b> and Depth <b>First</b> <b>search</b> algorithm (in this case computer). From the result of test, can be seen that searching by algorithm can be used to optimal of time and path solution in finishing slide puzzle which usually can’t be done if finishing game manually. ...|$|R
40|$|AbstractLet Pl,n {{denote the}} {{partition}} lattice of l with n parts, ordered by Hardy–Littlewood–Polya majorization. For any two comparable elements x and y of Pl,n, we denote by M(x,y), m(x,y), f(x,y), and F(x,y), respectively, {{the sizes of}} four typical chains between x and y: the longest chain, the shortest chain, the lexicographic chain, and the counter-lexicographic chain. The covers u=(u 1,…,un) ≻v=(v 1,…,vn) in Pl,n are of two types: N-shift (nearby shift) where vi=ui− 1, vi+ 1 =ui+ 1 + 1 for some i; and D-shift (distant shift) where ui− 1 =vi=vi+ 1 =⋯=vj=uj+ 1 for some i and j. An N-shift (a D-shift) is pure {{if it is not}} a D-shift (an N-shift). We develop linear algorithms for calculating M(x,y), m(x,y), f(x,y), and F(x,y), using the leftmost pure N-shift <b>first</b> <b>search,</b> the rightmost pure D-shift <b>first</b> <b>search,</b> the leftmost N-shift <b>first</b> <b>search,</b> and the rightmost D-shift <b>first</b> <b>search,</b> respectively. Those algorithms have significant applications in complexity analysis of biological sequences...|$|R
50|$|The path-based strong {{component}} algorithm uses a depth <b>first</b> <b>search,</b> like Tarjan's algorithm, {{but with}} two stacks. One of the stacks {{is used to}} keep track of the vertices not yet assigned to components, while the other keeps track of the current path in the depth <b>first</b> <b>search</b> tree. The <b>first</b> linear time version of this algorithm was published by Edsger W. Dijkstra in 1976.|$|R
50|$|Resident deans have {{separate}} administrative and personal email accounts. The <b>first</b> <b>search</b> examined only the administrative account.|$|R
5000|$|This {{application}} {{was the original}} motivation that led [...] to develop the lexicographic breadth <b>first</b> <b>search</b> algorithm.|$|R
5000|$|Water Rats: Dead in the Water (1996, director, telemovie <b>length</b> <b>first</b> {{episode of}} Water Rats) ...|$|R
40|$|The {{standard}} serial algorithm for strongly connected components has {{linear complexity}} {{and is based}} on depth <b>first</b> <b>search.</b> Unfortunately, depth <b>first</b> <b>search</b> is difficult to parallelize. We describe a divide-and-conquer algorithm for this problem which has significantly greater potential for parallelization. We show the expected serial running time of our algorithm to be O(|E| log |V|). We also present a variant of our algorithm that has O(|E| log |V|) worst-case complexity...|$|R
5000|$|A strong {{orientation}} {{of a given}} bridgeless undirected graph {{may be found in}} linear time by performing a depth <b>first</b> <b>search</b> of the graph, orienting all edges in the depth <b>first</b> <b>search</b> tree away from the tree root, and orienting all the remaining edges (which must necessarily connect an ancestor and a descendant in the depth <b>first</b> <b>search</b> tree) from the descendant to the ancestor. If an undirected graph [...] with bridges is given, together with a list of ordered pairs of vertices that must be connected by directed paths, it is possible in polynomial time to find an {{orientation of}} [...] that connects all the given pairs, if such an orientation exists. However, the same problem is NP-complete when the input may be a mixed graph.|$|R
25|$|In 1990, {{with the}} rise of {{computer}} technology, the <b>first</b> <b>search</b> engine was built by computer engineer Alan Emtage.|$|R
5000|$|The {{bus driver}} {{observed}} the <b>first</b> <b>search</b> of the bus, {{and said that}} no gun was found on it.|$|R
6000|$|... 'Help yourself,' she {{answered}} sullenly. 'But <b>first</b> <b>search</b> his pouch; {{there may be}} some trifle there which we can divide.' ...|$|R
5000|$|... #Caption: The Petersen graph as a Moore graph. Any breadth <b>first</b> <b>search</b> tree has d(d-1)i {{vertices}} in its ith level.|$|R
5000|$|The <b>first</b> <b>search</b> for extremely-high energy cosmogenic neutrinos {{with the}} IceCube Neutrino Observatory. (R. Abbasi et al.) Phys.Rev.D82:072003, 2010. arXiv:1009.1442 ...|$|R
25|$|The {{algorithm}} terminates when no more augmenting paths {{are found}} in the breadth <b>first</b> <b>search</b> part of one of the phases.|$|R
40|$|This paper {{compares the}} {{performance}} of popular AI techniques, namely the Breadth <b>First</b> <b>Search,</b> Depth <b>First</b> <b>Search,</b> A* <b>Search,</b> Greedy Best <b>First</b> <b>Search</b> and the Hill Climbing Search in approaching the solution of a N-Puzzle of size 8, on a 3 x 3 matrix board and for {{the solution of the}} classic 8 Queen Puzzle. It looks at the complexity of each algorithm as it tries to approaches the solution in order to evaluate the operation of each technique and identify the better functioning one in various cases. The N Puzzle and the 8 Queen is used as the test scenario. An application was created to implement each of the algorithms to extract results for each of the cases. The paper also depicts the extent each algorithm goes through while processing the solution and hence helps to clarify the specific cases in which a technique may be preferred over another...|$|R
6000|$|... "That's easy to understand," [...] laughed Carroll. [...] "Like you, they'd {{no doubt}} <b>first</b> <b>search</b> the most {{difficult}} spots to get at." ...|$|R
40|$|Abstract — In this paper, {{the effect}} of various {{parameters}} on the offline browsing efficiency of a web archiving system using breadth <b>first</b> <b>search</b> Algorithm is investigated. A web crawler based multithreaded web archiving system is designed using breadth <b>first</b> <b>search</b> algorithm and the offline browsing efficiency of the web archiving system is estimated {{in the presence of}} the parameters like the searching algorithm, browsing tool, speed of the Internet connectivity and the processing system configuration...|$|R
40|$|The traditional, serial, {{algorithm}} {{for finding}} the strongly connected components in a graph {{is based on}} depth <b>first</b> <b>search</b> and has complexity which is linear {{in the size of}} the graph. Depth <b>first</b> <b>search</b> is difficult to parallelize, which creates a need for a different parallel algorithm for this problem. We describe the implementation of a recently proposed parallel algorithm that finds strongly connected components in distributed graphs, and discuss how it is used in a radiation transport solver...|$|R
40|$|The N-Queens {{problem is}} {{examined}} and programmatically implemented for Depth <b>First</b> <b>Search,</b> Depth <b>First</b> <b>Search</b> with improvements, Branch and Bound, and Beam Search. Sev-eral heuristics are presented and implemented {{with each of}} the searches. Results were ana-lyzed for number of nodes generated, number of nodes traversed, and relative execution time. While heuristics were found which gave Branch and Bound and Beam Search a significant edge over DFS, there exist polynomial time algorithms using complete board assignment an...|$|R
60|$|The forecastles and cabin were <b>first</b> <b>searched</b> closely. Several of {{the sailors}} then descended into the hold. Two {{lanterns}} were handed down to them.|$|R
40|$|This paper {{presents}} a quantitative {{investigation of the}} differences between rule extraction through breadth <b>first</b> <b>search</b> and through sampling the states of the RNN in interaction with its domain. We show that for an RNN trained to predict symbol sequences in formal grammar domains, the breadth <b>first</b> <b>search</b> is especially inefficient for languages sharing properties with realistic real world domains. We also identify some important research issues, needed to be resolved to ensure further development in the field of rule extraction from RNNs...|$|R
40|$|The {{strongly}} connected {{components of}} a directed graph {{can be found in}} an optimal linear time, by algorithms based on depth <b>first</b> <b>search.</b> Unfortunately, depth <b>first</b> <b>search</b> is difficult to parallelize. We describe two divide-and-conquer algorithms for this problem that have significantly greater potential for parallelization. We show the expected serial runtime of our simpler algorithm to be O(m log n), for a graph with n vertices and m edges. We then show that the second algorithm has O(m log n) worst–case complexity...|$|R
