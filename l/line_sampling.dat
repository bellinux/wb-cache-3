87|1872|Public
50|$|The ATSC digital {{television}} standards define 480p with either 704 × 480 (BT.601 <b>line</b> <b>sampling)</b> or 640 × 480 (unscaled <b>line</b> <b>sampling)</b> pixel resolutions, at 24, 30, or 60 progressive frames per second.|$|E
5000|$|For {{problems}} {{in which the}} dependence of the performance function is only moderately non-linear {{with respect to the}} parameters modeled as random variables, setting the importance direction as the gradient vector of the performance function in the underlying standard normal space leads to highly efficient <b>Line</b> <b>Sampling.</b> In general it can be shown that the variance obtained by <b>line</b> <b>sampling</b> is always smaller than that obtained by conventional Monte Carlo simulation, and hence the <b>line</b> <b>sampling</b> algorithm converges more quickly [...] The rate of convergence is made quicker still by recent advancements which allow the importance direction to be repeatedly updated throughout the simulation, and this is known as adaptive <b>line</b> <b>sampling</b> [...]|$|E
5000|$|... #Caption: An {{illustration}} of the <b>line</b> <b>sampling</b> algorithm. Two line samples are shown approaching the limit state surface.|$|E
5000|$|The song {{features}} dialogue <b>lines</b> <b>sampled</b> {{from various}} episodes of Star Trek: The Original Series: ...|$|R
5000|$|... "The Process of Addiction Has Its Costs" [...] Phillip Morris - (bass <b>line</b> <b>sampled</b> on Political Science) * ...|$|R
40|$|Abstract. After over 16 {{years of}} service at the inner walls of a steel {{absorber}} and outlet channel in wet FGD system, the rubber lining was subjected to examinations. A series of impedance spectra for the pre-vulcanized soft rubber lining based on chlorobutyl rubber (CIIR) were recorded. Rubber <b>lining</b> <b>samples</b> taken from the absorber bottom, which had {{been in contact with}} the washer sump solution, exhibited properties similar to those of new rubber <b>lining</b> <b>samples</b> not exposed to the corrosive environment. Rubber <b>lining</b> <b>samples</b> taken from the absorber upper part and from the outlet channel showed significant damage, and so deterioration in their protective properties, in comparison with the new lining. Also the results of tensile strength and hardness tests carried out on rubber samples taken from various parts of the absorber and the outlet channel are presented...|$|R
50|$|The {{accuracy}} of the method can be improved by averaging over many samples, which is known as <b>Line</b> <b>Sampling.</b>|$|E
50|$|The method {{essentially}} involves successively determining {{an envelope}} of straight-line segments that approximates the logarithm {{better and better}} while still remaining above the curve, starting with a fixed number of segments (possibly just a single tangent <b>line).</b> <b>Sampling</b> from a truncated exponential random variable is straightfoward. Just take the log of a uniform random variable (with appropriate interva and corresponding truncation).|$|E
5000|$|<b>Line</b> <b>sampling</b> is {{a method}} used in {{reliability}} engineering to compute small (i.e., rare event) failure probabilities encountered in engineering systems. The method is particularly suitable for high-dimensional reliability problems, in which the performance function exhibits moderate non-linearity {{with respect to the}} uncertain parameters [...] The method is suitable for analyzing Black box systems, and unlike the Importance sampling method of Variance reduction, does not require detailed knowledge of the system.|$|E
40|$|The {{development}} of <b>line</b> intersect <b>sampling</b> in forestry is reviewed. Topics include {{the motivation for}} the method as originally conceived {{for the assessment of}} logging residue, the modifications that have been suggested and employed by various workers, the evaluation of performance including the determination of the variance of estimates so obtained, the handling of non-random orientation of pieces and the relationship of the method to other sampling techniques, in particular, angle-count (horizontal-point) sampling. The paper concludes with some general thoughts on the place and role of <b>line</b> intersect <b>sampling.</b> The Origin of <b>Line</b> Intersect <b>Sampling</b> <b>Line</b> intersect <b>sampling</b> has its roots in Buffon's (1777) needle problem. Although Canfield's (1941) extension of <b>line</b> transect <b>sampling</b> and Mate&quot;rn's (1964) method for estimating the total length of roads by means of a line survey contain something of the essence of <b>line</b> intersect <b>sampling,</b> the method as currently applied in forestry stems, primarily, from Warren and Olsen's (1964) development for the assessment of logging residue. As far as is known, it was these authors who first used the term &quot;line intersect sampling&quot;. Similar approaches have been used in other areas, for example the estimation o...|$|R
40|$|We {{present a}} novel {{visibility}} algorithm for rendering motion blur with per-pixel anti-aliasing. Our algorithm uses {{a number of}} <b>line</b> <b>samples</b> over a rectangular group of pixels, and together with the time dimension, a two-dimensional spatio-temporal visibility problem needs to be solved per <b>line</b> <b>sample.</b> In a coarse culling step, our algorithm first uses a bounding volume hierarchy to rapidly remove geometry that do not overlap with the current <b>line</b> <b>sample.</b> For the remaining triangles, we approximate each triangle's depth function, along the line and along the time dimension, {{with a number of}} patch triangles. We resolve for the final color using an analytical visibility algorithm with depth sorting, simple occlusion culling, and clipping. Shading is decoupled from visibility, and we use a shading cache for efficient reuse of shaded values. In our results, we show practically noise-free renderings of motion blur with high-quality spatial anti-aliasing and with competitive rendering times. We also demonstrate that our algorithm, with some adjustments, can be used to accurately compute motion blurred ambient occlusion...|$|R
40|$|Figure 1 : Stylized {{animation}} of a galloping horse. From left to right: <b>line</b> <b>samples</b> are {{extracted from}} a 3 D model; active strokes track the samples; brush paths are attched to the strokes and stylized as circular arcs; two more frames of animation exhibit temporal coherence. This paper presents {{a method for}} creating coherently animated line drawings that include strong abstraction and stylization effects. These effects are achieved with active strokes: 2 D contours that approximate and track the lines of an animated 3 D scene. Active strokes perform two functions: they connect and smooth unorganized <b>line</b> <b>samples,</b> and they carry coherent parameterization to support stylized rendering. <b>Line</b> <b>samples</b> are approximated and tracked using active contours (“snakes”) that automatically update their arrangment and topology to match the animation. Parameterization is maintained by brush paths that follow the snakes but are independent, permitting substantial shape abstraction without compromising fidelity in tracking. This approach renders complex models {{in a wide range}} of styles at interactive rates, making it suitable for applications like games and interactive illustrations...|$|R
5000|$|Due to {{the wide}} use of {{computer}} simulation across very different fields of endeavour, articles on the topic arise from quite disparate sources {{and it is difficult}} to make a coherent survey of rare event sampling techniques. [...] Contemporary methods include Transition Path Sampling (TPS), Repetitive Simulation Trials After Reaching Thresholds (RESTART), Forward Flux Sampling (FFS), Generalized Splitting, Adaptive Multilevel Splitting (AMS), Stochastic Process Rare Event Sampling (SPRES), <b>Line</b> <b>sampling</b> and Subset simulation. The first published rare event technique was by Herman Kahn and Theodore Edward Harris in 1951, who in turn referred to an unpublished technical report by John von Neumann and Stanislaw Ulam.|$|E
5000|$|Subset Simulation {{takes the}} {{relationship}} between the (input) random variables and the (output) response quantity of interest as a 'black-box'. This can be attractive for complex systems where it is difficult to use other variance reduction or rare event sampling techniques that require prior information about the system behaviour. For problems where it is possible to incorporate prior information into the reliability algorithm, it is often more efficient to use other variance reduction techniques such as importance sampling. It has been shown that subset simulation is more efficient than traditional Monte Carlo simulation, but less efficient than <b>Line</b> <b>Sampling,</b> when applied to a fracture mechanics test problem [...]|$|E
5000|$|In mathematics, more {{specifically}} {{in the theory of}} Monte Carlo methods, variance reduction is a procedure used to increase the precision of the estimates that can be obtained for a given number of iterations. Every output random variable from the simulation is associated with a variance which limits the precision of the simulation results. In order to make a simulation statistically efficient, i.e., to obtain a greater precision and smaller confidence intervals for the output random variable of interest, variance reduction techniques can be used. The main ones are: Common random numbers, antithetic variates, control variates, importance sampling and stratified sampling. For simulation with black-box models Subset simulation and <b>line</b> <b>sampling</b> can also be used. Under these headings are a variety of specialized techniques; for example, particle transport simulations make extensive use of [...] "weight windows" [...] and [...] "splitting/Russian roulette" [...] techniques, which are a form of importance sampling.|$|E
50|$|This is a {{game where}} Competitors (most often equal on both sides) must pull their {{opposing}} team across a line, into a puddle, etc. A team is meant to resist their competitors effort to pull them across the <b>line.</b> <b>sample</b> pic.|$|R
30|$|Two <b>lines</b> of <b>samples</b> {{were tested}} for the acute toxic {{response}} of aconitine: (1) the herbal decoctions including licorice roots, aconite roots, mixed licorice, and aconite roots (w/w[*]=[*] 1 : 1); (2) aconitine solution, GP-AC mixture dispersion at pH 5.0, filtrates, and cutoff aggregates (GP-AC NPs) of the mixture separated by ultrafiltration (MW cutoff 100  kDa). AC contents of the second <b>line</b> <b>samples</b> were adjusted to 50  μg/mL to give a universal substance background for toxicity comparison.|$|R
40|$|An {{adaptive}} {{procedure is}} described for the <b>line</b> intercept <b>sampling.</b> Modified Hansen-Hurwitz and Horvitz-Thompson estimators {{are used to}} find estiamtors for the population mean, population density and coverage. An example is given to justify the method and to compare it with ordinary <b>line</b> intercept <b>sampling...</b>|$|R
5000|$|The {{basic idea}} behind <b>line</b> <b>sampling</b> is to refine {{estimates}} {{obtained from the}} First-order reliability method (FORM), which may be incorrect due to the non-linearity of the limit state function. Conceptually, this is achieved by averaging the result of different FORM simulations. In practice, this is made possible by identifying the importance direction [...] in the input parameter space, which points towards the region which most strongly contributes to the overall failure probability. The importance direction can be {{closely related to the}} center of mass of the failure region, or to the failure point with the highest probability density, which often falls at the closest point to the origin of the limit state function, when the random variables of the problem have been transformed into the standard normal space. Once the importance direction has been set to point towards the failure region, samples are randomly generated from the standard normal space and lines are drawn parallel to the importance direction in order to compute the distance to the limit state function, which enables the probability of failure to be estimated for each sample. These failure probabilities can then be averaged to obtain an improved estimate.|$|E
40|$|Abstract. For {{reliability}} analysis of implicit limit state function, an improved <b>line</b> <b>sampling</b> method is presented {{on the basis}} of sample simulation in failure region. In the presented method, Markov Chain is employed to simulate the samples located at failure region, and the important direction of <b>line</b> <b>sampling</b> is obtained from these simulated samples. Simultaneously, the simulated samples can be used as the samples for <b>line</b> <b>sampling</b> to evaluate the failure probability. Since the Markov Chain samples are recycled for both determination of the important direction and calculation of the failure probability, the computational cost of the <b>line</b> <b>sampling</b> is reduced greatly. The practical application in {{reliability analysis}} for low cycle fatigue life of an aeronautical engine turbine disc structure under 0 -takeoff- 0 cycle load shows that the presented method is rational and feasible...|$|E
40|$|Abstract Snags and cavity {{trees are}} {{important}} structural features in forests, {{but they are}} often sparsely distributed, making efficient inventories problematic. We present a straightforward modification of horizontal <b>line</b> <b>sampling</b> designed to facilitate inventory of these features while remaining compatible with commonly employed sampling methods for the living overstory. The method is simpler in its implementation than traditional horizontal <b>line</b> <b>sampling.</b> We develop unbiased estimators and present methods for dealing with special cases, including boundary overlap. A field test of the method shows it to have time efficiency comparable with or better than ordinary prism cruising, and it requires far fewer sample locations to achieve similar confidence limits. The method may also be useful for inventorying other rare or unusual trees...|$|E
40|$|We have {{developed}} an ultra-high-performance liquid chromatography-atmospheric pressure photoionization-tandem mass spectrometric (UHPLC-APPI-MS/MS) method for the simultaneous quantitative analyses of several oxysterols and vitamin D metabolites in mouse brain and cell <b>line</b> <b>samples.</b> An UHPLC-APPI-high resolution mass spectrometric (UHPLC-APPI-HRMS) method that uses a quadrupole-time of flight mass spectrometer was also developed for confirmatory analysis and for the identification of non-targeted oxysterols. Both methods showed good quantitative performance. Furthermore, APPI provides high ionization efficiency for determining oxysterols and vitamin D related compounds without the time consuming derivatization step needed in the conventionally used electrospray ionization method to achieve acceptable sensitivity. Several oxysterols were quantified in mouse brain and cell <b>line</b> <b>samples.</b> Additionally, 25 -hydroxyvitamin D 3 was detected in mouse brain samples for the first time...|$|R
5000|$|Lane <b>Lines,</b> A <b>Sampler,</b> Paris, France: Cahier d’Acropole, 1992 ...|$|R
5000|$|... #Caption: Label on <b>line</b> {{conductor}} <b>sample</b> (original rating ±250 kV) ...|$|R
40|$|In this paper, {{available}} {{standard procedures}} {{for the evaluation of}} failure probabilities are compared and critically discussed in view of their applications in high dimensions, multiple failure domains and implicit performance function (FE-analyses). Approximate FORM/SORM and Importance Sampling are compared with <b>Line</b> <b>Sampling.</b> It is shown that FORM lacks robustness in high dimensions and SORM is simply not feasible for this class of problems. Importance Sampling also looses its robustnes and accuracy in case a surrogate limit state functions, determined by the response surface method, is used. The proposed <b>Line</b> <b>Sampling</b> procedure, however, does not require any approximating surrogate limit state surface and therefore combines the property of robustnes with accuracy. Moreover, multiple failure domain can be treated quite simple and straight forward...|$|E
40|$|A fast chemical-shift imaging {{technique}} is presented. The method involves saturating all spins outside a plane, selectively exciting individual lines, phase encoding along each <b>line,</b> <b>sampling</b> the FID without gradients, and interleaving interrogation of multiple lines. A 64 X 64 array of spectra with 5 Hz resolution {{can be obtained}} in 17 min...|$|E
40|$|In this dissertation, Random Sets and Advanced Sampling {{techniques}} are combined for general and efficient uncertainty quantification. Random Sets extend the traditional probabilistic framework, as they also comprise imprecision {{to account for}} scarce data, lack of knowledge, vagueness, subjectivity, etc. The general attitude of Random Sets to include different kinds of uncertainty is paid to a very high computational price. In fact, Random Sets requires a min-max convolution for each sample picked by the Monte Carlo method. The speed of the min-max convolution can be sensibly increased when the system response relationship is known in analytical form. However, in a general multidisciplinary design context, the system response is very often treated as a “black box”; thus, the convolution requires the adoption of evolutionary or stochastic algorithms, which need to be deployed for each Monte Carlo sample. Therefore, the availability of very efficient sampling techniques is paramount to allow Random Sets {{to be applied to}} engineering problems. In this dissertation, Advanced <b>Line</b> <b>Sampling</b> methods have been generalised and extended to include Random Sets. Advanced Sampling techniques make the estimation of quantiles on relevant probabilities extremely efficient, by requiring significantly fewer numbers of samples compared to standard Monte Carlo methods. In particular, the <b>Line</b> <b>Sampling</b> method has been enhanced to link well to the Random Set representation. These developments comprise line search, line selection, direction adaptation, and data buffering. The enhanced efficiency of <b>Line</b> <b>Sampling</b> is demonstrated by means of numerical and large scale finite element examples. With the enhanced algorithm, the connection between <b>Line</b> <b>Sampling</b> and the generalised uncertainty model has been possible, both in a Double Loop and in a Random Set approach. The presented computational strategies have been implemented in the open source general purpose software for uncertainty quantification, OpenCossan. The general reach of the proposed strategy is demonstrated by means of applications to structural reliability of a finite element model, to preventive maintenance, and to the NASA Langley multidisciplinary uncertainty quantification challenge...|$|E
3000|$|As {{a result}} of the taken as the {{standard}} deviation of {{the difference between the two}} areas of 1799  m 2 (the biggest standard error between differences the total affected areas and the permanent easement areas of each <b>lines),</b> <b>sample</b> size was calculated using the formula given below (Sümbüloğlu and Sümbüloğlu 2005): [...]...|$|R
40|$|Paper session 8 : Lines, {{strokes and}} textures in 3 DInternational audienceThis paper {{presents}} {{a method for}} creating coherently animated line drawings that include strong abstraction and stylization effects. These effects are achieved with active strokes: 2 D contours that approximate and track the lines of an animated 3 D scene. Active strokes perform two functions: they connect and smooth unorganized <b>line</b> <b>samples,</b> and they carry coherent parameterization to support stylized rendering. <b>Line</b> <b>samples</b> are approximated and tracked using active contours ("snakes") that automatically update their arrangment and topology to match the animation. Parameterization is maintained by brush paths that follow the snakes but are independent, permitting substantial shape abstraction without compromising fidelity in tracking. This approach renders complex models {{in a wide range}} of styles at interactive rates, making it suitable for applications like games and interactive illustrations...|$|R
40|$|Sample 112 KWBMF {{was taken}} from the K West Sandfilter Backwash Pit on June 1, 1999, and {{received}} by 222 -S Laboratory on June 2, 1999. Analyses were performed on sample 112 KWBMF in accordance with Letter of Instruction for K Basins Sandfilter Backwash <b>Line</b> <b>Samples</b> (LOI) in support of the K Basin Sandfilter Backwash Line Characterization Project...|$|R
30|$|The gold-standard {{method for}} {{determining}} input functions is direct arterial <b>line</b> <b>sampling.</b> However, {{we have used}} image-derived input functions (IDIFs) calculated from mean tracer activity concentrations within volumes drawn in the descending aorta, both for patient comfort and safety, and because good agreement has been demonstrated between directly sampled input functions and IDIFs obtained from the descending aorta [11].|$|E
40|$|Opacities of {{molecules}} in exoplanet atmospheres rely on increasingly detailed line-lists for these molecules. The line lists available today contain for many species {{up to several}} billions of lines. Computation of the spectral line profile created by pressure and temperature broadening, the Voigt profile, {{of all of these}} lines is becoming a computational challenge. We aim to create a method to compute the Voigt profile in a way that automatically focusses the computation time into the strongest lines, while still maintaining the continuum contribution of the high number of weaker lines. Here, we outline a statistical <b>line</b> <b>sampling</b> technique that samples the Voigt profile quickly and with high accuracy. The number of samples is adjusted to the strength of the line and the local spectral line density. This automatically provides high accuracy line shapes for strong lines or lines that are spectrally isolated. The <b>line</b> <b>sampling</b> technique automatically preserves the integrated line opacity for all lines, thereby also providing the continuum opacity created by the large number of weak lines at very low computational cost. The <b>line</b> <b>sampling</b> technique is tested for accuracy when computing line spectra and correlated-k tables. Extremely fast computations (~ 3. 5 e 5 lines per second per core on a standard current day desktop computer) with high accuracy (< 1 % almost everywhere) are obtained. A detailed recipe on how to perform the computations is given. Comment: Accepted for publication in A&...|$|E
40|$|Abstract—In this paper, {{we propose}} a {{real-time}} multicamera people localization method based on <b>line</b> <b>sampling</b> of image foregrounds. For each view, these line samples are originated from the vanishing point of lines {{perpendicular to the}} ground plane. With these line samples, vertical line samples in the 3 -D scene can be reconstructed for potential human locations. After some efficient geometric refinement and filtering procedures, the remaining qualified 3 -D line samples are clustered and integrated for the identification of locations and heights {{of people in the}} scene. Both indoor and outdoor scenarios are examined to demonstrate the effectiveness of our approach in handling serious occlusion in crowed scenes. The average localization error of less than 15 cm for average viewing distance of 15 m suggests that our method can be applied to a broad range of surveillance applications that require the real-time computation of localization without using special hardware for acceleration. Index Terms— 2 -D/ 3 -D <b>line</b> <b>sampling,</b> multicamera, people localization, real time, vanishing point. I...|$|E
50|$|A line gauge {{is a type}} of ruler used in the {{printing}} industry. These may be made from a variety of materials, typically metal or clear plastic. Units of measurement on a basic line gauge usually include inches, agate, picas, and points. More detailed line gauges may contain <b>sample</b> widths of <b>lines,</b> <b>samples</b> of common type in several point sizes, etc.|$|R
40|$|Figure 1 - Map of {{northern}} Luzon Island, Philippines, with the Sierra Madre and Cordillera mountain ranges indicated (contour shading depicts elevational increments; see key, lower right). Provincial boundaries are indicated with dashed <b>lines.</b> <b>Sampling</b> localities marked with numbered circles, corresponding to localities listed in Table 1. The inset (bottom left) shows {{the location of}} Luzon Island (darkly shaded) within the Philippines...|$|R
50|$|Nobel {{became part}} of Black Corners collective, a {{collection}} of artists who chose a “progressive approach to music”, avoiding the boundaries of a single genre. Together, Nobel and Doc experimented with various genres including rock, hip-hop, and electronica. In the process, Nobel developed a distinct sound, incorporating atmospheric guitars, hip-hop beats, heavy bass <b>lines,</b> <b>samples,</b> string arrangements and innovative programming.|$|R
