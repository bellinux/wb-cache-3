5|1661|Public
40|$|The {{temporal}} {{properties of}} human visual motion detection were explored. Experiment 1 measured thresholds for speed discrimination {{as a function}} of stimulus duration. Thresholds fell asymptotically to a Weber fraction around 0. 06 over a period of approx. 100 msec, with faster speeds asymptoting at slightly shorter stimulus durations. A second experiment required subjects to discriminate a pattern that was modulated between two speeds from one which remained at a constant speed. The minimum depth of the modulation required to make this judgement was found to be equivalent to a Weber fraction of 0. 3 at <b>low</b> <b>modulation</b> <b>rates,</b> around five times greater than when the velocities were presented in isolation (expt 1). At some higher modulation rate performance dramatically declined. The modulation rate at which this occurred decreased with stimulus speed, and increased with stimulus size. The results of expt 1 seem consistent with the known properties of primary motion sensors, while the results of the latter experiments may arise from a later stage integrating the output of these primary motion sensors...|$|E
40|$|For normal-hearing listeners, masked speech {{recognition}} can improve {{with the introduction}} of masker amplitude modulation. The present experiments tested the hypothesis that this masking release {{is due in part to}} an interaction between the temporal distribution of cues necessary to perform the task and the probability of those cues temporally coinciding with masker modulation minima. Stimuli were monosyllabic words masked by speech-shaped noise, and masker modulation was introduced via multiplication with a raised sinusoid of 2. 5 – 40 Hz. Tasks included detection, three-alternative forced-choice identification, and open-set identification. Overall, there was more masking release associated with the closed than the open-set tasks. The best rate of modulation also differed as a function of task; whereas <b>low</b> <b>modulation</b> <b>rates</b> were associated with best performance for the detection and three-alternative identification tasks, performance improved with modulation rate in the open-set task. This task-by-rate interaction was also observed when amplitude-modulated speech was presented in a steady masker, and for low- and high-pass filtered speech presented in modulated noise. These results were interpreted as showing that the optimal rate of amplitude modulation depends on the temporal distribution of speech cues and the information required to perform a particular task...|$|E
40|$|Frequency {{modulation}} (FM) detection {{was investigated}} in acoustic and electric hearing to characterize cochlear-implant subjects' ability to detect dynamic frequency changes and to assess the relative contributions of temporal and spectral cues to frequency processing. Difference limens were measured for frequency upward sweeps, downward sweeps, and sinusoidal FM {{as a function of}} standard frequency and modulation rate. In electric hearing, factors including electrode position and stimulation level were also studied. Electric hearing data showed that the difference limen increased monotonically as a function of standard frequency regardless of the modulation type, the modulation rate. the electrode position, and the stimulation level. In contrast, acoustic hearing data showed that the difference limen was nearly a constant as a function of standard frequency. This difference was interpreted to mean that temporal cues are used only at low standard frequencies and at <b>low</b> <b>modulation</b> <b>rates.</b> At higher standard frequencies and modulation rates, the reliance on the place cue is increased, accounting for the better performance in acoustic hearing than for electric hearing with single-electrode stimulation. The present data suggest a speech processing strategy that encodes slow frequency changes using lower stimulation rates than those typically employed by contemporary cochlear-implant speech processors. (C) 2004 Acoustical Society of America...|$|E
30|$|So far, the HM-based {{adaptive}} relaying scheme did {{send the}} additional {{information to the}} RS using a <b>low</b> <b>modulation</b> <b>rate</b> (4 -QAM in our example above). The BS-RS link is, however, typically of good radio conditions, which allows {{the use of a}} higher <b>modulation</b> <b>rate,</b> for instance 16 -QAM, to transmit the second level of hierarchy in the HM operation.|$|R
40|$|Studies {{have shown}} that {{acoustic}} experiences significantly contribute to the functional shaping of the structural organization and signal processing capacities of the mammalian auditory system during postnatal development. Here, we show how an early epoch of exposure to structured noise influences temporal processing in the rat primary auditory cortex documented immediately after exposure and again in adulthood. Pups were continuously exposed to broadband-pulsed noise across the critical period for auditory system development. Immediately after cessation of exposure at postnatal day ≈ 35 (P 35) or ≈ 55 days later (i. e., P 90) in other rats, the temporal modulation-transfer functions of cortical neurons were documented. We found that pulsed noise exposure at a <b>low</b> <b>modulation</b> <b>rate</b> significantly decreased cortical responses to repetitive stimuli presented {{across a range of}} higher <b>modulation</b> <b>rates.</b> The highest temporal rate at which temporal modulation-transfer function was at half of its maximum was reduced when compared with naïve rats. Low-rate pulsed noise exposure also decreased cortical response synchronization at higher stimulus rates, as shown by vector strength and Rayleigh statistic measures. These postexposure changes endured into adulthood. These findings bear significant implications for the role of early sound experiences as contributors to the ontogeny of human auditory and language-related abilities and impairments...|$|R
25|$|One key {{principle}} of OFDM {{is that since}} <b>low</b> symbol <b>rate</b> <b>modulation</b> schemes (i.e., where the symbols are relatively long compared to the channel time characteristics) suffer less from intersymbol interference caused by multipath propagation, it is advantageous to transmit a number of low-rate streams in parallel instead of a single high-rate stream. Since the duration of each symbol is long, it is feasible to insert a guard interval between the OFDM symbols, thus eliminating the intersymbol interference.|$|R
40|$|The {{period of}} complex signals is encoded in the bullfrog’s eighth nerve by a {{synchrony}} code based on phase-locked responding. We examined how these arrays of phase-locked activity {{are represented in}} different subnuclei of the auditory midbrain, the torus semicircularis (TS). Recording sites in {{different areas of the}} TS differ in their ability to synchronize to the envelope of complex stimuli, and these differences in synchronous activity are related to response latency. Cells in the caudal principal nucleus (cell sparse zone) have longer latencies, and show little or no phase-locked activity, even in response to <b>low</b> <b>modulation</b> <b>rates,</b> while some cells in lateral areas of the TS (magnocellular nucleus, lateral part of principal nucleus) synchronize to rates as high as 90 – 100 Hz. At midlevels of the TS, there is a lateral-to-medial gradient of synchronization ability: cells located more laterally show better phase-locking than those located more medially. Pooled all-order interval histograms from short latency cells located in the lateral TS represent the waveform periodicity of a biologically relevant complex harmonic signal at different stimulus levels, and {{in a manner consistent with}} behavioral data from vocalizing male frogs. Long latency cells in the caudal parts of the TS (cell sparse zone, caudal magnocellular nucleus) code stimulus period by changes in spike rate, rather than by changes in synchronized activity. These data suggest that neural codes based on rate processing and time domain processing are represented in anatomically different areas of the TS. They further show that a population-based analysis can increase the precision with which temporal features are represented in the central auditory system...|$|E
40|$|This thesis {{presents}} {{two approaches}} investigating how the human auditory system processes the brief frequency {{changes that occur}} in speech sounds. Section 1 of the thesis consists of a critical {{review of the literature}} on human auditory event-related potentials (ERPs) and speech perception. Section 2 consists of three experiments evaluating ERPs to non-speech frequency changes. The experiments evaluated steady state and transient auditory evoked potentials (EPs) to tones that were sinusoidally modulated in frequency and to tones that alternated between two frequencies with a linear ramp. The tones were presented at modulation rates typical of average syllable production. The steady state responses to sinusoidal FM were small and difficult to record at both the first and second harmonics. Ramp FM evoked larger and more consistent second harmonic steady state responses than the sinusoidal FM. Only the ramp FM stimuli elicited transient EPs and these only at <b>low</b> <b>modulation</b> <b>rates.</b> These responses were larger to upward ramps than to downward ramps. The response to two simultaneously presented ramp FM tones differed from the sum of responses to the individual tones indicating some interaction in the processing of the two stimuli. Since the first study found that steady state responses were not as reliable as ERPs to discrete frequency changes, the second study used speech sounds containing discrete frequency changes. In Section 3 of the thesis computer-modified speech sounds from the /ba/ to /da/ continuum were presented to reading subjects as a train of standard speech sounds interspersed with two types of infrequent deviant speech sounds. One deviant stimulus lay within the same category as the standard and the other lay across the categorical boundary from the standard, but both were acoustically equidistant from the standard in terms of the second formant transition. When the standard stimulus was drawn from the /ba/ end of the continuum, the across-category deviants elicited a clear mismatch negativity (MMN) in the auditory event-related potential whereas the within-category deviants did not. This MMN began at about 60 - 120 ms after stimulus onset and was present for several hundred ms. These results suggest that categorical processing of speech sounds occurs independently of attention at an early echoic memory stage. When the standard stimulus was drawn from the /da/ end of the continuum, the MMN to across-category deviants was not larger than the MMN to within-category deviants. Grand mean waveforms suggested that both deviant stimuli elicited small MMNs. Although this may indicate processing along an acoustic continuum, the results of the psychophysical tests suggest that the standard stimulus in this condition was too close to the category boundary for the deviants to evoke a consistent categorical mismatch...|$|E
30|$|The {{demand for}} high data {{transmission}} rates {{has been on}} the rise in recent years with organizations and individuals requiring ultra high-speed data transmission scheme. Broadband wireless transmission is employed in delivering this high speed data requirement to subscribers in a very hostile radio environment which offers multipath to transmitted signal. The multipath could be severe requiring sophisticated corrective measures at the receiver. Orthogonal frequency multiple access scheme (OFDMA) is a popular technique which uses a <b>low</b> symbol <b>rate</b> <b>modulation</b> specially designed to cope with severe channel conditions in multipath environment [1]. However, it has high peak to average power ratio (PAPR) which imposes high-power penalty on the mobile users [2].|$|R
40|$|Abstract — Magnetoencephalography (MEG) is a brain imaging {{technique}} that non-invasively measures neurallygenerated magnetic fields. Earlier MEG {{studies have focused}} on the neural responses to amplitude modulated (AM) auditory signals near 40 Hz. Speech signals, however, contain a wide range of <b>modulation</b> <b>rates,</b> most of which are well below 40 Hz. Therefore we seek to characterize the modulation transfer function (MTF) of the human brain at AM frequencies much lower than 40 Hz. The present study uses MEG to measure neural responses to pure-tone carrier signals amplitude modulated at frequencies exponentially fluctuating between 3 Hz and 60 Hz. Analysis of the neural MEG data includes noise reduction, timefrequency analysis to characterize the MTF, and a comparison to the neural response to constant AM stimuli. The maximal neural response was evident at <b>low</b> <b>rate</b> <b>modulations,</b> with the shape of the MTF following that of a shallow low-pass filter. The phase of the neural response was linear, consistent with an 80 ms delay. Neural phase responses to upward and downward sweeps differed by ~ � radians for AM frequencies 15 - 35 Hz. An exponential AM chirp gave a successful estimate of the neural power MTF, closely matching that of the response to constant AM stimuli. Index Terms—auditory, modulation, magnetoencephalograph...|$|R
40|$|The {{detection}} of specific temporal patterns in communication signals {{may be of}} vital importance for certain organisms. In crickets, for instance, a female will move towards a singing male only if she can recognize the appropriate pulse rate characteristic to its own species' song. Additionally, in order to evade predatory insectivorous bats, flying crickets {{must be able to}} track the predator's ultrasonic echolocation signals, which are emitted at a variety of pulse rates. In this thesis, the temporal processing, or the integration of stimulus through time, in the peripheral 1 auditory system of the cricket will be investigated. The ON 1 interneuron temporal processing was first examined and compared at high (bat-like) and low carrier (cricket-like) frequencies in three different experimental paradigms. First, integration time, which corresponds to the time it takes for a neuron to reach threshold when stimulated at the minimum effective intensity, was found to be significantly shorter at high carrier frequency than at low carrier frequency. Second, phase locking to sinusoidally amplitude modulated (SAM) signals was more efficient at high frequency, especially at high <b>modulation</b> <b>rates</b> and <b>low</b> <b>modulation</b> depths. Finally, we examined the efficiency with which ON 1 detects gaps in a constant tone. As reflected by the decrease in firing rate {{in the vicinity of the}} gap, ON 1 is better at detecting gaps at low carrier frequency. Following a gap, firing rate increases beyond the pre-gap level. This "rebound" phenomenon is similar for low and high carrier frequencies. To determine the source of this differential temporal processing, the sensory afferents making synapses with ON 1 were investigated. Low frequency (MT-type) and ultrasound auditory receptors were compared on the basis of latency, maximum firing rate, adaptation, information transmission, bursting and feature detection. Ultrasound receptors (HFs) were found to have a shorter latency, a higher maximum firing rate and stronger adaptation than low-frequency receptors (LFs). Individual HFs transmitted more linear (lower-bound) information than LFs. However, HFs' responses were more correlated than LFs' (i. e. they had larger mutual information), so that when superposing the spike trains of LFs, information transmission in the <b>lowest</b> amplitude <b>modulation</b> <b>rates</b> was greatly improved, and, in some cases, reached the level of HFs. Feature detection by spike in HFs was better than in LFs. Feature detection by bursts was better than for spikes, but equivalent in both types of receptors. The level of bursting in HFs, however, was much higher than in LFs, making them better feature detectors in general. 1 Because it lies in the prothoracic ganglion, ON 1 is technically part of the central nervous system. For the purpose of this thesis, however, because ON 1 receives direct input from the receptors, it will be considered to be part of the peripheral auditory systems...|$|R
30|$|Al, Am, Ah {{are defined}} as the carrier amplitudes in the <b>low</b> <b>{{modulation}},</b> middle modulation, and high modulation index regions, respectively. pl, pm, ph {{are defined as}} the carrier overlapping ratio in the <b>low</b> <b>modulation,</b> middle modulation, and high modulation index regions, respectively.|$|R
50|$|In {{synchronous}} binary signaling, the DSR in bits {{per second}} may be numerically {{the same as the}} <b>modulation</b> <b>rate</b> expressed in bauds. Signal processors, such as four-phase modems, cannot change the DSR, but the <b>modulation</b> <b>rate</b> depends on the line modulation scheme, in accordance with Note 4. For example, in a 2400 bit/s 4-phase sending modem, the signaling rate is 2400 bit/s on the serial input side, but the <b>modulation</b> <b>rate</b> is only 1200 bauds on the 4-phase output side.|$|R
40|$|This study {{examines}} the amplitude <b>modulation</b> <b>rate</b> discrimination for sinusoidal and noise carriers. It was {{shown that the}} discrimination of AM rates is a monotonically growing function of <b>modulation</b> <b>rate.</b> Higher values of the discrimination thresholds were observed for a narrowband carrier. It appears {{that in the case}} of a narrowband noise carrier, the spectral range of the noise envelope is similar to that of the <b>modulation</b> <b>rates</b> of the signal (up to 120 Hz). It results in a masking in the <b>modulation</b> <b>rate</b> domain and in a much higher threshold growth than that observed for a wideband noise carrier or a sinusoidal carrier. The results are consistent with the idea of the so-called second stage of filtering acting on the envelope of the acoustic signal. This hypothesis postulates the existence of a so-called modulation filter bank, (MFB), responsible for the frequency selectivity observed in the amplitude <b>modulation</b> <b>rate</b> domain. The existence of the MFB suggests that a certain form of the spectral analysis of any acoustic signal envelope may be performed in the auditory system after initial filtering in the auditory filter bank. A model of the <b>modulation</b> <b>rate</b> discrimination based either on the classical concept of the excitation patterns or on the modulation excitation patterns has not accounted for our experimental data. According to both the models, an increase in the frequency discrimination threshold versus <b>modulation</b> <b>rate</b> should be slower than that measured in the experiment. 1...|$|R
40|$|Sensitivity to {{interaural}} time differences (ITDs) conveyed in the temporal fine structure of low-frequency tones and the modulated envelopes of high-frequency sounds are considered comparable, particularly for envelopes shaped to transmit similar fidelity of temporal information normally present for low-frequency sounds. Nevertheless, discrimination performance for envelope <b>modulation</b> <b>rates</b> above {{a few hundred}} Hertz {{is reported to be}} poor—to the point of discrimination thresholds being unattainable—compared with the much higher (> 1, 000 ?Hz) limit for low-frequency ITD sensitivity, suggesting the presence of a low-pass filter in the envelope domain. Further, performance for identical <b>modulation</b> <b>rates</b> appears to decline with increasing carrier frequency, supporting the view that the low-pass characteristics observed for envelope ITD processing is carrier-frequency dependent. Here, we assessed listeners’ sensitivity to ITDs conveyed in pure tones and in the modulated envelopes of high-frequency tones. ITD discrimination for the modulated high-frequency tones was measured as a function of both <b>modulation</b> <b>rate</b> and carrier frequency. Some well-trained listeners appear able to discriminate ITDs extremely well, even at <b>modulation</b> <b>rates</b> well beyond 500 ?Hz, for 4 -kHz carriers. For one listener, thresholds were even obtained for a <b>modulation</b> <b>rate</b> of 800 ?Hz. The highest <b>modulation</b> <b>rate</b> for which thresholds could be obtained declined with increasing carrier frequency for all listeners. At 10 ?kHz, the highest <b>modulation</b> <b>rate</b> at which thresholds could be obtained was 600 ?Hz. The upper limit of sensitivity to ITDs conveyed in the envelope of high-frequency modulated sounds appears to be higher than previously considered...|$|R
50|$|Transmitting {{a signal}} at high <b>modulation</b> <b>rate</b> through a band-limited channel can create intersymbol interference. As the <b>modulation</b> <b>rate</b> increases, the signal's {{bandwidth}} increases. When the signal's bandwidth becomes {{larger than the}} channel bandwidth, the channel starts to introduce distortion to the signal. This distortion usually manifests itself as intersymbol interference.|$|R
5000|$|... #Subtitle level 3: Inherent Maximum <b>Modulation</b> <b>Rate</b> vs. Aperture Size ...|$|R
30|$|The {{modulation}} index regions {{can be obtained}} according to (13)-(15): <b>low</b> <b>modulation</b> index region, 0 [*]<[*]M[*]<[*] 0.4; middle {{modulation index}} region, 0.4 [*]≤[*]M[*]≤[*] 0.7; high modulation index region, 0.7 [*]<[*]M[*]≤[*] 1.15. The carrier amplitudes for CDOSFOPWM are A[*]=[*]Al[*]=[*] 1.99 UC in the <b>low</b> <b>modulation</b> index region, A[*]=[*]Am[*]=[*] 1.6 UC in the middle modulation index region, and A[*]=[*]Ah[*]=[*]UC in the high modulation index region. The modulation indexes are chosen as M[*]=[*] 1.1 in the high modulation index region, M[*]=[*] 0.55 in the middle modulation index region, and M[*]=[*] 0.35 in the <b>low</b> <b>modulation</b> index region. The average switching frequency of each SM for the CDOSFOPWM method and PSCPWM method is 900  Hz.|$|R
30|$|Modular {{multilevel}} converters (MMCs) {{operate in}} the <b>low</b> <b>modulation</b> index region in many applications. However, when utilized at the <b>low</b> <b>modulation</b> index region, large harmonics appear in the output voltage, which degrade {{the performance of the}} MMC. To improve the harmonic characteristic in the <b>low</b> <b>modulation</b> index, the carrier dynamic overlapping switching frequency optimal pulse width modulation (CDOSFOPWM) method is proposed for the MMC here. The whole modulation index region is divided into three regions: high modulation index region, middle modulation index region, and <b>low</b> <b>modulation</b> index region. The carrier amplitude, carrier overlap ratio, and frequency of triangular carriers are chosen dynamically according to the modulation index region of the modulation signals, to achieve the optimal harmonic characteristic in the whole modulation index region and maintain the switching loss. The number of on-state submodules (SMs) can be calculated by CDOSFOPWM, and the selection of SMs is performed by a reducing switching frequency voltage balancing algorithm. Finally, the proposed method is verified by simulation and experimental results.|$|R
30|$|According to (13)-(15), the {{modulation}} {{region in}} each arm {{can be calculated}} as follows: <b>low</b> <b>modulation</b> index region, 0 [*]<[*]M[*]<[*] 0.7; middle modulation index region, 0.7 [*]≤[*]M[*]≤[*] 0.9; high modulation index region, 0.9 [*]<[*]M[*]≤[*] 1.15. The carrier amplitudes for CDOSFOPWM are A[*]=[*]Al[*]=[*] 2.4 UC in the <b>low</b> <b>modulation</b> region, A[*]=[*]Am[*]=[*] 1.77 UC in the middle modulation region, and A[*]=[*]Ah[*]=[*]UC in the high modulation region.|$|R
30|$|As {{shown in}} Fig.  2, the average {{intersecting}} number within each carrier period, between the modulation signal and N triangular carriers in each arm at the high, middle, and <b>low</b> <b>modulation</b> index regions are 2, 4, and 6, respectively. This {{means that the}} number of on-state SMs are changed 2, 4, and 6 times, respectively. When the carrier frequency in the high modulation index region is three times the carrier frequency in the <b>low</b> <b>modulation</b> index region, and the carrier frequency in middle modulation index region is 1.5 times the carrier frequency in the <b>low</b> <b>modulation</b> index region, the average switching frequency and power loss in the three modulation index regions are the same.|$|R
40|$|Natural and behaviorally {{relevant}} {{sounds are}} characterized by temporal modulations of their waveforms, which carry important cues for sound segmentation and communication. Still, there is little consensus as to how this temporal information is represented in auditory cortex. Here, by using {{functional magnetic resonance imaging}} (fMRI) optimized for studying the auditory system, we report the existence of a topographically ordered spatial representation of temporal sound <b>modulation</b> <b>rates</b> in human auditory cortex. We found a topographically organized sensitivity within auditory cortex to sounds with varying <b>modulation</b> <b>rates,</b> with enhanced responses to lower <b>modulation</b> <b>rates</b> (2 and 4  Hz) on lateral parts of Heschl's gyrus (HG) and faster <b>modulation</b> <b>rates</b> (16 and 32  Hz) on medial HG. The representation of temporal <b>modulation</b> <b>rates</b> was distinct from the representation of sound frequencies (tonotopy) that was orientated roughly orthogonal. Moreover, the combination of probabilistic anatomical maps with a previously proposed functional delineation of auditory fields revealed that the distinct maps of temporal and spectral sound features both prevail within two presumed primary auditory fields hA 1 and hR. Our results reveal a topographically ordered representation of temporal sound cues in human primary auditory cortex that is complementary to maps of spectral cues. They thereby enhance our understanding of the functional parcellation and organization of auditory cortical processing...|$|R
50|$|The {{information}} transfer rate {{may or may not}} be equal to the transmission <b>modulation</b> <b>rate.</b>|$|R
30|$|Hitherto, {{few have}} {{analyzed}} the multilevel modulation methods for MMCs in the <b>low</b> <b>modulation</b> index region. However, the MMC will {{operate in the}} <b>low</b> <b>modulation</b> index region in many medium/high-voltage applications. The MMC {{can be used to}} connect a low-voltage AC source to a high-voltage DC source with a <b>low</b> <b>modulation</b> index, such as DC/AC distribution systems and DC collection of renewable energy [35]. When MMC-based variable-speed motor drives adopt the variable-speed variable-velocity variable-frequency (VVVF) technology, the output voltage of the MMC is proportional to the output frequency. As many medium/high voltage variable speed motor drives typically operate at just a fraction of their rated load [36], the MMC-based motor drive system will often operate in low frequency and <b>low</b> <b>modulation</b> index. The static synchronous compensator (STATCOM) and active power filter (APF) based on MMC may also operate for long durations well below their rated capabilities, such as at night when production has stopped at a commercial or industrial facility [36]. When MMCs are used in a unified power flow controller (UPFC), the output voltage of the series MMC in the MMC-UPFC can be regulated from 0 to the rated value, implying that the modulation index of the output voltage can be regulated from 0 to 1 [37]. Thus, the series MMC in the MMC-UPFC will operate at a <b>low</b> <b>modulation</b> index region in some cases. However, hitherto, few have analyzed the <b>low</b> <b>modulation</b> index operation for the MMC. In [35], a bifurcate MMC for low-modulation-ratio applications was proposed. Each arm had three branches, and the branch current was lower than the arm current of the conventional MMC. In [37], a harmonic influence analysis of MMC-UPFC based on the NLM was presented, which analyzed the influence of the series MMC in the UPFC on the power grid with different modulation indexes. In [38], a control method of low output frequency operation for the MMC was presented. However, when the MMC operates in the <b>low</b> <b>modulation</b> index region, large harmonics appear in the output voltage, which degrade the MMC performance.|$|R
3000|$|The {{range of}} the high {{modulation}} region, middle <b>modulation</b> region, and <b>low</b> <b>modulation</b> region {{can be defined as}} follows: [...]...|$|R
40|$|We have {{recently}} demonstrated an ultrafast photonic crystal laser and cavity coupled laser array with <b>modulation</b> <b>rates</b> of 1 THz at room temperature, a 20 GHz optical modulator with activation energies of 60 fJ and a quantum dot photonic crystal laser with large signal <b>modulation</b> <b>rates</b> of 30 GHz. These devices are enabled by the enhanced light-matter interaction in photonic crystals, {{and serve as}} {{the building blocks of}} on-optical information processing circuits...|$|R
30|$|The {{proposed}} method can {{be applied}} for normal frequency stabilizing LDs, which use a commercial EOM and a <b>low</b> <b>modulation</b> index with FMS.|$|R
30|$|Based on {{the various}} MCSs that were selected, the {{transmission}} rate and packet error rate also varied. Specifically, when a high data rate MCS (such as 64 QAM) is selected by BS for transmitting packets to SS, fewer time slots are consumed when transmitting, but higher packet loss rate could be encountered. On the other hand, if a <b>low</b> data <b>rate</b> <b>modulation</b> (such as BPSK) is selected by BS for transmitting information to SS, then more time slots are consumed, but the packet loss rate would decline. Gopala and Gamal[20] therefore introduced the concept of opportunistic transmission: if the AL-FEC was used to help reduce the packet loss rate, then the BS could employ a better modulation to transmit the packet. As a consequence, for a system with M MCSs and F AL-FECs, the BS was offered M*F possible combinations of MCS and AL-FEC to choose from when transmitting packets to an SS. The objective of opportunistic transmission was to select the best combination which could minimize the consuming of time slots while satisfying the packet loss rate guarantee. In this section, we proposed a simple algorithm to achieve this goal.|$|R
50|$|Digital {{data modem}} {{manufacturers}} commonly define the baud as the <b>modulation</b> <b>rate</b> of data transmission and express it as bits per second.|$|R
40|$|Modulation of a rain {{wave pattern}} by longer waves has been studied. An {{analytical}} model {{taking into account}} capillarity effects and obliquity of short waves has been developed. <b>Modulation</b> <b>rates</b> in wave number and amplitude have been computed. Experiments were carried out in a wave tank. First results agree with theoretical models, but higher values of <b>modulation</b> <b>rates</b> are measured. These results could {{be taken into account}} for understanding the radar response from the sea surface during rain...|$|R
40|$|Abstract—Recent {{work has}} {{examined}} techniques {{to estimate the}} “best ” <b>modulation</b> <b>rate</b> for data networks such as 802. 11 a/g. While accurate rate estimation yields better rate-selection decisions and increased throughput, those methods must still choose between a handful of <b>modulation</b> <b>rates.</b> Each <b>modulation</b> <b>rate</b> is effective {{in a range of}} actual signal-to-noise ratios (SNRs) but the limited number of practical rates means that transmitters are often forced to “step down ” to a lower data rate despite having a higher SNR than the minimum required for that lower rate. In this paper we describe, evaluate and implement a practical multiuser communication scheme that exploits these discrete “steps” in <b>modulation</b> <b>rates</b> to transmit two packets in the time normally needed to transmit a single packet, increasing aggregate throughput precisely when it is most needed- when the network is busy and suffers from rate unfairness. Because the method transmits a group of packets simultaneously, we call this scheme Group Rate Transmission with Intertwined Symbols, or GRaTIS. In addition to up to 120 % improvement in network throughput achieved by GRaTIS, the technique is backward compatible with 802. 11 and doesn’t require complex DSP algorithms as required by competing methods...|$|R
30|$|Roughness: feature modeled by the {{amplitude}} <b>modulation</b> <b>rate</b> of {{the temporal}} envelope (expressed in asper) and related to the sensation of auditory roughness.|$|R
50|$|In bit-synchronous operation, {{clock timing}} is usually {{delivered}} {{at twice the}} <b>modulation</b> <b>rate,</b> and one bit is transmitted or received during each clock cycle.|$|R
40|$|Recent {{research}} suggests that multisensory integration may occur at an early phase in sensory processing and within cortical regions traditionally though to be exclusively unisensory. Evidence from perceptual and electrophysiological studies indicate that the cross modal temporal correspondence of multisensory stimuli plays {{a fundamental role in}} the cortical integration of information across separate sensory modalities. Further, oscillatory neural activity in sensory cortices may provide the principle mechanism whereby sensory information from separate modalities is integrated. In the present study we aimed to extend this prior research by using the steady-state EEG response (SSR) to examine whether variations in the cross-modality temporal correspondence of amplitude modulated auditory and vibrotactile stimulation are apparent in SSR activity to multisensory stimulation. To achieve this we varied the cross-modal congruence of <b>modulation</b> <b>rate</b> for passively and simultaneously presented amplitude modulated auditory and vibrotactile stimuli. In order to maximise the SSR response in both modalities 21 and 40 Hz <b>modulation</b> <b>rates</b> were selected. Consistent with prior SSR studies, the present results showed clear evidence of phase-locking for EEG frequencies corresponding to the <b>modulation</b> <b>rate</b> of auditory and vibrotactile stimulation. As also found previously, the optimal <b>modulation</b> <b>rate</b> for SSR activity differed according to the modality, being greater at 40 Hz for auditory responses and greater at 21 Hz for vibrotactile responses. Despite consistent and reliable changes in SSR activity with manipulations of <b>modulation</b> <b>rate</b> within modality, the present study failed to provide strong evidence of multisensory interactions in SSR activity for temporally congruent, relative to incongruent, cross modal conditions. The results are discussed in terms of the role of attention as a possible factor in reconciling inconsistencies in SSR studies of multisensory integration...|$|R
50|$|Common {{clinical}} features of ataxic dysarthria include abnormalities in speech <b>modulation,</b> <b>rate</b> of speech, explosive or scanning speech, slurred speech, irregular stress patterns, and vocalic and consonantal misarticulations.|$|R
40|$|Detection and <b>modulation</b> <b>rate</b> {{discrimination}} {{were measured}} in cochlear-implant users for pulse-trains that were either sinusoidally amplitude modulated or were modulated with half-wave rectified sinusoids, which in acoustic hearing {{have been used}} to simulate the response to low-frequency temporal fine structure. In contrast to comparable results from acoustic hearing, <b>modulation</b> <b>rate</b> discrimination was not statistically different for the two stimulus types. The results suggest that, in contrast to binaural perception, pitch perception in cochlear-implant users does not benefit from using stimuli designed to more closely simulate the cochlear response to low-frequency pure tones...|$|R
