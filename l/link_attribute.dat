8|464|Public
5000|$|The [...] <b>link</b> <b>attribute</b> is a HTML meta element {{described}} in RFC 5988. Hreflang specifies {{the language and}} optional geographic restrictions for a document. Hreflang is interpreted by search engines {{and can be used}} by webmasters to clarify the lingual and geographical targeting of a website.|$|E
40|$|Networks are {{powerful}} tools for the presentation {{and analysis of}} interactions in multi-component systems. A commonly studied mesoscopic feature of networks is their community structure, which arises from grouping together similar nodes into one community and dissimilar nodes into separate communities. Here, the community structure of protein sequence similarity networks is determined with a new method: Attribute Clustering Dependent Communities (ACDC). Sequence similarity has hitherto typically been quantified by the alignment score or its expectation value. However, pair alignments with the same score or expectation value cannot thus be differentiated. To overcome this deficiency, the method constructs, for pair alignments, an extended alignment metric, the <b>link</b> <b>attribute</b> vector, which includes the score and other alignment characteristics. Rescaling components of the attribute vectors qualitatively identifies a systematic variation of sequence similarity within protein superfamilies. The problem of community detection is then mapped to clustering the <b>link</b> <b>attribute</b> vectors, selection of an optimal subset of links and community structure refinement based on the partition density of the network. ACDC-predicted communities {{are found to be}} in good agreement with gold standard sequence databases for which the "ground truth" community structures (or families) are known. ACDC is therefore a community detection method for sequence similarity networks based entirely on pair similarity information. A serial implementation of ACDC is available from [URL]...|$|E
40|$|In {{this study}} a new {{approach}} is proposed for partitioning and storing data cube efficiently. The new method partition the storage of the cube into multiple tables and uses a pointer table to <b>link</b> <b>attribute</b> combinations to attribute values. Experiments on synthetic and real data sets show that the required storage for the new method is about 60 % of that required for flat table cube. Also the proposed approach {{has the advantage of}} fast access to the attribute values. Also it supports fast roll up and drill down without the need of any indexes for the attribute values...|$|E
5000|$|November 14, 1980: Murder of Esperanza Arana and Joaquín Alfonso Etxeberría, {{attributed}} to BVE. Murder of junkman Joaquín Antimasbere Escoz, with no known political <b>links.</b> <b>Attributed</b> to BVE.|$|R
50|$|Many SGML {{features}} {{relate to}} markup minimization. Other features relate to concurrent (parallel) markup (CONCUR), to <b>linking</b> processing <b>attributes</b> (<b>LINK),</b> and to embedding SGML documents within SGML documents (SUBDOC).|$|R
40|$|Abstract—We {{consider}} {{a set of}} subjects that perform trans-actions through an anonymous system. Certain attributes of the subjects are known to a profiling entity, who can also probabilistically <b>link</b> <b>attributes</b> to the anonymous transactions. We model this system and explain how to measure the anonymity of the subjects under these conditions. I...|$|R
30|$|The SGDBE, {{at scale}} 1 : 1, 000, 000, and the PTRDB {{are parts of}} the European Soil Information System (Panagos 2006; van Liedekerke et al. 2004). The SGDBE {{consists}} of both a geometric dataset and a semantic dataset (set of attribute files) which <b>link</b> <b>attribute</b> values to the polygons of the geometrical dataset. The database contains a list of soil typological units (STU). Besides the higher level soil taxonomic classification units represented by a soil name, these units are described by variables (attributes) specifying the nature and properties of the soils, for example, texture, water regime, or stoniness. As the original taxonomic information of the SGDBE {{is based on the}} 1990 FAO-UNESCO Soil Revised Legend (FAO 1990), these names and associated information content are used in the current exercise.|$|E
40|$|AbstractFor {{the purpose}} of {{assembly}} quality control of CNC machine tools, this paper conducts the structure decomposition based on PFMA (Pedigree-Functions-Movement-Action) for CNC Machine Tool, and proposed the concept of “functional spectrum”. Take the movement function of CNC machine tools as a starting point, CNC machine tools were decomposed from the functional spectrum into the element action of the parts. In this process, we construct links to represent reliability quality relationships of element action assembly units, and then definite a <b>link</b> <b>attribute</b> called contribution degree, which measures the contribution of characteristics compared to links, for reliability analysis require of assembly process, and build a link network and link matrix model, finally, we use the link matrix model to the element action assembly units through the PFMA decomposition process from CNC rotary table to element action. The reliability was calculated to verify {{the applicability of the}} link model in the aspect of reliability quality characteristics structured modeling of element action assembly units...|$|E
40|$|Adaptive {{features}} of a hypermedia system using bookmark per Web page In this paper, we present a technique called bookmark per Web page by which users can build a new link structure in a hypermedia. It allows users {{to create their own}} links for Web pages. Our aim is to provide an adaptive hypermedia with additional adaptive features by considering properties which the author of the hyperspace did not provide when the hyperspace was designed. In addition, a general hypermedia that does not have adaptive features can support personalized views of hyperdocuments using this technique. We expect that the bookmark per Web page can enhance information accessibility and reduce navigation disorientation and cognitive overload. We implemented our technique by modifying AHA![De Bra et al., 2003] which is an open source adaptive hypermedia system. We developed Java servlets and included them in the adaptation engine of AHA!. We added a <b>link</b> <b>attribute</b> for each concept at the user profile and assigned URL addresses of new links for its values. ...|$|E
40|$|This {{document}} defines {{extensions of}} the RDF data model and of the SPARQL query language that capture an alternative approach to represent statement-level metadata. While this alternative approach is backwards compatible with RDF reification {{as defined by the}} RDF standard, the approach aims to address usability and data management shortcomings of RDF reification. One of the great advantages of the proposed approach is that it clarifies a means to (i) understand sparse matrices, the property graph model, hypergraphs, and other data structures with an emphasis on <b>link</b> <b>attributes,</b> (ii) map such data onto RDF, and (iii) query such data using SPARQL. Further, the proposal greatly expands both the freedom that database designers enjoy when creating physical indexing schemes and query plans for graph data annotated with <b>link</b> <b>attributes</b> and the interoperability of those database solutions. Comment: 14 page...|$|R
30|$|The intra-domain VN {{embedding}} {{problem is}} well-defined {{in the literature}} [5 – 9]. In this section, we formally define the inter-domain VN embedding problem. For simplicity, we avoid intra-domain aspects (e.g., node and <b>link</b> <b>attributes)</b> wherever we see fit. We use the notation introduced here to discuss {{the details of the}} PolyViNE protocol in section 3.|$|R
40|$|New input format: {{markdown}} 	New supported script format: Spyder cell markup 	Support new <b>link</b> <b>attributes</b> for pandoc >= 1. 16 	pypublish now embeds {{figures in}} html output 	pypublish no longer defaults to wrap = False in html output 	Improved test coverage 	More robust script reader, not sensitive to empty lines anymore 	Removed obsolete Julia support. Install via conda or PyPi...|$|R
40|$|The spatial {{variation}} of geographical phenomena is a classical problem in spatial data analysis and can {{provide insight into}} underlying processes. Traditional exploratory methods mostly depend on the planar distance assumption, but many spatial phenomena are constrained to a subset of Euclidean space. In this study, we apply a method based on a hierarchical Bayesian model to analyse the spatial {{variation of}} network-constrained phenomena represented by a <b>link</b> <b>attribute</b> in conjunction with two experiments based on a simplified hypothetical network and a complex road network in Shenzhen that includes 4212 urban facility points of interest (POIs) for leisure activities. Then, the methods named local indicators of network-constrained clusters (LINCS) are applied to explore local spatial patterns in the given network space. The proposed method is designed for phenomena that are represented by attribute values of network links and is capable of removing part of random variability resulting from small-sample estimation. The effects of spatial dependence and the base distribution are also considered in the proposed method, which could be applied {{in the fields of}} urban planning and safety research...|$|E
40|$|In social networks, one of {{the most}} {{challenging}} problems is to find the best way to establish a relationship between two nodes. Different attributes (Topological, Non-Topological) can be used to define friendship score between two nodes which indicates the strength of a relationship. Non-Topological attributes can be used to define the strength of a relationship even if two nodes are not connected. The concept of friendship score to define the strength of a relationship between two nodes transforms social network into a complete graph where each node is connected to every other node and where friendship score is used as <b>link</b> <b>attribute.</b> The information on already existing connections in social media network and graph which is formed based on friendship score can be used to find out best way of connecting two different nodes even if no path is in existence in social media network between these nodes. In this paper, we propose a novel way of estimating friendship score using non-topological attributes based on available information in social media network and algorithm to find out best way of connecting two nodes in the form of chain of reference. The chain of reference between node X 1 and Xn is a path X 1 ->X 2 ->…. ->Xn- 1 ->Xn where each link Xi->Xj is having high friendship score. The chain of reference indicates how X 1 can be connected to Xn even if no path exists between X 1 and Xn in social media network...|$|E
40|$|This paper {{deals with}} the Web Structure Mining and the {{different}} Structure Mining Algorithms like Page Rank, HITS, Trust Rank and Sel-HITS. The functioning of these algorithms are discussed. An incremental algorithm for calculation of PageRank using an interface has been formulated. This algorithm makes use of Web <b>Link</b> <b>Attributes</b> Information as key parameters and has been implemented using Visibility and Position of a Link. Th...|$|R
40|$|Search {{engines are}} playing a more and more {{important}} role in discovering information on the web now a day. Spam web pages, however, are employing various tricks to bamboozle search engines, therefore achieving undeserved ranks. In this paper an algorithm DBLCSPAMCLUST is proposed for spam detection based on content and <b>link</b> <b>attributes</b> details, which {{is an extension of}} DBSpamClust [1]. As showing through experiments such a method can filter out web spam effectively...|$|R
40|$|This paper {{introduces}} {{the notion of}} context-aware mobile hypermedia. Contextawareness means to take the users' context such as location, time, objective, community relations etc. into account when browsing, searching, annotating, and <b>linking.</b> <b>Attributes</b> constituting {{the context of the}} user may be sensed automatically and/or be provided by the user directly. When being mobile the user may achieve context-aware hypermedia support on a variety of small and medium sized computing platforms such as mobile phones, PDAs, tablet PCs and laptops...|$|R
50|$|In a pure IP network, the {{shortest}} {{path to a}} destination is chosen even when the path becomes congested. Meanwhile, in an IP network with MPLS Traffic Engineering CSPF routing, constraints such as the RSVP bandwidth of the traversed links can also be considered, such that {{the shortest}} path with available bandwidth will be chosen. MPLS Traffic Engineering relies upon the use of TE extensions to Open Shortest Path First (OSPF) or Intermediate System To Intermediate System (IS-IS) and RSVP. In addition to the constraint of RSVP bandwidth, users can also define their own constraints by specifying <b>link</b> <b>attributes</b> and special requirements for tunnels to route (or not to route) over <b>links</b> with certain <b>attributes.</b>|$|R
40|$|Recent {{advances}} {{in the field of}} data collection and related technologies have inaugurated a new era of research where existing data mining algorithms should be reconsidered from a different point of view, this of privacy preservation. Much research has been done recently on privacy preserving data mining (PPDM) based on perturbation, randomization and secure multiparty computations and more recently on anonymity including k-anonymity and l-diversity. We use the technique of k-Anonymization to de-associate sensitive attributes from the corresponding identifiers. This is done by anonymizing the <b>linking</b> <b>attributes</b> so that at least k released records match each value combination of the <b>linking</b> <b>attributes.</b> This paper proposes a k-Anonymization solution for classification. The proposed method has been implemented and evaluated using UCI repository datasets. After the k-anonymization solution is determined for the original data, classification, a data mining technique using the ID 3 algorithm, is applied on both the original table and the compressed table. The accuracy of the both is compared by determining the entropy and the information gain values. Experiments show that the quality of classification can be preserved even for highly restrictive anonymity requirements. Index Terms—k-Anonymization, privacy, masking, classification...|$|R
30|$|The aim of {{the method}} {{is to develop a}} ‘connectivity score’ of a {{particular}} port. Like LSCI, the scores of different ports (for LSCI: countries) can be compared. In addition, and more importantly, the connectivity score of a port can be monitored over time. We propose a method where the connectivity of a port is the sum of the ‘link qualities’ of all it’s connections based on the 3 <b>attributes</b> of the <b>links</b> (<b>attributes</b> two, three and four in Fig. 1).|$|R
40|$|SOMA uses {{longitudinal}} {{data collected from}} the Ophthalmology Clinic of the Royal Liverpool University Hospital. Using trend mining (an extension of association rule mining) SOMA <b>links</b> <b>attributes</b> from the data. However the large volume of information at the output makes them difficult to be explored by experts. This paper presents {{the extension of the}} SOMA framework which aims to improve the post-processing of the results from experts using a visualisation tool which parse and visualizes the results, which are stored into XML structured files...|$|R
50|$|Concordion {{specifications}} {{are written}} in Markdown, HTML or Excel and then instrumented with special <b>links,</b> <b>attributes</b> or comments respectively. When the corresponding test fixture class is run, Concordion interprets the instrumentation to execute the test. Rather than forcing product owners to specify requirements in a specially structured language, Concordion lets you write them in normal language using paragraphs, tables and proper punctuation. This makes the specifications much more natural to read and write, and helps everyone to understand and agree about what a feature is supposed to do.|$|R
40|$|Networks have {{remained}} {{a challenge for}} information visualization designers because of the complex issues of node and link layout coupled with the rich set of tasks that users present. This paper offers a five-layer hierarchy of network visualization situations with associated tasks: from simple node and link situations to more elaborate situations involving node labels, directed <b>links,</b> node <b>attributes,</b> and <b>link</b> <b>attributes.</b> Then, it offers a strategy based on tying node placement to node attributes within nonoverlapping regions. These user-defined meaningful substrates enable users to easily see which links remain within a region or cross to other regions. Link visibility is controlled by check boxes so that selected subsets of links can be displayed. To further limit display clutter, users can set sliders to control which nodes within a region have their edges visible. We illustrate our meaningful substrate approach in a modest example with legal precedents for 49 cases with 368 precedents, and show these in our implementation of NVMS 1. 0...|$|R
40|$|Abstract — Classification is a {{fundamental}} problem in data analysis. Training a classifier requires accessing a large collection of data. Releasing person-specific data, such as customer data or patient records, may {{pose a threat to}} individual’s privacy. Even after removing explicit identifying information such as Name and SSN, it is still possible to link released records back to their identities by matching some combination of non-identifying attributes such as {Sex, Zip, Birthdate}. A useful approach to combat such linking attacks, called k-anonymization [1], is anonymizing the <b>linking</b> <b>attributes</b> so that at least k released records match each value combination of the <b>linking</b> <b>attributes.</b> Previous work attempted to find an optimal k-anonymization that minimizes some data distortion metric. We argue that minimizing the distortion to the training data is not relevant to the classification goal that requires extracting the structure of predication on the “future ” data. In this paper, we propose a k-anonymization solution for classification. Our goal is to find a k-anonymization, not necessarily optimal in the sense of minimizing data distortion, that preserves the classification structure. We conducted intensive experiments to evaluate the impact of anonymization on the classification on future data. Experiments on real life data show that the quality of classification can be preserved even for highly restrictive anonymity requirements. Index Terms — Privacy protection, anonymity, security, integrity, data mining, classification, data sharin...|$|R
40|$|Abstract: This study {{examines}} {{the influences of}} university organizational structure on technology transfer performance. The analysis treats the organizational structure of the technology-transfer office as an independent variable that accounts, in part, for measured differences in inter-institutional patenting, licensing, and sponsored research activities. We derive and investigate hypotheses that <b>link</b> <b>attributes</b> of organizational form – information processing capacity, coordination capability and incentive alignment – to technology transfer outcomes. A detailed analysis of survey data from American major research universities provides evidence {{of the existence of}} alternative organizational structures. The data also suggest that these organizational capabilities result in differences in technology transfer activity...|$|R
40|$|This paper {{adopts a}} resource-based {{perspective}} {{to understand why}} some universities are more successful than others at generating technology-based spinoff companies. In this respect, we derive eight hypotheses that <b>link</b> <b>attributes</b> of resources and capabilities, institutional, financial, commercial and human capital, to university spinoff outcomes. Using panel data from 1980 to 2001, our econometric estimators reveal evidence of history dependence for successful technology transfer to occur although faculty quality, size and orientation of science and engineering funding and commercial capability were also found to be predictors of university spinoff activity. We conclude by drawing implications for policy makers and university heads. ...|$|R
40|$|Abstract: Accuracy {{of travel}} model network data is {{critical}} to the accuracy of travel demand forecasting. Houston-Galveston Area Council's Transportation Department has been using a set of customized ArcInfo menus and AML programs to check network coding errors (such as duplicate links and nodes, missing links and nodes, and incorrect <b>link</b> <b>attributes),</b> update the <b>attributes</b> of network <b>link</b> and centroid connector, and export network link data in EMME/ 2 readable format as input files to EMME/ 2 travel demand model. In order to enhance the existing application by taking advantage of the open customization environment within ArcGIS, we decided to migrate the existing AML application to an ArcGIS application using ArcObject...|$|R
40|$|Abstract—We {{propose a}} unified {{approach}} for imputation of the <b>links</b> and <b>attributes</b> in longitudinal social surveys {{which accounts for}} changing network topology and interdependence between the actor’s <b>links</b> and <b>attributes.</b> The previous studies on the treatment of non-respondents in longitudinal social networks were mostly concerned with imputation of the missing links only or imputation effects on the networks statistics. For this study we conduct a set of experiments on synthetic and real life datasets with 20 %- 60 % of nodes missing under four mechanisms. The obtained results were better than when using alternative methods which suggest that our method {{can be used as}} a viable imputation tool. Keywords-imputation, temporal data analysis, social networks, exponential random graph models I...|$|R
5000|$|Contrast set {{learning}} {{is a form of}} association rule learning. Association rule learners typically offer rules <b>linking</b> <b>attributes</b> commonly occurring together in a training set (for instance, people who are enrolled in four-year programs and take a full course load tend to also live near campus). Instead of ﬁnding rules that describe the current situation, contrast set learners seek rules that differ meaningfully in their distribution across groups (and thus, can be used as predictors for those groups). For example, a contrast set learner could ask, “What are the key identifiers of a person with a bachelor's degree or a person with a PhD, and how do people with PhD's and bachelor’s degrees differ?” ...|$|R
50|$|The ITU-T Y.156sam defines test streams with service <b>attributes</b> <b>linked</b> to the Metro Ethernet Forum (MEF) 10.2 definitions.|$|R
40|$|Realistic facial {{animation}} {{can enhance}} the immersion characteristic of 3 D games. This paper proposes a 3 D morphing target method based on GPU for real-time animation of facial expressions. We employ texture mapping to obtain a realistic appearance, and design a fast morphing process to achieve a relatively high FPS by modifying the morph data structure and implementing the morphing algorithm in the shader. The algorithm can be realized and divided into seven steps including creating morph target expressions, evaluating difference vector, initializing morph data structure, loading data into VBO, <b>linking</b> <b>attributes</b> to shader and rendering facial expressions. The rendering system also gives us convenient interaction with the digital character and realizes quick expressions shift for practical application. Experiment {{results show that the}} proposed approach yields realistic real-time expressions animation...|$|R
40|$|Abstract: Researchers in the {{hypermedia}} field often lament {{that the}} World Wide Web {{does not support}} many of hypermedia's rich structuring, navigation and annotation features. What would it take for everyday Web applications to be fully hypermedia compliant, now that the basic hypermedia building blocks exist on the Web? The following four capabilities are the most critical for integrating hypermedia support in the Web environment: edit-capable browsers, storing document content and link anchors separately, external linkbases, and displaying link spans, node and <b>link</b> <b>attributes.</b> Individual developers cannot decide autonomously on how to resolve many of the outstanding issues. Developers need agreed-upon conventions and tools built upon today's Web standards to fully incorporate hypermedia functionality into everyday applications. Categories and Subject Descriptors: H. 5. 4. [Information interfaces and presentation...|$|R
40|$|Temporal {{networks}} are ubiquitous and evolve over {{time by the}} addition, deletion, and changing of <b>links,</b> nodes, and <b>attributes.</b> Although many relational datasets contain temporal information, the majority of existing techniques in relational learning focus on static snapshots and ignore the temporal dynamics. We propose a framework for discovering temporal representations of relational data to increase the accuracy of statistical relational learning algorithms. The temporal relational representations serve {{as a basis for}} classification, ensembles, and pattern mining in evolving domains. The framework includes (1) selecting the time-varying relational components (<b>links,</b> <b>attributes,</b> nodes), (2) selecting the temporal granularity, (3) predicting the temporal influence of each time-varying relational component, and (4) choosing the weighted relational classifier. Additionally, we propose temporal ensemble methods that exploit the temporal-dimension of relational data. These ensembles outperform traditional and more sophisticated relational ensembles while avoiding the issue of learning the most optimal representation. Finally, the space of temporal-relational models are evaluated using a sample of classifiers. In all cases, the proposed temporal-relational classifiers outperform competing models that ignore the temporal information. The results demonstrate the capability and necessity of the temporal-relational representations for classification, ensembles, and for mining temporal datasets...|$|R
40|$|Abstract—With {{the rapid}} {{emergence}} of the internet world, {{a lot of information}} networks become available every day. In many cases, these information networks contain objects connected by multiple links and de-scribed by different attributes. In this paper the prob-lem of clustering homogeneous information networks in groups with similar attributes and connections is studied. Clustering such networks is a challenging task due to different importance of <b>links</b> and <b>attributes.</b> In addition, it is not straightforward how to balance the <b>links</b> and <b>attributes</b> information. In this article we describe these challenges and propose a fuzzy clus-tering model as well as a fuzzy clustering algorithm, HASCOP. Extensive experimentation on real world datasets has shown that HASCOP can be successfully applied in such networks, demonstrating its efficacy and superiority against the state-of-the-art attributed graph clustering methods. Keywords—Clustering, Information Networks I...|$|R
40|$|In a {{converging}} world, where borders {{between countries}} are surpassed {{in the digital}} environment, {{it is necessary to}} develop systems that effectively replace the recognition 'vis-avis' with digital means of recognizing and identifying entities and people. In this work we summarize the current standardization efforts in the area of digital identity management. We identify a number of open challenges {{that need to be addressed}} in the near future to ensure the interoperability and usability of digital identity management services in an efficient and privacy maintaining international framework. These challenges for standardization include: the management of identifiers for digital identities at the global level; attribute management including attribute format, structure, and assurance; procedures and protocols to <b>link</b> <b>attributes</b> to digital identities. Attention is drawn to key elements that should be considered in addressing these issues through standardization. © 2014 ITU...|$|R
40|$|In {{seasonal}} environments, parturition of most vertebrates generally occurs {{within a}} short time-window each year. This synchrony is generally interpreted as being adaptive, as early born young survive better over the critical season than late born young. Among large herbivores, the factors involved in driving among- and within-individual variation in parturition date are poorly understood. We explored this question by analyzing {{the relative importance of}} <b>attributes</b> <b>linked</b> to female quality (longevity, median adult body mass and cohort), time-dependent <b>attributes</b> <b>linked</b> to female condition (reproductive success the previous year, relative annual body mass and offspring cohort (year)), and age in shaping observed variation in parturition date of roe deer. A measure of quality combining the effects of female longevity and median adult body mass accounted for 11 % of the observed among-individual variation in parturition date. Females of 2 yr old give birth 5 d later than older females. Our study demonstrates that high quality (heavy and long-lived) females give birth earlier than low quality females. Temporally variable <b>attributes</b> <b>linked</b> to female condition, such as reproductive success in the previous year and relative annual body mass, had no detectable influence on parturition date. We conclude that parturition date, a crucial determinant of reproductive success, is shaped by <b>attributes</b> <b>linked</b> to female quality rather than by time-dependent <b>attributes</b> <b>linked</b> to female condition in income breeders (individuals that rely on current resource intake rather than on accumulated body reserves to offset the increased energy requirements due to reproduction) such as roe deer. © 2013 The Authors...|$|R
