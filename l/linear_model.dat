10000|10000|Public
25|$|In a <b>linear</b> <b>model,</b> if {{the errors}} {{belong to a}} normal {{distribution}} the least squares estimators are also the maximum likelihood estimators.|$|E
25|$|Each of the 50 million queries {{is tested}} as Q {{to see if}} the result {{computed}} from a single query could match the actual history ILI data obtained from the U.S. Centers for Disease Control and Prevention (CDC). This process produces a list of top queries which gives the most accurate predictions of CDC ILI data when using the <b>linear</b> <b>model.</b> Then the top 45 queries are chosen because, when aggregated together, these queries fit the history data the most accurately. Using the sum of top 45 ILI-related queries, the <b>linear</b> <b>model</b> is fitted to the weekly ILI data between 2003 and 2007 so that the coefficient can be gained. Finally, the trained model is used to predict flu outbreak across all regions in the United States.|$|E
25|$|In general, {{the more}} a {{measurement}} {{is like the}} sum of independent variables with equal influence on the result, the more normality it exhibits. This justifies the common use of this distribution to stand in {{for the effects of}} unobserved variables in models like the <b>linear</b> <b>model.</b>|$|E
5000|$|Model {{relationships}} between variables by linear or nonlinear regression, generalized <b>linear</b> <b>models,</b> generalized additive <b>models,</b> generalized <b>linear</b> mixed <b>models</b> or hierarchical generalized <b>linear</b> <b>models,</b> Logistics regression, Multinomial regression; ...|$|R
40|$|This package {{provides}} profile likelihoods for a parameter {{of interest}} in commonly used statistical models. The <b>models</b> include <b>linear</b> <b>models,</b> generalized <b>linear</b> <b>models,</b> proportional odds <b>models,</b> <b>linear</b> mixed-effects <b>models,</b> and <b>linear</b> <b>models</b> for longitudinal responses fitted by generalized least squares. The package also provides plots for normalized profile likelihoods {{as well as the}} maximum profile likelihood estimates and the kth likelihood support intervals...|$|R
40|$|<b>Linear</b> <b>Models</b> {{explores the}} theory of <b>linear</b> <b>models</b> and the dynamic {{relationships}} that these models have with Analysis of Variance (ANOVA), experimental design, and random and mixed-model effects. This one-of-a-kind book emphasizes an approach that clearly explains the distribution theory of <b>linear</b> <b>models</b> and experimental design starting from basic mathematical concepts in linear algebra. This book is a valuable book for courses on <b>linear</b> <b>models</b> at the upper-undergraduate and graduate levels. It is also an excellent reference for practitioners who use <b>linear</b> <b>models</b> to conduct research {{in the fields of}} econometrics, psychology, sociology, biology, and agriculture. " [...] BOOK JACKE...|$|R
25|$|The {{following}} discussion is mostly presented {{in terms of}} linear functions {{but the use of}} least squares is valid and practical for more general families of functions. Also, by iteratively applying local quadratic approximation to the likelihood (through the Fisher information), the least-squares method may be used to fit a generalized <b>linear</b> <b>model.</b>|$|E
25|$|Adaptive strategy: In this model, the organization's {{goals and}} {{activities}} are {{primarily concerned with}} adaptation to the environment, analogous to a biological organism. The need for continuous adaption reduces or eliminates the planning window. There is more focus on means (resource mobilization to address the environment) rather than ends (goals). Strategy is less centralized than in the <b>linear</b> <b>model.</b>|$|E
25|$|There {{may be some}} {{relationship}} between the regressors. For instance, the third regressor may be {{the square of the}} second regressor. In this case (assuming that the first regressor is constant) we have a quadratic model in the second regressor. But this is still considered a <b>linear</b> <b>model</b> because it is linear in the βs.|$|E
40|$|We {{consider}} an approach {{based on the}} hierarchical generalized <b>linear</b> <b>models</b> and h-likelihood estimators for claims reserving in non-life insurance. The hierarchical generalized <b>linear</b> <b>models</b> represent a class of flexible mixture models that extend the generalized <b>linear</b> <b>models</b> and the generalized <b>linear</b> mixed <b>models.</b> The fitting algorithm and the inferential analyses {{can be obtained by}} applying standard procedures to one or more generalized <b>linear</b> <b>models,</b> suitably defined. Our study examines how the models can be used to obtain predictors of the claims reserves and to determine their prediction uncertainty...|$|R
40|$|In recent years, {{the class}} of {{generalized}} <b>linear</b> <b>models</b> has gained popularity as a statistical modeling tool. This popularity {{is due in part}} to the flexibility of generalized <b>linear</b> <b>models</b> in addressing a variety of statistical problems and to the availability of software to fit the models. The SAS ® system provides two new tools that fit generalized <b>linear</b> <b>models.</b> The GEN-MOD procedure in SAS/STAT ® software is available in release 6. 09 of the SAS system and in experimental form in release 6. 08. SAS/INSIGHT ® software provides a generalized <b>linear</b> <b>modeling</b> capability in release 6. 08. This paper introduces generalized <b>linear</b> <b>models</b> and reviews the SAS software that fits the models...|$|R
40|$|This package {{provides}} commands for Markov chain Monte Carlo (MCMC) sampling {{from the}} posterior distribution of <b>linear</b> <b>models.</b> Two models {{are provided in}} this version: a normal <b>linear</b> regression <b>model</b> (the Bayesian equivalent of regress), and a normal <b>linear</b> mixed <b>model</b> (the Bayesian equivalent of xtmixed). MCMC, Markov Chain Monte Carlo, <b>linear</b> <b>models,</b> posterior distribution, regression, mixed models...|$|R
25|$|If x and y are {{results of}} {{measurements}} that contain measurement error, the realistic limits on the correlation coefficient are not −1 to +1 but a smaller range. For {{the case of a}} <b>linear</b> <b>model</b> with a single independent variable, the coefficient of determination (R squared) is the square of r, Pearson's product-moment coefficient.|$|E
25|$|Rosemary Basson {{proposed}} an alternative model of sexual response. She {{argues that the}} <b>linear</b> <b>model</b> is good at explaining men's sexual response but it poorly explains women's sexual responses; thus, she puts forth a circular model. She states that closeness or attachment to a partner increases the effectiveness of sexual stimulation. This leads to enhanced sexual arousal, which may ultimately result in orgasm. Consequently, this positive sexual arousal continues the sexual desire that women feel, and this desire increases intimacy with the partner. Other researchers have attempted to evaluate women's sexual functioning {{in terms of this}} new model but have found contradictory results. In one study conducted by Giles and McCabe, they found that the <b>linear</b> <b>model</b> of sexual response was a good predictor of women's sexual functioning (and dysfunction), while the circular model was a poor predictor. Once they modified the pathways of the model, the circular model then became a good predictor of sexual functioning. In another study looking at Malaysian women, researchers found that the circular model was actually a good predictor of women's sexual desire and arousal. More research {{needs to be done in}} this area to show whether the circular model more accurately describes women's sexual response.|$|E
25|$|In 1810, {{after reading}} Gauss's work, Laplace, after proving the central limit theorem, {{used it to}} give a large sample {{justification}} for the method of least square and the normal distribution. In 1822, Gauss was able to state that the least-squares approach to regression analysis is optimal {{in the sense that}} in a <b>linear</b> <b>model</b> where the errors have a mean of zero, are uncorrelated, and have equal variances, the best linear unbiased estimator of the coefficients is the least-squares estimator. This result is known as the Gauss–Markov theorem.|$|E
40|$|A Hands-On Way to Learning Data AnalysisPart of {{the core}} of statistics, <b>linear</b> <b>models</b> are used to make {{predictions}} and explain {{the relationship between the}} response and the predictors. Understanding <b>linear</b> <b>models</b> is crucial to a broader competence in the practice of statistics. <b>Linear</b> <b>Models</b> with R, Second Edition explains how to use <b>linear</b> <b>models</b> in physical science, engineering, social science, and business applications. The book incorporates several improvements that reflect how the world of R has greatly expanded since the publication of the first edition. New to the Second EditionReorgani...|$|R
40|$|This {{paper will}} discuss the basic {{principles}} underlying the theory of generalized <b>linear</b> <b>models</b> and the advantages of using generalized <b>linear</b> <b>models</b> over more traditional methods of actuarial <b>modeling.</b> Generalized <b>linear</b> <b>models</b> offer the flexibility needed to model real world data that does not conform to the strict assumptions underlying these traditional methods. The second part of this paper will illustrate how generalized <b>linear</b> <b>models</b> can be directly applied to current areas of actuarial practice, and the advantages {{that are to be}} gained. Honors College"May 2002. "Thesis (B. ?. ...|$|R
40|$|In the Searle's (1987) book, <b>Linear</b> <b>Models</b> for Unbalanced Data, a {{characterization}} of the estimable functions in <b>linear</b> <b>models</b> with non estimable constraints is presented. In this informal paper, I indicate another {{characterization of}} these&# 13; functions which was developed by Magnus and Neudecker (1988). The aim of the articte {{is to provide a}} caution signal to user of <b>linear</b> <b>models</b> theory...|$|R
25|$|In a 2014 study Hartley {{and colleagues}} at the University of York {{reported}} that impressions of the traits of approachability, youthfulness/attractiveness and dominance can be formed {{in as little as}} 100 milliseconds, from measurable characteristics such as the shape of and the spacing around the eyes, nose and mouth. it was found that first impressions of social traits, such as trustworthiness or dominance, are reliably perceived in faces. Physical facial features were objectively measured from feature positions and colours. A neural network was the used to model factor the dimensions of approachability, youthful-attractiveness and dominance. 58% of the variance in raters’ impressions was accounted for by a <b>linear</b> <b>model.</b>|$|E
25|$|This strong {{assumption}} was first studied in 1996 by Boynton and colleagues, who checked {{the effects on}} the primary visual cortex of patterns flickering 8times a second and presented for 3 to 24seconds. Their result showed that when visual contrast of the image was increased, the HDR shape stayed the same but its amplitude increased proportionally. With some exceptions, responses to longer stimuli could also be inferred by adding together the responses for multiple shorter stimuli summing to the same longer duration. In 1997, Dale and Buckner tested whether individual events, rather than blocks of some duration, also summed the same way, and found they did. But they also found deviations from the <b>linear</b> <b>model</b> at time intervals less than 2seconds.|$|E
25|$|One common {{approach}} to analysing fMRI data {{is to consider}} each voxel separately {{within the framework of}} the general <b>linear</b> <b>model.</b> The model assumes, at every time point, that the HDR is equal to the scaled and summed version of the events active at that point. A researcher creates a design matrix specifying which events are active at any timepoint. One common way is to create a matrix with one column per overlapping event, and one row per time point, and to mark it if a particular event, say a stimulus, is active at that time point. One then assumes a specific shape for the HDR, leaving only its amplitude changeable in active voxels. The design matrix and this shape are used to generate a prediction of the exact HDR response of the voxel at every timepoint, using the mathematical procedure of convolution. This prediction does not include the scaling required for every event before summing them.|$|E
40|$|Region-specific <b>linear</b> <b>models</b> {{are widely}} used in {{practical}} applications because of their non-linear but highly interpretable model representations. One of the key challenges in their use is non-convexity in simultaneous optimization of regions and region-specific models. This paper proposes novel convex region-specific lin-ear models, which we refer to as partition-wise <b>linear</b> <b>models.</b> Our key ideas are 1) assigning <b>linear</b> <b>models</b> not to regions but to partitions (region-specifiers) and representing region-specific <b>linear</b> <b>models</b> by <b>linear</b> combinations of partition-specific models, and 2) optimizing regions via partition selection from {{a large number of}} given partition candidates by means of convex structured regulariza-tions. In addition to providing initialization-free globally-optimal solutions, our convex formulation makes it possible to derive a generalization bound and to use such advanced optimization techniques as proximal methods and decomposition of the proximal maps for sparsity-inducing regularizations. Experimental results demonstrate that our partition-wise <b>linear</b> <b>models</b> perform better than or are at least competitive with state-of-the-art region-specific or locally <b>linear</b> <b>models.</b> ...|$|R
40|$|It is {{straightforward}} to fit multivariate <b>linear</b> <b>models</b> (MLMs) in R with the lm function. John Fox (McMaster) Multivariate <b>Linear</b> <b>Models</b> useR! 2011 2 / 37 Overview It {{is straightforward}} to fit multivariate <b>linear</b> <b>models</b> (MLMs) in R with the lm function. The anova function is flexible (Dalgaard, 2007) but it calculates sequential (“type I”) tests, and performing other common tests, especially for repeated-measures designs, is relatively inconvenient. John Fox (McMaster) Multivariate <b>Linear</b> <b>Models</b> useR! 2011 2 / 37 Overview It is straightforward to fit multivariate <b>linear</b> <b>models</b> (MLMs) in R with the lm function. The anova function is flexible (Dalgaard, 2007) but it calculates sequential (“type I”) tests, and performing other common tests, especially for repeated-measures designs, is relatively inconvenient. The Anova {{function in the}} car package (Fox and Weisberg, 2011) ca...|$|R
40|$|Partially <b>linear</b> <b>models</b> are <b>linear</b> {{regression}} <b>models</b> {{where one}} component {{is allowed to}} vary nonparametrically. Generalized partially <b>linear</b> <b>models</b> generalize this case from linear regression to the quasi-likelihood setting of standard GLIMs, thus encompassing a larger class models including logistic, Poisson, and Gamma regression. Although estimation for these models is possible in official Stata via fractional polynomials, this approach is entirely nonparametric and uses a local-linear smooth to estimate the "nonlinear" component. The Stata command gplm for fitting generalized partially <b>linear</b> <b>models</b> is discussed and demonstrated. ...|$|R
500|$|Evolutionary ideas, {{although}} not natural selection, were accepted by German biologists accustomed to ideas of homology in morphology from Goethe's Metamorphosis of Plants {{and from their}} long tradition of comparative anatomy. Bronn's alterations in his German translation added to the misgivings of conservatives, but enthused political radicals. Ernst Haeckel was particularly ardent, aiming to synthesise Darwin's ideas with those of Lamarck and Goethe while still reflecting the spirit of Naturphilosophie. Their ambitious programme to reconstruct the evolutionary history of life was joined by Huxley and supported by discoveries in [...] Haeckel used embryology extensively in his recapitulation theory, which embodied a progressive, almost <b>linear</b> <b>model</b> of evolution. Darwin was cautious about such histories, and had already noted that von Baer's laws of embryology supported his idea of complex branching.|$|E
2500|$|More generally, one {{can have}} [...] regressors , and a <b>linear</b> <b>model</b> ...|$|E
2500|$|Consider a <b>linear</b> <b>model</b> {{with more}} than a single {{explanatory}} variable, of the form ...|$|E
40|$|Adjusted responses, {{adjusted}} fitted {{values and}} adjusted residuals {{are known to}} play in Generalized <b>Linear</b> <b>Models</b> the role played in <b>Linear</b> <b>Models</b> by observations, fitted values and ordinary residuals. We think this parallelism, which was widely recognized and used in the early literature on Generalized <b>Linear</b> <b>Models,</b> has been somewhat overlooked in more recent presentations. We revise this parallelism, systematizing and proving some results that are either scattered or not satisfactorily {{spelled out in the}} literature. In particular, we formally derive the asymptotic dispersion matrix of the (scaled) adjusted residuals, by proving that in Generalized <b>Linear</b> <b>Models</b> the fitted values are asymptotically uncorrelated with the raw residuals and hence deriving the asymptotic dispersion matrix of these latter residuals. Also, we show that an orthogonal decomposition of the error vector between adjusted response and true linear predictor, parallel to the familiar decomposition in <b>Linear</b> <b>Models,</b> holds approximately. Finally, we provide some new perspective, both in Linear and Generalized <b>Linear</b> <b>Models,</b> on adjusted residuals for model comparison, and their relationships with test-statistics used to compare the fit of nested models...|$|R
5000|$|McCullagh is the {{coauthor}} with John Nelder of Generalized <b>Linear</b> <b>Models</b> (1983, Chapman and Hall - {{second edition}} 1989), a seminal {{text on the}} subject of generalized <b>linear</b> <b>models</b> (GLMs) with more than 23,000 citations.|$|R
30|$|Hierarchical <b>linear</b> <b>modeling.</b>|$|R
2500|$|A <b>linear</b> <b>model</b> is used {{to compute}} the log-odds of Influenza-like illness (ILI) {{physician}} visit and the log-odds of ILI-related search query: ...|$|E
2500|$|Of these, {{the first}} two {{hypotheses}} have been recently mathematically examined to have identical calcium-dependent dynamics which provides strong theoretical evidence for a calcium-based model of plasticity, which in a <b>linear</b> <b>model</b> where {{the total number of}} receptors are conserved looks like ...|$|E
2500|$|... of m linear {{equations}} in n unknown coefficients, β1,β2,…,β'n, with m > n. (Note: for a <b>linear</b> <b>model</b> as above, {{not all of}} [...] contains {{information on}} the data points. The first column is populated with ones, , only the other columns contain actual data, and n = number of regressors + 1.) This can be written in matrix form as ...|$|E
40|$|Description This package {{implements}} {{parameter estimation}} in normal (<b>linear)</b> <b>models</b> under <b>linear</b> equality and inequality constraints and implements normal likelihood ratio tests involving inequality-constrained hypotheses. For inequality-constrained <b>linear</b> <b>models,</b> averaging over R-squared for different orderings of regressors is also included...|$|R
40|$|Summary. Generalized <b>linear</b> <b>models</b> {{have become}} a {{standard}} technique in the statistical modelling toolbox for investigating relationships between variables. The assumption of homogeneity of regression coefficients over all observations can be relaxed by incorporating generalized <b>linear</b> <b>models</b> into the finite mixture framework. The model class consisting of finite mixtures of generalized <b>linear</b> <b>models</b> is pre-sented. Model identification is discussed given that difficulties might be encountered due to trivial and generic identifiability problems. These problems have already been observed for mixtures of distributions, but the extension to mixtures of regression models introduces additional identifiability problems. Details on model estimation are given and the application is illustrated on several examples. Key words: finite mixture <b>models,</b> generalized <b>linear</b> <b>models,</b> unobserved hetero-geneity...|$|R
40|$|For regularized estimation, {{the upper}} tail {{behavior}} of the random Lipschitz coefficient associated with empirical loss functions is known {{to play an important}} role in the error bound of Lasso for high dimensional generalized <b>linear</b> <b>models.</b> The upper tail behavior is known for <b>linear</b> <b>models</b> but much less so for nonlinear models. We establish exponential type inequalities for the upper tail of the coefficient and illustrate an application of the results to Lasso likelihood estimation for high dimensional generalized <b>linear</b> <b>models...</b>|$|R
