10000|6665|Public
5|$|Building on {{his results}} on matrix games {{and on his}} model of an {{expanding}} economy, von Neumann invented the theory of duality in <b>linear</b> <b>programming,</b> after George Dantzig described his work in a few minutes, when an impatient von Neumann asked him {{to get to the}} point. Then, Dantzig listened dumbfounded while von Neumann provided an hour lecture on convex sets, fixed-point theory, and duality, conjecturing the equivalence between matrix games and <b>linear</b> <b>programming.</b>|$|E
5|$|Later, von Neumann {{suggested}} a new method of <b>linear</b> <b>programming,</b> using the homogeneous linear system of Gordan (1873), which was later popularized by Karmarkar's algorithm. Von Neumann's method used a pivoting algorithm between simplices, with the pivoting decision {{determined by a}} nonnegative least squares subproblem with a convexity constraint (projecting the zero-vector onto the convex hull of the active simplex). Von Neumann's algorithm was the first interior point method of <b>linear</b> <b>programming.</b>|$|E
5|$|Von Neumann's {{results have}} been viewed as a special case of <b>linear</b> <b>programming,</b> where von Neumann's model uses only nonnegative matrices. The study of von Neumann's model of an {{expanding}} economy continues to interest mathematical economists with interests in computational economics. This paper {{has been called the}} greatest paper in mathematical economics by several authors, who recognized its introduction of fixed-point theorems, linear inequalities, complementary slackness, and saddlepoint duality. In the proceedings of a conference on von Neumann's growth model, Paul Samuelson said that many mathematicians had developed methods useful to economists, but that von Neumann was unique in having made significant contributions to economic theory itself.|$|E
50|$|Columns in {{the primal}} <b>linear</b> <b>program</b> {{corresponds}} to rows in the dual <b>linear</b> <b>program.</b> The equivalent dual <b>linear</b> <b>program</b> of LPBoost {{is the following}} <b>linear</b> <b>program.</b>|$|R
40|$|<b>Linear</b> <b>programs</b> are {{problems}} that involve the optimization of a linear objective function subject to linear constraints. Every <b>linear</b> <b>program</b> has an inherent geometric representation. Each constraint defines an halfspace and the feasible {{region of the}} the <b>linear</b> <b>program</b> is the convex polyhedron defined by intersection of all the halfspaces. The maximal solution to the <b>linear</b> <b>program</b> (if i...|$|R
40|$|We {{introduce}} {{a class of}} <b>linear</b> <b>programs</b> with constraints {{in the form of}} implications. Such <b>linear</b> <b>programs</b> arise in support vector machine classi cation, where in addition to explicit datasets to be classi ed, prior knowledge such as expert's experience in the form of logical implications, are imposed on the classi er. The overall problem can be viewed either as a semi-in nite <b>linear</b> <b>program</b> or as a <b>linear</b> <b>program</b> with equilibrium constraints which, in either case, can be solved by an equivalent simple <b>linear</b> <b>program</b> under mild assumptions...|$|R
25|$|<b>Linear</b> <b>programming</b> is {{a widely}} used field of {{optimization}} for several reasons. Many practical problems in operations research can be expressed as <b>linear</b> <b>programming</b> problems. Certain special cases of <b>linear</b> <b>programming,</b> such as network flow problems and multicommodity flow problems are considered important enough to have generated much research on specialized algorithms for their solution. A number of algorithms for other types of optimization problems work by solving LP problems as sub-problems. Historically, ideas from <b>linear</b> <b>programming</b> have inspired many of the central concepts of optimization theory, such as duality, decomposition, {{and the importance of}} convexity and its generalizations. Likewise, <b>linear</b> <b>programming</b> is heavily used in microeconomics and company management, such as planning, production, transportation, technology and other issues. Although the modern management issues are ever-changing, most companies would like to maximize profits or minimize costs with limited resources. Therefore, many issues can be characterized as <b>linear</b> <b>programming</b> problems.|$|E
25|$|In 1963, Dantzig’s <b>Linear</b> <b>Programming</b> and Extensions was {{published}} by Princeton University Press. Rich in insight and coverage of significant topics, the book quickly became “the bible” of <b>linear</b> <b>programming.</b>|$|E
25|$|<b>Linear</b> <b>programming</b> (LP, {{also called}} linear optimization) {{is a method}} to achieve the best outcome (such as maximum profit or lowest cost) in a {{mathematical}} model whose requirements are represented by linear relationships. <b>Linear</b> <b>programming</b> is a special case of mathematical programming (mathematical optimization).|$|E
40|$|Solving a <b>linear</b> <b>program</b> with 0 - 1 {{constrained}} variables is an NP-complete problem. Such <b>linear</b> <b>programs</b> {{have many}} practical uses {{in the area}} of scheduling. This paper describes a heuristic-based method for finding feasible solutions to such <b>linear</b> <b>programs.</b> We will also provide the motivation for attempting to find feasible solutions for such problems by showing how several interesting scheduling problems can be formulated as <b>linear</b> <b>program...</b>|$|R
40|$|AbstractIn {{previous}} work we proposed <b>Linear</b> <b>Programs</b> {{as a fine}} grained model for imperative programs, and showed how the model checking procedure used in SLAM can be generalised to a model checking procedure for <b>Linear</b> <b>Programs.</b> In this paper we show that our model checking procedure for <b>linear</b> <b>programs</b> can be extended {{in such a way}} to support the analysis of <b>linear</b> <b>programs</b> featuring a symbol for undefined values and conditional expressions. This extension is particularly important as it paves the way to the construction of model checking procedures for wider classes of imperative programs such as, e. g., <b>linear</b> <b>programs</b> with arrays. We provide a detailed account of a symbolic model checking procedure for this extended class of <b>linear</b> <b>programs,</b> discuss its implementation in the eureka tool, and present experimental results that confirm its effectiveness in the analysis of <b>linear</b> <b>programs</b> with arrays...|$|R
40|$|In this paper, we {{initiate}} {{the systematic study}} of solving <b>linear</b> <b>programs</b> under differential privacy. The first step is simply to define the problem: to this end, we introduce several natural classes of private <b>linear</b> <b>programs</b> that capture different ways sensitive data {{can be incorporated into}} a <b>linear</b> <b>program.</b> For each class of <b>linear</b> <b>programs</b> we give an efficient, differentially private solver based on the multiplicative weights framework, or we give an impossibility result...|$|R
25|$|The {{field of}} {{optimization}} is further split in several subfields, {{depending on the}} form of the objective function and the constraint. For instance, <b>linear</b> <b>programming</b> deals with the case that both the objective function and the constraints are linear. A famous method in <b>linear</b> <b>programming</b> is the simplex method.|$|E
25|$|Dantzig {{is known}} for his {{development}} of the simplex algorithm, an algorithm for solving <b>linear</b> <b>programming</b> problems, and for his other work with <b>linear</b> <b>programming.</b> In statistics, Dantzig solved two open problems in statistical theory, which he had mistaken for homework after arriving late to a lecture by Jerzy Neyman.|$|E
25|$|Simplex {{algorithm}} of George Dantzig, {{designed for}} <b>linear</b> <b>programming.</b>|$|E
25|$|The minimum vertex cover {{problem can}} be {{formulated}} as a half-integral <b>linear</b> <b>program</b> whose dual <b>linear</b> <b>program</b> is the maximum matching problem.|$|R
40|$|A simplex-based {{method of}} solving {{specific}} classes of large-scale <b>linear</b> <b>programs</b> is presented. The structure of both staircase and block-angular <b>linear</b> <b>programs</b> is exploited {{to construct an}} advanced or "crash" basis {{to be used with}} a simplex-based <b>linear</b> <b>program</b> solver. First, the constraint matrix is decomposed into blocks. In contrast to many other systems that require additional information about the form of the <b>linear</b> <b>program,</b> the method described here determines this decomposition without prior knowledge of the matrix structure. As the problem of automatically finding such a decomposition is NP-complete, a heuristic is used to discover blocks within the constraint matrix. After a decomposition of the constraint matrix is determined, smaller <b>linear</b> <b>programs</b> called subproblems are formed. These subproblems are solved using a simplex-based solver, and the solution information is used to construct an advanced or "crash" basis for the original <b>linear</b> <b>program.</b> In contrast to decomposition methods that iteratively solve subproblems to obtain a solution to the original problem, this approach requires solving each subproblem at most twice. Finally, the original <b>linear</b> <b>program</b> is solved by providing the advanced basis to a simplex-based solver. Results indicate that this method solves some large <b>linear</b> <b>programs</b> much faster than state-of-the-art simplex-based solvers do. For example, for a set of <b>linear</b> <b>programs</b> that range in size from 5, 000 x 9, 000 to 30, 000 x 50, 000 constraints and variables, the presented method solves each <b>linear</b> <b>program</b> in about a tenth the number of simplex iterations. This reduces the total time required to solve each <b>linear</b> <b>program</b> by a factor of from two to five...|$|R
30|$|Optimally {{solving the}} dual-objectives in (2) {{can be done}} {{sequentially}} via two <b>linear</b> <b>programs</b> (after relaxing the variables to be continuous) using solvers such as LIPSOL[19]. The MAXUSER problem can be solved first as a <b>linear</b> <b>program</b> to obtain the feasible set of users, and then solve the MINBANDWIDTH problem as another <b>linear</b> <b>program</b> for the feasible set of users. It may however be too complex to be beneficial in real time as it involves solving two <b>linear</b> <b>programs.</b>|$|R
25|$|<b>Linear</b> <b>programming</b> can {{be applied}} to various fields of study. It is widely used in {{business}} and economics, and is also utilized for some engineering problems. Industries that use <b>linear</b> <b>programming</b> models include transportation, energy, telecommunications, and manufacturing. It has proven useful in modeling diverse types of problems in planning, routing, scheduling, assignment, and design.|$|E
25|$|George B. Dantzig and Mukund N. Thapa. 1997. <b>Linear</b> <b>programming</b> 1: Introduction. Springer-Verlag.|$|E
25|$|However, the simplex {{algorithm}} has poor worst-case behavior: Klee and Minty {{constructed a}} family of <b>linear</b> <b>programming</b> problems for which the simplex method takes a number of steps exponential in the problem size. In fact, for some time it was not known whether the <b>linear</b> <b>programming</b> problem was solvable in polynomial time, i.e. of complexity class P.|$|E
40|$|Abstract: We {{present a}} new {{deterministic}} <b>linear</b> <b>program</b> {{for the network}} revenue management problem with customer choice behavior. The novel aspect of our <b>linear</b> <b>program</b> is that it naturally generates bid prices that depend on how much time is left until the time of departure. Similar to the earlier <b>linear</b> <b>program</b> used by van Ryzin and Liu (2004), the optimal objective value of our <b>linear</b> <b>program</b> provides an upper bound on the optimal total expected revenue over the planning horizon. In addition, the percent gap between the optimal objective value of our <b>linear</b> <b>program</b> and the optimal total expected revenue diminishes in an asymptotic regime where the leg capacities {{and the number of}} time periods in the planning horizon increase linearly with the same rate. Computational experiments indicate that when compared with the <b>linear</b> <b>program</b> that appears in the existing literature, ou...|$|R
5000|$|If all the {{solutions}} to the <b>linear</b> <b>program</b> are found, they will constitute all the Nash equilibria for the game. Conversely, any <b>linear</b> <b>program</b> can be converted into a two-player, zero-sum game by using a change of variables that {{puts it in the}} form of the above equations. So such games are equivalent to <b>linear</b> <b>programs,</b> in general.|$|R
40|$|By perturbing {{properly}} a <b>linear</b> <b>program</b> to a separable quadratic program it {{is possible}} to solve the latter in its dual variable space by iterative techniques such as sparsity-preserving SOR (successive over relaxations). In this way large sparse <b>linear</b> <b>programs</b> can be handled. This paper gives a new computational criterion to check whether the solution of the perturbed quadratic programs provide the least 2 -norm solution of the original <b>linear</b> <b>program.</b> This criterion improves on the criterion proposed in an earlier paper. The author also describes an algorithm for solving <b>linear</b> <b>programs</b> which is based on the SOR methods. The main property of this algorithm is that, under mild assumptions, it finds the least 2 -norm solution of a <b>linear</b> <b>program</b> in a finite number of iterations...|$|R
25|$|In {{mathematical}} optimization, Dantzig's simplex algorithm (or simplex method) is {{a popular}} algorithm for <b>linear</b> <b>programming.</b>|$|E
25|$|In {{operations}} research, <b>linear</b> <b>programming</b> {{problems can}} be solved by the simplex algorithm of George Dantzig.|$|E
25|$|Progressive {{improvement}} algorithms {{which use}} techniques reminiscent of <b>linear</b> <b>programming.</b> Works well {{for up to}} 200 cities.|$|E
50|$|<b>Linear</b> <b>programs</b> {{in which}} all {{constraints}} are binary can be solved in strongly polynomial time, a result that is not known to be true for more general <b>linear</b> <b>programs.</b>|$|R
40|$|The {{objective}} function of any solvable <b>linear</b> <b>program</b> can be perturbed by a differentiable, convex or Lipschitz continuous function {{in such a}} way that (a) a solution of the original <b>linear</b> <b>program</b> is also a Karush-Kuhn-Tucker point, local or global solution of the perturbed program, or (b) each global solution of the perturbed problem is also a solution of the <b>linear</b> <b>program...</b>|$|R
30|$|Multiobjective {{optimization}} {{and robust}} optimization {{have been well}} studied, but they are rarely considered in combination. In this paper, we consider the multiobjective <b>linear</b> <b>programs</b> where coefficients in the objective function belong to uncertain-but-bounded sets. First, we introduce {{the concept of a}} robust efficient solution to uncertain multiobjective <b>linear</b> <b>programs.</b> We also introduce two common scalarization methods, the weighted sum scalarization and ϵ-constraint scalarization, to compute robust efficient solutions of uncertain multiobjective <b>linear</b> <b>programs.</b> Finally, we obtain that the robust efficient solutions of uncertain multiobjective <b>linear</b> <b>programs</b> can be computed by some deterministic optimization problems using both weighted sum method and ϵ-constraint method.|$|R
25|$|He went on {{to study}} civil {{engineering}} at the National Autonomous University of Mexico, where he also concurrently taught algebra and <b>linear</b> <b>programming.</b>|$|E
25|$|<b>Linear</b> <b>programming</b> is a {{mathematical}} method for determining {{a way to}} achieve the best outcome (such as maximum profit or lowest cost) in a given mathematical model for some list of requirements represented as linear relationships. <b>Linear</b> <b>programming</b> arose as {{a mathematical}} model developed during World War II to plan expenditures and returns {{in order to reduce}} costs to the army and increase losses to the enemy. It was kept secret until 1947. Postwar, many industries found its use in their daily planning.|$|E
25|$|Dantzig's {{original}} {{example of}} finding the best assignment of 70 people to 70 jobs exemplifies the usefulness of <b>linear</b> <b>programming.</b> The computing power required to test all the permutations to select the best assignment is vast; the number of possible configurations exceeds the number of particles in the universe. However, it takes only a moment to find the optimum solution by posing the problem as a linear program and applying the Simplex algorithm. The theory behind <b>linear</b> <b>programming</b> drastically reduces the number of possible optimal solutions that must be checked.|$|E
40|$|We {{develop a}} {{framework}} for approximation limits of polynomial-size <b>linear</b> <b>programs</b> from lower bounds on the nonnegative ranks of suitably defined matrices. This framework yields unconditional impossibility results that are applicable to any <b>linear</b> <b>program</b> as opposed to only programs generated by hierarchies. Using our framework, we prove that O(n^ 1 / 2 -eps) -approximations for CLIQUE require <b>linear</b> <b>programs</b> of size 2 ^n^Ω(eps). (This lower bound applies to <b>linear</b> <b>programs</b> using a certain encoding of CLIQUE as a linear optimization problem.) Moreover, we establish a similar result for approximations of semidefinite <b>programs</b> by <b>linear</b> <b>programs.</b> Our main ingredient is a quantitative improvement of Razborov's rectangle corruption lemma for the high error regime, which gives strong lower bounds on the nonnegative rank of certain perturbations of the unique disjointness matrix. Comment: 23 pages, 2 figure...|$|R
40|$|One of {{my recent}} papers {{transforms}} an NP-Complete problem into {{the question of}} whether or not a feasible real solution exists to some <b>Linear</b> <b>Program.</b> The unique feature of this <b>Linear</b> <b>Program</b> is that though there is no explicit bound on the minimum required number of linear inequalities, which is most probably exponential to the size of the NP-Complete problem, the <b>Linear</b> <b>Program</b> can still be described efficiently. The reason for this efficient description is that coefficients keep repeating in some pattern, even as the number of inequalities is conveniently assumed to tend to Infinity. I discuss why this convenient assumption does not change the feasibility result of the <b>Linear</b> <b>Program.</b> I conclude with two Conjectures, which might help to make an efficient decision on the feasibility of this <b>Linear</b> <b>Program.</b> Comment: 4 Pages, 1 Generalization of earlier Theorem, and 2 Conjecture...|$|R
50|$|Khachiyan's {{algorithm}} was of landmark {{importance for}} establishing the polynomial-time solvability of <b>linear</b> <b>programs.</b> The algorithm {{was not a}} computational break-through, as the simplex method is more efficient for all but specially constructed families of <b>linear</b> <b>programs.</b>|$|R
