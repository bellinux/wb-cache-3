28|288|Public
50|$|Modern {{resistivity}} {{logging tools}} {{fall into two}} categories, Laterolog and Induction, with various commercial names, depending on the company providing the <b>logging</b> <b>services.</b>|$|E
50|$|On August 5, 2015 the Apache <b>Logging</b> <b>Services</b> Project Management Committee {{announced}} that Log4j 1 had reached {{end of life}} and that users of Log4j 1 are recommended to upgrade to Apache Log4j 2.|$|E
50|$|In 2011 GE {{completed}} {{the acquisition of}} John Wood Group PLC’s Well Support Division, which allowed for it to expand into the drilling and surface manufacturing and services portfolio. Its products include electric submersible pumps (ESP), surface wellheads, trees and <b>logging</b> <b>services.</b>|$|E
5000|$|Part 2 (optional services): File system access, Data <b>logging,</b> <b>Service</b> Access points, ...|$|R
40|$|The ALMA Common Software (ACS) is a {{software}} framework {{that provides the}} infrastructure for the Atacama Large Millimeter Array and other projects. ACS, based on CORBA, offers basic services and common design patterns for distributed software. Every properly built system {{needs to be able}} to log status and error information. Logging in a single computer scenario can be as easy as using fprintf statements. However, in a distributed system, it must provide a way to centralize all logging data in a single place without overloading the network nor complicating the applications. ACS provides a complete <b>logging</b> <b>service</b> infrastructure in which every log has an associated priority and timestamp, allowing filtering at different levels of the system (application, service and clients). Currently the ACS <b>logging</b> <b>service</b> uses an implementation of the CORBA Telecom <b>Log</b> <b>Service</b> in a customized way, using only a minimal subset of the features provided by the standard. The most relevant feature used by ACS is the ability to treat the logs as event data that gets distributed over the network in a publisher-subscriber paradigm. For this purpose the CORBA Notification Service, which is resource intensive, is used. On the other hand, the Data Distribution Service (DDS) provides an alternative standard for publisher-subscriber communication for real-time systems, offering better performance and featuring decentralized message processing. The current document describes how the new high performance <b>logging</b> <b>service</b> of ACS has been modeled and developed using DDS, replacing the Telecom <b>Log</b> <b>Service.</b> Benefits and drawbacks are analyzed. A benchmark is presented comparing the differences between the implementations...|$|R
5000|$|Gmail Time Tracker: Time <b>logging</b> <b>service</b> to {{help you}} track your reading and writing in email, {{so that you can}} include it in your {{billable}} hours.|$|R
50|$|In 1980, Halliburton Research Center {{opened in}} Duncan, Oklahoma. The company's billionth sack of cement for {{customers}} was pumped in 1983. In 1989, Halliburton acquired logging and perforating specialist company Gearhart Industries and combined it with its subsidiary Welex to form Halliburton <b>Logging</b> <b>Services.</b>|$|E
50|$|In {{the early}} 1990s, Halliburton {{was found to}} be in {{violation}} of federal trade barriers in Iraq and Libya, having sold these countries dual-use oil drilling equipment and, through its former subsidiary, Halliburton <b>Logging</b> <b>Services,</b> sending six pulse neutron generators to Libya. After having plead guilty, the company was fined $1.2 million, with another $2.61 million in penalties.|$|E
50|$|Change {{and access}} logging records who {{accessed}} which attributes, what was changed, {{and when it}} was changed. <b>Logging</b> <b>services</b> allow for a forensic database audit later by keeping a record of access occurrences and changes. Sometimes application-level code is used to record changes rather than leaving this to the database. Monitoring can be set up to attempt to detect security breaches.|$|E
5000|$|... 2001- Information Handling Service {{purchases}} Petroleum Data Services {{which provided}} detailed <b>Log</b> <b>Services</b> to the USA data compilation. This provided much more deep data within North America.|$|R
40|$|This paper {{presents}} a revised {{design and implementation}} of the <b>Log</b> <b>Service</b> for the ATLAS Trigger and Data Acquisition (TDAQ) framework at CERN. A previous version of this utility was rarely used for various reasons, herein explained. The lessons learned set the grounds and motivation for a new redesign. The <b>Log</b> <b>Service</b> consists of the Logger, the entity that collects logs and stores them in an Oracle database; a set of user utilities to access and maintain the database; and a Java based tool, known as the Log Manager, which provides a compact and intuitive interface for browsing the log messages based on a user defined search criteria. The outline of these software components are explained, including various optimization techniques deployed in order to handle the large volume of entries expected to be stored in the database. Finally, a performance study has been conducted to prove the validity and behavior of the <b>Log</b> <b>Service...</b>|$|R
50|$|The <b>log</b> <b>service</b> is {{intended}} for event logging, that is, for collecting cluster-wide, function-based (as opposed to implementation specific) information about the system, which is suited for system administrators or automated tools.|$|R
5000|$|In 1998, Western Atlas was {{acquired}} by Baker Hughes. Western Atlas wireline division, Western Atlas <b>Logging</b> <b>Services,</b> became Baker Atlas, one of seven divisions of Baker Hughes. The Western Geophysical division of Western Atlas was joined with Schlumberger geophysical operations, Geco-Prakla, to form WesternGeco in 2000. WesternGeco was initially owned jointly by Baker Hughes and Schlumberger. [...] In 2006 Schlumberger bought Baker Hughes' interest in WesternGeco.|$|E
50|$|NAFC and its Members (Australian States and Territories) {{have decided}} to adopt a {{national}} standard approach to the provision of tracking and event <b>logging</b> <b>services</b> for aircraft involved in firefighting and related operations. It is planned that this will extend to messaging systems in the future. The adoption of a national approach follows extensive investigation and consultation with agencies and operators throughout Australia. A number of operational trials have also been undertaken.|$|E
50|$|In 1952, in Sacramento, California a {{group of}} Stanford University {{engineering}} and geology graduates founded Exploration Logging Company (EXLOG) to provide geologic mud <b>logging</b> <b>services</b> from mobile logging units using technical innovations in hot-wire gas detection. Vern Jones was the company's first president. EXLOG would become a world leader in surface logging, rig instrumentation and data acquisition. Baker International acquired EXLOG in 1972, and invested in its expansion. By 1982, the company had more than 200 logging units and 1,000 geologists on staff. Its broad expertise in geological services would eventually become the Surface Logging Service product line of Baker Hughes INTEQ.|$|E
40|$|Event {{logging on}} mobile phones is {{interesting}} for e. g. diary keeping. We present a <b>logging</b> <b>service</b> which – automatically {{and in the}} background on Symbian based mobile phones – logs events originated by user interactivities with mobile phones. Context {{information that can be}} obtained by the phones themselves is logged as well. The service offers direct access to the logged events, so that data can be retrieved and reviewed. This <b>logging</b> <b>service</b> was developed with aim of logging user activity related data for the Affective Diary project at SICS. The Affective Diary project aims at reflecting user’s emotional experiences. There is...|$|R
50|$|The <b>Log</b> <b>Service</b> enables {{applications}} to express and write log records through log streams {{that lead to}} particular output destinations, such as a named file. Once at the output destination, a log record is subject to output formatting rules, which are configurable and public. The logging application {{does not need to}} be aware of any of these aspects (e.g. the destination file location, file rotation or formatting, etc.) as the <b>Log</b> <b>Service</b> handles them based on the current settings for the targeted log stream. Since the output format is public, third party tools can read these log files.|$|R
5000|$|... 2001-03: Lexicomp {{launches}} {{its first}} software for PDA on the Palm platform; the following year, software for Pocket PC devices is released. In November 2001, the company records 1 million <b>logged</b> <b>services</b> in a year's time for Lexicomp ONLINE.|$|R
50|$|Late in 1987, its Canadian partner Computalog {{had signed}} a letter of intent with Gearhart {{providing}} for the possible restructuring and whole acquisition of the company. By February of the following year it was ready and told the Gearhart management of the plan. On February 24, 1988 {{it was announced that}} Gearhart was entering into a buyout agreement with oilfield service giant Halliburton Company. Within Halliburton it was merged with Welex Jet Services to become Halliburton <b>Logging</b> <b>Services</b> completing the circle which began 33 years earlier. Also, Halliburton later also acquired the division of Smith International that was to have originally been combined with Gearhart's MWD division.|$|E
40|$|The main aim of {{the thesis}} is to {{introduce}} the security of Linux operating systems and the access control list mechanism. The thesis focuses on processing security messages produced by the security mechanism into <b>logging</b> <b>services</b> and on displaying those messages. In addition, the thesis includes a concept solution and its implementation, which integrates security messages into a centralized system, keeps them and reports bugs in the Linux community distribution Fedora and in the Linux commercial distribution Red Hat Enterprise Linux...|$|E
30|$|The servers are {{physically}} located within a large-scale wireless testbed: the w-iLab.t testbed[23]. Currently, six USRPs are {{deployed in the}} testbed, each connected {{to one of the}} hexa-core servers. The w-iLab.t uses OMF (cOntrol Management Framework) as its testbed control and management framework[24]. OMF allows experimenters to configure multiple devices simultaneously, providing easy data <b>logging</b> <b>services.</b> Therefore, the multiple USRPs can easily be set up as a distributed cooperative sensing system. This configuration will be used for the Bluetooth detection experiment in Section 4.3.|$|E
50|$|Windows NT has {{featured}} event logs {{since its}} release in 1993. Applications and operating-system components {{can use this}} centralized <b>log</b> <b>service</b> to report events that have taken place, such as a failure to start a component or to complete an action.|$|R
40|$|Distributed {{transaction}} processing hinges on enforc-ing {{agreement among the}} involved resource managers on whether to commit or abort transactions (atomicity) and on making their updates permanent (durability). This paper in-troduces a <b>log</b> <b>service</b> which abstracts these tasks. The ser-vice logs commit and abort votes {{as well as the}} updates per-formed by each resource manager. Based on the votes, the <b>log</b> <b>service</b> outputs the transaction’s outcome. The service also totally orders non-concurrent transactions and makes the sequence of updates performed by each resource man-ager available as a means to consistently recover resource managers without relying on their local state. Besides the specification, we overview two highly available implemen-tations of this service and present an experimental perfor-mance evaluation. 1...|$|R
40|$|Reusability, {{reliability}} and flexibility {{are the key}} concerns in component based development. Moreover components should not affect the functionality of other components. So {{to address these issues}} software component models were introduced. This component based approach is also used in embedded real time systems. But due to recourse restrictions, traditional component models have a small domain. This problem is resolved by introducing a new software component services approach extending the functionality of already available component models. In my thesis I created a visual studio add-in which extended the functionality of a COM type library and provided the <b>logging</b> <b>service</b> for ATL smart device. It reads the classes and methods of the COM type library and then adds <b>logging</b> <b>service</b> using proxy objects. Then I tested my add-in with a managed client of a simple calculator. First I used the simple COM type library with the managed client and then I used it with my add-in’s output. The result in both cases were same so it’s clear that my add-in didn’t alter the basic functionality of the COM type library it just added the <b>logging</b> <b>service</b> to it. ...|$|R
40|$|Main {{topic of}} master's {{dissertation}} is {{the analysis of}} log integrity auditing methods. In the analytical part of this work is described described most common attack types {{that can be used}} against system logs and the most common <b>logging</b> <b>services</b> (daemons) used in the GNU/Linux family operating systems. In the research part of this work there have been done a research of some of the methods described in the analytical part and a comparison in aspect of: secure log building performance, auditing performance of secure event log, resistance against denial-of-service attack and storage consumption...|$|E
40|$|Abstract. Logging is {{a central}} service in {{computing}} systems. It lays the foundation for accountability and audit services in computing systems, {{as well as for}} other accessory services. While providing <b>logging</b> <b>services</b> in traditional computing systems is a relatively smooth process, it turns to an intricate task in pervasive computing systems. In this context, we present two contributions addressing this problem. First, we develop an approach to securely log information in marginally trusted collectors. Second, we investigate {{the question of how to}} securely delegate our logging protocol to a relay equipped with trusted-computing modules. ...|$|E
40|$|Recent {{advances}} in high performance distributed computing {{have led to}} the emergence of computational and data grids. The resources within a single organisation are being exposed to other users within a `virtual organisation' (VO). The VO encompasses a dynamic set of distributed resources, a distributed user base and a distributed management infrastructure. Due to this dynamic nature of VOs, {{there is a need for}} an infrastructure to facilitate the management of the constituent users and resources. We have developed an easy to use and secure management infrastructure - the Virtual Organisation Management (VOM) Portal - that provides user authentication and authorisation, resource access control and usage <b>logging</b> <b>services</b> based on existing web and grid standards...|$|E
40|$|Based on {{previous}} experience with LEP, a long-term data <b>logging</b> <b>service</b> for the LHC {{was developed and}} put in place in 2003, several years before beam operation. The scope of the <b>logging</b> <b>service</b> covers the evolution over time of data acquisitions on accelerator equipment and beam related parameters. The intention is to keep all this time-series data on-line for the lifetime of LHC, allowing easy data comparisons with previous years. The LHC hardware commissioning has used this service extensively prior to the first beams in 2008 {{and even more so}} in 2009. Current data writing rates exceed 15 TB/year and continue to increase. The high data volumes and throughput rates, in writing as well as in reading, require special arrangements on data organization and data access methods...|$|R
30|$|Logging {{events is}} {{sometimes}} useful and necessary. The Vendor Agent provides the Vendor Module with a <b>logging</b> <b>service</b> {{in order for}} the significant events to be logged {{at the level of the}} agency. There are different logging levels, in a similar way the Java language itself provide logging support.|$|R
50|$|Loggly is a {{cloud-based}} <b>log</b> management <b>service</b> provider. It {{does not require}} the use of proprietary software agents to collect <b>log</b> data. The <b>service</b> uses open source technologies, including Elasticsearch, Apache Lucene 4 and Apache Kafka.|$|R
40|$|Network {{management}} applications using mobile agents require secure {{techniques for}} the lifecycle of the mobile agent, from both mobile agent and host points of view. Based on {{the analysis of}} the security threats that may occur during the mobile agent based network management applications, this paper presents Mobile Agent Security Facility (MASF). MASF has several key features: 1) a secure mechanism for dispatching agents to given domains or network elements from secured agent repository; 2) provision of encrypted communication; 3) a safe mobile agents execution environment that enables mobile agents different resource access permissions according to the result of authentication and authorization; 4) <b>logging</b> <b>services</b> to record security relevant events. MASF architecture is further integrated and verified in a practical network management application, inter-domain IP VPN configuration...|$|E
30|$|The first Repast Simphony data {{collection}} system was built upon Log 4 J (LOG 4 J – <b>Logging</b> <b>Services).</b> Although Log 4 J {{is a widely}} used for fast, minimal overhead logging, adapting it {{to the requirements of}} Repast Simphony’s {{data collection}} functionality proved to be problematic. Log 4 J was difficult to adapt to the time-stamped and time-phased nature of Repast Simphony data collection. Log 4 J has no real user-facing mechanism for repeated initialization and termination from within a single application instance. Our incremental understanding of these requirements and adapting them to Log 4 J’s system of logging levels and logging messages resulted in code that was inflexible and hard to manage. The isolation available in the multilayered Repast Simphony logging system made it easier for the Repast development team to transition from Log 4 J to custom code while largely maintaining backward compatibility.|$|E
40|$|Well-logging plays a very {{important}} role in the petroleum industry. It is an eye of oil industry as it provides detailed geological information of drilled holes which is very cost effective. It enables quantitative estimation of hydrocarbon reserves through its openhole services. The cased hole and production <b>logging</b> <b>services</b> are of immense help during exploitation and development stages of oil/gas fields. The geophysical well logging technique has also wide applica-tions in subsurface mineral, geothermal and ground water exploration. Of late it has found application in ‘Coal-Bed Methane ’ (CBM) exploration, which has opened up new opportunities. Because if its immense importance in subsurface hydrocarbon and mineral exploration the geophysical well-logging technique has seen tremendous development in the field of instrumentation and interpretation. This has become possible due to the advancement in science and technology aided by computerisation. The present paper (teals with the initiation of well-logging technique that has seen tremen-dous development in the field of instrumentation and interpretation. It also covers the initiation of well-logging services in India and the present state-of-the-art. Its future application is briefly discussed...|$|E
40|$|The CERN {{accelerator}} <b>Logging</b> <b>Service</b> currently holds {{more than}} 90 terabytes of data online, and processes approximately 450 gigabytes per day, via hundreds of data loading processes and data extraction requests. This service is mission-critical for day-to-day operations, especially {{with respect to}} the tracking of live data from the LHC beam and equipment. In order to effectively manage any service, the service provider’s goals should include knowing how the underlying systems are being used, in terms of: “Who is doing what, from where, using which applications and methods, and how long each action takes”. Armed with such information, it is then possible to: analyse and tune system performance over time; plan for scalability ahead of time; assess the impact of maintenance operations and infrastructure upgrades; diagnose past, on-going, or re-occurring problems. The <b>Logging</b> <b>Service</b> is based on Oracle DBMS and Application Servers, and Java technology, and is comprised of several layered and multi-tiered systems. These systems have all been heavily instrumented to capture data about system usage, using technologies such as JMX. The success of the <b>Logging</b> <b>Service</b> and its proven ability to cope with ever growing demands can be directly linked to the instrumentation in place. This paper describes the instrumentation that has been developed, and demonstrates how the instrumentation data is used to achieve the goals outlined above...|$|R
5000|$|... 2006: Lexicomp {{partners}} with the American Society of Health-System Pharmacists (ASHP). Together, in 2007, Lexicomp ONLINE with AHFS is introduced. Software for BlackBerry is released. Soon after, the company logs reaches over 4 million <b>logged</b> <b>services</b> in Lexicomp ONLINE {{in just one}} month. Software for iPhone, iPad, iPod touch, and Android is later released.|$|R
30|$|SDDL’s {{extensibility}} is also {{inherited from}} DDS, {{which makes it}} quite simple to add new nodes to the SDDL core network for inclusion of new processing services. For example, {{it is possible to}} add a <b>logging</b> <b>service</b> that captures all communications on the network and saves them to a database. This service would be completely independent {{of the rest of the}} nodes.|$|R
