10000|479|Public
5|$|Today, vector {{spaces are}} applied {{throughout}} mathematics, science and engineering. They are the appropriate linear-algebraic notion {{to deal with}} systems of linear equations; offer a framework for Fourier expansion, which is employed in image compression routines; or provide an environment {{that can be used}} for solution techniques for partial differential equations. Furthermore, vector spaces furnish an abstract, coordinate-free way of dealing with geometrical and physical objects such as tensors. This in turn allows the examination of local properties of manifolds by <b>linearization</b> techniques. Vector spaces may be generalized in several ways, leading to more advanced notions in geometry and abstract algebra.|$|E
25|$|This Oracle Bone Script shows {{extensive}} simplification and <b>linearization,</b> {{which most}} researchers believe indicates an extensive period of development.|$|E
25|$|In linguistics, antisymmetry is {{a theory}} of {{syntactic}} <b>linearization</b> presented in Richard Kayne's 1994 monograph The Antisymmetry of Syntax. The crux of this theory is that hierarchical structure in natural language maps universally onto a particular surface <b>linearization,</b> namely specifier-head-complement branching order. The theory derives a version of X-bar theory. Kayne hypothesizes that all phrases whose surface order is not specifier-head-complement have undergone movements that disrupt this underlying order. Subsequently, {{there have also been}} attempts at deriving specifier-complement-head as the basic word order.|$|E
40|$|Abstract. A {{standard}} way {{of dealing}} with matrixpolynomial eigenvalue problems is to use <b>linearizations.</b> Byers, Mehrmann and Xu have recently defined and studied <b>linearizations</b> of dimensions smaller than the classical ones. In this paper, lower bounds are provided for the dimensions of <b>linearizations</b> and strong <b>linearizations</b> of a given m × n matrixpolynomial, and particular <b>linearizations</b> are constructed for which these bounds are attained. It is also proven that strong <b>linearizations</b> of an n × n regular matrixpolynomial of degree ℓ must have dimension nℓ × nℓ...|$|R
5000|$|Starting at some {{estimate}} of the optimal solution, the method is based on solving a sequence of first-order approximations (i.e. <b>linearizations)</b> of the model. The <b>linearizations</b> are linear programming problems, which can be solved efficiently. As the <b>linearizations</b> need not be bounded, trust regions or similar techniques are needed to ensure convergence in theory.|$|R
40|$|Many {{applications}} {{give rise}} to structured matrix polynomials. The problem of constructing structure-preserving strong <b>linearizations</b> of structured matrix polynomials is revisited in this work and in the forthcoming ones PartII,PartIII. With the purpose of providing a much simpler framework for structure-preserving <b>linearizations</b> for symmetric and skew-symmetric matrix polynomial than the one based on Fiedler pencils with repetition, we introduce in this work the families of (modified) symmetric and skew-symmetric block Kronecker pencils. These families provide a large arena of structure-preserving strong <b>linearizations</b> of symmetric and skew-symmetric matrix polynomials. When the matrix polynomial has degree odd, these <b>linearizations</b> are strong {{regardless of whether the}} matrix polynomial is regular or singular, and many of them {{give rise to}} structure-preserving companion forms. When some generic nonsingularity conditions are satisfied, they are also strong <b>linearizations</b> for even-degree regular matrix polynomials. Many examples of structure-preserving <b>linearizations</b> obtained from Fiedler pencils with repetitions found in the literature are shown to belong (modulo permutations) to these families of <b>linearizations.</b> In particular, this is shown to be true for the well-known block-tridiagonal symmetric and skew-symmetric companion forms. Since the families of symmetric and skew-symmetric block Kronecker pencils belong to the recently introduced set of minimal bases pencils Fiedler-like, they inherit all its desirable properties for numerical applications. In particular, it is shown that eigenvectors, minimal indices, and minimal bases of matrix polynomials are easily recovered from those of any of the <b>linearizations</b> constructed in this work...|$|R
25|$|<b>Linearization</b> is an {{emergent}} field, {{and there}} are many techniques, such as feed forward, predistortion, postdistortion, {{in order to avoid the}} undesired effects of the non-linearities.|$|E
25|$|When {{the sample}} {{is not a simple}} random sample from a large population, the {{standard}} error and the confidence interval must be estimated through more advanced calculations. <b>Linearization</b> and resampling are widely used techniques for data from complex sample designs.|$|E
25|$|Asymmetric c-command is the {{relation}} that holds between two categories, A and B, if A c-commands B but B does not c-command A. This relationship is a primitive in Kayne's theory of <b>linearization,</b> {{the process that}} converts a tree structure into a flat (structureless) string of terminal nodes.|$|E
40|$|AbstractWe {{discuss the}} {{eigenvalue}} problem for general and structured matrix polynomials {{which may be}} singular and may have eigenvalues at infinity. We derive condensed forms that allow (partial) deflation of the infinite eigenvalue and singular structure of the matrix polynomial. The remaining reduced order staircase form leads to new types of <b>linearizations</b> which determine the finite eigenvalues and corresponding eigenvectors. The new <b>linearizations</b> also simplify the construction of structure preserving <b>linearizations...</b>|$|R
40|$|International audienceWe {{consider}} {{the problem of}} rewriting queries based exclusively on views. Both queries and views can contain aggregate functions and include arithmetic comparisons. To study the equivalence of a query with its rewriting query, the so called "linearizations of a query" need to be computed. To find the <b>linearizations</b> of a query, the <b>linearizations</b> of terms from the query need to be generated. We propose an algorithm to find these term <b>linearizations</b> and give a bound for its time-complexity...|$|R
40|$|Dedicated to Richard S. Varga on the {{occasion}} of his 80 th birthday. We discuss the eigenvalue problem for general and structured matrix polynomials which may be singular and may have eigenvalues at infinity. We derive condensed forms that allow (partial) deflation of the infinite eigenvalue and singular structure of the matrix polynomial. The remaining reduced order staircase form leads to new types of <b>linearizations</b> which determine the finite eigenvalues and corresponding eigenvectors. The new <b>linearizations</b> also simplify the construction of structure preserving <b>linearizations...</b>|$|R
25|$|Root-finding {{algorithms}} {{are used}} to solve nonlinear equations (they are so named since a root of a function is an argument for which the function yields zero). If the function is differentiable and the derivative is known, then Newton's method is a popular choice. <b>Linearization</b> is another technique for solving nonlinear equations.|$|E
25|$|It is {{possible}} that Debye–Hückel equation {{is not able to}} foresee this behavior because of the <b>linearization</b> of the Poisson–Boltzmann equation, or maybe not: studies about this have been started only during the last years of the 20th century because before it wasn’t possible to investigate the 10−4 M region, so it {{is possible}} that during the next years new theories will be born.|$|E
25|$|In mathematics, {{the theory}} of linear systems is the basis and a {{fundamental}} part of linear algebra, a subject which is used {{in most parts of}} modern mathematics. Computational algorithms for finding the solutions {{are an important part of}} numerical linear algebra, and play a prominent role in engineering, physics, chemistry, computer science, and economics. A system of non-linear equations can often be approximated by a linear system (see <b>linearization),</b> a helpful technique when making a mathematical model or computer simulation of a relatively complex system.|$|E
40|$|We {{consider}} {{the problem of}} moving the system state between different equilibrium points. For systems whose <b>linearizations</b> are exponentially stable along a curve connecting the given points we show that the transfer can be achieved in finite time. The result can be extended to systems whose <b>linearizations</b> are stabilizable...|$|R
40|$|AbstractThe {{connections}} between <b>linearizations</b> of regular matrix polynomials L(λ) under shift and inversion of the parameter are developed {{and used to}} obtain a new formula for the realization of L(λ) − 1. In the self-adjoint case nondegenerate indefinite scalar products are obtained in which the fundamental (companion) <b>linearizations</b> are self-adjoint...|$|R
40|$|Given a {{quadratic}} two-parameter matrix polynomial Q, {{we develop}} a systematic approach to generating a vector space of linear two-parameter matrix polynomials. We identify {{a set of}} <b>linearizations</b> of Q that lie in the vector space. Finally, we determine a class of <b>linearizations</b> for a quadratic two- parameter eigenvalue problem. Comment: 15 page...|$|R
25|$|The {{nonlinearity}} of the EFE makes finding exact solutions difficult. One way {{of solving}} the field equations is to make an approximation, namely, that far from the source(s) of gravitating matter, the gravitational field is very weak and the spacetime approximates that of Minkowski space. The metric is then written as {{the sum of the}} Minkowski metric and a term representing the deviation of the true metric from the Minkowski metric, with terms that are quadratic in or higher powers of the deviation being ignored. This <b>linearization</b> procedure can be used to investigate the phenomena of gravitational radiation.|$|E
25|$|Western Zhou dynasty {{characters}} (as {{exemplified by}} bronze inscriptions of that time) basically continue from the Shang writing system; that is, early W. Zhou forms resemble Shang bronze forms (both such as clan names, and typical writing), without any clear or sudden distinction. They are, like their Shang predecessors in all media, often irregular {{in shape and}} size, and the structures and details often vary from one piece of writing to the next, and even within the same piece. Although most are not pictographs in function, the early Western Zhou bronze inscriptions {{have been described as}} more pictographic in flavor than those of subsequent periods. During the Western Zhou, many graphs begin to show signs of simplification and <b>linearization</b> (the changing of rounded elements into squared ones, solid elements into short line segments, and thick, variable-width lines into thin ones of uniform width), with the result being a decrease in pictographic quality, as depicted in the chart below.|$|E
25|$|In {{a series}} of papers with several authors, Atiyah {{classified}} all instantons on 4-dimensional Euclidean space. It is more convenient to classify instantons on a sphere as this is compact, and this is essentially equivalent to classifying instantons on Euclidean space as this is conformally equivalent to a sphere and the equations for instantons are conformally invariant. With Hitchin and Singer he calculated the dimension of the moduli space of irreducible self-dual connections (instantons) for any principal bundle over a compact 4-dimensional Riemannian manifold (the Atiyah–Hitchin–Singer theorem). For example, the dimension of the space of SU2 instantons of rank k>0 is 8k−3. To do this they used the Atiyah–Singer index theorem to calculate the dimension of the tangent space of the moduli space at a point; the tangent space is essentially the space of solutions of an elliptic differential operator, given by the <b>linearization</b> of the non-linear Yang–Mills equations. These moduli spaces were later used by Donaldson to construct his invariants of 4-manifolds.|$|E
40|$|In this paper, we obtain {{formulas}} for {{the left}} and right eigenvectors and minimal bases of some families of Fiedler-like <b>linearizations</b> of square matrix polynomials. In particular, for the families of Fiedler pencils, generalized Fiedler pencils and Fiedler pencils with repetition. These formulas allow us to relate the eigenvectors and minimal bases of the <b>linearizations</b> with the ones of the polynomial. Since the eigenvectors appear in the standard formula of the condition number of eigenvalues of matrix polynomials, our results may be used to compare the condition numbers of eigenvalues of the <b>linearizations</b> within these families and the corresponding condition number of the polynomial eigenvalue problem. Publicad...|$|R
40|$|In {{the last}} decade, {{there has been}} a {{continued}} effort to produce families of strong <b>linearizations</b> of a matrix polynomial P(λ), regular and singular, with good properties. As a consequence of this research, families such as the family of Fiedler pencils, the family of generalized Fiedler pencils (GFP), the family of Fiedler pencils with repetition, and the family of generalized Fiedler pencils with repetition (GFPR) were constructed. In particular, one of the goals was to find in these families structured <b>linearizations</b> of structured matrix polynomials. For example, if a matrix polynomial P(λ) is symmetric (Hermitian), it is convenient to use <b>linearizations</b> of P(λ) that are also symmetric (Hermitian). Both the family of GFP and the family of GFPR contain block-symmetric <b>linearizations</b> of P(λ), which are symmetric (Hermitian) when P(λ) is. Now the objective is to determine which of those structured <b>linearizations</b> have the best numerical properties. The main obstacle for this study is the fact that these pencils are defined implicitly as products of so-called elementary matrices. In this paper we consider the family of block-minimal bases pencils, whose pencils are defined in terms of their block-structure, as a source of canonical forms for block-symmetric pencils. More precisely, we present four families of block-symmetric pencils which, under some generic nonsingularity conditions are block minimal bases pencils and strong <b>linearizations</b> of a matrix polynomial. We show that the block-symmetric GFP and GFPR, after some row and column permutations, belong to the union of these four families. Hence, these four families of pencils provide an alternative but explicit approach to the block-symmetric Fiedler-like pencils existing in the literature...|$|R
40|$|Consider the algebra M(n,F) of n x n {{matrices}} over {{an infinite}} field F of arbitrary characteristic. An identity for M(n,F) with forms {{is such a}} polynomial in n x n generic matrices and in σ_k(x), 0 n he introduced partial <b>linearizations</b> of σ_t and proved that they together with the well-known free relations and the Cayley [...] Hamilton polynomial generate T(n) as a T-ideal. We show that {{it is enough to}} take partial <b>linearizations</b> of σ_t for n<t≤ 2 n. In particular, the T-ideal T(n) is finitely based. Working over a field of characteristic different from two, we obtain a similar result for the ideal of identities with forms for the F-algebra generated by n x n generic and transpose generic matrices. These results imply that ideals of identities for the algebras of matrix GL(n) - and O(n) -invariants are generated by the well-known free relations together with partial <b>linearizations</b> of σ_t for n<t≤ 2 n and partial <b>linearizations</b> of σ_t,r for n<t+ 2 r≤ 2 n, respectively. Comment: 29 page...|$|R
25|$|Sodium dodecyl sulfate (SDS) (C12H25NaO4S; mW: 288.38) (only used in {{denaturing}} protein gels) is {{a strong}} detergent agent used to denature native proteins to individual polypeptides. This denaturation, which {{is referred to as}} reconstructive denaturation, is not accomplished by the total <b>linearization</b> of the protein, but instead, through a conformational change to a combination of random coil and α helix secondary structures. When a protein mixture is heated to 100°C in presence of SDS, the detergent wraps around the polypeptide backbone. It binds to polypeptides in a constant weight ratio of 1.4 g SDS/g of polypeptide. In this process, the intrinsic charges of polypeptides become negligible when compared to the negative charges contributed by SDS. Thus polypeptides after treatment become rod-like structures possessing a uniform charge density, that is same net negative charge per unit weight. The electrophoretic mobilities of these proteins is a linear function of the logarithms of their molecular weights. Without SDS, different proteins with similar molecular weights would migrate differently due to differences in mass-charge ratio, as each protein has an isoelectric point and molecular weight particular to its primary structure. This is known as native PAGE. Adding SDS solves this problem, as it binds to and unfolds the protein, giving a near uniform negative charge {{along the length of the}} polypeptide.|$|E
500|$|The {{tangent plane}} to a surface {{at a point}} is {{naturally}} a vector space whose origin is identified with the point of contact. [...] The tangent plane is the best linear approximation, or <b>linearization,</b> of a surface at a point. on the surface to the plane is infinitesimally small compared to the distance from P1 to P in the limit as P1 approaches P along the surface. Even in a three-dimensional Euclidean space, there is typically no natural way to prescribe a basis of the tangent plane, {{and so it is}} conceived of as an abstract vector space rather than a real coordinate space. The tangent space is the generalization to higher-dimensional differentiable manifolds.|$|E
2500|$|The [...] {{equation}} {{does not}} depend on , and <b>linearization</b> near its equilibrium position [...] shows that [...] decays exponentially to its equilibrium ...|$|E
40|$|We {{describe}} two simple {{methods for}} the evaluation of the exponential and logarithmic mappings and their 1 rst and second <b>linearizations</b> based on the Taylor expansion and the spectral representation. We also provide guidelines for switching between those representations {{on the basis of the}} size of the argument. The 1 rst and second <b>linearizations</b> of the exponential and logarithmic mappings provided here are based directly on the exponential formula for the solutions of systems of linear ordinary di;erential equations. This representation does not require the use of perturbation formulae for eigenvalues and eigenvectors. Our approach leads to workable and straightforward expressions for the 1 rst and second <b>linearizations</b> of the exponential and logarithmic mappings regardless of degeneracies in the spectra...|$|R
25|$|In {{cases where}} the models are nonlinear, {{step-wise}} <b>linearizations</b> may be within the minimum-variance filter and smoother recursions (extended Kalman filtering).|$|R
40|$|Current data {{structures}} for searching large string collections either fail to achieve minimum space or cause too many cache misses. In this {{paper we discuss}} some edge <b>linearizations</b> of the classic trie data structure that are simultaneously cache-friendly and compressed. We provide new insights on front coding [24], introduce other novel <b>linearizations,</b> and study how close their space occupancy is to the information-theoretic minimum. The moral is that they are not just heuristics. Our second contribution is a novel dictionary encoding scheme that builds upon such <b>linearizations</b> and achieves nearly optimal space, offers competitive I/O-search time, and is also conscious of the query distribution. Finally, we combine those data structures with cacheoblivious tries [2, 5] and obtain a succinct variant whose space is close to the information-theoretic minimum...|$|R
2500|$|Applying <b>linearization</b> {{techniques}} to {{the equation of}} motions for both species, to the equation of continuity, and Poisson's equation, and introducing the spatial and temporal harmonic operators , [...] {{we can get the}} following expression: ...|$|E
2500|$|Processes in {{industries}} like robotics and {{the aerospace industry}} typically have strong nonlinear dynamics. In control theory it is sometimes possible to linearize such classes of systems and apply linear techniques, {{but in many cases}} it can be necessary to devise from scratch theories permitting control of nonlinear systems. These, e.g., feedback <b>linearization,</b> backstepping, sliding mode control, trajectory <b>linearization</b> control normally take advantage of results based on Lyapunov's theory. Differential geometry has been widely used as a tool for generalizing well-known linear control concepts to the non-linear case, as well as showing the subtleties that make it a more challenging problem. [...] Control theory has also been used to decipher the neural mechanism that directs cognitive states.|$|E
2500|$|ICD-11 invokes a more {{sophisticated}} architecture than historical versions, consistent with its generation as a digital resource. [...] The core content of the system, called the Foundation Component, is a semantic network of words and terms, where any given term can {{have more than one}} parent. [...] To address the requirement that statistical classifications exhibit mutual exclusiveness (so events are not counted more than once) and exhaustiveness (so there is a place to tally all events), ICD11 supports the serialization of the Foundation Component into an arbitrary number of linearizations, optimized for use cases. [...] The main <b>linearization,</b> presently called the Joint <b>Linearization</b> for Morbidity and Mortality Statistics, is the tabular format with which most traditional users will become familiar. However, other linearizations, for primary care, multiple sub-specialty derivatives, or applications such as clinical decision support are possible. [...] Finally, preliminary work in partnership with the IHTSDO is underway to ensure that the ICD-11 Foundation Component is semantically coherent through development of the Common Ontology, a subset of SNOMED CT which will anchor the Foundation Component to terms defined through description logic.|$|E
40|$|Fiedler pencils are {{a family}} of strong <b>linearizations</b> for polynomials {{expressed}} in the monomial basis, that include the classical Frobenius companion pencils as special cases. We generalize {{the definition of a}} Fiedler pencil from monomials to a larger class of orthogonal polynomial bases. In particular, we derive comrade-Fiedler pencils for two bases that are extremely important in practical applications: the Chebyshev polynomials of the first and second kind. The new approach allows one to construct <b>linearizations</b> having limited bandwidth: a Chebyshev analogue of the pentadiagonal Fiedler pencils in the monomial basis. Moreover, our theory allows for <b>linearizations</b> of square matrix polynomials expressed in the Chebyshev basis (and in other bases), regardless of whether the matrix polynomial is regular or singular, and for recovery formulae for eigenvectors, and minimal indices and bases...|$|R
40|$|Many {{applications}} {{give rise}} to nonlinear eigenvalue problems with an underlying structured matrix polynomial. In this paper several useful classes of structured polynomial (e. g., palindromic, even, odd) are identified and the relationships between them explored. A special class of <b>linearizations</b> that reflect the structure of these polynomials, and therefore preserve symmetries in their spectra, is introduced and investigated. We analyze the existence and uniqueness of such <b>linearizations,</b> and show how they may be systematically constructed...|$|R
40|$|This paper {{concerns}} regular matrix polynomials P (λ) when {{represented in}} various polynomial bases (other than the monomials 1, λ, λ², [...] .). As in the monomial case, matrices of “companion ” form {{play an important}} part in theory and numerical practice. In particular, they are used here to construct “strong <b>linearizations</b> ” of P (λ). The paper contains three theorems concerning <b>linearizations</b> constructed for representations in (a) a general class of “degree graded ” polynomials, (b) Bernstein polynomials, (c) Lagrange polynomials...|$|R
