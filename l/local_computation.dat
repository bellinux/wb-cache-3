435|624|Public
25|$|Duck typing {{differs from}} {{structural}} typing in that, if the part (of the whole module structure) {{needed for a}} given <b>local</b> <b>computation</b> is present at runtime, the duck type system is satisfied in its type identity analysis. On the other hand, a structural type system would require {{the analysis of the}} whole module structure at compile time to determine type identity or type dependence.|$|E
25|$|In the {{analysis}} of distributed algorithms, more attention is usually paid on communication operations than computational steps. Perhaps the simplest model of distributed computing is a synchronous system where all nodes operate in a lockstep fashion. During each communication round, all nodes in parallel (1)receive the latest messages from their neighbours, (2)perform arbitrary <b>local</b> <b>computation,</b> and (3)send new messages to their neighbors. In such systems, a central complexity measure {{is the number of}} synchronous communication rounds required to complete the task.|$|E
500|$|One {{reason to}} study {{reversible}} universal models of computation {{such as the}} billiard-ball model is that they could theoretically lead to actual computer systems that consume very low quantities of energy. According to Landauer's principle, irreversible computational steps require a certain minimal amount of energy per step, but reversible steps can be performed with an amount of energy per step that is arbitrarily close to zero. However, in order to perform computation using less energy than Landauer's bound, {{it is not good}} enough for a cellular automaton to have a transition function that is globally reversible: what is required is that the <b>local</b> <b>computation</b> of the transition function also be done in a reversible way. For instance, reversible block cellular automata are always locally reversible: the behavior of each individual block involves the application of an invertible function with finitely many inputs and outputs. [...] were the first to ask whether every reversible cellular automaton has a locally reversible update rule. [...] showed that for one- and two-dimensional automata the answer is positive, and [...] showed that any reversible cellular automaton could be simulated by a (possibly different) locally reversible cellular automaton. However, the question of whether every reversible transition function is locally reversible remains open for dimensions higher than two.|$|E
40|$|AbstractThis {{paper is}} a {{contribution}} to understanding the power and the limitations of <b>local</b> <b>computations</b> in graphs. We use <b>local</b> <b>computations</b> to define a notion of graph recognition; our model allows a simulation of automata on words and on trees. We introduce the notion of k-covering to examine limitations of such systems. For example, we prove that the family of series-parallel graphs and the family of planar graphs cannot be recognized by means of <b>local</b> <b>computations...</b>|$|R
40|$|This paper {{presents}} a framework which enables to implement automatically distributed algorithms, encoded {{by means of}} <b>local</b> <b>computations,</b> into an asynchronous system with asynchronous message passing. We illustrate the dierent aspects of this implementation using various classical distributed algorithms. We give in Annex some properties about <b>local</b> <b>computations...</b>|$|R
5000|$|<b>Local</b> <b>computations</b> (i.e. {{swimming}} {{is composed}} of distinct components) ...|$|R
5000|$|... {{yielding}} [...] Item 3. {{follows from}} the fact the blowdown map Ï€ is an isomorphism away from the center [...] The last two items are seen from explicit <b>local</b> <b>computation.</b>|$|E
5000|$|Valuation algebras : Dropping the idempotency axiom {{leads to}} {{valuation}} algebras. These axioms {{have been introduced}} by [...] to generalize <b>local</b> <b>computation</b> schemes [...] from Bayesian networks to more general formalisms, including belief function, possibility potentials, etc[...] For a book-length exposition on the topic see [...]|$|E
50|$|Parallel Basic Linear Algebra Subprograms (PBLAS) is an {{implementation}} of Level 2 and 3 BLAS intended for distributed memory architectures. It provides a computational backbone for ScaLAPACK, a parallel {{implementation of}} LAPACK. It depends on Level 1 sequential BLAS operations for <b>local</b> <b>computation</b> and BLACS for communication between nodes.|$|E
30|$|The actual {{energy system}} benefits, however, {{come from the}} <b>local</b> <b>computations,</b> that take place all over on the {{connected}} entities of the smart grid. While smart grids have been studied for many years already and in the existing energy network systems there naturally already exists various kinds of intelligent decentralized computations on the grid nodes, here, in this paper and context, with the <b>local</b> <b>computations</b> we refer to the possibilities of third-party companies to execute their software where it {{makes the most sense}} {{from the point of view}} the benefits discussed already in this paper. The <b>local</b> <b>computations</b> enable virtualization of many services, like the virtual power plants for example.|$|R
3000|$|Open {{image in}} new window when denotations {{will not give}} rise to ambiguities). By <b>local</b> <b>computations,</b> we can verify that [...]...|$|R
40|$|Panagiota Fatourou Marios Mavronicolas y Paul Spirakis z Abstract Recent {{theoretical}} {{advances in}} rate-based, flow control [1, 9] accumulate in algorithms {{that work in}} a sequence of atomically executed abstract operations, adjusting the rates of sessions. However, besides having to rely on available atomicity, these algorithms mask "lowlevel " implementation details, while they incur non-trivial, <b>local</b> <b>computations</b> at network switches. In negligence of such <b>local</b> <b>computations,</b> these algorithms have been evaluated on an abstract level, and shown particularly efficient, in terms of convergence complexity, {{the maximum number of}} executed abstract operations till some kind of "fairness" is reached. In this work, we attempt to bridge the "gap" between the theoretical evaluation of ratebased, flow control algorithms, and a more realistic assessment of the global efficiency of their asynchronous, truly distributed implementations. We explore the precise impact of <b>local</b> <b>computations</b> on [...] ...|$|R
5000|$|If one of {{the players}} is honest (i.e., the other player may deviate {{arbitrarily}} from the protocol in his or her <b>local</b> <b>computation),</b> then the other party wins with probability at most [...] In other words, if B is dishonest, then , and if A is dishonest, then [...]|$|E
5000|$|The {{cost of a}} superstep is {{determined}} as the sum of three terms; {{the cost of the}} longest running <b>local</b> <b>computation,</b> the cost of global communication between the processors, and the cost of the barrier synchronisation {{at the end of the}} superstep. The cost of one superstepfor [...] processors: ...|$|E
50|$|Duck typing {{differs from}} {{structural}} typing in that, if the part (of the whole module structure) {{needed for a}} given <b>local</b> <b>computation</b> is present at runtime, the duck type system is satisfied in its type identity analysis. On the other hand, a structural type system would require {{the analysis of the}} whole module structure at compile time to determine type identity or type dependence.|$|E
40|$|International audienceThis paper {{investigates the}} power of <b>local</b> <b>computations</b> on graphs, by {{considering}} a classical problem in distributed algorithms, the recognition problem. Formally, we want to compute some topological information on a network of processes, possibly using additional knowledge about {{the structure of the}} underlying graph. We propose the notion of recognition with structural knowledge by means of <b>local</b> <b>computations.</b> Then we characterize the graph classes that are recognizable with or without structural knowledge. The characterizations are using graph coverings and a distributed enumeration algorithm proposed by A. Mazurkiewicz. Several applications are presented, in particular concerning minor-closed classes of graphs...|$|R
30|$|Once {{locality}} {{has been}} established, these algorithms exploit it with decentralized mechanisms that {{are able to}} provide global services (multicast) or answers (e.g., the k most similar items to a query) from lightweight <b>local</b> <b>computations.</b>|$|R
40|$|A {{synchronizer}} {{is intended}} to allow synchronous algorithms to be executed on asynchronous networks. It is useful because desiging synchronous algorithms are generally much easier than desining asynchronous ones. In this paper, we provide synchronization protocols described as <b>local</b> <b>computations.</b> The proofs of these protocols and their use to simulate synchronous algorithms make use of their high level encoding in form of rewriting rules. We obtain a general and a unied approach for handling synchrony {{in the framework of}} <b>local</b> <b>computations.</b> All the algorithms discussed in this paper have been implemented and tested in the Visidia plateform, yielding a layer to implement synchronous algorithms...|$|R
5000|$|... where [...] is {{the cost}} for the <b>local</b> <b>computation</b> in process , and [...] {{is the number of}} {{messages}} sent or received by process [...] Note that homogeneous processors are assumed here. It is more common for the expression to be written as [...] where [...] and [...] are maxima. The cost of the algorithm then, is the sum of the costs of each superstep.|$|E
50|$|In the {{analysis}} of distributed algorithms, more attention is usually paid on communication operations than computational steps. Perhaps the simplest model of distributed computing is a synchronous system where all nodes operate in a lockstep fashion. During each communication round, all nodes in parallel (1) receive the latest messages from their neighbours, (2) perform arbitrary <b>local</b> <b>computation,</b> and (3) send new messages to their neighbors. In such systems, a central complexity measure {{is the number of}} synchronous communication rounds required to complete the task.|$|E
5000|$|One {{reason to}} study {{reversible}} universal models of computation {{such as the}} billiard-ball model is that they could theoretically lead to actual computer systems that consume very low quantities of energy. According to Landauer's principle, irreversible computational steps require a certain minimal amount of energy per step, but reversible steps can be performed with an amount of energy per step that is arbitrarily close to zero. However, in order to perform computation using less energy than Landauer's bound, {{it is not good}} enough for a cellular automaton to have a transition function that is globally reversible: what is required is that the <b>local</b> <b>computation</b> of the transition function also be done in a reversible way. For instance, reversible block cellular automata are always locally reversible: the behavior of each individual block involves the application of an invertible function with finitely many inputs and outputs. [...] were the first to ask whether every reversible cellular automaton has a locally reversible update rule. [...] showed that for one- and two-dimensional automata the answer is positive, and [...] showed that any reversible cellular automaton could be simulated by a (possibly different) locally reversible cellular automaton. However, the question of whether every reversible transition function is locally reversible remains open for dimensions higher than two.|$|E
30|$|Seed <b>local</b> {{community}} <b>computation.</b>|$|R
40|$|International audienceThe {{different}} <b>local</b> <b>computations</b> {{mechanisms are}} very useful for delimiting the bordeline between {{positive and negative}} results in distributed computations. Indeed, they enable to study {{the importance of the}} synchronization level and to understand how important is the initial knowledg...|$|R
5000|$|Concurrent computation: every {{participating}} processor may perform <b>local</b> <b>computations,</b> i.e., {{each process}} {{can only make}} use of values stored in the local fast memory of the processor. The computations occur asynchronously of all the others but may overlap with communication.|$|R
50|$|Both SPBV and SPBM {{inherit the}} rapid {{convergence}} of a link state control plane. A special attribute of SPBM {{is its ability}} to rebuild multicast trees in a similar time to unicast convergence, because it substitutes computation for signaling. When an SPBM bridge has performed the computations on a topology database, it knows whether it is on the shortest path between a root and one or more leaves of the SPT and can install state accordingly. Convergence is not gated by incremental discovery of a bridgeâ€™s place on a multicast tree by the use of separate signaling transactions. However, SPBM on a node does not operate completely independently of its peers, and enforces agreement on the current network topology with its peers. This very efficient mechanism uses exchange of a single digest of link state covering the entire network view, and does not need agreement on each path to each root individually. The result is that the volume of messaging exchanged to converge the network is in proportion to the incremental change in topology and not the number of multicast trees in the network. A simple link event that may change many trees is communicated by signaling the link event only; the consequent tree construction is performed by <b>local</b> <b>computation</b> at each node. The addition of a single service access point to a service instance involves only the announcement of the I-SID, regardless of the number of trees. Similarly the removal of a bridge, which might involve the rebuilding of hundreds to thousands of trees, is signaled only with a few link state updates.|$|E
40|$|Abstract. The {{goal of this}} {{contribution}} is to discuss <b>local</b> <b>computation</b> in credal networks â€” graphical models that can represent imprecise and indeterminate probability values. We analyze the inference problem in credal networks, discuss how inference algorithms can benefit from <b>local</b> <b>computation,</b> and suggest that <b>local</b> <b>computation</b> can be particularly important in approximate inference algorithms. ...|$|E
40|$|Recently Rubinfeld et al. (ICS 2011, pp. 223 â€“ 238) {{proposed}} {{a new model}} of sublinear algorithms called <b>local</b> <b>computation</b> algorithms. In this model, a computation problem F may have more than one legal solution and each of them consists of many bits. The <b>local</b> <b>computation</b> algorithm for F should answer in an online fashion, for any index i, the i th bit of some legal solution of F. Further, all the answers given by the algorithm should be consistent with at least one solution of F. In this work, we continue the study of <b>local</b> <b>computation</b> algorithms. In particular, we develop a technique which under certain conditions can be applied to construct <b>local</b> <b>computation</b> algorithms that run not only in polylogarithmic time but also in polylogarithmic space. Moreover, these <b>local</b> <b>computation</b> algorithms are easily parallelizable and can answer all parallel queries consistently. Our main technical tools are pseudorandom numbers with bounded independence and the theory of branching processes...|$|E
40|$|A complete, subformula-preserving proof {{system for}} {{goal-driven}} reasoning in first-order logic is pre-sented. The proof {{system is a}} transition system and its proofs are (linear and <b>local)</b> <b>computations</b> in the transistion system. Thus the proof system fits into a standard framework for modeling problem-solving in cognitive psychology...|$|R
30|$|We {{used the}} ECL {{language}} {{to implement the}} main DataFlow in the L-BFGS algorithm. We also implemented in-line C++ functions as required to perform some <b>local</b> <b>computations.</b> We used the HPCC Systems platform without adding any new framework {{on top of it}} or modifying any underlying platform configuration.|$|R
40|$|AMiRALE (Asynchronous Missions Relay for Autonomous and Lively Entities) is {{a service}} {{discovery}} and collaboration mechanism dedicated to autonomous swarms of highly mobile and heterogeneous nodes. AMiRALE is only based on asynchronous communications and <b>local</b> <b>computations.</b> This report details the internal operations of AMiRALE based on dynamic graph relabeling...|$|R
40|$|Abstract. Valuation algebras are the {{foundation}} of a widespread theory unifying different fields of modern research and culminating in the power of <b>local</b> <b>computation.</b> Although this theory rejoys in great interest from a pure theoretical perspective, many questions were originally motivated by practical experiences. The aim {{of this paper is to}} return to this practical starting point by illustrating how these results can be used to design generic software for <b>local</b> <b>computation.</b> Thereby, the novelty consists in passing the high level of abstraction given by the mathematical theory to the implementation itself. Different architectures of <b>local</b> <b>computation</b> are realized independently to valuation algebra instances and join tree construction, which leads to a modular construction system inspired software project, available for anyone being interested in <b>local</b> <b>computation.</b> ...|$|E
40|$|We give an axiomatization of {{confidence}} transfer - a known conditioning scheme - {{from the perspective}} of expectation-based inference in the sense of Gardenfors and Makinson. Then, we use the notion of belief independence to "filter out" different proposal s of possibilistic conditioning rules, all are variations {{of confidence}} transfer. Among the three rules that we consider, only Dempster's rule of conditioning passes the test of supporting the notion of belief independence. With the use of this conditioning rule, we then show that we can use <b>local</b> <b>computation</b> for computing desired conditional marginal possibilities of the joint possibility satisfying the given constraints. It turns out that our <b>local</b> <b>computation</b> scheme is already proposed by Shenoy. However, our intuitions are completely different from that of Shenoy. While Shenoy just defines a <b>local</b> <b>computation</b> scheme that fits his framework of valuation-based systems, we derive that <b>local</b> <b>computation</b> scheme from II(, 8) = tI(, 8 I a) * II(a) and appropriate independence assumptions, just like how the Bayesians derive their <b>local</b> <b>computation</b> scheme. Comment: Appears in Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI 1994...|$|E
40|$|Abstract. From {{the very}} first beginning, <b>local</b> <b>computation</b> {{algorithms}} were considered as distributed algorithms wherein (virtual) processors exchange messages to solve a common computational task. Thereby, the efficiency of <b>local</b> <b>computation</b> is particularly pointed out, whenever {{the complexity of the}} underlying valuation algebra operations manifests an exponential complexity. This behavior is often related {{to the size of the}} involved messages and therefore, minimization of communication costs in <b>local</b> <b>computation</b> becomes an important issue. This paper measures these costs by use of a generic weight function and shows concretely, under which condition these costs can be minimized. Furthermore, we present an efficient algorithm for the appropriate minimization problem. ...|$|E
40|$|Most {{algorithms}} {{for these}} classes were originally developed for a single-agent What kinds of algorithms {{would be useful}} for cooperative problem solving by multiple agents? A search problem can be represented by using a graph. Some problems can be solved by accumulating <b>local</b> <b>computations</b> for each node in the graph...|$|R
40|$|Rapport de Recherche RR- 1466 - 09 LaBRIContrary to the {{sequential}} world, {{the processes}} involved in a distributed system do not necessarily know when a computation is globally finished. This paper investigates {{the problem of the}} detection of the termination of <b>local</b> <b>computations.</b> We define four types of termination detection: no detection, detection of the local termination, detection by a distributed observer, detection of the global termination. We give a complete characterisation (except in the local termination detection case where a partial one is given) for each of this termination detection and show that they define a strict hierarchy. These results emphasise the difference between computability of a distributed task and termination detection. Furthermore, these characterisations encompass all standard criteria that are usually formulated : topological restriction (tree, rings, or triangu- lated networks [...] .), topological knowledge (size, diameter [...] .), and local knowledge to distinguish nodes (identities, sense of direction). These results are now presented as corollaries of generalising theorems. As a very special and important case, the techniques are also applied to the election problem. Though given in the model of <b>local</b> <b>computations,</b> these results can give qualitative insight for similar results in other standard models. The necessary conditions involve graphs covering and quasi-covering; the sufficient conditions (constructive <b>local</b> <b>computations)</b> are based upon an enumeration algorithm of Mazurkiewicz and a stable properties detection algorithm of Szymanski, Shi and Prywes...|$|R
40|$|Contrary to the {{sequential}} world, {{the processes}} involved in a distributed system do not necessarily know when a computation is globally finished. This paper investigates {{the problem of the}} detection of the termination of <b>local</b> <b>computations.</b> We define four types of termination detection: no detection, detection of the local termination, detection by a distributed observer, detection of the global termination. We give a complete characterisation (except in the local termination detection case where a partial one is given) for each of this termination detection and show that they define a strict hierarchy. These results emphasise the difference between computability of a distributed task and termination detection. Furthermore, these characterisations encompass all standard criteria that are usually formulated : topological restriction (tree, rings, or triangu- lated networks [...] .), topological knowledge (size, diameter [...] .), and local knowledge to distinguish nodes (identities, sense of direction). These results are now presented as corollaries of generalising theorems. As a very special and important case, the techniques are also applied to the election problem. Though given in the model of <b>local</b> <b>computations,</b> these results can give qualitative insight for similar results in other standard models. The necessary conditions involve graphs covering and quasi-covering; the sufficient conditions (constructive <b>local</b> <b>computations)</b> are based upon an enumeration algorithm of Mazurkiewicz and a stable properties detection algorithm of Szymanski, Shi and Prywes...|$|R
