508|148|Public
25|$|Shadows on the Moon are {{complicated}} by reflected light, uneven ground, wide-angle <b>lens</b> <b>distortion,</b> and lunar dust. There are several light sources: the Sun, sunlight reflected from the Earth, sunlight reflected from the Moon's surface, and sunlight reflected from the astronauts and the Lunar Module. Light from these sources is scattered by lunar dust in many directions, including into shadows. Shadows falling into craters and hills may appear longer, shorter and distorted. Furthermore, shadows display {{the properties of}} vanishing point perspective, leading them to converge to a point on the horizon.|$|E
2500|$|Inoue, A., K. Yamamoto, N. Mizoue and Y. Kawahara. [...] 2004. [...] Calibrating {{view angle}} and <b>lens</b> <b>distortion</b> of the Nikon {{fish-eye}} converter FC-E8. [...] Journal of Forest Research 9:177-181.|$|E
5000|$|The GIMP {{includes}} manual <b>lens</b> <b>distortion</b> correction (from version 2.4).|$|E
5000|$|LensFun {{library to}} {{automatically}} fix various <b>lens</b> <b>distortions.</b>|$|R
40|$|Geometric image {{registration}} by estimating homographies {{is an important}} processing step {{in a wide variety}} of computer vision applications. The 2 D registration of two images does not require an explicit reconstruction of intrinsic or extrinsic camera parameters. However, correcting images for non-linear <b>lens</b> <b>distortions</b> is highly recommended. Unfortunately, standard calibration techniques are sometimes difficult to apply and reliable estimations of <b>lens</b> <b>distortions</b> can only rarely be obtained. In this paper we present a new technique for automatically detecting and categorising <b>lens</b> <b>distortions</b> in pairs of images by analysing registration results. The approach is based on a new metric for registration quality assessment and facilitates a PCA-based statistical model for classifying distortion effects. In doing so the overall importance for lens calibration and image corrections can be checked, and a measure for the efficiency of accordant correction steps is given...|$|R
40|$|Cornelis K., Pollefeys M., Van Gool L., ''Lens {{distortion}} {{recovery for}} accurate sequential structure and motion recovery'', Lecture notes in computer science, vol. 2351, pp. 186 - 200, 2002 (Proceedings 7 th European conference on computer vision - ECCV 2002, part II, May 28 - 31, 2002, Copenhagen, Denmark). Lens distortions in off-the-shelf or wide-angle cameras block {{the road to}} high accuracy Structure and Motion Recovery (SMR) from video sequences. Neglecting <b>lens</b> <b>distortions</b> introduces a systematic error buildup which causes recovered structure and motion to bend and inhibits turntable or other loop sequences to close perfectly. Locking back onto previously reconstructed structure can become impossible due to the large drift caused by the error buildup. Bundle adjustments are widely used to perform an ultimate post-minimization of the total reprojection error. However, the initial recovered structure and motion needs {{to be close to}} optimal to avoid local minima. We found that bundle adjustments cannot remedy the error buildup caused by ignoring <b>lens</b> <b>distortions.</b> The classical approach to distortion removal involves a preliminary distortion estimation using a calibration pattern, known geometric properties of perspective projections or only 2 D feature correspondences. Often the distortion is assumed constant during camera usage and removed from the images before applying SMR algorithms. However, <b>lens</b> <b>distortions</b> can change by zooming, focusing and temperature variations. Moreover, when only the video sequence is available preliminary calibration is often not an option. This paper addresses all fore-mentioned problems by sequentially recovering <b>lens</b> <b>distortions</b> together with structure and motion from video sequences without tedious pre-calibrations and allowing <b>lens</b> <b>distortions</b> to change over time. The devised algorithms are fairly simple as they only use linear least squares techniques. The unprocessed video sequence forms the only input and no severe restrictions are placed on viewed scene geometry. Therefore, the accurate recovery of structure and motion is fully automated and widely applicable. The experiments demonstrate the necessity of modeling <b>lens</b> <b>distortions</b> to achieve high accuracy in recovered structure and motion. status: publishe...|$|R
50|$|As there's no <b>lens</b> <b>distortion,</b> {{wide angle}} images remain {{absolutely}} rectilinear.|$|E
5000|$|Image correction: apply image {{processing}} techniques for <b>lens</b> <b>distortion</b> removal, etc.|$|E
5000|$|In-camera {{automatic}} <b>lens</b> <b>distortion</b> correction {{for most}} Canon lenses produced since 1995 ...|$|E
50|$|DxO ViewPoint {{allows the}} user to correct {{perspective}} and <b>lens</b> <b>distortions,</b> especially those caused by shooting with wide-angle lenses when the subject {{is not in the}} middle of the frame.|$|R
50|$|Photo {{manipulation}} packages have {{functions to}} correct images for various <b>lens</b> <b>distortions</b> including pincushion, fisheye and barrel distortions. The corrections are {{in most cases}} subtle, but can improve the appearance of some photographs.|$|R
40|$|When {{unmanned}} underwater vehicles (UUVs) perform missions {{near the}} ocean floor, optical {{sensors can be}} used to improve local navigation. Video mosaics allow to efficiently process the images acquired by the vehicle, and also to obtain position estimates. We discuss in this paper the role of <b>lens</b> <b>distortions</b> in this context, proving that degenerate mosaics have their origin not only in the selected motion model or in registration errors, but also in the cumulative effect of radial distortion residuals. Additionally, we present results on the accuracy of different feature-based approaches for self-correction of <b>lens</b> <b>distortions</b> that may guide the choice of appropriate techniques for correcting distortion...|$|R
5000|$|... optical {{correction}} - <b>lens</b> <b>distortion,</b> vignetting, {{chromatic aberration}} and color fringing correction ...|$|E
5000|$|<b>Lens</b> <b>distortion</b> {{correction}} {{as well as}} {{image rotation}} ("Straighten") via playback ("Retouch") menu ...|$|E
5000|$|Lensfun {{is a free}} to use {{database}} and library for correcting <b>lens</b> <b>distortion.</b>|$|E
40|$|The {{bachelor}} thesis {{deals with}} methods of removing digital photographies aberrations caused by photographical <b>lens</b> <b>distortions.</b> It describes {{the most frequent}} lens aberrations, deals with their causes, followed by consequences of these aberrations on destination pictures and ways of their removing from digital photographies. The main goal of the thesis is to design and implement tools for removing <b>lens</b> <b>distortions</b> aberrations from a digital photography. The application was created in C++ programming language {{with the support of}} Cimg and Imagemagick libraries. The application was also developed and tested for MS Windows XP and Linux Kubuntu 7. 10 operation systems. The results are compared with professional tools for digital photography processing...|$|R
40|$|This paper {{presents}} {{two methods}} of star camera calibration to determine camera calibrating parameters (like principal point, focal length etc) along with <b>lens</b> <b>distortions</b> (radial and decentering). First method works autonomously utilizing star coordinates in three consecutive image frames thus independent of star identification or biased attitude information. The parameters obtained in autonomous self-calibration technique helps {{to identify the}} imaged stars with the cataloged stars. Least Square based second method utilizes inertial star coordinates to determine satellite attitude and star camera parameters with <b>lens</b> radial <b>distortion,</b> both independent of each other. Camera parameters determined by the second method are more accurate than the first method of camera self calibration. Moreover, unlike most of the attitude determination algorithms where attitude of the satellite depend on the camera calibrating parameters, the second method {{has the advantage of}} computing spacecraft attitude independent of camera calibrating parameters except <b>lens</b> <b>distortions</b> (radial). Finally Kalman filter based sequential estimation scheme is employed to filter out the noise of the LS based estimation...|$|R
50|$|The Coolpix 9xx {{cameras were}} widely {{considered}} among the best cameras in their price range. Photographic quality was considered excellent with some minor <b>lens</b> <b>distortions</b> and chromatic aberration. Downsides of the Coolpix 995 included a concern about the robustness of the CF compartment door.|$|R
5000|$|... #Caption: Image {{captured}} from Oculus Rift DK2, showing {{compensation for}} <b>lens</b> <b>distortion</b> and chromatic aberration.|$|E
5000|$|Lens {{correction}} for <b>lens</b> <b>distortion</b> {{and lateral}} chromatic aberration in Pentax FA, DA and DFA lenses ...|$|E
5000|$|Auto <b>lens</b> <b>distortion</b> ("Distortion") {{correction}} and Perspective Control {{as well as}} {{image rotation}} ("Straighten") via playback ("Retouch") menu ...|$|E
50|$|The <b>lenses</b> {{introduce}} <b>distortion</b> and chromatic aberration, {{which are}} corrected in software.|$|R
40|$|With their {{constant}} {{perspective and}} large magnification {{in the working}} distance, double-sided telecentric lenses {{have been widely used}} in machine-vision applications. This paper puts forward a flexible calibration approach for the double-sided telecentric camera. Based on an orthographic projection model considering the major sources of <b>lens</b> <b>distortions,</b> a two-step calibration procedure is proposed. In this approach, the camera parameters apart from the <b>lens</b> <b>distortions</b> are achieved by a closed-form solution. Then a double non-linear optimization is performed to refine all the parameters, including the distortion coefficients and distortion centre. In addition, to achieve a flexible calibration procedure, the calibration pattern used is a cheap print product rather than a professional customized calibration pattern. Simulation and real-world experiments are performed to validate the performance of the proposed calibration approach. In addition, the comparison experiments between the print calibration pattern and professional calibration pattern are carried out, and the accuracy of calibration results are at the same level...|$|R
40|$|Modern hybrid video coding {{consists}} of basically three main techniques: motion estimation/compensation, transform and quantization and entropy coding. The process of motion estimation {{is a critical}} component in terms of efficiency and runtime. If the motion estimation does not work well, the residual to be coded grows and therefore the bitrate will increase. In the presence of <b>lens</b> <b>distortions</b> like radial distortion, the block-based motion estimation process is degraded: the content of compared blocks used in the motion estimation process is differently distorted, depending on {{the distance of the}} employed blocks to the distortion center. Actual coders do not consider <b>lens</b> <b>distortions.</b> In this paper we investigate the influence of radial distortion in hybrid video coding. We explore the achievable coding gain and show the improvement of in-loop radial distortion compensation in the motion estimation process. Furthermore we evaluate possible bitrate improvements by considering the radial distortion compensation in the latest reference software of the upcoming video coding standard HEVC...|$|R
50|$|In {{general the}} major issues to deal with are {{presence}} of parallax, <b>lens</b> <b>distortion,</b> scene motion, and exposure differences.|$|E
5000|$|Corel Paint Shop Pro Photo {{includes}} a manual <b>Lens</b> <b>Distortion</b> effect for simple (barrel, fisheye, fisheye spherical and pincushion) distortion.|$|E
50|$|The lens {{suffers from}} {{moderate}} barrel <b>lens</b> <b>distortion</b> and moderate vignetting when at f/2.0 (which {{can be resolved}} by stopping down to f/2.8).|$|E
40|$|Using OpenCV, a {{geometric}} correction method of plane image from single grid image {{in a state}} of unknown camera position is presented. The method can remove the perspective and <b>lens</b> <b>distortions</b> from an image. The method is simple and easy to implement, and the efficiency is high. Experiments indicate that this method has high precision, and can be used in some domains such as plane measurement. ...|$|R
40|$|The {{increase}} in computational power of consumer graphic cards has successfully motivated adaptation of stereo algorithms {{to this kind}} of hardware. In order to solve the stereo correspondence problem efficiently, the images need to be rectified and <b>lens</b> <b>distortions</b> need to be removed. This paper presents an efficient two step solution for rectifying and correcting <b>lens</b> <b>distortions</b> in images captured using a pair of stereo cameras. The first step consists of a one-time, off-line calculation of a look-up table, based on the calibration parameters, for each of the two cameras. The second step computes the final pixel intensities based on the pre-calculated mappings stored in the look-up table. The GPU implementation proposed makes use of the inherent parallelism in a cost-effective manner, making the method suitable for rectifying high resolution images in real-time. Results are compared against an optimized CPU-based implementation, written in assembly language using MMX instructions, for reference. The complete stereo reconstruction system was implemented and evaluated on a current generation GPU and offers a running time of 11 ms for images with resolution 512 x 383. 1...|$|R
40|$|Underwater {{machine vision}} should start with careful {{calibration}} of the <b>lens</b> <b>distortions.</b> Inhomogeneous lighting {{and loss of}} contrast require special solutions. On the Fraunhofer/IOSB experimental platforms a calibration plate with a lattice of holes is used. Detection and grouping of these hole-objects from the images is presented. The discussion extends the investigation from the special application (calibration of distortions for underwater cameras) to more general problems of grouping and automatic gestalt perception...|$|R
50|$|But in the non ideal {{real life}} case the {{intensity}} varies {{across the whole}} scene {{and so does the}} contrast and intensity across the frames. <b>Lens</b> <b>distortion,</b> motion in the scene and misalignment all cause ghosting.|$|E
5000|$|Geometric distortion, {{for example}} <b>lens</b> <b>distortion,</b> {{which means that}} the 3D to 2D mapping of the camera {{deviates}} from the pinhole camera model. To some extent these errors can be compensated for, leaving a residual geometric error.|$|E
5000|$|In 2009, Digitalis Education Solutions officially forked Nightshade {{from the}} Stellarium code base [...] under the Gnu Public License. This {{provided}} {{the foundation for}} several more years of planetarium specific development including features like <b>lens</b> <b>distortion</b> profiles and web-based interactions.|$|E
40|$|This {{paper will}} discuss, from design to implementation, the methodologies applied to MIPL's {{automated}} pipeline processing as a 'system of systems' {{integrated with the}} MER GDS. Overviews of the interconnected product generating systems will also be provided with emphasis on interdependencies, including those for a) geometric rectificationn of camera <b>lens</b> <b>distortions,</b> b) generation of stereo disparity, c) derivation of 3 -dimensional coordinates in XYZ space, d) generation of unified terrain meshes, e) camera-to-target ranging (distance) and f) multi-image mosaicking...|$|R
30|$|Use {{a better}} <b>lens</b> with less <b>distortion.</b>|$|R
40|$|A {{method of}} {{reducing}} GEOS satellite plates is described. The catalog positions of stars, whose images were measured, are updated {{to the time}} of the photographic observation. The plate constants are used to compute the positions of the seven (or fewer) flashing light images which were measured. There are corrected for refraction, parallax, and radial and decentering <b>lens</b> <b>distortions.</b> With sidereally tracking cameras, the exterior orientation is further corrected {{to the time of}} the particular flash, and the change of refraction with time is allowed for. First and second differences and standard deviations and covariances for the flashing light images are developed as a measure of accuracy...|$|R
