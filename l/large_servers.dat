50|512|Public
5000|$|Runs {{parallel}} on distributed {{and shared}} memory systems using MPI. These include workstation clusters, visualization systems, <b>large</b> <b>servers,</b> supercomputers, etc.|$|E
5000|$|Virtual machine {{monitors}} (also {{known as}} hypervisors) also often operate on mainframes and <b>large</b> <b>servers</b> running IBM, HP, and other systems.Server virtualization can provide benefits such as: ...|$|E
5000|$|GPFS {{distributes}} its directory indices {{and other}} metadata across the filesystem. Hadoop, in contrast, keeps {{this on the}} Primary and Secondary Namenodes, <b>large</b> <b>servers</b> which must store all index information in-RAM.|$|E
50|$|Server {{farms are}} {{increasingly}} being used instead of or in addition to mainframe computers by <b>large</b> enterprises, although <b>server</b> farms do not yet reach the same reliability levels as mainframes. Because of {{the sheer number of}} computers in <b>large</b> <b>server</b> farms, the failure of an individual machine is a commonplace event, and the management of <b>large</b> <b>server</b> farms needs to take this into account by providing support for redundancy, automatic failover, and rapid reconfiguration of the server cluster.|$|R
50|$|<b>Large</b> <b>server</b> farms {{typically}} also place {{load balancers}} between {{the front end}} servers and the network.|$|R
50|$|The 7xxx {{series is}} aimed at the <b>large</b> <b>server</b> market, {{supporting}} configurations of up to 32 CPUs per host.|$|R
50|$|Its use is {{widespread}} in computers and CPU cooling, where the computer processors produce {{large quantities of}} heat that, if not dissipated, could damage the CPU and other electronic components. In this case air {{has the advantage of}} being a good insulator too. Water cooling is somewhat popular in very high-power situations, such as <b>large</b> <b>servers,</b> gaming computers, or heavily overclocked amateur systems.|$|E
50|$|PerfectDisk has editions {{designed}} for most user categories, from home PCs to <b>large</b> <b>servers</b> and virtualization-aware editions for virtual environments. In addition to defragmenting files, it also optimizes disk drives with an optimization strategy called SMARTPlacement and it prevents fragmentation with the OptiWrite feature. PerfectDisk defragments data and system files and places {{a high priority}} on free space consolidation. SSD Optimize is an optimization method for solid state drives that focuses on free space consolidation without defragmentation of files.|$|E
50|$|Larger pages, {{despite being}} {{available}} in the processors used in most contemporary personal computers, are not in common use except in large-scale applications, the applications typically found in <b>large</b> <b>servers</b> and in computational clusters, and in the operating system itself. Commonly, their use requires elevated privileges, cooperation from the application making the large allocation (usually setting a flag to ask the operating system for huge pages), or manual administrator configuration; operating systems commonly, sometimes by design, cannot page them out to disk.|$|E
25|$|In 2008, The Local, an Irish pub in Minneapolis, sold 671 {{cases of}} Jameson (22 bottles a day), {{making it the}} <b>largest</b> <b>server</b> of Jameson's in the world – a title it {{maintained}} for four consecutive years.|$|R
50|$|In {{a manner}} more usually {{associated}} with very high cost SMP architectures. RAIS (“Redundant Array of Inexpensive Servers”) achieves this by turning a cluster of independent servers into a single <b>large</b> <b>server</b> running applications across a virtualised network of nodes.|$|R
5000|$|The subreddit also {{maintains}} a Discord server called [...] "Centipede Central," [...] {{which has about}} 2,000 active users as of May 2017 and was among the <b>largest</b> <b>servers</b> on Discord. The server was criticized for leaking personal information of anti-Trump activists.|$|R
50|$|Peer-to-peer {{file sharing}} is also {{efficient}} {{in terms of}} cost. The system administration overhead is smaller because the user is the provider and usually the provider is the administrator as well. Hence each network can be monitored by the users themselves. At the same time, <b>large</b> <b>servers</b> sometimes require more storage and this increases the cost since the storage has to be rented or bought exclusively for a server. However, usually peer-to-peer file sharing {{does not require a}} dedicated server.|$|E
50|$|At {{the base}} of Workplace OS was {{a version of the}} Mach 3.0 {{microkernel}} (release mk68) developed by Carnegie Mellon University and heavily modified by the Open Software Foundation's Research Institute. On top of the microkernel, Workplace OS was to run servers (also called operating-system personalities) that would execute DOS, OS/2, Microsoft Windows, OS/400, and AIX applications. IBM had planned for Workplace OS to run on several processor architectures, including PowerPC, ARM, and x86 computers, and ranging in size from PDAs to workstations to <b>large</b> <b>servers.</b>|$|E
50|$|However, dynamic {{configurations}} (i.e., {{not stored}} in a static configuration file but taken from outside the host, and potentially changing after boot) have been an increasingly more common configuration, especially as we've moved from physically <b>large</b> <b>servers</b> to more portable hosts that may be plugged and unplugged (or moved from WiFi hotspot to WiFi hotspot) at {{the will of the}} user. Bootp was an early protocol used for this, and to this day its descendant DHCP is still very common. Many Unix-like systems include a program called dhclient to handle this dynamic configuration.|$|E
5000|$|In {{the case}} of server consolidation, many small {{physical}} servers are replaced by one <b>larger</b> physical <b>server</b> to increase the utilization of costly hardware resources such as CPU. Although hardware is consolidated, typically OSs are not. Instead, each OS running on a physical server becomes converted to a distinct OS running inside a virtual machine. The <b>large</b> <b>server</b> can [...] "host" [...] many such [...] "guest" [...] virtual machines. This is known as Physical-to-Virtual (P2V) transformation.|$|R
25|$|In an OS, {{distributed}} and {{cloud computing}} context, templating refers {{to creating a}} single virtual machine image as a guest operating system, then saving it {{as a tool for}} multiple running virtual machines. The technique is used both in virtualization and cloud computing management, and is common in <b>large</b> <b>server</b> warehouses.|$|R
25|$|<b>Larger</b> <b>server</b> {{centers are}} {{sometimes}} located where energy and land are inexpensive and readily available. Local availability of renewable energy, climate that allows outside air {{to be used}} for cooling, or locating them where the heat they produce may be used for other purposes could be factors in green siting decisions.|$|R
50|$|South Korea {{has banned}} at least 65 sites {{considered}} sympathetic to North Korea {{through the use}} of IP blocking. Most North Korean websites are hosted overseas in the United States, Japan and China. Critics say that the only practical way of blocking a webpage is by denying its IP address, and since many of the North Korean sites are hosted on <b>large</b> <b>servers</b> together with hundreds of other sites, the impact on the number of real blocked pages increase significantly. Estimates are that over 3,000 additional webpages are rendered inaccessible.|$|E
5000|$|Solid-state {{storage devices}} serve as {{secondary}} storage components for more complex systems, which may range from embedded and portable devices to <b>large</b> <b>servers</b> and dedicated network-attached storage (NAS) systems. As a result, solid-state storage devices exist in different capacities, physical layouts and dimensions, using various interfaces and providing different feature sets. [...] Less complex solid-state storage {{devices such as}} memory cards use simpler, slower interfaces such as the one-bit SD interface or SPI, while more sophisticated high-performance devices use faster interfaces such as Serial ATA (SATA) or PCI Express (PCIe) paired with logical device interfaces such as AHCI or NVM Express (NVMe).|$|E
50|$|The {{boot process}} can be {{considered}} complete when the computer is ready {{to interact with the}} user, or the operating system is capable of running system programs or application programs. Typical modern personal computers boot in about one minute, of which about 15 seconds are taken by a power-on self-test (POST) and a preliminary boot loader, and the rest by loading the operating system and other software. Time spent after the operating system loading can be considerably shortened to as little as 3 seconds by bringing the system up with all cores at once, as with coreboot. <b>Large</b> <b>servers</b> may take several minutes to boot and start all their services.|$|E
50|$|In an OS, {{distributed}} and {{cloud computing}} context, templating refers {{to creating a}} single virtual machine image as a guest operating system, then saving it {{as a tool for}} multiple running virtual machines. The technique is used both in virtualization and cloud computing management, and is common in <b>large</b> <b>server</b> warehouses.|$|R
50|$|<b>Larger</b> <b>server</b> {{centers are}} {{sometimes}} located where energy and land are inexpensive and readily available. Local availability of renewable energy, climate that allows outside air {{to be used}} for cooling, or locating them where the heat they produce may be used for other purposes could be factors in green siting decisions.|$|R
40|$|Personal computer/Workstation (PC/WS) {{clusters}} {{have become}} a hot research topic recently {{in the field of}} parallel and distributed computing. They are considered {{to play an important role}} as a large scale computer system, such as <b>large</b> <b>server</b> sites and/or high performance parallel computers, because of their good scalability and cost performance ratio...|$|R
5000|$|The x86-64 {{architecture}} (...) allows 48 bits for {{virtual memory}} and, {{for any given}} processor, up to 52 bits for physical memory. These limits allow memory sizes of 256 TiB (256 × 10244 bytes) and 4 PiB (4 × 10245 bytes), respectively. A PC cannot currently contain 4 pebibytes of memory (due to the physical size of the memory chips), but AMD envisioned <b>large</b> <b>servers,</b> shared memory clusters, and other uses of physical address space that might approach this in the foreseeable future. Thus the 52-bit physical address provides ample room for expansion while not incurring the cost of implementing full 64-bit physical addresses. Similarly, the 48-bit virtual address space was designed to provide more than 65,000 (216) times the 32-bit limit of 4 GiB (4 × 10243 bytes), allowing room for later expansion and incurring no overhead of translating full 64-bit addresses.|$|E
50|$|PlateSpin is a {{software}} solution suite of Micro Focus International. Originally a standalone software company headquartered in Toronto, Canada, registered in Delaware, US as Platespin Inc. and founded by Robert Reive in 1999 with co-founders added later David Richards, Bruno Baloi and M. Verdun. Intel corp. via the Intel64fund {{was a key}} investor, along with 4Quarters Capital, Castlehill Ventures(Barry Laver) and AltaMira, the latter three all of Toronto, Canada. The original product for which the patent was filed was the Platespin Operations Center, the first usable VM provisioning tool for low cost deployment of servers in their VMs to Vmware ESX and GSX on 64bit processors. Platespin Operations Centre was designed to reduce operations cost and more efficiently use the resources of <b>large</b> <b>servers,</b> as well as deal with routine security patches to software servers and their OS efficiently. Today Platespin is a NetIQ suite of software solutions that help manage physical and virtualized server workloads on VMware, Microsoft Hyper-V, KVM or Citrix XenServer.|$|E
5000|$|The BitTorrent {{protocol}} {{can be used}} {{to reduce}} the server and network impact of distributing large files. Rather than downloading a file from a single source server, the BitTorrent protocol allows users to join a [...] "swarm" [...] of hosts to upload to/download from each other simultaneously. The protocol is an alternative to the older single source, multiple mirror sources technique for distributing data, and can work effectively over networks with lower bandwidth. Using the BitTorrent protocol, several basic computers, such as home computers, can replace <b>large</b> <b>servers</b> while efficiently distributing files to many recipients. This lower bandwidth usage also helps prevent large spikes in internet traffic in a given area, keeping internet speeds higher for all users in general, {{regardless of whether or not}} they use the BitTorrent protocol. A user who wants to upload a file first creates a small torrent descriptor file that they distribute by conventional means (web, email, etc.). They then make the file itself available through a BitTorrent node acting as a seed. Those with the torrent descriptor file can give it to their own BitTorrent nodes, which—acting as peers or leechers—download it by connecting to the seed and/or other peers (see diagram on the right).|$|E
40|$|In {{a typical}} {{large-scale}} digital computer system, thousands of high-speed parallel links are compacted {{into a very}} small volume. The number of links {{is determined by the}} number of processors, the bus width, and the interconnect architecture. A <b>large</b> <b>server</b> implementation (Sun Fire 15 k) can have up to 106 processors connected through a multi-stag...|$|R
5000|$|Arena: A special mode where players don't respawn upon {{death and}} can't change classes at spawn. The {{goal is to}} {{eliminate}} the enemy team before they do. Alternatively, the capture point in the center, after a while, becomes active and can be captured to win the round. Players are cycled out every few rounds on <b>larger</b> <b>servers.</b>|$|R
5000|$|In a cloud {{computing}} environment, {{there is a}} <b>large</b> <b>server</b> that runs many different tasks. Suppose {{a certain type of}} a task requires 2 CPUs, 3 gigabytes of memory and 4 gigabytes of disk-space to complete. The utility of the user is equal to the number of completed tasks. Hence, it can be represented by: [...]|$|R
40|$|Several {{recent studies}} {{have pointed out that}} file I/Os can be a major {{performance}} bottleneck for some large Web servers. Large I/O buffer caches often do not work effectively for <b>large</b> <b>servers.</b> This paper presents a novel, light-weight, temporary file system called TFS that can effectively improve I/O performance for <b>large</b> <b>servers</b> with minimal cost. TFS is a much more cost-effective scheme than the full caching policy for <b>large</b> <b>servers.</b> It is a user-level application that manages files on a raw disk and works in conjunction with a regular file system as an I/O accelerator. Since the entire system runs in the user space, it is easy and inexpensive to implement and maintain. It also has good portability. TFS uses a novel disk storage subsystem called Cluster-structured Storage System (CSS) to manage files. CSS uses only large disk reads and writes and does no have garbage collection problems. Comprehensive trace-driven simulation experiments show that, TFS achieves up to 160 % better system throughput and reduces at up to 77 % I/O latency per URL operation than that in a traditional Unix Fast File System in large Web servers. 1...|$|E
40|$|Computing environments change: {{everyone}} has portable computing devices (in form of mobile phones) {{and access to}} <b>large</b> <b>servers</b> (in the cloud). This change presents fundamental challenge of outsourcing computation, which is motivated by the asymmetry of the available computing power. In recent computing scenarios clients are trusted (but weak), while computationally strong servers ar...|$|E
40|$|Abstract — A {{foreseeable}} {{scenario is}} where on the Internet Mobile IPv 6 is deployed {{and a large}} percentage of the clients are mobile nodes. These mobile clients will communicate with <b>large</b> <b>servers,</b> which under the Mobile IPv 6 ’s point of view, will be Correspondent Nodes. Usually <b>large</b> <b>servers</b> operate in servers farms with a load balancer device. Mobile clients can communicate with these servers through their Home Agent (a sub-optimal path) or directly by using the built-in mechanisms of Mobile IPv 6 Route Optimization. In this paper we detail an important incompatibility between the Mobile IPv 6 ’s Route Optimization and several load balancing techniques. This means that mobile clients need to revert to the sub-optimal path when communicating with these server farms. This issue reduces considerably the communications performance increasing the delay and the infrastructure load. Moreover it may be an important drawback when considering Mobile IPv 6 ’s deployment. In this paper we show which load balancing techniques are incompatible with Route Optimization and we propose a novel mobile entity that solves this issue for several load balancing techniques...|$|E
40|$|This paper {{presents}} a systematic {{study of the}} properties {{of a large number}} of Web sites hosted by a major ISP. To our knowledge, ours is the first comprehensive study of a <b>large</b> <b>server</b> farm that contains thousands of commercial Web sites. We also perform a simulation analysis to estimate potential performance benefits of content delivery networks (CDNs) for these Web sites...|$|R
50|$|Studies {{showed the}} vast {{majority}} of this performance hit, 73% by one measure, was due to the overhead of the IPC. And this was measured on a system with a single <b>large</b> <b>server</b> providing the operating system; breaking the operating system down further into smaller servers would only make the problem worse. It appeared the goal of a collection-of-servers was simply not possible.|$|R
40|$|Java is {{increasingly}} {{used to develop}} <b>large</b> <b>server</b> applications. In order to provide powerful platforms for such applications a number of projects have proposed Java Virtual Machines (JVMs) {{that are based on}} network of workstations. These JVMs employ the message-passing paradigm, i. e. all communication between the distributed instances of the virtual machine take place using remote method invocation (RMI) or socket stream communication...|$|R
