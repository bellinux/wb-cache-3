10000|10000|Public
5|$|Later, von Neumann {{suggested}} a new method of linear programming, using the homogeneous linear system of Gordan (1873), which was later popularized by Karmarkar's algorithm. Von Neumann's method used a pivoting algorithm between simplices, with the pivoting decision {{determined by a}} nonnegative <b>least</b> <b>squares</b> subproblem with a convexity constraint (projecting the zero-vector onto the convex hull of the active simplex). Von Neumann's algorithm was the first interior point method of linear programming.|$|E
5|$|The {{experimental}} determination of pKa values is commonly performed {{by means of}} titrations, in a medium of high ionic strength and at constant temperature. A typical procedure would be as follows. A solution of the compound in the medium is acidified with a strong acid {{to the point where}} the compound is fully protonated. The solution is then titrated with a strong base until all the protons have been removed. At each point in the titration pH is measured using a glass electrode and a pH meter. The equilibrium constants are found by fitting calculated pH values to the observed values, using the method of <b>least</b> <b>squares.</b>|$|E
25|$|A {{special case}} of {{generalized}} <b>least</b> <b>squares</b> called weighted <b>least</b> <b>squares</b> occurs {{when all the}} off-diagonal entries of Ω (the correlation matrix of the residuals) are null; the variances of the observations (along the covariance matrix diagonal) may still be unequal (heteroscedasticity).|$|E
40|$|The paper {{presents}} a comparison {{study for the}} performances of seven wind estimation algorithms for spaceborne scatterometers. These algorithms are weighted <b>least</b> <b>square</b> in log domain, maximum-likelihood, <b>least</b> <b>square</b> weighted <b>least</b> <b>square,</b> adjustable weighted <b>least</b> <b>square,</b> L 1 norm, and <b>least</b> wind speed <b>square</b> algorithms using radar scatterometer measurements. For each algorithm, the system performance simulation results are presented for the NASA scatterometer system planned to be launched in the 1990 's...|$|R
3000|$|The {{goodness}} of the <b>least</b> <b>square</b> fitting is typically measured using the estimated Chi-square value, {{that is the}} <b>least</b> <b>squared</b> value, [...]...|$|R
30|$|Adaptive {{predictors}} using <b>least</b> <b>square</b> approach {{are also}} introduced in many papers [17, 18] and applied in reversible data hiding [19, 20]. Edge-directed prediction (EDP) is a <b>least</b> <b>square</b> predictor which optimizes the prediction coefficients locally inside a training set. Kau and Lin [17] proposed edge-look-ahead (ELA) scheme using <b>least</b> <b>square</b> prediction with efficient edge detector {{to maximize the}} edge-directed characteristics. Wu et al. improved the <b>least</b> <b>square</b> predictor by determining the order of predictor and support pixels adaptively [18].|$|R
25|$|In statistics, linear <b>least</b> <b>squares</b> {{problems}} {{correspond to}} a particularly important type of statistical model called linear regression which arises as a {{particular form of}} regression analysis. One basic form of such a model is an ordinary <b>least</b> <b>squares</b> model. The present article concentrates on the mathematical aspects of linear <b>least</b> <b>squares</b> problems, with discussion of the formulation and interpretation of statistical regression models and statistical inferences related to these being {{dealt with in the}} articles just mentioned. See outline of regression analysis for an outline of the topic.|$|E
25|$|This {{method is}} used in iteratively reweighted <b>least</b> <b>squares.</b>|$|E
25|$|In applied statistics, total <b>least</b> <b>squares</b> {{is a type}} of errors-in-variables regression, a <b>least</b> <b>squares</b> data {{modeling}} technique in which observational errors on both dependent and independent variables are taken into account. It is a generalization of Deming regression and also of orthogonal regression, and can be applied to both linear and non-linear models.|$|E
3000|$|... ℓ 2, 1 -norm <b>least</b> <b>square</b> {{regression}} (LSR 21) [22]: a supervised {{feature selection}} method built upon <b>least</b> <b>square</b> regression {{by using the}} ℓ 2, 1 -norm as the regularization term.|$|R
40|$|Many {{important}} {{values for}} cooperative games {{are known to}} arise from <b>least</b> <b>square</b> optimization problems. The present investigation develops an optimization framework to explain and clarify this phenomenon in a general setting. The main result shows that every linear value results from some <b>least</b> <b>square</b> approximation problem and that, conversely, every <b>least</b> <b>square</b> approximation problem with linear constraints yields a linear value. This approach includes and extends previous results on so-called <b>least</b> <b>square</b> values and semivalues in the literature. In particular, is it demonstrated how known explicit formulas for solutions under additional assumptions easily follow from the general results presented here...|$|R
40|$|Aiming at {{improving}} {{the precision of}} nodes’ localization, this paper analyses {{the source of the}} localization error when using <b>least</b> <b>square</b> algorithm, and proposes the principle to choose the benchmark anchor nodes in reducing the power of equation. Based on this principle, the algorithm choosing the nearest node as the benchmark anchor node in <b>least</b> <b>square</b> algorithm and the algorithm choosing the synthetic nearest node as the benchmark anchor node in <b>least</b> <b>square</b> algorithm are put forward. It is proved by the simulation in MatLab that the improved <b>least</b> <b>square</b> algorithm can effectively improve the precision of the nodes localization. </p...|$|R
25|$|For a {{derivation}} of this estimate see Linear <b>least</b> <b>squares</b> (mathematics).|$|E
25|$|Fitting {{of linear}} models by <b>least</b> <b>squares</b> often, but not always, {{arise in the}} context of {{statistical}} analysis. It can therefore be important that considerations of computation efficiency for such problems extend to all of the auxiliary quantities required for such analyses, and are not restricted to the formal solution of the linear <b>least</b> <b>squares</b> problem.|$|E
25|$|The {{method of}} <b>least</b> <b>squares</b> {{is often used}} to {{generate}} estimators and other statistics in regression analysis.|$|E
40|$|A <b>least</b> <b>square</b> {{estimation}} technique {{has been proposed}} for in-flight fuel estimation for a high performance combat aircraft. This paper presents the details of <b>least</b> <b>square</b> models for aircraft fuel estimation, the procedure for building the <b>least</b> <b>square</b> models and their fidelity to estimate the fuel quantity in the multiple internal fuel tanks of the aircraft from flight data. The performance of the fuel estimation by <b>least</b> <b>square</b> technique has been verified with 56 different post flight data with different maneuvers including probe failure cases and compared with lookup table based estimates, the technique currently being used on the aircraft. Few results of fuel quantity estimates are presented and discussed. Sensitivity of the <b>least</b> <b>square</b> model based fuel {{estimation technique}} to probe failures has been studied by simulating multiple probe failures in flight data...|$|R
40|$|Abstract. A {{difference}} {{method to}} order decision for <b>least</b> <b>square</b> in trend fitting is proposed in this paper. When the <b>least</b> <b>square</b> {{is used for}} fitting trend, choosing the proper order is important for trend fitting accuracy. We can use difference n times to obtain difference result data, and the mean value can be taken as decision criteria. Comparing with the threshold value, when the mth difference result mean is smaller, the trend fitting order for <b>least</b> <b>square</b> can be set to m. Simulation processing results show that this method resolve the problem of order decision for <b>least</b> <b>square</b> in trend fitting, and the method has high accuracy for trend extraction...|$|R
40|$|International audienceThis paper {{presents}} some {{tools for}} <b>least</b> <b>square</b> computation in Grassmann-Cayley algebra, more specifically for elements expressed in homogeneous coordinates. We show that building objects with the outer product from k-vectors of same grade presents some properties {{that can be}} expressed in term of linear algebra and can {{be treated as a}} <b>least</b> <b>square</b> problem. This paper mainly focuses on line and plane fitting and intersections computation, largely used in computer vision. We show that these <b>least</b> <b>square</b> problems written in Grassmann-Cayley algebra have a direct reformulation in linear algebra, corresponding to their standard expression in projective geometry and hence can be solved using standard <b>least</b> <b>square</b> tools...|$|R
25|$|These {{differences}} must {{be considered}} whenever the solution to a nonlinear <b>least</b> <b>squares</b> problem is being sought.|$|E
25|$|The first {{clear and}} concise {{exposition}} {{of the method}} of <b>least</b> <b>squares</b> was published by Legendre in 1805. The technique is described as an algebraic procedure for fitting linear equations to data and Legendre demonstrates the new method by analyzing the same data as Laplace for {{the shape of the}} earth. The value of Legendre's method of <b>least</b> <b>squares</b> was immediately recognized by leading astronomers and geodesists of the time.|$|E
25|$|Least-squares {{problems}} {{fall into}} two categories: linear or ordinary <b>least</b> <b>squares</b> and nonlinear <b>least</b> <b>squares,</b> depending {{on whether or not}} the residuals are linear in all unknowns. The linear least-squares problem occurs in statistical regression analysis; it has a closed-form solution. The nonlinear problem is usually solved by iterative refinement; at each iteration the system is approximated by a linear one, and thus the core calculation is similar in both cases.|$|E
40|$|AbstractFor {{a complex}} matrix {{equation}} AXB=C, we solve {{the following two}} problems: (1) the maximal and minimal ranks of <b>least</b> <b>square</b> solution X to AXB=C, and (2) the maximal and minimal ranks of two real matrices X 0 and X 1 in <b>least</b> <b>square</b> solution X=X 0 +iX 1 to AXB=C. We also give a necessary and sufficient condition for matrix equations AiXiBi=Ci(i= 1, 2) to have a common <b>least</b> <b>square</b> solution...|$|R
40|$|A local linear <b>least</b> <b>square</b> (LLLS) {{method to}} t multidimensional {{potential}} energy surface for quantum dynamics calculation is presented. The method uses only energy data points within a local area in multidimentional space. The potential is fit using a linear <b>least</b> <b>square</b> method with singular value decomposition. The method is tested in quantum dynamical calculation for three-dimensional H + H 2 reaction. The result {{indicates that the}} local linear <b>least</b> <b>square</b> tting is accurate and computationally efficient...|$|R
5000|$|In {{this form}} the above {{expression}} {{can be easily}} compared with weighed <b>least</b> <b>square</b> and Gauss-Markov estimate. In particular, when , corresponding to infinite variance of the apriori information concerning , the result [...] {{is identical to the}} weighed linear <b>least</b> <b>square</b> estimate with [...] as the weight matrix. Moreover, if the components of [...] are uncorrelated and have equal variance such that [...] where [...] is an identity matrix, then [...] is identical to the ordinary <b>least</b> <b>square</b> estimate.|$|R
25|$|For {{non-linear}} <b>least</b> <b>squares</b> systems {{a similar}} argument {{shows that the}} normal equations should be modified as follows.|$|E
25|$|Because of the <b>least</b> <b>squares</b> property, {{and because}} of the {{completeness}} of the Fourier basis, we obtain an elementary convergence result.|$|E
25|$|Refinement of the {{equilibrium}} constants. Usually a Non-linear <b>least</b> <b>squares</b> procedure is used. A weighted sum of squares, U, is minimized.|$|E
40|$|The {{purpose of}} this paper is to present an {{adaptive}} algorithm to find the best approximation in the <b>least</b> <b>square</b> sense of a given signal. The proposed method takes advantage of the fact that the <b>least</b> <b>square</b> approximation of a given signal over a chosen domain D can be directly obtained from the corresponding optimal <b>least</b> <b>square</b> approximations of this signal over any set of domains that constitute a partition of D. The approximation characteristics and a parameter that takes into account of the relative position and geometry of these domains are sufficient to provide the overall best approximation over D. This property is shown to be independent of the basis functions used in the approximation. It is also shown how the total <b>least</b> <b>square</b> error can be obtained from the <b>least</b> <b>square</b> errors that define a partition of D. The paper presents as well the computational efficiency of the algorithm. As an example, an applicaiton in the context of image segmentation is presented...|$|R
30|$|<b>Least</b> <b>square</b> {{regression}} technique [23] {{is used to}} fit a trend line on the RTS for each cluster. <b>Least</b> <b>square</b> simply states that it looks for an optimal solution for the overall fit of data such that sum of the squares error (SSE) is least.|$|R
40|$|Hybrid {{approach}} for seismic travel time tomography is {{proposed in the}} case of elliptical anisotropic media. A sequential scheme is presented that combines simulating annealing with linear <b>least</b> <b>square</b> inversion. Simulated annealing was implemented to obtain a velocity model that can be used as initial guess for linear <b>least</b> <b>square</b> inversion. Linear Traveltime Interpolation raytracing approximation is used to trace rays and calculate traveltimes. The procedure is tested both for a synthetic model and a real case. The real case comes from a previous study, that was solved by linear <b>least</b> <b>square</b> inversion. In both synthetic and real cases comparison is performed between the linear <b>least</b> <b>square</b> inversion results and hybrid approach; in the field study we compare the old results with those inferred by sequential approach...|$|R
25|$|S. Van Huffel and J. Vandewalle, The Total <b>Least</b> <b>Squares</b> Problems: Computational Aspects and Analysis. SIAM Publications, Philadelphia PA, 1991.|$|E
25|$|The fourth {{chapter of}} this {{treatise}} includes an exposition {{of the method}} of <b>least</b> <b>squares,</b> a remarkable testimony to Laplace's command over the processes of analysis. In 1805 Legendre had published the method of <b>least</b> <b>squares,</b> making no attempt to tie it {{to the theory of}} probability. In 1809 Gauss had derived the normal distribution from the principle that the arithmetic mean of observations gives the most probable value for the quantity measured; then, turning this argument back upon itself, he showed that, if the errors of observation are normally distributed, the <b>least</b> <b>squares</b> estimates give the most probable values for the coefficients in regression situations. These two works seem to have spurred Laplace to complete work toward a treatise on probability he had contemplated as early as 1783.|$|E
25|$|The {{gradient}} equations {{apply to}} all <b>least</b> <b>squares</b> problems. Each particular problem requires particular expressions for the model and its partial derivatives.|$|E
40|$|The topics, {{estimation}} of spatial variogram, bootstrap method for stationary processes and sequential sampling are studied in this thesis. Condition and exact covariance formulars are derived for Matheron 2 ̆ 7 s variogram estimators. The asymptotic {{properties of the}} <b>least</b> <b>square</b> estimator of the spatial variogram are also shown. Block bootstrap method is applied to get more efficient generalized <b>least</b> <b>square</b> estimator. Consistency and the asymptotic normality of the bootstrap based generalized <b>least</b> <b>square</b> estimators are proved. Performances of the <b>least</b> <b>square</b> estimators with finite sample are compared by simulation study which uses the random field generated by spectral method. Bias due to the repeated significance test which is an advanced version of sequential probability ratio test is estimated by bootstrap method...|$|R
40|$|The {{application}} of traditional <b>least</b> <b>square</b> method is limited when the experiment data are of heterogeneous structure. This paper presents a novel constrained <b>least</b> <b>square</b> method for solving the pieccal curve fitting problem with global continuity conatraint. In particular, the continuity constraint among the segment points was converted to the matrix equality Za= 0. Therefore, the <b>least</b> <b>square</b> model min ||Xa-y|| 2 was proposed with the linear equality constraint {{to address the}} problem. Here, {{the solution of the}} <b>least</b> <b>square</b> model was seriously derived in a simple exlicit form via the Lagrange multiplier method, which can be easily programmed in numerical calculation. The experimental results show that the method proposed here provided a "best" fit for the data and the global continuity on the segment points...|$|R
40|$|This paper aims {{to compare}} the {{relative}} efficiency of weighted <b>least</b> <b>square</b> (WLS), ordinary <b>least</b> <b>square</b> (OLS) and robust regression method in regression coefficient estimation when the error term is not homogen. The assumption of homegeneous error variance underlying the ordinary <b>least</b> <b>square</b> (OLS) {{is very important to}} get the best linear unbiased estimation of the regression coefficients. The investigation compares the methods in calculating efficiency of booth simulation and experimental data. In conclusion, the WLS method is relatively more efficient than OLS and Robust Regression methods...|$|R
