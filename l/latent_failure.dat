40|86|Public
50|$|Based on Reason's model, {{accident}} investigators {{analyze the}} accident from all four layers {{to determine the}} cause of the accident. There are two main types of failure investigators will focus on: active failure and <b>latent</b> <b>failure.</b>|$|E
5000|$|A four layered {{model for}} defense against human error has been described, which {{attributes}} error to {{three levels of}} <b>latent</b> <b>failure</b> and one of active failure, and posits that in general an accident is due to failure of all four levels of defence. These levels are: ...|$|E
5000|$|<b>Latent</b> <b>failure</b> usually occurs {{from the}} high level management. Investigators may ignore this kind of failure because it may remain undetected for a long time. During the {{investigation}} of <b>latent</b> <b>failure,</b> investigators have three levels to assess. The first is the factor that directly affects the operator's behavior: precondition (fatigue and illness). On February 12, 2009, a Colgan Air Bombardier DHC-8-400 was on approach to Buffalo-Niagara International Airport. The pilots were experiencing fatigue and their inattentiveness cost the lives of everyone on board and one person on the ground when it crashed near the airport. The investigation suggested that both pilots were tired and their conversation {{was not related to}} the flight operation, which indirectly caused the accident. The second level investigator will track precursors of accidents related to latent threats. On June 1, 2009, Air France 447 crashed into the Atlantic Ocean and 228 passengers on broad were killed. Analysis of the black box indicated that the airplane was controlled by an inexperienced co-pilot who lifted the nose too high and induced a stall. Letting an inexperienced pilot fly the airplane by himself is one of the cases of unsafe supervision. The last area that <b>latent</b> <b>failure</b> investigation will assess is organizational failure. For example, an airline company decides to reduce the cost spent on pilot training. Those who lack of training will directly lead to the existence of inexperienced pilots.|$|E
50|$|The Swiss Cheese model {{includes}} both active and <b>latent</b> <b>failures.</b> Active failures encompass the unsafe acts {{that can be}} directly linked to an accident, such as (in the case of aircraft accidents) pilot error. <b>Latent</b> <b>failures</b> include contributory factors that may lie dormant for days, weeks, or months until they contribute to the accident. <b>Latent</b> <b>failures</b> span the first three domains of failure in Reason's model.|$|R
40|$|Prior {{research}} on the occupational incidents show that job-related accidents are majorly caused by two types of failures: a) active failures (technical and human errors), they directly affect the occurrences and totally happen {{in the beginning of}} work, b) <b>latent</b> <b>failures,</b> though hold unseen and steady for a long while in the system, they are rooted in the decisions of top-ranking officials. Tripod-DELTA is a tool that exposes <b>latent</b> <b>failures.</b> It classifies all possible <b>latent</b> <b>failures</b> in to 11 GFTs. By analyzing an operation using the GFTs, DELTA assesses where the most problematic areas of an operation are. The process of action itemizing DELTA facilitates the removal of <b>latent</b> <b>failures...</b>|$|R
30|$|The human layer {{can be seen}} as {{the last}} layer of {{protection}}. Since we know the human element is dynamic and will always change, <b>latent</b> <b>failures</b> that are allowed in the other layers of protection will eventually be exposed by the human layer and cause an accident. Since we knew that the human element was variable, it was really the <b>latent</b> <b>failures</b> which caused the accident. To increase safety, <b>latent</b> <b>failures</b> must be minimized, identified, and monitored so that barriers can be constructed before them (Reason 1997).|$|R
5000|$|Active {{failure is}} an unsafe act {{conducted}} {{by an individual}} that directly leads to accident. Investigators will identify pilot error first. Misconducting of emergency procedure, misunderstanding of instructions, failing to put proper flaps on landing, and ignoring in-flight warning system are few examples of active failure. The difference between active failure and <b>latent</b> <b>failure</b> is that the effect caused by active failure will show up immediately.|$|E
5000|$|The same {{framework}} applies in healthcare. For example, a <b>latent</b> <b>failure</b> {{could be}} the similar packaging of two drugs that are then stored {{close to each other}} in a pharmacy. Such a failure would be a contributory factor in the administration of the wrong drug to a patient. Such research led to the realization that medical error can be the result of [...] "system flaws, not character flaws", and that greed, ignorance, malice or laziness are not the only causes of error.|$|E
50|$|This type of {{analysis}} {{is useful to}} determine how effective various test processes are at the detection of latent and dormant faults. The method used to accomplish this involves {{an examination of the}} applicable failure modes {{to determine whether or not}} their effects are detected, and to determine the percentage of failure rate applicable to the failure modes which are detected. The possibility that the detection means may itself fail latent should be accounted for in the coverage analysis as a limiting factor (i.e., coverage cannot be more reliable than the detection means availability). Inclusion of the detection coverage in the FMEA can lead to each individual failure that would have been one effect category now being a separate effect category due to the detection coverage possibilities. Another way to include detection coverage is for the FTA to conservatively assume that no holes in coverage due to <b>latent</b> <b>failure</b> in the detection method affect detection of all failures assigned to the failure effect category of concern. The FMEA can be revised ifnecessary for those cases where this conservative assumption does not allow the top event probability requirements to be met.|$|E
30|$|<b>Latent</b> <b>failures</b> {{which are}} not {{detected}} during maintenance due to operators' insufficient awareness.|$|R
40|$|Objectives The primary aim of {{this article}} was to {{identify}} the <b>latent</b> <b>failures</b> that are perceived to underpin medication errors. Study Setting The study was conducted within three medical wards in a hospital in the United Kingdom. Study Design The study employed a cross-sectional qualitative design. Data Collection Methods Interviews were conducted with 12 nurses and eight managers. Interviews were transcribed and subject to thematic content analysis. A two-step inter-rater comparison tested the reliability of the themes. Principal Findings Ten <b>latent</b> <b>failures</b> were identified based on the analysis of the interviews. These were ward climate, local working environment, workload, human resources, team communication, routine procedures, bed management, written policies and procedures, supervision and leadership, and training. The discussion focuses on ward climate, the most prevalent theme, which is conceptualized here as interacting with failures in the nine other organizational structures and processes. Conclusions This study is {{the first of its kind}} to identify the <b>latent</b> <b>failures</b> perceived to underpin medication errors in a systematic way. The findings can be used as a platform for researchers to test the impact of organization-level patient safety interventions and to design proactive error management tools and incident reporting systems in hospitals...|$|R
40|$|As part of {{a larger}} project to {{identify}} common human errors and system failures across different reporting systems, a large number of detailed reports of aircraft ground damage reports were analyzed. Such incidents cost major airlines {{tens of millions of dollars}} per year in repairs. It was found that consistent repeating patterns of incident emerged from the analysis based upon the final active failure and the resulting damage-causing impact. Behind these final outcomes, however, were numerous <b>latent</b> <b>failures,</b> or resident pathogens, which occurred across many hazard patterns. When the hazard patterns were expanded as event trees, the <b>latent</b> <b>failures</b> typical of each pattern were seen. For example, when a ground vehicle was driven into an aircraft, poorly maintained or substituted ground vehicles combined with management pressures for on-time departure and inadequate space around the aircraft led to the final or active failure. interventions must address <b>latent</b> <b>failures</b> in the system, instead of the "blame and train " philosophy currently in use. The methodology used in this analysis allows the most cost beneficial interventions to be easily determined. From these analyses, strategies for intervention can be derived at all systems levels. Syste...|$|R
40|$|This {{paper is}} {{concerned}} with identification of a competing risks model with unknown transformations of <b>latent</b> <b>failure</b> times. The model in this paper includes, as special cases, competing risks versions of proportional hazards, mixed proportional hazards, and accelerated failure time models. It is shown that covariate effects on <b>latent</b> <b>failure</b> times, cause-specific link functions, and the joint survivor function of the disturbance terms can be identified without relying on modelling the dependence between <b>latent</b> <b>failure</b> times parametrically nor using an exclusion restriction among covariates. As a result, the paper provides an identification result on the joint survivor function of the <b>latent</b> <b>failure</b> times conditional on covariates. Competing risks model; Identification; Transformation model...|$|E
40|$|It {{is shown}} that {{critical}} computer controls employing unmonitored safety circuits are unsafe. Analysis supporting this result leads to two additional, important conclusions: (1) annual maintenance checks of safety circuit function do not, as widely believed, eliminate <b>latent</b> <b>failure</b> risk; (2) safety risk remains even if multiple, series-connected protection circuits are employed. Finally, it is shown analytically that <b>latent</b> <b>failure</b> risk is eliminated when continuous monitoring is employed...|$|E
40|$|The {{theory of}} {{competing}} risks {{has been developed}} to asses a specific risk in presence of other risk factors. In this paper we consider the parametric estimation of different failure modes under partially complete time and type of failure data using <b>latent</b> <b>failure</b> times and cause specific hazard functions models. Uniformly minimum variance unbiased estimators and maximum likelihood estimators are obtained when <b>latent</b> <b>failure</b> times and cause specific hazard functions are exponentially distributed. We also consider the case when they follow Weibull distributions. One data set is used to illustrate the proposed techniques...|$|E
30|$|This paper {{explores the}} Tyne & Wear Metro (T&W Metro) drivers’ {{perception}} of causal factors behind some driver-related incidents. The paper {{provides an overview}} of drivers’ attitudes towards different design-related PSFs which have been identified as potential <b>latent</b> <b>failures</b> in previous research.|$|R
40|$|The {{validity}} of previous human factors data {{may be called}} into question when technology changes rapidly or new and radical designs are introduced as {{with the advent of}} unmanned aircraft systems (UASs). The {{purpose of this study was}} to analyze the role and pattern of active and <b>latent</b> human <b>failures</b> in USAF MQ- 1 Predator UAS mishaps using the Human Factors Analysis and Classification System. A mishap database was constructed and a factor analysis performed to detect structure in the relationships between <b>latent</b> and active <b>failures</b> and hence mishaps. The linkages between <b>latent</b> ant active <b>failures</b> identified from the factor analysis were used to construct a decision tree, allowing a quantitative comparison of the utility of addressing specific <b>latent</b> <b>failures.</b> Additionally, three cross sectional analyses were conducted to determine the prevalence odds ratios for human causal factors and phase of flight, mission type, and crew composition. Overall, human error was the most common cause of MQ- 1 Predator UAS mishaps and four recurring patterns of error were identified. Based on the utility analysis, preventing mishaps is best accomplished by addressing <b>latent</b> <b>failures</b> involving organizational factors and the technological environment. There was a greater likelihood for mishaps to involve perceptual factors and perceptual errors during launch and recovery operations and training operations and organizational climate factors and violations during operations other than training...|$|R
40|$|The {{undesirable}} effects {{and consequences of}} occupational fatal accidents have placed a great emphasis on applying preventive measures. This study was aimed to analyze and specify the latent causes of occupational fatal accidents in Exir Chemical Plant, Urmia - Iran in 2008 - 2009. The analytical Tripod-BETA method was used. A geographic Information System (GIS) was then used to determine {{a list of the}} most significant preconditions and active failures contributing to occupational fatal accidents. The total number of recognized preconditions and <b>latent</b> <b>failures</b> were 572 and 852 respectively. The most frequent preconditions and <b>latent</b> <b>failures</b> were determined by overlaying the coded sheets on each other. Results of the study showed that Promoting and enhancement of the company's safety culture, a carrot and stick motivation policy accompanied by comprehensive assessments to prioritize safety training programs, were among recommended preventive actions to control and reduce fatal accidents...|$|R
40|$|Background: Reviews {{of recent}} research-related {{fatalities}} {{have demonstrated that}} clinical research system failures likely contributed to the event. Current research safety-reporting mechanisms focus on individual protocols and are therefore less likely to detect system-level failures. Methods: We have implemented the “near-miss ” reporting system for a general clinical research center to detect <b>latent</b> <b>failure</b> within the research environment. Results: An identified research-related near miss includes a research volunteer being mistakenly directed into an incorrect protocol. Before beginning the incorrect study, the participant recognized that the protocol did not coincide with the consent document and the error was detected without harm. Lack of both reliable research-participant tracking and verification programs {{was believed to be}} an important <b>latent</b> <b>failure</b> associated with the research unit. Discussion: Collecting research unit-specific information on potential safety concerns could identify system failures that might not be identifiable through traditional human subjects protection programs...|$|E
40|$|The test of {{destination}} independence proposed by Ginsberg is reexamined. The original derivation {{of the test}} requires untestable assumptions about <b>latent</b> <b>failure</b> times. It is shown that these assumptions are unnecessary, although some reservations are expressed as to {{the utility of the}} test in social science applications. An alternative formulation is proposed which provides more readily interpretable results. The use of this revised test is illustrated by an application to second home tenure sojourn times. ...|$|E
40|$|Recent work in {{the field}} of {{competing}} risks enables us to start an assessment of the impact of preventive maintenance on the failure characteristics of a piece of equipment. Competing risk is the term given when more than one factor conspires to take a piece of equipment out of service. A simple example of this is given by preventive maintenance and failure. Each could occur to a piece of equipment but only one actually can. The preventive maintenance time may censor the unobserved <b>latent</b> <b>failure</b> time, thus ensuring that the statistical analysis of the failure times is made more difficult. Maintenance optimization models require knowledge of the underlying failure distribution. The Kaplan-Meier estimator (and other similar techniques) is commonly used to remove the effect of the censoring variable on the estimate of the distribution of the variable of interest. When the censoring variable is preventative maintenance, however, it is most unlikely that the assumptions of the Kaplan-Meier estimator (independence between the <b>latent</b> <b>failure</b> and preventive maintenance times) are valid. In this paper we give an overview of some of the different methods which have recently emerged in this area. These make different assumptions about the relation between PM and failure to allow the PM censoring to be removed. Potentially, these methods would allow us to look at changing maintenance strategies. Although they are {{in the early stages of}} development they do already allow us to quantify the effect of some changes...|$|E
40|$|Not least due to Seveso II, Safety Management Systems (SMS) {{have become}} a "hot topic". To reveal how organisations manage safety, {{classification}} schemes {{can be applied to}} identify plant-specific levels of safety precautions,- from "top level" equipment reliability to "bottom level" safety climate. Such a model is used to classify the accidents in MARS according to levels on which <b>latent</b> <b>failures</b> resulting in accidents did occur, and to cross-compare causation levels with overall accidents "severities". It is shown that the majority of accidents are caused by <b>latent</b> SMS <b>failures</b> and that they have significantly higher "severities" than other accidents. JRC. (ISIS) -Institute For Systems, Informatics And Safet...|$|R
50|$|The SHELL model {{adopts a}} systems {{perspective}} that suggests the human is rarely, if ever, the sole cause of an accident. The systems perspective considers {{a variety of}} contextual and task-related factors that interact with the human operator within the aviation system to affect operator performance. As a result, the SHELL model considers both active and <b>latent</b> <b>failures</b> in the aviation system.|$|R
5000|$|HFACS {{is based}} in the [...] "Swiss Cheese" [...] model of human error which looks at four levels of active errors and <b>latent</b> <b>failures,</b> {{including}} unsafe acts, preconditions for unsafe acts, unsafe supervision, and organizational influences. It is a comprehensive human error framework, that folded Reason's ideas into the applied setting, defining 19 causal categories within four levels of human failure.|$|R
40|$|We {{consider}} a competing risks setting, when evaluating the prognostic influence of an exposure {{on a specific}} cause of failure. Two main regression models are used in such analyses, the Cox cause-specific proportional hazards model and the subdistribution proportional hazards model. They are exemplified in a real data example focusing on relapse-free interval in acute leukaemia patients. We examine {{the properties of the}} estimator based on the latter model when the true model is the former. An explicit relationship between subdistribution hazards ratio and cause-specific hazards ratio is derived, assuming a flexible parametric distribution for <b>latent</b> <b>failure</b> times. Copyright (c) 2006 John Wiley & Sons, Ltd...|$|E
40|$|The {{incident}} {{database of}} the Dutch Health Care Inspectorate (IGZ) was suspected to be biased. To determine {{the type and}} extent of such biases three empirical analyses have been performed. In these analyses the current working method of the IGZ regarding the analysis and registration of incidents has been compared with PRISMA-Medical. The results of the analyses indicate {{that the number of}} registered root causes per incident is too small in the current incident database. Moreover, human failure is overrepresented, whereas organisational (<b>latent)</b> <b>failure</b> is underrepresented. When PRISMA-Medical is used for the analysis and registration of incidents, a more valid and reliable insight into the causes of incidents can be obtained...|$|E
40|$|In many instances, {{a subject}} can {{experience}} both a nonterminal and terminal event where the terminal event (e. g., death) censors the nonterminal event (e. g., relapse) but not vice versa. Typically, the two events are correlated. This situation has been termed semicompeting risks (e. g., Fine, Jiang, and Chappell, 2001,  Biometrika   88, 907 – 939; Wang, 2003,  Journal of the Royal Statistical Society, Series B   65, 257 – 273), and analysis {{has been based}} on a joint survival function of two event times over the positive quadrant but with observation restricted to the upper wedge. Implicitly, this approach entertains the idea of <b>latent</b> <b>failure</b> times and leads to discussion of a marginal distribution of the nonterminal event that is not grounded in reality. We argue that, similar to models for competing risks, <b>latent</b> <b>failure</b> times should generally be avoided in modeling such data. We note that semicompeting risks have more classically been described as an illness–death model and this formulation avoids any reference to latent times. We consider an illness–death model with shared frailty, which in its most restrictive form is identical to the semicompeting risks model that has been proposed and analyzed, but that allows for many generalizations and the simple incorporation of covariates. Nonparametric maximum likelihood estimation is used for inference and resulting estimates for the correlation parameter are compared with other proposed approaches. Asymptotic properties, simulations studies, and application to a randomized clinical trial in nasopharyngeal cancer evaluate and illustrate the methods. A simple and fast algorithm is developed for its numerical implementation...|$|E
40|$|Mathematical {{model of}} control of restorable system with <b>latent</b> <b>failures</b> has been built. Failures {{are assumed to be}} {{detected}} after control execution only. Stationary characteristics of system operation reliability and efficiency have been defined. The problem of control execution periodicity optimization has been solved. The model of control has been built by means of apparatus of semi-Markovian processes with a discrete-contin- uous field of states...|$|R
50|$|Catastrophic {{failures}} {{require the}} highest discharge voltages, are {{the easiest to}} test for and are rarest to occur. Parametric failures occur at intermediate discharge voltages and occur more often, with <b>latent</b> <b>failures</b> the most common. For each parametric failure, there are 4-10 latent ones. Modern VLSI circuits are more ESD-sensitive, with smaller features, lower capacitance and higher voltage-to-charge ratio. Silicon deposition of the conductive layers makes them more conductive, reducing the ballast resistance that has a protective role.|$|R
40|$|Models of {{organisational}} {{risk management}} often describe various layers of defences and interpret incident or accident causation as the successive penetration of these defences by either active <b>failures</b> or <b>latent</b> conditions. For any organisation within high-risk {{industries such as}} aviation and medicine, training is as an essential component in an organisation’s efforts to maintain high levels of operational performance and safety. However, {{it is possible to}} construe deficiencies in training as resident pathogens within an organisation’s defences. This paper presents a detailed example of the use of a new methodology developed to assist an organisation in the process of uncovering <b>latent</b> <b>failures</b> through the evaluation of training systems design in response to operational performance. The paper describes the types of <b>latent</b> <b>failures</b> which were uncovered through the use of this integrated approach to organisational safety within the airline concerned and highlights the benefits available to an organisation which adopts such a pro-active approach to safety. Latent Conditions and the Organisational Approach to Safety Recent research examining organisational safety has emphasised the need to examine the performance of organisational systems and systemic failures rather than merely the error...|$|R
40|$|The {{purpose of}} this paper is to develop a Bayesian {{approach}} for the log-Weibull-negative-binomial regression model under <b>latent</b> <b>failure</b> causes and presence of a randomized activation mechanism. We assume the number of competing causes of the event of interest follows a negative binomial distribution while the latent lifetimes are assumed to follows a Weibull distribution. Markov chain Monte Carlo methods are used to develop a Bayesian approach. Model selection to compare the fitted models is discussed. Moreover, we develop case deletion influence diagnostics for the joint posterior distribution based on the ψ-divergence, which has several divergence measures as particular cases. The developed procedures are illustrated on artificial and real data sets. FAPESPCNP...|$|E
40|$|The {{research}} of safety related organizational factors is hampered for two reasons: 1, accident retrospect analysis is always single-direction, {{it is hard}} to make conclusion what is the effect of some organizational factors even some accident analysis find they are safety related. 2, <b>latent</b> <b>failure,</b> as a core concept in the field of organizational safety, still has not been studied at the level of detailed description. In this study, we use organizational process analysis to show the relationship between organizational factors and safety. Results from 391 employees’ questionnaire investigation show that organization processes are the mediate between the organizational factors and safety. Latent failure,  which comes from some negative characteristics of organizational factors, could be represented by the negative condition of organizational processes...|$|E
40|$|We {{consider}} a stochastic model for competing risks involving the Mittag-Leffler distribution, inspired by fractional random growth phenomena. We prove the independence {{between the time}} to failure {{and the cause of}} failure, and investigate some properties of the related hazard rates and ageing notions. We also face the general problem of identifying the underlying distribution of <b>latent</b> <b>failure</b> times when their joint distribution is expressed in terms of copulas and the time transformed exponential model. The special case concerning the Mittag-Leffler distribution is approached by means of numerical treatment. We finally adapt the proposed model to the case of a random number of independent competing risks. This leads to certain mixtures of Mittag-Leffler distributions, whose parameters are estimated through the method of moments for fractional moments...|$|E
50|$|Decisions {{taken in}} the higher echelons of an {{organization}} can trigger the events towards an accident becoming more likely, the planning, scheduling, forecasting, designing, policy making, etc., can have a slow burning effect. The actual unsafe act that commits or triggers an accident {{can be traced back}} through the organization and the subsequent failures will be exposed, and discover the accumulation of <b>latent</b> <b>failures</b> within the system as a whole that led to the accident becoming more likely and ultimately happening.|$|R
40|$|Featuring {{previously}} unpublished results, Semi-Markov Models: Control of Restorable Systems with <b>Latent</b> <b>Failures</b> describes valuable methodology {{which can}} be used by readers to build mathematical models of a wide class of systems for various applications. In particular, this information can be applied to build models of reliability, queuing systems, and technical control. Beginning with a brief introduction to the area, the book covers semi-Markov models for different control strategies in one-component systems, defining their stationary characteristics of reliability and efficiency, and ut...|$|R
40|$|Thermal and {{electrical}} stress phases are commonly applied to automotive devices {{at the end}} of manufacturing test to give rise to early life <b>latent</b> <b>failures.</b> This paper proposes a new methodology to optimize the stress procedures during the Burn-In phase. In the proposed method, stress of CPU, RAM memory and FLASH memory are run in parallel using DMA and CACHE interventions. The paper reports also some experimental results gathered in an automotive microcontroller, and a comparison between traditional and parallelized burn-in stress technique is also provided...|$|R
