2|93|Public
5000|$|... {{relative}} luminance is the <b>luminance</b> <b>relative</b> {{to a white}} level, used in a color-space encoding; ...|$|E
40|$|The spatial cueing paradigm, with saccades to targets as {{the method}} of response, was used to {{investigate}} the influence of two simultaneously presented cues on the orienting of visual attention. Participants were presented with bilateral cues, {{one of which was}} perceptually salient (high <b>luminance)</b> <b>relative</b> to the other. They participated in one of three conditions: in the 'bright side likely' condition targets usually (p =. 8) appeared near the more salient cue; in the 'dim side likely' condition targets usually (p =. 8) appeared near the less salient cue; and in the 'neutral' condition the arrangement of the cues was uninformative with respect to target location. Brief SOAs (0, 50, 100 and 150 ms) were employed. Rapid reflexive orienting to the more salient stimulus was observed in the neutral condition: saccadic latencies were faster when the target appeared near the bright cue, and this was found even across the two shortest SOAs. However, this reflexive orienting was suppressed in both the bright side likely and dim side likely conditions: the advantage observed at the bright cue's location across the two shortest SOAs in the neutral condition was significantly attenuated in the two contingent conditions. Results point to rapid expectancy-based interference in the reflexive process of attention capture...|$|E
50|$|For color spaces such as XYZ, xyY, etc. {{the letter}} Y refers to <b>relative</b> <b>luminance.</b> No {{computation}} {{is required to}} find <b>relative</b> <b>luminance</b> when it is explicit in a color representation in such spaces.|$|R
5000|$|While luma is {{more often}} encountered, <b>relative</b> <b>luminance</b> is {{sometimes}} used in video engineering when referring to the brightness of a monitor. The formula used to calculate <b>relative</b> <b>luminance</b> uses coefficients based on the CIE color matching functions and the relevant standard chromaticities of red, green, and blue (e.g., the original NTSC primaries, SMPTE C, or Rec. 709). For the Rec. 709 primaries, the linear combination, based on pure colorimetric considerations and the definition of <b>relative</b> <b>luminance</b> is: ...|$|R
40|$| {{stimulus}} type, accurate <b>relative</b> <b>luminance</b> measurements. They were:|$|R
5000|$|... #Subtitle level 2: Relationship {{to value}} and <b>relative</b> <b>luminance</b> ...|$|R
40|$| compute: (1) screen gamma exponents and (2) <b>relative</b> <b>luminance</b> (Y/Yn) of|$|R
5000|$|Normalizing for <b>relative</b> <b>luminance</b> (i.e. set [...] ), the XYZ {{tristimulus values}} are ...|$|R
40|$|AbstractThe {{spectral}} {{sensitivity of the}} eye was investigated using reaction times to broadband chromatic stimuli over a range of background <b>luminances.</b> <b>Relative</b> sensitivity was determined from the nonlinear reaction time curve by converting reaction times to a linear measure that was independent of {{spectral sensitivity}}. Two models for mesopic spectral sensitivity were compared. The first was a linear combination of V(λ) and V′(λ), and the second included input from the L-M colour-opponent mechanism and the S-cones. The second model produced a significantly better fit to the data. The chromatic mechanisms appear to contribute to reaction time {{when there is an}} appreciable chromatic signal but luminance contrast is low...|$|R
50|$|Measurements of the <b>relative</b> <b>luminance</b> {{efficiency}} {{are typically}} largest and symmetric about some distance (dm), which is typically ranges from -0.2 to -0.5 mm, {{away from the}} center of the pupil towards the nasal side. The significance of the Stiles-Crawford effect is evident the drop of <b>relative</b> <b>luminance</b> efficiency by up to 90% for light entering near the edge of the pupil.|$|R
5000|$|... where Yb is the <b>relative</b> <b>luminance</b> of background, the [...] is the {{illuminance}} of {{the reference}} white in lux, LW {{is the absolute}} luminance of the reference white in cd/m2, and Yw is the <b>relative</b> <b>luminance</b> of the reference white in the adapting field. If unknown, the adapting field can be assumed to have average reflectance ("gray world" [...] assumption): [...]|$|R
50|$|The {{lightness}} correlate in CIELAB {{is calculated}} using the cube {{root of the}} <b>relative</b> <b>luminance.</b>|$|R
50|$|Note that <b>relative</b> <b>luminance</b> {{should not}} be {{confused}} with luma, the weighted sum of the nonlinear gamma-compressed R′G′B′ components. For color spaces that use luma, such as Y′UV or Y′CbCr (where Y′ represents luma), computation of <b>relative</b> <b>luminance</b> can still be done. The R′G′B′ components can be transformed into RGB linear components by undoing the gamma compression; these linear components can then be used to calculate luminance.|$|R
40|$|This article {{concentrates}} {{on the effects of}} surround <b>relative</b> <b>luminance</b> on the lightness contrast and chroma of images. It begins with a review of research on psychophysical scaling of brightness and lightness and the effects of background and surround <b>relative</b> <b>luminance</b> on lightness and chroma. Then the importance of this research for deviceindependent color imaging systems is described along with the prediction of these effects using the RLAB color-appearance model...|$|R
5000|$|... #Caption: Observe {{that the}} {{lightness}} is 50% for a <b>relative</b> <b>luminance</b> of around 18% {{relative to the}} reference white.|$|R
50|$|For L*a*b* space, the L* {{component}} is the lightness; a perceptual {{scale of the}} brightness as a nonlinear function of the <b>relative</b> <b>luminance</b> Y.|$|R
2500|$|... bit value 2: {{the image}} samples contain three {{channels}} of data encoding trichromatic colors, otherwise the image samples contain one channel of data encoding <b>relative</b> <b>luminance,</b> ...|$|R
5000|$|... 1933: Munsell, Sloan, and Godlove {{launch a}} study on the Munsell neutral value scale, {{considering}} several proposals relating the <b>relative</b> <b>luminance</b> to the Munsell value, and suggest: ...|$|R
5000|$|... where &eta; is the <b>relative</b> <b>luminance</b> efficiency, and d {{is defined}} as {{positive}} on the temporal side of the pupil and negative on the nasal side of the pupil.|$|R
40|$|The {{model is}} simple: For flicker {{luminance}} stimuli and maximum purity, the hue cycle's <b>relative</b> <b>luminance</b> (computed from CIE data) is reciprocal to relative saturation. Brightness/luminance ratio B/L {{is proportional to}} relative saturation S, i. e., B/L = 1. 5 S¹/⁴. S times B/L ratio gives relative saturation for brightness stimuli; just as <b>relative</b> <b>luminance</b> times B/L ratio gives brightness. Predictions for any purity agree with data on saturation discrimination, color appearance in CIE space, B/L, and CIE brightness Vb. Predictions support Hunt's concept of “colorfulness” and indicate its causal role in proporitionality of S and B/L. 14 page(s...|$|R
5000|$|For RGB color {{spaces that}} use the ITU-R BT.709 {{primaries}} (or sRGB, which defines the same primaries), <b>relative</b> <b>luminance</b> can be calculated from linear RGB components: first convert the gamma-compressed RGB values to linear RGB, and then ...|$|R
2500|$|Luminance (Y or Lv,Ω): The {{radiance}} weighted by {{the effect}} of each wavelength on a typical human observer, measured in SI units in candela per square meter (...) [...] Often the term luminance {{is used for the}} <b>relative</b> <b>luminance,</b> Y/Y'n, where Y'n is the luminance of the reference white point.|$|R
50|$|For other sets {{of primary}} {{chromaticities}} (defined by their x and y chromaticity coordinates), different linear coefficients {{are needed to}} get <b>relative</b> <b>luminance.</b> In general, the coefficients are all positive, the green coefficient is largest and blue smallest, and the three form the middle row of the RGB-to-XYZ color transformation matrix.|$|R
50|$|<b>Relative</b> <b>luminance</b> {{follows the}} {{photometric}} definition of luminance, {{but with the}} values normalized to 1 or 100 for a reference white. Like the photometric definition, it {{is related to the}} luminous flux density in a particular direction, which is radiant flux density weighted by the luminosity function (λ) of the CIE Standard Observer.|$|R
5000|$|... where p(&lambda;) is a {{wavelength}} {{dependent parameter}} {{which represents the}} magnitude of the Stiles-Crawford effect, with larger values of p corresponding to a stronger falloff in the <b>relative</b> <b>luminance</b> efficiency as a function of distance {{from the center of the}} pupil. Measurements indicate that the value of p(&lambda;) ranges from 0.05 to 0.08.|$|R
40|$|The {{specific}} grey shades in {{a visual}} scene {{can be derived}} from <b>relative</b> <b>luminance</b> values only when an anchoring rule is given. The anchoring theory of lightness (Gilchrist et al, 1999 Psychological Review 106 795 - 834) assumes that the highest luminance is perceived as white, and the appearance of all the other regions depends on their relationship to such white. It is thus a crucial prediction of the theory that equal regions representing <b>luminance</b> increments <b>relative</b> to their surrounds shall be perceived as identical. Our stimuli were incremental targets on two uniform surrounds placed side by side. We used the method of adjustment: observers varied the luminance of the test patch (set on a black surround) to match the achromatic colour of the comparison patch (set on a variable surround). We found that a target on a black surround looks always lighter than the same target on a more luminant surround. Previous failures to observe double-increment illusions may have been {{due to the fact that}} the strength of the effect rests on the specific luminances of the target and of the pair of surrounds chosen for the display...|$|R
25|$|When {{judging the}} <b>relative</b> <b>luminance</b> (brightness) of {{different}} colors in well-lit situations, humans tend to perceive light within the green parts of the spectrum as brighter than red or blue light of equal power. The luminosity function that describes the perceived brightnesses of different wavelengths is thus roughly analogous to the spectral sensitivity of M cones.|$|R
50|$|The signal {{value is}} 0.5 for the {{reference}} white level while the signal value for 1 has a <b>relative</b> <b>luminance</b> that is 12 {{times higher than}} the reference white level. ARIB STD-B67 has a nominal range of 0 to 12. HLG uses a logarithmic curve for the upper half of the signal values due to Weber's law.|$|R
50|$|When {{judging the}} <b>relative</b> <b>luminance</b> (brightness) of {{different}} colors in well-lit situations, humans tend to perceive light within the green parts of the spectrum as brighter than red or blue light of equal power. The luminosity function that describes the perceived brightnesses of different wavelengths is thus roughly analogous to the spectral sensitivity of M cones.|$|R
30|$|We {{fabricated}} Ag nanoparticle (NP) film {{in organic}} light emission diodes (OLEDs), and a 23 times increase in electroluminescence (EL) at 518  nm was probed by time-resolved EL measurement. The <b>luminance</b> and <b>relative</b> {{external quantum efficiency}} (REQE) were increased by 5.4 and 3.7 times, respectively. There comes a new energy transport way that localized surface plasmons (LSPs) would absorb energy that corresponds to the electron-hole pair before recombination, promoting the formation of electron-hole pair and exciting local surface plasmon resonance (LSPR). The extended lifetime of Alq 3 indicates the existence of strong interaction between LSPR and exciton, which decreases the nonradiative decay rate of OLEDs.|$|R
40|$|Detecting {{a target}} in a visible video is a {{challenge}} at times, as RGB sensors do capture color and correct <b>relative</b> <b>luminance,</b> but are under exposed and noisy. In the infrared band, visibility of the same target is better but they lack color and <b>relative</b> <b>luminance.</b> Frame by frame fusion of these two videos can be a solution but computationally expensive and thus impractical. For the video captured by fixed camera, the background can be extracted easily and fused with the moving target to save the computation. But if the camera is moving, then the extraction of the moving background is a big challenge. In this paper, we present an efficient multi spectral video visualization method using estimation of the background in motion. The analysis shows that the proposed method is superior compared to the existing methods quantitatively as well as visually. More importantly it is devised to use in real time {{to make it more}} practical...|$|R
5000|$|As well, the Rec. 709 luma {{coefficients}} may {{not necessarily}} provide better performance. Because {{of the difference between}} luma and <b>relative</b> <b>luminance,</b> luma does not exactly represent the luminance in an image. As a result, errors in chroma can affect luminance. Luma alone does not perfectly represent luminance; accurate luminance requires both accurate luma and chroma. Hence, errors in chroma [...] "bleed" [...] into the luminance of an image.|$|R
40|$|AbstractBistable apparent-movement {{displays}} {{were created}} using four {{different kinds of}} “second-order” stimuli in which figures were defined by binocular disparity, spatial phase shifts of periodic <b>luminance</b> distributions, <b>relative</b> motion, and texture-element orientation differences. For each display, characteristics of the local structure of the figures, backgrounds, or both were varied. For each experimental condition, the type of apparent movement seen {{as a function of}} interstimulus interval was measured, and {{it was found that the}} relationship between perceived apparent movement and interstimulus interval differed across the types of displays viewed. The results suggest that the transformations between first-order stimulus properties and second-order motion may be too complex to imply a single uniform class of second-order motion detectors. Alternative physiological accounts of the results are discussed...|$|R
50|$|A major {{exception}} to this rule should be applied when opaque spot colors are used. Other colors, regardless of the <b>relative</b> <b>luminance,</b> should always be trapped to (spread under) these spot colors. If several of these spot colors are used (a common practice in the packaging market), {{it is not the}} luminance of the color but the order of printing that will be the decisive element: the first color to be printed should always spread under the next color.|$|R
5000|$|Note. - Munsell's V {{runs from}} 0 to 10, while Y {{typically}} runs from 0 to 100 (often {{interpreted as a}} percentage). Typically, the <b>relative</b> <b>luminance</b> is normalized so that the [...] "reference white" [...] (say, magnesium oxide) has a tristimulus value of Y = 100. Since the reflectance of magnesium oxide (MgO) relative to the perfect reflecting diffuser is 97.5%, V = 10 corresponds to Y = 100/97.5% ≈ 102.6 if MgO is used as the reference.|$|R
5000|$|In principle, {{one wants}} to scale all <b>relative</b> <b>luminances</b> in an image so that objects which are {{believed}} to be neutral appear so. If, say, a surface with [...] was believed to be a white object, and if 255 is the count which corresponds to white, one could multiply all red values by 255/240. Doing analogously for green and blue would result, at least in theory, in a color balanced image. In this type of transformation the 3x3 matrix is a diagonal matrix.|$|R
