46|1818|Public
5000|$|<b>Load</b> <b>Memory</b> Scan (LMS) - Sets the {{starting}} address of graphics/character data (3-byte instruction) ...|$|E
5000|$|Memory reference: access memory if needed. If {{instruction}} is load, data returns from memory and {{is placed in}} the LMD (<b>load</b> <b>memory</b> data) register ...|$|E
50|$|The {{environment}} can be configured and monitored through a web-based administration interface. A farm can include multiple application servers, running {{a mix of}} Linux, Windows and Web servers, and the administrator can configure load balancing between them based on criteria such as processor <b>load,</b> <b>memory</b> usage, number of open sessions or random distribution. Ulteo states that a single farm can serve up to 50,000 users and more.|$|E
40|$|The {{influence}} of working <b>memory</b> <b>load</b> on visual selective attention was examined using a dual selective attention and working memory task. This dual task required participants to ignore distractor faces while categorizing superimposed celebrity names under low or high <b>memory</b> <b>loads.</b> Surprisingly, both <b>memory</b> <b>load</b> conditions produced equivalent interference effects from concurrent famous (compared to anonymous) distractor faces, and equivalent subsequent negative priming effects. These findings were consistent across {{all four of}} the present experiments, but they diverge from the dual-task <b>memory</b> <b>load</b> literature on interference and negative priming. Implications regarding the interaction between working memory and attentional selection are addressed...|$|R
50|$|There are {{accessories}} for the Disney Mix Stick sold separately. Customers {{can purchase}} a docking station with speakers, wall charger, {{two different types}} of headphones, carrying cases, and preloaded memory cards. The pre <b>loaded</b> <b>memory</b> cards, called Mix Clips, go right into the top memory slot.|$|R
40|$|We {{recorded}} ERPs {{to investigate}} whether the visual <b>memory</b> <b>load</b> can bias visual selective attention. Participants memorized one or four letters and then responded to memory-matching letters presented in a relevant color while ignoring distractor letters or letters in an irrelevant color. Stimuli in the relevant color elicited larger frontal selection positivities (FSP) and occipital selection negativities (OSN) compared to irrelevant color stimuli. Only distractors elicited a larger FSP in the high than in the low <b>memory</b> <b>load</b> task. <b>Memory</b> <b>load</b> prolonged the OSN for all letters. Response mapping complexity was also modulated but {{did not affect the}} FSP and OSN. Together, the FSP data suggest that high <b>memory</b> <b>load</b> increased distractability. The OSN data suggest that <b>memory</b> <b>load</b> sustained attention to letters in a relevant color until working memory processing was completed, independently of whether the letters were in working memory or not...|$|R
50|$|The Z80 has six new LD {{instructions}} that can load the DE, BC, and SP register pairs from memory, and <b>load</b> <b>memory</b> from these three register pairs -- unlike the 8080. As on the 8080, load instructions do {{not affect the}} flags (except for the special purpose I and R register loads). A quirk (common with the 8080) of the register-to-register load instructions is {{that each of the}} 8-bit registers can be loaded from themselves (e.g. LD A,A). This is effectively a NOP.|$|E
5000|$|One {{advantage}} to magnetic amplifiers {{is that they}} are open in the center and several input lines can be threaded through them. This makes it easy to implement chains of [...] "OR" [...] logic by threading a single core with all the inputs that need to be ORed together. This was widely used in the [...] "best two out of three" [...] circuits that were widely used in binary adders, which could reduce the component count of the ALU considerably. This was known as [...] "Ballot Box Logic" [...] due to the way the inputs [...] "voted" [...] on the output. Another way to use this feature was to use the same cores for different duties during different periods of the machine cycle, say to <b>load</b> <b>memory</b> during one portion and then as part of an adder in another. Each of the cores could be used for as many duties as there was room for wiring through the center.|$|E
50|$|The Memory Scan Register, a {{register}} addressing the data {{stored in the}} screen memory, is 16-bit, but only the lower 12 bits change when ANTIC is sequentially scanning the video memory. This means the Display List requires a Mode line instruction including the LMS (<b>Load</b> <b>Memory</b> Scan) option where screen memory crosses a 4K boundary. ANTIC's graphic modes E and F require more than 7.5K of screen memory for a full screen display. The Display Lists for these displays require the LMS option added to a Mode instruction near {{the middle of the}} display where screen memory crosses the 4K boundary. Note that the 4K boundary cannot be crossed within the middle of a Graphics Mode line. The 4K boundary address can only be crossed between the end of one Mode line {{and the beginning of the}} next line. In other words, the memory for the previous Mode line ends at the exact last byte of the 4K block and the next Mode line begins at the exact first byte on the other side of the 4K boundary.|$|E
40|$|Four {{experiments}} {{were conducted to}} determine whether the increased reaction time produced by <b>loading</b> <b>memory</b> with a set of irrelevant items depended on the complexity of the stage structure or of the stimulus-response (S-R) mapping rules underlying the task. In each experiment, reaction-time tasks varying in complexity were performed alone and in the retention interval of a short-term memory task requiring ordered recall of eight digits. Experiment 1 compared simple, choice, and go/no-go tasks over 3 days of practice and found no interaction between <b>memory</b> <b>load</b> and task complexity. Experiment 2 replicated the first day of Experiment 1 with more power and again found no interaction. Since the different tasks required different numbers of stages, this ruled out stage structure as a factor <b>loading</b> <b>memory.</b> However, in Experiment 1 and 2, the same subjects performed all three tasks with the same set of letters and may have developed one comprehensive set of mapping rules for all three tasks, essentially eliminating differences in memory demands between tasks. Experiment 3 used different groups of subject...|$|R
5000|$|... <b>load</b> data Contains <b>memory</b> <b>load</b> data.load request Request for <b>memory</b> <b>load</b> segment.load w/addr <b>Memory</b> <b>load</b> with {{transfer}} address.load w/addr Parameter load with transfer address.service req Request {{for assistance}} with dump operation.dump request Request for next memory dump segment.dump data Contains memory dump data.completed Acknowledgment of dump completion.assist Offer of dump/load/loop assistance.program Request for system or loader program.boot request Request for boot program.ID reqst Request for remote console identification.system ID Remote console identification information.request Request for communication information counters.reply Communication information counters.console Remote console in reserved state.console Release of remote console from reserved state.console poll Poll of remote console for status.console rply Response to remote console poll.request Request to loopback enclosed data.reply Response to loopback request with data.|$|R
50|$|In {{processor}} mode cores are on and executing code {{from the}} system memory and programmed I/O (inputs and outputs) through the system which {{is connected to the}} system board FPGA. <b>Loading</b> <b>memory</b> and configuring the processor for bootstrapping (sustaining after the initial load) is currently done by software running on the SCC's management console that's embedded in the chip.|$|R
40|$|International audienceThe Border Gateway Protocol propagates routing {{information}} accross the Internet in an incremental manner. It only advertises to its peers changes in routing. However, {{as early as}} 1998, observations have been made of BGP announcing the same route multiple times, causing router CPU <b>load,</b> <b>memory</b> usage and convergence time higher than expected. In this paper, by performing controlled experiments, we pinpoint multiple causes of duplicates, ranging {{from the lack of}} full RIB-Outs to the discrete processing of update messages...|$|E
40|$|Wireless {{sensor network}} (WSN) {{applications}} are notoriously difficult {{to develop and}} debug. This paper describes Clairvoyant which is a comprehensive source-level debugger for wireless, embedded networks. With Clairvoyant, a developer can wirelessly connect to a sensor network and execute standard debugging commands including break, step, watch, and backtrace, {{as well as new}} commands that are specially designed for debugging WSNs. Clairvoyant attempts to minimize its effect on the program being debugged in terms of network <b>load,</b> <b>memory</b> footprint, execution speed, clock consistency, and flash lifetime. Categories and Subject Descriptor...|$|E
40|$|Bottlenecks in high {{performance}} networking {{are difficult to}} pinpoint. In this report we try to identify which software and hardware parameters are the cause for these bottlenecks. The focus on this study is on the end points and not the link itself. It is shown that CPU <b>load,</b> <b>memory</b> swapping, bus speeds, MTUs and buffer sizes are parameters that cause {{the most of the}} performance issues. Further, we developed a performance measurement tool that gathers data from both end points, combines this information and gives a clear overview of the measured values for th...|$|E
5000|$|This {{method is}} invoked {{only when the}} servlet is first <b>loaded</b> into <b>memory.</b>|$|R
40|$|Load Theory (Lavie, 1995, 2005) {{states that}} the level of perceptual load in a task (i. e.,the amount of {{information}} involved in processing task-relevant stimuli) determines the efficiency of selective attention. There is evidence that perceptual load affects distractor processing, with increased inattentional blindness under high load. Given that high load can result in individuals failing to report seeing obvious objects, it is conceivable that load may also impair memory for the scene. The current study is the first to assess the effect of perceptual <b>load</b> on eyewitness <b>memory.</b> Across three experiments (two video-based and one in a driving simulator), the effect of perceptual <b>load</b> on eyewitness <b>memory</b> was assessed. The results showed that eyewitnesses were less accurate under high load, in particular for peripheral details. For example, memory for the central character in the video was not affected by <b>load</b> but <b>memory</b> for a witness who passed by the window {{at the edge of the}} scene was significantly worse under high <b>load.</b> High <b>load</b> <b>memories</b> were also more open to suggestion, showing increased susceptibility to leading questions. High visual perceptual load also affected recall for auditory information, illustrating a possible cross-modal perceptual <b>load</b> effect on <b>memory</b> accuracy. These results have implications for eyewitness memory researchers and forensic professionals...|$|R
40|$|The {{effect of}} <b>memory</b> <b>load</b> in visual search {{has shown a}} high {{heterogeneity}} of results: while some researchers have found an impairment of performance under high <b>memory</b> <b>load</b> conditions (eg. Lavie & De Fockert, 2006), others have found no effect of <b>memory</b> <b>load</b> (eg. Woodman, Vogel & Luck, 2001), and even others have found an improvement of performance under high <b>memory</b> <b>load</b> conditions (Smilek, Enns, Eastwood, & Merikle, 2006). In the present research we propose {{that the relationship between}} the material retained in working memory (WM) in a secondary <b>memory</b> <b>load</b> task and the target and distractors involved in the visual search task might be a key factor for explaining the discrepancies in the results. We tested our hypothesis manipulating that relationship in four experiments. The results show that the relationships between the material in WM and the target and distractors in the attentional task may be a crucial factor in modulating the effect of <b>memory</b> <b>load</b> in visual search. If the items retained in WM are similar to those presented as targets in the attentional task, visual search performance improves under high <b>memory</b> <b>load</b> conditions. On the contrary, if the items retained in WM are similar to those employed as distractors in the visual search task, there is no modulation of <b>memory</b> <b>load</b> in visual search. Finally, we discuss the theoretical implications {{in the context of the}} endogenous and exogenous attentional processes involved in visual search. The effect of <b>memory</b> <b>load</b> in attention is one key topic in the study of attentional processes. Specifically, in Visual Search (VS) tasks a variety of results have been found. Some of the evidence supports the assumption that as <b>memory</b> <b>load</b> increases, attention to relevant material is impaire...|$|R
40|$|Abstract. This paper {{examines}} global context classification in peer-topeer ad-hoc mobile wireless networks (P 2 P-MANETs). To begin, {{circumstances are}} presented in which such systems {{would be required to}} classify a global context. These circumstances are expounded upon by presenting concrete scenarios from which a set of requirements are derived. Using these requirements, related work is evaluated for applicability, indicating no adequate solutions. Algorithmic approaches are proposed, and analysis results in a benchmark as well as bounds for distribution of processing <b>load,</b> <b>memory</b> consumption and message passing in P 2 P-MANETs...|$|E
40|$|The {{complexity}} {{and size of}} software are increasing at a rapid rate. This results in the increase in build time and execution times. Cluster computing {{is proving to be}} an effective way to reduce this in an economical way. Currently, most available cluster computing software tools which achieve load balancing by process migration schemes, do not consider all characteristics such as CPU <b>load,</b> <b>memory</b> usage, network bandwidth usage during migration. For instance, Mosix, a cluster computing software tool for Linux, does not consider network bandwidth usage and neither does it consider CPU usage and memory characteristics together. In this paper we present the infrastructure for efficient load balancing on Mosix cluster through intelligent scheduling techniques...|$|E
40|$|This {{final report}} {{summarizes}} {{the work on}} the design of a fault tolerant digital computer for aircraft. Volume 2 is composed of two parts. Part 1 is concerned with the computational requirements associated with an advanced commercial aircraft. Part 2 reviews the technology that will be available for the implementation of the computer in the 1975 - 1985 period. With regard to the computation task 26 computations have been categorized according to computational <b>load,</b> <b>memory</b> requirements, criticality, permitted down-time, and the need to save data in order to effect a roll-back. The technology part stresses the impact of large scale integration (LSI) on the realization of logic and memory. Also considered was module interconnection possibilities so as to minimize fault propagation...|$|E
2500|$|In the 8-bit versions, while running, the CP/M {{operating}} system <b>loaded</b> into <b>memory</b> had three components: ...|$|R
5000|$|... "I, 0" [...] {{specifies}} {{that the}} actual address is to be <b>loaded</b> from <b>memory</b> location 0 ...|$|R
5000|$|... (Clear and Add): The Accumulator A is <b>loaded</b> from <b>memory.</b> The {{contents}} of memory remain unchanged.|$|R
30|$|Load Migration. If {{a server}} becomes {{overloaded}} by any metric, e.g., cpu <b>load,</b> <b>memory</b> usage, disk IO or network IO, {{this can be}} remedied by migrating some of the load to other servers with more available capacity. This {{can be done by}} either process migration or live VM migration. Clearly the overhead of either migration technique would limit how quickly service levels could be effectively re-established. Process migration may take less time since a smaller memory volume may have to be transferred, but migrating entire VMs allows sets of processes to be transferred. While migration can be done without interaction with the running application, the application is “down” during the migration. Hence, migration itself may precipitate, or contribute to, an SLA violation. Some clouds currently support live VM migration.|$|E
40|$|With the {{advances}} of network and communication technology, real time {{audio and video}} streaming services are becoming progressively popular over the Internet. In order to enable universal access of multimedia streaming content and thus the desired end-to-end QoS, it is very desirable to design a video server. A video server, that can dynamically coupled to dierent streaming engines and deployed in a test bed for conducting dierent streaming experiments. In this thesis we present {{the design of a}} video server that implement an agnostic" experiments using dierent engines. Proposed video server is also deployed in a test bed for evaluating dierent performance measurement parameters like CPU <b>load,</b> <b>memory</b> utilization etc. The results of test bed also support our proposed idea and unfold many opportunities for the research community to perform dierent multimedia streaming experiments with proposed video server. "engine-abstraction that will help to automate and repeat deterministic streamin...|$|E
40|$|Cloud {{computing}} is {{an emerging}} technology in parallel and distributed computing which requires {{large amount of}} infrastructure and resources. To optimally {{serve the needs of}} the clients all over the world, their providers have leveraged data centres at different geographical locations. Load Balancing {{is one of the key}} issue in cloud computing. A load can be a CPU <b>load,</b> <b>memory</b> capacity or network load. It is the process of distributing workload equally on all servers in order to improve resource utilization and response time. Such algorithms mainly aim at ignoring a state where some nodes are heavily loaded while others are lightly loaded or idle. In my presented work, comparative study of Round Robin, Honey Bee Foraging and Genetic Algorithm is conducted and is evaluated using CPU utilization time. The proposed Algorithm SOM (Self Organizing Map) provides optimum and efficient scheduling with low resource consumption and it is simulated using CloudSim...|$|E
5000|$|In the 8-bit versions, while running, the CP/M {{operating}} system <b>loaded</b> into <b>memory</b> had three components: ...|$|R
5000|$|When {{launched}} with administrator privileges, {{the program}} <b>load</b> in <b>memory</b> two files containing the attackers' demands : ...|$|R
40|$|Working {{memory is}} a limited resource: brains can only {{maintain}} small amounts of sensory input (<b>memory</b> <b>load)</b> over {{a brief period of}} time (memory decay). The dynamics of slow neural oscillations as recorded using magneto- and electroencephalography (M/EEG) provide a window into the neural mechanics of these limitations. Especially oscillations in the alpha range (8 – 13 Hz) are a sensitive marker for <b>memory</b> <b>load.</b> Moreover, according to current models, the resultant working <b>memory</b> <b>load</b> is determined by the relative noise in the neural representation of maintained information. The auditory domain allows memory researchers to apply and test the concept of noise quite literally: Employing degraded stimulus acoustics increases <b>memory</b> <b>load</b> and, at the same time, allows assessing the cognitive resources required to process speech in noise in an ecologically valid and clinically relevant way. The present review first summarizes recent findings on neural oscillations, especially alpha power, and how they reflect <b>memory</b> <b>load</b> and <b>memory</b> decay in auditory working memory. The focus is specifically on <b>memory</b> <b>load</b> resulting from acoustic degradation. These findings are then contrasted with contextual factors that benefit neural as well as behavioral markers of memory performance, by reducing representational noise. We end on discussing the functional role of alpha power in auditory working memory and suggest extensions of the current methodological toolkit...|$|R
40|$|Computational Grids are {{becoming}} attractive and promising platforms for solving large-scale (problem solving) applications of multi-institutional interest. When using Grid, Usage {{of the most}} suitable autonomous system to execute job {{is the best way}} to using Grid. However, the management of resources and scheduling computations in the Grid environment is a complex undertaking as they are (geographically) distributed, heterogeneous in nature, owned by different individuals or organizations with their own policies, different access and cost models, and have dynamically varying loads and availability. These problems lead to the difficulty of discovering the most suitable autonomous system in Grid. In this paper, we propose a new heuristic scheduling algorithm on the Grid called K-Windows. Using on real system, we demonstrate that K- Windows can achieve better performance than the other heuristics. We also study the impact of cpu <b>load,</b> <b>memory</b> usage and task remaining on scheduling...|$|E
40|$|Traditionally in a now each user {{works on}} his {{workstation}} independently of other users. So, {{it is possible}} that a user needs more resources than those offered by his workstation, whereas the resources of other workstations may be under-used. This paper presents the design of two integrated mechanisms which efficiently use the physical memories and processors of a now to improve the application performance. Integrated memory and processor management allows to define a policy to choose process or data migration according to machine <b>load,</b> <b>memory</b> occupation, and process data access pattern. Computational intensive applications which require large amounts of data may be executed efficiently in a now thanks to this strategy. 1 Introduction A lot of computing environments nowadays consist of several workstations communicating through a high speed network such as ATM. In these environments, called now (Networks of Workstations), each user works on his workstation independently of the other [...] ...|$|E
40|$|Subscription pruning {{has been}} proven as {{valuable}} routing optimization for Boolean subscriptions in publish/ subscribe systems. It aims at optimizing subscriptions independently {{of each other and}} is thus applicable for all kinds of subscriptions regardless of their individual and collective structures. The original subscription pruning approach tries to optimize the event routing process based on the expected increase in network load. However, a closer look at pruning-based routing reveals its further applicability to optimizations in respect to other dimensions. In this paper, we introduce and investigate subscription pruning based on three dimensions of optimization: network <b>load,</b> <b>memory</b> usage, and system throughput. We present the algorithms to perform prunings based on these dimensions and discuss the results of a series of practical experiments. Our analysis reveals {{the advantages and disadvantages of}} the different dimensions of optimization and allows conclusions about the suitability of dimension-based pruning for different application requirements...|$|E
40|$|AbstractParticipants’ eye-movements were {{monitored}} {{while they}} {{searched for a}} target among a varying number of distractors either {{with or without a}} concurrent <b>memory</b> <b>load.</b> Consistent with previous findings, adding a <b>memory</b> <b>load</b> slowed response times without affecting search slopes; a finding normally taken to imply that <b>memory</b> <b>load</b> affects pre- and/or post-search processes but not the search process itself. However, when overall response times were decomposed using eye-movement data into pre-search (e. g., initial encoding), search, and post-search (e. g., response selection) phases, analysis revealed that adding a <b>memory</b> <b>load</b> affected all phases, including the search phase. In addition, we report that fixations selected under load {{were more likely to be}} distant from search items, and more likely to be close to previously inspected locations. Thus, <b>memory</b> <b>load</b> affects the search process without affecting search slopes. These results challenge standard interpretations of search slopes and main effects in visual search...|$|R
50|$|In an {{experimental}} study done by Eder, Fiedler and Hamm-Eder (2011), {{the effects of}} working-memory capacity on illusory correlations were investigated. They first looked at the individual differences in working memory, and then looked {{to see if that}} had any effect on the formation of illusory correlations. They found that individuals with higher working memory capacity viewed minority group members more positively than individuals with lower working memory capacity. In a second experiment, the authors looked into the effects of <b>memory</b> <b>load</b> in working <b>memory</b> on illusory correlations. They found that increased <b>memory</b> <b>load</b> in working <b>memory</b> led to an increase in the prevalence of illusory correlations. The experiment was designed to specifically test working memory and not substantial stimulus memory. This means that the development of illusory correlations was caused by deficiencies in central cognitive resources caused by the <b>load</b> in working <b>memory,</b> not selective recall.|$|R
50|$|A {{bitmap image}} file <b>loaded</b> into <b>memory</b> becomes a DIB data {{structure}} - {{an important component}} of the Windows GDI API. The in-memory DIB data structure is almost the same as the BMP file format, but it does not contain the 14-byte bitmap file header and begins with the DIB header. For DIBs <b>loaded</b> in <b>memory,</b> the color table can also consist of 16-bit entries that constitute indexes to the currently realized palette (an additional level of indirection), instead of explicit RGB color definitions. In all cases, the pixel array must begin at a memory address that is a multiple of 4 bytes. In non-packed DIBs <b>loaded</b> in <b>memory,</b> the optional color profile data should be located immediately after the color table and before the gap1 and pixel array (unlike in diag. 1).|$|R
