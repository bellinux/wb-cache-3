0|10000|Public
5000|$|Uncertainty: the consumer's {{subjective}} assessment <b>of</b> the <b>likelihood</b> <b>of</b> <b>occurrence</b> ...|$|R
40|$|Two {{probabilistic}} {{approaches for}} assessing performance are presented. The first approach assesses {{probability of failure}} by simultaneously modeling all likely events. The probability each event causes failure along with the event's <b>likelihood</b> <b>of</b> <b>occurrence</b> contribute to the overall probability of failure. The second assessment method is based on stochastic sampling using an influence diagram. Latin-hypercube sampling is used to stochastically assess events. The overall probability of failure is taken as the maximum probability of failure of all the events. The <b>Likelihood</b> <b>of</b> <b>Occurrence</b> simulation suggests failure does not occur while the Stochastic Sampling approach predicts failure. The <b>Likelihood</b> <b>of</b> <b>Occurrence</b> results are used to validate finite element predictions...|$|R
50|$|Below {{table lists}} all 39 {{possible}} hand patterns, their probability <b>of</b> <b>occurrence,</b> {{as well as}} the number of suit permutations for each pattern. The list is ordered according to <b>likelihood</b> <b>of</b> <b>occurrence</b> <b>of</b> the hand patterns.|$|R
50|$|Hazard {{assessment}} - {{identification and}} mapping of geologic hazards and estimates of potential consequences and <b>likelihood</b> <b>of</b> <b>occurrence.</b>|$|R
40|$|This paper {{demonstrates}} {{the use of}} appropriate consequence evaluation criteria in conjunction with generic <b>likelihood</b> <b>of</b> <b>occurrence</b> data to produce consistent hazard analysis results for nonreactor nuclear facility Safety Analysis Reports (SAR). An additional objective is to demonstrate the use <b>of</b> generic <b>likelihood</b> <b>of</b> <b>occurrence</b> data {{as a means for}} deriving defendable accident sequence frequencies, thereby enabling the screening of potentially incredible events (< 10 - 6 per year) from the design basis accident envelope. Generic <b>likelihood</b> <b>of</b> <b>occurrence</b> data has been used successfully in performing SAR hazard and accident analyses for two nonreactor nuclear facilities at Sandia National Laboratories. DOE-STD- 3009 - 94 addresses and even encourages use of a qualitative binning technique for deriving and ranking nonreactor nuclear facility risks. However, qualitative techniques invariably lead to reviewer requests for more details associated with consequence or <b>likelihood</b> <b>of</b> <b>occurrence</b> bin assignments in the text of the SAR. Hazard analysis data displayed in simple worksheet format generally elicits questions about not only the assumptions behind the data, but also the quantitative bases for the assumptions themselves (“engineering judgment ” may not be considered sufficient by some reviewers). This is especially true where the criteria for “qualitative ” binning <b>of</b> <b>likelihood</b> <b>of</b> <b>occurrence</b> involves numerical ranges. Oftentimes reviewers want to see calculations or at least a discussion of event frequencies or failure probabilities to support <b>likelihood</b> <b>of</b> <b>occurrence</b> bin assignments. This may become a significant point of contention for events that have been binned as incredible. This paper will show how the use of readily available generic data can avoid many of the reviewer questions that will inevitably arise from strictly qualitative analyses, while not significantly increasing the overall burden on the analyst...|$|R
30|$|To {{investigate}} {{a little bit}} further this issue, we briefly sketch the proof of Theorem 1, at least in the stationary case and deduce from it a preliminary result on the <b>likelihood</b> <b>of</b> <b>occurrence</b> <b>of</b> the Simpson’s Paradox.|$|R
50|$|For {{categorical}} and multinomial distributions, the fitted {{values are}} an (M + 1)-vector of probabilities, with the property that all probabilities {{add up to}} 1. Each probability indicates the <b>likelihood</b> <b>of</b> <b>occurrence</b> <b>of</b> one of the M + 1 possible values.|$|R
30|$|Prediction Markets {{are based}} on the {{principle}} that predictions about any future event can be traded like a stock or option on a virtual market. The current value of such predictions can then be used as an indicator for their future <b>likelihood</b> <b>of</b> <b>occurrence.</b> One major drawbacks with prediction markets as Foresight tools is that they cannot depict anything but the <b>likelihood</b> <b>of</b> <b>occurrence.</b> Other quantitative data such as “desirability”, “impact” or “relevance” can hardly be traded and are therefore inaccessible on prediction markets.|$|R
40|$|Vibrio vulnificus, an estuarine bacterium, is the causative {{agent of}} seafood-related gastroenteritis, primary septicemia, and wound infections worldwide. It occurs {{as part of}} the normal {{microflora}} of coastal marine environments and can be isolated from water, sediment, and oysters. Hindcast prediction was undertaken to determine spatial and temporal variability in the <b>likelihood</b> <b>of</b> <b>occurrence</b> <b>of</b> V. vulnificus in surface waters of the Chesapeake Bay. Hindcast predictions were achieved by forcing a multivariate habitat suitability model with simulated sea surface temperature and salinity in the Bay for the period between 1991 and 2005 and the potential hotspots <b>of</b> <b>occurrence</b> <b>of</b> V. vulnificus in the Chesapeake Bay were identified. The <b>likelihood</b> <b>of</b> <b>occurrence</b> <b>of</b> V. vulnificus during high and low rainfall years was analyzed. From results of the study, it is concluded that hindcast prediction yields an improved understanding of environmental conditions associated with <b>occurrence</b> <b>of</b> V. vulnificus in the Chesapeake Bay...|$|R
30|$|Basically, risk {{register}} consists of brief description {{about the risks}} associated with the project, its likelihood and impact on the project. Risk register may be qualitative or it may be quantitative. Qualitative {{risk register}} is the one where the <b>likelihood</b> <b>of</b> <b>occurrence</b> <b>of</b> risk are estimated by ranking them as “high” to “low”. On the other hand, if the <b>likelihood</b> <b>of</b> <b>occurrence</b> is put in the form of probabilistic number then it is known as quantitative risk register. In this research both qualitative as well as quantitative analysis has been carried out. Risk register starts with the identification of risk.|$|R
40|$|This paper {{demonstrates}} a structured method of ranking the performance risks of distressed reinforced concrete bridges. Fault tree analysis {{has been used}} to model the <b>likelihood</b> <b>of</b> <b>occurrence</b> <b>of</b> major distress mechanisms. This model can be used to identify the important risks for particular bridge components and their relative severity and to rank the performance trends of bridges...|$|R
50|$|In other {{countries}} such as the UK, nuclear plants have not been claimed to be absolutely safe. It is instead claimed that a major accident has a <b>likelihood</b> <b>of</b> <b>occurrence</b> lower than (for example) 0.0001/year.|$|R
5000|$|A {{documented}} uniform {{method of}} assessing potential failure mechanisms, failure modes {{and their impact}} on system operation, resulting in a list of failure modes ranked according to the seriousness of their system impact and <b>likelihood</b> <b>of</b> <b>occurrence.</b>|$|R
5000|$|... the <b>likelihood</b> (probability) <b>of</b> <b>occurrence</b> <b>of</b> each consequence.|$|R
5|$|Risk is a {{combination}} of hazard, vulnerability and <b>likelihood</b> <b>of</b> <b>occurrence,</b> which can be the probability of a specific undesirable consequence of a hazard, or the combined probability of undesirable consequences of all the hazards of an activity.|$|R
50|$|Hazard and {{vulnerability}} interact with <b>likelihood</b> <b>of</b> <b>occurrence</b> to create risk, {{which can be}} {{the probability of a}} specific undesirable consequence of a specific hazard, or the combined probability of undesirable consequences of all the hazards of a specific activity.|$|R
50|$|Risk is a {{combination}} of hazard, vulnerability and <b>likelihood</b> <b>of</b> <b>occurrence,</b> which can be the probability of a specific undesirable consequence of a specific hazard, or the combined probability of undesirable consequences of all the hazards of a specific activity.|$|R
40|$|Discrete {{subgroups of}} random Möbius transformations are {{investigated}} using computational methods together with collateral mathematical analysis. The main results include quantification <b>of</b> the <b>likelihood</b> <b>of</b> <b>occurrence</b> <b>of</b> two generator discrete groups and {{studies of the}} sharpness of the Hadamard inequality for random matrices and of the scale invariance for the domain of definition for matrix entry distributions derived by normalisation of matrices in GL(2,C) to SL(2,C) ...|$|R
5|$|In these {{compliance}} models {{the possibility}} of entities breaking a law has both a <b>likelihood</b> <b>of</b> <b>occurrence</b> and a consequence <b>of</b> <b>occurrence,</b> known as a 'risk event'. Considering entities' <b>likelihood</b> <b>of</b> not complying {{and the consequences of}} their not complying usually provides a 'power distribution' of a few large consequence or higher likelihood clients and many more lower consequence/likelihood ones.|$|R
30|$|Mitigation {{correction}} assessment: In {{this phase}} if applying the mitigation leads to fault in the behavioral properties or due to incorrect mitigation then {{changes can be}} made by going back to previous phase and redesign the mitigations. After applying mitigation, if there is chance <b>of</b> <b>likelihood</b> <b>of</b> <b>occurrence</b> <b>of</b> risks then it can be redirected back to risk assessments phase in threat analysis to minimize threat affect in nets.|$|R
50|$|Consequences are {{expressed}} numerically (e.g., {{the number of}} people potentially hurt or killed) and their <b>likelihoods</b> <b>of</b> <b>occurrence</b> {{are expressed}} as probabilities or frequencies (i.e., the number <b>of</b> <b>occurrences</b> or the probability <b>of</b> <b>occurrence</b> per unit time). The total risk is the expected loss: the sum of the products of the consequences multiplied by their probabilities.|$|R
5000|$|The {{probability}} or <b>likelihood</b> <b>of</b> its <b>occurrence</b> {{rated on}} an integer scale ...|$|R
50|$|The {{standard}} advises that 'Either qualitative or quantitative hazard {{and risk}} analysis techniques may be used' and offers guidance {{on a number of}} approaches. One of these, for the qualitative analysis of hazards, is a framework based on 6 categories <b>of</b> <b>likelihood</b> <b>of</b> <b>occurrence</b> and 4 <b>of</b> consequence.|$|R
40|$|Methods, computer-readable media, {{and systems}} for {{automatically}} performing Human Factors Process Failure Modes and Effects Analysis for a process are provided. At least one task {{involved in a}} process is identified, where the task includes at least one human activity. The human activity is described using at least one verb. A human error potentially resulting from the human activity is automatically identified, the human error {{is related to the}} verb used in describing the task. A <b>likelihood</b> <b>of</b> <b>occurrence,</b> detection, and correction of the human error is identified. The severity of the effect of the human error is identified. The <b>likelihood</b> <b>of</b> <b>occurrence,</b> and the severity of the risk of potential harm is identified. The risk of potential harm is compared with a risk threshold to identify the appropriateness of corrective measures...|$|R
50|$|For {{categorical}} and multinomial distributions, the parameter to {{be predicted}} is a K-vector of probabilities, with the further restriction that all probabilities must {{add up to}} 1. Each probability indicates the <b>likelihood</b> <b>of</b> <b>occurrence</b> <b>of</b> one of the K possible values. For the multinomial distribution, and for the vector form of the categorical distribution, the expected values {{of the elements of}} the vector can be related to the predicted probabilities similarly to the binomial and Bernoulli distributions.|$|R
5000|$|... {{the global}} rarity {{of the species}} and the <b>likelihood</b> <b>of</b> its <b>occurrence</b> in Britain ...|$|R
40|$|The {{concept of}} the {{ecological}} niche relates a set of environmental variables to the fitness of species, while habitat suitability models (HSMs) relate environmental variables to the <b>likelihood</b> <b>of</b> <b>occurrence</b> <b>of</b> the species. In spite of this relationship, the concepts are weakly linked in the literature, {{and there is a}} strong need for better integration. 2. We selectively reviewed the literature for habitat suitability studies that directly addressed four common facets of niche theory: niche characteristics, niche interactions, community-wide processes and niche evolution...|$|R
40|$|Vibrio vulnificus, is an {{ubiquitous}} bacterium which primarily causes seafood related gastroenteritis, primary septicemia, {{and wound}} infections worldwide. It occurs {{as part of}} the normal micro-flora in the coastal marine environment and has been frequently isolated from water, sediment and oysters. A hindcast prediction study was undertaken to determine the <b>likelihood</b> <b>of</b> <b>occurrence</b> <b>of</b> V. vulnificus in the surface waters of Chesapeake Bay. Hindcast predictions were achieved by forcing a multivariate habitat suitability model with simulated sea surface temperature and salinity in the Bay. Predictions <b>of</b> V. vulnificus <b>occurrence</b> were generated for the period between 1991 and 2005. Potential hotspots <b>of</b> <b>occurrence</b> <b>of</b> V. vulnificus in Chesapeake Bay were identified. The <b>likelihood</b> <b>of</b> V. vulnificus <b>occurrence</b> during wet and dry years was analyzed. Hindcast prediction can provide {{a better understanding of the}} environmental conditions optimal for <b>occurrence</b> <b>of</b> V. vulnificus in Chesapeake Bay...|$|R
40|$|Planned {{emissions}} and unplanned {{incidents in the}} marine environment {{have the potential to}} result in adverse environmental effects if a discharge of hazardous material or release of energy comes into contact with sensitive receptors. Environmental risk management is the process of systematically identifying credible environmental hazards, analysing the <b>likelihood</b> <b>of</b> <b>occurrence</b> and severity <b>of</b> th...|$|R
40|$|We {{examine a}} number of objective, {{automatically}} computable TURN-YIELDING CUES — distinct prosodic, acoustic and syntactic events in a speaker’s speech that tend to precede a smooth turn exchange — in the Columbia Games Corpus, a large corpus of task-oriented dialogues. We show that the <b>likelihood</b> <b>of</b> <b>occurrence</b> <b>of</b> a turn-taking attempt from the interlocutor increases linearly {{with the number of}} cues conjointly displayed by the speaker. Our results are important for improving the coordination of speaking turns in interactive voice-response systems, so tha...|$|R
25|$|Research {{has found}} that the {{incidence}} of PTS varies widely based on the population studied; it may be as low as 4.4% or as high as 53%. Of all TBI patients who are hospitalized, 5 to 7% have PTS. PTS occur in about 3.1% of traumatic brain injuries, but the severity of injury affects the <b>likelihood</b> <b>of</b> <b>occurrence.</b>|$|R
5000|$|Risk Assessment Analytical Techniques : Analytical techniques, if used appropriately, {{can serve}} as a tool in the risk {{assessment}} process. Since risk is an outcome of perception, analytical techniques help remove subjectivity, to a certain extent by collation and presentation of data in a systematic manner for assessment of potential impact and <b>likelihood</b> <b>of</b> <b>occurrence</b> or risks.|$|R
30|$|One {{project that}} seeks to remedy the {{dichotomy}} between a priori and post-hoc expert judgement is a project by Forecasting ACE [79], funded by the IARPA and led by a consortium of Futures researchers. This project constantly evaluates results at any stage of the process with dynamical weights and therefore tries to improve overall <b>likelihood</b> <b>of</b> <b>occurrence</b> estimates for its predictions [80].|$|R
40|$|The {{objective}} of this project {{was to develop a}} framework for risk assessment of introduction, establishment, spread and persistence of vector-borne livestock diseases by integrating the essential elements of different approaches. This framework will help risk analysts to assess the risk of vector-borne diseases, considering both <b>likelihood</b> <b>of</b> <b>occurrence</b> and potential impact to inform stakeholders on behalf of their decision making...|$|R
5000|$|When {{including}} two suited hands with 5-4 distribution, two suiters {{have a high}} <b>likelihood</b> <b>of</b> <b>occurrence,</b> and the modern preemptive style is to incorporate such two-suited hands in the arsenal of preemptive openings. Example of such a preemptive conventional opening is the Muiderberg convention. Some take this aggressive style even further and utilise Ekren to preemptively open on a 4-4 in the majors.|$|R
30|$|When SME {{information}} about fungible skills (pairs or clusters of skills) is available, a supervised approach {{may be used}} to combine similarity matrices. If sufficient input–output data exemplars (in this case, fungible skill pairs) exist, supervised classification models may provide a feasible option. As will be discussed in Sect.  7, given very few skill pairs to work with, the choice of approach had to be more conservative. The objective of similarity matrix integration in this case would be to produce a resultant matrix that maximizes the <b>likelihood</b> <b>of</b> <b>occurrence</b> <b>of</b> the exemplars (fungible skill pairs) provided by the SME.|$|R
