434|10000|Public
2500|$|Grzymala-Busse, J. (1987). <b>Learning</b> <b>from</b> <b>examples</b> {{based on}} rough multisets, in Proceedings of the 2nd International Symposium on Methodologies for Intelligent Systems, pp.325–332. Charlotte, NC, USA, ...|$|E
2500|$|The data system LERS (<b>Learning</b> <b>from</b> <b>Examples</b> {{based on}} Rough Sets) Grzymala-Busse (1997) may induce rules from {{inconsistent}} data, i.e., data with conflicting objects. [...] Two objects are conflicting {{when they are}} characterized by the same values of all attributes, but they belong to different concepts (classes). LERS uses rough set theory to compute lower and upper approximations for concepts involved in conflicts with other concepts.|$|E
50|$|In September 1982 he was {{appointed}} Minister of Regional Development, Science and Technology. <b>Learning</b> <b>from</b> <b>examples</b> of other regional development policies, notably in Australia and Tennessee in the USA, he created two regional development authorities, the Lake Basin Development Authority and the Kerio Valley Development Authority.|$|E
5000|$|What can we <b>learn</b> <b>from</b> <b>examples</b> of {{good and}} {{interesting}} practice? ...|$|R
40|$|Abstract. The recent {{developments}} of statistical learning focused mainly on vector machines, i. e. on machines that <b>learn</b> <b>from</b> <b>examples</b> {{described by a}} vector of features. There are many fields where structured data must be handled; therefore, it would be desirable to <b>learn</b> <b>from</b> <b>examples</b> described by graphs. The presentation describes graph machines, which <b>learn</b> real numbers <b>from</b> graphs. Applications {{in the field of}} Quantitative Structure-Activity Relations (QSAR), which aim at predicting properties of molecules from their (graph) structures, are described. ...|$|R
40|$|We {{describe}} {{a framework that}} helps students <b>learn</b> <b>from</b> <b>examples</b> by generating example problem solutions whose level of detail is tailored to the students' domain knowledge. The framework uses natural language generation techniques and a probabilistic student model to selectively introduce gaps in the example solution, so that the student can practice applying rules <b>learned</b> <b>from</b> previous <b>examples</b> in problem solving episodes of difficulty adequate to her knowledge. Filling in solution gaps {{is part of the}} meta-cognitive skill known as selfexplanation (generate explanations to oneself to clarify an example solution), which is crucial to effectively <b>learn</b> <b>from</b> <b>examples.</b> In this paper, we describe how examples with tailored solution gaps are generated and how they are used to support students in learning through gap-filling self-explanation. ...|$|R
50|$|A more {{sophisticated}} approach to up scaling treats {{the problem as}} an inverse problem, solving the question of generating a plausible image which, when scaled down, would look like the input image. A variety of techniques have been applied for this, including optimization techniques with regularization terms {{and the use of}} machine <b>learning</b> <b>from</b> <b>examples.</b>|$|E
50|$|The data system LERS (<b>Learning</b> <b>from</b> <b>Examples</b> {{based on}} Rough Sets) Grzymala-Busse (1997) may induce rules from {{inconsistent}} data, i.e., data with conflicting objects. Two objects are conflicting {{when they are}} characterized by the same values of all attributes, but they belong to different concepts (classes). LERS uses rough set theory to compute lower and upper approximations for concepts involved in conflicts with other concepts.|$|E
50|$|There {{have been}} some studies about how to cite EAD files with {{variable}} granularity. In particular, Buneman and Silvello proposed a rule-based system to automatically create citation snippets {{to be used as}} references when citing XML data; a case study is based on EAD. Furthermore, Silvello proposed a framework, which <b>learning</b> <b>from</b> <b>examples,</b> automatically creates references at different level of coarseness for XML files. This framework has been tested on the Library of Congress collection of EAD files.|$|E
30|$|To {{provide a}} basis for {{computational}} support that uses examples in problem posing, this study discussed and experimentally investigated the effects of activities for <b>learning</b> <b>from</b> an <b>example</b> on composing solutions in problem posing. In our experiment, undergraduates were asked to pose their own new, unique problems from a base problem initially presented after they had learned an example. We compared three activities for <b>learning</b> <b>from</b> an <b>example</b> adopted in general mathematical education or computational support systems for problem posing. In the next session, we discussed problem posing and the activities of <b>learning</b> <b>from</b> problem-posing <b>examples.</b>|$|R
40|$|Existing {{studies show}} that a {{weighted}} context-free transduction of reasonable quality can be effectively <b>learned</b> <b>from</b> <b>examples.</b> This paper investigates the approximation of such transduction by means of weighted rational transduction. The advantage is increased processing speed, which benefits realtime applications involving spoken language. ...|$|R
40|$|Systematicity, {{the ability}} to {{represent}} and process structurally related objects, is a significant and pervasive property of cognitive behaviour, and clearly evident in language. In the case of Connectionist models that <b>learn</b> <b>from</b> <b>examples,</b> systematicity is generalization over examples sharing a common structure. Althoug...|$|R
50|$|Introduced in 2010 {{as part of}} {{the conference}} programme, Business EDUCA offers {{participants}} a range of sessions through which to discuss research, needs and trends in corporate learning. Business EDUCA attracts strong interest from HR and learning practitioners from companies across the world, as well as researchers and educationalists. Examples of some of the themes covered in Business EDUCA include: discovering top strategies to implement and embed workplace learning, <b>learning</b> <b>from</b> <b>examples</b> of best - and worst - practice from other organisations, as well as developing techniques for nurturing exceptional leadership.|$|E
50|$|Concept {{learning}} also {{refers to}} a learning task in which a human or machine learner is trained to classify objects by being shown a set of example objects along with their class labels. The learner simplifies what has been observed by condensing it {{in the form of}} an example. This simplified version of what has been learned is then applied to future examples. Concept learning may be simple or complex because learning takes place over many areas. When a concept is difficult, it is less likely that the learner will be able to simplify, and therefore will be less likely to learn. Colloquially, the task is known as <b>learning</b> <b>from</b> <b>examples.</b> Most theories of concept learning are based on the storage of exemplars and avoid summarization or overt abstraction of any kind.|$|E
40|$|Abstract: Although {{examples}} are frequently used by human tutors, {{they are not}} common in Intelligent Tutoring Systems (ITS). Previous research studies {{over the last three}} decades compared <b>learning</b> <b>from</b> <b>examples</b> to unsupported problem solving. Only recently there have been studies comparing <b>learning</b> <b>from</b> <b>examples</b> to problem solving in ITSs. This paper reviews those studies. We discuss unsolved issues such as when and how examples should be provided in intelligent tutoring systems, and some options to improve <b>learning</b> <b>from</b> <b>examples...</b>|$|E
5000|$|... #Subtitle level 2: <b>Learning</b> <b>from</b> one <b>example</b> through shared densities on {{transforms}} ...|$|R
40|$|Abstract. The recent {{developments}} of statistical learning focused on vector machines, which <b>learn</b> <b>from</b> <b>examples</b> that are described by vectors of features. However, {{there are many}} fields where structured data must be handled; there-fore, it would be desirable to <b>learn</b> <b>from</b> <b>examples</b> described by graphs. Graph machines <b>learn</b> real numbers <b>from</b> graphs. Basically, for each input graph, a separate learning machine is built, whose algebraic structure contains the same information as the graph. We describe the training of such machines, and show that virtual leave-one-out, a powerful method for assessing the generalization capabilities of conventional vector machines, can be extended to graph ma-chines. Academic examples are described, together with applications to the pre-diction of pharmaceutical activities of molecules and to the classification of properties; the potential of graph machines for computer-aided drug design is highlighted...|$|R
5000|$|... “Lean in to <b>Learn</b> <b>from</b> Global <b>Examples</b> of Women.” CNN.com March 8, 2013 ...|$|R
40|$|<b>Learning</b> <b>from</b> <b>examples</b> is {{a common}} and {{powerful}} approach when mastering the art of programming. It encourages students to reuse the code of previously analyzed examples in solving a new problem (Brna 1999; Weber & Brusilovsky 2001). Gomez-Albarran (2005) in a synthesis report about teaching and learning of programming stressed that example-based learning is a natural way of learning. To support online <b>learning</b> <b>from</b> <b>examples</b> i...|$|E
30|$|The {{research}} {{field of}} Intelligent Tutoring Systems/Artificial Intelligence in Education has long addressed <b>learning</b> <b>from</b> <b>examples.</b> Interactive scaffolding that enhances <b>learning</b> <b>from</b> <b>examples</b> has been implemented, {{and its effects}} have been discussed (e.g., Conati and VanLehn 2000; Koedinger and Aleven 2007; Schwonke et al. 2009; McLaren and Isotani 2011). However, the central issue in such research is basically limited to problem solving and does not include problem posing.|$|E
40|$|Abstract. We {{study the}} {{connections}} between <b>learning</b> <b>from</b> <b>examples</b> and inverse problems. We show that <b>learning</b> <b>from</b> <b>examples</b> {{can be seen as}} the discretization of a stochastic inverse problem defined by a Carleman operator. In particular we develop a discretization strategy for this class of inverse problems and we give a convergence analysis. Our approach can be applied to other classes of problems such as integral equations. 1...|$|E
40|$|Developers of {{language}} technology now routinely build scalable systems that can <b>learn</b> <b>from</b> <b>examples,</b> {{but we have}} yet to fully embrace these new capabilities to address the challenge of scalability in digital libraries. This paper relates some lessons <b>learned</b> <b>from</b> a recent experience with building language technology for Hindi, using those lessons to suggest implications for future digital library research...|$|R
3000|$|The second task takes {{advantage}} of the ability of ML paradigms to deal with multidimensional data characterized by complex relationships, which are <b>learned</b> <b>from</b> <b>examples</b> using a training algorithm. This, in turn, allows to bypass the challenging issue of designing an explicit model of the perceptual mechanisms that map [...]...|$|R
40|$|We {{address the}} problem of robust lip tracking, visual speech feature extraction, and sensor {{integration}} for audio-visual speech recognition applications. An appearance based model of the articulators, which represents linguistically important features, is <b>learned</b> <b>from</b> <b>example</b> images and is used to locate, track, and recover visual speech information. We tackl...|$|R
30|$|Despite {{substantial}} {{research into}} example-based learning, no study {{has examined the}} effectiveness of <b>learning</b> <b>from</b> <b>examples</b> and problems simultaneously.|$|E
30|$|Our {{results also}} {{indicate}} that <b>learning</b> <b>from</b> <b>examples</b> and problems simultaneously {{does not lead to}} failure in far-transfer tests. This challenges the traditional assumption that <b>learning</b> <b>from</b> <b>examples</b> and problems simultaneously will lead learners to imitate rather than understand. Our results are also consistent with CLT, which proposes that learning tasks that impose a lower cognitive load enable learners to obtain better scores in near-transfer problems as well as in far-transfer problems.|$|E
40|$|Gold [Gol 67] {{discovered}} a fundamental enumeration technique, the so-called identification-by-enumeration, {{a simple but}} powerful class of algorithms for <b>learning</b> <b>from</b> <b>examples</b> (inductive inference). We introduce a variety of more sophisticated (and more powerful) enumeration techniques and characterize their power. We conclude with the thesis that enumeration techniques are even universal in that each solvable learning problem in inductive inference can be solved by an adequate enumeration technique. This thesis is technically motivated and discussed. Keywords: <b>Learning</b> <b>from</b> <b>examples,</b> learning by search, identification by enumeration, enumeration techniques. Role of Search 1 1 Introduction The role of search, for <b>learning</b> <b>from</b> <b>examples,</b> is examined in a theoretical setting. Gold's seminal paper [Gol 67] on inductive inference introduced a simple but powerful learning technique which became known as identificationby -enumeration. Identification-by-enumeration begins with an infi [...] ...|$|E
50|$|One of {{the well}} known machine {{learning}} technique is Back Propagation Algorithm. This mimics how humans <b>learn</b> <b>from</b> <b>examples.</b> The training patters are repeatedly presented to the network. The error is back propagated and the network weights are adjusted using gradient descent. The network converges through several hundreds of iterative computations.|$|R
25|$|Parekh, R. and Honavar, V. (2001). DFA <b>Learning</b> <b>from</b> Simple <b>Examples.</b> Machine <b>Learning.</b> Vol. 44. pp.9–35.|$|R
40|$|This paper {{presents}} the current stage of my PhD research {{focused on the}} use of machine learning in supporting the human <b>learn</b> <b>from</b> <b>examples.</b> I present here an approach to answer how some concepts change their contexts in time, using two techniques suitable for indexing and data mining: latent semantic indexing (LSI) and the APRIORI algorithm...|$|R
30|$|This study {{investigated}} the effectiveness of <b>learning</b> <b>from</b> <b>examples</b> and problems simultaneously and example-problem pairs. Furthermore, we examined this problem {{within the context of}} novices as well as proficient learners. Our results demonstrate that for novice learners, <b>learning</b> <b>from</b> <b>examples</b> and problems simultaneously is more effective and efficient than learning from example-problem pairs. Using this strategy, learners earned better scores and they reported a significantly lower cognitive load. Among proficient learners, the difference between the strategies was not significant.|$|E
40|$|Although many {{algorithms}} for <b>learning</b> <b>from</b> <b>examples</b> {{have been}} developed and many comparisons have been reported, there is no generally accepted benchmark for classifier learning. The existence of a standard benchmark would greatly assist such comparisons. Sixteen dimensions are proposed to describe classification tasks. Based on these, thirteen real-world and synthetic datasets are chosen by a set covering method from the UCI Repository of machine learning databases to form such a benchmark. 1 Introduction Considerable advances have been made, {{in the field of}} classifier <b>learning</b> <b>from</b> <b>examples,</b> {{making it one of the}} most active research areas of machine learning. Many algorithms for this task {{have been developed}} and applied to problems from a variety of fields such as medical science [Detrano et al., 1989], biology [Qian and Sejnowski, 1988], linguistics [Sejnowski and Rosenberg, 1987]. The task of zeroth-order classifier <b>learning</b> <b>from</b> <b>examples</b> is generally in the form: Given: a set [...] ...|$|E
40|$|Editor: Many works related <b>learning</b> <b>from</b> <b>examples</b> to regularization {{techniques}} for inverse prob-lems. Nevertheless by {{now there was}} no formal evidence neither that <b>learning</b> <b>from</b> <b>examples</b> {{could be seen as}} an inverse problem nor that theoretical results in learning theory could be independently derived using tools from regularization theory. In this paper we provide a positive answer to both questions. Indeed, considering the square loss, we translate the learning problem in the language of regularization theory and we show that consistency results and optimal regularization parameter choice can be derived by the discretization of the corresponding inverse problem...|$|E
40|$|We {{describe}} how {{we used a}} data set of chorale harmonisations composed by Johann Sebastian Bach to train Hidden Markov Models. Using a probabilistic framework allows us to create a harmonisation system which <b>learns</b> <b>from</b> <b>examples,</b> and which can compose new harmonisations. We make a quantitative comparison of our system’s harmonisation performance against simpler models, and provide example harmonisations. ...|$|R
50|$|Similarity {{learning}} {{is an area}} of supervised machine learning in artificial intelligence. It is closely related to regression and classification, but the goal is to <b>learn</b> <b>from</b> <b>examples</b> a similarity function that measures how similar or related two objects are. It has applications in ranking, in recommendation systems, visual identity tracking, face verification, and speaker verification.|$|R
40|$|This work {{focuses on}} the design and {{implementation}} of a fuzzy inference system for fault detection and isolation (FDI) which can <b>learn</b> <b>from</b> <b>example</b> fault data, and the determination of a suitable optimisation strategy for the membership functions. A FDI system was developed {{which is based on}} adaptive fuzzy rules. A number of optimisation strategies were then applied; it was found that an evolutionary algorithm not only produced the best results but did so with relatively little processing effort and with excellent consistency. The adaptive fuzzy system, thus optimised, was tested against a neural network, which was trained to produce analogue outputs as an indication of fault magnitude. The fuzzy solution produced the best accuracy. We can conclude that an adaptive fuzzy inference system for FDI, using an evolutionary algorithm to <b>learn</b> <b>from</b> <b>examples,</b> can provide an accurate and readily comprehensible solution to diagnosing and evaluating fluid process plant faults...|$|R
