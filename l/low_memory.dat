1150|703|Public
5|$|The real minimum memory {{requirements}} {{depend on}} the architecture and may be {{much less than the}} numbers listed in this table. It is possible to install Debian with 60MB of RAM for x86-64; the installer will run in <b>low</b> <b>memory</b> mode and it is recommended to create a swap partition. The installer for z/Architecture requires about 20MB of RAM, but relies on network hardware. Similarly, disk space requirements, which {{depend on the}} packages to be installed, can be reduced by manually selecting the packages needed. , no Pure Blend exists that would lower the hardware requirements easily.|$|E
25|$|The first {{memory segment}} (64 KB) of the {{conventional}} memory area is named lower memory or <b>low</b> <b>memory</b> area.|$|E
2500|$|Following Bill Gates's {{internal}} [...] "Internet Tidal Wave memo" [...] on May 26, 1995, Microsoft {{began to}} redefine its offerings and expand its product line into computer networking and the World Wide Web. The company released Windows 95 on August 24, 1995, featuring pre-emptive multitasking, {{a completely new}} user interface with a novel start button, and 32-bit compatibility; similar to NT, it provided the Win32 API. Windows 95 came bundled with the online service MSN (which was at first {{intended to be a}} competitor to the Internet), and (for OEMs) Internet Explorer, a web browser. Internet Explorer was not bundled with the retail Windows 95 boxes because the boxes were printed before the team finished the web browser, and instead was included in the Windows 95 Plus! pack. Branching out into new markets in 1996, Microsoft and General Electric's NBC unit created a new 24/7 cable news channel, MSNBC. Microsoft created Windows CE 1.0, a new OS designed for devices with <b>low</b> <b>memory</b> and other constraints, such as personal digital assistants. In October 1997, the Justice Department filed a motion in the Federal District Court, stating that Microsoft violated an agreement signed in 1994 and asked the court to stop the bundling of Internet Explorer with Windows.|$|E
30|$|Agents will {{be stored}} using the layout shown in Table  2. The default {{identifier}} for each agent is its <b>lowest</b> <b>memory</b> address.|$|R
50|$|YADIFA has {{a simple}} {{configuration}} syntax and can handle more queries per second while maintaining {{one of the}} <b>lowest</b> <b>memory</b> footprints in the industry.|$|R
5000|$|During {{the course}} of a {{programs}} life, the heap, also called the data segment or [...]bss, will grow up; the heap expands towards the highest memory address available. Conversely, the stack grows down, towards the <b>lowest</b> <b>memory</b> address, 0.|$|R
50|$|<b>Low</b> <b>memory</b> {{foot print}} - Axis2 was {{designed}} ground-up keeping <b>low</b> <b>memory</b> foot print in mind.|$|E
50|$|Trampolines: Many CPUs have smaller {{subroutine}} call instructions to access <b>low</b> <b>memory.</b> A compiler can save space by using these small {{calls in the}} main body of code. Jump instructions in <b>low</b> <b>memory</b> can access the routines at any address. This multiplies space savings from code factoring.|$|E
50|$|It is {{featured}} by small size, <b>low</b> <b>memory</b> usage and relatively stable work.|$|E
30|$|The stack {{convention}} used in MicroBlaze {{starts from}} a higher memory location and grows downward to lower memory locations when items are pushed onto a stack with a function call. Items are popped off the stack the reverse order {{they were put}} on; item at the <b>lowest</b> <b>memory</b> location of the stack goes first and etc.|$|R
50|$|On August 25, 2014, JEDEC {{published}} the JESD209-4 LPDDR4 <b>Low</b> Power <b>Memory</b> Device Standard.|$|R
5000|$|EDMA: Enhanced DMA (EDMA) engine with <b>low</b> latency <b>memory</b> transfers; {{supports}} multiple peer-to-peer configurations ...|$|R
5000|$|Note {{that the}} RAM map is {{organised}} {{so that the}} system globals, system and application heaps grow upwards from <b>low</b> <b>memory,</b> everything else grows downwards from MemTop, from high memory towards <b>low</b> <b>memory.</b> On the 512K Macintosh, the [...] "extra" [...] RAM thus appears as a wider gap between the application heap and the stack, where it is available for application use.|$|E
50|$|The first {{memory segment}} (64 KB) of the {{conventional}} memory area is named <b>low</b> <b>memory.</b>|$|E
5000|$|... 3XOsc - A {{generator}} {{with three}} programmable oscillators that subtractively produce bright sound with <b>low</b> <b>memory</b> use.|$|E
50|$|In 2010, tests {{suggested}} that LXDE 0.5 had the <b>lowest</b> <b>memory</b> {{usage of the}} four most popular desktop environments of the time (GNOME 2.29, KDE Plasma Desktop 4.4, and Xfce 4.6), and that it consumed less energy, which suggests mobile computers with Linux distributions running LXDE 0.5 drained their battery {{at a slower pace}} than those with other desktop environments.|$|R
40|$|This paper {{presents}} an experiment that compared high and <b>low</b> working <b>memory</b> span readers' abilities to process Chinese subject-relative and object-relative clause structures in a self-paced reading paradigm. Comprehension performance {{results indicated that}} the object-relative structure was easier to understand than the subject-relative structure. Reading time results showed that participants with <b>low</b> working <b>memory</b> span read the subject-relative structures more slowly than the object-relative structures, but there was no reading time difference for the high working memory span participants. The experiment provides further evidence that the Chinese subject-relative clause structure is more difficult to process than the Chinese object-relative clause structure. especially for <b>low</b> working <b>memory</b> span individuals. Furthermore, these results support a syntactic storage account of the observed complexity difference. This paper {{presents an}} experiment that compared high and <b>low</b> working <b>memory</b> span readers' abilities to process Chinese subject-relative and object-relative clause structures in a self-paced reading paradigm. Comprehension performance {{results indicated that the}} object-relative structure was easier to understand than the subject-relative structure. Reading time results showed that participants with <b>low</b> working <b>memory</b> span read the subject-relative structures more slowly than the object-relative structures, but there was no reading time difference for the high working memory span participants. The experiment provides further evidence that the Chinese subject-relative clause structure is more difficult to process than the Chinese object-relative clause structure. especially for <b>low</b> working <b>memory</b> span individuals. Furthermore, these results support a syntactic storage account of the observed complexity difference. (C) 2008 Published by Elsevier B. V...|$|R
50|$|In {{algorithm}} we {{have the}} problem of Breadth-first search (BFS) and the single-source shortest path (SSSP), and these two problems are well understood in the RAM model, where {{the cost of a}} memory access is assumed to be independent of the accessed memory location. But modern computers contain a hierarchy of memory levels, and the cost of a memory access depends on the currently <b>lowest</b> <b>memory</b> level that contains the accessed element.|$|R
5000|$|Being {{optimized}} for <b>low</b> <b>memory</b> requirements, Dalvik has some specific characteristics that differentiate it from other standard VMs: ...|$|E
5000|$|Ability {{to handle}} more than 10,000 {{simultaneous}} connections with a <b>low</b> <b>memory</b> footprint (~2.5 MB per 10k inactive HTTP keep-alive connections) ...|$|E
50|$|If {{too many}} {{activities}} are loaded {{at the same}} time there may be performance problems due to <b>low</b> <b>memory</b> or processor load.|$|E
5000|$|RNA {{networks}} Memory Virtualization Platform - A <b>low</b> latency <b>memory</b> pool, implemented as {{a shared}} cache {{and a low}} latency messaging solution.|$|R
50|$|The {{lake was}} named after Abbot Augustus Low, son of Abiel Abbot Low; Low owned 40000 acre in this {{vicinity}} early in the 20th century. Low constructed two hydroelectric dams along the eastern portion of the Bog River Flow; the upper dam, where most of Low's main buildings were located, created Lows Lake. On the granite ledge above the second dam, there is a plaque commemorating the <b>Low's</b> <b>memory.</b> His ashes were spread from the ledge.|$|R
40|$|Abstract. We {{introduce}} {{a new approach to}} LZ 77 factorization that uses O(n/d) words of working space and O(dn) time for any d ≥ 1 (for polylogarithmic alphabet sizes). We also describe carefully engineered implementations of alternative approaches to lightweight LZ 77 factor-ization. Extensive experiments show that the new algorithm is superior in most cases, particularly at the <b>lowest</b> <b>memory</b> levels and for highly repetitive data. As a part of the algorithm, we describe new methods for computing matching statistics which may be of independent interest. ...|$|R
50|$|TinyVM {{is a small}} Java Virtual Machine {{primarily}} designed for use embedded systems with <b>low</b> <b>memory.</b> In 2000 the project was forked into LeJOS.|$|E
5000|$|High {{resistance}} against processing-memory tradeoffs: estimated processing costs of attacks with <b>low</b> <b>memory</b> usage involve {{a factor that}} grows exponentially with time cost due to recomputations ...|$|E
5000|$|Robustness - The {{software}} {{is able to}} operate under stress or tolerate unpredictable or invalid input. For example, it can be designed with resilience to <b>low</b> <b>memory</b> conditions.|$|E
5000|$|Due to the {{relatively}} <b>low</b> external <b>memory</b> bandwidth, and the modest amount of on-chip memory required, tiled rendering is a popular technology for embedded GPUs. Current examples include: ...|$|R
3000|$|... is the {{threshold}} for forgetting the knowledge on the corresponding hierarchical memory level of κ, κ {{will be removed}} from this memory level to a lower level, which has a larger memory space but longer accessing time. In order to achieve sufficient memory space of knowledge during long-term operation, the knowledge that forgotten by the <b>lowest</b> <b>memory</b> level will be permanently removed from the robot. The hierarchical structured memory is also divided into short-term memory and long-term memory. Those short-term memories, that have been strengthened multiple times, can be promoted as long-term memories.|$|R
40|$|We {{introduce}} {{a new approach to}} LZ 77 factorization that uses O(n/d) words of working space and O(dn) time for any d >= 1 (for polylogarithmic alphabet sizes). We also describe carefully engineered implementations of alternative approaches to lightweight LZ 77 factorization. Extensive experiments show that the new algorithm is superior in most cases, particularly at the <b>lowest</b> <b>memory</b> levels and for highly repetitive data. As a part of the algorithm, we describe new methods for computing matching statistics which may be of independent interest. Comment: 12 page...|$|R
5000|$|<b>Low</b> <b>Memory</b> Requirement — Only 16 - 40 KB of RAM {{required}} for a Latin font and 27 - 34 KB of RAM {{required for}} a stroke based Asian font.|$|E
5000|$|Windows XP {{introduces}} the CreateMemoryResourceNotification function which can notify user mode processes of high or <b>low</b> <b>memory</b> availability so applications can allocate more memory or free up memory as necessary[...]|$|E
5000|$|If {{the device}} is running low on memory, a message will pop up that not only informs the user of the <b>low</b> <b>memory,</b> but also {{recommends}} rarely used apps for deletion ...|$|E
40|$|The Multi-Process View {{proposes that}} {{different}} processes {{can be used}} to detect event-based prospective memory cues depending in part on the specificity of the cue. According to this theory, attentional processes are not necessary to detect focal cues whereas detection of nonfocal cues requires some form of controlled attention. This notion was tested using a design in which high or <b>low</b> working <b>memory</b> capacity participant’s performance on a focal versus a nonfocal prospective memory task were compared. An interaction was found such that high and <b>low</b> working <b>memory</b> participants performed equally well on the focal task whereas the high working memory participants performed significantly better than the <b>low</b> working <b>memory</b> participants on the nonfocal task. Thus, controlled attention was only necessary for detecting event-based prospective memory cues in the nonfocal task. These results have implications for theories of prospective memory and the processes necessary for cue detection and the successful fulfillment of intentions...|$|R
5000|$|... very <b>low</b> CPU and <b>memory</b> {{usage and}} minimum system overloading; ...|$|R
40|$|Abstract. ARIA [4] is a {{block cipher}} {{proposed}} at ICISC’ 03. Its design {{is very similar}} to the advanced encryption standard (AES). The authors propose that on 32 -bit processors, the encryption speed is at least 70 % of that of the AES. They claim to offer a higher security level than AES. In this paper we present two attacks of reduced round ARIA which shows some weaknesses of the cipher. Moreover, our attacks have the <b>lowest</b> <b>memory</b> requirements compared to existing attacks on ARIA with an increase in the time complexity. Keywords: block ciphers, differential cryptanalysis, ARIA. ...|$|R
