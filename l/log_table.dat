15|67|Public
5000|$|When Noah sends his {{animals to}} go forth and multiply, {{a pair of}} snakes replies [...] "We can't multiply, we're adders" [...] - [...] so Noah builds them a <b>log</b> <b>table.</b>|$|E
50|$|Over the ten seasons {{the team}} usually {{finished}} in lowly {{positions in the}} competition's <b>log</b> (<b>table).</b> However, for the 1987-88, 1988-89 and 1991-92 seasons, the Impalas reached the tournament semi-finals. Border, Boland, Orange Free State all eventually provided teams for the competition {{and there was not}} a need for the Impalas for the 1994-95 season.|$|E
50|$|Before {{the early}} 1970s, {{handheld}} electronic calculators {{were not available}} and mechanical calculators capable of multiplication were bulky, expensive and not widely available. Instead, tables of base-10 logarithms were used in science, engineering and navigation when calculations required greater accuracy than could be achieved with a slide rule. Use of logarithms avoided laborious and error prone paper and pencil multiplications and divisions. Because logarithms were so useful, tables of base-10 logarithms were given in appendices of many text books. Mathematical and navigation handbooks included tables of the logarithms of trigonometric functions as well. See <b>log</b> <b>table</b> {{for the history of}} such tables.|$|E
50|$|Before calculators, many {{calculations}} {{would be}} done by hand with slide rules and <b>log</b> <b>tables.</b>|$|R
5000|$|Version 5.1: {{production}} release 27 November 2008 (event scheduler, partitioning, plugin API, row-based replication, server <b>log</b> <b>tables)</b> ...|$|R
50|$|Today {{this space}} has large wooden <b>log</b> <b>tables</b> and chairs, and is where receptions take place after marriages or baptisms at the monastery.|$|R
30|$|Given {{a website}} to be protected, PathMarker needs to perform two major changes, adding URL markers into all URLs and {{creating}} extended access <b>log</b> <b>table</b> for saving visitors’ information and URL markers information.|$|E
30|$|Most {{websites}} maintain access log tables, {{which are}} responsible of recording all visitors’ accesses {{information such as}} IP address, the page URL being visited, and timestamp. In order to save more information than the normal access log, PathMarker creates a new table in the database. We call the new table as Extended Access <b>Log</b> <b>Table.</b> When a new web request is received, the server decrypts the encrypted URL and parses the plaintext to get the URL marker. Then PathMarker extracts {{the information in the}} server’s normal access log and insert them into the extended access <b>log</b> <b>table</b> with the visitor’s user ID and corresponding marker’s information.|$|E
3000|$|F(28) {{and adding}} symbols. If finite field {{addition}} consists in XORing the two values, finite field multiplications are more complex, requiring in general a <b>log</b> <b>table</b> lookup, an addition operation, and an exponentiation table lookup {{to determine the}} result. With G [...]...|$|E
50|$|His prime {{concern was}} that a design 'worked' both aerodynamically and visually. Some of his {{particular}} contributions were the introduction of slide rule and seven-figure <b>log</b> <b>tables</b> to work out formulae he invented for drawing curves, work which is now undertaken by complex Computer Aided Design software.|$|R
5000|$|Captain Joshua Slocum, {{in making}} the first solo circumnavigation in 1895 - 1898, {{somewhat}} anachronistically used the lunar method along with dead reckoning in his navigation. He comments in Sailing Alone Around the World on a sight taken in the South Pacific. After correcting an error he found in his <b>log</b> <b>tables,</b> the result was surprisingly accurate: ...|$|R
5000|$|... opEvents - Log and event {{correlator}} with deduplifcation and normalization across NMIS <b>logs,</b> database <b>tables,</b> security events, etc.|$|R
40|$|In {{this paper}} we discussed, a hybrid {{intrusion}} detection system using honey pot. Hybrid honeypot is the combination of low and high interaction honeypots. It helps in detecting intrusion attacking on the system. For this, I have proposed the hybrid model of hybrid honeypot. Low interaction honeypot provide enough interaction to attackers to allow honeypot to detect interesting attacks. It also includes the concept of neural network in combination with anomaly detection technique. Attacks against the honeypot are caught, and any incurred state changes are discarded and the alarm is raised. The outcome of processing a request is used to filter future attack instances and {{could be used to}} update the anomaly detector and updated in the <b>log</b> <b>table.</b> By using hybrid architecture, we can reduce the cost of deploying honeypots...|$|E
40|$|The OpenGL {{geometry}} pipeline lighting stage requires {{raising a}} {{number in the}} range [0, 1] to a power between [1, 128] to compute specular reflections and spotlights. The result need only be accurate {{to a number of}} bits related to the color depth of the output device. This paper describes a hardware implementation of such a powering unit based on a logarithm lookup table, a multiplier, and an inverse <b>log</b> <b>table.</b> The log lookup table is partitioned into subintervals to reduce table size. A synthesized design uses 84 k gates to achieve 10 -bit accuracy with a latency of 9. 62 ns in a 180 nm process. Although the system is tailored for the OpenGL application, the same principles {{can be applied to the}} design of other powering units. 1...|$|E
40|$|Since adversaries may spoof {{their source}} IPs in the attacks, traceback schemes have been {{proposed}} to identify the attack source. However, some of these schemes’ storage requirements increase with packet numbers. Some even have false positives because they use an IP header’s fragment offset for marking. Thus, we propose a 16 -bit single packet hybrid IP traceback scheme that combines packet marking and packet logging with high accuracy and low storage requirement. The size of our log tables can be bounded by route numbers. We also set a threshold to determine whether an upstream interface number is stored in a <b>log</b> <b>table</b> or in a marking field, so as to balance the logging frequency and our computational loads. Because we store user interface information on small-degree routers, compared with current single packet traceback schemes, ours can have the lowest storage requirements. Besides, our traceback achieves zero false positive/negative rates and guarantees reassembly of fragmented packets at the destination...|$|E
40|$|Relief {{shown by}} {{gradient}} tints and spot heights.; Sheets numbered: JN [...] .; "Restricted" on some sheets.; Airways map and flight <b>logging</b> <b>tables</b> on verso of some sheets.; Maps, and index indicating National Library of Australia holdings, {{in an online}} version at: [URL] JN 1 -S. Thailand Area [...] JN 2 -S. Philippines [...] JN 3 -S. Guam [...] JN 4 -S. Okinawa Island [...] JN 5 -S. Io Island...|$|R
50|$|The {{following}} Python code returns x-squared {{values for}} a given N (first column) and n (top row) in Table 1 (m = 1) and Table 2 (m = 2) of Gould 1855. Due to the Newton-method of iteration, look-up tables, such as N versus <b>log</b> Q (<b>Table</b> III in Gould, 1855) and x versus <b>log</b> R (<b>Table</b> III in Peirce, 1852 and Table IV in Gould, 1855) are no longer necessary.|$|R
50|$|Numerical approximations {{sometimes}} {{result from}} {{using a small}} number of significant digits. Calculations are likely to involve rounding errors leading to approximation. <b>Log</b> <b>tables,</b> slide rules and calculators produce approximate answers to all but the simplest calculations. The results of computer calculations are normally an approximation expressed in a limited number of significant digits, although they can be programmed to produce more precise results. Approximation can occur when a decimal number cannot be expressed in a finite number of binary digits.|$|R
40|$|As {{the telecom}} {{industry}} is witnessing {{a large scale}} growth, {{one of the major}} challenges faced in the domain deals with the analysis and processing of telecom transactional data which are generated in large volumes by embedded system communication controllers having various functions. This paper deals with the analysis of such raw data files which are made up of the sequences of the tokens. It also depicts the method in which the files are parsed for extracting the information leading to the final storage in predefined data base tables. The parser is capable of reading the file in a line structured way and store the tokens into the predefined tables of data bases. The whole process is automated using the SSIS tools available in the SQL server. The <b>log</b> <b>table</b> is maintained in each step of the process which will enable tracking of the file for any risk mitigation. It can extract, transform and load data resulting in the processing. Comment: 8 Pages, 8 Figures, Swarm Evolutionary and Memetric Computing Conferenc...|$|E
40|$|Abstract—The OpenGL {{geometry}} pipeline lighting stage requires {{raising a}} {{number in the}} range 0; 1 Š to a power between 1; 128 Š to compute specular reflections and spotlights. The result need only be accurate {{to a number of}} bits related to the color depth of the output device. This paper describes a hardware implementation of such an exponentiation unit based on a logarithm lookup table, a multiplier, and an inverse <b>log</b> <b>table.</b> The inputs arrive in IEEE single-precision floating-point format and the output is a floating-point color component in the range 0; 1 Š with 8 - 10 bits of accuracy. The log lookup table is partitioned into subintervals to reduce table size and each subinterval is computed from a bipartite table to further reduce size. A synthesized design uses 32 k gates to achieve 10 -bit accuracy with a latency of 9. 4 ns in a 180 nm process. Although the system is tailored to the OpenGL application, the same principles {{can be applied to the}} design of other exponentiation units...|$|E
40|$|Big Data {{is a hot}} topic, and the Internet {{is one of the}} few sources {{where it}} is {{possible}} to collect large amounts of data. It is not surprising then to see researchers trying to exploit Big Data techniques to analyze Internet data. This work goes in this direction, and applies Big Data methodologies to net-work monitoring and management. Authors propose Datix, a fully decentralized network traffic analytics engine for querying very large datasets using existing map-reduce infrastructures. The key contribution is the ability to do efficient distributed joins between network traffic data (in this case, SFlow packet samples) and metadata about fields in that data (e. g. IP to AS number mappings), a key primitive operation in many network traffic analysis studies. The data model is a star schema with a large <b>log</b> <b>table</b> and smaller dimension tables, which are partitioned by keys on load time. At runtime, queries are mapped to relevant partitions that contain the data, and the resulting query is passed to Shark or Hive for execution. The result is a fast and scalable system that results particu-larly suited for the analysis of network management traces. Reviewers found this paper to be interesting, well motivated, even if incremental. Despite the lim-ited novelty of the proposed work, reviewers found Datix to be an important contribution, allow-ing existing infrastructure to be applied to very common network measurement tasks [...] for which MapReduce is somewhat underutilized in practice. Plus, Datix is Open Source and available on GitHub. Public review written b...|$|E
5000|$|An {{important}} {{property of}} base-10 logarithms {{which makes them}} so useful in calculation is that the logarithm of numbers greater than one which differ {{by a factor of}} a power of ten all have the same fractional part. The fractional part is known as the mantissa. Thus <b>log</b> <b>tables</b> need only show the fractional part. Tables of common logarithms typically listed the mantissa, to 4 or 5 decimal places or more, of each number in a range, e.g. 1000 to 9999. Such a range would cover all possible values of the mantissa.|$|R
5000|$|In 1703, Magnitsky {{wrote his}} famous Arithmetic (Арифметика; 2,400 copies), {{which was used}} as the {{principal}} textbook on mathematics in Russia until the middle of the 18th century. Mikhail Lomonosov was himself taught by this book, which he called the [...] "gates to his own erudition". This book was more an encyclopedia of mathematics than a textbook, and the first secular book to be printed in Russia. In 1703, Magnitsky also produced a Russian edition of Adriaan Vlacq's <b>log</b> <b>tables</b> called Таблицы логарифмов и синусов, тангенсов и секансов (Tables of logarithms, sines, tangents, and secants).|$|R
5000|$|Robert B. Griffiths {{was born}} in Etah, Uttar Pradesh in 1937 to Presbyterian missionaries. Griffiths {{attended}} Woodstock School, India from fourth standard to tenth, along with his brothers and sisters. Even during his Woodstock days, Griffiths' mathematical and scientific aptitude was apparent. The 1952 year book remarks that [...] "Robert is famous for his long arguments (and unsurpassed knowledge) in chemistry class, his ability to 'recite' the <b>log</b> <b>tables</b> indelibly written in his brain, and his skill {{when it comes to}} fixing anything electrical." [...] This knack for electrical systems kept Griffiths at Woodstock through part of 1953, working with the school's various wiring systems.|$|R
40|$|Wearable {{computing}} {{has been}} in existence {{as part of our}} attire for many years, a few examples being the watches, cell phones and MP 3 players. Recently, many researchers have been devising ways to incorporate wearable devices seamlessly into our lives with the goal of making them an indispensable part of our daily routines. In this thesis, a new wearable computing device called WARM (Wearable Assistant for Remote Monitoring) for use by the elderly and the handicapped is proposed and its software architecture is defined and described. The physically challenged or the elderly, living on their own, but who require assistance with daily tasks, could retain some of their independence with the use of device like WARM. The software architecture of this proposed device is being designed so that the level and types of assistance necessary will be customized based on the user 2 ̆ 7 s needs and their family members can remotely monitor them and be alerted to any issues. In order to maintain extensibility and scalability, a table driven approach is used. The information for reminders is entered through the web-based front end portion of the application which is then written out to relational database tables using stored procedures. The synchronization program, which runs on the user 2 ̆ 7 s PC, also uses a series of stored procedure calls to determine while a reminder is to be sent, when contacts should be alerted and finally moves the cleared reminders to the <b>log</b> <b>table</b> for future reporting. The architecture of the proposed WARM device, its salient features, the software interface, the simulation set up and the results are presented...|$|E
40|$|Abstract Photomosaics are {{commonly}} used to construct maps of paleoseismic trench exposures, but the conventional process of manually using image-editing soft-ware is time consuming and produces undesirable artifacts and distortions. Herein, we document and evaluate the application of image-based modeling (IBM) for creating photomosaics and 3 D models of paleoseismic trench exposures, illustrated with a case-study trench across the Wasatch fault in Alpine, Utah. Our results include a structure-from-motion workflow for the semiautomated creation of seamless, high-resolution photomosaics designed for rapid implementation in a field setting. Com-pared with conventional manual methods, the IBM photomosaic method provides a more accurate, continuous, and detailed record of paleoseismic trench exposures in approximately half the processing time and 15 %– 20 % of the user input time. Our error analysis quantifies {{the effect of the}} number and spatial distribution of control points on model accuracy. For this case study, an ∼ 87 m 2 exposure of a benched trench photo-graphed at viewing distances of 1. 5 – 7 m yields a model with< 2 cm root mean square error (rmse) with as few as six control points. Rmse decreases as more control points are implemented, but the gains in accuracy are minimal beyond 12 control points. Spreading control points throughout the target area helps to minimize error. We pro-pose that 3 D digital models and corresponding photomosaics should be standard prac-tice in paleoseismic exposure archiving. The error analysis serves as a guide for future investigations that seek balance between speed and accuracy during photomosaic and 3 D model construction. Online Material: Image-based modeling workflow for paleoseismic trench photo-mosaics, 3 D trench model, example photomosaic <b>log,</b> <b>table</b> of error analysis data, and Python script for exporting photomosaics in a vertical plane...|$|E
40|$|AbstractThe {{course of}} HIV {{infection}} {{is accompanied by}} a wide individual variability. The complex and large in-terplay between host and viral factors is crucial in the disease’s evolution. The lung has been recognised {{from the beginning of the}} disease as one of the main targets of infectious and non-infectious complications of AIDS. In this setting both anatomic and immunologic particularities of this organ play an important role. The hallmark of HIV is progressive immune dys-function. Despite the intensive research into the pathogenesis, several questions remain to be answered on the dynamic effects of HIV on pulmonary cells. Previous studies in which we have participated sho-wed the early presence of lymphocytic alveolitis from the asymptomatic phase of infection. Since then, many collected data has brought new insights into the immune and biochemical mechanisms involving HIV cell entry, as well as target cells, cytokines and other cellular mediators. In this context, the discovery that specific chemokine receptors could act as co-receptors for HIV, allowed a better understanding of the mechanisms underlying viral cellular entry and tropism. On this issue several authors have reported that in addition to the CD 4 molecule, most strains of HIV use the chemokine receptor CCR 5 for viral attachment and entry into the host cells. This receptor seems to be very important in disease transmission, whereas CXCR 4 receptor tends to be used by the viral strains that emerge later in the disease in addition to or instead of the CCR 5. Aims: To evaluate the pulmonary cellular dynamics in AIDS patients regarding the viral load in bronchoalveolar lavage fluid (LLBA), as well as cellularity and tropism through CCR 5 and CXCR 4 receptors. Material: 14 AIDS patients were enrolled in this study, with a mean age of 39 ± 14. 3 years (9 males and 5 females) all HIV 1, heterosexuals, 6 smokers and 8 non-smokers, none of them drug addicts. These patients were referred to bronchoscopy with BAL, for clinical suspicion of opportunistic lung infections. These patients were later divided into two groups: Group I (recent diagnosis) and Group II (non-recent diagnosis). While all patients had AIDS, group I had also recent diagnosis of oportunistic infections and had not received yet anti-retroviral therapy whilst group II had a long-term disease evolution with several opportunistic episodes and anti-retroviral therapeutic. Methods: BAL was performed both in the middle bronchus in diffuse or in other segmentar bronchus, depending on radiographic abnormalities. Plasma viral load was performed through PCR-RT in blood samples with EDTA, centrifuged and frozen (- 80 º Cel-sius) in the first 4 hours after being collected. The viral load in BALf was quantified in 9 patients using the automatized Cobas Ampliprep/Cobas Amplicor HIV 1 Monitor TM Test, version 1. 5 Roche Diagnostic Systems. The results were expressed in a numeric scale, with a dynamic variation of 50 - 750. 000 copies of RNA HIV 1 /cm 3 and later converted into a logarithmic scale. In 10 patients an immunological study was carried out in BALf and blood to quantify the lymphocyte populations and subsets (CD 3, CD 4, CD 8, CD 19, CD 56 and CD 56 CD 8) as well as the receptors CD 3 CCR 5, CD 4 CCR 5, CD 8 CCR 5, CCR 5 Mø, CXCR 4, CD 3 CXCR 4, CXCR 4 CD 14 and co-stimulatory molecule CD 28, CD 3 CD 28, CD 4 CD 28, CD 8 CD 28 through monoclonal antibodies – CD 8 FITC, CD 19 FITC, CD 3 PE, CD 56 PE, CD 4 PECY 5 -Lymphogram Cytognos; CCR 5 PE, CXCRFITC-R & D Systems; CD 8 Cy 5 and CD 3 Cy 5 -DaKo, CD 4 PE, CD 14 PE, CD 28 FITC-Immunotech; CD 4 FITC-CLB, CD 8 Percp- Beckton Dickinson and CD 3 APC – Beckton Dickinson, by flow cytometry (Facs Calibur-Be-ckton-Dickinson) with 3 or 4 fluorescences – FL 1 -FITC, FL 2 -PE, FL 3 -PECY, FL 4 -APC. In the statistical analysis, we used the Student t-test, and linear correlation. Results: Presence of HIV 1 in BALf (2. 95 log± 3. 08 log), in small levels compared with plasma viral loads (5. 89 log ± 5. 90 <b>log)</b> (<b>Table</b> IV). There was great variability of viral loads in BALf as there was in blood independent of the time elapsed between diagnosis and the exam. As for the lymphocytic populations and subsets in blood (Table V) determined in 13 patients, there was a significant fall of total lymphocytes as well as of their subsets, although more marked in CD 4 cells; 42. 9 % had CD 4 levels 250 cels/mm 3. The CD 19 was reduced with an individual distribution similar to the CD 4 subset. In most cases, the fall of CD 8 accompanied the decrease of CD 4 and CD 19 (patients-nº 7 and 8). The lymphocyte populations and subsets in BALf (10 patients) (Table VI) showed a percentual distribution similar to that observed in blood (Table VII) for CD 3, CD 19, CD 4 and CD 8 lymphocytes, although the percentage of T cells was higher than in blood (94. 5 ± 5 / 84. 1 ± 10. 4) as opposed to B cells (2. 2 ± 3 / 10. 4 ± 9. 6). In BALf CD 8 T cells were higher than in blood (77. 7 ± 17. 6 / 67. 6 ± 4. 2), which was not observed for the CD 4 lymphocytes (8. 1 ± 9. 5 BALf vs. 10. 4 ± 9. 6 in blood). The natural killer activity expressed by CD 56 T cells had important indivi-dual variations in both biological fluids: higher levels in blood than in BALf (9. 1 ± 8 / 2. 9 ± 1. 9). The cytotoxic activity of CD 56 CD 8 was similar in blood and in BALf (2. 2 ± 2 / 1. 7 ± 1. 2) while the individual distribution seemed more homogeneous in BALf (Table VI) than in blood (Table VII). The double-negative (DN) cells had slightly higher values in BALf (7. 6 ± 4. 5 vs 5. 6 ± 5. 3). Curiously, in BALf we observed a higher percentage of less differenciated cells (13 ± 13. 6) (Table VI). The analysis of the receptors CCR 5 and CXCR 4 showed in general terms different behaviour concerning the two biological means (Tables VI and VII). Thus, the CCR 5 CD 3 was hi-gher in blood (10. 9 ± 13. 2) than in BALf (8. 4 ±± 3. 5) while the CCR 5 CD 4 and CCR 5 CD 8 had an increased expression in BALf in relation to blood (2 ± 2. 3 and 4. 9 ± 3. 7 / 0. 9 ± 0. 7 and 4. 1 ± 4. 0 respectively). Concerning the expression of this receptor on monocyte macrophage lineage a marked higher value was attained in BALft (77. 8 ±± 41 in BALf vs. 18. 7 ± 15 in blood). On the contrary the total expression of CXCR 4 was higher in BALf (31 ± 19. 9) than in blood (16. 4 ±± 8. 1). This tendency extended equally to the T lymphocytes (26. 6 ± 19. 8 vs. 10. 7 ± 7. 6) and also to the monocyte-macrophage lineage in an exuberant manner (84. 5 ± 30. 2 / 4. 8 ± 4. 6). The co-stimulatory activity of CD 28 showed higher values in blood (22. 8 ± 16. 2) than in BALf (15. 9 ±± 10. 1) for total T cells, CD 4 and CD 8 lymphocytes 22. 5 ± 16. 7; 7. 8 ± 8. 3; 13. 3 ± 8. 3 / 16. 5 ±± 10. 5; 2. 9 ± 2. 8; 10. 8 ± 8. 0 respectively). Conclusions: 1. HIV infection is responsible for important and extensive abnormalities in lung host defences. 2. The complex interaction between host and aggressor as well as the immune response particularly represented by natural killer and cytotoxic activities, apoptosis, and opportunistic diseases or others, therapeutics and other factors may contibute to the difficulty in obtaining homogenous medical samples within research. There are also ethical issues that restrict a purely scientific approach to these patients. 3. These results point to a pulmonary response to HIV in a compartmentalised fashion according to the dynamic cellular elements involved and receptors in which the latter had distinct profiles related to the biological fluids. In this context, the lung compartimental response is particularly dependent on alveolar macrophages activity which is from the beginning the cornerstone of this process and is the last cellular defense mechanism in this territory when all others are profoundly affected. 4. The dynamics of chemokines receptors may be very important in therapeutic approach as the blockage of the CCR 5 receptor does not seem to trigger an increased expression of CXCR 4 strains. In fact, we found that CXCR 4 remained high in monocyte-macrophage cells throughout infection and its expression was increased in T-lymphocytes in Group II patients as opposed to CCR 5 behavior in BALf which significantly decreases. However, in blood, CCR 5 expression increased, unlike CXCR 4. 5. Due to high co-existing opportunistic infections (71. 4 %) we cannot ignore the hypothesis that this increased expression of CXCR 4 was a result of the modulation induced by opportunistic agents. 6. Finally, this striking individual variability undoubtly has clinical implications. This makes a case-by-case management strategy the correct approach. Rev Port Pneumol 2007; XIII (2) : 175 - 21...|$|E
40|$|We present work towards using ontological {{information}} to facilitate collaborative tasks during operation, maintenance and service of industrial automation facilities. We use semantic models {{as an additional}} layer for a collaboration framework to enable automatic reasoning, decision support and knowledge sharing among multiple parties. Documents such as texts, workflows, images, social media profiles or models of production plants can be semantically annotated to facilitate their ontological classification. Our semantic models comprise behavior and space information, as well as links between documents and from documents to external data collections, such as <b>logs,</b> <b>tables</b> and sensor data. Our semantic models {{can be used to}} check consistency, confidentiality and security properties and to support collaborative tasks...|$|R
30|$|A field {{observation}} {{was performed}} in July and August 2014. Twenty students were recruited and trained to observe employees’ job performance using the log sheet. Two teachers were responsible for coordinating the work onsite. Two training sessions were provided to students. Each student was responsible for real-time tracking of four workers’ work behaviors during working hours. They recorded the content of every worker’s time use every 10  min and formed a closed loop time log per day. We recorded the allocation of workers’ leisure time the following morning based on students’ logbooks. Anonymous investigation, double-blind entering, and repeated retrials were used to ensure the reliability of data collection. Two teachers checked all students’ time <b>log</b> <b>tables</b> on a daily basis. Immediate corrections were made if any mistakes and omissions were found.|$|R
40|$|That `elementary {{transcendental}} function', the logarithm, is a {{very familiar}} function, that we learn early on, and I can still recall a mathematics teacher at school telling the class solemnly that `all logarithms are indices'. It seemed like a Zen koan at the time, but we were soon equipped with <b>log</b> <b>tables</b> and wrestling with {{the mysteries of the}} `bar' notation. A lost art to the youth of today who merely have to press the `ln' button on their calculator. Quite a few years on it seemed a good idea to try to generalise the logarithm and its inverse function, the exponential, by adding a parameter. From a practical viewpoint, this would mean that any model including logarithms or exponentials could be immediately generalised in the attempt to fit data better...|$|R
50|$|As {{with the}} {{previous}} two Filmation games, enemies may interact with scenery in a very basic way, shoving any movable objects (such as <b>logs</b> and <b>tables)</b> along when they bump into them. As before, Sabreman may also push {{one or more of}} these objects at once, though in Pentagram he may even move them from a distance with a blast of his magic.|$|R
40|$|QC 351 A 7 no. 14 Lens {{designers}} who use automatic programs and large computers {{are no longer}} considered to be pioneers but are now {{an integral part of}} the world's rapidly-expanding optical industry. Various techniques of automatic correction, though still in the developmental stage, are finding daily application. A designer armed with a powerful lens design program and a capable computer may now design, in a matter of hours, a lens system which would have taken months to perfect only a few years ago; the results are consistently better than those obtained by classical methods, using <b>log</b> <b>tables</b> and desk calculator. Realizing that much has been learned about automatic design in the past decade, and realizing that the time was ripe for this knowledge to be shared, the Institute of Optics (University of Rochester) sponsored an international conference on Lens Design with Large Computers. Following is an agenda and list of speakers at this conference, held July 5 - 8, 1966, in Rochester, New York...|$|R
40|$|During 1977 Chevron Resources {{conducted}} numerous temperature hole {{programs in}} the San Emidio Desert Prospect, Nevada. These programs were projected to evaluate recently acquired Fee Land and acreage which could {{be included in a}} unit package. The 1977 temperature holes (Map 1) were drilled to a maximum depth of 500 feet with a minimum of 100 feet. Maximum temperature encountered in these holes was 232 F with an average gradient of {approx} 9 F/ 100 feet (300 - 400 feet) and {approx} 11 F/ 100 feet (100 - 200 feet). In addition, shot holes drilled during the seismic program had temperature pipe installed and were also <b>logged.</b> <b>Table</b> 1 reflects data pertinent to the temperature holes drilled in 1977; in addition, complete temperature gradient plots (Appendix A) and lithology descriptions (Appendix B) are included in this report. Water samples from two temperature holes were collected early in the 1977 program and analyzed by Skyline Laboratories (Appendix C). The results of the estimated base temperature calculations are given...|$|R
60|$|A thud on {{the floor}} was the only reply of the Squire. They quickly turned. He had fallen down like a <b>log</b> behind the <b>table,</b> and lay {{motionless}} on the oak boards.|$|R
50|$|Volume tables {{created with}} Girard form class use the {{assumption}} that trees of the same diameter and merchantable height have similar rates of taper above the first log. This implies that volume differences in trees with the same diameter and merchantable height can be mostly attributed to taper variations in the first <b>log.</b> Volume <b>tables</b> using Girard form class are composite tables and are created independently of tree species.|$|R
500|$|In the {{following}} lists, the designation letter ("Des." [...] column) is a reference {{assigned to the}} chronometer while it was on board ship and was used to identify the instrument in <b>logged</b> <b>tables</b> of chronometer readings during the voyage. It was a temporary designation with no relevance once the ship's mission was over. The number ("No." [...] column) was a number permanently marked on it by the maker and together with the maker's name uniquely identified the instrument. When referring to chronometers, the maker's name is frequently abbreviated; for instance, Earnshaw's chronometer no. 509 is known simply as E509. The [...] "type" [...] of all chronometers listed here is either box or pocket. A boxed chronometer is mounted on gimbals attached to its box. A pocket chronometer is {{in the style of}} a pocketwatch. [...] "Winding" [...] refers to the number of days that a chronometer kept going before needing rewinding. However, they were all wound at precisely the same time every day, except for the eight-day chronometers which were wound weekly.|$|R
