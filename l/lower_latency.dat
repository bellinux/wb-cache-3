613|486|Public
25|$|LTE-Advanced – High-speed {{communication}} specification for mobile networks. Provides enhancements to the LTE standard with extended coverage, higher throughput, and <b>lower</b> <b>latency.</b>|$|E
25|$|In ARM-based machines, {{peripheral}} {{devices are}} usually {{attached to the}} processor by mapping their physical registers into ARM memory space, into the coprocessor space, or by connecting to another device (a bus) that in turn attaches to the processor. Coprocessor accesses have <b>lower</b> <b>latency,</b> so some peripherals—for example, an XScale interrupt controller—are accessible in both ways: through memory and through coprocessors.|$|E
25|$|Audio packets– {{also known}} as {{isochronous}} data packets, these packets are sent out by all CobraNet devices after they receive a beat packet. At standard latency settings, one audio packet is sent for each beat packet received, and each audio packet includes 64 samples of audio data per channel. At <b>lower</b> <b>latency</b> settings, audio packets may be sent twice or four times for each beat packet received. Bundles do not share packets; separate packets are sent in sequence for each bundle transmitted from the same device.|$|E
5000|$|Low data {{transfer}} latencies (sub-5 ms latency for small IP packets in optimal conditions), <b>lower</b> <b>latencies</b> for handover and connection setup time.|$|R
5000|$|Low data {{transfer}} latencies (sub-5 ms latency for small IP packets in optimal conditions), <b>lower</b> <b>latencies</b> for handover and connection setup time than with previous radio access technologies.|$|R
50|$|At 7 September 2016, the {{announced}} the successor of XQD, CFexpress. This new standard {{uses the same}} form-factor and interface but uses the NVMe protocol for higher speeds, <b>lower</b> <b>latencies</b> and <b>lower</b> power consumption.|$|R
25|$|Introduced by IBM in 1956, HDDs {{became the}} {{dominant}} secondary storage device for general-purpose computers {{by the early}} 1960s. Continuously improved, HDDs have maintained this position into the modern era of servers and personal computers. More than 200 companies have produced HDDs historically, though after extensive industry consolidation most current units are manufactured by Seagate, Toshiba, and Western Digital. HDD unit shipments and sales revenues are declining, though production (exabytes per year) is growing. Flash memory has a growing {{share of the market}} for secondary storage, in the form of solid-state drives (SSDs). SSDs have higher data-transfer rates, higher areal storage density, better reliability, and much <b>lower</b> <b>latency</b> and access times. Though SSDs have higher cost per bit, they are replacing HDDs where speed, power consumption, small size, and durability are important.|$|E
2500|$|In 2010, Sisense {{introduced}} {{the benefits of}} its In Chip data analytic method, which, according to the company, creates scalable columnar databases and processes data 10 times faster than conventional in-memory technologies. Simiarly to other column based storages, it is [...] able to returns answers to basic questions in much <b>lower</b> <b>latency</b> compared to row based storage systems.|$|E
2500|$|It {{may seem}} from the Latency vs. Channels per bundle table that more {{information}} can be sent at a <b>lower</b> <b>latency.</b> [...] However, {{that is not the}} case. [...] More channels can be sent per bundle, but fewer bundles can be processed simultaneously by one device. [...] So, while eight 24-bit, 96kHz channels can be sent in one bundle at [...] ms latency, due to processing constraints, the CobraNet device may only be able to send and receive one bundle instead of the usual four. [...] The bundle capacity of CobraNet devices are unique to the particular device, and are not always the same. [...] The Channels per bundle vs. test case latencies table illustrates the bundle capacity for a Biamp AudiaFLEX-CM DSP device. [...] The Rx and Tx columns indicate the absolute maximum number of channels that can be received or transmitted. [...] The Rx/Tx column represents the maximum number of channels that can be received and transmitted simultaneously.|$|E
25|$|CobraNet was {{subsequently}} enhanced {{to support and}} eventually require a switched Ethernet network. An SNMP agent was added for remote control and monitoring. Support for higher sample rates, increased bit resolutions and <b>lowered</b> <b>latency</b> capabilities were later introduced in an incremental and backwards-compatible manner.|$|R
40|$|With {{ever-increasing}} {{data rates}} and <b>lowering</b> <b>latencies,</b> the percieved quality and fairness of modern cellular telephony networks is largely determined by their packet schedulers. In this document {{we examine the}} HSDPA system to locate the packet scheduler and its parameters, examine its influence on the system, and compare solutions both current and of historical value...|$|R
5000|$|<b>Lower</b> link <b>latency</b> (one single packet can {{be spread}} across all links) ...|$|R
5000|$|Broadwell {{processor}} (with increased throughput and <b>lower</b> <b>latency)</b> ...|$|E
5000|$|... {{support for}} higher {{throughput}} and <b>lower</b> <b>latency</b> radio access networks (RANs) ...|$|E
5000|$|L1 cache {{has been}} changed from write-through to write-back, {{allowing}} for <b>lower</b> <b>latency</b> and higher bandwidth ...|$|E
50|$|DDR's {{prefetch}} buffer depth is 2 (bits), while DDR2 uses 4. Although {{the effective}} clock rates of DDR2 {{are higher than}} DDR, the overall performance was no greater in the early implementations, primarily due to the high latencies of the first DDR2 modules. DDR2 started to be effective {{by the end of}} 2004, as modules with <b>lower</b> <b>latencies</b> becameavailable.|$|R
40|$|Software {{oriented}} {{techniques to}} hide memory la-tency in superscalar and superpipe 2 ined machines include loop unrolling, software pipelining, and software cache prefetching. Issuing the data fetch request prior to ac-tual need for data allows overlap of accessing with use-ful computations. Loop unrolling and software pipelining do not necessitate microarchitecture or instruction set ar-chitecture changes, whereas software controlled prefetch-tng does. While {{studies on the}} benefits of the indiuid-ual techniques hawe been done, no study evaluates all of these techniques within a consistent framework. This pa-per attempts to remedy this by providing a comparative evaluation of the features and benefits of the techniques. Loop unrolling and static scheduling of loads is seen to produce significant improvement in performance at <b>lower</b> <b>latencies.</b> Software plpelining is observed to be better than software controlled prefetching at <b>lower</b> <b>latencies,</b> but at higher latencies, software prefetching outperforms soft-ware pipelining. Aggressive prefetching beyond conditional branches can detrimentally affect performance by increas-ing the memory bandwidth requirements and bus trafic...|$|R
50|$|As of Ubuntu Studio 12.04, {{the default}} kernel is linux-lowlatency, which in essence is a generic Ubuntu Linux kernel, with a tweaked {{configuration}} {{to allow for}} stable operation for audio applications at <b>lower</b> <b>latencies.</b> Since much of the real-time patch has now been implemented into the vanilla kernel, and considering the difficulties in maintaining linux-rt, Ubuntu Studio decided on using linux-lowlatency in its place.|$|R
5000|$|LTE-Advanced - High-speed {{communication}} specification for mobile networks. Provides enhancements to the LTE standard with extended coverage, higher throughput, and <b>lower</b> <b>latency.</b>|$|E
5000|$|... 5G {{research}} and development also aims at <b>lower</b> <b>latency</b> than 4G equipment and lower battery consumption, for better implementation of the Internet of things.|$|E
5000|$|DASH7 {{supports}} a built-in query protocol that minimizes [...] "round trips" [...] for most messaging applications {{that results in}} <b>lower</b> <b>latency</b> and higher network throughput.|$|E
5000|$|Some gamers {{claim that}} {{compared}} to USB, the PS/2 interface also has much <b>lower</b> <b>latencies</b> for keyboards {{due to the}} interrupt-driven manner PS/2 keyboards communicate with the computer by default compared to the polled nature of USB keyboards where the USB controller hardware polls USB keyboards, which can be important in some real-time applications or gaming.However, USB mice have <b>lower</b> <b>latencies</b> than PS/2 mice because standard USB mice are polled at a default rate of 125 hertz while standard PS/2 mice send interrupts at a default rate of 100 hertz when they have data to send to the computer. Also, USB mice do not cause the USB controller to interrupt the system when they have no status change to report according to the USB HID specification's default profile for mice. Both PS/2 and USB allow the sample rate to be overridden, with PS/2 supporting a sampling rate of up to 200 hertz and USB supporting a polling rate up to 1 kilohertz {{as long as the}} mouse runs at full-speed USB speeds or higher.|$|R
50|$|Direct Access File System (DAFS) is anetwork {{file system}} {{that is based on}} NFSv4 and the Virtual Interface (VI) data {{transfer}} mechanism. DAFS uses remote direct memory access (RDMA) to perform efficient network access to data in remote files. This <b>lowers</b> <b>latency</b> by reducing the number of steps needed to process and transfer remote data. File locking is cached on the client side, eliminating the need to access the file server for subsequent data access.|$|R
50|$|Scylla is an {{open-source}} distributed NoSQL data store. It {{was designed}} to be compatible with Apache Cassandra while achieving significantly higher throughputs and <b>lower</b> <b>latencies.</b> It supports the same protocols as Cassandra (CQL and Thrift) and the same file formats (SSTable), but is a completely rewritten implementation, using the C++14 language replacing Cassandra's Java, and the Seastar asynchronous programming library replacing threads, shared memory, mapped files, and other classic Linux programming techniques.|$|R
50|$|Cut-through {{switching}} {{has been}} applied to make block-relay <b>lower</b> <b>latency</b> in Bitcoin. Low latency is critical for Bitcoin miners to reduce the rate at which their blocks are orphaned.|$|E
5000|$|Delivery latency - vendors offer {{different}} {{amounts of}} data latency, with <b>lower</b> <b>latency</b> typically being more expensive and more complex. An individual vendor may offer different products with different latencies.|$|E
50|$|Head-related {{transfer}} functions (HRTFs) {{are used}} to generate positional audio cues in the two channel output signal. A finite impulse response (FIR) filter is used to process the audio with <b>lower</b> <b>latency.</b>|$|E
50|$|The {{focus in}} GSIF is to <b>lower</b> the <b>latency</b> in audio {{transactions}} whereas GSIF2 additionally provides audio routing capabilities between software and soundcard.|$|R
30|$|Higher {{data rates}} and <b>lower</b> <b>latencies</b> are two central {{objectives}} when advancing wireless networks, {{but while the}} role of interference at the physical (PHY) layer of wireless networks has recently been profoundly re-thought {{with the emergence of}} new techniques to combat and exploit it in order to maximize the efficiency of the physical resources [1], most of these advances in the PHY layer of wireless communications have not yet been translated to the way that message exchange protocols make use of the PHY layer [2, 3].|$|R
40|$|Sleep {{deprivation}} exists {{extensively in}} everyday life. It makes cognition functions lower. And vigilance level is affected significantly. In this research, we used discern task by Oddball to study ERPs of 32 young males in different sleep deprivation conditions (sleep deprived for 21 hours, sleep deprived for 45 hours, sleep deprived for 69 hours, normal subjects). Results proved that after sleep deprivation, amplitudes of ERP <b>lowered,</b> <b>latencies</b> prolonged, brain area affected enlarged. So ERP {{is the good}} index to indicate the lowered vigilance level after SD. IUPsy...|$|R
50|$|Newer upscale neighborhoods can feature {{fiber optic}} cables running {{directly}} into the homes. This enables service providers to offer internet services with much higher bandwidth and/or <b>lower</b> <b>latency</b> characteristics associated with end-to-end optical signaling.|$|E
5000|$|The default {{versions}} of DynamoDB, Cassandra, Riak and Cosmos DB are PA/EL systems: if a partition occurs, {{they give up}} consistency for availability, and under normal operation they give up consistency for <b>lower</b> <b>latency.</b>|$|E
5000|$|The {{incorporation}} of the schedule, bandwidth management, and USB device address assignment functions, that were previously performed by the driver in to the xHCI hardware enable a simpler, leaner, <b>lower</b> <b>latency</b> software stack for the xHCI.|$|E
40|$|Efficient {{querying}} of huge {{volumes of}} multidimensional data stored in cloud computing systems {{has become a}} necessity, due to the widespread of cloud storage facilities. With clouds getting larger and available data growing larger and larger it is mandatory to develop fast, scalable and efficient indexing schemes. In this paper, we propose the A-tree, a distributed indexing scheme for multidimensional data capable of handling both point and range queries, appropriate for cloud computing environments. A performance evaluation of the A-tree against the state-of-the-art competitor attests its superiority, achieving significantly <b>lower</b> <b>latencies.</b> © 2011 IEEE...|$|R
40|$|We {{evaluate}} various {{mechanisms for}} data communication in large-scale shared memory multiprocessors. Data communication involves both data transmission and synchronization, {{resulting in the}} transfer of data between computational threads. We use simple analytical models to evaluate the communication latency {{for each of the}} mechanisms. The models show that efficient and opportunistic synchronization is the most important determinant of latency, followed by efficient transmission. Producer-initiated mechanisms, in which data is sent by its producer as it is produced, generally achieve <b>lower</b> <b>latencies</b> than consumer-initiated mechanisms, in which data is retrieved as and when it is needed...|$|R
50|$|Some {{applications}} {{are amenable to}} flow processing, namely those that only need data from a single input at once (not totals, for instance): start the next step for each input as it completes the previous step. In this case flow processing <b>lowers</b> <b>latency</b> for individual inputs, allowing them to be completed without waiting for the entire batch to finish. However, many applications require data from all records, notably computations such as totals. In this case the entire batch must be completed before one has a usable result: partial results are not usable.|$|R
