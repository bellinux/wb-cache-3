4709|10000|Public
25|$|Because a Bayesian {{network is}} a {{complete}} model for the variables and their relationships, {{it can be used}} to answer probabilistic queries about them. For example, the network can be used to find out updated knowledge of the state of a subset of variables when other variables (the evidence variables) are observed. This process of computing the posterior distribution of variables given evidence is called probabilistic inference. The posterior gives a universal sufficient statistic for detection applications, when one wants to choose values for the variable subset which minimize some expected <b>loss</b> <b>function,</b> for instance the probability of decision error. A Bayesian network can thus be considered a mechanism for automatically applying Bayes' theorem to complex problems.|$|E
2500|$|To extend SVM {{to cases}} in which the data are not linearly separable, we {{introduce}} the hinge <b>loss</b> <b>function,</b> ...|$|E
2500|$|A maximum {{likelihood}} estimator is an extremum estimator obtained by maximizing, {{as a function}} of θ, the objective function (c.f. <b>loss</b> <b>function)</b> ...|$|E
40|$|<b>Loss</b> <b>functions</b> play a {{fundamental}} role in every quality engineering method. A {{new set of}} <b>loss</b> <b>functions</b> is proposed based on Taguchi’s societal loss concept. Its applications to robust parameter design are discussed in detail. The <b>loss</b> <b>functions</b> are shown to posses some interesting properties and lead to theoretical results that cannot be handled with other <b>loss</b> <b>functions...</b>|$|R
40|$|The {{problem of}} {{scheduling}} tasks with deadlines and linear <b>loss</b> <b>functions</b> was discussed {{in some detail}} in two papers [McNaughton, R. Scheduling with deadlines and <b>loss</b> <b>functions.</b> Management Sci. 6 (1) 1 - 12; Schild, A., I. J. Fredman. On scheduling tasks with associated linear <b>loss</b> <b>functions.</b> Management Sci. 7 (3) 280 - 285] by Robert McNaughton and the authors. In this paper, the problem of scheduling with nonlinear <b>loss</b> <b>functions</b> is attacked. In particular, certain criteria will be established for quadratic <b>loss</b> <b>functions</b> and an algorithm is proposed which will yield an optimal scheduling [...] i. e., a minimal total loss [...] for nonlinear <b>loss</b> <b>functions</b> in general. ...|$|R
40|$|In the convex {{optimization}} {{approach to}} online regret minimization, many {{methods have been}} devel-oped to guarantee a O(T) regret bound for subdifferentiable convex <b>loss</b> <b>functions</b> with bounded subgradients {{by means of a}} reduction to bounded linear <b>loss</b> <b>functions.</b> This suggests that the latter tend to be the hardest <b>loss</b> <b>functions</b> to learn against. We investigate this question in a system-atic fashion by establishing Ω(T) lower bounds on the minimum achievable regret for a class of piecewise linear <b>loss</b> <b>functions</b> that subsumes the class of bounded linear <b>loss</b> <b>functions.</b> These results hold in a completely adversarial setting. In contrast, we show that the minimum achievable regret can be significantly smaller when the opponent is “greedy”...|$|R
2500|$|In {{light of}} the above discussion, {{we see that the}} SVM {{technique}} is equivalent to empirical risk minimization with Tikhonov regularization, where in this case the <b>loss</b> <b>function</b> is the hinge loss ...|$|E
2500|$|The {{function}} f is called, variously, {{an objective}} function, a <b>loss</b> <b>function</b> or cost function (minimization), [...] a utility function or fitness function (maximization), or, in certain fields, an energy function or energy functional. A feasible solution that minimizes (or maximizes, {{if that is}} the goal) the objective function is called an optimal solution.|$|E
2500|$|In {{supervised}} learning, one {{is given}} a set of training examples [...] with labels , and wishes to predict [...] given [...] To do so one forms a hypothesis, , such that [...] is a [...] "good" [...] approximation of [...] A [...] "good" [...] approximation is usually defined {{with the help of}} a <b>loss</b> <b>function,</b> , which characterizes how bad [...] is as a prediction of [...] We would then like to choose a hypothesis that minimizes the expected risk: ...|$|E
40|$|Abstract Vapnik {{described}} the “three main learning problems ” of pattern recognition, regression estimation and density estimation. These are {{defined in terms}} of the <b>loss</b> <b>functions</b> used to evaluate performance (0 - 1 loss, squared loss and log loss respectively). But there are many other <b>loss</b> <b>functions</b> one could use. In this chapter I will summarise some recent work by myself and colleagues studying the theoretical aspects of <b>loss</b> <b>functions.</b> The results elucidate the richness of the set of <b>loss</b> <b>functions</b> and explain some of the implications of their choice. ...|$|R
50|$|Other <b>loss</b> <b>functions</b> can be conceived, {{although}} the {{mean squared error}} is {{the most widely used}} and validated. Other <b>loss</b> <b>functions</b> are used in statistics, particularly in robust statistics.|$|R
40|$|Bayes estimators of the {{parameter}} of {{exponential distribution}} are obtained with non-informative quasi-prior distribution based on record values under three <b>loss</b> <b>functions.</b> These functions are weighted squared error loss, square log error loss and entropy <b>loss</b> <b>functions.</b> Finally the minimax estimators of the parameter are obtained by using Lehmann’s theorem. Comparisons {{in terms of}} risks with the estimators of parameter under three <b>loss</b> <b>functions</b> are also studied...|$|R
2500|$|Linear {{regression}} models are often fitted using the least squares approach, {{but they may}} also be fitted in other ways, such as by minimizing the [...] "lack of fit" [...] in some other norm (as with least absolute deviations regression), or by minimizing a penalized version of the least squares <b>loss</b> <b>function</b> as in ridge regression (L2-norm penalty) and lasso (L1-norm penalty). Conversely, the least squares approach can be used to fit models that are not linear models. Thus, although the terms [...] "least squares" [...] and [...] "linear model" [...] are closely linked, they are not synonymous.|$|E
2500|$|On the entropy {{scale of}} {{information}} gain {{there is very}} little difference between near certainty and absolute certainty—coding according to a near certainty requires hardly any more bits than coding according to an absolute certainty. On the other hand, on the logit scale implied by weight of evidence, {{the difference between the two}} is enormous – infinite perhaps; this might reflect the difference between being almost sure (on a probabilistic level) that, say, the Riemann hypothesis is correct, compared to being certain that it is correct because one has a mathematical proof. [...] These two different scales of <b>loss</b> <b>function</b> for uncertainty are both useful, according to how well each reflects the particular circumstances of the problem in question.|$|E
2500|$|... where, [...] is the {{learning}} rate, [...] {{is the cost}} (or <b>loss)</b> <b>function</b> and [...] a stochastic term. The choice of the cost function depends on factors such as {{the learning}} type (supervised, unsupervised, reinforcement, etc.) and the activation function. For example, when performing supervised learning on a multiclass classification problem, common choices for the activation function and cost function are the softmax function and cross entropy function, respectively. The softmax function is defined as [...] where [...] represents the class probability (output of the unit [...] ) and [...] and [...] represent the total input to units [...] and [...] of the same level respectively. Cross entropy is defined as [...] where [...] represents the target probability for output unit [...] and [...] is the probability output for [...] after applying the activation function.|$|E
40|$|We study <b>loss</b> <b>functions</b> {{that measure}} the {{accuracy}} of a prediction based on multiple data points simultaneously. To our knowledge, such <b>loss</b> <b>functions</b> have not been studied before {{in the area of}} property elicitation or in machine learning more broadly. As compared to traditional <b>loss</b> <b>functions</b> that take only a single data point, these multi-observation <b>loss</b> <b>functions</b> can in some cases drastically reduce the dimensionality of the hypothesis required. In elicitation, this corresponds to requiring many fewer reports; in empirical risk minimization, it corresponds to algorithms on a hypothesis space of much smaller dimension. We explore some examples of the tradeoff between dimensionality and number of observations, give some geometric characterizations and intuition for relating <b>loss</b> <b>functions</b> and the properties that they elicit, and discuss some implications for both elicitation and machine-learning contexts...|$|R
40|$|Modern {{applications}} in sensitive domains such as biometrics and medicine fre-quently {{require the use}} of non-decomposable <b>loss</b> <b>functions</b> such as precision@k, F-measure etc. Compared to point <b>loss</b> <b>functions</b> such as hinge-loss, these of-fer much more fine grained control over prediction, {{but at the same time}} present novel challenges in terms of algorithm design and analysis. In this work we initiate a study of online learning techniques for such non-decomposable <b>loss</b> <b>functions</b> with an aim to enable incremental learning as well as design scalable solvers for batch problems. To this end, we propose an online learning framework for such <b>loss</b> <b>functions.</b> Our model enjoys several nice properties, chief amongst them be-ing the existence of efficient online learning algorithms with sublinear regret and online to batch conversion bounds. Our model is a provable extension of existing online learning models for point <b>loss</b> <b>functions.</b> We instantiate two popular losses, Prec@k and pAUC, in our model and prove sublinear regret bounds for both of them. Our proofs require a novel structural lemma over ranked lists which may be of independent interest. We then develop scalable stochastic gradient descent solvers for non-decomposable <b>loss</b> <b>functions.</b> We show that for a large family of <b>loss</b> <b>functions</b> satisfying a certain uniform convergence property (that include...|$|R
40|$|This paper {{examines}} {{monetary policy}} from an optimal control perspective. Three <b>loss</b> <b>functions</b> are minimized {{for each of}} three models, {{and the results are}} compared. The three <b>loss</b> <b>functions</b> target nominal growth, real growth, and inflation, respectively. The three models are a small structural model, a VAR model, and a large structural model. A numerical procedure is presented that can handle a variety of <b>loss</b> <b>functions</b> and models. ...|$|R
5000|$|The {{most common}} <b>loss</b> <b>function</b> for {{regression}} is the square <b>loss</b> <b>function</b> (also {{known as the}} L2-norm). This familiar <b>loss</b> <b>function</b> is used in ordinary least squares regression. The form is: ...|$|E
5000|$|In {{statistics}} and decision theory, a frequently used <b>loss</b> <b>function</b> is the 0-1 <b>loss</b> <b>function</b> ...|$|E
5000|$|... #Caption: Plot {{of various}} loss functions. Blue is the 0-1 {{indicator}} function. Green is the square <b>loss</b> <b>function.</b> Purple is the hinge <b>loss</b> <b>function.</b> Yellow is the logistic <b>loss</b> <b>function.</b> Note that all surrogates give a loss penalty of 1 for ...|$|E
40|$|Abstract. A game-theoretic {{approach}} for learning optimal parameter values for probabilistic rough set regions is presented. The parameters {{can be used}} to define approximation regions in a probabilistic decision space. New values for <b>loss</b> <b>functions</b> are learned from a sequence of risk modifications derived from game-theoretic analysis of the relationship between two classification measures. Using game theory to maximize these measures results in a learning method to reformulate the <b>loss</b> <b>functions.</b> The decision-theoretic rough set model acquires initial values for these parameters through a combination of <b>loss</b> <b>functions</b> provided by the user. The new game-theoretic learning method modifies these <b>loss</b> <b>functions</b> according to an acceptable threshold. ...|$|R
40|$|Abstract. In the paper, {{we present}} the {{relationship}} between <b>loss</b> <b>functions</b> and confirmation measures. We show that population minimizers for weighted <b>loss</b> <b>functions</b> correspond to confirmation measures. This result {{can be used in}} construction of machine learning methods, particularly, ensemble methods. ...|$|R
50|$|Some online {{prediction}} problems however cannot fit in {{the framework}} of OCO. For example, in online classification, the prediction domain and the <b>loss</b> <b>functions</b> are not convex. In such scenarios, two simple techniques for convexification are used: randomisation and surrogate <b>loss</b> <b>functions.</b>|$|R
5000|$|Let [...] {{denote the}} <b>loss</b> <b>function</b> for {{classifying}} {{an object in}} [...] into the POS region, [...] denote the <b>loss</b> <b>function</b> for classifying an object in [...] into the BND region, and let [...] denote the <b>loss</b> <b>function</b> for classifying an object in [...] into the NEG region. A <b>loss</b> <b>function</b> [...] denotes the loss of classifying an object that {{does not belong to}} [...] into the regions specified by [...]|$|E
50|$|Since the {{expected}} <b>loss</b> <b>function</b> is not applicable, the following empirical <b>loss</b> <b>function</b> is {{selected for the}} training data in practice.|$|E
5000|$|The Huber <b>loss</b> <b>function</b> {{describes}} the penalty incurred by an estimation procedure [...] Huber (1964) defines the <b>loss</b> <b>function</b> piecewise by ...|$|E
40|$|We {{provide the}} rate of {{convergence}} of the Bayes action derived from non smooth <b>loss</b> <b>functions</b> involved in Bayesian robustness. Such <b>loss</b> <b>functions</b> are typically not twice differentiable but admit right and left second derivatives. The asymptotic limit of three measures of global robustness is given. These measures are {{the range of the}} Bayes actions set associated with a class of <b>loss</b> <b>functions,</b> the maximum regret of using a particular loss when the subjective loss belongs to a given class and the range of the posterior expected loss when the loss ranges over a given class. An application to prior robustness with density ratio classes is provided. Bayesian robustness Class of <b>loss</b> <b>functions</b> Class of priors Asymptotic rate of convergence Misspecified models...|$|R
50|$|The frequentist {{procedures}} of significance testing and confidence intervals {{can be constructed}} without regard to utility functions. However, some elements of frequentist statistics, such as statistical decision theory, do incorporate utility functions. In particular, frequentist developments of optimal inference (such as minimum-variance unbiased estimators, or uniformly most powerful testing) make use of <b>loss</b> <b>functions,</b> which {{play the role of}} (negative) utility <b>functions.</b> <b>Loss</b> <b>functions</b> need not be explicitly stated for statistical theorists to prove that a statistical procedure has an optimality property. However, loss-functions are often useful for stating optimality properties: for example, median-unbiased estimators are optimal under absolute value <b>loss</b> <b>functions,</b> in that they minimize expected loss, and least squares estimators are optimal under squared error <b>loss</b> <b>functions,</b> in that they minimize expected loss.|$|R
40|$|Determination of {{the number}} of {{significant}} clusters in the sample represents a very important problem. It is expected that the outcome of clustering under a broad class of <b>loss</b> <b>functions</b> will be more stable if the correct number of clusters is used. In order to illustrate the model of universal clustering we consider 1) family of power <b>loss</b> <b>functions</b> in probabilistic space; 2) family of exponential <b>loss</b> <b>functions</b> in Euclidean space. The proposed model is general, and proved to be effective in application to the synthetic datasets...|$|R
5000|$|There {{is a lot}} of {{flexibility}} allowed in the choice of <b>loss</b> <b>function.</b> As long as the <b>loss</b> <b>function</b> is monotonic and continuously differentiable, the classifier will always be driven toward purer solutions. Zhang (2004) provides a <b>loss</b> <b>function</b> based on least squares, a modified Huber loss function: ...|$|E
50|$|The squared-error <b>loss</b> <b>function</b> {{is widely}} used in statistics, {{following}} Gauss's use of the squared-error <b>loss</b> <b>function</b> in justifying the method of least squares.|$|E
5000|$|The Pseudo-Huber <b>loss</b> <b>function</b> {{can be used}} as {{a smooth}} {{approximation}} of the Huber <b>loss</b> <b>function,</b> and ensures that derivatives are continuous for all degrees. It is defined as ...|$|E
30|$|Lastly, {{checking}} {{the use of}} general noise <b>loss</b> <b>functions</b> like the ones considered in this research in other regression methods where models are built by minimizing concrete <b>loss</b> <b>functions,</b> such as deep learning or model stacking frameworks, could also be an interesting idea worthy of further investigation.|$|R
40|$|Abstract — We provide {{necessary}} and sufficient conditions for general <b>loss</b> <b>functions</b> {{under which the}} conditional expectation is the unique optimal predictor of a random variable. Further, using such <b>loss</b> <b>functions,</b> we give an exact characterization {{of the difference between}} the two sides of Jensen’s inequality. I...|$|R
40|$|The censored Rayleigh model (with wide {{applications}} in notably survival analysis) is studied under extended <b>loss</b> <b>functions,</b> not previously considered, by deriving the Bayes estimators under these <b>loss</b> <b>functions,</b> and comparing {{them with a}} Monte Carlo simulation study via their risk functions using different objective priors. [URL]...|$|R
