474|118|Public
25|$|Driver design—including the {{particular}} way {{two or more}} drivers are combined in an enclosure to make a speaker system—is both an art, involving subjective perceptions of timbre and sound quality and a science, involving measurements and experiments. Adjusting a design to improve performance is done {{using a combination of}} magnetic, acoustic, mechanical, electrical, and material science theory, and tracked with high precision measurements and the observations of experienced listeners. A few of the issues speaker and driver designers must confront are distortion, radiation lobing, phase effects, off-axis response, and crossover artifacts. Designers can use an anechoic chamber to ensure the speaker can be measured independently of room effects, or any of several electronic techniques that, to some extent, substitute for such chambers. Some developers eschew anechoic chambers in favor of specific standardized room setups intended to simulate real-life <b>listening</b> <b>conditions.</b>|$|E
5000|$|... 2006: Strength of British English accents in altered <b>listening</b> <b>conditions</b> ...|$|E
50|$|There is {{disagreement}} on how equipment testing {{should be conducted}} and as to its utility. Audiophile publications frequently describe differences in quality which are not detected by standard audio system measurements and double blind testing, claiming that they perceive differences in audio quality which cannot be measured by current instrumentation, and cannot be detected by listeners if <b>listening</b> <b>conditions</b> are controlled, but without providing an explanation for those claims.|$|E
40|$|The {{time-based}} resource-sharing (TBRS) {{model of}} working memory indicates that secondary tasks that capture attention for relatively long periods {{can result in}} the interference of working memory processing and maintenance. The current study investigates if discrete and continuous movements have differing effects on a concurrent, verbal serial recall task. In the <b>listening</b> <b>condition,</b> {{participants were asked to}} recall spoken words presented in lists of six. In the drawing conditions, participants performed the same task while producing discrete (star) or continuous (circle) movements. As hypothesised, participants recalled more words overall in the <b>listening</b> <b>condition</b> compared to the combined drawing conditions. The prediction that the continuous movement condition would reduce recall compared to listening was also supported. Fine-grained analysis at each serial position revealed significantly more words were recalled at mid serial positions in the <b>listening</b> <b>condition,</b> with worst recall for the continuous condition at position 5 compared to the <b>listening</b> and discrete <b>conditions.</b> Kinematic analysis showed that participants increased the size and speed of the continuous movements resulting in a similar duration and number of strokes for each condition. The duration of brief pauses in the discrete condition was associated with the number of words recalled. The results indicate that fine motor movements reduced working memory performance; however, it was not merely performing a movement but the type of the movement that determined how resources were diverted. In the context of the TBRS, continuous movements could be capturing attention for longer periods relative to discrete movements, reducing verbal serial recall...|$|R
40|$|OBJECTIVES: To {{identify}} whether {{speech recognition}} outcomes {{are influenced by}} the choice of ear for cochlear implantation in adults with bilateral hearing loss who use a hearing aid in 1 ear but have long-term auditory deprivation in the other. STUDY DESIGN: Retrospective matched cohort study. Speech recognition results were examined in 30 adults with monaural sound deprivation. Fifteen received the implant in the sound-deprived ear and 15 in the aided ear. SETTING: Tertiary referral centers with active cochlear implant programs. PATIENTS: Adults with bilateral hearing loss and a minimum of 15 years of monaural sound deprivation who received a cochlear implant after meeting the traditional implantation criteria of the referral centers. INTERVENTION: Cochlear implantation with devices approved by the U. S. Food and Drug Administration. MAIN OUTCOME MEASURE(S) : Paired comparisons of postoperative monosyllabic word recognition scores obtained with the implant alone and in the usual <b>listening</b> <b>condition</b> (CI alone or bimodal). RESULTS: With the cochlear implant alone, individuals who received the implant in a sound-deprived ear obtained poorer scores than individuals who received the implant in the aided ear. There was no significant difference, however, in speech recognition results for the 2 groups when tested in their usual <b>listening</b> <b>condition.</b> In particular, poorer speech recognition scores were obtained with the cochlear implant alone by individuals using bimodal hearing. CONCLUSION: Similar clinical outcomes of cochlear implantation can be achieved by adults with a long-term monaural sound deprivation when comparing the usual <b>listening</b> <b>condition,</b> irrespective of whether the implant is in the sound-deprived or in the aided ear. 8 page(s...|$|R
5000|$|Digital <b>listening</b> (<b>condition</b> {{to be met}} {{in order}} to shut down FM in 2017. Failure to reach it can {{postpone}} the shutdown until 2019). Before 2015 50% of the radio listeners must daily use a digital radio platform (currently this is 45%). This does not specify market share of listening, contrary to the UK requirement, only reach. [...] "Digital platform" [...] also includes listening via internet and via the digital TV network. This condition is set {{in order to measure}} the listeners' independence of the analogue FM-platform.|$|R
5000|$|In many {{industrial}} settings {{noise exposure}} metrics {{have been established}} to quantify human exposure to sound. In aerospace settings the Speech Intelligibility Index (SII), published in 1986 by the American National Standards Institute, is a major revision of the AI standard and defines computational methods [...] "that produce highly correlated with the intelligibility of speech {{under a variety of}} adverse <b>listening</b> <b>conditions,</b> such as noise masking, filtering and reverberation".|$|E
50|$|Also {{beginning}} in 1956, his acoustic laboratory studied the subjective evaluation of audio transmission quality, reproduction, and <b>listening</b> <b>conditions.</b> Steinke {{worked closely with}} sound engineers, sound designers (Tonmeisters), and production artists at the Funkhaus Berlin Nalepastrasse, focusing on experimental recordings and the acoustical properties of rooms. In 1960, he became {{the head of a}} telecommunications and broadcasting group, where he was responsible for the introduction of stereophonic broadcasting in East Germany in 1963.|$|E
50|$|The Octagon is a {{flexible}} choice {{for up to}} third-order playback. When oriented one-in-front, {{it can be used}} for reasonably accurate native 5.1 playback (L and R at +/- 45° vs. 30°, and surrounds within the standardized sector at +/- 112.5°). For first order, phasing artefacts might become obvious under non-reverberant <b>listening</b> <b>conditions</b> due to the use of significantly more speakers than required, and Solvang's results (2008) suggest slightly increased timbral defects outside the sweet spot.|$|E
40|$|Introduction: A great {{similarity}} between the patients with cleft lip and palate' behavior and those with auditory processing disorder are related by parents and professors. Objective: To verify the listening in children with cleft lip and palate in six <b>conditions</b> of <b>listening.</b> Method: Professors of 224 students (7 to 11 years old) with cleft completed a questionnaire aiming to judge the student listening in the noise, ideal condition, with multiple stimulus, in the silence, when it is solicited to remember the listened information and during a lengthy period of listening, comparing {{it to the other}} of the same age and <b>listening</b> <b>condition,</b> without cleft. A Prospective Study. Results: The mean of the trial (- 0, 08, standard deviation of 0, 27) of the students with cleft, performed by professor was about the "same difficulty" (zero), when compared with the student without cleft. It was not found statistical significance to anyone conditions, neither to the total value of the questionnaire, considering the gender nor the school year level. Conclusion: The listening characteristics of the students with cleft lip and palate were similar to the other without this craniofacial deformity of the same age and similar <b>listening</b> <b>condition.</b> In the noise, the conditions more difficult occurred when the memory and the auditory attention were required...|$|R
40|$|The {{purpose of}} the study was to {{determine}} whether perceptual masking or cognitive processing accounts for a decline in working memory performance in the presence of competing speech. The types and patterns of errors made on the backward digit span in quiet and multitalker babble at - 5 dB signal-to-noise ratio (SNR) were analyzed. The errors were classified into two categories: item (if digits that were not presented in a list were repeated) and order (if correct digits were repeated but in an incorrect order). Fifty five children with normal hearing were included. All the children were aged between 7 years and 10 years. Repeated measures of analysis of variance (RM-ANOVA) revealed the main effects for error type and digit span length. In terms of <b>listening</b> <b>condition</b> interaction, it was found that the order errors occurred more frequently than item errors in the degraded <b>listening</b> <b>condition</b> compared to quiet. In addition, children had more difficulty recalling the correct order of intermediate items, supporting strong primacy and recency effects. Decline in children′s working memory performance was not primarily related to perceptual difficulties alone. The majority of errors was related to the maintenance of sequential order information, which suggests that reduced performance in competing speech may result from increased cognitive processing demands in noise...|$|R
40|$|This paper {{presents}} the results of computer simulation of active reflectors in a reference listening room which are used to create artificial reflections in a two speaker, stereo listening configuration. This formulates the second phase of experiments in the active listening room project involving the analysis of computer modeling results and loudspeaker selection based on free field response. The aim of this project is to create a truly variable <b>listening</b> <b>condition</b> in a reference listening room by means of active simulation of key acoustic parameters such as the early reflection pattern, early decay time and reverberation time. </p...|$|R
5000|$|Performance on the LISN-S is {{evaluated}} by comparing listeners' performances across four <b>listening</b> <b>conditions,</b> generating two SRT measures and three [...] "advantage" [...] measures. The advantage measures represent the benefit in dB gained when either talker, spatial, or both talker and spatial cues {{are available to}} the listener. The use of advantage measures minimizes the influence of higher order skills on test performance. [...] This serves to control for the inevitable differences that exist between individuals in functions such as language or memory.|$|E
50|$|The {{superior}} temporal gyrus (STG) {{is important}} for language comprehension, but studies also suggest that it plays a functional role in the cocktail party effect. A magnetoencephalography study was conducted on participants that were exposed to five differing <b>listening</b> <b>conditions</b> each with a different level of background noise. It was discovered that the STG has a strong connection with the attended speech stream in a cocktail party setting. When the attended speech stream wasn’t disrupted by background noise a bilateral connection was displayed, but as more background noise was introduced the connection became left-hemisphere-dependent.|$|E
50|$|Driver design—including the {{particular}} way {{two or more}} drivers are combined in an enclosure to make a speaker system—is both an art, involving subjective perceptions of timbre and sound quality and a science, involving measurements and experiments. Adjusting a design to improve performance is done {{using a combination of}} magnetic, acoustic, mechanical, electrical, and material science theory, and tracked with high precision measurements and the observations of experienced listeners. A few of the issues speaker and driver designers must confront are distortion, radiation lobing, phase effects, off-axis response, and crossover artifacts. Designers can use an anechoic chamber to ensure the speaker can be measured independently of room effects, or any of several electronic techniques that, to some extent, substitute for such chambers. Some developers eschew anechoic chambers in favor of specific standardized room setups intended to simulate real-life <b>listening</b> <b>conditions.</b>|$|E
40|$|Normal-­‐hearing {{listeners}} use acoustic cues {{in speech}} {{in order to}} interpret the speaker's emotional state. This study investigates how hearing loss affects {{the perception of the}} emotion dimensions arousal (aroused vs. calm) and valence (positive/negative attitude) in older adults using hearing aids. Affect ratings by 23 hearing aid users are compared for aided and unaided listening and are also compared to ratings by an age-­‐matched group of 24 participants with age-­‐ normal hearing. More specifically, we investigate whether wearing a hearing aid improves the correlation between affect ratings and affect-­‐related acoustic parameters. The rating results for the evaluation of arousal show that the hearing aid users rated utterances as generally more aroused in the aided compared to the unaided <b>condition.</b> Both <b>listening</b> <b>condition</b> and hearing loss severity differences among hearing aid users changed the use of certain acoustic parameters. Compared to the reference group, hearing aid users showed minor differences in the use of intensity for arousal rating. For valence, hearing loss severity did not influence ratings, and neither did <b>listening</b> <b>condition</b> (aided vs. unaided). For both emotion dimensions, ratings of hearing aid users in the aided condition did not generally differ from those of the participants with age-­‐normal hearing. Hearing impairment and the use of hearing aids thus matter particularly for the interpretation of arousal. Therefore, future studies on affect perception in hearing aid users should treat perception of arousal and valence separately...|$|R
50|$|Bose {{conducted}} {{further research}} into psychoacoustics that eventually clarified {{the importance of}} a dominance of reflected sound arriving {{at the head of the}} listener, a <b>listening</b> <b>condition</b> that is characteristic of live performances. This led to a speaker design that aimed eight identical mid-range drivers (with electronic equalization) at the wall behind the speaker, and a ninth driver towards the listener. The purpose of this design was to achieve a dominance of reflected over direct sound in home listening spaces. The pentagonal design used in the Model 901 was, and remains, unconventional compared with most systems, where mid-range and high-frequency speakers directly face the listener.|$|R
40|$|This article {{concentrates}} {{on the role of}} radio within and beyond the Falkland Islands. With radio as their primary communication technology, Falkland Islanders were part of a ‘sonic community’ framed around a complex radio environment. On the eve of the 1982 Argentine invasion, radio was to perform a vital strategic function in terms of alerting Islanders and wider communities (including the UK parliament) to the unfolding events. Using broadcast transcripts, interviews and published materials, this article reconstructs how, and with what consequences, broadcasting and <b>listening</b> <b>conditioned</b> the responses of Islanders to the seventy-four-day occupation, and also details Argentina's attempts to replace this Islander network. It is noted, by way of conclusion, that the official history of the Falklands campaign underplays this crucial sonic dimension...|$|R
5000|$|Good headphones, well {{sealed to}} the ear, provide a flat low-frequency {{pressure}} {{response to the}} ear canal, with low distortion even at high intensities. At low frequencies the ear is purely pressure-sensitive, and the cavity formed between headphones and ear {{is too small to}} introduce modifying resonances. Headphone testing is therefore a good way to derive equal-loudness contours below about 500 Hz, though reservations have been expressed about the validity of headphone measurements when determining the actual threshold of hearing, based on observation that closing off the ear canal produces increased sensitivity to the sound of blood flow within the ear, which the brain appears to mask in normal <b>listening</b> <b>conditions</b> [...] At high frequencies, headphone measurement gets unreliable, and the various resonances of pinnae (outer ear) and ear canal are severely affected by proximity to the headphone cavity.|$|E
5000|$|When one {{listens to}} sounds over {{headphones}} (in {{what is known}} as the [...] "closed field") the sound source appears to arise from center of the head. On the other hand, under normal, so-called free-field, <b>listening</b> <b>conditions</b> sounds are perceived as being externalized. The direction of a sound in space (see sound localization) is determined by the brain when it analyses the interaction of incoming sound with head and external ears. A sound arising to one side reaches the near ear before the far ear (creating an interaural time difference, ITD), and will also be louder at the near ear (creating an interaural level difference, ILD - also known as interaural intensity difference, IID). These binaural cues allow sounds to be lateralized. Although conventional stereo headphone signals make used of ILDs (not ITDs) the sound is not perceived as being externalized.|$|E
5000|$|Ideal <b>listening</b> <b>conditions</b> {{will most}} likely be {{experienced}} with headphones designed and calibrated to give an as flat frequency response as possible in order to reduce colouration of the audio the user is listening to. In most circumstances this has not seemed enough of a problem for end-users to make an investment into headphones {{that will allow them to}} hear audio exactly how the creator of the content intended, and will instead continue to use bundled headphones, or in some cases make investments into headphones endorsed and branded by certain artists. As previously discussed, there are issues of timbral effects present while using BRIR and HRTF data to create spatially improved audio, techniques used by Chris Pike and BBC R&D. The results experienced timbral issues and therefore this method may not yet be a successful way of creating spatially enhanced audio for headphones, but these timbral issues are also experienced with headphone choice. [...] "timbral issues brought about by the use of BRIR and HRFT data any worse than the difference between some cheap headphones that you get with an mp3 player versus some nice Sennhesiers".|$|E
40|$|The {{possible}} {{existence of}} Braille dyslexia has been proposed. We {{have investigated the}} relations between phonological, speech and auditory processing as well as tactile sensitivity measures {{in the group of}} Estonian braille readers. The results showed that braille readers outperformed print readers on the finger sensitivity task, being able to detect the direction of 0, 59 mm smaller gaps. Additionally, braille readers were able to identify nearly 10 % more words correctly than print readers in a most difficult <b>listening</b> <b>condition</b> on a speech perception task. Since the sample size is rather small, no ground breaking conclusions can be drawn. However, based on the results {{it can be said that}} Braille and print reading do largely rely on similar cognitive processes. status: publishe...|$|R
40|$|The {{purpose of}} this {{research}} was {{to examine the effects of}} grade level and playing experience as well as listening con-dition on melodic error detection by young instrumental students. Participants (N = 31) were fifth- and sixth-grade students with either 1 or 2 years of experience playing their instrument. The participants were tested in two listening con-ditions, listening to recordings and listening to themselves while playing. Analysis of the data revealed no differences attributable to <b>listening</b> <b>condition,</b> grade level, or experience. Overall high scores indicate strong abilities in melodic error detection with familiar melodies by students with 1 or more years of experience, including listening to themselves dur-ing performance. Further research is called for with a larger sample size and with more musical elements...|$|R
40|$|The {{infrequent}} {{occurrence of}} a transient feature (deviance; e. g. frequency modulation, FM) {{in one of}} the regular occurring sinusoidal tones (standards) elicits the deviance related mismatch negativity (MMN) component of the event-related brain potential. Based on a memory-based comparison, MMN reflects the mismatch between the representations of incoming and standard sounds. The present study investigated to what extent the infrequent exclusion of an FM is detected by the MMN system. For that purpose we measured MMN to deviances that either consisted of the exclusion or inclusion of an FM at an early or late position within the sound that was present or absent, respectively, in the standard. According to the information-content hypothesis, deviance detection relies on the difference in informational content of the deviant relative to that of the standard. As this difference between deviants with FM and standards without FM is the same as in the reversed case, comparable MMNs should be elicited to FM inclusions and exclusions. According to the feature-detector hypothesis, however, the deviance detection depends on the increased activation of feature detectors to additional sound features. Thus, rare exclusions of the FM should elicit no or smaller MMN than FM inclusions. In passive <b>listening</b> <b>condition,</b> MMN was obtained only for the early inclusion, but not for the exclusions nor for the late inclusion of an FM. This asymmetry in automatic deviance detection seems to partly reflect the contribution of feature detectors even though it cannot fully account for the missing MMN to late FM inclusions. Importantly, the behavioural deviance detection performance in the active <b>listening</b> <b>condition</b> did not reveal such an asymmetry, suggesting that the intentional detection of the deviants is based on the difference in informational content. On a more general level, the results partly support the fresh-afferent account or an extended memory-comparison based account of MMN...|$|R
5000|$|The book Blocks of Consciousness and the Unbroken Continuum (Sound323, UK, 2006) {{contains}} the chapter [...] "On {{the surface of}} silence: reticence in the music of Richard Chartier” in which author and critic Will Montgomery writes [...] "Chartier's work has this overriding singleness of formal vision. While it is clearly formed of discrete parts, the work doesn't look beyond itself, it doesn't refer to other sounds or musical instruments, it is entirely conceived {{within the field of}} digital sound. And, like Donald Judd's three-dimensional objects, it is faithful to itself as a medium: the audio is self-sufficient. Chartier allows his pieces to be governed by their own internal dynamics,finding specific arrangements of sound that integrate the various sonic objects he chooses to work with into coherent wholes.... The music has tended to be categorised in terms of an exemplary austerity. It is easy to see why. However, close listening reveals both a vacuum - that absolute digital silence - and an answering fullness. The counterpart of the work's vanishing quality is its urge to make itself present. To a degree, this is attributable {{to the way in which}} the ear bodies out the sounds it cannot quite grasp - the aural fantasy that the work brings into play. At the same time, it is work of extreme concentration and the sounds that are there in the music are rich with information. The work is ultimately experienced in terms of density as well sparseness, sensuality as well as coolness. The form of minimalism that Chartier has developed on his CDs favours <b>listening</b> <b>conditions</b> that are private, introverted and solitary. Yet the bareness of the works is illusory: under the microscope that he obliges each listener to peer down, a pulsating aural life becomes apparent." ...|$|E
40|$|Suboptimal <b>listening</b> <b>conditions</b> {{interfere}} with listeners' on-line comprehension. A degraded source signal, noise that interferes with sound transmission, and/or listeners' cognitive or linguistic limitations {{are examples of}} adverse <b>listening</b> <b>conditions.</b> Few studies have explored the interaction of these factors in pediatric populations. Yet, they represent an increasing challenge in educational settings. We will in the following report on our research and address the effect of adverse <b>listening</b> <b>conditions</b> pertaining to speakers' voices, background noise, and children's cognitive capacity on listening comprehension. Results from our studies clearly indicate that children risk underachieving both in formal assessments and in noisy class-rooms when an examiner or teacher speaks with a hoarse (dysphonic) voice. This seems particularly true when task complexity is low or {{when a child is}} approaching her/his limits of mastering a comprehension task...|$|E
40|$|Purpose: The {{objective}} {{of this study was}} to investigate the effect of chronic tinnitus on listening effort. Method: Thirteen normal-hearing young adults with chronic tinnitus were matched with a control group for age, gender, hearing thresholds, and educational level. A dual-task paradigm was used to evaluate listening effort in different <b>listening</b> <b>conditions.</b> A primary speech-recognition task and a secondary memory task were performed both separately and simultaneously. Furthermore, subjective listening effort was questioned for various listening situations. The Tinnitus Handicap Inventory was used to control for tinnitus handicap. Results: Listening effort significantly increased in the tinnitus group across <b>listening</b> <b>conditions.</b> There was no significant difference in listening effort between <b>listening</b> <b>conditions,</b> nor was there an interaction between groups and <b>listening</b> <b>conditions.</b> Subjective listening effort did not significantly differ between both groups. Conclusions: This study is a first exploration of listening effort in normal-hearing participants with chronic tinnitus showing that listening effort is increased as compared with a control group. There is a need to further investigate the cognitive functions important for speech understanding and their possible relation with the presence of tinnitus and listening effort...|$|E
40|$|Schizophrenia {{patients}} {{have been shown}} to exhibit subnormal levels of electrophysiological suppression to self-initiated, button press elicited sounds. These self-suppression deficits {{have been shown to}} improve following the imposition of a subsecond delay between the button press and the evoked sound. The current study aimed to investigate whether nonclinical individuals who scored highly on the personality dimension of schizotypy would exhibit similar patterns of self-suppression abnormalities to those exhibited in schizophrenia. Thirty-nine nonclinical individuals scoring above the median (High Schizotypy) and 41 individuals scoring below the median (Low Schizotypy) on the Schizotypal Personality Questionnaire (SPQ) underwent electroencephalographic recording. The amplitude of the N 1 -component was calculated while participants (1) listened to tones initiated by a willed button press and played back with varying delay periods between the button press and the tone (Active conditions) and (2) passively listened to a series of tones (<b>Listen</b> <b>condition).</b> N 1 -suppression was calculated by subtracting the amplitude of the N 1 -component of the auditory evoked potential in the Active condition from that of the <b>Listen</b> <b>condition,</b> while controlling for the activity evoked by the button press per se. The Low Schizotypy group exhibited significantly higher levels of N 1 -suppression to undelayed tones compared to the High Schizotypy group. Furthermore, while N 1 -suppression was found to decrease linearly with increasing delays between the button press and the tone in the Low Schizotypy group, {{this was not the case}} in the High Schizotypy group. The findings of this study suggest that nonclinical, highly schizotypal individuals exhibit subnormal levels of N 1 -suppression to undelayed self-initiated tones and an abnormal pattern of N 1 -suppression to delayed self-initiated tones. To the extent that these results are similar to those previously reported in patients with schizophrenia, these findings provide support for the existence of a neurophysiological "continuum of psychosis"...|$|R
40|$|The {{purpose of}} the study was to examine {{intonation}} patterns concerning melodic and harmonic musical intervals compared to equal temperament. Forty-eight junior high school, high school, and college undergraduate musicians were assigned to one offour experimental conditions in a split-plot design. Subjects performed four diatonic intervals (major third, perfect fourth, perfect fifth, and major sixth) both melodically and harmonically. Results indicated no significant differences in overall intonation accuracy in relationship to performed ascending and descending directions or among the four test intervals. In relationship to sharpness versus flatness there were significant, if musically inconsequential, differences: when subjects descended, intervals were performed slightly sharper; when subjects ascended, intervals were performed slightly flatter. Junior high school subjects performed slightly sharper compared to college subjects. Differential verbal feedback and a headphone <b>listening</b> <b>condition</b> produced no significant differences...|$|R
40|$|Word {{discrimination}} {{scores were}} obtained from 25 black and 25 white college students. Monosyllabic words were spoken by 24 black and 24 white children from a low socio-economic urban environment. Listening was conducted in quiet, at a 10 dB signal-to-noise ratio, and at a 0 dB signal-to-noise ratio. Results showed black children and white children were equally intelligible to the black adult-listeners, while the white adult-listeners found white children significantly more intelligible than black children. Word discrimination scores for black adults listening to black children were {{comparable to those of}} white adults listening to the white children. The quiet <b>listening</b> <b>condition</b> yielded the best scores, 10 dB S/N next best, and 0 dB the poorest. Noise deteriorated word discrimination scores of the black and white listeners differently. Important phonological differences noted between Black English and standard Englis...|$|R
40|$|Purpose: To {{evaluate}} cortical auditory function, including speech recognition, {{in children}} with benign rolandic epilepsy (BRE). Methods: Fourteen children, seven patients with BRE and seven matched controls, underwent audiometric and behavioral testing, simultaneous EEG recordings, and auditory-evoked potential recordings with speech and tones. Speech recognition was tested under multiple <b>listening</b> <b>conditions.</b> Results: All participants demonstrated normal speech recognition abilities in quiet, as well as normal peripheral and subcortical auditory function. BRE patients performed significantly worse than controls when speech recognition was tested under adverse <b>listening</b> <b>conditions,</b> including backgroun...|$|E
40|$|The {{learning}} effects under filtered and unfiltered <b>listening</b> <b>conditions</b> for ten severely hearing-impaired {{children were}} investigated using minimal pair distinctions. Significant learning occurred under both <b>listening</b> <b>conditions,</b> {{but there was}} no significant difference between performance with filtered and unfiltered speech. Subjects were able to learn distinctions based on gross spectral and durational cues, but no learning occurred when minimal pair distinctions depended on relatively subtle spectral differences. It was concluded that these deaf children did not have access to compensatory cues apparently used by hard-of-hearing adults in speech discrimination...|$|E
40|$|One of a listener’s major {{tasks in}} {{understanding}} continuous speech in segmenting the speech signal into separate words. When <b>listening</b> <b>conditions</b> are difficult, speakers can help listeners by deliberately clear speech. We found that speakers do indeed attempt to makr word boundaries; moreover, they differentiate between word boundaries {{in a way}} which suggest they are sensitive to listener needs. Application of heuristic segmentation strategies makes word boundaries before strong syllables easiest for listeners to perceive; but under difficult <b>listening</b> <b>conditions</b> speakers pay more attention to marking word boundaries before weak syllables, i. e. they mark those boundaries which are otherwise particularly hard to perceive...|$|E
40|$|M. Cardaci's (2000) Mental Clock Model {{maintains}} that a task requiring a low mental workload {{is associated with}} an acceleration of perceived time, whereas a task requiring a high mental workload {{is associated with a}} deceleration. The authors examined the predictions of this model in a musical <b>listening</b> <b>condition</b> in which musical pieces were audible in several structural complexities. To measure the effects of musical complexity on time estimation, the authors used retrospective and prospective time-estimation paradigms. For the retrospective paradigm, the authors invited participants to listen to a musical piece and then estimate its duration. For the prospective paradigm, the authors invited participants to stop the musical reproduction after a certain interval of time. Results show that the variations of musical complexity yielded the empirical effects that the Mental Clock Model predicted for both paradigms...|$|R
40|$|The {{effects of}} {{helicopter}} interior noise on passenger annoyance for both reverie and listening situations was investigated. The relative effectiveness of several metrics for quantifying annoyance response for these situations was also studied. The noise stimuli were based upon {{recordings of the}} interior noise of civil helicopter research aircraft. These noises were presented at levels ranging from approximately 70 to 86 d with various tonal components selectively attenuated to give a range of spectra. The listening task required the subjects to listen to and record phonetically-balanced words presented within the various noise environments. Results indicate that annoyance during a <b>listening</b> <b>condition</b> is generally higher than annoyance under a reverie condition for corresponding interior noise environments. Attenuation of the tonal components results in increases in listening performance but has only a small effect upon annoyance for a given noise level...|$|R
40|$|Reduction in {{frequency}} resolving {{capacity of the}} auditory system due to spread of masking of frequency components by neighboring frequency components degrades speech perception in cases of sensorineural hearing impairment. We have carried out experimental evaluation of splitting speech into two signals by using a bank of critical band filters, {{in order to reduce}} the effect of spectral masking in the cochlea. The dichotically presented signals are perceptually integrated in the auditory cortex. Listening tests were carried out with vowel-consonant-vowel and consonant-vowel syllables for twelve English consonants on five normal hearing subjects with simulation of sensorineural impairment done by adding white masking noise to the speech signal at various SNRs. Significant improvements in recognition score were obtained under adverse <b>listening</b> <b>condition.</b> Improvement in the reception of speech feature of voicing, place, and manner was observed in information transmission analysis...|$|R
