69|24|Public
2500|$|If one of {{the shape}} {{parameters}} is known, the problem is considerably simplified. [...] The following <b>logit</b> <b>transformation</b> {{can be used to}} solve for the unknown shape parameter (for skewed cases such that , otherwise, if symmetric, both -equal- parameters are known when one is known): ...|$|E
2500|$|This <b>logit</b> <b>transformation</b> is the {{logarithm}} of {{the transformation}} that divides the variable X by its mirror-image (X/(1 - X) resulting in the [...] "inverted beta distribution" [...] or beta prime distribution (also known as [...] beta distribution of the second kind or Pearson's Type VI) with support ...|$|E
50|$|If {{values are}} {{naturally}} restricted {{to be in}} the range 0 to 1, not including the end-points, then a <b>logit</b> <b>transformation</b> may be appropriate: this yields values in the range (&minus;∞,∞).|$|E
2500|$|<b>Logit</b> <b>{{transform}}ations</b> are interesting, as {{they usually}} transform various shapes (including J-shapes) into (usually skewed) bell-shaped densities over the logit variable, {{and they may}} remove the end singularities over the original variable: ...|$|R
5000|$|... #Caption: Plot of logit(X) = ln(X/(1−X)) (vertical axis) vs. X in {{the domain}} of 0 to 1 (horizontal axis). <b>Logit</b> <b>{{transform}}ations</b> are interesting, as they usually transform various shapes (including J-shapes) into (usually skewed) bell-shaped densities over the logit variable, and they may remove the end singularities over the original variable ...|$|R
40|$|In this paper, a Bayesian {{hierarchical}} model {{is used to}} anaylze the female breast cancer mortality rates for the State of Missouri from 1969 through 2001. The <b>logit</b> <b>transformations</b> of the mortality rates {{are assumed to be}} linear over the time with additive spatial and age effects as intercepts and slopes. Objective priors of the {{hierarchical model}} are explored. The Bayesian estimates are quite robustness in terms change of the hyperparamaters. The spatial correlations are appeared in both intercepts and slopes...|$|R
50|$|Thus the <b>logit</b> <b>transformation</b> is {{referred}} to as the link function in logistic regression—although the dependent variable in logistic regression is binomial, the logit is the continuous criterion upon which linear regression is conducted.|$|E
50|$|A variance-stabilizing {{transformation}} aims {{to remove}} a variance-on-mean relationship, so that the variance becomes constant relative to the mean. Examples of variance-stabilizing transformations are the Fisher transformation for the sample correlation coefficient, the square root transformation or Anscombe transform for Poisson data (count data), the Box-Cox transformation for regression analysis and the arcsine square root transformation or angular transformation for proportions (binomial data). While commonly used for statistical analysis of proportional data, the arcsine square root transformation is not recommended because logistic regression or a <b>logit</b> <b>transformation</b> are more appropriate for binomial or non-binomial proportions, respectively, especially due to decreased type-II error.|$|E
5000|$|The Beta(0,0) {{distribution}} {{was proposed}} by J.B.S. Haldane, {{who suggested that}} the prior probability representing complete uncertainty should be proportional to p−1(1−p)−1. The function p−1(1−p)−1 {{can be viewed as}} the limit of the numerator of the beta distribution as both shape parameters approach zero: α, β → 0. The Beta function (in the denominator of the beta distribution) approaches infinity, for both parameters approaching zero, α, β → 0. Therefore, p−1(1−p)−1 divided by the Beta function approaches a 2-point Bernoulli distribution with equal probability 1/2 at each Dirac delta function end, at 0 and 1, and nothing in between, as α, β → 0. A coin-toss: one face of the coin being at 0 and the other face being at 1. The Haldane prior probability distribution Beta(0,0) is an [...] "improper prior" [...] because its integration (from 0 to 1) fails to strictly converge to 1 due to the Dirac delta function singularities at each end. However, this is not an issue for computing posterior probabilities unless the sample size is very small. Furthermore, Zellner points out that on the log-odds scale, (the <b>logit</b> <b>transformation</b> ln(p/1−p)), the Haldane prior is the uniformly flat prior. The fact that a uniform prior probability on the logit transformed variable ln(p/1−p) (with domain (-∞, ∞)) is equivalent to the Haldane prior on the domain 1 was pointed out by Harold Jeffreys in the first edition (1939) of his book Theory of Probability ( [...] p. 123). Jeffreys writes [...] "Certainly if we take the Bayes-Laplace rule right up to the extremes we are led to results that do not correspond to anybody's way of thinking. The (Haldane) rule dx/(x(1−x)) goes too far the other way. It would lead to the conclusion that if a sample is of one type with respect to some property there is a probability 1 that the whole population is of that type." [...] The fact that [...] "uniform" [...] depends on the parametrization, led Jeffreys to seek a form of prior that would be invariant under different parametrizations.|$|E
40|$|Asymptotic {{standard}} errors (SEs) of item re-sponse theory equating coefficient estimates are derived using response functions or their transfor-mations. SEs are {{obtained by the}} method for the two- and three-parameter logistic models when the asymptotic variance-covariance matrix of the item parameter estimates is given. Two variations of the item and test response function methods and SEs of their parameter estimates are presented that use <b>logit</b> <b>transformations</b> of the item response functions. Numerical examples are given that show that the SEs of the item and test response function methods are smaller than those of other methods, particularly for the three-parameter model. Index terms: char-acteristic curve method, common items, equating...|$|R
40|$|A {{solid-phase}} immunofluorometric assay {{was used}} to qualitatively characterize and precisely measure human immunoglobulin class-specific antibody responses in legionellosis. Stable antigen preparations consisted of cells grown at 25 degrees C that were killed, fixed with Formalin vapors, washed, and lyophilized. Working-curve material consisted of dilutions of selected convalescent sera. Linear regressions of <b>logit</b> <b>transformations</b> of relative fluorescence intensities versus the logarithm of the relative concentrations of sera were determined to give immunoglobulin class-specific antibody levels from uninfected and infected individuals. Each fluorescence intensity obtained with immunoglobulin class-specific antibody was converted to a multiple of the median fluorescence intensity obtained with sera from uninfected individuals. A presumptive-positive acute-phase legionellosis serum was defined for each immunoglobulin class by a multiple of the normal median fluorescence intensity that was greater than the multiple of the normal median from approximately 97 % of the uninfected population...|$|R
40|$|Many {{variables}} in the social, physical, and biosciences, including neuroscience, are non-normally distributed. To improve the statistical properties of such data, or to allow parametric testing, logarithmic or <b>logit</b> <b>transformations</b> are often used. Box-Cox transformations or ad hoc methods are sometimes used for parameters for which no transformation is known to approximate normality. However, these methods do not always give good agreement with the Gaussian. A transformation is discussed that maps probability distributions {{as closely as possible}} to the normal distribution, with exact agreement for continuous distributions. To illustrate, the transformation is applied to a theoretical distribution, and to quantitative electroencephalographic (qEEG) measures from repeat recordings of 32 subjects which are highly non-normal. Agreement with the Gaussian was better than using logarithmic, <b>logit,</b> or Box-Cox <b>transformations.</b> Since normal data have previously been shown to have better test-retest reliability than non-normal data under fairly general circumstances, the implications of our transformation for the test-retest reliability of parameters were investigated. Reliability was shown to improve with the transformation, where the improvement was comparable to that using Box-Cox. An advantage of the general transformation {{is that it does not}} require laborious optimization over a range of parameters or a case-specific choice of form...|$|R
30|$|The {{contribution}} of each factor to the observed DRWR cannot be computed with the fractional logit model {{due to the}} <b>logit</b> <b>transformation.</b>|$|E
40|$|Representatives of the WHO {{influenza}} programme recently {{proposed a}} standard method of determining neuraminidase activity and neuraminidase inhibition (NI) antibody titres. <b>Logit</b> <b>transformation</b> {{of the data}} obtained with the WHO method for the NI assay permits a more efficient performance of the test and easy calculation of titres with a computer programme...|$|E
40|$|Observations of {{the recent}} {{developments}} in hardware, software, and the Internet reinforce the importance and role of Information and Communication Technology (ICT). This paper utilizes <b>logit</b> <b>transformation</b> for proportion data analysis to empirically investigate determinants of ICT expenditure. A fixed-effects panel data model {{was used to examine}} the factors influencing expenditure on ICT. Two regressions were estimated for a sub-sample of 11 Asia-Pacific countries and 22 OECD countrie...|$|E
40|$|A Bayesian {{adaptive}} design is proposed for dose-finding in phase I/II clinical trials {{to incorporate the}} bivariate outcomes, toxicity and efficacy, of a new treatment. Without specifying any parametric functional form for the drug dose-response curve, we jointly model the bivariate binary data {{to account for the}} correlation between toxicity and efficacy. After observing all the responses of each cohort of patients, the dosage for the next cohort is escalated, deescalated, or unchanged according to the proposed odds ratio criteria constructed from the posterior toxicity and efficacy probabilities. A novel class of prior distributions is proposed through <b>logit</b> <b>transformations</b> which implicitly imposes a monotonic constraint on dose toxicity probabilities and correlates the probabilities of the bivariate outcomes. We conduct simulation studies to evaluate the operating characteristics of the proposed method. Under various scenarios, the new Bayesian design based on the toxicity-efficacy odds ratio trade-offs exhibits good properties and treats most patients at the desirable dose levels. The method is illustrated with a real trial design for a breast medical oncology study. © 2006, The International Biometric Society. link_to_subscribed_fulltex...|$|R
40|$|Background: Prostate bed (PB) {{contouring}} is {{time consuming}} and associated with inter-observer variability. We evaluated an automated atlas-based segmentation (AABS) engine in {{its potential to}} reduce contouring time and inter-observer variability. Methods: An atlas builder (AB) manually contoured the prostate bed, rectum, left femoral head (LFH), right femoral head (RFH), bladder, and penile bulb of 75 post-prostatectomy cases to create an atlas according to the recent RTOG guidelines. 5 other Radiation Oncologists (RO) and the AABS contoured 5 new cases. A STAPLE contour {{for each of the}} 5 patients was generated. All contours were anonymized and sent back to the 5 RO to be edited as clinically necessary. All contouring times were recorded. The dice similarity coefficient (DSC) was used to evaluate the unedited- and edited- AABS and inter-observer variability among the RO. Descriptive statistics, paired t-tests and a Pearson correlation were performed. ANOVA analysis using <b>logit</b> <b>transformations</b> of DSC values was calculated to assess inter-observer variability. Results: The mean time for manual contours and AABS was 17. 5 - and 14. 1 minutes respectively (p = 0. 003). The DSC results (mean, SD) for the comparison of the unedited-AABS versus STAPLE contours for the PB (0. 48, 0. 17), bladder (0. 67, 0. 19), LFH (0. 92, 0. 01), RFH (0. 92, 0. 01), penile bulb (0. 33, 0. 25) and rectum (0. 59, 0. 11). The DSC result...|$|R
40|$|A {{risk score}} s for event E is a {{function}} of covariates with the property that P(E) is an increasing function of s. Motivated by applications in medicine and in criminology, we suggest the logit rank plot as a good way of summarizing the effectiveness of such a score. Explicitly, plot togit P(E) against logit(r), where r is the proportional rank of s in a sample or population. The slope of this plot gives an overall measure of effectiveness, and the <b>logit</b> rank <b>transformation</b> provides a common basis on which different risk scores can be compared. Some practical and theoretical aspects are discussed...|$|R
40|$|Abstract- This paper {{reports on}} the {{development}} of a learning system for the prediction of dichotomous response variables by combining fuzzy concept with classical regression technique. The algorithm involves linear transformation followed by linear programming. In the algorithm presented it was assumed that the logarithm of the odds (logit) is linearly related to X’s, the independent variables after undergoing the <b>logit</b> <b>transformation.</b> In this paper the research backgrounds and methodology are presented Index terms- dichotomous, fuzzy regression, prediction I...|$|E
30|$|Given the {{possibility}} of substantial bias in GLMM parameter estimates, as an alternative approach for comparison we fitted our model as a LMM using an empirical <b>logit</b> <b>transformation</b> of the proportional data. Piepho (2003) provides a good discussion of available transformations for proportional data. Except for the angular, most transformations fail when an observed proportion is 0 or 1, but some functions may be modified to account for such. We used the empirical <b>logit</b> <b>transformation,</b> log((x[*]+[*]c)/(1 [*]−[*]x[*]+[*]c)) (Atkinson 1985), where x is the observed proportion and c a small constant =[*] 0.5 /n when the data are binomial. The model was fitted using Proc MIXED in SAS® {{as well as in}} ASReml-R. Comparison of variance component estimates between GLMM and LMM (Table  1) appear to suggest that former underestimated the additive variance for which the random effects had a complex covariance structure, The sum of variance component estimates in the LMM (Table  1) agrees better with the total sample variance value of 2.04 for the empirical logit transformed data. The narrow-sense heritabilities estimated by LMM were much higher than those of GLMMs (Table  1).|$|E
40|$|In this paper, {{we propose}} one new {{confidence}} interval for the binomial proportion; our interval {{is based on}} the Edgeworth expansion of a <b>logit</b> <b>transformation</b> of the sample proportion. We provide theoretical justification for the proposed interval and also compare the finite-sample performance of the proposed interval with the three best existing intervals—the Wilson interval, the Agresti–Coull interval and the Jeffreys interval—in terms of their coverage probabilities and expected lengths. We illustrate the proposed method in two real clinical studies...|$|E
40|$|We {{tested the}} {{hypothesis}} that Crohn’s disease (CD) -related genetic polymorphisms involved in host innate immunity are associated with shifts in human ileum–associated microbial composition in a cross-sectional analysis of human ileal samples. Sanger sequencing of the bacterial 16 S ribosomal RNA (rRNA) gene and 454 sequencing of 16 S rRNA gene hypervariable regions (V 1 –V 3 and V 3 –V 5), were conducted on macroscopically disease-unaffected ileal biopsies collected from 52 ileal CD, 58 ulcerative colitis and 60 control patients without inflammatory bowel diseases (IBD) undergoing initial surgical resection. These subjects also were genotyped for the three major NOD 2 risk alleles (Leu 1007 fs, R 708 W, G 908 R) and the ATG 16 L 1 risk allele (T 300 A). The samples were linked to clinical metadata, including body mass index, smoking status and Clostridia difficile infection. The sequences were classified into seven phyla/subphyla categories using the Naïve Bayesian Classifier of the Ribosome Database Project. Centered log ratio transformation of six predominant categories was included {{as the dependent variable}} in the permutation based MANCOVA for the overall composition with stepwise variable selection. Polymerase chain reaction (PCR) assays were conducted to measure the relative frequencies of the Clostridium coccoides – Eubacterium rectales group and the Faecalibacterium prausnitzii spp. Empiric <b>logit</b> <b>transformations</b> of the relative frequencies of these two microbial groups were included in permutation-based ANCOVA. Regardless of sequencing method, IBD phenotype, Clostridia difficile and NOD 2 genotype were selected as associated (FDR ≤ 0. 05) with shifts in overall microbial composition. IBD phenotype and NOD 2 genotype were also selected as associated with shifts in the relative frequency of the C. coccoides – E. rectales group. IBD phenotype, smoking and IBD medications were selected as associated with shifts in the relative frequency of F. prausnitzii spp. These results indicate that the effects of genetic and environmental factors on IBD are mediated at least in part by the enteric microbiota...|$|R
40|$|A {{sequence}} of three programs is described for efficient design {{and analysis of}} radio-immunoassays. The first program designs the assay; the second program analyzes all available data according to the organizational base provided by the first program; and the third program summarizes the results of several assays in either tabular or graphical form. The analysis program uses a <b>logit</b> response-log dose <b>transformation</b> to obtain a linear inhibition curve for all preparations assayed at multiple levels. The curves are subjected to a weithted, least squares, regression analysis. All curves are tested for linearity and parallelism with the curve chosen as standard, and a weighted mean potency estimate with error limits is computed for all preparations run at single or multiple dose levels {{with any degree of}} replication...|$|R
40|$|Abstract Background Prostate bed (PB) {{contouring}} is {{time consuming}} and associated with inter-observer variability. We evaluated an automated atlas-based segmentation (AABS) engine in {{its potential to}} reduce contouring time and inter-observer variability. Methods An atlas builder (AB) manually contoured the prostate bed, rectum, left femoral head (LFH), right femoral head (RFH), bladder, and penile bulb of 75 post-prostatectomy cases to create an atlas according to the recent RTOG guidelines. 5 other Radiation Oncologists (RO) and the AABS contoured 5 new cases. A STAPLE contour {{for each of the}} 5 patients was generated. All contours were anonymized and sent back to the 5 RO to be edited as clinically necessary. All contouring times were recorded. The dice similarity coefficient (DSC) was used to evaluate the unedited- and edited- AABS and inter-observer variability among the RO. Descriptive statistics, paired t-tests and a Pearson correlation were performed. ANOVA analysis using <b>logit</b> <b>transformations</b> of DSC values was calculated to assess inter-observer variability. Results The mean time for manual contours and AABS was 17. 5 - and 14. 1 minutes respectively (p = 0. 003). The DSC results (mean, SD) for the comparison of the unedited-AABS versus STAPLE contours for the PB (0. 48, 0. 17), bladder (0. 67, 0. 19), LFH (0. 92, 0. 01), RFH (0. 92, 0. 01), penile bulb (0. 33, 0. 25) and rectum (0. 59, 0. 11). The DSC results (mean, SD) for the comparison of the edited-AABS versus STAPLE contours for the PB (0. 67, 0. 19), bladder (0. 88, 0. 13), LFH (0. 93, 0. 01), RFH (0. 92, 0. 01), penile bulb (0. 54, 0. 21) and rectum (0. 78, 0. 12). The DSC results (mean, SD) for the comparison of the edited-AABS versus the expert panel for the PB (0. 47, 0. 16), bladder (0. 67, 0. 18), LFH (0. 83, 0. 18), RFH (0. 83, 0. 17), penile bulb (0. 31, 0. 23) and rectum (0. 58, 0. 09). The DSC results (mean, SD) for the comparison of the STAPLE contours and the 5 RO are PB (0. 78, 0. 15), bladder (0. 96, 0. 02), left femoral head (0. 87, 0. 19), right femoral head (0. 87, 0. 19), penile bulb (0. 70, 0. 17) and the rectum (0. 89, 0. 06). The ANOVA analysis suggests inter-observer variability among {{at least one of the}} 5 RO (p value = 0. 002). Conclusion The AABS tool results in a time savings, and when used to generate auto-contours for the femoral heads, bladder and rectum had superior to good spatial overlap. However, the generated auto-contours for the prostate bed and penile bulb need improvement. </p...|$|R
40|$|Increased {{lymphocyte}} cytotoxicity, {{particularly of}} 'killer' K cell type was recorded with repeated immunizations of either C. parvum or BCG. A 3 week interval between immunizations {{was capable of}} maintaining the increase in cytotoxicity. No marked alterations of 'recall' skin hypersensitivity reactions nor of peripheral blood counts were noted. Expression of cytotoxicity results as percentage 51 Cr release, lytic units/ml and cytotoxic capacity (after <b>logit</b> <b>transformation</b> of the cytotoxicity-lymphocyte curves) are described. A 3 week immunization schedule is suggested where BCG and C. parvum are used as immunotherapeutic agents, in the doses quoted...|$|E
3000|$|Model {{calibration}} {{was assessed}} using the Hosmer–Lemeshow (HL) goodness-of-fit statistics with 8 degrees of freedom and plotting a calibration belt [21]. The calibration belt is a fitted polynomial logistic function curve between the <b>logit</b> <b>transformation</b> of the predicted probability and outcome with surrounding 80 % CI (light grey area) and 95 % CI (dark grey area) [21]. The calibration belt is more useful than the HL test as it highlights ranges of significant miscalibration [21]. To assess the discrimination performance, an area under the receiver operating characteristic (AUROC) curve was constructed and a c-statistic was estimated. The Nagelkerke’s R [...]...|$|E
40|$|OBJECTIVE—The {{attributable}} risk (AR), {{which represents the}} proportion of cases who can be preventable when we completely eliminate a risk factor in a population, is {{the most commonly used}} epidemiological index {{to assess the impact of}} controlling a selected risk factor on community health. The goal of this paper is to develop and search for good interval estimators of the AR for case-control studies with matched pairs.  METHODS—This paper considers five asymptotic interval estimators of the AR, including the interval estimator using Wald's statistic suggested elsewhere, the two interval estimators using the logarithmic transformations: log(x) and log(1 -x), the interval estimator using the <b>logit</b> <b>transformation</b> log(x/(1 -x)), and the interval estimator derived from a simple quadratic equation developed in this paper. This paper compares the finite sample performance of these five interval estimators by calculation of their coverage probability and average length in a variety of situations.  RESULTS—This paper demonstrates that the interval estimator derived from the quadratic equation proposed here can not only consistently perform well with respect to the coverage probability, but also be more efficient than the interval estimator using Wald's statistic in almost all the situations considered here. This paper notes that although the interval estimator using the logarithmic transformation log(1 -x) may also perform well with respect to the coverage probability, using this estimator is likely to be less efficient than the interval estimator using Wald's statistic. Finally, this paper notes that when both the underlying odds ratio (OR) and the prevalence of exposure (PE) in the case group are not large (OR ⩽ 2 and PE ⩽ 0. 10), the application of the two interval estimators using the transformations log(x) and log(x/(1 -x)) can be misleading. However, when both the underlying OR and PE in the case group are large (OR ⩾ 4 and PE ⩾ 0. 50), the interval estimator using the <b>logit</b> <b>transformation</b> can actually outperform all the other estimators considered here in terms of efficiency.  CONCLUSIONS—When there is no prior knowledge of the possible range for the underlying OR and PE, the interval estimator derived from the quadratic equation developed here for general use is recommended. When it is known that both the OR and PE in the case group are large (OR ⩾ 4 and PE ⩾ 0. 50), it is recommended that the interval estimator using the <b>logit</b> <b>transformation</b> is used.    Keywords: case-control studies; {{attributable risk}}; interval estimatio...|$|E
40|$|There is {{a strong}} {{competition}} from low-priced imported catfish fillets resulting in a declining market share for domestic farm-raised catfish fillets. To match the competition, catfish processors are embarking on pricing policy measures that are volume-oriented instead of profit- or image-oriented. This could be an effective short-run pricing policy measure for optimal long-run sustainability and profitability of the industry. Volume pricing strategies are aimed at meeting target sales volumes or market shares. This paper explores and compares {{the performance of the}} standard logit, the inverse power <b>transformation</b> (IPT) <b>logit</b> and the logarithmic version of the inverse power <b>transformation</b> <b>logit</b> models in terms of generating forecasts for market share of U. S. farm-raised catfish fillets. The results suggest a better performance of the log-IPT in every aspect compared to the linear standard logit and the IPT logit models. market share, forecasting, flexible logit, Marketing, Q 130, C 250, C 530,...|$|R
30|$|Estimation of {{variance}} components and best linear unbiased predictions (BLUPs) of genotype random effects on continuous traits by fitting linear mixed models (LMMs) to familial data is well established. Statistical models with complex variance structures {{that account for}} pedigree as well as spatial trends within a field layout have been extensively applied to such data to assess if the trait of interest has a significant genetic component and is heritable (Piepho et al. 2008). However, for transformed proportional data the use of LMMs can be limiting and results can be unreliable, particularly when sample sizes are variable and small. Furthermore, in case of some transformations such as the angular, model predictions back-transformed to the original proportional scale are not necessarily bounded in the interval [0, 1]. The empirical <b>logit</b> and probit <b>transformations</b> do not suffer from this problem. When estimating genetic parameters, such as the heritability, of binary traits, parameterisation is better handled on an underlying unbounded continuous liability scale {{in which it is}} most interpretable (Lee et al. 2011).|$|R
40|$|During {{the past}} years, the linear logit {{model has been}} used {{extensively}} in modal choice analysis. More recently, the introduction of Box-Cox transformations on the explanatory variables in passenger studies have generally shown {{the superiority of the}} Box-Cox logit over the linear logit. Nevertheless, we have found only one such application in freight transportation. This study is devoted to filling this gap by testing different configurations of the Box-Cox logit over the linear logit. Our results confirm the usefulness of the nonlinear Box-Cox specification found in passenger studies. We have used an original data bank developed for Canada. The bank contains, for 64 commodity groups, the 1979 domestic flows among 67 geographical zones, by three transportation modes: truck (private and for hire), rail and ship. To the authors' knowledge, this is the first Canadian study on mode choice that takes into account private trucking; since Canadian private trucking is at least as important as for hire trucking, this could have contributed to the results obtained. freight mode choice <b>logit</b> model Box-Cox <b>transformation</b> Canada...|$|R
40|$|This {{article is}} {{distinct}} in its {{application of the}} <b>logit</b> <b>transformation</b> to the poverty ratio {{for the purpose of}} empirically examining whether the financial sector helps improve standards of living for low-income people. We propose the term financial permeation to describe how financial networks expand to spread money among the poor. We measure financial permeation by three indicators related to microfinance institutions (MFIs) and then examine its effect on poverty reduction at the macro level using panel data for 90 developing countries from 1995 to 2008. We find that financial permeation has a statistically significant and robust effect on decreasing the poverty ratio. Developing countries, Microfinance, Poverty, Poverty reduction, Financial permeation, Microfinance, Panel Data...|$|E
40|$|This study {{examines}} the cost efficiency of non-life Takaful insurance firms operating in 10 Islamic countries. Non-parametric {{data envelopment analysis}} is used to compute cost efficiency scores and a second-stage <b>logit</b> <b>transformation</b> regression model is then estimated to test the influence of corporate characteristics on these efficiencies. We find that non-executive directors and separating the Chief Executive Officer and Chairman functions do not improve cost efficiency. However, board size, firm size and product specialisation have positive effects on the cost efficiency of Takaful insurers. In contrast, the regulatory environment is found not to be statistically significant in terms of improving cost efficiency. We conclude that our results could have important commercial and policy implications. ...|$|E
40|$|The use of {{logistic}} regression for outcome classification of dichotomous variables {{is well known}} in data mining applications. The estimated probability of the <b>logit</b> <b>transformation</b> belongs to the class of canonical link functions that follow from particular probability distribution functions. A closely related model is the probit link which can be used for binary responses. Although the probit link is not canonical, in some cases the overall fit of the model can be improved by using non-canonical link functions. This article reviews the properties of the probit link function and discusses its applications in data mining problems. Contrasts and comparisons are made with the logistic link function and an example provides further illustration...|$|E
40|$|Introduction. Health inequalities reflect multidimensional {{inequality}} (income, education, {{and other}} indicators of socioeconomic position) and vary across countries and welfare regimes. To which extent there is intergenerational transmission of health via parental socioeconomic status {{has rarely been}} investigated in comparative perspective. The study sought to explore if different measures of stratification produce the same health gradient and to which extent health gradients of income and of social origins vary with level of living and income inequality. Method. A total of 299, 770 observations were available from 18 countries assessed in EU-SILC 2005 and 2011 data, which contain information on social origins. Income inequality (Gini) and level of living were calculated from EU-SILC. <b>Logit</b> rank <b>transformation</b> provided normalized inequalities and distributions of income and social origins up to the extremes of the distribution and was used to investigate net comparable health gradients in detail. Multilevel random-slope models were run to post-estimate best linear unbiased predictors (BLUPs) and related standard deviations of residual intercepts (median health) and slopes (income-health gradients) per country and survey year. Results. Health gradients varied across different measures of stratification, with origins and income producing significant slopes after controls. Income inequality was associated with worse average health, but income inequality and steepness of the health gradient were only marginally associated. Discussion. Linear health gradients suggest gains in health per rank of income and of origins even at the very extremes of the distribution. Intergenerational transmission of status gains in importance in countries with higher income inequality. Countries differ in the association of income inequality and income-related health gradient, and low income inequality may mask health problems of vulnerable individuals with low status. Not only income inequality, but other country characteristics such as familial orientation play a considerable role in explaining steepness of the health gradient...|$|R
40|$|Background: Novel {{models for}} the {{assessment}} of non-linear data are being developed for the benefit of making better predictions from the data. Objective: To review traditional and modern models. Results, and Conclusions: 1) <b>Logit</b> and probit <b>transformations</b> are often successfully used to mimic a linear model. Logistic regression, Cox regression, Poisson regression, and Markow modeling are examples of logit transformation; 2) Either the x- or y-axis or both of them can be logarithmically transformed. Also Box Cox transformation equations and ACE (alternating conditional expectations) or AVAS (additive and variance stabilization for regression) packages are simple empirical methods often successful for linearly remodeling of non-linear data; 3) Data that are sinusoidal, can, generally, be successfully modeled using polynomial regression or Fourier analysis; 4) For exponential patterns like plasma concentration time relationships exponential modeling with or without Laplace transformations is a possibility. Spline and Loess are computationally intensive modern methods, suitable for smoothing data patterns, if the data plot leaves you with no idea {{of the relationship between the}} y- and x-values. There are no statistical tests to assess the goodness of fit of these methods, but it is always better than that of traditional models...|$|R
40|$|Infant {{mortality}} {{at birth}} may help illuminate {{the usefulness of}} season of birth {{as an indicator of}} early life exposures. We obtained data for infant mortality rates (IMR) at the county (municipio) level during the late 1920 s-early 1940 s in Puerto Rico using historical records and linked IMR with individual birth year and place using the PREHCO (Puerto Rican Elderly: Health Conditions) study. We classified PREHCO respondents into two groups according to high or low infectious disease load, corresponding to lower or higher proportion endogenous mortality in the year respondents were born. We estimated the effects of IMR (using continuous, <b>logit,</b> quartile, Box-Cox <b>transformations)</b> and season of birth on adult heart disease and diabetes for all respondents and then by subgroups, controlling for age, gender, obesity, respondent’s educational level, adult behavior (smoking, exercise) and other early life exposures (childhood health, knee height, childhood SES). Findings: (1) no significant associations between IMR and heart disease or diabetes but significant associations between high IMR and low knee height, low education, older age and no rigorous exercise as an adult; (2) stronger effects of season of birth on adult health among respondents born in years with lower infectious disease loads; (3) stron...|$|R
