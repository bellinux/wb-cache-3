12|1|Public
50|$|When pen {{plotters}} became widespread, {{a special}} variety of point assemblies was produced. These had the basic {{characteristics of the}} standard pen nib, but the tube was much thicker to strengthen it against quick lateral movements. Only {{the tip of the}} tube had the desired, <b>line-size</b> width. They fell out of use as plotters were replaced with ink-jet printers.|$|E
50|$|The PowerPC 620 data cache was {{optimized}} for technical and scientific applications. Its capacity was doubled to 64 KB, {{to improve the}} cache-hit rate; the cache was dual-ported, implemented by interleaving eight banks, to enable two loads or two stores to be performed in one cycle in certain cases; and the <b>line-size</b> was increased to 128-bytes. The L2 cache bus was doubled in width to 256 bits {{to compensate for the}} larger cache line size and to retain a four-cycle latency for cache refills.|$|E
40|$|This paper {{proposes a}} novel cache {{architecture}} suitable for merged DRAM/logic LSIs, {{which is called}} “dynamically variable <b>line-size</b> cache (D-VLS cache) ”. The D-VLS cache can optimize its <b>line-size</b> according to the characteristic of programs, and at-tempts to improve the performance by exploiting the high on-chip memory bandwidth on merged DRAM/logic LSIs appropriately. In our evaluation, {{it is observed that}} an average memory-access time improvement achieved by a direct-mapped D-VLS cache is about 20 % compared to a conventional direct-mapped cache with fixed 32 -byte lines. This performance improvement is better than that of a doubled-size conventional direct-mapped cache†. key words: cache, variable <b>line-size,</b> merged DRAM/logic LSIs, high bandwidth 1...|$|E
40|$|Many {{features}} {{were added to}} the Thermal Control System (TCS) program to increase its user-friendliness. Several apparent inconsistencies were identified. In some instances, these have led to modifications to the source programs. With the summary <b>line-sizing</b> information, the user can more readily compare the TCS program results with other available data. Two mathematical models were completed: one deals with sizing and analysis of bus heat exchangers and the other provides a means of analyzing a variety of heat pipe radiator designs. A generic heat pipe model was added to the TCS Analysis Program...|$|R
40|$|This paper {{proposes a}} novel cache {{architecture}} suitable for merged DRAM/logic LSIs, {{which is called}} 2 ̆ 2 dynamically variable <b>line-size</b> cache(D-VLS cache). 2 ̆ 2 The D-VLS cache can optimize its <b>line-size</b> according to the characteristic of programs, and attempts to improve the performance by exploiting the high on-chip memory bandwidth on merged DRAM/logic LSIs appropriately. In our evaluation, {{it is observed that}} an average memory-access time improvement achieved by a direct-mapped D-VLS cache is about 20...|$|E
40|$|This paperpro oo oo o {{the latter}} appro[hes, which is referredto as "dynamically {{variable}} <b>line-size</b> cache (D-VLS cache) " architecture, and evaluates the co[" 8 erfo 4 z 6 [x impro vements attainable by the DVLS cache. The D-VLS cache changes its cache-line size at run timeacco 4 " 88 to the characteristicso applicatio proatio to execute. <b>Line-size</b> determinater selects adequate line-sizes basedo recentlyoy["T ed data reference behavio 4 Since this schemedo es no require any mo dificatio o instructio set architectures, the fullco[44 """[xz yo f existingo jectco des can be kept. The go[o D-VLS cache isto impro ve the syste...|$|E
40|$|This paper proposes an on-chip memory-path {{architecture}} {{employing the}} dynamically variable <b>line-size</b> (D-VLS) cache for high performance and low energy consumption. The D-VLS cache exploits the high on-chip memory bandwidth attainable on merged DRAM/logic LSIs by replacing a whole large cache line in one cycle. At the same time, {{it attempts to}} avoid frequent evictions by decreasing the cache-line size when programs have poor spatial locality. Activating only on-chip DRAM subarrays corresponding to a replaced cache-line size produces a significant energy reduction. In our simulation, {{it is observed that}} our pro-posed on-chip memory-path architecture, which employs a direct-mapped D-VLS cache, improves the ED (Energy Delay) product by more than 75 % over a conventional memory-path model. key words: cache, low power, variable <b>line-size,</b> merged DRAM/logic LSIs, high bandwidth 1...|$|E
40|$|Abstract—The memory {{bandwidth}} can dramatically {{be improved}} by means of stacking the main memory (DRAM) on processor cores and connecting them by wide on-chip buses composed of through silicon vias (TSVs). The 3 D stacking {{makes it possible to}} reduce the cache miss penalty because large amount of data can be transferred from the main memory to the cache at a time. If a large cache line size is employed, we can expect the effect of prefetching. However, it might worsen the system performance if programs do not have enough spatial localities of memory references. To solve this problem, we introduce software-controllable variable <b>line-size</b> cache scheme. In this paper, we apply it to an L 1 data cache with 3 D stacked DRAM organization. In our evaluation, it is observed that our approach reduces the L 1 data cache and stacked DRAM energy consumption up to 75 %, compared to a conventional cache. Keywords-component; low power, variable <b>line-size,</b> 3 D stacked DRAM I...|$|E
40|$|This paper {{proposes a}} novel cache {{architecture}} suitable for merged DRAM/logic LSIs, called "dynamically variable <b>line-size</b> cache (D-VLS cache) ", and evaluates the cost/performance improvements attainable by the D-VLS cache. The D-VLS cache can make {{good use of}} the high on-chip memory bandwidth by means of larger cache lines and. At the same time, it can alleviate the negative effects of larger cache-line size by partitioning the large cache line into multiple small cache lines, and by adjusting the number of sublines to be involved in cache replacements. The <b>line-size</b> determinator for the D-VLS cache selects adequate line-sizes based on recently observed data reference behavior, and it can be implemented with a little addition of hardware cost. In our evaluation, it is observed that the performance improvement achieved by a direct-mapped D-VLS cache is more than 22 % while it increases the hardware cost by only 17 %, compared to a conventional direct-mapped cache with fixed 32 -byte lines...|$|E
40|$|This paper {{proposes a}} novel cache {{architecture}} suitable for merged DRAM/logic LSIs, {{which is called}} "dynamically variable <b>line-size</b> cache (D-VLS cache) ". The D-VLS cache can optimize its <b>line-size</b> according to the characteristic of programs, and attempts to improve the performance by exploiting the high on-chip memory bandwidth. In our evaluation, {{it is observed that}} the performance improvement achieved by a directmapped D-VLS cache is about 27 %, compared to a conventional direct-mapped cache with fixed 32 -byte lines. 1 Introduction For merged DRAM/logic LSIs with a memory hierarchy including cache memory, we can exploit high on-chip memory bandwidth by means of replacing a whole cache line at a time on cache misses [5][10][11]. This approach tends to increase the cache-line size if we attempt to improve the attainable memory bandwidth. In general, large cache lines can benefit some application as the effect of prefetching. Larger cache lines, however, might worsen the system performa [...] ...|$|E
40|$|Abstract—This paper {{proposes a}} software-controllable {{variable}} <b>line-size</b> (SC-VLS) cache architecture for low power embedded systems. High bandwidth between logic and a DRAM is realized {{by means of}} advanced integrated technology. In the merged logic/DRAM SoCs, {{it is important to}} reduce the DRAM energy consumption. The specific DRAM needs a small cache memory to improve the performance. We exploit the cache to reduce the DRAM energy consumption. The SC-VLS cache is able to change a line size to an adequate one at runtime with a small area and power overheads. We analyze the adequate line size and insert line size change instructions {{at the beginning of each}} function of a target program before executing the program. In our evaluation, it is observed that the SC-VLS cache reduces the DRAM energy consumption up to 50 %, compared to a conventional cache with fixed 256 B lines. I...|$|E
40|$|Caches are {{organized}} at a <b>line-size</b> granularity to exploit spatial locality. However, when spatial locality is low, many {{words in the}} cache line are not used. Unused words occupy cache space but do not contribute to cache hits. Filtering these words can allow the cache to store more cache lines. We show that unused words in a cache line {{are unlikely to be}} accessed in the less recent part of the LRU stack. We propose Line Distillation (LDIS), a technique that retains only the used words and evicts the unused words in a cache line. We also propose Distill Cache, a cache organization to utilize the capacity created by LDIS. Our experiments with 16 memory-intensive benchmarks show that LDIS reduces the average misses for a 1 MB 8 -way L 2 cache by 30 % and improves the average IPC by 12 %. 1...|$|E
40|$|This paper {{describes}} a novel cache architecture suitable for merged DRAM/logic LSIs, called variable <b>line-size</b> cache or VLS cache, for resolving the above-mentioned dilemma. The VLS cache can make {{good use of}} the high on-chip memory bandwidth by means of larger cache lines and, at the same time, alleviate the negative effects of larger cache-line size by partitioning each large cache line into multiple sub-lines and allowing every sub-line to work as an independent cache line. The number of sub-lines involved when a cache replacement occurs can be determined depending on the characteristics of programs. This paper also evaluates the cost/performance improvements attainable by the VLS cache and compares it with those of conventional cache architectures. As a result, it is observed that a VLS cache reduces the average memory-access time by 16 : 4 % while it increases the hardware cost by only 13 %, compared to a conventional direct-mapped cache with fixed 32 -byte lines...|$|E

