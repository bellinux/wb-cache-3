32|157|Public
50|$|To achieve {{responsiveness}} {{the game}} is partitioned across a number of datacenters, geographically distributed across the globe, offering high-bandwidth, <b>low-latency</b> <b>network</b> access for the players.|$|E
5000|$|Version 3.11, {{released}} on 2 September 2013, adds many new {{features such as}} new [...] flag for [...] to reduce temporary file vulnerabilities, experimental AMD Radeon dynamic power management, <b>low-latency</b> <b>network</b> polling, and zswap (compressed swap cache).|$|E
50|$|A zone is an {{isolated}} location within a region. Zones have high-bandwidth, <b>low-latency</b> <b>network</b> connections to other zones {{in the same}} region. In order to deploy fault-tolerant applications that have high availability, Google recommends deploying applications across multiple zones in a region. This helps protect against unexpected failures of components, {{up to and including}} a single zone. As of August 5, 2014, there are eight zones - three each in central US region and Asia East region and two zones in Western Europe region.|$|E
5000|$|... {{the use of}} InfiniBand, Fibrechannel {{or similar}} <b>low-latency</b> <b>networks</b> to avoid {{performance}} degradation with increasing cluster size and number of redundant copies.|$|R
50|$|Gradually, old-school, high latency {{architecture}} of algorithmic systems is {{being replaced by}} newer, state-of-the-art, high infrastructure, <b>low-latency</b> <b>networks.</b> The complex event processing engine (CEP), which {{is the heart of}} decision making in algo-based trading systems, is used for order routing and risk management.|$|R
40|$|With the {{increase}} of digital audio dissemination, generated by the popularization of personal computers and worldwide <b>low-latency</b> <b>networks,</b> many entertaining applications can easily be imagined to rhythmic analyses of audio. We herein report on a method of automatic extraction of a rhythmic attribute from percussive music audio signals: the smallest rhythmic pulse, called the “tick”. Evaluations of the proposed scheme yielded quite good results. We then discuss the relevance of use of the tick as the basic feature of rhythmic analyses...|$|R
5000|$|Avaya Virtual Services Platform 7000 Series or VSP 7000 {{is a set}} standalone/stackable switches, used in {{enterprise}} data networks, {{and data}} centers, manufactured by Avaya. This product is primarily offered to satisfy the Top-of-Rack (ToR) role for server farms and virtualized data centers. It supports Avaya's extended Shortest Path Bridging (SPB) implementation [...] "Fabric Connect", and is future-ready for Edge Virtual Bridging (EVB) - IEEE 802.1Qbg, and Fiber Channel over Ethernet (FCoE). The system incorporates fifth generation application-specific integrated circuit (ASIC) chips with redundant and hot-swappable power supplies, fans, and expansion modules. The VSP 7000's unique architecture allows it to be meshed - fully or partially - with like devices, creating a high-capacity, <b>low-latency</b> <b>network</b> of up to 500 units, supporting up to 16,000 ports of 10GbE supported by a virtual backplane of up to 280Tbit/s ...|$|E
40|$|Designing a wide-area {{distributed}} {{hash table}} (DHT) that provides high-throughput and <b>low-latency</b> <b>network</b> storage is a challenge. Existing systems have explored {{a range of}} solutions, including iterative routing, recursive routing, proximity routing and neighbor selection, erasure coding, replication, and server selection. Thi...|$|E
40|$|This {{paper is}} {{about the role of}} the {{operating}} system (OS) within computer nodes of network audio systems. While many efforts in the network-audio community focus on <b>low-latency</b> <b>network</b> protocols, here we highlight the importance of the OS for network audio applications. We present Tessellation, an experimental OS tailored to multicore processors. We show how specific OS features, such as guaranteed resource allocation and customizable user-level runtimes, can help ensure quality-of-service (QoS) guarantees for data transmission and audio signal processing, especially in scenarios where network bandwidth and processing resources are shared between applications. To demonstrate performance isolation and service guarantees, we benchmark Tessellation under different conditions using a resource-demanding network audio application. Our results show that Tessellation can be used to create <b>low-latency</b> <b>network</b> audio systems. ...|$|E
40|$|Abstract—This paper {{describes}} CADET, a new {{transport protocol}} for confidential and authenticated data transfer in decentralized networks. This transport protocol {{is designed to}} operate in restricted-route scenarios such as friend-to-friend or ad-hoc wireless networks. We have implemented CADET and evaluated its performance in various network scenarios, compared it to the well-known TCP/IP stack and tested its response to rapidly changing network topologies. While our current implementation is still significantly slower in high-speed <b>low-latency</b> <b>networks,</b> for typical Internet-usage our system provides much better connectivity and security with comparable performance to TCP/IP. I...|$|R
40|$|The {{construction}} of large-scale, <b>low-latency</b> <b>networks</b> becomes difficult {{as the number}} of nodes increases. In general, the way to construct a theoretically optimal solution is unknown. However, it is known that some methods can construct suboptimal <b>networks</b> with <b>low-latency.</b> One such method is to construct large-scale networks from optimal or suboptimal small networks, using the product of graphs. There are two major advantages to this method. One is that we can reuse small, already known networks to construct large-scale networks. The other is that the networks obtained by this method have graph-theoretical symmetry, which reduces the overhead of communication between nodes. A network {{can be viewed as a}} graph, which is a mathematical term from combinatorics. The design of <b>low-latency</b> <b>networks</b> can be treated as a mathematical problem of finding small diameter graphs with a given number of nodes (called order) and a given number of connections between each node (called degree). In this paper, we overview how to construct large graphs from optimal or suboptimal small graphs by using graph-theoretical products. We focus on the case of diameter 2 in particular. As an example, we introduce a graph of order 256, degree 22 and diameter 2, which granted us the Deepest Improvement Award at the Graph Golf competition. Moreover, the average shortest path length of the graph is the smallest in graphs of order 256 and degree 22...|$|R
40|$|The paper {{deals with}} a {{methodology}} of switching latency measurement in switched Ethernet networks. The switching latency is parameter necessary for simulation and design of <b>low-latency</b> <b>networks</b> that are often intended for realtime control inherent to many industrial applications. The proposed measurement methodology provides a simple way of switching the latency determination and vendor quoted latency values verification directly at the physical layer. Numerous experimental measurements were carried out to support the arguments in this paper and to demonstrate the usability of the proposed methodology. All results are presented and analysed up to 10 GBase-R Ethernet including OpenFlow switches. Web of Science 213787...|$|R
30|$|<b>Low-latency</b> <b>network</b> {{architectures}} {{are concerned}} with shortening the distances and number of hops between the user and the content, for example, by distributing some network functions that are centralized today or by applying local and universal caching {{as well as local}} breakouts to external networks like Internet, service provider, or enterprise networks.|$|E
40|$|Current {{electronic}} voting systems require an anonymous channel during the voting phase to prevent coercion. Typically, low-latency anonymization-networks like Tor {{are used for}} this purpose. In this paper we devise a monitoring attack that allows an attacker to monitor whether participants of an election voted, despite {{the use of a}} <b>low-latency</b> <b>network</b> during the voting phase, thereby breaking an important part of coercion-freeness. We implement a simulation carrying out our attack and measure its success rates...|$|E
40|$|The Message-Driven Processor is a node of a {{large-scale}} multiprocessor {{being developed by}} the Concurrent VLSI Architecture Group. It is intended to support fine-grained, message passing, parallel computation. It contains several novel architectural features, such as a <b>low-latency</b> <b>network</b> interface, extensive type-checking hardware, and on-chip memory {{that can be used}} as an associative lookup table. This document is a programmer's guide to the MDP. It describes the processor's register architecture, instruction set, and the data types supported by the processor. It also details the MDP's message sending and exception handling facilities...|$|E
40|$|Symmetric multiprocessors (SMPs) {{connected}} with <b>low-latency</b> <b>networks</b> provide attractive {{building blocks for}} software distributed shared memory systems. Two distinct approaches have been used: the fine-grain approach that instruments application loads and stores to support a small coherence granularity, and the coarse-grain approach based on virtual memory hardware that provides coherence at a page granularity. Fine-grain systems offer a simple migration path for applications developed on hardware multiprocessors by supporting coherence protocols similar to those implemented in hardware. On the other hand, coarse-grain systems can potentially provide higher performance through more optimized protocols and larger transfer granularities, while avoiding instrumentation overheads. Numerous studies have examined each approach individually, but major difference...|$|R
5000|$|The two managed Common Language Infrastructure [...]NET {{implementations}} are Pure Mpi.NET and MPI.NET, {{a research}} effort at Indiana University licensed under a BSD-style license. It {{is compatible with}} Mono, and can make full use of underlying <b>low-latency</b> MPI <b>network</b> fabrics.|$|R
50|$|Nodes running OneFS must be {{connected}} {{together with a}} high performance, <b>low-latency</b> back-end <b>network</b> for optimal performance. OneFS 1.0-3.0 used Gigabit Ethernet as that back-end network. Starting with OneFS 3.5, Isilon offered Infiniband models. Now all nodes sold utilize an Infiniband back-end.|$|R
40|$|Abstract- Emerging {{parallel}} applications {{require a}} significant improvement in communication latency. Since the time required for transferring data between host memory and network interface (NI) takes up {{a large portion of}} overall communication latency, the reduction of data transfer time is crucial for achieving low-latency communication. In this paper, a new data transfer mechanism- called hereafter the DT, is proposed to reduce communication latency for latency demanding applications. The DT employs a cache coherence interface hardware to utilize an eager method for transferring data between the host and NI. Our simulation results show that the DT significantly reduces message latency up to 36 % compared to a Direct Memory Access (DMA) based approach. Key Words: Data transfer, eager method, userlevel, cache coherence, <b>low-latency,</b> <b>network</b> protocols, message. 1...|$|E
40|$|Fine-grained {{dataflow}} {{processing of}} sparse Matrix-Solve computation (A~x = ~b) in the SPICE circuit simulator {{can provide an}} order of magnitude performance improvement on modern FPGAs. Matrix Solve is the dominant component of the simulator especially for large circuits and is invoked repeatedly during the simulation, once for every iteration. We process sparse-matrix computation generated from the SPICE-oriented KLU solver in dataflow fashion across multiple spatial floating-point operators coupled to high-bandwidth on-chip memories and interconnected by a <b>low-latency</b> <b>network.</b> Using this approach, we are able to show speedups of 1. 2 - 64 × (ge-ometric mean of 8. 8 ×) for a range of circuits and benchmark matrices when comparing double-precision implementations on a 250 MHz Xilinx Virtex- 5 FPGA (65 nm) and an Intel Core i 7 965 processor (45 nm). I...|$|E
40|$|Emerging high-bandwidth, <b>low-latency</b> <b>network</b> {{technology}} has made network-based architectures both feasible and potentially desirable {{for use in}} satellite payload architectures. The selection of network topology is a critical component when developing these multi-node or multi-point architectures. This study examines network topologies and their effect on overall network performance. Numerous topologies were reviewed against a number of performance, reliability, and cost metrics. This document identifies a handful of good network topologies for satellite applications and the metrics used to justify them as such. Since often multiple topologies will {{meet the requirements of}} the satellite payload architecture under development, the choice of network topology is not easy, and in the end the choice of topology is influenced by both the design characteristics and requirements of the overall system and the experience of the developer...|$|E
50|$|In the future, {{competition}} {{will be from}} {{the evolution of the}} major cellular standards to 4G, high-bandwidth, <b>low-latency,</b> all-IP <b>networks</b> with voice services built on top. The worldwide move to 4G for GSM/UMTS and AMPS/TIA (including CDMA2000) is the 3GPP Long Term Evolution (LTE) effort.|$|R
40|$|In {{order to}} connect and access {{instruments}} located at various {{places on earth}} one needs a special grid infrastructure connected via high-speed, <b>low-latency</b> <b>networks.</b> The requirements of the network are dictated by the instruments themselves which are deployed within the grid. There are several possibilities how to achieve the desired properties of a network: Using special hardware, using the right protocols in the network protocol stack, and selecting appropriate middleware. All of these options {{will be discussed in}} this deliverable. There also exist several projects and testbeds related to the idea of remote instrumentation. This deliverable will {{have a look at the}} most important ones, in order to gain information which would otherwise not be possible to retrieve during RINGrid 2 ̆ 7 s short project lifetime...|$|R
40|$|Abstract. There {{are many}} {{unexpected}} or unexpectedly difficult obstacles to deploying anonymous communications. Drawing on our experiences deploying Tor (the second-generation onion routing network), we describe social challenges and technical issues {{that must be}} faced in building, deploying, and sustaining a scalable, distributed, <b>low-latency</b> anonymity <b>network.</b> ...|$|R
40|$|For {{real-time}} system-on-a-chip (SoC) network applications, high-speed and lowlatency network I/O {{is the key}} {{to achieve}} predictable execution and high performance. Existing network I/O approaches are either not directly suited to SoC applications, or too complicated and expensive. This paper introduces a novel approach, referred to as shared address space I/O, for real-time SoC network applications. This approach facilitates build ing of heterogeneous multiprocessor systems with application intensiv e processors (main processor) and I/O intensive processors (I/O processor), where network I/O processing can be offloaded to a specialized I/O processor. With the shared address space I/O approach, in such a system, communication and synchronization between main and I/O processors can be implementedwitha shared address space. This approach is realized through Atalanta, a heterogeneous real-time SoC operating system we have developed. In this paper, we demonstrate that shared address space I/O can provide high-speed and <b>low-latency</b> <b>network</b> I/O for SoC network applications. ...|$|E
40|$|This paper {{explores the}} {{advantages}} of high performance asynchronous circuits in a semi-custom standard cell environment for high-throughput turbo coding. Turbo codes are high-performance error correction codes used in applications where maximal information transfer is needed over a limitedbandwidth communication link {{in the presence of}} data corrupting noise. Specifically we designed an asynchronous high-speed Turbo decoder that can be potentially used for new wireless communications protocols with close to OC- 12 throughputs. The design has been implemented using a new static single-track-full-buffer (SSTFB) standard cell library in IBM 0. 18 µm technology that provides low latency, fast cycle-time, and more robustness to noise than previously studied single-track full-buffer technology (STFB). A high-speed synchronous counterpart using the same high-speed architecture is designed in the same technology for comparison. The results demonstrate that for a variety of network constraints, the asynchronous design provides advantages in throughput per area. Moreover, the asynchronous design can support very <b>low-latency</b> <b>network</b> constraints not achievable with the synchronous alternative. 1...|$|E
40|$|We {{have been}} {{investigating}} an end system architecture to support networking with {{quality of service}} guarantees. For user level protocol code in our architecture to access the network, we have designed a kernel�user interface. The interface targets three areas for improvement: reduced copying, reduced reliance on explicit kernel�user interactions, and provision of rate-based flow control. In this paper, we present the concept of input�output efficient buffers for reduced copying, the concept of fast system calls for <b>low-latency</b> <b>network</b> access, {{and the concept of}} kernel threads for flow control. Also included is a concept called direct media streaming which is suitable for applications that require limited user processing of media data. These concepts have been implemented as an extension to SunOS 5. 3 Ž the operating system component of Solaris 2. 3 [...] We report some experimental results on the performance of our current system. � 1998 John Wiley & Sons, Inc. 1...|$|E
40|$|Interprocessor {{connection}} networks {{with very}} good topological properties are often impossible to build {{because of their}} prohibitively high wire complexity. Such a network is the generalized hypercube (GH) that supports full-connectivity of all its nodes in each dimension. We present here the class of HOW interprocessor connections which are capable of lower complexity than GHs, comparable performance, and better scalability. We analyze the hardware cost of HOWs, present communications algorithms for 2 -D HOWs, and carry out performance comparisons with binary hypercubes and GHs. Keywords: Parallel computer, interconnection network, cost analysis, communications operations. 1 Introduction Developing low-complexity, high-bisection bandwidth, and <b>low-latency</b> <b>networks</b> to interconnect processors (PEs) in MPP systems is a Herculean task. Several message passing interconnection networks have been proposed for parallel computers [1]. To support scalability, current approaches most often use b [...] ...|$|R
40|$|Clusters of multiprocessors, or Clumps, {{promise to}} be the {{supercomputers}} of the future, but obtaining high performance on these architectures requires an understanding of interactions between the multiple levels of interconnection. In this paper, we present the first multi-protocol implementation of a lightweight message layer [...] -a version of Active Messages-II running on a cluster of Sun Enterprise 5000 servers connected with Myrinet. This research brings together several pieces of high-performance interconnection technology: bus backplanes for symmetric multiprocessors, <b>low-latency</b> <b>networks</b> for connections between machines, and simple, user-level primitives for communication. The paper describes the shared memory message-passing protocol and analyzes the multi-protocol implementation with both microbenchmarks and Split-C applications. Three aspects of the communication layer are critical to performance: the overhead of cache-coherence mechanisms, the method of managing concurrent acce [...] ...|$|R
25|$|Like all current <b>low-latency</b> {{anonymity}} <b>networks,</b> Tor cannot {{and does}} not attempt to protect against monitoring of traffic at {{the boundaries of the}} Tor network (i.e., the traffic entering and exiting the network). While Tor does provide protection against traffic analysis, it cannot prevent traffic confirmation (also called end-to-end correlation).|$|R
40|$|Abstract—The {{security}} of computer systems and networks is severely threatened {{today by the}} combination of novel attack patterns and high traffic volumes. Together, this often exceeds the capabilities of purely software-based network security systems. As an alternative, hardware acceleration has been employed, e. g., for performing deep-packet inspection and pattern matching as well as general packet-header process-ing. While such implementations, capable of handling lower protocol layers, have been extensively studied in research and industry, their extension to higher communication layers has only rarely been addressed. Such capabilities, including the application level (OSI Layer 7), {{are the focus of}} this work. We present the NetStage platform, employing recon-figurable computing for high-throughput <b>low-latency</b> <b>network</b> processing, as well as associated development tools that allow networking domain experts to easily customize the system. As a use-case, we consider the realization of high-performance attack-resilient honeypots based on NetStage. To this end, we introduce the Malacoda language, its programming tools, and the generated target microarchitecture. We then evaluate the performance of Malacoda-generated vulnerability emulation handlers running on the NetStage platform...|$|E
40|$|Abstract. Keeping system time closely {{synchronized}} {{among all}} nodes of a cluster {{is a hard}} problem. The Network Time Protocol reliably syn-chronizes only to an accuracy of a few milliseconds. This is too coarse to compare time stamps of fast events on modern clusters, for example, the send and receive times of a message over a <b>low-latency</b> <b>network.</b> The Precision Time Protocol (PTP), defined in IEEE 1588, specifies a protocol which can substantially enhance the time accuracy across nodes in a local area network. An open source implementation of PTP (PTPd) relies on software time stamping, which is susceptible to jitter introduced by the non-realtime OS. An upcoming Ethernet NIC from Intel solves this problem by providing time stamping in hardware. This paper describes our modifications which allow PTPd {{to make use of}} this hardware feature, and evaluates several approaches for synchronizing the system time against the PTP time. Without hardware assistance, PTPd achieved accuracy as good as one microsecond; with hardware assistance, accuracy was reliably improved and dependence on real-time packet time stamping in software was virtually eliminated...|$|E
40|$|Within {{a digital}} map service environment, {{the rapid growth}} of Spatial Big-Data is driving new {{requirements}} for effective mechanisms for massive online vector map tile processing. The emergence of Not Only SQL (NoSQL) databases has resulted in a new data storage and management model for scalable spatial data deployments and fast tracking. They better suit the scenario of high-volume, <b>low-latency</b> <b>network</b> map services than traditional standalone high-performance computer (HPC) or relational databases. In this paper, we propose a flexible storage framework that provides feasible methods for tiled map data parallel clipping and retrieval operations within a distributed NoSQL database environment. We illustrate the parallel vector tile generation and querying algorithms with the MapReduce programming model. Three different processing approaches, including local caching, distributed file storage, and the NoSQL-based method, are compared by analyzing the concurrent load and calculation time. An online geological vector tile map service prototype was developed to embed our processing framework in the China Geological Survey Information Grid. Experimental results show that our NoSQL-based parallel tile management framework can support applications that process huge volumes of vector tile data and improve performance of the tiled map service...|$|E
40|$|Abstract. The {{design of}} {{anonymous}} communication systems is a rel-atively new field, but {{the desire to}} quantify the security these systems offer {{has been an important}} topic of research since its beginning. In recent years, anonymous communication systems have evolved from obscure tools used by specialists to mass-market software used by millions of peo-ple. In many cases the users of these tools are depending on the anonymity offered to protect their liberty, or more. As such, it is of critical impor-tance that not only can we quantify the anonymity these tools offer, but that the metrics used represent realistic expectations, can be communi-cated clearly, and the implementations actually offer the anonymity they promise. This paper will discuss how metrics, and the techniques used to measure them, have been developed for anonymous communication tools including <b>low-latency</b> <b>networks</b> and high-latency email systems. ...|$|R
40|$|Today, {{computational}} Clusters of Networked Workstations (usually off-the-shelf PCs interconnected by high-speed, <b>low-latency</b> communication <b>networks)</b> {{are playing}} {{a major role in}} redefining the concept of supercomputing. Sadly, the fierce competition and the lack of common industry standards have lead to wide spread of clusters interconnected with incompatible high-performance System Area Networks (Gigabit Ethernet, GigaNet, Myrinet, SCI, QNet, etc.) ...|$|R
40|$|Transport Control Protocol (TCP) in cast {{congestion}} {{happens in}} high-bandwidth and <b>low-latency</b> <b>networks</b> when multiple synchronized servers send {{data to the}} same receiver in parallel. For many important data-center applications such as MapReduce and Search, this many-to-one traffic pattern is common. Hence TCP in cast congestion may severely degrade their performances, e. g., by increasing response time. In this paper, we study TCP incast in detail {{by focusing on the}} relationships between TCP throughput, round-trip time (RTT), and receive window. Unlike previous approaches, which mitigate the impact of TCP incast congestion by using a fine-grained timeout value, our idea is to design an Incast congestion Control for TCP (ICTCP) scheme on the receiver side. In particular, our method adjusts the TCP receive window proactively before packet loss occurs. The implementation and experiments in our test bed demonstrate that we achieve almost zero timeouts and high goodput for TCP incast...|$|R
