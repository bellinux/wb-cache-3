0|80|Public
3000|$|..., {{as shown}} in Figure 1 c,d. In other words, by {{adopting}} a buffer layer, a fragile layer such as ITO can be located at the NA position and the bending stress acting on the fragile layer can be greatly reduced, thus <b>leading</b> to <b>flexible</b> nanoelectronics with high bendability.|$|R
50|$|Because of the building-block {{nature of}} the system, the {{configuration}} of the overall screen area and shape is <b>flexible,</b> <b>leading</b> to simple traditional rectangular displays, and more complex non-standard shapes.|$|R
50|$|SimBioSys (short for Simulated Biomolecular Systems) is a Toronto-based {{chemistry}} {{software company}} focusing on structure based drug discovery and retrosynthetic analysis tools. It {{has established a}} strong {{reputation as one of}} the <b>leading</b> developers of <b>flexible</b> docking applications, virtual screening methods and computer aided organic synthesis design.|$|R
40|$|The wing on the NASA F- 111 {{transonic}} aircraft technology (TACT) airplane was modified to provide <b>flexible</b> <b>leading</b> and trailing edge flaps; this modified wing {{is known as}} the mission adaptive wing (MAW). A dual digital primary fly-by-wire flight control system was developed with analog backup reversion for redundancy. This report discusses the functions, design, and redundancy management of the flight control system for these flaps...|$|R
40|$|This work {{presents}} an on-chip interconnection bus-based architecture developed to perform within reprogramrouble systems dedicated for network protocol processing. The architecture involves a centralized arbiter with simple control to achieve minimal latency. The interface {{of the components}} includes a minimal set of signals and data and control transfer operations use the same path. The control organization allows each component {{to play the role}} of master and slave, a fact <b>leading</b> to <b>flexible</b> reprogrammable system on chip designs that can be utilized in more than one protocol applications. Further, the architecture includes a test block that will allow the validation of the system by monitoring the sequence of control words used to accomplish each task...|$|R
30|$|Individual (constituent) systems {{dynamically}} {{connect to}} each other in order to collectively provide value-adding superordinate functionality. Instead of hierarchical systems, this leads to heterarchical systems of systems. There is no hierarchy, but all systems have equivalent rights and have their own mission and objectives. Nonetheless, they need to collaborate as a collective. The structure and behavior of an open system of systems dynamically emerge at runtime, <b>leading</b> to very <b>flexible</b> and adaptive solutions.|$|R
40|$|A {{formalism}} and {{a corresponding}} notation for earned value analysis are presented. With compact, consistent, mnemonic notation, earned value calculations become more transparent and <b>flexible,</b> <b>leading</b> to insights about standard quantities and advances through new measures. As {{an example of}} the notation’s utility, it is used to generate a modified earned value approach that weights quantities according to their position in a project’s timeline. earned value, managing projects, progress, cost, cash flow management...|$|R
40|$|For {{a proper}} {{selection}} of a packaging material for a given application, several criteria {{are taken into account}} which often lead to conflicting requirements. The paper shows that the specific packaging functionality plays the predominant role in the selection process. Environmental aspects may - as an estimation - be tackled by the total energy value of the whole packaging system. Technical developments with highest potential {{are to be found in}} polymer films, combined with coating processes, <b>leading</b> to lightweight <b>flexible</b> packagings...|$|R
40|$|In this paper, {{we propose}} an {{original}} {{system for a}} subjective utility function estimation suitable for real-time video applications. In video networking applications, utility function {{is defined as a}} video quality metrics representing a user satisfaction index as a function of bandwidth. The real-time performance is achieved in our system by (1) using novel content classification techniques based on visual features directly extracted from compressed video streams and (2) employing machine learning techniques for classification of utility functions. Our extensive experiments, based on MPEG- 4 encoded video streams, indicate that high accuracy of 80 %- 85 % in estimating utility functions can be achieved. These results demonstrate that the proposed system represents a promising approach to real-time utility function estimation. The real-time performance is instrumental in achieving higher network resource utilization <b>leading</b> to <b>flexible</b> and less expensive interactive multimedia ser [...] ...|$|R
40|$|Early spring 2010 we {{conducted}} a web survey and an interactive workshop among the current user community of the large scale topographic reference database (GRB) in Flanders, Belgium. The aim was {{to find out more}} about the needs and expectations of this community for 3 D-data and 3 D-capabilities. Several subgroups were addressed including administrators at regional, provincial and municipal level, cable and pipeline managers, contractors and road designers, surveyors and urban planners, representatives of the software industry and of education and research. The results reveal that 3 D-visualisation is high on the list of all subgroups while more specific requirements are subgroup-specific. It is acknowledged that in order to address this variety of expectations, 3 D-data model, data acquisition and database implementation must be developed in an iterative and progressive approach <b>leading</b> to <b>flexible</b> and extensible solutions. 1...|$|R
40|$|We {{present a}} novel {{architecture}} and execution model for an infrastructure supporting fault-tolerant, long-running distributed applications spanning multiple administrative domains. Components for both transaction processing and persistent state are replicated across multiple servers, en-suring that applications continue to function correctly de-spite arbitrary (Byzantine) {{failure of a}} bounded number of servers. We give a formal model of application execution, based on atomic execution steps, linearizability and a sep-aration between data objects and transactions that act on them. The architecture is designed for robust interoperability across domains, in an open and shared Internet computing infrastructure. A notable feature supporting cross-domain applications is that they may declare invariant constraints between data objects and furthermore declare dependencies on constraints maintained by other applications, <b>leading</b> to <b>flexible,</b> incidental atomicity between applications. The ar-chitecture is highly evolvable, maintaining system availabil-ity and integrity during upgrades to both application com-ponents and the system software itself. 1...|$|R
40|$|As a {{paradigm}} for coordinating cooperative agents in dynamic environments, teamwork {{has been shown}} to be capable of <b>leading</b> to <b>flexible</b> and robust behavior. How- ever, when we apply teamwork to the problem of building teams with hundreds of members, fundamental limitations become apparent. We have developed a model of teamwork that addresses the limitations of existing models as they apply to very large teams. A central idea of the model is to organize team members into dynamically evolving subteams. Additionally, we present a novel approach to sharing information, leveraging the proper- ties of small worlds networks. The algorithm provides targeted, efficient information delivery. We have developed domain independent software proxies with which we demonstrate teams at least an order of magnitude bigger than previously published. Moreover, the same proxies proved effective for teamwork in two distinct domains, illustrating the generality of the approach...|$|R
40|$|The {{need for}} {{participation}} in an emerging Information Society has led to several research efforts for designing accessibility solutions for disabled people. In this paper we present a method for developing Human-Computer Interfaces (HCIs) for quadriplegic people in modern programming environments. The presented method accommodates the design of scanning interfaces with modern programming tools, <b>leading</b> to <b>flexible</b> interfaces with improved appearance and {{it is based on}} the use of specially designed software objects called ""wifsids"" (Widgets For Single-switch Input Devices). The wifsid structure is demonstrated and 4 types of wifsids are analyzed. Developed software applications are to be operated by single-switch activations that are captured through the wifsids, with the employment of several modes of the scanning technique. We also demonstrate the ""Autonomia"" software application, that has been developed according to the specific methodology. The basic snapshots of this application are analyzed, in order to demonstrate how the wifsids cooperate with the scanning process in a user-friendly environment that enables a quadriplegic person to access an ordinary computer system...|$|R
40|$|We {{introduce}} a novel concurrent logic programming language, {{which we call}} LO, based on an extension of Horn logic. This language enhances the process view of objects implementable in Horn-based concurrent logic programming languages with powerful capabilities for knowledge structuring, <b>leading</b> to a <b>flexible</b> form of variable-structure inheritance. The main novelty about LO is {{a new kind of}} OR-concurrency which is dual to the usual AND-concurrency and provides us with the notion of structured process. Such OR-concurrency can be nicely characterized with a sociological metaphor as modelling the internal distribution of tasks inside a complex organization; this complements the external cooperation among different entities accounted for by AND-concurrency...|$|R
30|$|Young workers (aged between 18 and 24 years) {{have more}} rigid {{earnings}} than older workers. The result {{may be explained}} by the shirking model and the adverse selection model of Weiss (1980) applied to job quits. It predicts that younger workers are more likely to quit when their earnings increases are below their reference point because the cost of job loss is smaller for them than for older workers, i.e. finding a job is more difficult for older workers and, in addition, they might lose their tenure-related component of compensation. Furthermore, automatic tenure and age-related wage increases are more prominent for younger workers, while extra wage components are smaller, <b>leading</b> to less <b>flexible</b> earnings.|$|R
40|$|Functional data {{analysis}} commonly {{relies on the}} incorporation of basis functions having subject-specific coefficients, with the choice of basis and random effects distribution important. To allow the random effects distribution to be unknown, while inducing subject-specific basis selection and local borrowing of information across subjects, this article proposes a kernel local partition process (KLPP) prior. The KLPP selects the elements in a subject’s random effects vector locally from a collection of unique coefficient vectors, <b>leading</b> to a <b>flexible</b> local generalization of the Dirichlet process and to a sparse representation of complex functional data. Basic theoretical properties are considered, an MCMC algorithm is developed for posterior computation and the methods are applied to hormone data...|$|R
40|$|Fidaxomicin, {{also known}} as tiacumicin B or lipiarmycin A 3, is a novel macrocyclic {{antibiotic}} that is used in hospitals {{for the treatment of}} Clostridium difficile infections. This natural product has also been shown to have excellent bactericidal activity against multidrug-resistant Mycobacterium tuberculosis. In spite of its attractive biological activity, no total synthesis has been reported to date. The enantioselective synthesis of the central 18 -membered macrolactone is reported herein. The key reactions include ring-closing metathesis between a terminal olefin and a dienoate moiety for macrocyclization, a vinylogous Mukaiyama aldol reaction, and a Stille coupling reaction of sterically demanding substrates. The retrosynthesis involves three medium-sized fragments, thus <b>leading</b> to a <b>flexible</b> yet convergent synthetic route...|$|R
40|$|In 1998 and 1999 France {{passed the}} sixth and seventh laws in {{seventeen}} years affecting working time. They offered financial incentives to firms signing collective agreements that created or protected jobs and cut the legal working week from 39 to 35 hours from 1 January 2000. Early evidence suggests that while their direct job creation effect is limited they are moderating wage settlements and <b>leading</b> to more <b>flexible</b> working patterns. In this paper I situate the new hour laws within the long historical tradition of state political intervention over working time and argue that this remains {{a key element in}} reforming French industrial relations. Copyright Blackwell Publishers Ltd/London School of Economics 2000. ...|$|R
40|$|International audienceSparse {{estimation}} methods {{are aimed at}} using or obtaining parsimonious representations of data or models. While naturally cast as a combinatorial optimization problem, variable or feature selection admits a convex relaxation through the regularization by the ℓ_ 1 -norm. In this paper, we consider situations where we are not only interested in sparsity, but where some structural prior knowledge is available as well. We show that the ℓ_ 1 -norm can then be extended to structured norms built on either disjoint or overlapping groups of variables, <b>leading</b> to a <b>flexible</b> framework that can deal with various structures. We present applications to unsupervised learning, for structured sparse principal component analysis and hierarchical dictionary learning, and to supervised learning {{in the context of}} non-linear variable selection...|$|R
40|$|Psychrophilic microorganisms, {{hosts of}} {{permanently}} cold habitats, produce enzymes which are adapted {{to work at}} low temperatures. When compared to their mesophilic counterparts, these enzymes display a higher catalytic efficiency over a temperature range of roughly 0 - 30 degrees C and a high thermosensitivity. The molecular characteristics of cold enzymes originating from Antarctic bacteria have been approached through protein modelling and X-ray crystallography. The deduced three-dimensional structures of cold alpha-amylase, beta-lactamase, lipase and subtilisin have been compared to their mesophilic homologs. It appears that the molecular adaptation resides in a weakening of the intramolecular interactions, {{and in some cases}} in an increase of the interaction with the solvent, <b>leading</b> to more <b>flexible</b> molecular edifices capable of performing catalysis at a lower energy cost. Peer reviewe...|$|R
40|$|AbstractThe {{decision-making}} activities {{through all}} the design process are crucial for the final product success but currently there are limited computational tools available to provide better support to the designer especially at the earlier stages of the process. In addition the cost of fixing errors or making changes to a design escalates dramatically as the design advances in the product lifecycle. Besides, these activities, in a global design scenario, occur in different time and places, <b>leading</b> to a <b>flexible</b> and light solution {{that needs to be}} available for different users. Here is proposed an Augmented Reality (AR) application for Android mobile devices for getting feedback, via internet of a target user, in order to enhance the evaluation of aesthetical response in the conceptual design of discrete product...|$|R
40|$|Abstract. Language-based {{and process}} calculi-based {{information}} security are well developed fields of computer security. Although these fields {{have much in}} common, it is somewhat surprising that the literature lacks a comprehensive account of a formal link between the two disciplines. This paper develops such a link between a language-based specification of security and a process-algebraic framework for security properties. Encoding imperative programs into a CCSlike process calculus, we show that timing-sensitive security for these programs exactly corresponds to the well understood process-algebraic security property of persistent bisimulation-based nondeducibility on compositions (���). This rigorous connection opens up possibilities for cross-fertilization, <b>leading</b> to both <b>flexible</b> policies when specifying the security of heterogeneous systems and to a synergy of techniques for enforcing security specifications. ...|$|R
40|$|Abstract—We present several {{hardware}} architectures {{to implement}} low-density parity-check (LDPC) decoders for codes constructed with hierarchical structure. The proposed hierarchical {{formulation of the}} LDPC code allows a structured hardware realization of the decoder. For a fully-parallel implementation, there is reduced routing congestion, allowing implementations for blocks sizes up to 1024 bits in 0. 13 µm technology. Partially and fully serial implementations benefit greatly from {{the structure of the}} code as well, <b>leading</b> to several <b>flexible,</b> efficient architectures. In a general purpose 0. 13 µm technology, the approximate area required by a 1024 -bit fullyparallel LDPC decoder is found to be 12. 5 mm 2 while a serial decoder can be implemented in an area of 0. 15 mm 2. I...|$|R
40|$|Language-based {{and process}} calculi-based {{information}} security are well developed fields of computer security. Although these fields {{have much in}} common, it is somewhat surprising that the literature lacks a comprehensive account of a formal link between the two disciplines. This paper develops such a link between a language-based specification of security and a process-algebraic framework for security properties. Encoding imperative programs into a CCS-like process calculus, we show that timing-sensitive security for these programs exactly corresponds to the well understood process-algebraic security property of persistent bisimulation-based nondeducibility on compositions (P_BNDC). This rigorous connection opens up possibilities for cross-fertilization, <b>leading</b> to both <b>flexible</b> policies when specifying the security of heterogeneous systems and to a synergy of techniques for enforcing security specifications...|$|R
40|$|This paper {{presents}} {{an investigation into}} the controllability for an aircraft of seamless aeroelastic wing. The research is aimed at the design of control laws for the aircraft rolling by actively operating a pair of an unconventional hingeless <b>flexible</b> <b>leading</b> and trailing control surfaces at different flight speed. The main challenge is how to achieve a specified rolling rate for the aircraft when the control effectiveness drops down and even crosses over the rolling reversal point within the flight envelope. This phenomenon is mainly due to the aeroelastic effect of the large sweptback and highly flexible wing design for weight saving. The investigation shows that control laws varying with the flight speed can be designed to achieve the rolling control target...|$|R
40|$|This paper {{deals with}} the control of three {{dimensional}} rotational maneuvers of flexible spacecraft. A spacecraft with a spherical hub and six symmetric appendages is considered here as a model. The appendages are long and <b>flexible</b> <b>leading</b> to low frequency vibration under any control action. To provide a comprehensive treatment of input shaped controllers, both open loop and closed loop controllers are considered. The minimum-time bang-bang and the near-minimum-time controller, {{used in conjunction with}} the shaped input technique are studied. In addition, a combination of a Liapunov controller with the shaped input control technique is proposed {{to take advantage of the}} simple feedback control strategy and augment it with a technique that can eliminate the vibratory motion of the flexible appendages more efficiently...|$|R
40|$|Sparse {{estimation}} methods {{are aimed at}} using or obtaining parsimonious representations of data or models. While naturally cast as a combinatorial optimization problem, variable or feature selection admits a convex relaxation through the regularization by the ` 1 -norm. In this paper, we consider situations where we are not only interested in sparsity, but where some structural prior knowledge is available as well. We show that the ` 1 -norm can then be extended to structured norms built on either disjoint or overlapping groups of variables, <b>leading</b> to a <b>flexible</b> framework that can deal with various structures. We present applications to unsupervised learning, for structured sparse principal component analysis and hierarchical dictionary learning, and to supervised learning {{in the context of}} non-linear variable selection...|$|R
40|$|The {{choice of}} {{decision}} framework {{used to set}} regulatory tolerance levels for hazardous substances {{can be divided into}} rigid and flexible tolerance levels. Rigid decision frameworks include zero or deminimis that fix risk levels for some subpopulation. and/or highly tolerances The accelerating identification of highly sensitive exposed individuals and the division of the population into ever smaller subpopulations at higher risk could prove to be tremendously burdensome on regulatory systems, particularly for rigid decision frameworks. Rigid tolerance levels, philosophically based on "rights" to zero or arbitrarily low excess risks for individuals, do not contain sufficient flexibility to account for small high-risk subpopulations. Furthermore, the equal protection for all such groups is an illusion, mainly because of the potentially large number of such subgroups and the relatively fixed regulatory resources. Thus, deminimis regulation is seen as a minimal but inadequate improvement over zero risk regulation. with improved measures of the heterogeneous demand for risk reduction by various high-risk subpopulations, augmented cost-benefit analyses <b>leading</b> to <b>flexible</b> tolEr 2. nces could provide a richer analytic framework for more efficient regulatory decisions. Additionally, it may be useful to attempt to c 2. tegorize hazards and subpopulations {{on the basis of the}} ability to self-protect. De minimis, sensitive, decision framework, cost benefit, Food Consumption/Nutrition/Food Safety, Health Economics and Policy,...|$|R
30|$|The {{conceptual}} {{definition of}} TVET {{used in this}} review cuts across education level, type of learning arrangement, mode of delivery, setting, and type of provider/regulator. It includes provision of (i) initial training for young people {{from the age of}} 15 / 16  years after compulsory school, but prior to entering work; (ii) continuing education and training for adults in the labour market <b>leading</b> to personal, <b>flexible</b> and/or vocational competencies; and (iii) training for unemployed persons currently available for and seeking work (including retraining for those made redundant). Single- and multi-service TVET interventions were eligible for inclusion in the review, as were interventions delivered {{for any length of time}} or frequency. LMICs were defined according to World Bank classification of economies (in effect 1 July 2011 until 30 June 2012).|$|R
40|$|Abstract. Sparse {{estimation}} methods {{are aimed at}} using or obtaining parsimonious representations of data or models. While naturally cast as a combinatorial optimization problem, variable or feature selection admits a convex relaxation through the regularization by the ℓ 1 -norm. In this paper, we consider situations where we are not only interested in sparsity, but where some structural prior knowledge is available as well. We show that the ℓ 1 -norm can then be extended to structured norms built on either disjoint or overlapping groups of variables, <b>leading</b> to a <b>flexible</b> framework that can deal with various structures. We present applications to unsupervised learning, for structured sparse principal component analysis and hierarchical dictionary learning, and to supervised learning {{in the context of}} nonlinear variable selection. Key words and phrases: Sparsity, convex optimization. 1...|$|R
40|$|Abstract. Crack {{propagation}} is modelled using scaled boundary polygons. The polygons discretise the computational {{domain and}} can be of any number of sides, <b>leading</b> to more <b>flexible</b> mesh generation. The scaled boundary finite element method is used to construct shape functions of the polygon elements. These shape functions form a partition of unity and are linearly complete. They can accurately model any kind of stress singularity without local mesh refinement or asymptotic enrichment functions. The scaled boundary shape functions enable the method to be further developed to model the response of heterogeneous and nonlinear materials. As the polygons can be of any number of sides, simple re-meshing algorithms can be devised to model crack propagation. Two numerical benchmarks are modeled to illustrate the salient features of the scaled boundary polygons...|$|R
40|$|This paper {{presents}} {{an investigation into}} the roll controllability for an aircraft of seamless aeroelastic wing (SAW). The research is aimed at the modelling of the SAW aircraft and design of control laws for the aircraft rolling by actively operating a pair of unconventional hinge-less <b>flexible</b> <b>leading</b> and trailing control surfaces at different flight speed. The main challenge is how to achieve a specified rolling rate for the aircraft when the control effectiveness drops down and even crosses over the rolling reversal point within the flight envelope. This phenomenon is mainly due to the aeroelastic effect of the large swept back and highly flexible wing design for weight saving. The investigation shows that control gains varying with the flight speed can be designed to achieve the rolling control target...|$|R
40|$|This paper {{presents}} {{an overview of}} Dr. Gary Balas research activities in linear, parameter-varying (LPV) systems applied to aeroservoelastic (ASE) aircraft. More efficient aircraft can be designed by reducing weight and structure in the wings and fuselage. This makes the aircraft more <b>flexible</b> <b>leading</b> to increased ASE effects. Such ASE aircraft can be modeled as a linear parameter varying (LPV) system with an arbitrary, i. e. not necessarily rational, dependence on the scheduling parameters. The system involves coupling of the aircraft structural dynamics and aerodynamics thus resulting in large state dimension. This large dimension necessitates special approaches to modeling, order reduction and control design. The paper describes the process of designing an LPV controller for flutter suppression of a flexible unmanned aircraft starting from the nonlinear equation of motions for the vehicle...|$|R
40|$|The wing on the NASA F- 111 {{transonic}} aircraft technology airplane was modified to provide <b>flexible</b> <b>leading</b> and trailing edge flaps. This wing {{is known as}} the mission adaptive wing (MAW) because aerodynamic efficiency can be maintained at all speeds. Unlike a conventional wing, the MAW has no spoilers, external flap hinges, or fairings to break the smooth contour. The leading edge flaps and three-segment trailing edge flaps are controlled by a redundant fly-by-wire control system that features a dual digital primary system architecture providing roll and symmetric commands to the MAW control surfaces. A segregated analog backup system is provided {{in the event of a}} primary system failure. This paper discusses the design, development, testing, qualification, and flight test experience of the MAW primary and backup flight control systems...|$|R
40|$|This paper {{addresses}} {{the problem of}} estimating a density, with either a compact support or a support bounded at only one end, exploiting a general and natural form of a finite mixture of distributions. Due {{to the importance of}} the concept of multimodality in the mixture framework, unimodal beta and gamma densities are used as mixture components, <b>leading</b> to a <b>flexible</b> modeling approach. Accordingly, a mode-based parameterization of the components is provided. A partitional clustering method, named k-bumps, is also proposed; it is used as an ad hoc initialization strategy in the EM algorithm to obtain the maximum likelihood estimation of the mixture parameters. The performance of the k-bumps algorithm as an initialization tool, in comparison to other common initialization strategies, is evaluated through some simulation experiments. Finally, two real applications are presented...|$|R
40|$|This paper aims {{to give a}} brief {{overview}} of {{the current state of the}} art in emotional speech synthesis in view of a multi-modal context. After a brief introduction into the concept of text-to-speech synthesis, two approaches to the expression of emotions in speech synthesis are described. The categorical approach models emotions as discrete categories and is able to provide high-quality emotional speech for a few emotion categories; the dimensional approach uses emotion dimensions such as activation and evaluation to model essential emotional properties, <b>leading</b> to more <b>flexible</b> but less specific expressions. Architectural requirements for an audio-visual integration are outlined. Three examples of demonstrators illustrate the types of applications we currently envisage. Finally, the question of validation of a generation system is formulated, and a direction for the development of possible answers is suggested...|$|R
