17|3|Public
40|$|We {{work with}} <b>logarithmic</b> <b>interpolation</b> methods (A 0,A 1) θ,q,A where θ= 0 or 1. On the {{contrary}} to the case 0 <θ< 1, we show that their description {{in terms of the}} J-functional changes depending on the relationship between q and A, and that there is no description in a certain range. Then we use these J -descriptions to investigate the behavior of compact operators and weakly compact operators under <b>logarithmic</b> <b>interpolation</b> methods. In particular, we extend a recent compactness result of Edmunds and Opic for operators between Lp-spaces over finite measure spaces to σ -finite measure spaces. We also determine the dual of (A 0,A 1) θ,q,A when θ= 0 or 1...|$|E
40|$|This short {{communication}} extends earlier modelling of the {{tensile strength}} and failure strain of jute technical fibres. A maximum likelihood estimate (MLE) model, a linear model and a natural <b>logarithmic</b> <b>interpolation</b> model (NLIM) are compared. The NLIM model {{is found to}} give superior predictions. Griffith Sciences, Griffith School of EngineeringNo Full Tex...|$|E
40|$|The {{population}} map uses {{a quarter}} degree box resolution. Boxes with zero people {{are given in}} white. Darker shades of red indicate higher population counts per box using a <b>logarithmic</b> <b>interpolation.</b> The highest density boxes appear in Mumbai, with 11, 687, 850 people in the quarter degree block, Calcutta (10, 816, 010), an...|$|E
40|$|Given {{output data}} of a {{stationary}} stochastic process estimates of covariance and cepstrum parameters can be obtained. These estimates {{can be used}} to determine ARMA models to approximately fit the data by matching the parameters exactly. However, the estimates of the parameters may contain large errors, especially if they are determined from short data sequences, and thus it makes sense to match the parameters in an approximate way. Here we consider a convex method for solving an approximate linear and <b>logarithmic</b> spectrum <b>interpolation</b> problem while maximizing the entropy and penalize the quadratic deviation from the nominal parameters. QC 20110907 </p...|$|R
40|$|Butanol has {{received}} significant research attention as a second-generation biofuel {{in the past}} few years. In the present study, skeletal mechanisms for four butanol isomers were generated from two widely accepted, well-validated detailed chemical kinetic models for the butanol isomers. The detailed models were reduced using a two-stage approach consisting of the directed relation graph with error propagation and sensitivity analysis. During the reduction process, issues were encountered with pressure-dependent reactions formulated using the <b>logarithmic</b> pressure <b>interpolation</b> approach; these issues are discussed and recommendations made to avoid ambiguity in its future implementation in mechanism development. The performance of the skeletal mechanisms generated here was compared with that of detailed mechanisms in simulations of autoignition delay times, laminar flame speeds, and perfectly stirred reactor temperature response curves and extinction residence times, over a wide range of pressures, temperatures, and equivalence ratios. The detailed and skeletal mechanisms agreed well, demonstrating the adequacy of the resulting reduced chemistry for all the butanol isomers in predicting global combustion phenomena. In addition, the skeletal mechanisms closely predicted the time-histories of fuel mass fractions in homogeneous compression-ignition engine simulations. The performance of each butanol isomer was additionally compared with that of a gasoline surrogate with an antiknock index of 87 in a homogeneous compression-ignition engine simulation. The gasoline surrogate was consumed faster than any of the butanol isomers, with tert-butanol exhibiting the slowest fuel consumption rate. While n-butanol and isobutanol displayed the most similar consumption profiles relative to the gasoline surrogate, the two literature chemical kinetic models predicted different orderings. Comment: 39 pages, 16 figures. Supporting information available via [URL]...|$|R
40|$|An {{interpolation}} {{scheme for}} planar curves is described, obtained by patching together parametric rational cubics approximating logarithmic spiral segments. The resulting spline curves are G 2 continuous, their curvature radius plot {{is close to}} piecewise linear. The presented method is globally convexity preserving and essentially provides logarithmic spiral as well as circle precision. A number of examples illustrates the interpolation method. This work also includes an implementation of the described approach. Keywords: <b>Interpolation,</b> <b>logarithmic</b> spiral, approximation, shape optimization, circle precision, rational cubic, spline curve, geometric continuity, CAGD. Contents 1 Introduction 1 2 Rational cubic spline curves 3 2. 1 Rational B'ezier curves : : : : : : : : : : : : : : : : : : : : : : 3 2. 2 Arc length and curvature : : : : : : : : : : : : : : : : : : : : : 8 2. 3 G 2 continuity : : : : : : : : : : : : : : : : : : : : : : : : : : : 9 2. 3. 1 Algebraic G 2 construction : : [...] ...|$|R
40|$|An {{improved}} {{version of}} the “marching cubes” algorithm [W. Lorensen and H. Cline, Comp. Graph. 21, (1987) ] for the generation of isosurfaces from 3 D data fields is presented and applied to molecular surfaces. The new algorithm avoids inconsistent pattern definitions of the original one, which lead to artificial gaps. The advantage of a <b>logarithmic</b> <b>interpolation</b> procedure, in particular for data fields typically occurring in molecular science, is demonstrated. An example is the generation of molecular surfaces based upon electron density data...|$|E
40|$|We give {{criteria}} for the membership of Hankel operators on the Hardy space on the disc in the Dixmier class, and establish estimates for their Dixmier trace. In contrast {{to the situation in}} the Bergman space setting, it turns out that there exist Dixmier-class Hankel operators that are not measurable (that is, their Dixmier trace depends on the choice of the underlying Banach limit), as well as Dixmier-class Hankel operators that do not belong to the Schatten-Lorentz ideal. A related question concerning <b>logarithmic</b> <b>interpolation</b> of Besov spaces is also discussed...|$|E
40|$|Photon {{interaction}} effective {{atomic number}} (Zeff) for partial as well as total photon interaction processes has been computed using <b>logarithmic</b> <b>interpolation</b> method for seven different concretes viz. (i) Ordinary, (ii) Hematite - Serpentine, (iii) Ilmenite - Limonite, (iv) Basalt - magnetite, (v) Ilmenite, (vi) Steel - scrap and (vii) Steel - magnetite concrete in the wide energy range from 10. 0 keV to 100 GeV. It has been concluded that this method has an advantage over the atomic to electronic cross-section ratio method especially for mixtures in the intermediate energy level. However, {{due to lack of}} experimental data in the higher energy region, it is difficult to discuss, its validity in these energy regions...|$|E
40|$|In {{this paper}} we mainly {{investigate}} the Cauchy {{problem of a}} two-component Novikov system. We first prove the local well-posedness of the system in Besov spaces B^s- 1 _p,r× B^s_p,r with p,r∈[1,∞], s>{ 1 + 1 /p, 3 / 2 } by using the Littlewood-Paley theory and transport equations theory. Then, by virtue of <b>logarithmic</b> <b>interpolation</b> inequalities and the Osgood lemma, we establish the local well-posedness of the system in the critical Besov space B^ 1 / 2 _ 2, 1 × B^ 3 / 2 _ 2, 1. Moreover, we present two blow-up criteria for the system by making use of the conservation laws. Comment: arXiv admin note: text overlap with arXiv: 1505. 0008...|$|E
40|$|This image shows {{city lights}} at night. It was {{composed}} {{from hundreds of}} pictures made by orbiting satellites. The seaboards of Europe, the eastern United States, and Japan are particularly well lit. Many cities exist near rivers or oceans so that goods can be exchanged cheaply by boat. The central parts of South America, Africa, Asia, and Australia are rather dark despite their high population density, see map to the left. 5 2005 World Population The population map uses a quarter degree box resolution. Boxes with zero people are given in white. Darker shades of red indicate higher population counts per box using a <b>logarithmic</b> <b>interpolation.</b> The highest density boxes appear in Mumbai, with 11, 687, 850 people in the quarter degree block, Calcutta (10, 816, 010), an...|$|E
40|$|One hundred tensile {{tests were}} {{undertaken}} {{at each of}} five distinct fibre lengths (6, 10, 20, 30 and 50 mm) on a single batch of jute fibres from South Asia. The Young's moduli {{were found to be}} independent of length. The ultimate stress (fracture strength) and fracture strains were found to decrease with increasing fibre length. The variation in mechanical properties at each fibre length was characterised using Weibull statistics based on a maximum likelihood estimate; referred to as point estimates. Two empirical based models (a linear and a natural <b>logarithmic</b> <b>interpolation</b> model) have been developed to estimate the fracture properties at any length between 6 and 50 mm. These two interpolation models were also developed based on maximum likelihood estimates. The point estimates were used to benchmark the performance of the two models. The natural logarithmic model was found to be superior to the linear model. No Full Tex...|$|E
40|$|Five-year {{age-specific}} incidence {{rates were}} shown to produce small but systematic errors in the calculation of the expected number of tumours in a hypothetical but realistic study population. Underestimates occurred at younger ages (under 55) and overestimates at older ages, with a small overestimate (0. 22 %) overall. Larger errors (up to 12 %) were obtained {{when there was a}} rapid change in the single-year age structure of the study population. Interpolation between five-year rates will normally produce an inaccurate set of one-year rates. It is shown, with the example of a <b>logarithmic</b> <b>interpolation,</b> that these rates tend to produce errors of similar size to the five-year rates but with a small underestimate overall (0. 37 %). However, the interpolated rates produced the smaller errors (up to 1 %) when the study population age structure undergoes rapid change. A method is suggested for partially correcting the error in the interpolated rates...|$|E
40|$|The {{linearity}} {{of the log}} (adjusted {{retention time}} of normal alkanes) vs. C no. is of interest because {{of the possibility of}} calcg. retention indexes by <b>logarithmic</b> <b>interpolation</b> over a wider range of C atoms than as defined by Kovats who considered the adjusted retention times of 2 neighboring (even) normal alkanes. Although by some authors this log plot is considered to have a certain curvature, at least {{in a part of the}} plot, it appears that no curvature exists at all. One of the reasons that curvature has been found is due to the general assumption in gas chromatog. that the adjusted retention time of CH 4 equals zero. This induces an error which is responsible for the observed curvature in the initial region of the log plot. There is a way to get around this error, viz. by calcg. the column dead vol. point from three...|$|E
40|$|This {{contribution}} {{is aimed at}} designing the optimal thickness of lead-iron double-layer container to store a radioactive waste releasing the photon energy at 1. 3325 [*]MeV and initial radiation intensity at 100 [*]mSv/hr using the optimization design by MATLAB software. This design consisted of three parts of calculations to achieve 1000 times the radiation attenuation of container. The first was the <b>logarithmic</b> <b>interpolation</b> for the mass attenuation coefficient. The second was the bilogarithmic interpolation for the exposure buildup factor. The third was the contour-plotting analytical technique for the optimal thickness of radiation container. The values of mass attenuation coefficient and exposure buildup factor were exactly validated {{as compared with the}} standard reference database. Furthermore, we have found that the optimal thickness was 3. 2 [*]cm for lead (1 st layer) and 17. 0 [*]cm for iron (2 nd layer). Container weight was 994. 30 [*]kg, whilst container cost was 167. 30 [*]USD. The benefit of our design can quickly and precisely apply for the radiation safety assessment of the occupational radiation workers who always work in the nuclear reactor area...|$|E
40|$|The authors greatly {{acknowledge}} the Editor for carefully reading the manuscript and providing constructive comments. Following the suggestions {{we will make}} changes in the manuscript and here in bold responses to Editor Comments. 1. Presentation of the forcing calculation results. The description of aerosol forcing should be clearly described. The authors should clarify if they calculated instantaneous values or daily averages, how calculations were done (which properties of aerosol and surface reflectance were used, how their spectral variability was accounted). If the authors noted some important tendencies in the forcing variability {{it would be useful}} to discuss the causes of this variability. For example, if it is caused by variability in aerosol SSA, it could be useful to display and discuss values of SSA. The aerosol radiative forcing have been simulated using as input in the SBDART radiative transfer model the experimental aerosol information (aerosol optical depth, single scattering albedo and asymmetry parameter) derived from the principal plane retrievals. <b>Logarithmic</b> <b>interpolation</b> (or extrapolation for λ 860 nm) was used to supply SBDART with aerosol optical depth...|$|E
40|$|The Maxwell-Stefan (M-S) {{equations}} {{are widely}} used for modeling permeation of water-alcohol mixtures across microporous membranes in pervaporation and dehydration process applications. For binary mixtures, for example, the following set of assumptions is commonly invoked, either explicitly or implicitly. (1) The M-S diffusivities D- 1, and D- 2, that portray interactions of individual components with the pore-walls, can be identified with the corresponding values for pure component permeation. (2) The D-i are independent of the adsorbed phase mole fractions x(i) of the permeating mixture within the pores. (3) The exchange coefficient, D- 12, that signify correlations in diffusional jumps within the pores, can be estimated {{on the basis of}} the <b>logarithmic</b> <b>interpolation</b> formula D- 12 = (D(12) x(1) (->) (1)) (x 1) (D- 12 (x 2) (->) (1)) (x 2), suggested by Vignes [Diffusion in binary solutions, Ind. Eng. Chem. Fund. 5 (1966) 189 - 199] for diffusion in binary liquid mixtures. (4) For structures such as LTA and DDR that consist of cages separated by narrow windows of sizes in the 0. 35 - 0. 42 nm range, the exchange coefficient is often assumed to have a large value, D- 12 -> infinity, leading to a set of un-coupled M-S equations. Molecular Dynamics (MDs) simulations of diffusion in binary mixtures containing water, methanol, and ethanol in FAU, and LTA have been carried out to test each of the foregoing set of assumptions. The break-down of all four assumptions when applied to diffusion of water-alcohol mixture permeation is highlighted. The root-cause of this break-down can be traced to the hydrogen bonding between water and alcohol molecules, which is much more predominant than for water-water, and alcohol-alcohol molecule-pairs...|$|E
40|$|Context: In {{the past}} decade, sensitive, {{resolved}} Sunyaev-Zel'dovich (SZ) studies of galaxy clusters have become common. Whereas many previous SZ studies have parameterized the pressure profiles of galaxy clusters, non-parametric reconstructions will provide {{insights into the}} thermodynamic state of the intracluster medium (ICM). Aims: We seek to recover the non-parametric pressure profiles of the high redshift ($z= 0. 89 $) galaxy cluster CLJ 1226. 9 + 3332 as inferred from SZ data from the MUSTANG, NIKA, Bolocam, and Planck instruments, which all probe different angular scales. Methods: Our non-parametric algorithm makes use of <b>logarithmic</b> <b>interpolation,</b> which under the assumption of ellipsoidal symmetry is analytically integrable. For MUSTANG, NIKA, and Bolocam we derive a non-parametric pressure profile independently and find good agreement among the instruments. In particular, {{we find that the}} non-parametric profiles are consistent with a fitted gNFW profile. Given the ability of Planck to constrain the total signal, we include a prior on the integrated Compton Y parameter as determined by Planck. Results: For a given instrument, constraints on the pressure profile diminish rapidly beyond the field of view. The overlap in spatial scales probed by these four datasets is therefore critical in checking for consistency between instruments. By using multiple instruments, our analysis of CLJ 1226. 9 + 3332 covers a large radial range, from the central regions to the cluster outskirts: $ 0. 05 R_{ 500 } < r < 1. 1 R_{ 500 }$. This is a wider range of spatial scales than is typical recovered by SZ instruments. Similar analyses will be possible with the new generation of SZ instruments such as NIKA 2 and MUSTANG 2. Comment: 11 pages, 6 figures, submitted to A&...|$|E
40|$|SUMMARY Five-year {{age-specific}} incidence {{rates were}} shown to produce small but systematic errors in the calculation of the expected number of tumours in a hypothetical but realistic study population. Underestimates occurred at younger ages (under 55) and overestimates at older ages, with a small overestimate (0. 22 %) overall. Larger errors (up to 12 %) were obtained {{when there was a}} rapid change in the single-year age structure of the study population. Interpolation between five-year rates will normally produce an inaccurate set of one-year rates. It is shown, with the example of a <b>logarithmic</b> <b>interpolation,</b> that these rates tend to produce errors of similar size to the five-year rates but with a small underestimate overall (0. 37 %). However, the interpolated rates produced the smaller errors (up to 1 %) when the study population age structure undergoes rapid change. A method is suggested for partially correcting the error in the interpolated rates. Epidemiological studies frequently compare the observed cancer experience of a study group with that of the general population. The expected number of tumours is normally calculated by applying five-year age-specific incidence rates to the accumulated person-years of observation subdivided by age. ' These studies are expensive and time-consuming and it is clearly worthwhile to consider ways in which the calculation of the expected numbers could be refined. One obvious possibility is the use of one-year rates for five-year rates, but such rates are not available from published data and would have to be derived by some method of interpolation, a lengthy and possibly error-prone procedure. In this study we investigated the size of the errors arising from the use of five-year rates, comparing the results with those from a defined set of one-year rates. We examined a method of Qbtaining one-year rates by interpolating between five-year rates, determined the source and size of the errors which this entails, and suggested a possible solution...|$|E
40|$|Scientists and {{engineers}} {{work with the}} reduction, analysis, and manipulation of data. In many instances, the recorded data must meet certain requirements before standard numerical techniques {{may be used to}} interpret it. For example, the analysis of a linear visoelastic material requires knowledge of one of two time-dependent properties, the stress relaxation modulus E(t) or the creep compliance D(t), one of which may be derived from the other by a numerical method if the recorded data points are evenly spaced or increasingly spaced with respect to the time coordinate. The problem is that most laboratory data are variably spaced, making the use of numerical techniques difficult. To ease this difficulty in the case of stress relaxation data analysis, NASA scientists developed DATASPACE (A Program for the <b>Logarithmic</b> <b>Interpolation</b> of Test Data), to establish a logarithmically increasing time interval in the relaxation data. The program is generally applicable to any situation in which a data set needs increasingly spaced abscissa values. DATASPACE first takes the logarithm of the abscissa values, then uses a cubic spline interpolation routine (which minimizes interpolation error) to create an evenly spaced array from the log values. This array is returned from the log abscissa domain to the abscissa domain and written to an output file for further manipulation. As a result of the interpolation in the log abscissa domain, the data is increasingly spaced. In the case of stress relaxation data, the array is closely spaced at short times and widely spaced at long times, thus avoiding the distortion inherent in evenly spaced time coordinates. The interpolation routine gives results which compare favorably with the recorded data. The experimental data curve is retained and the interpolated points reflect the desired spacing. DATASPACE is written in FORTRAN 77 for IBM PC compatibles with a math co-processor running MS-DOS and Apple Macintosh computers running MacOS. With minor modifications the source code is portable to any platform that supports an ANSI FORTRAN 77 compiler. MicroSoft FORTRAN v 2. 1 is required for the Macintosh version. An executable is included with the PC version. DATASPACE is available on a 5. 25 inch 360 K MS-DOS format diskette (standard distribution) or on a 3. 5 inch 800 K Macintosh format diskette. This program was developed in 1991. IBM PC is a trademark of International Business Machines Corporation. MS-DOS is a registered trademark of Microsoft Corporation. Macintosh and MacOS are trademarks of Apple Computer, Inc...|$|E

