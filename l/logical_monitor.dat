0|22|Public
30|$|We {{opted for}} O'Malley and Chamot’s (1990) {{classification}} of learning strategies, and, more specifically, for Vandergrift’s (1997), Flowerdew and Miller’s (2005), and Vandergrift and Gogh’s (2012) adaptation {{of such a}} classification to listening. This taxonomy differentiates between metacognitive, cognitive, and socio-affective strategies. Each of the main three broad groups includes various types and sub-types of strategies. As many specialists (like Lynch, 2009) recommend to choose {{a certain number of}} strategies to be fully taught during the instruction, we decided to select a specific number of listening strategies to be directly and explicitly included in our instruction. The strategies that were selected to be explicitly included in the instruction were the metacognitive strategies of planning (comprehension task checking, focusing attention and global prediction), <b>monitoring</b> (<b>logical</b> <b>monitoring</b> and monitoring between parts), and evaluation (self-evaluation and problem identification); the cognitive strategies of elaboration and inferencing, and the socio-affective strategies of questioning for clarification and cooperation. As recommended by Graham and Macaro (2008), the selected strategies were taught in clusters.|$|R
40|$|Under the {{circumstances}} of certain weaknesses in the monitoring and evaluation processes of sustainable investment projects, the paper aims to develop a general integrated flow, encompassing both a project monitoring system and also a project evaluation system for the investment projects involving economic objectives, as well as cross-cutting social and environmental targets. The whole approach is being presented as a flowchart, which highlights the intimate relationship between the monitoring and evaluation processes, and provides a formal framework for performing a <b>logical</b> <b>monitoring</b> and evaluation process, taking into account simultaneously the economic, social and environmental perspectives, within an investment project. Last, but not least, the article states both the estimated advantages and the disadvantages of such a managerial tool, opening new perspectives for developing further improved models and systems. evaluation, flow, investment projects, monitoring, sustainability. ...|$|R
40|$|This paper {{describes}} {{a framework for}} practical and efficient monitoring of a wireless sensor network. The architecture proposed exploits the dynamic reasoning capabilities of the Situation Calculus {{in order to assess}} the sensor network behavior before actually deploying all the nodes. Designing a wireless sensor network for a specific application typically involves a preliminary phase of simulations that rely on specialized software, whose behavior does not necessarily reproduce what will be experienced by an actual network. On the other hand, delaying the test phase until deployment may not be advisable due to unreasonable costs. This paper suggests the adoption of a hybrid approach that involves coupling an actual wireless sensor network, composed of a minimal set of nodes, with a simulated one. We describe a framework that implements a <b>logical</b> <b>monitoring</b> entity able to analyze the network behavior by means of a superimposed communication control network. The system aims to enhance the simulation environment with a logical reasoning unit in order to extract higher level information about the network state, used to provide the network designer with guidance during the pre-deployment design phas...|$|R
30|$|In {{the context}} of forests, the main {{influence}} of management on biodiversity is through changes in forest structure and composition (Lindenmayer et al. 2000; Raison et al. 2001; Kuuluvainen 2009), where structure and composition are commonly deliberately manipulated to achieve certain ecosystem functions and services (Plieninger et al. 2010; Bauhus and Pyttel 2015). Thus it appears <b>logical</b> to <b>monitor</b> changes in these important determinants of biodiversity {{in the absence of}} direct data on forest species and their populations and genetic variation (Taboada et al. 2010). The monitoring of biodiversity relevant aspects of forest structure and composition may be integrated into standard forest inventories at little additional cost when compared to separate approaches for biodiversity monitoring (Corona 2016).|$|R
40|$|A {{possibility}} {{to reduce the}} investment costs is an improved functionality of the inspection station in order to awaken investors' interest to buy. A new concept for 2 -D and 3 -D metric and <b>logical</b> quality <b>monitoring</b> with a more accurate, flexible, economical and efficient inspection station has been developed and tested at IITB. The inspection station uses short- and wide-range sensors, an intelligent grip system and a so-called "sensor magazine" which make the inspection process more flexible. The sensor magazine consists of various sensor ports with various task-specific, interchangeable sensors. With the sensor magazine and the improved measuring methods, the testing periods and therefore the costs in factory can be substantially decreased...|$|R
40|$|Parallel program {{monitoring}} {{is a key}} {{to success}} in parallel program development. We have developed a novel approach, called the logical clock approach, for the highly transparent monitoring of parallel programs. To apply the logical clock approach in monitoring occam programs on transputer-based systems, we first study the (micro-coded) process scheduler of the transputer, and then demonstrate how the information on process scheduling can be employed for correctly updating logical clocks and controlling inter-process communication in <b>logical</b> clock <b>monitoring.</b> Keywords: parallel programming environment, program monitoring, monitoring intrusiveness, transputer scheduling. 1. Introduction The transputer has hardware support for executing concurrent processes and for interprocess communication. Typically, parallel programs (e. g. occam programs) are first developed on a single transputer, and then mapped onto a network of transputers. Because of the existence of multiple concurrent proc [...] ...|$|R
40|$|As {{an effect}} of globalization, product parts are {{manufactured}} {{more and more in}} different places. Due to the manufacturing processes, (sub-) products are being transported back and forth and rearranged until they can finally reach the consumer. Not only the environment is increasingly burdened, but also the natural resources are wasted increasingly thoughtless. One reason is certainly because for decades the industry has had only an inflexible concept for the inspection of (sub-) products, which cannot be easily adapted to changes in product layout, for example one robot with one sensor or one rigid structure with a fixed number of sensors for one specific inspection task. This rigid approach is unsuitable for the inspection of variant products. For these reasons, a new concept for 2 D and 3 D metric and <b>logical</b> quality <b>monitoring</b> with a more accurate, flexible, economical and efficient inspection station has been developed and tested in IOSB...|$|R
40|$|ISBN: 0 - 7803 - 9571 - 9 We {{prove the}} {{correctness}} of an original method for generating components that capture {{the occurrence of}} events, and <b>monitor</b> <b>logical</b> and temporal properties of hardware/software embedded systems. The properties are written in PSL, under the form of assertions in declarative form. The method {{is based on a}} library of primitive digital components for the PSL temporal operators. These building blocks are interconnected to construct complex properties, resulting in a synthesizable digital module that can be properly linked to the digital system under scrutiny. The proof reported in this paper applies to the weak version of all “foundation language” operators...|$|R
40|$|CMU-ITC- 88 - 067 In {{this paper}} we {{introduce}} {{the concepts of}} Logical and Physical Network Locality and point out their importance {{to the performance of}} distributed systems. We then describe the design of IPwatch, a simple and inexpensive tool for <b>monitoring</b> <b>logical</b> network locality. IPwatch exploits short-term locality to enable monitoring of medium- and long-term locality of large networks using modest computational resources. We describe experiments at Carnegie Mellon University to validate our ideas and to calibrate IPwatch. The results confirm the existence of substantial short-term locality in this environment. Less than 5 percent of the possible host pairs account for 75 percent of the traffic, and less than 15 percent of them account for 90 percent. Comparative measurements on another network in our environment show even stronger short-term locality...|$|R
40|$|This {{practitioner}} paper chronicles my {{involvement of}} the grant writing proposal that was designed {{on behalf of a}} non-for-profit organization, the Association of Dalit Women’s Advancement of Nepal (ADWAN), in order to secure funding and donations for the reconstruction of the destroyed Sinjali Secondary School in Gorkha district, Taklung village, after a 2015 earthquake struck Nepal. The proposal was guided by and collaborated with Professor Jude Fernando of Clark University, as Professor Fernando was able to visit Taklung village and gather information about the needs in the educational sector damaged by the earthquake. Literature review and research was gathered to focus on the ramifications of the lack of school access which validated the need of continuing education for the most vulnerable and marginalized community members. Literature included: yearly reports, government country profiles, and interviews with children that have been internally displaced due to damaged homes. Issues such as increased drop-out rates, physical and mental health impacts, infrastructure damage, increased child labor, and vulnerability are discussed in-depth. The grant writing proposal follows a traditional format in which it outlines the project’s purpose, objectives, and methodology. Furthermore, it details the <b>logical</b> framework, <b>monitoring</b> 2 ̆ 6 evaluation, budget, and a timeline for the project. In the final section of the paper, I reflect on the process and challenges I’ve encountered throughout writing the grant...|$|R
40|$|The main {{performance}} pitfall of the Time Warp distributed discrete event simulation (DDES) protocol {{has been}} widely recognized to be the overoptimistic progression of event execution into the simulated future. The premature execution of events that eventually have to be "rolled back" due to causality violations induces memory and communication overheads as sources of performance inefficiencies. Optimistic Time Windows and self adaptive mechanisms have been proposed in the literature to control the optimism in Time Warp {{in order to improve}} or optimize its execution performance. In this work, an adaptive optimism control mechanism based on the observed model parallelism is proposed. Methodologically, <b>logical</b> processes (LPs) <b>monitor</b> the local virtual time (LVT) progression per unit CPU-time from the timestamp of arriving messages and establish a cost model for the trade-off between optimistically progressing and conservatively blocking the simulation engine. Compared to previous approache [...] ...|$|R
40|$|In {{this paper}} we {{introduce}} {{the concepts of}} Logical and Physical Network Locality and point out their importance {{to the performance of}} distributed systems. We then describe the design of IPwatch, a simple and inexpensive tool for <b>monitoring</b> <b>logical</b> network locality. IPwatch exploits short-term locality to enable monitoring of medium- and long-term locality of large networks using modest computational resources. We describe experiments at Carnegie Mellon University to validate our ideas and to calibrate IPwatch. The results confirm the existence of substantial short-term locality in this environment. Less than 5 percent of the possible host pairs account for 75 percent of the traffic, and less than 15 percent of them account for 90 percent. Comparative measurements on another network in our environment show even stronger short-term locality. Copyright Ó 1988 Mark J. Lorence and M. Satyanarayanan This work was supported by the National Science Foundation (Contract No. CCR- 8657907), Defen [...] ...|$|R
40|$|The author’s {{research}} {{is dedicated to}} the enhancement of the level of the enterprise economic safety. This task involves developing the concept of an integrated system for early prevention of dangers and threats of business activity, substantiation of procedures for regulating the activities of the enterprise in accordance with the changing external and internal factors. Multiloop diagnostics model is proposed to identify causal relations of management dysfunction. It allows you to receive an adequate assessment of the basic parameters of activity of the enterprise and accurately identify its status. Researching problems of economic safety of the enterprise such diagnostic methods as economic and <b>logical</b> analysis, statistical <b>monitoring</b> and strategic management were applied. There was made a conclusion that a qualitative assessment is a key tool of the level assessment of the enterprise economic safety, its control, and monitoring. It allows you to get reliable information about the real possibilities of the enterprise at different stages of development, to monitor and evaluate the level of economic security, find effective solutions to transition to a higher level of economic safety of the enterprise...|$|R
40|$|Computer {{networks}} today {{typically do}} not provide any mechanisms to the users to learn, in a reliable manner, which paths have (and have not) been taken by their packets. Rather, it seems inevitable {{that as soon as}} a packet leaves the network card, the user is forced to trust the network provider to forward the packets as expected or agreed upon. This can be undesirable, especially in the light of today's trend toward more programmable networks: after a successful cyber attack on the network management system or Software-Defined Network (SDN) control plane, an adversary in principle has complete control over the network. This paper presents a low-cost and efficient solution to detect misbehaviors and ensure trustworthy routing over untrusted or insecure providers, in particular providers whose management system or control plane has been compromised (e. g., using a cyber attack). We propose Routing-Verification-as-a-Service (RVaaS) : RVaaS offers clients a flexible interface to query information relevant to their traffic, while respecting the autonomy of the network provider. RVaaS leverages key features of OpenFlow-based SDNs to combine (passive and active) configuration <b>monitoring,</b> <b>logical</b> data plane verification and actual in-band tests, in a novel manner...|$|R
40|$|Monitoring {{describes}} the prospective supervision, observation, {{and testing of}} an ongoing process. The result of monitoring provides reassurance that the goal has been or will be achieved, or suggests changes that will {{allow it to be}} achieved. In therapeutics, most thought has been given to Therapeutic Drug Monitoring, that is, monitoring of drug concentrations to achieve benefit or avoid harm, or both. Patients and their clinicians can also monitor the progress of a disease, and adjust treatment accordingly, for example, to achieve optimum glycaemic control. Very little consideration has been given to the development of effective schemes for monitoring for the occurrence of adverse effects, such as biochemical or haematological disturbance. Significant harm may go undetected in controlled clinical trials. Even where harm is detected, published details of trials are usually insufficient to allow a practical monitoring scheme to be introduced. The result is that information available to prescribers, such as the Summary of Product Characteristics, frequently provides advice that is incomplete or impossible to follow. We discuss here the elements of <b>logical</b> schemes for <b>monitoring</b> for adverse drug reactions, and the possible contributions that computerized decision support can make. We should require evidence that if a monitoring scheme is proposed, it can be put into practice, will prove effective, and is affordable...|$|R
40|$|AbstractToxicity {{and effects}} of an {{antiepileptic}} drug, carbamazepine (CBZ) on transaminases like glutamate oxaloacetate transaminase (GOT) and glutamate pyruvate transaminase (GPT); lactate dehydrogenase (LDH) activities in gill, liver and muscle of a freshwater fish, Cyprinus carpio were investigated. The median lethal concentration (LC 50) of CBZ to C. carpio for 24 h was determined (59. 70 mgl−l). 1 / 10 th of LC 50 value was taken as a sublethal concentration (5. 97 mgl−l). Fish were exposed to both acute and sublethal CBZ concentration for 24 h and 35 days (at weekly intervals), respectively. During acute treatment, GOT activity was decreased in all the organs (gill, liver and muscle); GPT and LDH activities were increased in liver and muscle while decreased in gill. During sublethal treatment, GOT activity was decreased in liver and muscle, whereas GPT activity was increased in these two organs. A biphasic trend was noted in GOT and GPT activity in gill and LDH activity in gill, liver and muscle. The present study indicates that CBZ induced alterations {{in the activities of}} GOT, GPT and LDH in various organs of fish; these enzymes may be used as <b>logical</b> candidates to <b>monitor</b> the toxic levels of pharmaceuticals in aquatic organisms...|$|R
40|$|The {{trigger and}} data {{acquisition}} (TDAQ) {{system of the}} ATLAS experiment at CERN comprises approximately 2500 servers interconnected by three separate Ethernet networks, totaling 250 switches. Due to its real-time nature, there are additional requirements in comparison to conventional networks in terms of speed and performance. A comprehensive monitoring framework has been developed for expert use. However, non experts may experience difficulties in using it and interpreting data. Moreover, specific performance issues, such as single component saturation or unbalanced workload, need to be spotted with ease, in real-time, and understood {{in the context of}} the full system view. We addressed these issues by developing an innovative visualization system where the users benefit from the advantages of 3 D graphics to visualize the large monitoring parameter space associated with our system. This has been done by developing a hierarchical model of the complete system onto which we overlaid geographical, <b>logical</b> and real-time <b>monitoring</b> information. This article briefly describes the network monitoring framework and introduces the system’s visualization challenges and previous limitations. The functionality, design and implementation of the 3 D visualization system are then described in detail, with a focus on the model design, user interaction, navigation mechanisms and methods used to achieve scalability when rendering and updating many objects in real-time...|$|R
40|$|The {{evaluation}} of projects involving Multipurpose Community Telecentres is still under discussion, {{and there is not}} a single model suitable to capture all their implications and effects. The classical approach distinguishes between the Product Evaluation, referred to expect outputs of the project, degree of achievement of the original goals, benefits and impacts of these products; and the Process Evaluation, intending to describe how the project was carried out. This refers to strategies adopted, degree of success obtained, problems and constraints encountered, and proposals for doing things better in forthcoming initiatives. In pilot projects comprising a sequence of phases or stages, the traditional summative aspects (product evaluation) become more important during latter stages. The Formative Evaluation tries to identify the “best ” and “worst” practices, assessing the real situation, problems and constraints, and when necessary, devising remedial measures or proposals for enhancing the right actions accomplished and the outcomes. The need for continuous monitoring of the projects (process evaluation) extends to their whole duration, but is in the first stages when they are critical, because there are more opportunities to take advantage of early information and recommendations. If the project was prepared according to a <b>Logical</b> Framework the <b>monitoring</b> process can be tracked out within any systemati...|$|R
40|$|Analog {{circuit design}} and {{verification}} face significant challenges due to circuit complexity and short market windows. In particular, {{the influence of}} technology parameters on circuits, noise modeling and verification still remain a priority for many applications. Noise {{could be due to}} unwanted interaction between the various circuit blocks or it could be inherited from the circuit elements. Current industrial designs rely heavily on simulation techniques, but ensuring the correctness of such designs under all circumstances usually becomes impractically expensive. In this PhD thesis, we propose a methodology for modeling and verification of analog designs in the presence of noise and process variation using run-time verification methods. Verification based on run-time techniques employs <b>logical</b> or statistical <b>monitors</b> to check if an execution (simulation) of the design model violates the design specifications (properties). In order to study the random behavior of noise, we propose an approach based on modeling the designs using stochastic differential equations (SDE) in the time domain. Then, we define assertion and statistical verification methods in a MATLAB SDE simulation framework for monitoring properties of interest in order to detect errors. In order to overcome some of the drawbacks associated with monitoring techniques, we define a pattern matching based verification method for qualitative estimation of the simulation traces. We illustrate the efficiency of the proposed methods on different benchmark circuits...|$|R
40|$|The Cilkview {{scalability}} analyzer is {{a software}} tool for profiling, estimating scalability, and benchmarking multithreaded Cilk++ ap-plications. Cilkview <b>monitors</b> <b>logical</b> parallelism during an instru-mented {{execution of the}} Cilk++ application on a single process-ing core. As Cilkview executes, it analyzes logical dependencies within the computation to determine its work and span (critical-path length). These metrics allow Cilkview to estimate parallelism and predict how the application will scale {{with the number of}} pro-cessing cores. In addition, Cilkview analyzes scheduling overhead using the concept of a “burdened dag, ” which allows it to diagnose performance problems in the application due to an insufficient grain size of parallel subcomputations. Cilkview employs the Pin dynamic-instrumentation framework to collect metrics during a serial execution of the application code. It operates directly on the optimized code rather than on a debug version. Metadata embedded by the Cilk++ compiler in the binary executable identifies the parallel control constructs in the executing application. This approach introduces little or no overhead to the program binary in normal runs. Cilkview can perform real-time scalability benchmarking auto-matically, producing gnuplot-compatible output that allows devel-opers to compare an application’s performance with the tool’s pre-dictions. If the program performs beneath the range of expectation, the programmer can be confident in seeking a cause such as insuf-ficient memory bandwidth, false sharing, or contention, rather than inadequate parallelism or insufficient grain size...|$|R
40|$|A {{soil and}} water {{conservation}} (SWC) project has been going on in southern Mali since 1986. Donor support was gradually withdrawn between 1998 and 2002, but no final evaluation was undertaken to learn lessons from this long-term and large-scale experience. The objective of this present research was {{to find out how to}} evaluate impact, what the impact in Mali has been, and which recommendations could be made for monitoring and evaluation in SWC projects. A reconstructed logical framework made it possible to find out what was needed for the impact evaluation, what was available from project monitoring and external monitoring, and what additional data and analyses were required. Missing baseline data were substituted by reconstructed baselines and virtual time series. Between 1988 and 2002, agriculture has expanded and intensified, but crop yields have declined and nutrient balances are still negative. Further intensification is needed to halt and reverse the yield decline. The cause-effect chain between project activities and impact showed that the SWC extension approach was effectively increasing farmer adoption of SWC measures. Farmer adoption steadily increased, spread to neighbouring villages and continued after project withdrawal. Erosion control measures (live fences, stone rows, grass strips and check dams) reduced erosion by 50 – 70 % and improved crop yields by 5 – 12 %. Current annual farmer benefits of increased cotton production largely outweigh the annual SWC extension costs during the project. SWC projects are recommended to complete the <b>logical</b> framework and <b>monitor</b> accordingly, and to collaborate with external monitoring for a more efficient evaluation of impact. Achieving impact may take longer than the project life span. Therefore, project activities should be embedded in a long-term national programme. It also implies that to assess impact after a short project period requires proxy impact indicators that reflect a continuing change, rather than an end-status...|$|R
40|$|Background: Given {{the strong}} {{relationship}} between sexually trans-mitted diseases (STDs) {{and the spread of}} HIV infection, recent outbreaks of syphilis in the United States could lead to increased rates of new HIV infection. STD clinics serving persons at risk for syphilis would be <b>logical</b> sites to <b>monitor</b> rates of acute HIV infection. The detection of acute HIV infection, however, is not routine and requires the use of HIV RNA testing in combination with HIV antibody testing. Methods: To determine the rate of acute HIV infection, we per-formed HIV RNA testing on pooled HIV antibody-negative speci-mens from persons seeking care at San Francisco City Clinic (SFCC) and from men seeking care at 3 STD clinics in Los Angeles. We compared prevalence of acute HIV infection among those groups. Results: From October 2003 to July 2004, we tested 3075 specimens from persons at the SFCC, of which 105 (3 %) were HIVantibody-positive and 11 were HIV RNA-positive/HIVantibody-negative, resulting in a prevalence of acute HIV infection of 36 per 10, 000 (95 % confidence interval [CI]: 26 to 50 per 10, 000) and increasing by 10. 5 % the diagnostic yield of HIV RNA testing compared with standard testing. From February 2004 to April 2004, 1712 specimens were tested from men at 3 Los Angeles STD clinics, of which 14 (0. 82 %) were HIV-positive by enzyme immunoassay testing and 1 was HIV RNA-positive/HIV antibody-negative, re-sulting in a prevalence of 6 per 10, 000 (95 % CI: 3 to 13 per 10, 000) and increasing the diagnostic yield for HIV infection by 7. 1 %. Conclusions: In our study, the addition of HIV RNA screening to routine HIV antibody testing in STD clinics identified a substantial increased proportion of HIV-infected persons at high risk for further HIV transmission, who would have been missed by routine HIV counseling and testing protocols. Further evaluation of the addition of HIV RNA screening to routine HIV antibody testing is warranted. Key Words: sexually transmitted disease, acute HIV infection, ribonucleic acid, syphilis, HIV detectio...|$|R

