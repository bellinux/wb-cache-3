2|3890|Public
40|$|Let ^d be the d-fold direct {{product of}} the set of primes. We prove that if A is a subset of ^d of {{positive}} relative upper density then A contains infinitely many "corners", that is sets of the form {x,x+te_ 1, [...] .,x+te_d} where x is an integer point and e_ 1, [...] .,e_d are the standard basis vectors of the d-dimensional Euclidean space. Our argument is based on proving a removal lemma for weighted uniform hypergraphs, where the weight system is {{defined in terms of}} a pairwise <b>linearly</b> <b>independent</b> <b>family</b> of linear forms...|$|E
40|$|Let M be a loopless matroid on {{a finite}} {{non-empty}} set I which is representable over a finite field F. Let A be {{a representation of}} M over F, i. e. A is a family (Ai, i ∈ I) indexed by I of vectors of Fn (for some n ⩾ 1) such that J⊆I is an independent set of M iff (Ai, i ∈ J) is a <b>linearly</b> <b>independent</b> <b>family</b> of vectors of Fn. The critical number of A, c (A), is the smallest integer k ⩾ 1 such that there exist k linear functionals fj : Fn → F (j ∈ { 1, [...] ., k}) with the following property: ∀i ∈ I, ∃j ∈ { 1, [...] ., k} such that fj (Ai) ≠ 0. It is known that all representations of M over F have the same critical number: by definition this number is the critical number of M over F and is denoted by cF(M). The critical problem (determine cF(M) for a given finite field F and for a given class of matroids M representable over F) contains as special cases {{some of the most}} fascinating problems in graph theory. We present here, for any k ⩾ 2 and finite field F, a simple constructive characterization of matroids M representable over F with cF(M) ⩾ k. Our result is quite similar to the Theorem of Hajós which gives a constructive characterization of simple graphs with chromatic number at least q(∀q⩾ 3) ...|$|E
40|$|Abstract. We give an {{explicit}} construction of <b>linearly</b> <b>independent</b> <b>families</b> of knots arbitrarily {{deep in the}} (n) -solvable filtration of the knot concordance group using the ρ 1 -invariant defined in [12]. A dif-ference between previous constructions of infinite rank subgroups in the concordance group and ours is that the deepest infecting knots in the construction we present are allowed to have vanishing Tristram-Levine signatures. 1...|$|R
40|$|We give an {{explicit}} construction of <b>linearly</b> <b>independent</b> <b>families</b> of knots arbitrarily {{deep in the}} (n) -solvable filtration of the knot concordance group using the ρ^ 1 -invariant. A difference between previous constructions of infinite rank subgroups in the concordance group and ours is that the deepest infecting knots in the construction we present are allowed to have vanishing Tristram-Levine signatures. Comment: 28 pages, 2 figures version 2 : Corrected some citation and typographical error...|$|R
40|$|New {{families}} of matroids are constructed in this note. These new fami- lies {{are derived from}} the concept of <b>linearly</b> <b>independent</b> set <b>family</b> (LISF) introduced by Eicker and Ewald [Linear Algebra and its Applications 388 (2004) 173 - 191]. The proposed construction generalizes in a natural way the well known class of vectorial matroids over a field...|$|R
40|$|Abstract — The paper {{proposes a}} dynamic {{programming}} al-gorithm for training of functional networks. The algorithm considers each node as a state. The problem is formulated as finding {{the sequence of}} states which minimizes {{the sum of the}} squared errors approximation. Each node is optimized with regard to its corresponding neural functions and its estimated neuron functions. The dynamic programming algorithm tries to find the best path from the final layer nodes to the input layer which minimizes an optimization criterion. Finally, in the pruning stage, the unused nodes are deleted. The output layer can be taken as a summation node using some <b>linearly</b> <b>independent</b> <b>families,</b> such as, polynomial, exponential, Fourier, [...] . etc. The algorithm is demonstrated by two examples and compared with other common algorithms in both computer science and statistics communities...|$|R
50|$|If we {{consider}} n = 2 and v1 = v2 = (1, 0), {{the set of}} them consists of only one element and is <b>linearly</b> <b>independent,</b> but the <b>family</b> contains the same element twice and is linearly dependent.|$|R
40|$|Let A = (A 1, [...] ., Am) be an m-tuple of n &times; n Hermitian matrices. For 1 k n, the kth joint {{numerical}} range of A {{is defined by}} W k (A) = f(tr (X A 1 X), [...] ., tr (X AmX)) : X 2 C n&times;k; X X = I k g: We consider <b>linearly</b> <b>independent</b> <b>families</b> of Hermitian matrices fA 1, [...] ., Amg so that W k (A) is convex. It is shown that m can reach the upper bound 2 k(n - k) + 1. A key idea in our study is relating the convexity of W k (A) {{to the problem of}} constructing rank k orthogonal projections under linear constraints determined by A. The techniques are extended to study the convexity of other generalized {{numerical range}}s and the corresponding matrix construction problems...|$|R
50|$|A set X of {{elements}} of V is <b>linearly</b> <b>independent</b> if the corresponding <b>family</b> {x}x∈X is <b>linearly</b> <b>independent.</b> Equivalently, a <b>family</b> is dependent if a member {{is in the}} linear span {{of the rest of}} the family, i.e., a member is a linear combination {{of the rest of the}} family. The trivial case of the empty family must be regarded as <b>linearly</b> <b>independent</b> for theorems to apply.|$|R
40|$|Dedicated to Professor Yik-Hoi Au-Yeung on the {{occasion}} of his retirement. Let A = (A 1, [...] ., Am) be an m-tuple of n × n Hermitian matrices. For 1 ≤ k ≤ n, the kth joint numerical range of A is defined by Wk(A) = {(tr (X ∗ A 1 X), [...] ., tr (X ∗ AmX)) : X ∈ C n×k, X ∗ X = Ik}. We consider <b>linearly</b> <b>independent</b> <b>families</b> of Hermitian matrices {A 1, [...] ., Am} so that Wk(A) is convex. It is shown that m can reach the upper bound 2 k(n − k) + 1. A key idea in our study is relating the convexity of Wk(A) to the problem of constructing rank k orthogonal projections under linear constraints determined by A. The techniques are extended to study the convexity of other generalized numerical ranges and the corresponding matrix construction problems. ...|$|R
40|$|AbstractAn {{apparently}} {{new definition}} of <b>linearly</b> <b>independent</b> set <b>families</b> in a linear space Rk is given (for short `independent set families') and a relation of such families to families of separating hyperplanes is established. <b>Independent</b> set <b>families</b> are families of k subsets of the Rk {{defined by the}} property that any k points Pi, one from each subset, are <b>linearly</b> <b>independent.</b> The concept {{is not related to}} that of independent subsets of a finite basic set used in matroid theory. A typical example of an <b>independent</b> set <b>family</b> arising from a statistical application consists of congruent narrow cones around the unit vectors ui of the Rk which are open and convex. The statistical application referred to is robust multilinear regression...|$|R
40|$|The {{instability}} of rectangular jets is investigated using a vortex sheet model. It is shown that such jets support four <b>linearly</b> <b>independent</b> <b>families</b> of instability waves. Within each family there are infinitely many modes. A way to classify these modes {{according to the}} characteristics of their mode shapes or eigenfunctions is proposed. A parametric study of the instability wave characteristics has been carried out. A sample of the numerical results is reported here. It is found that {{the first and third}} modes of each instability wave family are corner modes. The pressure fluctuations associated with these instability waves are localized near the corners of the jet. The second mode, however, is a center mode with maximum fluctuations concentrated in the central portion of the jet flow. The center mode has the largest spatial growth rate. It is anticipated that as the instability waves propagate downstream the center mode would emerge as the dominant {{instability of}} the jet...|$|R
5000|$|As in the {{previous}} example {{it is important that}} the rows of A are <b>linearly</b> <b>independent</b> as a <b>family,</b> not as a set. For Example, consider the matrixThe set of rows only consists of a single element (1, 1) and is <b>linearly</b> <b>independent,</b> but the matrix is not invertible. The family of rows contains two elements and is linearly dependent. The statement is therefore correct if it refers to the family of rows, but wrong if it refers to the set of rows. (The statement is also correct when [...] "the rows" [...] is interpreted as referring to a multiset, in which the elements are also kept distinct but which lacks some of the structure of an indexed family.) ...|$|R
5000|$|B is a maximal set of <b>linearly</b> <b>independent</b> vectors, i.e., it is a <b>linearly</b> <b>independent</b> set but {{no other}} <b>linearly</b> <b>independent</b> set {{contains}} it as a proper subset.|$|R
5000|$|Every n × n matrix [...] {{possesses}} n <b>linearly</b> <b>independent</b> generalized eigenvectors. Generalized eigenvectors {{corresponding to}} distinct eigenvalues are <b>linearly</b> <b>independent.</b> If [...] is an eigenvalue of [...] of algebraic multiplicity , then [...] will have [...] <b>linearly</b> <b>independent</b> generalized eigenvectors corresponding to [...]|$|R
3000|$|The vectors a_ 1,...,a_m are <b>linearly</b> <b>independent</b> if {{and only}} if the vectors c_ 1,...,c_m are <b>linearly</b> <b>independent.</b>|$|R
2500|$|Every n × n matrix [...] {{possesses}} n <b>linearly</b> <b>independent</b> generalized eigenvectors. [...] Generalized eigenvectors {{corresponding to}} distinct eigenvalues are <b>linearly</b> <b>independent.</b> [...] If [...] is an eigenvalue of [...] of algebraic multiplicity , then [...] will have [...] <b>linearly</b> <b>independent</b> generalized eigenvectors corresponding to [...]|$|R
5000|$|... has all columns <b>linearly</b> <b>independent</b> (full column rank) and [...] has all rows <b>linearly</b> <b>independent</b> (full row rank) or, ...|$|R
40|$|<b>Linearly</b> <b>independent</b> {{transforms}} in Galois Field (3) algebra {{have been}} investigated recently. This paper discusses six ternary <b>linearly</b> <b>independent</b> transforms, their various properties and relations. Some experimental results for <b>linearly</b> <b>independent</b> transforms over GF(3) using ternary benchmark functions and their comparison with ternary Reed-Muller transform is also conducted. 1...|$|R
3000|$|... are <b>linearly</b> <b>independent,</b> {{each of the}} summands in (42) has rank L. Thus, it is {{possible}} to find L <b>linearly</b> <b>independent</b> vectors [...]...|$|R
40|$|The {{aim of this}} {{contribution}} is to discuss the charac-terizations of L-semilinear spaces which are gener-ated by strong <b>linearly</b> <b>independent</b> vectors. First, we show that the basis in L-semilinear spaces which are generated by strong <b>linearly</b> <b>independent</b> vectors is also strong <b>linearly</b> <b>independent.</b> Then we prove that the analogue of the Kronecker-Capelli theorem is valid for systems of equations...|$|R
5000|$|The {{dimension}} of a vector space is the maximum {{size of a}} <b>linearly</b> <b>independent</b> subset. In a vector space consisting of a single point (which must be the zero vector 0), there is no <b>linearly</b> <b>independent</b> subset. The zero vector is not itself <b>linearly</b> <b>independent,</b> {{because there is a}} non trivial linear combination making it zero: [...]|$|R
50|$|The {{condition}} on <b>linearly</b> <b>independent</b> translations {{means that}} there exist <b>linearly</b> <b>independent</b> vectors v and w (in R2) such that the group contains both Tv and Tw.|$|R
5000|$|... where ω = b/2m. From this <b>linearly</b> <b>independent</b> pair of {{solutions}} {{can be constructed}} another <b>linearly</b> <b>independent</b> pair which thus serve {{as a basis for}} the two-dimensional solution space: ...|$|R
30|$|Given m <b>linearly</b> <b>independent</b> vectors z_ 1,z_ 2,...,z_m in R^n, if we {{structure}} an m-parallellotope [z_ 1,z_ 2,...,z_m] by them as edge vectors, then [z_ 1,z_ 2,...,z_m] has m <b>linearly</b> <b>independent</b> altitude vectors. Conversely, for {{any given}} m <b>linearly</b> <b>independent</b> vectors z_ 1,z_ 2,...,z_m, can we structure an m-parallellotope by them as m altitude vectors? The following lemma gives an affirmative answer.|$|R
3000|$|... (s, α), v(α) > for the {{equation}} ρφ(s) - Uφ(s) = 0, <b>linearly</b> <b>independent</b> solutions {{corresponding to the}} <b>linearly</b> <b>independent</b> solutions of Equation (40). Likewisely, a solution of {{the equation}} [...]...|$|R
5000|$|A {{defective}} matrix {{always has}} fewer than n distinct eigenvalues, since distinct eigenvalues always have <b>linearly</b> <b>independent</b> eigenvectors. In particular, a defective matrix has {{one or more}} eigenvalues λ with algebraic multiplicity m > 1 (that is, they are multiple roots of the characteristic polynomial), but fewer than m <b>linearly</b> <b>independent</b> eigenvectors associated with λ. If the algebraic multiplicity of λ exceeds its geometric multiplicity (that is, the number of <b>linearly</b> <b>independent</b> eigenvectors associated with λ), then λ {{is said to be}} a defective eigenvalue. [...] However, every eigenvalue with algebraic multiplicity m always has m <b>linearly</b> <b>independent</b> generalized eigenvectors.|$|R
25|$|This {{means that}} the two {{solutions}} are no longer <b>linearly</b> <b>independent.</b> In this case, the second <b>linearly</b> <b>independent</b> solution is then {{found to be the}} Bessel function of the second kind, as discussed below.|$|R
3000|$|... if {{equation}} (1.1) has {{exactly one}} <b>linearly</b> <b>independent</b> solution satisfying (3.10) {{and this is}} the only <b>linearly</b> <b>independent</b> solution of equation (1.1) in L^ 2 _w(ρ(0),+∞), then equation (1.1) is called case I; [...]...|$|R
3000|$|... will {{correspond}} to {{a solution of}} Equation (37) which coincides with (41), <b>linearly</b> <b>independent</b> solutions corresponding to <b>linearly</b> <b>independent</b> solutions. It follows from here that the equations ρφ(s) - Uφ(s) = 0 and [...]...|$|R
50|$|This {{means that}} the two {{solutions}} are no longer <b>linearly</b> <b>independent.</b> In this case, the second <b>linearly</b> <b>independent</b> solution is then {{found to be the}} Bessel function of the second kind, as discussed below.|$|R
2500|$|A set X of {{elements}} of V is <b>linearly</b> <b>independent</b> if the corresponding <b>family</b> {x}x∈X is <b>linearly</b> <b>independent.</b> [...] Equivalently, {{a family is}} dependent if a member is in the linear span {{of the rest of}} the family, i.e., a member is a linear combination {{of the rest of the}} family. [...] The trivial case of the empty family must be regarded as <b>linearly</b> <b>independent</b> for theorems to apply.|$|R
3000|$|... are <b>linearly</b> <b>independent,</b> {{then all}} the column vectors of A ⊗ B are <b>linearly</b> <b>independent,</b> and the matrix rank of A ⊗ B is nq = Rank (A ⊗ B) = Rank A × Rank B.|$|R
50|$|Also {{note that}} if {{altitude}} is not ignored, it becomes necessary {{to add a}} third vector to the <b>linearly</b> <b>independent</b> set. In general, n <b>linearly</b> <b>independent</b> vectors are required to describe any location in n-dimensional space.|$|R
3000|$|For integer order p, {{functions}} J_p and J_ - p are not <b>linearly</b> <b>independent,</b> J_ - p = ([...] [...] - 1 [...])^p J_p. In contrast, for non-integer orders, J_p and J_ - p are <b>linearly</b> <b>independent.</b>|$|R
50|$|The {{heat flux}} vector and viscous shear tensor are {{transverse}} {{to the world}} lines, in the sense thatThis means that they are effectively three-dimensional quantities, and since the viscous stress tensor is symmetric and traceless, they have respectively 3 and 5 <b>linearly</b> <b>independent</b> components. Together with the density and pressure, this makes a total of 10 <b>linearly</b> <b>independent</b> components, which {{is the number of}} <b>linearly</b> <b>independent</b> components in a four-dimensional symmetric rank two tensor.|$|R
