44|1813|Public
50|$|The {{standard}} {{nature of}} Digital Taylorism {{provides for a}} certain level of precision. Since everyone is operating in a predetermined way, it increases predictability and consistency while <b>limiting</b> <b>error.</b> Through the use of different technologies, Digital Taylorism also allows management to more precisely monitor their subordinates to ensure maximum productivity. While such standardization may increase precision, this type of inflexibility tends to inhibit creativity and growth within organizations.|$|E
40|$|URL] optimal {{algorithm}} for {{estimation of}} the brightness temperature of intrinsic thermal radio radiation of objects having different physical nature in additive noise microwave radiometer has been synthesized. A functional block diagram implementing this algorithm was developed. The <b>limiting</b> <b>error</b> of estimating the desired parameter was calculated, and the potential fluctuation sensitivity of the proposed radiometer was investigated. ???????????? ??????????? ???????? ?????? ????????? ??????????? ???????????? ?????????????? ????????? ???????? ?????? ?????????? ??????? ? ?????????-??????? ??? ??????????. ??????????? ??????????? ?????, ??????????? ?????????? ????????. ?????????? ?????????? ??????????? ?????? ???????? ?????????. ??????????? ????????????? ?????????????? ???????????????? ????????????? ??????????...|$|E
40|$|This {{thesis is}} based on four papers on high-dimensional {{discriminant}} analysis. Throughout, the curse-of-dimensionality effect on the precision of the discrimination performance is emphasized. A growing dimension asymptotic approach is used for assessing this effect and the <b>limiting</b> <b>error</b> probability are taken as the performance criteria. A combined effect of a high dimensionality and feature informativeness on the discrimination performance is evaluated...|$|E
40|$|Gravity {{gradient}} instrument (GGI) is {{the core}} of the gravity gradiometer, so the structural error of the sensor has a great impact on the measurement results. In order not to affect the aimed measurement accuracy, <b>limit</b> <b>error</b> is required in the installation of the accelerometer. In this paper, based on the established measuring principle model, the radial installation <b>limit</b> <b>error</b> is calibrated, which is taken as an example to provide a method to calculate the other <b>limit</b> <b>error</b> of the installation under the premise of ensuring the accuracy of the measurement result. This method provides the idea for deriving the <b>limit</b> <b>error</b> of the geometry structure of the sensor, laying the foundation for the mechanical precision design and physical design...|$|R
40|$| sample stipulated (10 % <b>limit</b> <b>error</b> and 95 % of|$|R
5000|$|... #Subtitle level 2: Western Digital Time <b>Limit</b> <b>Error</b> Recovery Utility ...|$|R
40|$|Abstract: In this paper, {{the subject}} is the {{robustness}} and noise rejection properties of an inverse type iterative learning control algorithm. As a new result it is shown that by adapting the learning gain {{as a function of}} trial number it is possible to produce a more accurate <b>limiting</b> <b>error</b> even when the plant is subject to measurement noise. This result is experimentally verified on an industrial-scale gantry robot system...|$|E
40|$|The {{signals from}} the Cassini {{spacecraft}} that {{will be affected by}} delay fluctuations in the Earth's atmosphere. These fluctuations are dominated by water vapor in the troposphere, {{and in the case of}} Gravitaional Wave Experiment (GWE), they are likely to be a <b>limiting</b> <b>error</b> source. A passive remote sensing system, centered around a water vapor radiometer (WVR), has been developed to provide calibrations of water vapor fluctuations during radio science experiments...|$|E
40|$|Electrical {{path delay}} caused by {{atmospheric}} water vapor {{may be a}} <b>limiting</b> <b>error</b> source for geodetic measurements made with VLBI. Direct measurement of atmospheric water vapor is necessary to obtain path delay correction required by the ORION project. A dual channel water vapor radiometer is described which operates at frequencies near the 22 GHz water vapor line and is capable of collecting data that permits calculation of path delay within 2 cm accuracy...|$|E
5000|$|<b>Limited</b> <b>error</b> handling. Non-runtime {{errors are}} handled by {{terminating}} the application or resetting the device.|$|R
25|$|Slew rate <b>limit</b> <b>error,</b> {{caused by}} the {{inability}} of the ADC input value to change sufficiently rapidly.|$|R
40|$|A new {{decoding}} algorithm {{for some}} convolutional codes constructed from block codes is given. The algorithm utilizes the decoding algorithm for the corresponding block code. It is {{shown that the}} codes obtained from one-step orthogonalizable block codes are majority decodable. Error propagation {{in some of these}} convolutional codes is studied. It is shown that if decoded with moderately reduced capability, these codes exhibit <b>limited</b> <b>error</b> propagation. A mode switching decoding method is suggested to realize a larger error correction capability while maintaining <b>limited</b> <b>error</b> propagation...|$|R
40|$|To {{introduce}} to {{the students}} the operation of various electronic Instruments which are {{used to measure the}} electronic parameters. Course Outcomes: Students would be able to: 1. understand operation of different instruments. 2. describe different terminology related to measurements. 3. understand the principles of various types of transducers and sensors. UNIT-I: Electro Mechanical instruments and their characteristics: Static characteristics, Dynamic Characterist ics. Errors: Gross error, systematic error, Random error, <b>limiting</b> <b>error,</b> Probable error...|$|E
40|$|We {{present a}} new model for LT codes which {{simplifies}} {{the analysis of the}} error probability of decoding by belief propagation. For any given degree distribution, we provide the first rigorous expression for the <b>limiting</b> <b>error</b> probability as the length of the code goes to infinity via recent results in random hypergraphs [2]. For a code of finite length, we provide an algorithm for computing the probability of error of the decoder. This algorithm improves the one of Karp, Luby, and Shokrollahi [5] by a linear factor. ...|$|E
40|$|The article {{describes}} {{the present state of}} the Fluency pronunciation trainer and deals with issues concerning the role of the user that have come up when choices had to be made about the system s interface. We first refer to several CALL systems in order to examine user and system initiative in controlling the course of events in a session. In light of this, we then present new additions to Fluency: choosing speakers, using a rejection threshold, <b>limiting</b> <b>error</b> correction, giving listening information, and finally, creating an authoring kit...|$|E
50|$|In most {{indicating}} instruments, {{the accuracy}} {{is guaranteed to}} {{a certain percentage of}} full-scale reading. The limits of these deviations from the specified values are known as <b>limiting</b> <b>errors</b> or guarantee errors.|$|R
40|$|When {{the total}} {{measurement}} <b>limit</b> <b>error</b> goes beyond 20 % of the prescribed tolerance for the parameter {{to be checked}} here is the risk accepting some parts which reality are waste {{and there is the}} risk of rejecting some other parts which in fact are good. These risks, take place with a certain probability, according to the ration between the measurement <b>limit</b> <b>error</b> and the tolerance prescribed for the parameter to be checked. This paper make an deep analyze related to the dependence of the control uncertainty degree on the asymmetry αd of the 6 σ-errors' distribution compared to tolerance...|$|R
40|$|Decision {{trees are}} a well known {{technique}} in machine learning for describing the underlying {{structure of a}} dataset. In [Bot and Langdon, 2000] a new representation of decision trees using strong typing in GP was introduced. In the function nodes, a linear combination of variables is made. The effects of techniques such as <b>limited</b> <b>error</b> fitness, fitness sharing Pareto scoring and domination Pareto scoring are evaluated {{on a set of}} benchmark classification problems. Comparisons with current state-of-the-art algorithms in machine learning are presented and areas of future research are identified. Results indicate that GP can be applied successfully to classification problems. <b>Limited</b> <b>error</b> fitness reduces runtime while maintaing equal accuracy. Pareto scoring works well against bloat. Fitness sharing Pareto works better than domination Pareto...|$|R
40|$|We have {{measured}} {{a contrast}} of 6. 5 {center_dot} 10 {sup - 8 } from 10 - 25 {lambda}/D {{in visible light}} on the Extreme Adaptive Optics testbed using a shaped pupil for diffraction suppression. The testbed was designed with a minimal number of high-quality optics to ensure low wavefront error and uses a phase shifting diffraction interferometer for metrology. This level of contrast is within the regime needed for imaging young Jupiter-like planets, a primary application of high-contrast imaging. We have concluded that wavefront error, not pupil quality, is the <b>limiting</b> <b>error</b> source for improved contrast in our system...|$|E
40|$|The {{fluorescence}} decay of the excited state of most biopolymers, and biopolymer conjugates and complexes, is not, in general, a simple exponential. The {{method of moments}} is used to establish a means of analyzing such multi-exponential decays. The method is tested {{by the use of}} computer simulated data, assuming that the <b>limiting</b> <b>error</b> is determined by noise generated by a pseudorandom number generator. Multi-exponential systems with relatively closely spaced decay constants may be successfully analyzed. The analyses show the requirements, in terms of precision, that data must meet. The results may be used both as an aid in the design of equipment and in the analysis of data subsequently obtained...|$|E
40|$|Accurate {{methods to}} predict the naturalization of {{non-native}} woody plants are key components of risk-management programs being considered by nursery and landscape professionals. The objective {{of this study was}} to evaluate four decision-tree models to predict naturalization (ﬁ rst tested in Iowa) on two new sets of data for non-native woody plants cultivated in the Chicago region. We identiﬁ ed life-history traits and native ranges for 193 species (52 known to naturalize and 141 not known to naturalize) in two study areas within the Chicago region. We used these datasets to test four models (one continental-scale and three regional-scale) as a form of external validation. Application of the continental-scale model resulted in classiﬁ cation rates of 72 – 76 %, horticulturally limiting (false positive) error rates of 20 – 24 %, and biologically signiﬁ cant (false negative) error rates of 5 – 6 %. Two regional modiﬁ cations to the continental model gave increased classiﬁ cation rates (85 – 93 %) and generally lower horticulturally <b>limiting</b> <b>error</b> rates (16 – 22 %), but similar biologically signiﬁ cant error rates (5 – 8 %). A simpler method, the CART model developed from the Iowa data, resulted in lower classiﬁ cation rates (70 – 72 %) and higher biologically signiﬁ cant error rates (8 – 10 %), but, to its credit, it also had much lower horticulturally <b>limiting</b> <b>error</b> rates (5 – 10 %). A combination of models to capture both high classiﬁ cation rates and low error rates will likely be the most effective until improved protocols based on multiple regional datasets can be developed and validated...|$|E
50|$|Jaguar CD games {{can include}} {{as much as}} 790MB of data, {{considerably}} more than conventional CD-ROMs. The designers chose to ignore established CD-ROM formats and instead created their own based on the audio CD format. While allowing for dramatically more storage on the disc and foiling casual piracy, the format only provides <b>limited</b> <b>error</b> correction.|$|R
5000|$|... cdparanoia is {{developed}} by Xiph.org, {{the same team}} behind Vorbis and Theora, who provide public Subversion read-only access. The project began {{as a set of}} patches to cdda2wav, called Paranoia I and II that provided <b>limited</b> <b>error</b> correction and supported few drives. Paranoia III, (January 1998), was a standalone library for BeOS and Linux.|$|R
5000|$|... #Caption: Bilingual city <b>limit</b> with <b>error</b> (only one L in German name) ...|$|R
40|$|Horizontal {{variations}} in the atmospheric refractivity are a <b>limiting</b> <b>error</b> source for many precise laser and radio space geodetic techniques. This experiment was designed to directly measure horizontal {{variations in}} atmospheric refractivity, for the first time, by using 2 color laser ranging measurements to an aircraft. The 2 color laser system at the Goddard Optical Research Facility (GORF) ranged to a cooperative laser target package on a T- 39 aircraft. Circular patterns which extended from {{the southern edge of}} the Washington D. C. Beltway to the southern edge of Baltimore, MD were flown counter clockwise around Greenbelt, MD. Successful acquisition, tracking, and ranging for 21 circular paths were achieved on three flights in August 1992, resulting in over 20, 000 two color ranging measurements...|$|E
40|$|A {{method of}} {{incorporating}} {{the effects of}} photographic emulsion grain noise into digital image centering algorithms is presented which improves {{the accuracy of the}} derived stellar positions and magnitudes. Theoretical formulae are then derived for the <b>limiting</b> <b>error</b> of the center, and the photometric parameters. For IIIa-J, this error is 0. 2 - 0. 3 mu for bright unsaturated images, which agrees quite well with measurements made with the Yale PDS microdensitometer. It is expected that, with further improvements in the positional accuracy of the PDS, {{it should be possible to}} reach the emulsion grain noise limit, providing that emulsion shifts or other large scale errors do not dominate. It is also shown that, with appropriate trimming, marginal distribution image centering algorithms can yield an accuracy only slightly poorer than that obtained with two-dimensional distributions...|$|E
40|$|Water vapor as {{an error}} source in radio {{interferometry}} systems is briefly examined. At microwave frequencies, the delay imposed by tropospheric water vapor becomes a <b>limiting</b> <b>error</b> source for high accuracy geodetic systems. The mapping of tropospheric induced errors into 'solved-for' parameters depends upon baseline length and observing strategy. Simulation analysis (and experience) indicates {{that in some}} cases, errors in estimating tropospheric delay can be magnified in their effect on baseline components. The various techniques by which tropospheric water can be estimated or measured are surveyed with particular consideration to their possible use as a calibration technique in support to very long baseline interferometry experiments. The method of remote sensing using a microwave radiometer {{seems to be the}} most effective way to provide an accurate estimate of water vapor delay...|$|E
40|$|Arctic is a 4 x 4 packet routing chip being {{developed}} for the *T multiprocessor. Arctic {{can be used to}} implement a variety of staged networks and will be used to implement a fat tree network for *T. Arctic meets the requirements of *T and of a wide class of systems. This paper discusses the key features of Arctic. These include its buffering scheme which enables very high utilization of network links and its test and control system which provides <b>error</b> detection, <b>limited</b> <b>error</b> handling, and in-circuit testability. 1 Introduction Arctic is a four input four output packet router implemented on a Motorola H 4 CP gate array chip. Arctic has all the features necessary for use in a commercial multiboard multiprocessor such as *T [7, 8, 1]. It has high bandwidth (200 MBytes/sec/port), two priority levels, packet sizes up to 96 bytes, and extensive error detection; it has <b>limited</b> <b>error</b> handling, keeps statistics, can directly drive long PC traces, and provides significant testing suppor [...] ...|$|R
40|$|This paper {{characterizes the}} {{existence}} and form of the possible <b>limit</b> <b>error</b> signals in typical parameter-optimal iterative learning control. The set of <b>limit</b> <b>errors</b> has attracting and repelling components and the behaviour of the algorithm {{in the vicinity of}} these sets can be associated with the undesirable properties of apparent (but in fact temporary) convergence or permanent slow convergence properties in practice. The avoidance of these behaviours in practice is investigated using novel switching strategies. Deterministic strategies are analysed to prove the feasibility of the concept by proving that each of a number of such strategies is guaranteed to produce global convergence of errors to zero independent of the details of plant dynamics. For practical applications a random switching strategy is proposed to replace these approaches and shown, by example, to produce substantial potential improvements when compared with the non-switching case. The work described in this paper is covered by pending patent applications in the UK and elsewhere. <br/...|$|R
500|$|No {{model is}} ever {{perfectly}} accurate {{because it is}} impossible to learn exactly everything about the atmosphere in a timely enough manner, and atmospheric measurements that are taken are not completely accurate. [...] The use of the ensemble method of forecasting, whether it be a multi-model ensemble, or numerous ensemble members based on the global model, helps define the uncertainty and further <b>limit</b> <b>errors.</b>|$|R
40|$|Robustness to {{packet loss}} is a {{critical}} requirement for video communication over packet switched networks. Intra-coding is an important tool to mitigate the eects of packet loss by <b>limiting</b> <b>error</b> propagation. This work proposes an algorithm for optimal intra/inter coding mode selection, while utilizing the feedback channel that carries acknowledgement information about received packets. The overall distortion in frame reconstruction at the decoder due to quantization, error concealment (after packet loss) and error propagation is estimated at pixel-level precision, and is dynamically rened based on the feedback information. The estimate is then integrated into a rate-distortion (RD) framework for optimal selection of coding mode for each macroblock. Simulation results demonstrate that precise distortion estimation enables the coder to achieve substantial and consistent gains in PSNR over known state-of-the-art feedback-based mode selection methods. I...|$|E
40|$|We present new {{photometry}} of HD 149026 spanning five transits of its "super-Neptune" planet. In {{combination with}} previous data, we improve upon {{the determination of}} the planet-to-star radius ratio: R_p/R_star = 0. 0491 ^{+ 0. 0018 }_{- 0. 0005 }. We find the planetary radius to be 0. 71 +/- 0. 05 R_Jup, in accordance with previous theoretical models invoking a high metal abundance for the planet. The <b>limiting</b> <b>error</b> is the uncertainty in the stellar radius. Although we find agreement among four different ways of estimating the stellar radius, the uncertainty remains at 7 %. We also present a refined transit ephemeris and a constraint on the orbital eccentricity and argument of pericenter, e cos(omega) = - 0. 0014 +/- 0. 0012, based on the measured interval between primary and secondary transits. Comment: To appear in ApJ [19 pages...|$|E
40|$|We apply {{traditional}} bimanual {{curve modeling}} using French curves {{to the problem}} of automatic neatening of sketched strokes. Given a sketched input stroke and a set of template French curves we present an approach that fits the stroke using an optimal number of French curve segments. Our algorithm operates in both curvature and point space, reconstructing the salient curvature profiles of French curve segments, while <b>limiting</b> <b>error</b> accumulation resulting from curvature integration. User-controlled parameters allow the neatened stroke to model G 2 continuous curves, capture G 1 discontinuities, define closed curves and explore the trade-off between fitting error and the number of French curve segments used. We present an interactive sketch stroke neatening implementation to demonstrate the real-time performance of our algorithm and evaluate the quality of its results. Categories and Subject Descriptors (according to ACM CCS) : Generation—Line and curve generatio...|$|E
2500|$|Like [...] other {{narrow band}} digital modes, PSK31 can often {{overcome}} interference and poor propagation conditions {{in situations where}} voice or other methods of communication fail. However, PSK31 was designed only for leisure use by amateurs, and due to its relatively slow speed and <b>limited</b> <b>error</b> control, is not suitable for transmitting large blocks of data or text, or critical data requiring high immunity from errors.|$|R
40|$|A {{convenient}} {{method for}} creating accurate 3 D urban models without expensive survey equipment is developed by introducing digital photogrammetry. As {{a matter of}} logic, the 3 D models for urban landscape simulations are expected to <b>limit</b> <b>errors</b> to several dozen centimeters. The proposed method is examined in order to reproduce the actual urban landscape and to provide accuracy that is sufficient to meet the theoretical requirement...|$|R
40|$|Technological {{development}} and explosion of computing tools allow today to make {{best use of}} modeling methodologies {{that in the past}} were not able to perform the calculations necessary for the mathematical representation of a complex system. This paper illustrates some directions in literature about the modeling of Dynamical Systems, targeting the algorithmic search of numerical methods with an exact or <b>limited</b> <b>error</b> approximation. modeling; dynamical systems; algorithm. ...|$|R
