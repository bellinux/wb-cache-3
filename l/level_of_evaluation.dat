87|10000|Public
25|$|However any Group, Individual and/or Hospital Triage {{system can}} be used at the {{appropriate}} <b>level</b> <b>of</b> <b>evaluation.</b>|$|E
25|$|When Ronald Reagan {{was elected}} in 1982, he {{significantly}} reduced the size and cost of many portions of government, thereby greatly limiting the Civil Service Reform Act. Satisfying {{the need for new}} legislation, the Performance Management and Recognition System (PMRS) was enacted on November 8, 1984. Most notably, the PMRS provided a greater <b>level</b> <b>of</b> <b>evaluation</b> accuracy and imposed minimum and maximum levels of pay increase to limit disparity among merit pay employees. PMRS also created Performance Standard Review Boards for each department and required that {{at least half of the}} board be members who were under the merit pay system. This requirement ensured that at least some board members had a vested interest in dealing with potential problems and concerns.|$|E
50|$|However any Group, Individual and/or Hospital Triage {{system can}} be used at the {{appropriate}} <b>level</b> <b>of</b> <b>evaluation.</b>|$|E
5000|$|High <b>levels</b> <b>of</b> <b>evaluation</b> under {{relevant}} security {{criteria are}} distinctive {{features of the}} Interactive Link hardware. They have been certified under the following criteria: ...|$|R
5000|$|He {{is noted}} {{for his work}} on Context Sensitive Evaluation, an {{approach}} derived from an understanding of factors found in the research literature that are associated with high <b>levels</b> <b>of</b> <b>evaluation</b> use.|$|R
5000|$|The four <b>levels</b> <b>of</b> Kirkpatrick's <b>evaluation</b> {{model are}} as follows: ...|$|R
50|$|Several {{authors have}} {{suggested}} an {{addition of a}} fifth <b>level</b> <b>of</b> <b>evaluation.</b> JJ Phillips has argued for {{the addition of a}} Return on Investment (ROI) level, which is essentially about comparing the fourth level of the standard model to the overall costs of training. Roger Kaufman has argued that ROI is essentially a Level 4 type of evaluation because it is still internal to the organization and that a fifth <b>level</b> <b>of</b> <b>evaluation</b> should focus on the impact of the organization on external clients and society.|$|E
5000|$|The [...] "organizational influences" [...] {{level is}} the final <b>level</b> <b>of</b> <b>evaluation.</b> It {{acknowledges}} that a fire departments top management is ultimately responsible for organizational culture, and {{may have contributed to}} some degree to a firefighter's actions that led to a near-miss event.|$|E
5000|$|To {{study the}} casual {{influence}} of evaluation apprehension in experimental designs, experimenters frequently {{have to try}} to manipulate this variable. By creating differing levels of evaluation apprehension, researchers can assess its effect on, and interaction with, other variables, such as self-esteem and manifest anxiety. To heighten participants' evaluation apprehension, experimenters create situations in which participants perceive themselves as being publicly judged. For example, Kim et. al. (2010)'s tested the effect of apprehension on making positive self-evaluations. [...] Specifically, they studied the effect of evaluation apprehension between two groups: people from collectivistic cultures and people from individualistic cultures. To manipulate evaluation apprehension, they raised and lowered the <b>level</b> <b>of</b> <b>evaluation</b> apprehension depending on if participants were alone or with a group of people when they were asked to make positive self-evaluations.|$|E
50|$|Martin, R., Latour, T., Burton, R., Busana, G., & Vandenabeele, L. (2005). Covering Different <b>Levels</b> <b>of</b> <b>Evaluation</b> Needs by an Internet-Based Computer-Assisted Testing Framework for Collaborative Distributed Test Development and Delivery. Communication orale à EDMEDIA 2005 World Conference on Educational Multimedia, Hypermedia & Telecommunications, 27 June - 2 July 2005. Montréal, Canada.|$|R
40|$|The paper {{discusses}} the underlying {{issues in the}} <b>evaluation</b> <b>of</b> computer systems which apply artificial intelligence in medicine (AIM). Three different <b>levels</b> <b>of</b> <b>evaluation</b> are described: 1) the subjective <b>evaluation</b> <b>of</b> the research contribution of a developmental prototype, 2) the validation of a system's knowledge and performance, 3) the <b>evaluation</b> <b>of</b> the clinical efficacy of an operational system. The paper outlines a number <b>of</b> <b>evaluation</b> issues at each level, and discusses how previous AIM evaluations fit into this framework...|$|R
40|$|How {{to use the}} workbooks p. 7 Introduction: Establishing {{a healthy}} culture for {{evaluation}} p. 8 Why is treatment evaluation important? p. 11 What is treatment? p. 13 <b>Levels</b> <b>of</b> <b>evaluation</b> p. 14 The foundation <b>of</b> <b>evaluations</b> p. 18 Types <b>of</b> <b>evaluation</b> p. 21 Needs assessment evaluation (workbook 3) p. 22 Process evaluation (workbook 4) p. 23 Cost evaluation (workbook 5) p. 24 Client satisfaction evaluation (workbook 6) p. 25 Outcome evaluation (workbook 7) p. 26 Economic evaluation (workbook 8) p. 27 Summary and conclusion p. 3...|$|R
50|$|Although it is {{commonly}} believed that evaluation apprehension is largely detrimental, research demonstrates that evaluation apprehension can have {{both positive and negative}} effects on social interactions. Evaluation apprehension can be useful at times in spite of its tendency to create anxiety. At high levels, evaluation apprehension can inform people that the situation is important and that they should focus attention on whatever stressor is causing the heightened levels of evaluation apprehension. Research indicates that a person is less easily distracted when they have a heightened <b>level</b> <b>of</b> <b>evaluation</b> apprehension and can therefore be more easily persuaded. Eliminating such distraction creates a higher level of understanding of the presented argument. At the same time, this heightened level of attention can create anxiety. Thus, evaluation apprehension leads to an amplified level of attention that is both beneficial and detrimental.|$|E
5000|$|An {{indirect}} {{manipulation of}} evaluation apprehension is demonstrated in Leary et. al. (1987)'s study of evaluation apprehension on social-esteem and self-esteem. One's social-esteem is how one is evaluated by others, {{or at least}} how one perceives that one is being perceived by others. Until recently, scholars hypothesized that the model of social-esteem directly contrasted the model of self-esteem, one's evaluation of oneself. There is some consensus that social-esteem is influenced by evaluation apprehension given that they are both related to a person's apprehension of being evaluated by others. However, recent research shows that evaluation apprehension can also influence general self-esteem. Leary et. al. conducted an experiment in which participants {{were told that they}} would be taking a test that could threaten their ego and that either [...] "only they, only another individual, both they and the other individual, or no one would see their test score". By varying the perceived audience, the researchers indirectly manipulated evaluation apprehension. Leary et. al. thus hoped to create conditions that tested the effects of differing levels of evaluation apprehension on social-esteem and self-esteem. Before the test began, the participants were all assessed on their <b>level</b> <b>of</b> <b>evaluation</b> apprehension. The {{purpose of the study was}} then to determine how one's evaluation apprehension was affected by a threat to one's self-esteem, social-esteem, both, or neither.|$|E
5000|$|The {{greatest}} {{benefits of}} the Act were that it clarified job expectations and defined goals and objectives. The clearest shortcoming was that it failed to establish a “demonstrable relationship between pay and performance.” [...] This failure {{had a number of}} causes—most notably a lack of adequate funding. Managers who performed satisfactorily often found themselves receiving less pay than their non-managerial counterparts because the non-managerial employees were still under the previous pay system. Some complained that this merit system seemed arbitrary and many employees did not perceive it as a fair assessment of performance and effort. Furthermore, the public became upset when they saw certain senior executives in the government receiving large paychecks. It became apparent that the Act was not an effective means of civic service reform.When Ronald Reagan was elected in 1982, he significantly reduced the size and cost of many portions of government, thereby greatly limiting the Civil Service Reform Act. Satisfying the need for new legislation, the Performance Management and Recognition System (PMRS) was enacted on November 8, 1984. Most notably, the PMRS provided a greater <b>level</b> <b>of</b> <b>evaluation</b> accuracy and imposed minimum and maximum levels of pay increase to limit disparity among merit pay employees. PMRS also created Performance Standard Review Boards for each department and required that {{at least half of the}} board be members who were under the merit pay system. This requirement ensured that at least some board members had a vested interest in dealing with potential problems and concerns.|$|E
5000|$|... #Subtitle <b>level</b> 3: <b>Levels</b> <b>of</b> {{evidence}} and <b>evaluation</b> <b>of</b> research ...|$|R
5000|$|... #Subtitle <b>level</b> 4: Order <b>of</b> <b>evaluation</b> <b>of</b> {{procedure}} arguments ...|$|R
3000|$|... [...]) (i[*]=[*] 1, 2, 3, 4, 5, 6,bij∈[0, 1]) is {{the first}} <b>level</b> <b>of</b> {{comprehensive}} <b>evaluation</b> results, indicating that each U [...]...|$|R
40|$|A {{technology}} for evaluating computer-based distance education curricula {{for children and}} people working with children is described. The technology originated from a model of evaluation described by Markle (1967). The components were elaborated through data-based decisions reported in technical reports for a reading acquisition program, two math programs, a curriculum for people with autism, and a professional development program for clinicians working with children and adolescents. The article integrates single-case and group evaluation strategies, and {{draws attention to the}} need for better data in evidence-based decisions, and the use of data in continuous improvement efforts. Details concerning the individual learner at the developmental <b>level</b> <b>of</b> <b>evaluation</b> are emphasized, including an illustration of an e-learning rubric assisting this <b>level</b> <b>of</b> <b>evaluation...</b>|$|E
40|$|In {{the summer}} 2003, an {{evaluation}} of Danida's rural development programme in Eastern and Coastal Provinces of Kenya took place. This external evaluation, commissioned by Danida's independent evaluation service, was unusual not least because {{each of the five}} evaluation teams included Kenya professionals as evaluators, a rare occurrence despite the current <b>level</b> <b>of</b> <b>evaluation</b> requirements. The evaluation covered the period from 1998 to 2003...|$|E
40|$|AbstractEnvironmental {{education}} {{organizations can}} do more to institute evaluation. In {{an effort to help}} Evaluators bridge the gap between the potential for high quality evaluation systems to improve environmental education, and the low <b>level</b> <b>of</b> <b>evaluation</b> in actual practice, I reviewed recent environmental education literature to reveal the challenges and opportunities for evaluating environmental education programs. The literature review identified strategies for confronting the challenges in environmental education evaluation, as well as notable opportunities for increasing the quality of evaluation in environmental education...|$|E
5000|$|... #Subtitle <b>level</b> 3: Factors <b>of</b> <b>Evaluation,</b> Potency, and Activity ...|$|R
5000|$|... #Subtitle <b>level</b> 3: Office <b>of</b> <b>Evaluations</b> and Special Projects ...|$|R
40|$|In today’s results-oriented, {{fast-moving}} business environment, it {{is critical}} for trainers to demonstrate the value of training to the organization: There is nothing inherently valuable about training. It is performance gains that training catalyzes that give it worth (Graber, 2000). This is why evaluations tied to business results are becoming commonplace. If you ask training professionals about measuring training, most will start talking about <b>levels</b> <b>of</b> <b>evaluation,</b> referring to Kirkpatrick’s landmark evaluation model developed in 1959. Kirkpatrick’s <b>levels</b> <b>of</b> <b>evaluation</b> have been the industry standard {{for nearly half a}} century. However, many professionals now believe that elearning and a shift in emphasis toward performance improvement have changed the training business so that these levels are no longer completely relevant. The {{purpose of this paper is}} to discuss what similarities and differences exist between evaluating elearning and traditional classroom instruction, how Kirkpatrick’s evaluation levels are currently conducted, why conducting Kirkpatrick’s Level 4 evaluation is so difficult to do, why elearning evaluation has evolved to include return-on-investment (ROI) calculations, and whether other evaluation methods currently practiced are more relevant and useful...|$|R
40|$|Three {{different}} {{operating system}} strategies for a parallel processor computer system are compared, {{and the most}} effective strategy for given job loads is determined. The three strategies compare uni-programming versus multiprogramming and distributed operating systems versus dedicated processor operating systems. The <b>level</b> <b>of</b> <b>evaluation</b> includes I/O operations, resource allocation, and interprocess communication. The results apply to architectures where jobs may be scheduled to processors {{on the basis of}} processor availability, memory availability, and the availability of one other resource used by all jobs...|$|E
40|$|Environmental {{education}} {{organizations can}} do more to either institute evaluation or {{improve the quality of}} their evaluation. In an effort to help evaluators bridge the gap between the potential for high quality evaluation systems to improve environmental education, and the low <b>level</b> <b>of</b> <b>evaluation</b> in actual practice, we reviewed recent environmental education literature to reveal the challenges and opportunities for evaluating environmental education programs. The literature review identified strategies for confronting the challenges in environmental education evaluation, as well as notable opportunities for increasing the quality of evaluation in environmental education. Environmental education Literature review...|$|E
30|$|However, for Kirkpatrick levels 3 and 4 {{evaluation}} {{to be more}} relevant, {{more time}} is needed to monitor the change in behavior. For instance, any noticeable change in the activity and performance of the learners after the training, how changes in learners’ job performance are affecting business performance or financial benefits. Despite the increased <b>level</b> <b>of</b> <b>evaluation</b> difficulty when elevating to another higher level of the Kirkpatrick model, the assessment methodology was discussed with management on how the success will be measured. Early successes such as cycle time improvement, products meeting customer requirements and manufacturing scrap improvement were observed.|$|E
5000|$|... #Subtitle <b>level</b> 2: Scheme <b>of</b> <b>evaluation</b> {{in other}} {{national}} boards ...|$|R
40|$|Management has {{traditionally}} asked the questions: “How many employees attended the course?” “How did {{they like the}} course?” “What did they learn?” However, with more of a bottom line orientation, managers are beginning to ask: “Are they using what they learned?” “Are there other things {{we should look at}} to change performance?” “What business results were improved?” “What is our return on investment for the training? The answers to these new questions can be found by systematically evaluating the training we provide. But while the idea of evaluating training is nothing new, instructional designers and human performance technologists have been slow to embrace this powerful tool for measuring the impact of training. In this article readers will be presented with the distinction between Formative and Summative Evaluation, will learn about Kirkpatrick’s <b>Levels</b> <b>of</b> <b>Evaluation</b> with additional <b>levels</b> <b>of</b> <b>evaluation</b> by developed Phillips and Kaufman, be presented case studies <b>of</b> three <b>evaluations,</b> and have summarized various lessons learned about evaluation. Instructional Systems Design (ISD) has given trainers the structure needed to systematically produce and refine training. While analysis, design, development, and implementation are routinely used to create and deliver courses, <b>evaluation</b> <b>of</b> the results has been typically limited to measurement of how participants reacted to the training and whether they improved their knowledge of the subject...|$|R
5000|$|Donald Kirkpatrick, founder <b>of</b> the 'Four <b>Level</b> Model' <b>of</b> {{training}} <b>evaluation</b> ...|$|R
40|$|The User Interview Survey was {{conducted}} by the Evaluation Use Project (EUP). The goals of the survey, which were achieved, were gathering, categorizing, and analyzing information about evaluation use among elementary school decisicr, makers. Most survey respondents agreed instructicnal and curricular issues were most important. It was found that most school decision aakers did not frequently rely upon evaluations when they made decisions. Needs assessment evaluations were most helpful to school staff in identifying areas requiring attention. Evaluative data were used more frequently in curricular decisions and in those involving the bilingual program. The data did not usually enter into administrative, staff development, or personnel decisions. The <b>level</b> <b>of</b> <b>evaluation</b> utilization increased in those decisions in which administrators participated. Refinements in the observations and dat...|$|E
40|$|OBJECTIVE: To {{test the}} {{influence}} of a chronic ultra mild stress (CUMS) procedure, based solely on socio-environmental stressors, on cognitive-behavioural function in mice. DESIGN: Behavioural study. PARTICIPANTS: B 6 D 2 F 1 mice. INTERVENTIONS: Mice were exposed to various stressors and then tested using a decision-making task. RESULTS: We observed that stress facilitated "choice" behaviour, with an absence of "no choice" behaviour. Stress also facilitated a more rapid capacity to process information, a decrease in the <b>level</b> <b>of</b> <b>evaluation</b> of the choice situation and less hesitation. These stress-related consequences on decision making may be attributed to a higher level of distractability in the stressed mice. CONCLUSIONS: The CUMS model may be useful for the study of stress-related disorders by proposing a new method for assessing gene-environment interactions in cognitive-affective behaviours...|$|E
40|$|This paper {{presents}} a novel automatic method (AutoSummENG) {{for the evaluation}} of summarization systems, based on comparing the character n-gram graphs representation of the extracted summaries and a number of model summaries. The presented approach is language neutral, due to its statistical nature, and appears to hold a <b>level</b> <b>of</b> <b>evaluation</b> performance that matches and even exceeds other contemporary evaluation methods. Within this study, we measure the effectiveness of different representation methods, namely word and character n-gram graph and histogram, different n-gram neighbourhood indication methods, as well as different comparison methods between the supplied representations. A theory for the a priori determination of the methods ’ parameters, along with supporting experiments, concludes the study, to provide a complete alternative of existing methods concerning the automatic summary system evaluation process...|$|E
40|$|The {{weakness}} <b>of</b> single <b>level</b> {{additive model}} <b>of</b> <b>evaluation</b> is considered. The model is frequently used by test systems and other systems <b>of</b> <b>evaluation.</b> It {{is very simple}} but the single <b>level</b> additive model <b>of</b> <b>evaluation</b> can’t realize linear indivisible function. Multi-layer neural nets and production systems described as method for overcoming of drawback of additive model. When you are citing the document, use the following link [URL]...|$|R
40|$|As {{our country}} {{appears to be}} moving toward a green economy, why aren’t more Latino/Hispanic {{students}} interested in pursuing careers in ecology and the natural sciences? This research and professional development project was implemented as a teacher training program that will engage the interest of Latino/Hispanic elementary school students in learning about and pursuing careers in ecology and the natural sciences. Findings from qualitative data analyses and interpretation of these analyses by project researchers and Latino/Hispanic staff from the subject school served as a conceptual framework for development of the teacher professional learning intervention. The intervention will be instituted in fall semester 2010 in an elementary school and will be evaluated using Guskey’s five <b>levels</b> <b>of</b> <b>evaluation</b> <b>of</b> professional development...|$|R
40|$|Brand choice models implicitly {{assume that}} {{consumers}} incorporate all relevant marketing {{information such as}} price, display, and feature for key brands on each purchase occasion. The authors examine whether consumers actively evaluate the brands on every occasion. They propose a multistate choice model with varying <b>levels</b> <b>of</b> <b>evaluation</b> and estimate the model with scanner data. In addition, the authors study the effect of household demographics, occasion-specific factors, as well as unmeasured household and purchase occasion factors on the extent <b>of</b> <b>evaluation.</b> The results indicate that consumers do not evaluate brands on all occasions. The authors discuss the implications <b>of</b> such limited <b>evaluation.</b> Copyright 1999 by University of Chicago Press. ...|$|R
