25|0|Public
500|$|Due to {{the nature}} of flash memory's operation, data cannot be {{directly}} overwritten as it can in a hard disk drive. When data is first written to an SSD, the cells all start in an erased state so data can be written directly using pages at a time ( [...] in size). The SSD controller on the SSD, which manages the flash memory and interfaces with the host system, uses a <b>logical-to-physical</b> mapping system known as logical block addressing (LBA) and {{that is part of the}} flash translation layer (FTL). When new data comes in replacing older data already written, the SSD controller will write the new data in a new location and update the logical mapping to point to the new physical location. The data in the old location is no longer valid, and will need to be erased before the location can be written again.|$|E
50|$|Usually, Flash Memory Controller {{also include}} the Flash Translation Layer (FTL) a layer below the file system that maps host side or file system logical block {{addresses}} (LBAs) to the physical address of the Flash memory (<b>logical-to-physical</b> mapping). The LBAs refer to sector numbers and to a mapping unit of 512 bytes. All LBAs that represent the logical size visible to and managed by the file system are mapped to a physical location (block ID, page ID and sector ID) of the Flash. As part of the wear leveling and other Flash management algorithms (bad block management, read disturb management, safe flash handling etc.), the physical location of an LBA might dynamically change frequently. The mapping units of an FTL can differ so that LBAs are mapped block-, page- or even sub-page-based. Depending on the usage pattern, a finer mapping granularity can significantly reduce the flash wear out and maximize the endurance of a flash based storage media.|$|E
40|$|On-chip storage {{has become}} {{critical}} in large FPGAs. This has led most FPGA vendors to include configurable embedded arrays in their devices. Because {{of the large}} number of ways in which the arrays can be combined, and because of the configurability of each array, there are often manyways to implement the memories required by a circuit. Implementing user memories using physical arrays is called <b>logical-to-physical</b> mapping, and has previously been studied for single-port FPGA memory arrays. Most current FPGAs, however, contain dual-port arrays. In this paper, we present a <b>logical-to-physical</b> algorithm that specifically targets dual-port FPGA arrays. We show that this algorithm results in 28 # denser memory implementations than the only previously published algorithm...|$|E
40|$|The {{implementation}} of the memory for storing image and transform coefficients in 2 -D DWT processing systems using the more cost-effective external memory module such as DDR DRAM is shown to suffer from effective memory bandwidth which is {{significantly lower than the}} memory system peak bandwidth if the conventional direct <b>logical-to-physical</b> memory address mapping is adopted. The low effective memory bandwidth is caused by the high level of memory overhead cycle occurrence which is in turn is closely related to the logical memory access patterns of 2 -D DWT processes. The problem becomes even more severe for the 2 -D DWT processing of video. An analysis on the logical memory access patterns of multi-level 2 -D DWT is carried out and an enhanced <b>logical-to-physical</b> memory mapping scheme which minimizes the occurrence of memory overhead cycles is proposed. The proposed scheme is simulated and its performance in terms of effective memory access bandwidth is evaluated and compared with the conventional direct mapping scheme...|$|E
40|$|Sophisticated disk {{scheduling}} algorithms require {{accurate and}} detailed disk drive speci cations, including information on mechanical delays, on-board caching and prefetching algorithms, command processing and protocol overheads, and <b>logical-to-physical</b> block mappings. Comprehensive disk models used in storage subsystem design require similar levels of detail. This report describes {{a suite of}} general-purpose techniques and algorithms for acquiring the necessary data from SCSI disks via the ANSI-standard interface. The accuracy of the extracted information is demonstrated by comparing {{the behavior of a}} con gurable disk simulator against actual disk drive activity. Detailed measurements extracted from several SCSI disk drives are provided...|$|E
40|$|The {{flash memory}} {{management}} functions of write coalescing, space management, <b>logical-to-physical</b> mapping, wear leveling, and garbage collection require significant on-going computation and data movement. MLC flash memory also introduces new challenges: (1) Pages in a block must be written sequentially. (2) Information {{to indicate a}} page being obsolete cannot be recorded in its spare area. This paper designs an MLC Flash Translation Layer (MFTL) for flash-memory storage systems which takes new constraints of MLC flash memory and access behaviors of file system into consideration. A series of trace driven simulations is conducted to evaluate {{the performance of the}} proposed scheme. Our experiment results show that the proposed MFTL outperforms other related works {{in terms of the number}} of extra page writes, the number of total block erasures, and the memory requirement for the management...|$|E
40|$|Optimal {{utilization}} of a multi-channel memory, such as Wide IO DRAM, as shared memory in multi-processor platforms {{depends on the}} mapping of memory clients to the memory channels, the granularity at which the memory requests are interleaved in each channel, and the bandwidth and memory capacity allocated to each memory client in each channel. Firm real-time applications in such platforms impose strict requirements on shared memory bandwidth and latency, which must be guaranteed at design-time to reduce verification effort. Our key contributions are: (1) A real-time multi-channel memory controller architecture with a new programmable Multi-Channel Interleaver unit. (2) A novel method for <b>logical-to-physical</b> address translation that enables interleaving memory requests across multiple memory channels at different granularities. (3) An optimal algorithm based on an integer programming formulation to map memory clients to the memory channels...|$|E
40|$|Sophisticated disk {{scheduling}} algorithms require accurate, detailed {{disk drive}} specifications, including data about mechanical delays, on-board caching and prefetching algorithms, command and protocol overheads, and <b>logical-to-physical</b> block mappings. Comprehensive disk models used in storage subsystem design require similar levels of detail. We describe {{a suite of}} general-purpose algorithms and techniques for acquiring the necessary information from a SCSI disk drive. Using only the ANSI-standard interface, we demonstrate how the important parameter values of a modern SCSI drive can be determined accurately and efficiently. 1 Introduction The magnetic disk drive remains firmly established as the preferred component for secondary data storage. Given the growing disparity between processor and disk speeds, achieving high system performance requires that disk drives be used intelligently. Previous work has demonstrated that disk request scheduling algorithms can significantly reduce see [...] ...|$|E
40|$|Abstract — The {{flash memory}} {{management}} functions of write coalescing, space management, <b>logical-to-physical</b> mapping, wear leveling, and garbage collection require significant on-going computation and data movement. MLC flash memory also introduces new challenges: (1) Pages in a block must be written sequentially. (2) Information {{to indicate a}} page being obsolete cannot be recorded in its spare area. This paper designs an MLC Flash Translation Layer (MFTL) for flash-memory storage systems which takes new constraints of MLC flash memory and access behaviors of file system into consideration. A series of trace driven simulations is conducted to evaluate {{the performance of the}} proposed scheme. Our experiment results show that the proposed MFTL outperforms other related works {{in terms of the number}} of extra page writes, the number of total block erasures, and the memory requirement for the management. Keywords-Flash memory; MFTL; MLC; BAST; FAST. I...|$|E
40|$|Software-driven cloud {{networking}} is a {{new paradigm}} in orchestrating physical resources (CPU, network bandwidth, energy, storage) allocated to network functions, services, and applications, which is commonly modeled as a cross-layer network. This model carries a physical network representing the physical infrastructure, a logical network showing demands, and <b>logical-to-physical</b> node/link mappings. In such networks, a single failure in the physical network may trigger cascading failures in the logical network and disable network services and connectivity. In this paper, we propose an evaluation metric, survivable probability, to evaluate the reliability of such networks under random physical link failure(s). We propose the concept of base protecting spanning tree and prove the necessary and sufficient conditions for its existence and relation to survivability. We then develop mathematical programming formulations for reliable cross-layer network routing design with the maximal reliable probability. Computation results demonstrate the viability of our approach. Comment: 7 pages, 6 figure...|$|E
40|$|Arrays in {{behavioral}} specifications {{that are too}} large to fit into on-chip registers are usually mapped to off-chip memories during behavioral synthesis. We {{address the problem of}} system power reduction through transition count minimization on the memory address bus when these arrays are accessed from memory. We exploit regularity and spatial locality in the memory accesses and determine the mapping of behavioral array references to physical memory locations to minimize address bus transitions. We describe array mapping strategies for two important memory configurations: all behavioral arrays mapped to a single off-chip memory and arrays mapped into multiple memory modules drawn from a library. For the single memory configuration, we describe a heuristic for selecting a memory mapping scheme to achieve low power for each behavioral array. For mapping into a library of multiple memory modules, we formulate the problem as three <b>logical-to-physical</b> memory mapping subtasks and present expe [...] ...|$|E
40|$|Embedded memory blocks are {{important}} resources in contemporary FPGA devices. When targeting FPGAs, application designers often specify high-level memory functions which exhibit {{a range of}} sizes and control structures. These logical memories must be mapped to FPGA embedded memory resources such that physical design objectives are met. In this work a set of power-aware <b>logical-to-physical</b> RAM mapping algorithms are described which convert user-defined memory specifications to on-chip FPGA memory block resources. These algorithms minimize RAM dynamic power by evaluating a range of possible embedded memory block mappings and selecting the most power-efficient choice. Our automated approach has been integrated into a commercial FPGA compiler and tested with 40 large FPGA benchmarks. Through experimentation, we show that, on average, embedded memory dynamic power can be reduced by 21 % and overall core dynamic power can be reduced by 7 % with a minimal loss (1 %) in design performance...|$|E
40|$|Disk {{subsystem}} {{performance can}} be dramatically improved by dynamically ordering, or scheduling, pending requests. Modern disk drives have several features, such as complex <b>logical-to-physical</b> mappings and large prefetching caches, that can in uence scheduling e ectiveness. Via strongly validated simulation, {{we examine the}} impact of these features on various scheduling algorithms. Using both synthetic workloads and traces captured from six di erent user environments, we arrive at three main conclusions: (1) Incorporating complex mapping information into the scheduler provides only a marginal (less than 2 %) decrease in response times for seek-reducing algorithms. (2) Algorithms which e ectively utilize a prefetching disk cache provide signi cant performance improvements for workloads with read sequentiality. The cyclical scan algorithm (C-LOOK), which always schedules requests in ascending logical order, achieves the highest performance among seek-reducing algorithms for such workloads (ve of the six examined). (3) Algorithms that reduce overall positioning delays produce the highest performance provided that they recognize and exploit a prefetching cache...|$|E
40|$|In {{this paper}} we discuss several {{possible}} uses of the knowledge of how user's logical designs are mapped to physical FPGA circuits. Some of these uses include power analyses, useful feedback on physical design implementations, and direct, quick modifications of physical designs. As {{an example of how}} this knowledge can be used, we describe, in detail, how to determine the <b>logical-to-physical</b> mapping of Xilinx XC 4000 circuits created with JHDL and how this mapping and FPGA state sampling, or readback, enables us to provide a hardware debugging environment with complete visibility of all flip-flops and LUT RAMs in executing hardware. 1 Introduction In supporting hardware debugging in the JHDL [1, 2] design environment, we have found that knowing how design elements from the user's logical design were mapped to their counterparts in the FPGA physical implementation is quite important. With only a partial mapping from the logical to the physical, we {{would not be able to}} provide users of J [...] ...|$|E
40|$|Targeting on {{the future}} fault-prone hybrid CMOS/Nanodevice digital memories, this paper present two {{fault-tolerance}} design approaches the integrally address the tolerance for defect and transient faults. These two approaches share several key features, {{including the use of}} a group of Bose-Chaudhuri- Hocquenghem (BCH) codes for both defect tolerance and transient fault tolerance, and integration of BCH code selection and dynamic <b>logical-to-physical</b> address mapping. Thus, a new model of BCH decoder is proposed to reduce the area and simplify the computational scheduling of both syndrome and chien search blocks without parallelism leading to high throughput. The goal of fault tolerant computing is improve the dependability of systems where dependability can be defined as the ability of a system to deliver service at an acceptable level of confidence in either presence or absence falult. ss The results of the simulation and implementation using Xilinx ISE software and the LCD screen on the FPGA's Board will be shown at last...|$|E
40|$|NANDFS is a flash {{file system}} that exposes a memory-performance {{tradeoff}} to system integrators. The file {{system can be}} configured to use {{a large amount of}} RAM, in which case it delivers excellent performance. In particular, when NANDFS is configured with the same amount of RAM that YAFFS 2 uses, the performance of the two file systems is comparable (YAFFS 2 is a file system that is widely used in embedded Linux and other embedded environments). But YAFFS 2 and other state-of-the-art flash file systems allocate RAM dynamically and do not provide the system builder with a way to limit the amount of memory that they allocate. NAND-FS, on the other hand, allows the system builder to configure it to use a specific amount of RAM. The performance of NANDFS degrades when the amount of RAM it uses shrinks, but the degradation is graceful, not catastrophic. NANDFS is able to provide this flexibility thanks to a novel data structure that combines a coarsegrained <b>logical-to-physical</b> mapping with a log-structured file system...|$|E
40|$|This paper proposes STORAGEDB: a {{paradigm}} for im-plementing storage virtualation using databases. It de-scribes details for storing the <b>logical-to-physical</b> mapping information as tables within the database; handling the in-coming I/O requests {{of the application}} as database queries; bookkeeping of the I/O operations as database transac-tions. In addition, STORAGEDB uses built-in DBMS fea-tures to support storage virtualization functionalities; as an example we describe how online table space migration {{can be used to}} support reallocation of logical disks. Finally, we describe our modifications to a traditional RDBMS imple-mentation, {{in order to make it}} light-weight. Improving the performance of a traditional DBMS is critical for the ac-ceptance of STORAGEDB since the performace overheads are considered a primary challenge in replacing existing storage virtualization engines. Our current lightweight RDBMS has a 19 times shorter invocation path length than the original. In comparision to the open-source virtualiza-tion software, namely LVM, the extra cost of STORAGEDB is within 20 % of LVM in trace-driven tests. (unlike STOR-AGEDB, LVM did not have logging overhead). We consider these initial results as the “stepping stone ” in the paradigm of applying databases for storage virtualization. 1...|$|E
40|$|SSDs) {{have been}} rapidly adopted in laptops, desktops, and server storage systems because their {{performance}} {{is superior to}} that of traditional magnetic disks. However, NAND flash memory has some limitations such as out-of-place updates, bulk erase operations, and {{a limited number of}} write operations. To alleviate these unfavorable characteristics, various techniques for improving internal software and hardware components have been devised. In particular, the internal device cache of SSDs has {{a significant impact on the}} performance. The device cache is used for two main purposes: to absorb frequent read/write requests and to store <b>logical-to-physical</b> address mapping information. In the device cache, we observed that the optimal ratio of the data buffering and the address mapping space changes according to workload characteristics. To achieve optimal performance in SSDs, the device cache should be appropriately partitioned between the two main purposes. In this paper, we propose an adaptive partitioning scheme, which is based on a ghost caching mechanism, to adaptively tune the ratio of the buffering and the mapping space in the device cache according to the workload characteristics. The simulation results demonstrate that the performance of the proposed scheme approximates the best performance. I...|$|E
40|$|Optimal {{utilization}} of a multi-channel memory, such as Wide IO DRAM, as shared memory in multi-processor platforms {{depends on the}} mapping of memory clients to the memory channels, the granularity at which the memory requests are interleaved in each channel, and the bandwidth and memory capacity allocated to each memory client in each channel. Firm real-time applications in such platforms impose strict requirements on shared memory bandwidth and latency, which must be guaranteed at design-time to reduce verification effort. However, there is currently no real-time memory controller for multichannel memories, {{and there is no}} methodology to optimally configure multi-channel memories in real-time systems. This paper has four key contributions: (1) A real-time multi-channel memory controller architecture with a new programmable Multi-Channel Interleaver unit. (2) A novel method for <b>logical-to-physical</b> address translation that enables inter-leaving memory requests across multiple memory channels at different granularities. (3) An optimal algorithm based on an Integer Linear Program (ILP) formulation to map memory clients to memory channels considering their communication dependencies, and to configure the memory controller for minimum bandwidth utilization. (4) We experimentally evaluate the run-time of the algorithm and show that an optimal solution can be found within 15 minutes for realistically sized problems. We also demonstrate configuring a multi-channel Wide IO DRAM in a High-Definition (HD) video and graphics processing system to emphasize the effectiveness of our approach...|$|E
40|$|Ever {{increasing}} {{demands for}} main memory bandwidth and memory speed/power trade-off {{led to the}} in-troduction of memories with multiple memory channels, such as Wide IO DRAM. Efficient utilization of a multi-channel memory as a shared resource in multi-processor real-time systems depends on mapping of the memory clients to the memory channels according to their requirements on latency, bandwidth, commu-nication and memory capacity. However, there is currently no real-time memory controller for multi-channel memories, {{and there is no}} methodology to optimally configure multi-channel memories in real-time systems. As a first work towards this direction, we present two main contributions in this article: 1) A configurable real-time multi-channel memory controller architecture with a novel method for <b>logical-to-physical</b> address translation. 2) Two design-time methods to map memory clients to the memory channels, one an optimal algorithm based on an integer programming formulation of the mapping problem, and the other a fast heuristic algorithm. We demonstrate the real-time guarantees on bandwidth and latency provided by our multi-channel memory controller architecture by experimental evaluation. Furthermore, we compare the performance of the mapping problem formulation in a solver and the heuristic algorithm against two exist-ing mapping algorithms in terms of computation time and mapping success ratio. We show that an optimal solution can be found in 2 hours using the solver and in less than 1 second with less than 7 %mapping failur...|$|E
40|$|Abstract — Contemporary FPGA design {{requires}} {{a spectrum of}} available physical resources. As FPGA logic capacity has grown, locally-accessed FPGA embedded memory blocks have increased in importance. When targeting FPGAs, application designers often specify high-level memory functions which exhibit a range of sizes and control structures. These logical memories must be mapped to FPGA embedded memory resources such that physical design objectives are met. In this work a set of power-efficient <b>logical-to-physical</b> RAM mapping algorithms are described which convert user-defined memory specifications to on-chip FPGA memory block resources. These algorithms minimize RAM dynamic power by evaluating a range of possible embedded memory block mappings and selecting the most power-efficient choice. Our automated approach has been validated with both simulation of power dissipation and measurements of power dissipation on FPGA hardware. A comparison of measured power reductions to values determined via simulation confirms the accuracy of our simulation approach. Our power-aware RAM mapping algorithms have been integrated into a commercial FPGA compiler and tested with 34 large FPGA benchmarks. Through experimentation, we show that, on average, embedded memory dynamic power can be reduced by 26 % and overall core dynamic power can be reduced by 6 % with a minimal loss (1 %) in design performance. Additionally, it is shown that the availability of multiple embedded memory block sizes in an FPGA reduces embedded memory dynamic power by an additional 9. 6 % by giving more choices to the CAD algorithms. Index Terms — power demand, field programmable gate arrays, memory architecture, design automation I...|$|E
40|$|Abstract—The {{solid-state}} disk (SSD) {{is becoming}} increasingly popular, especially among users whose workloads exhibit substantial random access patterns. As SSD competes with the hard disk, whose per-GB cost keeps dramatically falling, the SSD must retain its performance advantages even with lowcost configurations, such as those with a small built-in DRAM cache for mapping table and using MLC NAND. To this end, {{we need to make}} the limited cache space efficiently used to support fast <b>logical-to-physical</b> address translation in the flash translation layer (FTL) with minimal access of flash memory and minimal merge operations. Existing schemes usually require a large number of overhead accesses, either for accessing uncached entries of the mapping table or for the merge operation, and achieve suboptimal performance when the cache space is limited. In this paper we take into account spatial locality exhibited in the workloads to obtain a highly efficient FTL even with a relatively small cache, named as S-FTL. Specifically, we identify three access patterns related to spatial locality, including sequential writes, clustered access, and sparse writes. Accordingly we propose designs to take advantage of these patterns to reduce mapping table size, increase hit ratio for in-cache address translation, and minimize expensive writes to flash memory. We have conducted extensive trace-driven simulations to evaluate S-FTL and compared it with other state-of-the-art FTL schemes. Our experiments show that S-FTL can reduce accesses to the flash for address translation by up to 70 % and reduce response time of SSD by up to 25 %, compared with the stateof-the-art FTL strategies such as FAST and DFTL. I...|$|E
40|$|Performance {{models for}} storage devices are an {{important}} part of simulations of large-scale computing systems. Storage devices are traditionally modeled using discrete event simulation. However, this is expensive in terms of computation, memory, and configuration. Configuration alone can take months, and the model itself requires intimate knowledge of the internal layout of the device. The difficulty in white-box model creation has led to the current situation, where there are no current, precise models. Automatically learning device behavior is a much more desirable approach, requiring less expert knowledge, fewer assumptions, and less time. Other researchers have created behavioral models of storage device performance, but none have shown low per-request errors. By making use of only a few high-level domain-specific assumptions, such as spatial periodicity and the existence of a <b>logical-to-physical</b> mapping, neural nets can learn to predict access time with low per-request errors. Providing neural nets with specific sinusoidal inputs allows them to generate periodic output, which is necessary for this problem. Weight sharing in the neural net accounts for regularities in the structure of the input, which reduces data requirements and error by reducing the number of free parameters. A trigonometric change of variables in the output of the neural net removes a discontinuity in the objective function, which makes the problem more amenable to neural nets and reduces error. Combining these approaches, we demonstrate that a neural net can predict access times with a mean absolute error of about 0. 187 ms over a small portion of a hard disk drive, and a mean absolute error of about 2. 120 ms over half of a hard disk drive...|$|E

