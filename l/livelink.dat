32|3|Public
5000|$|<b>LiveLink</b> for MATLAB - {{integrates}} with MATLAB {{to extend}} modeling with scripting programming in the MATLAB environment. <b>LiveLink</b> for MATLAB allows for {{utilization of the}} full power of MATLAB and its toolboxes in preprocessing, model manipulation, and postprocessing.|$|E
5000|$|<b>LiveLink</b> for PTC Pro/ENGINEER - {{integrate}} 3D CAD {{design with}} COMSOL simulation.|$|E
5000|$|<b>LiveLink</b> for SolidWorks - {{enhanced}} connectivity for efficient {{integration of}} simulation into design workflow.|$|E
50|$|Most chatlines offer male callers a 30 to 60 minute free trial. In {{an attempt}} to keep their lines busy, some chatlines—including <b>Livelinks,</b> RedHot and QuestChat—give female callers {{unlimited}} access to their system; similar to a nightclub which allows free entry to women in order.|$|R
40|$|Figure 1. LivePulses project {{sharp and}} {{consistent}} “zones ” around physical objects and spaces. <b>LiveLinks</b> interact with LivePulses to provide location information. In this demonstration, we present the architecture, implementation, and applications of LiveSynergy — {{a system that}} provides reliable proximity sensing and open interactive abstractions for physical spaces and objects, to enable rich interactions between humans and their environment. Categories and Subject Descriptor...|$|R
50|$|Chatlines {{are most}} {{popular in the}} United States and Canada as an {{alternative}} to online dating. Some of the most popular chatlines include QuestChat, <b>Livelinks</b> and Fonochat. Both male and female callers dial in and through a common access number. As soon as a caller is connected into the system, he is prompted to record his name and a brief greeting describing himself and what he is looking for. The phone systems will usually allow users hear a chatline greeting example so the caller can get an idea of what he is expected to say. Profanity and sexual references are typically not allowed, the chatline moderator's job is to listen and approve every greeting that is recorded. Once the greeting is recorded, the caller is allowed into the live chat area (or live connector).|$|R
5000|$|<b>LiveLink</b> for Excel - use the {{capabilities}} and structured simplicity offered by Excel to extend COMSOL modeling capacity.|$|E
5000|$|<b>LiveLink</b> for AutoCAD - {{can be used}} to {{synchronize}} CAD {{models with}} COMSOL to create model geometries for simulation.|$|E
5000|$|<b>LiveLink</b> for PTC Creo Parametric - links 3D {{designs in}} the PTC Creo Parametric CAD system to COMSOL model {{geometries}} for simulation.|$|E
5000|$|<b>LiveLink</b> for Solid Edge - {{is part of}} {{a robust}} {{platform}} that enables to integrate multiphysics simulation into 3D product design workflow.|$|E
5000|$|<b>LiveLink</b> for Inventor - {{integrate}} {{with the}} capabilities of COMSOL from within the Inventor modeling environment, and utilize its power for geometry design.|$|E
5000|$|<b>LiveLink</b> for Revit - {{provides}} an integration tool and interface for transferring geometry of elements from architectural design projects in Autodesk Revit software to COMSOL software.|$|E
50|$|To {{facilitate}} {{the operation of}} the committees, CYS has been working with ISO to provide an electronic platform - <b>Livelink,</b> where members can exchange information and manage the respective committees at minimum effort and cost.|$|E
5000|$|BRS/Search North America User's Group (BRSNAUG) website with a June 8, 2003 date {{listed the}} {{following}} features for BRS/Search. [...] The BRSNAUG also disincorporated in 2003. Cross-references to BRS/Search on the WWW point to Open Text <b>Livelink.</b>|$|E
50|$|COMSOL Multiphysics is a {{cross-platform}} {{finite element}} analysis, solver and multiphysics simulation software. It allows conventional physics-based user interfaces and coupled systems of partial differential equations (PDEs). COMSOL provides an IDE and unified workflow for electrical, mechanical, fluid, and chemical applications. An API for Java and <b>LiveLink</b> for MATLAB {{may be used}} to control the software externally, and the same API is also used via the Method Editor.|$|E
50|$|BRS/Search is a full-text {{database}} and information retrieval system. BRS/Search uses a fully inverted indexing system to store, locate, and retrieve unstructured data. It was the search engine that in 1977 powered Bibliographic Retrieval Services (BRS) commercial operations with 20 databases (including {{the first national}} commercial availability of MEDLINE); it has changed ownership several times during its development and is currently sold as <b>Livelink</b> ECM Discovery Server by Open Text Corporation.|$|E
5000|$|The [...] "back-end" [...] to {{all these}} modules were also flexible. You had direct file system {{exposure}} - that included network mounted files. However, with NOTIS-DS it included [...] "Document Storage" [...] and management - a full Electronic Document Management System (as found in systems such as Documentum and OpenTexts <b>Livelink</b> today). The EDMS {{was based on a}} generic software interface, but only SIBAS was used commercially. This allowed fully localisation transparent document storage and retrieval. That of course demanded NOTIS-IR to search in all the documents. Software today used to power both Google and Altavista.|$|E
5000|$|In 1999 {{the company}} {{arranged}} a reverse takeover {{by a company}} from Vancouver to become listed on the Toronto Stock Exchange as Centrinity. [...] In September 2002 Open Text bought Centrinity, for a reported C$1.26 per share or C$19 million. [...] Open Text was developing a suite of online collaboration products {{through a series of}} mergers, and FirstClass's educational background seemed to fit particularly well with some of their other offerings. At the time Open Text stated their intention to integrate FirstClass into the [...] "LiveLink" [...] internet information collection engine, [...] but this integration has not yet happened and is rumored to be not practical due to the architecture of <b>LiveLink.</b>|$|E
40|$|In 1999 Southern Networks {{deployed}} the Open Text <b>Livelink</b> {{knowledge management}} system (KMS). <b>Livelink</b> {{allowed for the}} centralization of key corporate applications and associated content at a global, regional, line-of-business, departmental and personal level. Prior {{to the implementation of}} <b>Livelink</b> on an enterprise scale, the corporation’s 94, 500 employees relied on fragmented departmental web pages which were scattered across eleven different Web servers making the task of finding information very difficult. This paper describes how the process of knowledge transfer at Southern Networks changed with the deployment of <b>Livelink</b> and how it enabled the automation of workflows through the company’s Web-based Intranet. The paper also provides an insight into how KMS empowered employees, at least until the organization significantly downsized in 2001. The importance of this paper is in highlighting the role of people in th...|$|E
40|$|In 1999 Nortel Networks {{deployed}} the Open Text <b>Livelink</b> {{knowledge management}} system (KMS). <b>Livelink</b> {{allowed for the}} centralization of key corporate applications and associated content at a global, regional, line-of-business and departmental level. Prior {{to the implementation of}} <b>Livelink</b> on an enterprise scale, the corporation’s 80, 000 employees relied on fragmented departmental web pages which were scattered across 11 different Web servers making the task of finding information very difficult. This paper describes how the process of knowledge transfer at Nortel Networks changed with the deployment of <b>Livelink</b> and how it enabled the automation of workflows through the company’s Web-based Intranet. The paper also provides an insight into how KMS empowered employees, acted to increase productivity and encouraged innovation. The importance of this paper is in highlighting the significant role of people in the success of KMS and to provide examples of the dynamics at play in such a large-scale operation...|$|E
40|$|A {{common problem}} in mining {{association}} rules or sequential patterns {{is that a}} large number of rules or patterns can be generated from a database, making it impossible for a human analyst to digest the results. Solutions to the problem include, among others, using interestingness measures to identify interesting rules or patterns and pruning rules that are considered redundant. Various interestingness measures have been proposed, but little work has been reported on the effectiveness of the measures on real-world applications. We present an application of Web usage mining to a large collection of <b>Livelink</b> log data. <b>Livelink</b> is a web-based product of Open Text Corporation, which provides automatic management and retrieval of different types of information objects over an intranet, an extranet or the Internet. We report our experience in preprocessing raw log data, mining association rules and sequential patterns from the log data, and identifying interesting rules and patterns by use of interestingness measures and some pruning methods. In particular, we evaluate a number of interestingness measures in terms of their effectiveness in finding interesting association rules and sequential patterns. Our results show that some measures are much more effective than others. Web log mining, interestingness measures, association rule mining, sequential pattern mining...|$|E
40|$|Mathematical Modelling has a {{long history}} in {{developmental}} biology. Advances in experimental techniques and computational algorithms now permit the development of increasingly more realistic models of organogenesis. In particular, 3 D geometries of developing organs have recently become available. In this paper, we show how to use image-based data for simulations of organogenesis in COMSOL Multiphysics. As an example, we use limb bud development, a classical model system in mouse developmental biology. We discuss how embryonic geometries with several subdomains can be read into COMSOL using the Matlab <b>LiveLink,</b> and how these can be used to simulate models on growing embryonic domains. The ALE method is used to solve signaling models even on strongly deforming domains...|$|E
40|$|AbstractThe {{scope of}} this work is to show {{optimization}} potential for regularly structured composite latent heat storage (CLHS) devices with non-uniform heat loads by varying the distribution of fins on the contact surface to an electronic component. The modeling of the CLHS is carried out in 2 D using Matlab in combination with Comsol and the effective heat capacity method for the melting process. The link between Matlab and Comsol is carried out with the Comsol–Matlab <b>LiveLink.</b> The modeled CLHS is a composite of aluminum with the phase change material (PCM) Parafol 22 - 95 (Sasol). The optimization goal was the minimization of the surface-averaged temperature at the final time tf= 2400 s on the contact surface. The optimization parameters were the positions of fins along this surface. Optimization results were compared to a CLHS with equally distributed fins and showed relative improvement of up to 3 % for a certain aluminum/PCM-ratio. The optimization was done using the genetic algorithm (GA) of Matlab on a high performance computer (HPC) at the Hamburg University of Technology (TUHH) ...|$|E
40|$|The {{problem of}} {{modeling}} and predicting a Web user’s browsing pattern has gained in-creasing attention in recent years. In this thesis, we present our methods for clustering and making recommendations to Web users {{and the application}} of these methods to a real data set generated by a Web-based knowledge management system, <b>Livelink.</b> The problem of clustering Web users and access sequences presents two unique challenges: the immense volume of data and the sequentiality of user navigation patterns. Traditional distance-based clustering algorithms are ill-suited to solve the problem. We propose to model user access sequences as stochastic processes, and a Mixture of Markov Models based approach is taken to capture the sequential relationships inherent in user access histories. Several important issues that arise in constructing the Markov models are addressed in the thesis. The first issue lies in the complexity of the mixture of Markov Models. To improve the efficiency of building/maintaining the mixture of Markov models, we develop a light-weight adaptive algorithm to update the model parameters without evoking overhaul computations. The second issue involves the proper selection of training data for building the mixture o...|$|E
40|$|Abstract: In {{order to}} gauge how {{reasonable}} a finite element {{solution to a}} partial differential equation is on a given mesh, a common strategy is to refine the mesh, compute the solution on the finer mesh, and use the solutions on the two meshes for a qualitative comparison. The theory of the finite element method (FEM) makes these comparisons quantitative by estimating the convergence order of the FEM error on a sequence of progressively finer meshes obtained by uniform mesh refinement. We show in detail how to carry out convergence studies of this type using the graphical user interface (GUI) of COMSOL 4. 0 a as well as using COMSOL’s <b>LiveLink</b> for MATLAB on the example of Lagrange elements of varying polynomial degrees. Conducting the convergence study in this manner shows how to quantify the convergence of FEM solutions and brings out the potential benefit of using higher order elements. The interconnection of COMSOL with MATLAB allows for a convenient automization of the study that is not possible {{through the use of}} the GUI alone, but is vital for reproducible studies and useful for running studies in batch mode on computing clusters. Key words: Poisson equation, a priori error estimate, convergence study, mesh refinement...|$|E
40|$|With {{more and}} more {{information}} available on the Internet, the task of making personalized recommendations to assist the user’s navigation has become increasingly important. Considering there might be millions of users with different backgrounds accessing a Web site everyday, it is infeasible to build a separate recommendation system for each user. To address this problem, clustering techniques can first be employed to discover user groups. Then, user navigation patterns for each group can be discovered, to allow the adaptation of a Web site to the interest of each individual group. In this paper, we propose to model user access sequences as stochastic processes, and a mixture of Markov models based approach is taken to cluster users and to capture the sequential relationships inherent in user access histories. Several important issues that arise in constructing the Markov models are also addressed. The first issue lies in {{the complexity of the}} mixture of Markov models. To improve the efficiency of building/maintaining the mixture of Markov models, we develop a lightweight adaptive algorithm to update the model parameters without recomputing model parameters from scratch. The second issue concerns the proper selection of training data for building the mixture of Markov models. We investigate two different training data selection strategies and perform extensive experiments to compare their effectiveness on a real dataset that is generated by a Web-based knowledge management system, <b>Livelink...</b>|$|E
40|$|The {{blades of}} an {{offshore}} wind turbine are prone to be adhered with salt fog after long-time exposure in the marine-atmosphere environment, and salt fog reduces {{the efficiency of the}} lightning protection system. In order to study the influence of salt fog on lightning striking probability (LSP), the lightning discharge process model for the wind turbine blade is adopted in this paper considering the accumulation mechanism of surface charges around the salt fog area. The distribution of potential and electric field with the development of the downward leader is calculated by COMSOL Multiphysics <b>LiveLink</b> for MATLAB. A quantitative characterization method is established to calculate the LSP base on the average electric field before the return stroke and the LSP distribution of the blade is shown {{in the form of a}} graphic view. The simulation results indicate that the receptor and conductor area close to the receptor area are more likely to get struck by lightning, and the LSP increases under the influence of salt fog. The validity of the model is verified by experiments. Furthermore, the receptor can protect the blade from lightning strikes effectively when the lateral distance between the rod electrode and receptor is short. The influence of salt fog on LSP is more obvious if salt fog is close to the receptor or if the scope of salt fog area increases...|$|E
40|$|Validation {{of models}} that predict the {{performance}} of aerospace engine materials depends {{on the ability to}} obtain accurate single crystal elastic constants. Resonance Ultrasound Spectroscopy (RUS) is a nondestructive technique in which the natural resonances of a material are utilized to obtain these constants. Traditional RUS utilizes an analytic approach to determine the resonance frequencies of a specimen given an initial guess set of elastic constants. A nonlinear optimization process then fits the elastic constants to experimentally measured data. This approach is limited both in its ability to handle specimens with complex geometry and to handle polycrystalline materials. These more complex scenarios can be approached by utilizing a finite element forward model to obtain sample resonances. A finite element forward model is being developed utilizing COMSOL Multiphysics to compute specimen resonance frequencies. Elastic constants are obtained utilizing a bounded nonlinear optimization routine in MATLAB by way of COMSOL 2 ̆ 7 s <b>LiveLink</b> for MATLAB interface. Validation of this forward model has been performed on single crystal specimens, including a nickel superalloy parallelepiped and a fused silica cylinder with a chamfer, ultimately producing lower residual error after optimization than the traditional RUS approach. Model validation is also being performed on a Nickel Aluminide (NiAl) bicrystal. This paper presents the details of this validation process. Also presented is an examination of error sources and the impact they can play in the ability to accurately obtain elastic constants...|$|E
40|$|High {{frequency}} dispersion has a {{great influence}} on the perceived performance of a loudspeaker. The directivity of a single transducer primarily depends on driver size, however directivity can be modified using an acoustical waveguide. A method of modelling and designing a wide dispersion waveguide for a loudspeaker soft dome tweeter has been developed. A combination of finite element (FE) modelling and understanding of directivity and waveguides is used in order to prototype loudspeakers virtually. By utilizing computer simulations, the prototyping process is faster and more cost effective, all the while designing better performing loudspeakers. Firstly, a baseline acoustic-structure interaction FE model of a tweeter {{was built in the}} Comsol Multiphysics software. The model was verified by measurements, and the directional properties showed satisfactory agreement in the frequency range of interest. The accuracy of the baseline model allowed for credible simulations of waveguides. Secondly, many waveguide geometry types were investigated, and a method for randomizing geometries and automating the design process was developed using the <b>Livelink</b> for Matlab module in Comsol. Subsequently, a best fit waveguide design was selected based on a set of defined design criteria. Thirdly, a prototype was built, the measured performance compared to the simulated model, and discrepancies investigated. The waveguide directivity performs as modelled through most of the working range, although deviations from simulations were larger than expected at frequencies above 12 kHz. The measurements validate the modelling procedure and emphasize the value of the design algorithm, even though the prediction accuracy may be improved. It can be shown that a waveguide of this type can, with only small modifications, be an effective way to increase HF dispersion for a large range of commercially available tweeters...|$|E
40|$|In {{recent years}} deep brain {{stimulation}} (DBS) has seen success in curing adverseeffects of several diseases, among those Parkinson. Current method for treatmentuses implanted electrodes of the brain which stimulate neurons via potential fields. The precise mechanism with which DBS works is still being researched. To this end amodel allowing for seamless coupling of DBS-signals and neuron behavior will aid intesting and further development of the existing DBS-signals. We simulate the ionic channels in the neuronal membrane {{as well as the}} synapticchannels in the dendrites. The scheme has been implemented using URDME, aMATLAB research code, where a C-code solver is available. A neuron tree is loadedthrough the TREES toolbox from which a connectivity matrix can be formulated. Foreach time step the propagation of the electric potential in the neuronal membrane iscalculated in MATLAB using a Crank-Nicholson scheme. The membrane current isthen calculated and (through <b>Livelink</b> for COMSOL) it is sent to a time dependentPDE-solver which calculates the extracellular potential created by a action potential. Convergence of the interspike interval (ISI) as the time step decreases is shown, aswell as when the space discretization of a neuronal structure is refined. A majority ofthe computational time is spent evaluating the stochastic simulation of ion-channels,and computes the solution of a reference test in ~ 80 s, compared to the ODE modelwhich takes ~ 30 s. Due to the highly parallel nature of the stochastic solver this timecould be decreased. We also show that the stochastic model of a neuron has a different threshold currentfor a potential spike compared to the deterministic model, a systematic study is doneto find the threshold gradient for the stochastic case. Further, the propagationthrough a chain of neurons is simulated where the obtained potential field is realistic...|$|E
40|$|Graduation date: 2013 Global warming {{problem is}} {{becoming}} an increasingly important environmental concern and CO₂ is considered as the major cause of global warming. Among various methods of CO₂ utilization, conversion of CO₂ to value added chemical products is the most attractive. In this study, a microscale-based corona reactor is introduced for reduction of CO₂. Two kinds of solvent were {{used in this study}} for absorbing CO₂: DI-water and ionic liquid 1 -butyl- 3 -methylimidazolium tetrafluoroborate ([BMIM][BF 4]). The latter one has a much higher solubility of CO₂. After saturated with CO₂, solution was introduced into the microreactor built around the concept of corona discharge. The corona was created through a significant potential difference between two graphite electrodes. The current that passed through two electrodes acted as a catalytic agent for the reduction of CO₂. The experiments were conducted at room temperature and at steady state. The ranges of the operating conditions were: mean residence time 5 to 100 (sec), thickness of spacer 200 and 500 (μm), and voltage applied across the reactor 20 and 22. 5 (V). Reactions happened in the bulk of the reactor and five main products were detected at the outlet stream: i) formic acid (HCOOH), ii) formaldehyde (HCHO), iii) methanol (CH₃OH), iv) methane (CH₄) and v) hydrogen (H₂). Among these compounds, formic acid, formaldehyde and methanol are intermediate products. The conversion of CO₂ in aqueous solution can reach as high as 94. 8 % at mean residence time of 100 sec. Although in ionic liquid solution the conversion of CO₂ is much lower (19. 3 % at mean residence time of 100 sec), consumption of CO₂ in ionic liquid is 6 - 7 times larger than that in water when generating same volume of products. A mathematical model reflecting geometry and flow conditions inside the microreactor was developed to simulate the process of CO₂ reduction. The model was solved numerically using COMSOL Multiphysics software package. The simulated results were optimized to fit the experimental data using COMSOL-Matlab <b>LiveLink</b> software package. Primary reaction rate constants for CO₂ reduction were predicted. The mathematical model was found to explain the experimental data pretty well...|$|E
40|$|This thesis {{reports on}} the project {{developed}} between September 2010 and May 2011 at Deloitte Portugal, to pursuit a master’s degree in Computer Science, specialization in information systems at Faculdade de Ciências da Universidade de Lisboa. The internship aimed at the development and integration of an ECM – Enterprise Content Management module, to the company’s purchasing department based on OpenText ECM. For that, it was developed a portfolio of digital purchases for the department {{in order to allow}} easier access to digital documents, to scanned contracts and to search for information based on criteria defined by the purchasing department. This purchase folder was developed as a module for the D:Files system, which is used in the company to manage documents. We used the used the scrum methodology, which is the one that best suits the characteristics of the project, because it was necessary to present and evaluate the new module to the end users. The results met the needs listed by the department, and even exceeded them since it was possible to develop a system with a level of interaction higher than the expected by the purchases department of Deloitte Portugal. The internship, besides the objective of establishing the purchase folder, also served to deepen and apply the knowledge acquired during graduation and master's degrees in computer science, particularly the design, the development, and the project management, as well as to increase the capacity for self-learning, time management, interpersonal relationships, and understanding of the business world. On the internship it was performed additional work not planned on the original project, such as the user support and the participation in evolutionary maintenance system. So it was possible to get a continuous training on the entire D:Files project and also get an extended training on the D:Files system. The trainee also developed other projects, such as the centralization of digital information for the consulting department in the <b>LiveLink</b> system, the creation of Web services for use in other areas, the creation of informational web pages, the testing of D:Files system modules, the development of a system to store and deliver large files that x where previously handled in paper format, the system configuration used in the business,and the development of a system to control the company's budget...|$|E
40|$|Within {{the field}} of Non Destructive Testing (NDT) of materials, {{nonlinear}} ultrasonic techniques are becoming increasingly popular, since they provide extreme sensitivity in detecting the presence of incipient damage. However, the next step forward would be to fully characterize the detected defects (e. g. by estimating their geometric parameters), allowing to make some prediction about lifetime or serviceability of the tested samples and structures. This can for instance be done by comparing the experimentally obtained nonlinear indicators with the results obtained by an effective numerical model. On the other hand, such numerical models {{can also be used}} to assist in the further development and optimization of the existing experimental ultrasonic NDT techniques. In order to obtain a better understanding and analysis of the nonlinear behavior of early-stage damage features, we developed and investigated the results of a two-dimensional numerical model for elastic wave propagation in solid materials containing closed cracks. The model contains two components: the constitutive crack model, and the wave propagation model. In the constitutive crack model, implemented in MATLAB, a real crack in a structure is approximated by a number of mesoscopic cells. In each cell we search for a link between loads (normal N and tangential T) and displacements (normal a and tangential b). The mesoscopic load-displacement relationship integrates the microscopic contact behavior and takes into account roughness of internal crack faces and friction between them, together with the associated effects of memory and hysteresis. The normal reaction curve N(a) is obtained using conventional models of contact mechanics. The tangential reaction is calculated using the original method of memory diagrams that automates and greatly simplifies the account for friction and hysteresis. The full constitutive model allows to describe three different defect states: contact loss, total sliding, and partial slip when both stick and slip areas are present in the contact zone. The wave propagation problem is implemented in the structural mechanics module of COMSOL Multiphysics. Internal cracks are modeled using the ‘thin elastic layer’ boundary condition that allows one to use the customized constitutive relationships by introducing the above described MATLAB function into the COMSOL model using the <b>LiveLink</b> for MATLAB. At each time step of the procedure, COMSOL calculates normal and tangential displacements at each mesh node on the crack interface. These displacements are then used as an input in the MATLAB function in order to calculate the corresponding normal and tangential loads at these mesh nodes. Finally, these loads are re-introduced in the thin elastic layer boundary condition in COMSOL. The final objective of this model is to create some kind of a numerical laboratory capable of modeling various nonlinear experiments in different kinds of materials and geometries and for different defect configurations. status: publishe...|$|E
40|$|ITC/USA 2005 Conference Proceedings / The Forty-First Annual International Telemetering Conference and Technical Exhibition / October 24 - 27, 2005 / Riviera Hotel & Convention Center, Las Vegas, NevadaDuring the era 2000 - 2002, the U. S. Air Force C- 17 Follow-on Flight Test Program (FOFTP) transitioned {{to total}} bulk data {{collection}} employing the Veridian OMEGA™ Intelligent Multiplexer (IMUX) and associated Series 3000 Telemetry Processor. Advanced {{planning for the}} data management was deficient; engineers and analysts were overwhelmed by the actual quantity of instrumentation data collected, {{at a rate of}} 2 - to 3 -gigabytes per flight test hour. In fiscal year (FY) 2003, the Test Director initiated comprehensive planning for management of the C- 17 data elements. Including the bulk instrumentation data collected, this plan also addressed the management of programmatic information and correlation from the test definition program phase through the archiving of test reporting Information. The envisioned end-state of the C- 17 test data archive effort, also referred to as the C- 17 Enterprise Test Data Management System (ETDMS), seeks to provide the C- 17 Test Team with cradle-to-grave data management at a level unprecedented in the flight test community and is described herein. Once funding was received, the C- 17 Integrated Product Team (IPT) has aggressively moved into deploying the C- 17 ETDMS at the Air Force Flight Test Center (AFFTC) located at Edwards Air Force Base, California. Five modest objectives were set for the effort at initiation; these were: 1 ̆ 00089 Objective 1 : Establish C- 17 Technical Library; Complete Deployment of <b>LiveLink</b> Distribution System 1 ̆ 00089 Objective 2 : Improve Data Analysis (Telemetry) Toolset and Products; Train Users 1 ̆ 00089 Objective 3 : Modernize Legacy Databases/Applications (Measurands, Calibrations, Generation of the Test Parameter Requirements [TPR] Document) 1 ̆ 00089 Objective 4 : Fix the Test Planning and Test Point Tracking User Interface 1 ̆ 00089 Objective 5 : Implement the Approved ETDMS Framework The C- 17 ETDMS will link the many geographically separated users of C- 17 test results in near real-time. Thus, providing the program decision-makers with the information required to support the current worldwide combat operations tempo by joint force elements as exhibited during the recent deployments and sustainment of operations in the Southwest Asian AOR. Collaterally, the C- 17 ETDMS will support the efforts of our co-located NASA-Dryden colleagues seeking to improve the abilities of our National Airspace System (NAS) to support industry initiatives such as aircraft health monitoring and “call-ahead” maintenance planning. Currently ahead of schedule and within projected costs boundaries, the C- 17 ETDMS will provide government off-the-shelf (GOTS) /commercial off-the-shelf (COTS) solutions to the C- 17 test community during FY 2005...|$|E
40|$|The Ultra-Efficient Engine Technology (UEET) Office at NASA Glenn Research Center {{is a part}} of the Aeronautics Directorate. Its {{vision is}} to develop and hand off revolutionary turbine engine {{propulsion}} technologies that will enable future generation vehicles over a wide range of flight speeds. There are seven different technology area projects of UEET. During my tenure at NASA Glenn Research Center, my assignment was to assist three different areas of UEET, simultaneously. I worked with Kathy Zona in Education Outreach, Lynn Boukalik in Knowledge Management, and Denise Busch with Financial Management. All of my tasks were related to the business side of UEET. As an intern with Education Outreach I created a word search to partner with an exhibit of a Turbine Engine developed out of the UEET office. This exhibit is a portable model that is presented to students of varying ages. The word search complies with National Standards for Education which are part of every science, engineering, and technology teachers curriculum. I also updated a Conference Planning/Workshop Excel Spreadsheet for the UEET Office. I collected and inputted facility overviews from various venues, both on and off site to determine where to hold upcoming conferences. I then documented which facilities were compliant with the Federal Emergency Management Agency's (FEMA) Hotel and Motel Fire Safety Act of 1990. The second area in which I worked was Knowledge Management. a large knowledge management system online which has extensive documentation that continually needs reviewing, updating, and archiving. Knowledge management is the ability to bring individual or team knowledge to an organizational level so that the information can be stored, shared, reviewed, archived. <b>Livelink</b> and a secure server are the Knowledge Management systems that UEET utilizes, Through these systems, I was able to obtain the documents needed for archiving. My assignment was to obtain intellectual property including reports, presentations, or any other documents related to the project. My next task was to document the author, date of creation, and all other properties of each document. To archive these documents I worked extensively with Microsoft Excel. different financial systems of accounting such as the SAP business accounting system. I also learned the best ways to present financial data and shadowed my mentor as she presented financial data to both UEET's project management and the Resources Analysis and Management Office (RAMO). I analyzed the June 2004 financial data of UEET and used Microsoft Excel to input the results of the data. This process made it easier to present the full cost of the project in the month of June. In addition I assisted in the End of the Year 2003 Reconciliation of Purchases of UEET...|$|E

