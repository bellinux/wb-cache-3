7|3616|Public
40|$|Ullman ([Ull 89 a, Ull 89 b]) {{has shown}} that for the {{evaluation}} of safe Datalog programs, bottomup evaluation using Magic Sets optimization has time complexity {{less than or equal to}} a particular top-down strategy, Queue-based Rule Goal Tree (QRGT) evaluation. This result has sometimes been incorrectly interpreted to mean that bottom-up evaluation beats top-down evaluation for evaluating Datalog programs [...] -top-down strategies such as Prolog (which does no memoing, and uses <b>last</b> <b>call</b> <b>optimization)</b> can beat both QRGT and bottom-up evaluation on some Datalog programs. In this paper we compare a Prolog evaluation based on the WAM model (using <b>last</b> <b>call</b> <b>optimization)</b> with a bottom-up execution based on Magic Templates with Tail Recursion optimization ([Ros 91]), and show the following: (1) Bottom-up evaluation makes no more inferences than Prolog for range-restricted programs. (2) For a restricted class of programs (which properly includes safe Datalog) the cost of bottom-up evaluation is never [...] ...|$|E
40|$|Machine David M. Russinoff Microelectronics and Computer Technology Corporation 3500 West Balcones Center Drive Austin, TX 78759 (512) 338 - 3583 Abstract We {{extend the}} theory of Prolog to provide a {{framework}} for the study of Prolog compilation technology. For this purpose, we first demonstrate the semantic equivalence of two Prolog interpreters: a conventional SLD-refutation procedure and one that employs Warren's "last call" optimization. Next, we formally define the Warren Abstract Machine (WAM) and its instruction set and present a Prolog compiler for the WAM. Finally, we prove that the WAM execution of a compiled Prolog program produces the same result as the interpretation of its source. Contents 1 Introduction 1 2 Prolog 4 2. 1 Syntax............................... 4 2. 2 Semantics............................. 6 2. 3 <b>Last</b> <b>Call</b> <b>Optimization......................</b> 10 3 The WAM 15 3. 1 WAM States. [...] ...|$|E
40|$|We {{present a}} novel {{optimization}} called Last Parallel Call Optimization (LPCO) for parallel systems. The last parallel call optimization {{can be regarded}} as a parallel extension of <b>last</b> <b>call</b> <b>optimization</b> (which itself is a generalization of the tail recursion optimization) found in sequential systems. While the LPCO is fairly general, we use and-parallel logic programming systems to illustrate it and to report its performance on multiprocessor systems. The last parallel call optimization leads to improved time and space performance for a majority of and-parallel programs. We also present a generalization of the Last Parallel Call Optimization called Nested Parallel Call Optimization (NPCO). The NPCO is also illustrated and its performance reported in the context of and-parallel logic programming systems. The LPCO and NPCO can be incorporated in a parallel system through relatively minor modifications to the runtime machinery; its incorporation in an existing and-parallel system is illust [...] ...|$|E
40|$|And-parallelism {{arises in}} Prolog {{programs}} when conjunctive subgoals in a query or {{the body of}} a clause are executed in parallel. In this paper we present three optimizations, namely, the <b>last</b> parallel <b>call</b> <b>optimization,</b> the shallow parallelism optimization, and the processor determinacy optimization that take advantage of determinacy to improve efficiency of and-parallel execution of Prolog programs. All three optimizations depend on a posteriori knowledge of determinacy rather than on a priori knowledge detected at compile-time. With the help of these optimizations, data-and parallel Prolog programs can be efficiently executed on very general andparallel system (such as &ACE and &-Prolog) with the efficiency of dedicated dataand parallel systems (such as Reform Prolog system). These optimizations have been implemented in the &ACE system, and the results are also presented. 1 Introduction Two main types of (implicit) and-parallelism have been identified and successfully exploited in [...] ...|$|R
40|$|The ESS {{elliptical}} superconducting Linac {{consists of}} two types of 704. 42 MHz cavities, medium and high beta, to accelerate the beam from 216 MeV (spoke cavity Linac) up to the final energy at 2 GeV. The <b>last</b> Linac <b>optimization,</b> <b>called</b> Optimus+, {{has been carried out}} taking into account the limitations of SRF cavity performance (field emission). The medium and high-beta parts of the Linac are composed of 36 and 84 elliptical cavities, with geometrical beta values of 0. 67 and 0. 86 respectively. We describe here the procedures and numerical analysis leading from half-cells to a complete medium cavity assembly, which take into account not only the frequency of the fundamental accelerating mode but also the higher order modes near the machine line. The half-cell selection process to form dumb bells will be described, as well as the reshaping and trimming procedure...|$|R
40|$|International audienceThe ESS {{elliptical}} superconducting Linac {{consists of}} two types of 704. 42 MHz cavities, medium and high beta, to accelerate the beam from 216 MeV (spoke cavity Linac) up to the final energy at 2 GeV. The <b>last</b> Linac <b>optimization,</b> <b>called</b> Optimus+ [1], {{has been carried out}} taking into account the limitations of SRF cavity performance (field emission). The medium and high-beta parts of the Linac are composed of 36 and 84 elliptical cavities, with geometrical beta values of 0. 67 and 0. 86 respectively. This work presents the latest vertical test results on ESS medium beta elliptical cavity prototypes. We describe the cavity preparation procedure from buffer chemical polishing to vertical test. Finally magnetic probes (Fluxgate) were installed on the cavity to determine magnetic field background during vertical test. The latest vertical test results showed that our cavity design performance are beyond requirements...|$|R
40|$|In {{this paper}} {{we present a}} novel {{optimization}} called Last Parallel Call Optimization. The last parallel call optimization {{can be regarded as}} an extension of <b>last</b> <b>call</b> <b>optimization,</b> found in sequential systems, to and parallel systems. The last parallel call optimization leads to improved time and space performance for a majority of and-parallel programs. The last parallel call optimization is presented in detail in this paper and its advantages discussed at length. The last parallel call optimization can be incorporated in a parallel system (such as RAPWAM) through relatively minor modifications to the runtime machinery. We also present some experimental results from a limited implementation of last parallel call operation done on the DDAS System. These experimental results prove that last parallel call optimization is indeed effective and produces better speed-ups with respect to an unoptimized implementation. We also discuss the problem of efficiently performing the kill operation in [...] ...|$|E
40|$|AbstractThe type {{concept of}} the logic {{programming}} language PROTOS-L supports sorts, subsort relationships, and parametric polymorphism. Due to the order-sortedness, types are also present at run time, replacing parts of the deduction process required in an unsorted version by efficient type computations. Together with the polymorphism, most of the flexibility of untyped logic programming carries over the order-sorted approach. The operational semantics of PROTOS-L is based on polymorphic order-sorted resolution. Starting from an abstract specification, we show how this operational semantics can be implemented efficiently by {{an extension of the}} Warren Abstract machine, and give a detailed description of all instructions and low-level procedures responsible for type handling. Since the extension leaves the WAM's AND/OR structure unchanged, it allows for all WAM optimizations like <b>last</b> <b>call</b> <b>optimization,</b> environment trimming, etc. Moreover, the extension is orthogonal in the sense that any program part not exploiting the facilities of computing with subtypes is executed with almost the same efficiency as on the original WAM...|$|E
40|$|Abstract The {{categorical}} {{abstract machine}} (CAM) {{is a well-known}} environment-based architecture for implementing strict functional languages. Existing literature about the CAM presumes {{more or less a}} category-theoretical background. Although we appreciate the firm grounds on which the CAM is built, we try to motivate the components of the CAM from an implementor's point of view. This undertaking is facilitated by the conceptional simplicity of the CAM and its proximity to conventional stack architectures. We describe the translation of an augmented *-calculus into CAM instructions. The basic compilation scheme has its didactic virtues but for a real implementation many improvements are necessary (and applicable). A first improvement concerns the treatment of subexpressions which do not access the environment. Further improvements are achieved via simple local transformations of the generated CAM code [...] {{this is one of the}} novel features presented in this report. They include fi-reduction at compile-time, improving calls to local functions, and <b>last</b> <b>call</b> <b>optimization.</b> 1 Introduction Since we want to introduce a particular implementation technique for functional programming languages, we should first say 1. what we mean by &quot;functional &quot; programming languages and 2. why such languages require a special implementation technique...|$|E
5000|$|Functional {{programming}} languages tend {{to rely on}} tail <b>call</b> <b>optimization</b> and higher-order functions {{instead of}} imperative looping constructs.|$|R
50|$|Although Steele's paper did not {{introduce}} {{much that}} was new to computer science, at least as it was practised at MIT, it brought to light the scope for procedure <b>call</b> <b>optimization,</b> which made the modularity-promoting qualities of procedures into a more credible alternative to the then-common coding habits of large monolithic procedures with complex internal control structures and extensive state data. In particular, the tail <b>call</b> <b>optimizations</b> discussed by Steele turned the procedure into a credible way of implementing iteration through single tail recursion (tail recursion calling the same function). Further, tail <b>call</b> <b>optimization</b> allows mutual recursion of unbounded depth, assuming tail calls - this allows transfer of control, as in finite state machines, which otherwise is generally accomplished with goto statements.|$|R
5000|$|Trigger rate. When {{interrupts}} occur back-to-back, microcontrollers may {{avoid an}} extra context save/restore cycle by {{a form of}} tail <b>call</b> <b>optimization.</b>|$|R
25|$|Just as {{algorithms}} on recursive {{data types}} can naturally be given by recursive functions, algorithms on mutually recursive data structures can be naturally given by mutually recursive functions. Common examples include algorithms on trees, and recursive descent parsers. As with direct recursion, tail <b>call</b> <b>optimization</b> is necessary if the recursion depth is large or unbounded, such as using mutual recursion for multitasking. Note that tail <b>call</b> <b>optimization</b> in general (when the function called {{is not the}} same as the original function, as in tail-recursive calls) may be more difficult to implement than the special case of tail-recursive <b>call</b> <b>optimization,</b> and thus efficient implementation of mutual tail recursion may be absent from languages that only optimize tail-recursive calls. In languages such as Pascal that require declaration before use, mutually recursive functions require forward declaration, as a forward reference cannot be avoided when defining them.|$|R
5000|$|Functional {{programming}} languages commonly provide tail <b>call</b> <b>optimization</b> {{to allow}} for extensive use of recursion without stack overflow problems. Limitations in Java bytecode complicate tail <b>call</b> <b>optimization</b> on the JVM. In general, a function that calls itself with a tail call can be optimized, but mutually recursive functions cannot. Trampolines have been suggested as a workaround. Trampoline support has been provided by the Scala library with the object [...] since Scala 2.8.0 (released 14 July 2010). A function may optionally be annotated with , in which case it will not compile unless it is tail recursive.|$|R
5000|$|Ontario: <b>Last</b> <b>call</b> is 2 a.m. {{province}} wide, {{although the}} province {{has the authority}} to grant waivers to allow closing at 4 a.m. during special events. Alcohol sales occur only within regulated stores which will always close between 9 p.m. or 11 p.m. depending on location or store (LCBO, Beer Store or Wine Rack). <b>Last</b> <b>Call</b> is not announced, and if patrons request drinks after 2 a.m., they are told that <b>Last</b> <b>Call</b> has passed (though at some nightclubs <b>Last</b> <b>Call</b> does get announced by the DJ). At some establishments servers/bartenders will <b>last</b> <b>call</b> each table individually just before 2 a.m. to ensure they can order a last round of drinks if they want.|$|R
50|$|SKILL {{supports}} tail <b>call</b> <b>optimization,</b> if it {{is explicitly}} enabled. Here is a tail recursive version of factorial which requires no stack space for the recursion if optimizeTailCall is enabled.|$|R
40|$|Many {{programming}} language implementations compile to Java bytecode, which is executed by a virtual machine (e. g the Java HotSpot TM VM). Among these languages are functional languages, which require an optimization that guarantees that {{certain kinds of}} method calls do not cause the execution stack to grow unlimitedly. This <b>optimization</b> is <b>called</b> tail <b>call</b> <b>optimization</b> and is currently {{not supported by the}} HotSpot TM VM. Implementations of functional languages have to resort to alternative techniques to guarantee that the stack space does not increase unboundedly. These techniques complicate the implementation and also incur a performance penalty. This thesis presents techniques for supporting tail <b>call</b> <b>optimization</b> in the Java HotSpot TM Virtual Machine. Our optimization is implemented in the interpreter, the client compiler and the server compiler. Tail <b>call</b> <b>optimization</b> normally removes stack frames to guarantee that the stack space stays bounded. However, some stack frames are required for the Java access security mechanism to work and hence cannot be removed. virtual machine features a mechanism called deoptimization that allows one to rewrite stack frames. We describe an approach that uses the deoptimization infrastructure to compress stack frames when tail <b>call</b> <b>optimization</b> was disabled because of the security mechanism. This approach allows a series of tail calls to execute in bounded stack space {{in the presence of a}} stack-based security mechanism...|$|R
50|$|<b>Last</b> <b>call</b> in Albany is 4:00 am nightly per New York {{law that}} sets that time as <b>last</b> <b>call</b> {{throughout}} the state by default, though counties may set an earlier time individual municipalities may not. Even though {{more than half of}} the state's counties have an earlier closing time, Albany County, as with all counties in the Capital District, has retained the 4:00 am <b>last</b> <b>call</b> time.|$|R
5000|$|British Columbia: <b>Last</b> <b>call</b> {{for serving}} alcohol is {{generally}} 2:00 a.m. provincially, however municipalities can lower <b>last</b> <b>call</b> down to 12 a.m. or raise {{it up to}} 4 a.m. if they so choose. Downtown Vancouver's <b>last</b> <b>call</b> was moved to 4:00 a.m. but was subsequently lowered to 3 a.m. On New Year's Eve <b>last</b> <b>call</b> is extended to 4 a.m. province wide if food is available to patrons at the premises. Regulated liquor stores (both private and government-operated) can sell off-premises alcohol from 9:00 a.m. until 11:00 p.m, with government-operated liquor stores typically closing before 9 p.m.|$|R
5000|$|<b>Last</b> <b>Call</b> - The <b>last</b> <b>call</b> from {{a viewer}} or a driver. <b>Last</b> <b>call</b> is {{announced}} by a graphic {{of what is}} likely intended to be an Italian bartender, but fans call him the [...] "pizza guy" [...] saying {{he looks like a}} worker in a pizza restaurant and that his long sleeves would get wet if he were a bartender. Despain counters, [...] "Why would a pizza guy be saying [...] "last call!"? ...|$|R
5000|$|Alberta: <b>Last</b> <b>call</b> {{and sale}} of alcohol from a store or {{establishment}} is 2 a.m. province wide. In an establishment, a customer may have {{no more than two}} drinks in possession after 1 a.m. or <b>last</b> <b>call,</b> whatever comes first.|$|R
50|$|Mother Guttersnipe's. The <b>Last</b> <b>Call.</b>|$|R
50|$|After graduating with {{a general}} studies degree in 2001, Zumock {{continued}} his involvement with <b>Last</b> <b>Call</b> as the show itself transitioned into the sketch comedy troupe <b>Last</b> <b>Call</b> Cleveland. Although no longer directly involved, Zumock does {{continue to work with}} its current members, including comedian Mike Polk.|$|R
50|$|Prior to the {{formation}} of The Summer Set, Jess, John, and Stephen played in a band <b>called</b> <b>Last</b> <b>Call</b> for Camden with Kennedy Brock (The Maine (band)) and guitarist Weston Michl. <b>Last</b> <b>Call</b> for Camden released one album entitled Keep Your Feet On the Ground before disbanding.|$|R
50|$|In {{order to}} write {{efficient}} Prolog programs, {{a basic understanding}} of how the WAM works can be advantageous. Some of the most important WAM concepts are first argument indexing and its relation to choice-points, tail <b>call</b> <b>optimization</b> and memory reclamation on failure.|$|R
5000|$|... #Subtitle level 3: <b>Last</b> <b>call,</b> candidacy, and {{recommendation}} stages ...|$|R
50|$|<b>Last</b> <b>Call</b> premiered in 2002 as the {{successor}} to Later. <b>Last</b> <b>Call</b> initially aired Monday through Thursday until the cancellation of Late Friday in late May 2002; it has been aired five nights a week since. Its premiere was delayed one day {{at the last minute}} due to a contract dispute.|$|R
5000|$|David Friedman - <b>Last</b> <b>Call</b> with Carson Daly Executive Producer ...|$|R
5000|$|<b>Last</b> <b>Call</b> (1992): Locus Fantasy and World Fantasy Awards winner, 1993 ...|$|R
5000|$|<b>Last</b> <b>Call</b> (1999 film) (1999) (directed by Christine Lucas), as Mother ...|$|R
5000|$|... 1997 Long Green Boat (Greatest hits {{with live}} tracks) (<b>Last</b> <b>Call)</b> ...|$|R
5000|$|... 2006: <b>Last</b> <b>Call</b> CD / DVD Retrospective - Translation Loss Records ...|$|R
50|$|In 2014 Warm Soda {{performed}} live on <b>Last</b> <b>Call</b> with Carson Daly.|$|R
5000|$|A Night of Electric Silence, (2001) <b>Last</b> <b>Call,</b> Wagram Music 3068202 (live) ...|$|R
5000|$|The Cleveland House of Blues, Cleveland Ohio (Appeared with <b>Last</b> <b>Call</b> Cleveland) ...|$|R
5000|$|Live... At Blue Guitar... <b>Last</b> <b>Call</b> - Kal David (2006) Blue Guitar ...|$|R
