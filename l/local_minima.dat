5245|4066|Public
5|$|In reaction–diffusion systems modeled by the Allen–Cahn equation, the {{limiting}} behavior for fast reaction, slow diffusion, {{and two or}} more <b>local</b> <b>minima</b> of energy with the same energy level as each other is for the system to settle into regions of different <b>local</b> <b>minima,</b> with the fronts delimiting boundaries between these regions evolving according to the curve-shortening flow.|$|E
5|$|Related work on {{this model}} {{concerns}} deposition in which the arrival times of additional particles are random, rather than having particles arrive at all <b>local</b> <b>minima</b> simultaneously. These stochastic growth processes can be modeled as an asynchronous cellular automaton.|$|E
25|$|Solutions {{which are}} not self-dual also exist. These are not <b>local</b> <b>minima</b> of the action, but instead they {{correspond}} to saddle points.|$|E
5000|$|A <b>local</b> <b>minimum</b> {{with respect}} to one {{neighbourhood}} structure {{is not necessarily a}} <b>local</b> <b>minimum</b> for another neighbourhood structure.|$|R
5000|$|GLS uses an {{augmented}} {{cost function}} (defined below), {{to allow it}} to guide the Local Search algorithm out of the <b>local</b> <b>minimum,</b> through penalising features present in that <b>local</b> <b>minimum.</b> The idea is to make the <b>local</b> <b>minimum</b> more costly than the surrounding search space, where these features are not present.|$|R
30|$|A_i is low. This {{means that}} the {{inclusion}} possibility of newly formed solution, which have been generated by exploration technique {{at the end of}} the iterations, into the bat population is weak. At the beginning of the iterations, if the algorithm gets trapped into the <b>local</b> <b>minimum,</b> the newly generated solution also gathers around such <b>local</b> <b>minimum.</b> Hence, the escaping possibility of BA from the <b>local</b> <b>minimum</b> decreases.|$|R
25|$|Stochastic {{tunneling}} {{attempts to}} overcome the increasing difficulty simulated annealing runs have in escaping from <b>local</b> <b>minima</b> as the temperature decreases, by 'tunneling' through barriers.|$|E
25|$|One may {{reformulate}} the Lagrangian as a Hamiltonian, {{in which}} case the solutions are <b>local</b> <b>minima</b> for the Hamiltonian. This is done in optimal control theory, in the form of Pontryagin's minimum principle.|$|E
25|$|In {{order to}} solve this problem with a {{numerical}} optimization technique, we must first transform this problem such that the critical points occur at <b>local</b> <b>minima.</b> This is done by computing the magnitude of the gradient of the unconstrained optimization problem.|$|E
40|$|International audienceThe <b>local</b> <b>minimum</b> {{degree of}} a graph is the minimum degree {{that can be}} reached by means of local complementation. For any n, there exist graphs of order n which have a <b>local</b> <b>minimum</b> degree at least 0. 189 n, or at least 0. 110 n when {{restricted}} to bipartite graphs. Regarding the upper bound, we show that for any graph of order n, its <b>local</b> <b>minimum</b> degree is at most 3 n/ 8 +o(n) and n/ 4 +o(n) for bipartite graphs, improving the known n/ 2 upper bound. We also prove that the <b>local</b> <b>minimum</b> degree is smaller than half of the vertex cover number (up to a logarithmic term). The <b>local</b> <b>minimum</b> degree problem is NP-Complete and hard to approximate. We show that this problem, even when restricted to bipartite graphs, is in W[2] and FPT-equivalent to the EvenSet problem, which W[1]-hardness is a long standing open question. Finally, we show that the <b>local</b> <b>minimum</b> degree is computed by a O*(1. 938 ^n) -algorithm, and a O*(1. 466 ^n) -algorithm for the bipartite graphs...|$|R
50|$|Results {{from the}} {{calculations}} can include the binding energy. In a stable orbit the binding energy is a <b>local</b> <b>minimum</b> relative to parameter perturbation. At the innermost stable circular orbit the <b>local</b> <b>minimum</b> becomes an inflection point.|$|R
25|$|While a <b>local</b> <b>minimum</b> is {{at least}} as good as any nearby points, a global minimum {{is at least}} as good as every {{feasible}} point. In a convex problem, if there is a <b>local</b> <b>minimum</b> that is interior (not {{on the edge of the}} set of feasible points), it is also the global minimum, but a nonconvex problem may have more than one <b>local</b> <b>minimum</b> not all of which need be global minima.|$|R
25|$|This {{also has}} {{applications}} in graph sketching: once the <b>local</b> <b>minima</b> and maxima of a differentiable function have been found, a rough {{plot of the}} graph {{can be obtained from}} the observation that it will be either increasing or decreasing between critical points.|$|E
25|$|Models may not {{consistently}} converge {{on a single}} solution, firstly because many <b>local</b> <b>minima</b> may exist, depending on the cost function and the model. Secondly, the optimization method used might not guarantee to converge when it begins far from any local minimum. Thirdly, for sufficiently large data or parameters, some methods become impractical.|$|E
25|$|Taking {{derivatives}} {{and solving}} for critical points is therefore often {{a simple way}} to find <b>local</b> <b>minima</b> or maxima, which can be useful in optimization. By the extreme value theorem, a continuous function on a closed interval must attain its minimum and maximum values at least once. If the function is differentiable, the minima and maxima can only occur at critical points or endpoints.|$|E
50|$|A Hopfield {{network is}} a form of {{recurrent}} artificial neural network popularized by John Hopfield in 1982, but described earlier by Little in 1974. Hopfield nets serve as content-addressable memory systems with binary threshold nodes. They are guaranteed to converge to a <b>local</b> <b>minimum,</b> but will sometimes converge to a false pattern (wrong <b>local</b> <b>minimum)</b> rather than the stored pattern (expected <b>local</b> <b>minimum).</b> Hopfield networks also provide a model for understanding human memory.|$|R
50|$|While a <b>local</b> <b>minimum</b> is {{at least}} as good as any nearby points, a global minimum {{is at least}} as good as every {{feasible}} point. In a convex problem, if there is a <b>local</b> <b>minimum</b> that is interior (not {{on the edge of the}} set of feasible points), it is also the global minimum, but a nonconvex problem may have more than one <b>local</b> <b>minimum</b> not all of which need be global minima.|$|R
40|$|Abstract — We derive a <b>local</b> <b>minimum</b> of {{an elastic}} poten-tial energy {{due to the}} {{deformation}} of a hemispherical soft fingertip, and propose a quasi-static manipulation algorithm using the <b>local</b> <b>minimum</b> of the potential energy by means of two rotational fingers, on which the soft fingertips are mounted. In this model, a geometrical constraint between the grasped object and two fingertips, which includes the defor-mation of the fingertip, is derived. Using the constraint and the <b>local</b> <b>minimum</b> of the potential energy, we newly propose a numerical algorithm in the quasi-static manipulation. Finally, we conclude {{that the existence of}} the <b>local</b> <b>minimum</b> allows us to stably grasp an object in soft fingered manipulation...|$|R
25|$|In {{this type}} of plot (Figure 1), each axis {{represents}} a unique reaction coordinate, the corners represent <b>local</b> <b>minima</b> along the potential surface such as reactants, products or intermediates and the energy axis projects vertically out of the page. Changing a single reaction parameter can change the height {{of one or more}} of the corners of the plot. These changes are transmitted across the surface such that the position of the transition state (the saddle point) is altered.|$|E
25|$|An {{alternative}} method of structural learning uses optimization based search. It requires a scoring function and a search strategy. A common scoring function is posterior probability {{of the structure}} given the training data, like the BIC or the BDeu. The time requirement of an exhaustive search returning a structure that maximizes the score is superexponential {{in the number of}} variables. A local search strategy makes incremental changes aimed at improving the score of the structure. A global search algorithm like Markov chain Monte Carlo can avoid getting trapped in <b>local</b> <b>minima.</b> Friedman et al. discuss using mutual information between variables and finding a structure that maximizes this. They do this by restricting the parent candidate set to k nodes and exhaustively searching therein.|$|E
25|$|The {{determination}} of molecular structure by geometry optimization became routine only after efficient methods for calculating the first derivatives {{of the energy}} with respect to all atomic coordinates became available. Evaluation of the related second derivatives allows the prediction of vibrational frequencies if harmonic motion is estimated. More importantly, it allows for the characterization of stationary points. The frequencies {{are related to the}} eigenvalues of the Hessian matrix, which contains second derivatives. If the eigenvalues are all positive, then the frequencies are all real and the stationary point is a local minimum. If one eigenvalue is negative (i.e., an imaginary frequency), then the stationary point is a transition structure. If more than one eigenvalue is negative, then the stationary point is a more complex one, and is usually of little interest. When one of these is found, it is necessary to move the search away from it if the experimenter is looking solely for <b>local</b> <b>minima</b> and transition structures.|$|E
3000|$|To conclude, I(ϕ,ψ) has a <b>local</b> <b>minimum</b> (ϕ_ 1,ψ _ 1) {{such that}} A(ϕ_ 1,ψ_ 1)< r and a <b>local</b> <b>minimum</b> (ϕ _ 2,ψ_ 2) such that A(ϕ_ 2,ψ_ 2)>r. According to Lemma  2.3, the {{statement}} in Theorem  4.2 is proved. □ [...]...|$|R
3000|$|... is a Cartesian product. In addition, {{since the}} full minimum {{for the first}} of (24) may be not available, we relax the result by {{assuming}} that a <b>local</b> <b>minimum</b> is achieved and that the target function in this <b>local</b> <b>minimum</b> x [...]...|$|R
2500|$|It is {{possible}} that the process of removing the largest amount of energy and particles possible from a normal space results in a different configuration of quantum fields with a <b>local</b> <b>minimum</b> of energy. [...] This <b>local</b> <b>minimum</b> is called a [...] "false vacuum".|$|R
25|$|The above {{examples}} of mono-monostatic objects are necessarily inhomogeneous, that is, {{the density of}} their material varies across their body. The {{question of whether it}} is possible to construct a three-dimensional body which is mono-monostatic but also homogeneous and convex was raised by Russian mathematician Vladimir Arnold in 1995. The requirement of being convex is essential as it is trivial to construct a mono-monostatic non-convex body (an example would be a ball with a cavity inside it). Convex means that any straight line between two points on a body lies inside the body, or, in other words, that the surface has no sunken regions but instead bulges outward (or is at least flat) at every point. It was already well known, from a geometrical and topological generalization of the classical four-vertex theorem, that a plane curve has at least four extrema of curvature, specifically, at least two local maxima and at least two <b>local</b> <b>minima</b> (see right figure), meaning that a (convex) mono-monostatic object does not exist in two dimensions. Whereas a common anticipation was that a three-dimensional body should also have at least four extrema, Arnold conjectured that this number could be smaller.|$|E
25|$|Phi value {{analysis}} fundamentally {{assumes a}} close relationship between structure and energy. If the energy landscape has a well-defined and relatively deep global minimum, the resemblance of a folding intermediate structure to the native state may closely correlate with the energy of that structure. However, if the energy landscape is relatively flat or has many <b>local</b> <b>minima,</b> the relationship may not hold strongly enough for free energy destabilizations to provide useful structural information. The method also assumes that the folding pathway is not significantly altered, although the folding energies may be. For nonconservative mutations this assumption might be fundamentally flawed; thus conservative substitutions are preferred, though they may yield smaller energetic destabilizations that are thus more difficult to detect experimentally. Lastly, the restriction of the phi value range as necessarily nonnegative assumes that {{the introduction of a}} mutation will not increase the stability and thus lower the energy of either the native or the transition state relative to those of the wild-type protein. Also, it is implicitly assumed that the interactions that stabilize a folding transition state are native-like in nature. Many recent studies of protein folding, however, have suggested that stabilizing non-native interactions in a folding transition state may aid in folding. An elegant example of this is given in Zarrine-Afsar et al. (2008) PNAS, where authors have demonstrated that stabilizing non-native interaction in the Fyn SH3 domain actually accelerated the folding rate of this protein.|$|E
500|$|The {{principles}} {{of natural selection}} have inspired a variety of computational techniques, such as [...] "soft" [...] artificial life, that simulate selective processes and can be highly efficient in 'adapting' entities to an environment defined by a specified fitness function. For example, a class of heuristic optimisation algorithms known as genetic algorithms, pioneered by John Henry Holland in the 1970s and expanded upon by David E. Goldberg, identify optimal solutions by simulated reproduction and mutation of a population of solutions defined by an initial probability distribution. Such algorithms are particularly useful when applied to problems whose energy landscape is very rough or has many <b>local</b> <b>minima.</b>|$|E
3000|$|... {{corresponds}} to local maximum or <b>local</b> <b>minimum</b> energies in i-th motion sequence. And l {{is the total}} number of local maximum and <b>local</b> <b>minimum</b> values. Note, l is not a fixed value, and it depends on number of motion cycles and motion variations in the sequence.|$|R
30|$|<b>Local</b> <b>minimums</b> of cross {{correlation}} coefficients are identified.|$|R
5000|$|A {{variation}} on always tunneling {{is to do}} so only when trapped at a <b>local</b> <b>minimum.</b> [...] is then adjusted to tunnel out of the minimum and pursue a more globally optimum solution. Detrended fluctuation analysis is the recommended way of determining if trapped at a <b>local</b> <b>minimum.</b>|$|R
500|$|The {{technique}} of simulated annealing, by which an existing MSA produced by another method is refined {{by a series}} of rearrangements designed to find better regions of alignment space than the one the input alignment already occupies. Like the genetic algorithm method, simulated annealing maximizes an objective function like the sum-of-pairs function. Simulated annealing uses a metaphorical [...] "temperature factor" [...] that determines the rate at which rearrangements proceed and the likelihood of each rearrangement; typical usage alternates periods of high rearrangement rates with relatively low likelihood (to explore more distant regions of alignment space) with periods of lower rates and higher likelihoods to more thoroughly explore <b>local</b> <b>minima</b> near the newly [...] "colonized" [...] regions. This approach has been implemented in the program MSASA (Multiple Sequence Alignment by Simulated Annealing).|$|E
500|$|To model {{this process}} by Rule 184, observe that the {{boundary}} between filled and unfilled lattice positions can be marked by a polygonal line, the segments of which separate adjacent lattice positions and have slopes +1 and 1. Model a segment with slope +1 by an automaton cell with state 0, and a segment with slope 1 by an automaton cell with state 1. The <b>local</b> <b>minima</b> of the surface are the points where a segment of slope 1 lies {{to the left of}} a segment of slope +1; that is, in the automaton, a position where a cell with state 1 lies to the left of a cell with state 0. Adding a particle to that position corresponds to changing the states of these two adjacent cells from 1,0 to 0,1, so advancing the polygonal line. [...] This is exactly the behavior of Rule 184.|$|E
2500|$|This {{means that}} all their <b>local</b> <b>minima</b> and maxima have values of 1 and +1, ...|$|E
30|$|Algorithm is not {{be trapped}} into the <b>local</b> <b>minimum.</b>|$|R
30|$|The <b>local</b> <b>minimum</b> theorem and its variant are {{presented}} below.|$|R
40|$|Abstract. Necessary {{conditions}} {{in terms of}} a <b>local</b> <b>minimum</b> principle are derived for optimal control problems subject to index- 1 differential-algebraic equations, pure state constraints and mixed control-state constraints. Differential-algebraic equations are composite systems of differential equations and algebraic equations, which frequently arise in practical applications. The <b>local</b> <b>minimum</b> principle is based on necessary optimality conditions for general infinite optimization problems. The special structure of the optimal control problem under consideration is exploited and allows to obtain more regular representations for the multipliers involved. An additional Mangasarian-Fromowitz like constraint qualification for the optimal control problem ensures the regularity of a <b>local</b> <b>minimum...</b>|$|R
