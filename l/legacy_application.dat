149|932|Public
5000|$|... 1996 Carbon API for Mac OS - <b>legacy</b> <b>application</b> {{compatibility}} on Apple Computer's Darwin Kernel (derived from QTML authored for QuickTime).|$|E
5000|$|Steelroads - The {{company also}} {{operates}} Steelroads, a <b>legacy</b> <b>application</b> which allows shippers {{to trace the}} movement of their rail freight shipments.|$|E
50|$|Biometric {{security}} measures {{are difficult to}} implement on legacy systems. A workable solution {{is to use a}} telnet or http proxy server to sit between users and the mainframe to implement secure access to the <b>legacy</b> <b>application.</b>|$|E
5000|$|Re-engineering: A {{technique}} to rebuild <b>legacy</b> <b>applications</b> {{in a new}} technology or platform, with same or enhanced functionality - usually by adopting Service Oriented Architecture (SOA). This is the most efficient and agile way of transforming <b>legacy</b> <b>applications.</b>|$|R
40|$|This article {{provides}} keys to getting started with modeling <b>legacy</b> <b>applications</b> using the Unified Modeling Language (UML). <b>Legacy</b> <b>applications</b> are often complex {{and difficult to}} evolve. Usually, they are written in implementation languages that are not Object-Oriented (OO), the source code is not reverse engineered, and the documentation is not synchronized with prior evolutions. Often, <b>legacy</b> <b>applications</b> have been documented using various methodologies and tools, {{but there is no}} synchronization among the tools. If developers need detailed and unambiguous information, the...|$|R
5000|$|Maintenance & Enhancement of custom, {{package and}} <b>legacy</b> <b>applications</b> ...|$|R
50|$|The act of {{application}} retirement usually involves migrating {{data from the}} <b>legacy</b> <b>application</b> database to another data repository or archive store that can be accessed independently using industry standard reporting or business intelligence tools. Application retirement allows IT departments within companies to reduce the software, hardware and resources required to manage legacy data.|$|E
50|$|Printing {{improvements}} are problematic because legacy software systems often add no formatting instructions, or they use protocols {{that are not}} usable in modern PC/Windows printers. A print server {{can be used to}} intercept the data and translate it to a more modern code. Rich Text Format (RTF) or PostScript documents may be created in the <b>legacy</b> <b>application</b> and then interpreted at a PC before being printed.|$|E
50|$|Businesses {{often provide}} teleworkers access to {{corporate}} in-house applications, accessible by a remote device {{such as a}} tablet or laptop. These devices are gaining popularity in the workforce but come with different underlying operating systems and therefore a variety compatibility issues. However, {{with the use of}} desktop virtualization, specifically remote desktop virtualization, any <b>legacy</b> <b>application</b> or operating system can be accessed from a mobile device, as this device is primary used as a display unit while the processing is performed on the company's internal server.|$|E
5000|$|SCOx Web Services Substrate, a web services-based {{framework}} for modernizing <b>legacy</b> <b>applications.</b>|$|R
30|$|REuse and Migration of <b>legacy</b> <b>applications</b> to Interoperable Cloud Services (REMICS 2010) {{project has}} {{developed}} an advanced model driven methodology and the corresponding tools for reuse and migration of <b>legacy</b> <b>applications</b> to interoperable Cloud services. Service Cloud paradigm stands for combination of cloud computing and Service Oriented Architecture (SOA) for development of Software as a Service (SaaS) systems.|$|R
5000|$|A {{considerable}} number of shims {{are present in the}} application compatibility layer of later versions of Windows to intercept and modify API calls made by <b>legacy</b> <b>applications</b> that were written with a different set of assumptions and operating system best practices in mind. [...] These fixes are updated from time-to-time as issues are discovered in popular <b>legacy</b> <b>applications</b> that are still in use.|$|R
50|$|Operation Cyber Condition Zebra is {{a network}} {{operations}} campaign {{conducted by the}} United States Navy to deny network intrusion and establish an adequate computer network defense posture to provide defense-in-depth and warfighting capability. The operation specifies that perimeter security for legacy networks will deny intrusions and data infiltration, that firewalls will be maintained through risk assessment and formal adjudication of <b>legacy</b> <b>application</b> waiver requests, and that legacy networks will be shut down as quickly a possible after enterprise networks (such as the NMCI) are established.|$|E
50|$|Sphere is a {{parallel}} data processing engine integrated in Sector {{and it can}} be used to process data stored in Sector in parallel. It can broadly compared to MapReduce, but it uses generic user defined functions (UDFs) instead of the map and reduce functions. A UDF can be either a map function or a reduce function, or even others.Sphere can manipulate the locality of both input data and output data, thus it can effectively support multiple input datasets, combinative and iterative operations and even <b>legacy</b> <b>application</b> executable.|$|E
50|$|IBM Integration Bus {{provides}} {{capabilities to}} build solutions {{needed to support}} diverse integration requirements {{through a set of}} connectors to a range of data sources, including packaged applications, files, mobile devices, messaging systems, and databases. A benefit of using IBM Integration Bus is that the tool enables existing applications for Web Services without costly <b>legacy</b> <b>application</b> rewrites. IIB (IBM Integration Bus) avoids the point-to-point strain on development resources by connecting any application or service over multiple protocols, including SOAP, HTTP and JMS. Modern secure authentication mechanisms, including the ability to perform actions on behalf of masquerading or delegate users, through MQ, HTTP and SOAP nodes are supported such as LDAP, X-AUTH, O-AUTH, and two-way SSL.|$|E
50|$|Furthermore, <b>legacy</b> <b>applications</b> {{that attempt}} to access {{hardware}} directly cannot do so in user mode. <b>Legacy</b> <b>applications</b> may also fail if system configuration files from the DOS and Windows 9x era are not present in Windows NT based kernels, hence the reason for zero-length versions of files like AUTOEXEC.BAT and CONFIG.SYS having to be carried forward on operating systems that do not use them.|$|R
40|$|Grid environments {{present a}} virtual black box to {{scientists}} running <b>legacy</b> <b>applications,</b> with the Grid infrastructure effectively hiding the running application on a resource {{over which the}} scientist generally has limited or no control. Existing moni-toring systems that allow Grid-enabled applications to communicate their progress and receive steering information are inapplicable as they require code modification, and this not possible in true legacy scenarios. While a black box approach may be ac-ceptable in batch execution scenarios, it means the Grid is cut off to <b>legacy</b> <b>applications</b> where inter-actions or intermediate results are required. In this paper we present gridMonSteer, a sim-ple, non-intrusive architecture that allows scien-tists to receive intermediate results and interact with <b>legacy</b> <b>applications</b> running in a Grid envi-ronment. This architecture is Grid middleware in-dependent and can be employed to monitor ap-plications submitted via any Grid resource man-ager (e. g. GRAM, GRMS or Condor/G) or run-ning within a Grid service framework. We present a case study describing how gridMonSteer enables <b>legacy</b> <b>applications</b> to act as active components in Grid workflows, dynamically driving and steering the workflow execution. ...|$|R
50|$|Abstraction of transport/protocol {{connectivity}}â€”Abstraction of connectivity issues promotes {{ability to}} integrate new software with <b>legacy</b> <b>applications</b> through simplification of connections.|$|R
5000|$|Initially, WSIPC had {{developed}} their own Enterprise Resource Planning (ERP) application in-house, called WISE, which not only provided a complete SIS, but also information management for both finance and student data. Starting in 2001 WSIPC collaborated with Skyward and, as a result, completely restructured the computing infrastructure at WSIPC, replacing the <b>legacy</b> <b>application</b> offerings with one integrated ERP application provided to WSIPC customers. [...] WSIPC called its ERP application WESPaC (WSIPC Enhanced Skyward Point and Click) which included Skyward's software suite of student, human resources and financial management modules. WESPaC also included Citrix's MetaFrame which provided users with remote access. Skyward eventually converted its thick client student application into a web interface and part of its finance software to have a web front end. The other part of their finance software is still thick client. Therefore, WESPaC has now evolved into two applications, one being a web-based student application and the other being a finance application that is partly web-based and partly thick client. Both of these applications are currently provided by Skyward.|$|E
5000|$|A {{transaction}} processing capability {{was developed in}} the late 1960s as a joint project with United Airlines and later refined in another joint project with Air Canada. This capability was fully integrated into the operating system in 1972 and became the basis of much of the future growth of the 1100 Series. Early users controlled communication lines directly from within their real time programs. Part of the development of {{transaction processing}} included a communication message system that managed the communication lines and presented messages to Exec 8 to be scheduled as transactions. This moved all the low level communication physical line management and protocols out of the applications and into the CMS 1100 application. [...] CMS 1100 itself ran as a real time multi-threaded program with the privilege of acquiring control of communication lines and submitting transaction messages for scheduling. This led to the notions in Exec 8 that applications of any nature needed to be carefully controlled to ensure that they could not cause integrity issues. Security was certainly a concern, but in the early days system reliability and integrity were much larger issues. The system was still primarily batch and transaction processing and there was little chance that anyone could install unauthorized code on the system. CMS 1100 later added the capability to be the interface for demand terminals as well as transaction terminals so that terminals could be used for both and the early terminal drivers could be removed from the Exec. CMS 1100 was later replaced by a combination of CPComm (ClearPath Enterprise Servers Communications Platform) and SILAS (System Interface for <b>Legacy</b> <b>Application</b> Systems).For the Intel-based Dorado server models, the lower level communications were moved to firmware, with the upper levels handled by SILAS and CPCommOS (ClearPath Enterprise Servers Communications Platform for Open Systems).|$|E
40|$|Software {{reengineering}} is {{the concept}} of gracefully modernizing a <b>legacy</b> <b>application.</b> Many organizations are planning to modernize their <b>legacy</b> <b>application</b> through reengineering. However many of these efforts are often less than successful because they concentrate on a narrow set of risk issues without fully considering a broader set of enterprise wise system, managerial and technical risk issues. Overall success of reengineering effort requires a decision driven risk assessment framework that examines system, managerial and technical domain of <b>legacy</b> <b>application.</b> We present a hierarchical system domain risk framework SysRisk to analyze system dimensions of <b>legacy</b> <b>application.</b> The fundamental premise of framework is to observe, extract and categories the contextual perspective models and risk clusters of system domain. This work contributes for a decision driven framework to identify and assess risk components of system domain. Proposed framework provides guidance on interpreting the results obtained from assessment to take decision about when evolution of a legacy system through reengineering is successful...|$|E
5000|$|... #Caption: , MS-DOS {{is still}} {{used in some}} {{enterprises}} to run <b>legacy</b> <b>applications,</b> such as this US Navy food service management system.|$|R
5000|$|New BOA {{structures}} integrate <b>legacy</b> <b>applications</b> {{and assets}} {{in a single}} interoperable framework for increased leverage, reuse, and longevity of assets.|$|R
5000|$|Package implementation: Replacement of <b>legacy</b> <b>applications,</b> {{in whole}} or part, with {{off-the-shelf}} software (COTS) such as ERP, CRM, SCM, Billing software etc.|$|R
40|$|Many {{organizations}} have legacy applications and strive to modernise {{them in order}} to react on changes and adapt to the new environment, the cloud. The enticements are quite a few but the risks are lurking as well. How to migrate a <b>legacy</b> <b>application</b> to the cloud is an unanswered question for many organizations. We look at how research has answered this question and the methods and tools they provide. The research partially answers the question of migration of <b>legacy</b> <b>application</b> to the cloud. The methods and tools are still quite granular, not that automated and is very dependent of what type of <b>legacy</b> <b>application</b> and the aim of the end result is...|$|E
30|$|The TSP usually enables <b>Legacy</b> <b>Application</b> (LA) via Enterprise Service Bus (ESB) or RESTful web service. Thus, the {{interface}} of TSP should {{be adapted to}} IP.|$|E
40|$|Abstractâ€”Modernization of a <b>legacy</b> <b>application</b> is {{not very}} hard any more. Whereas {{this may have been}} true a couple of years ago, this paper {{describes}} a case study, which shows that the modernization is significantly easier if modern integration tools, a service-oriented architecture and Web services are used. This is by contrast to a common belief that the modernization is always hard, regardless of the technologies used. The case study, where bachelor students succeeded to carry out the modernization of a <b>legacy</b> <b>application,</b> shakes that belief. The students neither had previous experience with the technologies used in the <b>legacy</b> <b>application</b> nor with the ones used for the modernization. As major contributions this paper provides an overview of approaches to modernization, a full case study for the modernization (including details on business process analysis, architecture, and tools), and comprehensive â€˜lessons learned â€™ to help for â€˜the practiceâ€™. Keywordsâ€”service-oriented architecture; mainframe; legacy integration; experience report; Web service I...|$|E
5000|$|EGL is {{a target}} {{language}} for modernization of <b>legacy</b> <b>applications</b> {{because of the}} language semantics affinity with procedural languages and legacy 4th generation languages: ...|$|R
40|$|Various approache,y {{can be used}} {{to migrate}} <b>legac,Y</b> <b>applications</b> to the Web. In particular, {{migrating}} dataintensive <b>legacy</b> <b>applications</b> (e. g. traditional application for business management) needs methodological approach to face the challenges implied by the pro(~ss. The Ubiquitous Web Applications (UW A) framework {{is one of the most}} innovative and completeframeworksfor conceptual user centered modelling of a Web application. In this paper we describe the application of UWA to a real expE~rience of reengineering a real legacy applicationfor customer's order management. ...|$|R
40|$|International audienceSoftware systems should {{evolve in}} order to respond to {{changing}} client requirements and their evolving environments. But unfortunately, the evolution of <b>legacy</b> <b>applications</b> generates an exorbitant cost. In this paper, we propose an approach to restructure <b>legacy</b> object-oriented <b>applications</b> into component-based applications. Our approach is based on dynamic dependencies between classes to identify potential components. In this way, the composition is dictated by {{the context of the}} application to improve its evolvability. We validate our approach through the study of three <b>legacy</b> Java <b>applications...</b>|$|R
40|$|<b>Legacy</b> <b>application</b> {{developers}} {{today have}} a major concern regarding the impact that new technology will have on their careers, organizations, environment and their human selves. A paradigm shift will occur in the requirements to develop computer applications utilizing new technology which {{will need to be}} recognized by the mainframe developer. Legacy or mainframe application development requires a level of expertise that is built over years of experience. On the other hand, development of client/server applications requires a very different logical process since it can occur on any type of hardware whether it is a mainframe, midrange or personal computer. The future careers of <b>legacy</b> <b>application</b> programmers will be focused on the acquisition of expertise in new technology development of client/server applications. This movement will impact the leadership of new technology developers and will require a redefinition of the leadership role in their organization. The team structure and culture in organizations that partake in new technology development will drive the ripple effect of change on their application development areas. Todayâ€™s <b>legacy</b> <b>application</b> closed development environmen...|$|E
40|$|In {{this paper}} we {{describe}} our experience in porting a real-world <b>legacy</b> <b>application,</b> namely the statistic evaluation of ship vulnerability, to a parallel execution environment dynamically distributed over the intra-net Of the Italian naval research center (CETENA). More in details, we describe how we leveraged the dynamic, plug-in based metacomputing infrastructure {{provided by the}} HARNESS system to reconcile the requirements of a <b>legacy</b> <b>application</b> tightly tied to a specific CAD environment with a grid-like metacomputing environment in order to deploy over the machines connected through an intra-net multiple instances of the application, coordinate their execution, collect the so produced results and merge them into a unified, statistically improved simulation...|$|E
40|$|This paper {{presents}} {{the implementation of}} the ORFA client. ORFA aims at providing an efficient access to remote file systems through high-speed local networks such as MYRINET. The ORFA client is a lightweight shared library that may be pre-loaded to override standard file access routines to allow remote file access for any <b>legacy</b> <b>application...</b>|$|E
40|$|Providing {{support for}} <b>legacy</b> <b>applications</b> {{is a crucial}} {{component}} of many overlay networks, as it allows end-users to instantly benefit from the functionality introduced by these overlays. This paper presents the design and implementation of a proxy-based solution to support <b>legacy</b> <b>applications</b> {{in the context of}} the i 3 overlay [24]. The proxy design relies on an address virtualization technique which allows the proxy to tunnel the legacy traffic over the overlay transparently. Our solution can preserve IP packet headers on an end-to-end basis, even when end-host IP addresses change, or when endhosts live in different address spaces (e. g., behind NATs). In addition, our solution allows the use of human-readable names to refer to hosts or services, and requires no changes to applications or operating systems. To illustrate how the proxy enables <b>legacy</b> <b>applications</b> to take advantage of the overlay (i. e., i 3) functionality, we present four examples: enabling access to machines behind NAT boxes, secure Intranet access, routing legacy traffic through Bro, an intrusion detection system, and anonymous web download. We have implemented the proxy on Linux and Windows XP/ 2000 platforms, and used it over the i 3 service on PlanetLab over a three month period with a variety of <b>legacy</b> <b>applications</b> ranging from web browsers to operating system-specific file sharing. ...|$|R
40|$|<b>Legacy</b> <b>applications</b> {{represent}} software {{solutions for}} many organizations and businesses. These applications {{have been implemented}} using different IT platforms and few of these systems have been standardized or migrated to newer versions. Thus, {{there are a lot}} of heterogeneous applications running in different platforms, even within one organization. The need for interchanging strategic information between organizations or <b>legacy</b> <b>applications</b> is more common than a few years ago. Data interchange among these heterogeneous legacy systems is usually a major project. The solution is not unique and there might even be many solutions for every pair of <b>legacy</b> <b>applications.</b> We call data-middleware a product for interchanging information between two <b>legacy</b> <b>applications.</b> In order to develop a reusable and nonlegacy implementation dependent solution, this product could be developed using the software product line paradigm. The development of this product as part of a software product line includes new practice areas that must be defined in a Business Case. A Business Case (BC) is a tool for making a business decision, because it predicts the organizational consequences of this decision. We describe a BC with three core practice areas: how the organization should be structured, the base architecture as the main initial asset, and how the data-middleware product line organization is launched and institutionalized...|$|R
40|$|Currently, {{there are}} many <b>legacy</b> {{enterprise}} software <b>applications</b> in active deployment that are outdated. These large <b>legacy</b> <b>applications</b> are rapidly becoming less practical for both the organizations they service, and for the organizations responsible for servicing them. Due to this problem, organizations utilizing <b>legacy</b> enterprise software <b>applications</b> are looking for feasible methods for overhauling them. This thesis establishes a process model for refining the initial concept associated with overhauling <b>legacy</b> enterprise software <b>applications,</b> and examines {{a case study of}} that process as applied to a real-world legacy software system. Â Â M. S...|$|R
