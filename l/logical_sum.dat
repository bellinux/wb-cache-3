22|7|Public
2500|$|The {{defects in}} Boole's system (such {{as the use}} of the letter v for existential propositions) were all {{remedied}} by his followers. [...] Jevons published Pure Logic, or the Logic of Quality apart from Quantity in 1864, where he suggested a symbol to signify exclusive or, which allowed Boole's system to be greatly simplified. [...] This was usefully exploited by Schröder when he set out theorems in parallel columns in his Vorlesungen (1890–1905). [...] Peirce (1880) showed how all the Boolean elective functions could be expressed by the use of a single primitive binary operation, [...] "neither ... nor ..." [...] and equally well [...] "not both ... and ...", however, like many of Peirce's innovations, this remained unknown or unnoticed until Sheffer rediscovered it in 1913. [...] Boole's early work also lacks the idea of the <b>logical</b> <b>sum</b> which originates in Peirce (1867), Schröder (1877) and Jevons (1890), and the concept of inclusion, first suggested by Gergonne (1816) and clearly articulated by Peirce (1870).|$|E
50|$|The <b>logical</b> <b>sum</b> {{applied to}} two propositions returns their disjunction.|$|E
50|$|The four {{fundamental}} {{functions are}} the contradictory function, the <b>logical</b> <b>sum,</b> the logical product, and the implicative function.|$|E
5000|$|... “A ruthlessly <b>logical</b> <b>summing</b> {{up of the}} six Spro-cas commissions… one’s {{constant}} {{instinct is}} to cry: ‘For God’s sake, surely government thinkers must take note of this’.” - Tony Richmond, review of A Taste of Power in The Cape Herald, Cape Town, 20 October 1973.|$|R
50|$|Another kind of array {{reduction}} operation like <b>SUM,</b> <b>Logical</b> AND or MAX.|$|R
40|$|The paper {{focuses on}} {{aspects of the}} {{measurement}} problem introducing quantum states (q-states) for measured and measuring systems. The link between non-interacting and interacting quantum systems is first look at. For two independent partite systems <b>logical</b> <b>sums</b> A+B stand for non-interacting q-systems; while a direct product space AxB gathers interacting states. However this latter should support physical q-states with base states that do not separately belong to either A nor B; the latter correspond to bridge states, namely entangled states that can perform as links (bridges) between A+B and AxB domains. Bridge states at laboratory space open possibilities to describe transport in quantized amounts of energy and angular momentum. These link bases sustain entanglements of different kinds. Interactions bring in quantized electromagnetic (em) fields. Matter sustained q-states entangled to em-sustained q-states open bridges to transport information between matter and radiation. Comment: 22 page...|$|R
5000|$|The latter {{asserts that}} the <b>logical</b> <b>sum</b> (i.e. ⋁, OR) of a simple {{proposition}} p and a predicate ∀xf(x) implies the <b>logical</b> <b>sum</b> of each separately. But PM derives both of these from six primitive propositions of ❋9, which in the second edition of PM is discarded and replaced with four new [...] "Pp" [...] (primitive principles) of ❋8 (see in particular ❋8.2, and Hilbert derives the first from his [...] "logical ε-axiom" [...] in his 1927 and does not mention the second. How Hilbert and Gödel came to adopt these two as axioms is unclear.|$|E
5000|$|It {{was used}} by Russell and Whitehead in Principia Mathematica, where they called it the <b>Logical</b> <b>Sum</b> or Disjunctive Function. In Unicode the symbol is encoded [...] and by [...] and [...] in TeX. The {{opposite}} symbol (∧) is called a wedge.|$|E
5000|$|In general, the {{engineering}} connectives {{are just the}} same as the mathematics connectives excepting they tend to evaluate with [...] "1" [...] = [...] "T" [...] and [...] "0" [...] = [...] "F". This is done for the purposes of analysis/minimization and synthesis of formulas by use of the notion of minterms and Karnaugh maps (see below). Engineers also use the words logical product from Boole's notion (a*a = a) and <b>logical</b> <b>sum</b> from Jevons' notion (a+a = a).|$|E
40|$|Sparse grids are {{constructed}} as <b>logical</b> <b>sums</b> of product grids. Each product grid is formed by selecting, for each dimension, {{one element of}} an indexed family of quadrature rules. The identical family may be employed in each dimension, or the same rule may be used, but with certain parameters varying, or the family itself may change from one dimension to another. While many quadrature families are known, sparse grids are typically employed for functions with a stochastic component, in which case there are a small set of preferred families. Another issue with sparse grids involves the growth rule employed in a family, that is, {{the rate at which}} the order of the rules grows with the index. This article considers some typical 1 D quadrature rules, and some of the issues that arise when using them to build a sparse grid. ...|$|R
40|$|Abstract—Boolean {{networks}} are recently attracting considerable interest as computational models for genetic and cellular networks. We consider a Mayer–type optimal control {{problem for a}} single–input Boolean network, and derive {{a necessary condition for}} a control to be optimal. This provides an analog of Pontryagin’s maximum principle for single–input Boolean networks. Index Terms—Semi–tensor product, <b>logical</b> functions, <b>sum</b> of products representation, systems biology, variational analysis, necessary condition for optimality. I...|$|R
5000|$|We {{say that}} a binary matrix, , is -separable if every Boolean <b>sum</b> (<b>logical</b> OR) of any [...] of its columns is distinct. Additionally, we write that [...] is -separable if every sum of any of up to [...] of its columns is distinct. (Note {{that this is not}} the same as [...] being -separable for every [...]) ...|$|R
5000|$|The text {{leaps from}} section ✸14 {{directly}} to the foundational sections ✸20 GENERAL THEORY OF CLASSES and ✸21 GENERAL THEORY OF RELATIONS. [...] "Relations" [...] are what is known in contemporary set theory as sets of ordered pairs. Sections ✸20 and ✸22 introduce many of the symbols still in contemporary usage. These include the symbols [...] "ε", [...] "⊂", [...] "∩", [...] "∪", [...] "-", [...] "Λ", and [...] "V": [...] "ε" [...] signifies [...] "is an element of" [...] (PM 1962:188); [...] "⊂" [...] (✸22.01) signifies [...] "is contained in", [...] "is a subset of"; [...] "∩" [...] (✸22.02) signifies the intersection (logical product) of classes (sets); [...] "∪" [...] (✸22.03) signifies the union (<b>logical</b> <b>sum)</b> of classes (sets); [...] "-" [...] (✸22.03) signifies negation of a class (set); [...] "Λ" [...] signifies the null class; and [...] "V" [...] signifies the universal class or universe of discourse.|$|E
5000|$|Ludwig Wittgenstein's {{notion of}} language-games argues {{that there is}} no overarching, single, {{fundamental}} ontology, but only a patchwork of overlapping interconnected ontologies ineluctably leading from one to another. For example, Wittgenstein discusses 'number' as technical vocabulary and in more general usage: [...] "“All right: the concept of 'number' is defined for you as the <b>logical</b> <b>sum</b> of these individual interrelated concepts: cardinal numbers, rational numbers, real numbers etc.;” ... — it need not be so. For I can give the concept 'number' rigid limits in this way, that is, use the word 'number' for a rigidly limited concept, but I can also use it so that the extension of the concept is not closed by a frontier. ...Can you give the boundary? No. You can draw one..." [...] Ludwig Wittgenstein Wittgenstein suggests that {{it is not possible to}} identify a single concept underlying all versions of 'number', but that there are many interconnected meanings that transition one to another; vocabulary need not be restricted to technical meanings to be useful, and indeed technical meanings are 'exact' only within some proscribed context: ...|$|E
5000|$|He {{does not}} call his {{inference}} principle modus ponens, but his formal, symbolic expression {{of it in}} PM (2nd edition 1927) is that of modus ponens; modern logic calls this a [...] "rule" [...] {{as opposed to a}} [...] "law". In the quotation that follows, the symbol [...] "⊦" [...] is the [...] "assertion-sign" [...] (cf PM:92); “⊦" [...] means [...] "it is true that", therefore “⊦p” where [...] "p" [...] is [...] "the sun is rising" [...] means [...] "it is true that the sun is rising", alternately [...] "The statement The sun is rising is true". The [...] "implication" [...] symbol [...] "⊃" [...] is commonly read [...] "if p then q", or [...] "p implies q" [...] (cf PM:7). Embedded in this notion of [...] "implication" [...] are two [...] "primitive ideas", [...] "the Contradictory Function" [...] (symbolized by NOT, [...] "~") and [...] "the <b>Logical</b> <b>Sum</b> or Disjunction" [...] (symbolized by OR, [...] "⋁"); these appear as [...] "primitive propositions" [...] ❋1.7 and ❋1.71 in PM (PM:97). With these two [...] "primitive propositions" [...] Russell defines [...] "p ⊃ q" [...] to have the formal logical equivalence [...] "NOT-p OR q" [...] symbolized by [...] "~p ⋁ q": ...|$|E
40|$|The {{dissertation}} is a historical-cum-conceptual {{examination of}} the idea of self-causation (causa sui). In the Western metaphysical tradition, self-causation has been understood in two ways: (i.) as an individual existentâs spontaneous self-creation and internal causal or ontological determination (what we term ontological self-causation), and/ or (ii.) as an individualâs logical identity with an essence that uniquely characterizes it and out of which all of its features issue (<b>logical</b> self-causation). In <b>sum,</b> self-causation is (i.) the internal reason for an individualâs existence, and/ or (ii) the internal reason for an individualâs individuality. The question whether there really are existents self-caused in {{at least one of these}} two senses â and what precisely we can know or say about them â has, in one form or another, occupied metaphysicians of all historical epochs. Our aim is to distil the ideaâs logical structure and explanatory scope through philosophical engagement with a careful selection of paradigmatic discourses in the history of metaphysics. These are: Platoâs Theory of Forms, Aristotleâs theory of substance, John Duns Scotusâ and Francisco SuÃ¡rezâs theories of individuality, G. W. Leibnizâs monadological and Baruch Spinozaâs monistic metaphysics, Immanuel Kantâs transcendental and G. W. F. Hegelâs dialectical theory of individuality â inasmuch as they all contain, presuppose, or prefigure, theories of self-causation. A dialogical discussion of issues specific to each key discourse reveals a shared problematic bound up with an individualâs being or becoming (what it is) according to an internal principle, usually also in relation to other individuals or within a general order of things. It emerges that, after Aristotleâs step away from Platoâs transcendent Forms, the theory of self-causation embeds itself in immanentist, particularistic metaphysics. We argue that this theory finds its most complete articulation in Hegelâs metaphysics of the concrete universal. The outcome of the theory is that an individual can coherently be understood as self-caused only if it is fully identical with a unique essence (logical self-causation) yet without bringing itself into being (ontological self-causation). Self-causation is shown, accordingly, to be a viable criterion for an individualâs logical identity qua individual...|$|R
50|$|Generalized Kinetic LogicThe naive logical {{description}} can {{be generalized}} {{and made to}} accommodate situations in which some variables take more than two values, without complicating the analysis. Any variable {{has a number of}} biologically relevant levels, determined by the number of elements regulated by the product x. There is a specific threshold for each regulatory interaction, so if x regulates n elements, it will have up to n different thresholds.For the <b>logical</b> <b>sum,</b> there is a procedure that assigns a specific weight to each term in the logical relation. According to the scale of thresholds of the corresponding variable, the weighted algebraic sum is then discretized, so an n-valued variable is associated with an n-valued function. After discretization the integers of certain weights or sums of weights are called logical parameters. Generalized Kinetic Logic, although maintaining the analytic simplicity of the naive description, has certain features in common with the differential description. The generalized logical relations are completely independent of the differential description and can be directly derived from the graph of interactions or from an explicit verbal description. Consider an example of two elements in figure E. Using a software, this graph of interactions is drawn as shown in figure F. There are two thresholds assigned to element y: Ѳ12, concerning its interaction with x and Ѳ22, concerning its interaction with itself. The variable y and function Y have three possible values: 0, 1, and 2. Element x have a single threshold, Ѳ21, because of the interaction x to +y, so the variable x and function X will be two-valued.|$|E
5000|$|In his Symbolic Logic (1881), John Venn used {{diagrams}} {{of overlapping}} areas to express Boolean relations between classes or truth-conditions of propositions. In 1869 Jevons realised that Boole's methods could be mechanised, and constructed a [...] "logical machine" [...] which he showed to the Royal Society the following year. [...] In 1885 Allan Marquand proposed an electrical {{version of the}} machine that is still extant (picture at the Firestone Library).The defects in Boole's system (such {{as the use of}} the letter v for existential propositions) were all remedied by his followers. Jevons published Pure Logic, or the Logic of Quality apart from Quantity in 1864, where he suggested a symbol to signify exclusive or, which allowed Boole's system to be greatly simplified. [...] This was usefully exploited by Schröder when he set out theorems in parallel columns in his Vorlesungen (1890-1905). Peirce (1880) showed how all the Boolean elective functions could be expressed by the use of a single primitive binary operation, [...] "neither ... nor ..." [...] and equally well [...] "not both ... and ...", however, like many of Peirce's innovations, this remained unknown or unnoticed until Sheffer rediscovered it in 1913. [...] Boole's early work also lacks the idea of the <b>logical</b> <b>sum</b> which originates in Peirce (1867), Schröder (1877) and Jevons (1890), and the concept of inclusion, first suggested by Gergonne (1816) and clearly articulated by Peirce (1870).The success of Boole's algebraic system suggested that all logic must be capable of algebraic representation, and there were attempts to express a logic of relations in such form, of which the most ambitious was Schröder's monumental Vorlesungen über die Algebra der Logik ("Lectures on the Algebra of Logic", vol iii 1895), although the original idea was again anticipated by Peirce.|$|E
40|$|The logical {{equivalence}} {{between two}} powerful optical computing techniques, namely, optical symbolic substitution and optical shadow-casting is investigated. A common basis for both schemes is developed and their roots are {{traced back to}} fundamental principles of logic design. Both shadow-casting and symbolic substitution based optical computing operations are shown to be equivalent to <b>logical</b> <b>sum</b> of product operations...|$|E
40|$|The nuclide 18 F disintegrates to 18 O by beta+ {{emission}} (96. 86 %) and {{electron capture}} (3. 14 %) with a half-life of 1. 8288 h. It {{is widely used}} in nuclear medicine for positron emission tomography (PET). Because of its short half-life this nuclide requires the development of fast measuring methods to be standardized. The combination of LSC methods with digital techniques proves {{to be a good}} alternative to get low uncertainties for this, and other, short lived nuclides. A radioactive solution of 18 F has been standardized by coincidence counting with a LSC, using the <b>logical</b> <b>sum</b> of double coincidences in a TDCR array and a NaI scintillation detector. The results show good consistency with other techniques like 4 Pi gamma and LSC...|$|E
40|$|Abstract-An Impact Factor is {{one measure}} of the {{relative}} importance of a journal, individual article or scientist to science and social science literature and research. Each index or database used to create an impact factor uses a different methodology and produces slightly different results, revealing the importance of using several sources to judge the true impact of a journal's or scientist’s work. In the web environment, impact factor is measured through the number of hyperlinks counts and number of WebPages. The concept of self-citation is replaced by self-links, i. e., the links within the websites and citation is replaced by in-links, i. e., the links coming outside the websites. As we know, WIF is the <b>logical</b> <b>sum</b> of external and self-link WebPages divided by number of web pages found on that particular websites. There ar...|$|E
40|$|The {{effect of}} {{multiple}} γ-ray interactions within a liquid scintillation detector {{caused by a}} single radionuclide decay event on ionisation quenching corrections has been determined. Ionisation quenching corrections to the energy deposition spectrum {{have been carried out}} over all electron-generating gamma interactions of the decay event. Comparison has been made with the approximate method typically used to correct for ionisation quench. Both calculations were carried out using the Geant 4 simulation package. The two models are compared using the values of detection efficiencies of the <b>logical</b> <b>sum</b> of double coincidence obtained for 131 I, 123 I and 177 Lu measured using the Triple-to-Double Coincidence Ratio method of absolute activity measurement. Finally, predictions are made as to the circumstances under which the two quench correction approaches will be most discrepant. © 2010, Elsevier Ltd...|$|E
40|$|Abstract. The {{spectra of}} the conjunctively polynomial-like Boolean func-tions {{belonging}} to their modified canonical normal forms induce a linear space {{over the field}} of two elements. A basis of this space was given in [7]. In this article we give another way to generate a matrix of {{the basis of the}} space. In this article disjunction and <b>logical</b> <b>sum,</b> conjunction and logical product, exclusive or and modulo two sum, as well as complementation and negation are used in the same sense and they are denoted respectively by +, · (or simply without any operation sign), ⊕ and. The elements of the field with two elements and the elements of the Boolean algebra with two elements are denoted by the same signs, namely by 0 and 1; N denotes the non-negative integers, and N+ the positive ones. 1...|$|E
40|$|The nuclide 241 Am decays by alpha {{emission}} to 237 Np. Most of the decays (84. 6 %) {{populate the}} excited level of 237 Np with energy of 59. 54 keV. Digital Coincidence Counting {{was applied to}} standardize a solution of 241 Am by alpha-gamma coincidence counting with efficiency extrapolation. Electronic discrimination was implemented with a pressurized proportional counter {{and the results were}} compared with two other independent techniques: Liquid Scintillation Counting using the <b>logical</b> <b>sum</b> of double coincidences in a TDCR array and Defined Solid Angle Counting taking into account activity inhomogeneity in the active deposit. The results show consistency between the three methods within a limit of a 0. 3 %. An ampoule of this solution will be sent to the International Reference System (SIR) during 2009. Uncertainties were analysed and compared in detail for the three applied methods...|$|E
40|$|Coherence {{protocols}} {{and memory}} consistency models are two important issues in hardware coherent shared memory multiprocessors and software distributed shared memory(DSM) systems. Over the years, many researchers have made extensive study {{on these two}} issues respectively. However, the interaction between them has not been studied in the literature. In this paper, we study the coherence protocols and memory consistency models used by hardware and software DSM systems in detail. Based on our analysis, we draw a general definition for memory consistency model, i. e., memory consistency model is the <b>logical</b> <b>sum</b> of the ordering of events in each processor and coherence protocol. We also point that in hardware DSM system the emphasis of memory consistency model is relaxing the restriction of event ordering, while in software DSM system, memory consistency model focuses mainly on relaxing coherence protocol. Taking Lazy Release Consistency(LRC) as an example, we analyze the relationsh [...] ...|$|E
40|$|Abstract. In {{this article}} we apply {{the notion of the}} {{modified}} conjunctive normal form of a Boolean function which is equal to the canonical conjunc-tive normal form of the complement of the dual of the same Boolean func-tion. In the article a linear algebraic transform is given between the mod-ified conjunctive normal form and the Zhegalkin polynomial of a Boolean function and then the notion of the conjunctively polynomial-like Boolean functions as the functions having the same series of the coefficients in their modified conjunctive normal forms and in their Zhegalkin polynomials is introduced. In this article disjunction and <b>logical</b> <b>sum,</b> conjunction and logical product, exclusive or and modulo two sum, as well as complementation and negation are used in the same sense and they are denoted respectively by +, · (or simply without any operation sign), ⊕ and. The elements of the field with two elements and the elements of the Boolean algebra with two elements are denoted by the same signs, namely by 0 and 1; N 0 denotes the non-negative integers, and N the positive ones. 1...|$|E
40|$|BACKGROUND: To compare {{morphological}} gross tumor volumes (GTVs), {{defined as}} pre- and postoperative gadolinium enhancement on T 1 -weighted {{magnetic resonance imaging}} to biological tumor volumes (BTVs), defined by the uptake of (18) F fluoroethyltyrosine (FET) for the radiotherapy planning of high-grade glioma, using a dedicated positron emission tomography (PET) -CT scanner equipped with three triangulation lasers for patient positioning. METHODS: Nineteen patients with malignant glioma were included into a prospective protocol using FET PET-CT for radiotherapy planning. To be eligible, patients had to present with residual disease after surgery. Planning was performed using the clinical target volume (CTV = GTV union or <b>logical</b> <b>sum</b> BTV) and planning target volume (PTV = CTV + 20 mm). First, the interrater reliability for BTV delineation was assessed among three observers. Second, the BTV and GTV were quantified and compared. Finally, the geometrical relationships between GTV and BTV were assessed. RESULTS: Interrater agreement for BTV delineation was excellent (intraclass correlation coefficient 0. 9). Although, BTVs and GTVs {{were not significantly different}} (p = 0. 9), CTVs (mean 57. 8 +/- 30. 4 cm(3)) were significantly larger than BTVs (mean 42. 1 +/- 24. 4 cm(3); p or= 10 and 20 mm from the margin of the gadolinium enhancement. CONCLUSION: Using FET, the interrater reliability had excellent agreement for BTV delineation. With FET PET-CT planning, the size and geometrical location of GTVs and BTVs differed in a majority of patients...|$|E
40|$|An Impact Factor is {{one measure}} of the {{relative}} importance of a journal, individual article or scientist to science and social science literature and research. Each index or database used to create an impact factor uses a different methodology and produces slightly different results, revealing the importance of using several sources to judge the true impact of a journal's or scientist’s work. In the web environment, impact factor is measured through the number of hyperlinks counts and number of WebPages. The concept of self-citation is replaced by self-links, i. e., the links within the websites and citation is replaced by in-links, i. e., the links coming outside the websites. As we know, WIF is the <b>logical</b> <b>sum</b> of external and self-link WebPages divided by number of web pages found on that particular websites. There are number of way to find the impact of journal, paper, and Web sites etc. In this proposed system is going to find impact factor of E-books by using EigenFactor and the links of E-books represented by using UCINET software. The link of E-books can identify based on the degree, betweenness of the link. This system is used to measure the quality of E-books and to know how many of them referring the E-book. Most of the E-books are downloaded from the Web or require pages can read from the Web site itself. This was done by means of a citation analysis and a reader survey. For the citation analysis, impact factor, citing half-life, number of references per article, and the rate of self-references of a periodical were used as indicators. Webometric data have been collected through Yahoo! And Google search engines using special query syntax...|$|E
40|$|The topic {{which has}} been {{assigned}} to me, "Classification Today- Shadow or Substance," might more appropriately have come {{at the end of}} the Institute, rather than the beginning. If I could convince you that our pursuit of valid classifications was the pursuit of a shadow, there would be no reason to listen to the papers on the remaining part of the program. We could all pack up and go home. Hence, I must conclude that when those who planned this Institute gave me this topic, they assumed that regardless of what I might say about classification, I would certainly be unable to demonstrate its ephemeral or shadowy nature and that I would conclude that classification had substantial value for librarianship and related information activities. Confronted with this dilemma, it occurred to me that the way out for an erstwhile student of logic like myself might be found in the first instance not in examining the nature of shadows nor the nature of substances, but in examining the meaning of the connective between them, namely, the logical operator "or. " Most of us, when we think of the word "or," think of it in the exclusive sense as meaning "either or," that is, the word used in this title, "Shadow or Substance," would ordinarily be interpreted to mean that if classification were substantial it could not be shadowy, or if it were shadowy, it could not be substantial. There is, however, another meaning of "or" which is the usual meaning attributed to it in works of logic, where the "or" is taken as meaning logical disjunction with reference to propositions and <b>logical</b> <b>sum</b> with reference to classes. In this sense "or" means "and/or" rather than "either or. " Thus if I say "It will rain tomorrow or I will stay home," both statements could be true; that is, it might rain tomorrow and I could still stay home. Similarly, if I say of an item that it is a member of the class A or B, it could be a member of A, a member of B, or a member of AB, and the general proposition "X is a member of A or B" is true in all three cases. This general proposition is only false when the item is a member of neither A nor B. This logical relation can be illustrated by the truth table for disjunction at the top of the following page. published or submitted for publicatio...|$|E

