7|27|Public
50|$|Suitable {{materials}} {{for use in}} vacuum forming are conventionally thermoplastics. The most common and easiest to use thermoplastic is high impact polystyrene sheeting (HIPS). This is molded around a wood, structural foam or cast or machined aluminium mold, and can form to almost any shape. Vacuum forming is also appropriate for transparent materials such as acrylic, which are widely used in applications for aerospace such as passenger cabin window canopies for military fixed wing aircraft and compartments for rotary wing aircraft. Vacuum forming is often used in <b>low-level</b> <b>technology</b> classes for {{an easy way to}} mold.|$|E
40|$|This article {{concerns}} the Singapore government's strategy {{to transform the}} character of industrial relations from traditional authoritarianism to one reflecting the precepts of good human relations, having extended control over industrial relations during the successful first stage of industrialisation based on <b>low-level</b> <b>technology,</b> the government, anticipating unfavourable world economic trends, is inducing changes In workforce orientations suitable for meeting {{the challenges of the}} higher-level technology of Singapore's second industrial revolution...|$|E
40|$|This paper {{concerns}} the Singapore government's strategy {{to transform the}} character of industrial relations from traditional authoritarianism to one reflecting the precepts of good human relations. Having extended control over industrial relations during the successful first stage of industrialisation based on <b>low-level</b> <b>technology,</b> the government, anticipating unfavourable world economic trends, is inducing changes in workforce orientations suitable for meeting {{the challenges of the}} higher-level technology of Singapore's second industrial revolution. The authors examine the strategy and discuss the industrial relations issues arising from it...|$|E
40|$|The Deaf {{people have}} {{difficulty}} in communicating with others like who don’t understand sign language. In this purpose we are implementing this research. There {{has been a}} great development {{in the past few years}} on the infusion of technology in the life and curriculum of people with special needs. A techno logy that enables an individual with a learning disability to compensate for specific deficits is indeed an assistive technology. Technology to incorporate would usually range between the simple <b>low-level</b> <b>technologies</b> to the robust emerging technologies. As technology is meant to help humanity, assistive technology relates well to those with special needs. In this paper, we present the structure of our device, highlighting on how the sensors were made. We also discuss the block level implementation of the gesture to speech translator and report a few results of our preliminary testing...|$|R
40|$|Innovative {{solutions}} {{of bamboo}} connections and an application on Polonceau trusses {{to use for}} simple constructions are presented. Experimental tests show the performances and {{the high level of}} ductility of the proposed technique, joined with simplicity, with <b>low-level</b> of <b>technology</b> and low cost of all used materials. Their applications with sustainable maintenance are suitable in developing countries...|$|R
5000|$|Guaraná DSL is a Domain-Specific Language (DSL) {{to design}} {{enterprise}} application integration (EAI) solutions at a high-level of abstraction. The resulting models are platform-independent, so engineers {{do not need}} to have skills on a <b>low-level</b> integration <b>technology</b> when designing their solutions. Furthermore, this design can be re-used to automatically generate executable EAI solutions for different target technologies ...|$|R
40|$|Reducing {{the energy}} {{consumed}} {{in the use of}} computing devices is becoming a major design challenge. While the problem obviously must be addressed with improved <b>low-level</b> <b>technology,</b> we claim there is potential value in a higher-level perspective, as well. In our approach, the needs of applications serve as the driving force for the development of power-management functions in the operating system and of a power-based API that allows a partnership between applications and the system in setting energy policy. The development of a PalmPilot application is used as an illustration. We advocate that reducing energy consumption should be raised to first-class status among performance goals when software is being designed. In support of this objective, new programming models, measurement tools, and system support mechanisms must be developed. These needs motivate our Milly Watt Project...|$|E
40|$|Reducing {{the energy}} {{consumed}} {{in the use of}} mobile and wireless devices is becoming a major design challenge. While the problem obviously must be addressed with improved <b>low-level</b> <b>technology,</b> we have advocated also considering a higher-level view in which energy management becomes an explicit design goal of the software developer who can be more aware of the needs of applications. In support of this objective, new programming models, measurement tools, and simulation environments must be developed to provide the developer with feedback on the energy implications of various design decisions. In this paper, we describe an energy model and an execution-driven simulator incorporating this model for the PalmOS TM family of devices. 1. Introduction Reducing the energy consumed in using mobile/ wireless devices, thereby extending the lifetime of the batteries that power them, {{is one of the major}} challenges in designing such systems. While this problem can be addressed at various levels (e [...] . ...|$|E
30|$|The {{indicators}} used by {{the latter}} approach are based on product classification established by the Standard International Trade Classification (SITC), a system which, {{in the context of}} an increasingly fragmented world production in certain branches of production, limits our perception of the technological level of exports based on products. Lall et al. (2006) posit two concepts that characterize exports: sophistication and technological level. While the sophistication indicator arises from the correlation between countries’ income levels and their composition of exports, the technological level, developed by Lall (2000), is defined by the intensity of R&D in products. This leads us to differentiate between high-technology exports with a low level of sophistication, and low-technology exports with a high level of sophistication. In a context of fragmented production, the first group covers technology-intensive goods that are assembled by semi-industrialized countries and then exported. Although statistics show these countries’ exports to be sophisticated, by specializing in the assembly of high-technology products for export, the fact that they participate in technologically simple phases of high technology is concealed. The second group, <b>low-level</b> <b>technology</b> but sophisticated exports of developed countries, encompasses manufactured goods based on natural resource transformation.|$|E
40|$|Maintaining Situational Awareness and Tactical Decision Making are workload-intensive and timecritical {{challenges}} for {{the crew of the}} Army’s AH- 64 D Apache Longbow. The Apache crew faces these challenges with extreme mission demands coupled with stressful high-speed, <b>low-level</b> flight. Two <b>technology</b> trends show great promise in addressing these problems...|$|R
5000|$|The name LLVM was {{originally}} an initialism for Low Level Virtual Machine, but this became increasingly less apt as LLVM became an [...] "umbrella project" [...] {{that included a}} variety of other compiler and <b>low-level</b> tool <b>technologies,</b> so the project abandoned the initialism. [...] Now, LLVM is a brand that applies to the LLVM umbrella project, the LLVM intermediate representation (IR), the LLVM debugger, the LLVM C++ Standard Library (with full support of C++11 and C++14), etc. LLVM is administered by the LLVM Foundation. Its president is compiler engineer Tanya Lattner.|$|R
40|$|The {{emergence}} of large-scale receptor-based systems has enabled applications to execute complex business logic over data generated from monitoring the physical world. An important functionality required by these applications is the detection {{and response to}} complex events, often in real-time. Bridging the gap between <b>low-level</b> receptor <b>technology</b> and such high-level needs of applications remains a significant challenge. We demonstrate our {{solution to this problem}} in the context of HiFi, a system we are building to solve the data management problems of large-scale receptor-based systems. Specifically, we show how HiFi generates simple events out of receptor data at its edges and provides high-functionality complex event processing mechanisms for sophisticated event detection using a real-world library scenario. 1...|$|R
40|$|Abstract: Future cities {{will have}} to confront limited urban spaces and resources, {{undertake}} the preservation or conservation of sense of place, and continuously improve the existing urban environment. Accordingly, urban void spaces {{are likely to become}} key strategic places for ‘Green Urban Development’. Urban voids are spaces that are useless, underused, abandoned, or in-between spaces among public and private realms. This research looks into urban voids that can be found especially within the residential environment in Seoul, as a chance for sustainable urban design. Dispersed urban voids have been generated due to various reasons, such as intrinsic to policy and planning system, changing economic, social and functional aspect and further on. The study briefly evaluates the existing built environment especially the quality of urban spatial structure and public spaces in the residential area, which is made up of individual buildings. Existing urban voids are extracted, identified and then classified into three major categories- street, block and edge condition. A crucial aspect would be showing how these urban voids could be used or reused in terms of ‘green urban development’. Conventional <b>low-level</b> <b>technology</b> which involves planting and greening and environmental high technology which includes fuel cell, electric car station, and rainwater storage and so on can be potentially applied and integrated into these urban voids. Consequently this research paper will suggest that each improvement measure should be considered as a piecemeal ‘act ’ of an integrated urban regeneration and transformation of a whole city with adequate development guidelines...|$|E
40|$|The {{increasing}} {{volume of}} time-based generated {{data and the}} shift in storage technologies suggest that {{we might need to}} reconsider indexing. Several workloads- like social and service monitoring- often include attributes with implicit clustering because of their time-dependent nature. In addition, solid state disks (SSD) (using flash or other <b>low-level</b> <b>technologies)</b> emerge as viable competitors of hard disk drives (HDD). Capacity and access times of storage devices create a trade-off between SSD and HDD. Slow random accesses in HDD have been replaced by efficient random accesses in SSD, but their available capacity is one or more orders of mag-nitude more expensive than the one of HDD. Indexing, however, is designed assuming HDD as secondary storage, thus minimizing random accesses at the expense of capacity. Indexing data using SSD as secondary storage requires treating capacity as a scarce re-source. To this end, we introduce approximate tree indexing, which em-ploys probabilistic data structures (Bloom filters) to trade accuracy for size and produce smaller, yet powerful, tree indexes, which we name Bloom filter trees (BF-Trees). BF-Trees exploit pre-existing data ordering or partitioning to offer competitive search perfor-mance. We demonstrate, both by an analytical study and by ex-perimental results, that by using workload knowledge and reduc-ing indexing accuracy up to some extent, we can save substantially on capacity when indexing on ordered or partitioned attributes. In particular, in experiments with a synthetic workload, approximate indexing offers 2. 22 x- 48 x smaller index footprint with competitive response times, and in experiments with TPCH and a monitoring real-life dataset from an energy company, it offers 1. 6 x- 4 x smaller index footprint with competitive search times as well. 1...|$|R
40|$|Programming of {{embedded}} systems {{is still a}} special discipline. In many cases, developers are forced to use only <b>low-level</b> programming <b>technologies</b> and languages so {{it is obvious that}} this way of software development can be time-consuming and inefficient. However, there are several ways leading to more efficient programmers' work. One of those ways leading to speed-up of {{embedded systems}} software development process is application of formal-methods. The goal {{of this article is to}} point out that some specific formal languages (more exactly usage of Finite State Machines) can be effectively used for designing of embedded application logic. The paper also introduces a unique RAD development environment called State Builder for Processor Expert able to produce an optimized, platform-independent production-ready source code that fulfills all necessary requirements of embedded systems. Z(MSM 7088352102...|$|R
40|$|Standard Internet {{communication}} protocols are key enablers for the Internet of Things (IoT). Recent technological advances {{have made it}} possible to run such protocols on resource-constrained devices. Yet these devices often use energy-efficient, <b>low-level</b> communication <b>technologies,</b> like IEEE 802. 15. 4, which suffer from low-reliability and high latency. These drawbacks can be significantly reduced if communication occurs using concurrent transmissions - a novel communication paradigm for resource-constrained devices. In this paper, we show that Internet protocols like TCP/UDP and CoAP can run efficiently on top of a routing substrate based on concurrent transmissions. We call this substrate LaneFlood and demonstrate its effectiveness through extensive experiments on Flocklab, a publicly available testbed. Our results show that LaneFlood improves upon CXFS - a representative competitor - in terms of both duty cycle and reliability. Furthermore, LaneFlood can transport IoT traffic with an end-to-end latency of less than 300 ms over several hops...|$|R
40|$|An {{understanding}} of students’ use of {{social networking sites}} (SNS) for expressive participation in Internet Social Movements (ISMs) is absent {{in the literature on}} the social psychology of student social networking behavior. Using the Unified Theory of Acceptance and Use of Technology (UTAUT) as a theoretical framework and survey data collected from 214 students in Spain, we empirically test the UTAUT theory in this context. Our results confirm that effort expectancy, social influence, and performance expectancy significantly affect students’ intentions to use SNS for expressive participation in Internet social movements. We also test the moderating effect of students’ sex and Technology Readiness (TR) on these UTAUT relationships. Our results show that the intention to use SNS is strongly influenced by effort expectancy for female students and students with self-reported <b>low-levels</b> of <b>technology</b> readiness. For male students and students with self-reportinghigh-levels of technology readiness, the relationship is strongly influenced by social influence. The implications of our findings for theory and practice are discussed...|$|R
50|$|Many of the mummies {{have been}} found in very good condition, owing to the dryness of the desert and the {{desiccation}} it produced in the corpses. The mummies share many typical Caucasian body features (elongated bodies, angular faces, recessed eyes), and many of them have their hair physically intact, ranging in color from blond to red to deep brown, and generally long, curly and braided. Their costumes, and especially textiles, may indicate a common origin with Indo-European neolithic clothing techniques or a common <b>low-level</b> textile <b>technology.</b> Chärchän man wore a red twill tunic and tartan leggings. Textile expert Elizabeth Wayland Barber, who examined the tartan-style cloth, discusses similarities between it and fragments recovered from salt mines associated with the Hallstatt culture. As a result of the arid conditions and exceptional preservation, tattoos have been identified on mummies from several sites around the Tarim Basin, including Qäwrighul, Yanghai, Shengjindian, Shanpula, Zaghunluq, and Qizilchoqa.|$|R
40|$|This thesis {{will discuss}} the {{requirements}} of a software library for tomography and will derive a framework {{which can be used}} to realize various applications in cone-beam computed tomography (CBCT). The presented framework is self-contained and is realized using the MATLAB environment in combination with native <b>low-level</b> <b>technologies</b> (C/C++ and CUDA) to improve its computational performance, while providing accessibility and extendability through to use of a scripting language environment. On top of this framework, the realization of Katsevich’s algorithm on multicore hardware will be explained and the resulting implementation will be compared to the Feldkamp, Davis and Kress (FDK) algorithm. It will also be shown that this helical reconstruction method has the potential to reduce the measurement uncertainty. However, misalignment artifacts appear more severe in the helical reconstructions from real data than in the circular ones. Especially for helical CBCT (H-CBCT), this fact suggests that a precise calibration of the computed tomography (CT) system is inevitable. As a consequence, a self-calibration method will be designed that is able to estimate the misalignment parameters from the cone-beam projection data without the need of any additional measurements. The presented method employs a multi-resolution 2 D- 3 D registration technique and a novel volume update scheme in combination with a stochastic reprojection strategy to achieve a reasonable runtime performance. The presented results will show that this method reaches sub-voxel accuracy and can compete with current state-of-the-art online- and offline-calibration approaches. Additionally, for the construction of filters in the area of limited-angle tomography a general scheme which uses the Approximate Inverse (AI) to compute an optimized set of 2 D angle-dependent projection filters will be derived. Optimal sets of filters are then precomputed for two angular range setups and will be reused to perform various evaluations on multiple datasets with a filtered backprojection (FBP) -type method. This approach will be compared to the standard FDK algorithm and to the simultaneous iterative reconstruction technique (SIRT). The results of the study show that the introduced filter optimization produces results comparable to those of SIRT with respect to the reduction of reconstruction artifacts, whereby its runtime is comparable to that of the FDK algorithm...|$|R
40|$|Geosensor {{technology}} is radically changing {{our ability to}} collect data {{in a wide range}} of domains. While sensor hardware and <b>low-level</b> system <b>technology</b> is advancing rapidly, higher level modeling needs to be advanced in parallel, so that users can effectively utilize the potential. This paper proposes an approach to modeling interaction with geosensor networks based on dynamic primitives. Much of the current spatiotemporal information system {{technology is}} based on the snapshot metaphor, where the dynamic world is imagined as a temporal sequence of snapshots. This imposes limitations on the representations and reasoning capabilities of such systems. In particular, it is not possible using temporal snapshots to explicitly model events, processes, and actions. This paper summarizes some of the work done on extensions to current models to provide fuller event modeling capabilities, and gives examples of applications to the geosensor and geographic domain. The work will have impact in understanding physical aspects of the global security environment, because event-based models are needed for effective and high-level handling of geospatial intelligence information. 1...|$|R
40|$|Service Oriented Architecture (SOA) is an {{emerging}} style of software architectures to reuse and integrate existing systems for designing new applications. Each application is designed in an implementation independent manner using two major abstract concepts: services and connections between services. In SOA, non-functional aspects (e. g., security and fault tolerance) {{of services and}} connections should be described separately from their functional aspects (i. e., business logic) because different applications use services and connections in different non-functional contexts. This paper proposes a model-driven development (MDD) framework for non-functional aspects in SOA. The proposed MDD framework consists of (1) a Unified Modeling Language (UML) profile to graphically model non-functional aspects in SOA, and (2) an MDD tool that accepts a UML model defined with the proposed profile and transforms it to application code. This paper also demonstrates how the proposed framework is used in model-driven development of serviceoriented applications. Empirical evaluation {{results show that the}} proposed MDD framework improves the reusability and maintainability of service-oriented applications by hiding <b>low-level</b> implementation <b>technologies</b> in UML models...|$|R
40|$|This chapter {{describes}} {{the architecture of}} a middleware layer between low-level sensing devices and higher level software layers, to support the require- ments of a software infrastructure for networked enterprises. The development of such middleware layer is an important problem, {{as demonstrated by the}} number or research papers and the variety of approaches that can be found in literature. The main goals are to hide the complexity of <b>low-level</b> pervasive <b>technologies,</b> such as Wireless Sensors Networks (WSNs); and to help the higher software layers in man- aging the heterogeneous real-time data coming from the environment. In this chapter, after analysing the different approaches, we select the Service Oriented Architecture (SOA) design paradigm as the most suitable for allowing a seamless and effective integration of pervasive technologies into the enterprise information systems. We also present SensorsMW, our middleware proposal implemented {{in the context of the}} ArtDeco project, which is based on some of the many technologies that spin around the SOA world. In particular, our software is a service-oriented, flexible and adaptable middleware that allows applications to configure WSN functionalities and exploit them in the form of Web Services...|$|R
40|$|This article {{presents}} an empirical {{study of how}} the use of relational database access technologies in open source Java projects evolves over time. Our observations {{may be useful to}} project managers to make more informed decisions on which technologies to introduce into an existing project and when. We selected 2, 457 Java projects on GitHub using the <b>low-level</b> JDBC <b>technology</b> and higher-level object relational mappings such as Hibernate XML configuration files and JPA annotations. At a coarse-grained level, we analysed the probability of introducing such technologies over time, as well as the likelihood that multiple technologies co-occur within the same project. At a fine-grained level, we analysed to which extent these different technologies are used within the same set of project files. We also explored how the introduction of a new database technology in a Java project impacts the use of existing ones. We observed that, contrary to what could have been expected, object-relational mapping technologies do not tend to replace existing ones but rather complement them. Comment: Postproceeding of the SATTOSE 2015 Research Seminar on Advanced Tools and Techniques for Software Evolution. To be published in CEUR. WS workshop proceedings (2017...|$|R
40|$|Ethernet is {{the most}} widely {{implemented}} <b>low-level</b> networking <b>technology</b> used today, with Gigabit Ethernet seen as the emerging standard implementation. The backbones of many large scale networks (e. g., data centers, metro-area deployments) are increasingly made up of Gigabit Ethernet as the underlying technology, and Ethernet is seeing increasing use in dynamic and failure-prone settings (e. g., wireless backhaul, developing regions) with high rates of churn. Correspondingly, when using simulation to study such networks and applications that run on them, the switching makes up a significant fraction of the model, and can make up {{a significant amount of}} the simulation activity. This work describes a unique testbed that gathers highly accurate measurements of loss and latency through a switch, reports on experiments that reveal the behavior of three commercial switches, and then proposes simulation models that explain the observed data. The models vary in their computational complexity and in their accuracy with respect to frame loss patterns, and latency through the switch. In particular, the simplest model predicts a frame???s loss and latency immediately {{at the time of its}} arrival, which keeps the computational cost close to one event per frame per switch, provides excellent temporal separation between switches (useful for parallel simulation), and provides excellent accuracy for loss and adequate accuracy for latency...|$|R
40|$|Problems {{associated}} with instruments {{used to measure}} low levels of NO₂ include non-specificity, low sensitivity, and an uncharacterized dependence on environmental conditions. MDA Scientific has recently introduced a continuous colorimetric tape technique (chemcassette) to monitor for pollutant gases. Advantages of this technology include ease of use, fast-response alarm capability, and adaptability to measure different pollutants. This research characterized and compared chemcassette performance for NO₂ with other <b>low-level</b> NO₂ monitoring <b>technologies</b> including the luminox LMA- 3 monitor and the EPA reference CSI chemiluminescnt monitor. The test protocol was based on EPA procedures. The chemcassette {{was found to be}} sensitive to temperature and relative humidity effects. The chemiluminescent monitor had the best overall performance. The luminox monitor displayed temperature dependence. Variation in stability of the chemcassette optical system, tape paper uniformity, and possible interference from ozone were characterized. (Abstract shortened with permission of author. ...|$|R
40|$|Following recent {{technological}} advances in diverse mobile devices, including smartphones, tablets and smartwatches, in-depth studies {{aimed at improving}} the quality of augmented reality (AR) are currently ongoing. Smartphones feature the essential elements of AR implementation, such as a camera, a processor and a display in a single device. As a result, additional hardware expansion for AR implementation has become unnecessary, popularizing AR technology at the user level. In the early stages, <b>low-level</b> AR <b>technology</b> was used mainly in limited fields, including simple road guides and marker-based recognition. Due to advances in AR technology, the range of usage has expanded as diverse technologies and purposes are combined. Users’ expectations of AR technology have also increased with this trend, and a high quality of service (QoS), with high-resolution, high-quality images, is now available. However, there are limitations in terms of processing speed and graphic treatment with smart devices, which, due to their small size, have inferior performance compared to the desktop environment when processing data for the implementation of high-resolution, high-quality images. This paper proposes an optional frame-selection algorithm (OFSA), which eliminates the unnecessary work involved with redundant frames during rendering for adaptive symmetric service of augmented reality big data on smart devices. Moreover, the memory read-write delay of the internally-operating OFSA, is minimized by adding an adaptive operation function. It is possible to provide adaptive common AR images at an improved frame rate in heterogeneous smart devices with different levels of performance...|$|R
30|$|The {{ubiquity of}} {{technology}} {{calls for a}} shift away from <b>low-level</b> use of <b>technology,</b> such as drilling, practice and looking up information. Rather, smart education encourages a ‘high-level’ use of technology, utilising it as a ‘mind tool’ or ‘intellectual partner’ for creativity, collaboration and multimedia productivity. Technology must enable and accelerate learning relationships between teachers and students and between students and other learning partners, such as peers, mentors and others with similar learning interests. Deep learning tasks re-structure learning activities from a singular focus on content mastery to the explicit development of students’ capacities to learn, create and proactively implement their learning. In their most effective instances, deep learning tasks are guided by clear and appropriately challenging learning goals, which ideally incorporate both curricular content and students’ interests or aspirations; include specific and precise success criteria that help both teacher and student know how well the goals are being achieved; and, incorporate feedback and formative evaluation cycles into the learning and doing processes, building students’ self-confidence and proactive dispositions.|$|R
40|$|Current {{wireless}} networks commonly {{consist of}} nodes with different capabilities (e. g., laptops and PDAs). Link quality such as link error rate and data transmit rate can differ widely. For efficient operation, {{the design of}} wireless networks {{must take into account}} such heterogeneity among nodes and wireless links. We present systematic approaches to overcome problems due to heterogeneous node capability and link quality in wireless networks. We first present a general frame-work called WISE (Wireless Integration Sublayer Extension) that abstracts specific details of <b>low-level</b> wireless communication <b>technologies</b> (e. g., modulation or backoff scheme). WISE provides a set of common primitives, based on which upper-level protocols can operate efficiently without knowing the underlying details. We also present a number of protocol extensions that employ the WISE framework to enhance the performance of specific upper-level protocols while hiding lower-level heterogeneity (e. g., link error rate). Our multihop WLAN architecture improves system performance by allowing client nodes to use multihop paths via other clients to reach an AP. Our geographic routing extension considers both location and link quality in th...|$|R
40|$|The {{purpose of}} this study was to observe pre-kindergarten through fifth-grade public school {{classrooms}} to examine differences among instructional practices and technology use by teachers, students and the overall classroom. The current study differed from and built upon previous classroom observational research in a number of major ways. First, the observational data examined both student and teacher technology use and the availability of technology in the classroom. Second, authentic classroom behaviors were examined in relation to technology use; specifically, behaviors related to the impact of technology use on student engagement as well as differences among technology use in classrooms and differences by student socio-economic status. Finally, unlike previous studies, this study focused specifically on pre-kindergarten through fifth-grade classrooms from the same large public school district that was diverse by both socio-economic status (SES) and by student ethnicity. Overall, the results of this study suggest that technology has not been adequately implemented into the observed classrooms. Technology was available but was not used to a great extent. When technology was implemented, teachers were primarily observed using it to present material and students were observed using it almost exclusively for basic skills activities. This <b>low-level</b> of <b>technology</b> integration occurred in elementary schools of a high performing school district which had a technology plan in place, a low student to computer ratio, and 100 percent of the classrooms had Internet access. Furthermore, only 15 percent of teachers were observed integrating technology to a great extent; however, students in these classrooms were observed on task significantly more frequently than students in classrooms where technology was observed less or not at all. On the other hand, students were observed off task significantly more in classrooms where either no technology integration was observed or where it was only observed a moderate amount. These findings support and build upon previous observational studies. There is still a need, however, for strong, empirical research to be conducted to further examine the use of technology in elementary classrooms...|$|R
40|$|Agricultural {{products}} are indispensable components of daily life. Nowadays, most cities in China, food supply is already setup, however the whole {{food supply chain}} is quite long with low efficiency. After the harvest of agricultural products, they have been transported to multi-hierarchical markets and go through plurality sales links by simple vehicles before meeting consumer. Due {{to the existence of}} an imperfect agricultural product supply system, specifically the inadequate infrastructure for cold-chain transportation and <b>low-level</b> storage <b>technology,</b> agricultural products and aquatic products, among others, suffer huge loss rates ranging from 15 % to 30 % during picking, transportation, and storage as well as during processing in other logistics sectors. Thus, some unscrupulous producers or agents add preservatives to the agricultural products in order to keep them looks with good quality. Besides, for the producers, though they do their utmost for farming and cultivating，they still living {{at the bottom of the}} social ladder with low income. For the consumer, owing to the increasing standard of living, the improvement of the logistical system and the structural adjustment of modern agricultural products, more and more consumers no longer just pursue the goal of having sufficient food to eat. Instead, they hope to eat better and healthier and prefer fresher or more diverse food options with high quality and nutrition. This thesis aims to study the existing agricultural product system in Guangzhou, focusing on the agricultural products supply model and discusses ways to revolutionize the “farm-to-table” agricultural products channel by proposing a new supply model in a regional scale to narrow the gap between consumer and producer in two main methods. On one hand, establish Agricultural Association to coordinate the whole system and guide the local farmer cultivate agricultural product and deliver their product to the consumer with high efficiency. On the other hand, attract the costumer come to productive area that they not only get the product directly but also understand the process of production. In these ways can guarantee the safety, freshness, and nutritional value of agricultural products, improve farmer’s income and satisfied consumer’s requirement by achieving a high-efficiency, low-pollution and energy-saving “farm-to-table” channel for local agricultural products. published_or_final_versionArchitectureMasterMaster of Landscape Architectur...|$|R
40|$|Over {{the last}} years the ever-growing demand for higher {{performance}} has led to much interest in using nonlinear circuit concepts for electronic circuit design. For this {{we have to deal}} with analysis and synthesis of dynamic nonlinear circuits. This thesis proposes to handle the nonlinear design complexity by dividing the design process in two steps. In the first step, a high-level synthesis/analysis step, a circuit topology implementing the wanted (nonlinear) function is found. We conclude that an expansion in basic functions, chosen to fit the nonlinear building blocks used, appears to be the best option for implementing this step. The second step consists of a low-level analysis/synthesis step, in which the quality of the topology is determined. The thesis research has focused on using the linear time-varying (LTV) small-signal model for describing the dynamic behaviour of nonlinear circuits in the context of low-level analysis/synthesis. This model is a generalization of the conventional linear time-invariant small-signal model and allows the use of equivalent stability criterions. Linear eigenvalues and poles are generalized to dynamic eigenvalues, Floquet exponents and Lyapunov exponents. The LTV small-signal model decreases low-level modeling complexity by using knowledge from the high-level step. The linear time-varying approach was applied to various specific nonlinear circuits: a negative feedback amplifier with class-B output stage, a dynamic translinear filter and oscillator and a differential pair used as a limiter. These design examples show that the linear time-varying approach is a good modeling candidate for <b>low-level</b> synthesis/analysis. Information <b>Technology</b> and System...|$|R
40|$|Twenty-first century Field-Programmable Gate Arrays (FPGAs) are {{no longer}} used for {{implementing}} simple “glue logic” functions. They have become complex arrays of reconfigurable logic resources and memories as well as highly optimised functional blocks, capable of implementing large systems on a single chip. Moreover, Dynamic Partial Reconfiguration (DPR) capability permits to adjust some logic resources on the chip at runtime, whilst the rest are still performing active computations. During the last few years, DPR has become a hot research topic {{with the objective of}} building more reliable, efficient and powerful electronic systems. For instance, DPR can be used to mitigate spontaneously occurring bit upsets provoked by radiation, or to jiggle around the FPGA resources which progressively get damaged as the silicon ages. Moreover, DPR is the enabling technology for a new computing paradigm which combines computation in time and space. In Reconfigurable Computing (RC), a battery of computation-specific circuits (“hardware tasks”) are swapped {{in and out of the}} FPGA on demand to hold a continuous stream of input operands, computation and output results. Multitasking, adaptation and specialisation are key properties in RC, as multiple swappable tasks can run concurrently at different positions on chip, each with custom data-paths for efficient execution of specific computations. As a result, considerable computational throughput can be achieved even at low clock frequencies. However, DPR penetration in the commercial market is still testimonial, mainly due to the lack of suitable high-level design tools to exploit this technology. Indeed, currently, special skills are required to successfully develop a dynamically reconfigurable application. In light of the above, this thesis aims at bridging the gap between high-level application and <b>low-level</b> DPR <b>technology.</b> Its main objective is to develop Operating System (OS) -like support for high-level software-centric application developers in order to exploit the benefits brought about by DPR technology, without having to deal with the complex low-level hardware details. The developed solution in this thesis is named as R 3 TOS, which stands for Reliable Reconfigurable Real-Time Operating System. R 3 TOS defines a flexible infrastructure for reliably executing reconfigurable hardware-based applications under real-time constraints. In R 3 TOS, the hardware tasks are scheduled in order to meet their computation deadlines and allocated to non-damaged resources, keeping the system fault-free at all times. In addition, R 3 TOS envisages a computing framework whereby both hardware and software tasks coexist in a seamless manner, allowing the user to access the advanced computation capabilities of modern reconfigurable hardware from a software “look and feel” environment. This thesis covers all of the design and implementation aspects of R 3 TOS. The thesis proposes a novel EDF-based scheduling algorithm, two novel task allocation heuristics (EAC and EVC) and a novel task allocation strategy (called Snake), addressing many RC-related particularities as well as technological constraints imposed by current FPGA technology. Empirical results show that these approaches improve on the state of the art. Besides, the thesis describes a novel way to harness the internal reconfiguration mechanism of modern FPGAs to performinter-task communications and synchronisation regardless of the physical location of tasks on-chip. This paves the way for implementing more sophisticated RC solutions which were only possible in theory in the past. The thesis illustrates R 3 TOS through a proof-of-concept prototype with two demonstrator applications: (1) dependability oriented control of the power chain of a railway traction vehicle, and (2) datastreaming oriented Software Defined Radio (SDR) ...|$|R
40|$|Doctor of PhilosophyCurriculum and Instruction ProgramsDavid S. AllenHaijun KangUsing {{technology}} effectively {{has been}} proven to enhance education. The status quo in Saudi Arabia reflects <b>low-level</b> usage of <b>technology</b> in K- 12 classrooms. Preparing 21 st Century teachers to integrate technology in their future classrooms for meaningful learning requires College of Education faculty to model using technology effectively. This study investigated the technology integration practices of faculty members in the College of Education at Taibah University, particularly to what extent these practices are aligned with ISTE NETS-T standards and what factors predict these practices. Based on the literature, the factors examined include attitudes towards technology use, pedagogical beliefs, technical skills, workload, professional development, technology access, technical support, and leadership support. The population {{of the study was}} the 257 faculty in the College of Education at Taibah University. The study used a web-based survey containing 66 closed-ended items to collect data, and 170 valid responses were obtained (66 % response rate). Descriptive and multiple linear regression analyses were conducted to analyze data. Findings from the first research question revealed that faculty members’ technology integration practices were well-matched with ISTE NETS-T standards since the overall mean of these items was (M= 4. 25, SD=. 64). This indicates that faculty members had awareness of using technology effectively based on these standards to engage students in meaningful learning. Results from the multiple linear regression analysis revealed that the overall model was significant as it explains 43 % of the variability in faculty members’ technology integration practices. Three significant factors statistically predicted faculty members’ technology integration practices based on ISTE NETS standards. Faculty members’ attitude toward technology had a positive relationship with faculty members’ technology integration practices [β=. 35, p=. 00]. Faculty technical skills had also a statistically significant positive relationship with faculty members’ technology integration practices [β=. 19, p=. 00]. However, leadership support was found to have a statistically significant negative relationship with faculty members’ technology integration practices in teaching based on ISTE NETS-T standards [β=-. 23, p=. 00]. These results, in addition to the means of the independent variables, showed that the highly rated technology integration factors, including technology attitudes and technical skills, predict their high technology integration practices based on ISTE NET-T standards. However, faculty members still need more support in several technology integration factors including professional development, technology access, workload, and leadership support. The study recommends education faculty members to model the effective use of technology for pre-service teachers through providing them with opportunities to observe it in a variety of instructional models and practice the constructivist use of technology in lesson plan assignments and projects during the program, which helps in developing positive attitudes toward technology use among pre-service teachers. College of Education leaders are recommended to have a clear shared technology vision and offer the resources and support needed to make instructional technology integration successful. Recommendations for future studies are also discussed...|$|R

