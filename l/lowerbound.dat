97|36|Public
5000|$|... {{function}} MTDF(root, f, d) g := f upperBound := +∞ <b>lowerBound</b> := -∞ while <b>lowerBound</b> < upperBound β := max(g, lowerBound+1) g := AlphaBetaWithMemory(root, β-1, β, d) if g < β then upperBound := g [...] else <b>lowerBound</b> := g return g" [...] f [...] " [...] : {{first guess}} for best value. The best the quicker algorithm converges. Could be 0 for first call." [...] d [...] " [...] : depth to loop for. An iterative deepening depth-first search {{could be done}} by calling MTDF (...) multiple times with incrementing [...] "d" [...] and providing the best previous result in [...] " [...] f [...] ".|$|E
5000|$|In {{statistics}} (classical test theory), Cronbach's [...] (alpha) is the {{trivial name}} used for tau-equivalent reliability (...) as a (<b>lowerbound)</b> {{estimate of the}} reliability of a psychometric test. Synonymous terms are: coefficient alpha, Guttman's , Hoyt method and KR-20.|$|E
5000|$|... {{function}} negamax(node, depth, α, β, color) alphaOrig := α [...] // Transposition Table Lookup; node is the lookup key for ttEntry ttEntry := TranspositionTableLookup( [...] node [...] ) if ttEntry {{is valid}} and ttEntry.depth ≥ depth if ttEntry.Flag = EXACT return ttEntry.Value else if ttEntry.Flag = <b>LOWERBOUND</b> α := max( [...] α, ttEntry.Value) else if ttEntry.Flag = UPPERBOUND β := min( [...] β, ttEntry.Value) endif if α ≥ β return ttEntry.Value endif [...] if depth = 0 or node is a terminal node return color * the heuristic value of node [...] bestValue := -∞ childNodes := GenerateMoves(node) childNodes := OrderMoves(childNodes) foreach child in childNodes v := -negamax(child, depth - 1, -β, -α, -color) bestValue := max( [...] bestValue, v [...] ) α := max( [...] α, v [...] ) if α ≥ β break [...] // Transposition Table Store; node is the lookup key for ttEntry ttEntry.Value := bestValue if bestValue ≤ alphaOrig ttEntry.Flag := UPPERBOUND else if bestValue ≥ β ttEntry.Flag := <b>LOWERBOUND</b> else ttEntry.Flag := EXACT endif ttEntry.depth := depth [...] TranspositionTableStore( [...] node, ttEntry [...] ) [...] return bestValue ...|$|E
3000|$|... is defined. By {{means of}} algebraic,analytic, {{geometric}} and inequality theories, we obtain several sharp <b>lowerbounds</b> involving the circuit layout system.|$|R
40|$|International audienceWe use {{game theory}} {{techniques}} to automatically compute improved <b>lowerbounds</b> on the competitive ratio for the bin stretching problem. Using these techniques,we improve the best lower bound for this problem to 19 / 14. We explain the techniqueand {{show that it}} can be generalized to compute lower bounds for any online or semi-online packing or scheduling problem...|$|R
40|$|We {{consider}} computations of a Turing machine under {{noise that}} causes {{violations of the}} transition function. Given an upper bound β {{on the size of}} bursts of faults, we construct a Turing machine M (β) subject to faults that can simulate any fault-free machine under the condition that the time between bursts is <b>lowerbounded</b> by O(β 2). ...|$|R
30|$|A system load metric (e.g., CPU utilization) and the {{corresponding}} thresholds: <b>lowerBound</b> and upperBound (e.g., CPU utilization between 75  % and 85  %).|$|E
40|$|There {{are many}} {{algorithms}} to compute an upperbound, a <b>lowerbound</b> or the exact treewidth of a graph. We have implemented {{a lot of}} upperbound and <b>lowerbound</b> heuristics and two exact algorithms (a Dynamic Programming and a Branch and Bound algorithm). This report compares the different kind of algorithms and shows that some algorithms are preferred. From our results with the <b>lowerbound</b> algorithms we can conclude that the Least-C variant for Maximum Minimum Degree almost dominates the other algorithms. For the upperbounds, we conclude that Greedy-FillIn is best. TreewidthDP is quite fast {{on most of the}} tested graphs, but runs out of memory on large graphs. If TreewidthDP can not run with the available amount of memory one could use QuickBB, which is slower, but uses less memory. We investigated the effects of the Memorization method on QuickBB suggested by Van Hoesel and found that it improved the algorithm with at least factor 15. ...|$|E
40|$|Abstract. We {{investigate}} {{the problem of}} finding an unknown cut through querying vertices of a graph G. Our complexity measure {{is the number of}} submitted queries. To avoid some worst cases, we make a few assump-tions which allow us to obtain an algorithm with the worst case query complexity of O(k) + 2 k log n k in which k is the number of vertices ad-jacent to cut-edges. We also provide a matching <b>lowerbound</b> and then prove if G is a tree our algorithm can asymptotically achieve the informa-tion theoretic <b>lowerbound</b> on the query complexity. Finally, we show it is possible to remove our extra assumptions but achieve an approximate solution. ...|$|E
40|$|Proof (Part ii) : Since f(t) is a nondecreasing {{function}} of t, (1) and (2) yield E[d(X%) ] ” Y 2 f(n) E”%l (1 - 6 (X,&) n (t=o 1 -> f(n) E[l- 6 (X,&] n = P,f (n) /n. (5) For equally probable source vectors, Theorem l-ii <b>lowerbounds</b> P, and thus E [d,,(X,&] 1 f * exp [- n[E,,(R- ol(n)) + o,(n) ]]. (6...|$|R
40|$|Abstract. We {{consider}} scheduling {{problems in}} which a job consists of components of different types to be processed on m machines. Each machine is capable of processing components of a single type. Different components of a job are independent and can be processed in parallel on different machines. A job is considered as completed only when all its components have been completed. We study both completion time and flowtime aspects of such problems. We show both <b>lowerbounds</b> and upperbounds for the completion time problem. We first show that even the unweighted completion time with single release date is MAX-SNP hard. We give an approximation algorithm based on linear programming which has an approximation ratio of 3 for weighted completion time with multiple release dates. We give online algorithms for the weighted completion time which are constant factor competitive. For the flowtime, we give only <b>lowerbounds</b> in both the offline and online settings. We show that it is NP-hard to approximate flowtime within Ω(log m) intheoffline setting. We show that no online algorithm for the flowtime can have a competitive ratio better than Ω (√ m). ...|$|R
40|$|Timed Petri nets {{can be used}} {{to model}} and analyse {{scheduling}} problems. To support the modelling of scheduling problems, we provide a method to map tasks, resources and constraints onto a timed Petri net. By mapping scheduling problems onto Petri nets, we are able to use standard Petri net theory. In this paper we will show that we can use Petri net based tools and techniques to find conflicting and redundant precedences, upper- and <b>lowerbounds</b> for the makespan, etc. This is illustrated by a Petri net based analysis of the notorious 10 × 10 problem due to Fisher & Thompson (1963) ...|$|R
40|$|We {{present an}} idling, dynamic {{priority}} scheduling policy for non-preemptive task sets with precedence, wait constraints, and deadline constraints. The policy operates on a well-formed task model where tasks are related through a hierarchical temporal constraint structure {{found in many}} real-world applications. In general, the problem of sequencing according to both upperbound and <b>lowerbound</b> temporal constraints requires an idling scheduling policy and {{is known to be}} NP-complete. However, we show through empirical evaluation that, for a given task set, our polynomial-time scheduling policy is able to sequence the tasks such that the overall duration required to execute the task set, the makespan, is within a few percent of the theoretical, <b>lowerbound</b> makespan. I...|$|E
30|$|InputVariables.txt. This file {{contains}} all {{information regarding the}} input parameters in the optimisation problem (variables x in Eq. (1)). They {{can be defined as}} constant (variableName: value), variable within an interval (variableName: <b>lowerBound,</b> upperBound, increment), variable with predefined values extracted from a file (variableName: filename_columnName), or depending on other variables (variableName: expression).|$|E
40|$|This paper {{presents}} a bottleneck-based methodology to solve scheduling problem of M 1,M 2,M 3,M 4,M 3,M 4 re-entrant flow shop where M 1 and M 4 have high tendency {{of being the}} dominant machines. Two generalised makespan algorithms using bottleneck approach were developed for the identified bottleneck. Each algorithm has specific correction factor which was used to ensure {{the accuracy of the}} makespan computation. Using these correction factors, a constructive heuristic was developed to solve for near-optimal scheduling sequence. For small size problems, the heuristic results were compared with the optimum makespan generated from complete enumeration. For medium and large size problems, the heuristic performance was measured by comparing its makespan with the solutions generated by the NEH and <b>lowerbound.</b> At weak and strong dominance level, the heuristic shows good performance against the <b>lowerbound</b> and better results compared to the NEH for large and medium size problems...|$|E
40|$|We {{present an}} {{efficient}} approach to solve resource allocation {{problems with a}} single resource, a convex separable objective function, a convex separable resource-usage constraint, and variables that are bounded below and above. Through a combination of function evaluations and median searches, information {{on whether or not}} the upper- and <b>lowerbounds</b> are binding is obtained. Once this information is available for all upper and lower bounds, it remains to determine the optimum of a smaller problem with unbounded variables. This can be done through a multiplier search procedure. The information gathered allows for alternative approaches for the multiplier search which can reduce the complexity of this procedure. © 2011 The Author(s) ...|$|R
40|$|Abstract. We {{present an}} exact method {{for the global}} minimum energy {{conformation}} (GMEC) search of protein side-chains. Our method consists of a branch-and-bound (B&B) framework and a new subproblempruning scheme. The pruning scheme consists of upper/lower-bounding methods and problem-size reduction techniques. We explore a way of using the tree-reweighted max-product algorithm for computing <b>lowerbounds</b> of the GMEC energy. The problem-size reduction techniques are necessary when {{the size of the}} subproblem is too large to rely on more accurate yet expensive bounding methods. The experimental results show our pruning scheme is effective and our B&B method exactly solves protein sequence design cases that are very hard to solve with the dead-end elimination. ...|$|R
40|$|Algorithms which compute {{properties}} over graphs {{have always}} been of interest in computer science, {{with some of the}} fundamental algorithms, such as Dijkstra's algorithm, dating back to the 50 s. Since the 70 s there as been interest in computing over graphs which are constantly changing, in a way which is more efficient than simple recomputing after each time the graph changes. In this paper we provide a survey of both the foundational, and the state of the art, algorithms which solve either shortest path or transitive closure problems in either fully or partially dynamic graphs. We balance this with the known conditional <b>lowerbounds.</b> Comment: 17 pages, 3 figure...|$|R
40|$|The {{assessment}} {{of the number of}} dimensions and the dimensionality structure of questionnaire data is important in scale evaluation. In this study, the authors evaluate two dimensionality assessment procedures in the context of Mokken scale analysis (MSA), using a so-called fixed <b>lowerbound.</b> The comparative simulation study, covering various theoretically and empirically relevant conditions, indicates that the MSA procedures may result in scales that are inconsistent with the dimensionality of the data set at hand. That is, a single Mokken scale can be multidimensional, and two Mokken scales can pertain to a single dimension. In an illustrative evaluation, MSA using a range of lowerbounds, rather than a fixed <b>lowerbound,</b> was shown to have some benefits, but not to solve all limitations. The results of this study imply that MSA is perfectly suitable to create Mokken scales. However, MSA appears of limited value as a dimensionality assessment method...|$|E
40|$|In {{this paper}} {{we present a}} {{systematic}} technique for obtaining all the input sequences that are mapped by a given permutation either to themselves or to shifted versions of themselves (generically called permutation fixed points). Subsequently, we present {{a new class of}} permutations that nearly achieve the <b>lowerbound</b> on the number of possible fixed points associated with a given permutation of prime length p...|$|E
40|$|We {{examine the}} {{relationship}} between running time and error of parallel sorting algorithms. This is done by applying Hastad's main lemma to relate the size depth and error of simple circuits, that sort an input of 0 's and 1 's. As a consequence, we obtain lower bounds for approximate counting as well. 1 1 Introduction Recently, {{attempts have been made to}} sidestep the <b>lowerbound</b> of Beame and Hastad [1], by separating the sorting problem from the list ranking problem. These attempts have been of two kinds - chain sorting, i. e., sorting the elements into a linked list [2], and padded sorting, i. e., sorting into a larger array [3, 5, 6]. The algorithms in [5] require the elements to be uniformly distributed in a certain range, whereas the algorithms in [3, 6] are for the general case. The question we examine here, is what must the size of the output array be, if the <b>lowerbound</b> of [1] must be circumvented? In other words, if an algorithm sorts n items using polynomially many processors in [...] ...|$|E
40|$|Abstract—Unate and binate {{covering}} {{problems are}} a special class of general integer linear programming problems with which several problems in logic synthesis, such as two-level logic minimization and technology mapping, are formulated. Previous branch-and-bound methods for exactly solving these problems use lower-bounding techniques based on finding maximal independent sets. In this paper we examine <b>lowerbounding</b> techniques based on linear programming relaxation (LPR) for the binate covering problem. We {{show that a}} combination of traditional reductions (essentiality and dominance) and incremental computation of LPR-based lower bounds can exactly solve difficult covering problems orders of magnitude faster than traditional methods. Keywords—Covering problems, integer linear programming I...|$|R
40|$|We {{describe}} and motivate a proposed {{new approach to}} <b>lowerbounding</b> the circuit complexity of boolean functions, based on a new formalization of "patterns" as elements of a special basis of the vector space of all truth table properties. We prove that a "pattern basis" with certain properties {{would lead to a}} useful complexity formula of a specific form, and speculate on how to find such a basis. This formula might take as long to compute on arbitrary functions as a brute-force search among circuits, thus addressing the natural proofs barrier, but has a form amenable to proving lower bounds for well-understood explicit functions. Comment: 101 pages, 4 figure...|$|R
40|$|A {{scheduling}} {{system is}} proposed and developed {{for a special}} type of flow shop. In this flow shop there is one machine at each stage. A job may require multiple operations at each stage. The first operation of a job on stage j cannot start until the last operation of the job on stage j- 1 has finished. Preemption of the operations of a job is not allowed. The flow shop that we consider has another feature, namely time lags between the multiple operations of a job. To move from one operation of a job to another requires a finite amount of time. This time lag is independent of the sequence and need {{not be the same}} for all operations or jobs. During a time lag of a job, operations of other jobs may be processed. This problem originates from a flexible manufacturing system scheduling problem where, between operations of a job on the same workstation, refixturing of the parts has to take place in a load/unload station, accompanied by (manual) transportation activities. In this paper a scheduling system is proposed in which the inherent structure of this flow shop is used in the formulation of <b>lowerbounds</b> on the makespan. A number of <b>lowerbounds</b> are developed and discussed. The use of those bounds makes it possible to generate a schedule that minimizes makespan or to construct approximate solutions. Finally, some heuristic procedures for this type of flow shop are proposed and compared with some well known heuristic scheduling rules for job shop/flow shop scheduling. 1...|$|R
40|$|We {{study the}} dynamic bin packing problem {{introduced}} by Coffman, Garey and John-son [7]. This {{problem is a}} generalization of the bin packing problem in which items may arrive and depart from the packing dynamically. The main result in this paper is a <b>lowerbound</b> of 2. 5 on the achievable competitive ratio, improving the best known 2. 428 <b>lowerbound</b> [3], and revealing that packing items of restricted form like unit fractions (i. e., of size 1 /k for some integer k), which can guarantee a competitive ratio 2. 4985 [3], is indeed easier. We also investigate the resource augmentation analysis on the problem where the online algorithm can use bins of size b (> 1) {{times that of the}} optimal off-line algorithm. An interesting result is that we prove b = 2 is both necessary and sufficient for the on-line algorithm to match the performance of the optimal off-line algorithm, i. e., achieve 1 -competitiveness. Further analysis is made to give a trade-off between the bin size multiplier band the achievable competitive ratio...|$|E
40|$|Black hole spacetimes are semiclassically not static. For {{black holes}} whose {{lifetime}} {{is larger than}} {{the age of the universe}} we compute, in leading order, the power spectrum of deviations of the electromagnetic charge from it's average value, zero. Semiclassically the metric itself has a statistical interpretation and we compute a <b>lowerbound</b> on its variance. (1 figure, at end in encapsulated postscript - to locate use 'find figs') Comment: 21 pages, 1 figure, MIT CTP# 222...|$|E
40|$|Rafail Ostrovsky z Quadratic residuosity and graph {{isomorphism}} are classic {{problems and}} the canonical examples of zero-knowledge languages. However, despite much research e ort, all previous zeroknowledge proofs for them required either cryptography (and thus unproven assumptions) or an unbounded number of rounds of message exchange. For both (and similar) languages, we exhibit zero-knowledge proofs that require 5 rounds and no unproven assumptions. Our solution is essentially optimal, in this setting, due to a recent <b>lowerbound</b> argument of Goldreich and Krawzcyk. ...|$|E
40|$|Motivated by the {{resurgence}} of neural networks {{in being able to}} solve complex learning tasks we undertake a study of high depth networks using ReLU gates which implement the function $x \mapsto \max\{ 0,x\}$. We try to understand the role of depth in such neural networks by showing size <b>lowerbounds</b> against such network architectures in parameter regimes hitherto unexplored. In particular we show the following two main results about neural nets computing Boolean functions of input dimension $n$, 1. We use the method of random restrictions to show almost linear, $\Omega(\epsilon^{ 2 (1 -\delta) }n^{ 1 -\delta}) $, lower bound for completely weight unrestricted LTF-of-ReLU circuits to match the Andreev function on at least $\frac{ 1 }{ 2 } +\epsilon$ fraction of the inputs for $\epsilon > \sqrt{ 2 \frac{\log^{\frac { 2 }{ 2 -\delta}}(n) }{n}}$ for any $\delta \in (0,\frac 1 2) $ 2. We use the method of sign-rank to show exponential in dimension lower bounds for ReLU circuits ending in a LTF gate and of depths upto $O(n^{\xi}) $ with $\xi < \frac{ 1 }{ 8 }$ with some restrictions on the weights in the bottom most layer. All other weights in these circuits are kept unrestricted. This in turns also implies the same <b>lowerbounds</b> for LTF circuits with the same architecture and the same weight restrictions on their bottom most layer. Along the way we also show that there exists a $\mathbb{R}^ n\rightarrow \mathbb{R}$ Sum-of-ReLU-of-ReLU function which Sum-of-ReLU neural nets can never represent no matter how large they are allowed to be...|$|R
40|$|Unate and binate {{covering}} {{problems are}} a special class of general integer linear programming problems with which several problems in logic synthesis, such as two-level logic minimization and technology mapping, are formulated. Previous branch-and-bound methods for exactly solving these problems use lower-bounding techniques based on finding maximal independent sets. In this paper we examine <b>lowerbounding</b> techniques based on linear programming relaxation (LPR) for the binate covering problem. We {{show that a}} combination of traditional reductions (essentiality and dominance) and incremental computation of LPR-based lower bounds can exactly solve difficult covering problems orders of magnitude faster than traditional methods. Keywords [...] -Covering problems, integer linear programming I. INTRODUCTION Covering problems (unate and binate) are important combinatorial optimization problems with which several problems in logic synthesis (such as two-level logic minimization [12], state minimiza [...] ...|$|R
40|$|Many {{computer}} systems have a functional requirement to release information. Such requirements {{are an important}} part of a system’s information security requirements. Current information-flow control techniques are able to reason about permitted information flows, but not required information flows. In this paper, we introduce and explore the specification and enforcement of required information release in a language-based setting. We define semantic security conditions that express both what information a program is required to release, and how an observer is able to learn this information. We also consider the relationship between permitted and required information release, and define bounded release, which provides upper- and <b>lowerbounds</b> on the information a program releases. We show that both required information release and bounded release can be enforced using a security-type system. 1...|$|R
40|$|Responding {{quickly and}} {{efficiently}} to dynamic disturbances is a crucial challenge in domains such as manufacturing, aerial and underwater vehicle tasking, and health care. In many cases, accurately capturing the complicated dependencies between tasks in these environments {{requires the use of}} upper and <b>lowerbound</b> temporal constraints (i. e, deadlines and wait constraints). However, optimally scheduling tasks related by upper and <b>lowerbound</b> temporal constraints is known to be NP-Hard. 3 While exact solution techniques exist to efficiently schedule resources, these techniques are computationally intractable for problems of interest with fifty or more tasks and five agents. Furthermore, techniques that seek to improve scalability often attempt to distribute the scheduling problem amongst the agents, where each agent generates its own schedule. 5 However, when agents must share unary-access resources (e. g., a spatial location that can be occupied by only one agent at a time), these techniques lose their advantage because the problems do not naturally lend themselves to decomposition. As a result, many techniques work by first finding an initial, though possibly infeasible, schedule through solving a relaxed version of the problem, and then repairing the schedule to resolve any constraint violations. National Science Foundation (U. S.). Graduate Research Fellowship Program (Grant 2388357...|$|E
40|$|Abstract We {{study the}} {{performance}} of wireless ad hoc networksin the limit {{of a large number}} of nodes. We first define ad hoc networks and their capacity. We then calculate a <b>lowerbound</b> on the capacity by constructing a communications scheme that achieves it. We also determine an upper boundon the capacity by investigating the properties of any transmission schedule. Bounds indicate that for a large numberof nodes n, the total network capacity increases with a ratebetween k 1 n 1 3 and k 2 n 1 2, while the per-node rate goes tozero...|$|E
40|$|In {{this paper}} we provide an {{eigenvalue}} placement methodology that guarantees asymptotic stability in a piecewise linear switched system where a <b>lowerbound</b> on the dwell time {{is known in}} advance. In particular, considering the case where each subsystem is a linear controllable system, we introduce an algorithm for placing the eigenvalues of each subsystem {{in such a way}} that the overall switched system is asymptotically stable. This is obtained defining a relationship between the dwell time and the stability properties of each subsystem. Simulations of a heterogeneous multi-robot system are provided for validation purposes...|$|E
40|$|We {{consider}} {{the problem of}} finding the largest {{of a set of}} n uniquely numbered processors, arranged in a ring, by means of an asyn- chronous distributed algorithm without a central controller With a technique of Frederickson and Lynch [8] the worst-case number of mes- sages, sent by arbitrary algorithms, that solve this problem is related to this number for algorithms that do not use operations on the processor-numbers other than mutual comparisons (=,, ,, 2). This result is used to answer a question, posed by Korach, Rotem and Santoro in 1981 [10], whether each extrema-finding algorithm that uses time n on a ring of n processors must use a quadratic number of messages; and to obtain better <b>lowerbounds</b> for the case that the size of the ring is known...|$|R
40|$|THE “BEST ” ALGORITHM FOR SOLVING STOCHASTIC MIXED INTEGER PROGRAMS We {{present a}} new {{algorithm}} for solving two-stage stochastic mixed-integer programs (SMIPs) having discrete first-stage variables, and continuous or discrete second-stage variables. For a minimizing SMIP, the BEST algorithm (1) computes an upper Bound on the optimal objective value (typically a probabilistic bound), and identifies a deterministic <b>lowerbounding</b> function, (2) uses the bounds to Enumerate {{a set of}} first-stage solutions that contains an optimal solution with pre-specified confidence, (3) for each first-stage solution, Simulates second-stage operations by repeatedly sampling random parameters and solving the resulting model instances, and (4) applies statistical Tests (e. g., “screening procedures”) to the simulated outcomes to identify a nearoptimal first-stage solution with pre-specified confidence. We demonstrate the algorithm’s performance on a stochastic facility-location problem. ...|$|R
40|$|An {{incremental}} depth-first algorithm for computing the S- and G-set of Mitchell's Candidate Elimination and Mellish's Description Identification {{algorithm is}} presented. As in Mellish's approach, <b>lowerbounds</b> (examples) {{as well as}} upperbounds can be handled. Instead of storing the complete S- and G-sets, only one element s {{is an element of}} S and g is an element of G is stored, together with backtrack information. The worst-case space complexity of our algorithm is linear in the number of lower- and upperbounds. For the Candidate Elimination algorithm this can be exponential. We introduce a test for membership of S and G with a number of coverage tests linear in the number of examples. Consequently the worst-case time complexity to compute S and G for each example is only a linear factor worse than the Candidate Elimination algorithm's. status: publishe...|$|R
