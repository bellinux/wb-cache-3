27|92|Public
50|$|A {{unification}} {{of many of}} the above mentioned imprecise probability theories was proposed by Walley, although this is in no way the first attempt to formalize imprecise probabilities. In terms of probability interpretations, Walley’s formulation of imprecise probabilities is based on the subjective variant of the Bayesian interpretation of probability. Walley defines upper and lower probabilities as special cases of upper and lower previsions and the gambling framework advanced by Bruno de Finetti. In simple terms, a decision maker’s <b>lower</b> <b>prevision</b> is the highest price at which the decision maker is sure he or she would buy a gamble, and the upper prevision is the lowest price at which the decision maker is sure he or she would buy the opposite of the gamble (which is equivalent to selling the original gamble). If the upper and lower previsions are equal, then they jointly represent the decision maker’s fair price for the gamble, the price at which the decision maker is willing to take either side of the gamble. The existence of a fair price leads to precise probabilities.|$|E
40|$|Abstract. The {{conditions}} under which a 2 -monotone <b>lower</b> <b>prevision</b> can be uniquely updated (in the sense of focusing) to a conditional <b>lower</b> <b>prevision</b> are determined. Then a number of particular cases are investigated: completely monotone lower previsions, for which equivalent conditions {{in terms of the}} focal elements of the associated belief function are established; random sets, for which some conditions in terms of the measurable selections can be given; and minitive lower previsions, which are shown to correspond to the particular case of vacuous lower previsions...|$|E
40|$|We extend de Finetti's (1937) {{notion of}} exchangeability to finite and {{countable}} sequences of variables, when a subject's beliefs about them are modelled using coherent lower previsions rather than (linear) previsions. We prove representation theorems {{in both the}} finite and the countable case, in terms of sampling without and with replacement, respectively. We also establish a convergence result for sample means of exchangeable sequences. Finally, we study and {{solve the problem of}} exchangeable natural extension: how to find the most conservative (point-wise smallest) coherent and exchangeable <b>lower</b> <b>prevision</b> that dominates a given <b>lower</b> <b>prevision.</b> Comment: 1 figure. 26 pages. Submitted for publicatio...|$|E
40|$|Coherent {{upper and}} <b>lower</b> <b>previsions</b> are {{becoming}} more and more popular as a mathematical model for robust valuations under uncertainty. Likewise, the mathematically equivalent class of coherent risk measures is attracting a lot attention in mathematical finance. In this paper, we show that a misinterpretation of upper previsions demands a closer examination of the basis of the theory of imprecise previsions. As a consequence, we obtain a new interpretation of coherent <b>lower</b> <b>previsions</b> as fair prices, a class of coherent variability measures, and a new type of conditioning for coherent <b>lower</b> <b>previsions...</b>|$|R
40|$|This {{paper is}} devoted to the {{extension}} of conditional assessments that satisfy some consistency criteria, such as weak or strong coherence, to further domains. In particular, we characterise the natural extension of a number of conditional <b>lower</b> <b>previsions</b> on finite spaces, by showing that it can be calculated as the limit of a sequence of conditional <b>lower</b> <b>previsions</b> defined by regular extension. Our results are valid for conditional <b>lower</b> <b>previsions</b> with non-linear domains, and allow us to give an equivalent formulation of the notion of coherence in terms of credal sets...|$|R
40|$|<b>Lower</b> <b>previsions</b> defined on {{a finite}} set of gambles can {{be looked at}} as points in a finite-dimensional real vector space. Within that vector space, the sets of sure loss {{avoiding}} and coherent <b>lower</b> <b>previsions</b> form convex polyhedra. We present procedures for obtaining characterizations of these polyhedra {{in terms of a}} minimal, finite number of linear constraints. As compared to the previously known procedure, these procedures are more efficient and much more straightforward. Next, {{we take a look at}} a procedure for correcting incoherent <b>lower</b> <b>previsions</b> based on pointwise dominance. This procedure can be formulated as a multi-objective linear program, and the availability of the finite characterizations provide an avenue for making these programs computationally feasible...|$|R
40|$|We {{study the}} {{extension}} of coherent lower previsions from the set of bounded random variables to a larger set. An ad hoc method in the literature consists in approximating an unbounded random variable by a sequence of bounded ones. Its ‘extended’ <b>lower</b> <b>prevision</b> is then defined as the limit of the sequence of lower previsions of its approximations. We identify the random variables for which this limit {{does not depend on}} the details of the approximation, and call them previsible. We thus extend a <b>lower</b> <b>prevision</b> to previsible random variables, and we study the properties of this extension. We also consider the special case of super-modular lower previsions...|$|E
40|$|Given a {{coherent}} <b>lower</b> <b>prevision</b> P, {{we consider the}} problem of computing the smallest coherent <b>lower</b> <b>prevision</b> F ≥ P that is conglomerable, in case it exists. F is called the conglomerable natural extension. Past work has showed that F can be approximated by an increasing sequence (E n) n∈N of coherent lower previsions. We close an open problem by showing that this sequence can be made of infinitely many distinct elements. Moreover, we give sufficient conditions, of quite broad applicability, {{to make sure that}} the point-wise limit of the sequence is F in case P is the lower envelope of finitely many linear previsions. In addition, we study the question of the existence of F and its relationship with the notion of marginal extension...|$|E
40|$|We {{investigate}} {{a number of}} factorisation conditions in the frame- work of sets of probability measures, or coherent lower previsions, with finite referential spaces. We show that the so-called strong product constitutes one way to combine a number of marginal coherent lower previsions into an independent joint <b>lower</b> <b>prevision,</b> and we prove that under some conditions {{it is the only}} independent product that satisfies the factorisation conditions...|$|E
40|$|We {{consider}} {{the task of}} proving Walley’s (joint or strong) coherence {{of a number of}} probabilistic assessments, when these assessments are represented as a collection of conditional <b>lower</b> <b>previsions.</b> In order to maintain generality in the analysis, we assume to be given nearly no information about the numbers that make up the <b>lower</b> <b>previsions</b> in the collection. Under this condition, we investigate {{the extent to which the}} above global task can be decomposed into simpler and more local ones. This is done by introducing a graphical representation of the conditional <b>lower</b> <b>previsions,</b> that we call the coherence graph: we show that the coherence graph allows one to isolate some subsets of the collection whose coherence is sufficient for the coherence of all the assessments. The situation is shown to be completely analogous in the case of Walley’s notion of weak coherence, for which we prove in addition that the subsets found are optimal, in the sense that they embody the maximal degree to which the task of checking weak coherence can be decomposed. In doing all of this, we obtain a number of related results: we give a new characterisation of weak coherence; we characterise, by means of a special kind of coherence graph, when the local notion of separate coherence is sufficient for coherence; and we provide an envelope theorem for collections of <b>lower</b> <b>previsions</b> whose graph is of the latter type. Keywords. Walley’s strong and weak coherence, coherent <b>lower</b> <b>previsions,</b> graphical models, coherence graph. ...|$|R
40|$|AbstractWe generalise Walley’s Marginal Extension Theorem to {{the case}} of any finite number of {{conditional}} <b>lower</b> <b>previsions.</b> Unlike the procedure of natural extension, our marginal extension always provides the smallest (most conservative) coherent extensions. We show that they can also be calculated as lower envelopes of marginal extensions of conditional linear (precise) previsions. Finally, we use our version of the theorem to study the so-called forward irrelevant product and forward irrelevant natural extension of a number of marginal <b>lower</b> <b>previsions...</b>|$|R
40|$|We study n-monotone <b>lower</b> <b>previsions,</b> which {{constitute}} a generalisation of n-monotone lower probabilities. We investigate their {{relation with the}} concepts of coherence and natural extension in the behavioural theory of imprecise probabilities, and improve along the way upon a number of results from the literature. Finally, we indicate how many approaches to integration in the literature fall squarely {{within the framework of}} the present study of coherent n-monotone <b>lower</b> <b>previsions.</b> This discussion allows us to characterise which types of integrals can be used to calculate the natural extension of a probability charge...|$|R
40|$|The credal set {{operator}} is {{studied as}} a set-valued mapping that assigns {{the set of}} dominating probabilities to a coherent <b>lower</b> <b>prevision</b> on some set of gambles. It is shown that this mapping is affine on certain classes of coherent lower previsions, which enables to find a decomposition of credal sets. Continuity of the credal set operator is investigated on finite universes {{with the aim of}} approximating credal sets...|$|E
40|$|ABSTRACT. We prove {{weak and}} strong laws {{of large numbers}} for {{coherent}} lower previ-sions, where the <b>lower</b> <b>prevision</b> of a random variable is given a behavioural interpretation as a subject’s supremum acceptable price for buying it. Our laws are {{a consequence of the}} rationality criterion of coherence, and they can be proven under assumptions that are surprisingly weak when compared to the standard formulation of the laws in more classical approaches to probability theory. 1...|$|E
40|$|This paper {{studies the}} {{possibility}} of representing lower previsions by continuous linear functionals. We prove {{the existence of a}} linear isomorphism between the linear space spanned by the coherent lower previsions and that of an appropriate space of continuous linear functionals. Moreover, we show that a <b>lower</b> <b>prevision</b> is coherent if and only if its transform is monotone. We also discuss the interpretation of these results and the new light they shed on the theory of imprecise probabilities...|$|E
40|$|Abstract. We {{detail the}} {{relationship}} between sets of desirable gambles and conditional <b>lower</b> <b>previsions.</b> The former is one the most general models of uncertainty. The latter corresponds to Walley’s celebrated theory of imprecise probability. We consider two avenues: when a collection of conditional <b>lower</b> <b>previsions</b> is derived from a set of desirable gambles, and its converse. In either case, we relate {{the properties of the}} derived model with those of the originating one. Our results constitute basic tools to move from one formalism to the other, and thus to take advantage of work done in the two fronts. 1...|$|R
40|$|AbstractThis paper {{presents}} {{a summary of}} Peter Walley’s theory of coherent <b>lower</b> <b>previsions.</b> We introduce three representations of coherent assessments: coherent <b>lower</b> and upper <b>previsions,</b> closed and convex sets of linear previsions, and sets of desirable gambles. We show also how the notion of coherence {{can be used to}} update our beliefs with new information, and a number of possibilities to model the notion of independence with coherent <b>lower</b> <b>previsions.</b> Next, we comment on the connection with other approaches in the literature: de Finetti’s and Williams’ earlier work, Kuznetsov’s and Weischelberger’s work on interval-valued probabilities, Dempster–Shafer theory of evidence and Shafer and Vovk’s game-theoretic approach. Finally, we present a brief survey of some applications and summarize the main strengths and challenges of the theory...|$|R
40|$|Several {{consistency}} notions for <b>lower</b> <b>previsions</b> (coherence, convexity, others) {{require that}} the suprema of certain gambles, having the meaning of gains, are non-negative. The limit situation that a gain supremum is zero is termed Weak Dutch Book (WDB). In the literature, the special case of WDBs with precise probabilities has mostly been analysed, and strict coherence has been proposed as a radical alternative. In this paper {{the focus is on}} WDBs and generalised strict coherence, termed strict consistency, with imprecise previsions. We discuss properties of <b>lower</b> <b>previsions</b> incurring WDBs and conditions for strict consistency, showing in both cases how they are differentiated by the degree of consistency of the given uncertainty assessment...|$|R
40|$|We {{consider}} immediate predictive inference, where a subject, using {{a number}} of observations of {{a finite number of}} exchangeable random variables, is asked to coherently model his beliefs about the next observation, in terms of a predictive <b>lower</b> <b>prevision.</b> We study when such predictive lower previsions are representation insensitive, meaning that they are essentially independent of the choice of the (finite) set of possible values for the random variables. Such representation insensitive predictive models have very interesting properties, and among such models, the ones produced by the Imprecise Dirichlet-Multinomial Model are quite special in {{a number of}} ways...|$|E
40|$|Embedding conglomerability as a {{rationality}} {{requirement in}} probability {{was among the}} aims of Walley’s behavioural theory of coherent lower previsions. However, recent work has shown that this attempt has only been partly successful. If we focus in particular on the extension of given assessments to a rational and conglomerable model (in the least-committal way), we have that the procedure used in Walley’s theory, the natural extension, provides only an approximation to the model that is actually sought for: the so-called conglomerable natural extension. In this paper we consider probabilistic assessments {{in the form of}} a coherent <b>lower</b> <b>prevision</b> P, which is another name for a lower expectation functional, and make an in-depth mathematical study of the problem of computing the conglomerable natural extension for this case: that is, where it is defined as the smallest coherent <b>lower</b> <b>prevision</b> F ≥ P that is conglomerable, in case it exists. Past work has shown that F can be approximated by an increasing sequence (En) n∈N of coherent lower previsions. We solve an open problem by showing that this sequence can consist of infinitely many distinct elements. Moreover, we give sufficient conditions, of quite broad applicability, to make sure that the point-wise limit of the sequence is F in case P is the lower envelope of finitely many linear previsions. In addition, we study the question of the existence of F and its relationship with the notion of marginal extension...|$|E
40|$|This report {{constitutes}} an unrefereed manuscript which {{is intended to}} be submitted for publication. Any opinions and conclusions expressed in this report are those of the author(s) and do not necessarily represent the views of the Institute. The credal set operator is studied as a set-valued mapping that assigns the set of dominating probabilities to a coherent <b>lower</b> <b>prevision</b> on some set of gambles. It is shown that this mapping is ane on certain classes of coherent lower previsions, which enables to nd a decomposition of credal sets. Continuity of the credal set operator is investigated on nite universes with the aim of approximating credal sets. ...|$|E
50|$|The {{allowance}} for imprecision, or {{a gap between}} a decision maker's upper and <b>lower</b> <b>previsions,</b> is the primary difference between precise and imprecise probability theories. Interestingly, such gaps arise naturally in betting markets which happen to be financially illiquid due to asymmetric information.|$|R
40|$|We study n-monotone <b>lower</b> <b>previsions,</b> which {{constitute}} a generalisation of n-monotone lower probabilities. We investigate their {{relation with the}} concepts of coherence and natural extension in the behavioural theory of imprecise probabilities, and improve along the way upon a number of results from the literature...|$|R
40|$|In {{this paper}} we {{consider}} some bounds for <b>lower</b> <b>previsions</b> {{that are either}} coherent or, more generally, centered convex. We focus on bounds concerning the classical product and Bayes’ rules, discussing first weak product rules {{and some of their}} implications for coherent <b>lower</b> <b>previsions.</b> We then generalise a well-known lower bound, which is a (weak) version for events and coherent lower probabilities of Bayes’ theorem, to the case of random variables and (centered) convex previsions. We obtain a family of bounds and show that one of them is undominated in all cases. Some applications are outlined, and it is shown that 2 -monotonicity, which ensures that the bound is sharp in the case of events, plays a much more limited role in this general framework...|$|R
40|$|The {{standard}} coherence {{criterion for}} lower previsions is expressed using {{an infinite number}} of linear constraints. For lower previsions that are essentially defined on some finite set of gambles on a finite possibility space, we present a reformulation of this criterion that only uses a finite number of constraints. Any such <b>lower</b> <b>prevision</b> is coherent if it lies within the convex polytope defined by these constraints. The vertices of this polytope are the extreme coherent lower previsions for the given set of gambles. Our reformulation makes it possible to compute them. We show how this is done and illustrate the procedure and its results. ...|$|E
40|$|ABSTRACT. The {{generalized}} Bayes ’ rule (GBR) {{can be used}} {{to conduct}} ‘quasi-Bayesian ’ analyses when prior beliefs are represented by imprecise probability models. We describe a procedure for deriving coherent imprecise probability models when the event space consists of a finite set of mutually exclusive and exhaustive events. The procedure is based on Walley’s theory of upper and <b>lower</b> <b>prevision</b> and employs simple linear programming models. We then describe how these models can be updated using Cozman’s linear programming formulation of the GBR. Examples are provided to demonstrate how the GBR can be applied in practice. These examples also illustrate the effects of prior imprecision and prior-data conflict on the precision of the posterior probability distribution...|$|E
40|$|This {{study is}} about {{developing}} some further ideas in imprecise probability models of financial risk measures. A financial risk measure {{has been interpreted}} as an upper prevision of imprecise probability, which through the conjugacy relationship {{can be seen as}} a <b>lower</b> <b>prevision.</b> The risk measures selected in the study are value-at-risk (VaR) and conditional value-at-risk (CVaR). The notion of coherence of risk measures is explained. Stocks that are traded in the financial markets (the risky assets) are seen as the gambles. The study makes a determination through computation from actual assets data whether the risk measure assessments of gambles (assets) are coherent as an imprecise probability. It is observed that coherence of assessments depends on the asset's returns distribution characteristic...|$|E
40|$|Abstract. We {{study the}} {{consistency}} {{of a number of}} probability distributions, which are allowed to be imprecise. To make the treatment as general as possible, we represent those probabilistic assessments as a collection of conditional <b>lower</b> <b>previsions.</b> The problem then becomes proving Walley’s (strong) coherence of the assessments. In order to maintain generality in the analysis, we assume to be given nearly no information about the numbers that make up the <b>lower</b> <b>previsions</b> in the collection. Under this condition, we investigate {{the extent to which the}} above global task can be decomposed into simpler and more local ones. This is done by introducing a graphical representation of the conditional <b>lower</b> <b>previsions</b> that we call the coherence graph: we show that the coherence graph allows one to isolate some subsets of the collection whose coherence is sufficient for the coherence of all the assessments; and we provide a polynomial-time algorithm that finds the subsets efficiently. We show some of the implications of our results by focusing on three models and problems: Bayesian and credal networks, of which we prove coherence; the compatibility problem, for which we provide an optimal graphical decomposition; probabilistic satisfiability, of which we show that some intractable instances can instead be solved efficiently by exploiting coherence graphs. 1...|$|R
40|$|We generalise Cozman’s {{concept of}} a credal network under epistemic {{irrelevance}} (2000) to the case where lower (and upper) probabilities are allowed to be zero. Our main definition is {{expressed in terms of}} coherent <b>lower</b> <b>previsions</b> and imposes epistemic irrelevance by means of strong coherence rather than element-wise Bayes’s rule. We also present a number of alternative representations for the resulting joint model, both in terms of <b>lower</b> <b>previsions</b> and credal sets, a notable example being an intuitive characterisation of the joint credal set by means of linear constraints. We end by applying our method to a simple case: the independent natural extension for two binary variables. This allows us to, for the first time, find analytical expressions for the extreme points of this special type of independent product...|$|R
40|$|We {{study the}} weakest conglomerable model that is implied by {{desirability}} or probability assessments: the conglomerable natural extension. We show that taking the natural {{extension of the}} assessments while imposing conglomerability—the procedure adopted in Walley’s theory—does not yield, in general, the conglomerable natural extension (but it does so {{in the case of}} the marginal extension). Iterating this process produces a sequence of models that approach the conglomerable natural extension, although it is not known, at this point, whether it is attained in the limit. We give sufficient conditions for this to happen in some special cases, and study the differences between working with coherent sets of desirable gambles and coherent <b>lower</b> <b>previsions.</b> Our results indicate that it might be necessary to re-think the foundations of Walley’s theory of coherent conditional <b>lower</b> <b>previsions</b> for infinite partitions of conditioning events...|$|R
40|$|The {{generalized}} Bayes’ rule (GBR) {{can be used}} {{to conduct}} ‘quasi-Bayesian’ analyses when prior beliefs are represented by imprecise probability models. We describe a procedure for deriving coherent imprecise probability models when the event space consists of a finite set of mutually exclusive and exhaustive events. The procedure is based on Walley’s theory of upper and <b>lower</b> <b>prevision</b> and employs simple linear programming models. We then describe how these models can be updated using Cozman’s linear programming formulation of the GBR. Examples are provided to demonstrate how the GBR can be applied in practice. These examples also illustrate the effects of prior imprecision and prior-data conflict on the precision of the posterior probability distribution. Copyright Springer 2005 imprecise probability, generalized Bayes’ rule, second-order probability, quasi-Bayesian analysis,...|$|E
40|$|AbstractThe {{impact of}} the {{decision}} maker features on decision making process sometimes contradicts with the traditional theories. Modeling a decision making model {{it should be noted}} that it is primarily a behavioral model and behavior is influenced by ambiguity. Decision making is a behavioral process highly conditioned by the primary motives beliefs of a DM. In this paper we consider an imprecise hierarchical decision-making model where the first and the second level are described by interval probabilities. This method associates with the construction of a non-additive measure as a <b>lower</b> <b>prevision</b> and uses this capacity in Choquet integral for constructing a utility function. This method uses combined state of nature and decision maker's state which allows distinguishing the ambiguity and ambiguity attitude. We provide an experiment showing application of the suggested analysis...|$|E
40|$|AbstractWe {{consider}} immediate predictive inference, where a subject, using {{a number}} of observations of {{a finite number of}} exchangeable random variables, is asked to coherently model his beliefs about the next observation, in terms of a predictive <b>lower</b> <b>prevision.</b> We study when such predictive lower previsions are representation insensitive, meaning that they are essentially independent of the choice of the (finite) set of possible values for the random variables. We establish that such representation insensitive predictive models have very interesting properties, and show that among such models, the ones produced by the Imprecise Dirichlet-Multinomial Model are quite special in {{a number of}} ways. In the Conclusion, we discuss the open question as to how unique the predictive lower previsions of the Imprecise Dirichlet-Multinomial Model are in being representation insensitive...|$|E
40|$|ABSTRACT. We extend de Finetti’s (1937) {{notion of}} exchangeability to finite and {{countable}} sequences of variables, when a subject’s beliefs about them are modelled using coherent <b>lower</b> <b>previsions</b> rather than (linear) previsions. We derive representation theorems {{in both the}} finite and the countable case, in terms of sampling without and with replacement, respectively. 1...|$|R
40|$|The {{recently}} introduced weak consistency notions of 2 -coherence and 2 -convexity are endowed with {{a concept of}} 2 -coherent, respectively, 2 -convex natural extension, whose properties parallel those of the natural extension for coherent <b>lower</b> <b>previsions.</b> We show {{that some of these}} extensions coincide in various common instances, thus producing the same inferences...|$|R
40|$|We extend de Finetti’s [Ann. Inst. H. Poincaré 7 (1937) 1 – 68] {{notion of}} exchangeability to finite and {{countable}} sequences of variables, when a subject’s beliefs about them are modelled using coherent <b>lower</b> <b>previsions</b> rather than (linear) previsions. We derive representation theorems {{in both the}} finite and countable cases, in terms of sampling without and with replacement, respectively...|$|R
