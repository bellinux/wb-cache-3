2|2717|Public
50|$|As you can see, this {{is quite}} inefficient just to access a variable. With D {{register}}s, the D2 register points {{at the base of}} the lexical level 2 environment, and all we need to do to generate the address of the variable is to add its offset from the stack frame base to the frame base address in the D register. (There is an efficient <b>linked</b> <b>list</b> <b>search</b> operator LLLU, which could search the stack in the above fashion, but the D register approach is still going to be faster.) With D registers, access to entities in outer and global environments is just as efficient as local variable access.|$|E
5000|$|The {{basic data}} {{structure}} of Forth is the [...] "dictionary" [...] which maps [...] "words" [...] to executable code or named data structures. The dictionary {{is laid out}} in memory as a tree of linked lists with the links proceeding from the latest (most recently) defined word to the oldest, until a sentinel value, usually a NULL pointer, is found. A context switch causes a list search to start at a different leaf. A <b>linked</b> <b>list</b> <b>search</b> continues as the branch merges into the main trunk leading eventually back to the sentinel, the root.There can be several dictionaries. In rare cases such as meta-compilation a dictionary might be isolated and stand-alone.The effect resembles that of nesting namespaces and can overload keywords depending on the context.|$|E
50|$|Linked data {{structures}} include <b>linked</b> <b>lists,</b> <b>search</b> trees, expression trees, {{and many}} other widely used data structures. They are also key building blocks for many efficient algorithms, such as topological sort and set union-find.|$|R
50|$|The term array {{is often}} used to mean array data type, a kind of data type {{provided}} by most high-level programming languages that consists of a collection of values or variables that can be selected by one or more indices computed at run-time. Array types are often implemented by array structures; however, in some languages they may be implemented by hash tables, <b>linked</b> <b>lists,</b> <b>search</b> trees, or other data structures.|$|R
50|$|Depending on the language, array types may overlap (or be {{identified}} with) other data types that describe aggregates of values, such as lists and strings. Array types are often implemented by array data structures, but sometimes by other means, such as hash tables, <b>linked</b> <b>lists,</b> or <b>search</b> trees.|$|R
40|$|We {{introduce}} novel {{techniques for}} organizing the indexing structures of how data is stored so that alterations from an original version {{can be detected}} and the changed values specifically identified. We give forensic constructions for several fundamental data structures, including arrays, <b>linked</b> <b>lists,</b> binary <b>search</b> trees, skip <b>lists,</b> and hash tables. Some of our constructions {{are based on a}} new reduced-randomness construction for nonadaptive combinatorial group testing...|$|R
50|$|In a <b>linked</b> <b>list,</b> one {{normally}} <b>searches</b> linearly for {{an element}} by walking {{from one end}} to the other. If the <b>linked</b> <b>list</b> is sorted, and we have a reference to some node containing y, then we may find x in O(d) time by starting our search from y.|$|R
40|$|Abstract. We {{introduce}} novel {{techniques for}} organizing the indexing structures of how data is stored so that alterations from an original version {{can be detected}} and the changed values specifically identified. We give forensic constructions for several fundamental data structures, including arrays, <b>linked</b> <b>lists,</b> binary <b>search</b> trees, skip <b>lists,</b> and hash tables. Some of our constructions {{are based on a}} new reduced-randomness construction for nonadaptive combinatorial group testing...|$|R
40|$|Excellent site {{introduces}} {{careers in}} marine biology, oceanography (biological, chemical, physical, geological), ocean engineering, related fields like marine educator, fisherman. Profiles of professionals in each discipline demonstrate {{the diversity of}} people working in marine science. Valuable advice from experts on how to prepare. Career Outlook and Salaries describe what to expect for positions in academia, industry, government and other arenas. Helpful FAQ section; Resources and <b>Links</b> <b>list</b> job <b>search</b> information, internships and more. Educational levels: High school...|$|R
40|$|We {{consider}} indexing sliding {{windows in}} main memory over on-line data streams. Our proposed data structures and query semantics {{are based on}} a division of the sliding window into sub-windows. When a new sub-window fills up with newly arrived tuples, the oldest sub-window is evicted, indices are refreshed, and continuous queries are re-evaluated to reflect the new state of the window. By classifying relational operators according to their method of execution in the windowed scenario, we show that many useful operators require access to the entire window, motivating the need for two types of indices: those which provide a list of attribute values and their counts for answering set-valued queries, and those which provide direct access to tuples for answering attribute-valued queries. For the former, we evaluate the performance of <b>linked</b> <b>lists,</b> <b>search</b> trees, and hash tables as indexing structures, showing that the high costs of maintaining such structures over rapidly changing data are offset by the savings in query processing costs. For the latter, we propose novel ways of maintaining windowed ring indices, which we show to be much faster than conventional ring indices and more efficient than executing windowed queries without an index. ...|$|R
40|$|Abstract. We {{develop the}} first dynamic data {{structures}} that tolerate δ memory faults, lose no data, and incur only an Õ(δ) additive overhead in overall {{space and time}} per operation. We obtain such data structures for arrays, <b>linked</b> <b>lists,</b> binary <b>search</b> trees, interval trees, predecessor search, and suffix trees. Like previous data structures, δ must be known in advance, but we show how to restore pristine state in linear time, in parallel with queries, making δ just a bound on the rate of memory faults. Our data structures require Θ(δ) words of safe memory during an operation, {{which may not be}} theoretically necessary but seems a practical assumption. ...|$|R
30|$|The block {{preallocation}} cache is a <b>linked</b> <b>list</b> of {{the free}} blocks preallocated from a file system. In response to a block allocation request, a block is taken out from the <b>linked</b> <b>list</b> instead of <b>searching</b> a clear bit in the free block bitmap. When the list is empty, 64 blocks are allocated together from a file system and added to the <b>list.</b> <b>Searching</b> 64 free blocks in the bitmap can avoid bitwise operations. Since our target CPU is x 86 _ 64, its word size is 64 -bit. By considering the bitmap as an array of 64 -bit elements, searching 64 free blocks is simply searching an array element of which content is 0. When a block is freed, it is returned to the block preallocation cache. If there is an enough number of blocks in the cache, the freed block is returned to a file system.|$|R
40|$|We {{present a}} new system of {{automation}} for separation logic in the interactive theorem prover Isabelle. The system is based on the recently developed auto 2 prover, and follows a natural, saturation-based approach to reasoning about imperative programs. In addition to standard examples on <b>linked</b> <b>lists</b> and binary <b>search</b> trees, we apply the automation to red-black trees and indexed priority queues, showing that it provides a high degree of automation even on the more complicated data structures. Comment: 25 page...|$|R
40|$|We {{develop the}} first dynamic data {{structures}} that tolerate δ memory faults, lose no data, and incur only an O(δ) additive overhead in overall {{space and time}} per operation. We obtain such data structures for arrays, <b>linked</b> <b>lists,</b> binary <b>search</b> trees, interval trees, predecessor search, and suffix trees. Like previous data structures, δ must be known in advance, but we show how to restore pristine state in linear time, in parallel with queries, making δ just a bound on the rate of memory faults. Our data structures require Θ(δ) words of safe memory during an operation, {{which may not be}} theoretically necessary but seems a practical assumption. 12 th International Symposium, WADS 2011, New York, NY, USA, August 15 - 17, 2011. ProceedingsCenter for Massive Data Algorithmics (MADALGO...|$|R
40|$|We present ChunkStream, {{a system}} for {{efficient}} streaming and interactive editing of online video. Rather than using a specialized protocol and stream format, ChunkStream makes use of a generic mechanism employing chunks. Chunks are fixed-size arrays that contain a mixture of scalar data and references to other chunks. Chunks allow programmers to expose large, but fine-grained, data structures over the network. ChunkStream represents video clips using simple data types like <b>linked</b> <b>lists</b> and <b>search</b> trees, allowing a client to retrieve and work with only the portions of the clips that it needs. ChunkStream supports resource-adaptive playback and "live" streaming of real-time video as well as fast, frame-accurate seeking; bandwidth-efficient high-speed playback; and compilation of editing decisions from a set of clips. Benchmarks indicate that ChunkStream uses less bandwidth than HTTP Live Streaming while providing better support for editing primitives. T-Party Projec...|$|R
40|$|Abstract. We {{study the}} problem of {{maintaining}} a dynamic ordered set subject to insertions, deletions, and traversals of k consecutive elements. This problem is trivially solved on a RAM and on a simple two-level memory hierarchy. We explore this traversal problem on more realistic memory models: the cache-oblivious model, which applies to unknown and multi-level memory hierarchies, and sequential-access models, where sequential block transfers are less expensive than random block transfers. 1 Introduction A basic computational task is to maintain a dynamic ordered set of elements subject to insertions, deletions, and logical traversals. By a logical traversal we mean an in-order access of the k elements following an element x, for a given k and x. These three operations are performed by nearly any computer program that uses even the most common data structures, such as <b>linked</b> <b>lists</b> or <b>search</b> trees...|$|R
40|$|Data Type {{with certain}} {{fundamental}} operations, e. g., initialize, insert, and retrieve. Conceptually, all insertions occur before any retrievals. 1 It {{is a useful}} data structure for representing static search sets. Static search sets occur frequently in software system applications. Typical static search sets include compiler reserved words, assembler instruction opcodes, and built-in shell interpreter commands. Search set members, called keywords, are inserted into the structure only once, usually during program initialization, and are not generally modified at run-time. Numerous static search structure implementations exist, e. g., arrays, <b>linked</b> <b>lists,</b> binary <b>search</b> trees, digital search tries, and hash tables. Different approaches offer trade-offs between space utilization and search time efficiency. For example, an $n$ element sorted array is space efficient, though the average-case time complexity for retrieval operations using binary search is proportional to $"log n$. Converse [...] ...|$|R
40|$|AbstractWe {{develop a}} general method for proving {{properties}} of programs under arbitrary contexts–including (but not limited to) observational equivalence, space improvement, and {{a form of}} memory safety of the programs–in untyped call-by-value λ-calculus with first-class, dynamically allocated, higher-order references and deallocation. The method generalizes Sumii et al. ’s environmental bisimulation technique, and gives a sound and complete characterization of each proved property, {{in the sense that}} the “bisimilarity” (the largest set satisfying the bisimulation-like conditions) equals the set of terms with the property to be proved. We give examples of contextual properties concerning typical data structures such as <b>linked</b> <b>lists,</b> binary <b>search</b> trees, and directed acyclic graphs with reference counts, all with deletion operations that release memory. This shows the scalability of the environmental approach from contextual equivalence to other binary relations (such as space improvement) and unary predicates (such as memory safety), as well as to languages with non-monotone store...|$|R
40|$|Programmers spend a {{significant}} part of their time debugging, yet most of them simply add print statements and avoid debugging tools. Although the user interface of debuggers has improved significantly in the past decade, their basic debugging methodologies have changed little. This thesis examines single-process sequential debuggers and attempts to elucidate their weaknesses. Target-state exploration and conditional program execution are essential idioms that cannot be practiced e#ectively with existing debuggers. State exploration seeks answers to queries such as detecting a <b>linked</b> <b>list</b> containing a negative element and finding where that element was added. Previous work has focussed on the use of source-language interpreters and graphical interactive exploration as solutions to the state-exploration problem, but these cannot e#ectively search for a negative element in a <b>linked</b> <b>list,</b> specify a <b>search</b> for it, etc. This thesis describes Duel, a very high-level language designed specifi [...] ...|$|R
40|$|Link-based data structures, such as <b>linked</b> <b>lists</b> and binary <b>search</b> trees, {{have many}} {{well-known}} rearrangement steps allowing for efficient implementations of insertion, deletion, and other operations. We describe a rearrangement primitive designed for link-based, heap-ordered priority queues in the comparison model, {{such as those}} similar to Fibonacci heaps or binomial heaps. In its most basic form, the primitive rearranges a collection of heap-ordered perfect binary trees. Doing so offers a data structure control {{on the number of}} trees involved in such a collection, in particular keeping this number logarithmic in the number of elements. The rearrangement step is free from an amortized complexity standpoint (using an appropriate potential function). Comment: 3 pages, 1 figur...|$|R
40|$|We present CSTutor, a sketch-based {{interface}} {{designed to}} help students understand data structures. It currently supports <b>Linked</b> <b>Lists,</b> Binary <b>Search</b> Trees, AVL Trees, and Heaps, and creates {{an environment in which}} a user’s sketched diagram and code are combined seamlessly. In each of the data structure modes, the user can naturally sketch a data structure on the canvas just as they would on the white board. CSTutor analyzes the user’s diagrams in real time, and automatically generates code in a separate code view to reflect any changes the user has made. Additionally, the code can also be edited and any new code changes animate the data structure drawn on the canvas. The connection between the data structure drawn on the canvas and the code implementation is intended {{to bridge the gap between}} the conceptual diagram of a data structure and the actual implementation. We also present the results of a perceived usefulness survey. The results of the study indicate that the majority of students would find CSTutor helpful for learning data structures...|$|R
40|$|Abstract. We present Spt, a {{tool that}} helps programmers write {{low-level}} data-structure manipulations by combining various forms of insights such as abstract and concrete input-output examples as well as imple-mentation skeletons. When programmers write such manipulations, they typically have a clear high-level intuition about how the manipulation should work, but implementing efficient low-level pointer manipulating code is error-prone. Our tool aims {{to bridge the gap}} between the intuition and the corresponding implementation by automatically synthesizing the implementation. The tool frames the synthesis problem as a generaliza-tion of an abstract-interpretation based shape analysis, and represents the problem as a set of constraints which are solved efficiently by the Sketch solver. We report the successful evaluation of our tool on syn-thesizing several <b>linked</b> <b>list</b> and binary <b>search</b> tree manipulations. ...|$|R
40|$|We present Spt, a {{tool that}} helps programmers write {{low-level}} data-structure manipulations by combining various forms of insights such as abstract and concrete input-output examples as well as implementation skeletons. When programmers write such manipulations, they typically have a clear high-level intuition about how the manipulation should work, but implementing efficient low-level pointer manipulating code is error-prone. Our tool aims {{to bridge the gap}} between the intuition and the corresponding implementation by automatically synthesizing the implementation. The tool frames the synthesis problem as a generalization of an abstract-interpretation based shape analysis, and represents the problem as a set of constraints which are solved efficiently by the Sketch solver. We report the successful evaluation of our tool on synthesizing several <b>linked</b> <b>list</b> and binary <b>search</b> tree manipulations. National Science Foundation (U. S.) (Grant CCF- 1116362...|$|R
40|$|It was {{suggested}} in [8] to avoid redundant queries in the skip <b>list</b> <b>search</b> algorithm by marking those elements whose key {{has already been}} checked by the search algorithm. We present here a precise analysis of the total search cost (expectation and variance), where {{the cost of the}} search is measured {{in terms of the number}} of keyto -key comparison. These results are then compared with the corresponding values of the standard search algorithm. 1 Introduction Skip lists have recently been introduced as a type of list-based data structure that may substitute search trees [9]. A set of n elements is stored in a collection of sorted linear <b>linked</b> <b>lists</b> in the following manner: all elements are stored in increasing order in a <b>linked</b> <b>list</b> called level 1 and, recursively, each element which appears in the <b>linked</b> <b>list</b> level i is included with independent probability q (0 ! q ! 1) in the <b>linked</b> <b>list</b> level i + 1. The level of an element x is the number of <b>linked</b> <b>lists</b> it belongs to. For each elemen [...] ...|$|R
5000|$|Disadvantages of {{information}} grazing come from its advantages. Switching from a [...] "fixed" [...] source {{of information}} that is constant, verifiable, and worth memorizing to [...] "fluid" [...] sources that are always in flux can lead to quick solutions that are unverified or worse, incorrect. Studies have shown that many people don't read past the first sentences of a Web site's content, and many never go beyond the first ten <b>links</b> <b>listed</b> in a <b>search.</b> As information becomes more like an instantaneous consumable item, memorization is less fact-based but more procedural (i.e. how to find it). Similar concepts are found in Japanese education where after intense study of many unconnected facts, {{most of the information}} is forgotten or if remembered, not connected to other relevant facts. In the USA, this is similar to cramming an exam. Information grazing may have the same effect but greater, since it is done over the period of years.|$|R
40|$|My {{research}} in applied algorithms spans {{the areas of}} approximation algorithms, online algorithms, data structures, machine learning, and electronic commerce. My recent work has focused on two broad research agendas, namely uniquely represented data structures, and optimization under uncertainty. Uniquely Represented Data Structures. An implementation of an abstract data type (ADT) on a machine model is uniquely represented if it encodes each ADT state with a unique machine state. For my Ph. D. thesis I developed the first efficient constructions of uniquely represented hash tables, <b>linked</b> <b>lists,</b> binary <b>search</b> trees, and many other data structures on the RAM model of computation [3, 4, 7]. These results reversed over thirty years of pessimism in the research literature [1, 5, 13, 18]. These data structures provide the foundation for strongly history independent systems that store exactly the information specified by their designs, such as a filesystem that can delete a file {{in such a way}} that there is provably no trace on the system that the file ever existed, at least at the level of the machine model (i. e., bits rather than magnetic moments). They also provide the basis for fast equality testing of complex objects which may prove useful for speeding up software verification; I intend to explore this possibility in future work. Optimization Under Uncertainty. I have developed online algorithms [15, 16, 14] for some general classes of optimization problems, for example monotone submodular function maximization subject to a budget...|$|R
40|$|We {{present the}} Storyboard Programming framework, a new {{synthesis}} {{system designed to}} help programmers write imperative low-level data-structure manipulations. The goal of this system is {{to bridge the gap}} between the "boxes-and-arrows" diagrams that programmers often use to think about data-structure manipulation algorithms and the low-level imperative code that implements them. The system takes as input a set of partial input-output examples, as well as a description of the high-level structure of the desired solution. From this information, it is able to synthesize low-level imperative implementations in a matter of minutes. The framework is based on a new approach for combining constraint-based synthesis and abstract-interpretation-based shape analysis. The approach works by encoding both the synthesis and the abstract interpretation problem as a constraint satisfaction problem whose solution defines the desired low-level implementation. We have used the framework to synthesize several data-structure manipulations involving <b>linked</b> <b>lists</b> and binary <b>search</b> trees, as well as an insertion operation into an And Inverter Graph. National Science Foundation (U. S.). (Grant number CCF- 1049406) Massachusetts Institute of Technology. Computer Science and Artificial Intelligence Laborator...|$|R
40|$|Implementing a {{concurrent}} {{data structure}} typically begins with defining its sequential specification. However, when used as is, a nontrivial sequential data structure, {{such as a}} <b>linked</b> <b>list,</b> a <b>search</b> tree, or a hash table, may expose incorrect behavior: lost updates, inconsistent responses, etc. To ensure correctness, portions of the sequential code operating on the shared data must be "protected" from data races using synchronization primitives and, thus, certain schedules of the steps of concurrent operations must be rejected. But can we ensure {{that we do not}} "overuse" synchronization, i. e., that we reject a concurrent schedule only if it violates correctness? In this paper, we treat this question formally by introducing the notion of a concurrency-optimal implementation. A program's concurrency is defined here as its ability to accept concurrent schedules, i. e., interleavings of steps of its sequential implementation. An implementation is concurrency-optimal if it accepts all interleavings that do not violate the program's correctness. We explore the concurrency properties of search data structures which can be represented in the form of directed acyclic graphs exporting insert, delete and search operations. We prove, for the first time, that pessimistic e. g., based on conservative locking) and optimistic serializable e. g., based on serializable transactional memory) implementations of search data-structures are incomparable in terms of concurrency. Specifically, there exist simple interleavings of sequential code that cannot be accepted by any pessimistic (and resp., serializable optimistic) implementation, but accepted by a serializable optimistic one (and resp., pessimistic). Thus, neither of these two implementation classes is concurrency-optimal. Comment: Extended version of results in arXiv: 1203. 475...|$|R
40|$|Binary {{search tree}} is a best-suited data {{structure}} for data storage and retrieval when entire tree could be accommodated {{in the primary}} memory. However, this is true only when the tree is height-balanced. Lesser the height faster the search will be. Despite of the wide popularity of Binary search trees {{there has been a}} major concern to maintain the tree in proper shape. In worst case, a binary search tree may reduce to a linear <b>link</b> <b>list,</b> thereby reducing <b>search</b> to be sequential. Unfortunately, structure of the tree depends on nature of input. If input keys are not in random order the tree will become higher and higher on one side. In addition to that, the tree may become unbalanced after a series of operations like insertions and deletions. To maintain the tree in optimal shape many algorithms have been presented over the years. Most of the algorithms are static in nature as they take a whole binary search tree as input to create a balanced version of the tree. In this paper, few techniques have been discussed and analyzed in terms of time and space requirement. Key words...|$|R
5000|$|An {{asymmetric}} doubly <b>linked</b> <b>list</b> {{is somewhere}} between the singly <b>linked</b> <b>list</b> and the regular doubly <b>linked</b> <b>list.</b> It shares some features with the singly <b>linked</b> <b>list</b> (single-direction traversal) and others from the doubly <b>linked</b> <b>list</b> (ease of modification) ...|$|R
40|$|ABSTRACT – Our {{research}} paper aims at <b>linked</b> <b>list</b> {{which is a}} data structure {{and it is the}} collection of nodes which together represent a sequence. <b>Linked</b> <b>list</b> are of many types. It can be singly <b>linked</b> <b>list,</b> doubly <b>linked</b> <b>list,</b> circular <b>linked</b> <b>list.</b> In this we will focus on how to traverse a <b>linked</b> <b>list,</b> insertion of a node {{at the beginning of the}} <b>linked</b> <b>list,</b> insertion of the node after a node, deletion of node from beginning and deletion of node from the end of the <b>linked</b> <b>list</b> and how two <b>linked</b> <b>lists</b> can be concatenated...|$|R
5000|$|... {{the skip}} list, a similar {{variation}} on the <b>linked</b> <b>list,</b> offers fast lookup and hurts the advantages of <b>linked</b> <b>lists</b> (quick insert/deletion) less than an unrolled <b>linked</b> <b>list</b> ...|$|R
50|$|In {{languages}} {{that support}} abstract data types or templates, <b>linked</b> <b>list</b> ADTs or templates {{are available for}} building <b>linked</b> <b>lists.</b> In other languages, <b>linked</b> <b>lists</b> are typically built using references together with records.|$|R
25|$|Difficulties {{arise in}} <b>linked</b> <b>lists</b> {{when it comes}} to reverse traversing. For instance, singly <b>linked</b> <b>lists</b> are {{cumbersome}} to navigate backwards and while doubly <b>linked</b> <b>lists</b> are somewhat easier to read, memory is consumed in allocating space for a back-pointer.|$|R
50|$|XOR <b>linked</b> <b>lists</b> {{leverage}} XOR {{properties in}} order to save space to represent doubly <b>linked</b> <b>list</b> data structures.|$|R
5000|$|CDR coding, another {{technique}} for decreasing overhead and improving cache locality in <b>linked</b> <b>lists</b> similar to unrolled <b>linked</b> <b>lists.</b>|$|R
