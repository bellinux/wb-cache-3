3|32|Public
40|$|This paper {{evaluates the}} National Weather Service {{operational}} hydrologic model and operational flow forecasts for several subbasins of the American River. The evaluation includes: (1) {{the quality of}} the 6 -h operational flow forecasts with up to 5 days lead time; (2) the hydrologic model ability to reproduce observed mean daily flows; and (3) the reliability of the ensemble streamflow predictions of the hydrologic model to reproduce extremes of the monthly volume of full natural flow to Folsom Lake. The results indicate that the model represents the observed flow record well for sites and/or flow ranges unaffected by upstream regulation. Real time operational forecast produced by a forecaster that considers model predictions have good skill out to 18 h with precipitation forecast contributing significantly to forecast uncertainty. Certain high-flow events with a spatially distributed mix of snow/rain over the basin may not be reproduced well by the basic spatially <b>lumped</b> <b>structure</b> of the operational snow–soil–channel model. It is suggested to incorporate upstream regulation rules into the operational models for better reproduction of observed medium and low flows. Routine evaluation based on a national archive of operational flow forecasts and observations is also recommended...|$|E
40|$|Model intercomparison {{experiments}} {{are widely used}} to investigate and improve hydrological model performance. However, a study based only on runoff simulation {{is not sufficient to}} discriminate between different model structures. Hence, {{there is a need to}} improve hydrological models for specific streamflow signatures (e. g., low and high flow) and multi-variable predictions (e. g., soil moisture, snow and groundwater). This study assesses the impact of model structure on flow simulation and hydrological realism using three versions of a hydrological model called MORDOR: the historical <b>lumped</b> <b>structure</b> and a revisited formulation available in both lumped and semi-distributed structures. In particular, the main goal of this paper is to investigate the relative impact of model equations and spatial discretization on flow simulation, snowpack representation and evapotranspiration estimation. Comparison of the models is based on an extensive dataset composed of 50 catchments located in French mountainous regions. The evaluation framework is founded on a multi-criterion split-sample strategy. All models were calibrated using an automatic optimization method based on an efficient genetic algorithm. The evaluation framework is enriched by the assessment of snow and evapotranspiration modeling against in situ and satellite data. The results showed that the new model formulations perform significantly better than the initial one in terms of the various streamflow signatures, snow and evapotranspiration predictions. The semi-distributed approach provides better calibration–validation performance for the snow cover area, snow water equivalent and runoff simulation, especially for nival catchments...|$|E
40|$|The Iterative DEsign of Antenna Structures (IDEAS) {{program is}} a finite element {{analysis}} and design optimization program with special features for the analysis and design of microwave antennas and associated sub-structures. As the principal structure analysis and design tool for the Jet Propulsion Laboratory's Ground Antenna and Facilities Engineering section of NASA's Deep Space Network, IDEAS combines flexibility with easy use. The relatively small bending stiffness {{of the components of}} large, steerable reflector antennas allows IDEAS to use pinjointed (three translational degrees of freedom per joint) models for modeling the gross behavior of these antennas when subjected to static and dynamic loading. This facilitates the formulation of the redesign algorithm which has only one design variable per structural element. Input data deck preparation has been simplified by the use of NAMELIST inputs to promote clarity of data input for problem defining parameters, user selection of execution and design options and output requests, and by the use of many attractive and familiar features of the NASTRAN program (in many cases, NASTRAN and IDEAS formatted bulk data cards are interchangeable). Features such as simulation of a full symmetric structure based on analyses of only half the structure make IDEAS a handy and efficient analysis tool, with many features unavailable in any other finite element analysis program. IDEAS can choose design variables such as areas of rods and thicknesses of plates to minimize total structure weight, constrain the structure weight to a specified value while maximizing a natural frequency or minimizing compliance measures, and can use a stress ratio algorithm to size each structural member so that it is at maximum or minimum stress level for {{at least one of the}} applied loads. Calculations of total structure weight can be broken down according to material. Center of gravity weight balance, static first and second moments about the center of mass and optionally about a user-specified gridpoint, and <b>lumped</b> <b>structure</b> weight at grid points can also be calculated. Other analysis outputs include calculation of reactions, displacements, and element stresses due to specified gravity, thermal, and external applied loads; calculations of linear combinations of specific node displacements (e. g. to represent motions of rigid attachments not included in the structure model), natural frequency eigenvalues and eigenvectors, structure reactions and element stresses, and coordinates of effective modal masses. Cassegrain antenna boresight error analysis of a best fitting paraboloid and Cassegrain microwave antenna root mean square half-pathlength error analysis of a best fitting paraboloid are also performed. The IDEAS program is written in ATHENA FORTRAN and ASSEMBLER for an EXEC 8 operating system and was implemented on a UNIVAC 1100 series computer. The minimum memory requirement for the {{program is a}}pproximately 42, 000 36 -bit words. This program is available on a 9 -track 1600 BPI magnetic tape in UNIVAC FURPUR format only; since JPL-IDEAS will not run on other platforms, COSMIC will not reformat the code to be readable on other platforms. The program was developed in 1988...|$|E
30|$|Our {{study has}} a few limitations, {{primarily}} the exploratory {{nature of the work}} and the small number of patients enrolled in this study. These factors may limit the generalization of our findings. The simulation was performed using data segmented from intra-operative US images, which has less information than the pre-operative MR images. Complex and heterogeneous structures such as the neurovascular bundle were represented in the model as simpler <b>lumped</b> <b>structures</b> with homogenous electrical properties which reduce precision of the simulation model. Our simulation was not truly volumetric and was restricted to a single thick slice of tissue and therefore may not estimate the behavior of the entire ablation volume. Our results are pertinent for comparison of simulation findings with post-treatment imaging, and the absence of pathology data limits drawing definitive conclusions on the status of the treated tissue. Post-ablation tissue is constantly evolving, undergoing edema and tissue expansion in the early phase followed by fibrosis and tissue shrinkage at later periods. These dynamic changes may explain some of the inter-patient differences in simulation versus MRI measurements we observed. Finally, gadolinium-enhanced MRI by itself is not a validated technique for measuring the effectiveness of IRE in the prostate; therefore, we are unable to arrive at any conclusion on the value of simulations for estimating true treatment outcomes.|$|R
40|$|The {{desire of}} the This article {{describes}} {{the armed forces to}} methods used to design maintain instant broadband coaxial trans- communications with all former matching networks forces requires the design for an LDMOS power ampli- of miniature broadband fier that delivers consistent power amplifiers with performance over more greater than decade than a decade bandwidth bandwidth (30 to 512 MHz). This bandwidth is required for all-band transceivers that cover tactical ground and air frequencies in addition to civil telecommunication frequencies and the frequencies of our allies. All-band radios are commonplace in virtually every deployment of new platforms, {{as well as in the}} retrofitting of existing communications systems. This paper will discuss the design of miniature coaxial structures and examine the implementation of improved design techniques to enable the designer to obtain insight into matching the load line of power MOSFET transistors over decade bandwidths. This article presents the development of large signal parameters for a typical power MOSFET device and the development of a suitable load line using coaxial transmission line transformers in conjunction with embedded <b>lumped</b> <b>structures,</b> enabling an efficient load line match across a decade of bandwidth. Simulation Methodology. Linear simulation assumes that a circuit with active devices is operated at such a low power that the simulated measurements are no longer power dependent. This simulation can be achieved by two methods. First the circuit uses a nonlinear model and nonlinear simulator. The quiescent current is set at...|$|R
40|$|International audienceAn {{efficient}} {{method of}} updating numerical models for dynamics problems is presented. The {{objective is to}} minimize the difference between measured and simulated vibration data. The corresponding optimization problem is formulated in the modal domain and solved using the genetic algorithm (GA) stochastic algorithm. Original modifications of a standard GA are proposed to improve the updating process efficacy. New versions of GA exploit the speeding up procedures developed in the novel accelerated random search (ARS) algorithm. A finite element model of a <b>lumped</b> mass <b>structure</b> is analyzed to validate the approach. A real beam-like structure model is updated, making use of experimental modal data. The enhanced GA enables us to obtain results well correlated with experiment...|$|R
40|$|Non-smooth {{modelling}} {{techniques have}} been successfully applied to <b>lumped</b> mass-type <b>structures</b> for modelling phenomena such as vibro-impact and friction oscillators. In this paper, the application of these techniques to continuous elements using {{the example of a}} cantilever beam is considered. Employing a Galerkin reduction to form an N -degree-of-freedom modal model, a technique for modelling impact phenomena using a non-smooth dynamics approach is demonstrated. Numerical simulations computed using the non-smooth model are compared with experimentally recorded data for a flexible beam constrained to impact on one side. A method for dealing with sticking motions when numerically simulating the beam motion is presented. In addition, choosing the dimension of the model based on power spectra of experimentally recorded time series is discussed...|$|R
40|$|International audienceSecondary organic aerosol (SOA) {{formation}} in the atmosphere is currently often modeled using a multiple lumped "two-product" (N · 2 p) approach. The N · 2 p approach neglects: 1) variation of activity coefficient (? i) values and mean molecular weight MW in the particulate matter (PM) phase; 2) water uptake into the PM; and 3) the possibility of phase separation in the PM. This study considers these effects by adopting an (N · 2 p) ?, MW,? approach (? is a phase index). Specific chemical structures are assigned to 25 lumped SOA compounds and to 15 representative primary organic aerosol (POA) compounds to allow calculation of ? i and MW values. The SOA structure assignments are based on chamber-derived 2 p gas/particle partition coefficient values coupled with known effects of structure on vapor pressure p L, i ° (atm). To facilitate adoption of the (N· 2 p) ?, MW, ? approach in large-scale models, this study also develops CP-Wilson. 1, a group-contribution ? i -prediction method that is more computationally economical than the UNIFAC model of Fredenslund et al. (1975). Group parameter values required by CP-Wilson. 1 are obtained by fitting ? i values to predictions from UNIFAC. The (N· 2 p) ?,MW, ? approach is applied (using CP-Wilson. 1) to several real ?-pinene/O 3 chamber cases for high reacted hydrocarbon levels (?HC? 400 to 1000 ?g m ? 3) when relative humidity (RH) ? 50 %. Good agreement between the chamber and predicted results is obtained using both the (N· 2 p) ?, MW, ? and N· 2 p approaches, indicating relatively small water effects under these conditions. However, for a hypothetical ?-pinene/O 3 case at ?HC= 30 ?g m ? 3 and RH= 50 %, the (N· 2 p) ?, MW, ? approach predicts that water uptake will lead to an organic PM level that is more double that predicted by the N· 2 p approach. Adoption of the (N· 2 p) ?, MW, ? approach using reasonable <b>lumped</b> <b>structures</b> for SOA and POA compounds is recommended for ambient PM modeling...|$|R
40|$|Secondary organic aerosol (SOA) {{formation}} in the atmosphere is currently often modeled using a multiple lumped "two-product" (N&middot; 2 p) approach. The N&middot; 2 p approach neglects: 1) variation of activity coefficient (ζi) values and mean molecular weight MW in the particulate matter (PM) phase; 2) water uptake into the PM; and 3) the possibility of phase separation in the PM. This study considers these effects by adopting an (N&middot; 2 p) ζpMW,ζ approach (θ is a phase index). Specific chemical structures are assigned to 25 lumped SOA compounds and to 15 representative primary organic aerosol (POA) compounds to allow calculation of ζi and MW values. The SOA structure assignments are based on chamber-derived 2 p gas/particle partition coefficient values coupled with known effects of structure on vapor pressure pL,io (atm). To facilitate adoption of the (N&middot; 2 p) ζpMW,θ approach in large-scale models, this study also develops CP-Wilson. 1 (Chang-Pankow-Wilson. 1), a group-contribution ζi-prediction method that is more computationally economical than the UNIFAC model of Fredenslund et al. (1975). Group parameter values required by CP-Wilson. 1 are obtained by fitting ζi values to predictions from UNIFAC. The (N&middot; 2 p) ζpMW,θ approach is applied (using CP-Wilson. 1) to several real α-pinene/O 3 chamber cases for high reacted hydrocarbon levels (ΔHC≈ 400 to 1000 μg m− 3 ) when relative humidity (RH) &asymp; 50 %. Good agreement between the chamber and predicted results is obtained using both the (N&middot; 2 p) ζpMW,θ and N&middot; 2 p approaches, indicating relatively small water effects under these conditions. However, for a hypothetical α-pinene/O 3 case at &Delta;HC= 30 μg m− 3 and RH= 50 %, the (N&middot; 2 p) ζpMW,θ approach predicts that water uptake will lead to an organic PM level that is more double that predicted by the N&middot; 2 p approach. Adoption of the (N&middot; 2 p) ζpMW,θ approach using reasonable <b>lumped</b> <b>structures</b> for SOA and POA compounds is recommended for ambient PM modeling...|$|R
40|$|ABSTRACT ⎯ A compact {{dipole antenna}} for the {{terrestrial}} digital multimedia broadcasting (TDMB) application is presented. The {{length of the}} antenna is about 0. 06 λ at the TDMB resonance frequency of 190 MHz. Miniaturization of the antenna is achieved by using meander <b>structures</b> and <b>lumped</b> elements. The proposed antenna has two resonance frequencies and covers the TDMB band from 174 MHz to 216 MHz in Korea. The antenna has good impedance bandwidth and radiation characteristics for the TDMB. The experimental results of the designed dipole antenna are presented and analyzed. Keywords⎯Dipole antenna, TDMB, meander <b>structure,</b> <b>lumped</b> element...|$|R
40|$|Abstract — This paper {{introduces}} a new algorithm for the au-tomatic synthesis of SPICE-ready equivalent circuits of complex multiport <b>lumped</b> interconnect <b>structures.</b> The method is named Time-Domain Vector Fitting (TD-VF) {{due to its}} analogy to the well-known Vector Fitting algorithm, which operates in frequency domain. The TD-VF computes a rational approximation of the transfer matrix for the structure under modeling using as raw data its transient port responses to suitable excitations. These include, e. g., the case of transient port scattering responses as typically obtained by full-wave electromagnetic solvers based on the Finite-Differences Time-Domain (FDTD) or Finite In-tegration (FIT) methods. The TD-VF algorithm works entirely in the time domain, without requiring any knowledge of the frequency-domain responses. This allows direct processing of possibly truncated transient responses, therefore allowing for short full-wave simulations. This paper shows that the accuracy level achiavable by TD-VF is excellent. Hence, passivity can be enforced a posteriori using the spectral properties of associated Hamiltonian matrices. Several examples of package, connectors, and discontinuities are provided as illustration. I...|$|R
40|$|We {{observed}} the morphologic changes of tissue fragments of {{retinal pigment epithelium}} (RPE) of chick embryos in floating culture under the presence of bacic fibroblast growth factor (bFGF). At higher concentration (10 and 200 ng/ml) of bFGF, rolled up RPE sheets grew to develop non-pigmented <b>lumps</b> with the <b>structure</b> like onions, while dissociated RPE cells did not from such structure. Histologically, the onion-like structure consisted of lens-fiber-like cells, positive for anti-crystallin antibody and anti-bFGF-receptor antibody. This lentoid structure was not formed at 1 ng/ml or lower concentration of bFGF. The trans differentiation from RPE cells to lens epithelial cells was dependent upon the concentration of bFGF {{as well as the}} proper interaction among RPE cells...|$|R
40|$|When {{applying}} hydrological models, {{different sources}} of uncertainty are {{present and the}} incorporation of these uncertainties in evaluations of model performance are needed to assess model outcomes correctly. Nevertheless, uncertainty in the discharge observations complicate the model identification, {{both in terms of}} model structure and parameterization. In this paper, two different <b>lumped</b> model <b>structures</b> (PDM and NAM) are compared taking into account the uncertainty coming from the rating curve. The derived uncertainty bounds of the observations are used to derive limits of acceptance for the model simulations. The DYNamic Identifiability Approach (DYNIA) is applied to identify structural failure of both models and to evaluate the configuration of their structures. The analysis focuses on different parts of the hydrograph and evaluates the seasonal performance. In general, similar model performance is observed. However, the model structures tend to behave differently in function of the time. Based on the analyses we did, the probability based soil storage representation of the PDM model outperformed the NAM structure. The incorporation of the observation error did not prevent the DYNIA analysis to identify potential model structural deficiencies that are limiting the representation of the seasonal variation...|$|R
40|$|AbstractStudy regionTwenty diversified U. S. watersheds. Study focusIdentifying optimal {{parameter}} sets for hydrological modeling on a specific catchment remains an important challenge for numerous applied and research projects. This is particularly the case when working under contrasted climate conditions that question the temporal transposability of the parameters. Methodologies exist, mainly based on Differential Split Sample Tests, to examine this concern. This work assesses the improved temporal transposability of a multimodel implementation, based on twenty dissimilar <b>lumped</b> conceptual <b>structures</b> and on twenty U. S. watersheds, over {{the performance of the}} individual models. New hydrological insights for the regionIndividual and collective temporal transposabilities are analyzed and compared on the twenty studied watersheds. Results show that individual models performances on contrasted climate conditions are very dissimilar depending on test period and watershed, without the possibility to identify a best solution in all circumstances. They also confirm that performance and robustness are clearly enhanced using an ensemble of rainfall-runoff models instead of individual ones. The use of (calibrated) weight averaged multimodels further improves temporal transposability over simple averaged ensemble, in most instances, confirming added-value of this approach but also the need to evaluate how individual models compensate each other errors...|$|R
40|$|Large {{holes in}} {{graphene}} membranes were recently shown to heal, either {{at room temperature}} during a low energy STEM experiment, or by annealing at high temperatures. However, {{the details of the}} healing mechanism remain unclear. We carried out fully atomistic reactive molecular dynamics simulations in order to address these mechanisms under different experimental conditions. Our results show that, if a carbon atom source is present, high temperatures can provide enough energy for the carbon atoms to overcome the potential energy barrier and to produce perfect reconstruction of the graphene hexagonal structure. At room temperature, this perfect healing is only possible if the heat effects of the electron beam from STEM experiment are explicitly taken into account. The reconstruction process of a perfect or near perfect graphene structure involves the formation of linear carbon chains, as well as rings containing 5, 6, 7 and 8 atoms with planar (Stone-Wales) and non-planar (<b>lump</b> like) <b>structures.</b> These results shed light on the healing mechanism of graphene when subjected to different experimental conditions. Additionally, the methodology presented here can be useful for investigating the tailoring and manipulations of other nano-structures. Comment: 21 pages, 7 figure...|$|R
40|$|Study region: Twenty diversified U. S. watersheds. Study focus: Identifying optimal {{parameter}} sets for hydrological modeling on a specific catchment remains an important challenge for numerous applied and research projects. This is particularly the case when working under contrasted climate conditions that question the temporal transposability of the parameters. Methodologies exist, mainly based on Differential Split Sample Tests, to examine this concern. This work assesses the improved temporal transposability of a multimodel implementation, based on twenty dissimilar <b>lumped</b> conceptual <b>structures</b> and on twenty U. S. watersheds, over {{the performance of the}} individual models. New hydrological insights for the region: Individual and collective temporal transposabilities are analyzed and compared on the twenty studied watersheds. Results show that individual models performances on contrasted climate conditions are very dissimilar depending on test period and watershed, without the possibility to identify a best solution in all circumstances. They also confirm that performance and robustness are clearly enhanced using an ensemble of rainfall-runoff models instead of individual ones. The use of (calibrated) weight averaged multimodels further improves temporal transposability over simple averaged ensemble, in most instances, confirming added-value of this approach but also the need to evaluate how individual models compensate each other errors...|$|R
40|$|This chapter {{tells the}} story of Pembrokeshire between about 4000 BC and 700 BC, a remote period of more than 3000 years when life was quite {{different}} from that of more recent times. It is conventionally referred to as the Neolithic (4000 – 2000 BC), early Bronze Age (2000 – 1600 BC), middle Bronze Age (1600 – 1000 BC), and late Bronze Age (1000 – 700 BC), although advances in radiocarbon dating over recent decades provide a secure chronological framework that now allows us to talk in terms of specific millennia and centuries. What we present here is a summary based on currently available archaeological evidence that has survived to be described, investigated, studied, and interpreted by prehistorians and other specialists working in related fields. There are no written records to help us in this task; all we have to go on are the <b>lumps,</b> bumps, <b>structures,</b> monuments, deposits, and stray finds that survive in the modern landscape. Some remains, for example the Pentre Ifan megalithic tomb and the Gors Fawr stone circle, are truly spectacular in their form and setting, and have long been recognized as tourist destinations and places for spiritual nourishment through their connections with the distant past. Other sites and finds may seem less impressive, but their contribution to understanding prehistory is no less important...|$|R
40|$|An {{operational}} hydrological ensemble forecasting {{system based}} on a meteorological ensemble prediction system (M-EPS) coupled with a hydrological model searches to capture the uncertainties associated with the meteorological prediction to better predict river flows. However, {{the structure of the}} hydrological model is also an important source of uncertainty that has to be taken into account. This study aims at evaluating and comparing the performance and the reliability of different types of hydrological ensemble prediction systems (H-EPS), when ensemble weather forecasts are combined with a multi-model approach. The study is based on 29 catchments in France and 16 <b>lumped</b> hydrological model <b>structures,</b> driven by the weather forecasts from the European centre for medium-range weather forecasts (ECMWF). Results show that the ensemble predictions produced by a combination of several hydrological model structures and meteorological ensembles have higher skill and reliability than ensemble predictions given either by one single hydrological model fed by weather ensemble predictions or by several hydrological models and a deterministic meteorological forecast...|$|R
40|$|Dynamic {{tests of}} three {{structures}} are described. In two cases linear vibration theory {{is applied to}} explain {{the behavior of the}} structures. In the third case a new method of analyzing the vibration records is introduced to define nonlinear properties of the structure. Free and forced vibration tests were conducted on a reservoir outlet structure consisting of a reinforced concrete tower, 149 feet in height, with a steel truss bridge, 3139 feet long, connected to the tower near the top. Measurements revealed five natural frequencies and mode shapes, and indicated the extent and significance of foundation movements. A detailed theoretical analysis of linear vibrations of the structure is carried out to show good agreement with the observations and to illustrate a general technique for the dynamic analysis of framed structures. An earth dam 485 feet long by 60 feet in height by 450 feet thick at the base was subjected to a sinusoidal lateral exciting force at the top. Application of the theory of a truncated wedge vibrating in shear modes is made to determine an effective shear wave velocity in the earth fill and to estimate damping in the modes. A general procedure is presented for experimentally determining the restoring and dissipating functions in <b>lumped</b> mass. <b>structures,</b> linear or nonlinear. An experiment on a single degree of freedom laboratory structure with bolted joints is used to illustrate the method. The question of instrumentation suitable for structural dynamic work is considered and recommendations are {{made on the basis of}} tests and examination of many commercially available components...|$|R
40|$|A bench-scale shake {{table was}} {{designed}} and constructed for the Swarthmore College Engineering Department. The frame of the shake table was made of Unistrut. It's powered by a motor with a complete built-in servo control system that takes analog output as the velocity through an A/D converter. Two transfer functions were developed: one that connects the motor to the base plate and the other connecting the plate to a simple test <b>structure</b> (<b>lumped</b> mass model). Sensors (LVDT and accelerometers) were hooked onto the base plate and structure to measure acceleration and displacement data to {{be sent back to}} Matlab for further analysis and plotting. We used Matlab's linear simulator (lsim) to calculate the theoretical output for a known input waveform, and compared the results to the actual measured output (by the accelerometer). The results matched well for impulse functions, step functions, and arbitrary waveforms such as the El Centro earthquake. Two multi-story stick mass systems were shaken at their respective resonant frequencies to observe the effects of resonance...|$|R
40|$|This paper {{presents}} a modular approach {{for the design}} of MMIC lumped and transversal filter with LC tuned amplifiers. The filtering improvement due to the introduction of LC tuned amplifier modules (LCTAM) as the transversal element on the conven­tional <b>lumped</b> and transversal <b>structure</b> is illustrated by comparing the performances of a single LCTAM and double LCTAM filters with a conventional one. In order to demonstrate the novel filter usefulness three filters with two transversal sections were implemented with the same typical 0. 5 um GaAs MMIC technology (a conventional, a single and a double LCTAM). It is shown that when we increase the number of LCTAM the rejection increases, however the chip area and complexity also increase. For a 1. 54 GHz centre fre­quency filter, a good compromise is the double LCTAM. This solution on the lower stop band (- 250 MHz) has 15 dB more attenuation than the other two filters and on the upper stop band (+ 250 MHz) has 17 dB and 20 dB more attenuation than the single LCTAM or conventional filter topology, respectively...|$|R
40|$|In the {{framework}} of the SPEAR (Seismic PErformance Assessment and Rehabilitation) research Project, an under-designed three storey RC frame structure, designed to sustain only gravity loads, was subjected, in three different configurations "as-built", Fiber Reinforced Polymer (FRP) retrofitted and rehabilitated by reinforced concrete (RC) jacketing, to a series of bi-directional pseudodynamic (PsD) tests under different values of peak ground acceleration (PGA) (from a minimum of 0. 20 g to a maximum of 0. 30 g). The seismic deficiencies exhibited by the "as-built" structure after the test at PGA level of 0. 20 g were confirmed by a post - test assessment of the structural seismic capacity performed by a nonlinear static pushover analysis implemented on the <b>structure</b> <b>lumped</b> plasticity model. To improve the seismic performance of the "as-built" structure, two rehabilitation interventions by using either FRP laminates or RC jacketing were designed. Assumptions for the analytical modeling, design criteria and calculation procedures along with local and global intervention measures and their installation details are herein presented and discussed. Nonlinear static pushover analyses for the assessment of the theoretical seismic capacity of the structure in each retrofitted configuration were performed and compared with the experimental outcomes...|$|R
40|$|With the {{increasing}} demand on wireless and portable devices, the radio frequency front end blocks are required to feature properties such as wideband, high frequency, multiple operating frequencies, low cost and compact size. However, the current radio frequency system blocks are designed by combining several individual frequency band blocks into one functional block, which increase the cost and size of devices. To address these issues, {{it is important to}} develop novel approaches to further advance the current design methodologies in both space and spectrum domains. In recent years, the concept of artificial materials has been proposed and studied intensively in RF/Microwave, Terahertz, and optical frequency range. It is a combination of conventional materials such as air, wood, metal and plastic. It can achieve the material properties that have not been found in nature. Therefore, the artificial material (i. e. meta-materials) provides design freedoms to control both the spectrum performance and geometrical structures of radio frequency front end blocks and other high frequency systems. In this dissertation, several artificial materials are proposed and designed by different methods, and their applications to different high frequency components and circuits are studied. First, quasi-conformal mapping (QCM) method is applied to design plasmonic wave-adapters and couplers working at the optical frequency range. Second, inverse QCM method is proposed to implement flattened Luneburg lens antennas and parabolic antennas in the microwave range. Third, a dual-band compact directional coupler is realized by applying artificial transmission lines. In addition, a fully symmetrical coupler with artificial <b>lumped</b> element <b>structure</b> is also implemented. Finally, a tunable on-chip inductor, compact CMOS transmission lines, and metamaterial-based interconnects are proposed using artificial metal structures. All the proposed designs are simulated in full-wave 3 D electromagnetic solvers, and the measurement results agree well with the simulation results. These artificial material-based novel design methodologies pave the way toward next generation high frequency circuit, component, and system design...|$|R
40|$|This paper {{introduces}} a general framework that evaluates a numerical Bayesian multiresponse calibration approach {{based on a}} Gibbs within Metropolis searching algorithm and a statistical likelihood function. The methodology has been applied with two versions of TOPMODEL on the Haute-Mentue experimental basin in Switzerland. The approach computes the following: the parameter's uncertainty, the parametric uncertainty of the output responses stemming from parameter uncertainty, and the predictive uncertainty of the output responses stemming from an error term including, indiscriminately in a <b>lumped</b> way, model <b>structure</b> and input and output errors. Two case studies are presented: The first one applies this methodology with the classical TOPMODEL to assess the role of two-response calibration (observed discharge and soil saturation deficits) on model parameters and output uncertainty. The second one uses a three-response calibration (observed discharge, silica, and calcium stream water concentrations) with {{a modified version of}} TOPMODEL to study the uncertainty of the parameters and of the simulated responses. Despite its limitations, the present multiresponse Bayesian approach proved a valuable tool in uncertainty analyses, and it contributed {{to a better understanding of}} the role of the internal variables and the value of additional information for enhancing model structure robustness and for checking the performance of conceptual models...|$|R
40|$|Abstract: The current paper {{describes}} {{a simple and}} yet comprehensive lumped-parameter model (LPM) for simulating the National Highway Traffic Safety Administration (NHTSA) side-impact safety tests for passenger vehicles. The LPM includes new lumped masses, not previously reported in a single multibody model, for key vehicle side-structure systems identified {{with the help of}} an energy-based study conducted using explicit finite element analysis of two passenger vehicles. In addition to the vehicle side <b>structure,</b> <b>lumped</b> masses for the NHTSA side-impact barrier and ‘rest of vehicle’, the latter implying the mass of the vehicle minus the combined mass of the side-structure subsystems considered in the LPM, have been incorporated so that the total mass of the system corresponds to that of an actual vehicle– barrier system in a NHTSA side-impact test (Lateral Impact New Car Assessment Program (LINCAP) or FMVSS 214). The lumped masses are interconnected with elastic–plastic springs. A unique feature of the present model is the inclusion of two lumped side-impact dummies for obtaining predictions of the front and rear (thoracic trauma index (TTI)). The validity of the present LPM is established by performing LS-DYNA-based LINCAP simulations of two real-world vehicles, namely the Dodge Neon and Dodge Intrepid, and obtaining a reasonably good correlation of the computed structural and occupant responses as well as TTI (front and rear) with the corresponding test results reported by the NHTSA...|$|R
40|$|Diagnosing {{the impacts}} of climate change on water {{resources}} is a difficult task pertaining to the uncertainties arising from the different modelling steps. <b>Lumped</b> hydrological model <b>structures</b> contribute to this uncertainty {{as well as the}} natural climate variability, illustrated by several members from the same Global Circulation Model. In this paper, the hydroclimatic modelling chain consists of twenty-four potential evapotranspiration formulations, twenty lumped conceptual hydrological models, and seven snowmelt modules. These structures are applied on a natural Canadian sub-catchment to address related uncertainties and compare them to the natural internal variability of simulated climate system as depicted by five climatic members. Uncertainty in simulated streamflow under current and projected climates is assessed. They rely on interannual hydrographs and hydrological indicators analysis. Results show that natural climate variability is the major source of uncertainty, followed by potential evapotranspiration formulations and hydrological models. The selected snowmelt modules, however, do not contribute much to the uncertainty. The analysis also illustrates that the streamflow simulation over the current climate period is already conditioned by the tools' selection. This uncertainty is propagated to reference simulations and future projections, amplified by climatic members. These findings demonstrate the importance of opting for several climatic members to encompass the important uncertainty related to the climate natural variability, but also of selecting multiple modelling tools to provide a trustworthy diagnosis of {{the impacts of}} climate change on water resources...|$|R
40|$|The current paper {{describes}} {{a simple and}} yet comprehensive lumped-parameter model (LPM) for simulating the National Highway Traffic Safety Administration (NHTSA) side-impact safety tests for passenger vehicles. The LPM includes new lumped masses, not previously reported in a single multibody model, for key vehicle side-structure systems identified {{with the help of}} an energy-based study conducted using explicit finite element analysis of two passenger vehicles. In addition to the vehicle side <b>structure,</b> <b>lumped</b> masses for the NHTSA side-impact barrier and ‘rest of vehicle’, the latter implying the mass of the vehicle minus the combined mass of the side-structure subsystems considered in the LPM, have been incorporated so that the total mass of the system corresponds to that of an actual vehicle–barrier system in a NHTSA side-impact test (Lateral Impact New Car Assessment Program (LINCAP) or FMVSS 214). The lumped masses are interconnected with elastic–plastic springs. A unique feature of the present model is the inclusion of two lumped side-impact dummies for obtaining predictions of the front and rear (thoracic trauma index (TTI)). The validity of the present LPM is established by performing LS-DYNA-based LINCAP simulations of two real-world vehicles, namely the Dodge Neon and Dodge Intrepid, and obtaining a reasonably good correlation of the computed structural and occupant responses as well as TTI (front and rear) with the corresponding test results reported by the NHTSA...|$|R
40|$|International audienceCoupled {{resonators}} in an assembled structure {{lose their}} individuality and in co-operation {{contribute to the}} generation of structure modes (resonant frequencies). The resonant frequencies of these modes are the only measurable quantities. In order to predict structural behaviour {{in a variety of}} cases, the problem that arises is the extraction of all the parameters characterizing the structure from the measurements mentioned here. If all the modes are confined in a bandwidth that is small with respect to the central frequency, the total coupled resonator system is well represented by a circuit of unknown <b>lumped</b> constants. The <b>structure</b> modes are the solutions of the equation obtained by equating to zero the determinant relevant to the lumped circuit representation. The equation is a polynomial of the squared frequency variable, the degree of which is equal to the number M of circuits. The analysis method described in this paper consists in varying, by an unknown amount, the frequency of a single resonator in the chain. This variation will produce a change in the frequencies of all structure modes. It is possible to find certain invariants linearly dependent on all the unchanged parameters of the circuit. These invariants have an algebraic representation that allows the extraction of the structure parameter values with extremely high accuracy. The proposed method is quite general and, in the present work, we give an example applying the method to the characterization of a side-coupled linac (SCL...|$|R
40|$|Active pipe-embedded {{building}} envelope {{is a new}} {{building envelope}}, which is an external wall or roof with pipes embedded in it. This structure has the advantages to utilize directly low-grade energy sources for reducing building cooling/heating load and improving indoor thermal comfort. This structure may also use some phase change materials (PCM) to be pasted as a thin layer for further enhancing these benefits. This paper presents a dynamic simplified thermal model of this structure with the thermal network <b>structure</b> of <b>lumped</b> thermal mass, and the parameter identification of the simplified model based on frequency characteristic analysis. These resistances and capacitances are identified in frequency domain by using generic algorithm (GA) by comparing the frequency characteristics of the simplified model with the theoretical frequency characteristics of this structure obtained with Frequency-Domain Finite Difference (FDFD) method. Firstly, the FDFD model of this structure is established, and the theoretical frequency characteristics under various disturbances are calculated for the reference of parameter identification. Then, an equivalent dynamic simplified thermal model with <b>lump</b> thermal network <b>structure</b> is developed, and its frequency characteristics are also deduced and calculated. Finally, GA estimator is used to identify these parameters of the simplified model for allowing the frequency responses of the simplified model to match the theoretical frequency responses by using FDFD method. Various case studies are presented to validate {{the accuracy of the}} simplified models and the effectiveness of the parameter identification for the model. Department of Building Services Engineerin...|$|R
40|$|Continuous crystallizers are {{distributed}} dynamical systems. Physical modeling {{of these systems}} using basic principles results in partial and integro-differential equations. To exploit the physical models, {{in the analysis of}} the system behavior and the design of an appropriate controller, requires complicated measurement techniques especially in the spatial domain (crystal size distribution or crystal population density). Therefore, obtaining a <b>lumped</b> model <b>structure</b> is desirable. The lumped model of a continuous crystallizer can be obtained either from the physical model, using conventional techniques such as the discretization or function separation methods, or from input and output measurements using system identification approaches. Studies of the crystallization process have indicated that in order to improve the control performance, expressing the process dynamics using single-input, single-output models is insufficient. The aim of this thesis was to investigate the process behavior in a multivariable framework. In this regard, the dynamics of a continuous cooling KCl crystallizer were identified using three-input, three-output linear and nonlinear model structures. The autoregressive exogenous model structures were employed in linear modeling of the process. The nonlinear modeling was performed using several architectures of feedforward and recurrent neural networks. Simulation results demonstrated that the linear modeling, using a single model for the entire dynamics, is not adequate. Either multi-model or nonlinear modeling is recommended. The performance of different neural network structures in the nonlinear modeling of the process was illustrated and, based on the results, some comparisons were made between these networks. The next step {{in the study of the}} crystallization process as a multivariable system was to design and apply a multivariable control scheme. Simulation results from the modeling of the process indicated that strong interactions are present among different loops of the system. The process is nonlinear and some of the outputs exhibit inverse or non-minimum-phase responses. The model predictive control strategy is known to perform well in the control of the systems with the behaviors found in the crystallization process. To ensure a feasible solution, the feasible sequential quadratic optimization algorithm was successfully exploited in a model predictive controller. Computer simulations of the controller were performed in order to demonstrate control of the crystal size distribution, crystal purity, and production rate. The effects of different control parameters were illustrated using the simulation results. A brief discussion on how to select these parameters was also provided. Robustness of the model predictive controller was studied in the presence of mismatch between the model and the process...|$|R
30|$|Malaria is an Anopheles {{mosquito}} borne {{parasitic disease}} triggered by four species of genus plasmodium including P. falciparum, P. vivax, P. ovale, and P. malariae. Amongst these, P. falciparum {{is the most}} dangerous species because it can penetrate into deeper tissues and infect red blood corpuscles leading to its breakdown and rupture, forming sticky <b>lump</b> like mass <b>structure</b> in the blood capillary which may ground circulatory arrest such as cerebral attack causing death of the individual (Tham and Kennedy 2015). As per the updated reports approximately 3.4 billion cases of malaria occur every year and about 1.3 million deaths occurred in the year of 2013 worldwide (Seder 2014). Brutal death of more than 1 million people globally cries to develop new antimalarial chemotherapeutics. One of the promising antimalarial chemotherapeutics is 4 -anilinoquinoline derivatives including amodiaquine and piperaquine which act as blood schizontoside and haemazoin inhibitors. Due to drug resistance and lack of knowledge of exact mechanism of action of these series of compounds, it is really urgent to design and develop new congeneric leads utilizing structure activity-property relationship studies. Although the structure–property-activity relationships were developed since long years back (Crum-Brown and Fraser 1968), but now it is a multidisciplinary area of molecular design and are widely used for the prediction of properties, activities and/or toxicities of new chemicals by developing quantitative relationship between molecular activity or property (such as partition coefficient (log P), boiling point, melting point, acid and base constant, chromatographic retention index, toxicity, or reactivity) and computed structural properties such as constitutional, electrostatic, geometrical, topological, or quantum chemical molecular characteristics (Basak et al. 1997; Pompe and Novic 1999; Randic 1975; Roy et al. 2015 a, b, c). Therefore in the present paper QSAR modelling has been carried out for antimalarial 4 -anilinoquinolines based on the computed structure–property-activity correlations.|$|R
40|$|M. Ing. Electromagnetic Compatibility (EMC) of {{electronic}} equipment is currently an important design parameter. Layout {{play a significant}} role in the EMC of power electronic converters. This thesis describes an investigation undertaken into the electromagnetic effects of converter layout. Typical detrimental effects identified during experimental work are presented. Possible causes for these effects are discussed. The experimental work is based on a systematic approach, which starts with a basic single switch chopper and ends in a split supply half-bridge converter. Interconnection modelling and SPICE simulations of layout affects are investigated next. The focus falls on analytical equations for extraction and simplified simulation circuits to make the process generally accessible. Typical resonant frequencies present in some of the experimental circuits are investigated with the help of analytically extracted parameters. The possibility of minimizing detrimental layout effects through impedance matching of interconnections and their terminations, is investigated next, since the previous section quantified layout parameters. Distributed vs. lumped element modelling of interconnections, and the boudary in between, are discussed. Simulation and experimental results are presented. Since maximum fuctionality and power, and minimum cost, per volume drives product development, all elements of a circuit should be investigated for the possibility of realizing secondary or even tertiary functions contributing to normal circuit operation. This is the focus of the last part of this thesis. Employing interconnections as low-pass or surge filters are investigated. Several waveforms are used to test experimental interconnection <b>structures.</b> <b>Lumped</b> and distributed modelling of these strucutres are discussed. The thesis concludes with a theoretical investigation into the possibility of dissipation of surge-energy instead of reflection utilizing interconnection-structures. One of these structures utilizes the skin- and proximity effect to realize low-pass behaviour...|$|R
40|$|Poulakakis, IoannisA {{series of}} quadrupedal robots with {{different}} morphologies {{has been developed}} in the past forty years to explore the enhanced mobility such platforms may offer. The majority of these robots incorporate rigid, non-deformable torsos, a feature that distinguishes them from {{their counterparts in the}} animal world, which owe much of their remarkable locomotion abilities to their flexible bodies. Biological research indicates that torso flexibility may contribute to increased running speed, reduced energy cost and improved gait stability. This thesis proposes a modeling hierarchy that incorporates biological observations within a series of models with increasing complexity, and develops systematic feedback control algorithms for highly dynamic quadrupedal running motions that harness torso flexibility and compliant legs. On a macroscopic level, reduced-order models, or “templates”, can capture the dominant features of an observed locomotion behavior without delving into the fine details of a robot’s (or animal’s) structure and morphology. Templates provide unified, platform-independent descriptions of the desired locomotion task, and they have proved to be indispensable in designing legged robots and in synthesizing controllers for stabilizing highly-agile locomotion behaviors. One representative example is the Spring Loaded Inverted Pendulum (SLIP), which, despite its very simple structure, captures the evolution of kinetic and potential energy associated with running motions, and has informed controller design of many legged robots. However, because of its simple <b>lumped</b> point-mass <b>structure,</b> the SLIP and its immediate extensions cannot describe some of the common quadrupedal gaits that involve pronounced torso oscillations, such as bounding and galloping. Motivated by the capability as well as the limitations of SLIP-type templates, a number of reduced-order quadrupedal models that incorporate non-point-mass torsos has been proposed in the relevant literature to investigate quadrupedal running. However, partly because of the need to describe the torso morphology of the corresponding hardware platforms, and partly because of the need to simplify running dynamics, most of these quadrupedal templates only consider non-deformable, rigid torsos. Although, a few studies with preliminary results on running with torso compliance {{can be found in the}} relevant literature, studies on the conditions for generating periodic locomotion behaviors are rather limited while the stability properties of these motions are not carefully examined. As a result, feedback controller design in the presence of torso compliance has not been carefully investigated. Beyond stability and control design, the energetic cost of transport of quadrupedal running and, in particular, the contribution of torso flexibility to running efficiency, has not received adequate attention. This thesis aims at proposing a modeling and control hierarchy that enables the systematic evaluation of the role of torso compliance in quadrupedal running. The proposed templates have different modeling complexities and actuation schemes, and can be used to facilitate the investigation of a number of key issues in quadrupedal running, such as motion generation, gait stability, feedback design, gait transitions and energy efficiency. Through careful analysis of the models, a series of useful conclusions can be drawn; these conclusions pave the way toward synthesizing feedback control laws for legged robots with torso and leg compliance, and provide insight into designing robotic platforms that harness elastic elements to realize high-performance, reliable and natural-like quadrupedal running motions. University of Delaware, Department of Mechanical EngineeringPh. D...|$|R
40|$|Diaphragms are {{elements}} of the seismic force resisting system in charge of stabilizing structures by tying in vertical elements, transferring inertial forces from one vertical element of the seismic force-resisting system to another and transferring shear forces from one vertical element to another. When vertical {{elements of}} the seismic force resisting system are offset horizontally conditions, the diaphragm that connects them must transfer large story shears in {{what is known as}} a transfer condition. Transfer conditions are often unavoidable and remain one of the least understood and most consequential aspects of building response in an earthquake. Poor performance of transfer structures in recent earthquakes further underscores the importance of determining the true behavior of transfer structures under seismic loading. In order to begin to understand the behavior of transfer structures under seismic loading, finite element models were created for a 12 story building with offset shear walls. The models created represent one half of the building <b>structure</b> <b>lumped</b> into the two frames containing the shear walls in each half of the building. The first set of models (Phase 1) were developed starting from a nonlinear shear wall model. The model was incrementally made more complex, starting by adding a rigid, elastic transfer structure, and then elastic columns. Afterwards nonlinearity was added to the columns and finally typical floor diaphragms were added to the building. While results from these models showed similar curves for shear vs displacement and moment vs rotation for all models, issues with the fiber models used for the last model of this phase deemed the model too complex for the analyses required, particularly when modal analyses were performed on the structure. The next set of models was developed from two two-dimensional models, one for each frame. Incrementally, the model was made more complex, starting by modeling the frames in three dimensions, with diaphragms being modeled as beams initially and then as shells. Seismic design loads were applied to this model {{in order to determine the}} shear and moment profiles of the building, as well as the shear transfer occurring at every story. Nonlinearity was added to the base of the building, yielding similar results to the elastic models with respect to the shear and moment profiles, but very different results for the shear vs displacement and moment vs rotation curves for the Phase 1 models...|$|R
40|$|Two {{different}} soils may {{be generated}} from open-pit mining: lumpy soils with a granular structure and clay mixtures, {{depending on the}} length of the conveyor belt and the strength of the original soils. Lumpy soils may be created for a high strength of the excavated soils. They are dumped as landfills without any compaction, which permits the water and air flows via the inter-lump voids. As a result, a new structure consisting of the lumps and reconstituted soil within the inter-lump voids can be created. However, if the original soil has a low strength or a long transportation takes place, the material may disintegrate into small lumps and thoroughly mix soils from different layers. Landfills consisting of clay mixtures arise in this way. The stability and deformation of landfills are crucial for design of occupied area and landfill slopes. For this reason, three different landfill materials will be investigated in this thesis: (1) the lumpy granular soil from fresh landfills, (2) the lumpy composite soil corresponding to old landfills and (3) clay mixtures. Firstly, an artificial lumpy soil was investigated. It is a transition form between the reconstituted and natural lumpy soils. Compression, permeability and strength of lumpy materials have been evaluated based on oedometer and triaxial tests. The shear strength of the normally consolidated lumpy specimens lies approximately on the Critical State Line of the reconstituted soil. The reconstituted soil, which exists in the inter-lump voids, plays {{a crucial role in the}} behaviour of artificial lumpy materials. Similarly to the artificial lumpy soil, inter-lump voids of the natural lumpy soil are mainly closed above a relatively small stress level, which is induced by the rearrangement of the lumps. However, its limit stress state is located above the Critical State Line of the reconstituted soil, which may be caused by the diagenetic soil structure in the natural <b>lumps.</b> The <b>structure</b> transition of the lumpy granular material can be divided into three possible stages related to the stress level. Firstly, the compressibility of a fresh lumpy is relativity high due to the closure of the inter-lump voids within a low stress range. In this stage, the hydraulic conductivity is mainly controlled by the inter-lump skeleton due to the existence of macro drainage paths, while the shear strength is controlled by the reconstituted soil around the lumps. Afterwards, its compressibility decreases with the consolidation stress and the soil behaves similarly to an overconsolidated soil. The clayfill appears to be uniform visually in this stage, but its structure is still highly heterogeneous and the hydraulic conductivity is higher than that of the reconstituted soil with the same overall specific volume. Finally, the loading reaches the preconsolidation stress of the lumps, and the whole soil volume becomes normally consolidated. Isotropically consolidated drained triaxial shear tests were performed on artificially prepared specimens with parallel and series structures. The laboratory tests show that the specimens with the series structure have the same failure mode as the constituent with the lower strength; the specimens with the parallel structure have a failure plane which crosses both constituents. As a result, the shear strength of the series specimens is only slightly higher than that of the constituent with the lower strength and the strength of the parallel specimens lies between those of the constituents. Afterwards, the behaviour of an artificial lumpy material with randomly distributed inclusions is investigated using the Finite Element Method. The computation results show that the stress ratio, defined as the ratio of the volume-average stress between the lumps and the reconstituted soil within the inter-lump voids, is significantly affected by both the volume fraction and the preconsolidation pressure of the lumps under an isotropic compression path, while the volume fraction of the lumps plays a minor role under a triaxial compression path. Based on the simulation results and analysis of the two basic configurations, a homogenization law was proposed utilizing the secant stiffnesses. The compression behavior of the lumpy composite soil was analyzed within the homogenization framework. Firstly, the volume of the composite soil was divided into four individual components. The inter-lump porosity was introduced to account for the evolution of the volume fractions of the constituents, and it was formulated as a function of the overall porosity and those of its constituents. A homogenization law was then proposed based on the analysis of the lumpy structure together with a numerical method, which gives a relationship for tangent stiffnesses of the lumpy soil and its constituents. Finally, a simple compression model was proposed for the composite lumpy material, which incorporates both the influence of the soil structure and the volume fraction change of the reconstituted soil. Furthermore, a general framework for the consolidation behaviour of the lumpy composite soil was proposed based on the double porosity concept and the homogenization theory. To describe the behaviour of lumps with low stress level, a new failure line was proposed with help of the equivalent Hvorslev pressure and critical state concept. The structure effect was incorporated into the nonlinear Hvorslev surface within sensitivity framework and the generalized Cam clay model proposed by McDowell and Hau (2003) was adopted on the wet side of the critical state. A secant stiffness, defined as the ratio between the deviatoric stress and deviatoric strain, was used in the homogenization law. Finally, a simple model for the natural lumpy soil was proposed within the homogenization framework. The physical properties, compression behaviour and remolded undrained shear strength of clay mixtures were investigated by reproducing the soils artificially in the lab. Afterwards, the models for the compression and undrained shear strength of clay mixtures were proposed. The model for the strength of the clay mixture originated from simplifying the structure of a clay mixture, in which the elements of the constituents are randomly distributed in a representative elementary volume. By defining a water content ratio (the ratio of water contents between the constituents), the undrained shear strength of each constituent was estimated separately and then combined together with corresponding volume fractions. A homogenization law was proposed afterwards based on the analysis of the randomly arranged structure. A simple compression model considering $N$ constituents was proposed within the homogenization framework, which was evaluated by a mixture with two constituents. In einem Tagebau können die feinkörnigen Böden in unterschiedlichen Zustandsformen entstehen. Dies sind zum einen klumpige Böden mit einer granular ähnlichen Struktur (Pseudokornstruktur) und einer hohen Konsistenzzahl und zum anderen Mischungen aus mehreren Tonen oder Schluffen mit niedriger Konsistenzzahl. Der Zustand wird dabei massgebend von dem Transport (z. B. Länge des Förderbandes) und dem Ausgangszustand (z. B. der Anfangsscherfestigkeit) beeinflusst. Klumpige Böden entstehen bei der Abbaggerung des natürlichen Materials auf der Abbauseite, welches eine hohe Festigkeit besitzt. Alle Böden werden normalerweise ohne Verdichtung verkippt, so entstehen bei der Verkippung von klumpigen Böden grosse Makro-Porenräume zwischen den Klumpen, welche sehr luft- bzw. wasserdurchlässig sind. Nach einiger Zeit entsteht eine neue Struktur aus den Klumpen und dem Material des sich von aussen auflösenden Klumpens, welches das Füllmaterial bildet. Wenn die Festigkeit des Ausgangsmaterials niedrig ist oder lange Transportwege stattfinden, zerfallen die Klumpen. Zudem werden die Böden von verschiedenen Schichten der Abbauseite unter einander gemischt, wodurch die Tongemische entstehen. Sowohl für die Dimensionierung und Berechnung der aus den Verkippungen entstehenden Tagebaurandböschungen sowie für eine spätere Nutzung des ehemaligen Tagebaugebietes ist die Kenntnisüber das Deformations- und Verformungsverhalten von Kippenböden notwendig. Daher wurden in dieser Arbeit Tagebauböden und ihr zeitlich veränderliches Verhalten untersucht. Dabei werden diese, bezugnehmend auf den Anfangszustand, in drei typische Materialien unterschieden: (1) der frisch verkippte klumpige Boden, (2) eine Mischung aus Klumpen und Füllmaterial, welche höhere Liegezeiten repräsentiert und (3) Mischungen von feinkörnigen Ausgangsböden. Zunächst wurden künstlich hergestellte klumpige Böden untersucht. Sie bilden eine Übergangsform zwischen aufbereiteten und natürlichen klumpigen Böden. Das Kompressions- und Scherverhalten sowie die Durchlässigkeit wurden an Ödometer und Triaxialversuchen bestimmt. Das Füllmaterial, welches die Makroporen zwischen den Klumpen füllt, spielt eine entscheidende Rolle für das Materialverhalten. Ähnlich wie bei den künstlich hergestellten klumpigen Böden schliessen sich auch bei den Böden im Tagebau die Makroporenschen bei niedrigen Spannungen. Dabei werden die Klumpen umgelagert. Allerdings befindet sich die Grenze des Spannungszustandes oberhalb der Critical State Line des Füllmaterials, was möglicherweise mit den unter Diagenese entstandenen Bodenstrukturen erklärt werden kann. Die Strukturänderung der klumpigen Böden kann aufgrund des Spannungsniveaus in drei mögliche Stufen unterteilt werden. Am Anfang ist die Kompressibilität der frischen verkippten Klumpen hoch, da sich die Makroporen bereits bei geringen Spannungen schliessen. Zu diesem Zeitpunkt sind auch die Durchlässigkeiten in erster Linie von den grossen Porenräumen der Makroporen, welche als Entwässerungspfade dienen, beeinflusst. Die Scherfestigkeit hingegen, wird durch die aufgeweichten Böden an den Oberflächen der Klumpen massgebend beeinflusst. Bei höheren Konsolidationspannungen sinkt die Kompressibilität und der Boden verhält sich wie einüberkonsolidierter Boden. Obwohl die Struktur aufgrund der veränderten Klumpenoberflächen zu diesem Zeitpunkt homogener wirkt, ist die Struktur noch heterogen und die Durchlässigkeit ist höher als bei einem aufbereiteten Boden mit gleichem spezifischem Volumen (Porenzahl). Letztendlich erreicht der aktuelle Spannungszustand den derüberkonsolidierten Klumpen und der gesamte Boden verhält sich wie ein normal konsolidierter Boden. Des Weiteren wurden isotrop konsolidierte drainierte Triaxialversuche an künstlich aus zwei Ausgangsmaterialien hergestellten Proben mit parallelen und seriellen Strukturen durchgeführt. Die Laborversuche zeigten, dass die Proben mit seriellem Aufbau dieselben Gleitflächen haben, wie der Ausgangsboden mit der niedrigeren Scherfestigkeit. Die Gleitfläche der Proben mit parallelen Strukturen verlief durch beide Materialien. Es wurde festgestellt, dass die Scherfestigkeit der seriell aufgebauten Proben geringfügig höher, als die des Bodens mit der niedrigeren Scherfestigkeit ist. Die Scherfestigkeit der parallel aufgebauten Proben liegt zwischen den beiden Ausgangsmaterialien. Danach wurde das Verhalten der künstlich erzeugten klumpigen Böden mit zufällig verteiltem Füllmaterial mit Hilfe der Finiten Elemente Methode verglichen. Die Simulationen zeigten, dass unter einer isotropen Kompressionsbelastung das Spannungsverhältnis, definiert aus dem Verhältnis der Spannung des Volumendurchschnitts zwischen den Klumpen und dem Füllmaterial, deutlich durch die Volumenanteile und die Vorkonsoliderungsspannung der Klumpen beeinflusst wird. Während das Volumenverhältnis eine untergeordnete Rolle in den in Triaxialzellen unter Scherung belasteten Proben spielt. Aus den Simulationsergebnissen und den Laborversuchen der beiden Grundkonfigurationen wurde ein Homogenisierungsgesetz abgeleitet, welches die Sekandensteifigkeiten verwendet. Das Kompressionsverhalten der Mischungen aus Klumpen und Füllmaterial wurde mit Blick auf die Homogenisierung analysiert. Zunächst kann das Volumen der Mischungen in 4 individuelle Komponentenanteile zerlegt werden. Die Makroporosität zwischen den Klumpen wurde zur Entwicklung der Volumenanteile des Füllmaterials eingeführt. Sie wurde als eine Funktion der totalen Porosität und der Materialien formuliert. Auf Grundlage einer theoretischen Analyse an klumpigen Böden und unter Zuhilfenahme einer numerischen Methode wird ein Gesetz zur Homogenisierung vorgeschlagen. Dieses enthält eine Beziehung zwischen der Tagentensteifigkeit der Klumpen und seinem Füllmaterial. Abschliessend wird ein einfaches Kompressionsmodel für die Mischung aus Klumpen und Füllmaterial vorgeschlagen, welches den Einfluss der Bodenstruktur und der Änderung des Volumenanteils des Füllmaterials berücksichtigt. Darüber hinaus wurde eine allgemeine Formulierung für das Konsolidationsverhalten der klumpigen Böden mit Füllmaterial vorgeschlagen, welche sich auf das Konzept der doppelten Porosität (Klumpen und Füllmaterial) und eine Homogenisierungstheoerie bezieht. Um das Verhalten der Klumpen bei niedrigen Spannungen zu beschreiben, wird eine neue Grenzbedingung unter Zuhilfenahme der äquivalenten Hvorslev-Spannung und des Criticial State Konzeptes vorgeschlagen. Der Struktureffekt für sensitive Böden wurde in die nichtlineare Hvorslev-Oberfläche eingebaut. Das allgemein gültige Cam-Clay-Model von McDowell und Hau (2003) wurde um die nasse Seite des Critical State Konzeptes erweitert. Eine Sekandensteifigkeit, definiert aus dem Verhältnis zwischen der Deviatorspannung und der Deviatordehnung, wurde für das Homogenisieurungsgesetz ebenfalls verwendet. Abschliessend wird ein Modell für natürliche klumpige Böden vorgestellt, welches auch eine Homogenisierung beinhaltet. Die physikalischen Eigenschaften, das Kompressionsverhalten und die undrainierten Scherfestigkeiten von aufbereiten Tongemischen wurden im Labor unter Herstellung künstlicher Bödengemische untersucht. Anschliessend wurde ein Kompressions- und Schermodell für aufbereitete Tongemische vorgeschlagen. Das Modell der Scherfestigkeit der Tongemische entstand aus der Vereinfachung der Tongemischstruktur, in welcher die Elemente der Ausgangsmaterialien zufällig in dem Einheitsvolumen verteilt sind. Werden Wassergehaltsverhältnisse (das Verhältnis der Wassergehalte der Ausgangsmaterialien) definiert, kann die undrainierte Scherfestigkeit für alle Bestandteile separat geschätzt werden und dannüber die Volumenanteile bestimmt werden. Ein Homogenisierungsgesetz wurde auf Grundlage der theoretischen Analyse von zufällig angeordneten Strukturen entwickelt. Ein einfaches Kompressionsmodell, welches N-Ausgangsmaterielien bzw. Tone und eine Homogenisierung enthält, wird vorgeschlagen, und an einer Mischung aus 2 Bestandteilen im Labor validiert...|$|R

